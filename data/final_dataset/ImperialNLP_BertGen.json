{"home.repos.pwc.inspect_result.ImperialNLP_BertGen.LanguageGeneration.train_end2end.parse_args": [[11, 47], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "LanguageGeneration.function.config.update_config", "os.path.join", "int", "int", "torch.cuda.device_count", "subprocess.getoutput", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.scripts.launch.parse_args", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.function.config.update_config"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "'Train Cognition Network'", ")", "\n", "parser", ".", "add_argument", "(", "'--cfg'", ",", "type", "=", "str", ",", "help", "=", "'path to config file'", ")", "\n", "parser", ".", "add_argument", "(", "'--model-dir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'root path to store checkpoint'", ")", "\n", "parser", ".", "add_argument", "(", "'--log-dir'", ",", "type", "=", "str", ",", "help", "=", "'tensorboard log dir'", ")", "\n", "parser", ".", "add_argument", "(", "'--dist'", ",", "help", "=", "'whether to use distributed training'", ",", "\n", "default", "=", "False", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--slurm'", ",", "help", "=", "'whether this is a slurm job'", ",", "\n", "default", "=", "False", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--do-test'", ",", "help", "=", "'whether to generate csv result on test set'", ",", "\n", "default", "=", "False", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--cudnn-off'", ",", "help", "=", "'disable cudnn'", ",", "\n", "default", "=", "False", ",", "action", "=", "'store_true'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "cfg", "is", "not", "None", ":", "\n", "        ", "update_config", "(", "args", ".", "cfg", ")", "\n", "", "if", "args", ".", "model_dir", "is", "not", "None", ":", "\n", "        ", "config", ".", "OUTPUT_PATH", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_dir", ",", "config", ".", "OUTPUT_PATH", ")", "\n", "\n", "", "if", "args", ".", "slurm", ":", "\n", "        ", "proc_id", "=", "int", "(", "os", ".", "environ", "[", "'SLURM_PROCID'", "]", ")", "\n", "ntasks", "=", "int", "(", "os", ".", "environ", "[", "'SLURM_NTASKS'", "]", ")", "\n", "node_list", "=", "os", ".", "environ", "[", "'SLURM_NODELIST'", "]", "\n", "num_gpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "addr", "=", "subprocess", ".", "getoutput", "(", "\n", "'scontrol show hostname {} | head -n1'", ".", "format", "(", "node_list", ")", ")", "\n", "os", ".", "environ", "[", "'MASTER_PORT'", "]", "=", "str", "(", "29500", ")", "\n", "os", ".", "environ", "[", "'MASTER_ADDR'", "]", "=", "addr", "\n", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", "=", "str", "(", "ntasks", ")", "\n", "os", ".", "environ", "[", "'RANK'", "]", "=", "str", "(", "proc_id", ")", "\n", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", "=", "str", "(", "proc_id", "%", "num_gpus", ")", "\n", "\n", "", "return", "args", ",", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.LanguageGeneration.train_end2end.main": [[49, 52], ["train_end2end.parse_args", "LanguageGeneration.function.train.train_net"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.scripts.launch.parse_args", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.function.train.train_net"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", ",", "config", "=", "parse_args", "(", ")", "\n", "rank", ",", "model", "=", "train_net", "(", "args", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.LanguageGeneration._init_paths.add_path": [[7, 10], ["sys.path.insert"], "function", ["None"], ["def", "add_path", "(", "path", ")", ":", "\n", "    ", "if", "path", "not", "in", "sys", ".", "path", ":", "\n", "        ", "sys", ".", "path", ".", "insert", "(", "0", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.LanguageGeneration.test.parse_args": [[10, 39], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "LanguageGeneration.function.config.update_config", "os.path.join", "str"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.scripts.launch.parse_args", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.function.config.update_config"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "'Get Test Result of Retrieval Network'", ")", "\n", "parser", ".", "add_argument", "(", "'--cfg'", ",", "type", "=", "str", ",", "\n", "help", "=", "'path to retrieval net config yaml'", ")", "\n", "parser", ".", "add_argument", "(", "'--ckpt'", ",", "type", "=", "str", ",", "\n", "help", "=", "'path to checkpoint of retrieval net'", ")", "\n", "parser", ".", "add_argument", "(", "'--bs'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--gpus'", ",", "type", "=", "int", ",", "nargs", "=", "'+'", ")", "\n", "parser", ".", "add_argument", "(", "'--model-dir'", ",", "type", "=", "str", ",", "\n", "help", "=", "'root path to store checkpoint'", ")", "\n", "parser", ".", "add_argument", "(", "'--result-path'", ",", "type", "=", "str", ",", "\n", "help", "=", "'path to store test result file.'", ")", "\n", "parser", ".", "add_argument", "(", "'--result-name'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--split'", ",", "default", "=", "'test2015'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "cfg", "is", "not", "None", ":", "\n", "        ", "update_config", "(", "args", ".", "cfg", ")", "\n", "", "if", "args", ".", "bs", "is", "not", "None", ":", "\n", "        ", "config", ".", "TEST", ".", "BATCH_IMAGES", "=", "args", ".", "bs", "\n", "", "if", "args", ".", "gpus", "is", "not", "None", ":", "\n", "        ", "config", ".", "GPUS", "=", "','", ".", "join", "(", "[", "str", "(", "gpu", ")", "for", "gpu", "in", "args", ".", "gpus", "]", ")", "\n", "", "if", "args", ".", "split", "is", "not", "None", ":", "\n", "        ", "config", ".", "DATASET", ".", "TEST_IMAGE_SET", "=", "args", ".", "split", "\n", "", "if", "args", ".", "model_dir", "is", "not", "None", ":", "\n", "        ", "config", ".", "OUTPUT_PATH", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_dir", ",", "config", ".", "OUTPUT_PATH", ")", "\n", "\n", "", "return", "args", ",", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.LanguageGeneration.test.main": [[41, 45], ["test.parse_args", "LanguageGeneration.function.test.test_net"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.scripts.launch.parse_args", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.function.test.test_net"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", ",", "config", "=", "parse_args", "(", ")", "\n", "result_json_path", "=", "test_net", "(", "args", ",", "config", ",", "\n", "ckpt_path", "=", "args", ".", "ckpt", ",", "save_path", "=", "args", ".", "result_path", ",", "save_name", "=", "args", ".", "result_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_generate_mt.BERTGENGenerateMT.__init__": [[15, 63], ["common.module.Module.__init__", "common.fast_rcnn.FastRCNN", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "external.pytorch_pretrained_bert.BertTokenizer.from_pretrained", "common.visual_linguistic_bert.VisualLinguisticBertForPretraining", "bertgen_generate_mt.BERTGENGenerateMT.init_weight", "bertgen_generate_mt.BERTGENGenerateMT.fix_params", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "os.path.isdir", "print", "os.path.join", "os.path.isfile"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.from_pretrained", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.init_weight", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.fix_params"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "\n", "        ", "super", "(", "BERTGENGenerateMT", ",", "\n", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "image_feature_extractor", "=", "FastRCNN", "(", "config", ",", "\n", "average_pool", "=", "True", ",", "\n", "final_dim", "=", "config", ".", "NETWORK", ".", "IMAGE_FINAL_DIM", ",", "\n", "enable_cnn_reg_loss", "=", "False", ")", "\n", "self", ".", "object_linguistic_embeddings", "=", "nn", ".", "Embedding", "(", "\n", "1", ",", "config", ".", "NETWORK", ".", "VLBERT", ".", "hidden_size", ")", "\n", "if", "config", ".", "NETWORK", ".", "IMAGE_FEAT_PRECOMPUTED", ":", "\n", "            ", "self", ".", "object_mask_visual_embedding", "=", "nn", ".", "Embedding", "(", "1", ",", "2048", ")", "\n", "", "if", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", ":", "\n", "            ", "self", ".", "object_mask_word_embedding", "=", "nn", ".", "Embedding", "(", "\n", "1", ",", "config", ".", "NETWORK", ".", "VLBERT", ".", "hidden_size", ")", "\n", "", "self", ".", "aux_text_visual_embedding", "=", "nn", ".", "Embedding", "(", "\n", "1", ",", "config", ".", "NETWORK", ".", "VLBERT", ".", "hidden_size", ")", "\n", "self", ".", "image_feature_bn_eval", "=", "config", ".", "NETWORK", ".", "IMAGE_FROZEN_BN", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "\n", "config", ".", "NETWORK", ".", "BERT_MODEL_NAME", ")", "\n", "language_pretrained_model_path", "=", "None", "\n", "if", "config", ".", "NETWORK", ".", "BERT_PRETRAINED", "!=", "''", ":", "\n", "            ", "language_pretrained_model_path", "=", "'{}-{:04d}.model'", ".", "format", "(", "config", ".", "NETWORK", ".", "BERT_PRETRAINED", ",", "\n", "config", ".", "NETWORK", ".", "BERT_PRETRAINED_EPOCH", ")", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "config", ".", "NETWORK", ".", "BERT_MODEL_NAME", ")", ":", "\n", "            ", "weight_path", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "NETWORK", ".", "BERT_MODEL_NAME", ",", "BERT_WEIGHTS_NAME", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "weight_path", ")", ":", "\n", "                ", "language_pretrained_model_path", "=", "weight_path", "\n", "\n", "", "", "if", "language_pretrained_model_path", "is", "None", ":", "\n", "            ", "print", "(", "\"Warning: no pretrained language model found, training from scratch!!!\"", ")", "\n", "\n", "", "self", ".", "vlbert", "=", "VisualLinguisticBertForPretraining", "(", "\n", "config", ".", "NETWORK", ".", "VLBERT", ",", "\n", "language_pretrained_model_path", "=", "None", "if", "config", ".", "NETWORK", ".", "VLBERT", ".", "from_scratch", "else", "language_pretrained_model_path", ",", "\n", "with_rel_head", "=", "config", ".", "NETWORK", ".", "WITH_REL_LOSS", ",", "\n", "with_mlm_head", "=", "config", ".", "NETWORK", ".", "WITH_MLM_LOSS", ",", "\n", "with_mvrc_head", "=", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", ",", "\n", ")", "\n", "\n", "self", ".", "model_path", "=", "config", ".", "OUTPUT_PATH", "\n", "\n", "# init weights", "\n", "self", ".", "init_weight", "(", ")", "\n", "\n", "self", ".", "fix_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_generate_mt.BERTGENGenerateMT.init_weight": [[64, 74], ["bertgen_generate_mt.BERTGENGenerateMT.image_feature_extractor.init_weight", "bertgen_generate_mt.BERTGENGenerateMT.object_mask_visual_embedding.weight.data.fill_", "bertgen_generate_mt.BERTGENGenerateMT.object_mask_word_embedding.weight.data.normal_", "bertgen_generate_mt.BERTGENGenerateMT.object_linguistic_embeddings.weight.data.normal_"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.init_weight"], ["", "def", "init_weight", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "NETWORK", ".", "IMAGE_FEAT_PRECOMPUTED", ":", "\n", "            ", "self", ".", "object_mask_visual_embedding", ".", "weight", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", ":", "\n", "            ", "self", ".", "object_mask_word_embedding", ".", "weight", ".", "data", ".", "normal_", "(", "\n", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "NETWORK", ".", "VLBERT", ".", "initializer_range", ")", "\n", "", "self", ".", "image_feature_extractor", ".", "init_weight", "(", ")", "\n", "if", "self", ".", "object_linguistic_embeddings", "is", "not", "None", ":", "\n", "            ", "self", ".", "object_linguistic_embeddings", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "\n", "std", "=", "self", ".", "config", ".", "NETWORK", ".", "VLBERT", ".", "initializer_range", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_generate_mt.BERTGENGenerateMT.train": [[75, 80], ["super().train", "bertgen_generate_mt.BERTGENGenerateMT.image_feature_extractor.bn_eval"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.trainer.train", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.bn_eval"], ["", "", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "super", "(", "BERTGENGenerateMT", ",", "self", ")", ".", "train", "(", "mode", ")", "\n", "# turn some frozen layers to eval mode", "\n", "if", "self", ".", "image_feature_bn_eval", ":", "\n", "            ", "self", ".", "image_feature_extractor", ".", "bn_eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_generate_mt.BERTGENGenerateMT.fix_params": [[81, 83], ["None"], "methods", ["None"], ["", "", "def", "fix_params", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_generate_mt.BERTGENGenerateMT._collect_obj_reps": [[84, 104], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp.new_zeros", "torch.clamp.new_zeros", "torch.clamp.new_zeros", "range", "object_reps[].view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "len", "torch.clamp.new_zeros.view", "torch.clamp.view", "torch.clamp.view", "torch.clamp.view"], "methods", ["None"], ["", "def", "_collect_obj_reps", "(", "self", ",", "span_tags", ",", "object_reps", ")", ":", "\n", "        ", "\"\"\"\n        Collect span-level object representations\n        :param span_tags: [batch_size, ..leading_dims.., L]\n        :param object_reps: [batch_size, max_num_objs_per_batch, obj_dim]\n        :return:\n        \"\"\"", "\n", "\n", "# In case there were masked values here", "\n", "span_tags_fixed", "=", "torch", ".", "clamp", "(", "span_tags", ",", "min", "=", "0", ")", "\n", "row_id", "=", "span_tags_fixed", ".", "new_zeros", "(", "span_tags_fixed", ".", "shape", ")", "\n", "row_id_broadcaster", "=", "torch", ".", "arange", "(", "\n", "0", ",", "row_id", ".", "shape", "[", "0", "]", ",", "step", "=", "1", ",", "device", "=", "row_id", ".", "device", ")", "[", ":", ",", "None", "]", "\n", "\n", "# Add extra diminsions to the row broadcaster so it matches row_id", "\n", "leading_dims", "=", "len", "(", "span_tags", ".", "shape", ")", "-", "2", "\n", "for", "i", "in", "range", "(", "leading_dims", ")", ":", "\n", "            ", "row_id_broadcaster", "=", "row_id_broadcaster", "[", "...", ",", "None", "]", "\n", "", "row_id", "+=", "row_id_broadcaster", "\n", "return", "object_reps", "[", "row_id", ".", "view", "(", "-", "1", ")", ",", "span_tags_fixed", ".", "view", "(", "-", "1", ")", "]", ".", "view", "(", "*", "span_tags_fixed", ".", "shape", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_generate_mt.BERTGENGenerateMT.forward": [[105, 259], ["text.new_zeros", "text.new_zeros", "text_input_ids.new_zeros", "text_input_ids.new_zeros", "text_input_ids.new_zeros", "text_input_ids.new_zeros", "outputs.update", "torch.cross_entropy.mean", "bertgen_generate_mt.BERTGENGenerateMT.vlbert", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_tensor.repeat().view.repeat().view.repeat().view", "mlm_labels.new_zeros", "text_input_ids.new_zeros", "text_token_type_ids.new_zeros.new_zeros.new_zeros", "text_visual_embeddings_new.transpose.transpose.new_zeros", "text_visual_embeddings_new.transpose.transpose.transpose", "text_visual_embeddings_new.transpose.transpose.transpose", "enumerate", "generated_sentences.append", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "mlm_logits.new_zeros().fill_", "all", "bertgen_generate_mt.BERTGENGenerateMT.tokenizer.convert_tokens_to_ids", "bertgen_generate_mt.BERTGENGenerateMT.tokenizer.convert_tokens_to_ids", "bertgen_generate_mt.BERTGENGenerateMT.tokenizer.convert_tokens_to_ids", "new_sentence.replace", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "position_tensor.repeat().view.repeat().view.repeat", "generated.append", "mlm_logits.new_zeros", "mlm_logits.transpose", "mlm_logits.view", "mlm_labels.view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "generated[].append", "ele.item", "ele.item"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "forward", "(", "self", ",", "\n", "text", ",", "\n", "relationship_label", ",", "\n", "mlm_labels", ")", ":", "\n", "###########################################", "\n", "\n", "############################################", "\n", "\n", "# prepare text", "\n", "        ", "text_input_ids", "=", "text", "\n", "text_tags", "=", "text", ".", "new_zeros", "(", "text", ".", "shape", ")", "\n", "text_token_type_ids", "=", "text", ".", "new_zeros", "(", "text", ".", "shape", ")", "\n", "\n", "# ***** FM edit: blank out visual embeddings for translation retrieval task", "\n", "text_visual_embeddings", "=", "text_input_ids", ".", "new_zeros", "(", "\n", "(", "text_input_ids", ".", "shape", "[", "0", "]", ",", "text_input_ids", ".", "shape", "[", "1", "]", ",", "768", ")", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "# text_visual_embeddings[:] = self.aux_text_visual_embedding.weight[0]", "\n", "\n", "# ****** FM edit: blank visual embeddings (use known dimensions)", "\n", "object_vl_embeddings", "=", "text_input_ids", ".", "new_zeros", "(", "\n", "(", "text_input_ids", ".", "shape", "[", "0", "]", ",", "1", ",", "1536", ")", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "# FM edit: No auxiliary text is used for text only", "\n", "# add auxiliary text - Concatenates the batches from the two dataloaders", "\n", "# The visual features for the text only corpus is just the embedding of the aux_visual_embedding (only one embedding)", "\n", "max_text_len", "=", "text_input_ids", ".", "shape", "[", "1", "]", "\n", "text_token_type_ids", "=", "text_input_ids", ".", "new_zeros", "(", "text_input_ids", ".", "shape", ")", "\n", "text_mask", "=", "(", "text_input_ids", ">", "0", ")", "\n", "# FM: Edit: set to zero to ignore vision", "\n", "box_mask", "=", "text_input_ids", ".", "new_zeros", "(", "\n", "(", "text_input_ids", ".", "shape", "[", "0", "]", ",", "1", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "###########################################", "\n", "# Visual Linguistic BERT", "\n", "# #loop here for test mode:", "\n", "generated", "=", "[", "]", "\n", "stop", "=", "[", "False", "]", "*", "text", ".", "shape", "[", "0", "]", "\n", "curr_len", "=", "0", "\n", "max_len", "=", "300", "\n", "\n", "while", "not", "all", "(", "stop", ")", "and", "curr_len", "<=", "max_len", ":", "\n", "            ", "relationship_logits", ",", "mlm_logits", ",", "mvrc_logits", "=", "self", ".", "vlbert", "(", "text_input_ids", ",", "\n", "text_token_type_ids", ",", "\n", "text_visual_embeddings", ",", "\n", "text_mask", ",", "\n", "object_vl_embeddings", ",", "\n", "box_mask", ")", "\n", "# Ignore special tokens", "\n", "# mlm_logits[:, :, 0] = -10000000", "\n", "# mlm_logits[:, :, 2:100] = -10000000", "\n", "# mlm_logits[:, :, 101:104] = -10000000", "\n", "answers", "=", "torch", ".", "topk", "(", "mlm_logits", "[", "mlm_labels", "==", "103", "]", ",", "k", "=", "1", ",", "dim", "=", "1", ")", "\n", "\n", "# Get size of each tensor", "\n", "position_tensor", "=", "torch", ".", "arange", "(", "mlm_labels", ".", "shape", "[", "1", "]", ")", "\n", "position_tensor", "=", "position_tensor", ".", "repeat", "(", "\n", "mlm_labels", ".", "shape", "[", "0", "]", ")", ".", "view", "(", "mlm_labels", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "indeces", "=", "position_tensor", "[", "mlm_labels", "==", "103", "]", "\n", "\n", "# 1. Update mlm_labels:", "\n", "mlm_labels_new", "=", "mlm_labels", ".", "new_zeros", "(", "\n", "mlm_labels", ".", "shape", "[", "0", "]", ",", "mlm_labels", ".", "shape", "[", "1", "]", "+", "1", ")", "\n", "mlm_labels_new", "=", "mlm_labels_new", "-", "1", "\n", "mlm_labels_new", "[", "torch", ".", "arange", "(", "mlm_labels", ".", "shape", "[", "0", "]", ")", ",", "indeces", "+", "1", "]", "=", "103", "\n", "mlm_labels", "=", "mlm_labels_new", "\n", "\n", "# 2. Update text_input_ids:", "\n", "text_input_ids_new", "=", "text_input_ids", ".", "new_zeros", "(", "\n", "text_input_ids", ".", "shape", "[", "0", "]", ",", "text_input_ids", ".", "shape", "[", "1", "]", "+", "1", ")", "\n", "text_input_ids_new", "[", ":", ",", ":", "-", "1", "]", "=", "text_input_ids", "\n", "text_input_ids_new", "[", "torch", ".", "arange", "(", "\n", "text_input_ids", ".", "shape", "[", "0", "]", ")", ",", "indeces", "]", "=", "answers", "[", "1", "]", "[", ":", ",", "0", "]", "\n", "text_input_ids_new", "[", "torch", ".", "arange", "(", "text_input_ids", ".", "shape", "[", "0", "]", ")", ",", "indeces", "+", "1", "]", "=", "(", "\n", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "'[MASK]'", "]", ")", "[", "0", "]", ")", "\n", "text_input_ids_new", "[", "torch", ".", "arange", "(", "text_input_ids", ".", "shape", "[", "0", "]", ")", ",", "indeces", "+", "2", "]", "=", "(", "\n", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "'[PAD]'", "]", ")", "[", "0", "]", ")", "\n", "text_input_ids_new", "[", "torch", ".", "arange", "(", "text_input_ids", ".", "shape", "[", "0", "]", ")", ",", "indeces", "+", "3", "]", "=", "(", "\n", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "'[SEP]'", "]", ")", "[", "0", "]", ")", "\n", "text_input_ids", "=", "text_input_ids_new", "\n", "\n", "# 3. Update text_token_type_ids:", "\n", "text_token_type_ids", "=", "text_token_type_ids", ".", "new_zeros", "(", "\n", "text_token_type_ids", ".", "shape", "[", "0", "]", ",", "text_token_type_ids", ".", "shape", "[", "1", "]", "+", "1", ")", "\n", "\n", "# 4. Update text_input_ids:", "\n", "text_visual_embeddings_new", "=", "text_visual_embeddings", ".", "new_zeros", "(", "\n", "text_visual_embeddings", ".", "shape", "[", "0", "]", ",", "text_visual_embeddings", ".", "shape", "[", "1", "]", "+", "1", ",", "text_visual_embeddings", ".", "shape", "[", "2", "]", ")", "\n", "text_visual_embeddings_new", "=", "text_visual_embeddings_new", ".", "transpose", "(", "\n", "0", ",", "1", ")", "\n", "text_visual_embeddings_new", "[", ":", "]", "=", "text_visual_embeddings", "[", ":", ",", "0", ",", ":", "]", "\n", "text_visual_embeddings", "=", "text_visual_embeddings_new", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# 5. Update text_mask:", "\n", "text_mask", "=", "(", "text_input_ids", ">", "0", ")", "\n", "\n", "# 6. Add to generated", "\n", "for", "nid", ",", "row", "in", "enumerate", "(", "answers", "[", "1", "]", ")", ":", "\n", "                ", "if", "curr_len", "==", "0", ":", "\n", "                    ", "generated", ".", "append", "(", "[", "]", ")", "\n", "", "for", "ele", "in", "row", ":", "\n", "                    ", "if", "not", "stop", "[", "nid", "]", ":", "\n", "                        ", "if", "self", ".", "tokenizer", ".", "ids_to_tokens", "[", "ele", ".", "item", "(", ")", "]", "==", "'[STOP]'", ":", "\n", "                            ", "stop", "[", "nid", "]", "=", "True", "\n", "", "else", ":", "\n", "                            ", "generated", "[", "nid", "]", ".", "append", "(", "\n", "self", ".", "tokenizer", ".", "ids_to_tokens", "[", "ele", ".", "item", "(", ")", "]", ")", "\n", "", "", "", "", "curr_len", "+=", "1", "\n", "\n", "# Join in sentences", "\n", "", "generated_sentences", "=", "[", "]", "\n", "for", "sentence", "in", "generated", ":", "\n", "            ", "new_sentence", "=", "' '", ".", "join", "(", "sentence", ")", "\n", "generated_sentences", ".", "append", "(", "new_sentence", ".", "replace", "(", "' ##'", ",", "''", ")", ")", "\n", "\n", "###########################################", "\n", "", "outputs", "=", "{", "}", "\n", "\n", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_REL_LOSS", ":", "\n", "            ", "relationship_loss", "=", "F", ".", "cross_entropy", "(", "\n", "relationship_logits", ",", "relationship_label", ")", "\n", "", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MLM_LOSS", ":", "\n", "            ", "mlm_logits_padded", "=", "mlm_logits", ".", "new_zeros", "(", "\n", "(", "*", "mlm_labels", ".", "shape", ",", "mlm_logits", ".", "shape", "[", "-", "1", "]", ")", ")", ".", "fill_", "(", "-", "10000.0", ")", "\n", "mlm_logits_padded", "[", ":", ",", ":", "mlm_logits", ".", "shape", "[", "1", "]", "]", "=", "mlm_logits", "\n", "mlm_logits", "=", "mlm_logits_padded", "\n", "if", "self", ".", "config", ".", "NETWORK", ".", "MLM_LOSS_NORM_IN_BATCH_FIRST", ":", "\n", "                ", "mlm_loss", "=", "F", ".", "cross_entropy", "(", "mlm_logits", ".", "transpose", "(", "1", ",", "2", ")", ",", "\n", "mlm_labels", ",", "\n", "ignore_index", "=", "-", "1", ",", "reduction", "=", "'none'", ")", "\n", "num_mlm", "=", "(", "mlm_labels", "!=", "-", "1", ")", ".", "sum", "(", "1", ",", "\n", "keepdim", "=", "True", ")", ".", "to", "(", "dtype", "=", "mlm_loss", ".", "dtype", ")", "\n", "num_has_mlm", "=", "(", "num_mlm", "!=", "0", ")", ".", "sum", "(", ")", ".", "to", "(", "dtype", "=", "mlm_loss", ".", "dtype", ")", "\n", "mlm_loss", "=", "(", "mlm_loss", "/", "(", "num_mlm", "+", "1e-4", ")", ")", ".", "sum", "(", ")", "/", "(", "num_has_mlm", "+", "1e-4", ")", "\n", "", "else", ":", "\n", "                ", "mlm_loss", "=", "F", ".", "cross_entropy", "(", "mlm_logits", ".", "view", "(", "(", "-", "1", ",", "mlm_logits", ".", "shape", "[", "-", "1", "]", ")", ")", ",", "\n", "mlm_labels", ".", "view", "(", "-", "1", ")", ",", "\n", "ignore_index", "=", "-", "1", ")", "\n", "\n", "\n", "", "", "outputs", ".", "update", "(", "{", "\n", "'relationship_logits'", ":", "relationship_logits", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_REL_LOSS", "else", "None", ",", "\n", "'relationship_label'", ":", "relationship_label", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_REL_LOSS", "else", "None", ",", "\n", "'mlm_logits'", ":", "mlm_logits", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MLM_LOSS", "else", "None", ",", "\n", "'mlm_label'", ":", "mlm_labels", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MLM_LOSS", "else", "None", ",", "\n", "'mvrc_logits'", ":", "mvrc_logits", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", "else", "None", ",", "\n", "'mvrc_label'", ":", "mvrc_labels", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", "else", "None", ",", "\n", "'mlm_loss'", ":", "mlm_loss", ",", "\n", "'generated_sentences'", ":", "generated_sentences", "\n", "}", ")", "\n", "\n", "loss", "=", "mlm_loss", ".", "mean", "(", ")", "\n", "\n", "return", "outputs", ",", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_multitask_training.BERTGENMultitaskTraining.__init__": [[15, 66], ["common.module.Module.__init__", "common.fast_rcnn.FastRCNN", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "external.pytorch_pretrained_bert.BertTokenizer.from_pretrained", "common.visual_linguistic_bert.VisualLinguisticBertForPretraining", "bertgen_multitask_training.BERTGENMultitaskTraining.init_weight", "bertgen_multitask_training.BERTGENMultitaskTraining.fix_params", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "len", "os.path.isdir", "print", "os.path.join", "os.path.isfile"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.from_pretrained", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.init_weight", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.fix_params"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "\n", "        ", "super", "(", "BERTGENMultitaskTraining", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "# Constructs/initialises model elements", "\n", "self", ".", "image_feature_extractor", "=", "FastRCNN", "(", "config", ",", "\n", "average_pool", "=", "True", ",", "\n", "final_dim", "=", "config", ".", "NETWORK", ".", "IMAGE_FINAL_DIM", ",", "\n", "enable_cnn_reg_loss", "=", "False", ")", "\n", "self", ".", "object_linguistic_embeddings", "=", "nn", ".", "Embedding", "(", "\n", "1", ",", "config", ".", "NETWORK", ".", "VLBERT", ".", "hidden_size", ")", "\n", "if", "config", ".", "NETWORK", ".", "IMAGE_FEAT_PRECOMPUTED", "or", "(", "not", "config", ".", "NETWORK", ".", "MASK_RAW_PIXELS", ")", ":", "\n", "            ", "self", ".", "object_mask_visual_embedding", "=", "nn", ".", "Embedding", "(", "1", ",", "2048", ")", "\n", "", "if", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", ":", "\n", "            ", "self", ".", "object_mask_word_embedding", "=", "nn", ".", "Embedding", "(", "\n", "1", ",", "config", ".", "NETWORK", ".", "VLBERT", ".", "hidden_size", ")", "\n", "", "self", ".", "aux_text_visual_embedding", "=", "nn", ".", "Embedding", "(", "\n", "1", ",", "config", ".", "NETWORK", ".", "VLBERT", ".", "hidden_size", ")", "\n", "self", ".", "image_feature_bn_eval", "=", "config", ".", "NETWORK", ".", "IMAGE_FROZEN_BN", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "\n", "config", ".", "NETWORK", ".", "BERT_MODEL_NAME", ")", "\n", "try", ":", "\n", "            ", "self", ".", "num_datasets", "=", "len", "(", "config", ".", "TRAIN", ".", "BATCH_IMAGES", ")", "\n", "", "except", ":", "\n", "            ", "self", ".", "num_datasets", "=", "1", "\n", "# Can specify pre-trained model or use the downloaded pretrained model specific in .yaml file", "\n", "", "language_pretrained_model_path", "=", "None", "\n", "if", "config", ".", "NETWORK", ".", "BERT_PRETRAINED", "!=", "''", ":", "\n", "# FM edit: just use path of pretrained model", "\n", "            ", "language_pretrained_model_path", "=", "config", ".", "NETWORK", ".", "BERT_PRETRAINED", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "config", ".", "NETWORK", ".", "BERT_MODEL_NAME", ")", ":", "\n", "            ", "weight_path", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "NETWORK", ".", "BERT_MODEL_NAME", ",", "BERT_WEIGHTS_NAME", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "weight_path", ")", ":", "\n", "                ", "language_pretrained_model_path", "=", "weight_path", "\n", "\n", "", "", "if", "language_pretrained_model_path", "is", "None", ":", "\n", "            ", "print", "(", "\"Warning: no pretrained language model found, training from scratch!!!\"", ")", "\n", "\n", "", "self", ".", "vlbert", "=", "VisualLinguisticBertForPretraining", "(", "\n", "config", ".", "NETWORK", ".", "VLBERT", ",", "\n", "language_pretrained_model_path", "=", "None", "if", "config", ".", "NETWORK", ".", "VLBERT", ".", "from_scratch", "else", "language_pretrained_model_path", ",", "\n", "with_rel_head", "=", "config", ".", "NETWORK", ".", "WITH_REL_LOSS", ",", "\n", "with_mlm_head", "=", "config", ".", "NETWORK", ".", "WITH_MLM_LOSS", ",", "\n", "with_mvrc_head", "=", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", ",", "\n", ")", "\n", "\n", "# init weights", "\n", "self", ".", "init_weight", "(", ")", "\n", "\n", "self", ".", "fix_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_multitask_training.BERTGENMultitaskTraining.init_weight": [[67, 79], ["bertgen_multitask_training.BERTGENMultitaskTraining.aux_text_visual_embedding.weight.data.normal_", "bertgen_multitask_training.BERTGENMultitaskTraining.image_feature_extractor.init_weight", "bertgen_multitask_training.BERTGENMultitaskTraining.object_mask_visual_embedding.weight.data.fill_", "bertgen_multitask_training.BERTGENMultitaskTraining.object_mask_word_embedding.weight.data.normal_", "bertgen_multitask_training.BERTGENMultitaskTraining.object_linguistic_embeddings.weight.data.normal_"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.init_weight"], ["", "def", "init_weight", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "NETWORK", ".", "IMAGE_FEAT_PRECOMPUTED", "or", "(", "not", "self", ".", "config", ".", "NETWORK", ".", "MASK_RAW_PIXELS", ")", ":", "\n", "            ", "self", ".", "object_mask_visual_embedding", ".", "weight", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", ":", "\n", "            ", "self", ".", "object_mask_word_embedding", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "\n", "std", "=", "self", ".", "config", ".", "NETWORK", ".", "VLBERT", ".", "initializer_range", ")", "\n", "", "self", ".", "aux_text_visual_embedding", ".", "weight", ".", "data", ".", "normal_", "(", "\n", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "NETWORK", ".", "VLBERT", ".", "initializer_range", ")", "\n", "self", ".", "image_feature_extractor", ".", "init_weight", "(", ")", "\n", "if", "self", ".", "object_linguistic_embeddings", "is", "not", "None", ":", "\n", "            ", "self", ".", "object_linguistic_embeddings", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "\n", "std", "=", "self", ".", "config", ".", "NETWORK", ".", "VLBERT", ".", "initializer_range", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_multitask_training.BERTGENMultitaskTraining.train": [[80, 85], ["super().train", "bertgen_multitask_training.BERTGENMultitaskTraining.image_feature_extractor.bn_eval"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.trainer.train", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.bn_eval"], ["", "", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "super", "(", "BERTGENMultitaskTraining", ",", "self", ")", ".", "train", "(", "mode", ")", "\n", "# turn some frozen layers to eval mode", "\n", "if", "self", ".", "image_feature_bn_eval", ":", "\n", "            ", "self", ".", "image_feature_extractor", ".", "bn_eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_multitask_training.BERTGENMultitaskTraining.fix_params": [[86, 88], ["None"], "methods", ["None"], ["", "", "def", "fix_params", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_multitask_training.BERTGENMultitaskTraining._collect_obj_reps": [[89, 109], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp.new_zeros", "torch.clamp.new_zeros", "torch.clamp.new_zeros", "range", "object_reps[].view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "len", "torch.clamp.new_zeros.view", "torch.clamp.view", "torch.clamp.view", "torch.clamp.view"], "methods", ["None"], ["", "def", "_collect_obj_reps", "(", "self", ",", "span_tags", ",", "object_reps", ")", ":", "\n", "        ", "\"\"\"\n        Collect span-level object representations\n        :param span_tags: [batch_size, ..leading_dims.., L]\n        :param object_reps: [batch_size, max_num_objs_per_batch, obj_dim]\n        :return:\n        \"\"\"", "\n", "\n", "# In case there were masked values here", "\n", "span_tags_fixed", "=", "torch", ".", "clamp", "(", "span_tags", ",", "min", "=", "0", ")", "\n", "row_id", "=", "span_tags_fixed", ".", "new_zeros", "(", "span_tags_fixed", ".", "shape", ")", "\n", "row_id_broadcaster", "=", "torch", ".", "arange", "(", "\n", "0", ",", "row_id", ".", "shape", "[", "0", "]", ",", "step", "=", "1", ",", "device", "=", "row_id", ".", "device", ")", "[", ":", ",", "None", "]", "\n", "\n", "# Add extra diminsions to the row broadcaster so it matches row_id", "\n", "leading_dims", "=", "len", "(", "span_tags", ".", "shape", ")", "-", "2", "\n", "for", "i", "in", "range", "(", "leading_dims", ")", ":", "\n", "            ", "row_id_broadcaster", "=", "row_id_broadcaster", "[", "...", ",", "None", "]", "\n", "", "row_id", "+=", "row_id_broadcaster", "\n", "return", "object_reps", "[", "row_id", ".", "view", "(", "-", "1", ")", ",", "span_tags_fixed", ".", "view", "(", "-", "1", ")", "]", ".", "view", "(", "*", "span_tags_fixed", ".", "shape", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_multitask_training.BERTGENMultitaskTraining.forward": [[110, 337], ["range", "range", "text_list[].new_zeros.new_zeros", "bertgen_multitask_training.BERTGENMultitaskTraining.vlbert", "im_info_list[].new_zeros", "outputs.update", "torch.cross_entropy.mean", "text_tags_list.append", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "mlm_labels_list[].new_zeros().fill_", "range", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "has_visual.append", "has_visual.append", "image_list.append", "boxes_list.append", "boxes_mask_list.append", "im_info_list.append", "text_list.append", "relationship_label_list.append", "mlm_labels_list.append", "mvrc_ops_list.append", "mvrc_labels_list.append", "int", "text_list.append", "relationship_label_list.append", "mlm_labels_list.append", "obj_reps_list.append", "text_list[].new_zeros", "text_visual_embeddings_list.append", "object_linguistic_embeddings_list.append", "object_vl_embeddings_list.append", "text_list[].new_zeros", "text_visual_embeddings_list[].new_zeros", "object_vl_embeddings_list[].new_zeros", "boxes_mask_list[].new_zeros", "mlm_loss_list.append", "mlm_logits_multi.view", "mlm_labels_list[].new_zeros().fill_.view", "boxes_mask_list[].sum().max().item", "box_features_list.append", "bertgen_multitask_training.BERTGENMultitaskTraining.image_feature_extractor", "bertgen_multitask_training.BERTGENMultitaskTraining._collect_obj_reps", "bertgen_multitask_training.BERTGENMultitaskTraining.object_linguistic_embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mlm_labels_list[].new_zeros", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "boxes_list[].new_zeros().long", "mlm_logits_multi[].view", "mlm_labels_multi[].view", "boxes_mask_list[].sum().max", "str", "str", "str", "boxes_list[].new_zeros", "boxes_mask_list[].sum"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_generate_image_only.BERTGENGenerateImageOnly._collect_obj_reps"], ["", "def", "forward", "(", "self", ",", "\n", "*", "args", ")", ":", "\n", "\n", "\n", "        ", "num_datasets", "=", "self", ".", "num_datasets", "\n", "image_list", "=", "[", "]", "\n", "boxes_list", "=", "[", "]", "\n", "boxes_mask_list", "=", "[", "]", "\n", "im_info_list", "=", "[", "]", "\n", "text_list", "=", "[", "]", "\n", "relationship_label_list", "=", "[", "]", "\n", "mlm_labels_list", "=", "[", "]", "\n", "mvrc_ops_list", "=", "[", "]", "\n", "mvrc_labels_list", "=", "[", "]", "\n", "\n", "has_visual", "=", "[", "]", "\n", "\n", "max_global_len", "=", "0", "\n", "max_global_text_len", "=", "0", "\n", "\n", "total_examples", "=", "0", "\n", "\n", "###########################################", "\n", "# Step 1 - Loop through all to get sizes", "\n", "ref", "=", "0", "\n", "vis_i", "=", "0", "\n", "for", "i", "in", "range", "(", "num_datasets", ")", ":", "\n", "            ", "if", "args", "[", "ref", "]", "is", "None", ":", "\n", "                ", "has_visual", ".", "append", "(", "True", ")", "\n", "", "else", ":", "\n", "                ", "has_visual", ".", "append", "(", "False", ")", "\n", "", "if", "has_visual", "[", "i", "]", ":", "\n", "                ", "image_list", ".", "append", "(", "args", "[", "ref", "]", ")", "\n", "boxes_list", ".", "append", "(", "args", "[", "ref", "+", "1", "]", ")", "\n", "boxes_mask_list", ".", "append", "(", "(", "args", "[", "ref", "+", "1", "]", ")", "[", ":", ",", ":", ",", "0", "]", ">", "-", "1.5", ")", "\n", "im_info_list", ".", "append", "(", "args", "[", "ref", "+", "2", "]", ")", "\n", "text_list", ".", "append", "(", "args", "[", "ref", "+", "3", "]", ")", "\n", "relationship_label_list", ".", "append", "(", "args", "[", "ref", "+", "4", "]", ")", "\n", "mlm_labels_list", ".", "append", "(", "args", "[", "ref", "+", "5", "]", ")", "\n", "mvrc_ops_list", ".", "append", "(", "args", "[", "ref", "+", "6", "]", ")", "\n", "mvrc_labels_list", ".", "append", "(", "args", "[", "ref", "+", "7", "]", ")", "\n", "\n", "vis_len", "=", "int", "(", "boxes_mask_list", "[", "vis_i", "]", ".", "sum", "(", "1", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "if", "vis_len", ">", "max_global_len", ":", "\n", "                    ", "max_global_len", "=", "vis_len", "\n", "", "text_len", "=", "text_list", "[", "i", "]", ".", "shape", "[", "1", "]", "\n", "if", "text_len", ">", "max_global_text_len", ":", "\n", "                    ", "max_global_text_len", "=", "text_len", "\n", "", "ref", "+=", "8", "\n", "vis_i", "+=", "1", "\n", "", "else", ":", "\n", "                ", "text_list", ".", "append", "(", "args", "[", "ref", "]", ")", "\n", "relationship_label_list", ".", "append", "(", "args", "[", "ref", "+", "1", "]", ")", "\n", "mlm_labels_list", ".", "append", "(", "args", "[", "ref", "+", "2", "]", ")", "\n", "\n", "text_len", "=", "text_list", "[", "i", "]", ".", "shape", "[", "1", "]", "\n", "if", "text_len", ">", "max_global_text_len", ":", "\n", "                    ", "max_global_text_len", "=", "text_len", "\n", "", "ref", "+=", "3", "\n", "", "total_examples", "+=", "text_list", "[", "i", "]", ".", "shape", "[", "0", "]", "\n", "\n", "################################################", "\n", "# Step 2 - Loop through datasets", "\n", "", "cur_start", "=", "0", "\n", "cur_stop", "=", "0", "\n", "vis_i", "=", "0", "\n", "box_features_list", "=", "[", "]", "\n", "obj_reps_list", "=", "[", "]", "\n", "text_tags_list", "=", "[", "]", "\n", "text_visual_embeddings_list", "=", "[", "]", "\n", "object_linguistic_embeddings_list", "=", "[", "]", "\n", "object_vl_embeddings_list", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_datasets", ")", ":", "\n", "            ", "if", "has_visual", "[", "i", "]", ":", "\n", "                ", "boxes_mask_list", "[", "vis_i", "]", "=", "boxes_mask_list", "[", "vis_i", "]", "[", ":", ",", "\n", ":", "max_global_len", "]", "\n", "boxes_list", "[", "vis_i", "]", "=", "boxes_list", "[", "vis_i", "]", "[", ":", ",", ":", "max_global_len", "]", "\n", "mvrc_ops_list", "[", "vis_i", "]", "=", "mvrc_ops_list", "[", "vis_i", "]", "[", ":", ",", ":", "max_global_len", "]", "\n", "mvrc_labels_list", "[", "vis_i", "]", "=", "mvrc_labels_list", "[", "vis_i", "]", "[", ":", ",", "\n", ":", "max_global_len", "]", "\n", "\n", "if", "self", ".", "config", ".", "NETWORK", ".", "IMAGE_FEAT_PRECOMPUTED", ":", "\n", "                    ", "box_features_list", ".", "append", "(", "boxes_list", "[", "vis_i", "]", "[", ":", ",", ":", ",", "4", ":", "]", ")", "\n", "box_features_list", "[", "vis_i", "]", "[", "mvrc_ops_list", "[", "vis_i", "]", "==", "\n", "1", "]", "=", "self", ".", "object_mask_visual_embedding", ".", "weight", "[", "0", "]", "\n", "boxes_list", "[", "vis_i", "]", "[", ":", ",", ":", ",", "4", ":", "]", "=", "box_features_list", "[", "vis_i", "]", "\n", "\n", "", "obj_reps_list", ".", "append", "(", "self", ".", "image_feature_extractor", "(", "images", "=", "image_list", "[", "vis_i", "]", ",", "\n", "boxes", "=", "boxes_list", "[", "vis_i", "]", ",", "\n", "box_mask", "=", "boxes_mask_list", "[", "vis_i", "]", ",", "\n", "im_info", "=", "im_info_list", "[", "vis_i", "]", ",", "\n", "classes", "=", "None", ",", "\n", "segms", "=", "None", ",", "\n", "mvrc_ops", "=", "mvrc_ops_list", "[", "vis_i", "]", ",", "\n", "mask_visual_embed", "=", "self", ".", "object_mask_visual_embedding", ".", "weight", "[", "\n", "0", "]", "\n", "if", "(", "not", "self", ".", "config", ".", "NETWORK", ".", "IMAGE_FEAT_PRECOMPUTED", ")", "\n", "and", "(", "not", "self", ".", "config", ".", "NETWORK", ".", "MASK_RAW_PIXELS", ")", "\n", "else", "None", ")", ")", "\n", "\n", "############################################", "\n", "\n", "# prepare text", "\n", "# text_input_ids = text", "\n", "# size of sub-batch", "\n", "", "cur_stop", "+=", "text_list", "[", "i", "]", ".", "shape", "[", "0", "]", "\n", "# creates a text_tags tensor of the same shape as text tensor", "\n", "text_tags_list", ".", "append", "(", "text_list", "[", "i", "]", ".", "new_zeros", "(", "text_list", "[", "i", "]", ".", "shape", ")", ")", "\n", "\n", "if", "has_visual", "[", "i", "]", ":", "\n", "                ", "text_visual_embeddings_list", ".", "append", "(", "self", ".", "_collect_obj_reps", "(", "\n", "text_tags_list", "[", "i", "]", ",", "obj_reps_list", "[", "vis_i", "]", "[", "'obj_reps'", "]", ")", ")", "\n", "\n", "# linguistic embedding for visual uses [IMG] embedding for all (apart from masked visual)", "\n", "object_linguistic_embeddings_list", ".", "append", "(", "self", ".", "object_linguistic_embeddings", "(", "\n", "boxes_list", "[", "vis_i", "]", ".", "new_zeros", "(", "\n", "(", "boxes_list", "[", "vis_i", "]", ".", "shape", "[", "0", "]", ",", "boxes_list", "[", "vis_i", "]", ".", "shape", "[", "1", "]", ")", ")", ".", "long", "(", ")", "\n", ")", ")", "\n", "\n", "object_vl_embeddings_list", ".", "append", "(", "torch", ".", "cat", "(", "\n", "(", "obj_reps_list", "[", "vis_i", "]", "[", "'obj_reps'", "]", ",", "object_linguistic_embeddings_list", "[", "vis_i", "]", ")", ",", "-", "1", ")", ")", "\n", "\n", "# Initiliase in first pass", "\n", "", "if", "i", "==", "0", ":", "\n", "                ", "text_input_ids_multi", "=", "text_list", "[", "i", "]", ".", "new_zeros", "(", "\n", "(", "total_examples", ",", "max_global_text_len", ")", ")", "\n", "text_visual_embeddings_multi", "=", "text_visual_embeddings_list", "[", "vis_i", "]", ".", "new_zeros", "(", "(", "total_examples", ",", "\n", "max_global_text_len", ",", "\n", "text_visual_embeddings_list", "[", "vis_i", "]", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "object_vl_embeddings_multi", "=", "object_vl_embeddings_list", "[", "vis_i", "]", ".", "new_zeros", "(", "(", "total_examples", ",", "max_global_len", ",", "\n", "object_vl_embeddings_list", "[", "vis_i", "]", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "box_mask_multi", "=", "boxes_mask_list", "[", "vis_i", "]", ".", "new_zeros", "(", "\n", "(", "total_examples", ",", "max_global_len", ")", ")", "\n", "\n", "# Concatenates the sub-batches from all dataloaders", "\n", "", "text_input_ids_multi", "[", "cur_start", ":", "cur_stop", ",", "\n", ":", "text_list", "[", "i", "]", ".", "shape", "[", "1", "]", "]", "=", "text_list", "[", "i", "]", "\n", "if", "has_visual", "[", "i", "]", ":", "\n", "                ", "text_visual_embeddings_multi", "[", "cur_start", ":", "cur_stop", ",", ":", "text_visual_embeddings_list", "[", "vis_i", "]", ".", "shape", "[", "1", "]", "]", "=", "text_visual_embeddings_list", "[", "vis_i", "]", "\n", "object_vl_embeddings_multi", "[", "cur_start", ":", "cur_stop", ",", "\n", ":", "object_vl_embeddings_list", "[", "vis_i", "]", ".", "shape", "[", "1", "]", ",", ":", "]", "=", "object_vl_embeddings_list", "[", "vis_i", "]", "\n", "box_mask_multi", "[", "cur_start", ":", "cur_stop", ",", "\n", ":", "boxes_mask_list", "[", "vis_i", "]", ".", "shape", "[", "1", "]", "]", "=", "boxes_mask_list", "[", "vis_i", "]", "\n", "\n", "", "cur_start", "=", "cur_stop", "\n", "# TODO: fix to increment if non_visual", "\n", "if", "has_visual", "[", "i", "]", ":", "\n", "                ", "vis_i", "+=", "1", "\n", "\n", "# add final", "\n", "", "", "text_token_type_ids_multi", "=", "text_input_ids_multi", ".", "new_zeros", "(", "\n", "text_input_ids_multi", ".", "shape", ")", "\n", "text_mask_multi", "=", "(", "text_input_ids_multi", ">", "0", ")", "\n", "\n", "###########################################", "\n", "\n", "relationship_logits_multi", ",", "mlm_logits_multi", ",", "mvrc_logits_multi", "=", "self", ".", "vlbert", "(", "text_input_ids_multi", ",", "\n", "text_token_type_ids_multi", ",", "\n", "text_visual_embeddings_multi", ",", "\n", "text_mask_multi", ",", "\n", "object_vl_embeddings_multi", ",", "\n", "box_mask_multi", ")", "\n", "\n", "###########################################", "\n", "###########################################", "\n", "outputs", "=", "{", "}", "\n", "\n", "# loss", "\n", "# relationship_loss = im_info_list.new_zeros(())", "\n", "# mlm_loss = im_info_list.new_zeros(())", "\n", "# mvrc_loss = im_info.new_zeros(())", "\n", "mlm_logits_list", "=", "[", "]", "\n", "mlm_loss_list", "=", "[", "]", "\n", "\n", "outputs_dict", "=", "{", "}", "\n", "mlm_labels_dataset_list", "=", "[", "]", "\n", "loss", "=", "im_info_list", "[", "-", "1", "]", ".", "new_zeros", "(", "(", ")", ")", "\n", "\n", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_REL_LOSS", ":", "\n", "            ", "relationship_logits", "=", "relationship_logits_multi", "[", ":", "text_input_ids", ".", "shape", "[", "0", "]", "]", "\n", "relationship_loss", "=", "F", ".", "cross_entropy", "(", "\n", "relationship_logits", ",", "relationship_label", ")", "\n", "", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MLM_LOSS", ":", "\n", "            ", "mlm_labels_multi", "=", "mlm_labels_list", "[", "0", "]", ".", "new_zeros", "(", "(", "total_examples", ",", "max_global_text_len", ")", ")", ".", "fill_", "(", "\n", "-", "1", ")", "\n", "\n", "cur_start", "=", "0", "\n", "cur_stop", "=", "0", "\n", "for", "i", "in", "range", "(", "num_datasets", ")", ":", "\n", "                ", "cur_stop", "+=", "mlm_labels_list", "[", "i", "]", ".", "shape", "[", "0", "]", "\n", "\n", "mlm_labels_multi", "[", "cur_start", ":", "cur_stop", ",", "\n", ":", "mlm_labels_list", "[", "i", "]", ".", "shape", "[", "1", "]", "]", "=", "mlm_labels_list", "[", "i", "]", "\n", "\n", "# compute individual losses for reporting metrics", "\n", "mlm_loss_list", ".", "append", "(", "F", ".", "cross_entropy", "(", "\n", "mlm_logits_multi", "[", "cur_start", ":", "cur_stop", "]", ".", "view", "(", "\n", "(", "-", "1", ",", "mlm_logits_multi", "[", "cur_start", ":", "cur_stop", "]", ".", "shape", "[", "-", "1", "]", ")", ")", ",", "\n", "mlm_labels_multi", "[", "cur_start", ":", "cur_stop", "]", ".", "view", "(", "-", "1", ")", ",", "\n", "ignore_index", "=", "-", "1", "\n", ")", ")", "\n", "\n", "# collect data for metrics", "\n", "outputs_dict", "[", "'mlm_logits_'", "+", "\n", "str", "(", "i", ")", "]", "=", "mlm_logits_multi", "[", "cur_start", ":", "cur_stop", "]", "\n", "outputs_dict", "[", "'mlm_label_'", "+", "\n", "str", "(", "i", ")", "]", "=", "mlm_labels_multi", "[", "cur_start", ":", "cur_stop", "]", "\n", "outputs_dict", "[", "'mlm_loss_'", "+", "str", "(", "i", ")", "]", "=", "mlm_loss_list", "[", "i", "]", "\n", "\n", "cur_start", "=", "cur_stop", "\n", "\n", "# USE combined loss for backpropagation - only use per dataset for reporting metrics", "\n", "", "mlm_loss", "=", "(", "F", ".", "cross_entropy", "(", "\n", "mlm_logits_multi", ".", "view", "(", "(", "-", "1", ",", "mlm_logits_multi", ".", "shape", "[", "-", "1", "]", ")", ")", ",", "\n", "mlm_labels_multi", ".", "view", "(", "-", "1", ")", ",", "\n", "ignore_index", "=", "-", "1", "\n", ")", ")", "\n", "\n", "# # calculate total loss", "\n", "\n", "", "outputs", ".", "update", "(", "outputs_dict", ")", "\n", "\n", "loss", "=", "mlm_loss", ".", "mean", "(", ")", "\n", "\n", "return", "outputs", ",", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_global_generate_mmt.BERTGENGenerateMMT.__init__": [[15, 59], ["common.module.Module.__init__", "common.fast_rcnn.FastRCNN", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "external.pytorch_pretrained_bert.BertTokenizer.from_pretrained", "common.visual_linguistic_bert.VisualLinguisticBertForPretraining", "bertgen_global_generate_mmt.BERTGENGenerateMMT.init_weight", "bertgen_global_generate_mmt.BERTGENGenerateMMT.fix_params", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "os.path.isdir", "print", "os.path.join", "os.path.isfile"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.from_pretrained", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.init_weight", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.fix_params"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "\n", "        ", "super", "(", "BERTGENGenerateMMT", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "image_feature_extractor", "=", "FastRCNN", "(", "config", ",", "\n", "average_pool", "=", "True", ",", "\n", "final_dim", "=", "config", ".", "NETWORK", ".", "IMAGE_FINAL_DIM", ",", "\n", "enable_cnn_reg_loss", "=", "False", ")", "\n", "self", ".", "object_linguistic_embeddings", "=", "nn", ".", "Embedding", "(", "\n", "1", ",", "config", ".", "NETWORK", ".", "VLBERT", ".", "hidden_size", ")", "\n", "if", "config", ".", "NETWORK", ".", "IMAGE_FEAT_PRECOMPUTED", ":", "\n", "            ", "self", ".", "object_mask_visual_embedding", "=", "nn", ".", "Embedding", "(", "1", ",", "2048", ")", "\n", "", "if", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", ":", "\n", "            ", "self", ".", "object_mask_word_embedding", "=", "nn", ".", "Embedding", "(", "\n", "1", ",", "config", ".", "NETWORK", ".", "VLBERT", ".", "hidden_size", ")", "\n", "", "self", ".", "aux_text_visual_embedding", "=", "nn", ".", "Embedding", "(", "\n", "1", ",", "config", ".", "NETWORK", ".", "VLBERT", ".", "hidden_size", ")", "\n", "self", ".", "image_feature_bn_eval", "=", "config", ".", "NETWORK", ".", "IMAGE_FROZEN_BN", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "\n", "config", ".", "NETWORK", ".", "BERT_MODEL_NAME", ")", "\n", "language_pretrained_model_path", "=", "None", "\n", "if", "config", ".", "NETWORK", ".", "BERT_PRETRAINED", "!=", "''", ":", "\n", "            ", "language_pretrained_model_path", "=", "'{}-{:04d}.model'", ".", "format", "(", "config", ".", "NETWORK", ".", "BERT_PRETRAINED", ",", "\n", "config", ".", "NETWORK", ".", "BERT_PRETRAINED_EPOCH", ")", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "config", ".", "NETWORK", ".", "BERT_MODEL_NAME", ")", ":", "\n", "            ", "weight_path", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "NETWORK", ".", "BERT_MODEL_NAME", ",", "BERT_WEIGHTS_NAME", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "weight_path", ")", ":", "\n", "                ", "language_pretrained_model_path", "=", "weight_path", "\n", "\n", "", "", "if", "language_pretrained_model_path", "is", "None", ":", "\n", "            ", "print", "(", "\"Warning: no pretrained language model found, training from scratch!!!\"", ")", "\n", "\n", "", "self", ".", "vlbert", "=", "VisualLinguisticBertForPretraining", "(", "\n", "config", ".", "NETWORK", ".", "VLBERT", ",", "\n", "language_pretrained_model_path", "=", "None", "if", "config", ".", "NETWORK", ".", "VLBERT", ".", "from_scratch", "else", "language_pretrained_model_path", ",", "\n", "with_rel_head", "=", "config", ".", "NETWORK", ".", "WITH_REL_LOSS", ",", "\n", "with_mlm_head", "=", "config", ".", "NETWORK", ".", "WITH_MLM_LOSS", ",", "\n", "with_mvrc_head", "=", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", ",", "\n", ")", "\n", "\n", "# init weights", "\n", "self", ".", "init_weight", "(", ")", "\n", "self", ".", "fix_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_global_generate_mmt.BERTGENGenerateMMT.init_weight": [[60, 70], ["bertgen_global_generate_mmt.BERTGENGenerateMMT.image_feature_extractor.init_weight", "bertgen_global_generate_mmt.BERTGENGenerateMMT.object_mask_visual_embedding.weight.data.fill_", "bertgen_global_generate_mmt.BERTGENGenerateMMT.object_mask_word_embedding.weight.data.normal_", "bertgen_global_generate_mmt.BERTGENGenerateMMT.object_linguistic_embeddings.weight.data.normal_"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.init_weight"], ["", "def", "init_weight", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "NETWORK", ".", "IMAGE_FEAT_PRECOMPUTED", ":", "\n", "            ", "self", ".", "object_mask_visual_embedding", ".", "weight", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", ":", "\n", "            ", "self", ".", "object_mask_word_embedding", ".", "weight", ".", "data", ".", "normal_", "(", "\n", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "NETWORK", ".", "VLBERT", ".", "initializer_range", ")", "\n", "", "self", ".", "image_feature_extractor", ".", "init_weight", "(", ")", "\n", "if", "self", ".", "object_linguistic_embeddings", "is", "not", "None", ":", "\n", "            ", "self", ".", "object_linguistic_embeddings", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "\n", "std", "=", "self", ".", "config", ".", "NETWORK", ".", "VLBERT", ".", "initializer_range", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_global_generate_mmt.BERTGENGenerateMMT.train": [[71, 76], ["super().train", "bertgen_global_generate_mmt.BERTGENGenerateMMT.image_feature_extractor.bn_eval"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.trainer.train", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.bn_eval"], ["", "", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "super", "(", "BERTGENGenerateMMT", ",", "self", ")", ".", "train", "(", "mode", ")", "\n", "# turn some frozen layers to eval mode", "\n", "if", "self", ".", "image_feature_bn_eval", ":", "\n", "            ", "self", ".", "image_feature_extractor", ".", "bn_eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_global_generate_mmt.BERTGENGenerateMMT.fix_params": [[77, 79], ["None"], "methods", ["None"], ["", "", "def", "fix_params", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_global_generate_mmt.BERTGENGenerateMMT._collect_obj_reps": [[80, 100], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp.new_zeros", "torch.clamp.new_zeros", "torch.clamp.new_zeros", "range", "object_reps[].view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "len", "torch.clamp.new_zeros.view", "torch.clamp.view", "torch.clamp.view", "torch.clamp.view"], "methods", ["None"], ["", "def", "_collect_obj_reps", "(", "self", ",", "span_tags", ",", "object_reps", ")", ":", "\n", "        ", "\"\"\"\n        Collect span-level object representations\n        :param span_tags: [batch_size, ..leading_dims.., L]\n        :param object_reps: [batch_size, max_num_objs_per_batch, obj_dim]\n        :return:\n        \"\"\"", "\n", "\n", "# In case there were masked values here", "\n", "span_tags_fixed", "=", "torch", ".", "clamp", "(", "span_tags", ",", "min", "=", "0", ")", "\n", "row_id", "=", "span_tags_fixed", ".", "new_zeros", "(", "span_tags_fixed", ".", "shape", ")", "\n", "row_id_broadcaster", "=", "torch", ".", "arange", "(", "\n", "0", ",", "row_id", ".", "shape", "[", "0", "]", ",", "step", "=", "1", ",", "device", "=", "row_id", ".", "device", ")", "[", ":", ",", "None", "]", "\n", "\n", "# Add extra diminsions to the row broadcaster so it matches row_id", "\n", "leading_dims", "=", "len", "(", "span_tags", ".", "shape", ")", "-", "2", "\n", "for", "i", "in", "range", "(", "leading_dims", ")", ":", "\n", "            ", "row_id_broadcaster", "=", "row_id_broadcaster", "[", "...", ",", "None", "]", "\n", "", "row_id", "+=", "row_id_broadcaster", "\n", "return", "object_reps", "[", "row_id", ".", "view", "(", "-", "1", ")", ",", "span_tags_fixed", ".", "view", "(", "-", "1", ")", "]", ".", "view", "(", "*", "span_tags_fixed", ".", "shape", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_global_generate_mmt.BERTGENGenerateMMT.forward": [[101, 285], ["int", "bertgen_global_generate_mmt.BERTGENGenerateMMT.image_feature_extractor", "text.new_zeros", "text.new_zeros", "bertgen_global_generate_mmt.BERTGENGenerateMMT._collect_obj_reps", "bertgen_global_generate_mmt.BERTGENGenerateMMT.object_linguistic_embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "im_info.new_zeros", "im_info.new_zeros", "im_info.new_zeros", "outputs.update", "box_mask.sum().max().item", "boxes.new_zeros().long", "bertgen_global_generate_mmt.BERTGENGenerateMMT.vlbert", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_tensor.repeat().view.repeat().view.repeat().view", "mlm_labels.new_zeros", "text_input_ids.new_zeros", "text_token_type_ids.new_zeros.new_zeros.new_zeros", "text_visual_embeddings_new.transpose.transpose.new_zeros", "text_visual_embeddings_new.transpose.transpose.transpose", "text_visual_embeddings_new.transpose.transpose.transpose", "enumerate", "generated_sentences.append", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "mlm_logits.new_zeros().fill_", "im_info.new_zeros.mean", "all", "bertgen_global_generate_mmt.BERTGENGenerateMMT.tokenizer.convert_tokens_to_ids", "bertgen_global_generate_mmt.BERTGENGenerateMMT.tokenizer.convert_tokens_to_ids", "bertgen_global_generate_mmt.BERTGENGenerateMMT.tokenizer.convert_tokens_to_ids", "new_sentence.replace", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy.mean", "torch.cross_entropy.mean", "box_mask.sum().max", "boxes.new_zeros", "position_tensor.repeat().view.repeat().view.repeat", "generated.append", "mlm_logits.new_zeros", "mlm_logits.transpose", "mlm_logits.view", "mlm_labels.view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "box_mask.sum", "generated[].append", "ele.item", "ele.item"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_generate_image_only.BERTGENGenerateImageOnly._collect_obj_reps", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "forward", "(", "self", ",", "\n", "image", ",", "\n", "boxes", ",", "\n", "im_info", ",", "\n", "text", ",", "\n", "relationship_label", ",", "\n", "mlm_labels", ",", "\n", "mvrc_ops", ",", "\n", "mvrc_labels", ")", ":", "\n", "###########################################", "\n", "\n", "# visual feature extraction", "\n", "        ", "images", "=", "image", "\n", "box_mask", "=", "(", "boxes", "[", ":", ",", ":", ",", "0", "]", ">", "-", "1.5", ")", "\n", "origin_len", "=", "boxes", ".", "shape", "[", "1", "]", "\n", "max_len", "=", "int", "(", "box_mask", ".", "sum", "(", "1", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "box_mask", "=", "box_mask", "[", ":", ",", ":", "max_len", "]", "\n", "boxes", "=", "boxes", "[", ":", ",", ":", "max_len", "]", "\n", "mvrc_ops", "=", "mvrc_ops", "[", ":", ",", ":", "max_len", "]", "\n", "mvrc_labels", "=", "mvrc_labels", "[", ":", ",", ":", "max_len", "]", "\n", "\n", "if", "self", ".", "config", ".", "NETWORK", ".", "IMAGE_FEAT_PRECOMPUTED", ":", "\n", "            ", "box_features", "=", "boxes", "[", ":", ",", ":", ",", "4", ":", "]", "\n", "box_features", "[", "mvrc_ops", "==", "\n", "1", "]", "=", "self", ".", "object_mask_visual_embedding", ".", "weight", "[", "0", "]", "\n", "boxes", "[", ":", ",", ":", ",", "4", ":", "]", "=", "box_features", "\n", "\n", "", "obj_reps", "=", "self", ".", "image_feature_extractor", "(", "images", "=", "images", ",", "\n", "boxes", "=", "boxes", ",", "\n", "box_mask", "=", "box_mask", ",", "\n", "im_info", "=", "im_info", ",", "\n", "classes", "=", "None", ",", "\n", "segms", "=", "None", ",", "\n", "mvrc_ops", "=", "mvrc_ops", ",", "\n", "mask_visual_embed", "=", "None", ")", "\n", "\n", "############################################", "\n", "\n", "# prepare text", "\n", "text_input_ids", "=", "text", "\n", "text_tags", "=", "text", ".", "new_zeros", "(", "text", ".", "shape", ")", "\n", "text_token_type_ids", "=", "text", ".", "new_zeros", "(", "text", ".", "shape", ")", "\n", "text_mask", "=", "(", "text_input_ids", ">", "0", ")", "\n", "text_visual_embeddings", "=", "self", ".", "_collect_obj_reps", "(", "\n", "text_tags", ",", "obj_reps", "[", "'obj_reps'", "]", ")", "\n", "\n", "object_linguistic_embeddings", "=", "self", ".", "object_linguistic_embeddings", "(", "\n", "boxes", ".", "new_zeros", "(", "(", "boxes", ".", "shape", "[", "0", "]", ",", "boxes", ".", "shape", "[", "1", "]", ")", ")", ".", "long", "(", ")", "\n", ")", "\n", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", ":", "\n", "            ", "object_linguistic_embeddings", "[", "mvrc_ops", "==", "\n", "1", "]", "=", "self", ".", "object_mask_word_embedding", ".", "weight", "[", "0", "]", "\n", "", "object_vl_embeddings", "=", "torch", ".", "cat", "(", "\n", "(", "obj_reps", "[", "'obj_reps'", "]", ",", "object_linguistic_embeddings", ")", ",", "-", "1", ")", "\n", "\n", "###########################################", "\n", "# Visual Linguistic BERT", "\n", "# #loop here for test mode:", "\n", "generated", "=", "[", "]", "\n", "stop", "=", "[", "False", "]", "*", "text", ".", "shape", "[", "0", "]", "\n", "curr_len", "=", "0", "\n", "max_len", "=", "150", "\n", "while", "not", "all", "(", "stop", ")", "and", "curr_len", "<=", "max_len", ":", "\n", "            ", "relationship_logits", ",", "mlm_logits", ",", "mvrc_logits", "=", "self", ".", "vlbert", "(", "text_input_ids", ",", "\n", "text_token_type_ids", ",", "\n", "text_visual_embeddings", ",", "\n", "text_mask", ",", "\n", "object_vl_embeddings", ",", "\n", "box_mask", ")", "\n", "\n", "answers", "=", "torch", ".", "topk", "(", "mlm_logits", "[", "mlm_labels", "==", "103", "]", ",", "k", "=", "1", ",", "dim", "=", "1", ")", "\n", "\n", "# Get size of each tensor", "\n", "position_tensor", "=", "torch", ".", "arange", "(", "mlm_labels", ".", "shape", "[", "1", "]", ")", "\n", "position_tensor", "=", "position_tensor", ".", "repeat", "(", "\n", "mlm_labels", ".", "shape", "[", "0", "]", ")", ".", "view", "(", "mlm_labels", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "indeces", "=", "position_tensor", "[", "mlm_labels", "==", "103", "]", "\n", "\n", "# 1. Update mlm_labels:", "\n", "mlm_labels_new", "=", "mlm_labels", ".", "new_zeros", "(", "\n", "mlm_labels", ".", "shape", "[", "0", "]", ",", "mlm_labels", ".", "shape", "[", "1", "]", "+", "1", ")", "\n", "mlm_labels_new", "=", "mlm_labels_new", "-", "1", "\n", "mlm_labels_new", "[", "torch", ".", "arange", "(", "mlm_labels", ".", "shape", "[", "0", "]", ")", ",", "indeces", "+", "1", "]", "=", "103", "\n", "mlm_labels", "=", "mlm_labels_new", "\n", "\n", "# 2. Update text_input_ids:", "\n", "text_input_ids_new", "=", "text_input_ids", ".", "new_zeros", "(", "\n", "text_input_ids", ".", "shape", "[", "0", "]", ",", "text_input_ids", ".", "shape", "[", "1", "]", "+", "1", ")", "\n", "text_input_ids_new", "[", ":", ",", ":", "-", "1", "]", "=", "text_input_ids", "\n", "text_input_ids_new", "[", "torch", ".", "arange", "(", "\n", "text_input_ids", ".", "shape", "[", "0", "]", ")", ",", "indeces", "]", "=", "answers", "[", "1", "]", "[", ":", ",", "0", "]", "\n", "text_input_ids_new", "[", "torch", ".", "arange", "(", "text_input_ids", ".", "shape", "[", "0", "]", ")", ",", "indeces", "+", "1", "]", "=", "(", "\n", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "'[MASK]'", "]", ")", "[", "0", "]", ")", "\n", "text_input_ids_new", "[", "torch", ".", "arange", "(", "text_input_ids", ".", "shape", "[", "0", "]", ")", ",", "indeces", "+", "2", "]", "=", "(", "\n", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "'[PAD]'", "]", ")", "[", "0", "]", ")", "\n", "text_input_ids_new", "[", "torch", ".", "arange", "(", "text_input_ids", ".", "shape", "[", "0", "]", ")", ",", "indeces", "+", "3", "]", "=", "(", "\n", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "'[SEP]'", "]", ")", "[", "0", "]", ")", "\n", "text_input_ids", "=", "text_input_ids_new", "\n", "\n", "# 3. Update text_token_type_ids:", "\n", "text_token_type_ids", "=", "text_token_type_ids", ".", "new_zeros", "(", "\n", "text_token_type_ids", ".", "shape", "[", "0", "]", ",", "text_token_type_ids", ".", "shape", "[", "1", "]", "+", "1", ")", "\n", "\n", "# 4. Update text_input_ids:", "\n", "text_visual_embeddings_new", "=", "text_visual_embeddings", ".", "new_zeros", "(", "\n", "text_visual_embeddings", ".", "shape", "[", "0", "]", ",", "text_visual_embeddings", ".", "shape", "[", "1", "]", "+", "1", ",", "text_visual_embeddings", ".", "shape", "[", "2", "]", ")", "\n", "text_visual_embeddings_new", "=", "text_visual_embeddings_new", ".", "transpose", "(", "\n", "0", ",", "1", ")", "\n", "text_visual_embeddings_new", "[", ":", "]", "=", "text_visual_embeddings", "[", ":", ",", "0", ",", ":", "]", "\n", "text_visual_embeddings", "=", "text_visual_embeddings_new", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# 5. Update text_mask:", "\n", "text_mask", "=", "(", "text_input_ids", ">", "0", ")", "\n", "\n", "# 6. Append generated words from each sentence in the batch to list - terminate if all [STOP]", "\n", "for", "nid", ",", "row", "in", "enumerate", "(", "answers", "[", "1", "]", ")", ":", "\n", "                ", "if", "curr_len", "==", "0", ":", "\n", "                    ", "generated", ".", "append", "(", "[", "]", ")", "\n", "", "for", "ele", "in", "row", ":", "\n", "# try:", "\n", "                    ", "if", "not", "stop", "[", "nid", "]", ":", "\n", "                        ", "if", "self", ".", "tokenizer", ".", "ids_to_tokens", "[", "ele", ".", "item", "(", ")", "]", "==", "'[STOP]'", ":", "\n", "                            ", "stop", "[", "nid", "]", "=", "True", "\n", "", "else", ":", "\n", "# print('generated: ', ele.item())", "\n", "                            ", "generated", "[", "nid", "]", ".", "append", "(", "\n", "self", ".", "tokenizer", ".", "ids_to_tokens", "[", "ele", ".", "item", "(", ")", "]", ")", "\n", "# except:", "\n", "#     generated[nid].append(self.tokenizer.ids_to_tokens[100])", "\n", "", "", "", "", "curr_len", "+=", "1", "\n", "\n", "# Join in sentences", "\n", "", "generated_sentences", "=", "[", "]", "\n", "for", "sentence", "in", "generated", ":", "\n", "            ", "new_sentence", "=", "' '", ".", "join", "(", "sentence", ")", "\n", "generated_sentences", ".", "append", "(", "new_sentence", ".", "replace", "(", "' ##'", ",", "''", ")", ")", "\n", "\n", "\n", "###########################################", "\n", "", "outputs", "=", "{", "}", "\n", "\n", "# loss", "\n", "relationship_loss", "=", "im_info", ".", "new_zeros", "(", "(", ")", ")", "\n", "mlm_loss", "=", "im_info", ".", "new_zeros", "(", "(", ")", ")", "\n", "mvrc_loss", "=", "im_info", ".", "new_zeros", "(", "(", ")", ")", "\n", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_REL_LOSS", ":", "\n", "            ", "relationship_loss", "=", "F", ".", "cross_entropy", "(", "\n", "relationship_logits", ",", "relationship_label", ")", "\n", "", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MLM_LOSS", ":", "\n", "            ", "mlm_logits_padded", "=", "mlm_logits", ".", "new_zeros", "(", "\n", "(", "*", "mlm_labels", ".", "shape", ",", "mlm_logits", ".", "shape", "[", "-", "1", "]", ")", ")", ".", "fill_", "(", "-", "10000.0", ")", "\n", "mlm_logits_padded", "[", ":", ",", ":", "mlm_logits", ".", "shape", "[", "1", "]", "]", "=", "mlm_logits", "\n", "mlm_logits", "=", "mlm_logits_padded", "\n", "if", "self", ".", "config", ".", "NETWORK", ".", "MLM_LOSS_NORM_IN_BATCH_FIRST", ":", "\n", "                ", "mlm_loss", "=", "F", ".", "cross_entropy", "(", "mlm_logits", ".", "transpose", "(", "1", ",", "2", ")", ",", "\n", "mlm_labels", ",", "\n", "ignore_index", "=", "-", "1", ",", "reduction", "=", "'none'", ")", "\n", "num_mlm", "=", "(", "mlm_labels", "!=", "-", "1", ")", ".", "sum", "(", "1", ",", "\n", "keepdim", "=", "True", ")", ".", "to", "(", "dtype", "=", "mlm_loss", ".", "dtype", ")", "\n", "num_has_mlm", "=", "(", "num_mlm", "!=", "0", ")", ".", "sum", "(", ")", ".", "to", "(", "dtype", "=", "mlm_loss", ".", "dtype", ")", "\n", "mlm_loss", "=", "(", "mlm_loss", "/", "(", "num_mlm", "+", "1e-4", ")", ")", ".", "sum", "(", ")", "/", "(", "num_has_mlm", "+", "1e-4", ")", "\n", "", "else", ":", "\n", "                ", "mlm_loss", "=", "F", ".", "cross_entropy", "(", "mlm_logits", ".", "view", "(", "(", "-", "1", ",", "mlm_logits", ".", "shape", "[", "-", "1", "]", ")", ")", ",", "\n", "mlm_labels", ".", "view", "(", "-", "1", ")", ",", "\n", "ignore_index", "=", "-", "1", ")", "\n", "\n", "\n", "", "", "outputs", ".", "update", "(", "{", "\n", "'relationship_logits'", ":", "relationship_logits", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_REL_LOSS", "else", "None", ",", "\n", "'relationship_label'", ":", "relationship_label", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_REL_LOSS", "else", "None", ",", "\n", "'mlm_logits'", ":", "mlm_logits", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MLM_LOSS", "else", "None", ",", "\n", "'mlm_label'", ":", "mlm_labels", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MLM_LOSS", "else", "None", ",", "\n", "'mvrc_logits'", ":", "mvrc_logits", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", "else", "None", ",", "\n", "'mvrc_label'", ":", "mvrc_labels", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", "else", "None", ",", "\n", "'relationship_loss'", ":", "relationship_loss", ",", "\n", "'mlm_loss'", ":", "mlm_loss", ",", "\n", "'mvrc_loss'", ":", "mvrc_loss", ",", "\n", "'generated_sentences'", ":", "generated_sentences", "\n", "}", ")", "\n", "\n", "loss", "=", "relationship_loss", ".", "mean", "(", ")", "+", "mlm_loss", ".", "mean", "(", ")", "+", "mvrc_loss", ".", "mean", "(", ")", "\n", "\n", "return", "outputs", ",", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_generate_image_only.BERTGENGenerateImageOnly.__init__": [[15, 61], ["common.module.Module.__init__", "common.fast_rcnn.FastRCNN", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "external.pytorch_pretrained_bert.BertTokenizer.from_pretrained", "common.visual_linguistic_bert.VisualLinguisticBertForPretraining", "bertgen_generate_image_only.BERTGENGenerateImageOnly.init_weight", "bertgen_generate_image_only.BERTGENGenerateImageOnly.fix_params", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "os.path.isdir", "print", "os.path.join", "os.path.isfile"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.from_pretrained", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.init_weight", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.fix_params"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "\n", "        ", "super", "(", "BERTGENGenerateImageOnly", ",", "\n", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "image_feature_extractor", "=", "FastRCNN", "(", "config", ",", "\n", "average_pool", "=", "True", ",", "\n", "final_dim", "=", "config", ".", "NETWORK", ".", "IMAGE_FINAL_DIM", ",", "\n", "enable_cnn_reg_loss", "=", "False", ")", "\n", "self", ".", "object_linguistic_embeddings", "=", "nn", ".", "Embedding", "(", "\n", "1", ",", "config", ".", "NETWORK", ".", "VLBERT", ".", "hidden_size", ")", "\n", "if", "config", ".", "NETWORK", ".", "IMAGE_FEAT_PRECOMPUTED", ":", "\n", "            ", "self", ".", "object_mask_visual_embedding", "=", "nn", ".", "Embedding", "(", "1", ",", "2048", ")", "\n", "", "if", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", ":", "\n", "            ", "self", ".", "object_mask_word_embedding", "=", "nn", ".", "Embedding", "(", "\n", "1", ",", "config", ".", "NETWORK", ".", "VLBERT", ".", "hidden_size", ")", "\n", "", "self", ".", "aux_text_visual_embedding", "=", "nn", ".", "Embedding", "(", "\n", "1", ",", "config", ".", "NETWORK", ".", "VLBERT", ".", "hidden_size", ")", "\n", "self", ".", "image_feature_bn_eval", "=", "config", ".", "NETWORK", ".", "IMAGE_FROZEN_BN", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "\n", "config", ".", "NETWORK", ".", "BERT_MODEL_NAME", ")", "\n", "language_pretrained_model_path", "=", "None", "\n", "if", "config", ".", "NETWORK", ".", "BERT_PRETRAINED", "!=", "''", ":", "\n", "            ", "language_pretrained_model_path", "=", "'{}-{:04d}.model'", ".", "format", "(", "config", ".", "NETWORK", ".", "BERT_PRETRAINED", ",", "\n", "config", ".", "NETWORK", ".", "BERT_PRETRAINED_EPOCH", ")", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "config", ".", "NETWORK", ".", "BERT_MODEL_NAME", ")", ":", "\n", "            ", "weight_path", "=", "os", ".", "path", ".", "join", "(", "\n", "config", ".", "NETWORK", ".", "BERT_MODEL_NAME", ",", "BERT_WEIGHTS_NAME", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "weight_path", ")", ":", "\n", "                ", "language_pretrained_model_path", "=", "weight_path", "\n", "\n", "", "", "if", "language_pretrained_model_path", "is", "None", ":", "\n", "            ", "print", "(", "\"Warning: no pretrained language model found, training from scratch!!!\"", ")", "\n", "\n", "", "self", ".", "vlbert", "=", "VisualLinguisticBertForPretraining", "(", "\n", "config", ".", "NETWORK", ".", "VLBERT", ",", "\n", "language_pretrained_model_path", "=", "None", "if", "config", ".", "NETWORK", ".", "VLBERT", ".", "from_scratch", "else", "language_pretrained_model_path", ",", "\n", "with_rel_head", "=", "config", ".", "NETWORK", ".", "WITH_REL_LOSS", ",", "\n", "with_mlm_head", "=", "config", ".", "NETWORK", ".", "WITH_MLM_LOSS", ",", "\n", "with_mvrc_head", "=", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", ",", "\n", ")", "\n", "\n", "# init weights", "\n", "self", ".", "init_weight", "(", ")", "\n", "\n", "self", ".", "fix_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_generate_image_only.BERTGENGenerateImageOnly.init_weight": [[62, 72], ["bertgen_generate_image_only.BERTGENGenerateImageOnly.image_feature_extractor.init_weight", "bertgen_generate_image_only.BERTGENGenerateImageOnly.object_mask_visual_embedding.weight.data.fill_", "bertgen_generate_image_only.BERTGENGenerateImageOnly.object_mask_word_embedding.weight.data.normal_", "bertgen_generate_image_only.BERTGENGenerateImageOnly.object_linguistic_embeddings.weight.data.normal_"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.init_weight"], ["", "def", "init_weight", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "NETWORK", ".", "IMAGE_FEAT_PRECOMPUTED", ":", "\n", "            ", "self", ".", "object_mask_visual_embedding", ".", "weight", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", ":", "\n", "            ", "self", ".", "object_mask_word_embedding", ".", "weight", ".", "data", ".", "normal_", "(", "\n", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "NETWORK", ".", "VLBERT", ".", "initializer_range", ")", "\n", "", "self", ".", "image_feature_extractor", ".", "init_weight", "(", ")", "\n", "if", "self", ".", "object_linguistic_embeddings", "is", "not", "None", ":", "\n", "            ", "self", ".", "object_linguistic_embeddings", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "\n", "std", "=", "self", ".", "config", ".", "NETWORK", ".", "VLBERT", ".", "initializer_range", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_generate_image_only.BERTGENGenerateImageOnly.train": [[73, 78], ["super().train", "bertgen_generate_image_only.BERTGENGenerateImageOnly.image_feature_extractor.bn_eval"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.trainer.train", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.bn_eval"], ["", "", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "super", "(", "BERTGENGenerateImageOnly", ",", "self", ")", ".", "train", "(", "mode", ")", "\n", "# turn some frozen layers to eval mode", "\n", "if", "self", ".", "image_feature_bn_eval", ":", "\n", "            ", "self", ".", "image_feature_extractor", ".", "bn_eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_generate_image_only.BERTGENGenerateImageOnly.fix_params": [[79, 81], ["None"], "methods", ["None"], ["", "", "def", "fix_params", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_generate_image_only.BERTGENGenerateImageOnly._collect_obj_reps": [[82, 102], ["torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp.new_zeros", "torch.clamp.new_zeros", "torch.clamp.new_zeros", "range", "object_reps[].view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "len", "torch.clamp.new_zeros.view", "torch.clamp.view", "torch.clamp.view", "torch.clamp.view"], "methods", ["None"], ["", "def", "_collect_obj_reps", "(", "self", ",", "span_tags", ",", "object_reps", ")", ":", "\n", "        ", "\"\"\"\n        Collect span-level object representations\n        :param span_tags: [batch_size, ..leading_dims.., L]\n        :param object_reps: [batch_size, max_num_objs_per_batch, obj_dim]\n        :return:\n        \"\"\"", "\n", "\n", "# In case there were masked values here", "\n", "span_tags_fixed", "=", "torch", ".", "clamp", "(", "span_tags", ",", "min", "=", "0", ")", "\n", "row_id", "=", "span_tags_fixed", ".", "new_zeros", "(", "span_tags_fixed", ".", "shape", ")", "\n", "row_id_broadcaster", "=", "torch", ".", "arange", "(", "\n", "0", ",", "row_id", ".", "shape", "[", "0", "]", ",", "step", "=", "1", ",", "device", "=", "row_id", ".", "device", ")", "[", ":", ",", "None", "]", "\n", "\n", "# Add extra diminsions to the row broadcaster so it matches row_id", "\n", "leading_dims", "=", "len", "(", "span_tags", ".", "shape", ")", "-", "2", "\n", "for", "i", "in", "range", "(", "leading_dims", ")", ":", "\n", "            ", "row_id_broadcaster", "=", "row_id_broadcaster", "[", "...", ",", "None", "]", "\n", "", "row_id", "+=", "row_id_broadcaster", "\n", "return", "object_reps", "[", "row_id", ".", "view", "(", "-", "1", ")", ",", "span_tags_fixed", ".", "view", "(", "-", "1", ")", "]", ".", "view", "(", "*", "span_tags_fixed", ".", "shape", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_generate_image_only.BERTGENGenerateImageOnly.forward": [[103, 285], ["int", "bertgen_generate_image_only.BERTGENGenerateImageOnly.image_feature_extractor", "text.new_zeros", "text.new_zeros", "bertgen_generate_image_only.BERTGENGenerateImageOnly._collect_obj_reps", "bertgen_generate_image_only.BERTGENGenerateImageOnly.object_linguistic_embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "im_info.new_zeros", "im_info.new_zeros", "im_info.new_zeros", "outputs.update", "box_mask.sum().max().item", "boxes.new_zeros().long", "bertgen_generate_image_only.BERTGENGenerateImageOnly.vlbert", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_tensor.repeat().view.repeat().view.repeat().view", "mlm_labels.new_zeros", "text_input_ids.new_zeros", "text_token_type_ids.new_zeros.new_zeros.new_zeros", "text_visual_embeddings_new.transpose.transpose.new_zeros", "text_visual_embeddings_new.transpose.transpose.transpose", "text_visual_embeddings_new.transpose.transpose.transpose", "enumerate", "generated_sentences.append", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "mlm_logits.new_zeros().fill_", "im_info.new_zeros.mean", "all", "bertgen_generate_image_only.BERTGENGenerateImageOnly.tokenizer.convert_tokens_to_ids", "bertgen_generate_image_only.BERTGENGenerateImageOnly.tokenizer.convert_tokens_to_ids", "bertgen_generate_image_only.BERTGENGenerateImageOnly.tokenizer.convert_tokens_to_ids", "new_sentence.replace", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy.mean", "torch.cross_entropy.mean", "box_mask.sum().max", "boxes.new_zeros", "position_tensor.repeat().view.repeat().view.repeat", "generated.append", "mlm_logits.new_zeros", "mlm_logits.transpose", "mlm_logits.view", "mlm_labels.view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "box_mask.sum", "generated[].append", "ele.item", "ele.item"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.modules.bertgen_generate_image_only.BERTGENGenerateImageOnly._collect_obj_reps", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "forward", "(", "self", ",", "\n", "image", ",", "\n", "boxes", ",", "\n", "im_info", ",", "\n", "text", ",", "\n", "relationship_label", ",", "\n", "mlm_labels", ",", "\n", "mvrc_ops", ",", "\n", "mvrc_labels", ")", ":", "\n", "###########################################", "\n", "\n", "# visual feature extraction", "\n", "        ", "images", "=", "image", "\n", "box_mask", "=", "(", "boxes", "[", ":", ",", ":", ",", "0", "]", ">", "-", "1.5", ")", "\n", "origin_len", "=", "boxes", ".", "shape", "[", "1", "]", "\n", "max_len", "=", "int", "(", "box_mask", ".", "sum", "(", "1", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "box_mask", "=", "box_mask", "[", ":", ",", ":", "max_len", "]", "\n", "boxes", "=", "boxes", "[", ":", ",", ":", "max_len", "]", "\n", "mvrc_ops", "=", "mvrc_ops", "[", ":", ",", ":", "max_len", "]", "\n", "mvrc_labels", "=", "mvrc_labels", "[", ":", ",", ":", "max_len", "]", "\n", "\n", "if", "self", ".", "config", ".", "NETWORK", ".", "IMAGE_FEAT_PRECOMPUTED", ":", "\n", "            ", "box_features", "=", "boxes", "[", ":", ",", ":", ",", "4", ":", "]", "\n", "box_features", "[", "mvrc_ops", "==", "\n", "1", "]", "=", "self", ".", "object_mask_visual_embedding", ".", "weight", "[", "0", "]", "\n", "boxes", "[", ":", ",", ":", ",", "4", ":", "]", "=", "box_features", "\n", "\n", "", "obj_reps", "=", "self", ".", "image_feature_extractor", "(", "images", "=", "images", ",", "\n", "boxes", "=", "boxes", ",", "\n", "box_mask", "=", "box_mask", ",", "\n", "im_info", "=", "im_info", ",", "\n", "classes", "=", "None", ",", "\n", "segms", "=", "None", ",", "\n", "mvrc_ops", "=", "mvrc_ops", ",", "\n", "mask_visual_embed", "=", "None", ")", "\n", "\n", "############################################", "\n", "\n", "# prepare text", "\n", "text_input_ids", "=", "text", "\n", "text_tags", "=", "text", ".", "new_zeros", "(", "text", ".", "shape", ")", "\n", "text_token_type_ids", "=", "text", ".", "new_zeros", "(", "text", ".", "shape", ")", "\n", "text_mask", "=", "(", "text_input_ids", ">", "0", ")", "\n", "text_visual_embeddings", "=", "self", ".", "_collect_obj_reps", "(", "\n", "text_tags", ",", "obj_reps", "[", "'obj_reps'", "]", ")", "\n", "\n", "object_linguistic_embeddings", "=", "self", ".", "object_linguistic_embeddings", "(", "\n", "boxes", ".", "new_zeros", "(", "(", "boxes", ".", "shape", "[", "0", "]", ",", "boxes", ".", "shape", "[", "1", "]", ")", ")", ".", "long", "(", ")", "\n", ")", "\n", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", ":", "\n", "            ", "object_linguistic_embeddings", "[", "mvrc_ops", "==", "\n", "1", "]", "=", "self", ".", "object_mask_word_embedding", ".", "weight", "[", "0", "]", "\n", "", "object_vl_embeddings", "=", "torch", ".", "cat", "(", "\n", "(", "obj_reps", "[", "'obj_reps'", "]", ",", "object_linguistic_embeddings", ")", ",", "-", "1", ")", "\n", "\n", "###########################################", "\n", "# Visual Linguistic BERT", "\n", "# #loop here for test mode:", "\n", "generated", "=", "[", "]", "\n", "stop", "=", "[", "False", "]", "*", "text", ".", "shape", "[", "0", "]", "\n", "curr_len", "=", "0", "\n", "max_len", "=", "150", "\n", "while", "not", "all", "(", "stop", ")", "and", "curr_len", "<=", "max_len", ":", "\n", "            ", "relationship_logits", ",", "mlm_logits", ",", "mvrc_logits", "=", "self", ".", "vlbert", "(", "text_input_ids", ",", "\n", "text_token_type_ids", ",", "\n", "text_visual_embeddings", ",", "\n", "text_mask", ",", "\n", "object_vl_embeddings", ",", "\n", "box_mask", ")", "\n", "# Ignore special tokens", "\n", "answers", "=", "torch", ".", "topk", "(", "mlm_logits", "[", "mlm_labels", "==", "103", "]", ",", "k", "=", "1", ",", "dim", "=", "1", ")", "\n", "\n", "# Get size of each tensor", "\n", "position_tensor", "=", "torch", ".", "arange", "(", "mlm_labels", ".", "shape", "[", "1", "]", ")", "\n", "position_tensor", "=", "position_tensor", ".", "repeat", "(", "\n", "mlm_labels", ".", "shape", "[", "0", "]", ")", ".", "view", "(", "mlm_labels", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "indeces", "=", "position_tensor", "[", "mlm_labels", "==", "103", "]", "\n", "\n", "# 1. Update mlm_labels:", "\n", "mlm_labels_new", "=", "mlm_labels", ".", "new_zeros", "(", "\n", "mlm_labels", ".", "shape", "[", "0", "]", ",", "mlm_labels", ".", "shape", "[", "1", "]", "+", "1", ")", "\n", "mlm_labels_new", "=", "mlm_labels_new", "-", "1", "\n", "mlm_labels_new", "[", "torch", ".", "arange", "(", "mlm_labels", ".", "shape", "[", "0", "]", ")", ",", "indeces", "+", "1", "]", "=", "103", "\n", "mlm_labels", "=", "mlm_labels_new", "\n", "\n", "# 2. Update text_input_ids:", "\n", "text_input_ids_new", "=", "text_input_ids", ".", "new_zeros", "(", "\n", "text_input_ids", ".", "shape", "[", "0", "]", ",", "text_input_ids", ".", "shape", "[", "1", "]", "+", "1", ")", "\n", "text_input_ids_new", "[", ":", ",", ":", "-", "1", "]", "=", "text_input_ids", "\n", "text_input_ids_new", "[", "torch", ".", "arange", "(", "\n", "text_input_ids", ".", "shape", "[", "0", "]", ")", ",", "indeces", "]", "=", "answers", "[", "1", "]", "[", ":", ",", "0", "]", "\n", "text_input_ids_new", "[", "torch", ".", "arange", "(", "text_input_ids", ".", "shape", "[", "0", "]", ")", ",", "indeces", "+", "1", "]", "=", "(", "\n", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "'[MASK]'", "]", ")", "[", "0", "]", ")", "\n", "text_input_ids_new", "[", "torch", ".", "arange", "(", "text_input_ids", ".", "shape", "[", "0", "]", ")", ",", "indeces", "+", "2", "]", "=", "(", "\n", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "'[PAD]'", "]", ")", "[", "0", "]", ")", "\n", "text_input_ids_new", "[", "torch", ".", "arange", "(", "text_input_ids", ".", "shape", "[", "0", "]", ")", ",", "indeces", "+", "3", "]", "=", "(", "\n", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "'[SEP]'", "]", ")", "[", "0", "]", ")", "\n", "text_input_ids", "=", "text_input_ids_new", "\n", "\n", "# 3. Update text_token_type_ids:", "\n", "text_token_type_ids", "=", "text_token_type_ids", ".", "new_zeros", "(", "\n", "text_token_type_ids", ".", "shape", "[", "0", "]", ",", "text_token_type_ids", ".", "shape", "[", "1", "]", "+", "1", ")", "\n", "\n", "# 4. Update text_input_ids:", "\n", "text_visual_embeddings_new", "=", "text_visual_embeddings", ".", "new_zeros", "(", "\n", "text_visual_embeddings", ".", "shape", "[", "0", "]", ",", "text_visual_embeddings", ".", "shape", "[", "1", "]", "+", "1", ",", "text_visual_embeddings", ".", "shape", "[", "2", "]", ")", "\n", "text_visual_embeddings_new", "=", "text_visual_embeddings_new", ".", "transpose", "(", "\n", "0", ",", "1", ")", "\n", "text_visual_embeddings_new", "[", ":", "]", "=", "text_visual_embeddings", "[", ":", ",", "0", ",", ":", "]", "\n", "text_visual_embeddings", "=", "text_visual_embeddings_new", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# 5. Update text_mask:", "\n", "text_mask", "=", "(", "text_input_ids", ">", "0", ")", "\n", "\n", "# 6. Append generated words from each sentence in the batch to list - terminate if all [STOP]", "\n", "for", "nid", ",", "row", "in", "enumerate", "(", "answers", "[", "1", "]", ")", ":", "\n", "                ", "if", "curr_len", "==", "0", ":", "\n", "                    ", "generated", ".", "append", "(", "[", "]", ")", "\n", "", "for", "ele", "in", "row", ":", "\n", "# try:", "\n", "                    ", "if", "not", "stop", "[", "nid", "]", ":", "\n", "                        ", "if", "self", ".", "tokenizer", ".", "ids_to_tokens", "[", "ele", ".", "item", "(", ")", "]", "==", "'[STOP]'", ":", "\n", "                            ", "stop", "[", "nid", "]", "=", "True", "\n", "", "else", ":", "\n", "# print('generated: ', ele.item())", "\n", "                            ", "generated", "[", "nid", "]", ".", "append", "(", "\n", "self", ".", "tokenizer", ".", "ids_to_tokens", "[", "ele", ".", "item", "(", ")", "]", ")", "\n", "# except:", "\n", "#     generated[nid].append(self.tokenizer.ids_to_tokens[100])", "\n", "", "", "", "", "curr_len", "+=", "1", "\n", "\n", "# Join in sentences", "\n", "", "generated_sentences", "=", "[", "]", "\n", "for", "sentence", "in", "generated", ":", "\n", "            ", "new_sentence", "=", "' '", ".", "join", "(", "sentence", ")", "\n", "generated_sentences", ".", "append", "(", "new_sentence", ".", "replace", "(", "' ##'", ",", "''", ")", ")", "\n", "\n", "###########################################", "\n", "", "outputs", "=", "{", "}", "\n", "\n", "# loss", "\n", "relationship_loss", "=", "im_info", ".", "new_zeros", "(", "(", ")", ")", "\n", "mlm_loss", "=", "im_info", ".", "new_zeros", "(", "(", ")", ")", "\n", "mvrc_loss", "=", "im_info", ".", "new_zeros", "(", "(", ")", ")", "\n", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_REL_LOSS", ":", "\n", "            ", "relationship_loss", "=", "F", ".", "cross_entropy", "(", "\n", "relationship_logits", ",", "relationship_label", ")", "\n", "", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MLM_LOSS", ":", "\n", "            ", "mlm_logits_padded", "=", "mlm_logits", ".", "new_zeros", "(", "\n", "(", "*", "mlm_labels", ".", "shape", ",", "mlm_logits", ".", "shape", "[", "-", "1", "]", ")", ")", ".", "fill_", "(", "-", "10000.0", ")", "\n", "mlm_logits_padded", "[", ":", ",", ":", "mlm_logits", ".", "shape", "[", "1", "]", "]", "=", "mlm_logits", "\n", "mlm_logits", "=", "mlm_logits_padded", "\n", "if", "self", ".", "config", ".", "NETWORK", ".", "MLM_LOSS_NORM_IN_BATCH_FIRST", ":", "\n", "                ", "mlm_loss", "=", "F", ".", "cross_entropy", "(", "mlm_logits", ".", "transpose", "(", "1", ",", "2", ")", ",", "\n", "mlm_labels", ",", "\n", "ignore_index", "=", "-", "1", ",", "reduction", "=", "'none'", ")", "\n", "num_mlm", "=", "(", "mlm_labels", "!=", "-", "1", ")", ".", "sum", "(", "1", ",", "\n", "keepdim", "=", "True", ")", ".", "to", "(", "dtype", "=", "mlm_loss", ".", "dtype", ")", "\n", "num_has_mlm", "=", "(", "num_mlm", "!=", "0", ")", ".", "sum", "(", ")", ".", "to", "(", "dtype", "=", "mlm_loss", ".", "dtype", ")", "\n", "mlm_loss", "=", "(", "mlm_loss", "/", "(", "num_mlm", "+", "1e-4", ")", ")", ".", "sum", "(", ")", "/", "(", "num_has_mlm", "+", "1e-4", ")", "\n", "", "else", ":", "\n", "                ", "mlm_loss", "=", "F", ".", "cross_entropy", "(", "mlm_logits", ".", "view", "(", "(", "-", "1", ",", "mlm_logits", ".", "shape", "[", "-", "1", "]", ")", ")", ",", "\n", "mlm_labels", ".", "view", "(", "-", "1", ")", ",", "\n", "ignore_index", "=", "-", "1", ")", "\n", "\n", "", "", "outputs", ".", "update", "(", "{", "\n", "'relationship_logits'", ":", "relationship_logits", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_REL_LOSS", "else", "None", ",", "\n", "'relationship_label'", ":", "relationship_label", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_REL_LOSS", "else", "None", ",", "\n", "'mlm_logits'", ":", "mlm_logits", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MLM_LOSS", "else", "None", ",", "\n", "'mlm_label'", ":", "mlm_labels", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MLM_LOSS", "else", "None", ",", "\n", "'mvrc_logits'", ":", "mvrc_logits", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", "else", "None", ",", "\n", "'mvrc_label'", ":", "mvrc_labels", "if", "self", ".", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", "else", "None", ",", "\n", "'relationship_loss'", ":", "relationship_loss", ",", "\n", "'mlm_loss'", ":", "mlm_loss", ",", "\n", "'mvrc_loss'", ":", "mvrc_loss", ",", "\n", "'generated_sentences'", ":", "generated_sentences", "\n", "}", ")", "\n", "\n", "loss", "=", "relationship_loss", ".", "mean", "(", ")", "+", "mlm_loss", ".", "mean", "(", ")", "+", "mvrc_loss", ".", "mean", "(", ")", "\n", "\n", "return", "outputs", ",", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.build_dataset": [[23, 26], ["None"], "function", ["None"], ["def", "build_dataset", "(", "dataset_name", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "assert", "dataset_name", "in", "DATASET_CATALOGS", ",", "\"dataset not in catalogs\"", "\n", "return", "DATASET_CATALOGS", "[", "dataset_name", "]", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_data_sampler": [[28, 36], ["samplers.DistributedSampler", "torch.utils.data.sampler.RandomSampler", "torch.utils.data.sampler.SequentialSampler"], "function", ["None"], ["", "def", "make_data_sampler", "(", "dataset", ",", "shuffle", ",", "distributed", ",", "num_replicas", ",", "rank", ")", ":", "\n", "    ", "if", "distributed", ":", "\n", "        ", "return", "samplers", ".", "DistributedSampler", "(", "dataset", ",", "shuffle", "=", "shuffle", ",", "num_replicas", "=", "num_replicas", ",", "rank", "=", "rank", ")", "\n", "", "if", "shuffle", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "RandomSampler", "(", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "SequentialSampler", "(", "dataset", ")", "\n", "", "return", "sampler", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_batch_data_sampler": [[38, 49], ["samplers.GroupedBatchSampler", "torch.utils.data.sampler.BatchSampler"], "function", ["None"], ["", "def", "make_batch_data_sampler", "(", "dataset", ",", "sampler", ",", "aspect_grouping", ",", "batch_size", ")", ":", "\n", "    ", "if", "aspect_grouping", ":", "\n", "        ", "group_ids", "=", "dataset", ".", "group_ids", "\n", "batch_sampler", "=", "samplers", ".", "GroupedBatchSampler", "(", "\n", "sampler", ",", "group_ids", ",", "batch_size", ",", "drop_uneven", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "        ", "batch_sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "BatchSampler", "(", "\n", "sampler", ",", "batch_size", ",", "drop_last", "=", "False", "\n", ")", "\n", "", "return", "batch_sampler", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_dataloader": [[51, 121], ["transforms.build.build_transforms", "build.make_data_sampler", "build.make_batch_data_sampler", "collate_batch.BatchCollator", "torch.utils.data.DataLoader", "len", "build.build_dataset", "cfg.GPUS.split", "len", "len", "cfg.GPUS.split", "cfg.GPUS.split"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.transforms.build.build_transforms", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_data_sampler", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_batch_data_sampler", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.build_dataset"], ["", "def", "make_dataloader", "(", "cfg", ",", "dataset", "=", "None", ",", "mode", "=", "'train'", ",", "distributed", "=", "False", ",", "num_replicas", "=", "None", ",", "rank", "=", "None", ",", "\n", "expose_sampler", "=", "False", ")", ":", "\n", "    ", "assert", "mode", "in", "[", "'train'", ",", "'val'", ",", "'test'", "]", "\n", "if", "mode", "==", "'train'", ":", "\n", "        ", "ann_file", "=", "cfg", ".", "DATASET", ".", "TRAIN_ANNOTATION_FILE", "\n", "image_set", "=", "cfg", ".", "DATASET", ".", "TRAIN_IMAGE_SET", "\n", "aspect_grouping", "=", "cfg", ".", "TRAIN", ".", "ASPECT_GROUPING", "\n", "num_gpu", "=", "len", "(", "cfg", ".", "GPUS", ".", "split", "(", "','", ")", ")", "\n", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_IMAGES", "*", "num_gpu", "\n", "shuffle", "=", "cfg", ".", "TRAIN", ".", "SHUFFLE", "\n", "num_workers", "=", "cfg", ".", "NUM_WORKERS_PER_GPU", "*", "num_gpu", "\n", "", "elif", "mode", "==", "'val'", ":", "\n", "        ", "ann_file", "=", "cfg", ".", "DATASET", ".", "VAL_ANNOTATION_FILE", "\n", "image_set", "=", "cfg", ".", "DATASET", ".", "VAL_IMAGE_SET", "\n", "aspect_grouping", "=", "False", "\n", "num_gpu", "=", "len", "(", "cfg", ".", "GPUS", ".", "split", "(", "','", ")", ")", "\n", "batch_size", "=", "cfg", ".", "VAL", ".", "BATCH_IMAGES", "*", "num_gpu", "\n", "shuffle", "=", "cfg", ".", "VAL", ".", "SHUFFLE", "\n", "num_workers", "=", "cfg", ".", "NUM_WORKERS_PER_GPU", "*", "num_gpu", "\n", "", "else", ":", "\n", "        ", "ann_file", "=", "cfg", ".", "DATASET", ".", "TEST_ANNOTATION_FILE", "\n", "image_set", "=", "cfg", ".", "DATASET", ".", "TEST_IMAGE_SET", "\n", "aspect_grouping", "=", "False", "\n", "num_gpu", "=", "len", "(", "cfg", ".", "GPUS", ".", "split", "(", "','", ")", ")", "\n", "batch_size", "=", "cfg", ".", "TEST", ".", "BATCH_IMAGES", "*", "num_gpu", "\n", "shuffle", "=", "cfg", ".", "TEST", ".", "SHUFFLE", "\n", "num_workers", "=", "cfg", ".", "NUM_WORKERS_PER_GPU", "*", "num_gpu", "\n", "\n", "", "transform", "=", "build_transforms", "(", "cfg", ",", "mode", ")", "\n", "\n", "if", "dataset", "is", "None", ":", "\n", "\n", "        ", "dataset", "=", "build_dataset", "(", "dataset_name", "=", "cfg", ".", "DATASET", ".", "DATASET", ",", "ann_file", "=", "ann_file", ",", "image_set", "=", "image_set", ",", "\n", "seq_len", "=", "cfg", ".", "DATASET", ".", "SEQ_LEN", ",", "min_seq_len", "=", "cfg", ".", "DATASET", ".", "MIN_SEQ_LEN", ",", "\n", "with_precomputed_visual_feat", "=", "cfg", ".", "NETWORK", ".", "IMAGE_FEAT_PRECOMPUTED", ",", "\n", "mask_raw_pixels", "=", "cfg", ".", "NETWORK", ".", "MASK_RAW_PIXELS", ",", "\n", "with_rel_task", "=", "cfg", ".", "NETWORK", ".", "WITH_REL_LOSS", ",", "\n", "with_mlm_task", "=", "cfg", ".", "NETWORK", ".", "WITH_MLM_LOSS", ",", "\n", "with_mvrc_task", "=", "cfg", ".", "NETWORK", ".", "WITH_MVRC_LOSS", ",", "\n", "answer_vocab_file", "=", "cfg", ".", "DATASET", ".", "ANSWER_VOCAB_FILE", ",", "\n", "root_path", "=", "cfg", ".", "DATASET", ".", "ROOT_PATH", ",", "data_path", "=", "cfg", ".", "DATASET", ".", "DATASET_PATH", ",", "\n", "test_mode", "=", "(", "mode", "==", "'test'", ")", ",", "transform", "=", "transform", ",", "\n", "zip_mode", "=", "cfg", ".", "DATASET", ".", "ZIP_MODE", ",", "cache_mode", "=", "cfg", ".", "DATASET", ".", "CACHE_MODE", ",", "\n", "cache_db", "=", "True", "if", "(", "\n", "rank", "is", "None", "or", "rank", "==", "0", ")", "else", "False", ",", "\n", "ignore_db_cache", "=", "cfg", ".", "DATASET", ".", "IGNORE_DB_CACHE", ",", "\n", "add_image_as_a_box", "=", "cfg", ".", "DATASET", ".", "ADD_IMAGE_AS_A_BOX", ",", "\n", "aspect_grouping", "=", "aspect_grouping", ",", "\n", "mask_size", "=", "(", "cfg", ".", "DATASET", ".", "MASK_SIZE", ",", "\n", "cfg", ".", "DATASET", ".", "MASK_SIZE", ")", ",", "\n", "pretrained_model_name", "=", "cfg", ".", "NETWORK", ".", "BERT_MODEL_NAME", ",", "\n", "task_name", "=", "cfg", ".", "DATASET", ".", "TASK_NAME", ",", "\n", "lang", "=", "cfg", ".", "DATASET", ".", "LANG", ")", "\n", "\n", "", "sampler", "=", "make_data_sampler", "(", "\n", "dataset", ",", "shuffle", ",", "distributed", ",", "num_replicas", ",", "rank", ")", "\n", "batch_sampler", "=", "make_batch_data_sampler", "(", "\n", "dataset", ",", "sampler", ",", "aspect_grouping", ",", "batch_size", ")", "\n", "collator", "=", "BatchCollator", "(", "\n", "dataset", "=", "dataset", ",", "append_ind", "=", "cfg", ".", "DATASET", ".", "APPEND_INDEX", ")", "\n", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "dataset", ",", "\n", "batch_sampler", "=", "batch_sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "pin_memory", "=", "False", ",", "\n", "collate_fn", "=", "collator", ")", "\n", "if", "expose_sampler", ":", "\n", "        ", "return", "dataloader", ",", "sampler", "\n", "\n", "", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_dataloaders": [[123, 143], ["enumerate", "copy.deepcopy", "outputs.append", "build.make_dataloader"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_dataloader"], ["", "def", "make_dataloaders", "(", "cfg", ",", "mode", "=", "'train'", ",", "distributed", "=", "False", ",", "num_replicas", "=", "None", ",", "rank", "=", "None", ",", "expose_sampler", "=", "False", ")", ":", "\n", "\n", "    ", "outputs", "=", "[", "]", "\n", "\n", "for", "i", ",", "dataset_cfg", "in", "enumerate", "(", "cfg", ".", "DATASET", ")", ":", "\n", "        ", "cfg_", "=", "deepcopy", "(", "cfg", ")", "\n", "cfg_", ".", "DATASET", "=", "dataset_cfg", "\n", "cfg_", ".", "TRAIN", ".", "BATCH_IMAGES", "=", "cfg", ".", "TRAIN", ".", "BATCH_IMAGES", "[", "i", "]", "\n", "cfg_", ".", "VAL", ".", "BATCH_IMAGES", "=", "cfg", ".", "VAL", ".", "BATCH_IMAGES", "[", "i", "]", "\n", "cfg_", ".", "TEST", ".", "BATCH_IMAGES", "=", "cfg", ".", "TEST", ".", "BATCH_IMAGES", "[", "i", "]", "\n", "outputs", ".", "append", "(", "\n", "make_dataloader", "(", "cfg_", ",", "\n", "mode", "=", "mode", ",", "\n", "distributed", "=", "distributed", ",", "\n", "num_replicas", "=", "num_replicas", ",", "\n", "rank", "=", "rank", ",", "\n", "expose_sampler", "=", "expose_sampler", ")", "\n", ")", "\n", "\n", "", "return", "outputs", "\n", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.collate_batch.BatchCollator.__init__": [[6, 11], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "append_ind", "=", "False", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "test_mode", "=", "self", ".", "dataset", ".", "test_mode", "\n", "self", ".", "data_names", "=", "self", ".", "dataset", ".", "data_names", "\n", "self", ".", "append_ind", "=", "append_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.collate_batch.BatchCollator.__call__": [[12, 95], ["enumerate", "zip", "isinstance", "list", "max", "max", "max", "max", "tuple", "tuple", "clip_pad_boxes", "clip_pad_1d", "clip_pad_1d", "clip_pad_1d", "clip_pad_1d", "clip_pad_1d", "clip_pad_1d", "clip_pad_1d", "clip_pad_boxes", "torch.as_tensor", "len", "len", "len", "clip_pad_images", "torch.tensor", "torch.stack", "collate_batch.BatchCollator.data_names.index", "max", "collate_batch.BatchCollator.data_names.index", "collate_batch.BatchCollator.data_names.index", "collate_batch.BatchCollator.data_names.index", "collate_batch.BatchCollator.data_names.index", "collate_batch.BatchCollator.data_names.index", "collate_batch.BatchCollator.data_names.index", "collate_batch.BatchCollator.data_names.index", "collate_batch.BatchCollator.data_names.index", "collate_batch.BatchCollator.data_names.index", "tuple", "zip", "collate_batch.BatchCollator.data_names.index", "collate_batch.BatchCollator.data_names.index", "collate_batch.BatchCollator.data_names.index", "collate_batch.BatchCollator.data_names.index", "collate_batch.BatchCollator.data_names.index", "collate_batch.BatchCollator.data_names.index", "collate_batch.BatchCollator.data_names.index"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.clip_pad.clip_pad_boxes", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.clip_pad.clip_pad_1d", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.clip_pad.clip_pad_1d", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.clip_pad.clip_pad_1d", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.clip_pad.clip_pad_1d", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.clip_pad.clip_pad_1d", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.clip_pad.clip_pad_1d", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.clip_pad.clip_pad_1d", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.clip_pad.clip_pad_boxes", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.clip_pad.clip_pad_images"], ["", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "batch", ",", "list", ")", ":", "\n", "            ", "batch", "=", "list", "(", "batch", ")", "\n", "\n", "", "if", "'image'", "in", "self", ".", "data_names", ":", "\n", "            ", "if", "batch", "[", "0", "]", "[", "self", ".", "data_names", ".", "index", "(", "'image'", ")", "]", "is", "not", "None", ":", "\n", "                ", "max_shape", "=", "tuple", "(", "max", "(", "s", ")", "for", "s", "in", "zip", "(", "*", "[", "data", "[", "self", ".", "data_names", ".", "index", "(", "'image'", ")", "]", ".", "shape", "for", "data", "in", "batch", "]", ")", ")", "\n", "image_none", "=", "False", "\n", "", "else", ":", "\n", "                ", "image_none", "=", "True", "\n", "", "", "if", "'boxes'", "in", "self", ".", "data_names", ":", "\n", "            ", "max_boxes", "=", "max", "(", "[", "data", "[", "self", ".", "data_names", ".", "index", "(", "'boxes'", ")", "]", ".", "shape", "[", "0", "]", "for", "data", "in", "batch", "]", ")", "\n", "", "if", "'text'", "in", "self", ".", "data_names", ":", "\n", "            ", "max_text_length", "=", "max", "(", "[", "len", "(", "data", "[", "self", ".", "data_names", ".", "index", "(", "'text'", ")", "]", ")", "for", "data", "in", "batch", "]", ")", "\n", "", "if", "'text_en'", "in", "self", ".", "data_names", ":", "\n", "            ", "max_text_length_en", "=", "max", "(", "[", "len", "(", "data", "[", "self", ".", "data_names", ".", "index", "(", "'text_en'", ")", "]", ")", "for", "data", "in", "batch", "]", ")", "\n", "", "if", "'text_de'", "in", "self", ".", "data_names", ":", "\n", "            ", "max_text_length_de", "=", "max", "(", "[", "len", "(", "data", "[", "self", ".", "data_names", ".", "index", "(", "'text_de'", ")", "]", ")", "for", "data", "in", "batch", "]", ")", "\n", "\n", "", "for", "i", ",", "ibatch", "in", "enumerate", "(", "batch", ")", ":", "\n", "            ", "out", "=", "{", "}", "\n", "\n", "if", "'image'", "in", "self", ".", "data_names", ":", "\n", "                ", "if", "image_none", ":", "\n", "                    ", "out", "[", "'image'", "]", "=", "None", "\n", "", "else", ":", "\n", "                    ", "image", "=", "ibatch", "[", "self", ".", "data_names", ".", "index", "(", "'image'", ")", "]", "\n", "out", "[", "'image'", "]", "=", "clip_pad_images", "(", "image", ",", "max_shape", ",", "pad", "=", "0", ")", "\n", "\n", "", "", "if", "'boxes'", "in", "self", ".", "data_names", ":", "\n", "                ", "boxes", "=", "ibatch", "[", "self", ".", "data_names", ".", "index", "(", "'boxes'", ")", "]", "\n", "out", "[", "'boxes'", "]", "=", "clip_pad_boxes", "(", "boxes", ",", "max_boxes", ",", "pad", "=", "-", "2", ")", "\n", "\n", "", "if", "'text'", "in", "self", ".", "data_names", ":", "\n", "                ", "text", "=", "ibatch", "[", "self", ".", "data_names", ".", "index", "(", "'text'", ")", "]", "\n", "out", "[", "'text'", "]", "=", "clip_pad_1d", "(", "text", ",", "max_text_length", ",", "pad", "=", "0", ")", "\n", "\n", "", "if", "'mlm_labels'", "in", "self", ".", "data_names", ":", "\n", "                ", "mlm_labels", "=", "ibatch", "[", "self", ".", "data_names", ".", "index", "(", "'mlm_labels'", ")", "]", "\n", "out", "[", "'mlm_labels'", "]", "=", "clip_pad_1d", "(", "mlm_labels", ",", "max_text_length", ",", "pad", "=", "-", "1", ")", "\n", "#****************", "\n", "# FM edit: added for MT decoder encoder", "\n", "", "if", "'text_en'", "in", "self", ".", "data_names", ":", "\n", "                ", "text_en", "=", "ibatch", "[", "self", ".", "data_names", ".", "index", "(", "'text_en'", ")", "]", "\n", "out", "[", "'text_en'", "]", "=", "clip_pad_1d", "(", "text_en", ",", "max_text_length_en", ",", "pad", "=", "0", ")", "\n", "\n", "", "if", "'mlm_labels_en'", "in", "self", ".", "data_names", ":", "\n", "                ", "mlm_labels_en", "=", "ibatch", "[", "self", ".", "data_names", ".", "index", "(", "'mlm_labels_en'", ")", "]", "\n", "out", "[", "'mlm_labels_en'", "]", "=", "clip_pad_1d", "(", "mlm_labels_en", ",", "max_text_length_en", ",", "pad", "=", "-", "1", ")", "\n", "\n", "", "if", "'text_de'", "in", "self", ".", "data_names", ":", "\n", "                ", "text_de", "=", "ibatch", "[", "self", ".", "data_names", ".", "index", "(", "'text_de'", ")", "]", "\n", "out", "[", "'text_de'", "]", "=", "clip_pad_1d", "(", "text_de", ",", "max_text_length_de", ",", "pad", "=", "0", ")", "\n", "\n", "", "if", "'mlm_labels_de'", "in", "self", ".", "data_names", ":", "\n", "                ", "mlm_labels_de", "=", "ibatch", "[", "self", ".", "data_names", ".", "index", "(", "'mlm_labels_de'", ")", "]", "\n", "out", "[", "'mlm_labels_de'", "]", "=", "clip_pad_1d", "(", "mlm_labels_de", ",", "max_text_length_de", ",", "pad", "=", "-", "1", ")", "\n", "#****************", "\n", "\n", "", "if", "'mvrc_ops'", "in", "self", ".", "data_names", ":", "\n", "                ", "mvrc_ops", "=", "ibatch", "[", "self", ".", "data_names", ".", "index", "(", "'mvrc_ops'", ")", "]", "\n", "out", "[", "'mvrc_ops'", "]", "=", "clip_pad_1d", "(", "mvrc_ops", ",", "max_boxes", ",", "pad", "=", "0", ")", "\n", "\n", "", "if", "'mvrc_labels'", "in", "self", ".", "data_names", ":", "\n", "                ", "mvrc_labels", "=", "ibatch", "[", "self", ".", "data_names", ".", "index", "(", "'mvrc_labels'", ")", "]", "\n", "out", "[", "'mvrc_labels'", "]", "=", "clip_pad_boxes", "(", "mvrc_labels", ",", "max_boxes", ",", "pad", "=", "0", ")", "\n", "\n", "", "other_names", "=", "[", "data_name", "for", "data_name", "in", "self", ".", "data_names", "if", "data_name", "not", "in", "out", "]", "\n", "for", "name", "in", "other_names", ":", "\n", "                ", "out", "[", "name", "]", "=", "torch", ".", "as_tensor", "(", "ibatch", "[", "self", ".", "data_names", ".", "index", "(", "name", ")", "]", ")", "\n", "\n", "", "batch", "[", "i", "]", "=", "tuple", "(", "out", "[", "data_name", "]", "for", "data_name", "in", "self", ".", "data_names", ")", "\n", "if", "self", ".", "append_ind", ":", "\n", "                ", "batch", "[", "i", "]", "+=", "(", "torch", ".", "tensor", "(", "i", ",", "dtype", "=", "torch", ".", "int64", ")", ",", ")", "\n", "\n", "", "", "out_tuple", "=", "(", ")", "\n", "for", "items", "in", "zip", "(", "*", "batch", ")", ":", "\n", "            ", "if", "items", "[", "0", "]", "is", "None", ":", "\n", "                ", "out_tuple", "+=", "(", "None", ",", ")", "\n", "", "else", ":", "\n", "                ", "out_tuple", "+=", "(", "torch", ".", "stack", "(", "tuple", "(", "items", ")", ",", "dim", "=", "0", ")", ",", ")", "\n", "\n", "", "", "return", "out_tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only.Multi30kDatasetImageOnly.__init__": [[22, 161], ["torch.utils.data.Dataset.__init__", "os.path.join", "os.path.join", "common.utils.zipreader.ZipReader", "list", "enumerate", "print", "os.path.exists", "common.utils.create_logger.makedirsExist", "external.pytorch_pretrained_bert.BertTokenizer.from_pretrained", "jsonlines.open", "enumerate", "idb[].replace", "idb[].replace", "print", "print", "print", "print", "multi30k_image_only.Multi30kDatasetImageOnly.group_aspect", "idb[].replace().replace().replace().replace().replace", "idb[].replace", "[].split", "len", "len", "multi30k_image_only.Multi30kDatasetImageOnly.tokenizer.tokenize", "enumerate", "multi30k_image_only.Multi30kDatasetImageOnly.database.append", "multi30k_image_only.Multi30kDatasetImageOnly.tokenizer.tokenize", "enumerate", "multi30k_image_only.Multi30kDatasetImageOnly.database.append", "idb[].replace().replace().replace().replace", "multi30k_image_only.Multi30kDatasetImageOnly.database.append", "copy.deepcopy", "copy.deepcopy", "multi30k_image_only.Multi30kDatasetImageOnly.database.append", "copy.deepcopy", "copy.deepcopy", "idb[].split", "copy.deepcopy", "copy.deepcopy", "idb[].replace().replace().replace", "idb[].replace().replace", "idb[].replace"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.create_logger.makedirsExist", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.from_pretrained", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.group_aspect", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize"], ["    ", "def", "__init__", "(", "self", ",", "ann_file", ",", "image_set", ",", "root_path", ",", "data_path", ",", "seq_len", "=", "64", ",", "\n", "with_precomputed_visual_feat", "=", "False", ",", "mask_raw_pixels", "=", "True", ",", "\n", "with_rel_task", "=", "True", ",", "with_mlm_task", "=", "True", ",", "with_mvrc_task", "=", "True", ",", "\n", "transform", "=", "None", ",", "test_mode", "=", "False", ",", "\n", "zip_mode", "=", "False", ",", "cache_mode", "=", "False", ",", "cache_db", "=", "False", ",", "ignore_db_cache", "=", "True", ",", "\n", "tokenizer", "=", "None", ",", "pretrained_model_name", "=", "None", ",", "\n", "add_image_as_a_box", "=", "False", ",", "\n", "aspect_grouping", "=", "False", ",", "task_name", "=", "\"None\"", ",", "lang", "=", "\"second\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Conceptual Captions Dataset\n\n        :param ann_file: annotation jsonl file\n        :param image_set: image folder name, e.g., 'vcr1images'\n        :param root_path: root path to cache database loaded from annotation file\n        :param data_path: path to vcr dataset\n        :param transform: transform\n        :param test_mode: test mode means no labels available\n        :param zip_mode: reading images and metadata in zip archive\n        :param cache_mode: cache whole dataset to RAM first, then __getitem__ read them from RAM\n        :param ignore_db_cache: ignore previous cached database, reload it from annotation file\n        :param tokenizer: default is BertTokenizer from pytorch_pretrained_bert\n        :param add_image_as_a_box: add whole image as a box\n        :param aspect_grouping: whether to group images via their aspect\n        :param kwargs:\n        \"\"\"", "\n", "super", "(", "Multi30kDatasetImageOnly", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "not", "cache_mode", ",", "'currently not support cache mode!'", "\n", "# FM edit: commented out to allow testin", "\n", "# assert not test_mode", "\n", "\n", "annot", "=", "{", "'train'", ":", "'train_frcnn.json'", ",", "\n", "'val'", ":", "'val_frcnn.json'", ",", "\n", "'test2015'", ":", "'test_frcnn.json'", ",", "\n", "'test2018'", ":", "'test_frcnn2018.json'", ",", "\n", "}", "\n", "\n", "self", ".", "seq_len", "=", "seq_len", "\n", "self", ".", "with_rel_task", "=", "with_rel_task", "\n", "self", ".", "with_mlm_task", "=", "with_mlm_task", "\n", "self", ".", "with_mvrc_task", "=", "with_mvrc_task", "\n", "self", ".", "data_path", "=", "data_path", "\n", "self", ".", "root_path", "=", "root_path", "\n", "self", ".", "ann_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "annot", "[", "image_set", "]", ")", "\n", "self", ".", "with_precomputed_visual_feat", "=", "with_precomputed_visual_feat", "\n", "self", ".", "mask_raw_pixels", "=", "mask_raw_pixels", "\n", "self", ".", "image_set", "=", "image_set", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "zip_mode", "=", "zip_mode", "\n", "self", ".", "cache_mode", "=", "cache_mode", "\n", "self", ".", "cache_db", "=", "cache_db", "\n", "self", ".", "ignore_db_cache", "=", "ignore_db_cache", "\n", "self", ".", "aspect_grouping", "=", "aspect_grouping", "\n", "self", ".", "cache_dir", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "'cache'", ")", "\n", "self", ".", "add_image_as_a_box", "=", "add_image_as_a_box", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "cache_dir", ")", ":", "\n", "            ", "makedirsExist", "(", "self", ".", "cache_dir", ")", "\n", "", "self", ".", "tokenizer", "=", "tokenizer", "if", "tokenizer", "is", "not", "None", "else", "BertTokenizer", ".", "from_pretrained", "(", "\n", "'bert-base-uncased'", "if", "pretrained_model_name", "is", "None", "else", "pretrained_model_name", ",", "\n", "cache_dir", "=", "self", ".", "cache_dir", ",", "do_lower_case", "=", "False", ")", "\n", "\n", "self", ".", "zipreader", "=", "ZipReader", "(", ")", "\n", "\n", "# FM: define task name to add prefix", "\n", "self", ".", "task_name", "=", "task_name", "\n", "self", ".", "lang", "=", "lang", "\n", "\n", "# FM: Customise for multi30k dataset", "\n", "self", ".", "simple_database", "=", "list", "(", "jsonlines", ".", "open", "(", "self", ".", "ann_file", ")", ")", "\n", "if", "not", "self", ".", "zip_mode", ":", "\n", "            ", "for", "i", ",", "idb", "in", "enumerate", "(", "self", ".", "simple_database", ")", ":", "\n", "                ", "self", ".", "simple_database", "[", "i", "]", "[", "'frcnn'", "]", "=", "idb", "[", "'frcnn'", "]", ".", "replace", "(", "'.zip@'", ",", "''", ")", ".", "replace", "(", "'.0'", ",", "''", ")", ".", "replace", "(", "'.1'", ",", "''", ")", ".", "replace", "(", "'.2'", ",", "''", ")", ".", "replace", "(", "'.3'", ",", "''", ")", "\n", "self", ".", "simple_database", "[", "i", "]", "[", "'image'", "]", "=", "idb", "[", "'image'", "]", ".", "replace", "(", "\n", "'.zip@'", ",", "''", ")", "\n", "\n", "# FM: TODO correct this", "\n", "", "", "for", "i", ",", "idb", "in", "enumerate", "(", "self", ".", "simple_database", ")", ":", "\n", "# correct address:", "\n", "            ", "idb", "[", "'frcnn'", "]", "=", "idb", "[", "'frcnn'", "]", ".", "replace", "(", "\n", "\"test_2016_flickr_frcnn.zip\"", ",", "\"test_frcnn.zip\"", ")", "\n", "old_id", "=", "idb", "[", "'frcnn'", "]", ".", "split", "(", "'/'", ")", "[", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "image_id", "=", "old_id", "\n", "while", "len", "(", "image_id", ")", "<", "8", ":", "\n", "                ", "image_id", "=", "'0'", "+", "image_id", "\n", "", "self", ".", "simple_database", "[", "i", "]", "[", "'frcnn'", "]", "=", "idb", "[", "'frcnn'", "]", ".", "replace", "(", "\n", "old_id", ",", "image_id", ")", "\n", "\n", "", "if", "not", "self", ".", "test_mode", ":", "\n", "            ", "self", ".", "database", "=", "[", "]", "\n", "db_pos", "=", "0", "\n", "# create [MASK] every time", "\n", "for", "entry", "in", "self", ".", "simple_database", ":", "\n", "                ", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "                    ", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\n", "entry", "[", "'caption_de'", "]", ")", "\n", "# repeat each entry multiple times - MASK the last word in each case", "\n", "for", "pos", ",", "item", "in", "enumerate", "(", "caption_tokens_de", ")", ":", "\n", "                        ", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "entry", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_de'", "]", "=", "deepcopy", "(", "\n", "caption_tokens_de", "[", ":", "pos", "+", "1", "]", ")", "\n", "db_pos", "+=", "1", "\n", "# add one last entry with last token [STOP]", "\n", "", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "self", ".", "database", "[", "db_pos", "-", "1", "]", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_de'", "]", "=", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_de'", "]", "+", "[", "'[STOP]'", "]", "\n", "db_pos", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\n", "entry", "[", "'caption_en'", "]", ")", "\n", "# repeat each entry multiple times - MASK the last word in each case", "\n", "for", "pos", ",", "item", "in", "enumerate", "(", "caption_tokens_en", ")", ":", "\n", "                        ", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "entry", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_en'", "]", "=", "deepcopy", "(", "\n", "caption_tokens_en", "[", ":", "pos", "+", "1", "]", ")", "\n", "db_pos", "+=", "1", "\n", "# add one last entry with last token [STOP]", "\n", "", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "self", ".", "database", "[", "db_pos", "-", "1", "]", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_en'", "]", "=", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_en'", "]", "+", "[", "'[STOP]'", "]", "\n", "db_pos", "+=", "1", "\n", "", "", "print", "(", "'***********************'", ")", "\n", "print", "(", "'The dataset length is: '", ",", "len", "(", "self", ".", "database", ")", ")", "\n", "print", "(", "'Task: '", ",", "self", ".", "task_name", ")", "\n", "print", "(", "'Lang: '", ",", "self", ".", "lang", ")", "\n", "", "else", ":", "\n", "# ignore multiple in turkish (2xcaption), english/german(5xcaption)", "\n", "            ", "if", "self", ".", "task_name", "==", "'[TO_TU]'", ":", "\n", "                ", "self", ".", "database", "=", "self", ".", "simple_database", "[", ":", ":", "2", "]", "\n", "", "elif", "self", ".", "task_name", "==", "'[TO_FR]'", ":", "\n", "                ", "self", ".", "database", "=", "self", ".", "simple_database", "\n", "", "else", ":", "\n", "                ", "self", ".", "database", "=", "self", ".", "simple_database", "[", ":", ":", "5", "]", "\n", "\n", "", "", "if", "self", ".", "aspect_grouping", ":", "\n", "            ", "assert", "False", ",", "\"not support aspect grouping currently!\"", "\n", "self", ".", "group_ids", "=", "self", ".", "group_aspect", "(", "self", ".", "database", ")", "\n", "\n", "", "print", "(", "'mask_raw_pixels: '", ",", "self", ".", "mask_raw_pixels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only.Multi30kDatasetImageOnly.data_names": [[162, 166], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "data_names", "(", "self", ")", ":", "\n", "        ", "return", "[", "'image'", ",", "'boxes'", ",", "'im_info'", ",", "'text'", ",", "\n", "'relationship_label'", ",", "'mlm_labels'", ",", "'mvrc_ops'", ",", "'mvrc_labels'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only.Multi30kDatasetImageOnly.__getitem__": [[167, 373], ["multi30k_image_only.Multi30kDatasetImageOnly._load_json", "numpy.frombuffer().reshape", "numpy.frombuffer().reshape", "numpy.frombuffer().reshape.max", "torch.as_tensor", "torch.tensor", "im_info[].item", "im_info[].item", "boxes[].clamp", "boxes[].clamp", "random.random", "numpy.stack", "multi30k_image_only.Multi30kDatasetImageOnly.tokenizer.convert_tokens_to_ids", "os.path.join", "numpy.argsort", "numpy.frombuffer().reshape", "torch.as_tensor", "torch.as_tensor", "torch.cat", "multi30k_image_only.Multi30kDatasetImageOnly.transform", "int", "int", "torch.tensor.new_zeros", "random.randrange", "zip", "torch.cat", "len", "len", "numpy.frombuffer", "numpy.frombuffer", "multi30k_image_only.Multi30kDatasetImageOnly._load_image", "torch.cat.mean", "torch.cat", "im_info[].item", "im_info[].item", "len", "random.randrange", "multi30k_image_only.Multi30kDatasetImageOnly.tokenizer.tokenize", "multi30k_image_only.Multi30kDatasetImageOnly.tokenizer.tokenize", "multi30k_image_only.Multi30kDatasetImageOnly.random_mask_region", "multi30k_image_only.Multi30kDatasetImageOnly.random_mask_region", "len", "len", "len", "len", "len", "len", "multi30k_image_only.Multi30kDatasetImageOnly.b64_decode", "multi30k_image_only.Multi30kDatasetImageOnly.b64_decode", "numpy.frombuffer", "os.path.join", "print", "len", "multi30k_image_only.Multi30kDatasetImageOnly.tokenizer.tokenize", "multi30k_image_only.Multi30kDatasetImageOnly.tokenizer.tokenize", "len", "len", "zip", "numpy.zeros_like", "multi30k_image_only.Multi30kDatasetImageOnly.b64_decode", "mlm_labels_de.append", "mlm_labels_en.append", "numpy.zeros_like", "len", "mlm_labels_de.append", "logging.warning", "len", "mlm_labels_en.append", "logging.warning", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision._load_json", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision._load_image", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.random_mask_region", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.random_mask_region", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.b64_decode", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.b64_decode", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.b64_decode"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "idb", "=", "self", ".", "database", "[", "index", "]", "\n", "\n", "# image data", "\n", "# IN ALL CASES: boxes and cls scores are available for each image", "\n", "frcnn_data", "=", "self", ".", "_load_json", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "idb", "[", "'frcnn'", "]", ")", ")", "\n", "boxes", "=", "np", ".", "frombuffer", "(", "self", ".", "b64_decode", "(", "frcnn_data", "[", "'boxes'", "]", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "frcnn_data", "[", "'num_boxes'", "]", ",", "-", "1", ")", ")", "\n", "boxes_cls_scores", "=", "np", ".", "frombuffer", "(", "self", ".", "b64_decode", "(", "frcnn_data", "[", "'classes'", "]", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "frcnn_data", "[", "'num_boxes'", "]", ",", "-", "1", ")", ")", "\n", "boxes_max_conf", "=", "boxes_cls_scores", ".", "max", "(", "axis", "=", "1", ")", "\n", "inds", "=", "np", ".", "argsort", "(", "boxes_max_conf", ")", "[", ":", ":", "-", "1", "]", "\n", "boxes", "=", "boxes", "[", "inds", "]", "\n", "boxes_cls_scores", "=", "boxes_cls_scores", "[", "inds", "]", "\n", "boxes", "=", "torch", ".", "as_tensor", "(", "boxes", ")", "\n", "\n", "# load precomputed features or the whole image depending on setup", "\n", "if", "self", ".", "with_precomputed_visual_feat", ":", "\n", "            ", "image", "=", "None", "\n", "w0", ",", "h0", "=", "frcnn_data", "[", "'image_w'", "]", ",", "frcnn_data", "[", "'image_h'", "]", "\n", "boxes_features", "=", "np", ".", "frombuffer", "(", "self", ".", "b64_decode", "(", "frcnn_data", "[", "'features'", "]", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "frcnn_data", "[", "'num_boxes'", "]", ",", "-", "1", ")", ")", "\n", "boxes_features", "=", "boxes_features", "[", "inds", "]", "\n", "boxes_features", "=", "torch", ".", "as_tensor", "(", "boxes_features", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "image", "=", "self", ".", "_load_image", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "idb", "[", "'image'", "]", ")", ")", "\n", "w0", ",", "h0", "=", "image", ".", "size", "\n", "", "except", ":", "\n", "                ", "print", "(", "\"Failed to load image {}, use zero image!\"", ".", "format", "(", "\n", "idb", "[", "'image'", "]", ")", ")", "\n", "image", "=", "None", "\n", "w0", ",", "h0", "=", "frcnn_data", "[", "'image_w'", "]", ",", "frcnn_data", "[", "'image_h'", "]", "\n", "\n", "# append whole image to tensor of boxes (used for all linguistic tokens)", "\n", "", "", "if", "self", ".", "add_image_as_a_box", ":", "\n", "            ", "image_box", "=", "torch", ".", "as_tensor", "(", "[", "[", "0.0", ",", "0.0", ",", "w0", "-", "1.0", ",", "h0", "-", "1.0", "]", "]", ")", "\n", "boxes", "=", "torch", ".", "cat", "(", "(", "image_box", ",", "boxes", ")", ",", "dim", "=", "0", ")", "\n", "if", "self", ".", "with_precomputed_visual_feat", ":", "\n", "                ", "image_box_feat", "=", "boxes_features", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "boxes_features", "=", "torch", ".", "cat", "(", "\n", "(", "image_box_feat", ",", "boxes_features", ")", ",", "dim", "=", "0", ")", "\n", "\n", "# transform", "\n", "", "", "im_info", "=", "torch", ".", "tensor", "(", "[", "w0", ",", "h0", ",", "1.0", ",", "1.0", ",", "index", "]", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "image", ",", "boxes", ",", "_", ",", "im_info", "=", "self", ".", "transform", "(", "\n", "image", ",", "boxes", ",", "None", ",", "im_info", ")", "\n", "\n", "", "if", "image", "is", "None", "and", "(", "not", "self", ".", "with_precomputed_visual_feat", ")", ":", "\n", "            ", "w", "=", "int", "(", "im_info", "[", "0", "]", ".", "item", "(", ")", ")", "\n", "h", "=", "int", "(", "im_info", "[", "1", "]", ".", "item", "(", ")", ")", "\n", "image", "=", "im_info", ".", "new_zeros", "(", "(", "3", ",", "h", ",", "w", ")", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "# clamp boxes", "\n", "", "w", "=", "im_info", "[", "0", "]", ".", "item", "(", ")", "\n", "h", "=", "im_info", "[", "1", "]", ".", "item", "(", ")", "\n", "boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "w", "-", "1", ")", "\n", "boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", "=", "boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "h", "-", "1", ")", "\n", "\n", "# Task #1: Caption-Image Relationship Prediction", "\n", "_p", "=", "random", ".", "random", "(", ")", "\n", "if", "_p", "<", "0.5", "or", "(", "not", "self", ".", "with_rel_task", ")", ":", "\n", "            ", "relationship_label", "=", "1", "\n", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "                ", "caption_de", "=", "idb", "[", "'caption_de'", "]", "\n", "", "else", ":", "\n", "                ", "caption_en", "=", "idb", "[", "'caption_en'", "]", "\n", "", "", "else", ":", "\n", "            ", "relationship_label", "=", "0", "\n", "rand_index", "=", "random", ".", "randrange", "(", "0", ",", "len", "(", "self", ".", "database", ")", ")", "\n", "while", "rand_index", "==", "index", ":", "\n", "                ", "rand_index", "=", "random", ".", "randrange", "(", "0", ",", "len", "(", "self", ".", "database", ")", ")", "\n", "", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "                ", "caption_de", "=", "self", ".", "database", "[", "rand_index", "]", "[", "'caption_de'", "]", "\n", "", "else", ":", "\n", "                ", "caption_en", "=", "self", ".", "database", "[", "rand_index", "]", "[", "'caption_en'", "]", "\n", "\n", "# Task #2: Masked Language Modeling - Adapted for two languages", "\n", "\n", "", "", "if", "self", ".", "with_mlm_task", ":", "\n", "            ", "if", "not", "self", ".", "test_mode", ":", "\n", "                ", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "# FM edit: Mask always the last token", "\n", "                    ", "caption_tokens_de", "=", "caption_de", "\n", "mlm_labels_de", "=", "[", "-", "1", "]", "*", "(", "len", "(", "caption_tokens_de", ")", "-", "1", ")", "\n", "try", ":", "\n", "                        ", "mlm_labels_de", ".", "append", "(", "\n", "self", ".", "tokenizer", ".", "vocab", "[", "caption_tokens_de", "[", "-", "1", "]", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "# For unknown words (should not occur with BPE vocab)", "\n", "                        ", "mlm_labels_de", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "\"[UNK]\"", "]", ")", "\n", "logging", ".", "warning", "(", "\n", "\"Cannot find sub_token '{}' in vocab. Using [UNK] insetad\"", ".", "format", "(", "sub_token", ")", ")", "\n", "", "caption_tokens_de", "[", "-", "1", "]", "=", "'[MASK]'", "\n", "", "else", ":", "\n", "# FM edit: Mask always the last token", "\n", "                    ", "caption_tokens_en", "=", "caption_en", "\n", "mlm_labels_en", "=", "[", "-", "1", "]", "*", "(", "len", "(", "caption_tokens_en", ")", "-", "1", ")", "\n", "try", ":", "\n", "                        ", "mlm_labels_en", ".", "append", "(", "\n", "self", ".", "tokenizer", ".", "vocab", "[", "caption_tokens_en", "[", "-", "1", "]", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "# For unknown words (should not occur with BPE vocab)", "\n", "                        ", "mlm_labels_en", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "\"[UNK]\"", "]", ")", "\n", "logging", ".", "warning", "(", "\n", "\"Cannot find sub_token '{}' in vocab. Using [UNK] insetad\"", ".", "format", "(", "sub_token", ")", ")", "\n", "", "caption_tokens_en", "[", "-", "1", "]", "=", "'[MASK]'", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "# FM edit: add [MASK] to start guessing caption", "\n", "                    ", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_de", ")", "\n", "# FM edit: add label from vocabulary", "\n", "mlm_labels_de", "=", "[", "103", "]", "+", "[", "-", "1", "]", "\n", "caption_tokens_de", "=", "[", "'[MASK]'", "]", "+", "[", "'[PAD]'", "]", "\n", "", "else", ":", "\n", "# FM edit: add [MASK] to start guessing caption", "\n", "                    ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_en", ")", "\n", "# FM edit: add label from vocabulary", "\n", "mlm_labels_en", "=", "[", "103", "]", "+", "[", "-", "1", "]", "\n", "caption_tokens_en", "=", "[", "'[MASK]'", "]", "+", "[", "'[PAD]'", "]", "\n", "", "", "", "else", ":", "\n", "            ", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "                ", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_de", ")", "\n", "mlm_labels_de", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_de", ")", "\n", "", "else", ":", "\n", "                ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_en", ")", "\n", "mlm_labels_en", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_en", ")", "\n", "\n", "", "", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "            ", "text_tokens", "=", "[", "self", ".", "task_name", "]", "+", "[", "'[CLS]'", "]", "+", "[", "'[SEP]'", "]", "+", "caption_tokens_de", "+", "[", "'[SEP]'", "]", "\n", "mlm_labels", "=", "[", "-", "1", "]", "+", "[", "-", "1", "]", "+", "[", "-", "1", "]", "+", "mlm_labels_de", "+", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "text_tokens", "=", "[", "self", ".", "task_name", "]", "+", "[", "'[CLS]'", "]", "+", "[", "'[SEP]'", "]", "+", "caption_tokens_en", "+", "[", "'[SEP]'", "]", "\n", "mlm_labels", "=", "[", "-", "1", "]", "+", "[", "-", "1", "]", "+", "[", "-", "1", "]", "+", "mlm_labels_en", "+", "[", "-", "1", "]", "\n", "\n", "# Task #3: Masked Visual Region Classification", "\n", "", "if", "self", ".", "with_mvrc_task", ":", "\n", "            ", "if", "self", ".", "add_image_as_a_box", ":", "\n", "                ", "mvrc_ops", ",", "mvrc_labels", "=", "self", ".", "random_mask_region", "(", "\n", "boxes_cls_scores", ")", "\n", "mvrc_ops", "=", "[", "0", "]", "+", "mvrc_ops", "\n", "mvrc_labels", "=", "[", "np", ".", "zeros_like", "(", "\n", "boxes_cls_scores", "[", "0", "]", ")", "]", "+", "mvrc_labels", "\n", "num_real_boxes", "=", "boxes", ".", "shape", "[", "0", "]", "-", "1", "\n", "num_masked_boxes", "=", "0", "\n", "if", "self", ".", "with_precomputed_visual_feat", ":", "\n", "                    ", "boxes_features", "[", "0", "]", "*=", "num_real_boxes", "\n", "for", "mvrc_op", ",", "box_feat", "in", "zip", "(", "mvrc_ops", ",", "boxes_features", ")", ":", "\n", "                        ", "if", "mvrc_op", "==", "1", ":", "\n", "                            ", "num_masked_boxes", "+=", "1", "\n", "boxes_features", "[", "0", "]", "-=", "box_feat", "\n", "", "", "boxes_features", "[", "0", "]", "/=", "(", "num_real_boxes", "-", "\n", "num_masked_boxes", "+", "1e-5", ")", "\n", "", "", "else", ":", "\n", "                ", "mvrc_ops", ",", "mvrc_labels", "=", "self", ".", "random_mask_region", "(", "\n", "boxes_cls_scores", ")", "\n", "", "assert", "len", "(", "mvrc_ops", ")", "==", "boxes", ".", "shape", "[", "0", "]", ",", "\"Error: mvrc_ops have length {}, expected {}!\"", ".", "format", "(", "\n", "len", "(", "mvrc_ops", ")", ",", "boxes", ".", "shape", "[", "0", "]", ")", "\n", "assert", "len", "(", "mvrc_labels", ")", "==", "boxes", ".", "shape", "[", "0", "]", ",", "\"Error: mvrc_labels have length {}, expected {}!\"", ".", "format", "(", "\n", "len", "(", "mvrc_labels", ")", ",", "boxes", ".", "shape", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "mvrc_ops", "=", "[", "0", "]", "*", "boxes", ".", "shape", "[", "0", "]", "\n", "mvrc_labels", "=", "[", "np", ".", "zeros_like", "(", "boxes_cls_scores", "[", "0", "]", ")", "]", "*", "boxes", ".", "shape", "[", "0", "]", "\n", "\n", "# zero out pixels of masked RoI", "\n", "", "if", "(", "not", "self", ".", "with_precomputed_visual_feat", ")", "and", "self", ".", "mask_raw_pixels", ":", "\n", "            ", "for", "mvrc_op", ",", "box", "in", "zip", "(", "mvrc_ops", ",", "boxes", ")", ":", "\n", "                ", "if", "mvrc_op", "==", "1", ":", "\n", "                    ", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "box", "\n", "image", "[", ":", ",", "int", "(", "y1", ")", ":", "(", "int", "(", "y2", ")", "+", "1", ")", ",", "int", "(", "x1", ")", ":", "(", "int", "(", "x2", ")", "+", "1", ")", "]", "=", "0", "\n", "\n", "# store labels for masked regions", "\n", "", "", "", "mvrc_labels", "=", "np", ".", "stack", "(", "mvrc_labels", ",", "axis", "=", "0", ")", "\n", "\n", "text", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "text_tokens", ")", "\n", "\n", "if", "self", ".", "with_precomputed_visual_feat", ":", "\n", "            ", "boxes", "=", "torch", ".", "cat", "(", "(", "boxes", ",", "boxes_features", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# truncate seq to max len", "\n", "", "if", "len", "(", "text", ")", "+", "len", "(", "boxes", ")", ">", "self", ".", "seq_len", ":", "\n", "            ", "text_len_keep", "=", "len", "(", "text", ")", "\n", "box_len_keep", "=", "len", "(", "boxes", ")", "\n", "while", "(", "text_len_keep", "+", "box_len_keep", ")", ">", "self", ".", "seq_len", "and", "(", "text_len_keep", ">", "0", ")", "and", "(", "box_len_keep", ">", "0", ")", ":", "\n", "                ", "if", "box_len_keep", ">", "text_len_keep", ":", "\n", "                    ", "box_len_keep", "-=", "1", "\n", "", "else", ":", "\n", "                    ", "text_len_keep", "-=", "1", "\n", "", "", "if", "text_len_keep", "<", "2", ":", "\n", "                ", "text_len_keep", "=", "2", "\n", "", "if", "box_len_keep", "<", "1", ":", "\n", "                ", "box_len_keep", "=", "1", "\n", "", "boxes", "=", "boxes", "[", ":", "box_len_keep", "]", "\n", "text", "=", "text", "[", ":", "(", "text_len_keep", "-", "1", ")", "]", "+", "[", "text", "[", "-", "1", "]", "]", "\n", "mlm_labels", "=", "mlm_labels", "[", ":", "(", "text_len_keep", "-", "1", ")", "]", "+", "[", "mlm_labels", "[", "-", "1", "]", "]", "\n", "mvrc_ops", "=", "mvrc_ops", "[", ":", "box_len_keep", "]", "\n", "mvrc_labels", "=", "mvrc_labels", "[", ":", "box_len_keep", "]", "\n", "\n", "", "return", "image", ",", "boxes", ",", "im_info", ",", "text", ",", "relationship_label", ",", "mlm_labels", ",", "mvrc_ops", ",", "mvrc_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only.Multi30kDatasetImageOnly.random_word_wwm": [[374, 419], ["enumerate", "multi30k_image_only.Multi30kDatasetImageOnly.tokenizer.wordpiece_tokenizer.tokenize", "random.random", "output_tokens.append", "output_tokens.append", "output_label.append", "output_label.append", "output_label.append", "logging.warning"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize"], ["", "def", "random_word_wwm", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "output_tokens", "=", "[", "]", "\n", "output_label", "=", "[", "]", "\n", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "            ", "sub_tokens", "=", "self", ".", "tokenizer", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", "\n", "prob", "=", "random", ".", "random", "(", ")", "\n", "# mask token with 15% probability", "\n", "if", "prob", "<", "0.15", ":", "\n", "# prob /= 0.15", "\n", "# FM edit: always leave as mask", "\n", "# 80% randomly change token to mask token", "\n", "# if prob < 0.8:", "\n", "                ", "for", "sub_token", "in", "sub_tokens", ":", "\n", "                    ", "output_tokens", ".", "append", "(", "\"[MASK]\"", ")", "\n", "# 10% randomly change token to random token", "\n", "# elif prob < 0.9:", "\n", "#     for sub_token in sub_tokens:", "\n", "#         output_tokens.append(random.choice(list(self.tokenizer.vocab.keys())))", "\n", "#         # -> rest 10% randomly keep current token", "\n", "# else:", "\n", "#     for sub_token in sub_tokens:", "\n", "#         output_tokens.append(sub_token)", "\n", "\n", "# append current token to output (we will predict these later)", "\n", "", "for", "sub_token", "in", "sub_tokens", ":", "\n", "                    ", "try", ":", "\n", "                        ", "output_label", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "sub_token", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "# For unknown words (should not occur with BPE vocab)", "\n", "                        ", "output_label", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "\"[UNK]\"", "]", ")", "\n", "logging", ".", "warning", "(", "\n", "\"Cannot find sub_token '{}' in vocab. Using [UNK] insetad\"", ".", "format", "(", "sub_token", ")", ")", "\n", "", "", "", "else", ":", "\n", "                ", "for", "sub_token", "in", "sub_tokens", ":", "\n", "# no masking token (will be ignored by loss function later)", "\n", "                    ", "output_tokens", ".", "append", "(", "sub_token", ")", "\n", "output_label", ".", "append", "(", "-", "1", ")", "\n", "\n", "# if no word masked, random choose a word to mask", "\n", "# if all([l_ == -1 for l_ in output_label]):", "\n", "#    choosed = random.randrange(0, len(output_label))", "\n", "#    output_label[choosed] = self.tokenizer.vocab[tokens[choosed]]", "\n", "\n", "", "", "", "return", "output_tokens", ",", "output_label", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only.Multi30kDatasetImageOnly.random_mask_region": [[420, 451], ["enumerate", "random.random", "output_label.append", "output_op.append", "output_label.append", "output_op.append", "output_op.append", "numpy.zeros_like"], "methods", ["None"], ["", "def", "random_mask_region", "(", "self", ",", "regions_cls_scores", ")", ":", "\n", "        ", "num_regions", ",", "num_classes", "=", "regions_cls_scores", ".", "shape", "\n", "output_op", "=", "[", "]", "\n", "output_label", "=", "[", "]", "\n", "for", "k", ",", "cls_scores", "in", "enumerate", "(", "regions_cls_scores", ")", ":", "\n", "            ", "prob", "=", "random", ".", "random", "(", ")", "\n", "# mask region with 15% probability", "\n", "if", "prob", "<", "0.15", ":", "\n", "                ", "prob", "/=", "0.15", "\n", "\n", "if", "prob", "<", "0.9", ":", "\n", "# 90% randomly replace appearance feature by \"MASK\"", "\n", "                    ", "output_op", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "# -> rest 10% randomly keep current appearance feature", "\n", "                    ", "output_op", ".", "append", "(", "0", ")", "\n", "\n", "# append class of region to output (we will predict these later)", "\n", "", "output_label", ".", "append", "(", "cls_scores", ")", "\n", "", "else", ":", "\n", "# no masking region (will be ignored by loss function later)", "\n", "                ", "output_op", ".", "append", "(", "0", ")", "\n", "output_label", ".", "append", "(", "np", ".", "zeros_like", "(", "cls_scores", ")", ")", "\n", "\n", "# # if no region masked, random choose a region to mask", "\n", "# if all([op == 0 for op in output_op]):", "\n", "#     choosed = random.randrange(0, len(output_op))", "\n", "#     output_op[choosed] = 1", "\n", "#     output_label[choosed] = regions_cls_scores[choosed]", "\n", "\n", "", "", "return", "output_op", ",", "output_label", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only.Multi30kDatasetImageOnly.b64_decode": [[452, 455], ["base64.decodebytes", "string.encode"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.encode"], ["", "@", "staticmethod", "\n", "def", "b64_decode", "(", "string", ")", ":", "\n", "        ", "return", "base64", ".", "decodebytes", "(", "string", ".", "encode", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only.Multi30kDatasetImageOnly.group_aspect": [[456, 475], ["print", "time.time", "torch.as_tensor", "torch.as_tensor", "torch.zeros", "print", "len", "time.time"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "group_aspect", "(", "database", ")", ":", "\n", "        ", "print", "(", "'grouping aspect...'", ")", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "\n", "# get shape of all images", "\n", "widths", "=", "torch", ".", "as_tensor", "(", "[", "idb", "[", "'width'", "]", "for", "idb", "in", "database", "]", ")", "\n", "heights", "=", "torch", ".", "as_tensor", "(", "[", "idb", "[", "'height'", "]", "for", "idb", "in", "database", "]", ")", "\n", "\n", "# group", "\n", "group_ids", "=", "torch", ".", "zeros", "(", "len", "(", "database", ")", ")", "\n", "horz", "=", "widths", ">=", "heights", "\n", "vert", "=", "1", "-", "horz", "\n", "group_ids", "[", "horz", "]", "=", "0", "\n", "group_ids", "[", "vert", "]", "=", "1", "\n", "\n", "print", "(", "'Done (t={:.2f}s)'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "\n", "return", "group_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only.Multi30kDatasetImageOnly.__len__": [[476, 478], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "database", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only.Multi30kDatasetImageOnly._load_image": [[479, 484], ["multi30k_image_only.Multi30kDatasetImageOnly.zipreader.imread().convert", "PIL.Image.open().convert", "multi30k_image_only.Multi30kDatasetImageOnly.zipreader.imread", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.imread"], ["", "def", "_load_image", "(", "self", ",", "path", ")", ":", "\n", "        ", "if", "'.zip@'", "in", "path", ":", "\n", "            ", "return", "self", ".", "zipreader", ".", "imread", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "", "else", ":", "\n", "            ", "return", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only.Multi30kDatasetImageOnly._load_json": [[485, 492], ["multi30k_image_only.Multi30kDatasetImageOnly.zipreader.read", "json.loads", "multi30k_image_only.Multi30kDatasetImageOnly.decode", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.decode"], ["", "", "def", "_load_json", "(", "self", ",", "path", ")", ":", "\n", "        ", "if", "'.zip@'", "in", "path", ":", "\n", "            ", "f", "=", "self", ".", "zipreader", ".", "read", "(", "path", ")", "\n", "return", "json", ".", "loads", "(", "f", ".", "decode", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "return", "json", ".", "load", "(", "f", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.__init__": [[22, 152], ["torch.utils.data.Dataset.__init__", "os.path.join", "os.path.join", "common.utils.zipreader.ZipReader", "list", "enumerate", "print", "os.path.exists", "common.utils.create_logger.makedirsExist", "external.pytorch_pretrained_bert.BertTokenizer.from_pretrained", "jsonlines.open", "enumerate", "idb[].replace", "idb[].replace", "print", "print", "print", "print", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.group_aspect", "idb[].replace().replace().replace().replace().replace", "idb[].replace", "[].split", "len", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.tokenizer.tokenize", "enumerate", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.database.append", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.tokenizer.tokenize", "enumerate", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.database.append", "idb[].replace().replace().replace().replace", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.database.append", "copy.deepcopy", "copy.deepcopy", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.database.append", "copy.deepcopy", "copy.deepcopy", "idb[].split", "copy.deepcopy", "copy.deepcopy", "idb[].replace().replace().replace", "idb[].replace().replace", "idb[].replace"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.create_logger.makedirsExist", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.from_pretrained", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.group_aspect", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize"], ["    ", "def", "__init__", "(", "self", ",", "ann_file", ",", "image_set", ",", "root_path", ",", "data_path", ",", "seq_len", "=", "64", ",", "\n", "with_precomputed_visual_feat", "=", "False", ",", "mask_raw_pixels", "=", "True", ",", "\n", "with_rel_task", "=", "True", ",", "with_mlm_task", "=", "True", ",", "with_mvrc_task", "=", "True", ",", "\n", "transform", "=", "None", ",", "test_mode", "=", "False", ",", "\n", "zip_mode", "=", "False", ",", "cache_mode", "=", "False", ",", "cache_db", "=", "False", ",", "ignore_db_cache", "=", "True", ",", "\n", "tokenizer", "=", "None", ",", "pretrained_model_name", "=", "None", ",", "\n", "add_image_as_a_box", "=", "False", ",", "\n", "aspect_grouping", "=", "False", ",", "task_name", "=", "\"None\"", ",", "lang", "=", "\"second\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Conceptual Captions Dataset\n\n        :param ann_file: annotation jsonl file\n        :param image_set: image folder name, e.g., 'vcr1images'\n        :param root_path: root path to cache database loaded from annotation file\n        :param data_path: path to vcr dataset\n        :param transform: transform\n        :param test_mode: test mode means no labels available\n        :param zip_mode: reading images and metadata in zip archive\n        :param cache_mode: cache whole dataset to RAM first, then __getitem__ read them from RAM\n        :param ignore_db_cache: ignore previous cached database, reload it from annotation file\n        :param tokenizer: default is BertTokenizer from pytorch_pretrained_bert\n        :param add_image_as_a_box: add whole image as a box\n        :param aspect_grouping: whether to group images via their aspect\n        :param kwargs:\n        \"\"\"", "\n", "super", "(", "Multi30kDatasetImageOnlyCOCO", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "not", "cache_mode", ",", "'currently not support cache mode!'", "\n", "# FM edit: commented out to allow testin", "\n", "# assert not test_mode", "\n", "\n", "annot", "=", "{", "'train'", ":", "'train_frcnn.json'", ",", "\n", "'val'", ":", "'val_frcnn.json'", ",", "\n", "'test2015'", ":", "'test_frcnn.json'", ",", "\n", "}", "\n", "\n", "self", ".", "seq_len", "=", "seq_len", "\n", "self", ".", "with_rel_task", "=", "with_rel_task", "\n", "self", ".", "with_mlm_task", "=", "with_mlm_task", "\n", "self", ".", "with_mvrc_task", "=", "with_mvrc_task", "\n", "self", ".", "data_path", "=", "data_path", "\n", "self", ".", "root_path", "=", "root_path", "\n", "self", ".", "ann_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "annot", "[", "image_set", "]", ")", "\n", "self", ".", "with_precomputed_visual_feat", "=", "with_precomputed_visual_feat", "\n", "self", ".", "mask_raw_pixels", "=", "mask_raw_pixels", "\n", "self", ".", "image_set", "=", "image_set", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "zip_mode", "=", "zip_mode", "\n", "self", ".", "cache_mode", "=", "cache_mode", "\n", "self", ".", "cache_db", "=", "cache_db", "\n", "self", ".", "ignore_db_cache", "=", "ignore_db_cache", "\n", "self", ".", "aspect_grouping", "=", "aspect_grouping", "\n", "self", ".", "cache_dir", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "'cache'", ")", "\n", "self", ".", "add_image_as_a_box", "=", "add_image_as_a_box", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "cache_dir", ")", ":", "\n", "            ", "makedirsExist", "(", "self", ".", "cache_dir", ")", "\n", "", "self", ".", "tokenizer", "=", "tokenizer", "if", "tokenizer", "is", "not", "None", "else", "BertTokenizer", ".", "from_pretrained", "(", "\n", "'bert-base-uncased'", "if", "pretrained_model_name", "is", "None", "else", "pretrained_model_name", ",", "\n", "cache_dir", "=", "self", ".", "cache_dir", ",", "do_lower_case", "=", "False", ")", "\n", "\n", "self", ".", "zipreader", "=", "ZipReader", "(", ")", "\n", "\n", "# FM: define task name to add prefix", "\n", "self", ".", "task_name", "=", "task_name", "\n", "self", ".", "lang", "=", "lang", "\n", "\n", "# FM: Customise for multi30k dataset", "\n", "self", ".", "simple_database", "=", "list", "(", "jsonlines", ".", "open", "(", "self", ".", "ann_file", ")", ")", "\n", "if", "not", "self", ".", "zip_mode", ":", "\n", "            ", "for", "i", ",", "idb", "in", "enumerate", "(", "self", ".", "simple_database", ")", ":", "\n", "                ", "self", ".", "simple_database", "[", "i", "]", "[", "'frcnn'", "]", "=", "idb", "[", "'frcnn'", "]", ".", "replace", "(", "'.zip@'", ",", "''", ")", ".", "replace", "(", "'.0'", ",", "''", ")", ".", "replace", "(", "'.1'", ",", "''", ")", ".", "replace", "(", "'.2'", ",", "''", ")", ".", "replace", "(", "'.3'", ",", "''", ")", "\n", "self", ".", "simple_database", "[", "i", "]", "[", "'image'", "]", "=", "idb", "[", "'image'", "]", ".", "replace", "(", "\n", "'.zip@'", ",", "''", ")", "\n", "\n", "# FM: TODO correct this", "\n", "", "", "for", "i", ",", "idb", "in", "enumerate", "(", "self", ".", "simple_database", ")", ":", "\n", "# correct address:", "\n", "            ", "idb", "[", "'frcnn'", "]", "=", "idb", "[", "'frcnn'", "]", ".", "replace", "(", "\n", "\"test_2016_flickr_frcnn.zip\"", ",", "\"test_frcnn.zip\"", ")", "\n", "old_id", "=", "idb", "[", "'frcnn'", "]", ".", "split", "(", "'/'", ")", "[", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "image_id", "=", "old_id", "\n", "self", ".", "simple_database", "[", "i", "]", "[", "'frcnn'", "]", "=", "idb", "[", "'frcnn'", "]", ".", "replace", "(", "\n", "old_id", ",", "image_id", ")", "\n", "\n", "", "if", "not", "self", ".", "test_mode", ":", "\n", "            ", "self", ".", "database", "=", "[", "]", "\n", "db_pos", "=", "0", "\n", "# create [MASK] every time", "\n", "for", "entry", "in", "self", ".", "simple_database", ":", "\n", "                ", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "                    ", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\n", "entry", "[", "'caption_de'", "]", ")", "\n", "# repeat each entry multiple times - MASK the last word in each case", "\n", "for", "pos", ",", "item", "in", "enumerate", "(", "caption_tokens_de", ")", ":", "\n", "                        ", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "entry", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_de'", "]", "=", "deepcopy", "(", "\n", "caption_tokens_de", "[", ":", "pos", "+", "1", "]", ")", "\n", "db_pos", "+=", "1", "\n", "# add one last entry with last token [STOP]", "\n", "", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "self", ".", "database", "[", "db_pos", "-", "1", "]", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_de'", "]", "=", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_de'", "]", "+", "[", "'[STOP]'", "]", "\n", "db_pos", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\n", "entry", "[", "'caption_en'", "]", ")", "\n", "# repeat each entry multiple times - MASK the last word in each case", "\n", "for", "pos", ",", "item", "in", "enumerate", "(", "caption_tokens_en", ")", ":", "\n", "                        ", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "entry", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_en'", "]", "=", "deepcopy", "(", "\n", "caption_tokens_en", "[", ":", "pos", "+", "1", "]", ")", "\n", "db_pos", "+=", "1", "\n", "# add one last entry with last token [STOP]", "\n", "", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "self", ".", "database", "[", "db_pos", "-", "1", "]", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_en'", "]", "=", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_en'", "]", "+", "[", "'[STOP]'", "]", "\n", "db_pos", "+=", "1", "\n", "", "", "print", "(", "'***********************'", ")", "\n", "print", "(", "'The dataset length is: '", ",", "len", "(", "self", ".", "database", ")", ")", "\n", "print", "(", "'Task: '", ",", "self", ".", "task_name", ")", "\n", "print", "(", "'Lang: '", ",", "self", ".", "lang", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "database", "=", "self", ".", "simple_database", "[", ":", ":", "5", "]", "\n", "\n", "", "if", "self", ".", "aspect_grouping", ":", "\n", "            ", "assert", "False", ",", "\"not support aspect grouping currently!\"", "\n", "self", ".", "group_ids", "=", "self", ".", "group_aspect", "(", "self", ".", "database", ")", "\n", "\n", "", "print", "(", "'mask_raw_pixels: '", ",", "self", ".", "mask_raw_pixels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.data_names": [[153, 157], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "data_names", "(", "self", ")", ":", "\n", "        ", "return", "[", "'image'", ",", "'boxes'", ",", "'im_info'", ",", "'text'", ",", "\n", "'relationship_label'", ",", "'mlm_labels'", ",", "'mvrc_ops'", ",", "'mvrc_labels'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.__getitem__": [[158, 365], ["multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO._load_json", "numpy.frombuffer().reshape", "numpy.ones", "numpy.ones.max", "torch.as_tensor", "torch.tensor", "im_info[].item", "im_info[].item", "boxes[].clamp", "boxes[].clamp", "random.random", "numpy.stack", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.tokenizer.convert_tokens_to_ids", "os.path.join", "numpy.argsort", "numpy.frombuffer().reshape", "torch.as_tensor", "torch.as_tensor", "torch.cat", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.transform", "int", "int", "torch.tensor.new_zeros", "random.randrange", "zip", "torch.cat", "len", "len", "numpy.frombuffer", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO._load_image", "torch.cat.mean", "torch.cat", "im_info[].item", "im_info[].item", "len", "random.randrange", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.tokenizer.tokenize", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.tokenizer.tokenize", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.random_mask_region", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.random_mask_region", "len", "len", "len", "len", "len", "len", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.b64_decode", "numpy.frombuffer", "os.path.join", "print", "len", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.tokenizer.tokenize", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.tokenizer.tokenize", "len", "len", "zip", "numpy.zeros_like", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.b64_decode", "mlm_labels_de.append", "mlm_labels_en.append", "numpy.zeros_like", "len", "mlm_labels_de.append", "logging.warning", "len", "mlm_labels_en.append", "logging.warning", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision._load_json", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision._load_image", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.random_mask_region", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.random_mask_region", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.b64_decode", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.b64_decode"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "idb", "=", "self", ".", "database", "[", "index", "]", "\n", "\n", "# image data", "\n", "# IN ALL CASES: boxes and cls scores are available for each image", "\n", "frcnn_data", "=", "self", ".", "_load_json", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "idb", "[", "'frcnn'", "]", ")", ")", "\n", "boxes", "=", "np", ".", "frombuffer", "(", "self", ".", "b64_decode", "(", "frcnn_data", "[", "'boxes'", "]", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "frcnn_data", "[", "'num_boxes'", "]", ",", "-", "1", ")", ")", "\n", "boxes_cls_scores", "=", "np", ".", "ones", "(", "(", "boxes", ".", "shape", "[", "0", "]", ",", "1601", ")", ")", "\n", "# boxes_cls_scores = np.frombuffer(self.b64_decode(frcnn_data['classes']),", "\n", "#                                  dtype=np.float32).reshape((frcnn_data['num_boxes'], -1))", "\n", "boxes_max_conf", "=", "boxes_cls_scores", ".", "max", "(", "axis", "=", "1", ")", "\n", "inds", "=", "np", ".", "argsort", "(", "boxes_max_conf", ")", "[", ":", ":", "-", "1", "]", "\n", "boxes", "=", "boxes", "[", "inds", "]", "\n", "boxes_cls_scores", "=", "boxes_cls_scores", "[", "inds", "]", "\n", "boxes", "=", "torch", ".", "as_tensor", "(", "boxes", ")", "\n", "\n", "# load precomputed features or the whole image depending on setup", "\n", "if", "self", ".", "with_precomputed_visual_feat", ":", "\n", "            ", "image", "=", "None", "\n", "w0", ",", "h0", "=", "frcnn_data", "[", "'image_w'", "]", ",", "frcnn_data", "[", "'image_h'", "]", "\n", "boxes_features", "=", "np", ".", "frombuffer", "(", "self", ".", "b64_decode", "(", "frcnn_data", "[", "'features'", "]", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "frcnn_data", "[", "'num_boxes'", "]", ",", "-", "1", ")", ")", "\n", "boxes_features", "=", "boxes_features", "[", "inds", "]", "\n", "boxes_features", "=", "torch", ".", "as_tensor", "(", "boxes_features", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "image", "=", "self", ".", "_load_image", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "idb", "[", "'image'", "]", ")", ")", "\n", "w0", ",", "h0", "=", "image", ".", "size", "\n", "", "except", ":", "\n", "                ", "print", "(", "\"Failed to load image {}, use zero image!\"", ".", "format", "(", "\n", "idb", "[", "'image'", "]", ")", ")", "\n", "image", "=", "None", "\n", "w0", ",", "h0", "=", "frcnn_data", "[", "'image_w'", "]", ",", "frcnn_data", "[", "'image_h'", "]", "\n", "\n", "# append whole image to tensor of boxes (used for all linguistic tokens)", "\n", "", "", "if", "self", ".", "add_image_as_a_box", ":", "\n", "            ", "image_box", "=", "torch", ".", "as_tensor", "(", "[", "[", "0.0", ",", "0.0", ",", "w0", "-", "1.0", ",", "h0", "-", "1.0", "]", "]", ")", "\n", "boxes", "=", "torch", ".", "cat", "(", "(", "image_box", ",", "boxes", ")", ",", "dim", "=", "0", ")", "\n", "if", "self", ".", "with_precomputed_visual_feat", ":", "\n", "                ", "image_box_feat", "=", "boxes_features", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "boxes_features", "=", "torch", ".", "cat", "(", "\n", "(", "image_box_feat", ",", "boxes_features", ")", ",", "dim", "=", "0", ")", "\n", "\n", "# transform", "\n", "", "", "im_info", "=", "torch", ".", "tensor", "(", "[", "w0", ",", "h0", ",", "1.0", ",", "1.0", ",", "index", "]", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "image", ",", "boxes", ",", "_", ",", "im_info", "=", "self", ".", "transform", "(", "\n", "image", ",", "boxes", ",", "None", ",", "im_info", ")", "\n", "\n", "", "if", "image", "is", "None", "and", "(", "not", "self", ".", "with_precomputed_visual_feat", ")", ":", "\n", "            ", "w", "=", "int", "(", "im_info", "[", "0", "]", ".", "item", "(", ")", ")", "\n", "h", "=", "int", "(", "im_info", "[", "1", "]", ".", "item", "(", ")", ")", "\n", "image", "=", "im_info", ".", "new_zeros", "(", "(", "3", ",", "h", ",", "w", ")", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "# clamp boxes", "\n", "", "w", "=", "im_info", "[", "0", "]", ".", "item", "(", ")", "\n", "h", "=", "im_info", "[", "1", "]", ".", "item", "(", ")", "\n", "boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "w", "-", "1", ")", "\n", "boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", "=", "boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "h", "-", "1", ")", "\n", "\n", "# Task #1: Caption-Image Relationship Prediction", "\n", "_p", "=", "random", ".", "random", "(", ")", "\n", "if", "_p", "<", "0.5", "or", "(", "not", "self", ".", "with_rel_task", ")", ":", "\n", "            ", "relationship_label", "=", "1", "\n", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "                ", "caption_de", "=", "idb", "[", "'caption_de'", "]", "\n", "", "else", ":", "\n", "                ", "caption_en", "=", "idb", "[", "'caption_en'", "]", "\n", "", "", "else", ":", "\n", "            ", "relationship_label", "=", "0", "\n", "rand_index", "=", "random", ".", "randrange", "(", "0", ",", "len", "(", "self", ".", "database", ")", ")", "\n", "while", "rand_index", "==", "index", ":", "\n", "                ", "rand_index", "=", "random", ".", "randrange", "(", "0", ",", "len", "(", "self", ".", "database", ")", ")", "\n", "", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "                ", "caption_de", "=", "self", ".", "database", "[", "rand_index", "]", "[", "'caption_de'", "]", "\n", "", "else", ":", "\n", "                ", "caption_en", "=", "self", ".", "database", "[", "rand_index", "]", "[", "'caption_en'", "]", "\n", "\n", "# Task #2: Masked Language Modeling - Adapted for two languages", "\n", "\n", "", "", "if", "self", ".", "with_mlm_task", ":", "\n", "            ", "if", "not", "self", ".", "test_mode", ":", "\n", "                ", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "# FM edit: Mask always the last token", "\n", "                    ", "caption_tokens_de", "=", "caption_de", "\n", "mlm_labels_de", "=", "[", "-", "1", "]", "*", "(", "len", "(", "caption_tokens_de", ")", "-", "1", ")", "\n", "try", ":", "\n", "                        ", "mlm_labels_de", ".", "append", "(", "\n", "self", ".", "tokenizer", ".", "vocab", "[", "caption_tokens_de", "[", "-", "1", "]", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "# For unknown words (should not occur with BPE vocab)", "\n", "                        ", "mlm_labels_de", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "\"[UNK]\"", "]", ")", "\n", "logging", ".", "warning", "(", "\n", "\"Cannot find sub_token '{}' in vocab. Using [UNK] insetad\"", ".", "format", "(", "sub_token", ")", ")", "\n", "", "caption_tokens_de", "[", "-", "1", "]", "=", "'[MASK]'", "\n", "", "else", ":", "\n", "# FM edit: Mask always the last token", "\n", "                    ", "caption_tokens_en", "=", "caption_en", "\n", "mlm_labels_en", "=", "[", "-", "1", "]", "*", "(", "len", "(", "caption_tokens_en", ")", "-", "1", ")", "\n", "try", ":", "\n", "                        ", "mlm_labels_en", ".", "append", "(", "\n", "self", ".", "tokenizer", ".", "vocab", "[", "caption_tokens_en", "[", "-", "1", "]", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "# For unknown words (should not occur with BPE vocab)", "\n", "                        ", "mlm_labels_en", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "\"[UNK]\"", "]", ")", "\n", "logging", ".", "warning", "(", "\n", "\"Cannot find sub_token '{}' in vocab. Using [UNK] insetad\"", ".", "format", "(", "sub_token", ")", ")", "\n", "", "caption_tokens_en", "[", "-", "1", "]", "=", "'[MASK]'", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "# FM edit: add [MASK] to start guessing caption", "\n", "                    ", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_de", ")", "\n", "# FM edit: add label from vocabulary", "\n", "mlm_labels_de", "=", "[", "103", "]", "+", "[", "-", "1", "]", "\n", "caption_tokens_de", "=", "[", "'[MASK]'", "]", "+", "[", "'[PAD]'", "]", "\n", "", "else", ":", "\n", "# FM edit: add [MASK] to start guessing caption", "\n", "                    ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_en", ")", "\n", "# FM edit: add label from vocabulary", "\n", "mlm_labels_en", "=", "[", "103", "]", "+", "[", "-", "1", "]", "\n", "caption_tokens_en", "=", "[", "'[MASK]'", "]", "+", "[", "'[PAD]'", "]", "\n", "", "", "", "else", ":", "\n", "            ", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "                ", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_de", ")", "\n", "mlm_labels_de", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_de", ")", "\n", "", "else", ":", "\n", "                ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_en", ")", "\n", "mlm_labels_en", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_en", ")", "\n", "\n", "", "", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "            ", "text_tokens", "=", "[", "self", ".", "task_name", "]", "+", "[", "'[CLS]'", "]", "+", "[", "'[SEP]'", "]", "+", "caption_tokens_de", "+", "[", "'[SEP]'", "]", "\n", "mlm_labels", "=", "[", "-", "1", "]", "+", "[", "-", "1", "]", "+", "[", "-", "1", "]", "+", "mlm_labels_de", "+", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "text_tokens", "=", "[", "self", ".", "task_name", "]", "+", "[", "'[CLS]'", "]", "+", "[", "'[SEP]'", "]", "+", "caption_tokens_en", "+", "[", "'[SEP]'", "]", "\n", "mlm_labels", "=", "[", "-", "1", "]", "+", "[", "-", "1", "]", "+", "[", "-", "1", "]", "+", "mlm_labels_en", "+", "[", "-", "1", "]", "\n", "\n", "# Task #3: Masked Visual Region Classification", "\n", "", "if", "self", ".", "with_mvrc_task", ":", "\n", "            ", "if", "self", ".", "add_image_as_a_box", ":", "\n", "                ", "mvrc_ops", ",", "mvrc_labels", "=", "self", ".", "random_mask_region", "(", "\n", "boxes_cls_scores", ")", "\n", "mvrc_ops", "=", "[", "0", "]", "+", "mvrc_ops", "\n", "mvrc_labels", "=", "[", "np", ".", "zeros_like", "(", "\n", "boxes_cls_scores", "[", "0", "]", ")", "]", "+", "mvrc_labels", "\n", "num_real_boxes", "=", "boxes", ".", "shape", "[", "0", "]", "-", "1", "\n", "num_masked_boxes", "=", "0", "\n", "if", "self", ".", "with_precomputed_visual_feat", ":", "\n", "                    ", "boxes_features", "[", "0", "]", "*=", "num_real_boxes", "\n", "for", "mvrc_op", ",", "box_feat", "in", "zip", "(", "mvrc_ops", ",", "boxes_features", ")", ":", "\n", "                        ", "if", "mvrc_op", "==", "1", ":", "\n", "                            ", "num_masked_boxes", "+=", "1", "\n", "boxes_features", "[", "0", "]", "-=", "box_feat", "\n", "", "", "boxes_features", "[", "0", "]", "/=", "(", "num_real_boxes", "-", "\n", "num_masked_boxes", "+", "1e-5", ")", "\n", "", "", "else", ":", "\n", "                ", "mvrc_ops", ",", "mvrc_labels", "=", "self", ".", "random_mask_region", "(", "\n", "boxes_cls_scores", ")", "\n", "", "assert", "len", "(", "mvrc_ops", ")", "==", "boxes", ".", "shape", "[", "0", "]", ",", "\"Error: mvrc_ops have length {}, expected {}!\"", ".", "format", "(", "\n", "len", "(", "mvrc_ops", ")", ",", "boxes", ".", "shape", "[", "0", "]", ")", "\n", "assert", "len", "(", "mvrc_labels", ")", "==", "boxes", ".", "shape", "[", "0", "]", ",", "\"Error: mvrc_labels have length {}, expected {}!\"", ".", "format", "(", "\n", "len", "(", "mvrc_labels", ")", ",", "boxes", ".", "shape", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "mvrc_ops", "=", "[", "0", "]", "*", "boxes", ".", "shape", "[", "0", "]", "\n", "mvrc_labels", "=", "[", "np", ".", "zeros_like", "(", "boxes_cls_scores", "[", "0", "]", ")", "]", "*", "boxes", ".", "shape", "[", "0", "]", "\n", "\n", "# zero out pixels of masked RoI", "\n", "", "if", "(", "not", "self", ".", "with_precomputed_visual_feat", ")", "and", "self", ".", "mask_raw_pixels", ":", "\n", "            ", "for", "mvrc_op", ",", "box", "in", "zip", "(", "mvrc_ops", ",", "boxes", ")", ":", "\n", "                ", "if", "mvrc_op", "==", "1", ":", "\n", "                    ", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "box", "\n", "image", "[", ":", ",", "int", "(", "y1", ")", ":", "(", "int", "(", "y2", ")", "+", "1", ")", ",", "int", "(", "x1", ")", ":", "(", "int", "(", "x2", ")", "+", "1", ")", "]", "=", "0", "\n", "\n", "# store labels for masked regions", "\n", "", "", "", "mvrc_labels", "=", "np", ".", "stack", "(", "mvrc_labels", ",", "axis", "=", "0", ")", "\n", "\n", "text", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "text_tokens", ")", "\n", "\n", "if", "self", ".", "with_precomputed_visual_feat", ":", "\n", "            ", "boxes", "=", "torch", ".", "cat", "(", "(", "boxes", ",", "boxes_features", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# truncate seq to max len", "\n", "", "if", "len", "(", "text", ")", "+", "len", "(", "boxes", ")", ">", "self", ".", "seq_len", ":", "\n", "            ", "text_len_keep", "=", "len", "(", "text", ")", "\n", "box_len_keep", "=", "len", "(", "boxes", ")", "\n", "while", "(", "text_len_keep", "+", "box_len_keep", ")", ">", "self", ".", "seq_len", "and", "(", "text_len_keep", ">", "0", ")", "and", "(", "box_len_keep", ">", "0", ")", ":", "\n", "                ", "if", "box_len_keep", ">", "text_len_keep", ":", "\n", "                    ", "box_len_keep", "-=", "1", "\n", "", "else", ":", "\n", "                    ", "text_len_keep", "-=", "1", "\n", "", "", "if", "text_len_keep", "<", "2", ":", "\n", "                ", "text_len_keep", "=", "2", "\n", "", "if", "box_len_keep", "<", "1", ":", "\n", "                ", "box_len_keep", "=", "1", "\n", "", "boxes", "=", "boxes", "[", ":", "box_len_keep", "]", "\n", "text", "=", "text", "[", ":", "(", "text_len_keep", "-", "1", ")", "]", "+", "[", "text", "[", "-", "1", "]", "]", "\n", "mlm_labels", "=", "mlm_labels", "[", ":", "(", "text_len_keep", "-", "1", ")", "]", "+", "[", "mlm_labels", "[", "-", "1", "]", "]", "\n", "mvrc_ops", "=", "mvrc_ops", "[", ":", "box_len_keep", "]", "\n", "mvrc_labels", "=", "mvrc_labels", "[", ":", "box_len_keep", "]", "\n", "\n", "", "return", "image", ",", "boxes", ",", "im_info", ",", "text", ",", "relationship_label", ",", "mlm_labels", ",", "mvrc_ops", ",", "mvrc_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.random_word_wwm": [[366, 411], ["enumerate", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.tokenizer.wordpiece_tokenizer.tokenize", "random.random", "output_tokens.append", "output_tokens.append", "output_label.append", "output_label.append", "output_label.append", "logging.warning"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize"], ["", "def", "random_word_wwm", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "output_tokens", "=", "[", "]", "\n", "output_label", "=", "[", "]", "\n", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "            ", "sub_tokens", "=", "self", ".", "tokenizer", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", "\n", "prob", "=", "random", ".", "random", "(", ")", "\n", "# mask token with 15% probability", "\n", "if", "prob", "<", "0.15", ":", "\n", "# prob /= 0.15", "\n", "# FM edit: always leave as mask", "\n", "# 80% randomly change token to mask token", "\n", "# if prob < 0.8:", "\n", "                ", "for", "sub_token", "in", "sub_tokens", ":", "\n", "                    ", "output_tokens", ".", "append", "(", "\"[MASK]\"", ")", "\n", "# 10% randomly change token to random token", "\n", "# elif prob < 0.9:", "\n", "#     for sub_token in sub_tokens:", "\n", "#         output_tokens.append(random.choice(list(self.tokenizer.vocab.keys())))", "\n", "#         # -> rest 10% randomly keep current token", "\n", "# else:", "\n", "#     for sub_token in sub_tokens:", "\n", "#         output_tokens.append(sub_token)", "\n", "\n", "# append current token to output (we will predict these later)", "\n", "", "for", "sub_token", "in", "sub_tokens", ":", "\n", "                    ", "try", ":", "\n", "                        ", "output_label", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "sub_token", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "# For unknown words (should not occur with BPE vocab)", "\n", "                        ", "output_label", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "\"[UNK]\"", "]", ")", "\n", "logging", ".", "warning", "(", "\n", "\"Cannot find sub_token '{}' in vocab. Using [UNK] insetad\"", ".", "format", "(", "sub_token", ")", ")", "\n", "", "", "", "else", ":", "\n", "                ", "for", "sub_token", "in", "sub_tokens", ":", "\n", "# no masking token (will be ignored by loss function later)", "\n", "                    ", "output_tokens", ".", "append", "(", "sub_token", ")", "\n", "output_label", ".", "append", "(", "-", "1", ")", "\n", "\n", "# if no word masked, random choose a word to mask", "\n", "# if all([l_ == -1 for l_ in output_label]):", "\n", "#    choosed = random.randrange(0, len(output_label))", "\n", "#    output_label[choosed] = self.tokenizer.vocab[tokens[choosed]]", "\n", "\n", "", "", "", "return", "output_tokens", ",", "output_label", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.random_mask_region": [[412, 443], ["enumerate", "random.random", "output_label.append", "output_op.append", "output_label.append", "output_op.append", "output_op.append", "numpy.zeros_like"], "methods", ["None"], ["", "def", "random_mask_region", "(", "self", ",", "regions_cls_scores", ")", ":", "\n", "        ", "num_regions", ",", "num_classes", "=", "regions_cls_scores", ".", "shape", "\n", "output_op", "=", "[", "]", "\n", "output_label", "=", "[", "]", "\n", "for", "k", ",", "cls_scores", "in", "enumerate", "(", "regions_cls_scores", ")", ":", "\n", "            ", "prob", "=", "random", ".", "random", "(", ")", "\n", "# mask region with 15% probability", "\n", "if", "prob", "<", "0.15", ":", "\n", "                ", "prob", "/=", "0.15", "\n", "\n", "if", "prob", "<", "0.9", ":", "\n", "# 90% randomly replace appearance feature by \"MASK\"", "\n", "                    ", "output_op", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "# -> rest 10% randomly keep current appearance feature", "\n", "                    ", "output_op", ".", "append", "(", "0", ")", "\n", "\n", "# append class of region to output (we will predict these later)", "\n", "", "output_label", ".", "append", "(", "cls_scores", ")", "\n", "", "else", ":", "\n", "# no masking region (will be ignored by loss function later)", "\n", "                ", "output_op", ".", "append", "(", "0", ")", "\n", "output_label", ".", "append", "(", "np", ".", "zeros_like", "(", "cls_scores", ")", ")", "\n", "\n", "# # if no region masked, random choose a region to mask", "\n", "# if all([op == 0 for op in output_op]):", "\n", "#     choosed = random.randrange(0, len(output_op))", "\n", "#     output_op[choosed] = 1", "\n", "#     output_label[choosed] = regions_cls_scores[choosed]", "\n", "\n", "", "", "return", "output_op", ",", "output_label", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.b64_decode": [[444, 447], ["base64.decodebytes", "string.encode"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.encode"], ["", "@", "staticmethod", "\n", "def", "b64_decode", "(", "string", ")", ":", "\n", "        ", "return", "base64", ".", "decodebytes", "(", "string", ".", "encode", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.group_aspect": [[448, 467], ["print", "time.time", "torch.as_tensor", "torch.as_tensor", "torch.zeros", "print", "len", "time.time"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "group_aspect", "(", "database", ")", ":", "\n", "        ", "print", "(", "'grouping aspect...'", ")", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "\n", "# get shape of all images", "\n", "widths", "=", "torch", ".", "as_tensor", "(", "[", "idb", "[", "'width'", "]", "for", "idb", "in", "database", "]", ")", "\n", "heights", "=", "torch", ".", "as_tensor", "(", "[", "idb", "[", "'height'", "]", "for", "idb", "in", "database", "]", ")", "\n", "\n", "# group", "\n", "group_ids", "=", "torch", ".", "zeros", "(", "len", "(", "database", ")", ")", "\n", "horz", "=", "widths", ">=", "heights", "\n", "vert", "=", "1", "-", "horz", "\n", "group_ids", "[", "horz", "]", "=", "0", "\n", "group_ids", "[", "vert", "]", "=", "1", "\n", "\n", "print", "(", "'Done (t={:.2f}s)'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "\n", "return", "group_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.__len__": [[468, 470], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "database", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO._load_image": [[471, 476], ["multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.zipreader.imread().convert", "PIL.Image.open().convert", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.zipreader.imread", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.imread"], ["", "def", "_load_image", "(", "self", ",", "path", ")", ":", "\n", "        ", "if", "'.zip@'", "in", "path", ":", "\n", "            ", "return", "self", ".", "zipreader", ".", "imread", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "", "else", ":", "\n", "            ", "return", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO._load_json": [[477, 484], ["multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.zipreader.read", "json.loads", "multi30k_image_only_COCO.Multi30kDatasetImageOnlyCOCO.decode", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.decode"], ["", "", "def", "_load_json", "(", "self", ",", "path", ")", ":", "\n", "        ", "if", "'.zip@'", "in", "path", ":", "\n", "            ", "f", "=", "self", ".", "zipreader", ".", "read", "(", "path", ")", "\n", "return", "json", ".", "loads", "(", "f", ".", "decode", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "return", "json", ".", "load", "(", "f", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_5x.Multi30kDatasetImageOnly5x.__init__": [[21, 116], ["torch.utils.data.Dataset.__init__", "os.path.join", "os.path.join", "common.utils.zipreader.ZipReader", "list", "print", "os.path.exists", "common.utils.create_logger.makedirsExist", "external.pytorch_pretrained_bert.BertTokenizer.from_pretrained", "jsonlines.open", "enumerate", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.group_aspect", "idb[].replace().replace().replace().replace().replace", "idb[].replace", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.tokenizer.tokenize", "enumerate", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.database.append", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.database.append", "copy.deepcopy", "copy.deepcopy", "idb[].replace().replace().replace().replace", "copy.deepcopy", "idb[].replace().replace().replace", "idb[].replace().replace", "idb[].replace"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.create_logger.makedirsExist", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.from_pretrained", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.group_aspect", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize"], ["    ", "def", "__init__", "(", "self", ",", "ann_file", ",", "image_set", ",", "root_path", ",", "data_path", ",", "seq_len", "=", "64", ",", "\n", "with_precomputed_visual_feat", "=", "False", ",", "mask_raw_pixels", "=", "True", ",", "\n", "with_rel_task", "=", "True", ",", "with_mlm_task", "=", "True", ",", "with_mvrc_task", "=", "True", ",", "\n", "transform", "=", "None", ",", "test_mode", "=", "False", ",", "\n", "zip_mode", "=", "False", ",", "cache_mode", "=", "False", ",", "cache_db", "=", "False", ",", "ignore_db_cache", "=", "True", ",", "\n", "tokenizer", "=", "None", ",", "pretrained_model_name", "=", "None", ",", "\n", "add_image_as_a_box", "=", "False", ",", "\n", "aspect_grouping", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Conceptual Captions Dataset\n\n        :param ann_file: annotation jsonl file\n        :param image_set: image folder name, e.g., 'vcr1images'\n        :param root_path: root path to cache database loaded from annotation file\n        :param data_path: path to vcr dataset\n        :param transform: transform\n        :param test_mode: test mode means no labels available\n        :param zip_mode: reading images and metadata in zip archive\n        :param cache_mode: cache whole dataset to RAM first, then __getitem__ read them from RAM\n        :param ignore_db_cache: ignore previous cached database, reload it from annotation file\n        :param tokenizer: default is BertTokenizer from pytorch_pretrained_bert\n        :param add_image_as_a_box: add whole image as a box\n        :param aspect_grouping: whether to group images via their aspect\n        :param kwargs:\n        \"\"\"", "\n", "super", "(", "Multi30kDatasetImageOnly5x", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "not", "cache_mode", ",", "'currently not support cache mode!'", "\n", "# FM edit: commented out to allow testin", "\n", "# assert not test_mode", "\n", "\n", "annot", "=", "{", "'train'", ":", "'train_frcnn_5captions_both.json'", ",", "\n", "'val'", ":", "'val_frcnn.json'", ",", "\n", "'test2015'", ":", "'test_frcnn.json'", ",", "\n", "'test2018'", ":", "'test_frcnn2018.json'", "}", "\n", "\n", "self", ".", "seq_len", "=", "seq_len", "\n", "self", ".", "with_rel_task", "=", "with_rel_task", "\n", "self", ".", "with_mlm_task", "=", "with_mlm_task", "\n", "self", ".", "with_mvrc_task", "=", "with_mvrc_task", "\n", "self", ".", "data_path", "=", "data_path", "\n", "self", ".", "root_path", "=", "root_path", "\n", "self", ".", "ann_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "annot", "[", "image_set", "]", ")", "\n", "self", ".", "with_precomputed_visual_feat", "=", "with_precomputed_visual_feat", "\n", "self", ".", "mask_raw_pixels", "=", "mask_raw_pixels", "\n", "self", ".", "image_set", "=", "image_set", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "zip_mode", "=", "zip_mode", "\n", "self", ".", "cache_mode", "=", "cache_mode", "\n", "self", ".", "cache_db", "=", "cache_db", "\n", "self", ".", "ignore_db_cache", "=", "ignore_db_cache", "\n", "self", ".", "aspect_grouping", "=", "aspect_grouping", "\n", "self", ".", "cache_dir", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "'cache'", ")", "\n", "self", ".", "add_image_as_a_box", "=", "add_image_as_a_box", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "cache_dir", ")", ":", "\n", "            ", "makedirsExist", "(", "self", ".", "cache_dir", ")", "\n", "", "self", ".", "tokenizer", "=", "tokenizer", "if", "tokenizer", "is", "not", "None", "else", "BertTokenizer", ".", "from_pretrained", "(", "\n", "'bert-base-uncased'", "if", "pretrained_model_name", "is", "None", "else", "pretrained_model_name", ",", "\n", "cache_dir", "=", "self", ".", "cache_dir", ")", "\n", "\n", "self", ".", "zipreader", "=", "ZipReader", "(", ")", "\n", "\n", "# FM: Customise for multi30k dataset", "\n", "self", ".", "simple_database", "=", "list", "(", "jsonlines", ".", "open", "(", "self", ".", "ann_file", ")", ")", "\n", "if", "not", "self", ".", "zip_mode", ":", "\n", "            ", "for", "i", ",", "idb", "in", "enumerate", "(", "self", ".", "simple_database", ")", ":", "\n", "                ", "self", ".", "simple_database", "[", "i", "]", "[", "'frcnn'", "]", "=", "idb", "[", "'frcnn'", "]", ".", "replace", "(", "'.zip@'", ",", "''", ")", ".", "replace", "(", "'.0'", ",", "''", ")", ".", "replace", "(", "'.1'", ",", "''", ")", ".", "replace", "(", "'.2'", ",", "''", ")", ".", "replace", "(", "'.3'", ",", "''", ")", "\n", "self", ".", "simple_database", "[", "i", "]", "[", "'image'", "]", "=", "idb", "[", "'image'", "]", ".", "replace", "(", "'.zip@'", ",", "''", ")", "\n", "\n", "", "", "if", "not", "self", ".", "test_mode", ":", "\n", "            ", "self", ".", "database", "=", "[", "]", "\n", "db_pos", "=", "0", "\n", "# create [MASK] every time", "\n", "for", "entry", "in", "self", ".", "simple_database", ":", "\n", "                ", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "entry", "[", "'caption_de'", "]", ")", "\n", "# repeat each entry multiple times - MASK the last word in each case", "\n", "for", "pos", ",", "item", "in", "enumerate", "(", "caption_tokens_de", ")", ":", "\n", "                    ", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "entry", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_de'", "]", "=", "deepcopy", "(", "caption_tokens_de", "[", ":", "pos", "+", "1", "]", ")", "\n", "db_pos", "+=", "1", "\n", "# add one last entry with last token [STOP]", "\n", "", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "self", ".", "database", "[", "db_pos", "-", "1", "]", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_de'", "]", "=", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_de'", "]", "+", "[", "'[STOP]'", "]", "\n", "db_pos", "+=", "1", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "database", "=", "self", ".", "simple_database", "\n", "\n", "", "if", "self", ".", "aspect_grouping", ":", "\n", "            ", "assert", "False", ",", "\"not support aspect grouping currently!\"", "\n", "self", ".", "group_ids", "=", "self", ".", "group_aspect", "(", "self", ".", "database", ")", "\n", "\n", "", "print", "(", "'mask_raw_pixels: '", ",", "self", ".", "mask_raw_pixels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_5x.Multi30kDatasetImageOnly5x.data_names": [[117, 121], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "data_names", "(", "self", ")", ":", "\n", "        ", "return", "[", "'image'", ",", "'boxes'", ",", "'im_info'", ",", "'text'", ",", "\n", "'relationship_label'", ",", "'mlm_labels'", ",", "'mvrc_ops'", ",", "'mvrc_labels'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_5x.Multi30kDatasetImageOnly5x.__getitem__": [[122, 289], ["multi30k_image_only_5x.Multi30kDatasetImageOnly5x._load_json", "numpy.frombuffer().reshape", "numpy.frombuffer().reshape", "numpy.frombuffer().reshape.max", "torch.as_tensor", "torch.tensor", "im_info[].item", "im_info[].item", "boxes[].clamp", "boxes[].clamp", "random.random", "numpy.stack", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.tokenizer.convert_tokens_to_ids", "os.path.join", "numpy.argsort", "numpy.frombuffer().reshape", "torch.as_tensor", "torch.as_tensor", "torch.cat", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.transform", "int", "int", "torch.tensor.new_zeros", "random.randrange", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.tokenizer.tokenize", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.tokenizer.tokenize", "zip", "torch.cat", "len", "len", "numpy.frombuffer", "numpy.frombuffer", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x._load_image", "torch.cat.mean", "torch.cat", "im_info[].item", "im_info[].item", "len", "random.randrange", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.tokenizer.tokenize", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.tokenizer.tokenize", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.tokenizer.tokenize", "len", "len", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.random_mask_region", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.random_mask_region", "len", "len", "len", "len", "len", "len", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.b64_decode", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.b64_decode", "numpy.frombuffer", "os.path.join", "print", "len", "len", "mlm_labels_de.append", "len", "zip", "numpy.zeros_like", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.b64_decode", "len", "mlm_labels_de.append", "logging.warning", "numpy.zeros_like", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision._load_json", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision._load_image", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.random_mask_region", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.random_mask_region", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.b64_decode", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.b64_decode", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.b64_decode"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "idb", "=", "self", ".", "database", "[", "index", "]", "\n", "\n", "# image data", "\n", "# IN ALL CASES: boxes and cls scores are available for each image", "\n", "frcnn_data", "=", "self", ".", "_load_json", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "idb", "[", "'frcnn'", "]", ")", ")", "\n", "boxes", "=", "np", ".", "frombuffer", "(", "self", ".", "b64_decode", "(", "frcnn_data", "[", "'boxes'", "]", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "frcnn_data", "[", "'num_boxes'", "]", ",", "-", "1", ")", ")", "\n", "boxes_cls_scores", "=", "np", ".", "frombuffer", "(", "self", ".", "b64_decode", "(", "frcnn_data", "[", "'classes'", "]", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "frcnn_data", "[", "'num_boxes'", "]", ",", "-", "1", ")", ")", "\n", "boxes_max_conf", "=", "boxes_cls_scores", ".", "max", "(", "axis", "=", "1", ")", "\n", "inds", "=", "np", ".", "argsort", "(", "boxes_max_conf", ")", "[", ":", ":", "-", "1", "]", "\n", "boxes", "=", "boxes", "[", "inds", "]", "\n", "boxes_cls_scores", "=", "boxes_cls_scores", "[", "inds", "]", "\n", "boxes", "=", "torch", ".", "as_tensor", "(", "boxes", ")", "\n", "\n", "# load precomputed features or the whole image depending on setup", "\n", "if", "self", ".", "with_precomputed_visual_feat", ":", "\n", "            ", "image", "=", "None", "\n", "w0", ",", "h0", "=", "frcnn_data", "[", "'image_w'", "]", ",", "frcnn_data", "[", "'image_h'", "]", "\n", "boxes_features", "=", "np", ".", "frombuffer", "(", "self", ".", "b64_decode", "(", "frcnn_data", "[", "'features'", "]", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "frcnn_data", "[", "'num_boxes'", "]", ",", "-", "1", ")", ")", "\n", "boxes_features", "=", "boxes_features", "[", "inds", "]", "\n", "boxes_features", "=", "torch", ".", "as_tensor", "(", "boxes_features", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "image", "=", "self", ".", "_load_image", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "idb", "[", "'image'", "]", ")", ")", "\n", "w0", ",", "h0", "=", "image", ".", "size", "\n", "", "except", ":", "\n", "                ", "print", "(", "\"Failed to load image {}, use zero image!\"", ".", "format", "(", "idb", "[", "'image'", "]", ")", ")", "\n", "image", "=", "None", "\n", "w0", ",", "h0", "=", "frcnn_data", "[", "'image_w'", "]", ",", "frcnn_data", "[", "'image_h'", "]", "\n", "\n", "# append whole image to tensor of boxes (used for all linguistic tokens)", "\n", "", "", "if", "self", ".", "add_image_as_a_box", ":", "\n", "            ", "image_box", "=", "torch", ".", "as_tensor", "(", "[", "[", "0.0", ",", "0.0", ",", "w0", "-", "1.0", ",", "h0", "-", "1.0", "]", "]", ")", "\n", "boxes", "=", "torch", ".", "cat", "(", "(", "image_box", ",", "boxes", ")", ",", "dim", "=", "0", ")", "\n", "if", "self", ".", "with_precomputed_visual_feat", ":", "\n", "                ", "image_box_feat", "=", "boxes_features", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "boxes_features", "=", "torch", ".", "cat", "(", "(", "image_box_feat", ",", "boxes_features", ")", ",", "dim", "=", "0", ")", "\n", "\n", "# transform", "\n", "", "", "im_info", "=", "torch", ".", "tensor", "(", "[", "w0", ",", "h0", ",", "1.0", ",", "1.0", ",", "index", "]", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "image", ",", "boxes", ",", "_", ",", "im_info", "=", "self", ".", "transform", "(", "image", ",", "boxes", ",", "None", ",", "im_info", ")", "\n", "\n", "", "if", "image", "is", "None", "and", "(", "not", "self", ".", "with_precomputed_visual_feat", ")", ":", "\n", "            ", "w", "=", "int", "(", "im_info", "[", "0", "]", ".", "item", "(", ")", ")", "\n", "h", "=", "int", "(", "im_info", "[", "1", "]", ".", "item", "(", ")", ")", "\n", "image", "=", "im_info", ".", "new_zeros", "(", "(", "3", ",", "h", ",", "w", ")", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "# clamp boxes", "\n", "", "w", "=", "im_info", "[", "0", "]", ".", "item", "(", ")", "\n", "h", "=", "im_info", "[", "1", "]", ".", "item", "(", ")", "\n", "boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "w", "-", "1", ")", "\n", "boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", "=", "boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "h", "-", "1", ")", "\n", "\n", "# Task #1: Caption-Image Relationship Prediction", "\n", "_p", "=", "random", ".", "random", "(", ")", "\n", "if", "_p", "<", "0.5", "or", "(", "not", "self", ".", "with_rel_task", ")", ":", "\n", "            ", "relationship_label", "=", "1", "\n", "caption_en", "=", "idb", "[", "'caption_en'", "]", "\n", "caption_de", "=", "idb", "[", "'caption_de'", "]", "\n", "", "else", ":", "\n", "            ", "relationship_label", "=", "0", "\n", "rand_index", "=", "random", ".", "randrange", "(", "0", ",", "len", "(", "self", ".", "database", ")", ")", "\n", "while", "rand_index", "==", "index", ":", "\n", "                ", "rand_index", "=", "random", ".", "randrange", "(", "0", ",", "len", "(", "self", ".", "database", ")", ")", "\n", "", "caption_en", "=", "self", ".", "database", "[", "rand_index", "]", "[", "'caption_en'", "]", "\n", "caption_de", "=", "self", ".", "database", "[", "rand_index", "]", "[", "'caption_de'", "]", "\n", "\n", "# Task #2: Masked Language Modeling - Adapted for two languages", "\n", "\n", "", "if", "self", ".", "with_mlm_task", ":", "\n", "            ", "if", "not", "self", ".", "test_mode", ":", "\n", "# FM: removing joining of caption - split into two languages", "\n", "                ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_en", ")", "\n", "mlm_labels_en", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_en", ")", "\n", "# FM edit: Mask always the last token", "\n", "caption_tokens_de", "=", "caption_de", "\n", "mlm_labels_de", "=", "[", "-", "1", "]", "*", "(", "len", "(", "caption_tokens_de", ")", "-", "1", ")", "\n", "try", ":", "\n", "                    ", "mlm_labels_de", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "caption_tokens_de", "[", "-", "1", "]", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "# For unknown words (should not occur with BPE vocab)", "\n", "                    ", "mlm_labels_de", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "\"[UNK]\"", "]", ")", "\n", "logging", ".", "warning", "(", "\"Cannot find sub_token '{}' in vocab. Using [UNK] insetad\"", ".", "format", "(", "sub_token", ")", ")", "\n", "", "caption_tokens_de", "[", "-", "1", "]", "=", "'[MASK]'", "\n", "", "else", ":", "\n", "# FM TODO: fix inference", "\n", "                ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_en", ")", "\n", "mlm_labels_en", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_en", ")", "\n", "# FM edit: add [MASK] to start guessing caption", "\n", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_de", ")", "\n", "# FM edit: add label from vocabulary                ", "\n", "mlm_labels_de", "=", "[", "103", "]", "+", "[", "-", "1", "]", "\n", "caption_tokens_de", "=", "[", "'[MASK]'", "]", "+", "[", "'[PAD]'", "]", "\n", "", "", "else", ":", "\n", "            ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_en", ")", "\n", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_de", ")", "\n", "mlm_labels_en", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_en", ")", "\n", "mlm_labels_de", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_de", ")", "\n", "\n", "# remove english caption altogether - image captioning task", "\n", "", "text_tokens", "=", "[", "'[CLS]'", "]", "+", "[", "'[SEP]'", "]", "+", "caption_tokens_de", "+", "[", "'[SEP]'", "]", "\n", "mlm_labels", "=", "[", "-", "1", "]", "+", "[", "-", "1", "]", "+", "mlm_labels_de", "+", "[", "-", "1", "]", "\n", "\n", "# Task #3: Masked Visual Region Classification", "\n", "if", "self", ".", "with_mvrc_task", ":", "\n", "            ", "if", "self", ".", "add_image_as_a_box", ":", "\n", "                ", "mvrc_ops", ",", "mvrc_labels", "=", "self", ".", "random_mask_region", "(", "boxes_cls_scores", ")", "\n", "mvrc_ops", "=", "[", "0", "]", "+", "mvrc_ops", "\n", "mvrc_labels", "=", "[", "np", ".", "zeros_like", "(", "boxes_cls_scores", "[", "0", "]", ")", "]", "+", "mvrc_labels", "\n", "num_real_boxes", "=", "boxes", ".", "shape", "[", "0", "]", "-", "1", "\n", "num_masked_boxes", "=", "0", "\n", "if", "self", ".", "with_precomputed_visual_feat", ":", "\n", "                    ", "boxes_features", "[", "0", "]", "*=", "num_real_boxes", "\n", "for", "mvrc_op", ",", "box_feat", "in", "zip", "(", "mvrc_ops", ",", "boxes_features", ")", ":", "\n", "                        ", "if", "mvrc_op", "==", "1", ":", "\n", "                            ", "num_masked_boxes", "+=", "1", "\n", "boxes_features", "[", "0", "]", "-=", "box_feat", "\n", "", "", "boxes_features", "[", "0", "]", "/=", "(", "num_real_boxes", "-", "num_masked_boxes", "+", "1e-5", ")", "\n", "", "", "else", ":", "\n", "                ", "mvrc_ops", ",", "mvrc_labels", "=", "self", ".", "random_mask_region", "(", "boxes_cls_scores", ")", "\n", "", "assert", "len", "(", "mvrc_ops", ")", "==", "boxes", ".", "shape", "[", "0", "]", ",", "\"Error: mvrc_ops have length {}, expected {}!\"", ".", "format", "(", "len", "(", "mvrc_ops", ")", ",", "boxes", ".", "shape", "[", "0", "]", ")", "\n", "assert", "len", "(", "mvrc_labels", ")", "==", "boxes", ".", "shape", "[", "0", "]", ",", "\"Error: mvrc_labels have length {}, expected {}!\"", ".", "format", "(", "len", "(", "mvrc_labels", ")", ",", "boxes", ".", "shape", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "mvrc_ops", "=", "[", "0", "]", "*", "boxes", ".", "shape", "[", "0", "]", "\n", "mvrc_labels", "=", "[", "np", ".", "zeros_like", "(", "boxes_cls_scores", "[", "0", "]", ")", "]", "*", "boxes", ".", "shape", "[", "0", "]", "\n", "\n", "# zero out pixels of masked RoI", "\n", "", "if", "(", "not", "self", ".", "with_precomputed_visual_feat", ")", "and", "self", ".", "mask_raw_pixels", ":", "\n", "            ", "for", "mvrc_op", ",", "box", "in", "zip", "(", "mvrc_ops", ",", "boxes", ")", ":", "\n", "                ", "if", "mvrc_op", "==", "1", ":", "\n", "                    ", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "box", "\n", "image", "[", ":", ",", "int", "(", "y1", ")", ":", "(", "int", "(", "y2", ")", "+", "1", ")", ",", "int", "(", "x1", ")", ":", "(", "int", "(", "x2", ")", "+", "1", ")", "]", "=", "0", "\n", "\n", "# store labels for masked regions", "\n", "", "", "", "mvrc_labels", "=", "np", ".", "stack", "(", "mvrc_labels", ",", "axis", "=", "0", ")", "\n", "\n", "text", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "text_tokens", ")", "\n", "\n", "if", "self", ".", "with_precomputed_visual_feat", ":", "\n", "            ", "boxes", "=", "torch", ".", "cat", "(", "(", "boxes", ",", "boxes_features", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# truncate seq to max len", "\n", "", "if", "len", "(", "text", ")", "+", "len", "(", "boxes", ")", ">", "self", ".", "seq_len", ":", "\n", "            ", "text_len_keep", "=", "len", "(", "text", ")", "\n", "box_len_keep", "=", "len", "(", "boxes", ")", "\n", "while", "(", "text_len_keep", "+", "box_len_keep", ")", ">", "self", ".", "seq_len", "and", "(", "text_len_keep", ">", "0", ")", "and", "(", "box_len_keep", ">", "0", ")", ":", "\n", "                ", "if", "box_len_keep", ">", "text_len_keep", ":", "\n", "                    ", "box_len_keep", "-=", "1", "\n", "", "else", ":", "\n", "                    ", "text_len_keep", "-=", "1", "\n", "", "", "if", "text_len_keep", "<", "2", ":", "\n", "                ", "text_len_keep", "=", "2", "\n", "", "if", "box_len_keep", "<", "1", ":", "\n", "                ", "box_len_keep", "=", "1", "\n", "", "boxes", "=", "boxes", "[", ":", "box_len_keep", "]", "\n", "text", "=", "text", "[", ":", "(", "text_len_keep", "-", "1", ")", "]", "+", "[", "text", "[", "-", "1", "]", "]", "\n", "mlm_labels", "=", "mlm_labels", "[", ":", "(", "text_len_keep", "-", "1", ")", "]", "+", "[", "mlm_labels", "[", "-", "1", "]", "]", "\n", "mvrc_ops", "=", "mvrc_ops", "[", ":", "box_len_keep", "]", "\n", "mvrc_labels", "=", "mvrc_labels", "[", ":", "box_len_keep", "]", "\n", "\n", "", "return", "image", ",", "boxes", ",", "im_info", ",", "text", ",", "relationship_label", ",", "mlm_labels", ",", "mvrc_ops", ",", "mvrc_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_5x.Multi30kDatasetImageOnly5x.random_word_wwm": [[290, 334], ["enumerate", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.tokenizer.wordpiece_tokenizer.tokenize", "random.random", "output_tokens.append", "output_tokens.append", "output_label.append", "output_label.append", "output_label.append", "logging.warning"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize"], ["", "def", "random_word_wwm", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "output_tokens", "=", "[", "]", "\n", "output_label", "=", "[", "]", "\n", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "            ", "sub_tokens", "=", "self", ".", "tokenizer", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", "\n", "prob", "=", "random", ".", "random", "(", ")", "\n", "# mask token with 15% probability", "\n", "if", "prob", "<", "0.15", ":", "\n", "# prob /= 0.15", "\n", "# FM edit: always leave as mask", "\n", "# 80% randomly change token to mask token", "\n", "# if prob < 0.8:", "\n", "                ", "for", "sub_token", "in", "sub_tokens", ":", "\n", "                    ", "output_tokens", ".", "append", "(", "\"[MASK]\"", ")", "\n", "# 10% randomly change token to random token", "\n", "# elif prob < 0.9:", "\n", "#     for sub_token in sub_tokens:", "\n", "#         output_tokens.append(random.choice(list(self.tokenizer.vocab.keys())))", "\n", "#         # -> rest 10% randomly keep current token", "\n", "# else:", "\n", "#     for sub_token in sub_tokens:", "\n", "#         output_tokens.append(sub_token)", "\n", "\n", "# append current token to output (we will predict these later)", "\n", "", "for", "sub_token", "in", "sub_tokens", ":", "\n", "                    ", "try", ":", "\n", "                        ", "output_label", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "sub_token", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "# For unknown words (should not occur with BPE vocab)", "\n", "                        ", "output_label", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "\"[UNK]\"", "]", ")", "\n", "logging", ".", "warning", "(", "\"Cannot find sub_token '{}' in vocab. Using [UNK] insetad\"", ".", "format", "(", "sub_token", ")", ")", "\n", "", "", "", "else", ":", "\n", "                ", "for", "sub_token", "in", "sub_tokens", ":", "\n", "# no masking token (will be ignored by loss function later)", "\n", "                    ", "output_tokens", ".", "append", "(", "sub_token", ")", "\n", "output_label", ".", "append", "(", "-", "1", ")", "\n", "\n", "## if no word masked, random choose a word to mask", "\n", "# if all([l_ == -1 for l_ in output_label]):", "\n", "#    choosed = random.randrange(0, len(output_label))", "\n", "#    output_label[choosed] = self.tokenizer.vocab[tokens[choosed]]", "\n", "\n", "", "", "", "return", "output_tokens", ",", "output_label", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_5x.Multi30kDatasetImageOnly5x.random_mask_region": [[335, 366], ["enumerate", "random.random", "output_label.append", "output_op.append", "output_label.append", "output_op.append", "output_op.append", "numpy.zeros_like"], "methods", ["None"], ["", "def", "random_mask_region", "(", "self", ",", "regions_cls_scores", ")", ":", "\n", "        ", "num_regions", ",", "num_classes", "=", "regions_cls_scores", ".", "shape", "\n", "output_op", "=", "[", "]", "\n", "output_label", "=", "[", "]", "\n", "for", "k", ",", "cls_scores", "in", "enumerate", "(", "regions_cls_scores", ")", ":", "\n", "            ", "prob", "=", "random", ".", "random", "(", ")", "\n", "# mask region with 15% probability", "\n", "if", "prob", "<", "0.15", ":", "\n", "                ", "prob", "/=", "0.15", "\n", "\n", "if", "prob", "<", "0.9", ":", "\n", "# 90% randomly replace appearance feature by \"MASK\"", "\n", "                    ", "output_op", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "# -> rest 10% randomly keep current appearance feature", "\n", "                    ", "output_op", ".", "append", "(", "0", ")", "\n", "\n", "# append class of region to output (we will predict these later)", "\n", "", "output_label", ".", "append", "(", "cls_scores", ")", "\n", "", "else", ":", "\n", "# no masking region (will be ignored by loss function later)", "\n", "                ", "output_op", ".", "append", "(", "0", ")", "\n", "output_label", ".", "append", "(", "np", ".", "zeros_like", "(", "cls_scores", ")", ")", "\n", "\n", "# # if no region masked, random choose a region to mask", "\n", "# if all([op == 0 for op in output_op]):", "\n", "#     choosed = random.randrange(0, len(output_op))", "\n", "#     output_op[choosed] = 1", "\n", "#     output_label[choosed] = regions_cls_scores[choosed]", "\n", "\n", "", "", "return", "output_op", ",", "output_label", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_5x.Multi30kDatasetImageOnly5x.b64_decode": [[367, 370], ["base64.decodebytes", "string.encode"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.encode"], ["", "@", "staticmethod", "\n", "def", "b64_decode", "(", "string", ")", ":", "\n", "        ", "return", "base64", ".", "decodebytes", "(", "string", ".", "encode", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_5x.Multi30kDatasetImageOnly5x.group_aspect": [[371, 390], ["print", "time.time", "torch.as_tensor", "torch.as_tensor", "torch.zeros", "print", "len", "time.time"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "group_aspect", "(", "database", ")", ":", "\n", "        ", "print", "(", "'grouping aspect...'", ")", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "\n", "# get shape of all images", "\n", "widths", "=", "torch", ".", "as_tensor", "(", "[", "idb", "[", "'width'", "]", "for", "idb", "in", "database", "]", ")", "\n", "heights", "=", "torch", ".", "as_tensor", "(", "[", "idb", "[", "'height'", "]", "for", "idb", "in", "database", "]", ")", "\n", "\n", "# group", "\n", "group_ids", "=", "torch", ".", "zeros", "(", "len", "(", "database", ")", ")", "\n", "horz", "=", "widths", ">=", "heights", "\n", "vert", "=", "1", "-", "horz", "\n", "group_ids", "[", "horz", "]", "=", "0", "\n", "group_ids", "[", "vert", "]", "=", "1", "\n", "\n", "print", "(", "'Done (t={:.2f}s)'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "\n", "return", "group_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_5x.Multi30kDatasetImageOnly5x.__len__": [[391, 393], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "database", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_5x.Multi30kDatasetImageOnly5x._load_image": [[394, 399], ["multi30k_image_only_5x.Multi30kDatasetImageOnly5x.zipreader.imread().convert", "PIL.Image.open().convert", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.zipreader.imread", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.imread"], ["", "def", "_load_image", "(", "self", ",", "path", ")", ":", "\n", "        ", "if", "'.zip@'", "in", "path", ":", "\n", "            ", "return", "self", ".", "zipreader", ".", "imread", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "", "else", ":", "\n", "            ", "return", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_image_only_5x.Multi30kDatasetImageOnly5x._load_json": [[400, 407], ["multi30k_image_only_5x.Multi30kDatasetImageOnly5x.zipreader.read", "json.loads", "multi30k_image_only_5x.Multi30kDatasetImageOnly5x.decode", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.decode"], ["", "", "def", "_load_json", "(", "self", ",", "path", ")", ":", "\n", "        ", "if", "'.zip@'", "in", "path", ":", "\n", "            ", "f", "=", "self", ".", "zipreader", ".", "read", "(", "path", ")", "\n", "return", "json", ".", "loads", "(", "f", ".", "decode", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "return", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k.Multi30kDataset.__init__": [[22, 157], ["torch.utils.data.Dataset.__init__", "os.path.join", "os.path.join", "common.utils.zipreader.ZipReader", "list", "enumerate", "print", "os.path.exists", "common.utils.create_logger.makedirsExist", "external.pytorch_pretrained_bert.BertTokenizer.from_pretrained", "jsonlines.open", "enumerate", "idb[].replace", "idb[].replace", "print", "print", "print", "print", "multi30k.Multi30kDataset.group_aspect", "idb[].replace().replace().replace().replace().replace", "idb[].replace", "[].split", "len", "len", "multi30k.Multi30kDataset.tokenizer.tokenize", "enumerate", "multi30k.Multi30kDataset.database.append", "multi30k.Multi30kDataset.tokenizer.tokenize", "enumerate", "multi30k.Multi30kDataset.database.append", "idb[].replace().replace().replace().replace", "multi30k.Multi30kDataset.database.append", "copy.deepcopy", "copy.deepcopy", "multi30k.Multi30kDataset.database.append", "copy.deepcopy", "copy.deepcopy", "idb[].split", "copy.deepcopy", "copy.deepcopy", "idb[].replace().replace().replace", "idb[].replace().replace", "idb[].replace"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.create_logger.makedirsExist", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.from_pretrained", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.group_aspect", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize"], ["    ", "def", "__init__", "(", "self", ",", "ann_file", ",", "image_set", ",", "root_path", ",", "data_path", ",", "seq_len", "=", "64", ",", "\n", "with_precomputed_visual_feat", "=", "False", ",", "mask_raw_pixels", "=", "True", ",", "\n", "with_rel_task", "=", "True", ",", "with_mlm_task", "=", "True", ",", "with_mvrc_task", "=", "True", ",", "\n", "transform", "=", "None", ",", "test_mode", "=", "False", ",", "\n", "zip_mode", "=", "False", ",", "cache_mode", "=", "False", ",", "cache_db", "=", "False", ",", "ignore_db_cache", "=", "True", ",", "\n", "tokenizer", "=", "None", ",", "pretrained_model_name", "=", "None", ",", "\n", "add_image_as_a_box", "=", "False", ",", "\n", "aspect_grouping", "=", "False", ",", "task_name", "=", "\"None\"", ",", "lang", "=", "\"second\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Conceptual Captions Dataset\n\n        :param ann_file: annotation jsonl file\n        :param image_set: image folder name, e.g., 'vcr1images'\n        :param root_path: root path to cache database loaded from annotation file\n        :param data_path: path to vcr dataset\n        :param transform: transform\n        :param test_mode: test mode means no labels available\n        :param zip_mode: reading images and metadata in zip archive\n        :param cache_mode: cache whole dataset to RAM first, then __getitem__ read them from RAM\n        :param ignore_db_cache: ignore previous cached database, reload it from annotation file\n        :param tokenizer: default is BertTokenizer from pytorch_pretrained_bert\n        :param add_image_as_a_box: add whole image as a box\n        :param aspect_grouping: whether to group images via their aspect\n        :param kwargs:\n        \"\"\"", "\n", "super", "(", "Multi30kDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "not", "cache_mode", ",", "'currently not support cache mode!'", "\n", "# FM edit: commented out to allow testin", "\n", "# assert not test_mode", "\n", "\n", "annot", "=", "{", "'train'", ":", "'train_frcnn.json'", ",", "\n", "'val'", ":", "'val_frcnn.json'", ",", "\n", "'valshuffled'", ":", "'val_frcnn_shuffled.json'", ",", "\n", "'test2015'", ":", "'test_frcnn.json'", ",", "\n", "'test2015shuffled1'", ":", "'test_frcnn_shuffled_1.json'", ",", "\n", "'test2015shuffled2'", ":", "'test_frcnn_shuffled_2.json'", ",", "\n", "}", "\n", "\n", "self", ".", "seq_len", "=", "seq_len", "\n", "self", ".", "with_rel_task", "=", "with_rel_task", "\n", "self", ".", "with_mlm_task", "=", "with_mlm_task", "\n", "self", ".", "with_mvrc_task", "=", "with_mvrc_task", "\n", "self", ".", "data_path", "=", "data_path", "\n", "self", ".", "root_path", "=", "root_path", "\n", "self", ".", "ann_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "annot", "[", "image_set", "]", ")", "\n", "self", ".", "with_precomputed_visual_feat", "=", "with_precomputed_visual_feat", "\n", "self", ".", "mask_raw_pixels", "=", "mask_raw_pixels", "\n", "self", ".", "image_set", "=", "image_set", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "zip_mode", "=", "zip_mode", "\n", "self", ".", "cache_mode", "=", "cache_mode", "\n", "self", ".", "cache_db", "=", "cache_db", "\n", "self", ".", "ignore_db_cache", "=", "ignore_db_cache", "\n", "self", ".", "aspect_grouping", "=", "aspect_grouping", "\n", "self", ".", "cache_dir", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "'cache'", ")", "\n", "self", ".", "add_image_as_a_box", "=", "add_image_as_a_box", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "cache_dir", ")", ":", "\n", "            ", "makedirsExist", "(", "self", ".", "cache_dir", ")", "\n", "", "self", ".", "tokenizer", "=", "tokenizer", "if", "tokenizer", "is", "not", "None", "else", "BertTokenizer", ".", "from_pretrained", "(", "\n", "'bert-base-uncased'", "if", "pretrained_model_name", "is", "None", "else", "pretrained_model_name", ",", "\n", "cache_dir", "=", "self", ".", "cache_dir", ",", "do_lower_case", "=", "False", ")", "\n", "\n", "self", ".", "zipreader", "=", "ZipReader", "(", ")", "\n", "\n", "# FM: define task name to add prefix", "\n", "self", ".", "task_name", "=", "task_name", "\n", "self", ".", "lang", "=", "lang", "\n", "\n", "# FM: Customise for multi30k dataset", "\n", "self", ".", "simple_database", "=", "list", "(", "jsonlines", ".", "open", "(", "self", ".", "ann_file", ")", ")", "\n", "if", "not", "self", ".", "zip_mode", ":", "\n", "            ", "for", "i", ",", "idb", "in", "enumerate", "(", "self", ".", "simple_database", ")", ":", "\n", "                ", "self", ".", "simple_database", "[", "i", "]", "[", "'frcnn'", "]", "=", "idb", "[", "'frcnn'", "]", ".", "replace", "(", "'.zip@'", ",", "''", ")", ".", "replace", "(", "'.0'", ",", "''", ")", ".", "replace", "(", "'.1'", ",", "''", ")", ".", "replace", "(", "'.2'", ",", "''", ")", ".", "replace", "(", "'.3'", ",", "''", ")", "\n", "self", ".", "simple_database", "[", "i", "]", "[", "'image'", "]", "=", "idb", "[", "'image'", "]", ".", "replace", "(", "\n", "'.zip@'", ",", "''", ")", "\n", "\n", "# FM: TODO correct this", "\n", "", "", "for", "i", ",", "idb", "in", "enumerate", "(", "self", ".", "simple_database", ")", ":", "\n", "# correct address:", "\n", "            ", "idb", "[", "'frcnn'", "]", "=", "idb", "[", "'frcnn'", "]", ".", "replace", "(", "\n", "\"test_2016_flickr_frcnn.zip\"", ",", "\"test_frcnn.zip\"", ")", "\n", "old_id", "=", "idb", "[", "'frcnn'", "]", ".", "split", "(", "'/'", ")", "[", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "image_id", "=", "old_id", "\n", "while", "len", "(", "image_id", ")", "<", "8", ":", "\n", "                ", "image_id", "=", "'0'", "+", "image_id", "\n", "", "self", ".", "simple_database", "[", "i", "]", "[", "'frcnn'", "]", "=", "idb", "[", "'frcnn'", "]", ".", "replace", "(", "\n", "old_id", ",", "image_id", ")", "\n", "\n", "", "if", "not", "self", ".", "test_mode", ":", "\n", "            ", "self", ".", "database", "=", "[", "]", "\n", "db_pos", "=", "0", "\n", "# create [MASK] every time", "\n", "for", "entry", "in", "self", ".", "simple_database", ":", "\n", "                ", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "                    ", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\n", "entry", "[", "'caption_de'", "]", ")", "\n", "# repeat each entry multiple times - MASK the last word in each case", "\n", "for", "pos", ",", "item", "in", "enumerate", "(", "caption_tokens_de", ")", ":", "\n", "                        ", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "entry", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_de'", "]", "=", "deepcopy", "(", "\n", "caption_tokens_de", "[", ":", "pos", "+", "1", "]", ")", "\n", "db_pos", "+=", "1", "\n", "# add one last entry with last token [STOP]", "\n", "", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "self", ".", "database", "[", "db_pos", "-", "1", "]", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_de'", "]", "=", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_de'", "]", "+", "[", "'[STOP]'", "]", "\n", "db_pos", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\n", "entry", "[", "'caption_en'", "]", ")", "\n", "# repeat each entry multiple times - MASK the last word in each case", "\n", "for", "pos", ",", "item", "in", "enumerate", "(", "caption_tokens_en", ")", ":", "\n", "                        ", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "entry", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_en'", "]", "=", "deepcopy", "(", "\n", "caption_tokens_en", "[", ":", "pos", "+", "1", "]", ")", "\n", "db_pos", "+=", "1", "\n", "# add one last entry with last token [STOP]", "\n", "", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "self", ".", "database", "[", "db_pos", "-", "1", "]", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_en'", "]", "=", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_en'", "]", "+", "[", "'[STOP]'", "]", "\n", "db_pos", "+=", "1", "\n", "", "", "print", "(", "'***********************'", ")", "\n", "print", "(", "'The dataset length is: '", ",", "len", "(", "self", ".", "database", ")", ")", "\n", "print", "(", "'Task: '", ",", "self", ".", "task_name", ")", "\n", "print", "(", "'Lang: '", ",", "self", ".", "lang", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "database", "=", "self", ".", "simple_database", "\n", "\n", "", "if", "self", ".", "aspect_grouping", ":", "\n", "            ", "assert", "False", ",", "\"not support aspect grouping currently!\"", "\n", "self", ".", "group_ids", "=", "self", ".", "group_aspect", "(", "self", ".", "database", ")", "\n", "\n", "", "print", "(", "'mask_raw_pixels: '", ",", "self", ".", "mask_raw_pixels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k.Multi30kDataset.data_names": [[158, 162], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "data_names", "(", "self", ")", ":", "\n", "        ", "return", "[", "'image'", ",", "'boxes'", ",", "'im_info'", ",", "'text'", ",", "\n", "'relationship_label'", ",", "'mlm_labels'", ",", "'mvrc_ops'", ",", "'mvrc_labels'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k.Multi30kDataset.__getitem__": [[163, 377], ["multi30k.Multi30kDataset._load_json", "numpy.frombuffer().reshape", "numpy.frombuffer().reshape", "numpy.frombuffer().reshape.max", "torch.as_tensor", "torch.tensor", "im_info[].item", "im_info[].item", "boxes[].clamp", "boxes[].clamp", "random.random", "numpy.stack", "multi30k.Multi30kDataset.tokenizer.convert_tokens_to_ids", "os.path.join", "numpy.argsort", "numpy.frombuffer().reshape", "torch.as_tensor", "torch.as_tensor", "torch.cat", "multi30k.Multi30kDataset.transform", "int", "int", "torch.tensor.new_zeros", "random.randrange", "multi30k.Multi30kDataset.tokenizer.tokenize", "multi30k.Multi30kDataset.tokenizer.tokenize", "zip", "torch.cat", "len", "len", "numpy.frombuffer", "numpy.frombuffer", "multi30k.Multi30kDataset._load_image", "torch.cat.mean", "torch.cat", "im_info[].item", "im_info[].item", "len", "random.randrange", "len", "len", "multi30k.Multi30kDataset.random_mask_region", "multi30k.Multi30kDataset.random_mask_region", "len", "len", "len", "len", "len", "len", "multi30k.Multi30kDataset.b64_decode", "multi30k.Multi30kDataset.b64_decode", "numpy.frombuffer", "os.path.join", "print", "len", "multi30k.Multi30kDataset.tokenizer.tokenize", "multi30k.Multi30kDataset.tokenizer.tokenize", "multi30k.Multi30kDataset.tokenizer.tokenize", "multi30k.Multi30kDataset.tokenizer.tokenize", "multi30k.Multi30kDataset.tokenizer.tokenize", "multi30k.Multi30kDataset.tokenizer.tokenize", "zip", "numpy.zeros_like", "multi30k.Multi30kDataset.b64_decode", "len", "mlm_labels_de.append", "len", "mlm_labels_en.append", "len", "len", "numpy.zeros_like", "len", "mlm_labels_de.append", "logging.warning", "len", "mlm_labels_en.append", "logging.warning", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision._load_json", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision._load_image", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.random_mask_region", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.random_mask_region", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.b64_decode", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.b64_decode", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.b64_decode"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "idb", "=", "self", ".", "database", "[", "index", "]", "\n", "\n", "# image data", "\n", "# IN ALL CASES: boxes and cls scores are available for each image", "\n", "frcnn_data", "=", "self", ".", "_load_json", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "idb", "[", "'frcnn'", "]", ")", ")", "\n", "boxes", "=", "np", ".", "frombuffer", "(", "self", ".", "b64_decode", "(", "frcnn_data", "[", "'boxes'", "]", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "frcnn_data", "[", "'num_boxes'", "]", ",", "-", "1", ")", ")", "\n", "boxes_cls_scores", "=", "np", ".", "frombuffer", "(", "self", ".", "b64_decode", "(", "frcnn_data", "[", "'classes'", "]", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "frcnn_data", "[", "'num_boxes'", "]", ",", "-", "1", ")", ")", "\n", "boxes_max_conf", "=", "boxes_cls_scores", ".", "max", "(", "axis", "=", "1", ")", "\n", "inds", "=", "np", ".", "argsort", "(", "boxes_max_conf", ")", "[", ":", ":", "-", "1", "]", "\n", "boxes", "=", "boxes", "[", "inds", "]", "\n", "boxes_cls_scores", "=", "boxes_cls_scores", "[", "inds", "]", "\n", "boxes", "=", "torch", ".", "as_tensor", "(", "boxes", ")", "\n", "\n", "# load precomputed features or the whole image depending on setup", "\n", "if", "self", ".", "with_precomputed_visual_feat", ":", "\n", "            ", "image", "=", "None", "\n", "w0", ",", "h0", "=", "frcnn_data", "[", "'image_w'", "]", ",", "frcnn_data", "[", "'image_h'", "]", "\n", "boxes_features", "=", "np", ".", "frombuffer", "(", "self", ".", "b64_decode", "(", "frcnn_data", "[", "'features'", "]", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "(", "frcnn_data", "[", "'num_boxes'", "]", ",", "-", "1", ")", ")", "\n", "boxes_features", "=", "boxes_features", "[", "inds", "]", "\n", "boxes_features", "=", "torch", ".", "as_tensor", "(", "boxes_features", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "image", "=", "self", ".", "_load_image", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "idb", "[", "'image'", "]", ")", ")", "\n", "w0", ",", "h0", "=", "image", ".", "size", "\n", "", "except", ":", "\n", "                ", "print", "(", "\"Failed to load image {}, use zero image!\"", ".", "format", "(", "\n", "idb", "[", "'image'", "]", ")", ")", "\n", "image", "=", "None", "\n", "w0", ",", "h0", "=", "frcnn_data", "[", "'image_w'", "]", ",", "frcnn_data", "[", "'image_h'", "]", "\n", "\n", "# append whole image to tensor of boxes (used for all linguistic tokens)", "\n", "", "", "if", "self", ".", "add_image_as_a_box", ":", "\n", "            ", "image_box", "=", "torch", ".", "as_tensor", "(", "[", "[", "0.0", ",", "0.0", ",", "w0", "-", "1.0", ",", "h0", "-", "1.0", "]", "]", ")", "\n", "boxes", "=", "torch", ".", "cat", "(", "(", "image_box", ",", "boxes", ")", ",", "dim", "=", "0", ")", "\n", "if", "self", ".", "with_precomputed_visual_feat", ":", "\n", "                ", "image_box_feat", "=", "boxes_features", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "boxes_features", "=", "torch", ".", "cat", "(", "\n", "(", "image_box_feat", ",", "boxes_features", ")", ",", "dim", "=", "0", ")", "\n", "\n", "# transform", "\n", "", "", "im_info", "=", "torch", ".", "tensor", "(", "[", "w0", ",", "h0", ",", "1.0", ",", "1.0", ",", "index", "]", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "image", ",", "boxes", ",", "_", ",", "im_info", "=", "self", ".", "transform", "(", "\n", "image", ",", "boxes", ",", "None", ",", "im_info", ")", "\n", "\n", "", "if", "image", "is", "None", "and", "(", "not", "self", ".", "with_precomputed_visual_feat", ")", ":", "\n", "            ", "w", "=", "int", "(", "im_info", "[", "0", "]", ".", "item", "(", ")", ")", "\n", "h", "=", "int", "(", "im_info", "[", "1", "]", ".", "item", "(", ")", ")", "\n", "image", "=", "im_info", ".", "new_zeros", "(", "(", "3", ",", "h", ",", "w", ")", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "# clamp boxes", "\n", "", "w", "=", "im_info", "[", "0", "]", ".", "item", "(", ")", "\n", "h", "=", "im_info", "[", "1", "]", ".", "item", "(", ")", "\n", "boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "w", "-", "1", ")", "\n", "boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", "=", "boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "h", "-", "1", ")", "\n", "\n", "# Task #1: Caption-Image Relationship Prediction", "\n", "_p", "=", "random", ".", "random", "(", ")", "\n", "if", "_p", "<", "0.5", "or", "(", "not", "self", ".", "with_rel_task", ")", ":", "\n", "            ", "relationship_label", "=", "1", "\n", "caption_en", "=", "idb", "[", "'caption_en'", "]", "\n", "caption_de", "=", "idb", "[", "'caption_de'", "]", "\n", "", "else", ":", "\n", "            ", "relationship_label", "=", "0", "\n", "rand_index", "=", "random", ".", "randrange", "(", "0", ",", "len", "(", "self", ".", "database", ")", ")", "\n", "while", "rand_index", "==", "index", ":", "\n", "                ", "rand_index", "=", "random", ".", "randrange", "(", "0", ",", "len", "(", "self", ".", "database", ")", ")", "\n", "", "caption_en", "=", "self", ".", "database", "[", "rand_index", "]", "[", "'caption_en'", "]", "\n", "caption_de", "=", "self", ".", "database", "[", "rand_index", "]", "[", "'caption_de'", "]", "\n", "\n", "# Task #2: Masked Language Modeling - Adapted for two languages", "\n", "\n", "", "if", "self", ".", "with_mlm_task", ":", "\n", "            ", "if", "not", "self", ".", "test_mode", ":", "\n", "                ", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "# FM: removing joining of caption - split into two languages", "\n", "                    ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_en", ")", "\n", "mlm_labels_en", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_en", ")", "\n", "# FM edit: Mask always the last token", "\n", "caption_tokens_de", "=", "caption_de", "\n", "mlm_labels_de", "=", "[", "-", "1", "]", "*", "(", "len", "(", "caption_tokens_de", ")", "-", "1", ")", "\n", "try", ":", "\n", "                        ", "mlm_labels_de", ".", "append", "(", "\n", "self", ".", "tokenizer", ".", "vocab", "[", "caption_tokens_de", "[", "-", "1", "]", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "# For unknown words (should not occur with BPE vocab)", "\n", "                        ", "mlm_labels_de", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "\"[UNK]\"", "]", ")", "\n", "logging", ".", "warning", "(", "\n", "\"Cannot find sub_token '{}' in vocab. Using [UNK] insetad\"", ".", "format", "(", "sub_token", ")", ")", "\n", "", "caption_tokens_de", "[", "-", "1", "]", "=", "'[MASK]'", "\n", "", "else", ":", "\n", "# FM: removing joining of caption - split into two languages", "\n", "                    ", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_de", ")", "\n", "mlm_labels_de", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_de", ")", "\n", "# FM edit: Mask always the last token", "\n", "caption_tokens_en", "=", "caption_en", "\n", "mlm_labels_en", "=", "[", "-", "1", "]", "*", "(", "len", "(", "caption_tokens_en", ")", "-", "1", ")", "\n", "try", ":", "\n", "                        ", "mlm_labels_en", ".", "append", "(", "\n", "self", ".", "tokenizer", ".", "vocab", "[", "caption_tokens_en", "[", "-", "1", "]", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "# For unknown words (should not occur with BPE vocab)", "\n", "                        ", "mlm_labels_en", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "\"[UNK]\"", "]", ")", "\n", "logging", ".", "warning", "(", "\n", "\"Cannot find sub_token '{}' in vocab. Using [UNK] insetad\"", ".", "format", "(", "sub_token", ")", ")", "\n", "", "caption_tokens_en", "[", "-", "1", "]", "=", "'[MASK]'", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "# FM TODO: fix inference", "\n", "                    ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_en", ")", "\n", "mlm_labels_en", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_en", ")", "\n", "# FM edit: add [MASK] to start guessing caption", "\n", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_de", ")", "\n", "# FM edit: add label from vocabulary", "\n", "mlm_labels_de", "=", "[", "103", "]", "+", "[", "-", "1", "]", "\n", "caption_tokens_de", "=", "[", "'[MASK]'", "]", "+", "[", "'[PAD]'", "]", "\n", "", "else", ":", "\n", "# FM TODO: fix inference", "\n", "                    ", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_de", ")", "\n", "mlm_labels_de", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_de", ")", "\n", "# FM edit: add [MASK] to start guessing caption", "\n", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_en", ")", "\n", "# FM edit: add label from vocabulary", "\n", "mlm_labels_en", "=", "[", "103", "]", "+", "[", "-", "1", "]", "\n", "caption_tokens_en", "=", "[", "'[MASK]'", "]", "+", "[", "'[PAD]'", "]", "\n", "", "", "", "else", ":", "\n", "            ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_en", ")", "\n", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_de", ")", "\n", "mlm_labels_en", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_en", ")", "\n", "mlm_labels_de", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_de", ")", "\n", "\n", "", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "            ", "text_tokens", "=", "[", "self", ".", "task_name", "]", "+", "[", "'[CLS]'", "]", "+", "caption_tokens_en", "+", "[", "'[SEP]'", "]", "+", "caption_tokens_de", "+", "[", "'[SEP]'", "]", "\n", "mlm_labels", "=", "[", "-", "1", "]", "+", "[", "-", "1", "]", "+", "mlm_labels_en", "+", "[", "-", "1", "]", "+", "mlm_labels_de", "+", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "text_tokens", "=", "[", "self", ".", "task_name", "]", "+", "[", "'[CLS]'", "]", "+", "caption_tokens_de", "+", "[", "'[SEP]'", "]", "+", "caption_tokens_en", "+", "[", "'[SEP]'", "]", "\n", "mlm_labels", "=", "[", "-", "1", "]", "+", "[", "-", "1", "]", "+", "mlm_labels_de", "+", "[", "-", "1", "]", "+", "mlm_labels_en", "+", "[", "-", "1", "]", "\n", "\n", "# Task #3: Masked Visual Region Classification", "\n", "", "if", "self", ".", "with_mvrc_task", ":", "\n", "            ", "if", "self", ".", "add_image_as_a_box", ":", "\n", "                ", "mvrc_ops", ",", "mvrc_labels", "=", "self", ".", "random_mask_region", "(", "\n", "boxes_cls_scores", ")", "\n", "mvrc_ops", "=", "[", "0", "]", "+", "mvrc_ops", "\n", "mvrc_labels", "=", "[", "np", ".", "zeros_like", "(", "\n", "boxes_cls_scores", "[", "0", "]", ")", "]", "+", "mvrc_labels", "\n", "num_real_boxes", "=", "boxes", ".", "shape", "[", "0", "]", "-", "1", "\n", "num_masked_boxes", "=", "0", "\n", "if", "self", ".", "with_precomputed_visual_feat", ":", "\n", "                    ", "boxes_features", "[", "0", "]", "*=", "num_real_boxes", "\n", "for", "mvrc_op", ",", "box_feat", "in", "zip", "(", "mvrc_ops", ",", "boxes_features", ")", ":", "\n", "                        ", "if", "mvrc_op", "==", "1", ":", "\n", "                            ", "num_masked_boxes", "+=", "1", "\n", "boxes_features", "[", "0", "]", "-=", "box_feat", "\n", "", "", "boxes_features", "[", "0", "]", "/=", "(", "num_real_boxes", "-", "\n", "num_masked_boxes", "+", "1e-5", ")", "\n", "", "", "else", ":", "\n", "                ", "mvrc_ops", ",", "mvrc_labels", "=", "self", ".", "random_mask_region", "(", "\n", "boxes_cls_scores", ")", "\n", "", "assert", "len", "(", "mvrc_ops", ")", "==", "boxes", ".", "shape", "[", "0", "]", ",", "\"Error: mvrc_ops have length {}, expected {}!\"", ".", "format", "(", "\n", "len", "(", "mvrc_ops", ")", ",", "boxes", ".", "shape", "[", "0", "]", ")", "\n", "assert", "len", "(", "mvrc_labels", ")", "==", "boxes", ".", "shape", "[", "0", "]", ",", "\"Error: mvrc_labels have length {}, expected {}!\"", ".", "format", "(", "\n", "len", "(", "mvrc_labels", ")", ",", "boxes", ".", "shape", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "mvrc_ops", "=", "[", "0", "]", "*", "boxes", ".", "shape", "[", "0", "]", "\n", "mvrc_labels", "=", "[", "np", ".", "zeros_like", "(", "boxes_cls_scores", "[", "0", "]", ")", "]", "*", "boxes", ".", "shape", "[", "0", "]", "\n", "\n", "# zero out pixels of masked RoI", "\n", "", "if", "(", "not", "self", ".", "with_precomputed_visual_feat", ")", "and", "self", ".", "mask_raw_pixels", ":", "\n", "            ", "for", "mvrc_op", ",", "box", "in", "zip", "(", "mvrc_ops", ",", "boxes", ")", ":", "\n", "                ", "if", "mvrc_op", "==", "1", ":", "\n", "                    ", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "box", "\n", "image", "[", ":", ",", "int", "(", "y1", ")", ":", "(", "int", "(", "y2", ")", "+", "1", ")", ",", "int", "(", "x1", ")", ":", "(", "int", "(", "x2", ")", "+", "1", ")", "]", "=", "0", "\n", "\n", "# store labels for masked regions", "\n", "", "", "", "mvrc_labels", "=", "np", ".", "stack", "(", "mvrc_labels", ",", "axis", "=", "0", ")", "\n", "\n", "text", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "text_tokens", ")", "\n", "\n", "if", "self", ".", "with_precomputed_visual_feat", ":", "\n", "            ", "boxes", "=", "torch", ".", "cat", "(", "(", "boxes", ",", "boxes_features", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# truncate seq to max len", "\n", "", "if", "len", "(", "text", ")", "+", "len", "(", "boxes", ")", ">", "self", ".", "seq_len", ":", "\n", "            ", "text_len_keep", "=", "len", "(", "text", ")", "\n", "box_len_keep", "=", "len", "(", "boxes", ")", "\n", "while", "(", "text_len_keep", "+", "box_len_keep", ")", ">", "self", ".", "seq_len", "and", "(", "text_len_keep", ">", "0", ")", "and", "(", "box_len_keep", ">", "0", ")", ":", "\n", "                ", "if", "box_len_keep", ">", "text_len_keep", ":", "\n", "                    ", "box_len_keep", "-=", "1", "\n", "", "else", ":", "\n", "                    ", "text_len_keep", "-=", "1", "\n", "", "", "if", "text_len_keep", "<", "2", ":", "\n", "                ", "text_len_keep", "=", "2", "\n", "", "if", "box_len_keep", "<", "1", ":", "\n", "                ", "box_len_keep", "=", "1", "\n", "", "boxes", "=", "boxes", "[", ":", "box_len_keep", "]", "\n", "text", "=", "text", "[", ":", "(", "text_len_keep", "-", "1", ")", "]", "+", "[", "text", "[", "-", "1", "]", "]", "\n", "mlm_labels", "=", "mlm_labels", "[", ":", "(", "text_len_keep", "-", "1", ")", "]", "+", "[", "mlm_labels", "[", "-", "1", "]", "]", "\n", "mvrc_ops", "=", "mvrc_ops", "[", ":", "box_len_keep", "]", "\n", "mvrc_labels", "=", "mvrc_labels", "[", ":", "box_len_keep", "]", "\n", "\n", "", "return", "image", ",", "boxes", ",", "im_info", ",", "text", ",", "relationship_label", ",", "mlm_labels", ",", "mvrc_ops", ",", "mvrc_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k.Multi30kDataset.random_word_wwm": [[378, 423], ["enumerate", "multi30k.Multi30kDataset.tokenizer.wordpiece_tokenizer.tokenize", "random.random", "output_tokens.append", "output_tokens.append", "output_label.append", "output_label.append", "output_label.append", "logging.warning"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize"], ["", "def", "random_word_wwm", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "output_tokens", "=", "[", "]", "\n", "output_label", "=", "[", "]", "\n", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "            ", "sub_tokens", "=", "self", ".", "tokenizer", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", "\n", "prob", "=", "random", ".", "random", "(", ")", "\n", "# mask token with 15% probability", "\n", "if", "prob", "<", "0.15", ":", "\n", "# prob /= 0.15", "\n", "# FM edit: always leave as mask", "\n", "# 80% randomly change token to mask token", "\n", "# if prob < 0.8:", "\n", "                ", "for", "sub_token", "in", "sub_tokens", ":", "\n", "                    ", "output_tokens", ".", "append", "(", "\"[MASK]\"", ")", "\n", "# 10% randomly change token to random token", "\n", "# elif prob < 0.9:", "\n", "#     for sub_token in sub_tokens:", "\n", "#         output_tokens.append(random.choice(list(self.tokenizer.vocab.keys())))", "\n", "#         # -> rest 10% randomly keep current token", "\n", "# else:", "\n", "#     for sub_token in sub_tokens:", "\n", "#         output_tokens.append(sub_token)", "\n", "\n", "# append current token to output (we will predict these later)", "\n", "", "for", "sub_token", "in", "sub_tokens", ":", "\n", "                    ", "try", ":", "\n", "                        ", "output_label", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "sub_token", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "# For unknown words (should not occur with BPE vocab)", "\n", "                        ", "output_label", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "\"[UNK]\"", "]", ")", "\n", "logging", ".", "warning", "(", "\n", "\"Cannot find sub_token '{}' in vocab. Using [UNK] insetad\"", ".", "format", "(", "sub_token", ")", ")", "\n", "", "", "", "else", ":", "\n", "                ", "for", "sub_token", "in", "sub_tokens", ":", "\n", "# no masking token (will be ignored by loss function later)", "\n", "                    ", "output_tokens", ".", "append", "(", "sub_token", ")", "\n", "output_label", ".", "append", "(", "-", "1", ")", "\n", "\n", "# if no word masked, random choose a word to mask", "\n", "# if all([l_ == -1 for l_ in output_label]):", "\n", "#    choosed = random.randrange(0, len(output_label))", "\n", "#    output_label[choosed] = self.tokenizer.vocab[tokens[choosed]]", "\n", "\n", "", "", "", "return", "output_tokens", ",", "output_label", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k.Multi30kDataset.random_mask_region": [[424, 455], ["enumerate", "random.random", "output_label.append", "output_op.append", "output_label.append", "output_op.append", "output_op.append", "numpy.zeros_like"], "methods", ["None"], ["", "def", "random_mask_region", "(", "self", ",", "regions_cls_scores", ")", ":", "\n", "        ", "num_regions", ",", "num_classes", "=", "regions_cls_scores", ".", "shape", "\n", "output_op", "=", "[", "]", "\n", "output_label", "=", "[", "]", "\n", "for", "k", ",", "cls_scores", "in", "enumerate", "(", "regions_cls_scores", ")", ":", "\n", "            ", "prob", "=", "random", ".", "random", "(", ")", "\n", "# mask region with 15% probability", "\n", "if", "prob", "<", "0.15", ":", "\n", "                ", "prob", "/=", "0.15", "\n", "\n", "if", "prob", "<", "0.9", ":", "\n", "# 90% randomly replace appearance feature by \"MASK\"", "\n", "                    ", "output_op", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "# -> rest 10% randomly keep current appearance feature", "\n", "                    ", "output_op", ".", "append", "(", "0", ")", "\n", "\n", "# append class of region to output (we will predict these later)", "\n", "", "output_label", ".", "append", "(", "cls_scores", ")", "\n", "", "else", ":", "\n", "# no masking region (will be ignored by loss function later)", "\n", "                ", "output_op", ".", "append", "(", "0", ")", "\n", "output_label", ".", "append", "(", "np", ".", "zeros_like", "(", "cls_scores", ")", ")", "\n", "\n", "# # if no region masked, random choose a region to mask", "\n", "# if all([op == 0 for op in output_op]):", "\n", "#     choosed = random.randrange(0, len(output_op))", "\n", "#     output_op[choosed] = 1", "\n", "#     output_label[choosed] = regions_cls_scores[choosed]", "\n", "\n", "", "", "return", "output_op", ",", "output_label", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k.Multi30kDataset.b64_decode": [[456, 459], ["base64.decodebytes", "string.encode"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.encode"], ["", "@", "staticmethod", "\n", "def", "b64_decode", "(", "string", ")", ":", "\n", "        ", "return", "base64", ".", "decodebytes", "(", "string", ".", "encode", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k.Multi30kDataset.group_aspect": [[460, 479], ["print", "time.time", "torch.as_tensor", "torch.as_tensor", "torch.zeros", "print", "len", "time.time"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "group_aspect", "(", "database", ")", ":", "\n", "        ", "print", "(", "'grouping aspect...'", ")", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "\n", "# get shape of all images", "\n", "widths", "=", "torch", ".", "as_tensor", "(", "[", "idb", "[", "'width'", "]", "for", "idb", "in", "database", "]", ")", "\n", "heights", "=", "torch", ".", "as_tensor", "(", "[", "idb", "[", "'height'", "]", "for", "idb", "in", "database", "]", ")", "\n", "\n", "# group", "\n", "group_ids", "=", "torch", ".", "zeros", "(", "len", "(", "database", ")", ")", "\n", "horz", "=", "widths", ">=", "heights", "\n", "vert", "=", "1", "-", "horz", "\n", "group_ids", "[", "horz", "]", "=", "0", "\n", "group_ids", "[", "vert", "]", "=", "1", "\n", "\n", "print", "(", "'Done (t={:.2f}s)'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "\n", "return", "group_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k.Multi30kDataset.__len__": [[480, 482], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "database", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k.Multi30kDataset._load_image": [[483, 488], ["multi30k.Multi30kDataset.zipreader.imread().convert", "PIL.Image.open().convert", "multi30k.Multi30kDataset.zipreader.imread", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.imread"], ["", "def", "_load_image", "(", "self", ",", "path", ")", ":", "\n", "        ", "if", "'.zip@'", "in", "path", ":", "\n", "            ", "return", "self", ".", "zipreader", ".", "imread", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "", "else", ":", "\n", "            ", "return", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k.Multi30kDataset._load_json": [[489, 496], ["multi30k.Multi30kDataset.zipreader.read", "json.loads", "multi30k.Multi30kDataset.decode", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.decode"], ["", "", "def", "_load_json", "(", "self", ",", "path", ")", ":", "\n", "        ", "if", "'.zip@'", "in", "path", ":", "\n", "            ", "f", "=", "self", ".", "zipreader", ".", "read", "(", "path", ")", "\n", "return", "json", ".", "loads", "(", "f", ".", "decode", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "return", "json", ".", "load", "(", "f", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.__init__": [[22, 136], ["torch.utils.data.Dataset.__init__", "os.path.join", "os.path.join", "common.utils.zipreader.ZipReader", "list", "print", "os.path.exists", "common.utils.create_logger.makedirsExist", "external.pytorch_pretrained_bert.BertTokenizer.from_pretrained", "jsonlines.open", "print", "print", "print", "print", "multi30k_no_vision.Multi30kDatasetNoVision.group_aspect", "len", "multi30k_no_vision.Multi30kDatasetNoVision.tokenizer.tokenize", "enumerate", "multi30k_no_vision.Multi30kDatasetNoVision.database.append", "multi30k_no_vision.Multi30kDatasetNoVision.tokenizer.tokenize", "enumerate", "multi30k_no_vision.Multi30kDatasetNoVision.database.append", "multi30k_no_vision.Multi30kDatasetNoVision.database.append", "copy.deepcopy", "copy.deepcopy", "multi30k_no_vision.Multi30kDatasetNoVision.database.append", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.create_logger.makedirsExist", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.from_pretrained", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.group_aspect", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize"], ["    ", "def", "__init__", "(", "self", ",", "ann_file", ",", "image_set", ",", "root_path", ",", "data_path", ",", "seq_len", "=", "64", ",", "\n", "with_precomputed_visual_feat", "=", "False", ",", "mask_raw_pixels", "=", "True", ",", "\n", "with_rel_task", "=", "True", ",", "with_mlm_task", "=", "True", ",", "with_mvrc_task", "=", "True", ",", "\n", "transform", "=", "None", ",", "test_mode", "=", "False", ",", "\n", "zip_mode", "=", "False", ",", "cache_mode", "=", "False", ",", "cache_db", "=", "False", ",", "ignore_db_cache", "=", "True", ",", "\n", "tokenizer", "=", "None", ",", "pretrained_model_name", "=", "None", ",", "\n", "add_image_as_a_box", "=", "False", ",", "\n", "aspect_grouping", "=", "False", ",", "task_name", "=", "\"None\"", ",", "lang", "=", "\"second\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Conceptual Captions Dataset\n\n        :param ann_file: annotation jsonl file\n        :param image_set: image folder name, e.g., 'vcr1images'\n        :param root_path: root path to cache database loaded from annotation file\n        :param data_path: path to vcr dataset\n        :param transform: transform\n        :param test_mode: test mode means no labels available\n        :param zip_mode: reading images and metadata in zip archive\n        :param cache_mode: cache whole dataset to RAM first, then __getitem__ read them from RAM\n        :param ignore_db_cache: ignore previous cached database, reload it from annotation file\n        :param tokenizer: default is BertTokenizer from pytorch_pretrained_bert\n        :param add_image_as_a_box: add whole image as a box\n        :param aspect_grouping: whether to group images via their aspect\n        :param kwargs:\n        \"\"\"", "\n", "super", "(", "Multi30kDatasetNoVision", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "not", "cache_mode", ",", "'currently not support cache mode!'", "\n", "# FM edit: commented out to allow testin", "\n", "# assert not test_mode", "\n", "\n", "annot", "=", "{", "'train'", ":", "'train_frcnn.json'", ",", "\n", "'val'", ":", "'val_frcnn.json'", ",", "\n", "'test2015'", ":", "'test_frcnn.json'", ",", "\n", "}", "\n", "\n", "self", ".", "seq_len", "=", "seq_len", "\n", "self", ".", "with_rel_task", "=", "with_rel_task", "\n", "self", ".", "with_mlm_task", "=", "with_mlm_task", "\n", "self", ".", "with_mvrc_task", "=", "with_mvrc_task", "\n", "self", ".", "data_path", "=", "data_path", "\n", "self", ".", "root_path", "=", "root_path", "\n", "self", ".", "ann_file", "=", "os", ".", "path", ".", "join", "(", "data_path", ",", "annot", "[", "image_set", "]", ")", "\n", "self", ".", "with_precomputed_visual_feat", "=", "with_precomputed_visual_feat", "\n", "self", ".", "mask_raw_pixels", "=", "mask_raw_pixels", "\n", "self", ".", "image_set", "=", "image_set", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "zip_mode", "=", "zip_mode", "\n", "self", ".", "cache_mode", "=", "cache_mode", "\n", "self", ".", "cache_db", "=", "cache_db", "\n", "self", ".", "ignore_db_cache", "=", "ignore_db_cache", "\n", "self", ".", "aspect_grouping", "=", "aspect_grouping", "\n", "self", ".", "cache_dir", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "'cache'", ")", "\n", "self", ".", "add_image_as_a_box", "=", "add_image_as_a_box", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "cache_dir", ")", ":", "\n", "            ", "makedirsExist", "(", "self", ".", "cache_dir", ")", "\n", "", "self", ".", "tokenizer", "=", "tokenizer", "if", "tokenizer", "is", "not", "None", "else", "BertTokenizer", ".", "from_pretrained", "(", "\n", "'bert-base-uncased'", "if", "pretrained_model_name", "is", "None", "else", "pretrained_model_name", ",", "\n", "cache_dir", "=", "self", ".", "cache_dir", ",", "do_lower_case", "=", "False", ")", "\n", "\n", "self", ".", "zipreader", "=", "ZipReader", "(", ")", "\n", "\n", "# FM: define task name to add prefix", "\n", "self", ".", "task_name", "=", "task_name", "\n", "self", ".", "lang", "=", "lang", "\n", "\n", "# FM: Customise for multi30k dataset", "\n", "self", ".", "simple_database", "=", "list", "(", "jsonlines", ".", "open", "(", "self", ".", "ann_file", ")", ")", "\n", "\n", "if", "not", "self", ".", "test_mode", ":", "\n", "            ", "self", ".", "database", "=", "[", "]", "\n", "db_pos", "=", "0", "\n", "# create [MASK] every time", "\n", "for", "entry", "in", "self", ".", "simple_database", ":", "\n", "                ", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "                    ", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\n", "entry", "[", "'caption_de'", "]", ")", "\n", "# repeat each entry multiple times - MASK the last word in each case", "\n", "for", "pos", ",", "item", "in", "enumerate", "(", "caption_tokens_de", ")", ":", "\n", "                        ", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "entry", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_de'", "]", "=", "deepcopy", "(", "\n", "caption_tokens_de", "[", ":", "pos", "+", "1", "]", ")", "\n", "db_pos", "+=", "1", "\n", "# add one last entry with last token [STOP]", "\n", "", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "self", ".", "database", "[", "db_pos", "-", "1", "]", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_de'", "]", "=", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_de'", "]", "+", "[", "'[STOP]'", "]", "\n", "db_pos", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "\n", "entry", "[", "'caption_en'", "]", ")", "\n", "# repeat each entry multiple times - MASK the last word in each case", "\n", "for", "pos", ",", "item", "in", "enumerate", "(", "caption_tokens_en", ")", ":", "\n", "                        ", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "entry", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_en'", "]", "=", "deepcopy", "(", "\n", "caption_tokens_en", "[", ":", "pos", "+", "1", "]", ")", "\n", "db_pos", "+=", "1", "\n", "# add one last entry with last token [STOP]", "\n", "", "self", ".", "database", ".", "append", "(", "deepcopy", "(", "self", ".", "database", "[", "db_pos", "-", "1", "]", ")", ")", "\n", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_en'", "]", "=", "self", ".", "database", "[", "db_pos", "]", "[", "'caption_en'", "]", "+", "[", "'[STOP]'", "]", "\n", "db_pos", "+=", "1", "\n", "", "", "print", "(", "'***********************'", ")", "\n", "print", "(", "'The dataset length is: '", ",", "len", "(", "self", ".", "database", ")", ")", "\n", "print", "(", "'Task: '", ",", "self", ".", "task_name", ")", "\n", "print", "(", "'Lang: '", ",", "self", ".", "lang", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "database", "=", "self", ".", "simple_database", "\n", "\n", "", "if", "self", ".", "aspect_grouping", ":", "\n", "            ", "assert", "False", ",", "\"not support aspect grouping currently!\"", "\n", "self", ".", "group_ids", "=", "self", ".", "group_aspect", "(", "self", ".", "database", ")", "\n", "\n", "", "print", "(", "'mask_raw_pixels: '", ",", "self", ".", "mask_raw_pixels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.data_names": [[137, 141], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "data_names", "(", "self", ")", ":", "\n", "        ", "return", "[", "'text'", ",", "\n", "'relationship_label'", ",", "'mlm_labels'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.__getitem__": [[142, 243], ["random.random", "multi30k_no_vision.Multi30kDatasetNoVision.tokenizer.convert_tokens_to_ids", "random.randrange", "multi30k_no_vision.Multi30kDatasetNoVision.tokenizer.tokenize", "multi30k_no_vision.Multi30kDatasetNoVision.tokenizer.tokenize", "len", "len", "len", "random.randrange", "len", "len", "len", "multi30k_no_vision.Multi30kDatasetNoVision.tokenizer.tokenize", "multi30k_no_vision.Multi30kDatasetNoVision.tokenizer.tokenize", "multi30k_no_vision.Multi30kDatasetNoVision.tokenizer.tokenize", "multi30k_no_vision.Multi30kDatasetNoVision.tokenizer.tokenize", "multi30k_no_vision.Multi30kDatasetNoVision.tokenizer.tokenize", "multi30k_no_vision.Multi30kDatasetNoVision.tokenizer.tokenize", "len", "mlm_labels_de.append", "len", "mlm_labels_en.append", "len", "len", "len", "mlm_labels_de.append", "logging.warning", "len", "mlm_labels_en.append", "logging.warning"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "idb", "=", "self", ".", "database", "[", "index", "]", "\n", "\n", "# Task #1: Caption-Image Relationship Prediction", "\n", "_p", "=", "random", ".", "random", "(", ")", "\n", "if", "_p", "<", "0.5", "or", "(", "not", "self", ".", "with_rel_task", ")", ":", "\n", "            ", "relationship_label", "=", "1", "\n", "caption_en", "=", "idb", "[", "'caption_en'", "]", "\n", "caption_de", "=", "idb", "[", "'caption_de'", "]", "\n", "", "else", ":", "\n", "            ", "relationship_label", "=", "0", "\n", "rand_index", "=", "random", ".", "randrange", "(", "0", ",", "len", "(", "self", ".", "database", ")", ")", "\n", "while", "rand_index", "==", "index", ":", "\n", "                ", "rand_index", "=", "random", ".", "randrange", "(", "0", ",", "len", "(", "self", ".", "database", ")", ")", "\n", "", "caption_en", "=", "self", ".", "database", "[", "rand_index", "]", "[", "'caption_en'", "]", "\n", "caption_de", "=", "self", ".", "database", "[", "rand_index", "]", "[", "'caption_de'", "]", "\n", "\n", "# Task #2: Masked Language Modeling - Adapted for two languages", "\n", "\n", "", "if", "self", ".", "with_mlm_task", ":", "\n", "            ", "if", "not", "self", ".", "test_mode", ":", "\n", "                ", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "# FM: removing joining of caption - split into two languages", "\n", "                    ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_en", ")", "\n", "mlm_labels_en", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_en", ")", "\n", "# FM edit: Mask always the last token", "\n", "caption_tokens_de", "=", "caption_de", "\n", "mlm_labels_de", "=", "[", "-", "1", "]", "*", "(", "len", "(", "caption_tokens_de", ")", "-", "1", ")", "\n", "try", ":", "\n", "                        ", "mlm_labels_de", ".", "append", "(", "\n", "self", ".", "tokenizer", ".", "vocab", "[", "caption_tokens_de", "[", "-", "1", "]", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "# For unknown words (should not occur with BPE vocab)", "\n", "                        ", "mlm_labels_de", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "\"[UNK]\"", "]", ")", "\n", "logging", ".", "warning", "(", "\n", "\"Cannot find sub_token '{}' in vocab. Using [UNK] insetad\"", ".", "format", "(", "sub_token", ")", ")", "\n", "", "caption_tokens_de", "[", "-", "1", "]", "=", "'[MASK]'", "\n", "", "else", ":", "\n", "# FM: removing joining of caption - split into two languages", "\n", "                    ", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_de", ")", "\n", "mlm_labels_de", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_de", ")", "\n", "# FM edit: Mask always the last token", "\n", "caption_tokens_en", "=", "caption_en", "\n", "mlm_labels_en", "=", "[", "-", "1", "]", "*", "(", "len", "(", "caption_tokens_en", ")", "-", "1", ")", "\n", "try", ":", "\n", "                        ", "mlm_labels_en", ".", "append", "(", "\n", "self", ".", "tokenizer", ".", "vocab", "[", "caption_tokens_en", "[", "-", "1", "]", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "# For unknown words (should not occur with BPE vocab)", "\n", "                        ", "mlm_labels_en", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "\"[UNK]\"", "]", ")", "\n", "logging", ".", "warning", "(", "\n", "\"Cannot find sub_token '{}' in vocab. Using [UNK] insetad\"", ".", "format", "(", "sub_token", ")", ")", "\n", "", "caption_tokens_en", "[", "-", "1", "]", "=", "'[MASK]'", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "# FM TODO: fix inference", "\n", "                    ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_en", ")", "\n", "mlm_labels_en", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_en", ")", "\n", "# FM edit: add [MASK] to start guessing caption", "\n", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_de", ")", "\n", "# FM edit: add label from vocabulary", "\n", "mlm_labels_de", "=", "[", "103", "]", "+", "[", "-", "1", "]", "\n", "caption_tokens_de", "=", "[", "'[MASK]'", "]", "+", "[", "'[PAD]'", "]", "\n", "", "else", ":", "\n", "# FM TODO: fix inference", "\n", "                    ", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_de", ")", "\n", "mlm_labels_de", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_de", ")", "\n", "# FM edit: add [MASK] to start guessing caption", "\n", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_en", ")", "\n", "# FM edit: add label from vocabulary", "\n", "mlm_labels_en", "=", "[", "103", "]", "+", "[", "-", "1", "]", "\n", "caption_tokens_en", "=", "[", "'[MASK]'", "]", "+", "[", "'[PAD]'", "]", "\n", "", "", "", "else", ":", "\n", "            ", "caption_tokens_en", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_en", ")", "\n", "caption_tokens_de", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption_de", ")", "\n", "mlm_labels_en", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_en", ")", "\n", "mlm_labels_de", "=", "[", "-", "1", "]", "*", "len", "(", "caption_tokens_de", ")", "\n", "\n", "", "if", "self", ".", "lang", "==", "\"second\"", ":", "\n", "            ", "text_tokens", "=", "[", "self", ".", "task_name", "]", "+", "[", "'[CLS]'", "]", "+", "caption_tokens_en", "+", "[", "'[SEP]'", "]", "+", "caption_tokens_de", "+", "[", "'[SEP]'", "]", "\n", "mlm_labels", "=", "[", "-", "1", "]", "+", "[", "-", "1", "]", "+", "mlm_labels_en", "+", "[", "-", "1", "]", "+", "mlm_labels_de", "+", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "text_tokens", "=", "[", "self", ".", "task_name", "]", "+", "[", "'[CLS]'", "]", "+", "caption_tokens_de", "+", "[", "'[SEP]'", "]", "+", "caption_tokens_en", "+", "[", "'[SEP]'", "]", "\n", "mlm_labels", "=", "[", "-", "1", "]", "+", "[", "-", "1", "]", "+", "mlm_labels_de", "+", "[", "-", "1", "]", "+", "mlm_labels_en", "+", "[", "-", "1", "]", "\n", "\n", "", "text", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "text_tokens", ")", "\n", "\n", "# truncate seq to max len", "\n", "if", "len", "(", "text", ")", ">", "self", ".", "seq_len", ":", "\n", "            ", "text_len_keep", "=", "len", "(", "text", ")", "\n", "while", "(", "text_len_keep", ")", ">", "self", ".", "seq_len", "and", "(", "text_len_keep", ">", "0", ")", ":", "\n", "                ", "text_len_keep", "-=", "1", "\n", "", "if", "text_len_keep", "<", "2", ":", "\n", "                ", "text_len_keep", "=", "2", "\n", "", "text", "=", "text", "[", ":", "(", "text_len_keep", "-", "1", ")", "]", "+", "[", "text", "[", "-", "1", "]", "]", "\n", "\n", "", "return", "text", ",", "relationship_label", ",", "mlm_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.random_word_wwm": [[244, 289], ["enumerate", "multi30k_no_vision.Multi30kDatasetNoVision.tokenizer.wordpiece_tokenizer.tokenize", "random.random", "output_tokens.append", "output_tokens.append", "output_label.append", "output_label.append", "output_label.append", "logging.warning"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize"], ["", "def", "random_word_wwm", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "output_tokens", "=", "[", "]", "\n", "output_label", "=", "[", "]", "\n", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "            ", "sub_tokens", "=", "self", ".", "tokenizer", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", "\n", "prob", "=", "random", ".", "random", "(", ")", "\n", "# mask token with 15% probability", "\n", "if", "prob", "<", "0.15", ":", "\n", "# prob /= 0.15", "\n", "# FM edit: always leave as mask", "\n", "# 80% randomly change token to mask token", "\n", "# if prob < 0.8:", "\n", "                ", "for", "sub_token", "in", "sub_tokens", ":", "\n", "                    ", "output_tokens", ".", "append", "(", "\"[MASK]\"", ")", "\n", "# 10% randomly change token to random token", "\n", "# elif prob < 0.9:", "\n", "#     for sub_token in sub_tokens:", "\n", "#         output_tokens.append(random.choice(list(self.tokenizer.vocab.keys())))", "\n", "#         # -> rest 10% randomly keep current token", "\n", "# else:", "\n", "#     for sub_token in sub_tokens:", "\n", "#         output_tokens.append(sub_token)", "\n", "\n", "# append current token to output (we will predict these later)", "\n", "", "for", "sub_token", "in", "sub_tokens", ":", "\n", "                    ", "try", ":", "\n", "                        ", "output_label", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "sub_token", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "# For unknown words (should not occur with BPE vocab)", "\n", "                        ", "output_label", ".", "append", "(", "self", ".", "tokenizer", ".", "vocab", "[", "\"[UNK]\"", "]", ")", "\n", "logging", ".", "warning", "(", "\n", "\"Cannot find sub_token '{}' in vocab. Using [UNK] insetad\"", ".", "format", "(", "sub_token", ")", ")", "\n", "", "", "", "else", ":", "\n", "                ", "for", "sub_token", "in", "sub_tokens", ":", "\n", "# no masking token (will be ignored by loss function later)", "\n", "                    ", "output_tokens", ".", "append", "(", "sub_token", ")", "\n", "output_label", ".", "append", "(", "-", "1", ")", "\n", "\n", "# if no word masked, random choose a word to mask", "\n", "# if all([l_ == -1 for l_ in output_label]):", "\n", "#    choosed = random.randrange(0, len(output_label))", "\n", "#    output_label[choosed] = self.tokenizer.vocab[tokens[choosed]]", "\n", "\n", "", "", "", "return", "output_tokens", ",", "output_label", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.random_mask_region": [[290, 321], ["enumerate", "random.random", "output_label.append", "output_op.append", "output_label.append", "output_op.append", "output_op.append", "numpy.zeros_like"], "methods", ["None"], ["", "def", "random_mask_region", "(", "self", ",", "regions_cls_scores", ")", ":", "\n", "        ", "num_regions", ",", "num_classes", "=", "regions_cls_scores", ".", "shape", "\n", "output_op", "=", "[", "]", "\n", "output_label", "=", "[", "]", "\n", "for", "k", ",", "cls_scores", "in", "enumerate", "(", "regions_cls_scores", ")", ":", "\n", "            ", "prob", "=", "random", ".", "random", "(", ")", "\n", "# mask region with 15% probability", "\n", "if", "prob", "<", "0.15", ":", "\n", "                ", "prob", "/=", "0.15", "\n", "\n", "if", "prob", "<", "0.9", ":", "\n", "# 90% randomly replace appearance feature by \"MASK\"", "\n", "                    ", "output_op", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "# -> rest 10% randomly keep current appearance feature", "\n", "                    ", "output_op", ".", "append", "(", "0", ")", "\n", "\n", "# append class of region to output (we will predict these later)", "\n", "", "output_label", ".", "append", "(", "cls_scores", ")", "\n", "", "else", ":", "\n", "# no masking region (will be ignored by loss function later)", "\n", "                ", "output_op", ".", "append", "(", "0", ")", "\n", "output_label", ".", "append", "(", "np", ".", "zeros_like", "(", "cls_scores", ")", ")", "\n", "\n", "# # if no region masked, random choose a region to mask", "\n", "# if all([op == 0 for op in output_op]):", "\n", "#     choosed = random.randrange(0, len(output_op))", "\n", "#     output_op[choosed] = 1", "\n", "#     output_label[choosed] = regions_cls_scores[choosed]", "\n", "\n", "", "", "return", "output_op", ",", "output_label", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.b64_decode": [[322, 325], ["base64.decodebytes", "string.encode"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.encode"], ["", "@", "staticmethod", "\n", "def", "b64_decode", "(", "string", ")", ":", "\n", "        ", "return", "base64", ".", "decodebytes", "(", "string", ".", "encode", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.group_aspect": [[326, 345], ["print", "time.time", "torch.as_tensor", "torch.as_tensor", "torch.zeros", "print", "len", "time.time"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "group_aspect", "(", "database", ")", ":", "\n", "        ", "print", "(", "'grouping aspect...'", ")", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "\n", "# get shape of all images", "\n", "widths", "=", "torch", ".", "as_tensor", "(", "[", "idb", "[", "'width'", "]", "for", "idb", "in", "database", "]", ")", "\n", "heights", "=", "torch", ".", "as_tensor", "(", "[", "idb", "[", "'height'", "]", "for", "idb", "in", "database", "]", ")", "\n", "\n", "# group", "\n", "group_ids", "=", "torch", ".", "zeros", "(", "len", "(", "database", ")", ")", "\n", "horz", "=", "widths", ">=", "heights", "\n", "vert", "=", "1", "-", "horz", "\n", "group_ids", "[", "horz", "]", "=", "0", "\n", "group_ids", "[", "vert", "]", "=", "1", "\n", "\n", "print", "(", "'Done (t={:.2f}s)'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "\n", "return", "group_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision.__len__": [[346, 348], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "database", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision._load_image": [[349, 354], ["multi30k_no_vision.Multi30kDatasetNoVision.zipreader.imread().convert", "PIL.Image.open().convert", "multi30k_no_vision.Multi30kDatasetNoVision.zipreader.imread", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.imread"], ["", "def", "_load_image", "(", "self", ",", "path", ")", ":", "\n", "        ", "if", "'.zip@'", "in", "path", ":", "\n", "            ", "return", "self", ".", "zipreader", ".", "imread", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "", "else", ":", "\n", "            ", "return", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.datasets.multi30k_no_vision.Multi30kDatasetNoVision._load_json": [[355, 362], ["multi30k_no_vision.Multi30kDatasetNoVision.zipreader.read", "json.loads", "multi30k_no_vision.Multi30kDatasetNoVision.decode", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.decode"], ["", "", "def", "_load_json", "(", "self", ",", "path", ")", ":", "\n", "        ", "if", "'.zip@'", "in", "path", ":", "\n", "            ", "f", "=", "self", ".", "zipreader", ".", "read", "(", "path", ")", "\n", "return", "json", ".", "loads", "(", "f", ".", "decode", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "return", "json", ".", "load", "(", "f", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.samplers.distributed.DistributedSampler.__init__": [[25, 41], ["int", "torch.get_world_size", "torch.get_world_size", "torch.get_rank", "torch.get_rank", "math.ceil", "torch.is_available", "torch.is_available", "RuntimeError", "torch.is_available", "torch.is_available", "RuntimeError", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "num_replicas", "=", "None", ",", "rank", "=", "None", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "if", "num_replicas", "is", "None", ":", "\n", "            ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Requires distributed package to be available\"", ")", "\n", "", "num_replicas", "=", "dist", ".", "get_world_size", "(", ")", "\n", "", "if", "rank", "is", "None", ":", "\n", "            ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Requires distributed package to be available\"", ")", "\n", "", "rank", "=", "dist", ".", "get_rank", "(", ")", "\n", "", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "num_replicas", "=", "num_replicas", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "epoch", "=", "0", "\n", "self", ".", "num_samples", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "self", ".", "dataset", ")", "*", "1.0", "/", "self", ".", "num_replicas", ")", ")", "\n", "self", ".", "total_size", "=", "self", ".", "num_samples", "*", "self", ".", "num_replicas", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.samplers.distributed.DistributedSampler.__iter__": [[42, 61], ["iter", "torch.Generator", "torch.Generator", "torch.Generator", "torch.Generator", "torch.Generator.manual_seed", "torch.Generator.manual_seed", "torch.randperm().tolist", "torch.randperm().tolist", "torch.randperm().tolist", "torch.randperm().tolist", "torch.arange().tolist", "torch.arange().tolist", "torch.arange().tolist", "torch.arange().tolist", "len", "len", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "len", "len", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "# deterministically shuffle based on epoch", "\n", "            ", "g", "=", "torch", ".", "Generator", "(", ")", "\n", "g", ".", "manual_seed", "(", "self", ".", "epoch", ")", "\n", "indices", "=", "torch", ".", "randperm", "(", "len", "(", "self", ".", "dataset", ")", ",", "generator", "=", "g", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "            ", "indices", "=", "torch", ".", "arange", "(", "len", "(", "self", ".", "dataset", ")", ")", ".", "tolist", "(", ")", "\n", "\n", "# add extra samples to make it evenly divisible", "\n", "", "indices", "+=", "indices", "[", ":", "(", "self", ".", "total_size", "-", "len", "(", "indices", ")", ")", "]", "\n", "assert", "len", "(", "indices", ")", "==", "self", ".", "total_size", "\n", "\n", "# subsample", "\n", "offset", "=", "self", ".", "num_samples", "*", "self", ".", "rank", "\n", "indices", "=", "indices", "[", "offset", ":", "offset", "+", "self", ".", "num_samples", "]", "\n", "assert", "len", "(", "indices", ")", "==", "self", ".", "num_samples", "\n", "\n", "return", "iter", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.samplers.distributed.DistributedSampler.__len__": [[62, 64], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.samplers.distributed.DistributedSampler.set_epoch": [[65, 67], ["None"], "methods", ["None"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "self", ".", "epoch", "=", "epoch", "", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.samplers.grouped_batch_sampler.GroupedBatchSampler.__init__": [[22, 37], ["torch.as_tensor", "isinstance", "ValueError", "grouped_batch_sampler.GroupedBatchSampler.group_ids.dim", "torch.unique().sort", "torch.unique"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sampler", ",", "group_ids", ",", "batch_size", ",", "drop_uneven", "=", "False", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "sampler", ",", "Sampler", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"sampler should be an instance of \"", "\n", "\"torch.utils.data.Sampler, but got sampler={}\"", ".", "format", "(", "sampler", ")", "\n", ")", "\n", "", "self", ".", "sampler", "=", "sampler", "\n", "self", ".", "group_ids", "=", "torch", ".", "as_tensor", "(", "group_ids", ")", "\n", "assert", "self", ".", "group_ids", ".", "dim", "(", ")", "==", "1", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "drop_uneven", "=", "drop_uneven", "\n", "\n", "self", ".", "groups", "=", "torch", ".", "unique", "(", "self", ".", "group_ids", ")", ".", "sort", "(", "0", ")", "[", "0", "]", "\n", "\n", "self", ".", "_can_reuse_batches", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.samplers.grouped_batch_sampler.GroupedBatchSampler._prepare_batches": [[38, 99], ["len", "torch.as_tensor", "torch.full", "torch.arange", "tuple", "torch.as_tensor", "[].tolist", "list", "len", "c.split", "itertools.chain.from_iterable", "t[].item", "merged[].tolist", "enumerate", "torch.as_tensor.tolist", "torch.as_tensor.sort", "len", "kept.append", "s.sort"], "methods", ["None"], ["", "def", "_prepare_batches", "(", "self", ")", ":", "\n", "        ", "dataset_size", "=", "len", "(", "self", ".", "group_ids", ")", "\n", "# get the sampled indices from the sampler", "\n", "sampled_ids", "=", "torch", ".", "as_tensor", "(", "list", "(", "self", ".", "sampler", ")", ")", "\n", "# potentially not all elements of the dataset were sampled", "\n", "# by the sampler (e.g., DistributedSampler).", "\n", "# construct a tensor which contains -1 if the element was", "\n", "# not sampled, and a non-negative number indicating the", "\n", "# order where the element was sampled.", "\n", "# for example. if sampled_ids = [3, 1] and dataset_size = 5,", "\n", "# the order is [-1, 1, -1, 0, -1]", "\n", "order", "=", "torch", ".", "full", "(", "(", "dataset_size", ",", ")", ",", "-", "1", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "order", "[", "sampled_ids", "]", "=", "torch", ".", "arange", "(", "len", "(", "sampled_ids", ")", ")", "\n", "\n", "# get a mask with the elements that were sampled", "\n", "mask", "=", "order", ">=", "0", "\n", "\n", "# find the elements that belong to each individual cluster", "\n", "clusters", "=", "[", "(", "self", ".", "group_ids", "==", "i", ")", "&", "mask", "for", "i", "in", "self", ".", "groups", "]", "\n", "# get relative order of the elements inside each cluster", "\n", "# that follows the order from the sampler", "\n", "relative_order", "=", "[", "order", "[", "cluster", "]", "for", "cluster", "in", "clusters", "]", "\n", "# with the relative order, find the absolute order in the", "\n", "# sampled space", "\n", "permutation_ids", "=", "[", "s", "[", "s", ".", "sort", "(", ")", "[", "1", "]", "]", "for", "s", "in", "relative_order", "]", "\n", "# permute each cluster so that they follow the order from", "\n", "# the sampler", "\n", "permuted_clusters", "=", "[", "sampled_ids", "[", "idx", "]", "for", "idx", "in", "permutation_ids", "]", "\n", "\n", "# splits each cluster in batch_size, and merge as a list of tensors", "\n", "splits", "=", "[", "c", ".", "split", "(", "self", ".", "batch_size", ")", "for", "c", "in", "permuted_clusters", "]", "\n", "merged", "=", "tuple", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "splits", ")", ")", "\n", "\n", "# now each batch internally has the right order, but", "\n", "# they are grouped by clusters. Find the permutation between", "\n", "# different batches that brings them as close as possible to", "\n", "# the order that we have in the sampler. For that, we will consider the", "\n", "# ordering as coming from the first element of each batch, and sort", "\n", "# correspondingly", "\n", "first_element_of_batch", "=", "[", "t", "[", "0", "]", ".", "item", "(", ")", "for", "t", "in", "merged", "]", "\n", "# get and inverse mapping from sampled indices and the position where", "\n", "# they occur (as returned by the sampler)", "\n", "inv_sampled_ids_map", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "enumerate", "(", "sampled_ids", ".", "tolist", "(", ")", ")", "}", "\n", "# from the first element in each batch, get a relative ordering", "\n", "first_index_of_batch", "=", "torch", ".", "as_tensor", "(", "\n", "[", "inv_sampled_ids_map", "[", "s", "]", "for", "s", "in", "first_element_of_batch", "]", "\n", ")", "\n", "\n", "# permute the batches so that they approximately follow the order", "\n", "# from the sampler", "\n", "permutation_order", "=", "first_index_of_batch", ".", "sort", "(", "0", ")", "[", "1", "]", ".", "tolist", "(", ")", "\n", "# finally, permute the batches", "\n", "batches", "=", "[", "merged", "[", "i", "]", ".", "tolist", "(", ")", "for", "i", "in", "permutation_order", "]", "\n", "\n", "if", "self", ".", "drop_uneven", ":", "\n", "            ", "kept", "=", "[", "]", "\n", "for", "batch", "in", "batches", ":", "\n", "                ", "if", "len", "(", "batch", ")", "==", "self", ".", "batch_size", ":", "\n", "                    ", "kept", ".", "append", "(", "batch", ")", "\n", "", "", "batches", "=", "kept", "\n", "", "return", "batches", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.samplers.grouped_batch_sampler.GroupedBatchSampler.__iter__": [[100, 108], ["iter", "grouped_batch_sampler.GroupedBatchSampler._prepare_batches"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.samplers.grouped_batch_sampler.GroupedBatchSampler._prepare_batches"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_can_reuse_batches", ":", "\n", "            ", "batches", "=", "self", ".", "_batches", "\n", "self", ".", "_can_reuse_batches", "=", "False", "\n", "", "else", ":", "\n", "            ", "batches", "=", "self", ".", "_prepare_batches", "(", ")", "\n", "", "self", ".", "_batches", "=", "batches", "\n", "return", "iter", "(", "batches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.samplers.grouped_batch_sampler.GroupedBatchSampler.__len__": [[109, 114], ["len", "hasattr", "grouped_batch_sampler.GroupedBatchSampler._prepare_batches"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.samplers.grouped_batch_sampler.GroupedBatchSampler._prepare_batches"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "\"_batches\"", ")", ":", "\n", "            ", "self", ".", "_batches", "=", "self", ".", "_prepare_batches", "(", ")", "\n", "self", ".", "_can_reuse_batches", "=", "True", "\n", "", "return", "len", "(", "self", ".", "_batches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.transforms.transforms.Compose.__init__": [[11, 13], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.transforms.transforms.Compose.__call__": [[14, 18], ["t"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "image", ",", "boxes", ",", "masks", ",", "im_info", ")", ":", "\n", "        ", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "image", ",", "boxes", ",", "masks", ",", "im_info", "=", "t", "(", "image", ",", "boxes", ",", "masks", ",", "im_info", ")", "\n", "", "return", "image", ",", "boxes", ",", "masks", ",", "im_info", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.transforms.transforms.Compose.__repr__": [[19, 26], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "\"(\"", "\n", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "format_string", "+=", "\"\\n\"", "\n", "format_string", "+=", "\"    {0}\"", ".", "format", "(", "t", ")", "\n", "", "format_string", "+=", "\"\\n)\"", "\n", "return", "format_string", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.transforms.transforms.Resize.__init__": [[29, 32], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "min_size", ",", "max_size", ")", ":", "\n", "        ", "self", ".", "min_size", "=", "min_size", "\n", "self", ".", "max_size", "=", "max_size", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.transforms.transforms.Resize.get_size": [[34, 55], ["float", "float", "int", "int", "min", "max", "int"], "methods", ["None"], ["", "def", "get_size", "(", "self", ",", "image_size", ")", ":", "\n", "        ", "w", ",", "h", "=", "image_size", "\n", "size", "=", "self", ".", "min_size", "\n", "max_size", "=", "self", ".", "max_size", "\n", "if", "max_size", "is", "not", "None", ":", "\n", "            ", "min_original_size", "=", "float", "(", "min", "(", "(", "w", ",", "h", ")", ")", ")", "\n", "max_original_size", "=", "float", "(", "max", "(", "(", "w", ",", "h", ")", ")", ")", "\n", "if", "max_original_size", "/", "min_original_size", "*", "size", ">", "max_size", ":", "\n", "                ", "size", "=", "int", "(", "max_size", "*", "min_original_size", "/", "max_original_size", ")", "\n", "\n", "", "", "if", "(", "w", "<=", "h", "and", "w", "==", "size", ")", "or", "(", "h", "<=", "w", "and", "h", "==", "size", ")", ":", "\n", "            ", "return", "(", "w", ",", "h", ")", "\n", "\n", "", "if", "w", "<", "h", ":", "\n", "            ", "ow", "=", "size", "\n", "oh", "=", "int", "(", "size", "*", "h", "/", "w", ")", "\n", "", "else", ":", "\n", "            ", "oh", "=", "size", "\n", "ow", "=", "int", "(", "size", "*", "w", "/", "h", ")", "\n", "\n", "", "return", "(", "ow", ",", "oh", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.transforms.transforms.Resize.__call__": [[56, 69], ["transforms.Resize.get_size", "torchvision.transforms.functional.resize"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.transforms.transforms.Resize.get_size"], ["", "def", "__call__", "(", "self", ",", "image", ",", "boxes", ",", "masks", ",", "im_info", ")", ":", "\n", "        ", "origin_size", "=", "im_info", "[", ":", "2", "]", "\n", "size", "=", "self", ".", "get_size", "(", "origin_size", ")", "\n", "if", "image", "is", "not", "None", ":", "\n", "            ", "image", "=", "F", ".", "resize", "(", "image", ",", "(", "size", "[", "1", "]", ",", "size", "[", "0", "]", ")", ")", "\n", "\n", "", "ratios", "=", "[", "size", "[", "0", "]", "*", "1.0", "/", "origin_size", "[", "0", "]", ",", "size", "[", "1", "]", "*", "1.0", "/", "origin_size", "[", "1", "]", "]", "\n", "if", "boxes", "is", "not", "None", ":", "\n", "            ", "boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", "*=", "ratios", "[", "0", "]", "\n", "boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", "*=", "ratios", "[", "1", "]", "\n", "", "im_info", "[", "0", "]", ",", "im_info", "[", "1", "]", "=", "size", "\n", "im_info", "[", "2", "]", ",", "im_info", "[", "3", "]", "=", "ratios", "\n", "return", "image", ",", "boxes", ",", "masks", ",", "im_info", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.transforms.transforms.RandomHorizontalFlip.__init__": [[72, 74], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "prob", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "prob", "=", "prob", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.transforms.transforms.RandomHorizontalFlip.__call__": [[75, 85], ["random.random", "torchvision.transforms.functional.hflip", "torch.as_tensor", "[].tolist", "torch.as_tensor.numpy"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "image", ",", "boxes", ",", "masks", ",", "im_info", ")", ":", "\n", "        ", "if", "random", ".", "random", "(", ")", "<", "self", ".", "prob", ":", "\n", "            ", "w", ",", "h", "=", "im_info", "[", ":", "2", "]", "\n", "if", "image", "is", "not", "None", ":", "\n", "                ", "image", "=", "F", ".", "hflip", "(", "image", ")", "\n", "", "if", "boxes", "is", "not", "None", ":", "\n", "                ", "boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "w", "-", "1", "-", "boxes", "[", ":", ",", "[", "2", ",", "0", "]", "]", "\n", "", "if", "masks", "is", "not", "None", ":", "\n", "                ", "masks", "=", "torch", ".", "as_tensor", "(", "masks", ".", "numpy", "(", ")", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ".", "tolist", "(", ")", ")", "\n", "", "", "return", "image", ",", "boxes", ",", "masks", ",", "im_info", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.transforms.transforms.ToTensor.__call__": [[88, 90], ["torchvision.transforms.functional.to_tensor"], "methods", ["None"], ["    ", "def", "__call__", "(", "self", ",", "image", ",", "boxes", ",", "masks", ",", "im_info", ")", ":", "\n", "        ", "return", "F", ".", "to_tensor", "(", "image", ")", "if", "image", "is", "not", "None", "else", "image", ",", "boxes", ",", "masks", ",", "im_info", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.transforms.transforms.Normalize.__init__": [[93, 97], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mean", ",", "std", ",", "to_bgr255", "=", "True", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "self", ".", "to_bgr255", "=", "to_bgr255", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.transforms.transforms.Normalize.__call__": [[98, 104], ["torchvision.transforms.functional.normalize"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "image", ",", "boxes", ",", "masks", ",", "im_info", ")", ":", "\n", "        ", "if", "image", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "to_bgr255", ":", "\n", "                ", "image", "=", "image", "[", "[", "2", ",", "1", ",", "0", "]", "]", "*", "255", "\n", "", "image", "=", "F", ".", "normalize", "(", "image", ",", "mean", "=", "self", ".", "mean", ",", "std", "=", "self", ".", "std", ")", "\n", "", "return", "image", ",", "boxes", ",", "masks", ",", "im_info", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.transforms.transforms.FixPadding.__init__": [[107, 111], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "min_size", ",", "max_size", ",", "pad", "=", "0", ")", ":", "\n", "        ", "self", ".", "min_size", "=", "min_size", "\n", "self", ".", "max_size", "=", "max_size", "\n", "self", ".", "pad", "=", "pad", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.transforms.transforms.FixPadding.__call__": [[112, 128], ["image.new_zeros().fill_", "image.new_zeros"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "image", ",", "boxes", ",", "masks", ",", "im_info", ")", ":", "\n", "\n", "        ", "if", "image", "is", "not", "None", ":", "\n", "# padding to fixed size for determinacy", "\n", "            ", "c", ",", "h", ",", "w", "=", "image", ".", "shape", "\n", "if", "h", "<=", "w", ":", "\n", "                ", "h1", "=", "self", ".", "min_size", "\n", "w1", "=", "self", ".", "max_size", "\n", "", "else", ":", "\n", "                ", "h1", "=", "self", ".", "max_size", "\n", "w1", "=", "self", ".", "min_size", "\n", "", "padded_image", "=", "image", ".", "new_zeros", "(", "(", "c", ",", "h1", ",", "w1", ")", ")", ".", "fill_", "(", "self", ".", "pad", ")", "\n", "padded_image", "[", ":", ",", ":", "h", ",", ":", "w", "]", "=", "image", "\n", "image", "=", "padded_image", "\n", "\n", "", "return", "image", ",", "boxes", ",", "masks", ",", "im_info", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.transforms.build.build_transforms": [[4, 43], ["transforms.Normalize", "transforms.Compose", "transforms.Resize", "transforms.RandomHorizontalFlip", "transforms.ToTensor"], "function", ["None"], ["from", ".", "import", "samplers", "\n", "from", ".", "transforms", ".", "build", "import", "build_transforms", "\n", "from", ".", "collate_batch", "import", "BatchCollator", "\n", "import", "pprint", "\n", "from", "copy", "import", "deepcopy", "\n", "\n", "# FM: Added mutli30k to available datasets", "\n", "DATASET_CATALOGS", "=", "{", "\n", "'multi30k'", ":", "Multi30kDataset", ",", "\n", "'multi30k_image_only'", ":", "Multi30kDatasetImageOnly", ",", "\n", "'multi30k_image_only_COCO'", ":", "Multi30kDatasetImageOnlyCOCO", ",", "\n", "'multi30k_image_only5x'", ":", "Multi30kDatasetImageOnly5x", ",", "\n", "'multi30k_decoder'", ":", "Multi30kDatasetDecoder", ",", "\n", "'multi30k_no_vision'", ":", "Multi30kDatasetNoVision", ",", "\n", "'multi30k_taskB'", ":", "Multi30kTaskBDataset", ",", "\n", "'parallel_text'", ":", "ParallelTextDataset", "\n", "}", "\n", "\n", "\n", "def", "build_dataset", "(", "dataset_name", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "assert", "dataset_name", "in", "DATASET_CATALOGS", ",", "\"dataset not in catalogs\"", "\n", "return", "DATASET_CATALOGS", "[", "dataset_name", "]", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "\n", "", "def", "make_data_sampler", "(", "dataset", ",", "shuffle", ",", "distributed", ",", "num_replicas", ",", "rank", ")", ":", "\n", "    ", "if", "distributed", ":", "\n", "        ", "return", "samplers", ".", "DistributedSampler", "(", "dataset", ",", "shuffle", "=", "shuffle", ",", "num_replicas", "=", "num_replicas", ",", "rank", "=", "rank", ")", "\n", "", "if", "shuffle", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "RandomSampler", "(", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "SequentialSampler", "(", "dataset", ")", "\n", "", "return", "sampler", "\n", "\n", "\n", "", "def", "make_batch_data_sampler", "(", "dataset", ",", "sampler", ",", "aspect_grouping", ",", "batch_size", ")", ":", "\n", "    ", "if", "aspect_grouping", ":", "\n", "        ", "group_ids", "=", "dataset", ".", "group_ids", "\n", "batch_sampler", "=", "samplers", ".", "GroupedBatchSampler", "(", "\n", "sampler", ",", "group_ids", ",", "batch_size", ",", "drop_uneven", "=", "False", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.function.config.update_config": [[182, 220], ["open", "easydict.EasyDict", "isinstance", "easydict.EasyDict.items", "yaml.load", "isinstance", "isinstance", "ValueError", "enumerate", "v.items", "dataset_templ.items", "tuple", "ValueError", "tuple", "float", "tuple", "isinstance", "vv.items", "vv.split", "str", "ValueError", "vvi.split"], "function", ["None"], ["def", "update_config", "(", "config_file", ")", ":", "\n", "    ", "with", "open", "(", "config_file", ")", "as", "f", ":", "\n", "        ", "exp_config", "=", "edict", "(", "yaml", ".", "load", "(", "f", ")", ")", "\n", "if", "isinstance", "(", "exp_config", ".", "DATASET", ",", "list", ")", ":", "\n", "            ", "dataset_templ", "=", "config", ".", "DATASET", "\n", "config", ".", "DATASET", "=", "[", "]", "\n", "", "for", "k", ",", "v", "in", "exp_config", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "in", "config", ":", "\n", "                ", "if", "isinstance", "(", "v", ",", "dict", ")", ":", "\n", "                    ", "for", "vk", ",", "vv", "in", "v", ".", "items", "(", ")", ":", "\n", "                        ", "if", "vk", "in", "config", "[", "k", "]", ":", "\n", "                            ", "if", "vk", "==", "'LR_STEP'", ":", "\n", "                                ", "config", "[", "k", "]", "[", "vk", "]", "=", "tuple", "(", "float", "(", "s", ")", "for", "s", "in", "vv", ".", "split", "(", "','", ")", ")", "\n", "", "elif", "vk", "==", "'LOSS_LOGGERS'", ":", "\n", "                                ", "config", "[", "k", "]", "[", "vk", "]", "=", "[", "tuple", "(", "str", "(", "s", ")", "for", "s", "in", "vvi", ".", "split", "(", "','", ")", ")", "for", "vvi", "in", "vv", "]", "\n", "", "elif", "vk", "==", "\"VLBERT\"", "and", "isinstance", "(", "vv", ",", "dict", ")", ":", "\n", "                                ", "for", "vvk", ",", "vvv", "in", "vv", ".", "items", "(", ")", ":", "\n", "                                    ", "if", "vvk", "in", "config", "[", "k", "]", "[", "vk", "]", ":", "\n", "                                        ", "config", "[", "k", "]", "[", "vk", "]", "[", "vvk", "]", "=", "vvv", "\n", "", "else", ":", "\n", "                                        ", "raise", "ValueError", "(", "\"key {}.{}.{} not in config.py\"", ".", "format", "(", "k", ",", "vk", ",", "vvk", ")", ")", "\n", "", "", "", "else", ":", "\n", "                                ", "config", "[", "k", "]", "[", "vk", "]", "=", "vv", "\n", "", "", "else", ":", "\n", "                            ", "raise", "ValueError", "(", "\"key {}.{} not in config.py\"", ".", "format", "(", "k", ",", "vk", ")", ")", "\n", "", "", "", "else", ":", "\n", "                    ", "if", "k", "==", "'SCALES'", ":", "\n", "                        ", "config", "[", "k", "]", "=", "(", "tuple", "(", "v", ")", ")", "\n", "", "else", ":", "\n", "                        ", "config", "[", "k", "]", "=", "v", "\n", "", "", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"key {} not in config.py\"", ".", "format", "(", "k", ")", ")", "\n", "\n", "", "if", "isinstance", "(", "config", ".", "DATASET", ",", "list", ")", ":", "\n", "                ", "for", "i", ",", "dataset_cfg", "in", "enumerate", "(", "config", ".", "DATASET", ")", ":", "\n", "                    ", "for", "k", ",", "v", "in", "dataset_templ", ".", "items", "(", ")", ":", "\n", "                        ", "if", "k", "not", "in", "dataset_cfg", ":", "\n", "                            ", "config", ".", "DATASET", "[", "i", "]", "[", "k", "]", "=", "v", "\n", "", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.function.train.train_net": [[39, 420], ["common.utils.create_logger.create_logger", "os.path.join", "pprint.pprint", "logger.info", "pprint.pprint", "logger.info", "common.metrics.composite_eval_metric.CompositeEvalMetric", "common.metrics.composite_eval_metric.CompositeEvalMetric", "common.callbacks.epoch_end_callbacks.validation_monitor.ValidationMonitor", "common.trainer.train", "os.path.join", "random.seed", "numpy.random.seed", "torch.random.manual_seed", "torch.random.manual_seed", "torch.random.manual_seed", "torch.random.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "int", "str", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "int", "int", "int", "int", "int", "print", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "str", "Apex_DDP.cuda", "isinstance", "optimizer_grouped_parameters.append", "common.utils.misc.summary_parameters", "shutil.copy", "shutil.copy", "len", "isinstance", "optimizer_grouped_parameters.append", "train_metrics_list.append", "val_metrics_list.append", "train_metrics_list.append", "val_metrics_list.append", "train_metrics_list.append", "val_metrics_list.append", "common.metrics.composite_eval_metric.CompositeEvalMetric.add", "common.metrics.composite_eval_metric.CompositeEvalMetric.add", "group.setdefault", "common.utils.load.smart_resume", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.broadcast", "torch.tensor().cuda.item", "len", "common.callbacks.batch_end_callbacks.speedometer.Speedometer", "print", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.optim.lr_scheduler.ReduceLROnPlateau", "Apex_DDP.state_dict().values", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.broadcast", "torch.broadcast", "torch.tensor().cuda.item", "torch.tensor().cuda.item", "amp.initialize", "isinstance", "pprint.pformat", "eval", "torch.init_process_group", "torch.init_process_group", "torch.nn.parallel.DistributedDataParallel", "common.utils.misc.summary_parameters", "shutil.copy", "shutil.copy", "os.path.join", "tensorboardX.SummaryWriter", "LanguageGeneration.data.build.make_dataloaders", "LanguageGeneration.data.build.make_dataloaders", "common.utils.multi_task_dataloader.MultiTaskDataLoader", "common.utils.multi_task_dataloader.MultiTaskDataLoader", "LanguageGeneration.data.build.make_dataloader", "LanguageGeneration.data.build.make_dataloader", "torch.SGD", "eval", "inspect.getfile", "config.GPUS.split", "tensorboardX.SummaryWriter", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "Apex_DDP.cuda", "LanguageGeneration.data.build.make_dataloaders", "LanguageGeneration.data.build.make_dataloaders", "common.utils.multi_task_dataloader.MultiTaskDataLoader", "common.utils.multi_task_dataloader.MultiTaskDataLoader", "LanguageGeneration.data.build.make_dataloader", "LanguageGeneration.data.build.make_dataloader", "torch.SGD", "torch.load", "torch.load", "torch.load", "torch.load", "prefix_change.split", "len", "pretrain_state_dict.items", "common.utils.load.smart_hybrid_partial_load_model_state_dict", "common.metrics.pretrain_metrics.RelationshipAccuracy", "common.metrics.pretrain_metrics.RelationshipAccuracy", "train_metrics_list.append", "train_metrics_list.append", "train_metrics_list.append", "val_metrics_list.append", "val_metrics_list.append", "val_metrics_list.append", "common.metrics.pretrain_metrics.MVRCAccuracy", "common.metrics.pretrain_metrics.MVRCAccuracy", "common.metrics.pretrain_metrics.LossLogger", "common.metrics.pretrain_metrics.LossLogger", "common.callbacks.epoch_end_callbacks.checkpoint.Checkpoint", "config.GPUS.split", "isinstance", "sum", "common.nlp.bert.optimization.WarmupLinearSchedule", "torch.broadcast", "Apex_DDP", "os.environ.get", "inspect.getfile", "os.path.exists", "os.makedirs", "isinstance", "sum", "torch.Adam", "eval", "int", "isinstance", "sum", "torch.Adam", "common.utils.load.smart_skip_partial_load_model_state_dict", "common.utils.load.smart_partial_load_model_state_dict", "common.metrics.pretrain_metrics.MLMAccuracyDataset1", "common.metrics.pretrain_metrics.MLMAccuracyDataset2", "common.metrics.pretrain_metrics.MLMAccuracyDataset3", "common.metrics.pretrain_metrics.MLMAccuracyDataset1", "common.metrics.pretrain_metrics.MLMAccuracyDataset2", "common.metrics.pretrain_metrics.MLMAccuracyDataset3", "range", "train_metrics_list.append", "val_metrics_list.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "common.lr_scheduler.WarmupMultiStepLR", "ValueError", "Apex_DDP.state_dict", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "isinstance", "eval", "common.nlp.bert.optimization.AdamW", "ValueError", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "common.nlp.bert.optimization.AdamW", "ValueError", "k.startswith", "len", "train_metrics_list.append", "val_metrics_list.append", "common.metrics.pretrain_metrics.MLMAccuracy", "common.metrics.pretrain_metrics.MLMAccuracy", "int", "int", "Apex_DDP.named_parameters", "Apex_DDP.named_parameters", "all", "Apex_DDP.named_parameters", "Apex_DDP.named_parameters", "all", "common.metrics.pretrain_metrics.MLMAccuracyGlobal", "common.metrics.pretrain_metrics.MLMAccuracyGlobal", "int", "int", "int", "str", "str", "len", "len", "config.GPUS.split", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.create_logger.create_logger", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.trainer.train", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.summary_parameters", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.add", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.add", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.load.smart_resume", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.summary_parameters", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_dataloaders", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_dataloaders", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_dataloader", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_dataloader", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_dataloaders", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_dataloaders", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_dataloader", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_dataloader", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.load.smart_hybrid_partial_load_model_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.load.smart_skip_partial_load_model_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.load.smart_partial_load_model_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict"], ["", "def", "train_net", "(", "args", ",", "config", ")", ":", "\n", "# setup logger", "\n", "    ", "logger", ",", "final_output_path", "=", "create_logger", "(", "config", ".", "OUTPUT_PATH", ",", "\n", "args", ".", "cfg", ",", "\n", "config", ".", "DATASET", "[", "0", "]", ".", "TRAIN_IMAGE_SET", "if", "isinstance", "(", "config", ".", "DATASET", ",", "list", ")", "\n", "else", "config", ".", "DATASET", ".", "TRAIN_IMAGE_SET", ",", "\n", "split", "=", "'train'", ")", "\n", "model_prefix", "=", "os", ".", "path", ".", "join", "(", "final_output_path", ",", "config", ".", "MODEL_PREFIX", ")", "\n", "if", "args", ".", "log_dir", "is", "None", ":", "\n", "        ", "args", ".", "log_dir", "=", "os", ".", "path", ".", "join", "(", "final_output_path", ",", "'tensorboard_logs'", ")", "\n", "\n", "", "pprint", ".", "pprint", "(", "args", ")", "\n", "logger", ".", "info", "(", "'training args:{}\\n'", ".", "format", "(", "args", ")", ")", "\n", "pprint", ".", "pprint", "(", "config", ")", "\n", "logger", ".", "info", "(", "'training config:{}\\n'", ".", "format", "(", "pprint", ".", "pformat", "(", "config", ")", ")", ")", "\n", "\n", "# manually set random seed", "\n", "if", "config", ".", "RNG_SEED", ">", "-", "1", ":", "\n", "        ", "random", ".", "seed", "(", "config", ".", "RNG_SEED", ")", "\n", "np", ".", "random", ".", "seed", "(", "config", ".", "RNG_SEED", ")", "\n", "torch", ".", "random", ".", "manual_seed", "(", "config", ".", "RNG_SEED", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "config", ".", "RNG_SEED", ")", "\n", "\n", "# cudnn", "\n", "", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "if", "args", ".", "cudnn_off", ":", "\n", "        ", "torch", ".", "backends", ".", "cudnn", ".", "enabled", "=", "False", "\n", "\n", "", "if", "args", ".", "dist", ":", "\n", "        ", "model", "=", "eval", "(", "config", ".", "MODULE", ")", "(", "config", ")", "\n", "local_rank", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "'LOCAL_RANK'", ")", "or", "0", ")", "\n", "config", ".", "GPUS", "=", "str", "(", "local_rank", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "local_rank", ")", "\n", "master_address", "=", "os", ".", "environ", "[", "'MASTER_ADDR'", "]", "\n", "master_port", "=", "int", "(", "os", ".", "environ", "[", "'MASTER_PORT'", "]", "or", "23456", ")", "\n", "master_port", "=", "int", "(", "9994", ")", "\n", "master_port", "=", "int", "(", "10008", ")", "\n", "world_size", "=", "int", "(", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", "or", "1", ")", "\n", "rank", "=", "int", "(", "os", ".", "environ", "[", "'RANK'", "]", "or", "0", ")", "\n", "if", "args", ".", "slurm", ":", "\n", "            ", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "", "else", ":", "\n", "            ", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "'nccl'", ",", "\n", "init_method", "=", "'tcp://{}:{}'", ".", "format", "(", "master_address", ",", "master_port", ")", ",", "\n", "world_size", "=", "world_size", ",", "\n", "rank", "=", "rank", ",", "\n", "group_name", "=", "'mtorch'", ")", "\n", "", "print", "(", "\n", "f'native distributed, size: {world_size}, rank: {rank}, local rank: {local_rank}'", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "local_rank", ")", "\n", "config", ".", "GPUS", "=", "str", "(", "local_rank", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "if", "not", "config", ".", "TRAIN", ".", "FP16", ":", "\n", "            ", "model", "=", "DDP", "(", "model", ",", "find_unused_parameters", "=", "True", ",", "device_ids", "=", "[", "\n", "local_rank", "]", ",", "output_device", "=", "local_rank", ")", "\n", "\n", "", "if", "rank", "==", "0", ":", "\n", "            ", "summary_parameters", "(", "model", ".", "module", "if", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", ")", "else", "model", ",", "\n", "logger", ")", "\n", "shutil", ".", "copy", "(", "args", ".", "cfg", ",", "final_output_path", ")", "\n", "shutil", ".", "copy", "(", "inspect", ".", "getfile", "(", "\n", "eval", "(", "config", ".", "MODULE", ")", ")", ",", "final_output_path", ")", "\n", "\n", "", "writer", "=", "None", "\n", "if", "args", ".", "log_dir", "is", "not", "None", ":", "\n", "            ", "tb_log_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "log_dir", ",", "'rank{}'", ".", "format", "(", "rank", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "tb_log_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "tb_log_dir", ")", "\n", "", "writer", "=", "SummaryWriter", "(", "log_dir", "=", "tb_log_dir", ")", "\n", "\n", "", "if", "isinstance", "(", "config", ".", "DATASET", ",", "list", ")", ":", "\n", "            ", "train_loaders_and_samplers", "=", "make_dataloaders", "(", "config", ",", "\n", "mode", "=", "'train'", ",", "\n", "distributed", "=", "True", ",", "\n", "num_replicas", "=", "world_size", ",", "\n", "rank", "=", "rank", ",", "\n", "expose_sampler", "=", "True", ")", "\n", "val_loaders", "=", "make_dataloaders", "(", "config", ",", "\n", "mode", "=", "'val'", ",", "\n", "distributed", "=", "True", ",", "\n", "num_replicas", "=", "world_size", ",", "\n", "rank", "=", "rank", ")", "\n", "train_loader", "=", "MultiTaskDataLoader", "(", "\n", "[", "loader", "for", "loader", ",", "_", "in", "train_loaders_and_samplers", "]", ")", "\n", "val_loader", "=", "MultiTaskDataLoader", "(", "val_loaders", ")", "\n", "train_sampler", "=", "train_loaders_and_samplers", "[", "0", "]", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "train_loader", ",", "train_sampler", "=", "make_dataloader", "(", "config", ",", "\n", "mode", "=", "'train'", ",", "\n", "distributed", "=", "True", ",", "\n", "num_replicas", "=", "world_size", ",", "\n", "rank", "=", "rank", ",", "\n", "expose_sampler", "=", "True", ")", "\n", "val_loader", "=", "make_dataloader", "(", "config", ",", "\n", "mode", "=", "'val'", ",", "\n", "distributed", "=", "True", ",", "\n", "num_replicas", "=", "world_size", ",", "\n", "rank", "=", "rank", ")", "\n", "\n", "", "batch_size", "=", "world_size", "*", "(", "sum", "(", "config", ".", "TRAIN", ".", "BATCH_IMAGES", ")", "\n", "if", "isinstance", "(", "config", ".", "TRAIN", ".", "BATCH_IMAGES", ",", "list", ")", "\n", "else", "config", ".", "TRAIN", ".", "BATCH_IMAGES", ")", "\n", "if", "config", ".", "TRAIN", ".", "GRAD_ACCUMULATE_STEPS", ">", "1", ":", "\n", "            ", "batch_size", "=", "batch_size", "*", "config", ".", "TRAIN", ".", "GRAD_ACCUMULATE_STEPS", "\n", "", "base_lr", "=", "config", ".", "TRAIN", ".", "LR", "*", "batch_size", "\n", "optimizer_grouped_parameters", "=", "[", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "_k", "in", "n", "]", ",", "\n", "'lr'", ":", "base_lr", "*", "_lr_mult", "}", "\n", "for", "_k", ",", "_lr_mult", "in", "config", ".", "TRAIN", ".", "LR_MULT", "]", "\n", "optimizer_grouped_parameters", ".", "append", "(", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "all", "(", "[", "_k", "not", "in", "n", "for", "_k", ",", "_", "in", "config", ".", "TRAIN", ".", "LR_MULT", "]", ")", "]", "}", ")", "\n", "if", "config", ".", "TRAIN", ".", "OPTIMIZER", "==", "'SGD'", ":", "\n", "            ", "optimizer", "=", "optim", ".", "SGD", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "config", ".", "TRAIN", ".", "LR", "*", "batch_size", ",", "\n", "momentum", "=", "config", ".", "TRAIN", ".", "MOMENTUM", ",", "\n", "weight_decay", "=", "config", ".", "TRAIN", ".", "WD", ")", "\n", "", "elif", "config", ".", "TRAIN", ".", "OPTIMIZER", "==", "'Adam'", ":", "\n", "            ", "optimizer", "=", "optim", ".", "Adam", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "config", ".", "TRAIN", ".", "LR", "*", "batch_size", ",", "\n", "weight_decay", "=", "config", ".", "TRAIN", ".", "WD", ")", "\n", "", "elif", "config", ".", "TRAIN", ".", "OPTIMIZER", "==", "'AdamW'", ":", "\n", "            ", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "config", ".", "TRAIN", ".", "LR", "*", "batch_size", ",", "\n", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "\n", "eps", "=", "1e-6", ",", "\n", "weight_decay", "=", "config", ".", "TRAIN", ".", "WD", ",", "\n", "correct_bias", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Not support optimizer {}!'", ".", "format", "(", "\n", "config", ".", "TRAIN", ".", "OPTIMIZER", ")", ")", "\n", "", "total_gpus", "=", "world_size", "\n", "\n", "", "else", ":", "\n", "#os.environ['CUDA_VISIBLE_DEVICES'] = config.GPUS", "\n", "        ", "model", "=", "eval", "(", "config", ".", "MODULE", ")", "(", "config", ")", "\n", "summary_parameters", "(", "model", ",", "logger", ")", "\n", "shutil", ".", "copy", "(", "args", ".", "cfg", ",", "final_output_path", ")", "\n", "shutil", ".", "copy", "(", "inspect", ".", "getfile", "(", "eval", "(", "config", ".", "MODULE", ")", ")", ",", "final_output_path", ")", "\n", "num_gpus", "=", "len", "(", "config", ".", "GPUS", ".", "split", "(", "','", ")", ")", "\n", "assert", "num_gpus", "<=", "1", "or", "(", "not", "config", ".", "TRAIN", ".", "FP16", ")", ",", "\"Not support fp16 with torch.nn.DataParallel. \"", "\"Please use amp.parallel.DistributedDataParallel instead.\"", "\n", "total_gpus", "=", "num_gpus", "\n", "rank", "=", "None", "\n", "writer", "=", "SummaryWriter", "(", "\n", "log_dir", "=", "args", ".", "log_dir", ")", "if", "args", ".", "log_dir", "is", "not", "None", "else", "None", "\n", "\n", "# model", "\n", "if", "num_gpus", ">", "1", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "int", "(", "d", ")", "for", "d", "in", "config", ".", "GPUS", ".", "split", "(", "','", ")", "]", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "int", "(", "config", ".", "GPUS", ")", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "\n", "# loader", "\n", "", "if", "isinstance", "(", "config", ".", "DATASET", ",", "list", ")", ":", "\n", "            ", "train_loaders", "=", "make_dataloaders", "(", "\n", "config", ",", "mode", "=", "'train'", ",", "distributed", "=", "False", ")", "\n", "val_loaders", "=", "make_dataloaders", "(", "\n", "config", ",", "mode", "=", "'val'", ",", "distributed", "=", "False", ")", "\n", "train_loader", "=", "MultiTaskDataLoader", "(", "train_loaders", ")", "\n", "val_loader", "=", "MultiTaskDataLoader", "(", "val_loaders", ")", "\n", "", "else", ":", "\n", "            ", "train_loader", "=", "make_dataloader", "(", "\n", "config", ",", "mode", "=", "'train'", ",", "distributed", "=", "False", ")", "\n", "val_loader", "=", "make_dataloader", "(", "config", ",", "mode", "=", "'val'", ",", "distributed", "=", "False", ")", "\n", "", "train_sampler", "=", "None", "\n", "\n", "batch_size", "=", "num_gpus", "*", "(", "sum", "(", "config", ".", "TRAIN", ".", "BATCH_IMAGES", ")", "if", "isinstance", "(", "config", ".", "TRAIN", ".", "BATCH_IMAGES", ",", "list", ")", "\n", "else", "config", ".", "TRAIN", ".", "BATCH_IMAGES", ")", "\n", "if", "config", ".", "TRAIN", ".", "GRAD_ACCUMULATE_STEPS", ">", "1", ":", "\n", "            ", "batch_size", "=", "batch_size", "*", "config", ".", "TRAIN", ".", "GRAD_ACCUMULATE_STEPS", "\n", "", "base_lr", "=", "config", ".", "TRAIN", ".", "LR", "*", "batch_size", "\n", "optimizer_grouped_parameters", "=", "[", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "_k", "in", "n", "]", ",", "\n", "'lr'", ":", "base_lr", "*", "_lr_mult", "}", "\n", "for", "_k", ",", "_lr_mult", "in", "config", ".", "TRAIN", ".", "LR_MULT", "]", "\n", "optimizer_grouped_parameters", ".", "append", "(", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "all", "(", "[", "_k", "not", "in", "n", "for", "_k", ",", "_", "in", "config", ".", "TRAIN", ".", "LR_MULT", "]", ")", "]", "}", ")", "\n", "\n", "if", "config", ".", "TRAIN", ".", "OPTIMIZER", "==", "'SGD'", ":", "\n", "            ", "optimizer", "=", "optim", ".", "SGD", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "config", ".", "TRAIN", ".", "LR", "*", "batch_size", ",", "\n", "momentum", "=", "config", ".", "TRAIN", ".", "MOMENTUM", ",", "\n", "weight_decay", "=", "config", ".", "TRAIN", ".", "WD", ")", "\n", "", "elif", "config", ".", "TRAIN", ".", "OPTIMIZER", "==", "'Adam'", ":", "\n", "            ", "optimizer", "=", "optim", ".", "Adam", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "config", ".", "TRAIN", ".", "LR", "*", "batch_size", ",", "\n", "weight_decay", "=", "config", ".", "TRAIN", ".", "WD", ")", "\n", "", "elif", "config", ".", "TRAIN", ".", "OPTIMIZER", "==", "'AdamW'", ":", "\n", "            ", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "config", ".", "TRAIN", ".", "LR", "*", "batch_size", ",", "\n", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "\n", "eps", "=", "1e-6", ",", "\n", "weight_decay", "=", "config", ".", "TRAIN", ".", "WD", ",", "\n", "correct_bias", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Not support optimizer {}!'", ".", "format", "(", "\n", "config", ".", "TRAIN", ".", "OPTIMIZER", ")", ")", "\n", "\n", "# partial load pretrain state dict", "\n", "", "", "if", "config", ".", "NETWORK", ".", "PARTIAL_PRETRAIN", "!=", "\"\"", ":", "\n", "        ", "pretrain_state_dict", "=", "torch", ".", "load", "(", "\n", "config", ".", "NETWORK", ".", "PARTIAL_PRETRAIN", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "[", "'state_dict'", "]", "\n", "prefix_change", "=", "[", "prefix_change", ".", "split", "(", "\n", "'->'", ")", "for", "prefix_change", "in", "config", ".", "NETWORK", ".", "PARTIAL_PRETRAIN_PREFIX_CHANGES", "]", "\n", "if", "len", "(", "prefix_change", ")", ">", "0", ":", "\n", "            ", "pretrain_state_dict_parsed", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "pretrain_state_dict", ".", "items", "(", ")", ":", "\n", "                ", "no_match", "=", "True", "\n", "for", "pretrain_prefix", ",", "new_prefix", "in", "prefix_change", ":", "\n", "                    ", "if", "k", ".", "startswith", "(", "pretrain_prefix", ")", ":", "\n", "                        ", "k", "=", "new_prefix", "+", "k", "[", "len", "(", "pretrain_prefix", ")", ":", "]", "\n", "pretrain_state_dict_parsed", "[", "k", "]", "=", "v", "\n", "no_match", "=", "False", "\n", "break", "\n", "", "", "if", "no_match", ":", "\n", "                    ", "pretrain_state_dict_parsed", "[", "k", "]", "=", "v", "\n", "", "", "pretrain_state_dict", "=", "pretrain_state_dict_parsed", "\n", "# FM edit: introduce alternative initialisations", "\n", "", "if", "config", ".", "NETWORK", ".", "INITIALISATION", "==", "'hybrid'", ":", "\n", "            ", "smart_hybrid_partial_load_model_state_dict", "(", "\n", "model", ",", "pretrain_state_dict", ")", "\n", "", "elif", "config", ".", "NETWORK", ".", "INITIALISATION", "==", "'skip'", ":", "\n", "            ", "smart_skip_partial_load_model_state_dict", "(", "\n", "model", ",", "pretrain_state_dict", ")", "\n", "", "else", ":", "\n", "            ", "smart_partial_load_model_state_dict", "(", "model", ",", "pretrain_state_dict", ")", "\n", "\n", "# metrics", "\n", "", "", "metric_kwargs", "=", "{", "'allreduce'", ":", "args", ".", "dist", ",", "\n", "'num_replicas'", ":", "world_size", "if", "args", ".", "dist", "else", "1", "}", "\n", "train_metrics_list", "=", "[", "]", "\n", "val_metrics_list", "=", "[", "]", "\n", "if", "config", ".", "NETWORK", ".", "WITH_REL_LOSS", ":", "\n", "        ", "train_metrics_list", ".", "append", "(", "\n", "pretrain_metrics", ".", "RelationshipAccuracy", "(", "**", "metric_kwargs", ")", ")", "\n", "val_metrics_list", ".", "append", "(", "\n", "pretrain_metrics", ".", "RelationshipAccuracy", "(", "**", "metric_kwargs", ")", ")", "\n", "", "if", "config", ".", "NETWORK", ".", "WITH_MLM_LOSS", ":", "\n", "        ", "if", "config", ".", "MODULE", "==", "'ResNetVLBERTForPretrainingMultitask'", ":", "\n", "            ", "train_metrics_list", ".", "append", "(", "\n", "pretrain_metrics", ".", "MLMAccuracyDataset1", "(", "**", "metric_kwargs", ")", ")", "\n", "train_metrics_list", ".", "append", "(", "\n", "pretrain_metrics", ".", "MLMAccuracyDataset2", "(", "**", "metric_kwargs", ")", ")", "\n", "train_metrics_list", ".", "append", "(", "\n", "pretrain_metrics", ".", "MLMAccuracyDataset3", "(", "**", "metric_kwargs", ")", ")", "\n", "val_metrics_list", ".", "append", "(", "\n", "pretrain_metrics", ".", "MLMAccuracyDataset1", "(", "**", "metric_kwargs", ")", ")", "\n", "val_metrics_list", ".", "append", "(", "\n", "pretrain_metrics", ".", "MLMAccuracyDataset2", "(", "**", "metric_kwargs", ")", ")", "\n", "val_metrics_list", ".", "append", "(", "\n", "pretrain_metrics", ".", "MLMAccuracyDataset3", "(", "**", "metric_kwargs", ")", ")", "\n", "", "elif", "config", ".", "MODULE", "==", "'BERTGENMultitaskTraining'", ":", "\n", "            ", "num_metric", "=", "1", "\n", "try", ":", "\n", "                ", "num_metric", "=", "len", "(", "config", ".", "TRAIN", ".", "BATCH_IMAGES", ")", "\n", "", "except", ":", "\n", "                ", "num_metric", "=", "1", "\n", "", "for", "i", "in", "range", "(", "num_metric", ")", ":", "\n", "                ", "train_metrics_list", ".", "append", "(", "pretrain_metrics", ".", "MLMAccuracyGlobal", "(", "\n", "**", "metric_kwargs", ",", "eval_name", "=", "str", "(", "i", ")", ")", ")", "\n", "val_metrics_list", ".", "append", "(", "pretrain_metrics", ".", "MLMAccuracyGlobal", "(", "\n", "**", "metric_kwargs", ",", "eval_name", "=", "str", "(", "i", ")", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "train_metrics_list", ".", "append", "(", "\n", "pretrain_metrics", ".", "MLMAccuracy", "(", "**", "metric_kwargs", ")", ")", "\n", "val_metrics_list", ".", "append", "(", "\n", "pretrain_metrics", ".", "MLMAccuracy", "(", "**", "metric_kwargs", ")", ")", "\n", "", "", "if", "config", ".", "NETWORK", ".", "WITH_MVRC_LOSS", ":", "\n", "        ", "train_metrics_list", ".", "append", "(", "\n", "pretrain_metrics", ".", "MVRCAccuracy", "(", "**", "metric_kwargs", ")", ")", "\n", "val_metrics_list", ".", "append", "(", "pretrain_metrics", ".", "MVRCAccuracy", "(", "**", "metric_kwargs", ")", ")", "\n", "", "for", "output_name", ",", "display_name", "in", "config", ".", "TRAIN", ".", "LOSS_LOGGERS", ":", "\n", "        ", "train_metrics_list", ".", "append", "(", "pretrain_metrics", ".", "LossLogger", "(", "\n", "output_name", ",", "display_name", "=", "display_name", ",", "**", "metric_kwargs", ")", ")", "\n", "val_metrics_list", ".", "append", "(", "pretrain_metrics", ".", "LossLogger", "(", "\n", "output_name", ",", "display_name", "=", "display_name", ",", "**", "metric_kwargs", ")", ")", "\n", "\n", "", "train_metrics", "=", "CompositeEvalMetric", "(", ")", "\n", "val_metrics", "=", "CompositeEvalMetric", "(", ")", "\n", "for", "child_metric", "in", "train_metrics_list", ":", "\n", "        ", "train_metrics", ".", "add", "(", "child_metric", ")", "\n", "", "for", "child_metric", "in", "val_metrics_list", ":", "\n", "        ", "val_metrics", ".", "add", "(", "child_metric", ")", "\n", "\n", "# epoch end callbacks", "\n", "", "epoch_end_callbacks", "=", "[", "]", "\n", "if", "(", "rank", "is", "None", ")", "or", "(", "rank", "==", "0", ")", ":", "\n", "        ", "epoch_end_callbacks", "=", "[", "Checkpoint", "(", "\n", "model_prefix", ",", "config", ".", "CHECKPOINT_FREQUENT", ")", "]", "\n", "", "host_metric_name", "=", "'MLMAcc'", "if", "not", "config", ".", "MODULE", "==", "'ResNetVLBERTForPretrainingMultitask'", "else", "'MLMAccWVC'", "\n", "validation_monitor", "=", "ValidationMonitor", "(", "do_validation", ",", "val_loader", ",", "val_metrics", ",", "\n", "host_metric_name", "=", "host_metric_name", ")", "\n", "\n", "# optimizer initial lr before", "\n", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "group", ".", "setdefault", "(", "'initial_lr'", ",", "group", "[", "'lr'", "]", ")", "\n", "\n", "# resume/auto-resume", "\n", "", "if", "rank", "is", "None", "or", "rank", "==", "0", ":", "\n", "        ", "smart_resume", "(", "model", ",", "optimizer", ",", "validation_monitor", ",", "\n", "config", ",", "model_prefix", ",", "logger", ")", "\n", "", "if", "args", ".", "dist", ":", "\n", "        ", "begin_epoch", "=", "torch", ".", "tensor", "(", "config", ".", "TRAIN", ".", "BEGIN_EPOCH", ")", ".", "cuda", "(", ")", "\n", "distributed", ".", "broadcast", "(", "begin_epoch", ",", "src", "=", "0", ")", "\n", "config", ".", "TRAIN", ".", "BEGIN_EPOCH", "=", "begin_epoch", ".", "item", "(", ")", "\n", "\n", "# batch end callbacks", "\n", "", "batch_size", "=", "len", "(", "config", ".", "GPUS", ".", "split", "(", "','", ")", ")", "*", "(", "sum", "(", "config", ".", "TRAIN", ".", "BATCH_IMAGES", ")", "\n", "if", "isinstance", "(", "config", ".", "TRAIN", ".", "BATCH_IMAGES", ",", "list", ")", "\n", "else", "config", ".", "TRAIN", ".", "BATCH_IMAGES", ")", "\n", "batch_end_callbacks", "=", "[", "Speedometer", "(", "batch_size", ",", "config", ".", "LOG_FREQUENT", ",", "\n", "batches_per_epoch", "=", "len", "(", "train_loader", ")", ",", "\n", "epochs", "=", "config", ".", "TRAIN", ".", "END_EPOCH", "-", "config", ".", "TRAIN", ".", "BEGIN_EPOCH", ")", "]", "\n", "\n", "# setup lr step and lr scheduler", "\n", "if", "config", ".", "TRAIN", ".", "LR_SCHEDULE", "==", "'plateau'", ":", "\n", "        ", "print", "(", "\"Warning: not support resuming on plateau lr schedule!\"", ")", "\n", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "\n", "mode", "=", "'max'", ",", "\n", "factor", "=", "config", ".", "TRAIN", ".", "LR_FACTOR", ",", "\n", "patience", "=", "1", ",", "\n", "verbose", "=", "True", ",", "\n", "threshold", "=", "1e-4", ",", "\n", "threshold_mode", "=", "'rel'", ",", "\n", "cooldown", "=", "2", ",", "\n", "min_lr", "=", "0", ",", "\n", "eps", "=", "1e-8", ")", "\n", "", "elif", "config", ".", "TRAIN", ".", "LR_SCHEDULE", "==", "'triangle'", ":", "\n", "# FM edit: i am using here the new optimizer so that i can tweek the LR when i resume a model (not the best solution)", "\n", "# but this fix was so that  i can extend the number of epochs.", "\n", "        ", "lr_scheduler", "=", "WarmupLinearSchedule", "(", "optimizer", ",", "\n", "config", ".", "TRAIN", ".", "WARMUP_STEPS", "if", "config", ".", "TRAIN", ".", "WARMUP", "else", "0", ",", "\n", "t_total", "=", "int", "(", "\n", "config", ".", "TRAIN", ".", "END_EPOCH", "*", "len", "(", "train_loader", ")", "/", "config", ".", "TRAIN", ".", "GRAD_ACCUMULATE_STEPS", ")", ",", "\n", "last_epoch", "=", "int", "(", "config", ".", "TRAIN", ".", "BEGIN_EPOCH", "*", "len", "(", "train_loader", ")", "/", "config", ".", "TRAIN", ".", "GRAD_ACCUMULATE_STEPS", ")", "-", "1", ")", "\n", "", "elif", "config", ".", "TRAIN", ".", "LR_SCHEDULE", "==", "'step'", ":", "\n", "        ", "lr_iters", "=", "[", "int", "(", "epoch", "*", "len", "(", "train_loader", ")", "/", "config", ".", "TRAIN", ".", "GRAD_ACCUMULATE_STEPS", ")", "\n", "for", "epoch", "in", "config", ".", "TRAIN", ".", "LR_STEP", "]", "\n", "lr_scheduler", "=", "WarmupMultiStepLR", "(", "optimizer", ",", "milestones", "=", "lr_iters", ",", "gamma", "=", "config", ".", "TRAIN", ".", "LR_FACTOR", ",", "\n", "warmup_factor", "=", "config", ".", "TRAIN", ".", "WARMUP_FACTOR", ",", "\n", "warmup_iters", "=", "config", ".", "TRAIN", ".", "WARMUP_STEPS", "if", "config", ".", "TRAIN", ".", "WARMUP", "else", "0", ",", "\n", "warmup_method", "=", "config", ".", "TRAIN", ".", "WARMUP_METHOD", ",", "\n", "last_epoch", "=", "int", "(", "config", ".", "TRAIN", ".", "BEGIN_EPOCH", "*", "len", "(", "train_loader", ")", "/", "config", ".", "TRAIN", ".", "GRAD_ACCUMULATE_STEPS", ")", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Not support lr schedule: {}.\"", ".", "format", "(", "\n", "config", ".", "TRAIN", ".", "LR_SCHEDULE", ")", ")", "\n", "\n", "# broadcast parameter and optimizer state from rank 0 before training start", "\n", "", "if", "args", ".", "dist", ":", "\n", "        ", "for", "v", "in", "model", ".", "state_dict", "(", ")", ".", "values", "(", ")", ":", "\n", "            ", "distributed", ".", "broadcast", "(", "v", ",", "src", "=", "0", ")", "\n", "# for v in optimizer.state_dict().values():", "\n", "#     distributed.broadcast(v, src=0)", "\n", "", "best_epoch", "=", "torch", ".", "tensor", "(", "validation_monitor", ".", "best_epoch", ")", ".", "cuda", "(", ")", "\n", "best_val", "=", "torch", ".", "tensor", "(", "validation_monitor", ".", "best_val", ")", ".", "cuda", "(", ")", "\n", "distributed", ".", "broadcast", "(", "best_epoch", ",", "src", "=", "0", ")", "\n", "distributed", ".", "broadcast", "(", "best_val", ",", "src", "=", "0", ")", "\n", "validation_monitor", ".", "best_epoch", "=", "best_epoch", ".", "item", "(", ")", "\n", "validation_monitor", ".", "best_val", "=", "best_val", ".", "item", "(", ")", "\n", "\n", "# apex: amp fp16 mixed-precision training", "\n", "", "if", "config", ".", "TRAIN", ".", "FP16", ":", "\n", "# model.apply(bn_fp16_half_eval)", "\n", "        ", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "\n", "opt_level", "=", "'O2'", ",", "\n", "keep_batchnorm_fp32", "=", "False", ",", "\n", "loss_scale", "=", "config", ".", "TRAIN", ".", "FP16_LOSS_SCALE", ",", "\n", "max_loss_scale", "=", "128.0", ",", "\n", "min_loss_scale", "=", "128.0", ")", "\n", "if", "args", ".", "dist", ":", "\n", "            ", "model", "=", "Apex_DDP", "(", "model", ",", "delay_allreduce", "=", "True", ")", "\n", "\n", "", "", "train", "(", "model", ",", "optimizer", ",", "lr_scheduler", ",", "train_loader", ",", "train_sampler", ",", "train_metrics", ",", "\n", "config", ".", "TRAIN", ".", "BEGIN_EPOCH", ",", "config", ".", "TRAIN", ".", "END_EPOCH", ",", "logger", ",", "\n", "rank", "=", "rank", ",", "batch_end_callbacks", "=", "batch_end_callbacks", ",", "epoch_end_callbacks", "=", "epoch_end_callbacks", ",", "\n", "writer", "=", "writer", ",", "validation_monitor", "=", "validation_monitor", ",", "fp16", "=", "config", ".", "TRAIN", ".", "FP16", ",", "\n", "clip_grad_norm", "=", "config", ".", "TRAIN", ".", "CLIP_GRAD_NORM", ",", "\n", "gradient_accumulate_steps", "=", "config", ".", "TRAIN", ".", "GRAD_ACCUMULATE_STEPS", ")", "\n", "\n", "return", "rank", ",", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.function.val.do_validation": [[6, 14], ["torch.no_grad", "net.eval", "metrics.reset", "enumerate", "common.trainer.to_cuda", "net", "metrics.update"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.reset", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.trainer.to_cuda", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update"], ["@", "torch", ".", "no_grad", "(", ")", "\n", "def", "do_validation", "(", "net", ",", "val_loader", ",", "metrics", ",", "label_index_in_batch", ")", ":", "\n", "    ", "net", ".", "eval", "(", ")", "\n", "metrics", ".", "reset", "(", ")", "\n", "for", "nbatch", ",", "batch", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "        ", "batch", "=", "to_cuda", "(", "batch", ")", "\n", "outputs", ",", "_", "=", "net", "(", "*", "batch", ")", "\n", "metrics", ".", "update", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.function.test.test_net": [[24, 109], ["torch.no_grad", "torch.no_grad", "print", "pprint.pprint", "pprint.pprint", "shutil.copy2", "torch.load", "torch.load", "common.utils.load.smart_load_model_state_dict", "LanguageGeneration.data.build.make_dataloader", "model.cuda.eval", "zip", "os.path.join", "print", "int", "common.utils.create_logger.create_logger", "os.path.join", "print", "common.utils.create_logger.create_logger", "os.path.exists", "os.makedirs", "os.path.join", "eval", "len", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.cuda.set_device", "torch.cuda.set_device", "model.cuda.cuda", "tqdm.trange", "common.trainer.to_cuda", "model.cuda.", "generated_sentences.extend", "os.path.splitext", "open", "config.GPUS.split", "len", "os.path.basename", "f.write", "torch.nn.DataParallel", "torch.nn.DataParallel"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.load.smart_load_model_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_dataloader", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.create_logger.create_logger", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.create_logger.create_logger", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.trainer.to_cuda"], ["\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "cfg", "is", "not", "None", ":", "\n", "        ", "update_config", "(", "args", ".", "cfg", ")", "\n", "", "if", "args", ".", "bs", "is", "not", "None", ":", "\n", "        ", "config", ".", "TEST", ".", "BATCH_IMAGES", "=", "args", ".", "bs", "\n", "", "if", "args", ".", "gpus", "is", "not", "None", ":", "\n", "        ", "config", ".", "GPUS", "=", "','", ".", "join", "(", "[", "str", "(", "gpu", ")", "for", "gpu", "in", "args", ".", "gpus", "]", ")", "\n", "", "if", "args", ".", "split", "is", "not", "None", ":", "\n", "        ", "config", ".", "DATASET", ".", "TEST_IMAGE_SET", "=", "args", ".", "split", "\n", "", "if", "args", ".", "model_dir", "is", "not", "None", ":", "\n", "        ", "config", ".", "OUTPUT_PATH", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_dir", ",", "config", ".", "OUTPUT_PATH", ")", "\n", "\n", "", "return", "args", ",", "config", "\n", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "args", ",", "config", "=", "parse_args", "(", ")", "\n", "result_json_path", "=", "test_net", "(", "args", ",", "config", ",", "\n", "ckpt_path", "=", "args", ".", "ckpt", ",", "save_path", "=", "args", ".", "result_path", ",", "save_name", "=", "args", ".", "result_name", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.function.vis.vis_net": [[23, 114], ["pprint.pprint", "vis.vis", "int", "str", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "int", "int", "int", "print", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "str", "torch.nn.DataParallel().cuda.cuda", "torch.nn.parallel.DistributedDataParallel", "isinstance", "len", "isinstance", "common.utils.load.smart_partial_load_model_state_dict", "torch.nn.DataParallel().cuda.state_dict().values", "eval", "torch.init_process_group", "torch.init_process_group", "LanguageGeneration.data.build.make_dataloaders", "common.utils.multi_task_dataloader.MultiTaskDataLoader", "LanguageGeneration.data.build.make_dataloader", "eval", "config.GPUS.split", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.nn.DataParallel().cuda.cuda", "LanguageGeneration.data.build.make_dataloaders", "common.utils.multi_task_dataloader.MultiTaskDataLoader", "LanguageGeneration.data.build.make_dataloader", "torch.load", "torch.load", "torch.load", "prefix_change.split", "len", "pretrain_state_dict.items", "torch.broadcast", "os.environ.get", "int", "torch.nn.DataParallel().cuda.state_dict", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "k.startswith", "int", "config.GPUS.split", "len"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.function.vis.vis", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.load.smart_partial_load_model_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_dataloaders", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_dataloader", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_dataloaders", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.data.build.make_dataloader", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict"], ["def", "vis_net", "(", "args", ",", "config", ",", "save_dir", ")", ":", "\n", "    ", "pprint", ".", "pprint", "(", "config", ")", "\n", "\n", "if", "args", ".", "dist", ":", "\n", "        ", "model", "=", "eval", "(", "config", ".", "MODULE", ")", "(", "config", ")", "\n", "local_rank", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "'LOCAL_RANK'", ")", "or", "0", ")", "\n", "config", ".", "GPUS", "=", "str", "(", "local_rank", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "local_rank", ")", "\n", "master_address", "=", "os", ".", "environ", "[", "'MASTER_ADDR'", "]", "\n", "master_port", "=", "int", "(", "os", ".", "environ", "[", "'MASTER_PORT'", "]", "or", "23456", ")", "\n", "world_size", "=", "int", "(", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", "or", "1", ")", "\n", "rank", "=", "int", "(", "os", ".", "environ", "[", "'RANK'", "]", "or", "0", ")", "\n", "if", "args", ".", "slurm", ":", "\n", "            ", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "", "else", ":", "\n", "            ", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "'nccl'", ",", "\n", "init_method", "=", "'tcp://{}:{}'", ".", "format", "(", "master_address", ",", "master_port", ")", ",", "\n", "world_size", "=", "world_size", ",", "\n", "rank", "=", "rank", ",", "\n", "group_name", "=", "'mtorch'", ")", "\n", "", "print", "(", "\n", "f'native distributed, size: {world_size}, rank: {rank}, local rank: {local_rank}'", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "local_rank", ")", "\n", "config", ".", "GPUS", "=", "str", "(", "local_rank", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "model", "=", "DDP", "(", "model", ",", "device_ids", "=", "[", "local_rank", "]", ",", "output_device", "=", "local_rank", ")", "\n", "\n", "if", "isinstance", "(", "config", ".", "DATASET", ",", "list", ")", ":", "\n", "            ", "val_loaders", "=", "make_dataloaders", "(", "config", ",", "\n", "mode", "=", "'val'", ",", "\n", "distributed", "=", "True", ",", "\n", "num_replicas", "=", "world_size", ",", "\n", "rank", "=", "rank", ")", "\n", "val_loader", "=", "MultiTaskDataLoader", "(", "val_loaders", ")", "\n", "", "else", ":", "\n", "            ", "val_loader", "=", "make_dataloader", "(", "config", ",", "\n", "mode", "=", "'val'", ",", "\n", "distributed", "=", "True", ",", "\n", "num_replicas", "=", "world_size", ",", "\n", "rank", "=", "rank", ")", "\n", "", "", "else", ":", "\n", "        ", "model", "=", "eval", "(", "config", ".", "MODULE", ")", "(", "config", ")", "\n", "num_gpus", "=", "len", "(", "config", ".", "GPUS", ".", "split", "(", "','", ")", ")", "\n", "rank", "=", "None", "\n", "# model", "\n", "if", "num_gpus", ">", "1", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "int", "(", "d", ")", "for", "d", "in", "config", ".", "GPUS", ".", "split", "(", "','", ")", "]", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "int", "(", "config", ".", "GPUS", ")", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "\n", "# loader", "\n", "", "if", "isinstance", "(", "config", ".", "DATASET", ",", "list", ")", ":", "\n", "            ", "val_loaders", "=", "make_dataloaders", "(", "\n", "config", ",", "mode", "=", "'val'", ",", "distributed", "=", "False", ")", "\n", "val_loader", "=", "MultiTaskDataLoader", "(", "val_loaders", ")", "\n", "", "else", ":", "\n", "            ", "val_loader", "=", "make_dataloader", "(", "config", ",", "mode", "=", "'val'", ",", "distributed", "=", "False", ")", "\n", "\n", "# partial load pretrain state dict", "\n", "", "", "if", "config", ".", "NETWORK", ".", "PARTIAL_PRETRAIN", "!=", "\"\"", ":", "\n", "        ", "pretrain_state_dict", "=", "torch", ".", "load", "(", "\n", "config", ".", "NETWORK", ".", "PARTIAL_PRETRAIN", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "[", "'state_dict'", "]", "\n", "prefix_change", "=", "[", "prefix_change", ".", "split", "(", "\n", "'->'", ")", "for", "prefix_change", "in", "config", ".", "NETWORK", ".", "PARTIAL_PRETRAIN_PREFIX_CHANGES", "]", "\n", "if", "len", "(", "prefix_change", ")", ">", "0", ":", "\n", "            ", "pretrain_state_dict_parsed", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "pretrain_state_dict", ".", "items", "(", ")", ":", "\n", "                ", "no_match", "=", "True", "\n", "for", "pretrain_prefix", ",", "new_prefix", "in", "prefix_change", ":", "\n", "                    ", "if", "k", ".", "startswith", "(", "pretrain_prefix", ")", ":", "\n", "                        ", "k", "=", "new_prefix", "+", "k", "[", "len", "(", "pretrain_prefix", ")", ":", "]", "\n", "pretrain_state_dict_parsed", "[", "k", "]", "=", "v", "\n", "no_match", "=", "False", "\n", "break", "\n", "", "", "if", "no_match", ":", "\n", "                    ", "pretrain_state_dict_parsed", "[", "k", "]", "=", "v", "\n", "", "", "pretrain_state_dict", "=", "pretrain_state_dict_parsed", "\n", "", "smart_partial_load_model_state_dict", "(", "model", ",", "pretrain_state_dict", ")", "\n", "\n", "# broadcast parameter and optimizer state from rank 0 before training start", "\n", "", "if", "args", ".", "dist", ":", "\n", "        ", "for", "v", "in", "model", ".", "state_dict", "(", ")", ".", "values", "(", ")", ":", "\n", "            ", "distributed", ".", "broadcast", "(", "v", ",", "src", "=", "0", ")", "\n", "\n", "", "", "vis", "(", "model", ",", "val_loader", ",", "save_dir", ",", "rank", "=", "rank", ",", "\n", "world_size", "=", "world_size", "if", "args", ".", "dist", "else", "1", ")", "\n", "\n", "return", "rank", ",", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.function.vis.vis": [[116, 149], ["os.path.join", "os.path.join", "os.path.join", "model.eval", "zip", "os.path.exists", "common.utils.create_logger.makedirsExist", "tqdm.trange", "common.trainer.to_cuda", "model", "enumerate", "len", "zip", "int", "hasattr", "attention_probs.detach().cpu().numpy", "hidden_states.detach().cpu().numpy", "numpy.save", "os.path.join", "[].split", "attention_probs.detach().cpu", "hidden_states.detach().cpu", "attention_probs.detach", "hidden_states.detach", "[].split", "hidden_states.transpose"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.create_logger.makedirsExist", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.trainer.to_cuda"], ["", "def", "vis", "(", "model", ",", "loader", ",", "save_dir", ",", "rank", "=", "None", ",", "world_size", "=", "1", ")", ":", "\n", "    ", "attention_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'attention_probs'", ")", "\n", "hidden_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'hidden_states'", ")", "\n", "cos_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'cos_similarity'", ")", "\n", "# if not os.path.exists(hidden_dir):", "\n", "#     makedirsExist(hidden_dir)", "\n", "# if not os.path.exists(cos_dir):", "\n", "#     makedirsExist(cos_dir)", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "attention_dir", ")", ":", "\n", "        ", "makedirsExist", "(", "attention_dir", ")", "\n", "# offset = 0", "\n", "# if rank is not None:", "\n", "#     num_samples = int(math.ceil(len(loader.dataset) * 1.0 / world_size))", "\n", "#     offset = num_samples * rank", "\n", "# index = offset", "\n", "", "model", ".", "eval", "(", ")", "\n", "for", "i", ",", "data", "in", "zip", "(", "trange", "(", "len", "(", "loader", ")", ")", ",", "loader", ")", ":", "\n", "# for i, data in enumerate(loader):", "\n", "        ", "data", "=", "to_cuda", "(", "data", ")", "\n", "output", "=", "model", "(", "*", "data", ")", "\n", "for", "_i", ",", "(", "attention_probs", ",", "hidden_states", ")", "in", "enumerate", "(", "zip", "(", "output", "[", "'attention_probs'", "]", ",", "output", "[", "'hidden_states'", "]", ")", ")", ":", "\n", "            ", "index", "=", "int", "(", "data", "[", "2", "]", "[", "_i", "]", "[", "-", "1", "]", ")", "\n", "if", "hasattr", "(", "loader", ".", "dataset", ",", "'ids'", ")", ":", "\n", "                ", "image_id", "=", "loader", ".", "dataset", ".", "ids", "[", "index", "]", "\n", "", "else", ":", "\n", "                ", "image_id", "=", "loader", ".", "dataset", ".", "database", "[", "index", "]", "[", "'image'", "]", ".", "split", "(", "\n", "'/'", ")", "[", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "", "attention_probs_arr", "=", "attention_probs", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "hidden_states_arr", "=", "hidden_states", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "cos_similarity_arr", "=", "(", "hidden_states", "@", "hidden_states", ".", "transpose", "(", "\n", "1", ",", "2", ")", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "attention_dir", ",", "'{}.npy'", ".", "format", "(", "\n", "image_id", ")", ")", ",", "attention_probs_arr", ")", "\n", "# np.save(os.path.join(hidden_dir, '{}.npy'.format(image_id)), hidden_states_arr)", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.from_pretrained": [[57, 92], ["cls", "torch.load", "torch.load.items", "os.path.join", "file_utils.cached_path", "logger.info", "logger.info", "logger.error", "PRETRAINED_VOCAB_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.cached_path"], ["@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a TransfoXLTokenizer.\n        The TransfoXLTokenizer.\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_ARCHIVE_MAP", ":", "\n", "            ", "vocab_file", "=", "PRETRAINED_VOCAB_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "VOCAB_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_vocab_file", "=", "cached_path", "(", "vocab_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_VOCAB_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "vocab_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_vocab_file", "==", "vocab_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {}\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {} from cache at {}\"", ".", "format", "(", "\n", "vocab_file", ",", "resolved_vocab_file", ")", ")", "\n", "\n", "# Instantiate tokenizer.", "\n", "", "tokenizer", "=", "cls", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "vocab_dict", "=", "torch", ".", "load", "(", "resolved_vocab_file", ")", "\n", "for", "key", ",", "value", "in", "vocab_dict", ".", "items", "(", ")", ":", "\n", "            ", "tokenizer", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.__init__": [[93, 103], ["collections.Counter"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "special", "=", "[", "]", ",", "min_freq", "=", "0", ",", "max_size", "=", "None", ",", "lower_case", "=", "False", ",", "\n", "delimiter", "=", "None", ",", "vocab_file", "=", "None", ",", "never_split", "=", "(", "\"<unk>\"", ",", "\"<eos>\"", ",", "\"<formula>\"", ")", ")", ":", "\n", "        ", "self", ".", "counter", "=", "Counter", "(", ")", "\n", "self", ".", "special", "=", "special", "\n", "self", ".", "min_freq", "=", "min_freq", "\n", "self", ".", "max_size", "=", "max_size", "\n", "self", ".", "lower_case", "=", "lower_case", "\n", "self", ".", "delimiter", "=", "delimiter", "\n", "self", ".", "vocab_file", "=", "vocab_file", "\n", "self", ".", "never_split", "=", "never_split", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.count_file": [[104, 118], ["os.path.exists", "print", "io.open", "enumerate", "tokenization_transfo_xl.TransfoXLTokenizer.tokenize", "tokenization_transfo_xl.TransfoXLTokenizer.counter.update", "sents.append", "print"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update"], ["", "def", "count_file", "(", "self", ",", "path", ",", "verbose", "=", "False", ",", "add_eos", "=", "False", ")", ":", "\n", "        ", "if", "verbose", ":", "print", "(", "'counting file {} ...'", ".", "format", "(", "path", ")", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "\n", "sents", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                    ", "print", "(", "'    line {}'", ".", "format", "(", "idx", ")", ")", "\n", "", "symbols", "=", "self", ".", "tokenize", "(", "line", ",", "add_eos", "=", "add_eos", ")", "\n", "self", ".", "counter", ".", "update", "(", "symbols", ")", "\n", "sents", ".", "append", "(", "symbols", ")", "\n", "\n", "", "", "return", "sents", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.count_sents": [[119, 128], ["enumerate", "print", "tokenization_transfo_xl.TransfoXLTokenizer.counter.update", "print", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update"], ["", "def", "count_sents", "(", "self", ",", "sents", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            sents : a list of sentences, each a list of tokenized symbols\n        \"\"\"", "\n", "if", "verbose", ":", "print", "(", "'counting {} sents ...'", ".", "format", "(", "len", "(", "sents", ")", ")", ")", "\n", "for", "idx", ",", "symbols", "in", "enumerate", "(", "sents", ")", ":", "\n", "            ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                ", "print", "(", "'    line {}'", ".", "format", "(", "idx", ")", ")", "\n", "", "self", ".", "counter", ".", "update", "(", "symbols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer._build_from_file": [[129, 143], ["collections.OrderedDict", "io.open", "tokenization_transfo_xl.TransfoXLTokenizer.add_symbol", "ValueError", "line.strip().split", "line.strip"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.add_symbol"], ["", "", "def", "_build_from_file", "(", "self", ",", "vocab_file", ")", ":", "\n", "        ", "self", ".", "idx2sym", "=", "[", "]", "\n", "self", ".", "sym2idx", "=", "OrderedDict", "(", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "symb", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "0", "]", "\n", "self", ".", "add_symbol", "(", "symb", ")", "\n", "", "", "if", "'<UNK>'", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "unk_idx", "=", "self", ".", "sym2idx", "[", "'<UNK>'", "]", "\n", "", "elif", "'<unk>'", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "unk_idx", "=", "self", ".", "sym2idx", "[", "'<unk>'", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'No <unkown> token in vocabulary'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.build_vocab": [[144, 164], ["print", "tokenization_transfo_xl.TransfoXLTokenizer._build_from_file", "print", "print", "collections.OrderedDict", "tokenization_transfo_xl.TransfoXLTokenizer.counter.most_common", "print", "tokenization_transfo_xl.TransfoXLTokenizer.add_special", "tokenization_transfo_xl.TransfoXLTokenizer.add_symbol", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer._build_from_file", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.add_special", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.add_symbol"], ["", "", "def", "build_vocab", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "vocab_file", ":", "\n", "            ", "print", "(", "'building vocab from {}'", ".", "format", "(", "self", ".", "vocab_file", ")", ")", "\n", "self", ".", "_build_from_file", "(", "self", ".", "vocab_file", ")", "\n", "print", "(", "'final vocab size {}'", ".", "format", "(", "len", "(", "self", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'building vocab with min_freq={}, max_size={}'", ".", "format", "(", "\n", "self", ".", "min_freq", ",", "self", ".", "max_size", ")", ")", "\n", "self", ".", "idx2sym", "=", "[", "]", "\n", "self", ".", "sym2idx", "=", "OrderedDict", "(", ")", "\n", "\n", "for", "sym", "in", "self", ".", "special", ":", "\n", "                ", "self", ".", "add_special", "(", "sym", ")", "\n", "\n", "", "for", "sym", ",", "cnt", "in", "self", ".", "counter", ".", "most_common", "(", "self", ".", "max_size", ")", ":", "\n", "                ", "if", "cnt", "<", "self", ".", "min_freq", ":", "break", "\n", "self", ".", "add_symbol", "(", "sym", ")", "\n", "\n", "", "print", "(", "'final vocab size {} from {} unique tokens'", ".", "format", "(", "\n", "len", "(", "self", ")", ",", "len", "(", "self", ".", "counter", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file": [[165, 182], ["os.path.exists", "print", "io.open", "enumerate", "torch.cat", "tokenization_transfo_xl.TransfoXLTokenizer.tokenize", "torch.cat.append", "print", "tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor"], ["", "", "def", "encode_file", "(", "self", ",", "path", ",", "ordered", "=", "False", ",", "verbose", "=", "False", ",", "add_eos", "=", "True", ",", "\n", "add_double_eos", "=", "False", ")", ":", "\n", "        ", "if", "verbose", ":", "print", "(", "'encoding file {} ...'", ".", "format", "(", "path", ")", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "encoded", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                    ", "print", "(", "'    line {}'", ".", "format", "(", "idx", ")", ")", "\n", "", "symbols", "=", "self", ".", "tokenize", "(", "line", ",", "add_eos", "=", "add_eos", ",", "\n", "add_double_eos", "=", "add_double_eos", ")", "\n", "encoded", ".", "append", "(", "self", ".", "convert_to_tensor", "(", "symbols", ")", ")", "\n", "\n", "", "", "if", "ordered", ":", "\n", "            ", "encoded", "=", "torch", ".", "cat", "(", "encoded", ")", "\n", "\n", "", "return", "encoded", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_sents": [[183, 195], ["enumerate", "print", "torch.cat.append", "torch.cat", "print", "tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor"], ["", "def", "encode_sents", "(", "self", ",", "sents", ",", "ordered", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "if", "verbose", ":", "print", "(", "'encoding {} sents ...'", ".", "format", "(", "len", "(", "sents", ")", ")", ")", "\n", "encoded", "=", "[", "]", "\n", "for", "idx", ",", "symbols", "in", "enumerate", "(", "sents", ")", ":", "\n", "            ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                ", "print", "(", "'    line {}'", ".", "format", "(", "idx", ")", ")", "\n", "", "encoded", ".", "append", "(", "self", ".", "convert_to_tensor", "(", "symbols", ")", ")", "\n", "\n", "", "if", "ordered", ":", "\n", "            ", "encoded", "=", "torch", ".", "cat", "(", "encoded", ")", "\n", "\n", "", "return", "encoded", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.add_special": [[196, 201], ["tokenization_transfo_xl.TransfoXLTokenizer.idx2sym.append", "setattr", "len", "sym.strip"], "methods", ["None"], ["", "def", "add_special", "(", "self", ",", "sym", ")", ":", "\n", "        ", "if", "sym", "not", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "idx2sym", ".", "append", "(", "sym", ")", "\n", "self", ".", "sym2idx", "[", "sym", "]", "=", "len", "(", "self", ".", "idx2sym", ")", "-", "1", "\n", "setattr", "(", "self", ",", "'{}_idx'", ".", "format", "(", "sym", ".", "strip", "(", "'<>'", ")", ")", ",", "self", ".", "sym2idx", "[", "sym", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.add_symbol": [[202, 206], ["tokenization_transfo_xl.TransfoXLTokenizer.idx2sym.append", "len"], "methods", ["None"], ["", "", "def", "add_symbol", "(", "self", ",", "sym", ")", ":", "\n", "        ", "if", "sym", "not", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "idx2sym", ".", "append", "(", "sym", ")", "\n", "self", ".", "sym2idx", "[", "sym", "]", "=", "len", "(", "self", ".", "idx2sym", ")", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.get_sym": [[207, 210], ["len"], "methods", ["None"], ["", "", "def", "get_sym", "(", "self", ",", "idx", ")", ":", "\n", "        ", "assert", "0", "<=", "idx", "<", "len", "(", "self", ")", ",", "'Index {} out of vocabulary range'", ".", "format", "(", "idx", ")", "\n", "return", "self", ".", "idx2sym", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.get_idx": [[211, 226], ["hasattr", "tokenization_transfo_xl.TransfoXLTokenizer.sym2idx.get", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["", "def", "get_idx", "(", "self", ",", "sym", ")", ":", "\n", "        ", "if", "sym", "in", "self", ".", "sym2idx", ":", "\n", "            ", "return", "self", ".", "sym2idx", "[", "sym", "]", "\n", "", "else", ":", "\n", "# print('encounter unk {}'.format(sym))", "\n", "# assert '<eos>' not in sym", "\n", "            ", "if", "hasattr", "(", "self", ",", "'unk_idx'", ")", ":", "\n", "                ", "return", "self", ".", "sym2idx", ".", "get", "(", "sym", ",", "self", ".", "unk_idx", ")", "\n", "# Backward compatibility with pre-trained models", "\n", "", "elif", "'<unk>'", "in", "self", ".", "sym2idx", ":", "\n", "                ", "return", "self", ".", "sym2idx", "[", "'<unk>'", "]", "\n", "", "elif", "'<UNK>'", "in", "self", ".", "sym2idx", ":", "\n", "                ", "return", "self", ".", "sym2idx", "[", "'<UNK>'", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Token not in vocabulary and no <unk> token in vocabulary for replacement'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.convert_ids_to_tokens": [[227, 230], ["tokenization_transfo_xl.TransfoXLTokenizer.get_sym"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.get_sym"], ["", "", "", "def", "convert_ids_to_tokens", "(", "self", ",", "indices", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of indices in symbols using the vocab.\"\"\"", "\n", "return", "[", "self", ".", "get_sym", "(", "idx", ")", "for", "idx", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.convert_tokens_to_ids": [[231, 234], ["tokenization_transfo_xl.TransfoXLTokenizer.get_idx"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.get_idx"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "symbols", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of symbols into ids using the vocab.\"\"\"", "\n", "return", "[", "self", ".", "get_idx", "(", "sym", ")", "for", "sym", "in", "symbols", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor": [[235, 237], ["torch.LongTensor", "tokenization_transfo_xl.TransfoXLTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "convert_to_tensor", "(", "self", ",", "symbols", ")", ":", "\n", "        ", "return", "torch", ".", "LongTensor", "(", "self", ".", "convert_tokens_to_ids", "(", "symbols", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.decode": [[238, 244], ["tokenization_transfo_xl.TransfoXLTokenizer.get_sym", "tokenization_transfo_xl.TransfoXLTokenizer.get_sym"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.get_sym", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.get_sym"], ["", "def", "decode", "(", "self", ",", "indices", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of indices in a string.\"\"\"", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "return", "' '", ".", "join", "(", "[", "self", ".", "get_sym", "(", "idx", ")", "for", "idx", "in", "indices", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "' '", ".", "join", "(", "[", "self", ".", "get_sym", "(", "idx", ")", "for", "idx", "in", "indices", "if", "idx", "not", "in", "exclude", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.__len__": [[245, 247], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idx2sym", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer._run_split_on_punc": [[248, 269], ["list", "len", "tokenization_transfo_xl._is_punctuation", "output.append", "output[].append", "output.append"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization._is_punctuation"], ["", "def", "_run_split_on_punc", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Splits punctuation on a piece of text.\"\"\"", "\n", "if", "text", "in", "self", ".", "never_split", ":", "\n", "            ", "return", "[", "text", "]", "\n", "", "chars", "=", "list", "(", "text", ")", "\n", "i", "=", "0", "\n", "start_new_word", "=", "True", "\n", "output", "=", "[", "]", "\n", "while", "i", "<", "len", "(", "chars", ")", ":", "\n", "            ", "char", "=", "chars", "[", "i", "]", "\n", "if", "_is_punctuation", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "[", "char", "]", ")", "\n", "start_new_word", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "start_new_word", ":", "\n", "                    ", "output", ".", "append", "(", "[", "]", ")", "\n", "", "start_new_word", "=", "False", "\n", "output", "[", "-", "1", "]", ".", "append", "(", "char", ")", "\n", "", "i", "+=", "1", "\n", "\n", "", "return", "[", "\"\"", ".", "join", "(", "x", ")", "for", "x", "in", "output", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer._run_strip_accents": [[270, 280], ["unicodedata.normalize", "unicodedata.category", "output.append"], "methods", ["None"], ["", "def", "_run_strip_accents", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Strips accents from a piece of text.\"\"\"", "\n", "text", "=", "unicodedata", ".", "normalize", "(", "\"NFD\"", ",", "text", ")", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Mn\"", ":", "\n", "                ", "continue", "\n", "", "output", ".", "append", "(", "char", ")", "\n", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer._clean_text": [[281, 293], ["ord", "tokenization_transfo_xl._is_whitespace", "tokenization_transfo_xl._is_control", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization._is_whitespace", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization._is_control"], ["", "def", "_clean_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "cp", "==", "0", "or", "cp", "==", "0xfffd", "or", "_is_control", "(", "char", ")", ":", "\n", "                ", "continue", "\n", "", "if", "_is_whitespace", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.whitespace_tokenize": [[294, 304], ["text.strip.strip.strip", "text.strip.strip.split"], "methods", ["None"], ["", "def", "whitespace_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Runs basic whitespace cleaning and splitting on a peice of text.\"\"\"", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "            ", "return", "[", "]", "\n", "", "if", "self", ".", "delimiter", "==", "''", ":", "\n", "            ", "tokens", "=", "text", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "text", ".", "split", "(", "self", ".", "delimiter", ")", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.tokenize": [[305, 324], ["tokenization_transfo_xl.TransfoXLTokenizer._clean_text", "line.strip.strip.strip", "tokenization_transfo_xl.TransfoXLTokenizer.whitespace_tokenize", "split_symbols.extend", "tokenization_transfo_xl.TransfoXLTokenizer.lower", "tokenization_transfo_xl.TransfoXLTokenizer._run_strip_accents", "tokenization_transfo_xl.TransfoXLTokenizer._run_split_on_punc"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._clean_text", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_strip_accents", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_split_on_punc"], ["", "def", "tokenize", "(", "self", ",", "line", ",", "add_eos", "=", "False", ",", "add_double_eos", "=", "False", ")", ":", "\n", "        ", "line", "=", "self", ".", "_clean_text", "(", "line", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "\n", "symbols", "=", "self", ".", "whitespace_tokenize", "(", "line", ")", "\n", "\n", "split_symbols", "=", "[", "]", "\n", "for", "symbol", "in", "symbols", ":", "\n", "            ", "if", "self", ".", "lower_case", "and", "symbol", "not", "in", "self", ".", "never_split", ":", "\n", "                ", "symbol", "=", "symbol", ".", "lower", "(", ")", "\n", "symbol", "=", "self", ".", "_run_strip_accents", "(", "symbol", ")", "\n", "", "split_symbols", ".", "extend", "(", "self", ".", "_run_split_on_punc", "(", "symbol", ")", ")", "\n", "\n", "", "if", "add_double_eos", ":", "# lm1b", "\n", "            ", "return", "[", "'<S>'", "]", "+", "split_symbols", "+", "[", "'<S>'", "]", "\n", "", "elif", "add_eos", ":", "\n", "            ", "return", "split_symbols", "+", "[", "'<eos>'", "]", "\n", "", "else", ":", "\n", "            ", "return", "split_symbols", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMOrderedIterator.__init__": [[327, 348], ["data.narrow.narrow.narrow", "data.narrow.narrow.view().t().contiguous().to", "data.narrow.narrow.size", "data.narrow.narrow.view().t().contiguous", "data.narrow.narrow.view().t", "data.narrow.narrow.view"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "bsz", ",", "bptt", ",", "device", "=", "'cpu'", ",", "ext_len", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            data -- LongTensor -- the LongTensor is strictly ordered\n        \"\"\"", "\n", "self", ".", "bsz", "=", "bsz", "\n", "self", ".", "bptt", "=", "bptt", "\n", "self", ".", "ext_len", "=", "ext_len", "if", "ext_len", "is", "not", "None", "else", "0", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n", "# Work out how cleanly we can divide the dataset into bsz parts.", "\n", "self", ".", "n_step", "=", "data", ".", "size", "(", "0", ")", "//", "bsz", "\n", "\n", "# Trim off any extra elements that wouldn't cleanly fit (remainders).", "\n", "data", "=", "data", ".", "narrow", "(", "0", ",", "0", ",", "self", ".", "n_step", "*", "bsz", ")", "\n", "\n", "# Evenly divide the data across the bsz batches.", "\n", "self", ".", "data", "=", "data", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Number of mini-batches", "\n", "self", ".", "n_batch", "=", "(", "self", ".", "n_step", "+", "self", ".", "bptt", "-", "1", ")", "//", "self", ".", "bptt", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMOrderedIterator.get_batch": [[349, 363], ["min", "max", "data.transpose().contiguous().to", "target.transpose().contiguous().to", "data.transpose().contiguous", "target.transpose().contiguous", "tokenization_transfo_xl.LMOrderedIterator.data.size", "data.transpose", "target.transpose"], "methods", ["None"], ["", "def", "get_batch", "(", "self", ",", "i", ",", "bptt", "=", "None", ")", ":", "\n", "        ", "if", "bptt", "is", "None", ":", "bptt", "=", "self", ".", "bptt", "\n", "seq_len", "=", "min", "(", "bptt", ",", "self", ".", "data", ".", "size", "(", "0", ")", "-", "1", "-", "i", ")", "\n", "\n", "end_idx", "=", "i", "+", "seq_len", "\n", "beg_idx", "=", "max", "(", "0", ",", "i", "-", "self", ".", "ext_len", ")", "\n", "\n", "data", "=", "self", ".", "data", "[", "beg_idx", ":", "end_idx", "]", "\n", "target", "=", "self", ".", "data", "[", "i", "+", "1", ":", "i", "+", "1", "+", "seq_len", "]", "\n", "\n", "data_out", "=", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "target_out", "=", "target", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "return", "data_out", ",", "target_out", ",", "seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMOrderedIterator.get_fixlen_iter": [[364, 367], ["range", "tokenization_transfo_xl.LMOrderedIterator.data.size", "tokenization_transfo_xl.LMOrderedIterator.get_batch"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMOrderedIterator.get_batch"], ["", "def", "get_fixlen_iter", "(", "self", ",", "start", "=", "0", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "start", ",", "self", ".", "data", ".", "size", "(", "0", ")", "-", "1", ",", "self", ".", "bptt", ")", ":", "\n", "            ", "yield", "self", ".", "get_batch", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMOrderedIterator.get_varlen_iter": [[368, 379], ["min", "tokenization_transfo_xl.LMOrderedIterator.get_batch", "max", "numpy.random.random", "int", "tokenization_transfo_xl.LMOrderedIterator.data.size", "numpy.random.normal"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMOrderedIterator.get_batch"], ["", "", "def", "get_varlen_iter", "(", "self", ",", "start", "=", "0", ",", "std", "=", "5", ",", "min_len", "=", "5", ",", "max_deviation", "=", "3", ")", ":", "\n", "        ", "max_len", "=", "self", ".", "bptt", "+", "max_deviation", "*", "std", "\n", "i", "=", "start", "\n", "while", "True", ":", "\n", "            ", "bptt", "=", "self", ".", "bptt", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.95", "else", "self", ".", "bptt", "/", "2.", "\n", "bptt", "=", "min", "(", "max_len", ",", "max", "(", "min_len", ",", "int", "(", "np", ".", "random", ".", "normal", "(", "bptt", ",", "std", ")", ")", ")", ")", "\n", "data", ",", "target", ",", "seq_len", "=", "self", ".", "get_batch", "(", "i", ",", "bptt", ")", "\n", "i", "+=", "seq_len", "\n", "yield", "data", ",", "target", ",", "seq_len", "\n", "if", "i", ">=", "self", ".", "data", ".", "size", "(", "0", ")", "-", "2", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMOrderedIterator.__iter__": [[380, 382], ["tokenization_transfo_xl.LMOrderedIterator.get_fixlen_iter"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMOrderedIterator.get_fixlen_iter"], ["", "", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "get_fixlen_iter", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMShuffledIterator.__init__": [[385, 397], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "bsz", ",", "bptt", ",", "device", "=", "'cpu'", ",", "ext_len", "=", "None", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            data -- list[LongTensor] -- there is no order among the LongTensors\n        \"\"\"", "\n", "self", ".", "data", "=", "data", "\n", "\n", "self", ".", "bsz", "=", "bsz", "\n", "self", ".", "bptt", "=", "bptt", "\n", "self", ".", "ext_len", "=", "ext_len", "if", "ext_len", "is", "not", "None", "else", "0", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMShuffledIterator.get_sent_stream": [[398, 406], ["numpy.random.permutation", "numpy.array", "len", "range", "len"], "methods", ["None"], ["", "def", "get_sent_stream", "(", "self", ")", ":", "\n", "# index iterator", "\n", "        ", "epoch_indices", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ".", "data", ")", ")", "if", "self", ".", "shuffle", "else", "np", ".", "array", "(", "range", "(", "len", "(", "self", ".", "data", ")", ")", ")", "\n", "\n", "# sentence iterator", "\n", "for", "idx", "in", "epoch_indices", ":", "\n", "            ", "yield", "self", ".", "data", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMShuffledIterator.stream_iterator": [[407, 455], ["torch.LongTensor", "torch.LongTensor", "data[].fill_", "torch.LongTensor.fill_", "range", "torch.LongTensor.transpose().contiguous().to", "torch.LongTensor.transpose().contiguous().to", "min", "torch.LongTensor.resize_", "torch.LongTensor.size", "torch.LongTensor.size", "torch.LongTensor.transpose().contiguous", "torch.LongTensor.transpose().contiguous", "min", "next", "torch.LongTensor.transpose", "torch.LongTensor.transpose", "len", "len"], "methods", ["None"], ["", "", "def", "stream_iterator", "(", "self", ",", "sent_stream", ")", ":", "\n", "# streams for each data in the batch", "\n", "        ", "streams", "=", "[", "None", "]", "*", "self", ".", "bsz", "\n", "\n", "data", "=", "torch", ".", "LongTensor", "(", "self", ".", "bptt", ",", "self", ".", "bsz", ")", "\n", "target", "=", "torch", ".", "LongTensor", "(", "self", ".", "bptt", ",", "self", ".", "bsz", ")", "\n", "\n", "n_retain", "=", "0", "\n", "\n", "while", "True", ":", "\n", "# data   : [n_retain+bptt x bsz]", "\n", "# target : [bptt x bsz]", "\n", "            ", "data", "[", "n_retain", ":", "]", ".", "fill_", "(", "-", "1", ")", "\n", "target", ".", "fill_", "(", "-", "1", ")", "\n", "\n", "valid_batch", "=", "True", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "bsz", ")", ":", "\n", "                ", "n_filled", "=", "0", "\n", "try", ":", "\n", "                    ", "while", "n_filled", "<", "self", ".", "bptt", ":", "\n", "                        ", "if", "streams", "[", "i", "]", "is", "None", "or", "len", "(", "streams", "[", "i", "]", ")", "<=", "1", ":", "\n", "                            ", "streams", "[", "i", "]", "=", "next", "(", "sent_stream", ")", "\n", "# number of new tokens to fill in", "\n", "", "n_new", "=", "min", "(", "len", "(", "streams", "[", "i", "]", ")", "-", "1", ",", "self", ".", "bptt", "-", "n_filled", ")", "\n", "# first n_retain tokens are retained from last batch", "\n", "data", "[", "n_retain", "+", "n_filled", ":", "n_retain", "+", "n_filled", "+", "n_new", ",", "i", "]", "=", "streams", "[", "i", "]", "[", ":", "n_new", "]", "\n", "target", "[", "n_filled", ":", "n_filled", "+", "n_new", ",", "i", "]", "=", "streams", "[", "i", "]", "[", "1", ":", "n_new", "+", "1", "]", "\n", "streams", "[", "i", "]", "=", "streams", "[", "i", "]", "[", "n_new", ":", "]", "\n", "n_filled", "+=", "n_new", "\n", "", "", "except", "StopIteration", ":", "\n", "                    ", "valid_batch", "=", "False", "\n", "break", "\n", "\n", "", "", "if", "not", "valid_batch", ":", "\n", "                ", "return", "\n", "\n", "", "data_out", "=", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "target_out", "=", "target", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "yield", "data_out", ",", "target_out", ",", "self", ".", "bptt", "\n", "\n", "n_retain", "=", "min", "(", "data", ".", "size", "(", "0", ")", ",", "self", ".", "ext_len", ")", "\n", "if", "n_retain", ">", "0", ":", "\n", "                ", "data", "[", ":", "n_retain", "]", "=", "data", "[", "-", "n_retain", ":", "]", "\n", "", "data", ".", "resize_", "(", "n_retain", "+", "self", ".", "bptt", ",", "data", ".", "size", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMShuffledIterator.__iter__": [[456, 462], ["tokenization_transfo_xl.LMShuffledIterator.get_sent_stream", "tokenization_transfo_xl.LMShuffledIterator.stream_iterator"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMShuffledIterator.stream_iterator"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "# sent_stream is an iterator", "\n", "        ", "sent_stream", "=", "self", ".", "get_sent_stream", "(", ")", "\n", "\n", "for", "batch", "in", "self", ".", "stream_iterator", "(", "sent_stream", ")", ":", "\n", "            ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMMultiFileIterator.__init__": [[465, 477], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "paths", ",", "vocab", ",", "bsz", ",", "bptt", ",", "device", "=", "'cpu'", ",", "ext_len", "=", "None", ",", "\n", "shuffle", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "paths", "=", "paths", "\n", "self", ".", "vocab", "=", "vocab", "\n", "\n", "self", ".", "bsz", "=", "bsz", "\n", "self", ".", "bptt", "=", "bptt", "\n", "self", ".", "ext_len", "=", "ext_len", "if", "ext_len", "is", "not", "None", "else", "0", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream": [[478, 485], ["tokenization_transfo_xl.LMMultiFileIterator.vocab.encode_file", "iter", "numpy.random.shuffle"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file"], ["", "def", "get_sent_stream", "(", "self", ",", "path", ")", ":", "\n", "        ", "sents", "=", "self", ".", "vocab", ".", "encode_file", "(", "path", ",", "add_double_eos", "=", "True", ")", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "sents", ")", "\n", "", "sent_stream", "=", "iter", "(", "sents", ")", "\n", "\n", "return", "sent_stream", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMMultiFileIterator.__iter__": [[486, 495], ["numpy.random.shuffle", "tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream", "tokenization_transfo_xl.LMMultiFileIterator.stream_iterator"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.LMShuffledIterator.stream_iterator"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "paths", ")", "\n", "\n", "", "for", "path", "in", "self", ".", "paths", ":", "\n", "# sent_stream is an iterator", "\n", "            ", "sent_stream", "=", "self", ".", "get_sent_stream", "(", "path", ")", "\n", "for", "batch", "in", "self", ".", "stream_iterator", "(", "sent_stream", ")", ":", "\n", "                ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLCorpus.from_pretrained": [[498, 540], ["tokenization_transfo_xl.TransfoXLTokenizer.from_pretrained", "cls", "torch.load", "torch.load.items", "os.path.join", "file_utils.cached_path", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "logger.error", "PRETRAINED_VOCAB_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.from_pretrained", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.cached_path"], ["    ", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a pre-processed corpus.\n        \"\"\"", "\n", "vocab", "=", "TransfoXLTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_CORPUS_ARCHIVE_MAP", ":", "\n", "            ", "corpus_file", "=", "PRETRAINED_CORPUS_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "corpus_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CORPUS_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_corpus_file", "=", "cached_path", "(", "corpus_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Corpus '{}' was not found in corpus list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_VOCAB_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "corpus_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_corpus_file", "==", "corpus_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading corpus file {}\"", ".", "format", "(", "corpus_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading corpus file {} from cache at {}\"", ".", "format", "(", "\n", "corpus_file", ",", "resolved_corpus_file", ")", ")", "\n", "\n", "# Instantiate tokenizer.", "\n", "", "corpus", "=", "cls", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "corpus_dict", "=", "torch", ".", "load", "(", "resolved_corpus_file", ")", "\n", "for", "key", ",", "value", "in", "corpus_dict", ".", "items", "(", ")", ":", "\n", "            ", "corpus", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "corpus", ".", "vocab", "=", "vocab", "\n", "if", "corpus", ".", "train", "is", "not", "None", ":", "\n", "            ", "corpus", ".", "train", "=", "torch", ".", "tensor", "(", "corpus", ".", "train", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "if", "corpus", ".", "valid", "is", "not", "None", ":", "\n", "            ", "corpus", ".", "valid", "=", "torch", ".", "tensor", "(", "corpus", ".", "valid", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "if", "corpus", ".", "test", "is", "not", "None", ":", "\n", "            ", "corpus", ".", "test", "=", "torch", ".", "tensor", "(", "corpus", ".", "test", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLCorpus.__init__": [[541, 547], ["tokenization_transfo_xl.TransfoXLTokenizer"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "TransfoXLTokenizer", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "dataset", "=", "None", "\n", "self", ".", "train", "=", "None", "\n", "self", ".", "valid", "=", "None", "\n", "self", ".", "test", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLCorpus.build_corpus": [[548, 586], ["tokenization_transfo_xl.TransfoXLCorpus.vocab.build_vocab", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "os.path.join", "os.path.join", "os.path.join", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "os.path.join", "os.path.join", "os.path.join", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "os.path.join", "os.path.join", "glob.glob", "os.path.join", "os.path.join", "os.path.join", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.build_vocab", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLTokenizer.encode_file"], ["", "def", "build_corpus", "(", "self", ",", "path", ",", "dataset", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "\n", "if", "self", ".", "dataset", "in", "[", "'ptb'", ",", "'wt2'", ",", "'enwik8'", ",", "'text8'", "]", ":", "\n", "            ", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ")", "\n", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ")", "\n", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'wt103'", ":", "\n", "            ", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'lm1b'", ":", "\n", "            ", "train_path_pattern", "=", "os", ".", "path", ".", "join", "(", "\n", "path", ",", "'1-billion-word-language-modeling-benchmark-r13output'", ",", "\n", "'training-monolingual.tokenized.shuffled'", ",", "'news.en-*'", ")", "\n", "train_paths", "=", "glob", ".", "glob", "(", "train_path_pattern", ")", "\n", "# the vocab will load from file when build_vocab() is called", "\n", "\n", "", "self", ".", "vocab", ".", "build_vocab", "(", ")", "\n", "\n", "if", "self", ".", "dataset", "in", "[", "'ptb'", ",", "'wt2'", ",", "'wt103'", "]", ":", "\n", "            ", "self", ".", "train", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ",", "ordered", "=", "True", ")", "\n", "self", ".", "valid", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ",", "ordered", "=", "True", ")", "\n", "self", ".", "test", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ",", "ordered", "=", "True", ")", "\n", "", "elif", "self", ".", "dataset", "in", "[", "'enwik8'", ",", "'text8'", "]", ":", "\n", "            ", "self", ".", "train", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ",", "ordered", "=", "True", ",", "add_eos", "=", "False", ")", "\n", "self", ".", "valid", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ",", "ordered", "=", "True", ",", "add_eos", "=", "False", ")", "\n", "self", ".", "test", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ",", "ordered", "=", "True", ",", "add_eos", "=", "False", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'lm1b'", ":", "\n", "            ", "self", ".", "train", "=", "train_paths", "\n", "self", ".", "valid", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ",", "ordered", "=", "False", ",", "add_double_eos", "=", "True", ")", "\n", "self", ".", "test", "=", "self", ".", "vocab", ".", "encode_file", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ",", "ordered", "=", "False", ",", "add_double_eos", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.TransfoXLCorpus.get_iterator": [[587, 602], ["tokenization_transfo_xl.LMOrderedIterator", "tokenization_transfo_xl.LMMultiFileIterator", "tokenization_transfo_xl.LMOrderedIterator", "tokenization_transfo_xl.LMShuffledIterator"], "methods", ["None"], ["", "", "def", "get_iterator", "(", "self", ",", "split", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "split", "==", "'train'", ":", "\n", "            ", "if", "self", ".", "dataset", "in", "[", "'ptb'", ",", "'wt2'", ",", "'wt103'", ",", "'enwik8'", ",", "'text8'", "]", ":", "\n", "                ", "data_iter", "=", "LMOrderedIterator", "(", "self", ".", "train", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'lm1b'", ":", "\n", "                ", "kwargs", "[", "'shuffle'", "]", "=", "True", "\n", "data_iter", "=", "LMMultiFileIterator", "(", "self", ".", "train", ",", "self", ".", "vocab", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", "elif", "split", "in", "[", "'valid'", ",", "'test'", "]", ":", "\n", "            ", "data", "=", "self", ".", "valid", "if", "split", "==", "'valid'", "else", "self", ".", "test", "\n", "if", "self", ".", "dataset", "in", "[", "'ptb'", ",", "'wt2'", ",", "'wt103'", ",", "'enwik8'", ",", "'text8'", "]", ":", "\n", "                ", "data_iter", "=", "LMOrderedIterator", "(", "data", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'lm1b'", ":", "\n", "                ", "data_iter", "=", "LMShuffledIterator", "(", "data", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "data_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl.get_lm_corpus": [[604, 634], ["os.path.join", "os.path.join", "os.path.exists", "print", "torch.load", "os.path.exists", "print", "print", "tokenization_transfo_xl.TransfoXLCorpus", "torch.save", "io.open", "pickle.load", "os.path.join"], "function", ["None"], ["", "", "def", "get_lm_corpus", "(", "datadir", ",", "dataset", ")", ":", "\n", "    ", "fn", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "'cache.pt'", ")", "\n", "fn_pickle", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "'cache.pkl'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "fn", ")", ":", "\n", "        ", "print", "(", "'Loading cached dataset...'", ")", "\n", "corpus", "=", "torch", ".", "load", "(", "fn_pickle", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "fn", ")", ":", "\n", "        ", "print", "(", "'Loading cached dataset from pickle...'", ")", "\n", "with", "open", "(", "fn", ",", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "corpus", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "'Producing dataset {}...'", ".", "format", "(", "dataset", ")", ")", "\n", "kwargs", "=", "{", "}", "\n", "if", "dataset", "in", "[", "'wt103'", ",", "'wt2'", "]", ":", "\n", "            ", "kwargs", "[", "'special'", "]", "=", "[", "'<eos>'", "]", "\n", "kwargs", "[", "'lower_case'", "]", "=", "False", "\n", "", "elif", "dataset", "==", "'ptb'", ":", "\n", "            ", "kwargs", "[", "'special'", "]", "=", "[", "'<eos>'", "]", "\n", "kwargs", "[", "'lower_case'", "]", "=", "True", "\n", "", "elif", "dataset", "==", "'lm1b'", ":", "\n", "            ", "kwargs", "[", "'special'", "]", "=", "[", "]", "\n", "kwargs", "[", "'lower_case'", "]", "=", "False", "\n", "kwargs", "[", "'vocab_file'", "]", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "'1b_word_vocab.txt'", ")", "\n", "", "elif", "dataset", "in", "[", "'enwik8'", ",", "'text8'", "]", ":", "\n", "            ", "pass", "\n", "\n", "", "corpus", "=", "TransfoXLCorpus", "(", "datadir", ",", "dataset", ",", "**", "kwargs", ")", "\n", "torch", ".", "save", "(", "corpus", ",", "fn", ")", "\n", "\n", "", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl._is_whitespace": [[635, 645], ["unicodedata.category"], "function", ["None"], ["", "def", "_is_whitespace", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a whitespace character.\"\"\"", "\n", "# \\t, \\n, and \\r are technically contorl characters but we treat them", "\n", "# as whitespace since they are generally considered as such.", "\n", "if", "char", "==", "\" \"", "or", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Zs\"", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl._is_control": [[647, 657], ["unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_control", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a control character.\"\"\"", "\n", "# These are technically control characters but we count them as whitespace", "\n", "# characters.", "\n", "if", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "False", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"C\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_transfo_xl._is_punctuation": [[659, 673], ["ord", "unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_punctuation", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a punctuation character.\"\"\"", "\n", "cp", "=", "ord", "(", "char", ")", "\n", "# We treat all non-letter/number ASCII as punctuation.", "\n", "# Characters such as \"^\", \"$\", and \"`\" are not in the Unicode", "\n", "# Punctuation class but we treat them as punctuation anyways, for", "\n", "# consistency.", "\n", "if", "(", "(", "cp", ">=", "33", "and", "cp", "<=", "47", ")", "or", "(", "cp", ">=", "58", "and", "cp", "<=", "64", ")", "or", "\n", "(", "cp", ">=", "91", "and", "cp", "<=", "96", ")", "or", "(", "cp", ">=", "123", "and", "cp", "<=", "126", ")", ")", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"P\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertConfig.__init__": [[133, 189], ["isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", ",", "\n", "hidden_size", "=", "768", ",", "\n", "num_hidden_layers", "=", "12", ",", "\n", "num_attention_heads", "=", "12", ",", "\n", "intermediate_size", "=", "3072", ",", "\n", "hidden_act", "=", "\"gelu\"", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "type_vocab_size", "=", "2", ",", "\n", "initializer_range", "=", "0.02", ")", ":", "\n", "        ", "\"\"\"Constructs BertConfig.\n\n        Args:\n            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `BertModel`.\n            hidden_size: Size of the encoder layers and the pooler layer.\n            num_hidden_layers: Number of hidden layers in the Transformer encoder.\n            num_attention_heads: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n                layer in the Transformer encoder.\n            hidden_act: The non-linear activation function (function or string) in the\n                encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.\n            hidden_dropout_prob: The dropout probabilitiy for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            attention_probs_dropout_prob: The dropout ratio for the attention\n                probabilities.\n            max_position_embeddings: The maximum sequence length that this model might\n                ever be used with. Typically set this to something large just in case\n                (e.g., 512 or 1024 or 2048).\n            type_vocab_size: The vocabulary size of the `token_type_ids` passed into\n                `BertModel`.\n            initializer_range: The sttdev of the truncated_normal_initializer for\n                initializing all weight matrices.\n        \"\"\"", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_attention_heads", "=", "num_attention_heads", "\n", "self", ".", "hidden_act", "=", "hidden_act", "\n", "self", ".", "intermediate_size", "=", "intermediate_size", "\n", "self", ".", "hidden_dropout_prob", "=", "hidden_dropout_prob", "\n", "self", ".", "attention_probs_dropout_prob", "=", "attention_probs_dropout_prob", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "type_vocab_size", "=", "type_vocab_size", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertConfig.from_dict": [[191, 198], ["modeling.BertConfig", "json_object.items"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "BertConfig", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertConfig.from_json_file": [[199, 205], ["cls.from_dict", "io.open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertConfig.__repr__": [[206, 208], ["str", "modeling.BertConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertConfig.to_dict": [[209, 213], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertConfig.to_json_string": [[214, 217], ["json.dumps", "modeling.BertConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertEmbeddings.__init__": [[240, 250], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertEmbeddings.forward": [[251, 266], ["input_ids.size", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "modeling.BertEmbeddings.word_embeddings", "modeling.BertEmbeddings.position_embeddings", "modeling.BertEmbeddings.token_type_embeddings", "modeling.BertEmbeddings.LayerNorm", "modeling.BertEmbeddings.dropout", "torch.zeros_like", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ")", ":", "\n", "        ", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "", "words_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "words_embeddings", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertSelfAttention.__init__": [[269, 284], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", ")", "\n", "", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores": [[285, 289], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertSelfAttention.forward": [[290, 320], ["modeling.BertSelfAttention.query", "modeling.BertSelfAttention.key", "modeling.BertSelfAttention.value", "modeling.BertSelfAttention.transpose_for_scores", "modeling.BertSelfAttention.transpose_for_scores", "modeling.BertSelfAttention.transpose_for_scores", "torch.matmul", "modeling.BertSelfAttention.dropout", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "modeling.BertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "output_attention_probs", "=", "False", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "if", "output_attention_probs", ":", "\n", "            ", "return", "context_layer", ",", "attention_probs", "\n", "", "else", ":", "\n", "            ", "return", "context_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertSelfOutput.__init__": [[323, 328], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertSelfOutput.forward": [[329, 334], ["modeling.BertSelfOutput.dense", "modeling.BertSelfOutput.dropout", "modeling.BertSelfOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertAttention.__init__": [[337, 341], ["torch.nn.Module.__init__", "modeling.BertSelfAttention", "modeling.BertSelfOutput"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertAttention.forward": [[342, 350], ["modeling.BertAttention.self", "modeling.BertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_tensor", ",", "attention_mask", ",", "output_attention_probs", "=", "False", ")", ":", "\n", "        ", "self_output", "=", "self", ".", "self", "(", "input_tensor", ",", "attention_mask", ",", "output_attention_probs", "=", "output_attention_probs", ")", "\n", "if", "output_attention_probs", ":", "\n", "            ", "self_output", ",", "attention_probs", "=", "self_output", "\n", "", "attention_output", "=", "self", ".", "output", "(", "self_output", ",", "input_tensor", ")", "\n", "if", "output_attention_probs", ":", "\n", "            ", "return", "attention_output", ",", "attention_probs", "\n", "", "return", "attention_output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertIntermediate.__init__": [[353, 360], ["torch.nn.Module.__init__", "torch.nn.Linear", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertIntermediate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "hidden_act", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "config", ".", "hidden_act", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertIntermediate.forward": [[361, 365], ["modeling.BertIntermediate.dense", "modeling.BertIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertOutput.__init__": [[368, 373], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertOutput.forward": [[374, 379], ["modeling.BertOutput.dense", "modeling.BertOutput.dropout", "modeling.BertOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertLayer.__init__": [[382, 387], ["torch.nn.Module.__init__", "modeling.BertAttention", "modeling.BertIntermediate", "modeling.BertOutput"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "BertAttention", "(", "config", ")", "\n", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "BertOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertLayer.forward": [[388, 398], ["modeling.BertLayer.attention", "modeling.BertLayer.intermediate", "modeling.BertLayer.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "output_attention_probs", "=", "False", ")", ":", "\n", "        ", "attention_output", "=", "self", ".", "attention", "(", "hidden_states", ",", "attention_mask", ",", "output_attention_probs", "=", "output_attention_probs", ")", "\n", "if", "output_attention_probs", ":", "\n", "            ", "attention_output", ",", "attention_probs", "=", "attention_output", "\n", "", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "if", "output_attention_probs", ":", "\n", "            ", "return", "layer_output", ",", "attention_probs", "\n", "", "else", ":", "\n", "            ", "return", "layer_output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertEncoder.__init__": [[401, 405], ["torch.nn.Module.__init__", "modeling.BertLayer", "torch.nn.ModuleList", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layer", "=", "BertLayer", "(", "config", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "layer", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertEncoder.forward": [[406, 422], ["layer_module", "all_encoder_layers.append", "all_attention_probs.append", "all_encoder_layers.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "True", ",", "output_attention_probs", "=", "False", ")", ":", "\n", "        ", "all_encoder_layers", "=", "[", "]", "\n", "all_attention_probs", "=", "[", "]", "\n", "for", "layer_module", "in", "self", ".", "layer", ":", "\n", "            ", "hidden_states", "=", "layer_module", "(", "hidden_states", ",", "attention_mask", ",", "output_attention_probs", "=", "output_attention_probs", ")", "\n", "if", "output_attention_probs", ":", "\n", "                ", "hidden_states", ",", "attention_probs", "=", "hidden_states", "\n", "all_attention_probs", ".", "append", "(", "attention_probs", ")", "\n", "", "if", "output_all_encoded_layers", ":", "\n", "                ", "all_encoder_layers", ".", "append", "(", "hidden_states", ")", "\n", "", "", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "all_encoder_layers", ".", "append", "(", "hidden_states", ")", "\n", "", "if", "output_attention_probs", ":", "\n", "            ", "return", "all_encoder_layers", ",", "all_attention_probs", "\n", "", "else", ":", "\n", "            ", "return", "all_encoder_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertPooler.__init__": [[425, 429], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPooler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertPooler.forward": [[430, 437], ["modeling.BertPooler.dense", "modeling.BertPooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertPredictionHeadTransform.__init__": [[440, 448], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPredictionHeadTransform", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "hidden_act", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "config", ".", "hidden_act", "\n", "", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertPredictionHeadTransform.forward": [[449, 454], ["modeling.BertPredictionHeadTransform.dense", "modeling.BertPredictionHeadTransform.transform_act_fn", "modeling.BertPredictionHeadTransform.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "transform_act_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertLMPredictionHead.__init__": [[457, 468], ["torch.nn.Module.__init__", "modeling.BertPredictionHeadTransform", "torch.nn.Linear", "torch.nn.Parameter", "bert_model_embedding_weights.size", "bert_model_embedding_weights.size", "torch.zeros", "bert_model_embedding_weights.size"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertLMPredictionHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "BertPredictionHeadTransform", "(", "config", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "bert_model_embedding_weights", ".", "size", "(", "1", ")", ",", "\n", "bert_model_embedding_weights", ".", "size", "(", "0", ")", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "decoder", ".", "weight", "=", "bert_model_embedding_weights", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "bert_model_embedding_weights", ".", "size", "(", "0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertLMPredictionHead.forward": [[469, 473], ["modeling.BertLMPredictionHead.transform", "modeling.BertLMPredictionHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transform", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "decoder", "(", "hidden_states", ")", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertOnlyMLMHead.__init__": [[476, 479], ["torch.nn.Module.__init__", "modeling.BertLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertOnlyMLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ",", "bert_model_embedding_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertOnlyMLMHead.forward": [[480, 483], ["modeling.BertOnlyMLMHead.predictions"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertOnlyNSPHead.__init__": [[486, 489], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOnlyNSPHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertOnlyNSPHead.forward": [[490, 493], ["modeling.BertOnlyNSPHead.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pooled_output", ")", ":", "\n", "        ", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertPreTrainingHeads.__init__": [[496, 500], ["torch.nn.Module.__init__", "modeling.BertLMPredictionHead", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertPreTrainingHeads", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ",", "bert_model_embedding_weights", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertPreTrainingHeads.forward": [[501, 505], ["modeling.BertPreTrainingHeads.predictions", "modeling.BertPreTrainingHeads.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ",", "pooled_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertPreTrainedModel.__init__": [[511, 521], ["torch.nn.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BertPreTrainedModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "BertConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `BertConfig`. \"", "\n", "\"To create a model from a Google pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", ")", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertPreTrainedModel.init_bert_weights": [[522, 534], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "init_bert_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "BertLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertPreTrainedModel.from_pretrained": [[535, 657], ["os.path.join", "modeling.BertConfig.from_json_file", "logger.info", "cls", "torch.load.keys", "zip", "getattr", "torch.load.copy", "modeling.BertPreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_json_file"], ["", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "state_dict", "=", "None", ",", "cache_dir", "=", "None", ",", "\n", "from_tf", "=", "False", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a BertPreTrainedModel from a pre-trained model file or a pytorch state dict.\n        Download and cache the pre-trained model file if needed.\n\n        Params:\n            pretrained_model_name_or_path: either:\n                - a str with the name of a pre-trained model to load selected in the list of:\n                    . `bert-base-uncased`\n                    . `bert-large-uncased`\n                    . `bert-base-cased`\n                    . `bert-large-cased`\n                    . `bert-base-multilingual-uncased`\n                    . `bert-base-multilingual-cased`\n                    . `bert-base-chinese`\n                - a path or url to a pretrained model archive containing:\n                    . `bert_config.json` a configuration file for the model\n                    . `pytorch_model.bin` a PyTorch dump of a BertForPreTraining instance\n                - a path or url to a pretrained model archive containing:\n                    . `bert_config.json` a configuration file for the model\n                    . `model.chkpt` a TensorFlow checkpoint\n            from_tf: should we load the weights from a locally saved TensorFlow checkpoint\n            cache_dir: an optional path to a folder in which the pre-trained models will be cached.\n            state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of Google pre-trained models\n            *inputs, **kwargs: additional input for the specific Bert class\n                (ex: num_labels for BertForSequenceClassification)\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_MODEL_ARCHIVE_MAP", ":", "\n", "            ", "archive_file", "=", "PRETRAINED_MODEL_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "archive_file", "=", "pretrained_model_name_or_path", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading archive file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading archive file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "", "tempdir", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "resolved_archive_file", ")", "or", "from_tf", ":", "\n", "            ", "serialization_dir", "=", "resolved_archive_file", "\n", "", "else", ":", "\n", "# Extract archive to temp dir", "\n", "            ", "tempdir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "logger", ".", "info", "(", "\"extracting archive file {} to temp dir {}\"", ".", "format", "(", "\n", "resolved_archive_file", ",", "tempdir", ")", ")", "\n", "with", "tarfile", ".", "open", "(", "resolved_archive_file", ",", "'r:gz'", ")", "as", "archive", ":", "\n", "                ", "archive", ".", "extractall", "(", "tempdir", ")", "\n", "", "serialization_dir", "=", "tempdir", "\n", "# Load config", "\n", "", "config_file", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "CONFIG_NAME", ")", "\n", "config", "=", "BertConfig", ".", "from_json_file", "(", "config_file", ")", "\n", "logger", ".", "info", "(", "\"Model config {}\"", ".", "format", "(", "config", ")", ")", "\n", "# Instantiate model.", "\n", "model", "=", "cls", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "weights_path", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "WEIGHTS_NAME", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "weights_path", ",", "map_location", "=", "'cpu'", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "None", ")", "\n", "", "if", "tempdir", ":", "\n", "# Clean up temp dir", "\n", "            ", "shutil", ".", "rmtree", "(", "tempdir", ")", "\n", "", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "            ", "weights_path", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "TF_WEIGHTS_NAME", ")", "\n", "return", "load_tf_weights_in_bert", "(", "model", ",", "weights_path", ")", "\n", "# Load from a PyTorch state_dict", "\n", "", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "new_key", "=", "None", "\n", "if", "'gamma'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "new_key", ":", "\n", "                ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "            ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "            ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                ", "if", "child", "is", "not", "None", ":", "\n", "                    ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "", "", "", "start_prefix", "=", "''", "\n", "if", "not", "hasattr", "(", "model", ",", "'bert'", ")", "and", "any", "(", "s", ".", "startswith", "(", "'bert.'", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "start_prefix", "=", "'bert.'", "\n", "", "load", "(", "model", ",", "prefix", "=", "start_prefix", ")", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Error(s) in loading state_dict for {}:\\n\\t{}'", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertModel.__init__": [[703, 709], ["modeling.BertPreTrainedModel.__init__", "modeling.BertEmbeddings", "modeling.BertEncoder", "modeling.BertPooler", "modeling.BertModel.apply"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertModel.forward": [[710, 740], ["torch.ones_like.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "modeling.BertModel.embeddings", "modeling.BertModel.encoder", "modeling.BertModel.pooler", "torch.ones_like", "torch.zeros_like", "torch.ones_like.unsqueeze", "next", "modeling.BertModel.parameters"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "output_all_encoded_layers", "=", "True", ")", ":", "\n", "        ", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones_like", "(", "input_ids", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids", ",", "token_type_ids", ")", "\n", "encoded_layers", "=", "self", ".", "encoder", "(", "embedding_output", ",", "\n", "extended_attention_mask", ",", "\n", "output_all_encoded_layers", "=", "output_all_encoded_layers", ")", "\n", "sequence_output", "=", "encoded_layers", "[", "-", "1", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "encoded_layers", "=", "encoded_layers", "[", "-", "1", "]", "\n", "", "return", "encoded_layers", ",", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertForPreTraining.__init__": [[792, 797], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "modeling.BertPreTrainingHeads", "modeling.BertForPreTraining.apply"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForPreTraining", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertPreTrainingHeads", "(", "config", ",", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertForPreTraining.forward": [[798, 811], ["modeling.BertForPreTraining.bert", "modeling.BertForPreTraining.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "prediction_scores.view", "masked_lm_labels.view", "seq_relationship_score.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ",", "next_sentence_label", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "prediction_scores", ",", "seq_relationship_score", "=", "self", ".", "cls", "(", "sequence_output", ",", "pooled_output", ")", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", "and", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "total_loss", "=", "masked_lm_loss", "+", "next_sentence_loss", "\n", "return", "total_loss", "\n", "", "else", ":", "\n", "            ", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertForMaskedLM.__init__": [[855, 860], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "modeling.BertOnlyMLMHead", "modeling.BertForMaskedLM.apply"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyMLMHead", "(", "config", ",", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertForMaskedLM.forward": [[861, 872], ["modeling.BertForMaskedLM.bert", "modeling.BertForMaskedLM.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForMaskedLM.view", "masked_lm_labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "prediction_scores", "=", "self", ".", "cls", "(", "sequence_output", ")", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "masked_lm_loss", "\n", "", "else", ":", "\n", "            ", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertForNextSentencePrediction.__init__": [[917, 922], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "modeling.BertOnlyNSPHead", "modeling.BertForNextSentencePrediction.apply"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForNextSentencePrediction", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyNSPHead", "(", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertForNextSentencePrediction.forward": [[923, 934], ["modeling.BertForNextSentencePrediction.bert", "modeling.BertForNextSentencePrediction.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForNextSentencePrediction.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "next_sentence_label", "=", "None", ")", ":", "\n", "        ", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "seq_relationship_score", "=", "self", ".", "cls", "(", "pooled_output", ")", "\n", "\n", "if", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "next_sentence_loss", "\n", "", "else", ":", "\n", "            ", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertForSequenceClassification.__init__": [[981, 988], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling.BertForSequenceClassification.apply"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "num_labels", ")", ":", "\n", "        ", "super", "(", "BertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_labels", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertForSequenceClassification.forward": [[989, 1000], ["modeling.BertForSequenceClassification.bert", "modeling.BertForSequenceClassification.dropout", "modeling.BertForSequenceClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "loss", "\n", "", "else", ":", "\n", "            ", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertForMultipleChoice.__init__": [[1046, 1053], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling.BertForMultipleChoice.apply"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "num_choices", ")", ":", "\n", "        ", "super", "(", "BertForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_choices", "=", "num_choices", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertForMultipleChoice.forward": [[1054, 1069], ["input_ids.view", "token_type_ids.view", "attention_mask.view", "modeling.BertForMultipleChoice.bert", "modeling.BertForMultipleChoice.dropout", "modeling.BertForMultipleChoice.classifier", "modeling.BertForMultipleChoice.view", "input_ids.size", "token_type_ids.size", "attention_mask.size", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss."], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "\n", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "flat_input_ids", ",", "flat_token_type_ids", ",", "flat_attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_choices", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "return", "loss", "\n", "", "else", ":", "\n", "            ", "return", "reshaped_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertForTokenClassification.__init__": [[1116, 1123], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling.BertForTokenClassification.apply"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "num_labels", ")", ":", "\n", "        ", "super", "(", "BertForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_labels", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertForTokenClassification.forward": [[1124, 1142], ["modeling.BertForTokenClassification.bert", "modeling.BertForTokenClassification.dropout", "modeling.BertForTokenClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "modeling.BertForTokenClassification.view", "labels.view", "modeling.BertForTokenClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "return", "loss", "\n", "", "else", ":", "\n", "            ", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertForQuestionAnswering.__init__": [[1191, 1198], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "torch.nn.Linear", "modeling.BertForQuestionAnswering.apply"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "# TODO check with Google if it's normal there is no dropout on the token classifier of SQuAD in the TF version", "\n", "# self.dropout = nn.Dropout(config.hidden_dropout_prob)", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.BertForQuestionAnswering.forward": [[1199, 1224], ["modeling.BertForQuestionAnswering.bert", "modeling.BertForQuestionAnswering.qa_outputs", "modeling.BertForQuestionAnswering.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "return", "total_loss", "\n", "", "else", ":", "\n", "            ", "return", "start_logits", ",", "end_logits", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.load_tf_weights_in_bert": [[53, 112], ["os.path.abspath", "print", "tf.train.list_variables", "zip", "print", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "any", "print", "torch.from_numpy", "print", "print", "re.fullmatch", "getattr", "re.split", "getattr", "len", "int", "np.transpose", "getattr", "getattr", "getattr"], "function", ["None"], ["def", "load_tf_weights_in_bert", "(", "model", ",", "tf_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "print", "(", "\"Loading a TensorFlow models in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "print", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "print", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", ".", "split", "(", "'/'", ")", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "any", "(", "n", "in", "[", "\"adam_v\"", ",", "\"adam_m\"", "]", "for", "n", "in", "name", ")", ":", "\n", "            ", "print", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r'[A-Za-z]+_\\d+'", ",", "m_name", ")", ":", "\n", "                ", "l", "=", "re", ".", "split", "(", "r'_(\\d+)'", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "l", "=", "[", "m_name", "]", "\n", "", "if", "l", "[", "0", "]", "==", "'kernel'", "or", "l", "[", "0", "]", "==", "'gamma'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'output_bias'", "or", "l", "[", "0", "]", "==", "'beta'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'bias'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'output_weights'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "else", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "", "if", "len", "(", "l", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "if", "m_name", "[", "-", "11", ":", "]", "==", "'_embeddings'", ":", "\n", "            ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "m_name", "==", "'kernel'", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "print", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.gelu": [[114, 121], ["torch.erf", "math.sqrt"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\"Implementation of the gelu activation function.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.swish": [[123, 125], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2Config.__init__": [[108, 151], ["isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "50257", ",", "\n", "n_positions", "=", "1024", ",", "\n", "n_ctx", "=", "1024", ",", "\n", "n_embd", "=", "768", ",", "\n", "n_layer", "=", "12", ",", "\n", "n_head", "=", "12", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs GPT2Config.\n\n        Args:\n            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `GPT2Model` or a configuration json file.\n            n_positions: Number of positional embeddings.\n            n_ctx: Size of the causal mask (usually same as n_positions).\n            n_embd: Dimensionality of the embeddings and hidden states.\n            n_layer: Number of hidden layers in the Transformer encoder.\n            n_head: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            layer_norm_epsilon: epsilon to use in the layer norm layers\n            initializer_range: The sttdev of the truncated_normal_initializer for\n                initializing all weight matrices.\n        \"\"\"", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "n_embd", "=", "n_embd", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2Config.from_dict": [[154, 161], ["modeling_gpt2.GPT2Config", "json_object.items"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `GPT2Config` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "GPT2Config", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2Config.from_json_file": [[162, 168], ["cls.from_dict", "io.open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `GPT2Config` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2Config.__repr__": [[169, 171], ["str", "modeling_gpt2.GPT2Config.to_json_string"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2Config.to_dict": [[172, 176], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2Config.to_json_string": [[177, 180], ["json.dumps", "modeling_gpt2.GPT2Config.to_dict"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.Conv1D.__init__": [[183, 190], ["torch.Module.__init__", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.init.normal_", "torch.init.normal_", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "nx", ")", ":", "\n", "        ", "super", "(", "Conv1D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nf", "=", "nf", "\n", "w", "=", "torch", ".", "empty", "(", "nx", ",", "nf", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "w", ",", "std", "=", "0.02", ")", "\n", "self", ".", "weight", "=", "Parameter", "(", "w", ")", "\n", "self", ".", "bias", "=", "Parameter", "(", "torch", ".", "zeros", "(", "nf", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.Conv1D.forward": [[191, 196], ["torch.addmm", "torch.addmm", "torch.addmm", "torch.addmm", "x.view.view.view", "x.view.view.view", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "size_out", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "nf", ",", ")", "\n", "x", "=", "torch", ".", "addmm", "(", "self", ".", "bias", ",", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ",", "self", ".", "weight", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "size_out", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.Attention.__init__": [[199, 210], ["torch.Module.__init__", "modeling_gpt2.Attention.register_buffer", "modeling_gpt2.Conv1D", "modeling_gpt2.Conv1D", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "register_buffer", "(", "\"bias\"", ",", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "n_ctx", ",", "n_ctx", ")", ")", ".", "view", "(", "1", ",", "1", ",", "n_ctx", ",", "n_ctx", ")", ")", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "c_attn", "=", "Conv1D", "(", "n_state", "*", "3", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.Attention._attn": [[211, 221], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul.size", "torch.matmul.size", "torch.matmul.size", "torch.matmul.size", "torch.Softmax", "torch.Softmax", "math.sqrt", "v.size"], "methods", ["None"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "math", ".", "sqrt", "(", "v", ".", "size", "(", "-", "1", ")", ")", "\n", "", "nd", ",", "ns", "=", "w", ".", "size", "(", "-", "2", ")", ",", "w", ".", "size", "(", "-", "1", ")", "\n", "b", "=", "self", ".", "bias", "[", ":", ",", ":", ",", "ns", "-", "nd", ":", "ns", ",", ":", "ns", "]", "\n", "w", "=", "w", "*", "b", "-", "1e10", "*", "(", "1", "-", "b", ")", "\n", "\n", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "return", "torch", ".", "matmul", "(", "w", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.Attention.merge_heads": [[222, 226], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["None"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "x", ".", "size", "(", "-", "2", ")", "*", "x", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct merge_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.Attention.split_heads": [[227, 234], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "split_heads", "(", "self", ",", "x", ",", "k", "=", "False", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "n_head", ",", "x", ".", "size", "(", "-", "1", ")", "//", "self", ".", "n_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct split_states", "\n", "if", "k", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "# (batch, head, head_features, seq_length)", "\n", "", "else", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "# (batch, head, seq_length, head_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.Attention.forward": [[235, 250], ["modeling_gpt2.Attention.c_attn", "modeling_gpt2.Attention.split", "modeling_gpt2.Attention.split_heads", "modeling_gpt2.Attention.split_heads", "modeling_gpt2.Attention.split_heads", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "modeling_gpt2.Attention._attn", "modeling_gpt2.Attention.merge_heads", "modeling_gpt2.Attention.c_proj", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layer_past[].transpose", "torch.cat.transpose", "torch.cat.transpose"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Attention._attn", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Attention.merge_heads"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "layer_past", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "x", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ",", "k", "=", "True", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "if", "layer_past", "is", "not", "None", ":", "\n", "            ", "past_key", ",", "past_value", "=", "layer_past", "[", "0", "]", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "layer_past", "[", "1", "]", "# transpose back cf below", "\n", "key", "=", "torch", ".", "cat", "(", "(", "past_key", ",", "key", ")", ",", "dim", "=", "-", "1", ")", "\n", "value", "=", "torch", ".", "cat", "(", "(", "past_value", ",", "value", ")", ",", "dim", "=", "-", "2", ")", "\n", "", "present", "=", "torch", ".", "stack", "(", "(", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "value", ")", ")", "# transpose to have same shapes for stacking", "\n", "a", "=", "self", ".", "_attn", "(", "query", ",", "key", ",", "value", ")", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "return", "a", ",", "present", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.MLP.__init__": [[253, 259], ["torch.Module.__init__", "modeling_gpt2.Conv1D", "modeling_gpt2.Conv1D"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ")", ":", "# in MLP: n_state=3072 (4 * n_embd)", "\n", "        ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "nx", ",", "n_state", ")", "\n", "self", ".", "act", "=", "gelu", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.MLP.forward": [[260, 264], ["modeling_gpt2.MLP.act", "modeling_gpt2.MLP.c_proj", "modeling_gpt2.MLP.c_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "return", "h2", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.Block.__init__": [[267, 274], ["torch.Module.__init__", "modeling.BertLayerNorm", "modeling_gpt2.Attention", "modeling.BertLayerNorm", "modeling_gpt2.MLP"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "ln_1", "=", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "self", ".", "ln_2", "=", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "4", "*", "nx", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.Block.forward": [[275, 281], ["modeling_gpt2.Block.attn", "modeling_gpt2.Block.mlp", "modeling_gpt2.Block.ln_1", "modeling_gpt2.Block.ln_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "layer_past", "=", "None", ")", ":", "\n", "        ", "a", ",", "present", "=", "self", ".", "attn", "(", "self", ".", "ln_1", "(", "x", ")", ",", "layer_past", "=", "layer_past", ")", "\n", "x", "=", "x", "+", "a", "\n", "m", "=", "self", ".", "mlp", "(", "self", ".", "ln_2", "(", "x", ")", ")", "\n", "x", "=", "x", "+", "m", "\n", "return", "x", ",", "present", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2LMHead.__init__": [[286, 290], ["torch.Module.__init__", "modeling_gpt2.GPT2LMHead.set_embeddings_weights"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.set_embeddings_weights"], ["def", "__init__", "(", "self", ",", "model_embeddings_weights", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2LMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_embd", "=", "config", ".", "n_embd", "\n", "self", ".", "set_embeddings_weights", "(", "model_embeddings_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2LMHead.set_embeddings_weights": [[291, 295], ["torch.Linear", "torch.Linear"], "methods", ["None"], ["", "def", "set_embeddings_weights", "(", "self", ",", "model_embeddings_weights", ")", ":", "\n", "        ", "embed_shape", "=", "model_embeddings_weights", ".", "shape", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "embed_shape", "[", "1", "]", ",", "embed_shape", "[", "0", "]", ",", "bias", "=", "False", ")", "\n", "self", ".", "decoder", ".", "weight", "=", "model_embeddings_weights", "# Tied weights", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2LMHead.forward": [[296, 301], ["modeling_gpt2.GPT2LMHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_state", ")", ":", "\n", "# Truncated Language modeling logits (we remove the last token)", "\n", "# h_trunc = h[:, :-1].contiguous().view(-1, self.n_embd)", "\n", "        ", "lm_logits", "=", "self", ".", "decoder", "(", "hidden_state", ")", "\n", "return", "lm_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2MultipleChoiceHead.__init__": [[306, 313], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2MultipleChoiceHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_embd", "=", "config", ".", "n_embd", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "1", ")", "\n", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "linear", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "linear", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2MultipleChoiceHead.forward": [[314, 325], ["mc_token_ids.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand", "hidden_states.gather().squeeze", "modeling_gpt2.GPT2MultipleChoiceHead.linear().squeeze", "hidden_states.size", "mc_token_ids.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze", "hidden_states.gather", "modeling_gpt2.GPT2MultipleChoiceHead.linear", "mc_token_ids.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "mc_token_ids", ")", ":", "\n", "# Classification logits", "\n", "# hidden_state (bsz, num_choices, seq_length, hidden_size)", "\n", "# mc_token_ids (bsz, num_choices)", "\n", "        ", "mc_token_ids", "=", "mc_token_ids", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "-", "1", ",", "hidden_states", ".", "size", "(", "-", "1", ")", ")", "\n", "# (bsz, num_choices, 1, hidden_size)", "\n", "multiple_choice_h", "=", "hidden_states", ".", "gather", "(", "2", ",", "mc_token_ids", ")", ".", "squeeze", "(", "2", ")", "\n", "# (bsz, num_choices, hidden_size)", "\n", "multiple_choice_logits", "=", "self", ".", "linear", "(", "multiple_choice_h", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "# (bsz, num_choices)", "\n", "return", "multiple_choice_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2PreTrainedModel.__init__": [[332, 343], ["torch.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "GPT2PreTrainedModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "GPT2Config", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `GPT2Config`. \"", "\n", "\"To create a model from a pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", ")", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2PreTrainedModel.set_tied": [[344, 346], ["None"], "methods", ["None"], ["", "def", "set_tied", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2PreTrainedModel.init_weights": [[347, 359], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2PreTrainedModel.from_pretrained": [[360, 478], ["modeling_gpt2.GPT2Config.from_json_file", "logger.info", "cls", "torch.load.keys", "torch.load.keys", "zip", "getattr", "torch.load.copy", "torch.load.copy", "modeling_gpt2.GPT2PreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_json_file"], ["", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "\n", "cls", ",", "pretrained_model_name_or_path", ",", "state_dict", "=", "None", ",", "cache_dir", "=", "None", ",", "from_tf", "=", "False", ",", "*", "inputs", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a GPT2PreTrainedModel from a pre-trained model file or a pytorch state dict.\n        Download and cache the pre-trained model file if needed.\n\n        Params:\n            pretrained_model_name_or_path: either:\n                - a str with the name of a pre-trained model to load selected in the list of:\n                    . `openai-gpt`\n                - a path or url to a pretrained model archive containing:\n                    . `gpt2_config.json` a configuration file for the model\n                    . `pytorch_model.bin` a PyTorch dump of a GPT2Model instance\n                - a path or url to a pretrained model archive containing:\n                    . `bert_config.json` a configuration file for the model\n                    . a TensorFlow checkpoint with trained weights\n            from_tf: should we load the weights from a locally saved TensorFlow checkpoint\n            cache_dir: an optional path to a folder in which the pre-trained models will be cached.\n            state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of pre-trained models\n            *inputs, **kwargs: additional input for the specific Bert class\n                (ex: num_labels for BertForSequenceClassification)\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_MODEL_ARCHIVE_MAP", ":", "\n", "            ", "archive_file", "=", "PRETRAINED_MODEL_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "config_file", "=", "PRETRAINED_CONFIG_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "config_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CONFIG_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "resolved_config_file", "=", "cached_path", "(", "config_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} and {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\", \"", ".", "join", "(", "PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "pretrained_model_name_or_path", ",", "\n", "archive_file", ",", "config_file", "\n", ")", "\n", ")", "\n", "return", "None", "\n", "", "if", "resolved_archive_file", "==", "archive_file", "and", "resolved_config_file", "==", "config_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading configuration file {}\"", ".", "format", "(", "config_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading configuration file {} from cache at {}\"", ".", "format", "(", "\n", "config_file", ",", "resolved_config_file", ")", ")", "\n", "# Load config", "\n", "", "config", "=", "GPT2Config", ".", "from_json_file", "(", "resolved_config_file", ")", "\n", "logger", ".", "info", "(", "\"Model config {}\"", ".", "format", "(", "config", ")", ")", "\n", "# Instantiate model.", "\n", "model", "=", "cls", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "'cpu'", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "None", ")", "\n", "", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint (stored as NumPy array)", "\n", "            ", "return", "load_tf_weights_in_gpt2", "(", "model", ",", "resolved_archive_file", ")", "\n", "\n", "", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "new_key", "=", "None", "\n", "if", "key", ".", "endswith", "(", "\".g\"", ")", ":", "\n", "                ", "new_key", "=", "key", "[", ":", "-", "2", "]", "+", "\".weight\"", "\n", "", "elif", "key", ".", "endswith", "(", "\".b\"", ")", ":", "\n", "                ", "new_key", "=", "key", "[", ":", "-", "2", "]", "+", "\".bias\"", "\n", "", "elif", "key", ".", "endswith", "(", "\".w\"", ")", ":", "\n", "                ", "new_key", "=", "key", "[", ":", "-", "2", "]", "+", "\".weight\"", "\n", "", "if", "new_key", ":", "\n", "                ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "            ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "\"_metadata\"", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "\"\"", ")", ":", "\n", "            ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", "\n", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                ", "if", "child", "is", "not", "None", ":", "\n", "                    ", "load", "(", "child", ",", "prefix", "+", "name", "+", "\".\"", ")", "\n", "\n", "", "", "", "start_model", "=", "model", "\n", "if", "hasattr", "(", "model", ",", "\"transformer\"", ")", "and", "all", "(", "not", "s", ".", "startswith", "(", "'transformer.'", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "start_model", "=", "model", ".", "transformer", "\n", "", "load", "(", "start_model", ",", "prefix", "=", "\"\"", ")", "\n", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", "\n", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", "\n", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Error(s) in loading state_dict for {}:\\n\\t{}\"", ".", "format", "(", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", "\n", ")", "\n", "\n", "# Make sure we are still sharing the output and input embeddings after loading weights", "\n", "", "model", ".", "set_tied", "(", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2Model.__init__": [[514, 523], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "modeling_gpt2.Block", "torch.ModuleList", "torch.ModuleList", "modeling.BertLayerNorm", "modeling_gpt2.GPT2Model.apply", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2Model", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "wte", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "wpe", "=", "nn", ".", "Embedding", "(", "config", ".", "n_positions", ",", "config", ".", "n_embd", ")", "\n", "block", "=", "Block", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "block", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "ln_f", "=", "LayerNorm", "(", "config", ".", "n_embd", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2Model.forward": [[524, 553], ["input_ids.view.view.size", "input_ids.view.view.view", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.view", "modeling_gpt2.GPT2Model.wte", "modeling_gpt2.GPT2Model.wpe", "zip", "modeling_gpt2.GPT2Model.ln_f", "[].size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "input_ids.view.view.size", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.size", "token_type_ids.view.view.view", "modeling_gpt2.GPT2Model.wte", "block", "presents.append", "modeling_gpt2.GPT2Model.view", "len", "token_type_ids.view.view.size", "modeling_gpt2.GPT2Model.size", "input_ids.view.view.size", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "past", "=", "None", ")", ":", "\n", "        ", "if", "past", "is", "None", ":", "\n", "            ", "past_length", "=", "0", "\n", "past", "=", "[", "None", "]", "*", "len", "(", "self", ".", "h", ")", "\n", "", "else", ":", "\n", "            ", "past_length", "=", "past", "[", "0", "]", "[", "0", "]", ".", "size", "(", "-", "2", ")", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "past_length", ",", "input_ids", ".", "size", "(", "-", "1", ")", "+", "past_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "\n", "", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "inputs_embeds", "=", "self", ".", "wte", "(", "input_ids", ")", "\n", "position_embeds", "=", "self", ".", "wpe", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "token_type_embeds", "=", "self", ".", "wte", "(", "token_type_ids", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "presents", "=", "[", "]", "\n", "for", "block", ",", "layer_past", "in", "zip", "(", "self", ".", "h", ",", "past", ")", ":", "\n", "            ", "hidden_states", ",", "present", "=", "block", "(", "hidden_states", ",", "layer_past", ")", "\n", "presents", ".", "append", "(", "present", ")", "\n", "", "hidden_states", "=", "self", ".", "ln_f", "(", "hidden_states", ")", "\n", "output_shape", "=", "input_shape", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", "presents", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2LMHeadModel.__init__": [[594, 599], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "modeling_gpt2.GPT2Model", "modeling_gpt2.GPT2LMHead", "modeling_gpt2.GPT2LMHeadModel.apply"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2LMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "GPT2LMHead", "(", "self", ".", "transformer", ".", "wte", ".", "weight", ",", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2LMHeadModel.set_tied": [[600, 604], ["modeling_gpt2.GPT2LMHeadModel.lm_head.set_embeddings_weights"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.set_embeddings_weights"], ["", "def", "set_tied", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the embeddings\n        \"\"\"", "\n", "self", ".", "lm_head", ".", "set_embeddings_weights", "(", "self", ".", "transformer", ".", "wte", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2LMHeadModel.forward": [[605, 613], ["modeling_gpt2.GPT2LMHeadModel.transformer", "modeling_gpt2.GPT2LMHeadModel.lm_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_gpt2.GPT2LMHeadModel.view", "lm_labels.view", "modeling_gpt2.GPT2LMHeadModel.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "lm_labels", "=", "None", ",", "past", "=", "None", ")", ":", "\n", "        ", "hidden_states", ",", "presents", "=", "self", ".", "transformer", "(", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "past", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "size", "(", "-", "1", ")", ")", ",", "lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "loss", "\n", "", "return", "lm_logits", ",", "presents", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2DoubleHeadsModel.__init__": [[659, 665], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "modeling_gpt2.GPT2Model", "modeling_gpt2.GPT2LMHead", "modeling_gpt2.GPT2MultipleChoiceHead", "modeling_gpt2.GPT2DoubleHeadsModel.apply"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2DoubleHeadsModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "GPT2LMHead", "(", "self", ".", "transformer", ".", "wte", ".", "weight", ",", "config", ")", "\n", "self", ".", "multiple_choice_head", "=", "GPT2MultipleChoiceHead", "(", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2DoubleHeadsModel.set_tied": [[666, 670], ["modeling_gpt2.GPT2DoubleHeadsModel.lm_head.set_embeddings_weights"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.set_embeddings_weights"], ["", "def", "set_tied", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the embeddings\n        \"\"\"", "\n", "self", ".", "lm_head", ".", "set_embeddings_weights", "(", "self", ".", "transformer", ".", "wte", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.GPT2DoubleHeadsModel.forward": [[671, 685], ["modeling_gpt2.GPT2DoubleHeadsModel.transformer", "modeling_gpt2.GPT2DoubleHeadsModel.lm_head", "modeling_gpt2.GPT2DoubleHeadsModel.multiple_choice_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "losses.append", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "losses.append", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_gpt2.GPT2DoubleHeadsModel.view", "lm_labels.view", "modeling_gpt2.GPT2DoubleHeadsModel.view", "mc_labels.view", "modeling_gpt2.GPT2DoubleHeadsModel.size", "modeling_gpt2.GPT2DoubleHeadsModel.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "mc_token_ids", ",", "lm_labels", "=", "None", ",", "mc_labels", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "past", "=", "None", ")", ":", "\n", "        ", "hidden_states", ",", "presents", "=", "self", ".", "transformer", "(", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "past", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "hidden_states", ",", "mc_token_ids", ")", "\n", "losses", "=", "[", "]", "\n", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "losses", ".", "append", "(", "loss_fct", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "size", "(", "-", "1", ")", ")", ",", "lm_labels", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "", "if", "mc_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "losses", ".", "append", "(", "loss_fct", "(", "mc_logits", ".", "view", "(", "-", "1", ",", "mc_logits", ".", "size", "(", "-", "1", ")", ")", ",", "mc_labels", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "", "if", "losses", ":", "\n", "            ", "return", "losses", "\n", "", "return", "lm_logits", ",", "mc_logits", ",", "presents", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.load_tf_weights_in_gpt2": [[46, 98], ["os.path.abspath", "print", "tf.train.list_variables", "zip", "print", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "print", "torch.from_numpy", "torch.from_numpy", "print", "tf.train.load_variable.squeeze", "re.fullmatch", "re.split", "getattr", "len", "int", "getattr", "getattr", "getattr", "getattr"], "function", ["None"], ["def", "load_tf_weights_in_gpt2", "(", "model", ",", "gpt2_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "print", "(", "\"Loading a TensorFlow models in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "gpt2_checkpoint_path", ")", "\n", "print", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "print", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ".", "squeeze", "(", ")", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", "[", "6", ":", "]", "# skip \"model/\"", "\n", "name", "=", "name", ".", "split", "(", "'/'", ")", "\n", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r'[A-Za-z]+\\d+'", ",", "m_name", ")", ":", "\n", "                ", "l", "=", "re", ".", "split", "(", "r'(\\d+)'", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "l", "=", "[", "m_name", "]", "\n", "", "if", "l", "[", "0", "]", "==", "'w'", "or", "l", "[", "0", "]", "==", "'g'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'b'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'bias'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'wpe'", "or", "l", "[", "0", "]", "==", "'wte'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "else", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "", "if", "len", "(", "l", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "print", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.gelu": [[100, 102], ["torch.tanh", "torch.tanh", "math.sqrt", "torch.pow", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch": [[26, 38], ["external.pytorch_pretrained_bert.modeling.BertConfig.from_json_file", "print", "external.pytorch_pretrained_bert.modeling.BertForPreTraining", "external.pytorch_pretrained_bert.modeling.load_tf_weights_in_bert", "print", "torch.save", "external.pytorch_pretrained_bert.modeling.BertForPreTraining.state_dict", "str"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_json_file", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling.load_tf_weights_in_bert", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict"], ["def", "convert_tf_checkpoint_to_pytorch", "(", "tf_checkpoint_path", ",", "bert_config_file", ",", "pytorch_dump_path", ")", ":", "\n", "# Initialise PyTorch model", "\n", "    ", "config", "=", "BertConfig", ".", "from_json_file", "(", "bert_config_file", ")", "\n", "print", "(", "\"Building PyTorch model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "model", "=", "BertForPreTraining", "(", "config", ")", "\n", "\n", "# Load weights from tf checkpoint", "\n", "load_tf_weights_in_bert", "(", "model", ",", "tf_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_dump_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.convert_openai_checkpoint_to_pytorch.convert_openai_checkpoint_to_pytorch": [[30, 49], ["external.pytorch_pretrained_bert.modeling_openai.OpenAIGPTModel", "external.pytorch_pretrained_bert.modeling_openai.load_tf_weights_in_openai_gpt", "print", "torch.save", "print", "external.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig", "external.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig", "external.pytorch_pretrained_bert.modeling_openai.OpenAIGPTModel.state_dict", "io.open", "f.write", "external.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.load_tf_weights_in_openai_gpt", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string"], ["def", "convert_openai_checkpoint_to_pytorch", "(", "openai_checkpoint_folder_path", ",", "openai_config_file", ",", "pytorch_dump_folder_path", ")", ":", "\n", "# Construct model", "\n", "    ", "if", "openai_config_file", "==", "\"\"", ":", "\n", "        ", "config", "=", "OpenAIGPTConfig", "(", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "OpenAIGPTConfig", "(", "openai_config_file", ")", "\n", "", "model", "=", "OpenAIGPTModel", "(", "config", ")", "\n", "\n", "# Load weights from numpy", "\n", "load_tf_weights_in_openai_gpt", "(", "model", ",", "openai_checkpoint_folder_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "WEIGHTS_NAME", "\n", "pytorch_config_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "CONFIG_NAME", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_weights_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.optimization.BertAdam.__init__": [[59, 78], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "required", ",", "warmup", "=", "-", "1", ",", "t_total", "=", "-", "1", ",", "schedule", "=", "'warmup_linear'", ",", "\n", "b1", "=", "0.9", ",", "b2", "=", "0.999", ",", "e", "=", "1e-6", ",", "weight_decay", "=", "0.01", ",", "\n", "max_grad_norm", "=", "1.0", ")", ":", "\n", "        ", "if", "lr", "is", "not", "required", "and", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "schedule", "not", "in", "SCHEDULES", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid schedule parameter: {}\"", ".", "format", "(", "schedule", ")", ")", "\n", "", "if", "not", "0.0", "<=", "warmup", "<", "1.0", "and", "not", "warmup", "==", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\"", ".", "format", "(", "warmup", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b1", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b1 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b1", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b2", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b2 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b2", ")", ")", "\n", "", "if", "not", "e", ">=", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {} - should be >= 0.0\"", ".", "format", "(", "e", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "schedule", "=", "schedule", ",", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "\n", "b1", "=", "b1", ",", "b2", "=", "b2", ",", "e", "=", "e", ",", "weight_decay", "=", "weight_decay", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "super", "(", "BertAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.optimization.BertAdam.get_lr": [[79, 93], ["lr.append", "len", "schedule_fct"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "lr", "=", "[", "]", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "return", "[", "0", "]", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "", "lr", ".", "append", "(", "lr_scheduled", ")", "\n", "", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.optimization.BertAdam.step": [[94, 163], ["closure", "next_m.mul_().add_", "next_v.mul_().addcmul_", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.nn.utils.clip_grad_norm_", "next_m.mul_", "next_v.mul_", "next_v.sqrt", "schedule_fct"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'next_m'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'next_v'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "next_m", ",", "next_v", "=", "state", "[", "'next_m'", "]", ",", "state", "[", "'next_v'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'b1'", "]", ",", "group", "[", "'b2'", "]", "\n", "\n", "# Add grad clipping", "\n", "if", "group", "[", "'max_grad_norm'", "]", ">", "0", ":", "\n", "                    ", "clip_grad_norm_", "(", "p", ",", "group", "[", "'max_grad_norm'", "]", ")", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "# In-place operations to update the averages at the same time", "\n", "", "next_m", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "next_v", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "update", "=", "next_m", "/", "(", "next_v", ".", "sqrt", "(", ")", "+", "group", "[", "'e'", "]", ")", "\n", "\n", "# Just adding the square of the weights to the loss function is *not*", "\n", "# the correct way of using L2 regularization/weight decay with Adam,", "\n", "# since that will interact with the m and v parameters in strange ways.", "\n", "#", "\n", "# Instead we want to decay the weights in a manner that doesn't interact", "\n", "# with the m/v parameters. This is equivalent to adding the square", "\n", "# of the weights to the loss with plain (non-momentum) SGD.", "\n", "if", "group", "[", "'weight_decay'", "]", ">", "0.0", ":", "\n", "                    ", "update", "+=", "group", "[", "'weight_decay'", "]", "*", "p", ".", "data", "\n", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "\n", "", "update_with_lr", "=", "lr_scheduled", "*", "update", "\n", "p", ".", "data", ".", "add_", "(", "-", "update_with_lr", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# step_size = lr_scheduled * math.sqrt(bias_correction2) / bias_correction1", "\n", "# No bias correction", "\n", "# bias_correction1 = 1 - beta1 ** state['step']", "\n", "# bias_correction2 = 1 - beta2 ** state['step']", "\n", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.optimization.warmup_cosine": [[23, 27], ["torch.cos"], "function", ["None"], ["def", "warmup_cosine", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "0.5", "*", "(", "1.0", "+", "torch", ".", "cos", "(", "math", ".", "pi", "*", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.optimization.warmup_constant": [[28, 32], ["None"], "function", ["None"], ["", "def", "warmup_constant", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.optimization.warmup_linear": [[33, 37], ["None"], "function", ["None"], ["", "def", "warmup_linear", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "1.0", "-", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.from_pretrained": [[88, 130], ["cls", "os.path.join", "os.path.join", "file_utils.cached_path", "file_utils.cached_path", "logger.info", "logger.info", "logger.info", "logger.info", "min", "logger.error", "kwargs.get", "int", "PRETRAINED_VOCAB_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.cached_path", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.cached_path", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a PreTrainedBertModel from a pre-trained model file.\n        Download and cache the pre-trained model file if needed.\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_ARCHIVE_MAP", ":", "\n", "            ", "vocab_file", "=", "PRETRAINED_VOCAB_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "merges_file", "=", "PRETRAINED_MERGES_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "VOCAB_NAME", ")", "\n", "merges_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "MERGES_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_vocab_file", "=", "cached_path", "(", "vocab_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "resolved_merges_file", "=", "cached_path", "(", "merges_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} and {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_VOCAB_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "vocab_file", ",", "merges_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_vocab_file", "==", "vocab_file", "and", "resolved_merges_file", "==", "merges_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {}\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading merges file {}\"", ".", "format", "(", "merges_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {} from cache at {}\"", ".", "format", "(", "\n", "vocab_file", ",", "resolved_vocab_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading merges file {} from cache at {}\"", ".", "format", "(", "\n", "merges_file", ",", "resolved_merges_file", ")", ")", "\n", "", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", ":", "\n", "# if we're using a pretrained model, ensure the tokenizer wont index sequences longer", "\n", "# than the number of positional embeddings", "\n", "            ", "max_len", "=", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "kwargs", "[", "'max_len'", "]", "=", "min", "(", "kwargs", ".", "get", "(", "'max_len'", ",", "int", "(", "1e12", ")", ")", ",", "max_len", ")", "\n", "# Instantiate tokenizer.", "\n", "", "tokenizer", "=", "cls", "(", "resolved_vocab_file", ",", "resolved_merges_file", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.__init__": [[131, 145], ["json.load", "tokenization_gpt2.bytes_to_unicode", "dict", "regex.compile", "int", "io.open", "io.open().read().split", "tuple", "zip", "tokenization_gpt2.GPT2Tokenizer.encoder.items", "tokenization_gpt2.GPT2Tokenizer.byte_encoder.items", "merge.split", "range", "io.open().read", "len", "io.open"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.bytes_to_unicode", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read"], ["", "def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "errors", "=", "'replace'", ",", "max_len", "=", "None", ")", ":", "\n", "        ", "self", ".", "max_len", "=", "max_len", "if", "max_len", "is", "not", "None", "else", "int", "(", "1e12", ")", "\n", "self", ".", "encoder", "=", "json", ".", "load", "(", "open", "(", "vocab_file", ")", ")", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "errors", "=", "errors", "# how to handle errors in decoding", "\n", "self", ".", "byte_encoder", "=", "bytes_to_unicode", "(", ")", "\n", "self", ".", "byte_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "byte_encoder", ".", "items", "(", ")", "}", "\n", "bpe_data", "=", "open", "(", "merges_file", ",", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "[", "1", ":", "-", "1", "]", "\n", "bpe_merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "bpe_data", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "bpe_merges", ",", "range", "(", "len", "(", "bpe_merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n", "# Should haved added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions", "\n", "self", ".", "pat", "=", "re", ".", "compile", "(", "r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.__len__": [[146, 148], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.bpe": [[149, 189], ["tuple", "tokenization_gpt2.get_pairs", "min", "tuple", "len", "len", "tokenization_gpt2.get_pairs", "tuple.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_gpt2.GPT2Tokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.get_pairs", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.get_pairs", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "word", "=", "tuple", "(", "token", ")", "\n", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "' '", ".", "join", "(", "word", ")", "\n", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.encode": [[190, 202], ["regex.findall", "bpe_tokens.extend", "len", "ValueError", "len", "token.encode", "tokenization_gpt2.GPT2Tokenizer.bpe().split", "tokenization_gpt2.GPT2Tokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.tokenization_roberta.RobertaTokenizer.bpe"], ["", "def", "encode", "(", "self", ",", "text", ")", ":", "\n", "        ", "bpe_tokens", "=", "[", "]", "\n", "for", "token", "in", "re", ".", "findall", "(", "self", ".", "pat", ",", "text", ")", ":", "\n", "            ", "token", "=", "''", ".", "join", "(", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "bpe_tokens", ".", "extend", "(", "self", ".", "encoder", "[", "bpe_token", "]", "for", "bpe_token", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", ")", "\n", "", "if", "len", "(", "bpe_tokens", ")", ">", "self", ".", "max_len", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Token indices sequence length is longer than the specified maximum \"", "\n", "\" sequence length for this OpenAI GPT-2 model ({} > {}). Running this\"", "\n", "\" sequence through the model will result in indexing errors\"", ".", "format", "(", "len", "(", "bpe_tokens", ")", ",", "self", ".", "max_len", ")", "\n", ")", "\n", "", "return", "bpe_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_gpt2.GPT2Tokenizer.decode": [[203, 207], ["bytearray().decode", "bytearray"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.decode"], ["", "def", "decode", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "text", "=", "''", ".", "join", "(", "[", "self", ".", "decoder", "[", "token", "]", "for", "token", "in", "tokens", "]", ")", "\n", "text", "=", "bytearray", "(", "[", "self", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "text", "]", ")", ".", "decode", "(", "'utf-8'", ",", "errors", "=", "self", ".", "errors", ")", "\n", "return", "text", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_gpt2.bytes_to_unicode": [[49, 70], ["lru_cache", "range", "dict", "list", "chr", "zip", "list", "list", "range", "bs.append", "cs.append", "range", "range", "ord", "ord", "ord", "ord", "ord", "ord"], "function", ["None"], ["@", "lru_cache", "(", ")", "\n", "def", "bytes_to_unicode", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns list of utf-8 byte and a corresponding list of unicode strings.\n    The reversible bpe codes work on unicode strings.\n    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n    This is a signficant percentage of your normal, say, 32K bpe vocab.\n    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n    And avoids mapping to whitespace/control characters the bpe code barfs on.\n    \"\"\"", "\n", "bs", "=", "list", "(", "range", "(", "ord", "(", "\"!\"", ")", ",", "ord", "(", "\"~\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00a1\"", ")", ",", "ord", "(", "\"\u00ac\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00ae\"", ")", ",", "ord", "(", "\"\u00ff\"", ")", "+", "1", ")", ")", "\n", "cs", "=", "bs", "[", ":", "]", "\n", "n", "=", "0", "\n", "for", "b", "in", "range", "(", "2", "**", "8", ")", ":", "\n", "        ", "if", "b", "not", "in", "bs", ":", "\n", "            ", "bs", ".", "append", "(", "b", ")", "\n", "cs", ".", "append", "(", "2", "**", "8", "+", "n", ")", "\n", "n", "+=", "1", "\n", "", "", "cs", "=", "[", "chr", "(", "n", ")", "for", "n", "in", "cs", "]", "\n", "return", "dict", "(", "zip", "(", "bs", ",", "cs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_gpt2.get_pairs": [[71, 82], ["set", "set.add"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.add"], ["", "def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n\n    Word is represented as tuple of symbols (symbols being variable-length strings).\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLConfig.__init__": [[186, 288], ["isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "modeling_transfo_xl.TransfoXLConfig.cutoffs.extend", "ValueError", "reader.read", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "267735", ",", "\n", "cutoffs", "=", "[", "20000", ",", "40000", ",", "200000", "]", ",", "\n", "d_model", "=", "1024", ",", "\n", "d_embed", "=", "1024", ",", "\n", "n_head", "=", "16", ",", "\n", "d_head", "=", "64", ",", "\n", "d_inner", "=", "4096", ",", "\n", "div_val", "=", "4", ",", "\n", "pre_lnorm", "=", "False", ",", "\n", "n_layer", "=", "18", ",", "\n", "tgt_len", "=", "128", ",", "\n", "ext_len", "=", "0", ",", "\n", "mem_len", "=", "1600", ",", "\n", "clamp_len", "=", "1000", ",", "\n", "same_length", "=", "True", ",", "\n", "proj_share_all_but_first", "=", "True", ",", "\n", "attn_type", "=", "0", ",", "\n", "sample_softmax", "=", "-", "1", ",", "\n", "adaptive", "=", "True", ",", "\n", "tie_weight", "=", "True", ",", "\n", "dropout", "=", "0.1", ",", "\n", "dropatt", "=", "0.0", ",", "\n", "untie_r", "=", "True", ",", "\n", "init", "=", "\"normal\"", ",", "\n", "init_range", "=", "0.01", ",", "\n", "proj_init_std", "=", "0.01", ",", "\n", "init_std", "=", "0.02", ")", ":", "\n", "        ", "\"\"\"Constructs TransfoXLConfig.\n\n        Args:\n            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `TransfoXLModel` or a configuration json file.\n            cutoffs: cutoffs for the adaptive softmax\n            d_model: Dimensionality of the model's hidden states.\n            d_embed: Dimensionality of the embeddings\n            d_head: Dimensionality of the model's heads.\n            div_val: divident value for adapative input and softmax\n            pre_lnorm: apply LayerNorm to the input instead of the output\n            d_inner: Inner dimension in FF\n            n_layer: Number of hidden layers in the Transformer encoder.\n            n_head: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            tgt_len: number of tokens to predict\n            ext_len: length of the extended context\n            mem_len: length of the retained previous heads\n            same_length: use the same attn length for all tokens\n            proj_share_all_but_first: True to share all but first projs, False not to share.\n            attn_type: attention type. 0 for Transformer-XL, 1 for Shaw et al, 2 for Vaswani et al, 3 for Al Rfou et al.\n            clamp_len: use the same pos embeddings after clamp_len\n            sample_softmax: number of samples in sampled softmax\n            adaptive: use adaptive softmax\n            tie_weight: tie the word embedding and softmax weights\n            dropout: The dropout probabilitiy for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            dropatt: The dropout ratio for the attention probabilities.\n            untie_r: untie relative position biases           \n            embd_pdrop: The dropout ratio for the embeddings.\n            init: parameter initializer to use\n            init_range: parameters initialized by U(-init_range, init_range).\n            proj_init_std: parameters initialized by N(0, init_std)\n            init_std: parameters initialized by N(0, init_std)\n        \"\"\"", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "n_token", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "cutoffs", "=", "[", "]", "\n", "self", ".", "cutoffs", ".", "extend", "(", "cutoffs", ")", "\n", "self", ".", "tie_weight", "=", "tie_weight", "\n", "if", "proj_share_all_but_first", ":", "\n", "                ", "self", ".", "tie_projs", "=", "[", "False", "]", "+", "[", "True", "]", "*", "len", "(", "self", ".", "cutoffs", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "tie_projs", "=", "[", "False", "]", "+", "[", "False", "]", "*", "len", "(", "self", ".", "cutoffs", ")", "\n", "", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "div_val", "=", "div_val", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "same_length", "=", "same_length", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "self", ".", "clamp_len", "=", "clamp_len", "\n", "self", ".", "sample_softmax", "=", "sample_softmax", "\n", "self", ".", "adaptive", "=", "adaptive", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "dropatt", "=", "dropatt", "\n", "self", ".", "untie_r", "=", "untie_r", "\n", "self", ".", "init", "=", "init", "\n", "self", ".", "init_range", "=", "init_range", "\n", "self", ".", "proj_init_std", "=", "proj_init_std", "\n", "self", ".", "init_std", "=", "init_std", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLConfig.from_dict": [[290, 297], ["modeling_transfo_xl.TransfoXLConfig", "json_object.items"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `TransfoXLConfig` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "TransfoXLConfig", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLConfig.from_json_file": [[298, 304], ["cls.from_dict", "io.open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `TransfoXLConfig` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLConfig.__repr__": [[305, 307], ["str", "modeling_transfo_xl.TransfoXLConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLConfig.to_dict": [[308, 312], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLConfig.to_json_string": [[313, 316], ["json.dumps", "modeling_transfo_xl.TransfoXLConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.PositionalEmbedding.__init__": [[319, 326], ["torch.Module.__init__", "modeling_transfo_xl.PositionalEmbedding.register_buffer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "demb", ")", ":", "\n", "        ", "super", "(", "PositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "demb", "=", "demb", "\n", "\n", "inv_freq", "=", "1", "/", "(", "10000", "**", "(", "torch", ".", "arange", "(", "0.0", ",", "demb", ",", "2.0", ")", "/", "demb", ")", ")", "\n", "self", ".", "register_buffer", "(", "'inv_freq'", ",", "inv_freq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.PositionalEmbedding.forward": [[327, 335], ["torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pos_emb[].expand", "torch.ger.sin", "torch.ger.sin", "torch.ger.sin", "torch.ger.cos", "torch.ger.cos", "torch.ger.cos"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pos_seq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "torch", ".", "ger", "(", "pos_seq", ",", "self", ".", "inv_freq", ")", "\n", "pos_emb", "=", "torch", ".", "cat", "(", "[", "sinusoid_inp", ".", "sin", "(", ")", ",", "sinusoid_inp", ".", "cos", "(", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.PositionwiseFF.__init__": [[338, 355], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "modeling.BertLayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "d_inner", ",", "dropout", ",", "pre_lnorm", "=", "False", ")", ":", "\n", "        ", "super", "(", "PositionwiseFF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "CoreNet", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "d_model", ",", "d_inner", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "d_inner", ",", "d_model", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", ")", "\n", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "d_model", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.PositionwiseFF.forward": [[356, 371], ["modeling_transfo_xl.PositionwiseFF.CoreNet", "modeling_transfo_xl.PositionwiseFF.CoreNet", "modeling_transfo_xl.PositionwiseFF.layer_norm", "modeling_transfo_xl.PositionwiseFF.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "if", "self", ".", "pre_lnorm", ":", "\n", "##### layer normalization + positionwise feed-forward", "\n", "            ", "core_out", "=", "self", ".", "CoreNet", "(", "self", ".", "layer_norm", "(", "inp", ")", ")", "\n", "\n", "##### residual connection", "\n", "output", "=", "core_out", "+", "inp", "\n", "", "else", ":", "\n", "##### positionwise feed-forward", "\n", "            ", "core_out", "=", "self", ".", "CoreNet", "(", "inp", ")", "\n", "\n", "##### residual connection + layer normalization", "\n", "output", "=", "self", ".", "layer_norm", "(", "inp", "+", "core_out", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.MultiHeadAttn.__init__": [[373, 401], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "modeling.BertLayerNorm", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "dropatt", "=", "0", ",", "\n", "pre_lnorm", "=", "False", ",", "r_r_bias", "=", "None", ",", "r_w_bias", "=", "None", ")", ":", "\n", "        ", "super", "(", "MultiHeadAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "q_net", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_head", ",", "bias", "=", "False", ")", "\n", "self", ".", "kv_net", "=", "nn", ".", "Linear", "(", "d_model", ",", "2", "*", "n_head", "*", "d_head", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropatt", "=", "nn", ".", "Dropout", "(", "dropatt", ")", "\n", "self", ".", "o_net", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_head", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "d_model", ")", "\n", "\n", "self", ".", "scale", "=", "1", "/", "(", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n", "if", "r_r_bias", "is", "None", "or", "r_w_bias", "is", "None", ":", "# Biases are not shared", "\n", "            ", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "r_r_bias", "=", "r_r_bias", "\n", "self", ".", "r_w_bias", "=", "r_w_bias", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.MultiHeadAttn.forward": [[402, 452], ["modeling_transfo_xl.MultiHeadAttn.q_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "head_q.view.view.view", "head_k.view.view.view", "head_v.view.view.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum.mul_", "torch.einsum.mul_", "torch.einsum.mul_", "torch.softmax", "torch.softmax", "torch.softmax", "modeling_transfo_xl.MultiHeadAttn.dropatt", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "attn_vec.contiguous().view.contiguous().view.contiguous().view", "modeling_transfo_xl.MultiHeadAttn.o_net", "modeling_transfo_xl.MultiHeadAttn.drop", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_transfo_xl.MultiHeadAttn.layer_norm", "modeling_transfo_xl.MultiHeadAttn.kv_net", "h.size", "h.size", "modeling_transfo_xl.MultiHeadAttn.size", "modeling_transfo_xl.MultiHeadAttn.size", "modeling_transfo_xl.MultiHeadAttn.size", "modeling_transfo_xl.MultiHeadAttn.size", "attn_mask.any().item", "attn_vec.contiguous().view.contiguous().view.size", "attn_vec.contiguous().view.contiguous().view.size", "modeling_transfo_xl.MultiHeadAttn.layer_norm", "attn_mask.dim", "torch.einsum.masked_fill_", "torch.einsum.masked_fill_", "torch.einsum.masked_fill_", "attn_vec.contiguous().view.contiguous().view.contiguous", "attn_mask.any", "attn_mask.dim", "torch.einsum.masked_fill_", "torch.einsum.masked_fill_", "torch.einsum.masked_fill_", "float", "float"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "h", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "##### multihead attention", "\n", "# [hlen x bsz x n_head x d_head]", "\n", "\n", "        ", "if", "mems", "is", "not", "None", ":", "\n", "            ", "c", "=", "torch", ".", "cat", "(", "[", "mems", ",", "h", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "c", "=", "h", "\n", "\n", "", "if", "self", ".", "pre_lnorm", ":", "\n", "##### layer normalization", "\n", "            ", "c", "=", "self", ".", "layer_norm", "(", "c", ")", "\n", "\n", "", "head_q", "=", "self", ".", "q_net", "(", "h", ")", "\n", "head_k", ",", "head_v", "=", "torch", ".", "chunk", "(", "self", ".", "kv_net", "(", "c", ")", ",", "2", ",", "-", "1", ")", "\n", "\n", "head_q", "=", "head_q", ".", "view", "(", "h", ".", "size", "(", "0", ")", ",", "h", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "head_k", "=", "head_k", ".", "view", "(", "c", ".", "size", "(", "0", ")", ",", "c", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "head_v", "=", "head_v", ".", "view", "(", "c", ".", "size", "(", "0", ")", ",", "c", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "(", "head_q", ",", "head_k", ")", ")", "\n", "attn_score", ".", "mul_", "(", "self", ".", "scale", ")", "\n", "if", "attn_mask", "is", "not", "None", "and", "attn_mask", ".", "any", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "if", "attn_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "attn_score", ".", "masked_fill_", "(", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "", "elif", "attn_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "attn_score", ".", "masked_fill_", "(", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ")", "\n", "\n", "# [qlen x klen x bsz x n_head] + [klen x bsz x n_head x d_head] -> [qlen x bsz x n_head x d_head]", "\n", "attn_vec", "=", "torch", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "(", "attn_prob", ",", "head_v", ")", ")", "\n", "attn_vec", "=", "attn_vec", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "attn_vec", ".", "size", "(", "0", ")", ",", "attn_vec", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", "\n", "\n", "##### linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ")", "\n", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "##### residual connection", "\n", "            ", "output", "=", "h", "+", "attn_out", "\n", "", "else", ":", "\n", "##### residual connection + layer normalization", "\n", "            ", "output", "=", "self", ".", "layer_norm", "(", "h", "+", "attn_out", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.RelMultiHeadAttn.__init__": [[454, 482], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "modeling.BertLayerNorm", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "dropatt", "=", "0", ",", "\n", "tgt_len", "=", "None", ",", "ext_len", "=", "None", ",", "mem_len", "=", "None", ",", "pre_lnorm", "=", "False", ",", "\n", "r_r_bias", "=", "None", ",", "r_w_bias", "=", "None", ")", ":", "\n", "        ", "super", "(", "RelMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "qkv_net", "=", "nn", ".", "Linear", "(", "d_model", ",", "3", "*", "n_head", "*", "d_head", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropatt", "=", "nn", ".", "Dropout", "(", "dropatt", ")", "\n", "self", ".", "o_net", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_head", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "layer_norm", "=", "LayerNorm", "(", "d_model", ")", "\n", "\n", "self", ".", "scale", "=", "1", "/", "(", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n", "if", "r_r_bias", "is", "None", "or", "r_w_bias", "is", "None", ":", "# Biases are not shared", "\n", "            ", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "r_r_bias", "=", "r_r_bias", "\n", "self", ".", "r_w_bias", "=", "r_w_bias", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.RelMultiHeadAttn._parallelogram_mask": [[483, 493], ["torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "min", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones().byte.flip", "torch.ones().byte.flip", "torch.ones().byte.flip", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "", "def", "_parallelogram_mask", "(", "self", ",", "h", ",", "w", ",", "left", "=", "False", ")", ":", "\n", "        ", "mask", "=", "torch", ".", "ones", "(", "(", "h", ",", "w", ")", ")", ".", "byte", "(", ")", "\n", "m", "=", "min", "(", "h", ",", "w", ")", "\n", "mask", "[", ":", "m", ",", ":", "m", "]", "=", "torch", ".", "triu", "(", "mask", "[", ":", "m", ",", ":", "m", "]", ")", "\n", "mask", "[", "-", "m", ":", ",", "-", "m", ":", "]", "=", "torch", ".", "tril", "(", "mask", "[", "-", "m", ":", ",", "-", "m", ":", "]", ")", "\n", "\n", "if", "left", ":", "\n", "            ", "return", "mask", "\n", "", "else", ":", "\n", "            ", "return", "mask", ".", "flip", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.RelMultiHeadAttn._shift": [[494, 511], ["torch.cat().expand.masked_select().view", "torch.cat().expand.masked_select().view", "torch.cat().expand.masked_select().view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "mask.flip.flip.flip", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "", "def", "_shift", "(", "self", ",", "x", ",", "qlen", ",", "klen", ",", "mask", ",", "left", "=", "False", ")", ":", "\n", "        ", "if", "qlen", ">", "1", ":", "\n", "            ", "zero_pad", "=", "torch", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "qlen", "-", "1", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", ",", "\n", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "", "else", ":", "\n", "            ", "zero_pad", "=", "torch", ".", "zeros", "(", "0", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "\n", "", "if", "left", ":", "\n", "            ", "mask", "=", "mask", ".", "flip", "(", "1", ")", "\n", "x_padded", "=", "torch", ".", "cat", "(", "[", "zero_pad", ",", "x", "]", ",", "dim", "=", "1", ")", ".", "expand", "(", "qlen", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "x_padded", "=", "torch", ".", "cat", "(", "[", "x", ",", "zero_pad", "]", ",", "dim", "=", "1", ")", ".", "expand", "(", "qlen", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "\n", "", "x", "=", "x_padded", ".", "masked_select", "(", "mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", ")", ".", "view", "(", "qlen", ",", "klen", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.RelMultiHeadAttn._rel_shift": [[512, 527], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_padded.view.view.view", "x_padded[].view_as", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "x_padded[].view_as.size", "x_padded[].view_as.size"], "methods", ["None"], ["", "def", "_rel_shift", "(", "self", ",", "x", ",", "zero_triu", "=", "False", ")", ":", "\n", "        ", "zero_pad_shape", "=", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", "+", "x", ".", "size", "(", ")", "[", "2", ":", "]", "\n", "zero_pad", "=", "torch", ".", "zeros", "(", "zero_pad_shape", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "x_padded", "=", "torch", ".", "cat", "(", "[", "zero_pad", ",", "x", "]", ",", "dim", "=", "1", ")", "\n", "\n", "x_padded_shape", "=", "(", "x", ".", "size", "(", "1", ")", "+", "1", ",", "x", ".", "size", "(", "0", ")", ")", "+", "x", ".", "size", "(", ")", "[", "2", ":", "]", "\n", "x_padded", "=", "x_padded", ".", "view", "(", "*", "x_padded_shape", ")", "\n", "\n", "x", "=", "x_padded", "[", "1", ":", "]", ".", "view_as", "(", "x", ")", "\n", "\n", "if", "zero_triu", ":", "\n", "            ", "ones", "=", "torch", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ")", ")", "\n", "x", "=", "x", "*", "torch", ".", "tril", "(", "ones", ",", "x", ".", "size", "(", "1", ")", "-", "x", ".", "size", "(", "0", ")", ")", "[", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.RelMultiHeadAttn.forward": [[528, 530], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "w", ",", "r", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.__init__": [[532, 536], ["modeling_transfo_xl.RelMultiHeadAttn.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelPartialLearnableMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "r_net", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.forward": [[537, 611], ["w_head_k.view.view.size", "w_head_q.view.view.view", "w_head_k.view.view.view", "w_head_v.view.view.view", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn._rel_shift", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.mul_", "torch.softmax", "torch.softmax", "torch.softmax", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.dropatt", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "attn_vec.contiguous().view.contiguous().view.contiguous().view", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.o_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.drop", "w.size", "r.size", "w.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.r_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.r_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "attn_mask.any().item", "attn_vec.contiguous().view.contiguous().view.size", "attn_vec.contiguous().view.contiguous().view.size", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "attn_mask.dim", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "attn_vec.contiguous().view.contiguous().view.contiguous", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "attn_mask.any", "attn_mask.dim", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.RelMultiHeadAttn._rel_shift"], ["", "def", "forward", "(", "self", ",", "w", ",", "r", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "        ", "qlen", ",", "rlen", ",", "bsz", "=", "w", ".", "size", "(", "0", ")", ",", "r", ".", "size", "(", "0", ")", ",", "w", ".", "size", "(", "1", ")", "\n", "\n", "if", "mems", "is", "not", "None", ":", "\n", "            ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "w", "]", ",", "0", ")", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "cat", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "cat", ")", "\n", "", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "w_head_q", "=", "w_head_q", "[", "-", "qlen", ":", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "w", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "w", ")", "\n", "", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "klen", "=", "w_head_k", ".", "size", "(", "0", ")", "\n", "\n", "w_head_q", "=", "w_head_q", ".", "view", "(", "qlen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_k", "=", "w_head_k", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_v", "=", "w_head_v", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "\n", "r_head_k", "=", "r_head_k", ".", "view", "(", "rlen", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x n_head x d_head", "\n", "\n", "#### compute attention score", "\n", "rw_head_q", "=", "w_head_q", "+", "self", ".", "r_w_bias", "# qlen x bsz x n_head x d_head", "\n", "AC", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "(", "rw_head_q", ",", "w_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "\n", "rr_head_q", "=", "w_head_q", "+", "self", ".", "r_r_bias", "\n", "BD", "=", "torch", ".", "einsum", "(", "'ibnd,jnd->ijbn'", ",", "(", "rr_head_q", ",", "r_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "BD", "=", "self", ".", "_rel_shift", "(", "BD", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "AC", "+", "BD", "\n", "attn_score", ".", "mul_", "(", "self", ".", "scale", ")", "\n", "\n", "#### compute attention probability", "\n", "if", "attn_mask", "is", "not", "None", "and", "attn_mask", ".", "any", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "if", "attn_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "\n", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ",", "-", "1e30", ")", ".", "type_as", "(", "attn_score", ")", "\n", "", "elif", "attn_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "\n", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ",", "-", "1e30", ")", ".", "type_as", "(", "attn_score", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ")", "\n", "\n", "#### compute attention vector", "\n", "attn_vec", "=", "torch", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "(", "attn_prob", ",", "w_head_v", ")", ")", "\n", "\n", "# [qlen x bsz x n_head x d_head]", "\n", "attn_vec", "=", "attn_vec", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "attn_vec", ".", "size", "(", "0", ")", ",", "attn_vec", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", "\n", "\n", "##### linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ")", "\n", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "##### residual connection", "\n", "            ", "output", "=", "w", "+", "attn_out", "\n", "", "else", ":", "\n", "##### residual connection + layer normalization", "\n", "            ", "output", "=", "self", ".", "layer_norm", "(", "w", "+", "attn_out", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.RelLearnableMultiHeadAttn.__init__": [[613, 615], ["modeling_transfo_xl.RelMultiHeadAttn.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelLearnableMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.RelLearnableMultiHeadAttn.forward": [[616, 696], ["w_head_k.view.view.size", "w_head_q.view.view.view", "w_head_k.view.view.view", "w_head_v.view.view.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_transfo_xl.RelLearnableMultiHeadAttn._rel_shift", "attn_score.mul_", "torch.softmax", "torch.softmax", "torch.softmax", "modeling_transfo_xl.RelLearnableMultiHeadAttn.dropatt", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "attn_vec.contiguous().view.contiguous().view.contiguous().view", "modeling_transfo_xl.RelLearnableMultiHeadAttn.o_net", "modeling_transfo_xl.RelLearnableMultiHeadAttn.drop", "w.size", "w.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.cat.size", "torch.cat.size", "torch.cat.size", "r_emb[].expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "r_bias[].expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "attn_mask.any().item", "attn_vec.contiguous().view.contiguous().view.size", "attn_vec.contiguous().view.contiguous().view.size", "modeling_transfo_xl.RelLearnableMultiHeadAttn.layer_norm", "modeling_transfo_xl.RelLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelLearnableMultiHeadAttn.qkv_net", "attn_mask.dim", "attn_score.masked_fill_", "attn_vec.contiguous().view.contiguous().view.contiguous", "modeling_transfo_xl.RelLearnableMultiHeadAttn.layer_norm", "modeling_transfo_xl.RelLearnableMultiHeadAttn.layer_norm", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "attn_mask.any", "attn_mask.dim", "attn_score.masked_fill_", "float", "float"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.RelMultiHeadAttn._rel_shift"], ["", "def", "forward", "(", "self", ",", "w", ",", "r_emb", ",", "r_w_bias", ",", "r_bias", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "# r_emb: [klen, n_head, d_head], used for term B", "\n", "# r_w_bias: [n_head, d_head], used for term C", "\n", "# r_bias: [klen, n_head], used for term D", "\n", "\n", "        ", "qlen", ",", "bsz", "=", "w", ".", "size", "(", "0", ")", ",", "w", ".", "size", "(", "1", ")", "\n", "\n", "if", "mems", "is", "not", "None", ":", "\n", "            ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "w", "]", ",", "0", ")", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "cat", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "cat", ")", "\n", "", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n", "w_head_q", "=", "w_head_q", "[", "-", "qlen", ":", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "w", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "w", ")", "\n", "", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "klen", "=", "w_head_k", ".", "size", "(", "0", ")", "\n", "\n", "w_head_q", "=", "w_head_q", ".", "view", "(", "qlen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "w_head_k", "=", "w_head_k", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "w_head_v", "=", "w_head_v", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "\n", "if", "klen", ">", "r_emb", ".", "size", "(", "0", ")", ":", "\n", "            ", "r_emb_pad", "=", "r_emb", "[", "0", ":", "1", "]", ".", "expand", "(", "klen", "-", "r_emb", ".", "size", "(", "0", ")", ",", "-", "1", ",", "-", "1", ")", "\n", "r_emb", "=", "torch", ".", "cat", "(", "[", "r_emb_pad", ",", "r_emb", "]", ",", "0", ")", "\n", "r_bias_pad", "=", "r_bias", "[", "0", ":", "1", "]", ".", "expand", "(", "klen", "-", "r_bias", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "r_bias", "=", "torch", ".", "cat", "(", "[", "r_bias_pad", ",", "r_bias", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "r_emb", "=", "r_emb", "[", "-", "klen", ":", "]", "\n", "r_bias", "=", "r_bias", "[", "-", "klen", ":", "]", "\n", "\n", "#### compute attention score", "\n", "", "rw_head_q", "=", "w_head_q", "+", "r_w_bias", "[", "None", "]", "# qlen x bsz x n_head x d_head", "\n", "\n", "AC", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "(", "rw_head_q", ",", "w_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "B_", "=", "torch", ".", "einsum", "(", "'ibnd,jnd->ijbn'", ",", "(", "w_head_q", ",", "r_emb", ")", ")", "# qlen x klen x bsz x n_head", "\n", "D_", "=", "r_bias", "[", "None", ",", ":", ",", "None", "]", "# 1    x klen x 1   x n_head", "\n", "BD", "=", "self", ".", "_rel_shift", "(", "B_", "+", "D_", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "AC", "+", "BD", "\n", "attn_score", ".", "mul_", "(", "self", ".", "scale", ")", "\n", "\n", "#### compute attention probability", "\n", "if", "attn_mask", "is", "not", "None", "and", "attn_mask", ".", "any", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "if", "attn_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "attn_score", ".", "masked_fill_", "(", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "", "elif", "attn_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "attn_score", ".", "masked_fill_", "(", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ")", "\n", "\n", "#### compute attention vector", "\n", "attn_vec", "=", "torch", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "(", "attn_prob", ",", "w_head_v", ")", ")", "\n", "\n", "# [qlen x bsz x n_head x d_head]", "\n", "attn_vec", "=", "attn_vec", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "attn_vec", ".", "size", "(", "0", ")", ",", "attn_vec", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", "\n", "\n", "##### linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ")", "\n", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "##### residual connection", "\n", "            ", "output", "=", "w", "+", "attn_out", "\n", "", "else", ":", "\n", "##### residual connection + layer normalization", "\n", "            ", "output", "=", "self", ".", "layer_norm", "(", "w", "+", "attn_out", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.DecoderLayer.__init__": [[698, 704], ["torch.Module.__init__", "modeling_transfo_xl.MultiHeadAttn", "modeling_transfo_xl.PositionwiseFF", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "DecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dec_attn", "=", "MultiHeadAttn", "(", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "**", "kwargs", ")", "\n", "self", ".", "pos_ff", "=", "PositionwiseFF", "(", "d_model", ",", "d_inner", ",", "dropout", ",", "\n", "pre_lnorm", "=", "kwargs", ".", "get", "(", "'pre_lnorm'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.DecoderLayer.forward": [[705, 712], ["modeling_transfo_xl.DecoderLayer.dec_attn", "modeling_transfo_xl.DecoderLayer.pos_ff"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "dec_inp", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "\n", "        ", "output", "=", "self", ".", "dec_attn", "(", "dec_inp", ",", "attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems", ")", "\n", "output", "=", "self", ".", "pos_ff", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.RelLearnableDecoderLayer.__init__": [[714, 722], ["torch.Module.__init__", "modeling_transfo_xl.RelLearnableMultiHeadAttn", "modeling_transfo_xl.PositionwiseFF", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelLearnableDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dec_attn", "=", "RelLearnableMultiHeadAttn", "(", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "\n", "**", "kwargs", ")", "\n", "self", ".", "pos_ff", "=", "PositionwiseFF", "(", "d_model", ",", "d_inner", ",", "dropout", ",", "\n", "pre_lnorm", "=", "kwargs", ".", "get", "(", "'pre_lnorm'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.RelLearnableDecoderLayer.forward": [[723, 731], ["modeling_transfo_xl.RelLearnableDecoderLayer.dec_attn", "modeling_transfo_xl.RelLearnableDecoderLayer.pos_ff"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "dec_inp", ",", "r_emb", ",", "r_w_bias", ",", "r_bias", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "\n", "        ", "output", "=", "self", ".", "dec_attn", "(", "dec_inp", ",", "r_emb", ",", "r_w_bias", ",", "r_bias", ",", "\n", "attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems", ")", "\n", "output", "=", "self", ".", "pos_ff", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.RelPartialLearnableDecoderLayer.__init__": [[733, 741], ["torch.Module.__init__", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn", "modeling_transfo_xl.PositionwiseFF", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelPartialLearnableDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dec_attn", "=", "RelPartialLearnableMultiHeadAttn", "(", "n_head", ",", "d_model", ",", "\n", "d_head", ",", "dropout", ",", "**", "kwargs", ")", "\n", "self", ".", "pos_ff", "=", "PositionwiseFF", "(", "d_model", ",", "d_inner", ",", "dropout", ",", "\n", "pre_lnorm", "=", "kwargs", ".", "get", "(", "'pre_lnorm'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.RelPartialLearnableDecoderLayer.forward": [[742, 750], ["modeling_transfo_xl.RelPartialLearnableDecoderLayer.dec_attn", "modeling_transfo_xl.RelPartialLearnableDecoderLayer.pos_ff"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "dec_inp", ",", "r", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "\n", "        ", "output", "=", "self", ".", "dec_attn", "(", "dec_inp", ",", "r", ",", "\n", "attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems", ")", "\n", "output", "=", "self", ".", "pos_ff", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.AdaptiveEmbedding.__init__": [[753, 782], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "modeling_transfo_xl.AdaptiveEmbedding.emb_layers.append", "range", "torch.Embedding", "torch.Embedding", "torch.Embedding", "modeling_transfo_xl.AdaptiveEmbedding.emb_projs.append", "len", "modeling_transfo_xl.AdaptiveEmbedding.emb_layers.append", "modeling_transfo_xl.AdaptiveEmbedding.emb_projs.append", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_token", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "1", ",", "\n", "sample_softmax", "=", "False", ")", ":", "\n", "        ", "super", "(", "AdaptiveEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_token", "=", "n_token", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_token", "]", "\n", "self", ".", "div_val", "=", "div_val", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "self", ".", "emb_scale", "=", "d_proj", "**", "0.5", "\n", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "\n", "self", ".", "emb_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "emb_projs", "=", "nn", ".", "ParameterList", "(", ")", "\n", "if", "div_val", "==", "1", ":", "\n", "            ", "self", ".", "emb_layers", ".", "append", "(", "\n", "nn", ".", "Embedding", "(", "n_token", ",", "d_embed", ",", "sparse", "=", "sample_softmax", ">", "0", ")", "\n", ")", "\n", "if", "d_proj", "!=", "d_embed", ":", "\n", "                ", "self", ".", "emb_projs", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_proj", ",", "d_embed", ")", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "d_embed", "//", "(", "div_val", "**", "i", ")", "\n", "self", ".", "emb_layers", ".", "append", "(", "nn", ".", "Embedding", "(", "r_idx", "-", "l_idx", ",", "d_emb_i", ")", ")", "\n", "self", ".", "emb_projs", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_proj", ",", "d_emb_i", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.AdaptiveEmbedding.forward": [[783, 814], ["torch.linear.mul_", "next", "inp.view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.zeros.view", "torch.zeros.view", "torch.zeros.view", "torch.linear", "torch.linear", "torch.linear", "modeling_transfo_xl.AdaptiveEmbedding.parameters", "len", "mask_i.nonzero().squeeze", "torch.linear", "torch.linear", "torch.linear", "torch.zeros.index_copy_", "torch.zeros.index_copy_", "torch.zeros.index_copy_", "inp.size", "inp.view.size", "mask_i.nonzero().squeeze.numel", "inp.view.index_select", "mask_i.nonzero"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "            ", "embed", "=", "self", ".", "emb_layers", "[", "0", "]", "(", "inp", ")", "\n", "if", "self", ".", "d_proj", "!=", "self", ".", "d_embed", ":", "\n", "                ", "embed", "=", "F", ".", "linear", "(", "embed", ",", "self", ".", "emb_projs", "[", "0", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "param", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "inp_flat", "=", "inp", ".", "view", "(", "-", "1", ")", "\n", "emb_flat", "=", "torch", ".", "zeros", "(", "[", "inp_flat", ".", "size", "(", "0", ")", ",", "self", ".", "d_proj", "]", ",", "\n", "dtype", "=", "param", ".", "dtype", ",", "device", "=", "param", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "\n", "mask_i", "=", "(", "inp_flat", ">=", "l_idx", ")", "&", "(", "inp_flat", "<", "r_idx", ")", "\n", "indices_i", "=", "mask_i", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "\n", "if", "indices_i", ".", "numel", "(", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "inp_i", "=", "inp_flat", ".", "index_select", "(", "0", ",", "indices_i", ")", "-", "l_idx", "\n", "emb_i", "=", "self", ".", "emb_layers", "[", "i", "]", "(", "inp_i", ")", "\n", "emb_i", "=", "F", ".", "linear", "(", "emb_i", ",", "self", ".", "emb_projs", "[", "i", "]", ")", "\n", "\n", "emb_flat", ".", "index_copy_", "(", "0", ",", "indices_i", ",", "emb_i", ")", "\n", "\n", "", "embed_shape", "=", "inp", ".", "size", "(", ")", "+", "(", "self", ".", "d_proj", ",", ")", "\n", "embed", "=", "emb_flat", ".", "view", "(", "embed_shape", ")", "\n", "\n", "", "embed", ".", "mul_", "(", "self", ".", "emb_scale", ")", "\n", "\n", "return", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.__init__": [[820, 830], ["torch.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TransfoXLPreTrainedModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "TransfoXLConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `TransfoXLConfig`. \"", "\n", "\"To create a model from a pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", ")", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight": [[831, 836], ["torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_"], "methods", ["None"], ["", "def", "init_weight", "(", "self", ",", "weight", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "init", "==", "'uniform'", ":", "\n", "            ", "nn", ".", "init", ".", "uniform_", "(", "weight", ",", "-", "self", ".", "config", ".", "init_range", ",", "self", ".", "config", ".", "init_range", ")", "\n", "", "elif", "self", ".", "config", ".", "init", "==", "'normal'", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "weight", ",", "0.0", ",", "self", ".", "config", ".", "init_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias": [[837, 839], ["torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "", "def", "init_bias", "(", "self", ",", "bias", ")", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_weights": [[840, 880], ["classname.find", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias", "classname.find", "hasattr", "range", "classname.find", "hasattr", "len", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "classname.find", "hasattr", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias", "range", "classname.find", "hasattr", "len", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias", "classname.find", "hasattr", "hasattr", "hasattr", "hasattr", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_weight", "modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.init_weight", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.init_weight", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.init_weight", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.init_weight", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.init_weight", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.init_weight", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.init_bias"], ["", "def", "init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "m", ".", "weight", "is", "not", "None", ":", "\n", "                ", "self", ".", "init_weight", "(", "m", ".", "weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "self", ".", "init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'AdaptiveEmbedding'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'emb_projs'", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "emb_projs", ")", ")", ":", "\n", "                    ", "if", "m", ".", "emb_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                        ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "emb_projs", "[", "i", "]", ",", "0.0", ",", "self", ".", "config", ".", "proj_init_std", ")", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "'Embedding'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "                ", "self", ".", "init_weight", "(", "m", ".", "weight", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'ProjectedAdaptiveLogSoftmax'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'cluster_weight'", ")", "and", "m", ".", "cluster_weight", "is", "not", "None", ":", "\n", "                ", "self", ".", "init_weight", "(", "m", ".", "cluster_weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'cluster_bias'", ")", "and", "m", ".", "cluster_bias", "is", "not", "None", ":", "\n", "                ", "self", ".", "init_bias", "(", "m", ".", "cluster_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'out_projs'", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "out_projs", ")", ")", ":", "\n", "                    ", "if", "m", ".", "out_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                        ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "out_projs", "[", "i", "]", ",", "0.0", ",", "self", ".", "config", ".", "proj_init_std", ")", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "'LayerNorm'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "1.0", ",", "self", ".", "config", ".", "init_std", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "self", ".", "init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'TransformerLM'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'r_emb'", ")", ":", "\n", "                ", "self", ".", "init_weight", "(", "m", ".", "r_emb", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_w_bias'", ")", ":", "\n", "                ", "self", ".", "init_weight", "(", "m", ".", "r_w_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_r_bias'", ")", ":", "\n", "                ", "self", ".", "init_weight", "(", "m", ".", "r_r_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_bias'", ")", ":", "\n", "                ", "self", ".", "init_bias", "(", "m", ".", "r_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.set_num_special_tokens": [[881, 883], ["None"], "methods", ["None"], ["", "", "", "def", "set_num_special_tokens", "(", "self", ",", "num_special_tokens", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLPreTrainedModel.from_pretrained": [[884, 981], ["modeling_transfo_xl.TransfoXLConfig.from_json_file", "logger.info", "cls", "getattr", "torch.load.copy", "torch.load.copy", "torch.load.copy", "modeling_transfo_xl.TransfoXLPreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_json_file"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "state_dict", "=", "None", ",", "cache_dir", "=", "None", ",", "\n", "from_tf", "=", "False", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a TransfoXLPreTrainedModel from a pre-trained model file or a pytorch state dict.\n        Download and cache the pre-trained model file if needed.\n\n        Params:\n            pretrained_model_name_or_path: either:\n                - a str with the name of a pre-trained model to load selected in the list of:\n                    . `transfo-xl`\n                - a path or url to a pretrained model archive containing:\n                    . `transfo_xl_config.json` a configuration file for the model\n                    . `pytorch_model.bin` a PyTorch dump of a TransfoXLModel instance\n                - a path or url to a pretrained model archive containing:\n                    . `bert_config.json` a configuration file for the model\n                    . `model.chkpt` a TensorFlow checkpoint\n            from_tf: should we load the weights from a locally saved TensorFlow checkpoint\n            cache_dir: an optional path to a folder in which the pre-trained models will be cached.\n            state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of pre-trained models\n            *inputs, **kwargs: additional input for the specific Bert class\n                (ex: num_labels for BertForSequenceClassification)\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_MODEL_ARCHIVE_MAP", ":", "\n", "            ", "archive_file", "=", "PRETRAINED_MODEL_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "config_file", "=", "PRETRAINED_CONFIG_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "config_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CONFIG_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "resolved_config_file", "=", "cached_path", "(", "config_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} and {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "archive_file", ",", "config_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_archive_file", "==", "archive_file", "and", "resolved_config_file", "==", "config_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading configuration file {}\"", ".", "format", "(", "config_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading configuration file {} from cache at {}\"", ".", "format", "(", "\n", "config_file", ",", "resolved_config_file", ")", ")", "\n", "# Load config", "\n", "", "config", "=", "TransfoXLConfig", ".", "from_json_file", "(", "resolved_config_file", ")", "\n", "logger", ".", "info", "(", "\"Model config {}\"", ".", "format", "(", "config", ")", ")", "\n", "# Instantiate model.", "\n", "model", "=", "cls", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "'cpu'", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "None", ")", "\n", "", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "            ", "return", "load_tf_weights_in_transfo_xl", "(", "model", ",", "config", ",", "pretrained_model_name_or_path", ")", "\n", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "            ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                ", "if", "child", "is", "not", "None", ":", "\n", "                    ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "\n", "", "", "", "start_prefix", "=", "''", "\n", "if", "not", "hasattr", "(", "model", ",", "'transformer'", ")", "and", "any", "(", "s", ".", "startswith", "(", "'transformer.'", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "start_prefix", "=", "'transformer.'", "\n", "", "load", "(", "model", ",", "prefix", "=", "start_prefix", ")", "\n", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Error(s) in loading state_dict for {}:\\n\\t{}'", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", ")", "\n", "# Make sure we are still sharing the input and output embeddings", "\n", "", "if", "hasattr", "(", "model", ",", "'tie_weights'", ")", ":", "\n", "            ", "model", ".", "tie_weights", "(", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel.__init__": [[1023, 1097], ["modeling_transfo_xl.TransfoXLPreTrainedModel.__init__", "modeling_transfo_xl.AdaptiveEmbedding", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "modeling_transfo_xl.TransfoXLModel.apply", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "range", "modeling_transfo_xl.PositionalEmbedding", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "modeling_transfo_xl.TransfoXLModel.layers.append", "range", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "modeling_transfo_xl.RelPartialLearnableDecoderLayer", "modeling_transfo_xl.TransfoXLModel.layers.append", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "modeling_transfo_xl.PositionalEmbedding", "modeling_transfo_xl.RelLearnableDecoderLayer", "modeling_transfo_xl.TransfoXLModel.layers.append", "torch.Parameter", "torch.Parameter", "torch.Parameter", "modeling_transfo_xl.DecoderLayer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "TransfoXLModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "n_token", "=", "config", ".", "n_token", "\n", "\n", "self", ".", "d_embed", "=", "config", ".", "d_embed", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "d_head", "=", "config", ".", "d_head", "\n", "\n", "self", ".", "word_emb", "=", "AdaptiveEmbedding", "(", "config", ".", "n_token", ",", "config", ".", "d_embed", ",", "config", ".", "d_model", ",", "config", ".", "cutoffs", ",", "\n", "div_val", "=", "config", ".", "div_val", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n", "self", ".", "n_layer", "=", "config", ".", "n_layer", "\n", "\n", "self", ".", "tgt_len", "=", "config", ".", "tgt_len", "\n", "self", ".", "mem_len", "=", "config", ".", "mem_len", "\n", "self", ".", "ext_len", "=", "config", ".", "ext_len", "\n", "self", ".", "max_klen", "=", "config", ".", "tgt_len", "+", "config", ".", "ext_len", "+", "config", ".", "mem_len", "\n", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "\n", "if", "not", "config", ".", "untie_r", ":", "\n", "            ", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n", "", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "if", "config", ".", "attn_type", "==", "0", ":", "# the default attention", "\n", "            ", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "\n", "RelPartialLearnableDecoderLayer", "(", "\n", "config", ".", "n_head", ",", "config", ".", "d_model", ",", "config", ".", "d_head", ",", "config", ".", "d_inner", ",", "config", ".", "dropout", ",", "\n", "tgt_len", "=", "config", ".", "tgt_len", ",", "ext_len", "=", "config", ".", "ext_len", ",", "mem_len", "=", "config", ".", "mem_len", ",", "\n", "dropatt", "=", "config", ".", "dropatt", ",", "pre_lnorm", "=", "config", ".", "pre_lnorm", ",", "\n", "r_w_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_w_bias", ",", "\n", "r_r_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_r_bias", ")", "\n", ")", "\n", "", "", "elif", "config", ".", "attn_type", "==", "1", ":", "# learnable embeddings", "\n", "            ", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "\n", "RelLearnableDecoderLayer", "(", "\n", "config", ".", "n_head", ",", "config", ".", "d_model", ",", "config", ".", "d_head", ",", "config", ".", "d_inner", ",", "config", ".", "dropout", ",", "\n", "tgt_len", "=", "config", ".", "tgt_len", ",", "ext_len", "=", "config", ".", "ext_len", ",", "mem_len", "=", "config", ".", "mem_len", ",", "\n", "dropatt", "=", "config", ".", "dropatt", ",", "pre_lnorm", "=", "config", ".", "pre_lnorm", ",", "\n", "r_w_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_w_bias", ",", "\n", "r_r_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_r_bias", ")", "\n", ")", "\n", "", "", "elif", "config", ".", "attn_type", "in", "[", "2", ",", "3", "]", ":", "# absolute embeddings", "\n", "            ", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "\n", "DecoderLayer", "(", "\n", "config", ".", "n_head", ",", "config", ".", "d_model", ",", "config", ".", "d_head", ",", "config", ".", "d_inner", ",", "config", ".", "dropout", ",", "\n", "dropatt", "=", "config", ".", "dropatt", ",", "pre_lnorm", "=", "config", ".", "pre_lnorm", ",", "\n", "r_w_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_w_bias", ",", "\n", "r_r_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_r_bias", ")", "\n", ")", "\n", "\n", "", "", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "self", ".", "clamp_len", "=", "config", ".", "clamp_len", "\n", "\n", "if", "self", ".", "attn_type", "==", "0", ":", "# default attention", "\n", "            ", "self", ".", "pos_emb", "=", "PositionalEmbedding", "(", "self", ".", "d_model", ")", "\n", "", "elif", "self", ".", "attn_type", "==", "1", ":", "# learnable", "\n", "            ", "self", ".", "r_emb", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "self", ".", "n_layer", ",", "self", ".", "max_klen", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "self", ".", "n_layer", ",", "self", ".", "max_klen", ",", "self", ".", "n_head", ")", ")", "\n", "", "elif", "self", ".", "attn_type", "==", "2", ":", "# absolute standard", "\n", "            ", "self", ".", "pos_emb", "=", "PositionalEmbedding", "(", "self", ".", "d_model", ")", "\n", "", "elif", "self", ".", "attn_type", "==", "3", ":", "# absolute deeper SA", "\n", "            ", "self", ".", "r_emb", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "self", ".", "n_layer", ",", "self", ".", "max_klen", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel.backward_compatible": [[1098, 1100], ["None"], "methods", ["None"], ["", "def", "backward_compatible", "(", "self", ")", ":", "\n", "        ", "self", ".", "sample_softmax", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel.reset_length": [[1102, 1106], ["None"], "methods", ["None"], ["", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "ext_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel.init_mems": [[1107, 1119], ["next", "range", "modeling_transfo_xl.TransfoXLModel.parameters", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "mems.append", "data.size"], "methods", ["None"], ["", "def", "init_mems", "(", "self", ",", "data", ")", ":", "\n", "        ", "if", "self", ".", "mem_len", ">", "0", ":", "\n", "            ", "mems", "=", "[", "]", "\n", "param", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layer", ")", ":", "\n", "                ", "empty", "=", "torch", ".", "zeros", "(", "self", ".", "mem_len", ",", "data", ".", "size", "(", "1", ")", ",", "self", ".", "config", ".", "d_model", ",", "\n", "dtype", "=", "param", ".", "dtype", ",", "device", "=", "param", ".", "device", ")", "\n", "mems", ".", "append", "(", "empty", ")", "\n", "\n", "", "return", "mems", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel._update_mems": [[1120, 1142], ["len", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "max", "range", "max", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "new_mems.append", "cat[].detach"], "methods", ["None"], ["", "", "def", "_update_mems", "(", "self", ",", "hids", ",", "mems", ",", "qlen", ",", "mlen", ")", ":", "\n", "# does not deal with None", "\n", "        ", "if", "mems", "is", "None", ":", "return", "None", "\n", "\n", "# mems is not None", "\n", "assert", "len", "(", "hids", ")", "==", "len", "(", "mems", ")", ",", "'len(hids) != len(mems)'", "\n", "\n", "# There are `mlen + qlen` steps that can be cached into mems", "\n", "# For the next step, the last `ext_len` of the `qlen` tokens", "\n", "# will be used as the extended context. Hence, we only cache", "\n", "# the tokens from `mlen + qlen - self.ext_len - self.mem_len`", "\n", "# to `mlen + qlen - self.ext_len`.", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "new_mems", "=", "[", "]", "\n", "end_idx", "=", "mlen", "+", "max", "(", "0", ",", "qlen", "-", "0", "-", "self", ".", "ext_len", ")", "\n", "beg_idx", "=", "max", "(", "0", ",", "end_idx", "-", "self", ".", "mem_len", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "hids", ")", ")", ":", "\n", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", "[", "i", "]", ",", "hids", "[", "i", "]", "]", ",", "dim", "=", "0", ")", "\n", "new_mems", ".", "append", "(", "cat", "[", "beg_idx", ":", "end_idx", "]", ".", "detach", "(", ")", ")", "\n", "\n", "", "", "return", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel._forward": [[1143, 1232], ["dec_inp.size", "modeling_transfo_xl.TransfoXLModel.word_emb", "modeling_transfo_xl.TransfoXLModel.drop", "modeling_transfo_xl.TransfoXLModel._update_mems", "mems[].size", "modeling_transfo_xl.TransfoXLModel.new_ones", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "modeling_transfo_xl.TransfoXLModel.pos_emb", "modeling_transfo_xl.TransfoXLModel.drop", "modeling_transfo_xl.TransfoXLModel.drop", "enumerate", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.arange.clamp_", "torch.arange.clamp_", "torch.arange.clamp_", "hids.append", "layer", "modeling_transfo_xl.TransfoXLModel.drop", "enumerate", "hids.append", "layer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "modeling_transfo_xl.TransfoXLModel.pos_emb", "modeling_transfo_xl.TransfoXLModel.drop", "enumerate", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.arange.clamp_", "torch.arange.clamp_", "torch.arange.clamp_", "hids.append", "layer", "modeling_transfo_xl.TransfoXLModel.drop", "enumerate", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "modeling_transfo_xl.TransfoXLModel.new_ones", "hids.append", "[].view", "layer", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.view", "torch.cat.view", "torch.cat.view", "cur_emb[].expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel._update_mems"], ["", "def", "_forward", "(", "self", ",", "dec_inp", ",", "mems", "=", "None", ")", ":", "\n", "        ", "qlen", ",", "bsz", "=", "dec_inp", ".", "size", "(", ")", "\n", "\n", "word_emb", "=", "self", ".", "word_emb", "(", "dec_inp", ")", "\n", "\n", "mlen", "=", "mems", "[", "0", "]", ".", "size", "(", "0", ")", "if", "mems", "is", "not", "None", "else", "0", "\n", "klen", "=", "mlen", "+", "qlen", "\n", "if", "self", ".", "same_length", ":", "\n", "            ", "all_ones", "=", "word_emb", ".", "new_ones", "(", "qlen", ",", "klen", ")", "\n", "mask_len", "=", "klen", "-", "self", ".", "mem_len", "\n", "if", "mask_len", ">", "0", ":", "\n", "                ", "mask_shift_len", "=", "qlen", "-", "mask_len", "\n", "", "else", ":", "\n", "                ", "mask_shift_len", "=", "qlen", "\n", "", "dec_attn_mask", "=", "(", "torch", ".", "triu", "(", "all_ones", ",", "1", "+", "mlen", ")", "\n", "+", "torch", ".", "tril", "(", "all_ones", ",", "-", "mask_shift_len", ")", ")", ".", "byte", "(", ")", "[", ":", ",", ":", ",", "None", "]", "# -1", "\n", "", "else", ":", "\n", "            ", "dec_attn_mask", "=", "torch", ".", "triu", "(", "\n", "word_emb", ".", "new_ones", "(", "qlen", ",", "klen", ")", ",", "diagonal", "=", "1", "+", "mlen", ")", ".", "byte", "(", ")", "[", ":", ",", ":", ",", "None", "]", "\n", "\n", "", "hids", "=", "[", "]", "\n", "if", "self", ".", "attn_type", "==", "0", ":", "# default", "\n", "            ", "pos_seq", "=", "torch", ".", "arange", "(", "klen", "-", "1", ",", "-", "1", ",", "-", "1.0", ",", "device", "=", "word_emb", ".", "device", ",", "\n", "dtype", "=", "word_emb", ".", "dtype", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "pos_seq", ".", "clamp_", "(", "max", "=", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "pos_emb", "(", "pos_seq", ")", "\n", "\n", "core_out", "=", "self", ".", "drop", "(", "word_emb", ")", "\n", "pos_emb", "=", "self", ".", "drop", "(", "pos_emb", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hids", ".", "append", "(", "core_out", ")", "\n", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "core_out", "=", "layer", "(", "core_out", ",", "pos_emb", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "mems", "=", "mems_i", ")", "\n", "", "", "elif", "self", ".", "attn_type", "==", "1", ":", "# learnable", "\n", "            ", "core_out", "=", "self", ".", "drop", "(", "word_emb", ")", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hids", ".", "append", "(", "core_out", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                    ", "r_emb", "=", "self", ".", "r_emb", "[", "i", "]", "[", "-", "self", ".", "clamp_len", ":", "]", "\n", "r_bias", "=", "self", ".", "r_bias", "[", "i", "]", "[", "-", "self", ".", "clamp_len", ":", "]", "\n", "", "else", ":", "\n", "                    ", "r_emb", ",", "r_bias", "=", "self", ".", "r_emb", "[", "i", "]", ",", "self", ".", "r_bias", "[", "i", "]", "\n", "\n", "", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "core_out", "=", "layer", "(", "core_out", ",", "r_emb", ",", "self", ".", "r_w_bias", "[", "i", "]", ",", "\n", "r_bias", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "mems", "=", "mems_i", ")", "\n", "", "", "elif", "self", ".", "attn_type", "==", "2", ":", "# absolute", "\n", "            ", "pos_seq", "=", "torch", ".", "arange", "(", "klen", "-", "1", ",", "-", "1", ",", "-", "1.0", ",", "device", "=", "word_emb", ".", "device", ",", "\n", "dtype", "=", "word_emb", ".", "dtype", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "pos_seq", ".", "clamp_", "(", "max", "=", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "pos_emb", "(", "pos_seq", ")", "\n", "\n", "core_out", "=", "self", ".", "drop", "(", "word_emb", "+", "pos_emb", "[", "-", "qlen", ":", "]", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hids", ".", "append", "(", "core_out", ")", "\n", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "if", "mems_i", "is", "not", "None", "and", "i", "==", "0", ":", "\n", "                    ", "mems_i", "+=", "pos_emb", "[", ":", "mlen", "]", "\n", "", "core_out", "=", "layer", "(", "core_out", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems_i", ")", "\n", "", "", "elif", "self", ".", "attn_type", "==", "3", ":", "\n", "            ", "core_out", "=", "self", ".", "drop", "(", "word_emb", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hids", ".", "append", "(", "core_out", ")", "\n", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "if", "mems_i", "is", "not", "None", "and", "mlen", ">", "0", ":", "\n", "                    ", "cur_emb", "=", "self", ".", "r_emb", "[", "i", "]", "[", ":", "-", "qlen", "]", "\n", "cur_size", "=", "cur_emb", ".", "size", "(", "0", ")", "\n", "if", "cur_size", "<", "mlen", ":", "\n", "                        ", "cur_emb_pad", "=", "cur_emb", "[", "0", ":", "1", "]", ".", "expand", "(", "mlen", "-", "cur_size", ",", "-", "1", ",", "-", "1", ")", "\n", "cur_emb", "=", "torch", ".", "cat", "(", "[", "cur_emb_pad", ",", "cur_emb", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "                        ", "cur_emb", "=", "cur_emb", "[", "-", "mlen", ":", "]", "\n", "", "mems_i", "+=", "cur_emb", ".", "view", "(", "mlen", ",", "1", ",", "-", "1", ")", "\n", "", "core_out", "+=", "self", ".", "r_emb", "[", "i", "]", "[", "-", "qlen", ":", "]", ".", "view", "(", "qlen", ",", "1", ",", "-", "1", ")", "\n", "\n", "core_out", "=", "layer", "(", "core_out", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems_i", ")", "\n", "\n", "", "", "core_out", "=", "self", ".", "drop", "(", "core_out", ")", "\n", "\n", "new_mems", "=", "self", ".", "_update_mems", "(", "hids", ",", "mems", ",", "mlen", ",", "qlen", ")", "\n", "\n", "return", "core_out", ",", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel.forward": [[1233, 1258], ["input_ids.transpose().contiguous.transpose().contiguous.transpose().contiguous", "modeling_transfo_xl.TransfoXLModel._forward", "last_hidden.transpose().contiguous.transpose().contiguous.transpose().contiguous", "modeling_transfo_xl.TransfoXLModel.init_mems", "input_ids.transpose().contiguous.transpose().contiguous.transpose", "last_hidden.transpose().contiguous.transpose().contiguous.transpose"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLModel._forward", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "mems", "=", "None", ")", ":", "\n", "        ", "\"\"\" Params:\n                input_ids :: [bsz, len]\n                mems :: optional mems from previous forwar passes (or init_mems)\n                    list (num layers) of mem states at the entry of each layer\n                        shape :: [self.config.mem_len, bsz, self.config.d_model]\n                    Note that the first two dimensions are transposed in `mems` with regards to `input_ids` and `target`\n            Returns:\n                tuple (last_hidden, new_mems) where:\n                    new_mems: list (num layers) of mem states at the entry of each layer\n                        shape :: [self.config.mem_len, bsz, self.config.d_model]\n                    last_hidden: output of the last layer:\n                        shape :: [bsz, len, self.config.d_model]\n        \"\"\"", "\n", "# the original code for Transformer-XL used shapes [len, bsz] but we want a unified interface in the library", "\n", "# so we transpose here from shape [bsz, len] to shape [len, bsz]", "\n", "input_ids", "=", "input_ids", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "if", "mems", "is", "None", ":", "\n", "            ", "mems", "=", "self", ".", "init_mems", "(", "input_ids", ")", "\n", "", "last_hidden", ",", "new_mems", "=", "self", ".", "_forward", "(", "input_ids", ",", "mems", "=", "mems", ")", "\n", "\n", "# We transpose back here to shape [bsz, len, hidden_dim]", "\n", "last_hidden", "=", "last_hidden", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "return", "(", "last_hidden", ",", "new_mems", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.__init__": [[1310, 1324], ["modeling_transfo_xl.TransfoXLPreTrainedModel.__init__", "modeling_transfo_xl.TransfoXLModel", "modeling_transfo_xl.TransfoXLLMHeadModel.apply", "modeling_transfo_xl.TransfoXLLMHeadModel.tie_weights", "torch.Linear", "torch.Linear", "torch.Linear", "LogUniformSampler", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.modeling_roberta.RobertaForMaskedLM.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "TransfoXLLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "TransfoXLModel", "(", "config", ")", "\n", "self", ".", "sample_softmax", "=", "config", ".", "sample_softmax", "\n", "# use sampled softmax", "\n", "if", "config", ".", "sample_softmax", ">", "0", ":", "\n", "            ", "self", ".", "out_layer", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "n_token", ")", "\n", "self", ".", "sampler", "=", "LogUniformSampler", "(", "config", ".", "n_token", ",", "config", ".", "sample_softmax", ")", "\n", "# use adaptive softmax (including standard softmax)", "\n", "", "else", ":", "\n", "            ", "self", ".", "crit", "=", "ProjectedAdaptiveLogSoftmax", "(", "config", ".", "n_token", ",", "config", ".", "d_embed", ",", "config", ".", "d_model", ",", "\n", "config", ".", "cutoffs", ",", "div_val", "=", "config", ".", "div_val", ")", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.tie_weights": [[1325, 1342], ["range", "enumerate", "len"], "methods", ["None"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Run this to be sure output and input (adaptive) softmax weights are tied \"\"\"", "\n", "# sampled softmax", "\n", "if", "self", ".", "sample_softmax", ">", "0", ":", "\n", "            ", "if", "self", ".", "config", ".", "tie_weight", ":", "\n", "                ", "self", ".", "out_layer", ".", "weight", "=", "self", ".", "transformer", ".", "word_emb", ".", "weight", "\n", "# adaptive softmax (including standard softmax)", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "config", ".", "tie_weight", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "crit", ".", "out_layers", ")", ")", ":", "\n", "                    ", "self", ".", "crit", ".", "out_layers", "[", "i", "]", ".", "weight", "=", "self", ".", "transformer", ".", "word_emb", ".", "emb_layers", "[", "i", "]", ".", "weight", "\n", "", "", "if", "self", ".", "config", ".", "tie_projs", ":", "\n", "                ", "for", "i", ",", "tie_proj", "in", "enumerate", "(", "self", ".", "config", ".", "tie_projs", ")", ":", "\n", "                    ", "if", "tie_proj", "and", "self", ".", "config", ".", "div_val", "==", "1", "and", "self", ".", "config", ".", "d_model", "!=", "self", ".", "config", ".", "d_embed", ":", "\n", "                        ", "self", ".", "crit", ".", "out_projs", "[", "i", "]", "=", "self", ".", "transformer", ".", "word_emb", ".", "emb_projs", "[", "0", "]", "\n", "", "elif", "tie_proj", "and", "self", ".", "config", ".", "div_val", "!=", "1", ":", "\n", "                        ", "self", ".", "crit", ".", "out_projs", "[", "i", "]", "=", "self", ".", "transformer", ".", "word_emb", ".", "emb_projs", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.reset_length": [[1343, 1345], ["modeling_transfo_xl.TransfoXLLMHeadModel.transformer.reset_length"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.reset_length"], ["", "", "", "", "", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "ext_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "transformer", ".", "reset_length", "(", "tgt_len", ",", "ext_len", ",", "mem_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems": [[1346, 1348], ["modeling_transfo_xl.TransfoXLLMHeadModel.transformer.init_mems"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems"], ["", "def", "init_mems", "(", "self", ",", "data", ")", ":", "\n", "        ", "return", "self", ".", "transformer", ".", "init_mems", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.TransfoXLLMHeadModel.forward": [[1349, 1382], ["input_ids.size", "input_ids.size", "modeling_transfo_xl.TransfoXLLMHeadModel.transformer", "modeling_transfo_xl_utilities.sample_logits", "modeling_transfo_xl.TransfoXLLMHeadModel.crit", "pred_hid.view", "softmax_output.view.view.view", "softmax_output.view.view.view", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "pred_hid.size"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.sample_logits"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "target", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "        ", "\"\"\" Params:\n                input_ids :: [bsz, len]\n                target :: [bsz, len]\n            Returns:\n                tuple(softmax_output, new_mems) where:\n                    new_mems: list (num layers) of hidden states at the entry of each layer\n                        shape :: [mem_len, bsz, self.config.d_model] :: Warning: shapes are transposed here w. regards to input_ids\n                    softmax_output: output of the (adaptive) softmax:\n                        if target is None:\n                            Negative log likelihood of shape :: [bsz, len] \n                        else:\n                            log probabilities of tokens, shape :: [bsz, len, n_tokens]\n        \"\"\"", "\n", "bsz", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "tgt_len", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "\n", "last_hidden", ",", "new_mems", "=", "self", ".", "transformer", "(", "input_ids", ",", "mems", ")", "\n", "\n", "pred_hid", "=", "last_hidden", "[", ":", ",", "-", "tgt_len", ":", "]", "\n", "if", "self", ".", "sample_softmax", ">", "0", "and", "self", ".", "training", ":", "\n", "            ", "assert", "self", ".", "config", ".", "tie_weight", "\n", "logit", "=", "sample_logits", "(", "self", ".", "transformer", ".", "word_emb", ",", "self", ".", "out_layer", ".", "bias", ",", "target", ",", "pred_hid", ",", "self", ".", "sampler", ")", "\n", "softmax_output", "=", "-", "F", ".", "log_softmax", "(", "logit", ",", "-", "1", ")", "[", ":", ",", ":", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "softmax_output", "=", "self", ".", "crit", "(", "pred_hid", ".", "view", "(", "-", "1", ",", "pred_hid", ".", "size", "(", "-", "1", ")", ")", ",", "target", ")", "\n", "if", "target", "is", "None", ":", "\n", "                ", "softmax_output", "=", "softmax_output", ".", "view", "(", "bsz", ",", "tgt_len", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "softmax_output", "=", "softmax_output", ".", "view", "(", "bsz", ",", "tgt_len", ")", "\n", "\n", "# We transpose back", "\n", "", "", "return", "(", "softmax_output", ",", "new_mems", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.build_tf_to_pytorch_map": [[55, 126], ["hasattr", "enumerate", "enumerate", "tf_to_pt_map.update", "tf_to_pt_map.update", "enumerate", "zip", "tf_to_pt_map.update", "tf_to_pt_map.update", "zip", "r_r_list.append", "r_w_list.append", "tf_to_pt_map.update", "tf_to_pt_map.update", "tf_to_pt_map.update"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update"], ["def", "build_tf_to_pytorch_map", "(", "model", ",", "config", ")", ":", "\n", "    ", "\"\"\" A map of modules from TF to PyTorch.\n        This time I use a map to keep the PyTorch model as identical to the original PyTorch model as possible.\n    \"\"\"", "\n", "tf_to_pt_map", "=", "{", "}", "\n", "\n", "if", "hasattr", "(", "model", ",", "'transformer'", ")", ":", "\n", "# We are loading in a TransfoXLLMHeadModel => we will load also the Adaptive Softmax", "\n", "        ", "tf_to_pt_map", ".", "update", "(", "{", "\n", "\"transformer/adaptive_softmax/cutoff_0/cluster_W\"", ":", "model", ".", "crit", ".", "cluster_weight", ",", "\n", "\"transformer/adaptive_softmax/cutoff_0/cluster_b\"", ":", "model", ".", "crit", ".", "cluster_bias", "}", ")", "\n", "for", "i", ",", "(", "out_l", ",", "proj_l", ",", "tie_proj", ")", "in", "enumerate", "(", "zip", "(", "\n", "model", ".", "crit", ".", "out_layers", ",", "\n", "model", ".", "crit", ".", "out_projs", ",", "\n", "config", ".", "tie_projs", ")", ")", ":", "\n", "            ", "layer_str", "=", "\"transformer/adaptive_softmax/cutoff_%d/\"", "%", "i", "\n", "if", "config", ".", "tie_weight", ":", "\n", "                ", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "'b'", ":", "out_l", ".", "bias", "}", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "# I don't think this is implemented in the TF code", "\n", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "'lookup_table'", ":", "out_l", ".", "weight", ",", "\n", "layer_str", "+", "'b'", ":", "out_l", ".", "bias", "}", ")", "\n", "", "if", "not", "tie_proj", ":", "\n", "                ", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "'proj'", ":", "proj_l", "\n", "}", ")", "\n", "# Now load the rest of the transformer", "\n", "", "", "model", "=", "model", ".", "transformer", "\n", "\n", "# Embeddings", "\n", "", "for", "i", ",", "(", "embed_l", ",", "proj_l", ")", "in", "enumerate", "(", "zip", "(", "model", ".", "word_emb", ".", "emb_layers", ",", "model", ".", "word_emb", ".", "emb_projs", ")", ")", ":", "\n", "        ", "layer_str", "=", "\"transformer/adaptive_embed/cutoff_%d/\"", "%", "i", "\n", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "'lookup_table'", ":", "embed_l", ".", "weight", ",", "\n", "layer_str", "+", "'proj_W'", ":", "proj_l", "\n", "}", ")", "\n", "\n", "# Transformer blocks", "\n", "", "for", "i", ",", "b", "in", "enumerate", "(", "model", ".", "layers", ")", ":", "\n", "        ", "layer_str", "=", "\"transformer/layer_%d/\"", "%", "i", "\n", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/gamma\"", ":", "b", ".", "dec_attn", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/beta\"", ":", "b", ".", "dec_attn", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"rel_attn/o/kernel\"", ":", "b", ".", "dec_attn", ".", "o_net", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/qkv/kernel\"", ":", "b", ".", "dec_attn", ".", "qkv_net", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/r/kernel\"", ":", "b", ".", "dec_attn", ".", "r_net", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/gamma\"", ":", "b", ".", "pos_ff", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/beta\"", ":", "b", ".", "pos_ff", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_1/kernel\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "0", "]", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_1/bias\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "0", "]", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_2/kernel\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "3", "]", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_2/bias\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "3", "]", ".", "bias", ",", "\n", "}", ")", "\n", "\n", "# Relative positioning biases", "\n", "", "if", "config", ".", "untie_r", ":", "\n", "        ", "r_r_list", "=", "[", "]", "\n", "r_w_list", "=", "[", "]", "\n", "for", "b", "in", "model", ".", "layers", ":", "\n", "            ", "r_r_list", ".", "append", "(", "b", ".", "dec_attn", ".", "r_r_bias", ")", "\n", "r_w_list", ".", "append", "(", "b", ".", "dec_attn", ".", "r_w_bias", ")", "\n", "", "", "else", ":", "\n", "        ", "r_r_list", "=", "[", "model", ".", "r_r_bias", "]", "\n", "r_w_list", "=", "[", "model", ".", "r_w_bias", "]", "\n", "", "tf_to_pt_map", ".", "update", "(", "{", "\n", "'transformer/r_r_bias'", ":", "r_r_list", ",", "\n", "'transformer/r_w_bias'", ":", "r_w_list", "}", ")", "\n", "return", "tf_to_pt_map", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.load_tf_weights_in_transfo_xl": [[127, 181], ["modeling_transfo_xl.build_tf_to_pytorch_map", "tf.train.list_variables", "build_tf_to_pytorch_map.items", "print", "print", "tf.train.load_variable", "tf_weights.pop", "tf_weights.pop", "tf_weights.pop", "print", "np.transpose", "enumerate", "print", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "len", "len", "print", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "tf_weights.keys"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.build_tf_to_pytorch_map"], ["", "def", "load_tf_weights_in_transfo_xl", "(", "model", ",", "config", ",", "tf_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "print", "(", "\"Loading a TensorFlow models in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "# Build TF to PyTorch weights loading map", "\n", "", "tf_to_pt_map", "=", "build_tf_to_pytorch_map", "(", "model", ",", "config", ")", "\n", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "tf_weights", "=", "{", "}", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "print", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "tf_weights", "[", "name", "]", "=", "array", "\n", "\n", "", "for", "name", ",", "pointer", "in", "tf_to_pt_map", ".", "items", "(", ")", ":", "\n", "        ", "assert", "name", "in", "tf_weights", "\n", "array", "=", "tf_weights", "[", "name", "]", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "'kernel'", "in", "name", "or", "'proj'", "in", "name", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "if", "(", "'r_r_bias'", "in", "name", "or", "'r_w_bias'", "in", "name", ")", "and", "len", "(", "pointer", ")", ">", "1", ":", "\n", "# Here we will split the TF weigths", "\n", "            ", "assert", "len", "(", "pointer", ")", "==", "array", ".", "shape", "[", "0", "]", "\n", "for", "i", ",", "p_i", "in", "enumerate", "(", "pointer", ")", ":", "\n", "                ", "arr_i", "=", "array", "[", "i", ",", "...", "]", "\n", "try", ":", "\n", "                    ", "assert", "p_i", ".", "shape", "==", "arr_i", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                    ", "e", ".", "args", "+=", "(", "p_i", ".", "shape", ",", "arr_i", ".", "shape", ")", "\n", "raise", "\n", "", "print", "(", "\"Initialize PyTorch weight {} for layer {}\"", ".", "format", "(", "name", ",", "i", ")", ")", "\n", "p_i", ".", "data", "=", "torch", ".", "from_numpy", "(", "arr_i", ")", "\n", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "print", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "tf_weights", ".", "pop", "(", "name", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "'/Adam'", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "'/Adam_1'", ",", "None", ")", "\n", "\n", "", "print", "(", "\"Weights not copied to PyTorch model: {}\"", ".", "format", "(", "', '", ".", "join", "(", "tf_weights", ".", "keys", "(", ")", ")", ")", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.__init__": [[32, 77], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "len", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "range", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_layers.append", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "torch.Linear", "torch.Linear", "torch.Linear", "len", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_projs.append", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_layers.append", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_projs.append", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_projs.append", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_token", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "1", ",", "\n", "keep_order", "=", "False", ")", ":", "\n", "        ", "super", "(", "ProjectedAdaptiveLogSoftmax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_token", "=", "n_token", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_token", "]", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "self", ".", "div_val", "=", "div_val", "\n", "\n", "self", ".", "shortlist_size", "=", "self", ".", "cutoffs", "[", "0", "]", "\n", "self", ".", "n_clusters", "=", "len", "(", "self", ".", "cutoffs", ")", "-", "1", "\n", "self", ".", "head_size", "=", "self", ".", "shortlist_size", "+", "self", ".", "n_clusters", "\n", "\n", "if", "self", ".", "n_clusters", ">", "0", ":", "\n", "            ", "self", ".", "cluster_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "n_clusters", ",", "self", ".", "d_embed", ")", ")", "\n", "self", ".", "cluster_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "n_clusters", ")", ")", "\n", "\n", "", "self", ".", "out_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "out_projs", "=", "nn", ".", "ParameterList", "(", ")", "\n", "\n", "if", "div_val", "==", "1", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "d_proj", "!=", "d_embed", ":", "\n", "                    ", "self", ".", "out_projs", ".", "append", "(", "\n", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_proj", ",", "d_embed", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "out_projs", ".", "append", "(", "None", ")", "\n", "\n", "", "", "self", ".", "out_layers", ".", "append", "(", "nn", ".", "Linear", "(", "d_embed", ",", "n_token", ")", ")", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "d_embed", "//", "(", "div_val", "**", "i", ")", "\n", "\n", "self", ".", "out_projs", ".", "append", "(", "\n", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_proj", ",", "d_emb_i", ")", ")", "\n", ")", "\n", "\n", "self", ".", "out_layers", ".", "append", "(", "nn", ".", "Linear", "(", "d_emb_i", ",", "r_idx", "-", "l_idx", ")", ")", "\n", "\n", "", "", "self", ".", "keep_order", "=", "keep_order", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit": [[78, 91], ["torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "proj.t().contiguous", "proj.t"], "methods", ["None"], ["", "def", "_compute_logit", "(", "self", ",", "hidden", ",", "weight", ",", "bias", ",", "proj", ")", ":", "\n", "        ", "if", "proj", "is", "None", ":", "\n", "            ", "logit", "=", "F", ".", "linear", "(", "hidden", ",", "weight", ",", "bias", "=", "bias", ")", "\n", "", "else", ":", "\n", "# if CUDA_MAJOR <= 9 and CUDA_MINOR <= 1:", "\n", "            ", "proj_hid", "=", "F", ".", "linear", "(", "hidden", ",", "proj", ".", "t", "(", ")", ".", "contiguous", "(", ")", ")", "\n", "logit", "=", "F", ".", "linear", "(", "proj_hid", ",", "weight", ",", "bias", "=", "bias", ")", "\n", "# else:", "\n", "#     logit = torch.einsum('bd,de,ev->bv', (hidden, proj, weight.t()))", "\n", "#     if bias is not None:", "\n", "#         logit = logit + bias", "\n", "\n", "", "return", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.forward": [[92, 196], ["target.view.view.view", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "range", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "range", "hidden.size", "target.view.view.size", "RuntimeError", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "len", "weights.append", "biases.append", "hidden.new_empty", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.log_softmax().gather().squeeze", "torch.log_softmax().gather().squeeze", "torch.log_softmax().gather().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "mask_i.nonzero().squeeze", "torch.log_softmax.index_select", "hidden.index_select", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "head_logprob.index_select.gather().squeeze.size", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.size", "mask_i.nonzero().squeeze.numel", "target.view.view.index_select", "F.log_softmax.index_select.gather().squeeze", "torch.zeros_like.index_copy_", "torch.zeros_like.index_copy_", "torch.zeros_like.index_copy_", "out[].copy_", "torch.log_softmax().gather", "torch.log_softmax().gather", "torch.log_softmax().gather", "mask_i.nonzero", "torch.log_softmax.gather().squeeze", "hasattr", "target.view.view.unsqueeze", "F.log_softmax.index_select.gather", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax.gather", "head_logprob.index_select.gather().squeeze.size"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit"], ["", "def", "forward", "(", "self", ",", "hidden", ",", "target", "=", "None", ",", "keep_order", "=", "False", ")", ":", "\n", "        ", "'''\n            Params:\n                hidden :: [len*bsz x d_proj]\n                target :: [len*bsz]\n            Return:\n                if target is None:\n                    out :: [len*bsz] Negative log likelihood\n                else:\n                    out :: [len*bsz x n_tokens] log probabilities of tokens over the vocabulary\n            We could replace this implementation by the native PyTorch one\n            if their's had an option to set bias on all clusters in the native one.\n            here: https://github.com/pytorch/pytorch/blob/dbe6a7a9ff1a364a8706bf5df58a1ca96d2fd9da/torch/nn/modules/adaptive.py#L138\n        '''", "\n", "\n", "if", "target", "is", "not", "None", ":", "\n", "            ", "target", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "if", "hidden", ".", "size", "(", "0", ")", "!=", "target", ".", "size", "(", "0", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "'Input and target should have the same size '", "\n", "'in the batch dimension.'", ")", "\n", "\n", "", "", "if", "self", ".", "n_clusters", "==", "0", ":", "\n", "            ", "logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "self", ".", "out_layers", "[", "0", "]", ".", "weight", ",", "\n", "self", ".", "out_layers", "[", "0", "]", ".", "bias", ",", "self", ".", "out_projs", "[", "0", "]", ")", "\n", "if", "target", "is", "not", "None", ":", "\n", "                ", "output", "=", "-", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", ".", "gather", "(", "1", ",", "target", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "output", "=", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", "\n", "", "", "else", ":", "\n", "# construct weights and biases", "\n", "            ", "weights", ",", "biases", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "                    ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "weight_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "weight", "[", "l_idx", ":", "r_idx", "]", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "bias", "[", "l_idx", ":", "r_idx", "]", "\n", "", "else", ":", "\n", "                    ", "weight_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "weight", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "bias", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "weight_i", "=", "torch", ".", "cat", "(", "\n", "[", "weight_i", ",", "self", ".", "cluster_weight", "]", ",", "dim", "=", "0", ")", "\n", "bias_i", "=", "torch", ".", "cat", "(", "\n", "[", "bias_i", ",", "self", ".", "cluster_bias", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "weights", ".", "append", "(", "weight_i", ")", "\n", "biases", ".", "append", "(", "bias_i", ")", "\n", "\n", "", "head_weight", ",", "head_bias", ",", "head_proj", "=", "weights", "[", "0", "]", ",", "biases", "[", "0", "]", ",", "self", ".", "out_projs", "[", "0", "]", "\n", "\n", "head_logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "head_weight", ",", "head_bias", ",", "head_proj", ")", "\n", "head_logprob", "=", "F", ".", "log_softmax", "(", "head_logit", ",", "dim", "=", "1", ")", "\n", "\n", "if", "target", "is", "None", ":", "\n", "                ", "out", "=", "hidden", ".", "new_empty", "(", "(", "head_logit", ".", "size", "(", "0", ")", ",", "self", ".", "n_token", ")", ")", "\n", "", "else", ":", "\n", "                ", "out", "=", "torch", ".", "zeros_like", "(", "target", ",", "dtype", "=", "hidden", ".", "dtype", ",", "device", "=", "hidden", ".", "device", ")", "\n", "\n", "", "offset", "=", "0", "\n", "cutoff_values", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "for", "i", "in", "range", "(", "len", "(", "cutoff_values", ")", "-", "1", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "cutoff_values", "[", "i", "]", ",", "cutoff_values", "[", "i", "+", "1", "]", "\n", "\n", "if", "target", "is", "not", "None", ":", "\n", "                    ", "mask_i", "=", "(", "target", ">=", "l_idx", ")", "&", "(", "target", "<", "r_idx", ")", "\n", "indices_i", "=", "mask_i", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "\n", "if", "indices_i", ".", "numel", "(", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "\n", "", "target_i", "=", "target", ".", "index_select", "(", "0", ",", "indices_i", ")", "-", "l_idx", "\n", "head_logprob_i", "=", "head_logprob", ".", "index_select", "(", "0", ",", "indices_i", ")", "\n", "hidden_i", "=", "hidden", ".", "index_select", "(", "0", ",", "indices_i", ")", "\n", "", "else", ":", "\n", "                    ", "hidden_i", "=", "hidden", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "if", "target", "is", "not", "None", ":", "\n", "                        ", "logprob_i", "=", "head_logprob_i", ".", "gather", "(", "1", ",", "target_i", "[", ":", ",", "None", "]", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                        ", "out", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "=", "head_logprob", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "\n", "", "", "else", ":", "\n", "                    ", "weight_i", ",", "bias_i", ",", "proj_i", "=", "weights", "[", "i", "]", ",", "biases", "[", "i", "]", ",", "self", ".", "out_projs", "[", "i", "]", "\n", "\n", "tail_logit_i", "=", "self", ".", "_compute_logit", "(", "hidden_i", ",", "weight_i", ",", "bias_i", ",", "proj_i", ")", "\n", "tail_logprob_i", "=", "F", ".", "log_softmax", "(", "tail_logit_i", ",", "dim", "=", "1", ")", "\n", "cluster_prob_idx", "=", "self", ".", "cutoffs", "[", "0", "]", "+", "i", "-", "1", "# No probability for the head cluster", "\n", "if", "target", "is", "not", "None", ":", "\n", "                        ", "logprob_i", "=", "head_logprob_i", "[", ":", ",", "cluster_prob_idx", "]", "+", "tail_logprob_i", ".", "gather", "(", "1", ",", "target_i", "[", ":", ",", "None", "]", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                        ", "logprob_i", "=", "head_logprob", "[", ":", ",", "cluster_prob_idx", ",", "None", "]", "+", "tail_logprob_i", "\n", "out", "[", ":", ",", "l_idx", ":", "r_idx", "]", "=", "logprob_i", "\n", "\n", "", "", "if", "target", "is", "not", "None", ":", "\n", "                    ", "if", "(", "hasattr", "(", "self", ",", "'keep_order'", ")", "and", "self", ".", "keep_order", ")", "or", "keep_order", ":", "\n", "                        ", "out", ".", "index_copy_", "(", "0", ",", "indices_i", ",", "-", "logprob_i", ")", "\n", "", "else", ":", "\n", "                        ", "out", "[", "offset", ":", "offset", "+", "logprob_i", ".", "size", "(", "0", ")", "]", ".", "copy_", "(", "-", "logprob_i", ")", "\n", "", "offset", "+=", "logprob_i", ".", "size", "(", "0", ")", "\n", "\n", "", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.log_prob": [[198, 258], ["modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "range", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "hidden.new_empty", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "range", "len", "weights.append", "biases.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.size", "len", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit"], ["", "def", "log_prob", "(", "self", ",", "hidden", ")", ":", "\n", "        ", "r\"\"\" Computes log probabilities for all :math:`n\\_classes`\n        From: https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/adaptive.py\n        Args:\n            hidden (Tensor): a minibatch of examples\n        Returns:\n            log-probabilities of for each class :math:`c`\n            in range :math:`0 <= c <= n\\_classes`, where :math:`n\\_classes` is a\n            parameter passed to ``AdaptiveLogSoftmaxWithLoss`` constructor.\n        Shape:\n            - Input: :math:`(N, in\\_features)`\n            - Output: :math:`(N, n\\_classes)`\n        \"\"\"", "\n", "if", "self", ".", "n_clusters", "==", "0", ":", "\n", "            ", "logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "self", ".", "out_layers", "[", "0", "]", ".", "weight", ",", "\n", "self", ".", "out_layers", "[", "0", "]", ".", "bias", ",", "self", ".", "out_projs", "[", "0", "]", ")", "\n", "return", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "# construct weights and biases", "\n", "            ", "weights", ",", "biases", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "                    ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "weight_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "weight", "[", "l_idx", ":", "r_idx", "]", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "bias", "[", "l_idx", ":", "r_idx", "]", "\n", "", "else", ":", "\n", "                    ", "weight_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "weight", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "bias", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "weight_i", "=", "torch", ".", "cat", "(", "\n", "[", "weight_i", ",", "self", ".", "cluster_weight", "]", ",", "dim", "=", "0", ")", "\n", "bias_i", "=", "torch", ".", "cat", "(", "\n", "[", "bias_i", ",", "self", ".", "cluster_bias", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "weights", ".", "append", "(", "weight_i", ")", "\n", "biases", ".", "append", "(", "bias_i", ")", "\n", "\n", "", "head_weight", ",", "head_bias", ",", "head_proj", "=", "weights", "[", "0", "]", ",", "biases", "[", "0", "]", ",", "self", ".", "out_projs", "[", "0", "]", "\n", "head_logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "head_weight", ",", "head_bias", ",", "head_proj", ")", "\n", "\n", "out", "=", "hidden", ".", "new_empty", "(", "(", "head_logit", ".", "size", "(", "0", ")", ",", "self", ".", "n_token", ")", ")", "\n", "head_logprob", "=", "F", ".", "log_softmax", "(", "head_logit", ",", "dim", "=", "1", ")", "\n", "\n", "cutoff_values", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "for", "i", "in", "range", "(", "len", "(", "cutoff_values", ")", "-", "1", ")", ":", "\n", "                ", "start_idx", ",", "stop_idx", "=", "cutoff_values", "[", "i", "]", ",", "cutoff_values", "[", "i", "+", "1", "]", "\n", "\n", "if", "i", "==", "0", ":", "\n", "                    ", "out", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "=", "head_logprob", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "                    ", "weight_i", ",", "bias_i", ",", "proj_i", "=", "weights", "[", "i", "]", ",", "biases", "[", "i", "]", ",", "self", ".", "out_projs", "[", "i", "]", "\n", "\n", "tail_logit_i", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "weight_i", ",", "bias_i", ",", "proj_i", ")", "\n", "tail_logprob_i", "=", "F", ".", "log_softmax", "(", "tail_logit_i", ",", "dim", "=", "1", ")", "\n", "\n", "logprob_i", "=", "head_logprob", "[", ":", ",", "-", "i", "]", "+", "tail_logprob_i", "\n", "out", "[", ":", ",", "start_idx", ",", "stop_idx", "]", "=", "logprob_i", "\n", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.LogUniformSampler.__init__": [[261, 280], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "modeling_transfo_xl_utilities.LogUniformSampler.dist.double().log1p_", "modeling_transfo_xl_utilities.LogUniformSampler.dist.double"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "range_max", ",", "n_sample", ")", ":", "\n", "        ", "\"\"\"\n        Reference : https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/python/ops/candidate_sampling_ops.py\n            `P(class) = (log(class + 2) - log(class + 1)) / log(range_max + 1)`\n\n        expected count can be approximated by 1 - (1 - p)^n\n        and we use a numerically stable version -expm1(num_tries * log1p(-p))\n\n        Our implementation fixes num_tries at 2 * n_sample, and the actual #samples will vary from run to run\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "range_max", "=", "range_max", "\n", "log_indices", "=", "torch", ".", "arange", "(", "1.", ",", "range_max", "+", "2.", ",", "1.", ")", ".", "log_", "(", ")", "\n", "self", ".", "dist", "=", "(", "log_indices", "[", "1", ":", "]", "-", "log_indices", "[", ":", "-", "1", "]", ")", "/", "log_indices", "[", "-", "1", "]", "\n", "# print('P', self.dist.numpy().tolist()[-30:])", "\n", "\n", "self", ".", "log_q", "=", "(", "-", "(", "-", "self", ".", "dist", ".", "double", "(", ")", ".", "log1p_", "(", ")", "*", "2", "*", "n_sample", ")", ".", "expm1_", "(", ")", ")", ".", "log_", "(", ")", ".", "float", "(", ")", "\n", "\n", "", "self", ".", "n_sample", "=", "n_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.LogUniformSampler.sample": [[281, 301], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "neg_samples.to.to.to", "modeling_transfo_xl_utilities.LogUniformSampler.log_q[].to", "modeling_transfo_xl_utilities.LogUniformSampler.log_q[].to", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "labels", ")", ":", "\n", "        ", "\"\"\"\n            labels: [b1, b2]\n        Return\n            true_log_probs: [b1, b2]\n            samp_log_probs: [n_sample]\n            neg_samples: [n_sample]\n        \"\"\"", "\n", "\n", "# neg_samples = torch.empty(0).long()", "\n", "n_sample", "=", "self", ".", "n_sample", "\n", "n_tries", "=", "2", "*", "n_sample", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "neg_samples", "=", "torch", ".", "multinomial", "(", "self", ".", "dist", ",", "n_tries", ",", "replacement", "=", "True", ")", ".", "unique", "(", ")", "\n", "device", "=", "labels", ".", "device", "\n", "neg_samples", "=", "neg_samples", ".", "to", "(", "device", ")", "\n", "true_log_probs", "=", "self", ".", "log_q", "[", "labels", "]", ".", "to", "(", "device", ")", "\n", "samp_log_probs", "=", "self", ".", "log_q", "[", "neg_samples", "]", ".", "to", "(", "device", ")", "\n", "return", "true_log_probs", ",", "samp_log_probs", ",", "neg_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.sample_logits": [[302, 334], ["sampler.sample", "neg_samples.size", "torch.cat", "torch.cat", "torch.cat", "embedding", "all_w[].view", "all_w[].view", "all_b[].view", "sample_logits.masked_fill_", "torch.cat", "torch.cat", "torch.cat", "labels.size", "labels.size", "labels.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl_utilities.LogUniformSampler.sample", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBert.embedding"], ["", "", "", "def", "sample_logits", "(", "embedding", ",", "bias", ",", "labels", ",", "inputs", ",", "sampler", ")", ":", "\n", "    ", "\"\"\"\n        embedding: an nn.Embedding layer\n        bias: [n_vocab]\n        labels: [b1, b2]\n        inputs: [b1, b2, n_emb]\n        sampler: you may use a LogUniformSampler\n    Return\n        logits: [b1, b2, 1 + n_sample]\n    \"\"\"", "\n", "true_log_probs", ",", "samp_log_probs", ",", "neg_samples", "=", "sampler", ".", "sample", "(", "labels", ")", "\n", "n_sample", "=", "neg_samples", ".", "size", "(", "0", ")", "\n", "b1", ",", "b2", "=", "labels", ".", "size", "(", "0", ")", ",", "labels", ".", "size", "(", "1", ")", "\n", "all_ids", "=", "torch", ".", "cat", "(", "[", "labels", ".", "view", "(", "-", "1", ")", ",", "neg_samples", "]", ")", "\n", "all_w", "=", "embedding", "(", "all_ids", ")", "\n", "true_w", "=", "all_w", "[", ":", "-", "n_sample", "]", ".", "view", "(", "b1", ",", "b2", ",", "-", "1", ")", "\n", "sample_w", "=", "all_w", "[", "-", "n_sample", ":", "]", ".", "view", "(", "n_sample", ",", "-", "1", ")", "\n", "\n", "all_b", "=", "bias", "[", "all_ids", "]", "\n", "true_b", "=", "all_b", "[", ":", "-", "n_sample", "]", ".", "view", "(", "b1", ",", "b2", ")", "\n", "sample_b", "=", "all_b", "[", "-", "n_sample", ":", "]", "\n", "\n", "hit", "=", "(", "labels", "[", ":", ",", ":", ",", "None", "]", "==", "neg_samples", ")", ".", "detach", "(", ")", "\n", "\n", "true_logits", "=", "torch", ".", "einsum", "(", "'ijk,ijk->ij'", ",", "\n", "[", "true_w", ",", "inputs", "]", ")", "+", "true_b", "-", "true_log_probs", "\n", "sample_logits", "=", "torch", ".", "einsum", "(", "'lk,ijk->ijl'", ",", "\n", "[", "sample_w", ",", "inputs", "]", ")", "+", "sample_b", "-", "samp_log_probs", "\n", "sample_logits", ".", "masked_fill_", "(", "hit", ",", "-", "1e30", ")", "\n", "logits", "=", "torch", ".", "cat", "(", "[", "true_logits", "[", ":", ",", ":", ",", "None", "]", ",", "sample_logits", "]", ",", "-", "1", ")", "\n", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.file_utils.url_to_filename": [[39, 55], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.encode"], ["def", "url_to_filename", "(", "url", ",", "etag", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "'utf-8'", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "'utf-8'", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "'.'", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.file_utils.filename_to_url": [[57, 81], ["os.path.join", "isinstance", "str", "os.path.exists", "EnvironmentError", "os.path.exists", "EnvironmentError", "io.open", "json.load"], "function", ["None"], ["", "def", "filename_to_url", "(", "filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``EnvironmentError`` if `filename` or its stored metadata do not exist.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_PRETRAINED_BERT_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "cache_path", ")", ")", "\n", "\n", "", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "meta_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "meta_path", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "        ", "metadata", "=", "json", ".", "load", "(", "meta_file", ")", "\n", "", "url", "=", "metadata", "[", "'url'", "]", "\n", "etag", "=", "metadata", "[", "'etag'", "]", "\n", "\n", "return", "url", ",", "etag", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.file_utils.cached_path": [[83, 111], ["urlparse", "isinstance", "str", "isinstance", "str", "file_utils.get_from_cache", "os.path.exists", "EnvironmentError", "ValueError"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.get_from_cache"], ["", "def", "cached_path", "(", "url_or_filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_PRETRAINED_BERT_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "\n", "if", "parsed", ".", "scheme", "in", "(", "'http'", ",", "'https'", ",", "'s3'", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "return", "get_from_cache", "(", "url_or_filename", ",", "cache_dir", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n", "# File, and it exists.", "\n", "        ", "return", "url_or_filename", "\n", "", "elif", "parsed", ".", "scheme", "==", "''", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.file_utils.split_s3_path": [[113, 124], ["urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["", "", "def", "split_s3_path", "(", "url", ")", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "s3_path", "=", "s3_path", "[", "1", ":", "]", "\n", "", "return", "bucket_name", ",", "s3_path", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.file_utils.s3_request": [[126, 143], ["functools.wraps", "func", "int", "EnvironmentError"], "function", ["None"], ["", "def", "s3_request", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.file_utils.s3_etag": [[145, 152], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Object"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ")", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n", "return", "s3_object", ".", "e_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.file_utils.s3_get": [[154, 160], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Bucket().download_fileobj", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.file_utils.http_get": [[162, 172], ["requests.get", "requests.get.headers.get", "tqdm.tqdm", "requests.get.iter_content", "tqdm.tqdm.close", "int", "tqdm.tqdm.update", "temp_file.write", "len"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update"], ["", "def", "http_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "req", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "content_length", "=", "req", ".", "headers", ".", "get", "(", "'Content-Length'", ")", "\n", "total", "=", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "tqdm", "(", "unit", "=", "\"B\"", ",", "total", "=", "total", ")", "\n", "for", "chunk", "in", "req", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.file_utils.get_from_cache": [[174, 232], ["url.startswith", "file_utils.url_to_filename", "os.path.join", "isinstance", "str", "os.path.exists", "os.makedirs", "file_utils.s3_etag", "requests.head", "requests.head.headers.get", "os.path.exists", "IOError", "tempfile.NamedTemporaryFile", "logger.info", "url.startswith", "temp_file.flush", "temp_file.seek", "logger.info", "logger.info", "logger.info", "file_utils.s3_get", "file_utils.http_get", "io.open", "shutil.copyfileobj", "io.open", "json.dump"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.url_to_filename", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.s3_etag", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.s3_get", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.http_get"], ["", "def", "get_from_cache", "(", "url", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding dataset in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_PRETRAINED_BERT_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "cache_dir", ")", "\n", "\n", "# Get eTag to add to filename, if it exists.", "\n", "", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "        ", "etag", "=", "s3_etag", "(", "url", ")", "\n", "", "else", ":", "\n", "        ", "response", "=", "requests", ".", "head", "(", "url", ",", "allow_redirects", "=", "True", ")", "\n", "if", "response", ".", "status_code", "!=", "200", ":", "\n", "            ", "raise", "IOError", "(", "\"HEAD request failed for url {} with status code {}\"", "\n", ".", "format", "(", "url", ",", "response", ".", "status_code", ")", ")", "\n", "", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "\n", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "temp_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s not found in cache, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", ")", "\n", "\n", "# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                ", "s3_get", "(", "url", ",", "temp_file", ")", "\n", "", "else", ":", "\n", "                ", "http_get", "(", "url", ",", "temp_file", ")", "\n", "\n", "# we are copying the file before closing it, so flush to avoid truncation", "\n", "", "temp_file", ".", "flush", "(", ")", "\n", "# shutil.copyfileobj() starts at the current position, so go to the start", "\n", "temp_file", ".", "seek", "(", "0", ")", "\n", "\n", "logger", ".", "info", "(", "\"copying %s to cache at %s\"", ",", "temp_file", ".", "name", ",", "cache_path", ")", "\n", "with", "open", "(", "cache_path", ",", "'wb'", ")", "as", "cache_file", ":", "\n", "                ", "shutil", ".", "copyfileobj", "(", "temp_file", ",", "cache_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"creating metadata file for %s\"", ",", "cache_path", ")", "\n", "meta", "=", "{", "'url'", ":", "url", ",", "'etag'", ":", "etag", "}", "\n", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "with", "open", "(", "meta_path", ",", "'w'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "                ", "json", ".", "dump", "(", "meta", ",", "meta_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"removing temp file %s\"", ",", "temp_file", ".", "name", ")", "\n", "\n", "", "", "return", "cache_path", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.file_utils.read_set_from_file": [[234, 244], ["set", "io.open", "set.add", "line.rstrip"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.add"], ["", "def", "read_set_from_file", "(", "filename", ")", ":", "\n", "    ", "'''\n    Extract a de-duped collection (set) of text from a file.\n    Expected file format is one item per line.\n    '''", "\n", "collection", "=", "set", "(", ")", "\n", "with", "open", "(", "filename", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "file_", ":", "\n", "        ", "for", "line", "in", "file_", ":", "\n", "            ", "collection", ".", "add", "(", "line", ".", "rstrip", "(", ")", ")", "\n", "", "", "return", "collection", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.file_utils.get_file_extension": [[246, 250], ["os.path.splitext", "ext.lower"], "function", ["None"], ["", "def", "get_file_extension", "(", "path", ",", "dot", "=", "True", ",", "lower", "=", "True", ")", ":", "\n", "    ", "ext", "=", "os", ".", "path", ".", "splitext", "(", "path", ")", "[", "1", "]", "\n", "ext", "=", "ext", "if", "dot", "else", "ext", "[", "1", ":", "]", "\n", "return", "ext", ".", "lower", "(", ")", "if", "lower", "else", "ext", "\n", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BertTokenizer.__init__": [[77, 90], ["tokenization.load_vocab", "collections.OrderedDict", "tokenization.BasicTokenizer", "tokenization.WordpieceTokenizer", "os.path.isfile", "ValueError", "int", "tokenization.BertTokenizer.vocab.items"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.load_vocab"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "do_lower_case", "=", "True", ",", "max_len", "=", "None", ",", "\n", "never_split", "=", "(", "\"[UNK]\"", ",", "\"[SEP]\"", ",", "\"[PAD]\"", ",", "\"[CLS]\"", ",", "\"[MASK]\"", ")", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "isfile", "(", "vocab_file", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Can't find a vocabulary file at path '{}'. To load the vocabulary from a Google pretrained \"", "\n", "\"model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "", "self", ".", "vocab", "=", "load_vocab", "(", "vocab_file", ")", "\n", "self", ".", "ids_to_tokens", "=", "collections", ".", "OrderedDict", "(", "\n", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "self", ".", "vocab", ".", "items", "(", ")", "]", ")", "\n", "self", ".", "basic_tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ",", "\n", "never_split", "=", "never_split", ")", "\n", "self", ".", "wordpiece_tokenizer", "=", "WordpieceTokenizer", "(", "vocab", "=", "self", ".", "vocab", ")", "\n", "self", ".", "max_len", "=", "max_len", "if", "max_len", "is", "not", "None", "else", "int", "(", "1e12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BertTokenizer.tokenize": [[91, 97], ["tokenization.BertTokenizer.basic_tokenizer.tokenize", "tokenization.BertTokenizer.wordpiece_tokenizer.tokenize", "split_tokens.append"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "split_tokens", "=", "[", "]", "\n", "for", "token", "in", "self", ".", "basic_tokenizer", ".", "tokenize", "(", "text", ")", ":", "\n", "            ", "for", "sub_token", "in", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", ":", "\n", "                ", "split_tokens", ".", "append", "(", "sub_token", ")", "\n", "", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids": [[98, 110], ["ids.append", "len", "ValueError", "len"], "methods", ["None"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of tokens into ids using the vocab.\"\"\"", "\n", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "ids", ".", "append", "(", "self", ".", "vocab", "[", "token", "]", ")", "\n", "", "if", "len", "(", "ids", ")", ">", "self", ".", "max_len", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Token indices sequence length is longer than the specified maximum \"", "\n", "\" sequence length for this BERT model ({} > {}). Running this\"", "\n", "\" sequence through BERT will result in indexing errors\"", ".", "format", "(", "len", "(", "ids", ")", ",", "self", ".", "max_len", ")", "\n", ")", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BertTokenizer.convert_ids_to_tokens": [[111, 117], ["tokens.append"], "methods", ["None"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of ids in wordpiece tokens using the vocab.\"\"\"", "\n", "tokens", "=", "[", "]", "\n", "for", "i", "in", "ids", ":", "\n", "            ", "tokens", ".", "append", "(", "self", ".", "ids_to_tokens", "[", "i", "]", ")", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained": [[118, 155], ["os.path.isdir", "cls", "os.path.join", "file_utils.cached_path", "logger.info", "logger.info", "min", "logger.error", "kwargs.get", "int", "PRETRAINED_VOCAB_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.cached_path", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a PreTrainedBertModel from a pre-trained model file.\n        Download and cache the pre-trained model file if needed.\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_ARCHIVE_MAP", ":", "\n", "            ", "vocab_file", "=", "PRETRAINED_VOCAB_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "vocab_file", "=", "pretrained_model_name_or_path", "\n", "", "if", "os", ".", "path", ".", "isdir", "(", "vocab_file", ")", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "vocab_file", ",", "VOCAB_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_vocab_file", "=", "cached_path", "(", "vocab_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_VOCAB_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "vocab_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_vocab_file", "==", "vocab_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {}\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {} from cache at {}\"", ".", "format", "(", "\n", "vocab_file", ",", "resolved_vocab_file", ")", ")", "\n", "", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", ":", "\n", "# if we're using a pretrained model, ensure the tokenizer wont index sequences longer", "\n", "# than the number of positional embeddings", "\n", "            ", "max_len", "=", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "kwargs", "[", "'max_len'", "]", "=", "min", "(", "kwargs", ".", "get", "(", "'max_len'", ",", "int", "(", "1e12", ")", ")", ",", "max_len", ")", "\n", "# Instantiate tokenizer.", "\n", "", "tokenizer", "=", "cls", "(", "resolved_vocab_file", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BasicTokenizer.__init__": [[160, 170], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "do_lower_case", "=", "True", ",", "\n", "never_split", "=", "(", "\"[UNK]\"", ",", "\"[SEP]\"", ",", "\"[PAD]\"", ",", "\"[CLS]\"", ",", "\"[MASK]\"", ")", ")", ":", "\n", "        ", "\"\"\"Constructs a BasicTokenizer.\n\n        Args:\n          do_lower_case: Whether to lower case the input.\n        \"\"\"", "\n", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "self", ".", "never_split", "=", "never_split", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BasicTokenizer.tokenize": [[171, 191], ["tokenization.BasicTokenizer._clean_text", "tokenization.BasicTokenizer._tokenize_chinese_chars", "tokenization.whitespace_tokenize", "tokenization.whitespace_tokenize", "split_tokens.extend", "tokenization.BasicTokenizer.lower", "tokenization.BasicTokenizer._run_strip_accents", "tokenization.BasicTokenizer._run_split_on_punc"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._clean_text", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._tokenize_chinese_chars", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_strip_accents", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_split_on_punc"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text.\"\"\"", "\n", "text", "=", "self", ".", "_clean_text", "(", "text", ")", "\n", "# This was added on November 1st, 2018 for the multilingual and Chinese", "\n", "# models. This is also applied to the English models now, but it doesn't", "\n", "# matter since the English models were not trained on any Chinese data", "\n", "# and generally don't have any Chinese data in them (there are Chinese", "\n", "# characters in the vocabulary because Wikipedia does have some Chinese", "\n", "# words in the English Wikipedia.).", "\n", "text", "=", "self", ".", "_tokenize_chinese_chars", "(", "text", ")", "\n", "orig_tokens", "=", "whitespace_tokenize", "(", "text", ")", "\n", "split_tokens", "=", "[", "]", "\n", "for", "token", "in", "orig_tokens", ":", "\n", "            ", "if", "self", ".", "do_lower_case", "and", "token", "not", "in", "self", ".", "never_split", ":", "\n", "                ", "token", "=", "token", ".", "lower", "(", ")", "\n", "token", "=", "self", ".", "_run_strip_accents", "(", "token", ")", "\n", "", "split_tokens", ".", "extend", "(", "self", ".", "_run_split_on_punc", "(", "token", ")", ")", "\n", "\n", "", "output_tokens", "=", "whitespace_tokenize", "(", "\" \"", ".", "join", "(", "split_tokens", ")", ")", "\n", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_strip_accents": [[192, 202], ["unicodedata.normalize", "unicodedata.category", "output.append"], "methods", ["None"], ["", "def", "_run_strip_accents", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Strips accents from a piece of text.\"\"\"", "\n", "text", "=", "unicodedata", ".", "normalize", "(", "\"NFD\"", ",", "text", ")", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Mn\"", ":", "\n", "                ", "continue", "\n", "", "output", ".", "append", "(", "char", ")", "\n", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_split_on_punc": [[203, 224], ["list", "len", "tokenization._is_punctuation", "output.append", "output[].append", "output.append"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization._is_punctuation"], ["", "def", "_run_split_on_punc", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Splits punctuation on a piece of text.\"\"\"", "\n", "if", "text", "in", "self", ".", "never_split", ":", "\n", "            ", "return", "[", "text", "]", "\n", "", "chars", "=", "list", "(", "text", ")", "\n", "i", "=", "0", "\n", "start_new_word", "=", "True", "\n", "output", "=", "[", "]", "\n", "while", "i", "<", "len", "(", "chars", ")", ":", "\n", "            ", "char", "=", "chars", "[", "i", "]", "\n", "if", "_is_punctuation", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "[", "char", "]", ")", "\n", "start_new_word", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "start_new_word", ":", "\n", "                    ", "output", ".", "append", "(", "[", "]", ")", "\n", "", "start_new_word", "=", "False", "\n", "output", "[", "-", "1", "]", ".", "append", "(", "char", ")", "\n", "", "i", "+=", "1", "\n", "\n", "", "return", "[", "\"\"", ".", "join", "(", "x", ")", "for", "x", "in", "output", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._tokenize_chinese_chars": [[225, 237], ["ord", "tokenization.BasicTokenizer._is_chinese_char", "output.append", "output.append", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._is_chinese_char"], ["", "def", "_tokenize_chinese_chars", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Adds whitespace around any CJK character.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "self", ".", "_is_chinese_char", "(", "cp", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "output", ".", "append", "(", "char", ")", "\n", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._is_chinese_char": [[238, 259], ["None"], "methods", ["None"], ["", "def", "_is_chinese_char", "(", "self", ",", "cp", ")", ":", "\n", "        ", "\"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"", "\n", "# This defines a \"chinese character\" as anything in the CJK Unicode block:", "\n", "#   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)", "\n", "#", "\n", "# Note that the CJK Unicode block is NOT all Japanese and Korean characters,", "\n", "# despite its name. The modern Korean Hangul alphabet is a different block,", "\n", "# as is Japanese Hiragana and Katakana. Those alphabets are used to write", "\n", "# space-separated words, so they are not treated specially and handled", "\n", "# like the all of the other languages.", "\n", "if", "(", "(", "cp", ">=", "0x4E00", "and", "cp", "<=", "0x9FFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x3400", "and", "cp", "<=", "0x4DBF", ")", "or", "#", "\n", "(", "cp", ">=", "0x20000", "and", "cp", "<=", "0x2A6DF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2A700", "and", "cp", "<=", "0x2B73F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B740", "and", "cp", "<=", "0x2B81F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B820", "and", "cp", "<=", "0x2CEAF", ")", "or", "\n", "(", "cp", ">=", "0xF900", "and", "cp", "<=", "0xFAFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2F800", "and", "cp", "<=", "0x2FA1F", ")", ")", ":", "#", "\n", "            ", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.BasicTokenizer._clean_text": [[260, 272], ["ord", "tokenization._is_whitespace", "tokenization._is_control", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization._is_whitespace", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization._is_control"], ["", "def", "_clean_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "cp", "==", "0", "or", "cp", "==", "0xfffd", "or", "_is_control", "(", "char", ")", ":", "\n", "                ", "continue", "\n", "", "if", "_is_whitespace", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__": [[277, 281], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocab", ",", "unk_token", "=", "\"[UNK]\"", ",", "max_input_chars_per_word", "=", "100", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "unk_token", "=", "unk_token", "\n", "self", ".", "max_input_chars_per_word", "=", "max_input_chars_per_word", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.tokenize": [[282, 332], ["tokenization.whitespace_tokenize", "list", "len", "output_tokens.append", "len", "len", "sub_tokens.append", "output_tokens.append", "output_tokens.extend"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.whitespace_tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text into its word pieces.\n\n        This uses a greedy longest-match-first algorithm to perform tokenization\n        using the given vocabulary.\n\n        For example:\n          input = \"unaffable\"\n          output = [\"un\", \"##aff\", \"##able\"]\n\n        Args:\n          text: A single token or whitespace separated tokens. This should have\n            already been passed through `BasicTokenizer`.\n\n        Returns:\n          A list of wordpiece tokens.\n        \"\"\"", "\n", "\n", "output_tokens", "=", "[", "]", "\n", "for", "token", "in", "whitespace_tokenize", "(", "text", ")", ":", "\n", "            ", "chars", "=", "list", "(", "token", ")", "\n", "if", "len", "(", "chars", ")", ">", "self", ".", "max_input_chars_per_word", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "continue", "\n", "\n", "", "is_bad", "=", "False", "\n", "start", "=", "0", "\n", "sub_tokens", "=", "[", "]", "\n", "while", "start", "<", "len", "(", "chars", ")", ":", "\n", "                ", "end", "=", "len", "(", "chars", ")", "\n", "cur_substr", "=", "None", "\n", "while", "start", "<", "end", ":", "\n", "                    ", "substr", "=", "\"\"", ".", "join", "(", "chars", "[", "start", ":", "end", "]", ")", "\n", "if", "start", ">", "0", ":", "\n", "                        ", "substr", "=", "\"##\"", "+", "substr", "\n", "", "if", "substr", "in", "self", ".", "vocab", ":", "\n", "                        ", "cur_substr", "=", "substr", "\n", "break", "\n", "", "end", "-=", "1", "\n", "", "if", "cur_substr", "is", "None", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "sub_tokens", ".", "append", "(", "cur_substr", ")", "\n", "start", "=", "end", "\n", "\n", "", "if", "is_bad", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "", "else", ":", "\n", "                ", "output_tokens", ".", "extend", "(", "sub_tokens", ")", "\n", "", "", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.load_vocab": [[50, 63], ["collections.OrderedDict", "io.open", "reader.readline", "token.strip.strip"], "function", ["None"], ["def", "load_vocab", "(", "vocab_file", ")", ":", "\n", "    ", "\"\"\"Loads a vocabulary file into a dictionary.\"\"\"", "\n", "vocab", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "index", "=", "0", "\n", "with", "open", "(", "vocab_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "token", "=", "reader", ".", "readline", "(", ")", "\n", "if", "not", "token", ":", "\n", "                ", "break", "\n", "", "token", "=", "token", ".", "strip", "(", ")", "\n", "vocab", "[", "token", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization.whitespace_tokenize": [[65, 72], ["text.strip.strip", "text.strip.split"], "function", ["None"], ["", "def", "whitespace_tokenize", "(", "text", ")", ":", "\n", "    ", "\"\"\"Runs basic whitespace cleaning and splitting on a peice of text.\"\"\"", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "        ", "return", "[", "]", "\n", "", "tokens", "=", "text", ".", "split", "(", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization._is_whitespace": [[334, 344], ["unicodedata.category"], "function", ["None"], ["", "", "def", "_is_whitespace", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a whitespace character.\"\"\"", "\n", "# \\t, \\n, and \\r are technically contorl characters but we treat them", "\n", "# as whitespace since they are generally considered as such.", "\n", "if", "char", "==", "\" \"", "or", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Zs\"", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization._is_control": [[346, 356], ["unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_control", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a control character.\"\"\"", "\n", "# These are technically control characters but we count them as whitespace", "\n", "# characters.", "\n", "if", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "False", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"C\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization._is_punctuation": [[358, 372], ["ord", "unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_punctuation", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a punctuation character.\"\"\"", "\n", "cp", "=", "ord", "(", "char", ")", "\n", "# We treat all non-letter/number ASCII as punctuation.", "\n", "# Characters such as \"^\", \"$\", and \"`\" are not in the Unicode", "\n", "# Punctuation class but we treat them as punctuation anyways, for", "\n", "# consistency.", "\n", "if", "(", "(", "cp", ">=", "33", "and", "cp", "<=", "47", ")", "or", "(", "cp", ">=", "58", "and", "cp", "<=", "64", ")", "or", "\n", "(", "cp", ">=", "91", "and", "cp", "<=", "96", ")", "or", "(", "cp", ">=", "123", "and", "cp", "<=", "126", ")", ")", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"P\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.__main__.main": [[2, 82], ["print", "len", "len", "len", "print", "sys.argv.pop", "sys.argv.pop", "sys.argv.pop", "convert_tf_checkpoint_to_pytorch", "convert_openai_checkpoint_to_pytorch", "print", "len", "convert_transfo_xl_checkpoint_to_pytorch", "convert_gpt2_checkpoint_to_pytorch", "sys.argv[].lower", "len", "len", "print", "print"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.convert_openai_checkpoint_to_pytorch.convert_openai_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.convert_transfo_xl_checkpoint_to_pytorch.convert_transfo_xl_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.convert_gpt2_checkpoint_to_pytorch.convert_gpt2_checkpoint_to_pytorch"], ["def", "main", "(", ")", ":", "\n", "    ", "import", "sys", "\n", "if", "(", "len", "(", "sys", ".", "argv", ")", "!=", "4", "and", "len", "(", "sys", ".", "argv", ")", "!=", "5", ")", "or", "sys", ".", "argv", "[", "1", "]", "not", "in", "[", "\n", "\"convert_tf_checkpoint_to_pytorch\"", ",", "\n", "\"convert_openai_checkpoint\"", ",", "\n", "\"convert_transfo_xl_checkpoint\"", ",", "\n", "\"convert_gpt2_checkpoint\"", ",", "\n", "]", ":", "\n", "        ", "print", "(", "\n", "\"Should be used as one of: \\n\"", "\n", "\">> `pytorch_pretrained_bert convert_tf_checkpoint_to_pytorch TF_CHECKPOINT TF_CONFIG PYTORCH_DUMP_OUTPUT`, \\n\"", "\n", "\">> `pytorch_pretrained_bert convert_openai_checkpoint OPENAI_GPT_CHECKPOINT_FOLDER_PATH PYTORCH_DUMP_OUTPUT [OPENAI_GPT_CONFIG]`, \\n\"", "\n", "\">> `pytorch_pretrained_bert convert_transfo_xl_checkpoint TF_CHECKPOINT_OR_DATASET PYTORCH_DUMP_OUTPUT [TF_CONFIG]` or \\n\"", "\n", "\">> `pytorch_pretrained_bert convert_gpt2_checkpoint TF_CHECKPOINT PYTORCH_DUMP_OUTPUT [GPT2_CONFIG]`\"", ")", "\n", "", "else", ":", "\n", "        ", "if", "sys", ".", "argv", "[", "1", "]", "==", "\"convert_tf_checkpoint_to_pytorch\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", ".", "convert_tf_checkpoint_to_pytorch", "import", "convert_tf_checkpoint_to_pytorch", "\n", "", "except", "ImportError", ":", "\n", "                ", "print", "(", "\"pytorch_pretrained_bert can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "\n", "", "if", "len", "(", "sys", ".", "argv", ")", "!=", "5", ":", "\n", "# pylint: disable=line-too-long", "\n", "                ", "print", "(", "\"Should be used as `pytorch_pretrained_bert convert_tf_checkpoint_to_pytorch TF_CHECKPOINT TF_CONFIG PYTORCH_DUMP_OUTPUT`\"", ")", "\n", "", "else", ":", "\n", "                ", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", ".", "pop", "(", ")", "\n", "TF_CONFIG", "=", "sys", ".", "argv", ".", "pop", "(", ")", "\n", "TF_CHECKPOINT", "=", "sys", ".", "argv", ".", "pop", "(", ")", "\n", "convert_tf_checkpoint_to_pytorch", "(", "TF_CHECKPOINT", ",", "TF_CONFIG", ",", "PYTORCH_DUMP_OUTPUT", ")", "\n", "", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "\"convert_openai_checkpoint\"", ":", "\n", "            ", "from", ".", "convert_openai_checkpoint_to_pytorch", "import", "convert_openai_checkpoint_to_pytorch", "\n", "OPENAI_GPT_CHECKPOINT_FOLDER_PATH", "=", "sys", ".", "argv", "[", "2", "]", "\n", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", "[", "3", "]", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "5", ":", "\n", "                ", "OPENAI_GPT_CONFIG", "=", "sys", ".", "argv", "[", "4", "]", "\n", "", "else", ":", "\n", "                ", "OPENAI_GPT_CONFIG", "=", "\"\"", "\n", "", "convert_openai_checkpoint_to_pytorch", "(", "OPENAI_GPT_CHECKPOINT_FOLDER_PATH", ",", "\n", "OPENAI_GPT_CONFIG", ",", "\n", "PYTORCH_DUMP_OUTPUT", ")", "\n", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "\"convert_transfo_xl_checkpoint\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", ".", "convert_transfo_xl_checkpoint_to_pytorch", "import", "convert_transfo_xl_checkpoint_to_pytorch", "\n", "", "except", "ImportError", ":", "\n", "                ", "print", "(", "\"pytorch_pretrained_bert can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "\n", "", "if", "'ckpt'", "in", "sys", ".", "argv", "[", "2", "]", ".", "lower", "(", ")", ":", "\n", "                ", "TF_CHECKPOINT", "=", "sys", ".", "argv", "[", "2", "]", "\n", "TF_DATASET_FILE", "=", "\"\"", "\n", "", "else", ":", "\n", "                ", "TF_DATASET_FILE", "=", "sys", ".", "argv", "[", "2", "]", "\n", "TF_CHECKPOINT", "=", "\"\"", "\n", "", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", "[", "3", "]", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "5", ":", "\n", "                ", "TF_CONFIG", "=", "sys", ".", "argv", "[", "4", "]", "\n", "", "else", ":", "\n", "                ", "TF_CONFIG", "=", "\"\"", "\n", "", "convert_transfo_xl_checkpoint_to_pytorch", "(", "TF_CHECKPOINT", ",", "TF_CONFIG", ",", "PYTORCH_DUMP_OUTPUT", ",", "TF_DATASET_FILE", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "from", ".", "convert_gpt2_checkpoint_to_pytorch", "import", "convert_gpt2_checkpoint_to_pytorch", "\n", "", "except", "ImportError", ":", "\n", "                ", "print", "(", "\"pytorch_pretrained_bert can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "\n", "", "TF_CHECKPOINT", "=", "sys", ".", "argv", "[", "2", "]", "\n", "PYTORCH_DUMP_OUTPUT", "=", "sys", ".", "argv", "[", "3", "]", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "5", ":", "\n", "                ", "TF_CONFIG", "=", "sys", ".", "argv", "[", "4", "]", "\n", "", "else", ":", "\n", "                ", "TF_CONFIG", "=", "\"\"", "\n", "", "convert_gpt2_checkpoint_to_pytorch", "(", "TF_CHECKPOINT", ",", "TF_CONFIG", ",", "PYTORCH_DUMP_OUTPUT", ")", "\n", "", "", "", "if", "__name__", "==", "'__main__'", ":", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.convert_gpt2_checkpoint_to_pytorch.convert_gpt2_checkpoint_to_pytorch": [[30, 49], ["external.pytorch_pretrained_bert.modeling_gpt2.GPT2Model", "external.pytorch_pretrained_bert.modeling_gpt2.load_tf_weights_in_gpt2", "print", "torch.save", "print", "external.pytorch_pretrained_bert.modeling_gpt2.GPT2Config", "external.pytorch_pretrained_bert.modeling_gpt2.GPT2Config", "external.pytorch_pretrained_bert.modeling_gpt2.GPT2Model.state_dict", "io.open", "f.write", "external.pytorch_pretrained_bert.modeling_gpt2.GPT2Config.to_json_string"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_gpt2.load_tf_weights_in_gpt2", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string"], ["def", "convert_gpt2_checkpoint_to_pytorch", "(", "gpt2_checkpoint_path", ",", "gpt2_config_file", ",", "pytorch_dump_folder_path", ")", ":", "\n", "# Construct model", "\n", "    ", "if", "gpt2_config_file", "==", "\"\"", ":", "\n", "        ", "config", "=", "GPT2Config", "(", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "GPT2Config", "(", "gpt2_config_file", ")", "\n", "", "model", "=", "GPT2Model", "(", "config", ")", "\n", "\n", "# Load weights from numpy", "\n", "load_tf_weights_in_gpt2", "(", "model", ",", "gpt2_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "WEIGHTS_NAME", "\n", "pytorch_config_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "CONFIG_NAME", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_weights_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.convert_transfo_xl_checkpoint_to_pytorch.convert_transfo_xl_checkpoint_to_pytorch": [[47, 90], ["print", "torch.save", "corpus_dict_no_vocab.pop", "print", "torch.save", "os.path.abspath", "os.path.abspath", "print", "print", "external.pytorch_pretrained_bert.TransfoXLLMHeadModel", "external.pytorch_pretrained_bert.load_tf_weights_in_transfo_xl", "os.path.join", "os.path.join", "print", "torch.save", "print", "io.open", "pickle.load", "external.pytorch_pretrained_bert.TransfoXLConfig", "external.pytorch_pretrained_bert.TransfoXLConfig", "external.pytorch_pretrained_bert.load_tf_weights_in_transfo_xl.state_dict", "io.open", "f.write", "str", "os.path.abspath", "os.path.abspath", "external.pytorch_pretrained_bert.TransfoXLConfig.to_json_string"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_transfo_xl.load_tf_weights_in_transfo_xl", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string"], ["def", "convert_transfo_xl_checkpoint_to_pytorch", "(", "tf_checkpoint_path", ",", "\n", "transfo_xl_config_file", ",", "\n", "pytorch_dump_folder_path", ",", "\n", "transfo_xl_dataset_file", ")", ":", "\n", "    ", "if", "transfo_xl_dataset_file", ":", "\n", "# Convert a pre-processed corpus (see original TensorFlow repo)", "\n", "        ", "with", "open", "(", "transfo_xl_dataset_file", ",", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "corpus", "=", "pickle", ".", "load", "(", "fp", ",", "encoding", "=", "\"latin1\"", ")", "\n", "# Save vocabulary and dataset cache as Dictionaries (should be better than pickles for the long-term)", "\n", "", "pytorch_vocab_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "VOCAB_NAME", "\n", "print", "(", "\"Save vocabulary to {}\"", ".", "format", "(", "pytorch_vocab_dump_path", ")", ")", "\n", "corpus_vocab_dict", "=", "corpus", ".", "vocab", ".", "__dict__", "\n", "torch", ".", "save", "(", "corpus_vocab_dict", ",", "pytorch_vocab_dump_path", ")", "\n", "\n", "corpus_dict_no_vocab", "=", "corpus", ".", "__dict__", "\n", "corpus_dict_no_vocab", ".", "pop", "(", "'vocab'", ",", "None", ")", "\n", "pytorch_dataset_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "CORPUS_NAME", "\n", "print", "(", "\"Save dataset to {}\"", ".", "format", "(", "pytorch_dataset_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "corpus_dict_no_vocab", ",", "pytorch_dataset_dump_path", ")", "\n", "\n", "", "if", "tf_checkpoint_path", ":", "\n", "# Convert a pre-trained TensorFlow model", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "abspath", "(", "transfo_xl_config_file", ")", "\n", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "\n", "print", "(", "\"Converting Transformer XL checkpoint from {} with config at {}\"", ".", "format", "(", "tf_path", ",", "config_path", ")", ")", "\n", "# Initialise PyTorch model", "\n", "if", "transfo_xl_config_file", "==", "\"\"", ":", "\n", "            ", "config", "=", "TransfoXLConfig", "(", ")", "\n", "", "else", ":", "\n", "            ", "config", "=", "TransfoXLConfig", "(", "transfo_xl_config_file", ")", "\n", "", "print", "(", "\"Building PyTorch model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "model", "=", "TransfoXLLMHeadModel", "(", "config", ")", "\n", "\n", "model", "=", "load_tf_weights_in_transfo_xl", "(", "model", ",", "config", ",", "tf_path", ")", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "os", ".", "path", ".", "join", "(", "pytorch_dump_folder_path", ",", "WEIGHTS_NAME", ")", "\n", "pytorch_config_dump_path", "=", "os", ".", "path", ".", "join", "(", "pytorch_dump_folder_path", ",", "CONFIG_NAME", ")", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "pytorch_weights_dump_path", ")", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "pytorch_config_dump_path", ")", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.__init__": [[131, 192], ["isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size_or_config_json_file", "=", "40478", ",", "\n", "n_special", "=", "0", ",", "\n", "n_positions", "=", "512", ",", "\n", "n_ctx", "=", "512", ",", "\n", "n_embd", "=", "768", ",", "\n", "n_layer", "=", "12", ",", "\n", "n_head", "=", "12", ",", "\n", "afn", "=", "\"gelu\"", ",", "\n", "resid_pdrop", "=", "0.1", ",", "\n", "embd_pdrop", "=", "0.1", ",", "\n", "attn_pdrop", "=", "0.1", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs OpenAIGPTConfig.\n\n        Args:\n            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `OpenAIGPTModel` or a configuration json file.\n            n_special: The number of special tokens to learn during fine-tuning ('[SEP]', '[CLF]', ...)\n            n_positions: Number of positional embeddings.\n            n_ctx: Size of the causal mask (usually same as n_positions).\n            n_embd: Dimensionality of the embeddings and hidden states.\n            n_layer: Number of hidden layers in the Transformer encoder.\n            n_head: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            afn: The non-linear activation function (function or string) in the\n                encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.\n            resid_pdrop: The dropout probabilitiy for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            attn_pdrop: The dropout ratio for the attention\n                probabilities.\n            embd_pdrop: The dropout ratio for the embeddings.\n            layer_norm_epsilon: epsilon to use in the layer norm layers\n            initializer_range: The sttdev of the truncated_normal_initializer for\n                initializing all weight matrices.\n        \"\"\"", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "n_special", "=", "n_special", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "n_embd", "=", "n_embd", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "afn", "=", "afn", "\n", "self", ".", "resid_pdrop", "=", "resid_pdrop", "\n", "self", ".", "embd_pdrop", "=", "embd_pdrop", "\n", "self", ".", "attn_pdrop", "=", "attn_pdrop", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.total_tokens_embeddings": [[195, 198], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "total_tokens_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "vocab_size", "+", "self", ".", "n_special", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_dict": [[199, 206], ["modeling_openai.OpenAIGPTConfig", "json_object.items"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `OpenAIGPTConfig` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "OpenAIGPTConfig", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_json_file": [[207, 213], ["cls.from_dict", "io.open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `OpenAIGPTConfig` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.__repr__": [[214, 216], ["str", "modeling_openai.OpenAIGPTConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_dict": [[217, 221], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_json_string": [[222, 225], ["json.dumps", "modeling_openai.OpenAIGPTConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Conv1D.__init__": [[228, 239], ["torch.Module.__init__", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.init.normal_", "torch.init.normal_", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "rf", ",", "nx", ")", ":", "\n", "        ", "super", "(", "Conv1D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rf", "=", "rf", "\n", "self", ".", "nf", "=", "nf", "\n", "if", "rf", "==", "1", ":", "# faster 1x1 conv", "\n", "            ", "w", "=", "torch", ".", "empty", "(", "nx", ",", "nf", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "w", ",", "std", "=", "0.02", ")", "\n", "self", ".", "weight", "=", "Parameter", "(", "w", ")", "\n", "self", ".", "bias", "=", "Parameter", "(", "torch", ".", "zeros", "(", "nf", ")", ")", "\n", "", "else", ":", "# was used to train LM", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Conv1D.forward": [[240, 248], ["torch.addmm", "torch.addmm", "torch.addmm", "torch.addmm", "x.view.view.view", "x.view.view.view", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "rf", "==", "1", ":", "\n", "            ", "size_out", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "nf", ",", ")", "\n", "x", "=", "torch", ".", "addmm", "(", "self", ".", "bias", ",", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ",", "self", ".", "weight", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "size_out", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Attention.__init__": [[251, 264], ["torch.Module.__init__", "modeling_openai.Attention.register_buffer", "modeling_openai.Conv1D", "modeling_openai.Conv1D", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "register_buffer", "(", "\"bias\"", ",", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "n_ctx", ",", "n_ctx", ")", ")", ".", "view", "(", "1", ",", "1", ",", "n_ctx", ",", "n_ctx", ")", ")", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "c_attn", "=", "Conv1D", "(", "n_state", "*", "3", ",", "1", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "n_state", ",", "1", ",", "nx", ")", "\n", "self", ".", "attn_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Attention._attn": [[265, 277], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "modeling_openai.Attention.attn_dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.Softmax", "torch.Softmax", "math.sqrt", "v.size", "modeling_openai.Attention.size", "modeling_openai.Attention.size"], "methods", ["None"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "math", ".", "sqrt", "(", "v", ".", "size", "(", "-", "1", ")", ")", "\n", "# w = w * self.bias + -1e9 * (1 - self.bias)  # TF implem method: mask_attn_weights", "\n", "# XD: self.b may be larger than w, so we need to crop it", "\n", "", "b", "=", "self", ".", "bias", "[", ":", ",", ":", ",", ":", "w", ".", "size", "(", "-", "2", ")", ",", ":", "w", ".", "size", "(", "-", "1", ")", "]", "\n", "w", "=", "w", "*", "b", "+", "-", "1e9", "*", "(", "1", "-", "b", ")", "\n", "\n", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ")", "\n", "return", "torch", ".", "matmul", "(", "w", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Attention.merge_heads": [[278, 282], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["None"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "x", ".", "size", "(", "-", "2", ")", "*", "x", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct merge_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Attention.split_heads": [[283, 290], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "split_heads", "(", "self", ",", "x", ",", "k", "=", "False", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "n_head", ",", "x", ".", "size", "(", "-", "1", ")", "//", "self", ".", "n_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct split_states", "\n", "if", "k", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Attention.forward": [[291, 302], ["modeling_openai.Attention.c_attn", "modeling_openai.Attention.split", "modeling_openai.Attention.split_heads", "modeling_openai.Attention.split_heads", "modeling_openai.Attention.split_heads", "modeling_openai.Attention._attn", "modeling_openai.Attention.merge_heads", "modeling_openai.Attention.c_proj", "modeling_openai.Attention.resid_dropout"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Attention._attn", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Attention.merge_heads"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "x", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ",", "k", "=", "True", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "a", "=", "self", ".", "_attn", "(", "query", ",", "key", ",", "value", ")", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ")", "\n", "return", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.MLP.__init__": [[305, 312], ["torch.Module.__init__", "modeling_openai.Conv1D", "modeling_openai.Conv1D", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ")", ":", "# in MLP: n_state=3072 (4 * n_embd)", "\n", "        ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "Conv1D", "(", "n_state", ",", "1", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "nx", ",", "1", ",", "n_state", ")", "\n", "self", ".", "act", "=", "ACT_FNS", "[", "config", ".", "afn", "]", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.MLP.forward": [[313, 317], ["modeling_openai.MLP.act", "modeling_openai.MLP.c_proj", "modeling_openai.MLP.dropout", "modeling_openai.MLP.c_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "return", "self", ".", "dropout", "(", "h2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Block.__init__": [[320, 327], ["torch.Module.__init__", "modeling_openai.Attention", "modeling.BertLayerNorm", "modeling_openai.MLP", "modeling.BertLayerNorm"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "attn", "=", "Attention", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "self", ".", "ln_1", "=", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "4", "*", "nx", ",", "config", ")", "\n", "self", ".", "ln_2", "=", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.Block.forward": [[328, 334], ["modeling_openai.Block.attn", "modeling_openai.Block.ln_1", "modeling_openai.Block.mlp", "modeling_openai.Block.ln_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "a", "=", "self", ".", "attn", "(", "x", ")", "\n", "n", "=", "self", ".", "ln_1", "(", "x", "+", "a", ")", "\n", "m", "=", "self", ".", "mlp", "(", "n", ")", "\n", "h", "=", "self", ".", "ln_2", "(", "n", "+", "m", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.__init__": [[339, 343], ["torch.Module.__init__", "modeling_openai.OpenAIGPTLMHead.set_embeddings_weights"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.set_embeddings_weights"], ["def", "__init__", "(", "self", ",", "model_embeddings_weights", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_embd", "=", "config", ".", "n_embd", "\n", "self", ".", "set_embeddings_weights", "(", "model_embeddings_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.set_embeddings_weights": [[344, 348], ["torch.Linear", "torch.Linear"], "methods", ["None"], ["", "def", "set_embeddings_weights", "(", "self", ",", "model_embeddings_weights", ")", ":", "\n", "        ", "embed_shape", "=", "model_embeddings_weights", ".", "shape", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "embed_shape", "[", "1", "]", ",", "embed_shape", "[", "0", "]", ",", "bias", "=", "False", ")", "\n", "self", ".", "decoder", ".", "weight", "=", "model_embeddings_weights", "# Tied weights", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.forward": [[349, 354], ["modeling_openai.OpenAIGPTLMHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_state", ")", ":", "\n", "# Truncated Language modeling logits (we remove the last token)", "\n", "# h_trunc = h[:, :-1].contiguous().view(-1, self.n_embd)", "\n", "        ", "lm_logits", "=", "self", ".", "decoder", "(", "hidden_state", ")", "\n", "return", "lm_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTMultipleChoiceHead.__init__": [[359, 368], ["torch.Module.__init__", "torch.Dropout2d", "torch.Dropout2d", "torch.Linear", "torch.Linear", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTMultipleChoiceHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_embd", "=", "config", ".", "n_embd", "\n", "# self.multiple_choice_token = multiple_choice_token", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout2d", "(", "config", ".", "resid_pdrop", ")", "# To reproduce the noise_shape parameter of TF implementation", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "1", ")", "\n", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "linear", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "linear", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTMultipleChoiceHead.forward": [[369, 380], ["mc_token_ids.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand", "hidden_states.gather().squeeze", "modeling_openai.OpenAIGPTMultipleChoiceHead.linear().squeeze", "hidden_states.size", "mc_token_ids.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze", "hidden_states.gather", "modeling_openai.OpenAIGPTMultipleChoiceHead.linear", "mc_token_ids.unsqueeze().unsqueeze().expand.unsqueeze().unsqueeze().expand.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "mc_token_ids", ")", ":", "\n", "# Classification logits", "\n", "# hidden_state (bsz, num_choices, seq_length, hidden_size)", "\n", "# mc_token_ids (bsz, num_choices)", "\n", "        ", "mc_token_ids", "=", "mc_token_ids", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "-", "1", ",", "hidden_states", ".", "size", "(", "-", "1", ")", ")", "\n", "# (bsz, num_choices, 1, hidden_size)", "\n", "multiple_choice_h", "=", "hidden_states", ".", "gather", "(", "2", ",", "mc_token_ids", ")", ".", "squeeze", "(", "2", ")", "\n", "# (bsz, num_choices, hidden_size)", "\n", "multiple_choice_logits", "=", "self", ".", "linear", "(", "multiple_choice_h", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "# (bsz, num_choices)", "\n", "return", "multiple_choice_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTPreTrainedModel.__init__": [[387, 398], ["torch.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTPreTrainedModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "OpenAIGPTConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `OpenAIGPTConfig`. \"", "\n", "\"To create a model from a pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", ")", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTPreTrainedModel.init_weights": [[399, 411], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTPreTrainedModel.set_num_special_tokens": [[412, 414], ["None"], "methods", ["None"], ["", "", "def", "set_num_special_tokens", "(", "self", ",", "num_special_tokens", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTPreTrainedModel.from_pretrained": [[415, 534], ["modeling_openai.OpenAIGPTConfig.from_json_file", "logger.info", "cls", "torch.load.keys", "torch.load.keys", "zip", "getattr", "torch.load.copy", "torch.load.copy", "modeling_openai.OpenAIGPTPreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTConfig.from_json_file"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "\n", "cls", ",", "pretrained_model_name_or_path", ",", "num_special_tokens", "=", "None", ",", "state_dict", "=", "None", ",", "cache_dir", "=", "None", ",", "from_tf", "=", "False", ",", "*", "inputs", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a OpenAIGPTPreTrainedModel from a pre-trained model file or a pytorch state dict.\n        Download and cache the pre-trained model file if needed.\n\n        Params:\n            pretrained_model_name_or_path: either:\n                - a str with the name of a pre-trained model to load selected in the list of:\n                    . `openai-gpt`\n                - a path or url to a pretrained model archive containing:\n                    . `openai_gpt_config.json` a configuration file for the model\n                    . `pytorch_model.bin` a PyTorch dump of a OpenAIGPTModel instance\n                - a path or url to a pretrained model archive containing:\n                    . `bert_config.json` a configuration file for the model\n                    . a series of NumPy files containing OpenAI TensorFlow trained weights\n            from_tf: should we load the weights from a locally saved TensorFlow checkpoint\n            cache_dir: an optional path to a folder in which the pre-trained models will be cached.\n            state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of pre-trained models\n            *inputs, **kwargs: additional input for the specific Bert class\n                (ex: num_labels for BertForSequenceClassification)\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_MODEL_ARCHIVE_MAP", ":", "\n", "            ", "archive_file", "=", "PRETRAINED_MODEL_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "config_file", "=", "PRETRAINED_CONFIG_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "config_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CONFIG_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "resolved_config_file", "=", "cached_path", "(", "config_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} and {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\", \"", ".", "join", "(", "PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "pretrained_model_name_or_path", ",", "\n", "archive_file", ",", "config_file", "\n", ")", "\n", ")", "\n", "return", "None", "\n", "", "if", "resolved_archive_file", "==", "archive_file", "and", "resolved_config_file", "==", "config_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading configuration file {}\"", ".", "format", "(", "config_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading configuration file {} from cache at {}\"", ".", "format", "(", "\n", "config_file", ",", "resolved_config_file", ")", ")", "\n", "# Load config", "\n", "", "config", "=", "OpenAIGPTConfig", ".", "from_json_file", "(", "resolved_config_file", ")", "\n", "logger", ".", "info", "(", "\"Model config {}\"", ".", "format", "(", "config", ")", ")", "\n", "# Instantiate model.", "\n", "model", "=", "cls", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "'cpu'", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "None", ")", "\n", "", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint (stored as NumPy array)", "\n", "            ", "return", "load_tf_weights_in_openai_gpt", "(", "model", ",", "resolved_archive_file", ")", "\n", "\n", "", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "new_key", "=", "None", "\n", "if", "key", ".", "endswith", "(", "\".g\"", ")", ":", "\n", "                ", "new_key", "=", "key", "[", ":", "-", "2", "]", "+", "\".weight\"", "\n", "", "elif", "key", ".", "endswith", "(", "\".b\"", ")", ":", "\n", "                ", "new_key", "=", "key", "[", ":", "-", "2", "]", "+", "\".bias\"", "\n", "", "elif", "key", ".", "endswith", "(", "\".w\"", ")", ":", "\n", "                ", "new_key", "=", "key", "[", ":", "-", "2", "]", "+", "\".weight\"", "\n", "", "if", "new_key", ":", "\n", "                ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "            ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "\"_metadata\"", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "\"\"", ")", ":", "\n", "            ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", "\n", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                ", "if", "child", "is", "not", "None", ":", "\n", "                    ", "load", "(", "child", ",", "prefix", "+", "name", "+", "\".\"", ")", "\n", "\n", "", "", "", "start_model", "=", "model", "\n", "if", "hasattr", "(", "model", ",", "\"transformer\"", ")", "and", "all", "(", "not", "s", ".", "startswith", "(", "'transformer.'", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "start_model", "=", "model", ".", "transformer", "\n", "", "load", "(", "start_model", ",", "prefix", "=", "\"\"", ")", "\n", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", "\n", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", "\n", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Error(s) in loading state_dict for {}:\\n\\t{}\"", ".", "format", "(", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", "\n", ")", "\n", "\n", "# Add additional embeddings for special tokens if needed", "\n", "# This step also make sure we are still sharing the output and input embeddings after loading weights", "\n", "", "model", ".", "set_num_special_tokens", "(", "num_special_tokens", "if", "num_special_tokens", "is", "not", "None", "else", "config", ".", "n_special", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTModel.__init__": [[587, 597], ["modeling_openai.OpenAIGPTPreTrainedModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "modeling_openai.Block", "torch.ModuleList", "torch.ModuleList", "modeling_openai.OpenAIGPTModel.apply", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "num_tokens", "=", "config", ".", "vocab_size", "+", "config", ".", "n_special", "\n", "self", ".", "tokens_embed", "=", "nn", ".", "Embedding", "(", "num_tokens", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "positions_embed", "=", "nn", ".", "Embedding", "(", "config", ".", "n_positions", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "block", "=", "Block", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "block", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "# nn.init.normal_(self.embed.weight, std=0.02)", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTModel.set_num_special_tokens": [[599, 613], ["torch.Embedding", "torch.Embedding", "modeling_openai.OpenAIGPTModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.BaseModel.init_weights"], ["", "def", "set_num_special_tokens", "(", "self", ",", "num_special_tokens", ")", ":", "\n", "        ", "\" Update input embeddings with new embedding matrice if needed \"", "\n", "if", "self", ".", "config", ".", "n_special", "==", "num_special_tokens", ":", "\n", "            ", "return", "\n", "# Update config", "\n", "", "self", ".", "config", ".", "n_special", "=", "num_special_tokens", "\n", "# # Build new embeddings and initialize", "\n", "old_embed", "=", "self", ".", "tokens_embed", "\n", "self", ".", "tokens_embed", "=", "nn", ".", "Embedding", "(", "self", ".", "config", ".", "total_tokens_embeddings", ",", "self", ".", "config", ".", "n_embd", ")", "\n", "# Initialize all new embeddings (in particular the special tokens)", "\n", "self", ".", "init_weights", "(", "self", ".", "tokens_embed", ")", "\n", "# Copy word and positional embeddings from the previous weights", "\n", "self", ".", "tokens_embed", ".", "weight", ".", "data", "[", ":", "self", ".", "config", ".", "vocab_size", ",", ":", "]", "=", "old_embed", ".", "weight", ".", "data", "[", ":", "self", ".", "config", ".", "vocab_size", ",", ":", "]", "\n", "self", ".", "tokens_embed", ".", "weight", ".", "data", "[", "-", "self", ".", "config", ".", "n_positions", ":", ",", ":", "]", "=", "old_embed", ".", "weight", ".", "data", "[", "-", "self", ".", "config", ".", "n_positions", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTModel.forward": [[614, 641], ["input_ids.view.view.size", "input_ids.view.view.view", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.view", "modeling_openai.OpenAIGPTModel.tokens_embed", "modeling_openai.OpenAIGPTModel.positions_embed", "block.view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "input_ids.view.view.size", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.size", "token_type_ids.view.view.view", "modeling_openai.OpenAIGPTModel.tokens_embed", "block", "input_ids.view.view.size", "token_type_ids.view.view.size", "block.size", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ")", ":", "\n", "        ", "if", "position_ids", "is", "None", ":", "\n", "# This was used when we had a single embedding matrice from position and token embeddings", "\n", "# start = self.config.vocab_size + self.config.n_special", "\n", "# end = start + input_ids.size(-1)", "\n", "# position_ids = torch.arange(start, end, dtype=torch.long, device=input_ids.device)", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "input_ids", ".", "size", "(", "-", "1", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "\n", "", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "inputs_embeds", "=", "self", ".", "tokens_embed", "(", "input_ids", ")", "\n", "position_embeds", "=", "self", ".", "positions_embed", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "token_type_embeds", "=", "self", ".", "tokens_embed", "(", "token_type_ids", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "# Add the position information to the input embeddings", "\n", "# h = e.sum(dim=2)", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "for", "block", "in", "self", ".", "h", ":", "\n", "            ", "hidden_states", "=", "block", "(", "hidden_states", ")", "\n", "", "output_shape", "=", "input_shape", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "hidden_states", ".", "view", "(", "*", "output_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHeadModel.__init__": [[699, 704], ["modeling_openai.OpenAIGPTPreTrainedModel.__init__", "modeling_openai.OpenAIGPTModel", "modeling_openai.OpenAIGPTLMHead", "modeling_openai.OpenAIGPTLMHeadModel.apply"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "OpenAIGPTModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "OpenAIGPTLMHead", "(", "self", ".", "transformer", ".", "tokens_embed", ".", "weight", ",", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHeadModel.set_num_special_tokens": [[705, 711], ["modeling_openai.OpenAIGPTLMHeadModel.transformer.set_num_special_tokens", "modeling_openai.OpenAIGPTLMHeadModel.lm_head.set_embeddings_weights"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTDoubleHeadsModel.set_num_special_tokens", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.set_embeddings_weights"], ["", "def", "set_num_special_tokens", "(", "self", ",", "num_special_tokens", ")", ":", "\n", "        ", "\"\"\" Update input and output embeddings with new embedding matrice\n            Make sure we are sharing the embeddings\n        \"\"\"", "\n", "self", ".", "transformer", ".", "set_num_special_tokens", "(", "num_special_tokens", ")", "\n", "self", ".", "lm_head", ".", "set_embeddings_weights", "(", "self", ".", "transformer", ".", "tokens_embed", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHeadModel.forward": [[712, 720], ["modeling_openai.OpenAIGPTLMHeadModel.transformer", "modeling_openai.OpenAIGPTLMHeadModel.lm_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_openai.OpenAIGPTLMHeadModel.view", "lm_labels.view", "modeling_openai.OpenAIGPTLMHeadModel.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "lm_labels", "=", "None", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transformer", "(", "input_ids", ",", "position_ids", ",", "token_type_ids", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "size", "(", "-", "1", ")", ")", ",", "lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "loss", "\n", "", "return", "lm_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTDoubleHeadsModel.__init__": [[783, 789], ["modeling_openai.OpenAIGPTPreTrainedModel.__init__", "modeling_openai.OpenAIGPTModel", "modeling_openai.OpenAIGPTLMHead", "modeling_openai.OpenAIGPTMultipleChoiceHead", "modeling_openai.OpenAIGPTDoubleHeadsModel.apply"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTDoubleHeadsModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "OpenAIGPTModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "OpenAIGPTLMHead", "(", "self", ".", "transformer", ".", "tokens_embed", ".", "weight", ",", "config", ")", "\n", "self", ".", "multiple_choice_head", "=", "OpenAIGPTMultipleChoiceHead", "(", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTDoubleHeadsModel.set_num_special_tokens": [[790, 796], ["modeling_openai.OpenAIGPTDoubleHeadsModel.transformer.set_num_special_tokens", "modeling_openai.OpenAIGPTDoubleHeadsModel.lm_head.set_embeddings_weights"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTDoubleHeadsModel.set_num_special_tokens", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTLMHead.set_embeddings_weights"], ["", "def", "set_num_special_tokens", "(", "self", ",", "num_special_tokens", ")", ":", "\n", "        ", "\"\"\" Update input and output embeddings with new embedding matrice\n            Make sure we are sharing the embeddings\n        \"\"\"", "\n", "self", ".", "transformer", ".", "set_num_special_tokens", "(", "num_special_tokens", ")", "\n", "self", ".", "lm_head", ".", "set_embeddings_weights", "(", "self", ".", "transformer", ".", "tokens_embed", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.OpenAIGPTDoubleHeadsModel.forward": [[797, 811], ["modeling_openai.OpenAIGPTDoubleHeadsModel.transformer", "modeling_openai.OpenAIGPTDoubleHeadsModel.lm_head", "modeling_openai.OpenAIGPTDoubleHeadsModel.multiple_choice_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "losses.append", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "losses.append", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_openai.OpenAIGPTDoubleHeadsModel.view", "lm_labels.view", "modeling_openai.OpenAIGPTDoubleHeadsModel.view", "mc_labels.view", "modeling_openai.OpenAIGPTDoubleHeadsModel.size", "modeling_openai.OpenAIGPTDoubleHeadsModel.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "mc_token_ids", ",", "lm_labels", "=", "None", ",", "mc_labels", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transformer", "(", "input_ids", ",", "position_ids", ",", "token_type_ids", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "hidden_states", ",", "mc_token_ids", ")", "\n", "losses", "=", "[", "]", "\n", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "losses", ".", "append", "(", "loss_fct", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "size", "(", "-", "1", ")", ")", ",", "lm_labels", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "", "if", "mc_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "losses", ".", "append", "(", "loss_fct", "(", "mc_logits", ".", "view", "(", "-", "1", ",", "mc_logits", ".", "size", "(", "-", "1", ")", ")", ",", "mc_labels", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "", "if", "losses", ":", "\n", "            ", "return", "losses", "\n", "", "return", "lm_logits", ",", "mc_logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.load_tf_weights_in_openai_gpt": [[46, 114], ["print", "json.load", "json.load", "np.cumsum", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "json.load.pop", "init_params.pop", "init_params.pop", "zip", "io.open", "io.open", "np.load", "np.split", "param.reshape", "arr.squeeze", "name.split.split", "print", "torch.from_numpy", "torch.from_numpy", "np.prod", "range", "np.concatenate", "zip", "re.fullmatch", "re.split", "getattr", "len", "int", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.multi_task_dataloader.prod"], ["def", "load_tf_weights_in_openai_gpt", "(", "model", ",", "openai_checkpoint_folder_path", ")", ":", "\n", "    ", "\"\"\" Load tf pre-trained weights in a pytorch model (from NumPy arrays here)\n    \"\"\"", "\n", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "print", "(", "\"Loading weights...\"", ")", "\n", "names", "=", "json", ".", "load", "(", "open", "(", "openai_checkpoint_folder_path", "+", "'/parameters_names.json'", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "shapes", "=", "json", ".", "load", "(", "open", "(", "openai_checkpoint_folder_path", "+", "'/params_shapes.json'", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", ")", "\n", "offsets", "=", "np", ".", "cumsum", "(", "[", "np", ".", "prod", "(", "shape", ")", "for", "shape", "in", "shapes", "]", ")", "\n", "init_params", "=", "[", "np", ".", "load", "(", "openai_checkpoint_folder_path", "+", "'/params_{}.npy'", ".", "format", "(", "n", ")", ")", "for", "n", "in", "range", "(", "10", ")", "]", "\n", "init_params", "=", "np", ".", "split", "(", "np", ".", "concatenate", "(", "init_params", ",", "0", ")", ",", "offsets", ")", "[", ":", "-", "1", "]", "\n", "init_params", "=", "[", "param", ".", "reshape", "(", "shape", ")", "for", "param", ",", "shape", "in", "zip", "(", "init_params", ",", "shapes", ")", "]", "\n", "\n", "# This was used when we had a single embedding matrix for positions and tokens", "\n", "# init_params[0] = np.concatenate([init_params[1], init_params[0]], 0)", "\n", "# del init_params[1]", "\n", "init_params", "=", "[", "arr", ".", "squeeze", "(", ")", "for", "arr", "in", "init_params", "]", "\n", "\n", "try", ":", "\n", "        ", "assert", "model", ".", "tokens_embed", ".", "weight", ".", "shape", "==", "init_params", "[", "1", "]", ".", "shape", "\n", "assert", "model", ".", "positions_embed", ".", "weight", ".", "shape", "==", "init_params", "[", "0", "]", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "        ", "e", ".", "args", "+=", "(", "model", ".", "tokens_embed", ".", "weight", ".", "shape", ",", "init_params", "[", "1", "]", ".", "shape", ")", "\n", "e", ".", "args", "+=", "(", "model", ".", "positions_embed", ".", "weight", ".", "shape", ",", "init_params", "[", "0", "]", ".", "shape", ")", "\n", "raise", "\n", "\n", "", "model", ".", "tokens_embed", ".", "weight", ".", "data", "=", "torch", ".", "from_numpy", "(", "init_params", "[", "1", "]", ")", "\n", "model", ".", "positions_embed", ".", "weight", ".", "data", "=", "torch", ".", "from_numpy", "(", "init_params", "[", "0", "]", ")", "\n", "names", ".", "pop", "(", "0", ")", "\n", "# Pop position and token embedding arrays", "\n", "init_params", ".", "pop", "(", "0", ")", "\n", "init_params", ".", "pop", "(", "0", ")", "\n", "\n", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "init_params", ")", ":", "# names[1:n_transfer], init_params[1:n_transfer]):", "\n", "        ", "name", "=", "name", "[", "6", ":", "]", "# skip \"model/\"", "\n", "assert", "name", "[", "-", "2", ":", "]", "==", "\":0\"", "\n", "name", "=", "name", "[", ":", "-", "2", "]", "\n", "name", "=", "name", ".", "split", "(", "'/'", ")", "\n", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r'[A-Za-z]+\\d+'", ",", "m_name", ")", ":", "\n", "                ", "l", "=", "re", ".", "split", "(", "r'(\\d+)'", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "l", "=", "[", "m_name", "]", "\n", "", "if", "l", "[", "0", "]", "==", "'g'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'b'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'bias'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'w'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "else", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "", "if", "len", "(", "l", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "print", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.gelu": [[116, 118], ["torch.tanh", "torch.tanh", "math.sqrt", "torch.pow", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.swish": [[120, 122], ["torch.sigmoid", "torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.optimization_openai.OpenAIAdam.__init__": [[45, 64], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "required", ",", "schedule", "=", "'warmup_linear'", ",", "warmup", "=", "-", "1", ",", "t_total", "=", "-", "1", ",", "\n", "b1", "=", "0.9", ",", "b2", "=", "0.999", ",", "e", "=", "1e-8", ",", "weight_decay", "=", "0", ",", "\n", "vector_l2", "=", "False", ",", "max_grad_norm", "=", "-", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "lr", "is", "not", "required", "and", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "schedule", "not", "in", "SCHEDULES", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid schedule parameter: {}\"", ".", "format", "(", "schedule", ")", ")", "\n", "", "if", "not", "0.0", "<=", "warmup", "<", "1.0", "and", "not", "warmup", "==", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\"", ".", "format", "(", "warmup", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b1", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b1 parameter: {}\"", ".", "format", "(", "b1", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b2", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b2 parameter: {}\"", ".", "format", "(", "b2", ")", ")", "\n", "", "if", "not", "e", ">=", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "e", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "schedule", "=", "schedule", ",", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "\n", "b1", "=", "b1", ",", "b2", "=", "b2", ",", "e", "=", "e", ",", "weight_decay", "=", "weight_decay", ",", "vector_l2", "=", "vector_l2", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "super", "(", "OpenAIAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.optimization_openai.OpenAIAdam.get_lr": [[65, 79], ["lr.append", "len", "schedule_fct"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "lr", "=", "[", "]", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "return", "[", "0", "]", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "", "lr", ".", "append", "(", "lr_scheduled", ")", "\n", "", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.optimization_openai.OpenAIAdam.step": [[80, 141], ["closure", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "exp_avg_sq.sqrt().add_", "p.data.addcdiv_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.nn.utils.clip_grad_norm_", "p.data.add_", "exp_avg.mul_", "exp_avg_sq.mul_", "exp_avg_sq.sqrt", "schedule_fct", "math.sqrt", "len", "p.size"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'b1'", "]", ",", "group", "[", "'b2'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# Add grad clipping", "\n", "if", "group", "[", "'max_grad_norm'", "]", ">", "0", ":", "\n", "                    ", "clip_grad_norm_", "(", "p", ",", "group", "[", "'max_grad_norm'", "]", ")", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'e'", "]", ")", "\n", "\n", "bias_correction1", "=", "1", "-", "beta1", "**", "state", "[", "'step'", "]", "\n", "bias_correction2", "=", "1", "-", "beta2", "**", "state", "[", "'step'", "]", "\n", "\n", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "\n", "", "step_size", "=", "lr_scheduled", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "bias_correction1", "\n", "\n", "p", ".", "data", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "\n", "# Add weight decay at the end (fixed version)", "\n", "if", "(", "len", "(", "p", ".", "size", "(", ")", ")", ">", "1", "or", "group", "[", "'vector_l2'", "]", ")", "and", "group", "[", "'weight_decay'", "]", ">", "0", ":", "\n", "                    ", "p", ".", "data", ".", "add_", "(", "-", "lr_scheduled", "*", "group", "[", "'weight_decay'", "]", ",", "p", ".", "data", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.optimization_openai.warmup_cosine": [[23, 26], ["torch.cos"], "function", ["None"], ["def", "warmup_cosine", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "s", "=", "1", "if", "x", "<=", "warmup", "else", "0", "\n", "return", "s", "*", "(", "x", "/", "warmup", ")", "+", "(", "1", "-", "s", ")", "*", "(", "0.5", "*", "(", "1", "+", "torch", ".", "cos", "(", "math", ".", "pi", "*", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.optimization_openai.warmup_constant": [[27, 30], ["None"], "function", ["None"], ["", "def", "warmup_constant", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "s", "=", "1", "if", "x", "<=", "warmup", "else", "0", "\n", "return", "s", "*", "(", "x", "/", "warmup", ")", "+", "(", "1", "-", "s", ")", "*", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.optimization_openai.warmup_linear": [[31, 34], ["None"], "function", ["None"], ["", "def", "warmup_linear", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "s", "=", "1", "if", "x", "<=", "warmup", "else", "0", "\n", "return", "(", "s", "*", "(", "x", "/", "warmup", ")", "+", "(", "1", "-", "s", ")", ")", "*", "(", "1", "-", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.from_pretrained": [[80, 122], ["cls", "os.path.join", "os.path.join", "file_utils.cached_path", "file_utils.cached_path", "logger.info", "logger.info", "logger.info", "logger.info", "min", "logger.error", "kwargs.get", "int", "PRETRAINED_VOCAB_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.cached_path", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.cached_path", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a PreTrainedBertModel from a pre-trained model file.\n        Download and cache the pre-trained model file if needed.\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_ARCHIVE_MAP", ":", "\n", "            ", "vocab_file", "=", "PRETRAINED_VOCAB_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "merges_file", "=", "PRETRAINED_MERGES_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "VOCAB_NAME", ")", "\n", "merges_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "MERGES_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_vocab_file", "=", "cached_path", "(", "vocab_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "resolved_merges_file", "=", "cached_path", "(", "merges_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} and {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_VOCAB_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "vocab_file", ",", "merges_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_vocab_file", "==", "vocab_file", "and", "resolved_merges_file", "==", "merges_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {}\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading merges file {}\"", ".", "format", "(", "merges_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {} from cache at {}\"", ".", "format", "(", "\n", "vocab_file", ",", "resolved_vocab_file", ")", ")", "\n", "logger", ".", "info", "(", "\"loading merges file {} from cache at {}\"", ".", "format", "(", "\n", "merges_file", ",", "resolved_merges_file", ")", ")", "\n", "", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", ":", "\n", "# if we're using a pretrained model, ensure the tokenizer wont index sequences longer", "\n", "# than the number of positional embeddings", "\n", "            ", "max_len", "=", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "kwargs", "[", "'max_len'", "]", "=", "min", "(", "kwargs", ".", "get", "(", "'max_len'", ",", "int", "(", "1e12", ")", ")", ",", "max_len", ")", "\n", "# Instantiate tokenizer.", "\n", "", "tokenizer", "=", "cls", "(", "resolved_vocab_file", ",", "resolved_merges_file", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.__init__": [[123, 143], ["json.load", "dict", "tokenization_openai.OpenAIGPTTokenizer.set_special_tokens", "spacy.load", "int", "io.open", "io.open().read().split", "tuple", "zip", "logger.warning", "tokenization.BasicTokenizer", "tokenization_openai.OpenAIGPTTokenizer.encoder.items", "merge.split", "range", "io.open().read", "len", "io.open"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.set_special_tokens", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read"], ["", "def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "special_tokens", "=", "None", ",", "max_len", "=", "None", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "ftfy", "\n", "import", "spacy", "\n", "self", ".", "nlp", "=", "spacy", ".", "load", "(", "'en'", ",", "disable", "=", "[", "'parser'", ",", "'tagger'", ",", "'ner'", ",", "'textcat'", "]", ")", "\n", "self", ".", "fix_text", "=", "ftfy", ".", "fix_text", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\"ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\"", ")", "\n", "self", ".", "nlp", "=", "BasicTokenizer", "(", "do_lower_case", "=", "True", ",", "\n", "never_split", "=", "special_tokens", "if", "special_tokens", "is", "not", "None", "else", "[", "]", ")", "\n", "self", ".", "fix_text", "=", "None", "\n", "\n", "", "self", ".", "max_len", "=", "max_len", "if", "max_len", "is", "not", "None", "else", "int", "(", "1e12", ")", "\n", "self", ".", "encoder", "=", "json", ".", "load", "(", "open", "(", "vocab_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "merges", "=", "open", "(", "merges_file", ",", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "[", "1", ":", "-", "1", "]", "\n", "merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "merges", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "merges", ",", "range", "(", "len", "(", "merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "self", ".", "set_special_tokens", "(", "special_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.__len__": [[144, 146], ["len", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "+", "len", "(", "self", ".", "special_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.set_special_tokens": [[147, 162], ["dict", "logger.info", "tokenization_openai.OpenAIGPTTokenizer.special_tokens.items", "enumerate", "len"], "methods", ["None"], ["", "def", "set_special_tokens", "(", "self", ",", "special_tokens", ")", ":", "\n", "        ", "\"\"\" Add a list of additional tokens to the encoder.\n            The additional tokens are indexed starting from the last index of the\n            current vocabulary in the order of the `special_tokens` list.\n        \"\"\"", "\n", "if", "not", "special_tokens", ":", "\n", "            ", "self", ".", "special_tokens", "=", "{", "}", "\n", "self", ".", "special_tokens_decoder", "=", "{", "}", "\n", "return", "\n", "", "self", ".", "special_tokens", "=", "dict", "(", "(", "tok", ",", "len", "(", "self", ".", "encoder", ")", "+", "i", ")", "for", "i", ",", "tok", "in", "enumerate", "(", "special_tokens", ")", ")", "\n", "self", ".", "special_tokens_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "special_tokens", ".", "items", "(", ")", "}", "\n", "if", "self", ".", "fix_text", "is", "None", ":", "\n", "# Using BERT's BasicTokenizer: we can update the tokenizer", "\n", "            ", "self", ".", "nlp", ".", "never_split", "=", "special_tokens", "\n", "", "logger", ".", "info", "(", "\"Special tokens {}\"", ".", "format", "(", "self", ".", "special_tokens", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.bpe": [[163, 205], ["tokenization_openai.get_pairs", "tuple", "min", "tuple", "len", "len", "tokenization_openai.get_pairs", "word.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_openai.OpenAIGPTTokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.get_pairs", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.get_pairs", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "word", "=", "tuple", "(", "token", "[", ":", "-", "1", "]", ")", "+", "(", "token", "[", "-", "1", "]", "+", "'</w>'", ",", ")", "\n", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "+", "'</w>'", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "' '", ".", "join", "(", "word", ")", "\n", "if", "word", "==", "'\\n  </w>'", ":", "\n", "            ", "word", "=", "'\\n</w>'", "\n", "", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.tokenize": [[206, 220], ["tokenization_openai.OpenAIGPTTokenizer.nlp.tokenize", "tokenization_openai.OpenAIGPTTokenizer.nlp", "split_tokens.extend", "tokenization_openai.text_standardize", "split_tokens.extend", "tokenization_openai.OpenAIGPTTokenizer.fix_text", "tokenization_openai.OpenAIGPTTokenizer.bpe().split", "tokenization_openai.OpenAIGPTTokenizer.bpe().split", "tokenization_openai.OpenAIGPTTokenizer.bpe", "tokenization_openai.OpenAIGPTTokenizer.bpe", "token.text.lower"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_openai.text_standardize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.tokenization_roberta.RobertaTokenizer.bpe", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.tokenization_roberta.RobertaTokenizer.bpe"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Tokenize a string. \"\"\"", "\n", "split_tokens", "=", "[", "]", "\n", "if", "self", ".", "fix_text", "is", "None", ":", "\n", "# Using BERT's BasicTokenizer", "\n", "            ", "text", "=", "self", ".", "nlp", ".", "tokenize", "(", "text", ")", "\n", "for", "token", "in", "text", ":", "\n", "                ", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", "]", ")", "\n", "", "", "else", ":", "\n", "# Using SpaCy & ftfy (original tokenization process of OpenAI GPT)", "\n", "            ", "text", "=", "self", ".", "nlp", "(", "text_standardize", "(", "self", ".", "fix_text", "(", "text", ")", ")", ")", "\n", "for", "token", "in", "text", ":", "\n", "                ", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ".", "text", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "]", ")", "\n", "", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.convert_tokens_to_ids": [[221, 241], ["isinstance", "len", "ValueError", "isinstance", "tokenization_openai.OpenAIGPTTokenizer.encoder.get", "ids.append", "ids.append", "tokenization_openai.OpenAIGPTTokenizer.encoder.get", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens into ids using the vocab. \"\"\"", "\n", "ids", "=", "[", "]", "\n", "if", "isinstance", "(", "tokens", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "tokens", ",", "unicode", ")", ")", ":", "\n", "            ", "if", "tokens", "in", "self", ".", "special_tokens", ":", "\n", "                ", "return", "self", ".", "special_tokens", "[", "tokens", "]", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "encoder", ".", "get", "(", "tokens", ",", "0", ")", "\n", "", "", "for", "token", "in", "tokens", ":", "\n", "            ", "if", "token", "in", "self", ".", "special_tokens", ":", "\n", "                ", "ids", ".", "append", "(", "self", ".", "special_tokens", "[", "token", "]", ")", "\n", "", "else", ":", "\n", "                ", "ids", ".", "append", "(", "self", ".", "encoder", ".", "get", "(", "token", ",", "0", ")", ")", "\n", "", "", "if", "len", "(", "ids", ")", ">", "self", ".", "max_len", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Token indices sequence length is longer than the specified maximum \"", "\n", "\" sequence length for this OpenAI GPT model ({} > {}). Running this\"", "\n", "\" sequence through the model will result in indexing errors\"", ".", "format", "(", "len", "(", "ids", ")", ",", "self", ".", "max_len", ")", "\n", ")", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.convert_ids_to_tokens": [[242, 252], ["tokens.append", "tokens.append"], "methods", ["None"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ",", "skip_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of ids in BPE tokens using the vocab.\"\"\"", "\n", "tokens", "=", "[", "]", "\n", "for", "i", "in", "ids", ":", "\n", "            ", "if", "i", "in", "self", ".", "special_tokens_decoder", ":", "\n", "                ", "if", "not", "skip_special_tokens", ":", "\n", "                    ", "tokens", ".", "append", "(", "self", ".", "special_tokens_decoder", "[", "i", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "tokens", ".", "append", "(", "self", ".", "decoder", "[", "i", "]", ")", "\n", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_openai.OpenAIGPTTokenizer.decode": [[253, 264], ["tokenization_openai.OpenAIGPTTokenizer.convert_ids_to_tokens", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_ids_to_tokens"], ["", "def", "decode", "(", "self", ",", "ids", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "False", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of ids in a string.\"\"\"", "\n", "tokens", "=", "self", ".", "convert_ids_to_tokens", "(", "ids", ",", "skip_special_tokens", "=", "skip_special_tokens", ")", "\n", "out_string", "=", "''", ".", "join", "(", "tokens", ")", ".", "replace", "(", "'</w>'", ",", "' '", ")", ".", "strip", "(", ")", "\n", "if", "clean_up_tokenization_spaces", ":", "\n", "            ", "out_string", "=", "out_string", ".", "replace", "(", "'<unk>'", ",", "''", ")", "\n", "out_string", "=", "out_string", ".", "replace", "(", "' .'", ",", "'.'", ")", ".", "replace", "(", "' ?'", ",", "'?'", ")", ".", "replace", "(", "' !'", ",", "'!'", ")", ".", "replace", "(", "' ,'", ",", "','", ")", ".", "replace", "(", "' ,'", ",", "','", "\n", ")", ".", "replace", "(", "\" n't\"", ",", "\"n't\"", ")", ".", "replace", "(", "\" 'm\"", ",", "\"'m\"", ")", ".", "replace", "(", "\" 're\"", ",", "\"'re\"", ")", ".", "replace", "(", "\" do not\"", ",", "\" don't\"", "\n", ")", ".", "replace", "(", "\" 's\"", ",", "\"'s\"", ")", ".", "replace", "(", "\" t \"", ",", "\"'t \"", ")", ".", "replace", "(", "\" s \"", ",", "\"'s \"", ")", ".", "replace", "(", "\" m \"", ",", "\"'m \"", "\n", ")", ".", "replace", "(", "\" 've\"", ",", "\"'ve\"", ")", "\n", "", "return", "out_string", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_openai.get_pairs": [[45, 56], ["set", "set.add"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.add"], ["def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"\n    Return set of symbol pairs in a word.\n    word is represented as tuple of symbols (symbols being variable-length strings)\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.tokenization_openai.text_standardize": [[57, 71], ["re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub", "re.sub", "re.sub", "re.sub.strip"], "function", ["None"], ["", "def", "text_standardize", "(", "text", ")", ":", "\n", "    ", "\"\"\"\n    fixes some issues the spacy tokenizer had on books corpus\n    also does some whitespace standardization\n    \"\"\"", "\n", "text", "=", "text", ".", "replace", "(", "'\u2014'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2013'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2015'", ",", "'-'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u2026'", ",", "'...'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'\u00b4'", ",", "\"'\"", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'''(-+|~+|!+|\"+|;+|\\?+|\\++|,+|\\)+|\\(+|\\\\+|\\/+|\\*+|\\[+|\\]+|}+|{+|\\|+|_+)'''", ",", "r' \\1 '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'\\s*\\n\\s*'", ",", "' \\n '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'[^\\S\\n]+'", ",", "' '", ",", "text", ")", "\n", "return", "text", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.scripts.launch.parse_args": [[108, 154], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.scripts.launch.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "\"\"\"\n    Helper function parsing the command line options\n    @retval ArgumentParser\n    \"\"\"", "\n", "parser", "=", "ArgumentParser", "(", "description", "=", "\"PyTorch distributed training launch \"", "\n", "\"helper utilty that will spawn up \"", "\n", "\"multiple distributed processes\"", ")", "\n", "\n", "# Optional arguments for the launch helper", "\n", "parser", ".", "add_argument", "(", "\"--nnodes\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"The number of nodes to use for distributed \"", "\n", "\"training\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--node_rank\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"The rank of the node for multi-node distributed \"", "\n", "\"training\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--nproc_per_node\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"The number of processes to launch on each node, \"", "\n", "\"for GPU training, this is recommended to be set \"", "\n", "\"to the number of GPUs in your system so that \"", "\n", "\"each process can be bound to a single GPU.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--master_addr\"", ",", "default", "=", "\"127.0.0.1\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Master node (rank 0)'s address, should be either \"", "\n", "\"the IP address or the hostname of node 0, for \"", "\n", "\"single node multi-proc training, the \"", "\n", "\"--master_addr can simply be 127.0.0.1\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--master_port\"", ",", "default", "=", "29500", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Master node (rank 0)'s free port that needs to \"", "\n", "\"be used for communciation during distributed \"", "\n", "\"training\"", ")", "\n", "# parser.add_argument(\"--use_env\", default=False, action=\"store_true\",", "\n", "#                     help=\"Use environment variable to pass \"", "\n", "#                          \"'local rank'. For legacy reasons, the default value is False. \"", "\n", "#                          \"If set to True, the script will not pass \"", "\n", "#                          \"--local_rank as argument, and will instead set LOCAL_RANK.\")", "\n", "\n", "# positional", "\n", "parser", ".", "add_argument", "(", "\"training_script\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The full path to the single GPU training \"", "\n", "\"program/script to be launched in parallel, \"", "\n", "\"followed by all the arguments for the \"", "\n", "\"training script\"", ")", "\n", "\n", "# rest from the training program", "\n", "parser", ".", "add_argument", "(", "'training_script_args'", ",", "nargs", "=", "REMAINDER", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.scripts.launch.main": [[156, 197], ["launch.parse_args", "os.environ.copy", "str", "str", "range", "str", "str", "subprocess.Popen", "processes.append", "subprocess.Popen.wait", "subprocess.CalledProcessError"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.scripts.launch.parse_args"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "\n", "# world size in terms of number of processes", "\n", "dist_world_size", "=", "args", ".", "nproc_per_node", "*", "args", ".", "nnodes", "\n", "\n", "# set PyTorch distributed related environmental variables", "\n", "current_env", "=", "os", ".", "environ", ".", "copy", "(", ")", "\n", "current_env", "[", "\"MASTER_ADDR\"", "]", "=", "args", ".", "master_addr", "\n", "current_env", "[", "\"MASTER_PORT\"", "]", "=", "str", "(", "args", ".", "master_port", ")", "\n", "current_env", "[", "\"WORLD_SIZE\"", "]", "=", "str", "(", "dist_world_size", ")", "\n", "\n", "processes", "=", "[", "]", "\n", "\n", "for", "local_rank", "in", "range", "(", "0", ",", "args", ".", "nproc_per_node", ")", ":", "\n", "# each process's rank", "\n", "        ", "dist_rank", "=", "args", ".", "nproc_per_node", "*", "args", ".", "node_rank", "+", "local_rank", "\n", "current_env", "[", "\"RANK\"", "]", "=", "str", "(", "dist_rank", ")", "\n", "current_env", "[", "\"LOCAL_RANK\"", "]", "=", "str", "(", "local_rank", ")", "\n", "\n", "# # spawn the processes", "\n", "# if args.use_env:", "\n", "#     cmd = [sys.executable, \"-u\",", "\n", "#            args.training_script] + args.training_script_args", "\n", "# else:", "\n", "#     cmd = [sys.executable,", "\n", "#            \"-u\",", "\n", "#            args.training_script,", "\n", "#            \"--local_rank={}\".format(local_rank)] + args.training_script_args", "\n", "\n", "cmd", "=", "[", "sys", ".", "executable", ",", "\"-u\"", ",", "\n", "args", ".", "training_script", "]", "+", "args", ".", "training_script_args", "+", "[", "\"--dist\"", "]", "\n", "\n", "process", "=", "subprocess", ".", "Popen", "(", "cmd", ",", "env", "=", "current_env", ")", "\n", "processes", ".", "append", "(", "process", ")", "\n", "\n", "", "for", "process", "in", "processes", ":", "\n", "        ", "process", ".", "wait", "(", ")", "\n", "if", "process", ".", "returncode", "!=", "0", ":", "\n", "            ", "raise", "subprocess", ".", "CalledProcessError", "(", "returncode", "=", "process", ".", "returncode", ",", "\n", "cmd", "=", "process", ".", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.fast_rcnn.FastRCNN.__init__": [[18, 109], ["torch.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "common.lib.roi_pooling.roi_align.ROIAlign", "fast_rcnn.FastRCNN.backbone._make_layer", "fast_rcnn.FastRCNN.backbone.frozen_parameters", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "resnet18", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "fast_rcnn.FastRCNN.roi_head_feature_extractor.modules", "fast_rcnn.FastRCNN.roi_head_feature_extractor.parameters", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "resnet34", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "common.utils.flatten.Flattener", "isinstance", "resnet50", "module.parameters", "resnet101", "resnet152"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.frozen_parameters", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.resnet18", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.resnet34", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.resnet50", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.resnet101", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.resnet152"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "average_pool", "=", "True", ",", "final_dim", "=", "768", ",", "enable_cnn_reg_loss", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param config:\n        :param average_pool: whether or not to average pool the representations\n        :param final_dim:\n        :param is_train:\n        \"\"\"", "\n", "super", "(", "FastRCNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "average_pool", "=", "average_pool", "\n", "self", ".", "enable_cnn_reg_loss", "=", "enable_cnn_reg_loss", "\n", "self", ".", "final_dim", "=", "final_dim", "\n", "self", ".", "image_feat_precomputed", "=", "config", ".", "NETWORK", ".", "IMAGE_FEAT_PRECOMPUTED", "\n", "if", "self", ".", "image_feat_precomputed", ":", "\n", "            ", "if", "config", ".", "NETWORK", ".", "IMAGE_SEMANTIC", ":", "\n", "                ", "self", ".", "object_embed", "=", "torch", ".", "nn", ".", "Embedding", "(", "num_embeddings", "=", "81", ",", "embedding_dim", "=", "128", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "object_embed", "=", "None", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "stride_in_1x1", "=", "config", ".", "NETWORK", ".", "IMAGE_STRIDE_IN_1x1", "\n", "self", ".", "c5_dilated", "=", "config", ".", "NETWORK", ".", "IMAGE_C5_DILATED", "\n", "self", ".", "num_layers", "=", "config", ".", "NETWORK", ".", "IMAGE_NUM_LAYERS", "\n", "self", ".", "pretrained_model_path", "=", "'{}-{:04d}.model'", ".", "format", "(", "config", ".", "NETWORK", ".", "IMAGE_PRETRAINED", ",", "\n", "config", ".", "NETWORK", ".", "IMAGE_PRETRAINED_EPOCH", ")", "if", "config", ".", "NETWORK", ".", "IMAGE_PRETRAINED", "!=", "''", "else", "None", "\n", "self", ".", "output_conv5", "=", "config", ".", "NETWORK", ".", "OUTPUT_CONV5", "\n", "if", "self", ".", "num_layers", "==", "18", ":", "\n", "                ", "self", ".", "backbone", "=", "resnet18", "(", "pretrained", "=", "True", ",", "pretrained_model_path", "=", "self", ".", "pretrained_model_path", ",", "\n", "expose_stages", "=", "[", "4", "]", ")", "\n", "block", "=", "BasicBlock", "\n", "", "elif", "self", ".", "num_layers", "==", "34", ":", "\n", "                ", "self", ".", "backbone", "=", "resnet34", "(", "pretrained", "=", "True", ",", "pretrained_model_path", "=", "self", ".", "pretrained_model_path", ",", "\n", "expose_stages", "=", "[", "4", "]", ")", "\n", "block", "=", "BasicBlock", "\n", "", "elif", "self", ".", "num_layers", "==", "50", ":", "\n", "                ", "self", ".", "backbone", "=", "resnet50", "(", "pretrained", "=", "True", ",", "pretrained_model_path", "=", "self", ".", "pretrained_model_path", ",", "\n", "expose_stages", "=", "[", "4", "]", ",", "stride_in_1x1", "=", "self", ".", "stride_in_1x1", ")", "\n", "block", "=", "Bottleneck", "\n", "", "elif", "self", ".", "num_layers", "==", "101", ":", "\n", "                ", "self", ".", "backbone", "=", "resnet101", "(", "pretrained", "=", "True", ",", "pretrained_model_path", "=", "self", ".", "pretrained_model_path", ",", "\n", "expose_stages", "=", "[", "4", "]", ",", "stride_in_1x1", "=", "self", ".", "stride_in_1x1", ")", "\n", "block", "=", "Bottleneck", "\n", "", "elif", "self", ".", "num_layers", "==", "152", ":", "\n", "                ", "self", ".", "backbone", "=", "resnet152", "(", "pretrained", "=", "True", ",", "pretrained_model_path", "=", "self", ".", "pretrained_model_path", ",", "\n", "expose_stages", "=", "[", "4", "]", ",", "stride_in_1x1", "=", "self", ".", "stride_in_1x1", ")", "\n", "block", "=", "Bottleneck", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplemented", "\n", "\n", "", "output_size", "=", "(", "14", ",", "14", ")", "\n", "self", ".", "roi_align", "=", "ROIAlign", "(", "output_size", "=", "output_size", ",", "spatial_scale", "=", "1.0", "/", "16", ")", "\n", "\n", "if", "config", ".", "NETWORK", ".", "IMAGE_SEMANTIC", ":", "\n", "                ", "self", ".", "object_embed", "=", "torch", ".", "nn", ".", "Embedding", "(", "num_embeddings", "=", "81", ",", "embedding_dim", "=", "128", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "object_embed", "=", "None", "\n", "self", ".", "mask_upsample", "=", "None", "\n", "\n", "", "self", ".", "roi_head_feature_extractor", "=", "self", ".", "backbone", ".", "_make_layer", "(", "block", "=", "block", ",", "planes", "=", "512", ",", "blocks", "=", "3", ",", "\n", "stride", "=", "2", "if", "not", "self", ".", "c5_dilated", "else", "1", ",", "\n", "dilation", "=", "1", "if", "not", "self", ".", "c5_dilated", "else", "2", ",", "\n", "stride_in_1x1", "=", "self", ".", "stride_in_1x1", ")", "\n", "\n", "if", "average_pool", ":", "\n", "                ", "self", ".", "head", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "self", ".", "roi_head_feature_extractor", ",", "\n", "nn", ".", "AvgPool2d", "(", "7", "if", "not", "self", ".", "c5_dilated", "else", "14", ",", "stride", "=", "1", ")", ",", "\n", "Flattener", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "head", "=", "self", ".", "roi_head_feature_extractor", "\n", "\n", "", "if", "config", ".", "NETWORK", ".", "IMAGE_FROZEN_BN", ":", "\n", "                ", "for", "module", "in", "self", ".", "roi_head_feature_extractor", ".", "modules", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "module", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                        ", "for", "param", "in", "module", ".", "parameters", "(", ")", ":", "\n", "                            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "", "", "frozen_stages", "=", "config", ".", "NETWORK", ".", "IMAGE_FROZEN_BACKBONE_STAGES", "\n", "if", "5", "in", "frozen_stages", ":", "\n", "                ", "for", "p", "in", "self", ".", "roi_head_feature_extractor", ".", "parameters", "(", ")", ":", "\n", "                    ", "p", ".", "requires_grad", "=", "False", "\n", "", "frozen_stages", "=", "[", "stage", "for", "stage", "in", "frozen_stages", "if", "stage", "!=", "5", "]", "\n", "", "self", ".", "backbone", ".", "frozen_parameters", "(", "frozen_stages", "=", "frozen_stages", ",", "\n", "frozen_bn", "=", "config", ".", "NETWORK", ".", "IMAGE_FROZEN_BN", ")", "\n", "\n", "if", "self", ".", "enable_cnn_reg_loss", ":", "\n", "                ", "self", ".", "regularizing_predictor", "=", "torch", ".", "nn", ".", "Linear", "(", "2048", ",", "81", ")", "\n", "\n", "", "", "self", ".", "obj_downsample", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "0.1", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "2", "*", "2048", "+", "(", "128", "if", "config", ".", "NETWORK", ".", "IMAGE_SEMANTIC", "else", "0", ")", ",", "final_dim", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.fast_rcnn.FastRCNN.init_weight": [[111, 121], ["fast_rcnn.FastRCNN.roi_head_feature_extractor.load_state_dict", "torch.load_url", "torch.load_url", "torch.load_url", "torch.load_url", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "fast_rcnn.FastRCNN.conv5.load_state_dict", "torch.load.items", "torch.load.items", "torch.load.items", "torch.load.items", "k.startswith", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict"], ["", "def", "init_weight", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "image_feat_precomputed", ":", "\n", "            ", "if", "self", ".", "pretrained_model_path", "is", "None", ":", "\n", "                ", "pretrained_model", "=", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet{}'", ".", "format", "(", "self", ".", "num_layers", ")", "]", ")", "\n", "", "else", ":", "\n", "                ", "pretrained_model", "=", "torch", ".", "load", "(", "self", ".", "pretrained_model_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "", "roi_head_feat_dict", "=", "{", "k", "[", "len", "(", "'layer4.'", ")", ":", "]", ":", "v", "for", "k", ",", "v", "in", "pretrained_model", ".", "items", "(", ")", "if", "k", ".", "startswith", "(", "'layer4.'", ")", "}", "\n", "self", ".", "roi_head_feature_extractor", ".", "load_state_dict", "(", "roi_head_feat_dict", ")", "\n", "if", "self", ".", "output_conv5", ":", "\n", "                ", "self", ".", "conv5", ".", "load_state_dict", "(", "roi_head_feat_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.fast_rcnn.FastRCNN.bn_eval": [[122, 127], ["fast_rcnn.FastRCNN.modules", "isinstance", "module.eval"], "methods", ["None"], ["", "", "", "def", "bn_eval", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "image_feat_precomputed", ":", "\n", "            ", "for", "module", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "module", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                    ", "module", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.fast_rcnn.FastRCNN.forward": [[128, 204], ["box_mask.nonzero", "common.utils.bbox.coordinate_embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fast_rcnn.FastRCNN.obj_downsample", "common.utils.pad_sequence.pad_sequence", "common.utils.pad_sequence.pad_sequence", "common.utils.pad_sequence.pad_sequence.new_zeros", "_layer.new_zeros", "classes[].type", "fast_rcnn.FastRCNN.backbone", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fast_rcnn.FastRCNN.roi_align().type", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "box_mask.sum().tolist", "box_mask.sum().tolist", "output_dict.update", "fast_rcnn.FastRCNN.img_head", "fast_rcnn.FastRCNN.roi_head_feature_extractor", "fast_rcnn.FastRCNN.head", "fast_rcnn.FastRCNN.regularizing_predictor", "common.utils.bbox.coordinate_embeddings.view", "box_inds[].type", "fast_rcnn.FastRCNN.roi_align", "segms[].to", "_layer", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "fast_rcnn.FastRCNN.object_embed", "box_mask.sum", "box_mask.sum"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.bbox.coordinate_embeddings", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.pad_sequence.pad_sequence", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.pad_sequence.pad_sequence", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update"], ["", "", "", "", "def", "forward", "(", "self", ",", "images", ",", "boxes", ",", "box_mask", ",", "im_info", ",", "classes", "=", "None", ",", "segms", "=", "None", ",", "mvrc_ops", "=", "None", ",", "mask_visual_embed", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param images: [batch_size, 3, im_height, im_width]\n        :param boxes: [batch_size, max_num_objects, 4] Padded boxes\n        :param box_mask: [batch_size, max_num_objects] Mask for whether or not each box is OK\n        :return: object reps [batch_size, max_num_objects, dim]\n        \"\"\"", "\n", "\n", "box_inds", "=", "box_mask", ".", "nonzero", "(", ")", "\n", "obj_labels", "=", "classes", "[", "box_inds", "[", ":", ",", "0", "]", ",", "box_inds", "[", ":", ",", "1", "]", "]", ".", "type", "(", "torch", ".", "long", ")", "if", "classes", "is", "not", "None", "else", "None", "\n", "assert", "box_inds", ".", "shape", "[", "0", "]", ">", "0", "\n", "\n", "if", "self", ".", "image_feat_precomputed", ":", "\n", "            ", "post_roialign", "=", "boxes", "[", "box_inds", "[", ":", ",", "0", "]", ",", "box_inds", "[", ":", ",", "1", "]", "]", "[", ":", ",", "4", ":", "]", "\n", "boxes", "=", "boxes", "[", ":", ",", ":", ",", ":", "4", "]", "\n", "", "else", ":", "\n", "            ", "img_feats", "=", "self", ".", "backbone", "(", "images", ")", "\n", "rois", "=", "torch", ".", "cat", "(", "(", "\n", "box_inds", "[", ":", ",", "0", ",", "None", "]", ".", "type", "(", "boxes", ".", "dtype", ")", ",", "\n", "boxes", "[", "box_inds", "[", ":", ",", "0", "]", ",", "box_inds", "[", ":", ",", "1", "]", "]", ",", "\n", ")", ",", "1", ")", "\n", "roi_align_res", "=", "self", ".", "roi_align", "(", "img_feats", "[", "'body4'", "]", ",", "rois", ")", ".", "type", "(", "images", ".", "dtype", ")", "\n", "\n", "if", "segms", "is", "not", "None", ":", "\n", "                ", "pool_layers", "=", "self", ".", "head", "[", "1", ":", "]", "\n", "post_roialign", "=", "self", ".", "roi_head_feature_extractor", "(", "roi_align_res", ")", "\n", "post_roialign", "=", "post_roialign", "*", "segms", "[", "box_inds", "[", ":", ",", "0", "]", ",", "None", ",", "box_inds", "[", ":", ",", "1", "]", "]", ".", "to", "(", "dtype", "=", "post_roialign", ".", "dtype", ")", "\n", "for", "_layer", "in", "pool_layers", ":", "\n", "                    ", "post_roialign", "=", "_layer", "(", "post_roialign", ")", "\n", "", "", "else", ":", "\n", "                ", "post_roialign", "=", "self", ".", "head", "(", "roi_align_res", ")", "\n", "\n", "# Add some regularization, encouraging the model to keep giving decent enough predictions", "\n", "", "if", "self", ".", "enable_cnn_reg_loss", ":", "\n", "                ", "obj_logits", "=", "self", ".", "regularizing_predictor", "(", "post_roialign", ")", "\n", "cnn_regularization", "=", "F", ".", "cross_entropy", "(", "obj_logits", ",", "obj_labels", ")", "[", "None", "]", "\n", "\n", "", "", "feats_to_downsample", "=", "post_roialign", "if", "(", "self", ".", "object_embed", "is", "None", "or", "obj_labels", "is", "None", ")", "else", "torch", ".", "cat", "(", "(", "post_roialign", ",", "self", ".", "object_embed", "(", "obj_labels", ")", ")", ",", "-", "1", ")", "\n", "if", "mvrc_ops", "is", "not", "None", "and", "mask_visual_embed", "is", "not", "None", ":", "\n", "            ", "_to_masked", "=", "(", "mvrc_ops", "==", "1", ")", "[", "box_inds", "[", ":", ",", "0", "]", ",", "box_inds", "[", ":", ",", "1", "]", "]", "\n", "feats_to_downsample", "[", "_to_masked", "]", "=", "mask_visual_embed", "\n", "", "coord_embed", "=", "coordinate_embeddings", "(", "\n", "torch", ".", "cat", "(", "(", "boxes", "[", "box_inds", "[", ":", ",", "0", "]", ",", "box_inds", "[", ":", ",", "1", "]", "]", ",", "im_info", "[", "box_inds", "[", ":", ",", "0", "]", ",", ":", "2", "]", ")", ",", "1", ")", ",", "\n", "256", "\n", ")", "\n", "feats_to_downsample", "=", "torch", ".", "cat", "(", "(", "coord_embed", ".", "view", "(", "(", "coord_embed", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", ",", "feats_to_downsample", ")", ",", "-", "1", ")", "\n", "final_feats", "=", "self", ".", "obj_downsample", "(", "feats_to_downsample", ")", "\n", "\n", "# Reshape into a padded sequence - this is expensive and annoying but easier to implement and debug...", "\n", "obj_reps", "=", "pad_sequence", "(", "final_feats", ",", "box_mask", ".", "sum", "(", "1", ")", ".", "tolist", "(", ")", ")", "\n", "post_roialign", "=", "pad_sequence", "(", "post_roialign", ",", "box_mask", ".", "sum", "(", "1", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "# DataParallel compatibility", "\n", "obj_reps_padded", "=", "obj_reps", ".", "new_zeros", "(", "(", "obj_reps", ".", "shape", "[", "0", "]", ",", "boxes", ".", "shape", "[", "1", "]", ",", "obj_reps", ".", "shape", "[", "2", "]", ")", ")", "\n", "obj_reps_padded", "[", ":", ",", ":", "obj_reps", ".", "shape", "[", "1", "]", "]", "=", "obj_reps", "\n", "obj_reps", "=", "obj_reps_padded", "\n", "post_roialign_padded", "=", "post_roialign", ".", "new_zeros", "(", "(", "post_roialign", ".", "shape", "[", "0", "]", ",", "boxes", ".", "shape", "[", "1", "]", ",", "post_roialign", ".", "shape", "[", "2", "]", ")", ")", "\n", "post_roialign_padded", "[", ":", ",", ":", "post_roialign", ".", "shape", "[", "1", "]", "]", "=", "post_roialign", "\n", "post_roialign", "=", "post_roialign_padded", "\n", "\n", "# Output", "\n", "output_dict", "=", "{", "\n", "'obj_reps_raw'", ":", "post_roialign", ",", "\n", "'obj_reps'", ":", "obj_reps", ",", "\n", "}", "\n", "if", "(", "not", "self", ".", "image_feat_precomputed", ")", "and", "self", ".", "enable_cnn_reg_loss", ":", "\n", "            ", "output_dict", ".", "update", "(", "{", "'obj_logits'", ":", "obj_logits", ",", "\n", "'obj_labels'", ":", "obj_labels", ",", "\n", "'cnn_regularization_loss'", ":", "cnn_regularization", "}", ")", "\n", "\n", "", "if", "(", "not", "self", ".", "image_feat_precomputed", ")", "and", "self", ".", "output_conv5", ":", "\n", "            ", "image_feature", "=", "self", ".", "img_head", "(", "img_feats", "[", "'body4'", "]", ")", "\n", "output_dict", "[", "'image_feature'", "]", "=", "image_feature", "\n", "\n", "", "return", "output_dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.trainer._multiple_callbacks": [[29, 40], ["isinstance", "callbacks", "cb"], "function", ["None"], ["def", "_multiple_callbacks", "(", "callbacks", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Sends args and kwargs to any configured callbacks.\n    This handles the cases where the 'callbacks' variable\n    is ``None``, a single function, or a list.\n    \"\"\"", "\n", "if", "isinstance", "(", "callbacks", ",", "list", ")", ":", "\n", "        ", "for", "cb", "in", "callbacks", ":", "\n", "            ", "cb", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "\n", "", "if", "callbacks", ":", "\n", "        ", "callbacks", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.trainer.to_cuda": [[42, 54], ["list", "range", "len", "isinstance", "batch[].cuda", "isinstance", "enumerate", "isinstance", "o.cuda"], "function", ["None"], ["", "", "def", "to_cuda", "(", "batch", ")", ":", "\n", "    ", "batch", "=", "list", "(", "batch", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "batch", ")", ")", ":", "\n", "        ", "if", "isinstance", "(", "batch", "[", "i", "]", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "batch", "[", "i", "]", "=", "batch", "[", "i", "]", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "", "elif", "isinstance", "(", "batch", "[", "i", "]", ",", "list", ")", ":", "\n", "            ", "for", "j", ",", "o", "in", "enumerate", "(", "batch", "[", "i", "]", ")", ":", "\n", "                ", "if", "isinstance", "(", "batch", "[", "i", "]", ",", "torch", ".", "Tensor", ")", ":", "\n", "                    ", "batch", "[", "i", "]", "[", "j", "]", "=", "o", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "\n", "", "", "", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.trainer.train": [[56, 198], ["range", "isinstance", "print", "metrics.reset", "net.train", "time.time", "isinstance", "enumerate", "hasattr", "train_sampler.set_epoch", "validation_monitor.metrics.get", "lr_scheduler.step", "str", "time.time", "trainer.to_cuda", "time.time", "net", "loss.mean.mean", "time.time", "time.time", "time.time", "metrics.update", "time.time", "validation_monitor", "trainer._multiple_callbacks", "time.time", "time.time", "time.time", "loss.mean.backward", "time.time", "optimizer.step", "optimizer.zero_grad", "time.time", "time.time", "BatchEndParam", "trainer._multiple_callbacks", "name.index", "len", "amp.scale_loss", "scaled_loss.backward", "lr_scheduler.step", "torch.no_grad", "enumerate", "writer.add_scalar", "metrics.get", "zip", "isinstance", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "locals", "amp.master_params", "net.parameters", "float", "float", "loss.mean.item"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.reset", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.trainer.train", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.samplers.distributed.DistributedSampler.set_epoch", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.bert.optimization.AdamW.step", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.trainer.to_cuda", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.trainer._multiple_callbacks", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.bert.optimization.AdamW.step", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.trainer._multiple_callbacks", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.bert.optimization.AdamW.step", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["", "def", "train", "(", "net", ",", "\n", "optimizer", ",", "\n", "lr_scheduler", ",", "\n", "train_loader", ",", "\n", "train_sampler", ",", "\n", "metrics", ",", "\n", "begin_epoch", ",", "\n", "end_epoch", ",", "\n", "logger", ",", "\n", "rank", "=", "None", ",", "\n", "batch_end_callbacks", "=", "None", ",", "\n", "epoch_end_callbacks", "=", "None", ",", "\n", "writer", "=", "None", ",", "\n", "validation_monitor", "=", "None", ",", "\n", "fp16", "=", "False", ",", "\n", "clip_grad_norm", "=", "-", "1", ",", "\n", "gradient_accumulate_steps", "=", "1", ")", ":", "\n", "\n", "    ", "assert", "isinstance", "(", "gradient_accumulate_steps", ",", "int", ")", "and", "gradient_accumulate_steps", ">=", "1", "\n", "# torch.autograd.set_detect_anomaly(True)", "\n", "\n", "\n", "for", "epoch", "in", "range", "(", "begin_epoch", ",", "end_epoch", ")", ":", "\n", "        ", "print", "(", "'PROGRESS: %.2f%%'", "%", "(", "100.0", "*", "epoch", "/", "end_epoch", ")", ")", "\n", "\n", "# set epoch as random seed of sampler while distributed training", "\n", "if", "train_sampler", "is", "not", "None", "and", "hasattr", "(", "train_sampler", ",", "'set_epoch'", ")", ":", "\n", "            ", "train_sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "\n", "# reset metrics", "\n", "", "metrics", ".", "reset", "(", ")", "\n", "\n", "# set net to train mode", "\n", "net", ".", "train", "(", ")", "\n", "\n", "# clear the paramter gradients", "\n", "# optimizer.zero_grad()", "\n", "\n", "# init end time", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "isinstance", "(", "lr_scheduler", ",", "torch", ".", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", ")", ":", "\n", "            ", "name", ",", "value", "=", "validation_monitor", ".", "metrics", ".", "get", "(", ")", "\n", "val", "=", "value", "[", "name", ".", "index", "(", "validation_monitor", ".", "host_metric_name", ")", "]", "\n", "lr_scheduler", ".", "step", "(", "val", ",", "epoch", ")", "\n", "\n", "# training", "\n", "", "for", "nbatch", ",", "batch", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "global_steps", "=", "len", "(", "train_loader", ")", "*", "epoch", "+", "nbatch", "\n", "os", ".", "environ", "[", "'global_steps'", "]", "=", "str", "(", "global_steps", ")", "\n", "\n", "# record time", "\n", "data_in_time", "=", "time", ".", "time", "(", ")", "-", "end_time", "\n", "\n", "# transfer data to GPU", "\n", "data_transfer_time", "=", "time", ".", "time", "(", ")", "\n", "batch", "=", "to_cuda", "(", "batch", ")", "\n", "data_transfer_time", "=", "time", ".", "time", "(", ")", "-", "data_transfer_time", "\n", "\n", "# forward", "\n", "forward_time", "=", "time", ".", "time", "(", ")", "\n", "outputs", ",", "loss", "=", "net", "(", "*", "batch", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "if", "gradient_accumulate_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "gradient_accumulate_steps", "\n", "", "forward_time", "=", "time", ".", "time", "(", ")", "-", "forward_time", "\n", "\n", "# backward", "\n", "backward_time", "=", "time", ".", "time", "(", ")", "\n", "if", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "backward_time", "=", "time", ".", "time", "(", ")", "-", "backward_time", "\n", "\n", "optimizer_time", "=", "time", ".", "time", "(", ")", "\n", "if", "(", "global_steps", "+", "1", ")", "%", "gradient_accumulate_steps", "==", "0", ":", "\n", "# step LR scheduler", "\n", "                ", "if", "lr_scheduler", "is", "not", "None", "and", "not", "isinstance", "(", "lr_scheduler", ",", "\n", "torch", ".", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", ")", ":", "\n", "                    ", "lr_scheduler", ".", "step", "(", ")", "\n", "\n", "# clip gradient", "\n", "", "if", "clip_grad_norm", ">", "0", ":", "\n", "                    ", "if", "fp16", ":", "\n", "                        ", "total_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "\n", "clip_grad_norm", ")", "\n", "", "else", ":", "\n", "                        ", "total_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "net", ".", "parameters", "(", ")", ",", "\n", "clip_grad_norm", ")", "\n", "", "if", "writer", "is", "not", "None", ":", "\n", "                        ", "writer", ".", "add_scalar", "(", "tag", "=", "'grad-para/Total-Norm'", ",", "\n", "scalar_value", "=", "float", "(", "total_norm", ")", ",", "\n", "global_step", "=", "global_steps", ")", "\n", "\n", "", "", "optimizer", ".", "step", "(", ")", "\n", "# clear the parameter gradients", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "", "optimizer_time", "=", "time", ".", "time", "(", ")", "-", "optimizer_time", "\n", "\n", "# update metric", "\n", "metric_time", "=", "time", ".", "time", "(", ")", "\n", "metrics", ".", "update", "(", "outputs", ")", "\n", "if", "writer", "is", "not", "None", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "for", "group_i", ",", "param_group", "in", "enumerate", "(", "optimizer", ".", "param_groups", ")", ":", "\n", "                        ", "writer", ".", "add_scalar", "(", "tag", "=", "'Initial-LR/Group_{}'", ".", "format", "(", "group_i", ")", ",", "\n", "scalar_value", "=", "param_group", "[", "'initial_lr'", "]", ",", "\n", "global_step", "=", "global_steps", ")", "\n", "writer", ".", "add_scalar", "(", "tag", "=", "'LR/Group_{}'", ".", "format", "(", "group_i", ")", ",", "\n", "scalar_value", "=", "param_group", "[", "'lr'", "]", ",", "\n", "global_step", "=", "global_steps", ")", "\n", "", "writer", ".", "add_scalar", "(", "tag", "=", "'Train-Loss'", ",", "\n", "scalar_value", "=", "float", "(", "loss", ".", "item", "(", ")", ")", ",", "\n", "global_step", "=", "global_steps", ")", "\n", "name", ",", "value", "=", "metrics", ".", "get", "(", ")", "\n", "for", "n", ",", "v", "in", "zip", "(", "name", ",", "value", ")", ":", "\n", "                        ", "writer", ".", "add_scalar", "(", "tag", "=", "'Train-'", "+", "n", ",", "\n", "scalar_value", "=", "v", ",", "\n", "global_step", "=", "global_steps", ")", "\n", "\n", "", "", "", "metric_time", "=", "time", ".", "time", "(", ")", "-", "metric_time", "\n", "\n", "# execute batch_end_callbacks", "\n", "if", "batch_end_callbacks", "is", "not", "None", ":", "\n", "                ", "batch_end_params", "=", "BatchEndParam", "(", "epoch", "=", "epoch", ",", "nbatch", "=", "nbatch", ",", "add_step", "=", "True", ",", "rank", "=", "rank", ",", "\n", "data_in_time", "=", "data_in_time", ",", "data_transfer_time", "=", "data_transfer_time", ",", "\n", "forward_time", "=", "forward_time", ",", "backward_time", "=", "backward_time", ",", "\n", "optimizer_time", "=", "optimizer_time", ",", "metric_time", "=", "metric_time", ",", "\n", "eval_metric", "=", "metrics", ",", "locals", "=", "locals", "(", ")", ")", "\n", "_multiple_callbacks", "(", "batch_end_callbacks", ",", "batch_end_params", ")", "\n", "\n", "# update end time", "\n", "", "end_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# excute epoch_end_callbacks", "\n", "", "if", "validation_monitor", "is", "not", "None", ":", "\n", "            ", "validation_monitor", "(", "epoch", ",", "net", ",", "optimizer", ",", "writer", ")", "\n", "", "if", "epoch_end_callbacks", "is", "not", "None", ":", "\n", "            ", "_multiple_callbacks", "(", "epoch_end_callbacks", ",", "epoch", ",", "net", ",", "optimizer", ",", "writer", ",", "validation_monitor", "=", "validation_monitor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.__init__": [[9, 12], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "Module", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.init_weight": [[13, 15], ["NotImplementedError"], "methods", ["None"], ["", "def", "init_weight", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.fix_params": [[16, 18], ["NotImplementedError"], "methods", ["None"], ["", "def", "fix_params", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.forward": [[19, 25], ["module.Module.preprocess", "module.Module.train_forward", "module.Module.inference_forward"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.preprocess", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.train_forward", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.inference_forward"], ["", "def", "forward", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "inputs", ",", "kwargs", "=", "self", ".", "preprocess", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "train_forward", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "inference_forward", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.train_forward": [[26, 43], ["None"], "methods", ["None"], ["", "", "def", "train_forward", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        def train_forward(self, data, label, **kwargs):\n            # this is a toy example for 1 output, 2 loss function\n\n            output = None\n            loss1 = torch.tensor(0.0)\n            loss2 = torch.tensor(0.0)\n\n            outputs = {'output': output,\n                       'loss1': loss1,\n                       'loss2': loss2}\n            loss = loss1 + loss2\n\n            return outputs, loss\n        \"\"\"", "\n", "raise", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.inference_forward": [[44, 52], ["None"], "methods", ["None"], ["", "def", "inference_forward", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        def inference_forward(self, data, **kwargs):\n            output = None\n            outputs = {'output': output}\n            return outputs\n        \"\"\"", "\n", "raise", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.preprocess": [[53, 58], ["module.Module.train_preprocess", "module.Module.inference_preprocess"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.train_preprocess", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.inference_preprocess"], ["", "def", "preprocess", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "return", "self", ".", "train_preprocess", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "inference_preprocess", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.train_preprocess": [[59, 61], ["None"], "methods", ["None"], ["", "", "def", "train_preprocess", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "inputs", ",", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.module.Module.inference_preprocess": [[62, 64], ["None"], "methods", ["None"], ["", "def", "inference_preprocess", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "inputs", ",", "kwargs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.lr_scheduler.WarmupMultiStepLR.__init__": [[11, 38], ["super().__init__", "ValueError", "ValueError", "list", "sorted"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ",", "\n", "milestones", ",", "\n", "gamma", "=", "0.1", ",", "\n", "warmup_factor", "=", "1.0", "/", "3", ",", "\n", "warmup_iters", "=", "500", ",", "\n", "warmup_method", "=", "\"linear\"", ",", "\n", "last_epoch", "=", "-", "1", ",", "\n", ")", ":", "\n", "        ", "if", "not", "list", "(", "milestones", ")", "==", "sorted", "(", "milestones", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Milestones should be a list of\"", "\" increasing integers. Got {}\"", ",", "\n", "milestones", ",", "\n", ")", "\n", "\n", "", "if", "warmup_method", "not", "in", "(", "\"constant\"", ",", "\"linear\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Only 'constant' or 'linear' warmup_method accepted\"", "\n", "\"got {}\"", ".", "format", "(", "warmup_method", ")", "\n", ")", "\n", "", "self", ".", "milestones", "=", "milestones", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "warmup_factor", "=", "warmup_factor", "\n", "self", ".", "warmup_iters", "=", "warmup_iters", "\n", "self", ".", "warmup_method", "=", "warmup_method", "\n", "super", "(", "WarmupMultiStepLR", ",", "self", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.lr_scheduler.WarmupMultiStepLR.get_lr": [[39, 52], ["bisect.bisect_right"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "warmup_factor", "=", "1", "\n", "if", "self", ".", "last_epoch", "<", "self", ".", "warmup_iters", ":", "\n", "            ", "if", "self", ".", "warmup_method", "==", "\"constant\"", ":", "\n", "                ", "warmup_factor", "=", "self", ".", "warmup_factor", "\n", "", "elif", "self", ".", "warmup_method", "==", "\"linear\"", ":", "\n", "                ", "alpha", "=", "self", ".", "last_epoch", "/", "self", ".", "warmup_iters", "\n", "warmup_factor", "=", "self", ".", "warmup_factor", "*", "(", "1", "-", "alpha", ")", "+", "alpha", "\n", "", "", "return", "[", "\n", "base_lr", "\n", "*", "warmup_factor", "\n", "*", "self", ".", "gamma", "**", "bisect_right", "(", "self", ".", "milestones", ",", "self", ".", "last_epoch", ")", "\n", "for", "base_lr", "in", "self", ".", "base_lrs", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.BaseModel.__init__": [[10, 13], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "config", "=", "config", "\n", "super", "(", "BaseModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.BaseModel.init_weights": [[14, 26], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "BertLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.BaseModel.forward": [[27, 29], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBert.__init__": [[32, 85], ["visual_linguistic_bert.BaseModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "external.pytorch_pretrained_bert.modeling.BertLayerNorm", "torch.Dropout", "torch.Dropout", "external.pytorch_pretrained_bert.modeling.BertEncoder", "visual_linguistic_bert.VisualLinguisticBert.apply", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "external.pytorch_pretrained_bert.modeling.BertLayerNorm", "external.pytorch_pretrained_bert.modeling.BertLayerNorm", "torch.Parameter", "torch.Parameter", "visual_linguistic_bert.VisualLinguisticBert.register_parameter", "torch.Parameter", "torch.Parameter", "visual_linguistic_bert.VisualLinguisticBert.register_parameter", "external.pytorch_pretrained_bert.modeling.BertPooler", "visual_linguistic_bert.VisualLinguisticBert.visual_ln_text.weight.data.fill_", "visual_linguistic_bert.VisualLinguisticBert.visual_ln_object.weight.data.fill_", "visual_linguistic_bert.VisualLinguisticBert.load_language_pretrained_model", "visual_linguistic_bert.VisualLinguisticBert.word_embeddings.parameters", "torch.Embedding", "torch.Embedding", "visual_linguistic_bert.VisualLinguisticBert.special_word_embeddings.weight.data.copy_", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertEncoder.load_language_pretrained_model"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "language_pretrained_model_path", "=", "None", ")", ":", "\n", "        ", "super", "(", "VisualLinguisticBert", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "config", "=", "config", "\n", "\n", "# embeddings", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "end_embedding", "=", "nn", ".", "Embedding", "(", "1", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "embedding_LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "embedding_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "# for compatibility of roberta", "\n", "self", ".", "position_padding_idx", "=", "config", ".", "position_padding_idx", "\n", "\n", "# visual transform", "\n", "self", ".", "visual_1x1_text", "=", "None", "\n", "self", ".", "visual_1x1_object", "=", "None", "\n", "if", "config", ".", "visual_size", "!=", "config", ".", "hidden_size", ":", "\n", "            ", "self", ".", "visual_1x1_text", "=", "nn", ".", "Linear", "(", "config", ".", "visual_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "visual_1x1_object", "=", "nn", ".", "Linear", "(", "config", ".", "visual_size", ",", "config", ".", "hidden_size", ")", "\n", "", "if", "config", ".", "visual_ln", ":", "\n", "            ", "self", ".", "visual_ln_text", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "visual_ln_object", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "", "else", ":", "\n", "            ", "visual_scale_text", "=", "nn", ".", "Parameter", "(", "torch", ".", "as_tensor", "(", "self", ".", "config", ".", "visual_scale_text_init", ",", "dtype", "=", "torch", ".", "float", ")", ",", "\n", "requires_grad", "=", "True", ")", "\n", "self", ".", "register_parameter", "(", "'visual_scale_text'", ",", "visual_scale_text", ")", "\n", "visual_scale_object", "=", "nn", ".", "Parameter", "(", "torch", ".", "as_tensor", "(", "self", ".", "config", ".", "visual_scale_object_init", ",", "dtype", "=", "torch", ".", "float", ")", ",", "\n", "requires_grad", "=", "True", ")", "\n", "self", ".", "register_parameter", "(", "'visual_scale_object'", ",", "visual_scale_object", ")", "\n", "\n", "", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "\n", "if", "self", ".", "config", ".", "with_pooler", ":", "\n", "            ", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "# init weights", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "if", "config", ".", "visual_ln", ":", "\n", "            ", "self", ".", "visual_ln_text", ".", "weight", ".", "data", ".", "fill_", "(", "self", ".", "config", ".", "visual_scale_text_init", ")", "\n", "self", ".", "visual_ln_object", ".", "weight", ".", "data", ".", "fill_", "(", "self", ".", "config", ".", "visual_scale_object_init", ")", "\n", "\n", "# load language pretrained model", "\n", "", "if", "language_pretrained_model_path", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_language_pretrained_model", "(", "language_pretrained_model_path", ")", "\n", "\n", "", "if", "config", ".", "word_embedding_frozen", ":", "\n", "            ", "for", "p", "in", "self", ".", "word_embeddings", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "", "self", ".", "special_word_embeddings", "=", "nn", ".", "Embedding", "(", "NUM_SPECIAL_WORDS", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "special_word_embeddings", ".", "weight", ".", "data", ".", "copy_", "(", "self", ".", "word_embeddings", ".", "weight", ".", "data", "[", ":", "NUM_SPECIAL_WORDS", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBert.word_embeddings_wrapper": [[86, 94], ["visual_linguistic_bert.VisualLinguisticBert.word_embeddings", "visual_linguistic_bert.VisualLinguisticBert.special_word_embeddings", "visual_linguistic_bert.VisualLinguisticBert.word_embeddings"], "methods", ["None"], ["", "", "def", "word_embeddings_wrapper", "(", "self", ",", "input_ids", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "word_embedding_frozen", ":", "\n", "            ", "word_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "word_embeddings", "[", "input_ids", "<", "NUM_SPECIAL_WORDS", "]", "=", "self", ".", "special_word_embeddings", "(", "input_ids", "[", "input_ids", "<", "NUM_SPECIAL_WORDS", "]", ")", "\n", "return", "word_embeddings", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBert.forward": [[95, 172], ["visual_linguistic_bert.VisualLinguisticBert.embedding", "attention_mask.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "visual_linguistic_bert.VisualLinguisticBert.encoder", "visual_linguistic_bert.VisualLinguisticBert.encoder", "visual_linguistic_bert.VisualLinguisticBert.pooler", "attention_mask.unsqueeze", "encoded_layer.new_zeros", "encoded_layers_text.append", "encoded_layers_object.append", "next", "visual_linguistic_bert.VisualLinguisticBert.parameters"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBert.embedding"], ["", "", "def", "forward", "(", "self", ",", "\n", "text_input_ids", ",", "\n", "text_token_type_ids", ",", "\n", "text_visual_embeddings", ",", "\n", "text_mask", ",", "\n", "object_vl_embeddings", ",", "\n", "object_mask", ",", "\n", "output_all_encoded_layers", "=", "True", ",", "\n", "output_text_and_object_separately", "=", "False", ",", "\n", "output_attention_probs", "=", "False", ")", ":", "\n", "\n", "# get seamless concatenate embeddings and mask", "\n", "        ", "embedding_output", ",", "attention_mask", ",", "text_mask_new", ",", "object_mask_new", "=", "self", ".", "embedding", "(", "text_input_ids", ",", "\n", "text_token_type_ids", ",", "\n", "text_visual_embeddings", ",", "\n", "text_mask", ",", "\n", "object_vl_embeddings", ",", "\n", "object_mask", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "# extended_attention_mask = 1.0 - extended_attention_mask", "\n", "# extended_attention_mask[extended_attention_mask != 0] = float('-inf')", "\n", "\n", "if", "output_attention_probs", ":", "\n", "            ", "encoded_layers", ",", "attention_probs", "=", "self", ".", "encoder", "(", "embedding_output", ",", "\n", "extended_attention_mask", ",", "\n", "output_all_encoded_layers", "=", "output_all_encoded_layers", ",", "\n", "output_attention_probs", "=", "output_attention_probs", ")", "\n", "", "else", ":", "\n", "            ", "encoded_layers", "=", "self", ".", "encoder", "(", "embedding_output", ",", "\n", "extended_attention_mask", ",", "\n", "output_all_encoded_layers", "=", "output_all_encoded_layers", ",", "\n", "output_attention_probs", "=", "output_attention_probs", ")", "\n", "", "sequence_output", "=", "encoded_layers", "[", "-", "1", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "if", "self", ".", "config", ".", "with_pooler", "else", "None", "\n", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "encoded_layers", "=", "encoded_layers", "[", "-", "1", "]", "\n", "\n", "", "if", "output_text_and_object_separately", ":", "\n", "            ", "if", "not", "output_all_encoded_layers", ":", "\n", "                ", "encoded_layers", "=", "[", "encoded_layers", "]", "\n", "", "encoded_layers_text", "=", "[", "]", "\n", "encoded_layers_object", "=", "[", "]", "\n", "for", "encoded_layer", "in", "encoded_layers", ":", "\n", "                ", "max_text_len", "=", "text_input_ids", ".", "shape", "[", "1", "]", "\n", "max_object_len", "=", "object_vl_embeddings", ".", "shape", "[", "1", "]", "\n", "encoded_layer_text", "=", "encoded_layer", "[", ":", ",", ":", "max_text_len", "]", "\n", "encoded_layer_object", "=", "encoded_layer", ".", "new_zeros", "(", "\n", "(", "encoded_layer", ".", "shape", "[", "0", "]", ",", "max_object_len", ",", "encoded_layer", ".", "shape", "[", "2", "]", ")", ")", "\n", "encoded_layer_object", "[", "object_mask", "]", "=", "encoded_layer", "[", "object_mask_new", "]", "\n", "encoded_layers_text", ".", "append", "(", "encoded_layer_text", ")", "\n", "encoded_layers_object", ".", "append", "(", "encoded_layer_object", ")", "\n", "", "if", "not", "output_all_encoded_layers", ":", "\n", "                ", "encoded_layers_text", "=", "encoded_layers_text", "[", "0", "]", "\n", "encoded_layers_object", "=", "encoded_layers_object", "[", "0", "]", "\n", "", "if", "output_attention_probs", ":", "\n", "                ", "return", "encoded_layers_text", ",", "encoded_layers_object", ",", "pooled_output", ",", "attention_probs", "\n", "", "else", ":", "\n", "                ", "return", "encoded_layers_text", ",", "encoded_layers_object", ",", "pooled_output", "\n", "", "", "else", ":", "\n", "            ", "if", "output_attention_probs", ":", "\n", "                ", "return", "encoded_layers", ",", "pooled_output", ",", "attention_probs", "\n", "", "else", ":", "\n", "                ", "return", "encoded_layers", ",", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBert.embedding": [[173, 248], ["visual_linguistic_bert.VisualLinguisticBert.word_embeddings_wrapper", "text_vl_embeddings.size", "text_vl_embeddings.size", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "text_mask.sum", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "text_vl_embeddings.new_zeros", "visual_linguistic_bert.VisualLinguisticBert.end_embedding", "text_token_type_ids.new_zeros", "visual_linguistic_bert.VisualLinguisticBert.token_type_embeddings", "visual_linguistic_bert.VisualLinguisticBert.position_embeddings", "text_mask.new_zeros", "visual_linguistic_bert.VisualLinguisticBert.embedding_LayerNorm", "visual_linguistic_bert.VisualLinguisticBert.embedding_dropout", "visual_linguistic_bert.VisualLinguisticBert.visual_1x1_text", "visual_linguistic_bert.VisualLinguisticBert.visual_ln_text", "visual_linguistic_bert.VisualLinguisticBert.visual_1x1_object", "visual_linguistic_bert.VisualLinguisticBert.visual_ln_object", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "object_mask.sum", "text_mask.sum", "object_mask.sum", "text_mask.sum.expand"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBert.word_embeddings_wrapper"], ["", "", "", "def", "embedding", "(", "self", ",", "\n", "text_input_ids", ",", "\n", "text_token_type_ids", ",", "\n", "text_visual_embeddings", ",", "\n", "text_mask", ",", "\n", "object_vl_embeddings", ",", "\n", "object_mask", ")", ":", "\n", "\n", "\n", "        ", "text_linguistic_embedding", "=", "self", ".", "word_embeddings_wrapper", "(", "text_input_ids", ")", "\n", "if", "self", ".", "visual_1x1_text", "is", "not", "None", ":", "\n", "            ", "text_visual_embeddings", "=", "self", ".", "visual_1x1_text", "(", "text_visual_embeddings", ")", "\n", "", "if", "self", ".", "config", ".", "visual_ln", ":", "\n", "            ", "text_visual_embeddings", "=", "self", ".", "visual_ln_text", "(", "text_visual_embeddings", ")", "\n", "", "else", ":", "\n", "            ", "text_visual_embeddings", "*=", "self", ".", "visual_scale_text", "\n", "", "text_vl_embeddings", "=", "text_linguistic_embedding", "+", "text_visual_embeddings", "\n", "\n", "object_visual_embeddings", "=", "object_vl_embeddings", "[", ":", ",", ":", ",", ":", "self", ".", "config", ".", "visual_size", "]", "\n", "if", "self", ".", "visual_1x1_object", "is", "not", "None", ":", "\n", "            ", "object_visual_embeddings", "=", "self", ".", "visual_1x1_object", "(", "object_visual_embeddings", ")", "\n", "", "if", "self", ".", "config", ".", "visual_ln", ":", "\n", "            ", "object_visual_embeddings", "=", "self", ".", "visual_ln_object", "(", "object_visual_embeddings", ")", "\n", "", "else", ":", "\n", "            ", "object_visual_embeddings", "*=", "self", ".", "visual_scale_object", "\n", "", "object_linguistic_embeddings", "=", "object_vl_embeddings", "[", ":", ",", ":", ",", "self", ".", "config", ".", "visual_size", ":", "]", "\n", "object_vl_embeddings", "=", "object_linguistic_embeddings", "+", "object_visual_embeddings", "\n", "\n", "bs", "=", "text_vl_embeddings", ".", "size", "(", "0", ")", "\n", "vl_embed_size", "=", "text_vl_embeddings", ".", "size", "(", "-", "1", ")", "\n", "max_length", "=", "(", "text_mask", ".", "sum", "(", "1", ")", "+", "object_mask", ".", "sum", "(", "1", ")", ")", ".", "max", "(", ")", "+", "1", "\n", "grid_ind", ",", "grid_pos", "=", "torch", ".", "meshgrid", "(", "torch", ".", "arange", "(", "bs", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "text_vl_embeddings", ".", "device", ")", ",", "\n", "torch", ".", "arange", "(", "max_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "text_vl_embeddings", ".", "device", ")", ")", "\n", "text_end", "=", "text_mask", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "object_end", "=", "text_end", "+", "object_mask", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "# seamlessly concatenate visual linguistic embeddings of text and object", "\n", "# FM note: everything that's masked is left as zeros, everything that is not masked", "\n", "#          is replaced by the actual embeddings. Max length is the maximum plus 1 ", "\n", "#           of each batch of un-masked inputs (implies longest example in batch does fit..?)", "\n", "#      grid pos: simply 0,1,2,3,4... position id for each example in the batch", "\n", "_zero_id", "=", "torch", ".", "zeros", "(", "(", "bs", ",", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "text_vl_embeddings", ".", "device", ")", "\n", "vl_embeddings", "=", "text_vl_embeddings", ".", "new_zeros", "(", "(", "bs", ",", "max_length", ",", "vl_embed_size", ")", ")", "\n", "vl_embeddings", "[", "grid_pos", "<", "text_end", "]", "=", "text_vl_embeddings", "[", "text_mask", "]", "\n", "vl_embeddings", "[", "(", "grid_pos", ">=", "text_end", ")", "&", "(", "grid_pos", "<", "object_end", ")", "]", "=", "object_vl_embeddings", "[", "object_mask", "]", "\n", "vl_embeddings", "[", "grid_pos", "==", "object_end", "]", "=", "self", ".", "end_embedding", "(", "_zero_id", ")", "\n", "\n", "\n", "# token type embeddings/ segment embeddings", "\n", "token_type_ids", "=", "text_token_type_ids", ".", "new_zeros", "(", "(", "bs", ",", "max_length", ")", ")", "\n", "token_type_ids", "[", "grid_pos", "<", "text_end", "]", "=", "text_token_type_ids", "[", "text_mask", "]", "\n", "token_type_ids", "[", "(", "grid_pos", ">=", "text_end", ")", "&", "(", "grid_pos", "<=", "object_end", ")", "]", "=", "2", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "# position embeddings", "\n", "position_ids", "=", "grid_pos", "+", "self", ".", "position_padding_idx", "+", "1", "\n", "if", "self", ".", "config", ".", "obj_pos_id_relative", ":", "\n", "            ", "position_ids", "[", "(", "grid_pos", ">=", "text_end", ")", "&", "(", "grid_pos", "<", "object_end", ")", "]", "=", "text_end", ".", "expand", "(", "(", "bs", ",", "max_length", ")", ")", "[", "(", "grid_pos", ">=", "text_end", ")", "&", "(", "grid_pos", "<", "object_end", ")", "]", "+", "self", ".", "position_padding_idx", "+", "1", "\n", "position_ids", "[", "grid_pos", "==", "object_end", "]", "=", "(", "text_end", "+", "1", ")", ".", "squeeze", "(", "1", ")", "+", "self", ".", "position_padding_idx", "+", "1", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "\"Don't use position id 510/511 for objects and [END]!!!\"", "\n", "position_ids", "[", "(", "grid_pos", ">=", "text_end", ")", "&", "(", "grid_pos", "<", "object_end", ")", "]", "=", "self", ".", "config", ".", "max_position_embeddings", "-", "2", "\n", "position_ids", "[", "grid_pos", "==", "object_end", "]", "=", "self", ".", "config", ".", "max_position_embeddings", "-", "1", "\n", "\n", "", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "mask", "=", "text_mask", ".", "new_zeros", "(", "(", "bs", ",", "max_length", ")", ")", "\n", "mask", "[", "grid_pos", "<=", "object_end", "]", "=", "1", "\n", "\n", "embeddings", "=", "vl_embeddings", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "embedding_LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "embedding_dropout", "(", "embeddings", ")", "\n", "\n", "return", "embeddings", ",", "mask", ",", "grid_pos", "<", "text_end", ",", "(", "grid_pos", ">=", "text_end", ")", "&", "(", "grid_pos", "<", "object_end", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBert.load_language_pretrained_model": [[249, 316], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load.items", "torch.load.items", "visual_linguistic_bert.VisualLinguisticBert.embedding_LayerNorm.load_state_dict", "visual_linguistic_bert.VisualLinguisticBert.encoder.load_state_dict", "k.replace.replace.startswith", "k.replace.replace.startswith", "len", "print", "visual_linguistic_bert.VisualLinguisticBert.pooler.load_state_dict", "k.replace.replace.startswith", "k.replace.replace.replace", "k.replace.replace.replace", "k.replace.replace.startswith", "len", "unexpected_keys.append", "visual_linguistic_bert.VisualLinguisticBert.encoder.state_dict", "unexpected_keys.append", "len", "len", "v.to", "k.replace.replace.startswith", "unexpected_keys.append", "len", "len", "v.to", "visual_linguistic_bert.VisualLinguisticBert.pooler.state_dict", "unexpected_keys.append", "v.to", "k_.startswith", "len", "v.size", "v[].clone().to", "v[].clone().to", "unexpected_keys.append", "v.size", "visual_linguistic_bert.VisualLinguisticBert.embedding_LayerNorm.state_dict", "unexpected_keys.append", "v[].clone", "v[].clone", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict"], ["", "def", "load_language_pretrained_model", "(", "self", ",", "language_pretrained_model_path", ")", ":", "\n", "        ", "pretrained_state_dict", "=", "torch", ".", "load", "(", "language_pretrained_model_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "encoder_pretrained_state_dict", "=", "{", "}", "\n", "pooler_pretrained_state_dict", "=", "{", "}", "\n", "embedding_ln_pretrained_state_dict", "=", "{", "}", "\n", "unexpected_keys", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "pretrained_state_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", ".", "startswith", "(", "'bert.'", ")", ":", "\n", "                ", "k", "=", "k", "[", "len", "(", "'bert.'", ")", ":", "]", "\n", "", "elif", "k", ".", "startswith", "(", "'roberta.'", ")", ":", "\n", "                ", "k", "=", "k", "[", "len", "(", "'roberta.'", ")", ":", "]", "\n", "", "else", ":", "\n", "                ", "unexpected_keys", ".", "append", "(", "k", ")", "\n", "continue", "\n", "", "if", "'gamma'", "in", "k", ":", "\n", "                ", "k", "=", "k", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "k", ":", "\n", "                ", "k", "=", "k", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "k", ".", "startswith", "(", "'encoder.'", ")", ":", "\n", "                ", "k_", "=", "k", "[", "len", "(", "'encoder.'", ")", ":", "]", "\n", "if", "k_", "in", "self", ".", "encoder", ".", "state_dict", "(", ")", ":", "\n", "                    ", "encoder_pretrained_state_dict", "[", "k_", "]", "=", "v", "\n", "", "else", ":", "\n", "                    ", "unexpected_keys", ".", "append", "(", "k", ")", "\n", "", "", "elif", "k", ".", "startswith", "(", "'embeddings.'", ")", ":", "\n", "                ", "k_", "=", "k", "[", "len", "(", "'embeddings.'", ")", ":", "]", "\n", "if", "k_", "==", "'word_embeddings.weight'", ":", "\n", "                    ", "self", ".", "word_embeddings", ".", "weight", ".", "data", "=", "v", ".", "to", "(", "dtype", "=", "self", ".", "word_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "word_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "", "elif", "k_", "==", "'position_embeddings.weight'", ":", "\n", "                    ", "self", ".", "position_embeddings", ".", "weight", ".", "data", "=", "v", ".", "to", "(", "dtype", "=", "self", ".", "position_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "position_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "", "elif", "k_", "==", "'token_type_embeddings.weight'", ":", "\n", "                    ", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", ":", "v", ".", "size", "(", "0", ")", "]", "=", "v", ".", "to", "(", "\n", "dtype", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "if", "v", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "# Todo: roberta token type embedding", "\n", "                        ", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "1", "]", "=", "v", "[", "0", "]", ".", "clone", "(", ")", ".", "to", "(", "\n", "dtype", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "2", "]", "=", "v", "[", "0", "]", ".", "clone", "(", ")", ".", "to", "(", "\n", "dtype", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "\n", "", "", "elif", "k_", ".", "startswith", "(", "'LayerNorm.'", ")", ":", "\n", "                    ", "k__", "=", "k_", "[", "len", "(", "'LayerNorm.'", ")", ":", "]", "\n", "if", "k__", "in", "self", ".", "embedding_LayerNorm", ".", "state_dict", "(", ")", ":", "\n", "                        ", "embedding_ln_pretrained_state_dict", "[", "k__", "]", "=", "v", "\n", "", "else", ":", "\n", "                        ", "unexpected_keys", ".", "append", "(", "k", ")", "\n", "", "", "else", ":", "\n", "                    ", "unexpected_keys", ".", "append", "(", "k", ")", "\n", "", "", "elif", "self", ".", "config", ".", "with_pooler", "and", "k", ".", "startswith", "(", "'pooler.'", ")", ":", "\n", "                ", "k_", "=", "k", "[", "len", "(", "'pooler.'", ")", ":", "]", "\n", "if", "k_", "in", "self", ".", "pooler", ".", "state_dict", "(", ")", ":", "\n", "                    ", "pooler_pretrained_state_dict", "[", "k_", "]", "=", "v", "\n", "", "else", ":", "\n", "                    ", "unexpected_keys", ".", "append", "(", "k", ")", "\n", "", "", "else", ":", "\n", "                ", "unexpected_keys", ".", "append", "(", "k", ")", "\n", "", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "print", "(", "\"Warnings: Unexpected keys: {}.\"", ".", "format", "(", "unexpected_keys", ")", ")", "\n", "", "self", ".", "embedding_LayerNorm", ".", "load_state_dict", "(", "embedding_ln_pretrained_state_dict", ")", "\n", "self", ".", "encoder", ".", "load_state_dict", "(", "encoder_pretrained_state_dict", ")", "\n", "if", "self", ".", "config", ".", "with_pooler", "and", "len", "(", "pooler_pretrained_state_dict", ")", ">", "0", ":", "\n", "            ", "self", ".", "pooler", ".", "load_state_dict", "(", "pooler_pretrained_state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertForPretraining.__init__": [[319, 351], ["visual_linguistic_bert.VisualLinguisticBert.__init__", "visual_linguistic_bert.VisualLinguisticBertForPretraining.apply", "visual_linguistic_bert.VisualLinguisticBertRelationshipPredictionHead", "external.pytorch_pretrained_bert.modeling.BertOnlyMLMHead", "visual_linguistic_bert.VisualLinguisticBertMVRCHead", "visual_linguistic_bert.VisualLinguisticBertForPretraining.visual_ln_text.weight.data.fill_", "visual_linguistic_bert.VisualLinguisticBertForPretraining.visual_ln_object.weight.data.fill_", "visual_linguistic_bert.VisualLinguisticBertForPretraining.load_language_pretrained_model", "visual_linguistic_bert.VisualLinguisticBertForPretraining.word_embeddings.parameters", "visual_linguistic_bert.VisualLinguisticBertForPretraining.position_embeddings.parameters"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertEncoder.load_language_pretrained_model"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "language_pretrained_model_path", "=", "None", ",", "\n", "with_rel_head", "=", "True", ",", "with_mlm_head", "=", "True", ",", "with_mvrc_head", "=", "True", ")", ":", "\n", "\n", "        ", "super", "(", "VisualLinguisticBertForPretraining", ",", "self", ")", ".", "__init__", "(", "config", ",", "language_pretrained_model_path", "=", "None", ")", "\n", "\n", "self", ".", "with_rel_head", "=", "with_rel_head", "\n", "self", ".", "with_mlm_head", "=", "with_mlm_head", "\n", "self", ".", "with_mvrc_head", "=", "with_mvrc_head", "\n", "if", "with_rel_head", ":", "\n", "            ", "self", ".", "relationsip_head", "=", "VisualLinguisticBertRelationshipPredictionHead", "(", "config", ")", "\n", "", "if", "with_mlm_head", ":", "\n", "            ", "self", ".", "mlm_head", "=", "BertOnlyMLMHead", "(", "config", ",", "self", ".", "word_embeddings", ".", "weight", ")", "\n", "", "if", "with_mvrc_head", ":", "\n", "            ", "self", ".", "mvrc_head", "=", "VisualLinguisticBertMVRCHead", "(", "config", ")", "\n", "\n", "# init weights", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "if", "config", ".", "visual_ln", ":", "\n", "            ", "self", ".", "visual_ln_text", ".", "weight", ".", "data", ".", "fill_", "(", "self", ".", "config", ".", "visual_scale_text_init", ")", "\n", "self", ".", "visual_ln_object", ".", "weight", ".", "data", ".", "fill_", "(", "self", ".", "config", ".", "visual_scale_object_init", ")", "\n", "\n", "# load language pretrained model", "\n", "", "if", "language_pretrained_model_path", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_language_pretrained_model", "(", "language_pretrained_model_path", ")", "\n", "\n", "", "if", "config", ".", "word_embedding_frozen", ":", "\n", "            ", "for", "p", "in", "self", ".", "word_embeddings", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "if", "config", ".", "pos_embedding_frozen", ":", "\n", "            ", "for", "p", "in", "self", ".", "position_embeddings", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertForPretraining.forward": [[352, 387], ["visual_linguistic_bert.VisualLinguisticBert.forward", "visual_linguistic_bert.VisualLinguisticBertForPretraining.relationsip_head", "visual_linguistic_bert.VisualLinguisticBertForPretraining.mlm_head", "visual_linguistic_bert.VisualLinguisticBertForPretraining.mvrc_head"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.forward"], ["", "", "", "def", "forward", "(", "self", ",", "\n", "text_input_ids", ",", "\n", "text_token_type_ids", ",", "\n", "text_visual_embeddings", ",", "\n", "text_mask", ",", "\n", "object_vl_embeddings", ",", "\n", "object_mask", ",", "\n", "output_all_encoded_layers", "=", "True", ",", "\n", "output_text_and_object_separately", "=", "False", ")", ":", "\n", "\n", "        ", "text_out", ",", "object_out", ",", "pooled_rep", "=", "super", "(", "VisualLinguisticBertForPretraining", ",", "self", ")", ".", "forward", "(", "\n", "text_input_ids", ",", "\n", "text_token_type_ids", ",", "\n", "text_visual_embeddings", ",", "\n", "text_mask", ",", "\n", "object_vl_embeddings", ",", "\n", "object_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ",", "\n", "output_text_and_object_separately", "=", "True", "\n", ")", "\n", "\n", "if", "self", ".", "with_rel_head", ":", "\n", "            ", "relationship_logits", "=", "self", ".", "relationsip_head", "(", "pooled_rep", ")", "\n", "", "else", ":", "\n", "            ", "relationship_logits", "=", "None", "\n", "", "if", "self", ".", "with_mlm_head", ":", "\n", "            ", "mlm_logits", "=", "self", ".", "mlm_head", "(", "text_out", ")", "\n", "", "else", ":", "\n", "            ", "mlm_logits", "=", "None", "\n", "", "if", "self", ".", "with_mvrc_head", ":", "\n", "            ", "mvrc_logits", "=", "self", ".", "mvrc_head", "(", "object_out", ")", "\n", "", "else", ":", "\n", "            ", "mvrc_logits", "=", "None", "\n", "\n", "", "return", "relationship_logits", ",", "mlm_logits", ",", "mvrc_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertForPretraining.load_language_pretrained_model": [[388, 478], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load.items", "torch.load.items", "visual_linguistic_bert.VisualLinguisticBertForPretraining.embedding_LayerNorm.load_state_dict", "visual_linguistic_bert.VisualLinguisticBertForPretraining.encoder.load_state_dict", "len", "print", "visual_linguistic_bert.VisualLinguisticBertForPretraining.pooler.load_state_dict", "visual_linguistic_bert.VisualLinguisticBertForPretraining.relationsip_head.caption_image_relationship.load_state_dict", "visual_linguistic_bert.VisualLinguisticBertForPretraining.mlm_head.predictions.load_state_dict", "_k.startswith", "_k.startswith", "k.replace.replace.startswith", "len", "len", "_k.startswith", "k.replace.replace.replace", "k.replace.replace.replace", "k.replace.replace.startswith", "_k.startswith", "visual_linguistic_bert.VisualLinguisticBertForPretraining.encoder.state_dict", "unexpected_keys.append", "k_.replace.replace.replace", "k_.replace.replace.replace", "visual_linguistic_bert.VisualLinguisticBertForPretraining.relationsip_head.caption_image_relationship.state_dict", "unexpected_keys.append", "_k.startswith", "unexpected_keys.append", "len", "len", "len", "v.to", "k.replace.replace.startswith", "len", "_k.startswith", "_k.startswith", "_k.startswith", "k_.replace.replace.replace", "k_.replace.replace.replace", "visual_linguistic_bert.VisualLinguisticBertForPretraining.mlm_head.predictions.state_dict", "unexpected_keys.append", "len", "v.to", "visual_linguistic_bert.VisualLinguisticBertForPretraining.pooler.state_dict", "unexpected_keys.append", "k_.replace.replace.replace", "v.to", "k_.replace.replace.startswith", "len", "len", "len", "v.size", "v[].to", "unexpected_keys.append", "v.size", "visual_linguistic_bert.VisualLinguisticBertForPretraining.embedding_LayerNorm.state_dict", "unexpected_keys.append", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict"], ["", "def", "load_language_pretrained_model", "(", "self", ",", "language_pretrained_model_path", ")", ":", "\n", "        ", "pretrained_state_dict", "=", "torch", ".", "load", "(", "language_pretrained_model_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "encoder_pretrained_state_dict", "=", "{", "}", "\n", "pooler_pretrained_state_dict", "=", "{", "}", "\n", "embedding_ln_pretrained_state_dict", "=", "{", "}", "\n", "relationship_head_pretrained_state_dict", "=", "{", "}", "\n", "mlm_head_pretrained_state_dict", "=", "{", "}", "\n", "unexpected_keys", "=", "[", "]", "\n", "for", "_k", ",", "v", "in", "pretrained_state_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "_k", ".", "startswith", "(", "'bert.'", ")", "or", "_k", ".", "startswith", "(", "'roberta.'", ")", ":", "\n", "                ", "k", "=", "_k", "[", "len", "(", "'bert.'", ")", ":", "]", "if", "_k", ".", "startswith", "(", "'bert.'", ")", "else", "_k", "[", "len", "(", "'roberta.'", ")", ":", "]", "\n", "if", "'gamma'", "in", "k", ":", "\n", "                    ", "k", "=", "k", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "k", ":", "\n", "                    ", "k", "=", "k", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "k", ".", "startswith", "(", "'encoder.'", ")", ":", "\n", "                    ", "k_", "=", "k", "[", "len", "(", "'encoder.'", ")", ":", "]", "\n", "if", "k_", "in", "self", ".", "encoder", ".", "state_dict", "(", ")", ":", "\n", "                        ", "encoder_pretrained_state_dict", "[", "k_", "]", "=", "v", "\n", "", "else", ":", "\n", "                        ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "elif", "k", ".", "startswith", "(", "'embeddings.'", ")", ":", "\n", "                    ", "k_", "=", "k", "[", "len", "(", "'embeddings.'", ")", ":", "]", "\n", "if", "k_", "==", "'word_embeddings.weight'", ":", "\n", "                        ", "self", ".", "word_embeddings", ".", "weight", ".", "data", "=", "v", ".", "to", "(", "dtype", "=", "self", ".", "word_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "word_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "", "elif", "k_", "==", "'position_embeddings.weight'", ":", "\n", "                        ", "self", ".", "position_embeddings", ".", "weight", ".", "data", "=", "v", ".", "to", "(", "dtype", "=", "self", ".", "position_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "position_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "", "elif", "k_", "==", "'token_type_embeddings.weight'", ":", "\n", "                        ", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", ":", "v", ".", "size", "(", "0", ")", "]", "=", "v", ".", "to", "(", "\n", "dtype", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "if", "v", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "# Todo: roberta token type embedding", "\n", "                            ", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "1", "]", "=", "v", "[", "0", "]", ".", "to", "(", "\n", "dtype", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "", "", "elif", "k_", ".", "startswith", "(", "'LayerNorm.'", ")", ":", "\n", "                        ", "k__", "=", "k_", "[", "len", "(", "'LayerNorm.'", ")", ":", "]", "\n", "if", "k__", "in", "self", ".", "embedding_LayerNorm", ".", "state_dict", "(", ")", ":", "\n", "                            ", "embedding_ln_pretrained_state_dict", "[", "k__", "]", "=", "v", "\n", "", "else", ":", "\n", "                            ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "else", ":", "\n", "                        ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "elif", "self", ".", "config", ".", "with_pooler", "and", "k", ".", "startswith", "(", "'pooler.'", ")", ":", "\n", "                    ", "k_", "=", "k", "[", "len", "(", "'pooler.'", ")", ":", "]", "\n", "if", "k_", "in", "self", ".", "pooler", ".", "state_dict", "(", ")", ":", "\n", "                        ", "pooler_pretrained_state_dict", "[", "k_", "]", "=", "v", "\n", "", "else", ":", "\n", "                        ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "", "elif", "_k", ".", "startswith", "(", "'cls.seq_relationship.'", ")", "and", "self", ".", "with_rel_head", ":", "\n", "                ", "k_", "=", "_k", "[", "len", "(", "'cls.seq_relationship.'", ")", ":", "]", "\n", "if", "'gamma'", "in", "k_", ":", "\n", "                    ", "k_", "=", "k_", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "k_", ":", "\n", "                    ", "k_", "=", "k_", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "k_", "in", "self", ".", "relationsip_head", ".", "caption_image_relationship", ".", "state_dict", "(", ")", ":", "\n", "                    ", "relationship_head_pretrained_state_dict", "[", "k_", "]", "=", "v", "\n", "", "else", ":", "\n", "                    ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "elif", "(", "_k", ".", "startswith", "(", "'cls.predictions.'", ")", "or", "_k", ".", "startswith", "(", "'lm_head.'", ")", ")", "and", "self", ".", "with_mlm_head", ":", "\n", "                ", "k_", "=", "_k", "[", "len", "(", "'cls.predictions.'", ")", ":", "]", "if", "_k", ".", "startswith", "(", "'cls.predictions.'", ")", "else", "_k", "[", "len", "(", "'lm_head.'", ")", ":", "]", "\n", "if", "_k", ".", "startswith", "(", "'lm_head.'", ")", ":", "\n", "                    ", "if", "'dense'", "in", "k_", "or", "'layer_norm'", "in", "k_", ":", "\n", "                        ", "k_", "=", "'transform.'", "+", "k_", "\n", "", "if", "'layer_norm'", "in", "k_", ":", "\n", "                        ", "k_", "=", "k_", ".", "replace", "(", "'layer_norm'", ",", "'LayerNorm'", ")", "\n", "", "", "if", "'gamma'", "in", "k_", ":", "\n", "                    ", "k_", "=", "k_", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "k_", ":", "\n", "                    ", "k_", "=", "k_", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "k_", "in", "self", ".", "mlm_head", ".", "predictions", ".", "state_dict", "(", ")", ":", "\n", "                    ", "mlm_head_pretrained_state_dict", "[", "k_", "]", "=", "v", "\n", "", "else", ":", "\n", "                    ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "else", ":", "\n", "                ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "print", "(", "\"Warnings: Unexpected keys: {}.\"", ".", "format", "(", "unexpected_keys", ")", ")", "\n", "", "self", ".", "embedding_LayerNorm", ".", "load_state_dict", "(", "embedding_ln_pretrained_state_dict", ")", "\n", "self", ".", "encoder", ".", "load_state_dict", "(", "encoder_pretrained_state_dict", ")", "\n", "if", "self", ".", "config", ".", "with_pooler", "and", "len", "(", "pooler_pretrained_state_dict", ")", ">", "0", ":", "\n", "            ", "self", ".", "pooler", ".", "load_state_dict", "(", "pooler_pretrained_state_dict", ")", "\n", "", "if", "self", ".", "with_rel_head", "and", "len", "(", "relationship_head_pretrained_state_dict", ")", ">", "0", "and", "relationship_head_pretrained_state_dict", "[", "'weight'", "]", ".", "shape", "[", "0", "]", "==", "self", ".", "relationsip_head", ".", "caption_image_relationship", ".", "weight", ".", "shape", "[", "0", "]", ":", "\n", "            ", "self", ".", "relationsip_head", ".", "caption_image_relationship", ".", "load_state_dict", "(", "relationship_head_pretrained_state_dict", ")", "\n", "", "if", "self", ".", "with_mlm_head", ":", "\n", "            ", "self", ".", "mlm_head", ".", "predictions", ".", "load_state_dict", "(", "mlm_head_pretrained_state_dict", ")", "\n", "# TODO: load MVRC head ", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertMVRCHeadTransform.__init__": [[481, 488], ["visual_linguistic_bert.BaseModel.__init__", "torch.Linear", "torch.Linear", "visual_linguistic_bert.VisualLinguisticBertMVRCHeadTransform.apply"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "VisualLinguisticBertMVRCHeadTransform", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "act", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertMVRCHeadTransform.forward": [[489, 494], ["visual_linguistic_bert.VisualLinguisticBertMVRCHeadTransform.dense", "visual_linguistic_bert.VisualLinguisticBertMVRCHeadTransform.act"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "act", "(", "hidden_states", ")", "\n", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertMVRCHead.__init__": [[497, 503], ["visual_linguistic_bert.BaseModel.__init__", "visual_linguistic_bert.VisualLinguisticBertMVRCHeadTransform", "torch.Linear", "torch.Linear", "visual_linguistic_bert.VisualLinguisticBertMVRCHead.apply"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "VisualLinguisticBertMVRCHead", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "transform", "=", "VisualLinguisticBertMVRCHeadTransform", "(", "config", ")", "\n", "self", ".", "region_cls_pred", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "visual_region_classes", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertMVRCHead.forward": [[504, 510], ["visual_linguistic_bert.VisualLinguisticBertMVRCHead.transform", "visual_linguistic_bert.VisualLinguisticBertMVRCHead.region_cls_pred"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "\n", "        ", "hidden_states", "=", "self", ".", "transform", "(", "hidden_states", ")", "\n", "logits", "=", "self", ".", "region_cls_pred", "(", "hidden_states", ")", "\n", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertRelationshipPredictionHead.__init__": [[513, 518], ["visual_linguistic_bert.BaseModel.__init__", "torch.Linear", "torch.Linear", "visual_linguistic_bert.VisualLinguisticBertRelationshipPredictionHead.apply"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "VisualLinguisticBertRelationshipPredictionHead", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "# FM edit - change to single output", "\n", "self", ".", "caption_image_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertRelationshipPredictionHead.forward": [[519, 524], ["visual_linguistic_bert.VisualLinguisticBertRelationshipPredictionHead.caption_image_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pooled_rep", ")", ":", "\n", "\n", "        ", "relationship_logits", "=", "self", ".", "caption_image_relationship", "(", "pooled_rep", ")", "\n", "\n", "return", "relationship_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertForDistance.__init__": [[531, 563], ["visual_linguistic_bert.VisualLinguisticBert.__init__", "visual_linguistic_bert.VisualLinguisticBertForDistance.apply", "visual_linguistic_bert.VisualLinguisticBertRelationshipPredictionHead", "external.pytorch_pretrained_bert.modeling.BertOnlyMLMHead", "visual_linguistic_bert.VisualLinguisticBertMVRCHead", "visual_linguistic_bert.VisualLinguisticBertForDistance.visual_ln_text.weight.data.fill_", "visual_linguistic_bert.VisualLinguisticBertForDistance.visual_ln_object.weight.data.fill_", "visual_linguistic_bert.VisualLinguisticBertForDistance.load_language_pretrained_model", "visual_linguistic_bert.VisualLinguisticBertForDistance.word_embeddings.parameters", "visual_linguistic_bert.VisualLinguisticBertForDistance.position_embeddings.parameters"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertEncoder.load_language_pretrained_model"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "language_pretrained_model_path", "=", "None", ",", "\n", "with_rel_head", "=", "True", ",", "with_mlm_head", "=", "True", ",", "with_mvrc_head", "=", "True", ")", ":", "\n", "\n", "        ", "super", "(", "VisualLinguisticBertForDistance", ",", "self", ")", ".", "__init__", "(", "config", ",", "language_pretrained_model_path", "=", "None", ")", "\n", "\n", "self", ".", "with_rel_head", "=", "with_rel_head", "\n", "self", ".", "with_mlm_head", "=", "with_mlm_head", "\n", "self", ".", "with_mvrc_head", "=", "with_mvrc_head", "\n", "if", "with_rel_head", ":", "\n", "            ", "self", ".", "relationsip_head", "=", "VisualLinguisticBertRelationshipPredictionHead", "(", "config", ")", "\n", "", "if", "with_mlm_head", ":", "\n", "            ", "self", ".", "mlm_head", "=", "BertOnlyMLMHead", "(", "config", ",", "self", ".", "word_embeddings", ".", "weight", ")", "\n", "", "if", "with_mvrc_head", ":", "\n", "            ", "self", ".", "mvrc_head", "=", "VisualLinguisticBertMVRCHead", "(", "config", ")", "\n", "\n", "# init weights", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "if", "config", ".", "visual_ln", ":", "\n", "            ", "self", ".", "visual_ln_text", ".", "weight", ".", "data", ".", "fill_", "(", "self", ".", "config", ".", "visual_scale_text_init", ")", "\n", "self", ".", "visual_ln_object", ".", "weight", ".", "data", ".", "fill_", "(", "self", ".", "config", ".", "visual_scale_object_init", ")", "\n", "\n", "# load language pretrained model", "\n", "", "if", "language_pretrained_model_path", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_language_pretrained_model", "(", "language_pretrained_model_path", ")", "\n", "\n", "", "if", "config", ".", "word_embedding_frozen", ":", "\n", "            ", "for", "p", "in", "self", ".", "word_embeddings", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "if", "config", ".", "pos_embedding_frozen", ":", "\n", "            ", "for", "p", "in", "self", ".", "position_embeddings", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertForDistance.forward": [[564, 599], ["visual_linguistic_bert.VisualLinguisticBert.forward", "visual_linguistic_bert.VisualLinguisticBertForDistance.relationsip_head", "visual_linguistic_bert.VisualLinguisticBertForDistance.mlm_head", "visual_linguistic_bert.VisualLinguisticBertForDistance.mvrc_head"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.forward"], ["", "", "", "def", "forward", "(", "self", ",", "\n", "text_input_ids", ",", "\n", "text_token_type_ids", ",", "\n", "text_visual_embeddings", ",", "\n", "text_mask", ",", "\n", "object_vl_embeddings", ",", "\n", "object_mask", ",", "\n", "output_all_encoded_layers", "=", "True", ",", "\n", "output_text_and_object_separately", "=", "False", ")", ":", "\n", "\n", "        ", "text_out", ",", "object_out", ",", "pooled_rep", "=", "super", "(", "VisualLinguisticBertForDistance", ",", "self", ")", ".", "forward", "(", "\n", "text_input_ids", ",", "\n", "text_token_type_ids", ",", "\n", "text_visual_embeddings", ",", "\n", "text_mask", ",", "\n", "object_vl_embeddings", ",", "\n", "object_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ",", "\n", "output_text_and_object_separately", "=", "True", "\n", ")", "\n", "\n", "if", "self", ".", "with_rel_head", ":", "\n", "            ", "relationship_logits", "=", "self", ".", "relationsip_head", "(", "pooled_rep", ")", "\n", "", "else", ":", "\n", "            ", "relationship_logits", "=", "None", "\n", "", "if", "self", ".", "with_mlm_head", ":", "\n", "            ", "mlm_logits", "=", "self", ".", "mlm_head", "(", "text_out", ")", "\n", "", "else", ":", "\n", "            ", "mlm_logits", "=", "None", "\n", "", "if", "self", ".", "with_mvrc_head", ":", "\n", "            ", "mvrc_logits", "=", "self", ".", "mvrc_head", "(", "object_out", ")", "\n", "", "else", ":", "\n", "            ", "mvrc_logits", "=", "None", "\n", "\n", "", "return", "relationship_logits", ",", "mlm_logits", ",", "mvrc_logits", ",", "pooled_rep", ",", "text_out", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertForDistance.load_language_pretrained_model": [[600, 690], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load.items", "torch.load.items", "visual_linguistic_bert.VisualLinguisticBertForDistance.embedding_LayerNorm.load_state_dict", "visual_linguistic_bert.VisualLinguisticBertForDistance.encoder.load_state_dict", "len", "print", "visual_linguistic_bert.VisualLinguisticBertForDistance.pooler.load_state_dict", "visual_linguistic_bert.VisualLinguisticBertForDistance.relationsip_head.caption_image_relationship.load_state_dict", "visual_linguistic_bert.VisualLinguisticBertForDistance.mlm_head.predictions.load_state_dict", "_k.startswith", "_k.startswith", "k.replace.replace.startswith", "len", "len", "_k.startswith", "k.replace.replace.replace", "k.replace.replace.replace", "k.replace.replace.startswith", "_k.startswith", "visual_linguistic_bert.VisualLinguisticBertForDistance.encoder.state_dict", "unexpected_keys.append", "k_.replace.replace.replace", "k_.replace.replace.replace", "visual_linguistic_bert.VisualLinguisticBertForDistance.relationsip_head.caption_image_relationship.state_dict", "unexpected_keys.append", "_k.startswith", "unexpected_keys.append", "len", "len", "len", "v.to", "k.replace.replace.startswith", "len", "_k.startswith", "_k.startswith", "_k.startswith", "k_.replace.replace.replace", "k_.replace.replace.replace", "visual_linguistic_bert.VisualLinguisticBertForDistance.mlm_head.predictions.state_dict", "unexpected_keys.append", "len", "v.to", "visual_linguistic_bert.VisualLinguisticBertForDistance.pooler.state_dict", "unexpected_keys.append", "k_.replace.replace.replace", "v.to", "k_.replace.replace.startswith", "len", "len", "len", "v.size", "v[].to", "unexpected_keys.append", "v.size", "visual_linguistic_bert.VisualLinguisticBertForDistance.embedding_LayerNorm.state_dict", "unexpected_keys.append", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict"], ["", "def", "load_language_pretrained_model", "(", "self", ",", "language_pretrained_model_path", ")", ":", "\n", "        ", "pretrained_state_dict", "=", "torch", ".", "load", "(", "language_pretrained_model_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "encoder_pretrained_state_dict", "=", "{", "}", "\n", "pooler_pretrained_state_dict", "=", "{", "}", "\n", "embedding_ln_pretrained_state_dict", "=", "{", "}", "\n", "relationship_head_pretrained_state_dict", "=", "{", "}", "\n", "mlm_head_pretrained_state_dict", "=", "{", "}", "\n", "unexpected_keys", "=", "[", "]", "\n", "for", "_k", ",", "v", "in", "pretrained_state_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "_k", ".", "startswith", "(", "'bert.'", ")", "or", "_k", ".", "startswith", "(", "'roberta.'", ")", ":", "\n", "                ", "k", "=", "_k", "[", "len", "(", "'bert.'", ")", ":", "]", "if", "_k", ".", "startswith", "(", "'bert.'", ")", "else", "_k", "[", "len", "(", "'roberta.'", ")", ":", "]", "\n", "if", "'gamma'", "in", "k", ":", "\n", "                    ", "k", "=", "k", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "k", ":", "\n", "                    ", "k", "=", "k", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "k", ".", "startswith", "(", "'encoder.'", ")", ":", "\n", "                    ", "k_", "=", "k", "[", "len", "(", "'encoder.'", ")", ":", "]", "\n", "if", "k_", "in", "self", ".", "encoder", ".", "state_dict", "(", ")", ":", "\n", "                        ", "encoder_pretrained_state_dict", "[", "k_", "]", "=", "v", "\n", "", "else", ":", "\n", "                        ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "elif", "k", ".", "startswith", "(", "'embeddings.'", ")", ":", "\n", "                    ", "k_", "=", "k", "[", "len", "(", "'embeddings.'", ")", ":", "]", "\n", "if", "k_", "==", "'word_embeddings.weight'", ":", "\n", "                        ", "self", ".", "word_embeddings", ".", "weight", ".", "data", "=", "v", ".", "to", "(", "dtype", "=", "self", ".", "word_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "word_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "", "elif", "k_", "==", "'position_embeddings.weight'", ":", "\n", "                        ", "self", ".", "position_embeddings", ".", "weight", ".", "data", "=", "v", ".", "to", "(", "dtype", "=", "self", ".", "position_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "position_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "", "elif", "k_", "==", "'token_type_embeddings.weight'", ":", "\n", "                        ", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", ":", "v", ".", "size", "(", "0", ")", "]", "=", "v", ".", "to", "(", "\n", "dtype", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "if", "v", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "# Todo: roberta token type embedding", "\n", "                            ", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "1", "]", "=", "v", "[", "0", "]", ".", "to", "(", "\n", "dtype", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "", "", "elif", "k_", ".", "startswith", "(", "'LayerNorm.'", ")", ":", "\n", "                        ", "k__", "=", "k_", "[", "len", "(", "'LayerNorm.'", ")", ":", "]", "\n", "if", "k__", "in", "self", ".", "embedding_LayerNorm", ".", "state_dict", "(", ")", ":", "\n", "                            ", "embedding_ln_pretrained_state_dict", "[", "k__", "]", "=", "v", "\n", "", "else", ":", "\n", "                            ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "else", ":", "\n", "                        ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "elif", "self", ".", "config", ".", "with_pooler", "and", "k", ".", "startswith", "(", "'pooler.'", ")", ":", "\n", "                    ", "k_", "=", "k", "[", "len", "(", "'pooler.'", ")", ":", "]", "\n", "if", "k_", "in", "self", ".", "pooler", ".", "state_dict", "(", ")", ":", "\n", "                        ", "pooler_pretrained_state_dict", "[", "k_", "]", "=", "v", "\n", "", "else", ":", "\n", "                        ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "", "elif", "_k", ".", "startswith", "(", "'cls.seq_relationship.'", ")", "and", "self", ".", "with_rel_head", ":", "\n", "                ", "k_", "=", "_k", "[", "len", "(", "'cls.seq_relationship.'", ")", ":", "]", "\n", "if", "'gamma'", "in", "k_", ":", "\n", "                    ", "k_", "=", "k_", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "k_", ":", "\n", "                    ", "k_", "=", "k_", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "k_", "in", "self", ".", "relationsip_head", ".", "caption_image_relationship", ".", "state_dict", "(", ")", ":", "\n", "                    ", "relationship_head_pretrained_state_dict", "[", "k_", "]", "=", "v", "\n", "", "else", ":", "\n", "                    ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "elif", "(", "_k", ".", "startswith", "(", "'cls.predictions.'", ")", "or", "_k", ".", "startswith", "(", "'lm_head.'", ")", ")", "and", "self", ".", "with_mlm_head", ":", "\n", "                ", "k_", "=", "_k", "[", "len", "(", "'cls.predictions.'", ")", ":", "]", "if", "_k", ".", "startswith", "(", "'cls.predictions.'", ")", "else", "_k", "[", "len", "(", "'lm_head.'", ")", ":", "]", "\n", "if", "_k", ".", "startswith", "(", "'lm_head.'", ")", ":", "\n", "                    ", "if", "'dense'", "in", "k_", "or", "'layer_norm'", "in", "k_", ":", "\n", "                        ", "k_", "=", "'transform.'", "+", "k_", "\n", "", "if", "'layer_norm'", "in", "k_", ":", "\n", "                        ", "k_", "=", "k_", ".", "replace", "(", "'layer_norm'", ",", "'LayerNorm'", ")", "\n", "", "", "if", "'gamma'", "in", "k_", ":", "\n", "                    ", "k_", "=", "k_", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "k_", ":", "\n", "                    ", "k_", "=", "k_", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "k_", "in", "self", ".", "mlm_head", ".", "predictions", ".", "state_dict", "(", ")", ":", "\n", "                    ", "mlm_head_pretrained_state_dict", "[", "k_", "]", "=", "v", "\n", "", "else", ":", "\n", "                    ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "else", ":", "\n", "                ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "print", "(", "\"Warnings: Unexpected keys: {}.\"", ".", "format", "(", "unexpected_keys", ")", ")", "\n", "", "self", ".", "embedding_LayerNorm", ".", "load_state_dict", "(", "embedding_ln_pretrained_state_dict", ")", "\n", "self", ".", "encoder", ".", "load_state_dict", "(", "encoder_pretrained_state_dict", ")", "\n", "if", "self", ".", "config", ".", "with_pooler", "and", "len", "(", "pooler_pretrained_state_dict", ")", ">", "0", ":", "\n", "            ", "self", ".", "pooler", ".", "load_state_dict", "(", "pooler_pretrained_state_dict", ")", "\n", "", "if", "self", ".", "with_rel_head", "and", "len", "(", "relationship_head_pretrained_state_dict", ")", ">", "0", "and", "relationship_head_pretrained_state_dict", "[", "'weight'", "]", ".", "shape", "[", "0", "]", "==", "self", ".", "relationsip_head", ".", "caption_image_relationship", ".", "weight", ".", "shape", "[", "0", "]", ":", "\n", "            ", "self", ".", "relationsip_head", ".", "caption_image_relationship", ".", "load_state_dict", "(", "relationship_head_pretrained_state_dict", ")", "\n", "", "if", "self", ".", "with_mlm_head", ":", "\n", "            ", "self", ".", "mlm_head", ".", "predictions", ".", "load_state_dict", "(", "mlm_head_pretrained_state_dict", ")", "\n", "# TODO: load MVRC head ", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertEncoder.__init__": [[698, 730], ["visual_linguistic_bert.VisualLinguisticBert.__init__", "visual_linguistic_bert.VisualLinguisticBertEncoder.apply", "visual_linguistic_bert.VisualLinguisticBertRelationshipPredictionHead", "external.pytorch_pretrained_bert.modeling.BertOnlyMLMHead", "visual_linguistic_bert.VisualLinguisticBertMVRCHead", "visual_linguistic_bert.VisualLinguisticBertEncoder.visual_ln_text.weight.data.fill_", "visual_linguistic_bert.VisualLinguisticBertEncoder.visual_ln_object.weight.data.fill_", "visual_linguistic_bert.VisualLinguisticBertEncoder.load_language_pretrained_model", "visual_linguistic_bert.VisualLinguisticBertEncoder.word_embeddings.parameters", "visual_linguistic_bert.VisualLinguisticBertEncoder.position_embeddings.parameters"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertEncoder.load_language_pretrained_model"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "language_pretrained_model_path", "=", "None", ",", "\n", "with_rel_head", "=", "True", ",", "with_mlm_head", "=", "True", ",", "with_mvrc_head", "=", "True", ")", ":", "\n", "\n", "        ", "super", "(", "VisualLinguisticBertEncoder", ",", "self", ")", ".", "__init__", "(", "config", ",", "language_pretrained_model_path", "=", "None", ")", "\n", "\n", "self", ".", "with_rel_head", "=", "with_rel_head", "\n", "self", ".", "with_mlm_head", "=", "with_mlm_head", "\n", "self", ".", "with_mvrc_head", "=", "with_mvrc_head", "\n", "if", "with_rel_head", ":", "\n", "            ", "self", ".", "relationsip_head", "=", "VisualLinguisticBertRelationshipPredictionHead", "(", "config", ")", "\n", "", "if", "with_mlm_head", ":", "\n", "            ", "self", ".", "mlm_head", "=", "BertOnlyMLMHead", "(", "config", ",", "self", ".", "word_embeddings", ".", "weight", ")", "\n", "", "if", "with_mvrc_head", ":", "\n", "            ", "self", ".", "mvrc_head", "=", "VisualLinguisticBertMVRCHead", "(", "config", ")", "\n", "\n", "# init weights", "\n", "", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "if", "config", ".", "visual_ln", ":", "\n", "            ", "self", ".", "visual_ln_text", ".", "weight", ".", "data", ".", "fill_", "(", "self", ".", "config", ".", "visual_scale_text_init", ")", "\n", "self", ".", "visual_ln_object", ".", "weight", ".", "data", ".", "fill_", "(", "self", ".", "config", ".", "visual_scale_object_init", ")", "\n", "\n", "# load language pretrained model", "\n", "", "if", "language_pretrained_model_path", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_language_pretrained_model", "(", "language_pretrained_model_path", ")", "\n", "\n", "", "if", "config", ".", "word_embedding_frozen", ":", "\n", "            ", "for", "p", "in", "self", ".", "word_embeddings", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "if", "config", ".", "pos_embedding_frozen", ":", "\n", "            ", "for", "p", "in", "self", ".", "position_embeddings", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertEncoder.forward": [[731, 766], ["visual_linguistic_bert.VisualLinguisticBert.forward", "visual_linguistic_bert.VisualLinguisticBertEncoder.relationsip_head", "visual_linguistic_bert.VisualLinguisticBertEncoder.mlm_head", "visual_linguistic_bert.VisualLinguisticBertEncoder.mvrc_head"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.forward"], ["", "", "", "def", "forward", "(", "self", ",", "\n", "text_input_ids", ",", "\n", "text_token_type_ids", ",", "\n", "text_visual_embeddings", ",", "\n", "text_mask", ",", "\n", "object_vl_embeddings", ",", "\n", "object_mask", ",", "\n", "output_all_encoded_layers", "=", "True", ",", "\n", "output_text_and_object_separately", "=", "False", ")", ":", "\n", "\n", "        ", "encoder_output_embeddings", ",", "pooled_rep", "=", "super", "(", "VisualLinguisticBertEncoder", ",", "self", ")", ".", "forward", "(", "\n", "text_input_ids", ",", "\n", "text_token_type_ids", ",", "\n", "text_visual_embeddings", ",", "\n", "text_mask", ",", "\n", "object_vl_embeddings", ",", "\n", "object_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ",", "\n", "output_text_and_object_separately", "=", "False", "\n", ")", "\n", "\n", "if", "self", ".", "with_rel_head", ":", "\n", "            ", "relationship_logits", "=", "self", ".", "relationsip_head", "(", "pooled_rep", ")", "\n", "", "else", ":", "\n", "            ", "relationship_logits", "=", "None", "\n", "", "if", "self", ".", "with_mlm_head", ":", "\n", "            ", "mlm_logits", "=", "self", ".", "mlm_head", "(", "text_out", ")", "\n", "", "else", ":", "\n", "            ", "mlm_logits", "=", "None", "\n", "", "if", "self", ".", "with_mvrc_head", ":", "\n", "            ", "mvrc_logits", "=", "self", ".", "mvrc_head", "(", "object_out", ")", "\n", "", "else", ":", "\n", "            ", "mvrc_logits", "=", "None", "\n", "\n", "", "return", "relationship_logits", ",", "mlm_logits", ",", "mvrc_logits", ",", "encoder_output_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.common.visual_linguistic_bert.VisualLinguisticBertEncoder.load_language_pretrained_model": [[767, 857], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load.items", "torch.load.items", "visual_linguistic_bert.VisualLinguisticBertEncoder.embedding_LayerNorm.load_state_dict", "visual_linguistic_bert.VisualLinguisticBertEncoder.encoder.load_state_dict", "len", "print", "visual_linguistic_bert.VisualLinguisticBertEncoder.pooler.load_state_dict", "visual_linguistic_bert.VisualLinguisticBertEncoder.relationsip_head.caption_image_relationship.load_state_dict", "visual_linguistic_bert.VisualLinguisticBertEncoder.mlm_head.predictions.load_state_dict", "_k.startswith", "_k.startswith", "k.replace.replace.startswith", "len", "len", "_k.startswith", "k.replace.replace.replace", "k.replace.replace.replace", "k.replace.replace.startswith", "_k.startswith", "visual_linguistic_bert.VisualLinguisticBertEncoder.encoder.state_dict", "unexpected_keys.append", "k_.replace.replace.replace", "k_.replace.replace.replace", "visual_linguistic_bert.VisualLinguisticBertEncoder.relationsip_head.caption_image_relationship.state_dict", "unexpected_keys.append", "_k.startswith", "unexpected_keys.append", "len", "len", "len", "v.to", "k.replace.replace.startswith", "len", "_k.startswith", "_k.startswith", "_k.startswith", "k_.replace.replace.replace", "k_.replace.replace.replace", "visual_linguistic_bert.VisualLinguisticBertEncoder.mlm_head.predictions.state_dict", "unexpected_keys.append", "len", "v.to", "visual_linguistic_bert.VisualLinguisticBertEncoder.pooler.state_dict", "unexpected_keys.append", "k_.replace.replace.replace", "v.to", "k_.replace.replace.startswith", "len", "len", "len", "v.size", "v[].to", "unexpected_keys.append", "v.size", "visual_linguistic_bert.VisualLinguisticBertEncoder.embedding_LayerNorm.state_dict", "unexpected_keys.append", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict"], ["", "def", "load_language_pretrained_model", "(", "self", ",", "language_pretrained_model_path", ")", ":", "\n", "        ", "pretrained_state_dict", "=", "torch", ".", "load", "(", "language_pretrained_model_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "encoder_pretrained_state_dict", "=", "{", "}", "\n", "pooler_pretrained_state_dict", "=", "{", "}", "\n", "embedding_ln_pretrained_state_dict", "=", "{", "}", "\n", "relationship_head_pretrained_state_dict", "=", "{", "}", "\n", "mlm_head_pretrained_state_dict", "=", "{", "}", "\n", "unexpected_keys", "=", "[", "]", "\n", "for", "_k", ",", "v", "in", "pretrained_state_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "_k", ".", "startswith", "(", "'bert.'", ")", "or", "_k", ".", "startswith", "(", "'roberta.'", ")", ":", "\n", "                ", "k", "=", "_k", "[", "len", "(", "'bert.'", ")", ":", "]", "if", "_k", ".", "startswith", "(", "'bert.'", ")", "else", "_k", "[", "len", "(", "'roberta.'", ")", ":", "]", "\n", "if", "'gamma'", "in", "k", ":", "\n", "                    ", "k", "=", "k", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "k", ":", "\n", "                    ", "k", "=", "k", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "k", ".", "startswith", "(", "'encoder.'", ")", ":", "\n", "                    ", "k_", "=", "k", "[", "len", "(", "'encoder.'", ")", ":", "]", "\n", "if", "k_", "in", "self", ".", "encoder", ".", "state_dict", "(", ")", ":", "\n", "                        ", "encoder_pretrained_state_dict", "[", "k_", "]", "=", "v", "\n", "", "else", ":", "\n", "                        ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "elif", "k", ".", "startswith", "(", "'embeddings.'", ")", ":", "\n", "                    ", "k_", "=", "k", "[", "len", "(", "'embeddings.'", ")", ":", "]", "\n", "if", "k_", "==", "'word_embeddings.weight'", ":", "\n", "                        ", "self", ".", "word_embeddings", ".", "weight", ".", "data", "=", "v", ".", "to", "(", "dtype", "=", "self", ".", "word_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "word_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "", "elif", "k_", "==", "'position_embeddings.weight'", ":", "\n", "                        ", "self", ".", "position_embeddings", ".", "weight", ".", "data", "=", "v", ".", "to", "(", "dtype", "=", "self", ".", "position_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "position_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "", "elif", "k_", "==", "'token_type_embeddings.weight'", ":", "\n", "                        ", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", ":", "v", ".", "size", "(", "0", ")", "]", "=", "v", ".", "to", "(", "\n", "dtype", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "if", "v", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "# Todo: roberta token type embedding", "\n", "                            ", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", "[", "1", "]", "=", "v", "[", "0", "]", ".", "to", "(", "\n", "dtype", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "dtype", ",", "\n", "device", "=", "self", ".", "token_type_embeddings", ".", "weight", ".", "data", ".", "device", ")", "\n", "", "", "elif", "k_", ".", "startswith", "(", "'LayerNorm.'", ")", ":", "\n", "                        ", "k__", "=", "k_", "[", "len", "(", "'LayerNorm.'", ")", ":", "]", "\n", "if", "k__", "in", "self", ".", "embedding_LayerNorm", ".", "state_dict", "(", ")", ":", "\n", "                            ", "embedding_ln_pretrained_state_dict", "[", "k__", "]", "=", "v", "\n", "", "else", ":", "\n", "                            ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "else", ":", "\n", "                        ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "elif", "self", ".", "config", ".", "with_pooler", "and", "k", ".", "startswith", "(", "'pooler.'", ")", ":", "\n", "                    ", "k_", "=", "k", "[", "len", "(", "'pooler.'", ")", ":", "]", "\n", "if", "k_", "in", "self", ".", "pooler", ".", "state_dict", "(", ")", ":", "\n", "                        ", "pooler_pretrained_state_dict", "[", "k_", "]", "=", "v", "\n", "", "else", ":", "\n", "                        ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "", "elif", "_k", ".", "startswith", "(", "'cls.seq_relationship.'", ")", "and", "self", ".", "with_rel_head", ":", "\n", "                ", "k_", "=", "_k", "[", "len", "(", "'cls.seq_relationship.'", ")", ":", "]", "\n", "if", "'gamma'", "in", "k_", ":", "\n", "                    ", "k_", "=", "k_", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "k_", ":", "\n", "                    ", "k_", "=", "k_", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "k_", "in", "self", ".", "relationsip_head", ".", "caption_image_relationship", ".", "state_dict", "(", ")", ":", "\n", "                    ", "relationship_head_pretrained_state_dict", "[", "k_", "]", "=", "v", "\n", "", "else", ":", "\n", "                    ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "elif", "(", "_k", ".", "startswith", "(", "'cls.predictions.'", ")", "or", "_k", ".", "startswith", "(", "'lm_head.'", ")", ")", "and", "self", ".", "with_mlm_head", ":", "\n", "                ", "k_", "=", "_k", "[", "len", "(", "'cls.predictions.'", ")", ":", "]", "if", "_k", ".", "startswith", "(", "'cls.predictions.'", ")", "else", "_k", "[", "len", "(", "'lm_head.'", ")", ":", "]", "\n", "if", "_k", ".", "startswith", "(", "'lm_head.'", ")", ":", "\n", "                    ", "if", "'dense'", "in", "k_", "or", "'layer_norm'", "in", "k_", ":", "\n", "                        ", "k_", "=", "'transform.'", "+", "k_", "\n", "", "if", "'layer_norm'", "in", "k_", ":", "\n", "                        ", "k_", "=", "k_", ".", "replace", "(", "'layer_norm'", ",", "'LayerNorm'", ")", "\n", "", "", "if", "'gamma'", "in", "k_", ":", "\n", "                    ", "k_", "=", "k_", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "k_", ":", "\n", "                    ", "k_", "=", "k_", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "k_", "in", "self", ".", "mlm_head", ".", "predictions", ".", "state_dict", "(", ")", ":", "\n", "                    ", "mlm_head_pretrained_state_dict", "[", "k_", "]", "=", "v", "\n", "", "else", ":", "\n", "                    ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "else", ":", "\n", "                ", "unexpected_keys", ".", "append", "(", "_k", ")", "\n", "", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "print", "(", "\"Warnings: Unexpected keys: {}.\"", ".", "format", "(", "unexpected_keys", ")", ")", "\n", "", "self", ".", "embedding_LayerNorm", ".", "load_state_dict", "(", "embedding_ln_pretrained_state_dict", ")", "\n", "self", ".", "encoder", ".", "load_state_dict", "(", "encoder_pretrained_state_dict", ")", "\n", "if", "self", ".", "config", ".", "with_pooler", "and", "len", "(", "pooler_pretrained_state_dict", ")", ">", "0", ":", "\n", "            ", "self", ".", "pooler", ".", "load_state_dict", "(", "pooler_pretrained_state_dict", ")", "\n", "", "if", "self", ".", "with_rel_head", "and", "len", "(", "relationship_head_pretrained_state_dict", ")", ">", "0", "and", "relationship_head_pretrained_state_dict", "[", "'weight'", "]", ".", "shape", "[", "0", "]", "==", "self", ".", "relationsip_head", ".", "caption_image_relationship", ".", "weight", ".", "shape", "[", "0", "]", ":", "\n", "            ", "self", ".", "relationsip_head", ".", "caption_image_relationship", ".", "load_state_dict", "(", "relationship_head_pretrained_state_dict", ")", "\n", "", "if", "self", ".", "with_mlm_head", ":", "\n", "            ", "self", ".", "mlm_head", ".", "predictions", ".", "load_state_dict", "(", "mlm_head_pretrained_state_dict", ")", "\n", "# TODO: load MVRC head ", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.multi_task_dataloader.MultiTaskDataLoader.__init__": [[21, 28], ["len", "iter", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "loaders", ":", "List", "[", "DataLoader", "]", ")", ":", "\n", "        ", "assert", "len", "(", "loaders", ")", ">", "1", ",", "\"Less than 2 loader!\"", "\n", "self", ".", "loaders", "=", "loaders", "\n", "self", ".", "iters", "=", "[", "iter", "(", "loader", ")", "for", "loader", "in", "loaders", "]", "\n", "self", ".", "lens", "=", "[", "len", "(", "loader", ")", "for", "loader", "in", "loaders", "]", "\n", "self", ".", "global_idx_in_cycle", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.multi_task_dataloader.MultiTaskDataLoader.__iter__": [[29, 33], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "global_idx_in_cycle", ">", "0", ":", "\n", "            ", "self", ".", "iters", "[", "0", "]", "=", "iter", "(", "self", ".", "loaders", "[", "0", "]", ")", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.multi_task_dataloader.MultiTaskDataLoader.__next__": [[34, 52], ["enumerate", "zip", "hasattr", "next", "loader.batch_sampler.sampler.set_epoch", "int", "iter", "next", "next"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.samplers.distributed.DistributedSampler.set_epoch"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "output_tuple", "=", "(", "*", "next", "(", "self", ".", "iters", "[", "0", "]", ")", ",", ")", "\n", "for", "k", ",", "(", "loader", ",", "_iter", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "loaders", "[", "1", ":", "]", ",", "self", ".", "iters", "[", "1", ":", "]", ")", ")", ":", "\n", "            ", "if", "hasattr", "(", "loader", ".", "batch_sampler", ".", "sampler", ",", "'set_epoch'", ")", ":", "\n", "                ", "loader", ".", "batch_sampler", ".", "sampler", ".", "set_epoch", "(", "int", "(", "self", ".", "global_idx_in_cycle", "/", "self", ".", "lens", "[", "k", "+", "1", "]", ")", ")", "\n", "", "try", ":", "\n", "                ", "output_tuple", "+=", "(", "*", "next", "(", "_iter", ")", ",", ")", "\n", "", "except", "StopIteration", ":", "\n", "                ", "_iter", "=", "iter", "(", "loader", ")", "\n", "self", ".", "iters", "[", "k", "+", "1", "]", "=", "_iter", "\n", "output_tuple", "+=", "(", "*", "next", "(", "_iter", ")", ",", ")", "\n", "\n", "", "", "if", "self", ".", "global_idx_in_cycle", "<", "INT_MAX", "-", "1", ":", "\n", "            ", "self", ".", "global_idx_in_cycle", "+=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "global_idx_in_cycle", "=", "0", "\n", "\n", "", "return", "output_tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.multi_task_dataloader.MultiTaskDataLoader.__len__": [[53, 55], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lens", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.multi_task_dataloader.prod": [[10, 15], ["len", "functools.reduce", "list"], "function", ["None"], ["def", "prod", "(", "iterable", ")", ":", "\n", "    ", "if", "len", "(", "list", "(", "iterable", ")", ")", ">", "0", ":", "\n", "        ", "return", "reduce", "(", "operator", ".", "mul", ",", "iterable", ")", "\n", "", "else", ":", "\n", "        ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.bbox.nonlinear_transform": [[4, 31], ["torch.log", "torch.log", "torch.cat", "ex_widths.clamp", "ex_heights.clamp", "targets_dx.view", "targets_dy.view", "torch.log.view", "torch.log.view"], "function", ["None"], ["def", "nonlinear_transform", "(", "ex_rois", ",", "gt_rois", ")", ":", "\n", "    ", "\"\"\"\n    compute bounding box regression targets from ex_rois to gt_rois\n    :param ex_rois: [k, 4] ([x1, y1, x2, y2])\n    :param gt_rois: [k, 4] (corresponding gt_boxes [x1, y1, x2, y2] )\n    :return: bbox_targets: [k, 4]\n    \"\"\"", "\n", "assert", "ex_rois", ".", "shape", "[", "0", "]", "==", "gt_rois", ".", "shape", "[", "0", "]", ",", "'inconsistent rois number'", "\n", "\n", "ex_widths", "=", "ex_rois", "[", ":", ",", "2", "]", "-", "ex_rois", "[", ":", ",", "0", "]", "+", "1.0", "\n", "ex_heights", "=", "ex_rois", "[", ":", ",", "3", "]", "-", "ex_rois", "[", ":", ",", "1", "]", "+", "1.0", "\n", "ex_ctr_x", "=", "ex_rois", "[", ":", ",", "0", "]", "+", "0.5", "*", "(", "ex_widths", "-", "1.0", ")", "\n", "ex_ctr_y", "=", "ex_rois", "[", ":", ",", "1", "]", "+", "0.5", "*", "(", "ex_heights", "-", "1.0", ")", "\n", "\n", "gt_widths", "=", "gt_rois", "[", ":", ",", "2", "]", "-", "gt_rois", "[", ":", ",", "0", "]", "+", "1.0", "\n", "gt_heights", "=", "gt_rois", "[", ":", ",", "3", "]", "-", "gt_rois", "[", ":", ",", "1", "]", "+", "1.0", "\n", "gt_ctr_x", "=", "gt_rois", "[", ":", ",", "0", "]", "+", "0.5", "*", "(", "gt_widths", "-", "1.0", ")", "\n", "gt_ctr_y", "=", "gt_rois", "[", ":", ",", "1", "]", "+", "0.5", "*", "(", "gt_heights", "-", "1.0", ")", "\n", "\n", "targets_dx", "=", "(", "gt_ctr_x", "-", "ex_ctr_x", ")", "/", "(", "ex_widths", "+", "1e-6", ")", "\n", "targets_dy", "=", "(", "gt_ctr_y", "-", "ex_ctr_y", ")", "/", "(", "ex_heights", "+", "1e-6", ")", "\n", "targets_dw", "=", "torch", ".", "log", "(", "gt_widths", "/", "(", "ex_widths", ")", ".", "clamp", "(", "min", "=", "1e-6", ")", ")", "\n", "targets_dh", "=", "torch", ".", "log", "(", "gt_heights", "/", "(", "(", "ex_heights", ")", ".", "clamp", "(", "min", "=", "1e-6", ")", ")", ")", "\n", "\n", "targets", "=", "torch", ".", "cat", "(", "\n", "(", "targets_dx", ".", "view", "(", "-", "1", ",", "1", ")", ",", "targets_dy", ".", "view", "(", "-", "1", ",", "1", ")", ",", "targets_dw", ".", "view", "(", "-", "1", ",", "1", ")", ",", "targets_dh", ".", "view", "(", "-", "1", ",", "1", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "return", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.bbox.coordinate_embeddings": [[33, 66], ["boxes.new_zeros", "boxes.new_zeros", "torch.cat", "torch.arange", "boxes.new_zeros.view", "dim_mat.view", "boxes.new_zeros.view", "dim_mat.view"], "function", ["None"], ["", "def", "coordinate_embeddings", "(", "boxes", ",", "dim", ")", ":", "\n", "    ", "\"\"\"\n    Coordinate embeddings of bounding boxes\n    :param boxes: [K, 6] ([x1, y1, x2, y2, w_image, h_image])\n    :param dim: sin/cos embedding dimension\n    :return: [K, 4, 2 * dim]\n    \"\"\"", "\n", "\n", "num_boxes", "=", "boxes", ".", "shape", "[", "0", "]", "\n", "w", "=", "boxes", "[", ":", ",", "4", "]", "\n", "h", "=", "boxes", "[", ":", ",", "5", "]", "\n", "\n", "# transform to (x_c, y_c, w, h) format", "\n", "boxes_", "=", "boxes", ".", "new_zeros", "(", "(", "num_boxes", ",", "4", ")", ")", "\n", "boxes_", "[", ":", ",", "0", "]", "=", "(", "boxes", "[", ":", ",", "0", "]", "+", "boxes", "[", ":", ",", "2", "]", ")", "/", "2", "\n", "boxes_", "[", ":", ",", "1", "]", "=", "(", "boxes", "[", ":", ",", "1", "]", "+", "boxes", "[", ":", ",", "3", "]", ")", "/", "2", "\n", "boxes_", "[", ":", ",", "2", "]", "=", "boxes", "[", ":", ",", "2", "]", "-", "boxes", "[", ":", ",", "0", "]", "\n", "boxes_", "[", ":", ",", "3", "]", "=", "boxes", "[", ":", ",", "3", "]", "-", "boxes", "[", ":", ",", "1", "]", "\n", "boxes", "=", "boxes_", "\n", "\n", "# position", "\n", "pos", "=", "boxes", ".", "new_zeros", "(", "(", "num_boxes", ",", "4", ")", ")", "\n", "pos", "[", ":", ",", "0", "]", "=", "boxes", "[", ":", ",", "0", "]", "/", "w", "*", "100", "\n", "pos", "[", ":", ",", "1", "]", "=", "boxes", "[", ":", ",", "1", "]", "/", "h", "*", "100", "\n", "pos", "[", ":", ",", "2", "]", "=", "boxes", "[", ":", ",", "2", "]", "/", "w", "*", "100", "\n", "pos", "[", ":", ",", "3", "]", "=", "boxes", "[", ":", ",", "3", "]", "/", "h", "*", "100", "\n", "\n", "# sin/cos embedding", "\n", "dim_mat", "=", "1000", "**", "(", "torch", ".", "arange", "(", "dim", ",", "dtype", "=", "boxes", ".", "dtype", ",", "device", "=", "boxes", ".", "device", ")", "/", "dim", ")", "\n", "sin_embedding", "=", "(", "pos", ".", "view", "(", "(", "num_boxes", ",", "4", ",", "1", ")", ")", "/", "dim_mat", ".", "view", "(", "(", "1", ",", "1", ",", "-", "1", ")", ")", ")", ".", "sin", "(", ")", "\n", "cos_embedding", "=", "(", "pos", ".", "view", "(", "(", "num_boxes", ",", "4", ",", "1", ")", ")", "/", "dim_mat", ".", "view", "(", "(", "1", ",", "1", ",", "-", "1", ")", ")", ")", ".", "cos", "(", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "(", "sin_embedding", ",", "cos_embedding", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.bbox.bbox_iou_py_vectorized": [[68, 89], ["torch.meshgrid", "n_mesh.contiguous().view.contiguous().view", "k_mesh.contiguous().view.contiguous().view", "torch.max", "torch.max", "torch.min", "torch.min", "iou.view().to", "torch.clamp", "torch.clamp", "torch.arange", "torch.arange", "n_mesh.contiguous().view.contiguous", "k_mesh.contiguous().view.contiguous", "iou.view"], "function", ["None"], ["", "def", "bbox_iou_py_vectorized", "(", "boxes", ",", "query_boxes", ")", ":", "\n", "    ", "n_", "=", "boxes", ".", "shape", "[", "0", "]", "\n", "k_", "=", "query_boxes", ".", "shape", "[", "0", "]", "\n", "n_mesh", ",", "k_mesh", "=", "torch", ".", "meshgrid", "(", "[", "torch", ".", "arange", "(", "n_", ")", ",", "torch", ".", "arange", "(", "k_", ")", "]", ")", "\n", "n_mesh", "=", "n_mesh", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "k_mesh", "=", "k_mesh", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "boxes", "=", "boxes", "[", "n_mesh", "]", "\n", "query_boxes", "=", "query_boxes", "[", "k_mesh", "]", "\n", "\n", "x11", ",", "y11", ",", "x12", ",", "y12", "=", "boxes", "[", ":", ",", "0", "]", ",", "boxes", "[", ":", ",", "1", "]", ",", "boxes", "[", ":", ",", "2", "]", ",", "boxes", "[", ":", ",", "3", "]", "\n", "x21", ",", "y21", ",", "x22", ",", "y22", "=", "query_boxes", "[", ":", ",", "0", "]", ",", "query_boxes", "[", ":", ",", "1", "]", ",", "query_boxes", "[", ":", ",", "2", "]", ",", "query_boxes", "[", ":", ",", "3", "]", "\n", "xA", "=", "torch", ".", "max", "(", "x11", ",", "x21", ")", "\n", "yA", "=", "torch", ".", "max", "(", "y11", ",", "y21", ")", "\n", "xB", "=", "torch", ".", "min", "(", "x12", ",", "x22", ")", "\n", "yB", "=", "torch", ".", "min", "(", "y12", ",", "y22", ")", "\n", "interArea", "=", "torch", ".", "clamp", "(", "xB", "-", "xA", "+", "1", ",", "min", "=", "0", ")", "*", "torch", ".", "clamp", "(", "yB", "-", "yA", "+", "1", ",", "min", "=", "0", ")", "\n", "boxAArea", "=", "(", "x12", "-", "x11", "+", "1", ")", "*", "(", "y12", "-", "y11", "+", "1", ")", "\n", "boxBArea", "=", "(", "x22", "-", "x21", "+", "1", ")", "*", "(", "y22", "-", "y21", "+", "1", ")", "\n", "iou", "=", "interArea", "/", "(", "boxAArea", "+", "boxBArea", "-", "interArea", ")", "\n", "\n", "return", "iou", ".", "view", "(", "n_", ",", "k_", ")", ".", "to", "(", "boxes", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.load.smart_load_model_state_dict": [[5, 20], ["state_dict.items", "model.load_state_dict", "model.state_dict", "k.startswith", "model.state_dict", "print", "print", "ValueError", "len"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict"], ["def", "smart_load_model_state_dict", "(", "model", ",", "state_dict", ")", ":", "\n", "    ", "parsed_state_dict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", "not", "in", "model", ".", "state_dict", "(", ")", ":", "\n", "            ", "if", "k", ".", "startswith", "(", "'module.'", ")", ":", "\n", "                ", "k", "=", "k", "[", "len", "(", "'module.'", ")", ":", "]", "\n", "", "else", ":", "\n", "                ", "k", "=", "'module.'", "+", "k", "\n", "", "", "if", "k", "in", "model", ".", "state_dict", "(", ")", ":", "\n", "            ", "parsed_state_dict", "[", "k", "]", "=", "v", "\n", "", "else", ":", "\n", "            ", "print", "(", "'********'", ")", "\n", "print", "(", "k", ")", "\n", "raise", "ValueError", "(", "'failed to match key of state dict smartly!'", ")", "\n", "", "", "model", ".", "load_state_dict", "(", "parsed_state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.load.smart_resume": [[22, 66], ["print", "torch.load", "load.smart_load_model_state_dict", "optimizer.load_state_dict", "validation_monitor.load_state_dict", "print", "range", "print", "os.path.exists", "torch.load", "load.smart_load_model_state_dict", "optimizer.load_state_dict", "logger.info", "print", "validation_monitor.load_state_dict", "print"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.load.smart_load_model_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.load.smart_load_model_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict"], ["", "def", "smart_resume", "(", "model", ",", "optimizer", ",", "validation_monitor", ",", "config", ",", "model_prefix", ",", "logger", ")", ":", "\n", "    ", "if", "config", ".", "TRAIN", ".", "RESUME", ":", "\n", "        ", "print", "(", "(", "'continue training from '", ",", "config", ".", "TRAIN", ".", "BEGIN_EPOCH", ")", ")", "\n", "# load model", "\n", "model_filename", "=", "'{}-{:04d}.model'", ".", "format", "(", "\n", "model_prefix", ",", "config", ".", "TRAIN", ".", "BEGIN_EPOCH", "-", "1", ")", "\n", "check_point", "=", "torch", ".", "load", "(", "\n", "model_filename", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "# model.load_state_dict(check_point['state_dict'])", "\n", "smart_load_model_state_dict", "(", "model", ",", "check_point", "[", "'state_dict'", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "check_point", "[", "'optimizer'", "]", ")", "\n", "if", "'validation_monitor'", "in", "check_point", ":", "\n", "            ", "validation_monitor", ".", "load_state_dict", "(", "\n", "check_point", "[", "'validation_monitor'", "]", ")", "\n", "print", "(", "\n", "'Best Val {}: {}, Epoch: {}'", ".", "format", "(", "validation_monitor", ".", "host_metric_name", ",", "\n", "validation_monitor", ".", "best_val", ",", "\n", "validation_monitor", ".", "best_epoch", ")", "\n", ")", "\n", "", "", "elif", "config", ".", "TRAIN", ".", "AUTO_RESUME", ":", "\n", "        ", "for", "epoch", "in", "range", "(", "config", ".", "TRAIN", ".", "END_EPOCH", ",", "config", ".", "TRAIN", ".", "BEGIN_EPOCH", ",", "-", "1", ")", ":", "\n", "            ", "model_filename", "=", "'{}-{:04d}.model'", ".", "format", "(", "model_prefix", ",", "epoch", "-", "1", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "model_filename", ")", ":", "\n", "                ", "config", ".", "TRAIN", ".", "BEGIN_EPOCH", "=", "epoch", "\n", "check_point", "=", "torch", ".", "load", "(", "\n", "model_filename", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "# model.load_state_dict(check_point['state_dict'])", "\n", "smart_load_model_state_dict", "(", "model", ",", "check_point", "[", "'state_dict'", "]", ")", "\n", "# FM edit TODO: UNCOMMENT THIS! Only used for testing.", "\n", "optimizer", ".", "load_state_dict", "(", "check_point", "[", "'optimizer'", "]", ")", "\n", "if", "'validation_monitor'", "in", "check_point", ":", "\n", "                    ", "validation_monitor", ".", "load_state_dict", "(", "\n", "check_point", "[", "'validation_monitor'", "]", ")", "\n", "print", "(", "\n", "'Best Val {}: {}, Epoch: {}'", ".", "format", "(", "validation_monitor", ".", "host_metric_name", ",", "\n", "validation_monitor", ".", "best_val", ",", "\n", "validation_monitor", ".", "best_epoch", ")", "\n", ")", "\n", "", "logger", ".", "info", "(", "\n", "\"Auto continue training from {0}\"", ".", "format", "(", "model_filename", ")", ")", "\n", "print", "(", "\"Auto continue training from {0}\"", ".", "format", "(", "model_filename", ")", ")", "\n", "break", "\n", "# TODO: remove - just for testing", "\n", "", "", "print", "(", "'inside auto-resume --------------***********************'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.load.smart_partial_load_model_state_dict": [[68, 95], ["state_dict.items", "print", "print", "print", "model.state_dict", "model.state_dict.update", "model.load_state_dict", "model.state_dict", "k.startswith", "model.state_dict", "pretrained_keys.append", "non_match_keys.append", "model.state_dict().keys", "parsed_state_dict.keys", "model.state_dict", "len"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict"], ["", "", "def", "smart_partial_load_model_state_dict", "(", "model", ",", "state_dict", ")", ":", "\n", "    ", "parsed_state_dict", "=", "{", "}", "\n", "non_match_keys", "=", "[", "]", "\n", "pretrained_keys", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", "not", "in", "model", ".", "state_dict", "(", ")", ":", "\n", "            ", "if", "k", ".", "startswith", "(", "'module.'", ")", ":", "\n", "                ", "k", "=", "k", "[", "len", "(", "'module.'", ")", ":", "]", "\n", "", "else", ":", "\n", "                ", "k", "=", "'module.'", "+", "k", "\n", "", "", "if", "k", "in", "model", ".", "state_dict", "(", ")", ":", "\n", "            ", "parsed_state_dict", "[", "k", "]", "=", "v", "\n", "pretrained_keys", ".", "append", "(", "k", ")", "\n", "", "else", ":", "\n", "            ", "non_match_keys", ".", "append", "(", "k", ")", "\n", "# raise ValueError('failed to match key of state dict smartly!')", "\n", "\n", "", "", "non_pretrain_keys", "=", "[", "\n", "k", "for", "k", "in", "model", ".", "state_dict", "(", ")", ".", "keys", "(", ")", "if", "k", "not", "in", "pretrained_keys", "]", "\n", "\n", "print", "(", "\"[Partial Load] partial load state dict of keys: {}\"", ".", "format", "(", "\n", "parsed_state_dict", ".", "keys", "(", ")", ")", ")", "\n", "print", "(", "\"[Partial Load] non matched keys: {}\"", ".", "format", "(", "non_match_keys", ")", ")", "\n", "print", "(", "\"[Partial Load] non pretrain keys: {}\"", ".", "format", "(", "non_pretrain_keys", ")", ")", "\n", "new_state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "new_state_dict", ".", "update", "(", "parsed_state_dict", ")", "\n", "model", ".", "load_state_dict", "(", "new_state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.load.smart_skip_partial_load_model_state_dict": [[98, 129], ["state_dict.items", "print", "print", "print", "model.state_dict", "model.state_dict.update", "model.load_state_dict", "print", "model.state_dict", "k.startswith", "model.state_dict", "pretrained_keys.append", "non_match_keys.append", "model.state_dict().keys", "parsed_state_dict.keys", "model.state_dict", "len"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict"], ["", "def", "smart_skip_partial_load_model_state_dict", "(", "model", ",", "state_dict", ")", ":", "\n", "    ", "parsed_state_dict", "=", "{", "}", "\n", "non_match_keys", "=", "[", "]", "\n", "pretrained_keys", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "# FM: for partica", "\n", "        ", "if", "k", "in", "[", "'module.vlbert.mlm_head.predictions.decoder.weight'", ",", "'module.vlbert.mlm_head.predictions.bias'", ",", "'module.vlbert.word_embeddings.weight'", "]", ":", "\n", "            ", "print", "(", "'---------- skip :'", ",", "k", ")", "\n", "continue", "\n", "", "if", "k", "not", "in", "model", ".", "state_dict", "(", ")", ":", "\n", "            ", "if", "k", ".", "startswith", "(", "'module.'", ")", ":", "\n", "                ", "k", "=", "k", "[", "len", "(", "'module.'", ")", ":", "]", "\n", "", "else", ":", "\n", "                ", "k", "=", "'module.'", "+", "k", "\n", "", "", "if", "k", "in", "model", ".", "state_dict", "(", ")", ":", "\n", "            ", "parsed_state_dict", "[", "k", "]", "=", "v", "\n", "pretrained_keys", ".", "append", "(", "k", ")", "\n", "", "else", ":", "\n", "            ", "non_match_keys", ".", "append", "(", "k", ")", "\n", "# raise ValueError('failed to match key of state dict smartly!')", "\n", "\n", "", "", "non_pretrain_keys", "=", "[", "\n", "k", "for", "k", "in", "model", ".", "state_dict", "(", ")", ".", "keys", "(", ")", "if", "k", "not", "in", "pretrained_keys", "]", "\n", "\n", "print", "(", "\"[Partial Load] partial load state dict of keys: {}\"", ".", "format", "(", "\n", "parsed_state_dict", ".", "keys", "(", ")", ")", ")", "\n", "print", "(", "\"[Partial Load] non matched keys: {}\"", ".", "format", "(", "non_match_keys", ")", ")", "\n", "print", "(", "\"[Partial Load] non pretrain keys: {}\"", ".", "format", "(", "non_pretrain_keys", ")", ")", "\n", "new_state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "new_state_dict", ".", "update", "(", "parsed_state_dict", ")", "\n", "model", ".", "load_state_dict", "(", "new_state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.load.smart_hybrid_partial_load_model_state_dict": [[133, 164], ["state_dict.items", "print", "print", "print", "model.state_dict", "model.state_dict.update", "model.load_state_dict", "model.state_dict", "k.startswith", "pretrained_keys.append", "non_match_keys.append", "model.state_dict().keys", "parsed_state_dict.keys", "model.state_dict", "model.state_dict", "len"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict"], ["", "def", "smart_hybrid_partial_load_model_state_dict", "(", "model", ",", "state_dict", ")", ":", "\n", "    ", "parsed_state_dict", "=", "{", "}", "\n", "non_match_keys", "=", "[", "]", "\n", "pretrained_keys", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", "not", "in", "model", ".", "state_dict", "(", ")", ":", "\n", "            ", "if", "k", ".", "startswith", "(", "'module.'", ")", ":", "\n", "                ", "k", "=", "k", "[", "len", "(", "'module.'", ")", ":", "]", "\n", "", "else", ":", "\n", "                ", "k", "=", "'module.'", "+", "k", "\n", "", "", "if", "k", "in", "model", ".", "state_dict", "(", ")", "and", "(", "(", "\"vlbert.mvrc_head\"", "in", "k", ")", "or", "(", "\"image_feature_extractor\"", "in", "k", ")", "\n", "or", "(", "\"vlbert.visual_ln\"", "in", "k", ")", "or", "(", "\"end_embedding\"", "in", "k", ")", "\n", "or", "(", "\"token_type_embeddings\"", "in", "k", ")", "or", "(", "\"position_embeddings\"", "in", "k", ")", "\n", "or", "(", "\"aux_text_visual_embedding\"", "in", "k", ")", "or", "(", "\"object_mask_word_embedding\"", "in", "k", ")", "\n", "or", "(", "\"object_linguistic_embeddings\"", "in", "k", ")", ")", ":", "\n", "            ", "parsed_state_dict", "[", "k", "]", "=", "v", "\n", "pretrained_keys", ".", "append", "(", "k", ")", "\n", "", "else", ":", "\n", "            ", "non_match_keys", ".", "append", "(", "k", ")", "\n", "# raise ValueError('failed to match key of state dict smartly!')", "\n", "\n", "", "", "non_pretrain_keys", "=", "[", "\n", "k", "for", "k", "in", "model", ".", "state_dict", "(", ")", ".", "keys", "(", ")", "if", "k", "not", "in", "pretrained_keys", "]", "\n", "\n", "print", "(", "\"[Partial Load] partial load state dict of keys: {}\"", ".", "format", "(", "\n", "parsed_state_dict", ".", "keys", "(", ")", ")", ")", "\n", "print", "(", "\"[Partial Load] non matched keys: {}\"", ".", "format", "(", "non_match_keys", ")", ")", "\n", "print", "(", "\"[Partial Load] non pretrain keys: {}\"", ".", "format", "(", "non_pretrain_keys", ")", ")", "\n", "new_state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "new_state_dict", ".", "update", "(", "parsed_state_dict", ")", "\n", "model", ".", "load_state_dict", "(", "new_state_dict", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.__init__": [[11, 13], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "ZipReader", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.get_zipfile": [[14, 24], ["print", "zipfile.ZipFile"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_zipfile", "(", "path", ")", ":", "\n", "        ", "zip_bank", "=", "ZipReader", ".", "zip_bank", "\n", "if", "path", "in", "zip_bank", ":", "\n", "            ", "return", "zip_bank", "[", "path", "]", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"creating new zip_bank\"", ")", "\n", "zfile", "=", "zipfile", ".", "ZipFile", "(", "path", ",", "'r'", ")", "\n", "zip_bank", "[", "path", "]", "=", "zfile", "\n", "return", "zip_bank", "[", "path", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.split_zip_style_path": [[25, 37], ["path.index", "str.strip", "len", "print", "len"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "split_zip_style_path", "(", "path", ")", ":", "\n", "        ", "pos_zip_at", "=", "path", ".", "index", "(", "'.zip@'", ")", "\n", "if", "pos_zip_at", "==", "len", "(", "path", ")", ":", "\n", "            ", "print", "(", "\"character '@' is not found from the given path '%s'\"", "%", "(", "path", ")", ")", "\n", "assert", "0", "\n", "", "pos_at", "=", "pos_zip_at", "+", "len", "(", "'.zip@'", ")", "-", "1", "\n", "\n", "zip_path", "=", "path", "[", "0", ":", "pos_at", "]", "\n", "folder_path", "=", "path", "[", "pos_at", "+", "1", ":", "]", "\n", "folder_path", "=", "str", ".", "strip", "(", "folder_path", ",", "'/'", ")", "\n", "return", "zip_path", ",", "folder_path", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.list_folder": [[38, 55], ["zipreader.ZipReader.split_zip_style_path", "zipreader.ZipReader.get_zipfile", "zipreader.ZipReader.get_zipfile", "str.strip", "str.strip.startswith", "len", "len", "folder_list.append", "folder_list.append", "os.path.splitext", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.split_zip_style_path", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.get_zipfile", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.get_zipfile"], ["", "@", "staticmethod", "\n", "def", "list_folder", "(", "path", ")", ":", "\n", "        ", "zip_path", ",", "folder_path", "=", "ZipReader", ".", "split_zip_style_path", "(", "path", ")", "\n", "\n", "zfile", "=", "ZipReader", ".", "get_zipfile", "(", "zip_path", ")", "\n", "folder_list", "=", "[", "]", "\n", "for", "file_foler_name", "in", "zfile", ".", "namelist", "(", ")", ":", "\n", "            ", "file_foler_name", "=", "str", ".", "strip", "(", "file_foler_name", ",", "'/'", ")", "\n", "if", "file_foler_name", ".", "startswith", "(", "folder_path", ")", "and", "len", "(", "os", ".", "path", ".", "splitext", "(", "file_foler_name", ")", "[", "-", "1", "]", ")", "==", "0", "and", "file_foler_name", "!=", "folder_path", ":", "\n", "                ", "if", "len", "(", "folder_path", ")", "==", "0", ":", "\n", "                    ", "folder_list", ".", "append", "(", "file_foler_name", ")", "\n", "", "else", ":", "\n", "                    ", "folder_list", ".", "append", "(", "file_foler_name", "[", "len", "(", "folder_path", ")", "+", "1", ":", "]", ")", "\n", "\n", "", "", "", "return", "folder_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.list_files": [[56, 71], ["zipreader.ZipReader.split_zip_style_path", "zipreader.ZipReader.get_zipfile", "zipreader.ZipReader.get_zipfile", "str.strip", "str.strip.startswith", "str.lower", "len", "file_lists.append", "file_lists.append", "os.path.splitext", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.split_zip_style_path", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.get_zipfile", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.get_zipfile"], ["", "@", "staticmethod", "\n", "def", "list_files", "(", "path", ",", "extension", "=", "[", "'.*'", "]", ")", ":", "\n", "        ", "zip_path", ",", "folder_path", "=", "ZipReader", ".", "split_zip_style_path", "(", "path", ")", "\n", "\n", "zfile", "=", "ZipReader", ".", "get_zipfile", "(", "zip_path", ")", "\n", "file_lists", "=", "[", "]", "\n", "for", "file_foler_name", "in", "zfile", ".", "namelist", "(", ")", ":", "\n", "            ", "file_foler_name", "=", "str", ".", "strip", "(", "file_foler_name", ",", "'/'", ")", "\n", "if", "file_foler_name", ".", "startswith", "(", "folder_path", ")", "and", "str", ".", "lower", "(", "os", ".", "path", ".", "splitext", "(", "file_foler_name", ")", "[", "-", "1", "]", ")", "in", "extension", ":", "\n", "                ", "if", "len", "(", "folder_path", ")", "==", "0", ":", "\n", "                    ", "file_lists", ".", "append", "(", "file_foler_name", ")", "\n", "", "else", ":", "\n", "                    ", "file_lists", ".", "append", "(", "file_foler_name", "[", "len", "(", "folder_path", ")", "+", "1", ":", "]", ")", "\n", "\n", "", "", "", "return", "file_lists", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.imread": [[72, 79], ["zipreader.ZipReader.split_zip_style_path", "zipreader.ZipReader.get_zipfile", "zipreader.ZipReader.get_zipfile", "PIL.Image.open", "io.BytesIO"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.split_zip_style_path", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.get_zipfile", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.get_zipfile"], ["", "@", "staticmethod", "\n", "def", "imread", "(", "path", ")", ":", "\n", "        ", "zip_path", ",", "path_img", "=", "ZipReader", ".", "split_zip_style_path", "(", "path", ")", "\n", "zfile", "=", "ZipReader", ".", "get_zipfile", "(", "zip_path", ")", "\n", "data", "=", "zfile", ".", "read", "(", "path_img", ")", "\n", "im", "=", "Image", ".", "open", "(", "io", ".", "BytesIO", "(", "data", ")", ")", "\n", "return", "im", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read": [[80, 86], ["zipreader.ZipReader.split_zip_style_path", "zipreader.ZipReader.get_zipfile", "zipreader.ZipReader.get_zipfile"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.split_zip_style_path", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.get_zipfile", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.get_zipfile"], ["", "@", "staticmethod", "\n", "def", "read", "(", "path", ")", ":", "\n", "        ", "zip_path", ",", "path_img", "=", "ZipReader", ".", "split_zip_style_path", "(", "path", ")", "\n", "zfile", "=", "ZipReader", ".", "get_zipfile", "(", "zip_path", ")", "\n", "data", "=", "zfile", ".", "read", "(", "path_img", ")", "\n", "return", "data", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.masked_softmax.masked_softmax": [[4, 30], ["torch.nn.functional.softmax", "mask.unsqueeze.type", "torch.nn.functional.softmax", "mask.unsqueeze.dim", "vector.dim", "mask.unsqueeze.unsqueeze", "torch.nn.functional.softmax.sum"], "function", ["None"], ["def", "masked_softmax", "(", "vector", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ",", "dim", ":", "int", "=", "-", "1", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    ``torch.nn.functional.softmax(vector)`` does not work if some elements of ``vector`` should be\n    masked.  This performs a softmax on just the non-masked portions of ``vector``.  Passing\n    ``None`` in for the mask is also acceptable; you'll just get a regular softmax.\n\n    ``vector`` can have an arbitrary number of dimensions; the only requirement is that ``mask`` is\n    broadcastable to ``vector's`` shape.  If ``mask`` has fewer dimensions than ``vector``, we will\n    unsqueeze on dimension 1 until they match.  If you need a different unsqueezing of your mask,\n    do it yourself before passing the mask into this function.\n\n    In the case that the input vector is completely masked, this function returns an array\n    of ``0.0``. This behavior may cause ``NaN`` if this is used as the last layer of a model\n    that uses categorical cross-entropy loss.\n    \"\"\"", "\n", "if", "mask", "is", "None", ":", "\n", "        ", "result", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "vector", ",", "dim", "=", "dim", ")", "\n", "", "else", ":", "\n", "        ", "mask", "=", "mask", ".", "type", "(", "vector", ".", "dtype", ")", "\n", "while", "mask", ".", "dim", "(", ")", "<", "vector", ".", "dim", "(", ")", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "# To limit numerical errors from large vector elements outside the mask, we zero these out.", "\n", "", "result", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "vector", "*", "mask", ",", "dim", "=", "dim", ")", "\n", "result", "=", "result", "*", "mask", "\n", "result", "=", "result", "/", "(", "result", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "+", "(", "1e-7", "if", "vector", ".", "dtype", "==", "torch", ".", "half", "else", "1e-13", ")", ")", "\n", "", "return", "result", "\n", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.block_digonal_matrix": [[8, 30], ["torch.zeros", "torch.zeros", "zip", "len", "sum", "sum"], "function", ["None"], ["def", "block_digonal_matrix", "(", "*", "blocks", ")", ":", "\n", "    ", "\"\"\"\n    Construct block diagonal matrix\n    :param blocks: blocks of block diagonal matrix\n    :param device\n    :param dtype\n    :return: block diagonal matrix\n    \"\"\"", "\n", "assert", "len", "(", "blocks", ")", ">", "0", "\n", "rows", "=", "[", "block", ".", "shape", "[", "0", "]", "for", "block", "in", "blocks", "]", "\n", "cols", "=", "[", "block", ".", "shape", "[", "1", "]", "for", "block", "in", "blocks", "]", "\n", "out", "=", "torch", ".", "zeros", "(", "(", "sum", "(", "rows", ")", ",", "sum", "(", "cols", ")", ")", ",", "\n", "device", "=", "blocks", "[", "0", "]", ".", "device", ",", "\n", "dtype", "=", "blocks", "[", "0", "]", ".", "dtype", ")", "\n", "cur_row", "=", "0", "\n", "cur_col", "=", "0", "\n", "for", "block", ",", "row", ",", "col", "in", "zip", "(", "blocks", ",", "rows", ",", "cols", ")", ":", "\n", "        ", "out", "[", "cur_row", ":", "(", "cur_row", "+", "row", ")", ",", "cur_col", ":", "(", "cur_col", "+", "col", ")", "]", "=", "block", "\n", "cur_row", "+=", "row", "\n", "cur_col", "+=", "col", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.print_and_log": [[32, 38], ["print", "logging.info", "logger.info"], "function", ["None"], ["", "def", "print_and_log", "(", "string", ",", "logger", "=", "None", ")", ":", "\n", "    ", "print", "(", "string", ")", "\n", "if", "logger", "is", "None", ":", "\n", "        ", "logging", ".", "info", "(", "string", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.summary_parameters": [[40, 68], ["misc.print_and_log", "misc.print_and_log", "misc.print_and_log", "misc.print_and_log", "sum", "sum", "misc.print_and_log", "misc.print_and_log", "misc.print_and_log", "max", "raw_format.format", "misc.print_and_log", "misc.print_and_log", "str", "str", "str", "str", "model.named_parameters", "zip", "raw_format.format", "v.numel", "v.numel", "tuple", "v.numel", "sum", "len", "model.parameters", "model.parameters", "len"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.print_and_log", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.print_and_log", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.print_and_log", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.print_and_log", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.print_and_log", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.print_and_log", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.print_and_log", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.print_and_log", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.print_and_log"], ["", "", "def", "summary_parameters", "(", "model", ",", "logger", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Summary Parameters of Model\n    :param model: torch.nn.module_name\n    :param logger: logger\n    :return: None\n    \"\"\"", "\n", "\n", "print_and_log", "(", "'>> Trainable Parameters:'", ",", "logger", ")", "\n", "trainable_paramters", "=", "[", "(", "str", "(", "n", ")", ",", "str", "(", "v", ".", "dtype", ")", ",", "str", "(", "tuple", "(", "v", ".", "shape", ")", ")", ",", "str", "(", "v", ".", "numel", "(", ")", ")", ")", "\n", "for", "n", ",", "v", "in", "model", ".", "named_parameters", "(", ")", "if", "v", ".", "requires_grad", "]", "\n", "max_lens", "=", "[", "max", "(", "[", "len", "(", "item", ")", "+", "4", "for", "item", "in", "col", "]", ")", "for", "col", "in", "zip", "(", "*", "trainable_paramters", ")", "]", "\n", "raw_format", "=", "'|'", "+", "'|'", ".", "join", "(", "[", "'{{:{}s}}'", ".", "format", "(", "max_len", ")", "for", "max_len", "in", "max_lens", "]", ")", "+", "'|'", "\n", "raw_split", "=", "'-'", "*", "(", "sum", "(", "max_lens", ")", "+", "len", "(", "max_lens", ")", "+", "1", ")", "\n", "print_and_log", "(", "raw_split", ",", "logger", ")", "\n", "print_and_log", "(", "raw_format", ".", "format", "(", "'Name'", ",", "'Dtype'", ",", "'Shape'", ",", "'#Params'", ")", ",", "logger", ")", "\n", "print_and_log", "(", "raw_split", ",", "logger", ")", "\n", "\n", "for", "name", ",", "dtype", ",", "shape", ",", "number", "in", "trainable_paramters", ":", "\n", "        ", "print_and_log", "(", "raw_format", ".", "format", "(", "name", ",", "dtype", ",", "shape", ",", "number", ")", ",", "logger", ")", "\n", "print_and_log", "(", "raw_split", ",", "logger", ")", "\n", "\n", "", "num_trainable_params", "=", "sum", "(", "[", "v", ".", "numel", "(", ")", "for", "v", "in", "model", ".", "parameters", "(", ")", "if", "v", ".", "requires_grad", "]", ")", "\n", "total_params", "=", "sum", "(", "[", "v", ".", "numel", "(", ")", "for", "v", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "non_trainable_params", "=", "total_params", "-", "num_trainable_params", "\n", "print_and_log", "(", "'>> {:25s}\\t{:.2f}\\tM'", ".", "format", "(", "'# TrainableParams:'", ",", "num_trainable_params", "/", "(", "1.0", "*", "10", "**", "6", ")", ")", ",", "logger", ")", "\n", "print_and_log", "(", "'>> {:25s}\\t{:.2f}\\tM'", ".", "format", "(", "'# NonTrainableParams:'", ",", "non_trainable_params", "/", "(", "1.0", "*", "10", "**", "6", ")", ")", ",", "logger", ")", "\n", "print_and_log", "(", "'>> {:25s}\\t{:.2f}\\tM'", ".", "format", "(", "'# TotalParams:'", ",", "total_params", "/", "(", "1.0", "*", "10", "**", "6", ")", ")", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.clip_grad": [[72, 116], ["float", "p.grad.data.norm", "tuple", "numpy.isnan", "clip_coef.item", "logger.info", "print", "sorted", "print", "logger.info", "sorted", "logger.info", "norm.item", "p.size", "p.grad.data.norm.item", "ValueError", "p.grad.data.mul_", "param_to_norm.items", "print", "param_to_norm.items", "logger.info", "param_to_norm.items", "numpy.prod", "numpy.prod"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.multi_task_dataloader.prod", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.multi_task_dataloader.prod"], ["", "def", "clip_grad", "(", "named_parameters", ",", "max_norm", ",", "logger", "=", "logging", ",", "std_verbose", "=", "False", ",", "log_verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"Clips gradient norm of an iterable of parameters.\n    The norm is computed over all gradients together, as if they were\n    concatenated into a single vector. Gradients are modified in-place.\n    :param named_parameters: dict, named parameters of pytorch module\n    :param max_norm: float or int, max norm of the gradients\n    :param logger: logger to write verbose info\n    :param std_verbose: verbose info in stdout\n    :param log_verbose: verbose info in log\n\n    :return Total norm of the parameters (viewed as a dict: param name -> param grad norm).\n    \"\"\"", "\n", "max_norm", "=", "float", "(", "max_norm", ")", "\n", "parameters", "=", "[", "(", "n", ",", "p", ")", "for", "n", ",", "p", "in", "named_parameters", "if", "p", ".", "grad", "is", "not", "None", "]", "\n", "total_norm", "=", "0", "\n", "param_to_norm", "=", "{", "}", "\n", "param_to_shape", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "parameters", ":", "\n", "        ", "param_norm", "=", "p", ".", "grad", ".", "data", ".", "norm", "(", "2", ")", "\n", "total_norm", "+=", "param_norm", "**", "2", "\n", "param_to_norm", "[", "n", "]", "=", "param_norm", "\n", "param_to_shape", "[", "n", "]", "=", "tuple", "(", "p", ".", "size", "(", ")", ")", "\n", "if", "np", ".", "isnan", "(", "param_norm", ".", "item", "(", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"the param {} was null.\"", ".", "format", "(", "n", ")", ")", "\n", "\n", "", "", "total_norm", "=", "total_norm", "**", "(", "1.", "/", "2", ")", "\n", "clip_coef", "=", "max_norm", "/", "(", "total_norm", "+", "1e-6", ")", "\n", "if", "clip_coef", ".", "item", "(", ")", "<", "1", ":", "\n", "        ", "logger", ".", "info", "(", "'---Clip grad! Total norm: {:.3f}, clip coef: {:.3f}.'", ".", "format", "(", "total_norm", ",", "clip_coef", ")", ")", "\n", "for", "n", ",", "p", "in", "parameters", ":", "\n", "            ", "p", ".", "grad", ".", "data", ".", "mul_", "(", "clip_coef", ")", "\n", "\n", "", "", "if", "std_verbose", ":", "\n", "        ", "print", "(", "'---Total norm {:.3f} clip coef {:.3f}-----------------'", ".", "format", "(", "total_norm", ",", "clip_coef", ")", ")", "\n", "for", "name", ",", "norm", "in", "sorted", "(", "param_to_norm", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", ":", "\n", "            ", "print", "(", "\"{:<60s}: {:.3f}, ({}: {})\"", ".", "format", "(", "name", ",", "norm", ",", "np", ".", "prod", "(", "param_to_shape", "[", "name", "]", ")", ",", "param_to_shape", "[", "name", "]", ")", ")", "\n", "", "print", "(", "'-------------------------------'", ",", "flush", "=", "True", ")", "\n", "", "if", "log_verbose", ":", "\n", "        ", "logger", ".", "info", "(", "'---Total norm {:.3f} clip coef {:.3f}-----------------'", ".", "format", "(", "total_norm", ",", "clip_coef", ")", ")", "\n", "for", "name", ",", "norm", "in", "sorted", "(", "param_to_norm", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"{:<60s}: {:.3f}, ({}: {})\"", ".", "format", "(", "name", ",", "norm", ",", "np", ".", "prod", "(", "param_to_shape", "[", "name", "]", ")", ",", "param_to_shape", "[", "name", "]", ")", ")", "\n", "", "logger", ".", "info", "(", "'-------------------------------'", ")", "\n", "\n", "", "return", "{", "name", ":", "norm", ".", "item", "(", ")", "for", "name", ",", "norm", "in", "param_to_norm", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.bn_fp16_half_eval": [[118, 122], ["str", "m.half"], "function", ["None"], ["", "def", "bn_fp16_half_eval", "(", "m", ")", ":", "\n", "    ", "classname", "=", "str", "(", "m", ".", "__class__", ")", "\n", "if", "'BatchNorm'", "in", "classname", "and", "(", "not", "m", ".", "training", ")", ":", "\n", "        ", "m", ".", "half", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.misc.soft_cross_entropy": [[124, 152], ["valid.sum().item", "input.new_zeros", "valid.sum", "input.new_zeros", "ValueError", "target.sum", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "function", ["None"], ["", "", "def", "soft_cross_entropy", "(", "input", ",", "target", ",", "reduction", "=", "'mean'", ")", ":", "\n", "    ", "\"\"\"\n    Cross entropy loss with input logits and soft target\n    :param input: Tensor, size: (N, C)\n    :param target: Tensor, size: (N, C)\n    :param reduction: 'none' or 'mean' or 'sum', default: 'mean'\n    :return: loss\n    \"\"\"", "\n", "eps", "=", "1.0e-1", "\n", "# debug = False", "\n", "valid", "=", "(", "target", ".", "sum", "(", "1", ")", "-", "1", ")", ".", "abs", "(", ")", "<", "eps", "\n", "# if debug:", "\n", "#     print('valid', valid.sum().item())", "\n", "#     print('all', valid.numel())", "\n", "#     print('non valid')", "\n", "#     print(target[valid == 0])", "\n", "if", "valid", ".", "sum", "(", ")", ".", "item", "(", ")", "==", "0", ":", "\n", "        ", "return", "input", ".", "new_zeros", "(", "(", ")", ")", "\n", "", "if", "reduction", "==", "'mean'", ":", "\n", "        ", "return", "(", "-", "F", ".", "log_softmax", "(", "input", "[", "valid", "]", ",", "1", ")", "*", "target", "[", "valid", "]", ")", ".", "sum", "(", "1", ")", ".", "mean", "(", "0", ")", "\n", "", "elif", "reduction", "==", "'sum'", ":", "\n", "        ", "return", "(", "-", "F", ".", "log_softmax", "(", "input", "[", "valid", "]", ",", "1", ")", "*", "target", "[", "valid", "]", ")", ".", "sum", "(", ")", "\n", "", "elif", "reduction", "==", "'none'", ":", "\n", "        ", "l", "=", "input", ".", "new_zeros", "(", "(", "input", ".", "shape", "[", "0", "]", ",", ")", ")", "\n", "l", "[", "valid", "]", "=", "(", "-", "F", ".", "log_softmax", "(", "input", "[", "valid", "]", ",", "1", ")", "*", "target", "[", "valid", "]", ")", ".", "sum", "(", "1", ")", "\n", "return", "l", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Not support reduction type: {}.'", ".", "format", "(", "reduction", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.pad_sequence.pad_sequence": [[4, 18], ["sequence.new_zeros", "enumerate", "len", "max"], "function", ["None"], ["def", "pad_sequence", "(", "sequence", ",", "lengths", ")", ":", "\n", "    ", "\"\"\"\n    :param sequence: [\\sum b, .....] sequence\n    :param lengths: [b1, b2, b3...] that sum to \\sum b\n    :return: [len(lengths), maxlen(b), .....] tensor\n    \"\"\"", "\n", "\n", "output", "=", "sequence", ".", "new_zeros", "(", "len", "(", "lengths", ")", ",", "max", "(", "lengths", ")", ",", "*", "sequence", ".", "shape", "[", "1", ":", "]", ")", "\n", "start", "=", "0", "\n", "for", "i", ",", "diff", "in", "enumerate", "(", "lengths", ")", ":", "\n", "        ", "if", "diff", ">", "0", ":", "\n", "            ", "output", "[", "i", ",", ":", "diff", "]", "=", "sequence", "[", "start", ":", "(", "start", "+", "diff", ")", "]", "\n", "", "start", "+=", "diff", "\n", "", "return", "output", "\n", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.flatten.Flattener.__init__": [[5, 10], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Flattens last 3 dimensions to make it only batch size, -1\n        \"\"\"", "\n", "super", "(", "Flattener", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.flatten.Flattener.forward": [[11, 13], ["x.view", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.clip_pad.clip_pad_images": [[4, 21], ["isinstance", "torch.as_tensor", "torch.zeros", "min", "min", "min", "min"], "function", ["None"], ["def", "clip_pad_images", "(", "tensor", ",", "pad_shape", ",", "pad", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Clip clip_pad_images of the pad area.\n    :param tensor: [c, H, W]\n    :param pad_shape: [h, w]\n    :return: [c, h, w]\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "tensor", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "tensor", "=", "torch", ".", "as_tensor", "(", "tensor", ")", "\n", "", "H", ",", "W", "=", "tensor", ".", "shape", "[", "1", ":", "]", "\n", "h", "=", "pad_shape", "[", "1", "]", "\n", "w", "=", "pad_shape", "[", "2", "]", "\n", "\n", "tensor_ret", "=", "torch", ".", "zeros", "(", "(", "tensor", ".", "shape", "[", "0", "]", ",", "h", ",", "w", ")", ",", "dtype", "=", "tensor", ".", "dtype", ")", "+", "pad", "\n", "tensor_ret", "[", ":", ",", ":", "min", "(", "h", ",", "H", ")", ",", ":", "min", "(", "w", ",", "W", ")", "]", "=", "tensor", "[", ":", ",", ":", "min", "(", "h", ",", "H", ")", ",", ":", "min", "(", "w", ",", "W", ")", "]", "\n", "\n", "return", "tensor_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.clip_pad.clip_pad_boxes": [[23, 39], ["isinstance", "torch.as_tensor", "torch.zeros", "min", "min"], "function", ["None"], ["", "def", "clip_pad_boxes", "(", "tensor", ",", "pad_length", ",", "pad", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n        Clip boxes of the pad area.\n        :param tensor: [k, d]\n        :param pad_shape: K\n        :return: [K, d]\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "tensor", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "tensor", "=", "torch", ".", "as_tensor", "(", "tensor", ")", "\n", "", "k", "=", "tensor", ".", "shape", "[", "0", "]", "\n", "d", "=", "tensor", ".", "shape", "[", "1", "]", "\n", "K", "=", "pad_length", "\n", "tensor_ret", "=", "torch", ".", "zeros", "(", "(", "K", ",", "d", ")", ",", "dtype", "=", "tensor", ".", "dtype", ")", "+", "pad", "\n", "tensor_ret", "[", ":", "min", "(", "k", ",", "K", ")", ",", ":", "]", "=", "tensor", "[", ":", "min", "(", "k", ",", "K", ")", ",", ":", "]", "\n", "\n", "return", "tensor_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.clip_pad.clip_pad_1d": [[41, 48], ["isinstance", "torch.as_tensor", "torch.zeros", "min", "min"], "function", ["None"], ["", "def", "clip_pad_1d", "(", "tensor", ",", "pad_length", ",", "pad", "=", "0", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "tensor", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "tensor", "=", "torch", ".", "as_tensor", "(", "tensor", ")", "\n", "", "tensor_ret", "=", "torch", ".", "zeros", "(", "(", "pad_length", ",", ")", ",", "dtype", "=", "tensor", ".", "dtype", ")", "+", "pad", "\n", "tensor_ret", "[", ":", "min", "(", "tensor", ".", "shape", "[", "0", "]", ",", "pad_length", ")", "]", "=", "tensor", "[", ":", "min", "(", "tensor", ".", "shape", "[", "0", "]", ",", "pad_length", ")", "]", "\n", "\n", "return", "tensor_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.clip_pad.clip_pad_2d": [[50, 58], ["isinstance", "torch.as_tensor", "torch.zeros", "min", "min", "min", "min"], "function", ["None"], ["", "def", "clip_pad_2d", "(", "tensor", ",", "pad_shape", ",", "pad", "=", "0", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "tensor", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "tensor", "=", "torch", ".", "as_tensor", "(", "tensor", ")", "\n", "", "tensor_ret", "=", "torch", ".", "zeros", "(", "*", "pad_shape", ",", "dtype", "=", "tensor", ".", "dtype", ")", "+", "pad", "\n", "tensor_ret", "[", ":", "min", "(", "tensor", ".", "shape", "[", "0", "]", ",", "pad_shape", "[", "0", "]", ")", ",", ":", "min", "(", "tensor", ".", "shape", "[", "1", "]", ",", "pad_shape", "[", "1", "]", ")", "]", "=", "tensor", "[", ":", "min", "(", "tensor", ".", "shape", "[", "0", "]", ",", "pad_shape", "[", "0", "]", ")", ",", ":", "min", "(", "tensor", ".", "shape", "[", "1", "]", ",", "pad_shape", "[", "1", "]", ")", "]", "\n", "\n", "return", "tensor_ret", "\n", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.create_logger.makedirsExist": [[14, 22], ["os.makedirs", "print"], "function", ["None"], ["def", "makedirsExist", "(", "path", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "", "except", "OSError", "as", "e", ":", "\n", "        ", "if", "e", ".", "errno", "==", "errno", ".", "EEXIST", ":", "\n", "            ", "print", "(", "'Directory not created.'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.create_logger.create_logger": [[24, 49], ["os.path.exists", "os.path.join", "os.path.join", "logging.basicConfig", "logging.getLogger", "logging.getLogger.setLevel", "os.path.exists", "create_logger.makedirsExist", "os.path.splitext", "os.path.exists", "create_logger.makedirsExist", "os.path.exists", "create_logger.makedirsExist", "time.strftime", "os.path.basename", "os.path.join"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.create_logger.makedirsExist", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.create_logger.makedirsExist", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.create_logger.makedirsExist"], ["", "", "", "def", "create_logger", "(", "root_output_path", ",", "config_file", ",", "image_set", ",", "split", "=", "'train'", ",", "hypers", "=", "(", ")", ")", ":", "\n", "# set up logger", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "root_output_path", ")", ":", "\n", "        ", "makedirsExist", "(", "root_output_path", ")", "\n", "", "assert", "os", ".", "path", ".", "exists", "(", "root_output_path", ")", ",", "'{} does not exist'", ".", "format", "(", "root_output_path", ")", "\n", "\n", "cfg_name", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "config_file", ")", ")", "[", "0", "]", "\n", "\n", "config_output_path", "=", "os", ".", "path", ".", "join", "(", "root_output_path", ",", "'{}'", ".", "format", "(", "cfg_name", ")", ")", "\n", "for", "(", "hyper_name", ",", "hyper_val", ")", "in", "hypers", ":", "\n", "        ", "config_output_path", "+=", "'@{}={}'", ".", "format", "(", "hyper_name", ",", "hyper_val", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "config_output_path", ")", ":", "\n", "        ", "makedirsExist", "(", "config_output_path", ")", "\n", "\n", "", "final_output_path", "=", "os", ".", "path", ".", "join", "(", "config_output_path", ",", "image_set", "+", "'_'", "+", "split", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "final_output_path", ")", ":", "\n", "        ", "makedirsExist", "(", "final_output_path", ")", "\n", "\n", "", "log_file", "=", "'{}_{}.log'", ".", "format", "(", "cfg_name", ",", "time", ".", "strftime", "(", "'%Y-%m-%d-%H-%M'", ")", ")", "\n", "head", "=", "'%(asctime)-15s %(message)s'", "\n", "logging", ".", "basicConfig", "(", "filename", "=", "os", ".", "path", ".", "join", "(", "final_output_path", ",", "log_file", ")", ",", "format", "=", "head", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "\n", "return", "logger", ",", "final_output_path", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.mask.generate_instance_mask": [[5, 33], ["torch.zeros", "float", "float", "seg_poly.detach().clone.type", "skimage.draw.polygon", "seg_poly.detach().clone.detach().clone", "seg_poly[].clamp", "seg_poly[].clamp", "seg_poly.detach().clone.detach"], "function", ["None"], ["def", "generate_instance_mask", "(", "seg_polys", ",", "box", ",", "mask_size", "=", "(", "14", ",", "14", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "copy", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Generate instance mask from polygon\n    :param seg_poly: torch.Tensor, (N, 2), (x, y) coordinate of N vertices of segmented foreground polygon\n    :param box: array-like, (4, ), (xmin, ymin, xmax, ymax), instance bounding box\n    :param mask_size: tuple, (mask_height, mask_weight)\n    :param dtype: data type of generated mask\n    :param copy: whether copy seg_polys to a new tensor first\n    :return: torch.Tensor, of mask_size, instance mask\n    \"\"\"", "\n", "mask", "=", "torch", ".", "zeros", "(", "mask_size", ",", "dtype", "=", "dtype", ")", "\n", "w_ratio", "=", "float", "(", "mask_size", "[", "0", "]", ")", "/", "(", "box", "[", "2", "]", "-", "box", "[", "0", "]", "+", "1", ")", "\n", "h_ratio", "=", "float", "(", "mask_size", "[", "1", "]", ")", "/", "(", "box", "[", "3", "]", "-", "box", "[", "1", "]", "+", "1", ")", "\n", "\n", "# import IPython", "\n", "# IPython.embed()", "\n", "\n", "for", "seg_poly", "in", "seg_polys", ":", "\n", "        ", "if", "copy", ":", "\n", "            ", "seg_poly", "=", "seg_poly", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "", "seg_poly", "=", "seg_poly", ".", "type", "(", "torch", ".", "float32", ")", "\n", "seg_poly", "[", ":", ",", "0", "]", "=", "(", "seg_poly", "[", ":", ",", "0", "]", "-", "box", "[", "0", "]", ")", "*", "w_ratio", "\n", "seg_poly", "[", ":", ",", "1", "]", "=", "(", "seg_poly", "[", ":", ",", "1", "]", "-", "box", "[", "1", "]", ")", "*", "h_ratio", "\n", "rr", ",", "cc", "=", "polygon", "(", "seg_poly", "[", ":", ",", "1", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "mask_size", "[", "1", "]", "-", "1", ")", ",", "\n", "seg_poly", "[", ":", ",", "0", "]", ".", "clamp", "(", "min", "=", "0", ",", "max", "=", "mask_size", "[", "0", "]", "-", "1", ")", ")", "\n", "\n", "mask", "[", "rr", ",", "cc", "]", "=", "1", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.bert_encoder_wrapper.BertEncoderWrapper.__init__": [[7, 21], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "external.pytorch_pretrained_bert.modeling.BertEncoder", "bert_encoder_wrapper.BertEncoderWrapper.apply", "torch.Embedding", "torch.Embedding", "external.pytorch_pretrained_bert.modeling.BertLayerNorm", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "bert_config", ",", "input_size", ",", "output_all_encoded_layers", "=", "False", ")", ":", "\n", "        ", "super", "(", "BertEncoderWrapper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bert_config", "=", "bert_config", "\n", "self", ".", "output_all_encoded_layers", "=", "output_all_encoded_layers", "\n", "self", ".", "input_transform", "=", "nn", ".", "Linear", "(", "input_size", ",", "bert_config", ".", "hidden_size", ")", "\n", "self", ".", "with_position_embeddings", "=", "False", "if", "'with_position_embeddings'", "not", "in", "bert_config", "else", "bert_config", ".", "with_position_embeddings", "\n", "if", "self", ".", "with_position_embeddings", ":", "\n", "            ", "self", ".", "position_embedding", "=", "nn", ".", "Embedding", "(", "bert_config", ".", "max_position_embeddings", ",", "bert_config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "bert_config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "bert_config", ".", "hidden_dropout_prob", ")", "\n", "", "self", ".", "bert_encoder", "=", "BertEncoder", "(", "bert_config", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.bert_encoder_wrapper.BertEncoderWrapper.init_bert_weights": [[22, 34], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "init_bert_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "bert_config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "BertLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.bert_encoder_wrapper.BertEncoderWrapper.get_output_dim": [[35, 37], ["None"], "methods", ["None"], ["", "", "def", "get_output_dim", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "bert_config", ".", "hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.bert_encoder_wrapper.BertEncoderWrapper.forward": [[38, 63], ["bert_encoder_wrapper.BertEncoderWrapper.input_transform", "mask.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "bert_encoder_wrapper.BertEncoderWrapper.bert_encoder", "bert_encoder_wrapper.BertEncoderWrapper.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "bert_encoder_wrapper.BertEncoderWrapper.position_embedding", "bert_encoder_wrapper.BertEncoderWrapper.LayerNorm", "bert_encoder_wrapper.BertEncoderWrapper.dropout", "mask.unsqueeze", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze", "next", "bert_encoder_wrapper.BertEncoderWrapper.parameters"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "mask", ")", ":", "\n", "        ", "inputs", "=", "self", ".", "input_transform", "(", "inputs", ")", "\n", "if", "self", ".", "with_position_embeddings", ":", "\n", "            ", "seq_length", "=", "inputs", ".", "size", "(", "1", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "inputs", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "(", "inputs", ".", "shape", "[", "0", "]", ",", "inputs", ".", "shape", "[", "1", "]", ")", ")", "\n", "position_embeddings", "=", "self", ".", "position_embedding", "(", "position_ids", ")", "\n", "inputs", "=", "inputs", "+", "position_embeddings", "\n", "inputs", "=", "self", ".", "LayerNorm", "(", "inputs", ")", "\n", "inputs", "=", "self", ".", "dropout", "(", "inputs", ")", "\n", "\n", "", "extended_attention_mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "output", "=", "self", ".", "bert_encoder", "(", "inputs", ",", "\n", "extended_attention_mask", ",", "\n", "output_all_encoded_layers", "=", "self", ".", "output_all_encoded_layers", ")", "\n", "if", "not", "self", ".", "output_all_encoded_layers", ":", "\n", "            ", "output", "=", "output", "[", "0", "]", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.time_distributed.TimeDistributed.__init__": [[19, 22], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "module", ")", ":", "\n", "        ", "super", "(", "TimeDistributed", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_module", "=", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.time_distributed.TimeDistributed.forward": [[23, 52], ["time_distributed.TimeDistributed._module", "isinstance", "input_tensor.size", "reshaped_inputs.append", "time_distributed.TimeDistributed.contiguous().view", "isinstance", "len", "RuntimeError", "input_tensor.contiguous().view", "tuple", "ValueError", "time_distributed.TimeDistributed.contiguous", "tuple.append", "str", "input_tensor.contiguous", "output.contiguous().view", "time_distributed.TimeDistributed.size", "output.contiguous", "output.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "# pylint: disable=arguments-differ", "\n", "        ", "reshaped_inputs", "=", "[", "]", "\n", "for", "input_tensor", "in", "inputs", ":", "\n", "            ", "input_size", "=", "input_tensor", ".", "size", "(", ")", "\n", "if", "len", "(", "input_size", ")", "<=", "2", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"No dimension to distribute: \"", "+", "str", "(", "input_size", ")", ")", "\n", "\n", "# Squash batch_size and time_steps into a single axis; result has shape", "\n", "# (batch_size * time_steps, input_size).", "\n", "", "squashed_shape", "=", "[", "-", "1", "]", "+", "[", "x", "for", "x", "in", "input_size", "[", "2", ":", "]", "]", "\n", "reshaped_inputs", ".", "append", "(", "input_tensor", ".", "contiguous", "(", ")", ".", "view", "(", "*", "squashed_shape", ")", ")", "\n", "\n", "", "reshaped_outputs", "=", "self", ".", "_module", "(", "*", "reshaped_inputs", ",", "**", "kwargs", ")", "\n", "\n", "if", "isinstance", "(", "reshaped_outputs", ",", "torch", ".", "Tensor", ")", ":", "\n", "# Now get the output back into the right shape.", "\n", "# (batch_size, time_steps, [hidden_size])", "\n", "            ", "new_shape", "=", "[", "input_size", "[", "0", "]", ",", "input_size", "[", "1", "]", "]", "+", "[", "x", "for", "x", "in", "reshaped_outputs", ".", "size", "(", ")", "[", "1", ":", "]", "]", "\n", "outputs", "=", "reshaped_outputs", ".", "contiguous", "(", ")", ".", "view", "(", "*", "new_shape", ")", "\n", "", "elif", "isinstance", "(", "reshaped_outputs", ",", "tuple", ")", ":", "\n", "            ", "outputs", "=", "[", "]", "\n", "for", "output", "in", "reshaped_outputs", ":", "\n", "                ", "new_shape", "=", "[", "input_size", "[", "0", "]", ",", "input_size", "[", "1", "]", "]", "+", "[", "x", "for", "x", "in", "output", ".", "size", "(", ")", "[", "1", ":", "]", "]", "\n", "outputs", ".", "append", "(", "output", ".", "contiguous", "(", ")", ".", "view", "(", "*", "new_shape", ")", ")", "\n", "", "outputs", "=", "tuple", "(", "outputs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Not support!\"", ")", "\n", "\n", "", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.input_variational_dropout.InputVariationalDropout.forward": [[13, 35], ["input_tensor.data.new_ones", "torch.nn.functional.dropout", "torch.nn.functional.dropout.unsqueeze", "torch.nn.functional.dropout.unsqueeze"], "methods", ["None"], ["def", "forward", "(", "self", ",", "input_tensor", ")", ":", "\n", "# pylint: disable=arguments-differ", "\n", "        ", "\"\"\"\n        Apply dropout to input tensor.\n\n        Parameters\n        ----------\n        input_tensor: ``torch.FloatTensor``\n            A tensor of shape ``(batch_size, num_timesteps, embedding_dim)``\n\n        Returns\n        -------\n        output: ``torch.FloatTensor``\n            A tensor of shape ``(batch_size, num_timesteps, embedding_dim)`` with dropout applied.\n        \"\"\"", "\n", "ones", "=", "input_tensor", ".", "data", ".", "new_ones", "(", "input_tensor", ".", "shape", "[", "0", "]", ",", "input_tensor", ".", "shape", "[", "-", "1", "]", ")", "\n", "dropout_mask", "=", "torch", ".", "nn", ".", "functional", ".", "dropout", "(", "ones", ",", "self", ".", "p", ",", "self", ".", "training", ",", "inplace", "=", "False", ")", "\n", "if", "self", ".", "inplace", ":", "\n", "            ", "input_tensor", "*=", "dropout_mask", ".", "unsqueeze", "(", "1", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "            ", "return", "dropout_mask", ".", "unsqueeze", "(", "1", ")", "*", "input_tensor", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.misc.get_align_matrix": [[5, 32], ["len", "max", "torch.zeros", "torch.zeros.sum", "torch.arange"], "function", ["None"], ["import", "logging", "\n", "\n", "\n", "def", "block_digonal_matrix", "(", "*", "blocks", ")", ":", "\n", "    ", "\"\"\"\n    Construct block diagonal matrix\n    :param blocks: blocks of block diagonal matrix\n    :param device\n    :param dtype\n    :return: block diagonal matrix\n    \"\"\"", "\n", "assert", "len", "(", "blocks", ")", ">", "0", "\n", "rows", "=", "[", "block", ".", "shape", "[", "0", "]", "for", "block", "in", "blocks", "]", "\n", "cols", "=", "[", "block", ".", "shape", "[", "1", "]", "for", "block", "in", "blocks", "]", "\n", "out", "=", "torch", ".", "zeros", "(", "(", "sum", "(", "rows", ")", ",", "sum", "(", "cols", ")", ")", ",", "\n", "device", "=", "blocks", "[", "0", "]", ".", "device", ",", "\n", "dtype", "=", "blocks", "[", "0", "]", ".", "dtype", ")", "\n", "cur_row", "=", "0", "\n", "cur_col", "=", "0", "\n", "for", "block", ",", "row", ",", "col", "in", "zip", "(", "blocks", ",", "rows", ",", "cols", ")", ":", "\n", "        ", "out", "[", "cur_row", ":", "(", "cur_row", "+", "row", ")", ",", "cur_col", ":", "(", "cur_col", "+", "col", ")", "]", "=", "block", "\n", "cur_row", "+=", "row", "\n", "cur_col", "+=", "col", "\n", "\n", "", "return", "out", "\n", "\n", "\n", "", "def", "print_and_log", "(", "string", ",", "logger", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.misc.get_all_ngrams": [[34, 47], ["len", "range", "range", "ngrams.append", "range"], "function", ["None"], ["if", "logger", "is", "None", ":", "\n", "        ", "logging", ".", "info", "(", "string", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "string", ")", "\n", "\n", "\n", "", "", "def", "summary_parameters", "(", "model", ",", "logger", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Summary Parameters of Model\n    :param model: torch.nn.module_name\n    :param logger: logger\n    :return: None\n    \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.misc.random_word_with_token_ids": [[49, 82], ["enumerate", "tokenizer.convert_tokens_to_ids", "random.random", "output_label.append", "output_label.append", "random.choice", "list", "tokenizer.vocab.items"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["trainable_paramters", "=", "[", "(", "str", "(", "n", ")", ",", "str", "(", "v", ".", "dtype", ")", ",", "str", "(", "tuple", "(", "v", ".", "shape", ")", ")", ",", "str", "(", "v", ".", "numel", "(", ")", ")", ")", "\n", "for", "n", ",", "v", "in", "model", ".", "named_parameters", "(", ")", "if", "v", ".", "requires_grad", "]", "\n", "max_lens", "=", "[", "max", "(", "[", "len", "(", "item", ")", "+", "4", "for", "item", "in", "col", "]", ")", "for", "col", "in", "zip", "(", "*", "trainable_paramters", ")", "]", "\n", "raw_format", "=", "'|'", "+", "'|'", ".", "join", "(", "[", "'{{:{}s}}'", ".", "format", "(", "max_len", ")", "for", "max_len", "in", "max_lens", "]", ")", "+", "'|'", "\n", "raw_split", "=", "'-'", "*", "(", "sum", "(", "max_lens", ")", "+", "len", "(", "max_lens", ")", "+", "1", ")", "\n", "print_and_log", "(", "raw_split", ",", "logger", ")", "\n", "print_and_log", "(", "raw_format", ".", "format", "(", "'Name'", ",", "'Dtype'", ",", "'Shape'", ",", "'#Params'", ")", ",", "logger", ")", "\n", "print_and_log", "(", "raw_split", ",", "logger", ")", "\n", "\n", "for", "name", ",", "dtype", ",", "shape", ",", "number", "in", "trainable_paramters", ":", "\n", "        ", "print_and_log", "(", "raw_format", ".", "format", "(", "name", ",", "dtype", ",", "shape", ",", "number", ")", ",", "logger", ")", "\n", "print_and_log", "(", "raw_split", ",", "logger", ")", "\n", "\n", "", "num_trainable_params", "=", "sum", "(", "[", "v", ".", "numel", "(", ")", "for", "v", "in", "model", ".", "parameters", "(", ")", "if", "v", ".", "requires_grad", "]", ")", "\n", "total_params", "=", "sum", "(", "[", "v", ".", "numel", "(", ")", "for", "v", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "non_trainable_params", "=", "total_params", "-", "num_trainable_params", "\n", "print_and_log", "(", "'>> {:25s}\\t{:.2f}\\tM'", ".", "format", "(", "'# TrainableParams:'", ",", "num_trainable_params", "/", "(", "1.0", "*", "10", "**", "6", ")", ")", ",", "logger", ")", "\n", "print_and_log", "(", "'>> {:25s}\\t{:.2f}\\tM'", ".", "format", "(", "'# NonTrainableParams:'", ",", "non_trainable_params", "/", "(", "1.0", "*", "10", "**", "6", ")", ")", ",", "logger", ")", "\n", "print_and_log", "(", "'>> {:25s}\\t{:.2f}\\tM'", ".", "format", "(", "'# TotalParams:'", ",", "total_params", "/", "(", "1.0", "*", "10", "**", "6", ")", ")", ",", "logger", ")", "\n", "\n", "\n", "\n", "\n", "", "def", "clip_grad", "(", "named_parameters", ",", "max_norm", ",", "logger", "=", "logging", ",", "std_verbose", "=", "False", ",", "log_verbose", "=", "False", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.encoder_base._EncoderBase.__init__": [[85, 89], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "stateful", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", "_EncoderBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stateful", "=", "stateful", "\n", "self", ".", "_states", ":", "Optional", "[", "RnnStateStorage", "]", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.encoder_base._EncoderBase.sort_and_run_forward": [[90, 177], ["mask.size", "torch.sum().int().item", "encoder_base.get_lengths_from_binary_sequence_mask", "encoder_base.sort_batch_by_length", "torch.nn.utils.rnn.pack_padded_sequence", "module", "sorted_sequence_lengths[].data.tolist", "encoder_base._EncoderBase._get_initial_states", "torch.sum().int", "isinstance", "[].contiguous", "torch.sum", "[].contiguous", "hidden_state.index_select", "state.index_select"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.encoder_base.get_lengths_from_binary_sequence_mask", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.encoder_base.sort_batch_by_length", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.encoder_base._EncoderBase._get_initial_states"], ["", "def", "sort_and_run_forward", "(", "self", ",", "\n", "module", ":", "Callable", "[", "[", "PackedSequence", ",", "Optional", "[", "RnnState", "]", "]", ",", "\n", "Tuple", "[", "Union", "[", "PackedSequence", ",", "torch", ".", "Tensor", "]", ",", "RnnState", "]", "]", ",", "\n", "inputs", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "hidden_state", ":", "Optional", "[", "RnnState", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        This function exists because Pytorch RNNs require that their inputs be sorted\n        before being passed as input. As all of our Seq2xxxEncoders use this functionality,\n        it is provided in a base class. This method can be called on any module which\n        takes as input a ``PackedSequence`` and some ``hidden_state``, which can either be a\n        tuple of tensors or a tensor.\n\n        As all of our Seq2xxxEncoders have different return types, we return `sorted`\n        outputs from the module, which is called directly. Additionally, we return the\n        indices into the batch dimension required to restore the tensor to it's correct,\n        unsorted order and the number of valid batch elements (i.e the number of elements\n        in the batch which are not completely masked). This un-sorting and re-padding\n        of the module outputs is left to the subclasses because their outputs have different\n        types and handling them smoothly here is difficult.\n\n        Parameters\n        ----------\n        module : ``Callable[[PackedSequence, Optional[RnnState]],\n                            Tuple[Union[PackedSequence, torch.Tensor], RnnState]]``, required.\n            A function to run on the inputs. In most cases, this is a ``torch.nn.Module``.\n        inputs : ``torch.Tensor``, required.\n            A tensor of shape ``(batch_size, sequence_length, embedding_size)`` representing\n            the inputs to the Encoder.\n        mask : ``torch.Tensor``, required.\n            A tensor of shape ``(batch_size, sequence_length)``, representing masked and\n            non-masked elements of the sequence for each element in the batch.\n        hidden_state : ``Optional[RnnState]``, (default = None).\n            A single tensor of shape (num_layers, batch_size, hidden_size) representing the\n            state of an RNN with or a tuple of\n            tensors of shapes (num_layers, batch_size, hidden_size) and\n            (num_layers, batch_size, memory_size), representing the hidden state and memory\n            state of an LSTM-like RNN.\n\n        Returns\n        -------\n        module_output : ``Union[torch.Tensor, PackedSequence]``.\n            A Tensor or PackedSequence representing the output of the Pytorch Module.\n            The batch size dimension will be equal to ``num_valid``, as sequences of zero\n            length are clipped off before the module is called, as Pytorch cannot handle\n            zero length sequences.\n        final_states : ``Optional[RnnState]``\n            A Tensor representing the hidden state of the Pytorch Module. This can either\n            be a single tensor of shape (num_layers, num_valid, hidden_size), for instance in\n            the case of a GRU, or a tuple of tensors, such as those required for an LSTM.\n        restoration_indices : ``torch.LongTensor``\n            A tensor of shape ``(batch_size,)``, describing the re-indexing required to transform\n            the outputs back to their original batch order.\n        \"\"\"", "\n", "# In some circumstances you may have sequences of zero length. ``pack_padded_sequence``", "\n", "# requires all sequence lengths to be > 0, so remove sequences of zero length before", "\n", "# calling self._module, then fill with zeros.", "\n", "\n", "# First count how many sequences are empty.", "\n", "batch_size", "=", "mask", ".", "size", "(", "0", ")", "\n", "num_valid", "=", "torch", ".", "sum", "(", "mask", "[", ":", ",", "0", "]", ")", ".", "int", "(", ")", ".", "item", "(", ")", "\n", "\n", "sequence_lengths", "=", "get_lengths_from_binary_sequence_mask", "(", "mask", ")", "\n", "sorted_inputs", ",", "sorted_sequence_lengths", ",", "restoration_indices", ",", "sorting_indices", "=", "sort_batch_by_length", "(", "inputs", ",", "sequence_lengths", ")", "\n", "\n", "# Now create a PackedSequence with only the non-empty, sorted sequences.", "\n", "packed_sequence_input", "=", "pack_padded_sequence", "(", "sorted_inputs", "[", ":", "num_valid", ",", ":", ",", ":", "]", ",", "\n", "sorted_sequence_lengths", "[", ":", "num_valid", "]", ".", "data", ".", "tolist", "(", ")", ",", "\n", "batch_first", "=", "True", ")", "\n", "# Prepare the initial states.", "\n", "if", "not", "self", ".", "stateful", ":", "\n", "            ", "if", "hidden_state", "is", "None", ":", "\n", "                ", "initial_states", "=", "hidden_state", "\n", "", "elif", "isinstance", "(", "hidden_state", ",", "tuple", ")", ":", "\n", "                ", "initial_states", "=", "[", "state", ".", "index_select", "(", "1", ",", "sorting_indices", ")", "[", ":", ",", ":", "num_valid", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "for", "state", "in", "hidden_state", "]", "\n", "", "else", ":", "\n", "                ", "initial_states", "=", "hidden_state", ".", "index_select", "(", "1", ",", "sorting_indices", ")", "[", ":", ",", ":", "num_valid", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "initial_states", "=", "self", ".", "_get_initial_states", "(", "batch_size", ",", "num_valid", ",", "sorting_indices", ")", "\n", "\n", "# Actually call the module on the sorted PackedSequence.", "\n", "", "module_output", ",", "final_states", "=", "module", "(", "packed_sequence_input", ",", "initial_states", ")", "\n", "\n", "return", "module_output", ",", "final_states", ",", "restoration_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.encoder_base._EncoderBase._get_initial_states": [[178, 264], ["encoder_base._EncoderBase._states[].size", "tuple", "len", "correctly_shaped_state.index_select", "tuple", "encoder_base._EncoderBase._states[].size", "state.new_zeros", "resized_states.append", "encoder_base._EncoderBase._states[].size", "tuple", "state.index_select", "state.size", "state.size", "torch.cat"], "methods", ["None"], ["", "def", "_get_initial_states", "(", "self", ",", "\n", "batch_size", ":", "int", ",", "\n", "num_valid", ":", "int", ",", "\n", "sorting_indices", ":", "torch", ".", "LongTensor", ")", "->", "Optional", "[", "RnnState", "]", ":", "\n", "        ", "\"\"\"\n        Returns an initial state for use in an RNN. Additionally, this method handles\n        the batch size changing across calls by mutating the state to append initial states\n        for new elements in the batch. Finally, it also handles sorting the states\n        with respect to the sequence lengths of elements in the batch and removing rows\n        which are completely padded. Importantly, this `mutates` the state if the\n        current batch size is larger than when it was previously called.\n\n        Parameters\n        ----------\n        batch_size : ``int``, required.\n            The batch size can change size across calls to stateful RNNs, so we need\n            to know if we need to expand or shrink the states before returning them.\n            Expanded states will be set to zero.\n        num_valid : ``int``, required.\n            The batch may contain completely padded sequences which get removed before\n            the sequence is passed through the encoder. We also need to clip these off\n            of the state too.\n        sorting_indices ``torch.LongTensor``, required.\n            Pytorch RNNs take sequences sorted by length. When we return the states to be\n            used for a given call to ``module.forward``, we need the states to match up to\n            the sorted sequences, so before returning them, we sort the states using the\n            same indices used to sort the sequences.\n\n        Returns\n        -------\n        This method has a complex return type because it has to deal with the first time it\n        is called, when it has no state, and the fact that types of RNN have heterogeneous\n        states.\n\n        If it is the first time the module has been called, it returns ``None``, regardless\n        of the type of the ``Module``.\n\n        Otherwise, for LSTMs, it returns a tuple of ``torch.Tensors`` with shape\n        ``(num_layers, num_valid, state_size)`` and ``(num_layers, num_valid, memory_size)``\n        respectively, or for GRUs, it returns a single ``torch.Tensor`` of shape\n        ``(num_layers, num_valid, state_size)``.\n        \"\"\"", "\n", "# We don't know the state sizes the first time calling forward,", "\n", "# so we let the module define what it's initial hidden state looks like.", "\n", "if", "self", ".", "_states", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "# Otherwise, we have some previous states.", "\n", "", "if", "batch_size", ">", "self", ".", "_states", "[", "0", "]", ".", "size", "(", "1", ")", ":", "\n", "# This batch is larger than the all previous states.", "\n", "# If so, resize the states.", "\n", "            ", "num_states_to_concat", "=", "batch_size", "-", "self", ".", "_states", "[", "0", "]", ".", "size", "(", "1", ")", "\n", "resized_states", "=", "[", "]", "\n", "# state has shape (num_layers, batch_size, hidden_size)", "\n", "for", "state", "in", "self", ".", "_states", ":", "\n", "# This _must_ be inside the loop because some", "\n", "# RNNs have states with different last dimension sizes.", "\n", "                ", "zeros", "=", "state", ".", "new_zeros", "(", "state", ".", "size", "(", "0", ")", ",", "\n", "num_states_to_concat", ",", "\n", "state", ".", "size", "(", "2", ")", ")", "\n", "resized_states", ".", "append", "(", "torch", ".", "cat", "(", "[", "state", ",", "zeros", "]", ",", "1", ")", ")", "\n", "", "self", ".", "_states", "=", "tuple", "(", "resized_states", ")", "\n", "correctly_shaped_states", "=", "self", ".", "_states", "\n", "\n", "", "elif", "batch_size", "<", "self", ".", "_states", "[", "0", "]", ".", "size", "(", "1", ")", ":", "\n", "# This batch is smaller than the previous one.", "\n", "            ", "correctly_shaped_states", "=", "tuple", "(", "state", "[", ":", ",", ":", "batch_size", ",", ":", "]", "for", "state", "in", "self", ".", "_states", ")", "\n", "", "else", ":", "\n", "            ", "correctly_shaped_states", "=", "self", ".", "_states", "\n", "\n", "# At this point, our states are of shape (num_layers, batch_size, hidden_size).", "\n", "# However, the encoder uses sorted sequences and additionally removes elements", "\n", "# of the batch which are fully padded. We need the states to match up to these", "\n", "# sorted and filtered sequences, so we do that in the next two blocks before", "\n", "# returning the state/s.", "\n", "", "if", "len", "(", "self", ".", "_states", ")", "==", "1", ":", "\n", "# GRUs only have a single state. This `unpacks` it from the", "\n", "# tuple and returns the tensor directly.", "\n", "            ", "correctly_shaped_state", "=", "correctly_shaped_states", "[", "0", "]", "\n", "sorted_state", "=", "correctly_shaped_state", ".", "index_select", "(", "1", ",", "sorting_indices", ")", "\n", "return", "sorted_state", "[", ":", ",", ":", "num_valid", ",", ":", "]", "\n", "", "else", ":", "\n", "# LSTMs have a state tuple of (state, memory).", "\n", "            ", "sorted_states", "=", "[", "state", ".", "index_select", "(", "1", ",", "sorting_indices", ")", "\n", "for", "state", "in", "correctly_shaped_states", "]", "\n", "return", "tuple", "(", "state", "[", ":", ",", ":", "num_valid", ",", ":", "]", "for", "state", "in", "sorted_states", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.encoder_base._EncoderBase._update_states": [[265, 341], ["state.index_select", "tuple", "encoder_base._EncoderBase._states[].size", "final_states[].size", "tuple", "zip", "zip", "new_states.append", "new_states.append", "old_state.detach", "new_state.detach", "state[].sum"], "methods", ["None"], ["", "", "def", "_update_states", "(", "self", ",", "\n", "final_states", ":", "RnnStateStorage", ",", "\n", "restoration_indices", ":", "torch", ".", "LongTensor", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        After the RNN has run forward, the states need to be updated.\n        This method just sets the state to the updated new state, performing\n        several pieces of book-keeping along the way - namely, unsorting the\n        states and ensuring that the states of completely padded sequences are\n        not updated. Finally, it also detaches the state variable from the\n        computational graph, such that the graph can be garbage collected after\n        each batch iteration.\n\n        Parameters\n        ----------\n        final_states : ``RnnStateStorage``, required.\n            The hidden states returned as output from the RNN.\n        restoration_indices : ``torch.LongTensor``, required.\n            The indices that invert the sorting used in ``sort_and_run_forward``\n            to order the states with respect to the lengths of the sequences in\n            the batch.\n        \"\"\"", "\n", "# TODO(Mark): seems weird to sort here, but append zeros in the subclasses.", "\n", "# which way around is best?", "\n", "new_unsorted_states", "=", "[", "state", ".", "index_select", "(", "1", ",", "restoration_indices", ")", "\n", "for", "state", "in", "final_states", "]", "\n", "\n", "if", "self", ".", "_states", "is", "None", ":", "\n", "# We don't already have states, so just set the", "\n", "# ones we receive to be the current state.", "\n", "            ", "self", ".", "_states", "=", "tuple", "(", "state", ".", "data", "for", "state", "in", "new_unsorted_states", ")", "\n", "", "else", ":", "\n", "# Now we've sorted the states back so that they correspond to the original", "\n", "# indices, we need to figure out what states we need to update, because if we", "\n", "# didn't use a state for a particular row, we want to preserve its state.", "\n", "# Thankfully, the rows which are all zero in the state correspond exactly", "\n", "# to those which aren't used, so we create masks of shape (new_batch_size,),", "\n", "# denoting which states were used in the RNN computation.", "\n", "            ", "current_state_batch_size", "=", "self", ".", "_states", "[", "0", "]", ".", "size", "(", "1", ")", "\n", "new_state_batch_size", "=", "final_states", "[", "0", "]", ".", "size", "(", "1", ")", "\n", "# Masks for the unused states of shape (1, new_batch_size, 1)", "\n", "used_new_rows_mask", "=", "[", "(", "state", "[", "0", ",", ":", ",", ":", "]", ".", "sum", "(", "-", "1", ")", "\n", "!=", "0.0", ")", ".", "float", "(", ")", ".", "view", "(", "1", ",", "new_state_batch_size", ",", "1", ")", "\n", "for", "state", "in", "new_unsorted_states", "]", "\n", "new_states", "=", "[", "]", "\n", "if", "current_state_batch_size", ">", "new_state_batch_size", ":", "\n", "# The new state is smaller than the old one,", "\n", "# so just update the indices which we used.", "\n", "                ", "for", "old_state", ",", "new_state", ",", "used_mask", "in", "zip", "(", "self", ".", "_states", ",", "\n", "new_unsorted_states", ",", "\n", "used_new_rows_mask", ")", ":", "\n", "# zero out all rows in the previous state", "\n", "# which _were_ used in the current state.", "\n", "                    ", "masked_old_state", "=", "old_state", "[", ":", ",", ":", "new_state_batch_size", ",", ":", "]", "*", "(", "1", "-", "used_mask", ")", "\n", "# The old state is larger, so update the relevant parts of it.", "\n", "old_state", "[", ":", ",", ":", "new_state_batch_size", ",", ":", "]", "=", "new_state", "+", "masked_old_state", "\n", "new_states", ".", "append", "(", "old_state", ".", "detach", "(", ")", ")", "\n", "", "", "else", ":", "\n", "# The states are the same size, so we just have to", "\n", "# deal with the possibility that some rows weren't used.", "\n", "                ", "new_states", "=", "[", "]", "\n", "for", "old_state", ",", "new_state", ",", "used_mask", "in", "zip", "(", "self", ".", "_states", ",", "\n", "new_unsorted_states", ",", "\n", "used_new_rows_mask", ")", ":", "\n", "# zero out all rows which _were_ used in the current state.", "\n", "                    ", "masked_old_state", "=", "old_state", "*", "(", "1", "-", "used_mask", ")", "\n", "# The old state is larger, so update the relevant parts of it.", "\n", "new_state", "+=", "masked_old_state", "\n", "new_states", ".", "append", "(", "new_state", ".", "detach", "(", ")", ")", "\n", "\n", "# It looks like there should be another case handled here - when", "\n", "# the current_state_batch_size < new_state_batch_size. However,", "\n", "# this never happens, because the states themeselves are mutated", "\n", "# by appending zeros when calling _get_inital_states, meaning that", "\n", "# the new states are either of equal size, or smaller, in the case", "\n", "# that there are some unused elements (zero-length) for the RNN computation.", "\n", "", "", "self", ".", "_states", "=", "tuple", "(", "new_states", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.encoder_base._EncoderBase.reset_states": [[342, 344], ["None"], "methods", ["None"], ["", "", "def", "reset_states", "(", "self", ")", ":", "\n", "        ", "self", ".", "_states", "=", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.encoder_base.get_lengths_from_binary_sequence_mask": [[13, 30], ["mask.long().sum", "mask.long"], "function", ["None"], ["def", "get_lengths_from_binary_sequence_mask", "(", "mask", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"\n    Compute sequence lengths for each batch element in a tensor using a\n    binary mask.\n\n    Parameters\n    ----------\n    mask : torch.Tensor, required.\n        A 2D binary mask of shape (batch_size, sequence_length) to\n        calculate the per-batch sequence lengths from.\n\n    Returns\n    -------\n    A torch.LongTensor of shape (batch_size,) representing the lengths\n    of the sequences in the batch.\n    \"\"\"", "\n", "return", "mask", ".", "long", "(", ")", ".", "sum", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.nlp.encoder_base.sort_batch_by_length": [[32, 70], ["sequence_lengths.sort", "tensor.index_select", "torch.arange", "permutation_index.sort", "torch.arange.index_select", "Exception", "len", "isinstance", "isinstance"], "function", ["None"], ["", "def", "sort_batch_by_length", "(", "tensor", ":", "torch", ".", "Tensor", ",", "sequence_lengths", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"\n    Sort a batch first tensor by some specified lengths.\n\n    Parameters\n    ----------\n    tensor : torch.FloatTensor, required.\n        A batch first Pytorch tensor.\n    sequence_lengths : torch.LongTensor, required.\n        A tensor representing the lengths of some dimension of the tensor which\n        we want to sort by.\n\n    Returns\n    -------\n    sorted_tensor : torch.FloatTensor\n        The original tensor sorted along the batch dimension with respect to sequence_lengths.\n    sorted_sequence_lengths : torch.LongTensor\n        The original sequence_lengths sorted by decreasing size.\n    restoration_indices : torch.LongTensor\n        Indices into the sorted_tensor such that\n        ``sorted_tensor.index_select(0, restoration_indices) == original_tensor``\n    permuation_index : torch.LongTensor\n        The indices used to sort the tensor. This is useful if you want to sort many\n        tensors using the same ordering.\n    \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "tensor", ",", "torch", ".", "Tensor", ")", "or", "not", "isinstance", "(", "sequence_lengths", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"Both the tensor and sequence lengths must be torch.Tensors.\"", ")", "\n", "\n", "", "sorted_sequence_lengths", ",", "permutation_index", "=", "sequence_lengths", ".", "sort", "(", "0", ",", "descending", "=", "True", ")", "\n", "sorted_tensor", "=", "tensor", ".", "index_select", "(", "0", ",", "permutation_index", ")", "\n", "\n", "index_range", "=", "torch", ".", "arange", "(", "0", ",", "len", "(", "sequence_lengths", ")", ",", "device", "=", "sequence_lengths", ".", "device", ")", "\n", "# This is the equivalent of zipping with index, sorting by the original", "\n", "# sequence lengths and returning the now sorted indices.", "\n", "_", ",", "reverse_mapping", "=", "permutation_index", ".", "sort", "(", "0", ",", "descending", "=", "False", ")", "\n", "restoration_indices", "=", "index_range", ".", "index_select", "(", "0", ",", "reverse_mapping", ")", "\n", "return", "sorted_tensor", ",", "sorted_sequence_lengths", ",", "restoration_indices", ",", "permutation_index", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.bert.optimization.ConstantLRSchedule.__init__": [[30, 32], ["torch.optim.lr_scheduler.LambdaLR.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["        ", "return", "x", "/", "warmup", "\n", "", "return", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.bert.optimization.WarmupConstantSchedule.__init__": [[39, 42], ["torch.optim.lr_scheduler.LambdaLR.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["'warmup_cosine'", ":", "warmup_cosine", ",", "\n", "'warmup_constant'", ":", "warmup_constant", ",", "\n", "'warmup_linear'", ":", "warmup_linear", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.bert.optimization.WarmupConstantSchedule.lr_lambda": [[43, 47], ["float", "float", "max"], "methods", ["None"], ["\n", "\n", "class", "BertAdam", "(", "Optimizer", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.bert.optimization.WarmupLinearSchedule.__init__": [[54, 58], ["torch.optim.lr_scheduler.LambdaLR.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.bert.optimization.WarmupLinearSchedule.lr_lambda": [[59, 63], ["max", "float", "float", "float", "float", "max", "max"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "required", ",", "warmup", "=", "-", "1", ",", "t_total", "=", "-", "1", ",", "schedule", "=", "'warmup_linear'", ",", "\n", "b1", "=", "0.9", ",", "b2", "=", "0.999", ",", "e", "=", "1e-6", ",", "weight_decay", "=", "0.01", ",", "\n", "max_grad_norm", "=", "1.0", ")", ":", "\n", "        ", "if", "lr", "is", "not", "required", "and", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.bert.optimization.WarmupCosineSchedule.__init__": [[71, 76], ["torch.optim.lr_scheduler.LambdaLR.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["            ", "raise", "ValueError", "(", "\"Invalid b2 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b2", ")", ")", "\n", "", "if", "not", "e", ">=", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {} - should be >= 0.0\"", ".", "format", "(", "e", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "schedule", "=", "schedule", ",", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "\n", "b1", "=", "b1", ",", "b2", "=", "b2", ",", "e", "=", "e", ",", "weight_decay", "=", "weight_decay", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.bert.optimization.WarmupCosineSchedule.lr_lambda": [[77, 83], ["max", "float", "float", "float", "float", "max", "max", "math.cos", "float"], "methods", ["None"], ["super", "(", "BertAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n", "", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "lr", "=", "[", "]", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "state", "=", "self", ".", "state", "[", "p", "]", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.bert.optimization.WarmupCosineWithHardRestartsSchedule.__init__": [[91, 96], ["torch.optim.lr_scheduler.LambdaLR.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["", "lr", ".", "append", "(", "lr_scheduled", ")", "\n", "", "", "return", "lr", "\n", "\n", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.bert.optimization.WarmupCosineWithHardRestartsSchedule.lr_lambda": [[97, 105], ["max", "float", "float", "float", "float", "max", "max", "math.cos", "float"], "methods", ["None"], ["\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.bert.optimization.AdamW.__init__": [[116, 128], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'next_m'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'next_v'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "next_m", ",", "next_v", "=", "state", "[", "'next_m'", "]", ",", "state", "[", "'next_v'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'b1'", "]", ",", "group", "[", "'b2'", "]", "\n", "\n", "# Add grad clipping", "\n", "if", "group", "[", "'max_grad_norm'", "]", ">", "0", ":", "\n", "                    ", "clip_grad_norm_", "(", "p", ",", "group", "[", "'max_grad_norm'", "]", ")", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.bert.optimization.AdamW.step": [[129, 188], ["closure", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "exp_avg_sq.sqrt().add_", "p.data.addcdiv_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "p.data.add_", "exp_avg.mul_", "exp_avg_sq.mul_", "exp_avg_sq.sqrt", "math.sqrt"], "methods", ["None"], ["\n", "# Decay the first and second moment running average coefficient", "\n", "# In-place operations to update the averages at the same time", "\n", "", "next_m", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "next_v", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "update", "=", "next_m", "/", "(", "next_v", ".", "sqrt", "(", ")", "+", "group", "[", "'e'", "]", ")", "\n", "\n", "# Just adding the square of the weights to the loss function is *not*", "\n", "# the correct way of using L2 regularization/weight decay with Adam,", "\n", "# since that will interact with the m and v parameters in strange ways.", "\n", "#", "\n", "# Instead we want to decay the weights in a manner that doesn't interact", "\n", "# with the m/v parameters. This is equivalent to adding the square", "\n", "# of the weights to the loss with plain (non-momentum) SGD.", "\n", "if", "group", "[", "'weight_decay'", "]", ">", "0.0", ":", "\n", "                    ", "update", "+=", "group", "[", "'weight_decay'", "]", "*", "p", ".", "data", "\n", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "\n", "", "update_with_lr", "=", "lr_scheduled", "*", "update", "\n", "p", ".", "data", ".", "add_", "(", "-", "update_with_lr", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# step_size = lr_scheduled * math.sqrt(bias_correction2) / bias_correction1", "\n", "# No bias correction", "\n", "# bias_correction1 = 1 - beta1 ** state['step']", "\n", "# bias_correction2 = 1 - beta2 ** state['step']", "\n", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.modeling_roberta.RobertaEmbeddings.__init__": [[51, 54], ["external.pytorch_pretrained_bert.modeling.BertEmbeddings.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaEmbeddings", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "padding_idx", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.modeling_roberta.RobertaEmbeddings.forward": [[55, 65], ["input_ids.size", "super().forward", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.forward"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ")", ":", "\n", "        ", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "if", "position_ids", "is", "None", ":", "\n", "# Position numbers begin at padding_idx+1. Padding symbols are ignored.", "\n", "# cf. fairseq's `utils.make_positions`", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "self", ".", "padding_idx", "+", "1", ",", "seq_length", "+", "self", ".", "padding_idx", "+", "1", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "", "return", "super", "(", "RobertaEmbeddings", ",", "self", ")", ".", "forward", "(", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.modeling_roberta.RobertaModel.__init__": [[149, 154], ["external.pytorch_pretrained_bert.modeling.BertModel.__init__", "modeling_roberta.RobertaEmbeddings", "modeling_roberta.RobertaModel.apply"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "embeddings", "=", "RobertaEmbeddings", "(", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.modeling_roberta.RobertaModel.forward": [[155, 161], ["super().forward", "input_ids[].sum().item", "logger.warning", "input_ids[].sum"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.forward"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "if", "input_ids", "[", ":", ",", "0", "]", ".", "sum", "(", ")", ".", "item", "(", ")", "!=", "0", ":", "\n", "            ", "logger", ".", "warning", "(", "\"A sequence with no special tokens has been passed to the RoBERTa model. \"", "\n", "\"This model requires special tokens in order to work. \"", "\n", "\"Please specify add_special_tokens=True in your encoding.\"", ")", "\n", "", "return", "super", "(", "RobertaModel", ",", "self", ")", ".", "forward", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "position_ids", ",", "head_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.modeling_roberta.RobertaForMaskedLM.__init__": [[193, 201], ["external.pytorch_pretrained_bert.modeling.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "modeling_roberta.RobertaLMHead", "modeling_roberta.RobertaForMaskedLM.apply", "modeling_roberta.RobertaForMaskedLM.tie_weights"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.modeling_roberta.RobertaForMaskedLM.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "RobertaLMHead", "(", "config", ")", "\n", "\n", "self", ".", "apply", "(", "self", ".", "init_weights", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.modeling_roberta.RobertaForMaskedLM.tie_weights": [[202, 207], ["modeling_roberta.RobertaForMaskedLM._tie_or_clone_weights"], "methods", ["None"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "lm_head", ".", "decoder", ",", "self", ".", "roberta", ".", "embeddings", ".", "word_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.modeling_roberta.RobertaForMaskedLM.forward": [[208, 223], ["modeling_roberta.RobertaForMaskedLM.roberta", "modeling_roberta.RobertaForMaskedLM.lm_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_roberta.RobertaForMaskedLM.view", "masked_lm_labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ",", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (masked_lm_loss), prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.modeling_roberta.RobertaLMHead.__init__": [[228, 235], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "external.pytorch_pretrained_bert.modeling.BertLayerNorm", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "layer_norm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "config", ".", "vocab_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.modeling_roberta.RobertaLMHead.forward": [[236, 245], ["modeling_roberta.RobertaLMHead.dense", "external.pytorch_pretrained_bert.modeling.gelu", "modeling_roberta.RobertaLMHead.layer_norm", "modeling_roberta.RobertaLMHead.decoder"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.pytorch_pretrained_bert.modeling_openai.gelu"], ["", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "dense", "(", "features", ")", "\n", "x", "=", "gelu", "(", "x", ")", "\n", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# project back to size of vocabulary with bias", "\n", "x", "=", "self", ".", "decoder", "(", "x", ")", "+", "self", ".", "bias", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.modeling_roberta.RobertaForSequenceClassification.__init__": [[278, 284], ["external.pytorch_pretrained_bert.modeling.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "modeling_roberta.RobertaClassificationHead"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "classifier", "=", "RobertaClassificationHead", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.modeling_roberta.RobertaForSequenceClassification.forward": [[285, 304], ["modeling_roberta.RobertaForSequenceClassification.roberta", "modeling_roberta.RobertaForSequenceClassification.classifier", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_roberta.RobertaForSequenceClassification.view", "labels.view", "modeling_roberta.RobertaForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.modeling_roberta.RobertaClassificationHead.__init__": [[309, 314], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaClassificationHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.modeling_roberta.RobertaClassificationHead.forward": [[315, 323], ["modeling_roberta.RobertaClassificationHead.dropout", "modeling_roberta.RobertaClassificationHead.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "modeling_roberta.RobertaClassificationHead.dropout", "modeling_roberta.RobertaClassificationHead.out_proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "features", "[", ":", ",", "0", ",", ":", "]", "# take <s> token (equiv. to [CLS])", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.tokenization_roberta.RobertaTokenizer.__init__": [[74, 92], ["utils.PreTrainedTokenizer.__init__", "json.load", "utils.bytes_to_unicode", "dict", "regex.compile", "io.open", "io.open().read().split", "tuple", "zip", "tokenization_roberta.RobertaTokenizer.encoder.items", "tokenization_roberta.RobertaTokenizer.byte_encoder.items", "merge.split", "range", "io.open().read", "len", "io.open"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.bytes_to_unicode", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.utils.zipreader.ZipReader.read"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "errors", "=", "'replace'", ",", "bos_token", "=", "\"<s>\"", ",", "eos_token", "=", "\"</s>\"", ",", "sep_token", "=", "\"</s>\"", ",", "\n", "cls_token", "=", "\"<s>\"", ",", "unk_token", "=", "\"<unk>\"", ",", "pad_token", "=", "'<pad>'", ",", "mask_token", "=", "'<mask>'", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RobertaTokenizer", ",", "self", ")", ".", "__init__", "(", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ",", "unk_token", "=", "unk_token", ",", "\n", "sep_token", "=", "sep_token", ",", "cls_token", "=", "cls_token", ",", "pad_token", "=", "pad_token", ",", "\n", "mask_token", "=", "mask_token", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "encoder", "=", "json", ".", "load", "(", "open", "(", "vocab_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "errors", "=", "errors", "# how to handle errors in decoding", "\n", "self", ".", "byte_encoder", "=", "bytes_to_unicode", "(", ")", "\n", "self", ".", "byte_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "byte_encoder", ".", "items", "(", ")", "}", "\n", "bpe_data", "=", "open", "(", "merges_file", ",", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "[", "1", ":", "-", "1", "]", "\n", "bpe_merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "bpe_data", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "bpe_merges", ",", "range", "(", "len", "(", "bpe_merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n", "# Should haved added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions", "\n", "self", ".", "pat", "=", "re", ".", "compile", "(", "r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.tokenization_roberta.RobertaTokenizer.vocab_size": [[93, 96], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.tokenization_roberta.RobertaTokenizer.bpe": [[97, 137], ["tuple", "utils.get_pairs", "min", "tuple", "len", "len", "utils.get_pairs", "tuple.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_roberta.RobertaTokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.get_pairs", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.get_pairs", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "word", "=", "tuple", "(", "token", ")", "\n", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "' '", ".", "join", "(", "word", ")", "\n", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.tokenization_roberta.RobertaTokenizer._tokenize": [[138, 148], ["regex.findall", "bpe_tokens.extend", "tokenization_roberta.RobertaTokenizer.bpe().split", "token.encode", "ord", "tokenization_roberta.RobertaTokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.tokenization_roberta.RobertaTokenizer.bpe"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Tokenize a string. \"\"\"", "\n", "bpe_tokens", "=", "[", "]", "\n", "for", "token", "in", "re", ".", "findall", "(", "self", ".", "pat", ",", "text", ")", ":", "\n", "            ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                ", "token", "=", "''", ".", "join", "(", "self", ".", "byte_encoder", "[", "ord", "(", "b", ")", "]", "for", "b", "in", "token", ")", "\n", "", "else", ":", "\n", "                ", "token", "=", "''", ".", "join", "(", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "", "bpe_tokens", ".", "extend", "(", "bpe_token", "for", "bpe_token", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", ")", "\n", "", "return", "bpe_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.tokenization_roberta.RobertaTokenizer._convert_token_to_id": [[149, 152], ["tokenization_roberta.RobertaTokenizer.encoder.get", "tokenization_roberta.RobertaTokenizer.encoder.get"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "encoder", ".", "get", "(", "token", ",", "self", ".", "encoder", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.tokenization_roberta.RobertaTokenizer._convert_id_to_token": [[153, 156], ["tokenization_roberta.RobertaTokenizer.decoder.get"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "get", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.tokenization_roberta.RobertaTokenizer.convert_tokens_to_string": [[157, 162], ["bytearray().decode", "bytearray"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.decode"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "text", "=", "''", ".", "join", "(", "tokens", ")", "\n", "text", "=", "bytearray", "(", "[", "self", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "text", "]", ")", ".", "decode", "(", "'utf-8'", ",", "errors", "=", "self", ".", "errors", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.tokenization_roberta.RobertaTokenizer.add_special_tokens_single_sentence": [[163, 169], ["tokenization_roberta.RobertaTokenizer._convert_token_to_id", "tokenization_roberta.RobertaTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._convert_token_to_id", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._convert_token_to_id"], ["", "def", "add_special_tokens_single_sentence", "(", "self", ",", "token_ids", ")", ":", "\n", "        ", "\"\"\"\n        Adds special tokens to a sequence for sequence classification tasks.\n        A RoBERTa sequence has the following format: [CLS] X [SEP]\n        \"\"\"", "\n", "return", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "cls_token", ")", "]", "+", "token_ids", "+", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "sep_token", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.tokenization_roberta.RobertaTokenizer.add_special_tokens_sentences_pair": [[170, 178], ["tokenization_roberta.RobertaTokenizer._convert_token_to_id", "tokenization_roberta.RobertaTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._convert_token_to_id", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._convert_token_to_id"], ["", "def", "add_special_tokens_sentences_pair", "(", "self", ",", "token_ids_0", ",", "token_ids_1", ")", ":", "\n", "        ", "\"\"\"\n        Adds special tokens to a sequence pair for sequence classification tasks.\n        A RoBERTa sequence pair has the following format: [CLS] A [SEP][SEP] B [SEP]\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "sep_token", ")", "]", "\n", "cls", "=", "[", "self", ".", "_convert_token_to_id", "(", "self", ".", "cls_token", ")", "]", "\n", "return", "cls", "+", "token_ids_0", "+", "sep", "+", "sep", "+", "token_ids_1", "+", "sep", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.tokenization_roberta.RobertaTokenizer.save_vocabulary": [[179, 202], ["os.path.join", "os.path.join", "os.path.isdir", "logger.error", "io.open", "f.write", "io.open", "writer.write", "sorted", "json.dumps", "tokenization_roberta.RobertaTokenizer.bpe_ranks.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary and merge files to a directory.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", ")", "\n", "merge_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "'merges_file'", "]", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "encoder", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "index", "=", "0", "\n", "with", "open", "(", "merge_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "u'#version: 0.2\\n'", ")", "\n", "for", "bpe_tokens", ",", "token_index", "in", "sorted", "(", "self", ".", "bpe_ranks", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\"Saving vocabulary to {}: BPE merge indices are not consecutive.\"", "\n", "\" Please check that the tokenizer is not corrupted!\"", ".", "format", "(", "merge_file", ")", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "' '", ".", "join", "(", "bpe_tokens", ")", "+", "u'\\n'", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "return", "vocab_file", ",", "merge_file", "", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.bos_token": [[367, 370], ["None"], "methods", ["None"], ["", "@", "bos_token", ".", "setter", "\n", "def", "bos_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_bos_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.eos_token": [[371, 374], ["None"], "methods", ["None"], ["", "@", "eos_token", ".", "setter", "\n", "def", "eos_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_eos_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.unk_token": [[375, 378], ["None"], "methods", ["None"], ["", "@", "unk_token", ".", "setter", "\n", "def", "unk_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_unk_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.sep_token": [[379, 382], ["None"], "methods", ["None"], ["", "@", "sep_token", ".", "setter", "\n", "def", "sep_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_sep_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.pad_token": [[383, 386], ["None"], "methods", ["None"], ["", "@", "pad_token", ".", "setter", "\n", "def", "pad_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_pad_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.cls_token": [[387, 390], ["None"], "methods", ["None"], ["", "@", "cls_token", ".", "setter", "\n", "def", "cls_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_cls_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.mask_token": [[391, 394], ["None"], "methods", ["None"], ["", "@", "mask_token", ".", "setter", "\n", "def", "mask_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_mask_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.additional_special_tokens": [[395, 398], ["None"], "methods", ["None"], ["", "@", "additional_special_tokens", ".", "setter", "\n", "def", "additional_special_tokens", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_additional_special_tokens", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.__init__": [[399, 421], ["kwargs.items", "int", "setattr", "isinstance", "all", "isinstance", "isinstance", "isinstance", "isinstance"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "max_len", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_bos_token", "=", "None", "\n", "self", ".", "_eos_token", "=", "None", "\n", "self", ".", "_unk_token", "=", "None", "\n", "self", ".", "_sep_token", "=", "None", "\n", "self", ".", "_pad_token", "=", "None", "\n", "self", ".", "_cls_token", "=", "None", "\n", "self", ".", "_mask_token", "=", "None", "\n", "self", ".", "_additional_special_tokens", "=", "[", "]", "\n", "\n", "self", ".", "max_len", "=", "max_len", "if", "max_len", "is", "not", "None", "else", "int", "(", "1e12", ")", "\n", "self", ".", "added_tokens_encoder", "=", "{", "}", "\n", "self", ".", "added_tokens_decoder", "=", "{", "}", "\n", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "in", "self", ".", "SPECIAL_TOKENS_ATTRIBUTES", ":", "\n", "                ", "if", "key", "==", "'additional_special_tokens'", ":", "\n", "                    ", "assert", "isinstance", "(", "value", ",", "(", "list", ",", "tuple", ")", ")", "and", "all", "(", "\n", "isinstance", "(", "t", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "t", ",", "unicode", ")", ")", "for", "t", "in", "value", ")", "\n", "", "else", ":", "\n", "                    ", "assert", "isinstance", "(", "value", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "value", ",", "unicode", ")", ")", "\n", "", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.from_pretrained": [[422, 450], ["cls._from_pretrained"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._from_pretrained"], ["", "", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"\n        Instantiate a :class:`~pytorch_transformers.PreTrainedTokenizer` (or a derived class) from a predefined tokenizer.\n        Args:\n            pretrained_model_name_or_path: either:\n                - a string with the `shortcut name` of a predefined tokenizer to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing vocabulary files required by the tokenizer, for instance saved using the :func:`~pytorch_transformers.PreTrainedTokenizer.save_pretrained` method, e.g.: ``./my_model_directory/``.\n                - (not applicable to all derived classes) a path or url to a single saved vocabulary file if and only if the tokenizer only requires a single vocabulary file (e.g. Bert, XLNet), e.g.: ``./my_model_directory/vocab.txt``.\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded predefined tokenizer vocabulary files should be cached if the standard cache should not be used.\n            inputs: (`optional`) positional arguments: will be passed to the Tokenizer ``__init__`` method.\n            kwargs: (`optional`) keyword arguments: will be passed to the Tokenizer ``__init__`` method. Can be used to set special tokens like ``bos_token``, ``eos_token``, ``unk_token``, ``sep_token``, ``pad_token``, ``cls_token``, ``mask_token``, ``additional_special_tokens``. See parameters in the doc string of :class:`~pytorch_transformers.PreTrainedTokenizer` for details.\n        Examples::\n            # We can't instantiate directly the base class `PreTrainedTokenizer` so let's show our examples on a derived class: BertTokenizer\n            # Download vocabulary from S3 and cache.\n            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n            # If vocabulary files are in a directory (e.g. tokenizer was saved using `save_pretrained('./test/saved_model/')`)\n            tokenizer = BertTokenizer.from_pretrained('./test/saved_model/')\n            # If the tokenizer uses a single vocabulary file, you can point directly to this file\n            tokenizer = BertTokenizer.from_pretrained('./test/saved_model/my_vocab.txt')\n            # You can link tokens to special vocabulary when instantiating\n            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', unk_token='<unk>')\n            # You should be sure '<unk>' is in the vocabulary when doing that.\n            # Otherwise use tokenizer.add_special_tokens({'unk_token': '<unk>'}) instead)\n            assert tokenizer.unk_token == '<unk>'\n        \"\"\"", "\n", "return", "cls", ".", "_from_pretrained", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._from_pretrained": [[451, 565], ["kwargs.pop", "list", "vocab_files.items", "resolved_vocab_files.pop", "resolved_vocab_files.pop", "resolved_vocab_files.items", "cls", "cls.max_model_input_sizes.keys", "cls.pretrained_vocab_files_map.items", "logger.info", "cls.vocab_files_names.items", "all_vocab_files_names.items", "all", "vocab_files.items", "json.load", "json.load.items", "json.load", "cls.added_tokens_encoder.update", "cls.added_tokens_decoder.update", "os.path.isdir", "os.path.exists", "os.path.dirname", "os.path.join", "logger.error", "logger.info", "logger.info", "isinstance", "min", "io.open", "io.open", "os.path.join", "os.path.exists", "logger.info", "os.path.isdir", "os.path.exists", "logger.info", "utils.cached_path", "logger.error", "logger.error", "kwargs.get", "json.load.items", "vocab_files.values", "int", "str", "vocab_files.keys"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.cached_path", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["", "@", "classmethod", "\n", "def", "_from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "cache_dir", "=", "kwargs", ".", "pop", "(", "'cache_dir'", ",", "None", ")", "\n", "\n", "s3_models", "=", "list", "(", "cls", ".", "max_model_input_sizes", ".", "keys", "(", ")", ")", "\n", "vocab_files", "=", "{", "}", "\n", "if", "pretrained_model_name_or_path", "in", "s3_models", ":", "\n", "# Get the vocabulary from AWS S3 bucket", "\n", "            ", "for", "file_id", ",", "map_list", "in", "cls", ".", "pretrained_vocab_files_map", ".", "items", "(", ")", ":", "\n", "                ", "vocab_files", "[", "file_id", "]", "=", "map_list", "[", "pretrained_model_name_or_path", "]", "\n", "", "", "else", ":", "\n", "# Get the vocabulary from local files", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Model name '{}' not found in model shortcut name list ({}). \"", "\n", "\"Assuming '{}' is a path or url to a directory containing tokenizer files.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "', '", ".", "join", "(", "s3_models", ")", ",", "\n", "pretrained_model_name_or_path", ")", ")", "\n", "\n", "# Look for the tokenizer main vocabulary files", "\n", "for", "file_id", ",", "file_name", "in", "cls", ".", "vocab_files_names", ".", "items", "(", ")", ":", "\n", "                ", "if", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "# If a directory is provided we look for the standard filenames", "\n", "                    ", "full_file_name", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "file_name", ")", "\n", "", "else", ":", "\n", "# If a path to a file is provided we use it (will only work for non-BPE tokenizer using a single vocabulary file)", "\n", "                    ", "full_file_name", "=", "pretrained_model_name_or_path", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "full_file_name", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Didn't find file {}. We won't load it.\"", ".", "format", "(", "full_file_name", ")", ")", "\n", "full_file_name", "=", "None", "\n", "", "vocab_files", "[", "file_id", "]", "=", "full_file_name", "\n", "\n", "# Look for the additional tokens files", "\n", "", "all_vocab_files_names", "=", "{", "'added_tokens_file'", ":", "ADDED_TOKENS_FILE", ",", "\n", "'special_tokens_map_file'", ":", "SPECIAL_TOKENS_MAP_FILE", "}", "\n", "\n", "# If a path to a file was provided, get the parent directory", "\n", "saved_directory", "=", "pretrained_model_name_or_path", "\n", "if", "os", ".", "path", ".", "exists", "(", "saved_directory", ")", "and", "not", "os", ".", "path", ".", "isdir", "(", "saved_directory", ")", ":", "\n", "                ", "saved_directory", "=", "os", ".", "path", ".", "dirname", "(", "saved_directory", ")", "\n", "\n", "", "for", "file_id", ",", "file_name", "in", "all_vocab_files_names", ".", "items", "(", ")", ":", "\n", "                ", "full_file_name", "=", "os", ".", "path", ".", "join", "(", "saved_directory", ",", "file_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "full_file_name", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Didn't find file {}. We won't load it.\"", ".", "format", "(", "full_file_name", ")", ")", "\n", "full_file_name", "=", "None", "\n", "", "vocab_files", "[", "file_id", "]", "=", "full_file_name", "\n", "\n", "", "if", "all", "(", "full_file_name", "is", "None", "for", "full_file_name", "in", "vocab_files", ".", "values", "(", ")", ")", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find tokenizer files\"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "', '", ".", "join", "(", "s3_models", ")", ",", "\n", "pretrained_model_name_or_path", ",", ")", ")", "\n", "return", "None", "\n", "\n", "# Get files from url, cache, or disk depending on the case", "\n", "", "", "try", ":", "\n", "            ", "resolved_vocab_files", "=", "{", "}", "\n", "for", "file_id", ",", "file_path", "in", "vocab_files", ".", "items", "(", ")", ":", "\n", "                ", "if", "file_path", "is", "None", ":", "\n", "                    ", "resolved_vocab_files", "[", "file_id", "]", "=", "None", "\n", "", "else", ":", "\n", "                    ", "resolved_vocab_files", "[", "file_id", "]", "=", "cached_path", "(", "file_path", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "", "", "except", "EnvironmentError", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "s3_models", ":", "\n", "                ", "logger", ".", "error", "(", "\"Couldn't reach server to download vocabulary.\"", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "', '", ".", "join", "(", "s3_models", ")", ",", "\n", "pretrained_model_name_or_path", ",", "str", "(", "vocab_files", ".", "keys", "(", ")", ")", ")", ")", "\n", "", "return", "None", "\n", "\n", "", "for", "file_id", ",", "file_path", "in", "vocab_files", ".", "items", "(", ")", ":", "\n", "            ", "if", "file_path", "==", "resolved_vocab_files", "[", "file_id", "]", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading file {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading file {} from cache at {}\"", ".", "format", "(", "\n", "file_path", ",", "resolved_vocab_files", "[", "file_id", "]", ")", ")", "\n", "\n", "# Set max length if needed", "\n", "", "", "if", "pretrained_model_name_or_path", "in", "cls", ".", "max_model_input_sizes", ":", "\n", "# if we're using a pretrained model, ensure the tokenizer", "\n", "# wont index sequences longer than the number of positional embeddings", "\n", "            ", "max_len", "=", "cls", ".", "max_model_input_sizes", "[", "pretrained_model_name_or_path", "]", "\n", "if", "max_len", "is", "not", "None", "and", "isinstance", "(", "max_len", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "                ", "kwargs", "[", "'max_len'", "]", "=", "min", "(", "kwargs", ".", "get", "(", "'max_len'", ",", "int", "(", "1e12", ")", ")", ",", "max_len", ")", "\n", "\n", "# Merge resolved_vocab_files arguments in kwargs.", "\n", "", "", "added_tokens_file", "=", "resolved_vocab_files", ".", "pop", "(", "'added_tokens_file'", ",", "None", ")", "\n", "special_tokens_map_file", "=", "resolved_vocab_files", ".", "pop", "(", "'special_tokens_map_file'", ",", "None", ")", "\n", "for", "args_name", ",", "file_path", "in", "resolved_vocab_files", ".", "items", "(", ")", ":", "\n", "            ", "if", "args_name", "not", "in", "kwargs", ":", "\n", "                ", "kwargs", "[", "args_name", "]", "=", "file_path", "\n", "", "", "if", "special_tokens_map_file", "is", "not", "None", ":", "\n", "            ", "special_tokens_map", "=", "json", ".", "load", "(", "open", "(", "special_tokens_map_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "for", "key", ",", "value", "in", "special_tokens_map", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "not", "in", "kwargs", ":", "\n", "                    ", "kwargs", "[", "key", "]", "=", "value", "\n", "\n", "# Instantiate tokenizer.", "\n", "", "", "", "tokenizer", "=", "cls", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "# Add supplementary tokens.", "\n", "if", "added_tokens_file", "is", "not", "None", ":", "\n", "            ", "added_tok_encoder", "=", "json", ".", "load", "(", "open", "(", "added_tokens_file", ",", "encoding", "=", "\"utf-8\"", ")", ")", "\n", "added_tok_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "added_tok_encoder", ".", "items", "(", ")", "}", "\n", "tokenizer", ".", "added_tokens_encoder", ".", "update", "(", "added_tok_encoder", ")", "\n", "tokenizer", ".", "added_tokens_decoder", ".", "update", "(", "added_tok_decoder", ")", "\n", "\n", "", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.save_pretrained": [[566, 591], ["os.path.join", "os.path.join", "utils.PreTrainedTokenizer.save_vocabulary", "os.path.isdir", "logger.error", "io.open", "f.write", "io.open", "f.write", "json.dumps", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.save_vocabulary"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the tokenizer vocabulary files (with added tokens) and the\n            special-tokens-to-class-attributes-mapping to a directory.\n            This method make sure the full tokenizer can then be re-loaded using the :func:`~pytorch_transformers.PreTrainedTokenizer.from_pretrained` class method.\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Saving directory ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "\n", "", "special_tokens_map_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "SPECIAL_TOKENS_MAP_FILE", ")", "\n", "added_tokens_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "ADDED_TOKENS_FILE", ")", "\n", "\n", "with", "open", "(", "special_tokens_map_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "special_tokens_map", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "with", "open", "(", "added_tokens_file", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "if", "self", ".", "added_tokens_encoder", ":", "\n", "                ", "out_str", "=", "json", ".", "dumps", "(", "self", ".", "added_tokens_encoder", ",", "ensure_ascii", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "out_str", "=", "u\"{}\"", "\n", "", "f", ".", "write", "(", "out_str", ")", "\n", "\n", "", "vocab_files", "=", "self", ".", "save_vocabulary", "(", "save_directory", ")", "\n", "\n", "return", "vocab_files", "+", "(", "special_tokens_map_file", ",", "added_tokens_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.save_vocabulary": [[592, 598], ["None"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the tokenizer vocabulary to a directory. This method does *NOT* save added tokens\n            and special token mappings.\n            Please use :func:`~pytorch_transformers.PreTrainedTokenizer.save_pretrained` `()` to save the full Tokenizer state if you want to reload it using the :func:`~pytorch_transformers.PreTrainedTokenizer.from_pretrained` class method.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.vocab_size": [[599, 602], ["None"], "methods", ["None"], ["", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "\"\"\" Size of the base vocabulary (without the added tokens) \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.__len__": [[603, 606], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Size of the full vocabulary with the added tokens \"\"\"", "\n", "return", "self", ".", "vocab_size", "+", "len", "(", "self", ".", "added_tokens_encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.add_tokens": [[607, 640], ["dict", "utils.PreTrainedTokenizer.added_tokens_encoder.update", "utils.PreTrainedTokenizer.added_tokens_decoder.update", "len", "isinstance", "to_add_tokens.append", "logger.info", "dict.items", "isinstance", "utils.PreTrainedTokenizer.convert_tokens_to_ids", "utils.PreTrainedTokenizer.convert_tokens_to_ids", "enumerate", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "add_tokens", "(", "self", ",", "new_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Add a list of new tokens to the tokenizer class. If the new tokens are not in the\n        vocabulary, they are added to it with indices starting from length of the current vocabulary.\n        Args:\n            new_tokens: list of string. Each string is a token to add. Tokens are only added if they are not already in the vocabulary (tested by checking if the tokenizer assign the index of the ``unk_token`` to them).\n        Returns:\n            Number of tokens added to the vocabulary.\n        Examples::\n            # Let's see how to increase the vocabulary of Bert model and tokenizer\n            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n            model = BertModel.from_pretrained('bert-base-uncased')\n            num_added_toks = tokenizer.add_tokens(['new_tok1', 'my_new-tok2'])\n            print('We have added', num_added_toks, 'tokens')\n            model.resize_token_embeddings(len(tokenizer))  # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e. the length of the tokenizer.\n        \"\"\"", "\n", "if", "not", "new_tokens", ":", "\n", "            ", "return", "0", "\n", "\n", "", "to_add_tokens", "=", "[", "]", "\n", "for", "token", "in", "new_tokens", ":", "\n", "            ", "assert", "isinstance", "(", "token", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "token", ",", "unicode", ")", ")", "\n", "if", "token", "!=", "self", ".", "unk_token", "and", "self", ".", "convert_tokens_to_ids", "(", "token", ")", "==", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "unk_token", ")", ":", "\n", "                ", "to_add_tokens", ".", "append", "(", "token", ")", "\n", "logger", ".", "info", "(", "\"Adding %s to the vocabulary\"", ",", "token", ")", "\n", "\n", "", "", "added_tok_encoder", "=", "dict", "(", "(", "tok", ",", "len", "(", "self", ")", "+", "i", ")", "for", "i", ",", "tok", "in", "enumerate", "(", "to_add_tokens", ")", ")", "\n", "added_tok_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "added_tok_encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "added_tokens_encoder", ".", "update", "(", "added_tok_encoder", ")", "\n", "self", ".", "added_tokens_decoder", ".", "update", "(", "added_tok_decoder", ")", "\n", "\n", "return", "len", "(", "to_add_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.add_special_tokens": [[641, 680], ["special_tokens_dict.items", "logger.info", "setattr", "utils.PreTrainedTokenizer.add_tokens", "utils.PreTrainedTokenizer.add_tokens", "isinstance", "all", "isinstance", "isinstance", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.add_tokens", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.add_tokens"], ["", "def", "add_special_tokens", "(", "self", ",", "special_tokens_dict", ")", ":", "\n", "        ", "\"\"\"\n        Add a dictionary of special tokens (eos, pad, cls...) to the encoder and link them\n        to class attributes. If special tokens are NOT in the vocabulary, they are added\n        to it (indexed starting from the last index of the current vocabulary).\n        Args:\n            special_tokens_dict: dict of string. Keys should be in the list of predefined special attributes:\n                [``bos_token``, ``eos_token``, ``unk_token``, ``sep_token``, ``pad_token``, ``cls_token``, ``mask_token``,\n                ``additional_special_tokens``].\n                Tokens are only added if they are not already in the vocabulary (tested by checking if the tokenizer assign the index of the ``unk_token`` to them).\n        Returns:\n            Number of tokens added to the vocabulary.\n        Examples::\n            # Let's see how to add a new classification token to GPT-2\n            tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n            model = GPT2Model.from_pretrained('gpt2')\n            special_tokens_dict = {'cls_token': '<CLS>'}\n            num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n            print('We have added', num_added_toks, 'tokens')\n            model.resize_token_embeddings(len(tokenizer))  # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e. the length of the tokenizer.\n            assert tokenizer.cls_token == '<CLS>'\n        \"\"\"", "\n", "if", "not", "special_tokens_dict", ":", "\n", "            ", "return", "0", "\n", "\n", "", "added_tokens", "=", "0", "\n", "for", "key", ",", "value", "in", "special_tokens_dict", ".", "items", "(", ")", ":", "\n", "            ", "assert", "key", "in", "self", ".", "SPECIAL_TOKENS_ATTRIBUTES", "\n", "if", "key", "==", "'additional_special_tokens'", ":", "\n", "                ", "assert", "isinstance", "(", "value", ",", "(", "list", ",", "tuple", ")", ")", "and", "all", "(", "\n", "isinstance", "(", "t", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "t", ",", "unicode", ")", ")", "for", "t", "in", "value", ")", "\n", "added_tokens", "+=", "self", ".", "add_tokens", "(", "value", ")", "\n", "", "else", ":", "\n", "                ", "assert", "isinstance", "(", "value", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "value", ",", "unicode", ")", ")", "\n", "added_tokens", "+=", "self", ".", "add_tokens", "(", "[", "value", "]", ")", "\n", "", "logger", ".", "info", "(", "\"Assigning %s to the %s key of the tokenizer\"", ",", "value", ",", "key", ")", "\n", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "\n", "", "return", "added_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize": [[681, 701], ["utils.PreTrainedTokenizer.tokenize.split_on_tokens"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "text", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Converts a string in a sequence of tokens (string), using the tokenizer.\n            Split in words for word-based vocabulary or sub-words for sub-word-based\n            vocabularies (BPE/SentencePieces/WordPieces).\n            Take care of added tokens.\n        \"\"\"", "\n", "\n", "def", "split_on_tokens", "(", "tok_list", ",", "text", ")", ":", "\n", "            ", "if", "not", "text", ":", "\n", "                ", "return", "[", "]", "\n", "", "if", "not", "tok_list", ":", "\n", "                ", "return", "self", ".", "_tokenize", "(", "text", ",", "**", "kwargs", ")", "\n", "", "tok", "=", "tok_list", "[", "0", "]", "\n", "split_text", "=", "text", ".", "split", "(", "tok", ")", "\n", "return", "sum", "(", "(", "split_on_tokens", "(", "tok_list", "[", "1", ":", "]", ",", "sub_text", ".", "strip", "(", ")", ")", "+", "[", "tok", "]", "for", "sub_text", "in", "split_text", ")", ",", "[", "]", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "added_tokens", "=", "list", "(", "self", ".", "added_tokens_encoder", ".", "keys", "(", ")", ")", "+", "self", ".", "all_special_tokens", "\n", "tokenized_text", "=", "split_on_tokens", "(", "added_tokens", ",", "text", ")", "\n", "return", "tokenized_text", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._tokenize": [[702, 709], ["None"], "methods", ["None"], ["", "def", "_tokenize", "(", "self", ",", "text", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Converts a string in a sequence of tokens (string), using the tokenizer.\n            Split in words for word-based vocabulary or sub-words for sub-word-based\n            vocabularies (BPE/SentencePieces/WordPieces).\n            Do NOT take care of added tokens.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids": [[710, 725], ["isinstance", "utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc", "ids.append", "len", "logger.warning", "isinstance", "utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a single token, or a sequence of tokens, (str/unicode) in a single integer id\n            (resp. a sequence of ids), using the vocabulary.\n        \"\"\"", "\n", "if", "isinstance", "(", "tokens", ",", "str", ")", "or", "(", "six", ".", "PY2", "and", "isinstance", "(", "tokens", ",", "unicode", ")", ")", ":", "\n", "            ", "return", "self", ".", "_convert_token_to_id_with_added_voc", "(", "tokens", ")", "\n", "\n", "", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "ids", ".", "append", "(", "self", ".", "_convert_token_to_id_with_added_voc", "(", "token", ")", ")", "\n", "", "if", "len", "(", "ids", ")", ">", "self", ".", "max_len", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Token indices sequence length is longer than the specified maximum sequence length \"", "\n", "\"for this model ({} > {}). Running this sequence through the model will result in \"", "\n", "\"indexing errors\"", ".", "format", "(", "len", "(", "ids", ")", ",", "self", ".", "max_len", ")", ")", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc": [[726, 730], ["utils.PreTrainedTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._convert_token_to_id"], ["", "def", "_convert_token_to_id_with_added_voc", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "added_tokens_encoder", ":", "\n", "            ", "return", "self", ".", "added_tokens_encoder", "[", "token", "]", "\n", "", "return", "self", ".", "_convert_token_to_id", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._convert_token_to_id": [[731, 733], ["None"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.encode": [[734, 758], ["utils.PreTrainedTokenizer._convert_token_to_id", "utils.PreTrainedTokenizer._convert_token_to_id", "utils.PreTrainedTokenizer.add_special_tokens_sentences_pair", "utils.PreTrainedTokenizer.add_special_tokens_single_sentence", "utils.PreTrainedTokenizer.convert_tokens_to_ids", "utils.PreTrainedTokenizer.tokenize", "utils.PreTrainedTokenizer.tokenize", "utils.PreTrainedTokenizer.convert_tokens_to_ids", "utils.PreTrainedTokenizer.tokenize", "utils.PreTrainedTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._convert_token_to_id", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._convert_token_to_id", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.add_special_tokens_sentences_pair", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.add_special_tokens_single_sentence", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.tokenize"], ["", "def", "encode", "(", "self", ",", "text", ",", "text_pair", "=", "None", ",", "add_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Converts a string in a sequence of ids (integer), using the tokenizer and vocabulary.\n\n        Same as doing ``self.convert_tokens_to_ids(self.tokenize(text))``.\n        Args:\n            text: The first sequence to be encoded.\n            text_pair: Optional second sequence to be encoded.\n            add_special_tokens: if set to ``True``, the sequences will be encoded with the special tokens relative\n                to their model.\n        \"\"\"", "\n", "if", "text_pair", "is", "None", ":", "\n", "            ", "if", "add_special_tokens", ":", "\n", "                ", "return", "self", ".", "add_special_tokens_single_sentence", "(", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenize", "(", "text", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenize", "(", "text", ")", ")", "\n", "\n", "", "", "first_sentence_tokens", "=", "[", "self", ".", "_convert_token_to_id", "(", "token", ")", "for", "token", "in", "self", ".", "tokenize", "(", "text", ")", "]", "\n", "second_sentence_tokens", "=", "[", "self", ".", "_convert_token_to_id", "(", "token", ")", "for", "token", "in", "self", ".", "tokenize", "(", "text_pair", ")", "]", "\n", "\n", "if", "add_special_tokens", ":", "\n", "            ", "return", "self", ".", "add_special_tokens_sentences_pair", "(", "first_sentence_tokens", ",", "second_sentence_tokens", ")", "\n", "", "else", ":", "\n", "            ", "return", "first_sentence_tokens", ",", "second_sentence_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.add_special_tokens_single_sentence": [[759, 761], ["None"], "methods", ["None"], ["", "", "def", "add_special_tokens_single_sentence", "(", "self", ",", "token_ids", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.add_special_tokens_sentences_pair": [[762, 764], ["None"], "methods", ["None"], ["", "def", "add_special_tokens_sentences_pair", "(", "self", ",", "token_ids_0", ",", "token_ids_1", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_ids_to_tokens": [[765, 785], ["isinstance", "utils.PreTrainedTokenizer._convert_id_to_token", "tokens.append", "tokens.append", "utils.PreTrainedTokenizer._convert_id_to_token"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._convert_id_to_token", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._convert_id_to_token"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ",", "skip_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\" Converts a single index or a sequence of indices (integers) in a token \"\n            (resp.) a sequence of tokens (str/unicode), using the vocabulary and added tokens.\n            Args:\n                skip_special_tokens: Don't decode special tokens (self.all_special_tokens). Default: False\n        \"\"\"", "\n", "if", "isinstance", "(", "ids", ",", "int", ")", ":", "\n", "            ", "if", "ids", "in", "self", ".", "added_tokens_decoder", ":", "\n", "                ", "return", "self", ".", "added_tokens_decoder", "[", "ids", "]", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "_convert_id_to_token", "(", "ids", ")", "\n", "", "", "tokens", "=", "[", "]", "\n", "for", "index", "in", "ids", ":", "\n", "            ", "if", "index", "in", "self", ".", "all_special_ids", "and", "skip_special_tokens", ":", "\n", "                ", "continue", "\n", "", "if", "index", "in", "self", ".", "added_tokens_decoder", ":", "\n", "                ", "tokens", ".", "append", "(", "self", ".", "added_tokens_decoder", "[", "index", "]", ")", "\n", "", "else", ":", "\n", "                ", "tokens", ".", "append", "(", "self", ".", "_convert_id_to_token", "(", "index", ")", ")", "\n", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._convert_id_to_token": [[786, 788], ["None"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_string": [[789, 795], ["utils.PreTrainedTokenizer.convert_ids_to_tokens"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_ids_to_tokens"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string.\n            The most simple way to do it is ' '.join(self.convert_ids_to_tokens(token_ids))\n            but we often want to remove sub-word tokenization artifacts at the same time.\n        \"\"\"", "\n", "return", "' '", ".", "join", "(", "self", ".", "convert_ids_to_tokens", "(", "tokens", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.decode": [[796, 819], ["utils.PreTrainedTokenizer.convert_ids_to_tokens", "utils.PreTrainedTokenizer.convert_tokens_to_string", "text.replace.replace.replace", "list", "filter", "utils.PreTrainedTokenizer.clean_up_tokenization", "text.replace.replace.split", "utils.PreTrainedTokenizer.clean_up_tokenization", "len"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_ids_to_tokens", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.convert_tokens_to_string", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.clean_up_tokenization", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.clean_up_tokenization"], ["", "def", "decode", "(", "self", ",", "token_ids", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Converts a sequence of ids (integer) in a string, using the tokenizer and vocabulary\n        with options to remove special tokens and clean up tokenization spaces.\n        Similar to doing ``self.convert_tokens_to_string(self.convert_ids_to_tokens(token_ids))``.\n        \"\"\"", "\n", "filtered_tokens", "=", "self", ".", "convert_ids_to_tokens", "(", "token_ids", ",", "skip_special_tokens", "=", "skip_special_tokens", ")", "\n", "text", "=", "self", ".", "convert_tokens_to_string", "(", "filtered_tokens", ")", "\n", "\n", "if", "self", ".", "sep_token", "is", "not", "None", "and", "self", ".", "sep_token", "in", "text", ":", "\n", "            ", "text", "=", "text", ".", "replace", "(", "self", ".", "cls_token", ",", "self", ".", "sep_token", ")", "\n", "split_text", "=", "list", "(", "filter", "(", "lambda", "sentence", ":", "len", "(", "sentence", ")", ">", "0", ",", "text", ".", "split", "(", "self", ".", "sep_token", ")", ")", ")", "\n", "if", "clean_up_tokenization_spaces", ":", "\n", "                ", "clean_text", "=", "[", "self", ".", "clean_up_tokenization", "(", "text", ")", "for", "text", "in", "split_text", "]", "\n", "return", "clean_text", "\n", "", "else", ":", "\n", "                ", "return", "split_text", "\n", "", "", "else", ":", "\n", "            ", "if", "clean_up_tokenization_spaces", ":", "\n", "                ", "clean_text", "=", "self", ".", "clean_up_tokenization", "(", "text", ")", "\n", "return", "clean_text", "\n", "", "else", ":", "\n", "                ", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.special_tokens_map": [[820, 831], ["getattr"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "special_tokens_map", "(", "self", ")", ":", "\n", "        ", "\"\"\" A dictionary mapping special token class attribute (cls_token, unk_token...) to their\n            values ('<unk>', '<cls>'...)\n        \"\"\"", "\n", "set_attr", "=", "{", "}", "\n", "for", "attr", "in", "self", ".", "SPECIAL_TOKENS_ATTRIBUTES", ":", "\n", "            ", "attr_value", "=", "getattr", "(", "self", ",", "\"_\"", "+", "attr", ")", "\n", "if", "attr_value", ":", "\n", "                ", "set_attr", "[", "attr", "]", "=", "attr_value", "\n", "", "", "return", "set_attr", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.all_special_tokens": [[832, 843], ["set_attr.values", "list", "set", "isinstance"], "methods", ["None"], ["", "@", "property", "\n", "def", "all_special_tokens", "(", "self", ")", ":", "\n", "        ", "\"\"\" List all the special tokens ('<unk>', '<cls>'...) mapped to class attributes\n            (cls_token, unk_token...).\n        \"\"\"", "\n", "all_toks", "=", "[", "]", "\n", "set_attr", "=", "self", ".", "special_tokens_map", "\n", "for", "attr_value", "in", "set_attr", ".", "values", "(", ")", ":", "\n", "            ", "all_toks", "=", "all_toks", "+", "(", "attr_value", "if", "isinstance", "(", "attr_value", ",", "(", "list", ",", "tuple", ")", ")", "else", "[", "attr_value", "]", ")", "\n", "", "all_toks", "=", "list", "(", "set", "(", "all_toks", ")", ")", "\n", "return", "all_toks", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.all_special_ids": [[844, 852], ["list", "utils.PreTrainedTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer._convert_token_to_id"], ["", "@", "property", "\n", "def", "all_special_ids", "(", "self", ")", ":", "\n", "        ", "\"\"\" List the vocabulary indices of the special tokens ('<unk>', '<cls>'...) mapped to\n            class attributes (cls_token, unk_token...).\n        \"\"\"", "\n", "all_toks", "=", "self", ".", "all_special_tokens", "\n", "all_ids", "=", "list", "(", "self", ".", "_convert_token_to_id", "(", "t", ")", "for", "t", "in", "all_toks", ")", "\n", "return", "all_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.clean_up_tokenization": [[853, 864], ["out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "clean_up_tokenization", "(", "out_string", ")", ":", "\n", "        ", "\"\"\" Clean up a list of simple English tokenization artifacts like spaces before punctuations and abreviated forms.\n        \"\"\"", "\n", "out_string", "=", "out_string", ".", "replace", "(", "' .'", ",", "'.'", ")", ".", "replace", "(", "' ?'", ",", "'?'", ")", ".", "replace", "(", "' !'", ",", "'!'", ")", ".", "replace", "(", "' ,'", ",", "','", "\n", ")", ".", "replace", "(", "\" ' \"", ",", "\n", "\"'\"", ")", ".", "replace", "(", "\n", "\" n't\"", ",", "\"n't\"", ")", ".", "replace", "(", "\" 'm\"", ",", "\"'m\"", ")", ".", "replace", "(", "\" do not\"", ",", "\" don't\"", "\n", ")", ".", "replace", "(", "\" 's\"", ",", "\"'s\"", ")", ".", "replace", "(", "\" 've\"", ",", "\"'ve\"", ")", ".", "replace", "(", "\" 're\"", ",", "\n", "\"'re\"", ")", "\n", "return", "out_string", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.bytes_to_unicode": [[62, 84], ["lru_cache", "range", "dict", "list", "_chr", "zip", "list", "list", "range", "bs.append", "cs.append", "range", "range", "ord", "ord", "ord", "ord", "ord", "ord"], "function", ["None"], ["@", "lru_cache", "(", ")", "\n", "def", "bytes_to_unicode", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns list of utf-8 byte and a corresponding list of unicode strings.\n    The reversible bpe codes work on unicode strings.\n    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n    This is a signficant percentage of your normal, say, 32K bpe vocab.\n    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n    And avoids mapping to whitespace/control characters the bpe code barfs on.\n    \"\"\"", "\n", "_chr", "=", "unichr", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "else", "chr", "\n", "bs", "=", "list", "(", "range", "(", "ord", "(", "\"!\"", ")", ",", "ord", "(", "\"~\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00a1\"", ")", ",", "ord", "(", "\"\u00ac\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00ae\"", ")", ",", "ord", "(", "\"\u00ff\"", ")", "+", "1", ")", ")", "\n", "cs", "=", "bs", "[", ":", "]", "\n", "n", "=", "0", "\n", "for", "b", "in", "range", "(", "2", "**", "8", ")", ":", "\n", "        ", "if", "b", "not", "in", "bs", ":", "\n", "            ", "bs", ".", "append", "(", "b", ")", "\n", "cs", ".", "append", "(", "2", "**", "8", "+", "n", ")", "\n", "n", "+=", "1", "\n", "", "", "cs", "=", "[", "_chr", "(", "n", ")", "for", "n", "in", "cs", "]", "\n", "return", "dict", "(", "zip", "(", "bs", ",", "cs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.get_pairs": [[86, 96], ["set", "set.add"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.add"], ["", "def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n    Word is represented as tuple of symbols (symbols being variable-length strings).\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.s3_request": [[98, 115], ["functools.wraps", "func", "int", "EnvironmentError"], "function", ["None"], ["", "def", "s3_request", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.split_s3_path": [[117, 128], ["urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["", "def", "split_s3_path", "(", "url", ")", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "s3_path", "=", "s3_path", "[", "1", ":", "]", "\n", "", "return", "bucket_name", ",", "s3_path", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.s3_etag": [[130, 137], ["boto3.resource", "utils.split_s3_path", "boto3.resource.Object"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ")", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n", "return", "s3_object", ".", "e_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.s3_get": [[139, 145], ["boto3.resource", "utils.split_s3_path", "boto3.resource.Bucket().download_fileobj", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.http_get": [[147, 157], ["requests.get", "requests.get.headers.get", "tqdm.tqdm", "requests.get.iter_content", "tqdm.tqdm.close", "int", "tqdm.tqdm.update", "temp_file.write", "len"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update"], ["", "def", "http_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "req", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "content_length", "=", "req", ".", "headers", ".", "get", "(", "'Content-Length'", ")", "\n", "total", "=", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "tqdm", "(", "unit", "=", "\"B\"", ",", "total", "=", "total", ")", "\n", "for", "chunk", "in", "req", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.cached_path": [[159, 187], ["urlparse", "isinstance", "str", "isinstance", "str", "utils.get_from_cache", "os.path.exists", "EnvironmentError", "ValueError"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.get_from_cache"], ["", "def", "cached_path", "(", "url_or_filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_TRANSFORMERS_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "\n", "if", "parsed", ".", "scheme", "in", "(", "'http'", ",", "'https'", ",", "'s3'", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "return", "get_from_cache", "(", "url_or_filename", ",", "cache_dir", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n", "# File, and it exists.", "\n", "        ", "return", "url_or_filename", "\n", "", "elif", "parsed", ".", "scheme", "==", "''", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.url_to_filename": [[189, 205], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.encode"], ["", "", "def", "url_to_filename", "(", "url", ",", "etag", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "'utf-8'", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "'utf-8'", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "'.'", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.get_from_cache": [[207, 283], ["url.startswith", "utils.url_to_filename", "os.path.join", "isinstance", "str", "str", "os.path.exists", "os.makedirs", "utils.s3_etag", "response.headers.get.decode", "fnmatch.filter", "list", "os.path.exists", "isinstance", "requests.head", "os.path.exists", "os.listdir", "filter", "os.path.join", "tempfile.NamedTemporaryFile", "logger.info", "url.startswith", "temp_file.flush", "temp_file.seek", "logger.info", "logger.info", "logger.info", "requests.head.headers.get", "utils.s3_get", "utils.http_get", "io.open", "shutil.copyfileobj", "io.open", "json.dumps", "meta_file.write", "isinstance", "unicode", "s.endswith"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.url_to_filename", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.s3_etag", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.s3_get", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.roberta.utils.http_get"], ["", "def", "get_from_cache", "(", "url", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding dataset in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_TRANSFORMERS_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "not", "isinstance", "(", "cache_dir", ",", "str", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "cache_dir", ")", "\n", "\n", "# Get eTag to add to filename, if it exists.", "\n", "", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "        ", "etag", "=", "s3_etag", "(", "url", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "response", "=", "requests", ".", "head", "(", "url", ",", "allow_redirects", "=", "True", ")", "\n", "if", "response", ".", "status_code", "!=", "200", ":", "\n", "                ", "etag", "=", "None", "\n", "", "else", ":", "\n", "                ", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "", "", "except", "EnvironmentError", ":", "\n", "            ", "etag", "=", "None", "\n", "\n", "", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "etag", "is", "not", "None", ":", "\n", "        ", "etag", "=", "etag", ".", "decode", "(", "'utf-8'", ")", "\n", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "# If we don't have a connection (etag is None) and can't identify the file", "\n", "# try to get the last downloaded one", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", "and", "etag", "is", "None", ":", "\n", "        ", "matching_files", "=", "fnmatch", ".", "filter", "(", "os", ".", "listdir", "(", "cache_dir", ")", ",", "filename", "+", "'.*'", ")", "\n", "matching_files", "=", "list", "(", "filter", "(", "lambda", "s", ":", "not", "s", ".", "endswith", "(", "'.json'", ")", ",", "matching_files", ")", ")", "\n", "if", "matching_files", ":", "\n", "            ", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "matching_files", "[", "-", "1", "]", ")", "\n", "\n", "", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "temp_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s not found in cache, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", ")", "\n", "\n", "# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                ", "s3_get", "(", "url", ",", "temp_file", ")", "\n", "", "else", ":", "\n", "                ", "http_get", "(", "url", ",", "temp_file", ")", "\n", "\n", "# we are copying the file before closing it, so flush to avoid truncation", "\n", "", "temp_file", ".", "flush", "(", ")", "\n", "# shutil.copyfileobj() starts at the current position, so go to the start", "\n", "temp_file", ".", "seek", "(", "0", ")", "\n", "\n", "logger", ".", "info", "(", "\"copying %s to cache at %s\"", ",", "temp_file", ".", "name", ",", "cache_path", ")", "\n", "with", "open", "(", "cache_path", ",", "'wb'", ")", "as", "cache_file", ":", "\n", "                ", "shutil", ".", "copyfileobj", "(", "temp_file", ",", "cache_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"creating metadata file for %s\"", ",", "cache_path", ")", "\n", "meta", "=", "{", "'url'", ":", "url", ",", "'etag'", ":", "etag", "}", "\n", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "with", "open", "(", "meta_path", ",", "'w'", ")", "as", "meta_file", ":", "\n", "                ", "output_string", "=", "json", ".", "dumps", "(", "meta", ")", "\n", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "output_string", ",", "str", ")", ":", "\n", "                    ", "output_string", "=", "unicode", "(", "output_string", ",", "'utf-8'", ")", "# The beauty of python 2", "\n", "", "meta_file", ".", "write", "(", "output_string", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"removing temp file %s\"", ",", "temp_file", ".", "name", ")", "\n", "\n", "", "", "return", "cache_path", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.__init__": [[6, 15], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "val_func", ",", "val_loader", ",", "metrics", ",", "host_metric_name", "=", "'Acc'", ",", "label_index_in_batch", "=", "-", "1", ")", ":", "\n", "        ", "super", "(", "ValidationMonitor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "val_func", "=", "val_func", "\n", "self", ".", "val_loader", "=", "val_loader", "\n", "self", ".", "metrics", "=", "metrics", "\n", "self", ".", "host_metric_name", "=", "host_metric_name", "\n", "self", ".", "best_epoch", "=", "-", "1", "\n", "self", ".", "best_val", "=", "-", "1.0", "\n", "self", ".", "label_index_in_batch", "=", "label_index_in_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict": [[16, 19], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "'best_epoch'", ":", "self", ".", "best_epoch", ",", "\n", "'best_val'", ":", "self", ".", "best_val", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict": [[20, 25], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "assert", "'best_epoch'", "in", "state_dict", ",", "'miss key \\'best_epoch\\''", "\n", "assert", "'best_val'", "in", "state_dict", ",", "'miss key \\'best_val\\''", "\n", "self", ".", "best_epoch", "=", "state_dict", "[", "'best_epoch'", "]", "\n", "self", ".", "best_val", "=", "state_dict", "[", "'best_val'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.__call__": [[26, 47], ["validation_monitor.ValidationMonitor.val_func", "validation_monitor.ValidationMonitor.metrics.get", "zip", "logging.info", "print", "logging.info", "print", "logging.info", "print", "writer.add_scalar"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["", "def", "__call__", "(", "self", ",", "epoch_num", ",", "net", ",", "optimizer", ",", "writer", ")", ":", "\n", "        ", "self", ".", "val_func", "(", "net", ",", "self", ".", "val_loader", ",", "self", ".", "metrics", ",", "self", ".", "label_index_in_batch", ")", "\n", "\n", "name", ",", "value", "=", "self", ".", "metrics", ".", "get", "(", ")", "\n", "s", "=", "\"Epoch[%d] \\tVal-\"", "%", "(", "epoch_num", ")", "\n", "for", "n", ",", "v", "in", "zip", "(", "name", ",", "value", ")", ":", "\n", "            ", "if", "n", "==", "self", ".", "host_metric_name", "and", "v", ">", "self", ".", "best_val", ":", "\n", "                ", "self", ".", "best_epoch", "=", "epoch_num", "\n", "self", ".", "best_val", "=", "v", "\n", "logging", ".", "info", "(", "'New Best Val {}: {}, Epoch: {}'", ".", "format", "(", "self", ".", "host_metric_name", ",", "self", ".", "best_val", ",", "self", ".", "best_epoch", ")", ")", "\n", "print", "(", "'New Best Val {}: {}, Epoch: {}'", ".", "format", "(", "self", ".", "host_metric_name", ",", "self", ".", "best_val", ",", "self", ".", "best_epoch", ")", ")", "\n", "", "s", "+=", "\"%s=%f,\\t\"", "%", "(", "n", ",", "v", ")", "\n", "if", "writer", "is", "not", "None", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "tag", "=", "'Val-'", "+", "n", ",", "\n", "scalar_value", "=", "v", ",", "\n", "global_step", "=", "epoch_num", "+", "1", ")", "\n", "", "", "logging", ".", "info", "(", "s", ")", "\n", "print", "(", "s", ")", "\n", "\n", "logging", ".", "info", "(", "'Best Val {}: {}, Epoch: {}'", ".", "format", "(", "self", ".", "host_metric_name", ",", "self", ".", "best_val", ",", "self", ".", "best_epoch", ")", ")", "\n", "print", "(", "'Best Val {}: {}, Epoch: {}'", ".", "format", "(", "self", ".", "host_metric_name", ",", "self", ".", "best_val", ",", "self", ".", "best_epoch", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.checkpoint.Checkpoint.__init__": [[5, 9], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "prefix", ",", "frequent", ")", ":", "\n", "        ", "super", "(", "Checkpoint", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "prefix", "=", "prefix", "\n", "self", ".", "frequent", "=", "frequent", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.checkpoint.Checkpoint.__call__": [[10, 26], ["dict", "net.state_dict", "optimizer.state_dict", "torch.save", "validation_monitor.state_dict", "torch.save", "print"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict"], ["", "def", "__call__", "(", "self", ",", "epoch_num", ",", "net", ",", "optimizer", ",", "writer", ",", "validation_monitor", "=", "None", ")", ":", "\n", "        ", "if", "(", "epoch_num", "+", "1", ")", "%", "self", ".", "frequent", "==", "0", ":", "\n", "            ", "param_name", "=", "'{}-{:04d}.model'", ".", "format", "(", "self", ".", "prefix", ",", "epoch_num", ")", "\n", "checkpoint_dict", "=", "dict", "(", ")", "\n", "checkpoint_dict", "[", "'state_dict'", "]", "=", "net", ".", "state_dict", "(", ")", "\n", "checkpoint_dict", "[", "'optimizer'", "]", "=", "optimizer", ".", "state_dict", "(", ")", "\n", "save_to_best", "=", "False", "\n", "if", "validation_monitor", "is", "not", "None", ":", "\n", "                ", "checkpoint_dict", "[", "'validation_monitor'", "]", "=", "validation_monitor", ".", "state_dict", "(", ")", "\n", "if", "validation_monitor", ".", "best_epoch", "==", "epoch_num", ":", "\n", "                    ", "save_to_best", "=", "True", "\n", "", "", "torch", ".", "save", "(", "checkpoint_dict", ",", "param_name", ")", "\n", "if", "save_to_best", ":", "\n", "                ", "best_param_name", "=", "'{}-best.model'", ".", "format", "(", "self", ".", "prefix", ")", "\n", "torch", ".", "save", "(", "checkpoint_dict", ",", "best_param_name", ")", "\n", "print", "(", "'Save new best model to {}.'", ".", "format", "(", "best_param_name", ")", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.batch_end_callbacks.speedometer.Speedometer.__init__": [[16, 32], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "batch_size", ",", "frequent", "=", "50", ",", "\n", "batches_per_epoch", "=", "None", ",", "epochs", "=", "None", ")", ":", "\n", "        ", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "frequent", "=", "frequent", "\n", "self", ".", "batches_per_epoch", "=", "batches_per_epoch", "\n", "self", ".", "epochs", "=", "epochs", "\n", "self", ".", "epoch", "=", "-", "1", "\n", "self", ".", "init", "=", "False", "\n", "self", ".", "tic", "=", "0", "\n", "self", ".", "last_count", "=", "0", "\n", "self", ".", "data_in_time", "=", "0.0", "\n", "self", ".", "data_transfer_time", "=", "0.0", "\n", "self", ".", "forward_time", "=", "0.0", "\n", "self", ".", "backward_time", "=", "0.0", "\n", "self", ".", "optimizer_time", "=", "0.0", "\n", "self", ".", "metric_time", "=", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.batch_end_callbacks.speedometer.Speedometer.__call__": [[33, 103], ["logging.info", "print", "time.time", "int", "int", "logging.info", "print", "time.time", "param.eval_metric.get", "zip", "int", "param.eval_metric.get", "zip", "time.time"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["", "def", "__call__", "(", "self", ",", "param", ")", ":", "\n", "        ", "\"\"\"Callback to Show speed.\"\"\"", "\n", "count", "=", "param", ".", "nbatch", "\n", "if", "self", ".", "last_count", ">", "count", ":", "\n", "            ", "self", ".", "init", "=", "False", "\n", "", "self", ".", "last_count", "=", "count", "\n", "self", ".", "data_in_time", "+=", "param", ".", "data_in_time", "\n", "self", ".", "data_transfer_time", "+=", "param", ".", "data_transfer_time", "\n", "self", ".", "forward_time", "+=", "param", ".", "forward_time", "\n", "self", ".", "backward_time", "+=", "param", ".", "backward_time", "\n", "self", ".", "optimizer_time", "+=", "param", ".", "optimizer_time", "\n", "self", ".", "metric_time", "+=", "param", ".", "metric_time", "\n", "\n", "if", "self", ".", "init", ":", "\n", "            ", "if", "count", "%", "self", ".", "frequent", "==", "0", ":", "\n", "                ", "speed", "=", "self", ".", "frequent", "*", "self", ".", "batch_size", "/", "(", "time", ".", "time", "(", ")", "-", "self", ".", "tic", ")", "\n", "data_in_time", "=", "self", ".", "data_in_time", "/", "self", ".", "frequent", "\n", "data_transfer_time", "=", "self", ".", "data_transfer_time", "/", "self", ".", "frequent", "\n", "forward_time", "=", "self", ".", "forward_time", "/", "self", ".", "frequent", "\n", "backward_time", "=", "self", ".", "backward_time", "/", "self", ".", "frequent", "\n", "optimizer_time", "=", "self", ".", "optimizer_time", "/", "self", ".", "frequent", "\n", "metric_time", "=", "self", ".", "metric_time", "/", "self", ".", "frequent", "\n", "eta", "=", "(", "(", "self", ".", "epochs", "-", "self", ".", "epoch", "-", "1", ")", "*", "self", ".", "batches_per_epoch", "+", "self", ".", "batches_per_epoch", "-", "param", ".", "nbatch", ")", "*", "self", ".", "batch_size", "/", "speed", "\n", "eta", "=", "int", "(", "eta", "/", "60.0", ")", "\n", "eta_m", "=", "eta", "%", "60", "\n", "eta_h", "=", "int", "(", "(", "eta", "-", "eta_m", ")", "/", "60", ")", "%", "24", "\n", "eta_d", "=", "int", "(", "(", "eta", "-", "eta_m", "-", "eta_h", "*", "60", ")", "/", "(", "24", "*", "60", ")", ")", "\n", "s", "=", "''", "\n", "if", "param", ".", "eval_metric", "is", "not", "None", ":", "\n", "                    ", "prefix", "=", "\"Epoch[%d] Batch [%d]\\t\"", "%", "(", "param", ".", "epoch", ",", "count", ")", "\n", "name", ",", "value", "=", "param", ".", "eval_metric", ".", "get", "(", ")", "\n", "s", "=", "prefix", "+", "\"Speed: %.2f samples/s ETA: %d d %2d h %2d m\\tData: %.3f Tran: %.3f F: %.3f B: %.3f O: %.3f M: %.3f\\tTrain-\"", "%", "(", "speed", ",", "eta_d", ",", "eta_h", ",", "eta_m", ",", "data_in_time", ",", "data_transfer_time", ",", "forward_time", ",", "backward_time", ",", "optimizer_time", ",", "metric_time", ")", "\n", "for", "n", ",", "v", "in", "zip", "(", "name", ",", "value", ")", ":", "\n", "                        ", "s", "+=", "\"%s=%f,\\t\"", "%", "(", "n", ",", "v", ")", "\n", "", "", "else", ":", "\n", "                    ", "prefix", "=", "\"Epoch[%d] Batch [%d]\\t\"", "%", "(", "param", ".", "epoch", ",", "count", ")", "\n", "s", "=", "prefix", "+", "\"Speed: %.2f ETA: %d d %2d h %2d m samples/s\\tData: %.3f Tran: %.3f F: %.3f B: %.3f O: %.3f M: %.3f\"", "%", "(", "speed", ",", "eta_d", ",", "eta_h", ",", "eta_m", ",", "data_in_time", ",", "data_transfer_time", ",", "forward_time", ",", "backward_time", ",", "optimizer_time", ",", "metric_time", ")", "\n", "\n", "", "if", "param", ".", "rank", "is", "not", "None", ":", "\n", "                    ", "s", "=", "'Rank[%3d]'", "%", "param", ".", "rank", "+", "s", "\n", "\n", "", "logging", ".", "info", "(", "s", ")", "\n", "print", "(", "s", ")", "\n", "self", ".", "tic", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "data_in_time", "=", "0.0", "\n", "self", ".", "data_transfer_time", "=", "0.0", "\n", "self", ".", "forward_time", "=", "0.0", "\n", "self", ".", "backward_time", "=", "0.0", "\n", "self", ".", "optimizer_time", "=", "0.0", "\n", "self", ".", "metric_time", "=", "0.0", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "init", "=", "True", "\n", "self", ".", "epoch", "+=", "1", "\n", "if", "param", ".", "eval_metric", "is", "not", "None", ":", "\n", "                ", "name", ",", "value", "=", "param", ".", "eval_metric", ".", "get", "(", ")", "\n", "s", "=", "\"Epoch[%d] Batch [%d]\\tSpeed: - samples/sec ETA: - d - h - m\\tTrain-\"", "%", "(", "param", ".", "epoch", ",", "0", ")", "\n", "for", "n", ",", "v", "in", "zip", "(", "name", ",", "value", ")", ":", "\n", "                    ", "s", "+=", "\"%s=%f,\\t\"", "%", "(", "n", ",", "v", ")", "\n", "", "", "else", ":", "\n", "                ", "s", "=", "\"Epoch[%d] Batch [%d]\\tSpeed: - samples/sec ETA: - d - h - m\"", "%", "(", "param", ".", "epoch", ",", "0", ")", "\n", "\n", "", "if", "param", ".", "rank", "is", "not", "None", ":", "\n", "                ", "s", "=", "'Rank[%3d]'", "%", "param", ".", "rank", "+", "s", "\n", "\n", "", "logging", ".", "info", "(", "s", ")", "\n", "print", "(", "s", ")", "\n", "self", ".", "tic", "=", "time", ".", "time", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.BasicBlock.__init__": [[39, 54], ["torch.Module.__init__", "resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.conv3x3", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "dilation", "=", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# if dilation == 1:", "\n", "#     self.conv1 = conv3x3(inplanes, planes, stride, dilation)", "\n", "# elif dilation == 2:", "\n", "#     self.conv1 = conv3x3(inplanes, planes, stride, dilation, padding=2)", "\n", "# else:", "\n", "#     raise ValueError('dilation must be 1 or 2!')", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ",", "dilation", ",", "padding", "=", "dilation", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.BasicBlock.forward": [[55, 72], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.bn1", "resnet.BasicBlock.relu", "resnet.BasicBlock.conv2", "resnet.BasicBlock.bn2", "resnet.BasicBlock.relu", "resnet.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.Bottleneck.__init__": [[77, 97], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "dilation", "=", "1", ",", "stride_in_1x1", "=", "False", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", "if", "not", "stride_in_1x1", "else", "stride", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "# if dilation == 1:", "\n", "#     self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride if not stride_in_1x1 else 1,", "\n", "#                            dilation=dilation, padding=1, bias=False)", "\n", "# elif dilation == 2:", "\n", "#     self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride if not stride_in_1x1 else 1,", "\n", "#                            dilation=dilation, padding=2, bias=False)", "\n", "# else:", "\n", "#     raise ValueError('dilation must be 1 or 2!')", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", "if", "not", "stride_in_1x1", "else", "1", ",", "\n", "dilation", "=", "dilation", ",", "padding", "=", "dilation", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", "*", "self", ".", "expansion", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.Bottleneck.forward": [[98, 119], ["resnet.Bottleneck.conv1", "resnet.Bottleneck.bn1", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv2", "resnet.Bottleneck.bn2", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv3", "resnet.Bottleneck.bn3", "resnet.Bottleneck.relu", "resnet.Bottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.__init__": [[123, 157], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "enumerate", "enumerate", "resnet.ResNet.modules", "zip", "resnet.ResNet._make_layer", "resnet.ResNet.__setattr__", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Linear", "torch.Linear", "torch.Linear", "resnet.ResNet.expose_stages.remove", "isinstance", "len", "len", "len", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "num_classes", "=", "None", ",", "expose_stages", "=", "None", ",", "dilations", "=", "None", ",", "stride_in_1x1", "=", "False", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "layers_planes", "=", "[", "64", ",", "128", ",", "256", ",", "512", "]", "\n", "layers_strides", "=", "[", "1", ",", "2", ",", "2", ",", "2", "]", "\n", "layers_dilations", "=", "dilations", "if", "dilations", "is", "not", "None", "else", "[", "1", ",", "1", ",", "1", ",", "1", "]", "\n", "for", "i", ",", "dilation", "in", "enumerate", "(", "layers_dilations", ")", ":", "\n", "            ", "if", "dilation", "==", "2", ":", "\n", "                ", "layers_strides", "[", "i", "]", "=", "1", "\n", "", "", "layers_planes", "=", "layers_planes", "[", ":", "len", "(", "layers", ")", "]", "\n", "layers_strides", "=", "layers_strides", "[", ":", "len", "(", "layers", ")", "]", "\n", "layers_dilations", "=", "layers_dilations", "[", ":", "len", "(", "layers", ")", "]", "\n", "for", "i", ",", "(", "planes", ",", "blocks", ",", "stride", ",", "dilation", ")", "in", "enumerate", "(", "zip", "(", "layers_planes", ",", "layers", ",", "layers_strides", ",", "layers_dilations", ")", ")", ":", "\n", "            ", "layer", "=", "self", ".", "_make_layer", "(", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "stride_in_1x1", "=", "stride_in_1x1", ")", "\n", "self", ".", "__setattr__", "(", "'layer{}'", ".", "format", "(", "i", "+", "1", ")", ",", "layer", ")", "\n", "", "self", ".", "num_layers", "=", "i", "+", "1", "\n", "self", ".", "has_fc_head", "=", "6", "in", "expose_stages", "\n", "self", ".", "expose_stages", "=", "expose_stages", "\n", "if", "self", ".", "has_fc_head", ":", "\n", "            ", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "self", ".", "expose_stages", ".", "remove", "(", "6", ")", "\n", "\n", "", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet._make_layer": [[158, 174], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "stride_in_1x1", "=", "False", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ",", "dilation", ",", "stride_in_1x1", "=", "stride_in_1x1", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "dilation", "=", "dilation", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.forward": [[175, 200], ["resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.relu", "resnet.ResNet.maxpool", "range", "resnet.ResNet.avgpool", "resnet.ResNet.view", "resnet.ResNet.fc", "resnet.ResNet.__getattr__", "resnet.ResNet.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "expose_feats", "=", "{", "}", "\n", "feats", "=", "{", "}", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "feats", "[", "'body1'", "]", "=", "x", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "x", "=", "self", ".", "__getattr__", "(", "\"layer{}\"", ".", "format", "(", "i", "+", "1", ")", ")", "(", "x", ")", "\n", "feats", "[", "'body{}'", ".", "format", "(", "i", "+", "2", ")", "]", "=", "x", "\n", "\n", "", "if", "self", ".", "has_fc_head", ":", "\n", "            ", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "expose_feats", "[", "'cls_score'", "]", "=", "x", "\n", "\n", "", "if", "self", ".", "expose_stages", "is", "not", "None", ":", "\n", "            ", "for", "expose_stage", "in", "self", ".", "expose_stages", ":", "\n", "                ", "feat_name", "=", "'body{}'", ".", "format", "(", "expose_stage", ")", "\n", "expose_feats", "[", "feat_name", "]", "=", "feats", "[", "feat_name", "]", "\n", "\n", "", "", "return", "expose_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.load_pretrained_state_dict": [[201, 216], ["resnet.ResNet.state_dict", "resnet.ResNet.keys", "resnet.ResNet.load_state_dict", "len", "warnings.warn", "state_dict.keys", "miss_keys.append"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.state_dict", "home.repos.pwc.inspect_result.ImperialNLP_BertGen.epoch_end_callbacks.validation_monitor.ValidationMonitor.load_state_dict"], ["", "def", "load_pretrained_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Load state dict of pretrained model\n        Args:\n            state_dict (dict): state dict to load\n        \"\"\"", "\n", "new_state_dict", "=", "self", ".", "state_dict", "(", ")", "\n", "miss_keys", "=", "[", "]", "\n", "for", "k", "in", "new_state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "k", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "                ", "new_state_dict", "[", "k", "]", "=", "state_dict", "[", "k", "]", "\n", "", "else", ":", "\n", "                ", "miss_keys", ".", "append", "(", "k", ")", "\n", "", "", "if", "len", "(", "miss_keys", ")", ">", "0", ":", "\n", "            ", "warnings", ".", "warn", "(", "'miss keys: {}'", ".", "format", "(", "miss_keys", ")", ")", "\n", "", "self", ".", "load_state_dict", "(", "new_state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.frozen_parameters": [[217, 237], ["resnet.ResNet.modules", "isinstance", "module.parameters", "resnet.ResNet.conv1.parameters", "resnet.ResNet.bn1.parameters", "resnet.ResNet.__getattr__().parameters", "resnet.ResNet.fc.parameters", "resnet.ResNet.__getattr__"], "methods", ["None"], ["", "def", "frozen_parameters", "(", "self", ",", "frozen_stages", "=", "None", ",", "frozen_bn", "=", "False", ")", ":", "\n", "        ", "if", "frozen_bn", ":", "\n", "            ", "for", "module", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "module", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                    ", "for", "param", "in", "module", ".", "parameters", "(", ")", ":", "\n", "                        ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "", "", "if", "frozen_stages", "is", "not", "None", ":", "\n", "            ", "for", "stage", "in", "frozen_stages", ":", "\n", "                ", "assert", "(", "stage", ">=", "1", ")", "and", "(", "stage", "<=", "6", ")", "\n", "if", "stage", "==", "1", ":", "\n", "                    ", "for", "param", "in", "self", ".", "conv1", ".", "parameters", "(", ")", ":", "\n", "                        ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "self", ".", "bn1", ".", "parameters", "(", ")", ":", "\n", "                        ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "elif", "stage", "<", "6", ":", "\n", "                    ", "for", "param", "in", "self", ".", "__getattr__", "(", "\"layer{}\"", ".", "format", "(", "stage", "-", "1", ")", ")", ".", "parameters", "(", ")", ":", "\n", "                        ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "else", ":", "\n", "                    ", "for", "param", "in", "self", ".", "fc", ".", "parameters", "(", ")", ":", "\n", "                        ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.bn_eval": [[238, 242], ["resnet.ResNet.modules", "isinstance", "module.eval"], "methods", ["None"], ["", "", "", "", "", "def", "bn_eval", "(", "self", ")", ":", "\n", "        ", "for", "module", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "module", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "module", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.conv3x3": [[30, 34], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "padding", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "dilation", "=", "dilation", ",", "\n", "padding", "=", "padding", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.resnet18": [[244, 276], ["max", "resnet.ResNet", "resnet.ResNet.load_pretrained_state_dict", "torch.load", "torch.load", "torch.load", "torch.load_url"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.load_pretrained_state_dict"], ["", "", "", "", "def", "resnet18", "(", "pretrained", "=", "False", ",", "pretrained_model_path", "=", "None", ",", "num_classes", "=", "None", ",", "expose_stages", "=", "None", ",", "dilations", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model\n    Args:\n        pretrained (bool): if True, load pretrained model. Default: False\n        pretrained_model_path (str, optional): only effective when pretrained=True,\n                                            if not specified, use pretrained model from model_zoo.\n        num_classes (int): number of classes for the fc output score.\n        expose_stages (list, optional): list of expose stages, e.g. [4, 5] means expose conv4 and conv5 stage output.\n                                        if not specified, only expose output of end_stage.\n    \"\"\"", "\n", "\n", "if", "num_classes", "is", "None", ":", "\n", "        ", "assert", "expose_stages", "is", "not", "None", ",", "\"num_class and expose_stages is both None\"", "\n", "assert", "6", "not", "in", "expose_stages", ",", "\"can't expose the 6th stage for num_classes is None\"", "\n", "\n", "", "if", "expose_stages", "is", "None", ":", "\n", "        ", "expose_stages", "=", "[", "6", "]", "\n", "\n", "", "end_stage", "=", "max", "(", "expose_stages", ")", "\n", "assert", "end_stage", "<=", "6", ",", "\"the max expose_stage is out of range\"", "\n", "\n", "layers", "=", "model_layers", "[", "'resnet18'", "]", "[", ":", "end_stage", "-", "1", "]", "\n", "\n", "model", "=", "ResNet", "(", "block", "=", "BasicBlock", ",", "layers", "=", "layers", ",", "num_classes", "=", "num_classes", ",", "expose_stages", "=", "expose_stages", ",", "dilations", "=", "dilations", ")", "\n", "\n", "if", "pretrained", ":", "\n", "        ", "if", "pretrained_model_path", "is", "not", "None", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "pretrained_model_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "", "else", ":", "\n", "            ", "state_dict", "=", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet18'", "]", ")", "\n", "", "model", ".", "load_pretrained_state_dict", "(", "state_dict", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.resnet34": [[278, 311], ["max", "resnet.ResNet", "resnet.ResNet.load_pretrained_state_dict", "torch.load", "torch.load", "torch.load", "torch.load_url"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.load_pretrained_state_dict"], ["", "def", "resnet34", "(", "pretrained", "=", "False", ",", "pretrained_model_path", "=", "None", ",", "num_classes", "=", "None", ",", "expose_stages", "=", "None", ",", "dilations", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-34 model\n    Args:\n        pretrained (bool): if True, load pretrained model. Default: False\n        pretrained_model_path (str, optional): only effective when pretrained=True,\n                                            if not specified, use pretrained model from model_zoo.\n        num_classes (int): number of classes for the fc output score.\n        expose_stages (list, optional): list of expose stages, e.g. [4, 5] means expose conv4 and conv5 stage output.\n                                        if not specified, only expose output of end_stage.\n    \"\"\"", "\n", "\n", "if", "num_classes", "is", "None", ":", "\n", "        ", "assert", "expose_stages", "is", "not", "None", ",", "\"num_class and expose_stages is both None\"", "\n", "assert", "6", "not", "in", "expose_stages", ",", "\"can't expose the 6th stage for num_classes is None\"", "\n", "\n", "", "if", "expose_stages", "is", "None", ":", "\n", "        ", "expose_stages", "=", "[", "6", "]", "\n", "\n", "", "end_stage", "=", "max", "(", "expose_stages", ")", "\n", "assert", "end_stage", "<=", "6", ",", "\"the max expose_stage is out of range\"", "\n", "\n", "layers", "=", "model_layers", "[", "'resnet34'", "]", "[", ":", "end_stage", "-", "1", "]", "\n", "\n", "model", "=", "ResNet", "(", "block", "=", "BasicBlock", ",", "layers", "=", "layers", ",", "num_classes", "=", "num_classes", ",", "expose_stages", "=", "expose_stages", ",", "\n", "dilations", "=", "dilations", ")", "\n", "\n", "if", "pretrained", ":", "\n", "        ", "if", "pretrained_model_path", "is", "not", "None", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "pretrained_model_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "", "else", ":", "\n", "            ", "state_dict", "=", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet34'", "]", ")", "\n", "", "model", ".", "load_pretrained_state_dict", "(", "state_dict", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.resnet50": [[313, 346], ["max", "resnet.ResNet", "resnet.ResNet.load_pretrained_state_dict", "torch.load", "torch.load", "torch.load", "torch.load_url"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.load_pretrained_state_dict"], ["", "def", "resnet50", "(", "pretrained", "=", "False", ",", "pretrained_model_path", "=", "None", ",", "num_classes", "=", "None", ",", "expose_stages", "=", "None", ",", "dilations", "=", "None", ",", "stride_in_1x1", "=", "False", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model\n    Args:\n        pretrained (bool): if True, load pretrained model. Default: False\n        pretrained_model_path (str, optional): only effective when pretrained=True,\n                                            if not specified, use pretrained model from model_zoo.\n        num_classes (int): number of classes for the fc output score.\n        expose_stages (list, optional): list of expose stages, e.g. [4, 5] means expose conv4 and conv5 stage output.\n                                        if not specified, only expose output of end_stage.\n    \"\"\"", "\n", "\n", "if", "num_classes", "is", "None", ":", "\n", "        ", "assert", "expose_stages", "is", "not", "None", ",", "\"num_class and expose_stages is both None\"", "\n", "assert", "6", "not", "in", "expose_stages", ",", "\"can't expose the 6th stage for num_classes is None\"", "\n", "\n", "", "if", "expose_stages", "is", "None", ":", "\n", "        ", "expose_stages", "=", "[", "6", "]", "\n", "\n", "", "end_stage", "=", "max", "(", "expose_stages", ")", "\n", "assert", "end_stage", "<=", "6", ",", "\"the max expose_stage is out of range\"", "\n", "\n", "layers", "=", "model_layers", "[", "'resnet50'", "]", "[", ":", "end_stage", "-", "1", "]", "\n", "\n", "model", "=", "ResNet", "(", "block", "=", "Bottleneck", ",", "layers", "=", "layers", ",", "num_classes", "=", "num_classes", ",", "expose_stages", "=", "expose_stages", ",", "\n", "dilations", "=", "dilations", ",", "stride_in_1x1", "=", "stride_in_1x1", ")", "\n", "\n", "if", "pretrained", ":", "\n", "        ", "if", "pretrained_model_path", "is", "not", "None", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "pretrained_model_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "", "else", ":", "\n", "            ", "state_dict", "=", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet50'", "]", ")", "\n", "", "model", ".", "load_pretrained_state_dict", "(", "state_dict", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.resnet101": [[348, 381], ["max", "resnet.ResNet", "resnet.ResNet.load_pretrained_state_dict", "torch.load", "torch.load", "torch.load", "torch.load_url"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.load_pretrained_state_dict"], ["", "def", "resnet101", "(", "pretrained", "=", "False", ",", "pretrained_model_path", "=", "None", ",", "num_classes", "=", "None", ",", "expose_stages", "=", "None", ",", "dilations", "=", "None", ",", "stride_in_1x1", "=", "False", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model\n    Args:\n        pretrained (bool): if True, load pretrained model. Default: False\n        pretrained_model_path (str, optional): only effective when pretrained=True,\n                                            if not specified, use pretrained model from model_zoo.\n        num_classes (int): number of classes for the fc output score.\n        expose_stages (list, optional): list of expose stages, e.g. [4, 5] means expose conv4 and conv5 stage output.\n                                        if not specified, only expose output of end_stage.\n    \"\"\"", "\n", "\n", "if", "num_classes", "is", "None", ":", "\n", "        ", "assert", "expose_stages", "is", "not", "None", ",", "\"num_class and expose_stages is both None\"", "\n", "assert", "6", "not", "in", "expose_stages", ",", "\"can't expose the 6th stage for num_classes is None\"", "\n", "\n", "", "if", "expose_stages", "is", "None", ":", "\n", "        ", "expose_stages", "=", "[", "6", "]", "\n", "\n", "", "end_stage", "=", "max", "(", "expose_stages", ")", "\n", "assert", "end_stage", "<=", "6", ",", "\"the max expose_stage is out of range\"", "\n", "\n", "layers", "=", "model_layers", "[", "'resnet101'", "]", "[", ":", "end_stage", "-", "1", "]", "\n", "\n", "model", "=", "ResNet", "(", "block", "=", "Bottleneck", ",", "layers", "=", "layers", ",", "num_classes", "=", "num_classes", ",", "expose_stages", "=", "expose_stages", ",", "\n", "dilations", "=", "dilations", ",", "stride_in_1x1", "=", "stride_in_1x1", ")", "\n", "\n", "if", "pretrained", ":", "\n", "        ", "if", "pretrained_model_path", "is", "not", "None", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "pretrained_model_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "", "else", ":", "\n", "            ", "state_dict", "=", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet101'", "]", ")", "\n", "", "model", ".", "load_pretrained_state_dict", "(", "state_dict", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.resnet152": [[383, 416], ["max", "resnet.ResNet", "resnet.ResNet.load_pretrained_state_dict", "torch.load", "torch.load", "torch.load", "torch.load_url"], "function", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.resnet.resnet.ResNet.load_pretrained_state_dict"], ["", "def", "resnet152", "(", "pretrained", "=", "False", ",", "pretrained_model_path", "=", "None", ",", "num_classes", "=", "None", ",", "expose_stages", "=", "None", ",", "dilations", "=", "None", ",", "stride_in_1x1", "=", "False", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-152 model\n    Args:\n        pretrained (bool): if True, load pretrained model. Default: False\n        pretrained_model_path (str, optional): only effective when pretrained=True,\n                                            if not specified, use pretrained model from model_zoo.\n        num_classes (int): number of classes for the fc output score.\n        expose_stages (list, optional): list of expose stages, e.g. [4, 5] means expose conv4 and conv5 stage output.\n                                        if not specified, only expose output of end_stage.\n    \"\"\"", "\n", "\n", "if", "num_classes", "is", "None", ":", "\n", "        ", "assert", "expose_stages", "is", "not", "None", ",", "\"num_class and expose_stages is both None\"", "\n", "assert", "6", "not", "in", "expose_stages", ",", "\"can't expose the 6th stage for num_classes is None\"", "\n", "\n", "", "if", "expose_stages", "is", "None", ":", "\n", "        ", "expose_stages", "=", "[", "6", "]", "\n", "\n", "", "end_stage", "=", "max", "(", "expose_stages", ")", "\n", "assert", "end_stage", "<=", "6", ",", "\"the max expose_stage is out of range\"", "\n", "\n", "layers", "=", "model_layers", "[", "'resnet152'", "]", "[", ":", "end_stage", "-", "1", "]", "\n", "\n", "model", "=", "ResNet", "(", "block", "=", "Bottleneck", ",", "layers", "=", "layers", ",", "num_classes", "=", "num_classes", ",", "expose_stages", "=", "expose_stages", ",", "\n", "dilations", "=", "dilations", ",", "stride_in_1x1", "=", "stride_in_1x1", ")", "\n", "\n", "if", "pretrained", ":", "\n", "        ", "if", "pretrained_model_path", "is", "not", "None", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "pretrained_model_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "", "else", ":", "\n", "            ", "state_dict", "=", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet152'", "]", ")", "\n", "", "model", ".", "load_pretrained_state_dict", "(", "state_dict", ")", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.eval_metric.EvalMetric.__init__": [[15, 21], ["str", "eval_metric.EvalMetric.reset"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.reset"], ["def", "__init__", "(", "self", ",", "name", ",", "allreduce", "=", "False", ",", "num_replicas", "=", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "name", "=", "str", "(", "name", ")", "\n", "self", ".", "allreduce", "=", "allreduce", "\n", "self", ".", "num_replicas", "=", "num_replicas", "\n", "self", ".", "_kwargs", "=", "kwargs", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.eval_metric.EvalMetric.__str__": [[22, 24], ["dict", "eval_metric.EvalMetric.get_name_value"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.eval_metric.EvalMetric.get_name_value"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"EvalMetric: {}\"", ".", "format", "(", "dict", "(", "self", ".", "get_name_value", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.eval_metric.EvalMetric.update": [[25, 32], ["NotImplementedError"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "\"\"\"Updates the internal evaluation result.\n        Args\n            labels (list of `NDArray`): The labels of the data.\n            preds (list of `NDArray`): Predicted values.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.eval_metric.EvalMetric.reset": [[33, 37], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets the internal evaluation result to initial state.\"\"\"", "\n", "self", ".", "num_inst", "=", "torch", ".", "tensor", "(", "0.", ")", "\n", "self", ".", "sum_metric", "=", "torch", ".", "tensor", "(", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.eval_metric.EvalMetric.get": [[38, 57], ["eval_metric.EvalMetric.num_inst.item", "float", "eval_metric.EvalMetric.num_inst.clone().cuda", "eval_metric.EvalMetric.sum_metric.clone().cuda", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "torch.all_reduce", "metric_tensor.item", "eval_metric.EvalMetric.num_inst.clone", "eval_metric.EvalMetric.sum_metric.clone"], "methods", ["None"], ["", "def", "get", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the current evaluation result.\n        Returns:\n            names (list of str): Name of the metrics.\n            values (list of float): Value of the evaluations.\n        \"\"\"", "\n", "if", "self", ".", "num_inst", ".", "item", "(", ")", "==", "0", ":", "\n", "            ", "return", "(", "self", ".", "name", ",", "float", "(", "'nan'", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "allreduce", ":", "\n", "                ", "num_inst", "=", "self", ".", "num_inst", ".", "clone", "(", ")", ".", "cuda", "(", ")", "\n", "sum_metric", "=", "self", ".", "sum_metric", ".", "clone", "(", ")", ".", "cuda", "(", ")", "\n", "distributed", ".", "all_reduce", "(", "num_inst", ",", "op", "=", "distributed", ".", "ReduceOp", ".", "SUM", ")", "\n", "distributed", ".", "all_reduce", "(", "sum_metric", ",", "op", "=", "distributed", ".", "ReduceOp", ".", "SUM", ")", "\n", "metric_tensor", "=", "(", "sum_metric", "/", "num_inst", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "                ", "metric_tensor", "=", "(", "self", ".", "sum_metric", "/", "self", ".", "num_inst", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "", "return", "(", "self", ".", "name", ",", "metric_tensor", ".", "item", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.eval_metric.EvalMetric.get_name_value": [[58, 69], ["eval_metric.EvalMetric.get", "list", "isinstance", "isinstance", "zip"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["", "", "def", "get_name_value", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns zipped name and value pairs.\n        Returns\n            A (list of tuples): (name, value) tuple list.\n        \"\"\"", "\n", "name", ",", "value", "=", "self", ".", "get", "(", ")", "\n", "if", "not", "isinstance", "(", "name", ",", "list", ")", ":", "\n", "            ", "name", "=", "[", "name", "]", "\n", "", "if", "not", "isinstance", "(", "value", ",", "list", ")", ":", "\n", "            ", "value", "=", "[", "value", "]", "\n", "", "return", "list", "(", "zip", "(", "name", ",", "value", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.__init__": [[12, 17], ["eval_metric.EvalMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["def", "__init__", "(", "self", ",", "metrics", "=", "None", ",", "name", "=", "'composite'", ")", ":", "\n", "        ", "super", "(", "CompositeEvalMetric", ",", "self", ")", ".", "__init__", "(", "name", ")", "\n", "if", "metrics", "is", "None", ":", "\n", "            ", "metrics", "=", "[", "]", "\n", "", "self", ".", "metrics", "=", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.add": [[18, 24], ["composite_eval_metric.CompositeEvalMetric.metrics.append"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "metric", ")", ":", "\n", "        ", "\"\"\"Adds a child metric.\n        Args:\n            metric (EvalMetric): A metric instance.\n        \"\"\"", "\n", "self", ".", "metrics", ".", "append", "(", "metric", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get_metric": [[25, 35], ["ValueError", "len"], "methods", ["None"], ["", "def", "get_metric", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Returns a child metric.\n        Args:\n            index (int): Index of child metric in the list of metrics.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "return", "self", ".", "metrics", "[", "index", "]", "\n", "", "except", "IndexError", ":", "\n", "            ", "return", "ValueError", "(", "\"Metric index {} is out of range 0 and {}\"", ".", "format", "(", "\n", "index", ",", "len", "(", "self", ".", "metrics", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.update": [[36, 44], ["metric.update"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update"], ["", "", "def", "update", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "\"\"\"Updates the internal evaluation result.\n        Args:\n            labels (dict of `NDArray`): The labels of the data.\n            preds (dict of `NDArray`): Predicted values.\n        \"\"\"", "\n", "for", "metric", "in", "self", ".", "metrics", ":", "\n", "            ", "metric", ".", "update", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.reset": [[45, 52], ["metric.reset"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.reset"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets the internal evaluation result to initial state.\"\"\"", "\n", "try", ":", "\n", "            ", "for", "metric", "in", "self", ".", "metrics", ":", "\n", "                ", "metric", ".", "reset", "(", ")", "\n", "", "", "except", "AttributeError", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get": [[53, 70], ["metric.get", "isinstance", "isinstance", "names.extend", "values.extend"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.composite_eval_metric.CompositeEvalMetric.get"], ["", "", "def", "get", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the current evaluation result.\n        Returns:\n            names (list of str): Name of the metrics.\n            values (list of float): Value of the evaluations.\n        \"\"\"", "\n", "names", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "for", "metric", "in", "self", ".", "metrics", ":", "\n", "            ", "name", ",", "value", "=", "metric", ".", "get", "(", ")", "\n", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "name", "=", "[", "name", "]", "\n", "", "if", "isinstance", "(", "value", ",", "(", "float", ",", "int", ",", "np", ".", "generic", ",", "torch", ".", "Tensor", ")", ")", ":", "\n", "                ", "value", "=", "[", "value", "]", "\n", "", "names", ".", "extend", "(", "name", ")", "\n", "values", ".", "extend", "(", "value", ")", "\n", "", "return", "names", ",", "values", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.LossLogger.__init__": [[6, 12], ["eval_metric.EvalMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_name", ",", "display_name", "=", "None", ",", "\n", "allreduce", "=", "False", ",", "num_replicas", "=", "1", ")", ":", "\n", "        ", "self", ".", "output_name", "=", "output_name", "\n", "if", "display_name", "is", "None", ":", "\n", "            ", "display_name", "=", "output_name", "\n", "", "super", "(", "LossLogger", ",", "self", ")", ".", "__init__", "(", "display_name", ",", "allreduce", ",", "num_replicas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.LossLogger.update": [[13, 18], ["torch.no_grad", "float", "outputs[].mean().item", "outputs[].mean"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "self", ".", "output_name", "in", "outputs", ":", "\n", "                ", "self", ".", "sum_metric", "+=", "float", "(", "outputs", "[", "self", ".", "output_name", "]", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "", "self", ".", "num_inst", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.RelationshipAccuracy.__init__": [[21, 23], ["eval_metric.EvalMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "allreduce", "=", "False", ",", "num_replicas", "=", "1", ")", ":", "\n", "        ", "super", "(", "RelationshipAccuracy", ",", "self", ")", ".", "__init__", "(", "'RelAcc'", ",", "allreduce", ",", "num_replicas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.RelationshipAccuracy.update": [[24, 32], ["torch.no_grad", "float"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "outputs", "[", "'relationship_logits'", "]", "\n", "label", "=", "outputs", "[", "'relationship_label'", "]", "\n", "# FM edit: change to deal with sigmoid, single output", "\n", "# self.sum_metric += float((logits.argmax(dim=1) == label).sum().item())", "\n", "self", ".", "sum_metric", "+=", "float", "(", "(", "(", "(", "logits", ">", "0.5", ")", ".", "to", "(", "device", "=", "logits", ".", "device", ",", "dtype", "=", "torch", ".", "float", ")", ")", ".", "squeeze", "(", ")", "==", "label", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "self", ".", "num_inst", "+=", "logits", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MLMAccuracy.__init__": [[35, 37], ["eval_metric.EvalMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "allreduce", "=", "False", ",", "num_replicas", "=", "1", ")", ":", "\n", "        ", "super", "(", "MLMAccuracy", ",", "self", ")", ".", "__init__", "(", "'MLMAcc'", ",", "allreduce", ",", "num_replicas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MLMAccuracy.update": [[38, 46], ["torch.no_grad", "keep.sum", "float", "keep.sum().item", "keep.sum", "logits[].argmax"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "outputs", "[", "'mlm_logits'", "]", "\n", "label", "=", "outputs", "[", "'mlm_label'", "]", "\n", "keep", "=", "(", "label", "!=", "-", "1", ")", "\n", "if", "keep", ".", "sum", "(", ")", ">", "0", ":", "\n", "                ", "self", ".", "sum_metric", "+=", "float", "(", "(", "logits", "[", "keep", "]", ".", "argmax", "(", "dim", "=", "1", ")", "==", "label", "[", "keep", "]", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "self", ".", "num_inst", "+=", "keep", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MLMAccuracyWVC.__init__": [[49, 51], ["eval_metric.EvalMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "allreduce", "=", "False", ",", "num_replicas", "=", "1", ")", ":", "\n", "        ", "super", "(", "MLMAccuracyWVC", ",", "self", ")", ".", "__init__", "(", "'MLMAccWVC'", ",", "allreduce", ",", "num_replicas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MLMAccuracyWVC.update": [[52, 60], ["torch.no_grad", "keep.sum", "float", "keep.sum().item", "keep.sum", "logits[].argmax"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "outputs", "[", "'mlm_logits_wvc'", "]", "\n", "label", "=", "outputs", "[", "'mlm_label_wvc'", "]", "\n", "keep", "=", "(", "label", "!=", "-", "1", ")", "\n", "if", "keep", ".", "sum", "(", ")", ">", "0", ":", "\n", "                ", "self", ".", "sum_metric", "+=", "float", "(", "(", "logits", "[", "keep", "]", ".", "argmax", "(", "dim", "=", "1", ")", "==", "label", "[", "keep", "]", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "self", ".", "num_inst", "+=", "keep", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MLMAccuracyAUX.__init__": [[63, 65], ["eval_metric.EvalMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "allreduce", "=", "False", ",", "num_replicas", "=", "1", ")", ":", "\n", "        ", "super", "(", "MLMAccuracyAUX", ",", "self", ")", ".", "__init__", "(", "'MLMAccAUX'", ",", "allreduce", ",", "num_replicas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MLMAccuracyAUX.update": [[66, 74], ["torch.no_grad", "keep.sum", "float", "keep.sum().item", "keep.sum", "logits[].argmax"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "outputs", "[", "'mlm_logits_aux'", "]", "\n", "label", "=", "outputs", "[", "'mlm_label_aux'", "]", "\n", "keep", "=", "(", "label", "!=", "-", "1", ")", "\n", "if", "keep", ".", "sum", "(", ")", ">", "0", ":", "\n", "                ", "self", ".", "sum_metric", "+=", "float", "(", "(", "logits", "[", "keep", "]", ".", "argmax", "(", "dim", "=", "1", ")", "==", "label", "[", "keep", "]", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "self", ".", "num_inst", "+=", "keep", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MLMAccuracyGlobal.__init__": [[76, 79], ["eval_metric.EvalMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "allreduce", "=", "False", ",", "num_replicas", "=", "1", ",", "eval_name", "=", "'default_name'", ")", ":", "\n", "        ", "super", "(", "MLMAccuracyGlobal", ",", "self", ")", ".", "__init__", "(", "'MLMAccuracy'", "+", "eval_name", ",", "allreduce", ",", "num_replicas", ")", "\n", "self", ".", "eval_name", "=", "eval_name", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MLMAccuracyGlobal.update": [[80, 88], ["torch.no_grad", "keep.sum", "float", "keep.sum().item", "keep.sum", "logits[].argmax"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "outputs", "[", "'mlm_logits_'", "+", "self", ".", "eval_name", "]", "\n", "label", "=", "outputs", "[", "'mlm_label_'", "+", "self", ".", "eval_name", "]", "\n", "keep", "=", "(", "label", "!=", "-", "1", ")", "\n", "if", "keep", ".", "sum", "(", ")", ">", "0", ":", "\n", "                ", "self", ".", "sum_metric", "+=", "float", "(", "(", "logits", "[", "keep", "]", ".", "argmax", "(", "dim", "=", "1", ")", "==", "label", "[", "keep", "]", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "self", ".", "num_inst", "+=", "keep", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MLMAccuracyDataset1.__init__": [[91, 93], ["eval_metric.EvalMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "allreduce", "=", "False", ",", "num_replicas", "=", "1", ")", ":", "\n", "        ", "super", "(", "MLMAccuracyDataset1", ",", "self", ")", ".", "__init__", "(", "'MLMAccDataset1'", ",", "allreduce", ",", "num_replicas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MLMAccuracyDataset1.update": [[94, 102], ["torch.no_grad", "keep.sum", "float", "keep.sum().item", "keep.sum", "logits[].argmax"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "outputs", "[", "'mlm_logits_dataset1'", "]", "\n", "label", "=", "outputs", "[", "'mlm_label_dataset1'", "]", "\n", "keep", "=", "(", "label", "!=", "-", "1", ")", "\n", "if", "keep", ".", "sum", "(", ")", ">", "0", ":", "\n", "                ", "self", ".", "sum_metric", "+=", "float", "(", "(", "logits", "[", "keep", "]", ".", "argmax", "(", "dim", "=", "1", ")", "==", "label", "[", "keep", "]", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "self", ".", "num_inst", "+=", "keep", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MLMAccuracyDataset2.__init__": [[104, 106], ["eval_metric.EvalMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "allreduce", "=", "False", ",", "num_replicas", "=", "1", ")", ":", "\n", "        ", "super", "(", "MLMAccuracyDataset2", ",", "self", ")", ".", "__init__", "(", "'MLMAccDataset2'", ",", "allreduce", ",", "num_replicas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MLMAccuracyDataset2.update": [[107, 115], ["torch.no_grad", "keep.sum", "float", "keep.sum().item", "keep.sum", "logits[].argmax"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "outputs", "[", "'mlm_logits_dataset2'", "]", "\n", "label", "=", "outputs", "[", "'mlm_label_dataset2'", "]", "\n", "keep", "=", "(", "label", "!=", "-", "1", ")", "\n", "if", "keep", ".", "sum", "(", ")", ">", "0", ":", "\n", "                ", "self", ".", "sum_metric", "+=", "float", "(", "(", "logits", "[", "keep", "]", ".", "argmax", "(", "dim", "=", "1", ")", "==", "label", "[", "keep", "]", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "self", ".", "num_inst", "+=", "keep", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MLMAccuracyDataset3.__init__": [[117, 119], ["eval_metric.EvalMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "allreduce", "=", "False", ",", "num_replicas", "=", "1", ")", ":", "\n", "        ", "super", "(", "MLMAccuracyDataset3", ",", "self", ")", ".", "__init__", "(", "'MLMAccDataset3'", ",", "allreduce", ",", "num_replicas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MLMAccuracyDataset3.update": [[120, 128], ["torch.no_grad", "keep.sum", "float", "keep.sum().item", "keep.sum", "logits[].argmax"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "outputs", "[", "'mlm_logits_dataset3'", "]", "\n", "label", "=", "outputs", "[", "'mlm_label_dataset3'", "]", "\n", "keep", "=", "(", "label", "!=", "-", "1", ")", "\n", "if", "keep", ".", "sum", "(", ")", ">", "0", ":", "\n", "                ", "self", ".", "sum_metric", "+=", "float", "(", "(", "logits", "[", "keep", "]", ".", "argmax", "(", "dim", "=", "1", ")", "==", "label", "[", "keep", "]", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "self", ".", "num_inst", "+=", "keep", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracy.__init__": [[132, 134], ["eval_metric.EvalMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "allreduce", "=", "False", ",", "num_replicas", "=", "1", ")", ":", "\n", "        ", "super", "(", "MVRCAccuracy", ",", "self", ")", ".", "__init__", "(", "'MVRCAccuracy'", ",", "allreduce", ",", "num_replicas", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracy.update": [[135, 145], ["torch.no_grad", "keep.sum", "float", "keep.sum().item", "keep.sum", "label.sum", "logits[].argmax", "label[].argmax"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "outputs", "[", "'mvrc_logits'", "]", "\n", "label", "=", "outputs", "[", "'mvrc_label'", "]", "\n", "keep", "=", "(", "label", ".", "sum", "(", "2", ")", "-", "1.0", ")", ".", "abs", "(", ")", "<", "0.1", "\n", "if", "keep", ".", "sum", "(", ")", ">", "0", ":", "\n", "#FM note: when [keep] is applied it collapsees logits(batch,#RoI,#classes)", "\n", "#to logits(#relevant_RoI, #classes)", "\n", "                ", "self", ".", "sum_metric", "+=", "float", "(", "(", "logits", "[", "keep", "]", ".", "argmax", "(", "dim", "=", "1", ")", "==", "label", "[", "keep", "]", ".", "argmax", "(", "dim", "=", "1", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "self", ".", "num_inst", "+=", "keep", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__": [[147, 150], ["eval_metric.EvalMetric.__init__"], "methods", ["home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.__init__"], ["    ", "def", "__init__", "(", "self", ",", "allreduce", "=", "False", ",", "num_replicas", "=", "1", ",", "eval_name", "=", "'default_name'", ")", ":", "\n", "        ", "super", "(", "MVRCAccuracyGlobal", ",", "self", ")", ".", "__init__", "(", "'MVRCAccuracy'", "+", "eval_name", ",", "allreduce", ",", "num_replicas", ")", "\n", "self", ".", "eval_name", "=", "eval_name", "\n", "\n"]], "home.repos.pwc.inspect_result.ImperialNLP_BertGen.metrics.pretrain_metrics.MVRCAccuracyGlobal.update": [[151, 161], ["torch.no_grad", "keep.sum", "float", "keep.sum().item", "keep.sum", "label.sum", "logits[].argmax", "label[].argmax"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logits", "=", "outputs", "[", "'mvrc_logits_'", "+", "self", ".", "eval_name", "]", "\n", "label", "=", "outputs", "[", "'mvrc_label_'", "+", "self", ".", "eval_name", "]", "\n", "keep", "=", "(", "label", ".", "sum", "(", "2", ")", "-", "1.0", ")", ".", "abs", "(", ")", "<", "0.1", "\n", "if", "keep", ".", "sum", "(", ")", ">", "0", ":", "\n", "#FM note: when [keep] is applied it collapsees logits(batch,#RoI,#classes)", "\n", "#to logits(#relevant_RoI, #classes)", "\n", "                ", "self", ".", "sum_metric", "+=", "float", "(", "(", "logits", "[", "keep", "]", ".", "argmax", "(", "dim", "=", "1", ")", "==", "label", "[", "keep", "]", ".", "argmax", "(", "dim", "=", "1", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "self", ".", "num_inst", "+=", "keep", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]]}