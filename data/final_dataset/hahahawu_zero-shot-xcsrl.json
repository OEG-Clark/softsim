{"home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__init__": [[23, 45], ["transformers.AutoTokenizer.from_pretrained", "processor.Processor.tokenizer.add_tokens", "min", "processor.load_vocab", "len", "processor.Processor.tokenizer.get_vocab", "ValueError"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.srl_data.conll_preprocess.load_vocab"], ["    ", "def", "__init__", "(", "self", ",", "task", ",", "pretrain_model_name", ",", "label_path", "=", "None", ",", "max_seq_len", "=", "512", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "pretrain_model_name", ",", "use_fast", "=", "True", ")", "\n", "self", ".", "tokenizer", ".", "add_tokens", "(", "[", "\"[human]\"", ",", "\"[agent]\"", "]", ")", "\n", "# self.tokenizer.add_special_tokens({'bos_token': \"[BOS]\"})", "\n", "self", ".", "max_sequence_len", "=", "min", "(", "self", ".", "tokenizer", ".", "model_max_length", ",", "max_seq_len", ")", "\n", "if", "task", "==", "'csrl'", ":", "\n", "            ", "label_vocab", "=", "{", "\"O\"", ":", "0", "}", "\n", "self", ".", "label_vocab", "=", "load_vocab", "(", "label_path", ",", "label_vocab", ")", "\n", "", "elif", "task", "==", "'srl'", ":", "\n", "            ", "self", ".", "label_vocab", "=", "{", "\"O\"", ":", "0", "}", "\n", "for", "la", "in", "[", "\"B-V\"", ",", "\"I-V\"", ",", "\"B-ARG\"", ",", "\"I-ARG\"", ",", "\"B-LOC\"", ",", "\"I-LOC\"", ",", "\"B-TMP\"", ",", "\"I-TMP\"", ",", "\"B-PRP\"", ",", "\"I-PRP\"", "]", ":", "\n", "                ", "self", ".", "label_vocab", "[", "la", "]", "=", "len", "(", "self", ".", "label_vocab", ")", "\n", "", "", "elif", "task", "==", "'dialogue'", ":", "\n", "            ", "self", ".", "is_reorder", "=", "kwargs", "[", "\"is_reorder\"", "]", "\n", "self", ".", "is_role_detection", "=", "kwargs", "[", "\"is_role_detection\"", "]", "\n", "", "elif", "task", "==", "'language_model'", ":", "\n", "            ", "self", ".", "word_vocab", "=", "self", ".", "tokenizer", ".", "get_vocab", "(", ")", "\n", "self", ".", "alignment", "=", "kwargs", "[", "\"alignment\"", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"unexpected task {}\"", ".", "format", "(", "task", ")", ")", "\n", "\n", "", "self", ".", "pad_token_id", "=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.encode_csrl_case": [[46, 111], ["enumerate", "processor.Processor.tokenizer.convert_tokens_to_ids", "processor.Processor.__get_dialogue_indices", "subword_indices.insert", "speaker_role_ids.append", "subword_indices.append", "speaker_role_ids.append", "subword_indices.append", "processor.Processor.insert", "processor.Processor.append", "processor.Processor.append", "processor.Processor.tokenizer.tokenize", "tokens.extend", "subword_indices.extend", "speaker_role_ids.append", "len", "len", "len", "len", "len", "len", "len", "len", "len", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "range", "len", "len", "len", "min"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__get_dialogue_indices"], ["", "def", "encode_csrl_case", "(", "self", ",", "case", ")", ":", "\n", "        ", "words", ",", "pred_idx", ",", "turn_ids", ",", "label", "=", "case", "[", "\"words\"", "]", ",", "case", "[", "\"pred_idx\"", "]", ",", "case", "[", "\"turn_ids\"", "]", ",", "case", "[", "\"label\"", "]", "\n", "\n", "subword_indices", "=", "[", "]", "\n", "speaker_role_ids", "=", "[", "]", "\n", "tokens", "=", "[", "]", "\n", "word_idx", "=", "2", "\n", "speaker_role", "=", "\"[agent]\"", "\n", "speaker_role_id_mapping", "=", "{", "\"[agent]\"", ":", "1", ",", "\"[human]\"", ":", "2", "}", "\n", "for", "idx", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "            ", "tokenized_words", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "word", ")", "\n", "tokenized_words", "=", "[", "t", "for", "t", "in", "tokenized_words", "if", "t", "!=", "SPIECE_UNDERLINE", "]", "\n", "if", "len", "(", "tokenized_words", ")", "+", "len", "(", "tokens", ")", ">=", "self", ".", "max_sequence_len", "-", "3", ":", "\n", "                ", "words", "=", "words", "[", ":", "idx", "]", "\n", "break", "\n", "", "tokens", ".", "extend", "(", "tokenized_words", ")", "\n", "subword_indices", ".", "extend", "(", "[", "word_idx", "]", "*", "len", "(", "tokenized_words", ")", ")", "\n", "word_idx", "+=", "1", "\n", "\n", "if", "word", "in", "[", "\"[agent]\"", ",", "\"[human]\"", "]", ":", "\n", "                ", "speaker_role", "=", "word", "\n", "", "speaker_role_ids", ".", "append", "(", "speaker_role_id_mapping", "[", "speaker_role", "]", ")", "\n", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "sequence_length", "=", "len", "(", "words", ")", "+", "2", "\n", "\n", "# add [CLS] and [SEP]", "\n", "dialogue_indices", ",", "utterance_num", "=", "self", ".", "__get_dialogue_indices", "(", "words", ")", "\n", "subword_indices", ".", "insert", "(", "0", ",", "1", ")", "# [CLS]", "\n", "speaker_role_ids", ".", "append", "(", "0", ")", "\n", "subword_indices", ".", "append", "(", "subword_indices", "[", "-", "1", "]", "+", "1", ")", "# [SEP]", "\n", "speaker_role_ids", ".", "append", "(", "0", ")", "\n", "subword_indices", ".", "append", "(", "0", ")", "# [PAD]", "\n", "\n", "input_ids", ".", "insert", "(", "0", ",", "self", ".", "tokenizer", ".", "cls_token_id", ")", "# [CLS]", "\n", "input_ids", ".", "append", "(", "self", ".", "tokenizer", ".", "sep_token_id", ")", "# [SEP]", "\n", "input_ids", ".", "append", "(", "self", ".", "tokenizer", ".", "pad_token_id", ")", "# [PAD]", "\n", "\n", "pred_idx", "=", "[", "p", "+", "1", "for", "p", "in", "pred_idx", "]", "\n", "# pred_idx += (self.max_predicate_length - len(pred_idx)) * [0]", "\n", "predicate_ids", "=", "[", "2", "if", "_", "in", "pred_idx", "else", "1", "for", "_", "in", "range", "(", "sequence_length", ")", "]", "\n", "\n", "turn_ids", "=", "turn_ids", "[", ":", "sequence_length", "-", "2", "]", "\n", "turn_ids", "=", "[", "0", "]", "+", "[", "min", "(", "_", "+", "1", ",", "11", ")", "for", "_", "in", "turn_ids", "]", "+", "[", "0", "]", "\n", "label", "=", "label", "[", ":", "sequence_length", "-", "2", "]", "\n", "label", "=", "[", "\"O\"", "]", "+", "label", "+", "[", "\"O\"", "]", "\n", "label", "=", "[", "self", ".", "label_vocab", "[", "la", "]", "for", "la", "in", "label", "]", "\n", "\n", "tokenized_sequence_length", "=", "len", "(", "input_ids", ")", "-", "1", "\n", "\n", "assert", "len", "(", "input_ids", ")", "==", "len", "(", "subword_indices", ")", "==", "tokenized_sequence_length", "+", "1", "\n", "assert", "len", "(", "label", ")", "==", "sequence_length", "==", "len", "(", "turn_ids", ")", "==", "len", "(", "dialogue_indices", ")", "==", "len", "(", "\n", "speaker_role_ids", ")", "==", "len", "(", "predicate_ids", ")", "\n", "\n", "return", "{", "\n", "\"word_ids\"", ":", "torch", ".", "as_tensor", "(", "input_ids", ")", ",", "\n", "\"predicate_ids\"", ":", "torch", ".", "as_tensor", "(", "predicate_ids", ")", ",", "\n", "\"turn_ids\"", ":", "torch", ".", "as_tensor", "(", "turn_ids", ")", ",", "\n", "\"speaker_role_ids\"", ":", "torch", ".", "as_tensor", "(", "speaker_role_ids", ")", ",", "\n", "\"subword_indices\"", ":", "torch", ".", "as_tensor", "(", "subword_indices", ")", ",", "\n", "\"sequence_length\"", ":", "sequence_length", ",", "\n", "\"tokenized_sequence_length\"", ":", "tokenized_sequence_length", ",", "\n", "\"dialogue_indices\"", ":", "torch", ".", "as_tensor", "(", "dialogue_indices", ")", ",", "\n", "\"utterance_num\"", ":", "utterance_num", ",", "\n", "\"label\"", ":", "torch", ".", "as_tensor", "(", "label", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__dialogue_processing": [[113, 119], ["words.append", "words.extend", "conv.split"], "methods", ["None"], ["", "def", "__dialogue_processing", "(", "self", ",", "conversations", ")", ":", "\n", "        ", "words", "=", "[", "]", "\n", "for", "conv", "in", "conversations", ":", "\n", "            ", "words", ".", "append", "(", "self", ".", "tokenizer", ".", "bos_token", ")", "\n", "words", ".", "extend", "(", "conv", ".", "split", "(", "\" \"", ")", ")", "\n", "", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__dialogue_tokenization": [[120, 170], ["processor.Processor.__dialogue_processing", "enumerate", "processor.Processor.tokenizer.convert_tokens_to_ids", "processor.Processor.__get_dialogue_indices", "labels.insert", "labels.append", "subword_indices.insert", "subword_indices.append", "subword_indices.append", "processor.Processor.insert", "processor.Processor.append", "processor.Processor.append", "position_ids.insert", "position_ids.append", "position_ids.append", "processor.Processor.tokenizer.tokenize", "tokens.extend", "position_ids.extend", "subword_indices.extend", "len", "len", "len", "len", "len", "len", "len", "len", "max", "list", "len", "len", "len", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__dialogue_processing", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__get_dialogue_indices"], ["", "def", "__dialogue_tokenization", "(", "self", ",", "conversations", ",", "labels", ")", ":", "\n", "        ", "words", "=", "self", ".", "__dialogue_processing", "(", "conversations", ")", "\n", "cur_turn", "=", "0", "\n", "subword_indices", "=", "[", "]", "\n", "tokens", "=", "[", "]", "\n", "position_ids", "=", "[", "]", "\n", "cur_pos", "=", "0", "\n", "word_idx", "=", "2", "\n", "for", "idx", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "            ", "if", "word", "==", "self", ".", "tokenizer", ".", "eos_token", ":", "\n", "                ", "cur_turn", "+=", "1", "\n", "cur_pos", "=", "0", "\n", "", "tokenized_words", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "word", ")", "\n", "tokenized_words", "=", "[", "t", "for", "t", "in", "tokenized_words", "if", "t", "!=", "SPIECE_UNDERLINE", "]", "\n", "if", "len", "(", "tokenized_words", ")", "+", "len", "(", "tokens", ")", ">=", "self", ".", "max_sequence_len", "-", "3", ":", "\n", "                ", "words", "=", "words", "[", ":", "idx", "]", "\n", "labels", "=", "labels", "[", ":", "cur_turn", "]", "\n", "break", "\n", "", "tokens", ".", "extend", "(", "tokenized_words", ")", "\n", "position_ids", ".", "extend", "(", "list", "(", "range", "(", "cur_pos", ",", "cur_pos", "+", "len", "(", "tokenized_words", ")", ")", ")", ")", "\n", "subword_indices", ".", "extend", "(", "[", "word_idx", "]", "*", "len", "(", "tokenized_words", ")", ")", "\n", "word_idx", "+=", "1", "\n", "cur_pos", "+=", "len", "(", "tokenized_words", ")", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "dialogue_indices", ",", "utterance_num", "=", "self", ".", "__get_dialogue_indices", "(", "words", ")", "\n", "labels", ".", "insert", "(", "0", ",", "-", "100", ")", "\n", "labels", ".", "append", "(", "-", "100", ")", "\n", "\n", "subword_indices", ".", "insert", "(", "0", ",", "1", ")", "# [CLS]", "\n", "subword_indices", ".", "append", "(", "subword_indices", "[", "-", "1", "]", "+", "1", ")", "# [SEP]", "\n", "subword_indices", ".", "append", "(", "0", ")", "# add [PAD]", "\n", "\n", "input_ids", ".", "insert", "(", "0", ",", "self", ".", "tokenizer", ".", "cls_token_id", ")", "# [CLS]", "\n", "input_ids", ".", "append", "(", "self", ".", "tokenizer", ".", "sep_token_id", ")", "# [SEP]", "\n", "input_ids", ".", "append", "(", "self", ".", "pad_token_id", ")", "# [PAD]", "\n", "\n", "position_ids", ".", "insert", "(", "0", ",", "0", ")", "\n", "position_ids", ".", "append", "(", "0", ")", "\n", "position_ids", ".", "append", "(", "0", ")", "\n", "\n", "sequence_length", "=", "len", "(", "words", ")", "+", "2", "\n", "tokenized_sequence_length", "=", "len", "(", "input_ids", ")", "-", "1", "\n", "\n", "assert", "len", "(", "input_ids", ")", "==", "len", "(", "subword_indices", ")", "==", "len", "(", "position_ids", ")", "\n", "assert", "len", "(", "input_ids", ")", "<=", "self", ".", "tokenizer", ".", "model_max_length", "\n", "assert", "len", "(", "dialogue_indices", ")", "==", "len", "(", "words", ")", "+", "2", "\n", "assert", "sequence_length", "==", "max", "(", "subword_indices", ")", "\n", "\n", "return", "input_ids", ",", "subword_indices", ",", "dialogue_indices", ",", "utterance_num", ",", "labels", ",", "sequence_length", ",", "tokenized_sequence_length", ",", "position_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.encode_dialog_case": [[171, 239], ["copy.deepcopy", "copy.deepcopy", "max", "list", "random.shuffle", "processor.Processor.__dialogue_tokenization", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "enumerate", "processor.Processor.__dialogue_tokenization", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "min", "range", "_new_tmp.append", "len", "len", "len", "len", "len", "int", "len", "random.random", "re.split", "new_role_ids.append", "new_speaker_conv.append", "_.strip", "len", "_.strip", "len", "new_role_ids.append", "new_speaker_conv.append", "len", "len", "_.strip"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__dialogue_tokenization", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__dialogue_tokenization"], ["", "def", "encode_dialog_case", "(", "self", ",", "case", ")", ":", "\n", "        ", "conversations", "=", "case", "\n", "conversations", "=", "[", "_", "for", "_", "in", "conversations", "if", "len", "(", "_", ".", "strip", "(", ")", ")", ">", "0", "]", "\n", "\n", "reorder_conv", "=", "copy", ".", "deepcopy", "(", "conversations", ")", "\n", "speaker_conv", "=", "copy", ".", "deepcopy", "(", "conversations", ")", "\n", "\n", "return_dict", "=", "{", "}", "\n", "\n", "# utterance reorder", "\n", "if", "self", ".", "is_reorder", ":", "\n", "            ", "k", "=", "0.4", "# To reduce the search space, we only reorder k*U utterances", "\n", "num_reorder_utterance", "=", "max", "(", "min", "(", "int", "(", "k", "*", "len", "(", "reorder_conv", ")", ")", ",", "10", ")", ",", "2", ")", "\n", "# rand_s = random.randint(0, max(len(reorder_conv) - 1 - num_reorder_utterance, 0))", "\n", "_tmp", "=", "conversations", "[", "-", "num_reorder_utterance", ":", "]", "\n", "_tmp_seq", "=", "list", "(", "range", "(", "0", ",", "len", "(", "_tmp", ")", ")", ")", "\n", "random", ".", "shuffle", "(", "_tmp_seq", ")", "\n", "_new_tmp", "=", "[", "]", "\n", "for", "_t", "in", "_tmp_seq", ":", "\n", "                ", "_new_tmp", ".", "append", "(", "_tmp", "[", "_t", "]", ")", "\n", "", "reorder_conv", "[", "-", "num_reorder_utterance", ":", "]", "=", "_new_tmp", "\n", "reorder_label", "=", "[", "-", "100", "]", "*", "(", "len", "(", "reorder_conv", ")", "-", "num_reorder_utterance", ")", "+", "_tmp_seq", "\n", "assert", "len", "(", "reorder_label", ")", "==", "len", "(", "reorder_conv", ")", "\n", "\n", "reorder_input_ids", ",", "reorder_subword_indices", ",", "reorder_dialogue_indices", ",", "reorder_utterance_num", ",", "reorder_label", ",", "reorder_sequence_length", ",", "reorder_tokenized_sequence_length", ",", "reorder_position_ids", "=", "self", ".", "__dialogue_tokenization", "(", "reorder_conv", ",", "reorder_label", ")", "\n", "return_dict", "[", "\"reorder_input_ids\"", "]", "=", "torch", ".", "as_tensor", "(", "reorder_input_ids", ")", "\n", "return_dict", "[", "\"reorder_subword_indices\"", "]", "=", "torch", ".", "as_tensor", "(", "reorder_subword_indices", ")", "\n", "return_dict", "[", "\"reorder_dialogue_indices\"", "]", "=", "torch", ".", "as_tensor", "(", "reorder_dialogue_indices", ")", "\n", "return_dict", "[", "\"reorder_utterance_num\"", "]", "=", "reorder_utterance_num", "\n", "return_dict", "[", "\"reorder_label\"", "]", "=", "torch", ".", "as_tensor", "(", "reorder_label", ")", "\n", "return_dict", "[", "\"reorder_sequence_length\"", "]", "=", "reorder_sequence_length", "\n", "return_dict", "[", "\"reorder_tokenized_sequence_length\"", "]", "=", "reorder_tokenized_sequence_length", "\n", "return_dict", "[", "\"reorder_position_ids\"", "]", "=", "torch", ".", "as_tensor", "(", "reorder_position_ids", ")", "\n", "\n", "# speaker role identification; split the utterance by punctuations", "\n", "", "if", "self", ".", "is_role_detection", ":", "\n", "# we cut an utterance into 5 sub-sentences at maximum.", "\n", "            ", "max_sub_sentences", "=", "5", "\n", "new_role_ids", ",", "new_speaker_conv", "=", "[", "]", ",", "[", "]", "\n", "for", "idx", ",", "conv", "in", "enumerate", "(", "speaker_conv", ")", ":", "\n", "# 50% utterance unchanged and 50% utterances are cut", "\n", "                ", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "                    ", "split_sub_sentences", "=", "re", ".", "split", "(", "'[.,?!\u3002\uff0c\uff1f\uff01]'", ",", "conv", ")", "\n", "split_sub_sentences", "=", "[", "_", ".", "strip", "(", ")", "for", "_", "in", "split_sub_sentences", "if", "len", "(", "_", ".", "strip", "(", ")", ")", ">", "0", "]", "\n", "if", "len", "(", "split_sub_sentences", ")", ">", "max_sub_sentences", ":", "\n", "                        ", "split_sub_sentences", "[", "max_sub_sentences", "-", "1", "]", "=", "\" \"", ".", "join", "(", "split_sub_sentences", "[", "max_sub_sentences", ":", "]", ")", "\n", "", "for", "split_sent", "in", "split_sub_sentences", ":", "\n", "                        ", "new_role_ids", ".", "append", "(", "idx", "%", "2", ")", "\n", "new_speaker_conv", ".", "append", "(", "split_sent", ")", "\n", "", "", "else", ":", "\n", "                    ", "new_role_ids", ".", "append", "(", "idx", "%", "2", ")", "\n", "new_speaker_conv", ".", "append", "(", "conv", ")", "\n", "", "", "assert", "len", "(", "new_role_ids", ")", "==", "len", "(", "new_speaker_conv", ")", "\n", "role_input_ids", ",", "role_subword_indices", ",", "role_dialogue_indices", ",", "role_utterance_num", ",", "new_role_ids", ",", "role_sequence_length", ",", "role_tokenized_sequence_length", ",", "role_position_ids", "=", "self", ".", "__dialogue_tokenization", "(", "\n", "new_speaker_conv", ",", "new_role_ids", ")", "\n", "return_dict", "[", "\"role_input_ids\"", "]", "=", "torch", ".", "as_tensor", "(", "role_input_ids", ")", "\n", "return_dict", "[", "\"role_subword_indices\"", "]", "=", "torch", ".", "as_tensor", "(", "role_subword_indices", ")", "\n", "return_dict", "[", "\"role_dialogue_indices\"", "]", "=", "torch", ".", "as_tensor", "(", "role_dialogue_indices", ")", "\n", "return_dict", "[", "\"role_utterance_num\"", "]", "=", "role_utterance_num", "\n", "return_dict", "[", "\"role_label\"", "]", "=", "torch", ".", "as_tensor", "(", "new_role_ids", ")", "\n", "return_dict", "[", "\"role_sequence_length\"", "]", "=", "role_sequence_length", "\n", "return_dict", "[", "\"role_tokenized_sequence_length\"", "]", "=", "role_tokenized_sequence_length", "\n", "return_dict", "[", "\"role_position_ids\"", "]", "=", "torch", ".", "as_tensor", "(", "role_position_ids", ")", "\n", "\n", "", "return", "return_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__tokenize_sequence": [[240, 254], ["enumerate", "processor.Processor.tokenizer.tokenize", "tokens.extend", "subword_indices.extend", "len", "len", "len"], "methods", ["None"], ["", "def", "__tokenize_sequence", "(", "self", ",", "words", ")", ":", "\n", "        ", "subword_indices", "=", "[", "]", "\n", "tokens", "=", "[", "]", "\n", "word_idx", "=", "2", "\n", "for", "idx", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "            ", "tokenized_words", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "word", ")", "\n", "tokenized_words", "=", "[", "t", "for", "t", "in", "tokenized_words", "if", "t", "!=", "SPIECE_UNDERLINE", "]", "\n", "if", "len", "(", "tokenized_words", ")", "+", "len", "(", "tokens", ")", ">=", "self", ".", "max_sequence_len", "-", "3", ":", "\n", "                ", "words", "=", "words", "[", ":", "idx", "]", "\n", "break", "\n", "", "tokens", ".", "extend", "(", "tokenized_words", ")", "\n", "subword_indices", ".", "extend", "(", "[", "word_idx", "]", "*", "len", "(", "tokenized_words", ")", ")", "\n", "word_idx", "+=", "1", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.concat_and_convert_tokens_to_input_ids": [[255, 262], ["processor.Processor.tokenizer.convert_tokens_to_ids", "processor.Processor.tokenizer.convert_tokens_to_ids"], "methods", ["None"], ["", "def", "concat_and_convert_tokens_to_input_ids", "(", "self", ",", "token1", ",", "token2", "=", "None", ")", ":", "\n", "        ", "if", "token2", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "\n", "[", "self", ".", "tokenizer", ".", "cls_token", "]", "+", "token1", "+", "[", "self", ".", "tokenizer", ".", "sep_token", "]", "+", "token2", "+", "[", "self", ".", "tokenizer", ".", "sep_token", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "\n", "[", "self", ".", "tokenizer", ".", "cls_token", "]", "+", "token1", "+", "[", "self", ".", "tokenizer", ".", "sep_token", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.encoder_lm_case": [[263, 325], ["len", "processor.Processor.concat_and_convert_tokens_to_input_ids", "processor.Processor.concat_and_convert_tokens_to_input_ids", "random.random", "processor.Processor.__masking", "processor.Processor.__masking", "processor.Processor.__tokenize_sequence", "processor.Processor.__tokenize_sequence", "processor.Processor.__tokenize_sequence", "processor.Processor.__tokenize_sequence", "processor.Processor.concat_and_convert_tokens_to_input_ids", "len", "len", "len", "len", "torch.as_tensor", "torch.as_tensor", "len", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "len", "case[].split", "processor.Processor.__tokenize_sequence", "processor.Processor.concat_and_convert_tokens_to_input_ids", "processor.Processor.__masking", "ValueError", "random.random", "processor.Processor.concat_and_convert_tokens_to_input_ids", "processor.Processor.concat_and_convert_tokens_to_input_ids", "random.random", "processor.Processor.concat_and_convert_tokens_to_input_ids", "processor.Processor.concat_and_convert_tokens_to_input_ids", "processor.Processor.concat_and_convert_tokens_to_input_ids", "len", "len", "torch.as_tensor", "len", "torch.as_tensor", "len", "processor.Processor.concat_and_convert_tokens_to_input_ids", "processor.Processor.concat_and_convert_tokens_to_input_ids"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.concat_and_convert_tokens_to_input_ids", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.concat_and_convert_tokens_to_input_ids", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__masking", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__masking", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__tokenize_sequence", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__tokenize_sequence", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__tokenize_sequence", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__tokenize_sequence", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.concat_and_convert_tokens_to_input_ids", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__tokenize_sequence", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.concat_and_convert_tokens_to_input_ids", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__masking", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.concat_and_convert_tokens_to_input_ids", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.concat_and_convert_tokens_to_input_ids", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.concat_and_convert_tokens_to_input_ids", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.concat_and_convert_tokens_to_input_ids", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.concat_and_convert_tokens_to_input_ids", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.concat_and_convert_tokens_to_input_ids", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.concat_and_convert_tokens_to_input_ids"], ["", "", "def", "encoder_lm_case", "(", "self", ",", "case", ")", ":", "\n", "        ", "if", "len", "(", "case", ")", ">", "1", ":", "\n", "            ", "pos_pair", ",", "negative_pair", ",", "op_flag", "=", "case", "\n", "en_words", ",", "zh_words", "=", "pos_pair", "\n", "neg_en_words", ",", "neg_zh_words", "=", "negative_pair", "\n", "en_tokens", ",", "neg_en_tokens", "=", "self", ".", "__tokenize_sequence", "(", "en_words", ")", ",", "self", ".", "__tokenize_sequence", "(", "neg_en_words", ")", "\n", "zh_tokens", ",", "neg_zh_tokens", "=", "self", ".", "__tokenize_sequence", "(", "zh_words", ")", ",", "self", ".", "__tokenize_sequence", "(", "neg_zh_words", ")", "\n", "en_zh", "=", "self", ".", "concat_and_convert_tokens_to_input_ids", "(", "en_tokens", ",", "zh_tokens", ")", "\n", "zh_en", "=", "self", ".", "concat_and_convert_tokens_to_input_ids", "(", "zh_tokens", ",", "en_tokens", ")", "\n", "\n", "# For psi task, construct [neg, neg] pairs and [pos, neg] pairs", "\n", "# [neg, neg] pair", "\n", "if", "op_flag", ":", "\n", "                ", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "                    ", "pos_pair", "=", "self", ".", "concat_and_convert_tokens_to_input_ids", "(", "neg_en_tokens", ",", "neg_zh_tokens", ")", "\n", "", "else", ":", "\n", "                    ", "pos_pair", "=", "self", ".", "concat_and_convert_tokens_to_input_ids", "(", "neg_zh_tokens", ",", "neg_en_tokens", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "                    ", "pos_pair", "=", "self", ".", "concat_and_convert_tokens_to_input_ids", "(", "en_tokens", ",", "zh_tokens", ")", "\n", "", "else", ":", "\n", "                    ", "pos_pair", "=", "self", ".", "concat_and_convert_tokens_to_input_ids", "(", "zh_tokens", ",", "en_tokens", ")", "\n", "\n", "# [pos, neg] pairs", "\n", "", "", "rd", "=", "random", ".", "random", "(", ")", "\n", "if", "rd", ">", "0.75", ":", "\n", "                ", "neg_pair", "=", "self", ".", "concat_and_convert_tokens_to_input_ids", "(", "en_tokens", ",", "neg_zh_tokens", ")", "\n", "", "elif", "rd", ">", "0.5", ":", "\n", "                ", "neg_pair", "=", "self", ".", "concat_and_convert_tokens_to_input_ids", "(", "zh_tokens", ",", "neg_en_tokens", ")", "\n", "", "elif", "rd", ">", "0.25", ":", "\n", "                ", "neg_pair", "=", "self", ".", "concat_and_convert_tokens_to_input_ids", "(", "neg_en_tokens", ",", "zh_tokens", ")", "\n", "", "else", ":", "\n", "                ", "neg_pair", "=", "self", ".", "concat_and_convert_tokens_to_input_ids", "(", "neg_zh_tokens", ",", "en_tokens", ")", "\n", "\n", "", "en_zh_mlm_label", ",", "en_zh_ids", "=", "self", ".", "__masking", "(", "en_zh", ")", "\n", "zh_en_mlm_label", ",", "zh_en_ids", "=", "self", ".", "__masking", "(", "zh_en", ")", "\n", "\n", "assert", "len", "(", "en_zh_mlm_label", ")", "==", "len", "(", "en_zh_ids", ")", "==", "len", "(", "zh_en_mlm_label", ")", "==", "len", "(", "zh_en_ids", ")", "\n", "\n", "return", "{", "\n", "\"en_zh_ids\"", ":", "torch", ".", "as_tensor", "(", "en_zh_ids", ")", ",", "\n", "\"zh_en_ids\"", ":", "torch", ".", "as_tensor", "(", "zh_en_ids", ")", ",", "\n", "\"sequence_length\"", ":", "len", "(", "en_zh_mlm_label", ")", ",", "\n", "\"en_zh_label\"", ":", "torch", ".", "as_tensor", "(", "en_zh_mlm_label", ")", ",", "\n", "\"zh_en_label\"", ":", "torch", ".", "as_tensor", "(", "zh_en_mlm_label", ")", ",", "\n", "\"pos_pair\"", ":", "torch", ".", "as_tensor", "(", "pos_pair", ")", ",", "\n", "\"neg_pair\"", ":", "torch", ".", "as_tensor", "(", "neg_pair", ")", ",", "\n", "}", "\n", "\n", "", "elif", "len", "(", "case", ")", "==", "1", ":", "\n", "            ", "words", "=", "case", "[", "0", "]", ".", "split", "(", ")", "\n", "tokens", "=", "self", ".", "__tokenize_sequence", "(", "words", ")", "\n", "input_ids", "=", "self", ".", "concat_and_convert_tokens_to_input_ids", "(", "tokens", ")", "\n", "mask_label", ",", "input_ids", "=", "self", ".", "__masking", "(", "input_ids", ")", "\n", "assert", "len", "(", "mask_label", ")", "==", "len", "(", "input_ids", ")", "\n", "return", "{", "\n", "\"input_ids\"", ":", "torch", ".", "as_tensor", "(", "input_ids", ")", ",", "\n", "\"sequence_length\"", ":", "len", "(", "input_ids", ")", ",", "\n", "\"mlm_label\"", ":", "torch", ".", "as_tensor", "(", "mask_label", ")", "\n", "}", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unexpected example length %d\"", ",", "len", "(", "case", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.encode_srl_case": [[326, 369], ["enumerate", "processor.Processor.tokenizer.convert_tokens_to_ids", "subword_indices.insert", "subword_indices.append", "subword_indices.append", "processor.Processor.insert", "processor.Processor.append", "processor.Processor.append", "processor.Processor.tokenizer.tokenize", "tokens.extend", "subword_indices.extend", "len", "len", "len", "len", "len", "len", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "range", "len", "len", "len"], "methods", ["None"], ["", "", "def", "encode_srl_case", "(", "self", ",", "case", ")", ":", "\n", "        ", "pred_idx", ",", "words", ",", "labels", "=", "case", "\n", "\n", "subword_indices", "=", "[", "]", "\n", "tokens", "=", "[", "]", "\n", "word_idx", "=", "2", "\n", "for", "idx", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "            ", "tokenized_words", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "word", ")", "\n", "tokenized_words", "=", "[", "t", "for", "t", "in", "tokenized_words", "if", "t", "!=", "SPIECE_UNDERLINE", "]", "\n", "if", "len", "(", "tokenized_words", ")", "+", "len", "(", "tokens", ")", ">=", "self", ".", "max_sequence_len", "-", "3", ":", "\n", "                ", "words", "=", "words", "[", ":", "idx", "]", "\n", "break", "\n", "", "tokens", ".", "extend", "(", "tokenized_words", ")", "\n", "subword_indices", ".", "extend", "(", "[", "word_idx", "]", "*", "len", "(", "tokenized_words", ")", ")", "\n", "word_idx", "+=", "1", "\n", "\n", "", "input_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "sequence_length", "=", "len", "(", "words", ")", "+", "2", "\n", "\n", "# add [CLS] and [SEP]", "\n", "subword_indices", ".", "insert", "(", "0", ",", "1", ")", "# [CLS]", "\n", "subword_indices", ".", "append", "(", "subword_indices", "[", "-", "1", "]", "+", "1", ")", "# [SEP]", "\n", "subword_indices", ".", "append", "(", "0", ")", "# [PAD]", "\n", "input_ids", ".", "insert", "(", "0", ",", "self", ".", "tokenizer", ".", "cls_token_id", ")", "# [CLS]", "\n", "input_ids", ".", "append", "(", "self", ".", "tokenizer", ".", "sep_token_id", ")", "# [SEP]", "\n", "input_ids", ".", "append", "(", "self", ".", "tokenizer", ".", "pad_token_id", ")", "# [PAD]", "\n", "\n", "predicate_ids", "=", "[", "2", "if", "_", "==", "pred_idx", "+", "1", "else", "1", "for", "_", "in", "range", "(", "sequence_length", ")", "]", "\n", "labels", "=", "labels", "[", ":", "sequence_length", "-", "2", "]", "\n", "labels", "=", "[", "\"O\"", "]", "+", "labels", "+", "[", "\"O\"", "]", "\n", "labels", "=", "[", "self", ".", "label_vocab", "[", "la", "]", "for", "la", "in", "labels", "]", "\n", "tokenized_sequence_length", "=", "len", "(", "input_ids", ")", "-", "1", "\n", "\n", "assert", "len", "(", "input_ids", ")", "==", "len", "(", "subword_indices", ")", "\n", "assert", "len", "(", "labels", ")", "==", "sequence_length", "==", "len", "(", "predicate_ids", ")", "\n", "\n", "return", "{", "\n", "\"word_ids\"", ":", "torch", ".", "as_tensor", "(", "input_ids", ")", ",", "\n", "\"predicate_ids\"", ":", "torch", ".", "as_tensor", "(", "predicate_ids", ")", ",", "\n", "\"subword_indices\"", ":", "torch", ".", "as_tensor", "(", "subword_indices", ")", ",", "\n", "\"sequence_length\"", ":", "sequence_length", ",", "\n", "\"tokenized_sequence_length\"", ":", "tokenized_sequence_length", ",", "\n", "\"label\"", ":", "torch", ".", "as_tensor", "(", "labels", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.csrl_collate_fn": [[371, 419], ["torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.as_tensor", "torch.as_tensor", "torch.nn.utils.rnn.pad_sequence", "torch.as_tensor", "torch.nn.utils.rnn.pad_sequence", "processor.Processor.encode_csrl_case", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.encode_csrl_case"], ["", "def", "csrl_collate_fn", "(", "self", ",", "cases", ")", ":", "\n", "        ", "batch_sample", "=", "{", "\n", "\"word_ids\"", ":", "[", "]", ",", "\n", "\"predicate_ids\"", ":", "[", "]", ",", "\n", "\"turn_ids\"", ":", "[", "]", ",", "\n", "\"speaker_role_ids\"", ":", "[", "]", ",", "\n", "\"subword_indices\"", ":", "[", "]", ",", "\n", "\"sequence_length\"", ":", "[", "]", ",", "\n", "\"tokenized_sequence_length\"", ":", "[", "]", ",", "\n", "\"dialogue_indices\"", ":", "[", "]", ",", "\n", "\"utterance_num\"", ":", "[", "]", ",", "\n", "\"label\"", ":", "[", "]", "\n", "}", "\n", "# max_subword_index = 0", "\n", "for", "case", "in", "cases", ":", "\n", "            ", "encoded_csrl_example", "=", "self", ".", "encode_csrl_case", "(", "case", ")", "\n", "batch_sample", "[", "\"word_ids\"", "]", ".", "append", "(", "encoded_csrl_example", "[", "\"word_ids\"", "]", ")", "\n", "batch_sample", "[", "\"predicate_ids\"", "]", ".", "append", "(", "encoded_csrl_example", "[", "\"predicate_ids\"", "]", ")", "\n", "batch_sample", "[", "\"turn_ids\"", "]", ".", "append", "(", "encoded_csrl_example", "[", "\"turn_ids\"", "]", ")", "\n", "batch_sample", "[", "\"speaker_role_ids\"", "]", ".", "append", "(", "encoded_csrl_example", "[", "\"speaker_role_ids\"", "]", ")", "\n", "batch_sample", "[", "\"subword_indices\"", "]", ".", "append", "(", "encoded_csrl_example", "[", "\"subword_indices\"", "]", ")", "\n", "# max_subword_index = max_subword_index if max_subword_index >= encoded_csrl_example[\"subword_indices\"][", "\n", "#     -1] else encoded_csrl_example[\"subword_indices\"][-1]", "\n", "batch_sample", "[", "\"sequence_length\"", "]", ".", "append", "(", "encoded_csrl_example", "[", "\"sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"tokenized_sequence_length\"", "]", ".", "append", "(", "encoded_csrl_example", "[", "\"tokenized_sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"dialogue_indices\"", "]", ".", "append", "(", "encoded_csrl_example", "[", "\"dialogue_indices\"", "]", ")", "\n", "batch_sample", "[", "\"utterance_num\"", "]", ".", "append", "(", "encoded_csrl_example", "[", "\"utterance_num\"", "]", ")", "\n", "batch_sample", "[", "\"label\"", "]", ".", "append", "(", "encoded_csrl_example", "[", "\"label\"", "]", ")", "\n", "\n", "# for x in batch_sample[\"subword_indices\"]:", "\n", "#     x[-1] = max_subword_index", "\n", "\n", "", "batch_sample", "[", "\"word_ids\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"word_ids\"", "]", ",", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "self", ".", "pad_token_id", ")", "\n", "batch_sample", "[", "\"predicate_ids\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"predicate_ids\"", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "batch_sample", "[", "\"turn_ids\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"turn_ids\"", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "batch_sample", "[", "\"speaker_role_ids\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"speaker_role_ids\"", "]", ",", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "0", ")", "\n", "batch_sample", "[", "\"subword_indices\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"subword_indices\"", "]", ",", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "0", ")", "\n", "batch_sample", "[", "\"sequence_length\"", "]", "=", "torch", ".", "as_tensor", "(", "batch_sample", "[", "\"sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"tokenized_sequence_length\"", "]", "=", "torch", ".", "as_tensor", "(", "batch_sample", "[", "\"tokenized_sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"dialogue_indices\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"dialogue_indices\"", "]", ",", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "0", ")", "\n", "batch_sample", "[", "\"utterance_num\"", "]", "=", "torch", ".", "as_tensor", "(", "batch_sample", "[", "\"utterance_num\"", "]", ")", "\n", "batch_sample", "[", "\"label\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"label\"", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "-", "100", ")", "\n", "\n", "return", "batch_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.srl_collate_fn": [[420, 449], ["torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.as_tensor", "torch.as_tensor", "torch.nn.utils.rnn.pad_sequence", "processor.Processor.encode_srl_case", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.encode_srl_case"], ["", "def", "srl_collate_fn", "(", "self", ",", "cases", ")", ":", "\n", "        ", "batch_sample", "=", "{", "\n", "\"word_ids\"", ":", "[", "]", ",", "\n", "\"predicate_ids\"", ":", "[", "]", ",", "\n", "\"subword_indices\"", ":", "[", "]", ",", "\n", "\"sequence_length\"", ":", "[", "]", ",", "\n", "\"tokenized_sequence_length\"", ":", "[", "]", ",", "\n", "\"label\"", ":", "[", "]", "\n", "}", "\n", "\n", "for", "case", "in", "cases", ":", "\n", "            ", "encoded_srl_example", "=", "self", ".", "encode_srl_case", "(", "case", ")", "\n", "batch_sample", "[", "\"word_ids\"", "]", ".", "append", "(", "encoded_srl_example", "[", "\"word_ids\"", "]", ")", "\n", "batch_sample", "[", "\"subword_indices\"", "]", ".", "append", "(", "encoded_srl_example", "[", "\"subword_indices\"", "]", ")", "\n", "batch_sample", "[", "\"predicate_ids\"", "]", ".", "append", "(", "encoded_srl_example", "[", "\"predicate_ids\"", "]", ")", "\n", "batch_sample", "[", "\"sequence_length\"", "]", ".", "append", "(", "encoded_srl_example", "[", "\"sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"tokenized_sequence_length\"", "]", ".", "append", "(", "encoded_srl_example", "[", "\"tokenized_sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"label\"", "]", ".", "append", "(", "encoded_srl_example", "[", "\"label\"", "]", ")", "\n", "\n", "", "batch_sample", "[", "\"word_ids\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"word_ids\"", "]", ",", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "self", ".", "pad_token_id", ")", "\n", "batch_sample", "[", "\"subword_indices\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"subword_indices\"", "]", ",", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "0", ")", "\n", "batch_sample", "[", "\"predicate_ids\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"predicate_ids\"", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "batch_sample", "[", "\"sequence_length\"", "]", "=", "torch", ".", "as_tensor", "(", "batch_sample", "[", "\"sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"tokenized_sequence_length\"", "]", "=", "torch", ".", "as_tensor", "(", "batch_sample", "[", "\"tokenized_sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"label\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"label\"", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "-", "100", ")", "\n", "\n", "return", "batch_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.dialog_collate_fn": [[450, 502], ["processor.Processor.encode_dialog_case", "processor.Processor.items", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.as_tensor", "torch.nn.utils.rnn.pad_sequence", "torch.as_tensor", "torch.as_tensor", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.as_tensor", "torch.nn.utils.rnn.pad_sequence", "torch.as_tensor", "torch.as_tensor", "torch.nn.utils.rnn.pad_sequence", "batch_sample[].append"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.encode_dialog_case"], ["", "def", "dialog_collate_fn", "(", "self", ",", "cases", ")", ":", "\n", "        ", "batch_sample", "=", "{", "\n", "\"reorder_input_ids\"", ":", "[", "]", ",", "\n", "\"reorder_subword_indices\"", ":", "[", "]", ",", "\n", "\"reorder_dialogue_indices\"", ":", "[", "]", ",", "\n", "\"reorder_utterance_num\"", ":", "[", "]", ",", "\n", "\"reorder_label\"", ":", "[", "]", ",", "\n", "\"reorder_sequence_length\"", ":", "[", "]", ",", "\n", "\"reorder_tokenized_sequence_length\"", ":", "[", "]", ",", "\n", "\"reorder_position_ids\"", ":", "[", "]", ",", "\n", "\"role_input_ids\"", ":", "[", "]", ",", "\n", "\"role_subword_indices\"", ":", "[", "]", ",", "\n", "\"role_dialogue_indices\"", ":", "[", "]", ",", "\n", "\"role_utterance_num\"", ":", "[", "]", ",", "\n", "\"role_label\"", ":", "[", "]", ",", "\n", "\"role_sequence_length\"", ":", "[", "]", ",", "\n", "\"role_tokenized_sequence_length\"", ":", "[", "]", ",", "\n", "\"role_position_ids\"", ":", "[", "]", "\n", "}", "\n", "for", "case", "in", "cases", ":", "\n", "            ", "encoded_dialogue_example", "=", "self", ".", "encode_dialog_case", "(", "case", ")", "\n", "for", "k", ",", "v", "in", "encoded_dialogue_example", ".", "items", "(", ")", ":", "\n", "                ", "batch_sample", "[", "k", "]", ".", "append", "(", "v", ")", "\n", "\n", "", "", "if", "self", ".", "is_reorder", ":", "\n", "            ", "batch_sample", "[", "\"reorder_input_ids\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"reorder_input_ids\"", "]", ",", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "self", ".", "pad_token_id", ")", "\n", "batch_sample", "[", "\"reorder_subword_indices\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"reorder_subword_indices\"", "]", ",", "\n", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "batch_sample", "[", "\"reorder_dialogue_indices\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"reorder_dialogue_indices\"", "]", ",", "\n", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "batch_sample", "[", "\"reorder_utterance_num\"", "]", "=", "torch", ".", "as_tensor", "(", "batch_sample", "[", "\"reorder_utterance_num\"", "]", ")", "\n", "batch_sample", "[", "\"reorder_label\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"reorder_label\"", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "-", "100", ")", "\n", "batch_sample", "[", "\"reorder_sequence_length\"", "]", "=", "torch", ".", "as_tensor", "(", "batch_sample", "[", "\"reorder_sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"reorder_tokenized_sequence_length\"", "]", "=", "torch", ".", "as_tensor", "(", "batch_sample", "[", "\"reorder_tokenized_sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"reorder_position_ids\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"reorder_position_ids\"", "]", ",", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "0", ")", "\n", "", "if", "self", ".", "is_role_detection", ":", "\n", "            ", "batch_sample", "[", "\"role_input_ids\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"role_input_ids\"", "]", ",", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "batch_sample", "[", "\"role_subword_indices\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"role_subword_indices\"", "]", ",", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "0", ")", "\n", "batch_sample", "[", "\"role_dialogue_indices\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"role_dialogue_indices\"", "]", ",", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "0", ")", "\n", "batch_sample", "[", "\"role_utterance_num\"", "]", "=", "torch", ".", "as_tensor", "(", "batch_sample", "[", "\"role_utterance_num\"", "]", ")", "\n", "batch_sample", "[", "\"role_label\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"role_label\"", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "-", "100", ")", "\n", "batch_sample", "[", "\"role_sequence_length\"", "]", "=", "torch", ".", "as_tensor", "(", "batch_sample", "[", "\"role_sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"role_tokenized_sequence_length\"", "]", "=", "torch", ".", "as_tensor", "(", "batch_sample", "[", "\"role_tokenized_sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"role_position_ids\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"role_position_ids\"", "]", ",", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "0", ")", "\n", "\n", "", "return", "batch_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.lm_collate_fn": [[503, 554], ["torch.nn.utils.rnn.pad_sequence", "torch.as_tensor", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.as_tensor", "torch.as_tensor", "torch.nn.utils.rnn.pad_sequence", "torch.as_tensor", "torch.nn.utils.rnn.pad_sequence", "processor.Processor.encoder_lm_case", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "processor.Processor.encoder_lm_case", "batch_sample[].append", "batch_sample[].append", "batch_sample[].append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.encoder_lm_case", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.encoder_lm_case"], ["", "def", "lm_collate_fn", "(", "self", ",", "cases", ")", ":", "\n", "        ", "if", "self", ".", "alignment", ":", "\n", "            ", "batch_sample", "=", "{", "\n", "\"input_ids\"", ":", "[", "]", ",", "\n", "\"sequence_length\"", ":", "[", "]", ",", "\n", "\"mlm_label\"", ":", "[", "]", ",", "\n", "\"psi_pair\"", ":", "[", "]", ",", "\n", "\"psi_sequence_length\"", ":", "[", "]", ",", "\n", "\"psi_label\"", ":", "[", "]", "\n", "}", "\n", "for", "case", "in", "cases", ":", "\n", "                ", "encoded_alignment_example", "=", "self", ".", "encoder_lm_case", "(", "case", ")", "\n", "batch_sample", "[", "\"input_ids\"", "]", ".", "append", "(", "encoded_alignment_example", "[", "\"en_zh_ids\"", "]", ")", "\n", "batch_sample", "[", "\"input_ids\"", "]", ".", "append", "(", "encoded_alignment_example", "[", "\"zh_en_ids\"", "]", ")", "\n", "batch_sample", "[", "\"sequence_length\"", "]", ".", "append", "(", "encoded_alignment_example", "[", "\"sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"sequence_length\"", "]", ".", "append", "(", "encoded_alignment_example", "[", "\"sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"mlm_label\"", "]", ".", "append", "(", "encoded_alignment_example", "[", "\"en_zh_label\"", "]", ")", "\n", "batch_sample", "[", "\"mlm_label\"", "]", ".", "append", "(", "encoded_alignment_example", "[", "\"zh_en_label\"", "]", ")", "\n", "batch_sample", "[", "\"psi_pair\"", "]", ".", "append", "(", "encoded_alignment_example", "[", "\"pos_pair\"", "]", ")", "\n", "batch_sample", "[", "\"psi_pair\"", "]", ".", "append", "(", "encoded_alignment_example", "[", "\"neg_pair\"", "]", ")", "\n", "batch_sample", "[", "\"psi_sequence_length\"", "]", ".", "append", "(", "len", "(", "encoded_alignment_example", "[", "\"pos_pair\"", "]", ")", ")", "\n", "batch_sample", "[", "\"psi_sequence_length\"", "]", ".", "append", "(", "len", "(", "encoded_alignment_example", "[", "\"neg_pair\"", "]", ")", ")", "\n", "batch_sample", "[", "\"psi_label\"", "]", ".", "append", "(", "1", ")", "\n", "batch_sample", "[", "\"psi_label\"", "]", ".", "append", "(", "0", ")", "\n", "", "batch_sample", "[", "\"input_ids\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"input_ids\"", "]", ",", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "batch_sample", "[", "\"sequence_length\"", "]", "=", "torch", ".", "as_tensor", "(", "batch_sample", "[", "\"sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"mlm_label\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"mlm_label\"", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "-", "100", ")", "\n", "batch_sample", "[", "\"psi_pair\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"psi_pair\"", "]", ",", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "batch_sample", "[", "\"psi_sequence_length\"", "]", "=", "torch", ".", "as_tensor", "(", "batch_sample", "[", "\"psi_sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"psi_label\"", "]", "=", "torch", ".", "as_tensor", "(", "batch_sample", "[", "\"psi_label\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "batch_sample", "=", "{", "\n", "\"input_ids\"", ":", "[", "]", ",", "\n", "\"sequence_length\"", ":", "[", "]", ",", "\n", "\"mlm_label\"", ":", "[", "]", "\n", "}", "\n", "\n", "for", "case", "in", "cases", ":", "\n", "                ", "encoded_alignment_example", "=", "self", ".", "encoder_lm_case", "(", "case", ")", "\n", "batch_sample", "[", "\"input_ids\"", "]", ".", "append", "(", "encoded_alignment_example", "[", "\"input_ids\"", "]", ")", "\n", "batch_sample", "[", "\"sequence_length\"", "]", ".", "append", "(", "encoded_alignment_example", "[", "\"sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"mlm_label\"", "]", ".", "append", "(", "encoded_alignment_example", "[", "\"mlm_label\"", "]", ")", "\n", "\n", "", "batch_sample", "[", "\"input_ids\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"input_ids\"", "]", ",", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "self", ".", "pad_token_id", ")", "\n", "batch_sample", "[", "\"sequence_length\"", "]", "=", "torch", ".", "as_tensor", "(", "batch_sample", "[", "\"sequence_length\"", "]", ")", "\n", "batch_sample", "[", "\"mlm_label\"", "]", "=", "pad_sequence", "(", "batch_sample", "[", "\"mlm_label\"", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "-", "100", ")", "\n", "\n", "", "return", "batch_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__get_dialogue_indices": [[555, 573], ["dialogue_indices.append", "dialogue_indices.append", "dialogue_indices.append"], "methods", ["None"], ["", "def", "__get_dialogue_indices", "(", "self", ",", "words", ")", ":", "\n", "        ", "utterance_num", "=", "0", "\n", "# Denote [CLS] as the first utterance", "\n", "dialogue_indices", "=", "[", "1", "]", "\n", "utterance_num", "+=", "1", "\n", "dialogue_idx", "=", "1", "\n", "for", "w", "in", "words", ":", "\n", "            ", "if", "w", "in", "[", "\"[human]\"", ",", "\"[agent]\"", ",", "self", ".", "tokenizer", ".", "bos_token", "]", ":", "\n", "                ", "dialogue_idx", "+=", "1", "\n", "dialogue_indices", ".", "append", "(", "dialogue_idx", ")", "\n", "utterance_num", "+=", "1", "\n", "cur_pos", "=", "0", "\n", "", "else", ":", "\n", "                ", "dialogue_indices", ".", "append", "(", "dialogue_idx", ")", "\n", "# add [SEP] as the last utterance", "\n", "", "", "dialogue_indices", ".", "append", "(", "dialogue_idx", "+", "1", ")", "\n", "utterance_num", "+=", "1", "\n", "return", "dialogue_indices", ",", "utterance_num", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__preprocessing": [[574, 593], ["enumerate", "tmp_words.split", "words.extend", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "__preprocessing", "(", "conversations", ",", "is_truncation", ")", ":", "\n", "        ", "words", "=", "[", "]", "\n", "for", "idx", ",", "conv", "in", "enumerate", "(", "conversations", ")", ":", "\n", "            ", "if", "idx", "%", "2", "==", "0", ":", "\n", "                ", "tmp_words", "=", "\"[human] \"", "+", "conv", "\n", "if", "not", "is_truncation", ":", "\n", "                    ", "conversations", "[", "idx", "]", "=", "tmp_words", "\n", "", "", "else", ":", "\n", "                ", "tmp_words", "=", "\"[agent] \"", "+", "conv", "\n", "if", "not", "is_truncation", ":", "\n", "                    ", "conversations", "[", "idx", "]", "=", "tmp_words", "\n", "", "", "split_word", "=", "tmp_words", ".", "split", "(", "\" \"", ")", "\n", "if", "len", "(", "words", ")", "+", "len", "(", "split_word", ")", ">", "500", ":", "\n", "                ", "conversations", "=", "conversations", "[", ":", "idx", "]", "\n", "break", "\n", "", "else", ":", "\n", "                ", "words", ".", "extend", "(", "split_word", ")", "\n", "", "", "return", "conversations", ",", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.Processor.__masking": [[594, 611], ["enumerate", "random.random", "range", "len", "random.choice", "list", "processor.Processor.word_vocab.values"], "methods", ["None"], ["", "def", "__masking", "(", "self", ",", "token_ids", ")", ":", "\n", "        ", "targets", "=", "[", "-", "100", "for", "_", "in", "range", "(", "len", "(", "token_ids", ")", ")", "]", "\n", "\n", "for", "i", ",", "token_id", "in", "enumerate", "(", "token_ids", ")", ":", "\n", "            ", "if", "token_id", "in", "[", "self", ".", "tokenizer", ".", "cls_token_id", ",", "self", ".", "tokenizer", ".", "sep_token_id", "]", ":", "\n", "                ", "continue", "\n", "", "prob", "=", "random", ".", "random", "(", ")", "\n", "if", "prob", "<", "0.15", ":", "\n", "                ", "prob", "/=", "0.15", "\n", "\n", "if", "prob", "<", "0.8", ":", "\n", "                    ", "token_ids", "[", "i", "]", "=", "self", ".", "tokenizer", ".", "mask_token_id", "\n", "", "elif", "prob", "<", "0.9", ":", "\n", "                    ", "token_ids", "[", "i", "]", "=", "random", ".", "choice", "(", "list", "(", "self", ".", "word_vocab", ".", "values", "(", ")", ")", ")", "\n", "\n", "", "targets", "[", "i", "]", "=", "token_id", "\n", "", "", "return", "targets", ",", "token_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.processor.load_vocab": [[11, 20], ["open", "symbol.strip.strip", "len"], "function", ["None"], ["def", "load_vocab", "(", "path", ",", "symbol_idx", "=", "None", ")", ":", "\n", "    ", "if", "symbol_idx", "is", "None", ":", "\n", "        ", "symbol_idx", "=", "{", "}", "\n", "", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fr", ":", "\n", "        ", "for", "symbol", "in", "fr", ":", "\n", "            ", "symbol", "=", "symbol", ".", "strip", "(", ")", "\n", "if", "symbol", "not", "in", "symbol_idx", ":", "\n", "                ", "symbol_idx", "[", "symbol", "]", "=", "len", "(", "symbol_idx", ")", "\n", "", "", "", "return", "symbol_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.scores.scores": [[6, 35], ["utils.calc_f1", "utils.calc_f1", "utils.calc_f1", "open", "print", "print", "print", "json.loads", "gold_all_srl_list.append", "pred_all_srl_list.append", "gold_inter_srl_list.append", "pred_inter_srl_list.append", "gold_inner_srl_list.append", "pred_inner_srl_list.append", "line.strip"], "function", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.calc_f1", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.calc_f1", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.calc_f1"], ["def", "scores", "(", "in_file", ",", "return_res", "=", "False", ")", ":", "\n", "    ", "gold_all_srl_list", "=", "[", "]", "\n", "pred_all_srl_list", "=", "[", "]", "\n", "\n", "gold_inter_srl_list", "=", "[", "]", "\n", "pred_inter_srl_list", "=", "[", "]", "\n", "\n", "gold_inner_srl_list", "=", "[", "]", "\n", "pred_inner_srl_list", "=", "[", "]", "\n", "\n", "with", "open", "(", "in_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fr", ":", "\n", "        ", "for", "line", "in", "fr", ":", "\n", "            ", "jo", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "gold_all_srl_list", ".", "append", "(", "jo", "[", "\"gold_span\"", "]", ")", "\n", "pred_all_srl_list", ".", "append", "(", "jo", "[", "\"pred_span\"", "]", ")", "\n", "gold_inter_srl_list", ".", "append", "(", "jo", "[", "\"gold_inter_span\"", "]", ")", "\n", "pred_inter_srl_list", ".", "append", "(", "jo", "[", "\"pred_inter_span\"", "]", ")", "\n", "gold_inner_srl_list", ".", "append", "(", "jo", "[", "\"gold_inner_span\"", "]", ")", "\n", "pred_inner_srl_list", ".", "append", "(", "jo", "[", "\"pred_inner_span\"", "]", ")", "\n", "\n", "", "", "overall_f1", "=", "calc_f1", "(", "gold_all_srl_list", ",", "pred_all_srl_list", ")", "\n", "inter_f1", "=", "calc_f1", "(", "gold_inter_srl_list", ",", "pred_inter_srl_list", ")", "\n", "inner_f1", "=", "calc_f1", "(", "gold_inner_srl_list", ",", "pred_inner_srl_list", ")", "\n", "if", "return_res", ":", "\n", "        ", "return", "inner_f1", "[", "'F'", "]", ",", "inter_f1", "[", "'F'", "]", ",", "overall_f1", "[", "'F'", "]", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"results on all args: {}\"", ".", "format", "(", "overall_f1", ")", ")", "\n", "print", "(", "\"results on inter args: {}\"", ".", "format", "(", "inter_f1", ")", ")", "\n", "print", "(", "\"results on inner args: {}\"", ".", "format", "(", "inner_f1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.CSRLData.__init__": [[51, 54], ["torch.utils.data.Dataset.__init__", "dataset.load_CSRL_data"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.load_CSRL_data"], ["    ", "def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "        ", "super", "(", "CSRLData", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "instances", "=", "load_CSRL_data", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.CSRLData.__len__": [[55, 57], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "instances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.CSRLData.__getitem__": [[58, 60], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "instances", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.DialogSet.__init__": [[63, 70], ["torch.utils.data.Dataset.__init__", "isinstance", "dataset.DialogSet.instances.extend", "dataset.load_Dialogue_data"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.load_Dialogue_data"], ["    ", "def", "__init__", "(", "self", ",", "paths", ")", ":", "\n", "        ", "super", "(", "DialogSet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "paths", ",", "str", ")", ":", "\n", "            ", "paths", "=", "[", "paths", "]", "\n", "", "self", ".", "instances", "=", "[", "]", "\n", "for", "path", "in", "paths", ":", "\n", "            ", "self", ".", "instances", ".", "extend", "(", "load_Dialogue_data", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.DialogSet.__len__": [[71, 73], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "instances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.DialogSet.__getitem__": [[74, 76], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "instances", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.CrossLingualSet.__init__": [[117, 128], ["torch.utils.data.Dataset.__init__", "type", "dataset.load_paired_data", "dataset.CrossLingualSet.instances.extend", "dataset.load_unpaired_data"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.load_paired_data", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.load_unpaired_data"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "use_aligned_data", "=", "False", ")", ":", "\n", "        ", "super", "(", "CrossLingualSet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "instances", "=", "[", "]", "\n", "if", "type", "(", "path", ")", "==", "str", ":", "\n", "            ", "path", "=", "[", "path", "]", "\n", "", "for", "p", "in", "path", ":", "\n", "            ", "if", "use_aligned_data", ":", "\n", "                ", "self", ".", "instances", ",", "self", ".", "n_gram_hpsi", "=", "load_paired_data", "(", "p", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "instances", ".", "extend", "(", "load_unpaired_data", "(", "p", ")", ")", "\n", "", "", "self", ".", "alignment", "=", "use_aligned_data", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.CrossLingualSet.__len__": [[129, 131], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "instances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.CrossLingualSet.__getitem__": [[132, 171], ["random.randint", "copy.deepcopy", "len", "len", "random.randint", "random.randint", "random.shuffle", "copy.deepcopy", "enumerate", "len", "len", "random.choices", "range", "random.randint", "len", "len", "min", "min", "range", "len", "print", "len", "len", "len", "int", "new_words.append", "int", "random.choice", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "alignment", ":", "\n", "            ", "pos_pair", "=", "self", ".", "instances", "[", "x", "]", "\n", "# we select negative pairs from 1-4 gram similar pairs and perturbed sequence", "\n", "# 0-3 -> 1-4 gram similarity; 4 -> reorder; 5 -> delete words", "\n", "op_flag", "=", "False", "\n", "rd", "=", "random", ".", "randint", "(", "0", ",", "5", ")", "\n", "if", "rd", "==", "4", "and", "len", "(", "pos_pair", "[", "0", "]", ")", ">=", "8", "and", "len", "(", "pos_pair", "[", "1", "]", ")", ">=", "8", ":", "\n", "                ", "negative_pair", "=", "copy", ".", "deepcopy", "(", "pos_pair", ")", "\n", "for", "sent", "in", "negative_pair", ":", "\n", "                    ", "rd_s", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "sent", ")", "-", "2", ")", "\n", "rd_e", "=", "random", ".", "randint", "(", "rd_s", "+", "1", ",", "len", "(", "sent", ")", "-", "1", ")", "\n", "_tmp", "=", "sent", "[", "rd_s", ":", "min", "(", "len", "(", "sent", ")", ",", "rd_e", "+", "1", ")", "]", "\n", "random", ".", "shuffle", "(", "_tmp", ")", "\n", "sent", "[", "rd_s", ":", "min", "(", "len", "(", "sent", ")", ",", "rd_e", "+", "1", ")", "]", "=", "_tmp", "\n", "", "", "elif", "rd", "==", "5", "and", "len", "(", "pos_pair", "[", "0", "]", ")", ">=", "8", "and", "len", "(", "pos_pair", "[", "1", "]", ")", ">=", "8", ":", "\n", "                ", "negative_pair", "=", "copy", ".", "deepcopy", "(", "pos_pair", ")", "\n", "for", "x", ",", "words", "in", "enumerate", "(", "negative_pair", ")", ":", "\n", "                    ", "del_indices", "=", "random", ".", "choices", "(", "range", "(", "0", ",", "len", "(", "words", ")", ")", ",", "k", "=", "int", "(", "0.15", "*", "len", "(", "words", ")", ")", ")", "\n", "new_words", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "words", ")", ")", ":", "\n", "                        ", "if", "i", "in", "del_indices", ":", "\n", "                            ", "continue", "\n", "", "else", ":", "\n", "                            ", "new_words", ".", "append", "(", "words", "[", "i", "]", ")", "\n", "", "", "negative_pair", "[", "x", "]", "=", "new_words", "\n", "", "", "else", ":", "\n", "                ", "op_flag", "=", "True", "\n", "if", "rd", ">=", "4", ":", "\n", "                    ", "rd", "=", "random", ".", "randint", "(", "0", ",", "3", ")", "\n", "", "try", ":", "\n", "                    ", "gram_hpsi", "=", "self", ".", "n_gram_hpsi", "[", "rd", "]", "[", "x", "]", "\n", "negative_pair", "=", "self", ".", "instances", "[", "int", "(", "random", ".", "choice", "(", "gram_hpsi", ")", ")", "]", "\n", "", "except", "IndexError", ":", "\n", "                    ", "print", "(", "\"Index error occurred!\"", ")", "\n", "negative_pair", "=", "pos_pair", "\n", "", "", "return", "pos_pair", ",", "negative_pair", ",", "op_flag", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "instances", "[", "x", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.SRLSet.__init__": [[190, 197], ["torch.utils.data.Dataset.__init__", "dataset.SRLSet.instances.extend", "dataset.load_srl_data"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.load_srl_data"], ["    ", "def", "__init__", "(", "self", ",", "file_paths", ",", "lang", ")", ":", "\n", "        ", "super", "(", "SRLSet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "instances", "=", "[", "]", "\n", "if", "lang", "!=", "'zh+en'", ":", "\n", "            ", "file_paths", "=", "[", "_", "for", "_", "in", "file_paths", "if", "lang", "in", "_", "]", "\n", "", "for", "file_path", "in", "file_paths", ":", "\n", "            ", "self", ".", "instances", ".", "extend", "(", "load_srl_data", "(", "file_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.SRLSet.__getitem__": [[198, 200], ["None"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "instances", "[", "x", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.SRLSet.__len__": [[201, 203], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "instances", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.load_CSRL_data": [[9, 22], ["open", "line.strip().split.strip().split", "sent.split", "label.split.split", "instances.append", "int", "int", "line.strip().split.strip", "pred_idx.split", "turn_ids.split"], "function", ["None"], ["def", "load_CSRL_data", "(", "path", ")", ":", "\n", "    ", "instances", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fr", ":", "\n", "        ", "for", "line", "in", "fr", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"|||\"", ")", "\n", "sent_id", ",", "pred_idx", ",", "sent", ",", "turn_ids", ",", "label", "=", "line", "\n", "pred_idx", "=", "[", "int", "(", "p", ")", "for", "p", "in", "pred_idx", ".", "split", "(", ")", "]", "\n", "words", "=", "sent", ".", "split", "(", ")", "\n", "turn_ids", "=", "[", "int", "(", "_", ")", "for", "_", "in", "turn_ids", ".", "split", "(", ")", "]", "\n", "label", "=", "label", ".", "split", "(", ")", "\n", "instances", ".", "append", "(", "{", "\"sent_id\"", ":", "sent_id", ",", "\"pred_idx\"", ":", "pred_idx", ",", "\"words\"", ":", "words", ",", "\"turn_ids\"", ":", "turn_ids", ",", "\n", "\"label\"", ":", "label", "}", ")", "\n", "", "", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.load_Dialogue_data": [[24, 48], ["os.path.exists", "pickle.load", "open", "open", "print", "pickle.dump", "json.loads", "range", "instances.append", "open", "line.strip", "len", "len", "len", "new_conv.append", "len", "len", "len", "_.strip"], "function", ["None"], ["", "def", "load_Dialogue_data", "(", "path", ")", ":", "\n", "    ", "cache_ckpt_path", "=", "path", "+", "\".ckpt\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "cache_ckpt_path", ")", ":", "\n", "        ", "return", "pickle", ".", "load", "(", "open", "(", "cache_ckpt_path", ",", "\"rb\"", ")", ")", "\n", "", "else", ":", "\n", "        ", "instances", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fr", ":", "\n", "            ", "for", "line", "in", "fr", ":", "\n", "                ", "jo", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "conversations", "=", "jo", "[", "\"conversation\"", "]", "\n", "if", "len", "(", "[", "_", "for", "_", "in", "conversations", "if", "len", "(", "_", ".", "strip", "(", ")", ")", ">", "0", "]", ")", "<=", "2", ":", "\n", "                    ", "continue", "\n", "", "total_len", "=", "0", "\n", "new_conv", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "conversations", ")", ")", ":", "\n", "                    ", "if", "total_len", "+", "len", "(", "conversations", "[", "i", "]", ")", "<=", "400", ":", "\n", "                        ", "new_conv", ".", "append", "(", "conversations", "[", "i", "]", ")", "\n", "total_len", "+=", "len", "(", "conversations", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                        ", "break", "\n", "", "", "instances", ".", "append", "(", "new_conv", ")", "\n", "", "print", "(", "\"There are totally {} dialogues.\"", ".", "format", "(", "len", "(", "instances", ")", ")", ")", "\n", "pickle", ".", "dump", "(", "instances", ",", "open", "(", "cache_ckpt_path", ",", "\"wb\"", ")", ")", "\n", "", "", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.load_unpaired_data": [[78, 91], ["os.path.exists", "pickle.load", "open", "open", "print", "pickle.dump", "line.rstrip.rstrip", "instances.append", "open", "len"], "function", ["None"], ["", "", "def", "load_unpaired_data", "(", "path", ")", ":", "\n", "    ", "cache_ckpt_path", "=", "path", "+", "\".ckpt\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "cache_ckpt_path", ")", ":", "\n", "        ", "return", "pickle", ".", "load", "(", "open", "(", "cache_ckpt_path", ",", "\"rb\"", ")", ")", "\n", "", "else", ":", "\n", "        ", "instances", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fr", ":", "\n", "            ", "for", "line", "in", "fr", ":", "\n", "                ", "line", "=", "line", ".", "rstrip", "(", "\"\\n\"", ")", "\n", "instances", ".", "append", "(", "[", "line", "]", ")", "\n", "", "print", "(", "\"There are totally {} cross-lingual sentences.\"", ".", "format", "(", "len", "(", "instances", ")", ")", ")", "\n", "pickle", ".", "dump", "(", "instances", ",", "open", "(", "cache_ckpt_path", ",", "\"wb\"", ")", ")", "\n", "", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.load_paired_data": [[93, 114], ["os.path.exists", "pickle.load", "open", "open", "print", "pickle.dump", "json.loads", "sentences.append", "one_gram_hpsi.append", "two_gram_hpsi.append", "three_gram_hpsi.append", "four_gram_hpsi.append", "open", "line.strip", "len", "en_sent.split", "zh_sent.split"], "function", ["None"], ["", "", "def", "load_paired_data", "(", "path", ")", ":", "\n", "    ", "cache_ckpt_path", "=", "path", "+", "\".ckpt\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "cache_ckpt_path", ")", ":", "\n", "        ", "cache", "=", "pickle", ".", "load", "(", "open", "(", "cache_ckpt_path", ",", "\"rb\"", ")", ")", "\n", "return", "cache", "[", "\"sentences\"", "]", ",", "cache", "[", "\"grams\"", "]", "\n", "", "else", ":", "\n", "        ", "sentences", "=", "[", "]", "\n", "one_gram_hpsi", ",", "two_gram_hpsi", ",", "three_gram_hpsi", ",", "four_gram_hpsi", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fr", ":", "\n", "            ", "for", "line", "in", "fr", ":", "\n", "                ", "jo", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "en_sent", ",", "zh_sent", "=", "jo", "[", "\"pair\"", "]", "\n", "sentences", ".", "append", "(", "[", "en_sent", ".", "split", "(", "\" \"", ")", ",", "zh_sent", ".", "split", "(", ")", "]", ")", "\n", "one_gram_hpsi", ".", "append", "(", "jo", "[", "\"1_gram\"", "]", "[", "'en'", "]", "+", "jo", "[", "\"1_gram\"", "]", "[", "'zh'", "]", ")", "\n", "two_gram_hpsi", ".", "append", "(", "jo", "[", "\"2_gram\"", "]", "[", "'en'", "]", "+", "jo", "[", "\"1_gram\"", "]", "[", "'zh'", "]", ")", "\n", "three_gram_hpsi", ".", "append", "(", "jo", "[", "\"3_gram\"", "]", "[", "'en'", "]", "+", "jo", "[", "\"1_gram\"", "]", "[", "'zh'", "]", ")", "\n", "four_gram_hpsi", ".", "append", "(", "jo", "[", "\"4_gram\"", "]", "[", "'en'", "]", "+", "jo", "[", "\"1_gram\"", "]", "[", "'zh'", "]", ")", "\n", "", "print", "(", "\"There are totally {} cross-lingual pairs.\"", ".", "format", "(", "len", "(", "sentences", ")", ")", ")", "\n", "pickle", ".", "dump", "(", "{", "\"sentences\"", ":", "sentences", ",", "\"grams\"", ":", "[", "\n", "one_gram_hpsi", ",", "two_gram_hpsi", ",", "three_gram_hpsi", ",", "four_gram_hpsi", "]", "}", ",", "open", "(", "cache_ckpt_path", ",", "\"wb\"", ")", ")", "\n", "return", "sentences", ",", "[", "one_gram_hpsi", ",", "two_gram_hpsi", ",", "three_gram_hpsi", ",", "four_gram_hpsi", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.dataset.load_srl_data": [[173, 187], ["os.path.exists", "pickle.load", "open", "open", "print", "pickle.dump", "line.strip().split.strip().split", "instances.append", "open", "int", "line[].split", "line[].split", "len", "line.strip().split.strip"], "function", ["None"], ["", "", "", "def", "load_srl_data", "(", "path", ")", ":", "\n", "    ", "cpkt_cache_file", "=", "path", "+", "\".ckpt\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "cpkt_cache_file", ")", ":", "\n", "        ", "return", "pickle", ".", "load", "(", "open", "(", "cpkt_cache_file", ",", "\"rb\"", ")", ")", "\n", "", "else", ":", "\n", "        ", "instances", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fr", ":", "\n", "            ", "for", "line", "in", "fr", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"|||\"", ")", "\n", "pred", ",", "words", ",", "labels", "=", "int", "(", "line", "[", "0", "]", ")", ",", "line", "[", "1", "]", ".", "split", "(", "\" \"", ")", ",", "line", "[", "2", "]", ".", "split", "(", "\" \"", ")", "\n", "instances", ".", "append", "(", "(", "pred", ",", "words", ",", "labels", ")", ")", "\n", "", "print", "(", "\"There are totally {} standard SRL instances in file {}.\"", ".", "format", "(", "len", "(", "instances", ")", ",", "path", ")", ")", "\n", "pickle", ".", "dump", "(", "instances", ",", "open", "(", "path", "+", "\".ckpt\"", ",", "\"wb\"", ")", ")", "\n", "", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.fine_print_res": [[11, 82], ["range", "len", "sep_symbol.join", "len", "len", "sep_symbol.join", "role_idx[].append", "len", "utils.is_include_multi_mentions", "range", "range", "range"], "function", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.is_include_multi_mentions"], ["def", "fine_print_res", "(", "words", ",", "labels", ",", "reverse_mapping", "=", "None", ")", ":", "\n", "    ", "role_idx", "=", "{", "}", "\n", "for", "_", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "        ", "label", "=", "labels", "[", "_", "]", "\n", "if", "label", "[", "0", "]", "==", "\"B\"", "or", "label", "[", "0", "]", "==", "\"I\"", "or", "label", "[", "0", "]", "==", "\"V\"", ":", "\n", "            ", "if", "label", "[", "0", "]", "==", "\"V\"", ":", "\n", "                ", "role", "=", "\"V\"", "\n", "", "else", ":", "\n", "                ", "role", "=", "label", "[", "2", ":", "]", "\n", "", "if", "role", "in", "role_idx", ":", "\n", "                ", "role_idx", "[", "role", "]", ".", "append", "(", "_", ")", "\n", "", "else", ":", "\n", "                ", "role_idx", "[", "role", "]", "=", "[", "_", "]", "\n", "\n", "# make sure that the role idx list is in the order", "\n", "", "", "", "for", "role", "in", "role_idx", ":", "\n", "        ", "l", "=", "role_idx", "[", "role", "]", "\n", "if", "len", "(", "l", ")", ">", "0", ":", "\n", "            ", "fi", "=", "l", "[", "0", "]", "\n", "li", "=", "l", "[", "-", "1", "]", "\n", "if", "li", "-", "fi", "+", "1", "!=", "len", "(", "l", ")", ":", "\n", "# we need to make sure to select the first occurred span", "\n", "                ", "if", "role", "!=", "\"V\"", ":", "\n", "                    ", "new_fi", ",", "new_li", "=", "is_include_multi_mentions", "(", "labels", ",", "fi", ",", "li", ")", "\n", "fi", "=", "new_fi", "\n", "li", "=", "new_li", "\n", "\n", "", "l", "=", "[", "t", "for", "t", "in", "range", "(", "fi", ",", "li", "+", "1", ")", "]", "\n", "role_idx", "[", "role", "]", "=", "l", "\n", "\n", "", "", "", "if", "reverse_mapping", "is", "not", "None", ":", "\n", "        ", "for", "role", "in", "role_idx", ":", "\n", "            ", "input_left", "=", "reverse_mapping", "[", "role_idx", "[", "role", "]", "[", "0", "]", "]", "\n", "input_right", "=", "reverse_mapping", "[", "role_idx", "[", "role", "]", "[", "-", "1", "]", "]", "+", "1", "\n", "role_idx", "[", "role", "]", "=", "[", "_", "for", "_", "in", "range", "(", "input_left", ",", "input_right", ")", "]", "\n", "\n", "", "", "sep_symbol", "=", "\" \"", "\n", "all_role_spans", "=", "{", "}", "\n", "inner_role_spans", "=", "{", "}", "\n", "inter_role_spans", "=", "{", "}", "\n", "for", "key", "in", "role_idx", ":", "\n", "        ", "all_role_spans", "[", "key", "]", "=", "sep_symbol", ".", "join", "(", "[", "words", "[", "id", "]", "for", "id", "in", "role_idx", "[", "key", "]", "]", ")", "\n", "\n", "", "if", "\"V\"", "not", "in", "role_idx", "or", "len", "(", "role_idx", "[", "\"V\"", "]", ")", "==", "0", ":", "\n", "        ", "inner_role_spans", "=", "all_role_spans", "\n", "inter_role_spans", "=", "all_role_spans", "\n", "", "else", ":", "\n", "        ", "pred_idx", "=", "role_idx", "[", "\"V\"", "]", "[", "0", "]", "\n", "for", "key", "in", "role_idx", ":", "\n", "            ", "val", "=", "sep_symbol", ".", "join", "(", "[", "words", "[", "id", "]", "for", "id", "in", "role_idx", "[", "key", "]", "]", ")", "\n", "if", "key", "==", "\"V\"", ":", "\n", "                ", "inner_role_spans", "[", "key", "]", "=", "val", "\n", "inter_role_spans", "[", "key", "]", "=", "val", "\n", "continue", "\n", "", "tmp", "=", "role_idx", "[", "key", "]", "\n", "left_idx", "=", "tmp", "[", "0", "]", "\n", "right_idx", "=", "tmp", "[", "-", "1", "]", "\n", "if", "left_idx", ">", "pred_idx", ":", "\n", "                ", "inner_role_spans", "[", "key", "]", "=", "val", "\n", "", "elif", "right_idx", "<", "pred_idx", ":", "\n", "                ", "found_turn_break", "=", "False", "\n", "for", "_", "in", "range", "(", "right_idx", "+", "1", ",", "pred_idx", ")", ":", "\n", "                    ", "if", "words", "[", "_", "]", "==", "\"[human]\"", "or", "words", "[", "_", "]", "==", "\"[agent]\"", ":", "\n", "                        ", "found_turn_break", "=", "True", "\n", "break", "\n", "", "", "if", "found_turn_break", ":", "\n", "                    ", "inter_role_spans", "[", "key", "]", "=", "val", "\n", "", "else", ":", "\n", "                    ", "inner_role_spans", "[", "key", "]", "=", "val", "\n", "\n", "", "", "", "", "return", "all_role_spans", ",", "inner_role_spans", ",", "inter_role_spans", ",", "role_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.is_include_multi_mentions": [[84, 99], ["range"], "function", ["None"], ["", "def", "is_include_multi_mentions", "(", "labels", ",", "from_idx", ",", "to_idx", ")", ":", "\n", "    ", "is_find_mentions", "=", "False", "\n", "new_from_idx", "=", "-", "1", "\n", "new_to_idx", "=", "-", "1", "\n", "for", "_", "in", "range", "(", "from_idx", ",", "to_idx", "+", "1", ")", ":", "\n", "        ", "if", "labels", "[", "_", "]", "[", "0", "]", "==", "\"B\"", ":", "\n", "            ", "if", "not", "is_find_mentions", ":", "\n", "                ", "is_find_mentions", "=", "True", "\n", "new_from_idx", "=", "_", "\n", "new_to_idx", "=", "_", "\n", "", "else", ":", "\n", "                ", "return", "new_from_idx", ",", "new_to_idx", "\n", "", "", "elif", "labels", "[", "_", "]", "[", "0", "]", "==", "\"I\"", ":", "\n", "            ", "new_to_idx", "=", "_", "\n", "", "", "return", "from_idx", ",", "to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.update_counts_intersect": [[101, 114], ["collections.Counter", "collections.Counter", "collections.Counter.items", "collections.Counter.split", "collections.Counter.split", "min"], "function", ["None"], ["", "def", "update_counts_intersect", "(", "v1", ",", "v2", ",", "is_token_level", ")", ":", "\n", "    ", "if", "v1", "==", "''", "or", "v2", "==", "''", ":", "\n", "        ", "return", "0", "\n", "", "if", "is_token_level", ":", "\n", "        ", "v1", "=", "Counter", "(", "v1", ".", "split", "(", ")", ")", "\n", "v2", "=", "Counter", "(", "v2", ".", "split", "(", ")", ")", "\n", "res", "=", "0", "\n", "for", "k", ",", "cnt1", "in", "v1", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "in", "v2", ":", "\n", "                ", "res", "+=", "min", "(", "cnt1", ",", "v2", "[", "k", "]", ")", "\n", "", "", "return", "res", "\n", "", "else", ":", "\n", "        ", "return", "v1", "==", "v2", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.update_counts_denominator": [[116, 123], ["pas.items", "len", "v.split"], "function", ["None"], ["", "", "def", "update_counts_denominator", "(", "conv", ",", "is_token_level", ")", ":", "\n", "    ", "counts", "=", "0", "\n", "for", "pas", "in", "conv", ":", "\n", "        ", "for", "k", ",", "v", "in", "pas", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "!=", "'V'", ":", "# don't count \"pred\" for each PA structure", "\n", "                ", "counts", "+=", "len", "(", "v", ".", "split", "(", ")", ")", "if", "is_token_level", "else", "1", "\n", "", "", "", "return", "counts", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.update_counts": [[127, 147], ["utils.update_counts_denominator", "utils.update_counts_denominator", "zip", "ref_pas.items", "prd_pas.get", "utils.update_counts_intersect", "ref_pas.items", "prd_pas.get", "utils.update_counts_intersect"], "function", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.update_counts_denominator", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.update_counts_denominator", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.update_counts_intersect", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.update_counts_intersect"], ["", "def", "update_counts", "(", "ref_conv", ",", "prd_conv", ",", "counts", ",", "is_sync", ",", "is_token_level", ")", ":", "\n", "    ", "counts", "[", "1", "]", "+=", "update_counts_denominator", "(", "ref_conv", ",", "is_token_level", ")", "\n", "counts", "[", "2", "]", "+=", "update_counts_denominator", "(", "prd_conv", ",", "is_token_level", ")", "\n", "if", "is_sync", ":", "\n", "        ", "for", "ref_pas", ",", "prd_pas", "in", "zip", "(", "ref_conv", ",", "prd_conv", ")", ":", "\n", "            ", "for", "k", ",", "v1", "in", "ref_pas", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", "==", "'V'", ":", "\n", "                    ", "continue", "\n", "", "v2", "=", "prd_pas", ".", "get", "(", "k", ",", "''", ")", "\n", "counts", "[", "0", "]", "+=", "update_counts_intersect", "(", "v1", ",", "v2", ",", "is_token_level", ")", "\n", "", "", "", "else", ":", "\n", "        ", "for", "ref_pas", "in", "ref_conv", ":", "\n", "            ", "for", "prd_pas", "in", "prd_conv", ":", "\n", "                ", "if", "prd_pas", "[", "'V'", "]", "==", "ref_pas", "[", "'V'", "]", ":", "\n", "                    ", "for", "k", ",", "v1", "in", "ref_pas", ".", "items", "(", ")", ":", "\n", "                        ", "if", "k", "==", "'V'", ":", "\n", "                            ", "continue", "\n", "", "v2", "=", "prd_pas", ".", "get", "(", "k", ",", "''", ")", "\n", "counts", "[", "0", "]", "+=", "update_counts_intersect", "(", "v1", ",", "v2", ",", "is_token_level", ")", "\n", "", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.calc_f1": [[149, 156], ["utils.update_counts"], "function", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.update_counts"], ["", "", "", "", "", "def", "calc_f1", "(", "ref", ",", "prd", ",", "is_sync", "=", "True", ",", "is_token_level", "=", "False", ")", ":", "\n", "    ", "counts", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "update_counts", "(", "ref", ",", "prd", ",", "counts", ",", "is_sync", ",", "is_token_level", ")", "\n", "p", "=", "0.0", "if", "counts", "[", "2", "]", "==", "0", "else", "counts", "[", "0", "]", "/", "counts", "[", "2", "]", "\n", "r", "=", "0.0", "if", "counts", "[", "1", "]", "==", "0", "else", "counts", "[", "0", "]", "/", "counts", "[", "1", "]", "\n", "f", "=", "0.0", "if", "p", "==", "0.0", "or", "r", "==", "0.0", "else", "2", "*", "p", "*", "r", "/", "(", "p", "+", "r", ")", "\n", "return", "{", "'P'", ":", "p", ",", "'R'", ":", "r", ",", "'F'", ":", "f", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.save_hparams_dict": [[158, 161], ["vars", "json.dump", "open"], "function", ["None"], ["", "def", "save_hparams_dict", "(", "hparams", ",", "saved_path", ")", ":", "\n", "    ", "h_params_dict", "=", "vars", "(", "hparams", ")", "\n", "json", ".", "dump", "(", "h_params_dict", ",", "open", "(", "saved_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", ",", "ensure_ascii", "=", "False", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.str2bool": [[163, 168], ["v.lower", "v.lower"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "v", ".", "lower", "(", ")", "in", "(", "'y'", ",", "'yes'", ",", "'t'", ",", "'true'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'n'", ",", "'no'", ",", "'f'", ",", "'false'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.get_inverse_square_root_schedule_with_warmup": [[170, 186], ["torch.optim.lr_scheduler.LambdaLR", "max"], "function", ["None"], ["", "", "def", "get_inverse_square_root_schedule_with_warmup", "(", "\n", "optimizer", ",", "warmup_steps", ",", "last_epoch", "=", "-", "1", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Create a schedule with linear warmup and then inverse square root decay.\n    Linearly increases learning rate from 0 to 1 over `warmup_steps` training steps.\n    Inverse square root decreases learning rate from 1. to 0. over remaining steps.\n    \"\"\"", "\n", "\n", "def", "lr_lambda", "(", "step", ")", ":", "\n", "        ", "decay_factor", "=", "warmup_steps", "**", "0.5", "\n", "if", "step", "<", "warmup_steps", ":", "\n", "            ", "return", "step", "/", "max", "(", "1", ",", "warmup_steps", ")", "\n", "", "return", "decay_factor", "*", "step", "**", "-", "0.5", "\n", "\n", "", "return", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.get_linear_schedule_with_warmup": [[188, 203], ["torch.optim.lr_scheduler.LambdaLR", "max", "max", "max"], "function", ["None"], ["", "def", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "warmup_steps", ",", "training_steps", ",", "last_epoch", "=", "-", "1", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Create a schedule with a learning rate that decreases linearly after\n    linearly increasing during a warmup period.\n    \"\"\"", "\n", "\n", "def", "lr_lambda", "(", "step", ")", ":", "\n", "        ", "if", "step", "<", "warmup_steps", ":", "\n", "            ", "return", "step", "/", "max", "(", "1", ",", "warmup_steps", ")", "\n", "", "ratio", "=", "(", "training_steps", "-", "step", ")", "/", "max", "(", "1", ",", "training_steps", "-", "warmup_steps", ")", "\n", "return", "max", "(", "ratio", ",", "0", ")", "\n", "\n", "", "return", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.get_cosine_schedule_with_warmup": [[205, 237], ["torch.optim.lr_scheduler.LambdaLR", "max", "float", "float", "float", "float", "max", "max", "math.cos", "float"], "function", ["None"], ["", "def", "get_cosine_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", ":", "int", ",", "num_training_steps", ":", "int", ",", "num_cycles", ":", "float", "=", "0.5", ",", "last_epoch", ":", "int", "=", "-", "1", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Create a schedule with a learning rate that decreases following the values of the cosine function between the\n    initial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n    initial lr set in the optimizer.\n\n    Args:\n        optimizer (:class:`~torch.optim.Optimizer`):\n            The optimizer for which to schedule the learning rate.\n        num_warmup_steps (:obj:`int`):\n            The number of steps for the warmup phase.\n        num_training_steps (:obj:`int`):\n            The total number of training steps.\n        num_cycles (:obj:`float`, `optional`, defaults to 0.5):\n            The number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n            following a half-cosine).\n        last_epoch (:obj:`int`, `optional`, defaults to -1):\n            The index of the last epoch when resuming training.\n\n    Return:\n        :obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n    \"\"\"", "\n", "\n", "def", "lr_lambda", "(", "current_step", ")", ":", "\n", "        ", "if", "current_step", "<", "num_warmup_steps", ":", "\n", "            ", "return", "float", "(", "current_step", ")", "/", "float", "(", "max", "(", "1", ",", "num_warmup_steps", ")", ")", "\n", "", "progress", "=", "float", "(", "current_step", "-", "num_warmup_steps", ")", "/", "float", "(", "max", "(", "1", ",", "num_training_steps", "-", "num_warmup_steps", ")", ")", "\n", "return", "max", "(", "0.0", ",", "0.5", "*", "(", "1.0", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "float", "(", "num_cycles", ")", "*", "2.0", "*", "progress", ")", ")", ")", "\n", "\n", "", "return", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.z_norm": [[239, 243], ["inputs.mean", "inputs.var", "torch.sqrt", "torch.sqrt"], "function", ["None"], ["", "def", "z_norm", "(", "inputs", ",", "epsilon", "=", "1e-9", ")", ":", "\n", "    ", "mean", "=", "inputs", ".", "mean", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "var", "=", "inputs", ".", "var", "(", "0", ",", "unbiased", "=", "False", ",", "keepdim", "=", "True", ")", "\n", "return", "(", "inputs", "-", "mean", ")", "/", "torch", ".", "sqrt", "(", "var", "+", "epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.Embedding": [[245, 250], ["torch.Embedding", "torch.init.normal_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.Embedding"], ["", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.None.utils.load_from_pretrained_weights": [[252, 274], ["pretrained_encoders.split.split", "collections.OrderedDict", "model.load_state_dict", "os.listdir", "os.path.join", "print", "state_dict.items", "name.replace.endswith", "torch.load", "torch.load", "name.replace.replace", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros"], "function", ["None"], ["", "def", "load_from_pretrained_weights", "(", "model", ",", "pretrained_encoders", ")", ":", "\n", "    ", "pretrained_encoders", "=", "pretrained_encoders", ".", "split", "(", "\",\"", ")", "\n", "new_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "pretrained_encoder", "in", "pretrained_encoders", ":", "\n", "        ", "ckpt_dir", "=", "\"checkpoints\"", "+", "os", ".", "path", ".", "sep", "+", "pretrained_encoder", "+", "os", ".", "path", ".", "sep", "+", "\"checkpoints\"", "+", "os", ".", "path", ".", "sep", "+", "pretrained_encoder", "\n", "ckpt_name", "=", "os", ".", "listdir", "(", "ckpt_dir", ")", "\n", "select_name", "=", "ckpt_name", "[", "0", "]", "\n", "for", "name", "in", "ckpt_name", ":", "\n", "            ", "if", "name", ".", "endswith", "(", "\".tmp_end.ckpt\"", ")", ":", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "select_name", "=", "name", "\n", "", "", "ckpt_path", "=", "os", ".", "path", ".", "join", "(", "ckpt_dir", ",", "select_name", ")", "\n", "print", "(", "\"Loading weights from checkpoints - {}\"", ".", "format", "(", "ckpt_path", ")", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "ckpt_path", ",", "map_location", "=", "model", ".", "device", ")", "[", "\"state_dict\"", "]", "\n", "for", "name", ",", "para", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "name", "==", "[", "'turn_decoder.weight'", ",", "'speaker_decoder.weight'", "]", ":", "\n", "                ", "name", "=", "name", ".", "replace", "(", "\"decoder\"", ",", "\"embedding\"", ")", "\n", "para", "=", "torch", ".", "cat", "(", "[", "torch", ".", "zeros", "(", "(", "1", ",", "para", ".", "shape", "[", "-", "1", "]", ")", ",", "device", "=", "model", ".", "device", ")", ",", "para", "]", ",", "dim", "=", "0", ")", "\n", "", "new_state_dict", "[", "name", "]", "=", "para", "\n", "", "", "model", ".", "load_state_dict", "(", "new_state_dict", ",", "strict", "=", "False", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.state_encoder.StateEncoder.__init__": [[7, 26], ["torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.Dropout", "torch.Dropout", "torch.Identity", "torch.Identity", "_linears.append", "_linears.append", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "state_encoder.Swish"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "state_size", ",", "num_layers", ",", "activation", ",", "dropout_rate", ",", "output_size", "=", "768", ")", ":", "\n", "        ", "super", "(", "StateEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "_linears", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "_linears", ".", "append", "(", "nn", ".", "Linear", "(", "input_size", ",", "state_size", ")", ")", "\n", "", "else", ":", "\n", "                ", "_linears", ".", "append", "(", "nn", ".", "Linear", "(", "state_size", ",", "output_size", ")", ")", "\n", "\n", "", "", "self", ".", "linears", "=", "nn", ".", "ModuleList", "(", "_linears", ")", "\n", "\n", "if", "activation", "==", "'identity'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Identity", "(", ")", "\n", "", "elif", "activation", "==", "'relu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", ")", "\n", "", "elif", "activation", "==", "'swish'", ":", "\n", "            ", "self", ".", "activation", "=", "Swish", "(", ")", "\n", "\n", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.state_encoder.StateEncoder.forward": [[27, 33], ["linear", "state_encoder.StateEncoder.activation", "state_encoder.StateEncoder.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "linear", "in", "self", ".", "linears", ":", "\n", "            ", "x", "=", "linear", "(", "x", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.state_encoder.Swish.__init__": [[37, 39], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Swish", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.state_encoder.Swish.forward": [[40, 42], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.sequence_encoder.SequenceEncoder.__init__": [[10, 62], ["torch.Module.__init__", "sequence_encoder.StackedBiLSTM", "sequence_encoder.FullyConnectedBiLSTM", "sequence_encoder.ResidualBiLSTM", "sequence_encoder.AttentiveFullyConnectedBiLSTM", "sequence_encoder.ConnectedMHA"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encoder_type", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "SequenceEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "encoder_type", "==", "'lstm'", ":", "\n", "            ", "self", ".", "sequence_encoder", "=", "StackedBiLSTM", "(", "\n", "kwargs", "[", "'lstm_input_size'", "]", ",", "\n", "kwargs", "[", "'lstm_hidden_size'", "]", ",", "\n", "kwargs", "[", "'lstm_num_layers'", "]", ",", "\n", "kwargs", "[", "'lstm_dropout'", "]", ",", "\n", "kwargs", "[", "'lstm_bidirectional'", "]", ",", "\n", "kwargs", "[", "'pack_sequences'", "]", "\n", ")", "\n", "", "elif", "encoder_type", "==", "'connected_lstm'", ":", "\n", "            ", "self", ".", "sequence_encoder", "=", "FullyConnectedBiLSTM", "(", "\n", "kwargs", "[", "'lstm_input_size'", "]", ",", "\n", "kwargs", "[", "'lstm_hidden_size'", "]", ",", "\n", "kwargs", "[", "'lstm_num_layers'", "]", ",", "\n", "kwargs", "[", "'lstm_dropout'", "]", ",", "\n", "kwargs", "[", "'lstm_bidirectional'", "]", ",", "\n", "kwargs", "[", "'pack_sequences'", "]", "\n", ")", "\n", "", "elif", "encoder_type", "==", "'residual_lstm'", ":", "\n", "            ", "self", ".", "sequence_encoder", "=", "ResidualBiLSTM", "(", "\n", "kwargs", "[", "'lstm_input_size'", "]", ",", "\n", "kwargs", "[", "'lstm_hidden_size'", "]", ",", "\n", "kwargs", "[", "'lstm_num_layers'", "]", ",", "\n", "kwargs", "[", "'lstm_dropout'", "]", ",", "\n", "kwargs", "[", "'lstm_bidirectional'", "]", ",", "\n", "kwargs", "[", "'pack_sequences'", "]", "\n", ")", "\n", "", "elif", "encoder_type", "==", "'lstm+mha'", ":", "\n", "            ", "self", ".", "sequence_encoder", "=", "AttentiveFullyConnectedBiLSTM", "(", "\n", "kwargs", "[", "'lstm_input_size'", "]", ",", "\n", "kwargs", "[", "'lstm_hidden_size'", "]", ",", "\n", "kwargs", "[", "'lstm_num_layers'", "]", ",", "\n", "kwargs", "[", "'lstm_dropout'", "]", ",", "\n", "kwargs", "[", "'lstm_bidirectional'", "]", ",", "\n", "kwargs", "[", "'pack_sequences'", "]", ",", "\n", "kwargs", "[", "'mha_num_layers'", "]", ",", "\n", "kwargs", "[", "'mha_hidden_size'", "]", ",", "\n", "kwargs", "[", "'mha_num_heads'", "]", ",", "\n", "kwargs", "[", "'mha_dropout'", "]", ",", "\n", ")", "\n", "", "elif", "encoder_type", "==", "'connected_mha'", ":", "\n", "            ", "self", ".", "sequence_encoder", "=", "ConnectedMHA", "(", "\n", "kwargs", "[", "'input_size'", "]", ",", "\n", "kwargs", "[", "\"mha_num_layers\"", "]", ",", "\n", "kwargs", "[", "\"mha_num_heads\"", "]", ",", "\n", "kwargs", "[", "\"mha_dropout\"", "]", "\n", ")", "\n", "\n", "", "self", ".", "sequence_state_size", "=", "self", ".", "sequence_encoder", ".", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.sequence_encoder.SequenceEncoder.forward": [[63, 65], ["sequence_encoder.SequenceEncoder.sequence_encoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_sequences", ",", "sequence_lengths", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "sequence_encoder", "(", "input_sequences", ",", "sequence_lengths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.sequence_encoder.ConnectedMHA.__init__": [[68, 100], ["torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "layers.transformer.MultiheadAttention", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "_mhas.append", "_attn_layer_norms.append", "_ffn_layers.append", "_ffn_layer_norms.append"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "input_size", ",", "\n", "mha_num_layers", ",", "\n", "mha_num_heads", ",", "\n", "mha_dropout", "\n", ")", ":", "\n", "        ", "super", "(", "ConnectedMHA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "_mhas", "=", "[", "]", "\n", "_attn_layer_norms", "=", "[", "]", "\n", "_ffn_layers", "=", "[", "]", "\n", "_ffn_layer_norms", "=", "[", "]", "\n", "# input_sequence_dim = input_size", "\n", "for", "i", "in", "range", "(", "mha_num_layers", ")", ":", "\n", "            ", "input_sequence_dim", "=", "2", "**", "i", "*", "input_size", "\n", "mha", "=", "MultiheadAttention", "(", "input_sequence_dim", ",", "mha_num_heads", ",", "dropout", "=", "mha_dropout", ")", "\n", "attn_layer_norm", "=", "nn", ".", "LayerNorm", "(", "2", "*", "input_sequence_dim", ")", "\n", "ffn_layer", "=", "nn", ".", "Linear", "(", "2", "*", "input_sequence_dim", ",", "2", "*", "input_sequence_dim", ")", "\n", "ffn_layer_norm", "=", "nn", ".", "LayerNorm", "(", "2", "*", "input_sequence_dim", ")", "\n", "_mhas", ".", "append", "(", "mha", ")", "\n", "_attn_layer_norms", ".", "append", "(", "attn_layer_norm", ")", "\n", "_ffn_layers", ".", "append", "(", "ffn_layer", ")", "\n", "_ffn_layer_norms", ".", "append", "(", "ffn_layer_norm", ")", "\n", "\n", "", "self", ".", "mhas", "=", "nn", ".", "ModuleList", "(", "_mhas", ")", "\n", "self", ".", "attn_layer_norms", "=", "nn", ".", "ModuleList", "(", "_attn_layer_norms", ")", "\n", "self", ".", "ffn_layers", "=", "nn", ".", "ModuleList", "(", "_ffn_layers", ")", "\n", "self", ".", "ffn_layer_norms", "=", "nn", ".", "ModuleList", "(", "_ffn_layer_norms", ")", "\n", "self", ".", "dropout", "=", "mha_dropout", "\n", "\n", "self", ".", "output_size", "=", "input_size", "*", "2", "**", "mha_num_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.sequence_encoder.ConnectedMHA.forward": [[101, 127], ["torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "zip", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "mha", "torch.dropout", "torch.dropout", "torch.dropout", "al_norm", "ffn", "torch.dropout", "torch.dropout", "torch.dropout", "fl_norm", "torch.arange().expand().to", "torch.arange().expand().to", "torch.arange().expand().to", "torch.arange().expand().to", "torch.arange().expand().to", "torch.arange().expand().to", "torch.arange().expand().to", "torch.arange().expand().to", "torch.arange().expand().to", "ValueError", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sequence_lengths.unsqueeze", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_sequences", ",", "sequence_lengths", "=", "None", ",", "input_mask", "=", "None", ")", ":", "\n", "        ", "batch_size", ",", "max_length", ",", "_", "=", "input_sequences", ".", "shape", "\n", "\n", "if", "input_mask", "is", "None", ":", "\n", "            ", "if", "sequence_lengths", "is", "not", "None", ":", "\n", "                ", "input_mask", "=", "torch", ".", "arange", "(", "max_length", ")", ".", "expand", "(", "batch_size", ",", "max_length", ")", ".", "to", "(", "input_sequences", ".", "device", ")", "\n", "input_mask", "=", "input_mask", ">=", "sequence_lengths", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"One of sequence lengths and input mask should be assigned.\"", ")", "\n", "\n", "", "", "input_sequences", "=", "torch", ".", "transpose", "(", "input_sequences", ",", "0", ",", "1", ")", "\n", "input_mask", "=", "torch", ".", "transpose", "(", "input_mask", ",", "0", ",", "1", ")", "\n", "\n", "for", "mha", ",", "al_norm", ",", "ffn", ",", "fl_norm", "in", "zip", "(", "self", ".", "mhas", ",", "self", ".", "attn_layer_norms", ",", "self", ".", "ffn_layers", ",", "self", ".", "ffn_layer_norms", ")", ":", "\n", "            ", "output_sequences", ",", "_", "=", "mha", "(", "input_sequences", ",", "input_sequences", ",", "input_sequences", ",", "key_padding_mask", "=", "input_mask", ")", "\n", "output_sequences", "=", "F", ".", "dropout", "(", "output_sequences", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "output_sequences", "=", "al_norm", "(", "torch", ".", "cat", "(", "[", "input_sequences", ",", "output_sequences", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "residual", "=", "output_sequences", "\n", "output_sequences", "=", "ffn", "(", "output_sequences", ")", "\n", "output_sequences", "=", "F", ".", "dropout", "(", "output_sequences", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "output_sequences", "=", "fl_norm", "(", "residual", "+", "output_sequences", ")", "\n", "\n", "input_sequences", "=", "output_sequences", "\n", "", "output_sequences", "=", "torch", ".", "transpose", "(", "input_sequences", ",", "0", ",", "1", ")", "\n", "\n", "return", "output_sequences", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.sequence_encoder.StackedBiLSTM.__init__": [[131, 154], ["torch.Module.__init__", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LSTM", "torch.LSTM", "torch.LSTM"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "lstm_input_size", ",", "\n", "lstm_hidden_size", ",", "\n", "lstm_num_layers", ",", "\n", "lstm_dropout", ",", "\n", "lstm_bidirectional", ",", "\n", "pack_sequences", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "pack_sequences", "=", "pack_sequences", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "lstm_input_size", ")", "\n", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "\n", "lstm_input_size", ",", "\n", "lstm_hidden_size", ",", "\n", "num_layers", "=", "lstm_num_layers", ",", "\n", "dropout", "=", "lstm_dropout", ",", "\n", "bidirectional", "=", "lstm_bidirectional", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "self", ".", "output_size", "=", "lstm_hidden_size", "if", "not", "lstm_bidirectional", "else", "2", "*", "lstm_hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.sequence_encoder.StackedBiLSTM.forward": [[155, 180], ["sequence_encoder.StackedBiLSTM.layer_norm", "sequence_encoder.StackedBiLSTM.lstm", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_sequences", ",", "sequence_lengths", "=", "None", ")", ":", "\n", "\n", "        ", "total_length", "=", "input_sequences", ".", "shape", "[", "1", "]", "\n", "input_sequences", "=", "self", ".", "layer_norm", "(", "input_sequences", ")", "\n", "\n", "if", "self", ".", "pack_sequences", ":", "\n", "            ", "packed_input", "=", "pack_padded_sequence", "(", "\n", "input_sequences", ",", "\n", "sequence_lengths", ",", "\n", "batch_first", "=", "True", ",", "\n", "enforce_sorted", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "packed_input", "=", "input_sequences", "\n", "\n", "", "packed_sequence_encodings", ",", "_", "=", "self", ".", "lstm", "(", "packed_input", ")", "\n", "\n", "if", "self", ".", "pack_sequences", ":", "\n", "            ", "sequence_encodings", ",", "_", "=", "pad_packed_sequence", "(", "\n", "packed_sequence_encodings", ",", "\n", "total_length", "=", "total_length", ",", "\n", "batch_first", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "sequence_encodings", "=", "packed_sequence_encodings", "\n", "\n", "", "return", "sequence_encodings", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.sequence_encoder.FullyConnectedBiLSTM.__init__": [[184, 223], ["torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout", "_lstms.append", "_norms.append", "_drops.append"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "lstm_input_size", ",", "\n", "lstm_hidden_size", ",", "\n", "lstm_num_layers", ",", "\n", "lstm_dropout", ",", "\n", "lstm_bidirectional", ",", "\n", "pack_sequences", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "pack_sequences", "=", "pack_sequences", "\n", "\n", "_lstms", "=", "[", "]", "\n", "_norms", "=", "[", "]", "\n", "_drops", "=", "[", "]", "\n", "_layer_input_size", "=", "lstm_input_size", "\n", "for", "_", "in", "range", "(", "lstm_num_layers", ")", ":", "\n", "            ", "lstm", "=", "nn", ".", "LSTM", "(", "\n", "_layer_input_size", ",", "\n", "lstm_hidden_size", ",", "\n", "bidirectional", "=", "lstm_bidirectional", ",", "\n", "batch_first", "=", "True", ")", "\n", "norm", "=", "nn", ".", "LayerNorm", "(", "_layer_input_size", ")", "\n", "drop", "=", "nn", ".", "Dropout", "(", "lstm_dropout", ")", "\n", "\n", "_layer_input_size", "+=", "2", "*", "lstm_hidden_size", "if", "lstm_bidirectional", "else", "lstm_hidden_size", "\n", "_lstms", ".", "append", "(", "lstm", ")", "\n", "_norms", ".", "append", "(", "norm", ")", "\n", "_drops", ".", "append", "(", "drop", ")", "\n", "\n", "", "self", ".", "lstms", "=", "nn", ".", "ModuleList", "(", "_lstms", ")", "\n", "self", ".", "norms", "=", "nn", ".", "ModuleList", "(", "_norms", ")", "\n", "self", ".", "drops", "=", "nn", ".", "ModuleList", "(", "_drops", ")", "\n", "\n", "if", "lstm_bidirectional", ":", "\n", "            ", "self", ".", "output_size", "=", "lstm_input_size", "+", "lstm_num_layers", "*", "(", "2", "*", "lstm_hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "output_size", "=", "lstm_input_size", "+", "lstm_num_layers", "*", "lstm_hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.sequence_encoder.FullyConnectedBiLSTM.forward": [[224, 255], ["zip", "norm", "lstm", "drop", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "sequence_lengths.cpu"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_sequences", ",", "sequence_lengths", "=", "None", ")", ":", "\n", "        ", "total_length", "=", "input_sequences", ".", "shape", "[", "1", "]", "\n", "\n", "for", "lstm", ",", "drop", ",", "norm", "in", "zip", "(", "self", ".", "lstms", ",", "self", ".", "drops", ",", "self", ".", "norms", ")", ":", "\n", "            ", "normalized_input_sequences", "=", "norm", "(", "input_sequences", ")", "\n", "\n", "if", "self", ".", "pack_sequences", ":", "\n", "                ", "packed_input", "=", "pack_padded_sequence", "(", "\n", "normalized_input_sequences", ",", "\n", "sequence_lengths", ".", "cpu", "(", ")", ",", "\n", "batch_first", "=", "True", ",", "\n", "enforce_sorted", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "packed_input", "=", "input_sequences", "\n", "\n", "", "packed_sequence_encodings", ",", "_", "=", "lstm", "(", "packed_input", ")", "\n", "\n", "if", "self", ".", "pack_sequences", ":", "\n", "                ", "sequence_encodings", ",", "_", "=", "pad_packed_sequence", "(", "\n", "packed_sequence_encodings", ",", "\n", "total_length", "=", "total_length", ",", "\n", "batch_first", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "sequence_encodings", "=", "packed_sequence_encodings", "\n", "\n", "", "sequence_encodings", "=", "drop", "(", "sequence_encodings", ")", "\n", "input_sequences", "=", "torch", ".", "cat", "(", "[", "input_sequences", ",", "sequence_encodings", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "output_sequences", "=", "input_sequences", "\n", "\n", "return", "output_sequences", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.sequence_encoder.ResidualBiLSTM.__init__": [[259, 307], ["torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Dropout", "torch.Dropout", "torch.Dropout", "_lstms.append", "_norms.append", "_drops.append", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "lstm_input_size", ",", "\n", "lstm_hidden_size", ",", "\n", "lstm_num_layers", ",", "\n", "lstm_dropout", ",", "\n", "lstm_bidirectional", ",", "\n", "pack_sequences", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "pack_sequences", "=", "pack_sequences", "\n", "if", "lstm_bidirectional", ":", "\n", "            ", "self", ".", "input_projection", "=", "nn", ".", "Linear", "(", "lstm_input_size", ",", "2", "*", "lstm_hidden_size", ")", "\n", "self", ".", "input_norm", "=", "nn", ".", "LayerNorm", "(", "2", "*", "lstm_hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "input_projection", "=", "nn", ".", "Linear", "(", "lstm_input_size", ",", "lstm_hidden_size", ")", "\n", "self", ".", "input_norm", "=", "nn", ".", "LayerNorm", "(", "lstm_hidden_size", ")", "\n", "\n", "", "_lstms", "=", "[", "]", "\n", "_norms", "=", "[", "]", "\n", "_drops", "=", "[", "]", "\n", "_layer_input_size", "=", "2", "*", "lstm_hidden_size", "\n", "for", "i", "in", "range", "(", "lstm_num_layers", ")", ":", "\n", "            ", "lstm", "=", "nn", ".", "LSTM", "(", "\n", "_layer_input_size", ",", "\n", "lstm_hidden_size", ",", "\n", "bidirectional", "=", "lstm_bidirectional", ",", "\n", "batch_first", "=", "True", ")", "\n", "if", "lstm_bidirectional", ":", "\n", "                ", "norm", "=", "nn", ".", "LayerNorm", "(", "2", "*", "lstm_hidden_size", ")", "\n", "", "else", ":", "\n", "                ", "norm", "=", "nn", ".", "LayerNorm", "(", "lstm_hidden_size", ")", "\n", "", "drop", "=", "nn", ".", "Dropout", "(", "lstm_dropout", ")", "\n", "\n", "_layer_input_size", "=", "2", "*", "lstm_hidden_size", "if", "lstm_bidirectional", "else", "lstm_hidden_size", "\n", "_lstms", ".", "append", "(", "lstm", ")", "\n", "_norms", ".", "append", "(", "norm", ")", "\n", "_drops", ".", "append", "(", "drop", ")", "\n", "\n", "", "self", ".", "lstms", "=", "nn", ".", "ModuleList", "(", "_lstms", ")", "\n", "self", ".", "norms", "=", "nn", ".", "ModuleList", "(", "_norms", ")", "\n", "self", ".", "drops", "=", "nn", ".", "ModuleList", "(", "_drops", ")", "\n", "\n", "if", "lstm_bidirectional", ":", "\n", "            ", "self", ".", "output_size", "=", "2", "*", "lstm_hidden_size", "\n", "", "else", ":", "\n", "            ", "self", ".", "output_size", "=", "lstm_hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.sequence_encoder.ResidualBiLSTM.forward": [[308, 340], ["sequence_encoder.ResidualBiLSTM.input_projection", "sequence_encoder.ResidualBiLSTM.input_norm", "zip", "lstm", "norm", "drop", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_sequences", ",", "sequence_lengths", "=", "None", ")", ":", "\n", "\n", "        ", "total_length", "=", "input_sequences", ".", "shape", "[", "1", "]", "\n", "input_sequences", "=", "self", ".", "input_projection", "(", "input_sequences", ")", "\n", "input_sequences", "=", "self", ".", "input_norm", "(", "input_sequences", ")", "\n", "\n", "for", "lstm", ",", "drop", ",", "norm", "in", "zip", "(", "self", ".", "lstms", ",", "self", ".", "drops", ",", "self", ".", "norms", ")", ":", "\n", "            ", "if", "self", ".", "pack_sequences", ":", "\n", "                ", "packed_input", "=", "pack_padded_sequence", "(", "\n", "input_sequences", ",", "\n", "sequence_lengths", ",", "\n", "batch_first", "=", "True", ",", "\n", "enforce_sorted", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "packed_input", "=", "input_sequences", "\n", "\n", "", "packed_sequence_encodings", ",", "_", "=", "lstm", "(", "packed_input", ")", "\n", "\n", "if", "self", ".", "pack_sequences", ":", "\n", "                ", "sequence_encodings", ",", "_", "=", "pad_packed_sequence", "(", "\n", "packed_sequence_encodings", ",", "\n", "total_length", "=", "total_length", ",", "\n", "batch_first", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "sequence_encodings", "=", "packed_sequence_encodings", "\n", "\n", "", "sequence_encodings", "=", "norm", "(", "sequence_encodings", ")", "\n", "sequence_encodings", "=", "sequence_encodings", "+", "input_sequences", "\n", "sequence_encodings", "=", "drop", "(", "sequence_encodings", ")", "\n", "input_sequences", "=", "sequence_encodings", "\n", "\n", "", "return", "sequence_encodings", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.sequence_encoder.AttentiveFullyConnectedBiLSTM.__init__": [[344, 409], ["torch.Module.__init__", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout", "_lstms.append", "_norms.append", "_drops.append", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.MultiheadAttention", "torch.MultiheadAttention", "torch.MultiheadAttention", "_queries.append", "_keys.append", "_values.append", "_mhas.append"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "lstm_input_size", ",", "\n", "lstm_hidden_size", ",", "\n", "lstm_num_layers", ",", "\n", "lstm_dropout", ",", "\n", "lstm_bidirectional", ",", "\n", "pack_sequences", ",", "\n", "mha_num_layers", ",", "\n", "mha_hidden_size", ",", "\n", "mha_num_heads", ",", "\n", "mha_dropout", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "pack_sequences", "=", "pack_sequences", "\n", "self", ".", "input_norm", "=", "nn", ".", "LayerNorm", "(", "lstm_input_size", ")", "\n", "\n", "_lstms", "=", "[", "]", "\n", "_norms", "=", "[", "]", "\n", "_drops", "=", "[", "]", "\n", "_layer_input_size", "=", "lstm_input_size", "\n", "for", "i", "in", "range", "(", "lstm_num_layers", ")", ":", "\n", "            ", "lstm", "=", "nn", ".", "LSTM", "(", "\n", "_layer_input_size", ",", "\n", "lstm_hidden_size", ",", "\n", "bidirectional", "=", "lstm_bidirectional", ",", "\n", "batch_first", "=", "True", ")", "\n", "norm", "=", "nn", ".", "LayerNorm", "(", "2", "*", "lstm_hidden_size", ")", "\n", "drop", "=", "nn", ".", "Dropout", "(", "lstm_dropout", ")", "\n", "\n", "_layer_input_size", "=", "2", "*", "lstm_hidden_size", "if", "lstm_bidirectional", "else", "lstm_hidden_size", "\n", "_lstms", ".", "append", "(", "lstm", ")", "\n", "_norms", ".", "append", "(", "norm", ")", "\n", "_drops", ".", "append", "(", "drop", ")", "\n", "\n", "", "self", ".", "lstms", "=", "nn", ".", "ModuleList", "(", "_lstms", ")", "\n", "self", ".", "norms", "=", "nn", ".", "ModuleList", "(", "_norms", ")", "\n", "self", ".", "drops", "=", "nn", ".", "ModuleList", "(", "_drops", ")", "\n", "\n", "if", "lstm_bidirectional", ":", "\n", "            ", "lstm_output_size", "=", "lstm_input_size", "+", "lstm_num_layers", "*", "(", "2", "*", "lstm_hidden_size", ")", "\n", "", "else", ":", "\n", "            ", "lstm_output_size", "=", "lstm_input_size", "+", "lstm_num_layers", "*", "lstm_hidden_size", "\n", "\n", "", "_queries", "=", "[", "]", "\n", "_keys", "=", "[", "]", "\n", "_values", "=", "[", "]", "\n", "_mhas", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "mha_num_layers", ")", ":", "\n", "            ", "query", "=", "nn", ".", "Linear", "(", "lstm_output_size", ",", "mha_hidden_size", ")", "\n", "key", "=", "nn", ".", "Linear", "(", "lstm_output_size", ",", "mha_hidden_size", ")", "\n", "value", "=", "nn", ".", "Linear", "(", "lstm_output_size", ",", "mha_hidden_size", ")", "\n", "mha", "=", "nn", ".", "MultiheadAttention", "(", "mha_hidden_size", ",", "mha_num_heads", ",", "dropout", "=", "mha_dropout", ")", "\n", "_queries", ".", "append", "(", "query", ")", "\n", "_keys", ".", "append", "(", "key", ")", "\n", "_values", ".", "append", "(", "value", ")", "\n", "_mhas", ".", "append", "(", "mha", ")", "\n", "\n", "", "self", ".", "queries", "=", "nn", ".", "ModuleList", "(", "_queries", ")", "\n", "self", ".", "keys", "=", "nn", ".", "ModuleList", "(", "_keys", ")", "\n", "self", ".", "values", "=", "nn", ".", "ModuleList", "(", "_values", ")", "\n", "self", ".", "mhas", "=", "nn", ".", "ModuleList", "(", "_mhas", ")", "\n", "\n", "self", ".", "output_size", "=", "lstm_output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.sequence_encoder.AttentiveFullyConnectedBiLSTM.forward": [[410, 457], ["sequence_encoder.AttentiveFullyConnectedBiLSTM.input_norm", "zip", "torch.arange().expand().to", "torch.arange().expand().to", "torch.arange().expand().to", "torch.arange().expand().to", "torch.arange().expand().to", "torch.arange().expand().to", "torch.arange().expand().to", "torch.arange().expand().to", "torch.arange().expand().to", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "zip", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "lstm", "drop", "norm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sequence_lengths.unsqueeze", "wq", "wk", "wv", "mha", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_sequences", ",", "sequence_lengths", "=", "None", ")", ":", "\n", "\n", "        ", "total_length", "=", "input_sequences", ".", "shape", "[", "1", "]", "\n", "input_sequences", "=", "self", ".", "input_norm", "(", "input_sequences", ")", "\n", "output_sequences", "=", "input_sequences", "\n", "\n", "for", "lstm", ",", "drop", ",", "norm", "in", "zip", "(", "self", ".", "lstms", ",", "self", ".", "drops", ",", "self", ".", "norms", ")", ":", "\n", "            ", "if", "self", ".", "pack_sequences", ":", "\n", "                ", "packed_input", "=", "pack_padded_sequence", "(", "\n", "input_sequences", ",", "\n", "sequence_lengths", ",", "\n", "batch_first", "=", "True", ",", "\n", "enforce_sorted", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "packed_input", "=", "input_sequences", "\n", "\n", "", "packed_sequence_encodings", ",", "_", "=", "lstm", "(", "packed_input", ")", "\n", "\n", "if", "self", ".", "pack_sequences", ":", "\n", "                ", "sequence_encodings", ",", "_", "=", "pad_packed_sequence", "(", "\n", "packed_sequence_encodings", ",", "\n", "total_length", "=", "total_length", ",", "\n", "batch_first", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "sequence_encodings", "=", "packed_sequence_encodings", "\n", "\n", "", "sequence_encodings", "=", "drop", "(", "sequence_encodings", ")", "\n", "sequence_encodings", "=", "norm", "(", "sequence_encodings", ")", "\n", "input_sequences", "=", "sequence_encodings", "\n", "output_sequences", "=", "torch", ".", "cat", "(", "[", "output_sequences", ",", "sequence_encodings", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "batch_size", "=", "output_sequences", ".", "shape", "[", "0", "]", "\n", "max_length", "=", "output_sequences", ".", "shape", "[", "1", "]", "\n", "input_mask", "=", "torch", ".", "arange", "(", "max_length", ")", ".", "expand", "(", "batch_size", ",", "max_length", ")", ".", "to", "(", "\n", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "input_mask", "=", "input_mask", ">=", "sequence_lengths", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "input_sequences", "=", "torch", ".", "transpose", "(", "output_sequences", ",", "0", ",", "1", ")", "\n", "for", "wq", ",", "wk", ",", "wv", ",", "mha", "in", "zip", "(", "self", ".", "queries", ",", "self", ".", "keys", ",", "self", ".", "values", ",", "self", ".", "mhas", ")", ":", "\n", "            ", "q", "=", "wq", "(", "input_sequences", ")", "\n", "k", "=", "wk", "(", "input_sequences", ")", "\n", "v", "=", "wv", "(", "input_sequences", ")", "\n", "output_sequences", ",", "_", "=", "mha", "(", "q", ",", "k", ",", "v", ",", "key_padding_mask", "=", "input_mask", ")", "\n", "input_sequences", "=", "output_sequences", "\n", "", "output_sequences", "=", "torch", ".", "transpose", "(", "output_sequences", ",", "0", ",", "1", ")", "\n", "\n", "return", "output_sequences", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.lstm_decoder.LSTMDecoder.__init__": [[7, 21], ["torch.Module.__init__", "torch.LSTM", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "num_labels", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"\n        : param input_size:     the number of features in the input X\n        : param hidden_size:    the number of features in the hidden state h\n        : param num_layers:     number of recurrent layers (i.e., 2 means there are\n        :                       2 stacked LSTMs)\n        \"\"\"", "\n", "\n", "super", "(", "LSTMDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "input_size", "=", "input_size", ",", "hidden_size", "=", "hidden_size", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.lstm_decoder.LSTMDecoder.forward": [[22, 36], ["lstm_decoder.LSTMDecoder.lstm", "lstm_decoder.LSTMDecoder.linear", "x_input.unsqueeze", "lstm_out.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_input", ",", "encoder_hidden_states", ")", ":", "\n", "        ", "\"\"\"\n        : param x_input:                    should be 2D (batch_size, input_size)\n        : param encoder_hidden_states:      hidden states\n        : return output, hidden:            output gives all the hidden states in the sequence;\n        :                                   hidden gives the hidden state and cell state for the last\n        :                                   element in the sequence\n\n        \"\"\"", "\n", "\n", "lstm_out", ",", "hidden", ",", "cell", "=", "self", ".", "lstm", "(", "x_input", ".", "unsqueeze", "(", "0", ")", ",", "encoder_hidden_states", ")", "\n", "prediction", "=", "self", ".", "linear", "(", "lstm_out", ".", "squeeze", "(", "0", ")", ")", "\n", "\n", "return", "prediction", ",", "hidden", ",", "cell", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.word_encoder.WordEncoder.__init__": [[9, 27], ["torch.Module.__init__", "transformers.AutoConfig.from_pretrained", "transformers.AutoModel.from_pretrained", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "word_encoder.WordEncoder.language_model.resize_token_embeddings", "word_encoder.WordEncoder.language_model.parameters"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "language_model", "=", "\"xlm-roberta-base\"", ",", "fine_tune", "=", "False", ",", "vocab_size", "=", "None", ",", "word_dropout", "=", "0.4", ",", "\n", "hidden_size", "=", "512", ")", ":", "\n", "        ", "super", "(", "WordEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "lm_config", "=", "AutoConfig", ".", "from_pretrained", "(", "language_model", ",", "output_hidden_states", "=", "True", ")", "\n", "self", ".", "language_model", "=", "AutoModel", ".", "from_pretrained", "(", "language_model", ",", "config", "=", "lm_config", ")", "\n", "if", "vocab_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "language_model", ".", "resize_token_embeddings", "(", "vocab_size", ")", "\n", "\n", "", "if", "not", "fine_tune", ":", "\n", "            ", "for", "parameter", "in", "self", ".", "language_model", ".", "parameters", "(", ")", ":", "\n", "                ", "parameter", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "word_embedding_size", "=", "4", "*", "lm_config", ".", "hidden_size", "\n", "self", ".", "batch_normalization", "=", "nn", ".", "BatchNorm1d", "(", "word_embedding_size", ")", "\n", "self", ".", "projection", "=", "nn", ".", "Linear", "(", "word_embedding_size", ",", "hidden_size", ")", "\n", "self", ".", "word_dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "word_dropout", ")", "\n", "\n", "self", ".", "fine_tune", "=", "fine_tune", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.word_encoder.WordEncoder.forward": [[28, 62], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "word_encoder.WordEncoder.permute", "word_encoder.WordEncoder.batch_normalization", "word_encoder.WordEncoder.permute", "word_encoder.WordEncoder.projection", "word_encoder.WordEncoder.word_dropout", "ValueError", "word_encoder.WordEncoder.language_model", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch_scatter.scatter_mean", "torch.arange().unsqueeze().to", "torch.arange().unsqueeze().to", "torch.arange().unsqueeze().to", "torch.arange().unsqueeze().to", "sequence_lengths.unsqueeze", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "word_encoder.WordEncoder.language_model", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "word_ids", ",", "subword_indices", "=", "None", ",", "sequence_lengths", "=", "None", ",", "position_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", "get_pooled_output", "=", "False", ")", ":", "\n", "        ", "if", "sequence_lengths", "is", "None", "and", "attention_mask", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"One of sequence lengths attention mask should be assigned.\"", ")", "\n", "", "if", "attention_mask", "is", "None", "and", "sequence_lengths", "is", "not", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "arange", "(", "word_ids", ".", "shape", "[", "1", "]", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "\n", "word_ids", ".", "device", ")", "<", "sequence_lengths", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "if", "not", "self", ".", "fine_tune", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "token_embeddings", "=", "self", ".", "language_model", "(", "input_ids", "=", "word_ids", ",", "position_ids", "=", "position_ids", ",", "\n", "attention_mask", "=", "attention_mask", ")", "\n", "", "", "else", ":", "\n", "            ", "token_embeddings", "=", "self", ".", "language_model", "(", "input_ids", "=", "word_ids", ",", "position_ids", "=", "position_ids", ",", "\n", "attention_mask", "=", "attention_mask", ")", "\n", "\n", "", "if", "get_pooled_output", ":", "\n", "            ", "return", "token_embeddings", "[", "1", "]", "\n", "\n", "", "token_embeddings", "=", "torch", ".", "cat", "(", "token_embeddings", "[", "2", "]", "[", "-", "4", ":", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "token_embeddings", "=", "token_embeddings", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "token_embeddings", "=", "self", ".", "batch_normalization", "(", "token_embeddings", ")", "\n", "token_embeddings", "=", "token_embeddings", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "token_embeddings", "=", "self", ".", "projection", "(", "token_embeddings", ")", "\n", "word_embeddings", "=", "token_embeddings", "*", "torch", ".", "sigmoid", "(", "token_embeddings", ")", "\n", "token_embeddings", "=", "self", ".", "word_dropout", "(", "token_embeddings", ")", "\n", "\n", "if", "subword_indices", "is", "not", "None", ":", "\n", "            ", "word_embeddings", "=", "scatter", ".", "scatter_mean", "(", "word_embeddings", ",", "subword_indices", ",", "dim", "=", "1", ")", "\n", "return", "token_embeddings", ",", "word_embeddings", "\n", "", "else", ":", "\n", "            ", "return", "token_embeddings", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.Transformer.__init__": [[10, 16], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "transformer.Transformer.layers.append", "transformer.TransformerLayer"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", "=", "False", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "Transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "TransformerLayer", "(", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", ",", "weights_dropout", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.Transformer.forward": [[17, 23], ["enumerate", "layer"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "kv", "=", "None", ",", "\n", "self_padding_mask", "=", "None", ",", "self_attn_mask", "=", "None", ",", "\n", "external_memories", "=", "None", ",", "external_padding_mask", "=", "None", ")", ":", "\n", "        ", "for", "idx", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", ",", "_", ",", "_", "=", "layer", "(", "x", ",", "kv", ",", "self_padding_mask", ",", "self_attn_mask", ",", "external_memories", ",", "external_padding_mask", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.TransformerLayer.__init__": [[27, 38], ["torch.nn.Module.__init__", "transformer.MultiheadAttention", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "transformer.FeedForwardLayer", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "transformer.MultiheadAttention", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", "=", "False", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "TransformerLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", ")", "\n", "self", ".", "attn_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "ff_layer", "=", "FeedForwardLayer", "(", "embed_dim", ",", "ff_embed_dim", ",", "dropout", ")", "\n", "self", ".", "ff_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "with_external", "=", "with_external", "\n", "self", ".", "dropout", "=", "dropout", "\n", "if", "self", ".", "with_external", ":", "\n", "            ", "self", ".", "external_attn", "=", "MultiheadAttention", "(", "embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", ")", "\n", "self", ".", "external_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.TransformerLayer.forward": [[39, 69], ["torch.dropout", "torch.dropout", "transformer.TransformerLayer.attn_layer_norm", "transformer.TransformerLayer.ff_layer", "torch.dropout", "torch.dropout", "transformer.TransformerLayer.ff_layer_norm", "transformer.TransformerLayer.self_attn", "transformer.TransformerLayer.self_attn", "transformer.TransformerLayer.external_attn", "torch.dropout", "torch.dropout", "transformer.TransformerLayer.external_layer_norm"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "kv", "=", "None", ",", "\n", "self_padding_mask", "=", "None", ",", "self_attn_mask", "=", "None", ",", "\n", "external_memories", "=", "None", ",", "external_padding_mask", "=", "None", ",", "\n", "need_weights", "=", "None", ")", ":", "\n", "# x: seq_len x bsz x embed_dim", "\n", "        ", "residual", "=", "x", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "x", ",", "self_attn", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "key_padding_mask", "=", "self_padding_mask", ",", "\n", "attn_mask", "=", "self_attn_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "", "else", ":", "\n", "            ", "x", ",", "self_attn", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "kv", ",", "value", "=", "kv", ",", "key_padding_mask", "=", "self_padding_mask", ",", "\n", "attn_mask", "=", "self_attn_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "attn_layer_norm", "(", "residual", "+", "x", ")", "\n", "\n", "if", "self", ".", "with_external", ":", "\n", "            ", "residual", "=", "x", "\n", "x", ",", "external_attn", "=", "self", ".", "external_attn", "(", "query", "=", "x", ",", "key", "=", "external_memories", ",", "value", "=", "external_memories", ",", "\n", "key_padding_mask", "=", "external_padding_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "external_layer_norm", "(", "residual", "+", "x", ")", "\n", "", "else", ":", "\n", "            ", "external_attn", "=", "None", "\n", "\n", "", "residual", "=", "x", "\n", "x", "=", "self", ".", "ff_layer", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "ff_layer_norm", "(", "residual", "+", "x", ")", "\n", "return", "x", ",", "self_attn", ",", "external_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.FeedForwardLayer.__init__": [[73, 79], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "transformer.FeedForwardLayer.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "ff_embed_dim", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "FeedForwardLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "ff_embed_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "ff_embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.FeedForwardLayer.reset_parameters": [[80, 85], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "fc1", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "fc2", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "fc1", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "fc2", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.FeedForwardLayer.forward": [[86, 91], ["torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "transformer.FeedForwardLayer.fc2", "transformer.FeedForwardLayer.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention.__init__": [[95, 110], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "transformer.MultiheadAttention.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "dropout", "=", "0.", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "MultiheadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "in_proj_weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ",", "embed_dim", ")", ")", "\n", "self", ".", "in_proj_bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ")", ")", "\n", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "weights_dropout", "=", "weights_dropout", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention.reset_parameters": [[111, 116], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "in_proj_weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "out_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "in_proj_bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention.forward": [[117, 200], ["query.size", "transformer.MultiheadAttention.contiguous().view().transpose", "transformer.MultiheadAttention.contiguous().view().transpose", "transformer.MultiheadAttention.contiguous().view().transpose", "transformer.MultiheadAttention.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.dropout.transpose().contiguous().view", "transformer.MultiheadAttention.out_proj", "query.data_ptr", "key.data_ptr", "value.data_ptr", "key.data_ptr", "value.data_ptr", "key.size", "value.size", "transformer.MultiheadAttention.in_proj_qkv", "transformer.MultiheadAttention.transpose", "list", "attn_weights.transpose.transpose.view", "attn_bias.transpose().unsqueeze().unsqueeze.transpose().unsqueeze().unsqueeze.transpose().unsqueeze().unsqueeze", "attn_weights.transpose.transpose.view", "attn_weights.transpose.transpose.masked_fill_", "attn_weights.transpose.transpose.view", "attn_weights.transpose.transpose.masked_fill_", "attn_weights.transpose.transpose.view", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "list", "attn_weights.transpose.transpose.view", "attn_weights.transpose.transpose.transpose", "transformer.MultiheadAttention.in_proj_q", "transformer.MultiheadAttention.in_proj_kv", "transformer.MultiheadAttention.in_proj_q", "transformer.MultiheadAttention.in_proj_k", "transformer.MultiheadAttention.in_proj_v", "transformer.MultiheadAttention.contiguous().view", "transformer.MultiheadAttention.contiguous().view", "transformer.MultiheadAttention.contiguous().view", "attn_weights.transpose.transpose.size", "attn_mask.unsqueeze", "float", "key_padding_mask.transpose().unsqueeze().unsqueeze", "float", "torch.dropout.size", "torch.dropout.transpose().contiguous", "attn_weights.transpose.transpose.max", "attn_bias.transpose().unsqueeze().unsqueeze.transpose().unsqueeze().unsqueeze.transpose().unsqueeze", "transformer.MultiheadAttention.contiguous", "transformer.MultiheadAttention.contiguous", "transformer.MultiheadAttention.contiguous", "key_padding_mask.transpose().unsqueeze", "torch.dropout.transpose", "attn_bias.transpose().unsqueeze().unsqueeze.transpose().unsqueeze().unsqueeze.transpose", "key_padding_mask.transpose"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention.in_proj_qkv", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention.in_proj_kv", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention.in_proj_k", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention.in_proj_v"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "key_padding_mask", "=", "None", ",", "attn_mask", "=", "None", ",", "need_weights", "=", "None", ",", "attn_bias", "=", "None", ")", ":", "\n", "        ", "\"\"\" Input shape: Time x Batch x Channel\n            key_padding_mask: Time x batch\n            attn_mask:  tgt_len x src_len\n        \"\"\"", "\n", "qkv_same", "=", "query", ".", "data_ptr", "(", ")", "==", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "kv_same", "=", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "\n", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "key", ".", "size", "(", ")", "==", "value", ".", "size", "(", ")", "\n", "\n", "if", "qkv_same", ":", "\n", "# self-attention", "\n", "            ", "q", ",", "k", ",", "v", "=", "self", ".", "in_proj_qkv", "(", "query", ")", "\n", "", "elif", "kv_same", ":", "\n", "# encoder-decoder attention", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "k", ",", "v", "=", "self", ".", "in_proj_kv", "(", "key", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "k", "=", "self", ".", "in_proj_k", "(", "key", ")", "\n", "v", "=", "self", ".", "in_proj_v", "(", "value", ")", "\n", "", "q", "=", "q", "*", "self", ".", "scaling", "\n", "\n", "q", "=", "q", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "k", "=", "k", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "v", "=", "v", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "src_len", "=", "k", ".", "size", "(", "1", ")", "\n", "# k,v: bsz*heads x src_len x dim", "\n", "# q: bsz*heads x tgt_len x dim ", "\n", "\n", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "assert", "list", "(", "attn_weights", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "]", "\n", "if", "attn_bias", "is", "not", "None", ":", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_bias", "=", "attn_bias", ".", "transpose", "(", "0", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "attn_weights", "=", "attn_weights", "+", "attn_bias", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_weights", ".", "masked_fill_", "(", "\n", "attn_mask", ".", "unsqueeze", "(", "0", ")", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# don't attend to padding symbols", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_weights", ".", "masked_fill_", "(", "\n", "key_padding_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "attn_weights", "=", "F", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "self", ".", "weights_dropout", ":", "\n", "            ", "attn_weights", "=", "F", ".", "dropout", "(", "attn_weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "attn", "=", "torch", ".", "bmm", "(", "attn_weights", ",", "v", ")", "\n", "if", "not", "self", ".", "weights_dropout", ":", "\n", "            ", "attn", "=", "F", ".", "dropout", "(", "attn", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "assert", "list", "(", "attn", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", "]", "\n", "\n", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "attn", "=", "self", ".", "out_proj", "(", "attn", ")", "\n", "\n", "if", "need_weights", ":", "\n", "# maximum attention weight over heads", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "if", "need_weights", "==", "'max'", ":", "\n", "                ", "attn_weights", ",", "_", "=", "attn_weights", ".", "max", "(", "dim", "=", "1", ")", "\n", "", "elif", "need_weights", "==", "\"one\"", ":", "\n", "                ", "attn_weights", "=", "attn_weights", "[", ":", ",", "0", ",", ":", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "assert", "False", ",", "\"need weights?\"", "\n", "", "attn_weights", "=", "attn_weights", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "attn_weights", "=", "None", "\n", "\n", "", "return", "attn", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention.in_proj_qkv": [[201, 203], ["transformer.MultiheadAttention._in_proj().chunk", "transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_qkv", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ")", ".", "chunk", "(", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention.in_proj_kv": [[204, 206], ["transformer.MultiheadAttention._in_proj().chunk", "transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_kv", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention.in_proj_q": [[207, 209], ["transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_q", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ",", "end", "=", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention.in_proj_k": [[210, 212], ["transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_k", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ",", "end", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention.in_proj_v": [[213, 215], ["transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_v", "(", "self", ",", "value", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "value", ",", "start", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.MultiheadAttention._in_proj": [[216, 223], ["torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "_in_proj", "(", "self", ",", "input", ",", "start", "=", "0", ",", "end", "=", "None", ")", ":", "\n", "        ", "weight", "=", "self", ".", "in_proj_weight", "\n", "bias", "=", "self", ".", "in_proj_bias", "\n", "weight", "=", "weight", "[", "start", ":", "end", ",", ":", "]", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "bias", "=", "bias", "[", "start", ":", "end", "]", "\n", "", "return", "F", ".", "linear", "(", "input", ",", "weight", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.SelfAttentionMask.__init__": [[233, 236], ["torch.nn.Module.__init__", "transformer.SelfAttentionMask.get_mask"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.SelfAttentionMask.get_mask"], ["    ", "def", "__init__", "(", "self", ",", "init_size", "=", "100", ")", ":", "\n", "        ", "super", "(", "SelfAttentionMask", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weights", "=", "SelfAttentionMask", ".", "get_mask", "(", "init_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.SelfAttentionMask.get_mask": [[237, 241], ["torch.ones().triu_().bool", "torch.ones().triu_().bool", "torch.ones().triu_().bool", "torch.ones().triu_().bool", "torch.ones().triu_", "torch.ones().triu_", "torch.ones().triu_", "torch.ones().triu_", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_mask", "(", "size", ")", ":", "\n", "        ", "weights", "=", "torch", ".", "ones", "(", "(", "size", ",", "size", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ".", "triu_", "(", "1", ")", ".", "bool", "(", ")", "\n", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.SelfAttentionMask.forward": [[242, 249], ["input.size", "transformer.SelfAttentionMask.weights[].to().detach", "transformer.SelfAttentionMask.get_mask", "transformer.SelfAttentionMask.weights.size", "transformer.SelfAttentionMask.weights[].to"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.SelfAttentionMask.get_mask"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [seq_len x bsz x (...)].\"\"\"", "\n", "size", "=", "input", ".", "size", "(", "0", ")", "\n", "if", "self", ".", "weights", "is", "None", "or", "size", ">", "self", ".", "weights", ".", "size", "(", "0", ")", ":", "\n", "            ", "self", ".", "weights", "=", "SelfAttentionMask", ".", "get_mask", "(", "size", ")", "\n", "", "res", "=", "self", ".", "weights", "[", ":", "size", ",", ":", "size", "]", ".", "to", "(", "input", ".", "device", ")", ".", "detach", "(", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.LearnedPositionalEmbedding.__init__": [[255, 259], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "transformer.LearnedPositionalEmbedding.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.Embedding", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.Embedding", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.LearnedPositionalEmbedding.reset_parameters"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "init_size", "=", "512", ")", ":", "\n", "        ", "super", "(", "LearnedPositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weights", "=", "nn", ".", "Embedding", "(", "init_size", ",", "embedding_dim", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.LearnedPositionalEmbedding.reset_parameters": [[260, 262], ["torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "weights", ".", "weight", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.LearnedPositionalEmbedding.forward": [[263, 269], ["input.size", "transformer.LearnedPositionalEmbedding.weights().unsqueeze", "transformer.LearnedPositionalEmbedding.weights", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "offset", "=", "0", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [seq_len x bsz].\"\"\"", "\n", "seq_len", ",", "bsz", "=", "input", ".", "size", "(", ")", "\n", "positions", "=", "(", "offset", "+", "torch", ".", "arange", "(", "seq_len", ")", ")", ".", "to", "(", "input", ".", "device", ")", "\n", "res", "=", "self", ".", "weights", "(", "positions", ")", ".", "unsqueeze", "(", "1", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.SinusoidalPositionalEmbedding.__init__": [[275, 281], ["torch.nn.Module.__init__", "transformer.SinusoidalPositionalEmbedding.get_embedding"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.model_utils.SinusoidalPositionalEmbedding.get_embedding"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "init_size", "=", "512", ")", ":", "\n", "        ", "super", "(", "SinusoidalPositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "init_size", ",", "\n", "embedding_dim", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.SinusoidalPositionalEmbedding.get_embedding": [[283, 298], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "math.log", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_embedding", "(", "num_embeddings", ",", "embedding_dim", ")", ":", "\n", "        ", "\"\"\"Build sinusoidal embeddings.\n        This matches the implementation in tensor2tensor, but differs slightly\n        from the description in Section 3.5 of \"Attention Is All You Need\".\n        \"\"\"", "\n", "half_dim", "=", "embedding_dim", "//", "2", "\n", "emb", "=", "math", ".", "log", "(", "10000", ")", "/", "(", "half_dim", "-", "1", ")", "\n", "emb", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "half_dim", ",", "dtype", "=", "torch", ".", "float", ")", "*", "-", "emb", ")", "\n", "emb", "=", "torch", ".", "arange", "(", "num_embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "1", ")", "*", "emb", ".", "unsqueeze", "(", "0", ")", "\n", "emb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "emb", ")", ",", "torch", ".", "cos", "(", "emb", ")", "]", ",", "dim", "=", "1", ")", ".", "view", "(", "num_embeddings", ",", "-", "1", ")", "\n", "if", "embedding_dim", "%", "2", "==", "1", ":", "\n", "# zero pad", "\n", "            ", "emb", "=", "torch", ".", "cat", "(", "[", "emb", ",", "torch", ".", "zeros", "(", "num_embeddings", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.SinusoidalPositionalEmbedding.forward": [[299, 315], ["input.size", "transformer.SinusoidalPositionalEmbedding.weights.index_select().view().to().detach", "transformer.SinusoidalPositionalEmbedding.get_embedding", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "len", "transformer.SinusoidalPositionalEmbedding.weights.size", "transformer.SinusoidalPositionalEmbedding.weights.index_select().view().to", "transformer.SinusoidalPositionalEmbedding.weights.index_select().view", "transformer.SinusoidalPositionalEmbedding.weights.index_select"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.model_utils.SinusoidalPositionalEmbedding.get_embedding"], ["", "def", "forward", "(", "self", ",", "input", ",", "offset", "=", "0", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [seq_len x bsz x (...)].\"\"\"", "\n", "seq_len", ",", "*", "dims", "=", "input", ".", "size", "(", ")", "\n", "mx_position", "=", "seq_len", "+", "offset", "\n", "if", "self", ".", "weights", "is", "None", "or", "mx_position", ">", "self", ".", "weights", ".", "size", "(", "0", ")", ":", "\n", "# recompute/expand embeddings if needed", "\n", "            ", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "mx_position", ",", "\n", "self", ".", "embedding_dim", ",", "\n", ")", "\n", "\n", "", "positions", "=", "offset", "+", "torch", ".", "arange", "(", "seq_len", ")", "\n", "shape", "=", "[", "1", "]", "*", "len", "(", "dims", ")", "\n", "shape", "=", "[", "seq_len", "]", "+", "shape", "+", "[", "-", "1", "]", "\n", "res", "=", "self", ".", "weights", ".", "index_select", "(", "0", ",", "positions", ")", ".", "view", "(", "shape", ")", ".", "to", "(", "input", ".", "device", ")", ".", "detach", "(", ")", "\n", "return", "res", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.Embedding": [[225, 230], ["torch.nn.Embedding", "torch.nn.init.normal_", "torch.nn.init.constant_"], "function", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.alignment_model.AlignmentModel.__init__": [[12, 25], ["models.base_model.BaseModel.__init__", "alignment_model.AlignmentModel.save_hyperparameters", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ":", "Any", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "h_params", "=", "kwargs", "[", "\"hparams\"", "]", "\n", "\n", "self", ".", "vocab_size", "=", "h_params", ".", "num_labels", "\n", "self", ".", "h_params", "=", "h_params", "\n", "hidden_size", "=", "h_params", ".", "hidden_size", "\n", "\n", "self", ".", "save_hyperparameters", "(", "h_params", ")", "\n", "\n", "self", ".", "alignment_decoder", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "self", ".", "vocab_size", ")", "\n", "if", "h_params", ".", "train_psi", ":", "\n", "            ", "self", ".", "psi_decoder", "=", "nn", ".", "Linear", "(", "self", ".", "word_encoder", ".", "language_model", ".", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.alignment_model.AlignmentModel.forward": [[26, 39], ["alignment_model.AlignmentModel.word_encoder", "alignment_model.AlignmentModel.alignment_decoder", "alignment_model.AlignmentModel.word_encoder", "alignment_model.AlignmentModel.psi_decoder"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", "->", "Any", ":", "\n", "        ", "input_ids", "=", "x", "[", "\"input_ids\"", "]", "\n", "sequence_length", "=", "x", "[", "\"sequence_length\"", "]", "\n", "token_embeddings", "=", "self", ".", "word_encoder", "(", "input_ids", ",", "sequence_lengths", "=", "sequence_length", ")", "\n", "mlm_logits", "=", "self", ".", "alignment_decoder", "(", "token_embeddings", ")", "\n", "if", "self", ".", "h_params", ".", "train_psi", ":", "\n", "            ", "psi_input_ids", "=", "x", "[", "\"psi_pair\"", "]", "\n", "psi_sequence_length", "=", "x", "[", "\"psi_sequence_length\"", "]", "\n", "psi_logits", "=", "self", ".", "word_encoder", "(", "psi_input_ids", ",", "sequence_lengths", "=", "psi_sequence_length", ",", "get_pooled_output", "=", "True", ")", "\n", "psi_logits", "=", "self", ".", "psi_decoder", "(", "psi_logits", ")", "\n", "return", "mlm_logits", ",", "psi_logits", "\n", "", "else", ":", "\n", "            ", "return", "mlm_logits", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.alignment_model.AlignmentModel.training_step": [[40, 62], ["alignment_model.AlignmentModel.", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "alignment_model.AlignmentModel.log", "alignment_model.AlignmentModel.log", "mlm_logits.view", "batch[].view", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "psi_logits.view", "batch[].view", "alignment_model.AlignmentModel.optimizers", "alignment_model.AlignmentModel.optimizers"], "methods", ["None"], ["", "", "def", "training_step", "(", "self", ",", "batch", ",", "batch_index", ")", ":", "\n", "        ", "mlm_logits", ",", "psi_logits", "=", "self", "(", "batch", ")", "\n", "\n", "mlm_loss", "=", "F", ".", "cross_entropy", "(", "\n", "mlm_logits", ".", "view", "(", "-", "1", ",", "self", ".", "vocab_size", ")", ",", "\n", "batch", "[", "\"mlm_label\"", "]", ".", "view", "(", "-", "1", ")", ",", "\n", "reduction", "=", "'mean'", ",", "\n", "ignore_index", "=", "-", "100", "\n", ")", "\n", "psi_loss", "=", "0", "\n", "if", "self", ".", "h_params", ".", "train_psi", ":", "\n", "            ", "psi_loss", "=", "F", ".", "cross_entropy", "(", "\n", "psi_logits", ".", "view", "(", "-", "1", ",", "2", ")", ",", "\n", "batch", "[", "\"psi_label\"", "]", ".", "view", "(", "-", "1", ")", ",", "\n", "reduction", "=", "'mean'", ",", "\n", ")", "\n", "\n", "", "self", ".", "log", "(", "\"model_lr\"", ",", "self", ".", "optimizers", "(", ")", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "prog_bar", "=", "True", ",", "logger", "=", "False", ",", "on_epoch", "=", "False", ",", "\n", "on_step", "=", "True", ")", "\n", "self", ".", "log", "(", "\"lm_lr\"", ",", "self", ".", "optimizers", "(", ")", ".", "param_groups", "[", "1", "]", "[", "'lr'", "]", ",", "prog_bar", "=", "True", ",", "logger", "=", "False", ",", "on_epoch", "=", "False", ",", "\n", "on_step", "=", "True", ")", "\n", "return", "mlm_loss", "+", "psi_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.alignment_model.AlignmentModel.validation_step": [[63, 82], ["alignment_model.AlignmentModel.", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "mlm_logits.view", "batch[].view", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.as_tensor().float", "torch.as_tensor().float", "torch.as_tensor().float", "torch.as_tensor().float", "torch.as_tensor().float", "torch.as_tensor().float", "torch.as_tensor().float", "torch.as_tensor().float", "torch.as_tensor().float", "psi_logits.view", "batch[].view", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor"], "methods", ["None"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_index", ")", ":", "\n", "        ", "mlm_logits", ",", "psi_logits", "=", "self", "(", "batch", ")", "\n", "mlm_loss", "=", "F", ".", "cross_entropy", "(", "\n", "mlm_logits", ".", "view", "(", "-", "1", ",", "self", ".", "vocab_size", ")", ",", "\n", "batch", "[", "\"mlm_label\"", "]", ".", "view", "(", "-", "1", ")", ",", "\n", "reduction", "=", "'mean'", ",", "\n", "ignore_index", "=", "-", "100", "\n", ")", "\n", "psi_loss", "=", "0", "\n", "if", "self", ".", "h_params", ".", "train_psi", ":", "\n", "            ", "psi_loss", "=", "F", ".", "cross_entropy", "(", "\n", "psi_logits", ".", "view", "(", "-", "1", ",", "2", ")", ",", "\n", "batch", "[", "\"psi_label\"", "]", ".", "view", "(", "-", "1", ")", ",", "\n", "reduction", "=", "'mean'", ",", "\n", ")", "\n", "", "return", "{", "\n", "\"loss\"", ":", "mlm_loss", "+", "psi_loss", ",", "\n", "\"mlm_loss\"", ":", "mlm_loss", ",", "\n", "\"psi_loss\"", ":", "torch", ".", "as_tensor", "(", "psi_loss", ")", ".", "float", "(", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.alignment_model.AlignmentModel.validation_epoch_end": [[84, 97], ["torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "print", "print", "print", "print", "alignment_model.AlignmentModel.log", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ":", "EPOCH_OUTPUT", ")", ":", "\n", "        ", "avg_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"loss\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "avg_mlm_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"mlm_loss\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "avg_psi_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"psi_loss\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "select_metrics", "=", "avg_loss", "\n", "\n", "print", "(", "\"\\n======================\\n\"", ")", "\n", "print", "(", "\"average mlm loss: {}\"", ".", "format", "(", "avg_mlm_loss", ")", ")", "\n", "print", "(", "\"average psi loss: {}\"", ".", "format", "(", "avg_psi_loss", ")", ")", "\n", "print", "(", "\"\\n======================\\n\"", ")", "\n", "\n", "self", ".", "log", "(", "\"select_metrics\"", ",", "torch", ".", "tensor", "(", "select_metrics", ",", "device", "=", "self", ".", "device", ")", ",", "prog_bar", "=", "True", ",", "logger", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "on_step", "=", "False", ",", "sync_dist", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.alignment_model.AlignmentModel.add_model_specific_args": [[98, 101], ["models.base_model.BaseModel.add_model_specific_args"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ")", ":", "\n", "        ", "return", "BaseModel", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.model_utils.SinusoidalPositionalEmbedding.__init__": [[10, 16], ["torch.Module.__init__", "model_utils.SinusoidalPositionalEmbedding.get_embedding"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.model_utils.SinusoidalPositionalEmbedding.get_embedding"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "init_size", "=", "512", ")", ":", "\n", "        ", "super", "(", "SinusoidalPositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "init_size", ",", "\n", "embedding_dim", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.model_utils.SinusoidalPositionalEmbedding.get_embedding": [[18, 33], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "math.log", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_embedding", "(", "num_embeddings", ",", "embedding_dim", ")", ":", "\n", "        ", "\"\"\"Build sinusoidal embeddings.\n        This matches the implementation in tensor2tensor, but differs slightly\n        from the description in Section 3.5 of \"Attention Is All You Need\".\n        \"\"\"", "\n", "half_dim", "=", "embedding_dim", "//", "2", "\n", "emb", "=", "math", ".", "log", "(", "10000", ")", "/", "(", "half_dim", "-", "1", ")", "\n", "emb", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "half_dim", ",", "dtype", "=", "torch", ".", "float", ")", "*", "-", "emb", ")", "\n", "emb", "=", "torch", ".", "arange", "(", "num_embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "1", ")", "*", "emb", ".", "unsqueeze", "(", "0", ")", "\n", "emb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "emb", ")", ",", "torch", ".", "cos", "(", "emb", ")", "]", ",", "dim", "=", "1", ")", ".", "view", "(", "num_embeddings", ",", "-", "1", ")", "\n", "if", "embedding_dim", "%", "2", "==", "1", ":", "\n", "# zero pad", "\n", "            ", "emb", "=", "torch", ".", "cat", "(", "[", "emb", ",", "torch", ".", "zeros", "(", "num_embeddings", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.model_utils.SinusoidalPositionalEmbedding.forward": [[34, 50], ["input.size", "model_utils.SinusoidalPositionalEmbedding.weights.index_select().view().to().detach", "model_utils.SinusoidalPositionalEmbedding.get_embedding", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "len", "model_utils.SinusoidalPositionalEmbedding.weights.size", "model_utils.SinusoidalPositionalEmbedding.weights.index_select().view().to", "model_utils.SinusoidalPositionalEmbedding.weights.index_select().view", "model_utils.SinusoidalPositionalEmbedding.weights.index_select"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.model_utils.SinusoidalPositionalEmbedding.get_embedding"], ["", "def", "forward", "(", "self", ",", "input", ",", "offset", "=", "0", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [seq_len x bsz x (...)].\"\"\"", "\n", "seq_len", ",", "*", "dims", "=", "input", ".", "size", "(", ")", "\n", "mx_position", "=", "seq_len", "+", "offset", "\n", "if", "self", ".", "weights", "is", "None", "or", "mx_position", ">", "self", ".", "weights", ".", "size", "(", "0", ")", ":", "\n", "# recompute/expand embeddings if needed", "\n", "            ", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "mx_position", ",", "\n", "self", ".", "embedding_dim", ",", "\n", ")", "\n", "\n", "", "positions", "=", "offset", "+", "torch", ".", "arange", "(", "seq_len", ")", "\n", "shape", "=", "[", "1", "]", "*", "len", "(", "dims", ")", "\n", "shape", "=", "[", "seq_len", "]", "+", "shape", "+", "[", "-", "1", "]", "\n", "res", "=", "self", ".", "weights", ".", "index_select", "(", "0", ",", "positions", ")", ".", "view", "(", "shape", ")", ".", "to", "(", "input", ".", "device", ")", ".", "detach", "(", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.model_utils._gen_timing_signal": [[52, 72], ["numpy.arange", "numpy.concatenate", "numpy.pad", "signal.reshape.reshape", "torch.from_numpy().type", "torch.from_numpy().type", "math.log", "numpy.exp", "numpy.expand_dims", "numpy.expand_dims", "float", "numpy.sin", "numpy.cos", "torch.from_numpy", "torch.from_numpy", "float", "float", "numpy.arange().astype", "numpy.arange"], "function", ["None"], ["", "", "def", "_gen_timing_signal", "(", "length", ",", "channels", ",", "min_timescale", "=", "1.0", ",", "max_timescale", "=", "1.0e4", ")", ":", "\n", "    ", "\"\"\"\n    Generates a [1, length, channels] timing signal consisting of sinusoids\n    Adapted from:\n    https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/layers/common_attention.py\n    \"\"\"", "\n", "position", "=", "np", ".", "arange", "(", "length", ")", "\n", "num_timescales", "=", "channels", "//", "2", "\n", "log_timescale_increment", "=", "(", "\n", "math", ".", "log", "(", "float", "(", "max_timescale", ")", "/", "float", "(", "min_timescale", ")", ")", "/", "\n", "(", "float", "(", "num_timescales", ")", "-", "1", ")", ")", "\n", "inv_timescales", "=", "min_timescale", "*", "np", ".", "exp", "(", "\n", "np", ".", "arange", "(", "num_timescales", ")", ".", "astype", "(", "np", ".", "float", ")", "*", "-", "log_timescale_increment", ")", "\n", "scaled_time", "=", "np", ".", "expand_dims", "(", "position", ",", "1", ")", "*", "np", ".", "expand_dims", "(", "inv_timescales", ",", "0", ")", "\n", "\n", "signal", "=", "np", ".", "concatenate", "(", "[", "np", ".", "sin", "(", "scaled_time", ")", ",", "np", ".", "cos", "(", "scaled_time", ")", "]", ",", "axis", "=", "1", ")", "\n", "signal", "=", "np", ".", "pad", "(", "signal", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "channels", "%", "2", "]", "]", ",", "\n", "'constant'", ",", "constant_values", "=", "[", "0.0", ",", "0.0", "]", ")", "\n", "signal", "=", "signal", ".", "reshape", "(", "[", "1", ",", "length", ",", "channels", "]", ")", "\n", "return", "torch", ".", "from_numpy", "(", "signal", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.xsrl_model.XSRLModel.__init__": [[13, 75], ["models.base_model.BaseModel.__init__", "utils.Embedding", "layers.state_encoder.StateEncoder", "xsrl_model.XSRLModel.get_encoder", "xsrl_model.XSRLModel.get_encoder", "xsrl_model.XSRLModel.get_encoder", "layers.state_encoder.StateEncoder", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "utils.Embedding", "utils.Embedding"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.Embedding", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.get_encoder", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.get_encoder", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.get_encoder", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.Embedding", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.Embedding"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ":", "Any", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "h_params", "=", "kwargs", "[", "\"hparams\"", "]", "\n", "\n", "hidden_size", "=", "h_params", ".", "hidden_size", "\n", "\n", "feature_dim", "=", "1", "\n", "self", ".", "predicate_embedding", "=", "Embedding", "(", "num_embeddings", "=", "3", ",", "embedding_dim", "=", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "if", "h_params", ".", "use_turn_info", ":", "\n", "            ", "self", ".", "turn_embedding", "=", "Embedding", "(", "num_embeddings", "=", "12", ",", "embedding_dim", "=", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "feature_dim", "+=", "1", "\n", "", "if", "h_params", ".", "use_role_info", ":", "\n", "            ", "self", ".", "role_embedding", "=", "Embedding", "(", "num_embeddings", "=", "3", ",", "embedding_dim", "=", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "feature_dim", "+=", "1", "\n", "\n", "", "self", ".", "feature_combiner", "=", "StateEncoder", "(", "\n", "input_size", "=", "feature_dim", "*", "hidden_size", ",", "\n", "state_size", "=", "hidden_size", "//", "2", ",", "\n", "output_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "2", ",", "\n", "activation", "=", "h_params", ".", "activation_fn", ",", "\n", "dropout_rate", "=", "h_params", ".", "dropout", "\n", ")", "\n", "\n", "self", ".", "utterance_encoder", ",", "utterance_output_size", "=", "self", ".", "get_encoder", "(", "h_params", ".", "utterance_encoder_type", ",", "\n", "input_size", "=", "hidden_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "mha_heads", "=", "h_params", ".", "mha_heads", ",", "\n", "mha_num_layers", "=", "h_params", ".", "mha_num_layers", ",", "\n", "mha_dropout", "=", "h_params", ".", "mha_dropout", ",", "\n", "lstm_num_layers", "=", "h_params", ".", "lstm_num_layers", ",", "\n", "lstm_dropout", "=", "h_params", ".", "lstm_dropout", ",", "\n", "lstm_bidirectional", "=", "h_params", ".", "lstm_bidirectional", ")", "\n", "self", ".", "dialogue_encoder", ",", "dialogue_output_size", "=", "self", ".", "get_encoder", "(", "h_params", ".", "dialogue_encoder_type", ",", "\n", "input_size", "=", "utterance_output_size", ",", "\n", "hidden_size", "=", "utterance_output_size", ",", "\n", "mha_heads", "=", "h_params", ".", "mha_heads", ",", "\n", "mha_num_layers", "=", "h_params", ".", "mha_num_layers", ",", "\n", "mha_dropout", "=", "h_params", ".", "mha_dropout", ",", "\n", "lstm_num_layers", "=", "h_params", ".", "lstm_num_layers", ",", "\n", "lstm_dropout", "=", "h_params", ".", "lstm_dropout", ",", "\n", "lstm_bidirectional", "=", "h_params", ".", "lstm_bidirectional", ")", "\n", "self", ".", "predicate_argument_encoder", ",", "pred_arg_output_size", "=", "self", ".", "get_encoder", "(", "h_params", ".", "pa_encoder_type", ",", "\n", "input_size", "=", "hidden_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "mha_heads", "=", "h_params", ".", "mha_heads", ",", "\n", "mha_num_layers", "=", "h_params", ".", "mha_num_layers", ",", "\n", "mha_dropout", "=", "h_params", ".", "mha_dropout", ",", "\n", "lstm_num_layers", "=", "h_params", ".", "lstm_num_layers", ",", "\n", "lstm_dropout", "=", "h_params", ".", "lstm_dropout", ",", "\n", "lstm_bidirectional", "=", "h_params", ".", "lstm_bidirectional", ")", "\n", "\n", "self", ".", "hierarchical_feature_combiner", "=", "StateEncoder", "(", "\n", "input_size", "=", "utterance_output_size", "+", "dialogue_output_size", "+", "hidden_size", ",", "\n", "state_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "1", ",", "\n", "activation", "=", "h_params", ".", "activation_fn", ",", "\n", "dropout_rate", "=", "h_params", ".", "dropout", "\n", ")", "\n", "\n", "self", ".", "csrl_argument_classifier", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "predicate_argument_encoder", ".", "sequence_state_size", ",", "\n", "h_params", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.xsrl_model.XSRLModel.encode_dialogue": [[76, 103], ["xsrl_model.XSRLModel.utterance_encoder", "torch_scatter.scatter_mean", "xsrl_model.XSRLModel.dialogue_encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "dialogue_indices.unsqueeze().expand", "dialogue_indices.unsqueeze"], "methods", ["None"], ["", "def", "encode_dialogue", "(", "self", ",", "features", ",", "x", ")", ":", "\n", "        ", "sequence_length", "=", "x", "[", "\"sequence_length\"", "]", "\n", "dialogue_indices", "=", "x", "[", "\"dialogue_indices\"", "]", "# bsz, seq", "\n", "utterance_num", "=", "x", "[", "\"utterance_num\"", "]", "\n", "\n", "bsz", ",", "max_utterance_num", "=", "dialogue_indices", ".", "shape", "\n", "\n", "# bsz, seq, dim", "\n", "utterance_level_feature", "=", "self", ".", "utterance_encoder", "(", "features", ",", "sequence_length", ")", "\n", "dialogue_level_feature", "=", "scatter_mean", "(", "utterance_level_feature", ",", "index", "=", "dialogue_indices", ",", "dim", "=", "1", ")", "\n", "\n", "# bsz, utt_num, dim", "\n", "dialogue_level_feature", "=", "dialogue_level_feature", "[", ":", ",", "1", ":", "max_utterance_num", "+", "1", ":", ",", ":", "]", "\n", "dialogue_level_feature", "=", "self", ".", "dialogue_encoder", "(", "dialogue_level_feature", ",", "utterance_num", ")", "\n", "\n", "# add zero vector as paddings in the front of the features", "\n", "dim", "=", "dialogue_level_feature", ".", "shape", "[", "-", "1", "]", "\n", "context_embeddings", "=", "torch", ".", "cat", "(", "[", "torch", ".", "zeros", "(", "(", "bsz", ",", "1", ",", "dim", ")", ",", "device", "=", "self", ".", "device", ")", ",", "\n", "dialogue_level_feature", "]", ",", "dim", "=", "1", ")", "\n", "# mapping the dialogue features back wth utterance features", "\n", "# bsz, seq, dim", "\n", "context_embeddings", "=", "torch", ".", "gather", "(", "context_embeddings", ",", "dim", "=", "1", ",", "\n", "index", "=", "dialogue_indices", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "dim", ")", ")", "\n", "\n", "context_embeddings", "=", "torch", ".", "cat", "(", "[", "utterance_level_feature", ",", "context_embeddings", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "return", "context_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.xsrl_model.XSRLModel.forward": [[104, 131], ["xsrl_model.XSRLModel.encode_sent", "xsrl_model.XSRLModel.predicate_embedding", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "xsrl_model.XSRLModel.feature_combiner", "xsrl_model.XSRLModel.encode_dialogue", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "xsrl_model.XSRLModel.hierarchical_feature_combiner", "xsrl_model.XSRLModel.predicate_argument_encoder", "xsrl_model.XSRLModel.csrl_argument_classifier", "xsrl_model.XSRLModel.turn_embedding", "feature_list.append", "xsrl_model.XSRLModel.role_embedding", "feature_list.append"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.encode_sent", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.xsrl_model.XSRLModel.encode_dialogue"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "predicate_ids", "=", "x", "[", "\"predicate_ids\"", "]", "\n", "turn_ids", "=", "x", "[", "\"turn_ids\"", "]", "\n", "role_ids", "=", "x", "[", "\"speaker_role_ids\"", "]", "\n", "\n", "# bsz, seq, dim", "\n", "_", ",", "word_embeddings", "=", "self", ".", "encode_sent", "(", "x", ")", "\n", "predicate_embeddings", "=", "self", ".", "predicate_embedding", "(", "predicate_ids", ")", "\n", "\n", "feature_list", "=", "[", "word_embeddings", "]", "\n", "if", "self", ".", "h_params", ".", "use_turn_info", ":", "\n", "            ", "turn_embeddings", "=", "self", ".", "turn_embedding", "(", "turn_ids", ")", "\n", "feature_list", ".", "append", "(", "turn_embeddings", ")", "\n", "", "if", "self", ".", "h_params", ".", "use_role_info", ":", "\n", "            ", "role_embeddings", "=", "self", ".", "role_embedding", "(", "role_ids", ")", "\n", "feature_list", ".", "append", "(", "role_embeddings", ")", "\n", "\n", "", "combined_feature_embeddings", "=", "torch", ".", "cat", "(", "feature_list", ",", "dim", "=", "-", "1", ")", "\n", "combined_feature_embeddings", "=", "self", ".", "feature_combiner", "(", "combined_feature_embeddings", ")", "\n", "context_embeddings", "=", "self", ".", "encode_dialogue", "(", "combined_feature_embeddings", ",", "x", ")", "\n", "\n", "context_embeddings", "=", "torch", ".", "cat", "(", "[", "context_embeddings", ",", "predicate_embeddings", "]", ",", "dim", "=", "-", "1", ")", "\n", "context_embeddings", "=", "self", ".", "hierarchical_feature_combiner", "(", "context_embeddings", ")", "\n", "final_repr", "=", "self", ".", "predicate_argument_encoder", "(", "context_embeddings", ",", "x", "[", "\"sequence_length\"", "]", ")", "\n", "argument_logits", "=", "self", ".", "csrl_argument_classifier", "(", "final_repr", ")", "\n", "\n", "return", "argument_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.xsrl_model.XSRLModel.training_step": [[132, 148], ["xsrl_model.XSRLModel.", "torch.cross_entropy", "torch.cross_entropy", "xsrl_model.XSRLModel.log", "xsrl_model.XSRLModel.log", "xsrl_model.XSRLModel.view", "batch[].view", "xsrl_model.XSRLModel.optimizers", "xsrl_model.XSRLModel.optimizers"], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_index", ")", ":", "\n", "        ", "argument_scores", "=", "self", "(", "batch", ")", "# (bsz, seq, dim)", "\n", "argument_classification_loss", "=", "F", ".", "cross_entropy", "(", "\n", "argument_scores", ".", "view", "(", "-", "1", ",", "self", ".", "h_params", ".", "num_labels", ")", ",", "\n", "batch", "[", "\"label\"", "]", ".", "view", "(", "-", "1", ")", ",", "\n", "reduction", "=", "'mean'", ",", "\n", "ignore_index", "=", "-", "100", "\n", ")", "\n", "loss", "=", "argument_classification_loss", "\n", "self", ".", "log", "(", "\"model_lr\"", ",", "self", ".", "optimizers", "(", ")", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "prog_bar", "=", "True", ",", "logger", "=", "False", ",", "on_epoch", "=", "False", ",", "\n", "on_step", "=", "True", ")", "\n", "self", ".", "log", "(", "\"lm_lr\"", ",", "self", ".", "optimizers", "(", ")", ".", "param_groups", "[", "1", "]", "[", "'lr'", "]", ",", "prog_bar", "=", "True", ",", "logger", "=", "False", ",", "on_epoch", "=", "False", ",", "\n", "on_step", "=", "True", ")", "\n", "\n", "return", "{", "\n", "\"loss\"", ":", "loss", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.xsrl_model.XSRLModel.validation_step": [[150, 181], ["xsrl_model.XSRLModel.", "torch.cross_entropy", "torch.cross_entropy", "torch.max", "torch.max", "torch.max", "torch.max", "batch[].contiguous().view", "prediction.contiguous().view.contiguous().view.contiguous().view", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.eq().float().to", "torch.eq().float().to", "torch.eq().float().to", "torch.eq().float().to", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "xsrl_model.XSRLModel.view", "batch[].view", "torch.softmax", "torch.softmax", "torch.arange().unsqueeze().to", "torch.arange().unsqueeze().to", "torch.arange().unsqueeze().to", "torch.arange().unsqueeze().to", "sequence_lengths.unsqueeze", "torch.gt().float().to", "torch.gt().float().to", "torch.gt().float().to", "torch.gt().float().to", "torch.tensor().float.contiguous().view", "torch.tensor().float.contiguous().view", "batch[].contiguous", "prediction.contiguous().view.contiguous().view.contiguous", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.gt().float", "torch.gt().float", "torch.gt().float", "torch.gt().float", "torch.tensor().float.contiguous", "torch.tensor().float.contiguous", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "none_zero_mask.contiguous().view", "none_zero_mask.contiguous"], "methods", ["None"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_index", ")", ":", "\n", "        ", "device", "=", "self", ".", "device", "\n", "sequence_lengths", "=", "batch", "[", "\"sequence_length\"", "]", "\n", "argument_scores", "=", "self", "(", "batch", ")", "\n", "max_seq_length", "=", "argument_scores", ".", "shape", "[", "1", "]", "\n", "argument_classification_loss", "=", "F", ".", "cross_entropy", "(", "\n", "argument_scores", ".", "view", "(", "-", "1", ",", "self", ".", "h_params", ".", "num_labels", ")", ",", "\n", "batch", "[", "\"label\"", "]", ".", "view", "(", "-", "1", ")", ",", "\n", "reduction", "=", "\"mean\"", ",", "\n", "ignore_index", "=", "-", "100", "\n", ")", "\n", "val_loss", "=", "argument_classification_loss", "\n", "_", ",", "prediction", "=", "torch", ".", "max", "(", "F", ".", "softmax", "(", "argument_scores", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "label", "=", "batch", "[", "\"label\"", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "prediction", "=", "prediction", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "token_mask", "=", "torch", ".", "arange", "(", "max_seq_length", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "device", ")", "<", "sequence_lengths", ".", "unsqueeze", "(", "1", ")", "\n", "token_mask", "=", "torch", ".", "tensor", "(", "token_mask", ")", ".", "float", "(", ")", "\n", "none_zero_mask", "=", "torch", ".", "gt", "(", "prediction", ",", "0", ")", ".", "float", "(", ")", ".", "to", "(", "device", ")", "*", "token_mask", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "eq_num", "=", "torch", ".", "eq", "(", "prediction", ",", "label", ")", ".", "float", "(", ")", ".", "to", "(", "device", ")", "\n", "eq_num", "=", "(", "eq_num", "*", "none_zero_mask", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ")", ".", "sum", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "total_pred_count", "=", "torch", ".", "sum", "(", "none_zero_mask", ")", ".", "cpu", "(", ")", "\n", "total_gold_count", "=", "torch", ".", "sum", "(", "torch", ".", "gt", "(", "label", ",", "0", ")", ")", ".", "cpu", "(", ")", "\n", "\n", "return", "{", "\n", "\"loss\"", ":", "val_loss", ",", "\n", "\"eq_num\"", ":", "eq_num", ",", "\n", "\"total_pred_num\"", ":", "total_pred_count", ",", "\n", "\"total_gold_num\"", ":", "total_gold_count", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.xsrl_model.XSRLModel.validation_epoch_end": [[183, 197], ["torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "xsrl_model.XSRLModel.log", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ":", "EPOCH_OUTPUT", ")", "->", "None", ":", "\n", "        ", "avg_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"loss\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "total_pred_num", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"total_pred_num\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "total_gold_num", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"total_gold_num\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "correct_num", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"eq_num\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "\n", "val_p", "=", "correct_num", "/", "total_pred_num", "\n", "val_r", "=", "correct_num", "/", "total_gold_num", "\n", "val_f1", "=", "2", "*", "val_p", "*", "val_r", "/", "(", "val_p", "+", "val_r", ")", "\n", "\n", "select_metrics", "=", "val_f1", "\n", "\n", "self", ".", "log", "(", "\"select_metrics\"", ",", "torch", ".", "tensor", "(", "select_metrics", ",", "device", "=", "self", ".", "device", ")", ",", "logger", "=", "False", ",", "on_epoch", "=", "True", ",", "\n", "on_step", "=", "False", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.xsrl_model.XSRLModel.__prepare_test_data": [[198, 230], ["data_example[].long().to", "data_example[].long().to", "data_example[].long().to", "data_example[].long().to", "torch.tensor().long().to", "torch.tensor().long().to", "torch.tensor().long().to", "torch.tensor().long().to", "torch.tensor().long().to", "torch.tensor().long().to", "torch.tensor().long().to", "torch.tensor().long().to", "data_example[].long().to", "torch.tensor().long().to", "torch.tensor().long().to", "torch.tensor().long().to", "torch.tensor().long().to", "data_example[].long().to", "len", "word_ids.view.view.view", "predicate_ids.view.view.view", "turn_ids.view.view.view", "subword_indices.view.view.view", "sequence_length.view.view.view", "tokenized_sequence_length.view.view.view", "dialogue_indices.view.view.view", "utterance_num.view.view.view", "speaker_role_ids.view.view.view", "data_example[].long", "data_example[].long", "data_example[].long", "data_example[].long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "data_example[].long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "data_example[].long", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "__prepare_test_data", "(", "self", ",", "data_example", ")", ":", "\n", "        ", "word_ids", "=", "data_example", "[", "\"word_ids\"", "]", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "predicate_ids", "=", "data_example", "[", "\"predicate_ids\"", "]", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "turn_ids", "=", "data_example", "[", "\"turn_ids\"", "]", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "subword_indices", "=", "data_example", "[", "\"subword_indices\"", "]", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "sequence_length", "=", "torch", ".", "tensor", "(", "data_example", "[", "\"sequence_length\"", "]", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "tokenized_sequence_length", "=", "torch", ".", "tensor", "(", "data_example", "[", "\"tokenized_sequence_length\"", "]", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "dialogue_indices", "=", "data_example", "[", "\"dialogue_indices\"", "]", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "utterance_num", "=", "torch", ".", "tensor", "(", "data_example", "[", "\"utterance_num\"", "]", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "speaker_role_ids", "=", "data_example", "[", "\"speaker_role_ids\"", "]", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "if", "len", "(", "word_ids", ".", "shape", ")", "==", "1", ":", "\n", "            ", "word_ids", "=", "word_ids", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "predicate_ids", "=", "predicate_ids", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "turn_ids", "=", "turn_ids", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "subword_indices", "=", "subword_indices", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "sequence_length", "=", "sequence_length", ".", "view", "(", "-", "1", ")", "\n", "tokenized_sequence_length", "=", "tokenized_sequence_length", ".", "view", "(", "-", "1", ")", "\n", "dialogue_indices", "=", "dialogue_indices", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "utterance_num", "=", "utterance_num", ".", "view", "(", "-", "1", ")", "\n", "speaker_role_ids", "=", "speaker_role_ids", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "\n", "", "return", "{", "\n", "\"word_ids\"", ":", "word_ids", ",", "\n", "\"predicate_ids\"", ":", "predicate_ids", ",", "\n", "\"turn_ids\"", ":", "turn_ids", ",", "\n", "\"speaker_role_ids\"", ":", "speaker_role_ids", ",", "\n", "\"subword_indices\"", ":", "subword_indices", ",", "\n", "\"sequence_length\"", ":", "sequence_length", ",", "\n", "\"tokenized_sequence_length\"", ":", "tokenized_sequence_length", ",", "\n", "\"dialogue_indices\"", ":", "dialogue_indices", ",", "\n", "\"utterance_num\"", ":", "utterance_num", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.xsrl_model.XSRLModel.predict": [[232, 254], ["xsrl_model.XSRLModel.__prepare_test_data", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "xsrl_model.XSRLModel.", "torch.max", "torch.max", "torch.max", "torch.max", "predictions.contiguous().view().cpu().numpy.contiguous().view().cpu().numpy.contiguous().view().cpu().numpy", "range", "torch.softmax", "torch.softmax", "[].item", "valid_predictions.append", "predictions.contiguous().view().cpu().numpy.contiguous().view().cpu().numpy.contiguous().view().cpu", "batch_sample[].tolist", "predictions.contiguous().view().cpu().numpy.contiguous().view().cpu().numpy.contiguous().view", "predictions.contiguous().view().cpu().numpy.contiguous().view().cpu().numpy.contiguous"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.xsrl_model.XSRLModel.__prepare_test_data"], ["", "def", "predict", "(", "self", ",", "data_example", ",", "id2label", ",", "need_mapping", "=", "True", ")", ":", "\n", "        ", "batch_sample", "=", "self", ".", "__prepare_test_data", "(", "data_example", ")", "\n", "bsz", "=", "batch_sample", "[", "\"word_ids\"", "]", ".", "shape", "[", "0", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "csrl_logits", "=", "self", "(", "batch_sample", ")", "\n", "_", ",", "predictions", "=", "torch", ".", "max", "(", "F", ".", "softmax", "(", "csrl_logits", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "\n", "predictions", "=", "predictions", ".", "contiguous", "(", ")", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "valid_predictions", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "bsz", ")", ":", "\n", "                ", "sequence_length", "=", "batch_sample", "[", "\"sequence_length\"", "]", "[", "i", "]", ".", "item", "(", ")", "\n", "prediction", "=", "predictions", "[", "i", "]", "[", ":", "sequence_length", "]", "\n", "prediction", "=", "[", "id2label", "[", "idx", "]", "for", "idx", "in", "prediction", "]", "[", "1", ":", "-", "1", "]", "\n", "valid_predictions", ".", "append", "(", "prediction", ")", "\n", "\n", "", "if", "need_mapping", ":", "\n", "# [CLS] SENT [SEP]", "\n", "                ", "subword_indices", "=", "batch_sample", "[", "\"subword_indices\"", "]", ".", "tolist", "(", ")", "[", "0", "]", "[", "1", ":", "-", "1", "]", "\n", "subword_indices", "=", "[", "w", "-", "2", "for", "w", "in", "subword_indices", "]", "\n", "\n", "return", "predictions", ",", "subword_indices", "\n", "\n", "", "return", "valid_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.xsrl_model.XSRLModel.add_model_specific_args": [[255, 258], ["models.base_model.BaseModel.add_model_specific_args"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.add_model_specific_args"], ["", "", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ")", ":", "\n", "        ", "return", "BaseModel", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.srl_model.SRLModel.__init__": [[11, 41], ["models.base_model.BaseModel.__init__", "utils.Embedding", "srl_model.SRLModel.get_encoder", "srl_model.SRLModel.get_encoder", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.layers.transformer.Embedding", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.get_encoder", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.get_encoder"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ":", "Any", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "h_params", "=", "kwargs", "[", "\"hparams\"", "]", "\n", "\n", "hidden_size", "=", "h_params", ".", "hidden_size", "\n", "self", ".", "srl_lang", "=", "h_params", ".", "srl_lang", "\n", "\n", "self", ".", "predicate_embedding", "=", "Embedding", "(", "num_embeddings", "=", "3", ",", "embedding_dim", "=", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "\n", "self", ".", "utterance_encoder", ",", "utterance_output_size", "=", "self", ".", "get_encoder", "(", "h_params", ".", "utterance_encoder_type", ",", "\n", "input_size", "=", "hidden_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "mha_heads", "=", "h_params", ".", "mha_heads", ",", "\n", "mha_num_layers", "=", "h_params", ".", "mha_num_layers", ",", "\n", "mha_dropout", "=", "h_params", ".", "mha_dropout", ",", "\n", "lstm_num_layers", "=", "h_params", ".", "lstm_num_layers", ",", "\n", "lstm_dropout", "=", "h_params", ".", "lstm_dropout", ",", "\n", "lstm_bidirectional", "=", "h_params", ".", "lstm_bidirectional", ")", "\n", "self", ".", "predicate_argument_encoder", ",", "pa_output_size", "=", "self", ".", "get_encoder", "(", "h_params", ".", "pa_encoder_type", ",", "\n", "input_size", "=", "hidden_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "mha_heads", "=", "h_params", ".", "mha_heads", ",", "\n", "mha_num_layers", "=", "h_params", ".", "mha_num_layers", ",", "\n", "mha_dropout", "=", "h_params", ".", "mha_dropout", ",", "\n", "lstm_num_layers", "=", "h_params", ".", "lstm_num_layers", ",", "\n", "lstm_dropout", "=", "h_params", ".", "lstm_dropout", ",", "\n", "lstm_bidirectional", "=", "h_params", ".", "lstm_bidirectional", ")", "\n", "self", ".", "srl_projector", "=", "torch", ".", "nn", ".", "Linear", "(", "utterance_output_size", "+", "hidden_size", ",", "hidden_size", ")", "\n", "\n", "self", ".", "argument_classifier", "=", "torch", ".", "nn", ".", "Linear", "(", "pa_output_size", ",", "h_params", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.srl_model.SRLModel.forward": [[42, 56], ["srl_model.SRLModel.encode_sent", "srl_model.SRLModel.predicate_embedding", "srl_model.SRLModel.utterance_encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "srl_model.SRLModel.srl_projector", "srl_model.SRLModel.predicate_argument_encoder", "srl_model.SRLModel.argument_classifier"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.encode_sent"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "predicate_ids", "=", "x", "[", "\"predicate_ids\"", "]", "\n", "\n", "# bsz, seq, dim", "\n", "_", ",", "word_embeddings", "=", "self", ".", "encode_sent", "(", "x", ")", "\n", "predicate_embeddings", "=", "self", ".", "predicate_embedding", "(", "predicate_ids", ")", "\n", "context_embeddings", "=", "self", ".", "utterance_encoder", "(", "word_embeddings", ",", "x", "[", "\"sequence_length\"", "]", ")", "\n", "context_embeddings", "=", "torch", ".", "cat", "(", "[", "context_embeddings", ",", "predicate_embeddings", "]", ",", "dim", "=", "-", "1", ")", "\n", "context_embeddings", "=", "self", ".", "srl_projector", "(", "context_embeddings", ")", "\n", "final_repr", "=", "self", ".", "predicate_argument_encoder", "(", "context_embeddings", ",", "x", "[", "\"sequence_length\"", "]", ")", "\n", "\n", "argument_logits", "=", "self", ".", "argument_classifier", "(", "final_repr", ")", "\n", "\n", "return", "argument_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.srl_model.SRLModel.training_step": [[57, 73], ["srl_model.SRLModel.", "torch.cross_entropy", "torch.cross_entropy", "srl_model.SRLModel.log", "srl_model.SRLModel.log", "srl_model.SRLModel.view", "batch[].view", "srl_model.SRLModel.optimizers", "srl_model.SRLModel.optimizers"], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_index", ")", ":", "\n", "        ", "argument_scores", "=", "self", "(", "batch", ")", "# (bsz, seq, dim)", "\n", "argument_classification_loss", "=", "F", ".", "cross_entropy", "(", "\n", "argument_scores", ".", "view", "(", "-", "1", ",", "self", ".", "h_params", ".", "num_labels", ")", ",", "\n", "batch", "[", "\"label\"", "]", ".", "view", "(", "-", "1", ")", ",", "\n", "reduction", "=", "'mean'", ",", "\n", "ignore_index", "=", "-", "100", "\n", ")", "\n", "loss", "=", "argument_classification_loss", "\n", "self", ".", "log", "(", "\"model_lr\"", ",", "self", ".", "optimizers", "(", ")", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "prog_bar", "=", "True", ",", "logger", "=", "False", ",", "on_epoch", "=", "False", ",", "\n", "on_step", "=", "True", ")", "\n", "self", ".", "log", "(", "\"lm_lr\"", ",", "self", ".", "optimizers", "(", ")", ".", "param_groups", "[", "1", "]", "[", "'lr'", "]", ",", "prog_bar", "=", "True", ",", "logger", "=", "False", ",", "on_epoch", "=", "False", ",", "\n", "on_step", "=", "True", ")", "\n", "\n", "return", "{", "\n", "\"loss\"", ":", "loss", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.srl_model.SRLModel.validation_step": [[75, 105], ["srl_model.SRLModel.", "torch.cross_entropy", "torch.cross_entropy", "torch.max", "torch.max", "torch.max", "torch.max", "batch[].contiguous().view", "prediction.contiguous().view.contiguous().view.contiguous().view", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.eq().float().to", "torch.eq().float().to", "torch.eq().float().to", "torch.eq().float().to", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "srl_model.SRLModel.view", "batch[].view", "torch.softmax", "torch.softmax", "torch.arange().unsqueeze().to", "torch.arange().unsqueeze().to", "torch.arange().unsqueeze().to", "torch.arange().unsqueeze().to", "sequence_lengths.unsqueeze", "torch.gt().float().to", "torch.gt().float().to", "torch.gt().float().to", "torch.gt().float().to", "torch.tensor().float.contiguous().view", "torch.tensor().float.contiguous().view", "batch[].contiguous", "prediction.contiguous().view.contiguous().view.contiguous", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.gt().float", "torch.gt().float", "torch.gt().float", "torch.gt().float", "torch.tensor().float.contiguous", "torch.tensor().float.contiguous", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "none_zero_mask.contiguous().view", "none_zero_mask.contiguous"], "methods", ["None"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_index", ")", ":", "\n", "        ", "sequence_lengths", "=", "batch", "[", "\"sequence_length\"", "]", "\n", "argument_scores", "=", "self", "(", "batch", ")", "\n", "max_seq_length", "=", "argument_scores", ".", "shape", "[", "1", "]", "\n", "argument_classification_loss", "=", "F", ".", "cross_entropy", "(", "\n", "argument_scores", ".", "view", "(", "-", "1", ",", "self", ".", "h_params", ".", "num_labels", ")", ",", "\n", "batch", "[", "\"label\"", "]", ".", "view", "(", "-", "1", ")", ",", "\n", "reduction", "=", "\"mean\"", ",", "\n", "ignore_index", "=", "-", "100", "\n", ")", "\n", "val_loss", "=", "argument_classification_loss", "\n", "_", ",", "prediction", "=", "torch", ".", "max", "(", "F", ".", "softmax", "(", "argument_scores", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "label", "=", "batch", "[", "\"label\"", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "prediction", "=", "prediction", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "token_mask", "=", "torch", ".", "arange", "(", "max_seq_length", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "self", ".", "device", ")", "<", "sequence_lengths", ".", "unsqueeze", "(", "1", ")", "\n", "token_mask", "=", "torch", ".", "tensor", "(", "token_mask", ")", ".", "float", "(", ")", "\n", "none_zero_mask", "=", "torch", ".", "gt", "(", "prediction", ",", "0", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "device", ")", "*", "token_mask", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "eq_num", "=", "torch", ".", "eq", "(", "prediction", ",", "label", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "eq_num", "=", "(", "eq_num", "*", "none_zero_mask", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ")", ".", "sum", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "total_pred_count", "=", "torch", ".", "sum", "(", "none_zero_mask", ")", ".", "cpu", "(", ")", "\n", "total_gold_count", "=", "torch", ".", "sum", "(", "torch", ".", "gt", "(", "label", ",", "0", ")", ")", ".", "cpu", "(", ")", "\n", "\n", "return", "{", "\n", "\"loss\"", ":", "val_loss", ",", "\n", "\"eq_num\"", ":", "eq_num", ",", "\n", "\"total_pred_num\"", ":", "total_pred_count", ",", "\n", "\"total_gold_num\"", ":", "total_gold_count", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.srl_model.SRLModel.validation_epoch_end": [[107, 121], ["torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "srl_model.SRLModel.log", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ":", "EPOCH_OUTPUT", ")", "->", "None", ":", "\n", "        ", "avg_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"loss\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "total_pred_num", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"total_pred_num\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "total_gold_num", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"total_gold_num\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "correct_num", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"eq_num\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "\n", "val_p", "=", "correct_num", "/", "total_pred_num", "\n", "val_r", "=", "correct_num", "/", "total_gold_num", "\n", "val_f1", "=", "2", "*", "val_p", "*", "val_r", "/", "(", "val_p", "+", "val_r", ")", "\n", "\n", "select_metrics", "=", "val_f1", "\n", "\n", "self", ".", "log", "(", "\"select_metrics\"", ",", "torch", ".", "tensor", "(", "select_metrics", ",", "device", "=", "self", ".", "device", ")", ",", "logger", "=", "False", ",", "on_epoch", "=", "True", ",", "\n", "on_step", "=", "False", ",", "prog_bar", "=", "True", ",", "sync_dist", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.srl_model.SRLModel.add_model_specific_args": [[122, 125], ["models.base_model.BaseModel.add_model_specific_args"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ")", ":", "\n", "        ", "return", "BaseModel", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.dialogue_model.DialogueModel.__init__": [[13, 58], ["models.base_model.BaseModel.__init__", "dialogue_model.DialogueModel.save_hyperparameters", "dialogue_model.DialogueModel.get_encoder", "dialogue_model.DialogueModel.get_encoder", "layers.state_encoder.StateEncoder", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.get_encoder", "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.get_encoder"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ":", "Any", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "h_params", "=", "kwargs", "[", "\"hparams\"", "]", "\n", "hidden_size", "=", "h_params", ".", "hidden_size", "\n", "\n", "self", ".", "h_params", "=", "h_params", "\n", "self", ".", "save_hyperparameters", "(", "h_params", ")", "\n", "\n", "self", ".", "utterance_encoder", ",", "utterance_output_size", "=", "self", ".", "get_encoder", "(", "h_params", ".", "utterance_encoder_type", ",", "\n", "input_size", "=", "hidden_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "mha_heads", "=", "h_params", ".", "mha_heads", ",", "\n", "mha_num_layers", "=", "h_params", ".", "mha_num_layers", ",", "\n", "mha_dropout", "=", "h_params", ".", "mha_dropout", ",", "\n", "lstm_num_layers", "=", "h_params", ".", "lstm_num_layers", ",", "\n", "lstm_dropout", "=", "h_params", ".", "lstm_dropout", ",", "\n", "lstm_bidirectional", "=", "h_params", ".", "lstm_bidirectional", ")", "\n", "self", ".", "dialogue_encoder", ",", "dialogue_output_size", "=", "self", ".", "get_encoder", "(", "h_params", ".", "dialogue_encoder_type", ",", "\n", "input_size", "=", "utterance_output_size", ",", "\n", "hidden_size", "=", "utterance_output_size", ",", "\n", "mha_heads", "=", "h_params", ".", "mha_heads", ",", "\n", "mha_num_layers", "=", "h_params", ".", "mha_num_layers", ",", "\n", "mha_dropout", "=", "h_params", ".", "mha_dropout", ",", "\n", "lstm_num_layers", "=", "h_params", ".", "lstm_num_layers", ",", "\n", "lstm_dropout", "=", "h_params", ".", "lstm_dropout", ",", "\n", "lstm_bidirectional", "=", "h_params", ".", "lstm_bidirectional", ")", "\n", "\n", "self", ".", "dialogue_feature_proj", "=", "StateEncoder", "(", "\n", "input_size", "=", "dialogue_output_size", ",", "\n", "output_size", "=", "hidden_size", ",", "\n", "state_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "1", ",", "\n", "activation", "=", "'swish'", ",", "\n", "dropout_rate", "=", "h_params", ".", "dropout", ",", "\n", ")", "\n", "\n", "self", ".", "is_reorder", "=", "h_params", ".", "is_reorder", "\n", "self", ".", "is_role_detection", "=", "h_params", ".", "is_role_detection", "\n", "\n", "if", "self", ".", "is_reorder", ":", "\n", "            ", "self", ".", "turn_decoder", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_size", ",", "11", ",", "bias", "=", "False", ")", "\n", "", "if", "self", ".", "is_role_detection", ":", "\n", "            ", "self", ".", "speaker_decoder", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_size", ",", "2", ",", "bias", "=", "False", ")", "\n", "", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "turn_decoder", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "hidden_size", "**", "-", "0.5", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "speaker_decoder", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "hidden_size", "**", "-", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.dialogue_model.DialogueModel.forward": [[59, 74], ["dialogue_model.DialogueModel.word_encoder", "max", "dialogue_model.DialogueModel.utterance_encoder", "torch_scatter.scatter_mean", "max", "dialogue_model.DialogueModel.dialogue_encoder", "dialogue_model.DialogueModel.dialogue_feature_proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_", ",", "word_embeddings", "=", "self", ".", "word_encoder", "(", "x", "[", "\"input_ids\"", "]", ",", "subword_indices", "=", "x", "[", "\"subword_indices\"", "]", ",", "\n", "sequence_lengths", "=", "x", "[", "\"tokenized_sequence_length\"", "]", ")", "\n", "max_sequence_length", "=", "max", "(", "x", "[", "\"sequence_length\"", "]", ")", "\n", "word_embeddings", "=", "word_embeddings", "[", ":", ",", "1", ":", "max_sequence_length", "+", "1", ",", ":", "]", "\n", "\n", "utterance_feature", "=", "self", ".", "utterance_encoder", "(", "word_embeddings", ",", "x", "[", "\"sequence_length\"", "]", ")", "\n", "gathered_utterance_feature", "=", "scatter_mean", "(", "utterance_feature", ",", "index", "=", "x", "[", "\"dialogue_indices\"", "]", ",", "dim", "=", "1", ")", "\n", "\n", "max_utterance_num", "=", "max", "(", "x", "[", "\"utterance_num\"", "]", ")", "\n", "gathered_utterance_feature", "=", "gathered_utterance_feature", "[", ":", ",", "1", ":", "max_utterance_num", "+", "1", ",", ":", "]", "\n", "dialogue_feature", "=", "self", ".", "dialogue_encoder", "(", "gathered_utterance_feature", ",", "x", "[", "\"utterance_num\"", "]", ")", "\n", "dialogue_feature", "=", "self", ".", "dialogue_feature_proj", "(", "dialogue_feature", ")", "\n", "\n", "return", "dialogue_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.dialogue_model.DialogueModel.__shared_step": [[75, 115], ["dialogue_model.DialogueModel.", "dialogue_model.DialogueModel.turn_decoder", "torch.cross_entropy", "torch.cross_entropy", "dialogue_model.DialogueModel.", "dialogue_model.DialogueModel.speaker_decoder", "torch.cross_entropy", "torch.cross_entropy", "dialogue_model.DialogueModel.view", "batch[].view", "dialogue_model.DialogueModel.view", "batch[].view"], "methods", ["None"], ["", "def", "__shared_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "reorder_loss", ",", "role_loss", "=", "0", ",", "0", "\n", "reorder_logits", ",", "role_logits", "=", "None", ",", "None", "\n", "if", "self", ".", "is_reorder", ":", "\n", "            ", "dialogue_feature", "=", "self", "(", "{", "\n", "\"input_ids\"", ":", "batch", "[", "\"reorder_input_ids\"", "]", ",", "\n", "\"subword_indices\"", ":", "batch", "[", "\"reorder_subword_indices\"", "]", ",", "\n", "\"tokenized_sequence_length\"", ":", "batch", "[", "\"reorder_tokenized_sequence_length\"", "]", ",", "\n", "\"sequence_length\"", ":", "batch", "[", "\"reorder_sequence_length\"", "]", ",", "\n", "\"position_ids\"", ":", "batch", "[", "\"reorder_position_ids\"", "]", ",", "\n", "\"dialogue_indices\"", ":", "batch", "[", "\"reorder_dialogue_indices\"", "]", ",", "\n", "\"utterance_num\"", ":", "batch", "[", "\"reorder_utterance_num\"", "]", "\n", "}", ")", "\n", "reorder_logits", "=", "self", ".", "turn_decoder", "(", "dialogue_feature", ")", "\n", "reorder_loss", "=", "F", ".", "cross_entropy", "(", "\n", "reorder_logits", ".", "view", "(", "-", "1", ",", "11", ")", ",", "\n", "batch", "[", "\"reorder_label\"", "]", ".", "view", "(", "-", "1", ")", ",", "\n", "ignore_index", "=", "-", "100", ",", "\n", "reduction", "=", "'mean'", "\n", ")", "\n", "\n", "", "if", "self", ".", "is_role_detection", ":", "\n", "            ", "dialogue_feature", "=", "self", "(", "{", "\n", "\"input_ids\"", ":", "batch", "[", "\"role_input_ids\"", "]", ",", "\n", "\"subword_indices\"", ":", "batch", "[", "\"role_subword_indices\"", "]", ",", "\n", "\"tokenized_sequence_length\"", ":", "batch", "[", "\"role_tokenized_sequence_length\"", "]", ",", "\n", "\"sequence_length\"", ":", "batch", "[", "\"role_sequence_length\"", "]", ",", "\n", "\"position_ids\"", ":", "batch", "[", "\"role_position_ids\"", "]", ",", "\n", "\"dialogue_indices\"", ":", "batch", "[", "\"role_dialogue_indices\"", "]", ",", "\n", "\"utterance_num\"", ":", "batch", "[", "\"role_utterance_num\"", "]", "\n", "}", ")", "\n", "role_logits", "=", "self", ".", "speaker_decoder", "(", "dialogue_feature", ")", "\n", "role_loss", "=", "F", ".", "cross_entropy", "(", "\n", "role_logits", ".", "view", "(", "-", "1", ",", "2", ")", ",", "\n", "batch", "[", "\"role_label\"", "]", ".", "view", "(", "-", "1", ")", ",", "\n", "ignore_index", "=", "-", "100", ",", "\n", "reduction", "=", "'mean'", "\n", ")", "\n", "", "loss", "=", "reorder_loss", "+", "role_loss", "\n", "return", "loss", ",", "reorder_loss", ",", "role_loss", ",", "(", "reorder_logits", ",", "role_logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.dialogue_model.DialogueModel.training_step": [[116, 125], ["dialogue_model.DialogueModel.__shared_step", "dialogue_model.DialogueModel.log", "dialogue_model.DialogueModel.log", "dialogue_model.DialogueModel.optimizers", "dialogue_model.DialogueModel.optimizers"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.dialogue_model.DialogueModel.__shared_step"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_index", ")", "->", "STEP_OUTPUT", ":", "\n", "        ", "loss", ",", "reorder_loss", ",", "role_loss", ",", "_", "=", "self", ".", "__shared_step", "(", "batch", ")", "\n", "\n", "self", ".", "log", "(", "\"model_lr\"", ",", "self", ".", "optimizers", "(", ")", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "prog_bar", "=", "True", ",", "logger", "=", "False", ",", "on_epoch", "=", "False", ",", "\n", "on_step", "=", "True", ")", "\n", "self", ".", "log", "(", "\"lm_lr\"", ",", "self", ".", "optimizers", "(", ")", ".", "param_groups", "[", "1", "]", "[", "'lr'", "]", ",", "prog_bar", "=", "True", ",", "logger", "=", "False", ",", "on_epoch", "=", "False", ",", "\n", "on_step", "=", "True", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.dialogue_model.DialogueModel.validation_step": [[126, 147], ["dialogue_model.DialogueModel.__shared_step", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.eq().sum().float().to", "torch.eq().sum().float().to", "torch.eq().sum().float().to", "torch.eq().sum().float().to", "torch.gt().sum().float", "torch.gt().sum().float", "torch.gt().sum().float", "torch.gt().sum().float", "torch.eq().sum().float().to", "torch.eq().sum().float().to", "torch.eq().sum().float().to", "torch.eq().sum().float().to", "torch.gt().sum().float", "torch.gt().sum().float", "torch.gt().sum().float", "torch.gt().sum().float", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.eq().sum().float", "torch.eq().sum().float", "torch.eq().sum().float", "torch.eq().sum().float", "torch.gt().sum", "torch.gt().sum", "torch.gt().sum", "torch.gt().sum", "torch.eq().sum().float", "torch.eq().sum().float", "torch.eq().sum().float", "torch.eq().sum().float", "torch.gt().sum", "torch.gt().sum", "torch.gt().sum", "torch.gt().sum", "torch.eq().sum", "torch.eq().sum", "torch.eq().sum", "torch.eq().sum", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "torch.eq().sum", "torch.eq().sum", "torch.eq().sum", "torch.eq().sum", "torch.gt", "torch.gt", "torch.gt", "torch.gt", "batch[].view", "batch[].view", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "reorder_prediction.view", "batch[].view", "role_prediction.view", "batch[].view"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.dialogue_model.DialogueModel.__shared_step"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_index", ")", "->", "Optional", "[", "STEP_OUTPUT", "]", ":", "\n", "        ", "loss", ",", "reorder_loss", ",", "role_loss", ",", "(", "reorder_logits", ",", "role_logits", ")", "=", "self", ".", "__shared_step", "(", "batch", ")", "\n", "\n", "_", ",", "reorder_prediction", "=", "torch", ".", "max", "(", "F", ".", "softmax", "(", "reorder_logits", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "\n", "_", ",", "role_prediction", "=", "torch", ".", "max", "(", "F", ".", "softmax", "(", "role_logits", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "reorder_eq_num", "=", "torch", ".", "eq", "(", "reorder_prediction", ".", "view", "(", "-", "1", ")", ",", "batch", "[", "\"reorder_label\"", "]", ".", "view", "(", "-", "1", ")", ")", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "to", "(", "\n", "self", ".", "device", ")", "\n", "reorder_total_num", "=", "torch", ".", "gt", "(", "batch", "[", "\"reorder_label\"", "]", ".", "view", "(", "-", "1", ")", ",", "-", "1", ")", ".", "sum", "(", ")", ".", "float", "(", ")", "\n", "\n", "role_eq_num", "=", "torch", ".", "eq", "(", "role_prediction", ".", "view", "(", "-", "1", ")", ",", "batch", "[", "\"role_label\"", "]", ".", "view", "(", "-", "1", ")", ")", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "role_total_num", "=", "torch", ".", "gt", "(", "batch", "[", "\"role_label\"", "]", ".", "view", "(", "-", "1", ")", ",", "-", "1", ")", ".", "sum", "(", ")", ".", "float", "(", ")", "\n", "\n", "return", "{", "\n", "\"loss\"", ":", "loss", ",", "\n", "\"reorder_loss\"", ":", "reorder_loss", ",", "\n", "\"role_loss\"", ":", "role_loss", ",", "\n", "\"reorder_eq_num\"", ":", "reorder_eq_num", ",", "\n", "\"reorder_total_num\"", ":", "reorder_total_num", ",", "\n", "\"role_eq_num\"", ":", "role_eq_num", ",", "\n", "\"role_total_num\"", ":", "role_total_num", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.dialogue_model.DialogueModel.validation_epoch_end": [[149, 174], ["torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "print", "print", "print", "print", "print", "print", "print", "dialogue_model.DialogueModel.log", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ":", "EPOCH_OUTPUT", ")", "->", "None", ":", "\n", "        ", "avg_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"loss\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "avg_reorder_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"reorder_loss\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "avg_role_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"role_loss\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "\n", "total_reorder_eq_num", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"reorder_eq_num\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "total_reorder_total_num", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"reorder_total_num\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "total_role_eq_num", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"role_eq_num\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "total_role_total_num", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"role_total_num\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "sum", "(", ")", "\n", "\n", "reorder_acc", "=", "total_reorder_eq_num", "/", "total_reorder_total_num", "if", "total_reorder_total_num", "!=", "0", "else", "0", "\n", "role_acc", "=", "total_role_eq_num", "/", "total_role_total_num", "if", "total_role_total_num", "!=", "0", "else", "0", "\n", "\n", "select_metrics", "=", "avg_loss", "\n", "\n", "print", "(", "\"========================\"", ")", "\n", "print", "(", "\"avg loss: {}\"", ".", "format", "(", "avg_loss", ")", ")", "\n", "print", "(", "\"avg_reorder_loss: {}\"", ".", "format", "(", "avg_reorder_loss", ")", ")", "\n", "print", "(", "\"avg_role_loss: {}\"", ".", "format", "(", "avg_role_loss", ")", ")", "\n", "print", "(", "\"reorder accuracy: {}\"", ".", "format", "(", "reorder_acc", ")", ")", "\n", "print", "(", "\"role accuracy: {}\"", ".", "format", "(", "role_acc", ")", ")", "\n", "print", "(", "\"========================\"", ")", "\n", "\n", "self", ".", "log", "(", "\"select_metrics\"", ",", "torch", ".", "tensor", "(", "select_metrics", ",", "device", "=", "self", ".", "device", ")", ",", "prog_bar", "=", "True", ",", "logger", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "on_step", "=", "False", ",", "sync_dist", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.dialogue_model.DialogueModel.add_model_specific_args": [[175, 178], ["models.base_model.BaseModel.add_model_specific_args"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ")", ":", "\n", "        ", "return", "BaseModel", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__": [[15, 27], ["pytorch_lightning.LightningModule.__init__", "hasattr", "layers.word_encoder.WordEncoder"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ":", "Any", ")", "->", "None", ":", "\n", "        ", "super", "(", "BaseModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "h_params", "=", "kwargs", "[", "\"hparams\"", "]", "\n", "self", ".", "h_params", "=", "h_params", "\n", "\n", "if", "hasattr", "(", "h_params", ",", "\"vocab_size\"", ")", ":", "\n", "            ", "vocab_size", "=", "h_params", ".", "vocab_size", "\n", "", "else", ":", "\n", "            ", "vocab_size", "=", "None", "\n", "", "self", ".", "word_encoder", "=", "WordEncoder", "(", "language_model", "=", "h_params", ".", "language_model", ",", "fine_tune", "=", "h_params", ".", "fine_tune_lm", ",", "\n", "vocab_size", "=", "vocab_size", ",", "word_dropout", "=", "h_params", ".", "word_dropout", ",", "\n", "hidden_size", "=", "h_params", ".", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.get_encoder": [[28, 51], ["layers.sequence_encoder.SequenceEncoder", "layers.sequence_encoder.SequenceEncoder", "ValueError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_encoder", "(", "encoder_type", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "'lstm'", "in", "encoder_type", ":", "\n", "            ", "encoder", "=", "SequenceEncoder", "(", "\n", "encoder_type", "=", "encoder_type", ",", "\n", "lstm_input_size", "=", "kwargs", "[", "\"input_size\"", "]", ",", "\n", "lstm_hidden_size", "=", "kwargs", "[", "\"hidden_size\"", "]", ",", "\n", "lstm_num_layers", "=", "kwargs", "[", "\"lstm_num_layers\"", "]", ",", "\n", "lstm_dropout", "=", "kwargs", "[", "\"lstm_dropout\"", "]", ",", "\n", "lstm_bidirectional", "=", "kwargs", "[", "\"lstm_bidirectional\"", "]", ",", "\n", "pack_sequences", "=", "True", "\n", ")", "\n", "", "elif", "encoder_type", "==", "'connected_mha'", ":", "\n", "            ", "encoder", "=", "SequenceEncoder", "(", "\n", "encoder_type", "=", "encoder_type", ",", "\n", "input_size", "=", "kwargs", "[", "\"input_size\"", "]", ",", "\n", "mha_num_heads", "=", "kwargs", "[", "\"mha_heads\"", "]", ",", "\n", "mha_num_layers", "=", "kwargs", "[", "\"mha_num_layers\"", "]", ",", "\n", "mha_dropout", "=", "kwargs", "[", "\"mha_dropout\"", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unexpected encoder type {}\"", ".", "format", "(", "encoder_type", ")", ")", "\n", "", "return", "encoder", ",", "encoder", ".", "sequence_state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.encode_sent": [[52, 66], ["max", "base_model.BaseModel.word_encoder"], "methods", ["None"], ["", "def", "encode_sent", "(", "self", ",", "x", ")", ":", "\n", "        ", "word_ids", "=", "x", "[", "\"word_ids\"", "]", "\n", "sequence_length", "=", "x", "[", "\"sequence_length\"", "]", "\n", "subword_indices", "=", "x", "[", "\"subword_indices\"", "]", "\n", "tokenized_sequence_length", "=", "x", "[", "\"tokenized_sequence_length\"", "]", "\n", "\n", "max_sequence_length", "=", "max", "(", "sequence_length", ")", "\n", "\n", "# bsz, t_seq, dim", "\n", "token_embeddings", ",", "word_embeddings", "=", "self", ".", "word_encoder", "(", "word_ids", ",", "subword_indices", ",", "tokenized_sequence_length", ")", "\n", "# bsz, seq, dim", "\n", "word_embeddings", "=", "word_embeddings", "[", ":", ",", "1", ":", "max_sequence_length", "+", "1", ",", ":", "]", "\n", "\n", "return", "token_embeddings", ",", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.get_lr_scheduler": [[67, 83], ["torch.optim.lr_scheduler.CosineAnnealingLR", "torch.optim.lr_scheduler.ReduceLROnPlateau", "ValueError"], "methods", ["None"], ["", "def", "get_lr_scheduler", "(", "self", ",", "optimizer", ")", ":", "\n", "        ", "if", "self", ".", "h_params", ".", "lr_scheduler", "is", "None", "or", "self", ".", "h_params", ".", "lr_scheduler", "==", "'linear'", ":", "\n", "            ", "return", "None", "\n", "", "if", "self", ".", "h_params", ".", "lr_scheduler", "==", "'cosine'", ":", "\n", "            ", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "CosineAnnealingLR", "(", "optimizer", ",", "self", ".", "h_params", ".", "max_epochs", ",", "eta_min", "=", "1e-6", ")", "\n", "interval", "=", "'epoch'", "\n", "", "elif", "self", ".", "h_params", ".", "lr_scheduler", "==", "'plateau'", ":", "\n", "            ", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'max'", ",", "factor", "=", "0.5", ",", "patience", "=", "3", ",", "\n", "min_lr", "=", "1e-6", ")", "\n", "interval", "=", "'epoch'", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unexpected lr_scheduler: {}\"", ".", "format", "(", "self", ".", "h_params", ".", "lr_scheduler", ")", ")", "\n", "", "scheduler_dict", "=", "{", "\"scheduler\"", ":", "lr_scheduler", ",", "\"interval\"", ":", "interval", "}", "\n", "if", "self", ".", "h_params", ".", "lr_scheduler", "==", "'plateau'", ":", "\n", "            ", "scheduler_dict", "[", "\"monitor\"", "]", "=", "'select_metrics'", "\n", "", "return", "scheduler_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.optimizer_step": [[84, 130], ["optimizer.step", "optimizer.zero_grad", "max", "base_model.BaseModel.named_parameters", "print", "min", "base_model.BaseModel.h_params.unfreeze_layer_names.split", "base_model.BaseModel.h_params.permanent_frozen_layers.split", "any", "total_para.append", "min", "any", "trainable_para.append", "non_trainable_para.append", "parameter.numel", "sum", "sum", "sum", "float", "float", "print", "parameter.numel", "parameter.numel", "float", "max"], "methods", ["None"], ["", "def", "optimizer_step", "(", "self", ",", "epoch", ":", "int", "=", "None", ",", "batch_idx", ":", "int", "=", "None", ",", "optimizer", ":", "Optimizer", "=", "None", ",", "\n", "optimizer_idx", ":", "int", "=", "None", ",", "optimizer_closure", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "on_tpu", ":", "bool", "=", "None", ",", "\n", "using_native_amp", ":", "bool", "=", "None", ",", "using_lbfgs", ":", "bool", "=", "None", ")", "->", "None", ":", "\n", "        ", "step", "=", "self", ".", "trainer", ".", "global_step", "\n", "if", "step", "==", "max", "(", "self", ".", "h_params", ".", "frozen_steps", ",", "self", ".", "h_params", ".", "steps_per_epoch", "*", "self", ".", "h_params", ".", "frozen_epochs", ")", ":", "\n", "            ", "unfreeze_layers", "=", "self", ".", "h_params", ".", "unfreeze_layer_names", ".", "split", "(", "\",\"", ")", "if", "self", ".", "h_params", ".", "unfreeze_layer_names", "is", "not", "None", "else", "[", "]", "\n", "permanent_frozen_layers", "=", "self", ".", "h_params", ".", "permanent_frozen_layers", ".", "split", "(", "\",\"", ")", "if", "self", ".", "h_params", ".", "permanent_frozen_layers", "is", "not", "None", "else", "[", "]", "\n", "\n", "total_para", ",", "trainable_para", ",", "non_trainable_para", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "name", ",", "parameter", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "any", "(", "[", "x", "in", "name", "for", "x", "in", "permanent_frozen_layers", "]", ")", ":", "\n", "                    ", "parameter", ".", "requires_grad", "=", "False", "\n", "", "elif", "any", "(", "[", "_", "in", "name", "for", "_", "in", "unfreeze_layers", "]", ")", ":", "\n", "                    ", "print", "(", "\"Parameters named {} UNFREEZE.\"", ".", "format", "(", "name", ")", ")", "\n", "parameter", ".", "requires_grad", "=", "True", "\n", "", "if", "parameter", ".", "requires_grad", ":", "\n", "                    ", "trainable_para", ".", "append", "(", "parameter", ".", "numel", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "non_trainable_para", ".", "append", "(", "parameter", ".", "numel", "(", ")", ")", "\n", "", "total_para", ".", "append", "(", "parameter", ".", "numel", "(", ")", ")", "\n", "", "print", "(", "\"Trainable params: {}\\nNon-trainable params: {}\\nTotal params: {}\\n\"", ".", "format", "(", "\n", "sum", "(", "trainable_para", ")", ",", "sum", "(", "non_trainable_para", ")", ",", "sum", "(", "total_para", ")", ")", ")", "\n", "\n", "", "if", "self", ".", "h_params", ".", "lr_scheduler", "==", "'linear'", ":", "\n", "            ", "warmup_steps", "=", "self", ".", "h_params", ".", "warmup_epochs", "*", "self", ".", "h_params", ".", "steps_per_epoch", "\n", "training_steps", "=", "min", "(", "self", ".", "h_params", ".", "max_epochs", "*", "self", ".", "h_params", ".", "steps_per_epoch", ",", "self", ".", "h_params", ".", "max_steps", ")", "\n", "\n", "if", "step", "<", "warmup_steps", ":", "\n", "                ", "lr_scale", "=", "min", "(", "1.", ",", "float", "(", "step", "+", "1", ")", "/", "warmup_steps", ")", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr_scale", "*", "self", ".", "h_params", ".", "model_lr", "\n", "optimizer", ".", "param_groups", "[", "1", "]", "[", "'lr'", "]", "=", "lr_scale", "*", "self", ".", "h_params", ".", "lm_lr", "\n", "optimizer", ".", "param_groups", "[", "2", "]", "[", "'lr'", "]", "=", "lr_scale", "*", "self", ".", "h_params", ".", "small_lr", "\n", "", "else", ":", "\n", "                ", "progress", "=", "float", "(", "step", "-", "warmup_steps", ")", "/", "float", "(", "max", "(", "1", ",", "training_steps", "-", "warmup_steps", ")", ")", "\n", "lr_scale", "=", "(", "1.", "-", "progress", ")", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "h_params", ".", "min_model_lr", "+", "lr_scale", "*", "(", "self", ".", "h_params", ".", "model_lr", "-", "\n", "self", ".", "h_params", ".", "min_model_lr", ")", "\n", "optimizer", ".", "param_groups", "[", "1", "]", "[", "'lr'", "]", "=", "self", ".", "h_params", ".", "min_lm_lr", "+", "lr_scale", "*", "(", "self", ".", "h_params", ".", "lm_lr", "-", "\n", "self", ".", "h_params", ".", "min_lm_lr", ")", "\n", "optimizer", ".", "param_groups", "[", "2", "]", "[", "'lr'", "]", "=", "self", ".", "h_params", ".", "min_small_lr", "+", "lr_scale", "*", "(", "self", ".", "h_params", ".", "small_lr", "-", "\n", "self", ".", "h_params", ".", "min_small_lr", ")", "\n", "\n", "", "", "optimizer", ".", "step", "(", "closure", "=", "optimizer_closure", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.configure_optimizers": [[131, 173], ["base_model.BaseModel.named_parameters", "torch.optim.AdamW", "base_model.BaseModel.get_lr_scheduler", "base_model.BaseModel.h_params.frozen_layer_names.split", "base_model.BaseModel.h_params.small_lr_group.split", "any", "no_decay_params.append", "any", "language_model_params.append", "any", "print", "small_lr_params.append", "base_params.append"], "methods", ["home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.get_lr_scheduler"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "base_params", "=", "[", "]", "\n", "language_model_params", "=", "[", "]", "\n", "no_decay_params", "=", "[", "]", "\n", "small_lr_params", "=", "[", "]", "\n", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "\n", "frozen_layer_names", "=", "self", ".", "h_params", ".", "frozen_layer_names", ".", "split", "(", "\",\"", ")", "if", "self", ".", "h_params", ".", "frozen_layer_names", "is", "not", "None", "else", "[", "]", "\n", "\n", "small_lr_group", "=", "self", ".", "h_params", ".", "small_lr_group", ".", "split", "(", "\",\"", ")", "if", "self", ".", "h_params", ".", "small_lr_group", "is", "not", "None", "else", "[", "]", "\n", "\n", "for", "name", ",", "parameter", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "any", "(", "nd", "in", "name", "for", "nd", "in", "no_decay", ")", ":", "\n", "                ", "no_decay_params", ".", "append", "(", "parameter", ")", "\n", "", "else", ":", "\n", "                ", "if", "'language_model'", "in", "name", ":", "\n", "                    ", "language_model_params", ".", "append", "(", "parameter", ")", "\n", "", "elif", "any", "(", "[", "_", "in", "name", "for", "_", "in", "small_lr_group", "]", ")", ":", "\n", "                    ", "small_lr_params", ".", "append", "(", "parameter", ")", "\n", "", "else", ":", "\n", "                    ", "base_params", ".", "append", "(", "parameter", ")", "\n", "", "if", "any", "(", "[", "_", "in", "name", "for", "_", "in", "frozen_layer_names", "]", ")", ":", "\n", "                    ", "print", "(", "\"Parameters named {} FROZEN.\"", ".", "format", "(", "name", ")", ")", "\n", "parameter", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "", "optimizer", "=", "torch", ".", "optim", ".", "AdamW", "(", "\n", "[", "\n", "{", "'params'", ":", "base_params", ",", "'lr'", ":", "self", ".", "h_params", ".", "model_lr", ",", "'weight_decay'", ":", "self", ".", "h_params", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "language_model_params", ",", "'lr'", ":", "self", ".", "h_params", ".", "lm_lr", ",", "\n", "'weight_decay'", ":", "self", ".", "h_params", ".", "lm_weight_decay", ",", "'correct_bias'", ":", "False", "}", ",", "\n", "{", "'params'", ":", "small_lr_params", ",", "'lr'", ":", "self", ".", "h_params", ".", "small_lr", ",", "'weight_decay'", ":", "self", ".", "h_params", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "no_decay_params", ",", "'lr'", ":", "2e-5", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", ")", "\n", "\n", "scheduler_dict", "=", "self", ".", "get_lr_scheduler", "(", "optimizer", ")", "\n", "\n", "if", "scheduler_dict", ":", "\n", "            ", "return", "[", "optimizer", "]", ",", "[", "scheduler_dict", "]", "\n", "", "else", ":", "\n", "            ", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.models.base_model.BaseModel.add_model_specific_args": [[174, 220], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ")", ":", "\n", "        ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "parents", "=", "[", "parent_parser", "]", ",", "add_help", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--language_model\"", ",", "type", "=", "str", ",", "default", "=", "\"xlm-roberta-base\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--word_dropout\"", ",", "type", "=", "float", ",", "default", "=", "0.4", ")", "\n", "parser", ".", "add_argument", "(", "\"--dropout\"", ",", "type", "=", "float", ",", "default", "=", "0.2", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_role_info\"", ",", "type", "=", "str2bool", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_turn_info\"", ",", "type", "=", "str2bool", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--hidden_size\"", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "parser", ".", "add_argument", "(", "\"--activation_fn\"", ",", "type", "=", "str", ",", "default", "=", "'swish'", ")", "\n", "\n", "# learning rate and weight decay", "\n", "parser", ".", "add_argument", "(", "\"--model_lr\"", ",", "type", "=", "float", ",", "default", "=", "5e-5", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_model_lr\"", ",", "type", "=", "float", ",", "default", "=", "5e-5", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "type", "=", "float", ",", "default", "=", "1e-4", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--lm_lr\"", ",", "type", "=", "float", ",", "default", "=", "5e-5", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_lm_lr\"", ",", "type", "=", "float", ",", "default", "=", "5e-5", ")", "\n", "parser", ".", "add_argument", "(", "\"--lm_weight_decay\"", ",", "type", "=", "float", ",", "default", "=", "1e-4", ")", "\n", "parser", ".", "add_argument", "(", "\"--fine_tune_lm\"", ",", "type", "=", "str2bool", ",", "default", "=", "False", ")", "\n", "\n", "# warmup", "\n", "parser", ".", "add_argument", "(", "\"--warmup_epochs\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr_scheduler\"", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "\n", "# Sequence LSTM", "\n", "parser", ".", "add_argument", "(", "\"--lstm_num_layers\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--lstm_dropout\"", ",", "type", "=", "float", ",", "default", "=", "0.2", ")", "\n", "parser", ".", "add_argument", "(", "\"--lstm_bidirectional\"", ",", "type", "=", "str2bool", ",", "default", "=", "False", ")", "\n", "\n", "# self attention", "\n", "parser", ".", "add_argument", "(", "\"--mha_heads\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "\"--mha_num_layers\"", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "\"--mha_dropout\"", ",", "type", "=", "float", ",", "default", "=", "0.2", ")", "\n", "\n", "# encoder type", "\n", "parser", ".", "add_argument", "(", "\"--utterance_encoder_type\"", ",", "type", "=", "str", ",", "default", "=", "'connected_lstm'", ")", "\n", "parser", ".", "add_argument", "(", "\"--dialogue_encoder_type\"", ",", "type", "=", "str", ",", "default", "=", "'connected_lstm'", ")", "\n", "parser", ".", "add_argument", "(", "\"--pa_encoder_type\"", ",", "type", "=", "str", ",", "default", "=", "'connected_lstm'", ")", "\n", "\n", "# training with minimum lr", "\n", "parser", ".", "add_argument", "(", "\"--small_lr_group\"", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--small_lr\"", ",", "type", "=", "float", ",", "default", "=", "5e-5", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_small_lr\"", ",", "type", "=", "float", ",", "default", "=", "5e-5", ")", "\n", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.srl_data.conll_preprocess.load_vocab": [[2, 11], ["open", "symbol.strip.strip", "len"], "function", ["None"], ["def", "load_vocab", "(", "path", ",", "symbol_idx", "=", "None", ")", ":", "\n", "    ", "if", "symbol_idx", "is", "None", ":", "\n", "        ", "symbol_idx", "=", "{", "}", "\n", "", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fr", ":", "\n", "        ", "for", "symbol", "in", "fr", ":", "\n", "            ", "symbol", "=", "symbol", ".", "strip", "(", ")", "\n", "if", "symbol", "not", "in", "symbol_idx", ":", "\n", "                ", "symbol_idx", "[", "symbol", "]", "=", "len", "(", "symbol_idx", ")", "\n", "", "", "", "return", "symbol_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.hahahawu_zero-shot-xcsrl.srl_data.conll_preprocess.gen_labeled_data": [[13, 40], ["open", "open", "line.strip().split", "words.strip().split.strip().split", "labels.strip().split.strip().split", "fw.write", "int", "len", "len", "line.strip", "words.strip().split.strip", "labels.strip().split.strip", "new_label.append", "new_label.append", "la.replace().replace.replace().replace", "new_label.append", "new_label.append", "str", "la.replace().replace.replace"], "function", ["None"], ["", "def", "gen_labeled_data", "(", "in_path", ",", "out_file", ",", "explicit_arg", "=", "False", ")", ":", "\n", "    ", "with", "open", "(", "in_path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fr", ",", "open", "(", "out_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fw", ":", "\n", "        ", "for", "line", "in", "fr", ":", "\n", "            ", "words", ",", "labels", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"|||\"", ")", "\n", "words", "=", "words", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "pred", ",", "words", "=", "int", "(", "words", "[", "0", "]", ")", ",", "words", "[", "1", ":", "]", "\n", "labels", "=", "labels", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "assert", "len", "(", "words", ")", "==", "len", "(", "labels", ")", "\n", "assert", "labels", "[", "pred", "]", "==", "'B-V'", "\n", "new_label", "=", "[", "]", "\n", "for", "la", "in", "labels", ":", "\n", "                ", "if", "la", "[", "2", ":", "]", "in", "allow_arguments", ":", "\n", "                    ", "if", "explicit_arg", ":", "\n", "                        ", "if", "la", "not", "in", "target_labels", ":", "\n", "                            ", "la", "=", "la", ".", "replace", "(", "\"ARGM-\"", ",", "\"\"", ")", ".", "replace", "(", "\"C-\"", ",", "\"\"", ")", "\n", "if", "la", "[", "2", ":", "5", "]", "==", "\"ARG\"", ":", "\n", "                                ", "la", "=", "la", "[", ":", "2", "]", "+", "\"ARG\"", "\n", "", "", "assert", "la", "in", "target_labels", "\n", "new_label", ".", "append", "(", "la", ")", "\n", "", "else", ":", "\n", "                        ", "if", "la", "[", "2", ":", "]", "==", "'V'", ":", "\n", "                            ", "new_label", ".", "append", "(", "la", ")", "\n", "", "else", ":", "\n", "                            ", "new_label", ".", "append", "(", "la", "[", ":", "2", "]", "+", "\"ARG\"", ")", "\n", "", "", "", "else", ":", "\n", "                    ", "new_label", ".", "append", "(", "\"O\"", ")", "\n", "", "", "fw", ".", "write", "(", "\"|||\"", ".", "join", "(", "[", "str", "(", "pred", ")", ",", "\" \"", ".", "join", "(", "words", ")", ",", "\" \"", ".", "join", "(", "new_label", ")", "]", ")", "+", "\"\\n\"", ")", "\n", "\n"]]}