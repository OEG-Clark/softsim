{"home.repos.pwc.inspect_result.google-research_fitvid.None.models.MultiGaussianLSTM.setup": [[37, 42], ["flax.linen.Dense", "flax.linen.Dense", "flax.linen.Dense", "flax.linen.recurrent.LSTMCell", "range"], "methods", ["None"], ["def", "setup", "(", "self", ")", ":", "\n", "    ", "self", ".", "embed", "=", "nn", ".", "Dense", "(", "self", ".", "hidden_size", ")", "\n", "self", ".", "mean", "=", "nn", ".", "Dense", "(", "self", ".", "output_size", ")", "\n", "self", ".", "logvar", "=", "nn", ".", "Dense", "(", "self", ".", "output_size", ")", "\n", "self", ".", "layers", "=", "[", "nn", ".", "recurrent", ".", "LSTMCell", "(", ")", "for", "_", "in", "range", "(", "self", ".", "num_layers", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.models.MultiGaussianLSTM.init_states": [[43, 53], ["functools.partial", "range", "flax.linen.recurrent.LSTMCell.initialize_carry", "models.MultiGaussianLSTM.make_rng"], "methods", ["None"], ["", "def", "init_states", "(", "self", ",", "batch_size", ")", ":", "\n", "    ", "init_fn", "=", "functools", ".", "partial", "(", "initializers", ".", "zeros", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", "states", "=", "[", "None", "]", "*", "self", ".", "num_layers", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "      ", "states", "[", "i", "]", "=", "nn", ".", "recurrent", ".", "LSTMCell", ".", "initialize_carry", "(", "\n", "self", ".", "make_rng", "(", "'rng'", ")", ",", "\n", "(", "batch_size", ",", ")", ",", "\n", "self", ".", "hidden_size", ",", "\n", "init_fn", "=", "init_fn", ")", "\n", "", "return", "states", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.models.MultiGaussianLSTM.reparameterize": [[54, 58], ["jax.exp", "jax.exp", "jax.random.normal", "jax.random.normal", "jax.random.normal", "jax.random.normal", "models.MultiGaussianLSTM.make_rng"], "methods", ["None"], ["", "def", "reparameterize", "(", "self", ",", "mu", ",", "logvar", ")", ":", "\n", "    ", "var", "=", "jnp", ".", "exp", "(", "0.5", "*", "logvar", ")", "\n", "epsilon", "=", "jax", ".", "random", ".", "normal", "(", "self", ".", "make_rng", "(", "'rng'", ")", ",", "var", ".", "shape", ")", "\n", "return", "mu", "+", "var", "*", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.models.MultiGaussianLSTM.__call__": [[59, 67], ["models.MultiGaussianLSTM.embed", "range", "models.MultiGaussianLSTM.mean", "models.MultiGaussianLSTM.logvar", "models.MultiGaussianLSTM.reparameterize"], "methods", ["home.repos.pwc.inspect_result.google-research_fitvid.None.models.MultiGaussianLSTM.reparameterize"], ["", "def", "__call__", "(", "self", ",", "x", ",", "states", ")", ":", "\n", "    ", "x", "=", "self", ".", "embed", "(", "x", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "      ", "states", "[", "i", "]", ",", "x", "=", "self", ".", "layers", "[", "i", "]", "(", "states", "[", "i", "]", ",", "x", ")", "\n", "", "mean", "=", "self", ".", "mean", "(", "x", ")", "\n", "logvar", "=", "self", ".", "logvar", "(", "x", ")", "\n", "z", "=", "self", ".", "reparameterize", "(", "mean", ",", "logvar", ")", "\n", "return", "states", ",", "(", "z", ",", "mean", ",", "logvar", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.models.FitVid.setup": [[83, 99], ["fitvid.nvae.NVAE_ENCODER_VIDEO", "fitvid.nvae.NVAE_DECODER_VIDEO", "models.MultiGaussianLSTM", "models.MultiGaussianLSTM", "models.MultiGaussianLSTM"], "methods", ["None"], ["def", "setup", "(", "self", ")", ":", "\n", "    ", "self", ".", "encoder", "=", "nvae", ".", "NVAE_ENCODER_VIDEO", "(", "\n", "training", "=", "self", ".", "training", ",", "\n", "stage_sizes", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "num_classes", "=", "self", ".", "g_dim", ")", "\n", "self", ".", "decoder", "=", "nvae", ".", "NVAE_DECODER_VIDEO", "(", "\n", "training", "=", "self", ".", "training", ",", "\n", "stage_sizes", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "first_block_shape", "=", "(", "8", ",", "8", ",", "512", ")", ",", "\n", "skip_type", "=", "'residual'", ")", "\n", "self", ".", "frame_predictor", "=", "MultiGaussianLSTM", "(", "\n", "hidden_size", "=", "self", ".", "rnn_size", ",", "output_size", "=", "self", ".", "g_dim", ",", "num_layers", "=", "2", ")", "\n", "self", ".", "posterior", "=", "MultiGaussianLSTM", "(", "\n", "hidden_size", "=", "self", ".", "rnn_size", ",", "output_size", "=", "self", ".", "z_dim", ",", "num_layers", "=", "1", ")", "\n", "self", ".", "prior", "=", "MultiGaussianLSTM", "(", "\n", "hidden_size", "=", "self", ".", "rnn_size", ",", "output_size", "=", "self", ".", "z_dim", ",", "num_layers", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.models.FitVid.get_input": [[100, 107], ["jax.concatenate", "jax.concatenate"], "methods", ["None"], ["", "def", "get_input", "(", "self", ",", "hidden", ",", "action", ",", "z", ")", ":", "\n", "    ", "inp", "=", "[", "hidden", "]", "\n", "if", "self", ".", "action_conditioned", ":", "\n", "      ", "inp", "+=", "[", "action", "]", "\n", "", "if", "self", ".", "stochastic", ":", "\n", "      ", "inp", "+=", "[", "z", "]", "\n", "", "return", "jnp", ".", "concatenate", "(", "inp", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.models.FitVid.__call__": [[108, 175], ["models.FitVid.frame_predictor.init_states", "models.FitVid.posterior.init_states", "models.FitVid.prior.init_states", "functools.partial", "models.FitVid.encoder", "jax.stack", "jax.stack", "jax.stack", "jax.stack", "fitvid.utils.l2_loss", "range", "jax.stack", "jax.stack", "models.FitVid.decoder", "range", "jax.stack", "jax.stack", "skips.keys", "models.FitVid.posterior", "models.FitVid.prior", "models.FitVid.get_input", "models.FitVid.frame_predictor", "flax.linen.sigmoid", "jax.stack.append", "jax.stack.append", "jax.stack.append", "functools.partial.", "models.FitVid.posterior", "models.FitVid.prior", "models.FitVid.get_input", "models.FitVid.frame_predictor", "flax.linen.sigmoid", "jax.stack.append", "jax.stack.append", "jax.stack.append", "functools.partial.", "models.FitVid.decoder", "jax.expand_dims", "jax.expand_dims", "models.FitVid.encoder", "jax.expand_dims", "jax.expand_dims"], "methods", ["home.repos.pwc.inspect_result.google-research_fitvid.None.models.MultiGaussianLSTM.init_states", "home.repos.pwc.inspect_result.google-research_fitvid.None.models.MultiGaussianLSTM.init_states", "home.repos.pwc.inspect_result.google-research_fitvid.None.models.MultiGaussianLSTM.init_states", "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.l2_loss", "home.repos.pwc.inspect_result.google-research_fitvid.None.models.FitVid.get_input", "home.repos.pwc.inspect_result.google-research_fitvid.None.models.FitVid.get_input"], ["", "def", "__call__", "(", "self", ",", "video", ",", "actions", ",", "step", ")", ":", "\n", "    ", "batch_size", ",", "video_len", "=", "video", ".", "shape", "[", "0", "]", ",", "video", ".", "shape", "[", "1", "]", "\n", "pred_s", "=", "self", ".", "frame_predictor", ".", "init_states", "(", "batch_size", ")", "\n", "post_s", "=", "self", ".", "posterior", ".", "init_states", "(", "batch_size", ")", "\n", "prior_s", "=", "self", ".", "prior", ".", "init_states", "(", "batch_size", ")", "\n", "kl", "=", "functools", ".", "partial", "(", "utils", ".", "kl_divergence", ",", "batch_size", "=", "batch_size", ")", "\n", "\n", "# encode frames", "\n", "hidden", ",", "skips", "=", "self", ".", "encoder", "(", "video", ")", "\n", "# Keep the last available skip only", "\n", "skips", "=", "{", "k", ":", "skips", "[", "k", "]", "[", ":", ",", "self", ".", "n_past", "-", "1", "]", "for", "k", "in", "skips", ".", "keys", "(", ")", "}", "\n", "\n", "kld", ",", "means", ",", "logvars", "=", "0.0", ",", "[", "]", ",", "[", "]", "\n", "if", "self", ".", "training", ":", "\n", "      ", "h_preds", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "video_len", ")", ":", "\n", "        ", "h", ",", "h_target", "=", "hidden", "[", ":", ",", "i", "-", "1", "]", ",", "hidden", "[", ":", ",", "i", "]", "\n", "post_s", ",", "(", "z_t", ",", "mu", ",", "logvar", ")", "=", "self", ".", "posterior", "(", "h_target", ",", "post_s", ")", "\n", "prior_s", ",", "(", "_", ",", "prior_mu", ",", "prior_logvar", ")", "=", "self", ".", "prior", "(", "h", ",", "prior_s", ")", "\n", "\n", "inp", "=", "self", ".", "get_input", "(", "h", ",", "actions", "[", ":", ",", "i", "-", "1", "]", ",", "z_t", ")", "\n", "pred_s", ",", "(", "_", ",", "h_pred", ",", "_", ")", "=", "self", ".", "frame_predictor", "(", "inp", ",", "pred_s", ")", "\n", "h_pred", "=", "nn", ".", "sigmoid", "(", "h_pred", ")", "\n", "h_preds", ".", "append", "(", "h_pred", ")", "\n", "means", ".", "append", "(", "mu", ")", "\n", "logvars", ".", "append", "(", "logvar", ")", "\n", "kld", "+=", "kl", "(", "mu", ",", "logvar", ",", "prior_mu", ",", "prior_logvar", ")", "\n", "\n", "", "h_preds", "=", "jnp", ".", "stack", "(", "h_preds", ",", "axis", "=", "1", ")", "\n", "preds", "=", "self", ".", "decoder", "(", "h_preds", ",", "skips", ")", "\n", "\n", "", "else", ":", "# eval", "\n", "      ", "preds", ",", "x_pred", "=", "[", "]", ",", "None", "\n", "for", "i", "in", "range", "(", "1", ",", "video_len", ")", ":", "\n", "        ", "h", ",", "h_target", "=", "hidden", "[", ":", ",", "i", "-", "1", "]", ",", "hidden", "[", ":", ",", "i", "]", "\n", "if", "i", ">", "self", ".", "n_past", ":", "\n", "          ", "h", "=", "self", ".", "encoder", "(", "jnp", ".", "expand_dims", "(", "x_pred", ",", "1", ")", ")", "[", "0", "]", "[", ":", ",", "0", "]", "\n", "\n", "", "post_s", ",", "(", "_", ",", "mu", ",", "logvar", ")", "=", "self", ".", "posterior", "(", "h_target", ",", "post_s", ")", "\n", "prior_s", ",", "(", "z_t", ",", "prior_mu", ",", "prior_logvar", ")", "=", "self", ".", "prior", "(", "h", ",", "prior_s", ")", "\n", "\n", "inp", "=", "self", ".", "get_input", "(", "h", ",", "actions", "[", ":", ",", "i", "-", "1", "]", ",", "z_t", ")", "\n", "pred_s", ",", "(", "_", ",", "h_pred", ",", "_", ")", "=", "self", ".", "frame_predictor", "(", "inp", ",", "pred_s", ")", "\n", "h_pred", "=", "nn", ".", "sigmoid", "(", "h_pred", ")", "\n", "x_pred", "=", "self", ".", "decoder", "(", "jnp", ".", "expand_dims", "(", "h_pred", ",", "1", ")", ",", "skips", ")", "[", ":", ",", "0", "]", "\n", "preds", ".", "append", "(", "x_pred", ")", "\n", "means", ".", "append", "(", "mu", ")", "\n", "logvars", ".", "append", "(", "logvar", ")", "\n", "kld", "+=", "kl", "(", "mu", ",", "logvar", ",", "prior_mu", ",", "prior_logvar", ")", "\n", "\n", "", "preds", "=", "jnp", ".", "stack", "(", "preds", ",", "axis", "=", "1", ")", "\n", "\n", "", "means", "=", "jnp", ".", "stack", "(", "means", ",", "axis", "=", "1", ")", "\n", "logvars", "=", "jnp", ".", "stack", "(", "logvars", ",", "axis", "=", "1", ")", "\n", "mse", "=", "utils", ".", "l2_loss", "(", "preds", ",", "video", "[", ":", ",", "1", ":", "]", ")", "\n", "loss", "=", "mse", "+", "kld", "*", "self", ".", "beta", "\n", "\n", "# Metrics", "\n", "metrics", "=", "{", "\n", "'hist/mean'", ":", "means", ",", "\n", "'hist/logvars'", ":", "logvars", ",", "\n", "'loss/mse'", ":", "mse", ",", "\n", "'loss/kld'", ":", "kld", ",", "\n", "'loss/all'", ":", "loss", ",", "\n", "}", "\n", "\n", "return", "loss", ",", "preds", ",", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.flatten_video": [[27, 29], ["numpy.reshape"], "function", ["None"], ["def", "flatten_video", "(", "video", ")", ":", "\n", "  ", "return", "np", ".", "reshape", "(", "video", ",", "(", "-", "1", ",", ")", "+", "video", ".", "shape", "[", "2", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.psnr": [[31, 36], ["metrics.flatten_video", "metrics.flatten_video", "tensorflow.image.psnr", "numpy.mean", "tf.image.psnr.numpy"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.flatten_video", "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.flatten_video", "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.psnr"], ["", "def", "psnr", "(", "video_1", ",", "video_2", ")", ":", "\n", "  ", "video_1", "=", "flatten_video", "(", "video_1", ")", "\n", "video_2", "=", "flatten_video", "(", "video_2", ")", "\n", "dist", "=", "tf", ".", "image", ".", "psnr", "(", "video_1", ",", "video_2", ",", "max_val", "=", "1.0", ")", "\n", "return", "np", ".", "mean", "(", "dist", ".", "numpy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.ssim": [[38, 43], ["metrics.flatten_video", "metrics.flatten_video", "tensorflow.image.ssim", "numpy.mean", "tf.image.ssim.numpy"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.flatten_video", "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.flatten_video", "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.ssim"], ["", "def", "ssim", "(", "video_1", ",", "video_2", ")", ":", "\n", "  ", "video_1", "=", "flatten_video", "(", "video_1", ")", "\n", "video_2", "=", "flatten_video", "(", "video_2", ")", "\n", "dist", "=", "tf", ".", "image", ".", "ssim", "(", "video_1", ",", "video_2", ",", "max_val", "=", "1.0", ")", "\n", "return", "np", ".", "mean", "(", "dist", ".", "numpy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.psnr_image": [[45, 48], ["tensorflow.image.psnr", "numpy.mean", "tf.image.psnr.numpy"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.psnr"], ["", "def", "psnr_image", "(", "target_image", ",", "out_image", ")", ":", "\n", "  ", "dist", "=", "tf", ".", "image", ".", "psnr", "(", "target_image", ",", "out_image", ",", "max_val", "=", "1.0", ")", "\n", "return", "np", ".", "mean", "(", "dist", ".", "numpy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.psnr_per_frame": [[50, 54], ["numpy.mean", "numpy.square", "numpy.log10", "numpy.log10"], "function", ["None"], ["", "def", "psnr_per_frame", "(", "target_video", ",", "out_video", ")", ":", "\n", "  ", "max_val", "=", "1.0", "\n", "mse", "=", "np", ".", "mean", "(", "np", ".", "square", "(", "out_video", "-", "target_video", ")", ",", "axis", "=", "(", "2", ",", "3", ",", "4", ")", ")", "\n", "return", "20", "*", "np", ".", "log10", "(", "max_val", ")", "-", "10.0", "*", "np", ".", "log10", "(", "mse", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.lpips_image": [[56, 60], ["tensorflow.convert_to_tensor"], "function", ["None"], ["", "def", "lpips_image", "(", "generated_image", ",", "real_image", ")", ":", "\n", "  ", "global", "lpips_model", "\n", "result", "=", "tf", ".", "convert_to_tensor", "(", "0.0", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.lpips": [[62, 67], ["metrics.flatten_video", "metrics.flatten_video", "metrics.lpips_image", "numpy.mean", "lpips_image.numpy"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.flatten_video", "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.flatten_video", "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.lpips_image"], ["", "def", "lpips", "(", "video_1", ",", "video_2", ")", ":", "\n", "  ", "video_1", "=", "flatten_video", "(", "video_1", ")", "\n", "video_2", "=", "flatten_video", "(", "video_2", ")", "\n", "dist", "=", "lpips_image", "(", "video_1", ",", "video_2", ")", "\n", "return", "np", ".", "mean", "(", "dist", ".", "numpy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.fvd_preprocess": [[69, 78], ["tensorflow.convert_to_tensor", "tf.convert_to_tensor.shape.as_list", "tensorflow.reshape", "tensorflow.image.resize", "tensorflow.reshape", "list", "tensorflow.cast"], "function", ["None"], ["", "def", "fvd_preprocess", "(", "videos", ",", "target_resolution", ")", ":", "\n", "  ", "videos", "=", "tf", ".", "convert_to_tensor", "(", "videos", "*", "255.0", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "videos_shape", "=", "videos", ".", "shape", ".", "as_list", "(", ")", "\n", "all_frames", "=", "tf", ".", "reshape", "(", "videos", ",", "[", "-", "1", "]", "+", "videos_shape", "[", "-", "3", ":", "]", ")", "\n", "resized_videos", "=", "tf", ".", "image", ".", "resize", "(", "all_frames", ",", "size", "=", "target_resolution", ")", "\n", "target_shape", "=", "[", "videos_shape", "[", "0", "]", ",", "-", "1", "]", "+", "list", "(", "target_resolution", ")", "+", "[", "3", "]", "\n", "output_videos", "=", "tf", ".", "reshape", "(", "resized_videos", ",", "target_shape", ")", "\n", "scaled_videos", "=", "2.", "*", "tf", ".", "cast", "(", "output_videos", ",", "tf", ".", "float32", ")", "/", "255.", "-", "1", "\n", "return", "scaled_videos", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.create_id3_embedding": [[80, 92], ["base_model.prune.", "tensorflow_hub.load", "hub.load.graph.get_tensor_by_name", "hub.load.prune"], "function", ["None"], ["", "def", "create_id3_embedding", "(", "videos", ")", ":", "\n", "  ", "\"\"\"Get id3 embeddings.\"\"\"", "\n", "global", "i3d_model", "\n", "module_spec", "=", "'https://tfhub.dev/deepmind/i3d-kinetics-400/1'", "\n", "\n", "if", "not", "i3d_model", ":", "\n", "    ", "base_model", "=", "hub", ".", "load", "(", "module_spec", ")", "\n", "input_tensor", "=", "base_model", ".", "graph", ".", "get_tensor_by_name", "(", "'input_frames:0'", ")", "\n", "i3d_model", "=", "base_model", ".", "prune", "(", "input_tensor", ",", "'RGB/inception_i3d/Mean:0'", ")", "\n", "\n", "", "output", "=", "i3d_model", "(", "videos", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.calculate_fvd": [[94, 97], ["tensorflow_gan.eval.frechet_classifier_distance_from_activations"], "function", ["None"], ["", "def", "calculate_fvd", "(", "real_activations", ",", "generated_activations", ")", ":", "\n", "  ", "return", "tfgan", ".", "eval", ".", "frechet_classifier_distance_from_activations", "(", "\n", "real_activations", ",", "generated_activations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.fvd": [[99, 106], ["metrics.fvd_preprocess", "metrics.fvd_preprocess", "metrics.create_id3_embedding", "metrics.create_id3_embedding", "metrics.calculate_fvd", "calculate_fvd.numpy"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.fvd_preprocess", "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.fvd_preprocess", "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.create_id3_embedding", "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.create_id3_embedding", "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.calculate_fvd"], ["", "def", "fvd", "(", "video_1", ",", "video_2", ")", ":", "\n", "  ", "video_1", "=", "fvd_preprocess", "(", "video_1", ",", "(", "224", ",", "224", ")", ")", "\n", "video_2", "=", "fvd_preprocess", "(", "video_2", ",", "(", "224", ",", "224", ")", ")", "\n", "x", "=", "create_id3_embedding", "(", "video_1", ")", "\n", "y", "=", "create_id3_embedding", "(", "video_2", ")", "\n", "result", "=", "calculate_fvd", "(", "x", ",", "y", ")", "\n", "return", "result", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.inception_score": [[108, 110], ["tensorflow_gan.eval.inception_score"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.inception_score"], ["", "def", "inception_score", "(", "images", ")", ":", "\n", "  ", "return", "tfgan", ".", "eval", ".", "inception_score", "(", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.eval.eval_model": [[43, 73], ["jax.random.PRNGKey", "os.path.join", "flax.metrics.tensorboard.SummaryWriter", "fitvid.train.get_data", "next", "fitvid.utils.get_first_device", "fitvid.train.MODEL_CLS", "fitvid.train.init_model_state", "int", "jax.random.split", "jax.local_device_count", "flax.training.checkpoints.restore_checkpoint", "int", "time.sleep", "int", "flax.jax_utils.replicate", "fitvid.train.evaluate", "jax.host_id", "fitvid.train.write_summaries", "numpy.concatenate", "tensorflow.io.gfile.GFile", "numpy.save"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.train.get_data", "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.get_first_device", "home.repos.pwc.inspect_result.google-research_fitvid.None.train.init_model_state", "home.repos.pwc.inspect_result.google-research_fitvid.None.train.evaluate", "home.repos.pwc.inspect_result.google-research_fitvid.None.train.write_summaries"], ["def", "eval_model", "(", ")", ":", "\n", "  ", "\"\"\"Evaluates the latest model checkpoint.\"\"\"", "\n", "rng_key", "=", "jax", ".", "random", ".", "PRNGKey", "(", "0", ")", "\n", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "output_dir", ",", "'evaluate'", ")", "\n", "summary_writer", "=", "tensorboard", ".", "SummaryWriter", "(", "log_dir", ")", "\n", "\n", "data_itr", "=", "get_data", "(", "False", ")", "\n", "batch", "=", "next", "(", "data_itr", ")", "\n", "sample", "=", "utils", ".", "get_first_device", "(", "batch", ")", "\n", "\n", "model", "=", "MODEL_CLS", "(", "n_past", "=", "FLAGS", ".", "n_past", ",", "training", "=", "False", ")", "\n", "state", "=", "init_model_state", "(", "rng_key", ",", "model", ",", "sample", ")", "\n", "\n", "last_checkpoint", "=", "int", "(", "state", ".", "step", ")", "\n", "rng_key", "=", "jax", ".", "random", ".", "split", "(", "rng_key", ",", "jax", ".", "local_device_count", "(", ")", ")", "\n", "while", "True", ":", "\n", "    ", "state", "=", "checkpoints", ".", "restore_checkpoint", "(", "FLAGS", ".", "output_dir", ",", "state", ")", "\n", "if", "int", "(", "state", ".", "step", ")", "==", "last_checkpoint", ":", "\n", "      ", "time", ".", "sleep", "(", "60", ")", "# sleep for 60 secs", "\n", "", "else", ":", "\n", "      ", "last_checkpoint", "=", "int", "(", "state", ".", "step", ")", "\n", "state", "=", "jax_utils", ".", "replicate", "(", "state", ")", "\n", "metrics", ",", "gt", ",", "out_vid", "=", "evaluate", "(", "\n", "rng_key", ",", "state", ",", "model", ",", "data_itr", ",", "eval_steps", "=", "256", "//", "FLAGS", ".", "batch_size", ")", "\n", "if", "jax", ".", "host_id", "(", ")", "==", "0", ":", "\n", "        ", "write_summaries", "(", "summary_writer", ",", "metrics", ",", "last_checkpoint", ",", "out_vid", ",", "gt", ")", "\n", "video_summary", "=", "np", ".", "concatenate", "(", "[", "gt", ",", "out_vid", "]", ",", "axis", "=", "3", ")", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "f'{log_dir}/video.npy'", ",", "'w'", ")", "as", "outfile", ":", "\n", "          ", "np", ".", "save", "(", "outfile", ",", "video_summary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.eval.main": [[75, 81], ["tensorflow.enable_v2_behavior", "eval.eval_model", "jax.random.normal().block_until_ready", "jax.random.normal", "jax.random.PRNGKey"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.eval.eval_model"], ["", "", "", "", "", "def", "main", "(", "argv", ")", ":", "\n", "  ", "del", "argv", "# Unused", "\n", "tf", ".", "enable_v2_behavior", "(", ")", "\n", "eval_model", "(", ")", "\n", "# Wait until computations are done before exiting", "\n", "jax", ".", "random", ".", "normal", "(", "jax", ".", "random", ".", "PRNGKey", "(", "0", ")", ",", "(", ")", ")", ".", "block_until_ready", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.train.additional_metrics": [[60, 66], ["fitvid.metrics.psnr", "fitvid.metrics.ssim", "fitvid.metrics.fvd", "fitvid.metrics.lpips"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.psnr", "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.ssim", "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.fvd", "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.lpips"], ["def", "additional_metrics", "(", "metrics", ",", "gt", ",", "out_video", ")", ":", "\n", "  ", "metrics", "[", "'metrics/psnr'", "]", "=", "psnr", "(", "gt", ",", "out_video", ")", "\n", "metrics", "[", "'metrics/ssim'", "]", "=", "ssim", "(", "gt", ",", "out_video", ")", "\n", "metrics", "[", "'metrics/fvd'", "]", "=", "fvd", "(", "gt", ",", "out_video", ")", "\n", "metrics", "[", "'metrics/lpips'", "]", "=", "lpips", "(", "gt", ",", "out_video", ")", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.train.write_summaries": [[68, 84], ["metrics.items", "numpy.concatenate", "fitvid.utils.write_video_summaries", "summary_writer.flush", "fitvid.utils.plot_1d_signals", "summary_writer.image", "key.startswith", "summary_writer.histogram", "summary_writer.scalar", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.utils.write_video_summaries", "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.plot_1d_signals"], ["", "def", "write_summaries", "(", "summary_writer", ",", "metrics", ",", "step", ",", "vid_out", ",", "gt", ")", ":", "\n", "  ", "\"\"\"\"Writes TensorBoard summaries.\"\"\"", "\n", "# Scalar summaries", "\n", "for", "key", ",", "val", "in", "metrics", ".", "items", "(", ")", ":", "\n", "    ", "tag", "=", "key", "\n", "if", "key", "==", "'graphs/psnr'", ":", "\n", "      ", "image", "=", "utils", ".", "plot_1d_signals", "(", "[", "np", ".", "mean", "(", "val", ",", "axis", "=", "0", ")", "]", ",", "[", "''", "]", ")", "\n", "summary_writer", ".", "image", "(", "tag", "=", "tag", ",", "image", "=", "image", ",", "step", "=", "step", ")", "\n", "", "elif", "key", ".", "startswith", "(", "'hist'", ")", ":", "\n", "      ", "summary_writer", ".", "histogram", "(", "tag", ",", "val", ",", "step", ")", "\n", "", "else", ":", "\n", "      ", "summary_writer", ".", "scalar", "(", "tag", ",", "val", ",", "step", ")", "\n", "# GIFs", "\n", "", "", "video_summary", "=", "np", ".", "concatenate", "(", "[", "gt", ",", "vid_out", "]", ",", "axis", "=", "3", ")", "\n", "utils", ".", "write_video_summaries", "(", "summary_writer", ",", "video_summary", ",", "1", ",", "step", ")", "\n", "summary_writer", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.train.eval_step": [[86, 102], ["functools.partial", "model.apply", "jax.lax.all_gather", "jax.lax.all_gather", "jax.lax.all_gather", "jax.lax.all_gather", "jax.lax.all_gather", "jax.lax.all_gather", "fitvid.utils.generate_rng_dict"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.utils.generate_rng_dict"], ["", "@", "functools", ".", "partial", "(", "jax", ".", "pmap", ",", "axis_name", "=", "'batch'", ",", "static_broadcasted_argnums", "=", "0", ")", "\n", "def", "eval_step", "(", "model", ",", "batch", ",", "state", ",", "rng", ")", ":", "\n", "  ", "\"\"\"A single evaluation step.\"\"\"", "\n", "variables", "=", "{", "'params'", ":", "state", ".", "optimizer", ".", "target", ",", "**", "state", ".", "model_state", "}", "\n", "(", "_", ",", "out_video", ",", "metrics", ")", ",", "_", "=", "model", ".", "apply", "(", "\n", "variables", ",", "\n", "video", "=", "batch", "[", "'video'", "]", ",", "\n", "actions", "=", "batch", "[", "'actions'", "]", ",", "\n", "rngs", "=", "utils", ".", "generate_rng_dict", "(", "rng", ")", ",", "\n", "step", "=", "state", ".", "step", ",", "\n", "mutable", "=", "[", "'batch_stats'", "]", ")", "\n", "n_past", "=", "FLAGS", ".", "n_past", "\n", "out_video", "=", "jax", ".", "lax", ".", "all_gather", "(", "out_video", "[", ":", ",", "n_past", "-", "1", ":", "]", ",", "axis_name", "=", "'batch'", ")", "\n", "gt", "=", "jax", ".", "lax", ".", "all_gather", "(", "batch", "[", "'video'", "]", "[", ":", ",", "n_past", ":", "]", ",", "axis_name", "=", "'batch'", ")", "\n", "metrics", "=", "jax", ".", "lax", ".", "all_gather", "(", "metrics", ",", "axis_name", "=", "'batch'", ")", "\n", "return", "gt", ",", "out_video", ",", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.train.train_step": [[104, 144], ["functools.partial", "jax.value_and_grad", "jax.value_and_grad", "jax.value_and_grad.", "jax.lax.pmean", "fitvid.utils.clip_grads", "optimizer.apply_gradient", "jax.all", "state.replace", "state.replace", "jax.tree_multimap", "jax.tree_multimap", "state.replace", "model.apply", "jax.asarray", "jax.random.split", "jax.random.split", "jax.where", "fitvid.utils.generate_rng_dict", "jax.all", "jax.isfinite", "jax.tree_leaves", "jax.tree_leaves"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.utils.clip_grads", "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.generate_rng_dict"], ["", "@", "functools", ".", "partial", "(", "\n", "jax", ".", "pmap", ",", "axis_name", "=", "'batch'", ",", "\n", "static_broadcasted_argnums", "=", "0", ",", "donate_argnums", "=", "(", "2", ",", ")", ")", "\n", "def", "train_step", "(", "model", ",", "batch", ",", "state", ",", "rng", ")", ":", "\n", "  ", "\"\"\"A single training step.\"\"\"", "\n", "def", "loss", "(", "params", ")", ":", "\n", "    ", "variables", "=", "{", "'params'", ":", "params", ",", "**", "state", ".", "model_state", "}", "\n", "(", "loss", ",", "out_video", ",", "metrics", ")", ",", "new_model_state", "=", "model", ".", "apply", "(", "\n", "variables", ",", "\n", "video", "=", "batch", "[", "'video'", "]", ",", "\n", "actions", "=", "batch", "[", "'actions'", "]", ",", "\n", "rngs", "=", "utils", ".", "generate_rng_dict", "(", "rng", ")", ",", "\n", "step", "=", "state", ".", "step", ",", "\n", "mutable", "=", "[", "'batch_stats'", "]", ")", "\n", "return", "loss", ",", "(", "new_model_state", ",", "out_video", ",", "metrics", ")", "\n", "\n", "", "optimizer", "=", "state", ".", "optimizer", "\n", "grad_fn", "=", "jax", ".", "value_and_grad", "(", "loss", ",", "has_aux", "=", "True", ")", "\n", "aux", ",", "grads", "=", "grad_fn", "(", "optimizer", ".", "target", ")", "\n", "new_model_state", ",", "out_video", ",", "metrics", "=", "aux", "[", "1", "]", "\n", "grads", "=", "lax", ".", "pmean", "(", "grads", ",", "axis_name", "=", "'batch'", ")", "\n", "# metrics = jax.lax.pmean(metrics, axis_name='batch')", "\n", "grads_clipped", "=", "utils", ".", "clip_grads", "(", "grads", ",", "100.0", ")", "\n", "new_optimizer", "=", "optimizer", ".", "apply_gradient", "(", "grads_clipped", ")", "\n", "# Apply update if the new optimizer state is all finite", "\n", "ok", "=", "jnp", ".", "all", "(", "jnp", ".", "asarray", "(", "[", "\n", "jnp", ".", "all", "(", "jnp", ".", "isfinite", "(", "p", ")", ")", "for", "p", "in", "jax", ".", "tree_leaves", "(", "new_optimizer", ")", "]", ")", ")", "\n", "new_state_with_update", "=", "state", ".", "replace", "(", "\n", "step", "=", "state", ".", "step", "+", "1", ",", "\n", "optimizer", "=", "new_optimizer", ",", "\n", "model_state", "=", "new_model_state", ")", "\n", "new_state_no_update", "=", "state", ".", "replace", "(", "\n", "step", "=", "state", ".", "step", "+", "1", ")", "\n", "new_state", "=", "jax", ".", "tree_multimap", "(", "\n", "lambda", "a", ",", "b", ":", "jnp", ".", "where", "(", "ok", ",", "a", ",", "b", ")", ",", "\n", "new_state_with_update", ",", "new_state_no_update", ")", "\n", "rng", "=", "jax", ".", "random", ".", "split", "(", "rng", ")", "[", "1", "]", "\n", "new_state", "=", "state", ".", "replace", "(", "\n", "step", "=", "state", ".", "step", "+", "1", ",", "optimizer", "=", "new_optimizer", ",", "model_state", "=", "new_model_state", ")", "\n", "return", "new_state", ",", "rng", ",", "metrics", ",", "out_video", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.train.get_log_directories": [[146, 152], ["os.path.join", "os.path.join", "flax.metrics.tensorboard.SummaryWriter"], "function", ["None"], ["", "def", "get_log_directories", "(", ")", ":", "\n", "  ", "output_dir", "=", "FLAGS", ".", "output_dir", "\n", "model_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'model'", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'train'", ")", "\n", "summary_writer", "=", "tensorboard", ".", "SummaryWriter", "(", "log_dir", ")", "\n", "return", "model_dir", ",", "summary_writer", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.train.get_data": [[154, 158], ["fitvid.data.load_dataset_robonet", "jax.host_count", "jax.host_count"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.data.load_dataset_robonet"], ["", "def", "get_data", "(", "training", ")", ":", "\n", "  ", "video_len", "=", "FLAGS", ".", "n_past", "+", "FLAGS", ".", "n_future", "\n", "local_batch_size", "=", "FLAGS", ".", "batch_size", "//", "jax", ".", "host_count", "(", ")", "\n", "return", "data", ".", "load_dataset_robonet", "(", "local_batch_size", ",", "video_len", ",", "training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.train.init_model_state": [[160, 173], ["model.init", "model.init.pop", "flax.optim.Adam", "optim.Adam.create", "fitvid.utils.print_model_size", "fitvid.utils.TrainState", "fitvid.utils.generate_rng_dict"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.utils.print_model_size", "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.generate_rng_dict"], ["", "def", "init_model_state", "(", "rng_key", ",", "model", ",", "sample", ")", ":", "\n", "  ", "\"\"\"Initialize the model state.\"\"\"", "\n", "variables", "=", "model", ".", "init", "(", "\n", "rngs", "=", "utils", ".", "generate_rng_dict", "(", "rng_key", ")", ",", "\n", "video", "=", "sample", "[", "'video'", "]", ",", "\n", "actions", "=", "sample", "[", "'actions'", "]", ",", "\n", "step", "=", "0", ")", "\n", "model_state", ",", "params", "=", "variables", ".", "pop", "(", "'params'", ")", "\n", "\n", "optimizer_def", "=", "optim", ".", "Adam", "(", "learning_rate", "=", "1e-3", ")", "\n", "optimizer", "=", "optimizer_def", ".", "create", "(", "params", ")", "\n", "utils", ".", "print_model_size", "(", "params", ",", "'Model Size'", ")", "\n", "return", "utils", ".", "TrainState", "(", "step", "=", "0", ",", "optimizer", "=", "optimizer", ",", "model_state", "=", "model_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.train.evaluate": [[175, 195], ["range", "next", "train.eval_step", "train.evaluate.get_all"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.train.eval_step"], ["", "def", "evaluate", "(", "rng_key", ",", "state", ",", "model", ",", "data_itr", ",", "eval_steps", ")", ":", "\n", "  ", "\"\"\"Evaluates the model on the entire dataset.\"\"\"", "\n", "all_metrics", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "eval_steps", ")", ":", "\n", "    ", "batch", "=", "next", "(", "data_itr", ")", "\n", "gt", ",", "out_video", ",", "metrics", "=", "eval_step", "(", "model", ",", "batch", ",", "state", ",", "rng_key", ")", "\n", "\n", "def", "get_all", "(", "x", ")", ":", "\n", "      ", "return", "utils", ".", "get_all_devices", "(", "jax_utils", ".", "unreplicate", "(", "x", ")", ")", "\n", "", "out_video", "=", "get_all", "(", "out_video", ")", "\n", "gt", "=", "get_all", "(", "gt", ")", "\n", "metrics", "=", "jax", ".", "tree_map", "(", "get_all", ",", "metrics", ")", "\n", "metrics", "=", "additional_metrics", "(", "metrics", ",", "gt", ",", "out_video", ")", "\n", "all_metrics", ".", "append", "(", "metrics", ")", "\n", "\n", "", "if", "jax", ".", "host_id", "(", ")", "==", "0", ":", "\n", "    ", "metrics", "=", "{", "\n", "k", ":", "np", ".", "mean", "(", "[", "dic", "[", "k", "]", "for", "dic", "in", "all_metrics", "]", ")", "for", "k", "in", "all_metrics", "[", "0", "]", "}", "\n", "metrics", "[", "'graphs/psnr'", "]", "=", "psnr_per_frame", "(", "gt", ",", "out_video", ")", "\n", "", "return", "metrics", ",", "gt", ",", "out_video", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.train.train": [[197, 239], ["jax.random.PRNGKey", "jax.random.PRNGKey", "train.get_log_directories", "train.get_data", "next", "fitvid.utils.get_first_device", "MODEL_CLS", "train.init_model_state", "flax.training.checkpoints.restore_checkpoint", "int", "flax.jax_utils.replicate", "jax.random.split", "jax.random.split", "time.time", "range", "jax.local_device_count", "jax.local_device_count", "train.train_step", "next", "fitvid.utils.sync_batch_stats", "time.time", "jax.host_id", "jax.host_id", "fitvid.utils.get_average_across_devices", "flax.jax_utils.unreplicate", "flax.training.checkpoints.save_checkpoint", "summary_writer.scalar", "fitvid.utils.get_all_devices", "train.additional_metrics", "fitvid.metrics.psnr_per_frame", "train.write_summaries", "absl.logging.info", "time.time", "fitvid.utils.get_all_devices"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.train.get_log_directories", "home.repos.pwc.inspect_result.google-research_fitvid.None.train.get_data", "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.get_first_device", "home.repos.pwc.inspect_result.google-research_fitvid.None.train.init_model_state", "home.repos.pwc.inspect_result.google-research_fitvid.None.train.train_step", "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.sync_batch_stats", "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.get_average_across_devices", "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.get_all_devices", "home.repos.pwc.inspect_result.google-research_fitvid.None.train.additional_metrics", "home.repos.pwc.inspect_result.google-research_fitvid.None.metrics.psnr_per_frame", "home.repos.pwc.inspect_result.google-research_fitvid.None.train.write_summaries", "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.get_all_devices"], ["", "def", "train", "(", ")", ":", "\n", "  ", "\"\"\"Main training loop.\"\"\"", "\n", "rng_key", "=", "jax", ".", "random", ".", "PRNGKey", "(", "0", ")", "\n", "training_steps", "=", "FLAGS", ".", "training_steps", "\n", "log_every", "=", "FLAGS", ".", "log_every", "\n", "\n", "model_dir", ",", "summary_writer", "=", "get_log_directories", "(", ")", "\n", "data_itr", "=", "get_data", "(", "True", ")", "\n", "\n", "batch", "=", "next", "(", "data_itr", ")", "\n", "sample", "=", "utils", ".", "get_first_device", "(", "batch", ")", "\n", "\n", "model", "=", "MODEL_CLS", "(", "n_past", "=", "FLAGS", ".", "n_past", ",", "training", "=", "True", ")", "\n", "\n", "state", "=", "init_model_state", "(", "rng_key", ",", "model", ",", "sample", ")", "\n", "state", "=", "checkpoints", ".", "restore_checkpoint", "(", "model_dir", ",", "state", ")", "\n", "start_step", "=", "int", "(", "state", ".", "step", ")", "\n", "state", "=", "jax_utils", ".", "replicate", "(", "state", ")", "\n", "\n", "rng_key", "=", "jax", ".", "random", ".", "split", "(", "rng_key", ",", "jax", ".", "local_device_count", "(", ")", ")", "\n", "t_loop_start", "=", "time", ".", "time", "(", ")", "\n", "for", "step", "in", "range", "(", "start_step", ",", "training_steps", ")", ":", "\n", "    ", "output", "=", "train_step", "(", "model", ",", "batch", ",", "state", ",", "rng_key", ")", "\n", "state", ",", "rng_key", ",", "metrics", ",", "out_video", "=", "output", "\n", "\n", "if", "step", "%", "log_every", "==", "0", ":", "\n", "      ", "state", "=", "utils", ".", "sync_batch_stats", "(", "state", ")", "\n", "steps_per_sec", "=", "log_every", "/", "(", "time", ".", "time", "(", ")", "-", "t_loop_start", ")", "\n", "t_loop_start", "=", "time", ".", "time", "(", ")", "\n", "if", "jax", ".", "host_id", "(", ")", "==", "0", ":", "\n", "        ", "train_metrics", "=", "utils", ".", "get_average_across_devices", "(", "metrics", ")", "\n", "state_", "=", "jax_utils", ".", "unreplicate", "(", "state", ")", "\n", "checkpoints", ".", "save_checkpoint", "(", "model_dir", ",", "state_", ",", "step", ",", "keep", "=", "3", ")", "\n", "summary_writer", ".", "scalar", "(", "'info/steps-per-second'", ",", "steps_per_sec", ",", "step", ")", "\n", "out_video", "=", "utils", ".", "get_all_devices", "(", "out_video", ")", "\n", "gt", "=", "utils", ".", "get_all_devices", "(", "batch", "[", "'video'", "]", ")", "[", ":", ",", "1", ":", "]", "\n", "train_metrics", "=", "additional_metrics", "(", "train_metrics", ",", "gt", ",", "out_video", ")", "\n", "train_metrics", "[", "'graphs/psnr'", "]", "=", "psnr_per_frame", "(", "gt", ",", "out_video", ")", "\n", "write_summaries", "(", "summary_writer", ",", "train_metrics", ",", "step", ",", "out_video", ",", "gt", ")", "\n", "logging", ".", "info", "(", "'>>> Step: %d Loss: %.4f'", ",", "step", ",", "train_metrics", "[", "'loss/all'", "]", ")", "\n", "\n", "", "", "batch", "=", "next", "(", "data_itr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.train.main": [[241, 249], ["tensorflow.enable_v2_behavior", "tensorflow.config.experimental.set_visible_devices", "train.train", "jax.random.normal().block_until_ready", "jax.random.normal().block_until_ready", "jax.random.normal", "jax.random.normal", "jax.random.PRNGKey", "jax.random.PRNGKey"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.train.train"], ["", "", "def", "main", "(", "argv", ")", ":", "\n", "  ", "del", "argv", "# Unused", "\n", "tf", ".", "enable_v2_behavior", "(", ")", "\n", "# make sure tf does not allocate gpu memory", "\n", "tf", ".", "config", ".", "experimental", ".", "set_visible_devices", "(", "[", "]", ",", "'GPU'", ")", "\n", "train", "(", ")", "\n", "# Wait until computations are done before exiting", "\n", "jax", ".", "random", ".", "normal", "(", "jax", ".", "random", ".", "PRNGKey", "(", "0", ")", ",", "(", ")", ")", ".", "block_until_ready", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.data.rand_crop": [[28, 38], ["tensorflow.random.stateless_uniform", "tensorflow.random.stateless_uniform"], "function", ["None"], ["def", "rand_crop", "(", "seeds", ",", "video", ",", "width", ",", "height", ",", "wiggle", ")", ":", "\n", "  ", "\"\"\"Random crop of a video. Assuming height < width.\"\"\"", "\n", "x_wiggle", "=", "wiggle", "\n", "crop_width", "=", "height", "-", "wiggle", "\n", "y_wiggle", "=", "width", "-", "crop_width", "\n", "xx", "=", "tf", ".", "random", ".", "stateless_uniform", "(", "\n", "[", "]", ",", "seed", "=", "seeds", "[", "0", "]", ",", "minval", "=", "0", ",", "maxval", "=", "x_wiggle", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "yy", "=", "tf", ".", "random", ".", "stateless_uniform", "(", "\n", "[", "]", ",", "seed", "=", "seeds", "[", "1", "]", ",", "minval", "=", "0", ",", "maxval", "=", "y_wiggle", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "return", "video", "[", ":", ",", "xx", ":", "xx", "+", "crop_width", ",", "yy", ":", "yy", "+", "crop_width", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.data.rand_aug": [[40, 44], ["tensorflow.scan", "fitvid.randaug.randaugment"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.randaugment"], ["", "def", "rand_aug", "(", "seeds", ",", "video", ",", "num_layers", ",", "magnitude", ")", ":", "\n", "  ", "\"\"\"RandAug for video with the same random seed for all frames.\"\"\"", "\n", "image_aug", "=", "lambda", "a", ",", "x", ":", "randaugment", "(", "x", ",", "num_layers", ",", "magnitude", ",", "seeds", ")", "\n", "return", "tf", ".", "scan", "(", "image_aug", ",", "video", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.data.augment_dataset": [[46, 61], ["tensorflow.data.experimental.RandomDataset().batch().batch", "tensorflow.data.Dataset.zip", "dataset.map.map", "tensorflow.cast", "tensorflow.image.resize", "aug_fn", "tensorflow.data.experimental.RandomDataset().batch", "tensorflow.data.experimental.RandomDataset"], "function", ["None"], ["", "def", "augment_dataset", "(", "dataset", ",", "augmentations", ")", ":", "\n", "  ", "\"\"\"Augment dataset with a list of augmentations.\"\"\"", "\n", "def", "augment", "(", "seeds", ",", "features", ")", ":", "\n", "    ", "video", "=", "tf", ".", "cast", "(", "features", "[", "'video'", "]", ",", "tf", ".", "uint8", ")", "\n", "for", "aug_fn", "in", "augmentations", ":", "\n", "      ", "video", "=", "aug_fn", "(", "seeds", ",", "video", ")", "\n", "", "video", "=", "tf", ".", "image", ".", "resize", "(", "video", ",", "(", "64", ",", "64", ")", ")", "\n", "features", "[", "'video'", "]", "=", "video", "\n", "return", "features", "\n", "\n", "", "randds", "=", "tf", ".", "data", ".", "experimental", ".", "RandomDataset", "(", "1", ")", ".", "batch", "(", "2", ")", ".", "batch", "(", "4", ")", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "zip", "(", "(", "randds", ",", "dataset", ")", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "augment", ",", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.data.normalize_video": [[63, 66], ["tensorflow.cast"], "function", ["None"], ["", "def", "normalize_video", "(", "features", ")", ":", "\n", "  ", "features", "[", "'video'", "]", "=", "tf", ".", "cast", "(", "features", "[", "'video'", "]", ",", "tf", ".", "float32", ")", "/", "255.0", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.data.get_iterator": [[68, 91], ["jax.local_device_count", "tensorflow.data.Options", "dataset.shuffle.with_options", "dataset.shuffle.map", "dataset.shuffle.repeat", "dataset.shuffle.batch", "dataset.shuffle.prefetch", "map", "flax.jax_utils.prefetch_to_device", "dataset.shuffle.shuffle", "jax.tree_map", "x._numpy._numpy", "x._numpy.reshape"], "function", ["None"], ["", "def", "get_iterator", "(", "dataset", ",", "batch_size", ",", "is_train", ")", ":", "\n", "  ", "\"\"\"\"Returns a performance optimized iterator from dataset.\"\"\"", "\n", "local_device_count", "=", "jax", ".", "local_device_count", "(", ")", "\n", "options", "=", "tf", ".", "data", ".", "Options", "(", ")", "\n", "options", ".", "experimental_threading", ".", "private_threadpool_size", "=", "48", "\n", "options", ".", "experimental_threading", ".", "max_intra_op_parallelism", "=", "1", "\n", "dataset", "=", "dataset", ".", "with_options", "(", "options", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "normalize_video", ")", "\n", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "if", "is_train", ":", "\n", "    ", "dataset", "=", "dataset", ".", "shuffle", "(", "batch_size", "*", "64", ",", "seed", "=", "0", ")", "\n", "", "dataset", "=", "dataset", ".", "batch", "(", "batch_size", ",", "drop_remainder", "=", "True", ")", "\n", "dataset", "=", "dataset", ".", "prefetch", "(", "32", ")", "\n", "\n", "def", "prepare_tf_data", "(", "xs", ")", ":", "\n", "    ", "def", "_prepare", "(", "x", ")", ":", "\n", "      ", "x", "=", "x", ".", "_numpy", "(", ")", "\n", "return", "x", ".", "reshape", "(", "(", "local_device_count", ",", "-", "1", ")", "+", "x", ".", "shape", "[", "1", ":", "]", ")", "\n", "", "return", "jax", ".", "tree_map", "(", "_prepare", ",", "xs", ")", "\n", "\n", "", "iterator", "=", "map", "(", "prepare_tf_data", ",", "dataset", ")", "\n", "iterator", "=", "jax_utils", ".", "prefetch_to_device", "(", "iterator", ",", "2", ")", "\n", "return", "iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.data.load_dataset_robonet": [[95, 141], ["tensorflow_datasets.builder", "tfds.builder.download_and_prepare", "tfds.builder.as_dataset", "tensorflow.data.Options", "dataset.map.with_options", "data.load_dataset_robonet.get_robonet_test_filenames"], "function", ["None"], ["", "def", "load_dataset_robonet", "(", "batch_size", ",", "video_len", ",", "is_train", ")", ":", "\n", "  ", "\"\"\"\"Load RoboNet dataset.\"\"\"", "\n", "\n", "def", "extract_features_robonet", "(", "features", ")", ":", "\n", "    ", "dtype", "=", "tf", ".", "float32", "\n", "video", "=", "tf", ".", "cast", "(", "features", "[", "'video'", "]", ",", "dtype", ")", "\n", "actions", "=", "tf", ".", "cast", "(", "features", "[", "'actions'", "]", ",", "dtype", ")", "\n", "video", "/=", "255.0", "\n", "return", "{", "\n", "'video'", ":", "tf", ".", "identity", "(", "video", "[", ":", "video_len", "]", ")", ",", "\n", "'actions'", ":", "tf", ".", "identity", "(", "actions", "[", ":", "video_len", "-", "1", "]", ")", ",", "\n", "}", "\n", "\n", "", "def", "robonet_filter_by_filename", "(", "features", ",", "filenames", ",", "white", "=", "True", ")", ":", "\n", "    ", "in_list", "=", "tf", ".", "reduce_any", "(", "tf", ".", "math", ".", "equal", "(", "features", "[", "'filename'", "]", ",", "filenames", ")", ")", "\n", "return", "in_list", "if", "white", "else", "tf", ".", "math", ".", "logical_not", "(", "in_list", ")", "\n", "\n", "", "def", "get_robonet_test_filenames", "(", ")", ":", "\n", "    ", "testfiles", "=", "None", "\n", "if", "testfiles", "is", "None", ":", "\n", "      ", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "'fitvid/robonet_testset_filenames.txt'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "testfiles", "=", "f", ".", "read", "(", ")", "\n", "", "", "testfiles", "=", "(", "[", "x", ".", "encode", "(", "'ascii'", ")", "for", "x", "in", "testfiles", ".", "split", "(", "'\\n'", ")", "if", "x", "]", ")", "\n", "return", "testfiles", "\n", "\n", "", "dataset_builder", "=", "tfds", ".", "builder", "(", "'robonet/robonet_64'", ")", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "num_examples", "=", "dataset_builder", ".", "info", ".", "splits", "[", "'train'", "]", ".", "num_examples", "\n", "split_size", "=", "num_examples", "//", "jax", ".", "host_count", "(", ")", "\n", "start", "=", "jax", ".", "host_id", "(", ")", "*", "split_size", "\n", "split", "=", "'train[{}:{}]'", ".", "format", "(", "start", ",", "start", "+", "split_size", ")", "\n", "dataset", "=", "dataset_builder", ".", "as_dataset", "(", "split", "=", "split", ")", "\n", "options", "=", "tf", ".", "data", ".", "Options", "(", ")", "\n", "options", ".", "experimental_threading", ".", "private_threadpool_size", "=", "48", "\n", "options", ".", "experimental_threading", ".", "max_intra_op_parallelism", "=", "1", "\n", "dataset", "=", "dataset", ".", "with_options", "(", "options", ")", "\n", "\n", "test_filenames", "=", "get_robonet_test_filenames", "(", ")", "\n", "train_filter", "=", "functools", ".", "partial", "(", "\n", "robonet_filter_by_filename", ",", "filenames", "=", "test_filenames", ",", "white", "=", "not", "is_train", ")", "\n", "\n", "dataset", "=", "dataset", ".", "filter", "(", "train_filter", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "extract_features_robonet", ",", "\n", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "return", "get_iterator", "(", "dataset", ",", "batch_size", ",", "is_train", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_fitvid.None.nvae.SEBlock.__call__": [[37, 45], ["max", "x.mean", "nvae.SEBlock.act", "flax.linen.Dense", "flax.linen.Dense", "flax.linen.sigmoid"], "methods", ["None"], ["@", "nn", ".", "compact", "\n", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "    ", "hidden_size", "=", "max", "(", "x", ".", "shape", "[", "-", "1", "]", "//", "16", ",", "4", ")", "\n", "y", "=", "x", ".", "mean", "(", "axis", "=", "self", ".", "axis", ",", "keepdims", "=", "True", ")", "\n", "y", "=", "nn", ".", "Dense", "(", "features", "=", "hidden_size", ",", "dtype", "=", "self", ".", "dtype", ",", "name", "=", "'reduce'", ")", "(", "y", ")", "\n", "y", "=", "self", ".", "act", "(", "y", ")", "\n", "y", "=", "nn", ".", "Dense", "(", "features", "=", "x", ".", "shape", "[", "-", "1", "]", ",", "dtype", "=", "self", ".", "dtype", ",", "name", "=", "'expand'", ")", "(", "y", ")", "\n", "return", "nn", ".", "sigmoid", "(", "y", ")", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.nvae.EncoderBlock.__call__": [[55, 76], ["nvae.EncoderBlock.act", "nvae.EncoderBlock.act", "nvae.EncoderBlock.act", "nvae.EncoderBlock.norm", "nvae.EncoderBlock.conv", "nvae.EncoderBlock.norm", "nvae.EncoderBlock.conv", "nvae.SEBlock", "print", "nvae.EncoderBlock.conv", "nvae.EncoderBlock.norm"], "methods", ["None"], ["@", "nn", ".", "compact", "\n", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "    ", "strides", "=", "(", "2", ",", "2", ")", "if", "self", ".", "downsample", "else", "(", "1", ",", "1", ")", "\n", "\n", "residual", "=", "x", "\n", "y", "=", "x", "\n", "y", "=", "self", ".", "norm", "(", ")", "(", "y", ")", "\n", "y", "=", "self", ".", "act", "(", "y", ")", "\n", "y", "=", "self", ".", "conv", "(", "self", ".", "filters", ",", "(", "3", ",", "3", ")", ",", "strides", ")", "(", "y", ")", "\n", "y", "=", "self", ".", "norm", "(", ")", "(", "y", ")", "\n", "y", "=", "self", ".", "act", "(", "y", ")", "\n", "y", "=", "self", ".", "conv", "(", "self", ".", "filters", ",", "(", "3", ",", "3", ")", ")", "(", "y", ")", "\n", "y", "=", "SEBlock", "(", ")", "(", "y", ")", "\n", "\n", "if", "residual", ".", "shape", "!=", "y", ".", "shape", ":", "\n", "      ", "print", "(", "'E adjust'", ")", "\n", "residual", "=", "self", ".", "conv", "(", "self", ".", "filters", ",", "(", "1", ",", "1", ")", ",", "\n", "strides", ",", "name", "=", "'conv_proj'", ")", "(", "residual", ")", "\n", "residual", "=", "self", ".", "norm", "(", "name", "=", "'norm_proj'", ")", "(", "residual", ")", "\n", "\n", "", "return", "self", ".", "act", "(", "residual", "+", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.nvae.DecoderBlock.upsample_image": [[87, 93], ["jax.image.resize", "jax.image.resize", "jax.image.resize", "jax.image.resize"], "methods", ["None"], ["def", "upsample_image", "(", "self", ",", "img", ",", "multiplier", ")", ":", "\n", "    ", "shape", "=", "(", "img", ".", "shape", "[", "0", "]", ",", "\n", "img", ".", "shape", "[", "1", "]", "*", "multiplier", ",", "\n", "img", ".", "shape", "[", "2", "]", "*", "multiplier", ",", "\n", "img", ".", "shape", "[", "3", "]", ")", "\n", "return", "jax", ".", "image", ".", "resize", "(", "img", ",", "shape", ",", "jax", ".", "image", ".", "ResizeMethod", ".", "NEAREST", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.nvae.DecoderBlock.__call__": [[94, 118], ["nvae.DecoderBlock.act", "nvae.DecoderBlock.act", "nvae.DecoderBlock.act", "nvae.DecoderBlock.upsample_image", "nvae.DecoderBlock.norm", "nvae.DecoderBlock.conv", "nvae.DecoderBlock.norm", "nvae.DecoderBlock.conv", "nvae.DecoderBlock.norm", "nvae.DecoderBlock.conv", "nvae.DecoderBlock.norm", "nvae.SEBlock", "print", "nvae.DecoderBlock.conv", "nvae.DecoderBlock.norm"], "methods", ["home.repos.pwc.inspect_result.google-research_fitvid.None.nvae.DecoderBlock.upsample_image"], ["", "@", "nn", ".", "compact", "\n", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "    ", "if", "self", ".", "upsample", ":", "\n", "      ", "x", "=", "self", ".", "upsample_image", "(", "x", ",", "multiplier", "=", "2", ")", "\n", "\n", "", "residual", "=", "x", "\n", "y", "=", "x", "\n", "y", "=", "self", ".", "norm", "(", ")", "(", "y", ")", "\n", "y", "=", "self", ".", "conv", "(", "self", ".", "filters", "*", "self", ".", "expand", ",", "(", "1", ",", "1", ")", ")", "(", "y", ")", "\n", "y", "=", "self", ".", "norm", "(", ")", "(", "y", ")", "\n", "y", "=", "self", ".", "act", "(", "y", ")", "\n", "y", "=", "self", ".", "conv", "(", "self", ".", "filters", "*", "self", ".", "expand", ",", "(", "5", ",", "5", ")", ")", "(", "y", ")", "\n", "y", "=", "self", ".", "norm", "(", ")", "(", "y", ")", "\n", "y", "=", "self", ".", "act", "(", "y", ")", "\n", "y", "=", "self", ".", "conv", "(", "self", ".", "filters", ",", "(", "1", ",", "1", ")", ")", "(", "y", ")", "\n", "y", "=", "self", ".", "norm", "(", "scale_init", "=", "nn", ".", "initializers", ".", "zeros", ")", "(", "y", ")", "\n", "y", "=", "SEBlock", "(", ")", "(", "y", ")", "\n", "\n", "if", "residual", ".", "shape", "!=", "y", ".", "shape", ":", "\n", "      ", "print", "(", "'D adjust'", ")", "\n", "residual", "=", "self", ".", "conv", "(", "self", ".", "filters", ",", "(", "1", ",", "1", ")", ",", "name", "=", "'conv_proj'", ")", "(", "residual", ")", "\n", "residual", "=", "self", ".", "norm", "(", "name", "=", "'norm_proj'", ")", "(", "residual", ")", "\n", "\n", "", "return", "self", ".", "act", "(", "residual", "+", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.nvae.ModularEncoder.__call__": [[130, 154], ["functools.partial", "functools.partial", "enumerate", "print", "jax.mean", "jax.mean", "jax.asarray", "jax.asarray", "range", "flax.linen.Dense", "print", "block"], "methods", ["None"], ["@", "nn", ".", "compact", "\n", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "    ", "conv", "=", "functools", ".", "partial", "(", "nn", ".", "Conv", ",", "use_bias", "=", "False", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", "norm", "=", "functools", ".", "partial", "(", "nn", ".", "BatchNorm", ",", "\n", "use_running_average", "=", "not", "self", ".", "training", ",", "\n", "momentum", "=", "0.9", ",", "\n", "epsilon", "=", "1e-5", ",", "\n", "axis_name", "=", "'time'", ",", "\n", "dtype", "=", "self", ".", "dtype", ")", "\n", "\n", "skips", "=", "{", "}", "\n", "for", "i", ",", "block_size", "in", "enumerate", "(", "self", ".", "stage_sizes", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "block_size", ")", ":", "\n", "        ", "print", "(", "'E'", ",", "i", ",", "j", ",", "x", ".", "shape", ")", "\n", "filters", "=", "self", ".", "num_filters", "*", "2", "**", "i", "\n", "block", "=", "self", ".", "down_block", "if", "i", ">", "0", "and", "j", "==", "0", "else", "self", ".", "encoder_block", "\n", "x", "=", "block", "(", "filters", "=", "filters", ",", "conv", "=", "conv", ",", "norm", "=", "norm", ")", "(", "x", ")", "\n", "skips", "[", "(", "i", ",", "j", ")", "]", "=", "x", "\n", "\n", "", "", "print", "(", "'E'", ",", "i", ",", "j", ",", "x", ".", "shape", ")", "\n", "x", "=", "jnp", ".", "mean", "(", "x", ",", "axis", "=", "(", "1", ",", "2", ")", ")", "\n", "x", "=", "nn", ".", "Dense", "(", "self", ".", "num_classes", ",", "dtype", "=", "self", ".", "dtype", ")", "(", "x", ")", "\n", "x", "=", "jnp", ".", "asarray", "(", "x", ",", "self", ".", "dtype", ")", "\n", "return", "x", ",", "skips", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.nvae.ModularDecoder.__call__": [[167, 202], ["functools.partial", "functools.partial", "numpy.prod", "jax.reshape", "jax.reshape", "enumerate", "print", "flax.linen.sigmoid", "jax.asarray", "jax.asarray", "numpy.array", "flax.linen.Dense", "reversed", "range", "functools.partial.", "print", "block", "jax.concatenate", "jax.concatenate", "Exception", "len", "len", "len"], "methods", ["None"], ["@", "nn", ".", "compact", "\n", "def", "__call__", "(", "self", ",", "x", ",", "skips", ")", ":", "\n", "    ", "conv", "=", "functools", ".", "partial", "(", "nn", ".", "Conv", ",", "use_bias", "=", "False", ",", "dtype", "=", "self", ".", "dtype", ")", "\n", "norm", "=", "functools", ".", "partial", "(", "nn", ".", "BatchNorm", ",", "\n", "use_running_average", "=", "not", "self", ".", "training", ",", "\n", "momentum", "=", "0.9", ",", "\n", "epsilon", "=", "1e-5", ",", "\n", "axis_name", "=", "'time'", ",", "\n", "dtype", "=", "self", ".", "dtype", ")", "\n", "\n", "filters", "=", "np", ".", "prod", "(", "np", ".", "array", "(", "self", ".", "first_block_shape", ")", ")", "\n", "x", "=", "nn", ".", "Dense", "(", "filters", ",", "dtype", "=", "self", ".", "dtype", ")", "(", "x", ")", "\n", "x", "=", "jnp", ".", "reshape", "(", "x", ",", "(", "x", ".", "shape", "[", "0", "]", ",", ")", "+", "self", ".", "first_block_shape", ")", "\n", "\n", "for", "i", ",", "block_size", "in", "enumerate", "(", "reversed", "(", "self", ".", "stage_sizes", ")", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "block_size", ")", ":", "\n", "        ", "print", "(", "'D'", ",", "i", ",", "j", ",", "x", ".", "shape", ")", "\n", "filters", "=", "self", ".", "num_filters", "*", "2", "**", "(", "len", "(", "self", ".", "stage_sizes", ")", "-", "i", "-", "1", ")", "\n", "block", "=", "self", ".", "up_block", "if", "i", ">", "0", "and", "j", "==", "0", "else", "self", ".", "decoder_block", "\n", "x", "=", "block", "(", "filters", "=", "filters", ",", "conv", "=", "conv", ",", "norm", "=", "norm", ")", "(", "x", ")", "\n", "\n", "if", "self", ".", "skip_type", "==", "'residual'", ":", "\n", "          ", "x", "=", "x", "+", "skips", "[", "(", "len", "(", "self", ".", "stage_sizes", ")", "-", "i", "-", "1", ",", "block_size", "-", "j", "-", "1", ")", "]", "\n", "", "elif", "self", ".", "skip_type", "==", "'concat'", ":", "\n", "          ", "x", "=", "jnp", ".", "concatenate", "(", "\n", "[", "x", ",", "skips", "[", "(", "len", "(", "self", ".", "stage_sizes", ")", "-", "i", "-", "1", ",", "block_size", "-", "j", "-", "1", ")", "]", "]", ",", "\n", "axis", "=", "-", "1", ")", "\n", "", "elif", "self", ".", "skip_type", "is", "not", "None", ":", "\n", "          ", "raise", "Exception", "(", "'Unknown Skip Type.'", ")", "\n", "\n", "", "", "", "print", "(", "'D'", ",", "i", ",", "j", ",", "x", ".", "shape", ")", "\n", "x", "=", "conv", "(", "3", ",", "(", "3", ",", "3", ")", ")", "(", "x", ")", "\n", "x", "=", "nn", ".", "sigmoid", "(", "x", ")", "\n", "x", "=", "jnp", ".", "asarray", "(", "x", ",", "self", ".", "dtype", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.blend": [[33, 74], ["tensorflow.to_float", "tensorflow.to_float", "tensorflow.cast", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.to_float", "tensorflow.cast", "tensorflow.clip_by_value", "tensorflow_addons.image", "tensorflow_addons.image", "tensorflow_addons.image"], "function", ["None"], ["def", "blend", "(", "image1", ",", "image2", ",", "factor", ")", ":", "\n", "  ", "\"\"\"Blend image1 and image2 using 'factor'.\n\n  Factor can be above 0.0.  A value of 0.0 means only image1 is used.\n  A value of 1.0 means only image2 is used.  A value between 0.0 and\n  1.0 means we linearly interpolate the pixel values between the two\n  images.  A value greater than 1.0 \"extrapolates\" the difference\n  between the two pixel values, and we clip the results to values\n  between 0 and 255.\n\n  Args:\n    image1: An image Tensor of type uint8.\n    image2: An image Tensor of type uint8.\n    factor: A floating point value above 0.0.\n\n  Returns:\n    A blended image Tensor of type uint8.\n  \"\"\"", "\n", "if", "factor", "==", "0.0", ":", "\n", "    ", "return", "tf1", ".", "convert_to_tensor", "(", "image1", ")", "\n", "", "if", "factor", "==", "1.0", ":", "\n", "    ", "return", "tf1", ".", "convert_to_tensor", "(", "image2", ")", "\n", "\n", "", "image1", "=", "tf1", ".", "to_float", "(", "image1", ")", "\n", "image2", "=", "tf1", ".", "to_float", "(", "image2", ")", "\n", "\n", "difference", "=", "image2", "-", "image1", "\n", "scaled", "=", "factor", "*", "difference", "\n", "\n", "# Do addition in float.", "\n", "temp", "=", "tf1", ".", "to_float", "(", "image1", ")", "+", "scaled", "\n", "\n", "# Interpolate", "\n", "if", "factor", ">", "0.0", "and", "factor", "<", "1.0", ":", "\n", "# Interpolation means we always stay within 0 and 255.", "\n", "    ", "return", "tf1", ".", "cast", "(", "temp", ",", "tf1", ".", "uint8", ")", "\n", "\n", "# Extrapolate:", "\n", "#", "\n", "# We need to clip and then cast.", "\n", "", "return", "tf1", ".", "cast", "(", "tf1", ".", "clip_by_value", "(", "temp", ",", "0.0", ",", "255.0", ")", ",", "tf1", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.cutout": [[76, 126], ["tensorflow.random.stateless_uniform", "tensorflow.random.stateless_uniform", "tensorflow.maximum", "tensorflow.maximum", "tensorflow.maximum", "tensorflow.maximum", "tensorflow.pad", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.where", "tensorflow.shape", "tensorflow.shape", "tensorflow.zeros", "tensorflow.equal", "tensorflow.ones_like"], "function", ["None"], ["", "def", "cutout", "(", "image", ",", "seed", ",", "pad_size", ",", "replace", "=", "0", ")", ":", "\n", "  ", "\"\"\"Apply cutout (https://arxiv.org/abs/1708.04552) to image.\n\n  This operation applies a (2*pad_size x 2*pad_size) mask of zeros to\n  a random location within `img`. The pixel values filled in will be of the\n  value `replace`. The located where the mask will be applied is randomly\n  chosen uniformly over the whole image.\n\n  Args:\n    image: An image Tensor of type uint8.\n    seed: the random seed.\n    pad_size: Specifies how big the zero mask that will be generated is that\n      is applied to the image. The mask will be of size\n      (2*pad_size x 2*pad_size).\n    replace: What pixel value to fill in the image in the area that has\n      the cutout mask applied to it.\n\n  Returns:\n    An image Tensor that is of type uint8.\n  \"\"\"", "\n", "image_height", "=", "tf1", ".", "shape", "(", "image", ")", "[", "0", "]", "\n", "image_width", "=", "tf1", ".", "shape", "(", "image", ")", "[", "1", "]", "\n", "\n", "# Sample the center location in the image where the zero mask will be applied.", "\n", "cutout_center_height", "=", "tf2", ".", "random", ".", "stateless_uniform", "(", "\n", "seed", "=", "seed", ",", "shape", "=", "[", "]", ",", "minval", "=", "0", ",", "maxval", "=", "image_height", ",", "\n", "dtype", "=", "tf1", ".", "int32", ")", "\n", "\n", "cutout_center_width", "=", "tf2", ".", "random", ".", "stateless_uniform", "(", "\n", "seed", "=", "seed", ",", "shape", "=", "[", "]", ",", "minval", "=", "0", ",", "maxval", "=", "image_width", ",", "\n", "dtype", "=", "tf1", ".", "int32", ")", "\n", "\n", "lower_pad", "=", "tf1", ".", "maximum", "(", "0", ",", "cutout_center_height", "-", "pad_size", ")", "\n", "upper_pad", "=", "tf1", ".", "maximum", "(", "0", ",", "image_height", "-", "cutout_center_height", "-", "pad_size", ")", "\n", "left_pad", "=", "tf1", ".", "maximum", "(", "0", ",", "cutout_center_width", "-", "pad_size", ")", "\n", "right_pad", "=", "tf1", ".", "maximum", "(", "0", ",", "image_width", "-", "cutout_center_width", "-", "pad_size", ")", "\n", "\n", "cutout_shape", "=", "[", "image_height", "-", "(", "lower_pad", "+", "upper_pad", ")", ",", "\n", "image_width", "-", "(", "left_pad", "+", "right_pad", ")", "]", "\n", "padding_dims", "=", "[", "[", "lower_pad", ",", "upper_pad", "]", ",", "[", "left_pad", ",", "right_pad", "]", "]", "\n", "mask", "=", "tf1", ".", "pad", "(", "\n", "tf1", ".", "zeros", "(", "cutout_shape", ",", "dtype", "=", "image", ".", "dtype", ")", ",", "\n", "padding_dims", ",", "constant_values", "=", "1", ")", "\n", "mask", "=", "tf1", ".", "expand_dims", "(", "mask", ",", "-", "1", ")", "\n", "mask", "=", "tf1", ".", "tile", "(", "mask", ",", "[", "1", ",", "1", ",", "3", "]", ")", "\n", "image", "=", "tf1", ".", "where", "(", "\n", "tf1", ".", "equal", "(", "mask", ",", "0", ")", ",", "\n", "tf1", ".", "ones_like", "(", "image", ",", "dtype", "=", "image", ".", "dtype", ")", "*", "replace", ",", "\n", "image", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.solarize": [[128, 134], ["tensorflow.where"], "function", ["None"], ["", "def", "solarize", "(", "image", ",", "seed", ",", "threshold", "=", "128", ")", ":", "\n", "# For each pixel in the image, select the pixel", "\n", "# if the value is less than the threshold.", "\n", "# Otherwise, subtract 255 from the pixel.", "\n", "  ", "del", "seed", "\n", "return", "tf1", ".", "where", "(", "image", "<", "threshold", ",", "image", ",", "255", "-", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.solarize_add": [[136, 145], ["tensorflow.cast", "tensorflow.where", "tensorflow.cast", "tensorflow.clip_by_value"], "function", ["None"], ["", "def", "solarize_add", "(", "image", ",", "seed", ",", "addition", "=", "0", ",", "threshold", "=", "128", ")", ":", "\n", "# For each pixel in the image less than threshold", "\n", "# we add 'addition' amount to it and then clip the", "\n", "# pixel value to be between 0 and 255. The value", "\n", "# of 'addition' is between -128 and 128.", "\n", "  ", "del", "seed", "\n", "added_image", "=", "tf1", ".", "cast", "(", "image", ",", "tf1", ".", "int64", ")", "+", "addition", "\n", "added_image", "=", "tf1", ".", "cast", "(", "tf1", ".", "clip_by_value", "(", "added_image", ",", "0", ",", "255", ")", ",", "tf1", ".", "uint8", ")", "\n", "return", "tf1", ".", "where", "(", "image", "<", "threshold", ",", "added_image", ",", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.color": [[147, 152], ["tensorflow.image.grayscale_to_rgb", "randaug.blend", "tensorflow.image.rgb_to_grayscale"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.blend"], ["", "def", "color", "(", "image", ",", "seed", ",", "factor", ")", ":", "\n", "  ", "\"\"\"Equivalent of PIL Color.\"\"\"", "\n", "del", "seed", "\n", "degenerate", "=", "tf1", ".", "image", ".", "grayscale_to_rgb", "(", "tf1", ".", "image", ".", "rgb_to_grayscale", "(", "image", ")", ")", "\n", "return", "blend", "(", "degenerate", ",", "image", ",", "factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.contrast": [[154, 170], ["tensorflow.image.rgb_to_grayscale", "tensorflow.cast", "tensorflow.histogram_fixed_width", "tensorflow.clip_by_value", "tensorflow.image.grayscale_to_rgb", "randaug.blend", "tensorflow.reduce_sum", "tensorflow.ones_like", "tensorflow.cast", "tensorflow.cast"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.blend"], ["", "def", "contrast", "(", "image", ",", "seed", ",", "factor", ")", ":", "\n", "  ", "\"\"\"Equivalent of PIL Contrast.\"\"\"", "\n", "del", "seed", "\n", "degenerate", "=", "tf1", ".", "image", ".", "rgb_to_grayscale", "(", "image", ")", "\n", "# Cast before calling tf1.histogram.", "\n", "degenerate", "=", "tf1", ".", "cast", "(", "degenerate", ",", "tf1", ".", "int32", ")", "\n", "\n", "# Compute the grayscale histogram, then compute the mean pixel value,", "\n", "# and create a constant image size of that value.  Use that as the", "\n", "# blending degenerate target of the original image.", "\n", "hist", "=", "tf1", ".", "histogram_fixed_width", "(", "degenerate", ",", "[", "0", ",", "255", "]", ",", "nbins", "=", "256", ")", "\n", "mean", "=", "tf1", ".", "reduce_sum", "(", "tf1", ".", "cast", "(", "hist", ",", "tf1", ".", "float32", ")", ")", "/", "256.0", "\n", "degenerate", "=", "tf1", ".", "ones_like", "(", "degenerate", ",", "dtype", "=", "tf1", ".", "float32", ")", "*", "mean", "\n", "degenerate", "=", "tf1", ".", "clip_by_value", "(", "degenerate", ",", "0.0", ",", "255.0", ")", "\n", "degenerate", "=", "tf1", ".", "image", ".", "grayscale_to_rgb", "(", "tf1", ".", "cast", "(", "degenerate", ",", "tf1", ".", "uint8", ")", ")", "\n", "return", "blend", "(", "degenerate", ",", "image", ",", "factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.brightness": [[172, 177], ["tensorflow.zeros_like", "randaug.blend"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.blend"], ["", "def", "brightness", "(", "image", ",", "seed", ",", "factor", ")", ":", "\n", "  ", "\"\"\"Equivalent of PIL Brightness.\"\"\"", "\n", "del", "seed", "\n", "degenerate", "=", "tf1", ".", "zeros_like", "(", "image", ")", "\n", "return", "blend", "(", "degenerate", ",", "image", ",", "factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.posterize": [[179, 184], ["tensorflow.bitwise.left_shift", "tensorflow.bitwise.right_shift"], "function", ["None"], ["", "def", "posterize", "(", "image", ",", "seed", ",", "bits", ")", ":", "\n", "  ", "\"\"\"Equivalent of PIL Posterize.\"\"\"", "\n", "del", "seed", "\n", "shift", "=", "8", "-", "bits", "\n", "return", "tf1", ".", "bitwise", ".", "left_shift", "(", "tf1", ".", "bitwise", ".", "right_shift", "(", "image", ",", "shift", ")", ",", "shift", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.rotate": [[186, 211], ["tensorflow_addons.image.rotate", "randaug.unwrap", "randaug.wrap"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.rotate", "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.unwrap", "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.wrap"], ["", "def", "rotate", "(", "image", ",", "seed", ",", "degrees", ",", "replace", ")", ":", "\n", "  ", "\"\"\"Rotates the image by degrees either clockwise or counterclockwise.\n\n  Args:\n    image: An image Tensor of type uint8.\n    seed: the random seed.\n    degrees: Float, a scalar angle in degrees to rotate all images by. If\n      degrees is positive the image will be rotated clockwise otherwise it will\n      be rotated counterclockwise.\n    replace: A one or three value 1D tensor to fill empty pixels caused by\n      the rotate operation.\n\n  Returns:\n    The rotated version of image.\n  \"\"\"", "\n", "del", "seed", "\n", "# Convert from degrees to radians.", "\n", "degrees_to_radians", "=", "math", ".", "pi", "/", "180.0", "\n", "radians", "=", "degrees", "*", "degrees_to_radians", "\n", "\n", "# In practice, we should randomize the rotation degrees by flipping", "\n", "# it negatively half the time, but that's done on 'degrees' outside", "\n", "# of the function.", "\n", "image", "=", "contrib_image", ".", "rotate", "(", "wrap", "(", "image", ")", ",", "radians", ")", "\n", "return", "unwrap", "(", "image", ",", "replace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.flip": [[213, 217], ["tensorflow.image.flip_left_right", "randaug.unwrap", "randaug.wrap"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.unwrap", "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.wrap"], ["", "def", "flip", "(", "image", ",", "seed", ",", "replace", ")", ":", "\n", "  ", "del", "seed", "\n", "image", "=", "tf2", ".", "image", ".", "flip_left_right", "(", "wrap", "(", "image", ")", ")", "\n", "return", "unwrap", "(", "image", ",", "replace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.translate_x": [[219, 224], ["tensorflow_addons.image.translate", "randaug.unwrap", "randaug.wrap"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.unwrap", "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.wrap"], ["", "def", "translate_x", "(", "image", ",", "seed", ",", "pixels", ",", "replace", ")", ":", "\n", "  ", "\"\"\"Equivalent of PIL Translate in X dimension.\"\"\"", "\n", "del", "seed", "\n", "image", "=", "contrib_image", ".", "translate", "(", "wrap", "(", "image", ")", ",", "[", "-", "pixels", ",", "0", "]", ")", "\n", "return", "unwrap", "(", "image", ",", "replace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.translate_y": [[226, 231], ["tensorflow_addons.image.translate", "randaug.unwrap", "randaug.wrap"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.unwrap", "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.wrap"], ["", "def", "translate_y", "(", "image", ",", "seed", ",", "pixels", ",", "replace", ")", ":", "\n", "  ", "\"\"\"Equivalent of PIL Translate in Y dimension.\"\"\"", "\n", "del", "seed", "\n", "image", "=", "contrib_image", ".", "translate", "(", "wrap", "(", "image", ")", ",", "[", "0", ",", "-", "pixels", "]", ")", "\n", "return", "unwrap", "(", "image", ",", "replace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.shear_x": [[233, 243], ["tensorflow_addons.image.transform", "randaug.unwrap", "randaug.wrap"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.unwrap", "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.wrap"], ["", "def", "shear_x", "(", "image", ",", "seed", ",", "level", ",", "replace", ")", ":", "\n", "  ", "\"\"\"Equivalent of PIL Shearing in X dimension.\"\"\"", "\n", "# Shear parallel to x axis is a projective transform", "\n", "# with a matrix form of:", "\n", "# [1  level", "\n", "#  0  1].", "\n", "del", "seed", "\n", "image", "=", "contrib_image", ".", "transform", "(", "\n", "wrap", "(", "image", ")", ",", "[", "1.", ",", "level", ",", "0.", ",", "0.", ",", "1.", ",", "0.", ",", "0.", ",", "0.", "]", ")", "\n", "return", "unwrap", "(", "image", ",", "replace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.shear_y": [[245, 255], ["tensorflow_addons.image.transform", "randaug.unwrap", "randaug.wrap"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.unwrap", "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.wrap"], ["", "def", "shear_y", "(", "image", ",", "seed", ",", "level", ",", "replace", ")", ":", "\n", "  ", "\"\"\"Equivalent of PIL Shearing in Y dimension.\"\"\"", "\n", "# Shear parallel to y axis is a projective transform", "\n", "# with a matrix form of:", "\n", "# [1  0", "\n", "#  level  1].", "\n", "del", "seed", "\n", "image", "=", "contrib_image", ".", "transform", "(", "\n", "wrap", "(", "image", ")", ",", "[", "1.", ",", "0.", ",", "0.", ",", "level", ",", "1.", ",", "0.", ",", "0.", ",", "0.", "]", ")", "\n", "return", "unwrap", "(", "image", ",", "replace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.autocontrast": [[257, 296], ["randaug.autocontrast.scale_channel"], "function", ["None"], ["", "def", "autocontrast", "(", "image", ",", "seed", ")", ":", "\n", "  ", "\"\"\"Implements Autocontrast function from PIL using TF ops.\n\n  Args:\n    image: A 3D uint8 tensor.\n    seed: the random seed.\n\n  Returns:\n    The image after it has had autocontrast applied to it and will be of type\n    uint8.\n  \"\"\"", "\n", "\n", "del", "seed", "\n", "def", "scale_channel", "(", "image", ")", ":", "\n", "    ", "\"\"\"Scale the 2D image using the autocontrast rule.\"\"\"", "\n", "# A possibly cheaper version can be done using cumsum/unique_with_counts", "\n", "# over the histogram values, rather than iterating over the entire image.", "\n", "# to compute mins and maxes.", "\n", "lo", "=", "tf1", ".", "to_float", "(", "tf1", ".", "reduce_min", "(", "image", ")", ")", "\n", "hi", "=", "tf1", ".", "to_float", "(", "tf1", ".", "reduce_max", "(", "image", ")", ")", "\n", "\n", "# Scale the image, making the lowest value 0 and the highest value 255.", "\n", "def", "scale_values", "(", "im", ")", ":", "\n", "      ", "scale", "=", "255.0", "/", "(", "hi", "-", "lo", ")", "\n", "offset", "=", "-", "lo", "*", "scale", "\n", "im", "=", "tf1", ".", "to_float", "(", "im", ")", "*", "scale", "+", "offset", "\n", "im", "=", "tf1", ".", "clip_by_value", "(", "im", ",", "0.0", ",", "255.0", ")", "\n", "return", "tf1", ".", "cast", "(", "im", ",", "tf1", ".", "uint8", ")", "\n", "\n", "", "result", "=", "tf1", ".", "cond", "(", "hi", ">", "lo", ",", "lambda", ":", "scale_values", "(", "image", ")", ",", "lambda", ":", "image", ")", "\n", "return", "result", "\n", "\n", "# Assumes RGB for now.  Scales each channel independently", "\n", "# and then stacks the result.", "\n", "", "s1", "=", "scale_channel", "(", "image", "[", ":", ",", ":", ",", "0", "]", ")", "\n", "s2", "=", "scale_channel", "(", "image", "[", ":", ",", ":", ",", "1", "]", ")", "\n", "s3", "=", "scale_channel", "(", "image", "[", ":", ",", ":", ",", "2", "]", ")", "\n", "image", "=", "tf1", ".", "stack", "(", "[", "s1", ",", "s2", ",", "s3", "]", ",", "2", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.sharpness": [[298, 329], ["tensorflow.cast", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.clip_by_value", "tensorflow.squeeze", "tensorflow.ones_like", "tensorflow.pad", "tensorflow.pad", "tensorflow.where", "randaug.blend", "tensorflow.constant", "tensorflow.device", "tensorflow.nn.depthwise_conv2d", "tensorflow.cast", "tensorflow.equal"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.blend"], ["", "def", "sharpness", "(", "image", ",", "seed", ",", "factor", ")", ":", "\n", "  ", "\"\"\"Implements Sharpness function from PIL using TF ops.\"\"\"", "\n", "del", "seed", "\n", "orig_image", "=", "image", "\n", "image", "=", "tf1", ".", "cast", "(", "image", ",", "tf1", ".", "float32", ")", "\n", "# Make image 4D for conv operation.", "\n", "image", "=", "tf1", ".", "expand_dims", "(", "image", ",", "0", ")", "\n", "# SMOOTH PIL Kernel.", "\n", "kernel", "=", "tf1", ".", "constant", "(", "\n", "[", "[", "1", ",", "1", ",", "1", "]", ",", "[", "1", ",", "5", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", "]", "]", ",", "dtype", "=", "tf1", ".", "float32", ",", "\n", "shape", "=", "[", "3", ",", "3", ",", "1", ",", "1", "]", ")", "/", "13.", "\n", "# Tile across channel dimension.", "\n", "kernel", "=", "tf1", ".", "tile", "(", "kernel", ",", "[", "1", ",", "1", ",", "3", ",", "1", "]", ")", "\n", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", "\n", "with", "tf1", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "# Some augmentation that uses depth-wise conv will cause crashing when", "\n", "# training on GPU. See (b/156242594) for details.", "\n", "    ", "degenerate", "=", "tf1", ".", "nn", ".", "depthwise_conv2d", "(", "\n", "image", ",", "kernel", ",", "strides", ",", "padding", "=", "'VALID'", ",", "rate", "=", "[", "1", ",", "1", "]", ")", "\n", "", "degenerate", "=", "tf1", ".", "clip_by_value", "(", "degenerate", ",", "0.0", ",", "255.0", ")", "\n", "degenerate", "=", "tf1", ".", "squeeze", "(", "tf1", ".", "cast", "(", "degenerate", ",", "tf1", ".", "uint8", ")", ",", "[", "0", "]", ")", "\n", "\n", "# For the borders of the resulting image, fill in the values of the", "\n", "# original image.", "\n", "mask", "=", "tf1", ".", "ones_like", "(", "degenerate", ")", "\n", "padded_mask", "=", "tf1", ".", "pad", "(", "mask", ",", "[", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "padded_degenerate", "=", "tf1", ".", "pad", "(", "degenerate", ",", "[", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "result", "=", "tf1", ".", "where", "(", "tf1", ".", "equal", "(", "padded_mask", ",", "1", ")", ",", "padded_degenerate", ",", "orig_image", ")", "\n", "\n", "# Blend the final result.", "\n", "return", "blend", "(", "result", ",", "orig_image", ",", "factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.equalize": [[331, 370], ["randaug.autocontrast.scale_channel"], "function", ["None"], ["", "def", "equalize", "(", "image", ",", "seed", ")", ":", "\n", "  ", "\"\"\"Implements Equalize function from PIL using TF ops.\"\"\"", "\n", "del", "seed", "\n", "def", "scale_channel", "(", "im", ",", "c", ")", ":", "\n", "    ", "\"\"\"Scale the data in the channel to implement equalize.\"\"\"", "\n", "im", "=", "tf1", ".", "cast", "(", "im", "[", ":", ",", ":", ",", "c", "]", ",", "tf1", ".", "int32", ")", "\n", "# Compute the histogram of the image channel.", "\n", "histo", "=", "tf1", ".", "histogram_fixed_width", "(", "im", ",", "[", "0", ",", "255", "]", ",", "nbins", "=", "256", ")", "\n", "\n", "# For the purposes of computing the step, filter out the nonzeros.", "\n", "nonzero", "=", "tf1", ".", "where", "(", "tf1", ".", "not_equal", "(", "histo", ",", "0", ")", ")", "\n", "nonzero_histo", "=", "tf1", ".", "reshape", "(", "tf1", ".", "gather", "(", "histo", ",", "nonzero", ")", ",", "[", "-", "1", "]", ")", "\n", "step", "=", "(", "tf1", ".", "reduce_sum", "(", "nonzero_histo", ")", "-", "nonzero_histo", "[", "-", "1", "]", ")", "//", "255", "\n", "\n", "def", "build_lut", "(", "histo", ",", "step", ")", ":", "\n", "# Compute the cumulative sum, shifting by step // 2", "\n", "# and then normalization by step.", "\n", "      ", "lut", "=", "(", "tf1", ".", "cumsum", "(", "histo", ")", "+", "(", "step", "//", "2", ")", ")", "//", "step", "\n", "# Shift lut, prepending with 0.", "\n", "lut", "=", "tf1", ".", "concat", "(", "[", "[", "0", "]", ",", "lut", "[", ":", "-", "1", "]", "]", ",", "0", ")", "\n", "# Clip the counts to be in range.  This is done", "\n", "# in the C code for image.point.", "\n", "return", "tf1", ".", "clip_by_value", "(", "lut", ",", "0", ",", "255", ")", "\n", "\n", "# If step is zero, return the original image.  Otherwise, build", "\n", "# lut from the full histogram and step and then index from it.", "\n", "", "result", "=", "tf1", ".", "cond", "(", "tf1", ".", "equal", "(", "step", ",", "0", ")", ",", "\n", "lambda", ":", "im", ",", "\n", "lambda", ":", "tf1", ".", "gather", "(", "build_lut", "(", "histo", ",", "step", ")", ",", "im", ")", ")", "\n", "\n", "return", "tf1", ".", "cast", "(", "result", ",", "tf1", ".", "uint8", ")", "\n", "\n", "# Assumes RGB for now.  Scales each channel independently", "\n", "# and then stacks the result.", "\n", "", "s1", "=", "scale_channel", "(", "image", ",", "0", ")", "\n", "s2", "=", "scale_channel", "(", "image", ",", "1", ")", "\n", "s3", "=", "scale_channel", "(", "image", ",", "2", ")", "\n", "image", "=", "tf1", ".", "stack", "(", "[", "s1", ",", "s2", ",", "s3", "]", ",", "2", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.invert": [[372, 377], ["tensorflow.convert_to_tensor"], "function", ["None"], ["", "def", "invert", "(", "image", ",", "seed", ")", ":", "\n", "  ", "\"\"\"Inverts the image pixels.\"\"\"", "\n", "del", "seed", "\n", "image", "=", "tf1", ".", "convert_to_tensor", "(", "image", ")", "\n", "return", "255", "-", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.wrap": [[379, 385], ["tensorflow.shape", "tensorflow.ones", "tensorflow.concat", "tensorflow_addons.image", "tensorflow_addons.image", "tensorflow_addons.image", "tensorflow_addons.image", "tensorflow_addons.image", "tensorflow_addons.image"], "function", ["None"], ["", "def", "wrap", "(", "image", ")", ":", "\n", "  ", "\"\"\"Returns 'image' with an extra channel set to all 1s.\"\"\"", "\n", "shape", "=", "tf1", ".", "shape", "(", "image", ")", "\n", "extended_channel", "=", "tf1", ".", "ones", "(", "[", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ",", "1", "]", ",", "image", ".", "dtype", ")", "\n", "extended", "=", "tf1", ".", "concat", "(", "[", "image", ",", "extended_channel", "]", ",", "2", ")", "\n", "return", "extended", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.unwrap": [[387, 423], ["tensorflow.shape", "tensorflow.reshape", "tensorflow.concat", "tensorflow.where", "tensorflow.reshape", "tensorflow.slice", "tensorflow.equal", "tensorflow.ones", "tensorflow.ones_like", "tensorflow_addons.image", "tensorflow_addons.image", "tensorflow_addons.image", "tensorflow_addons.image", "tensorflow_addons.image", "tensorflow_addons.image"], "function", ["None"], ["", "def", "unwrap", "(", "image", ",", "replace", ")", ":", "\n", "  ", "\"\"\"Unwraps an image produced by wrap.\n\n  Where there is a 0 in the last channel for every spatial position,\n  the rest of the three channels in that spatial dimension are grayed\n  (set to 128).  Operations like translate and shear on a wrapped\n  Tensor will leave 0s in empty locations.  Some transformations look\n  at the intensity of values to do preprocessing, and we want these\n  empty pixels to assume the 'average' value, rather than pure black.\n\n\n  Args:\n    image: A 3D Image Tensor with 4 channels.\n    replace: A one or three value 1D tensor to fill empty pixels.\n\n  Returns:\n    image: A 3D image Tensor with 3 channels.\n  \"\"\"", "\n", "image_shape", "=", "tf1", ".", "shape", "(", "image", ")", "\n", "# Flatten the spatial dimensions.", "\n", "flattened_image", "=", "tf1", ".", "reshape", "(", "image", ",", "[", "-", "1", ",", "image_shape", "[", "2", "]", "]", ")", "\n", "\n", "# Find all pixels where the last channel is zero.", "\n", "alpha_channel", "=", "flattened_image", "[", ":", ",", "3", "]", "\n", "\n", "replace", "=", "tf1", ".", "concat", "(", "[", "replace", ",", "tf1", ".", "ones", "(", "[", "1", "]", ",", "image", ".", "dtype", ")", "]", ",", "0", ")", "\n", "\n", "# Where they are zero, fill them in with 'replace'.", "\n", "flattened_image", "=", "tf1", ".", "where", "(", "\n", "tf1", ".", "equal", "(", "alpha_channel", ",", "0", ")", ",", "\n", "tf1", ".", "ones_like", "(", "flattened_image", ",", "dtype", "=", "image", ".", "dtype", ")", "*", "replace", ",", "\n", "flattened_image", ")", "\n", "\n", "image", "=", "tf1", ".", "reshape", "(", "flattened_image", ",", "image_shape", ")", "\n", "image", "=", "tf1", ".", "slice", "(", "image", ",", "[", "0", ",", "0", ",", "0", "]", ",", "[", "image_shape", "[", "0", "]", ",", "image_shape", "[", "1", "]", ",", "3", "]", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug._randomly_negate_tensor": [[446, 452], ["tensorflow.random.stateless_uniform", "tensorflow.cast", "tensorflow.cond", "tensorflow.floor"], "function", ["None"], ["def", "_randomly_negate_tensor", "(", "tensor", ",", "seed", ")", ":", "\n", "  ", "\"\"\"With 50% prob turn the tensor negative.\"\"\"", "\n", "rnd", "=", "tf2", ".", "random", ".", "stateless_uniform", "(", "[", "]", ",", "seed", "=", "seed", ")", "\n", "should_flip", "=", "tf1", ".", "cast", "(", "tf1", ".", "floor", "(", "rnd", "+", "0.5", ")", ",", "tf1", ".", "bool", ")", "\n", "final_tensor", "=", "tf1", ".", "cond", "(", "should_flip", ",", "lambda", ":", "tensor", ",", "lambda", ":", "-", "tensor", ")", "\n", "return", "final_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug._rotate_level_to_arg": [[454, 458], ["randaug._randomly_negate_tensor"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug._randomly_negate_tensor"], ["", "def", "_rotate_level_to_arg", "(", "level", ",", "seed", ")", ":", "\n", "  ", "level", "=", "(", "level", "/", "_MAX_LEVEL", ")", "*", "30.", "\n", "level", "=", "_randomly_negate_tensor", "(", "level", ",", "seed", ")", "\n", "return", "(", "level", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug._shrink_level_to_arg": [[460, 467], ["None"], "function", ["None"], ["", "def", "_shrink_level_to_arg", "(", "level", ")", ":", "\n", "  ", "\"\"\"Converts level to ratio by which we shrink the image content.\"\"\"", "\n", "if", "level", "==", "0", ":", "\n", "    ", "return", "(", "1.0", ",", ")", "# if level is zero, do not shrink the image", "\n", "# Maximum shrinking ratio is 2.9.", "\n", "", "level", "=", "2.", "/", "(", "_MAX_LEVEL", "/", "level", ")", "+", "0.9", "\n", "return", "(", "level", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug._enhance_level_to_arg": [[469, 471], ["None"], "function", ["None"], ["", "def", "_enhance_level_to_arg", "(", "level", ")", ":", "\n", "  ", "return", "(", "(", "level", "/", "_MAX_LEVEL", ")", "*", "1.8", "+", "0.1", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug._shear_level_to_arg": [[473, 478], ["randaug._randomly_negate_tensor"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug._randomly_negate_tensor"], ["", "def", "_shear_level_to_arg", "(", "level", ",", "seed", ")", ":", "\n", "  ", "level", "=", "(", "level", "/", "_MAX_LEVEL", ")", "*", "0.3", "\n", "# Flip level to negative with 50% chance.", "\n", "level", "=", "_randomly_negate_tensor", "(", "level", ",", "seed", ")", "\n", "return", "(", "level", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug._translate_level_to_arg": [[480, 485], ["randaug._randomly_negate_tensor", "float"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug._randomly_negate_tensor"], ["", "def", "_translate_level_to_arg", "(", "level", ",", "seed", ",", "translate_const", ")", ":", "\n", "  ", "level", "=", "(", "level", "/", "_MAX_LEVEL", ")", "*", "float", "(", "translate_const", ")", "\n", "# Flip level to negative with 50% chance.", "\n", "level", "=", "_randomly_negate_tensor", "(", "level", ",", "seed", ")", "\n", "return", "(", "level", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.level_to_arg": [[487, 510], ["randaug._rotate_level_to_arg", "randaug._shear_level_to_arg", "randaug._shear_level_to_arg", "randaug._translate_level_to_arg", "randaug._translate_level_to_arg", "int", "int", "int", "int"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug._rotate_level_to_arg", "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug._shear_level_to_arg", "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug._shear_level_to_arg", "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug._translate_level_to_arg", "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug._translate_level_to_arg"], ["", "def", "level_to_arg", "(", "hparams", ",", "seed", ")", ":", "\n", "  ", "return", "{", "\n", "'AutoContrast'", ":", "lambda", "level", ":", "(", ")", ",", "\n", "'Equalize'", ":", "lambda", "level", ":", "(", ")", ",", "\n", "'Flip'", ":", "lambda", "level", ":", "(", ")", ",", "\n", "'Invert'", ":", "lambda", "level", ":", "(", ")", ",", "\n", "'Rotate'", ":", "lambda", "level", ":", "_rotate_level_to_arg", "(", "level", ",", "seed", ")", ",", "\n", "'Posterize'", ":", "lambda", "level", ":", "(", "int", "(", "(", "level", "/", "_MAX_LEVEL", ")", "*", "4", ")", ",", ")", ",", "\n", "'Solarize'", ":", "lambda", "level", ":", "(", "int", "(", "(", "level", "/", "_MAX_LEVEL", ")", "*", "256", ")", ",", ")", ",", "\n", "'SolarizeAdd'", ":", "lambda", "level", ":", "(", "int", "(", "(", "level", "/", "_MAX_LEVEL", ")", "*", "110", ")", ",", ")", ",", "\n", "'Color'", ":", "_enhance_level_to_arg", ",", "\n", "'Contrast'", ":", "_enhance_level_to_arg", ",", "\n", "'Brightness'", ":", "_enhance_level_to_arg", ",", "\n", "'Sharpness'", ":", "_enhance_level_to_arg", ",", "\n", "'ShearX'", ":", "lambda", "level", ":", "_shear_level_to_arg", "(", "level", ",", "seed", ")", ",", "\n", "'ShearY'", ":", "lambda", "level", ":", "_shear_level_to_arg", "(", "level", ",", "seed", ")", ",", "\n", "# pylint:disable=g-long-lambda", "\n", "'Cutout'", ":", "lambda", "level", ":", "(", "int", "(", "(", "level", "/", "_MAX_LEVEL", ")", "*", "\n", "hparams", "[", "'cutout_const'", "]", ")", ",", ")", ",", "\n", "'TranslateX'", ":", "lambda", "level", ":", "_translate_level_to_arg", "(", "\n", "level", ",", "seed", ",", "hparams", "[", "'translate_const'", "]", ")", ",", "\n", "'TranslateY'", ":", "lambda", "level", ":", "_translate_level_to_arg", "(", "\n", "level", ",", "seed", ",", "hparams", "[", "'translate_const'", "]", ")", ",", "\n", "# pylint:enable=g-long-lambda", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug._parse_policy_info": [[514, 536], ["tuple", "tuple", "randaug.level_to_arg", "inspect.getargspec", "inspect.getargspec", "list", "list", "inspect.getargspec"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.level_to_arg"], ["", "def", "_parse_policy_info", "(", "\n", "name", ",", "seed", ",", "prob", ",", "level", ",", "replace_value", ",", "augmentation_hparams", ")", ":", "\n", "  ", "\"\"\"Return the function that corresponds to `name` and update `level` param.\"\"\"", "\n", "func", "=", "NAME_TO_FUNC", "[", "name", "]", "\n", "args", "=", "level_to_arg", "(", "augmentation_hparams", ",", "seed", ")", "[", "name", "]", "(", "level", ")", "\n", "\n", "# Check to see if prob is passed into function. This is used for operations", "\n", "# where we alter bboxes independently.", "\n", "# pytype:disable=wrong-arg-types", "\n", "if", "'prob'", "in", "inspect", ".", "getargspec", "(", "func", ")", "[", "0", "]", ":", "# pylint:disable=deprecated-method", "\n", "    ", "args", "=", "tuple", "(", "[", "prob", "]", "+", "list", "(", "args", ")", ")", "\n", "# pytype:enable=wrong-arg-types", "\n", "\n", "# Add in replace arg if it is required for the function that is being called.", "\n", "# pytype:disable=wrong-arg-types", "\n", "", "if", "'replace'", "in", "inspect", ".", "getargspec", "(", "func", ")", "[", "0", "]", ":", "# pylint:disable=deprecated-method", "\n", "# Make sure replace is the final argument", "\n", "    ", "assert", "'replace'", "==", "inspect", ".", "getargspec", "(", "func", ")", "[", "0", "]", "[", "-", "1", "]", "# pylint:disable=deprecated-method", "\n", "args", "=", "tuple", "(", "list", "(", "args", ")", "+", "[", "replace_value", "]", ")", "\n", "# pytype:enable=wrong-arg-types", "\n", "\n", "", "return", "(", "func", ",", "prob", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.randaug.randaugment": [[538, 601], ["tensorflow.logging.info", "range", "tensorflow.random.stateless_uniform", "float", "tensorflow.name_scope", "enumerate", "len", "tensorflow.random.stateless_uniform", "randaug._parse_policy_info", "tensorflow.cond", "tensorflow.equal", "selected_func"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.randaug._parse_policy_info"], ["", "def", "randaugment", "(", "image", ",", "num_layers", ",", "magnitude", ",", "seeds", ")", ":", "\n", "  ", "\"\"\"Applies the RandAugment policy to `image`.\n\n  RandAugment is from the paper https://arxiv.org/abs/1909.13719,\n\n  Args:\n    image: `Tensor` of shape [height, width, 3] representing an image.\n    num_layers: Integer, the number of augmentation transformations to apply\n      sequentially to an image. Represented as (N) in the paper. Usually best\n      values will be in the range [1, 3].\n    magnitude: Integer, shared magnitude across all augmentation operations.\n      Represented as (M) in the paper. Usually best values are in the range\n      [5, 30].\n    seeds: The random seeds.\n\n  Returns:\n    The augmented version of `image`.\n  \"\"\"", "\n", "replace_value", "=", "[", "128", "]", "*", "3", "\n", "tf1", ".", "logging", ".", "info", "(", "'Using RandAug.'", ")", "\n", "augmentation_hparams", "=", "{", "\n", "'cutout_const'", ":", "10", ",", "\n", "'translate_const'", ":", "10", "\n", "}", "\n", "available_ops", "=", "[", "\n", "'AutoContrast'", ",", "\n", "'Equalize'", ",", "\n", "'Flip'", ",", "\n", "# 'Invert',", "\n", "'Rotate'", ",", "\n", "'Posterize'", ",", "\n", "# 'Solarize',", "\n", "'Color'", ",", "\n", "'Contrast'", ",", "\n", "'Brightness'", ",", "\n", "'Sharpness'", ",", "\n", "'ShearX'", ",", "\n", "'ShearY'", ",", "\n", "'TranslateX'", ",", "\n", "'TranslateY'", ",", "\n", "# 'Cutout',", "\n", "# 'SolarizeAdd'", "\n", "]", "\n", "\n", "for", "layer_num", "in", "range", "(", "num_layers", ")", ":", "\n", "    ", "op_to_select", "=", "tf2", ".", "random", ".", "stateless_uniform", "(", "\n", "[", "]", ",", "seed", "=", "seeds", "[", "0", "]", ",", "maxval", "=", "len", "(", "available_ops", ")", ",", "dtype", "=", "tf1", ".", "int32", ")", "\n", "random_magnitude", "=", "float", "(", "magnitude", ")", "\n", "with", "tf1", ".", "name_scope", "(", "'randaug_layer_{}'", ".", "format", "(", "layer_num", ")", ")", ":", "\n", "      ", "for", "(", "i", ",", "op_name", ")", "in", "enumerate", "(", "available_ops", ")", ":", "\n", "        ", "prob", "=", "tf2", ".", "random", ".", "stateless_uniform", "(", "\n", "[", "]", ",", "seed", "=", "seeds", "[", "1", "]", ",", "minval", "=", "0.2", ",", "maxval", "=", "0.8", ",", "dtype", "=", "tf1", ".", "float32", ")", "\n", "func", ",", "_", ",", "args", "=", "_parse_policy_info", "(", "op_name", ",", "seeds", "[", "2", "]", ",", "\n", "prob", ",", "random_magnitude", ",", "\n", "replace_value", ",", "augmentation_hparams", ")", "\n", "image", "=", "tf1", ".", "cond", "(", "\n", "tf1", ".", "equal", "(", "i", ",", "op_to_select", ")", ",", "\n", "# pylint:disable=g-long-lambda", "\n", "lambda", "selected_func", "=", "func", ",", "selected_args", "=", "args", ":", "selected_func", "(", "\n", "image", ",", "seeds", "[", "3", "]", ",", "*", "selected_args", ")", ",", "\n", "# pylint:enable=g-long-lambda", "\n", "lambda", ":", "image", ")", "\n", "", "", "", "return", "image", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.flatten": [[39, 41], ["jax.reshape"], "function", ["None"], ["", "def", "flatten", "(", "x", ")", ":", "\n", "  ", "return", "jnp", ".", "reshape", "(", "x", ",", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.discretize": [[43, 47], ["flax.linen.tanh", "jax.asarray", "jax.less", "jax.lax.stop_gradient"], "function", ["None"], ["", "def", "discretize", "(", "x", ")", ":", "\n", "  ", "z", "=", "nn", ".", "tanh", "(", "x", ")", "\n", "d", "=", "jnp", ".", "asarray", "(", "jnp", ".", "less", "(", "0.0", ",", "z", ")", ",", "dtype", "=", "jnp", ".", "float32", ")", "\n", "return", "z", "+", "lax", ".", "stop_gradient", "(", "2.0", "*", "d", "-", "1.0", "-", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.kl_divergence": [[49, 53], ["jax.sum", "jax.exp", "jax.square", "jax.exp"], "function", ["None"], ["", "def", "kl_divergence", "(", "mean1", ",", "logvar1", ",", "mean2", ",", "logvar2", ",", "batch_size", ")", ":", "\n", "  ", "kld", "=", "0.5", "*", "(", "-", "1.0", "+", "logvar2", "-", "logvar1", "+", "jnp", ".", "exp", "(", "logvar1", "-", "logvar2", ")", "\n", "+", "jnp", ".", "square", "(", "mean1", "-", "mean2", ")", "*", "jnp", ".", "exp", "(", "-", "logvar2", ")", ")", "\n", "return", "jnp", ".", "sum", "(", "kld", ")", "/", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.l2_norm": [[55, 59], ["jax.tree_flatten", "jax.tree_flatten", "jax.sqrt", "sum", "jax.vdot"], "function", ["None"], ["", "def", "l2_norm", "(", "tree", ")", ":", "\n", "  ", "\"\"\"Compute the l2 norm of a pytree of arrays.\"\"\"", "\n", "leaves", ",", "_", "=", "jax", ".", "tree_flatten", "(", "tree", ")", "\n", "return", "jnp", ".", "sqrt", "(", "sum", "(", "jnp", ".", "vdot", "(", "x", ",", "x", ")", "for", "x", "in", "leaves", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.clip_grads": [[61, 66], ["utils.l2_norm", "jax.tree_map", "jax.tree_map", "jax.where"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.utils.l2_norm"], ["", "def", "clip_grads", "(", "grad_tree", ",", "max_norm", ")", ":", "\n", "  ", "\"\"\"Clip gradients stored as a pytree of arrays to maximum norm `max_norm`.\"\"\"", "\n", "norm", "=", "l2_norm", "(", "grad_tree", ")", "\n", "normalize", "=", "lambda", "g", ":", "jnp", ".", "where", "(", "norm", "<", "max_norm", ",", "g", ",", "g", "*", "(", "max_norm", "/", "norm", ")", ")", "\n", "return", "jax", ".", "tree_map", "(", "normalize", ",", "grad_tree", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.image_float_to_uint": [[68, 72], ["numpy.clip"], "function", ["None"], ["", "def", "image_float_to_uint", "(", "image", ")", ":", "\n", "  ", "image", "=", "np", ".", "clip", "(", "image", ",", "0.0", ",", "1.0", ")", "\n", "image", "=", "(", "255", "*", "image", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.generate_rng_dict": [[74, 78], ["jax.random.split", "jax.random.split", "len", "enumerate"], "function", ["None"], ["", "def", "generate_rng_dict", "(", "base_rng", ")", ":", "\n", "  ", "keys", "=", "(", "\"params\"", ",", "\"dropout\"", ",", "\"rng\"", ")", "\n", "rngs", "=", "jax", ".", "random", ".", "split", "(", "base_rng", ",", "len", "(", "keys", ")", ")", "\n", "return", "{", "key", ":", "rngs", "[", "i", "]", "for", "i", ",", "key", "in", "enumerate", "(", "keys", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.cross_entropy_loss": [[80, 85], ["jax.nn.one_hot", "jax.nn.one_hot", "jax.nn.log_softmax", "jax.nn.log_softmax", "jax.mean", "jax.sum"], "function", ["None"], ["", "def", "cross_entropy_loss", "(", "logits", ",", "labels", ")", ":", "\n", "  ", "labels", "=", "jax", ".", "nn", ".", "one_hot", "(", "labels", ",", "logits", ".", "shape", "[", "-", "1", "]", ")", "\n", "log_probs", "=", "jax", ".", "nn", ".", "log_softmax", "(", "logits", ",", "axis", "=", "-", "1", ")", "\n", "x_entropy", "=", "-", "jnp", ".", "sum", "(", "log_probs", "*", "labels", ",", "axis", "=", "-", "1", ")", "\n", "return", "jnp", ".", "mean", "(", "x_entropy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.l1_loss": [[87, 89], ["jax.mean", "jax.absolute"], "function", ["None"], ["", "def", "l1_loss", "(", "model_logits", ",", "ground_truth", ")", ":", "\n", "  ", "return", "jnp", ".", "mean", "(", "jnp", ".", "absolute", "(", "model_logits", "-", "ground_truth", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.l2_loss": [[91, 93], ["jax.mean", "jax.square"], "function", ["None"], ["", "def", "l2_loss", "(", "model_logits", ",", "ground_truth", ")", ":", "\n", "  ", "return", "jnp", ".", "mean", "(", "jnp", ".", "square", "(", "model_logits", "-", "ground_truth", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils._sync_batch_stats": [[95, 97], ["jax.lax.pmean"], "function", ["None"], ["", "def", "_sync_batch_stats", "(", "x", ")", ":", "\n", "  ", "return", "lax", ".", "pmean", "(", "x", ",", "\"batch\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.sync_batch_stats": [[99, 108], ["jax.pmap", "jax.pmap", "state.model_state.copy", "state.replace", "state.model_state.keys", "jax.pmap."], "function", ["None"], ["", "def", "sync_batch_stats", "(", "state", ")", ":", "\n", "  ", "\"\"\"Sync the batch statistics across replicas.\"\"\"", "\n", "if", "\"batch_stats\"", "not", "in", "state", ".", "model_state", ".", "keys", "(", ")", ":", "\n", "    ", "return", "state", "\n", "\n", "", "avg", "=", "jax", ".", "pmap", "(", "_sync_batch_stats", ",", "\"batch\"", ")", "\n", "new_model_state", "=", "state", ".", "model_state", ".", "copy", "(", "{", "\n", "\"batch_stats\"", ":", "avg", "(", "state", ".", "model_state", "[", "\"batch_stats\"", "]", ")", "}", ")", "\n", "return", "state", ".", "replace", "(", "model_state", "=", "new_model_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.nested_dict_path_print": [[110, 119], ["utils.nested_dict_path_print.pretty_dict"], "function", ["None"], ["", "def", "nested_dict_path_print", "(", "d", ")", ":", "\n", "  ", "def", "pretty_dict", "(", "x", ",", "path", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "x", ",", "dict", ")", ":", "\n", "      ", "return", "f\"{path}: {repr(x)}\\n\"", "\n", "", "rep", "=", "\"\"", "\n", "for", "key", ",", "val", "in", "x", ".", "items", "(", ")", ":", "\n", "      ", "rep", "+=", "pretty_dict", "(", "val", ",", "f\"{path}/{key}\"", ")", "\n", "", "return", "rep", "\n", "", "return", "pretty_dict", "(", "d", ",", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.print_model_size": [[121, 128], ["jax.tree_map", "jax.tree_map", "sum", "absl.logging.info", "absl.logging.info", "absl.logging.info", "absl.logging.info", "utils.nested_dict_path_print", "jax.tree_flatten", "jax.tree_flatten"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.utils.nested_dict_path_print"], ["", "def", "print_model_size", "(", "params", ",", "name", "=", "\"\"", ")", ":", "\n", "  ", "model_params_size", "=", "jax", ".", "tree_map", "(", "lambda", "x", ":", "x", ".", "size", ",", "params", ")", "\n", "total_params_size", "=", "sum", "(", "jax", ".", "tree_flatten", "(", "model_params_size", ")", "[", "0", "]", ")", "\n", "logging", ".", "info", "(", "\"#\"", "*", "30", ")", "\n", "logging", ".", "info", "(", "\"###### %s Parameters: %d\"", ",", "name", ",", "total_params_size", ")", "\n", "logging", ".", "info", "(", "\"#\"", "*", "30", ")", "\n", "logging", ".", "info", "(", "nested_dict_path_print", "(", "model_params_size", ".", "_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.get_average_across_devices": [[130, 133], ["jax.tree_map", "jax.tree_map", "jax.device_get", "jax.device_get", "a.mean"], "function", ["None"], ["", "def", "get_average_across_devices", "(", "x", ")", ":", "\n", "  ", "x", "=", "jax", ".", "tree_map", "(", "lambda", "a", ":", "a", ".", "mean", "(", "axis", "=", "0", ")", ",", "x", ")", "\n", "return", "jax", ".", "device_get", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.get_first_device": [[135, 138], ["jax.tree_map", "jax.tree_map", "jax.device_get", "jax.device_get"], "function", ["None"], ["", "def", "get_first_device", "(", "x", ")", ":", "\n", "  ", "x", "=", "jax", ".", "tree_map", "(", "lambda", "a", ":", "a", "[", "0", "]", ",", "x", ")", "\n", "return", "jax", ".", "device_get", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.get_all_devices": [[140, 143], ["jax.tree_map", "jax.tree_map", "jax.device_get", "jax.device_get", "jax.reshape"], "function", ["None"], ["", "def", "get_all_devices", "(", "x", ")", ":", "\n", "  ", "x", "=", "jax", ".", "tree_map", "(", "lambda", "a", ":", "jnp", ".", "reshape", "(", "a", ",", "(", "-", "1", ",", ")", "+", "a", ".", "shape", "[", "2", ":", "]", ")", ",", "x", ")", "\n", "return", "jax", ".", "device_get", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.encode_gif": [[145, 172], ["subprocess.Popen", "range", "subprocess.Popen.communicate", "subprocess.Popen.stdin.write", "IOError", "video[].tostring", "err.decode"], "function", ["None"], ["", "def", "encode_gif", "(", "video", ",", "fps", ")", ":", "\n", "  ", "\"\"\"Encode a video into gif.\"\"\"", "\n", "import", "subprocess", "\n", "l", ",", "h", ",", "w", ",", "c", "=", "video", ".", "shape", "\n", "ffmpeg", "=", "\"ffmpeg\"", "\n", "cmd", "=", "[", "\n", "ffmpeg", ",", "\"-y\"", ",", "\"-f\"", ",", "\"rawvideo\"", ",", "\"-vcodec\"", ",", "\"rawvideo\"", ",", "\"-r\"", ",", "\n", "\"%.02f\"", "%", "fps", ",", "\"-s\"", ",", "\n", "\"%dx%d\"", "%", "(", "w", ",", "h", ")", ",", "\"-pix_fmt\"", ",", "{", "\n", "1", ":", "\"gray\"", ",", "\n", "3", ":", "\"rgb24\"", "\n", "}", "[", "c", "]", ",", "\"-i\"", ",", "\"-\"", ",", "\"-filter_complex\"", ",", "\n", "\"[0:v]split[x][z];[z]palettegen[y];[x]fifo[x];[x][y]paletteuse\"", ",", "\"-r\"", ",", "\n", "\"%.02f\"", "%", "fps", ",", "\"-f\"", ",", "\"gif\"", ",", "\"-\"", "\n", "]", "\n", "proc", "=", "subprocess", ".", "Popen", "(", "\n", "cmd", ",", "\n", "stdin", "=", "subprocess", ".", "PIPE", ",", "\n", "stdout", "=", "subprocess", ".", "PIPE", ",", "\n", "stderr", "=", "subprocess", ".", "PIPE", ")", "\n", "for", "i", "in", "range", "(", "l", ")", ":", "\n", "    ", "proc", ".", "stdin", ".", "write", "(", "video", "[", "i", "]", ".", "tostring", "(", ")", ")", "\n", "", "out", ",", "err", "=", "proc", ".", "communicate", "(", ")", "\n", "if", "proc", ".", "returncode", ":", "\n", "    ", "raise", "IOError", "(", "\"\\n\"", ".", "join", "(", "[", "\" \"", ".", "join", "(", "cmd", ")", ",", "err", ".", "decode", "(", "\"utf8\"", ")", "]", ")", ")", "\n", "", "del", "proc", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.write_video_summaries": [[174, 189], ["utils.image_float_to_uint", "tuple", "range", "utils.encode_gif", "tensorflow.concat", "tensorboard.plugins.image.metadata.create_summary_metadata", "summary_writer.write", "numpy.reshape", "summary_writer.image", "tensorflow.as_string", "tensorflow.as_string", "tensorflow.convert_to_tensor"], "function", ["home.repos.pwc.inspect_result.google-research_fitvid.None.utils.image_float_to_uint", "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.encode_gif"], ["", "def", "write_video_summaries", "(", "summary_writer", ",", "video_batch", ",", "num_samples", ",", "step", ")", ":", "\n", "  ", "\"\"\"Writes a video summary in gif and side by side images format.\"\"\"", "\n", "video_batch", "=", "image_float_to_uint", "(", "video_batch", ")", "\n", "_", ",", "video_len", ",", "w", ",", "h", ",", "c", "=", "tuple", "(", "video_batch", ".", "shape", ")", "\n", "for", "i", "in", "range", "(", "num_samples", ")", ":", "\n", "    ", "video", "=", "video_batch", "[", "i", "]", "\n", "summary", "=", "encode_gif", "(", "video", ",", "fps", "=", "15", ")", "\n", "tensor", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "as_string", "(", "w", ")", ",", "tf", ".", "as_string", "(", "h", ")", ",", "tf", ".", "convert_to_tensor", "(", "summary", ")", "]", ",", "\n", "axis", "=", "0", ")", "\n", "md", "=", "metadata", ".", "create_summary_metadata", "(", "\n", "display_name", "=", "None", ",", "description", "=", "None", ")", "\n", "summary_writer", ".", "write", "(", "tag", "=", "\"gif_%d\"", "%", "i", ",", "tensor", "=", "tensor", ",", "step", "=", "step", ",", "metadata", "=", "md", ")", "\n", "mo", "=", "np", ".", "reshape", "(", "video", ",", "[", "w", "*", "video_len", ",", "h", ",", "c", "]", ")", "\n", "summary_writer", ".", "image", "(", "tag", "=", "\"sidebyside_%d\"", "%", "i", ",", "image", "=", "mo", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.scheduler": [[191, 246], ["n.strip", "jax.asarray", "factors.split", "jax.minimum", "jax.sqrt", "jax.maximum", "jax.sqrt", "jax.sqrt", "jax.maximum", "jax.maximum", "jax.maximum", "ValueError", "float", "jax.cos"], "function", ["None"], ["", "", "def", "scheduler", "(", "\n", "factors", "=", "\"constant * linear_warmup * rsqrt_decay\"", ",", "\n", "base_learning_rate", "=", "0.5", ",", "\n", "warmup_steps", "=", "8000", ",", "\n", "decay_factor", "=", "0.5", ",", "\n", "steps_per_decay", "=", "20000", ",", "\n", "steps_per_cycle", "=", "100000", ")", ":", "\n", "  ", "\"\"\"creates learning rate schedule.\n\n  Interprets factors in the factors string which can consist of:\n  * constant: interpreted as the constant value,\n  * linear_warmup: interpreted as linear warmup until warmup_steps,\n  * rsqrt_decay: divide by square root of max(step, warmup_steps)\n  * decay_every: Every k steps decay the learning rate by decay_factor.\n  * cosine_decay: Cyclic cosine decay, uses steps_per_cycle parameter.\n\n  Args:\n    factors: a string with factors separated by '*' that defines the schedule.\n    base_learning_rate: float, the starting constant for the lr schedule.\n    warmup_steps: how many steps to warm up for in the warmup schedule.\n    decay_factor: The amount to decay the learning rate by.\n    steps_per_decay: How often to decay the learning rate.\n    steps_per_cycle: Steps per cycle when using cosine decay.\n\n  Returns:\n    a function learning_rate(step): float -> {'learning_rate': float}, the\n    step-dependent lr.\n  \"\"\"", "\n", "factors", "=", "[", "n", ".", "strip", "(", ")", "for", "n", "in", "factors", ".", "split", "(", "\"*\"", ")", "]", "\n", "\n", "def", "step_fn", "(", "step", ")", ":", "\n", "    ", "\"\"\"Step to learning rate function.\"\"\"", "\n", "ret", "=", "1.0", "\n", "for", "name", "in", "factors", ":", "\n", "      ", "if", "name", "==", "\"constant\"", ":", "\n", "        ", "ret", "*=", "base_learning_rate", "\n", "", "elif", "name", "==", "\"linear_warmup\"", ":", "\n", "        ", "ret", "*=", "jnp", ".", "minimum", "(", "1.0", ",", "step", "/", "warmup_steps", ")", "\n", "", "elif", "name", "==", "\"rsqrt_decay\"", ":", "\n", "        ", "ret", "/=", "jnp", ".", "sqrt", "(", "jnp", ".", "maximum", "(", "step", ",", "warmup_steps", ")", ")", "\n", "", "elif", "name", "==", "\"rsqrt_normalized_decay\"", ":", "\n", "        ", "ret", "*=", "jnp", ".", "sqrt", "(", "warmup_steps", ")", "\n", "ret", "/=", "jnp", ".", "sqrt", "(", "jnp", ".", "maximum", "(", "step", ",", "warmup_steps", ")", ")", "\n", "", "elif", "name", "==", "\"decay_every\"", ":", "\n", "        ", "ret", "*=", "(", "decay_factor", "**", "(", "step", "//", "steps_per_decay", ")", ")", "\n", "", "elif", "name", "==", "\"cosine_decay\"", ":", "\n", "        ", "progress", "=", "jnp", ".", "maximum", "(", "0.0", ",", "\n", "(", "step", "-", "warmup_steps", ")", "/", "float", "(", "steps_per_cycle", ")", ")", "\n", "ret", "*=", "jnp", ".", "maximum", "(", "0.0", ",", "\n", "0.5", "*", "(", "1.0", "+", "jnp", ".", "cos", "(", "jnp", ".", "pi", "*", "(", "progress", "%", "1.0", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown factor %s.\"", "%", "name", ")", "\n", "", "", "return", "jnp", ".", "asarray", "(", "ret", ",", "dtype", "=", "jnp", ".", "float32", ")", "\n", "\n", "", "return", "step_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_fitvid.None.utils.plot_1d_signals": [[248, 264], ["matplotlib.use", "plt.figure", "plt.figure.add_subplot", "zip", "fig.add_subplot.legend", "plt.figure.canvas.draw", "numpy.fromstring", "image.reshape.reshape", "plt.close", "fig.add_subplot.plot", "plt.figure.canvas.tostring_rgb", "plt.figure.canvas.get_width_height"], "function", ["None"], ["", "def", "plot_1d_signals", "(", "signals", ",", "labels", ")", ":", "\n", "  ", "\"\"\"Plot a 1d signals and converts into an image.\"\"\"", "\n", "import", "matplotlib", "\n", "matplotlib", ".", "use", "(", "\"Agg\"", ")", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "1", ",", "1", ",", "1", ")", "\n", "for", "x", ",", "l", "in", "zip", "(", "signals", ",", "labels", ")", ":", "\n", "    ", "ax", ".", "plot", "(", "x", ",", "\"--o\"", ",", "label", "=", "l", ")", "\n", "", "ax", ".", "legend", "(", ")", "\n", "fig", ".", "canvas", ".", "draw", "(", ")", "\n", "image", "=", "np", ".", "fromstring", "(", "fig", ".", "canvas", ".", "tostring_rgb", "(", ")", ",", "dtype", "=", "np", ".", "uint8", ",", "sep", "=", "\"\"", ")", "\n", "image", "=", "image", ".", "reshape", "(", "fig", ".", "canvas", ".", "get_width_height", "(", ")", "[", ":", ":", "-", "1", "]", "+", "(", "3", ",", ")", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "return", "image", "\n", "", ""]]}