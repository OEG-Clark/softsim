{"home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.run_epoch": [[21, 52], ["tqdm.tqdm", "images.to.to", "labels.to.to", "epoch_labels.append", "epoch_logits.append", "epoch_group_ids.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "algorithm.learn", "algorithm.predict", "labels.to.to().clone().detach", "algorithm.predict.to().clone().detach", "group_ids.to().clone().detach", "labels.to.to().clone", "algorithm.predict.to().clone", "group_ids.to().clone", "labels.to.to", "algorithm.predict.to", "group_ids.to"], "function", ["home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DANN.learn", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ARM_BN.predict"], ["def", "run_epoch", "(", "algorithm", ",", "loader", ",", "train", ",", "progress_bar", "=", "True", ")", ":", "\n", "\n", "    ", "epoch_labels", "=", "[", "]", "\n", "epoch_logits", "=", "[", "]", "\n", "epoch_group_ids", "=", "[", "]", "\n", "\n", "if", "progress_bar", ":", "\n", "        ", "loader", "=", "tqdm", "(", "loader", ",", "desc", "=", "f'{\"train\" if train else \"eval\"} loop'", ")", "\n", "\n", "\n", "", "for", "images", ",", "labels", ",", "group_ids", "in", "loader", ":", "\n", "\n", "# Put on GPU", "\n", "        ", "images", "=", "images", ".", "to", "(", "algorithm", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "algorithm", ".", "device", ")", "\n", "\n", "\n", "\n", "# Forward", "\n", "if", "train", ":", "\n", "            ", "logits", ",", "batch_stats", "=", "algorithm", ".", "learn", "(", "images", ",", "labels", ",", "group_ids", ")", "\n", "if", "logits", "is", "None", ":", "# DANN", "\n", "                ", "continue", "\n", "", "", "else", ":", "\n", "            ", "logits", "=", "algorithm", ".", "predict", "(", "images", ")", "\n", "\n", "", "epoch_labels", ".", "append", "(", "labels", ".", "to", "(", "'cpu'", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", ")", "\n", "epoch_logits", ".", "append", "(", "logits", ".", "to", "(", "'cpu'", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", ")", "\n", "epoch_group_ids", ".", "append", "(", "group_ids", ".", "to", "(", "'cpu'", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "epoch_logits", ")", ",", "torch", ".", "cat", "(", "epoch_labels", ")", ",", "torch", ".", "cat", "(", "epoch_group_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.train": [[53, 82], ["data.get_loaders", "algorithm.init_algorithm", "utils.Saver", "tqdm.trange", "train.run_epoch", "train.eval_groupwise", "print", "utils.Saver.save", "wandb.log"], "function", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.loader.get_loaders", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.init_algorithm", "home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.run_epoch", "home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.eval_groupwise", "home.repos.pwc.inspect_result.henrikmarklund_arm.utils.model_utils.Saver.save", "home.repos.pwc.inspect_result.henrikmarklund_arm.None.run.ScoreKeeper.log"], ["", "def", "train", "(", "args", ")", ":", "\n", "\n", "# Get data", "\n", "    ", "train_loader", ",", "_", ",", "val_loader", ",", "_", "=", "data", ".", "get_loaders", "(", "args", ")", "\n", "args", ".", "n_groups", "=", "train_loader", ".", "dataset", ".", "n_groups", "\n", "\n", "algorithm", "=", "init_algorithm", "(", "args", ",", "train_loader", ".", "dataset", ")", "\n", "saver", "=", "utils", ".", "Saver", "(", "algorithm", ",", "args", ".", "device", ",", "args", ".", "ckpt_dir", ")", "\n", "\n", "# Train loop", "\n", "best_worst_case_acc", "=", "0", "\n", "\n", "for", "epoch", "in", "trange", "(", "args", ".", "num_epochs", ")", ":", "\n", "        ", "epoch_logits", ",", "epoch_labels", ",", "epoch_group_ids", "=", "run_epoch", "(", "algorithm", ",", "train_loader", ",", "train", "=", "True", ",", "progress_bar", "=", "args", ".", "progress_bar", ")", "\n", "\n", "if", "epoch", "%", "args", ".", "epochs_per_eval", "==", "0", ":", "\n", "            ", "stats", "=", "eval_groupwise", "(", "args", ",", "algorithm", ",", "val_loader", ",", "epoch", ",", "split", "=", "'val'", ",", "n_samples_per_group", "=", "args", ".", "n_samples_per_group", ")", "\n", "\n", "# Track early stopping values with respect to worst case.", "\n", "if", "stats", "[", "'val/worst_case_acc'", "]", ">", "best_worst_case_acc", ":", "\n", "                ", "best_worst_case_acc", "=", "stats", "[", "'val/worst_case_acc'", "]", "\n", "saver", ".", "save", "(", "epoch", ",", "is_best", "=", "True", ")", "\n", "\n", "\n", "# Log early stopping values", "\n", "", "if", "args", ".", "log_wandb", ":", "\n", "                ", "wandb", ".", "log", "(", "{", "\"val/best_worst_case_acc\"", ":", "best_worst_case_acc", "}", ")", "\n", "\n", "", "print", "(", "f\"\\nEpoch: \"", ",", "epoch", ",", "\"\\nWorst Case Acc: \"", ",", "stats", "[", "'val/worst_case_acc'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.get_group_iterator": [[87, 110], ["enumerate", "numpy.nonzero", "X.append", "Y.append", "G.append", "batches.append", "numpy.random.permutation", "batches.append", "torch.stack", "torch.stack", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "torch.stack", "torch.stack", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "", "", "def", "get_group_iterator", "(", "loader", ",", "group", ",", "support_size", ",", "n_samples_per_group", "=", "None", ")", ":", "\n", "    ", "example_ids", "=", "np", ".", "nonzero", "(", "loader", ".", "dataset", ".", "group_ids", "==", "group", ")", "[", "0", "]", "\n", "example_ids", "=", "example_ids", "[", "np", ".", "random", ".", "permutation", "(", "len", "(", "example_ids", ")", ")", "]", "# Shuffle example ids", "\n", "\n", "# Create batches", "\n", "batches", "=", "[", "]", "\n", "X", ",", "Y", ",", "G", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "counter", "=", "0", "\n", "for", "i", ",", "idx", "in", "enumerate", "(", "example_ids", ")", ":", "\n", "        ", "x", ",", "y", ",", "g", "=", "loader", ".", "dataset", "[", "idx", "]", "\n", "X", ".", "append", "(", "x", ")", ";", "Y", ".", "append", "(", "y", ")", ";", "G", ".", "append", "(", "g", ")", "\n", "if", "(", "i", "+", "1", ")", "%", "support_size", "==", "0", ":", "\n", "            ", "X", ",", "Y", ",", "G", "=", "torch", ".", "stack", "(", "X", ")", ",", "torch", ".", "tensor", "(", "Y", ",", "dtype", "=", "torch", ".", "long", ")", ",", "torch", ".", "tensor", "(", "G", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "batches", ".", "append", "(", "(", "X", ",", "Y", ",", "G", ")", ")", "\n", "X", ",", "Y", ",", "G", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "", "if", "n_samples_per_group", "is", "not", "None", "and", "i", "==", "(", "n_samples_per_group", "-", "1", ")", ":", "\n", "            ", "break", "\n", "", "", "if", "X", ":", "\n", "        ", "X", ",", "Y", ",", "G", "=", "torch", ".", "stack", "(", "X", ")", ",", "torch", ".", "tensor", "(", "Y", ",", "dtype", "=", "torch", ".", "long", ")", ",", "torch", ".", "tensor", "(", "G", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "batches", ".", "append", "(", "(", "X", ",", "Y", ",", "G", ")", ")", "\n", "\n", "", "return", "batches", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.eval_groupwise": [[111, 172], ["numpy.zeros", "numpy.zeros", "tqdm.tqdm", "numpy.amin", "numpy.array", "np.zeros.dot", "numpy.mean", "np.array.sum", "len", "len", "algorithm.train", "algorithm.eval", "enumerate", "train.get_group_iterator", "train.run_epoch", "numpy.argmax", "numpy.mean", "len", "np.array.sum", "wandb.log", "len", "numpy.argmin", "wandb.log", "wandb.log"], "function", ["home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.train", "home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.get_group_iterator", "home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.run_epoch", "home.repos.pwc.inspect_result.henrikmarklund_arm.None.run.ScoreKeeper.log", "home.repos.pwc.inspect_result.henrikmarklund_arm.None.run.ScoreKeeper.log", "home.repos.pwc.inspect_result.henrikmarklund_arm.None.run.ScoreKeeper.log"], ["", "def", "eval_groupwise", "(", "args", ",", "algorithm", ",", "loader", ",", "epoch", "=", "None", ",", "split", "=", "'val'", ",", "n_samples_per_group", "=", "None", ")", ":", "\n", "    ", "\"\"\" Test model on groups and log to wandb\n\n        Separate script for femnist for speed.\"\"\"", "\n", "\n", "groups", "=", "[", "]", "\n", "accuracies", "=", "np", ".", "zeros", "(", "len", "(", "loader", ".", "dataset", ".", "groups", ")", ")", "\n", "num_examples", "=", "np", ".", "zeros", "(", "len", "(", "loader", ".", "dataset", ".", "groups", ")", ")", "\n", "\n", "if", "args", ".", "adapt_bn", ":", "\n", "        ", "algorithm", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "        ", "algorithm", ".", "eval", "(", ")", "\n", "\n", "# Loop over each group", "\n", "", "for", "i", ",", "group", "in", "tqdm", "(", "enumerate", "(", "loader", ".", "dataset", ".", "groups", ")", ",", "desc", "=", "'Evaluating'", ",", "total", "=", "len", "(", "loader", ".", "dataset", ".", "groups", ")", ")", ":", "\n", "        ", "counter", "=", "0", "\n", "group_iterator", "=", "get_group_iterator", "(", "loader", ",", "group", ",", "args", ".", "support_size", ",", "n_samples_per_group", ")", "\n", "\n", "logits", ",", "labels", ",", "group_ids", "=", "run_epoch", "(", "algorithm", ",", "group_iterator", ",", "train", "=", "False", ",", "progress_bar", "=", "False", ")", "\n", "preds", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", "\n", "\n", "# Evaluate", "\n", "accuracy", "=", "np", ".", "mean", "(", "(", "preds", "==", "labels", ")", ".", "numpy", "(", ")", ")", "\n", "num_examples", "[", "group", "]", "=", "len", "(", "labels", ")", "\n", "accuracies", "[", "group", "]", "=", "accuracy", "\n", "\n", "if", "args", ".", "log_wandb", ":", "\n", "            ", "if", "epoch", "is", "None", ":", "\n", "                ", "wandb", ".", "log", "(", "{", "f\"{split}/acc\"", ":", "accuracy", ",", "# Gives us Acc vs Group Id", "\n", "f\"{split}/group_id\"", ":", "group", "}", ")", "\n", "", "else", ":", "\n", "                ", "wandb", ".", "log", "(", "{", "f\"{split}/acc_e{epoch}\"", ":", "accuracy", ",", "# Gives us Acc vs Group Id", "\n", "f\"{split}/group_id\"", ":", "group", "}", ")", "\n", "\n", "# Log worst, average and empirical accuracy", "\n", "", "", "", "worst_case_acc", "=", "np", ".", "amin", "(", "accuracies", ")", "\n", "worst_case_group_size", "=", "num_examples", "[", "np", ".", "argmin", "(", "accuracies", ")", "]", "\n", "\n", "num_examples", "=", "np", ".", "array", "(", "num_examples", ")", "\n", "props", "=", "num_examples", "/", "num_examples", ".", "sum", "(", ")", "\n", "empirical_case_acc", "=", "accuracies", ".", "dot", "(", "props", ")", "\n", "average_case_acc", "=", "np", ".", "mean", "(", "accuracies", ")", "\n", "\n", "total_size", "=", "num_examples", ".", "sum", "(", ")", "\n", "\n", "stats", "=", "{", "\n", "f'{split}/worst_case_acc'", ":", "worst_case_acc", ",", "\n", "f'{split}/worst_case_group_size'", ":", "worst_case_group_size", ",", "\n", "f'{split}/average_acc'", ":", "average_case_acc", ",", "\n", "f'{split}/total_size'", ":", "total_size", ",", "\n", "f'{split}/empirical_acc'", ":", "empirical_case_acc", "\n", "}", "\n", "\n", "if", "epoch", "is", "not", "None", ":", "\n", "        ", "stats", "[", "'epoch'", "]", "=", "epoch", "\n", "\n", "", "if", "args", ".", "log_wandb", ":", "\n", "        ", "wandb", ".", "log", "(", "stats", ")", "\n", "\n", "", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.None.run.ScoreKeeper.__init__": [[130, 138], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "splits", ",", "n_seeds", ")", ":", "\n", "\n", "        ", "self", ".", "splits", "=", "splits", "\n", "self", ".", "n_seeds", "=", "n_seeds", "\n", "\n", "self", ".", "results", "=", "{", "}", "\n", "for", "split", "in", "splits", ":", "\n", "            ", "self", ".", "results", "[", "split", "]", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.None.run.ScoreKeeper.log": [[139, 150], ["[].append", "key.split"], "methods", ["None"], ["", "", "def", "log", "(", "self", ",", "stats", ")", ":", "\n", "        ", "for", "split", "in", "stats", ":", "\n", "            ", "split_stats", "=", "stats", "[", "split", "]", "\n", "for", "key", "in", "split_stats", ":", "\n", "                ", "value", "=", "split_stats", "[", "key", "]", "\n", "metric_name", "=", "key", ".", "split", "(", "'/'", ")", "[", "1", "]", "\n", "\n", "if", "metric_name", "not", "in", "self", ".", "results", "[", "split", "]", ":", "\n", "                    ", "self", ".", "results", "[", "split", "]", "[", "metric_name", "]", "=", "[", "]", "\n", "\n", "", "self", ".", "results", "[", "split", "]", "[", "metric_name", "]", ".", "append", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.None.run.ScoreKeeper.print_stats": [[151, 163], ["print", "numpy.array", "numpy.mean", "print", "numpy.std", "numpy.sqrt"], "methods", ["None"], ["", "", "", "def", "print_stats", "(", "self", ",", "metric_names", "=", "[", "'worst_case_acc'", ",", "'average_acc'", ",", "'empirical_acc'", "]", ")", ":", "\n", "\n", "        ", "for", "split", "in", "self", ".", "splits", ":", "\n", "            ", "print", "(", "\"Split: \"", ",", "split", ")", "\n", "\n", "for", "metric_name", "in", "metric_names", ":", "\n", "\n", "                ", "values", "=", "np", ".", "array", "(", "self", ".", "results", "[", "split", "]", "[", "metric_name", "]", ")", "\n", "avg", "=", "np", ".", "mean", "(", "values", ")", "\n", "standard_error", "=", "np", ".", "std", "(", "values", ")", "/", "np", ".", "sqrt", "(", "self", ".", "n_seeds", "-", "1", ")", "\n", "\n", "print", "(", "f\"{metric_name}: {avg}, standard error: {standard_error}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.None.run.test": [[13, 29], ["data.get_loaders", "run.set_seed", "train.eval_groupwise"], "function", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.loader.get_loaders", "home.repos.pwc.inspect_result.henrikmarklund_arm.None.run.set_seed", "home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.eval_groupwise"], ["def", "test", "(", "args", ",", "algorithm", ",", "seed", ",", "eval_on", ")", ":", "\n", "\n", "# Get data", "\n", "    ", "train_loader", ",", "train_eval_loader", ",", "val_loader", ",", "test_loader", "=", "data", ".", "get_loaders", "(", "args", ")", "\n", "\n", "stats", "=", "{", "}", "\n", "loaders", "=", "{", "'train'", ":", "train_eval_loader", ",", "\n", "'val'", ":", "val_loader", ",", "\n", "'test'", ":", "test_loader", "}", "\n", "for", "split", "in", "eval_on", ":", "\n", "        ", "set_seed", "(", "seed", "+", "10", ",", "args", ".", "cuda", ")", "\n", "loader", "=", "loaders", "[", "split", "]", "\n", "split_stats", "=", "train", ".", "eval_groupwise", "(", "args", ",", "algorithm", ",", "loader", ",", "split", "=", "split", ",", "n_samples_per_group", "=", "args", ".", "test_n_samples_per_group", ")", "\n", "stats", "[", "split", "]", "=", "split_stats", "\n", "\n", "", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.None.run.get_parser": [[31, 112], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["", "def", "get_parser", "(", ")", ":", "\n", "# Arguments", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Train / test", "\n", "parser", ".", "add_argument", "(", "'--train'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"Train models\"", ")", "\n", "parser", ".", "add_argument", "(", "'--test'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"Test models\"", ")", "\n", "parser", ".", "add_argument", "(", "'--ckpt_folders'", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ")", "# only applicable when train is 0 and test is 1", "\n", "\n", "parser", ".", "add_argument", "(", "'--progress_bar'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"Test models\"", ")", "\n", "\n", "# Training / Optimization args", "\n", "parser", ".", "add_argument", "(", "'--num_epochs'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "'Number of epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--optimizer'", ",", "type", "=", "str", ",", "default", "=", "'adam'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adam'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "type", "=", "float", ",", "default", "=", "1e-4", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "type", "=", "float", ",", "default", "=", "0", ")", "\n", "\n", "# Data args", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "type", "=", "str", ",", "default", "=", "'mnist'", ",", "choices", "=", "[", "'mnist'", ",", "'femnist'", ",", "'cifar-c'", ",", "'tinyimg'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--data_dir'", ",", "type", "=", "str", ",", "default", "=", "'../data/'", ")", "\n", "\n", "\n", "# Data sampling", "\n", "parser", ".", "add_argument", "(", "'--sampler'", ",", "type", "=", "str", ",", "default", "=", "'standard'", ",", "\n", "choices", "=", "[", "'standard'", ",", "'group'", "]", ",", "\n", "help", "=", "'Standard or group sampler'", ")", "\n", "parser", ".", "add_argument", "(", "'--uniform_over_groups'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Sample across groups uniformly'", ")", "\n", "parser", ".", "add_argument", "(", "'--meta_batch_size'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "'Number of classes'", ")", "\n", "parser", ".", "add_argument", "(", "'--support_size'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'Support size: same as what we call batch size in the appendix'", ")", "\n", "parser", ".", "add_argument", "(", "'--shuffle_train'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Only relevant when no group sampling = 0 \\\n                        and --uniform_over_groups 0'", ")", "\n", "parser", ".", "add_argument", "(", "'--drop_last'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--loading_type'", ",", "type", "=", "str", ",", "choices", "=", "[", "'PIL'", ",", "'jpeg'", "]", ",", "default", "=", "'jpeg'", ",", "\n", "help", "=", "'Whether to use PIL or jpeg4py when loading images. Jpeg is faster. See README for deatiles'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--num_workers'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "'Num workers for pytorch data loader'", ")", "\n", "parser", ".", "add_argument", "(", "'--pin_memory'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'Pytorch loader pin memory. \\\n                        Best practice is to use this'", ")", "\n", "\n", "# Model args", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "'convnet'", ",", "\n", "choices", "=", "[", "'resnet50'", ",", "'convnet'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Pretrained resnet'", ")", "\n", "\n", "# Method", "\n", "parser", ".", "add_argument", "(", "'--algorithm'", ",", "type", "=", "str", ",", "default", "=", "'ERM'", ",", "choices", "=", "[", "'ERM'", ",", "'DRNN'", ",", "'ARM-CML'", ",", "'ARM-BN'", ",", "'ARM-LL'", ",", "'DANN'", ",", "'MMD'", "]", ")", "\n", "\n", "# ARM-CML", "\n", "parser", ".", "add_argument", "(", "'--n_context_channels'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'Used when using a convnet/resnet'", ")", "\n", "parser", ".", "add_argument", "(", "'--context_net'", ",", "type", "=", "str", ",", "default", "=", "'convnet'", ")", "\n", "parser", ".", "add_argument", "(", "'--pret_add_channels'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--adapt_bn'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "\n", "# Evalaution", "\n", "parser", ".", "add_argument", "(", "'--n_samples_per_group'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'Number of examples to evaluate on per test distribution'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_n_samples_per_group'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'Number of examples to evaluate on per test distribution'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs_per_eval'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "\n", "# Test", "\n", "parser", ".", "add_argument", "(", "'--eval_on'", ",", "type", "=", "str", ",", "nargs", "=", "\"*\"", ",", "default", "=", "[", "'test'", "]", ")", "\n", "\n", "# DANN", "\n", "parser", ".", "add_argument", "(", "'--lambd'", ",", "type", "=", "float", ",", "default", "=", "0.01", ")", "\n", "parser", ".", "add_argument", "(", "'--d_steps_per_g_step'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "\n", "# Logging", "\n", "parser", ".", "add_argument", "(", "'--seeds'", ",", "type", "=", "int", ",", "nargs", "=", "\"*\"", ",", "default", "=", "[", "0", "]", ",", "help", "=", "'Seeds'", ")", "\n", "parser", ".", "add_argument", "(", "'--plot'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Plot or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--exp_name'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--debug'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--log_wandb'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.None.run.set_seed": [[114, 125], ["print", "torch.manual_seed", "numpy.random.seed", "random.seed", "torch.cuda.manual_seed"], "function", ["None"], ["", "def", "set_seed", "(", "seed", ",", "cuda", ")", ":", "\n", "\n", "# Make as reproducible as possible.", "\n", "# Please note that pytorch does not let us make things completely reproducible across machines.", "\n", "# See https://pytorch.org/docs/stable/notes/randomness.html", "\n", "    ", "print", "(", "'setting seed'", ",", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "cuda", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.utils.model_utils.Saver.__init__": [[6, 11], ["pathlib.Path"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "algorithm", ",", "device", ",", "ckpt_dir", ")", ":", "\n", "\n", "        ", "self", ".", "algorithm", "=", "algorithm", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "ckpt_dir", "=", "Path", "(", "ckpt_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.utils.model_utils.Saver.save": [[12, 22], ["model_utils.Saver.ckpt_dir.mkdir", "torch.save", "model_utils.Saver.algorithm.to", "model_utils.Saver.algorithm.to", "torch.save"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.utils.model_utils.Saver.save", "home.repos.pwc.inspect_result.henrikmarklund_arm.utils.model_utils.Saver.save"], ["", "def", "save", "(", "self", ",", "epoch", ",", "is_best", ")", ":", "\n", "        ", "self", ".", "ckpt_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "ckpt_path", "=", "self", ".", "ckpt_dir", "/", "f'{epoch}.pkl'", "\n", "torch", ".", "save", "(", "self", ".", "algorithm", ".", "to", "(", "'cpu'", ")", ",", "ckpt_path", ")", "\n", "\n", "if", "is_best", ":", "\n", "            ", "ckpt_path", "=", "self", ".", "ckpt_dir", "/", "f'best.pkl'", "\n", "torch", ".", "save", "(", "self", ".", "algorithm", ",", "ckpt_path", ")", "\n", "\n", "", "self", ".", "algorithm", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.models.Identity.__init__": [[7, 9], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.FEMNISTDataset.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Identity", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.models.Identity.forward": [[10, 12], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.models.MLP.__init__": [[15, 26], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.FEMNISTDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_size", "=", "10", ",", "out_size", "=", "1", ",", "hidden_dim", "=", "32", ",", "norm_reduce", "=", "False", ")", ":", "\n", "        ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm_reduce", "=", "norm_reduce", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_size", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "out_size", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.models.MLP.forward": [[27, 33], ["models.MLP.model", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "model", "(", "x", ")", "\n", "if", "self", ".", "norm_reduce", ":", "\n", "            ", "out", "=", "torch", ".", "norm", "(", "out", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.models.ContextNet.__init__": [[36, 50], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.FEMNISTDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "hidden_dim", ",", "kernel_size", ")", ":", "\n", "        ", "super", "(", "ContextNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Keep same dimensions", "\n", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", "\n", "\n", "self", ".", "context_net", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "hidden_dim", ",", "kernel_size", ",", "padding", "=", "padding", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "hidden_dim", ",", "hidden_dim", ",", "kernel_size", ",", "padding", "=", "padding", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "hidden_dim", ",", "out_channels", ",", "kernel_size", ",", "padding", "=", "padding", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.models.ContextNet.forward": [[53, 56], ["models.ContextNet.context_net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "context_net", "(", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.models.ConvNet.__init__": [[58, 104], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sequential", "torch.Sequential", "print", "torch.Sequential", "torch.Sequential", "print", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "models.Identity", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.FEMNISTDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_classes", "=", "10", ",", "num_channels", "=", "3", ",", "smaller_model", "=", "True", ",", "hidden_dim", "=", "128", ",", "return_features", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "ConvNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "kernel_size", "=", "5", "\n", "\n", "self", ".", "smaller_model", "=", "smaller_model", "\n", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", "\n", "if", "smaller_model", ":", "\n", "            ", "print", "(", "\"using smaller model\"", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "num_channels", ",", "hidden_dim", ",", "kernel_size", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"using larger model\"", ")", "\n", "self", ".", "conv0", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "num_channels", ",", "hidden_dim", ",", "kernel_size", ",", "padding", "=", "padding", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "hidden_dim", ",", "hidden_dim", ",", "kernel_size", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", ")", "\n", "\n", "\n", "", "self", ".", "conv2", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "hidden_dim", ",", "hidden_dim", ",", "kernel_size", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ")", "\n", ")", "\n", "\n", "self", ".", "adaptive_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "\n", "self", ".", "final", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "200", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "Identity", "(", ")", "if", "return_features", "else", "nn", ".", "Linear", "(", "200", ",", "num_classes", ")", "\n", ")", "\n", "self", ".", "num_features", "=", "200", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.models.ConvNet.forward": [[106, 122], ["models.ConvNet.conv2", "models.ConvNet.adaptive_pool", "models.ConvNet.squeeze().squeeze", "models.ConvNet.final", "models.ConvNet.conv1", "models.ConvNet.conv0", "models.ConvNet.conv1", "models.ConvNet.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Returns logit with shape (batch_size, num_classes)\"\"\"", "\n", "\n", "# x shape: batch_size, num_channels, w, h", "\n", "\n", "if", "self", ".", "smaller_model", ":", "\n", "            ", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "self", ".", "conv0", "(", "x", ")", "\n", "out", "=", "self", ".", "conv1", "(", "out", ")", "\n", "", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "adaptive_pool", "(", "out", ")", "# shape: batch_size, hidden_dim, 1, 1", "\n", "out", "=", "out", ".", "squeeze", "(", "dim", "=", "-", "1", ")", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "# make sure not to squeeze the first dimension when batch size is 0.", "\n", "out", "=", "self", ".", "final", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.models.ResNet.__init__": [[126, 151], ["torch.Module.__init__", "models.Identity", "torch.Linear", "torch.Linear", "torch.Conv2d", "torch.Conv2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "range"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.FEMNISTDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_channels", ",", "num_classes", ",", "model_name", ",", "pretrained", "=", "None", ",", "\n", "avgpool", "=", "False", ",", "return_features", "=", "False", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "model", "=", "torchvision", ".", "models", ".", "__dict__", "[", "model_name", "]", "(", "pretrained", "=", "pretrained", ")", "\n", "self", ".", "num_features", "=", "self", ".", "model", ".", "fc", ".", "in_features", "\n", "if", "return_features", ":", "\n", "            ", "self", ".", "model", ".", "fc", "=", "Identity", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", ".", "fc", "=", "nn", ".", "Linear", "(", "self", ".", "num_features", ",", "num_classes", ")", "\n", "\n", "# Change number of input channels from 3 to whatever is needed", "\n", "# to take in the context also.", "\n", "", "if", "num_channels", "!=", "3", ":", "\n", "            ", "model_inplanes", "=", "64", "\n", "old_weights", "=", "self", ".", "model", ".", "conv1", ".", "weight", ".", "data", "\n", "self", ".", "model", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "num_channels", ",", "model_inplanes", ",", "\n", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "bias", "=", "False", ")", "\n", "\n", "if", "pretrained", ":", "\n", "                ", "for", "i", "in", "range", "(", "num_channels", ")", ":", "\n", "                    ", "self", ".", "model", ".", "conv1", ".", "weight", ".", "data", "[", ":", ",", "i", ",", ":", ",", ":", "]", "=", "old_weights", "[", ":", ",", "i", "%", "3", ",", ":", ",", ":", "]", "\n", "\n", "", "", "", "if", "avgpool", ":", "\n", "            ", "self", ".", "model", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.models.ResNet.forward": [[152, 156], ["models.ResNet.model"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "out", "=", "self", ".", "model", "(", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.AverageMeter.__init__": [[100, 103], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "name", ")", ":", "\n", "        ", "self", ".", "value", "=", "0", "\n", "self", ".", "total_count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.AverageMeter.update": [[104, 110], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "value", ",", "count", ")", ":", "\n", "        ", "old_count", "=", "self", ".", "total_count", "\n", "new_count", "=", "new_count", "+", "count", "\n", "\n", "self", ".", "value", "=", "self", ".", "value", "*", "old_count", "/", "new_count", "+", "value", "*", "count", "/", "new_count", "\n", "self", ".", "total_count", "=", "new_count", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.AverageMeter.reset": [[111, 114], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "value", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ERM.__init__": [[116, 129], ["torch.nn.Module.__init__", "algorithm.ERM.model.parameters", "algorithm.ERM.init_optimizers"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.FEMNISTDataset.__init__", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DANN.init_optimizers"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "loss_fn", ",", "device", ",", "hparams", ",", "init_optim", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "loss_fn", "=", "loss_fn", "\n", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "optimizer_name", "=", "hparams", "[", "'optimizer'", "]", "\n", "self", ".", "learning_rate", "=", "hparams", "[", "'learning_rate'", "]", "\n", "self", ".", "weight_decay", "=", "hparams", "[", "'weight_decay'", "]", "\n", "\n", "if", "init_optim", ":", "\n", "            ", "params", "=", "self", ".", "model", ".", "parameters", "(", ")", "\n", "self", ".", "init_optimizers", "(", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ERM.init_optimizers": [[130, 140], ["torch.optim.Adam", "torch.optim.SGD", "filter"], "methods", ["None"], ["", "", "def", "init_optimizers", "(", "self", ",", "params", ")", ":", "\n", "        ", "if", "self", ".", "optimizer_name", "==", "'adam'", ":", "\n", "            ", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "params", ",", "lr", "=", "self", ".", "learning_rate", ",", "\n", "weight_decay", "=", "self", ".", "weight_decay", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "params", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "\n", "momentum", "=", "0.9", ",", "\n", "weight_decay", "=", "self", ".", "weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ERM.predict": [[141, 143], ["algorithm.ERM.model"], "methods", ["None"], ["", "", "def", "predict", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ERM.update": [[144, 148], ["algorithm.ERM.optimizer.zero_grad", "loss.backward", "algorithm.ERM.optimizer.step"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "loss", ")", ":", "\n", "        ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ERM.get_acc": [[149, 154], ["numpy.argmax", "numpy.mean", "logits.detach().cpu().numpy", "labels.detach().cpu().numpy().reshape", "logits.detach().cpu", "labels.detach().cpu().numpy", "logits.detach", "labels.detach().cpu", "labels.detach"], "methods", ["None"], ["", "def", "get_acc", "(", "self", ",", "logits", ",", "labels", ")", ":", "\n", "# Evaluate", "\n", "        ", "preds", "=", "np", ".", "argmax", "(", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "1", ")", "\n", "accuracy", "=", "np", ".", "mean", "(", "preds", "==", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "reshape", "(", "-", "1", ")", ")", "\n", "return", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ERM.learn": [[155, 171], ["algorithm.ERM.train", "algorithm.ERM.predict", "algorithm.ERM.loss_fn", "algorithm.ERM.update", "algorithm.ERM.detach().item", "algorithm.ERM.detach"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.train", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ARM_BN.predict", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ERM.update"], ["", "def", "learn", "(", "self", ",", "images", ",", "labels", ",", "group_ids", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "train", "(", ")", "\n", "\n", "# Forward", "\n", "logits", "=", "self", ".", "predict", "(", "images", ")", "\n", "loss", "=", "self", ".", "loss_fn", "(", "logits", ",", "labels", ")", "\n", "\n", "\n", "self", ".", "update", "(", "loss", ")", "\n", "\n", "stats", "=", "{", "\n", "'objective'", ":", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", ",", "\n", "}", "\n", "\n", "return", "logits", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DRNNLossComputer.__init__": [[174, 194], ["torch.ones().to", "torch.ones"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "criterion", ",", "is_robust", ",", "n_groups", ",", "alpha", "=", "None", ",", "gamma", "=", "0.1", ",", "adj", "=", "None", ",", "\n", "min_var_weight", "=", "0", ",", "step_size", "=", "0.01", ",", "normalize_loss", "=", "False", ",", "btl", "=", "False", ",", "device", "=", "'cpu'", ")", ":", "\n", "\n", "        ", "self", ".", "criterion", "=", "criterion", "\n", "self", ".", "is_robust", "=", "is_robust", "\n", "self", ".", "step_size", "=", "step_size", "\n", "\n", "self", ".", "btl", "=", "btl", "# set to false", "\n", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "n_groups", "=", "n_groups", "\n", "\n", "# quantities mintained throughout training", "\n", "self", ".", "adv_probs", "=", "torch", ".", "ones", "(", "self", ".", "n_groups", ")", ".", "to", "(", "device", ")", "/", "self", ".", "n_groups", "\n", "\n", "# The following 4 variables are not used", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "min_var_weight", "=", "min_var_weight", "\n", "self", ".", "normalize_loss", "=", "normalize_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DRNNLossComputer.loss": [[195, 210], ["algorithm.DRNNLossComputer.criterion", "algorithm.DRNNLossComputer.compute_group_avg", "algorithm.DRNNLossComputer.compute_robust_loss", "algorithm.DRNNLossComputer.compute_robust_loss_btl", "algorithm.DRNNLossComputer.mean"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DRNNLossComputer.compute_group_avg", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DRNNLossComputer.compute_robust_loss"], ["", "def", "loss", "(", "self", ",", "yhat", ",", "y", ",", "group_idx", "=", "None", ",", "is_training", "=", "False", ")", ":", "\n", "# compute per-sample and per-group losses", "\n", "        ", "per_sample_losses", "=", "self", ".", "criterion", "(", "yhat", ",", "y", ")", "\n", "group_loss", ",", "group_count", "=", "self", ".", "compute_group_avg", "(", "per_sample_losses", ",", "group_idx", ")", "\n", "\n", "# compute overall loss", "\n", "if", "self", ".", "is_robust", "and", "not", "self", ".", "btl", ":", "\n", "            ", "actual_loss", ",", "weights", "=", "self", ".", "compute_robust_loss", "(", "group_loss", ",", "group_count", ")", "# this one is actually used", "\n", "", "elif", "self", ".", "is_robust", "and", "self", ".", "btl", ":", "\n", "             ", "actual_loss", ",", "weights", "=", "self", ".", "compute_robust_loss_btl", "(", "group_loss", ",", "group_count", ")", "\n", "", "else", ":", "\n", "            ", "actual_loss", "=", "per_sample_losses", ".", "mean", "(", ")", "\n", "weights", "=", "None", "\n", "\n", "", "return", "actual_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DRNNLossComputer.compute_robust_loss": [[211, 219], ["torch.exp", "algorithm.DRNNLossComputer.adv_probs.sum"], "methods", ["None"], ["", "def", "compute_robust_loss", "(", "self", ",", "group_loss", ",", "group_count", ")", ":", "\n", "        ", "adjusted_loss", "=", "group_loss", "\n", "\n", "self", ".", "adv_probs", "=", "self", ".", "adv_probs", "*", "torch", ".", "exp", "(", "self", ".", "step_size", "*", "adjusted_loss", ".", "data", ")", "\n", "self", ".", "adv_probs", "=", "self", ".", "adv_probs", "/", "(", "self", ".", "adv_probs", ".", "sum", "(", ")", ")", "\n", "\n", "robust_loss", "=", "group_loss", "@", "self", ".", "adv_probs", "\n", "return", "robust_loss", ",", "self", ".", "adv_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DRNNLossComputer.compute_group_avg": [[220, 227], ["group_map.sum", "losses.view", "torch.arange().unsqueeze().long().to", "torch.arange().unsqueeze().long", "torch.arange().unsqueeze", "torch.arange"], "methods", ["None"], ["", "def", "compute_group_avg", "(", "self", ",", "losses", ",", "group_idx", ")", ":", "\n", "# compute observed counts and mean loss for each group", "\n", "        ", "group_map", "=", "(", "group_idx", "==", "torch", ".", "arange", "(", "self", ".", "n_groups", ")", ".", "unsqueeze", "(", "1", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", ")", ".", "float", "(", ")", "\n", "group_count", "=", "group_map", ".", "sum", "(", "1", ")", "\n", "group_denom", "=", "group_count", "+", "(", "group_count", "==", "0", ")", ".", "float", "(", ")", "# avoid nans", "\n", "group_loss", "=", "(", "group_map", "@", "losses", ".", "view", "(", "-", "1", ")", ")", "/", "group_denom", "\n", "return", "group_loss", ",", "group_count", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DRNN.__init__": [[231, 240], ["algorithm.ERM.__init__", "algorithm.DRNNLossComputer"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.FEMNISTDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "loss_fn", ",", "device", ",", "n_groups", ",", "hparams", "=", "{", "}", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "loss_fn", ",", "device", ",", "hparams", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "n_groups", "=", "n_groups", "\n", "self", ".", "loss_computer", "=", "DRNNLossComputer", "(", "loss_fn", ",", "is_robust", "=", "True", ",", "\n", "n_groups", "=", "n_groups", ",", "\n", "step_size", "=", "hparams", "[", "'robust_step_size'", "]", ",", "\n", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DRNN.learn": [[241, 255], ["algorithm.DRNN.train", "algorithm.DRNN.predict", "algorithm.DRNN.loss_computer.loss", "algorithm.DRNN.update", "group_ids.to", "algorithm.DRNN.detach().item", "algorithm.DRNN.detach"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.train", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ARM_BN.predict", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DRNNLossComputer.loss", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ERM.update"], ["", "def", "learn", "(", "self", ",", "images", ",", "labels", ",", "group_ids", ")", ":", "\n", "        ", "self", ".", "train", "(", ")", "\n", "\n", "# Forward and backward", "\n", "logits", "=", "self", ".", "predict", "(", "images", ")", "\n", "loss", "=", "self", ".", "loss_computer", ".", "loss", "(", "logits", ",", "labels", ",", "group_ids", ".", "to", "(", "self", ".", "device", ")", ",", "is_training", "=", "True", ")", "\n", "\n", "self", ".", "update", "(", "loss", ")", "\n", "\n", "stats", "=", "{", "\n", "'objective'", ":", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "}", "\n", "\n", "return", "logits", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ARM_CML.__init__": [[258, 268], ["algorithm.ERM.__init__", "algorithm.ARM_CML.init_optimizers", "list", "list", "algorithm.ARM_CML.model.parameters", "algorithm.ARM_CML.context_net.parameters"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.FEMNISTDataset.__init__", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DANN.init_optimizers"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "loss_fn", ",", "device", ",", "context_net", ",", "hparams", "=", "{", "}", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "loss_fn", ",", "device", ",", "hparams", ")", "\n", "\n", "self", ".", "context_net", "=", "context_net", "\n", "self", ".", "support_size", "=", "hparams", "[", "'support_size'", "]", "\n", "self", ".", "n_context_channels", "=", "hparams", "[", "'n_context_channels'", "]", "\n", "self", ".", "adapt_bn", "=", "hparams", "[", "'adapt_bn'", "]", "\n", "\n", "params", "=", "list", "(", "self", ".", "model", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "context_net", ".", "parameters", "(", ")", ")", "\n", "self", ".", "init_optimizers", "(", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ARM_CML.predict": [[270, 294], ["range", "torch.cat", "algorithm.ARM_CML.context_net", "torch.repeat_interleave.reshape", "torch.repeat_interleave.mean", "torch.repeat_interleave", "torch.cat", "algorithm.ARM_CML.model", "algorithm.ARM_CML.context_net", "context_i.mean().expand.mean().expand.mean().expand", "torch.cat", "out.append", "algorithm.ARM_CML.model", "context_i.mean().expand.mean().expand.mean"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "x", ")", ":", "\n", "        ", "batch_size", ",", "c", ",", "h", ",", "w", "=", "x", ".", "shape", "\n", "\n", "if", "batch_size", "%", "self", ".", "support_size", "==", "0", ":", "\n", "            ", "meta_batch_size", ",", "support_size", "=", "batch_size", "//", "self", ".", "support_size", ",", "self", ".", "support_size", "\n", "", "else", ":", "\n", "            ", "meta_batch_size", ",", "support_size", "=", "1", ",", "batch_size", "\n", "\n", "", "if", "self", ".", "adapt_bn", ":", "\n", "            ", "out", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "meta_batch_size", ")", ":", "\n", "                ", "x_i", "=", "x", "[", "i", "*", "support_size", ":", "(", "i", "+", "1", ")", "*", "support_size", "]", "\n", "context_i", "=", "self", ".", "context_net", "(", "x_i", ")", "\n", "context_i", "=", "context_i", ".", "mean", "(", "dim", "=", "0", ")", ".", "expand", "(", "support_size", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "x_i", "=", "torch", ".", "cat", "(", "[", "x_i", ",", "context_i", "]", ",", "dim", "=", "1", ")", "\n", "out", ".", "append", "(", "self", ".", "model", "(", "x_i", ")", ")", "\n", "", "return", "torch", ".", "cat", "(", "out", ")", "\n", "", "else", ":", "\n", "            ", "context", "=", "self", ".", "context_net", "(", "x", ")", "# Shape: batch_size, channels, H, W", "\n", "context", "=", "context", ".", "reshape", "(", "(", "meta_batch_size", ",", "support_size", ",", "self", ".", "n_context_channels", ",", "h", ",", "w", ")", ")", "\n", "context", "=", "context", ".", "mean", "(", "dim", "=", "1", ")", "# Shape: meta_batch_size, self.n_context_channels", "\n", "context", "=", "torch", ".", "repeat_interleave", "(", "context", ",", "repeats", "=", "support_size", ",", "dim", "=", "0", ")", "# meta_batch_size * support_size, context_size", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "context", "]", ",", "dim", "=", "1", ")", "\n", "return", "self", ".", "model", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ARM_LL.__init__": [[297, 309], ["algorithm.ERM.__init__", "torch.optim.SGD", "algorithm.ARM_LL.init_optimizers", "model.parameters", "list", "list", "algorithm.ARM_LL.model.parameters", "algorithm.ARM_LL.learned_loss_net.parameters"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.FEMNISTDataset.__init__", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DANN.init_optimizers"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "loss_fn", ",", "device", ",", "learned_loss_net", ",", "hparams", "=", "{", "}", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "loss_fn", ",", "device", ",", "hparams", ")", "\n", "\n", "self", ".", "support_size", "=", "hparams", "[", "'support_size'", "]", "\n", "self", ".", "learned_loss_net", "=", "learned_loss_net", "\n", "self", ".", "n_inner_iter", "=", "1", "\n", "self", ".", "inner_lr", "=", "1e-1", "\n", "self", ".", "inner_opt", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "inner_lr", ")", "\n", "\n", "params", "=", "list", "(", "self", ".", "model", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "learned_loss_net", ".", "parameters", "(", ")", ")", "\n", "self", ".", "init_optimizers", "(", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ARM_LL.predict": [[310, 351], ["algorithm.ARM_LL.train", "math.ceil", "range", "torch.cat", "min", "len", "len", "higher.innerloop_ctx", "range", "fnet", "torch.cat.append", "numpy.mean", "fnet", "algorithm.ARM_LL.learned_loss_net", "diffopt.step", "algorithm.ARM_LL.loss_fn", "algorithm.ARM_LL.backward", "loss.append", "algorithm.ARM_LL.to().detach().item", "algorithm.ARM_LL.to().detach", "algorithm.ARM_LL.to"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.train"], ["", "def", "predict", "(", "self", ",", "x", ",", "labels", "=", "None", ",", "backprop_loss", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "train", "(", ")", "# see this thread for why this is done https://github.com/facebookresearch/higher/issues/55", "\n", "\n", "n_domains", "=", "math", ".", "ceil", "(", "len", "(", "x", ")", "/", "self", ".", "support_size", ")", "\n", "\n", "logits", "=", "[", "]", "\n", "loss", "=", "[", "]", "\n", "for", "domain_id", "in", "range", "(", "n_domains", ")", ":", "\n", "            ", "start", "=", "domain_id", "*", "self", ".", "support_size", "\n", "end", "=", "start", "+", "self", ".", "support_size", "\n", "end", "=", "min", "(", "len", "(", "x", ")", ",", "end", ")", "# in case final domain has fewer than support size samples", "\n", "\n", "domain_x", "=", "x", "[", "start", ":", "end", "]", "\n", "\n", "with", "higher", ".", "innerloop_ctx", "(", "\n", "self", ".", "model", ",", "self", ".", "inner_opt", ",", "copy_initial_weights", "=", "False", ")", "as", "(", "fnet", ",", "diffopt", ")", ":", "\n", "\n", "# Inner loop", "\n", "                ", "for", "_", "in", "range", "(", "self", ".", "n_inner_iter", ")", ":", "\n", "                    ", "spt_logits", "=", "fnet", "(", "domain_x", ")", "\n", "spt_loss", "=", "self", ".", "learned_loss_net", "(", "spt_logits", ")", "\n", "diffopt", ".", "step", "(", "spt_loss", ")", "\n", "\n", "# Evaluate", "\n", "", "domain_logits", "=", "fnet", "(", "domain_x", ")", "\n", "logits", ".", "append", "(", "domain_logits", ")", "\n", "\n", "if", "backprop_loss", "and", "labels", "is", "not", "None", ":", "\n", "                    ", "domain_labels", "=", "labels", "[", "start", ":", "end", "]", "\n", "domain_loss", "=", "self", ".", "loss_fn", "(", "domain_logits", ",", "domain_labels", ")", "\n", "domain_loss", ".", "backward", "(", ")", "\n", "loss", ".", "append", "(", "domain_loss", ".", "to", "(", "'cpu'", ")", ".", "detach", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "\n", "", "", "", "logits", "=", "torch", ".", "cat", "(", "logits", ")", "\n", "\n", "if", "backprop_loss", ":", "\n", "            ", "return", "logits", ",", "np", ".", "mean", "(", "loss", ")", "\n", "", "else", ":", "\n", "            ", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ARM_LL.learn": [[353, 362], ["algorithm.ARM_LL.train", "algorithm.ARM_LL.predict", "algorithm.ARM_LL.optimizer.step", "algorithm.ARM_LL.optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.train", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ARM_BN.predict"], ["", "", "def", "learn", "(", "self", ",", "x", ",", "labels", ",", "group_ids", "=", "None", ")", ":", "\n", "        ", "self", ".", "train", "(", ")", "\n", "logits", ",", "loss", "=", "self", ".", "predict", "(", "x", ",", "labels", ",", "backprop_loss", "=", "True", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "stats", "=", "{", "}", "\n", "\n", "return", "logits", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ARM_BN.__init__": [[366, 370], ["algorithm.ERM.__init__"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.FEMNISTDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "loss_fn", ",", "device", ",", "hparams", "=", "{", "}", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "loss_fn", ",", "device", ",", "hparams", ")", "\n", "\n", "self", ".", "support_size", "=", "hparams", "[", "'support_size'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ARM_BN.predict": [[371, 388], ["algorithm.ARM_BN.model.train", "math.ceil", "range", "torch.cat", "min", "algorithm.ARM_BN.model", "torch.cat.append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.train"], ["", "def", "predict", "(", "self", ",", "x", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "n_domains", "=", "math", ".", "ceil", "(", "len", "(", "x", ")", "/", "self", ".", "support_size", ")", "\n", "\n", "logits", "=", "[", "]", "\n", "for", "domain_id", "in", "range", "(", "n_domains", ")", ":", "\n", "            ", "start", "=", "domain_id", "*", "self", ".", "support_size", "\n", "end", "=", "start", "+", "self", ".", "support_size", "\n", "end", "=", "min", "(", "len", "(", "x", ")", ",", "end", ")", "# in case final domain has fewer than support size samples", "\n", "domain_x", "=", "x", "[", "start", ":", "end", "]", "\n", "domain_logits", "=", "self", ".", "model", "(", "domain_x", ")", "\n", "logits", ".", "append", "(", "domain_logits", ")", "\n", "\n", "", "logits", "=", "torch", ".", "cat", "(", "logits", ")", "\n", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.MMD.my_cdist": [[391, 398], ["x1.pow().sum", "x2.pow().sum", "torch.addmm().add_", "torch.addmm().add_.clamp_min_", "x1.pow", "x2.pow", "torch.addmm", "x2.pow().sum.transpose", "x2.transpose"], "methods", ["None"], ["    ", "def", "my_cdist", "(", "cls", ",", "x1", ",", "x2", ")", ":", "\n", "        ", "x1_norm", "=", "x1", ".", "pow", "(", "2", ")", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "x2_norm", "=", "x2", ".", "pow", "(", "2", ")", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "res", "=", "torch", ".", "addmm", "(", "x2_norm", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "\n", "x1", ",", "\n", "x2", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "alpha", "=", "-", "2", ")", ".", "add_", "(", "x1_norm", ")", "\n", "return", "res", ".", "clamp_min_", "(", "1e-30", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.MMD.gaussian_kernel": [[399, 408], ["cls.my_cdist", "torch.zeros_like", "torch.zeros_like.add_", "torch.exp", "cls.my_cdist.mul"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.MMD.my_cdist"], ["", "def", "gaussian_kernel", "(", "cls", ",", "x", ",", "y", ",", "gamma", "=", "[", "0.001", ",", "0.01", ",", "0.1", ",", "1", ",", "10", ",", "100", ",", "\n", "1000", "]", ")", ":", "\n", "        ", "D", "=", "cls", ".", "my_cdist", "(", "x", ",", "y", ")", "\n", "K", "=", "torch", ".", "zeros_like", "(", "D", ")", "\n", "\n", "for", "g", "in", "gamma", ":", "\n", "            ", "K", ".", "add_", "(", "torch", ".", "exp", "(", "D", ".", "mul", "(", "-", "g", ")", ")", ")", "\n", "\n", "", "return", "K", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.MMD.mmd": [[409, 414], ["cls.gaussian_kernel().mean", "cls.gaussian_kernel().mean", "cls.gaussian_kernel().mean", "cls.gaussian_kernel", "cls.gaussian_kernel", "cls.gaussian_kernel"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.MMD.gaussian_kernel", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.MMD.gaussian_kernel", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.MMD.gaussian_kernel"], ["", "def", "mmd", "(", "cls", ",", "x", ",", "y", ")", ":", "\n", "        ", "Kxx", "=", "cls", ".", "gaussian_kernel", "(", "x", ",", "x", ")", ".", "mean", "(", ")", "\n", "Kyy", "=", "cls", ".", "gaussian_kernel", "(", "y", ",", "y", ")", ".", "mean", "(", ")", "\n", "Kxy", "=", "cls", ".", "gaussian_kernel", "(", "x", ",", "y", ")", ".", "mean", "(", ")", "\n", "return", "Kxx", "+", "Kyy", "-", "2", "*", "Kxy", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.MMD.__init__": [[415, 427], ["torch.nn.Linear", "torch.nn.Sequential().to", "algorithm.ERM.__init__", "featurizer.to", "torch.nn.Linear.to", "torch.nn.Sequential"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.FEMNISTDataset.__init__"], ["", "def", "__init__", "(", "self", ",", "model", ",", "loss_fn", ",", "device", ",", "hparams", ",", "num_classes", ")", ":", "\n", "\n", "        ", "featurizer", "=", "model", "\n", "classifier", "=", "nn", ".", "Linear", "(", "model", ".", "num_features", ",", "num_classes", ")", "\n", "model", "=", "nn", ".", "Sequential", "(", "featurizer", ",", "classifier", ")", ".", "to", "(", "device", ")", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "loss_fn", ",", "device", ",", "hparams", ")", "\n", "\n", "self", ".", "featurizer", "=", "featurizer", ".", "to", "(", "device", ")", "\n", "self", ".", "classifier", "=", "classifier", ".", "to", "(", "device", ")", "\n", "\n", "self", ".", "gamma", "=", "hparams", "[", "'gamma'", "]", "\n", "self", ".", "support_size", "=", "hparams", "[", "'support_size'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.MMD.learn": [[428, 451], ["algorithm.MMD.train", "algorithm.MMD.featurizer", "algorithm.MMD.classifier", "algorithm.MMD.loss_fn", "math.ceil", "range", "algorithm.MMD.update", "range", "len", "algorithm.MMD.mmd"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.train", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ERM.update", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.MMD.mmd"], ["", "def", "learn", "(", "self", ",", "images", ",", "labels", ",", "group_ids", ")", ":", "\n", "        ", "self", ".", "train", "(", ")", "\n", "\n", "features", "=", "self", ".", "featurizer", "(", "images", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "features", ")", "\n", "loss", "=", "self", ".", "loss_fn", "(", "logits", ",", "labels", ")", "\n", "penalty", "=", "0", "\n", "\n", "num_domains", "=", "math", ".", "ceil", "(", "len", "(", "images", ")", "/", "self", ".", "support_size", ")", "# meta batch size", "\n", "\n", "for", "i", "in", "range", "(", "num_domains", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "i", ",", "num_domains", ")", ":", "\n", "                ", "penalty_add", "=", "self", ".", "mmd", "(", "features", "[", "i", "*", "self", ".", "support_size", ":", "(", "i", "+", "1", ")", "*", "self", ".", "support_size", "]", ",", "features", "[", "j", "*", "self", ".", "support_size", ":", "(", "j", "+", "1", ")", "*", "self", ".", "support_size", "]", ")", "\n", "penalty", "+=", "penalty_add", "\n", "", "", "penalty", "/=", "(", "num_domains", "*", "(", "num_domains", "-", "1", ")", "/", "2", ")", "\n", "objective", "=", "loss", "+", "self", ".", "gamma", "*", "penalty", "\n", "self", ".", "update", "(", "objective", ")", "\n", "\n", "stats", "=", "{", "'loss'", ":", "loss", ",", "\n", "'objective'", ":", "objective", "}", "\n", "\n", "\n", "return", "logits", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DANN.__init__": [[454, 482], ["torch.nn.Linear", "torch.nn.Sequential().to", "algorithm.ERM.__init__", "torch.nn.Sequential().to", "featurizer.to", "torch.nn.Linear.to", "algorithm.DANN.init_optimizers", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.FEMNISTDataset.__init__", "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DANN.init_optimizers"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "loss_fn", ",", "device", ",", "hparams", ",", "num_domains", ",", "num_classes", ")", ":", "\n", "\n", "        ", "featurizer", "=", "model", "\n", "classifier", "=", "nn", ".", "Linear", "(", "model", ".", "num_features", ",", "num_classes", ")", "\n", "\n", "model", "=", "nn", ".", "Sequential", "(", "featurizer", ",", "classifier", ")", ".", "to", "(", "device", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "model", ",", "loss_fn", ",", "device", ",", "hparams", ",", "init_optim", "=", "False", ")", "\n", "\n", "self", ".", "discriminator", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "featurizer", ".", "num_features", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "num_domains", ")", ",", "\n", ")", ".", "to", "(", "device", ")", "\n", "\n", "self", ".", "num_domains", "=", "num_domains", "\n", "self", ".", "featurizer", "=", "featurizer", ".", "to", "(", "device", ")", "\n", "self", ".", "classifier", "=", "classifier", ".", "to", "(", "device", ")", "\n", "\n", "self", ".", "support_size", "=", "hparams", "[", "'support_size'", "]", "\n", "self", ".", "d_steps_per_g_step", "=", "hparams", "[", "'d_steps_per_g_step'", "]", "\n", "self", ".", "lambd", "=", "hparams", "[", "'lambd'", "]", "\n", "\n", "self", ".", "step_count", "=", "0", "\n", "\n", "self", ".", "init_optimizers", "(", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DANN.init_optimizers": [[484, 500], ["torch.optim.Adam", "torch.optim.Adam", "algorithm.DANN.model.parameters", "algorithm.DANN.discriminator.parameters", "torch.optim.SGD", "torch.optim.SGD", "algorithm.DANN.model.parameters", "algorithm.DANN.discriminator.parameters"], "methods", ["None"], ["", "def", "init_optimizers", "(", "self", ",", "params", ")", ":", "\n", "        ", "if", "self", ".", "optimizer_name", "==", "'adam'", ":", "# This is used for MNIST.", "\n", "            ", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "weight_decay", "=", "self", ".", "weight_decay", ")", "\n", "self", ".", "disc_optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "discriminator", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "weight_decay", "=", "self", ".", "weight_decay", ")", "\n", "\n", "", "elif", "self", ".", "optimizer_name", "==", "'sgd'", ":", "\n", "            ", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "\n", "weight_decay", "=", "self", ".", "weight_decay", ",", "\n", "momentum", "=", "0.9", ")", "\n", "self", ".", "disc_optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "discriminator", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "learning_rate", ",", "\n", "weight_decay", "=", "self", ".", "weight_decay", ",", "\n", "momentum", "=", "0.9", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.DANN.learn": [[503, 536], ["algorithm.DANN.train", "algorithm.DANN.featurizer", "algorithm.DANN.discriminator", "group_ids.to.to.to", "algorithm.DANN.loss_fn", "algorithm.DANN.disc_optimizer.zero_grad", "algorithm.DANN.backward", "algorithm.DANN.disc_optimizer.step", "algorithm.DANN.classifier", "algorithm.DANN.loss_fn", "algorithm.DANN.optimizer.zero_grad", "gen_loss.backward", "algorithm.DANN.optimizer.step"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.None.train.train"], ["", "", "def", "learn", "(", "self", ",", "images", ",", "labels", ",", "group_ids", ")", ":", "\n", "        ", "self", ".", "train", "(", ")", "\n", "\n", "\n", "# Forward", "\n", "features", "=", "self", ".", "featurizer", "(", "images", ")", "\n", "\n", "domain_preds", "=", "self", ".", "discriminator", "(", "features", ")", "\n", "group_ids", "=", "group_ids", ".", "to", "(", "self", ".", "device", ")", "\n", "disc_loss", "=", "self", ".", "loss_fn", "(", "domain_preds", ",", "group_ids", ")", "\n", "\n", "# Backprop", "\n", "if", "self", ".", "step_count", "%", "(", "self", ".", "d_steps_per_g_step", "+", "1", ")", "<", "self", ".", "d_steps_per_g_step", ":", "\n", "\n", "            ", "self", ".", "disc_optimizer", ".", "zero_grad", "(", ")", "\n", "disc_loss", ".", "backward", "(", ")", "\n", "self", ".", "disc_optimizer", ".", "step", "(", ")", "\n", "\n", "self", ".", "step_count", "+=", "1", "\n", "return", "None", ",", "None", "\n", "", "else", ":", "\n", "            ", "logits", "=", "self", ".", "classifier", "(", "features", ")", "\n", "\n", "# Evaluate", "\n", "loss", "=", "self", ".", "loss_fn", "(", "logits", ",", "labels", ")", "\n", "gen_loss", "=", "loss", "-", "self", ".", "lambd", "*", "disc_loss", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "gen_loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "stats", "=", "{", "}", "\n", "self", ".", "step_count", "+=", "1", "\n", "return", "logits", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.init_algorithm": [[11, 96], ["models.ResNet.to", "models.ContextNet().to", "models.ConvNet", "models.ResNet", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "algorithm.ERM", "algorithm.DRNN", "models.ContextNet", "algorithm.DANN", "algorithm.MMD", "algorithm.ARM_CML", "models.MLP().to", "algorithm.ARM_LL", "algorithm.ARM_BN", "models.MLP"], "function", ["None"], ["def", "init_algorithm", "(", "args", ",", "train_dataset", ")", ":", "\n", "\n", "    ", "if", "args", ".", "dataset", "in", "[", "'mnist'", "]", ":", "\n", "        ", "num_classes", "=", "10", "\n", "num_train_domains", "=", "14", "\n", "n_img_channels", "=", "1", "\n", "", "elif", "args", ".", "dataset", "==", "'femnist'", ":", "\n", "        ", "num_classes", "=", "62", "\n", "num_train_domains", "=", "262", "\n", "n_img_channels", "=", "1", "\n", "", "elif", "args", ".", "dataset", "in", "'tinyimg'", ":", "\n", "        ", "num_classes", "=", "200", "\n", "num_train_domains", "=", "51", "\n", "n_img_channels", "=", "3", "\n", "", "elif", "args", ".", "dataset", "in", "'cifar-c'", ":", "\n", "        ", "num_classes", "=", "10", "\n", "num_train_domains", "=", "56", "\n", "n_img_channels", "=", "3", "\n", "\n", "# Channels of main model", "\n", "", "if", "args", ".", "algorithm", "==", "'ARM-CML'", ":", "\n", "        ", "n_channels", "=", "n_img_channels", "+", "args", ".", "n_context_channels", "\n", "hidden_dim", "=", "64", "\n", "context_net", "=", "models", ".", "ContextNet", "(", "n_img_channels", ",", "args", ".", "n_context_channels", ",", "\n", "hidden_dim", "=", "hidden_dim", ",", "kernel_size", "=", "5", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "", "else", ":", "\n", "        ", "n_channels", "=", "n_img_channels", "\n", "\n", "", "if", "args", ".", "algorithm", "in", "[", "'DANN'", ",", "'MMD'", "]", ":", "\n", "        ", "return_features", "=", "True", "\n", "", "else", ":", "\n", "        ", "return_features", "=", "False", "\n", "\n", "# Main model", "\n", "", "if", "args", ".", "model", "==", "'convnet'", ":", "\n", "        ", "model", "=", "models", ".", "ConvNet", "(", "num_channels", "=", "n_channels", ",", "num_classes", "=", "num_classes", ",", "smaller_model", "=", "(", "args", ".", "algorithm", "==", "'ARM-CML'", ")", ",", "return_features", "=", "return_features", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "models", ".", "ResNet", "(", "num_channels", "=", "n_channels", ",", "num_classes", "=", "num_classes", ",", "model_name", "=", "args", ".", "model", ",", "\n", "pretrained", "=", "args", ".", "pretrained", ",", "return_features", "=", "return_features", ")", "\n", "", "model", "=", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "\n", "# Loss fn", "\n", "if", "args", ".", "algorithm", "in", "[", "'DRNN'", "]", ":", "\n", "        ", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "", "else", ":", "\n", "        ", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "# Algorithm", "\n", "", "hparams", "=", "{", "'optimizer'", ":", "args", ".", "optimizer", ",", "\n", "'learning_rate'", ":", "args", ".", "learning_rate", ",", "\n", "'weight_decay'", ":", "args", ".", "weight_decay", "}", "\n", "\n", "if", "args", ".", "algorithm", "==", "'ERM'", ":", "\n", "        ", "algorithm", "=", "ERM", "(", "model", ",", "loss_fn", ",", "args", ".", "device", ",", "hparams", ")", "\n", "", "elif", "args", ".", "algorithm", "==", "'DRNN'", ":", "\n", "        ", "hparams", "[", "'robust_step_size'", "]", "=", "0.01", "\n", "algorithm", "=", "DRNN", "(", "model", ",", "loss_fn", ",", "args", ".", "device", ",", "num_train_domains", ",", "hparams", ")", "\n", "\n", "", "elif", "args", ".", "algorithm", "==", "'DANN'", ":", "\n", "        ", "hparams", "[", "'d_steps_per_g_step'", "]", "=", "args", ".", "d_steps_per_g_step", "\n", "hparams", "[", "'lambd'", "]", "=", "args", ".", "lambd", "\n", "hparams", "[", "'support_size'", "]", "=", "args", ".", "support_size", "\n", "algorithm", "=", "DANN", "(", "model", ",", "loss_fn", ",", "args", ".", "device", ",", "hparams", ",", "num_train_domains", ",", "num_classes", ")", "\n", "\n", "", "elif", "args", ".", "algorithm", "==", "'MMD'", ":", "\n", "        ", "hparams", "[", "'support_size'", "]", "=", "args", ".", "support_size", "\n", "hparams", "[", "'gamma'", "]", "=", "1", "\n", "algorithm", "=", "MMD", "(", "model", ",", "loss_fn", ",", "args", ".", "device", ",", "hparams", ",", "num_classes", ")", "\n", "\n", "", "elif", "args", ".", "algorithm", "==", "'ARM-CML'", ":", "\n", "        ", "hparams", "[", "'support_size'", "]", "=", "args", ".", "support_size", "\n", "hparams", "[", "'n_context_channels'", "]", "=", "args", ".", "n_context_channels", "\n", "hparams", "[", "'adapt_bn'", "]", "=", "args", ".", "adapt_bn", "\n", "algorithm", "=", "ARM_CML", "(", "model", ",", "loss_fn", ",", "args", ".", "device", ",", "context_net", ",", "hparams", ")", "\n", "\n", "", "elif", "args", ".", "algorithm", "==", "'ARM-LL'", ":", "\n", "        ", "learned_loss_net", "=", "models", ".", "MLP", "(", "in_size", "=", "num_classes", ",", "norm_reduce", "=", "True", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "hparams", "[", "'support_size'", "]", "=", "args", ".", "support_size", "\n", "algorithm", "=", "ARM_LL", "(", "model", ",", "loss_fn", ",", "args", ".", "device", ",", "learned_loss_net", ",", "hparams", ")", "\n", "", "elif", "args", ".", "algorithm", "==", "'ARM-BN'", ":", "\n", "        ", "hparams", "[", "'support_size'", "]", "=", "args", ".", "support_size", "\n", "algorithm", "=", "ARM_BN", "(", "model", ",", "loss_fn", ",", "args", ".", "device", ",", "hparams", ")", "\n", "\n", "", "return", "algorithm", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.samplers.GroupSampler.__init__": [[16, 47], ["range", "len", "numpy.array", "len", "len", "samplers.GroupSampler.group_count.append", "numpy.sum", "numpy.nonzero", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "meta_batch_size", ",", "support_size", ",", "\n", "drop_last", "=", "None", ",", "uniform_over_groups", "=", "True", ")", ":", "\n", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "indices", "=", "range", "(", "len", "(", "dataset", ")", ")", "\n", "\n", "self", ".", "group_ids", "=", "dataset", ".", "group_ids", "\n", "self", ".", "groups", "=", "dataset", ".", "groups", "\n", "self", ".", "num_groups", "=", "dataset", ".", "n_groups", "\n", "\n", "self", ".", "meta_batch_size", "=", "meta_batch_size", "\n", "self", ".", "support_size", "=", "support_size", "\n", "self", ".", "batch_size", "=", "meta_batch_size", "*", "support_size", "\n", "self", ".", "drop_last", "=", "drop_last", "\n", "self", ".", "dataset_size", "=", "len", "(", "self", ".", "dataset", ")", "\n", "self", ".", "num_batches", "=", "len", "(", "self", ".", "dataset", ")", "//", "self", ".", "batch_size", "\n", "\n", "self", ".", "groups_with_ids", "=", "{", "}", "\n", "self", ".", "actual_groups", "=", "[", "]", "\n", "\n", "# group_count will have one entry per group", "\n", "# with the size of the group", "\n", "self", ".", "group_count", "=", "[", "]", "\n", "for", "group_id", "in", "self", ".", "groups", ":", "\n", "            ", "ids", "=", "np", ".", "nonzero", "(", "self", ".", "group_ids", "==", "group_id", ")", "[", "0", "]", "\n", "self", ".", "group_count", ".", "append", "(", "len", "(", "ids", ")", ")", "\n", "self", ".", "groups_with_ids", "[", "group_id", "]", "=", "ids", "\n", "\n", "", "self", ".", "group_count", "=", "np", ".", "array", "(", "self", ".", "group_count", ")", "\n", "self", ".", "group_prob", "=", "self", ".", "group_count", "/", "np", ".", "sum", "(", "self", ".", "group_count", ")", "\n", "self", ".", "uniform_over_groups", "=", "uniform_over_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.samplers.GroupSampler.__iter__": [[48, 75], ["numpy.zeros", "range", "len", "numpy.random.choice", "numpy.random.choice", "numpy.concatenate", "numpy.random.choice", "range"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "\n", "        ", "n_batches", "=", "len", "(", "self", ".", "dataset", ")", "//", "self", ".", "batch_size", "\n", "if", "self", ".", "uniform_over_groups", ":", "\n", "            ", "sampled_groups", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "groups", ",", "size", "=", "(", "n_batches", ",", "self", ".", "meta_batch_size", ")", ")", "\n", "", "else", ":", "\n", "# Sample groups according to the size of the group", "\n", "            ", "sampled_groups", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "groups", ",", "size", "=", "(", "n_batches", ",", "self", ".", "meta_batch_size", ")", ",", "p", "=", "self", ".", "group_prob", ")", "\n", "\n", "", "group_sizes", "=", "np", ".", "zeros", "(", "sampled_groups", ".", "shape", ")", "\n", "\n", "for", "batch_id", "in", "range", "(", "self", ".", "num_batches", ")", ":", "\n", "\n", "            ", "sampled_ids", "=", "[", "np", ".", "random", ".", "choice", "(", "self", ".", "groups_with_ids", "[", "sampled_groups", "[", "batch_id", ",", "sub_batch", "]", "]", ",", "\n", "size", "=", "self", ".", "support_size", ",", "\n", "replace", "=", "True", ",", "\n", "p", "=", "None", ")", "\n", "for", "sub_batch", "in", "range", "(", "self", ".", "meta_batch_size", ")", "]", "\n", "\n", "\n", "\n", "# Flatten", "\n", "sampled_ids", "=", "np", ".", "concatenate", "(", "sampled_ids", ")", "\n", "\n", "yield", "sampled_ids", "\n", "\n", "", "self", ".", "sub_distributions", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.samplers.GroupSampler.__len__": [[76, 78], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "//", "self", ".", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.samplers.get_one_hot": [[7, 9], ["numpy.eye"], "function", ["None"], ["def", "get_one_hot", "(", "values", ",", "num_classes", ")", ":", "\n", "    ", "return", "np", ".", "eye", "(", "num_classes", ")", "[", "values", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.tinyimagenet_dataset.ImageNetDataset.__init__": [[22, 74], ["print", "list", "len", "print", "numpy.histogram", "tinyimagenet_dataset.get_transform", "print", "print", "print", "print", "print", "data.extend", "data.extend", "range", "numpy.array().flatten", "numpy.array().flatten", "len", "numpy.min", "numpy.max", "pathlib.Path", "pathlib.Path", "pathlib.Path", "tinyimagenet_dataset.ImageNetDataset.construct_imdb", "tinyimagenet_dataset.ImageNetDataset.construct_imdb", "data.extend", "len", "len", "len", "range", "tinyimagenet_dataset.ImageNetDataset.construct_imdb", "numpy.array", "numpy.array", "range", "range"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.get_transform", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.tinyimagenet_dataset.ImageNetDataset.construct_imdb", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.tinyimagenet_dataset.ImageNetDataset.construct_imdb", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.tinyimagenet_dataset.ImageNetDataset.construct_imdb"], ["    ", "def", "__init__", "(", "self", ",", "split", ",", "root_dir", ")", ":", "\n", "        ", "if", "split", "==", "'train'", ":", "\n", "            ", "self", ".", "root_dir", "=", "Path", "(", "root_dir", ")", "/", "'Tiny-ImageNet-C-new/train/'", "\n", "corruptions", "=", "[", "'gaussian_noise'", ",", "'shot_noise'", ",", "'defocus_blur'", ",", "'glass_blur'", ",", "'zoom_blur'", ",", "'snow'", ",", "'brightness'", ",", "'contrast'", ",", "'pixelate'", "]", "\n", "frost_idx", "=", "[", "1", ",", "2", ",", "3", "]", "\n", "jpeg_idx", "=", "[", "1", ",", "2", ",", "3", "]", "\n", "", "if", "split", "==", "'val'", ":", "\n", "            ", "self", ".", "root_dir", "=", "Path", "(", "root_dir", ")", "/", "'Tiny-ImageNet-C-new/val'", "\n", "corruptions", "=", "[", "'speckle_noise'", ",", "'gaussian_blur'", ",", "'saturate'", "]", "\n", "frost_idx", "=", "[", "4", "]", "\n", "jpeg_idx", "=", "[", "5", "]", "\n", "", "if", "split", "==", "'test'", ":", "\n", "            ", "self", ".", "root_dir", "=", "Path", "(", "root_dir", ")", "/", "'Tiny-ImageNet-C/'", "\n", "corruptions", "=", "[", "'impulse_noise'", ",", "'motion_blur'", ",", "'fog'", ",", "'elastic_transform'", "]", "\n", "frost_idx", "=", "[", "5", "]", "\n", "jpeg_idx", "=", "[", "4", "]", "\n", "", "print", "(", "\"loading tiny-imagenet-c\"", ")", "\n", "\n", "data", "=", "[", "]", "\n", "for", "level", "in", "frost_idx", ":", "\n", "            ", "data", ".", "extend", "(", "self", ".", "construct_imdb", "(", "'frost'", ",", "level", ")", ")", "\n", "", "for", "level", "in", "jpeg_idx", ":", "\n", "            ", "data", ".", "extend", "(", "self", ".", "construct_imdb", "(", "'jpeg_compression'", ",", "level", ")", ")", "\n", "", "for", "corruption", "in", "corruptions", ":", "\n", "            ", "for", "level", "in", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ":", "\n", "                ", "data", ".", "extend", "(", "self", ".", "construct_imdb", "(", "corruption", ",", "level", ")", ")", "\n", "", "", "self", ".", "_X", "=", "data", "# np.concatenate([spatter, jpeg, data], axis=0)", "\n", "self", ".", "n_groups", "=", "len", "(", "frost_idx", ")", "+", "len", "(", "jpeg_idx", ")", "+", "5", "*", "len", "(", "corruptions", ")", "\n", "self", ".", "groups", "=", "list", "(", "range", "(", "self", ".", "n_groups", ")", ")", "\n", "\n", "self", ".", "image_shape", "=", "(", "3", ",", "64", ",", "64", ")", "\n", "if", "split", "==", "'test'", ":", "\n", "            ", "self", ".", "group_ids", "=", "np", ".", "array", "(", "[", "[", "i", "]", "*", "10000", "for", "i", "in", "range", "(", "self", ".", "n_groups", ")", "]", ")", ".", "flatten", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "group_ids", "=", "np", ".", "array", "(", "[", "[", "i", "]", "*", "2000", "for", "i", "in", "range", "(", "self", ".", "n_groups", ")", "]", ")", ".", "flatten", "(", ")", "\n", "\n", "", "self", ".", "_len", "=", "len", "(", "self", ".", "group_ids", ")", "\n", "print", "(", "\"loaded\"", ")", "\n", "\n", "self", ".", "group_counts", ",", "_", "=", "np", ".", "histogram", "(", "self", ".", "group_ids", ",", "\n", "bins", "=", "range", "(", "self", ".", "n_groups", "+", "1", ")", ",", "\n", "density", "=", "False", ")", "\n", "\n", "self", ".", "transform", "=", "get_transform", "(", "split", ")", "\n", "\n", "\n", "print", "(", "\"split: \"", ",", "split", ")", "\n", "print", "(", "\"n groups: \"", ",", "self", ".", "n_groups", ")", "\n", "print", "(", "\"Dataset size: \"", ",", "len", "(", "self", ".", "_X", ")", ")", "\n", "\n", "print", "(", "\"Smallest group: \"", ",", "np", ".", "min", "(", "self", ".", "group_counts", ")", ")", "\n", "print", "(", "\"Largest group: \"", ",", "np", ".", "max", "(", "self", ".", "group_counts", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.tinyimagenet_dataset.ImageNetDataset.construct_imdb": [[75, 94], ["os.path.join", "sorted", "str", "os.path.join", "os.listdir", "enumerate", "imdb.append", "os.listdir", "re.match", "os.path.join"], "methods", ["None"], ["", "def", "construct_imdb", "(", "self", ",", "corruption", ",", "level", ")", ":", "\n", "        ", "\"\"\"Constructs the imdb.\"\"\"", "\n", "# Compile the split data path", "\n", "split_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "corruption", ",", "str", "(", "level", ")", ")", "\n", "re_pattern", "=", "r\"^n[0-9]+$\"", "\n", "# Images are stored per class in subdirs (format: n<number>)", "\n", "class_ids", "=", "sorted", "(", "f", "for", "f", "in", "os", ".", "listdir", "(", "split_path", ")", "if", "re", ".", "match", "(", "re_pattern", ",", "f", ")", ")", "\n", "# Map ImageNet class ids to contiguous ids", "\n", "class_id_cont_id", "=", "{", "v", ":", "i", "for", "i", ",", "v", "in", "enumerate", "(", "class_ids", ")", "}", "\n", "# Construct the image db", "\n", "imdb", "=", "[", "]", "\n", "for", "class_id", "in", "class_ids", ":", "\n", "            ", "cont_id", "=", "class_id_cont_id", "[", "class_id", "]", "\n", "im_dir", "=", "os", ".", "path", ".", "join", "(", "split_path", ",", "class_id", ")", "\n", "for", "im_name", "in", "os", ".", "listdir", "(", "im_dir", ")", ":", "\n", "                ", "imdb", ".", "append", "(", "\n", "{", "\"im_path\"", ":", "os", ".", "path", ".", "join", "(", "im_dir", ",", "im_name", ")", ",", "\"class\"", ":", "cont_id", "}", "\n", ")", "\n", "", "", "return", "imdb", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.tinyimagenet_dataset.ImageNetDataset.__len__": [[95, 97], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_len", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.tinyimagenet_dataset.ImageNetDataset.__getitem__": [[98, 105], ["PIL.Image.open", "numpy.array", "torch.tensor", "torch.tensor", "tinyimagenet_dataset.ImageNetDataset.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "self", ".", "_X", "[", "index", "]", "[", "\"im_path\"", "]", ")", "\n", "img", "=", "np", ".", "array", "(", "img", ")", "\n", "img", "=", "self", ".", "transform", "(", "**", "{", "\"image\"", ":", "img", "}", ")", "[", "'image'", "]", "\n", "y", "=", "torch", ".", "tensor", "(", "self", ".", "_X", "[", "index", "]", "[", "\"class\"", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "g", "=", "torch", ".", "tensor", "(", "self", ".", "group_ids", "[", "index", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "return", "img", ",", "y", ",", "g", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.tinyimagenet_dataset.get_transform": [[107, 115], ["albumentations.Compose", "albumentations.Normalize", "albumentations.pytorch.ToTensor"], "function", ["None"], ["", "", "def", "get_transform", "(", "split", ")", ":", "\n", "    ", "transform", "=", "albumentations", ".", "Compose", "(", "[", "\n", "albumentations", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ",", "max_pixel_value", "=", "255", ",", "\n", "p", "=", "1.0", ",", "always_apply", "=", "True", ")", ",", "\n", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "return", "transform", "\n", "", ""]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.cifar_dataset.CIFARDataset.__init__": [[22, 82], ["print", "numpy.concatenate", "numpy.concatenate", "list", "cifar_dataset.CIFARDataset._X.reshape", "len", "print", "numpy.histogram", "cifar_dataset.get_transform", "print", "print", "print", "print", "print", "cifar_dataset.load_corruption", "numpy.concatenate", "cifar_dataset.load_corruption", "range", "numpy.tile", "numpy.array().flatten", "numpy.concatenate", "numpy.concatenate().flatten", "numpy.array().flatten", "len", "numpy.min", "numpy.max", "pathlib.Path", "pathlib.Path", "pathlib.Path", "numpy.load", "cifar_dataset.load_corruption", "numpy.concatenate", "cifar_dataset.load_corruption", "range", "numpy.array", "numpy.concatenate", "numpy.array", "range", "range"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.get_transform", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.cifar_dataset.load_corruption", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.cifar_dataset.load_corruption", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.cifar_dataset.load_corruption", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.cifar_dataset.load_corruption"], ["    ", "def", "__init__", "(", "self", ",", "split", ",", "root_dir", ")", ":", "\n", "\n", "        ", "if", "split", "==", "'train'", ":", "\n", "            ", "self", ".", "root_dir", "=", "Path", "(", "root_dir", ")", "/", "'CIFAR-10-C-new/train/'", "\n", "corruptions", "=", "[", "'gaussian_noise'", ",", "'shot_noise'", ",", "'defocus_blur'", ",", "'glass_blur'", ",", "'zoom_blur'", ",", "'snow'", ",", "'frost'", ",", "'brightness'", ",", "'contrast'", ",", "'pixelate'", "]", "\n", "other_idx", "=", "[", "0", ",", "1", ",", "2", ",", "5", ",", "6", ",", "7", "]", "\n", "\n", "", "if", "split", "==", "'val'", ":", "\n", "            ", "self", ".", "root_dir", "=", "Path", "(", "root_dir", ")", "/", "'CIFAR-10-C-new/val/'", "\n", "corruptions", "=", "[", "'speckle_noise'", ",", "'gaussian_blur'", ",", "'saturate'", "]", "\n", "other_idx", "=", "[", "3", ",", "9", "]", "\n", "\n", "", "if", "split", "==", "'test'", ":", "\n", "            ", "self", ".", "root_dir", "=", "Path", "(", "root_dir", ")", "/", "'CIFAR-10-C/'", "\n", "corruptions", "=", "[", "'impulse_noise'", ",", "'motion_blur'", ",", "'fog'", ",", "'elastic_transform'", "]", "\n", "other_idx", "=", "[", "4", ",", "8", "]", "\n", "\n", "", "print", "(", "\"loading cifar-10-c\"", ")", "\n", "other", "=", "[", "load_corruption", "(", "self", ".", "root_dir", "/", "(", "corruption", "+", "'.npy'", ")", ")", "for", "corruption", "in", "[", "'spatter'", ",", "'jpeg_compression'", "]", "]", "\n", "other", "=", "np", ".", "concatenate", "(", "other", ",", "axis", "=", "0", ")", "[", "other_idx", "]", "\n", "\n", "data", "=", "[", "load_corruption", "(", "self", ".", "root_dir", "/", "(", "corruption", "+", "'.npy'", ")", ")", "for", "corruption", "in", "corruptions", "]", "\n", "data", "=", "np", ".", "concatenate", "(", "data", ",", "axis", "=", "0", ")", "\n", "\n", "self", ".", "_X", "=", "np", ".", "concatenate", "(", "[", "other", ",", "data", "]", ",", "axis", "=", "0", ")", "\n", "\n", "n_images_per_group", "=", "self", ".", "_X", ".", "shape", "[", "1", "]", "\n", "\n", "self", ".", "n_groups", "=", "self", ".", "_X", ".", "shape", "[", "0", "]", "\n", "self", ".", "groups", "=", "list", "(", "range", "(", "self", ".", "n_groups", ")", ")", "\n", "self", ".", "image_shape", "=", "(", "3", ",", "32", ",", "32", ")", "\n", "self", ".", "_X", "=", "self", ".", "_X", ".", "reshape", "(", "(", "-", "1", ",", "32", ",", "32", ",", "3", ")", ")", "\n", "self", ".", "num_classes", "=", "10", "\n", "\n", "if", "split", "==", "'test'", ":", "\n", "            ", "n_images", "=", "10000", "\n", "self", ".", "_y", "=", "np", ".", "load", "(", "self", ".", "root_dir", "/", "'labels.npy'", ")", "[", ":", "n_images", "]", "\n", "self", ".", "_y", "=", "np", ".", "tile", "(", "self", ".", "_y", ",", "self", ".", "n_groups", ")", "\n", "self", ".", "group_ids", "=", "np", ".", "array", "(", "[", "[", "i", "]", "*", "n_images", "for", "i", "in", "range", "(", "self", ".", "n_groups", ")", "]", ")", ".", "flatten", "(", ")", "\n", "", "else", ":", "\n", "            ", "n_images", "=", "1000", "\n", "other_labels", "=", "[", "load_corruption", "(", "self", ".", "root_dir", "/", "(", "corruption", "+", "'_labels.npy'", ")", ")", "for", "corruption", "in", "[", "'spatter'", ",", "'jpeg_compression'", "]", "]", "\n", "other_labels", "=", "np", ".", "concatenate", "(", "other_labels", ",", "axis", "=", "0", ")", "[", "other_idx", "]", "\n", "data_labels", "=", "[", "load_corruption", "(", "self", ".", "root_dir", "/", "(", "corruption", "+", "'_labels.npy'", ")", ")", "for", "corruption", "in", "corruptions", "]", "\n", "data_labels", "=", "np", ".", "concatenate", "(", "data_labels", ",", "axis", "=", "0", ")", "\n", "self", ".", "_y", "=", "np", ".", "concatenate", "(", "[", "other_labels", ",", "data_labels", "]", ",", "axis", "=", "0", ")", ".", "flatten", "(", ")", "\n", "self", ".", "group_ids", "=", "np", ".", "array", "(", "[", "[", "i", "]", "*", "n_images", "for", "i", "in", "range", "(", "self", ".", "n_groups", ")", "]", ")", ".", "flatten", "(", ")", "\n", "\n", "", "self", ".", "_len", "=", "len", "(", "self", ".", "group_ids", ")", "\n", "print", "(", "\"loaded\"", ")", "\n", "\n", "self", ".", "group_counts", ",", "_", "=", "np", ".", "histogram", "(", "self", ".", "group_ids", ",", "\n", "bins", "=", "range", "(", "self", ".", "n_groups", "+", "1", ")", ",", "\n", "density", "=", "False", ")", "\n", "self", ".", "transform", "=", "get_transform", "(", ")", "\n", "print", "(", "\"split: \"", ",", "split", ")", "\n", "print", "(", "\"n groups: \"", ",", "self", ".", "n_groups", ")", "\n", "print", "(", "\"Dataset size: \"", ",", "len", "(", "self", ".", "_y", ")", ")", "\n", "print", "(", "\"Smallest group: \"", ",", "np", ".", "min", "(", "self", ".", "group_counts", ")", ")", "\n", "print", "(", "\"Largest group: \"", ",", "np", ".", "max", "(", "self", ".", "group_counts", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.cifar_dataset.CIFARDataset.__len__": [[83, 85], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_len", "\n", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.cifar_dataset.CIFARDataset.__getitem__": [[85, 91], ["torch.tensor", "torch.tensor", "cifar_dataset.CIFARDataset.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "x", "=", "self", ".", "transform", "(", "**", "{", "'image'", ":", "self", ".", "_X", "[", "index", "]", "}", ")", "[", "'image'", "]", "\n", "y", "=", "torch", ".", "tensor", "(", "self", ".", "_y", "[", "index", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "g", "=", "torch", ".", "tensor", "(", "self", ".", "group_ids", "[", "index", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "return", "x", ",", "y", ",", "g", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.cifar_dataset.load_corruption": [[17, 20], ["numpy.load", "numpy.array", "numpy.array_split"], "function", ["None"], ["def", "load_corruption", "(", "path", ")", ":", "\n", "    ", "data", "=", "np", ".", "load", "(", "path", ")", "\n", "return", "np", ".", "array", "(", "np", ".", "array_split", "(", "data", ",", "5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.cifar_dataset.get_transform": [[93, 101], ["albumentations.Compose", "albumentations.Normalize", "albumentations.pytorch.ToTensor"], "function", ["None"], ["", "", "def", "get_transform", "(", ")", ":", "\n", "    ", "transform", "=", "albumentations", ".", "Compose", "(", "[", "\n", "albumentations", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ",", "max_pixel_value", "=", "255", ",", "\n", "p", "=", "1.0", ",", "always_apply", "=", "True", ")", ",", "\n", "ToTensor", "(", ")", "\n", "]", ")", "\n", "return", "transform", "\n", "", ""]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.StaticMNISTUnknown.__init__": [[81, 139], ["torch.utils.data.Dataset.__init__", "len", "range", "numpy.random.seed", "numpy.unique", "numpy.zeros", "numpy.histogram", "numpy.histogram", "range", "print", "pandas.DataFrame", "static_mnist_unknown.StaticMNISTUnknown.df_stats[].apply", "print", "print", "static_mnist_unknown.StaticMNISTUnknown._get_train_skew", "static_mnist_unknown.StaticMNISTUnknown._get_test", "len", "len", "len", "tabulate.tabulate.tabulate", "range", "range", "numpy.nonzero", "len", "numpy.asarray", "int", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.FEMNISTDataset.__init__", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.StaticMNISTUnknown._get_train_skew", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.StaticMNISTUnknown._get_test", "home.repos.pwc.inspect_result.henrikmarklund_arm.None.run.ScoreKeeper.log"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "split", ",", "args", ",", "\n", "data_folder", "=", "'datasets'", ")", ":", "\n", "\n", "        ", "super", "(", "StaticMNISTUnknown", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "images", ",", "self", ".", "labels", "=", "data", "\n", "self", ".", "original_size", "=", "len", "(", "self", ".", "images", ")", "\n", "\n", "self", ".", "num_classes", "=", "10", "\n", "\n", "self", ".", "all_indices", "=", "range", "(", "self", ".", "original_size", ")", "\n", "\n", "# Generate the right dataset based on config", "\n", "# Create skew", "\n", "np", ".", "random", ".", "seed", "(", "1", ")", "\n", "config", "=", "CONFIGS", "[", "'rotation'", "]", "\n", "self", ".", "image_shape", "=", "(", "1", ",", "28", ",", "28", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "group_type", "=", "config", "[", "'group_type'", "]", "\n", "self", ".", "group_values", "=", "config", "[", "'group_values'", "]", "\n", "\n", "if", "split", "==", "'train'", ":", "\n", "            ", "self", ".", "indices", ",", "self", ".", "group_ids", "=", "self", ".", "_get_train_skew", "(", "config", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "indices", ",", "self", ".", "group_ids", "=", "self", ".", "_get_test", "(", "config", ")", "\n", "\n", "# Retrieve set", "\n", "", "self", ".", "images", ",", "self", ".", "labels", "=", "self", ".", "images", "[", "self", ".", "indices", "]", ",", "self", ".", "labels", "[", "self", ".", "indices", "]", "\n", "\n", "\n", "# Map to groups", "\n", "# Get group ids", "\n", "self", ".", "groups", "=", "np", ".", "unique", "(", "self", ".", "group_ids", ")", "\n", "self", ".", "n_groups", "=", "config", "[", "'n_groups'", "]", "\n", "\n", "self", ".", "group_stats", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_groups", ",", "2", ")", ")", "\n", "\n", "self", ".", "group_counts", ",", "bin_edges", "=", "np", ".", "histogram", "(", "self", ".", "group_ids", ",", "bins", "=", "range", "(", "self", ".", "n_groups", "+", "1", ")", ",", "density", "=", "False", ")", "\n", "self", ".", "group_dist", ",", "bin_edges", "=", "np", ".", "histogram", "(", "self", ".", "group_ids", ",", "bins", "=", "range", "(", "self", ".", "n_groups", "+", "1", ")", ",", "density", "=", "True", ")", "\n", "\n", "for", "group_id", "in", "range", "(", "self", ".", "n_groups", ")", ":", "\n", "            ", "indices", "=", "np", ".", "nonzero", "(", "np", ".", "asarray", "(", "self", ".", "group_ids", "==", "group_id", ")", ")", "[", "0", "]", "\n", "num_in_group", "=", "len", "(", "indices", ")", "\n", "self", ".", "group_stats", "[", "group_id", ",", "0", "]", "=", "num_in_group", "# Num in group", "\n", "self", ".", "group_stats", "[", "group_id", ",", "1", "]", "=", "num_in_group", "/", "len", "(", "self", ".", "labels", ")", "# Frac in group", "\n", "\n", "", "print", "(", "\"len dataset: \"", ",", "len", "(", "self", ".", "labels", ")", ")", "\n", "\n", "self", ".", "df_stats", "=", "pd", ".", "DataFrame", "(", "self", ".", "group_stats", ",", "columns", "=", "[", "'n'", ",", "'frac'", "]", ")", "\n", "self", ".", "df_stats", "[", "'group_id'", "]", "=", "self", ".", "df_stats", ".", "index", "\n", "self", ".", "df_stats", "[", "'binary'", "]", "=", "self", ".", "df_stats", "[", "'group_id'", "]", ".", "apply", "(", "lambda", "x", ":", "'{0:b}'", ".", "format", "(", "x", ")", ".", "zfill", "(", "int", "(", "np", ".", "log", "(", "self", ".", "n_groups", ")", ")", ")", ")", "\n", "\n", "self", ".", "binarize", "=", "False", "\n", "\n", "# Print dataset stats", "\n", "print", "(", "\"Number of examples\"", ",", "len", "(", "self", ".", "indices", ")", ")", "\n", "print", "(", "tabulate", "(", "self", ".", "df_stats", ",", "headers", "=", "'keys'", ",", "tablefmt", "=", "'psql'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.StaticMNISTUnknown._get_test": [[141, 162], ["range", "numpy.array", "numpy.array", "int", "numpy.array.extend", "numpy.array.extend"], "methods", ["None"], ["", "def", "_get_test", "(", "self", ",", "skew_config", ")", ":", "\n", "        ", "\"\"\"Returns the test set by duplicating the original\n            MNIST test set for each rotation angle.\n\n            There is no skew.\n\n            TODO: Clean up this function\"\"\"", "\n", "\n", "group_ids", "=", "[", "]", "\n", "indices", "=", "[", "]", "\n", "\n", "for", "group_id", "in", "range", "(", "skew_config", "[", "'n_groups'", "]", ")", ":", "\n", "\n", "            ", "num_examples", "=", "int", "(", "self", ".", "original_size", "/", "3", ")", "\n", "group_ids", ".", "extend", "(", "[", "group_id", "]", "*", "num_examples", ")", "\n", "indices", ".", "extend", "(", "self", ".", "all_indices", ")", "\n", "\n", "", "group_ids", "=", "np", ".", "array", "(", "group_ids", ")", "\n", "indices", "=", "np", ".", "array", "(", "indices", ")", "\n", "\n", "return", "indices", ",", "group_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.StaticMNISTUnknown._get_train_skew": [[163, 193], ["len", "range", "numpy.concatenate", "numpy.concatenate", "int", "print", "numpy.random.choice", "numpy.concatenate.append", "print", "numpy.concatenate.append", "len"], "methods", ["None"], ["", "def", "_get_train_skew", "(", "self", ",", "skew_config", ")", ":", "\n", "        ", "\"\"\"Returns a skewed train set\"\"\"", "\n", "\n", "\n", "num_examples_total", "=", "len", "(", "self", ".", "labels", ")", "\n", "\n", "indices", "=", "[", "]", "\n", "group_ids", "=", "[", "]", "\n", "for", "group_id", "in", "range", "(", "skew_config", "[", "'n_groups'", "]", ")", ":", "\n", "\n", "            ", "group_prob", "=", "skew_config", "[", "'group_probs'", "]", "[", "group_id", "]", "\n", "\n", "if", "group_prob", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "num_examples", "=", "int", "(", "group_prob", "*", "self", ".", "original_size", "/", "5", ")", "\n", "\n", "print", "(", "\"group type: \"", ",", "self", ".", "group_type", ")", "\n", "\n", "indices_for_group", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "original_size", ",", "size", "=", "num_examples", ")", "\n", "group_ids", ".", "append", "(", "len", "(", "indices_for_group", ")", "*", "[", "group_id", "]", ")", "\n", "\n", "print", "(", "\"Group id\"", ",", "group_id", ")", "\n", "\n", "indices", ".", "append", "(", "indices_for_group", ")", "\n", "\n", "", "group_ids", "=", "np", ".", "concatenate", "(", "group_ids", ")", "\n", "indices", "=", "np", ".", "concatenate", "(", "indices", ")", "\n", "\n", "return", "indices", ",", "group_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.StaticMNISTUnknown.__len__": [[194, 197], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns number of examples in the dataset\"\"\"", "\n", "return", "len", "(", "self", ".", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.StaticMNISTUnknown.__getitem__": [[198, 224], ["static_mnist_unknown.rescale", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.random.binomial().astype.permute", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "static_mnist_unknown.rotate", "numpy.random.binomial().astype", "numpy.random.binomial"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.rescale", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.rotate"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "group_id", "=", "self", ".", "group_ids", "[", "index", "]", "\n", "\n", "img", "=", "self", ".", "images", "[", "index", "]", "\n", "\n", "self", ".", "apply_transform", "=", "True", "\n", "if", "self", ".", "apply_transform", ":", "\n", "\n", "            ", "group_value", "=", "self", ".", "group_values", "[", "group_id", "]", "\n", "img", "=", "rotate", "(", "img", ",", "group_value", ",", "single_image", "=", "True", ")", "\n", "\n", "", "img", "=", "rescale", "(", "img", ")", "# =/ 256", "\n", "if", "self", ".", "binarize", ":", "\n", "            ", "img", "=", "np", ".", "random", ".", "binomial", "(", "1", ",", "img", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "img", "=", "torch", ".", "tensor", "(", "img", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "# Put color channel first", "\n", "img", "=", "img", ".", "permute", "(", "-", "1", ",", "0", ",", "1", ")", "\n", "\n", "label", "=", "self", ".", "labels", "[", "index", "]", "\n", "label", "=", "torch", ".", "tensor", "(", "label", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "\n", "return", "img", ",", "label", ",", "group_id", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.preprocess": [[36, 38], ["X.reshape().astype", "X.reshape"], "function", ["None"], ["def", "preprocess", "(", "X", ",", "y", ")", ":", "\n", "    ", "return", "X", ".", "reshape", "(", "[", "-", "1", ",", "28", ",", "28", ",", "1", "]", ")", ".", "astype", "(", "np", ".", "float64", ")", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.to_rgb": [[39, 42], ["numpy.concatenate"], "function", ["None"], ["", "def", "to_rgb", "(", "X", ")", ":", "\n", "\n", "    ", "return", "np", ".", "concatenate", "(", "[", "X", ",", "X", ",", "X", "]", ",", "axis", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.rescale": [[43, 45], ["X.astype"], "function", ["None"], ["", "def", "rescale", "(", "X", ")", ":", "\n", "    ", "return", "X", ".", "astype", "(", "np", ".", "float32", ")", "/", "255.", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.rotate": [[46, 53], ["numpy.array", "numpy.array", "scipy.ndimage.rotate", "scipy.ndimage.rotate", "range"], "function", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.rotate", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.rotate"], ["", "def", "rotate", "(", "X", ",", "rotation", ",", "single_image", "=", "False", ")", ":", "\n", "    ", "if", "single_image", ":", "\n", "        ", "return", "np", ".", "array", "(", "sp", ".", "ndimage", ".", "rotate", "(", "X", ",", "rotation", ",", "reshape", "=", "False", ",", "order", "=", "0", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "array", "(", "\n", "[", "sp", ".", "ndimage", ".", "rotate", "(", "X", "[", "i", "]", ",", "rotation", "[", "i", "]", ",", "reshape", "=", "False", ",", "order", "=", "0", ")", "\n", "for", "i", "in", "range", "(", "X", ".", "shape", "[", "0", "]", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.get_data": [[55, 78], ["static_mnist_unknown.preprocess", "numpy.random.permutation", "int", "numpy.random.permutation", "tensorflow.keras.datasets.mnist.load_data", "len"], "function", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.preprocess"], ["", "", "def", "get_data", "(", "shuffle", "=", "True", ")", ":", "\n", "    ", "\"\"\"Returns train, val and test for mnist\"\"\"", "\n", "(", "X_train", ",", "y_train", ")", ",", "(", "X_test", ",", "y_test", ")", "=", "[", "preprocess", "(", "*", "data", ")", "for", "data", "in", "\n", "keras", ".", "datasets", ".", "mnist", ".", "load_data", "(", ")", "]", "\n", "\n", "if", "shuffle", ":", "\n", "        ", "train_perm", "=", "np", ".", "random", ".", "permutation", "(", "X_train", ".", "shape", "[", "0", "]", ")", "\n", "X_train", ",", "y_train", "=", "X_train", "[", "train_perm", "]", ",", "y_train", "[", "train_perm", "]", "\n", "\n", "train_frac", "=", "0.90", "\n", "n_train", "=", "int", "(", "len", "(", "X_train", ")", "*", "train_frac", ")", "\n", "\n", "X_val", "=", "X_train", "[", "n_train", ":", "]", "\n", "y_val", "=", "y_train", "[", "n_train", ":", "]", "\n", "\n", "X_train", "=", "X_train", "[", ":", "n_train", "]", "\n", "y_train", "=", "y_train", "[", ":", "n_train", "]", "\n", "\n", "test_perm", "=", "np", ".", "random", ".", "permutation", "(", "X_test", ".", "shape", "[", "0", "]", ")", "\n", "X_test", ",", "y_test", "=", "X_test", "[", "test_perm", "]", ",", "y_test", "[", "test_perm", "]", "\n", "\n", "\n", "", "return", "(", "X_train", ",", "y_train", ")", ",", "(", "X_val", ",", "y_val", ")", ",", "(", "X_test", ",", "y_test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.FEMNISTDataset.__init__": [[39, 93], ["femnist_dataset.read_dir", "len", "list", "print", "enumerate", "print", "len", "numpy.array", "femnist_dataset.get_transform", "numpy.histogram", "print", "print", "print", "print", "print", "print", "print", "len", "len", "range", "len", "numpy.array().reshape", "agg_X.append", "agg_y.extend", "agg_groups.extend", "numpy.concatenate", "numpy.array", "numpy.load", "numpy.argmax", "print", "list", "femnist_dataset.FEMNISTDataset._X.sum", "len", "len", "numpy.min", "numpy.max", "pathlib.Path", "set", "len", "len", "numpy.max", "range", "range", "numpy.array", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.read_dir", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.get_transform"], ["    ", "def", "__init__", "(", "self", ",", "split", ",", "root_dir", ",", "args", ")", ":", "\n", "        ", "self", ".", "root_dir", "=", "Path", "(", "root_dir", ")", "/", "'femnist'", "/", "split", "\n", "clients", ",", "_", ",", "data", "=", "read_dir", "(", "self", ".", "root_dir", ")", "\n", "assert", "len", "(", "clients", ")", "==", "len", "(", "set", "(", "clients", ")", ")", ",", "'duplicate users'", "\n", "self", ".", "n_groups", "=", "len", "(", "clients", ")", "\n", "self", ".", "groups", "=", "list", "(", "range", "(", "self", ".", "n_groups", ")", ")", "\n", "\n", "self", ".", "num_classes", "=", "62", "\n", "\n", "self", ".", "image_shape", "=", "(", "1", ",", "28", ",", "28", ")", "\n", "\n", "agg_X", ",", "agg_y", ",", "agg_groups", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "print", "(", "\"loading femnist\"", ")", "\n", "for", "i", ",", "client", "in", "enumerate", "(", "clients", ")", ":", "\n", "            ", "client_X", ",", "client_y", "=", "data", "[", "client", "]", "[", "'x'", "]", ",", "data", "[", "client", "]", "[", "'y'", "]", "\n", "assert", "len", "(", "client_X", ")", "==", "len", "(", "client_y", ")", ",", "'malformed user data'", "\n", "client_N", "=", "len", "(", "client_X", ")", "\n", "X_processed", "=", "np", ".", "array", "(", "client_X", ")", ".", "reshape", "(", "(", "client_N", ",", "28", ",", "28", ",", "1", ")", ")", "\n", "X_processed", "=", "(", "1.0", "-", "X_processed", ")", "\n", "agg_X", ".", "append", "(", "X_processed", ")", "\n", "agg_y", ".", "extend", "(", "client_y", ")", "\n", "agg_groups", ".", "extend", "(", "[", "i", "]", "*", "client_N", ")", "\n", "", "print", "(", "\"loaded\"", ")", "\n", "self", ".", "_len", "=", "len", "(", "agg_groups", ")", "\n", "self", ".", "_X", ",", "self", ".", "_y", "=", "np", ".", "concatenate", "(", "agg_X", ")", ",", "np", ".", "array", "(", "agg_y", ")", "\n", "self", ".", "group_ids", "=", "np", ".", "array", "(", "agg_groups", ")", "\n", "\n", "self", ".", "transform", "=", "get_transform", "(", ")", "\n", "\n", "if", "split", "==", "'train'", "and", "'learned_groups'", "in", "args", "and", "args", ".", "learned_groups", ":", "\n", "            ", "path", "=", "Path", "(", "'output/clusterings/'", ")", "/", "'femnist'", "/", "args", ".", "clustering_filename", "\n", "#df_clusters = pd.read_csv(path)", "\n", "cluster_probs", "=", "np", ".", "load", "(", "path", ")", "\n", "self", ".", "group_ids", "=", "np", ".", "argmax", "(", "cluster_probs", "[", ":", ",", "0", ",", ":", "]", ",", "axis", "=", "1", ")", "\n", "print", "(", "\"group ids: \"", ",", "self", ".", "group_ids", ")", "\n", "self", ".", "n_groups", "=", "np", ".", "max", "(", "self", ".", "group_ids", ")", "+", "1", "\n", "self", ".", "groups", "=", "list", "(", "range", "(", "self", ".", "n_groups", ")", ")", "\n", "\n", "", "self", ".", "group_counts", ",", "_", "=", "np", ".", "histogram", "(", "self", ".", "group_ids", ",", "\n", "bins", "=", "range", "(", "self", ".", "n_groups", "+", "1", ")", ",", "\n", "density", "=", "False", ")", "\n", "\n", "\n", "\n", "print", "(", "\"split: \"", ",", "split", ")", "\n", "\n", "print", "(", "\"X sum: \"", ",", "self", ".", "_X", ".", "sum", "(", ")", ")", "\n", "\n", "print", "(", "\"n groups: \"", ",", "len", "(", "clients", ")", ")", "\n", "print", "(", "\"n groups: \"", ",", "self", ".", "n_groups", ")", "\n", "print", "(", "\"Dataset size: \"", ",", "len", "(", "self", ".", "_y", ")", ")", "\n", "\n", "print", "(", "\"Smallest group: \"", ",", "np", ".", "min", "(", "self", ".", "group_counts", ")", ")", "\n", "print", "(", "\"Largest group: \"", ",", "np", ".", "max", "(", "self", ".", "group_counts", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.FEMNISTDataset.__len__": [[94, 96], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_len", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.FEMNISTDataset.__getitem__": [[97, 102], ["torch.tensor", "torch.tensor", "femnist_dataset.FEMNISTDataset.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "x", "=", "self", ".", "transform", "(", "**", "{", "'image'", ":", "self", ".", "_X", "[", "index", "]", "}", ")", "[", "'image'", "]", "\n", "y", "=", "torch", ".", "tensor", "(", "self", ".", "_y", "[", "index", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "g", "=", "torch", ".", "tensor", "(", "self", ".", "group_ids", "[", "index", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "return", "x", ",", "y", ",", "g", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.read_dir": [[17, 35], ["collections.defaultdict", "os.listdir", "list", "os.path.join", "list.extend", "collections.defaultdict.update", "sorted", "f.endswith", "open", "json.load", "groups.extend", "collections.defaultdict.keys"], "function", ["home.repos.pwc.inspect_result.henrikmarklund_arm.algorithm.algorithm.ERM.update"], ["def", "read_dir", "(", "data_dir", ")", ":", "\n", "    ", "clients", "=", "[", "]", "\n", "groups", "=", "[", "]", "\n", "data", "=", "defaultdict", "(", "lambda", ":", "None", ")", "\n", "\n", "files", "=", "os", ".", "listdir", "(", "data_dir", ")", "\n", "files", "=", "[", "f", "for", "f", "in", "files", "if", "f", ".", "endswith", "(", "'.json'", ")", "]", "\n", "for", "f", "in", "files", ":", "\n", "        ", "file_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "f", ")", "\n", "with", "open", "(", "file_path", ",", "'r'", ")", "as", "inf", ":", "\n", "            ", "cdata", "=", "json", ".", "load", "(", "inf", ")", "\n", "", "clients", ".", "extend", "(", "cdata", "[", "'users'", "]", ")", "\n", "if", "'hierarchies'", "in", "cdata", ":", "\n", "            ", "groups", ".", "extend", "(", "cdata", "[", "'hierarchies'", "]", ")", "\n", "", "data", ".", "update", "(", "cdata", "[", "'user_data'", "]", ")", "\n", "\n", "", "clients", "=", "list", "(", "sorted", "(", "data", ".", "keys", "(", ")", ")", ")", "\n", "return", "clients", ",", "groups", ",", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.femnist_dataset.get_transform": [[103, 108], ["albumentations.Compose", "albumentations.pytorch.ToTensor"], "function", ["None"], ["", "", "def", "get_transform", "(", ")", ":", "\n", "    ", "transform", "=", "albumentations", ".", "Compose", "(", "[", "\n", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "return", "transform", "\n", "", ""]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.loader.get_loader": [[11, 64], ["torch.utils.data.DataLoader", "samplers.GroupSampler", "torch.utils.data.WeightedRandomSampler", "print", "print", "len", "bool"], "function", ["None"], ["def", "get_loader", "(", "dataset", ",", "sampler_type", ",", "uniform_over_groups", "=", "False", ",", "\n", "meta_batch_size", "=", "None", ",", "support_size", "=", "None", ",", "shuffle", "=", "True", ",", "\n", "pin_memory", "=", "True", ",", "num_workers", "=", "8", ",", "args", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns a data loader that sample meta_batches of data where each\n            meta batch contains a set of support batches. Each support batch\n            contain examples all having the same angle\n\n    \"\"\"", "\n", "\n", "if", "sampler_type", "==", "'group'", ":", "# Sample support batches from multiple sub distributions", "\n", "        ", "batch_sampler", "=", "GroupSampler", "(", "dataset", ",", "meta_batch_size", ",", "support_size", ",", "\n", "uniform_over_groups", "=", "uniform_over_groups", ")", "\n", "\n", "batch_size", "=", "1", "\n", "shuffle", "=", "None", "\n", "sampler", "=", "None", "\n", "drop_last", "=", "False", "\n", "", "else", ":", "\n", "\n", "        ", "batch_size", "=", "meta_batch_size", "*", "support_size", "\n", "\n", "if", "uniform_over_groups", ":", "\n", "            ", "group_weights", "=", "1", "/", "dataset", ".", "group_counts", "\n", "weights", "=", "group_weights", "[", "dataset", ".", "group_ids", "]", "\n", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "WeightedRandomSampler", "(", "weights", ",", "len", "(", "dataset", ")", ",", "replacement", "=", "True", ")", "\n", "batch_sampler", "=", "None", "\n", "drop_last", "=", "True", "\n", "shuffle", "=", "None", "\n", "", "else", ":", "# Sample each example uniformly", "\n", "\n", "            ", "print", "(", "\"standard sampler\"", ")", "\n", "\n", "sampler", "=", "None", "\n", "batch_sampler", "=", "None", "\n", "if", "args", "is", "not", "None", ":", "\n", "                ", "drop_last", "=", "bool", "(", "args", ".", "drop_last", ")", "\n", "", "else", ":", "\n", "                ", "drop_last", "=", "False", "\n", "", "if", "shuffle", "==", "0", ":", "\n", "                ", "shuffle", "=", "False", "\n", "", "else", ":", "\n", "                ", "shuffle", "=", "True", "\n", "", "print", "(", "\"shuffle: \"", ",", "shuffle", ")", "\n", "\n", "", "", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "sampler", "=", "sampler", ",", "\n", "batch_sampler", "=", "batch_sampler", ",", "\n", "pin_memory", "=", "pin_memory", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "drop_last", "=", "drop_last", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.loader.get_dataset": [[66, 94], ["femnist_dataset.FEMNISTDataset", "femnist_dataset.FEMNISTDataset", "femnist_dataset.FEMNISTDataset", "tinyimagenet_dataset.ImageNetDataset", "tinyimagenet_dataset.ImageNetDataset", "tinyimagenet_dataset.ImageNetDataset", "cifar_dataset.CIFARDataset", "cifar_dataset.CIFARDataset", "cifar_dataset.CIFARDataset", "static_mnist_unknown.get_data", "static_mnist_unknown.StaticMNISTUnknown", "static_mnist_unknown.StaticMNISTUnknown", "static_mnist_unknown.StaticMNISTUnknown"], "function", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.static_mnist_unknown.get_data"], ["", "def", "get_dataset", "(", "args", ",", "only_train", "=", "False", ")", ":", "\n", "\n", "\n", "    ", "if", "args", ".", "dataset", "==", "'femnist'", ":", "\n", "        ", "train_dataset", "=", "FEMNISTDataset", "(", "'train'", ",", "args", ".", "data_dir", ",", "args", ")", "\n", "val_dataset", "=", "FEMNISTDataset", "(", "'val'", ",", "args", ".", "data_dir", ",", "args", ")", "\n", "test_dataset", "=", "FEMNISTDataset", "(", "'test'", ",", "args", ".", "data_dir", ",", "args", ")", "\n", "\n", "", "elif", "args", ".", "dataset", "==", "'tinyimg'", ":", "\n", "        ", "train_dataset", "=", "ImageNetDataset", "(", "'train'", ",", "args", ".", "data_dir", ")", "\n", "val_dataset", "=", "ImageNetDataset", "(", "'val'", ",", "args", ".", "data_dir", ")", "\n", "test_dataset", "=", "ImageNetDataset", "(", "'test'", ",", "args", ".", "data_dir", ")", "\n", "\n", "", "elif", "args", ".", "dataset", "==", "'cifar-c'", ":", "\n", "        ", "train_dataset", "=", "CIFARDataset", "(", "'train'", ",", "args", ".", "data_dir", ")", "\n", "val_dataset", "=", "CIFARDataset", "(", "'val'", ",", "args", ".", "data_dir", ")", "\n", "test_dataset", "=", "CIFARDataset", "(", "'test'", ",", "args", ".", "data_dir", ")", "\n", "\n", "", "elif", "args", ".", "dataset", "==", "'mnist'", ":", "\n", "        ", "train", ",", "val", ",", "test", "=", "static_mnist_unknown", ".", "get_data", "(", ")", "\n", "train_dataset", "=", "StaticMNISTUnknown", "(", "train", ",", "'train'", ",", "args", ")", "\n", "val_dataset", "=", "StaticMNISTUnknown", "(", "val", ",", "'val'", ",", "args", ")", "\n", "test_dataset", "=", "StaticMNISTUnknown", "(", "test", ",", "'test'", ",", "args", ")", "\n", "\n", "", "if", "only_train", ":", "\n", "        ", "return", "train_dataset", "\n", "", "else", ":", "\n", "        ", "return", "train_dataset", ",", "val_dataset", ",", "test_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.henrikmarklund_arm.data.loader.get_loaders": [[96, 141], ["print", "loader.get_dataset", "loader.get_dataset", "loader.get_loader", "loader.get_loader", "loader.get_loader", "loader.get_loader"], "function", ["home.repos.pwc.inspect_result.henrikmarklund_arm.data.loader.get_dataset", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.loader.get_dataset", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.loader.get_loader", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.loader.get_loader", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.loader.get_loader", "home.repos.pwc.inspect_result.henrikmarklund_arm.data.loader.get_loader"], ["", "", "def", "get_loaders", "(", "args", ",", "only_train", "=", "False", ")", ":", "\n", "    ", "train_loader", ",", "train_eval_loader", ",", "val_loader", ",", "test_loader", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "\n", "if", "only_train", ":", "\n", "        ", "train_dataset", "=", "get_dataset", "(", "args", ",", "only_train", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "train_dataset", ",", "val_dataset", ",", "test_dataset", "=", "get_dataset", "(", "args", ",", "only_train", "=", "False", ")", "\n", "\n", "", "print", "(", "\"dataset: \"", ",", "train_dataset", ")", "\n", "\n", "if", "train_dataset", "is", "not", "None", ":", "\n", "        ", "train_loader", "=", "get_loader", "(", "train_dataset", ",", "sampler_type", "=", "args", ".", "sampler", ",", "uniform_over_groups", "=", "args", ".", "uniform_over_groups", ",", "\n", "meta_batch_size", "=", "args", ".", "meta_batch_size", ",", "\n", "support_size", "=", "args", ".", "support_size", ",", "\n", "shuffle", "=", "args", ".", "shuffle_train", ",", "\n", "pin_memory", "=", "args", ".", "pin_memory", ",", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "args", "=", "args", ")", "\n", "\n", "# The test loader will sample examples from a sub distribution that is set during evaluation", "\n", "# You can update this sub distribution during evaluation", "\n", "# The following are not really in use", "\n", "", "eval_sampling_type", "=", "'group'", "\n", "if", "not", "only_train", ":", "\n", "        ", "if", "train_dataset", "is", "not", "None", ":", "\n", "            ", "train_eval_loader", "=", "get_loader", "(", "train_dataset", ",", "eval_sampling_type", ",", "uniform_over_groups", "=", "False", ",", "\n", "meta_batch_size", "=", "args", ".", "meta_batch_size", ",", "\n", "support_size", "=", "args", ".", "support_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "pin_memory", "=", "args", ".", "pin_memory", ",", "num_workers", "=", "args", ".", "num_workers", ")", "\n", "", "if", "val_dataset", "is", "not", "None", ":", "\n", "            ", "val_loader", "=", "get_loader", "(", "val_dataset", ",", "eval_sampling_type", ",", "uniform_over_groups", "=", "False", ",", "\n", "meta_batch_size", "=", "args", ".", "meta_batch_size", ",", "\n", "support_size", "=", "args", ".", "support_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "pin_memory", "=", "args", ".", "pin_memory", ",", "num_workers", "=", "args", ".", "num_workers", ")", "\n", "", "if", "test_dataset", "is", "not", "None", ":", "\n", "            ", "test_loader", "=", "get_loader", "(", "test_dataset", ",", "eval_sampling_type", ",", "uniform_over_groups", "=", "False", ",", "\n", "meta_batch_size", "=", "args", ".", "meta_batch_size", ",", "\n", "support_size", "=", "args", ".", "support_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "pin_memory", "=", "args", ".", "pin_memory", ",", "num_workers", "=", "args", ".", "num_workers", ")", "\n", "\n", "", "return", "train_loader", ",", "train_eval_loader", ",", "val_loader", ",", "test_loader", "\n", "", "else", ":", "\n", "        ", "return", "train_loader", "\n", "\n"]]}