{"home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.pycocoevalcap.eval.COCOEvalCap.__init__": [[9, 16], ["coco.getImgIds"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "coco", ",", "cocoRes", ")", ":", "\n", "        ", "self", ".", "evalImgs", "=", "[", "]", "\n", "self", ".", "eval", "=", "{", "}", "\n", "self", ".", "imgToEval", "=", "{", "}", "\n", "self", ".", "coco", "=", "coco", "\n", "self", ".", "cocoRes", "=", "cocoRes", "\n", "self", ".", "params", "=", "{", "'image_id'", ":", "coco", ".", "getImgIds", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.pycocoevalcap.eval.COCOEvalCap.evaluate": [[17, 61], ["print", "tokenizer.ptbtokenizer.PTBTokenizer.ptbtokenizer.PTBTokenizer", "tokenizer.ptbtokenizer.PTBTokenizer.ptbtokenizer.PTBTokenizer.tokenize", "tokenizer.ptbtokenizer.PTBTokenizer.ptbtokenizer.PTBTokenizer.tokenize", "print", "eval.COCOEvalCap.setEvalImgs", "print", "scorer.compute_score", "bleu.bleu.Bleu", "meteor.meteor.Meteor", "rouge.rouge.Rouge", "cider.cider.Cider", "type", "zip", "eval.COCOEvalCap.setEval", "eval.COCOEvalCap.setImgToEvalImgs", "print", "scorer.method", "eval.COCOEvalCap.setEval", "eval.COCOEvalCap.setImgToEvalImgs", "print", "tokenizer.ptbtokenizer.PTBTokenizer.tokenize.keys", "tokenizer.ptbtokenizer.PTBTokenizer.tokenize.keys"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.tokenize", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.tokenize", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.pycocoevalcap.eval.COCOEvalCap.setEvalImgs", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider.Cider.compute_score", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.pycocoevalcap.eval.COCOEvalCap.setEval", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.pycocoevalcap.eval.COCOEvalCap.setImgToEvalImgs", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider.Cider.method", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.pycocoevalcap.eval.COCOEvalCap.setEval", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.pycocoevalcap.eval.COCOEvalCap.setImgToEvalImgs"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "imgIds", "=", "self", ".", "params", "[", "'image_id'", "]", "\n", "# imgIds = self.coco.getImgIds()", "\n", "gts", "=", "{", "}", "\n", "res", "=", "{", "}", "\n", "for", "imgId", "in", "imgIds", ":", "\n", "            ", "gts", "[", "imgId", "]", "=", "self", ".", "coco", ".", "imgToAnns", "[", "imgId", "]", "\n", "res", "[", "imgId", "]", "=", "self", ".", "cocoRes", ".", "imgToAnns", "[", "imgId", "]", "\n", "\n", "# =================================================", "\n", "# Set up scorers", "\n", "# =================================================", "\n", "", "print", "(", "'tokenization...'", ")", "\n", "tokenizer", "=", "PTBTokenizer", "(", ")", "\n", "gts", "=", "tokenizer", ".", "tokenize", "(", "gts", ")", "\n", "res", "=", "tokenizer", ".", "tokenize", "(", "res", ")", "\n", "\n", "# =================================================", "\n", "# Set up scorers", "\n", "# =================================================", "\n", "print", "(", "'setting up scorers...'", ")", "\n", "scorers", "=", "[", "\n", "(", "Bleu", "(", "4", ")", ",", "[", "\"Bleu_1\"", ",", "\"Bleu_2\"", ",", "\"Bleu_3\"", ",", "\"Bleu_4\"", "]", ")", ",", "\n", "(", "Meteor", "(", ")", ",", "\"METEOR\"", ")", ",", "\n", "(", "Rouge", "(", ")", ",", "\"ROUGE_L\"", ")", ",", "\n", "(", "Cider", "(", ")", ",", "\"CIDEr\"", ")", "\n", "]", "\n", "\n", "# =================================================", "\n", "# Compute scores", "\n", "# =================================================", "\n", "for", "scorer", ",", "method", "in", "scorers", ":", "\n", "            ", "print", "(", "'computing %s score...'", "%", "(", "scorer", ".", "method", "(", ")", ")", ")", "\n", "score", ",", "scores", "=", "scorer", ".", "compute_score", "(", "gts", ",", "res", ")", "\n", "if", "type", "(", "method", ")", "==", "list", ":", "\n", "                ", "for", "sc", ",", "scs", ",", "m", "in", "zip", "(", "score", ",", "scores", ",", "method", ")", ":", "\n", "                    ", "self", ".", "setEval", "(", "sc", ",", "m", ")", "\n", "self", ".", "setImgToEvalImgs", "(", "scs", ",", "gts", ".", "keys", "(", ")", ",", "m", ")", "\n", "print", "(", "\"%s: %0.3f\"", "%", "(", "m", ",", "sc", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "setEval", "(", "score", ",", "method", ")", "\n", "self", ".", "setImgToEvalImgs", "(", "scores", ",", "gts", ".", "keys", "(", ")", ",", "method", ")", "\n", "print", "(", "\"%s: %0.3f\"", "%", "(", "method", ",", "score", ")", ")", "\n", "", "", "self", ".", "setEvalImgs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.pycocoevalcap.eval.COCOEvalCap.setEval": [[62, 64], ["None"], "methods", ["None"], ["", "def", "setEval", "(", "self", ",", "score", ",", "method", ")", ":", "\n", "        ", "self", ".", "eval", "[", "method", "]", "=", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.pycocoevalcap.eval.COCOEvalCap.setImgToEvalImgs": [[65, 71], ["zip"], "methods", ["None"], ["", "def", "setImgToEvalImgs", "(", "self", ",", "scores", ",", "imgIds", ",", "method", ")", ":", "\n", "        ", "for", "imgId", ",", "score", "in", "zip", "(", "imgIds", ",", "scores", ")", ":", "\n", "            ", "if", "not", "imgId", "in", "self", ".", "imgToEval", ":", "\n", "                ", "self", ".", "imgToEval", "[", "imgId", "]", "=", "{", "}", "\n", "self", ".", "imgToEval", "[", "imgId", "]", "[", "\"image_id\"", "]", "=", "imgId", "\n", "", "self", ".", "imgToEval", "[", "imgId", "]", "[", "method", "]", "=", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.pycocoevalcap.eval.COCOEvalCap.setEvalImgs": [[72, 74], ["eval.COCOEvalCap.imgToEval.items"], "methods", ["None"], ["", "", "def", "setEvalImgs", "(", "self", ")", ":", "\n", "        ", "self", ".", "evalImgs", "=", "[", "eval", "for", "imgId", ",", "eval", "in", "self", ".", "imgToEval", ".", "items", "(", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu.Bleu.__init__": [[15, 20], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n", "=", "4", ")", ":", "\n", "# default compute Blue score up to 4", "\n", "        ", "self", ".", "_n", "=", "n", "\n", "self", ".", "_hypo_for_image", "=", "{", "}", "\n", "self", ".", "ref_for_image", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu.Bleu.compute_score": [[21, 45], ["gts.keys", "bleu_scorer.BleuScorer.BleuScorer", "bleu_scorer.BleuScorer.BleuScorer.compute_score", "gts.keys", "res.keys", "type", "len", "type", "len"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider.Cider.compute_score"], ["", "def", "compute_score", "(", "self", ",", "gts", ",", "res", ")", ":", "\n", "\n", "        ", "assert", "(", "gts", ".", "keys", "(", ")", "==", "res", ".", "keys", "(", ")", ")", "\n", "imgIds", "=", "gts", ".", "keys", "(", ")", "\n", "\n", "bleu_scorer", "=", "BleuScorer", "(", "n", "=", "self", ".", "_n", ")", "\n", "for", "id", "in", "imgIds", ":", "\n", "            ", "hypo", "=", "res", "[", "id", "]", "\n", "ref", "=", "gts", "[", "id", "]", "\n", "\n", "# Sanity check.", "\n", "assert", "(", "type", "(", "hypo", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "hypo", ")", "==", "1", ")", "\n", "assert", "(", "type", "(", "ref", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "ref", ")", ">=", "1", ")", "\n", "\n", "bleu_scorer", "+=", "(", "hypo", "[", "0", "]", ",", "ref", ")", "\n", "\n", "#score, scores = bleu_scorer.compute_score(option='shortest')", "\n", "", "score", ",", "scores", "=", "bleu_scorer", ".", "compute_score", "(", "option", "=", "'closest'", ",", "verbose", "=", "1", ")", "\n", "#score, scores = bleu_scorer.compute_score(option='average', verbose=1)", "\n", "\n", "# return (bleu, bleu_info)", "\n", "return", "score", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu.Bleu.method": [[46, 48], ["None"], "methods", ["None"], ["", "def", "method", "(", "self", ")", ":", "\n", "        ", "return", "\"Bleu\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.copy": [[93, 100], ["bleu_scorer.BleuScorer", "copy.copy", "copy.copy"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.copy", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.copy"], ["def", "copy", "(", "self", ")", ":", "\n", "        ", "''' copy the refs.'''", "\n", "new", "=", "BleuScorer", "(", "n", "=", "self", ".", "n", ")", "\n", "new", ".", "ctest", "=", "copy", ".", "copy", "(", "self", ".", "ctest", ")", "\n", "new", ".", "crefs", "=", "copy", ".", "copy", "(", "self", ".", "crefs", ")", "\n", "new", ".", "_score", "=", "None", "\n", "return", "new", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.__init__": [[101, 109], ["bleu_scorer.BleuScorer.cook_append"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.cook_append"], ["", "def", "__init__", "(", "self", ",", "test", "=", "None", ",", "refs", "=", "None", ",", "n", "=", "4", ",", "special_reflen", "=", "None", ")", ":", "\n", "        ", "''' singular instance '''", "\n", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "crefs", "=", "[", "]", "\n", "self", ".", "ctest", "=", "[", "]", "\n", "self", ".", "cook_append", "(", "test", ",", "refs", ")", "\n", "self", ".", "special_reflen", "=", "special_reflen", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.cook_append": [[110, 122], ["bleu_scorer.BleuScorer.crefs.append", "bleu_scorer.cook_refs", "bleu_scorer.cook_test", "bleu_scorer.BleuScorer.ctest.append", "bleu_scorer.BleuScorer.ctest.append"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.cook_refs", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.cook_test"], ["", "def", "cook_append", "(", "self", ",", "test", ",", "refs", ")", ":", "\n", "        ", "'''called by constructor and __iadd__ to avoid creating new instances.'''", "\n", "\n", "if", "refs", "is", "not", "None", ":", "\n", "            ", "self", ".", "crefs", ".", "append", "(", "cook_refs", "(", "refs", ")", ")", "\n", "if", "test", "is", "not", "None", ":", "\n", "                ", "cooked_test", "=", "cook_test", "(", "test", ",", "self", ".", "crefs", "[", "-", "1", "]", ")", "\n", "self", ".", "ctest", ".", "append", "(", "cooked_test", ")", "## N.B.: -1", "\n", "", "else", ":", "\n", "                ", "self", ".", "ctest", ".", "append", "(", "None", ")", "# lens of crefs and ctest have to match", "\n", "\n", "", "", "self", ".", "_score", "=", "None", "## need to recompute", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.ratio": [[123, 126], ["bleu_scorer.BleuScorer.compute_score"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider.Cider.compute_score"], ["", "def", "ratio", "(", "self", ",", "option", "=", "None", ")", ":", "\n", "        ", "self", ".", "compute_score", "(", "option", "=", "option", ")", "\n", "return", "self", ".", "_ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.score_ratio": [[127, 130], ["bleu_scorer.BleuScorer.fscore", "bleu_scorer.BleuScorer.ratio"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.ratio"], ["", "def", "score_ratio", "(", "self", ",", "option", "=", "None", ")", ":", "\n", "        ", "'''return (bleu, len_ratio) pair'''", "\n", "return", "(", "self", ".", "fscore", "(", "option", "=", "option", ")", ",", "self", ".", "ratio", "(", "option", "=", "option", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.score_ratio_str": [[131, 133], ["bleu_scorer.BleuScorer.score_ratio"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.score_ratio"], ["", "def", "score_ratio_str", "(", "self", ",", "option", "=", "None", ")", ":", "\n", "        ", "return", "\"%.4f (%.2f)\"", "%", "self", ".", "score_ratio", "(", "option", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.reflen": [[134, 137], ["bleu_scorer.BleuScorer.compute_score"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider.Cider.compute_score"], ["", "def", "reflen", "(", "self", ",", "option", "=", "None", ")", ":", "\n", "        ", "self", ".", "compute_score", "(", "option", "=", "option", ")", "\n", "return", "self", ".", "_reflen", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.testlen": [[138, 141], ["bleu_scorer.BleuScorer.compute_score"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider.Cider.compute_score"], ["", "def", "testlen", "(", "self", ",", "option", "=", "None", ")", ":", "\n", "        ", "self", ".", "compute_score", "(", "option", "=", "option", ")", "\n", "return", "self", ".", "_testlen", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.retest": [[142, 152], ["zip", "type", "len", "len", "bleu_scorer.BleuScorer.ctest.append", "bleu_scorer.cook_test"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.cook_test"], ["", "def", "retest", "(", "self", ",", "new_test", ")", ":", "\n", "        ", "if", "type", "(", "new_test", ")", "is", "str", ":", "\n", "            ", "new_test", "=", "[", "new_test", "]", "\n", "", "assert", "len", "(", "new_test", ")", "==", "len", "(", "self", ".", "crefs", ")", ",", "new_test", "\n", "self", ".", "ctest", "=", "[", "]", "\n", "for", "t", ",", "rs", "in", "zip", "(", "new_test", ",", "self", ".", "crefs", ")", ":", "\n", "            ", "self", ".", "ctest", ".", "append", "(", "cook_test", "(", "t", ",", "rs", ")", ")", "\n", "", "self", ".", "_score", "=", "None", "\n", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.rescore": [[153, 157], ["bleu_scorer.BleuScorer.retest().compute_score", "bleu_scorer.BleuScorer.retest"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider.Cider.compute_score", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.retest"], ["", "def", "rescore", "(", "self", ",", "new_test", ")", ":", "\n", "        ", "''' replace test(s) with new test(s), and returns the new score.'''", "\n", "\n", "return", "self", ".", "retest", "(", "new_test", ")", ".", "compute_score", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.size": [[158, 161], ["len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "size", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "crefs", ")", "==", "len", "(", "self", ".", "ctest", ")", ",", "\"refs/test mismatch! %d<>%d\"", "%", "(", "len", "(", "self", ".", "crefs", ")", ",", "len", "(", "self", ".", "ctest", ")", ")", "\n", "return", "len", "(", "self", ".", "crefs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.__iadd__": [[162, 175], ["type", "bleu_scorer.BleuScorer.cook_append", "bleu_scorer.BleuScorer.compatible", "bleu_scorer.BleuScorer.ctest.extend", "bleu_scorer.BleuScorer.crefs.extend"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.cook_append", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.compatible"], ["", "def", "__iadd__", "(", "self", ",", "other", ")", ":", "\n", "        ", "'''add an instance (e.g., from another sentence).'''", "\n", "\n", "if", "type", "(", "other", ")", "is", "tuple", ":", "\n", "## avoid creating new BleuScorer instances", "\n", "            ", "self", ".", "cook_append", "(", "other", "[", "0", "]", ",", "other", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "assert", "self", ".", "compatible", "(", "other", ")", ",", "\"incompatible BLEUs.\"", "\n", "self", ".", "ctest", ".", "extend", "(", "other", ".", "ctest", ")", "\n", "self", ".", "crefs", ".", "extend", "(", "other", ".", "crefs", ")", "\n", "self", ".", "_score", "=", "None", "## need to recompute", "\n", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.compatible": [[176, 178], ["isinstance"], "methods", ["None"], ["", "def", "compatible", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "isinstance", "(", "other", ",", "BleuScorer", ")", "and", "self", ".", "n", "==", "other", ".", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.single_reflen": [[179, 181], ["bleu_scorer.BleuScorer._single_reflen"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer._single_reflen"], ["", "def", "single_reflen", "(", "self", ",", "option", "=", "\"average\"", ")", ":", "\n", "        ", "return", "self", ".", "_single_reflen", "(", "self", ".", "crefs", "[", "0", "]", "[", "0", "]", ",", "option", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer._single_reflen": [[182, 194], ["min", "float", "len", "sum", "min", "abs"], "methods", ["None"], ["", "def", "_single_reflen", "(", "self", ",", "reflens", ",", "option", "=", "None", ",", "testlen", "=", "None", ")", ":", "\n", "\n", "        ", "if", "option", "==", "\"shortest\"", ":", "\n", "            ", "reflen", "=", "min", "(", "reflens", ")", "\n", "", "elif", "option", "==", "\"average\"", ":", "\n", "            ", "reflen", "=", "float", "(", "sum", "(", "reflens", ")", ")", "/", "len", "(", "reflens", ")", "\n", "", "elif", "option", "==", "\"closest\"", ":", "\n", "            ", "reflen", "=", "min", "(", "(", "abs", "(", "l", "-", "testlen", ")", ",", "l", ")", "for", "l", "in", "reflens", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "assert", "False", ",", "\"unsupported reflen option %s\"", "%", "option", "\n", "\n", "", "return", "reflen", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.recompute_score": [[195, 198], ["bleu_scorer.BleuScorer.compute_score"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider.Cider.compute_score"], ["", "def", "recompute_score", "(", "self", ",", "option", "=", "None", ",", "verbose", "=", "0", ")", ":", "\n", "        ", "self", ".", "_score", "=", "None", "\n", "return", "self", ".", "compute_score", "(", "option", ",", "verbose", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer.compute_score": [[199, 265], ["range", "range", "bleus.append", "range", "print", "print", "range", "bleu_scorer.BleuScorer._single_reflen", "range", "bleu_list[].append", "range", "print", "float", "math.exp", "len", "math.exp", "float", "float"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.BleuScorer._single_reflen"], ["", "def", "compute_score", "(", "self", ",", "option", "=", "None", ",", "verbose", "=", "0", ")", ":", "\n", "        ", "n", "=", "self", ".", "n", "\n", "small", "=", "1e-9", "\n", "tiny", "=", "1e-15", "## so that if guess is 0 still return 0", "\n", "bleu_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "\n", "if", "self", ".", "_score", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_score", "\n", "\n", "", "if", "option", "is", "None", ":", "\n", "            ", "option", "=", "\"average\"", "if", "len", "(", "self", ".", "crefs", ")", "==", "1", "else", "\"closest\"", "\n", "\n", "", "self", ".", "_testlen", "=", "0", "\n", "self", ".", "_reflen", "=", "0", "\n", "totalcomps", "=", "{", "'testlen'", ":", "0", ",", "'reflen'", ":", "0", ",", "'guess'", ":", "[", "0", "]", "*", "n", ",", "'correct'", ":", "[", "0", "]", "*", "n", "}", "\n", "\n", "# for each sentence", "\n", "for", "comps", "in", "self", ".", "ctest", ":", "\n", "            ", "testlen", "=", "comps", "[", "'testlen'", "]", "\n", "self", ".", "_testlen", "+=", "testlen", "\n", "\n", "if", "self", ".", "special_reflen", "is", "None", ":", "## need computation", "\n", "                ", "reflen", "=", "self", ".", "_single_reflen", "(", "comps", "[", "'reflen'", "]", ",", "option", ",", "testlen", ")", "\n", "", "else", ":", "\n", "                ", "reflen", "=", "self", ".", "special_reflen", "\n", "\n", "", "self", ".", "_reflen", "+=", "reflen", "\n", "\n", "for", "key", "in", "[", "'guess'", ",", "'correct'", "]", ":", "\n", "                ", "for", "k", "in", "range", "(", "n", ")", ":", "\n", "                    ", "totalcomps", "[", "key", "]", "[", "k", "]", "+=", "comps", "[", "key", "]", "[", "k", "]", "\n", "\n", "# append per image bleu score", "\n", "", "", "bleu", "=", "1.", "\n", "for", "k", "in", "range", "(", "n", ")", ":", "\n", "                ", "bleu", "*=", "(", "float", "(", "comps", "[", "'correct'", "]", "[", "k", "]", ")", "+", "tiny", ")", "/", "(", "float", "(", "comps", "[", "'guess'", "]", "[", "k", "]", ")", "+", "small", ")", "\n", "bleu_list", "[", "k", "]", ".", "append", "(", "bleu", "**", "(", "1.", "/", "(", "k", "+", "1", ")", ")", ")", "\n", "", "ratio", "=", "(", "testlen", "+", "tiny", ")", "/", "(", "reflen", "+", "small", ")", "## N.B.: avoid zero division", "\n", "if", "ratio", "<", "1", ":", "\n", "                ", "for", "k", "in", "range", "(", "n", ")", ":", "\n", "                    ", "bleu_list", "[", "k", "]", "[", "-", "1", "]", "*=", "math", ".", "exp", "(", "1", "-", "1", "/", "ratio", ")", "\n", "\n", "", "", "if", "verbose", ">", "1", ":", "\n", "                ", "print", "(", "comps", ",", "reflen", ")", "\n", "\n", "", "", "totalcomps", "[", "'reflen'", "]", "=", "self", ".", "_reflen", "\n", "totalcomps", "[", "'testlen'", "]", "=", "self", ".", "_testlen", "\n", "\n", "bleus", "=", "[", "]", "\n", "bleu", "=", "1.", "\n", "for", "k", "in", "range", "(", "n", ")", ":", "\n", "            ", "bleu", "*=", "float", "(", "totalcomps", "[", "'correct'", "]", "[", "k", "]", "+", "tiny", ")", "/", "(", "totalcomps", "[", "'guess'", "]", "[", "k", "]", "+", "small", ")", "\n", "bleus", ".", "append", "(", "bleu", "**", "(", "1.", "/", "(", "k", "+", "1", ")", ")", ")", "\n", "", "ratio", "=", "(", "self", ".", "_testlen", "+", "tiny", ")", "/", "(", "self", ".", "_reflen", "+", "small", ")", "## N.B.: avoid zero division", "\n", "if", "ratio", "<", "1", ":", "\n", "            ", "for", "k", "in", "range", "(", "n", ")", ":", "\n", "                ", "bleus", "[", "k", "]", "*=", "math", ".", "exp", "(", "1", "-", "1", "/", "ratio", ")", "\n", "\n", "", "", "if", "verbose", ">", "0", ":", "\n", "            ", "print", "(", "totalcomps", ")", "\n", "print", "(", "\"ratio:\"", ",", "ratio", ")", "\n", "\n", "", "self", ".", "_score", "=", "bleus", "\n", "return", "self", ".", "_score", ",", "bleu_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.precook": [[23, 34], ["s.split", "collections.defaultdict", "range", "range", "len", "tuple", "len"], "function", ["None"], ["def", "precook", "(", "s", ",", "n", "=", "4", ",", "out", "=", "False", ")", ":", "\n", "    ", "\"\"\"Takes a string as input and returns an object that can be given to\n    either cook_refs or cook_test. This is optional: cook_refs and cook_test\n    can take string arguments as well.\"\"\"", "\n", "words", "=", "s", ".", "split", "(", ")", "\n", "counts", "=", "defaultdict", "(", "int", ")", "\n", "for", "k", "in", "range", "(", "1", ",", "n", "+", "1", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "words", ")", "-", "k", "+", "1", ")", ":", "\n", "            ", "ngram", "=", "tuple", "(", "words", "[", "i", ":", "i", "+", "k", "]", ")", "\n", "counts", "[", "ngram", "]", "+=", "1", "\n", "", "", "return", "(", "len", "(", "words", ")", ",", "counts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.cook_refs": [[35, 59], ["bleu_scorer.precook", "min.append", "counts.items", "min", "max", "maxcounts.get", "float", "len", "sum"], "function", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.precook"], ["", "def", "cook_refs", "(", "refs", ",", "eff", "=", "None", ",", "n", "=", "4", ")", ":", "## lhuang: oracle will call with \"average\"", "\n", "    ", "'''Takes a list of reference sentences for a single segment\n    and returns an object that encapsulates everything that BLEU\n    needs to know about them.'''", "\n", "\n", "reflen", "=", "[", "]", "\n", "maxcounts", "=", "{", "}", "\n", "for", "ref", "in", "refs", ":", "\n", "        ", "rl", ",", "counts", "=", "precook", "(", "ref", ",", "n", ")", "\n", "reflen", ".", "append", "(", "rl", ")", "\n", "for", "(", "ngram", ",", "count", ")", "in", "counts", ".", "items", "(", ")", ":", "\n", "            ", "maxcounts", "[", "ngram", "]", "=", "max", "(", "maxcounts", ".", "get", "(", "ngram", ",", "0", ")", ",", "count", ")", "\n", "\n", "# Calculate effective reference sentence length.", "\n", "", "", "if", "eff", "==", "\"shortest\"", ":", "\n", "        ", "reflen", "=", "min", "(", "reflen", ")", "\n", "", "elif", "eff", "==", "\"average\"", ":", "\n", "        ", "reflen", "=", "float", "(", "sum", "(", "reflen", ")", ")", "/", "len", "(", "reflen", ")", "\n", "\n", "## lhuang: N.B.: leave reflen computaiton to the very end!!", "\n", "\n", "## lhuang: N.B.: in case of \"closest\", keep a list of reflens!! (bad design)", "\n", "\n", "", "return", "(", "reflen", ",", "maxcounts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.bleu.bleu_scorer.cook_test": [[60, 85], ["bleu_scorer.precook", "counts.items", "max", "min", "min", "range", "refmaxcounts.get", "len", "abs"], "function", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.precook"], ["", "def", "cook_test", "(", "test", ",", "refs", ",", "eff", "=", "None", ",", "n", "=", "4", ")", ":", "\n", "    ", "'''Takes a test sentence and returns an object that\n    encapsulates everything that BLEU needs to know about it.'''", "\n", "\n", "reflen", ",", "refmaxcounts", "=", "refs", "\n", "testlen", ",", "counts", "=", "precook", "(", "test", ",", "n", ",", "True", ")", "\n", "\n", "result", "=", "{", "}", "\n", "\n", "# Calculate effective reference sentence length.", "\n", "\n", "if", "eff", "==", "\"closest\"", ":", "\n", "        ", "result", "[", "\"reflen\"", "]", "=", "min", "(", "(", "abs", "(", "l", "-", "testlen", ")", ",", "l", ")", "for", "l", "in", "reflen", ")", "[", "1", "]", "\n", "", "else", ":", "## i.e., \"average\" or \"shortest\" or None", "\n", "        ", "result", "[", "\"reflen\"", "]", "=", "reflen", "\n", "\n", "", "result", "[", "\"testlen\"", "]", "=", "testlen", "\n", "\n", "result", "[", "\"guess\"", "]", "=", "[", "max", "(", "0", ",", "testlen", "-", "k", "+", "1", ")", "for", "k", "in", "range", "(", "1", ",", "n", "+", "1", ")", "]", "\n", "\n", "result", "[", "'correct'", "]", "=", "[", "0", "]", "*", "n", "\n", "for", "(", "ngram", ",", "count", ")", "in", "counts", ".", "items", "(", ")", ":", "\n", "        ", "result", "[", "\"correct\"", "]", "[", "len", "(", "ngram", ")", "-", "1", "]", "+=", "min", "(", "refmaxcounts", ".", "get", "(", "ngram", ",", "0", ")", ",", "count", ")", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.rouge.rouge.Rouge.__init__": [[41, 44], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# vrama91: updated the value below based on discussion with Hovey", "\n", "        ", "self", ".", "beta", "=", "1.2", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.rouge.rouge.Rouge.calc_score": [[45, 76], ["candidate[].split", "max", "max", "len", "len", "reference.split", "rouge.my_lcs", "prec.append", "rec.append", "float", "float", "float", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.rouge.rouge.my_lcs"], ["", "def", "calc_score", "(", "self", ",", "candidate", ",", "refs", ")", ":", "\n", "        ", "\"\"\"\n        Compute ROUGE-L score given one candidate and references for an image\n        :param candidate: str : candidate sentence to be evaluated\n        :param refs: list of str : COCO reference sentences for the particular image to be evaluated\n        :returns score: int (ROUGE-L score for the candidate evaluated against references)\n        \"\"\"", "\n", "assert", "(", "len", "(", "candidate", ")", "==", "1", ")", "\n", "assert", "(", "len", "(", "refs", ")", ">", "0", ")", "\n", "prec", "=", "[", "]", "\n", "rec", "=", "[", "]", "\n", "\n", "# split into tokens", "\n", "token_c", "=", "candidate", "[", "0", "]", ".", "split", "(", "\" \"", ")", "\n", "\n", "for", "reference", "in", "refs", ":", "\n", "# split into tokens", "\n", "            ", "token_r", "=", "reference", ".", "split", "(", "\" \"", ")", "\n", "# compute the longest common subsequence", "\n", "lcs", "=", "my_lcs", "(", "token_r", ",", "token_c", ")", "\n", "prec", ".", "append", "(", "lcs", "/", "float", "(", "len", "(", "token_c", ")", ")", ")", "\n", "rec", ".", "append", "(", "lcs", "/", "float", "(", "len", "(", "token_r", ")", ")", ")", "\n", "\n", "", "prec_max", "=", "max", "(", "prec", ")", "\n", "rec_max", "=", "max", "(", "rec", ")", "\n", "\n", "if", "(", "prec_max", "!=", "0", "and", "rec_max", "!=", "0", ")", ":", "\n", "            ", "score", "=", "(", "(", "1", "+", "self", ".", "beta", "**", "2", ")", "*", "prec_max", "*", "rec_max", ")", "/", "float", "(", "rec_max", "+", "self", ".", "beta", "**", "2", "*", "prec_max", ")", "\n", "", "else", ":", "\n", "            ", "score", "=", "0.0", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.rouge.rouge.Rouge.compute_score": [[77, 103], ["gts.keys", "numpy.mean", "gts.keys", "res.keys", "score.append", "numpy.array", "numpy.array", "rouge.Rouge.calc_score", "type", "len", "type", "len"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.rouge.rouge.Rouge.calc_score"], ["", "def", "compute_score", "(", "self", ",", "gts", ",", "res", ")", ":", "\n", "        ", "\"\"\"\n        Computes Rouge-L score given a set of reference and candidate sentences for the dataset\n        Invoked by evaluate_captions.py\n        :param hypo_for_image: dict : candidate / test sentences with \"image name\" key and \"tokenized sentences\" as values\n        :param ref_for_image: dict : reference MS-COCO sentences with \"image name\" key and \"tokenized sentences\" as values\n        :returns: average_score: float (mean ROUGE-L score computed by averaging scores for all the images)\n        \"\"\"", "\n", "assert", "(", "gts", ".", "keys", "(", ")", "==", "res", ".", "keys", "(", ")", ")", "\n", "imgIds", "=", "gts", ".", "keys", "(", ")", "\n", "\n", "score", "=", "[", "]", "\n", "for", "id", "in", "imgIds", ":", "\n", "            ", "hypo", "=", "res", "[", "id", "]", "\n", "ref", "=", "gts", "[", "id", "]", "\n", "\n", "score", ".", "append", "(", "self", ".", "calc_score", "(", "hypo", ",", "ref", ")", ")", "\n", "\n", "# Sanity check.", "\n", "assert", "(", "type", "(", "hypo", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "hypo", ")", "==", "1", ")", "\n", "assert", "(", "type", "(", "ref", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "ref", ")", ">", "0", ")", "\n", "\n", "", "average_score", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "score", ")", ")", "\n", "return", "average_score", ",", "np", ".", "array", "(", "score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.rouge.rouge.Rouge.method": [[104, 106], ["None"], "methods", ["None"], ["", "def", "method", "(", "self", ")", ":", "\n", "        ", "return", "\"Rouge\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.rouge.rouge.my_lcs": [[13, 35], ["range", "len", "len", "range", "range", "len", "len", "range", "len", "max", "len", "len", "len"], "function", ["None"], ["def", "my_lcs", "(", "string", ",", "sub", ")", ":", "\n", "    ", "\"\"\"\n    Calculates longest common subsequence for a pair of tokenized strings\n    :param string : list of str : tokens from a string split using whitespace\n    :param sub : list of str : shorter string, also split using whitespace\n    :returns: length (list of int): length of the longest common subsequence between the two strings\n\n    Note: my_lcs only gives length of the longest common subsequence, not the actual LCS\n    \"\"\"", "\n", "if", "(", "len", "(", "string", ")", "<", "len", "(", "sub", ")", ")", ":", "\n", "        ", "sub", ",", "string", "=", "string", ",", "sub", "\n", "\n", "", "lengths", "=", "[", "[", "0", "for", "i", "in", "range", "(", "0", ",", "len", "(", "sub", ")", "+", "1", ")", "]", "for", "j", "in", "range", "(", "0", ",", "len", "(", "string", ")", "+", "1", ")", "]", "\n", "\n", "for", "j", "in", "range", "(", "1", ",", "len", "(", "sub", ")", "+", "1", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "1", ",", "len", "(", "string", ")", "+", "1", ")", ":", "\n", "            ", "if", "(", "string", "[", "i", "-", "1", "]", "==", "sub", "[", "j", "-", "1", "]", ")", ":", "\n", "                ", "lengths", "[", "i", "]", "[", "j", "]", "=", "lengths", "[", "i", "-", "1", "]", "[", "j", "-", "1", "]", "+", "1", "\n", "", "else", ":", "\n", "                ", "lengths", "[", "i", "]", "[", "j", "]", "=", "max", "(", "lengths", "[", "i", "-", "1", "]", "[", "j", "]", ",", "lengths", "[", "i", "]", "[", "j", "-", "1", "]", ")", "\n", "\n", "", "", "", "return", "lengths", "[", "len", "(", "string", ")", "]", "[", "len", "(", "sub", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.meteor.meteor.Meteor.__init__": [[17, 27], ["subprocess.Popen", "threading.Lock", "os.path.dirname", "os.path.abspath"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "meteor_cmd", "=", "[", "'java'", ",", "'-jar'", ",", "'-Xmx2G'", ",", "METEOR_JAR", ",", "'-'", ",", "'-'", ",", "'-stdio'", ",", "'-l'", ",", "'en'", ",", "'-norm'", "]", "\n", "self", ".", "meteor_p", "=", "subprocess", ".", "Popen", "(", "self", ".", "meteor_cmd", ",", "cwd", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", ",", "stdin", "=", "subprocess", ".", "PIPE", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "stderr", "=", "subprocess", ".", "PIPE", ")", "\n", "# Used to guarantee thread safety", "\n", "self", ".", "lock", "=", "threading", ".", "Lock", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.meteor.meteor.Meteor.compute_score": [[28, 48], ["gts.keys", "meteor.Meteor.lock.acquire", "meteor.Meteor.meteor_p.stdin.write", "meteor.Meteor.meteor_p.stdin.flush", "range", "float", "meteor.Meteor.lock.release", "gts.keys", "res.keys", "meteor.Meteor._stat", "len", "scores.append", "meteor.Meteor.meteor_p.stdout.readline().strip", "len", "float", "meteor.Meteor.meteor_p.stdout.readline().strip", "meteor.Meteor.meteor_p.stdout.readline", "meteor.Meteor.meteor_p.stdout.readline"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.meteor.meteor.Meteor._stat"], ["", "def", "compute_score", "(", "self", ",", "gts", ",", "res", ")", ":", "\n", "        ", "assert", "(", "gts", ".", "keys", "(", ")", "==", "res", ".", "keys", "(", ")", ")", "\n", "imgIds", "=", "gts", ".", "keys", "(", ")", "\n", "scores", "=", "[", "]", "\n", "\n", "eval_line", "=", "'EVAL'", "\n", "self", ".", "lock", ".", "acquire", "(", ")", "\n", "for", "i", "in", "imgIds", ":", "\n", "            ", "assert", "(", "len", "(", "res", "[", "i", "]", ")", "==", "1", ")", "\n", "stat", "=", "self", ".", "_stat", "(", "res", "[", "i", "]", "[", "0", "]", ",", "gts", "[", "i", "]", ")", "\n", "eval_line", "+=", "' ||| {}'", ".", "format", "(", "stat", ")", "\n", "\n", "", "self", ".", "meteor_p", ".", "stdin", ".", "write", "(", "'{}\\n'", ".", "format", "(", "eval_line", ")", ".", "encode", "(", ")", ")", "\n", "self", ".", "meteor_p", ".", "stdin", ".", "flush", "(", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "imgIds", ")", ")", ":", "\n", "            ", "scores", ".", "append", "(", "float", "(", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", ")", "\n", "", "score", "=", "float", "(", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "self", ".", "lock", ".", "release", "(", ")", "\n", "\n", "return", "score", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.meteor.meteor.Meteor.method": [[49, 51], ["None"], "methods", ["None"], ["", "def", "method", "(", "self", ")", ":", "\n", "        ", "return", "\"METEOR\"", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.meteor.meteor.Meteor._stat": [[52, 59], ["hypothesis_str.replace().replace.replace().replace.replace().replace", "meteor.Meteor.meteor_p.stdin.write", "meteor.Meteor.meteor_p.stdin.flush", "meteor.Meteor.meteor_p.stdout.readline().decode().strip", "hypothesis_str.replace().replace.replace().replace.replace", "meteor.Meteor.meteor_p.stdout.readline().decode", "meteor.Meteor.meteor_p.stdout.readline"], "methods", ["None"], ["", "def", "_stat", "(", "self", ",", "hypothesis_str", ",", "reference_list", ")", ":", "\n", "# SCORE ||| reference 1 words ||| reference n words ||| hypothesis words", "\n", "        ", "hypothesis_str", "=", "hypothesis_str", ".", "replace", "(", "'|||'", ",", "''", ")", ".", "replace", "(", "'  '", ",", "' '", ")", "\n", "score_line", "=", "' ||| '", ".", "join", "(", "(", "'SCORE'", ",", "' ||| '", ".", "join", "(", "reference_list", ")", ",", "hypothesis_str", ")", ")", "\n", "self", ".", "meteor_p", ".", "stdin", ".", "write", "(", "'{}\\n'", ".", "format", "(", "score_line", ")", ".", "encode", "(", ")", ")", "\n", "self", ".", "meteor_p", ".", "stdin", ".", "flush", "(", ")", "\n", "return", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "decode", "(", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.meteor.meteor.Meteor._score": [[60, 76], ["meteor.Meteor.lock.acquire", "hypothesis_str.replace().replace.replace().replace.replace().replace", "meteor.Meteor.meteor_p.stdin.write", "meteor.Meteor.meteor_p.stdout.readline().strip", "meteor.Meteor.meteor_p.stdin.write", "float", "float", "meteor.Meteor.lock.release", "meteor.Meteor.meteor_p.stdout.readline().strip", "meteor.Meteor.meteor_p.stdout.readline().strip", "hypothesis_str.replace().replace.replace().replace.replace", "meteor.Meteor.meteor_p.stdout.readline", "meteor.Meteor.meteor_p.stdout.readline", "meteor.Meteor.meteor_p.stdout.readline"], "methods", ["None"], ["", "def", "_score", "(", "self", ",", "hypothesis_str", ",", "reference_list", ")", ":", "\n", "        ", "self", ".", "lock", ".", "acquire", "(", ")", "\n", "# SCORE ||| reference 1 words ||| reference n words ||| hypothesis words", "\n", "hypothesis_str", "=", "hypothesis_str", ".", "replace", "(", "'|||'", ",", "''", ")", ".", "replace", "(", "'  '", ",", "' '", ")", "\n", "score_line", "=", "' ||| '", ".", "join", "(", "(", "'SCORE'", ",", "' ||| '", ".", "join", "(", "reference_list", ")", ",", "hypothesis_str", ")", ")", "\n", "self", ".", "meteor_p", ".", "stdin", ".", "write", "(", "'{}\\n'", ".", "format", "(", "score_line", ")", ")", "\n", "stats", "=", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", "\n", "eval_line", "=", "'EVAL ||| {}'", ".", "format", "(", "stats", ")", "\n", "# EVAL ||| stats", "\n", "self", ".", "meteor_p", ".", "stdin", ".", "write", "(", "'{}\\n'", ".", "format", "(", "eval_line", ")", ")", "\n", "score", "=", "float", "(", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "# bug fix: there are two values returned by the jar file, one average, and one all, so do it twice", "\n", "# thanks for Andrej for pointing this out", "\n", "score", "=", "float", "(", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "self", ".", "lock", ".", "release", "(", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.meteor.meteor.Meteor.__del__": [[77, 83], ["meteor.Meteor.lock.acquire", "meteor.Meteor.meteor_p.stdin.close", "meteor.Meteor.meteor_p.kill", "meteor.Meteor.meteor_p.wait", "meteor.Meteor.lock.release"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "lock", ".", "acquire", "(", ")", "\n", "self", ".", "meteor_p", ".", "stdin", ".", "close", "(", ")", "\n", "self", ".", "meteor_p", ".", "kill", "(", ")", "\n", "self", ".", "meteor_p", ".", "wait", "(", ")", "\n", "self", ".", "lock", ".", "release", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.tokenizer.ptbtokenizer.PTBTokenizer.tokenize": [[28, 73], ["os.path.dirname", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.close", "cmd.append", "subprocess.Popen", "token_lines.decode.decode.decode", "token_lines.decode.decode.split", "os.remove", "zip", "os.path.abspath", "sentences.encode", "os.path.basename", "subprocess.Popen.communicate", "final_tokenized_captions_for_image[].append", "captions_for_image.items", "range", "c[].replace", "len", "captions_for_image.items", "sentences.rstrip", "line.rstrip().split", "line.rstrip"], "methods", ["None"], ["def", "tokenize", "(", "self", ",", "captions_for_image", ")", ":", "\n", "        ", "cmd", "=", "[", "'java'", ",", "'-cp'", ",", "STANFORD_CORENLP_3_4_1_JAR", ",", "'edu.stanford.nlp.process.PTBTokenizer'", ",", "'-preserveLines'", ",", "'-lowerCase'", "]", "\n", "\n", "# ======================================================", "\n", "# prepare data for PTB Tokenizer", "\n", "# ======================================================", "\n", "final_tokenized_captions_for_image", "=", "{", "}", "\n", "image_id", "=", "[", "k", "for", "k", ",", "v", "in", "captions_for_image", ".", "items", "(", ")", "for", "_", "in", "range", "(", "len", "(", "v", ")", ")", "]", "\n", "sentences", "=", "'\\n'", ".", "join", "(", "[", "c", "[", "'caption'", "]", ".", "replace", "(", "'\\n'", ",", "' '", ")", "for", "k", ",", "v", "in", "captions_for_image", ".", "items", "(", ")", "for", "c", "in", "v", "]", ")", "\n", "\n", "# ======================================================", "\n", "# save sentences to temporary file", "\n", "# ======================================================", "\n", "path_to_jar_dirname", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "tmp_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", "delete", "=", "False", ",", "dir", "=", "path_to_jar_dirname", ")", "\n", "tmp_file", ".", "write", "(", "sentences", ".", "encode", "(", ")", ")", "\n", "tmp_file", ".", "close", "(", ")", "\n", "\n", "# ======================================================", "\n", "# tokenize sentence", "\n", "# ======================================================", "\n", "cmd", ".", "append", "(", "os", ".", "path", ".", "basename", "(", "tmp_file", ".", "name", ")", ")", "\n", "p_tokenizer", "=", "subprocess", ".", "Popen", "(", "cmd", ",", "cwd", "=", "path_to_jar_dirname", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "\n", "token_lines", "=", "p_tokenizer", ".", "communicate", "(", "input", "=", "sentences", ".", "rstrip", "(", ")", ")", "[", "0", "]", "\n", "\n", "token_lines", "=", "token_lines", ".", "decode", "(", ")", "\n", "lines", "=", "token_lines", ".", "split", "(", "'\\n'", ")", "\n", "# remove temp file", "\n", "os", ".", "remove", "(", "tmp_file", ".", "name", ")", "\n", "\n", "# ======================================================", "\n", "# create dictionary for tokenized captions", "\n", "# ======================================================", "\n", "for", "k", ",", "line", "in", "zip", "(", "image_id", ",", "lines", ")", ":", "\n", "            ", "if", "not", "k", "in", "final_tokenized_captions_for_image", ":", "\n", "                ", "final_tokenized_captions_for_image", "[", "k", "]", "=", "[", "]", "\n", "", "tokenized_caption", "=", "' '", ".", "join", "(", "[", "w", "for", "w", "in", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "if", "w", "not", "in", "PUNCTUATIONS", "]", ")", "\n", "final_tokenized_captions_for_image", "[", "k", "]", ".", "append", "(", "tokenized_caption", ")", "\n", "\n", "", "return", "final_tokenized_captions_for_image", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.copy": [[51, 57], ["cider_scorer.CiderScorer", "copy.copy", "copy.copy"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.copy", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.copy"], ["def", "copy", "(", "self", ")", ":", "\n", "        ", "''' copy the refs.'''", "\n", "new", "=", "CiderScorer", "(", "n", "=", "self", ".", "n", ")", "\n", "new", ".", "ctest", "=", "copy", ".", "copy", "(", "self", ".", "ctest", ")", "\n", "new", ".", "crefs", "=", "copy", ".", "copy", "(", "self", ".", "crefs", ")", "\n", "return", "new", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.__init__": [[58, 67], ["collections.defaultdict", "cider_scorer.CiderScorer.cook_append"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.cook_append"], ["", "def", "__init__", "(", "self", ",", "test", "=", "None", ",", "refs", "=", "None", ",", "n", "=", "4", ",", "sigma", "=", "6.0", ")", ":", "\n", "        ", "''' singular instance '''", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "sigma", "=", "sigma", "\n", "self", ".", "crefs", "=", "[", "]", "\n", "self", ".", "ctest", "=", "[", "]", "\n", "self", ".", "document_frequency", "=", "defaultdict", "(", "float", ")", "\n", "self", ".", "cook_append", "(", "test", ",", "refs", ")", "\n", "self", ".", "ref_len", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.cook_append": [[68, 77], ["cider_scorer.CiderScorer.crefs.append", "cider_scorer.cook_refs", "cider_scorer.CiderScorer.ctest.append", "cider_scorer.CiderScorer.ctest.append", "cider_scorer.cook_test"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.cook_refs", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.cook_test"], ["", "def", "cook_append", "(", "self", ",", "test", ",", "refs", ")", ":", "\n", "        ", "'''called by constructor and __iadd__ to avoid creating new instances.'''", "\n", "\n", "if", "refs", "is", "not", "None", ":", "\n", "            ", "self", ".", "crefs", ".", "append", "(", "cook_refs", "(", "refs", ")", ")", "\n", "if", "test", "is", "not", "None", ":", "\n", "                ", "self", ".", "ctest", ".", "append", "(", "cook_test", "(", "test", ")", ")", "## N.B.: -1", "\n", "", "else", ":", "\n", "                ", "self", ".", "ctest", ".", "append", "(", "None", ")", "# lens of crefs and ctest have to match", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.size": [[78, 81], ["len", "len", "len", "len", "len"], "methods", ["None"], ["", "", "", "def", "size", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "crefs", ")", "==", "len", "(", "self", ".", "ctest", ")", ",", "\"refs/test mismatch! %d<>%d\"", "%", "(", "len", "(", "self", ".", "crefs", ")", ",", "len", "(", "self", ".", "ctest", ")", ")", "\n", "return", "len", "(", "self", ".", "crefs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.__iadd__": [[82, 93], ["type", "cider_scorer.CiderScorer.cook_append", "cider_scorer.CiderScorer.ctest.extend", "cider_scorer.CiderScorer.crefs.extend"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.cook_append"], ["", "def", "__iadd__", "(", "self", ",", "other", ")", ":", "\n", "        ", "'''add an instance (e.g., from another sentence).'''", "\n", "\n", "if", "type", "(", "other", ")", "is", "tuple", ":", "\n", "## avoid creating new CiderScorer instances", "\n", "            ", "self", ".", "cook_append", "(", "other", "[", "0", "]", ",", "other", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ctest", ".", "extend", "(", "other", ".", "ctest", ")", "\n", "self", ".", "crefs", ".", "extend", "(", "other", ".", "crefs", ")", "\n", "\n", "", "return", "self", "\n", "", "def", "compute_doc_freq", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.compute_doc_freq": [[93, 104], ["set", "ref.items"], "methods", ["None"], ["", "def", "compute_doc_freq", "(", "self", ")", ":", "\n", "        ", "'''\n        Compute term frequency for reference data.\n        This will be used to compute idf (inverse document frequency later)\n        The term frequency is stored in the object\n        :return: None\n        '''", "\n", "for", "refs", "in", "self", ".", "crefs", ":", "\n", "# refs, k ref captions of one image", "\n", "            ", "for", "ngram", "in", "set", "(", "[", "ngram", "for", "ref", "in", "refs", "for", "(", "ngram", ",", "count", ")", "in", "ref", ".", "items", "(", ")", "]", ")", ":", "\n", "                ", "self", ".", "document_frequency", "[", "ngram", "]", "+=", "1", "\n", "# maxcounts[ngram] = max(maxcounts.get(ngram,0), count)", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.compute_cider": [[106, 182], ["numpy.log", "zip", "cnts.items", "float", "numpy.array", "range", "float", "cider_scorer.CiderScorer.compute_cider.counts2vec"], "methods", ["None"], ["", "", "", "def", "compute_cider", "(", "self", ")", ":", "\n", "        ", "def", "counts2vec", "(", "cnts", ")", ":", "\n", "            ", "\"\"\"\n            Function maps counts of ngram to vector of tfidf weights.\n            The function returns vec, an array of dictionary that store mapping of n-gram and tf-idf weights.\n            The n-th entry of array denotes length of n-grams.\n            :param cnts:\n            :return: vec (array of dict), norm (array of float), length (int)\n            \"\"\"", "\n", "vec", "=", "[", "defaultdict", "(", "float", ")", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "length", "=", "0", "\n", "norm", "=", "[", "0.0", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "for", "(", "ngram", ",", "term_freq", ")", "in", "cnts", ".", "items", "(", ")", ":", "\n", "# give word count 1 if it doesn't appear in reference corpus", "\n", "                ", "df", "=", "np", ".", "log", "(", "max", "(", "1.0", ",", "self", ".", "document_frequency", "[", "ngram", "]", ")", ")", "\n", "# ngram index", "\n", "n", "=", "len", "(", "ngram", ")", "-", "1", "\n", "# tf (term_freq) * idf (precomputed idf) for n-grams", "\n", "vec", "[", "n", "]", "[", "ngram", "]", "=", "float", "(", "term_freq", ")", "*", "(", "self", ".", "ref_len", "-", "df", ")", "\n", "# compute norm for the vector.  the norm will be used for computing similarity", "\n", "norm", "[", "n", "]", "+=", "pow", "(", "vec", "[", "n", "]", "[", "ngram", "]", ",", "2", ")", "\n", "\n", "if", "n", "==", "1", ":", "\n", "                    ", "length", "+=", "term_freq", "\n", "", "", "norm", "=", "[", "np", ".", "sqrt", "(", "n", ")", "for", "n", "in", "norm", "]", "\n", "return", "vec", ",", "norm", ",", "length", "\n", "\n", "", "def", "sim", "(", "vec_hyp", ",", "vec_ref", ",", "norm_hyp", ",", "norm_ref", ",", "length_hyp", ",", "length_ref", ")", ":", "\n", "            ", "'''\n            Compute the cosine similarity of two vectors.\n            :param vec_hyp: array of dictionary for vector corresponding to hypothesis\n            :param vec_ref: array of dictionary for vector corresponding to reference\n            :param norm_hyp: array of float for vector corresponding to hypothesis\n            :param norm_ref: array of float for vector corresponding to reference\n            :param length_hyp: int containing length of hypothesis\n            :param length_ref: int containing length of reference\n            :return: array of score for each n-grams cosine similarity\n            '''", "\n", "delta", "=", "float", "(", "length_hyp", "-", "length_ref", ")", "\n", "# measure consine similarity", "\n", "val", "=", "np", ".", "array", "(", "[", "0.0", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "# ngram", "\n", "                ", "for", "(", "ngram", ",", "count", ")", "in", "vec_hyp", "[", "n", "]", ".", "items", "(", ")", ":", "\n", "# vrama91 : added clipping", "\n", "                    ", "val", "[", "n", "]", "+=", "min", "(", "vec_hyp", "[", "n", "]", "[", "ngram", "]", ",", "vec_ref", "[", "n", "]", "[", "ngram", "]", ")", "*", "vec_ref", "[", "n", "]", "[", "ngram", "]", "\n", "\n", "", "if", "(", "norm_hyp", "[", "n", "]", "!=", "0", ")", "and", "(", "norm_ref", "[", "n", "]", "!=", "0", ")", ":", "\n", "                    ", "val", "[", "n", "]", "/=", "(", "norm_hyp", "[", "n", "]", "*", "norm_ref", "[", "n", "]", ")", "\n", "\n", "", "assert", "(", "not", "math", ".", "isnan", "(", "val", "[", "n", "]", ")", ")", "\n", "# vrama91: added a length based gaussian penalty", "\n", "val", "[", "n", "]", "*=", "np", ".", "e", "**", "(", "-", "(", "delta", "**", "2", ")", "/", "(", "2", "*", "self", ".", "sigma", "**", "2", ")", ")", "\n", "", "return", "val", "\n", "\n", "# compute log reference length", "\n", "", "self", ".", "ref_len", "=", "np", ".", "log", "(", "float", "(", "len", "(", "self", ".", "crefs", ")", ")", ")", "\n", "\n", "scores", "=", "[", "]", "\n", "for", "test", ",", "refs", "in", "zip", "(", "self", ".", "ctest", ",", "self", ".", "crefs", ")", ":", "\n", "# compute vector for test captions", "\n", "            ", "vec", ",", "norm", ",", "length", "=", "counts2vec", "(", "test", ")", "\n", "# compute vector for ref captions", "\n", "score", "=", "np", ".", "array", "(", "[", "0.0", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", ")", "\n", "for", "ref", "in", "refs", ":", "\n", "                ", "vec_ref", ",", "norm_ref", ",", "length_ref", "=", "counts2vec", "(", "ref", ")", "\n", "score", "+=", "sim", "(", "vec", ",", "vec_ref", ",", "norm", ",", "norm_ref", ",", "length", ",", "length_ref", ")", "\n", "# change by vrama91 - mean of ngram scores, instead of sum", "\n", "", "score_avg", "=", "np", ".", "mean", "(", "score", ")", "\n", "# divide by number of references", "\n", "score_avg", "/=", "len", "(", "refs", ")", "\n", "# multiply score by 10", "\n", "score_avg", "*=", "10.0", "\n", "# append score of an image to the score list", "\n", "scores", ".", "append", "(", "score_avg", ")", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.compute_score": [[183, 193], ["cider_scorer.CiderScorer.compute_doc_freq", "cider_scorer.CiderScorer.compute_cider", "len", "max", "numpy.mean", "numpy.array", "cider_scorer.CiderScorer.document_frequency.values", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.compute_doc_freq", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.compute_cider"], ["", "def", "compute_score", "(", "self", ",", "option", "=", "None", ",", "verbose", "=", "0", ")", ":", "\n", "# compute idf", "\n", "        ", "self", ".", "compute_doc_freq", "(", ")", "\n", "# assert to check document frequency", "\n", "assert", "(", "len", "(", "self", ".", "ctest", ")", ">=", "max", "(", "self", ".", "document_frequency", ".", "values", "(", ")", ")", ")", "\n", "# compute cider score", "\n", "score", "=", "self", ".", "compute_cider", "(", ")", "\n", "# debug", "\n", "# print score", "\n", "return", "np", ".", "mean", "(", "np", ".", "array", "(", "score", ")", ")", ",", "np", ".", "array", "(", "score", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.precook": [[11, 27], ["s.split", "collections.defaultdict", "range", "range", "tuple", "len"], "function", ["None"], ["def", "precook", "(", "s", ",", "n", "=", "4", ",", "out", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Takes a string as input and returns an object that can be given to\n    either cook_refs or cook_test. This is optional: cook_refs and cook_test\n    can take string arguments as well.\n    :param s: string : sentence to be converted into ngrams\n    :param n: int    : number of ngrams for which representation is calculated\n    :return: term frequency vector for occuring ngrams\n    \"\"\"", "\n", "words", "=", "s", ".", "split", "(", ")", "\n", "counts", "=", "defaultdict", "(", "int", ")", "\n", "for", "k", "in", "range", "(", "1", ",", "n", "+", "1", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "words", ")", "-", "k", "+", "1", ")", ":", "\n", "            ", "ngram", "=", "tuple", "(", "words", "[", "i", ":", "i", "+", "k", "]", ")", "\n", "counts", "[", "ngram", "]", "+=", "1", "\n", "", "", "return", "counts", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.cook_refs": [[28, 37], ["cider_scorer.precook"], "function", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.precook"], ["", "def", "cook_refs", "(", "refs", ",", "n", "=", "4", ")", ":", "## lhuang: oracle will call with \"average\"", "\n", "    ", "'''Takes a list of reference sentences for a single segment\n    and returns an object that encapsulates everything that BLEU\n    needs to know about them.\n    :param refs: list of string : reference sentences for some image\n    :param n: int : number of ngrams for which (ngram) representation is calculated\n    :return: result (list of dict)\n    '''", "\n", "return", "[", "precook", "(", "ref", ",", "n", ")", "for", "ref", "in", "refs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.cook_test": [[38, 46], ["cider_scorer.precook"], "function", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.precook"], ["", "def", "cook_test", "(", "test", ",", "n", "=", "4", ")", ":", "\n", "    ", "'''Takes a test sentence and returns an object that\n    encapsulates everything that BLEU needs to know about it.\n    :param test: list of string : hypothesis sentence for some image\n    :param n: int : number of ngrams for which (ngram) representation is calculated\n    :return: result (dict)\n    '''", "\n", "return", "precook", "(", "test", ",", "n", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider.Cider.__init__": [[18, 23], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "test", "=", "None", ",", "refs", "=", "None", ",", "n", "=", "4", ",", "sigma", "=", "6.0", ")", ":", "\n", "# set cider to sum over 1 to 4-grams", "\n", "        ", "self", ".", "_n", "=", "n", "\n", "# set the standard deviation parameter for gaussian penalty", "\n", "self", ".", "_sigma", "=", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider.Cider.compute_score": [[24, 52], ["gts.keys", "cider_scorer.CiderScorer.CiderScorer", "cider_scorer.CiderScorer.CiderScorer.compute_score", "gts.keys", "res.keys", "type", "len", "type", "len"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider.Cider.compute_score"], ["", "def", "compute_score", "(", "self", ",", "gts", ",", "res", ")", ":", "\n", "        ", "\"\"\"\n        Main function to compute CIDEr score\n        :param  hypo_for_image (dict) : dictionary with key <image> and value <tokenized hypothesis / candidate sentence>\n                ref_for_image (dict)  : dictionary with key <image> and value <tokenized reference sentence>\n        :return: cider (float) : computed CIDEr score for the corpus\n        \"\"\"", "\n", "\n", "assert", "(", "gts", ".", "keys", "(", ")", "==", "res", ".", "keys", "(", ")", ")", "\n", "imgIds", "=", "gts", ".", "keys", "(", ")", "\n", "\n", "cider_scorer", "=", "CiderScorer", "(", "n", "=", "self", ".", "_n", ",", "sigma", "=", "self", ".", "_sigma", ")", "\n", "\n", "for", "id", "in", "imgIds", ":", "\n", "            ", "hypo", "=", "res", "[", "id", "]", "\n", "ref", "=", "gts", "[", "id", "]", "\n", "\n", "# Sanity check.", "\n", "assert", "(", "type", "(", "hypo", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "hypo", ")", "==", "1", ")", "\n", "assert", "(", "type", "(", "ref", ")", "is", "list", ")", "\n", "assert", "(", "len", "(", "ref", ")", ">", "0", ")", "\n", "\n", "cider_scorer", "+=", "(", "hypo", "[", "0", "]", ",", "ref", ")", "\n", "\n", "", "(", "score", ",", "scores", ")", "=", "cider_scorer", ".", "compute_score", "(", ")", "\n", "\n", "return", "score", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider.Cider.method": [[53, 55], ["None"], "methods", ["None"], ["", "def", "method", "(", "self", ")", ":", "\n", "        ", "return", "\"CIDEr\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.training.train_edlps.main": [[18, 179], ["misc.utils.make_parser", "utils.make_parser.parse_args", "misc.dataloader.Dataloader", "models.enc_dec_sh_dis.ParaphraseGenerator", "tensorboardX.SummaryWriter", "os.makedirs", "torch.DataLoader", "torch.DataLoader", "torch.RMSprop", "pgen.to.train", "pgen.to.to", "torch.CrossEntropyLoss", "range", "tensorboardX.SummaryWriter.close", "print", "misc.dataloader.Dataloader.getVocabSize", "misc.dataloader.Dataloader.getSeqLength", "os.path.join", "os.path.join", "torch.Subset", "torch.Subset", "pgen.to.parameters", "pgen.to.train", "tqdm.tqdm", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "misc.train_util.evaluate_scores", "misc.train_util.dump_samples", "pgen.to.eval", "misc.train_util.save_model", "range", "range", "phrase.to.to", "para_phrase.to.to", "pgen.to.", "nn.CrossEntropyLoss.", "misc.net_utils.JointEmbeddingLoss", "optim.RMSprop.zero_grad", "optim.RMSprop.step", "cross_entropy_loss.item", "net_utils.JointEmbeddingLoss.item", "misc.net_utils.decode_sequence", "misc.net_utils.decode_sequence", "misc.net_utils.decode_sequence", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "tensorboardX.SummaryWriter.add_scalar", "os.path.join", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "misc.train_util.evaluate_scores", "misc.train_util.dump_samples", "os.path.join", "phrase.to.t", "out.permute", "torch.argmax().t", "torch.argmax().t", "torch.argmax().t", "torch.argmax().t", "phrase.to.to", "para_phrase.to.to", "pgen.to.", "nn.CrossEntropyLoss.", "misc.net_utils.JointEmbeddingLoss", "cross_entropy_loss.item", "net_utils.JointEmbeddingLoss.item", "misc.net_utils.decode_sequence", "misc.net_utils.decode_sequence", "misc.net_utils.decode_sequence", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "tensorboardX.SummaryWriter.add_scalar", "os.path.join", "str", "str", "para_phrase.to.t", "str", "phrase.to.t", "out.permute", "torch.argmax().t", "torch.argmax().t", "torch.argmax().t", "torch.argmax().t", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "str", "para_phrase.to.t", "str", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax"], "function", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.utils.make_parser", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.getVocabSize", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.getSeqLength", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.train_util.evaluate_scores", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.train_util.dump_samples", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.train_util.save_model", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.JointEmbeddingLoss", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.decode_sequence", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.decode_sequence", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.decode_sequence", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.train_util.evaluate_scores", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.train_util.dump_samples", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.JointEmbeddingLoss", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.decode_sequence", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.decode_sequence", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.decode_sequence"], ["def", "main", "(", ")", ":", "\n", "\n", "# get arguments ---", "\n", "\n", "    ", "parser", "=", "utils", ".", "make_parser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# build model", "\n", "\n", "# # get data", "\n", "data", "=", "Dataloader", "(", "args", ".", "input_json", ",", "args", ".", "input_ques_h5", ")", "\n", "\n", "# # make op", "\n", "op", "=", "{", "\n", "\"vocab_sz\"", ":", "data", ".", "getVocabSize", "(", ")", ",", "\n", "\"max_seq_len\"", ":", "data", ".", "getSeqLength", "(", ")", ",", "\n", "\"emb_hid_dim\"", ":", "args", ".", "emb_hid_dim", ",", "\n", "\"emb_dim\"", ":", "args", ".", "emb_dim", ",", "\n", "\"enc_dim\"", ":", "args", ".", "enc_dim", ",", "\n", "\"enc_dropout\"", ":", "args", ".", "enc_dropout", ",", "\n", "\"enc_rnn_dim\"", ":", "args", ".", "enc_rnn_dim", ",", "\n", "\"gen_rnn_dim\"", ":", "args", ".", "gen_rnn_dim", ",", "\n", "\"gen_dropout\"", ":", "args", ".", "gen_dropout", ",", "\n", "\"lr\"", ":", "args", ".", "learning_rate", ",", "\n", "\"epochs\"", ":", "args", ".", "n_epoch", "\n", "}", "\n", "\n", "# # instantiate paraphrase generator", "\n", "pgen", "=", "ParaphraseGenerator", "(", "op", ")", "\n", "\n", "# setup logging", "\n", "logger", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "LOG_DIR", ",", "TIME", "+", "args", ".", "name", ")", ")", "\n", "# subprocess.run(['mkdir', os.path.join(GEN_DIR, TIME), os.path.join(SAVE_DIR, TIME)], check=False)", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "GEN_DIR", ",", "TIME", ")", ",", "exist_ok", "=", "True", ")", "\n", "# ready model for training", "\n", "\n", "train_loader", "=", "Data", ".", "DataLoader", "(", "\n", "Data", ".", "Subset", "(", "data", ",", "range", "(", "args", ".", "train_dataset_len", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", ")", "\n", "test_loader", "=", "Data", ".", "DataLoader", "(", "Data", ".", "Subset", "(", "\n", "data", ",", "\n", "range", "(", "args", ".", "train_dataset_len", ",", "\n", "args", ".", "train_dataset_len", "+", "args", ".", "val_dataset_len", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ")", "\n", "\n", "pgen_optim", "=", "optim", ".", "RMSprop", "(", "pgen", ".", "parameters", "(", ")", ",", "lr", "=", "op", "[", "\"lr\"", "]", ")", "\n", "pgen", ".", "train", "(", ")", "\n", "\n", "# train model", "\n", "pgen", "=", "pgen", ".", "to", "(", "DEVICE", ")", "\n", "cross_entropy_loss", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "data", ".", "PAD_token", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "op", "[", "\"epochs\"", "]", ")", ":", "\n", "\n", "        ", "epoch_l1", "=", "0", "\n", "epoch_l2", "=", "0", "\n", "itr", "=", "0", "\n", "ph", "=", "[", "]", "\n", "pph", "=", "[", "]", "\n", "gpph", "=", "[", "]", "\n", "pgen", ".", "train", "(", ")", "\n", "\n", "for", "phrase", ",", "phrase_len", ",", "para_phrase", ",", "para_phrase_len", ",", "_", "in", "tqdm", "(", "\n", "train_loader", ",", "ascii", "=", "True", ",", "desc", "=", "\"epoch\"", "+", "str", "(", "epoch", ")", ")", ":", "\n", "\n", "            ", "phrase", "=", "phrase", ".", "to", "(", "DEVICE", ")", "\n", "para_phrase", "=", "para_phrase", ".", "to", "(", "DEVICE", ")", "\n", "\n", "out", ",", "enc_out", ",", "enc_sim_phrase", "=", "pgen", "(", "\n", "phrase", ".", "t", "(", ")", ",", "\n", "sim_phrase", "=", "para_phrase", ".", "t", "(", ")", ",", "\n", "train", "=", "True", ",", "\n", ")", "\n", "\n", "loss_1", "=", "cross_entropy_loss", "(", "out", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ",", "para_phrase", ")", "\n", "loss_2", "=", "net_utils", ".", "JointEmbeddingLoss", "(", "enc_out", ",", "enc_sim_phrase", ")", "\n", "\n", "pgen_optim", ".", "zero_grad", "(", ")", "\n", "(", "loss_1", "+", "loss_2", ")", ".", "backward", "(", ")", "\n", "\n", "pgen_optim", ".", "step", "(", ")", "\n", "\n", "# accumulate results", "\n", "\n", "epoch_l1", "+=", "loss_1", ".", "item", "(", ")", "\n", "epoch_l2", "+=", "loss_2", ".", "item", "(", ")", "\n", "ph", "+=", "net_utils", ".", "decode_sequence", "(", "data", ".", "ix_to_word", ",", "phrase", ")", "\n", "pph", "+=", "net_utils", ".", "decode_sequence", "(", "data", ".", "ix_to_word", ",", "para_phrase", ")", "\n", "gpph", "+=", "net_utils", ".", "decode_sequence", "(", "data", ".", "ix_to_word", ",", "\n", "torch", ".", "argmax", "(", "out", ",", "dim", "=", "-", "1", ")", ".", "t", "(", ")", ")", "\n", "\n", "itr", "+=", "1", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "# log results", "\n", "\n", "", "logger", ".", "add_scalar", "(", "\"l2_train\"", ",", "epoch_l2", "/", "itr", ",", "epoch", ")", "\n", "logger", ".", "add_scalar", "(", "\"l1_train\"", ",", "epoch_l1", "/", "itr", ",", "epoch", ")", "\n", "\n", "scores", "=", "evaluate_scores", "(", "gpph", ",", "pph", ")", "\n", "\n", "for", "key", "in", "scores", ":", "\n", "            ", "logger", ".", "add_scalar", "(", "key", "+", "\"_train\"", ",", "scores", "[", "key", "]", ",", "epoch", ")", "\n", "\n", "", "dump_samples", "(", "ph", ",", "pph", ",", "gpph", ",", "\n", "os", ".", "path", ".", "join", "(", "GEN_DIR", ",", "TIME", ",", "\n", "str", "(", "epoch", ")", "+", "\"_train.txt\"", ")", ")", "\n", "# start validation", "\n", "\n", "epoch_l1", "=", "0", "\n", "epoch_l2", "=", "0", "\n", "itr", "=", "0", "\n", "ph", "=", "[", "]", "\n", "pph", "=", "[", "]", "\n", "gpph", "=", "[", "]", "\n", "pgen", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "phrase", ",", "phrase_len", ",", "para_phrase", ",", "para_phrase_len", ",", "_", "in", "tqdm", "(", "\n", "test_loader", ",", "ascii", "=", "True", ",", "desc", "=", "\"val\"", "+", "str", "(", "epoch", ")", ")", ":", "\n", "\n", "                ", "phrase", "=", "phrase", ".", "to", "(", "DEVICE", ")", "\n", "para_phrase", "=", "para_phrase", ".", "to", "(", "DEVICE", ")", "\n", "\n", "out", ",", "enc_out", ",", "enc_sim_phrase", "=", "pgen", "(", "phrase", ".", "t", "(", ")", ",", "\n", "sim_phrase", "=", "para_phrase", ".", "t", "(", ")", ")", "\n", "\n", "loss_1", "=", "cross_entropy_loss", "(", "out", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ",", "para_phrase", ")", "\n", "loss_2", "=", "net_utils", ".", "JointEmbeddingLoss", "(", "enc_out", ",", "enc_sim_phrase", ")", "\n", "\n", "epoch_l1", "+=", "loss_1", ".", "item", "(", ")", "\n", "epoch_l2", "+=", "loss_2", ".", "item", "(", ")", "\n", "ph", "+=", "net_utils", ".", "decode_sequence", "(", "data", ".", "ix_to_word", ",", "phrase", ")", "\n", "pph", "+=", "net_utils", ".", "decode_sequence", "(", "data", ".", "ix_to_word", ",", "para_phrase", ")", "\n", "gpph", "+=", "net_utils", ".", "decode_sequence", "(", "\n", "data", ".", "ix_to_word", ",", "\n", "torch", ".", "argmax", "(", "out", ",", "dim", "=", "-", "1", ")", ".", "t", "(", ")", ")", "\n", "\n", "itr", "+=", "1", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "logger", ".", "add_scalar", "(", "\"l2_val\"", ",", "epoch_l2", "/", "itr", ",", "epoch", ")", "\n", "logger", ".", "add_scalar", "(", "\"l1_val\"", ",", "epoch_l1", "/", "itr", ",", "epoch", ")", "\n", "\n", "scores", "=", "evaluate_scores", "(", "gpph", ",", "pph", ")", "\n", "\n", "for", "key", "in", "scores", ":", "\n", "                ", "logger", ".", "add_scalar", "(", "key", "+", "\"_val\"", ",", "scores", "[", "key", "]", ",", "epoch", ")", "\n", "\n", "", "dump_samples", "(", "ph", ",", "pph", ",", "gpph", ",", "\n", "os", ".", "path", ".", "join", "(", "GEN_DIR", ",", "TIME", ",", "\n", "str", "(", "epoch", ")", "+", "\"_val.txt\"", ")", ")", "\n", "\n", "", "save_model", "(", "pgen", ",", "pgen_optim", ",", "epoch", ",", "os", ".", "path", ".", "join", "(", "SAVE_DIR", ",", "TIME", ",", "str", "(", "epoch", ")", ")", ")", "\n", "\n", "# wrap ups", "\n", "", "logger", ".", "close", "(", ")", "\n", "print", "(", "\"Done !!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.training.train_edlp.main": [[18, 179], ["misc.utils.make_parser", "utils.make_parser.parse_args", "misc.dataloader.Dataloader", "models.enc_dec_dis.ParaphraseGenerator", "tensorboardX.SummaryWriter", "os.makedirs", "torch.DataLoader", "torch.DataLoader", "torch.RMSprop", "pgen.to.train", "pgen.to.to", "torch.CrossEntropyLoss", "range", "tensorboardX.SummaryWriter.close", "print", "misc.dataloader.Dataloader.getVocabSize", "misc.dataloader.Dataloader.getSeqLength", "os.path.join", "os.path.join", "torch.Subset", "torch.Subset", "pgen.to.parameters", "pgen.to.train", "tqdm.tqdm", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "misc.train_util.evaluate_scores", "misc.train_util.dump_samples", "pgen.to.eval", "misc.train_util.save_model", "range", "range", "phrase.to.to", "para_phrase.to.to", "pgen.to.", "nn.CrossEntropyLoss.", "misc.net_utils.JointEmbeddingLoss", "optim.RMSprop.zero_grad", "optim.RMSprop.step", "cross_entropy_loss.item", "net_utils.JointEmbeddingLoss.item", "misc.net_utils.decode_sequence", "misc.net_utils.decode_sequence", "misc.net_utils.decode_sequence", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "tensorboardX.SummaryWriter.add_scalar", "os.path.join", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "misc.train_util.evaluate_scores", "misc.train_util.dump_samples", "os.path.join", "phrase.to.t", "out.permute", "torch.argmax().t", "torch.argmax().t", "torch.argmax().t", "torch.argmax().t", "phrase.to.to", "para_phrase.to.to", "pgen.to.", "nn.CrossEntropyLoss.", "misc.net_utils.JointEmbeddingLoss", "cross_entropy_loss.item", "net_utils.JointEmbeddingLoss.item", "misc.net_utils.decode_sequence", "misc.net_utils.decode_sequence", "misc.net_utils.decode_sequence", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "tensorboardX.SummaryWriter.add_scalar", "os.path.join", "str", "str", "para_phrase.to.t", "str", "phrase.to.t", "out.permute", "torch.argmax().t", "torch.argmax().t", "torch.argmax().t", "torch.argmax().t", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "str", "para_phrase.to.t", "str", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax"], "function", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.utils.make_parser", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.getVocabSize", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.getSeqLength", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.train_util.evaluate_scores", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.train_util.dump_samples", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.train_util.save_model", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.JointEmbeddingLoss", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.decode_sequence", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.decode_sequence", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.decode_sequence", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.train_util.evaluate_scores", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.train_util.dump_samples", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.JointEmbeddingLoss", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.decode_sequence", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.decode_sequence", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.decode_sequence"], ["def", "main", "(", ")", ":", "\n", "\n", "# get arguments ---", "\n", "\n", "    ", "parser", "=", "utils", ".", "make_parser", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# build model", "\n", "\n", "# # get data", "\n", "data", "=", "Dataloader", "(", "args", ".", "input_json", ",", "args", ".", "input_ques_h5", ")", "\n", "\n", "# # make op", "\n", "op", "=", "{", "\n", "\"vocab_sz\"", ":", "data", ".", "getVocabSize", "(", ")", ",", "\n", "\"max_seq_len\"", ":", "data", ".", "getSeqLength", "(", ")", ",", "\n", "\"emb_hid_dim\"", ":", "args", ".", "emb_hid_dim", ",", "\n", "\"emb_dim\"", ":", "args", ".", "emb_dim", ",", "\n", "\"enc_dim\"", ":", "args", ".", "enc_dim", ",", "\n", "\"enc_dropout\"", ":", "args", ".", "enc_dropout", ",", "\n", "\"enc_rnn_dim\"", ":", "args", ".", "enc_rnn_dim", ",", "\n", "\"gen_rnn_dim\"", ":", "args", ".", "gen_rnn_dim", ",", "\n", "\"gen_dropout\"", ":", "args", ".", "gen_dropout", ",", "\n", "\"lr\"", ":", "args", ".", "learning_rate", ",", "\n", "\"epochs\"", ":", "args", ".", "n_epoch", "\n", "}", "\n", "\n", "# # instantiate paraphrase generator", "\n", "pgen", "=", "ParaphraseGenerator", "(", "op", ")", "\n", "\n", "# setup logging", "\n", "logger", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "LOG_DIR", ",", "TIME", "+", "args", ".", "name", ")", ")", "\n", "# subprocess.run(['mkdir', os.path.join(GEN_DIR, TIME)], check=False)", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "GEN_DIR", ",", "TIME", ")", ",", "exist_ok", "=", "True", ")", "\n", "# ready model for training", "\n", "\n", "train_loader", "=", "Data", ".", "DataLoader", "(", "\n", "Data", ".", "Subset", "(", "data", ",", "range", "(", "args", ".", "train_dataset_len", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", ")", "\n", "test_loader", "=", "Data", ".", "DataLoader", "(", "Data", ".", "Subset", "(", "\n", "data", ",", "\n", "range", "(", "args", ".", "train_dataset_len", ",", "\n", "args", ".", "train_dataset_len", "+", "args", ".", "val_dataset_len", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ")", "\n", "\n", "pgen_optim", "=", "optim", ".", "RMSprop", "(", "pgen", ".", "parameters", "(", ")", ",", "lr", "=", "op", "[", "\"lr\"", "]", ")", "\n", "pgen", ".", "train", "(", ")", "\n", "\n", "# train model", "\n", "pgen", "=", "pgen", ".", "to", "(", "DEVICE", ")", "\n", "cross_entropy_loss", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "data", ".", "PAD_token", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "op", "[", "\"epochs\"", "]", ")", ":", "\n", "\n", "        ", "epoch_l1", "=", "0", "\n", "epoch_l2", "=", "0", "\n", "itr", "=", "0", "\n", "ph", "=", "[", "]", "\n", "pph", "=", "[", "]", "\n", "gpph", "=", "[", "]", "\n", "pgen", ".", "train", "(", ")", "\n", "\n", "for", "phrase", ",", "phrase_len", ",", "para_phrase", ",", "para_phrase_len", ",", "_", "in", "tqdm", "(", "\n", "train_loader", ",", "ascii", "=", "True", ",", "desc", "=", "\"epoch\"", "+", "str", "(", "epoch", ")", ")", ":", "\n", "\n", "            ", "phrase", "=", "phrase", ".", "to", "(", "DEVICE", ")", "\n", "para_phrase", "=", "para_phrase", ".", "to", "(", "DEVICE", ")", "\n", "\n", "out", ",", "enc_out", ",", "enc_sim_phrase", "=", "pgen", "(", "\n", "phrase", ".", "t", "(", ")", ",", "\n", "sim_phrase", "=", "para_phrase", ".", "t", "(", ")", ",", "\n", "train", "=", "True", ",", "\n", ")", "\n", "\n", "loss_1", "=", "cross_entropy_loss", "(", "out", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ",", "para_phrase", ")", "\n", "loss_2", "=", "net_utils", ".", "JointEmbeddingLoss", "(", "enc_out", ",", "enc_sim_phrase", ")", "\n", "\n", "pgen_optim", ".", "zero_grad", "(", ")", "\n", "(", "loss_1", "+", "loss_2", ")", ".", "backward", "(", ")", "\n", "\n", "pgen_optim", ".", "step", "(", ")", "\n", "\n", "# accumulate results", "\n", "\n", "epoch_l1", "+=", "loss_1", ".", "item", "(", ")", "\n", "epoch_l2", "+=", "loss_2", ".", "item", "(", ")", "\n", "ph", "+=", "net_utils", ".", "decode_sequence", "(", "data", ".", "ix_to_word", ",", "phrase", ")", "\n", "pph", "+=", "net_utils", ".", "decode_sequence", "(", "data", ".", "ix_to_word", ",", "para_phrase", ")", "\n", "gpph", "+=", "net_utils", ".", "decode_sequence", "(", "data", ".", "ix_to_word", ",", "\n", "torch", ".", "argmax", "(", "out", ",", "dim", "=", "-", "1", ")", ".", "t", "(", ")", ")", "\n", "\n", "itr", "+=", "1", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "# log results", "\n", "\n", "", "logger", ".", "add_scalar", "(", "\"l2_train\"", ",", "epoch_l2", "/", "itr", ",", "epoch", ")", "\n", "logger", ".", "add_scalar", "(", "\"l1_train\"", ",", "epoch_l1", "/", "itr", ",", "epoch", ")", "\n", "\n", "scores", "=", "evaluate_scores", "(", "gpph", ",", "pph", ")", "\n", "\n", "for", "key", "in", "scores", ":", "\n", "            ", "logger", ".", "add_scalar", "(", "key", "+", "\"_train\"", ",", "scores", "[", "key", "]", ",", "epoch", ")", "\n", "\n", "", "dump_samples", "(", "ph", ",", "pph", ",", "gpph", ",", "\n", "os", ".", "path", ".", "join", "(", "GEN_DIR", ",", "TIME", ",", "\n", "str", "(", "epoch", ")", "+", "\"_train.txt\"", ")", ")", "\n", "\n", "# start validation", "\n", "\n", "epoch_l1", "=", "0", "\n", "epoch_l2", "=", "0", "\n", "itr", "=", "0", "\n", "ph", "=", "[", "]", "\n", "pph", "=", "[", "]", "\n", "gpph", "=", "[", "]", "\n", "pgen", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "phrase", ",", "phrase_len", ",", "para_phrase", ",", "para_phrase_len", ",", "_", "in", "tqdm", "(", "\n", "test_loader", ",", "ascii", "=", "True", ",", "desc", "=", "\"val\"", "+", "str", "(", "epoch", ")", ")", ":", "\n", "\n", "                ", "phrase", "=", "phrase", ".", "to", "(", "DEVICE", ")", "\n", "para_phrase", "=", "para_phrase", ".", "to", "(", "DEVICE", ")", "\n", "\n", "out", ",", "enc_out", ",", "enc_sim_phrase", "=", "pgen", "(", "phrase", ".", "t", "(", ")", ",", "\n", "sim_phrase", "=", "para_phrase", ".", "t", "(", ")", ")", "\n", "\n", "loss_1", "=", "cross_entropy_loss", "(", "out", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ",", "para_phrase", ")", "\n", "loss_2", "=", "net_utils", ".", "JointEmbeddingLoss", "(", "enc_out", ",", "enc_sim_phrase", ")", "\n", "\n", "epoch_l1", "+=", "loss_1", ".", "item", "(", ")", "\n", "epoch_l2", "+=", "loss_2", ".", "item", "(", ")", "\n", "ph", "+=", "net_utils", ".", "decode_sequence", "(", "data", ".", "ix_to_word", ",", "phrase", ")", "\n", "pph", "+=", "net_utils", ".", "decode_sequence", "(", "data", ".", "ix_to_word", ",", "para_phrase", ")", "\n", "gpph", "+=", "net_utils", ".", "decode_sequence", "(", "\n", "data", ".", "ix_to_word", ",", "\n", "torch", ".", "argmax", "(", "out", ",", "dim", "=", "-", "1", ")", ".", "t", "(", ")", ")", "\n", "\n", "itr", "+=", "1", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "logger", ".", "add_scalar", "(", "\"l2_val\"", ",", "epoch_l2", "/", "itr", ",", "epoch", ")", "\n", "logger", ".", "add_scalar", "(", "\"l1_val\"", ",", "epoch_l1", "/", "itr", ",", "epoch", ")", "\n", "\n", "scores", "=", "evaluate_scores", "(", "gpph", ",", "pph", ")", "\n", "\n", "for", "key", "in", "scores", ":", "\n", "                ", "logger", ".", "add_scalar", "(", "key", "+", "\"_val\"", ",", "scores", "[", "key", "]", ",", "epoch", ")", "\n", "\n", "", "dump_samples", "(", "ph", ",", "pph", ",", "gpph", ",", "\n", "os", ".", "path", ".", "join", "(", "GEN_DIR", ",", "TIME", ",", "\n", "str", "(", "epoch", ")", "+", "\"_val.txt\"", ")", ")", "\n", "", "save_model", "(", "pgen", ",", "pgen_optim", ",", "epoch", ",", "os", ".", "path", ".", "join", "(", "SAVE_DIR", ",", "TIME", ",", "str", "(", "epoch", ")", ")", ")", "\n", "\n", "# wrap ups", "\n", "", "logger", ".", "close", "(", ")", "\n", "print", "(", "\"Done !!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.models.enc_dec_sh_dis.ParaphraseGenerator.__init__": [[11, 37], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.GRU", "torch.GRU", "torch.Sequential", "torch.Sequential", "torch.Embedding", "torch.Embedding", "torch.LSTM", "torch.LSTM", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Threshold", "torch.Threshold", "torch.Linear", "torch.Linear", "torch.Threshold", "torch.Threshold", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.LogSoftmax", "torch.LogSoftmax"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.__init__"], ["def", "__init__", "(", "self", ",", "op", ")", ":", "\n", "\n", "        ", "super", "(", "ParaphraseGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# encoder | shared pair-wise discriminator:", "\n", "self", ".", "emb_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "op", "[", "\"vocab_sz\"", "]", ",", "op", "[", "\"emb_hid_dim\"", "]", ")", ",", "\n", "nn", ".", "Threshold", "(", "0.000001", ",", "0", ")", ",", "\n", "nn", ".", "Linear", "(", "op", "[", "\"emb_hid_dim\"", "]", ",", "op", "[", "\"emb_dim\"", "]", ")", ",", "\n", "nn", ".", "Threshold", "(", "0.000001", ",", "0", ")", ")", "\n", "self", ".", "enc_rnn", "=", "nn", ".", "GRU", "(", "op", "[", "\"emb_dim\"", "]", ",", "op", "[", "\"enc_rnn_dim\"", "]", ")", "\n", "self", ".", "enc_lin", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "op", "[", "\"enc_dropout\"", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "op", "[", "\"enc_rnn_dim\"", "]", ",", "op", "[", "\"enc_dim\"", "]", ")", ")", "\n", "\n", "# generator :", "\n", "self", ".", "gen_emb", "=", "nn", ".", "Embedding", "(", "op", "[", "\"vocab_sz\"", "]", ",", "op", "[", "\"emb_dim\"", "]", ")", "\n", "self", ".", "gen_rnn", "=", "nn", ".", "LSTM", "(", "op", "[", "\"enc_dim\"", "]", ",", "op", "[", "\"gen_rnn_dim\"", "]", ")", "\n", "self", ".", "gen_lin", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "op", "[", "\"gen_dropout\"", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "op", "[", "\"gen_rnn_dim\"", "]", ",", "op", "[", "\"vocab_sz\"", "]", ")", ",", "\n", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", ")", "\n", "\n", "# some useful constants :", "\n", "self", ".", "max_seq_len", "=", "op", "[", "\"max_seq_len\"", "]", "\n", "self", ".", "vocab_sz", "=", "op", "[", "\"vocab_sz\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.models.enc_dec_sh_dis.ParaphraseGenerator.forward": [[38, 114], ["enc_dec_sh_dis.ParaphraseGenerator.squeeze_", "enc_dec_sh_dis.ParaphraseGenerator.squeeze_", "enc_dec_sh_dis.ParaphraseGenerator.enc_lin", "enc_dec_sh_dis.ParaphraseGenerator.gen_emb", "enc_dec_sh_dis.ParaphraseGenerator.gen_rnn", "enc_dec_sh_dis.ParaphraseGenerator.gen_lin", "enc_dec_sh_dis.ParaphraseGenerator.enc_lin", "enc_dec_sh_dis.ParaphraseGenerator.enc_lin", "enc_dec_sh_dis.ParaphraseGenerator.enc_lin", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "enc_dec_sh_dis.ParaphraseGenerator.enc_lin", "enc_dec_sh_dis.ParaphraseGenerator.enc_lin", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "enc_dec_sh_dis.ParaphraseGenerator.gen_rnn", "enc_dec_sh_dis.ParaphraseGenerator.gen_lin", "words.append", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "word.t.t.t", "enc_dec_sh_dis.ParaphraseGenerator.gen_emb", "enc_dec_sh_dis.ParaphraseGenerator.enc_rnn", "enc_dec_sh_dis.ParaphraseGenerator.enc_rnn", "enc_dec_sh_dis.ParaphraseGenerator.enc_rnn", "enc_dec_sh_dis.ParaphraseGenerator.enc_rnn", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "enc_dec_sh_dis.ParaphraseGenerator.enc_rnn", "enc_dec_sh_dis.ParaphraseGenerator.enc_rnn", "enc_dec_sh_dis.ParaphraseGenerator.emb_layer", "enc_dec_sh_dis.ParaphraseGenerator.emb_layer", "enc_dec_sh_dis.ParaphraseGenerator.emb_layer", "enc_dec_sh_dis.ParaphraseGenerator.emb_layer", "enc_dec_sh_dis.ParaphraseGenerator.emb_layer", "enc_dec_sh_dis.ParaphraseGenerator.emb_layer", "misc.one_hot", "misc.one_hot", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "misc.one_hot", "misc.one_hot", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.utils.one_hot", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.utils.one_hot", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.utils.one_hot", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.utils.one_hot"], ["", "def", "forward", "(", "self", ",", "phrase", ",", "sim_phrase", "=", "None", ",", "train", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        forward pass\n\n        inputs :-\n\n        phrase : given phrase , shape = (max sequence length, batch size)\n        sim_phrase : (if train == True), shape = (max seq length, batch sz)\n        train : if true teacher forcing is used to train the module\n\n        outputs :-\n\n        out : generated paraphrase, shape = (max sequence length, batch size, )\n        enc_out : encoded generated paraphrase, shape=(batch size, enc_dim)\n        enc_sim_phrase : encoded sim_phrase, shape=(batch size, enc_dim)\n\n        \"\"\"", "\n", "\n", "if", "sim_phrase", "is", "None", ":", "\n", "            ", "sim_phrase", "=", "phrase", "\n", "\n", "", "if", "train", ":", "\n", "\n", "# encode input phrase", "\n", "            ", "enc_phrase", "=", "self", ".", "enc_lin", "(", "\n", "self", ".", "enc_rnn", "(", "\n", "self", ".", "emb_layer", "(", "utils", ".", "one_hot", "(", "phrase", ",", "self", ".", "vocab_sz", ")", ")", ")", "[", "1", "]", ")", "\n", "\n", "# generate similar phrase using teacher forcing", "\n", "emb_sim_phrase_gen", "=", "self", ".", "gen_emb", "(", "sim_phrase", ")", "\n", "out_rnn", ",", "_", "=", "self", ".", "gen_rnn", "(", "\n", "torch", ".", "cat", "(", "[", "enc_phrase", ",", "emb_sim_phrase_gen", "[", ":", "-", "1", ",", ":", "]", "]", ",", "dim", "=", "0", ")", ")", "\n", "out", "=", "self", ".", "gen_lin", "(", "out_rnn", ")", "\n", "\n", "# encode similar phrase and generated output", "\n", "# (propagated from shared discriminator) to calculate", "\n", "# pair-wise discriminator loss", "\n", "enc_sim_phrase", "=", "self", ".", "enc_lin", "(", "\n", "self", ".", "enc_rnn", "(", "\n", "self", ".", "emb_layer", "(", "utils", ".", "one_hot", "(", "sim_phrase", ",", "\n", "self", ".", "vocab_sz", ")", ")", ")", "[", "1", "]", ")", "\n", "enc_out", "=", "self", ".", "enc_lin", "(", "\n", "self", ".", "enc_rnn", "(", "self", ".", "emb_layer", "(", "torch", ".", "exp", "(", "out", ")", ")", ")", "[", "1", "]", ")", "\n", "\n", "", "else", ":", "\n", "\n", "# encode input phrase", "\n", "            ", "enc_phrase", "=", "self", ".", "enc_lin", "(", "\n", "self", ".", "enc_rnn", "(", "\n", "self", ".", "emb_layer", "(", "utils", ".", "one_hot", "(", "phrase", ",", "self", ".", "vocab_sz", ")", ")", ")", "[", "1", "]", ")", "\n", "\n", "# generate similar phrase using teacher forcing", "\n", "words", "=", "[", "]", "\n", "h", "=", "None", "\n", "for", "__", "in", "range", "(", "self", ".", "max_seq_len", ")", ":", "\n", "                ", "word", ",", "h", "=", "self", ".", "gen_rnn", "(", "enc_phrase", ",", "hx", "=", "h", ")", "\n", "word", "=", "self", ".", "gen_lin", "(", "word", ")", "\n", "words", ".", "append", "(", "word", ")", "\n", "word", "=", "torch", ".", "multinomial", "(", "torch", ".", "exp", "(", "word", "[", "0", "]", ")", ",", "1", ")", "\n", "word", "=", "word", ".", "t", "(", ")", "\n", "enc_phrase", "=", "self", ".", "gen_emb", "(", "word", ")", "\n", "", "out", "=", "torch", ".", "cat", "(", "words", ",", "dim", "=", "0", ")", "\n", "\n", "# encode similar phrase and generated output", "\n", "# (propagated from shared discriminator) to calculate", "\n", "# pair-wise discriminator loss", "\n", "enc_sim_phrase", "=", "self", ".", "enc_lin", "(", "\n", "self", ".", "enc_rnn", "(", "\n", "self", ".", "emb_layer", "(", "utils", ".", "one_hot", "(", "sim_phrase", ",", "\n", "self", ".", "vocab_sz", ")", ")", ")", "[", "1", "]", ")", "\n", "enc_out", "=", "self", ".", "enc_lin", "(", "\n", "self", ".", "enc_rnn", "(", "self", ".", "emb_layer", "(", "torch", ".", "exp", "(", "out", ")", ")", ")", "[", "1", "]", ")", "\n", "\n", "", "enc_out", ".", "squeeze_", "(", "0", ")", "\n", "enc_sim_phrase", ".", "squeeze_", "(", "0", ")", "\n", "return", "out", ",", "enc_out", ",", "enc_sim_phrase", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.models.enc_dec_dis.ParaphraseGenerator.__init__": [[11, 49], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.GRU", "torch.GRU", "torch.Sequential", "torch.Sequential", "torch.Embedding", "torch.Embedding", "torch.LSTM", "torch.LSTM", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.GRU", "torch.GRU", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Threshold", "torch.Threshold", "torch.Linear", "torch.Linear", "torch.Threshold", "torch.Threshold", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.LogSoftmax", "torch.LogSoftmax", "torch.Linear", "torch.Linear", "torch.Threshold", "torch.Threshold", "torch.Linear", "torch.Linear", "torch.Threshold", "torch.Threshold", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.__init__"], ["def", "__init__", "(", "self", ",", "op", ")", ":", "\n", "\n", "        ", "super", "(", "ParaphraseGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# encoder :", "\n", "self", ".", "emb_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "op", "[", "\"vocab_sz\"", "]", ",", "op", "[", "\"emb_hid_dim\"", "]", ")", ",", "\n", "nn", ".", "Threshold", "(", "0.000001", ",", "0", ")", ",", "\n", "nn", ".", "Linear", "(", "op", "[", "\"emb_hid_dim\"", "]", ",", "op", "[", "\"emb_dim\"", "]", ")", ",", "\n", "nn", ".", "Threshold", "(", "0.000001", ",", "0", ")", ")", "\n", "self", ".", "enc_rnn", "=", "nn", ".", "GRU", "(", "op", "[", "\"emb_dim\"", "]", ",", "op", "[", "\"enc_rnn_dim\"", "]", ")", "\n", "self", ".", "enc_lin", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "op", "[", "\"enc_dropout\"", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "op", "[", "\"enc_rnn_dim\"", "]", ",", "op", "[", "\"enc_dim\"", "]", ")", ")", "\n", "\n", "# generator :", "\n", "self", ".", "gen_emb", "=", "nn", ".", "Embedding", "(", "op", "[", "\"vocab_sz\"", "]", ",", "op", "[", "\"emb_dim\"", "]", ")", "\n", "self", ".", "gen_rnn", "=", "nn", ".", "LSTM", "(", "op", "[", "\"enc_dim\"", "]", ",", "op", "[", "\"gen_rnn_dim\"", "]", ")", "\n", "self", ".", "gen_lin", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "op", "[", "\"gen_dropout\"", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "op", "[", "\"gen_rnn_dim\"", "]", ",", "op", "[", "\"vocab_sz\"", "]", ")", ",", "\n", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", ")", "\n", "\n", "# pair-wise discriminator :", "\n", "self", ".", "dis_emb_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "op", "[", "\"vocab_sz\"", "]", ",", "op", "[", "\"emb_hid_dim\"", "]", ")", ",", "\n", "nn", ".", "Threshold", "(", "0.000001", ",", "0", ")", ",", "\n", "nn", ".", "Linear", "(", "op", "[", "\"emb_hid_dim\"", "]", ",", "op", "[", "\"emb_dim\"", "]", ")", ",", "\n", "nn", ".", "Threshold", "(", "0.000001", ",", "0", ")", ",", "\n", ")", "\n", "self", ".", "dis_rnn", "=", "nn", ".", "GRU", "(", "op", "[", "\"emb_dim\"", "]", ",", "op", "[", "\"enc_rnn_dim\"", "]", ")", "\n", "self", ".", "dis_lin", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "op", "[", "\"enc_dropout\"", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "op", "[", "\"enc_rnn_dim\"", "]", ",", "op", "[", "\"enc_dim\"", "]", ")", ")", "\n", "\n", "# some useful constants :", "\n", "self", ".", "max_seq_len", "=", "op", "[", "\"max_seq_len\"", "]", "\n", "self", ".", "vocab_sz", "=", "op", "[", "\"vocab_sz\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.models.enc_dec_dis.ParaphraseGenerator.forward": [[50, 124], ["enc_dec_dis.ParaphraseGenerator.squeeze_", "enc_dec_dis.ParaphraseGenerator.squeeze_", "enc_dec_dis.ParaphraseGenerator.enc_lin", "enc_dec_dis.ParaphraseGenerator.gen_emb", "enc_dec_dis.ParaphraseGenerator.gen_rnn", "enc_dec_dis.ParaphraseGenerator.gen_lin", "enc_dec_dis.ParaphraseGenerator.dis_lin", "enc_dec_dis.ParaphraseGenerator.dis_lin", "enc_dec_dis.ParaphraseGenerator.enc_lin", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "enc_dec_dis.ParaphraseGenerator.dis_lin", "enc_dec_dis.ParaphraseGenerator.dis_lin", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "enc_dec_dis.ParaphraseGenerator.gen_rnn", "enc_dec_dis.ParaphraseGenerator.gen_lin", "words.append", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "word.t.t.t", "enc_dec_dis.ParaphraseGenerator.gen_emb", "enc_dec_dis.ParaphraseGenerator.enc_rnn", "enc_dec_dis.ParaphraseGenerator.dis_rnn", "enc_dec_dis.ParaphraseGenerator.dis_rnn", "enc_dec_dis.ParaphraseGenerator.enc_rnn", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "enc_dec_dis.ParaphraseGenerator.dis_rnn", "enc_dec_dis.ParaphraseGenerator.dis_rnn", "enc_dec_dis.ParaphraseGenerator.emb_layer", "enc_dec_dis.ParaphraseGenerator.dis_emb_layer", "enc_dec_dis.ParaphraseGenerator.dis_emb_layer", "enc_dec_dis.ParaphraseGenerator.emb_layer", "enc_dec_dis.ParaphraseGenerator.dis_emb_layer", "enc_dec_dis.ParaphraseGenerator.dis_emb_layer", "misc.one_hot", "misc.one_hot", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "misc.one_hot", "misc.one_hot", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.utils.one_hot", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.utils.one_hot", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.utils.one_hot", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.utils.one_hot"], ["", "def", "forward", "(", "self", ",", "phrase", ",", "sim_phrase", "=", "None", ",", "train", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        forward pass\n\n        inputs :-\n\n        phrase : given phrase , shape = (max sequence length, batch size)\n        sim_phrase : (if train == True), shape = (max seq length, batch sz)\n        train : if true teacher forcing is used to train the module\n\n        outputs :-\n\n        out : generated paraphrase, shape = (max sequence length, batch size, )\n        enc_out : encoded generated paraphrase, shape=(batch size, enc_dim)\n        enc_sim_phrase : encoded sim_phrase, shape=(batch size, enc_dim)\n\n        \"\"\"", "\n", "\n", "if", "sim_phrase", "is", "None", ":", "\n", "            ", "sim_phrase", "=", "phrase", "\n", "\n", "", "if", "train", ":", "\n", "\n", "# encode input phrase", "\n", "            ", "enc_phrase", "=", "self", ".", "enc_lin", "(", "\n", "self", ".", "enc_rnn", "(", "\n", "self", ".", "emb_layer", "(", "utils", ".", "one_hot", "(", "phrase", ",", "self", ".", "vocab_sz", ")", ")", ")", "[", "1", "]", ")", "\n", "\n", "# generate similar phrase using teacher forcing", "\n", "emb_sim_phrase_gen", "=", "self", ".", "gen_emb", "(", "sim_phrase", ")", "\n", "out_rnn", ",", "_", "=", "self", ".", "gen_rnn", "(", "\n", "torch", ".", "cat", "(", "[", "enc_phrase", ",", "emb_sim_phrase_gen", "[", ":", "-", "1", ",", ":", "]", "]", ",", "dim", "=", "0", ")", ")", "\n", "out", "=", "self", ".", "gen_lin", "(", "out_rnn", ")", "\n", "\n", "# propagated from shared discriminator to calculate", "\n", "# pair-wise discriminator loss", "\n", "enc_sim_phrase", "=", "self", ".", "dis_lin", "(", "\n", "self", ".", "dis_rnn", "(", "\n", "self", ".", "dis_emb_layer", "(", "utils", ".", "one_hot", "(", "sim_phrase", ",", "\n", "self", ".", "vocab_sz", ")", ")", ")", "[", "1", "]", ")", "\n", "enc_out", "=", "self", ".", "dis_lin", "(", "\n", "self", ".", "dis_rnn", "(", "self", ".", "dis_emb_layer", "(", "torch", ".", "exp", "(", "out", ")", ")", ")", "[", "1", "]", ")", "\n", "\n", "", "else", ":", "\n", "\n", "# encode input phrase", "\n", "            ", "enc_phrase", "=", "self", ".", "enc_lin", "(", "\n", "self", ".", "enc_rnn", "(", "\n", "self", ".", "emb_layer", "(", "utils", ".", "one_hot", "(", "phrase", ",", "self", ".", "vocab_sz", ")", ")", ")", "[", "1", "]", ")", "\n", "\n", "# generate similar phrase using teacher forcing", "\n", "words", "=", "[", "]", "\n", "h", "=", "None", "\n", "for", "__", "in", "range", "(", "self", ".", "max_seq_len", ")", ":", "\n", "                ", "word", ",", "h", "=", "self", ".", "gen_rnn", "(", "enc_phrase", ",", "hx", "=", "h", ")", "\n", "word", "=", "self", ".", "gen_lin", "(", "word", ")", "\n", "words", ".", "append", "(", "word", ")", "\n", "word", "=", "torch", ".", "multinomial", "(", "torch", ".", "exp", "(", "word", "[", "0", "]", ")", ",", "1", ")", "\n", "word", "=", "word", ".", "t", "(", ")", "\n", "enc_phrase", "=", "self", ".", "gen_emb", "(", "word", ")", "\n", "", "out", "=", "torch", ".", "cat", "(", "words", ",", "dim", "=", "0", ")", "\n", "\n", "# propagated from shared discriminator to calculate", "\n", "# pair-wise discriminator loss", "\n", "enc_sim_phrase", "=", "self", ".", "dis_lin", "(", "\n", "self", ".", "dis_rnn", "(", "\n", "self", ".", "dis_emb_layer", "(", "utils", ".", "one_hot", "(", "sim_phrase", ",", "\n", "self", ".", "vocab_sz", ")", ")", ")", "[", "1", "]", ")", "\n", "enc_out", "=", "self", ".", "dis_lin", "(", "\n", "self", ".", "dis_rnn", "(", "self", ".", "dis_emb_layer", "(", "torch", ".", "exp", "(", "out", ")", ")", ")", "[", "1", "]", ")", "\n", "\n", "", "enc_out", ".", "squeeze_", "(", "0", ")", "\n", "enc_sim_phrase", ".", "squeeze_", "(", "0", ")", "\n", "return", "out", ",", "enc_out", ",", "enc_sim_phrase", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.tokenize": [[26, 28], ["re.split"], "function", ["None"], ["def", "tokenize", "(", "sentence", ")", ":", "\n", "    ", "return", "[", "i", "for", "i", "in", "re", ".", "split", "(", "r\"([-.\\\"',:? !\\$#@~()*&\\^%;\\[\\]/\\\\\\+<>\\n=])\"", ",", "sentence", ")", "if", "i", "!=", "''", "and", "i", "!=", "' '", "and", "i", "!=", "'\\n'", "]", ";", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.prepro_question": [[29, 45], ["print", "enumerate", "nltk.tokenize.word_tokenize", "prepro_quora.tokenize", "print", "sys.stdout.write", "sys.stdout.flush", "len", "len"], "function", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.tokenize"], ["", "def", "prepro_question", "(", "imgs", ",", "params", ")", ":", "\n", "\n", "# preprocess all the question", "\n", "    ", "print", "(", "'example processed tokens:'", ")", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "        ", "s", "=", "img", "[", "'question'", "]", "\n", "if", "params", "[", "'token_method'", "]", "==", "'nltk'", ":", "\n", "            ", "txt", "=", "word_tokenize", "(", "s", ")", "\n", "", "else", ":", "\n", "            ", "txt", "=", "tokenize", "(", "s", ")", "\n", "", "img", "[", "'processed_tokens'", "]", "=", "txt", "\n", "if", "i", "<", "10", ":", "print", "(", "txt", ")", "\n", "if", "i", "%", "1000", "==", "0", ":", "\n", "            ", "sys", ".", "stdout", ".", "write", "(", "\"processing %d/%d (%.2f%% done)   \\r\"", "%", "(", "i", ",", "len", "(", "imgs", ")", ",", "i", "*", "100.0", "/", "len", "(", "imgs", ")", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.prepro_question1": [[46, 63], ["print", "enumerate", "nltk.tokenize.word_tokenize", "prepro_quora.tokenize", "print", "sys.stdout.write", "sys.stdout.flush", "len", "len"], "function", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.tokenize"], ["", "def", "prepro_question1", "(", "imgs", ",", "params", ")", ":", "\n", "\n", "# preprocess all the question", "\n", "    ", "print", "(", "'example processed tokens:'", ")", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "        ", "s", "=", "img", "[", "'question1'", "]", "\n", "if", "params", "[", "'token_method'", "]", "==", "'nltk'", ":", "\n", "            ", "txt_c", "=", "word_tokenize", "(", "s", ")", "\n", "", "else", ":", "\n", "            ", "txt_c", "=", "tokenize", "(", "s", ")", "\n", "\n", "", "img", "[", "'processed_tokens_caption'", "]", "=", "txt_c", "#this name is a bit misleading, it is for paraphrase questions actually.", "\n", "if", "i", "<", "10", ":", "print", "(", "txt_c", ")", "\n", "if", "i", "%", "1000", "==", "0", ":", "\n", "            ", "sys", ".", "stdout", ".", "write", "(", "\"processing %d/%d (%.2f%% done)   \\r\"", "%", "(", "i", ",", "len", "(", "imgs", ")", ",", "i", "*", "100.0", "/", "len", "(", "imgs", ")", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.build_vocab_question": [[65, 107], ["sorted", "print", "print", "sum", "print", "sum", "print", "print", "print", "print", "vocab.append", "counts.itervalues", "map", "counts.iteritems", "counts.iteritems", "counts.get", "counts.iteritems", "len", "len", "len", "len", "counts.get", "counts.get", "len"], "function", ["None"], ["", "def", "build_vocab_question", "(", "imgs5", ",", "params", ")", ":", "#imgs1,imgs2,imgs3,imgs4,imgs5,imgs6,imgs7,imgs8,", "\n", "# build vocabulary for question and answers.", "\n", "\n", "    ", "count_thr", "=", "params", "[", "'word_count_threshold'", "]", "\n", "\n", "# count up the number of words", "\n", "counts", "=", "{", "}", "\n", "\n", "for", "img", "in", "imgs5", ":", "\n", "        ", "for", "w", "in", "img", "[", "'processed_tokens'", "]", ":", "\n", "            ", "counts", "[", "w", "]", "=", "counts", ".", "get", "(", "w", ",", "0", ")", "+", "1", "\n", "\n", "", "", "cw", "=", "sorted", "(", "[", "(", "count", ",", "w", ")", "for", "w", ",", "count", "in", "counts", ".", "iteritems", "(", ")", "]", ",", "reverse", "=", "True", ")", "\n", "print", "(", "'top words and their counts:'", ")", "\n", "print", "(", "'\\n'", ".", "join", "(", "map", "(", "str", ",", "cw", "[", ":", "20", "]", ")", ")", ")", "\n", "\n", "# print some stats", "\n", "total_words", "=", "sum", "(", "counts", ".", "itervalues", "(", ")", ")", "\n", "print", "(", "'total words:'", ",", "total_words", ")", "\n", "bad_words", "=", "[", "w", "for", "w", ",", "n", "in", "counts", ".", "iteritems", "(", ")", "if", "n", "<=", "count_thr", "]", "\n", "vocab", "=", "[", "w", "for", "w", ",", "n", "in", "counts", ".", "iteritems", "(", ")", "if", "n", ">", "count_thr", "]", "# will incorpate vocab for  both caption and question", "\n", "bad_count", "=", "sum", "(", "counts", "[", "w", "]", "for", "w", "in", "bad_words", ")", "\n", "print", "(", "'number of bad words: %d/%d = %.2f%%'", "%", "(", "len", "(", "bad_words", ")", ",", "len", "(", "counts", ")", ",", "len", "(", "bad_words", ")", "*", "100.0", "/", "len", "(", "counts", ")", ")", ")", "\n", "print", "(", "'number of words in vocab would be %d'", "%", "(", "len", "(", "vocab", ")", ",", ")", ")", "\n", "print", "(", "'number of UNKs: %d/%d = %.2f%%'", "%", "(", "bad_count", ",", "total_words", ",", "bad_count", "*", "100.0", "/", "total_words", ")", ")", "\n", "\n", "\n", "# lets now produce the final annotation", "\n", "# additional special UNK token we will use below to map infrequent words to", "\n", "print", "(", "'inserting the special UNK token'", ")", "\n", "vocab", ".", "append", "(", "'UNK'", ")", "\n", "\n", "\n", "for", "img", "in", "imgs5", ":", "\n", "        ", "txt", "=", "img", "[", "'processed_tokens'", "]", "\n", "question", "=", "[", "w", "if", "counts", ".", "get", "(", "w", ",", "0", ")", ">", "count_thr", "else", "'UNK'", "for", "w", "in", "txt", "]", "\n", "img", "[", "'final_question'", "]", "=", "question", "\n", "txt_c", "=", "img", "[", "'processed_tokens_caption'", "]", "\n", "caption", "=", "[", "w", "if", "counts", ".", "get", "(", "w", ",", "0", ")", ">", "count_thr", "else", "'UNK'", "for", "w", "in", "txt_c", "]", "\n", "img", "[", "'final_caption'", "]", "=", "caption", "\n", "\n", "", "return", "imgs5", ",", "vocab", "#, imgs1,imgs2,imgs3,imgs4,imgs5,imgs6,imgs7,imgs8, vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.apply_vocab_question": [[108, 119], ["wtoi.get", "len", "len"], "function", ["None"], ["", "def", "apply_vocab_question", "(", "imgs", ",", "wtoi", ")", ":", "## this is for val or test question and caption ", "\n", "# apply the vocab on test.", "\n", "    ", "for", "img", "in", "imgs", ":", "\n", "        ", "txt", "=", "img", "[", "'processed_tokens'", "]", "\n", "question", "=", "[", "w", "if", "wtoi", ".", "get", "(", "w", ",", "len", "(", "wtoi", ")", "+", "1", ")", "!=", "(", "len", "(", "wtoi", ")", "+", "1", ")", "else", "'UNK'", "for", "w", "in", "txt", "]", "\n", "img", "[", "'final_question'", "]", "=", "question", "\n", "txt_c", "=", "img", "[", "'processed_tokens_caption'", "]", "\n", "caption", "=", "[", "w", "if", "w", "in", "wtoi", "else", "'UNK'", "for", "w", "in", "txt_c", "]", "\n", "img", "[", "'final_caption'", "]", "=", "caption", "\n", "\n", "", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.encode_question2": [[120, 147], ["len", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "min", "min", "enumerate", "enumerate", "len", "len"], "function", ["None"], ["", "def", "encode_question2", "(", "imgs", ",", "params", ",", "wtoi", ")", ":", "\n", "\n", "    ", "max_length", "=", "params", "[", "'max_length'", "]", "\n", "N", "=", "len", "(", "imgs", ")", "\n", "\n", "label_arrays", "=", "np", ".", "zeros", "(", "(", "N", ",", "max_length", ")", ",", "dtype", "=", "'uint32'", ")", "\n", "label_length", "=", "np", ".", "zeros", "(", "N", ",", "dtype", "=", "'uint32'", ")", "\n", "question_id", "=", "np", ".", "zeros", "(", "N", ",", "dtype", "=", "'uint32'", ")", "\n", "question_counter", "=", "0", "\n", "\n", "caption_arrays", "=", "np", ".", "zeros", "(", "(", "N", ",", "max_length", ")", ",", "dtype", "=", "'uint32'", ")", "# will store encoding caption words", "\n", "caption_length", "=", "np", ".", "zeros", "(", "N", ",", "dtype", "=", "'uint32'", ")", "# will store encoding caption words", "\n", "\n", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "        ", "question_id", "[", "question_counter", "]", "=", "img", "[", "'id'", "]", "#unique_id", "\n", "label_length", "[", "question_counter", "]", "=", "min", "(", "max_length", ",", "len", "(", "img", "[", "'final_question'", "]", ")", ")", "# record the length of this question sequence", "\n", "caption_length", "[", "question_counter", "]", "=", "min", "(", "max_length", ",", "len", "(", "img", "[", "'final_caption'", "]", ")", ")", "# record the length of this caption sequence        ", "\n", "question_counter", "+=", "1", "\n", "for", "k", ",", "w", "in", "enumerate", "(", "img", "[", "'final_question'", "]", ")", ":", "\n", "            ", "if", "k", "<", "max_length", ":", "\n", "                ", "label_arrays", "[", "i", ",", "k", "]", "=", "wtoi", "[", "w", "]", "\n", "", "", "for", "k", ",", "w", "in", "enumerate", "(", "img", "[", "'final_caption'", "]", ")", ":", "## this is for caption", "\n", "            ", "if", "k", "<", "max_length", ":", "\n", "                ", "caption_arrays", "[", "i", ",", "k", "]", "=", "wtoi", "[", "w", "]", "\n", "\n", "", "", "", "return", "label_arrays", ",", "label_length", ",", "question_id", ",", "caption_arrays", ",", "caption_length", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.main": [[149, 216], ["json.load", "json.load", "prepro_quora.prepro_question", "prepro_quora.prepro_question", "prepro_quora.prepro_question1", "prepro_quora.prepro_question1", "prepro_quora.build_vocab_question", "prepro_quora.encode_question2", "prepro_quora.apply_vocab_question", "prepro_quora.encode_question2", "len", "h5py.File", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.close", "print", "json.dump", "print", "open", "open", "open", "enumerate", "enumerate"], "function", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.prepro_question", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.prepro_question", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.prepro_question1", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.prepro_question1", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.build_vocab_question", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.encode_question2", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.apply_vocab_question", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.prepro_quora.encode_question2"], ["", "def", "main", "(", "params", ")", ":", "\n", "\n", "    ", "imgs_train5", "=", "json", ".", "load", "(", "open", "(", "params", "[", "'input_train_json5'", "]", ",", "'r'", ")", ")", "\n", "imgs_test5", "=", "json", ".", "load", "(", "open", "(", "params", "[", "'input_test_json5'", "]", ",", "'r'", ")", ")", "\n", "\n", "\n", "\n", "##seed(123) # make reproducible", "\n", "##shuffle(imgs_train) # shuffle the order", "\n", "\n", "\n", "# tokenization and preprocessing training question", "\n", "imgs_train5", "=", "prepro_question", "(", "imgs_train5", ",", "params", ")", "\n", "# tokenization and preprocessing test question", "\n", "imgs_test5", "=", "prepro_question", "(", "imgs_test5", ",", "params", ")", "\n", "\n", "# tokenization and preprocessing training paraphrase question", "\n", "imgs_train5", "=", "prepro_question1", "(", "imgs_train5", ",", "params", ")", "\n", "# tokenization and preprocessing test paraphrase question", "\n", "imgs_test5", "=", "prepro_question1", "(", "imgs_test5", ",", "params", ")", "\n", "\n", "\n", "# create the vocab for question", "\n", "imgs_train5", ",", "vocab", "=", "build_vocab_question", "(", "imgs_train5", ",", "params", ")", "\n", "\n", "\n", "itow", "=", "{", "i", "+", "1", ":", "w", "for", "i", ",", "w", "in", "enumerate", "(", "vocab", ")", "}", "# a 1-indexed vocab translation table", "\n", "wtoi", "=", "{", "w", ":", "i", "+", "1", "for", "i", ",", "w", "in", "enumerate", "(", "vocab", ")", "}", "# inverse table", "\n", "\n", "\n", "ques_train5", ",", "ques_length_train5", ",", "question_id_train5", ",", "cap_train5", ",", "cap_length_train5", "=", "encode_question2", "(", "imgs_train5", ",", "params", ",", "wtoi", ")", "\n", "\n", "\n", "imgs_test5", "=", "apply_vocab_question", "(", "imgs_test5", ",", "wtoi", ")", "\n", "\n", "\n", "ques_test5", ",", "ques_length_test5", ",", "question_id_test5", ",", "cap_test5", ",", "cap_length_test5", "=", "encode_question2", "(", "imgs_test5", ",", "params", ",", "wtoi", ")", "\n", "\n", "\n", "\n", "\n", "N", "=", "len", "(", "imgs_train5", ")", "\n", "f", "=", "h5py", ".", "File", "(", "params", "[", "'output_h55'", "]", ",", "\"w\"", ")", "\n", "## for train information", "\n", "f", ".", "create_dataset", "(", "\"ques_train\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "ques_train5", ")", "\n", "f", ".", "create_dataset", "(", "\"ques_length_train\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "ques_length_train5", ")", "\n", "f", ".", "create_dataset", "(", "\"ques_cap_id_train\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "question_id_train5", ")", "#this is actually the ques_cap_id", "\n", "f", ".", "create_dataset", "(", "\"ques1_train\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "cap_train5", ")", "\n", "f", ".", "create_dataset", "(", "\"ques1_length_train\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "cap_length_train5", ")", "\n", "\n", "\n", "## for test information", "\n", "f", ".", "create_dataset", "(", "\"ques_test\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "ques_test5", ")", "\n", "f", ".", "create_dataset", "(", "\"ques_length_test\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "ques_length_test5", ")", "\n", "f", ".", "create_dataset", "(", "\"ques_cap_id_test\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "question_id_test5", ")", "\n", "f", ".", "create_dataset", "(", "\"ques1_test\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "cap_test5", ")", "\n", "f", ".", "create_dataset", "(", "\"ques1_length_test\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "cap_length_test5", ")", "\n", "\n", "f", ".", "close", "(", ")", "\n", "print", "(", "'wrote '", ",", "params", "[", "'output_h55'", "]", ")", "\n", "\n", "# create output json file", "\n", "\n", "out", "=", "{", "}", "\n", "out", "[", "'ix_to_word'", "]", "=", "itow", "# encode the (1-indexed) vocab", "\n", "json", ".", "dump", "(", "out", ",", "open", "(", "params", "[", "'output_json5'", "]", ",", "'w'", ")", ")", "\n", "print", "(", "'wrote '", ",", "params", "[", "'output_json5'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.prepro.quora_prepro.main": [[5, 77], ["print", "json.dump", "print", "json.dump", "print", "json.dump", "open", "csv.reader", "len", "open", "len", "open", "len", "open", "out.append", "outtest.append", "outval.append"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "\t", "out", "=", "[", "]", "\n", "outtest", "=", "[", "]", "\n", "outval", "=", "[", "]", "\n", "with", "open", "(", "'../data/quora_duplicate_questions.tsv'", ",", "'rb'", ")", "as", "tsvin", ":", "\n", "\t\t", "tsvin", "=", "csv", ".", "reader", "(", "tsvin", ",", "delimiter", "=", "'\\t'", ")", "#read the tsv file of quora question pairs", "\n", "count0", "=", "1", "\n", "count1", "=", "1", "\n", "counter", "=", "1", "\n", "for", "row", "in", "tsvin", ":", "\n", "\t\t\t", "counter", "=", "counter", "+", "1", "\n", "if", "row", "[", "5", "]", "==", "'0'", "and", "row", "[", "4", "]", "[", "-", "1", ":", "]", "==", "'?'", ":", "#the 6th entry in every row has value 0 or 1 and it represents paraphrases if that value is 1", "\n", "\t\t\t\t", "count0", "=", "count0", "+", "1", "\n", "", "elif", "row", "[", "5", "]", "==", "'1'", "and", "row", "[", "4", "]", "[", "-", "1", ":", "]", "==", "'?'", ":", "\n", "\t\t\t\t", "count1", "=", "count1", "+", "1", "\n", "if", "count1", ">", "1", "and", "count1", "<", "100002", ":", "#taking the starting 1 lakh pairs as train set. Change this to 50002 for taking staring 50 k examples as train set", "\n", "# get the question and unique id from the tsv file", "\n", "\t\t\t\t\t", "quesid", "=", "row", "[", "1", "]", "#first question id", "\n", "ques", "=", "row", "[", "3", "]", "#first question", "\n", "img_id", "=", "row", "[", "0", "]", "#unique id for every pair", "\n", "ques1", "=", "row", "[", "4", "]", "#paraphrase question", "\n", "quesid1", "=", "row", "[", "2", "]", "#paraphrase question id\t\t\t\t", "\n", "\n", "# set the parameters of json file for writing ", "\n", "jimg", "=", "{", "}", "\n", "\n", "jimg", "[", "'question'", "]", "=", "ques", "\n", "jimg", "[", "'question1'", "]", "=", "ques1", "\n", "jimg", "[", "'ques_id'", "]", "=", "quesid", "\n", "jimg", "[", "'ques_id1'", "]", "=", "quesid1", "\n", "jimg", "[", "'id'", "]", "=", "img_id", "\n", "\n", "out", ".", "append", "(", "jimg", ")", "\n", "\n", "", "elif", "count1", ">", "100001", "and", "count1", "<", "130002", ":", "#next 30k as the test set acc to https://arxiv.org/pdf/1711.00279.pdf", "\n", "\t\t\t\t\t", "quesid", "=", "row", "[", "1", "]", "\n", "ques", "=", "row", "[", "3", "]", "\n", "img_id", "=", "row", "[", "0", "]", "\n", "ques1", "=", "row", "[", "4", "]", "\n", "quesid1", "=", "row", "[", "2", "]", "\n", "\n", "jimg", "=", "{", "}", "\n", "\n", "jimg", "[", "'question'", "]", "=", "ques", "\n", "jimg", "[", "'question1'", "]", "=", "ques1", "\n", "jimg", "[", "'ques_id'", "]", "=", "quesid", "\n", "jimg", "[", "'ques_id1'", "]", "=", "quesid1", "\n", "jimg", "[", "'id'", "]", "=", "img_id", "\n", "\n", "outtest", ".", "append", "(", "jimg", ")", "\n", "", "else", ":", "#rest as val", "\n", "\t\t\t\t\t", "quesid", "=", "row", "[", "1", "]", "\n", "ques", "=", "row", "[", "3", "]", "\n", "img_id", "=", "row", "[", "0", "]", "\n", "ques1", "=", "row", "[", "4", "]", "\n", "quesid1", "=", "row", "[", "2", "]", "\n", "\n", "jimg", "=", "{", "}", "\n", "jimg", "[", "'question'", "]", "=", "ques", "\n", "jimg", "[", "'question1'", "]", "=", "ques1", "\n", "jimg", "[", "'ques_id'", "]", "=", "quesid", "\n", "jimg", "[", "'ques_id1'", "]", "=", "quesid1", "\n", "jimg", "[", "'id'", "]", "=", "img_id", "\n", "\n", "outval", ".", "append", "(", "jimg", ")", "\n", "#write the json files for train test and val", "\n", "", "", "", "", "print", "(", "len", "(", "out", ")", ")", "\n", "json", ".", "dump", "(", "out", ",", "open", "(", "'../data/quora_raw_train.json'", ",", "'w'", ")", ")", "\n", "print", "(", "len", "(", "outtest", ")", ")", "\n", "json", ".", "dump", "(", "outtest", ",", "open", "(", "'../data/quora_raw_test.json'", ",", "'w'", ")", ")", "\n", "print", "(", "len", "(", "outval", ")", ")", "\n", "json", ".", "dump", "(", "outval", ",", "open", "(", "'../data/quora_raw_val.json'", ",", "'w'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.train_util.getObjsForScores": [[9, 19], ["coco", "coco", "range", "range", "len", "len"], "function", ["None"], ["def", "getObjsForScores", "(", "real_sents", ",", "pred_sents", ")", ":", "\n", "    ", "class", "coco", ":", "\n", "        ", "def", "__init__", "(", "self", ",", "sents", ")", ":", "\n", "            ", "self", ".", "sents", "=", "sents", "\n", "self", ".", "imgToAnns", "=", "[", "[", "{", "'caption'", ":", "sents", "[", "i", "]", "}", "]", "for", "i", "in", "range", "(", "len", "(", "sents", ")", ")", "]", "\n", "\n", "", "def", "getImgIds", "(", "self", ")", ":", "\n", "            ", "return", "[", "i", "for", "i", "in", "range", "(", "len", "(", "self", ".", "sents", ")", ")", "]", "\n", "\n", "", "", "return", "coco", "(", "real_sents", ")", ",", "coco", "(", "pred_sents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.train_util.evaluate_scores": [[21, 33], ["train_util.getObjsForScores", "pycocoevalcap.eval.COCOEvalCap", "pycocoevalcap.eval.COCOEvalCap.evaluate"], "function", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.train_util.getObjsForScores", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.pycocoevalcap.eval.COCOEvalCap.evaluate"], ["", "def", "evaluate_scores", "(", "s1", ",", "s2", ")", ":", "\n", "\n", "    ", "'''\n    calculates scores and return the dict with score_name and value\n    '''", "\n", "coco", ",", "cocoRes", "=", "getObjsForScores", "(", "s1", ",", "s2", ")", "\n", "\n", "evalObj", "=", "COCOEvalCap", "(", "coco", ",", "cocoRes", ")", "\n", "\n", "evalObj", ".", "evaluate", "(", ")", "\n", "\n", "return", "evalObj", ".", "eval", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.train_util.dump_samples": [[35, 42], ["open", "zip", "open.close", "open.write"], "function", ["None"], ["", "def", "dump_samples", "(", "ph", ",", "pph", ",", "gpph", ",", "file_name", ")", ":", "\n", "\n", "    ", "file", "=", "open", "(", "file_name", ",", "\"w\"", ")", "\n", "\n", "for", "r", ",", "s", ",", "t", "in", "zip", "(", "ph", ",", "pph", ",", "gpph", ")", ":", "\n", "        ", "file", ".", "write", "(", "\"ph : \"", "+", "r", "+", "\"\\npph : \"", "+", "s", "+", "\"\\ngpph : \"", "+", "t", "+", "'\\n\\n'", ")", "\n", "", "file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.train_util.save_model": [[64, 73], ["torch.save", "torch.save", "model.state_dict", "model_opt.state_dict"], "function", ["None"], ["", "def", "save_model", "(", "model", ",", "model_opt", ",", "epoch", ",", "save_file", ")", ":", "\n", "\n", "    ", "checkpoint", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'model_opt'", ":", "model_opt", ".", "state_dict", "(", ")", "\n", "}", "\n", "\n", "torch", ".", "save", "(", "checkpoint", ",", "save_file", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.decode_sequence": [[5, 30], ["range", "range", "out.append", "seq.size", "seq.size", "int", "print", "ix.item", "str", "ix.item", "int", "len", "ix.item"], "function", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.size"], ["def", "decode_sequence", "(", "ix_to_word", ",", "seq", ")", ":", "\n", "    ", "N", ",", "D", "=", "seq", ".", "size", "(", ")", "[", "0", "]", ",", "seq", ".", "size", "(", ")", "[", "1", "]", "\n", "out", "=", "[", "]", "\n", "EOS_flag", "=", "False", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "        ", "txt", "=", "''", "\n", "for", "j", "in", "range", "(", "D", ")", ":", "\n", "            ", "ix", "=", "seq", "[", "i", ",", "j", "]", "\n", "if", "int", "(", "ix", ".", "item", "(", ")", ")", "not", "in", "ix_to_word", ":", "\n", "                ", "print", "(", "\"UNK token \"", ",", "str", "(", "ix", ".", "item", "(", ")", ")", ")", "\n", "word", "=", "ix_to_word", "[", "len", "(", "ix_to_word", ")", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "word", "=", "ix_to_word", "[", "int", "(", "ix", ".", "item", "(", ")", ")", "]", "\n", "", "if", "word", "==", "'<EOS>'", ":", "\n", "                ", "txt", "=", "txt", "+", "' '", "\n", "txt", "=", "txt", "+", "word", "\n", "break", "\n", "", "if", "word", "==", "'<SOS>'", ":", "\n", "                ", "txt", "=", "txt", "+", "'<SOS>'", "\n", "continue", "\n", "", "if", "j", ">", "0", ":", "\n", "                ", "txt", "=", "txt", "+", "' '", "\n", "", "txt", "=", "txt", "+", "word", "\n", "", "out", ".", "append", "(", "txt", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.prob2pred": [[31, 34], ["torch.multinomial().view", "prob.size", "prob.size", "torch.multinomial", "torch.exp", "prob.view", "prob.size"], "function", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.size"], ["", "def", "prob2pred", "(", "prob", ")", ":", "\n", "\n", "    ", "return", "torch", ".", "multinomial", "(", "torch", ".", "exp", "(", "prob", ".", "view", "(", "-", "1", ",", "prob", ".", "size", "(", "-", "1", ")", ")", ")", ",", "1", ")", ".", "view", "(", "prob", ".", "size", "(", "0", ")", ",", "prob", ".", "size", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.net_utils.JointEmbeddingLoss": [[35, 45], ["feature_emb1.size", "torch.sum", "torch.clamp", "torch.mm", "torch.sum", "feature_emb2.t"], "function", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.size"], ["", "def", "JointEmbeddingLoss", "(", "feature_emb1", ",", "feature_emb2", ")", ":", "\n", "\n", "    ", "batch_size", "=", "feature_emb1", ".", "size", "(", ")", "[", "0", "]", "\n", "\n", "return", "torch", ".", "sum", "(", "\n", "torch", ".", "clamp", "(", "\n", "torch", ".", "mm", "(", "feature_emb1", ",", "feature_emb2", ".", "t", "(", ")", ")", "-", "torch", ".", "sum", "(", "feature_emb1", "*", "feature_emb2", ",", "dim", "=", "-", "1", ")", "+", "1", ",", "\n", "min", "=", "0.0", "\n", ")", "\n", ")", "/", "(", "batch_size", "*", "batch_size", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.__init__": [[9, 68], ["torch.Dataset.__init__", "print", "len", "len", "len", "len", "print", "h5py.File", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "dataloader.Dataloader.process_data", "dataloader.Dataloader.process_data", "print", "dataloader.Dataloader.process_data", "dataloader.Dataloader.process_data", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "print", "h5py.File.close", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "open", "json.load", "[].astype", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "ques_train.size", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "[].astype", "[].astype", "[].astype", "[].astype", "[].astype", "ques_train.size", "[].astype", "[].astype", "[].astype", "[].astype", "ques_test.size", "int"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.__init__", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.process_data", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.process_data", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.process_data", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.process_data", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.size"], ["    ", "def", "__init__", "(", "self", ",", "input_json_file_path", ",", "input_ques_h5_path", ")", ":", "\n", "\n", "        ", "super", "(", "Dataloader", ",", "self", ")", ".", "__init__", "(", ")", "\n", "print", "(", "'Reading'", ",", "input_json_file_path", ")", "\n", "\n", "with", "open", "(", "input_json_file_path", ")", "as", "input_file", ":", "\n", "            ", "data_dict", "=", "json", ".", "load", "(", "input_file", ")", "\n", "\n", "", "self", ".", "ix_to_word", "=", "{", "}", "\n", "\n", "for", "k", "in", "data_dict", "[", "'ix_to_word'", "]", ":", "\n", "            ", "self", ".", "ix_to_word", "[", "int", "(", "k", ")", "]", "=", "data_dict", "[", "'ix_to_word'", "]", "[", "k", "]", "\n", "\n", "", "self", ".", "UNK_token", "=", "0", "\n", "\n", "if", "0", "not", "in", "self", ".", "ix_to_word", ":", "\n", "            ", "self", ".", "ix_to_word", "[", "0", "]", "=", "'<UNK>'", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "\n", "\n", "", "self", ".", "EOS_token", "=", "len", "(", "self", ".", "ix_to_word", ")", "\n", "self", ".", "ix_to_word", "[", "self", ".", "EOS_token", "]", "=", "'<EOS>'", "\n", "self", ".", "PAD_token", "=", "len", "(", "self", ".", "ix_to_word", ")", "\n", "self", ".", "ix_to_word", "[", "self", ".", "PAD_token", "]", "=", "'<PAD>'", "\n", "self", ".", "SOS_token", "=", "len", "(", "self", ".", "ix_to_word", ")", "\n", "self", ".", "ix_to_word", "[", "self", ".", "SOS_token", "]", "=", "'<SOS>'", "\n", "self", ".", "vocab_size", "=", "len", "(", "self", ".", "ix_to_word", ")", "\n", "print", "(", "'DataLoader loading h5 question file:'", ",", "input_ques_h5_path", ")", "\n", "qa_data", "=", "h5py", ".", "File", "(", "input_ques_h5_path", ",", "'r'", ")", "\n", "\n", "ques_id_train", "=", "torch", ".", "from_numpy", "(", "qa_data", "[", "'ques_cap_id_train'", "]", "[", "...", "]", ".", "astype", "(", "int", ")", ")", "\n", "\n", "ques_train", ",", "ques_len_train", "=", "self", ".", "process_data", "(", "torch", ".", "from_numpy", "(", "qa_data", "[", "'ques_train'", "]", "[", "...", "]", ".", "astype", "(", "int", ")", ")", ",", "torch", ".", "from_numpy", "(", "qa_data", "[", "'ques_length_train'", "]", "[", "...", "]", ".", "astype", "(", "int", ")", ")", ")", "\n", "\n", "label_train", ",", "label_len_train", "=", "self", ".", "process_data", "(", "torch", ".", "from_numpy", "(", "qa_data", "[", "'ques1_train'", "]", "[", "...", "]", ".", "astype", "(", "int", ")", ")", ",", "torch", ".", "from_numpy", "(", "qa_data", "[", "'ques1_length_train'", "]", "[", "...", "]", ".", "astype", "(", "int", ")", ")", ")", "\n", "\n", "self", ".", "train_id", "=", "0", "\n", "self", ".", "seq_length", "=", "ques_train", ".", "size", "(", ")", "[", "1", "]", "\n", "\n", "print", "(", "'Training dataset length : '", ",", "ques_train", ".", "size", "(", ")", "[", "0", "]", ")", "\n", "\n", "\n", "ques_test", ",", "ques_len_test", "=", "self", ".", "process_data", "(", "torch", ".", "from_numpy", "(", "qa_data", "[", "'ques_test'", "]", "[", "...", "]", ".", "astype", "(", "int", ")", ")", ",", "torch", ".", "from_numpy", "(", "qa_data", "[", "'ques_length_test'", "]", "[", "...", "]", ".", "astype", "(", "int", ")", ")", ")", "\n", "\n", "label_test", ",", "label_len_test", "=", "self", ".", "process_data", "(", "torch", ".", "from_numpy", "(", "qa_data", "[", "'ques1_test'", "]", "[", "...", "]", ".", "astype", "(", "int", ")", ")", ",", "torch", ".", "from_numpy", "(", "qa_data", "[", "'ques1_length_test'", "]", "[", "...", "]", ".", "astype", "(", "int", ")", ")", ")", "\n", "\n", "ques_id_test", "=", "torch", ".", "from_numpy", "(", "qa_data", "[", "'ques_cap_id_test'", "]", "[", "...", "]", ".", "astype", "(", "int", ")", ")", "\n", "\n", "self", ".", "test_id", "=", "0", "\n", "\n", "print", "(", "'Test dataset length : '", ",", "ques_test", ".", "size", "(", ")", "[", "0", "]", ")", "\n", "qa_data", ".", "close", "(", ")", "\n", "\n", "self", ".", "ques", "=", "torch", ".", "cat", "(", "[", "ques_train", ",", "ques_test", "]", ")", "\n", "self", ".", "len", "=", "torch", ".", "cat", "(", "[", "ques_len_train", ",", "ques_len_test", "]", ")", "\n", "self", ".", "label", "=", "torch", ".", "cat", "(", "[", "label_train", ",", "label_test", "]", ")", "\n", "self", ".", "label_len", "=", "torch", ".", "cat", "(", "[", "label_len_train", ",", "label_len_test", "]", ")", "\n", "self", ".", "id", "=", "torch", ".", "cat", "(", "[", "ques_id_train", ",", "ques_id_test", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.process_data": [[69, 78], ["range", "torch.size", "torch.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.size", "torch.size"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.size", "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.size"], ["", "def", "process_data", "(", "self", ",", "data", ",", "data_len", ")", ":", "\n", "        ", "N", "=", "data", ".", "size", "(", ")", "[", "0", "]", "\n", "new_data", "=", "torch", ".", "zeros", "(", "N", ",", "data", ".", "size", "(", ")", "[", "1", "]", "+", "2", ",", "dtype", "=", "torch", ".", "long", ")", "+", "self", ".", "PAD_token", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "            ", "new_data", "[", "i", ",", "1", ":", "data_len", "[", "i", "]", "+", "1", "]", "=", "data", "[", "i", ",", ":", "data_len", "[", "i", "]", "]", "\n", "new_data", "[", "i", ",", "0", "]", "=", "self", ".", "SOS_token", "\n", "new_data", "[", "i", ",", "data_len", "[", "i", "]", "+", "1", "]", "=", "self", ".", "EOS_token", "\n", "data_len", "[", "i", "]", "+=", "2", "\n", "", "return", "new_data", ",", "data_len", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.__len__": [[79, 81], ["dataloader.Dataloader.len.size"], "methods", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.size"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "len", ".", "size", "(", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.__getitem__": [[82, 84], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "(", "self", ".", "ques", "[", "idx", "]", ",", "self", ".", "len", "[", "idx", "]", ",", "self", ".", "label", "[", "idx", "]", ",", "self", ".", "label_len", "[", "idx", "]", ",", "self", ".", "id", "[", "idx", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.getVocabSize": [[85, 87], ["None"], "methods", ["None"], ["", "def", "getVocabSize", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.getDataNum": [[88, 94], ["None"], "methods", ["None"], ["", "def", "getDataNum", "(", "self", ",", "split", ")", ":", "\n", "        ", "if", "split", "==", "1", ":", "\n", "            ", "return", "100000", "\n", "\n", "", "if", "split", "==", "2", ":", "\n", "            ", "return", "30000", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.dataloader.Dataloader.getSeqLength": [[95, 97], ["None"], "methods", ["None"], ["", "", "def", "getSeqLength", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "seq_length", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.utils.one_hot": [[5, 7], ["torch.zeros().scatter_", "t.unsqueeze", "torch.zeros", "t.size"], "function", ["home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.cider.cider_scorer.CiderScorer.size"], ["def", "one_hot", "(", "t", ",", "c", ")", ":", "\n", "    ", "return", "torch", ".", "zeros", "(", "*", "t", ".", "size", "(", ")", ",", "c", ",", "device", "=", "t", ".", "device", ")", ".", "scatter_", "(", "-", "1", ",", "t", ".", "unsqueeze", "(", "-", "1", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dev-chauhan_PQG-pytorch.misc.utils.make_parser": [[9, 68], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["", "def", "make_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--input_ques_h5'", ",", "default", "=", "'data/quora_dataset/quora_data_prepro.h5'", ",", "help", "=", "'path to the h5file containing the preprocessed dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_json'", ",", "default", "=", "'data/quora_dataset/quora_data_prepro.json'", ",", "help", "=", "'path to the json file containing additional info and vocab'", ")", "\n", "\n", "# starting point", "\n", "parser", ".", "add_argument", "(", "'--start_from'", ",", "default", "=", "'None'", ",", "help", "=", "'path to a model checkpoint to initialize model weights from. Empty = don\\'t'", ")", "\n", "\n", "# # Model settings", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "default", "=", "'EDLPS'", ",", "help", "=", "'which model to use? EDL|EDP|EDLP|EDLPS|EDLPG|EDLPGS|EDG|EDPG'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "150", ",", "help", "=", "'what is theutils batch size in number of images per batch? (there will be x seq_per_img sentences)'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_encoding_size'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "help", "=", "'the encoding size of each token in the vocabulary, and the image.'", ")", "\n", "parser", ".", "add_argument", "(", "'--att_size'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "help", "=", "'size of sttention vector which refer to k in paper'", ")", "\n", "parser", ".", "add_argument", "(", "'--emb_size'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "help", "=", "'the size after embeeding from onehot'", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'number of the rnn layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_dataset_len'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "help", "=", "'length of train dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--val_dataset_len'", ",", "type", "=", "int", ",", "default", "=", "30000", ",", "help", "=", "'length of validation dataset'", ")", "\n", "\n", "# Optimization", "\n", "parser", ".", "add_argument", "(", "'--optim'", ",", "default", "=", "'rmsprop'", ",", "help", "=", "'what update to use? rmsprop|sgd|sgdmom|adagrad|adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "default", "=", "0.0008", ",", "help", "=", "'learning rate'", ",", "type", "=", "float", ")", "#0.0001,#0.0002,#0.005", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_decay_start'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'at what epoch to start decaying learning rate? (-1 = dont)'", ")", "#learning_rate_decay_start', 100,", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_decay_every'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'every how many epoch thereafter to drop LR by half?'", ")", "#-learning_rate_decay_every', 1500,", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "help", "=", "'momentum'", ")", "\n", "parser", ".", "add_argument", "(", "'--optim_alpha'", ",", "type", "=", "float", ",", "default", "=", "0.8", ",", "help", "=", "'alpha for adagrad/rmsprop/momentum/adam'", ")", "#optim_alpha',0.99", "\n", "parser", ".", "add_argument", "(", "'--optim_beta'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "help", "=", "'beta used for adam'", ")", "#optim_beta',0.995", "\n", "parser", ".", "add_argument", "(", "'--optim_epsilon'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ",", "help", "=", "'epsilon that goes into denominator in rmsprop'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_iters'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'max number of iterations to run for (-1 = run forever)'", ")", "\n", "parser", ".", "add_argument", "(", "'--iterPerEpoch'", ",", "default", "=", "1250", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--drop_prob_lm'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'strength of drop_prob_lm in the Language Model RNN'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_epoch'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'number of epochs during training'", ")", "\n", "\n", "# Evaluation/Checkpointing", "\n", "\n", "parser", ".", "add_argument", "(", "'--save'", ",", "default", "=", "'Results'", ",", "help", "=", "'save directory'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint_dir'", ",", "default", "=", "'Results/checkpoints'", ",", "help", "=", "'folder to save checkpoints into (empty = this folder)'", ")", "\n", "parser", ".", "add_argument", "(", "'--language_eval'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'Evaluate language as well (1 = yes, 0 = no)? BLEU/CIDEr/METEOR/ROUGE_L? requires coco-caption code from Github.'", ")", "\n", "parser", ".", "add_argument", "(", "'--val_images_use'", ",", "type", "=", "int", ",", "default", "=", "24800", ",", "help", "=", "'how many images to use when periodically evaluating the validation loss? (-1 = all)'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_every'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "'how often to save a model checkpoint?'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_every'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'How often do we snapshot losses, for inclusion in the progress dump? (0 = disable)'", ")", "\n", "\n", "# misc", "\n", "parser", ".", "add_argument", "(", "'--backend'", ",", "default", "=", "'cudnn'", ",", "help", "=", "'nn|cudnn'", ")", "\n", "parser", ".", "add_argument", "(", "'--name'", ",", "default", "=", "''", ",", "help", "=", "'an id identifying this run/job. used in cross-val and appended when writing progress files'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "1234", ",", "help", "=", "'random number generator seed to use'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpuid'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'which gpu to use. -1 = use CPU'", ")", "\n", "parser", ".", "add_argument", "(", "'--nGPU'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'Number of GPUs to use by default'", ")", "\n", "\n", "#text encoder", "\n", "parser", ".", "add_argument", "(", "'--emb_dim'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "help", "=", "'dim of word embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--emb_hid_dim'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'hidden dim of word embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--enc_dropout'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'dropout for encoder module'", ")", "\n", "parser", ".", "add_argument", "(", "'--enc_rnn_dim'", ",", "default", "=", "512", ",", "type", "=", "int", ",", "help", "=", "'size of the rnn in number of hidden nodes in each layer of gru in encoder'", ")", "\n", "parser", ".", "add_argument", "(", "'--enc_dim'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "help", "=", "'size of the encoded sentence'", ")", "\n", "parser", ".", "add_argument", "(", "'--gen_rnn_dim'", ",", "default", "=", "512", ",", "type", "=", "int", ",", "help", "=", "'size of the rnn in number of hidden nodes in each layer of lstm in generator'", ")", "\n", "parser", ".", "add_argument", "(", "'--gen_dropout'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'dropout for generator module'", ")", "\n", "\n", "return", "parser", "\n", "", ""]]}