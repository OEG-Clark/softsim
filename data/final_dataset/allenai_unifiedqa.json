{"home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks.dataset_preprocessor": [[53, 68], ["ds.map", "tensorflow.strings.lower", "tensorflow.strings.regex_replace", "tasks.dataset_preprocessor.normalize_text"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks_v2.normalize_text"], ["def", "dataset_preprocessor", "(", "ds", ")", ":", "\n", "    ", "def", "normalize_text", "(", "text", ")", ":", "\n", "        ", "\"\"\"Lowercase and remove quotes from a TensorFlow string.\"\"\"", "\n", "text", "=", "tf", ".", "strings", ".", "lower", "(", "text", ")", "\n", "text", "=", "tf", ".", "strings", ".", "regex_replace", "(", "text", ",", "\"'(.*)'\"", ",", "r\"\\1\"", ")", "\n", "return", "text", "\n", "\n", "", "def", "to_inputs_and_targets", "(", "ex", ")", ":", "\n", "        ", "return", "{", "\n", "\"inputs\"", ":", "normalize_text", "(", "ex", "[", "\"inputs\"", "]", ")", ",", "\n", "\"targets\"", ":", "normalize_text", "(", "ex", "[", "\"targets\"", "]", ")", "\n", "}", "\n", "\n", "", "return", "ds", ".", "map", "(", "to_inputs_and_targets", ",", "\n", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks.get_path": [[69, 76], ["os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "get_path", "(", "data_dir1", ",", "split", ")", ":", "\n", "    ", "tsv_path", "=", "{", "\n", "\"train\"", ":", "os", ".", "path", ".", "join", "(", "data_dir1", ",", "\"train.tsv\"", ")", ",", "\n", "\"dev\"", ":", "os", ".", "path", ".", "join", "(", "data_dir1", ",", "\"dev.tsv\"", ")", ",", "\n", "\"test\"", ":", "os", ".", "path", ".", "join", "(", "data_dir1", ",", "\"test.tsv\"", ")", "\n", "}", "\n", "return", "tsv_path", "[", "split", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks.dataset_fn": [[78, 95], ["tensorflow.data.TextLineDataset", "print", "ds.map.map", "ds.map.map", "tasks.get_path", "functools.partial", "dict", "zip"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks.get_path"], ["", "def", "dataset_fn", "(", "split", ",", "shuffle_files", "=", "False", ",", "dataset", "=", "\"\"", ")", ":", "\n", "# We only have one file for each split.", "\n", "    ", "del", "shuffle_files", "\n", "\n", "# Load lines from the text file as examples.", "\n", "ds", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "get_path", "(", "DATA_DIR", "+", "dataset", ",", "split", ")", ")", "\n", "# Split each \"<question>\\t<answer>\" example into (question, answer) tuple.", "\n", "print", "(", "\" >>>> about to read csv . . . \"", ")", "\n", "ds", "=", "ds", ".", "map", "(", "\n", "functools", ".", "partial", "(", "tf", ".", "io", ".", "decode_csv", ",", "record_defaults", "=", "[", "\"\"", ",", "\"\"", "]", ",", "\n", "field_delim", "=", "\"\\t\"", ",", "use_quote_delim", "=", "False", ")", ",", "\n", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "# print(\" >>>> after reading csv . . . \")", "\n", "# Map each tuple to a {\"question\": ... \"answer\": ...} dict.", "\n", "ds", "=", "ds", ".", "map", "(", "lambda", "*", "ex", ":", "dict", "(", "zip", "(", "[", "\"inputs\"", ",", "\"targets\"", "]", ",", "ex", ")", ")", ")", "\n", "# print(\" >>>> after mapping . . . \")", "\n", "return", "ds", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks_v2.get_downloaded_data_path": [[11, 13], ["os.path.join"], "function", ["None"], ["def", "get_downloaded_data_path", "(", "data_dir1", ",", "split", ",", "extension", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "join", "(", "data_dir1", ",", "split", "+", "extension", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks_v2.normalize_text": [[14, 19], ["tensorflow.strings.lower", "tensorflow.strings.regex_replace"], "function", ["None"], ["", "def", "normalize_text", "(", "text", ")", ":", "\n", "    ", "\"\"\"Lowercase and remove quotes from a TensorFlow string.\"\"\"", "\n", "text", "=", "tf", ".", "strings", ".", "lower", "(", "text", ")", "\n", "text", "=", "tf", ".", "strings", ".", "regex_replace", "(", "text", ",", "\"'(.*)'\"", ",", "r\"\\1\"", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks_v2.to_inputs_and_targets": [[20, 24], ["tasks_v2.normalize_text", "tasks_v2.normalize_text"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks_v2.normalize_text", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks_v2.normalize_text"], ["", "def", "to_inputs_and_targets", "(", "ex", ")", ":", "\n", "    ", "return", "{", "\n", "\"inputs\"", ":", "normalize_text", "(", "ex", "[", "\"inputs\"", "]", ")", ",", "\n", "\"targets\"", ":", "normalize_text", "(", "ex", "[", "\"targets\"", "]", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks_v2.preprocess": [[26, 33], ["dataset.map"], "function", ["None"], ["", "def", "preprocess", "(", "\n", "dataset", ",", "\n", "prefix", "=", "''", ",", "# not used", "\n", "sample_answer", "=", "False", ",", "# not used", "\n", ")", ":", "\n", "    ", "return", "dataset", ".", "map", "(", "to_inputs_and_targets", ",", "\n", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks_v2.dataset_fn": [[35, 45], ["tensorflow.data.TextLineDataset", "print", "ds.map.map", "ds.map.map", "tasks_v2.get_downloaded_data_path", "functools.partial", "dict", "zip"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks_v2.get_downloaded_data_path"], ["", "def", "dataset_fn", "(", "split", ",", "shuffle_files", "=", "False", ",", "dataset", "=", "\"\"", ")", ":", "\n", "# Load lines from the text file as examples.", "\n", "    ", "ds", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "get_downloaded_data_path", "(", "DATA_DIR", "+", "dataset", ",", "split", ",", "\".tsv\"", ")", ")", "\n", "print", "(", "\" >>>> about to read tsv . . . \"", ")", "\n", "ds", "=", "ds", ".", "map", "(", "\n", "functools", ".", "partial", "(", "tf", ".", "io", ".", "decode_csv", ",", "record_defaults", "=", "[", "\"\"", ",", "\"\"", ",", "\"\"", "]", ",", "use_quote_delim", "=", "False", ",", "field_delim", "=", "\"\\t\"", ")", ",", "\n", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "# Map each tuple to a {\"question\": ... \"answers\": ...} dict.", "\n", "ds", "=", "ds", ".", "map", "(", "lambda", "*", "ex", ":", "dict", "(", "zip", "(", "[", "\"inputs\"", ",", "\"targets\"", ",", "\"id\"", "]", ",", "ex", ")", ")", ")", "\n", "return", "ds", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks_v2.dataset_fn_two_column": [[47, 57], ["tensorflow.data.TextLineDataset", "print", "ds.map.map", "ds.map.map", "tasks_v2.get_downloaded_data_path", "functools.partial", "dict", "zip"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks_v2.get_downloaded_data_path"], ["", "def", "dataset_fn_two_column", "(", "split", ",", "shuffle_files", "=", "False", ",", "dataset", "=", "\"\"", ")", ":", "\n", "# Load lines from the text file as examples.", "\n", "    ", "ds", "=", "tf", ".", "data", ".", "TextLineDataset", "(", "get_downloaded_data_path", "(", "DATA_DIR", "+", "dataset", ",", "split", ",", "\".tsv\"", ")", ")", "\n", "print", "(", "\" >>>> about to read tsv . . . \"", ")", "\n", "ds", "=", "ds", ".", "map", "(", "\n", "functools", ".", "partial", "(", "tf", ".", "io", ".", "decode_csv", ",", "record_defaults", "=", "[", "\"\"", ",", "\"\"", "]", ",", "use_quote_delim", "=", "False", ",", "field_delim", "=", "\"\\t\"", ")", ",", "\n", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "# Map each tuple to a {\"question\": ... \"answers\": ...} dict.", "\n", "ds", "=", "ds", ".", "map", "(", "lambda", "*", "ex", ":", "dict", "(", "zip", "(", "[", "\"inputs\"", ",", "\"targets\"", "]", ",", "ex", ")", ")", ")", "\n", "return", "ds", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks_v2.postprocessor": [[59, 65], ["tensorflow.compat.as_text", "tensorflow.compat.as_text"], "function", ["None"], ["", "def", "postprocessor", "(", "answer", ",", "example", "=", "None", ",", "is_target", "=", "False", ")", ":", "\n", "    ", "\"\"\"Returns answer, or all answers if the full example is provided.\"\"\"", "\n", "if", "example", ":", "\n", "        ", "return", "tf", ".", "compat", ".", "as_text", "(", "answer", ")", "+", "\"\\t\"", "+", "tf", ".", "compat", ".", "as_text", "(", "example", "[", "\"id\"", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "answer", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.tasks_v2.postprocessor_two_column": [[67, 70], ["tensorflow.compat.as_text"], "function", ["None"], ["", "", "def", "postprocessor_two_column", "(", "answer", ",", "example", "=", "None", ",", "is_target", "=", "False", ")", ":", "\n", "    ", "\"\"\"Returns answer, or all answers if the full example is provided.\"\"\"", "\n", "return", "tf", ".", "compat", ".", "as_text", "(", "answer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.commonsenseqa": [[27, 54], ["encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["def", "commonsenseqa", "(", ")", ":", "\n", "    ", "def", "read_file", "(", "file", ",", "split", ")", ":", "\n", "        ", "fout", "=", "open", "(", "f\"commonsenseqa/{split}.tsv\"", ",", "\"w\"", ")", "\n", "fout_meta", "=", "open", "(", "f\"commonsenseqa/{split}_meta.tsv\"", ",", "\"w\"", ")", "\n", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "json_line", "=", "json", ".", "loads", "(", "line", ")", "\n", "\n", "candidates_str", "=", "\" \"", ".", "join", "(", "[", "f\"({x['label']}) {x['text']}\"", "for", "x", "in", "json_line", "[", "'question'", "]", "[", "'choices'", "]", "]", ")", "\n", "if", "split", "!=", "\"test\"", ":", "\n", "                    ", "selected_ans_string", "=", "[", "x", "[", "'text'", "]", "for", "x", "in", "json_line", "[", "'question'", "]", "[", "'choices'", "]", "if", "\n", "json_line", "[", "'answerKey'", "]", "==", "x", "[", "'label'", "]", "]", "\n", "assert", "len", "(", "selected_ans_string", ")", "==", "1", ",", "f\"{len(selected_ans_string)} -- {json_line['answerKey']}\"", "\n", "", "json_line", "[", "'question'", "]", "[", "'stem'", "]", "=", "json_line", "[", "'question'", "]", "[", "'stem'", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "candidates_str", "=", "candidates_str", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "\n", "if", "split", "==", "\"test\"", ":", "\n", "                    ", "fout_meta", ".", "write", "(", "f\"{json_line['id']}\\t-\\n\"", ")", "\n", "fout", ".", "write", "(", "f\"{json_line['question']['stem']} \\\\n {candidates_str}\\t-\\n\"", ")", "\n", "", "else", ":", "\n", "                    ", "fout_meta", ".", "write", "(", "f\"{json_line['id']}\\t{json_line['answerKey']}\\n\"", ")", "\n", "selected_ans_string", "[", "0", "]", "=", "selected_ans_string", "[", "0", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "fout", ".", "write", "(", "f\"{json_line['question']['stem']} \\\\n {candidates_str}\\t{selected_ans_string[0]}\\n\"", ")", "\n", "\n", "", "", "", "", "read_file", "(", "\"commonsenseqa/dev_rand_split.jsonl\"", ",", "\"dev\"", ")", "\n", "read_file", "(", "\"commonsenseqa/train_rand_split.jsonl\"", ",", "\"train\"", ")", "\n", "read_file", "(", "\"commonsenseqa/test_rand_split_no_answers.jsonl\"", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_qas_paragraphs": [[56, 73], ["print", "open", "f.readlines", "json.loads", "list", "length_list.append", "nlp", "set", "len", "sent.text.strip", "map[].split"], "function", ["None"], ["", "def", "read_qas_paragraphs", "(", "file", ")", ":", "\n", "    ", "map", "=", "{", "}", "\n", "length_list", "=", "[", "]", "\n", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "json_line", "=", "json", ".", "loads", "(", "line", ")", "\n", "sentence_list", "=", "[", "]", "\n", "for", "c", "in", "json_line", "[", "'question'", "]", "[", "'choices'", "]", ":", "\n", "                ", "doc", "=", "nlp", "(", "c", "[", "'para'", "]", ")", "\n", "all_sentences", "=", "[", "sent", ".", "text", ".", "strip", "(", ")", "for", "sent", "in", "doc", ".", "sents", "]", "\n", "sentence_list", "+=", "all_sentences", "[", "-", "4", ":", "]", "\n", "", "sentence_list", "=", "list", "(", "set", "(", "sentence_list", ")", ")", "\n", "map", "[", "json_line", "[", "'id'", "]", "]", "=", "\" \"", ".", "join", "(", "sentence_list", ")", "\n", "\n", "length_list", ".", "append", "(", "len", "(", "map", "[", "json_line", "[", "'id'", "]", "]", ".", "split", "(", "\" \"", ")", ")", ")", "\n", "", "", "print", "(", "length_list", ")", "\n", "return", "map", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.qasc": [[75, 112], ["encode_datasets.read_qas_paragraphs", "encode_datasets.read_qas_paragraphs", "encode_datasets.read_qas_paragraphs", "qasc_para.update", "qasc_para.update", "qasc_para.update", "open", "open", "encode_datasets.qasc.process_file"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_qas_paragraphs", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_qas_paragraphs", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_qas_paragraphs"], ["", "def", "qasc", "(", ")", ":", "\n", "    ", "qasc_para", "=", "{", "}", "\n", "map1", "=", "read_qas_paragraphs", "(", "\"QASC_Dataset_2Step/train.jsonl\"", ")", "\n", "map2", "=", "read_qas_paragraphs", "(", "\"QASC_Dataset_2Step/test.jsonl\"", ")", "\n", "map3", "=", "read_qas_paragraphs", "(", "\"QASC_Dataset_2Step/dev.jsonl\"", ")", "\n", "qasc_para", ".", "update", "(", "map1", ")", "\n", "qasc_para", ".", "update", "(", "map2", ")", "\n", "qasc_para", ".", "update", "(", "map3", ")", "\n", "\n", "def", "process_file", "(", "file", ",", "split", ",", "with_para", ")", ":", "\n", "        ", "outdir", "=", "\"qasc\"", "\n", "if", "with_para", ":", "\n", "            ", "outdir", "=", "\"qasc_with_ir\"", "\n", "", "fout", "=", "open", "(", "f\"{outdir}/{split}.tsv\"", ",", "\"w\"", ")", "\n", "fout_meta", "=", "open", "(", "f\"{outdir}/{split}_meta.tsv\"", ",", "\"w\"", ")", "\n", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "json_line", "=", "json", ".", "loads", "(", "line", ")", "\n", "para", "=", "\"\"", "\n", "if", "with_para", ":", "\n", "                    ", "para", "=", "\"\\\\n\"", "+", "qasc_para", "[", "json_line", "[", "'id'", "]", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "", "candidates_str", "=", "\" \"", ".", "join", "(", "[", "f\"({x['label']}) {x['text']}\"", "for", "x", "in", "json_line", "[", "'question'", "]", "[", "'choices'", "]", "]", ")", "\n", "if", "'answerKey'", "in", "json_line", ":", "\n", "                    ", "selected_ans_string", "=", "[", "x", "[", "'text'", "]", "for", "x", "in", "json_line", "[", "'question'", "]", "[", "'choices'", "]", "if", "\n", "json_line", "[", "'answerKey'", "]", "==", "x", "[", "'label'", "]", "]", "\n", "assert", "len", "(", "selected_ans_string", ")", "==", "1", ",", "f\"{len(selected_ans_string)} -- {json_line['answerKey']}\"", "\n", "ansKey", "=", "json_line", "[", "'answerKey'", "]", "\n", "", "else", ":", "\n", "                    ", "selected_ans_string", "=", "[", "'-'", "]", "\n", "ansKey", "=", "'-'", "\n", "", "fout", ".", "write", "(", "f\"{json_line['question']['stem']} \\\\n {candidates_str}{para}\\t{selected_ans_string[0]}\\n\"", ")", "\n", "fout_meta", ".", "write", "(", "f\"{json_line['id']}\\t{ansKey}\\n\"", ")", "\n", "\n", "", "", "", "for", "with_para", "in", "[", "True", ",", "False", "]", ":", "\n", "        ", "process_file", "(", "\"QASC_Dataset/dev.jsonl\"", ",", "\"dev\"", ",", "with_para", ")", "\n", "process_file", "(", "\"QASC_Dataset/test.jsonl\"", ",", "\"test\"", ",", "with_para", ")", "\n", "process_file", "(", "\"QASC_Dataset/train.jsonl\"", ",", "\"train\"", ",", "with_para", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.boolq_contrast_sets": [[114, 133], ["encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["", "", "def", "boolq_contrast_sets", "(", ")", ":", "\n", "    ", "def", "read_file", "(", "split", ")", ":", "\n", "        ", "fout", "=", "open", "(", "f\"contrast_sets_boolq/{split}.tsv\"", ",", "\"w\"", ")", "\n", "# fout_meta = open(f\"boolq-experts/{split}_meta.tsv\", \"w\")", "\n", "with", "open", "(", "\"contrast_sets/boolq_expert_perturbations.json\"", ")", "as", "f", ":", "\n", "            ", "json_content", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "entry", "in", "json_content", "[", "'data'", "]", ":", "\n", "                ", "passage", "=", "f\"({entry['title']}) {entry['paragraph']}\"", "\n", "for", "q", "in", "entry", "[", "'perturbed_questions'", "]", ":", "\n", "                    ", "if", "'?'", "not", "in", "q", "[", "'perturbed_q'", "]", ":", "\n", "                        ", "q", "[", "'perturbed_q'", "]", "+=", "'?'", "\n", "", "if", "q", "[", "'answer'", "]", "==", "'TRUE'", ":", "\n", "                        ", "ans", "=", "\"yes\"", "\n", "", "else", ":", "\n", "                        ", "ans", "=", "\"no\"", "\n", "", "fout", ".", "write", "(", "f\"{q['perturbed_q']} \\\\n {passage}\\t{ans}\\n\"", ")", "\n", "\n", "", "", "", "", "read_file", "(", "\"train\"", ")", "\n", "read_file", "(", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.physical_iqa": [[134, 167], ["encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["", "def", "physical_iqa", "(", ")", ":", "\n", "    ", "def", "read_file", "(", "split", ")", ":", "\n", "        ", "fout", "=", "open", "(", "f\"physical_iqa/{split}.tsv\"", ",", "\"w\"", ")", "\n", "fout_meta", "=", "open", "(", "f\"physical_iqa/{split}_meta.tsv\"", ",", "\"w\"", ")", "\n", "\n", "with", "open", "(", "f\"physicaliqa-train-dev/{split}-labels.lst\"", ")", "as", "f", ":", "\n", "            ", "labels", "=", "[", "line", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "counter", "=", "0", "\n", "with", "open", "(", "f\"physicaliqa-train-dev/{split}.jsonl\"", ")", "as", "f", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ".", "readlines", "(", ")", ")", ":", "\n", "                ", "label", "=", "labels", "[", "idx", "]", "\n", "json_line", "=", "json", ".", "loads", "(", "line", ")", "\n", "id", "=", "json_line", "[", "'id'", "]", "\n", "goal", "=", "json_line", "[", "'goal'", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "sol1", "=", "json_line", "[", "'sol1'", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "sol2", "=", "json_line", "[", "'sol2'", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "assert", "label", "==", "\"1\"", "or", "label", "==", "\"0\"", ",", "f\" * label: {label}\"", "\n", "ans", "=", "sol1", "\n", "ans_label_ab", "=", "\"A\"", "\n", "if", "label", "==", "\"1\"", ":", "\n", "                    ", "ans", "=", "sol2", "\n", "ans_label_ab", "=", "\"B\"", "\n", "", "ans", "=", "ans", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "fout", ".", "write", "(", "f\"{goal} \\\\n (A) {sol1} (B) {sol2} \\t {ans}\\n\"", ")", "\n", "fout_meta", ".", "write", "(", "f\"{id}\\t{ans_label_ab}\\t numeric_from_zero \\t{ans}\\n\"", ")", "\n", "counter", "+=", "1", "\n", "", "", "return", "counter", "\n", "\n", "", "dev_count", "=", "read_file", "(", "\"dev\"", ")", "\n", "train_count", "=", "read_file", "(", "\"train\"", ")", "\n", "with", "open", "(", "f\"physical_iqa/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"dev\"", ":", "dev_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.social_iqa": [[168, 207], ["encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["", "", "def", "social_iqa", "(", ")", ":", "\n", "    ", "def", "read_file", "(", "split", ")", ":", "\n", "        ", "fout", "=", "open", "(", "f\"social_iqa/{split}.tsv\"", ",", "\"w\"", ")", "\n", "fout_meta", "=", "open", "(", "f\"social_iqa/{split}_meta.tsv\"", ",", "\"w\"", ")", "\n", "\n", "with", "open", "(", "f\"socialiqa-train-dev/{split}-labels.lst\"", ")", "as", "f", ":", "\n", "            ", "labels", "=", "[", "line", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "strip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "counter", "=", "0", "\n", "with", "open", "(", "f\"socialiqa-train-dev/{split}.jsonl\"", ")", "as", "f", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ".", "readlines", "(", ")", ")", ":", "\n", "                ", "label", "=", "labels", "[", "idx", "]", "\n", "json_line", "=", "json", ".", "loads", "(", "line", ")", "\n", "context", "=", "json_line", "[", "'context'", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "question", "=", "json_line", "[", "'question'", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "answerA", "=", "json_line", "[", "'answerA'", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "answerB", "=", "json_line", "[", "'answerB'", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "answerC", "=", "json_line", "[", "'answerC'", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "assert", "label", "==", "\"1\"", "or", "label", "==", "\"2\"", "or", "label", "==", "\"3\"", ",", "f\" * label: {label}\"", "\n", "ans", "=", "answerA", "\n", "abc_label", "=", "\"A\"", "\n", "if", "label", "==", "\"2\"", ":", "\n", "                    ", "ans", "=", "answerB", "\n", "abc_label", "=", "\"B\"", "\n", "", "if", "label", "==", "\"3\"", ":", "\n", "                    ", "ans", "=", "answerC", "\n", "abc_label", "=", "\"C\"", "\n", "", "ans", "=", "ans", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n (A) {answerA} (B) {answerB} (C) {answerC} \\\\n {context} \\t {ans}\\n\"", ")", "\n", "fout_meta", ".", "write", "(", "f\"-\\t{abc_label}\\t numeric \\t{ans} \\n\"", ")", "\n", "counter", "+=", "1", "\n", "\n", "", "", "return", "counter", "\n", "\n", "\n", "", "dev_count", "=", "read_file", "(", "\"dev\"", ")", "\n", "train_count", "=", "read_file", "(", "\"train\"", ")", "\n", "with", "open", "(", "f\"social_iqa/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"dev\"", ":", "dev_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.drop_contrast_sets": [[209, 246], ["encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["", "", "def", "drop_contrast_sets", "(", ")", ":", "\n", "    ", "def", "read_file", "(", "split", ")", ":", "\n", "        ", "fout", "=", "open", "(", "f\"contrast_sets_drop/{split}.tsv\"", ",", "\"w\"", ")", "\n", "fout_meta", "=", "open", "(", "f\"contrast_sets_drop/{split}_meta.tsv\"", ",", "\"w\"", ")", "\n", "with", "open", "(", "\"drop_dataset/DROP/drop_contrast_sets_test.json\"", ")", "as", "f", ":", "\n", "            ", "json_content", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "title", ",", "content", "in", "json_content", ".", "items", "(", ")", ":", "\n", "                ", "for", "qp", "in", "content", "[", "'qa_pairs'", "]", ":", "\n", "                    ", "answer", "=", "qp", "[", "'answer'", "]", "\n", "number", "=", "answer", "[", "'number'", "]", "\n", "spans", "=", "answer", "[", "'spans'", "]", "\n", "if", "len", "(", "spans", ")", ">", "0", ":", "\n", "                        ", "ans_text", "=", "\", \"", ".", "join", "(", "spans", ")", "\n", "", "elif", "len", "(", "number", ")", ">", "0", ":", "\n", "                        ", "ans_text", "=", "number", "\n", "", "else", ":", "\n", "                        ", "day", "=", "answer", "[", "'date'", "]", "[", "'day'", "]", "\n", "month", "=", "answer", "[", "'date'", "]", "[", "'month'", "]", "\n", "year", "=", "answer", "[", "'date'", "]", "[", "'year'", "]", "\n", "if", "len", "(", "month", ")", ">", "0", ":", "\n", "                            ", "ans_text", "+=", "month", "\n", "", "if", "len", "(", "day", ")", ">", "0", ":", "\n", "                            ", "ans_text", "+=", "f\" {day}\"", "\n", "", "if", "len", "(", "year", ")", ">", "0", ":", "\n", "                            ", "ans_text", "+=", "f\" {year}\"", "\n", "\n", "# assert ans_text != \"\"", "\n", "# print(ans_text)", "\n", "", "", "if", "ans_text", "==", "\"\"", ":", "\n", "                        ", "print", "(", "\" >>>> skipping the question . . . \"", ")", "\n", "continue", "\n", "\n", "", "fout", ".", "write", "(", "f\"{qp['question']} \\\\n {content['passage']}\\t{ans_text}\\n\"", ")", "\n", "fout_meta", ".", "write", "(", "f\"{qp['query_id']}\\n\"", ")", "\n", "\n", "", "", "", "", "read_file", "(", "\"train\"", ")", "\n", "read_file", "(", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.quoref_contrast_sets": [[248, 267], ["encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["", "def", "quoref_contrast_sets", "(", ")", ":", "\n", "    ", "def", "read_file", "(", "split", ")", ":", "\n", "        ", "fout", "=", "open", "(", "f\"contrast_sets_quoref/{split}.tsv\"", ",", "\"w\"", ")", "\n", "fout_meta", "=", "open", "(", "f\"contrast_sets_quoref/{split}_meta.tsv\"", ",", "\"w\"", ")", "\n", "with", "open", "(", "\n", "\"drop_dataset/quoref/quoref_test_perturbations_20191206_merged.json\"", ")", "as", "f", ":", "\n", "            ", "json_content", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "entry", "in", "json_content", "[", "'data'", "]", ":", "\n", "                ", "entry", "[", "'title'", "]", "=", "entry", "[", "'title'", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "for", "p", "in", "entry", "[", "'paragraphs'", "]", ":", "\n", "                    ", "p", "[", "'context'", "]", "=", "p", "[", "'context'", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "passage", "=", "f\"({entry['title']}) {p['context']}\"", "\n", "for", "q", "in", "p", "[", "'qas'", "]", ":", "\n", "                        ", "answers", "=", "\"///\"", ".", "join", "(", "[", "x", "[", "'text'", "]", "for", "x", "in", "q", "[", "'answers'", "]", "]", ")", "\n", "fout", ".", "write", "(", "f\"{q['question']}\\\\n{passage}\\t{answers}\\n\"", ")", "\n", "fout_meta", ".", "write", "(", "f\"{q['id']}\\n\"", ")", "\n", "\n", "", "", "", "", "", "read_file", "(", "\"train\"", ")", "\n", "read_file", "(", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.ropes_contrast_sets": [[269, 287], ["encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["", "def", "ropes_contrast_sets", "(", ")", ":", "\n", "    ", "def", "read_file", "(", "split", ")", ":", "\n", "        ", "fout", "=", "open", "(", "f\"contrast_sets_ropes/{split}.tsv\"", ",", "\"w\"", ")", "\n", "fout_meta", "=", "open", "(", "f\"contrast_sets_ropes/{split}_meta.tsv\"", ",", "\"w\"", ")", "\n", "with", "open", "(", "\n", "\"drop_dataset/ropes/data/ropes_contrast_set_032820.json\"", ")", "as", "f", ":", "\n", "            ", "json_content", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "para", "in", "json_content", "[", "'data'", "]", "[", "0", "]", "[", "'paragraphs'", "]", ":", "\n", "                ", "context", "=", "f\"{para['background']} {para['situation']}\"", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "for", "qa", "in", "para", "[", "'qas'", "]", ":", "\n", "                    ", "question", "=", "qa", "[", "'question'", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "for", "a", "in", "qa", "[", "'answers'", "]", ":", "\n", "                        ", "answer", "=", "a", "[", "'text'", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n {context}\\t{answer}\\n\"", ")", "\n", "fout_meta", ".", "write", "(", "f\"{qa['id']}\\n\"", ")", "\n", "\n", "", "", "", "", "", "read_file", "(", "\"train\"", ")", "\n", "read_file", "(", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.mctest": [[289, 341], ["encode_datasets.mctest.read_and_convert_mctest_data"], "function", ["None"], ["", "def", "mctest", "(", ")", ":", "\n", "    ", "def", "read_and_convert_mctest_data", "(", "file", ",", "output_dir", ",", "out_file", ",", "write_format", "=", "\"w+\"", ")", ":", "\n", "# out_file = file.split(\"/\")[-1].replace(\".tsv\", \"\")", "\n", "# fdataset_idx = open(f\"{output_dir}/{out_file}_idx.tsv\", \"w+\")", "\n", "        ", "fdataset_string", "=", "open", "(", "f\"{output_dir}/{out_file}.tsv\"", ",", "write_format", ")", "\n", "fmeta", "=", "open", "(", "f\"{output_dir}/{out_file}_meta.txt\"", ",", "write_format", ")", "\n", "global", "all_inputs", "\n", "all_inputs", "=", "[", "]", "\n", "all_answers", "=", "[", "]", "\n", "all_meta", "=", "[", "]", "\n", "all_candidates", "=", "[", "]", "\n", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "            ", "for", "l", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "line_split", "=", "l", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\\\newline\"", ",", "\" \"", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "pid", "=", "line_split", "[", "0", "]", "\n", "paragraph", "=", "line_split", "[", "2", "]", "\n", "\n", "def", "get_question_and_candidates", "(", "split_row", ":", "List", "[", "str", "]", ")", ":", "\n", "                    ", "kind", "=", "\"one\"", "if", "\"one: \"", "in", "split_row", "[", "0", "]", "else", "\"multiple\"", "\n", "question", "=", "split_row", "[", "0", "]", ".", "replace", "(", "\"one: \"", ",", "\"\"", ")", ".", "replace", "(", "\"multiple: \"", ",", "\"\"", ")", "\n", "candidates", "=", "split_row", "[", "1", ":", "5", "]", "\n", "all_candidates", ".", "append", "(", "candidates", ")", "\n", "candidates", "=", "\" \"", ".", "join", "(", "[", "f\"({chr(ord('A') + i)}) {x}\"", "for", "i", ",", "x", "in", "enumerate", "(", "candidates", ")", "]", ")", "\n", "# fmeta.write(pid + \"\\t\" + kind + \" \\n\")", "\n", "all_meta", ".", "append", "(", "[", "pid", ",", "kind", "]", ")", "\n", "all_inputs", ".", "append", "(", "f\"{question} \\\\n {candidates} \\\\n {paragraph}\"", ")", "\n", "\n", "", "get_question_and_candidates", "(", "line_split", "[", "3", ":", "8", "]", ")", "\n", "get_question_and_candidates", "(", "line_split", "[", "8", ":", "13", "]", ")", "\n", "get_question_and_candidates", "(", "line_split", "[", "13", ":", "18", "]", ")", "\n", "get_question_and_candidates", "(", "line_split", "[", "18", ":", "23", "]", ")", "\n", "\n", "# try:", "\n", "", "", "with", "open", "(", "file", ".", "replace", "(", "\".tsv\"", ",", "\".ans\"", ")", ")", "as", "fans", ":", "\n", "            ", "for", "l", "in", "fans", ".", "readlines", "(", ")", ":", "\n", "                ", "all_answers", ".", "extend", "(", "l", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "split", "(", "\"\\t\"", ")", ")", "\n", "# except (FileNotFoundError):", "\n", "#     pass", "\n", "\n", "", "", "assert", "len", "(", "all_answers", ")", "==", "len", "(", "all_inputs", ")", "\n", "\n", "for", "i", ",", "y", "in", "enumerate", "(", "all_answers", ")", ":", "\n", "# fdataset_idx.write(all_inputs[i] + \"\\t\" + y + \"\\n\")", "\n", "            ", "correct_ans_idx", "=", "ord", "(", "y", ")", "-", "ord", "(", "'A'", ")", "\n", "fmeta", ".", "write", "(", "all_meta", "[", "i", "]", "[", "0", "]", "+", "\"\\t\"", "+", "y", "+", "\"\\t\"", "+", "all_meta", "[", "i", "]", "[", "1", "]", "+", "\" \\n\"", ")", "\n", "fdataset_string", ".", "write", "(", "all_inputs", "[", "i", "]", "+", "\"\\t\"", "+", "all_candidates", "[", "i", "]", "[", "correct_ans_idx", "]", "+", "\"\\n\"", ")", "\n", "\n", "", "", "read_and_convert_mctest_data", "(", "'../datasets/mctest-master/data/MCTest/mc160.dev.tsv'", ",", "\"mc160\"", ",", "\"dev\"", ")", "\n", "read_and_convert_mctest_data", "(", "'../datasets/mctest-master/data/MCTest/mc160.train.tsv'", ",", "\"mc160\"", ",", "\"train\"", ")", "\n", "\n", "read_and_convert_mctest_data", "(", "'../datasets/mctest-master/data/MCTest/mc500.dev.tsv'", ",", "\"mc500\"", ",", "\"dev\"", ")", "\n", "read_and_convert_mctest_data", "(", "'../datasets/mctest-master/data/MCTest/mc500.train.tsv'", ",", "\"mc500\"", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa": [[1874, 1920], ["open", "open", "open", "open", "f.readlines", "json.loads", "paragraph.replace().replace().replace().replace.strip().replace().replace", "open.write", "print", "paragraph.replace().replace().replace().replace.replace().replace().replace().replace", "question.replace().replace().replace().replace.replace().replace().replace().replace", "print", "open.write", "open.write", "paragraph.replace().replace().replace().replace.strip().replace", "len", "a.replace().replace().replace().replace", "answers.append", "print", "paragraph.replace().replace().replace().replace.replace().replace().replace", "question.replace().replace().replace().replace.replace().replace().replace", "json.dumps", "paragraph.replace().replace().replace().replace.strip", "answers.append", "a.replace().replace().replace", "question.replace().replace().replace().replace.strip", "paragraph.replace().replace().replace().replace.strip", "all_ans[].strip", "answers.append", "print", "paragraph.replace().replace().replace().replace.replace().replace", "question.replace().replace().replace().replace.replace().replace", "a.replace().replace", "paragraph.replace().replace().replace().replace.replace", "question.replace().replace().replace().replace.replace", "a.replace"], "function", ["None"], ["", "def", "read_and_parse_multiqa", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout", "=", "open", "(", "f\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/{dataset}/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "ans", "=", "open", "(", "f\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/{dataset}/{kind}_ans.jsonl\"", ",", "\"w+\"", ")", "\n", "\n", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "        ", "for", "l", "in", "f", ".", "readlines", "(", ")", "[", "1", ":", "]", ":", "\n", "            ", "json_line", "=", "json", ".", "loads", "(", "l", ")", "\n", "pid", "=", "json_line", "[", "'id'", "]", "\n", "paragraph", "=", "\"\"", "\n", "for", "p", "in", "json_line", "[", "'context'", "]", "[", "'documents'", "]", ":", "\n", "                ", "if", "'title'", "in", "p", ":", "\n", "                    ", "paragraph", "+=", "f\" ({p['title']}) \"", "\n", "", "paragraph", "+=", "p", "[", "'text'", "]", "\n", "", "paragraph", "=", "paragraph", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", "\n", "for", "q", "in", "json_line", "[", "'qas'", "]", ":", "\n", "                ", "qid", "=", "q", "[", "'qid'", "]", "\n", "fmeta", ".", "write", "(", "f\"{pid}, {qid} \\n\"", ")", "\n", "question", "=", "q", "[", "'question'", "]", "\n", "answers", "=", "[", "]", "\n", "print", "(", "q", ")", "\n", "if", "'cannot_answer'", "in", "q", "[", "'answers'", "]", "[", "'open-ended'", "]", ":", "\n", "                    ", "if", "q", "[", "'answers'", "]", "[", "'open-ended'", "]", "[", "'cannot_answer'", "]", "==", "'yes'", ":", "\n", "                        ", "answers", ".", "append", "(", "'<No Answer>'", ")", "\n", "", "", "else", ":", "\n", "                    ", "for", "a", "in", "q", "[", "'answers'", "]", "[", "'open-ended'", "]", "[", "'annotators_answer_candidates'", "]", ":", "\n", "                        ", "print", "(", "a", ")", "\n", "if", "'extractive'", "in", "a", "[", "'single_answer'", "]", ":", "\n", "                            ", "answers", ".", "append", "(", "a", "[", "'single_answer'", "]", "[", "'extractive'", "]", "[", "'answer'", "]", ")", "\n", "", "elif", "'yesno'", "in", "a", "[", "'single_answer'", "]", ":", "\n", "                            ", "answers", ".", "append", "(", "a", "[", "'single_answer'", "]", "[", "'yesno'", "]", ")", "\n", "", "else", ":", "\n", "                            ", "print", "(", "\"yo yo yo \"", ")", "\n", "\n", "", "", "", "assert", "len", "(", "answers", ")", ">", "0", "\n", "\n", "paragraph", "=", "paragraph", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "question", "=", "question", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "if", "'?'", "not", "in", "question", ":", "\n", "                    ", "question", "=", "question", "+", "\"?\"", "\n", "", "all_ans", "=", "[", "a", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "for", "a", "in", "\n", "answers", "]", "\n", "\n", "print", "(", "all_ans", ")", "\n", "fout", ".", "write", "(", "f\"{question.strip()} \\\\n {paragraph.strip()}\\t{all_ans[0].strip()}\\n\"", ")", "\n", "ans", ".", "write", "(", "json", ".", "dumps", "(", "all_ans", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.mkdir": [[396, 402], ["os.makedirs"], "function", ["None"], ["", "", "", "", "def", "mkdir", "(", "directory", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "os", ".", "makedirs", "(", "directory", ")", "\n", "", "except", "OSError", "as", "e", ":", "\n", "        ", "if", "e", ".", "errno", "!=", "errno", ".", "EEXIST", ":", "\n", "            ", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.race": [[407, 479], ["print", "encode_datasets.race.process_race_dir"], "function", ["None"], ["def", "race", "(", "variation", ",", "grade", ",", "write_format", "=", "\"w+\"", ")", ":", "\n", "    ", "print", "(", "f\">>>> race variation: {variation} / {grade}\"", ")", "\n", "assert", "variation", "==", "\"idx\"", "or", "variation", "==", "\"string\"", "or", "variation", "==", "'string_no_candidates'", "\n", "\n", "count_map", "=", "{", "}", "\n", "\n", "def", "process_race_dir", "(", "kind", ")", ":", "\n", "        ", "counter", "=", "{", "\"counter\"", ":", "0", "}", "\n", "if", "variation", "==", "\"idx\"", ":", "\n", "            ", "dir", "=", "f\"race_idx_{grade}\"", "\n", "mkdir", "(", "dir", ")", "\n", "fin", "=", "open", "(", "f\"{dir}/{kind.split('/')[0]}.tsv\"", ",", "write_format", ")", "\n", "fmeta", "=", "open", "(", "f\"{dir}/{kind.split('/')[0]}_meta.txt\"", ",", "write_format", ")", "\n", "", "elif", "variation", "==", "\"string\"", ":", "\n", "            ", "dir", "=", "f\"race_string_{grade}\"", "\n", "mkdir", "(", "dir", ")", "\n", "fin", "=", "open", "(", "f\"{dir}/{kind.split('/')[0]}.tsv\"", ",", "write_format", ")", "\n", "fmeta", "=", "open", "(", "f\"{dir}/{kind.split('/')[0]}_meta.txt\"", ",", "write_format", ")", "\n", "", "elif", "variation", "==", "\"string_no_candidates\"", ":", "\n", "            ", "dir", "=", "f\"race_string_no_candidates_{grade}\"", "\n", "mkdir", "(", "dir", ")", "\n", "fin", "=", "open", "(", "f\"{dir}/{kind.split('/')[0]}.tsv\"", ",", "write_format", ")", "\n", "fmeta", "=", "open", "(", "f\"{dir}/{kind.split('/')[0]}_meta.txt\"", ",", "write_format", ")", "\n", "", "else", ":", "\n", "            ", "raise", "AttributeError", "\n", "\n", "", "def", "read_and_parse_race", "(", "file", ")", ":", "\n", "            ", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "                ", "counter", "[", "\"counter\"", "]", "+=", "1", "\n", "line", "=", "f", ".", "readlines", "(", ")", "[", "0", "]", "\n", "line", "=", "line", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "jsonline", "=", "json", ".", "loads", "(", "line", ")", "\n", "answers", "=", "jsonline", "[", "'answers'", "]", "\n", "options", "=", "jsonline", "[", "'options'", "]", "\n", "questions", "=", "jsonline", "[", "'questions'", "]", "\n", "article", "=", "jsonline", "[", "'article'", "]", "\n", "article", "=", "article", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "id", "=", "jsonline", "[", "'id'", "]", "\n", "for", "i", ",", "q", "in", "enumerate", "(", "questions", ")", ":", "\n", "                    ", "options", "[", "i", "]", "=", "[", "x", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "for", "x", "in", "options", "[", "i", "]", "]", "\n", "q", "=", "q", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "candidates", "=", "(", "\"\"", ".", "join", "(", "[", "f\" ({chr(ord('A') + i)}) {x}\"", "for", "i", ",", "x", "in", "enumerate", "(", "options", "[", "i", "]", ")", "]", ")", ")", ".", "replace", "(", "\n", "\"\\n\"", ",", "\" \"", ")", "\n", "answer_idx", "=", "ord", "(", "answers", "[", "i", "]", ")", "-", "ord", "(", "'A'", ")", "\n", "if", "variation", "==", "\"idx\"", ":", "\n", "                        ", "fin", ".", "write", "(", "f\"{q} \\\\n {candidates} \\\\n {article}\\t{answers[i]} \\n\"", ")", "\n", "", "elif", "variation", "==", "\"string\"", ":", "\n", "                        ", "fin", ".", "write", "(", "f\"{q} \\\\n {candidates} \\\\n {article}\\t{options[i][answer_idx]} \\n\"", ")", "\n", "", "elif", "variation", "==", "\"string_no_candidates\"", ":", "\n", "                        ", "fin", ".", "write", "(", "f\"{q} \\\\n {article} \\t {options[i][answer_idx]} \\n\"", ")", "\n", "", "else", ":", "\n", "                        ", "raise", "AttributeError", "\n", "\n", "", "fmeta", ".", "write", "(", "f\"{id}\\t{answers[i]}\\n\"", ")", "\n", "\n", "", "", "", "directory_address", "=", "f\"../datasets/RACE/{kind}/\"", "\n", "directory", "=", "os", ".", "fsencode", "(", "directory_address", ")", "\n", "for", "file", "in", "os", ".", "listdir", "(", "directory", ")", ":", "\n", "            ", "filename", "=", "os", ".", "fsdecode", "(", "file", ")", "\n", "if", "filename", ".", "endswith", "(", "\".txt\"", ")", ":", "\n", "                ", "read_and_parse_race", "(", "directory_address", "+", "filename", ")", "\n", "", "else", ":", "\n", "                ", "continue", "\n", "\n", "", "", "count_map", "[", "kind", ".", "split", "(", "\"/\"", ")", "[", "0", "]", "]", "=", "counter", "[", "\"counter\"", "]", "\n", "\n", "", "process_race_dir", "(", "f\"dev/{grade}\"", ")", "\n", "process_race_dir", "(", "f\"test/{grade}\"", ")", "\n", "process_race_dir", "(", "f\"train/{grade}\"", ")", "\n", "\n", "count_file", "=", "open", "(", "f\"race_{variation}_{grade}/counts.json\"", ",", "\"w+\"", ")", "\n", "count_file", ".", "write", "(", "json", ".", "dumps", "(", "count_map", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.newsqa": [[481, 484], ["encode_datasets.read_and_parse_multiqa", "encode_datasets.read_and_parse_multiqa"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa"], ["", "def", "newsqa", "(", ")", ":", "\n", "    ", "read_and_parse_multiqa", "(", "\"../datasets/NewsQA_dev.jsonl\"", ",", "\"newsqa\"", ",", "\"dev\"", ")", "\n", "read_and_parse_multiqa", "(", "\"../datasets/NewsQA_train.jsonl\"", ",", "\"newsqa\"", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.hotpotqa": [[486, 489], ["encode_datasets.read_and_parse_multiqa", "encode_datasets.read_and_parse_multiqa"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa"], ["", "def", "hotpotqa", "(", ")", ":", "\n", "    ", "read_and_parse_multiqa", "(", "\"../datasets/HotpotQA_dev.jsonl\"", ",", "\"hotpotqa\"", ",", "\"dev\"", ")", "\n", "read_and_parse_multiqa", "(", "\"../datasets/HotpotQA_train.jsonl\"", ",", "\"hotpotqa\"", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.squad": [[491, 494], ["encode_datasets.read_and_parse_multiqa", "encode_datasets.read_and_parse_multiqa"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa"], ["", "def", "squad", "(", ")", ":", "\n", "    ", "read_and_parse_multiqa", "(", "\"../datasets/SQuAD1-1_dev.jsonl\"", ",", "\"squad1_1\"", ",", "\"dev\"", ")", "\n", "read_and_parse_multiqa", "(", "\"../datasets/SQuAD1-1_train.jsonl\"", ",", "\"squad1_1\"", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.squad2": [[496, 499], ["encode_datasets.read_and_parse_multiqa", "encode_datasets.read_and_parse_multiqa"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa"], ["", "def", "squad2", "(", ")", ":", "\n", "    ", "read_and_parse_multiqa", "(", "\"../datasets/SQuAD2-0_dev.jsonl\"", ",", "\"squad2\"", ",", "\"dev\"", ")", "\n", "read_and_parse_multiqa", "(", "\"../datasets/SQuAD2-0_train.jsonl\"", ",", "\"squad2\"", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.triviaqa": [[501, 504], ["encode_datasets.read_and_parse_multiqa", "encode_datasets.read_and_parse_multiqa"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa"], ["", "def", "triviaqa", "(", ")", ":", "\n", "    ", "read_and_parse_multiqa", "(", "\"../datasets/TriviaQA_wiki_train.jsonl\"", ",", "\"triviaqa\"", ",", "\"train\"", ")", "\n", "read_and_parse_multiqa", "(", "\"../datasets/TriviaQA_wiki_dev.jsonl\"", ",", "\"triviaqa\"", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.searchqa": [[506, 509], ["encode_datasets.read_and_parse_multiqa", "encode_datasets.read_and_parse_multiqa"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa"], ["", "def", "searchqa", "(", ")", ":", "\n", "    ", "read_and_parse_multiqa", "(", "\"../datasets/SearchQA_dev.jsonl\"", ",", "\"searchqa\"", ",", "\"dev\"", ")", "\n", "read_and_parse_multiqa", "(", "\"../datasets/SearchQA_train.jsonl\"", ",", "\"searchqa\"", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.boolq": [[511, 514], ["encode_datasets.read_and_parse_multiqa", "encode_datasets.read_and_parse_multiqa"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa"], ["", "def", "boolq", "(", ")", ":", "\n", "    ", "read_and_parse_multiqa", "(", "\"../datasets/BoolQ_dev.jsonl\"", ",", "\"boolq\"", ",", "\"dev\"", ")", "\n", "read_and_parse_multiqa", "(", "\"../datasets/BoolQ_train.jsonl\"", ",", "\"boolq\"", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.duo_rc": [[1923, 1931], ["encode_datasets.read_and_parse_multiqa", "encode_datasets.read_and_parse_multiqa", "encode_datasets.read_and_parse_multiqa", "encode_datasets.read_and_parse_multiqa"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_and_parse_multiqa"], ["", "", "", "", "def", "duo_rc", "(", ")", ":", "\n", "    ", "read_and_parse_multiqa", "(", "\"/Users/danielk/ideaProjects/t2t-qa/datasets/DuoRC_Paraphrase_dev.jsonl\"", ",", "\n", "\"duo_rc_paraphrase\"", ",", "\"dev\"", ")", "\n", "read_and_parse_multiqa", "(", "\"/Users/danielk/ideaProjects/t2t-qa/datasets/DuoRC_Paraphrase_train.jsonl\"", ",", "\n", "\"duo_rc_paraphrase\"", ",", "\"train\"", ")", "\n", "\n", "read_and_parse_multiqa", "(", "\"/Users/danielk/ideaProjects/t2t-qa/datasets/DuoRC_Self_dev.jsonl\"", ",", "\"duo_rc_self\"", ",", "\"dev\"", ")", "\n", "read_and_parse_multiqa", "(", "\"/Users/danielk/ideaProjects/t2t-qa/datasets/DuoRC_Self_train.jsonl\"", ",", "\"duo_rc_self\"", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.drop": [[524, 578], ["encode_datasets.drop.load_file"], "function", ["None"], ["", "def", "drop", "(", ")", ":", "\n", "    ", "def", "load_file", "(", "name", ",", "dir", ")", ":", "\n", "        ", "ftargets", "=", "open", "(", "f\"{dir}/{name}_targets.txt\"", ",", "\"+w\"", ")", "\n", "finput", "=", "open", "(", "f\"{dir}/{name}_inputs.txt\"", ",", "\"+w\"", ")", "\n", "fout", "=", "open", "(", "f\"{dir}/{name}.tsv\"", ",", "\"+w\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dir}/{name}_meta.txt\"", ",", "\"+w\"", ")", "\n", "span_lens", "=", "[", "]", "\n", "with", "open", "(", "f\"../datasets/drop_dataset/drop_dataset_{name}.json\"", ")", "as", "f", ":", "\n", "            ", "whole_data", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "key", "in", "whole_data", ".", "keys", "(", ")", ":", "\n", "# print(\"------\")", "\n", "# print(key)", "\n", "                ", "content", "=", "whole_data", "[", "key", "]", "\n", "passage", "=", "content", "[", "'passage'", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "qa_pairs", "=", "content", "[", "'qa_pairs'", "]", "\n", "for", "qpair", "in", "qa_pairs", ":", "\n", "                    ", "ans_text", "=", "\"\"", "\n", "question", "=", "qpair", "[", "'question'", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "answer", "=", "qpair", "[", "'answer'", "]", "\n", "# print(answer)", "\n", "number", "=", "answer", "[", "'number'", "]", "\n", "spans", "=", "answer", "[", "'spans'", "]", "\n", "if", "len", "(", "spans", ")", ">", "0", ":", "\n", "                        ", "span_lens", ".", "append", "(", "len", "(", "spans", ")", ")", "\n", "ans_text", "=", "\", \"", ".", "join", "(", "spans", ")", "\n", "", "elif", "len", "(", "number", ")", ">", "0", ":", "\n", "                        ", "ans_text", "=", "number", "\n", "", "else", ":", "\n", "                        ", "day", "=", "answer", "[", "'date'", "]", "[", "'day'", "]", "\n", "month", "=", "answer", "[", "'date'", "]", "[", "'month'", "]", "\n", "year", "=", "answer", "[", "'date'", "]", "[", "'year'", "]", "\n", "if", "len", "(", "month", ")", ">", "0", ":", "\n", "                            ", "ans_text", "+=", "month", "\n", "", "if", "len", "(", "day", ")", ">", "0", ":", "\n", "                            ", "ans_text", "+=", "f\" {day}\"", "\n", "", "if", "len", "(", "year", ")", ">", "0", ":", "\n", "                            ", "ans_text", "+=", "f\" {year}\"", "\n", "\n", "# assert ans_text != \"\"", "\n", "# print(ans_text)", "\n", "", "", "if", "ans_text", "==", "\"\"", ":", "\n", "                        ", "print", "(", "\" >>>> skipping the question . . . \"", ")", "\n", "continue", "\n", "", "ans_text", "=", "ans_text", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "query_id", "=", "qpair", "[", "'query_id'", "]", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n {passage}\\t{ans_text}\\n\"", ")", "\n", "ftargets", ".", "write", "(", "f\"{ans_text}\\n\"", ")", "\n", "finput", ".", "write", "(", "f\"{question} \\\\n {passage}\\n\"", ")", "\n", "fmeta", ".", "write", "(", "f\" {query_id}\"", ")", "\n", "\n", "", "", "", "print", "(", "span_lens", ")", "\n", "\n", "", "load_file", "(", "\"dev\"", ",", "\"drop\"", ")", "\n", "load_file", "(", "\"train\"", ",", "\"drop\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.extract_oyvind_predictions": [[601, 612], ["open", "f.readlines", "json.loads"], "function", ["None"], ["", "def", "extract_oyvind_predictions", "(", "file", ")", ":", "\n", "    ", "all_predictions", "=", "{", "}", "\n", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "jsonline", "=", "json", ".", "loads", "(", "line", ")", "\n", "id", "=", "jsonline", "[", "'id'", "]", "\n", "if", "id", "not", "in", "all_predictions", ":", "\n", "                ", "all_predictions", "[", "id", "]", "=", "jsonline", "\n", "", "else", ":", "\n", "                ", "raise", "EnvironmentError", "\n", "", "", "", "return", "all_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.arc": [[653, 741], ["open", "open", "correctness_map.keys", "encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["def", "arc", "(", ")", ":", "\n", "    ", "directory_easy", "=", "\"ARC-V1-Feb2018-2/ARC-Easy/ARC-Easy\"", "\n", "directory_hard", "=", "\"ARC-V1-Feb2018-2/ARC-Challenge/ARC-Challenge\"", "\n", "\n", "def", "read_file", "(", "dir", ",", "split", ",", "kind", ",", "predictions_files", ",", "with_para", "=", "False", ")", ":", "\n", "        ", "outdir", "=", "f\"arc_{kind}\"", "\n", "if", "with_para", ":", "\n", "            ", "outdir", "=", "f\"arc_{kind}_with_ir\"", "\n", "", "fout", "=", "open", "(", "f\"{outdir}/{split.lower()}.tsv\"", ",", "\"w+\"", ")", "\n", "fout_meta", "=", "open", "(", "f\"{outdir}/{split.lower()}_meta.tsv\"", ",", "\"w+\"", ")", "\n", "output_files", "=", "[", "]", "\n", "if", "predictions_files", ":", "\n", "            ", "for", "x", "in", "predictions_files", ":", "\n", "                ", "fout_tmp", "=", "open", "(", "f\"arc_{kind}/predictions_{x[0]}_{split}.txt\"", ",", "\"w\"", ")", "\n", "output_files", ".", "append", "(", "fout_tmp", ")", "\n", "print", "(", "fout_tmp", ")", "\n", "\n", "", "", "correctness_map", "=", "{", "}", "\n", "with", "open", "(", "f\"{dir}-{split}.jsonl\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "json_line", "=", "json", ".", "loads", "(", "line", ")", "\n", "question", "=", "json_line", "[", "'question'", "]", "[", "'stem'", "]", "\n", "choices", "=", "json_line", "[", "'question'", "]", "[", "'choices'", "]", "\n", "if", "kind", "==", "\"easy\"", ":", "\n", "                    ", "id", "=", "\"ARCEZ_\"", "+", "json_line", "[", "'id'", "]", "\n", "", "else", ":", "\n", "                    ", "id", "=", "\"ARCCH_\"", "+", "json_line", "[", "'id'", "]", "\n", "", "para", "=", "\"\"", "\n", "if", "with_para", ":", "\n", "                    ", "print", "(", "\"done\"", ")", "\n", "para", "=", "\"\\\\n\"", "+", "oyvind_paragraphs", "[", "id", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "# print(json_line)", "\n", "", "answer_key", "=", "json_line", "[", "'answerKey'", "]", "\n", "numbers", "=", "\"\"", "\n", "if", "'A'", "in", "[", "c", "[", "'label'", "]", "for", "c", "in", "choices", "]", ":", "\n", "                    ", "answer_key_idx", "=", "ord", "(", "answer_key", "[", "0", "]", ")", "-", "ord", "(", "'A'", ")", "\n", "answer_label", "=", "answer_key", "[", "0", "]", "\n", "", "else", ":", "\n", "                    ", "answer_key_idx", "=", "ord", "(", "answer_key", "[", "0", "]", ")", "-", "ord", "(", "'1'", ")", "\n", "answer_label", "=", "chr", "(", "ord", "(", "answer_key", "[", "0", "]", ")", "-", "ord", "(", "'1'", ")", "+", "ord", "(", "'A'", ")", ")", "\n", "numbers", "=", "\"numerical\"", "\n", "\n", "", "candidates", "=", "\" \"", ".", "join", "(", "[", "f\"({chr(ord('A') + i)}) {c['text']}\"", "for", "i", ",", "c", "in", "enumerate", "(", "choices", ")", "]", ")", ".", "replace", "(", "\n", "\"\\n\"", ",", "\" \"", ")", "\n", "\n", "# print((answer_key_idx, answer_key, candidates))", "\n", "answer_text", "=", "choices", "[", "answer_key_idx", "]", "[", "'text'", "]", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n {candidates}{para}\\t{answer_text}\\n\"", ")", "\n", "fout_meta", ".", "write", "(", "f\"{json_line['id']}\\t{answer_label}\\t{numbers}\\n\"", ")", "\n", "# fout_meta.write(f\"{json_line['id']},{json_line['answerKey'][0]}\\n\")", "\n", "\n", "if", "predictions_files", ":", "\n", "                    ", "for", "i", ",", "x", "in", "enumerate", "(", "predictions_files", ")", ":", "\n", "                        ", "pred_type", "=", "x", "[", "0", "]", "\n", "predictions", "=", "x", "[", "1", "]", "\n", "fout_tmp", "=", "output_files", "[", "i", "]", "\n", "# print(f\" ** pred type: {pred_type}\")", "\n", "if", "id", "not", "in", "predictions", ":", "\n", "                            ", "print", "(", "\" >>>>> id not found . . . \"", ")", "\n", "# hack: use the gold ans", "\n", "fout_tmp", ".", "write", "(", "answer_text", "+", "\"\\n\"", ")", "\n", "", "else", ":", "\n", "                            ", "pred_json", "=", "predictions", "[", "id", "]", "\n", "\n", "choice_text_list", "=", "pred_json", "[", "'choice_text_list'", "]", "\n", "correct_answer_index", "=", "pred_json", "[", "'correct_answer_index'", "]", "\n", "# label_probs = pred_json['label_probs']", "\n", "answer_index", "=", "pred_json", "[", "'answer_index'", "]", "\n", "fout_tmp", ".", "write", "(", "choice_text_list", "[", "answer_index", "]", "+", "\"\\n\"", ")", "\n", "\n", "if", "pred_type", "not", "in", "correctness_map", ":", "\n", "                                ", "correctness_map", "[", "pred_type", "]", "=", "[", "]", "\n", "", "correctness_map", "[", "pred_type", "]", ".", "append", "(", "1.0", "if", "answer_index", "==", "correct_answer_index", "else", "0.0", ")", "\n", "\n", "", "", "", "", "", "for", "pred_type", "in", "correctness_map", ".", "keys", "(", ")", ":", "\n", "            ", "if", "len", "(", "correctness_map", "[", "pred_type", "]", ")", ">", "0", ":", "\n", "                ", "print", "(", "len", "(", "correctness_map", "[", "pred_type", "]", ")", ")", "\n", "print", "(", "\n", "f\" **** Accuracy on {split} of ARC-{kind} ({pred_type}): {sum(correctness_map[pred_type]) / len(correctness_map[pred_type])}\"", ")", "\n", "\n", "", "", "", "for", "with_para", "in", "[", "True", ",", "False", "]", ":", "\n", "        ", "read_file", "(", "directory_easy", ",", "\"Dev\"", ",", "\"easy\"", ",", "oyvind_dev_preds", ",", "with_para", ")", "\n", "read_file", "(", "directory_easy", ",", "\"Test\"", ",", "\"easy\"", ",", "oyvind_test_preds", ",", "with_para", ")", "\n", "read_file", "(", "directory_easy", ",", "\"Train\"", ",", "\"easy\"", ",", "None", ",", "with_para", ")", "\n", "\n", "read_file", "(", "directory_hard", ",", "\"Dev\"", ",", "\"hard\"", ",", "oyvind_dev_preds", ",", "with_para", ")", "\n", "read_file", "(", "directory_hard", ",", "\"Test\"", ",", "\"hard\"", ",", "oyvind_test_preds", ",", "with_para", ")", "\n", "read_file", "(", "directory_hard", ",", "\"Train\"", ",", "\"hard\"", ",", "None", ",", "with_para", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.ai2_science": [[743, 770], ["encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["", "", "def", "ai2_science", "(", ")", ":", "\n", "    ", "directory_middle", "=", "\"../datasets/AI2-ScienceQuestions-V2.1-Jan2018/MiddleSchool/Middle-\"", "\n", "directory_elementary", "=", "\"../datasets/AI2-ScienceQuestions-V2.1-Jan2018/ElementarySchool/Elementary-\"", "\n", "\n", "def", "read_file", "(", "dir", ",", "split", ",", "grade", ")", ":", "\n", "        ", "fout", "=", "open", "(", "f\"ai2_science_{grade.lower()}/{split}.tsv\"", ".", "lower", "(", ")", ",", "\"w+\"", ")", "\n", "foutmeta", "=", "open", "(", "f\"ai2_science_{grade.lower()}/{split}_meta.tsv\"", ".", "lower", "(", ")", ",", "\"w+\"", ")", "\n", "with", "open", "(", "f\"{dir}NDMC-{split.lower()}.jsonl\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "json_line", "=", "json", ".", "loads", "(", "line", ")", "\n", "question", "=", "json_line", "[", "'question'", "]", "[", "'stem'", "]", "\n", "choices", "=", "json_line", "[", "'question'", "]", "[", "'choices'", "]", "\n", "candidates", "=", "\" \"", ".", "join", "(", "[", "f\"({c['label']}) {c['text']}\"", "for", "c", "in", "choices", "]", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "print", "(", "json_line", ")", "\n", "answer_key", "=", "json_line", "[", "'answerKey'", "]", "\n", "answer_key_idx", "=", "ord", "(", "answer_key", "[", "0", "]", ")", "-", "ord", "(", "'A'", ")", "\n", "answer_text", "=", "choices", "[", "answer_key_idx", "]", "[", "'text'", "]", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n {candidates}\\t{answer_text}\\n\"", ")", "\n", "foutmeta", ".", "write", "(", "f\"{json_line['id']}\\t{answer_key[0]}\\n\"", ")", "\n", "\n", "", "", "", "read_file", "(", "directory_middle", ",", "\"Dev\"", ",", "\"Middle\"", ")", "\n", "read_file", "(", "directory_middle", ",", "\"Test\"", ",", "\"Middle\"", ")", "\n", "read_file", "(", "directory_middle", ",", "\"Train\"", ",", "\"Middle\"", ")", "\n", "\n", "read_file", "(", "directory_elementary", ",", "\"Dev\"", ",", "\"Elementary\"", ")", "\n", "read_file", "(", "directory_elementary", ",", "\"Test\"", ",", "\"Elementary\"", ")", "\n", "read_file", "(", "directory_elementary", ",", "\"Train\"", ",", "\"Elementary\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.quoref": [[772, 796], ["encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["", "def", "quoref", "(", ")", ":", "\n", "    ", "def", "read_file", "(", "file", ",", "segment", ")", ":", "\n", "        ", "fout", "=", "open", "(", "f\"quoref/{segment}.tsv\"", ",", "\"w+\"", ")", "\n", "ftargets", "=", "open", "(", "f\"quoref/{segment}_targets.txt\"", ",", "\"+w\"", ")", "\n", "finputs", "=", "open", "(", "f\"quoref/{segment}_inputs.txt\"", ",", "\"+w\"", ")", "\n", "ans_size", "=", "[", "]", "\n", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "            ", "file", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "section", "in", "file", "[", "'data'", "]", ":", "\n", "                ", "title", "=", "section", "[", "'title'", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "for", "para", "in", "section", "[", "'paragraphs'", "]", ":", "\n", "                    ", "context", "=", "para", "[", "'context'", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "for", "qa", "in", "para", "[", "'qas'", "]", ":", "\n", "                        ", "question", "=", "qa", "[", "'question'", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "ans_size", ".", "append", "(", "len", "(", "qa", "[", "'answers'", "]", ")", ")", "\n", "for", "a", "in", "qa", "[", "'answers'", "]", ":", "\n", "                            ", "answer", "=", "a", "[", "'text'", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n ({title}) {context}\\t{answer}\\n\"", ")", "\n", "ftargets", ".", "write", "(", "f\"{answer}\\n\"", ")", "\n", "finputs", ".", "write", "(", "f\"{question} \\\\n ({title}) {context}\\n\"", ")", "\n", "", "", "", "", "", "print", "(", "sum", "(", "ans_size", ")", "/", "len", "(", "ans_size", ")", ")", "\n", "\n", "", "read_file", "(", "\"../datasets/quoref-train-dev-v0.1/quoref-dev-v0.1.json\"", ",", "\"dev\"", ")", "\n", "read_file", "(", "\"../datasets/quoref-train-dev-v0.1/quoref-train-v0.1.json\"", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.ropes": [[798, 820], ["encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["", "def", "ropes", "(", ")", ":", "\n", "    ", "def", "read_file", "(", "file", ",", "segment", ")", ":", "\n", "        ", "ans_size", "=", "[", "]", "\n", "fout", "=", "open", "(", "f\"ropes/{segment}.tsv\"", ",", "\"w+\"", ")", "\n", "ftargets", "=", "open", "(", "f\"ropes/{segment}_targets.txt\"", ",", "\"+w\"", ")", "\n", "finput", "=", "open", "(", "f\"ropes/{segment}_inputs.txt\"", ",", "\"+w\"", ")", "\n", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "            ", "file", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "section", "in", "file", "[", "'data'", "]", ":", "\n", "                ", "for", "para", "in", "section", "[", "'paragraphs'", "]", ":", "\n", "                    ", "context", "=", "f\"{para['background']} {para['situation']}\"", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "for", "qa", "in", "para", "[", "'qas'", "]", ":", "\n", "                        ", "question", "=", "qa", "[", "'question'", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "ans_size", ".", "append", "(", "len", "(", "qa", "[", "'answers'", "]", ")", ")", "\n", "for", "a", "in", "qa", "[", "'answers'", "]", ":", "\n", "                            ", "answer", "=", "a", "[", "'text'", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n {context}\\t{answer}\\n\"", ")", "\n", "ftargets", ".", "write", "(", "f\"{answer}\\n\"", ")", "\n", "finput", ".", "write", "(", "f\"{question} \\\\n {context}\\n\"", ")", "\n", "\n", "", "", "", "", "", "", "read_file", "(", "\"../datasets/ropes-train-dev-v1.0/dev-v1.0.json\"", ",", "\"dev\"", ")", "\n", "read_file", "(", "\"../datasets/ropes-train-dev-v1.0/train-v1.0.json\"", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.narrative_qa": [[822, 864], ["open", "open", "open", "open", "open.write", "open", "csv.reader", "enumerate", "open", "csv.reader", "enumerate", "json.dumps", "print", "line[].replace", "print", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "print"], "function", ["None"], ["", "def", "narrative_qa", "(", ")", ":", "\n", "    ", "paragraphs", "=", "{", "}", "\n", "with", "open", "(", "\"../datasets/narrativeqa/third_party/wikipedia/summaries.csv\"", ")", "as", "f", ":", "\n", "        ", "spamreader", "=", "csv", ".", "reader", "(", "f", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "spamreader", ")", ":", "\n", "            ", "print", "(", "line", ")", "\n", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "paragraphs", "[", "line", "[", "0", "]", "]", "=", "line", "[", "2", "]", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "\n", "", "", "fout_test", "=", "open", "(", "f\"narrativeqa/test.tsv\"", ",", "\"w+\"", ")", "\n", "fout_train", "=", "open", "(", "f\"narrativeqa/train.tsv\"", ",", "\"w+\"", ")", "\n", "fout_dev", "=", "open", "(", "f\"narrativeqa/dev.tsv\"", ",", "\"w+\"", ")", "\n", "counts", "=", "open", "(", "f\"narrativeqa/counts.json\"", ",", "\"w+\"", ")", "\n", "\n", "count_train", "=", "0", "\n", "count_test", "=", "0", "\n", "count_dev", "=", "0", "\n", "with", "open", "(", "\"..//datasets/narrativeqa/qaps.csv\"", ")", "as", "f", ":", "\n", "        ", "spamreader", "=", "csv", ".", "reader", "(", "f", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "spamreader", ")", ":", "\n", "            ", "print", "(", "line", ")", "\n", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "line1", "=", "f\"{line[2]} \\\\n {paragraphs[line[0]]} \\t {line[3]} \\n\"", "\n", "line2", "=", "f\"{line[2]} \\\\n {paragraphs[line[0]]} \\t {line[4]} \\n\"", "\n", "if", "line", "[", "1", "]", "==", "\"train\"", ":", "\n", "                ", "fout_train", ".", "write", "(", "line1", ")", "\n", "fout_train", ".", "write", "(", "line2", ")", "\n", "count_train", "+=", "1", "\n", "", "elif", "line", "[", "1", "]", "==", "\"test\"", ":", "\n", "                ", "fout_test", ".", "write", "(", "line1", ")", "\n", "fout_test", ".", "write", "(", "line2", ")", "\n", "count_test", "+=", "1", "\n", "", "elif", "line", "[", "1", "]", "==", "\"valid\"", ":", "\n", "                ", "fout_dev", ".", "write", "(", "line1", ")", "\n", "fout_dev", ".", "write", "(", "line2", ")", "\n", "count_dev", "+=", "1", "\n", "", "else", ":", "\n", "                ", "print", "(", "\" >>>> ERROR \"", ")", "\n", "\n", "", "", "", "counts", ".", "write", "(", "json", ".", "dumps", "(", "{", "\"train\"", ":", "count_train", ",", "\"dev\"", ":", "count_dev", ",", "\"test\"", ":", "count_test", "}", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.multirc": [[866, 887], ["encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["", "def", "multirc", "(", ")", ":", "\n", "    ", "def", "read_file", "(", "file", ")", ":", "\n", "        ", "lines", "=", "[", "]", "\n", "with", "open", "(", "f\"../datasets/multirc/{file}\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "line_split", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "paragraph", "=", "line_split", "[", "4", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "question", "=", "line_split", "[", "5", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "line_split", "[", "6", "]", "=", "line_split", "[", "6", "]", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "assert", "line_split", "[", "6", "]", "==", "\"True\"", "or", "line_split", "[", "6", "]", "==", "\"False\"", ",", "f\"`{line_split[6]}`\"", "\n", "answer", "=", "\"yes\"", "if", "line_split", "[", "6", "]", "==", "\"True\"", "else", "\"no\"", "\n", "lines", ".", "append", "(", "f\"{question} \\\\n {paragraph}\\t{answer}\\n\"", ")", "\n", "", "", "return", "lines", "\n", "\n", "", "lines1", "=", "read_file", "(", "\"dev_83-fixedIds.json.yes-nos.tsv\"", ")", "\n", "lines2", "=", "read_file", "(", "\"train_456-fixedIds.json.yes-nos.tsv\"", ")", "\n", "fout", "=", "open", "(", "f\"multirc/dev.tsv\"", ",", "\"w+\"", ")", "\n", "fout2", "=", "open", "(", "f\"multirc/train.tsv\"", ",", "\"w+\"", ")", "\n", "for", "line", "in", "lines1", "+", "lines2", ":", "\n", "        ", "fout", ".", "write", "(", "line", ")", "\n", "fout2", ".", "write", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.openbookqa": [[889, 954], ["open", "open", "encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["", "", "def", "openbookqa", "(", ")", ":", "\n", "    ", "def", "read_file", "(", "file", ",", "split", ",", "predictions_files", ",", "with_para", "=", "False", ")", ":", "\n", "        ", "out_dir", "=", "\"openbookqa\"", "\n", "if", "with_para", ":", "\n", "            ", "out_dir", "=", "\"openbookqa_with_ir\"", "\n", "", "fout", "=", "open", "(", "f\"{out_dir}/{split}.tsv\"", ",", "\"w+\"", ")", "\n", "fout_meta", "=", "open", "(", "f\"{out_dir}/{split}_meta.tsv\"", ",", "\"w+\"", ")", "\n", "output_files", "=", "[", "]", "\n", "oyind_accuracy", "=", "{", "}", "\n", "if", "predictions_files", ":", "\n", "            ", "fout_target_tmp", "=", "open", "(", "f\"openbookqa/oyvind/_target.txt\"", ",", "\"w\"", ")", "\n", "for", "x", "in", "predictions_files", ":", "\n", "                ", "fout_tmp", "=", "open", "(", "f\"openbookqa/oyvind/predictions_{x[0]}_{split}.txt\"", ",", "\"w\"", ")", "\n", "output_files", ".", "append", "(", "fout_tmp", ")", "\n", "# print(fout_tmp)", "\n", "oyind_accuracy", "[", "x", "]", "=", "[", "]", "\n", "\n", "", "", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "json_line", "=", "json", ".", "loads", "(", "line", ")", "\n", "question", "=", "json_line", "[", "'question'", "]", "[", "'stem'", "]", "\n", "choices", "=", "json_line", "[", "'question'", "]", "[", "'choices'", "]", "\n", "candidates", "=", "\" \"", ".", "join", "(", "[", "f\"({c['label']}) {c['text']}\"", "for", "c", "in", "choices", "]", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "print", "(", "json_line", ")", "\n", "answer_key", "=", "json_line", "[", "'answerKey'", "]", "\n", "answer_key_idx", "=", "ord", "(", "answer_key", "[", "0", "]", ")", "-", "ord", "(", "'A'", ")", "\n", "answer_text", "=", "choices", "[", "answer_key_idx", "]", "[", "'text'", "]", "\n", "id", "=", "\"OBQA_\"", "+", "json_line", "[", "'id'", "]", "\n", "para", "=", "\"\"", "\n", "if", "with_para", ":", "\n", "                    ", "para", "=", "\"\\\\n\"", "+", "oyvind_paragraphs", "[", "id", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "", "fout", ".", "write", "(", "f\"{question} \\\\n {candidates}{para}\\t{answer_text}\\n\"", ")", "\n", "fout_meta", ".", "write", "(", "f\"{json_line['id']}\\t{answer_key[0]}\\n\"", ")", "\n", "if", "predictions_files", ":", "\n", "                    ", "fout_target_tmp", ".", "write", "(", "f\"{answer_text}\\n\"", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "predictions_files", ")", ":", "\n", "                        ", "pred_type", "=", "x", "[", "0", "]", "\n", "predictions", "=", "x", "[", "1", "]", "\n", "fout_tmp", "=", "output_files", "[", "i", "]", "\n", "# print(f\" ** pred type: {pred_type}\")", "\n", "if", "id", "not", "in", "predictions", ":", "\n", "                            ", "print", "(", "\" >>>>> id not found . . . \"", ")", "\n", "# hack: use the gold ans", "\n", "fout_tmp", ".", "write", "(", "answer_text", "+", "\"\\n\"", ")", "\n", "", "else", ":", "\n", "                            ", "pred_json", "=", "predictions", "[", "id", "]", "\n", "\n", "choice_text_list", "=", "pred_json", "[", "'choice_text_list'", "]", "\n", "# correct_answer_index = pred_json['correct_answer_index']", "\n", "answer_index", "=", "pred_json", "[", "'answer_index'", "]", "\n", "fout_tmp", ".", "write", "(", "choice_text_list", "[", "answer_index", "]", "+", "\"\\n\"", ")", "\n", "if", "answer_index", "==", "answer_key_idx", ":", "\n", "                                ", "oyind_accuracy", "[", "x", "]", ".", "append", "(", "1.0", ")", "\n", "", "else", ":", "\n", "                                ", "oyind_accuracy", "[", "x", "]", ".", "append", "(", "0.0", ")", "\n", "\n", "", "", "", "", "", "if", "predictions_files", ":", "\n", "                ", "for", "x", "in", "predictions_files", ":", "\n", "                    ", "print", "(", "f\" *** {x} \\t accuracy: {sum(predictions_files[x]) / len(predictions_files)} \"", ")", "\n", "\n", "", "", "", "", "for", "with_para", "in", "[", "True", ",", "False", "]", ":", "\n", "        ", "read_file", "(", "\"../datasets/OpenBookQA-V1-Sep2018/Data/Main/dev.jsonl\"", ",", "\"dev\"", ",", "None", ",", "with_para", ")", "\n", "# read_file(\"../datasets/OpenBookQA-V1-Sep2018/Data/Main/test.jsonl\", \"test\", oyvind_test_preds, with_para)", "\n", "read_file", "(", "\"../datasets/OpenBookQA-V1-Sep2018/Data/Main/test.jsonl\"", ",", "\"test\"", ",", "None", ",", "with_para", ")", "\n", "read_file", "(", "\"../datasets/OpenBookQA-V1-Sep2018/Data/Main/train.jsonl\"", ",", "\"train\"", ",", "None", ",", "with_para", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.boolq_np": [[956, 969], ["open", "open", "open", "f.readlines", "json.loads", "outfile[].write"], "function", ["None"], ["", "", "def", "boolq_np", "(", ")", ":", "\n", "    ", "outfile", "=", "{", "\n", "\"dev\"", ":", "open", "(", "\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/boolq-np/dev.tsv\"", ",", "\"w\"", ")", ",", "\n", "\"train\"", ":", "open", "(", "\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/boolq-np/train.tsv\"", ",", "\"w\"", ")", ",", "\n", "}", "\n", "with", "open", "(", "\"boolq_natural_perturbations.jsonl\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "json_line", "=", "json", ".", "loads", "(", "line", ")", "\n", "# print(json_line['split'])", "\n", "if", "json_line", "[", "'is_seed_question'", "]", "==", "1", ":", "\n", "                ", "json_line", "[", "'question'", "]", "+=", "'?'", "\n", "", "label", "=", "\"yes\"", "if", "json_line", "[", "'hard_label'", "]", "==", "\"True\"", "else", "\"no\"", "\n", "outfile", "[", "json_line", "[", "'split'", "]", "]", ".", "write", "(", "f\"{json_line['question']}\\\\n{json_line['passage']}\\t{label}\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_paragraphs": [[971, 979], ["open", "f.readlines", "json.loads"], "function", ["None"], ["", "", "", "def", "read_paragraphs", "(", "file", ")", ":", "\n", "    ", "map", "=", "{", "}", "\n", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "json_line", "=", "json", ".", "loads", "(", "line", ")", "\n", "map", "[", "json_line", "[", "'id'", "]", "]", "=", "json_line", "[", "'para'", "]", "\n", "\n", "", "", "return", "map", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.ambigqa": [[990, 1033], ["encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["def", "ambigqa", "(", ")", ":", "\n", "    ", "def", "read_file", "(", "file", ",", "dir", ",", "split", ")", ":", "\n", "        ", "outfile", "=", "open", "(", "f\"{dir}/{split}.tsv\"", ",", "\"+w\"", ")", "\n", "outfile_meta", "=", "open", "(", "f\"{dir}/{split}_meta.tsv\"", ",", "\"+w\"", ")", "\n", "size", "=", "0", "\n", "with", "open", "(", "file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "json_file", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "item", "in", "tqdm", "(", "json_file", ")", ":", "\n", "                ", "question", "=", "item", "[", "'question'", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "single_answers_already_included", "=", "[", "]", "\n", "for", "anno", "in", "item", "[", "\"annotations\"", "]", ":", "\n", "                    ", "if", "anno", "[", "'type'", "]", "==", "\"singleAnswer\"", ":", "\n", "                        ", "for", "ans", "in", "anno", "[", "'answer'", "]", ":", "\n", "                            ", "if", "ans", "not", "in", "single_answers_already_included", ":", "\n", "                                ", "ans", "=", "ans", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "outfile", ".", "write", "(", "f\"{question}\\t{ans}\\n\"", ")", "\n", "outfile_meta", ".", "write", "(", "item", "[", "'id'", "]", "+", "\"\\n\"", ")", "\n", "single_answers_already_included", ".", "append", "(", "ans", ")", "\n", "size", "+=", "1", "\n", "", "", "", "else", ":", "\n", "                        ", "answers", "=", "[", "]", "\n", "for", "x", "in", "anno", "[", "'qaPairs'", "]", ":", "\n", "                            ", "answers", ".", "append", "(", "x", "[", "'answer'", "]", "[", "0", "]", ")", "\n", "\n", "", "answers", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "answers", "]", "\n", "answers", "=", "list", "(", "set", "(", "answers", ")", ")", "# to drop duplicate answers", "\n", "for", "i", ",", "ordering", "in", "enumerate", "(", "itertools", ".", "permutations", "(", "answers", ")", ")", ":", "\n", "                            ", "if", "i", ">=", "3", ":", "\n", "                                ", "break", "\n", "", "ans_str", "=", "\" [SEP] \"", ".", "join", "(", "ordering", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "outfile", ".", "write", "(", "f\"{question}\\t{ans_str}\\n\"", ")", "\n", "outfile_meta", ".", "write", "(", "item", "[", "'id'", "]", "+", "\"\\n\"", ")", "\n", "size", "+=", "1", "\n", "", "", "", "", "", "return", "size", "\n", "\n", "", "count_dev", "=", "read_file", "(", "\"ambignq_light/dev_light.json\"", ",", "\"ambigqa\"", ",", "\"dev\"", ")", "\n", "count_train", "=", "read_file", "(", "\"ambignq_light/train_light.json\"", ",", "\"ambigqa\"", ",", "\n", "\"train\"", ")", "\n", "count_test", "=", "0", "\n", "\n", "# Create TSVs and get counts.", "\n", "with", "open", "(", "\"ambigqa/counts.json\"", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "count_train", ",", "\"dev\"", ":", "count_dev", ",", "\"test\"", ":", "count_test", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.natural_questions_direct_answer": [[1035, 1084], ["encode_datasets.read_natural_questions_paragraphs", "print", "open", "open", "encode_datasets.commonsenseqa.read_file"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_natural_questions_paragraphs"], ["", "", "def", "natural_questions_direct_answer", "(", ")", ":", "\n", "\n", "    ", "question_to_para_map", "=", "read_natural_questions_paragraphs", "(", ")", "\n", "\n", "def", "read_file", "(", "in_fname", ",", "dir", ",", "split", ",", "with_paragraphs", "=", "False", ",", "aggregared_ans", "=", "False", ")", ":", "\n", "        ", "outfile", "=", "open", "(", "f\"{dir}/{split}.tsv\"", ",", "\"+w\"", ")", "\n", "outfile_meta", "=", "open", "(", "f\"{dir}/{split}_meta.tsv\"", ",", "\"+w\"", ")", "\n", "with", "open", "(", "in_fname", ")", "as", "f", ":", "\n", "            ", "json_file", "=", "json", ".", "load", "(", "f", ")", "\n", "size", "=", "0", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "json_file", ")", ":", "\n", "                ", "id", "=", "item", "[", "'id'", "]", "\n", "question", "=", "item", "[", "'question'", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "if", "\"?\"", "not", "in", "question", ":", "\n", "                    ", "question", "+=", "\"?\"", "\n", "", "para", "=", "\"\"", "\n", "if", "with_paragraphs", ":", "\n", "                    ", "para", "=", "question_to_para_map", "[", "f\"{split}-{i}\"", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"[SEP]\"", ",", "\"-\"", ")", ".", "replace", "(", "\"[sep]\"", ",", "\"-\"", ")", "\n", "para", "=", "\" \"", ".", "join", "(", "para", ".", "split", "(", "\" \"", ")", "[", "1", ":", "600", "]", ")", "# take the subset", "\n", "para", "=", "\"\\\\n\"", "+", "para", "\n", "", "if", "aggregared_ans", ":", "\n", "                    ", "answers", "=", "[", "answer", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "for", "answer", "in", "item", "[", "'answer'", "]", "]", "\n", "random", ".", "shuffle", "(", "answers", ")", "\n", "concatenated_answers", "=", "\"///\"", ".", "join", "(", "answers", ")", "\n", "outfile", ".", "write", "(", "f\"{question}{para}\\t{concatenated_answers}\\t{answers[0]}\\n\"", ")", "\n", "outfile_meta", ".", "write", "(", "f\"{id}\\n\"", ")", "\n", "size", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "for", "answer", "in", "item", "[", "'answer'", "]", ":", "\n", "                        ", "answer", "=", "answer", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "outfile", ".", "write", "(", "f\"{question}{para}\\t{answer}\\n\"", ")", "\n", "outfile_meta", ".", "write", "(", "f\"{id}\\n\"", ")", "\n", "size", "+=", "1", "\n", "", "", "", "", "return", "size", "\n", "\n", "", "print", "(", "\"Generating NQ TSVs.\"", ")", "\n", "# Create TSVs and get counts.", "\n", "for", "dir", "in", "[", "'natural_questions_direct_ans_aggregated'", "]", ":", "# ['natural_questions_direct_ans', 'natural_questions_with_dpr_para']:", "\n", "        ", "with_para", "=", "True", "if", "\"dpr\"", "in", "dir", "else", "False", "\n", "aggregared_ans", "=", "True", "if", "\"aggregated\"", "in", "dir", "else", "False", "\n", "count_dev", "=", "read_file", "(", "\"../datasets/nq/nqopen/nqopen-dev.json\"", ",", "dir", ",", "\"dev\"", ",", "with_para", ",", "aggregared_ans", ")", "\n", "count_train", "=", "read_file", "(", "\"../datasets/nq/nqopen/nqopen-train.json\"", ",", "dir", ",", "\"train\"", ",", "with_para", ",", "aggregared_ans", ")", "\n", "with", "open", "(", "dir", "+", "\"/counts.json\"", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "            ", "json", ".", "dump", "(", "{", "\"train\"", ":", "count_train", ",", "\"dev\"", ":", "count_dev", "}", ",", "outfile", ")", "\n", "\n", "", "count_train", "=", "read_file", "(", "\"../datasets/nq/nqopen/nqopen-train.json\"", ",", "dir", "+", "\"_test\"", ",", "\"train\"", ",", "with_para", ",", "aggregared_ans", ")", "\n", "count_test", "=", "read_file", "(", "\"../datasets/nq/nqopen/nqopen-test.json\"", ",", "dir", "+", "\"_test\"", ",", "\"test\"", ",", "with_para", ",", "aggregared_ans", ")", "\n", "with", "open", "(", "dir", "+", "\"_test\"", "+", "\"/counts.json\"", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "            ", "json", ".", "dump", "(", "{", "\"train\"", ":", "count_train", ",", "\"test\"", ":", "count_test", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.read_natural_questions_paragraphs": [[1086, 1099], ["encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["", "", "", "def", "read_natural_questions_paragraphs", "(", ")", ":", "\n", "    ", "question_to_para_map", "=", "{", "}", "\n", "def", "read_file", "(", "file", ",", "split", ")", ":", "\n", "        ", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "            ", "json_file", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "json_file", ")", ":", "\n", "                ", "question_to_para_map", "[", "f\"{split}-{i}\"", "]", "=", "item", "[", "'context'", "]", "\n", "\n", "", "", "", "read_file", "(", "\"../datasets/nq-dpr-output/train.json\"", ",", "\"train\"", ")", "\n", "read_file", "(", "\"../datasets/nq-dpr-output/test.json\"", ",", "\"test\"", ")", "\n", "read_file", "(", "\"../datasets/nq-dpr-output/dev.json\"", ",", "\"dev\"", ")", "\n", "\n", "return", "question_to_para_map", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.natural_questions_reading_comprehension": [[1101, 1146], ["encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["", "def", "natural_questions_reading_comprehension", "(", ")", ":", "\n", "    ", "def", "read_file", "(", "in_fname", ",", "out_fname", ")", ":", "\n", "\n", "        ", "def", "extract_answer", "(", "tokens", ",", "span", ")", ":", "\n", "            ", "\"\"\"Reconstruct answer from token span and remove extra spaces.\"\"\"", "\n", "start", ",", "end", "=", "span", "[", "\"start_token\"", "]", ",", "span", "[", "\"end_token\"", "]", "\n", "ans", "=", "\" \"", ".", "join", "(", "tokens", "[", "start", ":", "end", "]", ")", "\n", "# Remove incorrect spacing around punctuation.", "\n", "ans", "=", "ans", ".", "replace", "(", "\" ,\"", ",", "\",\"", ")", ".", "replace", "(", "\" .\"", ",", "\".\"", ")", ".", "replace", "(", "\" %\"", ",", "\"%\"", ")", "\n", "ans", "=", "ans", ".", "replace", "(", "\" - \"", ",", "\"-\"", ")", ".", "replace", "(", "\" : \"", ",", "\":\"", ")", ".", "replace", "(", "\" / \"", ",", "\"/\"", ")", "\n", "ans", "=", "ans", ".", "replace", "(", "\"( \"", ",", "\"(\"", ")", ".", "replace", "(", "\" )\"", ",", "\")\"", ")", "\n", "ans", "=", "ans", ".", "replace", "(", "\"`` \"", ",", "\"\\\"\"", ")", ".", "replace", "(", "\" ''\"", ",", "\"\\\"\"", ")", "\n", "ans", "=", "ans", ".", "replace", "(", "\" 's\"", ",", "\"'s\"", ")", ".", "replace", "(", "\"s ' \"", ",", "\"s' \"", ")", "\n", "return", "ans", "\n", "\n", "", "count", "=", "0", "\n", "with", "open", "(", "in_fname", ",", "\"r\"", ")", "as", "infile", ",", "open", "(", "out_fname", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "            ", "for", "line", "in", "infile", ".", "readlines", "(", ")", ":", "\n", "                ", "ex", "=", "json", ".", "loads", "(", "line", ")", "\n", "# Remove any examples with more than one answer.", "\n", "if", "len", "(", "ex", "[", "'annotations'", "]", "[", "0", "]", "[", "'short_answers'", "]", ")", "!=", "1", ":", "\n", "                    ", "continue", "\n", "# Questions in NQ do not include a question mark.", "\n", "", "question", "=", "ex", "[", "\"question_text\"", "]", "+", "\"?\"", "\n", "answer_span", "=", "ex", "[", "'annotations'", "]", "[", "0", "]", "[", "'short_answers'", "]", "[", "0", "]", "\n", "# Handle the two document formats in NQ (tokens or text).", "\n", "if", "\"document_tokens\"", "in", "ex", ":", "\n", "                    ", "tokens", "=", "[", "t", "[", "\"token\"", "]", "for", "t", "in", "ex", "[", "\"document_tokens\"", "]", "]", "\n", "", "elif", "\"document_text\"", "in", "ex", ":", "\n", "                    ", "tokens", "=", "ex", "[", "\"document_text\"", "]", ".", "split", "(", "\" \"", ")", "\n", "", "answer", "=", "extract_answer", "(", "tokens", ",", "answer_span", ")", "\n", "# Write this line as <question>\\t<answer>", "\n", "outfile", ".", "write", "(", "\"%s\\t%s\\n\"", "%", "(", "question", ",", "answer", ")", ")", "\n", "count", "+=", "1", "\n", "if", "count", "%", "1000", "==", "1", ":", "\n", "                    ", "print", "(", "f\"Wrote {count} examples to {out_fname}.\"", ")", "\n", "", "", "return", "count", "\n", "\n", "", "", "count_dev", "=", "read_file", "(", "\"../datasets/dev-all.jsonl\"", ",", "\"natural_questions/dev.tsv\"", ")", "\n", "count_train", "=", "read_file", "(", "\"../datasets/nq-train.jsonl\"", ",", "\"natural_questions/train.tsv\"", ")", "\n", "\n", "# Create TSVs and get counts.", "\n", "print", "(", "\"Generating NQ TSVs.\"", ")", "\n", "with", "open", "(", "\"natural_questions/counts.json\"", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "count_train", ",", "\"dev\"", ":", "count_dev", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.winogrande": [[1148, 1196], ["encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["", "", "def", "winogrande", "(", ")", ":", "\n", "    ", "def", "read_file", "(", "size", ",", "split", ",", "outfolder", ")", ":", "\n", "        ", "counter", "=", "0", "\n", "outfile", "=", "open", "(", "f\"{outfolder}/{split}.tsv\"", ",", "\"w+\"", ")", "\n", "outfile_meta", "=", "open", "(", "f\"{outfolder}/{split}_meta.tsv\"", ",", "\"w+\"", ")", "\n", "file_name", "=", "f\"{split}_{size}.jsonl\"", "\n", "# label_file_name = f\"{split}_{size}-labels.lst\"", "\n", "if", "split", "!=", "\"train\"", ":", "\n", "            ", "file_name", "=", "f\"{split}.jsonl\"", "\n", "# label_file_name = f\"{split}-labels.lst\"", "\n", "\n", "", "with", "open", "(", "f\"winogrande_1.1/{file_name}\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "json_line", "=", "json", ".", "loads", "(", "line", ")", "\n", "qID", "=", "json_line", "[", "'qID'", "]", "\n", "sentence", "=", "json_line", "[", "'sentence'", "]", "\n", "option1", "=", "json_line", "[", "'option1'", "]", "\n", "option2", "=", "json_line", "[", "'option2'", "]", "\n", "ans", "=", "\"\"", "\n", "idx", "=", "\"-\"", "\n", "idx_string", "=", "\"-\"", "\n", "if", "'answer'", "in", "json_line", ":", "\n", "                    ", "idx", "=", "json_line", "[", "'answer'", "]", "\n", "ans", "=", "option1", "\n", "assert", "idx", "==", "\"1\"", "or", "idx", "==", "\"2\"", "\n", "if", "idx", "==", "\"2\"", ":", "\n", "                        ", "ans", "=", "option2", "\n", "idx_string", "=", "\"B\"", "\n", "", "else", ":", "\n", "                        ", "idx_string", "=", "\"A\"", "\n", "", "", "outfile", ".", "write", "(", "f\"{sentence} \\\\n (A) {option1} (B) {option2} \\t {ans} \\n\"", ")", "\n", "outfile_meta", ".", "write", "(", "f\"{qID}\\t{idx_string}\\t numeric \\t {ans} \\n\"", ")", "\n", "\n", "counter", "+=", "1", "\n", "", "", "return", "counter", "\n", "\n", "", "for", "size", "in", "[", "\"xs\"", ",", "\"s\"", ",", "\"m\"", ",", "\"l\"", ",", "\"xl\"", "]", ":", "\n", "        ", "train_count", "=", "read_file", "(", "size", ",", "\"train\"", ",", "f\"winogrande_{size}\"", ")", "\n", "dev_count", "=", "read_file", "(", "size", ",", "\"dev\"", ",", "f\"winogrande_{size}\"", ")", "\n", "# test_count = read_file(size, \"test\")", "\n", "\n", "with", "open", "(", "f\"winogrande_{size}/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "            ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"dev\"", ":", "dev_count", "}", ",", "outfile", ")", "\n", "\n", "", "", "train_count", "=", "read_file", "(", "\"s\"", ",", "\"train\"", ",", "f\"winogrande_test\"", ")", "\n", "test_count", "=", "read_file", "(", "\"s\"", ",", "\"test\"", ",", "f\"winogrande_test\"", ")", "\n", "with", "open", "(", "f\"winogrande_test/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"test\"", ":", "test_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.anlg": [[1197, 1224], ["encode_datasets.anlg.readfile"], "function", ["None"], ["", "", "def", "anlg", "(", ")", ":", "\n", "    ", "director", "=", "\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/anlg_dev/\"", "\n", "def", "readfile", "(", "inputfile", ",", "labelfile", ",", "split", ")", ":", "\n", "        ", "labels", "=", "[", "]", "\n", "with", "open", "(", "labelfile", ")", "as", "f1", ":", "\n", "            ", "for", "line", "in", "f1", ".", "readlines", "(", ")", ":", "\n", "                ", "labels", ".", "append", "(", "int", "(", "line", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", ")", "\n", "", "", "outfile", "=", "open", "(", "director", "+", "split", "+", "\".tsv\"", ",", "\"+w\"", ")", "\n", "outmetafile", "=", "open", "(", "director", "+", "split", "+", "\"_meta.tsv\"", ",", "\"+w\"", ")", "\n", "with", "open", "(", "inputfile", ")", "as", "f2", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f2", ".", "readlines", "(", ")", ")", ":", "\n", "                ", "label", "=", "labels", "[", "idx", "]", "\n", "assert", "label", "==", "1", "or", "label", "==", "2", ",", "f\" * the label is: {label}\"", "\n", "json_line", "=", "json", ".", "loads", "(", "line", ")", "\n", "outstring", "=", "json_line", "[", "'hyp1'", "]", "\n", "if", "label", "==", "2", ":", "\n", "                    ", "outstring", "=", "json_line", "[", "'hyp2'", "]", "\n", "", "outfile", ".", "write", "(", "json_line", "[", "'obs1'", "]", "+", "\" ___ \"", "+", "json_line", "[", "'obs2'", "]", "+", "\"\\t\"", "+", "outstring", "+", "\"\\n\"", ")", "\n", "outmetafile", ".", "write", "(", "f\"{json_line['story_id']}\\t{label}\\n\"", ")", "\n", "\n", "", "", "return", "len", "(", "labels", ")", "\n", "\n", "", "dev_count", "=", "readfile", "(", "\"../datasets/aNLG/dev.jsonl\"", ",", "\"../datasets/aNLG/dev-labels.lst\"", ",", "\"dev\"", ")", "\n", "train_count", "=", "readfile", "(", "\"../datasets/aNLG/train.jsonl\"", ",", "\"../datasets/aNLG/train-labels.lst\"", ",", "\"train\"", ")", "\n", "\n", "with", "open", "(", "director", "+", "\"counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"dev\"", ":", "dev_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.summarization": [[1227, 1249], ["encode_datasets.anlg.readfile"], "function", ["None"], ["def", "summarization", "(", ")", ":", "\n", "    ", "def", "readfile", "(", "file", ")", ":", "\n", "        ", "outfile", "=", "open", "(", "file", ".", "replace", "(", "\".tsv\"", ",", "\"_2.tsv\"", ")", ",", "\"+w\"", ")", "\n", "with", "open", "(", "file", ")", "as", "csvfile", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "csvfile", ",", "delimiter", "=", "'\\t'", ")", "\n", "for", "row", "in", "reader", ":", "\n", "                ", "row", "[", "0", "]", "=", "row", "[", "0", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "row", "[", "0", "]", "=", "row", "[", "0", "]", "[", ":", "6", "*", "500", "]", "\n", "row", "[", "1", "]", "=", "row", "[", "1", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "outfile", ".", "write", "(", "row", "[", "0", "]", "+", "\"\\t\"", "+", "row", "[", "1", "]", "+", "\"\\n\"", ")", "\n", "\n", "", "", "", "readfile", "(", "\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/summarization-cnndm-dev/dev.tsv\"", ")", "\n", "readfile", "(", "\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/summarization-cnndm-dev/train.tsv\"", ")", "\n", "\n", "readfile", "(", "\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/summarization-cnndm-test/test.tsv\"", ")", "\n", "readfile", "(", "\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/summarization-cnndm-test/train.tsv\"", ")", "\n", "\n", "readfile", "(", "\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/summarization-xsum-dev/dev.tsv\"", ")", "\n", "readfile", "(", "\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/summarization-xsum-dev/train.tsv\"", ")", "\n", "\n", "readfile", "(", "\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/summarization-xsum-test/test.tsv\"", ")", "\n", "readfile", "(", "\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/summarization-xsum-test/train.tsv\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.csqa2_process": [[1251, 1270], ["open", "open", "open", "pandas.read_json", "range", "len", "len", "[].strip().replace().replace().replace().replace", "open.write", "open.write", "open.write", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace", "json.dumps", "[].strip().replace().replace().replace", "[].strip().replace().replace", "[].strip().replace().replace", "[].strip().replace", "[].strip().replace", "[].strip", "[].strip"], "function", ["None"], ["", "def", "csqa2_process", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout", "=", "open", "(", "f\"{dataset}/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "ans", "=", "open", "(", "f\"{dataset}/{kind}_ans.jsonl\"", ",", "\"w+\"", ")", "\n", "\n", "df", "=", "pd", ".", "read_json", "(", "'/content/csqa2/dataset/'", "+", "file", ",", "lines", "=", "True", ",", "compression", "=", "'gzip'", ")", "\n", "questions", "=", "df", "[", "[", "'question'", ",", "'answer'", ",", "'id'", "]", "]", ".", "values", "\n", "\n", "for", "row", "in", "range", "(", "len", "(", "questions", ")", ")", ":", "\n", "        ", "question", "=", "questions", "[", "row", "]", "[", "0", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "'?'", "not", "in", "question", ":", "\n", "            ", "question", "=", "question", "+", "\"?\"", "\n", "", "answer", "=", "[", "questions", "[", "row", "]", "[", "1", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "]", "\n", "id", "=", "questions", "[", "row", "]", "[", "2", "]", "\n", "\n", "fmeta", ".", "write", "(", "f\"{id} \\n\"", ")", "\n", "fout", ".", "write", "(", "f\"{question} \\t{answer[0]}\\n\"", ")", "\n", "ans", ".", "write", "(", "json", ".", "dumps", "(", "answer", ")", "+", "\"\\n\"", ")", "\n", "", "return", "len", "(", "questions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.csqa2_process_test": [[1271, 1288], ["open", "open", "pandas.read_json", "range", "len", "len", "[].strip().replace().replace().replace().replace", "open.write", "open.write", "[].strip().replace().replace().replace", "[].strip().replace().replace", "[].strip().replace", "[].strip"], "function", ["None"], ["", "def", "csqa2_process_test", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout", "=", "open", "(", "f\"{dataset}/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "\n", "df", "=", "pd", ".", "read_json", "(", "'/content/'", "+", "file", ",", "lines", "=", "True", ",", "compression", "=", "'gzip'", ")", "\n", "questions", "=", "df", "[", "[", "'question'", ",", "'id'", "]", "]", ".", "values", "\n", "\n", "for", "row", "in", "range", "(", "len", "(", "questions", ")", ")", ":", "\n", "        ", "question", "=", "questions", "[", "row", "]", "[", "0", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "'?'", "not", "in", "question", ":", "\n", "            ", "question", "=", "question", "+", "\"?\"", "\n", "", "id", "=", "questions", "[", "row", "]", "[", "1", "]", "\n", "answer", "=", "[", "\"-\"", "]", "\n", "\n", "fmeta", ".", "write", "(", "f\"{id}\\t{answer[0]} \\n\"", ")", "\n", "fout", ".", "write", "(", "f\"{question} \\t{answer[0]}\\n\"", ")", "\n", "", "return", "len", "(", "questions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.csqa": [[1289, 1295], ["encode_datasets.csqa2_process", "encode_datasets.csqa2_process", "encode_datasets.csqa2_process_test", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.csqa2_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.csqa2_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.csqa2_process_test"], ["", "def", "csqa", "(", ")", ":", "\n", "    ", "train_count", "=", "csqa2_process", "(", "'CSQA2_train.json.gz'", ",", "'csqa2'", ",", "'train'", ")", "\n", "dev_count", "=", "csqa2_process", "(", "'CSQA2_dev.json.gz'", ",", "'csqa2'", ",", "'dev'", ")", "\n", "test_count", "=", "csqa2_process_test", "(", "'CSQA2_test_no_answers.json.gz'", ",", "'csqa2'", ",", "'test'", ")", "\n", "with", "open", "(", "f\"/content/csqa2/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"dev\"", ":", "dev_count", ",", "\"test\"", ":", "test_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.pubmedqa_process": [[1296, 1322], ["open", "open", "open", "open", "open", "pandas.read_json().transpose", "range", "open.write", "len", "[].strip().replace().replace().replace().replace", "separator.join().strip().replace().replace().replace().replace", "open.write", "open.write", "open.write", "open.write", "pandas.read_json", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace", "codecs.open", "[].strip().replace().replace().replace", "separator.join().strip().replace().replace().replace", "json.dumps", "json.dumps", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "[].strip().replace().replace", "separator.join().strip().replace().replace", "[].strip().replace().replace", "[].strip().replace().replace", "[].strip().replace", "separator.join().strip().replace", "[].strip().replace", "[].strip().replace", "[].strip", "separator.join().strip", "[].strip", "[].strip", "separator.join"], "function", ["None"], ["", "", "def", "pubmedqa_process", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout_long", "=", "open", "(", "f\"{dataset}/long_answer/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fout_short", "=", "open", "(", "f\"{dataset}/short_answer/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "ans_long", "=", "open", "(", "f\"{dataset}/long_answer/{kind}_ans.jsonl\"", ",", "\"w+\"", ")", "\n", "ans_short", "=", "open", "(", "f\"{dataset}/short_answer/{kind}_ans.jsonl\"", ",", "\"w+\"", ")", "\n", "\n", "df", "=", "pd", ".", "read_json", "(", "codecs", ".", "open", "(", "'/content/'", "+", "file", ",", "'r'", ",", "'utf-8'", ")", ")", ".", "transpose", "(", ")", "\n", "questions", "=", "df", "[", "[", "'QUESTION'", ",", "'CONTEXTS'", ",", "'LONG_ANSWER'", ",", "'final_decision'", "]", "]", ".", "values", "\n", "meta", "=", "df", ".", "index", ".", "values", "\n", "for", "id", "in", "meta", ":", "\n", "        ", "fmeta", ".", "write", "(", "f\"{id} \\n\"", ")", "\n", "\n", "", "for", "row", "in", "range", "(", "len", "(", "questions", ")", ")", ":", "\n", "        ", "question", "=", "questions", "[", "row", "]", "[", "0", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "'?'", "not", "in", "question", ":", "\n", "            ", "question", "=", "question", "+", "\"?\"", "\n", "", "separator", "=", "','", "\n", "contexts", "=", "separator", ".", "join", "(", "questions", "[", "row", "]", "[", "1", "]", ")", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "long_answer", "=", "[", "questions", "[", "row", "]", "[", "2", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "]", "\n", "answer", "=", "[", "questions", "[", "row", "]", "[", "3", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "]", "\n", "\n", "fout_long", ".", "write", "(", "f\"{question}\\\\n {contexts} \\t{long_answer[0]}\\n\"", ")", "\n", "fout_short", ".", "write", "(", "f\"{question}\\\\n {contexts} \\t{answer[0]}\\n\"", ")", "\n", "ans_short", ".", "write", "(", "json", ".", "dumps", "(", "answer", ")", "+", "\"\\n\"", ")", "\n", "ans_long", ".", "write", "(", "json", ".", "dumps", "(", "long_answer", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.pubmedqa_process_un": [[1323, 1344], ["open", "open", "open", "pandas.read_json().transpose", "range", "open.write", "len", "[].strip().replace().replace().replace().replace", "separator.join().strip().replace().replace().replace().replace", "open.write", "open.write", "pandas.read_json", "[].strip().replace().replace().replace().replace", "codecs.open", "[].strip().replace().replace().replace", "separator.join().strip().replace().replace().replace", "json.dumps", "[].strip().replace().replace().replace", "[].strip().replace().replace", "separator.join().strip().replace().replace", "[].strip().replace().replace", "[].strip().replace", "separator.join().strip().replace", "[].strip().replace", "[].strip", "separator.join().strip", "[].strip", "separator.join"], "function", ["None"], ["", "", "def", "pubmedqa_process_un", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout_long", "=", "open", "(", "f\"{dataset}/long_answer/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "ans_long", "=", "open", "(", "f\"{dataset}/long_answer/{kind}_ans.jsonl\"", ",", "\"w+\"", ")", "\n", "\n", "df", "=", "pd", ".", "read_json", "(", "codecs", ".", "open", "(", "'/content/'", "+", "file", ",", "'r'", ",", "'utf-8'", ")", ")", ".", "transpose", "(", ")", "\n", "questions", "=", "df", "[", "[", "'QUESTION'", ",", "'CONTEXTS'", ",", "'LONG_ANSWER'", "]", "]", ".", "values", "\n", "meta", "=", "df", ".", "index", ".", "values", "\n", "for", "id", "in", "meta", ":", "\n", "        ", "fmeta", ".", "write", "(", "f\"{id} \\n\"", ")", "\n", "\n", "", "for", "row", "in", "range", "(", "len", "(", "questions", ")", ")", ":", "\n", "        ", "question", "=", "questions", "[", "row", "]", "[", "0", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "'?'", "not", "in", "question", ":", "\n", "            ", "question", "=", "question", "+", "\"?\"", "\n", "", "separator", "=", "','", "\n", "contexts", "=", "separator", ".", "join", "(", "questions", "[", "row", "]", "[", "1", "]", ")", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "long_answer", "=", "[", "questions", "[", "row", "]", "[", "2", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "]", "\n", "\n", "fout_long", ".", "write", "(", "f\"{question}\\\\n {contexts} \\t{long_answer[0]}\\n\"", ")", "\n", "ans_long", ".", "write", "(", "json", ".", "dumps", "(", "long_answer", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.pubmedqa": [[1345, 1350], ["encode_datasets.pubmedqa_process", "encode_datasets.pubmedqa_process", "encode_datasets.pubmedqa_process", "encode_datasets.pubmedqa_process_un"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.pubmedqa_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.pubmedqa_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.pubmedqa_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.pubmedqa_process_un"], ["", "", "def", "pubmedqa", "(", ")", ":", "\n", "    ", "pubmedqa_process", "(", "'ori_pqal.json'", ",", "'pubmedqa'", ",", "'pqal_train'", ")", "\n", "pubmedqa_process", "(", "'ori_pqaa.json'", ",", "'pubmedqa'", ",", "'pqaa_train'", ")", "\n", "pubmedqa_process", "(", "'test_set.json'", ",", "'pubmedqa'", ",", "'test'", ")", "\n", "pubmedqa_process_un", "(", "'ori_pqau.json'", ",", "'pubmedqa'", ",", "'pqau_train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.strategyqa_process": [[1351, 1388], ["open", "open", "open", "pandas.read_json", "pandas.read_json", "range", "len", "codecs.open", "codecs.open", "len", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace", "encode_datasets.clean_query", "open.write", "open.write", "open.write", "result[].split", "range", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "json.dumps", "len", "len", "retrieved_documents.append", "[].strip().replace().replace", "[].strip().replace().replace", "len", "sentences[].split", "sentences[].split", "[].strip().replace", "[].strip().replace", "[].strip", "[].strip"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.clean_query"], ["", "def", "strategyqa_process", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout", "=", "open", "(", "f\"{dataset}/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "ans", "=", "open", "(", "f\"{dataset}/{kind}_ans.jsonl\"", ",", "\"w+\"", ")", "\n", "\n", "df", "=", "pd", ".", "read_json", "(", "codecs", ".", "open", "(", "'/content/'", "+", "file", ",", "'r'", ",", "'utf-8'", ")", ")", "\n", "questions", "=", "df", "[", "[", "'qid'", ",", "'term'", ",", "'question'", ",", "'answer'", "]", "]", ".", "values", "\n", "\n", "documents", "=", "pd", ".", "read_json", "(", "codecs", ".", "open", "(", "'/content/queries_cache.json'", ",", "'r'", ",", "'utf-8'", ")", ")", "\n", "\n", "for", "row", "in", "range", "(", "len", "(", "questions", ")", ")", ":", "\n", "        ", "qid", "=", "questions", "[", "row", "]", "[", "0", "]", "\n", "term", "=", "questions", "[", "row", "]", "[", "1", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "term", "=", "\"(\"", "+", "term", "+", "\")\"", "\n", "question", "=", "questions", "[", "row", "]", "[", "2", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "'?'", "not", "in", "question", ":", "\n", "            ", "question", "=", "question", "+", "\"?\"", "\n", "", "if", "questions", "[", "row", "]", "[", "3", "]", "==", "True", ":", "\n", "            ", "answer", "=", "[", "\"yes\"", "]", "\n", "", "else", ":", "\n", "            ", "answer", "=", "[", "\"no\"", "]", "\n", "", "query", "=", "clean_query", "(", "questions", "[", "row", "]", "[", "2", "]", ")", "\n", "arr", "=", "documents", "[", "query", "]", "\n", "retrieved_documents", "=", "[", "]", "\n", "token_num", "=", "0", "\n", "for", "result", "in", "arr", "[", "0", "]", ":", "\n", "            ", "sentences", "=", "result", "[", "\"sentence\"", "]", ".", "split", "(", "\".\"", ")", "\n", "for", "index", "in", "range", "(", "len", "(", "sentences", ")", "-", "1", ")", ":", "\n", "                ", "if", "(", "token_num", "+", "len", "(", "sentences", "[", "index", "]", ".", "split", "(", "\" \"", ")", ")", ")", "<", "500", ":", "\n", "                    ", "token_num", "+=", "len", "(", "sentences", "[", "index", "]", ".", "split", "(", "\" \"", ")", ")", "\n", "retrieved_documents", ".", "append", "(", "sentences", "[", "index", "]", "+", "\".\"", ")", "\n", "", "", "", "retrieved_document", "=", "''", ".", "join", "(", "retrieved_documents", ")", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "\n", "fout", ".", "write", "(", "f\"{question}\\\\n {term} {retrieved_document} \\t{answer[0]}\\n\"", ")", "\n", "ans", ".", "write", "(", "json", ".", "dumps", "(", "answer", ")", "+", "\"\\n\"", ")", "\n", "fmeta", ".", "write", "(", "f\"{qid} \\n\"", ")", "\n", "", "return", "len", "(", "questions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.strategyqa_process_test": [[1389, 1420], ["open", "open", "pandas.read_json", "pandas.read_json", "range", "len", "codecs.open", "codecs.open", "len", "[].strip().replace().replace().replace().replace", "encode_datasets.clean_query", "open.write", "open.write", "result[].split", "range", "[].strip().replace().replace().replace", "len", "len", "retrieved_documents.append", "[].strip().replace().replace", "len", "sentences[].split", "sentences[].split", "[].strip().replace", "[].strip"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.clean_query"], ["", "def", "strategyqa_process_test", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout", "=", "open", "(", "f\"{dataset}/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "\n", "df", "=", "pd", ".", "read_json", "(", "codecs", ".", "open", "(", "'/content/'", "+", "file", ",", "'r'", ",", "'utf-8'", ")", ")", "\n", "questions", "=", "df", "[", "[", "'qid'", ",", "'question'", "]", "]", ".", "values", "\n", "\n", "documents", "=", "pd", ".", "read_json", "(", "codecs", ".", "open", "(", "'/content/queries_cache.json'", ",", "'r'", ",", "'utf-8'", ")", ")", "\n", "\n", "for", "row", "in", "range", "(", "len", "(", "questions", ")", ")", ":", "\n", "        ", "qid", "=", "questions", "[", "row", "]", "[", "0", "]", "\n", "question", "=", "questions", "[", "row", "]", "[", "1", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "'?'", "not", "in", "question", ":", "\n", "            ", "question", "=", "question", "+", "\"?\"", "\n", "\n", "", "query", "=", "clean_query", "(", "questions", "[", "row", "]", "[", "1", "]", ")", "\n", "arr", "=", "documents", "[", "query", "]", "\n", "retrieved_documents", "=", "[", "]", "\n", "token_num", "=", "0", "\n", "answer", "=", "[", "\"-\"", "]", "\n", "for", "result", "in", "arr", "[", "0", "]", ":", "\n", "            ", "sentences", "=", "result", "[", "\"sentence\"", "]", ".", "split", "(", "\".\"", ")", "\n", "for", "index", "in", "range", "(", "len", "(", "sentences", ")", "-", "1", ")", ":", "\n", "                ", "if", "(", "token_num", "+", "len", "(", "sentences", "[", "index", "]", ".", "split", "(", "\" \"", ")", ")", ")", "<", "500", ":", "\n", "                    ", "token_num", "+=", "len", "(", "sentences", "[", "index", "]", ".", "split", "(", "\" \"", ")", ")", "\n", "retrieved_documents", ".", "append", "(", "sentences", "[", "index", "]", "+", "\".\"", ")", "\n", "", "", "", "retrieved_document", "=", "''", ".", "join", "(", "retrieved_documents", ")", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "\n", "fout", ".", "write", "(", "f\"{question}\\\\n {retrieved_document} \\t{answer[0]}\\n\"", ")", "\n", "fmeta", ".", "write", "(", "f\"{qid} \\n\"", ")", "\n", "", "return", "len", "(", "questions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.clean_query": [[1421, 1430], ["query.split", "new_query_split.append", "word.lower"], "function", ["None"], ["", "def", "clean_query", "(", "query", ",", "remove_stopwords", "=", "True", ")", ":", "\n", "    ", "if", "remove_stopwords", ":", "\n", "        ", "query_split", "=", "query", ".", "split", "(", ")", "\n", "new_query_split", "=", "[", "]", "\n", "for", "word", "in", "query_split", ":", "\n", "            ", "if", "word", ".", "lower", "(", ")", "+", "\" \"", "not", "in", "STOPWORDS", ":", "\n", "                ", "new_query_split", ".", "append", "(", "word", ")", "\n", "", "", "query", "=", "\" \"", ".", "join", "(", "new_query_split", ")", "\n", "", "return", "query", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.strategyqa": [[1431, 1436], ["encode_datasets.strategyqa_process", "encode_datasets.strategyqa_process_test", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.strategyqa_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.strategyqa_process_test"], ["", "def", "strategyqa", "(", ")", ":", "\n", "    ", "train_count", "=", "strategyqa_process", "(", "'strategyqa_train.json'", ",", "'strategyqa'", ",", "'train'", ")", "\n", "test_count", "=", "strategyqa_process_test", "(", "'strategyqa_test.json'", ",", "'strategyqa'", ",", "'test'", ")", "\n", "with", "open", "(", "f\"/content/strategyqa/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"test\"", ":", "test_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.reclor_process": [[1437, 1460], ["open", "open", "pandas.read_json", "range", "len", "codecs.open", "len", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace", "chr", "open.write", "open.write", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "ord", "enumerate", "[].strip().replace().replace", "chr", "[].strip().replace().replace", "[].strip().replace().replace", "[].strip().replace", "ord", "[].strip().replace", "[].strip().replace", "[].strip", "[].strip", "[].strip"], "function", ["None"], ["", "", "def", "reclor_process", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout", "=", "open", "(", "f\"{dataset}/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "\n", "df", "=", "pd", ".", "read_json", "(", "codecs", ".", "open", "(", "'/content/'", "+", "file", ",", "'r'", ",", "'utf-8'", ")", ")", "\n", "questions", "=", "df", "[", "[", "'question'", ",", "'answers'", ",", "'context'", ",", "'label'", ",", "'id_string'", "]", "]", ".", "values", "\n", "\n", "for", "row", "in", "range", "(", "len", "(", "questions", ")", ")", ":", "\n", "        ", "question", "=", "questions", "[", "row", "]", "[", "0", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "'?'", "not", "in", "question", ":", "\n", "            ", "question", "=", "question", "+", "\"?\"", "\n", "", "candidates", "=", "questions", "[", "row", "]", "[", "1", "]", "\n", "options", "=", "\" \"", ".", "join", "(", "[", "f\"({chr(ord('A') + i)}) {x}\"", "for", "i", ",", "x", "in", "enumerate", "(", "candidates", ")", "]", ")", "\n", "contexts", "=", "questions", "[", "row", "]", "[", "2", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "\n", "label", "=", "questions", "[", "row", "]", "[", "3", "]", "\n", "answer", "=", "questions", "[", "row", "]", "[", "1", "]", "[", "label", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "id", "=", "questions", "[", "row", "]", "[", "4", "]", "\n", "answer_index", "=", "chr", "(", "ord", "(", "'A'", ")", "+", "(", "label", ")", ")", "\n", "\n", "fmeta", ".", "write", "(", "f\"{id}\\t{answer_index}\\n\"", ")", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n{options} \\\\n {contexts}\\t{answer}\\n\"", ")", "\n", "", "return", "len", "(", "questions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.reclor_process_test": [[1461, 1482], ["open", "open", "pandas.read_json", "range", "len", "codecs.open", "len", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace", "open.write", "open.write", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "enumerate", "[].strip().replace().replace", "chr", "[].strip().replace().replace", "[].strip().replace", "ord", "[].strip().replace", "[].strip", "[].strip"], "function", ["None"], ["", "def", "reclor_process_test", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout", "=", "open", "(", "f\"{dataset}/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "\n", "df", "=", "pd", ".", "read_json", "(", "codecs", ".", "open", "(", "'/content/'", "+", "file", ",", "'r'", ",", "'utf-8'", ")", ")", "\n", "questions", "=", "df", "[", "[", "'question'", ",", "'answers'", ",", "'context'", ",", "'id_string'", "]", "]", ".", "values", "\n", "\n", "for", "row", "in", "range", "(", "len", "(", "questions", ")", ")", ":", "\n", "        ", "question", "=", "questions", "[", "row", "]", "[", "0", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "'?'", "not", "in", "question", ":", "\n", "            ", "question", "=", "question", "+", "\"?\"", "\n", "", "candidates", "=", "questions", "[", "row", "]", "[", "1", "]", "\n", "options", "=", "\" \"", ".", "join", "(", "[", "f\"({chr(ord('A') + i)}) {x}\"", "for", "i", ",", "x", "in", "enumerate", "(", "candidates", ")", "]", ")", "\n", "contexts", "=", "questions", "[", "row", "]", "[", "2", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "answer_index", "=", "\"-\"", "\n", "answer", "=", "\"-\"", "\n", "id", "=", "questions", "[", "row", "]", "[", "3", "]", "\n", "\n", "fmeta", ".", "write", "(", "f\"{id}\\t{answer_index}\\n\"", ")", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n{options} \\\\n {contexts}\\t{answer}\\n\"", ")", "\n", "", "return", "len", "(", "questions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.reclor": [[1483, 1489], ["encode_datasets.reclor_process", "encode_datasets.reclor_process", "encode_datasets.reclor_process_test", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.reclor_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.reclor_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.reclor_process_test"], ["", "def", "reclor", "(", ")", ":", "\n", "    ", "train_count", "=", "reclor_process", "(", "\"train.json\"", ",", "\"reclor\"", ",", "\"train\"", ")", "\n", "dev_count", "=", "reclor_process", "(", "\"val.json\"", ",", "\"reclor\"", ",", "\"dev\"", ")", "\n", "test_count", "=", "reclor_process_test", "(", "\"test.json\"", ",", "\"reclor\"", ",", "\"test\"", ")", "\n", "with", "open", "(", "f\"/content/reclor/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"dev\"", ":", "dev_count", ",", "\"test\"", ":", "test_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.race_c_process": [[1490, 1514], ["open", "open", "pandas.concat", "range", "len", "pandas.read_json", "len", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace", "open.write", "open.write", "glob.glob", "ord", "ord", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "enumerate", "[].strip().replace().replace", "chr", "[].strip().replace().replace", "[].strip().replace().replace", "[].strip().replace", "ord", "[].strip().replace", "[].strip().replace", "[].strip", "[].strip", "[].strip"], "function", ["None"], ["", "", "def", "race_c_process", "(", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout", "=", "open", "(", "f\"{dataset}/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "\n", "l", "=", "[", "pd", ".", "read_json", "(", "filename", ")", "for", "filename", "in", "glob", ".", "glob", "(", "\"/content/data/\"", "+", "kind", "+", "\"/*.txt\"", ")", "]", "\n", "df", "=", "pd", ".", "concat", "(", "l", ",", "axis", "=", "0", ")", "\n", "questions", "=", "df", "[", "[", "'questions'", ",", "'options'", ",", "'article'", ",", "'answers'", ",", "'id'", "]", "]", ".", "values", "\n", "\n", "for", "row", "in", "range", "(", "len", "(", "questions", ")", ")", ":", "\n", "        ", "question", "=", "questions", "[", "row", "]", "[", "0", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "'?'", "not", "in", "question", ":", "\n", "            ", "question", "=", "question", "+", "\"?\"", "\n", "", "candidates", "=", "questions", "[", "row", "]", "[", "1", "]", "\n", "options", "=", "\" \"", ".", "join", "(", "[", "f\"({chr(ord('A') + i)}) {x}\"", "for", "i", ",", "x", "in", "enumerate", "(", "candidates", ")", "]", ")", "\n", "contexts", "=", "questions", "[", "row", "]", "[", "2", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "\n", "answer", "=", "questions", "[", "row", "]", "[", "3", "]", "\n", "answer_index", "=", "ord", "(", "answer", ")", "-", "ord", "(", "'A'", ")", "\n", "answer_string", "=", "questions", "[", "row", "]", "[", "1", "]", "[", "answer_index", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "id", "=", "questions", "[", "row", "]", "[", "4", "]", "\n", "\n", "fmeta", ".", "write", "(", "f\"{id}\\t{answer} \\n\"", ")", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n{options} \\\\n {contexts}\\t{answer_string} \\n\"", ")", "\n", "", "return", "len", "(", "questions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.race_c": [[1515, 1521], ["encode_datasets.race_c_process", "encode_datasets.race_c_process", "encode_datasets.race_c_process", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.race_c_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.race_c_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.race_c_process"], ["", "def", "race_c", "(", ")", ":", "\n", "    ", "train_count", "=", "race_c_process", "(", "\"race-c\"", ",", "\"train\"", ")", "\n", "dev_count", "=", "race_c_process", "(", "\"race-c\"", ",", "\"dev\"", ")", "\n", "test_count", "=", "race_c_process", "(", "\"race-c\"", ",", "\"test\"", ")", "\n", "with", "open", "(", "f\"/content/race-c/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"dev\"", ":", "dev_count", ",", "\"test\"", ":", "test_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.record_process_extractive": [[1522, 1550], ["open", "open", "open", "f.readlines", "json.loads", "[].replace", "contexts.strip().replace().replace().replace().replace.strip().replace().replace().replace().replace", "range", "len", "[].replace", "question.replace().replace().replace().replace.replace().replace().replace().replace", "open.write", "open.write", "contexts.strip().replace().replace().replace().replace.strip().replace().replace().replace", "set", "range", "question.replace().replace().replace().replace.replace().replace().replace", "len", "set.add", "contexts.strip().replace().replace().replace().replace.strip().replace().replace", "[].strip().replace().replace().replace().replace", "question.replace().replace().replace().replace.replace().replace", "contexts.strip().replace().replace().replace().replace.strip().replace", "[].strip().replace().replace().replace", "question.replace().replace().replace().replace.replace", "contexts.strip().replace().replace().replace().replace.strip", "[].strip().replace().replace", "[].strip().replace", "[].strip"], "function", ["None"], ["", "", "def", "record_process_extractive", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout", "=", "open", "(", "f\"{dataset}/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "counter", "=", "0", "\n", "\n", "with", "open", "(", "\"/content/\"", "+", "file", ")", "as", "f", ":", "\n", "        ", "for", "l", "in", "f", ".", "readlines", "(", ")", "[", "1", ":", "]", ":", "\n", "            ", "json_line", "=", "json", ".", "loads", "(", "l", ")", "\n", "contexts", "=", "json_line", "[", "'passage'", "]", "[", "'text'", "]", ".", "replace", "(", "\"@highlight\"", ",", "\"\"", ")", "\n", "contexts", "=", "contexts", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "for", "index", "in", "range", "(", "len", "(", "json_line", "[", "'qas'", "]", ")", ")", ":", "\n", "                ", "counter", "+=", "1", "\n", "question", "=", "json_line", "[", "'qas'", "]", "[", "index", "]", "[", "'query'", "]", ".", "replace", "(", "\"@placeholder\"", ",", "\"_\"", ")", "\n", "question", "=", "question", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "'.'", "not", "in", "question", ":", "\n", "                    ", "question", "=", "question", "+", "\".\"", "\n", "", "if", "kind", "is", "not", "\"test\"", ":", "\n", "                    ", "all_answers", "=", "set", "(", ")", "\n", "for", "answer", "in", "range", "(", "len", "(", "json_line", "[", "'qas'", "]", "[", "index", "]", "[", "'answers'", "]", ")", ")", ":", "\n", "                        ", "all_answers", ".", "add", "(", "json_line", "[", "'qas'", "]", "[", "index", "]", "[", "'answers'", "]", "[", "answer", "]", "[", "'text'", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", ")", "\n", "", "answer_string", "=", "\"//\"", ".", "join", "(", "all_answers", ")", "\n", "", "else", ":", "\n", "                    ", "answer_string", "=", "\"-\"", "\n", "", "id", "=", "json_line", "[", "'qas'", "]", "[", "index", "]", "[", "'idx'", "]", "\n", "\n", "fmeta", ".", "write", "(", "f\"{id}\\t{answer_string}\\n\"", ")", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n {contexts} \\t {answer_string} \\n\"", ")", "\n", "", "", "", "return", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.record_extractive": [[1551, 1557], ["encode_datasets.record_process_extractive", "encode_datasets.record_process_extractive", "encode_datasets.record_process_extractive", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.record_process_extractive", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.record_process_extractive", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.record_process_extractive"], ["", "def", "record_extractive", "(", ")", ":", "\n", "    ", "train_count", "=", "record_process_extractive", "(", "\"train.jsonl\"", ",", "\"record\"", ",", "\"train\"", ")", "\n", "dev_count", "=", "record_process_extractive", "(", "\"val.jsonl\"", ",", "\"record\"", ",", "\"dev\"", ")", "\n", "test_count", "=", "record_process_extractive", "(", "\"test.jsonl\"", ",", "\"record\"", ",", "\"test\"", ")", "\n", "with", "open", "(", "f\"/content/record/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"dev\"", ":", "dev_count", ",", "\"test\"", ":", "test_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.record_process_mc": [[1558, 1600], ["open", "open", "open", "f.readlines", "json.loads", "range", "len", "contexts.strip().replace().replace().replace().replace().replace.strip().replace().replace().replace().replace().replace", "[].replace", "question.replace().replace().replace().replace.replace().replace().replace().replace", "open.write", "open.write", "range", "answers.remove", "answer_string.strip().replace().replace().replace().replace.strip().replace().replace().replace().replace", "chr", "len", "options.append", "contexts.strip().replace().replace().replace().replace().replace.strip().replace().replace().replace().replace", "question.replace().replace().replace().replace.replace().replace().replace", "answers.append", "option.strip().replace().replace().replace().replace().replace", "enumerate", "answer_string.strip().replace().replace().replace().replace.strip().replace().replace().replace", "ord", "options.index", "chr", "contexts.strip().replace().replace().replace().replace().replace.strip().replace().replace().replace", "question.replace().replace().replace().replace.replace().replace", "option.strip().replace().replace().replace().replace", "answer_string.strip().replace().replace().replace().replace.strip().replace().replace", "ord", "contexts.strip().replace().replace().replace().replace().replace.strip().replace().replace", "question.replace().replace().replace().replace.replace", "option.strip().replace().replace().replace", "answer_string.strip().replace().replace().replace().replace.strip().replace", "contexts.strip().replace().replace().replace().replace().replace.strip().replace", "option.strip().replace().replace", "answer_string.strip().replace().replace().replace().replace.strip", "contexts.strip().replace().replace().replace().replace().replace.strip", "option.strip().replace", "option.strip"], "function", ["None"], ["", "", "def", "record_process_mc", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout", "=", "open", "(", "f\"{dataset}/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "counter", "=", "0", "\n", "\n", "with", "open", "(", "\"/content/\"", "+", "file", ")", "as", "f", ":", "\n", "        ", "for", "l", "in", "f", ".", "readlines", "(", ")", "[", "1", ":", "]", ":", "\n", "            ", "json_line", "=", "json", ".", "loads", "(", "l", ")", "\n", "for", "index", "in", "range", "(", "len", "(", "json_line", "[", "'qas'", "]", ")", ")", ":", "\n", "                ", "counter", "+=", "1", "\n", "contexts", "=", "json_line", "[", "'passage'", "]", "[", "'text'", "]", "\n", "entities", "=", "json_line", "[", "'passage'", "]", "[", "'entities'", "]", "\n", "options", "=", "[", "]", "\n", "answers", "=", "[", "]", "\n", "if", "kind", "is", "not", "\"test\"", ":", "\n", "                    ", "for", "row", "in", "range", "(", "len", "(", "json_line", "[", "'qas'", "]", "[", "index", "]", "[", "'answers'", "]", ")", ")", ":", "\n", "                        ", "answer_string", "=", "json_line", "[", "'qas'", "]", "[", "index", "]", "[", "'answers'", "]", "[", "row", "]", "[", "'text'", "]", "\n", "if", "answer_string", "not", "in", "answers", ":", "\n", "                            ", "answers", ".", "append", "(", "answer_string", ")", "\n", "", "", "answer_string", "=", "answers", "[", "0", "]", "\n", "answers", ".", "remove", "(", "answer_string", ")", "\n", "", "for", "entity", "in", "entities", ":", "\n", "                    ", "option", "=", "contexts", "[", "entity", "[", "'start'", "]", ":", "entity", "[", "'end'", "]", "+", "1", "]", "\n", "if", "option", "not", "in", "options", "and", "option", "not", "in", "answers", ":", "\n", "                        ", "options", ".", "append", "(", "option", ".", "strip", "(", ")", ".", "replace", "(", "\"@highlight\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", ")", "\n", "", "", "candidates", "=", "\" \"", ".", "join", "(", "[", "f\"({chr(ord('A') + i)}) {x}\"", "for", "i", ",", "x", "in", "enumerate", "(", "options", ")", "]", ")", "\n", "contexts", "=", "contexts", ".", "strip", "(", ")", ".", "replace", "(", "\"@highlight\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "question", "=", "json_line", "[", "'qas'", "]", "[", "index", "]", "[", "'query'", "]", ".", "replace", "(", "\"@placeholder\"", ",", "\"_\"", ")", "\n", "question", "=", "question", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "'.'", "not", "in", "question", ":", "\n", "                    ", "question", "=", "question", "+", "\".\"", "\n", "", "if", "kind", "is", "not", "\"test\"", ":", "\n", "                    ", "answer_string", "=", "answer_string", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "answer_index", "=", "chr", "(", "ord", "(", "'A'", ")", "+", "options", ".", "index", "(", "answer_string", ")", ")", "\n", "", "else", ":", "\n", "                    ", "answer_string", "=", "\"-\"", "\n", "answer_index", "=", "\"-\"", "\n", "", "id", "=", "json_line", "[", "'qas'", "]", "[", "index", "]", "[", "'idx'", "]", "\n", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n {candidates} \\\\n {contexts} \\t {answer_string} \\n\"", ")", "\n", "fmeta", ".", "write", "(", "f\"{id}\\t{answer_index}\\n\"", ")", "\n", "", "", "", "return", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.record_mc": [[1601, 1607], ["encode_datasets.record_process_mc", "encode_datasets.record_process_mc", "encode_datasets.record_process_mc", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.record_process_mc", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.record_process_mc", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.record_process_mc"], ["", "def", "record_mc", "(", ")", ":", "\n", "    ", "train_count", "=", "record_process_mc", "(", "\"train.jsonl\"", ",", "\"record\"", ",", "\"train\"", ")", "\n", "dev_count", "=", "record_process_mc", "(", "\"val.jsonl\"", ",", "\"record\"", ",", "\"dev\"", ")", "\n", "test_count", "=", "record_process_mc", "(", "\"test.jsonl\"", ",", "\"record\"", ",", "\"test\"", ")", "\n", "with", "open", "(", "f\"/content/record/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"dev\"", ":", "dev_count", ",", "\"test\"", ":", "test_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.quail_process": [[1608, 1630], ["open", "open", "open", "f.readlines", "json.loads", "json_line[].strip().replace().replace().replace().replace", "json_line[].replace().replace().replace().replace", "int", "options[].strip().replace().replace().replace().replace", "chr", "open.write", "open.write", "json_line[].strip().replace().replace().replace", "json_line[].replace().replace().replace", "options[].strip().replace().replace().replace", "ord", "enumerate", "json_line[].strip().replace().replace", "chr", "json_line[].replace().replace", "options[].strip().replace().replace", "json_line[].strip().replace", "ord", "json_line[].replace", "options[].strip().replace", "json_line[].strip", "options[].strip"], "function", ["None"], ["", "", "def", "quail_process", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout", "=", "open", "(", "f\"{dataset}/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "counter", "=", "0", "\n", "\n", "with", "open", "(", "\"/content/quail/quail_v1.3/json/\"", "+", "file", ")", "as", "f", ":", "\n", "        ", "for", "l", "in", "f", ".", "readlines", "(", ")", "[", "1", ":", "]", ":", "\n", "            ", "counter", "+=", "1", "\n", "json_line", "=", "json", ".", "loads", "(", "l", ")", "\n", "contexts", "=", "json_line", "[", "'context'", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "options", "=", "json_line", "[", "'answers'", "]", "\n", "candidates", "=", "\" \"", ".", "join", "(", "[", "f\"({chr(ord('A') + i)}) {x}\"", "for", "i", ",", "x", "in", "enumerate", "(", "options", ")", "]", ")", "\n", "question", "=", "json_line", "[", "'question'", "]", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "\n", "answer_id", "=", "int", "(", "json_line", "[", "'correct_answer_id'", "]", ")", "\n", "answer_string", "=", "options", "[", "answer_id", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "answer_index", "=", "chr", "(", "ord", "(", "'A'", ")", "+", "answer_id", ")", "\n", "id", "=", "json_line", "[", "'id'", "]", "\n", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n {candidates} \\\\n {contexts} \\t {answer_string} \\n\"", ")", "\n", "fmeta", ".", "write", "(", "f\"{id}\\t{answer_index}\\n\"", ")", "\n", "", "", "return", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.quail": [[1631, 1637], ["encode_datasets.quail_process", "encode_datasets.quail_process", "encode_datasets.quail_process", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.quail_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.quail_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.quail_process"], ["", "def", "quail", "(", ")", ":", "\n", "    ", "train_count", "=", "quail_process", "(", "\"train.jsonl\"", ",", "\"quail\"", ",", "\"train\"", ")", "\n", "dev_count", "=", "quail_process", "(", "\"dev.jsonl\"", ",", "\"quail\"", ",", "\"dev\"", ")", "\n", "challenge_count", "=", "quail_process", "(", "\"challenge.jsonl\"", ",", "\"quail\"", ",", "\"challenge\"", ")", "\n", "with", "open", "(", "f\"/content/quail/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"dev\"", ":", "dev_count", ",", "\"challenge\"", ":", "challenge_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.onestopqa_process": [[1638, 1691], ["open", "open", "open", "open", "open", "open", "glob.glob", "open", "f.read", "paras.append", "para.split", "list", "range", "f.read.split", "filter", "len", "paralines[].find", "adv.replace.strip().replace().replace", "paralines[].find", "inter.replace.strip().replace().replace", "paralines[].find", "ele.replace.strip().replace().replace", "paralines[].find", "question.strip().replace().replace().replace().replace.strip().replace().replace().replace().replace", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "adv.replace.replace", "inter.replace.replace", "ele.replace.replace", "adv.replace.strip().replace", "inter.replace.strip().replace", "ele.replace.strip().replace", "question.strip().replace().replace().replace().replace.strip().replace().replace().replace", "enumerate", "adv.replace.strip", "inter.replace.strip", "ele.replace.strip", "question.strip().replace().replace().replace().replace.strip().replace().replace", "chr", "question.strip().replace().replace().replace().replace.strip().replace", "ord", "question.strip().replace().replace().replace().replace.strip"], "function", ["None"], ["", "", "def", "onestopqa_process", "(", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout_adv", "=", "open", "(", "f\"{dataset}_advanced/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta_adv", "=", "open", "(", "f\"{dataset}_advanced/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "fout_int", "=", "open", "(", "f\"{dataset}_intermediate/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta_int", "=", "open", "(", "f\"{dataset}_intermediate/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "fout_ele", "=", "open", "(", "f\"{dataset}_elementry/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta_ele", "=", "open", "(", "f\"{dataset}_elementry/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "counter", "=", "0", "\n", "paras", "=", "[", "]", "\n", "spans", "=", "[", "\"<A1>\"", ",", "\"<A2>\"", ",", "\"<A3>\"", ",", "\"</A1>\"", ",", "\"</A2>\"", ",", "\"</A3>\"", ",", "\"<D1>\"", ",", "\"<D2>\"", ",", "\"<D3>\"", ",", "\"</D1>\"", ",", "\"</D2>\"", ",", "\"</D3>\"", ",", "\"\\n\"", ",", "\"\\t\"", "]", "\n", "file_path", "=", "\"/content/onestop-qa/annotations/annotated_articles/*.txt\"", "\n", "for", "file", "in", "glob", ".", "glob", "(", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "            ", "content", "=", "f", ".", "read", "(", ")", "\n", "paras", ".", "append", "(", "content", ".", "split", "(", "\"# Paragraph\"", ")", ")", "\n", "", "", "for", "paragraph", "in", "paras", ":", "\n", "        ", "for", "para", "in", "paragraph", ":", "\n", "            ", "paralines", "=", "para", ".", "split", "(", "\"\\n\"", ")", "\n", "paralines", "=", "list", "(", "filter", "(", "None", ",", "paralines", ")", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "paralines", ")", ")", ":", "\n", "                ", "if", "paralines", "[", "idx", "]", ".", "find", "(", "\"Adv: \"", ")", "!=", "-", "1", ":", "\n", "                    ", "adv", "=", "paralines", "[", "idx", "]", "[", "5", ":", "]", "\n", "adv", ".", "strip", "(", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "for", "item", "in", "spans", ":", "\n", "                        ", "adv", "=", "adv", ".", "replace", "(", "item", ",", "\"\"", ")", "\n", "", "", "if", "paralines", "[", "idx", "]", ".", "find", "(", "\"Int: \"", ")", "!=", "-", "1", ":", "\n", "                    ", "inter", "=", "paralines", "[", "idx", "]", "[", "5", ":", "]", "\n", "inter", ".", "strip", "(", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "for", "item", "in", "spans", ":", "\n", "                        ", "inter", "=", "inter", ".", "replace", "(", "item", ",", "\"\"", ")", "\n", "", "", "if", "paralines", "[", "idx", "]", ".", "find", "(", "\"Ele: \"", ")", "!=", "-", "1", ":", "\n", "                    ", "ele", "=", "paralines", "[", "idx", "]", "[", "5", ":", "]", "\n", "ele", ".", "strip", "(", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "for", "item", "in", "spans", ":", "\n", "                        ", "ele", "=", "ele", ".", "replace", "(", "item", ",", "\"\"", ")", "\n", "", "", "if", "paralines", "[", "idx", "]", ".", "find", "(", "\"Q: \"", ")", "!=", "-", "1", ":", "\n", "                    ", "counter", "+=", "1", "\n", "question", "=", "paralines", "[", "idx", "]", "[", "3", ":", "]", "\n", "question", "=", "question", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "'?'", "not", "in", "question", ":", "\n", "                        ", "question", "=", "question", "+", "\"?\"", "\n", "", "options", "=", "paralines", "[", "idx", "+", "1", ":", "idx", "+", "5", "]", "\n", "answer_string", "=", "paralines", "[", "idx", "+", "1", "]", "[", "3", ":", "]", "\n", "answer_index", "=", "\"A\"", "\n", "candidates", "=", "\" \"", ".", "join", "(", "[", "f\"({chr(ord('A') + i)}) {x[3:]}\"", "for", "i", ",", "x", "in", "enumerate", "(", "options", ")", "]", ")", "\n", "\n", "fout_adv", ".", "write", "(", "f\"{question} \\\\n {candidates} \\\\n {adv} \\t {answer_string} \\n\"", ")", "\n", "fmeta_adv", ".", "write", "(", "f\"{counter}\\t{answer_index}\\n\"", ")", "\n", "fout_int", ".", "write", "(", "f\"{question} \\\\n {candidates} \\\\n {inter} \\t {answer_string} \\n\"", ")", "\n", "fmeta_int", ".", "write", "(", "f\"{counter}\\t{answer_index}\\n\"", ")", "\n", "fout_ele", ".", "write", "(", "f\"{question} \\\\n {candidates} \\\\n {ele} \\t {answer_string} \\n\"", ")", "\n", "fmeta_ele", ".", "write", "(", "f\"{counter}\\t{answer_index}\\n\"", ")", "\n", "", "", "", "", "return", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.onestopqa": [[1692, 1696], ["encode_datasets.onestopqa_process", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.onestopqa_process"], ["", "def", "onestopqa", "(", ")", ":", "\n", "    ", "train_count", "=", "onestopqa_process", "(", "\"onestopqa\"", ",", "\"train\"", ")", "\n", "with", "open", "(", "f\"/content/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.mcscript_process": [[1697, 1726], ["open", "open", "xml.parse", "ET.parse.getroot", "context.strip().replace().replace().replace().replace().replace.strip().replace().replace().replace().replace().replace", "elem.get", "questions.get", "question.strip().replace().replace().replace().replace.strip().replace().replace().replace().replace", "questions.get", "range", "open.write", "open.write", "context.strip().replace().replace().replace().replace().replace.strip().replace().replace().replace().replace", "len", "candidates.append", "question.strip().replace().replace().replace().replace.strip().replace().replace().replace", "questions[].get", "chr", "questions[].get", "questions[].get", "context.strip().replace().replace().replace().replace().replace.strip().replace().replace().replace", "enumerate", "question.strip().replace().replace().replace().replace.strip().replace().replace", "ord", "chr", "context.strip().replace().replace().replace().replace().replace.strip().replace().replace", "question.strip().replace().replace().replace().replace.strip().replace", "ord", "context.strip().replace().replace().replace().replace().replace.strip().replace", "question.strip().replace().replace().replace().replace.strip", "context.strip().replace().replace().replace().replace().replace.strip"], "function", ["None"], ["", "", "def", "mcscript_process", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout", "=", "open", "(", "f\"{dataset}/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "counter", "=", "0", "\n", "\n", "tree", "=", "ET", ".", "parse", "(", "\"/content/\"", "+", "file", ")", "\n", "root", "=", "tree", ".", "getroot", "(", ")", "\n", "for", "elem", "in", "root", ":", "#instance", "\n", "        ", "context", "=", "elem", "[", "0", "]", ".", "text", "\n", "context", "=", "context", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"--\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "id1", "=", "elem", ".", "get", "(", "'id'", ")", "\n", "for", "questions", "in", "elem", "[", "1", "]", ":", "\n", "            ", "counter", "+=", "1", "\n", "question", "=", "questions", ".", "get", "(", "'text'", ")", "\n", "question", "=", "question", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "'?'", "not", "in", "question", ":", "\n", "                ", "question", "=", "question", "+", "\"?\"", "\n", "", "id2", "=", "questions", ".", "get", "(", "'id'", ")", "\n", "candidates", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "questions", ")", ")", ":", "\n", "                ", "if", "questions", "[", "idx", "]", ".", "get", "(", "'correct'", ")", "==", "\"True\"", ":", "\n", "                    ", "answer_index", "=", "chr", "(", "ord", "(", "'A'", ")", "+", "idx", ")", "\n", "answer_string", "=", "questions", "[", "idx", "]", ".", "get", "(", "'text'", ")", "\n", "", "candidates", ".", "append", "(", "questions", "[", "idx", "]", ".", "get", "(", "'text'", ")", ")", "\n", "", "options", "=", "\" \"", ".", "join", "(", "[", "f\"({chr(ord('A') + i)}) {x}\"", "for", "i", ",", "x", "in", "enumerate", "(", "candidates", ")", "]", ")", "\n", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n {options} \\\\n {context} \\t {answer_string} \\n\"", ")", "\n", "fmeta", ".", "write", "(", "f\"{id1} {id2}\\t{answer_index}\\n\"", ")", "\n", "", "", "return", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.mcscript": [[1727, 1738], ["encode_datasets.mcscript_process", "encode_datasets.mcscript_process", "encode_datasets.mcscript_process", "encode_datasets.mcscript_process", "encode_datasets.mcscript_process", "encode_datasets.mcscript_process", "open", "json.dump", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.mcscript_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.mcscript_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.mcscript_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.mcscript_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.mcscript_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.mcscript_process"], ["", "def", "mcscript", "(", ")", ":", "\n", "    ", "train_count", "=", "mcscript_process", "(", "\"train-data.xml\"", ",", "\"mcscript\"", ",", "\"train\"", ")", "\n", "dev_count", "=", "mcscript_process", "(", "\"dev-data.xml\"", ",", "\"mcscript\"", ",", "\"dev\"", ")", "\n", "test_count", "=", "mcscript_process", "(", "\"test-data.xml\"", ",", "\"mcscript\"", ",", "\"test\"", ")", "\n", "with", "open", "(", "f\"/content/mcscript/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"dev\"", ":", "dev_count", ",", "\"test\"", ":", "test_count", "}", ",", "outfile", ")", "\n", "", "train_count", "=", "mcscript_process", "(", "\"train-data.xml\"", ",", "\"mcscript 2.0\"", ",", "\"train\"", ")", "\n", "dev_count", "=", "mcscript_process", "(", "\"dev-data.xml\"", ",", "\"mcscript 2.0\"", ",", "\"dev\"", ")", "\n", "test_count", "=", "mcscript_process", "(", "\"test-data.xml\"", ",", "\"mcscript 2.0\"", ",", "\"test\"", ")", "\n", "with", "open", "(", "f\"/content/mcscript 2.0/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"dev\"", ":", "dev_count", ",", "\"test\"", ":", "test_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.adversarialqa": [[1739, 1769], ["datasets.load_dataset", "print", "open", "open.write", "open", "open.write", "json.dumps", "x[].lower().replace().replace", "x[].lower().replace().replace", "x[].lower().replace().replace", "len", "[].lower().replace().replace", "x[].lower().replace", "x[].lower().replace", "x[].lower().replace", "[].lower().replace", "x[].lower", "x[].lower", "x[].lower", "[].lower"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.load_dataset"], ["", "", "def", "adversarialqa", "(", ")", ":", "\n", "    ", "for", "dataset1", "in", "[", "'dbidaf'", ",", "'dbert'", ",", "'droberta'", "]", ":", "\n", "        ", "dataset", "=", "load_dataset", "(", "\"adversarial_qa\"", ",", "dataset1", ")", "\n", "print", "(", "f\" * dataset: {dataset1}\"", ")", "\n", "stats", "=", "{", "}", "\n", "for", "split", "in", "[", "'train'", ",", "'test'", ",", "'dev'", "]", ":", "\n", "            ", "outfile", "=", "open", "(", "f\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/adversarialqa_{dataset1}/{split}.tsv\"", ",", "\"w+\"", ")", "\n", "# outfile_meta = open(f\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/adversarialqa_{dataset1}/{split}_meta.tsv\", \"w+\")", "\n", "split1", "=", "split", "\n", "if", "split", "==", "\"dev\"", ":", "\n", "                ", "split1", "=", "\"validation\"", "\n", "", "all_encoded", "=", "\"\"", "\n", "# all_encoded_meta = \"\"", "\n", "counter", "=", "0", "\n", "for", "x", "in", "dataset", "[", "split1", "]", ":", "\n", "                ", "counter", "+=", "1", "\n", "context", "=", "x", "[", "'context'", "]", ".", "lower", "(", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "question", "=", "x", "[", "'question'", "]", ".", "lower", "(", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "title", "=", "x", "[", "'title'", "]", ".", "lower", "(", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "if", "len", "(", "x", "[", "'answers'", "]", "[", "'text'", "]", ")", "==", "0", ":", "\n", "                    ", "answer_text", "=", "\"\"", "\n", "", "else", ":", "\n", "                    ", "answer_text", "=", "x", "[", "'answers'", "]", "[", "'text'", "]", "[", "0", "]", ".", "lower", "(", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "", "all_encoded", "+=", "f\"{question} \\\\n ({title}) {context} \\t {answer_text} \\n\"", "\n", "# all_encoded_meta += f\"{question} \\\\n ({title}) {context} \\t {answer_text} \\n\"", "\n", "", "outfile", ".", "write", "(", "all_encoded", ")", "\n", "stats", "[", "split", "]", "=", "counter", "\n", "\n", "", "outfile_stat", "=", "open", "(", "f\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/adversarialqa_{dataset1}/counts.json\"", ",", "\"w+\"", ")", "\n", "outfile_stat", ".", "write", "(", "json", ".", "dumps", "(", "stats", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.aqua_rat": [[1771, 1801], ["open", "open", "open", "open.write", "open", "f.readlines", "open.write", "open.write", "json.dumps", "json.loads", "print", "json_all[].lower().replace().replace", "json_all[].lower", "print", "chr", "line.replace", "ord", "ord", "options[].split", "json_all[].lower().replace", "ord", "json_all[].lower"], "function", ["None"], ["", "", "def", "aqua_rat", "(", ")", ":", "\n", "    ", "stats", "=", "{", "}", "\n", "for", "split", "in", "[", "'test'", ",", "'dev'", ",", "'train'", "]", ":", "\n", "        ", "file", "=", "f\"/Users/danielk/ideaProjects/AQuA/{split}.json\"", "\n", "all_encoded", "=", "\"\"", "\n", "all_encoded_meta", "=", "\"\"", "\n", "outfile", "=", "open", "(", "f\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/aqua_rat/{split}.tsv\"", ",", "\"w+\"", ")", "\n", "outfile_meta", "=", "open", "(", "f\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/aqua_rat/{split}_meta.tsv\"", ",", "\"w+\"", ")", "\n", "counter", "=", "0", "\n", "with", "open", "(", "file", ",", "\"+r\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "json_all", "=", "json", ".", "loads", "(", "line", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", "\n", "print", "(", "json_all", ")", "\n", "question", "=", "json_all", "[", "'question'", "]", ".", "lower", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "options", "=", "json_all", "[", "'options'", "]", "\n", "options_str", "=", "\" (\"", ".", "join", "(", "options", ")", ".", "lower", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "options_str", "=", "\"(\"", "+", "options_str", "\n", "correct", "=", "json_all", "[", "'correct'", "]", ".", "lower", "(", ")", "\n", "print", "(", "correct", ")", "\n", "correct_idx", "=", "ord", "(", "correct", ")", "-", "ord", "(", "'a'", ")", "\n", "correct_ans_str", "=", "options", "[", "correct_idx", "]", ".", "split", "(", "\")\"", ")", "[", "1", "]", "\n", "all_encoded", "+=", "f\"{question}\\\\n{options_str}\\t{correct_ans_str} \\n\"", "\n", "correct_ans_label", "=", "chr", "(", "correct_idx", "+", "ord", "(", "'A'", ")", ")", "\n", "all_encoded_meta", "+=", "f\"-\\t{correct_ans_label}\\n\"", "\n", "counter", "+=", "1", "\n", "", "outfile", ".", "write", "(", "all_encoded", ")", "\n", "outfile_meta", ".", "write", "(", "all_encoded_meta", ")", "\n", "stats", "[", "split", "]", "=", "counter", "\n", "", "outfile_stat", "=", "open", "(", "f\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/aqua_rat/counts.json\"", ",", "\"w+\"", ")", "\n", "outfile_stat", ".", "write", "(", "json", ".", "dumps", "(", "stats", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.CODAH": [[1803, 1837], ["open", "open.write", "open", "open.write", "open", "f.readlines", "json.dumps", "line.split", "int", "ans_str.replace().replace.replace().replace", "ans_str.replace().replace.replace", "Exception"], "function", ["None"], ["", "", "def", "CODAH", "(", ")", ":", "\n", "    ", "file", "=", "\"/Users/danielk/ideaProjects/CODAH/data/full_data.tsv\"", "\n", "outfile", "=", "open", "(", "f\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/codah/dev.tsv\"", ",", "\"w+\"", ")", "\n", "counter", "=", "0", "\n", "stats", "=", "{", "}", "\n", "all_encoded", "=", "\"\"", "\n", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "counter", "+=", "1", "\n", "line_split", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "type", "=", "line_split", "[", "0", "]", "\n", "question", "=", "line_split", "[", "1", "]", "\n", "o1", "=", "line_split", "[", "2", "]", "\n", "o2", "=", "line_split", "[", "3", "]", "\n", "o3", "=", "line_split", "[", "4", "]", "\n", "o4", "=", "line_split", "[", "5", "]", "\n", "ans_idx", "=", "int", "(", "line_split", "[", "6", "]", ")", "\n", "if", "ans_idx", "==", "0", ":", "\n", "                ", "ans_str", "=", "o1", "\n", "", "elif", "ans_idx", "==", "1", ":", "\n", "                ", "ans_str", "=", "o2", "\n", "", "elif", "ans_idx", "==", "2", ":", "\n", "                ", "ans_str", "=", "o3", "\n", "", "elif", "ans_idx", "==", "3", ":", "\n", "                ", "ans_str", "=", "o4", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "f\"hm .... {ans_idx}\"", ")", "\n", "", "ans_str", "=", "ans_str", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "input", "=", "f\"{question} \\\\n (a) {o1} (b) {o2} (c) {o3} (d) {o4}\"", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "all_encoded", "+=", "f\"{input}\\t{ans_str} \\n\"", "\n", "", "", "outfile", ".", "write", "(", "all_encoded", ")", "\n", "stats", "[", "'dev'", "]", "=", "counter", "\n", "outfile_stat", "=", "open", "(", "f\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/codah/counts.json\"", ",", "\"w+\"", ")", "\n", "outfile_stat", ".", "write", "(", "json", ".", "dumps", "(", "stats", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.covidqa": [[1841, 1872], ["open", "print", "open", "open.write", "print", "print", "open", "json.load", "json.dumps", "statistics.mean", "sum", "len", "para[].replace().replace", "qa[].replace().replace", "ans_size.append", "para[].replace", "len", "a[].replace().replace", "open.write", "context_size.append", "qa[].replace", "len", "a[].replace", "para[].replace().replace.split"], "function", ["None"], ["", "def", "covidqa", "(", ")", ":", "\n", "    ", "file", "=", "\"/Users/danielk/Desktop/COVID-QA.json\"", "\n", "fout", "=", "open", "(", "f\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/covid_qa_deepset/dev.tsv\"", ",", "\"w+\"", ")", "\n", "# ftargets = open(f\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/covid_qa_deepset/{segment}_targets.txt\", \"+w\")", "\n", "# finputs = open(f\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/covid_qa_deepset/{segment}_inputs.txt\", \"+w\")", "\n", "ans_size", "=", "[", "]", "\n", "counter", "=", "0", "\n", "stats", "=", "{", "}", "\n", "context_size", "=", "[", "]", "\n", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "        ", "file", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "section", "in", "file", "[", "'data'", "]", ":", "\n", "# title = section['title'].replace(\"\\n\", \" \").replace(\"\\t\", \" \")", "\n", "            ", "for", "para", "in", "section", "[", "'paragraphs'", "]", ":", "\n", "                ", "context", "=", "para", "[", "'context'", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "for", "qa", "in", "para", "[", "'qas'", "]", ":", "\n", "                    ", "question", "=", "qa", "[", "'question'", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "ans_size", ".", "append", "(", "len", "(", "qa", "[", "'answers'", "]", ")", ")", "\n", "for", "a", "in", "qa", "[", "'answers'", "]", ":", "\n", "                        ", "answer", "=", "a", "[", "'text'", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n {context}\\t{answer}\\n\"", ")", "\n", "counter", "+=", "1", "\n", "context_size", ".", "append", "(", "len", "(", "context", ".", "split", "(", "\" \"", ")", ")", ")", "\n", "# ftargets.write(f\"{answer}\\n\")", "\n", "# finputs.write(f\"{question} \\\\n ({title}) {context}\\n\")", "\n", "", "", "", "", "", "print", "(", "sum", "(", "ans_size", ")", "/", "len", "(", "ans_size", ")", ")", "\n", "stats", "[", "'dev'", "]", "=", "counter", "\n", "outfile_stat", "=", "open", "(", "f\"/Users/danielk/ideaProjects/t2t-qa/t2t-data/covid_qa_deepset/counts.json\"", ",", "\"w+\"", ")", "\n", "outfile_stat", ".", "write", "(", "json", ".", "dumps", "(", "stats", ")", ")", "\n", "print", "(", "context_size", ")", "\n", "print", "(", "statistics", ".", "mean", "(", "context_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.headqa": [[1933, 1972], ["encode_datasets.commonsenseqa.read_file"], "function", ["None"], ["", "def", "headqa", "(", ")", ":", "\n", "    ", "def", "read_file", "(", "infile", ",", "outfile", ",", "outfile_meta", ")", ":", "\n", "        ", "outfile", "=", "open", "(", "outfile", ",", "\"w+\"", ")", "\n", "outfile_meta", "=", "open", "(", "outfile_meta", ",", "\"w+\"", ")", "\n", "all_lines", "=", "\"\"", "\n", "counter", "=", "0", "\n", "with", "open", "(", "infile", ")", "as", "f", ":", "\n", "            ", "json_data", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "ex", ",", "v", "in", "json_data", "[", "'exams'", "]", ".", "items", "(", ")", ":", "\n", "                ", "for", "x", "in", "v", "[", "'data'", "]", ":", "\n", "                    ", "counter", "+=", "1", "\n", "print", "(", "\" - - - - - - - - - \"", ")", "\n", "print", "(", "x", ")", "\n", "question", "=", "x", "[", "'qtext'", "]", ".", "lower", "(", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "answer_idx", "=", "int", "(", "x", "[", "'ra'", "]", ")", "-", "1", "\n", "answers", "=", "[", "y", "[", "'atext'", "]", "for", "y", "in", "x", "[", "'answers'", "]", "]", "\n", "candidates", "=", "\"\"", ".", "join", "(", "[", "f\" ({chr(ord('A') + i)}) {x}\"", "for", "i", ",", "x", "in", "enumerate", "(", "answers", ")", "]", ")", "\n", "candidates", "=", "candidates", ".", "lower", "(", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "correct_ans_str", "=", "answers", "[", "answer_idx", "]", ".", "lower", "(", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "correct_ans_label", "=", "chr", "(", "answer_idx", "+", "ord", "(", "'A'", ")", ")", "\n", "all_lines", "+=", "f\"{question} \\\\n {candidates} \\t {correct_ans_str} \\n\"", "\n", "outfile_meta", ".", "write", "(", "f\"{x['qid']} \\t {correct_ans_label} \\n\"", ")", "\n", "", "", "", "outfile", ".", "write", "(", "all_lines", ")", "\n", "return", "counter", "\n", "\n", "", "stats", "=", "{", "}", "\n", "dir", "=", "\"/Users/danielk\"", "\n", "stats", "[", "'dev'", "]", "=", "read_file", "(", "f\"{dir}/Desktop/HEAD_EN/dev_HEAD_EN.json\"", ",", "\n", "f\"{dir}/ideaProjects/t2t-qa/t2t-data/head_qa_en_test/dev.tsv\"", ",", "\n", "f\"{dir}/ideaProjects/t2t-qa/t2t-data/head_qa_en_test/dev_meta.tsv\"", ")", "\n", "stats", "[", "'test'", "]", "=", "read_file", "(", "f\"{dir}/Desktop/HEAD_EN/test_HEAD_EN.json\"", ",", "\n", "f\"{dir}/ideaProjects/t2t-qa/t2t-data/head_qa_en_test/test.tsv\"", ",", "\n", "f\"{dir}/ideaProjects/t2t-qa/t2t-data/head_qa_en_test/test_meta.tsv\"", ")", "\n", "stats", "[", "'train'", "]", "=", "read_file", "(", "f\"{dir}/Desktop/HEAD_EN/train_HEAD_EN.json\"", ",", "\n", "f\"{dir}/ideaProjects/t2t-qa/t2t-data/head_qa_en_test/train.tsv\"", ",", "\n", "f\"{dir}/ideaProjects/t2t-qa/t2t-data/head_qa_en_test/train_meta.tsv\"", ")", "\n", "\n", "outfile_stat", "=", "open", "(", "f\"{dir}/ideaProjects/t2t-qa/t2t-data/head_qa_en_test/counts.json\"", ",", "\"w+\"", ")", "\n", "outfile_stat", ".", "write", "(", "json", ".", "dumps", "(", "stats", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.convert_proccess_bank": [[2028, 2070], ["encode_datasets.convert_proccess_bank.process"], "function", ["None"], ["def", "convert_proccess_bank", "(", ")", ":", "\n", "\n", "    ", "def", "process", "(", "inputfile", ",", "outfile", ")", ":", "\n", "        ", "all_lines", "=", "\"\"", "\n", "counter", "=", "0", "\n", "inputfile", "=", "open", "(", "inputfile", ",", "\"r\"", ")", "\n", "outfile", "=", "open", "(", "outfile", ",", "\"w+\"", ")", "\n", "for", "line", "in", "inputfile", ".", "readlines", "(", ")", ":", "\n", "            ", "counter", "+=", "1", "\n", "linejson", "=", "json", ".", "loads", "(", "line", ")", "\n", "# print(linejson)", "\n", "context", "=", "linejson", "[", "'text'", "]", ".", "lower", "(", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "for", "question", "in", "linejson", "[", "'questions'", "]", "[", "'question'", "]", ":", "\n", "                ", "print", "(", "\" - - - - \"", ")", "\n", "print", "(", "question", ")", "\n", "print", "(", "type", "(", "question", ")", ")", "\n", "if", "type", "(", "question", ")", "==", "str", ":", "\n", "                    ", "continue", "\n", "", "q", "=", "question", "[", "'q'", "]", ".", "lower", "(", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "a0", "=", "question", "[", "'a0'", "]", "\n", "a1", "=", "question", "[", "'a1'", "]", "\n", "if", "type", "(", "a0", ")", "==", "str", ":", "\n", "                    ", "a0", "=", "a0", ".", "lower", "(", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "", "if", "type", "(", "a1", ")", "==", "str", ":", "\n", "                    ", "a1", "=", "a1", ".", "lower", "(", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "", "candidates", "=", "f\"(a) {a0} (b) {a1} \"", ".", "lower", "(", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "correct", "=", "question", "[", "'correct'", "]", "\n", "if", "correct", "==", "0", ":", "\n", "                    ", "correct_str", "=", "a0", "\n", "", "else", ":", "\n", "                    ", "correct_str", "=", "a1", "\n", "\n", "", "all_lines", "+=", "f\"{q} \\\\n {candidates} \\\\n {context} \\t {correct_str} \\n\"", "\n", "", "", "outfile", ".", "write", "(", "all_lines", ")", "\n", "return", "counter", "\n", "\n", "", "dir", "=", "\"/Users/danielk\"", "\n", "stats", "=", "{", "}", "\n", "stats", "[", "'test'", "]", "=", "process", "(", "f\"{dir}/Desktop/processbankdata/test.jsonl\"", ",", "f\"{dir}/ideaProjects/t2t-qa/t2t-data/processbank/test.tsv\"", ")", "\n", "stats", "[", "'train'", "]", "=", "process", "(", "f\"{dir}/Desktop/processbankdata/train.jsonl\"", ",", "f\"{dir}/ideaProjects/t2t-qa/t2t-data/processbank/train.tsv\"", ")", "\n", "outfile_stat", "=", "open", "(", "f\"{dir}/ideaProjects/t2t-qa/t2t-data/processbank/counts.json\"", ",", "\"w+\"", ")", "\n", "outfile_stat", ".", "write", "(", "json", ".", "dumps", "(", "stats", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.cosmosqa_process": [[2071, 2105], ["open", "open", "range", "len", "pandas.read_json", "pandas.read_csv", "len", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace", "open.write", "open.write", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace", "chr", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "ord", "[].strip().replace().replace().replace", "[].strip().replace().replace", "[].strip().replace().replace", "[].strip().replace().replace", "[].strip().replace().replace", "[].strip().replace().replace", "[].strip().replace().replace", "[].strip().replace().replace", "[].strip().replace", "[].strip().replace", "[].strip().replace", "[].strip().replace", "[].strip().replace", "[].strip().replace", "[].strip().replace", "[].strip", "[].strip", "[].strip", "[].strip", "[].strip", "[].strip", "[].strip"], "function", ["None"], ["", "def", "cosmosqa_process", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout", "=", "open", "(", "f\"{dataset}/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "counter", "=", "0", "\n", "\n", "if", "kind", "==", "'test'", ":", "\n", "        ", "df", "=", "pd", ".", "read_json", "(", "\"/content/cosmosqa/data/test.jsonl\"", ",", "lines", "=", "True", ")", "\n", "questions", "=", "df", "[", "[", "'id'", ",", "'context'", ",", "'question'", ",", "'answer0'", ",", "'answer1'", ",", "'answer2'", ",", "'answer3'", "]", "]", ".", "values", "\n", "", "else", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "\"/content/cosmosqa/data/\"", "+", "file", ")", "\n", "questions", "=", "df", "[", "[", "'id'", ",", "'context'", ",", "'question'", ",", "'answer0'", ",", "'answer1'", ",", "'answer2'", ",", "'answer3'", ",", "'label'", "]", "]", ".", "values", "\n", "\n", "", "for", "row", "in", "range", "(", "len", "(", "questions", ")", ")", ":", "\n", "        ", "id", "=", "questions", "[", "row", "]", "[", "0", "]", "\n", "contexts", "=", "questions", "[", "row", "]", "[", "1", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "question", "=", "questions", "[", "row", "]", "[", "2", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "'?'", "not", "in", "question", ":", "\n", "            ", "question", "=", "question", "+", "\"?\"", "\n", "", "option1", "=", "\" (A) \"", "+", "questions", "[", "row", "]", "[", "3", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "option2", "=", "\" (B) \"", "+", "questions", "[", "row", "]", "[", "4", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "option3", "=", "\" (C) \"", "+", "questions", "[", "row", "]", "[", "5", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "option4", "=", "\" (D) \"", "+", "questions", "[", "row", "]", "[", "6", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "options", "=", "option1", "+", "option2", "+", "option3", "+", "option4", "\n", "\n", "if", "kind", "==", "'test'", ":", "\n", "            ", "answer", "=", "\"-\"", "\n", "answer_string", "=", "\"-\"", "\n", "", "else", ":", "\n", "            ", "answer_index", "=", "questions", "[", "row", "]", "[", "7", "]", "\n", "answer", "=", "chr", "(", "ord", "(", "'A'", ")", "+", "answer_index", ")", "\n", "answer_string", "=", "questions", "[", "row", "]", "[", "answer_index", "+", "3", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "", "fmeta", ".", "write", "(", "f\"{id}\\t{answer} \\n\"", ")", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n{options} \\\\n {contexts}\\t{answer_string} \\n\"", ")", "\n", "", "return", "len", "(", "questions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.cosmosqa": [[2106, 2112], ["encode_datasets.cosmosqa_process", "encode_datasets.cosmosqa_process", "encode_datasets.cosmosqa_process", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.cosmosqa_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.cosmosqa_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.cosmosqa_process"], ["", "def", "cosmosqa", "(", ")", ":", "\n", "    ", "train_count", "=", "cosmosqa_process", "(", "\"train.csv\"", ",", "\"cosmos\"", ",", "\"train\"", ")", "\n", "dev_count", "=", "cosmosqa_process", "(", "\"valid.csv\"", ",", "\"cosmos\"", ",", "\"dev\"", ")", "\n", "test_count", "=", "cosmosqa_process", "(", "\"test.jsonl\"", ",", "\"cosmos\"", ",", "\"test\"", ")", "\n", "with", "open", "(", "f\"/content/cosmos/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"dev\"", ":", "dev_count", ",", "\"test\"", ":", "test_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.tweetqa_process": [[2113, 2139], ["open", "open", "pandas.read_json", "range", "len", "len", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace", "open.write", "open.write", "set", "range", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "len", "set.add", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace", "[].strip().replace().replace", "[].strip().replace().replace().replace", "[].strip().replace", "[].strip().replace", "[].strip().replace().replace", "[].strip", "[].strip", "[].strip().replace", "[].strip"], "function", ["None"], ["", "", "def", "tweetqa_process", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout", "=", "open", "(", "f\"{dataset}/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "df", "=", "pd", ".", "read_json", "(", "\"/content/\"", "+", "file", ")", "\n", "\n", "if", "kind", "==", "'test'", ":", "\n", "        ", "questions", "=", "df", "[", "[", "'Question'", ",", "'Tweet'", ",", "'qid'", "]", "]", ".", "values", "\n", "", "else", ":", "\n", "        ", "questions", "=", "df", "[", "[", "'Question'", ",", "'Tweet'", ",", "'qid'", ",", "'Answer'", "]", "]", ".", "values", "\n", "\n", "", "for", "row", "in", "range", "(", "len", "(", "questions", ")", ")", ":", "\n", "        ", "id", "=", "questions", "[", "row", "]", "[", "2", "]", "\n", "contexts", "=", "questions", "[", "row", "]", "[", "1", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "question", "=", "questions", "[", "row", "]", "[", "0", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "'?'", "not", "in", "question", ":", "\n", "            ", "question", "=", "question", "+", "\"?\"", "\n", "", "if", "kind", "==", "'test'", ":", "\n", "            ", "answer_string", "=", "\"-\"", "\n", "", "else", ":", "\n", "            ", "all_answers", "=", "set", "(", ")", "\n", "for", "answer", "in", "range", "(", "len", "(", "questions", "[", "row", "]", "[", "3", "]", ")", ")", ":", "\n", "                ", "all_answers", ".", "add", "(", "questions", "[", "row", "]", "[", "3", "]", "[", "answer", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", ")", "\n", "", "answer_string", "=", "\"//\"", ".", "join", "(", "all_answers", ")", "\n", "", "fmeta", ".", "write", "(", "f\"{id}\\t{answer_string}\\n\"", ")", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n {contexts}\\t{answer_string} \\n\"", ")", "\n", "", "return", "len", "(", "questions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.tweetqa": [[2140, 2146], ["encode_datasets.tweetqa_process", "encode_datasets.tweetqa_process", "encode_datasets.tweetqa_process", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.tweetqa_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.tweetqa_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.tweetqa_process"], ["", "def", "tweetqa", "(", ")", ":", "\n", "    ", "train_count", "=", "tweetqa_process", "(", "\"train.json\"", ",", "\"tweetqa\"", ",", "\"train\"", ")", "\n", "dev_count", "=", "tweetqa_process", "(", "\"dev.json\"", ",", "\"tweetqa\"", ",", "\"dev\"", ")", "\n", "test_count", "=", "tweetqa_process", "(", "\"test.json\"", ",", "\"tweetqa\"", ",", "\"test\"", ")", "\n", "with", "open", "(", "f\"/content/tweetqa/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"dev\"", ":", "dev_count", ",", "\"test\"", ":", "test_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.mmmlu_process": [[2148, 2173], ["open", "open", "glob.glob", "pandas.read_csv", "range", "len", "[].strip().rstrip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace", "open.write", "open.write", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace", "ord", "ord", "[].strip().rstrip().replace().replace().replace", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace", "[].strip().rstrip().replace().replace", "[].strip().replace().replace", "[].strip().replace().replace", "[].strip().replace().replace", "[].strip().replace().replace", "[].strip().replace().replace", "[].strip().rstrip().replace", "[].strip().replace", "[].strip().replace", "[].strip().replace", "[].strip().replace", "[].strip().replace", "[].strip().rstrip", "[].strip", "[].strip", "[].strip", "[].strip", "[].strip", "[].strip"], "function", ["None"], ["", "", "def", "mmmlu_process", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout", "=", "open", "(", "f\"{dataset}/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "counter", "=", "0", "\n", "\n", "file_path", "=", "\"/content/\"", "+", "file", "+", "\"/*.csv\"", "\n", "for", "file", "in", "glob", ".", "glob", "(", "file_path", ")", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "file", ",", "header", "=", "None", ")", "\n", "questions", "=", "df", ".", "values", "\n", "\n", "for", "row", "in", "range", "(", "len", "(", "questions", ")", ")", ":", "\n", "            ", "counter", "+=", "1", "\n", "question", "=", "questions", "[", "row", "]", "[", "0", "]", ".", "strip", "(", ")", ".", "rstrip", "(", "\"\\n\"", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "option1", "=", "\" (A) \"", "+", "questions", "[", "row", "]", "[", "1", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "option2", "=", "\" (B) \"", "+", "questions", "[", "row", "]", "[", "2", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "option3", "=", "\" (C) \"", "+", "questions", "[", "row", "]", "[", "3", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "option4", "=", "\" (D) \"", "+", "questions", "[", "row", "]", "[", "4", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "options", "=", "option1", "+", "option2", "+", "option3", "+", "option4", "\n", "\n", "answer", "=", "questions", "[", "row", "]", "[", "5", "]", "\n", "answer_index", "=", "ord", "(", "answer", ")", "-", "ord", "(", "'A'", ")", "\n", "answer_string", "=", "questions", "[", "row", "]", "[", "answer_index", "+", "1", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "fmeta", ".", "write", "(", "f\"{counter}\\t{answer} \\n\"", ")", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n{options} \\t{answer_string} \\n\"", ")", "\n", "", "", "return", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.mmmlu": [[2174, 2180], ["encode_datasets.mmmlu_process", "encode_datasets.mmmlu_process", "encode_datasets.mmmlu_process", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.mmmlu_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.mmmlu_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.mmmlu_process"], ["", "def", "mmmlu", "(", ")", ":", "\n", "    ", "test_count", "=", "mmmlu_process", "(", "\"val\"", ",", "\"measuring_massive_multitask_language_understanding\"", ",", "\"test\"", ")", "\n", "dev_count", "=", "mmmlu_process", "(", "\"dev\"", ",", "\"measuring_massive_multitask_language_understanding\"", ",", "\"dev\"", ")", "\n", "train_count", "=", "mmmlu_process", "(", "\"test\"", ",", "\"measuring_massive_multitask_language_understanding\"", ",", "\"train\"", ")", "\n", "with", "open", "(", "f\"/content/measuring_massive_multitask_language_understanding/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"dev\"", ":", "dev_count", ",", "\"test\"", ":", "test_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.dream_process": [[2181, 2206], ["open", "open", "pandas.read_json", "range", "len", "context.strip().rstrip().replace().replace().replace().replace.strip().rstrip().replace().replace().replace().replace", "item[].strip().rstrip().replace().replace().replace().replace", "item[].strip().replace().replace().replace().replace", "chr", "open.write", "open.write", "context.strip().rstrip().replace().replace().replace().replace.strip().rstrip().replace().replace().replace", "item[].strip().rstrip().replace().replace().replace", "item[].strip().replace().replace().replace", "ord", "choices.index", "context.strip().rstrip().replace().replace().replace().replace.strip().rstrip().replace().replace", "enumerate", "item[].strip().rstrip().replace().replace", "chr", "item[].strip().replace().replace", "context.strip().rstrip().replace().replace().replace().replace.strip().rstrip().replace", "item[].strip().rstrip().replace", "ord", "item[].strip().replace", "context.strip().rstrip().replace().replace().replace().replace.strip().rstrip", "item[].strip().rstrip", "item[].strip", "context.strip().rstrip().replace().replace().replace().replace.strip", "item[].strip"], "function", ["None"], ["", "", "def", "dream_process", "(", "file", ",", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout", "=", "open", "(", "f\"{dataset}/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta", "=", "open", "(", "f\"{dataset}/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "counter", "=", "0", "\n", "\n", "df", "=", "pd", ".", "read_json", "(", "'/content/dream/data/'", "+", "file", ")", "\n", "questions", "=", "df", ".", "values", "\n", "\n", "for", "row", "in", "range", "(", "len", "(", "questions", ")", ")", ":", "\n", "        ", "dialogs", "=", "questions", "[", "row", "]", "[", "0", "]", "\n", "context", "=", "\" \"", ".", "join", "(", "dialogs", ")", "\n", "context", "=", "context", ".", "strip", "(", ")", ".", "rstrip", "(", "\"\\n\"", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "materials", "=", "questions", "[", "row", "]", "[", "1", "]", "\n", "id", "=", "questions", "[", "row", "]", "[", "2", "]", "\n", "for", "item", "in", "materials", ":", "\n", "            ", "question", "=", "item", "[", "'question'", "]", ".", "strip", "(", ")", ".", "rstrip", "(", "\"\\n\"", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "choices", "=", "item", "[", "'choice'", "]", "\n", "options", "=", "\" \"", ".", "join", "(", "[", "f\"({chr(ord('A') + i)}) {x}\"", "for", "i", ",", "x", "in", "enumerate", "(", "choices", ")", "]", ")", "\n", "answer_string", "=", "item", "[", "'answer'", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "answer", "=", "chr", "(", "ord", "(", "'A'", ")", "+", "choices", ".", "index", "(", "answer_string", ")", ")", "\n", "counter", "+=", "1", "\n", "\n", "fmeta", ".", "write", "(", "f\"{id}\\t{answer} \\n\"", ")", "\n", "fout", ".", "write", "(", "f\"{question} \\\\n{options} \\\\n {context}\\t{answer_string} \\n\"", ")", "\n", "", "", "return", "counter", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.dream": [[2207, 2213], ["encode_datasets.dream_process", "encode_datasets.dream_process", "encode_datasets.dream_process", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.dream_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.dream_process", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.dream_process"], ["", "def", "dream", "(", ")", ":", "\n", "    ", "train_count", "=", "dream_process", "(", "\"train.json\"", ",", "\"Dream\"", ",", "\"train\"", ")", "\n", "dev_count", "=", "dream_process", "(", "\"dev.json\"", ",", "\"Dream\"", ",", "\"dev\"", ")", "\n", "test_count", "=", "dream_process", "(", "\"test.json\"", ",", "\"Dream\"", ",", "\"test\"", ")", "\n", "with", "open", "(", "f\"/content/Dream/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "train_count", ",", "\"dev\"", ":", "dev_count", ",", "\"test\"", ":", "test_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.prost_process": [[2214, 2247], ["open", "open", "open", "open", "open", "open", "open", "open", "datasets.load_dataset", "range", "len", "len", "[].strip().replace().replace().replace().replace", "[].strip().replace().replace().replace().replace().replace", "[].strip().rstrip().replace().replace().replace().replace", "chr", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "[].strip().replace().replace().replace", "[].strip().replace().replace().replace().replace", "[].strip().rstrip().replace().replace().replace", "ord", "enumerate", "[].strip().replace().replace", "[].strip().replace().replace().replace", "[].strip().rstrip().replace().replace", "chr", "[].strip().replace", "[].strip().replace().replace", "[].strip().rstrip().replace", "ord", "[].strip", "[].strip().replace", "[].strip().rstrip", "[].strip", "[].strip"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.load_dataset"], ["", "", "def", "prost_process", "(", "dataset", ",", "kind", ")", ":", "\n", "    ", "fout_od", "=", "open", "(", "f\"{dataset}_open_domain_with_context/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta_od", "=", "open", "(", "f\"{dataset}_open_domain_with_context/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "fout_mc", "=", "open", "(", "f\"{dataset}_multiple_choice_with_context/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta_mc", "=", "open", "(", "f\"{dataset}_multiple_choice_with_context/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "fout_od_no", "=", "open", "(", "f\"{dataset}_open_domain_with_no_context/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta_od_no", "=", "open", "(", "f\"{dataset}_open_domain_with_no_context/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "fout_mc_no", "=", "open", "(", "f\"{dataset}_multiple_choice_with_no_context/{kind}.tsv\"", ",", "\"w+\"", ")", "\n", "fmeta_mc_no", "=", "open", "(", "f\"{dataset}_multiple_choice_with_no_context/{kind}_meta.txt\"", ",", "\"w+\"", ")", "\n", "counter", "=", "0", "\n", "\n", "dataset", "=", "load_dataset", "(", "'corypaik/prost'", ",", "split", "=", "'test'", ")", "\n", "\n", "for", "row", "in", "range", "(", "len", "(", "dataset", ")", ")", ":", "\n", "        ", "question", "=", "dataset", "[", "row", "]", "[", "'ex_question'", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "open_question", "=", "dataset", "[", "row", "]", "[", "'question'", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"[MASK]\"", ",", "\"_\"", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "context", "=", "dataset", "[", "row", "]", "[", "'context'", "]", ".", "strip", "(", ")", ".", "rstrip", "(", "\"\\n\"", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "id", "=", "dataset", "[", "row", "]", "[", "'name'", "]", "\n", "choices", "=", "[", "dataset", "[", "row", "]", "[", "'A'", "]", ",", "dataset", "[", "row", "]", "[", "'B'", "]", ",", "dataset", "[", "row", "]", "[", "'C'", "]", ",", "dataset", "[", "row", "]", "[", "'D'", "]", "]", "\n", "options", "=", "\" \"", ".", "join", "(", "[", "f\"({chr(ord('A') + i)}) {x}\"", "for", "i", ",", "x", "in", "enumerate", "(", "choices", ")", "]", ")", "\n", "answer_index", "=", "dataset", "[", "row", "]", "[", "'label'", "]", "\n", "answer_string", "=", "choices", "[", "answer_index", "]", "\n", "answer", "=", "chr", "(", "ord", "(", "'A'", ")", "+", "answer_index", ")", "\n", "\n", "fmeta_mc", ".", "write", "(", "f\"{id}\\t{answer} \\n\"", ")", "\n", "fout_mc", ".", "write", "(", "f\"{question} \\\\n{options} \\\\n {context}\\t{answer_string} \\n\"", ")", "\n", "fmeta_od", ".", "write", "(", "f\"{id}\\n\"", ")", "\n", "fout_od", ".", "write", "(", "f\"{open_question} \\\\n {context}\\t{answer_string} \\n\"", ")", "\n", "fmeta_mc_no", ".", "write", "(", "f\"{id}\\t{answer} \\n\"", ")", "\n", "fout_mc_no", ".", "write", "(", "f\"{question} \\\\n{options}\\t{answer_string} \\n\"", ")", "\n", "fmeta_od_no", ".", "write", "(", "f\"{id}\\n\"", ")", "\n", "fout_od_no", ".", "write", "(", "f\"{open_question}\\t{answer_string} \\n\"", ")", "\n", "", "return", "len", "(", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.prost": [[2248, 2252], ["encode_datasets.prost_process", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.prost_process"], ["", "def", "prost", "(", ")", ":", "\n", "    ", "test_count", "=", "prost_process", "(", "\"prost\"", ",", "\"test\"", ")", "\n", "with", "open", "(", "f\"/content/counts.json\"", ",", "\"w+\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"test\"", ":", "test_count", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.qaconv": [[2253, 2294], ["json.load", "open", "os.path.exists", "os.makedirs", "json.load", "count_all.append", "open", "json.dump", "open", "context.strip().replace().replace().replace().replace.strip().replace().replace().replace().replace", "qa_pair[].strip().replace().replace().replace().replace", "len", "src_all.append", "meta_all.append", "open", "fout.write", "open", "fout.write", "[].strip().replace().replace().replace().replace", "context.strip().replace().replace().replace().replace.strip().replace().replace().replace", "qa_pair[].strip().replace().replace().replace", "c[].replace", "[].strip().replace().replace().replace", "x.strip().replace().replace().replace().replace", "context.strip().replace().replace().replace().replace.strip().replace().replace", "qa_pair[].strip().replace().replace", "[].strip().replace().replace", "x.strip().replace().replace().replace", "context.strip().replace().replace().replace().replace.strip().replace", "qa_pair[].strip().replace", "[].strip().replace", "x.strip().replace().replace", "context.strip().replace().replace().replace().replace.strip", "qa_pair[].strip", "[].strip", "x.strip().replace", "x.strip"], "function", ["None"], ["", "", "def", "qaconv", "(", ")", ":", "\n", "    ", "mapping", "=", "{", "\n", "\"trn\"", ":", "\"train\"", ",", "\n", "\"val\"", ":", "\"dev\"", ",", "\n", "\"tst\"", ":", "\"test\"", "\n", "}", "\n", "\n", "article_json", "=", "json", ".", "load", "(", "open", "(", "\"/content/QAConv/data/article_segment.json\"", ")", ")", "\n", "\n", "output_dir", "=", "\"/content/qaconv\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "\n", "", "count_all", "=", "[", "]", "\n", "for", "dtype", "in", "[", "\"trn\"", ",", "\"val\"", ",", "\"tst\"", "]", ":", "\n", "        ", "ques_json", "=", "json", ".", "load", "(", "open", "(", "\"/content/QAConv/data/{}.json\"", ".", "format", "(", "dtype", ")", ")", ")", "\n", "src_all", "=", "[", "]", "\n", "meta_all", "=", "[", "]", "\n", "count", "=", "0", "\n", "for", "qa_pair", "in", "ques_json", ":", "\n", "            ", "count", "+=", "1", "\n", "context", "=", "article_json", "[", "qa_pair", "[", "\"article_segment_id\"", "]", "]", "[", "\"seg_dialog\"", "]", "\n", "context", "=", "\" \"", ".", "join", "(", "[", "'{}: {}'", ".", "format", "(", "c", "[", "\"speaker\"", "]", ",", "c", "[", "\"text\"", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ")", "for", "c", "in", "context", "]", ")", "\n", "context", "=", "context", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "question", "=", "qa_pair", "[", "\"question\"", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "if", "len", "(", "qa_pair", "[", "\"answers\"", "]", ")", ":", "\n", "                ", "answer", "=", "qa_pair", "[", "\"answers\"", "]", "[", "0", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "\n", "all_answers", "=", "\"//\"", ".", "join", "(", "[", "x", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\"\\t\"", ",", "\"\"", ")", ".", "replace", "(", "\"   \"", ",", "\" \"", ")", ".", "replace", "(", "\"  \"", ",", "\" \"", ")", "for", "x", "in", "qa_pair", "[", "\"answers\"", "]", "]", ")", "\n", "", "else", ":", "# unanswerable", "\n", "                ", "all_answers", "=", "\"<No Answer>\"", "\n", "", "src", "=", "\"{} \\\\n {} \\t {}\"", ".", "format", "(", "question", ",", "context", ",", "all_answers", ")", "\n", "src_all", ".", "append", "(", "src", ")", "\n", "id", "=", "qa_pair", "[", "\"id\"", "]", "\n", "meta_all", ".", "append", "(", "f\"{id}\\t{all_answers}\"", ")", "\n", "", "count_all", ".", "append", "(", "count", ")", "\n", "with", "open", "(", "\"{}/{}.tsv\"", ".", "format", "(", "output_dir", ",", "mapping", "[", "dtype", "]", ")", ",", "\"w\"", ")", "as", "fout", ":", "\n", "            ", "fout", ".", "write", "(", "\"\\n\"", ".", "join", "(", "src_all", ")", ")", "\n", "", "with", "open", "(", "\"{}/{}_meta.txt\"", ".", "format", "(", "output_dir", ",", "mapping", "[", "dtype", "]", ")", ",", "\"w\"", ")", "as", "fout", ":", "\n", "            ", "fout", ".", "write", "(", "\"\\n\"", ".", "join", "(", "meta_all", ")", ")", "\n", "", "", "with", "open", "(", "\"{}/counts.json\"", ".", "format", "(", "output_dir", ")", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "\"train\"", ":", "count_all", "[", "0", "]", ",", "\"dev\"", ":", "count_all", "[", "1", "]", ",", "\"test\"", ":", "count_all", "[", "2", "]", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.unified_data.UnifiedQAData.__init__": [[16, 62], ["data_path.replace.replace.replace", "data_path.replace.replace.endswith", "data_path.replace.replace.replace", "data_path.replace.replace.split", "open", "line.split", "[].append", "[].append", "[].append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "logger", ",", "args", ",", "data_path", ",", "is_training", ")", ":", "\n", "        ", "self", ".", "unified_dataset", "=", "[", "\n", "\"narrativeqa\"", ",", "\n", "\"ai2_science_middle\"", ",", "\"ai2_science_elementary\"", ",", "\n", "\"arc_hard\"", ",", "\"arc_easy\"", ",", "\n", "\"mctest_corrected_the_separator\"", ",", "\n", "\"squad1_1\"", ",", "\"squad2\"", ",", "\n", "\"boolq\"", ",", "\n", "\"race_string\"", ",", "\n", "\"openbookqa\"", "]", "\n", "self", ".", "data_path", "=", "data_path", "\n", "self", ".", "data_type", "=", "data_path", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", "\n", "assert", "self", ".", "data_type", "in", "[", "\"train\"", ",", "\"dev\"", ",", "\"test\"", "]", "\n", "\n", "if", "args", ".", "debug", ":", "\n", "            ", "self", ".", "unified_dataset", "=", "self", ".", "unified_dataset", "[", ":", "2", "]", "\n", "self", ".", "data_type", "=", "\"dev\"", "\n", "data_path", "=", "data_path", ".", "replace", "(", "\"train\"", ",", "\"dev\"", ")", "\n", "\n", "", "self", ".", "data", "=", "{", "}", "\n", "for", "dataset", "in", "self", ".", "unified_dataset", ":", "\n", "            ", "assert", "data_path", ".", "endswith", "(", "\".tsv\"", ")", ",", "\"data file has to be in tsv format\"", "\n", "curr_data_path", "=", "data_path", ".", "replace", "(", "\"{}.tsv\"", ".", "format", "(", "self", ".", "data_type", ")", ",", "\n", "\"{}/{}.tsv\"", ".", "format", "(", "dataset", ",", "self", ".", "data_type", ")", ")", "\n", "self", ".", "data", "[", "dataset", "]", "=", "{", "\"id\"", ":", "[", "]", ",", "\"question\"", ":", "[", "]", ",", "\"answer\"", ":", "[", "]", "}", "\n", "with", "open", "(", "curr_data_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "cnt", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "                    ", "question", ",", "answer", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "self", ".", "data", "[", "dataset", "]", "[", "\"id\"", "]", ".", "append", "(", "\"{}-{}-{}\"", ".", "format", "(", "dataset", ",", "self", ".", "data_type", ",", "cnt", ")", ")", "\n", "self", ".", "data", "[", "dataset", "]", "[", "\"question\"", "]", ".", "append", "(", "question", ")", "\n", "self", ".", "data", "[", "dataset", "]", "[", "\"answer\"", "]", ".", "append", "(", "answer", ")", "\n", "cnt", "+=", "1", "\n", "if", "args", ".", "debug", "and", "cnt", "==", "20", ":", "\n", "                        ", "break", "\n", "\n", "", "", "", "", "self", ".", "is_training", "=", "is_training", "\n", "self", ".", "load", "=", "not", "args", ".", "debug", "\n", "self", ".", "logger", "=", "logger", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "max_input_length", "=", "self", ".", "args", ".", "max_input_length", "\n", "self", ".", "tokenizer", "=", "None", "\n", "self", ".", "dataset", "=", "None", "\n", "self", ".", "dataloader", "=", "None", "\n", "self", ".", "cache", "=", "None", "\n", "self", ".", "metric", "=", "\"Accuracy\"", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.unified_data.UnifiedQAData.__len__": [[63, 65], ["numpy.sum", "len", "unified_data.UnifiedQAData.data.values"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "sum", "(", "[", "len", "(", "d", "[", "\"question\"", "]", ")", "for", "d", "in", "self", ".", "data", ".", "values", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.unified_data.UnifiedQAData.decode": [[66, 68], ["unified_data.UnifiedQAData.tokenizer.decode().lower", "unified_data.UnifiedQAData.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.Solver.decode"], ["", "def", "decode", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "decode", "(", "tokens", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "True", ")", ".", "lower", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.unified_data.UnifiedQAData.decode_batch": [[69, 71], ["unified_data.UnifiedQAData.decode"], "methods", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.Solver.decode"], ["", "def", "decode_batch", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "return", "[", "self", ".", "decode", "(", "_tokens", ")", "for", "_tokens", "in", "tokens", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.unified_data.UnifiedQAData.load_dataset": [[72, 115], ["unified_data.UnifiedQAData.tokenizer.__class__.__name__.replace", "os.path.join", "unified_data.MyUnifiedQADataset", "[].replace", "os.path.exists", "unified_data.UnifiedQAData.logger.info", "print", "unified_data.UnifiedQAData.tokenizer.batch_encode_plus", "unified_data.UnifiedQAData.tokenizer.batch_encode_plus", "print", "open", "json.load", "metadata.append", "unified_data.UnifiedQAData.data_path.split", "question.lower", "answer.lower", "open", "json.dump", "unified_data.UnifiedQAData.data_path.split", "len", "len", "len"], "methods", ["None"], ["", "def", "load_dataset", "(", "self", ",", "tokenizer", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "postfix", "=", "self", ".", "tokenizer", ".", "__class__", ".", "__name__", ".", "replace", "(", "\"zer\"", ",", "\"zed\"", ")", "\n", "preprocessed_path", "=", "os", ".", "path", ".", "join", "(", "\n", "\"/\"", ".", "join", "(", "self", ".", "data_path", ".", "split", "(", "\"/\"", ")", "[", ":", "-", "1", "]", ")", ",", "\n", "self", ".", "data_path", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "replace", "(", "\".tsv\"", ",", "\"{}{}-{}.json\"", ".", "format", "(", "\n", "\"-uncased\"", "if", "self", ".", "args", ".", "do_lowercase", "else", "\"\"", ",", "\n", "\"-xbos\"", "if", "self", ".", "args", ".", "append_another_bos", "else", "\"\"", ",", "\n", "postfix", ")", ")", ")", "\n", "if", "self", ".", "load", "and", "os", ".", "path", ".", "exists", "(", "preprocessed_path", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Loading pre-tokenized data from {}\"", ".", "format", "(", "preprocessed_path", ")", ")", "\n", "with", "open", "(", "preprocessed_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "input_ids", ",", "attention_mask", ",", "decoder_input_ids", ",", "decoder_attention_mask", ",", "metadata", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "\"Start tokenizing...\"", ")", "\n", "metadata", ",", "questions", ",", "answers", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "dataset", "in", "self", ".", "unified_dataset", ":", "\n", "                ", "metadata", ".", "append", "(", "(", "len", "(", "questions", ")", ",", "len", "(", "questions", ")", "+", "len", "(", "self", ".", "data", "[", "dataset", "]", "[", "\"question\"", "]", ")", ")", ")", "\n", "questions", "+=", "self", ".", "data", "[", "dataset", "]", "[", "\"question\"", "]", "\n", "answers", "+=", "self", ".", "data", "[", "dataset", "]", "[", "\"answer\"", "]", "\n", "", "if", "self", ".", "args", ".", "do_lowercase", ":", "\n", "                ", "questions", "=", "[", "question", ".", "lower", "(", ")", "for", "question", "in", "questions", "]", "\n", "answers", "=", "[", "answer", ".", "lower", "(", ")", "for", "answer", "in", "answers", "]", "\n", "", "if", "self", ".", "args", ".", "append_another_bos", ":", "\n", "                ", "questions", "=", "[", "\"<s> \"", "+", "question", "for", "question", "in", "questions", "]", "\n", "answers", "=", "[", "\"<s> \"", "+", "answer", "for", "answer", "in", "answers", "]", "\n", "", "question_input", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "questions", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_input_length", ")", "\n", "answer_input", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "answers", ",", "\n", "pad_to_max_length", "=", "True", ")", "\n", "input_ids", ",", "attention_mask", "=", "question_input", "[", "\"input_ids\"", "]", ",", "question_input", "[", "\"attention_mask\"", "]", "\n", "decoder_input_ids", ",", "decoder_attention_mask", "=", "answer_input", "[", "\"input_ids\"", "]", ",", "answer_input", "[", "\"attention_mask\"", "]", "\n", "print", "(", "\"Finish tokenizering...\"", ")", "\n", "if", "self", ".", "load", ":", "\n", "                ", "with", "open", "(", "preprocessed_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "                    ", "json", ".", "dump", "(", "[", "input_ids", ",", "attention_mask", ",", "\n", "decoder_input_ids", ",", "decoder_attention_mask", ",", "metadata", "]", ",", "f", ")", "\n", "\n", "", "", "", "self", ".", "metadata", "=", "metadata", "\n", "self", ".", "dataset", "=", "MyUnifiedQADataset", "(", "input_ids", ",", "attention_mask", ",", "\n", "decoder_input_ids", ",", "decoder_attention_mask", ",", "\n", "metadata", "=", "metadata", ",", "is_training", "=", "self", ".", "is_training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.unified_data.UnifiedQAData.load_dataloader": [[117, 121], ["data.MyDataLoader"], "methods", ["None"], ["", "def", "load_dataloader", "(", "self", ",", "do_return", "=", "False", ")", ":", "\n", "        ", "self", ".", "dataloader", "=", "MyDataLoader", "(", "self", ".", "args", ",", "self", ".", "dataset", ",", "self", ".", "is_training", ")", "\n", "if", "do_return", ":", "\n", "            ", "return", "self", ".", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.unified_data.UnifiedQAData.evaluate": [[122, 135], ["enumerate", "len", "len", "len", "len", "numpy.mean", "ems.append", "len", "len", "unified_data.UnifiedQAData.logger.info", "unified_data.get_exact_match", "zip"], "methods", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.get_exact_match"], ["", "", "def", "evaluate", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "assert", "len", "(", "predictions", ")", "==", "len", "(", "self", ")", ",", "(", "len", "(", "predictions", ")", ",", "len", "(", "self", ")", ")", "\n", "ems", "=", "[", "]", "\n", "for", "i", ",", "dataset", "in", "enumerate", "(", "self", ".", "unified_dataset", ")", ":", "\n", "            ", "start", ",", "end", "=", "self", ".", "metadata", "[", "i", "]", "\n", "_predictions", "=", "predictions", "[", "start", ":", "end", "]", "\n", "assert", "len", "(", "_predictions", ")", "==", "len", "(", "self", ".", "data", "[", "dataset", "]", "[", "\"answer\"", "]", ")", "\n", "em", "=", "np", ".", "mean", "(", "[", "get_exact_match", "(", "prediction", ",", "gt", ")", "for", "(", "prediction", ",", "gt", ")", "in", "zip", "(", "_predictions", ",", "self", ".", "data", "[", "dataset", "]", "[", "\"answer\"", "]", ")", "]", ")", "\n", "ems", ".", "append", "(", "em", ")", "\n", "if", "self", ".", "args", ".", "verbose", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "\"%s Accuracy = %.2f\"", "%", "(", "dataset", ",", "100", "*", "em", ")", ")", "\n", "", "", "return", "ems", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.unified_data.UnifiedQAData.save_predictions": [[136, 148], ["enumerate", "os.path.join", "unified_data.UnifiedQAData.logger.info", "len", "len", "len", "len", "open", "json.dump", "len", "len"], "methods", ["None"], ["", "def", "save_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "assert", "len", "(", "predictions", ")", "==", "len", "(", "self", ")", ",", "(", "len", "(", "predictions", ")", ",", "len", "(", "self", ")", ")", "\n", "prediction_dict", "=", "{", "}", "\n", "for", "i", ",", "dataset", "in", "enumerate", "(", "self", ".", "unified_dataset", ")", ":", "\n", "            ", "start", ",", "end", "=", "self", ".", "metadata", "[", "i", "]", "\n", "_predictions", "=", "predictions", "[", "start", ":", "end", "]", "\n", "assert", "len", "(", "_predictions", ")", "==", "len", "(", "self", ".", "data", "[", "dataset", "]", "[", "\"answer\"", "]", ")", "\n", "prediction_dict", "[", "dataset", "]", "=", "_predictions", "\n", "", "save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output_dir", ",", "\"{}predictions.json\"", ".", "format", "(", "self", ".", "args", ".", "prefix", ")", ")", "\n", "with", "open", "(", "save_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "prediction_dict", ",", "f", ")", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Saved prediction in {}\"", ".", "format", "(", "save_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.unified_data.MyUnifiedQADataset.__init__": [[170, 189], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "len", "len", "len", "len", "len", "numpy.random.permutation", "len", "range", "len", "numpy.min"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "input_ids", ",", "attention_mask", ",", "\n", "decoder_input_ids", ",", "decoder_attention_mask", ",", "\n", "metadata", ",", "\n", "is_training", "=", "False", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "torch", ".", "LongTensor", "(", "input_ids", ")", "\n", "self", ".", "attention_mask", "=", "torch", ".", "LongTensor", "(", "attention_mask", ")", "\n", "self", ".", "decoder_input_ids", "=", "torch", ".", "LongTensor", "(", "decoder_input_ids", ")", "\n", "self", ".", "decoder_attention_mask", "=", "torch", ".", "LongTensor", "(", "decoder_attention_mask", ")", "\n", "self", ".", "metadata", "=", "metadata", "\n", "self", ".", "is_training", "=", "is_training", "\n", "\n", "assert", "len", "(", "self", ".", "input_ids", ")", "==", "len", "(", "self", ".", "attention_mask", ")", "==", "len", "(", "self", ".", "decoder_input_ids", ")", "==", "len", "(", "self", ".", "decoder_attention_mask", ")", "\n", "assert", "len", "(", "self", ".", "input_ids", ")", "==", "metadata", "[", "-", "1", "]", "[", "-", "1", "]", "\n", "\n", "self", ".", "indices", "=", "[", "np", ".", "random", ".", "permutation", "(", "range", "(", "start", ",", "end", ")", ")", "for", "start", ",", "end", "in", "self", ".", "metadata", "]", "\n", "self", ".", "positions", "=", "[", "0", "for", "_", "in", "self", ".", "metadata", "]", "\n", "self", ".", "length", "=", "len", "(", "self", ".", "metadata", ")", "*", "np", ".", "min", "(", "[", "end", "-", "start", "for", "start", ",", "end", "in", "self", ".", "metadata", "]", ")", "if", "is_training", "else", "len", "(", "self", ".", "input_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.unified_data.MyUnifiedQADataset.__len__": [[190, 192], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.unified_data.MyUnifiedQADataset.__getitem__": [[193, 208], ["len", "len", "numpy.random.permutation", "range"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "not", "self", ".", "is_training", ":", "\n", "            ", "return", "self", ".", "input_ids", "[", "idx", "]", ",", "self", ".", "attention_mask", "[", "idx", "]", "\n", "\n", "", "idx", "=", "idx", "%", "len", "(", "self", ".", "metadata", ")", "\n", "if", "self", ".", "positions", "[", "idx", "]", "==", "len", "(", "self", ".", "indices", "[", "idx", "]", ")", ":", "\n", "            ", "start", ",", "end", "=", "self", ".", "metadata", "[", "idx", "]", "\n", "self", ".", "indices", "[", "idx", "]", "=", "np", ".", "random", ".", "permutation", "(", "range", "(", "start", ",", "end", ")", ")", "\n", "self", ".", "positions", "[", "idx", "]", "=", "0", "\n", "\n", "", "dp_idx", "=", "self", ".", "indices", "[", "idx", "]", "[", "self", ".", "positions", "[", "idx", "]", "]", "\n", "self", ".", "positions", "[", "idx", "]", "+=", "1", "\n", "\n", "return", "self", ".", "input_ids", "[", "dp_idx", "]", ",", "self", ".", "attention_mask", "[", "dp_idx", "]", ",", "self", ".", "decoder_input_ids", "[", "dp_idx", "]", ",", "self", ".", "decoder_attention_mask", "[", "dp_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.unified_data.get_exact_match": [[149, 155], ["type", "numpy.max", "unified_data.normalize_answer", "unified_data.normalize_answer", "len", "unified_data.get_exact_match"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.get_exact_match"], ["", "", "def", "get_exact_match", "(", "prediction", ",", "groundtruth", ")", ":", "\n", "    ", "if", "type", "(", "groundtruth", ")", "==", "list", ":", "\n", "        ", "if", "len", "(", "groundtruth", ")", "==", "0", ":", "\n", "            ", "return", "0", "\n", "", "return", "np", ".", "max", "(", "[", "get_exact_match", "(", "prediction", ",", "gt", ")", "for", "gt", "in", "groundtruth", "]", ")", "\n", "", "return", "(", "normalize_answer", "(", "prediction", ")", "==", "normalize_answer", "(", "groundtruth", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.unified_data.normalize_answer": [[156, 167], ["unified_data.normalize_answer.white_space_fix"], "function", ["None"], ["", "def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.cli.main": [[31, 131], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logging.getLogger", "logging.getLogger.info", "logging.getLogger.info", "random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.device_count", "logging.getLogger.info", "run.run", "os.path.exists", "os.listdir", "print", "os.path.exists", "os.makedirs", "torch.cuda.manual_seed_all", "ValueError", "ValueError", "ValueError", "ValueError", "logging.FileHandler", "logging.StreamHandler", "os.path.join"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart.run.run"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Basic parameters", "\n", "parser", ".", "add_argument", "(", "\"--train_file\"", ",", "default", "=", "\"data/train.tsv\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--predict_file\"", ",", "default", "=", "\"data/dev.tsv\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_predict\"", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "\"--is_unifiedqa\"", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "\"--skip_inference\"", ",", "action", "=", "'store_true'", ")", "\n", "\n", "## Model parameters", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint_step'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lowercase\"", ",", "action", "=", "'store_true'", ")", "\n", "\n", "# Preprocessing/decoding-related parameters", "\n", "parser", ".", "add_argument", "(", "'--max_input_length'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "parser", ".", "add_argument", "(", "'--max_output_length'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "'--num_beams'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "\"--append_another_bos\"", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "\n", "# Training-related parameters", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "default", "=", "40", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--predict_batch_size\"", ",", "default", "=", "400", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "1e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_proportion\"", ",", "default", "=", "0.01", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gradient_accumulation_steps\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "10000.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--wait_step'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--verbose\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"If true, all of the warnings related to data processing will be printed. \"", "\n", "\"A number of warnings are expected for a normal SQuAD evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_period'", ",", "type", "=", "int", ",", "default", "=", "2000", ",", "\n", "help", "=", "\"Evaluate & save model\"", ")", "\n", "parser", ".", "add_argument", "(", "'--prefix'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "\"Prefix for saving predictions\"", ")", "\n", "parser", ".", "add_argument", "(", "'--debug'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Use a subset of data for debugging\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", ":", "\n", "        ", "print", "(", "\"Output directory () already exists and is not empty.\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "##### Start writing logs", "\n", "\n", "", "log_filename", "=", "\"{}log.txt\"", ".", "format", "(", "\"\"", "if", "args", ".", "do_train", "else", "\"eval_\"", ")", "\n", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s - %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "\n", "level", "=", "logging", ".", "INFO", ",", "\n", "handlers", "=", "[", "logging", ".", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "log_filename", ")", ")", ",", "\n", "logging", ".", "StreamHandler", "(", ")", "]", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "args", ")", "\n", "logger", ".", "info", "(", "args", ".", "output_dir", ")", "\n", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n", "", "if", "not", "args", ".", "do_train", "and", "not", "args", ".", "do_predict", ":", "\n", "        ", "raise", "ValueError", "(", "\"At least one of `do_train` or `do_predict` must be True.\"", ")", "\n", "\n", "", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "not", "args", ".", "train_file", ":", "\n", "            ", "raise", "ValueError", "(", "\"If `do_train` is True, then `train_file` must be specified.\"", ")", "\n", "", "if", "not", "args", ".", "predict_file", ":", "\n", "            ", "raise", "ValueError", "(", "\"If `do_train` is True, then `predict_file` must be specified.\"", ")", "\n", "\n", "", "", "if", "args", ".", "do_predict", ":", "\n", "        ", "if", "not", "args", ".", "predict_file", ":", "\n", "            ", "raise", "ValueError", "(", "\"If `do_predict` is True, then `predict_file` must be specified.\"", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"Using {} gpus\"", ".", "format", "(", "args", ".", "n_gpu", ")", ")", "\n", "run", "(", "args", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.__init__": [[13, 64], ["data.QAData.data_path.endswith", "all", "data.QAData.data[].keys", "data_path.replace", "open", "type", "type", "range", "data.QAData.data.append", "print", "len", "str", "enumerate", "enumerate", "NotImplementedError", "line.split"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "logger", ",", "args", ",", "data_path", ",", "is_training", ")", ":", "\n", "        ", "self", ".", "data_path", "=", "data_path", "\n", "if", "args", ".", "debug", ":", "\n", "            ", "self", ".", "data_path", "=", "data_path", ".", "replace", "(", "\"train\"", ",", "\"dev\"", ")", "\n", "", "if", "\"/test\"", "in", "self", ".", "data_path", ":", "\n", "            ", "self", ".", "data_type", "=", "\"test\"", "\n", "", "elif", "\"/dev\"", "in", "self", ".", "data_path", ":", "\n", "            ", "self", ".", "data_type", "=", "\"dev\"", "\n", "", "elif", "\"/train\"", "in", "self", ".", "data_path", ":", "\n", "            ", "self", ".", "data_type", "=", "\"train\"", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "", "assert", "self", ".", "data_path", ".", "endswith", "(", "\".tsv\"", ")", ",", "\"data file has to be in tsv format.\"", "\n", "self", ".", "data", "=", "[", "]", "\n", "with", "open", "(", "self", ".", "data_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "cnt", "=", "0", "\n", "invalid_lines", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "                ", "try", ":", "\n", "                    ", "question", ",", "answer", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "", "except", "Exception", ":", "\n", "                    ", "invalid_lines", "+=", "1", "\n", "continue", "\n", "", "self", ".", "data", ".", "append", "(", "{", "\n", "\"id\"", ":", "\"{}-{}\"", ".", "format", "(", "self", ".", "data_type", ",", "cnt", ")", ",", "\n", "\"question\"", ":", "question", ",", "\n", "\"answer\"", ":", "[", "answer", "]", "\n", "}", ")", "\n", "", "if", "invalid_lines", ">", "0", ":", "\n", "                ", "print", "(", "\"# invalid lines: {}\"", ".", "format", "(", "invalid_lines", ")", ")", "\n", "\n", "", "", "if", "args", ".", "debug", ":", "\n", "            ", "self", ".", "data", "=", "self", ".", "data", "[", ":", "40", "]", "\n", "", "assert", "type", "(", "self", ".", "data", ")", "==", "list", "\n", "assert", "all", "(", "[", "\"id\"", "in", "d", "for", "d", "in", "self", ".", "data", "]", ")", ",", "self", ".", "data", "[", "0", "]", ".", "keys", "(", ")", "\n", "if", "type", "(", "self", ".", "data", "[", "0", "]", "[", "\"id\"", "]", ")", "==", "int", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "data", ")", ")", ":", "\n", "                ", "self", ".", "data", "[", "i", "]", "[", "\"id\"", "]", "=", "str", "(", "self", ".", "data", "[", "i", "]", "[", "\"id\"", "]", ")", "\n", "\n", "", "", "self", ".", "index2id", "=", "{", "i", ":", "d", "[", "\"id\"", "]", "for", "i", ",", "d", "in", "enumerate", "(", "self", ".", "data", ")", "}", "\n", "self", ".", "id2index", "=", "{", "d", "[", "\"id\"", "]", ":", "i", "for", "i", ",", "d", "in", "enumerate", "(", "self", ".", "data", ")", "}", "\n", "self", ".", "is_training", "=", "is_training", "\n", "self", ".", "load", "=", "not", "args", ".", "debug", "\n", "self", ".", "logger", "=", "logger", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "metric", "=", "\"EM\"", "\n", "self", ".", "max_input_length", "=", "self", ".", "args", ".", "max_input_length", "\n", "self", ".", "tokenizer", "=", "None", "\n", "self", ".", "dataset", "=", "None", "\n", "self", ".", "dataloader", "=", "None", "\n", "self", ".", "cache", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.__len__": [[65, 67], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.decode": [[68, 72], ["data.QAData.tokenizer.decode().strip", "data.QAData.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.Solver.decode"], ["", "def", "decode", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "decode", "(", "tokens", ",", "\n", "skip_special_tokens", "=", "True", ",", "\n", "clean_up_tokenization_spaces", "=", "True", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.decode_batch": [[73, 75], ["data.QAData.decode"], "methods", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.Solver.decode"], ["", "def", "decode_batch", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "return", "[", "self", ".", "decode", "(", "_tokens", ")", "for", "_tokens", "in", "tokens", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.flatten": [[76, 83], ["metadata.append", "type", "len", "len", "len"], "methods", ["None"], ["", "def", "flatten", "(", "self", ",", "answers", ")", ":", "\n", "        ", "new_answers", ",", "metadata", "=", "[", "]", ",", "[", "]", "\n", "for", "answer", "in", "answers", ":", "\n", "            ", "assert", "type", "(", "answer", ")", "==", "list", "\n", "metadata", ".", "append", "(", "(", "len", "(", "new_answers", ")", ",", "len", "(", "new_answers", ")", "+", "len", "(", "answer", ")", ")", ")", "\n", "new_answers", "+=", "answer", "\n", "", "return", "new_answers", ",", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.load_dataset": [[84, 137], ["tokenizer.__class__.__name__.replace", "os.path.join", "data.MyQADataset", "data.QAData.logger.info", "[].replace", "os.path.exists", "data.QAData.logger.info", "print", "data.QAData.flatten", "tokenizer.batch_encode_plus", "tokenizer.batch_encode_plus", "open", "json.load", "len", "data.QAData.data_path.split", "data.QAData.data_path.endswith", "d[].endswith", "question.lower", "answer.lower", "open", "json.dump", "data.QAData.data_path.split"], "methods", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.flatten"], ["", "def", "load_dataset", "(", "self", ",", "tokenizer", ",", "do_return", "=", "False", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "postfix", "=", "tokenizer", ".", "__class__", ".", "__name__", ".", "replace", "(", "\"zer\"", ",", "\"zed\"", ")", "\n", "preprocessed_path", "=", "os", ".", "path", ".", "join", "(", "\n", "\"/\"", ".", "join", "(", "self", ".", "data_path", ".", "split", "(", "\"/\"", ")", "[", ":", "-", "1", "]", ")", ",", "\n", "self", ".", "data_path", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "replace", "(", "\n", "\".tsv\"", "if", "self", ".", "data_path", ".", "endswith", "(", "\".tsv\"", ")", "else", "\".json\"", ",", "\n", "\"{}{}-{}.json\"", ".", "format", "(", "\n", "\"-uncased\"", "if", "self", ".", "args", ".", "do_lowercase", "else", "\"\"", ",", "\n", "\"-xbos\"", "if", "self", ".", "args", ".", "append_another_bos", "else", "\"\"", ",", "\n", "postfix", ")", ")", ")", "\n", "if", "self", ".", "load", "and", "os", ".", "path", ".", "exists", "(", "preprocessed_path", ")", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Loading pre-tokenized data from {}\"", ".", "format", "(", "preprocessed_path", ")", ")", "\n", "with", "open", "(", "preprocessed_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "input_ids", ",", "attention_mask", ",", "decoder_input_ids", ",", "decoder_attention_mask", ",", "metadata", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "\"Start tokenizing...\"", ")", "\n", "questions", "=", "[", "d", "[", "\"question\"", "]", "if", "d", "[", "\"question\"", "]", ".", "endswith", "(", "\"?\"", ")", "else", "d", "[", "\"question\"", "]", "+", "\"?\"", "\n", "for", "d", "in", "self", ".", "data", "]", "\n", "answers", "=", "[", "d", "[", "\"answer\"", "]", "for", "d", "in", "self", ".", "data", "]", "\n", "answers", ",", "metadata", "=", "self", ".", "flatten", "(", "answers", ")", "\n", "if", "self", ".", "args", ".", "do_lowercase", ":", "\n", "                ", "questions", "=", "[", "question", ".", "lower", "(", ")", "for", "question", "in", "questions", "]", "\n", "answers", "=", "[", "answer", ".", "lower", "(", ")", "for", "answer", "in", "answers", "]", "\n", "", "if", "self", ".", "args", ".", "append_another_bos", ":", "\n", "                ", "questions", "=", "[", "\"<s> \"", "+", "question", "for", "question", "in", "questions", "]", "\n", "answers", "=", "[", "\"<s> \"", "+", "answer", "for", "answer", "in", "answers", "]", "\n", "", "question_input", "=", "tokenizer", ".", "batch_encode_plus", "(", "questions", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_input_length", ")", "\n", "answer_input", "=", "tokenizer", ".", "batch_encode_plus", "(", "answers", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "max_length", "=", "self", ".", "args", ".", "max_output_length", ")", "\n", "input_ids", ",", "attention_mask", "=", "question_input", "[", "\"input_ids\"", "]", ",", "question_input", "[", "\"attention_mask\"", "]", "\n", "decoder_input_ids", ",", "decoder_attention_mask", "=", "answer_input", "[", "\"input_ids\"", "]", ",", "answer_input", "[", "\"attention_mask\"", "]", "\n", "if", "self", ".", "load", ":", "\n", "                ", "preprocessed_data", "=", "[", "input_ids", ",", "attention_mask", ",", "\n", "decoder_input_ids", ",", "decoder_attention_mask", ",", "\n", "metadata", "]", "\n", "with", "open", "(", "preprocessed_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "                    ", "json", ".", "dump", "(", "[", "input_ids", ",", "attention_mask", ",", "\n", "decoder_input_ids", ",", "decoder_attention_mask", ",", "\n", "metadata", "]", ",", "f", ")", "\n", "\n", "", "", "", "self", ".", "dataset", "=", "MyQADataset", "(", "input_ids", ",", "attention_mask", ",", "\n", "decoder_input_ids", ",", "decoder_attention_mask", ",", "\n", "in_metadata", "=", "None", ",", "out_metadata", "=", "metadata", ",", "\n", "is_training", "=", "self", ".", "is_training", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Loaded {} examples from {} data\"", ".", "format", "(", "len", "(", "self", ".", "dataset", ")", ",", "self", ".", "data_type", ")", ")", "\n", "\n", "if", "do_return", ":", "\n", "            ", "return", "self", ".", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.load_dataloader": [[138, 142], ["data.MyDataLoader"], "methods", ["None"], ["", "", "def", "load_dataloader", "(", "self", ",", "do_return", "=", "False", ")", ":", "\n", "        ", "self", ".", "dataloader", "=", "MyDataLoader", "(", "self", ".", "args", ",", "self", ".", "dataset", ",", "self", ".", "is_training", ")", "\n", "if", "do_return", ":", "\n", "            ", "return", "self", ".", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.evaluate": [[143, 149], ["zip", "len", "len", "len", "len", "ems.append", "data.get_exact_match"], "methods", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.get_exact_match"], ["", "", "def", "evaluate", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "assert", "len", "(", "predictions", ")", "==", "len", "(", "self", ")", ",", "(", "len", "(", "predictions", ")", ",", "len", "(", "self", ")", ")", "\n", "ems", "=", "[", "]", "\n", "for", "(", "prediction", ",", "dp", ")", "in", "zip", "(", "predictions", ",", "self", ".", "data", ")", ":", "\n", "            ", "ems", ".", "append", "(", "get_exact_match", "(", "prediction", ",", "dp", "[", "\"answer\"", "]", ")", ")", "\n", "", "return", "ems", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.save_predictions": [[150, 157], ["os.path.join", "data.QAData.logger.info", "len", "len", "len", "len", "open", "json.dump"], "methods", ["None"], ["", "def", "save_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "assert", "len", "(", "predictions", ")", "==", "len", "(", "self", ")", ",", "(", "len", "(", "predictions", ")", ",", "len", "(", "self", ")", ")", "\n", "#prediction_dict = {dp[\"id\"]:prediction for dp, prediction in zip(self.data, predictions)}", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output_dir", ",", "\"{}predictions.json\"", ".", "format", "(", "self", ".", "args", ".", "prefix", ")", ")", "\n", "with", "open", "(", "save_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "predictions", ",", "f", ")", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Saved prediction in {}\"", ".", "format", "(", "save_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.MyQADataset.__init__": [[179, 196], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "list", "list", "len", "len", "len", "len", "zip", "zip", "range", "range", "range", "range", "len", "len", "len", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "input_ids", ",", "attention_mask", ",", "\n", "decoder_input_ids", ",", "decoder_attention_mask", ",", "\n", "in_metadata", "=", "None", ",", "out_metadata", "=", "None", ",", "\n", "is_training", "=", "False", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "torch", ".", "LongTensor", "(", "input_ids", ")", "\n", "self", ".", "attention_mask", "=", "torch", ".", "LongTensor", "(", "attention_mask", ")", "\n", "self", ".", "decoder_input_ids", "=", "torch", ".", "LongTensor", "(", "decoder_input_ids", ")", "\n", "self", ".", "decoder_attention_mask", "=", "torch", ".", "LongTensor", "(", "decoder_attention_mask", ")", "\n", "self", ".", "in_metadata", "=", "list", "(", "zip", "(", "range", "(", "len", "(", "input_ids", ")", ")", ",", "range", "(", "1", ",", "1", "+", "len", "(", "input_ids", ")", ")", ")", ")", "if", "in_metadata", "is", "None", "else", "in_metadata", "\n", "self", ".", "out_metadata", "=", "list", "(", "zip", "(", "range", "(", "len", "(", "decoder_input_ids", ")", ")", ",", "range", "(", "1", ",", "1", "+", "len", "(", "decoder_input_ids", ")", ")", ")", ")", "if", "out_metadata", "is", "None", "else", "out_metadata", "\n", "self", ".", "is_training", "=", "is_training", "\n", "\n", "assert", "len", "(", "self", ".", "input_ids", ")", "==", "len", "(", "self", ".", "attention_mask", ")", "==", "self", ".", "in_metadata", "[", "-", "1", "]", "[", "-", "1", "]", "\n", "assert", "len", "(", "self", ".", "decoder_input_ids", ")", "==", "len", "(", "self", ".", "decoder_attention_mask", ")", "==", "self", ".", "out_metadata", "[", "-", "1", "]", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.MyQADataset.__len__": [[197, 199], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "in_metadata", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.MyQADataset.__getitem__": [[200, 209], ["numpy.random.choice", "numpy.random.choice", "range", "range"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "not", "self", ".", "is_training", ":", "\n", "            ", "idx", "=", "self", ".", "in_metadata", "[", "idx", "]", "[", "0", "]", "\n", "return", "self", ".", "input_ids", "[", "idx", "]", ",", "self", ".", "attention_mask", "[", "idx", "]", "\n", "\n", "", "in_idx", "=", "np", ".", "random", ".", "choice", "(", "range", "(", "*", "self", ".", "in_metadata", "[", "idx", "]", ")", ")", "\n", "out_idx", "=", "np", ".", "random", ".", "choice", "(", "range", "(", "*", "self", ".", "out_metadata", "[", "idx", "]", ")", ")", "\n", "return", "self", ".", "input_ids", "[", "in_idx", "]", ",", "self", ".", "attention_mask", "[", "in_idx", "]", ",", "self", ".", "decoder_input_ids", "[", "out_idx", "]", ",", "self", ".", "decoder_attention_mask", "[", "out_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.MyDataLoader.__init__": [[212, 220], ["torch.utils.data.DataLoader.__init__", "torch.utils.data.RandomSampler", "torch.utils.data.SequentialSampler"], "methods", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.Solver.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "dataset", ",", "is_training", ")", ":", "\n", "        ", "if", "is_training", ":", "\n", "            ", "sampler", "=", "RandomSampler", "(", "dataset", ")", "\n", "batch_size", "=", "args", ".", "train_batch_size", "\n", "", "else", ":", "\n", "            ", "sampler", "=", "SequentialSampler", "(", "dataset", ")", "\n", "batch_size", "=", "args", ".", "predict_batch_size", "\n", "", "super", "(", "MyDataLoader", ",", "self", ")", ".", "__init__", "(", "dataset", ",", "sampler", "=", "sampler", ",", "batch_size", "=", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.get_exact_match": [[158, 164], ["type", "numpy.max", "data.normalize_answer", "data.normalize_answer", "len", "data.get_exact_match"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.get_exact_match"], ["", "", "def", "get_exact_match", "(", "prediction", ",", "groundtruth", ")", ":", "\n", "    ", "if", "type", "(", "groundtruth", ")", "==", "list", ":", "\n", "        ", "if", "len", "(", "groundtruth", ")", "==", "0", ":", "\n", "            ", "return", "0", "\n", "", "return", "np", ".", "max", "(", "[", "get_exact_match", "(", "prediction", ",", "gt", ")", "for", "gt", "in", "groundtruth", "]", ")", "\n", "", "return", "(", "normalize_answer", "(", "prediction", ")", "==", "normalize_answer", "(", "groundtruth", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.normalize_answer": [[165, 176], ["data.normalize_answer.white_space_fix"], "function", ["None"], ["", "def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.run.run": [[13, 64], ["transformers.BartTokenizer.from_pretrained", "unified_data.UnifiedQAData", "data.QAData", "data.QAData.load_dataset", "data.QAData.load_dataloader", "data.QAData.load_dataset", "data.QAData.load_dataloader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "run.train", "bart.MyBart.from_pretrained", "logger.info", "torch.nn.DataParallel.eval", "run.inference", "logger.info", "unified_data.UnifiedQAData", "data.QAData", "bart.MyBart.from_pretrained", "bart.MyBart.from_pretrained", "torch.nn.DataParallel", "torch.nn.DataParallel.to", "os.path.join", "torch.nn.DataParallel.to", "torch.device", "torch.load", "torch.device", "torch.load", "torch.nn.DataParallel.named_parameters", "torch.nn.DataParallel.named_parameters", "any", "numpy.mean", "any"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.load_dataset", "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.load_dataloader", "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.load_dataset", "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.load_dataloader", "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.run.train", "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.run.inference"], ["def", "run", "(", "args", ",", "logger", ")", ":", "\n", "    ", "tokenizer", "=", "BartTokenizer", ".", "from_pretrained", "(", "\"bart-large\"", ")", "\n", "\n", "if", "args", ".", "is_unifiedqa", ":", "\n", "        ", "dev_data", "=", "UnifiedQAData", "(", "logger", ",", "args", ",", "args", ".", "predict_file", ",", "False", ")", "\n", "", "else", ":", "\n", "        ", "dev_data", "=", "QAData", "(", "logger", ",", "args", ",", "args", ".", "predict_file", ",", "False", ")", "\n", "\n", "", "if", "not", "args", ".", "skip_inference", ":", "\n", "        ", "dev_data", ".", "load_dataset", "(", "tokenizer", ")", "\n", "dev_data", ".", "load_dataloader", "(", ")", "\n", "\n", "", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "is_unifiedqa", ":", "\n", "            ", "train_data", "=", "UnifiedQAData", "(", "logger", ",", "args", ",", "args", ".", "train_file", ",", "True", ")", "\n", "", "else", ":", "\n", "            ", "train_data", "=", "QAData", "(", "logger", ",", "args", ",", "args", ".", "train_file", ",", "True", ")", "\n", "", "train_data", ".", "load_dataset", "(", "tokenizer", ")", "\n", "train_data", ".", "load_dataloader", "(", ")", "\n", "\n", "if", "args", ".", "checkpoint", "is", "not", "None", ":", "\n", "            ", "model", "=", "MyBart", ".", "from_pretrained", "(", "\"bart-large\"", ",", "\n", "state_dict", "=", "torch", ".", "load", "(", "args", ".", "checkpoint", ")", ")", "\n", "", "else", ":", "\n", "            ", "model", "=", "MyBart", ".", "from_pretrained", "(", "\"bart-large\"", ")", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "            ", "model", ".", "to", "(", "torch", ".", "device", "(", "\"cuda\"", ")", ")", "\n", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "\n", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "\n", "num_training_steps", "=", "100000", ")", "\n", "train", "(", "args", ",", "logger", ",", "model", ",", "train_data", ",", "dev_data", ",", "optimizer", ",", "scheduler", ")", "\n", "\n", "", "if", "args", ".", "do_predict", ":", "\n", "        ", "checkpoint", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'best-model.pt'", ")", "if", "args", ".", "checkpoint", "is", "None", "else", "args", ".", "checkpoint", "\n", "model", "=", "MyBart", ".", "from_pretrained", "(", "\"bart-large\"", ",", "\n", "state_dict", "=", "torch", ".", "load", "(", "checkpoint", ")", ")", "\n", "logger", ".", "info", "(", "\"Loading checkpoint from {}\"", ".", "format", "(", "checkpoint", ")", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "            ", "model", ".", "to", "(", "torch", ".", "device", "(", "\"cuda\"", ")", ")", "\n", "", "model", ".", "eval", "(", ")", "\n", "ems", "=", "inference", "(", "model", ",", "dev_data", ",", "save_predictions", "=", "True", ")", "\n", "logger", ".", "info", "(", "\"%s on %s data: %.2f\"", "%", "(", "dev_data", ".", "metric", ",", "dev_data", ".", "data_type", ",", "np", ".", "mean", "(", "ems", ")", "*", "100", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.run.train": [[65, 147], ["model.train", "logger.info", "range", "range", "int", "scheduler.step", "key.startswith", "_convert"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart.run.train"], ["", "", "def", "train", "(", "args", ",", "logger", ",", "model", ",", "train_data", ",", "dev_data", ",", "optimizer", ",", "scheduler", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "global_step", "=", "0", "\n", "train_losses", "=", "[", "]", "\n", "best_accuracy", "=", "-", "1", "\n", "stop_training", "=", "False", "\n", "\n", "if", "args", ".", "checkpoint_step", ">", "0", ":", "\n", "        ", "for", "_", "in", "range", "(", "args", ".", "checkpoint_step", ")", ":", "\n", "            ", "global_step", "+=", "1", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "", "", "def", "convert_to_single_gpu", "(", "state_dict", ")", ":", "\n", "        ", "def", "_convert", "(", "key", ")", ":", "\n", "            ", "if", "key", ".", "startswith", "(", "'module.'", ")", ":", "\n", "                ", "return", "key", "[", "7", ":", "]", "\n", "", "return", "key", "\n", "", "return", "{", "_convert", "(", "key", ")", ":", "value", "for", "key", ",", "value", "in", "state_dict", ".", "items", "(", ")", "}", "\n", "\n", "", "logger", ".", "info", "(", "\"Starting training!\"", ")", "\n", "for", "epoch", "in", "range", "(", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "        ", "for", "batch", "in", "train_data", ".", "dataloader", ":", "\n", "            ", "global_step", "+=", "1", "\n", "batch", "=", "[", "b", ".", "to", "(", "torch", ".", "device", "(", "\"cuda\"", ")", ")", "for", "b", "in", "batch", "]", "\n", "loss", "=", "model", "(", "input_ids", "=", "batch", "[", "0", "]", ",", "attention_mask", "=", "batch", "[", "1", "]", ",", "\n", "decoder_input_ids", "=", "batch", "[", "2", "]", ",", "decoder_attention_mask", "=", "batch", "[", "3", "]", ",", "\n", "is_training", "=", "True", ")", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu.", "\n", "", "if", "torch", ".", "isnan", "(", "loss", ")", ".", "data", ":", "\n", "                ", "logger", ".", "info", "(", "\"Stop training because loss=%s\"", "%", "(", "loss", ".", "data", ")", ")", "\n", "stop_training", "=", "True", "\n", "break", "\n", "", "train_losses", ".", "append", "(", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "global_step", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "optimizer", ".", "step", "(", ")", "# We have accumulated enought gradients", "\n", "scheduler", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "if", "global_step", "%", "args", ".", "eval_period", "==", "0", ":", "\n", "                ", "if", "args", ".", "skip_inference", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Step %d (epoch %d) Train loss %.2f\"", "%", "(", "\n", "global_step", ",", "\n", "epoch", ",", "\n", "np", ".", "mean", "(", "train_losses", ")", ")", ")", "\n", "train_losses", "=", "[", "]", "\n", "model_state_dict", "=", "{", "k", ":", "v", ".", "cpu", "(", ")", "for", "(", "k", ",", "v", ")", "in", "model", ".", "state_dict", "(", ")", ".", "items", "(", ")", "}", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                        ", "model_state_dict", "=", "convert_to_single_gpu", "(", "model_state_dict", ")", "\n", "", "torch", ".", "save", "(", "model_state_dict", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\n", "\"best-model-{}.pt\"", ".", "format", "(", "str", "(", "global_step", ")", ".", "zfill", "(", "6", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "model", ".", "eval", "(", ")", "\n", "curr_em", "=", "inference", "(", "model", "if", "args", ".", "n_gpu", "==", "1", "else", "model", ".", "module", ",", "dev_data", ")", "\n", "logger", ".", "info", "(", "\"Step %d Train loss %.2f %s %.2f%% on epoch=%d\"", "%", "(", "\n", "global_step", ",", "\n", "np", ".", "mean", "(", "train_losses", ")", ",", "\n", "dev_data", ".", "metric", ",", "\n", "curr_em", "*", "100", ",", "\n", "epoch", ")", ")", "\n", "train_losses", "=", "[", "]", "\n", "if", "best_accuracy", "<", "curr_em", ":", "\n", "                        ", "model_state_dict", "=", "{", "k", ":", "v", ".", "cpu", "(", ")", "for", "(", "k", ",", "v", ")", "in", "model", ".", "state_dict", "(", ")", ".", "items", "(", ")", "}", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                            ", "model_state_dict", "=", "convert_to_single_gpu", "(", "model_state_dict", ")", "\n", "", "torch", ".", "save", "(", "model_state_dict", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"best-model.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model with best %s: %.2f%% -> %.2f%% on epoch=%d, global_step=%d\"", "%", "(", "dev_data", ".", "metric", ",", "best_accuracy", "*", "100.0", ",", "curr_em", "*", "100.0", ",", "epoch", ",", "global_step", ")", ")", "\n", "best_accuracy", "=", "curr_em", "\n", "wait_step", "=", "0", "\n", "stop_training", "=", "False", "\n", "", "else", ":", "\n", "                        ", "wait_step", "+=", "1", "\n", "if", "wait_step", ">=", "args", ".", "wait_step", ":", "\n", "                            ", "stop_training", "=", "True", "\n", "break", "\n", "", "", "", "model", ".", "train", "(", ")", "\n", "", "", "if", "stop_training", ":", "\n", "            ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.run.inference": [[148, 167], ["enumerate", "numpy.mean", "tqdm.tqdm", "model.generate", "zip", "dev_data.save_predictions", "dev_data.evaluate", "b.to", "dev_data.decode", "predictions.append", "torch.device"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.save_predictions", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.tweetqa_eval.evaluate", "home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.Solver.decode"], ["", "", "", "def", "inference", "(", "model", ",", "dev_data", ",", "save_predictions", "=", "False", ")", ":", "\n", "    ", "predictions", "=", "[", "]", "\n", "bos_token_id", "=", "dev_data", ".", "tokenizer", ".", "bos_token_id", "\n", "if", "dev_data", ".", "args", ".", "verbose", ":", "\n", "        ", "dev_data", ".", "dataloader", "=", "tqdm", "(", "dev_data", ".", "dataloader", ")", "\n", "", "for", "i", ",", "batch", "in", "enumerate", "(", "dev_data", ".", "dataloader", ")", ":", "\n", "        ", "batch", "=", "[", "b", ".", "to", "(", "torch", ".", "device", "(", "\"cuda\"", ")", ")", "for", "b", "in", "batch", "]", "\n", "outputs", "=", "model", ".", "generate", "(", "input_ids", "=", "batch", "[", "0", "]", ",", "\n", "attention_mask", "=", "batch", "[", "1", "]", ",", "\n", "num_beams", "=", "dev_data", ".", "args", ".", "num_beams", ",", "\n", "min_length", "=", "1", ",", "\n", "max_length", "=", "dev_data", ".", "args", ".", "max_output_length", ",", "\n", "early_stopping", "=", "True", ",", ")", "\n", "for", "input_", ",", "output", "in", "zip", "(", "batch", "[", "0", "]", ",", "outputs", ")", ":", "\n", "            ", "pred", "=", "dev_data", ".", "decode", "(", "output", ")", "\n", "predictions", ".", "append", "(", "pred", ")", "\n", "", "", "if", "save_predictions", ":", "\n", "        ", "dev_data", ".", "save_predictions", "(", "predictions", ")", "\n", "", "return", "np", ".", "mean", "(", "dev_data", ".", "evaluate", "(", "predictions", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.bart.MyBart.forward": [[7, 36], ["bart.MyBart.model", "torch.linear", "torch.linear", "decoder_input_ids.new_zeros", "decoder_input_ids[].clone", "decoder_input_ids.clone", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.linear.view", "decoder_input_ids.view", "decoder_attention_mask.float().view", "decoder_attention_mask.float"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "encoder_outputs", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "decoder_attention_mask", "=", "None", ",", "decoder_cached_states", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "is_training", "=", "False", ")", ":", "\n", "\n", "        ", "if", "is_training", ":", "\n", "            ", "decoder_start_token_id", "=", "self", ".", "config", ".", "decoder_start_token_id", "\n", "_decoder_input_ids", "=", "decoder_input_ids", ".", "new_zeros", "(", "decoder_input_ids", ".", "shape", ")", "\n", "_decoder_input_ids", "[", "...", ",", "1", ":", "]", "=", "decoder_input_ids", "[", "...", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "_decoder_input_ids", "[", "...", ",", "0", "]", "=", "decoder_start_token_id", "\n", "", "else", ":", "\n", "            ", "_decoder_input_ids", "=", "decoder_input_ids", ".", "clone", "(", ")", "\n", "\n", "", "outputs", "=", "self", ".", "model", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "encoder_outputs", "=", "encoder_outputs", ",", "\n", "decoder_input_ids", "=", "_decoder_input_ids", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", ")", "\n", "lm_logits", "=", "F", ".", "linear", "(", "outputs", "[", "0", "]", ",", "self", ".", "model", ".", "shared", ".", "weight", ",", "bias", "=", "self", ".", "final_logits_bias", ")", "\n", "if", "is_training", ":", "\n", "            ", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", "reduce", "=", "False", ")", "\n", "losses", "=", "loss_fct", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "\n", "decoder_input_ids", ".", "view", "(", "-", "1", ")", ")", "\n", "loss", "=", "torch", ".", "sum", "(", "losses", "*", "decoder_attention_mask", ".", "float", "(", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "loss", "\n", "", "return", "(", "lm_logits", ",", ")", "+", "outputs", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.bart.MyBart.generate_from_string": [[37, 50], ["isinstance", "isinstance", "bart.MyBart.generate", "isinstance", "isinstance", "isinstance", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "tokenizer.decode().strip", "tokenizer.encode", "tokenizer.encode", "tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.Solver.decode"], ["", "def", "generate_from_string", "(", "self", ",", "_input", ",", "tokenizer", "=", "None", ",", "**", "generator_args", ")", ":", "\n", "        ", "assert", "tokenizer", "is", "not", "None", "\n", "if", "isinstance", "(", "_input", ",", "str", ")", ":", "\n", "            ", "_input", "=", "[", "[", "0", "]", "+", "tokenizer", ".", "encode", "(", "_input", ")", "]", "\n", "", "if", "isinstance", "(", "_input", ",", "list", ")", "and", "isinstance", "(", "_input", "[", "0", "]", ",", "str", ")", ":", "\n", "            ", "_input", "=", "[", "[", "0", "]", "+", "tokenizer", ".", "encode", "(", "i", ")", "for", "i", "in", "_input", "]", "\n", "", "if", "isinstance", "(", "_input", ",", "list", ")", ":", "\n", "            ", "if", "isinstance", "(", "_input", "[", "0", "]", ",", "int", ")", ":", "\n", "                ", "_input", "=", "[", "_input", "]", "\n", "", "_input", "=", "torch", ".", "LongTensor", "(", "_input", ")", "\n", "", "res", "=", "self", ".", "generate", "(", "_input", ",", "**", "generator_args", ")", "\n", "return", "(", "[", "tokenizer", ".", "decode", "(", "x", ",", "skip_special_tokens", "=", "True", ",", "\n", "clean_up_tokenization_spaces", "=", "True", ")", ".", "strip", "(", ")", "for", "x", "in", "res", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.Solver.__init__": [[52, 71], ["transformers.BartTokenizer.from_pretrained", "urllib.request.urlretrieve", "bart.MyBart.from_pretrained", "solver.Solver.model.eval", "key.startswith", "_convert"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "checkpoint", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "BartTokenizer", ".", "from_pretrained", "(", "\"bart-large\"", ")", "\n", "def", "convert_to_single_gpu", "(", "state_dict", ")", ":", "\n", "            ", "def", "_convert", "(", "key", ")", ":", "\n", "                ", "if", "key", ".", "startswith", "(", "'module.'", ")", ":", "\n", "                    ", "return", "key", "[", "7", ":", "]", "\n", "", "return", "key", "\n", "", "return", "{", "_convert", "(", "key", ")", ":", "value", "for", "key", ",", "value", "in", "state_dict", ".", "items", "(", ")", "}", "\n", "\n", "\n", "", "file_name", ",", "headers", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "checkpoint", ")", "\n", "\n", "self", ".", "model", "=", "MyBart", ".", "from_pretrained", "(", "\"bart-large\"", ",", "state_dict", "=", "convert_to_single_gpu", "(", "torch", ".", "load", "(", "file_name", ")", ")", ")", "\n", "# self.model.to(torch.device(\"cuda\"))", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "self", ".", "num_beams", "=", "4", "\n", "self", ".", "max_input_length", "=", "512", "\n", "self", ".", "max_output_length", "=", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.Solver.get_answers": [[73, 101], ["solver.Solver.tokenizer.batch_encode_plus", "torch.utils.data.TensorDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "tqdm.tqdm.tqdm", "x.lower", "torch.LongTensor", "torch.LongTensor", "enumerate", "solver.Solver.model.generate().detach().cpu().numpy", "solver.Solver.decode", "predictions.append", "question.lower", "solver.Solver.model.generate().detach().cpu", "solver.Solver.model.generate().detach", "solver.Solver.model.generate"], "methods", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.Solver.decode"], ["", "def", "get_answers", "(", "self", ",", "questions", ",", "batch_size", ")", ":", "\n", "        ", "'''\n        :param questions: a list of string\n        :param batch_size: batch_size of inference, depending on gpu availability.\n                        (50 was good with one 16 GB gpu)\n        '''", "\n", "questions", "=", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "questions", "]", "\n", "question_input", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "\n", "[", "\"<s> \"", "+", "question", ".", "lower", "(", ")", "for", "question", "in", "questions", "]", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "max_length", "=", "self", ".", "max_input_length", ")", "\n", "dataset", "=", "TensorDataset", "(", "torch", ".", "LongTensor", "(", "question_input", "[", "\"input_ids\"", "]", ")", ",", "\n", "torch", ".", "LongTensor", "(", "question_input", "[", "\"attention_mask\"", "]", ")", ")", "\n", "sampler", "=", "SequentialSampler", "(", "dataset", ")", "\n", "dataloader", "=", "DataLoader", "(", "dataset", ",", "sampler", "=", "sampler", ",", "batch_size", "=", "batch_size", ")", "\n", "predictions", "=", "[", "]", "\n", "for", "i", ",", "batch", "in", "tqdm", "(", "enumerate", "(", "dataloader", ")", ")", ":", "\n", "# batch = [b.to(torch.device(\"cuda\")) for b in batch]", "\n", "            ", "outputs", "=", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "batch", "[", "0", "]", ",", "\n", "attention_mask", "=", "batch", "[", "1", "]", ",", "\n", "num_beams", "=", "self", ".", "num_beams", ",", "\n", "min_lnegth", "=", "1", ",", "\n", "max_length", "=", "self", ".", "max_output_length", ",", "\n", "early_stopping", "=", "True", ",", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "output", "in", "outputs", ":", "\n", "                ", "pred", "=", "self", ".", "decode", "(", "output", ")", "\n", "predictions", ".", "append", "(", "pred", ")", "\n", "", "", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.Solver.decode": [[102, 106], ["solver.Solver.tokenizer.decode().strip", "solver.Solver.tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.Solver.decode"], ["", "def", "decode", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "decode", "(", "tokens", ",", "\n", "skip_special_tokens", "=", "True", ",", "\n", "clean_up_tokenization_spaces", "=", "True", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.Solver.main": [[108, 141], ["solver.read_jsonl_lines", "enumerate", "print", "print", "print", "json_line[].replace().replace", "json_line[].replace().replace", "json_line[].replace().replace", "print", "time.time", "time.time", "time_list.append", "print", "print", "numpy.argmax", "print", "predicted_answers.append", "open", "f.close", "solver.Solver.get_answers", "solver.score_string_similarity", "str", "f.write", "f.write", "json_line[].replace", "json_line[].replace", "json_line[].replace", "sum", "len"], "methods", ["home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.read_jsonl_lines", "home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.Solver.get_answers", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.score_string_similarity"], ["", "def", "main", "(", "self", ",", "input_file", ",", "output_file", ")", ":", "\n", "# Read the records from the test set.", "\n", "        ", "test_records", "=", "read_jsonl_lines", "(", "input_file", ")", "\n", "predicted_answers", "=", "[", "]", "\n", "# Make predictions for each example in the test set.", "\n", "time_list", "=", "[", "]", "\n", "for", "i", ",", "json_line", "in", "enumerate", "(", "test_records", ")", ":", "\n", "            ", "print", "(", "\"-  -  -  -  -  -  -  -  -  -  \"", ")", "\n", "print", "(", "f\" * i: {i}\"", ")", "\n", "print", "(", "json_line", ")", "\n", "goal", "=", "json_line", "[", "'goal'", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "sol1", "=", "json_line", "[", "'sol1'", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "sol2", "=", "json_line", "[", "'sol2'", "]", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "input", "=", "f\"{goal} \\\\n (A) {sol1} (B) {sol2}\"", "\n", "print", "(", "f\" * input: {input}\"", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "prediction", "=", "self", ".", "get_answers", "(", "[", "input", "]", ",", "1", ")", "[", "0", "]", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "time_list", ".", "append", "(", "end", "-", "start", ")", "\n", "print", "(", "f\"* prediction: {prediction}\"", ")", "\n", "print", "(", "f\" * avg time: {sum(time_list)/len(time_list)}\"", ")", "\n", "\n", "scores", "=", "[", "score_string_similarity", "(", "x", ",", "prediction", ")", "for", "x", "in", "[", "sol1", ",", "sol2", "]", "]", "\n", "max_idx", "=", "np", ".", "argmax", "(", "scores", ")", "\n", "print", "(", "f\"max_idx: {max_idx}\"", ")", "\n", "predicted_answers", ".", "append", "(", "str", "(", "max_idx", ")", ")", "\n", "\n", "# Write the predictions to the output file.", "\n", "", "with", "open", "(", "output_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "p", "in", "predicted_answers", ":", "\n", "                ", "f", ".", "write", "(", "p", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.read_jsonl_lines": [[17, 21], ["open", "f.readlines", "json.loads", "l.strip"], "function", ["None"], ["def", "read_jsonl_lines", "(", "input_file", ":", "str", ")", "->", "List", "[", "dict", "]", ":", "\n", "    ", "with", "open", "(", "input_file", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "return", "[", "json", ".", "loads", "(", "l", ".", "strip", "(", ")", ")", "for", "l", "in", "lines", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.replace_punctuation": [[23, 25], ["str.replace().replace", "str.replace"], "function", ["None"], ["", "", "def", "replace_punctuation", "(", "str", ")", ":", "\n", "    ", "return", "str", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", ".", "replace", "(", "\"'\"", ",", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.fix_buggy_characters": [[28, 30], ["re.sub"], "function", ["None"], ["", "def", "fix_buggy_characters", "(", "str", ")", ":", "\n", "    ", "return", "re", ".", "sub", "(", "\"[{}^\\\\\\\\`\\u2047<]\"", ",", "\" \"", ",", "str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.solver.score_string_similarity": [[32, 49], ["solver.fix_buggy_characters", "solver.fix_buggy_characters", "solver.replace_punctuation", "solver.replace_punctuation", "fix_buggy_characters.split", "fix_buggy_characters.split", "list", "len", "max", "set", "set", "len", "len"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.fix_buggy_characters", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.fix_buggy_characters", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.replace_punctuation", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.replace_punctuation"], ["", "def", "score_string_similarity", "(", "str1", ",", "str2", ")", ":", "\n", "    ", "if", "str1", "==", "str2", ":", "\n", "        ", "return", "3.0", "# Better than perfect token match", "\n", "", "str1", "=", "fix_buggy_characters", "(", "replace_punctuation", "(", "str1", ")", ")", "\n", "str2", "=", "fix_buggy_characters", "(", "replace_punctuation", "(", "str2", ")", ")", "\n", "if", "str1", "==", "str2", ":", "\n", "        ", "return", "2.0", "\n", "", "if", "\" \"", "in", "str1", "or", "\" \"", "in", "str2", ":", "\n", "        ", "str1_split", "=", "str1", ".", "split", "(", "\" \"", ")", "\n", "str2_split", "=", "str2", ".", "split", "(", "\" \"", ")", "\n", "overlap", "=", "list", "(", "set", "(", "str1_split", ")", "&", "set", "(", "str2_split", ")", ")", "\n", "return", "len", "(", "overlap", ")", "/", "max", "(", "len", "(", "str1_split", ")", ",", "len", "(", "str2_split", ")", ")", "\n", "", "else", ":", "\n", "        ", "if", "str1", "==", "str2", ":", "\n", "            ", "return", "1.0", "\n", "", "else", ":", "\n", "            ", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.bart_example_solver.bart.MyBart.forward": [[8, 37], ["bart.MyBart.model", "torch.linear", "torch.linear", "decoder_input_ids.new_zeros", "decoder_input_ids[].clone", "decoder_input_ids.clone", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.linear.view", "decoder_input_ids.view", "decoder_attention_mask.float().view", "decoder_attention_mask.float"], "methods", ["None"], ["decoder_input_ids", "=", "None", ",", "decoder_attention_mask", "=", "None", ",", "decoder_cached_states", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "is_training", "=", "False", ")", ":", "\n", "\n", "        ", "if", "is_training", ":", "\n", "            ", "decoder_start_token_id", "=", "self", ".", "config", ".", "decoder_start_token_id", "\n", "_decoder_input_ids", "=", "decoder_input_ids", ".", "new_zeros", "(", "decoder_input_ids", ".", "shape", ")", "\n", "_decoder_input_ids", "[", "...", ",", "1", ":", "]", "=", "decoder_input_ids", "[", "...", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "_decoder_input_ids", "[", "...", ",", "0", "]", "=", "decoder_start_token_id", "\n", "", "else", ":", "\n", "            ", "_decoder_input_ids", "=", "decoder_input_ids", ".", "clone", "(", ")", "\n", "\n", "", "outputs", "=", "self", ".", "model", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "encoder_outputs", "=", "encoder_outputs", ",", "\n", "decoder_input_ids", "=", "_decoder_input_ids", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", ")", "\n", "lm_logits", "=", "F", ".", "linear", "(", "outputs", "[", "0", "]", ",", "self", ".", "model", ".", "shared", ".", "weight", ",", "bias", "=", "self", ".", "final_logits_bias", ")", "\n", "if", "is_training", ":", "\n", "            ", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", "reduce", "=", "False", ")", "\n", "losses", "=", "loss_fct", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "\n", "decoder_input_ids", ".", "view", "(", "-", "1", ")", ")", "\n", "loss", "=", "torch", ".", "sum", "(", "losses", "*", "decoder_attention_mask", ".", "float", "(", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "loss", "\n", "", "return", "(", "lm_logits", ",", ")", "+", "outputs", "[", "1", ":", "]", "\n", "\n", "", "def", "generate_from_string", "(", "self", ",", "_input", ",", "tokenizer", "=", "None", ",", "**", "generator_args", ")", ":", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_multiple_choice_answers.score_string_similarity": [[6, 23], ["evaluate_multiple_choice_answers.fix_buggy_characters", "evaluate_multiple_choice_answers.fix_buggy_characters", "evaluate_multiple_choice_answers.replace_punctuation", "evaluate_multiple_choice_answers.replace_punctuation", "fix_buggy_characters.split", "fix_buggy_characters.split", "list", "len", "max", "set", "set", "len", "len"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.fix_buggy_characters", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.fix_buggy_characters", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.replace_punctuation", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.replace_punctuation"], ["def", "score_string_similarity", "(", "str1", ",", "str2", ")", ":", "\n", "    ", "if", "str1", "==", "str2", ":", "\n", "        ", "return", "3.0", "# Better than perfect token match", "\n", "", "str1", "=", "fix_buggy_characters", "(", "replace_punctuation", "(", "str1", ")", ")", "\n", "str2", "=", "fix_buggy_characters", "(", "replace_punctuation", "(", "str2", ")", ")", "\n", "if", "str1", "==", "str2", ":", "\n", "        ", "return", "2.0", "\n", "", "if", "\" \"", "in", "str1", "or", "\" \"", "in", "str2", ":", "\n", "        ", "str1_split", "=", "str1", ".", "split", "(", "\" \"", ")", "\n", "str2_split", "=", "str2", ".", "split", "(", "\" \"", ")", "\n", "overlap", "=", "list", "(", "set", "(", "str1_split", ")", "&", "set", "(", "str2_split", ")", ")", "\n", "return", "len", "(", "overlap", ")", "/", "max", "(", "len", "(", "str1_split", ")", ",", "len", "(", "str2_split", ")", ")", "\n", "", "else", ":", "\n", "        ", "if", "str1", "==", "str2", ":", "\n", "            ", "return", "1.0", "\n", "", "else", ":", "\n", "            ", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_multiple_choice_answers.replace_punctuation": [[24, 26], ["str.replace().replace", "str.replace"], "function", ["None"], ["", "", "", "def", "replace_punctuation", "(", "str", ")", ":", "\n", "    ", "return", "str", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", ".", "replace", "(", "\"'\"", ",", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_multiple_choice_answers.fix_buggy_characters": [[28, 30], ["re.sub"], "function", ["None"], ["", "def", "fix_buggy_characters", "(", "str", ")", ":", "\n", "    ", "return", "re", ".", "sub", "(", "\"[{}^\\\\\\\\`\\u2047<]\"", ",", "\" \"", ",", "str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_multiple_choice_answers.eval_dir": [[32, 49], ["sorted", "evaluate_multiple_choice_answers.convert_predictions", "os.listdir", "os.path.isfile", "len", "os.path.join", "int", "int", "x.split", "x.split"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_multiple_choice_answers.convert_predictions"], ["", "def", "eval_dir", "(", "dir", ",", "checkpoints", "=", "'all'", ")", ":", "\n", "    ", "onlyfiles", "=", "[", "f", "for", "f", "in", "listdir", "(", "dir", ")", "if", "isfile", "(", "join", "(", "dir", ",", "f", ")", ")", "]", "\n", "\n", "only_predictions", "=", "[", "f", "for", "f", "in", "onlyfiles", "if", "\"_predictions\"", "in", "f", "]", "\n", "if", "checkpoints", "==", "'all'", ":", "\n", "        ", "only_predictions", "=", "sorted", "(", "only_predictions", ")", "\n", "# print(only_predictions)", "\n", "", "else", ":", "\n", "        ", "only_predictions", "=", "[", "x", "for", "x", "in", "only_predictions", "if", "\n", "'.csv'", "not", "in", "x", "and", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "2", "]", ")", ">", "1090500", "and", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "2", "]", ")", "<", "1110000", "]", "\n", "\n", "if", "len", "(", "only_predictions", ")", ">", "1", ":", "\n", "            ", "raise", "EnvironmentError", "\n", "\n", "\n", "", "", "for", "p", "in", "only_predictions", ":", "\n", "        ", "convert_predictions", "(", "input_file", ",", "dir", "+", "\"/\"", "+", "p", ",", "meta_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_multiple_choice_answers.convert_predictions": [[50, 117], ["open", "zip", "print", "open", "f.readlines", "open", "list", "open", "list", "len", "len", "print", "len", "len", "prediction.replace().strip.replace().strip", "id_and_gold.replace().strip().split", "input.split", "input_split[].strip().lower", "regex.split", "numpy.argmax", "chr", "open.write", "input_lines.append", "f.readlines", "f.readlines", "len", "len", "len", "len", "x.strip", "evaluate_multiple_choice_answers.score_string_similarity", "accuracy.append", "accuracy.append", "prediction.replace().strip.replace", "id_and_gold.replace().strip", "input_split[].strip", "ord", "chr", "chr", "line.split", "len", "len", "id_and_gold.replace", "x.strip", "ord", "ord", "sum"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.score_string_similarity"], ["", "", "def", "convert_predictions", "(", "input", ",", "pred", ",", "meta_file", ")", ":", "\n", "    ", "input_lines", "=", "[", "]", "\n", "with", "open", "(", "input", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "input_lines", ".", "append", "(", "line", ".", "split", "(", "\"\\t\"", ")", "[", "0", "]", ")", "\n", "# print(line.split(\"\\t\")[0])", "\n", "\n", "", "", "with", "open", "(", "pred", ")", "as", "f", ":", "\n", "        ", "pred_lines", "=", "list", "(", "f", ".", "readlines", "(", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_file", ")", "as", "f", ":", "\n", "        ", "id_lines", "=", "list", "(", "f", ".", "readlines", "(", ")", ")", "\n", "\n", "", "if", "len", "(", "pred_lines", ")", "!=", "len", "(", "input_lines", ")", ":", "\n", "        ", "print", "(", "\"skipping . . . \"", ")", "\n", "return", "\n", "\n", "", "assert", "len", "(", "pred_lines", ")", "==", "len", "(", "input_lines", ")", ",", "f\"{len(pred_lines)} vs {len(input_lines)} / {input} / {pred}\"", "\n", "\n", "outfile", "=", "open", "(", "pred", "+", "\"_selected_candidate.csv\"", ",", "\"w\"", ")", "\n", "\n", "accuracy", "=", "[", "]", "\n", "for", "prediction", ",", "input", ",", "id_and_gold", "in", "zip", "(", "pred_lines", ",", "input_lines", ",", "id_lines", ")", ":", "\n", "        ", "prediction", "=", "prediction", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "strip", "(", ")", "\n", "id_and_gold_split", "=", "id_and_gold", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "id", "=", "id_and_gold_split", "[", "0", "]", "\n", "gold", "=", "id_and_gold_split", "[", "1", "]", "\n", "assert", "len", "(", "gold", ")", "<", "3", ",", "f\"gold: {gold} - id_and_gold: {id_and_gold} \"", "\n", "is_numeric", "=", "False", "\n", "numeric_from_zero", "=", "False", "\n", "if", "len", "(", "id_and_gold_split", ")", ">", "2", ":", "\n", "            ", "if", "\"numeric\"", "in", "id_and_gold_split", "[", "2", "]", ":", "\n", "                ", "is_numeric", "=", "True", "\n", "", "if", "\"numeric_from_zero\"", "in", "id_and_gold_split", "[", "2", "]", ":", "\n", "                ", "numeric_from_zero", "=", "True", "\n", "# print((is_numeric, numeric_from_zero))", "\n", "", "", "input_split", "=", "input", ".", "split", "(", "\"\\\\n\"", ")", "\n", "# print(input_split)", "\n", "candidates_string", "=", "input_split", "[", "1", "]", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "candidates_split", "=", "regex", ".", "split", "(", "candidates_string", ")", "\n", "candidates_split", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "candidates_split", "if", "len", "(", "x", ".", "strip", "(", ")", ")", ">", "0", "]", "\n", "# print(f\"{prediction} <-> {candidates_split}\")", "\n", "scores", "=", "[", "score_string_similarity", "(", "x", ",", "prediction", ")", "for", "x", "in", "candidates_split", "]", "\n", "max_idx", "=", "np", ".", "argmax", "(", "scores", ")", "\n", "# TODO: If multiple options has max score, look for best token alignment", "\n", "selected_ans", "=", "chr", "(", "ord", "(", "'A'", ")", "+", "max_idx", ")", "\n", "\n", "# print((gold, selected_ans))", "\n", "if", "selected_ans", "==", "gold", ":", "\n", "            ", "accuracy", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "accuracy", ".", "append", "(", "0", ")", "\n", "\n", "", "if", "is_numeric", ":", "\n", "# print(f\"is numeric: {selected_ans} -> {chr(ord('1') + max_idx)}\")", "\n", "            ", "if", "numeric_from_zero", ":", "\n", "                ", "selected_ans", "=", "chr", "(", "ord", "(", "'0'", ")", "+", "max_idx", ")", "\n", "", "else", ":", "\n", "                ", "selected_ans", "=", "chr", "(", "ord", "(", "'1'", ")", "+", "max_idx", ")", "\n", "\n", "", "", "outfile", ".", "write", "(", "f\"{id},{selected_ans}\\n\"", ")", "\n", "\n", "# if max(scores) == 0:", "\n", "#     print(f\" ***** ERRROR: {prediction} <-> {candidates_split} \")", "\n", "# break", "\n", "\n", "", "print", "(", "f\" *** {pred} \\t {100.0 * sum(accuracy) / len(accuracy)}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.get_lines_from_file": [[243, 250], ["tensorflow.io.gfile.GFile", "lines.append", "line.strip"], "function", ["None"], ["def", "get_lines_from_file", "(", "bucket_name", ",", "file_name", ")", ":", "\n", "    ", "full_file_name", "=", "f'gs://{bucket_name}/{file_name}'", "\n", "lines", "=", "[", "]", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "full_file_name", ")", "as", "ip_lines", ":", "\n", "        ", "for", "line", "in", "ip_lines", ":", "\n", "            ", "lines", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.score_string_similarity": [[251, 268], ["evaluate_v2.fix_buggy_characters", "evaluate_v2.fix_buggy_characters", "evaluate_v2.replace_punctuation", "evaluate_v2.replace_punctuation", "fix_buggy_characters.split", "fix_buggy_characters.split", "list", "len", "max", "set", "set", "len", "len"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.fix_buggy_characters", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.fix_buggy_characters", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.replace_punctuation", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.replace_punctuation"], ["", "def", "score_string_similarity", "(", "str1", ",", "str2", ")", ":", "\n", "    ", "if", "str1", "==", "str2", ":", "\n", "        ", "return", "3.0", "# Better than perfect token match", "\n", "", "str1", "=", "fix_buggy_characters", "(", "replace_punctuation", "(", "str1", ")", ")", "\n", "str2", "=", "fix_buggy_characters", "(", "replace_punctuation", "(", "str2", ")", ")", "\n", "if", "str1", "==", "str2", ":", "\n", "        ", "return", "2.0", "\n", "", "if", "\" \"", "in", "str1", "or", "\" \"", "in", "str2", ":", "\n", "        ", "str1_split", "=", "str1", ".", "split", "(", "\" \"", ")", "\n", "str2_split", "=", "str2", ".", "split", "(", "\" \"", ")", "\n", "overlap", "=", "list", "(", "set", "(", "str1_split", ")", "&", "set", "(", "str2_split", ")", ")", "\n", "return", "len", "(", "overlap", ")", "/", "max", "(", "len", "(", "str1_split", ")", ",", "len", "(", "str2_split", ")", ")", "\n", "", "else", ":", "\n", "        ", "if", "str1", "==", "str2", ":", "\n", "            ", "return", "1.0", "\n", "", "else", ":", "\n", "            ", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.replace_punctuation": [[270, 272], ["str.replace().replace", "str.replace"], "function", ["None"], ["", "", "", "def", "replace_punctuation", "(", "str", ")", ":", "\n", "    ", "return", "str", ".", "replace", "(", "\"\\\"\"", ",", "\"\"", ")", ".", "replace", "(", "\"'\"", ",", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.fix_buggy_characters": [[275, 277], ["re.sub", "re.sub"], "function", ["None"], ["", "def", "fix_buggy_characters", "(", "str", ")", ":", "\n", "    ", "return", "re", ".", "sub", "(", "\"[{}^\\\\\\\\`\\u2047<]\"", ",", "\" \"", ",", "str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.normalize_answer": [[278, 295], ["evaluate_v2.normalize_answer.white_space_fix"], "function", ["None"], ["", "def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.f1_score": [[296, 307], ["qaconv_eval.normalize_answer().split", "qaconv_eval.normalize_answer().split", "sum", "collections.Counter", "collections.Counter", "common.values", "len", "len", "qaconv_eval.normalize_answer", "qaconv_eval.normalize_answer"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer"], ["", "def", "f1_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "prediction_tokens", "=", "normalize_answer", "(", "prediction", ")", ".", "split", "(", ")", "\n", "ground_truth_tokens", "=", "normalize_answer", "(", "ground_truth", ")", ".", "split", "(", ")", "\n", "common", "=", "Counter", "(", "prediction_tokens", ")", "&", "Counter", "(", "ground_truth_tokens", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "prediction_tokens", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "ground_truth_tokens", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.exact_match_score": [[309, 311], ["qaconv_eval.normalize_answer", "qaconv_eval.normalize_answer"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer"], ["", "def", "exact_match_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "return", "(", "normalize_answer", "(", "prediction", ")", "==", "normalize_answer", "(", "ground_truth", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.metric_max_over_ground_truths": [[313, 319], ["max", "scores_for_ground_truths.append", "prediction.lower", "ground_truth.lower", "evaluate_v2.f1_score", "evaluate_squad2.compute_f1", "qaconv_eval.compute_f1", "evaluate_narrativeqa.rouge_l"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_natural_questions_ambigqa.f1_score", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.compute_f1", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.compute_f1", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_narrativeqa.rouge_l"], ["", "def", "metric_max_over_ground_truths", "(", "metric_fn", ",", "prediction", ",", "ground_truths", ")", ":", "\n", "    ", "scores_for_ground_truths", "=", "[", "]", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "score", "=", "metric_fn", "(", "prediction", ".", "lower", "(", ")", ",", "ground_truth", ".", "lower", "(", ")", ")", "\n", "scores_for_ground_truths", ".", "append", "(", "score", ")", "\n", "", "return", "max", "(", "scores_for_ground_truths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.evaluate_generic": [[321, 366], ["enumerate", "type", "x.replace().strip", "len", "len", "len", "len", "evaluate_v2.metric_max_over_ground_truths", "x.replace().strip", "x.replace", "evaluate_v2.metric_max_over_ground_truths", "qaconv_eval.normalize_answer.lower", "tweetqa_eval.ans_score", "x.replace", "g.lower", "evaluate_drop_quoref_ropes.f1_metrics", "tuple", "qaconv_eval.normalize_answer", "qaconv_eval.add_word_number_mapping", "evaluate_v2.metric_max_over_ground_truths", "qaconv_eval.normalize_answer", "evaluate_v2.metric_max_over_ground_truths"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_narrativeqa.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_narrativeqa.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.tweetqa_eval.ans_score", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes.f1_metrics", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.add_word_number_mapping", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_narrativeqa.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_narrativeqa.metric_max_over_ground_truths"], ["", "def", "evaluate_generic", "(", "target_lines", ":", "List", ",", "pred_lines", ":", "List", ",", "variant_type", ")", ":", "\n", "    ", "if", "type", "(", "target_lines", "[", "0", "]", ")", "==", "str", ":", "\n", "# strip and turn into *list of* strings", "\n", "        ", "golds", "=", "[", "[", "x", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "strip", "(", ")", "]", "for", "x", "in", "target_lines", "]", "\n", "", "else", ":", "\n", "        ", "golds", "=", "target_lines", "\n", "", "predictions", "=", "[", "x", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "strip", "(", ")", "for", "x", "in", "pred_lines", "]", "\n", "\n", "assert", "len", "(", "golds", ")", "==", "len", "(", "predictions", ")", ",", "f\" {len(predictions)}  / {len(golds)} \"", "\n", "\n", "score", "=", "total", "=", "0", "\n", "for", "i", ",", "prediction", "in", "enumerate", "(", "predictions", ")", ":", "\n", "        ", "if", "variant_type", "==", "\"generic-f1\"", ":", "\n", "            ", "out", "=", "metric_max_over_ground_truths", "(", "f1_score", ",", "prediction", ",", "golds", "[", "i", "]", ")", "\n", "score", "+=", "out", "\n", "", "elif", "variant_type", "==", "\"squad2-f1\"", ":", "\n", "            ", "no_ans", "=", "\"no answer\"", "\n", "for", "g", "in", "golds", "[", "i", "]", ":", "\n", "                ", "if", "no_ans", "in", "g", ".", "lower", "(", ")", ":", "\n", "                    ", "golds", "[", "i", "]", "=", "[", "\"\"", "]", "\n", "break", "\n", "", "", "if", "no_ans", "in", "prediction", ".", "lower", "(", ")", ":", "\n", "                ", "prediction", "=", "\"\"", "\n", "", "score", "+=", "metric_max_over_ground_truths", "(", "squad2_compute_f1", ",", "prediction", ",", "golds", "[", "i", "]", ")", "\n", "", "elif", "variant_type", "==", "\"tweetqa-textgen\"", ":", "\n", "            ", "out", "=", "tweetqa_metric", "(", "prediction", ",", "golds", "[", "i", "]", ")", "\n", "score", "+=", "out", "[", "\"bleu\"", "]", "\n", "", "elif", "variant_type", "==", "\"allennlp-f1\"", ":", "\n", "            ", "out", "=", "drop_quoref_ropes_f1_metrics", "(", "prediction", ",", "tuple", "(", "golds", "[", "i", "]", ")", ")", "\n", "score", "+=", "out", "[", "1", "]", "\n", "", "elif", "variant_type", "==", "\"qaconv-f1\"", ":", "\n", "            ", "prediction", "=", "qaconv_normalize_answer", "(", "prediction", ")", "\n", "gold_answers", "=", "golds", "[", "i", "]", "\n", "gold_answers", "=", "[", "qaconv_normalize_answer", "(", "a", ")", "for", "a", "in", "gold_answers", "]", "\n", "gold_answers", "+=", "qaconv_add_word_number_mapping", "(", "gold_answers", ")", "\n", "out", "=", "metric_max_over_ground_truths", "(", "qaconv_compute_f1", ",", "prediction", ",", "gold_answers", ")", "\n", "score", "+=", "out", "\n", "", "elif", "variant_type", "==", "\"rouge-l\"", ":", "\n", "            ", "rouge_l_score", "=", "metric_max_over_ground_truths", "(", "rouge_l", ",", "prediction", ",", "golds", "[", "i", "]", ")", "\n", "score", "+=", "rouge_l_score", "[", "\"rouge-l\"", "]", "[", "\"f\"", "]", "\n", "", "total", "+=", "1", "\n", "\n", "", "score", "=", "100.0", "*", "score", "/", "total", "\n", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.evaluate_multple_choice_predictions": [[368, 406], ["zip", "prediction.replace().strip().lower.replace().strip().lower", "id_and_gold.replace().strip().split", "id_and_gold_split[].strip", "input.split", "input_split[].strip().lower", "regex.split", "numpy.argmax", "chr", "outfile.write", "len", "len", "len", "x.strip", "evaluate_v2.score_string_similarity", "accuracy.append", "accuracy.append", "sum", "prediction.replace().strip().lower.replace().strip", "id_and_gold.replace().strip", "input_split[].strip", "ord", "chr", "chr", "len", "prediction.replace().strip().lower.replace", "id_and_gold.replace", "x.strip", "ord", "ord"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.score_string_similarity"], ["", "def", "evaluate_multple_choice_predictions", "(", "target_lines", ",", "pred_lines", ",", "meta_lines", ",", "regex", ",", "outfile", ")", ":", "\n", "    ", "accuracy", "=", "[", "]", "\n", "for", "prediction", ",", "input", ",", "id_and_gold", "in", "zip", "(", "pred_lines", ",", "target_lines", ",", "meta_lines", ")", ":", "\n", "        ", "prediction", "=", "prediction", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "id_and_gold_split", "=", "id_and_gold", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "id", "=", "id_and_gold_split", "[", "0", "]", "\n", "gold", "=", "id_and_gold_split", "[", "1", "]", ".", "strip", "(", ")", "\n", "assert", "len", "(", "gold", ")", "<", "3", ",", "f\"gold: {gold} - id_and_gold: {id_and_gold} \"", "\n", "is_numeric", "=", "False", "\n", "numeric_from_zero", "=", "False", "\n", "if", "len", "(", "id_and_gold_split", ")", ">", "2", ":", "\n", "            ", "if", "\"numeric\"", "in", "id_and_gold_split", "[", "2", "]", ":", "\n", "                ", "is_numeric", "=", "True", "\n", "", "if", "\"numeric_from_zero\"", "in", "id_and_gold_split", "[", "2", "]", ":", "\n", "                ", "numeric_from_zero", "=", "True", "\n", "", "", "input_split", "=", "input", ".", "split", "(", "\"\\\\n\"", ")", "\n", "candidates_string", "=", "input_split", "[", "1", "]", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "candidates_split", "=", "regex", ".", "split", "(", "candidates_string", ")", "\n", "candidates_split", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "candidates_split", "if", "len", "(", "x", ".", "strip", "(", ")", ")", ">", "0", "]", "\n", "scores", "=", "[", "score_string_similarity", "(", "x", ",", "prediction", ")", "for", "x", "in", "candidates_split", "]", "\n", "max_idx", "=", "np", ".", "argmax", "(", "scores", ")", "\n", "# TODO: If multiple options has max score, look for best token alignment", "\n", "selected_ans", "=", "chr", "(", "ord", "(", "'A'", ")", "+", "max_idx", ")", "\n", "if", "selected_ans", "==", "gold", ":", "\n", "            ", "accuracy", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "accuracy", ".", "append", "(", "0", ")", "\n", "\n", "", "if", "is_numeric", ":", "\n", "            ", "if", "numeric_from_zero", ":", "\n", "                ", "selected_ans", "=", "chr", "(", "ord", "(", "'0'", ")", "+", "max_idx", ")", "\n", "", "else", ":", "\n", "                ", "selected_ans", "=", "chr", "(", "ord", "(", "'1'", ")", "+", "max_idx", ")", "\n", "\n", "", "", "outfile", ".", "write", "(", "f\"{id},{selected_ans}\\n\"", ")", "\n", "\n", "", "acc", "=", "100.0", "*", "sum", "(", "accuracy", ")", "/", "len", "(", "accuracy", ")", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.create_map": [[408, 416], ["zip", "new_dict[].append"], "function", ["None"], ["", "def", "create_map", "(", "list1", ",", "list2", ")", ":", "\n", "    ", "new_dict", "=", "{", "}", "\n", "for", "(", "key", ",", "value", ")", "in", "zip", "(", "list1", ",", "list2", ")", ":", "\n", "        ", "if", "key", "in", "new_dict", ":", "\n", "            ", "new_dict", "[", "key", "]", ".", "append", "(", "value", ")", "\n", "", "else", ":", "\n", "            ", "new_dict", "[", "key", "]", "=", "[", "value", "]", "\n", "", "", "return", "new_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.evaluate_for_size": [[418, 584], ["re.match", "re.match", "print", "google.cloud.storage.Client", "list", "print", "re.match.groupdict", "re.match.groupdict", "storage.Client.list_blobs", "print", "print", "evaluate_v2.get_lines_from_file", "print", "open", "f.readlines", "evaluate_v2.get_lines_from_file", "blob.name.endswith", "pathlib.Path().mkdir", "open", "evaluate_v2.evaluate_multple_choice_predictions", "get_lines_from_file.append", "[].split", "print", "evaluate_v2.get_lines_from_file", "x.split", "len", "len", "print", "len", "len", "print", "evaluate_v2.evaluate_generic", "Exception", "json.loads", "pathlib.Path", "len", "len", "print", "l.replace", "x.split", "open", "f.readlines", "x.split", "l.replace().strip().split", "id_and_gold_split[].strip", "get_lines_from_file.append", "open", "f.readlines", "len", "print", "evaluate_v2.get_lines_from_file", "len", "len", "len", "len", "blob.name.endswith", "id_and_gold_split[].strip.split", "get_lines_from_file.append", "x.split", "len", "len", "l.replace().strip", "json.loads", "x.split", "datasets.load_dataset", "get_lines_from_file.append", "evaluate_v2.get_lines_from_file", "l.replace", "datasets.load_dataset", "[].split", "len", "print", "evaluate_v2.get_lines_from_file", "l.replace", "blob.name.endswith", "datasets.load_dataset", "Exception", "a.lower().replace().replace", "len", "print", "Exception", "x.split", "open", "re.compile", "re.compile", "re.compile", "re.compile", "open", "list", "a.lower().replace", "x.split", "f.readlines", "blob.name.endswith", "x.split", "f.readlines", "a.lower"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.get_lines_from_file", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.get_lines_from_file", "home.repos.pwc.inspect_result.allenai_unifiedqa.None.encode_datasets.mkdir", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.evaluate_multple_choice_predictions", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.get_lines_from_file", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.evaluate_generic", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.get_lines_from_file", "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.load_dataset", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.get_lines_from_file", "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.load_dataset", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_v2.get_lines_from_file", "home.repos.pwc.inspect_result.allenai_unifiedqa.bart.data.QAData.load_dataset"], ["", "def", "evaluate_for_size", "(", "eval_path", ",", "target_dataset", ")", ":", "\n", "\n", "    ", "path_regex", "=", "r'gs://(?P<bucket_name>[^/]+)/(?P<file_path>.+)'", "\n", "m", "=", "re", ".", "match", "(", "path_regex", ",", "eval_path", ")", "\n", "bucket_name", "=", "m", ".", "groupdict", "(", ")", "[", "'bucket_name'", "]", "\n", "path", "=", "m", ".", "groupdict", "(", ")", "[", "'file_path'", "]", "\n", "\n", "print", "(", "f'Bucket name: {bucket_name}, Path: {path}'", ")", "\n", "storage_client", "=", "storage", ".", "Client", "(", ")", "\n", "blobs", "=", "list", "(", "storage_client", ".", "list_blobs", "(", "\n", "bucket_name", ",", "prefix", "=", "path", "\n", ")", ")", "\n", "\n", "eval_type", "=", "\"\"", "\n", "# for multple-choice, use the reference labels", "\n", "if", "\"squad1_1\"", "in", "target_dataset", ":", "\n", "        ", "eval_type", "=", "\"generic-f1\"", "\n", "targets", "=", "[", "]", "\n", "gold_all_ans", "=", "\"t2t-qa/t2t-data/squad1_1/dev_ans.jsonl\"", "\n", "with", "open", "(", "gold_all_ans", ")", "as", "f", ":", "\n", "            ", "for", "l", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "targets", ".", "append", "(", "json", ".", "loads", "(", "l", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", ")", "\n", "", "", "", "elif", "\"record_extractive\"", "in", "target_dataset", ":", "\n", "        ", "eval_type", "=", "\"generic-f1\"", "\n", "if", "\"dev\"", "in", "eval_path", ":", "\n", "            ", "split", "=", "'dev'", "\n", "", "else", ":", "\n", "            ", "split", "=", "'test'", "# the test set does not have any gold labels", "\n", "", "tsv_file", "=", "get_lines_from_file", "(", "bucket_name", "=", "bucket_name", ",", "file_name", "=", "f\"data/record_extractive/{split}_meta.txt\"", ")", "\n", "targets", "=", "[", "target_line", "for", "target_line", "in", "tsv_file", "]", "\n", "targets", "=", "[", "x", ".", "split", "(", "\"\\t\"", ")", "[", "1", "]", ".", "split", "(", "\"//\"", ")", "for", "x", "in", "targets", "]", "\n", "", "elif", "\"narrativeqa\"", "in", "target_dataset", ":", "\n", "        ", "eval_type", "=", "\"rouge-l\"", "\n", "targets_file", "=", "(", "[", "blob", "for", "blob", "in", "blobs", "if", "blob", ".", "name", ".", "endswith", "(", "'_targets'", ")", "and", "\n", "\"/\"", "+", "target_dataset", "+", "\"_mixture\"", "in", "blob", ".", "name", "]", ")", "[", "0", "]", "\n", "print", "(", "f\" * targets_file.name: {targets_file.name}\"", ")", "\n", "targets", "=", "get_lines_from_file", "(", "bucket_name", ",", "targets_file", ".", "name", ")", "\n", "targets", "=", "[", "x", ".", "split", "(", "\"\\t\"", ")", "[", "0", "]", "for", "x", "in", "targets", "]", "\n", "# targets = [x.split(\"///\") for x in targets]", "\n", "", "elif", "\"tweetqa\"", "in", "target_dataset", ":", "\n", "        ", "eval_type", "=", "\"tweetqa-textgen\"", "\n", "if", "\"dev\"", "in", "eval_path", ":", "\n", "            ", "gold_all_ans", "=", "f\"t2t-qa/t2t-data/tweetqa/dev_meta.tsv\"", "\n", "", "else", ":", "\n", "            ", "gold_all_ans", "=", "f\"t2t-qa/t2t-data/tweetqa/test_meta.tsv\"", "\n", "", "targets", "=", "[", "]", "\n", "with", "open", "(", "gold_all_ans", ")", "as", "f", ":", "\n", "            ", "for", "l", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "id_and_gold_split", "=", "l", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "# id = id_and_gold_split[0]", "\n", "gold", "=", "id_and_gold_split", "[", "1", "]", ".", "strip", "(", ")", "\n", "targets", ".", "append", "(", "gold", ".", "split", "(", "\"///\"", ")", ")", "\n", "", "", "", "elif", "\"squad2\"", "in", "target_dataset", ":", "\n", "        ", "eval_type", "=", "\"squad2-f1\"", "\n", "targets", "=", "[", "]", "\n", "gold_all_ans", "=", "\"t2t-qa/t2t-data/squad2/dev_ans.jsonl\"", "\n", "with", "open", "(", "gold_all_ans", ")", "as", "f", ":", "\n", "            ", "for", "l", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "targets", ".", "append", "(", "json", ".", "loads", "(", "l", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", ")", "\n", "", "", "", "elif", "len", "(", "[", "x", "for", "x", "in", "[", "\"quoref\"", ",", "\"drop\"", ",", "\"ropes\"", "]", "if", "x", "in", "target_dataset", "]", ")", ">", "0", ":", "\n", "        ", "eval_type", "=", "\"allennlp-f1\"", "\n", "targets_file", "=", "(", "[", "blob", "for", "blob", "in", "blobs", "if", "blob", ".", "name", ".", "endswith", "(", "'_targets'", ")", "and", "\n", "\"/\"", "+", "target_dataset", "+", "\"_mixture\"", "in", "blob", ".", "name", "]", ")", "[", "0", "]", "\n", "print", "(", "f\" * targets_file.name: {targets_file.name}\"", ")", "\n", "targets", "=", "get_lines_from_file", "(", "bucket_name", ",", "targets_file", ".", "name", ")", "\n", "targets", "=", "[", "x", ".", "split", "(", "\"\\t\"", ")", "[", "0", "]", "for", "x", "in", "targets", "]", "\n", "targets", "=", "[", "x", ".", "split", "(", "\"///\"", ")", "for", "x", "in", "targets", "]", "\n", "", "elif", "\"adversarialqa_\"", "in", "target_dataset", ":", "\n", "        ", "eval_type", "=", "\"generic-f1\"", "\n", "if", "'dbidaf'", "in", "target_dataset", ":", "\n", "            ", "dataset", "=", "load_dataset", "(", "\"adversarial_qa\"", ",", "'dbidaf'", ")", "\n", "", "elif", "'dbert'", "in", "target_dataset", ":", "\n", "            ", "dataset", "=", "load_dataset", "(", "\"adversarial_qa\"", ",", "'dbert'", ")", "\n", "", "elif", "'droberta'", "in", "target_dataset", ":", "\n", "            ", "dataset", "=", "load_dataset", "(", "\"adversarial_qa\"", ",", "'droberta'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"unknown split for adversarialqa\"", ")", "\n", "", "if", "\"dev\"", "in", "eval_path", ":", "\n", "            ", "split", "=", "'validation'", "\n", "", "else", ":", "\n", "            ", "split", "=", "'test'", "# the test set does not have any gold labels", "\n", "", "targets", "=", "[", "]", "\n", "for", "x", "in", "dataset", "[", "split", "]", ":", "\n", "            ", "targets", ".", "append", "(", "[", "a", ".", "lower", "(", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "for", "a", "in", "x", "[", "'answers'", "]", "[", "'text'", "]", "]", ")", "\n", "", "", "elif", "\"qaconv\"", "in", "target_dataset", ":", "\n", "        ", "eval_type", "=", "\"qaconv-f1\"", "\n", "if", "\"dev\"", "in", "eval_path", ":", "\n", "            ", "split", "=", "'dev'", "\n", "", "else", ":", "\n", "            ", "split", "=", "'test'", "# the test set does not have any gold labels", "\n", "", "tsv_file", "=", "get_lines_from_file", "(", "bucket_name", "=", "bucket_name", ",", "file_name", "=", "f\"data/qaconv/{split}_meta.txt\"", ")", "\n", "targets", "=", "[", "target_line", "for", "target_line", "in", "tsv_file", "]", "\n", "targets", "=", "[", "x", ".", "split", "(", "\"\\t\"", ")", "[", "1", "]", ".", "split", "(", "\"//\"", ")", "for", "x", "in", "targets", "]", "\n", "", "elif", "len", "(", "[", "x", "for", "x", "in", "[", "\"boolq\"", ",", "\"csqa2\"", ",", "\"squad\"", ",", "\"multirc\"", ",", "\"newsqa\"", ",", "\"strategyqa\"", ",", "\"pubmedqa_pqal_short_ans\"", "]", "if", "x", "in", "target_dataset", "]", ")", ">", "0", ":", "\n", "        ", "eval_type", "=", "\"generic-f1\"", "\n", "targets_file", "=", "(", "[", "blob", "for", "blob", "in", "blobs", "if", "blob", ".", "name", ".", "endswith", "(", "'_targets'", ")", "and", "target_dataset", "in", "blob", ".", "name", "]", ")", "[", "0", "]", "\n", "print", "(", "f\" * targets_file.name: {targets_file.name}\"", ")", "\n", "targets", "=", "get_lines_from_file", "(", "bucket_name", ",", "targets_file", ".", "name", ")", "\n", "targets", "=", "[", "target_line", "for", "target_line", "in", "targets", "]", "\n", "targets", "=", "[", "x", ".", "split", "(", "\"\\t\"", ")", "[", "0", "]", "for", "x", "in", "targets", "]", "\n", "", "elif", "len", "(", "[", "x", "for", "x", "in", "[", "\"race_string\"", ",", "\"race_c\"", ",", "\"openbookqa\"", ",", "\"aqua_rat\"", ",", "\"quail\"", ",", "\n", "\"mcscript\"", ",", "\"mcscript2\"", ",", "\"measuring_massive_multitask_language_understanding\"", ",", "\n", "\"record_multiple_choice\"", ",", "\"qasc\"", ",", "\"qasc_with_ir\"", ",", "\"mctest_corrected_the_separator\"", ",", "\n", "\"arc_hard_dev\"", ",", "\"arc_hard_with_ir_dev\"", ",", "\"arc_easy_with_ir_dev\"", ",", "\"arc_easy_dev\"", ",", "\n", "\"openbookqa_dev\"", ",", "\"openbookqa_with_ir_dev\"", ",", "\"commonsenseqa\"", ",", "\"dream\"", ",", "\n", "\"prost_multiple_choice_with_no_context\"", ",", "\"prost_multiple_choice_with_context\"", ",", "\n", "\"head_qa_en_dev\"", ",", "\"reclor\"", ",", "\"cosmosqa\"", ",", "\n", "\"onestopqa_advanced\"", ",", "\"onestopqa_elementry\"", ",", "\"onestopqa_intermediate\"", ",", "\n", "\"processbank_test\"", ",", "\"winogrande_xl\"", ",", "\"social_iqa\"", ",", "\"social_iqa_test\"", ",", "\n", "\"physical_iqa\"", ",", "\"physical_iqa_test\"", "]", "if", "x", "in", "target_dataset", "]", ")", ">", "0", ":", "\n", "        ", "eval_type", "=", "\"multiple-choice\"", "\n", "print", "(", "f\" * target_dataset: {target_dataset}\"", ")", "\n", "if", "\"dev_eval\"", "in", "eval_path", ":", "\n", "            ", "input_file", "=", "f\"t2t-data/{target_dataset}/dev.tsv\"", "\n", "meta_file", "=", "f\"t2t-data/{target_dataset}/dev_meta.tsv\"", "\n", "", "else", ":", "\n", "            ", "input_file", "=", "f\"t2t-qa/t2t-data/{target_dataset}/test.tsv\"", "\n", "meta_file", "=", "f\"t2t-data/{target_dataset}/test_meta.tsv\"", "\n", "\n", "", "with", "open", "(", "input_file", ")", "as", "f", ":", "\n", "            ", "inputs", "=", "[", "x", ".", "split", "(", "\"\\t\"", ")", "[", "0", "]", "for", "x", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "if", "\"/qasc/\"", "in", "meta_file", ":", "\n", "            ", "regex", "=", "re", ".", "compile", "(", "\"\\([a-h]\\)\"", ")", "\n", "", "else", ":", "\n", "            ", "regex", "=", "re", ".", "compile", "(", "\"\\([a-e]\\)\"", ")", "\n", "\n", "", "with", "open", "(", "meta_file", ")", "as", "f", ":", "\n", "            ", "meta_lines", "=", "list", "(", "f", ".", "readlines", "(", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"unknown dataset . . . \"", ")", "\n", "\n", "", "prediction_checkpoints", "=", "[", "blob", "for", "blob", "in", "blobs", "if", "blob", ".", "name", ".", "endswith", "(", "'_predictions'", ")", "]", "\n", "best_score", "=", "0.0", "\n", "best_checkpoint", "=", "None", "\n", "for", "prediction_checkpoint", "in", "prediction_checkpoints", ":", "\n", "        ", "if", "\"/\"", "+", "target_dataset", "not", "in", "prediction_checkpoint", ".", "name", ":", "\n", "            ", "continue", "\n", "", "print", "(", "f\" * eval_type: {eval_type}\"", ")", "\n", "print", "(", "f' * Evaluating prediction checkpoint {prediction_checkpoint.name}'", ")", "\n", "predictions", "=", "get_lines_from_file", "(", "bucket_name", ",", "prediction_checkpoint", ".", "name", ")", "\n", "predictions", "=", "[", "x", ".", "split", "(", "\"\\t\"", ")", "[", "0", "]", "for", "x", "in", "predictions", "]", "\n", "if", "eval_type", "==", "\"multiple-choice\"", ":", "\n", "            ", "if", "len", "(", "inputs", ")", "!=", "len", "(", "predictions", ")", ":", "\n", "                ", "print", "(", "f' \ud83d\uded1 \ud83d\uded1 \ud83d\uded1 \ud83d\uded1 Something is wrong! The no. of predictions {len(predictions)} does not match no. of target labels {len(inputs)}.'", ")", "\n", "continue", "\n", "", "if", "len", "(", "meta_lines", ")", "!=", "len", "(", "predictions", ")", ":", "\n", "                ", "print", "(", "f' \ud83d\uded1 \ud83d\uded1 \ud83d\uded1 \ud83d\uded1 Something is wrong! {len(predictions)} vs {len(meta_lines)} '", ")", "\n", "continue", "\n", "# create directories, if not availeble (Python >=3.5)", "\n", "", "Path", "(", "prediction_checkpoint", ".", "name", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "outfile", "=", "open", "(", "prediction_checkpoint", ".", "name", "+", "\".csv\"", ",", "\"w\"", ")", "\n", "score", "=", "evaluate_multple_choice_predictions", "(", "inputs", ",", "predictions", ",", "meta_lines", ",", "regex", ",", "outfile", ")", "\n", "", "elif", "eval_type", "in", "[", "\"generic-f1\"", ",", "\"squad2-f1\"", ",", "\"qaconv-f1\"", ",", "\"allennlp-f1\"", ",", "\"tweetqa-textgen\"", ",", "\"rouge-l\"", "]", ":", "\n", "            ", "if", "len", "(", "targets", ")", "!=", "len", "(", "predictions", ")", ":", "\n", "                ", "print", "(", "f' \ud83d\uded1 \ud83d\uded1 \ud83d\uded1 \ud83d\uded1 Something is wrong! The no. of predictions {len(predictions)} does not match no. of target labels {len(targets)}.'", ")", "\n", "continue", "\n", "", "score", "=", "evaluate_generic", "(", "targets", ",", "predictions", ",", "eval_type", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f\" * Unknown eval type: {eval_type}\"", ")", "\n", "\n", "", "print", "(", "f'Score on current checkpoint: {score}'", ")", "\n", "if", "score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "score", "\n", "best_checkpoint", "=", "prediction_checkpoint", ".", "name", "\n", "", "", "print", "(", "f' * Best checkpoint: {best_checkpoint}. Best score: {best_score}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_squad11.normalize_answer": [[13, 29], ["evaluate_squad11.normalize_answer.white_space_fix"], "function", ["None"], ["def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_squad11.f1_score": [[31, 42], ["normalize_answer().split", "normalize_answer().split", "sum", "collections.Counter", "collections.Counter", "common.values", "len", "len", "evaluate_squad11.normalize_answer", "evaluate_squad11.normalize_answer"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer"], ["", "def", "f1_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "prediction_tokens", "=", "normalize_answer", "(", "prediction", ")", ".", "split", "(", ")", "\n", "ground_truth_tokens", "=", "normalize_answer", "(", "ground_truth", ")", ".", "split", "(", ")", "\n", "common", "=", "Counter", "(", "prediction_tokens", ")", "&", "Counter", "(", "ground_truth_tokens", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "prediction_tokens", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "ground_truth_tokens", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_squad11.exact_match_score": [[43, 45], ["evaluate_squad11.normalize_answer", "evaluate_squad11.normalize_answer"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer"], ["", "def", "exact_match_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "return", "(", "normalize_answer", "(", "prediction", ")", "==", "normalize_answer", "(", "ground_truth", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_squad11.metric_max_over_ground_truths": [[47, 53], ["max", "scores_for_ground_truths.append", "evaluate_squad11.exact_match_score", "evaluate_squad11.f1_score"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_natural_questions_ambigqa.exact_match_score", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_natural_questions_ambigqa.f1_score"], ["", "def", "metric_max_over_ground_truths", "(", "metric_fn", ",", "prediction", ",", "ground_truths", ")", ":", "\n", "    ", "scores_for_ground_truths", "=", "[", "]", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "score", "=", "metric_fn", "(", "prediction", ",", "ground_truth", ")", "\n", "scores_for_ground_truths", ".", "append", "(", "score", ")", "\n", "", "return", "max", "(", "scores_for_ground_truths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_squad11.eval_dir": [[54, 94], ["open", "f.readlines", "sorted", "print", "enumerate", "print", "all_predictions.append", "os.listdir", "os.path.isfile", "gold.append", "open", "f.readlines", "len", "len", "evaluate_squad11.metric_max_over_ground_truths", "evaluate_squad11.metric_max_over_ground_truths", "os.path.join", "json.loads", "predictions.append", "len", "len", "l.replace", "l.replace", "int", "int", "x.split", "x.split"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_narrativeqa.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_narrativeqa.metric_max_over_ground_truths"], ["", "def", "eval_dir", "(", "dir", ",", "checkpoint", "=", "'all'", ")", ":", "\n", "# print(dir)", "\n", "    ", "all_predictions", "=", "[", "]", "\n", "onlyfiles", "=", "[", "f", "for", "f", "in", "listdir", "(", "dir", ")", "if", "isfile", "(", "join", "(", "dir", ",", "f", ")", ")", "]", "\n", "\n", "gold", "=", "[", "]", "\n", "with", "open", "(", "gold_all_ans", ")", "as", "f", ":", "\n", "        ", "for", "l", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "gold", ".", "append", "(", "json", ".", "loads", "(", "l", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", ")", "\n", "\n", "", "", "only_predictions", "=", "[", "f", "for", "f", "in", "onlyfiles", "if", "\"_predictions\"", "in", "f", "]", "\n", "if", "checkpoint", "==", "'all'", ":", "\n", "        ", "only_predictions", "=", "sorted", "(", "only_predictions", ")", "\n", "", "else", ":", "\n", "        ", "only_predictions", "=", "[", "x", "for", "x", "in", "only_predictions", "if", "\n", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "2", "]", ")", ">", "1090500", "and", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "2", "]", ")", "<", "1110000", "]", "\n", "\n", "", "for", "file", "in", "only_predictions", ":", "\n", "        ", "print", "(", "dir", "+", "file", ")", "\n", "predictions", "=", "[", "]", "\n", "with", "open", "(", "dir", "+", "file", ")", "as", "f", ":", "\n", "            ", "for", "l", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "predictions", ".", "append", "(", "l", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", "\n", "\n", "", "", "assert", "len", "(", "gold", ")", "==", "len", "(", "predictions", ")", ",", "f\" {len(predictions)}  / {len(gold)} \"", "\n", "\n", "f1", "=", "exact_match", "=", "total", "=", "0", "\n", "for", "i", ",", "prediction", "in", "enumerate", "(", "predictions", ")", ":", "\n", "            ", "exact_match", "+=", "metric_max_over_ground_truths", "(", "\n", "exact_match_score", ",", "prediction", ",", "gold", "[", "i", "]", ")", "\n", "f1", "+=", "metric_max_over_ground_truths", "(", "\n", "f1_score", ",", "prediction", ",", "gold", "[", "i", "]", ")", "\n", "total", "+=", "1", "\n", "\n", "", "exact_match", "=", "100.0", "*", "exact_match", "/", "total", "\n", "f1", "=", "100.0", "*", "f1", "/", "total", "\n", "eval", "=", "{", "'exact_match'", ":", "exact_match", ",", "'f1'", ":", "f1", "}", "\n", "print", "(", "f\" * {dir}{file} -> {eval}\"", ")", "\n", "all_predictions", ".", "append", "(", "[", "file", ",", "eval", "]", ")", "\n", "", "return", "all_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.orb_utils.get_metric_squad": [[8, 17], ["exact_match_score", "f1_score", "em_scores.append", "f1_scores.append", "max", "max"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_natural_questions_ambigqa.exact_match_score", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_natural_questions_ambigqa.f1_score"], ["def", "get_metric_squad", "(", "prediction", ",", "ground_truths", ")", ":", "\n", "    ", "em_scores", "=", "[", "]", "\n", "f1_scores", "=", "[", "]", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "em", "=", "exact_match_score", "(", "prediction", ",", "ground_truth", ")", "\n", "f1", "=", "f1_score", "(", "prediction", ",", "ground_truth", ")", "\n", "em_scores", ".", "append", "(", "em", ")", "\n", "f1_scores", ".", "append", "(", "f1", ")", "\n", "", "return", "max", "(", "em_scores", ")", ",", "max", "(", "f1_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.orb_utils.get_metric_drop": [[19, 27], ["drop_metrics", "em_scores.append", "f1_scores.append", "max", "max"], "function", ["None"], ["", "def", "get_metric_drop", "(", "predicted", ":", "str", ",", "ground_truths", ":", "List", "[", "str", "]", ")", "->", "Tuple", "[", "float", ",", "float", "]", ":", "\n", "    ", "em_scores", "=", "[", "]", "\n", "f1_scores", "=", "[", "]", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "exact_match", ",", "f1", "=", "drop_metrics", "(", "predicted", ",", "ground_truth", ")", "\n", "em_scores", ".", "append", "(", "exact_match", ")", "\n", "f1_scores", ".", "append", "(", "f1", ")", "\n", "", "return", "max", "(", "em_scores", ")", ",", "max", "(", "f1_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.orb_utils.update_extractive_metrics": [[29, 42], ["None"], "function", ["None"], ["", "def", "update_extractive_metrics", "(", "metrics", ",", "dataset_name", ",", "exact_match", ",", "f1", ")", ":", "\n", "    ", "metrics", "[", "dataset_name", "]", "[", "\"exact_match\"", "]", "=", "(", "\n", "metrics", "[", "dataset_name", "]", "[", "\"exact_match\"", "]", "+", "exact_match", "\n", "if", "\"exact_match\"", "in", "metrics", "[", "dataset_name", "]", "\n", "else", "exact_match", "\n", ")", "\n", "metrics", "[", "dataset_name", "]", "[", "\"f1\"", "]", "=", "(", "\n", "metrics", "[", "dataset_name", "]", "[", "\"f1\"", "]", "+", "f1", "if", "\"f1\"", "in", "metrics", "[", "dataset_name", "]", "else", "f1", "\n", ")", "\n", "metrics", "[", "dataset_name", "]", "[", "\"total\"", "]", "=", "(", "\n", "metrics", "[", "dataset_name", "]", "[", "\"total\"", "]", "+", "1", "if", "\"total\"", "in", "metrics", "[", "dataset_name", "]", "else", "1", "\n", ")", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.orb_utils.update_abstractive_metrics": [[44, 81], ["None"], "function", ["None"], ["", "def", "update_abstractive_metrics", "(", "\n", "metrics", ",", "bleu_1_score", ",", "bleu_4_score", ",", "meteor_score", ",", "rouge_f", ",", "rouge_p", ",", "rouge_r", "\n", ")", ":", "\n", "    ", "metrics", "[", "\"narrativeqa\"", "]", "[", "\"bleu_1\"", "]", "=", "(", "\n", "metrics", "[", "\"narrativeqa\"", "]", "[", "\"bleu_1\"", "]", "+", "bleu_1_score", "\n", "if", "\"bleu_1\"", "in", "metrics", "[", "\"narrativeqa\"", "]", "\n", "else", "bleu_1_score", "\n", ")", "\n", "metrics", "[", "\"narrativeqa\"", "]", "[", "\"bleu_4\"", "]", "=", "(", "\n", "metrics", "[", "\"narrativeqa\"", "]", "[", "\"bleu_4\"", "]", "+", "bleu_4_score", "\n", "if", "\"bleu_4\"", "in", "metrics", "[", "\"narrativeqa\"", "]", "\n", "else", "bleu_4_score", "\n", ")", "\n", "metrics", "[", "\"narrativeqa\"", "]", "[", "\"meteor\"", "]", "=", "(", "\n", "metrics", "[", "\"narrativeqa\"", "]", "[", "\"meteor\"", "]", "+", "meteor_score", "\n", "if", "\"meteor\"", "in", "metrics", "[", "\"narrativeqa\"", "]", "\n", "else", "meteor_score", "\n", ")", "\n", "metrics", "[", "\"narrativeqa\"", "]", "[", "\"rouge_f\"", "]", "=", "(", "\n", "metrics", "[", "\"narrativeqa\"", "]", "[", "\"rouge_f\"", "]", "+", "rouge_f", "\n", "if", "\"rouge_f\"", "in", "metrics", "[", "\"narrativeqa\"", "]", "\n", "else", "rouge_f", "\n", ")", "\n", "metrics", "[", "\"narrativeqa\"", "]", "[", "\"rouge_p\"", "]", "=", "(", "\n", "metrics", "[", "\"narrativeqa\"", "]", "[", "\"rouge_p\"", "]", "+", "rouge_p", "\n", "if", "\"rouge_p\"", "in", "metrics", "[", "\"narrativeqa\"", "]", "\n", "else", "rouge_p", "\n", ")", "\n", "metrics", "[", "\"narrativeqa\"", "]", "[", "\"rouge_r\"", "]", "=", "(", "\n", "metrics", "[", "\"narrativeqa\"", "]", "[", "\"rouge_r\"", "]", "+", "rouge_r", "\n", "if", "\"rouge_r\"", "in", "metrics", "[", "\"narrativeqa\"", "]", "\n", "else", "rouge_r", "\n", ")", "\n", "metrics", "[", "\"narrativeqa\"", "]", "[", "\"total\"", "]", "=", "(", "\n", "metrics", "[", "\"narrativeqa\"", "]", "[", "\"total\"", "]", "+", "1", "if", "\"total\"", "in", "metrics", "[", "\"narrativeqa\"", "]", "else", "1", "\n", ")", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.orb_utils.evaluate_dataset": [[83, 117], ["isinstance", "orb_utils.get_metric_squad", "orb_utils.update_extractive_metrics", "get_metric_squad2", "orb_utils.update_extractive_metrics", "orb_utils.get_metric_drop", "orb_utils.update_extractive_metrics", "get_metric_narrativeqa", "orb_utils.update_abstractive_metrics", "print", "isinstance"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.orb_utils.get_metric_squad", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.orb_utils.update_extractive_metrics", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.orb_utils.update_extractive_metrics", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.orb_utils.get_metric_drop", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.orb_utils.update_extractive_metrics", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.orb_utils.update_abstractive_metrics"], ["", "def", "evaluate_dataset", "(", "dataset_name", ",", "prediction", ",", "ground_truths", ",", "metrics", ")", ":", "\n", "    ", "prediction", "=", "prediction", "[", "0", "]", "if", "isinstance", "(", "prediction", ",", "list", ")", "else", "prediction", "\n", "if", "dataset_name", "in", "[", "\n", "\"squad1\"", ",", "\n", "\"ropes\"", ",", "\n", "\"newsqa\"", ",", "\n", "\"duorc\"", ",", "\n", "\"squad1_syn\"", ",", "\n", "\"ropes_syn\"", ",", "\n", "\"newsqa_syn\"", ",", "\n", "\"duorc_syn\"", ",", "\n", "]", ":", "\n", "        ", "exact_match", ",", "f1", "=", "get_metric_squad", "(", "prediction", ",", "[", "truth", "[", "0", "]", "for", "truth", "in", "ground_truths", "]", ")", "\n", "metrics", "=", "update_extractive_metrics", "(", "metrics", ",", "dataset_name", ",", "exact_match", ",", "f1", ")", "\n", "", "elif", "dataset_name", "in", "[", "\"squad2\"", "]", ":", "\n", "        ", "exact_match", ",", "f1", "=", "get_metric_squad2", "(", "prediction", ",", "[", "truth", "[", "0", "]", "for", "truth", "in", "ground_truths", "]", ")", "\n", "metrics", "=", "update_extractive_metrics", "(", "metrics", ",", "dataset_name", ",", "exact_match", ",", "f1", ")", "\n", "", "elif", "dataset_name", "in", "[", "\"drop\"", ",", "\"quoref\"", ",", "\"drop_syn\"", ",", "\"quoref_syn\"", "]", ":", "\n", "        ", "exact_match", ",", "f1", "=", "get_metric_drop", "(", "prediction", ",", "[", "truth", "[", "0", "]", "for", "truth", "in", "ground_truths", "]", ")", "\n", "metrics", "=", "update_extractive_metrics", "(", "metrics", ",", "dataset_name", ",", "exact_match", ",", "f1", ")", "\n", "", "elif", "dataset_name", "==", "\"narrativeqa\"", ":", "\n", "        ", "prediction", "=", "prediction", "[", "0", "]", "if", "isinstance", "(", "prediction", ",", "list", ")", "else", "prediction", "\n", "ground_truths", "=", "[", "truth", "[", "0", "]", "for", "truth", "in", "ground_truths", "]", "\n", "bleu1", ",", "bleu4", ",", "meteor", ",", "rouge_f", ",", "rouge_p", ",", "rouge_r", "=", "get_metric_narrativeqa", "(", "\n", "prediction", ",", "ground_truths", "\n", ")", "\n", "metrics", "=", "update_abstractive_metrics", "(", "\n", "metrics", ",", "bleu1", ",", "bleu4", ",", "meteor", ",", "rouge_f", ",", "rouge_p", ",", "rouge_r", "\n", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Incorrect dataset name at :{0}\"", ".", "format", "(", "dataset_name", ")", ")", "\n", "raise", "ValueError", "\n", "\n", "", "return", "metrics", "", "", ""]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._answer_to_bags": [[11, 25], ["isinstance", "evaluate_drop_quoref_ropes._normalize_answer", "normalized_spans.append", "token_bags.append", "set", "_normalize_answer.split"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._normalize_answer"], ["def", "_answer_to_bags", "(", "\n", "answer", ":", "Union", "[", "str", ",", "List", "[", "str", "]", ",", "Tuple", "[", "str", ",", "...", "]", "]", "\n", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "List", "[", "Set", "[", "str", "]", "]", "]", ":", "\n", "    ", "if", "isinstance", "(", "answer", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "raw_spans", "=", "answer", "\n", "", "else", ":", "\n", "        ", "raw_spans", "=", "[", "answer", "]", "\n", "", "normalized_spans", ":", "List", "[", "str", "]", "=", "[", "]", "\n", "token_bags", "=", "[", "]", "\n", "for", "raw_span", "in", "raw_spans", ":", "\n", "        ", "normalized_span", "=", "_normalize_answer", "(", "raw_span", ")", "\n", "normalized_spans", ".", "append", "(", "normalized_span", ")", "\n", "token_bags", ".", "append", "(", "set", "(", "normalized_span", ".", "split", "(", ")", ")", ")", "\n", "", "return", "normalized_spans", ",", "token_bags", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._white_space_fix": [[27, 29], ["text.split"], "function", ["None"], ["", "def", "_white_space_fix", "(", "text", ":", "str", ")", "->", "str", ":", "\n", "    ", "return", "\" \"", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._remove_punc": [[34, 39], ["evaluate_drop_quoref_ropes._is_number"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._is_number"], ["def", "_remove_punc", "(", "text", ":", "str", ")", "->", "str", ":", "\n", "    ", "if", "not", "_is_number", "(", "text", ")", ":", "\n", "        ", "return", "\"\"", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "EXCLUDE", ")", "\n", "", "else", ":", "\n", "        ", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._lower": [[41, 43], ["text.lower"], "function", ["None"], ["", "", "def", "_lower", "(", "text", ":", "str", ")", "->", "str", ":", "\n", "    ", "return", "text", ".", "lower", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._tokenize": [[45, 47], ["re.split"], "function", ["None"], ["", "def", "_tokenize", "(", "text", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "return", "re", ".", "split", "(", "\" |-\"", ",", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._remove_articles": [[49, 52], ["re.compile", "re.sub"], "function", ["None"], ["", "def", "_remove_articles", "(", "text", ":", "str", ")", "->", "str", ":", "\n", "    ", "regex", "=", "re", ".", "compile", "(", "r\"\\b(a|an|the)\\b\"", ",", "re", ".", "UNICODE", ")", "\n", "return", "re", ".", "sub", "(", "regex", ",", "\" \"", ",", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._normalize_answer": [[54, 64], ["evaluate_drop_quoref_ropes._white_space_fix", "evaluate_drop_quoref_ropes._remove_articles", "evaluate_drop_quoref_ropes._tokenize", "part.strip", "evaluate_drop_quoref_ropes._normalize_number", "evaluate_drop_quoref_ropes._remove_punc", "evaluate_drop_quoref_ropes._lower"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._white_space_fix", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._remove_articles", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._tokenize", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._normalize_number", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._remove_punc", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._lower"], ["", "def", "_normalize_answer", "(", "text", ":", "str", ")", "->", "str", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "\n", "parts", "=", "[", "\n", "_white_space_fix", "(", "_remove_articles", "(", "_normalize_number", "(", "_remove_punc", "(", "_lower", "(", "token", ")", ")", ")", ")", ")", "\n", "for", "token", "in", "_tokenize", "(", "text", ")", "\n", "]", "\n", "parts", "=", "[", "part", "for", "part", "in", "parts", "if", "part", ".", "strip", "(", ")", "]", "\n", "normalized", "=", "\" \"", ".", "join", "(", "parts", ")", ".", "strip", "(", ")", "\n", "return", "normalized", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._is_number": [[66, 72], ["float"], "function", ["None"], ["", "def", "_is_number", "(", "text", ":", "str", ")", "->", "bool", ":", "\n", "    ", "try", ":", "\n", "        ", "float", "(", "text", ")", "\n", "return", "True", "\n", "", "except", "ValueError", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._normalize_number": [[74, 79], ["evaluate_drop_quoref_ropes._is_number", "str", "float"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._is_number"], ["", "", "def", "_normalize_number", "(", "text", ":", "str", ")", "->", "str", ":", "\n", "    ", "if", "_is_number", "(", "text", ")", ":", "\n", "        ", "return", "str", "(", "float", "(", "text", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._match_numbers_if_present": [[81, 93], ["set", "set", "evaluate_drop_quoref_ropes._is_number", "evaluate_drop_quoref_ropes._is_number", "set.intersection", "set.add", "set.add"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._is_number", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._is_number"], ["", "", "def", "_match_numbers_if_present", "(", "gold_bag", ":", "Set", "[", "str", "]", ",", "predicted_bag", ":", "Set", "[", "str", "]", ")", "->", "bool", ":", "\n", "    ", "gold_numbers", "=", "set", "(", ")", "\n", "predicted_numbers", "=", "set", "(", ")", "\n", "for", "word", "in", "gold_bag", ":", "\n", "        ", "if", "_is_number", "(", "word", ")", ":", "\n", "            ", "gold_numbers", ".", "add", "(", "word", ")", "\n", "", "", "for", "word", "in", "predicted_bag", ":", "\n", "        ", "if", "_is_number", "(", "word", ")", ":", "\n", "            ", "predicted_numbers", ".", "add", "(", "word", ")", "\n", "", "", "if", "(", "not", "gold_numbers", ")", "or", "gold_numbers", ".", "intersection", "(", "predicted_numbers", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._compute_f1": [[95, 111], ["len", "gold_bag.intersection", "float", "float", "len", "len"], "function", ["None"], ["", "def", "_compute_f1", "(", "predicted_bag", ":", "Set", "[", "str", "]", ",", "gold_bag", ":", "Set", "[", "str", "]", ")", "->", "float", ":", "\n", "    ", "intersection", "=", "len", "(", "gold_bag", ".", "intersection", "(", "predicted_bag", ")", ")", "\n", "if", "not", "predicted_bag", ":", "\n", "        ", "precision", "=", "1.0", "\n", "", "else", ":", "\n", "        ", "precision", "=", "intersection", "/", "float", "(", "len", "(", "predicted_bag", ")", ")", "\n", "", "if", "not", "gold_bag", ":", "\n", "        ", "recall", "=", "1.0", "\n", "", "else", ":", "\n", "        ", "recall", "=", "intersection", "/", "float", "(", "len", "(", "gold_bag", ")", ")", "\n", "", "f1", "=", "(", "\n", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "if", "not", "(", "precision", "==", "0.0", "and", "recall", "==", "0.0", ")", "\n", "else", "0.0", "\n", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._align_bags": [[113, 129], ["numpy.zeros", "enumerate", "scipy.optimize.linear_sum_assignment", "numpy.zeros", "zip", "enumerate", "max", "len", "len", "evaluate_drop_quoref_ropes._match_numbers_if_present", "max", "evaluate_drop_quoref_ropes._compute_f1", "len", "len"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._match_numbers_if_present", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._compute_f1"], ["", "def", "_align_bags", "(", "predicted", ":", "List", "[", "Set", "[", "str", "]", "]", ",", "gold", ":", "List", "[", "Set", "[", "str", "]", "]", ")", "->", "List", "[", "float", "]", ":", "\n", "    ", "\"\"\"\n    Takes gold and predicted answer sets and first finds the optimal 1-1 alignment\n    between them and gets maximum metric values over all the answers.\n    \"\"\"", "\n", "scores", "=", "np", ".", "zeros", "(", "[", "len", "(", "gold", ")", ",", "len", "(", "predicted", ")", "]", ")", "\n", "for", "gold_index", ",", "gold_item", "in", "enumerate", "(", "gold", ")", ":", "\n", "        ", "for", "pred_index", ",", "pred_item", "in", "enumerate", "(", "predicted", ")", ":", "\n", "            ", "if", "_match_numbers_if_present", "(", "gold_item", ",", "pred_item", ")", ":", "\n", "                ", "scores", "[", "gold_index", ",", "pred_index", "]", "=", "_compute_f1", "(", "pred_item", ",", "gold_item", ")", "\n", "", "", "", "row_ind", ",", "col_ind", "=", "linear_sum_assignment", "(", "-", "scores", ")", "\n", "\n", "max_scores", "=", "np", ".", "zeros", "(", "[", "max", "(", "len", "(", "gold", ")", ",", "len", "(", "predicted", ")", ")", "]", ")", "\n", "for", "row", ",", "column", "in", "zip", "(", "row_ind", ",", "col_ind", ")", ":", "\n", "        ", "max_scores", "[", "row", "]", "=", "max", "(", "max_scores", "[", "row", "]", ",", "scores", "[", "row", ",", "column", "]", ")", "\n", "", "return", "max_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes.f1_metrics": [[131, 153], ["evaluate_drop_quoref_ropes._answer_to_bags", "evaluate_drop_quoref_ropes._answer_to_bags", "evaluate_drop_quoref_ropes._align_bags", "numpy.mean", "round", "set", "set", "len", "len"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._answer_to_bags", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._answer_to_bags", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes._align_bags"], ["", "def", "f1_metrics", "(", "\n", "predicted", ":", "Union", "[", "str", ",", "List", "[", "str", "]", ",", "Tuple", "[", "str", ",", "...", "]", "]", ",", "gold", ":", "Union", "[", "str", ",", "List", "[", "str", "]", ",", "Tuple", "[", "str", ",", "...", "]", "]", "\n", ")", "->", "Tuple", "[", "float", ",", "float", "]", ":", "\n", "    ", "\"\"\"\n    Takes a predicted answer and a gold answer (that are both either a string or a list of\n    strings), and returns exact match and the DROP F1 metric for the prediction.  If you are\n    writing a script for evaluating objects in memory (say, the output of predictions during\n    validation, or while training), this is the function you want to call, after using\n    :func:`answer_json_to_strings` when reading the gold answer from the released data file.\n    \"\"\"", "\n", "predicted_bags", "=", "_answer_to_bags", "(", "predicted", ")", "\n", "gold_bags", "=", "_answer_to_bags", "(", "gold", ")", "\n", "\n", "if", "set", "(", "predicted_bags", "[", "0", "]", ")", "==", "set", "(", "gold_bags", "[", "0", "]", ")", "and", "len", "(", "predicted_bags", "[", "0", "]", ")", "==", "len", "(", "gold_bags", "[", "0", "]", ")", ":", "\n", "        ", "exact_match", "=", "1.0", "\n", "", "else", ":", "\n", "        ", "exact_match", "=", "0.0", "\n", "\n", "", "f1_per_bag", "=", "_align_bags", "(", "predicted_bags", "[", "1", "]", ",", "gold_bags", "[", "1", "]", ")", "\n", "f1", "=", "np", ".", "mean", "(", "f1_per_bag", ")", "\n", "f1", "=", "round", "(", "f1", ",", "2", ")", "\n", "return", "exact_match", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes.eval_dir": [[155, 210], ["len", "len", "len", "len", "open", "enumerate", "open", "f.readlines", "sorted", "print", "instances.items", "print", "all_predictions.append", "os.listdir", "os.path.isfile", "f.readlines", "instances[].append", "golds.append", "open", "f.readlines", "len", "len", "evaluate_drop_quoref_ropes.f1_metrics", "scores.append", "os.path.join", "l.replace().strip", "predictions.append", "len", "len", "tuple", "l.replace().strip", "l.replace", "int", "int", "len", "l.replace", "sum", "x.split", "x.split"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_drop_quoref_ropes.f1_metrics"], ["", "def", "eval_dir", "(", "dir", ",", "checkpoint", "=", "'all'", ")", ":", "\n", "    ", "all_predictions", "=", "[", "]", "\n", "onlyfiles", "=", "[", "f", "for", "f", "in", "listdir", "(", "dir", ")", "if", "isfile", "(", "join", "(", "dir", ",", "f", ")", ")", "]", "\n", "only_targets", "=", "[", "f", "for", "f", "in", "onlyfiles", "if", "\"_targets\"", "in", "f", "]", "\n", "if", "len", "(", "only_targets", ")", ">", "1", ":", "\n", "        ", "return", "None", "\n", "", "assert", "len", "(", "only_targets", ")", "==", "1", ",", "f\"targets: {only_targets} - dir: {dir} - onlyfiles: {onlyfiles}\"", "\n", "\n", "only_inputs", "=", "[", "f", "for", "f", "in", "onlyfiles", "if", "\"input\"", "in", "f", "]", "\n", "if", "len", "(", "only_inputs", ")", ">", "1", ":", "\n", "        ", "return", "None", "\n", "", "assert", "len", "(", "only_inputs", ")", "==", "1", ",", "f\"inputs: {only_inputs} - dir: {dir}\"", "\n", "\n", "instances", "=", "{", "}", "\n", "with", "open", "(", "dir", "+", "only_inputs", "[", "0", "]", ")", "as", "f", ":", "\n", "        ", "for", "i", ",", "l", "in", "enumerate", "(", "f", ".", "readlines", "(", ")", ")", ":", "\n", "            ", "if", "l", "not", "in", "instances", ":", "\n", "                ", "instances", "[", "l", "]", "=", "[", "]", "\n", "", "instances", "[", "l", "]", ".", "append", "(", "i", ")", "\n", "\n", "", "", "golds", "=", "[", "]", "\n", "with", "open", "(", "dir", "+", "only_targets", "[", "0", "]", ")", "as", "f", ":", "\n", "        ", "for", "l", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "golds", ".", "append", "(", "l", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "only_predictions", "=", "[", "f", "for", "f", "in", "onlyfiles", "if", "\"_predictions\"", "in", "f", "]", "\n", "if", "checkpoint", "==", "'all'", ":", "\n", "        ", "only_predictions", "=", "sorted", "(", "only_predictions", ")", "\n", "", "else", ":", "\n", "        ", "only_predictions", "=", "[", "x", "for", "x", "in", "only_predictions", "if", "\n", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "2", "]", ")", ">", "1090500", "and", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "2", "]", ")", "<", "1110000", "]", "\n", "\n", "", "for", "file", "in", "only_predictions", ":", "\n", "        ", "predictions", "=", "[", "]", "\n", "if", "\".json\"", "in", "file", ":", "\n", "            ", "continue", "\n", "", "print", "(", "f\" >> prediction: {file}\"", ")", "\n", "with", "open", "(", "dir", "+", "file", ")", "as", "f", ":", "\n", "            ", "for", "l", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "predictions", ".", "append", "(", "l", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "assert", "len", "(", "golds", ")", "==", "len", "(", "predictions", ")", ",", "f\" {len(predictions)}  / {len(golds)} \"", "\n", "scores", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "instances", ".", "items", "(", ")", ":", "\n", "            ", "golds_subset", "=", "[", "golds", "[", "i", "]", "for", "i", "in", "v", "]", "\n", "metric", "=", "f1_metrics", "(", "predictions", "[", "v", "[", "0", "]", "]", ",", "tuple", "(", "golds_subset", ")", ")", "\n", "scores", ".", "append", "(", "metric", "[", "1", "]", ")", "\n", "# print(metric)", "\n", "# rouge_l_score = metric_max_over_ground_truths(rouge_l, predictions[v[0]], golds_subset)", "\n", "# scores.append(rouge_l_score[\"rouge-l\"][\"f\"])", "\n", "\n", "", "print", "(", "f\" * {dir}{file} -> {100.0 * sum(scores) / len(scores)}\"", ")", "\n", "\n", "all_predictions", ".", "append", "(", "[", "file", ",", "eval", "]", ")", "\n", "", "return", "all_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_squad2.normalize_answer": [[14, 27], ["evaluate_squad2.normalize_answer.white_space_fix"], "function", ["None"], ["def", "normalize_answer", "(", "s", ")", ":", "\n", "  ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "    ", "regex", "=", "re", ".", "compile", "(", "r'\\b(a|an|the)\\b'", ",", "re", ".", "UNICODE", ")", "\n", "return", "re", ".", "sub", "(", "regex", ",", "' '", ",", "text", ")", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "    ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "    ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "    ", "return", "text", ".", "lower", "(", ")", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_squad2.get_tokens": [[28, 31], ["normalize_answer().split", "evaluate_squad2.normalize_answer"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer"], ["", "def", "get_tokens", "(", "s", ")", ":", "\n", "  ", "if", "not", "s", ":", "return", "[", "]", "\n", "return", "normalize_answer", "(", "s", ")", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_squad2.compute_exact": [[32, 34], ["int", "evaluate_squad2.normalize_answer", "evaluate_squad2.normalize_answer"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer"], ["", "def", "compute_exact", "(", "a_gold", ",", "a_pred", ")", ":", "\n", "  ", "return", "int", "(", "normalize_answer", "(", "a_gold", ")", "==", "normalize_answer", "(", "a_pred", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_squad2.compute_f1": [[35, 49], ["evaluate_squad2.get_tokens", "evaluate_squad2.get_tokens", "sum", "collections.Counter", "collections.Counter", "common.values", "int", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.get_tokens", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.get_tokens"], ["", "def", "compute_f1", "(", "a_gold", ",", "a_pred", ")", ":", "\n", "  ", "gold_toks", "=", "get_tokens", "(", "a_gold", ")", "\n", "pred_toks", "=", "get_tokens", "(", "a_pred", ")", "\n", "common", "=", "collections", ".", "Counter", "(", "gold_toks", ")", "&", "collections", ".", "Counter", "(", "pred_toks", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "len", "(", "gold_toks", ")", "==", "0", "or", "len", "(", "pred_toks", ")", "==", "0", ":", "\n", "# If either is no-answer, then F1 is 1 if they agree, 0 otherwise", "\n", "    ", "return", "int", "(", "gold_toks", "==", "pred_toks", ")", "\n", "", "if", "num_same", "==", "0", ":", "\n", "    ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "pred_toks", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "gold_toks", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_squad2.eval_dir": [[50, 100], ["open", "f.readlines", "sorted", "print", "enumerate", "print", "all_predictions.append", "os.listdir", "os.path.isfile", "gold.append", "open", "f.readlines", "len", "len", "max", "max", "os.path.join", "json.loads", "predictions.append", "len", "len", "prediction.lower", "l.replace", "l.replace", "g.lower", "evaluate_squad2.compute_exact", "evaluate_squad2.compute_f1", "int", "int", "x.split", "x.split"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.compute_exact", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.compute_f1"], ["", "def", "eval_dir", "(", "dir", ",", "checkpoint", "=", "'all'", ")", ":", "\n", "# print(dir)", "\n", "    ", "all_predictions", "=", "[", "]", "\n", "onlyfiles", "=", "[", "f", "for", "f", "in", "listdir", "(", "dir", ")", "if", "isfile", "(", "join", "(", "dir", ",", "f", ")", ")", "]", "\n", "\n", "gold", "=", "[", "]", "\n", "with", "open", "(", "gold_all_ans", ")", "as", "f", ":", "\n", "        ", "for", "l", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "gold", ".", "append", "(", "json", ".", "loads", "(", "l", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", ")", "\n", "\n", "", "", "only_predictions", "=", "[", "f", "for", "f", "in", "onlyfiles", "if", "\"_predictions\"", "in", "f", "]", "\n", "if", "checkpoint", "==", "'all'", ":", "\n", "        ", "only_predictions", "=", "sorted", "(", "only_predictions", ")", "\n", "", "else", ":", "\n", "        ", "only_predictions", "=", "[", "x", "for", "x", "in", "only_predictions", "if", "\n", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "2", "]", ")", ">", "1090500", "and", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "2", "]", ")", "<", "1110000", "]", "\n", "\n", "", "for", "file", "in", "only_predictions", ":", "\n", "        ", "print", "(", "dir", "+", "file", ")", "\n", "predictions", "=", "[", "]", "\n", "with", "open", "(", "dir", "+", "file", ")", "as", "f", ":", "\n", "            ", "for", "l", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "predictions", ".", "append", "(", "l", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", "\n", "\n", "", "", "assert", "len", "(", "gold", ")", "==", "len", "(", "predictions", ")", ",", "f\" {len(predictions)}  / {len(gold)} \"", "\n", "\n", "\n", "f1", "=", "exact_match", "=", "total", "=", "0", "\n", "for", "i", ",", "prediction", "in", "enumerate", "(", "predictions", ")", ":", "\n", "# For unanswerable questions, only correct answer is empty string", "\n", "            ", "for", "g", "in", "gold", "[", "i", "]", ":", "\n", "                ", "if", "no_ans", "in", "g", ".", "lower", "(", ")", ":", "\n", "# print(gold[i])", "\n", "                    ", "gold", "[", "i", "]", "=", "[", "\"\"", "]", "\n", "break", "\n", "\n", "", "", "if", "no_ans", "in", "prediction", ".", "lower", "(", ")", ":", "\n", "                ", "prediction", "=", "\"\"", "\n", "\n", "", "exact_match", "+=", "max", "(", "compute_exact", "(", "a", ",", "prediction", ")", "for", "a", "in", "gold", "[", "i", "]", ")", "\n", "f1", "+=", "max", "(", "compute_f1", "(", "a", ",", "prediction", ")", "for", "a", "in", "gold", "[", "i", "]", ")", "\n", "\n", "total", "+=", "1", "\n", "\n", "", "exact_match", "=", "100.0", "*", "exact_match", "/", "total", "\n", "f1", "=", "100.0", "*", "f1", "/", "total", "\n", "eval", "=", "{", "'exact_match'", ":", "exact_match", ",", "'f1'", ":", "f1", "}", "\n", "print", "(", "f\" * {dir}{file} -> {eval}\"", ")", "\n", "all_predictions", ".", "append", "(", "[", "file", ",", "eval", "]", ")", "\n", "", "return", "all_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_natural_questions_ambigqa.normalize_answer": [[14, 31], ["evaluate_natural_questions_ambigqa.normalize_answer.white_space_fix"], "function", ["None"], ["def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_natural_questions_ambigqa.f1_score": [[33, 44], ["normalize_answer().split", "normalize_answer().split", "sum", "collections.Counter", "collections.Counter", "common.values", "len", "len", "evaluate_natural_questions_ambigqa.normalize_answer", "evaluate_natural_questions_ambigqa.normalize_answer"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer"], ["", "def", "f1_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "prediction_tokens", "=", "normalize_answer", "(", "prediction", ")", ".", "split", "(", ")", "\n", "ground_truth_tokens", "=", "normalize_answer", "(", "ground_truth", ")", ".", "split", "(", ")", "\n", "common", "=", "Counter", "(", "prediction_tokens", ")", "&", "Counter", "(", "ground_truth_tokens", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "prediction_tokens", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "ground_truth_tokens", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_natural_questions_ambigqa.exact_match_score": [[46, 49], ["evaluate_natural_questions_ambigqa.normalize_answer", "evaluate_natural_questions_ambigqa.normalize_answer"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer"], ["", "def", "exact_match_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "# print(f\"{prediction} vs {ground_truth} : {normalize_answer(prediction)} : {normalize_answer(ground_truth)}\")", "\n", "    ", "return", "(", "normalize_answer", "(", "prediction", ")", "==", "normalize_answer", "(", "ground_truth", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_natural_questions_ambigqa.metric_max_over_ground_truths": [[51, 57], ["max", "scores_for_ground_truths.append", "evaluate_natural_questions_ambigqa.exact_match_score", "evaluate_natural_questions_ambigqa.f1_score"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_natural_questions_ambigqa.exact_match_score", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_natural_questions_ambigqa.f1_score"], ["", "def", "metric_max_over_ground_truths", "(", "metric_fn", ",", "prediction", ",", "ground_truths", ")", ":", "\n", "    ", "scores_for_ground_truths", "=", "[", "]", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "score", "=", "metric_fn", "(", "prediction", ",", "ground_truth", ")", "\n", "scores_for_ground_truths", ".", "append", "(", "score", ")", "\n", "", "return", "max", "(", "scores_for_ground_truths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_natural_questions_ambigqa.eval_dir": [[59, 118], ["enumerate", "len", "len", "open", "f.readlines", "sorted", "golds_tmp.append", "len", "len", "print", "enumerate", "enumerate", "print", "all_predictions.append", "os.listdir", "os.path.isfile", "golds.append", "open", "f.readlines", "preds_tmp.append", "len", "len", "len", "len", "evaluate_natural_questions_ambigqa.metric_max_over_ground_truths", "evaluate_natural_questions_ambigqa.metric_max_over_ground_truths", "os.path.join", "l.replace().strip", "predictions.append", "len", "len", "l.replace().strip", "l.replace", "int", "int", "l.replace", "x.split", "x.split"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_narrativeqa.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_narrativeqa.metric_max_over_ground_truths"], ["", "def", "eval_dir", "(", "dir", ",", "checkpoint", "=", "'all'", ")", ":", "\n", "    ", "all_predictions", "=", "[", "]", "\n", "onlyfiles", "=", "[", "f", "for", "f", "in", "listdir", "(", "dir", ")", "if", "isfile", "(", "join", "(", "dir", ",", "f", ")", ")", "]", "\n", "only_targets", "=", "[", "f", "for", "f", "in", "onlyfiles", "if", "\"_targets\"", "in", "f", "]", "\n", "if", "len", "(", "only_targets", ")", ">", "1", ":", "\n", "        ", "return", "None", "\n", "", "assert", "len", "(", "only_targets", ")", "==", "1", ",", "f\"targets: {only_targets} - dir: {dir}\"", "\n", "golds", "=", "[", "]", "\n", "with", "open", "(", "dir", "+", "only_targets", "[", "0", "]", ")", "as", "f", ":", "\n", "        ", "for", "l", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "golds", ".", "append", "(", "l", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "only_predictions", "=", "[", "f", "for", "f", "in", "onlyfiles", "if", "\"_predictions\"", "in", "f", "]", "\n", "if", "checkpoint", "==", "'all'", ":", "\n", "        ", "only_predictions", "=", "sorted", "(", "only_predictions", ")", "\n", "", "else", ":", "\n", "        ", "only_predictions", "=", "[", "x", "for", "x", "in", "only_predictions", "if", "\n", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "2", "]", ")", ">", "1090500", "and", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "2", "]", ")", "<", "1110000", "]", "\n", "\n", "", "golds_tmp", "=", "[", "]", "\n", "for", "i", ",", "id", "in", "enumerate", "(", "meta_ids", ")", ":", "\n", "        ", "if", "id", "in", "meta_ids", "[", ":", "i", "]", ":", "\n", "            ", "continue", "\n", "", "golds_tmp", ".", "append", "(", "golds", "[", "i", "]", ")", "\n", "", "assert", "len", "(", "golds", ")", ">", "len", "(", "golds_tmp", ")", "\n", "golds", "=", "golds_tmp", "\n", "\n", "for", "file", "in", "only_predictions", ":", "\n", "        ", "print", "(", "dir", "+", "file", ")", "\n", "predictions", "=", "[", "]", "\n", "with", "open", "(", "dir", "+", "file", ")", "as", "f", ":", "\n", "            ", "for", "l", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "predictions", ".", "append", "(", "l", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "preds_tmp", "=", "[", "]", "\n", "for", "i", ",", "id", "in", "enumerate", "(", "meta_ids", ")", ":", "\n", "            ", "if", "id", "in", "meta_ids", "[", ":", "i", "]", ":", "\n", "                ", "continue", "\n", "", "preds_tmp", ".", "append", "(", "predictions", "[", "i", "]", ")", "\n", "", "assert", "len", "(", "predictions", ")", ">", "len", "(", "preds_tmp", ")", "\n", "\n", "predictions", "=", "preds_tmp", "\n", "\n", "assert", "len", "(", "golds", ")", "==", "len", "(", "predictions", ")", ",", "f\" {len(predictions)}  / {len(golds)} \"", "\n", "\n", "f1", "=", "exact_match", "=", "total", "=", "0", "\n", "for", "i", ",", "prediction", "in", "enumerate", "(", "predictions", ")", ":", "\n", "            ", "exact_match", "+=", "metric_max_over_ground_truths", "(", "\n", "exact_match_score", ",", "prediction", ",", "[", "golds", "[", "i", "]", "]", ")", "\n", "f1", "+=", "metric_max_over_ground_truths", "(", "\n", "f1_score", ",", "prediction", ",", "[", "golds", "[", "i", "]", "]", ")", "\n", "total", "+=", "1", "\n", "\n", "", "exact_match", "=", "100.0", "*", "exact_match", "/", "total", "\n", "f1", "=", "100.0", "*", "f1", "/", "total", "\n", "eval", "=", "{", "'exact_match'", ":", "exact_match", ",", "'f1'", ":", "f1", "}", "\n", "print", "(", "f\" * {dir}{file} -> {eval}\"", ")", "\n", "all_predictions", ".", "append", "(", "[", "file", ",", "eval", "]", ")", "\n", "", "return", "all_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_narrativeqa.rouge_l": [[22, 24], ["rouge_l_evaluator.get_scores"], "function", ["None"], ["def", "rouge_l", "(", "p", ",", "g", ")", ":", "\n", "    ", "return", "rouge_l_evaluator", ".", "get_scores", "(", "p", ",", "g", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_narrativeqa.metric_max_over_ground_truths": [[25, 44], ["scores_for_ground_truths.append", "isinstance", "copy.deepcopy", "round", "round", "round", "round", "max", "max", "max", "max", "evaluate_narrativeqa.rouge_l"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_narrativeqa.rouge_l"], ["", "def", "metric_max_over_ground_truths", "(", "metric_fn", ",", "prediction", ",", "ground_truths", ")", ":", "\n", "    ", "scores_for_ground_truths", "=", "[", "]", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "score", "=", "metric_fn", "(", "prediction", ",", "[", "ground_truth", "]", ")", "\n", "scores_for_ground_truths", ".", "append", "(", "score", ")", "\n", "", "if", "isinstance", "(", "score", ",", "dict", ")", "and", "\"rouge-l\"", "in", "score", ":", "\n", "        ", "max_score", "=", "copy", ".", "deepcopy", "(", "score", ")", "\n", "max_score", "[", "\"rouge-l\"", "]", "[", "\"f\"", "]", "=", "round", "(", "\n", "max", "(", "[", "score", "[", "\"rouge-l\"", "]", "[", "\"f\"", "]", "for", "score", "in", "scores_for_ground_truths", "]", ")", ",", "2", "\n", ")", "\n", "max_score", "[", "\"rouge-l\"", "]", "[", "\"p\"", "]", "=", "round", "(", "\n", "max", "(", "[", "score", "[", "\"rouge-l\"", "]", "[", "\"p\"", "]", "for", "score", "in", "scores_for_ground_truths", "]", ")", ",", "2", "\n", ")", "\n", "max_score", "[", "\"rouge-l\"", "]", "[", "\"r\"", "]", "=", "round", "(", "\n", "max", "(", "[", "score", "[", "\"rouge-l\"", "]", "[", "\"r\"", "]", "for", "score", "in", "scores_for_ground_truths", "]", ")", ",", "2", "\n", ")", "\n", "return", "max_score", "\n", "", "else", ":", "\n", "        ", "return", "round", "(", "max", "(", "scores_for_ground_truths", ")", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_narrativeqa.eval_dir": [[46, 95], ["len", "len", "len", "len", "open", "enumerate", "open", "f.readlines", "sorted", "instances.items", "print", "all_predictions.append", "os.listdir", "os.path.isfile", "f.readlines", "instances[].append", "golds.append", "open", "f.readlines", "len", "len", "evaluate_narrativeqa.metric_max_over_ground_truths", "scores.append", "os.path.join", "l.replace().strip", "predictions.append", "len", "len", "l.replace().strip", "l.replace", "int", "int", "len", "l.replace", "sum", "x.split", "x.split"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_narrativeqa.metric_max_over_ground_truths"], ["", "", "def", "eval_dir", "(", "dir", ",", "checkpoints", "=", "'all'", ")", ":", "\n", "    ", "all_predictions", "=", "[", "]", "\n", "onlyfiles", "=", "[", "f", "for", "f", "in", "listdir", "(", "dir", ")", "if", "isfile", "(", "join", "(", "dir", ",", "f", ")", ")", "]", "\n", "only_targets", "=", "[", "f", "for", "f", "in", "onlyfiles", "if", "\"_targets\"", "in", "f", "]", "\n", "if", "len", "(", "only_targets", ")", ">", "1", ":", "\n", "        ", "return", "None", "\n", "", "assert", "len", "(", "only_targets", ")", "==", "1", ",", "f\"targets: {only_targets} - dir: {dir}\"", "\n", "\n", "only_inputs", "=", "[", "f", "for", "f", "in", "onlyfiles", "if", "\"inputs\"", "in", "f", "]", "\n", "if", "len", "(", "only_inputs", ")", ">", "1", ":", "\n", "        ", "return", "None", "\n", "", "assert", "len", "(", "only_inputs", ")", "==", "1", ",", "f\"inputs: {only_inputs} - dir: {dir}\"", "\n", "\n", "instances", "=", "{", "}", "\n", "with", "open", "(", "dir", "+", "only_inputs", "[", "0", "]", ")", "as", "f", ":", "\n", "        ", "for", "i", ",", "l", "in", "enumerate", "(", "f", ".", "readlines", "(", ")", ")", ":", "\n", "            ", "if", "l", "not", "in", "instances", ":", "\n", "                ", "instances", "[", "l", "]", "=", "[", "]", "\n", "", "instances", "[", "l", "]", ".", "append", "(", "i", ")", "\n", "\n", "", "", "golds", "=", "[", "]", "\n", "with", "open", "(", "dir", "+", "only_targets", "[", "0", "]", ")", "as", "f", ":", "\n", "        ", "for", "l", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "golds", ".", "append", "(", "l", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "only_predictions", "=", "[", "f", "for", "f", "in", "onlyfiles", "if", "\"_predictions\"", "in", "f", "]", "\n", "if", "checkpoints", "==", "'all'", ":", "\n", "        ", "only_predictions", "=", "sorted", "(", "only_predictions", ")", "\n", "", "else", ":", "\n", "        ", "only_predictions", "=", "[", "x", "for", "x", "in", "only_predictions", "if", "\n", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "2", "]", ")", ">", "1090500", "and", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "-", "2", "]", ")", "<", "1110000", "]", "\n", "\n", "", "for", "file", "in", "only_predictions", ":", "\n", "        ", "predictions", "=", "[", "]", "\n", "with", "open", "(", "dir", "+", "file", ")", "as", "f", ":", "\n", "            ", "for", "l", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "predictions", ".", "append", "(", "l", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "assert", "len", "(", "golds", ")", "==", "len", "(", "predictions", ")", ",", "f\" {len(predictions)}  / {len(golds)} \"", "\n", "scores", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "instances", ".", "items", "(", ")", ":", "\n", "            ", "golds_subset", "=", "[", "golds", "[", "i", "]", "for", "i", "in", "v", "]", "\n", "rouge_l_score", "=", "metric_max_over_ground_truths", "(", "rouge_l", ",", "predictions", "[", "v", "[", "0", "]", "]", ",", "golds_subset", ")", "\n", "scores", ".", "append", "(", "rouge_l_score", "[", "\"rouge-l\"", "]", "[", "\"f\"", "]", ")", "\n", "\n", "", "print", "(", "f\" * {dir}{file} -> {100.0 * sum(scores) / len(scores)}\"", ")", "\n", "\n", "all_predictions", ".", "append", "(", "[", "file", ",", "eval", "]", ")", "\n", "", "return", "all_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.tweetqa_eval.normalize_answer": [[20, 36], ["tweetqa_eval.normalize_answer.white_space_fix"], "function", ["None"], ["def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.tweetqa_eval.ans_score": [[40, 49], ["tweetqa_eval.normalize_answer", "nltk.translate.bleu_score.sentence_bleu", "tweetqa_eval.normalize_answer", "normalize_answer.split", "_.split"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer"], ["def", "ans_score", "(", "ans", ",", "gold_list", ")", ":", "\n", "    ", "ans", "=", "normalize_answer", "(", "ans", ")", "\n", "gold_list", "=", "[", "normalize_answer", "(", "ref", ")", "for", "ref", "in", "gold_list", "]", "\n", "bleu", "=", "sentence_bleu", "(", "[", "_", ".", "split", "(", ")", "for", "_", "in", "gold_list", "]", ",", "ans", ".", "split", "(", ")", ",", "weights", "=", "(", "1", ",", "0", ",", "0", ",", "0", ")", ")", "\n", "# meteor, _ = meteor_scorer.compute_score({0:gold_list}, {0:[ans]})", "\n", "# rouge, _ = rouge_scorer.compute_score({0:gold_list}, {0:[ans]})", "\n", "# Daniel (December'21): disabled metrics other than BLEU since we don't use them (and they seem to correlate)", "\n", "return", "{", "\n", "'bleu'", ":", "bleu", ",", "\n", "# 'meteor':meteor,", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.tweetqa_eval.evaluate": [[53, 84], ["json.load", "json.load", "idx2gold.keys", "print", "open", "open", "isinstance", "tweetqa_eval.ans_score", "idx2scores.values", "idx2scores.values", "idx2scores.values", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.tweetqa_eval.ans_score"], ["", "def", "evaluate", "(", "test_annotation_file", ",", "user_annotation_file", ",", "phase_codename", ",", "**", "kwargs", ")", ":", "\n", "    ", "gold_file", "=", "test_annotation_file", "\n", "pred_file", "=", "user_annotation_file", "\n", "gold", "=", "json", ".", "load", "(", "open", "(", "gold_file", ")", ")", "\n", "pred", "=", "json", ".", "load", "(", "open", "(", "pred_file", ")", ")", "\n", "idx2gold", "=", "{", "item", "[", "'qid'", "]", ":", "item", "[", "'Answer'", "]", "for", "item", "in", "gold", "}", "\n", "idx2pred", "=", "{", "item", "[", "'qid'", "]", ":", "item", "[", "'Answer'", "]", "for", "item", "in", "pred", "}", "\n", "idx2scores", "=", "{", "}", "\n", "for", "id_", "in", "idx2gold", ".", "keys", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "idx2pred", "[", "id_", "]", ",", "list", ")", ":", "\n", "            ", "pred_ans", "=", "idx2pred", "[", "id_", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "pred_ans", "=", "idx2pred", "[", "id_", "]", "\n", "", "idx2scores", "[", "id_", "]", "=", "ans_score", "(", "pred_ans", ",", "idx2gold", "[", "id_", "]", ")", "\n", "", "bleus", "=", "[", "item", "[", "'bleu'", "]", "for", "item", "in", "idx2scores", ".", "values", "(", ")", "]", "\n", "meteors", "=", "[", "item", "[", "'meteor'", "]", "for", "item", "in", "idx2scores", ".", "values", "(", ")", "]", "\n", "rouges", "=", "[", "item", "[", "'rouge'", "]", "for", "item", "in", "idx2scores", ".", "values", "(", ")", "]", "\n", "print", "(", "{", "'BLEU'", ":", "np", ".", "mean", "(", "bleus", ")", ",", "'METEOR'", ":", "np", ".", "mean", "(", "meteors", ")", ",", "'ROUGE'", ":", "np", ".", "mean", "(", "rouges", ")", "}", ")", "\n", "\n", "output", "=", "{", "}", "\n", "output", "[", "'result'", "]", "=", "[", "\n", "{", "'test_split'", ":", "\n", "{", "\n", "'BLEU-1'", ":", "np", ".", "mean", "(", "bleus", ")", ",", "\n", "'METEOR'", ":", "np", ".", "mean", "(", "meteors", ")", ",", "\n", "'ROUGE'", ":", "np", ".", "mean", "(", "rouges", ")", "\n", "}", "\n", "}", "\n", "]", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.make_qid_to_has_ans": [[31, 37], ["bool"], "function", ["None"], ["def", "make_qid_to_has_ans", "(", "dataset", ")", ":", "\n", "    ", "qid_to_has_ans", "=", "{", "}", "\n", "for", "qa", "in", "dataset", ":", "\n", "#print(qa)", "\n", "        ", "qid_to_has_ans", "[", "qa", "[", "'id'", "]", "]", "=", "bool", "(", "qa", "[", "'answers'", "]", ")", "\n", "", "return", "qid_to_has_ans", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer": [[38, 51], ["qaconv_eval.normalize_answer.white_space_fix"], "function", ["None"], ["", "def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "regex", "=", "re", ".", "compile", "(", "r'\\b(a|an|the)\\b'", ",", "re", ".", "UNICODE", ")", "\n", "return", "re", ".", "sub", "(", "regex", ",", "' '", ",", "text", ")", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.get_tokens": [[52, 55], ["normalize_answer().split", "qaconv_eval.normalize_answer"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer"], ["", "def", "get_tokens", "(", "s", ")", ":", "\n", "    ", "if", "not", "s", ":", "return", "[", "]", "\n", "return", "normalize_answer", "(", "s", ")", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.compute_exact": [[56, 58], ["int", "qaconv_eval.normalize_answer", "qaconv_eval.normalize_answer"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer"], ["", "def", "compute_exact", "(", "a_gold", ",", "a_pred", ")", ":", "\n", "    ", "return", "int", "(", "normalize_answer", "(", "a_gold", ")", "==", "normalize_answer", "(", "a_pred", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.compute_fuzz_ratio": [[59, 61], ["fuzzywuzzy.fuzz.ratio", "qaconv_eval.normalize_answer", "qaconv_eval.normalize_answer"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer"], ["", "def", "compute_fuzz_ratio", "(", "a_gold", ",", "a_pred", ")", ":", "\n", "    ", "return", "fuzz", ".", "ratio", "(", "normalize_answer", "(", "a_pred", ")", ",", "normalize_answer", "(", "a_gold", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.add_word_number_mapping": [[62, 74], ["ans.isdigit", "added_ans.append", "num2words.num2words", "str", "added_ans.append", "word2number.w2n.word_to_num"], "function", ["None"], ["", "def", "add_word_number_mapping", "(", "answers", ")", ":", "\n", "    ", "added_ans", "=", "[", "]", "\n", "for", "ans", "in", "answers", ":", "\n", "        ", "if", "ans", ".", "isdigit", "(", ")", ":", "\n", "            ", "added_ans", ".", "append", "(", "num2words", "(", "ans", ")", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "temp", "=", "str", "(", "w2n", ".", "word_to_num", "(", "ans", ")", ")", "\n", "added_ans", ".", "append", "(", "temp", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "", "", "", "return", "added_ans", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.compute_unanswerable_binary": [[75, 80], ["sklearn.metrics.f1_score", "qaconv_eval.normalize_answer"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.evaluate_natural_questions_ambigqa.f1_score", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer"], ["", "def", "compute_unanswerable_binary", "(", "a_gold_list", ",", "a_pred_list", ")", ":", "\n", "    ", "a_gold_unanswerable", "=", "[", "1", "if", "\"unanswerable\"", "in", "a", "else", "0", "for", "a", "in", "a_gold_list", "]", "\n", "a_pred_unanswerable", "=", "[", "1", "if", "normalize_answer", "(", "a", ")", "==", "\"unanswerable\"", "else", "0", "for", "a", "in", "a_pred_list", "]", "\n", "f1", "=", "f1_score", "(", "a_gold_unanswerable", ",", "a_pred_unanswerable", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.compute_f1": [[81, 95], ["qaconv_eval.get_tokens", "qaconv_eval.get_tokens", "sum", "collections.Counter", "collections.Counter", "common.values", "int", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.get_tokens", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.get_tokens"], ["", "def", "compute_f1", "(", "a_pred", ",", "a_gold", ")", ":", "\n", "    ", "gold_toks", "=", "get_tokens", "(", "a_gold", ")", "\n", "pred_toks", "=", "get_tokens", "(", "a_pred", ")", "\n", "common", "=", "collections", ".", "Counter", "(", "gold_toks", ")", "&", "collections", ".", "Counter", "(", "pred_toks", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "len", "(", "gold_toks", ")", "==", "0", "or", "len", "(", "pred_toks", ")", "==", "0", ":", "\n", "# If either is no-answer, then F1 is 1 if they agree, 0 otherwise", "\n", "        ", "return", "int", "(", "gold_toks", "==", "pred_toks", ")", "\n", "", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "pred_toks", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "gold_toks", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.get_raw_scores": [[96, 124], ["qaconv_eval.compute_unanswerable_binary", "qaconv_eval.add_word_number_mapping", "max", "max", "max", "a_gold_list.append", "a_pred_list.append", "print", "qaconv_eval.normalize_answer", "qaconv_eval.compute_exact", "qaconv_eval.compute_f1", "qaconv_eval.compute_fuzz_ratio", "qaconv_eval.normalize_answer"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.compute_unanswerable_binary", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.add_word_number_mapping", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.compute_exact", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.compute_f1", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.compute_fuzz_ratio", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.normalize_answer"], ["", "def", "get_raw_scores", "(", "dataset", ",", "preds", ")", ":", "\n", "    ", "exact_scores", "=", "{", "}", "\n", "f1_scores", "=", "{", "}", "\n", "fuzz_ratio_scores", "=", "{", "}", "\n", "a_gold_list", ",", "a_pred_list", "=", "[", "]", ",", "[", "]", "\n", "for", "qa", "in", "dataset", ":", "\n", "        ", "qid", "=", "qa", "[", "'id'", "]", "\n", "gold_answers", "=", "[", "a", "for", "a", "in", "qa", "[", "'answers'", "]", "\n", "if", "normalize_answer", "(", "a", ")", "]", "\n", "gold_answers", "+=", "add_word_number_mapping", "(", "gold_answers", ")", "\n", "if", "not", "gold_answers", ":", "\n", "# For unanswerable questions, only correct answer is empty string", "\n", "            ", "gold_answers", "=", "[", "'unanswerable'", "]", "\n", "", "if", "qid", "not", "in", "preds", ":", "\n", "            ", "print", "(", "'Missing prediction for %s'", "%", "qid", ")", "\n", "continue", "\n", "", "a_pred", "=", "preds", "[", "qid", "]", "\n", "# Take max over all gold answers", "\n", "exact_scores", "[", "qid", "]", "=", "max", "(", "compute_exact", "(", "a", ",", "a_pred", ")", "for", "a", "in", "gold_answers", ")", "\n", "f1_scores", "[", "qid", "]", "=", "max", "(", "compute_f1", "(", "a", ",", "a_pred", ")", "for", "a", "in", "gold_answers", ")", "\n", "fuzz_ratio_scores", "[", "qid", "]", "=", "max", "(", "compute_fuzz_ratio", "(", "a", ",", "a_pred", ")", "for", "a", "in", "gold_answers", ")", "\n", "\n", "a_gold_list", ".", "append", "(", "[", "normalize_answer", "(", "a", ")", "for", "a", "in", "gold_answers", "]", ")", "\n", "a_pred_list", ".", "append", "(", "a_pred", ")", "\n", "\n", "", "unanswerable_binary_f1", "=", "compute_unanswerable_binary", "(", "a_gold_list", ",", "a_pred_list", ")", "\n", "\n", "return", "exact_scores", ",", "f1_scores", ",", "fuzz_ratio_scores", ",", "unanswerable_binary_f1", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.apply_no_ans_threshold": [[125, 134], ["scores.items", "float"], "function", ["None"], ["", "def", "apply_no_ans_threshold", "(", "scores", ",", "na_probs", ",", "qid_to_has_ans", ",", "na_prob_thresh", ")", ":", "\n", "    ", "new_scores", "=", "{", "}", "\n", "for", "qid", ",", "s", "in", "scores", ".", "items", "(", ")", ":", "\n", "        ", "pred_na", "=", "na_probs", "[", "qid", "]", ">", "na_prob_thresh", "\n", "if", "pred_na", ":", "\n", "            ", "new_scores", "[", "qid", "]", "=", "float", "(", "not", "qid_to_has_ans", "[", "qid", "]", ")", "\n", "", "else", ":", "\n", "            ", "new_scores", "[", "qid", "]", "=", "s", "\n", "", "", "return", "new_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.make_eval_dict": [[135, 151], ["len", "collections.OrderedDict", "len", "collections.OrderedDict", "sum", "sum", "sum", "sum", "fuzz_scores.values", "sum", "sum", "exact_scores.values", "f1_scores.values"], "function", ["None"], ["", "def", "make_eval_dict", "(", "exact_scores", ",", "f1_scores", ",", "fuzz_scores", ",", "qid_list", "=", "None", ")", ":", "\n", "    ", "if", "not", "qid_list", ":", "\n", "        ", "total", "=", "len", "(", "exact_scores", ")", "\n", "return", "collections", ".", "OrderedDict", "(", "[", "\n", "(", "'exact'", ",", "100.0", "*", "sum", "(", "exact_scores", ".", "values", "(", ")", ")", "/", "total", ")", ",", "\n", "(", "'f1'", ",", "100.0", "*", "sum", "(", "f1_scores", ".", "values", "(", ")", ")", "/", "total", ")", ",", "\n", "(", "'fzr'", ",", "sum", "(", "fuzz_scores", ".", "values", "(", ")", ")", "/", "total", ")", ",", "\n", "(", "'total'", ",", "total", ")", ",", "\n", "]", ")", "\n", "", "else", ":", "\n", "        ", "total", "=", "len", "(", "qid_list", ")", "\n", "return", "collections", ".", "OrderedDict", "(", "[", "\n", "(", "'exact'", ",", "100.0", "*", "sum", "(", "exact_scores", "[", "k", "]", "for", "k", "in", "qid_list", ")", "/", "total", ")", ",", "\n", "(", "'f1'", ",", "100.0", "*", "sum", "(", "f1_scores", "[", "k", "]", "for", "k", "in", "qid_list", ")", "/", "total", ")", ",", "\n", "(", "'fzr'", ",", "sum", "(", "fuzz_scores", "[", "k", "]", "for", "k", "in", "qid_list", ")", "/", "total", ")", ",", "\n", "(", "'total'", ",", "total", ")", ",", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.merge_eval": [[153, 156], ["None"], "function", ["None"], ["", "", "def", "merge_eval", "(", "main_eval", ",", "new_eval", ",", "prefix", ")", ":", "\n", "    ", "for", "k", "in", "new_eval", ":", "\n", "        ", "main_eval", "[", "'%s_%s'", "%", "(", "prefix", ",", "k", ")", "]", "=", "new_eval", "[", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.plot_pr_curve": [[157, 167], ["plt.step", "plt.fill_between", "plt.xlabel", "plt.ylabel", "plt.xlim", "plt.ylim", "plt.title", "plt.savefig", "plt.clf"], "function", ["None"], ["", "", "def", "plot_pr_curve", "(", "precisions", ",", "recalls", ",", "out_image", ",", "title", ")", ":", "\n", "    ", "plt", ".", "step", "(", "recalls", ",", "precisions", ",", "color", "=", "'b'", ",", "alpha", "=", "0.2", ",", "where", "=", "'post'", ")", "\n", "plt", ".", "fill_between", "(", "recalls", ",", "precisions", ",", "step", "=", "'post'", ",", "alpha", "=", "0.2", ",", "color", "=", "'b'", ")", "\n", "plt", ".", "xlabel", "(", "'Recall'", ")", "\n", "plt", ".", "ylabel", "(", "'Precision'", ")", "\n", "plt", ".", "xlim", "(", "[", "0.0", ",", "1.05", "]", ")", "\n", "plt", ".", "ylim", "(", "[", "0.0", ",", "1.05", "]", ")", "\n", "plt", ".", "title", "(", "title", ")", "\n", "plt", ".", "savefig", "(", "out_image", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.make_precision_recall_eval": [[168, 190], ["sorted", "enumerate", "qaconv_eval.plot_pr_curve", "float", "float", "precisions.append", "recalls.append", "len"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.plot_pr_curve"], ["", "def", "make_precision_recall_eval", "(", "scores", ",", "na_probs", ",", "num_true_pos", ",", "qid_to_has_ans", ",", "\n", "out_image", "=", "None", ",", "title", "=", "None", ")", ":", "\n", "    ", "qid_list", "=", "sorted", "(", "na_probs", ",", "key", "=", "lambda", "k", ":", "na_probs", "[", "k", "]", ")", "\n", "true_pos", "=", "0.0", "\n", "cur_p", "=", "1.0", "\n", "cur_r", "=", "0.0", "\n", "precisions", "=", "[", "1.0", "]", "\n", "recalls", "=", "[", "0.0", "]", "\n", "avg_prec", "=", "0.0", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "        ", "if", "qid_to_has_ans", "[", "qid", "]", ":", "\n", "            ", "true_pos", "+=", "scores", "[", "qid", "]", "\n", "", "cur_p", "=", "true_pos", "/", "float", "(", "i", "+", "1", ")", "\n", "cur_r", "=", "true_pos", "/", "float", "(", "num_true_pos", ")", "\n", "if", "i", "==", "len", "(", "qid_list", ")", "-", "1", "or", "na_probs", "[", "qid", "]", "!=", "na_probs", "[", "qid_list", "[", "i", "+", "1", "]", "]", ":", "\n", "# i.e., if we can put a threshold after this point", "\n", "            ", "avg_prec", "+=", "cur_p", "*", "(", "cur_r", "-", "recalls", "[", "-", "1", "]", ")", "\n", "precisions", ".", "append", "(", "cur_p", ")", "\n", "recalls", ".", "append", "(", "cur_r", ")", "\n", "", "", "if", "out_image", ":", "\n", "        ", "plot_pr_curve", "(", "precisions", ",", "recalls", ",", "out_image", ",", "title", ")", "\n", "", "return", "{", "'ap'", ":", "100.0", "*", "avg_prec", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.run_precision_recall_analysis": [[191, 214], ["sum", "qaconv_eval.make_precision_recall_eval", "qaconv_eval.make_precision_recall_eval", "qaconv_eval.make_precision_recall_eval", "qaconv_eval.merge_eval", "qaconv_eval.merge_eval", "qaconv_eval.merge_eval", "os.makedirs", "float", "os.path.exists", "os.path.join", "os.path.join", "qid_to_has_ans.items", "os.path.join", "qid_to_has_ans.values"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.make_precision_recall_eval", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.make_precision_recall_eval", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.make_precision_recall_eval", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.merge_eval", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.merge_eval", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.merge_eval"], ["", "def", "run_precision_recall_analysis", "(", "main_eval", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "\n", "qid_to_has_ans", ",", "out_image_dir", ")", ":", "\n", "    ", "if", "out_image_dir", "and", "not", "os", ".", "path", ".", "exists", "(", "out_image_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "out_image_dir", ")", "\n", "", "num_true_pos", "=", "sum", "(", "1", "for", "v", "in", "qid_to_has_ans", ".", "values", "(", ")", "if", "v", ")", "\n", "if", "num_true_pos", "==", "0", ":", "\n", "        ", "return", "\n", "", "pr_exact", "=", "make_precision_recall_eval", "(", "\n", "exact_raw", ",", "na_probs", ",", "num_true_pos", ",", "qid_to_has_ans", ",", "\n", "out_image", "=", "os", ".", "path", ".", "join", "(", "out_image_dir", ",", "'pr_exact.png'", ")", ",", "\n", "title", "=", "'Precision-Recall curve for Exact Match score'", ")", "\n", "pr_f1", "=", "make_precision_recall_eval", "(", "\n", "f1_raw", ",", "na_probs", ",", "num_true_pos", ",", "qid_to_has_ans", ",", "\n", "out_image", "=", "os", ".", "path", ".", "join", "(", "out_image_dir", ",", "'pr_f1.png'", ")", ",", "\n", "title", "=", "'Precision-Recall curve for F1 score'", ")", "\n", "oracle_scores", "=", "{", "k", ":", "float", "(", "v", ")", "for", "k", ",", "v", "in", "qid_to_has_ans", ".", "items", "(", ")", "}", "\n", "pr_oracle", "=", "make_precision_recall_eval", "(", "\n", "oracle_scores", ",", "na_probs", ",", "num_true_pos", ",", "qid_to_has_ans", ",", "\n", "out_image", "=", "os", ".", "path", ".", "join", "(", "out_image_dir", ",", "'pr_oracle.png'", ")", ",", "\n", "title", "=", "'Oracle Precision-Recall curve (binary task of HasAns vs. NoAns)'", ")", "\n", "merge_eval", "(", "main_eval", ",", "pr_exact", ",", "'pr_exact'", ")", "\n", "merge_eval", "(", "main_eval", ",", "pr_f1", ",", "'pr_f1'", ")", "\n", "merge_eval", "(", "main_eval", ",", "pr_oracle", ",", "'pr_oracle'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.histogram_na_prob": [[215, 226], ["plt.hist", "plt.xlabel", "plt.ylabel", "plt.title", "plt.savefig", "plt.clf", "numpy.ones_like", "float", "os.path.join", "len"], "function", ["None"], ["", "def", "histogram_na_prob", "(", "na_probs", ",", "qid_list", ",", "image_dir", ",", "name", ")", ":", "\n", "    ", "if", "not", "qid_list", ":", "\n", "        ", "return", "\n", "", "x", "=", "[", "na_probs", "[", "k", "]", "for", "k", "in", "qid_list", "]", "\n", "weights", "=", "np", ".", "ones_like", "(", "x", ")", "/", "float", "(", "len", "(", "x", ")", ")", "\n", "plt", ".", "hist", "(", "x", ",", "weights", "=", "weights", ",", "bins", "=", "20", ",", "range", "=", "(", "0.0", ",", "1.0", ")", ")", "\n", "plt", ".", "xlabel", "(", "'Model probability of no-answer'", ")", "\n", "plt", ".", "ylabel", "(", "'Proportion of dataset'", ")", "\n", "plt", ".", "title", "(", "'Histogram of no-answer probability: %s'", "%", "name", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'na_prob_hist_%s.png'", "%", "name", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.find_best_thresh": [[227, 247], ["sum", "sorted", "enumerate", "len"], "function", ["None"], ["", "def", "find_best_thresh", "(", "preds", ",", "scores", ",", "na_probs", ",", "qid_to_has_ans", ")", ":", "\n", "    ", "num_no_ans", "=", "sum", "(", "1", "for", "k", "in", "qid_to_has_ans", "if", "not", "qid_to_has_ans", "[", "k", "]", ")", "\n", "cur_score", "=", "num_no_ans", "\n", "best_score", "=", "cur_score", "\n", "best_thresh", "=", "0.0", "\n", "qid_list", "=", "sorted", "(", "na_probs", ",", "key", "=", "lambda", "k", ":", "na_probs", "[", "k", "]", ")", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "        ", "if", "qid", "not", "in", "scores", ":", "continue", "\n", "if", "qid_to_has_ans", "[", "qid", "]", ":", "\n", "            ", "diff", "=", "scores", "[", "qid", "]", "\n", "", "else", ":", "\n", "            ", "if", "preds", "[", "qid", "]", ":", "\n", "                ", "diff", "=", "-", "1", "\n", "", "else", ":", "\n", "                ", "diff", "=", "0", "\n", "", "", "cur_score", "+=", "diff", "\n", "if", "cur_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "cur_score", "\n", "best_thresh", "=", "na_probs", "[", "qid", "]", "\n", "", "", "return", "100.0", "*", "best_score", "/", "len", "(", "scores", ")", ",", "best_thresh", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.find_all_best_thresh": [[248, 255], ["qaconv_eval.find_best_thresh", "qaconv_eval.find_best_thresh"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.find_best_thresh", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.find_best_thresh"], ["", "def", "find_all_best_thresh", "(", "main_eval", ",", "preds", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", ":", "\n", "    ", "best_exact", ",", "exact_thresh", "=", "find_best_thresh", "(", "preds", ",", "exact_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "best_f1", ",", "f1_thresh", "=", "find_best_thresh", "(", "preds", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "main_eval", "[", "'best_exact'", "]", "=", "best_exact", "\n", "main_eval", "[", "'best_exact_thresh'", "]", "=", "exact_thresh", "\n", "main_eval", "[", "'best_f1'", "]", "=", "best_f1", "\n", "main_eval", "[", "'best_f1_thresh'", "]", "=", "f1_thresh", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.main": [[256, 298], ["qaconv_eval.make_qid_to_has_ans", "qaconv_eval.get_raw_scores", "qaconv_eval.apply_no_ans_threshold", "qaconv_eval.apply_no_ans_threshold", "qaconv_eval.apply_no_ans_threshold", "qaconv_eval.make_eval_dict", "open", "json.load", "open", "json.load", "qaconv_eval.make_eval_dict", "qaconv_eval.merge_eval", "qaconv_eval.make_eval_dict", "qaconv_eval.merge_eval", "qaconv_eval.find_all_best_thresh", "qaconv_eval.run_precision_recall_analysis", "qaconv_eval.histogram_na_prob", "qaconv_eval.histogram_na_prob", "open", "json.load", "make_qid_to_has_ans.items", "make_qid_to_has_ans.items"], "function", ["home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.make_qid_to_has_ans", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.get_raw_scores", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.apply_no_ans_threshold", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.apply_no_ans_threshold", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.apply_no_ans_threshold", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.make_eval_dict", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.make_eval_dict", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.merge_eval", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.make_eval_dict", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.merge_eval", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.find_all_best_thresh", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.run_precision_recall_analysis", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.histogram_na_prob", "home.repos.pwc.inspect_result.allenai_unifiedqa.evaluation.qaconv_eval.histogram_na_prob"], ["", "def", "main", "(", "OPTS", ")", ":", "\n", "    ", "with", "open", "(", "OPTS", ".", "data_file", ")", "as", "f", ":", "\n", "        ", "dataset", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "OPTS", ".", "pred_file", ")", "as", "f", ":", "\n", "        ", "preds", "=", "json", ".", "load", "(", "f", ")", "\n", "", "if", "OPTS", ".", "na_prob_file", ":", "\n", "        ", "with", "open", "(", "OPTS", ".", "na_prob_file", ")", "as", "f", ":", "\n", "            ", "na_probs", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "na_probs", "=", "{", "k", ":", "0.0", "for", "k", "in", "preds", "}", "\n", "\n", "", "qid_to_has_ans", "=", "make_qid_to_has_ans", "(", "dataset", ")", "# maps qid to True/False", "\n", "has_ans_qids", "=", "[", "k", "for", "k", ",", "v", "in", "qid_to_has_ans", ".", "items", "(", ")", "if", "v", "]", "\n", "no_ans_qids", "=", "[", "k", "for", "k", ",", "v", "in", "qid_to_has_ans", ".", "items", "(", ")", "if", "not", "v", "]", "\n", "exact_raw", ",", "f1_raw", ",", "fuzz_raw", ",", "unans_bin_f1", "=", "get_raw_scores", "(", "dataset", ",", "preds", ")", "\n", "exact_thresh", "=", "apply_no_ans_threshold", "(", "exact_raw", ",", "na_probs", ",", "qid_to_has_ans", ",", "\n", "OPTS", ".", "na_prob_thresh", ")", "\n", "f1_thresh", "=", "apply_no_ans_threshold", "(", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ",", "\n", "OPTS", ".", "na_prob_thresh", ")", "\n", "fuzz_thresh", "=", "apply_no_ans_threshold", "(", "fuzz_raw", ",", "na_probs", ",", "qid_to_has_ans", ",", "\n", "OPTS", ".", "na_prob_thresh", ")", "\n", "out_eval", "=", "make_eval_dict", "(", "exact_thresh", ",", "f1_thresh", ",", "fuzz_thresh", ")", "\n", "\n", "if", "has_ans_qids", ":", "\n", "        ", "has_ans_eval", "=", "make_eval_dict", "(", "exact_thresh", ",", "f1_thresh", ",", "fuzz_thresh", ",", "qid_list", "=", "has_ans_qids", ")", "\n", "merge_eval", "(", "out_eval", ",", "has_ans_eval", ",", "'HasAns'", ")", "\n", "\n", "", "if", "no_ans_qids", ":", "\n", "        ", "no_ans_eval", "=", "make_eval_dict", "(", "exact_thresh", ",", "f1_thresh", ",", "fuzz_thresh", ",", "qid_list", "=", "no_ans_qids", ")", "\n", "merge_eval", "(", "out_eval", ",", "no_ans_eval", ",", "'NoAns'", ")", "\n", "out_eval", "[", "\"unans_bin_f1\"", "]", "=", "unans_bin_f1", "*", "100", "\n", "\n", "", "if", "OPTS", ".", "na_prob_file", ":", "\n", "        ", "find_all_best_thresh", "(", "out_eval", ",", "preds", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "\n", "", "if", "OPTS", ".", "na_prob_file", "and", "OPTS", ".", "out_image_dir", ":", "\n", "        ", "run_precision_recall_analysis", "(", "out_eval", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "\n", "qid_to_has_ans", ",", "OPTS", ".", "out_image_dir", ")", "\n", "histogram_na_prob", "(", "na_probs", ",", "has_ans_qids", ",", "OPTS", ".", "out_image_dir", ",", "'hasAns'", ")", "\n", "histogram_na_prob", "(", "na_probs", ",", "no_ans_qids", ",", "OPTS", ".", "out_image_dir", ",", "'noAns'", ")", "\n", "\n", "", "return", "out_eval", "\n", "# if OPTS.out_file:", "\n"]]}