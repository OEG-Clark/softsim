{"home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).write_to_log.write_log": [[1, 4], ["open", "f.write"], "function", ["None"], ["def", "write_log", "(", "str", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "+", "\"\\n\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.__init__": [[13, 32], ["vqa_data_provider_layer.VQADataProvider.load_data", "len", "open", "json.load", "open", "json.load", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data"], ["    ", "def", "__init__", "(", "self", ",", "batchsize", "=", "64", ",", "max_length", "=", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "max_w_length", "=", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "batchsize", "\n", "self", ".", "d_vocabulary", "=", "None", "\n", "self", ".", "batch_index", "=", "None", "\n", "self", ".", "batch_len", "=", "None", "\n", "self", ".", "rev_adict", "=", "None", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "max_w_length", "=", "max_w_length", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "qdic", ",", "self", ".", "adic", "=", "VQADataProvider", ".", "load_data", "(", "mode", ")", "\n", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "cdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "vdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "adict", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "self", ".", "n_ans_vocabulary", "=", "len", "(", "self", ".", "adict", ")", "\n", "#self.nlp = spacy.load('en', vectors='en_glove_cc_300_1m_vectors')", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.load_vqa_json": [[35, 58], ["write_to_log.write_log", "open", "json.load", "open", "json.load", "str", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["", "@", "staticmethod", "\n", "def", "load_vqa_json", "(", "data_split", ")", ":", "\n", "        ", "\"\"\"\n        Parses the question and answer json files for the given data split. \n        Returns the question dictionary and the answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ques_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "[", "'questions'", "]", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "qdic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'question_id'", "]", ")", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image_id'", "]", "}", "\n", "\n", "", "", "if", "'test'", "not", "in", "data_split", ":", "\n", "            ", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ans_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "adata", "=", "json", ".", "load", "(", "f", ")", "[", "'annotations'", "]", "\n", "for", "a", "in", "adata", ":", "\n", "                    ", "adic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "a", "[", "'question_id'", "]", ")", "]", "=", "a", "[", "'answers'", "]", "\n", "\n", "", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for '", "+", "data_split", ",", "'log.txt'", ")", "\n", "return", "qdic", ",", "adic", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.load_genome_json": [[59, 76], ["write_to_log.write_log", "open", "json.load", "str", "str", "len"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["", "@", "staticmethod", "\n", "def", "load_genome_json", "(", ")", ":", "\n", "        ", "\"\"\"\n        Parses the genome json file. Returns the question dictionary and the\n        answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'genome_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "key", "=", "'genome'", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'id'", "]", ")", "\n", "qdic", "[", "key", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image'", "]", "}", "\n", "adic", "[", "key", "]", "=", "[", "{", "'answer'", ":", "q", "[", "'answer'", "]", "}", "]", "\n", "\n", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for genome'", ",", "'log.txt'", ")", "\n", "return", "qdic", ",", "adic", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.load_data": [[77, 92], ["data_split_str.split", "config.DATA_PATHS.keys", "vqa_data_provider_layer.VQADataProvider.load_genome_json", "all_qdic.update", "all_adic.update", "vqa_data_provider_layer.VQADataProvider.load_vqa_json", "all_qdic.update", "all_adic.update"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_genome_json", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_vqa_json"], ["", "@", "staticmethod", "\n", "def", "load_data", "(", "data_split_str", ")", ":", "\n", "        ", "all_qdic", ",", "all_adic", "=", "{", "}", ",", "{", "}", "\n", "for", "data_split", "in", "data_split_str", ".", "split", "(", "'+'", ")", ":", "\n", "            ", "assert", "data_split", "in", "config", ".", "DATA_PATHS", ".", "keys", "(", ")", ",", "'unknown data split'", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_genome_json", "(", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "", "else", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_vqa_json", "(", "data_split", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "\n", "", "", "return", "all_qdic", ",", "all_adic", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.getQuesIds": [[93, 95], ["vqa_data_provider_layer.VQADataProvider.qdic.keys"], "methods", ["None"], ["", "def", "getQuesIds", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "qdic", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId": [[96, 98], ["qid.split"], "methods", ["None"], ["", "def", "getStrippedQuesId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.getImgId": [[99, 101], ["None"], "methods", ["None"], ["", "def", "getImgId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'iid'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.getQuesStr": [[102, 104], ["None"], "methods", ["None"], ["", "def", "getQuesStr", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.getAnsObj": [[105, 109], ["None"], "methods", ["None"], ["", "def", "getAnsObj", "(", "self", ",", "qid", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "", "return", "self", ".", "adic", "[", "qid", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.seq_to_list": [[110, 120], ["s.lower", "re.sub().split", "filter", "re.sub", "re.sub", "re.sub", "re.sub.lower", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "seq_to_list", "(", "s", ")", ":", "\n", "        ", "t_str", "=", "s", ".", "lower", "(", ")", "\n", "for", "i", "in", "[", "r'\\?'", ",", "r'\\!'", ",", "r'\\''", ",", "r'\\\"'", ",", "r'\\$'", ",", "r'\\:'", ",", "r'\\@'", ",", "r'\\('", ",", "r'\\)'", ",", "r'\\,'", ",", "r'\\.'", ",", "r'\\;'", "]", ":", "\n", "            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "''", ",", "t_str", ")", "\n", "", "for", "i", "in", "[", "r'\\-'", ",", "r'\\/'", "]", ":", "\n", "            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "' '", ",", "t_str", ")", "\n", "", "q_list", "=", "re", ".", "sub", "(", "r'\\?'", ",", "''", ",", "t_str", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "\n", "q_list", "=", "filter", "(", "lambda", "x", ":", "len", "(", "x", ")", ">", "0", ",", "q_list", ")", "\n", "return", "q_list", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.extract_answer": [[121, 134], ["dic.has_key", "max", "xrange", "dic.items"], "methods", ["None"], ["", "def", "extract_answer", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "", "answer_list", "=", "[", "answer_obj", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "dic", "=", "{", "}", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "dic", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "dic", "[", "ans", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "dic", "[", "ans", "]", "=", "1", "\n", "", "", "max_key", "=", "max", "(", "(", "v", ",", "k", ")", "for", "(", "k", ",", "v", ")", "in", "dic", ".", "items", "(", ")", ")", "[", "1", "]", "\n", "return", "max_key", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.extract_answer_prob": [[135, 153], ["vqa_data_provider_layer.VQADataProvider.adict.has_key", "len", "random.choice", "prob_answer_list.append", "Exception"], "methods", ["None"], ["", "def", "extract_answer_prob", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "prob_answer_list", "=", "[", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "prob_answer_list", ".", "append", "(", "ans", ")", "\n", "\n", "", "", "if", "len", "(", "prob_answer_list", ")", "==", "0", ":", "\n", "            ", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "return", "'hoge'", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"This should not happen.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "random", ".", "choice", "(", "prob_answer_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.qlist_to_vec": [[202, 244], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "xrange", "list", "xrange", "len", "vqa_data_provider_layer.VQADataProvider.vdict.has_key", "len", "len", "vqa_data_provider_layer.VQADataProvider.cdict.has_key", "len", "len", "len"], "methods", ["None"], ["", "", "def", "qlist_to_vec", "(", "self", ",", "max_length", ",", "max_w_length", ",", "q_list", ")", ":", "\n", "        ", "\"\"\"\n        Converts a list of chars into a format suitable for the embedding layer.\n\n        Arguments:\n        max_length -- the maximum length of a question sequence\n        max_w_length -- the maximum length of a character sequence for each word\n        q_list -- a list of words which are the tokens in the question\n\n        Returns:\n        qvec -- A max_length length vector containing one-hot indices for each word\n        cvec -- A max_length length sequence continuation indicator vector\n        qcvec -- A max_w_length*max_length length vector containing one-hot indices for each char\n        ccvec -- A max_w_length*max_length length sequence continuation indicator vector\n        \"\"\"", "\n", "qvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "cvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "qcvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "ccvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "for", "i", "in", "xrange", "(", "max_length", ")", ":", "\n", "            ", "if", "i", "<", "max_length", "-", "len", "(", "q_list", ")", ":", "\n", "                ", "cvec", "[", "i", "]", "=", "0", "\n", "", "else", ":", "\n", "                ", "w", "=", "q_list", "[", "i", "-", "(", "max_length", "-", "len", "(", "q_list", ")", ")", "]", "\n", "# is the word in the vocabulary?", "\n", "if", "self", ".", "vdict", ".", "has_key", "(", "w", ")", "is", "False", ":", "\n", "                    ", "w", "=", "''", "\n", "", "qvec", "[", "i", "]", "=", "self", ".", "vdict", "[", "w", "]", "\n", "cvec", "[", "i", "]", "=", "1.0", "/", "len", "(", "q_list", ")", "\n", "j", "=", "max_w_length", "*", "i", "\n", "w_list", "=", "list", "(", "w", ")", "\n", "for", "k", "in", "xrange", "(", "max_w_length", ")", ":", "\n", "                    ", "if", "k", "<", "max_w_length", "-", "len", "(", "w_list", ")", ":", "\n", "                        ", "ccvec", "[", "j", "+", "k", "]", "=", "0", "\n", "", "else", ":", "\n", "                        ", "c", "=", "w_list", "[", "k", "-", "(", "max_w_length", "-", "len", "(", "w_list", ")", ")", "]", "\n", "# is the char in the vocabulary?", "\n", "if", "self", ".", "cdict", ".", "has_key", "(", "c", ")", "is", "False", ":", "\n", "                            ", "c", "=", "''", "\n", "", "qcvec", "[", "j", "+", "k", "]", "=", "self", ".", "cdict", "[", "c", "]", "\n", "ccvec", "[", "j", "+", "k", "]", "=", "1.0", "/", "len", "(", "w_list", ")", "\n", "", "", "", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.answer_to_vec": [[245, 255], ["vqa_data_provider_layer.VQADataProvider.adict.has_key"], "methods", ["None"], ["", "def", "answer_to_vec", "(", "self", ",", "ans_str", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "if", "self", ".", "adict", ".", "has_key", "(", "ans_str", ")", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "ans_str", "]", "\n", "", "else", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "''", "]", "\n", "", "return", "ans", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.vec_to_answer": [[256, 265], ["vqa_data_provider_layer.VQADataProvider.adict.items"], "methods", ["None"], ["", "def", "vec_to_answer", "(", "self", ",", "ans_symbol", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "rev_adict", "is", "None", ":", "\n", "            ", "rev_adict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "adict", ".", "items", "(", ")", ":", "\n", "                ", "rev_adict", "[", "v", "]", "=", "k", "\n", "", "self", ".", "rev_adict", "=", "rev_adict", "\n", "\n", "", "return", "self", ".", "rev_adict", "[", "ans_symbol", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.create_batch": [[266, 316], ["numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "enumerate", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "vqa_data_provider_layer.VQADataProvider.answer_to_vec", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "qid.split", "vqa_data_provider_layer.VQADataProvider.extract_answer", "vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "numpy.sqrt", "write_to_log.write_log", "numpy.load", "numpy.load", "str", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.answer_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["", "def", "create_batch", "(", "self", ",", "qid_list", ")", ":", "\n", "\n", "        ", "qvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "cvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "qcvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ccvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ivec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "2048", "*", "14", "*", "14", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "2048", ",", "14", ",", "14", ")", "\n", "avec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ")", "\n", "#glove_matrix = np.zeros(self.batchsize * self.max_length * GLOVE_EMBEDDING_SIZE).reshape(\\", "\n", "#self.batchsize, self.max_length, GLOVE_EMBEDDING_SIZE)", "\n", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "\n", "# load raw question information", "\n", "            ", "q_str", "=", "self", ".", "getQuesStr", "(", "qid", ")", "\n", "q_ans", "=", "self", ".", "getAnsObj", "(", "qid", ")", "\n", "q_iid", "=", "self", ".", "getImgId", "(", "qid", ")", "\n", "\n", "# convert question to vec", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "t_qvec", ",", "t_cvec", ",", "t_qcvec", ",", "t_ccvec", "=", "self", ".", "qlist_to_vec", "(", "self", ".", "max_length", ",", "self", ".", "max_w_length", ",", "q_list", ")", "\n", "\n", "try", ":", "\n", "                ", "qid_split", "=", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "\n", "data_split", "=", "qid_split", "[", "0", "]", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "else", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "t_ivec", "=", "(", "t_ivec", "/", "np", ".", "sqrt", "(", "(", "t_ivec", "**", "2", ")", ".", "sum", "(", ")", ")", ")", "\n", "", "except", ":", "\n", "                ", "t_ivec", "=", "0.", "\n", "write_log", "(", "'data not found for qid : '", "+", "str", "(", "q_iid", ")", "+", "' '", "+", "self", ".", "mode", ",", "'log.txt'", ")", "\n", "\n", "# convert answer to vec", "\n", "", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer", "(", "q_ans", ")", "\n", "", "else", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer_prob", "(", "q_ans", ")", "\n", "", "t_avec", "=", "self", ".", "answer_to_vec", "(", "q_ans_str", ")", "\n", "\n", "qvec", "[", "i", ",", "...", "]", "=", "t_qvec", "\n", "cvec", "[", "i", ",", "...", "]", "=", "t_cvec", "\n", "qcvec", "[", "i", ",", "...", "]", "=", "t_qcvec", "\n", "ccvec", "[", "i", ",", "...", "]", "=", "t_ccvec", "\n", "ivec", "[", "i", ",", "...", "]", "=", "t_ivec", "\n", "avec", "[", "i", ",", "...", "]", "=", "t_avec", "\n", "#glove_matrix[i,...] = t_glove_matrix", "\n", "\n", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", ",", "ivec", ",", "avec", "#, glove_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProvider.get_batch_vec": [[318, 365], ["vqa_data_provider_layer.VQADataProvider.create_batch", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "random.shuffle", "len", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.adict.has_key", "t_qid_list.append", "t_iid_list.append", "vqa_data_provider_layer.VQADataProvider.get_batch_vec.has_at_least_one_valid_answer"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.create_batch", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId"], ["", "def", "get_batch_vec", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "batch_len", "is", "None", ":", "\n", "            ", "self", ".", "n_skipped", "=", "0", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_len", "=", "len", "(", "qid_list", ")", "\n", "self", ".", "batch_index", "=", "0", "\n", "self", ".", "epoch_counter", "=", "0", "\n", "\n", "", "def", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "            ", "answer_obj", "=", "self", ".", "getAnsObj", "(", "t_qid", ")", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "                ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n", "                    ", "return", "True", "\n", "\n", "", "", "", "counter", "=", "0", "\n", "t_qid_list", "=", "[", "]", "\n", "t_iid_list", "=", "[", "]", "\n", "while", "counter", "<", "self", ".", "batchsize", ":", "\n", "            ", "t_qid", "=", "self", ".", "qid_list", "[", "self", ".", "batch_index", "]", "\n", "t_iid", "=", "self", ".", "getImgId", "(", "t_qid", ")", "\n", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n", "", "elif", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n", "", "else", ":", "\n", "                ", "self", ".", "n_skipped", "+=", "1", "\n", "\n", "", "if", "self", ".", "batch_index", "<", "self", ".", "batch_len", "-", "1", ":", "\n", "                ", "self", ".", "batch_index", "+=", "1", "\n", "", "else", ":", "\n", "                ", "self", ".", "epoch_counter", "+=", "1", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_index", "=", "0", "\n", "write_log", "(", "\"%d questions were skipped in a single epoch\"", "%", "self", ".", "n_skipped", ",", "'log.txt'", ")", "\n", "self", ".", "n_skipped", "=", "0", "\n", "\n", "", "", "t_batch", "=", "self", ".", "create_batch", "(", "t_qid_list", ")", "\n", "return", "t_batch", "+", "(", "t_qid_list", ",", "t_iid_list", ",", "self", ".", "epoch_counter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProviderLayer.setup": [[371, 387], ["top[].reshape", "top[].reshape", "top[].reshape", "top[].reshape", "top[].reshape", "top[].reshape", "json.loads", "json.loads", "vqa_data_provider_layer.VQADataProvider"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape"], ["def", "setup", "(", "self", ",", "bottom", ",", "top", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "json", ".", "loads", "(", "self", ".", "param_str", ")", "[", "'batchsize'", "]", "\n", "self", ".", "top_names", "=", "[", "'data'", ",", "'cont'", ",", "'data1'", ",", "'cont1'", ",", "'feature'", ",", "'label'", "]", "#,'glove']", "\n", "top", "[", "0", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ")", "\n", "top", "[", "1", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ")", "\n", "top", "[", "2", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", "*", "config", ".", "MAX_WORDS_IN_QUESTION", ")", "\n", "top", "[", "3", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", "*", "config", ".", "MAX_WORDS_IN_QUESTION", ")", "\n", "top", "[", "4", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "2048", ",", "14", ",", "14", ")", "\n", "top", "[", "5", "]", ".", "reshape", "(", "self", ".", "batchsize", ")", "\n", "#top[4].reshape(self.batchsize,config.MAX_WORDS_IN_QUESTION,GLOVE_EMBEDDING_SIZE)", "\n", "\n", "self", ".", "mode", "=", "json", ".", "loads", "(", "self", ".", "param_str", ")", "[", "'mode'", "]", "\n", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "self", ".", "dp", "=", "VQADataProvider", "(", "batchsize", "=", "self", ".", "batchsize", ",", "mode", "=", "self", ".", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProviderLayer.reshape": [[388, 390], ["None"], "methods", ["None"], ["", "", "def", "reshape", "(", "self", ",", "bottom", ",", "top", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProviderLayer.forward": [[391, 402], ["vqa_data_provider_layer.VQADataProviderLayer.dp.get_batch_vec"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec"], ["", "def", "forward", "(", "self", ",", "bottom", ",", "top", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "word", ",", "cont", ",", "word_c", ",", "cont_c", ",", "feature", ",", "answer", ",", "_", ",", "_", ",", "_", "=", "self", ".", "dp", ".", "get_batch_vec", "(", ")", "\n", "top", "[", "0", "]", ".", "data", "[", "...", "]", "=", "word", "# np.transpose(word,(1,0)) # N x T -> T x N", "\n", "top", "[", "1", "]", ".", "data", "[", "...", "]", "=", "cont", "# np.transpose(cont,(1,0))", "\n", "top", "[", "2", "]", ".", "data", "[", "...", "]", "=", "word_c", "\n", "top", "[", "3", "]", ".", "data", "[", "...", "]", "=", "cont_c", "\n", "top", "[", "4", "]", ".", "data", "[", "...", "]", "=", "feature", "\n", "top", "[", "5", "]", ".", "data", "[", "...", "]", "=", "answer", "\n", "#top[4].data[...] = glove_matrix # np.transpose(glove_matrix, (1,0,2)) # N x T x 300 -> T x N x 300", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).vqa_data_provider_layer.VQADataProviderLayer.backward": [[404, 406], ["None"], "methods", ["None"], ["", "", "def", "backward", "(", "self", ",", "top", ",", "propagate_down", ",", "bottom", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).train_att_bc.qlstm": [[19, 117], ["caffe.NetSpec", "json.dumps", "caffe.layers.Python", "caffe.layers.Embed", "caffe.layers.Scale", "caffe.layers.Reshape", "caffe.layers.Slice", "xrange", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Concat", "caffe.layers.Reshape", "caffe.layers.Embed", "caffe.layers.Concat", "caffe.layers.Scale", "caffe.layers.Reshape", "caffe.layers.Convolution", "caffe.layers.Reshape", "caffe.layers.Tile", "caffe.layers.Tile", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.Reshape", "caffe.layers.Softmax", "caffe.layers.Reshape", "caffe.layers.Slice", "caffe.layers.DummyData", "caffe.layers.SoftAttention", "caffe.layers.SoftAttention", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Concat", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Reshape", "caffe.layers.InnerProduct", "caffe.layers.SoftmaxWithLoss", "caffe.NetSpec.to_proto", "caffe.NetSpec.__setattr__", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "str", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "int", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "config.TRAIN_DATA_SPLITS", "config.BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION", "config.LENGTH_OF_LONGEST_WORD", "config.VAL_BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION", "config.LENGTH_OF_LONGEST_WORD"], "function", ["None"], ["def", "qlstm", "(", "mode", ",", "batchsize", ",", "T", ",", "T_c", ",", "question_c_vocab_size", ",", "question_vocab_size", ")", ":", "\n", "    ", "n", "=", "caffe", ".", "NetSpec", "(", ")", "\n", "mode_str", "=", "json", ".", "dumps", "(", "{", "'mode'", ":", "mode", ",", "'batchsize'", ":", "batchsize", "}", ")", "\n", "n", ".", "data", ",", "n", ".", "cont", ",", "n", ".", "data1", ",", "n", ".", "cont1", ",", "n", ".", "img_feature", ",", "n", ".", "label", "=", "L", ".", "Python", "(", "module", "=", "'vqa_data_provider_layer'", ",", "layer", "=", "'VQADataProviderLayer'", ",", "param_str", "=", "mode_str", ",", "ntop", "=", "6", ")", "#5 )", "\n", "\n", "# char embedding", "\n", "n", ".", "embed_c", "=", "L", ".", "Embed", "(", "n", ".", "data1", ",", "input_dim", "=", "question_c_vocab_size", ",", "num_output", "=", "100", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "\n", "n", ".", "embed_c_scale", "=", "L", ".", "Scale", "(", "n", ".", "embed_c", ",", "n", ".", "cont1", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "\n", "n", ".", "embed_c_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_c_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T_c", "*", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T_c*T x d_c x 1", "\n", "tops", "=", "L", ".", "Slice", "(", "n", ".", "embed_c_scale_resh", ",", "ntop", "=", "T", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T_c x d_c x 1", "\n", "for", "i", "in", "xrange", "(", "T", ")", ":", "\n", "        ", "n", ".", "__setattr__", "(", "'Slice_'", "+", "str", "(", "i", "+", "1", ")", ",", "tops", "[", "int", "(", "i", ")", "]", ")", "\n", "\n", "# avg of char embedding", "\n", "", "n", ".", "c_embed_1", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_1", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_2", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_2", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_3", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_3", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_4", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_4", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_5", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_5", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_6", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_6", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_7", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_7", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_8", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_8", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_9", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_9", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_10", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_10", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_11", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_11", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_12", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_12", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_13", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_13", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_14", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_14", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_15", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_15", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_16", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_16", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_17", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_17", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_18", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_18", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_19", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_19", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_20", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_20", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_21", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_21", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_22", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_22", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "\n", "concat_c_embed", "=", "[", "n", ".", "c_embed_1", ",", "n", ".", "c_embed_2", ",", "n", ".", "c_embed_3", ",", "n", ".", "c_embed_4", ",", "n", ".", "c_embed_5", ",", "n", ".", "c_embed_6", ",", "n", ".", "c_embed_7", ",", "n", ".", "c_embed_8", ",", "n", ".", "c_embed_9", ",", "n", ".", "c_embed_10", ",", "n", ".", "c_embed_11", ",", "n", ".", "c_embed_12", ",", "n", ".", "c_embed_13", ",", "n", ".", "c_embed_14", ",", "n", ".", "c_embed_15", ",", "n", ".", "c_embed_16", ",", "n", ".", "c_embed_17", ",", "n", ".", "c_embed_18", ",", "n", ".", "c_embed_19", ",", "n", ".", "c_embed_20", ",", "n", ".", "c_embed_21", ",", "n", ".", "c_embed_22", "]", "\n", "n", ".", "concat_char_embed", "=", "L", ".", "Concat", "(", "*", "concat_c_embed", ",", "concat_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T x d_c x 1", "\n", "n", ".", "concat_char_embed_resh", "=", "L", ".", "Reshape", "(", "n", ".", "concat_char_embed", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", "]", ")", ")", ")", "\n", "\n", "# word embedding", "\n", "n", ".", "embed_w", "=", "L", ".", "Embed", "(", "n", ".", "data", ",", "input_dim", "=", "question_vocab_size", ",", "num_output", "=", "200", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "# N x T x d_w", "\n", "\n", "# combine word and char embedding", "\n", "concat_word_embed", "=", "[", "n", ".", "embed_w", ",", "n", ".", "concat_char_embed_resh", "]", "\n", "n", ".", "concat_embed", "=", "L", ".", "Concat", "(", "*", "concat_word_embed", ",", "concat_param", "=", "{", "'axis'", ":", "2", "}", ")", "# N x T x (d_c+d_w)", "\n", "\n", "n", ".", "embed_scale", "=", "L", ".", "Scale", "(", "n", ".", "concat_embed", ",", "n", ".", "cont", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "# N x T x (d_c+d_w)", "\n", "n", ".", "embed_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T x (d_c+d_w) x 1", "\n", "\n", "# avg of word embedding", "\n", "n", ".", "embed_avg", "=", "L", ".", "Convolution", "(", "n", ".", "embed_scale_resh", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x (d_c+d_w) x 1", "\n", "n", ".", "embed_avg_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_avg", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "300", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled_1", "=", "L", ".", "Tile", "(", "n", ".", "embed_avg_resh", ",", "axis", "=", "2", ",", "tiles", "=", "14", ")", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled", "=", "L", ".", "Tile", "(", "n", ".", "q_emb_tanh_droped_resh_tiled_1", ",", "axis", "=", "3", ",", "tiles", "=", "14", ")", "\n", "n", ".", "i_emb_tanh_droped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "img_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "n", ".", "blcf", "=", "L", ".", "CompactBilinear", "(", "n", ".", "q_emb_tanh_droped_resh_tiled", ",", "n", ".", "i_emb_tanh_droped_resh", ",", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "blcf_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "blcf", ")", "\n", "n", ".", "blcf_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "blcf_sign_sqrt", ")", "\n", "n", ".", "blcf_droped", "=", "L", ".", "Dropout", "(", "n", ".", "blcf_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "\n", "# multi-channel attention", "\n", "n", ".", "att_conv1", "=", "L", ".", "Convolution", "(", "n", ".", "blcf_droped", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "512", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_conv1_relu", "=", "L", ".", "ReLU", "(", "n", ".", "att_conv1", ")", "\n", "n", ".", "att_conv2", "=", "L", ".", "Convolution", "(", "n", ".", "att_conv1_relu", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "2", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_reshaped", "=", "L", ".", "Reshape", "(", "n", ".", "att_conv2", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", "*", "14", "]", ")", ")", ")", "\n", "n", ".", "att_softmax", "=", "L", ".", "Softmax", "(", "n", ".", "att_reshaped", ",", "axis", "=", "2", ")", "\n", "n", ".", "att", "=", "L", ".", "Reshape", "(", "n", ".", "att_softmax", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "att_maps", "=", "L", ".", "Slice", "(", "n", ".", "att", ",", "ntop", "=", "2", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "\n", "n", ".", "att_map0", "=", "att_maps", "[", "0", "]", "\n", "n", ".", "att_map1", "=", "att_maps", "[", "1", "]", "\n", "dummy", "=", "L", ".", "DummyData", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "1", "]", ")", ",", "data_filler", "=", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", ",", "ntop", "=", "1", ")", "\n", "n", ".", "att_feature0", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map0", ",", "dummy", ")", "\n", "n", ".", "att_feature1", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map1", ",", "dummy", ")", "\n", "n", ".", "att_feature0_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature0", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature1_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature1", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature", "=", "L", ".", "Concat", "(", "n", ".", "att_feature0_resh", ",", "n", ".", "att_feature1_resh", ")", "\n", "\n", "# merge attention and lstm with compact bilinear pooling", "\n", "n", ".", "att_feature_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "4096", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "#n.lstm_12_resh = L.Reshape(n.lstm_12, reshape_param=dict(shape=dict(dim=[-1,2048,1,1])))", "\n", "n", ".", "bc_att_lstm", "=", "L", ".", "CompactBilinear", "(", "n", ".", "att_feature_resh", ",", "n", ".", "embed_avg_resh", ",", "\n", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "bc_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "bc_att_lstm", ")", "\n", "n", ".", "bc_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "bc_sign_sqrt", ")", "\n", "\n", "n", ".", "bc_dropped", "=", "L", ".", "Dropout", "(", "n", ".", "bc_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "n", ".", "bc_dropped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "bc_dropped", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "16000", "]", ")", ")", ")", "\n", "\n", "n", ".", "prediction", "=", "L", ".", "InnerProduct", "(", "n", ".", "bc_dropped_resh", ",", "num_output", "=", "3000", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "loss", "=", "L", ".", "SoftmaxWithLoss", "(", "n", ".", "prediction", ",", "n", ".", "label", ")", "\n", "return", "n", ".", "to_proto", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).train_att_bc.make_answer_vocab": [[118, 155], ["adic.keys", "sorted", "enumerate", "enumerate", "nadict.items", "nalist.append", "adict.has_key", "config.NUM_OUTPUT_UNITS"], "function", ["None"], ["", "def", "make_answer_vocab", "(", "adic", ",", "vocab_size", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "adict", "=", "{", "''", ":", "0", "}", "\n", "nadict", "=", "{", "''", ":", "1000000", "}", "\n", "vid", "=", "1", "\n", "for", "qid", "in", "adic", ".", "keys", "(", ")", ":", "\n", "        ", "answer_obj", "=", "adic", "[", "qid", "]", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "\n", "for", "q_ans", "in", "answer_list", ":", "\n", "# create dict", "\n", "            ", "if", "adict", ".", "has_key", "(", "q_ans", ")", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "=", "1", "\n", "adict", "[", "q_ans", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "\n", "# debug", "\n", "", "", "", "nalist", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "sorted", "(", "nadict", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ":", "\n", "        ", "nalist", ".", "append", "(", "(", "k", ",", "v", ")", ")", "\n", "\n", "# keep the top 3000 answers", "\n", "", "n_del_ans", "=", "0", "\n", "n_valid_ans", "=", "0", "\n", "adict_nid", "=", "{", "}", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", ":", "-", "vocab_size", "]", ")", ":", "\n", "        ", "del", "adict", "[", "w", "[", "0", "]", "]", "\n", "n_del_ans", "+=", "w", "[", "1", "]", "\n", "", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", "-", "vocab_size", ":", "]", ")", ":", "\n", "        ", "n_valid_ans", "+=", "w", "[", "1", "]", "\n", "adict_nid", "[", "w", "[", "0", "]", "]", "=", "i", "\n", "\n", "", "return", "adict_nid", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).train_att_bc.make_question_vocab": [[156, 180], ["qdic.keys", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "list", "vdict.has_key", "cdict.has_key"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list"], ["", "def", "make_question_vocab", "(", "qdic", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "vdict", "=", "{", "''", ":", "0", "}", "\n", "vid", "=", "1", "\n", "cdict", "=", "{", "''", ":", "0", "}", "\n", "cvid", "=", "1", "\n", "for", "qid", "in", "qdic", ".", "keys", "(", ")", ":", "\n", "# sequence to list", "\n", "        ", "q_str", "=", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "\n", "# create dict", "\n", "for", "w", "in", "q_list", ":", "\n", "            ", "if", "not", "vdict", ".", "has_key", "(", "w", ")", ":", "\n", "                ", "vdict", "[", "w", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "", "for", "c", "in", "list", "(", "w", ")", ":", "\n", "                ", "if", "not", "cdict", ".", "has_key", "(", "c", ")", ":", "\n", "                    ", "cdict", "[", "c", "]", "=", "cvid", "\n", "cvid", "+=", "1", "\n", "\n", "", "", "", "", "return", "vdict", ",", "cdict", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).train_att_bc.make_vocab_files": [[181, 193], ["write_to_log.write_log", "write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_question_vocab", "write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_answer_vocab"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_question_vocab", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_answer_vocab"], ["", "def", "make_vocab_files", "(", ")", ":", "\n", "    ", "\"\"\"\n    Produce the question and answer vocabulary files.\n    \"\"\"", "\n", "write_log", "(", "'making question vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "write_log", "(", "'making question character vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "qdic", ",", "_", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "QUESTION_VOCAB_SPACE", ")", "\n", "question_vocab", ",", "question_char_vocab", "=", "make_question_vocab", "(", "qdic", ")", "\n", "write_log", "(", "'making answer vocab... '", "+", "config", ".", "ANSWER_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "_", ",", "adic", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "ANSWER_VOCAB_SPACE", ")", "\n", "answer_vocab", "=", "make_answer_vocab", "(", "adic", ",", "config", ".", "NUM_OUTPUT_UNITS", ")", "\n", "return", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).train_att_bc.main": [[194, 260], ["write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "caffe.set_device", "caffe.set_mode_gpu", "caffe.get_solver", "numpy.zeros", "range", "os.path.exists", "os.makedirs", "os.path.exists", "os.path.exists", "os.path.exists", "write_to_log.write_log", "train_att_bc.make_vocab_files", "open", "f.write", "open", "f.write", "caffe.get_solver.step", "open", "json.load", "open", "json.load", "open", "json.load", "open", "json.dump", "open", "json.dump", "open", "json.dump", "str", "str", "str", "str", "str", "write_to_log.write_log", "write_to_log.write_log", "train_loss[].mean", "write_to_log.write_log", "caffe.get_solver.test_nets[].save", "write_to_log.write_log", "visualize_tools.exec_validation", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "len", "train_att_bc.qlstm", "train_att_bc.qlstm", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "len", "len", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_vocab_files", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.exec_validation", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["", "def", "main", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "'./result'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'./result'", ")", "\n", "\n", "", "question_vocab", ",", "answer_vocab", "=", "{", "}", ",", "{", "}", "\n", "if", "os", ".", "path", ".", "exists", "(", "'./result/cdict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/adict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/vdict.json'", ")", ":", "\n", "        ", "write_log", "(", "'restoring vocab'", ",", "'log.txt'", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_char_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "answer_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "=", "make_vocab_files", "(", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_char_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "answer_vocab", ",", "f", ")", "\n", "\n", "", "", "write_log", "(", "'question character vocab size: '", "+", "str", "(", "len", "(", "question_char_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'question vocab size: '", "+", "str", "(", "len", "(", "question_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'answer vocab size: '", "+", "str", "(", "len", "(", "answer_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "\n", "\n", "with", "open", "(", "'./result/proto_train.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "config", ".", "TRAIN_DATA_SPLITS", ",", "config", ".", "BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "with", "open", "(", "'./result/proto_test.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "'val'", ",", "config", ".", "VAL_BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "caffe", ".", "set_device", "(", "config", ".", "GPU_ID", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "solver", "=", "caffe", ".", "get_solver", "(", "'./qlstm_solver.prototxt'", ")", "\n", "\n", "train_loss", "=", "np", ".", "zeros", "(", "config", ".", "MAX_ITERATIONS", ")", "\n", "# results = []", "\n", "\n", "for", "it", "in", "range", "(", "config", ".", "MAX_ITERATIONS", ")", ":", "\n", "        ", "solver", ".", "step", "(", "1", ")", "\n", "\n", "# store the train loss", "\n", "train_loss", "[", "it", "]", "=", "solver", ".", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", "\n", "\n", "if", "it", "!=", "0", "and", "it", "%", "config", ".", "PRINT_INTERVAL", "==", "0", ":", "\n", "            ", "write_log", "(", "'------------------------------------'", ",", "'log.txt'", ")", "\n", "write_log", "(", "'Iteration: '", "+", "str", "(", "it", ")", ",", "'log.txt'", ")", "\n", "c_mean_loss", "=", "train_loss", "[", "it", "-", "config", ".", "PRINT_INTERVAL", ":", "it", "]", ".", "mean", "(", ")", "\n", "write_log", "(", "'Train loss: '", "+", "str", "(", "c_mean_loss", ")", ",", "'log.txt'", ")", "\n", "", "if", "it", "!=", "0", "and", "it", "%", "config", ".", "VALIDATE_INTERVAL", "==", "0", ":", "# acutually test", "\n", "            ", "solver", ".", "test_nets", "[", "0", "]", ".", "save", "(", "'./result/tmp.caffemodel'", ")", "\n", "write_log", "(", "'Validating...'", ",", "'log.txt'", ")", "\n", "test_loss", ",", "acc_overall", ",", "acc_per_ques", ",", "acc_per_ans", "=", "exec_validation", "(", "config", ".", "GPU_ID", ",", "'val'", ",", "it", "=", "it", ")", "\n", "write_log", "(", "'Iteration: '", "+", "str", "(", "it", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'Test loss: '", "+", "str", "(", "test_loss", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'Overall Accuracy: '", "+", "str", "(", "acc_overall", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'Per Question Type Accuracy is the following:'", ",", "'log.txt'", ")", "\n", "for", "quesType", "in", "acc_per_ques", ":", "\n", "                ", "write_log", "(", "\"%s : %.02f\"", "%", "(", "quesType", ",", "acc_per_ques", "[", "quesType", "]", ")", ",", "'log.txt'", ")", "\n", "", "write_log", "(", "'Per Answer Type Accuracy is the following:'", ",", "'log.txt'", ")", "\n", "for", "ansType", "in", "acc_per_ans", ":", "\n", "                ", "write_log", "(", "\"%s : %.02f\"", "%", "(", "ansType", ",", "acc_per_ans", "[", "ansType", "]", ")", ",", "'log.txt'", ")", "\n", "# results.append([it, c_mean_loss, test_loss, acc_overall, acc_per_ques, acc_per_ans])", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).visualize_tools.visualize_failures": [[27, 119], ["write_to_log.write_log", "visualize_tools.visualize_failures.save_qtype"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["def", "visualize_failures", "(", "stat_list", ",", "mode", ")", ":", "\n", "\n", "    ", "def", "save_qtype", "(", "qtype_list", ",", "save_filename", ",", "mode", ")", ":", "\n", "\n", "        ", "if", "mode", "==", "'val'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./eval'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/val2014'", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test-dev'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "elif", "mode", "==", "'test'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unsupported mode'", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "shutil", ".", "rmtree", "(", "savepath", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "os", ".", "makedirs", "(", "savepath", ")", "\n", "\n", "for", "qt", "in", "qtype_list", ":", "\n", "            ", "count", "=", "0", "\n", "for", "t_question", "in", "stat_list", ":", "\n", "#print count, t_question", "\n", "                ", "if", "count", "<", "40", "/", "len", "(", "qtype_list", ")", ":", "\n", "                    ", "t_question_list", "=", "t_question", "[", "'q_list'", "]", "\n", "saveflag", "=", "False", "\n", "#print 'debug****************************'", "\n", "#print qt", "\n", "#print t_question_list", "\n", "#print t_question_list[0] == qt[0]", "\n", "#print t_question_list[1] == qt[1]", "\n", "if", "t_question_list", "[", "0", "]", "==", "qt", "[", "0", "]", "and", "t_question_list", "[", "1", "]", "==", "qt", "[", "1", "]", ":", "\n", "                        ", "saveflag", "=", "True", "\n", "", "else", ":", "\n", "                        ", "saveflag", "=", "False", "\n", "\n", "", "if", "saveflag", "==", "True", ":", "\n", "                        ", "t_iid", "=", "t_question", "[", "'iid'", "]", "\n", "if", "mode", "==", "'val'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_val2014_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "", "elif", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_test2015_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "\n", "# for caption", "\n", "#print t_iid", "\n", "#annIds = caps.getAnnIds(t_iid)", "\n", "#anns = caps.loadAnns(annIds)", "\n", "#cap_list = [ann['caption'] for ann in anns]", "\n", "", "ans_list", "=", "t_question", "[", "'ans_list'", "]", "\n", "draw", "=", "ImageDraw", ".", "Draw", "(", "t_img", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ans_list", ")", ")", ":", "\n", "                            ", "try", ":", "\n", "                                ", "draw", ".", "text", "(", "(", "10", ",", "10", "*", "i", ")", ",", "str", "(", "ans_list", "[", "i", "]", ")", ")", "\n", "", "except", ":", "\n", "                                ", "pass", "\n", "\n", "", "", "ans", "=", "t_question", "[", "'answer'", "]", "\n", "pred", "=", "t_question", "[", "'pred'", "]", "\n", "if", "ans", "==", "-", "1", ":", "\n", "                            ", "pre", "=", "''", "\n", "", "elif", "ans", "==", "pred", ":", "\n", "                            ", "pre", "=", "'correct  '", "\n", "", "else", ":", "\n", "                            ", "pre", "=", "'failure  '", "\n", "#print ' aaa ', ans, pred", "\n", "", "ans", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "ans", ")", ")", "\n", "pred", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "pred", ")", ")", "\n", "img_title", "=", "pre", "+", "str", "(", "' '", ".", "join", "(", "t_question_list", ")", ")", "+", "'.  a_'", "+", "str", "(", "ans", ")", "+", "' p_'", "+", "str", "(", "pred", ")", "+", "'.png'", "\n", "count", "+=", "1", "\n", "write_log", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ",", "'visualize_log.txt'", ")", "\n", "t_img", ".", "save", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ")", "\n", "\n", "", "", "", "", "", "write_log", "(", "'saving colors'", ",", "'visualize_log.txt'", ")", "\n", "qt_color_list", "=", "[", "[", "'what'", ",", "'color'", "]", "]", "\n", "save_qtype", "(", "qt_color_list", ",", "'colors'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving what is'", ",", "'visualize_log.txt'", ")", "\n", "qt_whatis_list", "=", "[", "[", "'what'", ",", "'is'", "]", ",", "[", "'what'", ",", "'kind'", "]", ",", "[", "'what'", ",", "'are'", "]", "]", "\n", "save_qtype", "(", "qt_whatis_list", ",", "'whatis'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving is'", ",", "'visualize_log.txt'", ")", "\n", "qt_is_list", "=", "[", "[", "'is'", ",", "'the'", "]", ",", "[", "'is'", ",", "'this'", "]", ",", "[", "'is'", ",", "'there'", "]", "]", "\n", "save_qtype", "(", "qt_is_list", ",", "'is'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving how many'", ",", "'visualize_log.txt'", ")", "\n", "qt_howmany_list", "=", "[", "[", "'how'", ",", "'many'", "]", "]", "\n", "save_qtype", "(", "qt_howmany_list", ",", "'howmany'", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).visualize_tools.exec_validation": [[120, 202], ["caffe.set_device", "caffe.set_mode_gpu", "caffe.Net", "vqa_data_provider_layer.VQADataProvider", "len", "numpy.array().mean", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "vqa_data_provider_layer.VQADataProvider.get_batch_vec", "caffe.Net.forward", "caffe.Net.blobs[].data.argmax", "testloss_list.append", "zip", "vqaTools.vqa.VQA", "vqaTools.vqa.VQA.loadRes", "vqaEvaluation.vqaEval.VQAEval", "vqaEvaluation.vqaEval.VQAEval.evaluate", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "t_answer.tolist", "pred_list.append", "numpy.array", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "stat_list.append", "open", "json.dump", "visualize_tools.visualize_failures", "int", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "str().zfill", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "str().zfill", "xrange", "str", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.forward", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj"], ["", "def", "exec_validation", "(", "device_id", ",", "mode", ",", "it", "=", "''", ",", "visualize", "=", "False", ")", ":", "\n", "\n", "    ", "caffe", ".", "set_device", "(", "device_id", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "net", "=", "caffe", ".", "Net", "(", "'./result/proto_test.prototxt'", ",", "'./result/tmp.caffemodel'", ",", "caffe", ".", "TEST", ")", "\n", "\n", "dp", "=", "VQADataProvider", "(", "mode", "=", "mode", ",", "batchsize", "=", "config", ".", "VAL_BATCH_SIZE", ")", "\n", "total_questions", "=", "len", "(", "dp", ".", "getQuesIds", "(", ")", ")", "\n", "epoch", "=", "0", "\n", "\n", "pred_list", "=", "[", "]", "\n", "testloss_list", "=", "[", "]", "\n", "stat_list", "=", "[", "]", "\n", "\n", "while", "epoch", "==", "0", ":", "\n", "        ", "t_word", ",", "t_cont", ",", "t_word_c", ",", "t_cont_c", ",", "t_img_feature", ",", "t_answer", ",", "t_qid_list", ",", "t_iid_list", ",", "epoch", "=", "dp", ".", "get_batch_vec", "(", ")", "\n", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "...", "]", "=", "t_word", "# np.transpose(t_word,(1,0))", "\n", "net", ".", "blobs", "[", "'cont'", "]", ".", "data", "[", "...", "]", "=", "t_cont", "# np.transpose(t_cont,(1,0))", "\n", "net", ".", "blobs", "[", "'data1'", "]", ".", "data", "[", "...", "]", "=", "t_word_c", "\n", "net", ".", "blobs", "[", "'cont1'", "]", ".", "data", "[", "...", "]", "=", "t_cont_c", "\n", "net", ".", "blobs", "[", "'img_feature'", "]", ".", "data", "[", "...", "]", "=", "t_img_feature", "\n", "net", ".", "blobs", "[", "'label'", "]", ".", "data", "[", "...", "]", "=", "t_answer", "\n", "#net.blobs['glove'].data[...] = t_glove_matrix # np.transpose(t_glove_matrix, (1,0,2))", "\n", "net", ".", "forward", "(", ")", "\n", "t_pred_list", "=", "net", ".", "blobs", "[", "'prediction'", "]", ".", "data", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "t_pred_str", "=", "[", "dp", ".", "vec_to_answer", "(", "pred_symbol", ")", "for", "pred_symbol", "in", "t_pred_list", "]", "\n", "testloss_list", ".", "append", "(", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", ")", "\n", "for", "qid", ",", "iid", ",", "ans", ",", "pred", "in", "zip", "(", "t_qid_list", ",", "t_iid_list", ",", "t_answer", ".", "tolist", "(", ")", ",", "t_pred_str", ")", ":", "\n", "            ", "pred_list", ".", "append", "(", "{", "u'answer'", ":", "pred", ",", "u'question_id'", ":", "int", "(", "dp", ".", "getStrippedQuesId", "(", "qid", ")", ")", "}", ")", "\n", "if", "visualize", ":", "\n", "                ", "q_list", "=", "dp", ".", "seq_to_list", "(", "dp", ".", "getQuesStr", "(", "qid", ")", ")", "\n", "if", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                    ", "ans_str", "=", "''", "\n", "ans_list", "=", "[", "''", "]", "*", "10", "\n", "", "else", ":", "\n", "                    ", "ans_str", "=", "dp", ".", "vec_to_answer", "(", "ans", ")", "\n", "ans_list", "=", "[", "dp", ".", "getAnsObj", "(", "qid", ")", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "", "stat_list", ".", "append", "(", "{", "'qid'", ":", "qid", ",", "\n", "'q_list'", ":", "q_list", ",", "\n", "'iid'", ":", "iid", ",", "\n", "'answer'", ":", "ans_str", ",", "\n", "'ans_list'", ":", "ans_list", ",", "\n", "'pred'", ":", "pred", "}", ")", "\n", "#percent = 100 * float(len(pred_list)) / total_questions", "\n", "#sys.stdout.write('\\r' + ('%.2f' % percent) + '%')", "\n", "#sys.stdout.flush()", "\n", "\n", "\n", "\n", "", "", "", "mean_testloss", "=", "np", ".", "array", "(", "testloss_list", ")", ".", "mean", "(", ")", "\n", "\n", "if", "mode", "==", "'val'", ":", "\n", "        ", "valFile", "=", "'./result/val2014_resfile'", "\n", "with", "open", "(", "valFile", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "annFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ans_file'", "]", "\n", "quesFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ques_file'", "]", "\n", "vqa", "=", "VQA", "(", "annFile", ",", "quesFile", ")", "\n", "vqaRes", "=", "vqa", ".", "loadRes", "(", "valFile", ",", "quesFile", ")", "\n", "vqaEval", "=", "VQAEval", "(", "vqa", ",", "vqaRes", ",", "n", "=", "2", ")", "\n", "vqaEval", ".", "evaluate", "(", ")", "\n", "acc_overall", "=", "vqaEval", ".", "accuracy", "[", "'overall'", "]", "\n", "acc_perQuestionType", "=", "vqaEval", ".", "accuracy", "[", "'perQuestionType'", "]", "\n", "acc_perAnswerType", "=", "vqaEval", ".", "accuracy", "[", "'perAnswerType'", "]", "\n", "return", "mean_testloss", ",", "acc_overall", ",", "acc_perQuestionType", ",", "acc_perAnswerType", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test-dev2015_v3t'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "", "elif", "mode", "==", "'test'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test2015_v3c'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (char+word).visualize_tools.drawgraph": [[203, 271], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.twinx", "fig.add_subplot.plot", "fig.add_subplot.plot", "ax1.twinx.plot", "matplotlib.legend", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "ax1.twinx.set_ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "numpy.array", "numpy.array", "matplotlib.figure", "matplotlib.legend", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "sorted", "visualize_tools.drawgraph.draw_qt_acc"], "function", ["None"], ["", "", "", "def", "drawgraph", "(", "results", ",", "save_question_type_graphs", "=", "False", ")", ":", "\n", "# 0:it", "\n", "# 1:trainloss", "\n", "# 2:testloss", "\n", "# 3:oa_acc", "\n", "# 4:qt_acc", "\n", "# 5:at_acc", "\n", "\n", "# training curve", "\n", "    ", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "loss", "=", "np", ".", "array", "(", "[", "l", "[", "1", "]", "for", "l", "in", "results", "]", ")", "\n", "valloss", "=", "np", ".", "array", "(", "[", "l", "[", "2", "]", "for", "l", "in", "results", "]", ")", "\n", "valacc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax1", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "ax2", "=", "ax1", ".", "twinx", "(", ")", "\n", "\n", "ax1", ".", "plot", "(", "it", ",", "loss", ",", "color", "=", "'blue'", ",", "label", "=", "'train loss'", ")", "\n", "ax1", ".", "plot", "(", "it", ",", "valloss", ",", "'--'", ",", "color", "=", "'blue'", ",", "label", "=", "'test loss'", ")", "\n", "ax2", ".", "plot", "(", "it", ",", "valacc", ",", "color", "=", "'red'", ",", "label", "=", "'acc on val'", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'lower left'", ")", "\n", "\n", "ax1", ".", "set_xlabel", "(", "'Iterations'", ")", "\n", "ax1", ".", "set_ylabel", "(", "'Loss Value'", ")", "\n", "ax2", ".", "set_ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "'./learning_curve max_%2.2f.png'", "%", "valacc", ".", "max", "(", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "# question type", "\n", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "oa_acc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "qt_dic_list", "=", "[", "l", "[", "4", "]", "for", "l", "in", "results", "]", "\n", "\n", "def", "draw_qt_acc", "(", "target_key_list", ",", "figname", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "for", "k", "in", "target_key_list", ":", "\n", "            ", "write_log", "(", "str", "(", "k", ")", "+", "str", "(", "type", "(", "k", ")", ")", ",", "'visualize_log.txt'", ")", "\n", "t_val", "=", "np", ".", "array", "(", "[", "qt_dic", "[", "k", "]", "for", "qt_dic", "in", "qt_dic_list", "]", ")", "\n", "plt", ".", "plot", "(", "it", ",", "t_val", ",", "label", "=", "str", "(", "k", ")", ")", "\n", "", "plt", ".", "legend", "(", "fontsize", "=", "'small'", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "100.", ")", "\n", "#plt.legend(prop={'size':6})", "\n", "\n", "plt", ".", "xlabel", "(", "'Iterations'", ")", "\n", "plt", ".", "ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "figname", ",", "dpi", "=", "200", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "", "if", "save_question_type_graphs", ":", "\n", "        ", "s_keys", "=", "sorted", "(", "qt_dic_list", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "0", ":", "13", "]", "+", "[", "s_keys", "[", "31", "]", ",", "]", ",", "'./ind_qt_are.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "13", ":", "17", "]", "+", "s_keys", "[", "49", ":", "]", ",", "'./ind_qt_how_where_who_why.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "17", ":", "31", "]", "+", "[", "s_keys", "[", "32", "]", ",", "]", ",", "'./ind_qt_is.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "33", ":", "49", "]", ",", "'./ind_qt_what.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what color is the'", ",", "'what color are the'", ",", "'what color is'", ",", "'what color'", ",", "'what is the color of the'", "]", ",", "'./qt_color.png'", ")", "\n", "draw_qt_acc", "(", "[", "'how many'", ",", "'how'", ",", "'how many people are'", ",", "'how many people are in'", "]", ",", "'./qt_number.png'", ")", "\n", "draw_qt_acc", "(", "[", "'who is'", ",", "'why'", ",", "'why is the'", ",", "'where is the'", ",", "'where are the'", ",", "'which'", "]", ",", "'./qt_who_why_where_which.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what is the man'", ",", "'is the man'", ",", "'are they'", ",", "'is he'", ",", "'is the woman'", ",", "'is this person'", ",", "'what is the woman'", ",", "'is the person'", ",", "'what is the person'", "]", ",", "'./qt_human.png'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).write_to_log.write_log": [[1, 4], ["open", "f.write"], "function", ["None"], ["def", "write_log", "(", "str", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "+", "\"\\n\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.__init__": [[13, 30], ["vqa_data_provider_layer.VQADataProvider.load_data", "len", "open", "json.load", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data"], ["    ", "def", "__init__", "(", "self", ",", "batchsize", "=", "64", ",", "max_length", "=", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "max_w_length", "=", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "batchsize", "\n", "self", ".", "d_vocabulary", "=", "None", "\n", "self", ".", "batch_index", "=", "None", "\n", "self", ".", "batch_len", "=", "None", "\n", "self", ".", "rev_adict", "=", "None", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "max_w_length", "=", "max_w_length", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "qdic", ",", "self", ".", "adic", "=", "VQADataProvider", ".", "load_data", "(", "mode", ")", "\n", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "cdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "vdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "adict", "=", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.load_vqa_json": [[33, 56], ["write_to_log.write_log", "open", "json.load", "open", "json.load", "str", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["#self.glove_dict = {} # word -> glove vector", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_vqa_json", "(", "data_split", ")", ":", "\n", "        ", "\"\"\"\n        Parses the question and answer json files for the given data split. \n        Returns the question dictionary and the answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ques_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "[", "'questions'", "]", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "qdic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'question_id'", "]", ")", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image_id'", "]", "}", "\n", "\n", "", "", "if", "'test'", "not", "in", "data_split", ":", "\n", "            ", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ans_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "adata", "=", "json", ".", "load", "(", "f", ")", "[", "'annotations'", "]", "\n", "for", "a", "in", "adata", ":", "\n", "                    ", "adic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "a", "[", "'question_id'", "]", ")", "]", "=", "a", "[", "'answers'", "]", "\n", "\n", "", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for '", "+", "data_split", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.load_genome_json": [[57, 74], ["write_to_log.write_log", "open", "json.load", "str", "str", "len"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_genome_json", "(", ")", ":", "\n", "        ", "\"\"\"\n        Parses the genome json file. Returns the question dictionary and the\n        answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'genome_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "key", "=", "'genome'", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'id'", "]", ")", "\n", "qdic", "[", "key", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image'", "]", "}", "\n", "adic", "[", "key", "]", "=", "[", "{", "'answer'", ":", "q", "[", "'answer'", "]", "}", "]", "\n", "\n", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for genome'", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.load_data": [[75, 101], ["data_split_str.split", "config.DATA_PATHS.keys", "vqa_data_provider_layer.VQADataProvider.load_genome_json", "all_qdic.update", "all_adic.update", "vqa_data_provider_layer.VQADataProvider.load_vqa_json", "all_qdic.update", "all_adic.update"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_genome_json", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_vqa_json"], ["return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_data", "(", "data_split_str", ")", ":", "\n", "        ", "all_qdic", ",", "all_adic", "=", "{", "}", ",", "{", "}", "\n", "for", "data_split", "in", "data_split_str", ".", "split", "(", "'+'", ")", ":", "\n", "            ", "assert", "data_split", "in", "config", ".", "DATA_PATHS", ".", "keys", "(", ")", ",", "'unknown data split'", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_genome_json", "(", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "", "else", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_vqa_json", "(", "data_split", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "\n", "", "", "return", "all_qdic", ",", "all_adic", "\n", "\n", "", "def", "getQuesIds", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "qdic", ".", "keys", "(", ")", "\n", "\n", "", "def", "getStrippedQuesId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "[", "1", "]", "\n", "\n", "", "def", "getImgId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'iid'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.getQuesIds": [[102, 104], ["vqa_data_provider_layer.VQADataProvider.qdic.keys"], "methods", ["None"], ["", "def", "getQuesStr", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId": [[105, 107], ["qid.split"], "methods", ["None"], ["", "def", "getAnsObj", "(", "self", ",", "qid", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.getImgId": [[108, 110], ["None"], "methods", ["None"], ["", "return", "self", ".", "adic", "[", "qid", "]", "\n", "\n", "", "@", "staticmethod", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.getQuesStr": [[111, 113], ["None"], "methods", ["None"], ["def", "seq_to_list", "(", "s", ")", ":", "\n", "        ", "t_str", "=", "s", ".", "lower", "(", ")", "\n", "for", "i", "in", "[", "r'\\?'", ",", "r'\\!'", ",", "r'\\''", ",", "r'\\\"'", ",", "r'\\$'", ",", "r'\\:'", ",", "r'\\@'", ",", "r'\\('", ",", "r'\\)'", ",", "r'\\,'", ",", "r'\\.'", ",", "r'\\;'", "]", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.getAnsObj": [[114, 118], ["None"], "methods", ["None"], ["            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "''", ",", "t_str", ")", "\n", "", "for", "i", "in", "[", "r'\\-'", ",", "r'\\/'", "]", ":", "\n", "            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "' '", ",", "t_str", ")", "\n", "", "q_list", "=", "re", ".", "sub", "(", "r'\\?'", ",", "''", ",", "t_str", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "\n", "q_list", "=", "filter", "(", "lambda", "x", ":", "len", "(", "x", ")", ">", "0", ",", "q_list", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.seq_to_list": [[119, 129], ["s.lower", "re.sub().split", "filter", "re.sub", "re.sub", "re.sub", "re.sub.lower", "len"], "methods", ["None"], ["return", "q_list", "\n", "\n", "", "def", "extract_answer", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "", "answer_list", "=", "[", "answer_obj", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "dic", "=", "{", "}", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "dic", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "dic", "[", "ans", "]", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.extract_answer": [[130, 143], ["dic.has_key", "max", "xrange", "dic.items"], "methods", ["None"], ["", "else", ":", "\n", "                ", "dic", "[", "ans", "]", "=", "1", "\n", "", "", "max_key", "=", "max", "(", "(", "v", ",", "k", ")", "for", "(", "k", ",", "v", ")", "in", "dic", ".", "items", "(", ")", ")", "[", "1", "]", "\n", "return", "max_key", "\n", "\n", "", "def", "extract_answer_prob", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "prob_answer_list", "=", "[", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.extract_answer_prob": [[144, 162], ["vqa_data_provider_layer.VQADataProvider.adict.has_key", "len", "random.choice", "prob_answer_list.append", "Exception"], "methods", ["None"], ["                ", "prob_answer_list", ".", "append", "(", "ans", ")", "\n", "\n", "", "", "if", "len", "(", "prob_answer_list", ")", "==", "0", ":", "\n", "            ", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "return", "'hoge'", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"This should not happen.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "random", ".", "choice", "(", "prob_answer_list", ")", "\n", "\n", "# def qlist_to_vec(self, max_length, q_list):", "\n", "#     \"\"\"", "\n", "#     Converts a list of words into a format suitable for the embedding layer.", "\n", "\n", "#     Arguments:", "\n", "#     max_length -- the maximum length of a question sequence", "\n", "#     q_list -- a list of words which are the tokens in the question", "\n", "\n", "#     Returns:", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.qlist_to_vec": [[163, 195], ["numpy.zeros", "numpy.zeros", "xrange", "len", "vqa_data_provider_layer.VQADataProvider.vdict.has_key", "len", "len"], "methods", ["None"], ["#     qvec -- A max_length length vector containing one-hot indices for each word", "\n", "#     cvec -- A max_length length sequence continuation indicator vector", "\n", "#     glove_matrix -- A max_length x GLOVE_EMBEDDING_SIZE matrix containing the glove embedding for", "\n", "#         each word", "\n", "#     \"\"\"", "\n", "#     qvec = np.zeros(max_length)", "\n", "#     cvec = np.zeros(max_length)", "\n", "#     glove_matrix = np.zeros(max_length * GLOVE_EMBEDDING_SIZE).reshape(max_length, GLOVE_EMBEDDING_SIZE)", "\n", "#     for i in xrange(max_length):", "\n", "#         if i < max_length - len(q_list):", "\n", "#             cvec[i] = 0", "\n", "#         else:", "\n", "#             w = q_list[i-(max_length-len(q_list))]", "\n", "#             if w not in self.glove_dict:", "\n", "#                 self.glove_dict[w] = self.nlp(u'%s' % w).vector", "\n", "#             glove_matrix[i] = self.glove_dict[w]", "\n", "#             # is the word in the vocabulary?", "\n", "#             if self.vdict.has_key(w) is False:", "\n", "#                 w = ''", "\n", "#             qvec[i] = self.vdict[w]", "\n", "#             cvec[i] = 1 #0 if i == max_length - len(q_list) else 1", "\n", "#             # UPDATE_10/12:", "\n", "#             #It seems that the original way is right for lstm.", "\n", "#             '''", "\n", "#             This is from https://github.com/BVLC/caffe/pull/1873.", "\n", "#             \"delta_{t,n} should be a binary indicator (i.e., value in {0, 1}),", "\n", "#             where a value of 0 means that timestep t of stream n is the beginning of a new sequence,", "\n", "#             and a value of 1 means that timestep t of stream n is continuing the sequence from timestep t-1 of stream n.", "\n", "#             Under the hood, the previous timestep's hidden state is multiplied by these delta values.", "\n", "#             The fact that these indicators are specified on a per-timestep and per-stream basis allows for streams of arbitrary different lengths without any padding or truncation.", "\n", "#             At the beginning of the forward pass, the final hidden state from the previous forward pass (h_T) is copied into the initial hidden state for the new forward pass (h_0),", "\n", "#             allowing for exact inference across arbitrarily long sequences, even if T == 1.", "\n", "#             However, if any sequences cross batch boundaries, backpropagation through time is approximate -- it is truncated along the batch boundaries.\"", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.answer_to_vec": [[196, 206], ["vqa_data_provider_layer.VQADataProvider.adict.has_key"], "methods", ["None"], ["#             '''", "\n", "#             # I think the original way is false for CNN here. I want to keep the word embedding for unknown word as zero vector.", "\n", "#             # For example, if we have a sentence of length 7, there would be only 6 1's in cvec.", "\n", "\n", "#     return qvec, cvec, glove_matrix", "\n", "\n", "", "", "def", "qlist_to_vec", "(", "self", ",", "max_length", ",", "max_w_length", ",", "q_list", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.vec_to_answer": [[207, 216], ["vqa_data_provider_layer.VQADataProvider.adict.items"], "methods", ["None"], ["\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.create_batch": [[217, 263], ["numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "enumerate", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "vqa_data_provider_layer.VQADataProvider.answer_to_vec", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "qid.split", "vqa_data_provider_layer.VQADataProvider.extract_answer", "vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "numpy.sqrt", "write_to_log.write_log", "numpy.load", "numpy.load", "str", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.answer_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["qvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "cvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "qcvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "ccvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "for", "i", "in", "xrange", "(", "max_length", ")", ":", "\n", "            ", "if", "i", "<", "max_length", "-", "len", "(", "q_list", ")", ":", "\n", "                ", "cvec", "[", "i", "]", "=", "0", "\n", "", "else", ":", "\n", "                ", "w", "=", "q_list", "[", "i", "-", "(", "max_length", "-", "len", "(", "q_list", ")", ")", "]", "\n", "# is the word in the vocabulary?", "\n", "if", "self", ".", "vdict", ".", "has_key", "(", "w", ")", "is", "False", ":", "\n", "                    ", "w", "=", "''", "\n", "", "qvec", "[", "i", "]", "=", "self", ".", "vdict", "[", "w", "]", "\n", "cvec", "[", "i", "]", "=", "1.0", "/", "len", "(", "q_list", ")", "\n", "j", "=", "max_w_length", "*", "i", "\n", "w_list", "=", "list", "(", "w", ")", "\n", "for", "k", "in", "xrange", "(", "max_w_length", ")", ":", "\n", "                    ", "if", "k", "<", "max_w_length", "-", "len", "(", "w_list", ")", ":", "\n", "                        ", "ccvec", "[", "j", "+", "k", "]", "=", "0", "\n", "", "else", ":", "\n", "                        ", "c", "=", "w_list", "[", "k", "-", "(", "max_w_length", "-", "len", "(", "w_list", ")", ")", "]", "\n", "# is the char in the vocabulary?", "\n", "if", "self", ".", "cdict", ".", "has_key", "(", "c", ")", "is", "False", ":", "\n", "                            ", "c", "=", "''", "\n", "", "qcvec", "[", "j", "+", "k", "]", "=", "self", ".", "cdict", "[", "c", "]", "\n", "ccvec", "[", "j", "+", "k", "]", "=", "1.0", "/", "len", "(", "w_list", ")", "\n", "", "", "", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", "\n", "\n", "", "def", "answer_to_vec", "(", "self", ",", "ans_str", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "if", "self", ".", "adict", ".", "has_key", "(", "ans_str", ")", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "ans_str", "]", "\n", "", "else", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "''", "]", "\n", "", "return", "ans", "\n", "\n", "", "def", "vec_to_answer", "(", "self", ",", "ans_symbol", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "rev_adict", "is", "None", ":", "\n", "            ", "rev_adict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "adict", ".", "items", "(", ")", ":", "\n", "                ", "rev_adict", "[", "v", "]", "=", "k", "\n", "", "self", ".", "rev_adict", "=", "rev_adict", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProvider.get_batch_vec": [[265, 312], ["vqa_data_provider_layer.VQADataProvider.create_batch", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "random.shuffle", "len", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.adict.has_key", "t_qid_list.append", "t_iid_list.append", "vqa_data_provider_layer.VQADataProvider.get_batch_vec.has_at_least_one_valid_answer"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.create_batch", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId"], ["\n", "", "def", "create_batch", "(", "self", ",", "qid_list", ")", ":", "\n", "\n", "        ", "qvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "cvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "qcvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ccvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ivec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "2048", "*", "14", "*", "14", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "2048", ",", "14", ",", "14", ")", "\n", "avec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ")", "\n", "#glove_matrix = np.zeros(self.batchsize * self.max_length * GLOVE_EMBEDDING_SIZE).reshape(\\", "\n", "#self.batchsize, self.max_length, GLOVE_EMBEDDING_SIZE)", "\n", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "\n", "# load raw question information", "\n", "            ", "q_str", "=", "self", ".", "getQuesStr", "(", "qid", ")", "\n", "q_ans", "=", "self", ".", "getAnsObj", "(", "qid", ")", "\n", "q_iid", "=", "self", ".", "getImgId", "(", "qid", ")", "\n", "\n", "# convert question to vec", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "t_qvec", ",", "t_cvec", ",", "t_qcvec", ",", "t_ccvec", "=", "self", ".", "qlist_to_vec", "(", "self", ".", "max_length", ",", "self", ".", "max_w_length", ",", "q_list", ")", "\n", "\n", "try", ":", "\n", "                ", "qid_split", "=", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "\n", "data_split", "=", "qid_split", "[", "0", "]", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "else", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "t_ivec", "=", "(", "t_ivec", "/", "np", ".", "sqrt", "(", "(", "t_ivec", "**", "2", ")", ".", "sum", "(", ")", ")", ")", "\n", "", "except", ":", "\n", "                ", "t_ivec", "=", "0.", "\n", "write_log", "(", "'data not found for qid : '", "+", "str", "(", "q_iid", ")", "+", "' '", "+", "self", ".", "mode", ",", "'log.txt'", ")", "\n", "\n", "# convert answer to vec", "\n", "", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer", "(", "q_ans", ")", "\n", "", "else", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer_prob", "(", "q_ans", ")", "\n", "", "t_avec", "=", "self", ".", "answer_to_vec", "(", "q_ans_str", ")", "\n", "\n", "qvec", "[", "i", ",", "...", "]", "=", "t_qvec", "\n", "cvec", "[", "i", ",", "...", "]", "=", "t_cvec", "\n", "qcvec", "[", "i", ",", "...", "]", "=", "t_qcvec", "\n", "ccvec", "[", "i", ",", "...", "]", "=", "t_ccvec", "\n", "ivec", "[", "i", ",", "...", "]", "=", "t_ivec", "\n", "avec", "[", "i", ",", "...", "]", "=", "t_avec", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProviderLayer.setup": [[319, 333], ["top[].reshape", "top[].reshape", "top[].reshape", "top[].reshape", "json.loads", "json.loads", "vqa_data_provider_layer.VQADataProvider"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape"], ["        ", "if", "self", ".", "batch_len", "is", "None", ":", "\n", "            ", "self", ".", "n_skipped", "=", "0", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_len", "=", "len", "(", "qid_list", ")", "\n", "self", ".", "batch_index", "=", "0", "\n", "self", ".", "epoch_counter", "=", "0", "\n", "\n", "", "def", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "            ", "answer_obj", "=", "self", ".", "getAnsObj", "(", "t_qid", ")", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "                ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n", "                    ", "return", "True", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProviderLayer.reshape": [[334, 336], ["None"], "methods", ["None"], ["\n", "", "", "", "counter", "=", "0", "\n", "t_qid_list", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProviderLayer.forward": [[337, 346], ["vqa_data_provider_layer.VQADataProviderLayer.dp.get_batch_vec"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec"], ["t_iid_list", "=", "[", "]", "\n", "while", "counter", "<", "self", ".", "batchsize", ":", "\n", "            ", "t_qid", "=", "self", ".", "qid_list", "[", "self", ".", "batch_index", "]", "\n", "t_iid", "=", "self", ".", "getImgId", "(", "t_qid", ")", "\n", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n", "", "elif", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).vqa_data_provider_layer.VQADataProviderLayer.backward": [[348, 350], ["None"], "methods", ["None"], ["counter", "+=", "1", "\n", "", "else", ":", "\n", "                ", "self", ".", "n_skipped", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).train_att_bc.qlstm": [[19, 74], ["caffe.NetSpec", "json.dumps", "caffe.layers.Python", "caffe.layers.Embed", "caffe.layers.Scale", "caffe.layers.Reshape", "caffe.layers.Convolution", "caffe.layers.Reshape", "caffe.layers.Tile", "caffe.layers.Tile", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.Reshape", "caffe.layers.Softmax", "caffe.layers.Reshape", "caffe.layers.Slice", "caffe.layers.DummyData", "caffe.layers.SoftAttention", "caffe.layers.SoftAttention", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Concat", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Reshape", "caffe.layers.InnerProduct", "caffe.layers.SoftmaxWithLoss", "caffe.NetSpec.to_proto", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "config.TRAIN_DATA_SPLITS", "config.BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION", "config.EMBEDDING_SIZE", "config.VAL_BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION", "config.EMBEDDING_SIZE"], "function", ["None"], ["def", "qlstm", "(", "mode", ",", "batchsize", ",", "T", ",", "T_c", ",", "question_c_vocab_size", ",", "question_vocab_size", ")", ":", "\n", "    ", "n", "=", "caffe", ".", "NetSpec", "(", ")", "\n", "mode_str", "=", "json", ".", "dumps", "(", "{", "'mode'", ":", "mode", ",", "'batchsize'", ":", "batchsize", "}", ")", "\n", "n", ".", "data", ",", "n", ".", "cont", ",", "n", ".", "data1", ",", "n", ".", "cont1", ",", "n", ".", "img_feature", ",", "n", ".", "label", "=", "L", ".", "Python", "(", "module", "=", "'vqa_data_provider_layer'", ",", "layer", "=", "'VQADataProviderLayer'", ",", "param_str", "=", "mode_str", ",", "ntop", "=", "6", ")", "#5 )", "\n", "\n", "# char embedding", "\n", "n", ".", "embed_c", "=", "L", ".", "Embed", "(", "n", ".", "data1", ",", "input_dim", "=", "question_c_vocab_size", ",", "num_output", "=", "100", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "\n", "n", ".", "embed_c_scale", "=", "L", ".", "Scale", "(", "n", ".", "embed_c", ",", "n", ".", "cont1", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "\n", "n", ".", "embed_c_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_c_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T_c", "*", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T_c*T x d_c x 1", "\n", "tops", "=", "L", ".", "Slice", "(", "n", ".", "embed_c_scale_resh", ",", "ntop", "=", "T", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T_c x d_c x 1", "\n", "for", "i", "in", "xrange", "(", "T", ")", ":", "\n", "        ", "n", ".", "__setattr__", "(", "'Slice_'", "+", "str", "(", "i", "+", "1", ")", ",", "tops", "[", "int", "(", "i", ")", "]", ")", "\n", "\n", "# avg of char embedding", "\n", "", "n", ".", "c_embed_1", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_1", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_2", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_2", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_3", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_3", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_4", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_4", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_5", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_5", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_6", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_6", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_7", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_7", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_8", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_8", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_9", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_9", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_10", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_10", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_11", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_11", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_12", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_12", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_13", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_13", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_14", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_14", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_15", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_15", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_16", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_16", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_17", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_17", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_18", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_18", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_19", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_19", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_20", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_20", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_21", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_21", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_22", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_22", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "\n", "concat_c_embed", "=", "[", "n", ".", "c_embed_1", ",", "n", ".", "c_embed_2", ",", "n", ".", "c_embed_3", ",", "n", ".", "c_embed_4", ",", "n", ".", "c_embed_5", ",", "n", ".", "c_embed_6", ",", "n", ".", "c_embed_7", ",", "n", ".", "c_embed_8", ",", "n", ".", "c_embed_9", ",", "n", ".", "c_embed_10", ",", "n", ".", "c_embed_11", ",", "n", ".", "c_embed_12", ",", "n", ".", "c_embed_13", ",", "n", ".", "c_embed_14", ",", "n", ".", "c_embed_15", ",", "n", ".", "c_embed_16", ",", "n", ".", "c_embed_17", ",", "n", ".", "c_embed_18", ",", "n", ".", "c_embed_19", ",", "n", ".", "c_embed_20", ",", "n", ".", "c_embed_21", ",", "n", ".", "c_embed_22", "]", "\n", "n", ".", "concat_char_embed", "=", "L", ".", "Concat", "(", "*", "concat_c_embed", ",", "concat_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T x d_c x 1", "\n", "n", ".", "concat_char_embed_resh", "=", "L", ".", "Reshape", "(", "n", ".", "concat_char_embed", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", "]", ")", ")", ")", "\n", "\n", "# word embedding", "\n", "n", ".", "embed_w", "=", "L", ".", "Embed", "(", "n", ".", "data", ",", "input_dim", "=", "question_vocab_size", ",", "num_output", "=", "200", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "# N x T x d_w", "\n", "\n", "# combine word and char embedding", "\n", "concat_word_embed", "=", "[", "n", ".", "embed_w", ",", "n", ".", "concat_char_embed_resh", "]", "\n", "n", ".", "concat_embed", "=", "L", ".", "Concat", "(", "*", "concat_word_embed", ",", "concat_param", "=", "{", "'axis'", ":", "2", "}", ")", "# N x T x (d_c+d_w)", "\n", "\n", "n", ".", "embed_scale", "=", "L", ".", "Scale", "(", "n", ".", "concat_embed", ",", "n", ".", "cont", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "# N x T x (d_c+d_w)", "\n", "n", ".", "embed_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T x (d_c+d_w) x 1", "\n", "\n", "# avg of word embedding", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).train_att_bc.make_answer_vocab": [[75, 112], ["adic.keys", "sorted", "enumerate", "enumerate", "nadict.items", "nalist.append", "adict.has_key", "config.NUM_OUTPUT_UNITS"], "function", ["None"], ["n", ".", "embed_avg", "=", "L", ".", "Convolution", "(", "n", ".", "embed_scale_resh", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x (d_c+d_w) x 1", "\n", "n", ".", "embed_avg_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_avg", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "300", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled_1", "=", "L", ".", "Tile", "(", "n", ".", "embed_avg_resh", ",", "axis", "=", "2", ",", "tiles", "=", "14", ")", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled", "=", "L", ".", "Tile", "(", "n", ".", "q_emb_tanh_droped_resh_tiled_1", ",", "axis", "=", "3", ",", "tiles", "=", "14", ")", "\n", "n", ".", "i_emb_tanh_droped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "img_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "n", ".", "blcf", "=", "L", ".", "CompactBilinear", "(", "n", ".", "q_emb_tanh_droped_resh_tiled", ",", "n", ".", "i_emb_tanh_droped_resh", ",", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "blcf_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "blcf", ")", "\n", "n", ".", "blcf_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "blcf_sign_sqrt", ")", "\n", "n", ".", "blcf_droped", "=", "L", ".", "Dropout", "(", "n", ".", "blcf_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "\n", "# multi-channel attention", "\n", "n", ".", "att_conv1", "=", "L", ".", "Convolution", "(", "n", ".", "blcf_droped", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "512", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_conv1_relu", "=", "L", ".", "ReLU", "(", "n", ".", "att_conv1", ")", "\n", "n", ".", "att_conv2", "=", "L", ".", "Convolution", "(", "n", ".", "att_conv1_relu", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "2", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_reshaped", "=", "L", ".", "Reshape", "(", "n", ".", "att_conv2", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", "*", "14", "]", ")", ")", ")", "\n", "n", ".", "att_softmax", "=", "L", ".", "Softmax", "(", "n", ".", "att_reshaped", ",", "axis", "=", "2", ")", "\n", "n", ".", "att", "=", "L", ".", "Reshape", "(", "n", ".", "att_softmax", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "att_maps", "=", "L", ".", "Slice", "(", "n", ".", "att", ",", "ntop", "=", "2", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "\n", "n", ".", "att_map0", "=", "att_maps", "[", "0", "]", "\n", "n", ".", "att_map1", "=", "att_maps", "[", "1", "]", "\n", "dummy", "=", "L", ".", "DummyData", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "1", "]", ")", ",", "data_filler", "=", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", ",", "ntop", "=", "1", ")", "\n", "n", ".", "att_feature0", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map0", ",", "dummy", ")", "\n", "n", ".", "att_feature1", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map1", ",", "dummy", ")", "\n", "n", ".", "att_feature0_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature0", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature1_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature1", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature", "=", "L", ".", "Concat", "(", "n", ".", "att_feature0_resh", ",", "n", ".", "att_feature1_resh", ")", "\n", "\n", "# merge attention and lstm with compact bilinear pooling", "\n", "n", ".", "att_feature_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "4096", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "#n.lstm_12_resh = L.Reshape(n.lstm_12, reshape_param=dict(shape=dict(dim=[-1,2048,1,1])))", "\n", "n", ".", "bc_att_lstm", "=", "L", ".", "CompactBilinear", "(", "n", ".", "att_feature_resh", ",", "n", ".", "embed_avg_resh", ",", "\n", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "bc_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "bc_att_lstm", ")", "\n", "n", ".", "bc_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "bc_sign_sqrt", ")", "\n", "\n", "n", ".", "bc_dropped", "=", "L", ".", "Dropout", "(", "n", ".", "bc_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "n", ".", "bc_dropped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "bc_dropped", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "16000", "]", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).train_att_bc.make_question_vocab": [[113, 131], ["qdic.keys", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vdict.has_key"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list"], ["\n", "n", ".", "prediction", "=", "L", ".", "InnerProduct", "(", "n", ".", "bc_dropped_resh", ",", "num_output", "=", "3000", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "loss", "=", "L", ".", "SoftmaxWithLoss", "(", "n", ".", "prediction", ",", "n", ".", "label", ")", "\n", "return", "n", ".", "to_proto", "(", ")", "\n", "\n", "", "def", "make_answer_vocab", "(", "adic", ",", "vocab_size", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "adict", "=", "{", "''", ":", "0", "}", "\n", "nadict", "=", "{", "''", ":", "1000000", "}", "\n", "vid", "=", "1", "\n", "for", "qid", "in", "adic", ".", "keys", "(", ")", ":", "\n", "        ", "answer_obj", "=", "adic", "[", "qid", "]", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "\n", "for", "q_ans", "in", "answer_list", ":", "\n", "# create dict", "\n", "            ", "if", "adict", ".", "has_key", "(", "q_ans", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).train_att_bc.make_vocab_files": [[132, 143], ["write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_question_vocab", "write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_answer_vocab"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_question_vocab", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_answer_vocab"], ["                ", "nadict", "[", "q_ans", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "=", "1", "\n", "adict", "[", "q_ans", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "\n", "# debug", "\n", "", "", "", "nalist", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "sorted", "(", "nadict", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ":", "\n", "        ", "nalist", ".", "append", "(", "(", "k", ",", "v", ")", ")", "\n", "\n", "# keep the top 3000 answers", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).train_att_bc.main": [[144, 204], ["write_to_log.write_log", "write_to_log.write_log", "caffe.set_device", "caffe.set_mode_gpu", "caffe.get_solver", "numpy.zeros", "range", "os.path.exists", "os.makedirs", "os.path.exists", "os.path.exists", "write_to_log.write_log", "train_att_bc.make_vocab_files", "open", "f.write", "open", "f.write", "caffe.get_solver.step", "open", "json.load", "open", "json.load", "open", "json.dump", "open", "json.dump", "str", "str", "str", "str", "write_to_log.write_log", "write_to_log.write_log", "train_loss[].mean", "write_to_log.write_log", "caffe.get_solver.test_nets[].save", "write_to_log.write_log", "visualize_tools.exec_validation", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "train_att_bc.qlstm", "train_att_bc.qlstm", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_vocab_files", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.exec_validation", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["", "n_del_ans", "=", "0", "\n", "n_valid_ans", "=", "0", "\n", "adict_nid", "=", "{", "}", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", ":", "-", "vocab_size", "]", ")", ":", "\n", "        ", "del", "adict", "[", "w", "[", "0", "]", "]", "\n", "n_del_ans", "+=", "w", "[", "1", "]", "\n", "", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", "-", "vocab_size", ":", "]", ")", ":", "\n", "        ", "n_valid_ans", "+=", "w", "[", "1", "]", "\n", "adict_nid", "[", "w", "[", "0", "]", "]", "=", "i", "\n", "\n", "", "return", "adict_nid", "\n", "\n", "", "def", "make_question_vocab", "(", "qdic", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "vdict", "=", "{", "''", ":", "0", "}", "\n", "vid", "=", "1", "\n", "cdict", "=", "{", "''", ":", "0", "}", "\n", "cvid", "=", "1", "\n", "for", "qid", "in", "qdic", ".", "keys", "(", ")", ":", "\n", "# sequence to list", "\n", "        ", "q_str", "=", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "\n", "# create dict", "\n", "for", "w", "in", "q_list", ":", "\n", "            ", "if", "not", "vdict", ".", "has_key", "(", "w", ")", ":", "\n", "                ", "vdict", "[", "w", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "", "for", "c", "in", "list", "(", "w", ")", ":", "\n", "                ", "if", "not", "cdict", ".", "has_key", "(", "c", ")", ":", "\n", "                    ", "cdict", "[", "c", "]", "=", "cvid", "\n", "cvid", "+=", "1", "\n", "\n", "", "", "", "", "return", "vdict", ",", "cdict", "\n", "\n", "", "def", "make_vocab_files", "(", ")", ":", "\n", "    ", "\"\"\"\n    Produce the question and answer vocabulary files.\n    \"\"\"", "\n", "write_log", "(", "'making question vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "write_log", "(", "'making question character vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "qdic", ",", "_", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "QUESTION_VOCAB_SPACE", ")", "\n", "question_vocab", ",", "question_char_vocab", "=", "make_question_vocab", "(", "qdic", ")", "\n", "write_log", "(", "'making answer vocab... '", "+", "config", ".", "ANSWER_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "_", ",", "adic", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "ANSWER_VOCAB_SPACE", ")", "\n", "answer_vocab", "=", "make_answer_vocab", "(", "adic", ",", "config", ".", "NUM_OUTPUT_UNITS", ")", "\n", "return", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "'./result'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'./result'", ")", "\n", "\n", "", "question_vocab", ",", "answer_vocab", "=", "{", "}", ",", "{", "}", "\n", "if", "os", ".", "path", ".", "exists", "(", "'./result/cdict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/adict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/vdict.json'", ")", ":", "\n", "        ", "write_log", "(", "'restoring vocab'", ",", "'log.txt'", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_char_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_vocab", "=", "json", ".", "load", "(", "f", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).visualize_tools.visualize_failures": [[27, 119], ["write_to_log.write_log", "visualize_tools.visualize_failures.save_qtype"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["def", "visualize_failures", "(", "stat_list", ",", "mode", ")", ":", "\n", "\n", "    ", "def", "save_qtype", "(", "qtype_list", ",", "save_filename", ",", "mode", ")", ":", "\n", "\n", "        ", "if", "mode", "==", "'val'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./eval'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/val2014'", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test-dev'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "elif", "mode", "==", "'test'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unsupported mode'", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "shutil", ".", "rmtree", "(", "savepath", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "os", ".", "makedirs", "(", "savepath", ")", "\n", "\n", "for", "qt", "in", "qtype_list", ":", "\n", "            ", "count", "=", "0", "\n", "for", "t_question", "in", "stat_list", ":", "\n", "#print count, t_question", "\n", "                ", "if", "count", "<", "40", "/", "len", "(", "qtype_list", ")", ":", "\n", "                    ", "t_question_list", "=", "t_question", "[", "'q_list'", "]", "\n", "saveflag", "=", "False", "\n", "#print 'debug****************************'", "\n", "#print qt", "\n", "#print t_question_list", "\n", "#print t_question_list[0] == qt[0]", "\n", "#print t_question_list[1] == qt[1]", "\n", "if", "t_question_list", "[", "0", "]", "==", "qt", "[", "0", "]", "and", "t_question_list", "[", "1", "]", "==", "qt", "[", "1", "]", ":", "\n", "                        ", "saveflag", "=", "True", "\n", "", "else", ":", "\n", "                        ", "saveflag", "=", "False", "\n", "\n", "", "if", "saveflag", "==", "True", ":", "\n", "                        ", "t_iid", "=", "t_question", "[", "'iid'", "]", "\n", "if", "mode", "==", "'val'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_val2014_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "", "elif", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_test2015_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "\n", "# for caption", "\n", "#print t_iid", "\n", "#annIds = caps.getAnnIds(t_iid)", "\n", "#anns = caps.loadAnns(annIds)", "\n", "#cap_list = [ann['caption'] for ann in anns]", "\n", "", "ans_list", "=", "t_question", "[", "'ans_list'", "]", "\n", "draw", "=", "ImageDraw", ".", "Draw", "(", "t_img", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ans_list", ")", ")", ":", "\n", "                            ", "try", ":", "\n", "                                ", "draw", ".", "text", "(", "(", "10", ",", "10", "*", "i", ")", ",", "str", "(", "ans_list", "[", "i", "]", ")", ")", "\n", "", "except", ":", "\n", "                                ", "pass", "\n", "\n", "", "", "ans", "=", "t_question", "[", "'answer'", "]", "\n", "pred", "=", "t_question", "[", "'pred'", "]", "\n", "if", "ans", "==", "-", "1", ":", "\n", "                            ", "pre", "=", "''", "\n", "", "elif", "ans", "==", "pred", ":", "\n", "                            ", "pre", "=", "'correct  '", "\n", "", "else", ":", "\n", "                            ", "pre", "=", "'failure  '", "\n", "#print ' aaa ', ans, pred", "\n", "", "ans", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "ans", ")", ")", "\n", "pred", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "pred", ")", ")", "\n", "img_title", "=", "pre", "+", "str", "(", "' '", ".", "join", "(", "t_question_list", ")", ")", "+", "'.  a_'", "+", "str", "(", "ans", ")", "+", "' p_'", "+", "str", "(", "pred", ")", "+", "'.png'", "\n", "count", "+=", "1", "\n", "write_log", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ",", "'visualize_log.txt'", ")", "\n", "t_img", ".", "save", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ")", "\n", "\n", "", "", "", "", "", "write_log", "(", "'saving colors'", ",", "'visualize_log.txt'", ")", "\n", "qt_color_list", "=", "[", "[", "'what'", ",", "'color'", "]", "]", "\n", "save_qtype", "(", "qt_color_list", ",", "'colors'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving what is'", ",", "'visualize_log.txt'", ")", "\n", "qt_whatis_list", "=", "[", "[", "'what'", ",", "'is'", "]", ",", "[", "'what'", ",", "'kind'", "]", ",", "[", "'what'", ",", "'are'", "]", "]", "\n", "save_qtype", "(", "qt_whatis_list", ",", "'whatis'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving is'", ",", "'visualize_log.txt'", ")", "\n", "qt_is_list", "=", "[", "[", "'is'", ",", "'the'", "]", ",", "[", "'is'", ",", "'this'", "]", ",", "[", "'is'", ",", "'there'", "]", "]", "\n", "save_qtype", "(", "qt_is_list", ",", "'is'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving how many'", ",", "'visualize_log.txt'", ")", "\n", "qt_howmany_list", "=", "[", "[", "'how'", ",", "'many'", "]", "]", "\n", "save_qtype", "(", "qt_howmany_list", ",", "'howmany'", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).visualize_tools.exec_validation": [[120, 200], ["caffe.set_device", "caffe.set_mode_gpu", "caffe.Net", "vqa_data_provider_layer.VQADataProvider", "len", "numpy.array().mean", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "vqa_data_provider_layer.VQADataProvider.get_batch_vec", "caffe.Net.forward", "caffe.Net.blobs[].data.argmax", "testloss_list.append", "zip", "vqaTools.vqa.VQA", "vqaTools.vqa.VQA.loadRes", "vqaEvaluation.vqaEval.VQAEval", "vqaEvaluation.vqaEval.VQAEval.evaluate", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "t_answer.tolist", "pred_list.append", "numpy.array", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "stat_list.append", "open", "json.dump", "visualize_tools.visualize_failures", "int", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "str().zfill", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "str().zfill", "xrange", "str", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.forward", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj"], ["", "def", "exec_validation", "(", "device_id", ",", "mode", ",", "it", "=", "''", ",", "visualize", "=", "False", ")", ":", "\n", "\n", "    ", "caffe", ".", "set_device", "(", "device_id", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "net", "=", "caffe", ".", "Net", "(", "'./result/proto_test.prototxt'", ",", "'./result/tmp.caffemodel'", ",", "caffe", ".", "TEST", ")", "\n", "\n", "dp", "=", "VQADataProvider", "(", "mode", "=", "mode", ",", "batchsize", "=", "config", ".", "VAL_BATCH_SIZE", ")", "\n", "total_questions", "=", "len", "(", "dp", ".", "getQuesIds", "(", ")", ")", "\n", "epoch", "=", "0", "\n", "\n", "pred_list", "=", "[", "]", "\n", "testloss_list", "=", "[", "]", "\n", "stat_list", "=", "[", "]", "\n", "\n", "while", "epoch", "==", "0", ":", "\n", "        ", "t_word", ",", "t_cont", ",", "t_word_c", ",", "t_cont_c", ",", "t_img_feature", ",", "t_answer", ",", "t_qid_list", ",", "t_iid_list", ",", "epoch", "=", "dp", ".", "get_batch_vec", "(", ")", "\n", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "...", "]", "=", "t_word", "# np.transpose(t_word,(1,0))", "\n", "net", ".", "blobs", "[", "'cont'", "]", ".", "data", "[", "...", "]", "=", "t_cont", "# np.transpose(t_cont,(1,0))", "\n", "net", ".", "blobs", "[", "'data1'", "]", ".", "data", "[", "...", "]", "=", "t_word_c", "\n", "net", ".", "blobs", "[", "'cont1'", "]", ".", "data", "[", "...", "]", "=", "t_cont_c", "\n", "net", ".", "blobs", "[", "'img_feature'", "]", ".", "data", "[", "...", "]", "=", "t_img_feature", "\n", "net", ".", "blobs", "[", "'label'", "]", ".", "data", "[", "...", "]", "=", "t_answer", "\n", "#net.blobs['glove'].data[...] = t_glove_matrix # np.transpose(t_glove_matrix, (1,0,2))", "\n", "net", ".", "forward", "(", ")", "\n", "t_pred_list", "=", "net", ".", "blobs", "[", "'prediction'", "]", ".", "data", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "t_pred_str", "=", "[", "dp", ".", "vec_to_answer", "(", "pred_symbol", ")", "for", "pred_symbol", "in", "t_pred_list", "]", "\n", "testloss_list", ".", "append", "(", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", ")", "\n", "for", "qid", ",", "iid", ",", "ans", ",", "pred", "in", "zip", "(", "t_qid_list", ",", "t_iid_list", ",", "t_answer", ".", "tolist", "(", ")", ",", "t_pred_str", ")", ":", "\n", "            ", "pred_list", ".", "append", "(", "{", "u'answer'", ":", "pred", ",", "u'question_id'", ":", "int", "(", "dp", ".", "getStrippedQuesId", "(", "qid", ")", ")", "}", ")", "\n", "if", "visualize", ":", "\n", "                ", "q_list", "=", "dp", ".", "seq_to_list", "(", "dp", ".", "getQuesStr", "(", "qid", ")", ")", "\n", "if", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                    ", "ans_str", "=", "''", "\n", "ans_list", "=", "[", "''", "]", "*", "10", "\n", "", "else", ":", "\n", "                    ", "ans_str", "=", "dp", ".", "vec_to_answer", "(", "ans", ")", "\n", "ans_list", "=", "[", "dp", ".", "getAnsObj", "(", "qid", ")", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "", "stat_list", ".", "append", "(", "{", "'qid'", ":", "qid", ",", "\n", "'q_list'", ":", "q_list", ",", "\n", "'iid'", ":", "iid", ",", "\n", "'answer'", ":", "ans_str", ",", "\n", "'ans_list'", ":", "ans_list", ",", "\n", "'pred'", ":", "pred", "}", ")", "\n", "#percent = 100 * float(len(pred_list)) / total_questions", "\n", "#sys.stdout.write('\\r' + ('%.2f' % percent) + '%')", "\n", "#sys.stdout.flush()", "\n", "\n", "\n", "\n", "", "", "", "mean_testloss", "=", "np", ".", "array", "(", "testloss_list", ")", ".", "mean", "(", ")", "\n", "\n", "if", "mode", "==", "'val'", ":", "\n", "        ", "valFile", "=", "'./result/val2014_resfile'", "\n", "with", "open", "(", "valFile", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "annFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ans_file'", "]", "\n", "quesFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ques_file'", "]", "\n", "vqa", "=", "VQA", "(", "annFile", ",", "quesFile", ")", "\n", "vqaRes", "=", "vqa", ".", "loadRes", "(", "valFile", ",", "quesFile", ")", "\n", "vqaEval", "=", "VQAEval", "(", "vqa", ",", "vqaRes", ",", "n", "=", "2", ")", "\n", "vqaEval", ".", "evaluate", "(", ")", "\n", "acc_overall", "=", "vqaEval", ".", "accuracy", "[", "'overall'", "]", "\n", "acc_perQuestionType", "=", "vqaEval", ".", "accuracy", "[", "'perQuestionType'", "]", "\n", "acc_perAnswerType", "=", "vqaEval", ".", "accuracy", "[", "'perAnswerType'", "]", "\n", "return", "mean_testloss", ",", "acc_overall", ",", "acc_perQuestionType", ",", "acc_perAnswerType", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test-dev2015_v3t'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "", "elif", "mode", "==", "'test'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test2015_v3c'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.fastText (word).visualize_tools.drawgraph": [[201, 269], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.twinx", "fig.add_subplot.plot", "fig.add_subplot.plot", "ax1.twinx.plot", "matplotlib.legend", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "ax1.twinx.set_ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "numpy.array", "numpy.array", "matplotlib.figure", "matplotlib.legend", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "sorted", "visualize_tools.drawgraph.draw_qt_acc"], "function", ["None"], ["            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "\n", "", "", "", "def", "drawgraph", "(", "results", ",", "save_question_type_graphs", "=", "False", ")", ":", "\n", "# 0:it", "\n", "# 1:trainloss", "\n", "# 2:testloss", "\n", "# 3:oa_acc", "\n", "# 4:qt_acc", "\n", "# 5:at_acc", "\n", "\n", "# training curve", "\n", "    ", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "loss", "=", "np", ".", "array", "(", "[", "l", "[", "1", "]", "for", "l", "in", "results", "]", ")", "\n", "valloss", "=", "np", ".", "array", "(", "[", "l", "[", "2", "]", "for", "l", "in", "results", "]", ")", "\n", "valacc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax1", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "ax2", "=", "ax1", ".", "twinx", "(", ")", "\n", "\n", "ax1", ".", "plot", "(", "it", ",", "loss", ",", "color", "=", "'blue'", ",", "label", "=", "'train loss'", ")", "\n", "ax1", ".", "plot", "(", "it", ",", "valloss", ",", "'--'", ",", "color", "=", "'blue'", ",", "label", "=", "'test loss'", ")", "\n", "ax2", ".", "plot", "(", "it", ",", "valacc", ",", "color", "=", "'red'", ",", "label", "=", "'acc on val'", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'lower left'", ")", "\n", "\n", "ax1", ".", "set_xlabel", "(", "'Iterations'", ")", "\n", "ax1", ".", "set_ylabel", "(", "'Loss Value'", ")", "\n", "ax2", ".", "set_ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "'./learning_curve max_%2.2f.png'", "%", "valacc", ".", "max", "(", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "# question type", "\n", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "oa_acc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "qt_dic_list", "=", "[", "l", "[", "4", "]", "for", "l", "in", "results", "]", "\n", "\n", "def", "draw_qt_acc", "(", "target_key_list", ",", "figname", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "for", "k", "in", "target_key_list", ":", "\n", "            ", "write_log", "(", "str", "(", "k", ")", "+", "str", "(", "type", "(", "k", ")", ")", ",", "'visualize_log.txt'", ")", "\n", "t_val", "=", "np", ".", "array", "(", "[", "qt_dic", "[", "k", "]", "for", "qt_dic", "in", "qt_dic_list", "]", ")", "\n", "plt", ".", "plot", "(", "it", ",", "t_val", ",", "label", "=", "str", "(", "k", ")", ")", "\n", "", "plt", ".", "legend", "(", "fontsize", "=", "'small'", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "100.", ")", "\n", "#plt.legend(prop={'size':6})", "\n", "\n", "plt", ".", "xlabel", "(", "'Iterations'", ")", "\n", "plt", ".", "ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "figname", ",", "dpi", "=", "200", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "", "if", "save_question_type_graphs", ":", "\n", "        ", "s_keys", "=", "sorted", "(", "qt_dic_list", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "0", ":", "13", "]", "+", "[", "s_keys", "[", "31", "]", ",", "]", ",", "'./ind_qt_are.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "13", ":", "17", "]", "+", "s_keys", "[", "49", ":", "]", ",", "'./ind_qt_how_where_who_why.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "17", ":", "31", "]", "+", "[", "s_keys", "[", "32", "]", ",", "]", ",", "'./ind_qt_is.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "33", ":", "49", "]", ",", "'./ind_qt_what.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what color is the'", ",", "'what color are the'", ",", "'what color is'", ",", "'what color'", ",", "'what is the color of the'", "]", ",", "'./qt_color.png'", ")", "\n", "draw_qt_acc", "(", "[", "'how many'", ",", "'how'", ",", "'how many people are'", ",", "'how many people are in'", "]", ",", "'./qt_number.png'", ")", "\n", "draw_qt_acc", "(", "[", "'who is'", ",", "'why'", ",", "'why is the'", ",", "'where is the'", ",", "'where are the'", ",", "'which'", "]", ",", "'./qt_who_why_where_which.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what is the man'", ",", "'is the man'", ",", "'are they'", ",", "'is he'", ",", "'is the woman'", ",", "'is this person'", ",", "'what is the woman'", ",", "'is the person'", ","]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).write_to_log.write_log": [[1, 4], ["open", "f.write"], "function", ["None"], ["def", "write_log", "(", "str", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "+", "\"\\n\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.__init__": [[13, 29], ["vqa_data_provider_layer.VQADataProvider.load_data", "len", "open", "json.load", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data"], ["    ", "def", "__init__", "(", "self", ",", "batchsize", "=", "64", ",", "max_length", "=", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "max_w_length", "=", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "batchsize", "\n", "self", ".", "d_vocabulary", "=", "None", "\n", "self", ".", "batch_index", "=", "None", "\n", "self", ".", "batch_len", "=", "None", "\n", "self", ".", "rev_adict", "=", "None", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "max_w_length", "=", "max_w_length", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "qdic", ",", "self", ".", "adic", "=", "VQADataProvider", ".", "load_data", "(", "mode", ")", "\n", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "cdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "vdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "adict", "=", "json", ".", "load", "(", "f", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.load_vqa_json": [[32, 55], ["write_to_log.write_log", "open", "json.load", "open", "json.load", "str", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["#self.nlp = spacy.load('en', vectors='en_glove_cc_300_1m_vectors')", "\n", "#self.glove_dict = {} # word -> glove vector", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_vqa_json", "(", "data_split", ")", ":", "\n", "        ", "\"\"\"\n        Parses the question and answer json files for the given data split. \n        Returns the question dictionary and the answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ques_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "[", "'questions'", "]", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "qdic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'question_id'", "]", ")", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image_id'", "]", "}", "\n", "\n", "", "", "if", "'test'", "not", "in", "data_split", ":", "\n", "            ", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ans_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "adata", "=", "json", ".", "load", "(", "f", ")", "[", "'annotations'", "]", "\n", "for", "a", "in", "adata", ":", "\n", "                    ", "adic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "a", "[", "'question_id'", "]", ")", "]", "=", "a", "[", "'answers'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.load_genome_json": [[56, 73], ["write_to_log.write_log", "open", "json.load", "str", "str", "len"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for '", "+", "data_split", ",", "'log.txt'", ")", "\n", "return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_genome_json", "(", ")", ":", "\n", "        ", "\"\"\"\n        Parses the genome json file. Returns the question dictionary and the\n        answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'genome_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "key", "=", "'genome'", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'id'", "]", ")", "\n", "qdic", "[", "key", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image'", "]", "}", "\n", "adic", "[", "key", "]", "=", "[", "{", "'answer'", ":", "q", "[", "'answer'", "]", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.load_data": [[74, 89], ["data_split_str.split", "config.DATA_PATHS.keys", "vqa_data_provider_layer.VQADataProvider.load_genome_json", "all_qdic.update", "all_adic.update", "vqa_data_provider_layer.VQADataProvider.load_vqa_json", "all_qdic.update", "all_adic.update"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_genome_json", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_vqa_json"], ["", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for genome'", ",", "'log.txt'", ")", "\n", "return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_data", "(", "data_split_str", ")", ":", "\n", "        ", "all_qdic", ",", "all_adic", "=", "{", "}", ",", "{", "}", "\n", "for", "data_split", "in", "data_split_str", ".", "split", "(", "'+'", ")", ":", "\n", "            ", "assert", "data_split", "in", "config", ".", "DATA_PATHS", ".", "keys", "(", ")", ",", "'unknown data split'", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_genome_json", "(", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "", "else", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_vqa_json", "(", "data_split", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.getQuesIds": [[90, 92], ["vqa_data_provider_layer.VQADataProvider.qdic.keys"], "methods", ["None"], ["\n", "", "", "return", "all_qdic", ",", "all_adic", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId": [[93, 95], ["qid.split"], "methods", ["None"], ["", "def", "getQuesIds", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "qdic", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.getImgId": [[96, 98], ["None"], "methods", ["None"], ["", "def", "getStrippedQuesId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.getQuesStr": [[99, 101], ["None"], "methods", ["None"], ["", "def", "getImgId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'iid'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.getAnsObj": [[102, 106], ["None"], "methods", ["None"], ["", "def", "getQuesStr", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "\n", "", "def", "getAnsObj", "(", "self", ",", "qid", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.seq_to_char_list": [[118, 123], ["list", "filter", "s.lower", "len"], "methods", ["None"], ["q_list", "=", "filter", "(", "lambda", "x", ":", "len", "(", "x", ")", ">", "0", ",", "q_list", ")", "\n", "return", "q_list", "\n", "\n", "", "def", "extract_answer", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.extract_answer": [[124, 137], ["dic.has_key", "max", "xrange", "dic.items"], "methods", ["None"], ["            ", "return", "-", "1", "\n", "", "answer_list", "=", "[", "answer_obj", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "dic", "=", "{", "}", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "dic", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "dic", "[", "ans", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "dic", "[", "ans", "]", "=", "1", "\n", "", "", "max_key", "=", "max", "(", "(", "v", ",", "k", ")", "for", "(", "k", ",", "v", ")", "in", "dic", ".", "items", "(", ")", ")", "[", "1", "]", "\n", "return", "max_key", "\n", "\n", "", "def", "extract_answer_prob", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.extract_answer_prob": [[138, 156], ["vqa_data_provider_layer.VQADataProvider.adict.has_key", "len", "random.choice", "prob_answer_list.append", "Exception"], "methods", ["None"], ["            ", "return", "-", "1", "\n", "\n", "", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "prob_answer_list", "=", "[", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "prob_answer_list", ".", "append", "(", "ans", ")", "\n", "\n", "", "", "if", "len", "(", "prob_answer_list", ")", "==", "0", ":", "\n", "            ", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "return", "'hoge'", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"This should not happen.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "random", ".", "choice", "(", "prob_answer_list", ")", "\n", "\n", "# def qlist_to_vec(self, max_length, q_list):", "\n", "#     \"\"\"", "\n", "#     Converts a list of words into a format suitable for the embedding layer.", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.qc_list_to_vec": [[205, 230], ["numpy.zeros", "numpy.zeros", "xrange", "len", "vqa_data_provider_layer.VQADataProvider.cdict.has_key", "len"], "methods", ["None"], ["\n", "qvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "cvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "qcvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "ccvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "for", "i", "in", "xrange", "(", "max_length", ")", ":", "\n", "            ", "if", "i", "<", "max_length", "-", "len", "(", "q_list", ")", ":", "\n", "                ", "cvec", "[", "i", "]", "=", "0", "\n", "", "else", ":", "\n", "                ", "w", "=", "q_list", "[", "i", "-", "(", "max_length", "-", "len", "(", "q_list", ")", ")", "]", "\n", "# is the word in the vocabulary?", "\n", "if", "self", ".", "vdict", ".", "has_key", "(", "w", ")", "is", "False", ":", "\n", "                    ", "w", "=", "''", "\n", "", "qvec", "[", "i", "]", "=", "self", ".", "vdict", "[", "w", "]", "\n", "cvec", "[", "i", "]", "=", "1.0", "/", "len", "(", "q_list", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.answer_to_vec": [[231, 241], ["vqa_data_provider_layer.VQADataProvider.adict.has_key"], "methods", ["None"], ["j", "=", "max_w_length", "*", "i", "\n", "w_list", "=", "list", "(", "w", ")", "\n", "for", "k", "in", "xrange", "(", "max_w_length", ")", ":", "\n", "                    ", "if", "k", "<", "max_w_length", "-", "len", "(", "w_list", ")", ":", "\n", "                        ", "ccvec", "[", "j", "+", "k", "]", "=", "0", "\n", "", "else", ":", "\n", "                        ", "c", "=", "w_list", "[", "k", "-", "(", "max_w_length", "-", "len", "(", "w_list", ")", ")", "]", "\n", "# is the char in the vocabulary?", "\n", "if", "self", ".", "cdict", ".", "has_key", "(", "c", ")", "is", "False", ":", "\n", "                            ", "c", "=", "''", "\n", "", "qcvec", "[", "j", "+", "k", "]", "=", "self", ".", "cdict", "[", "c", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.vec_to_answer": [[242, 251], ["vqa_data_provider_layer.VQADataProvider.adict.items"], "methods", ["None"], ["ccvec", "[", "j", "+", "k", "]", "=", "1.0", "/", "len", "(", "w_list", ")", "\n", "", "", "", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", "\n", "\n", "", "def", "answer_to_vec", "(", "self", ",", "ans_str", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "if", "self", ".", "adict", ".", "has_key", "(", "ans_str", ")", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "ans_str", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.create_batch": [[252, 298], ["numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "enumerate", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.seq_to_char_list", "vqa_data_provider_layer.VQADataProvider.qc_list_to_vec", "vqa_data_provider_layer.VQADataProvider.answer_to_vec", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "qid.split", "vqa_data_provider_layer.VQADataProvider.extract_answer", "vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "numpy.sqrt", "write_to_log.write_log", "numpy.load", "numpy.load", "str", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId", "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.seq_to_char_list", "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.qc_list_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.answer_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["", "else", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "''", "]", "\n", "", "return", "ans", "\n", "\n", "", "def", "vec_to_answer", "(", "self", ",", "ans_symbol", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "rev_adict", "is", "None", ":", "\n", "            ", "rev_adict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "adict", ".", "items", "(", ")", ":", "\n", "                ", "rev_adict", "[", "v", "]", "=", "k", "\n", "", "self", ".", "rev_adict", "=", "rev_adict", "\n", "\n", "", "return", "self", ".", "rev_adict", "[", "ans_symbol", "]", "\n", "\n", "", "def", "create_batch", "(", "self", ",", "qid_list", ")", ":", "\n", "\n", "        ", "qvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "cvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "qcvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ccvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ivec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "2048", "*", "14", "*", "14", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "2048", ",", "14", ",", "14", ")", "\n", "avec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ")", "\n", "#glove_matrix = np.zeros(self.batchsize * self.max_length * GLOVE_EMBEDDING_SIZE).reshape(\\", "\n", "#self.batchsize, self.max_length, GLOVE_EMBEDDING_SIZE)", "\n", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "\n", "# load raw question information", "\n", "            ", "q_str", "=", "self", ".", "getQuesStr", "(", "qid", ")", "\n", "q_ans", "=", "self", ".", "getAnsObj", "(", "qid", ")", "\n", "q_iid", "=", "self", ".", "getImgId", "(", "qid", ")", "\n", "\n", "# convert question to vec", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "t_qvec", ",", "t_cvec", ",", "t_qcvec", ",", "t_ccvec", "=", "self", ".", "qlist_to_vec", "(", "self", ".", "max_length", ",", "self", ".", "max_w_length", ",", "q_list", ")", "\n", "\n", "try", ":", "\n", "                ", "qid_split", "=", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "\n", "data_split", "=", "qid_split", "[", "0", "]", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "else", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "t_ivec", "=", "(", "t_ivec", "/", "np", ".", "sqrt", "(", "(", "t_ivec", "**", "2", ")", ".", "sum", "(", ")", ")", ")", "\n", "", "except", ":", "\n", "                ", "t_ivec", "=", "0.", "\n", "write_log", "(", "'data not found for qid : '", "+", "str", "(", "q_iid", ")", "+", "' '", "+", "self", ".", "mode", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProvider.get_batch_vec": [[300, 347], ["vqa_data_provider_layer.VQADataProvider.create_batch", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "random.shuffle", "len", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.adict.has_key", "t_qid_list.append", "t_iid_list.append", "vqa_data_provider_layer.VQADataProvider.get_batch_vec.has_at_least_one_valid_answer"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.create_batch", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId"], ["# convert answer to vec", "\n", "", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer", "(", "q_ans", ")", "\n", "", "else", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer_prob", "(", "q_ans", ")", "\n", "", "t_avec", "=", "self", ".", "answer_to_vec", "(", "q_ans_str", ")", "\n", "\n", "qvec", "[", "i", ",", "...", "]", "=", "t_qvec", "\n", "cvec", "[", "i", ",", "...", "]", "=", "t_cvec", "\n", "qcvec", "[", "i", ",", "...", "]", "=", "t_qcvec", "\n", "ccvec", "[", "i", ",", "...", "]", "=", "t_ccvec", "\n", "ivec", "[", "i", ",", "...", "]", "=", "t_ivec", "\n", "avec", "[", "i", ",", "...", "]", "=", "t_avec", "\n", "#glove_matrix[i,...] = t_glove_matrix", "\n", "\n", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", ",", "ivec", ",", "avec", "#, glove_matrix", "\n", "\n", "\n", "", "def", "get_batch_vec", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "batch_len", "is", "None", ":", "\n", "            ", "self", ".", "n_skipped", "=", "0", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_len", "=", "len", "(", "qid_list", ")", "\n", "self", ".", "batch_index", "=", "0", "\n", "self", ".", "epoch_counter", "=", "0", "\n", "\n", "", "def", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "            ", "answer_obj", "=", "self", ".", "getAnsObj", "(", "t_qid", ")", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "                ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n", "                    ", "return", "True", "\n", "\n", "", "", "", "counter", "=", "0", "\n", "t_qid_list", "=", "[", "]", "\n", "t_iid_list", "=", "[", "]", "\n", "while", "counter", "<", "self", ".", "batchsize", ":", "\n", "            ", "t_qid", "=", "self", ".", "qid_list", "[", "self", ".", "batch_index", "]", "\n", "t_iid", "=", "self", ".", "getImgId", "(", "t_qid", ")", "\n", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n", "", "elif", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProviderLayer.setup": [[353, 367], ["top[].reshape", "top[].reshape", "top[].reshape", "top[].reshape", "json.loads", "json.loads", "vqa_data_provider_layer.VQADataProvider"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape"], ["                ", "self", ".", "batch_index", "+=", "1", "\n", "", "else", ":", "\n", "                ", "self", ".", "epoch_counter", "+=", "1", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_index", "=", "0", "\n", "write_log", "(", "\"%d questions were skipped in a single epoch\"", "%", "self", ".", "n_skipped", ",", "'log.txt'", ")", "\n", "self", ".", "n_skipped", "=", "0", "\n", "\n", "", "", "t_batch", "=", "self", ".", "create_batch", "(", "t_qid_list", ")", "\n", "return", "t_batch", "+", "(", "t_qid_list", ",", "t_iid_list", ",", "self", ".", "epoch_counter", ")", "\n", "\n", "", "", "class", "VQADataProviderLayer", "(", "caffe", ".", "Layer", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProviderLayer.reshape": [[368, 370], ["None"], "methods", ["None"], ["\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProviderLayer.forward": [[371, 380], ["vqa_data_provider_layer.VQADataProviderLayer.dp.get_batch_vec"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec"], ["def", "setup", "(", "self", ",", "bottom", ",", "top", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "json", ".", "loads", "(", "self", ".", "param_str", ")", "[", "'batchsize'", "]", "\n", "self", ".", "top_names", "=", "[", "'data'", ",", "'cont'", ",", "'data1'", ",", "'cont1'", ",", "'feature'", ",", "'label'", "]", "#,'glove']", "\n", "top", "[", "0", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ")", "\n", "top", "[", "1", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ")", "\n", "top", "[", "2", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", "*", "config", ".", "MAX_WORDS_IN_QUESTION", ")", "\n", "top", "[", "3", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", "*", "config", ".", "MAX_WORDS_IN_QUESTION", ")", "\n", "top", "[", "4", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "2048", ",", "14", ",", "14", ")", "\n", "top", "[", "5", "]", ".", "reshape", "(", "self", ".", "batchsize", ")", "\n", "#top[4].reshape(self.batchsize,config.MAX_WORDS_IN_QUESTION,GLOVE_EMBEDDING_SIZE)", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).vqa_data_provider_layer.VQADataProviderLayer.backward": [[382, 384], ["None"], "methods", ["None"], ["self", ".", "mode", "=", "json", ".", "loads", "(", "self", ".", "param_str", ")", "[", "'mode'", "]", "\n", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "pass", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).train_att_bc.qlstm": [[19, 89], ["caffe.NetSpec", "json.dumps", "caffe.layers.Python", "caffe.layers.Embed", "caffe.layers.Scale", "caffe.layers.Reshape", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.ReLU", "caffe.layers.ReLU", "caffe.layers.ReLU", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Concat", "caffe.layers.Dropout", "caffe.layers.Tile", "caffe.layers.Tile", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.Reshape", "caffe.layers.Softmax", "caffe.layers.Reshape", "caffe.layers.Slice", "caffe.layers.DummyData", "caffe.layers.SoftAttention", "caffe.layers.SoftAttention", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Concat", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Reshape", "caffe.layers.InnerProduct", "caffe.layers.SoftmaxWithLoss", "caffe.NetSpec.to_proto", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "config.TRAIN_DATA_SPLITS", "config.BATCH_SIZE", "config.MAX_CHARS_IN_QUESTION", "config.VAL_BATCH_SIZE", "config.MAX_CHARS_IN_QUESTION"], "function", ["None"], ["def", "qlstm", "(", "mode", ",", "batchsize", ",", "T", ",", "T_c", ",", "question_c_vocab_size", ",", "question_vocab_size", ")", ":", "\n", "    ", "n", "=", "caffe", ".", "NetSpec", "(", ")", "\n", "mode_str", "=", "json", ".", "dumps", "(", "{", "'mode'", ":", "mode", ",", "'batchsize'", ":", "batchsize", "}", ")", "\n", "n", ".", "data", ",", "n", ".", "cont", ",", "n", ".", "data1", ",", "n", ".", "cont1", ",", "n", ".", "img_feature", ",", "n", ".", "label", "=", "L", ".", "Python", "(", "module", "=", "'vqa_data_provider_layer'", ",", "layer", "=", "'VQADataProviderLayer'", ",", "param_str", "=", "mode_str", ",", "ntop", "=", "6", ")", "#5 )", "\n", "\n", "# char embedding", "\n", "n", ".", "embed_c", "=", "L", ".", "Embed", "(", "n", ".", "data1", ",", "input_dim", "=", "question_c_vocab_size", ",", "num_output", "=", "100", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "\n", "n", ".", "embed_c_scale", "=", "L", ".", "Scale", "(", "n", ".", "embed_c", ",", "n", ".", "cont1", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "\n", "n", ".", "embed_c_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_c_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T_c", "*", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T_c*T x d_c x 1", "\n", "tops", "=", "L", ".", "Slice", "(", "n", ".", "embed_c_scale_resh", ",", "ntop", "=", "T", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T_c x d_c x 1", "\n", "for", "i", "in", "xrange", "(", "T", ")", ":", "\n", "        ", "n", ".", "__setattr__", "(", "'Slice_'", "+", "str", "(", "i", "+", "1", ")", ",", "tops", "[", "int", "(", "i", ")", "]", ")", "\n", "\n", "# avg of char embedding", "\n", "", "n", ".", "c_embed_1", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_1", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_2", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_2", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_3", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_3", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_4", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_4", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_5", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_5", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_6", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_6", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_7", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_7", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_8", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_8", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_9", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_9", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_10", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_10", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_11", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_11", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_12", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_12", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_13", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_13", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_14", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_14", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_15", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_15", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_16", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_16", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_17", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_17", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_18", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_18", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_19", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_19", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_20", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_20", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_21", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_21", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_22", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_22", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "\n", "concat_c_embed", "=", "[", "n", ".", "c_embed_1", ",", "n", ".", "c_embed_2", ",", "n", ".", "c_embed_3", ",", "n", ".", "c_embed_4", ",", "n", ".", "c_embed_5", ",", "n", ".", "c_embed_6", ",", "n", ".", "c_embed_7", ",", "n", ".", "c_embed_8", ",", "n", ".", "c_embed_9", ",", "n", ".", "c_embed_10", ",", "n", ".", "c_embed_11", ",", "n", ".", "c_embed_12", ",", "n", ".", "c_embed_13", ",", "n", ".", "c_embed_14", ",", "n", ".", "c_embed_15", ",", "n", ".", "c_embed_16", ",", "n", ".", "c_embed_17", ",", "n", ".", "c_embed_18", ",", "n", ".", "c_embed_19", ",", "n", ".", "c_embed_20", ",", "n", ".", "c_embed_21", ",", "n", ".", "c_embed_22", "]", "\n", "n", ".", "concat_char_embed", "=", "L", ".", "Concat", "(", "*", "concat_c_embed", ",", "concat_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T x d_c x 1", "\n", "n", ".", "concat_char_embed_resh", "=", "L", ".", "Reshape", "(", "n", ".", "concat_char_embed", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", "]", ")", ")", ")", "\n", "\n", "# word embedding", "\n", "n", ".", "embed_w", "=", "L", ".", "Embed", "(", "n", ".", "data", ",", "input_dim", "=", "question_vocab_size", ",", "num_output", "=", "200", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "# N x T x d_w", "\n", "\n", "# combine word and char embedding", "\n", "concat_word_embed", "=", "[", "n", ".", "embed_w", ",", "n", ".", "concat_char_embed_resh", "]", "\n", "n", ".", "concat_embed", "=", "L", ".", "Concat", "(", "*", "concat_word_embed", ",", "concat_param", "=", "{", "'axis'", ":", "2", "}", ")", "# N x T x (d_c+d_w)", "\n", "\n", "n", ".", "embed_scale", "=", "L", ".", "Scale", "(", "n", ".", "concat_embed", ",", "n", ".", "cont", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "# N x T x (d_c+d_w)", "\n", "n", ".", "embed_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T x (d_c+d_w) x 1", "\n", "\n", "# avg of word embedding", "\n", "n", ".", "embed_avg", "=", "L", ".", "Convolution", "(", "n", ".", "embed_scale_resh", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x (d_c+d_w) x 1", "\n", "n", ".", "embed_avg_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_avg", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "300", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled_1", "=", "L", ".", "Tile", "(", "n", ".", "embed_avg_resh", ",", "axis", "=", "2", ",", "tiles", "=", "14", ")", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled", "=", "L", ".", "Tile", "(", "n", ".", "q_emb_tanh_droped_resh_tiled_1", ",", "axis", "=", "3", ",", "tiles", "=", "14", ")", "\n", "n", ".", "i_emb_tanh_droped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "img_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "n", ".", "blcf", "=", "L", ".", "CompactBilinear", "(", "n", ".", "q_emb_tanh_droped_resh_tiled", ",", "n", ".", "i_emb_tanh_droped_resh", ",", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "blcf_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "blcf", ")", "\n", "n", ".", "blcf_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "blcf_sign_sqrt", ")", "\n", "n", ".", "blcf_droped", "=", "L", ".", "Dropout", "(", "n", ".", "blcf_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "\n", "# multi-channel attention", "\n", "n", ".", "att_conv1", "=", "L", ".", "Convolution", "(", "n", ".", "blcf_droped", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "512", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_conv1_relu", "=", "L", ".", "ReLU", "(", "n", ".", "att_conv1", ")", "\n", "n", ".", "att_conv2", "=", "L", ".", "Convolution", "(", "n", ".", "att_conv1_relu", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "2", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).train_att_bc.make_answer_vocab": [[90, 127], ["adic.keys", "sorted", "enumerate", "enumerate", "nadict.items", "nalist.append", "adict.has_key", "config.NUM_OUTPUT_UNITS"], "function", ["None"], ["n", ".", "att_reshaped", "=", "L", ".", "Reshape", "(", "n", ".", "att_conv2", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", "*", "14", "]", ")", ")", ")", "\n", "n", ".", "att_softmax", "=", "L", ".", "Softmax", "(", "n", ".", "att_reshaped", ",", "axis", "=", "2", ")", "\n", "n", ".", "att", "=", "L", ".", "Reshape", "(", "n", ".", "att_softmax", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "att_maps", "=", "L", ".", "Slice", "(", "n", ".", "att", ",", "ntop", "=", "2", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "\n", "n", ".", "att_map0", "=", "att_maps", "[", "0", "]", "\n", "n", ".", "att_map1", "=", "att_maps", "[", "1", "]", "\n", "dummy", "=", "L", ".", "DummyData", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "1", "]", ")", ",", "data_filler", "=", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", ",", "ntop", "=", "1", ")", "\n", "n", ".", "att_feature0", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map0", ",", "dummy", ")", "\n", "n", ".", "att_feature1", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map1", ",", "dummy", ")", "\n", "n", ".", "att_feature0_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature0", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature1_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature1", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature", "=", "L", ".", "Concat", "(", "n", ".", "att_feature0_resh", ",", "n", ".", "att_feature1_resh", ")", "\n", "\n", "# merge attention and lstm with compact bilinear pooling", "\n", "n", ".", "att_feature_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "4096", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "#n.lstm_12_resh = L.Reshape(n.lstm_12, reshape_param=dict(shape=dict(dim=[-1,2048,1,1])))", "\n", "n", ".", "bc_att_lstm", "=", "L", ".", "CompactBilinear", "(", "n", ".", "att_feature_resh", ",", "n", ".", "embed_avg_resh", ",", "\n", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "bc_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "bc_att_lstm", ")", "\n", "n", ".", "bc_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "bc_sign_sqrt", ")", "\n", "\n", "n", ".", "bc_dropped", "=", "L", ".", "Dropout", "(", "n", ".", "bc_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "n", ".", "bc_dropped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "bc_dropped", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "16000", "]", ")", ")", ")", "\n", "\n", "n", ".", "prediction", "=", "L", ".", "InnerProduct", "(", "n", ".", "bc_dropped_resh", ",", "num_output", "=", "3000", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "loss", "=", "L", ".", "SoftmaxWithLoss", "(", "n", ".", "prediction", ",", "n", ".", "label", ")", "\n", "return", "n", ".", "to_proto", "(", ")", "\n", "\n", "", "def", "make_answer_vocab", "(", "adic", ",", "vocab_size", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "adict", "=", "{", "''", ":", "0", "}", "\n", "nadict", "=", "{", "''", ":", "1000000", "}", "\n", "vid", "=", "1", "\n", "for", "qid", "in", "adic", ".", "keys", "(", ")", ":", "\n", "        ", "answer_obj", "=", "adic", "[", "qid", "]", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).train_att_bc.make_question_char_vocab": [[147, 163], ["qdic.keys", "vqa_data_provider_layer.VQADataProvider.seq_to_char_list", "cdict.has_key"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.seq_to_char_list"], ["for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", ":", "-", "vocab_size", "]", ")", ":", "\n", "        ", "del", "adict", "[", "w", "[", "0", "]", "]", "\n", "n_del_ans", "+=", "w", "[", "1", "]", "\n", "", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", "-", "vocab_size", ":", "]", ")", ":", "\n", "        ", "n_valid_ans", "+=", "w", "[", "1", "]", "\n", "adict_nid", "[", "w", "[", "0", "]", "]", "=", "i", "\n", "\n", "", "return", "adict_nid", "\n", "\n", "", "def", "make_question_vocab", "(", "qdic", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "vdict", "=", "{", "''", ":", "0", "}", "\n", "vid", "=", "1", "\n", "cdict", "=", "{", "''", ":", "0", "}", "\n", "cvid", "=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).train_att_bc.make_vocab_files": [[164, 177], ["write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_question_char_vocab", "write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_answer_vocab"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.train_att_bc.make_question_char_vocab", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_answer_vocab"], ["for", "qid", "in", "qdic", ".", "keys", "(", ")", ":", "\n", "# sequence to list", "\n", "        ", "q_str", "=", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "\n", "# create dict", "\n", "for", "w", "in", "q_list", ":", "\n", "            ", "if", "not", "vdict", ".", "has_key", "(", "w", ")", ":", "\n", "                ", "vdict", "[", "w", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "", "for", "c", "in", "list", "(", "w", ")", ":", "\n", "                ", "if", "not", "cdict", ".", "has_key", "(", "c", ")", ":", "\n", "                    ", "cdict", "[", "c", "]", "=", "cvid", "\n", "cvid", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).train_att_bc.main": [[179, 245], ["write_to_log.write_log", "write_to_log.write_log", "caffe.set_device", "caffe.set_mode_gpu", "caffe.get_solver", "numpy.zeros", "range", "os.path.exists", "os.makedirs", "os.path.exists", "os.path.exists", "write_to_log.write_log", "train_att_bc.make_vocab_files", "open", "f.write", "open", "f.write", "caffe.get_solver.step", "open", "json.load", "open", "json.load", "open", "json.dump", "open", "json.dump", "str", "str", "str", "str", "write_to_log.write_log", "write_to_log.write_log", "train_loss[].mean", "write_to_log.write_log", "caffe.get_solver.test_nets[].save", "write_to_log.write_log", "visualize_tools.exec_validation", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "train_att_bc.qlstm", "train_att_bc.qlstm", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_vocab_files", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.exec_validation", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["", "", "", "", "return", "vdict", ",", "cdict", "\n", "\n", "", "def", "make_vocab_files", "(", ")", ":", "\n", "    ", "\"\"\"\n    Produce the question and answer vocabulary files.\n    \"\"\"", "\n", "write_log", "(", "'making question vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "write_log", "(", "'making question character vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "qdic", ",", "_", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "QUESTION_VOCAB_SPACE", ")", "\n", "question_vocab", ",", "question_char_vocab", "=", "make_question_vocab", "(", "qdic", ")", "\n", "write_log", "(", "'making answer vocab... '", "+", "config", ".", "ANSWER_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "_", ",", "adic", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "ANSWER_VOCAB_SPACE", ")", "\n", "answer_vocab", "=", "make_answer_vocab", "(", "adic", ",", "config", ".", "NUM_OUTPUT_UNITS", ")", "\n", "return", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "'./result'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'./result'", ")", "\n", "\n", "", "question_vocab", ",", "answer_vocab", "=", "{", "}", ",", "{", "}", "\n", "if", "os", ".", "path", ".", "exists", "(", "'./result/cdict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/adict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/vdict.json'", ")", ":", "\n", "        ", "write_log", "(", "'restoring vocab'", ",", "'log.txt'", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_char_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "answer_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "=", "make_vocab_files", "(", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_char_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "answer_vocab", ",", "f", ")", "\n", "\n", "", "", "write_log", "(", "'question character vocab size: '", "+", "str", "(", "len", "(", "question_char_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'question vocab size: '", "+", "str", "(", "len", "(", "question_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'answer vocab size: '", "+", "str", "(", "len", "(", "answer_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "\n", "\n", "with", "open", "(", "'./result/proto_train.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "config", ".", "TRAIN_DATA_SPLITS", ",", "config", ".", "BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "with", "open", "(", "'./result/proto_test.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "'val'", ",", "config", ".", "VAL_BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "caffe", ".", "set_device", "(", "config", ".", "GPU_ID", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "solver", "=", "caffe", ".", "get_solver", "(", "'./qlstm_solver.prototxt'", ")", "\n", "\n", "train_loss", "=", "np", ".", "zeros", "(", "config", ".", "MAX_ITERATIONS", ")", "\n", "# results = []", "\n", "\n", "for", "it", "in", "range", "(", "config", ".", "MAX_ITERATIONS", ")", ":", "\n", "        ", "solver", ".", "step", "(", "1", ")", "\n", "\n", "# store the train loss", "\n", "train_loss", "[", "it", "]", "=", "solver", ".", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", "\n", "\n", "if", "it", "!=", "0", "and", "it", "%", "config", ".", "PRINT_INTERVAL", "==", "0", ":", "\n", "            ", "write_log", "(", "'------------------------------------'", ",", "'log.txt'", ")", "\n", "write_log", "(", "'Iteration: '", "+", "str", "(", "it", ")", ",", "'log.txt'", ")", "\n", "c_mean_loss", "=", "train_loss", "[", "it", "-", "config", ".", "PRINT_INTERVAL", ":", "it", "]", ".", "mean", "(", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).visualize_tools.visualize_failures": [[27, 119], ["write_to_log.write_log", "visualize_tools.visualize_failures.save_qtype"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["def", "visualize_failures", "(", "stat_list", ",", "mode", ")", ":", "\n", "\n", "    ", "def", "save_qtype", "(", "qtype_list", ",", "save_filename", ",", "mode", ")", ":", "\n", "\n", "        ", "if", "mode", "==", "'val'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./eval'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/val2014'", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test-dev'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "elif", "mode", "==", "'test'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unsupported mode'", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "shutil", ".", "rmtree", "(", "savepath", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "os", ".", "makedirs", "(", "savepath", ")", "\n", "\n", "for", "qt", "in", "qtype_list", ":", "\n", "            ", "count", "=", "0", "\n", "for", "t_question", "in", "stat_list", ":", "\n", "#print count, t_question", "\n", "                ", "if", "count", "<", "40", "/", "len", "(", "qtype_list", ")", ":", "\n", "                    ", "t_question_list", "=", "t_question", "[", "'q_list'", "]", "\n", "saveflag", "=", "False", "\n", "#print 'debug****************************'", "\n", "#print qt", "\n", "#print t_question_list", "\n", "#print t_question_list[0] == qt[0]", "\n", "#print t_question_list[1] == qt[1]", "\n", "if", "t_question_list", "[", "0", "]", "==", "qt", "[", "0", "]", "and", "t_question_list", "[", "1", "]", "==", "qt", "[", "1", "]", ":", "\n", "                        ", "saveflag", "=", "True", "\n", "", "else", ":", "\n", "                        ", "saveflag", "=", "False", "\n", "\n", "", "if", "saveflag", "==", "True", ":", "\n", "                        ", "t_iid", "=", "t_question", "[", "'iid'", "]", "\n", "if", "mode", "==", "'val'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_val2014_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "", "elif", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_test2015_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "\n", "# for caption", "\n", "#print t_iid", "\n", "#annIds = caps.getAnnIds(t_iid)", "\n", "#anns = caps.loadAnns(annIds)", "\n", "#cap_list = [ann['caption'] for ann in anns]", "\n", "", "ans_list", "=", "t_question", "[", "'ans_list'", "]", "\n", "draw", "=", "ImageDraw", ".", "Draw", "(", "t_img", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ans_list", ")", ")", ":", "\n", "                            ", "try", ":", "\n", "                                ", "draw", ".", "text", "(", "(", "10", ",", "10", "*", "i", ")", ",", "str", "(", "ans_list", "[", "i", "]", ")", ")", "\n", "", "except", ":", "\n", "                                ", "pass", "\n", "\n", "", "", "ans", "=", "t_question", "[", "'answer'", "]", "\n", "pred", "=", "t_question", "[", "'pred'", "]", "\n", "if", "ans", "==", "-", "1", ":", "\n", "                            ", "pre", "=", "''", "\n", "", "elif", "ans", "==", "pred", ":", "\n", "                            ", "pre", "=", "'correct  '", "\n", "", "else", ":", "\n", "                            ", "pre", "=", "'failure  '", "\n", "#print ' aaa ', ans, pred", "\n", "", "ans", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "ans", ")", ")", "\n", "pred", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "pred", ")", ")", "\n", "img_title", "=", "pre", "+", "str", "(", "' '", ".", "join", "(", "t_question_list", ")", ")", "+", "'.  a_'", "+", "str", "(", "ans", ")", "+", "' p_'", "+", "str", "(", "pred", ")", "+", "'.png'", "\n", "count", "+=", "1", "\n", "write_log", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ",", "'visualize_log.txt'", ")", "\n", "t_img", ".", "save", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ")", "\n", "\n", "", "", "", "", "", "write_log", "(", "'saving colors'", ",", "'visualize_log.txt'", ")", "\n", "qt_color_list", "=", "[", "[", "'what'", ",", "'color'", "]", "]", "\n", "save_qtype", "(", "qt_color_list", ",", "'colors'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving what is'", ",", "'visualize_log.txt'", ")", "\n", "qt_whatis_list", "=", "[", "[", "'what'", ",", "'is'", "]", ",", "[", "'what'", ",", "'kind'", "]", ",", "[", "'what'", ",", "'are'", "]", "]", "\n", "save_qtype", "(", "qt_whatis_list", ",", "'whatis'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving is'", ",", "'visualize_log.txt'", ")", "\n", "qt_is_list", "=", "[", "[", "'is'", ",", "'the'", "]", ",", "[", "'is'", ",", "'this'", "]", ",", "[", "'is'", ",", "'there'", "]", "]", "\n", "save_qtype", "(", "qt_is_list", ",", "'is'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving how many'", ",", "'visualize_log.txt'", ")", "\n", "qt_howmany_list", "=", "[", "[", "'how'", ",", "'many'", "]", "]", "\n", "save_qtype", "(", "qt_howmany_list", ",", "'howmany'", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).visualize_tools.exec_validation": [[120, 200], ["caffe.set_device", "caffe.set_mode_gpu", "caffe.Net", "vqa_data_provider_layer.VQADataProvider", "len", "numpy.array().mean", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "vqa_data_provider_layer.VQADataProvider.get_batch_vec", "caffe.Net.forward", "caffe.Net.blobs[].data.argmax", "testloss_list.append", "zip", "vqaTools.vqa.VQA", "vqaTools.vqa.VQA.loadRes", "vqaEvaluation.vqaEval.VQAEval", "vqaEvaluation.vqaEval.VQAEval.evaluate", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "t_answer.tolist", "pred_list.append", "numpy.array", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "stat_list.append", "open", "json.dump", "visualize_tools.visualize_failures", "int", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "str().zfill", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "str().zfill", "xrange", "str", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.forward", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj"], ["", "def", "exec_validation", "(", "device_id", ",", "mode", ",", "it", "=", "''", ",", "visualize", "=", "False", ")", ":", "\n", "\n", "    ", "caffe", ".", "set_device", "(", "device_id", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "net", "=", "caffe", ".", "Net", "(", "'./result/proto_test.prototxt'", ",", "'./result/tmp.caffemodel'", ",", "caffe", ".", "TEST", ")", "\n", "\n", "dp", "=", "VQADataProvider", "(", "mode", "=", "mode", ",", "batchsize", "=", "config", ".", "VAL_BATCH_SIZE", ")", "\n", "total_questions", "=", "len", "(", "dp", ".", "getQuesIds", "(", ")", ")", "\n", "epoch", "=", "0", "\n", "\n", "pred_list", "=", "[", "]", "\n", "testloss_list", "=", "[", "]", "\n", "stat_list", "=", "[", "]", "\n", "\n", "while", "epoch", "==", "0", ":", "\n", "        ", "t_word", ",", "t_cont", ",", "t_word_c", ",", "t_cont_c", ",", "t_img_feature", ",", "t_answer", ",", "t_qid_list", ",", "t_iid_list", ",", "epoch", "=", "dp", ".", "get_batch_vec", "(", ")", "\n", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "...", "]", "=", "t_word", "# np.transpose(t_word,(1,0))", "\n", "net", ".", "blobs", "[", "'cont'", "]", ".", "data", "[", "...", "]", "=", "t_cont", "# np.transpose(t_cont,(1,0))", "\n", "net", ".", "blobs", "[", "'data1'", "]", ".", "data", "[", "...", "]", "=", "t_word_c", "\n", "net", ".", "blobs", "[", "'cont1'", "]", ".", "data", "[", "...", "]", "=", "t_cont_c", "\n", "net", ".", "blobs", "[", "'img_feature'", "]", ".", "data", "[", "...", "]", "=", "t_img_feature", "\n", "net", ".", "blobs", "[", "'label'", "]", ".", "data", "[", "...", "]", "=", "t_answer", "\n", "#net.blobs['glove'].data[...] = t_glove_matrix # np.transpose(t_glove_matrix, (1,0,2))", "\n", "net", ".", "forward", "(", ")", "\n", "t_pred_list", "=", "net", ".", "blobs", "[", "'prediction'", "]", ".", "data", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "t_pred_str", "=", "[", "dp", ".", "vec_to_answer", "(", "pred_symbol", ")", "for", "pred_symbol", "in", "t_pred_list", "]", "\n", "testloss_list", ".", "append", "(", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", ")", "\n", "for", "qid", ",", "iid", ",", "ans", ",", "pred", "in", "zip", "(", "t_qid_list", ",", "t_iid_list", ",", "t_answer", ".", "tolist", "(", ")", ",", "t_pred_str", ")", ":", "\n", "            ", "pred_list", ".", "append", "(", "{", "u'answer'", ":", "pred", ",", "u'question_id'", ":", "int", "(", "dp", ".", "getStrippedQuesId", "(", "qid", ")", ")", "}", ")", "\n", "if", "visualize", ":", "\n", "                ", "q_list", "=", "dp", ".", "seq_to_list", "(", "dp", ".", "getQuesStr", "(", "qid", ")", ")", "\n", "if", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                    ", "ans_str", "=", "''", "\n", "ans_list", "=", "[", "''", "]", "*", "10", "\n", "", "else", ":", "\n", "                    ", "ans_str", "=", "dp", ".", "vec_to_answer", "(", "ans", ")", "\n", "ans_list", "=", "[", "dp", ".", "getAnsObj", "(", "qid", ")", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "", "stat_list", ".", "append", "(", "{", "'qid'", ":", "qid", ",", "\n", "'q_list'", ":", "q_list", ",", "\n", "'iid'", ":", "iid", ",", "\n", "'answer'", ":", "ans_str", ",", "\n", "'ans_list'", ":", "ans_list", ",", "\n", "'pred'", ":", "pred", "}", ")", "\n", "#percent = 100 * float(len(pred_list)) / total_questions", "\n", "#sys.stdout.write('\\r' + ('%.2f' % percent) + '%')", "\n", "#sys.stdout.flush()", "\n", "\n", "\n", "\n", "", "", "", "mean_testloss", "=", "np", ".", "array", "(", "testloss_list", ")", ".", "mean", "(", ")", "\n", "\n", "if", "mode", "==", "'val'", ":", "\n", "        ", "valFile", "=", "'./result/val2014_resfile'", "\n", "with", "open", "(", "valFile", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "annFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ans_file'", "]", "\n", "quesFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ques_file'", "]", "\n", "vqa", "=", "VQA", "(", "annFile", ",", "quesFile", ")", "\n", "vqaRes", "=", "vqa", ".", "loadRes", "(", "valFile", ",", "quesFile", ")", "\n", "vqaEval", "=", "VQAEval", "(", "vqa", ",", "vqaRes", ",", "n", "=", "2", ")", "\n", "vqaEval", ".", "evaluate", "(", ")", "\n", "acc_overall", "=", "vqaEval", ".", "accuracy", "[", "'overall'", "]", "\n", "acc_perQuestionType", "=", "vqaEval", ".", "accuracy", "[", "'perQuestionType'", "]", "\n", "acc_perAnswerType", "=", "vqaEval", ".", "accuracy", "[", "'perAnswerType'", "]", "\n", "return", "mean_testloss", ",", "acc_overall", ",", "acc_perQuestionType", ",", "acc_perAnswerType", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test-dev2015_v3t'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "", "elif", "mode", "==", "'test'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test2015_v3c'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char).visualize_tools.drawgraph": [[201, 269], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.twinx", "fig.add_subplot.plot", "fig.add_subplot.plot", "ax1.twinx.plot", "matplotlib.legend", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "ax1.twinx.set_ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "numpy.array", "numpy.array", "matplotlib.figure", "matplotlib.legend", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "sorted", "visualize_tools.drawgraph.draw_qt_acc"], "function", ["None"], ["            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "\n", "", "", "", "def", "drawgraph", "(", "results", ",", "save_question_type_graphs", "=", "False", ")", ":", "\n", "# 0:it", "\n", "# 1:trainloss", "\n", "# 2:testloss", "\n", "# 3:oa_acc", "\n", "# 4:qt_acc", "\n", "# 5:at_acc", "\n", "\n", "# training curve", "\n", "    ", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "loss", "=", "np", ".", "array", "(", "[", "l", "[", "1", "]", "for", "l", "in", "results", "]", ")", "\n", "valloss", "=", "np", ".", "array", "(", "[", "l", "[", "2", "]", "for", "l", "in", "results", "]", ")", "\n", "valacc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax1", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "ax2", "=", "ax1", ".", "twinx", "(", ")", "\n", "\n", "ax1", ".", "plot", "(", "it", ",", "loss", ",", "color", "=", "'blue'", ",", "label", "=", "'train loss'", ")", "\n", "ax1", ".", "plot", "(", "it", ",", "valloss", ",", "'--'", ",", "color", "=", "'blue'", ",", "label", "=", "'test loss'", ")", "\n", "ax2", ".", "plot", "(", "it", ",", "valacc", ",", "color", "=", "'red'", ",", "label", "=", "'acc on val'", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'lower left'", ")", "\n", "\n", "ax1", ".", "set_xlabel", "(", "'Iterations'", ")", "\n", "ax1", ".", "set_ylabel", "(", "'Loss Value'", ")", "\n", "ax2", ".", "set_ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "'./learning_curve max_%2.2f.png'", "%", "valacc", ".", "max", "(", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "# question type", "\n", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "oa_acc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "qt_dic_list", "=", "[", "l", "[", "4", "]", "for", "l", "in", "results", "]", "\n", "\n", "def", "draw_qt_acc", "(", "target_key_list", ",", "figname", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "for", "k", "in", "target_key_list", ":", "\n", "            ", "write_log", "(", "str", "(", "k", ")", "+", "str", "(", "type", "(", "k", ")", ")", ",", "'visualize_log.txt'", ")", "\n", "t_val", "=", "np", ".", "array", "(", "[", "qt_dic", "[", "k", "]", "for", "qt_dic", "in", "qt_dic_list", "]", ")", "\n", "plt", ".", "plot", "(", "it", ",", "t_val", ",", "label", "=", "str", "(", "k", ")", ")", "\n", "", "plt", ".", "legend", "(", "fontsize", "=", "'small'", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "100.", ")", "\n", "#plt.legend(prop={'size':6})", "\n", "\n", "plt", ".", "xlabel", "(", "'Iterations'", ")", "\n", "plt", ".", "ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "figname", ",", "dpi", "=", "200", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "", "if", "save_question_type_graphs", ":", "\n", "        ", "s_keys", "=", "sorted", "(", "qt_dic_list", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "0", ":", "13", "]", "+", "[", "s_keys", "[", "31", "]", ",", "]", ",", "'./ind_qt_are.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "13", ":", "17", "]", "+", "s_keys", "[", "49", ":", "]", ",", "'./ind_qt_how_where_who_why.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "17", ":", "31", "]", "+", "[", "s_keys", "[", "32", "]", ",", "]", ",", "'./ind_qt_is.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "33", ":", "49", "]", ",", "'./ind_qt_what.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what color is the'", ",", "'what color are the'", ",", "'what color is'", ",", "'what color'", ",", "'what is the color of the'", "]", ",", "'./qt_color.png'", ")", "\n", "draw_qt_acc", "(", "[", "'how many'", ",", "'how'", ",", "'how many people are'", ",", "'how many people are in'", "]", ",", "'./qt_number.png'", ")", "\n", "draw_qt_acc", "(", "[", "'who is'", ",", "'why'", ",", "'why is the'", ",", "'where is the'", ",", "'where are the'", ",", "'which'", "]", ",", "'./qt_who_why_where_which.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what is the man'", ",", "'is the man'", ",", "'are they'", ",", "'is he'", ",", "'is the woman'", ",", "'is this person'", ",", "'what is the woman'", ",", "'is the person'", ","]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.write_to_log.write_log": [[1, 4], ["open", "f.write"], "function", ["None"], ["def", "write_log", "(", "str", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "+", "\"\\n\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.__init__": [[13, 30], ["vqa_data_provider_layer.VQADataProvider.load_data", "len", "open", "json.load", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data"], ["    ", "def", "__init__", "(", "self", ",", "batchsize", "=", "64", ",", "max_length", "=", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "max_w_length", "=", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "batchsize", "\n", "self", ".", "d_vocabulary", "=", "None", "\n", "self", ".", "batch_index", "=", "None", "\n", "self", ".", "batch_len", "=", "None", "\n", "self", ".", "rev_adict", "=", "None", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "max_w_length", "=", "max_w_length", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "qdic", ",", "self", ".", "adic", "=", "VQADataProvider", ".", "load_data", "(", "mode", ")", "\n", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "cdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "vdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "adict", "=", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.load_vqa_json": [[33, 56], ["write_to_log.write_log", "open", "json.load", "open", "json.load", "str", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["#self.glove_dict = {} # word -> glove vector", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_vqa_json", "(", "data_split", ")", ":", "\n", "        ", "\"\"\"\n        Parses the question and answer json files for the given data split. \n        Returns the question dictionary and the answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ques_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "[", "'questions'", "]", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "qdic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'question_id'", "]", ")", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image_id'", "]", "}", "\n", "\n", "", "", "if", "'test'", "not", "in", "data_split", ":", "\n", "            ", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ans_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "adata", "=", "json", ".", "load", "(", "f", ")", "[", "'annotations'", "]", "\n", "for", "a", "in", "adata", ":", "\n", "                    ", "adic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "a", "[", "'question_id'", "]", ")", "]", "=", "a", "[", "'answers'", "]", "\n", "\n", "", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for '", "+", "data_split", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.load_genome_json": [[57, 74], ["write_to_log.write_log", "open", "json.load", "str", "str", "len"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_genome_json", "(", ")", ":", "\n", "        ", "\"\"\"\n        Parses the genome json file. Returns the question dictionary and the\n        answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'genome_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "key", "=", "'genome'", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'id'", "]", ")", "\n", "qdic", "[", "key", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image'", "]", "}", "\n", "adic", "[", "key", "]", "=", "[", "{", "'answer'", ":", "q", "[", "'answer'", "]", "}", "]", "\n", "\n", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for genome'", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.load_data": [[75, 101], ["data_split_str.split", "config.DATA_PATHS.keys", "vqa_data_provider_layer.VQADataProvider.load_genome_json", "all_qdic.update", "all_adic.update", "vqa_data_provider_layer.VQADataProvider.load_vqa_json", "all_qdic.update", "all_adic.update"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_genome_json", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_vqa_json"], ["return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_data", "(", "data_split_str", ")", ":", "\n", "        ", "all_qdic", ",", "all_adic", "=", "{", "}", ",", "{", "}", "\n", "for", "data_split", "in", "data_split_str", ".", "split", "(", "'+'", ")", ":", "\n", "            ", "assert", "data_split", "in", "config", ".", "DATA_PATHS", ".", "keys", "(", ")", ",", "'unknown data split'", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_genome_json", "(", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "", "else", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_vqa_json", "(", "data_split", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "\n", "", "", "return", "all_qdic", ",", "all_adic", "\n", "\n", "", "def", "getQuesIds", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "qdic", ".", "keys", "(", ")", "\n", "\n", "", "def", "getStrippedQuesId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "[", "1", "]", "\n", "\n", "", "def", "getImgId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'iid'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.getQuesIds": [[102, 104], ["vqa_data_provider_layer.VQADataProvider.qdic.keys"], "methods", ["None"], ["", "def", "getQuesStr", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.getStrippedQuesId": [[105, 107], ["qid.split"], "methods", ["None"], ["", "def", "getAnsObj", "(", "self", ",", "qid", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.getImgId": [[108, 110], ["None"], "methods", ["None"], ["", "return", "self", ".", "adic", "[", "qid", "]", "\n", "\n", "", "@", "staticmethod", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.getQuesStr": [[111, 113], ["None"], "methods", ["None"], ["def", "seq_to_list", "(", "s", ")", ":", "\n", "        ", "t_str", "=", "s", ".", "lower", "(", ")", "\n", "for", "i", "in", "[", "r'\\?'", ",", "r'\\!'", ",", "r'\\''", ",", "r'\\\"'", ",", "r'\\$'", ",", "r'\\:'", ",", "r'\\@'", ",", "r'\\('", ",", "r'\\)'", ",", "r'\\,'", ",", "r'\\.'", ",", "r'\\;'", "]", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.getAnsObj": [[114, 118], ["None"], "methods", ["None"], ["            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "''", ",", "t_str", ")", "\n", "", "for", "i", "in", "[", "r'\\-'", ",", "r'\\/'", "]", ":", "\n", "            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "' '", ",", "t_str", ")", "\n", "", "q_list", "=", "re", ".", "sub", "(", "r'\\?'", ",", "''", ",", "t_str", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "\n", "q_list", "=", "filter", "(", "lambda", "x", ":", "len", "(", "x", ")", ">", "0", ",", "q_list", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.seq_to_list": [[119, 129], ["s.lower", "re.sub().split", "filter", "re.sub", "re.sub", "re.sub", "re.sub.lower", "len"], "methods", ["None"], ["return", "q_list", "\n", "\n", "", "def", "extract_answer", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "", "answer_list", "=", "[", "answer_obj", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "dic", "=", "{", "}", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "dic", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "dic", "[", "ans", "]", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.extract_answer": [[130, 143], ["dic.has_key", "max", "xrange", "dic.items"], "methods", ["None"], ["", "else", ":", "\n", "                ", "dic", "[", "ans", "]", "=", "1", "\n", "", "", "max_key", "=", "max", "(", "(", "v", ",", "k", ")", "for", "(", "k", ",", "v", ")", "in", "dic", ".", "items", "(", ")", ")", "[", "1", "]", "\n", "return", "max_key", "\n", "\n", "", "def", "extract_answer_prob", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "prob_answer_list", "=", "[", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.extract_answer_prob": [[144, 162], ["vqa_data_provider_layer.VQADataProvider.adict.has_key", "len", "random.choice", "prob_answer_list.append", "Exception"], "methods", ["None"], ["                ", "prob_answer_list", ".", "append", "(", "ans", ")", "\n", "\n", "", "", "if", "len", "(", "prob_answer_list", ")", "==", "0", ":", "\n", "            ", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "return", "'hoge'", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"This should not happen.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "random", ".", "choice", "(", "prob_answer_list", ")", "\n", "\n", "# def qlist_to_vec(self, max_length, q_list):", "\n", "#     \"\"\"", "\n", "#     Converts a list of words into a format suitable for the embedding layer.", "\n", "\n", "#     Arguments:", "\n", "#     max_length -- the maximum length of a question sequence", "\n", "#     q_list -- a list of words which are the tokens in the question", "\n", "\n", "#     Returns:", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.qlist_to_vec": [[163, 208], ["numpy.zeros", "numpy.zeros", "xrange", "len", "vqa_data_provider_layer.VQADataProvider.vdict.has_key", "len"], "methods", ["None"], ["#     qvec -- A max_length length vector containing one-hot indices for each word", "\n", "#     cvec -- A max_length length sequence continuation indicator vector", "\n", "#     glove_matrix -- A max_length x GLOVE_EMBEDDING_SIZE matrix containing the glove embedding for", "\n", "#         each word", "\n", "#     \"\"\"", "\n", "#     qvec = np.zeros(max_length)", "\n", "#     cvec = np.zeros(max_length)", "\n", "#     glove_matrix = np.zeros(max_length * GLOVE_EMBEDDING_SIZE).reshape(max_length, GLOVE_EMBEDDING_SIZE)", "\n", "#     for i in xrange(max_length):", "\n", "#         if i < max_length - len(q_list):", "\n", "#             cvec[i] = 0", "\n", "#         else:", "\n", "#             w = q_list[i-(max_length-len(q_list))]", "\n", "#             if w not in self.glove_dict:", "\n", "#                 self.glove_dict[w] = self.nlp(u'%s' % w).vector", "\n", "#             glove_matrix[i] = self.glove_dict[w]", "\n", "#             # is the word in the vocabulary?", "\n", "#             if self.vdict.has_key(w) is False:", "\n", "#                 w = ''", "\n", "#             qvec[i] = self.vdict[w]", "\n", "#             cvec[i] = 1 #0 if i == max_length - len(q_list) else 1", "\n", "#             # UPDATE_10/12:", "\n", "#             #It seems that the original way is right for lstm.", "\n", "#             '''", "\n", "#             This is from https://github.com/BVLC/caffe/pull/1873.", "\n", "#             \"delta_{t,n} should be a binary indicator (i.e., value in {0, 1}),", "\n", "#             where a value of 0 means that timestep t of stream n is the beginning of a new sequence,", "\n", "#             and a value of 1 means that timestep t of stream n is continuing the sequence from timestep t-1 of stream n.", "\n", "#             Under the hood, the previous timestep's hidden state is multiplied by these delta values.", "\n", "#             The fact that these indicators are specified on a per-timestep and per-stream basis allows for streams of arbitrary different lengths without any padding or truncation.", "\n", "#             At the beginning of the forward pass, the final hidden state from the previous forward pass (h_T) is copied into the initial hidden state for the new forward pass (h_0),", "\n", "#             allowing for exact inference across arbitrarily long sequences, even if T == 1.", "\n", "#             However, if any sequences cross batch boundaries, backpropagation through time is approximate -- it is truncated along the batch boundaries.\"", "\n", "#             '''", "\n", "#             # I think the original way is false for CNN here. I want to keep the word embedding for unknown word as zero vector.", "\n", "#             # For example, if we have a sentence of length 7, there would be only 6 1's in cvec.", "\n", "\n", "#     return qvec, cvec, glove_matrix", "\n", "\n", "", "", "def", "qlist_to_vec", "(", "self", ",", "max_length", ",", "max_w_length", ",", "q_list", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.answer_to_vec": [[209, 219], ["vqa_data_provider_layer.VQADataProvider.adict.has_key"], "methods", ["None"], ["\n", "qvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "cvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "qcvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.vec_to_answer": [[220, 229], ["vqa_data_provider_layer.VQADataProvider.adict.items"], "methods", ["None"], ["ccvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "for", "i", "in", "xrange", "(", "max_length", ")", ":", "\n", "            ", "if", "i", "<", "max_length", "-", "len", "(", "q_list", ")", ":", "\n", "                ", "cvec", "[", "i", "]", "=", "0", "\n", "", "else", ":", "\n", "                ", "w", "=", "q_list", "[", "i", "-", "(", "max_length", "-", "len", "(", "q_list", ")", ")", "]", "\n", "# is the word in the vocabulary?", "\n", "if", "self", ".", "vdict", ".", "has_key", "(", "w", ")", "is", "False", ":", "\n", "                    ", "w", "=", "''", "\n", "", "qvec", "[", "i", "]", "=", "self", ".", "vdict", "[", "w", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.create_batch": [[230, 277], ["numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "enumerate", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "vqa_data_provider_layer.VQADataProvider.answer_to_vec", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "qid.split", "vqa_data_provider_layer.VQADataProvider.extract_answer", "vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "numpy.sqrt", "write_to_log.write_log", "numpy.load", "numpy.load", "str", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.answer_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["cvec", "[", "i", "]", "=", "1.0", "/", "len", "(", "q_list", ")", "\n", "j", "=", "max_w_length", "*", "i", "\n", "w_list", "=", "list", "(", "w", ")", "\n", "for", "k", "in", "xrange", "(", "max_w_length", ")", ":", "\n", "                    ", "if", "k", "<", "max_w_length", "-", "len", "(", "w_list", ")", ":", "\n", "                        ", "ccvec", "[", "j", "+", "k", "]", "=", "0", "\n", "", "else", ":", "\n", "                        ", "c", "=", "w_list", "[", "k", "-", "(", "max_w_length", "-", "len", "(", "w_list", ")", ")", "]", "\n", "# is the char in the vocabulary?", "\n", "if", "self", ".", "cdict", ".", "has_key", "(", "c", ")", "is", "False", ":", "\n", "                            ", "c", "=", "''", "\n", "", "qcvec", "[", "j", "+", "k", "]", "=", "self", ".", "cdict", "[", "c", "]", "\n", "ccvec", "[", "j", "+", "k", "]", "=", "1.0", "/", "len", "(", "w_list", ")", "\n", "", "", "", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", "\n", "\n", "", "def", "answer_to_vec", "(", "self", ",", "ans_str", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "if", "self", ".", "adict", ".", "has_key", "(", "ans_str", ")", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "ans_str", "]", "\n", "", "else", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "''", "]", "\n", "", "return", "ans", "\n", "\n", "", "def", "vec_to_answer", "(", "self", ",", "ans_symbol", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "rev_adict", "is", "None", ":", "\n", "            ", "rev_adict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "adict", ".", "items", "(", ")", ":", "\n", "                ", "rev_adict", "[", "v", "]", "=", "k", "\n", "", "self", ".", "rev_adict", "=", "rev_adict", "\n", "\n", "", "return", "self", ".", "rev_adict", "[", "ans_symbol", "]", "\n", "\n", "", "def", "create_batch", "(", "self", ",", "qid_list", ")", ":", "\n", "\n", "        ", "qvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "cvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "qcvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ccvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ivec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "2048", "*", "14", "*", "14", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "2048", ",", "14", ",", "14", ")", "\n", "avec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ")", "\n", "#glove_matrix = np.zeros(self.batchsize * self.max_length * GLOVE_EMBEDDING_SIZE).reshape(\\", "\n", "#self.batchsize, self.max_length, GLOVE_EMBEDDING_SIZE)", "\n", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProvider.get_batch_vec": [[279, 326], ["vqa_data_provider_layer.VQADataProvider.create_batch", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "random.shuffle", "len", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.adict.has_key", "t_qid_list.append", "t_iid_list.append", "vqa_data_provider_layer.VQADataProvider.get_batch_vec.has_at_least_one_valid_answer"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.create_batch", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId"], ["# load raw question information", "\n", "            ", "q_str", "=", "self", ".", "getQuesStr", "(", "qid", ")", "\n", "q_ans", "=", "self", ".", "getAnsObj", "(", "qid", ")", "\n", "q_iid", "=", "self", ".", "getImgId", "(", "qid", ")", "\n", "\n", "# convert question to vec", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "t_qvec", ",", "t_cvec", ",", "t_qcvec", ",", "t_ccvec", "=", "self", ".", "qlist_to_vec", "(", "self", ".", "max_length", ",", "self", ".", "max_w_length", ",", "q_list", ")", "\n", "\n", "try", ":", "\n", "                ", "qid_split", "=", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "\n", "data_split", "=", "qid_split", "[", "0", "]", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "else", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "t_ivec", "=", "(", "t_ivec", "/", "np", ".", "sqrt", "(", "(", "t_ivec", "**", "2", ")", ".", "sum", "(", ")", ")", ")", "\n", "", "except", ":", "\n", "                ", "t_ivec", "=", "0.", "\n", "write_log", "(", "'data not found for qid : '", "+", "str", "(", "q_iid", ")", "+", "' '", "+", "self", ".", "mode", ",", "'log.txt'", ")", "\n", "\n", "# convert answer to vec", "\n", "", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer", "(", "q_ans", ")", "\n", "", "else", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer_prob", "(", "q_ans", ")", "\n", "", "t_avec", "=", "self", ".", "answer_to_vec", "(", "q_ans_str", ")", "\n", "\n", "qvec", "[", "i", ",", "...", "]", "=", "t_qvec", "\n", "cvec", "[", "i", ",", "...", "]", "=", "t_cvec", "\n", "qcvec", "[", "i", ",", "...", "]", "=", "t_qcvec", "\n", "ccvec", "[", "i", ",", "...", "]", "=", "t_ccvec", "\n", "ivec", "[", "i", ",", "...", "]", "=", "t_ivec", "\n", "avec", "[", "i", ",", "...", "]", "=", "t_avec", "\n", "#glove_matrix[i,...] = t_glove_matrix", "\n", "\n", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", ",", "ivec", ",", "avec", "#, glove_matrix", "\n", "\n", "\n", "", "def", "get_batch_vec", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "batch_len", "is", "None", ":", "\n", "            ", "self", ".", "n_skipped", "=", "0", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_len", "=", "len", "(", "qid_list", ")", "\n", "self", ".", "batch_index", "=", "0", "\n", "self", ".", "epoch_counter", "=", "0", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProviderLayer.setup": [[333, 348], ["top[].reshape", "top[].reshape", "top[].reshape", "top[].reshape", "json.loads", "json.loads", "vqa_data_provider_layer.VQADataProvider"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape"], ["                    ", "return", "True", "\n", "\n", "", "", "", "counter", "=", "0", "\n", "t_qid_list", "=", "[", "]", "\n", "t_iid_list", "=", "[", "]", "\n", "while", "counter", "<", "self", ".", "batchsize", ":", "\n", "            ", "t_qid", "=", "self", ".", "qid_list", "[", "self", ".", "batch_index", "]", "\n", "t_iid", "=", "self", ".", "getImgId", "(", "t_qid", ")", "\n", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n", "", "elif", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProviderLayer.reshape": [[349, 351], ["None"], "methods", ["None"], ["", "else", ":", "\n", "                ", "self", ".", "n_skipped", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProviderLayer.forward": [[352, 362], ["vqa_data_provider_layer.VQADataProviderLayer.dp.get_batch_vec"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec"], ["", "if", "self", ".", "batch_index", "<", "self", ".", "batch_len", "-", "1", ":", "\n", "                ", "self", ".", "batch_index", "+=", "1", "\n", "", "else", ":", "\n", "                ", "self", ".", "epoch_counter", "+=", "1", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_index", "=", "0", "\n", "write_log", "(", "\"%d questions were skipped in a single epoch\"", "%", "self", ".", "n_skipped", ",", "'log.txt'", ")", "\n", "self", ".", "n_skipped", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.vqa_data_provider_layer.VQADataProviderLayer.backward": [[364, 366], ["None"], "methods", ["None"], ["return", "t_batch", "+", "(", "t_qid_list", ",", "t_iid_list", ",", "self", ".", "epoch_counter", ")", "\n", "\n", "", "", "class", "VQADataProviderLayer", "(", "caffe", ".", "Layer", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.train_att_bc.qlstm": [[19, 98], ["caffe.NetSpec", "json.dumps", "caffe.layers.Python", "caffe.layers.Embed", "caffe.layers.Scale", "caffe.layers.Reshape", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.ReLU", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Concat", "caffe.layers.Dropout", "caffe.layers.Tile", "caffe.layers.Tile", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.Reshape", "caffe.layers.Softmax", "caffe.layers.Reshape", "caffe.layers.Slice", "caffe.layers.DummyData", "caffe.layers.SoftAttention", "caffe.layers.SoftAttention", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Concat", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Reshape", "caffe.layers.InnerProduct", "caffe.layers.SoftmaxWithLoss", "caffe.NetSpec.to_proto", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "config.TRAIN_DATA_SPLITS", "config.BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION", "config.VAL_BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION"], "function", ["None"], ["def", "qlstm", "(", "mode", ",", "batchsize", ",", "T", ",", "T_c", ",", "question_c_vocab_size", ",", "question_vocab_size", ")", ":", "\n", "    ", "n", "=", "caffe", ".", "NetSpec", "(", ")", "\n", "mode_str", "=", "json", ".", "dumps", "(", "{", "'mode'", ":", "mode", ",", "'batchsize'", ":", "batchsize", "}", ")", "\n", "n", ".", "data", ",", "n", ".", "cont", ",", "n", ".", "data1", ",", "n", ".", "cont1", ",", "n", ".", "img_feature", ",", "n", ".", "label", "=", "L", ".", "Python", "(", "module", "=", "'vqa_data_provider_layer'", ",", "layer", "=", "'VQADataProviderLayer'", ",", "param_str", "=", "mode_str", ",", "ntop", "=", "6", ")", "#5 )", "\n", "\n", "# char embedding", "\n", "n", ".", "embed_c", "=", "L", ".", "Embed", "(", "n", ".", "data1", ",", "input_dim", "=", "question_c_vocab_size", ",", "num_output", "=", "100", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "\n", "n", ".", "embed_c_scale", "=", "L", ".", "Scale", "(", "n", ".", "embed_c", ",", "n", ".", "cont1", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "\n", "n", ".", "embed_c_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_c_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T_c", "*", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T_c*T x d_c x 1", "\n", "tops", "=", "L", ".", "Slice", "(", "n", ".", "embed_c_scale_resh", ",", "ntop", "=", "T", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T_c x d_c x 1", "\n", "for", "i", "in", "xrange", "(", "T", ")", ":", "\n", "        ", "n", ".", "__setattr__", "(", "'Slice_'", "+", "str", "(", "i", "+", "1", ")", ",", "tops", "[", "int", "(", "i", ")", "]", ")", "\n", "\n", "# avg of char embedding", "\n", "", "n", ".", "c_embed_1", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_1", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_2", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_2", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_3", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_3", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_4", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_4", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_5", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_5", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_6", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_6", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_7", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_7", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_8", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_8", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_9", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_9", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_10", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_10", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_11", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_11", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_12", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_12", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_13", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_13", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_14", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_14", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_15", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_15", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_16", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_16", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_17", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_17", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_18", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_18", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_19", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_19", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_20", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_20", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_21", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_21", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_22", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_22", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "\n", "concat_c_embed", "=", "[", "n", ".", "c_embed_1", ",", "n", ".", "c_embed_2", ",", "n", ".", "c_embed_3", ",", "n", ".", "c_embed_4", ",", "n", ".", "c_embed_5", ",", "n", ".", "c_embed_6", ",", "n", ".", "c_embed_7", ",", "n", ".", "c_embed_8", ",", "n", ".", "c_embed_9", ",", "n", ".", "c_embed_10", ",", "n", ".", "c_embed_11", ",", "n", ".", "c_embed_12", ",", "n", ".", "c_embed_13", ",", "n", ".", "c_embed_14", ",", "n", ".", "c_embed_15", ",", "n", ".", "c_embed_16", ",", "n", ".", "c_embed_17", ",", "n", ".", "c_embed_18", ",", "n", ".", "c_embed_19", ",", "n", ".", "c_embed_20", ",", "n", ".", "c_embed_21", ",", "n", ".", "c_embed_22", "]", "\n", "n", ".", "concat_char_embed", "=", "L", ".", "Concat", "(", "*", "concat_c_embed", ",", "concat_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T x d_c x 1", "\n", "n", ".", "concat_char_embed_resh", "=", "L", ".", "Reshape", "(", "n", ".", "concat_char_embed", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", "]", ")", ")", ")", "\n", "\n", "# word embedding", "\n", "n", ".", "embed_w", "=", "L", ".", "Embed", "(", "n", ".", "data", ",", "input_dim", "=", "question_vocab_size", ",", "num_output", "=", "200", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "# N x T x d_w", "\n", "\n", "# combine word and char embedding", "\n", "concat_word_embed", "=", "[", "n", ".", "embed_w", ",", "n", ".", "concat_char_embed_resh", "]", "\n", "n", ".", "concat_embed", "=", "L", ".", "Concat", "(", "*", "concat_word_embed", ",", "concat_param", "=", "{", "'axis'", ":", "2", "}", ")", "# N x T x (d_c+d_w)", "\n", "\n", "n", ".", "embed_scale", "=", "L", ".", "Scale", "(", "n", ".", "concat_embed", ",", "n", ".", "cont", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "# N x T x (d_c+d_w)", "\n", "n", ".", "embed_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T x (d_c+d_w) x 1", "\n", "\n", "# avg of word embedding", "\n", "n", ".", "embed_avg", "=", "L", ".", "Convolution", "(", "n", ".", "embed_scale_resh", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x (d_c+d_w) x 1", "\n", "n", ".", "embed_avg_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_avg", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "300", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled_1", "=", "L", ".", "Tile", "(", "n", ".", "embed_avg_resh", ",", "axis", "=", "2", ",", "tiles", "=", "14", ")", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled", "=", "L", ".", "Tile", "(", "n", ".", "q_emb_tanh_droped_resh_tiled_1", ",", "axis", "=", "3", ",", "tiles", "=", "14", ")", "\n", "n", ".", "i_emb_tanh_droped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "img_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "n", ".", "blcf", "=", "L", ".", "CompactBilinear", "(", "n", ".", "q_emb_tanh_droped_resh_tiled", ",", "n", ".", "i_emb_tanh_droped_resh", ",", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "blcf_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "blcf", ")", "\n", "n", ".", "blcf_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "blcf_sign_sqrt", ")", "\n", "n", ".", "blcf_droped", "=", "L", ".", "Dropout", "(", "n", ".", "blcf_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "\n", "# multi-channel attention", "\n", "n", ".", "att_conv1", "=", "L", ".", "Convolution", "(", "n", ".", "blcf_droped", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "512", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_conv1_relu", "=", "L", ".", "ReLU", "(", "n", ".", "att_conv1", ")", "\n", "n", ".", "att_conv2", "=", "L", ".", "Convolution", "(", "n", ".", "att_conv1_relu", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "2", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_reshaped", "=", "L", ".", "Reshape", "(", "n", ".", "att_conv2", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", "*", "14", "]", ")", ")", ")", "\n", "n", ".", "att_softmax", "=", "L", ".", "Softmax", "(", "n", ".", "att_reshaped", ",", "axis", "=", "2", ")", "\n", "n", ".", "att", "=", "L", ".", "Reshape", "(", "n", ".", "att_softmax", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "att_maps", "=", "L", ".", "Slice", "(", "n", ".", "att", ",", "ntop", "=", "2", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "\n", "n", ".", "att_map0", "=", "att_maps", "[", "0", "]", "\n", "n", ".", "att_map1", "=", "att_maps", "[", "1", "]", "\n", "dummy", "=", "L", ".", "DummyData", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "1", "]", ")", ",", "data_filler", "=", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", ",", "ntop", "=", "1", ")", "\n", "n", ".", "att_feature0", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map0", ",", "dummy", ")", "\n", "n", ".", "att_feature1", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map1", ",", "dummy", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.train_att_bc.make_answer_vocab": [[99, 136], ["adic.keys", "sorted", "enumerate", "enumerate", "nadict.items", "nalist.append", "adict.has_key", "config.NUM_OUTPUT_UNITS"], "function", ["None"], ["n", ".", "att_feature0_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature0", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature1_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature1", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature", "=", "L", ".", "Concat", "(", "n", ".", "att_feature0_resh", ",", "n", ".", "att_feature1_resh", ")", "\n", "\n", "# merge attention and lstm with compact bilinear pooling", "\n", "n", ".", "att_feature_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "4096", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "#n.lstm_12_resh = L.Reshape(n.lstm_12, reshape_param=dict(shape=dict(dim=[-1,2048,1,1])))", "\n", "n", ".", "bc_att_lstm", "=", "L", ".", "CompactBilinear", "(", "n", ".", "att_feature_resh", ",", "n", ".", "embed_avg_resh", ",", "\n", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "bc_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "bc_att_lstm", ")", "\n", "n", ".", "bc_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "bc_sign_sqrt", ")", "\n", "\n", "n", ".", "bc_dropped", "=", "L", ".", "Dropout", "(", "n", ".", "bc_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "n", ".", "bc_dropped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "bc_dropped", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "16000", "]", ")", ")", ")", "\n", "\n", "n", ".", "prediction", "=", "L", ".", "InnerProduct", "(", "n", ".", "bc_dropped_resh", ",", "num_output", "=", "3000", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "loss", "=", "L", ".", "SoftmaxWithLoss", "(", "n", ".", "prediction", ",", "n", ".", "label", ")", "\n", "return", "n", ".", "to_proto", "(", ")", "\n", "\n", "", "def", "make_answer_vocab", "(", "adic", ",", "vocab_size", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "adict", "=", "{", "''", ":", "0", "}", "\n", "nadict", "=", "{", "''", ":", "1000000", "}", "\n", "vid", "=", "1", "\n", "for", "qid", "in", "adic", ".", "keys", "(", ")", ":", "\n", "        ", "answer_obj", "=", "adic", "[", "qid", "]", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "\n", "for", "q_ans", "in", "answer_list", ":", "\n", "# create dict", "\n", "            ", "if", "adict", ".", "has_key", "(", "q_ans", ")", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "=", "1", "\n", "adict", "[", "q_ans", "]", "=", "vid", "\n", "vid", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.train_att_bc.make_question_vocab": [[137, 155], ["qdic.keys", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vdict.has_key"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list"], ["\n", "# debug", "\n", "", "", "", "nalist", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "sorted", "(", "nadict", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ":", "\n", "        ", "nalist", ".", "append", "(", "(", "k", ",", "v", ")", ")", "\n", "\n", "# keep the top 3000 answers", "\n", "", "n_del_ans", "=", "0", "\n", "n_valid_ans", "=", "0", "\n", "adict_nid", "=", "{", "}", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", ":", "-", "vocab_size", "]", ")", ":", "\n", "        ", "del", "adict", "[", "w", "[", "0", "]", "]", "\n", "n_del_ans", "+=", "w", "[", "1", "]", "\n", "", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", "-", "vocab_size", ":", "]", ")", ":", "\n", "        ", "n_valid_ans", "+=", "w", "[", "1", "]", "\n", "adict_nid", "[", "w", "[", "0", "]", "]", "=", "i", "\n", "\n", "", "return", "adict_nid", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.train_att_bc.make_vocab_files": [[156, 167], ["write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_question_vocab", "write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_answer_vocab"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_question_vocab", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_answer_vocab"], ["", "def", "make_question_vocab", "(", "qdic", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "vdict", "=", "{", "''", ":", "0", "}", "\n", "vid", "=", "1", "\n", "cdict", "=", "{", "''", ":", "0", "}", "\n", "cvid", "=", "1", "\n", "for", "qid", "in", "qdic", ".", "keys", "(", ")", ":", "\n", "# sequence to list", "\n", "        ", "q_str", "=", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.train_att_bc.main": [[168, 228], ["write_to_log.write_log", "write_to_log.write_log", "caffe.set_device", "caffe.set_mode_gpu", "caffe.get_solver", "numpy.zeros", "range", "os.path.exists", "os.makedirs", "os.path.exists", "os.path.exists", "write_to_log.write_log", "train_att_bc.make_vocab_files", "open", "f.write", "open", "f.write", "caffe.get_solver.step", "open", "json.load", "open", "json.load", "open", "json.dump", "open", "json.dump", "str", "str", "str", "str", "write_to_log.write_log", "write_to_log.write_log", "train_loss[].mean", "write_to_log.write_log", "caffe.get_solver.test_nets[].save", "write_to_log.write_log", "visualize_tools.exec_validation", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "train_att_bc.qlstm", "train_att_bc.qlstm", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_vocab_files", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.exec_validation", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["\n", "# create dict", "\n", "for", "w", "in", "q_list", ":", "\n", "            ", "if", "not", "vdict", ".", "has_key", "(", "w", ")", ":", "\n", "                ", "vdict", "[", "w", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "", "for", "c", "in", "list", "(", "w", ")", ":", "\n", "                ", "if", "not", "cdict", ".", "has_key", "(", "c", ")", ":", "\n", "                    ", "cdict", "[", "c", "]", "=", "cvid", "\n", "cvid", "+=", "1", "\n", "\n", "", "", "", "", "return", "vdict", ",", "cdict", "\n", "\n", "", "def", "make_vocab_files", "(", ")", ":", "\n", "    ", "\"\"\"\n    Produce the question and answer vocabulary files.\n    \"\"\"", "\n", "write_log", "(", "'making question vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "write_log", "(", "'making question character vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "qdic", ",", "_", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "QUESTION_VOCAB_SPACE", ")", "\n", "question_vocab", ",", "question_char_vocab", "=", "make_question_vocab", "(", "qdic", ")", "\n", "write_log", "(", "'making answer vocab... '", "+", "config", ".", "ANSWER_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "_", ",", "adic", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "ANSWER_VOCAB_SPACE", ")", "\n", "answer_vocab", "=", "make_answer_vocab", "(", "adic", ",", "config", ".", "NUM_OUTPUT_UNITS", ")", "\n", "return", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "'./result'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'./result'", ")", "\n", "\n", "", "question_vocab", ",", "answer_vocab", "=", "{", "}", ",", "{", "}", "\n", "if", "os", ".", "path", ".", "exists", "(", "'./result/cdict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/adict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/vdict.json'", ")", ":", "\n", "        ", "write_log", "(", "'restoring vocab'", ",", "'log.txt'", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_char_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "answer_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "=", "make_vocab_files", "(", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_char_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "answer_vocab", ",", "f", ")", "\n", "\n", "", "", "write_log", "(", "'question character vocab size: '", "+", "str", "(", "len", "(", "question_char_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'question vocab size: '", "+", "str", "(", "len", "(", "question_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'answer vocab size: '", "+", "str", "(", "len", "(", "answer_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "\n", "\n", "with", "open", "(", "'./result/proto_train.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "config", ".", "TRAIN_DATA_SPLITS", ",", "config", ".", "BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "with", "open", "(", "'./result/proto_test.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "'val'", ",", "config", ".", "VAL_BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.visualize_tools.visualize_failures": [[27, 119], ["write_to_log.write_log", "visualize_tools.visualize_failures.save_qtype"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["def", "visualize_failures", "(", "stat_list", ",", "mode", ")", ":", "\n", "\n", "    ", "def", "save_qtype", "(", "qtype_list", ",", "save_filename", ",", "mode", ")", ":", "\n", "\n", "        ", "if", "mode", "==", "'val'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./eval'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/val2014'", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test-dev'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "elif", "mode", "==", "'test'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unsupported mode'", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "shutil", ".", "rmtree", "(", "savepath", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "os", ".", "makedirs", "(", "savepath", ")", "\n", "\n", "for", "qt", "in", "qtype_list", ":", "\n", "            ", "count", "=", "0", "\n", "for", "t_question", "in", "stat_list", ":", "\n", "#print count, t_question", "\n", "                ", "if", "count", "<", "40", "/", "len", "(", "qtype_list", ")", ":", "\n", "                    ", "t_question_list", "=", "t_question", "[", "'q_list'", "]", "\n", "saveflag", "=", "False", "\n", "#print 'debug****************************'", "\n", "#print qt", "\n", "#print t_question_list", "\n", "#print t_question_list[0] == qt[0]", "\n", "#print t_question_list[1] == qt[1]", "\n", "if", "t_question_list", "[", "0", "]", "==", "qt", "[", "0", "]", "and", "t_question_list", "[", "1", "]", "==", "qt", "[", "1", "]", ":", "\n", "                        ", "saveflag", "=", "True", "\n", "", "else", ":", "\n", "                        ", "saveflag", "=", "False", "\n", "\n", "", "if", "saveflag", "==", "True", ":", "\n", "                        ", "t_iid", "=", "t_question", "[", "'iid'", "]", "\n", "if", "mode", "==", "'val'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_val2014_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "", "elif", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_test2015_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "\n", "# for caption", "\n", "#print t_iid", "\n", "#annIds = caps.getAnnIds(t_iid)", "\n", "#anns = caps.loadAnns(annIds)", "\n", "#cap_list = [ann['caption'] for ann in anns]", "\n", "", "ans_list", "=", "t_question", "[", "'ans_list'", "]", "\n", "draw", "=", "ImageDraw", ".", "Draw", "(", "t_img", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ans_list", ")", ")", ":", "\n", "                            ", "try", ":", "\n", "                                ", "draw", ".", "text", "(", "(", "10", ",", "10", "*", "i", ")", ",", "str", "(", "ans_list", "[", "i", "]", ")", ")", "\n", "", "except", ":", "\n", "                                ", "pass", "\n", "\n", "", "", "ans", "=", "t_question", "[", "'answer'", "]", "\n", "pred", "=", "t_question", "[", "'pred'", "]", "\n", "if", "ans", "==", "-", "1", ":", "\n", "                            ", "pre", "=", "''", "\n", "", "elif", "ans", "==", "pred", ":", "\n", "                            ", "pre", "=", "'correct  '", "\n", "", "else", ":", "\n", "                            ", "pre", "=", "'failure  '", "\n", "#print ' aaa ', ans, pred", "\n", "", "ans", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "ans", ")", ")", "\n", "pred", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "pred", ")", ")", "\n", "img_title", "=", "pre", "+", "str", "(", "' '", ".", "join", "(", "t_question_list", ")", ")", "+", "'.  a_'", "+", "str", "(", "ans", ")", "+", "' p_'", "+", "str", "(", "pred", ")", "+", "'.png'", "\n", "count", "+=", "1", "\n", "write_log", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ",", "'visualize_log.txt'", ")", "\n", "t_img", ".", "save", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ")", "\n", "\n", "", "", "", "", "", "write_log", "(", "'saving colors'", ",", "'visualize_log.txt'", ")", "\n", "qt_color_list", "=", "[", "[", "'what'", ",", "'color'", "]", "]", "\n", "save_qtype", "(", "qt_color_list", ",", "'colors'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving what is'", ",", "'visualize_log.txt'", ")", "\n", "qt_whatis_list", "=", "[", "[", "'what'", ",", "'is'", "]", ",", "[", "'what'", ",", "'kind'", "]", ",", "[", "'what'", ",", "'are'", "]", "]", "\n", "save_qtype", "(", "qt_whatis_list", ",", "'whatis'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving is'", ",", "'visualize_log.txt'", ")", "\n", "qt_is_list", "=", "[", "[", "'is'", ",", "'the'", "]", ",", "[", "'is'", ",", "'this'", "]", ",", "[", "'is'", ",", "'there'", "]", "]", "\n", "save_qtype", "(", "qt_is_list", ",", "'is'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving how many'", ",", "'visualize_log.txt'", ")", "\n", "qt_howmany_list", "=", "[", "[", "'how'", ",", "'many'", "]", "]", "\n", "save_qtype", "(", "qt_howmany_list", ",", "'howmany'", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.visualize_tools.exec_validation": [[120, 201], ["caffe.set_device", "caffe.set_mode_gpu", "caffe.Net", "vqa_data_provider_layer.VQADataProvider", "len", "numpy.array().mean", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "vqa_data_provider_layer.VQADataProvider.get_batch_vec", "caffe.Net.forward", "caffe.Net.blobs[].data.argmax", "testloss_list.append", "zip", "vqaTools.vqa.VQA", "vqaTools.vqa.VQA.loadRes", "vqaEvaluation.vqaEval.VQAEval", "vqaEvaluation.vqaEval.VQAEval.evaluate", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "t_answer.tolist", "pred_list.append", "numpy.array", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "stat_list.append", "open", "json.dump", "visualize_tools.visualize_failures", "int", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "str().zfill", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "str().zfill", "xrange", "str", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.forward", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj"], ["", "def", "exec_validation", "(", "device_id", ",", "mode", ",", "it", "=", "''", ",", "visualize", "=", "False", ")", ":", "\n", "\n", "    ", "caffe", ".", "set_device", "(", "device_id", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "net", "=", "caffe", ".", "Net", "(", "'./result/proto_test.prototxt'", ",", "'./result/tmp.caffemodel'", ",", "caffe", ".", "TEST", ")", "\n", "\n", "dp", "=", "VQADataProvider", "(", "mode", "=", "mode", ",", "batchsize", "=", "config", ".", "VAL_BATCH_SIZE", ")", "\n", "total_questions", "=", "len", "(", "dp", ".", "getQuesIds", "(", ")", ")", "\n", "epoch", "=", "0", "\n", "\n", "pred_list", "=", "[", "]", "\n", "testloss_list", "=", "[", "]", "\n", "stat_list", "=", "[", "]", "\n", "\n", "while", "epoch", "==", "0", ":", "\n", "        ", "t_word", ",", "t_cont", ",", "t_word_c", ",", "t_cont_c", ",", "t_img_feature", ",", "t_answer", ",", "t_qid_list", ",", "t_iid_list", ",", "epoch", "=", "dp", ".", "get_batch_vec", "(", ")", "\n", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "...", "]", "=", "t_word", "# np.transpose(t_word,(1,0))", "\n", "net", ".", "blobs", "[", "'cont'", "]", ".", "data", "[", "...", "]", "=", "t_cont", "# np.transpose(t_cont,(1,0))", "\n", "net", ".", "blobs", "[", "'data1'", "]", ".", "data", "[", "...", "]", "=", "t_word_c", "\n", "net", ".", "blobs", "[", "'cont1'", "]", ".", "data", "[", "...", "]", "=", "t_cont_c", "\n", "net", ".", "blobs", "[", "'img_feature'", "]", ".", "data", "[", "...", "]", "=", "t_img_feature", "\n", "net", ".", "blobs", "[", "'label'", "]", ".", "data", "[", "...", "]", "=", "t_answer", "\n", "#net.blobs['glove'].data[...] = t_glove_matrix # np.transpose(t_glove_matrix, (1,0,2))", "\n", "net", ".", "forward", "(", ")", "\n", "t_pred_list", "=", "net", ".", "blobs", "[", "'prediction'", "]", ".", "data", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "t_pred_str", "=", "[", "dp", ".", "vec_to_answer", "(", "pred_symbol", ")", "for", "pred_symbol", "in", "t_pred_list", "]", "\n", "testloss_list", ".", "append", "(", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", ")", "\n", "for", "qid", ",", "iid", ",", "ans", ",", "pred", "in", "zip", "(", "t_qid_list", ",", "t_iid_list", ",", "t_answer", ".", "tolist", "(", ")", ",", "t_pred_str", ")", ":", "\n", "            ", "pred_list", ".", "append", "(", "{", "u'answer'", ":", "pred", ",", "u'question_id'", ":", "int", "(", "dp", ".", "getStrippedQuesId", "(", "qid", ")", ")", "}", ")", "\n", "if", "visualize", ":", "\n", "                ", "q_list", "=", "dp", ".", "seq_to_list", "(", "dp", ".", "getQuesStr", "(", "qid", ")", ")", "\n", "if", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                    ", "ans_str", "=", "''", "\n", "ans_list", "=", "[", "''", "]", "*", "10", "\n", "", "else", ":", "\n", "                    ", "ans_str", "=", "dp", ".", "vec_to_answer", "(", "ans", ")", "\n", "ans_list", "=", "[", "dp", ".", "getAnsObj", "(", "qid", ")", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "", "stat_list", ".", "append", "(", "{", "'qid'", ":", "qid", ",", "\n", "'q_list'", ":", "q_list", ",", "\n", "'iid'", ":", "iid", ",", "\n", "'answer'", ":", "ans_str", ",", "\n", "'ans_list'", ":", "ans_list", ",", "\n", "'pred'", ":", "pred", "}", ")", "\n", "#percent = 100 * float(len(pred_list)) / total_questions", "\n", "#sys.stdout.write('\\r' + ('%.2f' % percent) + '%')", "\n", "#sys.stdout.flush()", "\n", "\n", "\n", "\n", "", "", "", "mean_testloss", "=", "np", ".", "array", "(", "testloss_list", ")", ".", "mean", "(", ")", "\n", "\n", "if", "mode", "==", "'val'", ":", "\n", "        ", "valFile", "=", "'./result/val2014_resfile'", "\n", "with", "open", "(", "valFile", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "annFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ans_file'", "]", "\n", "quesFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ques_file'", "]", "\n", "vqa", "=", "VQA", "(", "annFile", ",", "quesFile", ")", "\n", "vqaRes", "=", "vqa", ".", "loadRes", "(", "valFile", ",", "quesFile", ")", "\n", "vqaEval", "=", "VQAEval", "(", "vqa", ",", "vqaRes", ",", "n", "=", "2", ")", "\n", "vqaEval", ".", "evaluate", "(", ")", "\n", "acc_overall", "=", "vqaEval", ".", "accuracy", "[", "'overall'", "]", "\n", "acc_perQuestionType", "=", "vqaEval", ".", "accuracy", "[", "'perQuestionType'", "]", "\n", "acc_perAnswerType", "=", "vqaEval", ".", "accuracy", "[", "'perAnswerType'", "]", "\n", "return", "mean_testloss", ",", "acc_overall", ",", "acc_perQuestionType", ",", "acc_perAnswerType", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test-dev2015_v3t'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "", "elif", "mode", "==", "'test'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test2015_v3c'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Bottleneck.visualize_tools.drawgraph": [[202, 270], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.twinx", "fig.add_subplot.plot", "fig.add_subplot.plot", "ax1.twinx.plot", "matplotlib.legend", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "ax1.twinx.set_ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "numpy.array", "numpy.array", "matplotlib.figure", "matplotlib.legend", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "sorted", "visualize_tools.drawgraph.draw_qt_acc"], "function", ["None"], ["\n", "", "", "", "def", "drawgraph", "(", "results", ",", "save_question_type_graphs", "=", "False", ")", ":", "\n", "# 0:it", "\n", "# 1:trainloss", "\n", "# 2:testloss", "\n", "# 3:oa_acc", "\n", "# 4:qt_acc", "\n", "# 5:at_acc", "\n", "\n", "# training curve", "\n", "    ", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "loss", "=", "np", ".", "array", "(", "[", "l", "[", "1", "]", "for", "l", "in", "results", "]", ")", "\n", "valloss", "=", "np", ".", "array", "(", "[", "l", "[", "2", "]", "for", "l", "in", "results", "]", ")", "\n", "valacc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax1", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "ax2", "=", "ax1", ".", "twinx", "(", ")", "\n", "\n", "ax1", ".", "plot", "(", "it", ",", "loss", ",", "color", "=", "'blue'", ",", "label", "=", "'train loss'", ")", "\n", "ax1", ".", "plot", "(", "it", ",", "valloss", ",", "'--'", ",", "color", "=", "'blue'", ",", "label", "=", "'test loss'", ")", "\n", "ax2", ".", "plot", "(", "it", ",", "valacc", ",", "color", "=", "'red'", ",", "label", "=", "'acc on val'", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'lower left'", ")", "\n", "\n", "ax1", ".", "set_xlabel", "(", "'Iterations'", ")", "\n", "ax1", ".", "set_ylabel", "(", "'Loss Value'", ")", "\n", "ax2", ".", "set_ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "'./learning_curve max_%2.2f.png'", "%", "valacc", ".", "max", "(", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "# question type", "\n", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "oa_acc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "qt_dic_list", "=", "[", "l", "[", "4", "]", "for", "l", "in", "results", "]", "\n", "\n", "def", "draw_qt_acc", "(", "target_key_list", ",", "figname", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "for", "k", "in", "target_key_list", ":", "\n", "            ", "write_log", "(", "str", "(", "k", ")", "+", "str", "(", "type", "(", "k", ")", ")", ",", "'visualize_log.txt'", ")", "\n", "t_val", "=", "np", ".", "array", "(", "[", "qt_dic", "[", "k", "]", "for", "qt_dic", "in", "qt_dic_list", "]", ")", "\n", "plt", ".", "plot", "(", "it", ",", "t_val", ",", "label", "=", "str", "(", "k", ")", ")", "\n", "", "plt", ".", "legend", "(", "fontsize", "=", "'small'", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "100.", ")", "\n", "#plt.legend(prop={'size':6})", "\n", "\n", "plt", ".", "xlabel", "(", "'Iterations'", ")", "\n", "plt", ".", "ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "figname", ",", "dpi", "=", "200", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "", "if", "save_question_type_graphs", ":", "\n", "        ", "s_keys", "=", "sorted", "(", "qt_dic_list", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "0", ":", "13", "]", "+", "[", "s_keys", "[", "31", "]", ",", "]", ",", "'./ind_qt_are.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "13", ":", "17", "]", "+", "s_keys", "[", "49", ":", "]", ",", "'./ind_qt_how_where_who_why.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "17", ":", "31", "]", "+", "[", "s_keys", "[", "32", "]", ",", "]", ",", "'./ind_qt_is.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "33", ":", "49", "]", ",", "'./ind_qt_what.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what color is the'", ",", "'what color are the'", ",", "'what color is'", ",", "'what color'", ",", "'what is the color of the'", "]", ",", "'./qt_color.png'", ")", "\n", "draw_qt_acc", "(", "[", "'how many'", ",", "'how'", ",", "'how many people are'", ",", "'how many people are in'", "]", ",", "'./qt_number.png'", ")", "\n", "draw_qt_acc", "(", "[", "'who is'", ",", "'why'", ",", "'why is the'", ",", "'where is the'", ",", "'where are the'", ",", "'which'", "]", ",", "'./qt_who_why_where_which.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what is the man'", ",", "'is the man'", ",", "'are they'", ",", "'is he'", ",", "'is the woman'", ",", "'is this person'", ",", "'what is the woman'", ",", "'is the person'", ",", "'what is the person'", "]", ",", "'./qt_human.png'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).write_to_log.write_log": [[1, 4], ["open", "f.write"], "function", ["None"], ["def", "write_log", "(", "str", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "+", "\"\\n\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.__init__": [[13, 32], ["vqa_data_provider_layer.VQADataProvider.load_data", "len", "open", "json.load", "open", "json.load", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data"], ["    ", "def", "__init__", "(", "self", ",", "batchsize", "=", "64", ",", "max_length", "=", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "max_w_length", "=", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "batchsize", "\n", "self", ".", "d_vocabulary", "=", "None", "\n", "self", ".", "batch_index", "=", "None", "\n", "self", ".", "batch_len", "=", "None", "\n", "self", ".", "rev_adict", "=", "None", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "max_w_length", "=", "max_w_length", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "qdic", ",", "self", ".", "adic", "=", "VQADataProvider", ".", "load_data", "(", "mode", ")", "\n", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "cdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "vdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "adict", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "self", ".", "n_ans_vocabulary", "=", "len", "(", "self", ".", "adict", ")", "\n", "#self.nlp = spacy.load('en', vectors='en_glove_cc_300_1m_vectors')", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.load_vqa_json": [[35, 58], ["write_to_log.write_log", "open", "json.load", "open", "json.load", "str", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["", "@", "staticmethod", "\n", "def", "load_vqa_json", "(", "data_split", ")", ":", "\n", "        ", "\"\"\"\n        Parses the question and answer json files for the given data split. \n        Returns the question dictionary and the answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ques_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "[", "'questions'", "]", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "qdic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'question_id'", "]", ")", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image_id'", "]", "}", "\n", "\n", "", "", "if", "'test'", "not", "in", "data_split", ":", "\n", "            ", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ans_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "adata", "=", "json", ".", "load", "(", "f", ")", "[", "'annotations'", "]", "\n", "for", "a", "in", "adata", ":", "\n", "                    ", "adic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "a", "[", "'question_id'", "]", ")", "]", "=", "a", "[", "'answers'", "]", "\n", "\n", "", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for '", "+", "data_split", ",", "'log.txt'", ")", "\n", "return", "qdic", ",", "adic", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.load_genome_json": [[59, 76], ["write_to_log.write_log", "open", "json.load", "str", "str", "len"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["", "@", "staticmethod", "\n", "def", "load_genome_json", "(", ")", ":", "\n", "        ", "\"\"\"\n        Parses the genome json file. Returns the question dictionary and the\n        answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'genome_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "key", "=", "'genome'", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'id'", "]", ")", "\n", "qdic", "[", "key", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image'", "]", "}", "\n", "adic", "[", "key", "]", "=", "[", "{", "'answer'", ":", "q", "[", "'answer'", "]", "}", "]", "\n", "\n", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for genome'", ",", "'log.txt'", ")", "\n", "return", "qdic", ",", "adic", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.load_data": [[77, 92], ["data_split_str.split", "config.DATA_PATHS.keys", "vqa_data_provider_layer.VQADataProvider.load_genome_json", "all_qdic.update", "all_adic.update", "vqa_data_provider_layer.VQADataProvider.load_vqa_json", "all_qdic.update", "all_adic.update"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_genome_json", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_vqa_json"], ["", "@", "staticmethod", "\n", "def", "load_data", "(", "data_split_str", ")", ":", "\n", "        ", "all_qdic", ",", "all_adic", "=", "{", "}", ",", "{", "}", "\n", "for", "data_split", "in", "data_split_str", ".", "split", "(", "'+'", ")", ":", "\n", "            ", "assert", "data_split", "in", "config", ".", "DATA_PATHS", ".", "keys", "(", ")", ",", "'unknown data split'", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_genome_json", "(", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "", "else", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_vqa_json", "(", "data_split", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "\n", "", "", "return", "all_qdic", ",", "all_adic", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.getQuesIds": [[93, 95], ["vqa_data_provider_layer.VQADataProvider.qdic.keys"], "methods", ["None"], ["", "def", "getQuesIds", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "qdic", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId": [[96, 98], ["qid.split"], "methods", ["None"], ["", "def", "getStrippedQuesId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.getImgId": [[99, 101], ["None"], "methods", ["None"], ["", "def", "getImgId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'iid'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.getQuesStr": [[102, 104], ["None"], "methods", ["None"], ["", "def", "getQuesStr", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.getAnsObj": [[105, 109], ["None"], "methods", ["None"], ["", "def", "getAnsObj", "(", "self", ",", "qid", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "", "return", "self", ".", "adic", "[", "qid", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.seq_to_list": [[110, 120], ["s.lower", "re.sub().split", "filter", "re.sub", "re.sub", "re.sub", "re.sub.lower", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "seq_to_list", "(", "s", ")", ":", "\n", "        ", "t_str", "=", "s", ".", "lower", "(", ")", "\n", "for", "i", "in", "[", "r'\\?'", ",", "r'\\!'", ",", "r'\\''", ",", "r'\\\"'", ",", "r'\\$'", ",", "r'\\:'", ",", "r'\\@'", ",", "r'\\('", ",", "r'\\)'", ",", "r'\\,'", ",", "r'\\.'", ",", "r'\\;'", "]", ":", "\n", "            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "''", ",", "t_str", ")", "\n", "", "for", "i", "in", "[", "r'\\-'", ",", "r'\\/'", "]", ":", "\n", "            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "' '", ",", "t_str", ")", "\n", "", "q_list", "=", "re", ".", "sub", "(", "r'\\?'", ",", "''", ",", "t_str", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "\n", "q_list", "=", "filter", "(", "lambda", "x", ":", "len", "(", "x", ")", ">", "0", ",", "q_list", ")", "\n", "return", "q_list", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.extract_answer": [[121, 134], ["dic.has_key", "max", "xrange", "dic.items"], "methods", ["None"], ["", "def", "extract_answer", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "", "answer_list", "=", "[", "answer_obj", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "dic", "=", "{", "}", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "dic", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "dic", "[", "ans", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "dic", "[", "ans", "]", "=", "1", "\n", "", "", "max_key", "=", "max", "(", "(", "v", ",", "k", ")", "for", "(", "k", ",", "v", ")", "in", "dic", ".", "items", "(", ")", ")", "[", "1", "]", "\n", "return", "max_key", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.extract_answer_prob": [[135, 153], ["vqa_data_provider_layer.VQADataProvider.adict.has_key", "len", "random.choice", "prob_answer_list.append", "Exception"], "methods", ["None"], ["", "def", "extract_answer_prob", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "prob_answer_list", "=", "[", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "prob_answer_list", ".", "append", "(", "ans", ")", "\n", "\n", "", "", "if", "len", "(", "prob_answer_list", ")", "==", "0", ":", "\n", "            ", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "return", "'hoge'", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"This should not happen.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "random", ".", "choice", "(", "prob_answer_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.qlist_to_vec": [[202, 244], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "xrange", "list", "xrange", "len", "vqa_data_provider_layer.VQADataProvider.vdict.has_key", "len", "vqa_data_provider_layer.VQADataProvider.cdict.has_key", "len", "len"], "methods", ["None"], ["", "", "def", "qlist_to_vec", "(", "self", ",", "max_length", ",", "max_w_length", ",", "q_list", ")", ":", "\n", "        ", "\"\"\"\n        Converts a list of chars into a format suitable for the embedding layer.\n\n        Arguments:\n        max_length -- the maximum length of a question sequence\n        max_w_length -- the maximum length of a character sequence for each word\n        q_list -- a list of words which are the tokens in the question\n\n        Returns:\n        qvec -- A max_length length vector containing one-hot indices for each word\n        cvec -- A max_length length sequence continuation indicator vector\n        qcvec -- A max_w_length*max_length length vector containing one-hot indices for each char\n        ccvec -- A max_w_length*max_length length sequence continuation indicator vector\n        \"\"\"", "\n", "qvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "cvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "qcvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "ccvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "for", "i", "in", "xrange", "(", "max_length", ")", ":", "\n", "            ", "if", "i", "<", "max_length", "-", "len", "(", "q_list", ")", ":", "\n", "                ", "cvec", "[", "i", "]", "=", "0", "\n", "", "else", ":", "\n", "                ", "w", "=", "q_list", "[", "i", "-", "(", "max_length", "-", "len", "(", "q_list", ")", ")", "]", "\n", "# is the word in the vocabulary?", "\n", "if", "self", ".", "vdict", ".", "has_key", "(", "w", ")", "is", "False", ":", "\n", "                    ", "w", "=", "''", "\n", "", "qvec", "[", "i", "]", "=", "self", ".", "vdict", "[", "w", "]", "\n", "cvec", "[", "i", "]", "=", "1.0", "/", "len", "(", "q_list", ")", "\n", "j", "=", "max_w_length", "*", "i", "\n", "w_list", "=", "list", "(", "w", ")", "\n", "for", "k", "in", "xrange", "(", "max_w_length", ")", ":", "\n", "                    ", "if", "k", "<", "max_w_length", "-", "len", "(", "w_list", ")", ":", "\n", "                        ", "ccvec", "[", "j", "+", "k", "]", "=", "0", "\n", "", "else", ":", "\n", "                        ", "c", "=", "w_list", "[", "k", "-", "(", "max_w_length", "-", "len", "(", "w_list", ")", ")", "]", "\n", "# is the char in the vocabulary?", "\n", "if", "self", ".", "cdict", ".", "has_key", "(", "c", ")", "is", "False", ":", "\n", "                            ", "c", "=", "''", "\n", "", "qcvec", "[", "j", "+", "k", "]", "=", "self", ".", "cdict", "[", "c", "]", "\n", "ccvec", "[", "j", "+", "k", "]", "=", "1.0", "/", "len", "(", "w_list", ")", "\n", "", "", "", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.answer_to_vec": [[245, 255], ["vqa_data_provider_layer.VQADataProvider.adict.has_key"], "methods", ["None"], ["", "def", "answer_to_vec", "(", "self", ",", "ans_str", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "if", "self", ".", "adict", ".", "has_key", "(", "ans_str", ")", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "ans_str", "]", "\n", "", "else", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "''", "]", "\n", "", "return", "ans", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.vec_to_answer": [[256, 265], ["vqa_data_provider_layer.VQADataProvider.adict.items"], "methods", ["None"], ["", "def", "vec_to_answer", "(", "self", ",", "ans_symbol", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "rev_adict", "is", "None", ":", "\n", "            ", "rev_adict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "adict", ".", "items", "(", ")", ":", "\n", "                ", "rev_adict", "[", "v", "]", "=", "k", "\n", "", "self", ".", "rev_adict", "=", "rev_adict", "\n", "\n", "", "return", "self", ".", "rev_adict", "[", "ans_symbol", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.create_batch": [[266, 316], ["numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "enumerate", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "vqa_data_provider_layer.VQADataProvider.answer_to_vec", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "qid.split", "vqa_data_provider_layer.VQADataProvider.extract_answer", "vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "numpy.sqrt", "write_to_log.write_log", "numpy.load", "numpy.load", "str", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.answer_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["", "def", "create_batch", "(", "self", ",", "qid_list", ")", ":", "\n", "\n", "        ", "qvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "cvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "qcvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ccvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ivec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "2048", "*", "14", "*", "14", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "2048", ",", "14", ",", "14", ")", "\n", "avec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ")", "\n", "#glove_matrix = np.zeros(self.batchsize * self.max_length * GLOVE_EMBEDDING_SIZE).reshape(\\", "\n", "#self.batchsize, self.max_length, GLOVE_EMBEDDING_SIZE)", "\n", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "\n", "# load raw question information", "\n", "            ", "q_str", "=", "self", ".", "getQuesStr", "(", "qid", ")", "\n", "q_ans", "=", "self", ".", "getAnsObj", "(", "qid", ")", "\n", "q_iid", "=", "self", ".", "getImgId", "(", "qid", ")", "\n", "\n", "# convert question to vec", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "t_qvec", ",", "t_cvec", ",", "t_qcvec", ",", "t_ccvec", "=", "self", ".", "qlist_to_vec", "(", "self", ".", "max_length", ",", "self", ".", "max_w_length", ",", "q_list", ")", "\n", "\n", "try", ":", "\n", "                ", "qid_split", "=", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "\n", "data_split", "=", "qid_split", "[", "0", "]", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "else", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "t_ivec", "=", "(", "t_ivec", "/", "np", ".", "sqrt", "(", "(", "t_ivec", "**", "2", ")", ".", "sum", "(", ")", ")", ")", "\n", "", "except", ":", "\n", "                ", "t_ivec", "=", "0.", "\n", "write_log", "(", "'data not found for qid : '", "+", "str", "(", "q_iid", ")", "+", "' '", "+", "self", ".", "mode", ",", "'log.txt'", ")", "\n", "\n", "# convert answer to vec", "\n", "", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer", "(", "q_ans", ")", "\n", "", "else", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer_prob", "(", "q_ans", ")", "\n", "", "t_avec", "=", "self", ".", "answer_to_vec", "(", "q_ans_str", ")", "\n", "\n", "qvec", "[", "i", ",", "...", "]", "=", "t_qvec", "\n", "cvec", "[", "i", ",", "...", "]", "=", "t_cvec", "\n", "qcvec", "[", "i", ",", "...", "]", "=", "t_qcvec", "\n", "ccvec", "[", "i", ",", "...", "]", "=", "t_ccvec", "\n", "ivec", "[", "i", ",", "...", "]", "=", "t_ivec", "\n", "avec", "[", "i", ",", "...", "]", "=", "t_avec", "\n", "#glove_matrix[i,...] = t_glove_matrix", "\n", "\n", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", ",", "ivec", ",", "avec", "#, glove_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProvider.get_batch_vec": [[318, 365], ["vqa_data_provider_layer.VQADataProvider.create_batch", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "random.shuffle", "len", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.adict.has_key", "t_qid_list.append", "t_iid_list.append", "vqa_data_provider_layer.VQADataProvider.get_batch_vec.has_at_least_one_valid_answer"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.create_batch", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId"], ["", "def", "get_batch_vec", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "batch_len", "is", "None", ":", "\n", "            ", "self", ".", "n_skipped", "=", "0", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_len", "=", "len", "(", "qid_list", ")", "\n", "self", ".", "batch_index", "=", "0", "\n", "self", ".", "epoch_counter", "=", "0", "\n", "\n", "", "def", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "            ", "answer_obj", "=", "self", ".", "getAnsObj", "(", "t_qid", ")", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "                ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n", "                    ", "return", "True", "\n", "\n", "", "", "", "counter", "=", "0", "\n", "t_qid_list", "=", "[", "]", "\n", "t_iid_list", "=", "[", "]", "\n", "while", "counter", "<", "self", ".", "batchsize", ":", "\n", "            ", "t_qid", "=", "self", ".", "qid_list", "[", "self", ".", "batch_index", "]", "\n", "t_iid", "=", "self", ".", "getImgId", "(", "t_qid", ")", "\n", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n", "", "elif", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n", "", "else", ":", "\n", "                ", "self", ".", "n_skipped", "+=", "1", "\n", "\n", "", "if", "self", ".", "batch_index", "<", "self", ".", "batch_len", "-", "1", ":", "\n", "                ", "self", ".", "batch_index", "+=", "1", "\n", "", "else", ":", "\n", "                ", "self", ".", "epoch_counter", "+=", "1", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_index", "=", "0", "\n", "write_log", "(", "\"%d questions were skipped in a single epoch\"", "%", "self", ".", "n_skipped", ",", "'log.txt'", ")", "\n", "self", ".", "n_skipped", "=", "0", "\n", "\n", "", "", "t_batch", "=", "self", ".", "create_batch", "(", "t_qid_list", ")", "\n", "return", "t_batch", "+", "(", "t_qid_list", ",", "t_iid_list", ",", "self", ".", "epoch_counter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProviderLayer.setup": [[371, 387], ["top[].reshape", "top[].reshape", "top[].reshape", "top[].reshape", "top[].reshape", "top[].reshape", "json.loads", "json.loads", "vqa_data_provider_layer.VQADataProvider"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape"], ["def", "setup", "(", "self", ",", "bottom", ",", "top", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "json", ".", "loads", "(", "self", ".", "param_str", ")", "[", "'batchsize'", "]", "\n", "self", ".", "top_names", "=", "[", "'data'", ",", "'cont'", ",", "'data1'", ",", "'cont1'", ",", "'feature'", ",", "'label'", "]", "#,'glove']", "\n", "top", "[", "0", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ")", "\n", "top", "[", "1", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ")", "\n", "top", "[", "2", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", "*", "config", ".", "MAX_WORDS_IN_QUESTION", ")", "\n", "top", "[", "3", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", "*", "config", ".", "MAX_WORDS_IN_QUESTION", ")", "\n", "top", "[", "4", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "2048", ",", "14", ",", "14", ")", "\n", "top", "[", "5", "]", ".", "reshape", "(", "self", ".", "batchsize", ")", "\n", "#top[4].reshape(self.batchsize,config.MAX_WORDS_IN_QUESTION,GLOVE_EMBEDDING_SIZE)", "\n", "\n", "self", ".", "mode", "=", "json", ".", "loads", "(", "self", ".", "param_str", ")", "[", "'mode'", "]", "\n", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "self", ".", "dp", "=", "VQADataProvider", "(", "batchsize", "=", "self", ".", "batchsize", ",", "mode", "=", "self", ".", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProviderLayer.reshape": [[388, 390], ["None"], "methods", ["None"], ["", "", "def", "reshape", "(", "self", ",", "bottom", ",", "top", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProviderLayer.forward": [[391, 402], ["vqa_data_provider_layer.VQADataProviderLayer.dp.get_batch_vec"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec"], ["", "def", "forward", "(", "self", ",", "bottom", ",", "top", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "word", ",", "cont", ",", "word_c", ",", "cont_c", ",", "feature", ",", "answer", ",", "_", ",", "_", ",", "_", "=", "self", ".", "dp", ".", "get_batch_vec", "(", ")", "\n", "top", "[", "0", "]", ".", "data", "[", "...", "]", "=", "word", "# np.transpose(word,(1,0)) # N x T -> T x N", "\n", "top", "[", "1", "]", ".", "data", "[", "...", "]", "=", "cont", "# np.transpose(cont,(1,0))", "\n", "top", "[", "2", "]", ".", "data", "[", "...", "]", "=", "word_c", "\n", "top", "[", "3", "]", ".", "data", "[", "...", "]", "=", "cont_c", "\n", "top", "[", "4", "]", ".", "data", "[", "...", "]", "=", "feature", "\n", "top", "[", "5", "]", ".", "data", "[", "...", "]", "=", "answer", "\n", "#top[4].data[...] = glove_matrix # np.transpose(glove_matrix, (1,0,2)) # N x T x 300 -> T x N x 300", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).vqa_data_provider_layer.VQADataProviderLayer.backward": [[404, 406], ["None"], "methods", ["None"], ["", "", "def", "backward", "(", "self", ",", "top", ",", "propagate_down", ",", "bottom", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).train_att_bc.qlstm": [[19, 182], ["caffe.NetSpec", "json.dumps", "caffe.layers.Python", "caffe.layers.Embed", "caffe.layers.Scale", "caffe.layers.Reshape", "caffe.layers.Slice", "xrange", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Concat", "caffe.layers.Embed", "caffe.layers.Concat", "caffe.layers.Scale", "caffe.layers.Reshape", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.ReLU", "caffe.layers.ReLU", "caffe.layers.ReLU", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Concat", "caffe.layers.Dropout", "caffe.layers.Tile", "caffe.layers.Tile", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.Reshape", "caffe.layers.Softmax", "caffe.layers.Reshape", "caffe.layers.Slice", "caffe.layers.DummyData", "caffe.layers.SoftAttention", "caffe.layers.SoftAttention", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Concat", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Reshape", "caffe.layers.InnerProduct", "caffe.layers.SoftmaxWithLoss", "caffe.NetSpec.to_proto", "caffe.NetSpec.__setattr__", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "str", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "int", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "config.TRAIN_DATA_SPLITS", "config.BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION", "config.LENGTH_OF_LONGEST_WORD", "config.VAL_BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION", "config.LENGTH_OF_LONGEST_WORD"], "function", ["None"], ["def", "qlstm", "(", "mode", ",", "batchsize", ",", "T", ",", "T_c", ",", "question_c_vocab_size", ",", "question_vocab_size", ")", ":", "\n", "    ", "n", "=", "caffe", ".", "NetSpec", "(", ")", "\n", "mode_str", "=", "json", ".", "dumps", "(", "{", "'mode'", ":", "mode", ",", "'batchsize'", ":", "batchsize", "}", ")", "\n", "n", ".", "data", ",", "n", ".", "cont", ",", "n", ".", "data1", ",", "n", ".", "cont1", ",", "n", ".", "img_feature", ",", "n", ".", "label", "=", "L", ".", "Python", "(", "module", "=", "'vqa_data_provider_layer'", ",", "layer", "=", "'VQADataProviderLayer'", ",", "param_str", "=", "mode_str", ",", "ntop", "=", "6", ")", "#5 )", "\n", "\n", "# char embedding", "\n", "n", ".", "embed_c", "=", "L", ".", "Embed", "(", "n", ".", "data1", ",", "input_dim", "=", "question_c_vocab_size", ",", "num_output", "=", "100", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "\n", "n", ".", "embed_c_scale", "=", "L", ".", "Scale", "(", "n", ".", "embed_c", ",", "n", ".", "cont1", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "\n", "n", ".", "embed_c_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_c_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T_c", "*", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T_c*T x d_c x 1", "\n", "tops", "=", "L", ".", "Slice", "(", "n", ".", "embed_c_scale_resh", ",", "ntop", "=", "T", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T_c x d_c x 1", "\n", "for", "i", "in", "xrange", "(", "T", ")", ":", "\n", "        ", "n", ".", "__setattr__", "(", "'Slice_'", "+", "str", "(", "i", "+", "1", ")", ",", "tops", "[", "int", "(", "i", ")", "]", ")", "\n", "\n", "# avg of char embedding", "\n", "", "n", ".", "c_embed_1", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_1", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_2", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_2", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_3", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_3", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_4", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_4", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_5", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_5", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_6", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_6", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_7", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_7", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_8", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_8", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_9", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_9", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_10", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_10", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_11", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_11", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_12", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_12", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_13", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_13", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_14", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_14", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_15", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_15", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_16", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_16", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_17", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_17", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_18", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_18", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_19", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_19", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_20", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_20", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_21", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_21", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_22", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_22", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "\n", "concat_c_embed", "=", "[", "n", ".", "c_embed_1", ",", "n", ".", "c_embed_2", ",", "n", ".", "c_embed_3", ",", "n", ".", "c_embed_4", ",", "n", ".", "c_embed_5", ",", "n", ".", "c_embed_6", ",", "n", ".", "c_embed_7", ",", "n", ".", "c_embed_8", ",", "n", ".", "c_embed_9", ",", "n", ".", "c_embed_10", ",", "n", ".", "c_embed_11", ",", "n", ".", "c_embed_12", ",", "n", ".", "c_embed_13", ",", "n", ".", "c_embed_14", ",", "n", ".", "c_embed_15", ",", "n", ".", "c_embed_16", ",", "n", ".", "c_embed_17", ",", "n", ".", "c_embed_18", ",", "n", ".", "c_embed_19", ",", "n", ".", "c_embed_20", ",", "n", ".", "c_embed_21", ",", "n", ".", "c_embed_22", "]", "\n", "n", ".", "concat_char_embed", "=", "L", ".", "Concat", "(", "*", "concat_c_embed", ",", "concat_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T x d_c x 1", "\n", "n", ".", "concat_char_embed_resh", "=", "L", ".", "Reshape", "(", "n", ".", "concat_char_embed", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", "]", ")", ")", ")", "\n", "\n", "# word embedding", "\n", "n", ".", "embed_w", "=", "L", ".", "Embed", "(", "n", ".", "data", ",", "input_dim", "=", "question_vocab_size", ",", "num_output", "=", "200", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "# N x T x d_w", "\n", "\n", "# combine word and char embedding", "\n", "concat_word_embed", "=", "[", "n", ".", "embed_w", ",", "n", ".", "concat_char_embed_resh", "]", "\n", "n", ".", "concat_embed", "=", "L", ".", "Concat", "(", "*", "concat_word_embed", ",", "concat_param", "=", "{", "'axis'", ":", "2", "}", ")", "# N x T x (d_c+d_w)", "\n", "\n", "n", ".", "embed_scale", "=", "L", ".", "Scale", "(", "n", ".", "concat_embed", ",", "n", ".", "cont", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "# N x T x (d_c+d_w)", "\n", "n", ".", "embed_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T x (d_c+d_w) x 1", "\n", "\n", "# avg of word embedding", "\n", "n", ".", "embed_avg", "=", "L", ".", "Convolution", "(", "n", ".", "embed_scale_resh", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x (d_c+d_w) x 1", "\n", "n", ".", "embed_avg_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_avg", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "300", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled_1", "=", "L", ".", "Tile", "(", "n", ".", "embed_avg_resh", ",", "axis", "=", "2", ",", "tiles", "=", "14", ")", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled", "=", "L", ".", "Tile", "(", "n", ".", "q_emb_tanh_droped_resh_tiled_1", ",", "axis", "=", "3", ",", "tiles", "=", "14", ")", "\n", "n", ".", "i_emb_tanh_droped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "img_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "n", ".", "blcf", "=", "L", ".", "CompactBilinear", "(", "n", ".", "q_emb_tanh_droped_resh_tiled", ",", "n", ".", "i_emb_tanh_droped_resh", ",", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "blcf_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "blcf", ")", "\n", "n", ".", "blcf_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "blcf_sign_sqrt", ")", "\n", "n", ".", "blcf_droped", "=", "L", ".", "Dropout", "(", "n", ".", "blcf_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "\n", "# multi-channel attention", "\n", "n", ".", "att_conv1", "=", "L", ".", "Convolution", "(", "n", ".", "blcf_droped", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "512", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_conv1_relu", "=", "L", ".", "ReLU", "(", "n", ".", "att_conv1", ")", "\n", "n", ".", "att_conv2", "=", "L", ".", "Convolution", "(", "n", ".", "att_conv1_relu", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "2", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_reshaped", "=", "L", ".", "Reshape", "(", "n", ".", "att_conv2", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", "*", "14", "]", ")", ")", ")", "\n", "n", ".", "att_softmax", "=", "L", ".", "Softmax", "(", "n", ".", "att_reshaped", ",", "axis", "=", "2", ")", "\n", "n", ".", "att", "=", "L", ".", "Reshape", "(", "n", ".", "att_softmax", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "att_maps", "=", "L", ".", "Slice", "(", "n", ".", "att", ",", "ntop", "=", "2", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "\n", "n", ".", "att_map0", "=", "att_maps", "[", "0", "]", "\n", "n", ".", "att_map1", "=", "att_maps", "[", "1", "]", "\n", "dummy", "=", "L", ".", "DummyData", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "1", "]", ")", ",", "data_filler", "=", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", ",", "ntop", "=", "1", ")", "\n", "n", ".", "att_feature0", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map0", ",", "dummy", ")", "\n", "n", ".", "att_feature1", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map1", ",", "dummy", ")", "\n", "n", ".", "att_feature0_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature0", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature1_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature1", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature", "=", "L", ".", "Concat", "(", "n", ".", "att_feature0_resh", ",", "n", ".", "att_feature1_resh", ")", "\n", "\n", "# merge attention and lstm with compact bilinear pooling", "\n", "n", ".", "att_feature_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "4096", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "#n.lstm_12_resh = L.Reshape(n.lstm_12, reshape_param=dict(shape=dict(dim=[-1,2048,1,1])))", "\n", "n", ".", "bc_att_lstm", "=", "L", ".", "CompactBilinear", "(", "n", ".", "att_feature_resh", ",", "n", ".", "embed_avg_resh", ",", "\n", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "bc_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "bc_att_lstm", ")", "\n", "n", ".", "bc_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "bc_sign_sqrt", ")", "\n", "\n", "n", ".", "bc_dropped", "=", "L", ".", "Dropout", "(", "n", ".", "bc_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "n", ".", "bc_dropped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "bc_dropped", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "16000", "]", ")", ")", ")", "\n", "\n", "n", ".", "prediction", "=", "L", ".", "InnerProduct", "(", "n", ".", "bc_dropped_resh", ",", "num_output", "=", "3000", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "loss", "=", "L", ".", "SoftmaxWithLoss", "(", "n", ".", "prediction", ",", "n", ".", "label", ")", "\n", "return", "n", ".", "to_proto", "(", ")", "\n", "\n", "", "def", "make_answer_vocab", "(", "adic", ",", "vocab_size", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "adict", "=", "{", "''", ":", "0", "}", "\n", "nadict", "=", "{", "''", ":", "1000000", "}", "\n", "vid", "=", "1", "\n", "for", "qid", "in", "adic", ".", "keys", "(", ")", ":", "\n", "        ", "answer_obj", "=", "adic", "[", "qid", "]", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "\n", "for", "q_ans", "in", "answer_list", ":", "\n", "# create dict", "\n", "            ", "if", "adict", ".", "has_key", "(", "q_ans", ")", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "=", "1", "\n", "adict", "[", "q_ans", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "\n", "# debug", "\n", "", "", "", "nalist", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "sorted", "(", "nadict", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ":", "\n", "        ", "nalist", ".", "append", "(", "(", "k", ",", "v", ")", ")", "\n", "\n", "# keep the top 3000 answers", "\n", "", "n_del_ans", "=", "0", "\n", "n_valid_ans", "=", "0", "\n", "adict_nid", "=", "{", "}", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", ":", "-", "vocab_size", "]", ")", ":", "\n", "        ", "del", "adict", "[", "w", "[", "0", "]", "]", "\n", "n_del_ans", "+=", "w", "[", "1", "]", "\n", "", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", "-", "vocab_size", ":", "]", ")", ":", "\n", "        ", "n_valid_ans", "+=", "w", "[", "1", "]", "\n", "adict_nid", "[", "w", "[", "0", "]", "]", "=", "i", "\n", "\n", "", "return", "adict_nid", "\n", "\n", "", "def", "make_question_vocab", "(", "qdic", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "vdict", "=", "{", "''", ":", "0", "}", "\n", "vid", "=", "1", "\n", "cdict", "=", "{", "''", ":", "0", "}", "\n", "cvid", "=", "1", "\n", "for", "qid", "in", "qdic", ".", "keys", "(", ")", ":", "\n", "# sequence to list", "\n", "        ", "q_str", "=", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "\n", "# create dict", "\n", "for", "w", "in", "q_list", ":", "\n", "            ", "if", "not", "vdict", ".", "has_key", "(", "w", ")", ":", "\n", "                ", "vdict", "[", "w", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "", "for", "c", "in", "list", "(", "w", ")", ":", "\n", "                ", "if", "not", "cdict", ".", "has_key", "(", "c", ")", ":", "\n", "                    ", "cdict", "[", "c", "]", "=", "cvid", "\n", "cvid", "+=", "1", "\n", "\n", "", "", "", "", "return", "vdict", ",", "cdict", "\n", "\n", "", "def", "make_vocab_files", "(", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).train_att_bc.make_answer_vocab": [[183, 220], ["adic.keys", "sorted", "enumerate", "enumerate", "nadict.items", "nalist.append", "adict.has_key", "config.NUM_OUTPUT_UNITS"], "function", ["None"], ["\n", "write_log", "(", "'making question vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "write_log", "(", "'making question character vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "qdic", ",", "_", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "QUESTION_VOCAB_SPACE", ")", "\n", "question_vocab", ",", "question_char_vocab", "=", "make_question_vocab", "(", "qdic", ")", "\n", "write_log", "(", "'making answer vocab... '", "+", "config", ".", "ANSWER_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "_", ",", "adic", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "ANSWER_VOCAB_SPACE", ")", "\n", "answer_vocab", "=", "make_answer_vocab", "(", "adic", ",", "config", ".", "NUM_OUTPUT_UNITS", ")", "\n", "return", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "'./result'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'./result'", ")", "\n", "\n", "", "question_vocab", ",", "answer_vocab", "=", "{", "}", ",", "{", "}", "\n", "if", "os", ".", "path", ".", "exists", "(", "'./result/cdict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/adict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/vdict.json'", ")", ":", "\n", "        ", "write_log", "(", "'restoring vocab'", ",", "'log.txt'", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_char_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "answer_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "=", "make_vocab_files", "(", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_char_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "answer_vocab", ",", "f", ")", "\n", "\n", "", "", "write_log", "(", "'question character vocab size: '", "+", "str", "(", "len", "(", "question_char_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'question vocab size: '", "+", "str", "(", "len", "(", "question_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'answer vocab size: '", "+", "str", "(", "len", "(", "answer_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).train_att_bc.make_question_vocab": [[221, 245], ["qdic.keys", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "list", "vdict.has_key", "cdict.has_key"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list"], ["with", "open", "(", "'./result/proto_train.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "config", ".", "TRAIN_DATA_SPLITS", ",", "config", ".", "BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "with", "open", "(", "'./result/proto_test.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "'val'", ",", "config", ".", "VAL_BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "caffe", ".", "set_device", "(", "config", ".", "GPU_ID", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "solver", "=", "caffe", ".", "get_solver", "(", "'./qlstm_solver.prototxt'", ")", "\n", "\n", "train_loss", "=", "np", ".", "zeros", "(", "config", ".", "MAX_ITERATIONS", ")", "\n", "# results = []", "\n", "\n", "for", "it", "in", "range", "(", "config", ".", "MAX_ITERATIONS", ")", ":", "\n", "        ", "solver", ".", "step", "(", "1", ")", "\n", "\n", "# store the train loss", "\n", "train_loss", "[", "it", "]", "=", "solver", ".", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", "\n", "\n", "if", "it", "!=", "0", "and", "it", "%", "config", ".", "PRINT_INTERVAL", "==", "0", ":", "\n", "            ", "write_log", "(", "'------------------------------------'", ",", "'log.txt'", ")", "\n", "write_log", "(", "'Iteration: '", "+", "str", "(", "it", ")", ",", "'log.txt'", ")", "\n", "c_mean_loss", "=", "train_loss", "[", "it", "-", "config", ".", "PRINT_INTERVAL", ":", "it", "]", ".", "mean", "(", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).train_att_bc.make_vocab_files": [[246, 258], ["write_to_log.write_log", "write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_question_vocab", "write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_answer_vocab"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_question_vocab", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_answer_vocab"], ["write_log", "(", "'Train loss: '", "+", "str", "(", "c_mean_loss", ")", ",", "'log.txt'", ")", "\n", "", "if", "it", "!=", "0", "and", "it", "%", "config", ".", "VALIDATE_INTERVAL", "==", "0", ":", "# acutually test", "\n", "            ", "solver", ".", "test_nets", "[", "0", "]", ".", "save", "(", "'./result/tmp.caffemodel'", ")", "\n", "write_log", "(", "'Validating...'", ",", "'log.txt'", ")", "\n", "test_loss", ",", "acc_overall", ",", "acc_per_ques", ",", "acc_per_ans", "=", "exec_validation", "(", "config", ".", "GPU_ID", ",", "'val'", ",", "it", "=", "it", ")", "\n", "write_log", "(", "'Iteration: '", "+", "str", "(", "it", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'Test loss: '", "+", "str", "(", "test_loss", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'Overall Accuracy: '", "+", "str", "(", "acc_overall", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'Per Question Type Accuracy is the following:'", ",", "'log.txt'", ")", "\n", "for", "quesType", "in", "acc_per_ques", ":", "\n", "                ", "write_log", "(", "\"%s : %.02f\"", "%", "(", "quesType", ",", "acc_per_ques", "[", "quesType", "]", ")", ",", "'log.txt'", ")", "\n", "", "write_log", "(", "'Per Answer Type Accuracy is the following:'", ",", "'log.txt'", ")", "\n", "for", "ansType", "in", "acc_per_ans", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).train_att_bc.main": [[259, 325], ["write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "caffe.set_device", "caffe.set_mode_gpu", "caffe.get_solver", "numpy.zeros", "range", "os.path.exists", "os.makedirs", "os.path.exists", "os.path.exists", "os.path.exists", "write_to_log.write_log", "train_att_bc.make_vocab_files", "open", "f.write", "open", "f.write", "caffe.get_solver.step", "open", "json.load", "open", "json.load", "open", "json.load", "open", "json.dump", "open", "json.dump", "open", "json.dump", "str", "str", "str", "str", "str", "write_to_log.write_log", "write_to_log.write_log", "train_loss[].mean", "write_to_log.write_log", "caffe.get_solver.test_nets[].save", "write_to_log.write_log", "visualize_tools.exec_validation", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "len", "train_att_bc.qlstm", "train_att_bc.qlstm", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "len", "len", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_vocab_files", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.exec_validation", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["                ", "write_log", "(", "\"%s : %.02f\"", "%", "(", "ansType", ",", "acc_per_ans", "[", "ansType", "]", ")", ",", "'log.txt'", ")", "\n", "# results.append([it, c_mean_loss, test_loss, acc_overall, acc_per_ques, acc_per_ans])", "\n", "# best_result_idx = np.array([x[3] for x in results]).argmax()", "\n", "# write_log('Best accuracy of ' + str(results[best_result_idx][3]) + ' was at iteration ' + str(results[best_result_idx][0]), 'log.txt')", "\n", "# drawgraph(results)", "\n", "\n", "", "", "", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).visualize_tools.visualize_failures": [[27, 119], ["write_to_log.write_log", "visualize_tools.visualize_failures.save_qtype"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["def", "visualize_failures", "(", "stat_list", ",", "mode", ")", ":", "\n", "\n", "    ", "def", "save_qtype", "(", "qtype_list", ",", "save_filename", ",", "mode", ")", ":", "\n", "\n", "        ", "if", "mode", "==", "'val'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./eval'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/val2014'", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test-dev'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "elif", "mode", "==", "'test'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unsupported mode'", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "shutil", ".", "rmtree", "(", "savepath", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "os", ".", "makedirs", "(", "savepath", ")", "\n", "\n", "for", "qt", "in", "qtype_list", ":", "\n", "            ", "count", "=", "0", "\n", "for", "t_question", "in", "stat_list", ":", "\n", "#print count, t_question", "\n", "                ", "if", "count", "<", "40", "/", "len", "(", "qtype_list", ")", ":", "\n", "                    ", "t_question_list", "=", "t_question", "[", "'q_list'", "]", "\n", "saveflag", "=", "False", "\n", "#print 'debug****************************'", "\n", "#print qt", "\n", "#print t_question_list", "\n", "#print t_question_list[0] == qt[0]", "\n", "#print t_question_list[1] == qt[1]", "\n", "if", "t_question_list", "[", "0", "]", "==", "qt", "[", "0", "]", "and", "t_question_list", "[", "1", "]", "==", "qt", "[", "1", "]", ":", "\n", "                        ", "saveflag", "=", "True", "\n", "", "else", ":", "\n", "                        ", "saveflag", "=", "False", "\n", "\n", "", "if", "saveflag", "==", "True", ":", "\n", "                        ", "t_iid", "=", "t_question", "[", "'iid'", "]", "\n", "if", "mode", "==", "'val'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_val2014_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "", "elif", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_test2015_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "\n", "# for caption", "\n", "#print t_iid", "\n", "#annIds = caps.getAnnIds(t_iid)", "\n", "#anns = caps.loadAnns(annIds)", "\n", "#cap_list = [ann['caption'] for ann in anns]", "\n", "", "ans_list", "=", "t_question", "[", "'ans_list'", "]", "\n", "draw", "=", "ImageDraw", ".", "Draw", "(", "t_img", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ans_list", ")", ")", ":", "\n", "                            ", "try", ":", "\n", "                                ", "draw", ".", "text", "(", "(", "10", ",", "10", "*", "i", ")", ",", "str", "(", "ans_list", "[", "i", "]", ")", ")", "\n", "", "except", ":", "\n", "                                ", "pass", "\n", "\n", "", "", "ans", "=", "t_question", "[", "'answer'", "]", "\n", "pred", "=", "t_question", "[", "'pred'", "]", "\n", "if", "ans", "==", "-", "1", ":", "\n", "                            ", "pre", "=", "''", "\n", "", "elif", "ans", "==", "pred", ":", "\n", "                            ", "pre", "=", "'correct  '", "\n", "", "else", ":", "\n", "                            ", "pre", "=", "'failure  '", "\n", "#print ' aaa ', ans, pred", "\n", "", "ans", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "ans", ")", ")", "\n", "pred", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "pred", ")", ")", "\n", "img_title", "=", "pre", "+", "str", "(", "' '", ".", "join", "(", "t_question_list", ")", ")", "+", "'.  a_'", "+", "str", "(", "ans", ")", "+", "' p_'", "+", "str", "(", "pred", ")", "+", "'.png'", "\n", "count", "+=", "1", "\n", "write_log", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ",", "'visualize_log.txt'", ")", "\n", "t_img", ".", "save", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ")", "\n", "\n", "", "", "", "", "", "write_log", "(", "'saving colors'", ",", "'visualize_log.txt'", ")", "\n", "qt_color_list", "=", "[", "[", "'what'", ",", "'color'", "]", "]", "\n", "save_qtype", "(", "qt_color_list", ",", "'colors'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving what is'", ",", "'visualize_log.txt'", ")", "\n", "qt_whatis_list", "=", "[", "[", "'what'", ",", "'is'", "]", ",", "[", "'what'", ",", "'kind'", "]", ",", "[", "'what'", ",", "'are'", "]", "]", "\n", "save_qtype", "(", "qt_whatis_list", ",", "'whatis'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving is'", ",", "'visualize_log.txt'", ")", "\n", "qt_is_list", "=", "[", "[", "'is'", ",", "'the'", "]", ",", "[", "'is'", ",", "'this'", "]", ",", "[", "'is'", ",", "'there'", "]", "]", "\n", "save_qtype", "(", "qt_is_list", ",", "'is'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving how many'", ",", "'visualize_log.txt'", ")", "\n", "qt_howmany_list", "=", "[", "[", "'how'", ",", "'many'", "]", "]", "\n", "save_qtype", "(", "qt_howmany_list", ",", "'howmany'", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).visualize_tools.exec_validation": [[120, 202], ["caffe.set_device", "caffe.set_mode_gpu", "caffe.Net", "vqa_data_provider_layer.VQADataProvider", "len", "numpy.array().mean", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "vqa_data_provider_layer.VQADataProvider.get_batch_vec", "caffe.Net.forward", "caffe.Net.blobs[].data.argmax", "testloss_list.append", "zip", "vqaTools.vqa.VQA", "vqaTools.vqa.VQA.loadRes", "vqaEvaluation.vqaEval.VQAEval", "vqaEvaluation.vqaEval.VQAEval.evaluate", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "t_answer.tolist", "pred_list.append", "numpy.array", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "stat_list.append", "open", "json.dump", "visualize_tools.visualize_failures", "int", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "str().zfill", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "str().zfill", "xrange", "str", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.forward", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj"], ["", "def", "exec_validation", "(", "device_id", ",", "mode", ",", "it", "=", "''", ",", "visualize", "=", "False", ")", ":", "\n", "\n", "    ", "caffe", ".", "set_device", "(", "device_id", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "net", "=", "caffe", ".", "Net", "(", "'./result/proto_test.prototxt'", ",", "'./result/tmp.caffemodel'", ",", "caffe", ".", "TEST", ")", "\n", "\n", "dp", "=", "VQADataProvider", "(", "mode", "=", "mode", ",", "batchsize", "=", "config", ".", "VAL_BATCH_SIZE", ")", "\n", "total_questions", "=", "len", "(", "dp", ".", "getQuesIds", "(", ")", ")", "\n", "epoch", "=", "0", "\n", "\n", "pred_list", "=", "[", "]", "\n", "testloss_list", "=", "[", "]", "\n", "stat_list", "=", "[", "]", "\n", "\n", "while", "epoch", "==", "0", ":", "\n", "        ", "t_word", ",", "t_cont", ",", "t_word_c", ",", "t_cont_c", ",", "t_img_feature", ",", "t_answer", ",", "t_qid_list", ",", "t_iid_list", ",", "epoch", "=", "dp", ".", "get_batch_vec", "(", ")", "\n", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "...", "]", "=", "t_word", "# np.transpose(t_word,(1,0))", "\n", "net", ".", "blobs", "[", "'cont'", "]", ".", "data", "[", "...", "]", "=", "t_cont", "# np.transpose(t_cont,(1,0))", "\n", "net", ".", "blobs", "[", "'data1'", "]", ".", "data", "[", "...", "]", "=", "t_word_c", "\n", "net", ".", "blobs", "[", "'cont1'", "]", ".", "data", "[", "...", "]", "=", "t_cont_c", "\n", "net", ".", "blobs", "[", "'img_feature'", "]", ".", "data", "[", "...", "]", "=", "t_img_feature", "\n", "net", ".", "blobs", "[", "'label'", "]", ".", "data", "[", "...", "]", "=", "t_answer", "\n", "#net.blobs['glove'].data[...] = t_glove_matrix # np.transpose(t_glove_matrix, (1,0,2))", "\n", "net", ".", "forward", "(", ")", "\n", "t_pred_list", "=", "net", ".", "blobs", "[", "'prediction'", "]", ".", "data", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "t_pred_str", "=", "[", "dp", ".", "vec_to_answer", "(", "pred_symbol", ")", "for", "pred_symbol", "in", "t_pred_list", "]", "\n", "testloss_list", ".", "append", "(", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", ")", "\n", "for", "qid", ",", "iid", ",", "ans", ",", "pred", "in", "zip", "(", "t_qid_list", ",", "t_iid_list", ",", "t_answer", ".", "tolist", "(", ")", ",", "t_pred_str", ")", ":", "\n", "            ", "pred_list", ".", "append", "(", "{", "u'answer'", ":", "pred", ",", "u'question_id'", ":", "int", "(", "dp", ".", "getStrippedQuesId", "(", "qid", ")", ")", "}", ")", "\n", "if", "visualize", ":", "\n", "                ", "q_list", "=", "dp", ".", "seq_to_list", "(", "dp", ".", "getQuesStr", "(", "qid", ")", ")", "\n", "if", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                    ", "ans_str", "=", "''", "\n", "ans_list", "=", "[", "''", "]", "*", "10", "\n", "", "else", ":", "\n", "                    ", "ans_str", "=", "dp", ".", "vec_to_answer", "(", "ans", ")", "\n", "ans_list", "=", "[", "dp", ".", "getAnsObj", "(", "qid", ")", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "", "stat_list", ".", "append", "(", "{", "'qid'", ":", "qid", ",", "\n", "'q_list'", ":", "q_list", ",", "\n", "'iid'", ":", "iid", ",", "\n", "'answer'", ":", "ans_str", ",", "\n", "'ans_list'", ":", "ans_list", ",", "\n", "'pred'", ":", "pred", "}", ")", "\n", "#percent = 100 * float(len(pred_list)) / total_questions", "\n", "#sys.stdout.write('\\r' + ('%.2f' % percent) + '%')", "\n", "#sys.stdout.flush()", "\n", "\n", "\n", "\n", "", "", "", "mean_testloss", "=", "np", ".", "array", "(", "testloss_list", ")", ".", "mean", "(", ")", "\n", "\n", "if", "mode", "==", "'val'", ":", "\n", "        ", "valFile", "=", "'./result/val2014_resfile'", "\n", "with", "open", "(", "valFile", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "annFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ans_file'", "]", "\n", "quesFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ques_file'", "]", "\n", "vqa", "=", "VQA", "(", "annFile", ",", "quesFile", ")", "\n", "vqaRes", "=", "vqa", ".", "loadRes", "(", "valFile", ",", "quesFile", ")", "\n", "vqaEval", "=", "VQAEval", "(", "vqa", ",", "vqaRes", ",", "n", "=", "2", ")", "\n", "vqaEval", ".", "evaluate", "(", ")", "\n", "acc_overall", "=", "vqaEval", ".", "accuracy", "[", "'overall'", "]", "\n", "acc_perQuestionType", "=", "vqaEval", ".", "accuracy", "[", "'perQuestionType'", "]", "\n", "acc_perAnswerType", "=", "vqaEval", ".", "accuracy", "[", "'perAnswerType'", "]", "\n", "return", "mean_testloss", ",", "acc_overall", ",", "acc_perQuestionType", ",", "acc_perAnswerType", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test-dev2015_v3t'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "", "elif", "mode", "==", "'test'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test2015_v3c'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (char+word).visualize_tools.drawgraph": [[203, 271], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.twinx", "fig.add_subplot.plot", "fig.add_subplot.plot", "ax1.twinx.plot", "matplotlib.legend", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "ax1.twinx.set_ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "numpy.array", "numpy.array", "matplotlib.figure", "matplotlib.legend", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "sorted", "visualize_tools.drawgraph.draw_qt_acc"], "function", ["None"], ["", "", "", "def", "drawgraph", "(", "results", ",", "save_question_type_graphs", "=", "False", ")", ":", "\n", "# 0:it", "\n", "# 1:trainloss", "\n", "# 2:testloss", "\n", "# 3:oa_acc", "\n", "# 4:qt_acc", "\n", "# 5:at_acc", "\n", "\n", "# training curve", "\n", "    ", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "loss", "=", "np", ".", "array", "(", "[", "l", "[", "1", "]", "for", "l", "in", "results", "]", ")", "\n", "valloss", "=", "np", ".", "array", "(", "[", "l", "[", "2", "]", "for", "l", "in", "results", "]", ")", "\n", "valacc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax1", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "ax2", "=", "ax1", ".", "twinx", "(", ")", "\n", "\n", "ax1", ".", "plot", "(", "it", ",", "loss", ",", "color", "=", "'blue'", ",", "label", "=", "'train loss'", ")", "\n", "ax1", ".", "plot", "(", "it", ",", "valloss", ",", "'--'", ",", "color", "=", "'blue'", ",", "label", "=", "'test loss'", ")", "\n", "ax2", ".", "plot", "(", "it", ",", "valacc", ",", "color", "=", "'red'", ",", "label", "=", "'acc on val'", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'lower left'", ")", "\n", "\n", "ax1", ".", "set_xlabel", "(", "'Iterations'", ")", "\n", "ax1", ".", "set_ylabel", "(", "'Loss Value'", ")", "\n", "ax2", ".", "set_ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "'./learning_curve max_%2.2f.png'", "%", "valacc", ".", "max", "(", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "# question type", "\n", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "oa_acc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "qt_dic_list", "=", "[", "l", "[", "4", "]", "for", "l", "in", "results", "]", "\n", "\n", "def", "draw_qt_acc", "(", "target_key_list", ",", "figname", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "for", "k", "in", "target_key_list", ":", "\n", "            ", "write_log", "(", "str", "(", "k", ")", "+", "str", "(", "type", "(", "k", ")", ")", ",", "'visualize_log.txt'", ")", "\n", "t_val", "=", "np", ".", "array", "(", "[", "qt_dic", "[", "k", "]", "for", "qt_dic", "in", "qt_dic_list", "]", ")", "\n", "plt", ".", "plot", "(", "it", ",", "t_val", ",", "label", "=", "str", "(", "k", ")", ")", "\n", "", "plt", ".", "legend", "(", "fontsize", "=", "'small'", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "100.", ")", "\n", "#plt.legend(prop={'size':6})", "\n", "\n", "plt", ".", "xlabel", "(", "'Iterations'", ")", "\n", "plt", ".", "ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "figname", ",", "dpi", "=", "200", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "", "if", "save_question_type_graphs", ":", "\n", "        ", "s_keys", "=", "sorted", "(", "qt_dic_list", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "0", ":", "13", "]", "+", "[", "s_keys", "[", "31", "]", ",", "]", ",", "'./ind_qt_are.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "13", ":", "17", "]", "+", "s_keys", "[", "49", ":", "]", ",", "'./ind_qt_how_where_who_why.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "17", ":", "31", "]", "+", "[", "s_keys", "[", "32", "]", ",", "]", ",", "'./ind_qt_is.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "33", ":", "49", "]", ",", "'./ind_qt_what.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what color is the'", ",", "'what color are the'", ",", "'what color is'", ",", "'what color'", ",", "'what is the color of the'", "]", ",", "'./qt_color.png'", ")", "\n", "draw_qt_acc", "(", "[", "'how many'", ",", "'how'", ",", "'how many people are'", ",", "'how many people are in'", "]", ",", "'./qt_number.png'", ")", "\n", "draw_qt_acc", "(", "[", "'who is'", ",", "'why'", ",", "'why is the'", ",", "'where is the'", ",", "'where are the'", ",", "'which'", "]", ",", "'./qt_who_why_where_which.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what is the man'", ",", "'is the man'", ",", "'are they'", ",", "'is he'", ",", "'is the woman'", ",", "'is this person'", ",", "'what is the woman'", ",", "'is the person'", ",", "'what is the person'", "]", ",", "'./qt_human.png'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).write_to_log.write_log": [[1, 4], ["open", "f.write"], "function", ["None"], ["def", "write_log", "(", "str", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "+", "\"\\n\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.__init__": [[13, 30], ["vqa_data_provider_layer.VQADataProvider.load_data", "len", "open", "json.load", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data"], ["    ", "def", "__init__", "(", "self", ",", "batchsize", "=", "64", ",", "max_length", "=", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "max_w_length", "=", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "batchsize", "\n", "self", ".", "d_vocabulary", "=", "None", "\n", "self", ".", "batch_index", "=", "None", "\n", "self", ".", "batch_len", "=", "None", "\n", "self", ".", "rev_adict", "=", "None", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "max_w_length", "=", "max_w_length", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "qdic", ",", "self", ".", "adic", "=", "VQADataProvider", ".", "load_data", "(", "mode", ")", "\n", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "cdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "vdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "adict", "=", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.load_vqa_json": [[33, 56], ["write_to_log.write_log", "open", "json.load", "open", "json.load", "str", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["#self.glove_dict = {} # word -> glove vector", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_vqa_json", "(", "data_split", ")", ":", "\n", "        ", "\"\"\"\n        Parses the question and answer json files for the given data split. \n        Returns the question dictionary and the answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ques_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "[", "'questions'", "]", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "qdic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'question_id'", "]", ")", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image_id'", "]", "}", "\n", "\n", "", "", "if", "'test'", "not", "in", "data_split", ":", "\n", "            ", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ans_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "adata", "=", "json", ".", "load", "(", "f", ")", "[", "'annotations'", "]", "\n", "for", "a", "in", "adata", ":", "\n", "                    ", "adic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "a", "[", "'question_id'", "]", ")", "]", "=", "a", "[", "'answers'", "]", "\n", "\n", "", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for '", "+", "data_split", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.load_genome_json": [[57, 74], ["write_to_log.write_log", "open", "json.load", "str", "str", "len"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_genome_json", "(", ")", ":", "\n", "        ", "\"\"\"\n        Parses the genome json file. Returns the question dictionary and the\n        answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'genome_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "key", "=", "'genome'", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'id'", "]", ")", "\n", "qdic", "[", "key", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image'", "]", "}", "\n", "adic", "[", "key", "]", "=", "[", "{", "'answer'", ":", "q", "[", "'answer'", "]", "}", "]", "\n", "\n", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for genome'", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.load_data": [[75, 101], ["data_split_str.split", "config.DATA_PATHS.keys", "vqa_data_provider_layer.VQADataProvider.load_genome_json", "all_qdic.update", "all_adic.update", "vqa_data_provider_layer.VQADataProvider.load_vqa_json", "all_qdic.update", "all_adic.update"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_genome_json", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_vqa_json"], ["return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_data", "(", "data_split_str", ")", ":", "\n", "        ", "all_qdic", ",", "all_adic", "=", "{", "}", ",", "{", "}", "\n", "for", "data_split", "in", "data_split_str", ".", "split", "(", "'+'", ")", ":", "\n", "            ", "assert", "data_split", "in", "config", ".", "DATA_PATHS", ".", "keys", "(", ")", ",", "'unknown data split'", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_genome_json", "(", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "", "else", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_vqa_json", "(", "data_split", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "\n", "", "", "return", "all_qdic", ",", "all_adic", "\n", "\n", "", "def", "getQuesIds", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "qdic", ".", "keys", "(", ")", "\n", "\n", "", "def", "getStrippedQuesId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "[", "1", "]", "\n", "\n", "", "def", "getImgId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'iid'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.getQuesIds": [[102, 104], ["vqa_data_provider_layer.VQADataProvider.qdic.keys"], "methods", ["None"], ["", "def", "getQuesStr", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId": [[105, 107], ["qid.split"], "methods", ["None"], ["", "def", "getAnsObj", "(", "self", ",", "qid", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.getImgId": [[108, 110], ["None"], "methods", ["None"], ["", "return", "self", ".", "adic", "[", "qid", "]", "\n", "\n", "", "@", "staticmethod", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.getQuesStr": [[111, 113], ["None"], "methods", ["None"], ["def", "seq_to_list", "(", "s", ")", ":", "\n", "        ", "t_str", "=", "s", ".", "lower", "(", ")", "\n", "for", "i", "in", "[", "r'\\?'", ",", "r'\\!'", ",", "r'\\''", ",", "r'\\\"'", ",", "r'\\$'", ",", "r'\\:'", ",", "r'\\@'", ",", "r'\\('", ",", "r'\\)'", ",", "r'\\,'", ",", "r'\\.'", ",", "r'\\;'", "]", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.getAnsObj": [[114, 118], ["None"], "methods", ["None"], ["            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "''", ",", "t_str", ")", "\n", "", "for", "i", "in", "[", "r'\\-'", ",", "r'\\/'", "]", ":", "\n", "            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "' '", ",", "t_str", ")", "\n", "", "q_list", "=", "re", ".", "sub", "(", "r'\\?'", ",", "''", ",", "t_str", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "\n", "q_list", "=", "filter", "(", "lambda", "x", ":", "len", "(", "x", ")", ">", "0", ",", "q_list", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.seq_to_list": [[119, 129], ["s.lower", "re.sub().split", "filter", "re.sub", "re.sub", "re.sub", "re.sub.lower", "len"], "methods", ["None"], ["return", "q_list", "\n", "\n", "", "def", "extract_answer", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "", "answer_list", "=", "[", "answer_obj", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "dic", "=", "{", "}", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "dic", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "dic", "[", "ans", "]", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.extract_answer": [[130, 143], ["dic.has_key", "max", "xrange", "dic.items"], "methods", ["None"], ["", "else", ":", "\n", "                ", "dic", "[", "ans", "]", "=", "1", "\n", "", "", "max_key", "=", "max", "(", "(", "v", ",", "k", ")", "for", "(", "k", ",", "v", ")", "in", "dic", ".", "items", "(", ")", ")", "[", "1", "]", "\n", "return", "max_key", "\n", "\n", "", "def", "extract_answer_prob", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "prob_answer_list", "=", "[", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.extract_answer_prob": [[144, 162], ["vqa_data_provider_layer.VQADataProvider.adict.has_key", "len", "random.choice", "prob_answer_list.append", "Exception"], "methods", ["None"], ["                ", "prob_answer_list", ".", "append", "(", "ans", ")", "\n", "\n", "", "", "if", "len", "(", "prob_answer_list", ")", "==", "0", ":", "\n", "            ", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "return", "'hoge'", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"This should not happen.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "random", ".", "choice", "(", "prob_answer_list", ")", "\n", "\n", "# def qlist_to_vec(self, max_length, q_list):", "\n", "#     \"\"\"", "\n", "#     Converts a list of words into a format suitable for the embedding layer.", "\n", "\n", "#     Arguments:", "\n", "#     max_length -- the maximum length of a question sequence", "\n", "#     q_list -- a list of words which are the tokens in the question", "\n", "\n", "#     Returns:", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.qlist_to_vec": [[163, 208], ["numpy.zeros", "numpy.zeros", "xrange", "len", "vqa_data_provider_layer.VQADataProvider.vdict.has_key", "len"], "methods", ["None"], ["#     qvec -- A max_length length vector containing one-hot indices for each word", "\n", "#     cvec -- A max_length length sequence continuation indicator vector", "\n", "#     glove_matrix -- A max_length x GLOVE_EMBEDDING_SIZE matrix containing the glove embedding for", "\n", "#         each word", "\n", "#     \"\"\"", "\n", "#     qvec = np.zeros(max_length)", "\n", "#     cvec = np.zeros(max_length)", "\n", "#     glove_matrix = np.zeros(max_length * GLOVE_EMBEDDING_SIZE).reshape(max_length, GLOVE_EMBEDDING_SIZE)", "\n", "#     for i in xrange(max_length):", "\n", "#         if i < max_length - len(q_list):", "\n", "#             cvec[i] = 0", "\n", "#         else:", "\n", "#             w = q_list[i-(max_length-len(q_list))]", "\n", "#             if w not in self.glove_dict:", "\n", "#                 self.glove_dict[w] = self.nlp(u'%s' % w).vector", "\n", "#             glove_matrix[i] = self.glove_dict[w]", "\n", "#             # is the word in the vocabulary?", "\n", "#             if self.vdict.has_key(w) is False:", "\n", "#                 w = ''", "\n", "#             qvec[i] = self.vdict[w]", "\n", "#             cvec[i] = 1 #0 if i == max_length - len(q_list) else 1", "\n", "#             # UPDATE_10/12:", "\n", "#             #It seems that the original way is right for lstm.", "\n", "#             '''", "\n", "#             This is from https://github.com/BVLC/caffe/pull/1873.", "\n", "#             \"delta_{t,n} should be a binary indicator (i.e., value in {0, 1}),", "\n", "#             where a value of 0 means that timestep t of stream n is the beginning of a new sequence,", "\n", "#             and a value of 1 means that timestep t of stream n is continuing the sequence from timestep t-1 of stream n.", "\n", "#             Under the hood, the previous timestep's hidden state is multiplied by these delta values.", "\n", "#             The fact that these indicators are specified on a per-timestep and per-stream basis allows for streams of arbitrary different lengths without any padding or truncation.", "\n", "#             At the beginning of the forward pass, the final hidden state from the previous forward pass (h_T) is copied into the initial hidden state for the new forward pass (h_0),", "\n", "#             allowing for exact inference across arbitrarily long sequences, even if T == 1.", "\n", "#             However, if any sequences cross batch boundaries, backpropagation through time is approximate -- it is truncated along the batch boundaries.\"", "\n", "#             '''", "\n", "#             # I think the original way is false for CNN here. I want to keep the word embedding for unknown word as zero vector.", "\n", "#             # For example, if we have a sentence of length 7, there would be only 6 1's in cvec.", "\n", "\n", "#     return qvec, cvec, glove_matrix", "\n", "\n", "", "", "def", "qlist_to_vec", "(", "self", ",", "max_length", ",", "max_w_length", ",", "q_list", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.answer_to_vec": [[209, 219], ["vqa_data_provider_layer.VQADataProvider.adict.has_key"], "methods", ["None"], ["\n", "qvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "cvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "qcvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.vec_to_answer": [[220, 229], ["vqa_data_provider_layer.VQADataProvider.adict.items"], "methods", ["None"], ["ccvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "for", "i", "in", "xrange", "(", "max_length", ")", ":", "\n", "            ", "if", "i", "<", "max_length", "-", "len", "(", "q_list", ")", ":", "\n", "                ", "cvec", "[", "i", "]", "=", "0", "\n", "", "else", ":", "\n", "                ", "w", "=", "q_list", "[", "i", "-", "(", "max_length", "-", "len", "(", "q_list", ")", ")", "]", "\n", "# is the word in the vocabulary?", "\n", "if", "self", ".", "vdict", ".", "has_key", "(", "w", ")", "is", "False", ":", "\n", "                    ", "w", "=", "''", "\n", "", "qvec", "[", "i", "]", "=", "self", ".", "vdict", "[", "w", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.create_batch": [[230, 277], ["numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "enumerate", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "vqa_data_provider_layer.VQADataProvider.answer_to_vec", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "qid.split", "vqa_data_provider_layer.VQADataProvider.extract_answer", "vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "numpy.sqrt", "write_to_log.write_log", "numpy.load", "numpy.load", "str", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.answer_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["cvec", "[", "i", "]", "=", "1.0", "/", "len", "(", "q_list", ")", "\n", "j", "=", "max_w_length", "*", "i", "\n", "w_list", "=", "list", "(", "w", ")", "\n", "for", "k", "in", "xrange", "(", "max_w_length", ")", ":", "\n", "                    ", "if", "k", "<", "max_w_length", "-", "len", "(", "w_list", ")", ":", "\n", "                        ", "ccvec", "[", "j", "+", "k", "]", "=", "0", "\n", "", "else", ":", "\n", "                        ", "c", "=", "w_list", "[", "k", "-", "(", "max_w_length", "-", "len", "(", "w_list", ")", ")", "]", "\n", "# is the char in the vocabulary?", "\n", "if", "self", ".", "cdict", ".", "has_key", "(", "c", ")", "is", "False", ":", "\n", "                            ", "c", "=", "''", "\n", "", "qcvec", "[", "j", "+", "k", "]", "=", "self", ".", "cdict", "[", "c", "]", "\n", "ccvec", "[", "j", "+", "k", "]", "=", "1.0", "/", "len", "(", "w_list", ")", "\n", "", "", "", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", "\n", "\n", "", "def", "answer_to_vec", "(", "self", ",", "ans_str", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "if", "self", ".", "adict", ".", "has_key", "(", "ans_str", ")", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "ans_str", "]", "\n", "", "else", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "''", "]", "\n", "", "return", "ans", "\n", "\n", "", "def", "vec_to_answer", "(", "self", ",", "ans_symbol", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "rev_adict", "is", "None", ":", "\n", "            ", "rev_adict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "adict", ".", "items", "(", ")", ":", "\n", "                ", "rev_adict", "[", "v", "]", "=", "k", "\n", "", "self", ".", "rev_adict", "=", "rev_adict", "\n", "\n", "", "return", "self", ".", "rev_adict", "[", "ans_symbol", "]", "\n", "\n", "", "def", "create_batch", "(", "self", ",", "qid_list", ")", ":", "\n", "\n", "        ", "qvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "cvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "qcvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ccvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ivec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "2048", "*", "14", "*", "14", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "2048", ",", "14", ",", "14", ")", "\n", "avec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ")", "\n", "#glove_matrix = np.zeros(self.batchsize * self.max_length * GLOVE_EMBEDDING_SIZE).reshape(\\", "\n", "#self.batchsize, self.max_length, GLOVE_EMBEDDING_SIZE)", "\n", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProvider.get_batch_vec": [[279, 326], ["vqa_data_provider_layer.VQADataProvider.create_batch", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "random.shuffle", "len", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.adict.has_key", "t_qid_list.append", "t_iid_list.append", "vqa_data_provider_layer.VQADataProvider.get_batch_vec.has_at_least_one_valid_answer"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.create_batch", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId"], ["# load raw question information", "\n", "            ", "q_str", "=", "self", ".", "getQuesStr", "(", "qid", ")", "\n", "q_ans", "=", "self", ".", "getAnsObj", "(", "qid", ")", "\n", "q_iid", "=", "self", ".", "getImgId", "(", "qid", ")", "\n", "\n", "# convert question to vec", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "t_qvec", ",", "t_cvec", ",", "t_qcvec", ",", "t_ccvec", "=", "self", ".", "qlist_to_vec", "(", "self", ".", "max_length", ",", "self", ".", "max_w_length", ",", "q_list", ")", "\n", "\n", "try", ":", "\n", "                ", "qid_split", "=", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "\n", "data_split", "=", "qid_split", "[", "0", "]", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "else", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "t_ivec", "=", "(", "t_ivec", "/", "np", ".", "sqrt", "(", "(", "t_ivec", "**", "2", ")", ".", "sum", "(", ")", ")", ")", "\n", "", "except", ":", "\n", "                ", "t_ivec", "=", "0.", "\n", "write_log", "(", "'data not found for qid : '", "+", "str", "(", "q_iid", ")", "+", "' '", "+", "self", ".", "mode", ",", "'log.txt'", ")", "\n", "\n", "# convert answer to vec", "\n", "", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer", "(", "q_ans", ")", "\n", "", "else", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer_prob", "(", "q_ans", ")", "\n", "", "t_avec", "=", "self", ".", "answer_to_vec", "(", "q_ans_str", ")", "\n", "\n", "qvec", "[", "i", ",", "...", "]", "=", "t_qvec", "\n", "cvec", "[", "i", ",", "...", "]", "=", "t_cvec", "\n", "qcvec", "[", "i", ",", "...", "]", "=", "t_qcvec", "\n", "ccvec", "[", "i", ",", "...", "]", "=", "t_ccvec", "\n", "ivec", "[", "i", ",", "...", "]", "=", "t_ivec", "\n", "avec", "[", "i", ",", "...", "]", "=", "t_avec", "\n", "#glove_matrix[i,...] = t_glove_matrix", "\n", "\n", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", ",", "ivec", ",", "avec", "#, glove_matrix", "\n", "\n", "\n", "", "def", "get_batch_vec", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "batch_len", "is", "None", ":", "\n", "            ", "self", ".", "n_skipped", "=", "0", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_len", "=", "len", "(", "qid_list", ")", "\n", "self", ".", "batch_index", "=", "0", "\n", "self", ".", "epoch_counter", "=", "0", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProviderLayer.setup": [[333, 348], ["top[].reshape", "top[].reshape", "top[].reshape", "top[].reshape", "json.loads", "json.loads", "vqa_data_provider_layer.VQADataProvider"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape"], ["                    ", "return", "True", "\n", "\n", "", "", "", "counter", "=", "0", "\n", "t_qid_list", "=", "[", "]", "\n", "t_iid_list", "=", "[", "]", "\n", "while", "counter", "<", "self", ".", "batchsize", ":", "\n", "            ", "t_qid", "=", "self", ".", "qid_list", "[", "self", ".", "batch_index", "]", "\n", "t_iid", "=", "self", ".", "getImgId", "(", "t_qid", ")", "\n", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n", "", "elif", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProviderLayer.reshape": [[349, 351], ["None"], "methods", ["None"], ["", "else", ":", "\n", "                ", "self", ".", "n_skipped", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProviderLayer.forward": [[352, 362], ["vqa_data_provider_layer.VQADataProviderLayer.dp.get_batch_vec"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec"], ["", "if", "self", ".", "batch_index", "<", "self", ".", "batch_len", "-", "1", ":", "\n", "                ", "self", ".", "batch_index", "+=", "1", "\n", "", "else", ":", "\n", "                ", "self", ".", "epoch_counter", "+=", "1", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_index", "=", "0", "\n", "write_log", "(", "\"%d questions were skipped in a single epoch\"", "%", "self", ".", "n_skipped", ",", "'log.txt'", ")", "\n", "self", ".", "n_skipped", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).vqa_data_provider_layer.VQADataProviderLayer.backward": [[364, 366], ["None"], "methods", ["None"], ["return", "t_batch", "+", "(", "t_qid_list", ",", "t_iid_list", ",", "self", ".", "epoch_counter", ")", "\n", "\n", "", "", "class", "VQADataProviderLayer", "(", "caffe", ".", "Layer", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).train_att_bc.qlstm": [[19, 92], ["caffe.NetSpec", "json.dumps", "caffe.layers.Python", "caffe.layers.Embed", "caffe.layers.Scale", "caffe.layers.Reshape", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.ReLU", "caffe.layers.ReLU", "caffe.layers.ReLU", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Concat", "caffe.layers.Dropout", "caffe.layers.Tile", "caffe.layers.Tile", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.Reshape", "caffe.layers.Softmax", "caffe.layers.Reshape", "caffe.layers.Slice", "caffe.layers.DummyData", "caffe.layers.SoftAttention", "caffe.layers.SoftAttention", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Concat", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Reshape", "caffe.layers.InnerProduct", "caffe.layers.SoftmaxWithLoss", "caffe.NetSpec.to_proto", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "config.TRAIN_DATA_SPLITS", "config.BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION", "config.VAL_BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION"], "function", ["None"], ["def", "qlstm", "(", "mode", ",", "batchsize", ",", "T", ",", "T_c", ",", "question_c_vocab_size", ",", "question_vocab_size", ")", ":", "\n", "    ", "n", "=", "caffe", ".", "NetSpec", "(", ")", "\n", "mode_str", "=", "json", ".", "dumps", "(", "{", "'mode'", ":", "mode", ",", "'batchsize'", ":", "batchsize", "}", ")", "\n", "n", ".", "data", ",", "n", ".", "cont", ",", "n", ".", "data1", ",", "n", ".", "cont1", ",", "n", ".", "img_feature", ",", "n", ".", "label", "=", "L", ".", "Python", "(", "module", "=", "'vqa_data_provider_layer'", ",", "layer", "=", "'VQADataProviderLayer'", ",", "param_str", "=", "mode_str", ",", "ntop", "=", "6", ")", "#5 )", "\n", "\n", "# char embedding", "\n", "n", ".", "embed_c", "=", "L", ".", "Embed", "(", "n", ".", "data1", ",", "input_dim", "=", "question_c_vocab_size", ",", "num_output", "=", "100", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "\n", "n", ".", "embed_c_scale", "=", "L", ".", "Scale", "(", "n", ".", "embed_c", ",", "n", ".", "cont1", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "\n", "n", ".", "embed_c_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_c_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T_c", "*", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T_c*T x d_c x 1", "\n", "tops", "=", "L", ".", "Slice", "(", "n", ".", "embed_c_scale_resh", ",", "ntop", "=", "T", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T_c x d_c x 1", "\n", "for", "i", "in", "xrange", "(", "T", ")", ":", "\n", "        ", "n", ".", "__setattr__", "(", "'Slice_'", "+", "str", "(", "i", "+", "1", ")", ",", "tops", "[", "int", "(", "i", ")", "]", ")", "\n", "\n", "# avg of char embedding", "\n", "", "n", ".", "c_embed_1", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_1", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_2", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_2", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_3", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_3", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_4", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_4", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_5", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_5", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_6", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_6", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_7", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_7", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_8", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_8", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_9", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_9", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_10", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_10", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_11", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_11", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_12", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_12", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_13", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_13", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_14", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_14", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_15", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_15", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_16", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_16", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_17", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_17", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_18", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_18", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_19", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_19", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_20", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_20", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_21", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_21", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_22", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_22", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "\n", "concat_c_embed", "=", "[", "n", ".", "c_embed_1", ",", "n", ".", "c_embed_2", ",", "n", ".", "c_embed_3", ",", "n", ".", "c_embed_4", ",", "n", ".", "c_embed_5", ",", "n", ".", "c_embed_6", ",", "n", ".", "c_embed_7", ",", "n", ".", "c_embed_8", ",", "n", ".", "c_embed_9", ",", "n", ".", "c_embed_10", ",", "n", ".", "c_embed_11", ",", "n", ".", "c_embed_12", ",", "n", ".", "c_embed_13", ",", "n", ".", "c_embed_14", ",", "n", ".", "c_embed_15", ",", "n", ".", "c_embed_16", ",", "n", ".", "c_embed_17", ",", "n", ".", "c_embed_18", ",", "n", ".", "c_embed_19", ",", "n", ".", "c_embed_20", ",", "n", ".", "c_embed_21", ",", "n", ".", "c_embed_22", "]", "\n", "n", ".", "concat_char_embed", "=", "L", ".", "Concat", "(", "*", "concat_c_embed", ",", "concat_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T x d_c x 1", "\n", "n", ".", "concat_char_embed_resh", "=", "L", ".", "Reshape", "(", "n", ".", "concat_char_embed", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", "]", ")", ")", ")", "\n", "\n", "# word embedding", "\n", "n", ".", "embed_w", "=", "L", ".", "Embed", "(", "n", ".", "data", ",", "input_dim", "=", "question_vocab_size", ",", "num_output", "=", "200", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "# N x T x d_w", "\n", "\n", "# combine word and char embedding", "\n", "concat_word_embed", "=", "[", "n", ".", "embed_w", ",", "n", ".", "concat_char_embed_resh", "]", "\n", "n", ".", "concat_embed", "=", "L", ".", "Concat", "(", "*", "concat_word_embed", ",", "concat_param", "=", "{", "'axis'", ":", "2", "}", ")", "# N x T x (d_c+d_w)", "\n", "\n", "n", ".", "embed_scale", "=", "L", ".", "Scale", "(", "n", ".", "concat_embed", ",", "n", ".", "cont", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "# N x T x (d_c+d_w)", "\n", "n", ".", "embed_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T x (d_c+d_w) x 1", "\n", "\n", "# avg of word embedding", "\n", "n", ".", "embed_avg", "=", "L", ".", "Convolution", "(", "n", ".", "embed_scale_resh", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x (d_c+d_w) x 1", "\n", "n", ".", "embed_avg_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_avg", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "300", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled_1", "=", "L", ".", "Tile", "(", "n", ".", "embed_avg_resh", ",", "axis", "=", "2", ",", "tiles", "=", "14", ")", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled", "=", "L", ".", "Tile", "(", "n", ".", "q_emb_tanh_droped_resh_tiled_1", ",", "axis", "=", "3", ",", "tiles", "=", "14", ")", "\n", "n", ".", "i_emb_tanh_droped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "img_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "n", ".", "blcf", "=", "L", ".", "CompactBilinear", "(", "n", ".", "q_emb_tanh_droped_resh_tiled", ",", "n", ".", "i_emb_tanh_droped_resh", ",", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "blcf_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "blcf", ")", "\n", "n", ".", "blcf_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "blcf_sign_sqrt", ")", "\n", "n", ".", "blcf_droped", "=", "L", ".", "Dropout", "(", "n", ".", "blcf_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "\n", "# multi-channel attention", "\n", "n", ".", "att_conv1", "=", "L", ".", "Convolution", "(", "n", ".", "blcf_droped", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "512", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_conv1_relu", "=", "L", ".", "ReLU", "(", "n", ".", "att_conv1", ")", "\n", "n", ".", "att_conv2", "=", "L", ".", "Convolution", "(", "n", ".", "att_conv1_relu", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "2", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_reshaped", "=", "L", ".", "Reshape", "(", "n", ".", "att_conv2", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", "*", "14", "]", ")", ")", ")", "\n", "n", ".", "att_softmax", "=", "L", ".", "Softmax", "(", "n", ".", "att_reshaped", ",", "axis", "=", "2", ")", "\n", "n", ".", "att", "=", "L", ".", "Reshape", "(", "n", ".", "att_softmax", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", ",", "14", "]", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).train_att_bc.make_answer_vocab": [[93, 130], ["adic.keys", "sorted", "enumerate", "enumerate", "nadict.items", "nalist.append", "adict.has_key", "config.NUM_OUTPUT_UNITS"], "function", ["None"], ["att_maps", "=", "L", ".", "Slice", "(", "n", ".", "att", ",", "ntop", "=", "2", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "\n", "n", ".", "att_map0", "=", "att_maps", "[", "0", "]", "\n", "n", ".", "att_map1", "=", "att_maps", "[", "1", "]", "\n", "dummy", "=", "L", ".", "DummyData", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "1", "]", ")", ",", "data_filler", "=", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", ",", "ntop", "=", "1", ")", "\n", "n", ".", "att_feature0", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map0", ",", "dummy", ")", "\n", "n", ".", "att_feature1", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map1", ",", "dummy", ")", "\n", "n", ".", "att_feature0_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature0", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature1_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature1", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature", "=", "L", ".", "Concat", "(", "n", ".", "att_feature0_resh", ",", "n", ".", "att_feature1_resh", ")", "\n", "\n", "# merge attention and lstm with compact bilinear pooling", "\n", "n", ".", "att_feature_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "4096", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "#n.lstm_12_resh = L.Reshape(n.lstm_12, reshape_param=dict(shape=dict(dim=[-1,2048,1,1])))", "\n", "n", ".", "bc_att_lstm", "=", "L", ".", "CompactBilinear", "(", "n", ".", "att_feature_resh", ",", "n", ".", "embed_avg_resh", ",", "\n", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "bc_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "bc_att_lstm", ")", "\n", "n", ".", "bc_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "bc_sign_sqrt", ")", "\n", "\n", "n", ".", "bc_dropped", "=", "L", ".", "Dropout", "(", "n", ".", "bc_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "n", ".", "bc_dropped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "bc_dropped", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "16000", "]", ")", ")", ")", "\n", "\n", "n", ".", "prediction", "=", "L", ".", "InnerProduct", "(", "n", ".", "bc_dropped_resh", ",", "num_output", "=", "3000", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "loss", "=", "L", ".", "SoftmaxWithLoss", "(", "n", ".", "prediction", ",", "n", ".", "label", ")", "\n", "return", "n", ".", "to_proto", "(", ")", "\n", "\n", "", "def", "make_answer_vocab", "(", "adic", ",", "vocab_size", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "adict", "=", "{", "''", ":", "0", "}", "\n", "nadict", "=", "{", "''", ":", "1000000", "}", "\n", "vid", "=", "1", "\n", "for", "qid", "in", "adic", ".", "keys", "(", ")", ":", "\n", "        ", "answer_obj", "=", "adic", "[", "qid", "]", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "\n", "for", "q_ans", "in", "answer_list", ":", "\n", "# create dict", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).train_att_bc.make_question_vocab": [[131, 149], ["qdic.keys", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vdict.has_key"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list"], ["            ", "if", "adict", ".", "has_key", "(", "q_ans", ")", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "=", "1", "\n", "adict", "[", "q_ans", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "\n", "# debug", "\n", "", "", "", "nalist", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "sorted", "(", "nadict", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ":", "\n", "        ", "nalist", ".", "append", "(", "(", "k", ",", "v", ")", ")", "\n", "\n", "# keep the top 3000 answers", "\n", "", "n_del_ans", "=", "0", "\n", "n_valid_ans", "=", "0", "\n", "adict_nid", "=", "{", "}", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", ":", "-", "vocab_size", "]", ")", ":", "\n", "        ", "del", "adict", "[", "w", "[", "0", "]", "]", "\n", "n_del_ans", "+=", "w", "[", "1", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).train_att_bc.make_vocab_files": [[150, 161], ["write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_question_vocab", "write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_answer_vocab"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_question_vocab", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_answer_vocab"], ["", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", "-", "vocab_size", ":", "]", ")", ":", "\n", "        ", "n_valid_ans", "+=", "w", "[", "1", "]", "\n", "adict_nid", "[", "w", "[", "0", "]", "]", "=", "i", "\n", "\n", "", "return", "adict_nid", "\n", "\n", "", "def", "make_question_vocab", "(", "qdic", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "vdict", "=", "{", "''", ":", "0", "}", "\n", "vid", "=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).train_att_bc.main": [[162, 222], ["write_to_log.write_log", "write_to_log.write_log", "caffe.set_device", "caffe.set_mode_gpu", "caffe.get_solver", "numpy.zeros", "range", "os.path.exists", "os.makedirs", "os.path.exists", "os.path.exists", "write_to_log.write_log", "train_att_bc.make_vocab_files", "open", "f.write", "open", "f.write", "caffe.get_solver.step", "open", "json.load", "open", "json.load", "open", "json.dump", "open", "json.dump", "str", "str", "str", "str", "write_to_log.write_log", "write_to_log.write_log", "train_loss[].mean", "write_to_log.write_log", "caffe.get_solver.test_nets[].save", "write_to_log.write_log", "visualize_tools.exec_validation", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "train_att_bc.qlstm", "train_att_bc.qlstm", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_vocab_files", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.exec_validation", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["cdict", "=", "{", "''", ":", "0", "}", "\n", "cvid", "=", "1", "\n", "for", "qid", "in", "qdic", ".", "keys", "(", ")", ":", "\n", "# sequence to list", "\n", "        ", "q_str", "=", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "\n", "# create dict", "\n", "for", "w", "in", "q_list", ":", "\n", "            ", "if", "not", "vdict", ".", "has_key", "(", "w", ")", ":", "\n", "                ", "vdict", "[", "w", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "", "for", "c", "in", "list", "(", "w", ")", ":", "\n", "                ", "if", "not", "cdict", ".", "has_key", "(", "c", ")", ":", "\n", "                    ", "cdict", "[", "c", "]", "=", "cvid", "\n", "cvid", "+=", "1", "\n", "\n", "", "", "", "", "return", "vdict", ",", "cdict", "\n", "\n", "", "def", "make_vocab_files", "(", ")", ":", "\n", "    ", "\"\"\"\n    Produce the question and answer vocabulary files.\n    \"\"\"", "\n", "write_log", "(", "'making question vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "write_log", "(", "'making question character vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "qdic", ",", "_", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "QUESTION_VOCAB_SPACE", ")", "\n", "question_vocab", ",", "question_char_vocab", "=", "make_question_vocab", "(", "qdic", ")", "\n", "write_log", "(", "'making answer vocab... '", "+", "config", ".", "ANSWER_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "_", ",", "adic", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "ANSWER_VOCAB_SPACE", ")", "\n", "answer_vocab", "=", "make_answer_vocab", "(", "adic", ",", "config", ".", "NUM_OUTPUT_UNITS", ")", "\n", "return", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "'./result'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'./result'", ")", "\n", "\n", "", "question_vocab", ",", "answer_vocab", "=", "{", "}", ",", "{", "}", "\n", "if", "os", ".", "path", ".", "exists", "(", "'./result/cdict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/adict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/vdict.json'", ")", ":", "\n", "        ", "write_log", "(", "'restoring vocab'", ",", "'log.txt'", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_char_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "answer_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "=", "make_vocab_files", "(", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_char_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "answer_vocab", ",", "f", ")", "\n", "\n", "", "", "write_log", "(", "'question character vocab size: '", "+", "str", "(", "len", "(", "question_char_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'question vocab size: '", "+", "str", "(", "len", "(", "question_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'answer vocab size: '", "+", "str", "(", "len", "(", "answer_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "\n", "\n", "with", "open", "(", "'./result/proto_train.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "config", ".", "TRAIN_DATA_SPLITS", ",", "config", ".", "BATCH_SIZE", ","]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).visualize_tools.visualize_failures": [[27, 119], ["write_to_log.write_log", "visualize_tools.visualize_failures.save_qtype"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["def", "visualize_failures", "(", "stat_list", ",", "mode", ")", ":", "\n", "\n", "    ", "def", "save_qtype", "(", "qtype_list", ",", "save_filename", ",", "mode", ")", ":", "\n", "\n", "        ", "if", "mode", "==", "'val'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./eval'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/val2014'", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test-dev'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "elif", "mode", "==", "'test'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unsupported mode'", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "shutil", ".", "rmtree", "(", "savepath", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "os", ".", "makedirs", "(", "savepath", ")", "\n", "\n", "for", "qt", "in", "qtype_list", ":", "\n", "            ", "count", "=", "0", "\n", "for", "t_question", "in", "stat_list", ":", "\n", "#print count, t_question", "\n", "                ", "if", "count", "<", "40", "/", "len", "(", "qtype_list", ")", ":", "\n", "                    ", "t_question_list", "=", "t_question", "[", "'q_list'", "]", "\n", "saveflag", "=", "False", "\n", "#print 'debug****************************'", "\n", "#print qt", "\n", "#print t_question_list", "\n", "#print t_question_list[0] == qt[0]", "\n", "#print t_question_list[1] == qt[1]", "\n", "if", "t_question_list", "[", "0", "]", "==", "qt", "[", "0", "]", "and", "t_question_list", "[", "1", "]", "==", "qt", "[", "1", "]", ":", "\n", "                        ", "saveflag", "=", "True", "\n", "", "else", ":", "\n", "                        ", "saveflag", "=", "False", "\n", "\n", "", "if", "saveflag", "==", "True", ":", "\n", "                        ", "t_iid", "=", "t_question", "[", "'iid'", "]", "\n", "if", "mode", "==", "'val'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_val2014_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "", "elif", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_test2015_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "\n", "# for caption", "\n", "#print t_iid", "\n", "#annIds = caps.getAnnIds(t_iid)", "\n", "#anns = caps.loadAnns(annIds)", "\n", "#cap_list = [ann['caption'] for ann in anns]", "\n", "", "ans_list", "=", "t_question", "[", "'ans_list'", "]", "\n", "draw", "=", "ImageDraw", ".", "Draw", "(", "t_img", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ans_list", ")", ")", ":", "\n", "                            ", "try", ":", "\n", "                                ", "draw", ".", "text", "(", "(", "10", ",", "10", "*", "i", ")", ",", "str", "(", "ans_list", "[", "i", "]", ")", ")", "\n", "", "except", ":", "\n", "                                ", "pass", "\n", "\n", "", "", "ans", "=", "t_question", "[", "'answer'", "]", "\n", "pred", "=", "t_question", "[", "'pred'", "]", "\n", "if", "ans", "==", "-", "1", ":", "\n", "                            ", "pre", "=", "''", "\n", "", "elif", "ans", "==", "pred", ":", "\n", "                            ", "pre", "=", "'correct  '", "\n", "", "else", ":", "\n", "                            ", "pre", "=", "'failure  '", "\n", "#print ' aaa ', ans, pred", "\n", "", "ans", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "ans", ")", ")", "\n", "pred", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "pred", ")", ")", "\n", "img_title", "=", "pre", "+", "str", "(", "' '", ".", "join", "(", "t_question_list", ")", ")", "+", "'.  a_'", "+", "str", "(", "ans", ")", "+", "' p_'", "+", "str", "(", "pred", ")", "+", "'.png'", "\n", "count", "+=", "1", "\n", "write_log", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ",", "'visualize_log.txt'", ")", "\n", "t_img", ".", "save", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ")", "\n", "\n", "", "", "", "", "", "write_log", "(", "'saving colors'", ",", "'visualize_log.txt'", ")", "\n", "qt_color_list", "=", "[", "[", "'what'", ",", "'color'", "]", "]", "\n", "save_qtype", "(", "qt_color_list", ",", "'colors'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving what is'", ",", "'visualize_log.txt'", ")", "\n", "qt_whatis_list", "=", "[", "[", "'what'", ",", "'is'", "]", ",", "[", "'what'", ",", "'kind'", "]", ",", "[", "'what'", ",", "'are'", "]", "]", "\n", "save_qtype", "(", "qt_whatis_list", ",", "'whatis'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving is'", ",", "'visualize_log.txt'", ")", "\n", "qt_is_list", "=", "[", "[", "'is'", ",", "'the'", "]", ",", "[", "'is'", ",", "'this'", "]", ",", "[", "'is'", ",", "'there'", "]", "]", "\n", "save_qtype", "(", "qt_is_list", ",", "'is'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving how many'", ",", "'visualize_log.txt'", ")", "\n", "qt_howmany_list", "=", "[", "[", "'how'", ",", "'many'", "]", "]", "\n", "save_qtype", "(", "qt_howmany_list", ",", "'howmany'", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).visualize_tools.exec_validation": [[120, 201], ["caffe.set_device", "caffe.set_mode_gpu", "caffe.Net", "vqa_data_provider_layer.VQADataProvider", "len", "numpy.array().mean", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "vqa_data_provider_layer.VQADataProvider.get_batch_vec", "caffe.Net.forward", "caffe.Net.blobs[].data.argmax", "testloss_list.append", "zip", "vqaTools.vqa.VQA", "vqaTools.vqa.VQA.loadRes", "vqaEvaluation.vqaEval.VQAEval", "vqaEvaluation.vqaEval.VQAEval.evaluate", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "t_answer.tolist", "pred_list.append", "numpy.array", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "stat_list.append", "open", "json.dump", "visualize_tools.visualize_failures", "int", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "str().zfill", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "str().zfill", "xrange", "str", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.forward", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj"], ["", "def", "exec_validation", "(", "device_id", ",", "mode", ",", "it", "=", "''", ",", "visualize", "=", "False", ")", ":", "\n", "\n", "    ", "caffe", ".", "set_device", "(", "device_id", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "net", "=", "caffe", ".", "Net", "(", "'./result/proto_test.prototxt'", ",", "'./result/tmp.caffemodel'", ",", "caffe", ".", "TEST", ")", "\n", "\n", "dp", "=", "VQADataProvider", "(", "mode", "=", "mode", ",", "batchsize", "=", "config", ".", "VAL_BATCH_SIZE", ")", "\n", "total_questions", "=", "len", "(", "dp", ".", "getQuesIds", "(", ")", ")", "\n", "epoch", "=", "0", "\n", "\n", "pred_list", "=", "[", "]", "\n", "testloss_list", "=", "[", "]", "\n", "stat_list", "=", "[", "]", "\n", "\n", "while", "epoch", "==", "0", ":", "\n", "        ", "t_word", ",", "t_cont", ",", "t_word_c", ",", "t_cont_c", ",", "t_img_feature", ",", "t_answer", ",", "t_qid_list", ",", "t_iid_list", ",", "epoch", "=", "dp", ".", "get_batch_vec", "(", ")", "\n", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "...", "]", "=", "t_word", "# np.transpose(t_word,(1,0))", "\n", "net", ".", "blobs", "[", "'cont'", "]", ".", "data", "[", "...", "]", "=", "t_cont", "# np.transpose(t_cont,(1,0))", "\n", "net", ".", "blobs", "[", "'data1'", "]", ".", "data", "[", "...", "]", "=", "t_word_c", "\n", "net", ".", "blobs", "[", "'cont1'", "]", ".", "data", "[", "...", "]", "=", "t_cont_c", "\n", "net", ".", "blobs", "[", "'img_feature'", "]", ".", "data", "[", "...", "]", "=", "t_img_feature", "\n", "net", ".", "blobs", "[", "'label'", "]", ".", "data", "[", "...", "]", "=", "t_answer", "\n", "#net.blobs['glove'].data[...] = t_glove_matrix # np.transpose(t_glove_matrix, (1,0,2))", "\n", "net", ".", "forward", "(", ")", "\n", "t_pred_list", "=", "net", ".", "blobs", "[", "'prediction'", "]", ".", "data", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "t_pred_str", "=", "[", "dp", ".", "vec_to_answer", "(", "pred_symbol", ")", "for", "pred_symbol", "in", "t_pred_list", "]", "\n", "testloss_list", ".", "append", "(", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", ")", "\n", "for", "qid", ",", "iid", ",", "ans", ",", "pred", "in", "zip", "(", "t_qid_list", ",", "t_iid_list", ",", "t_answer", ".", "tolist", "(", ")", ",", "t_pred_str", ")", ":", "\n", "            ", "pred_list", ".", "append", "(", "{", "u'answer'", ":", "pred", ",", "u'question_id'", ":", "int", "(", "dp", ".", "getStrippedQuesId", "(", "qid", ")", ")", "}", ")", "\n", "if", "visualize", ":", "\n", "                ", "q_list", "=", "dp", ".", "seq_to_list", "(", "dp", ".", "getQuesStr", "(", "qid", ")", ")", "\n", "if", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                    ", "ans_str", "=", "''", "\n", "ans_list", "=", "[", "''", "]", "*", "10", "\n", "", "else", ":", "\n", "                    ", "ans_str", "=", "dp", ".", "vec_to_answer", "(", "ans", ")", "\n", "ans_list", "=", "[", "dp", ".", "getAnsObj", "(", "qid", ")", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "", "stat_list", ".", "append", "(", "{", "'qid'", ":", "qid", ",", "\n", "'q_list'", ":", "q_list", ",", "\n", "'iid'", ":", "iid", ",", "\n", "'answer'", ":", "ans_str", ",", "\n", "'ans_list'", ":", "ans_list", ",", "\n", "'pred'", ":", "pred", "}", ")", "\n", "#percent = 100 * float(len(pred_list)) / total_questions", "\n", "#sys.stdout.write('\\r' + ('%.2f' % percent) + '%')", "\n", "#sys.stdout.flush()", "\n", "\n", "\n", "\n", "", "", "", "mean_testloss", "=", "np", ".", "array", "(", "testloss_list", ")", ".", "mean", "(", ")", "\n", "\n", "if", "mode", "==", "'val'", ":", "\n", "        ", "valFile", "=", "'./result/val2014_resfile'", "\n", "with", "open", "(", "valFile", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "annFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ans_file'", "]", "\n", "quesFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ques_file'", "]", "\n", "vqa", "=", "VQA", "(", "annFile", ",", "quesFile", ")", "\n", "vqaRes", "=", "vqa", ".", "loadRes", "(", "valFile", ",", "quesFile", ")", "\n", "vqaEval", "=", "VQAEval", "(", "vqa", ",", "vqaRes", ",", "n", "=", "2", ")", "\n", "vqaEval", ".", "evaluate", "(", ")", "\n", "acc_overall", "=", "vqaEval", ".", "accuracy", "[", "'overall'", "]", "\n", "acc_perQuestionType", "=", "vqaEval", ".", "accuracy", "[", "'perQuestionType'", "]", "\n", "acc_perAnswerType", "=", "vqaEval", ".", "accuracy", "[", "'perAnswerType'", "]", "\n", "return", "mean_testloss", ",", "acc_overall", ",", "acc_perQuestionType", ",", "acc_perAnswerType", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test-dev2015_v3t'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "", "elif", "mode", "==", "'test'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test2015_v3c'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception (word).visualize_tools.drawgraph": [[202, 270], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.twinx", "fig.add_subplot.plot", "fig.add_subplot.plot", "ax1.twinx.plot", "matplotlib.legend", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "ax1.twinx.set_ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "numpy.array", "numpy.array", "matplotlib.figure", "matplotlib.legend", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "sorted", "visualize_tools.drawgraph.draw_qt_acc"], "function", ["None"], ["\n", "", "", "", "def", "drawgraph", "(", "results", ",", "save_question_type_graphs", "=", "False", ")", ":", "\n", "# 0:it", "\n", "# 1:trainloss", "\n", "# 2:testloss", "\n", "# 3:oa_acc", "\n", "# 4:qt_acc", "\n", "# 5:at_acc", "\n", "\n", "# training curve", "\n", "    ", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "loss", "=", "np", ".", "array", "(", "[", "l", "[", "1", "]", "for", "l", "in", "results", "]", ")", "\n", "valloss", "=", "np", ".", "array", "(", "[", "l", "[", "2", "]", "for", "l", "in", "results", "]", ")", "\n", "valacc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax1", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "ax2", "=", "ax1", ".", "twinx", "(", ")", "\n", "\n", "ax1", ".", "plot", "(", "it", ",", "loss", ",", "color", "=", "'blue'", ",", "label", "=", "'train loss'", ")", "\n", "ax1", ".", "plot", "(", "it", ",", "valloss", ",", "'--'", ",", "color", "=", "'blue'", ",", "label", "=", "'test loss'", ")", "\n", "ax2", ".", "plot", "(", "it", ",", "valacc", ",", "color", "=", "'red'", ",", "label", "=", "'acc on val'", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'lower left'", ")", "\n", "\n", "ax1", ".", "set_xlabel", "(", "'Iterations'", ")", "\n", "ax1", ".", "set_ylabel", "(", "'Loss Value'", ")", "\n", "ax2", ".", "set_ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "'./learning_curve max_%2.2f.png'", "%", "valacc", ".", "max", "(", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "# question type", "\n", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "oa_acc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "qt_dic_list", "=", "[", "l", "[", "4", "]", "for", "l", "in", "results", "]", "\n", "\n", "def", "draw_qt_acc", "(", "target_key_list", ",", "figname", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "for", "k", "in", "target_key_list", ":", "\n", "            ", "write_log", "(", "str", "(", "k", ")", "+", "str", "(", "type", "(", "k", ")", ")", ",", "'visualize_log.txt'", ")", "\n", "t_val", "=", "np", ".", "array", "(", "[", "qt_dic", "[", "k", "]", "for", "qt_dic", "in", "qt_dic_list", "]", ")", "\n", "plt", ".", "plot", "(", "it", ",", "t_val", ",", "label", "=", "str", "(", "k", ")", ")", "\n", "", "plt", ".", "legend", "(", "fontsize", "=", "'small'", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "100.", ")", "\n", "#plt.legend(prop={'size':6})", "\n", "\n", "plt", ".", "xlabel", "(", "'Iterations'", ")", "\n", "plt", ".", "ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "figname", ",", "dpi", "=", "200", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "", "if", "save_question_type_graphs", ":", "\n", "        ", "s_keys", "=", "sorted", "(", "qt_dic_list", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "0", ":", "13", "]", "+", "[", "s_keys", "[", "31", "]", ",", "]", ",", "'./ind_qt_are.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "13", ":", "17", "]", "+", "s_keys", "[", "49", ":", "]", ",", "'./ind_qt_how_where_who_why.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "17", ":", "31", "]", "+", "[", "s_keys", "[", "32", "]", ",", "]", ",", "'./ind_qt_is.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "33", ":", "49", "]", ",", "'./ind_qt_what.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what color is the'", ",", "'what color are the'", ",", "'what color is'", ",", "'what color'", ",", "'what is the color of the'", "]", ",", "'./qt_color.png'", ")", "\n", "draw_qt_acc", "(", "[", "'how many'", ",", "'how'", ",", "'how many people are'", ",", "'how many people are in'", "]", ",", "'./qt_number.png'", ")", "\n", "draw_qt_acc", "(", "[", "'who is'", ",", "'why'", ",", "'why is the'", ",", "'where is the'", ",", "'where are the'", ",", "'which'", "]", ",", "'./qt_who_why_where_which.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what is the man'", ",", "'is the man'", ",", "'are they'", ",", "'is he'", ",", "'is the woman'", ",", "'is this person'", ",", "'what is the woman'", ",", "'is the person'", ",", "'what is the person'", "]", ",", "'./qt_human.png'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).write_to_log.write_log": [[1, 4], ["open", "f.write"], "function", ["None"], ["def", "write_log", "(", "str", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "+", "\"\\n\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.__init__": [[13, 30], ["vqa_data_provider_layer.VQADataProvider.load_data", "len", "open", "json.load", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data"], ["    ", "def", "__init__", "(", "self", ",", "batchsize", "=", "64", ",", "max_length", "=", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "max_w_length", "=", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "batchsize", "\n", "self", ".", "d_vocabulary", "=", "None", "\n", "self", ".", "batch_index", "=", "None", "\n", "self", ".", "batch_len", "=", "None", "\n", "self", ".", "rev_adict", "=", "None", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "max_w_length", "=", "max_w_length", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "qdic", ",", "self", ".", "adic", "=", "VQADataProvider", ".", "load_data", "(", "mode", ")", "\n", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "cdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "vdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "adict", "=", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.load_vqa_json": [[33, 56], ["write_to_log.write_log", "open", "json.load", "open", "json.load", "str", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["#self.glove_dict = {} # word -> glove vector", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_vqa_json", "(", "data_split", ")", ":", "\n", "        ", "\"\"\"\n        Parses the question and answer json files for the given data split. \n        Returns the question dictionary and the answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ques_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "[", "'questions'", "]", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "qdic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'question_id'", "]", ")", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image_id'", "]", "}", "\n", "\n", "", "", "if", "'test'", "not", "in", "data_split", ":", "\n", "            ", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ans_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "adata", "=", "json", ".", "load", "(", "f", ")", "[", "'annotations'", "]", "\n", "for", "a", "in", "adata", ":", "\n", "                    ", "adic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "a", "[", "'question_id'", "]", ")", "]", "=", "a", "[", "'answers'", "]", "\n", "\n", "", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for '", "+", "data_split", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.load_genome_json": [[57, 74], ["write_to_log.write_log", "open", "json.load", "str", "str", "len"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_genome_json", "(", ")", ":", "\n", "        ", "\"\"\"\n        Parses the genome json file. Returns the question dictionary and the\n        answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'genome_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "key", "=", "'genome'", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'id'", "]", ")", "\n", "qdic", "[", "key", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image'", "]", "}", "\n", "adic", "[", "key", "]", "=", "[", "{", "'answer'", ":", "q", "[", "'answer'", "]", "}", "]", "\n", "\n", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for genome'", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.load_data": [[75, 101], ["data_split_str.split", "config.DATA_PATHS.keys", "vqa_data_provider_layer.VQADataProvider.load_genome_json", "all_qdic.update", "all_adic.update", "vqa_data_provider_layer.VQADataProvider.load_vqa_json", "all_qdic.update", "all_adic.update"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_genome_json", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_vqa_json"], ["return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_data", "(", "data_split_str", ")", ":", "\n", "        ", "all_qdic", ",", "all_adic", "=", "{", "}", ",", "{", "}", "\n", "for", "data_split", "in", "data_split_str", ".", "split", "(", "'+'", ")", ":", "\n", "            ", "assert", "data_split", "in", "config", ".", "DATA_PATHS", ".", "keys", "(", ")", ",", "'unknown data split'", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_genome_json", "(", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "", "else", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_vqa_json", "(", "data_split", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "\n", "", "", "return", "all_qdic", ",", "all_adic", "\n", "\n", "", "def", "getQuesIds", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "qdic", ".", "keys", "(", ")", "\n", "\n", "", "def", "getStrippedQuesId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "[", "1", "]", "\n", "\n", "", "def", "getImgId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'iid'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.getQuesIds": [[102, 104], ["vqa_data_provider_layer.VQADataProvider.qdic.keys"], "methods", ["None"], ["", "def", "getQuesStr", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId": [[105, 107], ["qid.split"], "methods", ["None"], ["", "def", "getAnsObj", "(", "self", ",", "qid", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.getImgId": [[108, 110], ["None"], "methods", ["None"], ["", "return", "self", ".", "adic", "[", "qid", "]", "\n", "\n", "", "@", "staticmethod", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.getQuesStr": [[111, 113], ["None"], "methods", ["None"], ["def", "seq_to_list", "(", "s", ")", ":", "\n", "        ", "t_str", "=", "s", ".", "lower", "(", ")", "\n", "for", "i", "in", "[", "r'\\?'", ",", "r'\\!'", ",", "r'\\''", ",", "r'\\\"'", ",", "r'\\$'", ",", "r'\\:'", ",", "r'\\@'", ",", "r'\\('", ",", "r'\\)'", ",", "r'\\,'", ",", "r'\\.'", ",", "r'\\;'", "]", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.getAnsObj": [[114, 118], ["None"], "methods", ["None"], ["            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "''", ",", "t_str", ")", "\n", "", "for", "i", "in", "[", "r'\\-'", ",", "r'\\/'", "]", ":", "\n", "            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "' '", ",", "t_str", ")", "\n", "", "q_list", "=", "re", ".", "sub", "(", "r'\\?'", ",", "''", ",", "t_str", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "\n", "q_list", "=", "filter", "(", "lambda", "x", ":", "len", "(", "x", ")", ">", "0", ",", "q_list", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.seq_to_list": [[119, 129], ["s.lower", "re.sub().split", "filter", "re.sub", "re.sub", "re.sub", "re.sub.lower", "len"], "methods", ["None"], ["return", "q_list", "\n", "\n", "", "def", "extract_answer", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "", "answer_list", "=", "[", "answer_obj", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "dic", "=", "{", "}", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "dic", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "dic", "[", "ans", "]", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.extract_answer": [[130, 143], ["dic.has_key", "max", "xrange", "dic.items"], "methods", ["None"], ["", "else", ":", "\n", "                ", "dic", "[", "ans", "]", "=", "1", "\n", "", "", "max_key", "=", "max", "(", "(", "v", ",", "k", ")", "for", "(", "k", ",", "v", ")", "in", "dic", ".", "items", "(", ")", ")", "[", "1", "]", "\n", "return", "max_key", "\n", "\n", "", "def", "extract_answer_prob", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "prob_answer_list", "=", "[", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.extract_answer_prob": [[144, 162], ["vqa_data_provider_layer.VQADataProvider.adict.has_key", "len", "random.choice", "prob_answer_list.append", "Exception"], "methods", ["None"], ["                ", "prob_answer_list", ".", "append", "(", "ans", ")", "\n", "\n", "", "", "if", "len", "(", "prob_answer_list", ")", "==", "0", ":", "\n", "            ", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "return", "'hoge'", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"This should not happen.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "random", ".", "choice", "(", "prob_answer_list", ")", "\n", "\n", "# def qlist_to_vec(self, max_length, q_list):", "\n", "#     \"\"\"", "\n", "#     Converts a list of words into a format suitable for the embedding layer.", "\n", "\n", "#     Arguments:", "\n", "#     max_length -- the maximum length of a question sequence", "\n", "#     q_list -- a list of words which are the tokens in the question", "\n", "\n", "#     Returns:", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.qlist_to_vec": [[163, 208], ["numpy.zeros", "numpy.zeros", "xrange", "len", "vqa_data_provider_layer.VQADataProvider.vdict.has_key", "len"], "methods", ["None"], ["#     qvec -- A max_length length vector containing one-hot indices for each word", "\n", "#     cvec -- A max_length length sequence continuation indicator vector", "\n", "#     glove_matrix -- A max_length x GLOVE_EMBEDDING_SIZE matrix containing the glove embedding for", "\n", "#         each word", "\n", "#     \"\"\"", "\n", "#     qvec = np.zeros(max_length)", "\n", "#     cvec = np.zeros(max_length)", "\n", "#     glove_matrix = np.zeros(max_length * GLOVE_EMBEDDING_SIZE).reshape(max_length, GLOVE_EMBEDDING_SIZE)", "\n", "#     for i in xrange(max_length):", "\n", "#         if i < max_length - len(q_list):", "\n", "#             cvec[i] = 0", "\n", "#         else:", "\n", "#             w = q_list[i-(max_length-len(q_list))]", "\n", "#             if w not in self.glove_dict:", "\n", "#                 self.glove_dict[w] = self.nlp(u'%s' % w).vector", "\n", "#             glove_matrix[i] = self.glove_dict[w]", "\n", "#             # is the word in the vocabulary?", "\n", "#             if self.vdict.has_key(w) is False:", "\n", "#                 w = ''", "\n", "#             qvec[i] = self.vdict[w]", "\n", "#             cvec[i] = 1 #0 if i == max_length - len(q_list) else 1", "\n", "#             # UPDATE_10/12:", "\n", "#             #It seems that the original way is right for lstm.", "\n", "#             '''", "\n", "#             This is from https://github.com/BVLC/caffe/pull/1873.", "\n", "#             \"delta_{t,n} should be a binary indicator (i.e., value in {0, 1}),", "\n", "#             where a value of 0 means that timestep t of stream n is the beginning of a new sequence,", "\n", "#             and a value of 1 means that timestep t of stream n is continuing the sequence from timestep t-1 of stream n.", "\n", "#             Under the hood, the previous timestep's hidden state is multiplied by these delta values.", "\n", "#             The fact that these indicators are specified on a per-timestep and per-stream basis allows for streams of arbitrary different lengths without any padding or truncation.", "\n", "#             At the beginning of the forward pass, the final hidden state from the previous forward pass (h_T) is copied into the initial hidden state for the new forward pass (h_0),", "\n", "#             allowing for exact inference across arbitrarily long sequences, even if T == 1.", "\n", "#             However, if any sequences cross batch boundaries, backpropagation through time is approximate -- it is truncated along the batch boundaries.\"", "\n", "#             '''", "\n", "#             # I think the original way is false for CNN here. I want to keep the word embedding for unknown word as zero vector.", "\n", "#             # For example, if we have a sentence of length 7, there would be only 6 1's in cvec.", "\n", "\n", "#     return qvec, cvec, glove_matrix", "\n", "\n", "", "", "def", "qlist_to_vec", "(", "self", ",", "max_length", ",", "max_w_length", ",", "q_list", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.answer_to_vec": [[209, 219], ["vqa_data_provider_layer.VQADataProvider.adict.has_key"], "methods", ["None"], ["\n", "qvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "cvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "qcvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.vec_to_answer": [[220, 229], ["vqa_data_provider_layer.VQADataProvider.adict.items"], "methods", ["None"], ["ccvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "for", "i", "in", "xrange", "(", "max_length", ")", ":", "\n", "            ", "if", "i", "<", "max_length", "-", "len", "(", "q_list", ")", ":", "\n", "                ", "cvec", "[", "i", "]", "=", "0", "\n", "", "else", ":", "\n", "                ", "w", "=", "q_list", "[", "i", "-", "(", "max_length", "-", "len", "(", "q_list", ")", ")", "]", "\n", "# is the word in the vocabulary?", "\n", "if", "self", ".", "vdict", ".", "has_key", "(", "w", ")", "is", "False", ":", "\n", "                    ", "w", "=", "''", "\n", "", "qvec", "[", "i", "]", "=", "self", ".", "vdict", "[", "w", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.create_batch": [[230, 277], ["numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "enumerate", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "vqa_data_provider_layer.VQADataProvider.answer_to_vec", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "qid.split", "vqa_data_provider_layer.VQADataProvider.extract_answer", "vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "numpy.sqrt", "write_to_log.write_log", "numpy.load", "numpy.load", "str", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.answer_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["cvec", "[", "i", "]", "=", "1.0", "/", "len", "(", "q_list", ")", "\n", "j", "=", "max_w_length", "*", "i", "\n", "w_list", "=", "list", "(", "w", ")", "\n", "for", "k", "in", "xrange", "(", "max_w_length", ")", ":", "\n", "                    ", "if", "k", "<", "max_w_length", "-", "len", "(", "w_list", ")", ":", "\n", "                        ", "ccvec", "[", "j", "+", "k", "]", "=", "0", "\n", "", "else", ":", "\n", "                        ", "c", "=", "w_list", "[", "k", "-", "(", "max_w_length", "-", "len", "(", "w_list", ")", ")", "]", "\n", "# is the char in the vocabulary?", "\n", "if", "self", ".", "cdict", ".", "has_key", "(", "c", ")", "is", "False", ":", "\n", "                            ", "c", "=", "''", "\n", "", "qcvec", "[", "j", "+", "k", "]", "=", "self", ".", "cdict", "[", "c", "]", "\n", "ccvec", "[", "j", "+", "k", "]", "=", "1.0", "/", "len", "(", "w_list", ")", "\n", "", "", "", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", "\n", "\n", "", "def", "answer_to_vec", "(", "self", ",", "ans_str", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "if", "self", ".", "adict", ".", "has_key", "(", "ans_str", ")", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "ans_str", "]", "\n", "", "else", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "''", "]", "\n", "", "return", "ans", "\n", "\n", "", "def", "vec_to_answer", "(", "self", ",", "ans_symbol", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "rev_adict", "is", "None", ":", "\n", "            ", "rev_adict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "adict", ".", "items", "(", ")", ":", "\n", "                ", "rev_adict", "[", "v", "]", "=", "k", "\n", "", "self", ".", "rev_adict", "=", "rev_adict", "\n", "\n", "", "return", "self", ".", "rev_adict", "[", "ans_symbol", "]", "\n", "\n", "", "def", "create_batch", "(", "self", ",", "qid_list", ")", ":", "\n", "\n", "        ", "qvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "cvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "qcvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ccvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ivec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "2048", "*", "14", "*", "14", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "2048", ",", "14", ",", "14", ")", "\n", "avec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ")", "\n", "#glove_matrix = np.zeros(self.batchsize * self.max_length * GLOVE_EMBEDDING_SIZE).reshape(\\", "\n", "#self.batchsize, self.max_length, GLOVE_EMBEDDING_SIZE)", "\n", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProvider.get_batch_vec": [[279, 326], ["vqa_data_provider_layer.VQADataProvider.create_batch", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "random.shuffle", "len", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.adict.has_key", "t_qid_list.append", "t_iid_list.append", "vqa_data_provider_layer.VQADataProvider.get_batch_vec.has_at_least_one_valid_answer"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.create_batch", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId"], ["# load raw question information", "\n", "            ", "q_str", "=", "self", ".", "getQuesStr", "(", "qid", ")", "\n", "q_ans", "=", "self", ".", "getAnsObj", "(", "qid", ")", "\n", "q_iid", "=", "self", ".", "getImgId", "(", "qid", ")", "\n", "\n", "# convert question to vec", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "t_qvec", ",", "t_cvec", ",", "t_qcvec", ",", "t_ccvec", "=", "self", ".", "qlist_to_vec", "(", "self", ".", "max_length", ",", "self", ".", "max_w_length", ",", "q_list", ")", "\n", "\n", "try", ":", "\n", "                ", "qid_split", "=", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "\n", "data_split", "=", "qid_split", "[", "0", "]", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "else", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "t_ivec", "=", "(", "t_ivec", "/", "np", ".", "sqrt", "(", "(", "t_ivec", "**", "2", ")", ".", "sum", "(", ")", ")", ")", "\n", "", "except", ":", "\n", "                ", "t_ivec", "=", "0.", "\n", "write_log", "(", "'data not found for qid : '", "+", "str", "(", "q_iid", ")", "+", "' '", "+", "self", ".", "mode", ",", "'log.txt'", ")", "\n", "\n", "# convert answer to vec", "\n", "", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer", "(", "q_ans", ")", "\n", "", "else", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer_prob", "(", "q_ans", ")", "\n", "", "t_avec", "=", "self", ".", "answer_to_vec", "(", "q_ans_str", ")", "\n", "\n", "qvec", "[", "i", ",", "...", "]", "=", "t_qvec", "\n", "cvec", "[", "i", ",", "...", "]", "=", "t_cvec", "\n", "qcvec", "[", "i", ",", "...", "]", "=", "t_qcvec", "\n", "ccvec", "[", "i", ",", "...", "]", "=", "t_ccvec", "\n", "ivec", "[", "i", ",", "...", "]", "=", "t_ivec", "\n", "avec", "[", "i", ",", "...", "]", "=", "t_avec", "\n", "#glove_matrix[i,...] = t_glove_matrix", "\n", "\n", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", ",", "ivec", ",", "avec", "#, glove_matrix", "\n", "\n", "\n", "", "def", "get_batch_vec", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "batch_len", "is", "None", ":", "\n", "            ", "self", ".", "n_skipped", "=", "0", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_len", "=", "len", "(", "qid_list", ")", "\n", "self", ".", "batch_index", "=", "0", "\n", "self", ".", "epoch_counter", "=", "0", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProviderLayer.setup": [[333, 348], ["top[].reshape", "top[].reshape", "top[].reshape", "top[].reshape", "json.loads", "json.loads", "vqa_data_provider_layer.VQADataProvider"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape"], ["                    ", "return", "True", "\n", "\n", "", "", "", "counter", "=", "0", "\n", "t_qid_list", "=", "[", "]", "\n", "t_iid_list", "=", "[", "]", "\n", "while", "counter", "<", "self", ".", "batchsize", ":", "\n", "            ", "t_qid", "=", "self", ".", "qid_list", "[", "self", ".", "batch_index", "]", "\n", "t_iid", "=", "self", ".", "getImgId", "(", "t_qid", ")", "\n", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n", "", "elif", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProviderLayer.reshape": [[349, 351], ["None"], "methods", ["None"], ["", "else", ":", "\n", "                ", "self", ".", "n_skipped", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProviderLayer.forward": [[352, 362], ["vqa_data_provider_layer.VQADataProviderLayer.dp.get_batch_vec"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec"], ["", "if", "self", ".", "batch_index", "<", "self", ".", "batch_len", "-", "1", ":", "\n", "                ", "self", ".", "batch_index", "+=", "1", "\n", "", "else", ":", "\n", "                ", "self", ".", "epoch_counter", "+=", "1", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_index", "=", "0", "\n", "write_log", "(", "\"%d questions were skipped in a single epoch\"", "%", "self", ".", "n_skipped", ",", "'log.txt'", ")", "\n", "self", ".", "n_skipped", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).vqa_data_provider_layer.VQADataProviderLayer.backward": [[364, 366], ["None"], "methods", ["None"], ["return", "t_batch", "+", "(", "t_qid_list", ",", "t_iid_list", ",", "self", ".", "epoch_counter", ")", "\n", "\n", "", "", "class", "VQADataProviderLayer", "(", "caffe", ".", "Layer", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).train_att_bc.qlstm": [[19, 110], ["caffe.NetSpec", "json.dumps", "caffe.layers.Python", "caffe.layers.Embed", "caffe.layers.Scale", "caffe.layers.Reshape", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.TanH", "caffe.layers.TanH", "caffe.layers.TanH", "caffe.layers.TanH", "caffe.layers.Sigmoid", "caffe.layers.Sigmoid", "caffe.layers.Sigmoid", "caffe.layers.Sigmoid", "caffe.layers.Eltwise", "caffe.layers.Eltwise", "caffe.layers.Eltwise", "caffe.layers.Eltwise", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Concat", "caffe.layers.Dropout", "caffe.layers.Tile", "caffe.layers.Tile", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.Reshape", "caffe.layers.Softmax", "caffe.layers.Reshape", "caffe.layers.Slice", "caffe.layers.DummyData", "caffe.layers.SoftAttention", "caffe.layers.SoftAttention", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Concat", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Reshape", "caffe.layers.InnerProduct", "caffe.layers.SoftmaxWithLoss", "caffe.NetSpec.to_proto", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "config.TRAIN_DATA_SPLITS", "config.BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION", "config.VAL_BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION"], "function", ["None"], ["def", "qlstm", "(", "mode", ",", "batchsize", ",", "T", ",", "T_c", ",", "question_c_vocab_size", ",", "question_vocab_size", ")", ":", "\n", "    ", "n", "=", "caffe", ".", "NetSpec", "(", ")", "\n", "mode_str", "=", "json", ".", "dumps", "(", "{", "'mode'", ":", "mode", ",", "'batchsize'", ":", "batchsize", "}", ")", "\n", "n", ".", "data", ",", "n", ".", "cont", ",", "n", ".", "data1", ",", "n", ".", "cont1", ",", "n", ".", "img_feature", ",", "n", ".", "label", "=", "L", ".", "Python", "(", "module", "=", "'vqa_data_provider_layer'", ",", "layer", "=", "'VQADataProviderLayer'", ",", "param_str", "=", "mode_str", ",", "ntop", "=", "6", ")", "#5 )", "\n", "\n", "# char embedding", "\n", "n", ".", "embed_c", "=", "L", ".", "Embed", "(", "n", ".", "data1", ",", "input_dim", "=", "question_c_vocab_size", ",", "num_output", "=", "100", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "\n", "n", ".", "embed_c_scale", "=", "L", ".", "Scale", "(", "n", ".", "embed_c", ",", "n", ".", "cont1", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "\n", "n", ".", "embed_c_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_c_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T_c", "*", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T_c*T x d_c x 1", "\n", "tops", "=", "L", ".", "Slice", "(", "n", ".", "embed_c_scale_resh", ",", "ntop", "=", "T", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T_c x d_c x 1", "\n", "for", "i", "in", "xrange", "(", "T", ")", ":", "\n", "        ", "n", ".", "__setattr__", "(", "'Slice_'", "+", "str", "(", "i", "+", "1", ")", ",", "tops", "[", "int", "(", "i", ")", "]", ")", "\n", "\n", "# avg of char embedding", "\n", "", "n", ".", "c_embed_1", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_1", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_2", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_2", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_3", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_3", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_4", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_4", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_5", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_5", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_6", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_6", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_7", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_7", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_8", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_8", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_9", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_9", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_10", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_10", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_11", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_11", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_12", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_12", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_13", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_13", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_14", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_14", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_15", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_15", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_16", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_16", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_17", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_17", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_18", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_18", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_19", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_19", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_20", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_20", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_21", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_21", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_22", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_22", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "\n", "concat_c_embed", "=", "[", "n", ".", "c_embed_1", ",", "n", ".", "c_embed_2", ",", "n", ".", "c_embed_3", ",", "n", ".", "c_embed_4", ",", "n", ".", "c_embed_5", ",", "n", ".", "c_embed_6", ",", "n", ".", "c_embed_7", ",", "n", ".", "c_embed_8", ",", "n", ".", "c_embed_9", ",", "n", ".", "c_embed_10", ",", "n", ".", "c_embed_11", ",", "n", ".", "c_embed_12", ",", "n", ".", "c_embed_13", ",", "n", ".", "c_embed_14", ",", "n", ".", "c_embed_15", ",", "n", ".", "c_embed_16", ",", "n", ".", "c_embed_17", ",", "n", ".", "c_embed_18", ",", "n", ".", "c_embed_19", ",", "n", ".", "c_embed_20", ",", "n", ".", "c_embed_21", ",", "n", ".", "c_embed_22", "]", "\n", "n", ".", "concat_char_embed", "=", "L", ".", "Concat", "(", "*", "concat_c_embed", ",", "concat_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T x d_c x 1", "\n", "n", ".", "concat_char_embed_resh", "=", "L", ".", "Reshape", "(", "n", ".", "concat_char_embed", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", "]", ")", ")", ")", "\n", "\n", "# word embedding", "\n", "n", ".", "embed_w", "=", "L", ".", "Embed", "(", "n", ".", "data", ",", "input_dim", "=", "question_vocab_size", ",", "num_output", "=", "200", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "# N x T x d_w", "\n", "\n", "# combine word and char embedding", "\n", "concat_word_embed", "=", "[", "n", ".", "embed_w", ",", "n", ".", "concat_char_embed_resh", "]", "\n", "n", ".", "concat_embed", "=", "L", ".", "Concat", "(", "*", "concat_word_embed", ",", "concat_param", "=", "{", "'axis'", ":", "2", "}", ")", "# N x T x (d_c+d_w)", "\n", "\n", "n", ".", "embed_scale", "=", "L", ".", "Scale", "(", "n", ".", "concat_embed", ",", "n", ".", "cont", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "# N x T x (d_c+d_w)", "\n", "n", ".", "embed_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T x (d_c+d_w) x 1", "\n", "\n", "# avg of word embedding", "\n", "n", ".", "embed_avg", "=", "L", ".", "Convolution", "(", "n", ".", "embed_scale_resh", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x (d_c+d_w) x 1", "\n", "n", ".", "embed_avg_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_avg", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "300", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled_1", "=", "L", ".", "Tile", "(", "n", ".", "embed_avg_resh", ",", "axis", "=", "2", ",", "tiles", "=", "14", ")", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled", "=", "L", ".", "Tile", "(", "n", ".", "q_emb_tanh_droped_resh_tiled_1", ",", "axis", "=", "3", ",", "tiles", "=", "14", ")", "\n", "n", ".", "i_emb_tanh_droped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "img_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "n", ".", "blcf", "=", "L", ".", "CompactBilinear", "(", "n", ".", "q_emb_tanh_droped_resh_tiled", ",", "n", ".", "i_emb_tanh_droped_resh", ",", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "blcf_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "blcf", ")", "\n", "n", ".", "blcf_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "blcf_sign_sqrt", ")", "\n", "n", ".", "blcf_droped", "=", "L", ".", "Dropout", "(", "n", ".", "blcf_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "\n", "# multi-channel attention", "\n", "n", ".", "att_conv1", "=", "L", ".", "Convolution", "(", "n", ".", "blcf_droped", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "512", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_conv1_relu", "=", "L", ".", "ReLU", "(", "n", ".", "att_conv1", ")", "\n", "n", ".", "att_conv2", "=", "L", ".", "Convolution", "(", "n", ".", "att_conv1_relu", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "2", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_reshaped", "=", "L", ".", "Reshape", "(", "n", ".", "att_conv2", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", "*", "14", "]", ")", ")", ")", "\n", "n", ".", "att_softmax", "=", "L", ".", "Softmax", "(", "n", ".", "att_reshaped", ",", "axis", "=", "2", ")", "\n", "n", ".", "att", "=", "L", ".", "Reshape", "(", "n", ".", "att_softmax", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "att_maps", "=", "L", ".", "Slice", "(", "n", ".", "att", ",", "ntop", "=", "2", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "\n", "n", ".", "att_map0", "=", "att_maps", "[", "0", "]", "\n", "n", ".", "att_map1", "=", "att_maps", "[", "1", "]", "\n", "dummy", "=", "L", ".", "DummyData", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "1", "]", ")", ",", "data_filler", "=", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", ",", "ntop", "=", "1", ")", "\n", "n", ".", "att_feature0", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map0", ",", "dummy", ")", "\n", "n", ".", "att_feature1", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map1", ",", "dummy", ")", "\n", "n", ".", "att_feature0_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature0", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature1_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature1", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature", "=", "L", ".", "Concat", "(", "n", ".", "att_feature0_resh", ",", "n", ".", "att_feature1_resh", ")", "\n", "\n", "# merge attention and lstm with compact bilinear pooling", "\n", "n", ".", "att_feature_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "4096", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "#n.lstm_12_resh = L.Reshape(n.lstm_12, reshape_param=dict(shape=dict(dim=[-1,2048,1,1])))", "\n", "n", ".", "bc_att_lstm", "=", "L", ".", "CompactBilinear", "(", "n", ".", "att_feature_resh", ",", "n", ".", "embed_avg_resh", ",", "\n", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "bc_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "bc_att_lstm", ")", "\n", "n", ".", "bc_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "bc_sign_sqrt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).train_att_bc.make_answer_vocab": [[111, 148], ["adic.keys", "sorted", "enumerate", "enumerate", "nadict.items", "nalist.append", "adict.has_key", "config.NUM_OUTPUT_UNITS"], "function", ["None"], ["n", ".", "bc_dropped", "=", "L", ".", "Dropout", "(", "n", ".", "bc_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "n", ".", "bc_dropped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "bc_dropped", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "16000", "]", ")", ")", ")", "\n", "\n", "n", ".", "prediction", "=", "L", ".", "InnerProduct", "(", "n", ".", "bc_dropped_resh", ",", "num_output", "=", "3000", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "loss", "=", "L", ".", "SoftmaxWithLoss", "(", "n", ".", "prediction", ",", "n", ".", "label", ")", "\n", "return", "n", ".", "to_proto", "(", ")", "\n", "\n", "", "def", "make_answer_vocab", "(", "adic", ",", "vocab_size", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "adict", "=", "{", "''", ":", "0", "}", "\n", "nadict", "=", "{", "''", ":", "1000000", "}", "\n", "vid", "=", "1", "\n", "for", "qid", "in", "adic", ".", "keys", "(", ")", ":", "\n", "        ", "answer_obj", "=", "adic", "[", "qid", "]", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "\n", "for", "q_ans", "in", "answer_list", ":", "\n", "# create dict", "\n", "            ", "if", "adict", ".", "has_key", "(", "q_ans", ")", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "=", "1", "\n", "adict", "[", "q_ans", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "\n", "# debug", "\n", "", "", "", "nalist", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "sorted", "(", "nadict", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ":", "\n", "        ", "nalist", ".", "append", "(", "(", "k", ",", "v", ")", ")", "\n", "\n", "# keep the top 3000 answers", "\n", "", "n_del_ans", "=", "0", "\n", "n_valid_ans", "=", "0", "\n", "adict_nid", "=", "{", "}", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", ":", "-", "vocab_size", "]", ")", ":", "\n", "        ", "del", "adict", "[", "w", "[", "0", "]", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).train_att_bc.make_question_vocab": [[149, 167], ["qdic.keys", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vdict.has_key"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list"], ["n_del_ans", "+=", "w", "[", "1", "]", "\n", "", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", "-", "vocab_size", ":", "]", ")", ":", "\n", "        ", "n_valid_ans", "+=", "w", "[", "1", "]", "\n", "adict_nid", "[", "w", "[", "0", "]", "]", "=", "i", "\n", "\n", "", "return", "adict_nid", "\n", "\n", "", "def", "make_question_vocab", "(", "qdic", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "vdict", "=", "{", "''", ":", "0", "}", "\n", "vid", "=", "1", "\n", "cdict", "=", "{", "''", ":", "0", "}", "\n", "cvid", "=", "1", "\n", "for", "qid", "in", "qdic", ".", "keys", "(", ")", ":", "\n", "# sequence to list", "\n", "        ", "q_str", "=", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).train_att_bc.make_vocab_files": [[168, 179], ["write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_question_vocab", "write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_answer_vocab"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_question_vocab", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_answer_vocab"], ["\n", "# create dict", "\n", "for", "w", "in", "q_list", ":", "\n", "            ", "if", "not", "vdict", ".", "has_key", "(", "w", ")", ":", "\n", "                ", "vdict", "[", "w", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "", "for", "c", "in", "list", "(", "w", ")", ":", "\n", "                ", "if", "not", "cdict", ".", "has_key", "(", "c", ")", ":", "\n", "                    ", "cdict", "[", "c", "]", "=", "cvid", "\n", "cvid", "+=", "1", "\n", "\n", "", "", "", "", "return", "vdict", ",", "cdict", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).train_att_bc.main": [[180, 240], ["write_to_log.write_log", "write_to_log.write_log", "caffe.set_device", "caffe.set_mode_gpu", "caffe.get_solver", "numpy.zeros", "range", "os.path.exists", "os.makedirs", "os.path.exists", "os.path.exists", "write_to_log.write_log", "train_att_bc.make_vocab_files", "open", "f.write", "open", "f.write", "caffe.get_solver.step", "open", "json.load", "open", "json.load", "open", "json.dump", "open", "json.dump", "str", "str", "str", "str", "write_to_log.write_log", "write_to_log.write_log", "train_loss[].mean", "write_to_log.write_log", "caffe.get_solver.test_nets[].save", "write_to_log.write_log", "visualize_tools.exec_validation", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "train_att_bc.qlstm", "train_att_bc.qlstm", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_vocab_files", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.exec_validation", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["\n", "", "def", "make_vocab_files", "(", ")", ":", "\n", "    ", "\"\"\"\n    Produce the question and answer vocabulary files.\n    \"\"\"", "\n", "write_log", "(", "'making question vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "write_log", "(", "'making question character vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "qdic", ",", "_", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "QUESTION_VOCAB_SPACE", ")", "\n", "question_vocab", ",", "question_char_vocab", "=", "make_question_vocab", "(", "qdic", ")", "\n", "write_log", "(", "'making answer vocab... '", "+", "config", ".", "ANSWER_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "_", ",", "adic", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "ANSWER_VOCAB_SPACE", ")", "\n", "answer_vocab", "=", "make_answer_vocab", "(", "adic", ",", "config", ".", "NUM_OUTPUT_UNITS", ")", "\n", "return", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "'./result'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'./result'", ")", "\n", "\n", "", "question_vocab", ",", "answer_vocab", "=", "{", "}", ",", "{", "}", "\n", "if", "os", ".", "path", ".", "exists", "(", "'./result/cdict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/adict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/vdict.json'", ")", ":", "\n", "        ", "write_log", "(", "'restoring vocab'", ",", "'log.txt'", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_char_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "answer_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "=", "make_vocab_files", "(", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_char_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "answer_vocab", ",", "f", ")", "\n", "\n", "", "", "write_log", "(", "'question character vocab size: '", "+", "str", "(", "len", "(", "question_char_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'question vocab size: '", "+", "str", "(", "len", "(", "question_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'answer vocab size: '", "+", "str", "(", "len", "(", "answer_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "\n", "\n", "with", "open", "(", "'./result/proto_train.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "config", ".", "TRAIN_DATA_SPLITS", ",", "config", ".", "BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "with", "open", "(", "'./result/proto_test.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "'val'", ",", "config", ".", "VAL_BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "caffe", ".", "set_device", "(", "config", ".", "GPU_ID", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "solver", "=", "caffe", ".", "get_solver", "(", "'./qlstm_solver.prototxt'", ")", "\n", "\n", "train_loss", "=", "np", ".", "zeros", "(", "config", ".", "MAX_ITERATIONS", ")", "\n", "# results = []", "\n", "\n", "for", "it", "in", "range", "(", "config", ".", "MAX_ITERATIONS", ")", ":", "\n", "        ", "solver", ".", "step", "(", "1", ")", "\n", "\n", "# store the train loss", "\n", "train_loss", "[", "it", "]", "=", "solver", ".", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).visualize_tools.visualize_failures": [[27, 119], ["write_to_log.write_log", "visualize_tools.visualize_failures.save_qtype"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["def", "visualize_failures", "(", "stat_list", ",", "mode", ")", ":", "\n", "\n", "    ", "def", "save_qtype", "(", "qtype_list", ",", "save_filename", ",", "mode", ")", ":", "\n", "\n", "        ", "if", "mode", "==", "'val'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./eval'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/val2014'", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test-dev'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "elif", "mode", "==", "'test'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unsupported mode'", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "shutil", ".", "rmtree", "(", "savepath", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "os", ".", "makedirs", "(", "savepath", ")", "\n", "\n", "for", "qt", "in", "qtype_list", ":", "\n", "            ", "count", "=", "0", "\n", "for", "t_question", "in", "stat_list", ":", "\n", "#print count, t_question", "\n", "                ", "if", "count", "<", "40", "/", "len", "(", "qtype_list", ")", ":", "\n", "                    ", "t_question_list", "=", "t_question", "[", "'q_list'", "]", "\n", "saveflag", "=", "False", "\n", "#print 'debug****************************'", "\n", "#print qt", "\n", "#print t_question_list", "\n", "#print t_question_list[0] == qt[0]", "\n", "#print t_question_list[1] == qt[1]", "\n", "if", "t_question_list", "[", "0", "]", "==", "qt", "[", "0", "]", "and", "t_question_list", "[", "1", "]", "==", "qt", "[", "1", "]", ":", "\n", "                        ", "saveflag", "=", "True", "\n", "", "else", ":", "\n", "                        ", "saveflag", "=", "False", "\n", "\n", "", "if", "saveflag", "==", "True", ":", "\n", "                        ", "t_iid", "=", "t_question", "[", "'iid'", "]", "\n", "if", "mode", "==", "'val'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_val2014_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "", "elif", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_test2015_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "\n", "# for caption", "\n", "#print t_iid", "\n", "#annIds = caps.getAnnIds(t_iid)", "\n", "#anns = caps.loadAnns(annIds)", "\n", "#cap_list = [ann['caption'] for ann in anns]", "\n", "", "ans_list", "=", "t_question", "[", "'ans_list'", "]", "\n", "draw", "=", "ImageDraw", ".", "Draw", "(", "t_img", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ans_list", ")", ")", ":", "\n", "                            ", "try", ":", "\n", "                                ", "draw", ".", "text", "(", "(", "10", ",", "10", "*", "i", ")", ",", "str", "(", "ans_list", "[", "i", "]", ")", ")", "\n", "", "except", ":", "\n", "                                ", "pass", "\n", "\n", "", "", "ans", "=", "t_question", "[", "'answer'", "]", "\n", "pred", "=", "t_question", "[", "'pred'", "]", "\n", "if", "ans", "==", "-", "1", ":", "\n", "                            ", "pre", "=", "''", "\n", "", "elif", "ans", "==", "pred", ":", "\n", "                            ", "pre", "=", "'correct  '", "\n", "", "else", ":", "\n", "                            ", "pre", "=", "'failure  '", "\n", "#print ' aaa ', ans, pred", "\n", "", "ans", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "ans", ")", ")", "\n", "pred", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "pred", ")", ")", "\n", "img_title", "=", "pre", "+", "str", "(", "' '", ".", "join", "(", "t_question_list", ")", ")", "+", "'.  a_'", "+", "str", "(", "ans", ")", "+", "' p_'", "+", "str", "(", "pred", ")", "+", "'.png'", "\n", "count", "+=", "1", "\n", "write_log", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ",", "'visualize_log.txt'", ")", "\n", "t_img", ".", "save", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ")", "\n", "\n", "", "", "", "", "", "write_log", "(", "'saving colors'", ",", "'visualize_log.txt'", ")", "\n", "qt_color_list", "=", "[", "[", "'what'", ",", "'color'", "]", "]", "\n", "save_qtype", "(", "qt_color_list", ",", "'colors'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving what is'", ",", "'visualize_log.txt'", ")", "\n", "qt_whatis_list", "=", "[", "[", "'what'", ",", "'is'", "]", ",", "[", "'what'", ",", "'kind'", "]", ",", "[", "'what'", ",", "'are'", "]", "]", "\n", "save_qtype", "(", "qt_whatis_list", ",", "'whatis'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving is'", ",", "'visualize_log.txt'", ")", "\n", "qt_is_list", "=", "[", "[", "'is'", ",", "'the'", "]", ",", "[", "'is'", ",", "'this'", "]", ",", "[", "'is'", ",", "'there'", "]", "]", "\n", "save_qtype", "(", "qt_is_list", ",", "'is'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving how many'", ",", "'visualize_log.txt'", ")", "\n", "qt_howmany_list", "=", "[", "[", "'how'", ",", "'many'", "]", "]", "\n", "save_qtype", "(", "qt_howmany_list", ",", "'howmany'", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).visualize_tools.exec_validation": [[120, 201], ["caffe.set_device", "caffe.set_mode_gpu", "caffe.Net", "vqa_data_provider_layer.VQADataProvider", "len", "numpy.array().mean", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "vqa_data_provider_layer.VQADataProvider.get_batch_vec", "caffe.Net.forward", "caffe.Net.blobs[].data.argmax", "testloss_list.append", "zip", "vqaTools.vqa.VQA", "vqaTools.vqa.VQA.loadRes", "vqaEvaluation.vqaEval.VQAEval", "vqaEvaluation.vqaEval.VQAEval.evaluate", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "t_answer.tolist", "pred_list.append", "numpy.array", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "stat_list.append", "open", "json.dump", "visualize_tools.visualize_failures", "int", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "str().zfill", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "str().zfill", "xrange", "str", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.forward", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj"], ["", "def", "exec_validation", "(", "device_id", ",", "mode", ",", "it", "=", "''", ",", "visualize", "=", "False", ")", ":", "\n", "\n", "    ", "caffe", ".", "set_device", "(", "device_id", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "net", "=", "caffe", ".", "Net", "(", "'./result/proto_test.prototxt'", ",", "'./result/tmp.caffemodel'", ",", "caffe", ".", "TEST", ")", "\n", "\n", "dp", "=", "VQADataProvider", "(", "mode", "=", "mode", ",", "batchsize", "=", "config", ".", "VAL_BATCH_SIZE", ")", "\n", "total_questions", "=", "len", "(", "dp", ".", "getQuesIds", "(", ")", ")", "\n", "epoch", "=", "0", "\n", "\n", "pred_list", "=", "[", "]", "\n", "testloss_list", "=", "[", "]", "\n", "stat_list", "=", "[", "]", "\n", "\n", "while", "epoch", "==", "0", ":", "\n", "        ", "t_word", ",", "t_cont", ",", "t_word_c", ",", "t_cont_c", ",", "t_img_feature", ",", "t_answer", ",", "t_qid_list", ",", "t_iid_list", ",", "epoch", "=", "dp", ".", "get_batch_vec", "(", ")", "\n", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "...", "]", "=", "t_word", "# np.transpose(t_word,(1,0))", "\n", "net", ".", "blobs", "[", "'cont'", "]", ".", "data", "[", "...", "]", "=", "t_cont", "# np.transpose(t_cont,(1,0))", "\n", "net", ".", "blobs", "[", "'data1'", "]", ".", "data", "[", "...", "]", "=", "t_word_c", "\n", "net", ".", "blobs", "[", "'cont1'", "]", ".", "data", "[", "...", "]", "=", "t_cont_c", "\n", "net", ".", "blobs", "[", "'img_feature'", "]", ".", "data", "[", "...", "]", "=", "t_img_feature", "\n", "net", ".", "blobs", "[", "'label'", "]", ".", "data", "[", "...", "]", "=", "t_answer", "\n", "#net.blobs['glove'].data[...] = t_glove_matrix # np.transpose(t_glove_matrix, (1,0,2))", "\n", "net", ".", "forward", "(", ")", "\n", "t_pred_list", "=", "net", ".", "blobs", "[", "'prediction'", "]", ".", "data", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "t_pred_str", "=", "[", "dp", ".", "vec_to_answer", "(", "pred_symbol", ")", "for", "pred_symbol", "in", "t_pred_list", "]", "\n", "testloss_list", ".", "append", "(", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", ")", "\n", "for", "qid", ",", "iid", ",", "ans", ",", "pred", "in", "zip", "(", "t_qid_list", ",", "t_iid_list", ",", "t_answer", ".", "tolist", "(", ")", ",", "t_pred_str", ")", ":", "\n", "            ", "pred_list", ".", "append", "(", "{", "u'answer'", ":", "pred", ",", "u'question_id'", ":", "int", "(", "dp", ".", "getStrippedQuesId", "(", "qid", ")", ")", "}", ")", "\n", "if", "visualize", ":", "\n", "                ", "q_list", "=", "dp", ".", "seq_to_list", "(", "dp", ".", "getQuesStr", "(", "qid", ")", ")", "\n", "if", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                    ", "ans_str", "=", "''", "\n", "ans_list", "=", "[", "''", "]", "*", "10", "\n", "", "else", ":", "\n", "                    ", "ans_str", "=", "dp", ".", "vec_to_answer", "(", "ans", ")", "\n", "ans_list", "=", "[", "dp", ".", "getAnsObj", "(", "qid", ")", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "", "stat_list", ".", "append", "(", "{", "'qid'", ":", "qid", ",", "\n", "'q_list'", ":", "q_list", ",", "\n", "'iid'", ":", "iid", ",", "\n", "'answer'", ":", "ans_str", ",", "\n", "'ans_list'", ":", "ans_list", ",", "\n", "'pred'", ":", "pred", "}", ")", "\n", "#percent = 100 * float(len(pred_list)) / total_questions", "\n", "#sys.stdout.write('\\r' + ('%.2f' % percent) + '%')", "\n", "#sys.stdout.flush()", "\n", "\n", "\n", "\n", "", "", "", "mean_testloss", "=", "np", ".", "array", "(", "testloss_list", ")", ".", "mean", "(", ")", "\n", "\n", "if", "mode", "==", "'val'", ":", "\n", "        ", "valFile", "=", "'./result/val2014_resfile'", "\n", "with", "open", "(", "valFile", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "annFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ans_file'", "]", "\n", "quesFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ques_file'", "]", "\n", "vqa", "=", "VQA", "(", "annFile", ",", "quesFile", ")", "\n", "vqaRes", "=", "vqa", ".", "loadRes", "(", "valFile", ",", "quesFile", ")", "\n", "vqaEval", "=", "VQAEval", "(", "vqa", ",", "vqaRes", ",", "n", "=", "2", ")", "\n", "vqaEval", ".", "evaluate", "(", ")", "\n", "acc_overall", "=", "vqaEval", ".", "accuracy", "[", "'overall'", "]", "\n", "acc_perQuestionType", "=", "vqaEval", ".", "accuracy", "[", "'perQuestionType'", "]", "\n", "acc_perAnswerType", "=", "vqaEval", ".", "accuracy", "[", "'perAnswerType'", "]", "\n", "return", "mean_testloss", ",", "acc_overall", ",", "acc_perQuestionType", ",", "acc_perAnswerType", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test-dev2015_v3t'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "", "elif", "mode", "==", "'test'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test2015_v3c'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate (tanh).visualize_tools.drawgraph": [[202, 270], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.twinx", "fig.add_subplot.plot", "fig.add_subplot.plot", "ax1.twinx.plot", "matplotlib.legend", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "ax1.twinx.set_ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "numpy.array", "numpy.array", "matplotlib.figure", "matplotlib.legend", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "sorted", "visualize_tools.drawgraph.draw_qt_acc"], "function", ["None"], ["\n", "", "", "", "def", "drawgraph", "(", "results", ",", "save_question_type_graphs", "=", "False", ")", ":", "\n", "# 0:it", "\n", "# 1:trainloss", "\n", "# 2:testloss", "\n", "# 3:oa_acc", "\n", "# 4:qt_acc", "\n", "# 5:at_acc", "\n", "\n", "# training curve", "\n", "    ", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "loss", "=", "np", ".", "array", "(", "[", "l", "[", "1", "]", "for", "l", "in", "results", "]", ")", "\n", "valloss", "=", "np", ".", "array", "(", "[", "l", "[", "2", "]", "for", "l", "in", "results", "]", ")", "\n", "valacc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax1", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "ax2", "=", "ax1", ".", "twinx", "(", ")", "\n", "\n", "ax1", ".", "plot", "(", "it", ",", "loss", ",", "color", "=", "'blue'", ",", "label", "=", "'train loss'", ")", "\n", "ax1", ".", "plot", "(", "it", ",", "valloss", ",", "'--'", ",", "color", "=", "'blue'", ",", "label", "=", "'test loss'", ")", "\n", "ax2", ".", "plot", "(", "it", ",", "valacc", ",", "color", "=", "'red'", ",", "label", "=", "'acc on val'", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'lower left'", ")", "\n", "\n", "ax1", ".", "set_xlabel", "(", "'Iterations'", ")", "\n", "ax1", ".", "set_ylabel", "(", "'Loss Value'", ")", "\n", "ax2", ".", "set_ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "'./learning_curve max_%2.2f.png'", "%", "valacc", ".", "max", "(", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "# question type", "\n", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "oa_acc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "qt_dic_list", "=", "[", "l", "[", "4", "]", "for", "l", "in", "results", "]", "\n", "\n", "def", "draw_qt_acc", "(", "target_key_list", ",", "figname", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "for", "k", "in", "target_key_list", ":", "\n", "            ", "write_log", "(", "str", "(", "k", ")", "+", "str", "(", "type", "(", "k", ")", ")", ",", "'visualize_log.txt'", ")", "\n", "t_val", "=", "np", ".", "array", "(", "[", "qt_dic", "[", "k", "]", "for", "qt_dic", "in", "qt_dic_list", "]", ")", "\n", "plt", ".", "plot", "(", "it", ",", "t_val", ",", "label", "=", "str", "(", "k", ")", ")", "\n", "", "plt", ".", "legend", "(", "fontsize", "=", "'small'", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "100.", ")", "\n", "#plt.legend(prop={'size':6})", "\n", "\n", "plt", ".", "xlabel", "(", "'Iterations'", ")", "\n", "plt", ".", "ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "figname", ",", "dpi", "=", "200", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "", "if", "save_question_type_graphs", ":", "\n", "        ", "s_keys", "=", "sorted", "(", "qt_dic_list", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "0", ":", "13", "]", "+", "[", "s_keys", "[", "31", "]", ",", "]", ",", "'./ind_qt_are.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "13", ":", "17", "]", "+", "s_keys", "[", "49", ":", "]", ",", "'./ind_qt_how_where_who_why.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "17", ":", "31", "]", "+", "[", "s_keys", "[", "32", "]", ",", "]", ",", "'./ind_qt_is.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "33", ":", "49", "]", ",", "'./ind_qt_what.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what color is the'", ",", "'what color are the'", ",", "'what color is'", ",", "'what color'", ",", "'what is the color of the'", "]", ",", "'./qt_color.png'", ")", "\n", "draw_qt_acc", "(", "[", "'how many'", ",", "'how'", ",", "'how many people are'", ",", "'how many people are in'", "]", ",", "'./qt_number.png'", ")", "\n", "draw_qt_acc", "(", "[", "'who is'", ",", "'why'", ",", "'why is the'", ",", "'where is the'", ",", "'where are the'", ",", "'which'", "]", ",", "'./qt_who_why_where_which.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what is the man'", ",", "'is the man'", ",", "'are they'", ",", "'is he'", ",", "'is the woman'", ",", "'is this person'", ",", "'what is the woman'", ",", "'is the person'", ",", "'what is the person'", "]", ",", "'./qt_human.png'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.write_to_log.write_log": [[1, 4], ["open", "f.write"], "function", ["None"], ["def", "write_log", "(", "str", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "+", "\"\\n\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.__init__": [[13, 30], ["vqa_data_provider_layer.VQADataProvider.load_data", "len", "open", "json.load", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data"], ["    ", "def", "__init__", "(", "self", ",", "batchsize", "=", "64", ",", "max_length", "=", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "max_w_length", "=", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "batchsize", "\n", "self", ".", "d_vocabulary", "=", "None", "\n", "self", ".", "batch_index", "=", "None", "\n", "self", ".", "batch_len", "=", "None", "\n", "self", ".", "rev_adict", "=", "None", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "max_w_length", "=", "max_w_length", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "qdic", ",", "self", ".", "adic", "=", "VQADataProvider", ".", "load_data", "(", "mode", ")", "\n", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "cdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "vdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "adict", "=", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.load_vqa_json": [[33, 56], ["write_to_log.write_log", "open", "json.load", "open", "json.load", "str", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["#self.glove_dict = {} # word -> glove vector", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_vqa_json", "(", "data_split", ")", ":", "\n", "        ", "\"\"\"\n        Parses the question and answer json files for the given data split. \n        Returns the question dictionary and the answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ques_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "[", "'questions'", "]", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "qdic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'question_id'", "]", ")", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image_id'", "]", "}", "\n", "\n", "", "", "if", "'test'", "not", "in", "data_split", ":", "\n", "            ", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ans_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "adata", "=", "json", ".", "load", "(", "f", ")", "[", "'annotations'", "]", "\n", "for", "a", "in", "adata", ":", "\n", "                    ", "adic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "a", "[", "'question_id'", "]", ")", "]", "=", "a", "[", "'answers'", "]", "\n", "\n", "", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for '", "+", "data_split", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.load_genome_json": [[57, 74], ["write_to_log.write_log", "open", "json.load", "str", "str", "len"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_genome_json", "(", ")", ":", "\n", "        ", "\"\"\"\n        Parses the genome json file. Returns the question dictionary and the\n        answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'genome_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "key", "=", "'genome'", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'id'", "]", ")", "\n", "qdic", "[", "key", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image'", "]", "}", "\n", "adic", "[", "key", "]", "=", "[", "{", "'answer'", ":", "q", "[", "'answer'", "]", "}", "]", "\n", "\n", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for genome'", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.load_data": [[75, 101], ["data_split_str.split", "config.DATA_PATHS.keys", "vqa_data_provider_layer.VQADataProvider.load_genome_json", "all_qdic.update", "all_adic.update", "vqa_data_provider_layer.VQADataProvider.load_vqa_json", "all_qdic.update", "all_adic.update"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_genome_json", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_vqa_json"], ["return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_data", "(", "data_split_str", ")", ":", "\n", "        ", "all_qdic", ",", "all_adic", "=", "{", "}", ",", "{", "}", "\n", "for", "data_split", "in", "data_split_str", ".", "split", "(", "'+'", ")", ":", "\n", "            ", "assert", "data_split", "in", "config", ".", "DATA_PATHS", ".", "keys", "(", ")", ",", "'unknown data split'", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_genome_json", "(", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "", "else", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_vqa_json", "(", "data_split", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "\n", "", "", "return", "all_qdic", ",", "all_adic", "\n", "\n", "", "def", "getQuesIds", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "qdic", ".", "keys", "(", ")", "\n", "\n", "", "def", "getStrippedQuesId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "[", "1", "]", "\n", "\n", "", "def", "getImgId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'iid'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.getQuesIds": [[102, 104], ["vqa_data_provider_layer.VQADataProvider.qdic.keys"], "methods", ["None"], ["", "def", "getQuesStr", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.getStrippedQuesId": [[105, 107], ["qid.split"], "methods", ["None"], ["", "def", "getAnsObj", "(", "self", ",", "qid", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.getImgId": [[108, 110], ["None"], "methods", ["None"], ["", "return", "self", ".", "adic", "[", "qid", "]", "\n", "\n", "", "@", "staticmethod", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.getQuesStr": [[111, 113], ["None"], "methods", ["None"], ["def", "seq_to_list", "(", "s", ")", ":", "\n", "        ", "t_str", "=", "s", ".", "lower", "(", ")", "\n", "for", "i", "in", "[", "r'\\?'", ",", "r'\\!'", ",", "r'\\''", ",", "r'\\\"'", ",", "r'\\$'", ",", "r'\\:'", ",", "r'\\@'", ",", "r'\\('", ",", "r'\\)'", ",", "r'\\,'", ",", "r'\\.'", ",", "r'\\;'", "]", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.getAnsObj": [[114, 118], ["None"], "methods", ["None"], ["            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "''", ",", "t_str", ")", "\n", "", "for", "i", "in", "[", "r'\\-'", ",", "r'\\/'", "]", ":", "\n", "            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "' '", ",", "t_str", ")", "\n", "", "q_list", "=", "re", ".", "sub", "(", "r'\\?'", ",", "''", ",", "t_str", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "\n", "q_list", "=", "filter", "(", "lambda", "x", ":", "len", "(", "x", ")", ">", "0", ",", "q_list", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.seq_to_list": [[119, 129], ["s.lower", "re.sub().split", "filter", "re.sub", "re.sub", "re.sub", "re.sub.lower", "len"], "methods", ["None"], ["return", "q_list", "\n", "\n", "", "def", "extract_answer", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "", "answer_list", "=", "[", "answer_obj", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "dic", "=", "{", "}", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "dic", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "dic", "[", "ans", "]", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.extract_answer": [[130, 143], ["dic.has_key", "max", "xrange", "dic.items"], "methods", ["None"], ["", "else", ":", "\n", "                ", "dic", "[", "ans", "]", "=", "1", "\n", "", "", "max_key", "=", "max", "(", "(", "v", ",", "k", ")", "for", "(", "k", ",", "v", ")", "in", "dic", ".", "items", "(", ")", ")", "[", "1", "]", "\n", "return", "max_key", "\n", "\n", "", "def", "extract_answer_prob", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "prob_answer_list", "=", "[", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.extract_answer_prob": [[144, 162], ["vqa_data_provider_layer.VQADataProvider.adict.has_key", "len", "random.choice", "prob_answer_list.append", "Exception"], "methods", ["None"], ["                ", "prob_answer_list", ".", "append", "(", "ans", ")", "\n", "\n", "", "", "if", "len", "(", "prob_answer_list", ")", "==", "0", ":", "\n", "            ", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "return", "'hoge'", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"This should not happen.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "random", ".", "choice", "(", "prob_answer_list", ")", "\n", "\n", "# def qlist_to_vec(self, max_length, q_list):", "\n", "#     \"\"\"", "\n", "#     Converts a list of words into a format suitable for the embedding layer.", "\n", "\n", "#     Arguments:", "\n", "#     max_length -- the maximum length of a question sequence", "\n", "#     q_list -- a list of words which are the tokens in the question", "\n", "\n", "#     Returns:", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.qlist_to_vec": [[163, 208], ["numpy.zeros", "numpy.zeros", "xrange", "len", "vqa_data_provider_layer.VQADataProvider.vdict.has_key", "len"], "methods", ["None"], ["#     qvec -- A max_length length vector containing one-hot indices for each word", "\n", "#     cvec -- A max_length length sequence continuation indicator vector", "\n", "#     glove_matrix -- A max_length x GLOVE_EMBEDDING_SIZE matrix containing the glove embedding for", "\n", "#         each word", "\n", "#     \"\"\"", "\n", "#     qvec = np.zeros(max_length)", "\n", "#     cvec = np.zeros(max_length)", "\n", "#     glove_matrix = np.zeros(max_length * GLOVE_EMBEDDING_SIZE).reshape(max_length, GLOVE_EMBEDDING_SIZE)", "\n", "#     for i in xrange(max_length):", "\n", "#         if i < max_length - len(q_list):", "\n", "#             cvec[i] = 0", "\n", "#         else:", "\n", "#             w = q_list[i-(max_length-len(q_list))]", "\n", "#             if w not in self.glove_dict:", "\n", "#                 self.glove_dict[w] = self.nlp(u'%s' % w).vector", "\n", "#             glove_matrix[i] = self.glove_dict[w]", "\n", "#             # is the word in the vocabulary?", "\n", "#             if self.vdict.has_key(w) is False:", "\n", "#                 w = ''", "\n", "#             qvec[i] = self.vdict[w]", "\n", "#             cvec[i] = 1 #0 if i == max_length - len(q_list) else 1", "\n", "#             # UPDATE_10/12:", "\n", "#             #It seems that the original way is right for lstm.", "\n", "#             '''", "\n", "#             This is from https://github.com/BVLC/caffe/pull/1873.", "\n", "#             \"delta_{t,n} should be a binary indicator (i.e., value in {0, 1}),", "\n", "#             where a value of 0 means that timestep t of stream n is the beginning of a new sequence,", "\n", "#             and a value of 1 means that timestep t of stream n is continuing the sequence from timestep t-1 of stream n.", "\n", "#             Under the hood, the previous timestep's hidden state is multiplied by these delta values.", "\n", "#             The fact that these indicators are specified on a per-timestep and per-stream basis allows for streams of arbitrary different lengths without any padding or truncation.", "\n", "#             At the beginning of the forward pass, the final hidden state from the previous forward pass (h_T) is copied into the initial hidden state for the new forward pass (h_0),", "\n", "#             allowing for exact inference across arbitrarily long sequences, even if T == 1.", "\n", "#             However, if any sequences cross batch boundaries, backpropagation through time is approximate -- it is truncated along the batch boundaries.\"", "\n", "#             '''", "\n", "#             # I think the original way is false for CNN here. I want to keep the word embedding for unknown word as zero vector.", "\n", "#             # For example, if we have a sentence of length 7, there would be only 6 1's in cvec.", "\n", "\n", "#     return qvec, cvec, glove_matrix", "\n", "\n", "", "", "def", "qlist_to_vec", "(", "self", ",", "max_length", ",", "max_w_length", ",", "q_list", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.answer_to_vec": [[209, 219], ["vqa_data_provider_layer.VQADataProvider.adict.has_key"], "methods", ["None"], ["\n", "qvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "cvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "qcvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.vec_to_answer": [[220, 229], ["vqa_data_provider_layer.VQADataProvider.adict.items"], "methods", ["None"], ["ccvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "for", "i", "in", "xrange", "(", "max_length", ")", ":", "\n", "            ", "if", "i", "<", "max_length", "-", "len", "(", "q_list", ")", ":", "\n", "                ", "cvec", "[", "i", "]", "=", "0", "\n", "", "else", ":", "\n", "                ", "w", "=", "q_list", "[", "i", "-", "(", "max_length", "-", "len", "(", "q_list", ")", ")", "]", "\n", "# is the word in the vocabulary?", "\n", "if", "self", ".", "vdict", ".", "has_key", "(", "w", ")", "is", "False", ":", "\n", "                    ", "w", "=", "''", "\n", "", "qvec", "[", "i", "]", "=", "self", ".", "vdict", "[", "w", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.create_batch": [[230, 277], ["numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "enumerate", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "vqa_data_provider_layer.VQADataProvider.answer_to_vec", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "qid.split", "vqa_data_provider_layer.VQADataProvider.extract_answer", "vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "numpy.sqrt", "write_to_log.write_log", "numpy.load", "numpy.load", "str", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.answer_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["cvec", "[", "i", "]", "=", "1.0", "/", "len", "(", "q_list", ")", "\n", "j", "=", "max_w_length", "*", "i", "\n", "w_list", "=", "list", "(", "w", ")", "\n", "for", "k", "in", "xrange", "(", "max_w_length", ")", ":", "\n", "                    ", "if", "k", "<", "max_w_length", "-", "len", "(", "w_list", ")", ":", "\n", "                        ", "ccvec", "[", "j", "+", "k", "]", "=", "0", "\n", "", "else", ":", "\n", "                        ", "c", "=", "w_list", "[", "k", "-", "(", "max_w_length", "-", "len", "(", "w_list", ")", ")", "]", "\n", "# is the char in the vocabulary?", "\n", "if", "self", ".", "cdict", ".", "has_key", "(", "c", ")", "is", "False", ":", "\n", "                            ", "c", "=", "''", "\n", "", "qcvec", "[", "j", "+", "k", "]", "=", "self", ".", "cdict", "[", "c", "]", "\n", "ccvec", "[", "j", "+", "k", "]", "=", "1.0", "/", "len", "(", "w_list", ")", "\n", "", "", "", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", "\n", "\n", "", "def", "answer_to_vec", "(", "self", ",", "ans_str", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "if", "self", ".", "adict", ".", "has_key", "(", "ans_str", ")", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "ans_str", "]", "\n", "", "else", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "''", "]", "\n", "", "return", "ans", "\n", "\n", "", "def", "vec_to_answer", "(", "self", ",", "ans_symbol", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "rev_adict", "is", "None", ":", "\n", "            ", "rev_adict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "adict", ".", "items", "(", ")", ":", "\n", "                ", "rev_adict", "[", "v", "]", "=", "k", "\n", "", "self", ".", "rev_adict", "=", "rev_adict", "\n", "\n", "", "return", "self", ".", "rev_adict", "[", "ans_symbol", "]", "\n", "\n", "", "def", "create_batch", "(", "self", ",", "qid_list", ")", ":", "\n", "\n", "        ", "qvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "cvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "qcvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ccvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ivec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "2048", "*", "14", "*", "14", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "2048", ",", "14", ",", "14", ")", "\n", "avec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ")", "\n", "#glove_matrix = np.zeros(self.batchsize * self.max_length * GLOVE_EMBEDDING_SIZE).reshape(\\", "\n", "#self.batchsize, self.max_length, GLOVE_EMBEDDING_SIZE)", "\n", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProvider.get_batch_vec": [[279, 326], ["vqa_data_provider_layer.VQADataProvider.create_batch", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "random.shuffle", "len", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.adict.has_key", "t_qid_list.append", "t_iid_list.append", "vqa_data_provider_layer.VQADataProvider.get_batch_vec.has_at_least_one_valid_answer"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.create_batch", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId"], ["# load raw question information", "\n", "            ", "q_str", "=", "self", ".", "getQuesStr", "(", "qid", ")", "\n", "q_ans", "=", "self", ".", "getAnsObj", "(", "qid", ")", "\n", "q_iid", "=", "self", ".", "getImgId", "(", "qid", ")", "\n", "\n", "# convert question to vec", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "t_qvec", ",", "t_cvec", ",", "t_qcvec", ",", "t_ccvec", "=", "self", ".", "qlist_to_vec", "(", "self", ".", "max_length", ",", "self", ".", "max_w_length", ",", "q_list", ")", "\n", "\n", "try", ":", "\n", "                ", "qid_split", "=", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "\n", "data_split", "=", "qid_split", "[", "0", "]", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "else", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "t_ivec", "=", "(", "t_ivec", "/", "np", ".", "sqrt", "(", "(", "t_ivec", "**", "2", ")", ".", "sum", "(", ")", ")", ")", "\n", "", "except", ":", "\n", "                ", "t_ivec", "=", "0.", "\n", "write_log", "(", "'data not found for qid : '", "+", "str", "(", "q_iid", ")", "+", "' '", "+", "self", ".", "mode", ",", "'log.txt'", ")", "\n", "\n", "# convert answer to vec", "\n", "", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer", "(", "q_ans", ")", "\n", "", "else", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer_prob", "(", "q_ans", ")", "\n", "", "t_avec", "=", "self", ".", "answer_to_vec", "(", "q_ans_str", ")", "\n", "\n", "qvec", "[", "i", ",", "...", "]", "=", "t_qvec", "\n", "cvec", "[", "i", ",", "...", "]", "=", "t_cvec", "\n", "qcvec", "[", "i", ",", "...", "]", "=", "t_qcvec", "\n", "ccvec", "[", "i", ",", "...", "]", "=", "t_ccvec", "\n", "ivec", "[", "i", ",", "...", "]", "=", "t_ivec", "\n", "avec", "[", "i", ",", "...", "]", "=", "t_avec", "\n", "#glove_matrix[i,...] = t_glove_matrix", "\n", "\n", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", ",", "ivec", ",", "avec", "#, glove_matrix", "\n", "\n", "\n", "", "def", "get_batch_vec", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "batch_len", "is", "None", ":", "\n", "            ", "self", ".", "n_skipped", "=", "0", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_len", "=", "len", "(", "qid_list", ")", "\n", "self", ".", "batch_index", "=", "0", "\n", "self", ".", "epoch_counter", "=", "0", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProviderLayer.setup": [[333, 348], ["top[].reshape", "top[].reshape", "top[].reshape", "top[].reshape", "json.loads", "json.loads", "vqa_data_provider_layer.VQADataProvider"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape"], ["                    ", "return", "True", "\n", "\n", "", "", "", "counter", "=", "0", "\n", "t_qid_list", "=", "[", "]", "\n", "t_iid_list", "=", "[", "]", "\n", "while", "counter", "<", "self", ".", "batchsize", ":", "\n", "            ", "t_qid", "=", "self", ".", "qid_list", "[", "self", ".", "batch_index", "]", "\n", "t_iid", "=", "self", ".", "getImgId", "(", "t_qid", ")", "\n", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n", "", "elif", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProviderLayer.reshape": [[349, 351], ["None"], "methods", ["None"], ["", "else", ":", "\n", "                ", "self", ".", "n_skipped", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProviderLayer.forward": [[352, 362], ["vqa_data_provider_layer.VQADataProviderLayer.dp.get_batch_vec"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec"], ["", "if", "self", ".", "batch_index", "<", "self", ".", "batch_len", "-", "1", ":", "\n", "                ", "self", ".", "batch_index", "+=", "1", "\n", "", "else", ":", "\n", "                ", "self", ".", "epoch_counter", "+=", "1", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_index", "=", "0", "\n", "write_log", "(", "\"%d questions were skipped in a single epoch\"", "%", "self", ".", "n_skipped", ",", "'log.txt'", ")", "\n", "self", ".", "n_skipped", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.vqa_data_provider_layer.VQADataProviderLayer.backward": [[364, 366], ["None"], "methods", ["None"], ["return", "t_batch", "+", "(", "t_qid_list", ",", "t_iid_list", ",", "self", ".", "epoch_counter", ")", "\n", "\n", "", "", "class", "VQADataProviderLayer", "(", "caffe", ".", "Layer", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.train_att_bc.qlstm": [[19, 99], ["caffe.NetSpec", "json.dumps", "caffe.layers.Python", "caffe.layers.Embed", "caffe.layers.Scale", "caffe.layers.Reshape", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.ReLU", "caffe.layers.ReLU", "caffe.layers.ReLU", "caffe.layers.Concat", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Concat", "caffe.layers.Eltwise", "caffe.layers.ReLU", "caffe.layers.Pooling", "caffe.layers.Dropout", "caffe.layers.Tile", "caffe.layers.Tile", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.Reshape", "caffe.layers.Softmax", "caffe.layers.Reshape", "caffe.layers.Slice", "caffe.layers.DummyData", "caffe.layers.SoftAttention", "caffe.layers.SoftAttention", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Concat", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Reshape", "caffe.layers.InnerProduct", "caffe.layers.SoftmaxWithLoss", "caffe.NetSpec.to_proto", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "config.TRAIN_DATA_SPLITS", "config.BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION", "config.VAL_BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION"], "function", ["None"], ["def", "qlstm", "(", "mode", ",", "batchsize", ",", "T", ",", "T_c", ",", "question_c_vocab_size", ",", "question_vocab_size", ")", ":", "\n", "    ", "n", "=", "caffe", ".", "NetSpec", "(", ")", "\n", "mode_str", "=", "json", ".", "dumps", "(", "{", "'mode'", ":", "mode", ",", "'batchsize'", ":", "batchsize", "}", ")", "\n", "n", ".", "data", ",", "n", ".", "cont", ",", "n", ".", "data1", ",", "n", ".", "cont1", ",", "n", ".", "img_feature", ",", "n", ".", "label", "=", "L", ".", "Python", "(", "module", "=", "'vqa_data_provider_layer'", ",", "layer", "=", "'VQADataProviderLayer'", ",", "param_str", "=", "mode_str", ",", "ntop", "=", "6", ")", "#5 )", "\n", "\n", "# char embedding", "\n", "n", ".", "embed_c", "=", "L", ".", "Embed", "(", "n", ".", "data1", ",", "input_dim", "=", "question_c_vocab_size", ",", "num_output", "=", "100", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "\n", "n", ".", "embed_c_scale", "=", "L", ".", "Scale", "(", "n", ".", "embed_c", ",", "n", ".", "cont1", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "\n", "n", ".", "embed_c_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_c_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T_c", "*", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T_c*T x d_c x 1", "\n", "tops", "=", "L", ".", "Slice", "(", "n", ".", "embed_c_scale_resh", ",", "ntop", "=", "T", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T_c x d_c x 1", "\n", "for", "i", "in", "xrange", "(", "T", ")", ":", "\n", "        ", "n", ".", "__setattr__", "(", "'Slice_'", "+", "str", "(", "i", "+", "1", ")", ",", "tops", "[", "int", "(", "i", ")", "]", ")", "\n", "\n", "# avg of char embedding", "\n", "", "n", ".", "c_embed_1", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_1", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_2", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_2", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_3", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_3", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_4", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_4", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_5", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_5", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_6", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_6", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_7", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_7", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_8", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_8", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_9", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_9", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_10", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_10", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_11", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_11", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_12", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_12", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_13", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_13", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_14", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_14", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_15", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_15", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_16", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_16", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_17", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_17", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_18", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_18", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_19", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_19", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_20", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_20", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_21", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_21", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_22", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_22", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "\n", "concat_c_embed", "=", "[", "n", ".", "c_embed_1", ",", "n", ".", "c_embed_2", ",", "n", ".", "c_embed_3", ",", "n", ".", "c_embed_4", ",", "n", ".", "c_embed_5", ",", "n", ".", "c_embed_6", ",", "n", ".", "c_embed_7", ",", "n", ".", "c_embed_8", ",", "n", ".", "c_embed_9", ",", "n", ".", "c_embed_10", ",", "n", ".", "c_embed_11", ",", "n", ".", "c_embed_12", ",", "n", ".", "c_embed_13", ",", "n", ".", "c_embed_14", ",", "n", ".", "c_embed_15", ",", "n", ".", "c_embed_16", ",", "n", ".", "c_embed_17", ",", "n", ".", "c_embed_18", ",", "n", ".", "c_embed_19", ",", "n", ".", "c_embed_20", ",", "n", ".", "c_embed_21", ",", "n", ".", "c_embed_22", "]", "\n", "n", ".", "concat_char_embed", "=", "L", ".", "Concat", "(", "*", "concat_c_embed", ",", "concat_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T x d_c x 1", "\n", "n", ".", "concat_char_embed_resh", "=", "L", ".", "Reshape", "(", "n", ".", "concat_char_embed", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", "]", ")", ")", ")", "\n", "\n", "# word embedding", "\n", "n", ".", "embed_w", "=", "L", ".", "Embed", "(", "n", ".", "data", ",", "input_dim", "=", "question_vocab_size", ",", "num_output", "=", "200", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "# N x T x d_w", "\n", "\n", "# combine word and char embedding", "\n", "concat_word_embed", "=", "[", "n", ".", "embed_w", ",", "n", ".", "concat_char_embed_resh", "]", "\n", "n", ".", "concat_embed", "=", "L", ".", "Concat", "(", "*", "concat_word_embed", ",", "concat_param", "=", "{", "'axis'", ":", "2", "}", ")", "# N x T x (d_c+d_w)", "\n", "\n", "n", ".", "embed_scale", "=", "L", ".", "Scale", "(", "n", ".", "concat_embed", ",", "n", ".", "cont", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "# N x T x (d_c+d_w)", "\n", "n", ".", "embed_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T x (d_c+d_w) x 1", "\n", "\n", "# avg of word embedding", "\n", "n", ".", "embed_avg", "=", "L", ".", "Convolution", "(", "n", ".", "embed_scale_resh", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x (d_c+d_w) x 1", "\n", "n", ".", "embed_avg_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_avg", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "300", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled_1", "=", "L", ".", "Tile", "(", "n", ".", "embed_avg_resh", ",", "axis", "=", "2", ",", "tiles", "=", "14", ")", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled", "=", "L", ".", "Tile", "(", "n", ".", "q_emb_tanh_droped_resh_tiled_1", ",", "axis", "=", "3", ",", "tiles", "=", "14", ")", "\n", "n", ".", "i_emb_tanh_droped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "img_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "n", ".", "blcf", "=", "L", ".", "CompactBilinear", "(", "n", ".", "q_emb_tanh_droped_resh_tiled", ",", "n", ".", "i_emb_tanh_droped_resh", ",", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "blcf_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "blcf", ")", "\n", "n", ".", "blcf_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "blcf_sign_sqrt", ")", "\n", "n", ".", "blcf_droped", "=", "L", ".", "Dropout", "(", "n", ".", "blcf_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "\n", "# multi-channel attention", "\n", "n", ".", "att_conv1", "=", "L", ".", "Convolution", "(", "n", ".", "blcf_droped", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "512", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_conv1_relu", "=", "L", ".", "ReLU", "(", "n", ".", "att_conv1", ")", "\n", "n", ".", "att_conv2", "=", "L", ".", "Convolution", "(", "n", ".", "att_conv1_relu", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "2", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_reshaped", "=", "L", ".", "Reshape", "(", "n", ".", "att_conv2", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", "*", "14", "]", ")", ")", ")", "\n", "n", ".", "att_softmax", "=", "L", ".", "Softmax", "(", "n", ".", "att_reshaped", ",", "axis", "=", "2", ")", "\n", "n", ".", "att", "=", "L", ".", "Reshape", "(", "n", ".", "att_softmax", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "att_maps", "=", "L", ".", "Slice", "(", "n", ".", "att", ",", "ntop", "=", "2", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "\n", "n", ".", "att_map0", "=", "att_maps", "[", "0", "]", "\n", "n", ".", "att_map1", "=", "att_maps", "[", "1", "]", "\n", "dummy", "=", "L", ".", "DummyData", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "1", "]", ")", ",", "data_filler", "=", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", ",", "ntop", "=", "1", ")", "\n", "n", ".", "att_feature0", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map0", ",", "dummy", ")", "\n", "n", ".", "att_feature1", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map1", ",", "dummy", ")", "\n", "n", ".", "att_feature0_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature0", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.train_att_bc.make_answer_vocab": [[100, 137], ["adic.keys", "sorted", "enumerate", "enumerate", "nadict.items", "nalist.append", "adict.has_key", "config.NUM_OUTPUT_UNITS"], "function", ["None"], ["n", ".", "att_feature1_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature1", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature", "=", "L", ".", "Concat", "(", "n", ".", "att_feature0_resh", ",", "n", ".", "att_feature1_resh", ")", "\n", "\n", "# merge attention and lstm with compact bilinear pooling", "\n", "n", ".", "att_feature_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "4096", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "#n.lstm_12_resh = L.Reshape(n.lstm_12, reshape_param=dict(shape=dict(dim=[-1,2048,1,1])))", "\n", "n", ".", "bc_att_lstm", "=", "L", ".", "CompactBilinear", "(", "n", ".", "att_feature_resh", ",", "n", ".", "embed_avg_resh", ",", "\n", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "bc_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "bc_att_lstm", ")", "\n", "n", ".", "bc_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "bc_sign_sqrt", ")", "\n", "\n", "n", ".", "bc_dropped", "=", "L", ".", "Dropout", "(", "n", ".", "bc_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "n", ".", "bc_dropped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "bc_dropped", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "16000", "]", ")", ")", ")", "\n", "\n", "n", ".", "prediction", "=", "L", ".", "InnerProduct", "(", "n", ".", "bc_dropped_resh", ",", "num_output", "=", "3000", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "loss", "=", "L", ".", "SoftmaxWithLoss", "(", "n", ".", "prediction", ",", "n", ".", "label", ")", "\n", "return", "n", ".", "to_proto", "(", ")", "\n", "\n", "", "def", "make_answer_vocab", "(", "adic", ",", "vocab_size", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "adict", "=", "{", "''", ":", "0", "}", "\n", "nadict", "=", "{", "''", ":", "1000000", "}", "\n", "vid", "=", "1", "\n", "for", "qid", "in", "adic", ".", "keys", "(", ")", ":", "\n", "        ", "answer_obj", "=", "adic", "[", "qid", "]", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "\n", "for", "q_ans", "in", "answer_list", ":", "\n", "# create dict", "\n", "            ", "if", "adict", ".", "has_key", "(", "q_ans", ")", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "=", "1", "\n", "adict", "[", "q_ans", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.train_att_bc.make_question_vocab": [[138, 156], ["qdic.keys", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vdict.has_key"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list"], ["# debug", "\n", "", "", "", "nalist", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "sorted", "(", "nadict", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ":", "\n", "        ", "nalist", ".", "append", "(", "(", "k", ",", "v", ")", ")", "\n", "\n", "# keep the top 3000 answers", "\n", "", "n_del_ans", "=", "0", "\n", "n_valid_ans", "=", "0", "\n", "adict_nid", "=", "{", "}", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", ":", "-", "vocab_size", "]", ")", ":", "\n", "        ", "del", "adict", "[", "w", "[", "0", "]", "]", "\n", "n_del_ans", "+=", "w", "[", "1", "]", "\n", "", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", "-", "vocab_size", ":", "]", ")", ":", "\n", "        ", "n_valid_ans", "+=", "w", "[", "1", "]", "\n", "adict_nid", "[", "w", "[", "0", "]", "]", "=", "i", "\n", "\n", "", "return", "adict_nid", "\n", "\n", "", "def", "make_question_vocab", "(", "qdic", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.train_att_bc.make_vocab_files": [[157, 168], ["write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_question_vocab", "write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_answer_vocab"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_question_vocab", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_answer_vocab"], ["    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "vdict", "=", "{", "''", ":", "0", "}", "\n", "vid", "=", "1", "\n", "cdict", "=", "{", "''", ":", "0", "}", "\n", "cvid", "=", "1", "\n", "for", "qid", "in", "qdic", ".", "keys", "(", ")", ":", "\n", "# sequence to list", "\n", "        ", "q_str", "=", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.train_att_bc.main": [[169, 229], ["write_to_log.write_log", "write_to_log.write_log", "caffe.set_device", "caffe.set_mode_gpu", "caffe.get_solver", "numpy.zeros", "range", "os.path.exists", "os.makedirs", "os.path.exists", "os.path.exists", "write_to_log.write_log", "train_att_bc.make_vocab_files", "open", "f.write", "open", "f.write", "caffe.get_solver.step", "open", "json.load", "open", "json.load", "open", "json.dump", "open", "json.dump", "str", "str", "str", "str", "write_to_log.write_log", "write_to_log.write_log", "train_loss[].mean", "write_to_log.write_log", "caffe.get_solver.test_nets[].save", "write_to_log.write_log", "visualize_tools.exec_validation", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "train_att_bc.qlstm", "train_att_bc.qlstm", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_vocab_files", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.exec_validation", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["# create dict", "\n", "for", "w", "in", "q_list", ":", "\n", "            ", "if", "not", "vdict", ".", "has_key", "(", "w", ")", ":", "\n", "                ", "vdict", "[", "w", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "", "for", "c", "in", "list", "(", "w", ")", ":", "\n", "                ", "if", "not", "cdict", ".", "has_key", "(", "c", ")", ":", "\n", "                    ", "cdict", "[", "c", "]", "=", "cvid", "\n", "cvid", "+=", "1", "\n", "\n", "", "", "", "", "return", "vdict", ",", "cdict", "\n", "\n", "", "def", "make_vocab_files", "(", ")", ":", "\n", "    ", "\"\"\"\n    Produce the question and answer vocabulary files.\n    \"\"\"", "\n", "write_log", "(", "'making question vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "write_log", "(", "'making question character vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "qdic", ",", "_", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "QUESTION_VOCAB_SPACE", ")", "\n", "question_vocab", ",", "question_char_vocab", "=", "make_question_vocab", "(", "qdic", ")", "\n", "write_log", "(", "'making answer vocab... '", "+", "config", ".", "ANSWER_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "_", ",", "adic", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "ANSWER_VOCAB_SPACE", ")", "\n", "answer_vocab", "=", "make_answer_vocab", "(", "adic", ",", "config", ".", "NUM_OUTPUT_UNITS", ")", "\n", "return", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "'./result'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'./result'", ")", "\n", "\n", "", "question_vocab", ",", "answer_vocab", "=", "{", "}", ",", "{", "}", "\n", "if", "os", ".", "path", ".", "exists", "(", "'./result/cdict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/adict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/vdict.json'", ")", ":", "\n", "        ", "write_log", "(", "'restoring vocab'", ",", "'log.txt'", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_char_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "answer_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "=", "make_vocab_files", "(", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_char_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "answer_vocab", ",", "f", ")", "\n", "\n", "", "", "write_log", "(", "'question character vocab size: '", "+", "str", "(", "len", "(", "question_char_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'question vocab size: '", "+", "str", "(", "len", "(", "question_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'answer vocab size: '", "+", "str", "(", "len", "(", "answer_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "\n", "\n", "with", "open", "(", "'./result/proto_train.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "config", ".", "TRAIN_DATA_SPLITS", ",", "config", ".", "BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "with", "open", "(", "'./result/proto_test.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "'val'", ",", "config", ".", "VAL_BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "caffe", ".", "set_device", "(", "config", ".", "GPU_ID", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.visualize_tools.visualize_failures": [[27, 119], ["write_to_log.write_log", "visualize_tools.visualize_failures.save_qtype"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["def", "visualize_failures", "(", "stat_list", ",", "mode", ")", ":", "\n", "\n", "    ", "def", "save_qtype", "(", "qtype_list", ",", "save_filename", ",", "mode", ")", ":", "\n", "\n", "        ", "if", "mode", "==", "'val'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./eval'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/val2014'", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test-dev'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "elif", "mode", "==", "'test'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unsupported mode'", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "shutil", ".", "rmtree", "(", "savepath", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "os", ".", "makedirs", "(", "savepath", ")", "\n", "\n", "for", "qt", "in", "qtype_list", ":", "\n", "            ", "count", "=", "0", "\n", "for", "t_question", "in", "stat_list", ":", "\n", "#print count, t_question", "\n", "                ", "if", "count", "<", "40", "/", "len", "(", "qtype_list", ")", ":", "\n", "                    ", "t_question_list", "=", "t_question", "[", "'q_list'", "]", "\n", "saveflag", "=", "False", "\n", "#print 'debug****************************'", "\n", "#print qt", "\n", "#print t_question_list", "\n", "#print t_question_list[0] == qt[0]", "\n", "#print t_question_list[1] == qt[1]", "\n", "if", "t_question_list", "[", "0", "]", "==", "qt", "[", "0", "]", "and", "t_question_list", "[", "1", "]", "==", "qt", "[", "1", "]", ":", "\n", "                        ", "saveflag", "=", "True", "\n", "", "else", ":", "\n", "                        ", "saveflag", "=", "False", "\n", "\n", "", "if", "saveflag", "==", "True", ":", "\n", "                        ", "t_iid", "=", "t_question", "[", "'iid'", "]", "\n", "if", "mode", "==", "'val'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_val2014_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "", "elif", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_test2015_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "\n", "# for caption", "\n", "#print t_iid", "\n", "#annIds = caps.getAnnIds(t_iid)", "\n", "#anns = caps.loadAnns(annIds)", "\n", "#cap_list = [ann['caption'] for ann in anns]", "\n", "", "ans_list", "=", "t_question", "[", "'ans_list'", "]", "\n", "draw", "=", "ImageDraw", ".", "Draw", "(", "t_img", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ans_list", ")", ")", ":", "\n", "                            ", "try", ":", "\n", "                                ", "draw", ".", "text", "(", "(", "10", ",", "10", "*", "i", ")", ",", "str", "(", "ans_list", "[", "i", "]", ")", ")", "\n", "", "except", ":", "\n", "                                ", "pass", "\n", "\n", "", "", "ans", "=", "t_question", "[", "'answer'", "]", "\n", "pred", "=", "t_question", "[", "'pred'", "]", "\n", "if", "ans", "==", "-", "1", ":", "\n", "                            ", "pre", "=", "''", "\n", "", "elif", "ans", "==", "pred", ":", "\n", "                            ", "pre", "=", "'correct  '", "\n", "", "else", ":", "\n", "                            ", "pre", "=", "'failure  '", "\n", "#print ' aaa ', ans, pred", "\n", "", "ans", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "ans", ")", ")", "\n", "pred", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "pred", ")", ")", "\n", "img_title", "=", "pre", "+", "str", "(", "' '", ".", "join", "(", "t_question_list", ")", ")", "+", "'.  a_'", "+", "str", "(", "ans", ")", "+", "' p_'", "+", "str", "(", "pred", ")", "+", "'.png'", "\n", "count", "+=", "1", "\n", "write_log", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ",", "'visualize_log.txt'", ")", "\n", "t_img", ".", "save", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ")", "\n", "\n", "", "", "", "", "", "write_log", "(", "'saving colors'", ",", "'visualize_log.txt'", ")", "\n", "qt_color_list", "=", "[", "[", "'what'", ",", "'color'", "]", "]", "\n", "save_qtype", "(", "qt_color_list", ",", "'colors'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving what is'", ",", "'visualize_log.txt'", ")", "\n", "qt_whatis_list", "=", "[", "[", "'what'", ",", "'is'", "]", ",", "[", "'what'", ",", "'kind'", "]", ",", "[", "'what'", ",", "'are'", "]", "]", "\n", "save_qtype", "(", "qt_whatis_list", ",", "'whatis'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving is'", ",", "'visualize_log.txt'", ")", "\n", "qt_is_list", "=", "[", "[", "'is'", ",", "'the'", "]", ",", "[", "'is'", ",", "'this'", "]", ",", "[", "'is'", ",", "'there'", "]", "]", "\n", "save_qtype", "(", "qt_is_list", ",", "'is'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving how many'", ",", "'visualize_log.txt'", ")", "\n", "qt_howmany_list", "=", "[", "[", "'how'", ",", "'many'", "]", "]", "\n", "save_qtype", "(", "qt_howmany_list", ",", "'howmany'", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.visualize_tools.exec_validation": [[120, 201], ["caffe.set_device", "caffe.set_mode_gpu", "caffe.Net", "vqa_data_provider_layer.VQADataProvider", "len", "numpy.array().mean", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "vqa_data_provider_layer.VQADataProvider.get_batch_vec", "caffe.Net.forward", "caffe.Net.blobs[].data.argmax", "testloss_list.append", "zip", "vqaTools.vqa.VQA", "vqaTools.vqa.VQA.loadRes", "vqaEvaluation.vqaEval.VQAEval", "vqaEvaluation.vqaEval.VQAEval.evaluate", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "t_answer.tolist", "pred_list.append", "numpy.array", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "stat_list.append", "open", "json.dump", "visualize_tools.visualize_failures", "int", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "str().zfill", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "str().zfill", "xrange", "str", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.forward", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj"], ["", "def", "exec_validation", "(", "device_id", ",", "mode", ",", "it", "=", "''", ",", "visualize", "=", "False", ")", ":", "\n", "\n", "    ", "caffe", ".", "set_device", "(", "device_id", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "net", "=", "caffe", ".", "Net", "(", "'./result/proto_test.prototxt'", ",", "'./result/tmp.caffemodel'", ",", "caffe", ".", "TEST", ")", "\n", "\n", "dp", "=", "VQADataProvider", "(", "mode", "=", "mode", ",", "batchsize", "=", "config", ".", "VAL_BATCH_SIZE", ")", "\n", "total_questions", "=", "len", "(", "dp", ".", "getQuesIds", "(", ")", ")", "\n", "epoch", "=", "0", "\n", "\n", "pred_list", "=", "[", "]", "\n", "testloss_list", "=", "[", "]", "\n", "stat_list", "=", "[", "]", "\n", "\n", "while", "epoch", "==", "0", ":", "\n", "        ", "t_word", ",", "t_cont", ",", "t_word_c", ",", "t_cont_c", ",", "t_img_feature", ",", "t_answer", ",", "t_qid_list", ",", "t_iid_list", ",", "epoch", "=", "dp", ".", "get_batch_vec", "(", ")", "\n", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "...", "]", "=", "t_word", "# np.transpose(t_word,(1,0))", "\n", "net", ".", "blobs", "[", "'cont'", "]", ".", "data", "[", "...", "]", "=", "t_cont", "# np.transpose(t_cont,(1,0))", "\n", "net", ".", "blobs", "[", "'data1'", "]", ".", "data", "[", "...", "]", "=", "t_word_c", "\n", "net", ".", "blobs", "[", "'cont1'", "]", ".", "data", "[", "...", "]", "=", "t_cont_c", "\n", "net", ".", "blobs", "[", "'img_feature'", "]", ".", "data", "[", "...", "]", "=", "t_img_feature", "\n", "net", ".", "blobs", "[", "'label'", "]", ".", "data", "[", "...", "]", "=", "t_answer", "\n", "#net.blobs['glove'].data[...] = t_glove_matrix # np.transpose(t_glove_matrix, (1,0,2))", "\n", "net", ".", "forward", "(", ")", "\n", "t_pred_list", "=", "net", ".", "blobs", "[", "'prediction'", "]", ".", "data", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "t_pred_str", "=", "[", "dp", ".", "vec_to_answer", "(", "pred_symbol", ")", "for", "pred_symbol", "in", "t_pred_list", "]", "\n", "testloss_list", ".", "append", "(", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", ")", "\n", "for", "qid", ",", "iid", ",", "ans", ",", "pred", "in", "zip", "(", "t_qid_list", ",", "t_iid_list", ",", "t_answer", ".", "tolist", "(", ")", ",", "t_pred_str", ")", ":", "\n", "            ", "pred_list", ".", "append", "(", "{", "u'answer'", ":", "pred", ",", "u'question_id'", ":", "int", "(", "dp", ".", "getStrippedQuesId", "(", "qid", ")", ")", "}", ")", "\n", "if", "visualize", ":", "\n", "                ", "q_list", "=", "dp", ".", "seq_to_list", "(", "dp", ".", "getQuesStr", "(", "qid", ")", ")", "\n", "if", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                    ", "ans_str", "=", "''", "\n", "ans_list", "=", "[", "''", "]", "*", "10", "\n", "", "else", ":", "\n", "                    ", "ans_str", "=", "dp", ".", "vec_to_answer", "(", "ans", ")", "\n", "ans_list", "=", "[", "dp", ".", "getAnsObj", "(", "qid", ")", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "", "stat_list", ".", "append", "(", "{", "'qid'", ":", "qid", ",", "\n", "'q_list'", ":", "q_list", ",", "\n", "'iid'", ":", "iid", ",", "\n", "'answer'", ":", "ans_str", ",", "\n", "'ans_list'", ":", "ans_list", ",", "\n", "'pred'", ":", "pred", "}", ")", "\n", "#percent = 100 * float(len(pred_list)) / total_questions", "\n", "#sys.stdout.write('\\r' + ('%.2f' % percent) + '%')", "\n", "#sys.stdout.flush()", "\n", "\n", "\n", "\n", "", "", "", "mean_testloss", "=", "np", ".", "array", "(", "testloss_list", ")", ".", "mean", "(", ")", "\n", "\n", "if", "mode", "==", "'val'", ":", "\n", "        ", "valFile", "=", "'./result/val2014_resfile'", "\n", "with", "open", "(", "valFile", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "annFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ans_file'", "]", "\n", "quesFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ques_file'", "]", "\n", "vqa", "=", "VQA", "(", "annFile", ",", "quesFile", ")", "\n", "vqaRes", "=", "vqa", ".", "loadRes", "(", "valFile", ",", "quesFile", ")", "\n", "vqaEval", "=", "VQAEval", "(", "vqa", ",", "vqaRes", ",", "n", "=", "2", ")", "\n", "vqaEval", ".", "evaluate", "(", ")", "\n", "acc_overall", "=", "vqaEval", ".", "accuracy", "[", "'overall'", "]", "\n", "acc_perQuestionType", "=", "vqaEval", ".", "accuracy", "[", "'perQuestionType'", "]", "\n", "acc_perAnswerType", "=", "vqaEval", ".", "accuracy", "[", "'perAnswerType'", "]", "\n", "return", "mean_testloss", ",", "acc_overall", ",", "acc_perQuestionType", ",", "acc_perAnswerType", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test-dev2015_v3t'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "", "elif", "mode", "==", "'test'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test2015_v3c'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Residual.visualize_tools.drawgraph": [[202, 270], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.twinx", "fig.add_subplot.plot", "fig.add_subplot.plot", "ax1.twinx.plot", "matplotlib.legend", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "ax1.twinx.set_ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "numpy.array", "numpy.array", "matplotlib.figure", "matplotlib.legend", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "sorted", "visualize_tools.drawgraph.draw_qt_acc"], "function", ["None"], ["\n", "", "", "", "def", "drawgraph", "(", "results", ",", "save_question_type_graphs", "=", "False", ")", ":", "\n", "# 0:it", "\n", "# 1:trainloss", "\n", "# 2:testloss", "\n", "# 3:oa_acc", "\n", "# 4:qt_acc", "\n", "# 5:at_acc", "\n", "\n", "# training curve", "\n", "    ", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "loss", "=", "np", ".", "array", "(", "[", "l", "[", "1", "]", "for", "l", "in", "results", "]", ")", "\n", "valloss", "=", "np", ".", "array", "(", "[", "l", "[", "2", "]", "for", "l", "in", "results", "]", ")", "\n", "valacc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax1", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "ax2", "=", "ax1", ".", "twinx", "(", ")", "\n", "\n", "ax1", ".", "plot", "(", "it", ",", "loss", ",", "color", "=", "'blue'", ",", "label", "=", "'train loss'", ")", "\n", "ax1", ".", "plot", "(", "it", ",", "valloss", ",", "'--'", ",", "color", "=", "'blue'", ",", "label", "=", "'test loss'", ")", "\n", "ax2", ".", "plot", "(", "it", ",", "valacc", ",", "color", "=", "'red'", ",", "label", "=", "'acc on val'", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'lower left'", ")", "\n", "\n", "ax1", ".", "set_xlabel", "(", "'Iterations'", ")", "\n", "ax1", ".", "set_ylabel", "(", "'Loss Value'", ")", "\n", "ax2", ".", "set_ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "'./learning_curve max_%2.2f.png'", "%", "valacc", ".", "max", "(", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "# question type", "\n", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "oa_acc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "qt_dic_list", "=", "[", "l", "[", "4", "]", "for", "l", "in", "results", "]", "\n", "\n", "def", "draw_qt_acc", "(", "target_key_list", ",", "figname", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "for", "k", "in", "target_key_list", ":", "\n", "            ", "write_log", "(", "str", "(", "k", ")", "+", "str", "(", "type", "(", "k", ")", ")", ",", "'visualize_log.txt'", ")", "\n", "t_val", "=", "np", ".", "array", "(", "[", "qt_dic", "[", "k", "]", "for", "qt_dic", "in", "qt_dic_list", "]", ")", "\n", "plt", ".", "plot", "(", "it", ",", "t_val", ",", "label", "=", "str", "(", "k", ")", ")", "\n", "", "plt", ".", "legend", "(", "fontsize", "=", "'small'", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "100.", ")", "\n", "#plt.legend(prop={'size':6})", "\n", "\n", "plt", ".", "xlabel", "(", "'Iterations'", ")", "\n", "plt", ".", "ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "figname", ",", "dpi", "=", "200", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "", "if", "save_question_type_graphs", ":", "\n", "        ", "s_keys", "=", "sorted", "(", "qt_dic_list", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "0", ":", "13", "]", "+", "[", "s_keys", "[", "31", "]", ",", "]", ",", "'./ind_qt_are.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "13", ":", "17", "]", "+", "s_keys", "[", "49", ":", "]", ",", "'./ind_qt_how_where_who_why.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "17", ":", "31", "]", "+", "[", "s_keys", "[", "32", "]", ",", "]", ",", "'./ind_qt_is.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "33", ":", "49", "]", ",", "'./ind_qt_what.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what color is the'", ",", "'what color are the'", ",", "'what color is'", ",", "'what color'", ",", "'what is the color of the'", "]", ",", "'./qt_color.png'", ")", "\n", "draw_qt_acc", "(", "[", "'how many'", ",", "'how'", ",", "'how many people are'", ",", "'how many people are in'", "]", ",", "'./qt_number.png'", ")", "\n", "draw_qt_acc", "(", "[", "'who is'", ",", "'why'", ",", "'why is the'", ",", "'where is the'", ",", "'where are the'", ",", "'which'", "]", ",", "'./qt_who_why_where_which.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what is the man'", ",", "'is the man'", ",", "'are they'", ",", "'is he'", ",", "'is the woman'", ",", "'is this person'", ",", "'what is the woman'", ",", "'is the person'", ",", "'what is the person'", "]", ",", "'./qt_human.png'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.write_to_log.write_log": [[1, 4], ["open", "f.write"], "function", ["None"], ["def", "write_log", "(", "str", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "+", "\"\\n\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.__init__": [[13, 29], ["vqa_data_provider_layer.VQADataProvider.load_data", "len", "open", "json.load", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data"], ["    ", "def", "__init__", "(", "self", ",", "batchsize", "=", "64", ",", "max_length", "=", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "max_w_length", "=", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "batchsize", "\n", "self", ".", "d_vocabulary", "=", "None", "\n", "self", ".", "batch_index", "=", "None", "\n", "self", ".", "batch_len", "=", "None", "\n", "self", ".", "rev_adict", "=", "None", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "max_w_length", "=", "max_w_length", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "qdic", ",", "self", ".", "adic", "=", "VQADataProvider", ".", "load_data", "(", "mode", ")", "\n", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "cdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "vdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "adict", "=", "json", ".", "load", "(", "f", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.load_vqa_json": [[32, 55], ["write_to_log.write_log", "open", "json.load", "open", "json.load", "str", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["#self.nlp = spacy.load('en', vectors='en_glove_cc_300_1m_vectors')", "\n", "#self.glove_dict = {} # word -> glove vector", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_vqa_json", "(", "data_split", ")", ":", "\n", "        ", "\"\"\"\n        Parses the question and answer json files for the given data split. \n        Returns the question dictionary and the answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ques_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "[", "'questions'", "]", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "qdic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'question_id'", "]", ")", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image_id'", "]", "}", "\n", "\n", "", "", "if", "'test'", "not", "in", "data_split", ":", "\n", "            ", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ans_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "adata", "=", "json", ".", "load", "(", "f", ")", "[", "'annotations'", "]", "\n", "for", "a", "in", "adata", ":", "\n", "                    ", "adic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "a", "[", "'question_id'", "]", ")", "]", "=", "a", "[", "'answers'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.load_genome_json": [[56, 73], ["write_to_log.write_log", "open", "json.load", "str", "str", "len"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for '", "+", "data_split", ",", "'log.txt'", ")", "\n", "return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_genome_json", "(", ")", ":", "\n", "        ", "\"\"\"\n        Parses the genome json file. Returns the question dictionary and the\n        answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'genome_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "key", "=", "'genome'", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'id'", "]", ")", "\n", "qdic", "[", "key", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image'", "]", "}", "\n", "adic", "[", "key", "]", "=", "[", "{", "'answer'", ":", "q", "[", "'answer'", "]", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.load_data": [[74, 89], ["data_split_str.split", "config.DATA_PATHS.keys", "vqa_data_provider_layer.VQADataProvider.load_genome_json", "all_qdic.update", "all_adic.update", "vqa_data_provider_layer.VQADataProvider.load_vqa_json", "all_qdic.update", "all_adic.update"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_genome_json", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_vqa_json"], ["", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for genome'", ",", "'log.txt'", ")", "\n", "return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_data", "(", "data_split_str", ")", ":", "\n", "        ", "all_qdic", ",", "all_adic", "=", "{", "}", ",", "{", "}", "\n", "for", "data_split", "in", "data_split_str", ".", "split", "(", "'+'", ")", ":", "\n", "            ", "assert", "data_split", "in", "config", ".", "DATA_PATHS", ".", "keys", "(", ")", ",", "'unknown data split'", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_genome_json", "(", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "", "else", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_vqa_json", "(", "data_split", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.getQuesIds": [[90, 92], ["vqa_data_provider_layer.VQADataProvider.qdic.keys"], "methods", ["None"], ["\n", "", "", "return", "all_qdic", ",", "all_adic", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.getStrippedQuesId": [[93, 95], ["qid.split"], "methods", ["None"], ["", "def", "getQuesIds", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "qdic", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.getImgId": [[96, 98], ["None"], "methods", ["None"], ["", "def", "getStrippedQuesId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.getQuesStr": [[99, 101], ["None"], "methods", ["None"], ["", "def", "getImgId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'iid'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.getAnsObj": [[102, 106], ["None"], "methods", ["None"], ["", "def", "getQuesStr", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "\n", "", "def", "getAnsObj", "(", "self", ",", "qid", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.seq_to_char_list": [[118, 123], ["list", "filter", "s.lower", "len"], "methods", ["None"], ["q_list", "=", "filter", "(", "lambda", "x", ":", "len", "(", "x", ")", ">", "0", ",", "q_list", ")", "\n", "return", "q_list", "\n", "\n", "", "def", "extract_answer", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.extract_answer": [[124, 137], ["dic.has_key", "max", "xrange", "dic.items"], "methods", ["None"], ["            ", "return", "-", "1", "\n", "", "answer_list", "=", "[", "answer_obj", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "dic", "=", "{", "}", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "dic", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "dic", "[", "ans", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "dic", "[", "ans", "]", "=", "1", "\n", "", "", "max_key", "=", "max", "(", "(", "v", ",", "k", ")", "for", "(", "k", ",", "v", ")", "in", "dic", ".", "items", "(", ")", ")", "[", "1", "]", "\n", "return", "max_key", "\n", "\n", "", "def", "extract_answer_prob", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.extract_answer_prob": [[138, 156], ["vqa_data_provider_layer.VQADataProvider.adict.has_key", "len", "random.choice", "prob_answer_list.append", "Exception"], "methods", ["None"], ["            ", "return", "-", "1", "\n", "\n", "", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "prob_answer_list", "=", "[", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "prob_answer_list", ".", "append", "(", "ans", ")", "\n", "\n", "", "", "if", "len", "(", "prob_answer_list", ")", "==", "0", ":", "\n", "            ", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "return", "'hoge'", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"This should not happen.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "random", ".", "choice", "(", "prob_answer_list", ")", "\n", "\n", "# def qlist_to_vec(self, max_length, q_list):", "\n", "#     \"\"\"", "\n", "#     Converts a list of words into a format suitable for the embedding layer.", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.qc_list_to_vec": [[205, 230], ["numpy.zeros", "numpy.zeros", "xrange", "len", "vqa_data_provider_layer.VQADataProvider.cdict.has_key", "len"], "methods", ["None"], ["\n", "qvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "cvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "qcvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "ccvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "for", "i", "in", "xrange", "(", "max_length", ")", ":", "\n", "            ", "if", "i", "<", "max_length", "-", "len", "(", "q_list", ")", ":", "\n", "                ", "cvec", "[", "i", "]", "=", "0", "\n", "", "else", ":", "\n", "                ", "w", "=", "q_list", "[", "i", "-", "(", "max_length", "-", "len", "(", "q_list", ")", ")", "]", "\n", "# is the word in the vocabulary?", "\n", "if", "self", ".", "vdict", ".", "has_key", "(", "w", ")", "is", "False", ":", "\n", "                    ", "w", "=", "''", "\n", "", "qvec", "[", "i", "]", "=", "self", ".", "vdict", "[", "w", "]", "\n", "cvec", "[", "i", "]", "=", "1.0", "/", "len", "(", "q_list", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.answer_to_vec": [[231, 241], ["vqa_data_provider_layer.VQADataProvider.adict.has_key"], "methods", ["None"], ["j", "=", "max_w_length", "*", "i", "\n", "w_list", "=", "list", "(", "w", ")", "\n", "for", "k", "in", "xrange", "(", "max_w_length", ")", ":", "\n", "                    ", "if", "k", "<", "max_w_length", "-", "len", "(", "w_list", ")", ":", "\n", "                        ", "ccvec", "[", "j", "+", "k", "]", "=", "0", "\n", "", "else", ":", "\n", "                        ", "c", "=", "w_list", "[", "k", "-", "(", "max_w_length", "-", "len", "(", "w_list", ")", ")", "]", "\n", "# is the char in the vocabulary?", "\n", "if", "self", ".", "cdict", ".", "has_key", "(", "c", ")", "is", "False", ":", "\n", "                            ", "c", "=", "''", "\n", "", "qcvec", "[", "j", "+", "k", "]", "=", "self", ".", "cdict", "[", "c", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.vec_to_answer": [[242, 251], ["vqa_data_provider_layer.VQADataProvider.adict.items"], "methods", ["None"], ["ccvec", "[", "j", "+", "k", "]", "=", "1.0", "/", "len", "(", "w_list", ")", "\n", "", "", "", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", "\n", "\n", "", "def", "answer_to_vec", "(", "self", ",", "ans_str", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "if", "self", ".", "adict", ".", "has_key", "(", "ans_str", ")", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "ans_str", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.create_batch": [[252, 298], ["numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "enumerate", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.seq_to_char_list", "vqa_data_provider_layer.VQADataProvider.qc_list_to_vec", "vqa_data_provider_layer.VQADataProvider.answer_to_vec", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "qid.split", "vqa_data_provider_layer.VQADataProvider.extract_answer", "vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "numpy.sqrt", "write_to_log.write_log", "numpy.load", "numpy.load", "str", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId", "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.seq_to_char_list", "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.qc_list_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.answer_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["", "else", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "''", "]", "\n", "", "return", "ans", "\n", "\n", "", "def", "vec_to_answer", "(", "self", ",", "ans_symbol", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "rev_adict", "is", "None", ":", "\n", "            ", "rev_adict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "adict", ".", "items", "(", ")", ":", "\n", "                ", "rev_adict", "[", "v", "]", "=", "k", "\n", "", "self", ".", "rev_adict", "=", "rev_adict", "\n", "\n", "", "return", "self", ".", "rev_adict", "[", "ans_symbol", "]", "\n", "\n", "", "def", "create_batch", "(", "self", ",", "qid_list", ")", ":", "\n", "\n", "        ", "qvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "cvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "qcvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ccvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ivec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "2048", "*", "14", "*", "14", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "2048", ",", "14", ",", "14", ")", "\n", "avec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ")", "\n", "#glove_matrix = np.zeros(self.batchsize * self.max_length * GLOVE_EMBEDDING_SIZE).reshape(\\", "\n", "#self.batchsize, self.max_length, GLOVE_EMBEDDING_SIZE)", "\n", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "\n", "# load raw question information", "\n", "            ", "q_str", "=", "self", ".", "getQuesStr", "(", "qid", ")", "\n", "q_ans", "=", "self", ".", "getAnsObj", "(", "qid", ")", "\n", "q_iid", "=", "self", ".", "getImgId", "(", "qid", ")", "\n", "\n", "# convert question to vec", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "t_qvec", ",", "t_cvec", ",", "t_qcvec", ",", "t_ccvec", "=", "self", ".", "qlist_to_vec", "(", "self", ".", "max_length", ",", "self", ".", "max_w_length", ",", "q_list", ")", "\n", "\n", "try", ":", "\n", "                ", "qid_split", "=", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "\n", "data_split", "=", "qid_split", "[", "0", "]", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "else", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "t_ivec", "=", "(", "t_ivec", "/", "np", ".", "sqrt", "(", "(", "t_ivec", "**", "2", ")", ".", "sum", "(", ")", ")", ")", "\n", "", "except", ":", "\n", "                ", "t_ivec", "=", "0.", "\n", "write_log", "(", "'data not found for qid : '", "+", "str", "(", "q_iid", ")", "+", "' '", "+", "self", ".", "mode", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.get_batch_vec": [[300, 347], ["vqa_data_provider_layer.VQADataProvider.create_batch", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "random.shuffle", "len", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.adict.has_key", "t_qid_list.append", "t_iid_list.append", "vqa_data_provider_layer.VQADataProvider.get_batch_vec.has_at_least_one_valid_answer"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.create_batch", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId"], ["# convert answer to vec", "\n", "", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer", "(", "q_ans", ")", "\n", "", "else", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer_prob", "(", "q_ans", ")", "\n", "", "t_avec", "=", "self", ".", "answer_to_vec", "(", "q_ans_str", ")", "\n", "\n", "qvec", "[", "i", ",", "...", "]", "=", "t_qvec", "\n", "cvec", "[", "i", ",", "...", "]", "=", "t_cvec", "\n", "qcvec", "[", "i", ",", "...", "]", "=", "t_qcvec", "\n", "ccvec", "[", "i", ",", "...", "]", "=", "t_ccvec", "\n", "ivec", "[", "i", ",", "...", "]", "=", "t_ivec", "\n", "avec", "[", "i", ",", "...", "]", "=", "t_avec", "\n", "#glove_matrix[i,...] = t_glove_matrix", "\n", "\n", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", ",", "ivec", ",", "avec", "#, glove_matrix", "\n", "\n", "\n", "", "def", "get_batch_vec", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "batch_len", "is", "None", ":", "\n", "            ", "self", ".", "n_skipped", "=", "0", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_len", "=", "len", "(", "qid_list", ")", "\n", "self", ".", "batch_index", "=", "0", "\n", "self", ".", "epoch_counter", "=", "0", "\n", "\n", "", "def", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "            ", "answer_obj", "=", "self", ".", "getAnsObj", "(", "t_qid", ")", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "                ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n", "                    ", "return", "True", "\n", "\n", "", "", "", "counter", "=", "0", "\n", "t_qid_list", "=", "[", "]", "\n", "t_iid_list", "=", "[", "]", "\n", "while", "counter", "<", "self", ".", "batchsize", ":", "\n", "            ", "t_qid", "=", "self", ".", "qid_list", "[", "self", ".", "batch_index", "]", "\n", "t_iid", "=", "self", ".", "getImgId", "(", "t_qid", ")", "\n", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n", "", "elif", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProviderLayer.setup": [[353, 367], ["top[].reshape", "top[].reshape", "top[].reshape", "top[].reshape", "json.loads", "json.loads", "vqa_data_provider_layer.VQADataProvider"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape"], ["                ", "self", ".", "batch_index", "+=", "1", "\n", "", "else", ":", "\n", "                ", "self", ".", "epoch_counter", "+=", "1", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_index", "=", "0", "\n", "write_log", "(", "\"%d questions were skipped in a single epoch\"", "%", "self", ".", "n_skipped", ",", "'log.txt'", ")", "\n", "self", ".", "n_skipped", "=", "0", "\n", "\n", "", "", "t_batch", "=", "self", ".", "create_batch", "(", "t_qid_list", ")", "\n", "return", "t_batch", "+", "(", "t_qid_list", ",", "t_iid_list", ",", "self", ".", "epoch_counter", ")", "\n", "\n", "", "", "class", "VQADataProviderLayer", "(", "caffe", ".", "Layer", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProviderLayer.reshape": [[368, 370], ["None"], "methods", ["None"], ["\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProviderLayer.forward": [[371, 380], ["vqa_data_provider_layer.VQADataProviderLayer.dp.get_batch_vec"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec"], ["def", "setup", "(", "self", ",", "bottom", ",", "top", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "json", ".", "loads", "(", "self", ".", "param_str", ")", "[", "'batchsize'", "]", "\n", "self", ".", "top_names", "=", "[", "'data'", ",", "'cont'", ",", "'data1'", ",", "'cont1'", ",", "'feature'", ",", "'label'", "]", "#,'glove']", "\n", "top", "[", "0", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ")", "\n", "top", "[", "1", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ")", "\n", "top", "[", "2", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", "*", "config", ".", "MAX_WORDS_IN_QUESTION", ")", "\n", "top", "[", "3", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", "*", "config", ".", "MAX_WORDS_IN_QUESTION", ")", "\n", "top", "[", "4", "]", ".", "reshape", "(", "self", ".", "batchsize", ",", "2048", ",", "14", ",", "14", ")", "\n", "top", "[", "5", "]", ".", "reshape", "(", "self", ".", "batchsize", ")", "\n", "#top[4].reshape(self.batchsize,config.MAX_WORDS_IN_QUESTION,GLOVE_EMBEDDING_SIZE)", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProviderLayer.backward": [[382, 384], ["None"], "methods", ["None"], ["self", ".", "mode", "=", "json", ".", "loads", "(", "self", ".", "param_str", ")", "[", "'mode'", "]", "\n", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "pass", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.train_att_bc.qlstm": [[19, 103], ["caffe.NetSpec", "json.dumps", "caffe.layers.Python", "caffe.layers.Embed", "caffe.layers.Scale", "caffe.layers.Reshape", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Pooling", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Pooling", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Pooling", "caffe.layers.Reshape", "caffe.layers.Dropout", "caffe.layers.Tile", "caffe.layers.Tile", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.Reshape", "caffe.layers.Softmax", "caffe.layers.Reshape", "caffe.layers.Slice", "caffe.layers.DummyData", "caffe.layers.SoftAttention", "caffe.layers.SoftAttention", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Concat", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Reshape", "caffe.layers.InnerProduct", "caffe.layers.SoftmaxWithLoss", "caffe.NetSpec.to_proto", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "config.TRAIN_DATA_SPLITS", "config.BATCH_SIZE", "config.MAX_CHARS_IN_QUESTION", "config.VAL_BATCH_SIZE", "config.MAX_CHARS_IN_QUESTION"], "function", ["None"], ["def", "qlstm", "(", "mode", ",", "batchsize", ",", "T", ",", "T_c", ",", "question_c_vocab_size", ",", "question_vocab_size", ")", ":", "\n", "    ", "n", "=", "caffe", ".", "NetSpec", "(", ")", "\n", "mode_str", "=", "json", ".", "dumps", "(", "{", "'mode'", ":", "mode", ",", "'batchsize'", ":", "batchsize", "}", ")", "\n", "n", ".", "data", ",", "n", ".", "cont", ",", "n", ".", "data1", ",", "n", ".", "cont1", ",", "n", ".", "img_feature", ",", "n", ".", "label", "=", "L", ".", "Python", "(", "module", "=", "'vqa_data_provider_layer'", ",", "layer", "=", "'VQADataProviderLayer'", ",", "param_str", "=", "mode_str", ",", "ntop", "=", "6", ")", "#5 )", "\n", "\n", "# char embedding", "\n", "n", ".", "embed_c", "=", "L", ".", "Embed", "(", "n", ".", "data1", ",", "input_dim", "=", "question_c_vocab_size", ",", "num_output", "=", "100", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "\n", "n", ".", "embed_c_scale", "=", "L", ".", "Scale", "(", "n", ".", "embed_c", ",", "n", ".", "cont1", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "\n", "n", ".", "embed_c_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_c_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T_c", "*", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T_c*T x d_c x 1", "\n", "tops", "=", "L", ".", "Slice", "(", "n", ".", "embed_c_scale_resh", ",", "ntop", "=", "T", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T_c x d_c x 1", "\n", "for", "i", "in", "xrange", "(", "T", ")", ":", "\n", "        ", "n", ".", "__setattr__", "(", "'Slice_'", "+", "str", "(", "i", "+", "1", ")", ",", "tops", "[", "int", "(", "i", ")", "]", ")", "\n", "\n", "# avg of char embedding", "\n", "", "n", ".", "c_embed_1", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_1", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_2", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_2", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_3", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_3", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_4", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_4", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_5", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_5", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_6", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_6", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_7", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_7", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_8", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_8", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_9", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_9", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_10", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_10", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_11", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_11", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_12", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_12", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_13", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_13", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_14", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_14", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_15", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_15", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_16", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_16", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_17", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_17", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_18", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_18", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_19", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_19", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_20", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_20", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_21", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_21", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_22", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_22", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "\n", "concat_c_embed", "=", "[", "n", ".", "c_embed_1", ",", "n", ".", "c_embed_2", ",", "n", ".", "c_embed_3", ",", "n", ".", "c_embed_4", ",", "n", ".", "c_embed_5", ",", "n", ".", "c_embed_6", ",", "n", ".", "c_embed_7", ",", "n", ".", "c_embed_8", ",", "n", ".", "c_embed_9", ",", "n", ".", "c_embed_10", ",", "n", ".", "c_embed_11", ",", "n", ".", "c_embed_12", ",", "n", ".", "c_embed_13", ",", "n", ".", "c_embed_14", ",", "n", ".", "c_embed_15", ",", "n", ".", "c_embed_16", ",", "n", ".", "c_embed_17", ",", "n", ".", "c_embed_18", ",", "n", ".", "c_embed_19", ",", "n", ".", "c_embed_20", ",", "n", ".", "c_embed_21", ",", "n", ".", "c_embed_22", "]", "\n", "n", ".", "concat_char_embed", "=", "L", ".", "Concat", "(", "*", "concat_c_embed", ",", "concat_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T x d_c x 1", "\n", "n", ".", "concat_char_embed_resh", "=", "L", ".", "Reshape", "(", "n", ".", "concat_char_embed", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", "]", ")", ")", ")", "\n", "\n", "# word embedding", "\n", "n", ".", "embed_w", "=", "L", ".", "Embed", "(", "n", ".", "data", ",", "input_dim", "=", "question_vocab_size", ",", "num_output", "=", "200", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "# N x T x d_w", "\n", "\n", "# combine word and char embedding", "\n", "concat_word_embed", "=", "[", "n", ".", "embed_w", ",", "n", ".", "concat_char_embed_resh", "]", "\n", "n", ".", "concat_embed", "=", "L", ".", "Concat", "(", "*", "concat_word_embed", ",", "concat_param", "=", "{", "'axis'", ":", "2", "}", ")", "# N x T x (d_c+d_w)", "\n", "\n", "n", ".", "embed_scale", "=", "L", ".", "Scale", "(", "n", ".", "concat_embed", ",", "n", ".", "cont", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "# N x T x (d_c+d_w)", "\n", "n", ".", "embed_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T x (d_c+d_w) x 1", "\n", "\n", "# avg of word embedding", "\n", "n", ".", "embed_avg", "=", "L", ".", "Convolution", "(", "n", ".", "embed_scale_resh", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x (d_c+d_w) x 1", "\n", "n", ".", "embed_avg_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_avg", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "300", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled_1", "=", "L", ".", "Tile", "(", "n", ".", "embed_avg_resh", ",", "axis", "=", "2", ",", "tiles", "=", "14", ")", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled", "=", "L", ".", "Tile", "(", "n", ".", "q_emb_tanh_droped_resh_tiled_1", ",", "axis", "=", "3", ",", "tiles", "=", "14", ")", "\n", "n", ".", "i_emb_tanh_droped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "img_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "n", ".", "blcf", "=", "L", ".", "CompactBilinear", "(", "n", ".", "q_emb_tanh_droped_resh_tiled", ",", "n", ".", "i_emb_tanh_droped_resh", ",", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "blcf_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "blcf", ")", "\n", "n", ".", "blcf_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "blcf_sign_sqrt", ")", "\n", "n", ".", "blcf_droped", "=", "L", ".", "Dropout", "(", "n", ".", "blcf_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "\n", "# multi-channel attention", "\n", "n", ".", "att_conv1", "=", "L", ".", "Convolution", "(", "n", ".", "blcf_droped", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "512", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_conv1_relu", "=", "L", ".", "ReLU", "(", "n", ".", "att_conv1", ")", "\n", "n", ".", "att_conv2", "=", "L", ".", "Convolution", "(", "n", ".", "att_conv1_relu", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "2", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_reshaped", "=", "L", ".", "Reshape", "(", "n", ".", "att_conv2", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", "*", "14", "]", ")", ")", ")", "\n", "n", ".", "att_softmax", "=", "L", ".", "Softmax", "(", "n", ".", "att_reshaped", ",", "axis", "=", "2", ")", "\n", "n", ".", "att", "=", "L", ".", "Reshape", "(", "n", ".", "att_softmax", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "att_maps", "=", "L", ".", "Slice", "(", "n", ".", "att", ",", "ntop", "=", "2", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "\n", "n", ".", "att_map0", "=", "att_maps", "[", "0", "]", "\n", "n", ".", "att_map1", "=", "att_maps", "[", "1", "]", "\n", "dummy", "=", "L", ".", "DummyData", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "1", "]", ")", ",", "data_filler", "=", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", ",", "ntop", "=", "1", ")", "\n", "n", ".", "att_feature0", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map0", ",", "dummy", ")", "\n", "n", ".", "att_feature1", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map1", ",", "dummy", ")", "\n", "n", ".", "att_feature0_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature0", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature1_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature1", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature", "=", "L", ".", "Concat", "(", "n", ".", "att_feature0_resh", ",", "n", ".", "att_feature1_resh", ")", "\n", "\n", "# merge attention and lstm with compact bilinear pooling", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.train_att_bc.make_answer_vocab": [[104, 141], ["adic.keys", "sorted", "enumerate", "enumerate", "nadict.items", "nalist.append", "adict.has_key", "config.NUM_OUTPUT_UNITS"], "function", ["None"], ["n", ".", "att_feature_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "4096", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "#n.lstm_12_resh = L.Reshape(n.lstm_12, reshape_param=dict(shape=dict(dim=[-1,2048,1,1])))", "\n", "n", ".", "bc_att_lstm", "=", "L", ".", "CompactBilinear", "(", "n", ".", "att_feature_resh", ",", "n", ".", "embed_avg_resh", ",", "\n", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "bc_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "bc_att_lstm", ")", "\n", "n", ".", "bc_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "bc_sign_sqrt", ")", "\n", "\n", "n", ".", "bc_dropped", "=", "L", ".", "Dropout", "(", "n", ".", "bc_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "n", ".", "bc_dropped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "bc_dropped", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "16000", "]", ")", ")", ")", "\n", "\n", "n", ".", "prediction", "=", "L", ".", "InnerProduct", "(", "n", ".", "bc_dropped_resh", ",", "num_output", "=", "3000", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "loss", "=", "L", ".", "SoftmaxWithLoss", "(", "n", ".", "prediction", ",", "n", ".", "label", ")", "\n", "return", "n", ".", "to_proto", "(", ")", "\n", "\n", "", "def", "make_answer_vocab", "(", "adic", ",", "vocab_size", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "adict", "=", "{", "''", ":", "0", "}", "\n", "nadict", "=", "{", "''", ":", "1000000", "}", "\n", "vid", "=", "1", "\n", "for", "qid", "in", "adic", ".", "keys", "(", ")", ":", "\n", "        ", "answer_obj", "=", "adic", "[", "qid", "]", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "\n", "for", "q_ans", "in", "answer_list", ":", "\n", "# create dict", "\n", "            ", "if", "adict", ".", "has_key", "(", "q_ans", ")", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "=", "1", "\n", "adict", "[", "q_ans", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "\n", "# debug", "\n", "", "", "", "nalist", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "sorted", "(", "nadict", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ":", "\n", "        ", "nalist", ".", "append", "(", "(", "k", ",", "v", ")", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.train_att_bc.make_question_char_vocab": [[161, 177], ["qdic.keys", "vqa_data_provider_layer.VQADataProvider.seq_to_char_list", "cdict.has_key"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.vqa_data_provider_layer.VQADataProvider.seq_to_char_list"], ["vid", "=", "1", "\n", "cdict", "=", "{", "''", ":", "0", "}", "\n", "cvid", "=", "1", "\n", "for", "qid", "in", "qdic", ".", "keys", "(", ")", ":", "\n", "# sequence to list", "\n", "        ", "q_str", "=", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "\n", "# create dict", "\n", "for", "w", "in", "q_list", ":", "\n", "            ", "if", "not", "vdict", ".", "has_key", "(", "w", ")", ":", "\n", "                ", "vdict", "[", "w", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "", "for", "c", "in", "list", "(", "w", ")", ":", "\n", "                ", "if", "not", "cdict", ".", "has_key", "(", "c", ")", ":", "\n", "                    ", "cdict", "[", "c", "]", "=", "cvid", "\n", "cvid", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.train_att_bc.make_vocab_files": [[178, 191], ["write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_question_char_vocab", "write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_answer_vocab"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.train_att_bc.make_question_char_vocab", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_answer_vocab"], ["\n", "", "", "", "", "return", "vdict", ",", "cdict", "\n", "\n", "", "def", "make_vocab_files", "(", ")", ":", "\n", "    ", "\"\"\"\n    Produce the question and answer vocabulary files.\n    \"\"\"", "\n", "write_log", "(", "'making question vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "write_log", "(", "'making question character vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "qdic", ",", "_", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "QUESTION_VOCAB_SPACE", ")", "\n", "question_vocab", ",", "question_char_vocab", "=", "make_question_vocab", "(", "qdic", ")", "\n", "write_log", "(", "'making answer vocab... '", "+", "config", ".", "ANSWER_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "_", ",", "adic", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "ANSWER_VOCAB_SPACE", ")", "\n", "answer_vocab", "=", "make_answer_vocab", "(", "adic", ",", "config", ".", "NUM_OUTPUT_UNITS", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.train_att_bc.main": [[193, 259], ["write_to_log.write_log", "write_to_log.write_log", "caffe.set_device", "caffe.set_mode_gpu", "caffe.get_solver", "numpy.zeros", "range", "os.path.exists", "os.makedirs", "os.path.exists", "os.path.exists", "write_to_log.write_log", "train_att_bc.make_vocab_files", "open", "f.write", "open", "f.write", "caffe.get_solver.step", "open", "json.load", "open", "json.load", "open", "json.dump", "open", "json.dump", "str", "str", "str", "str", "write_to_log.write_log", "write_to_log.write_log", "train_loss[].mean", "write_to_log.write_log", "caffe.get_solver.test_nets[].save", "write_to_log.write_log", "visualize_tools.exec_validation", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "train_att_bc.qlstm", "train_att_bc.qlstm", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_vocab_files", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.exec_validation", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["\n", "", "def", "main", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "'./result'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'./result'", ")", "\n", "\n", "", "question_vocab", ",", "answer_vocab", "=", "{", "}", ",", "{", "}", "\n", "if", "os", ".", "path", ".", "exists", "(", "'./result/cdict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/adict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/vdict.json'", ")", ":", "\n", "        ", "write_log", "(", "'restoring vocab'", ",", "'log.txt'", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_char_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "answer_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "=", "make_vocab_files", "(", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_char_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "answer_vocab", ",", "f", ")", "\n", "\n", "", "", "write_log", "(", "'question character vocab size: '", "+", "str", "(", "len", "(", "question_char_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'question vocab size: '", "+", "str", "(", "len", "(", "question_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'answer vocab size: '", "+", "str", "(", "len", "(", "answer_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "\n", "\n", "with", "open", "(", "'./result/proto_train.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "config", ".", "TRAIN_DATA_SPLITS", ",", "config", ".", "BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "with", "open", "(", "'./result/proto_test.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "'val'", ",", "config", ".", "VAL_BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "caffe", ".", "set_device", "(", "config", ".", "GPU_ID", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "solver", "=", "caffe", ".", "get_solver", "(", "'./qlstm_solver.prototxt'", ")", "\n", "\n", "train_loss", "=", "np", ".", "zeros", "(", "config", ".", "MAX_ITERATIONS", ")", "\n", "# results = []", "\n", "\n", "for", "it", "in", "range", "(", "config", ".", "MAX_ITERATIONS", ")", ":", "\n", "        ", "solver", ".", "step", "(", "1", ")", "\n", "\n", "# store the train loss", "\n", "train_loss", "[", "it", "]", "=", "solver", ".", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", "\n", "\n", "if", "it", "!=", "0", "and", "it", "%", "config", ".", "PRINT_INTERVAL", "==", "0", ":", "\n", "            ", "write_log", "(", "'------------------------------------'", ",", "'log.txt'", ")", "\n", "write_log", "(", "'Iteration: '", "+", "str", "(", "it", ")", ",", "'log.txt'", ")", "\n", "c_mean_loss", "=", "train_loss", "[", "it", "-", "config", ".", "PRINT_INTERVAL", ":", "it", "]", ".", "mean", "(", ")", "\n", "write_log", "(", "'Train loss: '", "+", "str", "(", "c_mean_loss", ")", ",", "'log.txt'", ")", "\n", "", "if", "it", "!=", "0", "and", "it", "%", "config", ".", "VALIDATE_INTERVAL", "==", "0", ":", "# acutually test", "\n", "            ", "solver", ".", "test_nets", "[", "0", "]", ".", "save", "(", "'./result/tmp.caffemodel'", ")", "\n", "write_log", "(", "'Validating...'", ",", "'log.txt'", ")", "\n", "test_loss", ",", "acc_overall", ",", "acc_per_ques", ",", "acc_per_ans", "=", "exec_validation", "(", "config", ".", "GPU_ID", ",", "'val'", ",", "it", "=", "it", ")", "\n", "write_log", "(", "'Iteration: '", "+", "str", "(", "it", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'Test loss: '", "+", "str", "(", "test_loss", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'Overall Accuracy: '", "+", "str", "(", "acc_overall", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'Per Question Type Accuracy is the following:'", ",", "'log.txt'", ")", "\n", "for", "quesType", "in", "acc_per_ques", ":", "\n", "                ", "write_log", "(", "\"%s : %.02f\"", "%", "(", "quesType", ",", "acc_per_ques", "[", "quesType", "]", ")", ",", "'log.txt'", ")", "\n", "", "write_log", "(", "'Per Answer Type Accuracy is the following:'", ",", "'log.txt'", ")", "\n", "for", "ansType", "in", "acc_per_ans", ":", "\n", "                ", "write_log", "(", "\"%s : %.02f\"", "%", "(", "ansType", ",", "acc_per_ans", "[", "ansType", "]", ")", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.visualize_tools.visualize_failures": [[27, 119], ["write_to_log.write_log", "visualize_tools.visualize_failures.save_qtype"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["def", "visualize_failures", "(", "stat_list", ",", "mode", ")", ":", "\n", "\n", "    ", "def", "save_qtype", "(", "qtype_list", ",", "save_filename", ",", "mode", ")", ":", "\n", "\n", "        ", "if", "mode", "==", "'val'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./eval'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/val2014'", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test-dev'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "elif", "mode", "==", "'test'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unsupported mode'", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "shutil", ".", "rmtree", "(", "savepath", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "os", ".", "makedirs", "(", "savepath", ")", "\n", "\n", "for", "qt", "in", "qtype_list", ":", "\n", "            ", "count", "=", "0", "\n", "for", "t_question", "in", "stat_list", ":", "\n", "#print count, t_question", "\n", "                ", "if", "count", "<", "40", "/", "len", "(", "qtype_list", ")", ":", "\n", "                    ", "t_question_list", "=", "t_question", "[", "'q_list'", "]", "\n", "saveflag", "=", "False", "\n", "#print 'debug****************************'", "\n", "#print qt", "\n", "#print t_question_list", "\n", "#print t_question_list[0] == qt[0]", "\n", "#print t_question_list[1] == qt[1]", "\n", "if", "t_question_list", "[", "0", "]", "==", "qt", "[", "0", "]", "and", "t_question_list", "[", "1", "]", "==", "qt", "[", "1", "]", ":", "\n", "                        ", "saveflag", "=", "True", "\n", "", "else", ":", "\n", "                        ", "saveflag", "=", "False", "\n", "\n", "", "if", "saveflag", "==", "True", ":", "\n", "                        ", "t_iid", "=", "t_question", "[", "'iid'", "]", "\n", "if", "mode", "==", "'val'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_val2014_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "", "elif", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_test2015_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "\n", "# for caption", "\n", "#print t_iid", "\n", "#annIds = caps.getAnnIds(t_iid)", "\n", "#anns = caps.loadAnns(annIds)", "\n", "#cap_list = [ann['caption'] for ann in anns]", "\n", "", "ans_list", "=", "t_question", "[", "'ans_list'", "]", "\n", "draw", "=", "ImageDraw", ".", "Draw", "(", "t_img", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ans_list", ")", ")", ":", "\n", "                            ", "try", ":", "\n", "                                ", "draw", ".", "text", "(", "(", "10", ",", "10", "*", "i", ")", ",", "str", "(", "ans_list", "[", "i", "]", ")", ")", "\n", "", "except", ":", "\n", "                                ", "pass", "\n", "\n", "", "", "ans", "=", "t_question", "[", "'answer'", "]", "\n", "pred", "=", "t_question", "[", "'pred'", "]", "\n", "if", "ans", "==", "-", "1", ":", "\n", "                            ", "pre", "=", "''", "\n", "", "elif", "ans", "==", "pred", ":", "\n", "                            ", "pre", "=", "'correct  '", "\n", "", "else", ":", "\n", "                            ", "pre", "=", "'failure  '", "\n", "#print ' aaa ', ans, pred", "\n", "", "ans", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "ans", ")", ")", "\n", "pred", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "pred", ")", ")", "\n", "img_title", "=", "pre", "+", "str", "(", "' '", ".", "join", "(", "t_question_list", ")", ")", "+", "'.  a_'", "+", "str", "(", "ans", ")", "+", "' p_'", "+", "str", "(", "pred", ")", "+", "'.png'", "\n", "count", "+=", "1", "\n", "write_log", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ",", "'visualize_log.txt'", ")", "\n", "t_img", ".", "save", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ")", "\n", "\n", "", "", "", "", "", "write_log", "(", "'saving colors'", ",", "'visualize_log.txt'", ")", "\n", "qt_color_list", "=", "[", "[", "'what'", ",", "'color'", "]", "]", "\n", "save_qtype", "(", "qt_color_list", ",", "'colors'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving what is'", ",", "'visualize_log.txt'", ")", "\n", "qt_whatis_list", "=", "[", "[", "'what'", ",", "'is'", "]", ",", "[", "'what'", ",", "'kind'", "]", ",", "[", "'what'", ",", "'are'", "]", "]", "\n", "save_qtype", "(", "qt_whatis_list", ",", "'whatis'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving is'", ",", "'visualize_log.txt'", ")", "\n", "qt_is_list", "=", "[", "[", "'is'", ",", "'the'", "]", ",", "[", "'is'", ",", "'this'", "]", ",", "[", "'is'", ",", "'there'", "]", "]", "\n", "save_qtype", "(", "qt_is_list", ",", "'is'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving how many'", ",", "'visualize_log.txt'", ")", "\n", "qt_howmany_list", "=", "[", "[", "'how'", ",", "'many'", "]", "]", "\n", "save_qtype", "(", "qt_howmany_list", ",", "'howmany'", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.visualize_tools.exec_validation": [[120, 200], ["caffe.set_device", "caffe.set_mode_gpu", "caffe.Net", "vqa_data_provider_layer.VQADataProvider", "len", "numpy.array().mean", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "vqa_data_provider_layer.VQADataProvider.get_batch_vec", "caffe.Net.forward", "caffe.Net.blobs[].data.argmax", "testloss_list.append", "zip", "vqaTools.vqa.VQA", "vqaTools.vqa.VQA.loadRes", "vqaEvaluation.vqaEval.VQAEval", "vqaEvaluation.vqaEval.VQAEval.evaluate", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "t_answer.tolist", "pred_list.append", "numpy.array", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "stat_list.append", "open", "json.dump", "visualize_tools.visualize_failures", "int", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "str().zfill", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "str().zfill", "xrange", "str", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.forward", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj"], ["", "def", "exec_validation", "(", "device_id", ",", "mode", ",", "it", "=", "''", ",", "visualize", "=", "False", ")", ":", "\n", "\n", "    ", "caffe", ".", "set_device", "(", "device_id", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "net", "=", "caffe", ".", "Net", "(", "'./result/proto_test.prototxt'", ",", "'./result/tmp.caffemodel'", ",", "caffe", ".", "TEST", ")", "\n", "\n", "dp", "=", "VQADataProvider", "(", "mode", "=", "mode", ",", "batchsize", "=", "config", ".", "VAL_BATCH_SIZE", ")", "\n", "total_questions", "=", "len", "(", "dp", ".", "getQuesIds", "(", ")", ")", "\n", "epoch", "=", "0", "\n", "\n", "pred_list", "=", "[", "]", "\n", "testloss_list", "=", "[", "]", "\n", "stat_list", "=", "[", "]", "\n", "\n", "while", "epoch", "==", "0", ":", "\n", "        ", "t_word", ",", "t_cont", ",", "t_word_c", ",", "t_cont_c", ",", "t_img_feature", ",", "t_answer", ",", "t_qid_list", ",", "t_iid_list", ",", "epoch", "=", "dp", ".", "get_batch_vec", "(", ")", "\n", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "...", "]", "=", "t_word", "# np.transpose(t_word,(1,0))", "\n", "net", ".", "blobs", "[", "'cont'", "]", ".", "data", "[", "...", "]", "=", "t_cont", "# np.transpose(t_cont,(1,0))", "\n", "net", ".", "blobs", "[", "'data1'", "]", ".", "data", "[", "...", "]", "=", "t_word_c", "\n", "net", ".", "blobs", "[", "'cont1'", "]", ".", "data", "[", "...", "]", "=", "t_cont_c", "\n", "net", ".", "blobs", "[", "'img_feature'", "]", ".", "data", "[", "...", "]", "=", "t_img_feature", "\n", "net", ".", "blobs", "[", "'label'", "]", ".", "data", "[", "...", "]", "=", "t_answer", "\n", "#net.blobs['glove'].data[...] = t_glove_matrix # np.transpose(t_glove_matrix, (1,0,2))", "\n", "net", ".", "forward", "(", ")", "\n", "t_pred_list", "=", "net", ".", "blobs", "[", "'prediction'", "]", ".", "data", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "t_pred_str", "=", "[", "dp", ".", "vec_to_answer", "(", "pred_symbol", ")", "for", "pred_symbol", "in", "t_pred_list", "]", "\n", "testloss_list", ".", "append", "(", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", ")", "\n", "for", "qid", ",", "iid", ",", "ans", ",", "pred", "in", "zip", "(", "t_qid_list", ",", "t_iid_list", ",", "t_answer", ".", "tolist", "(", ")", ",", "t_pred_str", ")", ":", "\n", "            ", "pred_list", ".", "append", "(", "{", "u'answer'", ":", "pred", ",", "u'question_id'", ":", "int", "(", "dp", ".", "getStrippedQuesId", "(", "qid", ")", ")", "}", ")", "\n", "if", "visualize", ":", "\n", "                ", "q_list", "=", "dp", ".", "seq_to_list", "(", "dp", ".", "getQuesStr", "(", "qid", ")", ")", "\n", "if", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                    ", "ans_str", "=", "''", "\n", "ans_list", "=", "[", "''", "]", "*", "10", "\n", "", "else", ":", "\n", "                    ", "ans_str", "=", "dp", ".", "vec_to_answer", "(", "ans", ")", "\n", "ans_list", "=", "[", "dp", ".", "getAnsObj", "(", "qid", ")", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "", "stat_list", ".", "append", "(", "{", "'qid'", ":", "qid", ",", "\n", "'q_list'", ":", "q_list", ",", "\n", "'iid'", ":", "iid", ",", "\n", "'answer'", ":", "ans_str", ",", "\n", "'ans_list'", ":", "ans_list", ",", "\n", "'pred'", ":", "pred", "}", ")", "\n", "#percent = 100 * float(len(pred_list)) / total_questions", "\n", "#sys.stdout.write('\\r' + ('%.2f' % percent) + '%')", "\n", "#sys.stdout.flush()", "\n", "\n", "\n", "\n", "", "", "", "mean_testloss", "=", "np", ".", "array", "(", "testloss_list", ")", ".", "mean", "(", ")", "\n", "\n", "if", "mode", "==", "'val'", ":", "\n", "        ", "valFile", "=", "'./result/val2014_resfile'", "\n", "with", "open", "(", "valFile", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "annFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ans_file'", "]", "\n", "quesFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ques_file'", "]", "\n", "vqa", "=", "VQA", "(", "annFile", ",", "quesFile", ")", "\n", "vqaRes", "=", "vqa", ".", "loadRes", "(", "valFile", ",", "quesFile", ")", "\n", "vqaEval", "=", "VQAEval", "(", "vqa", ",", "vqaRes", ",", "n", "=", "2", ")", "\n", "vqaEval", ".", "evaluate", "(", ")", "\n", "acc_overall", "=", "vqaEval", ".", "accuracy", "[", "'overall'", "]", "\n", "acc_perQuestionType", "=", "vqaEval", ".", "accuracy", "[", "'perQuestionType'", "]", "\n", "acc_perAnswerType", "=", "vqaEval", ".", "accuracy", "[", "'perAnswerType'", "]", "\n", "return", "mean_testloss", ",", "acc_overall", ",", "acc_perQuestionType", ",", "acc_perAnswerType", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test-dev2015_v3t'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "", "elif", "mode", "==", "'test'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test2015_v3c'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Deep Residual.visualize_tools.drawgraph": [[201, 269], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.twinx", "fig.add_subplot.plot", "fig.add_subplot.plot", "ax1.twinx.plot", "matplotlib.legend", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "ax1.twinx.set_ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "numpy.array", "numpy.array", "matplotlib.figure", "matplotlib.legend", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "sorted", "visualize_tools.drawgraph.draw_qt_acc"], "function", ["None"], ["            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "\n", "", "", "", "def", "drawgraph", "(", "results", ",", "save_question_type_graphs", "=", "False", ")", ":", "\n", "# 0:it", "\n", "# 1:trainloss", "\n", "# 2:testloss", "\n", "# 3:oa_acc", "\n", "# 4:qt_acc", "\n", "# 5:at_acc", "\n", "\n", "# training curve", "\n", "    ", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "loss", "=", "np", ".", "array", "(", "[", "l", "[", "1", "]", "for", "l", "in", "results", "]", ")", "\n", "valloss", "=", "np", ".", "array", "(", "[", "l", "[", "2", "]", "for", "l", "in", "results", "]", ")", "\n", "valacc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax1", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "ax2", "=", "ax1", ".", "twinx", "(", ")", "\n", "\n", "ax1", ".", "plot", "(", "it", ",", "loss", ",", "color", "=", "'blue'", ",", "label", "=", "'train loss'", ")", "\n", "ax1", ".", "plot", "(", "it", ",", "valloss", ",", "'--'", ",", "color", "=", "'blue'", ",", "label", "=", "'test loss'", ")", "\n", "ax2", ".", "plot", "(", "it", ",", "valacc", ",", "color", "=", "'red'", ",", "label", "=", "'acc on val'", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'lower left'", ")", "\n", "\n", "ax1", ".", "set_xlabel", "(", "'Iterations'", ")", "\n", "ax1", ".", "set_ylabel", "(", "'Loss Value'", ")", "\n", "ax2", ".", "set_ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "'./learning_curve max_%2.2f.png'", "%", "valacc", ".", "max", "(", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "# question type", "\n", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "oa_acc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "qt_dic_list", "=", "[", "l", "[", "4", "]", "for", "l", "in", "results", "]", "\n", "\n", "def", "draw_qt_acc", "(", "target_key_list", ",", "figname", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "for", "k", "in", "target_key_list", ":", "\n", "            ", "write_log", "(", "str", "(", "k", ")", "+", "str", "(", "type", "(", "k", ")", ")", ",", "'visualize_log.txt'", ")", "\n", "t_val", "=", "np", ".", "array", "(", "[", "qt_dic", "[", "k", "]", "for", "qt_dic", "in", "qt_dic_list", "]", ")", "\n", "plt", ".", "plot", "(", "it", ",", "t_val", ",", "label", "=", "str", "(", "k", ")", ")", "\n", "", "plt", ".", "legend", "(", "fontsize", "=", "'small'", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "100.", ")", "\n", "#plt.legend(prop={'size':6})", "\n", "\n", "plt", ".", "xlabel", "(", "'Iterations'", ")", "\n", "plt", ".", "ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "figname", ",", "dpi", "=", "200", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "", "if", "save_question_type_graphs", ":", "\n", "        ", "s_keys", "=", "sorted", "(", "qt_dic_list", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "0", ":", "13", "]", "+", "[", "s_keys", "[", "31", "]", ",", "]", ",", "'./ind_qt_are.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "13", ":", "17", "]", "+", "s_keys", "[", "49", ":", "]", ",", "'./ind_qt_how_where_who_why.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "17", ":", "31", "]", "+", "[", "s_keys", "[", "32", "]", ",", "]", ",", "'./ind_qt_is.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "33", ":", "49", "]", ",", "'./ind_qt_what.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what color is the'", ",", "'what color are the'", ",", "'what color is'", ",", "'what color'", ",", "'what is the color of the'", "]", ",", "'./qt_color.png'", ")", "\n", "draw_qt_acc", "(", "[", "'how many'", ",", "'how'", ",", "'how many people are'", ",", "'how many people are in'", "]", ",", "'./qt_number.png'", ")", "\n", "draw_qt_acc", "(", "[", "'who is'", ",", "'why'", ",", "'why is the'", ",", "'where is the'", ",", "'where are the'", ",", "'which'", "]", ",", "'./qt_who_why_where_which.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what is the man'", ",", "'is the man'", ",", "'are they'", ",", "'is he'", ",", "'is the woman'", ",", "'is this person'", ",", "'what is the woman'", ",", "'is the person'", ","]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.write_to_log.write_log": [[1, 4], ["open", "f.write"], "function", ["None"], ["def", "write_log", "(", "str", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "+", "\"\\n\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.__init__": [[13, 30], ["vqa_data_provider_layer.VQADataProvider.load_data", "len", "open", "json.load", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data"], ["    ", "def", "__init__", "(", "self", ",", "batchsize", "=", "64", ",", "max_length", "=", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "max_w_length", "=", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "batchsize", "\n", "self", ".", "d_vocabulary", "=", "None", "\n", "self", ".", "batch_index", "=", "None", "\n", "self", ".", "batch_len", "=", "None", "\n", "self", ".", "rev_adict", "=", "None", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "max_w_length", "=", "max_w_length", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "qdic", ",", "self", ".", "adic", "=", "VQADataProvider", ".", "load_data", "(", "mode", ")", "\n", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "cdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "vdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "adict", "=", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.load_vqa_json": [[33, 56], ["write_to_log.write_log", "open", "json.load", "open", "json.load", "str", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["#self.glove_dict = {} # word -> glove vector", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_vqa_json", "(", "data_split", ")", ":", "\n", "        ", "\"\"\"\n        Parses the question and answer json files for the given data split. \n        Returns the question dictionary and the answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ques_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "[", "'questions'", "]", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "qdic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'question_id'", "]", ")", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image_id'", "]", "}", "\n", "\n", "", "", "if", "'test'", "not", "in", "data_split", ":", "\n", "            ", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ans_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "adata", "=", "json", ".", "load", "(", "f", ")", "[", "'annotations'", "]", "\n", "for", "a", "in", "adata", ":", "\n", "                    ", "adic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "a", "[", "'question_id'", "]", ")", "]", "=", "a", "[", "'answers'", "]", "\n", "\n", "", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for '", "+", "data_split", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.load_genome_json": [[57, 74], ["write_to_log.write_log", "open", "json.load", "str", "str", "len"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_genome_json", "(", ")", ":", "\n", "        ", "\"\"\"\n        Parses the genome json file. Returns the question dictionary and the\n        answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'genome_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "key", "=", "'genome'", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'id'", "]", ")", "\n", "qdic", "[", "key", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image'", "]", "}", "\n", "adic", "[", "key", "]", "=", "[", "{", "'answer'", ":", "q", "[", "'answer'", "]", "}", "]", "\n", "\n", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for genome'", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.load_data": [[75, 101], ["data_split_str.split", "config.DATA_PATHS.keys", "vqa_data_provider_layer.VQADataProvider.load_genome_json", "all_qdic.update", "all_adic.update", "vqa_data_provider_layer.VQADataProvider.load_vqa_json", "all_qdic.update", "all_adic.update"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_genome_json", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_vqa_json"], ["return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_data", "(", "data_split_str", ")", ":", "\n", "        ", "all_qdic", ",", "all_adic", "=", "{", "}", ",", "{", "}", "\n", "for", "data_split", "in", "data_split_str", ".", "split", "(", "'+'", ")", ":", "\n", "            ", "assert", "data_split", "in", "config", ".", "DATA_PATHS", ".", "keys", "(", ")", ",", "'unknown data split'", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_genome_json", "(", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "", "else", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_vqa_json", "(", "data_split", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "\n", "", "", "return", "all_qdic", ",", "all_adic", "\n", "\n", "", "def", "getQuesIds", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "qdic", ".", "keys", "(", ")", "\n", "\n", "", "def", "getStrippedQuesId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "[", "1", "]", "\n", "\n", "", "def", "getImgId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'iid'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.getQuesIds": [[102, 104], ["vqa_data_provider_layer.VQADataProvider.qdic.keys"], "methods", ["None"], ["", "def", "getQuesStr", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.getStrippedQuesId": [[105, 107], ["qid.split"], "methods", ["None"], ["", "def", "getAnsObj", "(", "self", ",", "qid", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.getImgId": [[108, 110], ["None"], "methods", ["None"], ["", "return", "self", ".", "adic", "[", "qid", "]", "\n", "\n", "", "@", "staticmethod", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.getQuesStr": [[111, 113], ["None"], "methods", ["None"], ["def", "seq_to_list", "(", "s", ")", ":", "\n", "        ", "t_str", "=", "s", ".", "lower", "(", ")", "\n", "for", "i", "in", "[", "r'\\?'", ",", "r'\\!'", ",", "r'\\''", ",", "r'\\\"'", ",", "r'\\$'", ",", "r'\\:'", ",", "r'\\@'", ",", "r'\\('", ",", "r'\\)'", ",", "r'\\,'", ",", "r'\\.'", ",", "r'\\;'", "]", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.getAnsObj": [[114, 118], ["None"], "methods", ["None"], ["            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "''", ",", "t_str", ")", "\n", "", "for", "i", "in", "[", "r'\\-'", ",", "r'\\/'", "]", ":", "\n", "            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "' '", ",", "t_str", ")", "\n", "", "q_list", "=", "re", ".", "sub", "(", "r'\\?'", ",", "''", ",", "t_str", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "\n", "q_list", "=", "filter", "(", "lambda", "x", ":", "len", "(", "x", ")", ">", "0", ",", "q_list", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.seq_to_list": [[119, 129], ["s.lower", "re.sub().split", "filter", "re.sub", "re.sub", "re.sub", "re.sub.lower", "len"], "methods", ["None"], ["return", "q_list", "\n", "\n", "", "def", "extract_answer", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "", "answer_list", "=", "[", "answer_obj", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "dic", "=", "{", "}", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "dic", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "dic", "[", "ans", "]", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.extract_answer": [[130, 143], ["dic.has_key", "max", "xrange", "dic.items"], "methods", ["None"], ["", "else", ":", "\n", "                ", "dic", "[", "ans", "]", "=", "1", "\n", "", "", "max_key", "=", "max", "(", "(", "v", ",", "k", ")", "for", "(", "k", ",", "v", ")", "in", "dic", ".", "items", "(", ")", ")", "[", "1", "]", "\n", "return", "max_key", "\n", "\n", "", "def", "extract_answer_prob", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "prob_answer_list", "=", "[", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.extract_answer_prob": [[144, 162], ["vqa_data_provider_layer.VQADataProvider.adict.has_key", "len", "random.choice", "prob_answer_list.append", "Exception"], "methods", ["None"], ["                ", "prob_answer_list", ".", "append", "(", "ans", ")", "\n", "\n", "", "", "if", "len", "(", "prob_answer_list", ")", "==", "0", ":", "\n", "            ", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "return", "'hoge'", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"This should not happen.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "random", ".", "choice", "(", "prob_answer_list", ")", "\n", "\n", "# def qlist_to_vec(self, max_length, q_list):", "\n", "#     \"\"\"", "\n", "#     Converts a list of words into a format suitable for the embedding layer.", "\n", "\n", "#     Arguments:", "\n", "#     max_length -- the maximum length of a question sequence", "\n", "#     q_list -- a list of words which are the tokens in the question", "\n", "\n", "#     Returns:", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.qlist_to_vec": [[163, 208], ["numpy.zeros", "numpy.zeros", "xrange", "len", "vqa_data_provider_layer.VQADataProvider.vdict.has_key", "len"], "methods", ["None"], ["#     qvec -- A max_length length vector containing one-hot indices for each word", "\n", "#     cvec -- A max_length length sequence continuation indicator vector", "\n", "#     glove_matrix -- A max_length x GLOVE_EMBEDDING_SIZE matrix containing the glove embedding for", "\n", "#         each word", "\n", "#     \"\"\"", "\n", "#     qvec = np.zeros(max_length)", "\n", "#     cvec = np.zeros(max_length)", "\n", "#     glove_matrix = np.zeros(max_length * GLOVE_EMBEDDING_SIZE).reshape(max_length, GLOVE_EMBEDDING_SIZE)", "\n", "#     for i in xrange(max_length):", "\n", "#         if i < max_length - len(q_list):", "\n", "#             cvec[i] = 0", "\n", "#         else:", "\n", "#             w = q_list[i-(max_length-len(q_list))]", "\n", "#             if w not in self.glove_dict:", "\n", "#                 self.glove_dict[w] = self.nlp(u'%s' % w).vector", "\n", "#             glove_matrix[i] = self.glove_dict[w]", "\n", "#             # is the word in the vocabulary?", "\n", "#             if self.vdict.has_key(w) is False:", "\n", "#                 w = ''", "\n", "#             qvec[i] = self.vdict[w]", "\n", "#             cvec[i] = 1 #0 if i == max_length - len(q_list) else 1", "\n", "#             # UPDATE_10/12:", "\n", "#             #It seems that the original way is right for lstm.", "\n", "#             '''", "\n", "#             This is from https://github.com/BVLC/caffe/pull/1873.", "\n", "#             \"delta_{t,n} should be a binary indicator (i.e., value in {0, 1}),", "\n", "#             where a value of 0 means that timestep t of stream n is the beginning of a new sequence,", "\n", "#             and a value of 1 means that timestep t of stream n is continuing the sequence from timestep t-1 of stream n.", "\n", "#             Under the hood, the previous timestep's hidden state is multiplied by these delta values.", "\n", "#             The fact that these indicators are specified on a per-timestep and per-stream basis allows for streams of arbitrary different lengths without any padding or truncation.", "\n", "#             At the beginning of the forward pass, the final hidden state from the previous forward pass (h_T) is copied into the initial hidden state for the new forward pass (h_0),", "\n", "#             allowing for exact inference across arbitrarily long sequences, even if T == 1.", "\n", "#             However, if any sequences cross batch boundaries, backpropagation through time is approximate -- it is truncated along the batch boundaries.\"", "\n", "#             '''", "\n", "#             # I think the original way is false for CNN here. I want to keep the word embedding for unknown word as zero vector.", "\n", "#             # For example, if we have a sentence of length 7, there would be only 6 1's in cvec.", "\n", "\n", "#     return qvec, cvec, glove_matrix", "\n", "\n", "", "", "def", "qlist_to_vec", "(", "self", ",", "max_length", ",", "max_w_length", ",", "q_list", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.answer_to_vec": [[209, 219], ["vqa_data_provider_layer.VQADataProvider.adict.has_key"], "methods", ["None"], ["\n", "qvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "cvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "qcvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.vec_to_answer": [[220, 229], ["vqa_data_provider_layer.VQADataProvider.adict.items"], "methods", ["None"], ["ccvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "for", "i", "in", "xrange", "(", "max_length", ")", ":", "\n", "            ", "if", "i", "<", "max_length", "-", "len", "(", "q_list", ")", ":", "\n", "                ", "cvec", "[", "i", "]", "=", "0", "\n", "", "else", ":", "\n", "                ", "w", "=", "q_list", "[", "i", "-", "(", "max_length", "-", "len", "(", "q_list", ")", ")", "]", "\n", "# is the word in the vocabulary?", "\n", "if", "self", ".", "vdict", ".", "has_key", "(", "w", ")", "is", "False", ":", "\n", "                    ", "w", "=", "''", "\n", "", "qvec", "[", "i", "]", "=", "self", ".", "vdict", "[", "w", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.create_batch": [[230, 277], ["numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "enumerate", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "vqa_data_provider_layer.VQADataProvider.answer_to_vec", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "qid.split", "vqa_data_provider_layer.VQADataProvider.extract_answer", "vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "numpy.sqrt", "write_to_log.write_log", "numpy.load", "numpy.load", "str", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.answer_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["cvec", "[", "i", "]", "=", "1.0", "/", "len", "(", "q_list", ")", "\n", "j", "=", "max_w_length", "*", "i", "\n", "w_list", "=", "list", "(", "w", ")", "\n", "for", "k", "in", "xrange", "(", "max_w_length", ")", ":", "\n", "                    ", "if", "k", "<", "max_w_length", "-", "len", "(", "w_list", ")", ":", "\n", "                        ", "ccvec", "[", "j", "+", "k", "]", "=", "0", "\n", "", "else", ":", "\n", "                        ", "c", "=", "w_list", "[", "k", "-", "(", "max_w_length", "-", "len", "(", "w_list", ")", ")", "]", "\n", "# is the char in the vocabulary?", "\n", "if", "self", ".", "cdict", ".", "has_key", "(", "c", ")", "is", "False", ":", "\n", "                            ", "c", "=", "''", "\n", "", "qcvec", "[", "j", "+", "k", "]", "=", "self", ".", "cdict", "[", "c", "]", "\n", "ccvec", "[", "j", "+", "k", "]", "=", "1.0", "/", "len", "(", "w_list", ")", "\n", "", "", "", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", "\n", "\n", "", "def", "answer_to_vec", "(", "self", ",", "ans_str", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "if", "self", ".", "adict", ".", "has_key", "(", "ans_str", ")", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "ans_str", "]", "\n", "", "else", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "''", "]", "\n", "", "return", "ans", "\n", "\n", "", "def", "vec_to_answer", "(", "self", ",", "ans_symbol", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "rev_adict", "is", "None", ":", "\n", "            ", "rev_adict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "adict", ".", "items", "(", ")", ":", "\n", "                ", "rev_adict", "[", "v", "]", "=", "k", "\n", "", "self", ".", "rev_adict", "=", "rev_adict", "\n", "\n", "", "return", "self", ".", "rev_adict", "[", "ans_symbol", "]", "\n", "\n", "", "def", "create_batch", "(", "self", ",", "qid_list", ")", ":", "\n", "\n", "        ", "qvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "cvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "qcvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ccvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ivec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "2048", "*", "14", "*", "14", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "2048", ",", "14", ",", "14", ")", "\n", "avec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ")", "\n", "#glove_matrix = np.zeros(self.batchsize * self.max_length * GLOVE_EMBEDDING_SIZE).reshape(\\", "\n", "#self.batchsize, self.max_length, GLOVE_EMBEDDING_SIZE)", "\n", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProvider.get_batch_vec": [[279, 326], ["vqa_data_provider_layer.VQADataProvider.create_batch", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "random.shuffle", "len", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.adict.has_key", "t_qid_list.append", "t_iid_list.append", "vqa_data_provider_layer.VQADataProvider.get_batch_vec.has_at_least_one_valid_answer"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.create_batch", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId"], ["# load raw question information", "\n", "            ", "q_str", "=", "self", ".", "getQuesStr", "(", "qid", ")", "\n", "q_ans", "=", "self", ".", "getAnsObj", "(", "qid", ")", "\n", "q_iid", "=", "self", ".", "getImgId", "(", "qid", ")", "\n", "\n", "# convert question to vec", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "t_qvec", ",", "t_cvec", ",", "t_qcvec", ",", "t_ccvec", "=", "self", ".", "qlist_to_vec", "(", "self", ".", "max_length", ",", "self", ".", "max_w_length", ",", "q_list", ")", "\n", "\n", "try", ":", "\n", "                ", "qid_split", "=", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "\n", "data_split", "=", "qid_split", "[", "0", "]", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "else", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "t_ivec", "=", "(", "t_ivec", "/", "np", ".", "sqrt", "(", "(", "t_ivec", "**", "2", ")", ".", "sum", "(", ")", ")", ")", "\n", "", "except", ":", "\n", "                ", "t_ivec", "=", "0.", "\n", "write_log", "(", "'data not found for qid : '", "+", "str", "(", "q_iid", ")", "+", "' '", "+", "self", ".", "mode", ",", "'log.txt'", ")", "\n", "\n", "# convert answer to vec", "\n", "", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer", "(", "q_ans", ")", "\n", "", "else", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer_prob", "(", "q_ans", ")", "\n", "", "t_avec", "=", "self", ".", "answer_to_vec", "(", "q_ans_str", ")", "\n", "\n", "qvec", "[", "i", ",", "...", "]", "=", "t_qvec", "\n", "cvec", "[", "i", ",", "...", "]", "=", "t_cvec", "\n", "qcvec", "[", "i", ",", "...", "]", "=", "t_qcvec", "\n", "ccvec", "[", "i", ",", "...", "]", "=", "t_ccvec", "\n", "ivec", "[", "i", ",", "...", "]", "=", "t_ivec", "\n", "avec", "[", "i", ",", "...", "]", "=", "t_avec", "\n", "#glove_matrix[i,...] = t_glove_matrix", "\n", "\n", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", ",", "ivec", ",", "avec", "#, glove_matrix", "\n", "\n", "\n", "", "def", "get_batch_vec", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "batch_len", "is", "None", ":", "\n", "            ", "self", ".", "n_skipped", "=", "0", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_len", "=", "len", "(", "qid_list", ")", "\n", "self", ".", "batch_index", "=", "0", "\n", "self", ".", "epoch_counter", "=", "0", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProviderLayer.setup": [[333, 348], ["top[].reshape", "top[].reshape", "top[].reshape", "top[].reshape", "json.loads", "json.loads", "vqa_data_provider_layer.VQADataProvider"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape"], ["                    ", "return", "True", "\n", "\n", "", "", "", "counter", "=", "0", "\n", "t_qid_list", "=", "[", "]", "\n", "t_iid_list", "=", "[", "]", "\n", "while", "counter", "<", "self", ".", "batchsize", ":", "\n", "            ", "t_qid", "=", "self", ".", "qid_list", "[", "self", ".", "batch_index", "]", "\n", "t_iid", "=", "self", ".", "getImgId", "(", "t_qid", ")", "\n", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n", "", "elif", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProviderLayer.reshape": [[349, 351], ["None"], "methods", ["None"], ["", "else", ":", "\n", "                ", "self", ".", "n_skipped", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProviderLayer.forward": [[352, 362], ["vqa_data_provider_layer.VQADataProviderLayer.dp.get_batch_vec"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec"], ["", "if", "self", ".", "batch_index", "<", "self", ".", "batch_len", "-", "1", ":", "\n", "                ", "self", ".", "batch_index", "+=", "1", "\n", "", "else", ":", "\n", "                ", "self", ".", "epoch_counter", "+=", "1", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_index", "=", "0", "\n", "write_log", "(", "\"%d questions were skipped in a single epoch\"", "%", "self", ".", "n_skipped", ",", "'log.txt'", ")", "\n", "self", ".", "n_skipped", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.vqa_data_provider_layer.VQADataProviderLayer.backward": [[364, 366], ["None"], "methods", ["None"], ["return", "t_batch", "+", "(", "t_qid_list", ",", "t_iid_list", ",", "self", ".", "epoch_counter", ")", "\n", "\n", "", "", "class", "VQADataProviderLayer", "(", "caffe", ".", "Layer", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.train_att_bc.qlstm": [[19, 105], ["caffe.NetSpec", "json.dumps", "caffe.layers.Python", "caffe.layers.Embed", "caffe.layers.Scale", "caffe.layers.Reshape", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Convolution", "caffe.layers.Sigmoid", "caffe.layers.Sigmoid", "caffe.layers.Sigmoid", "caffe.layers.Sigmoid", "caffe.layers.Eltwise", "caffe.layers.Eltwise", "caffe.layers.Eltwise", "caffe.layers.Eltwise", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Pooling", "caffe.layers.Concat", "caffe.layers.Dropout", "caffe.layers.Tile", "caffe.layers.Tile", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.Reshape", "caffe.layers.Softmax", "caffe.layers.Reshape", "caffe.layers.Slice", "caffe.layers.DummyData", "caffe.layers.SoftAttention", "caffe.layers.SoftAttention", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Concat", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Reshape", "caffe.layers.InnerProduct", "caffe.layers.SoftmaxWithLoss", "caffe.NetSpec.to_proto", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "config.TRAIN_DATA_SPLITS", "config.BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION", "config.VAL_BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION"], "function", ["None"], ["def", "qlstm", "(", "mode", ",", "batchsize", ",", "T", ",", "T_c", ",", "question_c_vocab_size", ",", "question_vocab_size", ")", ":", "\n", "    ", "n", "=", "caffe", ".", "NetSpec", "(", ")", "\n", "mode_str", "=", "json", ".", "dumps", "(", "{", "'mode'", ":", "mode", ",", "'batchsize'", ":", "batchsize", "}", ")", "\n", "n", ".", "data", ",", "n", ".", "cont", ",", "n", ".", "data1", ",", "n", ".", "cont1", ",", "n", ".", "img_feature", ",", "n", ".", "label", "=", "L", ".", "Python", "(", "module", "=", "'vqa_data_provider_layer'", ",", "layer", "=", "'VQADataProviderLayer'", ",", "param_str", "=", "mode_str", ",", "ntop", "=", "6", ")", "#5 )", "\n", "\n", "# char embedding", "\n", "n", ".", "embed_c", "=", "L", ".", "Embed", "(", "n", ".", "data1", ",", "input_dim", "=", "question_c_vocab_size", ",", "num_output", "=", "100", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "\n", "n", ".", "embed_c_scale", "=", "L", ".", "Scale", "(", "n", ".", "embed_c", ",", "n", ".", "cont1", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "\n", "n", ".", "embed_c_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_c_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T_c", "*", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T_c*T x d_c x 1", "\n", "tops", "=", "L", ".", "Slice", "(", "n", ".", "embed_c_scale_resh", ",", "ntop", "=", "T", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T_c x d_c x 1", "\n", "for", "i", "in", "xrange", "(", "T", ")", ":", "\n", "        ", "n", ".", "__setattr__", "(", "'Slice_'", "+", "str", "(", "i", "+", "1", ")", ",", "tops", "[", "int", "(", "i", ")", "]", ")", "\n", "\n", "# avg of char embedding", "\n", "", "n", ".", "c_embed_1", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_1", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_2", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_2", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_3", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_3", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_4", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_4", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_5", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_5", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_6", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_6", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_7", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_7", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_8", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_8", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_9", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_9", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_10", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_10", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_11", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_11", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_12", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_12", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_13", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_13", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_14", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_14", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_15", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_15", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_16", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_16", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_17", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_17", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_18", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_18", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_19", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_19", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_20", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_20", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_21", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_21", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_22", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_22", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "\n", "concat_c_embed", "=", "[", "n", ".", "c_embed_1", ",", "n", ".", "c_embed_2", ",", "n", ".", "c_embed_3", ",", "n", ".", "c_embed_4", ",", "n", ".", "c_embed_5", ",", "n", ".", "c_embed_6", ",", "n", ".", "c_embed_7", ",", "n", ".", "c_embed_8", ",", "n", ".", "c_embed_9", ",", "n", ".", "c_embed_10", ",", "n", ".", "c_embed_11", ",", "n", ".", "c_embed_12", ",", "n", ".", "c_embed_13", ",", "n", ".", "c_embed_14", ",", "n", ".", "c_embed_15", ",", "n", ".", "c_embed_16", ",", "n", ".", "c_embed_17", ",", "n", ".", "c_embed_18", ",", "n", ".", "c_embed_19", ",", "n", ".", "c_embed_20", ",", "n", ".", "c_embed_21", ",", "n", ".", "c_embed_22", "]", "\n", "n", ".", "concat_char_embed", "=", "L", ".", "Concat", "(", "*", "concat_c_embed", ",", "concat_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T x d_c x 1", "\n", "n", ".", "concat_char_embed_resh", "=", "L", ".", "Reshape", "(", "n", ".", "concat_char_embed", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", "]", ")", ")", ")", "\n", "\n", "# word embedding", "\n", "n", ".", "embed_w", "=", "L", ".", "Embed", "(", "n", ".", "data", ",", "input_dim", "=", "question_vocab_size", ",", "num_output", "=", "200", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "# N x T x d_w", "\n", "\n", "# combine word and char embedding", "\n", "concat_word_embed", "=", "[", "n", ".", "embed_w", ",", "n", ".", "concat_char_embed_resh", "]", "\n", "n", ".", "concat_embed", "=", "L", ".", "Concat", "(", "*", "concat_word_embed", ",", "concat_param", "=", "{", "'axis'", ":", "2", "}", ")", "# N x T x (d_c+d_w)", "\n", "\n", "n", ".", "embed_scale", "=", "L", ".", "Scale", "(", "n", ".", "concat_embed", ",", "n", ".", "cont", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "# N x T x (d_c+d_w)", "\n", "n", ".", "embed_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T x (d_c+d_w) x 1", "\n", "\n", "# avg of word embedding", "\n", "n", ".", "embed_avg", "=", "L", ".", "Convolution", "(", "n", ".", "embed_scale_resh", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x (d_c+d_w) x 1", "\n", "n", ".", "embed_avg_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_avg", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "300", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled_1", "=", "L", ".", "Tile", "(", "n", ".", "embed_avg_resh", ",", "axis", "=", "2", ",", "tiles", "=", "14", ")", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled", "=", "L", ".", "Tile", "(", "n", ".", "q_emb_tanh_droped_resh_tiled_1", ",", "axis", "=", "3", ",", "tiles", "=", "14", ")", "\n", "n", ".", "i_emb_tanh_droped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "img_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "n", ".", "blcf", "=", "L", ".", "CompactBilinear", "(", "n", ".", "q_emb_tanh_droped_resh_tiled", ",", "n", ".", "i_emb_tanh_droped_resh", ",", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "blcf_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "blcf", ")", "\n", "n", ".", "blcf_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "blcf_sign_sqrt", ")", "\n", "n", ".", "blcf_droped", "=", "L", ".", "Dropout", "(", "n", ".", "blcf_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "\n", "# multi-channel attention", "\n", "n", ".", "att_conv1", "=", "L", ".", "Convolution", "(", "n", ".", "blcf_droped", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "512", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_conv1_relu", "=", "L", ".", "ReLU", "(", "n", ".", "att_conv1", ")", "\n", "n", ".", "att_conv2", "=", "L", ".", "Convolution", "(", "n", ".", "att_conv1_relu", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "2", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_reshaped", "=", "L", ".", "Reshape", "(", "n", ".", "att_conv2", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", "*", "14", "]", ")", ")", ")", "\n", "n", ".", "att_softmax", "=", "L", ".", "Softmax", "(", "n", ".", "att_reshaped", ",", "axis", "=", "2", ")", "\n", "n", ".", "att", "=", "L", ".", "Reshape", "(", "n", ".", "att_softmax", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "att_maps", "=", "L", ".", "Slice", "(", "n", ".", "att", ",", "ntop", "=", "2", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "\n", "n", ".", "att_map0", "=", "att_maps", "[", "0", "]", "\n", "n", ".", "att_map1", "=", "att_maps", "[", "1", "]", "\n", "dummy", "=", "L", ".", "DummyData", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "1", "]", ")", ",", "data_filler", "=", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", ",", "ntop", "=", "1", ")", "\n", "n", ".", "att_feature0", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map0", ",", "dummy", ")", "\n", "n", ".", "att_feature1", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map1", ",", "dummy", ")", "\n", "n", ".", "att_feature0_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature0", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature1_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature1", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature", "=", "L", ".", "Concat", "(", "n", ".", "att_feature0_resh", ",", "n", ".", "att_feature1_resh", ")", "\n", "\n", "# merge attention and lstm with compact bilinear pooling", "\n", "n", ".", "att_feature_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "4096", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "#n.lstm_12_resh = L.Reshape(n.lstm_12, reshape_param=dict(shape=dict(dim=[-1,2048,1,1])))", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.train_att_bc.make_answer_vocab": [[106, 143], ["adic.keys", "sorted", "enumerate", "enumerate", "nadict.items", "nalist.append", "adict.has_key", "config.NUM_OUTPUT_UNITS"], "function", ["None"], ["n", ".", "bc_att_lstm", "=", "L", ".", "CompactBilinear", "(", "n", ".", "att_feature_resh", ",", "n", ".", "embed_avg_resh", ",", "\n", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "bc_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "bc_att_lstm", ")", "\n", "n", ".", "bc_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "bc_sign_sqrt", ")", "\n", "\n", "n", ".", "bc_dropped", "=", "L", ".", "Dropout", "(", "n", ".", "bc_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "n", ".", "bc_dropped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "bc_dropped", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "16000", "]", ")", ")", ")", "\n", "\n", "n", ".", "prediction", "=", "L", ".", "InnerProduct", "(", "n", ".", "bc_dropped_resh", ",", "num_output", "=", "3000", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "loss", "=", "L", ".", "SoftmaxWithLoss", "(", "n", ".", "prediction", ",", "n", ".", "label", ")", "\n", "return", "n", ".", "to_proto", "(", ")", "\n", "\n", "", "def", "make_answer_vocab", "(", "adic", ",", "vocab_size", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "adict", "=", "{", "''", ":", "0", "}", "\n", "nadict", "=", "{", "''", ":", "1000000", "}", "\n", "vid", "=", "1", "\n", "for", "qid", "in", "adic", ".", "keys", "(", ")", ":", "\n", "        ", "answer_obj", "=", "adic", "[", "qid", "]", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "\n", "for", "q_ans", "in", "answer_list", ":", "\n", "# create dict", "\n", "            ", "if", "adict", ".", "has_key", "(", "q_ans", ")", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "=", "1", "\n", "adict", "[", "q_ans", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "\n", "# debug", "\n", "", "", "", "nalist", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "sorted", "(", "nadict", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ":", "\n", "        ", "nalist", ".", "append", "(", "(", "k", ",", "v", ")", ")", "\n", "\n", "# keep the top 3000 answers", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.train_att_bc.make_question_vocab": [[144, 162], ["qdic.keys", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vdict.has_key"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list"], ["", "n_del_ans", "=", "0", "\n", "n_valid_ans", "=", "0", "\n", "adict_nid", "=", "{", "}", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", ":", "-", "vocab_size", "]", ")", ":", "\n", "        ", "del", "adict", "[", "w", "[", "0", "]", "]", "\n", "n_del_ans", "+=", "w", "[", "1", "]", "\n", "", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", "-", "vocab_size", ":", "]", ")", ":", "\n", "        ", "n_valid_ans", "+=", "w", "[", "1", "]", "\n", "adict_nid", "[", "w", "[", "0", "]", "]", "=", "i", "\n", "\n", "", "return", "adict_nid", "\n", "\n", "", "def", "make_question_vocab", "(", "qdic", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "vdict", "=", "{", "''", ":", "0", "}", "\n", "vid", "=", "1", "\n", "cdict", "=", "{", "''", ":", "0", "}", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.train_att_bc.make_vocab_files": [[163, 174], ["write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_question_vocab", "write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_answer_vocab"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_question_vocab", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_answer_vocab"], ["cvid", "=", "1", "\n", "for", "qid", "in", "qdic", ".", "keys", "(", ")", ":", "\n", "# sequence to list", "\n", "        ", "q_str", "=", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "\n", "# create dict", "\n", "for", "w", "in", "q_list", ":", "\n", "            ", "if", "not", "vdict", ".", "has_key", "(", "w", ")", ":", "\n", "                ", "vdict", "[", "w", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "", "for", "c", "in", "list", "(", "w", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.train_att_bc.main": [[175, 235], ["write_to_log.write_log", "write_to_log.write_log", "caffe.set_device", "caffe.set_mode_gpu", "caffe.get_solver", "numpy.zeros", "range", "os.path.exists", "os.makedirs", "os.path.exists", "os.path.exists", "write_to_log.write_log", "train_att_bc.make_vocab_files", "open", "f.write", "open", "f.write", "caffe.get_solver.step", "open", "json.load", "open", "json.load", "open", "json.dump", "open", "json.dump", "str", "str", "str", "str", "write_to_log.write_log", "write_to_log.write_log", "train_loss[].mean", "write_to_log.write_log", "caffe.get_solver.test_nets[].save", "write_to_log.write_log", "visualize_tools.exec_validation", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "train_att_bc.qlstm", "train_att_bc.qlstm", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_vocab_files", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.exec_validation", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["                ", "if", "not", "cdict", ".", "has_key", "(", "c", ")", ":", "\n", "                    ", "cdict", "[", "c", "]", "=", "cvid", "\n", "cvid", "+=", "1", "\n", "\n", "", "", "", "", "return", "vdict", ",", "cdict", "\n", "\n", "", "def", "make_vocab_files", "(", ")", ":", "\n", "    ", "\"\"\"\n    Produce the question and answer vocabulary files.\n    \"\"\"", "\n", "write_log", "(", "'making question vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "write_log", "(", "'making question character vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "qdic", ",", "_", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "QUESTION_VOCAB_SPACE", ")", "\n", "question_vocab", ",", "question_char_vocab", "=", "make_question_vocab", "(", "qdic", ")", "\n", "write_log", "(", "'making answer vocab... '", "+", "config", ".", "ANSWER_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "_", ",", "adic", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "ANSWER_VOCAB_SPACE", ")", "\n", "answer_vocab", "=", "make_answer_vocab", "(", "adic", ",", "config", ".", "NUM_OUTPUT_UNITS", ")", "\n", "return", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "'./result'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'./result'", ")", "\n", "\n", "", "question_vocab", ",", "answer_vocab", "=", "{", "}", ",", "{", "}", "\n", "if", "os", ".", "path", ".", "exists", "(", "'./result/cdict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/adict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/vdict.json'", ")", ":", "\n", "        ", "write_log", "(", "'restoring vocab'", ",", "'log.txt'", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_char_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "answer_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "=", "make_vocab_files", "(", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_char_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "answer_vocab", ",", "f", ")", "\n", "\n", "", "", "write_log", "(", "'question character vocab size: '", "+", "str", "(", "len", "(", "question_char_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'question vocab size: '", "+", "str", "(", "len", "(", "question_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'answer vocab size: '", "+", "str", "(", "len", "(", "answer_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "\n", "\n", "with", "open", "(", "'./result/proto_train.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "config", ".", "TRAIN_DATA_SPLITS", ",", "config", ".", "BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "with", "open", "(", "'./result/proto_test.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "'val'", ",", "config", ".", "VAL_BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "caffe", ".", "set_device", "(", "config", ".", "GPU_ID", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "solver", "=", "caffe", ".", "get_solver", "(", "'./qlstm_solver.prototxt'", ")", "\n", "\n", "train_loss", "=", "np", ".", "zeros", "(", "config", ".", "MAX_ITERATIONS", ")", "\n", "# results = []", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.visualize_tools.visualize_failures": [[27, 119], ["write_to_log.write_log", "visualize_tools.visualize_failures.save_qtype"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["def", "visualize_failures", "(", "stat_list", ",", "mode", ")", ":", "\n", "\n", "    ", "def", "save_qtype", "(", "qtype_list", ",", "save_filename", ",", "mode", ")", ":", "\n", "\n", "        ", "if", "mode", "==", "'val'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./eval'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/val2014'", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test-dev'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "elif", "mode", "==", "'test'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unsupported mode'", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "shutil", ".", "rmtree", "(", "savepath", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "os", ".", "makedirs", "(", "savepath", ")", "\n", "\n", "for", "qt", "in", "qtype_list", ":", "\n", "            ", "count", "=", "0", "\n", "for", "t_question", "in", "stat_list", ":", "\n", "#print count, t_question", "\n", "                ", "if", "count", "<", "40", "/", "len", "(", "qtype_list", ")", ":", "\n", "                    ", "t_question_list", "=", "t_question", "[", "'q_list'", "]", "\n", "saveflag", "=", "False", "\n", "#print 'debug****************************'", "\n", "#print qt", "\n", "#print t_question_list", "\n", "#print t_question_list[0] == qt[0]", "\n", "#print t_question_list[1] == qt[1]", "\n", "if", "t_question_list", "[", "0", "]", "==", "qt", "[", "0", "]", "and", "t_question_list", "[", "1", "]", "==", "qt", "[", "1", "]", ":", "\n", "                        ", "saveflag", "=", "True", "\n", "", "else", ":", "\n", "                        ", "saveflag", "=", "False", "\n", "\n", "", "if", "saveflag", "==", "True", ":", "\n", "                        ", "t_iid", "=", "t_question", "[", "'iid'", "]", "\n", "if", "mode", "==", "'val'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_val2014_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "", "elif", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_test2015_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "\n", "# for caption", "\n", "#print t_iid", "\n", "#annIds = caps.getAnnIds(t_iid)", "\n", "#anns = caps.loadAnns(annIds)", "\n", "#cap_list = [ann['caption'] for ann in anns]", "\n", "", "ans_list", "=", "t_question", "[", "'ans_list'", "]", "\n", "draw", "=", "ImageDraw", ".", "Draw", "(", "t_img", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ans_list", ")", ")", ":", "\n", "                            ", "try", ":", "\n", "                                ", "draw", ".", "text", "(", "(", "10", ",", "10", "*", "i", ")", ",", "str", "(", "ans_list", "[", "i", "]", ")", ")", "\n", "", "except", ":", "\n", "                                ", "pass", "\n", "\n", "", "", "ans", "=", "t_question", "[", "'answer'", "]", "\n", "pred", "=", "t_question", "[", "'pred'", "]", "\n", "if", "ans", "==", "-", "1", ":", "\n", "                            ", "pre", "=", "''", "\n", "", "elif", "ans", "==", "pred", ":", "\n", "                            ", "pre", "=", "'correct  '", "\n", "", "else", ":", "\n", "                            ", "pre", "=", "'failure  '", "\n", "#print ' aaa ', ans, pred", "\n", "", "ans", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "ans", ")", ")", "\n", "pred", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "pred", ")", ")", "\n", "img_title", "=", "pre", "+", "str", "(", "' '", ".", "join", "(", "t_question_list", ")", ")", "+", "'.  a_'", "+", "str", "(", "ans", ")", "+", "' p_'", "+", "str", "(", "pred", ")", "+", "'.png'", "\n", "count", "+=", "1", "\n", "write_log", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ",", "'visualize_log.txt'", ")", "\n", "t_img", ".", "save", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ")", "\n", "\n", "", "", "", "", "", "write_log", "(", "'saving colors'", ",", "'visualize_log.txt'", ")", "\n", "qt_color_list", "=", "[", "[", "'what'", ",", "'color'", "]", "]", "\n", "save_qtype", "(", "qt_color_list", ",", "'colors'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving what is'", ",", "'visualize_log.txt'", ")", "\n", "qt_whatis_list", "=", "[", "[", "'what'", ",", "'is'", "]", ",", "[", "'what'", ",", "'kind'", "]", ",", "[", "'what'", ",", "'are'", "]", "]", "\n", "save_qtype", "(", "qt_whatis_list", ",", "'whatis'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving is'", ",", "'visualize_log.txt'", ")", "\n", "qt_is_list", "=", "[", "[", "'is'", ",", "'the'", "]", ",", "[", "'is'", ",", "'this'", "]", ",", "[", "'is'", ",", "'there'", "]", "]", "\n", "save_qtype", "(", "qt_is_list", ",", "'is'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving how many'", ",", "'visualize_log.txt'", ")", "\n", "qt_howmany_list", "=", "[", "[", "'how'", ",", "'many'", "]", "]", "\n", "save_qtype", "(", "qt_howmany_list", ",", "'howmany'", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.visualize_tools.exec_validation": [[120, 201], ["caffe.set_device", "caffe.set_mode_gpu", "caffe.Net", "vqa_data_provider_layer.VQADataProvider", "len", "numpy.array().mean", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "vqa_data_provider_layer.VQADataProvider.get_batch_vec", "caffe.Net.forward", "caffe.Net.blobs[].data.argmax", "testloss_list.append", "zip", "vqaTools.vqa.VQA", "vqaTools.vqa.VQA.loadRes", "vqaEvaluation.vqaEval.VQAEval", "vqaEvaluation.vqaEval.VQAEval.evaluate", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "t_answer.tolist", "pred_list.append", "numpy.array", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "stat_list.append", "open", "json.dump", "visualize_tools.visualize_failures", "int", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "str().zfill", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "str().zfill", "xrange", "str", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.forward", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj"], ["", "def", "exec_validation", "(", "device_id", ",", "mode", ",", "it", "=", "''", ",", "visualize", "=", "False", ")", ":", "\n", "\n", "    ", "caffe", ".", "set_device", "(", "device_id", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "net", "=", "caffe", ".", "Net", "(", "'./result/proto_test.prototxt'", ",", "'./result/tmp.caffemodel'", ",", "caffe", ".", "TEST", ")", "\n", "\n", "dp", "=", "VQADataProvider", "(", "mode", "=", "mode", ",", "batchsize", "=", "config", ".", "VAL_BATCH_SIZE", ")", "\n", "total_questions", "=", "len", "(", "dp", ".", "getQuesIds", "(", ")", ")", "\n", "epoch", "=", "0", "\n", "\n", "pred_list", "=", "[", "]", "\n", "testloss_list", "=", "[", "]", "\n", "stat_list", "=", "[", "]", "\n", "\n", "while", "epoch", "==", "0", ":", "\n", "        ", "t_word", ",", "t_cont", ",", "t_word_c", ",", "t_cont_c", ",", "t_img_feature", ",", "t_answer", ",", "t_qid_list", ",", "t_iid_list", ",", "epoch", "=", "dp", ".", "get_batch_vec", "(", ")", "\n", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "...", "]", "=", "t_word", "# np.transpose(t_word,(1,0))", "\n", "net", ".", "blobs", "[", "'cont'", "]", ".", "data", "[", "...", "]", "=", "t_cont", "# np.transpose(t_cont,(1,0))", "\n", "net", ".", "blobs", "[", "'data1'", "]", ".", "data", "[", "...", "]", "=", "t_word_c", "\n", "net", ".", "blobs", "[", "'cont1'", "]", ".", "data", "[", "...", "]", "=", "t_cont_c", "\n", "net", ".", "blobs", "[", "'img_feature'", "]", ".", "data", "[", "...", "]", "=", "t_img_feature", "\n", "net", ".", "blobs", "[", "'label'", "]", ".", "data", "[", "...", "]", "=", "t_answer", "\n", "#net.blobs['glove'].data[...] = t_glove_matrix # np.transpose(t_glove_matrix, (1,0,2))", "\n", "net", ".", "forward", "(", ")", "\n", "t_pred_list", "=", "net", ".", "blobs", "[", "'prediction'", "]", ".", "data", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "t_pred_str", "=", "[", "dp", ".", "vec_to_answer", "(", "pred_symbol", ")", "for", "pred_symbol", "in", "t_pred_list", "]", "\n", "testloss_list", ".", "append", "(", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", ")", "\n", "for", "qid", ",", "iid", ",", "ans", ",", "pred", "in", "zip", "(", "t_qid_list", ",", "t_iid_list", ",", "t_answer", ".", "tolist", "(", ")", ",", "t_pred_str", ")", ":", "\n", "            ", "pred_list", ".", "append", "(", "{", "u'answer'", ":", "pred", ",", "u'question_id'", ":", "int", "(", "dp", ".", "getStrippedQuesId", "(", "qid", ")", ")", "}", ")", "\n", "if", "visualize", ":", "\n", "                ", "q_list", "=", "dp", ".", "seq_to_list", "(", "dp", ".", "getQuesStr", "(", "qid", ")", ")", "\n", "if", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                    ", "ans_str", "=", "''", "\n", "ans_list", "=", "[", "''", "]", "*", "10", "\n", "", "else", ":", "\n", "                    ", "ans_str", "=", "dp", ".", "vec_to_answer", "(", "ans", ")", "\n", "ans_list", "=", "[", "dp", ".", "getAnsObj", "(", "qid", ")", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "", "stat_list", ".", "append", "(", "{", "'qid'", ":", "qid", ",", "\n", "'q_list'", ":", "q_list", ",", "\n", "'iid'", ":", "iid", ",", "\n", "'answer'", ":", "ans_str", ",", "\n", "'ans_list'", ":", "ans_list", ",", "\n", "'pred'", ":", "pred", "}", ")", "\n", "#percent = 100 * float(len(pred_list)) / total_questions", "\n", "#sys.stdout.write('\\r' + ('%.2f' % percent) + '%')", "\n", "#sys.stdout.flush()", "\n", "\n", "\n", "\n", "", "", "", "mean_testloss", "=", "np", ".", "array", "(", "testloss_list", ")", ".", "mean", "(", ")", "\n", "\n", "if", "mode", "==", "'val'", ":", "\n", "        ", "valFile", "=", "'./result/val2014_resfile'", "\n", "with", "open", "(", "valFile", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "annFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ans_file'", "]", "\n", "quesFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ques_file'", "]", "\n", "vqa", "=", "VQA", "(", "annFile", ",", "quesFile", ")", "\n", "vqaRes", "=", "vqa", ".", "loadRes", "(", "valFile", ",", "quesFile", ")", "\n", "vqaEval", "=", "VQAEval", "(", "vqa", ",", "vqaRes", ",", "n", "=", "2", ")", "\n", "vqaEval", ".", "evaluate", "(", ")", "\n", "acc_overall", "=", "vqaEval", ".", "accuracy", "[", "'overall'", "]", "\n", "acc_perQuestionType", "=", "vqaEval", ".", "accuracy", "[", "'perQuestionType'", "]", "\n", "acc_perAnswerType", "=", "vqaEval", ".", "accuracy", "[", "'perAnswerType'", "]", "\n", "return", "mean_testloss", ",", "acc_overall", ",", "acc_perQuestionType", ",", "acc_perAnswerType", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test-dev2015_v3t'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "", "elif", "mode", "==", "'test'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test2015_v3c'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Inception + Gate.visualize_tools.drawgraph": [[202, 270], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.twinx", "fig.add_subplot.plot", "fig.add_subplot.plot", "ax1.twinx.plot", "matplotlib.legend", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "ax1.twinx.set_ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "numpy.array", "numpy.array", "matplotlib.figure", "matplotlib.legend", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "sorted", "visualize_tools.drawgraph.draw_qt_acc"], "function", ["None"], ["\n", "", "", "", "def", "drawgraph", "(", "results", ",", "save_question_type_graphs", "=", "False", ")", ":", "\n", "# 0:it", "\n", "# 1:trainloss", "\n", "# 2:testloss", "\n", "# 3:oa_acc", "\n", "# 4:qt_acc", "\n", "# 5:at_acc", "\n", "\n", "# training curve", "\n", "    ", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "loss", "=", "np", ".", "array", "(", "[", "l", "[", "1", "]", "for", "l", "in", "results", "]", ")", "\n", "valloss", "=", "np", ".", "array", "(", "[", "l", "[", "2", "]", "for", "l", "in", "results", "]", ")", "\n", "valacc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax1", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "ax2", "=", "ax1", ".", "twinx", "(", ")", "\n", "\n", "ax1", ".", "plot", "(", "it", ",", "loss", ",", "color", "=", "'blue'", ",", "label", "=", "'train loss'", ")", "\n", "ax1", ".", "plot", "(", "it", ",", "valloss", ",", "'--'", ",", "color", "=", "'blue'", ",", "label", "=", "'test loss'", ")", "\n", "ax2", ".", "plot", "(", "it", ",", "valacc", ",", "color", "=", "'red'", ",", "label", "=", "'acc on val'", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'lower left'", ")", "\n", "\n", "ax1", ".", "set_xlabel", "(", "'Iterations'", ")", "\n", "ax1", ".", "set_ylabel", "(", "'Loss Value'", ")", "\n", "ax2", ".", "set_ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "'./learning_curve max_%2.2f.png'", "%", "valacc", ".", "max", "(", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "# question type", "\n", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "oa_acc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "qt_dic_list", "=", "[", "l", "[", "4", "]", "for", "l", "in", "results", "]", "\n", "\n", "def", "draw_qt_acc", "(", "target_key_list", ",", "figname", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "for", "k", "in", "target_key_list", ":", "\n", "            ", "write_log", "(", "str", "(", "k", ")", "+", "str", "(", "type", "(", "k", ")", ")", ",", "'visualize_log.txt'", ")", "\n", "t_val", "=", "np", ".", "array", "(", "[", "qt_dic", "[", "k", "]", "for", "qt_dic", "in", "qt_dic_list", "]", ")", "\n", "plt", ".", "plot", "(", "it", ",", "t_val", ",", "label", "=", "str", "(", "k", ")", ")", "\n", "", "plt", ".", "legend", "(", "fontsize", "=", "'small'", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "100.", ")", "\n", "#plt.legend(prop={'size':6})", "\n", "\n", "plt", ".", "xlabel", "(", "'Iterations'", ")", "\n", "plt", ".", "ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "figname", ",", "dpi", "=", "200", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "", "if", "save_question_type_graphs", ":", "\n", "        ", "s_keys", "=", "sorted", "(", "qt_dic_list", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "0", ":", "13", "]", "+", "[", "s_keys", "[", "31", "]", ",", "]", ",", "'./ind_qt_are.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "13", ":", "17", "]", "+", "s_keys", "[", "49", ":", "]", ",", "'./ind_qt_how_where_who_why.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "17", ":", "31", "]", "+", "[", "s_keys", "[", "32", "]", ",", "]", ",", "'./ind_qt_is.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "33", ":", "49", "]", ",", "'./ind_qt_what.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what color is the'", ",", "'what color are the'", ",", "'what color is'", ",", "'what color'", ",", "'what is the color of the'", "]", ",", "'./qt_color.png'", ")", "\n", "draw_qt_acc", "(", "[", "'how many'", ",", "'how'", ",", "'how many people are'", ",", "'how many people are in'", "]", ",", "'./qt_number.png'", ")", "\n", "draw_qt_acc", "(", "[", "'who is'", ",", "'why'", ",", "'why is the'", ",", "'where is the'", ",", "'where are the'", ",", "'which'", "]", ",", "'./qt_who_why_where_which.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what is the man'", ",", "'is the man'", ",", "'are they'", ",", "'is he'", ",", "'is the woman'", ",", "'is this person'", ",", "'what is the woman'", ",", "'is the person'", ",", "'what is the person'", "]", ",", "'./qt_human.png'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.write_to_log.write_log": [[1, 4], ["open", "f.write"], "function", ["None"], ["def", "write_log", "(", "str", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "+", "\"\\n\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.__init__": [[13, 30], ["vqa_data_provider_layer.VQADataProvider.load_data", "len", "open", "json.load", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data"], ["    ", "def", "__init__", "(", "self", ",", "batchsize", "=", "64", ",", "max_length", "=", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "max_w_length", "=", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "batchsize", "\n", "self", ".", "d_vocabulary", "=", "None", "\n", "self", ".", "batch_index", "=", "None", "\n", "self", ".", "batch_len", "=", "None", "\n", "self", ".", "rev_adict", "=", "None", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "max_w_length", "=", "max_w_length", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "qdic", ",", "self", ".", "adic", "=", "VQADataProvider", ".", "load_data", "(", "mode", ")", "\n", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "cdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "vdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "adict", "=", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.load_vqa_json": [[33, 56], ["write_to_log.write_log", "open", "json.load", "open", "json.load", "str", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["#self.glove_dict = {} # word -> glove vector", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_vqa_json", "(", "data_split", ")", ":", "\n", "        ", "\"\"\"\n        Parses the question and answer json files for the given data split. \n        Returns the question dictionary and the answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ques_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "[", "'questions'", "]", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "qdic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'question_id'", "]", ")", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image_id'", "]", "}", "\n", "\n", "", "", "if", "'test'", "not", "in", "data_split", ":", "\n", "            ", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ans_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "adata", "=", "json", ".", "load", "(", "f", ")", "[", "'annotations'", "]", "\n", "for", "a", "in", "adata", ":", "\n", "                    ", "adic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "a", "[", "'question_id'", "]", ")", "]", "=", "a", "[", "'answers'", "]", "\n", "\n", "", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for '", "+", "data_split", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.load_genome_json": [[57, 74], ["write_to_log.write_log", "open", "json.load", "str", "str", "len"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_genome_json", "(", ")", ":", "\n", "        ", "\"\"\"\n        Parses the genome json file. Returns the question dictionary and the\n        answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'genome_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "key", "=", "'genome'", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'id'", "]", ")", "\n", "qdic", "[", "key", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image'", "]", "}", "\n", "adic", "[", "key", "]", "=", "[", "{", "'answer'", ":", "q", "[", "'answer'", "]", "}", "]", "\n", "\n", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for genome'", ",", "'log.txt'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.load_data": [[75, 101], ["data_split_str.split", "config.DATA_PATHS.keys", "vqa_data_provider_layer.VQADataProvider.load_genome_json", "all_qdic.update", "all_adic.update", "vqa_data_provider_layer.VQADataProvider.load_vqa_json", "all_qdic.update", "all_adic.update"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_genome_json", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_vqa_json"], ["return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_data", "(", "data_split_str", ")", ":", "\n", "        ", "all_qdic", ",", "all_adic", "=", "{", "}", ",", "{", "}", "\n", "for", "data_split", "in", "data_split_str", ".", "split", "(", "'+'", ")", ":", "\n", "            ", "assert", "data_split", "in", "config", ".", "DATA_PATHS", ".", "keys", "(", ")", ",", "'unknown data split'", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_genome_json", "(", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "", "else", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_vqa_json", "(", "data_split", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "\n", "", "", "return", "all_qdic", ",", "all_adic", "\n", "\n", "", "def", "getQuesIds", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "qdic", ".", "keys", "(", ")", "\n", "\n", "", "def", "getStrippedQuesId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "[", "1", "]", "\n", "\n", "", "def", "getImgId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'iid'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.getQuesIds": [[102, 104], ["vqa_data_provider_layer.VQADataProvider.qdic.keys"], "methods", ["None"], ["", "def", "getQuesStr", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.getStrippedQuesId": [[105, 107], ["qid.split"], "methods", ["None"], ["", "def", "getAnsObj", "(", "self", ",", "qid", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.getImgId": [[108, 110], ["None"], "methods", ["None"], ["", "return", "self", ".", "adic", "[", "qid", "]", "\n", "\n", "", "@", "staticmethod", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.getQuesStr": [[111, 113], ["None"], "methods", ["None"], ["def", "seq_to_list", "(", "s", ")", ":", "\n", "        ", "t_str", "=", "s", ".", "lower", "(", ")", "\n", "for", "i", "in", "[", "r'\\?'", ",", "r'\\!'", ",", "r'\\''", ",", "r'\\\"'", ",", "r'\\$'", ",", "r'\\:'", ",", "r'\\@'", ",", "r'\\('", ",", "r'\\)'", ",", "r'\\,'", ",", "r'\\.'", ",", "r'\\;'", "]", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.getAnsObj": [[114, 118], ["None"], "methods", ["None"], ["            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "''", ",", "t_str", ")", "\n", "", "for", "i", "in", "[", "r'\\-'", ",", "r'\\/'", "]", ":", "\n", "            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "' '", ",", "t_str", ")", "\n", "", "q_list", "=", "re", ".", "sub", "(", "r'\\?'", ",", "''", ",", "t_str", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "\n", "q_list", "=", "filter", "(", "lambda", "x", ":", "len", "(", "x", ")", ">", "0", ",", "q_list", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.seq_to_list": [[119, 129], ["s.lower", "re.sub().split", "filter", "re.sub", "re.sub", "re.sub", "re.sub.lower", "len"], "methods", ["None"], ["return", "q_list", "\n", "\n", "", "def", "extract_answer", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "", "answer_list", "=", "[", "answer_obj", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "dic", "=", "{", "}", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "dic", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "dic", "[", "ans", "]", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.extract_answer": [[130, 143], ["dic.has_key", "max", "xrange", "dic.items"], "methods", ["None"], ["", "else", ":", "\n", "                ", "dic", "[", "ans", "]", "=", "1", "\n", "", "", "max_key", "=", "max", "(", "(", "v", ",", "k", ")", "for", "(", "k", ",", "v", ")", "in", "dic", ".", "items", "(", ")", ")", "[", "1", "]", "\n", "return", "max_key", "\n", "\n", "", "def", "extract_answer_prob", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "prob_answer_list", "=", "[", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.extract_answer_prob": [[144, 162], ["vqa_data_provider_layer.VQADataProvider.adict.has_key", "len", "random.choice", "prob_answer_list.append", "Exception"], "methods", ["None"], ["                ", "prob_answer_list", ".", "append", "(", "ans", ")", "\n", "\n", "", "", "if", "len", "(", "prob_answer_list", ")", "==", "0", ":", "\n", "            ", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "return", "'hoge'", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"This should not happen.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "random", ".", "choice", "(", "prob_answer_list", ")", "\n", "\n", "# def qlist_to_vec(self, max_length, q_list):", "\n", "#     \"\"\"", "\n", "#     Converts a list of words into a format suitable for the embedding layer.", "\n", "\n", "#     Arguments:", "\n", "#     max_length -- the maximum length of a question sequence", "\n", "#     q_list -- a list of words which are the tokens in the question", "\n", "\n", "#     Returns:", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.qlist_to_vec": [[163, 208], ["numpy.zeros", "numpy.zeros", "xrange", "len", "vqa_data_provider_layer.VQADataProvider.vdict.has_key", "len"], "methods", ["None"], ["#     qvec -- A max_length length vector containing one-hot indices for each word", "\n", "#     cvec -- A max_length length sequence continuation indicator vector", "\n", "#     glove_matrix -- A max_length x GLOVE_EMBEDDING_SIZE matrix containing the glove embedding for", "\n", "#         each word", "\n", "#     \"\"\"", "\n", "#     qvec = np.zeros(max_length)", "\n", "#     cvec = np.zeros(max_length)", "\n", "#     glove_matrix = np.zeros(max_length * GLOVE_EMBEDDING_SIZE).reshape(max_length, GLOVE_EMBEDDING_SIZE)", "\n", "#     for i in xrange(max_length):", "\n", "#         if i < max_length - len(q_list):", "\n", "#             cvec[i] = 0", "\n", "#         else:", "\n", "#             w = q_list[i-(max_length-len(q_list))]", "\n", "#             if w not in self.glove_dict:", "\n", "#                 self.glove_dict[w] = self.nlp(u'%s' % w).vector", "\n", "#             glove_matrix[i] = self.glove_dict[w]", "\n", "#             # is the word in the vocabulary?", "\n", "#             if self.vdict.has_key(w) is False:", "\n", "#                 w = ''", "\n", "#             qvec[i] = self.vdict[w]", "\n", "#             cvec[i] = 1 #0 if i == max_length - len(q_list) else 1", "\n", "#             # UPDATE_10/12:", "\n", "#             #It seems that the original way is right for lstm.", "\n", "#             '''", "\n", "#             This is from https://github.com/BVLC/caffe/pull/1873.", "\n", "#             \"delta_{t,n} should be a binary indicator (i.e., value in {0, 1}),", "\n", "#             where a value of 0 means that timestep t of stream n is the beginning of a new sequence,", "\n", "#             and a value of 1 means that timestep t of stream n is continuing the sequence from timestep t-1 of stream n.", "\n", "#             Under the hood, the previous timestep's hidden state is multiplied by these delta values.", "\n", "#             The fact that these indicators are specified on a per-timestep and per-stream basis allows for streams of arbitrary different lengths without any padding or truncation.", "\n", "#             At the beginning of the forward pass, the final hidden state from the previous forward pass (h_T) is copied into the initial hidden state for the new forward pass (h_0),", "\n", "#             allowing for exact inference across arbitrarily long sequences, even if T == 1.", "\n", "#             However, if any sequences cross batch boundaries, backpropagation through time is approximate -- it is truncated along the batch boundaries.\"", "\n", "#             '''", "\n", "#             # I think the original way is false for CNN here. I want to keep the word embedding for unknown word as zero vector.", "\n", "#             # For example, if we have a sentence of length 7, there would be only 6 1's in cvec.", "\n", "\n", "#     return qvec, cvec, glove_matrix", "\n", "\n", "", "", "def", "qlist_to_vec", "(", "self", ",", "max_length", ",", "max_w_length", ",", "q_list", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.answer_to_vec": [[209, 219], ["vqa_data_provider_layer.VQADataProvider.adict.has_key"], "methods", ["None"], ["\n", "qvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "cvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "qcvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.vec_to_answer": [[220, 229], ["vqa_data_provider_layer.VQADataProvider.adict.items"], "methods", ["None"], ["ccvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "for", "i", "in", "xrange", "(", "max_length", ")", ":", "\n", "            ", "if", "i", "<", "max_length", "-", "len", "(", "q_list", ")", ":", "\n", "                ", "cvec", "[", "i", "]", "=", "0", "\n", "", "else", ":", "\n", "                ", "w", "=", "q_list", "[", "i", "-", "(", "max_length", "-", "len", "(", "q_list", ")", ")", "]", "\n", "# is the word in the vocabulary?", "\n", "if", "self", ".", "vdict", ".", "has_key", "(", "w", ")", "is", "False", ":", "\n", "                    ", "w", "=", "''", "\n", "", "qvec", "[", "i", "]", "=", "self", ".", "vdict", "[", "w", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.create_batch": [[230, 277], ["numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "enumerate", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "vqa_data_provider_layer.VQADataProvider.answer_to_vec", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "qid.split", "vqa_data_provider_layer.VQADataProvider.extract_answer", "vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "numpy.sqrt", "write_to_log.write_log", "numpy.load", "numpy.load", "str", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.answer_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["cvec", "[", "i", "]", "=", "1.0", "/", "len", "(", "q_list", ")", "\n", "j", "=", "max_w_length", "*", "i", "\n", "w_list", "=", "list", "(", "w", ")", "\n", "for", "k", "in", "xrange", "(", "max_w_length", ")", ":", "\n", "                    ", "if", "k", "<", "max_w_length", "-", "len", "(", "w_list", ")", ":", "\n", "                        ", "ccvec", "[", "j", "+", "k", "]", "=", "0", "\n", "", "else", ":", "\n", "                        ", "c", "=", "w_list", "[", "k", "-", "(", "max_w_length", "-", "len", "(", "w_list", ")", ")", "]", "\n", "# is the char in the vocabulary?", "\n", "if", "self", ".", "cdict", ".", "has_key", "(", "c", ")", "is", "False", ":", "\n", "                            ", "c", "=", "''", "\n", "", "qcvec", "[", "j", "+", "k", "]", "=", "self", ".", "cdict", "[", "c", "]", "\n", "ccvec", "[", "j", "+", "k", "]", "=", "1.0", "/", "len", "(", "w_list", ")", "\n", "", "", "", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", "\n", "\n", "", "def", "answer_to_vec", "(", "self", ",", "ans_str", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "if", "self", ".", "adict", ".", "has_key", "(", "ans_str", ")", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "ans_str", "]", "\n", "", "else", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "''", "]", "\n", "", "return", "ans", "\n", "\n", "", "def", "vec_to_answer", "(", "self", ",", "ans_symbol", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "rev_adict", "is", "None", ":", "\n", "            ", "rev_adict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "adict", ".", "items", "(", ")", ":", "\n", "                ", "rev_adict", "[", "v", "]", "=", "k", "\n", "", "self", ".", "rev_adict", "=", "rev_adict", "\n", "\n", "", "return", "self", ".", "rev_adict", "[", "ans_symbol", "]", "\n", "\n", "", "def", "create_batch", "(", "self", ",", "qid_list", ")", ":", "\n", "\n", "        ", "qvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "cvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "qcvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ccvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ivec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "2048", "*", "14", "*", "14", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "2048", ",", "14", ",", "14", ")", "\n", "avec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ")", "\n", "#glove_matrix = np.zeros(self.batchsize * self.max_length * GLOVE_EMBEDDING_SIZE).reshape(\\", "\n", "#self.batchsize, self.max_length, GLOVE_EMBEDDING_SIZE)", "\n", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProvider.get_batch_vec": [[279, 326], ["vqa_data_provider_layer.VQADataProvider.create_batch", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "random.shuffle", "len", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.adict.has_key", "t_qid_list.append", "t_iid_list.append", "vqa_data_provider_layer.VQADataProvider.get_batch_vec.has_at_least_one_valid_answer"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.create_batch", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId"], ["# load raw question information", "\n", "            ", "q_str", "=", "self", ".", "getQuesStr", "(", "qid", ")", "\n", "q_ans", "=", "self", ".", "getAnsObj", "(", "qid", ")", "\n", "q_iid", "=", "self", ".", "getImgId", "(", "qid", ")", "\n", "\n", "# convert question to vec", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "t_qvec", ",", "t_cvec", ",", "t_qcvec", ",", "t_ccvec", "=", "self", ".", "qlist_to_vec", "(", "self", ".", "max_length", ",", "self", ".", "max_w_length", ",", "q_list", ")", "\n", "\n", "try", ":", "\n", "                ", "qid_split", "=", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "\n", "data_split", "=", "qid_split", "[", "0", "]", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "else", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "t_ivec", "=", "(", "t_ivec", "/", "np", ".", "sqrt", "(", "(", "t_ivec", "**", "2", ")", ".", "sum", "(", ")", ")", ")", "\n", "", "except", ":", "\n", "                ", "t_ivec", "=", "0.", "\n", "write_log", "(", "'data not found for qid : '", "+", "str", "(", "q_iid", ")", "+", "' '", "+", "self", ".", "mode", ",", "'log.txt'", ")", "\n", "\n", "# convert answer to vec", "\n", "", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer", "(", "q_ans", ")", "\n", "", "else", ":", "\n", "                ", "q_ans_str", "=", "self", ".", "extract_answer_prob", "(", "q_ans", ")", "\n", "", "t_avec", "=", "self", ".", "answer_to_vec", "(", "q_ans_str", ")", "\n", "\n", "qvec", "[", "i", ",", "...", "]", "=", "t_qvec", "\n", "cvec", "[", "i", ",", "...", "]", "=", "t_cvec", "\n", "qcvec", "[", "i", ",", "...", "]", "=", "t_qcvec", "\n", "ccvec", "[", "i", ",", "...", "]", "=", "t_ccvec", "\n", "ivec", "[", "i", ",", "...", "]", "=", "t_ivec", "\n", "avec", "[", "i", ",", "...", "]", "=", "t_avec", "\n", "#glove_matrix[i,...] = t_glove_matrix", "\n", "\n", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", ",", "ivec", ",", "avec", "#, glove_matrix", "\n", "\n", "\n", "", "def", "get_batch_vec", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "batch_len", "is", "None", ":", "\n", "            ", "self", ".", "n_skipped", "=", "0", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_len", "=", "len", "(", "qid_list", ")", "\n", "self", ".", "batch_index", "=", "0", "\n", "self", ".", "epoch_counter", "=", "0", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProviderLayer.setup": [[333, 348], ["top[].reshape", "top[].reshape", "top[].reshape", "top[].reshape", "json.loads", "json.loads", "vqa_data_provider_layer.VQADataProvider"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape"], ["                    ", "return", "True", "\n", "\n", "", "", "", "counter", "=", "0", "\n", "t_qid_list", "=", "[", "]", "\n", "t_iid_list", "=", "[", "]", "\n", "while", "counter", "<", "self", ".", "batchsize", ":", "\n", "            ", "t_qid", "=", "self", ".", "qid_list", "[", "self", ".", "batch_index", "]", "\n", "t_iid", "=", "self", ".", "getImgId", "(", "t_qid", ")", "\n", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n", "", "elif", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "                ", "t_qid_list", ".", "append", "(", "t_qid", ")", "\n", "t_iid_list", ".", "append", "(", "t_iid", ")", "\n", "counter", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProviderLayer.reshape": [[349, 351], ["None"], "methods", ["None"], ["", "else", ":", "\n", "                ", "self", ".", "n_skipped", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProviderLayer.forward": [[352, 362], ["vqa_data_provider_layer.VQADataProviderLayer.dp.get_batch_vec"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec"], ["", "if", "self", ".", "batch_index", "<", "self", ".", "batch_len", "-", "1", ":", "\n", "                ", "self", ".", "batch_index", "+=", "1", "\n", "", "else", ":", "\n", "                ", "self", ".", "epoch_counter", "+=", "1", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n", "self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_index", "=", "0", "\n", "write_log", "(", "\"%d questions were skipped in a single epoch\"", "%", "self", ".", "n_skipped", ",", "'log.txt'", ")", "\n", "self", ".", "n_skipped", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.vqa_data_provider_layer.VQADataProviderLayer.backward": [[364, 366], ["None"], "methods", ["None"], ["return", "t_batch", "+", "(", "t_qid_list", ",", "t_iid_list", ",", "self", ".", "epoch_counter", ")", "\n", "\n", "", "", "class", "VQADataProviderLayer", "(", "caffe", ".", "Layer", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.train_att_bc.qlstm": [[19, 81], ["caffe.NetSpec", "json.dumps", "caffe.layers.Python", "caffe.layers.Embed", "caffe.layers.Scale", "caffe.layers.Reshape", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Pooling", "caffe.layers.Dropout", "caffe.layers.Tile", "caffe.layers.Tile", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.Reshape", "caffe.layers.Softmax", "caffe.layers.Reshape", "caffe.layers.Slice", "caffe.layers.DummyData", "caffe.layers.SoftAttention", "caffe.layers.SoftAttention", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Concat", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Reshape", "caffe.layers.InnerProduct", "caffe.layers.SoftmaxWithLoss", "caffe.NetSpec.to_proto", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "config.TRAIN_DATA_SPLITS", "config.BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION", "config.VAL_BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION"], "function", ["None"], ["def", "qlstm", "(", "mode", ",", "batchsize", ",", "T", ",", "T_c", ",", "question_c_vocab_size", ",", "question_vocab_size", ")", ":", "\n", "    ", "n", "=", "caffe", ".", "NetSpec", "(", ")", "\n", "mode_str", "=", "json", ".", "dumps", "(", "{", "'mode'", ":", "mode", ",", "'batchsize'", ":", "batchsize", "}", ")", "\n", "n", ".", "data", ",", "n", ".", "cont", ",", "n", ".", "data1", ",", "n", ".", "cont1", ",", "n", ".", "img_feature", ",", "n", ".", "label", "=", "L", ".", "Python", "(", "module", "=", "'vqa_data_provider_layer'", ",", "layer", "=", "'VQADataProviderLayer'", ",", "param_str", "=", "mode_str", ",", "ntop", "=", "6", ")", "#5 )", "\n", "\n", "# char embedding", "\n", "n", ".", "embed_c", "=", "L", ".", "Embed", "(", "n", ".", "data1", ",", "input_dim", "=", "question_c_vocab_size", ",", "num_output", "=", "100", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "\n", "n", ".", "embed_c_scale", "=", "L", ".", "Scale", "(", "n", ".", "embed_c", ",", "n", ".", "cont1", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "\n", "n", ".", "embed_c_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_c_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T_c", "*", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T_c*T x d_c x 1", "\n", "tops", "=", "L", ".", "Slice", "(", "n", ".", "embed_c_scale_resh", ",", "ntop", "=", "T", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T_c x d_c x 1", "\n", "for", "i", "in", "xrange", "(", "T", ")", ":", "\n", "        ", "n", ".", "__setattr__", "(", "'Slice_'", "+", "str", "(", "i", "+", "1", ")", ",", "tops", "[", "int", "(", "i", ")", "]", ")", "\n", "\n", "# avg of char embedding", "\n", "", "n", ".", "c_embed_1", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_1", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_2", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_2", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_3", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_3", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_4", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_4", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_5", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_5", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_6", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_6", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_7", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_7", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_8", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_8", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_9", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_9", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_10", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_10", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_11", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_11", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_12", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_12", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_13", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_13", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_14", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_14", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_15", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_15", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_16", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_16", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_17", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_17", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_18", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_18", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_19", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_19", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_20", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_20", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_21", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_21", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_22", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_22", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "\n", "concat_c_embed", "=", "[", "n", ".", "c_embed_1", ",", "n", ".", "c_embed_2", ",", "n", ".", "c_embed_3", ",", "n", ".", "c_embed_4", ",", "n", ".", "c_embed_5", ",", "n", ".", "c_embed_6", ",", "n", ".", "c_embed_7", ",", "n", ".", "c_embed_8", ",", "n", ".", "c_embed_9", ",", "n", ".", "c_embed_10", ",", "n", ".", "c_embed_11", ",", "n", ".", "c_embed_12", ",", "n", ".", "c_embed_13", ",", "n", ".", "c_embed_14", ",", "n", ".", "c_embed_15", ",", "n", ".", "c_embed_16", ",", "n", ".", "c_embed_17", ",", "n", ".", "c_embed_18", ",", "n", ".", "c_embed_19", ",", "n", ".", "c_embed_20", ",", "n", ".", "c_embed_21", ",", "n", ".", "c_embed_22", "]", "\n", "n", ".", "concat_char_embed", "=", "L", ".", "Concat", "(", "*", "concat_c_embed", ",", "concat_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T x d_c x 1", "\n", "n", ".", "concat_char_embed_resh", "=", "L", ".", "Reshape", "(", "n", ".", "concat_char_embed", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", "]", ")", ")", ")", "\n", "\n", "# word embedding", "\n", "n", ".", "embed_w", "=", "L", ".", "Embed", "(", "n", ".", "data", ",", "input_dim", "=", "question_vocab_size", ",", "num_output", "=", "200", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "# N x T x d_w", "\n", "\n", "# combine word and char embedding", "\n", "concat_word_embed", "=", "[", "n", ".", "embed_w", ",", "n", ".", "concat_char_embed_resh", "]", "\n", "n", ".", "concat_embed", "=", "L", ".", "Concat", "(", "*", "concat_word_embed", ",", "concat_param", "=", "{", "'axis'", ":", "2", "}", ")", "# N x T x (d_c+d_w)", "\n", "\n", "n", ".", "embed_scale", "=", "L", ".", "Scale", "(", "n", ".", "concat_embed", ",", "n", ".", "cont", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "# N x T x (d_c+d_w)", "\n", "n", ".", "embed_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T x (d_c+d_w) x 1", "\n", "\n", "# avg of word embedding", "\n", "n", ".", "embed_avg", "=", "L", ".", "Convolution", "(", "n", ".", "embed_scale_resh", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x (d_c+d_w) x 1", "\n", "n", ".", "embed_avg_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_avg", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "300", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled_1", "=", "L", ".", "Tile", "(", "n", ".", "embed_avg_resh", ",", "axis", "=", "2", ",", "tiles", "=", "14", ")", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled", "=", "L", ".", "Tile", "(", "n", ".", "q_emb_tanh_droped_resh_tiled_1", ",", "axis", "=", "3", ",", "tiles", "=", "14", ")", "\n", "n", ".", "i_emb_tanh_droped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "img_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "n", ".", "blcf", "=", "L", ".", "CompactBilinear", "(", "n", ".", "q_emb_tanh_droped_resh_tiled", ",", "n", ".", "i_emb_tanh_droped_resh", ",", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.train_att_bc.make_answer_vocab": [[82, 119], ["adic.keys", "sorted", "enumerate", "enumerate", "nadict.items", "nalist.append", "adict.has_key", "config.NUM_OUTPUT_UNITS"], "function", ["None"], ["n", ".", "blcf_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "blcf", ")", "\n", "n", ".", "blcf_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "blcf_sign_sqrt", ")", "\n", "n", ".", "blcf_droped", "=", "L", ".", "Dropout", "(", "n", ".", "blcf_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "\n", "# multi-channel attention", "\n", "n", ".", "att_conv1", "=", "L", ".", "Convolution", "(", "n", ".", "blcf_droped", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "512", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_conv1_relu", "=", "L", ".", "ReLU", "(", "n", ".", "att_conv1", ")", "\n", "n", ".", "att_conv2", "=", "L", ".", "Convolution", "(", "n", ".", "att_conv1_relu", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "2", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_reshaped", "=", "L", ".", "Reshape", "(", "n", ".", "att_conv2", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", "*", "14", "]", ")", ")", ")", "\n", "n", ".", "att_softmax", "=", "L", ".", "Softmax", "(", "n", ".", "att_reshaped", ",", "axis", "=", "2", ")", "\n", "n", ".", "att", "=", "L", ".", "Reshape", "(", "n", ".", "att_softmax", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "att_maps", "=", "L", ".", "Slice", "(", "n", ".", "att", ",", "ntop", "=", "2", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "\n", "n", ".", "att_map0", "=", "att_maps", "[", "0", "]", "\n", "n", ".", "att_map1", "=", "att_maps", "[", "1", "]", "\n", "dummy", "=", "L", ".", "DummyData", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "1", "]", ")", ",", "data_filler", "=", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", ",", "ntop", "=", "1", ")", "\n", "n", ".", "att_feature0", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map0", ",", "dummy", ")", "\n", "n", ".", "att_feature1", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map1", ",", "dummy", ")", "\n", "n", ".", "att_feature0_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature0", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature1_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature1", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature", "=", "L", ".", "Concat", "(", "n", ".", "att_feature0_resh", ",", "n", ".", "att_feature1_resh", ")", "\n", "\n", "# merge attention and lstm with compact bilinear pooling", "\n", "n", ".", "att_feature_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "4096", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "#n.lstm_12_resh = L.Reshape(n.lstm_12, reshape_param=dict(shape=dict(dim=[-1,2048,1,1])))", "\n", "n", ".", "bc_att_lstm", "=", "L", ".", "CompactBilinear", "(", "n", ".", "att_feature_resh", ",", "n", ".", "embed_avg_resh", ",", "\n", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "bc_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "bc_att_lstm", ")", "\n", "n", ".", "bc_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "bc_sign_sqrt", ")", "\n", "\n", "n", ".", "bc_dropped", "=", "L", ".", "Dropout", "(", "n", ".", "bc_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "n", ".", "bc_dropped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "bc_dropped", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "16000", "]", ")", ")", ")", "\n", "\n", "n", ".", "prediction", "=", "L", ".", "InnerProduct", "(", "n", ".", "bc_dropped_resh", ",", "num_output", "=", "3000", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "loss", "=", "L", ".", "SoftmaxWithLoss", "(", "n", ".", "prediction", ",", "n", ".", "label", ")", "\n", "return", "n", ".", "to_proto", "(", ")", "\n", "\n", "", "def", "make_answer_vocab", "(", "adic", ",", "vocab_size", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.train_att_bc.make_question_vocab": [[120, 138], ["qdic.keys", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vdict.has_key"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list"], ["\n", "adict", "=", "{", "''", ":", "0", "}", "\n", "nadict", "=", "{", "''", ":", "1000000", "}", "\n", "vid", "=", "1", "\n", "for", "qid", "in", "adic", ".", "keys", "(", ")", ":", "\n", "        ", "answer_obj", "=", "adic", "[", "qid", "]", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "\n", "for", "q_ans", "in", "answer_list", ":", "\n", "# create dict", "\n", "            ", "if", "adict", ".", "has_key", "(", "q_ans", ")", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "=", "1", "\n", "adict", "[", "q_ans", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "\n", "# debug", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.train_att_bc.make_vocab_files": [[139, 150], ["write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_question_vocab", "write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_answer_vocab"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_question_vocab", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_answer_vocab"], ["", "", "", "nalist", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "sorted", "(", "nadict", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ":", "\n", "        ", "nalist", ".", "append", "(", "(", "k", ",", "v", ")", ")", "\n", "\n", "# keep the top 3000 answers", "\n", "", "n_del_ans", "=", "0", "\n", "n_valid_ans", "=", "0", "\n", "adict_nid", "=", "{", "}", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", ":", "-", "vocab_size", "]", ")", ":", "\n", "        ", "del", "adict", "[", "w", "[", "0", "]", "]", "\n", "n_del_ans", "+=", "w", "[", "1", "]", "\n", "", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", "-", "vocab_size", ":", "]", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.train_att_bc.main": [[151, 211], ["write_to_log.write_log", "write_to_log.write_log", "caffe.set_device", "caffe.set_mode_gpu", "caffe.get_solver", "numpy.zeros", "range", "os.path.exists", "os.makedirs", "os.path.exists", "os.path.exists", "write_to_log.write_log", "train_att_bc.make_vocab_files", "open", "f.write", "open", "f.write", "caffe.get_solver.step", "open", "json.load", "open", "json.load", "open", "json.dump", "open", "json.dump", "str", "str", "str", "str", "write_to_log.write_log", "write_to_log.write_log", "train_loss[].mean", "write_to_log.write_log", "caffe.get_solver.test_nets[].save", "write_to_log.write_log", "visualize_tools.exec_validation", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "train_att_bc.qlstm", "train_att_bc.qlstm", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_vocab_files", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.exec_validation", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["        ", "n_valid_ans", "+=", "w", "[", "1", "]", "\n", "adict_nid", "[", "w", "[", "0", "]", "]", "=", "i", "\n", "\n", "", "return", "adict_nid", "\n", "\n", "", "def", "make_question_vocab", "(", "qdic", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "vdict", "=", "{", "''", ":", "0", "}", "\n", "vid", "=", "1", "\n", "cdict", "=", "{", "''", ":", "0", "}", "\n", "cvid", "=", "1", "\n", "for", "qid", "in", "qdic", ".", "keys", "(", ")", ":", "\n", "# sequence to list", "\n", "        ", "q_str", "=", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "\n", "# create dict", "\n", "for", "w", "in", "q_list", ":", "\n", "            ", "if", "not", "vdict", ".", "has_key", "(", "w", ")", ":", "\n", "                ", "vdict", "[", "w", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "", "for", "c", "in", "list", "(", "w", ")", ":", "\n", "                ", "if", "not", "cdict", ".", "has_key", "(", "c", ")", ":", "\n", "                    ", "cdict", "[", "c", "]", "=", "cvid", "\n", "cvid", "+=", "1", "\n", "\n", "", "", "", "", "return", "vdict", ",", "cdict", "\n", "\n", "", "def", "make_vocab_files", "(", ")", ":", "\n", "    ", "\"\"\"\n    Produce the question and answer vocabulary files.\n    \"\"\"", "\n", "write_log", "(", "'making question vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "write_log", "(", "'making question character vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "qdic", ",", "_", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "QUESTION_VOCAB_SPACE", ")", "\n", "question_vocab", ",", "question_char_vocab", "=", "make_question_vocab", "(", "qdic", ")", "\n", "write_log", "(", "'making answer vocab... '", "+", "config", ".", "ANSWER_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "_", ",", "adic", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "ANSWER_VOCAB_SPACE", ")", "\n", "answer_vocab", "=", "make_answer_vocab", "(", "adic", ",", "config", ".", "NUM_OUTPUT_UNITS", ")", "\n", "return", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "'./result'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'./result'", ")", "\n", "\n", "", "question_vocab", ",", "answer_vocab", "=", "{", "}", ",", "{", "}", "\n", "if", "os", ".", "path", ".", "exists", "(", "'./result/cdict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/adict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/vdict.json'", ")", ":", "\n", "        ", "write_log", "(", "'restoring vocab'", ",", "'log.txt'", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_char_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "answer_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "=", "make_vocab_files", "(", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_char_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'w'", ")", "as", "f", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.visualize_tools.visualize_failures": [[27, 119], ["write_to_log.write_log", "visualize_tools.visualize_failures.save_qtype"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["def", "visualize_failures", "(", "stat_list", ",", "mode", ")", ":", "\n", "\n", "    ", "def", "save_qtype", "(", "qtype_list", ",", "save_filename", ",", "mode", ")", ":", "\n", "\n", "        ", "if", "mode", "==", "'val'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./eval'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/val2014'", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test-dev'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "elif", "mode", "==", "'test'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unsupported mode'", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "shutil", ".", "rmtree", "(", "savepath", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "os", ".", "makedirs", "(", "savepath", ")", "\n", "\n", "for", "qt", "in", "qtype_list", ":", "\n", "            ", "count", "=", "0", "\n", "for", "t_question", "in", "stat_list", ":", "\n", "#print count, t_question", "\n", "                ", "if", "count", "<", "40", "/", "len", "(", "qtype_list", ")", ":", "\n", "                    ", "t_question_list", "=", "t_question", "[", "'q_list'", "]", "\n", "saveflag", "=", "False", "\n", "#print 'debug****************************'", "\n", "#print qt", "\n", "#print t_question_list", "\n", "#print t_question_list[0] == qt[0]", "\n", "#print t_question_list[1] == qt[1]", "\n", "if", "t_question_list", "[", "0", "]", "==", "qt", "[", "0", "]", "and", "t_question_list", "[", "1", "]", "==", "qt", "[", "1", "]", ":", "\n", "                        ", "saveflag", "=", "True", "\n", "", "else", ":", "\n", "                        ", "saveflag", "=", "False", "\n", "\n", "", "if", "saveflag", "==", "True", ":", "\n", "                        ", "t_iid", "=", "t_question", "[", "'iid'", "]", "\n", "if", "mode", "==", "'val'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_val2014_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "", "elif", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_test2015_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "\n", "# for caption", "\n", "#print t_iid", "\n", "#annIds = caps.getAnnIds(t_iid)", "\n", "#anns = caps.loadAnns(annIds)", "\n", "#cap_list = [ann['caption'] for ann in anns]", "\n", "", "ans_list", "=", "t_question", "[", "'ans_list'", "]", "\n", "draw", "=", "ImageDraw", ".", "Draw", "(", "t_img", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ans_list", ")", ")", ":", "\n", "                            ", "try", ":", "\n", "                                ", "draw", ".", "text", "(", "(", "10", ",", "10", "*", "i", ")", ",", "str", "(", "ans_list", "[", "i", "]", ")", ")", "\n", "", "except", ":", "\n", "                                ", "pass", "\n", "\n", "", "", "ans", "=", "t_question", "[", "'answer'", "]", "\n", "pred", "=", "t_question", "[", "'pred'", "]", "\n", "if", "ans", "==", "-", "1", ":", "\n", "                            ", "pre", "=", "''", "\n", "", "elif", "ans", "==", "pred", ":", "\n", "                            ", "pre", "=", "'correct  '", "\n", "", "else", ":", "\n", "                            ", "pre", "=", "'failure  '", "\n", "#print ' aaa ', ans, pred", "\n", "", "ans", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "ans", ")", ")", "\n", "pred", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "pred", ")", ")", "\n", "img_title", "=", "pre", "+", "str", "(", "' '", ".", "join", "(", "t_question_list", ")", ")", "+", "'.  a_'", "+", "str", "(", "ans", ")", "+", "' p_'", "+", "str", "(", "pred", ")", "+", "'.png'", "\n", "count", "+=", "1", "\n", "write_log", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ",", "'visualize_log.txt'", ")", "\n", "t_img", ".", "save", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ")", "\n", "\n", "", "", "", "", "", "write_log", "(", "'saving colors'", ",", "'visualize_log.txt'", ")", "\n", "qt_color_list", "=", "[", "[", "'what'", ",", "'color'", "]", "]", "\n", "save_qtype", "(", "qt_color_list", ",", "'colors'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving what is'", ",", "'visualize_log.txt'", ")", "\n", "qt_whatis_list", "=", "[", "[", "'what'", ",", "'is'", "]", ",", "[", "'what'", ",", "'kind'", "]", ",", "[", "'what'", ",", "'are'", "]", "]", "\n", "save_qtype", "(", "qt_whatis_list", ",", "'whatis'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving is'", ",", "'visualize_log.txt'", ")", "\n", "qt_is_list", "=", "[", "[", "'is'", ",", "'the'", "]", ",", "[", "'is'", ",", "'this'", "]", ",", "[", "'is'", ",", "'there'", "]", "]", "\n", "save_qtype", "(", "qt_is_list", ",", "'is'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving how many'", ",", "'visualize_log.txt'", ")", "\n", "qt_howmany_list", "=", "[", "[", "'how'", ",", "'many'", "]", "]", "\n", "save_qtype", "(", "qt_howmany_list", ",", "'howmany'", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.visualize_tools.exec_validation": [[120, 201], ["caffe.set_device", "caffe.set_mode_gpu", "caffe.Net", "vqa_data_provider_layer.VQADataProvider", "len", "numpy.array().mean", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "vqa_data_provider_layer.VQADataProvider.get_batch_vec", "caffe.Net.forward", "caffe.Net.blobs[].data.argmax", "testloss_list.append", "zip", "vqaTools.vqa.VQA", "vqaTools.vqa.VQA.loadRes", "vqaEvaluation.vqaEval.VQAEval", "vqaEvaluation.vqaEval.VQAEval.evaluate", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "t_answer.tolist", "pred_list.append", "numpy.array", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "stat_list.append", "open", "json.dump", "visualize_tools.visualize_failures", "int", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "str().zfill", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "str().zfill", "xrange", "str", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.forward", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj"], ["", "def", "exec_validation", "(", "device_id", ",", "mode", ",", "it", "=", "''", ",", "visualize", "=", "False", ")", ":", "\n", "\n", "    ", "caffe", ".", "set_device", "(", "device_id", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "net", "=", "caffe", ".", "Net", "(", "'./result/proto_test.prototxt'", ",", "'./result/tmp.caffemodel'", ",", "caffe", ".", "TEST", ")", "\n", "\n", "dp", "=", "VQADataProvider", "(", "mode", "=", "mode", ",", "batchsize", "=", "config", ".", "VAL_BATCH_SIZE", ")", "\n", "total_questions", "=", "len", "(", "dp", ".", "getQuesIds", "(", ")", ")", "\n", "epoch", "=", "0", "\n", "\n", "pred_list", "=", "[", "]", "\n", "testloss_list", "=", "[", "]", "\n", "stat_list", "=", "[", "]", "\n", "\n", "while", "epoch", "==", "0", ":", "\n", "        ", "t_word", ",", "t_cont", ",", "t_word_c", ",", "t_cont_c", ",", "t_img_feature", ",", "t_answer", ",", "t_qid_list", ",", "t_iid_list", ",", "epoch", "=", "dp", ".", "get_batch_vec", "(", ")", "\n", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "...", "]", "=", "t_word", "# np.transpose(t_word,(1,0))", "\n", "net", ".", "blobs", "[", "'cont'", "]", ".", "data", "[", "...", "]", "=", "t_cont", "# np.transpose(t_cont,(1,0))", "\n", "net", ".", "blobs", "[", "'data1'", "]", ".", "data", "[", "...", "]", "=", "t_word_c", "\n", "net", ".", "blobs", "[", "'cont1'", "]", ".", "data", "[", "...", "]", "=", "t_cont_c", "\n", "net", ".", "blobs", "[", "'img_feature'", "]", ".", "data", "[", "...", "]", "=", "t_img_feature", "\n", "net", ".", "blobs", "[", "'label'", "]", ".", "data", "[", "...", "]", "=", "t_answer", "\n", "#net.blobs['glove'].data[...] = t_glove_matrix # np.transpose(t_glove_matrix, (1,0,2))", "\n", "net", ".", "forward", "(", ")", "\n", "t_pred_list", "=", "net", ".", "blobs", "[", "'prediction'", "]", ".", "data", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "t_pred_str", "=", "[", "dp", ".", "vec_to_answer", "(", "pred_symbol", ")", "for", "pred_symbol", "in", "t_pred_list", "]", "\n", "testloss_list", ".", "append", "(", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", ")", "\n", "for", "qid", ",", "iid", ",", "ans", ",", "pred", "in", "zip", "(", "t_qid_list", ",", "t_iid_list", ",", "t_answer", ".", "tolist", "(", ")", ",", "t_pred_str", ")", ":", "\n", "            ", "pred_list", ".", "append", "(", "{", "u'answer'", ":", "pred", ",", "u'question_id'", ":", "int", "(", "dp", ".", "getStrippedQuesId", "(", "qid", ")", ")", "}", ")", "\n", "if", "visualize", ":", "\n", "                ", "q_list", "=", "dp", ".", "seq_to_list", "(", "dp", ".", "getQuesStr", "(", "qid", ")", ")", "\n", "if", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                    ", "ans_str", "=", "''", "\n", "ans_list", "=", "[", "''", "]", "*", "10", "\n", "", "else", ":", "\n", "                    ", "ans_str", "=", "dp", ".", "vec_to_answer", "(", "ans", ")", "\n", "ans_list", "=", "[", "dp", ".", "getAnsObj", "(", "qid", ")", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "", "stat_list", ".", "append", "(", "{", "'qid'", ":", "qid", ",", "\n", "'q_list'", ":", "q_list", ",", "\n", "'iid'", ":", "iid", ",", "\n", "'answer'", ":", "ans_str", ",", "\n", "'ans_list'", ":", "ans_list", ",", "\n", "'pred'", ":", "pred", "}", ")", "\n", "#percent = 100 * float(len(pred_list)) / total_questions", "\n", "#sys.stdout.write('\\r' + ('%.2f' % percent) + '%')", "\n", "#sys.stdout.flush()", "\n", "\n", "\n", "\n", "", "", "", "mean_testloss", "=", "np", ".", "array", "(", "testloss_list", ")", ".", "mean", "(", ")", "\n", "\n", "if", "mode", "==", "'val'", ":", "\n", "        ", "valFile", "=", "'./result/val2014_resfile'", "\n", "with", "open", "(", "valFile", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "annFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ans_file'", "]", "\n", "quesFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ques_file'", "]", "\n", "vqa", "=", "VQA", "(", "annFile", ",", "quesFile", ")", "\n", "vqaRes", "=", "vqa", ".", "loadRes", "(", "valFile", ",", "quesFile", ")", "\n", "vqaEval", "=", "VQAEval", "(", "vqa", ",", "vqaRes", ",", "n", "=", "2", ")", "\n", "vqaEval", ".", "evaluate", "(", ")", "\n", "acc_overall", "=", "vqaEval", ".", "accuracy", "[", "'overall'", "]", "\n", "acc_perQuestionType", "=", "vqaEval", ".", "accuracy", "[", "'perQuestionType'", "]", "\n", "acc_perAnswerType", "=", "vqaEval", ".", "accuracy", "[", "'perAnswerType'", "]", "\n", "return", "mean_testloss", ",", "acc_overall", ",", "acc_perQuestionType", ",", "acc_perAnswerType", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test-dev2015_v3t'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "", "elif", "mode", "==", "'test'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test2015_v3c'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.CNN Non-Inception.visualize_tools.drawgraph": [[202, 270], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.twinx", "fig.add_subplot.plot", "fig.add_subplot.plot", "ax1.twinx.plot", "matplotlib.legend", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "ax1.twinx.set_ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "numpy.array", "numpy.array", "matplotlib.figure", "matplotlib.legend", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "sorted", "visualize_tools.drawgraph.draw_qt_acc"], "function", ["None"], ["\n", "", "", "", "def", "drawgraph", "(", "results", ",", "save_question_type_graphs", "=", "False", ")", ":", "\n", "# 0:it", "\n", "# 1:trainloss", "\n", "# 2:testloss", "\n", "# 3:oa_acc", "\n", "# 4:qt_acc", "\n", "# 5:at_acc", "\n", "\n", "# training curve", "\n", "    ", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "loss", "=", "np", ".", "array", "(", "[", "l", "[", "1", "]", "for", "l", "in", "results", "]", ")", "\n", "valloss", "=", "np", ".", "array", "(", "[", "l", "[", "2", "]", "for", "l", "in", "results", "]", ")", "\n", "valacc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax1", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "ax2", "=", "ax1", ".", "twinx", "(", ")", "\n", "\n", "ax1", ".", "plot", "(", "it", ",", "loss", ",", "color", "=", "'blue'", ",", "label", "=", "'train loss'", ")", "\n", "ax1", ".", "plot", "(", "it", ",", "valloss", ",", "'--'", ",", "color", "=", "'blue'", ",", "label", "=", "'test loss'", ")", "\n", "ax2", ".", "plot", "(", "it", ",", "valacc", ",", "color", "=", "'red'", ",", "label", "=", "'acc on val'", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'lower left'", ")", "\n", "\n", "ax1", ".", "set_xlabel", "(", "'Iterations'", ")", "\n", "ax1", ".", "set_ylabel", "(", "'Loss Value'", ")", "\n", "ax2", ".", "set_ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "'./learning_curve max_%2.2f.png'", "%", "valacc", ".", "max", "(", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "# question type", "\n", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "oa_acc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "qt_dic_list", "=", "[", "l", "[", "4", "]", "for", "l", "in", "results", "]", "\n", "\n", "def", "draw_qt_acc", "(", "target_key_list", ",", "figname", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "for", "k", "in", "target_key_list", ":", "\n", "            ", "write_log", "(", "str", "(", "k", ")", "+", "str", "(", "type", "(", "k", ")", ")", ",", "'visualize_log.txt'", ")", "\n", "t_val", "=", "np", ".", "array", "(", "[", "qt_dic", "[", "k", "]", "for", "qt_dic", "in", "qt_dic_list", "]", ")", "\n", "plt", ".", "plot", "(", "it", ",", "t_val", ",", "label", "=", "str", "(", "k", ")", ")", "\n", "", "plt", ".", "legend", "(", "fontsize", "=", "'small'", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "100.", ")", "\n", "#plt.legend(prop={'size':6})", "\n", "\n", "plt", ".", "xlabel", "(", "'Iterations'", ")", "\n", "plt", ".", "ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "figname", ",", "dpi", "=", "200", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "", "if", "save_question_type_graphs", ":", "\n", "        ", "s_keys", "=", "sorted", "(", "qt_dic_list", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "0", ":", "13", "]", "+", "[", "s_keys", "[", "31", "]", ",", "]", ",", "'./ind_qt_are.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "13", ":", "17", "]", "+", "s_keys", "[", "49", ":", "]", ",", "'./ind_qt_how_where_who_why.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "17", ":", "31", "]", "+", "[", "s_keys", "[", "32", "]", ",", "]", ",", "'./ind_qt_is.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "33", ":", "49", "]", ",", "'./ind_qt_what.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what color is the'", ",", "'what color are the'", ",", "'what color is'", ",", "'what color'", ",", "'what is the color of the'", "]", ",", "'./qt_color.png'", ")", "\n", "draw_qt_acc", "(", "[", "'how many'", ",", "'how'", ",", "'how many people are'", ",", "'how many people are in'", "]", ",", "'./qt_number.png'", ")", "\n", "draw_qt_acc", "(", "[", "'who is'", ",", "'why'", ",", "'why is the'", ",", "'where is the'", ",", "'where are the'", ",", "'which'", "]", ",", "'./qt_who_why_where_which.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what is the man'", ",", "'is the man'", ",", "'are they'", ",", "'is he'", ",", "'is the woman'", ",", "'is this person'", ",", "'what is the woman'", ",", "'is the person'", ",", "'what is the person'", "]", ",", "'./qt_human.png'", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log": [[1, 4], ["open", "f.write"], "function", ["None"], ["def", "write_log", "(", "str", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "+", "\"\\n\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.__init__": [[13, 29], ["vqa_data_provider_layer.VQADataProvider.load_data", "len", "open", "json.load", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data"], ["    ", "def", "__init__", "(", "self", ",", "batchsize", "=", "64", ",", "max_length", "=", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "max_w_length", "=", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "batchsize", "=", "batchsize", "\n", "self", ".", "d_vocabulary", "=", "None", "\n", "self", ".", "batch_index", "=", "None", "\n", "self", ".", "batch_len", "=", "None", "\n", "self", ".", "rev_adict", "=", "None", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "max_w_length", "=", "max_w_length", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "qdic", ",", "self", ".", "adic", "=", "VQADataProvider", ".", "load_data", "(", "mode", ")", "\n", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "cdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "vdict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "adict", "=", "json", ".", "load", "(", "f", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_vqa_json": [[32, 55], ["write_to_log.write_log", "open", "json.load", "open", "json.load", "str", "str", "len", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["#self.nlp = spacy.load('en', vectors='en_glove_cc_300_1m_vectors')", "\n", "#self.glove_dict = {} # word -> glove vector", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_vqa_json", "(", "data_split", ")", ":", "\n", "        ", "\"\"\"\n        Parses the question and answer json files for the given data split. \n        Returns the question dictionary and the answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ques_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "[", "'questions'", "]", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "qdic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'question_id'", "]", ")", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image_id'", "]", "}", "\n", "\n", "", "", "if", "'test'", "not", "in", "data_split", ":", "\n", "            ", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'ans_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "adata", "=", "json", ".", "load", "(", "f", ")", "[", "'annotations'", "]", "\n", "for", "a", "in", "adata", ":", "\n", "                    ", "adic", "[", "data_split", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "a", "[", "'question_id'", "]", ")", "]", "=", "a", "[", "'answers'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_genome_json": [[56, 73], ["write_to_log.write_log", "open", "json.load", "str", "str", "len"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["", "", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for '", "+", "data_split", ",", "'log.txt'", ")", "\n", "return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_genome_json", "(", ")", ":", "\n", "        ", "\"\"\"\n        Parses the genome json file. Returns the question dictionary and the\n        answer dictionary.\n        \"\"\"", "\n", "qdic", ",", "adic", "=", "{", "}", ",", "{", "}", "\n", "\n", "with", "open", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'genome_file'", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "qdata", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "q", "in", "qdata", ":", "\n", "                ", "key", "=", "'genome'", "+", "QID_KEY_SEPARATOR", "+", "str", "(", "q", "[", "'id'", "]", ")", "\n", "qdic", "[", "key", "]", "=", "{", "'qstr'", ":", "q", "[", "'question'", "]", ",", "'iid'", ":", "q", "[", "'image'", "]", "}", "\n", "adic", "[", "key", "]", "=", "[", "{", "'answer'", ":", "q", "[", "'answer'", "]", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data": [[74, 88], ["data_split_str.split", "config.DATA_PATHS.keys", "vqa_data_provider_layer.VQADataProvider.load_genome_json", "all_qdic.update", "all_adic.update", "vqa_data_provider_layer.VQADataProvider.load_vqa_json", "all_qdic.update", "all_adic.update"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_genome_json", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_vqa_json"], ["", "", "write_log", "(", "'parsed '", "+", "str", "(", "len", "(", "qdic", ")", ")", "+", "' questions for genome'", ",", "'log.txt'", ")", "\n", "return", "qdic", ",", "adic", "\n", "\n", "", "@", "staticmethod", "\n", "def", "load_data", "(", "data_split_str", ")", ":", "\n", "        ", "all_qdic", ",", "all_adic", "=", "{", "}", ",", "{", "}", "\n", "for", "data_split", "in", "data_split_str", ".", "split", "(", "'+'", ")", ":", "\n", "            ", "assert", "data_split", "in", "config", ".", "DATA_PATHS", ".", "keys", "(", ")", ",", "'unknown data split'", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_genome_json", "(", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n", "all_adic", ".", "update", "(", "adic", ")", "\n", "", "else", ":", "\n", "                ", "qdic", ",", "adic", "=", "VQADataProvider", ".", "load_vqa_json", "(", "data_split", ")", "\n", "all_qdic", ".", "update", "(", "qdic", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds": [[89, 91], ["vqa_data_provider_layer.VQADataProvider.qdic.keys"], "methods", ["None"], ["all_adic", ".", "update", "(", "adic", ")", "\n", "\n", "", "", "return", "all_qdic", ",", "all_adic", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId": [[92, 94], ["qid.split"], "methods", ["None"], ["\n", "", "def", "getQuesIds", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "qdic", ".", "keys", "(", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId": [[95, 97], ["None"], "methods", ["None"], ["\n", "", "def", "getStrippedQuesId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "[", "1", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr": [[98, 100], ["None"], "methods", ["None"], ["\n", "", "def", "getImgId", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'iid'", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj": [[101, 105], ["None"], "methods", ["None"], ["\n", "", "def", "getQuesStr", "(", "self", ",", "qid", ")", ":", "\n", "        ", "return", "self", ".", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n", "\n", "", "def", "getAnsObj", "(", "self", ",", "qid", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list": [[106, 116], ["s.lower", "re.sub().split", "filter", "re.sub", "re.sub", "re.sub", "re.sub.lower", "len"], "methods", ["None"], ["        ", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "", "return", "self", ".", "adic", "[", "qid", "]", "\n", "\n", "", "@", "staticmethod", "\n", "def", "seq_to_list", "(", "s", ")", ":", "\n", "        ", "t_str", "=", "s", ".", "lower", "(", ")", "\n", "for", "i", "in", "[", "r'\\?'", ",", "r'\\!'", ",", "r'\\''", ",", "r'\\\"'", ",", "r'\\$'", ",", "r'\\:'", ",", "r'\\@'", ",", "r'\\('", ",", "r'\\)'", ",", "r'\\,'", ",", "r'\\.'", ",", "r'\\;'", "]", ":", "\n", "            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "''", ",", "t_str", ")", "\n", "", "for", "i", "in", "[", "r'\\-'", ",", "r'\\/'", "]", ":", "\n", "            ", "t_str", "=", "re", ".", "sub", "(", "i", ",", "' '", ",", "t_str", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer": [[117, 130], ["dic.has_key", "max", "xrange", "dic.items"], "methods", ["None"], ["", "q_list", "=", "re", ".", "sub", "(", "r'\\?'", ",", "''", ",", "t_str", ".", "lower", "(", ")", ")", ".", "split", "(", "' '", ")", "\n", "q_list", "=", "filter", "(", "lambda", "x", ":", "len", "(", "x", ")", ">", "0", ",", "q_list", ")", "\n", "return", "q_list", "\n", "\n", "", "def", "extract_answer", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "", "answer_list", "=", "[", "answer_obj", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "dic", "=", "{", "}", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "dic", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "dic", "[", "ans", "]", "+=", "1", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer_prob": [[131, 149], ["vqa_data_provider_layer.VQADataProvider.adict.has_key", "len", "random.choice", "prob_answer_list.append", "Exception"], "methods", ["None"], ["                ", "dic", "[", "ans", "]", "=", "1", "\n", "", "", "max_key", "=", "max", "(", "(", "v", ",", "k", ")", "for", "(", "k", ",", "v", ")", "in", "dic", ".", "items", "(", ")", ")", "[", "1", "]", "\n", "return", "max_key", "\n", "\n", "", "def", "extract_answer_prob", "(", "self", ",", "answer_obj", ")", ":", "\n", "        ", "\"\"\" Return the most popular answer in string.\"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "prob_answer_list", "=", "[", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "            ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n", "                ", "prob_answer_list", ".", "append", "(", "ans", ")", "\n", "\n", "", "", "if", "len", "(", "prob_answer_list", ")", "==", "0", ":", "\n", "            ", "if", "self", ".", "mode", "==", "'val'", "or", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "                ", "return", "'hoge'", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.qlist_to_vec": [[150, 182], ["numpy.zeros", "numpy.zeros", "xrange", "len", "vqa_data_provider_layer.VQADataProvider.vdict.has_key", "len", "len"], "methods", ["None"], ["                ", "raise", "Exception", "(", "\"This should not happen.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "random", ".", "choice", "(", "prob_answer_list", ")", "\n", "\n", "# def qlist_to_vec(self, max_length, q_list):", "\n", "#     \"\"\"", "\n", "#     Converts a list of words into a format suitable for the embedding layer.", "\n", "\n", "#     Arguments:", "\n", "#     max_length -- the maximum length of a question sequence", "\n", "#     q_list -- a list of words which are the tokens in the question", "\n", "\n", "#     Returns:", "\n", "#     qvec -- A max_length length vector containing one-hot indices for each word", "\n", "#     cvec -- A max_length length sequence continuation indicator vector", "\n", "#     glove_matrix -- A max_length x GLOVE_EMBEDDING_SIZE matrix containing the glove embedding for", "\n", "#         each word", "\n", "#     \"\"\"", "\n", "#     qvec = np.zeros(max_length)", "\n", "#     cvec = np.zeros(max_length)", "\n", "#     glove_matrix = np.zeros(max_length * GLOVE_EMBEDDING_SIZE).reshape(max_length, GLOVE_EMBEDDING_SIZE)", "\n", "#     for i in xrange(max_length):", "\n", "#         if i < max_length - len(q_list):", "\n", "#             cvec[i] = 0", "\n", "#         else:", "\n", "#             w = q_list[i-(max_length-len(q_list))]", "\n", "#             if w not in self.glove_dict:", "\n", "#                 self.glove_dict[w] = self.nlp(u'%s' % w).vector", "\n", "#             glove_matrix[i] = self.glove_dict[w]", "\n", "#             # is the word in the vocabulary?", "\n", "#             if self.vdict.has_key(w) is False:", "\n", "#                 w = ''", "\n", "#             qvec[i] = self.vdict[w]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.answer_to_vec": [[183, 193], ["vqa_data_provider_layer.VQADataProvider.adict.has_key"], "methods", ["None"], ["#             cvec[i] = 1 #0 if i == max_length - len(q_list) else 1", "\n", "#             # UPDATE_10/12:", "\n", "#             #It seems that the original way is right for lstm.", "\n", "#             '''", "\n", "#             This is from https://github.com/BVLC/caffe/pull/1873.", "\n", "#             \"delta_{t,n} should be a binary indicator (i.e., value in {0, 1}),", "\n", "#             where a value of 0 means that timestep t of stream n is the beginning of a new sequence,", "\n", "#             and a value of 1 means that timestep t of stream n is continuing the sequence from timestep t-1 of stream n.", "\n", "#             Under the hood, the previous timestep's hidden state is multiplied by these delta values.", "\n", "#             The fact that these indicators are specified on a per-timestep and per-stream basis allows for streams of arbitrary different lengths without any padding or truncation.", "\n", "#             At the beginning of the forward pass, the final hidden state from the previous forward pass (h_T) is copied into the initial hidden state for the new forward pass (h_0),", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer": [[194, 203], ["vqa_data_provider_layer.VQADataProvider.adict.items"], "methods", ["None"], ["#             allowing for exact inference across arbitrarily long sequences, even if T == 1.", "\n", "#             However, if any sequences cross batch boundaries, backpropagation through time is approximate -- it is truncated along the batch boundaries.\"", "\n", "#             '''", "\n", "#             # I think the original way is false for CNN here. I want to keep the word embedding for unknown word as zero vector.", "\n", "#             # For example, if we have a sentence of length 7, there would be only 6 1's in cvec.", "\n", "\n", "#     return qvec, cvec, glove_matrix", "\n", "\n", "", "", "def", "qlist_to_vec", "(", "self", ",", "max_length", ",", "max_w_length", ",", "q_list", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.create_batch": [[204, 251], ["numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "numpy.zeros().reshape", "enumerate", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "vqa_data_provider_layer.VQADataProvider.answer_to_vec", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "qid.split", "vqa_data_provider_layer.VQADataProvider.extract_answer", "vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "numpy.sqrt", "write_to_log.write_log", "numpy.load", "numpy.load", "str", "str().zfill", "str", "str"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.qlist_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.answer_to_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.extract_answer_prob", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["\n", "qvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "cvec", "=", "np", ".", "zeros", "(", "max_length", ")", "\n", "qcvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "ccvec", "=", "np", ".", "zeros", "(", "max_w_length", "*", "max_length", ")", "\n", "for", "i", "in", "xrange", "(", "max_length", ")", ":", "\n", "            ", "if", "i", "<", "max_length", "-", "len", "(", "q_list", ")", ":", "\n", "                ", "cvec", "[", "i", "]", "=", "0", "\n", "", "else", ":", "\n", "                ", "w", "=", "q_list", "[", "i", "-", "(", "max_length", "-", "len", "(", "q_list", ")", ")", "]", "\n", "# is the word in the vocabulary?", "\n", "if", "self", ".", "vdict", ".", "has_key", "(", "w", ")", "is", "False", ":", "\n", "                    ", "w", "=", "''", "\n", "", "qvec", "[", "i", "]", "=", "self", ".", "vdict", "[", "w", "]", "\n", "cvec", "[", "i", "]", "=", "1.0", "/", "len", "(", "q_list", ")", "\n", "j", "=", "max_w_length", "*", "i", "\n", "w_list", "=", "list", "(", "w", ")", "\n", "for", "k", "in", "xrange", "(", "max_w_length", ")", ":", "\n", "                    ", "if", "k", "<", "max_w_length", "-", "len", "(", "w_list", ")", ":", "\n", "                        ", "ccvec", "[", "j", "+", "k", "]", "=", "0", "\n", "", "else", ":", "\n", "                        ", "c", "=", "w_list", "[", "k", "-", "(", "max_w_length", "-", "len", "(", "w_list", ")", ")", "]", "\n", "# is the char in the vocabulary?", "\n", "if", "self", ".", "cdict", ".", "has_key", "(", "c", ")", "is", "False", ":", "\n", "                            ", "c", "=", "''", "\n", "", "qcvec", "[", "j", "+", "k", "]", "=", "self", ".", "cdict", "[", "c", "]", "\n", "ccvec", "[", "j", "+", "k", "]", "=", "1.0", "/", "len", "(", "w_list", ")", "\n", "", "", "", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", "\n", "\n", "", "def", "answer_to_vec", "(", "self", ",", "ans_str", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "mode", "==", "'test-dev'", "or", "self", ".", "mode", "==", "'test'", ":", "\n", "            ", "return", "-", "1", "\n", "\n", "", "if", "self", ".", "adict", ".", "has_key", "(", "ans_str", ")", ":", "\n", "            ", "ans", "=", "self", ".", "adict", "[", "ans_str", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec": [[253, 300], ["vqa_data_provider_layer.VQADataProvider.create_batch", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "random.shuffle", "len", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "vqa_data_provider_layer.VQADataProvider.getImgId", "vqa_data_provider_layer.VQADataProvider.adict.has_key", "t_qid_list.append", "t_iid_list.append", "vqa_data_provider_layer.VQADataProvider.get_batch_vec.has_at_least_one_valid_answer"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.create_batch", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getImgId"], ["            ", "ans", "=", "self", ".", "adict", "[", "''", "]", "\n", "", "return", "ans", "\n", "\n", "", "def", "vec_to_answer", "(", "self", ",", "ans_symbol", ")", ":", "\n", "        ", "\"\"\" Return answer id if the answer is included in vocabulary otherwise '' \"\"\"", "\n", "if", "self", ".", "rev_adict", "is", "None", ":", "\n", "            ", "rev_adict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "adict", ".", "items", "(", ")", ":", "\n", "                ", "rev_adict", "[", "v", "]", "=", "k", "\n", "", "self", ".", "rev_adict", "=", "rev_adict", "\n", "\n", "", "return", "self", ".", "rev_adict", "[", "ans_symbol", "]", "\n", "\n", "", "def", "create_batch", "(", "self", ",", "qid_list", ")", ":", "\n", "\n", "        ", "qvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "cvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_length", ")", "\n", "qcvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ccvec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "self", ".", "max_w_length", "*", "self", ".", "max_length", ")", "\n", "ivec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", "*", "2048", "*", "14", "*", "14", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ",", "2048", ",", "14", ",", "14", ")", "\n", "avec", "=", "(", "np", ".", "zeros", "(", "self", ".", "batchsize", ")", ")", ".", "reshape", "(", "self", ".", "batchsize", ")", "\n", "#glove_matrix = np.zeros(self.batchsize * self.max_length * GLOVE_EMBEDDING_SIZE).reshape(\\", "\n", "#self.batchsize, self.max_length, GLOVE_EMBEDDING_SIZE)", "\n", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "\n", "# load raw question information", "\n", "            ", "q_str", "=", "self", ".", "getQuesStr", "(", "qid", ")", "\n", "q_ans", "=", "self", ".", "getAnsObj", "(", "qid", ")", "\n", "q_iid", "=", "self", ".", "getImgId", "(", "qid", ")", "\n", "\n", "# convert question to vec", "\n", "q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "t_qvec", ",", "t_cvec", ",", "t_qcvec", ",", "t_ccvec", "=", "self", ".", "qlist_to_vec", "(", "self", ".", "max_length", ",", "self", ".", "max_w_length", ",", "q_list", ")", "\n", "\n", "try", ":", "\n", "                ", "qid_split", "=", "qid", ".", "split", "(", "QID_KEY_SEPARATOR", ")", "\n", "data_split", "=", "qid_split", "[", "0", "]", "\n", "if", "data_split", "==", "'genome'", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "'genome'", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "else", ":", "\n", "                    ", "t_ivec", "=", "np", ".", "load", "(", "config", ".", "DATA_PATHS", "[", "data_split", "]", "[", "'features_prefix'", "]", "+", "str", "(", "q_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg.npz'", ")", "[", "'x'", "]", "\n", "", "t_ivec", "=", "(", "t_ivec", "/", "np", ".", "sqrt", "(", "(", "t_ivec", "**", "2", ")", ".", "sum", "(", ")", ")", ")", "\n", "", "except", ":", "\n", "                ", "t_ivec", "=", "0.", "\n", "write_log", "(", "'data not found for qid : '", "+", "str", "(", "q_iid", ")", "+", "' '", "+", "self", ".", "mode", ",", "'log.txt'", ")", "\n", "\n", "# convert answer to vec", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.setup": [[307, 322], ["top[].reshape", "top[].reshape", "top[].reshape", "top[].reshape", "json.loads", "json.loads", "vqa_data_provider_layer.VQADataProvider"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape"], ["qvec", "[", "i", ",", "...", "]", "=", "t_qvec", "\n", "cvec", "[", "i", ",", "...", "]", "=", "t_cvec", "\n", "qcvec", "[", "i", ",", "...", "]", "=", "t_qcvec", "\n", "ccvec", "[", "i", ",", "...", "]", "=", "t_ccvec", "\n", "ivec", "[", "i", ",", "...", "]", "=", "t_ivec", "\n", "avec", "[", "i", ",", "...", "]", "=", "t_avec", "\n", "#glove_matrix[i,...] = t_glove_matrix", "\n", "\n", "", "return", "qvec", ",", "cvec", ",", "qcvec", ",", "ccvec", ",", "ivec", ",", "avec", "#, glove_matrix", "\n", "\n", "\n", "", "def", "get_batch_vec", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "batch_len", "is", "None", ":", "\n", "            ", "self", ".", "n_skipped", "=", "0", "\n", "qid_list", "=", "self", ".", "getQuesIds", "(", ")", "\n", "random", ".", "shuffle", "(", "qid_list", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.reshape": [[323, 325], ["None"], "methods", ["None"], ["self", ".", "qid_list", "=", "qid_list", "\n", "self", ".", "batch_len", "=", "len", "(", "qid_list", ")", "\n", "self", ".", "batch_index", "=", "0", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.forward": [[326, 336], ["vqa_data_provider_layer.VQADataProviderLayer.dp.get_batch_vec", "numpy.transpose", "numpy.transpose"], "methods", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec"], ["self", ".", "epoch_counter", "=", "0", "\n", "\n", "", "def", "has_at_least_one_valid_answer", "(", "t_qid", ")", ":", "\n", "            ", "answer_obj", "=", "self", ".", "getAnsObj", "(", "t_qid", ")", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "for", "ans", "in", "answer_list", ":", "\n", "                ", "if", "self", ".", "adict", ".", "has_key", "(", "ans", ")", ":", "\n", "                    ", "return", "True", "\n", "\n", "", "", "", "counter", "=", "0", "\n", "t_qid_list", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.backward": [[338, 340], ["None"], "methods", ["None"], ["while", "counter", "<", "self", ".", "batchsize", ":", "\n", "            ", "t_qid", "=", "self", ".", "qid_list", "[", "self", ".", "batch_index", "]", "\n", "t_iid", "=", "self", ".", "getImgId", "(", "t_qid", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm": [[19, 109], ["caffe.NetSpec", "json.dumps", "caffe.layers.Python", "caffe.layers.Embed", "caffe.layers.TanH", "caffe.layers.LSTM", "caffe.layers.Slice", "xrange", "caffe.layers.Reshape", "caffe.layers.Dropout", "caffe.layers.Dropout", "caffe.layers.LSTM", "caffe.layers.Slice", "xrange", "caffe.layers.Reshape", "caffe.layers.Dropout", "caffe.layers.Concat", "caffe.layers.Reshape", "caffe.layers.Tile", "caffe.layers.Tile", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Convolution", "caffe.layers.ReLU", "caffe.layers.Convolution", "caffe.layers.Reshape", "caffe.layers.Softmax", "caffe.layers.Reshape", "caffe.layers.Slice", "caffe.layers.DummyData", "caffe.layers.SoftAttention", "caffe.layers.SoftAttention", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.Concat", "caffe.layers.Reshape", "caffe.layers.Reshape", "caffe.layers.CompactBilinear", "caffe.layers.SignedSqrt", "caffe.layers.L2Normalize", "caffe.layers.Dropout", "caffe.layers.Reshape", "caffe.layers.InnerProduct", "caffe.layers.SoftmaxWithLoss", "caffe.NetSpec.to_proto", "caffe.NetSpec.__setattr__", "caffe.NetSpec.__setattr__", "caffe.NetSpec.__setattr__", "caffe.NetSpec.__setattr__", "dict", "dict", "caffe.layers.Silence", "dict", "dict", "caffe.layers.Silence", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "str", "str", "str", "str", "dict", "dict", "int", "dict", "dict", "dict", "int", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "int", "int", "config.TRAIN_DATA_SPLITS", "config.BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION", "config.VAL_BATCH_SIZE", "config.MAX_WORDS_IN_QUESTION"], "function", ["None"], ["def", "qlstm", "(", "mode", ",", "batchsize", ",", "T", ",", "T_c", ",", "question_c_vocab_size", ",", "question_vocab_size", ")", ":", "\n", "    ", "n", "=", "caffe", ".", "NetSpec", "(", ")", "\n", "mode_str", "=", "json", ".", "dumps", "(", "{", "'mode'", ":", "mode", ",", "'batchsize'", ":", "batchsize", "}", ")", "\n", "n", ".", "data", ",", "n", ".", "cont", ",", "n", ".", "data1", ",", "n", ".", "cont1", ",", "n", ".", "img_feature", ",", "n", ".", "label", "=", "L", ".", "Python", "(", "module", "=", "'vqa_data_provider_layer'", ",", "layer", "=", "'VQADataProviderLayer'", ",", "param_str", "=", "mode_str", ",", "ntop", "=", "6", ")", "#5 )", "\n", "\n", "# char embedding", "\n", "n", ".", "embed_c", "=", "L", ".", "Embed", "(", "n", ".", "data1", ",", "input_dim", "=", "question_c_vocab_size", ",", "num_output", "=", "100", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "\n", "n", ".", "embed_c_scale", "=", "L", ".", "Scale", "(", "n", ".", "embed_c", ",", "n", ".", "cont1", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "\n", "n", ".", "embed_c_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_c_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T_c", "*", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T_c*T x d_c x 1", "\n", "tops", "=", "L", ".", "Slice", "(", "n", ".", "embed_c_scale_resh", ",", "ntop", "=", "T", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T_c x d_c x 1", "\n", "for", "i", "in", "xrange", "(", "T", ")", ":", "\n", "        ", "n", ".", "__setattr__", "(", "'Slice_'", "+", "str", "(", "i", "+", "1", ")", ",", "tops", "[", "int", "(", "i", ")", "]", ")", "\n", "\n", "# avg of char embedding", "\n", "", "n", ".", "c_embed_1", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_1", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_2", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_2", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_3", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_3", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_4", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_4", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_5", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_5", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_6", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_6", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_7", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_7", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_8", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_8", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_9", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_9", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_10", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_10", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_11", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_11", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_12", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_12", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_13", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_13", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_14", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_14", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_15", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_15", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_16", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_16", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_17", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_17", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_18", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_18", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_19", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_19", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_20", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_20", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_21", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_21", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "n", ".", "c_embed_22", "=", "L", ".", "Convolution", "(", "n", ".", "Slice_22", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x d_c x 1", "\n", "\n", "concat_c_embed", "=", "[", "n", ".", "c_embed_1", ",", "n", ".", "c_embed_2", ",", "n", ".", "c_embed_3", ",", "n", ".", "c_embed_4", ",", "n", ".", "c_embed_5", ",", "n", ".", "c_embed_6", ",", "n", ".", "c_embed_7", ",", "n", ".", "c_embed_8", ",", "n", ".", "c_embed_9", ",", "n", ".", "c_embed_10", ",", "n", ".", "c_embed_11", ",", "n", ".", "c_embed_12", ",", "n", ".", "c_embed_13", ",", "n", ".", "c_embed_14", ",", "n", ".", "c_embed_15", ",", "n", ".", "c_embed_16", ",", "n", ".", "c_embed_17", ",", "n", ".", "c_embed_18", ",", "n", ".", "c_embed_19", ",", "n", ".", "c_embed_20", ",", "n", ".", "c_embed_21", ",", "n", ".", "c_embed_22", "]", "\n", "n", ".", "concat_char_embed", "=", "L", ".", "Concat", "(", "*", "concat_c_embed", ",", "concat_param", "=", "{", "'axis'", ":", "1", "}", ")", "# N x T x d_c x 1", "\n", "n", ".", "concat_char_embed_resh", "=", "L", ".", "Reshape", "(", "n", ".", "concat_char_embed", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", "]", ")", ")", ")", "\n", "\n", "# word embedding", "\n", "n", ".", "embed_w", "=", "L", ".", "Embed", "(", "n", ".", "data", ",", "input_dim", "=", "question_vocab_size", ",", "num_output", "=", "200", ",", "weight_filler", "=", "dict", "(", "type", "=", "'uniform'", ",", "min", "=", "-", "0.08", ",", "max", "=", "0.08", ")", ")", "# N x T x d_w", "\n", "\n", "# combine word and char embedding", "\n", "concat_word_embed", "=", "[", "n", ".", "embed_w", ",", "n", ".", "concat_char_embed_resh", "]", "\n", "n", ".", "concat_embed", "=", "L", ".", "Concat", "(", "*", "concat_word_embed", ",", "concat_param", "=", "{", "'axis'", ":", "2", "}", ")", "# N x T x (d_c+d_w)", "\n", "\n", "n", ".", "embed_scale", "=", "L", ".", "Scale", "(", "n", ".", "concat_embed", ",", "n", ".", "cont", ",", "scale_param", "=", "dict", "(", "dict", "(", "axis", "=", "0", ")", ")", ")", "# N x T x (d_c+d_w)", "\n", "n", ".", "embed_scale_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_scale", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "T", ",", "-", "1", ",", "1", "]", ")", ")", ")", "# N x T x (d_c+d_w) x 1", "\n", "\n", "# avg of word embedding", "\n", "n", ".", "embed_avg", "=", "L", ".", "Convolution", "(", "n", ".", "embed_scale_resh", ",", "convolution_param", "=", "{", "'kernel_size'", ":", "1", ",", "'num_output'", ":", "1", ",", "'bias_term'", ":", "False", ",", "'weight_filler'", ":", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", "}", ",", "param", "=", "dict", "(", "lr_mult", "=", "0", ",", "decay_mult", "=", "0", ")", ")", "# N x 1 x (d_c+d_w) x 1", "\n", "n", ".", "embed_avg_resh", "=", "L", ".", "Reshape", "(", "n", ".", "embed_avg", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "300", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled_1", "=", "L", ".", "Tile", "(", "n", ".", "embed_avg_resh", ",", "axis", "=", "2", ",", "tiles", "=", "14", ")", "\n", "n", ".", "q_emb_tanh_droped_resh_tiled", "=", "L", ".", "Tile", "(", "n", ".", "q_emb_tanh_droped_resh_tiled_1", ",", "axis", "=", "3", ",", "tiles", "=", "14", ")", "\n", "n", ".", "i_emb_tanh_droped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "img_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "n", ".", "blcf", "=", "L", ".", "CompactBilinear", "(", "n", ".", "q_emb_tanh_droped_resh_tiled", ",", "n", ".", "i_emb_tanh_droped_resh", ",", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "blcf_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "blcf", ")", "\n", "n", ".", "blcf_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "blcf_sign_sqrt", ")", "\n", "n", ".", "blcf_droped", "=", "L", ".", "Dropout", "(", "n", ".", "blcf_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "\n", "# multi-channel attention", "\n", "n", ".", "att_conv1", "=", "L", ".", "Convolution", "(", "n", ".", "blcf_droped", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "512", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_conv1_relu", "=", "L", ".", "ReLU", "(", "n", ".", "att_conv1", ")", "\n", "n", ".", "att_conv2", "=", "L", ".", "Convolution", "(", "n", ".", "att_conv1_relu", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "num_output", "=", "2", ",", "pad", "=", "0", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "att_reshaped", "=", "L", ".", "Reshape", "(", "n", ".", "att_conv2", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", "*", "14", "]", ")", ")", ")", "\n", "n", ".", "att_softmax", "=", "L", ".", "Softmax", "(", "n", ".", "att_reshaped", ",", "axis", "=", "2", ")", "\n", "n", ".", "att", "=", "L", ".", "Reshape", "(", "n", ".", "att_softmax", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2", ",", "14", ",", "14", "]", ")", ")", ")", "\n", "att_maps", "=", "L", ".", "Slice", "(", "n", ".", "att", ",", "ntop", "=", "2", ",", "slice_param", "=", "{", "'axis'", ":", "1", "}", ")", "\n", "n", ".", "att_map0", "=", "att_maps", "[", "0", "]", "\n", "n", ".", "att_map1", "=", "att_maps", "[", "1", "]", "\n", "dummy", "=", "L", ".", "DummyData", "(", "shape", "=", "dict", "(", "dim", "=", "[", "batchsize", ",", "1", "]", ")", ",", "data_filler", "=", "dict", "(", "type", "=", "'constant'", ",", "value", "=", "1", ")", ",", "ntop", "=", "1", ")", "\n", "n", ".", "att_feature0", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map0", ",", "dummy", ")", "\n", "n", ".", "att_feature1", "=", "L", ".", "SoftAttention", "(", "n", ".", "i_emb_tanh_droped_resh", ",", "n", ".", "att_map1", ",", "dummy", ")", "\n", "n", ".", "att_feature0_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature0", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature1_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature1", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "2048", "]", ")", ")", ")", "\n", "n", ".", "att_feature", "=", "L", ".", "Concat", "(", "n", ".", "att_feature0_resh", ",", "n", ".", "att_feature1_resh", ")", "\n", "\n", "# merge attention and lstm with compact bilinear pooling", "\n", "n", ".", "att_feature_resh", "=", "L", ".", "Reshape", "(", "n", ".", "att_feature", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "4096", ",", "1", ",", "1", "]", ")", ")", ")", "\n", "#n.lstm_12_resh = L.Reshape(n.lstm_12, reshape_param=dict(shape=dict(dim=[-1,2048,1,1])))", "\n", "n", ".", "bc_att_lstm", "=", "L", ".", "CompactBilinear", "(", "n", ".", "att_feature_resh", ",", "n", ".", "embed_avg_resh", ",", "\n", "compact_bilinear_param", "=", "dict", "(", "num_output", "=", "16000", ",", "sum_pool", "=", "False", ")", ")", "\n", "n", ".", "bc_sign_sqrt", "=", "L", ".", "SignedSqrt", "(", "n", ".", "bc_att_lstm", ")", "\n", "n", ".", "bc_sign_sqrt_l2", "=", "L", ".", "L2Normalize", "(", "n", ".", "bc_sign_sqrt", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_answer_vocab": [[110, 147], ["adic.keys", "sorted", "enumerate", "enumerate", "nadict.items", "nalist.append", "adict.has_key", "config.NUM_OUTPUT_UNITS"], "function", ["None"], ["\n", "n", ".", "bc_dropped", "=", "L", ".", "Dropout", "(", "n", ".", "bc_sign_sqrt_l2", ",", "dropout_param", "=", "{", "'dropout_ratio'", ":", "0.1", "}", ")", "\n", "n", ".", "bc_dropped_resh", "=", "L", ".", "Reshape", "(", "n", ".", "bc_dropped", ",", "reshape_param", "=", "dict", "(", "shape", "=", "dict", "(", "dim", "=", "[", "-", "1", ",", "16000", "]", ")", ")", ")", "\n", "\n", "n", ".", "prediction", "=", "L", ".", "InnerProduct", "(", "n", ".", "bc_dropped_resh", ",", "num_output", "=", "3000", ",", "weight_filler", "=", "dict", "(", "type", "=", "'xavier'", ")", ")", "\n", "n", ".", "loss", "=", "L", ".", "SoftmaxWithLoss", "(", "n", ".", "prediction", ",", "n", ".", "label", ")", "\n", "return", "n", ".", "to_proto", "(", ")", "\n", "\n", "", "def", "make_answer_vocab", "(", "adic", ",", "vocab_size", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "adict", "=", "{", "''", ":", "0", "}", "\n", "nadict", "=", "{", "''", ":", "1000000", "}", "\n", "vid", "=", "1", "\n", "for", "qid", "in", "adic", ".", "keys", "(", ")", ":", "\n", "        ", "answer_obj", "=", "adic", "[", "qid", "]", "\n", "answer_list", "=", "[", "ans", "[", "'answer'", "]", "for", "ans", "in", "answer_obj", "]", "\n", "\n", "for", "q_ans", "in", "answer_list", ":", "\n", "# create dict", "\n", "            ", "if", "adict", ".", "has_key", "(", "q_ans", ")", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "nadict", "[", "q_ans", "]", "=", "1", "\n", "adict", "[", "q_ans", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "\n", "# debug", "\n", "", "", "", "nalist", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "sorted", "(", "nadict", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ":", "\n", "        ", "nalist", ".", "append", "(", "(", "k", ",", "v", ")", ")", "\n", "\n", "# keep the top 3000 answers", "\n", "", "n_del_ans", "=", "0", "\n", "n_valid_ans", "=", "0", "\n", "adict_nid", "=", "{", "}", "\n", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", ":", "-", "vocab_size", "]", ")", ":", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_question_vocab": [[148, 166], ["qdic.keys", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "vdict.has_key"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list"], ["        ", "del", "adict", "[", "w", "[", "0", "]", "]", "\n", "n_del_ans", "+=", "w", "[", "1", "]", "\n", "", "for", "i", ",", "w", "in", "enumerate", "(", "nalist", "[", "-", "vocab_size", ":", "]", ")", ":", "\n", "        ", "n_valid_ans", "+=", "w", "[", "1", "]", "\n", "adict_nid", "[", "w", "[", "0", "]", "]", "=", "i", "\n", "\n", "", "return", "adict_nid", "\n", "\n", "", "def", "make_question_vocab", "(", "qdic", ")", ":", "\n", "    ", "\"\"\"\n    Returns a dictionary that maps words to indices.\n    \"\"\"", "\n", "vdict", "=", "{", "''", ":", "0", "}", "\n", "vid", "=", "1", "\n", "cdict", "=", "{", "''", ":", "0", "}", "\n", "cvid", "=", "1", "\n", "for", "qid", "in", "qdic", ".", "keys", "(", ")", ":", "\n", "# sequence to list", "\n", "        ", "q_str", "=", "qdic", "[", "qid", "]", "[", "'qstr'", "]", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_vocab_files": [[167, 178], ["write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_question_vocab", "write_to_log.write_log", "vqa_data_provider_layer.VQADataProvider.load_data", "train_att_bc.make_answer_vocab"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_question_vocab", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.load_data", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_answer_vocab"], ["q_list", "=", "VQADataProvider", ".", "seq_to_list", "(", "q_str", ")", "\n", "\n", "# create dict", "\n", "for", "w", "in", "q_list", ":", "\n", "            ", "if", "not", "vdict", ".", "has_key", "(", "w", ")", ":", "\n", "                ", "vdict", "[", "w", "]", "=", "vid", "\n", "vid", "+=", "1", "\n", "", "for", "c", "in", "list", "(", "w", ")", ":", "\n", "                ", "if", "not", "cdict", ".", "has_key", "(", "c", ")", ":", "\n", "                    ", "cdict", "[", "c", "]", "=", "cvid", "\n", "cvid", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.main": [[179, 239], ["write_to_log.write_log", "write_to_log.write_log", "caffe.set_device", "caffe.set_mode_gpu", "caffe.get_solver", "numpy.zeros", "range", "os.path.exists", "os.makedirs", "os.path.exists", "os.path.exists", "write_to_log.write_log", "train_att_bc.make_vocab_files", "open", "f.write", "open", "f.write", "caffe.get_solver.step", "open", "json.load", "open", "json.load", "open", "json.dump", "open", "json.dump", "str", "str", "str", "str", "write_to_log.write_log", "write_to_log.write_log", "train_loss[].mean", "write_to_log.write_log", "caffe.get_solver.test_nets[].save", "write_to_log.write_log", "visualize_tools.exec_validation", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "train_att_bc.qlstm", "train_att_bc.qlstm", "write_to_log.write_log", "write_to_log.write_log", "len", "len", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.make_vocab_files", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.exec_validation", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).train_att_bc.qlstm", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["", "", "", "", "return", "vdict", ",", "cdict", "\n", "\n", "", "def", "make_vocab_files", "(", ")", ":", "\n", "    ", "\"\"\"\n    Produce the question and answer vocabulary files.\n    \"\"\"", "\n", "write_log", "(", "'making question vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "write_log", "(", "'making question character vocab... '", "+", "config", ".", "QUESTION_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "qdic", ",", "_", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "QUESTION_VOCAB_SPACE", ")", "\n", "question_vocab", ",", "question_char_vocab", "=", "make_question_vocab", "(", "qdic", ")", "\n", "write_log", "(", "'making answer vocab... '", "+", "config", ".", "ANSWER_VOCAB_SPACE", ",", "'log.txt'", ")", "\n", "_", ",", "adic", "=", "VQADataProvider", ".", "load_data", "(", "config", ".", "ANSWER_VOCAB_SPACE", ")", "\n", "answer_vocab", "=", "make_answer_vocab", "(", "adic", ",", "config", ".", "NUM_OUTPUT_UNITS", ")", "\n", "return", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "'./result'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'./result'", ")", "\n", "\n", "", "question_vocab", ",", "answer_vocab", "=", "{", "}", ",", "{", "}", "\n", "if", "os", ".", "path", ".", "exists", "(", "'./result/cdict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/adict.json'", ")", "and", "os", ".", "path", ".", "exists", "(", "'./result/vdict.json'", ")", ":", "\n", "        ", "write_log", "(", "'restoring vocab'", ",", "'log.txt'", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_char_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "question_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "answer_vocab", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "question_vocab", ",", "question_char_vocab", ",", "answer_vocab", "=", "make_vocab_files", "(", ")", "\n", "with", "open", "(", "'./result/cdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_char_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/vdict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "question_vocab", ",", "f", ")", "\n", "", "with", "open", "(", "'./result/adict.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "answer_vocab", ",", "f", ")", "\n", "\n", "", "", "write_log", "(", "'question character vocab size: '", "+", "str", "(", "len", "(", "question_char_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'question vocab size: '", "+", "str", "(", "len", "(", "question_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "write_log", "(", "'answer vocab size: '", "+", "str", "(", "len", "(", "answer_vocab", ")", ")", ",", "'log.txt'", ")", "\n", "\n", "\n", "with", "open", "(", "'./result/proto_train.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "config", ".", "TRAIN_DATA_SPLITS", ",", "config", ".", "BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "with", "open", "(", "'./result/proto_test.prototxt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "qlstm", "(", "'val'", ",", "config", ".", "VAL_BATCH_SIZE", ",", "config", ".", "MAX_WORDS_IN_QUESTION", ",", "config", ".", "LENGTH_OF_LONGEST_WORD", ",", "len", "(", "question_char_vocab", ")", ",", "len", "(", "question_vocab", ")", ")", ")", ")", "\n", "\n", "", "caffe", ".", "set_device", "(", "config", ".", "GPU_ID", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "solver", "=", "caffe", ".", "get_solver", "(", "'./qlstm_solver.prototxt'", ")", "\n", "\n", "train_loss", "=", "np", ".", "zeros", "(", "config", ".", "MAX_ITERATIONS", ")", "\n", "# results = []", "\n", "\n", "for", "it", "in", "range", "(", "config", ".", "MAX_ITERATIONS", ")", ":", "\n", "        ", "solver", ".", "step", "(", "1", ")", "\n", "\n", "# store the train loss", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures": [[27, 119], ["write_to_log.write_log", "visualize_tools.visualize_failures.save_qtype"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).write_to_log.write_log"], ["def", "visualize_failures", "(", "stat_list", ",", "mode", ")", ":", "\n", "\n", "    ", "def", "save_qtype", "(", "qtype_list", ",", "save_filename", ",", "mode", ")", ":", "\n", "\n", "        ", "if", "mode", "==", "'val'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./eval'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/val2014'", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test-dev'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "elif", "mode", "==", "'test'", ":", "\n", "            ", "savepath", "=", "os", ".", "path", ".", "join", "(", "'./test'", ",", "save_filename", ")", "\n", "# TODO", "\n", "img_pre", "=", "'/tempspace/zwang6/VQA/Images/mscoco/test2015'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unsupported mode'", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "shutil", ".", "rmtree", "(", "savepath", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "savepath", ")", ":", "os", ".", "makedirs", "(", "savepath", ")", "\n", "\n", "for", "qt", "in", "qtype_list", ":", "\n", "            ", "count", "=", "0", "\n", "for", "t_question", "in", "stat_list", ":", "\n", "#print count, t_question", "\n", "                ", "if", "count", "<", "40", "/", "len", "(", "qtype_list", ")", ":", "\n", "                    ", "t_question_list", "=", "t_question", "[", "'q_list'", "]", "\n", "saveflag", "=", "False", "\n", "#print 'debug****************************'", "\n", "#print qt", "\n", "#print t_question_list", "\n", "#print t_question_list[0] == qt[0]", "\n", "#print t_question_list[1] == qt[1]", "\n", "if", "t_question_list", "[", "0", "]", "==", "qt", "[", "0", "]", "and", "t_question_list", "[", "1", "]", "==", "qt", "[", "1", "]", ":", "\n", "                        ", "saveflag", "=", "True", "\n", "", "else", ":", "\n", "                        ", "saveflag", "=", "False", "\n", "\n", "", "if", "saveflag", "==", "True", ":", "\n", "                        ", "t_iid", "=", "t_question", "[", "'iid'", "]", "\n", "if", "mode", "==", "'val'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_val2014_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "", "elif", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                            ", "t_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "img_pre", ",", "'COCO_test2015_'", "+", "str", "(", "t_iid", ")", ".", "zfill", "(", "12", ")", "+", "'.jpg'", ")", ")", "\n", "\n", "# for caption", "\n", "#print t_iid", "\n", "#annIds = caps.getAnnIds(t_iid)", "\n", "#anns = caps.loadAnns(annIds)", "\n", "#cap_list = [ann['caption'] for ann in anns]", "\n", "", "ans_list", "=", "t_question", "[", "'ans_list'", "]", "\n", "draw", "=", "ImageDraw", ".", "Draw", "(", "t_img", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "ans_list", ")", ")", ":", "\n", "                            ", "try", ":", "\n", "                                ", "draw", ".", "text", "(", "(", "10", ",", "10", "*", "i", ")", ",", "str", "(", "ans_list", "[", "i", "]", ")", ")", "\n", "", "except", ":", "\n", "                                ", "pass", "\n", "\n", "", "", "ans", "=", "t_question", "[", "'answer'", "]", "\n", "pred", "=", "t_question", "[", "'pred'", "]", "\n", "if", "ans", "==", "-", "1", ":", "\n", "                            ", "pre", "=", "''", "\n", "", "elif", "ans", "==", "pred", ":", "\n", "                            ", "pre", "=", "'correct  '", "\n", "", "else", ":", "\n", "                            ", "pre", "=", "'failure  '", "\n", "#print ' aaa ', ans, pred", "\n", "", "ans", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "ans", ")", ")", "\n", "pred", "=", "re", ".", "sub", "(", "'/'", ",", "' '", ",", "str", "(", "pred", ")", ")", "\n", "img_title", "=", "pre", "+", "str", "(", "' '", ".", "join", "(", "t_question_list", ")", ")", "+", "'.  a_'", "+", "str", "(", "ans", ")", "+", "' p_'", "+", "str", "(", "pred", ")", "+", "'.png'", "\n", "count", "+=", "1", "\n", "write_log", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ",", "'visualize_log.txt'", ")", "\n", "t_img", ".", "save", "(", "os", ".", "path", ".", "join", "(", "savepath", ",", "img_title", ")", ")", "\n", "\n", "", "", "", "", "", "write_log", "(", "'saving colors'", ",", "'visualize_log.txt'", ")", "\n", "qt_color_list", "=", "[", "[", "'what'", ",", "'color'", "]", "]", "\n", "save_qtype", "(", "qt_color_list", ",", "'colors'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving what is'", ",", "'visualize_log.txt'", ")", "\n", "qt_whatis_list", "=", "[", "[", "'what'", ",", "'is'", "]", ",", "[", "'what'", ",", "'kind'", "]", ",", "[", "'what'", ",", "'are'", "]", "]", "\n", "save_qtype", "(", "qt_whatis_list", ",", "'whatis'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving is'", ",", "'visualize_log.txt'", ")", "\n", "qt_is_list", "=", "[", "[", "'is'", ",", "'the'", "]", ",", "[", "'is'", ",", "'this'", "]", ",", "[", "'is'", ",", "'there'", "]", "]", "\n", "save_qtype", "(", "qt_is_list", ",", "'is'", ",", "mode", ")", "\n", "\n", "write_log", "(", "'saving how many'", ",", "'visualize_log.txt'", ")", "\n", "qt_howmany_list", "=", "[", "[", "'how'", ",", "'many'", "]", "]", "\n", "save_qtype", "(", "qt_howmany_list", ",", "'howmany'", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.exec_validation": [[120, 201], ["caffe.set_device", "caffe.set_mode_gpu", "caffe.Net", "vqa_data_provider_layer.VQADataProvider", "len", "numpy.array().mean", "vqa_data_provider_layer.VQADataProvider.getQuesIds", "vqa_data_provider_layer.VQADataProvider.get_batch_vec", "numpy.transpose", "numpy.transpose", "caffe.Net.forward", "caffe.Net.blobs[].data.argmax", "testloss_list.append", "zip", "vqaTools.vqa.VQA", "vqaTools.vqa.VQA.loadRes", "vqaEvaluation.vqaEval.VQAEval", "vqaEvaluation.vqaEval.VQAEval.evaluate", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "t_answer.tolist", "pred_list.append", "numpy.array", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.seq_to_list", "stat_list.append", "open", "json.dump", "visualize_tools.visualize_failures", "int", "vqa_data_provider_layer.VQADataProvider.getQuesStr", "vqa_data_provider_layer.VQADataProvider.vec_to_answer", "str().zfill", "open", "json.dump", "visualize_tools.visualize_failures", "vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "str().zfill", "xrange", "str", "vqa_data_provider_layer.VQADataProvider.getAnsObj", "str"], "function", ["home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesIds", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.get_batch_vec", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProviderLayer.forward", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.seq_to_list", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getQuesStr", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.vec_to_answer", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.visualize_failures", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getStrippedQuesId", "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).vqa_data_provider_layer.VQADataProvider.getAnsObj"], ["", "def", "exec_validation", "(", "device_id", ",", "mode", ",", "it", "=", "''", ",", "visualize", "=", "False", ")", ":", "\n", "\n", "    ", "caffe", ".", "set_device", "(", "device_id", ")", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "net", "=", "caffe", ".", "Net", "(", "'./result/proto_test.prototxt'", ",", "'./result/tmp.caffemodel'", ",", "caffe", ".", "TEST", ")", "\n", "\n", "dp", "=", "VQADataProvider", "(", "mode", "=", "mode", ",", "batchsize", "=", "config", ".", "VAL_BATCH_SIZE", ")", "\n", "total_questions", "=", "len", "(", "dp", ".", "getQuesIds", "(", ")", ")", "\n", "epoch", "=", "0", "\n", "\n", "pred_list", "=", "[", "]", "\n", "testloss_list", "=", "[", "]", "\n", "stat_list", "=", "[", "]", "\n", "\n", "while", "epoch", "==", "0", ":", "\n", "        ", "t_word", ",", "t_cont", ",", "t_word_c", ",", "t_cont_c", ",", "t_img_feature", ",", "t_answer", ",", "t_qid_list", ",", "t_iid_list", ",", "epoch", "=", "dp", ".", "get_batch_vec", "(", ")", "\n", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "...", "]", "=", "t_word", "# np.transpose(t_word,(1,0))", "\n", "net", ".", "blobs", "[", "'cont'", "]", ".", "data", "[", "...", "]", "=", "t_cont", "# np.transpose(t_cont,(1,0))", "\n", "net", ".", "blobs", "[", "'data1'", "]", ".", "data", "[", "...", "]", "=", "t_word_c", "\n", "net", ".", "blobs", "[", "'cont1'", "]", ".", "data", "[", "...", "]", "=", "t_cont_c", "\n", "net", ".", "blobs", "[", "'img_feature'", "]", ".", "data", "[", "...", "]", "=", "t_img_feature", "\n", "net", ".", "blobs", "[", "'label'", "]", ".", "data", "[", "...", "]", "=", "t_answer", "\n", "#net.blobs['glove'].data[...] = t_glove_matrix # np.transpose(t_glove_matrix, (1,0,2))", "\n", "net", ".", "forward", "(", ")", "\n", "t_pred_list", "=", "net", ".", "blobs", "[", "'prediction'", "]", ".", "data", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "t_pred_str", "=", "[", "dp", ".", "vec_to_answer", "(", "pred_symbol", ")", "for", "pred_symbol", "in", "t_pred_list", "]", "\n", "testloss_list", ".", "append", "(", "net", ".", "blobs", "[", "'loss'", "]", ".", "data", ")", "\n", "for", "qid", ",", "iid", ",", "ans", ",", "pred", "in", "zip", "(", "t_qid_list", ",", "t_iid_list", ",", "t_answer", ".", "tolist", "(", ")", ",", "t_pred_str", ")", ":", "\n", "            ", "pred_list", ".", "append", "(", "{", "u'answer'", ":", "pred", ",", "u'question_id'", ":", "int", "(", "dp", ".", "getStrippedQuesId", "(", "qid", ")", ")", "}", ")", "\n", "if", "visualize", ":", "\n", "                ", "q_list", "=", "dp", ".", "seq_to_list", "(", "dp", ".", "getQuesStr", "(", "qid", ")", ")", "\n", "if", "mode", "==", "'test-dev'", "or", "'test'", ":", "\n", "                    ", "ans_str", "=", "''", "\n", "ans_list", "=", "[", "''", "]", "*", "10", "\n", "", "else", ":", "\n", "                    ", "ans_str", "=", "dp", ".", "vec_to_answer", "(", "ans", ")", "\n", "ans_list", "=", "[", "dp", ".", "getAnsObj", "(", "qid", ")", "[", "i", "]", "[", "'answer'", "]", "for", "i", "in", "xrange", "(", "10", ")", "]", "\n", "", "stat_list", ".", "append", "(", "{", "'qid'", ":", "qid", ",", "\n", "'q_list'", ":", "q_list", ",", "\n", "'iid'", ":", "iid", ",", "\n", "'answer'", ":", "ans_str", ",", "\n", "'ans_list'", ":", "ans_list", ",", "\n", "'pred'", ":", "pred", "}", ")", "\n", "#percent = 100 * float(len(pred_list)) / total_questions", "\n", "#sys.stdout.write('\\r' + ('%.2f' % percent) + '%')", "\n", "#sys.stdout.flush()", "\n", "\n", "\n", "\n", "", "", "", "mean_testloss", "=", "np", ".", "array", "(", "testloss_list", ")", ".", "mean", "(", ")", "\n", "\n", "if", "mode", "==", "'val'", ":", "\n", "        ", "valFile", "=", "'./result/val2014_resfile'", "\n", "with", "open", "(", "valFile", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "annFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ans_file'", "]", "\n", "quesFile", "=", "config", ".", "DATA_PATHS", "[", "'val'", "]", "[", "'ques_file'", "]", "\n", "vqa", "=", "VQA", "(", "annFile", ",", "quesFile", ")", "\n", "vqaRes", "=", "vqa", ".", "loadRes", "(", "valFile", ",", "quesFile", ")", "\n", "vqaEval", "=", "VQAEval", "(", "vqa", ",", "vqaRes", ",", "n", "=", "2", ")", "\n", "vqaEval", ".", "evaluate", "(", ")", "\n", "acc_overall", "=", "vqaEval", ".", "accuracy", "[", "'overall'", "]", "\n", "acc_perQuestionType", "=", "vqaEval", ".", "accuracy", "[", "'perQuestionType'", "]", "\n", "acc_perAnswerType", "=", "vqaEval", ".", "accuracy", "[", "'perAnswerType'", "]", "\n", "return", "mean_testloss", ",", "acc_overall", ",", "acc_perQuestionType", ",", "acc_perAnswerType", "\n", "", "elif", "mode", "==", "'test-dev'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test-dev2015_v3t'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n", "", "", "elif", "mode", "==", "'test'", ":", "\n", "        ", "filename", "=", "'./result/vqa_OpenEnded_mscoco_test2015_v3c'", "+", "str", "(", "it", ")", ".", "zfill", "(", "8", ")", "+", "'_results'", "\n", "with", "open", "(", "filename", "+", "'.json'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "pred_list", ",", "f", ")", "\n", "", "if", "visualize", ":", "\n", "            ", "visualize_failures", "(", "stat_list", ",", "mode", ")", "\n"]], "home.repos.pwc.inspect_result.divelab_vqa-text.LSTM (baseline).visualize_tools.drawgraph": [[202, 270], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.twinx", "fig.add_subplot.plot", "fig.add_subplot.plot", "ax1.twinx.plot", "matplotlib.legend", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "ax1.twinx.set_ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "numpy.array", "numpy.array", "matplotlib.figure", "matplotlib.legend", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.savefig", "matplotlib.clf", "matplotlib.close", "sorted", "visualize_tools.drawgraph.draw_qt_acc"], "function", ["None"], ["\n", "", "", "", "def", "drawgraph", "(", "results", ",", "save_question_type_graphs", "=", "False", ")", ":", "\n", "# 0:it", "\n", "# 1:trainloss", "\n", "# 2:testloss", "\n", "# 3:oa_acc", "\n", "# 4:qt_acc", "\n", "# 5:at_acc", "\n", "\n", "# training curve", "\n", "    ", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "loss", "=", "np", ".", "array", "(", "[", "l", "[", "1", "]", "for", "l", "in", "results", "]", ")", "\n", "valloss", "=", "np", ".", "array", "(", "[", "l", "[", "2", "]", "for", "l", "in", "results", "]", ")", "\n", "valacc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax1", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "ax2", "=", "ax1", ".", "twinx", "(", ")", "\n", "\n", "ax1", ".", "plot", "(", "it", ",", "loss", ",", "color", "=", "'blue'", ",", "label", "=", "'train loss'", ")", "\n", "ax1", ".", "plot", "(", "it", ",", "valloss", ",", "'--'", ",", "color", "=", "'blue'", ",", "label", "=", "'test loss'", ")", "\n", "ax2", ".", "plot", "(", "it", ",", "valacc", ",", "color", "=", "'red'", ",", "label", "=", "'acc on val'", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'lower left'", ")", "\n", "\n", "ax1", ".", "set_xlabel", "(", "'Iterations'", ")", "\n", "ax1", ".", "set_ylabel", "(", "'Loss Value'", ")", "\n", "ax2", ".", "set_ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "'./learning_curve max_%2.2f.png'", "%", "valacc", ".", "max", "(", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "# question type", "\n", "it", "=", "np", ".", "array", "(", "[", "l", "[", "0", "]", "for", "l", "in", "results", "]", ")", "\n", "oa_acc", "=", "np", ".", "array", "(", "[", "l", "[", "3", "]", "for", "l", "in", "results", "]", ")", "\n", "qt_dic_list", "=", "[", "l", "[", "4", "]", "for", "l", "in", "results", "]", "\n", "\n", "def", "draw_qt_acc", "(", "target_key_list", ",", "figname", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "for", "k", "in", "target_key_list", ":", "\n", "            ", "write_log", "(", "str", "(", "k", ")", "+", "str", "(", "type", "(", "k", ")", ")", ",", "'visualize_log.txt'", ")", "\n", "t_val", "=", "np", ".", "array", "(", "[", "qt_dic", "[", "k", "]", "for", "qt_dic", "in", "qt_dic_list", "]", ")", "\n", "plt", ".", "plot", "(", "it", ",", "t_val", ",", "label", "=", "str", "(", "k", ")", ")", "\n", "", "plt", ".", "legend", "(", "fontsize", "=", "'small'", ")", "\n", "plt", ".", "ylim", "(", "0", ",", "100.", ")", "\n", "#plt.legend(prop={'size':6})", "\n", "\n", "plt", ".", "xlabel", "(", "'Iterations'", ")", "\n", "plt", ".", "ylabel", "(", "'Accuracy on Val [%]'", ")", "\n", "\n", "plt", ".", "savefig", "(", "figname", ",", "dpi", "=", "200", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "plt", ".", "close", "(", "\"all\"", ")", "\n", "\n", "", "if", "save_question_type_graphs", ":", "\n", "        ", "s_keys", "=", "sorted", "(", "qt_dic_list", "[", "0", "]", ".", "keys", "(", ")", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "0", ":", "13", "]", "+", "[", "s_keys", "[", "31", "]", ",", "]", ",", "'./ind_qt_are.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "13", ":", "17", "]", "+", "s_keys", "[", "49", ":", "]", ",", "'./ind_qt_how_where_who_why.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "17", ":", "31", "]", "+", "[", "s_keys", "[", "32", "]", ",", "]", ",", "'./ind_qt_is.png'", ")", "\n", "draw_qt_acc", "(", "s_keys", "[", "33", ":", "49", "]", ",", "'./ind_qt_what.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what color is the'", ",", "'what color are the'", ",", "'what color is'", ",", "'what color'", ",", "'what is the color of the'", "]", ",", "'./qt_color.png'", ")", "\n", "draw_qt_acc", "(", "[", "'how many'", ",", "'how'", ",", "'how many people are'", ",", "'how many people are in'", "]", ",", "'./qt_number.png'", ")", "\n", "draw_qt_acc", "(", "[", "'who is'", ",", "'why'", ",", "'why is the'", ",", "'where is the'", ",", "'where are the'", ",", "'which'", "]", ",", "'./qt_who_why_where_which.png'", ")", "\n", "draw_qt_acc", "(", "[", "'what is the man'", ",", "'is the man'", ",", "'are they'", ",", "'is he'", ",", "'is the woman'", ",", "'is this person'", ",", "'what is the woman'", ",", "'is the person'", ",", "'what is the person'", "]", ",", "'./qt_human.png'", ")", "\n"]]}