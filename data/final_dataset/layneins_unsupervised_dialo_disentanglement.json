{"home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.bert-reward.bert-eval.DatasetForBertEval.__init__": [[21, 28], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "features", ",", "max_source_len", ",", "cls_id", ",", "sep_id", ",", "pad_id", ",", "mask_id", ")", ":", "\n", "        ", "self", ".", "features", "=", "features", "\n", "self", ".", "max_source_len", "=", "max_source_len", "\n", "self", ".", "cls_id", "=", "cls_id", "\n", "self", ".", "sep_id", "=", "sep_id", "\n", "self", ".", "pad_id", "=", "pad_id", "\n", "self", ".", "mask_id", "=", "mask_id", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.bert-reward.bert-eval.DatasetForBertEval.__len__": [[29, 31], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.bert-reward.bert-eval.DatasetForBertEval.__trunk": [[32, 37], ["len"], "methods", ["None"], ["", "def", "__trunk", "(", "self", ",", "ids", ",", "max_len", ")", ":", "\n", "        ", "if", "len", "(", "ids", ")", ">", "max_len", "-", "1", ":", "\n", "            ", "ids", "=", "ids", "[", ":", "max_len", "-", "1", "]", "\n", "", "ids", "=", "ids", "+", "[", "self", ".", "sep_id", "]", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.bert-reward.bert-eval.DatasetForBertEval.__pad": [[38, 44], ["len", "len", "len"], "methods", ["None"], ["", "def", "__pad", "(", "self", ",", "ids", ",", "max_len", ")", ":", "\n", "        ", "if", "len", "(", "ids", ")", "<", "max_len", ":", "\n", "            ", "return", "ids", "+", "[", "self", ".", "pad_id", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "ids", ")", "==", "max_len", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.bert-reward.bert-eval.DatasetForBertEval.__getitem__": [[45, 66], ["bert-eval.DatasetForBertEval.__trunk", "bert-eval.DatasetForBertEval.__pad", "bert-eval.DatasetForBertEval.__trunk", "bert-eval.DatasetForBertEval.__pad", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__trunk", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__pad", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__trunk", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__pad"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "feature", "=", "self", ".", "features", "[", "idx", "]", "\n", "\n", "source_id_1", "=", "self", ".", "__trunk", "(", "[", "self", ".", "cls_id", "]", "+", "feature", "[", "\"text1\"", "]", ",", "self", ".", "max_source_len", ")", "\n", "segment_id_1", "=", "[", "0", "]", "*", "len", "(", "source_id_1", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_source_len", "-", "len", "(", "source_id_1", ")", ")", "\n", "input_mask_1", "=", "[", "1", "]", "*", "len", "(", "source_id_1", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_source_len", "-", "len", "(", "source_id_1", ")", ")", "\n", "input_id_1", "=", "self", ".", "__pad", "(", "source_id_1", ",", "self", ".", "max_source_len", ")", "\n", "\n", "source_id_2", "=", "self", ".", "__trunk", "(", "[", "self", ".", "cls_id", "]", "+", "feature", "[", "\"text2\"", "]", ",", "self", ".", "max_source_len", ")", "\n", "segment_id_2", "=", "[", "0", "]", "*", "len", "(", "source_id_2", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_source_len", "-", "len", "(", "source_id_2", ")", ")", "\n", "input_mask_2", "=", "[", "1", "]", "*", "len", "(", "source_id_2", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_source_len", "-", "len", "(", "source_id_2", ")", ")", "\n", "input_id_2", "=", "self", ".", "__pad", "(", "source_id_2", ",", "self", ".", "max_source_len", ")", "\n", "\n", "pos1", "=", "feature", "[", "'pos1'", "]", "\n", "pos2", "=", "feature", "[", "'pos2'", "]", "\n", "label1", "=", "feature", "[", "'label1'", "]", "\n", "label2", "=", "feature", "[", "'label2'", "]", "\n", "data_id", "=", "feature", "[", "'data_id'", "]", "\n", "return", "input_id_1", ",", "input_mask_1", ",", "segment_id_1", ",", "input_id_2", ",", "input_mask_2", ",", "segment_id_2", ",", "pos1", ",", "pos2", ",", "label1", ",", "label2", ",", "data_id", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.bert-reward.bert-eval.batch_list_to_batch_tensors": [[68, 73], ["zip", "batch_tensors.append", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "", "def", "batch_list_to_batch_tensors", "(", "batch", ")", ":", "\n", "    ", "batch_tensors", "=", "[", "]", "\n", "for", "x", "in", "zip", "(", "*", "batch", ")", ":", "\n", "        ", "batch_tensors", ".", "append", "(", "torch", ".", "tensor", "(", "x", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "", "return", "batch_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.bert-reward.bert-eval.read_data": [[75, 81], ["print", "print", "open", "json.load", "len"], "function", ["None"], ["", "def", "read_data", "(", "filename", ")", ":", "\n", "    ", "print", "(", "\"Reading data from {} ...\"", ".", "format", "(", "filename", ")", ")", "\n", "with", "open", "(", "filename", ")", "as", "fin", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "fin", ")", "\n", "", "print", "(", "\"{} original data read\"", ".", "format", "(", "len", "(", "data", ")", ")", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.bert-reward.bert-eval.convert_data_to_id": [[83, 108], ["os.path.exists", "print", "torch.load", "torch.load", "print", "print", "tqdm.tqdm", "print", "torch.save", "torch.save", "tokenizer.convert_tokens_to_ids", "tokenizer.convert_tokens_to_ids", "torch.load.append", "len", "text1.split", "text2.split", "len"], "function", ["None"], ["", "def", "convert_data_to_id", "(", "data", ",", "tokenizer", ",", "filename", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "        ", "print", "(", "\"Loading tokenized data ...\"", ")", "\n", "new_data", "=", "torch", ".", "load", "(", "filename", ")", "\n", "print", "(", "\"{} data loaded\"", ".", "format", "(", "len", "(", "new_data", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Converting data text to id ...\"", ")", "\n", "new_data", "=", "[", "]", "\n", "for", "item", "in", "tqdm", "(", "data", ")", ":", "\n", "            ", "text1", "=", "item", "[", "'text1'", "]", "\n", "text2", "=", "item", "[", "'text2'", "]", "\n", "text_id1", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "text1", ".", "split", "(", ")", ")", "\n", "text_id2", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "text2", ".", "split", "(", ")", ")", "\n", "new_data", ".", "append", "(", "{", "\n", "'text1'", ":", "text_id1", ",", "\n", "'label1'", ":", "item", "[", "'label1'", "]", ",", "\n", "'pos1'", ":", "item", "[", "'pos1'", "]", ",", "\n", "'text2'", ":", "text_id2", ",", "\n", "'label2'", ":", "item", "[", "'label2'", "]", ",", "\n", "'pos2'", ":", "item", "[", "'pos2'", "]", ",", "\n", "'data_id'", ":", "item", "[", "'data_id'", "]", ",", "\n", "}", ")", "\n", "", "print", "(", "\"{} data converted\"", ".", "format", "(", "len", "(", "new_data", ")", ")", ")", "\n", "torch", ".", "save", "(", "new_data", ",", "filename", ")", "\n", "", "return", "new_data", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.bert-reward.bert-eval.evaluate": [[110, 184], ["bert-eval.DatasetForBertEval", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "bert-eval.write_results", "amp.initialize", "max", "torch.nn.DataParallel", "torch.nn.DataParallel", "len", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "isinstance", "args.model_config.startswith", "args.model_config.startswith", "torch.matmul().squeeze().squeeze", "torch.matmul().squeeze().squeeze", "t.to", "torch.nn.DataParallel.", "torch.nn.DataParallel.", "torch.Sigmoid", "probs.detach().cpu().numpy", "pos1.detach().cpu().numpy", "pos2.detach().cpu().numpy", "label1.detach().cpu().numpy", "label2.detach().cpu().numpy", "data_id.detach().cpu().numpy", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "torch.matmul().squeeze", "torch.matmul().squeeze", "probs.detach().cpu().numpy", "pos1.detach().cpu().numpy", "pos2.detach().cpu().numpy", "label1.detach().cpu().numpy", "label2.detach().cpu().numpy", "data_id.detach().cpu().numpy", "probs.detach().cpu", "pos1.detach().cpu", "pos2.detach().cpu", "label1.detach().cpu", "label2.detach().cpu", "data_id.detach().cpu", "torch.matmul", "torch.matmul", "probs.detach().cpu", "pos1.detach().cpu", "pos2.detach().cpu", "label1.detach().cpu", "label2.detach().cpu", "data_id.detach().cpu", "sent1_vec.unsqueeze", "sent2_vec.unsqueeze().permute", "probs.detach", "pos1.detach", "pos2.detach", "label1.detach", "label2.detach", "data_id.detach", "probs.detach", "pos1.detach", "pos2.detach", "label1.detach", "label2.detach", "data_id.detach", "sent2_vec.unsqueeze"], "function", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.bert-reward.bert-eval.write_results"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "data", ",", "logger", ")", ":", "\n", "    ", "if", "args", ".", "fp16", ":", "\n", "        ", "from", "apex", "import", "amp", "\n", "", "else", ":", "\n", "        ", "amp", "=", "None", "\n", "\n", "", "if", "amp", ":", "\n", "        ", "model", "=", "amp", ".", "initialize", "(", "model", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "", "eval_dataset", "=", "DatasetForBertEval", "(", "\n", "features", "=", "data", ",", "max_source_len", "=", "args", ".", "max_source_len", ",", "\n", "cls_id", "=", "tokenizer", ".", "cls_token_id", ",", "sep_id", "=", "tokenizer", ".", "sep_token_id", ",", "\n", "pad_id", "=", "tokenizer", ".", "pad_token_id", ",", "mask_id", "=", "tokenizer", ".", "mask_token_id", "\n", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "\n", "batch_size", "=", "args", ".", "eval_batch_size", ",", "\n", "collate_fn", "=", "batch_list_to_batch_tensors", ")", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "not", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Num of GPUs = %d\"", ",", "args", ".", "n_gpu", ")", "\n", "all_pos1", "=", "None", "\n", "all_pos2", "=", "None", "\n", "all_label1", "=", "None", "\n", "all_label2", "=", "None", "\n", "all_data_ids", "=", "None", "\n", "all_probs", "=", "None", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "            ", "batch", "=", "[", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", "]", "\n", "input_id_1", ",", "input_mask_1", ",", "segment_id_1", ",", "input_id_2", ",", "input_mask_2", ",", "segment_id_2", ",", "pos1", ",", "pos2", ",", "label1", ",", "label2", ",", "data_id", "=", "batch", "\n", "inputs_1", "=", "{", "'input_ids'", ":", "input_id_1", ",", "\n", "'attention_mask'", ":", "input_mask_1", ",", "\n", "}", "\n", "if", "args", ".", "model_config", ".", "startswith", "(", "'bert'", ")", ":", "\n", "                ", "inputs_1", "[", "'token_type_ids'", "]", "=", "segment_id_1", "\n", "", "sent1_vec", "=", "model", "(", "**", "inputs_1", ")", "[", "1", "]", "\n", "\n", "inputs_2", "=", "{", "'input_ids'", ":", "input_id_2", ",", "\n", "'attention_mask'", ":", "input_mask_2", ",", "\n", "}", "\n", "if", "args", ".", "model_config", ".", "startswith", "(", "'bert'", ")", ":", "\n", "                ", "inputs_2", "[", "'token_type_ids'", "]", "=", "segment_id_2", "\n", "", "sent2_vec", "=", "model", "(", "**", "inputs_2", ")", "[", "1", "]", "\n", "\n", "score", "=", "torch", ".", "matmul", "(", "sent1_vec", ".", "unsqueeze", "(", "1", ")", ",", "sent2_vec", ".", "unsqueeze", "(", "1", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "probs", "=", "nn", ".", "Sigmoid", "(", ")", "(", "score", ")", "\n", "if", "all_probs", "is", "None", ":", "\n", "                ", "all_probs", "=", "probs", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "all_pos1", "=", "pos1", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "all_pos2", "=", "pos2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "all_label1", "=", "label1", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "all_label2", "=", "label2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "all_data_ids", "=", "data_id", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "all_probs", "=", "np", ".", "append", "(", "all_probs", ",", "probs", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "all_pos1", "=", "np", ".", "append", "(", "all_pos1", ",", "pos1", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "all_pos2", "=", "np", ".", "append", "(", "all_pos2", ",", "pos2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "all_label1", "=", "np", ".", "append", "(", "all_label1", ",", "label1", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "all_label2", "=", "np", ".", "append", "(", "all_label2", ",", "label2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "all_data_ids", "=", "np", ".", "append", "(", "all_data_ids", ",", "data_id", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "", "write_results", "(", "args", ",", "all_probs", ",", "all_pos1", ",", "all_pos2", ",", "all_label1", ",", "all_label2", ",", "all_data_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.bert-reward.bert-eval.write_results": [[186, 223], ["os.path.join", "torch.save", "torch.save", "os.path.join", "bert-eval.write_results.get_data_length"], "function", ["None"], ["", "def", "write_results", "(", "args", ",", "probs", ",", "pos1", ",", "pos2", ",", "label1", ",", "label2", ",", "data_ids", ")", ":", "\n", "    ", "def", "get_data_length", "(", "pos1", ",", "pos2", ",", "data_ids", ")", ":", "\n", "        ", "lengths", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "data_ids", ")", ")", ":", "\n", "            ", "if", "data_ids", "[", "i", "]", "not", "in", "lengths", ":", "\n", "                ", "lengths", "[", "data_ids", "[", "i", "]", "]", "=", "0", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "data_ids", ")", ")", ":", "\n", "            ", "lengths", "[", "data_ids", "[", "i", "]", "]", "=", "max", "(", "pos1", "[", "i", "]", "+", "1", ",", "lengths", "[", "data_ids", "[", "i", "]", "]", ")", "\n", "lengths", "[", "data_ids", "[", "i", "]", "]", "=", "max", "(", "pos2", "[", "i", "]", "+", "1", ",", "lengths", "[", "data_ids", "[", "i", "]", "]", ")", "\n", "", "return", "lengths", "\n", "\n", "", "temp_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "result_dir", ",", "'tmp.pt'", ")", "\n", "torch", ".", "save", "(", "[", "probs", ",", "pos1", ",", "pos2", ",", "label1", ",", "label2", ",", "data_ids", "]", ",", "temp_filename", ")", "\n", "\n", "reward_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "result_dir", ",", "\"reward.pt\"", ")", "\n", "\n", "reward", "=", "{", "}", "\n", "data_lengths", "=", "get_data_length", "(", "pos1", ",", "pos2", ",", "data_ids", ")", "\n", "\n", "for", "key", ",", "val", "in", "data_lengths", ".", "items", "(", ")", ":", "\n", "        ", "reward", "[", "key", "]", "=", "{", "\n", "'reward'", ":", "np", ".", "ones", "(", "[", "val", ",", "val", "]", ",", "dtype", "=", "np", ".", "float64", ")", ",", "\n", "'label'", ":", "np", ".", "empty", "(", "[", "val", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "}", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "data_ids", ")", ")", ":", "\n", "        ", "one_data_id", "=", "data_ids", "[", "i", "]", "\n", "one_prob", "=", "probs", "[", "i", "]", "\n", "one_pos1", "=", "pos1", "[", "i", "]", "\n", "one_pos2", "=", "pos2", "[", "i", "]", "\n", "one_label1", "=", "label1", "[", "i", "]", "\n", "one_label2", "=", "label2", "[", "i", "]", "\n", "reward", "[", "one_data_id", "]", "[", "'reward'", "]", "[", "one_pos1", "]", "[", "one_pos2", "]", "=", "one_prob", "\n", "reward", "[", "one_data_id", "]", "[", "'reward'", "]", "[", "one_pos2", "]", "[", "one_pos1", "]", "=", "one_prob", "\n", "reward", "[", "one_data_id", "]", "[", "'label'", "]", "[", "one_pos1", "]", "=", "one_label1", "\n", "reward", "[", "one_data_id", "]", "[", "'label'", "]", "[", "one_pos2", "]", "=", "one_label2", "\n", "", "torch", ".", "save", "(", "reward", ",", "reward_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.bert-reward.bert-eval.prepare": [[225, 255], ["os.path.join", "os.makedirs", "os.path.join", "os.makedirs", "os.path.join", "os.makedirs", "os.path.join", "logging.basicConfig", "logging.getLogger", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "logging.getLogger.info", "logging.getLogger.info", "json.dumps", "torch.cuda.is_available", "torch.cuda.is_available", "apex.amp.register_half_function", "ImportError"], "function", ["None"], ["", "def", "prepare", "(", "args", ")", ":", "\n", "    ", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "args", ".", "round", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "args", ".", "result_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "args", ".", "result_dir", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "result_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "args", ".", "cached_input_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "cached_input_dir", ",", "args", ".", "data_name", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "cached_input_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# define the logger", "\n", "logger_name", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"log.txt\"", ")", "\n", "LOG_FORMAT", "=", "'%(asctime)s %(name)-12s %(levelname)-8s %(message)s'", "\n", "logging", ".", "basicConfig", "(", "format", "=", "LOG_FORMAT", ",", "level", "=", "logging", ".", "INFO", ",", "filename", "=", "logger_name", ",", "filemode", "=", "'a'", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "logger_msg", "=", "'\\n\\n========================='", "\n", "logger", ".", "info", "(", "logger_msg", ")", "\n", "logger", ".", "info", "(", "json", ".", "dumps", "(", "args", ".", "__dict__", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "args", ".", "device", "=", "device", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "apex", ".", "amp", ".", "register_half_function", "(", "torch", ",", "'einsum'", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.bert-reward.bert-eval.get_model_and_tokenizer": [[257, 264], ["transformers.BertTokenizer.from_pretrained", "transformers.BertModel.from_pretrained", "transformers.BertModel.from_pretrained"], "function", ["None"], ["", "def", "get_model_and_tokenizer", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "model_path", "is", "not", "'none'", ":", "\n", "        ", "model", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "model_path", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "model_config", ")", "\n", "", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "model_config", ")", "\n", "return", "model", ",", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.bert-reward.bert-eval.get_args": [[266, 289], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--data_dir'", ",", "type", "=", "str", ",", "default", "=", "'./data/'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_type'", ",", "type", "=", "str", ",", "default", "=", "'train'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_name'", ",", "type", "=", "str", ",", "choices", "=", "[", "'movie'", "]", ",", "default", "=", "'movie'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_config'", ",", "type", "=", "str", ",", "default", "=", "'bert-base-uncased'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_path'", ",", "type", "=", "str", ",", "default", "=", "'none'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_dir'", ",", "type", "=", "str", ",", "default", "=", "'output'", ")", "\n", "parser", ".", "add_argument", "(", "'--result_dir'", ",", "type", "=", "str", ",", "default", "=", "'reward'", ")", "\n", "parser", ".", "add_argument", "(", "'--cached_input_dir'", ",", "type", "=", "str", ",", "default", "=", "'cached_input'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_source_len'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "'--round'", ",", "type", "=", "str", ",", "default", "=", "'1'", ")", "\n", "parser", ".", "add_argument", "(", "'--per_gpu_eval_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "'--read_cached_input'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Read cached input or not\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.bert-reward.bert-eval.main": [[291, 315], ["bert-eval.get_args", "bert-eval.prepare", "bert-eval.get_model_and_tokenizer", "os.path.join", "bert-eval.convert_data_to_id", "prepare.info", "model.to", "bert-eval.evaluate", "os.path.join", "bert-eval.read_data", "prepare.info", "len", "len"], "function", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.get_args", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.prepare", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.get_model_and_tokenizer", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.convert_data_to_id", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.evaluate", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.read_data"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "logger", "=", "prepare", "(", "args", ")", "\n", "\n", "model", ",", "tokenizer", "=", "get_model_and_tokenizer", "(", "args", ")", "\n", "\n", "if", "not", "args", ".", "read_cached_input", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "data_name", ",", "'{}.json'", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n", "raw_data", "=", "read_data", "(", "filename", ")", "\n", "logger", ".", "info", "(", "\"{} original data read\"", ".", "format", "(", "len", "(", "raw_data", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "raw_data", "=", "None", "\n", "\n", "", "cached_tokenized_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "cached_input_dir", ",", "\"{}_data_id.pt\"", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n", "data_id", "=", "convert_data_to_id", "(", "raw_data", ",", "tokenizer", ",", "cached_tokenized_filename", ")", "\n", "logger", ".", "info", "(", "\"{} data converted\"", ".", "format", "(", "len", "(", "data_id", ")", ")", ")", "\n", "\n", "# cached_flat_data_filename = os.path.join(args.cached_input_dir, \"flat_tokenized_{}.pt\".format(args.data_type)) ", "\n", "# data, labels = flatten_utterance(tokenized_data, tokenizer, cached_flat_data_filename)", "\n", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# res_filename = os.path.join(args.result_dir, '{}_res.pk'.format(args.data_type))", "\n", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "data_id", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.main.preprare": [[19, 43], ["time.strftime", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "logging.basicConfig", "logging.getLogger", "torch.device", "torch.cuda.device_count", "logging.getLogger.info", "transformers.BertTokenizer.from_pretrained", "time.gmtime", "str", "str", "json.dumps", "torch.cuda.is_available"], "function", ["None"], ["def", "preprare", "(", "args", ")", ":", "\n", "    ", "current_time", "=", "strftime", "(", "\"%Y-%b-%d-%H_%M_%S\"", ",", "gmtime", "(", ")", ")", "\n", "args", ".", "current_time", "=", "current_time", "\n", "\n", "args", ".", "data_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "data_name", ",", "'tokenized'", ",", "\"{}.json\"", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n", "args", ".", "reward_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "reward_path", ",", "str", "(", "args", ".", "round", ")", ",", "\"reward\"", ",", "\"reward.pt\"", ")", "\n", "\n", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "args", ".", "data_name", ",", "str", "(", "args", ".", "round", ")", ",", "args", ".", "current_time", ")", "\n", "args", ".", "cache_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "args", ".", "cache_dir", ")", "\n", "args", ".", "log_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'log.txt'", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "cache_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "LOG_FORMAT", "=", "'%(asctime)s %(name)-12s %(levelname)-8s %(message)s'", "\n", "logging", ".", "basicConfig", "(", "format", "=", "LOG_FORMAT", ",", "level", "=", "logging", ".", "INFO", ",", "filename", "=", "args", ".", "log_file", ",", "filemode", "=", "'a'", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "logger", ".", "info", "(", "json", ".", "dumps", "(", "args", ".", "__dict__", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "args", ".", "device", "=", "device", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "'bert-base-uncased'", ")", "\n", "\n", "return", "logger", ",", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.main.set_random_seed": [[45, 51], ["random.seed", "torch.manual_seed", "numpy.random.seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_random_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "random_seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "random_seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "random_seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "random_seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.main.get_args": [[53, 86], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "", "def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--data_dir'", ",", "type", "=", "str", ",", "default", "=", "\"../../../data/\"", ")", "\n", "parser", ".", "add_argument", "(", "'--data_name'", ",", "type", "=", "str", ",", "default", "=", "\"movie\"", ")", "\n", "parser", ".", "add_argument", "(", "'--data_type'", ",", "type", "=", "str", ",", "default", "=", "\"train\"", ")", "\n", "parser", ".", "add_argument", "(", "'--output_dir'", ",", "type", "=", "str", ",", "default", "=", "\"./output\"", ")", "\n", "parser", ".", "add_argument", "(", "'--cache_dir'", ",", "type", "=", "str", ",", "default", "=", "\"cached\"", ")", "\n", "parser", ".", "add_argument", "(", "'--init_checkpoint'", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--word_dict'", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--reward_path'", ",", "type", "=", "str", ",", "default", "=", "\"../bert-reward/output/\"", ")", "\n", "parser", ".", "add_argument", "(", "'--round'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--seq_max_len'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "\"the maximum length of a sequence\"", ")", "\n", "parser", ".", "add_argument", "(", "'--min_token_freq'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"the minimum frequency of a token\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max_session_number'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "'--per_gpu_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "'--num_warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "30", ")", "\n", "parser", ".", "add_argument", "(", "'--coherency_reward_weight'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "parser", ".", "add_argument", "(", "'--hidden_size'", ",", "type", "=", "int", ",", "default", "=", "300", ")", "\n", "parser", ".", "add_argument", "(", "'--emb_size'", ",", "type", "=", "int", ",", "default", "=", "300", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ")", "\n", "parser", ".", "add_argument", "(", "\"--bidirectional\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether not to use bidirectional encoder\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether not to use CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_cell'", ",", "type", "=", "str", ",", "choices", "=", "[", "'gru'", ",", "'lstm'", "]", ",", "default", "=", "\"lstm\"", ")", "\n", "parser", ".", "add_argument", "(", "'--random_seed'", ",", "type", "=", "int", ",", "default", "=", "1234", ")", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.main.main": [[88, 119], ["main.get_args", "main.preprare", "main.set_random_seed", "utils.read_raw_data", "logger.info", "utils.tokenize_data", "logger.info", "torch.load", "utils.convert_data_to_id", "logger.info", "utils.get_max_context_length", "logger.info", "torch.load", "utils.parse_reward", "model.MatchModel", "trainer.supervised_trainer", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.get_args", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.preprare", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.set_random_seed", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.read_raw_data", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.tokenize_data", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.convert_data_to_id", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.get_max_context_length", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.utils.parse_reward", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.trainer.supervised_trainer"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "\n", "logger", ",", "tokenizer", "=", "preprare", "(", "args", ")", "\n", "set_random_seed", "(", "args", ")", "\n", "\n", "raw_data", "=", "utils", ".", "read_raw_data", "(", "args", ".", "data_path", ")", "\n", "logger", ".", "info", "(", "\"{} data instances read from the original dataset.\"", ".", "format", "(", "len", "(", "raw_data", ")", ")", ")", "\n", "\n", "tokenized_data", "=", "utils", ".", "tokenize_data", "(", "raw_data", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\"{} tokenized data read.\"", ".", "format", "(", "len", "(", "tokenized_data", ")", ")", ")", "\n", "\n", "word_dict", "=", "torch", ".", "load", "(", "args", ".", "word_dict", ")", "\n", "args", ".", "pad_id", "=", "word_dict", "[", "'<PAD>'", "]", "\n", "\n", "word_emb_matrix", "=", "None", "\n", "\n", "training_data_id", "=", "utils", ".", "convert_data_to_id", "(", "tokenized_data", ",", "word_dict", ")", "\n", "logger", ".", "info", "(", "\"{} data id read.\"", ".", "format", "(", "len", "(", "training_data_id", ")", ")", ")", "\n", "\n", "args", ".", "max_context_len", "=", "utils", ".", "get_max_context_length", "(", "training_data_id", ")", "\n", "logger", ".", "info", "(", "\"Max context length: {}\"", ".", "format", "(", "args", ".", "max_context_len", ")", ")", "\n", "\n", "reward", "=", "torch", ".", "load", "(", "args", ".", "reward_path", ")", "\n", "coherency_reward", ",", "speaker_reward", "=", "utils", ".", "parse_reward", "(", "reward", ",", "tokenized_data", ")", "\n", "\n", "model", "=", "MatchModel", "(", "args", ".", "rnn_cell", ",", "len", "(", "word_dict", ")", ",", "word_emb_matrix", ",", "\n", "args", ".", "hidden_size", ",", "args", ".", "emb_size", ",", "args", ".", "max_context_len", ",", "\n", "bidirectional", "=", "args", ".", "bidirectional", ")", "\n", "\n", "supervised_trainer", "(", "args", ",", "model", ",", "training_data_id", ",", "coherency_reward", ",", "speaker_reward", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.data_loader.DatasetforDisentanglement.__init__": [[8, 15], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "training_data", ",", "coherency_reward", ",", "speaker_reward", ",", "seq_max_len", ",", "num_training_instances", ",", "pad_id", ")", ":", "\n", "        ", "self", ".", "training_data", "=", "training_data", "\n", "self", ".", "coherency_reward", "=", "coherency_reward", "\n", "self", ".", "speaker_reward", "=", "speaker_reward", "\n", "self", ".", "seq_max_len", "=", "seq_max_len", "\n", "self", ".", "num_training_instances", "=", "num_training_instances", "\n", "self", ".", "pad_id", "=", "pad_id", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.data_loader.DatasetforDisentanglement.__len__": [[16, 18], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_training_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.data_loader.DatasetforDisentanglement.__trunk": [[19, 23], ["len"], "methods", ["None"], ["", "def", "__trunk", "(", "self", ",", "ids", ",", "max_len", ")", ":", "\n", "        ", "if", "len", "(", "ids", ")", ">", "max_len", ":", "\n", "            ", "ids", "=", "ids", "[", ":", "max_len", "]", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.data_loader.DatasetforDisentanglement.__pad": [[24, 30], ["len", "len", "len"], "methods", ["None"], ["", "def", "__pad", "(", "self", ",", "ids", ",", "max_len", ")", ":", "\n", "        ", "if", "len", "(", "ids", ")", "<", "max_len", ":", "\n", "            ", "return", "ids", "+", "[", "self", ".", "pad_id", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "ids", ")", "==", "max_len", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.data_loader.DatasetforDisentanglement.__getitem__": [[31, 49], ["len", "data_loader.DatasetforDisentanglement.__trunk", "len", "data_loader.DatasetforDisentanglement.__pad", "messages.append", "message_seq_len.append", "labels.append", "len"], "methods", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__trunk", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__pad"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "idx", "=", "idx", "%", "len", "(", "self", ".", "training_data", ")", "\n", "example", "=", "self", ".", "training_data", "[", "idx", "]", "\n", "speaker_reward", "=", "self", ".", "speaker_reward", "[", "idx", "]", "\n", "coherency_reward", "=", "self", ".", "coherency_reward", "[", "idx", "]", "\n", "messages", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "message_seq_len", "=", "[", "]", "\n", "for", "item", "in", "example", ":", "\n", "            ", "text", "=", "item", "[", "'message'", "]", "\n", "label", "=", "item", "[", "'label'", "]", "\n", "text", "=", "self", ".", "__trunk", "(", "text", ",", "self", ".", "seq_max_len", ")", "\n", "text_seq_len", "=", "len", "(", "text", ")", "\n", "text", "=", "self", ".", "__pad", "(", "text", ",", "self", ".", "seq_max_len", ")", "\n", "messages", ".", "append", "(", "text", ")", "\n", "message_seq_len", ".", "append", "(", "text_seq_len", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "", "return", "messages", ",", "message_seq_len", ",", "labels", ",", "len", "(", "messages", ")", ",", "coherency_reward", ",", "speaker_reward", "", "", "", ""]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.policy.update_action_list": [[7, 11], ["range", "len"], "function", ["None"], ["def", "update_action_list", "(", "action_list", ",", "current_actions", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "len", "(", "action_list", ")", ")", ":", "\n", "        ", "action_list", "[", "i", "]", "+=", "[", "current_actions", "[", "i", "]", "]", "\n", "", "return", "action_list", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.policy.get_coherency_reward": [[13, 24], ["numpy.average", "numpy.average", "numpy.amax", "numpy.amax"], "function", ["None"], ["", "def", "get_coherency_reward", "(", "coherency_reward", ",", "reward_type", "=", "'avg'", ",", "message_type", "=", "'new'", ")", ":", "\n", "    ", "if", "reward_type", "==", "'avg'", ":", "\n", "        ", "if", "message_type", "==", "'new'", ":", "\n", "            ", "return", "0.5", "-", "np", ".", "average", "(", "coherency_reward", ")", "\n", "", "elif", "message_type", "==", "'select'", ":", "\n", "            ", "return", "np", ".", "average", "(", "coherency_reward", ")", "-", "0.5", "\n", "", "", "elif", "reward_type", "==", "'max'", ":", "\n", "        ", "if", "message_type", "==", "'new'", ":", "\n", "            ", "return", "0.5", "-", "np", ".", "amax", "(", "coherency_reward", ")", "\n", "", "elif", "message_type", "==", "'select'", ":", "\n", "            ", "return", "np", ".", "amax", "(", "coherency_reward", ")", "-", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.policy.get_speaker_reward": [[26, 37], ["numpy.sum", "numpy.sum"], "function", ["None"], ["", "", "", "def", "get_speaker_reward", "(", "speaker_reward", ",", "message_type", "=", "'new'", ",", "scaling_lambda", "=", "-", "1", ")", ":", "\n", "    ", "if", "message_type", "==", "'new'", ":", "\n", "        ", "if", "np", ".", "sum", "(", "speaker_reward", ")", ">", "0", ":", "\n", "            ", "return", "-", "1", "\n", "", "else", ":", "\n", "            ", "return", "0", "\n", "", "", "elif", "message_type", "==", "'select'", ":", "\n", "        ", "if", "np", ".", "sum", "(", "speaker_reward", ")", ">", "0", ":", "\n", "            ", "return", "1", "\n", "", "else", ":", "\n", "            ", "return", "scaling_lambda", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.policy.get_reward_loss": [[39, 69], ["len", "range", "range", "total_loss.append", "[].data.item", "policy.get_coherency_reward", "policy.get_speaker_reward", "step_choice.cpu().numpy.cpu().numpy", "policy.get_coherency_reward", "policy.get_speaker_reward", "torch.log", "step_choice.cpu().numpy.cpu", "torch.log"], "function", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.policy.get_coherency_reward", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.policy.get_speaker_reward", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.policy.get_coherency_reward", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.policy.get_speaker_reward"], ["", "", "", "def", "get_reward_loss", "(", "coherency_reward_weight", ",", "action_list", ",", "decision_sequence", ",", "coherency_reward", ",", "speaker_reward", ",", "context_len", ")", ":", "\n", "    ", "batch_size", "=", "len", "(", "action_list", ")", "\n", "total_loss", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "one_loss", "=", "0.", "\n", "for", "j", "in", "range", "(", "1", ",", "context_len", "[", "i", "]", ")", ":", "\n", "            ", "action_type", ",", "action", ",", "prob", ",", "new_session_probs", "=", "action_list", "[", "i", "]", "[", "j", "]", "\n", "decision", "=", "decision_sequence", "[", "i", "]", "[", "j", "]", ".", "data", ".", "item", "(", ")", "\n", "if", "action_type", "==", "'new'", ":", "\n", "                ", "step_coherency_matrix", "=", "coherency_reward", "[", "i", "]", "[", "j", ",", "0", ":", "j", "]", "\n", "new_action_coherency_reward", "=", "get_coherency_reward", "(", "step_coherency_matrix", ",", "reward_type", "=", "'avg'", ",", "message_type", "=", "'new'", ")", "\n", "step_speaker_matrix", "=", "speaker_reward", "[", "i", "]", "[", "j", ",", "0", ":", "j", "]", "\n", "new_action_speaker_reward", "=", "get_speaker_reward", "(", "step_speaker_matrix", ",", "message_type", "=", "'new'", ")", "\n", "step_reward", "=", "coherency_reward_weight", "*", "new_action_coherency_reward", "+", "(", "1", "-", "coherency_reward_weight", ")", "*", "new_action_speaker_reward", "\n", "step_loss", "=", "step_reward", "*", "(", "-", "torch", ".", "log", "(", "prob", "[", "0", "]", "[", "0", "]", ")", ")", "\n", "one_loss", "+=", "step_loss", "\n", "", "elif", "action_type", "==", "'select'", ":", "\n", "                ", "step_choice", "=", "decision_sequence", "[", "i", "]", "==", "action", "\n", "step_choice", "=", "step_choice", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "step_choice", "=", "step_choice", "[", "0", ":", "j", "]", "\n", "step_coherency_matrix", "=", "coherency_reward", "[", "i", "]", "[", "j", "]", "[", "0", ":", "j", "]", "[", "step_choice", "]", "\n", "step_speaker_matrix", "=", "speaker_reward", "[", "i", "]", "[", "j", "]", "[", "0", ":", "j", "]", "[", "step_choice", "]", "\n", "new_action_coherency_reward", "=", "get_coherency_reward", "(", "step_coherency_matrix", ",", "reward_type", "=", "'avg'", ",", "message_type", "=", "'select'", ")", "\n", "new_action_speaker_reward", "=", "get_speaker_reward", "(", "step_speaker_matrix", ",", "message_type", "=", "'select'", ")", "\n", "step_reward", "=", "coherency_reward_weight", "*", "new_action_coherency_reward", "+", "(", "1", "-", "coherency_reward_weight", ")", "*", "new_action_speaker_reward", "\n", "step_loss", "=", "step_reward", "*", "(", "-", "torch", ".", "log", "(", "prob", "[", "0", "]", "[", "1", "]", "*", "new_session_probs", "[", "0", "]", "[", "1", "]", ")", ")", "\n", "one_loss", "+=", "step_loss", "\n", "", "", "total_loss", ".", "append", "(", "one_loss", ")", "\n", "\n", "", "return", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.trainer.supervised_trainer": [[17, 120], ["torch.nn.DataParallel.to", "torch.nn.DataParallel.load_state_dict", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "int", "data_loader.DatasetforDisentanglement", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "tqdm.tqdm", "torch.nn.DataParallel.train", "torch.nn.DataParallel.zero_grad", "list", "torch.Adam", "transformers.get_linear_schedule_with_warmup", "torch.load", "torch.load", "torch.load", "torch.load", "len", "torch.nn.DataParallel.parameters", "context_tensor.to.to", "context_len.to.to", "max", "torch.nn.DataParallel.module.message_encoder", "torch.nn.DataParallel.module.build_context_batch", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "range", "policy.get_reward_loss", "tqdm.tqdm.set_description", "policy.get_reward_loss.backward", "optim.Adam.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.DataParallel.zero_grad", "len", "len", "context_len.to.size", "torch.nn.DataParallel.module.get_random_decision", "policy.update_action_list", "range", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sum", "len", "logger.info", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "logger.info", "len", "range", "torch.nn.DataParallel.state_dict", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "policy.get_reward_loss.item", "torch.tensor().view.append", "torch.tensor().view.append", "torch.tensor().view.append", "transformers.get_linear_schedule_with_warmup.get_last_lr", "session_number[].data.item"], "function", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.train", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.build_context_batch", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.policy.get_reward_loss", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.model.MatchModel.get_random_decision", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.policy.update_action_list"], ["def", "supervised_trainer", "(", "args", ",", "model", ",", "training_data", ",", "coherency_reward", ",", "speaker_reward", ",", "logger", ",", "optimizer", "=", "None", ")", ":", "\n", "    ", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "args", ".", "init_checkpoint", ")", ")", "\n", "# if args.n_gpu > 1:", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "if", "args", ".", "n_gpu", "==", "0", "or", "args", ".", "no_cuda", ":", "\n", "        ", "training_batch_size", "=", "args", ".", "per_gpu_batch_size", "\n", "", "else", ":", "\n", "        ", "training_batch_size", "=", "args", ".", "per_gpu_batch_size", "*", "args", ".", "n_gpu", "\n", "\n", "", "num_training_steps", "=", "int", "(", "args", ".", "epochs", "*", "len", "(", "training_data", ")", "/", "training_batch_size", ")", "\n", "\n", "train_dataset", "=", "DatasetforDisentanglement", "(", "\n", "training_data", ",", "coherency_reward", ",", "speaker_reward", ",", "args", ".", "seq_max_len", ",", "\n", "num_training_steps", "*", "training_batch_size", ",", "args", ".", "pad_id", ")", "\n", "\n", "# Train!", "\n", "logger", ".", "info", "(", "\"  ***** Running training *****  *\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "training_data", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %.2f\"", ",", "len", "(", "train_dataset", ")", "/", "len", "(", "training_data", ")", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "training_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "num_training_steps", ")", "\n", "\n", "train_sampler", "=", "SequentialSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "training_batch_size", ",", "\n", "collate_fn", "=", "utils", ".", "batch_list_to_batch_tensors", ")", "\n", "\n", "train_iterator", "=", "tqdm", "(", "\n", "train_dataloader", ",", "initial", "=", "0", ",", "\n", "desc", "=", "\"Iter (loss=X.XXX, lr=X.XXXXXXX)\"", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "global_step", "=", "0", "\n", "logging_loss", "=", "0.", "\n", "# loss_func = nn.CrossEntropyLoss()", "\n", "params", "=", "list", "(", "model", ".", "parameters", "(", ")", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "params", ",", "lr", "=", "args", ".", "lr", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "num_warmup_steps", ",", "\n", "num_training_steps", "=", "num_training_steps", ",", "last_epoch", "=", "-", "1", ")", "\n", "\n", "for", "batch", "in", "train_iterator", ":", "\n", "        ", "context_tensor", ",", "context_seq_len_tensor", ",", "context_len", ",", "coherency_reward", ",", "speaker_reward", "=", "batch", "\n", "context_tensor", "=", "context_tensor", ".", "to", "(", "args", ".", "device", ")", "\n", "# context_seq_len_tensor = context_seq_len_tensor.to(args.device)", "\n", "context_len", "=", "context_len", ".", "to", "(", "args", ".", "device", ")", "\n", "max_context_len", "=", "max", "(", "context_len", ")", "\n", "context_vector", "=", "model", ".", "module", ".", "message_encoder", "(", "context_tensor", ",", "context_seq_len_tensor", ")", "\n", "context_batch", "=", "model", ".", "module", ".", "build_context_batch", "(", "context_vector", ",", "context_len", ",", "max_context_len", ")", "\n", "\n", "batch_size", "=", "context_len", ".", "size", "(", ")", "[", "0", "]", "\n", "\n", "decision_sequence", "=", "torch", ".", "zeros", "(", "[", "batch_size", ",", "1", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "args", ".", "device", ")", "\n", "session_number", "=", "torch", ".", "ones", "(", "[", "batch_size", ",", "1", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "args", ".", "device", ")", "\n", "action_list", "=", "[", "[", "[", "None", ",", "None", ",", "None", "]", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "for", "step", "in", "range", "(", "1", ",", "max_context_len", ")", ":", "\n", "            ", "current_context", "=", "context_batch", "[", ":", ",", "0", ":", "step", ",", ":", "]", "\n", "current_message", "=", "context_batch", "[", ":", ",", "step", ",", ":", "]", "\n", "ret_value", "=", "model", ".", "module", ".", "get_random_decision", "(", "current_context", ",", "current_message", ",", "decision_sequence", ",", "session_number", ")", "\n", "action_list", "=", "policy", ".", "update_action_list", "(", "action_list", ",", "ret_value", ")", "\n", "current_decision", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "action_type", ",", "action", ",", "prob", ",", "new_session_prob", "=", "ret_value", "[", "i", "]", "\n", "if", "action_type", "==", "'new'", ":", "\n", "                    ", "if", "session_number", "[", "i", "]", "<", "args", ".", "max_session_number", ":", "\n", "                        ", "current_decision", ".", "append", "(", "session_number", "[", "i", "]", ".", "data", ".", "item", "(", ")", ")", "\n", "session_number", "[", "i", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "current_decision", ".", "append", "(", "action", ")", "\n", "", "", "elif", "action_type", "==", "'select'", ":", "\n", "                    ", "current_decision", ".", "append", "(", "action", ")", "\n", "", "", "current_decision", "=", "torch", ".", "tensor", "(", "current_decision", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "args", ".", "device", ")", ".", "view", "(", "batch_size", ",", "1", ")", "\n", "decision_sequence", "=", "torch", ".", "cat", "(", "[", "decision_sequence", ",", "current_decision", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "policy_loss", "=", "policy", ".", "get_reward_loss", "(", "args", ".", "coherency_reward_weight", ",", "action_list", ",", "decision_sequence", ",", "coherency_reward", ",", "speaker_reward", ",", "context_len", ")", "\n", "policy_loss", "=", "sum", "(", "policy_loss", ")", "/", "len", "(", "policy_loss", ")", "\n", "\n", "logging_loss", "+=", "policy_loss", "\n", "\n", "train_iterator", ".", "set_description", "(", "'Iter (loss=%5.3f) lr=%9.7f'", "%", "(", "policy_loss", ".", "item", "(", ")", ",", "scheduler", ".", "get_last_lr", "(", ")", "[", "0", "]", ")", ")", "\n", "\n", "policy_loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\" Step [%d ~ %d]: %.2f\"", ",", "global_step", "-", "args", ".", "logging_steps", ",", "global_step", ",", "logging_loss", ")", "\n", "logging_loss", "=", "0.0", "\n", "", "if", "args", ".", "save_steps", ">", "0", "and", "(", "global_step", "%", "args", ".", "save_steps", "==", "0", "or", "global_step", "==", "num_training_steps", ")", ":", "\n", "\n", "            ", "save_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "cache_dir", ",", "\"ckpt-%d.pkl\"", "%", "global_step", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint %d into %s\"", ",", "global_step", ",", "save_path", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.model.MatchModel.__init__": [[8, 15], ["torch.Module.__init__", "model.MessageEncoder", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__init__"], ["    ", "def", "__init__", "(", "self", ",", "rnn_cell", ",", "token_num", ",", "word_emb", ",", "hidden_size", ",", "emb_size", ",", "max_context_len", ",", "bidirectional", "=", "True", ",", "max_session_number", "=", "4", ")", ":", "\n", "        ", "super", "(", "MatchModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "message_encoder", "=", "MessageEncoder", "(", "rnn_cell", ",", "token_num", ",", "word_emb", ",", "hidden_size", ",", "emb_size", ",", "bidirectional", "=", "bidirectional", ")", "\n", "self", ".", "max_context_len", "=", "max_context_len", "\n", "self", ".", "attention_liearn", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ")", "\n", "self", ".", "max_session_number", "=", "max_session_number", "\n", "self", ".", "sigmoid_func", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.model.MatchModel.pad_item": [[16, 20], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "pad_item", "(", "self", ",", "context", ",", "length", ",", "hidden_size", ",", "device", ")", ":", "\n", "        ", "zero_item", "=", "torch", ".", "zeros", "(", "[", "length", ",", "hidden_size", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "padded_context", "=", "torch", ".", "cat", "(", "[", "context", ",", "zero_item", "]", ",", "dim", "=", "0", ")", "\n", "return", "padded_context", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.model.MatchModel.build_context_batch": [[21, 38], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "context_for_a_sample.size", "model.MatchModel.pad_item", "torch.cat.append", "torch.cat.append", "torch.cat.append", "model.MatchModel.unsqueeze", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "context_for_a_sample.get_device"], "methods", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.pad_item"], ["", "def", "build_context_batch", "(", "self", ",", "context", ",", "context_len", ",", "max_context_len", ")", ":", "\n", "        ", "start", "=", "0", "\n", "end", "=", "0", "\n", "context_batch", "=", "[", "]", "\n", "for", "one_len", "in", "context_len", ":", "\n", "            ", "start", "=", "end", "\n", "end", "=", "end", "+", "one_len", "\n", "context_for_a_sample", "=", "context", "[", "start", ":", "end", "]", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda:{}\"", ".", "format", "(", "context_for_a_sample", ".", "get_device", "(", ")", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "length", ",", "hidden_size", "=", "context_for_a_sample", ".", "size", "(", ")", "\n", "length", "=", "max_context_len", "-", "length", "\n", "\n", "context_with_padding", "=", "self", ".", "pad_item", "(", "context_for_a_sample", ",", "length", ",", "hidden_size", ",", "device", ")", "\n", "context_batch", ".", "append", "(", "context_with_padding", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "context_batch", "=", "torch", ".", "cat", "(", "context_batch", ",", "dim", "=", "0", ")", "\n", "return", "context_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.model.MatchModel.get_random_decision": [[39, 79], ["model.MatchModel.attention_liearn().transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "model.MatchModel.sigmoid_func", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample", "range", "context.size", "torch.Softmax", "torch.Softmax", "torch.Softmax", "range", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.sample", "model.MatchModel.sigmoid_func", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ret_value.append", "model.MatchModel.attention_liearn", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "ret_value.append", "model.MatchModel.attention_liearn().transpose", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm().squeeze", "torch.mm().squeeze", "torch.mm().squeeze", "torch.mm().squeeze", "torch.mm().squeeze", "torch.mm().squeeze", "torch.mm().squeeze", "torch.mm().squeeze", "torch.mm().squeeze", "current_sample_logits[].unsqueeze", "message.view", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.MatchModel.attention_liearn", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "current_sample_message.view"], "methods", ["None"], ["", "def", "get_random_decision", "(", "self", ",", "context", ",", "message", ",", "decision_sequence", ",", "session_number", ")", ":", "\n", "        ", "batch_size", "=", "context", ".", "size", "(", ")", "[", "0", "]", "\n", "ret_value", "=", "[", "]", "\n", "\n", "context_message_weight", "=", "self", ".", "attention_liearn", "(", "context", ")", ".", "transpose", "(", "2", ",", "1", ")", "\n", "context_attention_score", "=", "nn", ".", "Softmax", "(", "dim", "=", "2", ")", "(", "context_message_weight", ")", "\n", "attended_context_vector", "=", "torch", ".", "bmm", "(", "context_attention_score", ",", "context", ")", "\n", "new_session_scores", "=", "torch", ".", "bmm", "(", "attended_context_vector", ",", "message", ".", "view", "(", "batch_size", ",", "-", "1", ",", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "new_session_probs", "=", "self", ".", "sigmoid_func", "(", "new_session_scores", ")", "\n", "new_session_probs", "=", "torch", ".", "cat", "(", "[", "1", "-", "new_session_probs", ",", "new_session_probs", "]", ",", "dim", "=", "1", ")", "\n", "\n", "new_session_probs_dist", "=", "torch", ".", "distributions", ".", "Categorical", "(", "new_session_probs", ")", "# probs should be of size batch x classes", "\n", "sampled_new_session_action", "=", "new_session_probs_dist", ".", "sample", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "if", "sampled_new_session_action", "[", "i", "]", "==", "0", "and", "session_number", "[", "i", "]", "!=", "self", ".", "max_session_number", ":", "\n", "                ", "ret_value", ".", "append", "(", "[", "'new'", ",", "None", ",", "new_session_probs", "[", "i", ":", "i", "+", "1", "]", ",", "None", "]", ")", "\n", "continue", "\n", "", "current_sample_context", "=", "context", "[", "i", "]", "\n", "current_sample_message", "=", "message", "[", "i", "]", "\n", "current_sample_decision", "=", "decision_sequence", "[", "i", "]", "\n", "current_sample_logits", "=", "None", "\n", "for", "k", "in", "range", "(", "session_number", "[", "i", "]", ")", ":", "\n", "                ", "step_decision", "=", "current_sample_decision", "==", "k", "\n", "step_context", "=", "current_sample_context", "[", "step_decision", "]", "\n", "\n", "weight", "=", "self", ".", "attention_liearn", "(", "step_context", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "context_attention_score", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "weight", ")", "\n", "attended_context_vector", "=", "torch", ".", "mm", "(", "context_attention_score", ",", "step_context", ")", "\n", "score", "=", "torch", ".", "mm", "(", "attended_context_vector", ",", "current_sample_message", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "if", "current_sample_logits", "is", "None", ":", "\n", "                    ", "current_sample_logits", "=", "score", "\n", "", "else", ":", "\n", "                    ", "current_sample_logits", "=", "torch", ".", "cat", "(", "[", "current_sample_logits", ",", "score", "]", ",", "dim", "=", "0", ")", "\n", "", "", "current_sample_probs_dist", "=", "torch", ".", "distributions", ".", "Categorical", "(", "logits", "=", "current_sample_logits", ")", "\n", "current_sample_action", "=", "current_sample_probs_dist", ".", "sample", "(", ")", "\n", "selected_action_prob", "=", "self", ".", "sigmoid_func", "(", "current_sample_logits", "[", "current_sample_action", ":", "current_sample_action", "+", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "selected_action_prob", "=", "torch", ".", "cat", "(", "[", "1", "-", "selected_action_prob", ",", "selected_action_prob", "]", ",", "dim", "=", "1", ")", "\n", "ret_value", ".", "append", "(", "[", "'select'", ",", "current_sample_action", ",", "selected_action_prob", ",", "new_session_probs", "[", "i", ":", "i", "+", "1", "]", "]", ")", "\n", "", "return", "ret_value", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.model.MatchModel.build_context_batch_with_attention": [[80, 94], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.MatchModel.attention_liearn().transpose", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.Softmax", "torch.Softmax", "torch.Softmax", "model.MatchModel.attention_liearn"], "methods", ["None"], ["", "def", "build_context_batch_with_attention", "(", "self", ",", "context", ",", "context_len", ")", ":", "\n", "        ", "start", "=", "0", "\n", "end", "=", "0", "\n", "context_batch", "=", "[", "]", "\n", "for", "one_len", "in", "context_len", ":", "\n", "            ", "start", "=", "end", "\n", "end", "=", "end", "+", "one_len", "\n", "context_for_a_sample", "=", "context", "[", "start", ":", "end", "]", "\n", "weight", "=", "self", ".", "attention_liearn", "(", "context_for_a_sample", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "context_attention_score", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "weight", ")", "\n", "attended_context_vector", "=", "torch", ".", "mm", "(", "context_attention_score", ",", "context_for_a_sample", ")", "\n", "context_batch", ".", "append", "(", "attended_context_vector", ")", "\n", "", "context_batch", "=", "torch", ".", "cat", "(", "context_batch", ",", "dim", "=", "0", ")", "\n", "return", "context_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.model.MatchModel.forward": [[95, 115], ["model.MatchModel.message_encoder", "model.MatchModel.build_context_batch_with_attention", "model.MatchModel.message_encoder", "model.MatchModel.size", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "model.MatchModel.view", "model.MatchModel.view"], "methods", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.build_context_batch_with_attention"], ["", "def", "forward", "(", "self", ",", "context", ",", "context_seq_len", ",", "context_len", ",", "current_message", "=", "None", ",", "\n", "current_message_seq_len", "=", "None", ",", "max_context_len", "=", "-", "1", ")", ":", "\n", "        ", "context_vector", "=", "self", ".", "message_encoder", "(", "context", ",", "context_seq_len", ")", "\n", "return", "context_vector", "\n", "\n", "# if inference:", "\n", "#     context_batch = self.build_context_batch(context_vector, context_len, max_context_len)", "\n", "#     return context_batch", "\n", "# else:", "\n", "context_batch", "=", "self", ".", "build_context_batch_with_attention", "(", "context_vector", ",", "context_len", ")", "\n", "current_message_vector", "=", "self", ".", "message_encoder", "(", "current_message", ",", "current_message_seq_len", ")", "\n", "\n", "batch_size", ",", "hidden_size", "=", "context_batch", ".", "size", "(", ")", "\n", "logit", "=", "torch", ".", "bmm", "(", "\n", "context_batch", ".", "view", "(", "batch_size", ",", "1", ",", "hidden_size", ")", ",", "current_message_vector", ".", "view", "(", "batch_size", ",", "hidden_size", ",", "1", ")", "\n", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "pos_output", "=", "nn", ".", "Sigmoid", "(", ")", "(", "logit", ")", "\n", "neg_output", "=", "1", "-", "pos_output", "\n", "output", "=", "torch", ".", "cat", "(", "[", "neg_output", ",", "pos_output", "]", ",", "dim", "=", "1", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.model.MessageEncoder.__init__": [[118, 136], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "model.MessageEncoder.init_embedding", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.GRU", "torch.GRU", "torch.GRU", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__init__", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MessageEncoder.init_embedding"], ["    ", "def", "__init__", "(", "self", ",", "rnn_cell", ",", "token_num", ",", "word_emb", ",", "hidden_size", ",", "emb_size", ",", "bidirectional", ",", "dropout_rate", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "MessageEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_emb", "=", "word_emb", "\n", "self", ".", "word_emb_matrix", "=", "nn", ".", "Embedding", "(", "token_num", ",", "emb_size", ")", "\n", "self", ".", "init_embedding", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout_rate", ")", "\n", "self", ".", "rnn_cell", "=", "rnn_cell", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "\n", "if", "self", ".", "rnn_cell", "==", "'lstm'", ":", "\n", "            ", "self", ".", "encoder", "=", "nn", ".", "LSTM", "(", "emb_size", ",", "hidden_size", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "bidirectional", ")", "\n", "", "elif", "self", ".", "rnn_cell", "==", "'gru'", ":", "\n", "            ", "self", ".", "encoder", "=", "nn", ".", "GRU", "(", "emb_size", ",", "hidden_size", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "bidirectional", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Message encoder {} not implemented\"", ".", "format", "(", "self", ".", "rnn_cell", ")", ")", "\n", "\n", "", "if", "self", ".", "bidirectional", ":", "\n", "            ", "self", ".", "output_linear", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", ",", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.model.MessageEncoder.init_embedding": [[137, 142], ["model.MessageEncoder.word_emb_matrix.weight.data.uniform_", "model.MessageEncoder.word_emb_matrix.weight.data.copy_", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "", "def", "init_embedding", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "word_emb", "is", "None", ":", "\n", "            ", "self", ".", "word_emb_matrix", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "word_emb_matrix", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "word_emb", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.model.MessageEncoder.forward": [[143, 159], ["model.MessageEncoder.word_emb_matrix", "model.MessageEncoder.dropout", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "model.MessageEncoder.encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.MessageEncoder.output_linear", "model.MessageEncoder.encoder"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_data", ",", "seq_len", ")", ":", "\n", "        ", "embeded_input", "=", "self", ".", "word_emb_matrix", "(", "input_data", ")", "\n", "embeded_input", "=", "self", ".", "dropout", "(", "embeded_input", ")", "\n", "\n", "packed_", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "embeded_input", ",", "seq_len", ",", "batch_first", "=", "True", ",", "enforce_sorted", "=", "False", ")", "\n", "\n", "if", "self", ".", "rnn_cell", "==", "'lstm'", ":", "\n", "            ", "_", ",", "hidden_state", "=", "self", ".", "encoder", "(", "packed_", ")", "\n", "h_state", "=", "hidden_state", "[", "0", "]", "\n", "", "elif", "self", ".", "rnn_cell", "==", "'gru'", ":", "\n", "            ", "_", ",", "h_state", "=", "self", ".", "encoder", "(", "packed_", ")", "\n", "\n", "", "if", "self", ".", "bidirectional", ":", "\n", "            ", "h_state_cat", "=", "torch", ".", "cat", "(", "[", "h_state", "[", "0", "]", ",", "h_state", "[", "1", "]", "]", ",", "dim", "=", "1", ")", "\n", "output_vec", "=", "self", ".", "output_linear", "(", "h_state_cat", ")", "\n", "", "return", "output_vec", "", "", "", ""]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.disentangle_inference.DatasetforDisentanglement.__init__": [[24, 29], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "training_data", ",", "seq_max_len", ",", "num_training_instances", ",", "pad_id", ")", ":", "\n", "        ", "self", ".", "training_data", "=", "training_data", "\n", "self", ".", "seq_max_len", "=", "seq_max_len", "\n", "self", ".", "num_training_instances", "=", "num_training_instances", "\n", "self", ".", "pad_id", "=", "pad_id", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.disentangle_inference.DatasetforDisentanglement.__len__": [[30, 32], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_training_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.disentangle_inference.DatasetforDisentanglement.__trunk": [[33, 37], ["len"], "methods", ["None"], ["", "def", "__trunk", "(", "self", ",", "ids", ",", "max_len", ")", ":", "\n", "        ", "if", "len", "(", "ids", ")", ">", "max_len", ":", "\n", "            ", "ids", "=", "ids", "[", ":", "max_len", "]", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.disentangle_inference.DatasetforDisentanglement.__pad": [[38, 44], ["len", "len", "len"], "methods", ["None"], ["", "def", "__pad", "(", "self", ",", "ids", ",", "max_len", ")", ":", "\n", "        ", "if", "len", "(", "ids", ")", "<", "max_len", ":", "\n", "            ", "return", "ids", "+", "[", "self", ".", "pad_id", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "ids", ")", "==", "max_len", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.disentangle_inference.DatasetforDisentanglement.__getitem__": [[45, 64], ["len", "disentangle_inference.DatasetforDisentanglement.__trunk", "len", "disentangle_inference.DatasetforDisentanglement.__pad", "messages.append", "message_seq_len.append", "labels.append", "speakers.append", "len"], "methods", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__trunk", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__pad"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "idx", "=", "idx", "%", "len", "(", "self", ".", "training_data", ")", "\n", "example", "=", "self", ".", "training_data", "[", "idx", "]", "\n", "messages", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "message_seq_len", "=", "[", "]", "\n", "speakers", "=", "[", "]", "\n", "for", "item", "in", "example", ":", "\n", "            ", "text", "=", "item", "[", "'message'", "]", "\n", "label", "=", "item", "[", "'label'", "]", "\n", "speaker", "=", "item", "[", "'speaker'", "]", "\n", "text", "=", "self", ".", "__trunk", "(", "text", ",", "self", ".", "seq_max_len", ")", "\n", "text_seq_len", "=", "len", "(", "text", ")", "\n", "text", "=", "self", ".", "__pad", "(", "text", ",", "self", ".", "seq_max_len", ")", "\n", "messages", ".", "append", "(", "text", ")", "\n", "message_seq_len", ".", "append", "(", "text_seq_len", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "speakers", ".", "append", "(", "speaker", ")", "\n", "", "return", "messages", ",", "message_seq_len", ",", "labels", ",", "len", "(", "messages", ")", ",", "speakers", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.disentangle_inference.batch_list_to_batch_tensors": [[66, 78], ["list", "list", "torch.tensor", "list", "torch.tensor", "torch.tensor", "zip", "itertools.chain", "itertools.chain"], "function", ["None"], ["", "", "def", "batch_list_to_batch_tensors", "(", "batch", ")", ":", "\n", "    ", "new_batch", "=", "list", "(", "zip", "(", "*", "batch", ")", ")", "\n", "context", ",", "context_seq_len", ",", "label_id", ",", "context_len", ",", "speakers", "=", "new_batch", "\n", "\n", "context", "=", "list", "(", "itertools", ".", "chain", "(", "*", "context", ")", ")", "\n", "context_tensor", "=", "torch", ".", "tensor", "(", "context", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "context_seq_len", "=", "list", "(", "itertools", ".", "chain", "(", "*", "context_seq_len", ")", ")", "\n", "context_seq_len_tensor", "=", "torch", ".", "tensor", "(", "context_seq_len", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "\n", "context_len", "=", "torch", ".", "tensor", "(", "context_len", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "return", "context_tensor", ",", "context_seq_len_tensor", ",", "context_len", ",", "label_id", ",", "speakers", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.disentangle_inference.read_raw_data": [[80, 86], ["print", "print", "open", "json.load", "len"], "function", ["None"], ["", "def", "read_raw_data", "(", "data_path", ")", ":", "\n", "    ", "print", "(", "\"Reading original data ...\"", ")", "\n", "with", "open", "(", "data_path", ")", "as", "fin", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "fin", ")", "\n", "", "print", "(", "\"{} data instances read from the original dataset.\"", ".", "format", "(", "len", "(", "data", ")", ")", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.disentangle_inference.tokenize_data": [[88, 107], ["print", "tqdm.tqdm", "print", "logger.info", "tokenized_data.append", "message[].split", "one_dialogue.append", "len"], "function", ["None"], ["", "def", "tokenize_data", "(", "data", ",", "cached_features_file", ",", "tokenizer", ",", "logger", ")", ":", "\n", "    ", "print", "(", "\"Tokenizing data ...\"", ")", "\n", "tokenized_data", "=", "[", "]", "\n", "for", "item", "in", "tqdm", "(", "data", ")", ":", "\n", "        ", "one_dialogue", "=", "[", "]", "\n", "for", "message", "in", "item", ":", "\n", "            ", "speaker", "=", "message", "[", "'speaker'", "]", "\n", "text", "=", "message", "[", "'text'", "]", ".", "split", "(", ")", "\n", "label", "=", "message", "[", "'label'", "]", "\n", "one_dialogue", ".", "append", "(", "{", "\n", "'speaker'", ":", "speaker", ",", "\n", "'message'", ":", "text", ",", "\n", "'label'", ":", "label", "\n", "}", ")", "\n", "", "tokenized_data", ".", "append", "(", "one_dialogue", ")", "\n", "", "print", "(", "\"Saving tokenized data into cached file {}\"", ".", "format", "(", "cached_features_file", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\"{} tokenized data read.\"", ".", "format", "(", "len", "(", "tokenized_data", ")", ")", ")", "\n", "return", "tokenized_data", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.disentangle_inference.convert_data_to_id": [[109, 130], ["tqdm.tqdm", "print", "logger.info", "data_id.append", "new_item.append", "len", "message_id.append", "word_dict.get", "word_dict.get"], "function", ["None"], ["", "def", "convert_data_to_id", "(", "data", ",", "word_dict", ",", "cached_features_file", ",", "logger", ")", ":", "\n", "    ", "data_id", "=", "[", "]", "\n", "for", "item", "in", "tqdm", "(", "data", ")", ":", "\n", "        ", "new_item", "=", "[", "]", "\n", "for", "message", "in", "item", ":", "\n", "            ", "text", "=", "message", "[", "'message'", "]", "\n", "label", "=", "message", "[", "'label'", "]", "\n", "speaker", "=", "message", "[", "'speaker'", "]", "\n", "message_id", "=", "[", "]", "\n", "for", "token", "in", "text", ":", "\n", "                ", "message_id", ".", "append", "(", "word_dict", ".", "get", "(", "token", ",", "word_dict", ".", "get", "(", "'<UNK>'", ")", ")", ")", "\n", "", "new_item", ".", "append", "(", "{", "\n", "'message'", ":", "message_id", ",", "\n", "'label'", ":", "label", ",", "\n", "'speaker'", ":", "speaker", "\n", "}", ")", "\n", "", "data_id", ".", "append", "(", "new_item", ")", "\n", "", "print", "(", "\"Saving data id into cached file {}\"", ".", "format", "(", "cached_features_file", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\"{} data id read.\"", ".", "format", "(", "len", "(", "data_id", ")", ")", ")", "\n", "return", "data_id", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.disentangle_inference.get_max_context_length": [[132, 139], ["print", "tqdm.tqdm", "logger.info", "max", "len"], "function", ["None"], ["", "def", "get_max_context_length", "(", "data_id", ",", "logger", ")", ":", "\n", "    ", "print", "(", "\"Retrieving the maximum context length ...\"", ")", "\n", "context_length", "=", "0", "\n", "for", "item", "in", "tqdm", "(", "data_id", ")", ":", "\n", "        ", "context_length", "=", "max", "(", "len", "(", "item", ")", ",", "context_length", ")", "\n", "", "logger", ".", "info", "(", "\"Max context length: {}\"", ".", "format", "(", "context_length", ")", ")", "\n", "return", "context_length", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.disentangle_inference.write_result": [[141, 155], ["range", "os.path.join", "len", "re.findall", "open", "json.dump"], "function", ["None"], ["", "def", "write_result", "(", "labels", ",", "preds", ",", "args", ")", ":", "\n", "    ", "results", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "        ", "one_pred", "=", "preds", "[", "i", "]", "\n", "one_label", "=", "labels", "[", "i", "]", "\n", "one_item", "=", "{", "\n", "'pred'", ":", "one_pred", ",", "\n", "'label'", ":", "one_label", "\n", "}", "\n", "results", "[", "i", "]", "=", "one_item", "\n", "", "checkpoint_num", "=", "re", ".", "findall", "(", "r\"ckpt-(.+?)\\.pkl\"", ",", "args", ".", "checkpoint", ")", "[", "0", "]", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "result_dir", ",", "\"{}_checkpoint_{}.json\"", ".", "format", "(", "args", ".", "data_type", ",", "checkpoint_num", ")", ")", "\n", "with", "open", "(", "filename", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "json", ".", "dump", "(", "results", ",", "fout", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.disentangle_inference.preprare": [[157, 182], ["os.path.join", "os.path.join", "os.path.join", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "logging.basicConfig", "logging.getLogger", "torch.device", "torch.cuda.device_count", "logging.getLogger.info", "transformers.BertTokenizer.from_pretrained", "json.dumps", "torch.cuda.is_available"], "function", ["None"], ["", "", "def", "preprare", "(", "args", ")", ":", "\n", "    ", "args", ".", "data_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "data_name", ",", "'tokenized'", ",", "\"{}.json\"", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n", "args", ".", "cache_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "args", ".", "cache_dir", ")", "\n", "\n", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"disentanglement\"", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "args", ".", "result_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "args", ".", "result_dir", ")", "\n", "\n", "args", ".", "cached_input_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_type", ",", "args", ".", "cached_input_dir", ",", "args", ".", "data_name", ",", "\"disentanglement\"", ")", "\n", "args", ".", "log_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}_log.txt'", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "result_dir", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "cached_input_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "LOG_FORMAT", "=", "'%(asctime)s %(name)-12s %(levelname)-8s %(message)s'", "\n", "logging", ".", "basicConfig", "(", "format", "=", "LOG_FORMAT", ",", "level", "=", "logging", ".", "INFO", ",", "filename", "=", "args", ".", "log_file", ",", "filemode", "=", "'a'", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "logger", ".", "info", "(", "json", ".", "dumps", "(", "args", ".", "__dict__", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "args", ".", "device", "=", "device", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "'bert-base-uncased'", ")", "\n", "\n", "return", "logger", ",", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.disentangle_inference.set_random_seed": [[184, 190], ["random.seed", "torch.manual_seed", "numpy.random.seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_random_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "random_seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "random_seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "random_seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "random_seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.disentangle_inference.get_args": [[192, 222], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "", "def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--data_dir'", ",", "type", "=", "str", ",", "default", "=", "\"../../data/\"", ")", "\n", "parser", ".", "add_argument", "(", "'--data_name'", ",", "type", "=", "str", ",", "default", "=", "\"movie\"", ")", "\n", "parser", ".", "add_argument", "(", "'--data_type'", ",", "type", "=", "str", ",", "choices", "=", "[", "'test'", ",", "'dev'", ",", "'train'", "]", ",", "default", "=", "\"dev\"", ")", "\n", "parser", ".", "add_argument", "(", "'--model_type'", ",", "type", "=", "str", ",", "default", "=", "\"process1\"", ")", "\n", "parser", ".", "add_argument", "(", "'--output_dir'", ",", "type", "=", "str", ",", "default", "=", "\"./output\"", ")", "\n", "parser", ".", "add_argument", "(", "'--result_dir'", ",", "type", "=", "str", ",", "default", "=", "\"disentangle_result/\"", ")", "\n", "parser", ".", "add_argument", "(", "'--cache_dir'", ",", "type", "=", "str", ",", "default", "=", "\"cached/\"", ")", "\n", "parser", ".", "add_argument", "(", "'--cached_input_dir'", ",", "type", "=", "str", ",", "default", "=", "\"cached_input\"", ")", "\n", "parser", ".", "add_argument", "(", "'--word_dict'", ",", "type", "=", "str", ",", "default", "=", "\"./process1/cached_input/movie/single/word_dict.pt\"", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--seq_max_len'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "\"the maximum length of a sequence\"", ")", "\n", "parser", ".", "add_argument", "(", "'--per_gpu_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "'--hidden_size'", ",", "type", "=", "int", ",", "default", "=", "300", ")", "\n", "parser", ".", "add_argument", "(", "'--emb_size'", ",", "type", "=", "int", ",", "default", "=", "300", ")", "\n", "parser", ".", "add_argument", "(", "'--max_session_number'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "\"--bidirectional\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether not to use bidirectional encoder\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--read_cached_input\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether not to read cached input\"", ")", "\n", "# parser.add_argument(\"--multiple_gpu\", action='store_true',", "\n", "#                     help=\"Whether not to use multiple gpu\")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether not to use CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_cell'", ",", "type", "=", "str", ",", "choices", "=", "[", "'gru'", ",", "'lstm'", "]", ",", "default", "=", "\"lstm\"", ")", "\n", "parser", ".", "add_argument", "(", "'--random_seed'", ",", "type", "=", "int", ",", "default", "=", "1234", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.disentangle_inference.main": [[224, 339], ["disentangle_inference.get_args", "disentangle_inference.preprare", "disentangle_inference.set_random_seed", "disentangle_inference.read_raw_data", "os.path.join", "disentangle_inference.tokenize_data", "torch.load", "os.path.join", "disentangle_inference.convert_data_to_id", "disentangle_inference.get_max_context_length", "print", "print", "tqdm.tqdm", "print", "list", "logger.info", "process1.model.MatchModel", "torch.nn.DataParallel", "torch.nn.DataParallel.load_state_dict", "torch.nn.DataParallel.to", "disentangle_inference.DatasetforDisentanglement", "logger.info", "logger.info", "logger.info", "torch.utils.data.DataLoader", "tqdm.tqdm", "torch.nn.DataParallel.eval", "disentangle_inference.write_result", "sorted", "os.path.join", "len", "torch.load", "len", "len", "context.to.to", "context_len.to.to", "max", "torch.nn.DataParallel.", "torch.nn.DataParallel.module.build_context_batch", "torch.zeros", "torch.ones", "range", "glob.glob", "model.module.build_context_batch.size", "torch.nn.DataParallel.module.get_decision_v2", "range", "torch.tensor().view", "torch.cat", "torch.cat.detach().cpu().numpy().tolist", "torch.cat.detach().cpu().numpy().tolist", "len", "torch.tensor().view.append", "torch.tensor", "torch.cat.detach().cpu().numpy", "range", "torch.cat.detach().cpu().numpy", "range", "speaker_list[].index", "torch.tensor().view.append", "torch.tensor().view.append", "torch.tensor().view.append", "torch.cat.detach().cpu", "torch.cat.detach().cpu", "session_number[].data.item", "torch.cat.detach", "torch.cat.detach"], "function", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.get_args", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.preprare", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.set_random_seed", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.read_raw_data", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.tokenize_data", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.convert_data_to_id", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.get_max_context_length", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.write_result", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.build_context_batch", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.get_decision_v2"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "\n", "logger", ",", "tokenizer", "=", "preprare", "(", "args", ")", "\n", "set_random_seed", "(", "args", ")", "\n", "\n", "raw_data", "=", "read_raw_data", "(", "args", ".", "data_path", ")", "\n", "# print items for debug", "\n", "for", "item", "in", "raw_data", "[", "0", ":", "2", "]", ":", "\n", "        ", "print", "(", "item", ")", "\n", "# end debug", "\n", "\n", "", "tokenized_data_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "cached_input_dir", ",", "'tokenized_{}.pt'", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n", "tokenized_data", "=", "tokenize_data", "(", "raw_data", ",", "tokenized_data_filename", ",", "tokenizer", ",", "logger", ")", "\n", "\n", "word_dict", "=", "torch", ".", "load", "(", "args", ".", "word_dict", ")", "\n", "args", ".", "pad_id", "=", "word_dict", "[", "'<PAD>'", "]", "\n", "\n", "word_emb_matrix", "=", "None", "\n", "\n", "data_id_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "cached_input_dir", ",", "'{}_data_id.pt'", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n", "data_id", "=", "convert_data_to_id", "(", "tokenized_data", ",", "word_dict", ",", "data_id_filename", ",", "logger", ")", "\n", "\n", "args", ".", "max_context_len", "=", "get_max_context_length", "(", "data_id", ",", "logger", ")", "\n", "print", "(", "\"Max context length: {}\"", ".", "format", "(", "args", ".", "max_context_len", ")", ")", "\n", "\n", "if", "args", ".", "checkpoint", "==", "-", "1", ":", "\n", "        ", "checkpoints", "=", "list", "(", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "cache_dir", "+", "\"ckpt-*\"", ",", "recursive", "=", "True", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "checkpoints", "=", "[", "os", ".", "path", ".", "join", "(", "args", ".", "cache_dir", ",", "\"ckpt-{}.pkl\"", ".", "format", "(", "args", ".", "checkpoint", ")", ")", "]", "\n", "\n", "", "print", "(", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "tqdm", "(", "checkpoints", ")", ":", "\n", "        ", "args", ".", "checkpoint", "=", "checkpoint", "\n", "logger", ".", "info", "(", "\"{} results for checkpoint: {}\"", ".", "format", "(", "args", ".", "data_type", ",", "args", ".", "checkpoint", ")", ")", "\n", "model", "=", "MatchModel", "(", "args", ".", "rnn_cell", ",", "len", "(", "word_dict", ")", ",", "word_emb_matrix", ",", "\n", "args", ".", "hidden_size", ",", "args", ".", "emb_size", ",", "args", ".", "max_context_len", ",", "\n", "bidirectional", "=", "args", ".", "bidirectional", ",", "max_session_number", "=", "args", ".", "max_session_number", ",", "\n", "inference", "=", "True", ")", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "checkpoint", ")", ")", "\n", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "dev_dataset", "=", "DatasetforDisentanglement", "(", "data_id", ",", "args", ".", "seq_max_len", ",", "len", "(", "data_id", ")", ",", "args", ".", "pad_id", ")", "\n", "\n", "# Test!", "\n", "logger", ".", "info", "(", "\"  ***** Running Testing *****  *\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "dev_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_batch_size", ")", "\n", "\n", "dev_dataloader", "=", "DataLoader", "(", "\n", "dev_dataset", ",", "\n", "batch_size", "=", "args", ".", "per_gpu_batch_size", ",", "\n", "collate_fn", "=", "batch_list_to_batch_tensors", ")", "\n", "\n", "dev_iterator", "=", "tqdm", "(", "\n", "dev_dataloader", ",", "initial", "=", "0", ",", "\n", "desc", "=", "\"Iter (loss=X.XXX, lr=X.XXXXXXX)\"", ")", "\n", "\n", "preds", "=", "None", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "for", "batch", "in", "dev_iterator", ":", "\n", "            ", "context", ",", "context_seq_len", ",", "context_len", ",", "label", ",", "speakers", "=", "batch", "\n", "context", "=", "context", ".", "to", "(", "args", ".", "device", ")", "\n", "context_len", "=", "context_len", ".", "to", "(", "args", ".", "device", ")", "\n", "max_context_len", "=", "max", "(", "context_len", ")", "\n", "context_vector", "=", "model", "(", "context", ",", "context_seq_len", ",", "context_len", ")", "\n", "context_vector", "=", "model", ".", "module", ".", "build_context_batch", "(", "context_vector", ",", "context_len", ",", "max_context_len", ")", "\n", "\n", "batch_size", "=", "context_vector", ".", "size", "(", ")", "[", "0", "]", "\n", "\n", "decision_sequence", "=", "torch", ".", "zeros", "(", "[", "batch_size", ",", "1", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "args", ".", "device", ")", "\n", "session_number", "=", "torch", ".", "ones", "(", "[", "batch_size", ",", "1", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "args", ".", "device", ")", "\n", "for", "step", "in", "range", "(", "1", ",", "max_context_len", ")", ":", "\n", "                ", "current_context", "=", "context_vector", "[", ":", ",", "0", ":", "step", ",", ":", "]", "\n", "current_message", "=", "context_vector", "[", ":", ",", "step", ",", ":", "]", "\n", "values", ",", "new_session_value", "=", "model", ".", "module", ".", "get_decision_v2", "(", "current_context", ",", "current_message", ",", "decision_sequence", ",", "session_number", ")", "\n", "current_decision", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "max_num", ",", "max_value_index", "=", "values", "[", "i", "]", "\n", "new_session_score", "=", "new_session_value", "[", "i", "]", "\n", "speaker_list", "=", "speakers", "[", "i", "]", "\n", "flag", "=", "False", "\n", "if", "step", "<", "len", "(", "speaker_list", ")", ":", "\n", "                        ", "speaker", "=", "speaker_list", "[", "step", "]", "\n", "speaker_index", "=", "speaker_list", "[", ":", "step", "]", ".", "index", "(", "speaker", ")", "if", "speaker", "in", "speaker_list", "[", ":", "step", "]", "else", "-", "1", "\n", "if", "speaker_index", "!=", "-", "1", ":", "\n", "                            ", "flag", "=", "True", "\n", "one_decision", "=", "decision_sequence", "[", "i", "]", "[", "speaker_index", "]", "\n", "", "", "if", "flag", ":", "\n", "                        ", "current_decision", ".", "append", "(", "max_value_index", ")", "\n", "", "else", ":", "\n", "                        ", "if", "new_session_score", "<", "0", ":", "\n", "                            ", "if", "session_number", "[", "i", "]", "<", "args", ".", "max_session_number", ":", "\n", "                                ", "current_decision", ".", "append", "(", "session_number", "[", "i", "]", ".", "data", ".", "item", "(", ")", ")", "\n", "session_number", "[", "i", "]", "+=", "1", "\n", "", "else", ":", "\n", "                                ", "current_decision", ".", "append", "(", "max_value_index", ")", "\n", "", "", "else", ":", "\n", "                            ", "current_decision", ".", "append", "(", "max_value_index", ")", "\n", "", "", "", "current_decision", "=", "torch", ".", "tensor", "(", "current_decision", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "args", ".", "device", ")", ".", "view", "(", "batch_size", ",", "1", ")", "\n", "decision_sequence", "=", "torch", ".", "cat", "(", "[", "decision_sequence", ",", "current_decision", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "preds", "is", "None", ":", "\n", "                ", "preds", "=", "decision_sequence", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "preds", "=", "[", "preds", "[", "i", "]", "[", ":", "context_len", "[", "i", "]", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "out_labels", "=", "label", "\n", "", "else", ":", "\n", "                ", "one_preds", "=", "decision_sequence", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "one_preds", "=", "[", "one_preds", "[", "i", "]", "[", ":", "context_len", "[", "i", "]", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "preds", "+=", "one_preds", "\n", "out_labels", "+=", "label", "\n", "", "", "write_result", "(", "out_labels", ",", "preds", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.utils.read_raw_data": [[11, 17], ["print", "print", "open", "json.load", "len"], "function", ["None"], ["def", "read_raw_data", "(", "data_path", ")", ":", "\n", "    ", "print", "(", "\"Reading original data ...\"", ")", "\n", "with", "open", "(", "data_path", ")", "as", "fin", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "fin", ")", "\n", "", "print", "(", "\"{} data instances read from the original dataset.\"", ".", "format", "(", "len", "(", "data", ")", ")", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.utils.tokenize_data": [[19, 37], ["print", "tqdm.tqdm", "print", "tokenized_data.append", "message[].split", "one_dialogue.append", "len"], "function", ["None"], ["", "def", "tokenize_data", "(", "data", ",", "tokenizer", ")", ":", "\n", "    ", "print", "(", "\"Tokenizing data ...\"", ")", "\n", "tokenized_data", "=", "[", "]", "\n", "for", "item", "in", "tqdm", "(", "data", ")", ":", "\n", "        ", "one_dialogue", "=", "[", "]", "\n", "for", "message", "in", "item", ":", "\n", "            ", "speaker", "=", "message", "[", "'speaker'", "]", "\n", "text", "=", "message", "[", "'text'", "]", ".", "split", "(", ")", "\n", "label", "=", "message", "[", "'label'", "]", "\n", "one_dialogue", ".", "append", "(", "{", "\n", "'speaker'", ":", "speaker", ",", "\n", "'message'", ":", "text", ",", "\n", "'label'", ":", "label", "\n", "}", ")", "\n", "", "tokenized_data", ".", "append", "(", "one_dialogue", ")", "\n", "\n", "", "print", "(", "\"{} tokenized data read.\"", ".", "format", "(", "len", "(", "tokenized_data", ")", ")", ")", "\n", "return", "tokenized_data", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.utils.convert_data_to_id": [[39, 58], ["print", "tqdm.tqdm", "print", "data_id.append", "new_item.append", "len", "word_dict.get", "word_dict.get"], "function", ["None"], ["", "def", "convert_data_to_id", "(", "data", ",", "word_dict", ")", ":", "\n", "    ", "print", "(", "\"Converting data to id ...\"", ")", "\n", "data_id", "=", "[", "]", "\n", "for", "item", "in", "tqdm", "(", "data", ")", ":", "\n", "        ", "new_item", "=", "[", "]", "\n", "for", "message", "in", "item", ":", "\n", "            ", "text", "=", "message", "[", "'message'", "]", "\n", "label", "=", "message", "[", "'label'", "]", "\n", "speaker", "=", "message", "[", "'speaker'", "]", "\n", "message_id", "=", "[", "word_dict", ".", "get", "(", "token", ",", "word_dict", ".", "get", "(", "'<UNK>'", ")", ")", "for", "token", "in", "text", "]", "\n", "new_item", ".", "append", "(", "{", "\n", "'message'", ":", "message_id", ",", "\n", "'label'", ":", "label", ",", "\n", "'speaker'", ":", "speaker", "\n", "}", ")", "\n", "", "data_id", ".", "append", "(", "new_item", ")", "\n", "\n", "", "print", "(", "\"{} data id read.\"", ".", "format", "(", "len", "(", "data_id", ")", ")", ")", "\n", "return", "data_id", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.utils.get_max_context_length": [[60, 67], ["print", "tqdm.tqdm", "print", "max", "len"], "function", ["None"], ["", "def", "get_max_context_length", "(", "data_id", ")", ":", "\n", "    ", "print", "(", "\"Retrieving the maximum context length ...\"", ")", "\n", "context_length", "=", "0", "\n", "for", "item", "in", "tqdm", "(", "data_id", ")", ":", "\n", "        ", "context_length", "=", "max", "(", "len", "(", "item", ")", ",", "context_length", ")", "\n", "", "print", "(", "\"Max context length: {}\"", ".", "format", "(", "context_length", ")", ")", "\n", "return", "context_length", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.utils.parse_reward": [[69, 87], ["print", "tqdm.tqdm", "range", "numpy.zeros_like", "range", "coherency_reward.append", "speaker_reward.append", "len", "len", "len", "range", "len"], "function", ["None"], ["", "def", "parse_reward", "(", "reward", ",", "data", ")", ":", "\n", "    ", "print", "(", "\"Parsing reward item ...\"", ")", "\n", "coherency_reward", "=", "[", "]", "\n", "speaker_reward", "=", "[", "]", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "data", ")", ")", ")", ":", "\n", "        ", "data_item", "=", "data", "[", "i", "]", "\n", "coherency_matrix", "=", "reward", "[", "i", "]", "[", "'reward'", "]", "\n", "assert", "coherency_matrix", ".", "shape", "[", "0", "]", "==", "len", "(", "data_item", ")", "\n", "speaker_matrix", "=", "np", ".", "zeros_like", "(", "coherency_matrix", ",", "dtype", "=", "float", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "data_item", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "data_item", ")", ")", ":", "\n", "                ", "speaker_1", "=", "data_item", "[", "i", "]", "[", "'speaker'", "]", "\n", "speaker_2", "=", "data_item", "[", "j", "]", "[", "'speaker'", "]", "\n", "val", "=", "1", "if", "speaker_1", "==", "speaker_2", "else", "0", "\n", "speaker_matrix", "[", "i", "]", "[", "j", "]", "=", "val", "\n", "", "", "coherency_reward", ".", "append", "(", "coherency_matrix", ")", "\n", "speaker_reward", ".", "append", "(", "speaker_matrix", ")", "\n", "", "return", "coherency_reward", ",", "speaker_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.rl.utils.batch_list_to_batch_tensors": [[99, 111], ["list", "list", "torch.tensor", "list", "torch.tensor", "torch.tensor", "zip", "itertools.chain", "itertools.chain"], "function", ["None"], ["", "def", "batch_list_to_batch_tensors", "(", "batch", ")", ":", "\n", "    ", "new_batch", "=", "list", "(", "zip", "(", "*", "batch", ")", ")", "\n", "context", ",", "context_seq_len", ",", "_", ",", "context_len", ",", "coherency_reward", ",", "speaker_reward", "=", "new_batch", "\n", "\n", "context", "=", "list", "(", "itertools", ".", "chain", "(", "*", "context", ")", ")", "\n", "context_tensor", "=", "torch", ".", "tensor", "(", "context", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "context_seq_len", "=", "list", "(", "itertools", ".", "chain", "(", "*", "context_seq_len", ")", ")", "\n", "context_seq_len_tensor", "=", "torch", ".", "tensor", "(", "context_seq_len", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "context_len", "=", "torch", ".", "tensor", "(", "context_len", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "return", "context_tensor", ",", "context_seq_len_tensor", ",", "context_len", ",", "coherency_reward", ",", "speaker_reward", "\n", "", ""]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.DatasetForBert.__init__": [[24, 37], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "features", ",", "max_source_len", ",", "max_seq_len", ",", "\n", "cls_id", ",", "sep_id", ",", "pad_id", ",", "mask_id", ",", "\n", "offset", ",", "num_training_instances", ")", ":", "\n", "        ", "self", ".", "features", "=", "features", "\n", "self", ".", "max_source_len", "=", "max_source_len", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "self", ".", "offset", "=", "offset", "\n", "self", ".", "cls_id", "=", "cls_id", "\n", "self", ".", "sep_id", "=", "sep_id", "\n", "self", ".", "pad_id", "=", "pad_id", "\n", "self", ".", "mask_id", "=", "mask_id", "\n", "self", ".", "num_training_instances", "=", "num_training_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.DatasetForBert.__len__": [[38, 40], ["int"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "int", "(", "self", ".", "num_training_instances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.DatasetForBert.__trunk": [[41, 46], ["len"], "methods", ["None"], ["", "def", "__trunk", "(", "self", ",", "ids", ",", "max_len", ")", ":", "\n", "        ", "if", "len", "(", "ids", ")", ">", "max_len", "-", "1", ":", "\n", "            ", "ids", "=", "ids", "[", ":", "max_len", "-", "1", "]", "\n", "", "ids", "=", "ids", "+", "[", "self", ".", "sep_id", "]", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.DatasetForBert.__pad": [[47, 53], ["len", "len", "len"], "methods", ["None"], ["", "def", "__pad", "(", "self", ",", "ids", ",", "max_len", ")", ":", "\n", "        ", "if", "len", "(", "ids", ")", "<", "max_len", ":", "\n", "            ", "return", "ids", "+", "[", "self", ".", "pad_id", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "ids", ")", "==", "max_len", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.DatasetForBert.__getitem__": [[54, 71], ["bert_train.DatasetForBert.__trunk", "bert_train.DatasetForBert.__pad", "bert_train.DatasetForBert.__trunk", "bert_train.DatasetForBert.__pad", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__trunk", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__pad", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__trunk", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__pad"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "idx", "=", "(", "self", ".", "offset", "+", "idx", ")", "%", "len", "(", "self", ".", "features", ")", "\n", "feature", "=", "self", ".", "features", "[", "idx", "]", "\n", "\n", "source_id_1", "=", "self", ".", "__trunk", "(", "[", "self", ".", "cls_id", "]", "+", "feature", "[", "\"sent1\"", "]", ",", "self", ".", "max_source_len", ")", "\n", "segment_id_1", "=", "[", "0", "]", "*", "len", "(", "source_id_1", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_source_len", "-", "len", "(", "source_id_1", ")", ")", "\n", "input_mask_1", "=", "[", "1", "]", "*", "len", "(", "source_id_1", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_source_len", "-", "len", "(", "source_id_1", ")", ")", "\n", "input_id_1", "=", "self", ".", "__pad", "(", "source_id_1", ",", "self", ".", "max_source_len", ")", "\n", "\n", "source_id_2", "=", "self", ".", "__trunk", "(", "[", "self", ".", "cls_id", "]", "+", "feature", "[", "\"sent2\"", "]", ",", "self", ".", "max_source_len", ")", "\n", "segment_id_2", "=", "[", "0", "]", "*", "len", "(", "source_id_2", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_source_len", "-", "len", "(", "source_id_2", ")", ")", "\n", "input_mask_2", "=", "[", "1", "]", "*", "len", "(", "source_id_2", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_source_len", "-", "len", "(", "source_id_2", ")", ")", "\n", "input_id_2", "=", "self", ".", "__pad", "(", "source_id_2", ",", "self", ".", "max_source_len", ")", "\n", "\n", "label_id", "=", "feature", "[", "\"label\"", "]", "\n", "return", "input_id_1", ",", "input_mask_1", ",", "segment_id_1", ",", "input_id_2", ",", "input_mask_2", ",", "segment_id_2", ",", "label_id", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.read_data": [[73, 78], ["print", "open", "json.load"], "function", ["None"], ["", "", "def", "read_data", "(", "filename", ")", ":", "\n", "    ", "print", "(", "\"Reading data from {} ...\"", ".", "format", "(", "filename", ")", ")", "\n", "with", "open", "(", "filename", ")", "as", "fin", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "fin", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.tokenize_data": [[80, 98], ["os.path.exists", "print", "torch.load", "torch.load", "torch.load", "print", "tqdm.tqdm", "torch.save", "torch.save", "torch.save", "tokenizer.convert_tokens_to_ids", "tokenizer.convert_tokens_to_ids", "torch.load.append", "sent1.split", "sent2.split"], "function", ["None"], ["", "def", "tokenize_data", "(", "train_data", ",", "tokenizer", ",", "filename", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "        ", "print", "(", "\"Loading tokenized data ...\"", ")", "\n", "data", "=", "torch", ".", "load", "(", "filename", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Tokenizing data ...\"", ")", "\n", "data", "=", "[", "]", "\n", "for", "item", "in", "tqdm", "(", "train_data", ")", ":", "\n", "            ", "sent1", ",", "sent2", ",", "label", "=", "item", "\n", "sent1_id", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "sent1", ".", "split", "(", ")", ")", "\n", "sent2_id", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "sent2", ".", "split", "(", ")", ")", "\n", "data", ".", "append", "(", "{", "\n", "'sent1'", ":", "sent1_id", ",", "\n", "'sent2'", ":", "sent2_id", ",", "\n", "'label'", ":", "label", ",", "\n", "}", ")", "\n", "", "torch", ".", "save", "(", "data", ",", "filename", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.get_model_and_tokenizer": [[100, 104], ["transformers.BertModel.from_pretrained", "transformers.BertTokenizer.from_pretrained"], "function", ["None"], ["", "def", "get_model_and_tokenizer", "(", "model_config", ")", ":", "\n", "    ", "model", "=", "BertModel", ".", "from_pretrained", "(", "model_config", ")", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "model_config", ")", "\n", "return", "model", ",", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.prepare_for_training": [[106, 130], ["transformers.AdamW", "amp.initialize", "transformers.AdamW.load_state_dict", "torch.nn.DataParallel.load_state_dict", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "amp.load_state_dict", "torch.nn.DataParallel.named_parameters", "torch.nn.DataParallel.named_parameters", "any", "any"], "function", ["None"], ["", "def", "prepare_for_training", "(", "args", ",", "model", ",", "checkpoint_state_dict", ",", "amp", "=", "None", ")", ":", "\n", "# define the optimizer", "\n", "    ", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "\n", "if", "amp", ":", "\n", "        ", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "if", "checkpoint_state_dict", ":", "\n", "            ", "amp", ".", "load_state_dict", "(", "checkpoint_state_dict", "[", "'amp'", "]", ")", "\n", "\n", "", "", "if", "checkpoint_state_dict", ":", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "checkpoint_state_dict", "[", "'optimizer'", "]", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint_state_dict", "[", "'model'", "]", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "", "return", "model", ",", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.batch_list_to_batch_tensors": [[132, 142], ["enumerate", "zip", "isinstance", "batch_tensors.append", "batch_tensors.append", "batch_tensors.append", "torch.stack", "torch.stack", "torch.stack", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "batch_list_to_batch_tensors", "(", "batch", ")", ":", "\n", "    ", "batch_tensors", "=", "[", "]", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "zip", "(", "*", "batch", ")", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", "[", "0", "]", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "batch_tensors", ".", "append", "(", "torch", ".", "stack", "(", "x", ")", ")", "\n", "", "if", "i", "==", "6", ":", "\n", "            ", "batch_tensors", ".", "append", "(", "torch", ".", "tensor", "(", "x", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "", "else", ":", "\n", "            ", "batch_tensors", ".", "append", "(", "torch", ".", "tensor", "(", "x", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "", "", "return", "batch_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.train": [[144, 273], ["model.to", "bert_train.prepare_for_training", "transformers.get_linear_schedule_with_warmup", "bert_train.DatasetForBert", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "tqdm.tqdm", "model.train", "model.zero_grad", "enumerate", "int", "transformers.get_linear_schedule_with_warmup.load_state_dict", "len", "tuple", "args.model_config.startswith", "args.model_config.startswith", "torch.matmul().squeeze().squeeze", "torch.matmul().squeeze().squeeze", "torch.matmul().squeeze().squeeze", "torch.BCELoss", "nn.BCELoss.", "tqdm.tqdm.set_description", "loss.mean.item", "len", "len", "model", "model", "torch.Sigmoid", "loss.mean.mean", "loss.mean.backward", "optimizer.step", "transformers.get_linear_schedule_with_warmup.step", "model.zero_grad", "t.to", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "logger.info", "os.path.join", "os.makedirs", "model_to_save.save_pretrained", "logger.info", "len", "loss.mean.item", "amp.master_params", "model.parameters", "hasattr", "torch.matmul", "torch.matmul", "torch.matmul", "transformers.get_linear_schedule_with_warmup.get_last_lr", "sent1_vec.unsqueeze", "sent2_vec.unsqueeze().permute", "sent2_vec.unsqueeze"], "function", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.prepare_for_training", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.train"], ["", "def", "train", "(", "args", ",", "model", ",", "tokenizer", ",", "training_data", ",", "logger", ")", ":", "\n", "    ", "if", "args", ".", "fp16", ":", "\n", "        ", "from", "apex", "import", "amp", "\n", "", "else", ":", "\n", "        ", "amp", "=", "None", "\n", "\n", "", "checkpoint_state_dict", "=", "None", "\n", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "model", ",", "optimizer", "=", "prepare_for_training", "(", "args", ",", "model", ",", "checkpoint_state_dict", ",", "amp", "=", "amp", ")", "\n", "\n", "# define the total batch size", "\n", "if", "args", ".", "n_gpu", "==", "0", "or", "args", ".", "no_cuda", ":", "\n", "        ", "per_node_train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "\n", "", "else", ":", "\n", "        ", "per_node_train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "args", ".", "n_gpu", "*", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "args", ".", "train_batch_size", "=", "per_node_train_batch_size", "\n", "global_step", "=", "0", "\n", "\n", "# the total training steps", "\n", "if", "args", ".", "num_training_steps", "==", "-", "1", ":", "\n", "        ", "args", ".", "num_training_steps", "=", "int", "(", "args", ".", "num_training_epochs", "*", "len", "(", "training_data", ")", "/", "args", ".", "train_batch_size", ")", "\n", "\n", "", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "num_warmup_steps", ",", "\n", "num_training_steps", "=", "args", ".", "num_training_steps", ",", "last_epoch", "=", "-", "1", ")", "\n", "\n", "if", "checkpoint_state_dict", ":", "\n", "        ", "scheduler", ".", "load_state_dict", "(", "checkpoint_state_dict", "[", "\"lr_scheduler\"", "]", ")", "\n", "\n", "# dataset", "\n", "", "train_dataset", "=", "DatasetForBert", "(", "\n", "features", "=", "training_data", ",", "\n", "max_source_len", "=", "args", ".", "max_source_len", ",", "\n", "max_seq_len", "=", "args", ".", "max_len", ",", "\n", "cls_id", "=", "tokenizer", ".", "cls_token_id", ",", "sep_id", "=", "tokenizer", ".", "sep_token_id", ",", "\n", "pad_id", "=", "tokenizer", ".", "pad_token_id", ",", "mask_id", "=", "tokenizer", ".", "mask_token_id", ",", "\n", "offset", "=", "args", ".", "train_batch_size", "*", "global_step", ",", "\n", "num_training_instances", "=", "args", ".", "train_batch_size", "*", "args", ".", "num_training_steps", ",", "\n", ")", "\n", "\n", "# Train!", "\n", "logger", ".", "info", "(", "\"  ***** Running training *****  *\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "training_data", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %.2f\"", ",", "len", "(", "train_dataset", ")", "/", "len", "(", "training_data", ")", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Batch size per node = %d\"", ",", "per_node_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "args", ".", "num_training_steps", ")", "\n", "\n", "# The training features are shuffled", "\n", "train_sampler", "=", "SequentialSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "per_node_train_batch_size", "//", "args", ".", "gradient_accumulation_steps", ",", "\n", "collate_fn", "=", "batch_list_to_batch_tensors", ")", "\n", "\n", "train_iterator", "=", "tqdm", "(", "\n", "train_dataloader", ",", "initial", "=", "global_step", ",", "\n", "desc", "=", "\"Iter (loss=X.XXX, lr=X.XXXXXXX)\"", ",", "disable", "=", "False", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "logging_loss", "=", "0.0", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_iterator", ")", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "labels", "=", "batch", "[", "6", "]", "\n", "inputs_1", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "}", "\n", "if", "args", ".", "model_config", ".", "startswith", "(", "'bert'", ")", ":", "\n", "            ", "inputs_1", "[", "'token_type_ids'", "]", "=", "batch", "[", "2", "]", "\n", "\n", "", "sent1_vec", "=", "model", "(", "**", "inputs_1", ")", "[", "1", "]", "\n", "\n", "inputs_2", "=", "{", "'input_ids'", ":", "batch", "[", "3", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "4", "]", ",", "\n", "}", "\n", "if", "args", ".", "model_config", ".", "startswith", "(", "'bert'", ")", ":", "\n", "            ", "inputs_2", "[", "'token_type_ids'", "]", "=", "batch", "[", "5", "]", "\n", "\n", "", "sent2_vec", "=", "model", "(", "**", "inputs_2", ")", "[", "1", "]", "\n", "\n", "score", "=", "torch", ".", "matmul", "(", "sent1_vec", ".", "unsqueeze", "(", "1", ")", ",", "sent2_vec", ".", "unsqueeze", "(", "1", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "logits", "=", "nn", ".", "Sigmoid", "(", ")", "(", "score", ")", "\n", "\n", "loss_fct", "=", "nn", ".", "BCELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ",", "labels", ")", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "            ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel (not distributed) training", "\n", "\n", "", "train_iterator", ".", "set_description", "(", "'Iter (loss=%5.3f) lr=%9.7f'", "%", "(", "loss", ".", "item", "(", ")", ",", "scheduler", ".", "get_last_lr", "(", ")", "[", "0", "]", ")", ")", "\n", "\n", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "            ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "            ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "logging_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "            ", "if", "args", ".", "fp16", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\" Step [%d ~ %d]: %.2f\"", ",", "global_step", "-", "args", ".", "logging_steps", ",", "global_step", ",", "logging_loss", ")", "\n", "logging_loss", "=", "0.0", "\n", "\n", "", "if", "args", ".", "save_steps", ">", "0", "and", "(", "global_step", "%", "args", ".", "save_steps", "==", "0", "or", "global_step", "==", "args", ".", "num_training_steps", ")", ":", "\n", "                ", "save_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "cache_dir", ",", "\"ckpt-%d\"", "%", "global_step", ")", "\n", "os", ".", "makedirs", "(", "save_path", ",", "exist_ok", "=", "True", ")", "\n", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", "model_to_save", ".", "save_pretrained", "(", "save_path", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint %d into %s\"", ",", "global_step", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.prepare": [[275, 309], ["time.strftime", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "logging.basicConfig", "logging.getLogger", "torch.device", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "logging.getLogger.info", "logging.getLogger.info", "time.gmtime", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "json.dumps", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "apex.amp.register_half_function", "apex.amp.register_float_function", "ImportError"], "function", ["None"], ["", "", "", "", "def", "prepare", "(", "args", ")", ":", "\n", "    ", "args", ".", "current_time", "=", "strftime", "(", "\"%Y-%b-%d-%H_%M_%S\"", ",", "gmtime", "(", ")", ")", "\n", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "args", ".", "data_name", ",", "args", ".", "aug_type", ",", "args", ".", "current_time", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "", "args", ".", "cache_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "args", ".", "cache_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "cache_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "cache_dir", ")", "\n", "\n", "", "args", ".", "cached_input_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "cached_input_dir", ",", "args", ".", "data_name", ",", "args", ".", "aug_type", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "cached_input_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "cached_input_dir", ")", "\n", "\n", "# define the logger", "\n", "", "logger_name", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"log.txt\"", ")", "\n", "LOG_FORMAT", "=", "'%(asctime)s %(name)-12s %(levelname)-8s %(message)s'", "\n", "logging", ".", "basicConfig", "(", "format", "=", "LOG_FORMAT", ",", "level", "=", "logging", ".", "INFO", ",", "filename", "=", "logger_name", ",", "filemode", "=", "'a'", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "logger_msg", "=", "'\\n========================='", "\n", "logger", ".", "info", "(", "logger_msg", ")", "\n", "logger", ".", "info", "(", "json", ".", "dumps", "(", "args", ".", "__dict__", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "args", ".", "device", "=", "device", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "apex", ".", "amp", ".", "register_half_function", "(", "torch", ",", "'einsum'", ")", "\n", "apex", ".", "amp", ".", "register_float_function", "(", "torch", ",", "'sigmoid'", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.get_args": [[311, 342], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--data_dir'", ",", "type", "=", "str", ",", "default", "=", "'../data/'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_name'", ",", "type", "=", "str", ",", "choices", "=", "[", "'movie'", "]", ",", "default", "=", "'movie'", ")", "\n", "parser", ".", "add_argument", "(", "'--aug_type'", ",", "type", "=", "str", ",", "choices", "=", "[", "'same_speaker'", ",", "'filtered_same_speaker'", ",", "'mix'", ",", "'gold'", "]", ",", "default", "=", "'same_speaker'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_config'", ",", "type", "=", "str", ",", "default", "=", "'bert-base-uncased'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_dir'", ",", "type", "=", "str", ",", "default", "=", "'output'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_source_len'", ",", "type", "=", "int", ",", "default", "=", "64", ")", "\n", "parser", ".", "add_argument", "(", "'--max_len'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ")", "\n", "parser", ".", "add_argument", "(", "'--adam_epsilon'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "type", "=", "float", ",", "default", "=", "1e-2", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--num_training_steps'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--num_training_epochs'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--num_warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "1000", ")", "\n", "parser", ".", "add_argument", "(", "'--max_grad_norm'", ",", "type", "=", "float", ",", "default", "=", "1.0", ")", "\n", "parser", ".", "add_argument", "(", "'--no_cuda'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--per_gpu_train_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "1000", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "8000", ")", "\n", "parser", ".", "add_argument", "(", "'--cached_input_dir'", ",", "type", "=", "str", ",", "default", "=", "'cached_input'", ")", "\n", "parser", ".", "add_argument", "(", "'--cache_dir'", ",", "type", "=", "str", ",", "default", "=", "'cache'", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.main": [[344, 359], ["bert_train.get_args", "bert_train.prepare", "bert_train.get_model_and_tokenizer", "os.path.join", "bert_train.read_data", "os.path.join", "bert_train.tokenize_data", "model.to", "bert_train.train"], "function", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.get_args", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.prepare", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.get_model_and_tokenizer", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.read_data", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.tokenize_data", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.train"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "logger", "=", "prepare", "(", "args", ")", "\n", "\n", "model", ",", "tokenizer", "=", "get_model_and_tokenizer", "(", "args", ".", "model_config", ")", "\n", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "data_name", ",", "args", ".", "aug_type", ",", "'train.json'", ")", "\n", "train_data", "=", "read_data", "(", "filename", ")", "\n", "\n", "cached_tokenized_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "cached_input_dir", ",", "\"tokenized_train.pt\"", ")", "\n", "tokenized_data", "=", "tokenize_data", "(", "train_data", ",", "tokenizer", ",", "cached_tokenized_filename", ")", "\n", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "train", "(", "args", ",", "model", ",", "tokenizer", ",", "tokenized_data", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.DatasetForBertEval.__init__": [[21, 29], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "features", ",", "max_source_len", ",", "max_len", ",", "cls_id", ",", "sep_id", ",", "pad_id", ",", "mask_id", ")", ":", "\n", "        ", "self", ".", "features", "=", "features", "\n", "self", ".", "max_source_len", "=", "max_source_len", "\n", "self", ".", "max_seq_len", "=", "max_len", "\n", "self", ".", "cls_id", "=", "cls_id", "\n", "self", ".", "sep_id", "=", "sep_id", "\n", "self", ".", "pad_id", "=", "pad_id", "\n", "self", ".", "mask_id", "=", "mask_id", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.DatasetForBertEval.__len__": [[30, 32], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.DatasetForBertEval.__trunk": [[33, 38], ["len"], "methods", ["None"], ["", "def", "__trunk", "(", "self", ",", "ids", ",", "max_len", ")", ":", "\n", "        ", "if", "len", "(", "ids", ")", ">", "max_len", "-", "1", ":", "\n", "            ", "ids", "=", "ids", "[", ":", "max_len", "-", "1", "]", "\n", "", "ids", "=", "ids", "+", "[", "self", ".", "sep_id", "]", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.DatasetForBertEval.__pad": [[39, 45], ["len", "len", "len"], "methods", ["None"], ["", "def", "__pad", "(", "self", ",", "ids", ",", "max_len", ")", ":", "\n", "        ", "if", "len", "(", "ids", ")", "<", "max_len", ":", "\n", "            ", "return", "ids", "+", "[", "self", ".", "pad_id", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "ids", ")", "==", "max_len", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.DatasetForBertEval.__getitem__": [[46, 64], ["bert_eval_disentangle.DatasetForBertEval.__trunk", "bert_eval_disentangle.DatasetForBertEval.__pad", "bert_eval_disentangle.DatasetForBertEval.__trunk", "bert_eval_disentangle.DatasetForBertEval.__pad", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__trunk", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__pad", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__trunk", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__pad"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "feature", "=", "self", ".", "features", "[", "idx", "]", "\n", "\n", "source_id_1", "=", "self", ".", "__trunk", "(", "[", "self", ".", "cls_id", "]", "+", "feature", "[", "\"text1_id\"", "]", ",", "self", ".", "max_source_len", ")", "\n", "segment_id_1", "=", "[", "0", "]", "*", "len", "(", "source_id_1", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_source_len", "-", "len", "(", "source_id_1", ")", ")", "\n", "input_mask_1", "=", "[", "1", "]", "*", "len", "(", "source_id_1", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_source_len", "-", "len", "(", "source_id_1", ")", ")", "\n", "input_id_1", "=", "self", ".", "__pad", "(", "source_id_1", ",", "self", ".", "max_source_len", ")", "\n", "\n", "source_id_2", "=", "self", ".", "__trunk", "(", "[", "self", ".", "cls_id", "]", "+", "feature", "[", "\"text2_id\"", "]", ",", "self", ".", "max_source_len", ")", "\n", "segment_id_2", "=", "[", "0", "]", "*", "len", "(", "source_id_2", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_source_len", "-", "len", "(", "source_id_2", ")", ")", "\n", "input_mask_2", "=", "[", "1", "]", "*", "len", "(", "source_id_2", ")", "+", "[", "0", "]", "*", "(", "self", ".", "max_source_len", "-", "len", "(", "source_id_2", ")", ")", "\n", "input_id_2", "=", "self", ".", "__pad", "(", "source_id_2", ",", "self", ".", "max_source_len", ")", "\n", "\n", "pos1", "=", "feature", "[", "'pos1'", "]", "\n", "pos2", "=", "feature", "[", "'pos2'", "]", "\n", "item_num", "=", "feature", "[", "'item_num'", "]", "\n", "return", "input_id_1", ",", "input_mask_1", ",", "segment_id_1", ",", "input_id_2", ",", "input_mask_2", ",", "segment_id_2", ",", "pos1", ",", "pos2", ",", "item_num", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.batch_list_to_batch_tensors": [[66, 74], ["enumerate", "zip", "batch_tensors.append", "batch_tensors.append", "torch.tensor", "torch.tensor", "numpy.asarray"], "function", ["None"], ["", "", "def", "batch_list_to_batch_tensors", "(", "batch", ")", ":", "\n", "    ", "batch_tensors", "=", "[", "]", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "zip", "(", "*", "batch", ")", ")", ":", "\n", "        ", "if", "i", "<=", "5", ":", "\n", "            ", "batch_tensors", ".", "append", "(", "torch", ".", "tensor", "(", "x", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "", "else", ":", "\n", "            ", "batch_tensors", ".", "append", "(", "np", ".", "asarray", "(", "x", ")", ")", "\n", "", "", "return", "batch_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.read_data": [[76, 81], ["print", "open", "json.load"], "function", ["None"], ["", "def", "read_data", "(", "filename", ")", ":", "\n", "    ", "print", "(", "\"Reading data from {} ...\"", ".", "format", "(", "filename", ")", ")", "\n", "with", "open", "(", "filename", ")", "as", "fin", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "fin", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.tokenize_data": [[83, 107], ["os.path.exists", "print", "torch.load", "torch.load", "print", "tqdm.tqdm", "torch.save", "torch.save", "enumerate", "enumerate", "torch.load.append", "msg.split", "new_item.append"], "function", ["None"], ["", "def", "tokenize_data", "(", "entangled_data", ",", "tokenizer", ",", "filename", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "        ", "print", "(", "\"Loading tokenized data ...\"", ")", "\n", "data", "=", "torch", ".", "load", "(", "filename", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Tokenizing data ...\"", ")", "\n", "data", "=", "[", "]", "\n", "for", "i", ",", "item", "in", "tqdm", "(", "enumerate", "(", "entangled_data", ")", ")", ":", "\n", "            ", "new_item", "=", "[", "]", "\n", "for", "j", ",", "utterance", "in", "enumerate", "(", "item", ")", ":", "\n", "# speaker = utterance['speaker']", "\n", "                ", "msg", "=", "utterance", "[", "'text'", "]", "\n", "label", "=", "utterance", "[", "'label'", "]", "\n", "# tokenized_msg = tokenizer.tokenize(msg)", "\n", "tokenized_msg", "=", "msg", ".", "split", "(", ")", "\n", "new_item", ".", "append", "(", "{", "\n", "'msg'", ":", "tokenized_msg", ",", "\n", "'label'", ":", "label", ",", "\n", "'item_num'", ":", "i", ",", "\n", "'position'", ":", "j", ",", "\n", "}", ")", "\n", "", "data", ".", "append", "(", "new_item", ")", "\n", "", "torch", ".", "save", "(", "data", ",", "filename", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.flatten_utterance": [[109, 143], ["os.path.exists", "torch.load", "torch.load", "tqdm.tqdm", "torch.save", "torch.save", "range", "one_label.append", "len", "range", "new_data.append", "tokenizer.convert_tokens_to_ids", "tokenizer.convert_tokens_to_ids"], "function", ["None"], ["", "def", "flatten_utterance", "(", "data", ",", "tokenizer", ",", "filename", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "        ", "new_data", ",", "labels", "=", "torch", ".", "load", "(", "filename", ")", "\n", "", "else", ":", "\n", "        ", "labels", "=", "{", "}", "\n", "for", "item", "in", "data", ":", "\n", "            ", "one_label", "=", "[", "]", "\n", "item_num", "=", "-", "1", "\n", "for", "utterance", "in", "item", ":", "\n", "                ", "item_num", "=", "utterance", "[", "'item_num'", "]", "\n", "label", "=", "utterance", "[", "'label'", "]", "\n", "one_label", ".", "append", "(", "label", ")", "\n", "", "labels", "[", "item_num", "]", "=", "one_label", "\n", "\n", "", "new_data", "=", "[", "]", "\n", "for", "item", "in", "tqdm", "(", "data", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "1", ",", "len", "(", "item", ")", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "i", ")", ":", "\n", "                    ", "msg1", "=", "item", "[", "j", "]", "\n", "msg2", "=", "item", "[", "i", "]", "\n", "text1", "=", "msg1", "[", "'msg'", "]", "\n", "text2", "=", "msg2", "[", "'msg'", "]", "\n", "msg1_pos", "=", "msg1", "[", "'position'", "]", "\n", "msg2_pos", "=", "msg2", "[", "'position'", "]", "\n", "item_num", "=", "msg1", "[", "'item_num'", "]", "\n", "new_data", ".", "append", "(", "{", "\n", "'text1_id'", ":", "tokenizer", ".", "convert_tokens_to_ids", "(", "text1", ")", ",", "\n", "'text2_id'", ":", "tokenizer", ".", "convert_tokens_to_ids", "(", "text2", ")", ",", "\n", "'pos1'", ":", "msg1_pos", ",", "\n", "'pos2'", ":", "msg2_pos", ",", "\n", "'item_num'", ":", "item_num", "\n", "}", ")", "\n", "", "", "", "torch", ".", "save", "(", "[", "new_data", ",", "labels", "]", ",", "filename", ")", "\n", "", "return", "new_data", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.get_model_and_tokenizer": [[145, 152], ["transformers.BertTokenizer.from_pretrained", "transformers.BertModel.from_pretrained", "transformers.BertModel.from_pretrained"], "function", ["None"], ["", "def", "get_model_and_tokenizer", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "model_path", "is", "not", "'none'", ":", "\n", "        ", "model", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "model_path", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "BertModel", ".", "from_pretrained", "(", "args", ".", "model_config", ")", "\n", "", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "model_config", ")", "\n", "return", "model", ",", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.evaluate": [[154, 223], ["bert_eval_disentangle.DatasetForBertEval", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "logger.info", "bert_eval_disentangle.parse_predictions", "amp.initialize", "max", "torch.nn.DataParallel", "torch.nn.DataParallel", "len", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "open", "json.dump", "isinstance", "torch.nn.DataParallel.eval", "args.model_config.startswith", "args.model_config.startswith", "torch.matmul().squeeze().squeeze", "torch.matmul().squeeze().squeeze", "torch.nn.DataParallel.", "torch.nn.DataParallel.", "torch.Sigmoid", "probs.detach().cpu().numpy", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "item.to", "enumerate", "torch.matmul().squeeze", "torch.matmul().squeeze", "probs.detach().cpu().numpy", "probs.detach().cpu", "torch.matmul", "torch.matmul", "probs.detach().cpu", "sent1_vec.unsqueeze", "sent2_vec.unsqueeze().permute", "probs.detach", "probs.detach", "sent2_vec.unsqueeze"], "function", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.parse_predictions"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "data", ",", "labels", ",", "res_filename", ",", "logger", ")", ":", "\n", "    ", "if", "args", ".", "fp16", ":", "\n", "        ", "from", "apex", "import", "amp", "\n", "", "else", ":", "\n", "        ", "amp", "=", "None", "\n", "\n", "", "if", "amp", ":", "\n", "        ", "model", "=", "amp", ".", "initialize", "(", "model", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "", "eval_dataset", "=", "DatasetForBertEval", "(", "\n", "features", "=", "data", ",", "max_source_len", "=", "args", ".", "max_source_len", ",", "\n", "max_len", "=", "args", ".", "max_len", ",", "\n", "cls_id", "=", "tokenizer", ".", "cls_token_id", ",", "sep_id", "=", "tokenizer", ".", "sep_token_id", ",", "\n", "pad_id", "=", "tokenizer", ".", "pad_token_id", ",", "mask_id", "=", "tokenizer", ".", "mask_token_id", "\n", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "\n", "batch_size", "=", "args", ".", "eval_batch_size", ",", "\n", "collate_fn", "=", "batch_list_to_batch_tensors", ")", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "not", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Num of GPUs = %d\"", ",", "args", ".", "n_gpu", ")", "\n", "all_pos1", "=", "None", "\n", "all_pos2", "=", "None", "\n", "all_item_nums", "=", "None", "\n", "all_probs", "=", "None", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "[", "item", ".", "to", "(", "args", ".", "device", ")", "if", "i", "<=", "5", "else", "item", "for", "i", ",", "item", "in", "enumerate", "(", "batch", ")", "]", "\n", "input_id_1", ",", "input_mask_1", ",", "segment_id_1", ",", "input_id_2", ",", "input_mask_2", ",", "segment_id_2", ",", "pos1", ",", "pos2", ",", "item_num", "=", "batch", "\n", "inputs_1", "=", "{", "'input_ids'", ":", "input_id_1", ",", "\n", "'attention_mask'", ":", "input_mask_1", ",", "\n", "}", "\n", "if", "args", ".", "model_config", ".", "startswith", "(", "'bert'", ")", ":", "\n", "                ", "inputs_1", "[", "'token_type_ids'", "]", "=", "segment_id_1", "\n", "", "sent1_vec", "=", "model", "(", "**", "inputs_1", ")", "[", "1", "]", "\n", "\n", "inputs_2", "=", "{", "'input_ids'", ":", "input_id_2", ",", "\n", "'attention_mask'", ":", "input_mask_2", ",", "\n", "}", "\n", "if", "args", ".", "model_config", ".", "startswith", "(", "'bert'", ")", ":", "\n", "                ", "inputs_2", "[", "'token_type_ids'", "]", "=", "segment_id_2", "\n", "", "sent2_vec", "=", "model", "(", "**", "inputs_2", ")", "[", "1", "]", "\n", "\n", "score", "=", "torch", ".", "matmul", "(", "sent1_vec", ".", "unsqueeze", "(", "1", ")", ",", "sent2_vec", ".", "unsqueeze", "(", "1", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "probs", "=", "nn", ".", "Sigmoid", "(", ")", "(", "score", ")", "\n", "if", "all_probs", "is", "None", ":", "\n", "                ", "all_probs", "=", "probs", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "all_pos1", "=", "pos1", "\n", "all_pos2", "=", "pos2", "\n", "all_item_nums", "=", "item_num", "\n", "", "else", ":", "\n", "                ", "all_probs", "=", "np", ".", "append", "(", "all_probs", ",", "probs", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "all_pos1", "=", "np", ".", "append", "(", "all_pos1", ",", "pos1", ",", "axis", "=", "0", ")", "\n", "all_pos2", "=", "np", ".", "append", "(", "all_pos2", ",", "pos2", ",", "axis", "=", "0", ")", "\n", "all_item_nums", "=", "np", ".", "append", "(", "all_item_nums", ",", "item_num", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "", "predictions", "=", "parse_predictions", "(", "all_probs", ",", "all_pos1", ",", "all_pos2", ",", "all_item_nums", ")", "\n", "with", "open", "(", "res_filename", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "json", ".", "dump", "(", "[", "predictions", ",", "labels", "]", ",", "fout", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.parse_predictions": [[225, 242], ["print", "tqdm.tqdm", "range", "round", "int", "int", "int", "len", "float"], "function", ["None"], ["", "", "def", "parse_predictions", "(", "probs", ",", "all_pos1", ",", "all_pos2", ",", "all_item_num", ")", ":", "\n", "    ", "preds_dict", "=", "{", "}", "\n", "print", "(", "\"Parsing Predictions ... \"", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "all_item_num", ")", ")", ")", ":", "\n", "        ", "prob", "=", "round", "(", "float", "(", "probs", "[", "i", "]", ")", ",", "4", ")", "\n", "pos1", "=", "int", "(", "all_pos1", "[", "i", "]", ")", "\n", "pos2", "=", "int", "(", "all_pos2", "[", "i", "]", ")", "\n", "item_num", "=", "int", "(", "all_item_num", "[", "i", "]", ")", "\n", "if", "item_num", "not", "in", "preds_dict", ":", "\n", "            ", "preds_dict", "[", "item_num", "]", "=", "{", "}", "\n", "", "if", "pos1", "not", "in", "preds_dict", "[", "item_num", "]", ":", "\n", "            ", "preds_dict", "[", "item_num", "]", "[", "pos1", "]", "=", "{", "}", "\n", "", "if", "pos2", "not", "in", "preds_dict", "[", "item_num", "]", ":", "\n", "            ", "preds_dict", "[", "item_num", "]", "[", "pos2", "]", "=", "{", "}", "\n", "", "preds_dict", "[", "item_num", "]", "[", "pos1", "]", "[", "pos2", "]", "=", "prob", "\n", "preds_dict", "[", "item_num", "]", "[", "pos2", "]", "[", "pos1", "]", "=", "prob", "\n", "", "return", "preds_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.prepare": [[244, 285], ["os.path.join", "os.path.join", "os.path.join", "logging.basicConfig", "logging.getLogger", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "logging.getLogger.info", "logging.getLogger.info", "os.path.join", "time.strftime", "os.path.join", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "json.dumps", "re.findall", "re.findall", "time.gmtime", "torch.cuda.is_available", "torch.cuda.is_available", "apex.amp.register_half_function", "ImportError"], "function", ["None"], ["", "def", "prepare", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "model_path", "is", "not", "'none'", ":", "\n", "        ", "args", ".", "current_time", "=", "re", ".", "findall", "(", "\".*(2021.+?)/.*\"", ",", "args", ".", "model_path", ")", "[", "0", "]", "\n", "checkpoint", "=", "re", ".", "findall", "(", "\".*ckpt-(.+?)/.*\"", ",", "args", ".", "model_path", ")", "[", "0", "]", "\n", "args", ".", "result_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "args", ".", "data_name", ",", "args", ".", "aug_type", ",", "args", ".", "current_time", ",", "args", ".", "result_dir", ",", "checkpoint", ")", "\n", "", "else", ":", "\n", "        ", "args", ".", "current_time", "=", "strftime", "(", "\"%Y-%b-%d-%H_%M_%S\"", ",", "gmtime", "(", ")", ")", "\n", "args", ".", "result_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "args", ".", "data_name", ",", "args", ".", "aug_type", ",", "args", ".", "current_time", ",", "args", ".", "result_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "result_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "result_dir", ")", "\n", "\n", "", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "args", ".", "data_name", ",", "args", ".", "aug_type", ",", "args", ".", "current_time", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "args", ".", "cached_input_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "cached_input_dir", ",", "args", ".", "data_name", ",", "args", ".", "aug_type", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "cached_input_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "cached_input_dir", ")", "\n", "\n", "# define the logger", "\n", "", "logger_name", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}_log.txt\"", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n", "LOG_FORMAT", "=", "'%(asctime)s %(name)-12s %(levelname)-8s %(message)s'", "\n", "logging", ".", "basicConfig", "(", "format", "=", "LOG_FORMAT", ",", "level", "=", "logging", ".", "INFO", ",", "filename", "=", "logger_name", ",", "filemode", "=", "'a'", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "logger_msg", "=", "'\\n\\n========================='", "\n", "logger", ".", "info", "(", "logger_msg", ")", "\n", "logger", ".", "info", "(", "json", ".", "dumps", "(", "args", ".", "__dict__", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "args", ".", "device", "=", "device", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "apex", ".", "amp", ".", "register_half_function", "(", "torch", ",", "'einsum'", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.get_args": [[287, 309], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--data_dir'", ",", "type", "=", "str", ",", "default", "=", "'../../data/'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_type'", ",", "type", "=", "str", ",", "choices", "=", "[", "'test'", ",", "'dev'", "]", ",", "default", "=", "'dev'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_name'", ",", "type", "=", "str", ",", "choices", "=", "[", "'movie'", ",", "'politics'", ",", "'iphones'", ",", "'gadgets'", "]", ",", "default", "=", "'movie'", ")", "\n", "parser", ".", "add_argument", "(", "'--aug_type'", ",", "type", "=", "str", ",", "choices", "=", "[", "'same_speaker'", ",", "'filtered_same_speaker'", ",", "'mix'", ",", "'gold'", ",", "'no_train'", "]", ",", "default", "=", "'same_speaker'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_config'", ",", "type", "=", "str", ",", "default", "=", "'bert-base-uncased'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_path'", ",", "type", "=", "str", ",", "default", "=", "'none'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_dir'", ",", "type", "=", "str", ",", "default", "=", "'output'", ")", "\n", "parser", ".", "add_argument", "(", "'--result_dir'", ",", "type", "=", "str", ",", "default", "=", "'results'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_source_len'", ",", "type", "=", "int", ",", "default", "=", "64", ")", "\n", "parser", ".", "add_argument", "(", "'--max_len'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "'--per_gpu_eval_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "'--cached_input_dir'", ",", "type", "=", "str", ",", "default", "=", "'cached_input'", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.main": [[311, 329], ["bert_eval_disentangle.get_args", "bert_eval_disentangle.prepare", "bert_eval_disentangle.get_model_and_tokenizer", "os.path.join", "bert_eval_disentangle.read_data", "os.path.join", "bert_eval_disentangle.tokenize_data", "os.path.join", "bert_eval_disentangle.flatten_utterance", "model.to", "os.path.join", "bert_eval_disentangle.evaluate", "os.path.join"], "function", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.get_args", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.prepare", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.get_model_and_tokenizer", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.read_data", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.tokenize_data", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.flatten_utterance", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_eval_disentangle.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "logger", "=", "prepare", "(", "args", ")", "\n", "\n", "model", ",", "tokenizer", "=", "get_model_and_tokenizer", "(", "args", ")", "\n", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "data_name", ")", ",", "'tokenized'", ",", "'{}.json'", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n", "entangled_data", "=", "read_data", "(", "filename", ")", "\n", "\n", "cached_tokenized_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "cached_input_dir", ",", "\"tokenized_{}.pt\"", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n", "tokenized_data", "=", "tokenize_data", "(", "entangled_data", ",", "tokenizer", ",", "cached_tokenized_filename", ")", "\n", "cached_flat_data_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "cached_input_dir", ",", "\"flat_tokenized_{}.pt\"", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n", "data", ",", "labels", "=", "flatten_utterance", "(", "tokenized_data", ",", "tokenizer", ",", "cached_flat_data_filename", ")", "\n", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "res_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "result_dir", ",", "'{}_res.pk'", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "data", ",", "labels", ",", "res_filename", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.main.preprare": [[20, 45], ["time.strftime", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "logging.basicConfig", "logging.getLogger", "torch.device", "torch.cuda.device_count", "logging.getLogger.info", "transformers.BertTokenizer.from_pretrained", "time.gmtime", "json.dumps", "torch.cuda.is_available"], "function", ["None"], ["    ", "current_time", "=", "strftime", "(", "\"%Y-%b-%d-%H_%M_%S\"", ",", "gmtime", "(", ")", ")", "\n", "args", ".", "current_time", "=", "current_time", "\n", "\n", "args", ".", "data_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "data_name", ",", "'tokenized'", ",", "\"{}.json\"", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n", "args", ".", "reward_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "reward_path", ",", "str", "(", "args", ".", "round", ")", ",", "\"reward\"", ",", "\"reward.pt\"", ")", "\n", "\n", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "args", ".", "data_name", ",", "str", "(", "args", ".", "round", ")", ",", "args", ".", "current_time", ")", "\n", "args", ".", "cache_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "args", ".", "cache_dir", ")", "\n", "args", ".", "log_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'log.txt'", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "cache_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "LOG_FORMAT", "=", "'%(asctime)s %(name)-12s %(levelname)-8s %(message)s'", "\n", "logging", ".", "basicConfig", "(", "format", "=", "LOG_FORMAT", ",", "level", "=", "logging", ".", "INFO", ",", "filename", "=", "args", ".", "log_file", ",", "filemode", "=", "'a'", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "logger", ".", "info", "(", "json", ".", "dumps", "(", "args", ".", "__dict__", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "args", ".", "device", "=", "device", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "'bert-base-uncased'", ")", "\n", "\n", "return", "logger", ",", "tokenizer", "\n", "\n", "\n", "", "def", "set_random_seed", "(", "args", ")", ":", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.main.set_random_seed": [[47, 53], ["random.seed", "torch.manual_seed", "numpy.random.seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["torch", ".", "manual_seed", "(", "args", ".", "random_seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "random_seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "random_seed", ")", "\n", "\n", "\n", "", "", "def", "get_args", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.main.get_args": [[54, 85], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--data_dir'", ",", "type", "=", "str", ",", "default", "=", "\"../../../data/\"", ")", "\n", "parser", ".", "add_argument", "(", "'--data_name'", ",", "type", "=", "str", ",", "default", "=", "\"movie\"", ")", "\n", "parser", ".", "add_argument", "(", "'--data_type'", ",", "type", "=", "str", ",", "default", "=", "\"train\"", ")", "\n", "parser", ".", "add_argument", "(", "'--output_dir'", ",", "type", "=", "str", ",", "default", "=", "\"./output\"", ")", "\n", "parser", ".", "add_argument", "(", "'--cache_dir'", ",", "type", "=", "str", ",", "default", "=", "\"cached\"", ")", "\n", "parser", ".", "add_argument", "(", "'--init_checkpoint'", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--word_dict'", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--reward_path'", ",", "type", "=", "str", ",", "default", "=", "\"../bert-reward/output/\"", ")", "\n", "parser", ".", "add_argument", "(", "'--round'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--seq_max_len'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "\"the maximum length of a sequence\"", ")", "\n", "parser", ".", "add_argument", "(", "'--min_token_freq'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"the minimum frequency of a token\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max_session_number'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "'--per_gpu_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "'--num_warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "30", ")", "\n", "parser", ".", "add_argument", "(", "'--coherency_reward_weight'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "parser", ".", "add_argument", "(", "'--hidden_size'", ",", "type", "=", "int", ",", "default", "=", "300", ")", "\n", "parser", ".", "add_argument", "(", "'--emb_size'", ",", "type", "=", "int", ",", "default", "=", "300", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ")", "\n", "parser", ".", "add_argument", "(", "\"--bidirectional\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether not to use bidirectional encoder\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether not to use CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_cell'", ",", "type", "=", "str", ",", "choices", "=", "[", "'gru'", ",", "'lstm'", "]", ",", "default", "=", "\"lstm\"", ")", "\n", "parser", ".", "add_argument", "(", "'--random_seed'", ",", "type", "=", "int", ",", "default", "=", "1234", ")", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.main.main": [[87, 129], ["main.get_args", "main.preprare", "main.set_random_seed", "os.path.join", "utils.get_word_dict", "os.path.join", "utils.build_word_emb_matrix", "os.path.join", "utils.convert_data_to_id", "gc.collect", "utils.get_max_context_length", "logger.info", "model.MatchModel", "trainer.supervised_trainer", "utils.read_raw_data", "os.path.join", "utils.tokenize_data", "logger.info", "gc.collect", "len", "print", "str", "len"], "function", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.get_args", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.preprare", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.set_random_seed", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.get_word_dict", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.build_word_emb_matrix", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.convert_data_to_id", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.get_max_context_length", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.trainer.supervised_trainer", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.read_raw_data", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.tokenize_data"], ["\n", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "\n", "logger", ",", "tokenizer", "=", "preprare", "(", "args", ")", "\n", "set_random_seed", "(", "args", ")", "\n", "\n", "raw_data", "=", "utils", ".", "read_raw_data", "(", "args", ".", "data_path", ")", "\n", "logger", ".", "info", "(", "\"{} data instances read from the original dataset.\"", ".", "format", "(", "len", "(", "raw_data", ")", ")", ")", "\n", "\n", "tokenized_data", "=", "utils", ".", "tokenize_data", "(", "raw_data", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\"{} tokenized data read.\"", ".", "format", "(", "len", "(", "tokenized_data", ")", ")", ")", "\n", "\n", "word_dict", "=", "torch", ".", "load", "(", "args", ".", "word_dict", ")", "\n", "args", ".", "pad_id", "=", "word_dict", "[", "'<PAD>'", "]", "\n", "\n", "word_emb_matrix", "=", "None", "\n", "\n", "training_data_id", "=", "utils", ".", "convert_data_to_id", "(", "tokenized_data", ",", "word_dict", ")", "\n", "logger", ".", "info", "(", "\"{} data id read.\"", ".", "format", "(", "len", "(", "training_data_id", ")", ")", ")", "\n", "\n", "args", ".", "max_context_len", "=", "utils", ".", "get_max_context_length", "(", "training_data_id", ")", "\n", "logger", ".", "info", "(", "\"Max context length: {}\"", ".", "format", "(", "args", ".", "max_context_len", ")", ")", "\n", "\n", "reward", "=", "torch", ".", "load", "(", "args", ".", "reward_path", ")", "\n", "coherency_reward", ",", "speaker_reward", "=", "utils", ".", "parse_reward", "(", "reward", ",", "tokenized_data", ")", "\n", "\n", "model", "=", "MatchModel", "(", "args", ".", "rnn_cell", ",", "len", "(", "word_dict", ")", ",", "word_emb_matrix", ",", "\n", "args", ".", "hidden_size", ",", "args", ".", "emb_size", ",", "args", ".", "max_context_len", ",", "\n", "bidirectional", "=", "args", ".", "bidirectional", ")", "\n", "\n", "supervised_trainer", "(", "args", ",", "model", ",", "training_data_id", ",", "coherency_reward", ",", "speaker_reward", ",", "logger", ")", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "main", "(", ")", "", "", ""]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.data_loader.DatasetforMM.__init__": [[8, 13], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "training_data", ",", "coherency_reward", ",", "speaker_reward", ",", "seq_max_len", ",", "num_training_instances", ",", "pad_id", ")", ":", "\n", "        ", "self", ".", "training_data", "=", "training_data", "\n", "self", ".", "coherency_reward", "=", "coherency_reward", "\n", "self", ".", "speaker_reward", "=", "speaker_reward", "\n", "self", ".", "seq_max_len", "=", "seq_max_len", "\n", "self", ".", "num_training_instances", "=", "num_training_instances", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.data_loader.DatasetforMM.__len__": [[14, 16], ["None"], "methods", ["None"], ["self", ".", "pad_id", "=", "pad_id", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.data_loader.DatasetforMM.__trunk": [[17, 21], ["len"], "methods", ["None"], ["        ", "return", "self", ".", "num_training_instances", "\n", "\n", "", "def", "__trunk", "(", "self", ",", "ids", ",", "max_len", ")", ":", "\n", "        ", "if", "len", "(", "ids", ")", ">", "max_len", ":", "\n", "            ", "ids", "=", "ids", "[", ":", "max_len", "]", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.data_loader.DatasetforMM.__pad": [[22, 28], ["len", "len", "len"], "methods", ["None"], ["", "return", "ids", "\n", "\n", "", "def", "__pad", "(", "self", ",", "ids", ",", "max_len", ")", ":", "\n", "        ", "if", "len", "(", "ids", ")", "<", "max_len", ":", "\n", "            ", "return", "ids", "+", "[", "self", ".", "pad_id", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "ids", ")", "==", "max_len", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.data_loader.DatasetforMM.__getitem__": [[29, 47], ["data_loader.DatasetforMM.__trunk", "len", "data_loader.DatasetforMM.__pad", "len", "len", "data_loader.DatasetforMM.__trunk", "len", "data_loader.DatasetforMM.__pad"], "methods", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__trunk", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__pad", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__trunk", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__pad"], ["return", "ids", "\n", "\n", "", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "idx", "=", "idx", "%", "len", "(", "self", ".", "training_data", ")", "\n", "example", "=", "self", ".", "training_data", "[", "idx", "]", "\n", "speaker_reward", "=", "self", ".", "speaker_reward", "[", "idx", "]", "\n", "coherency_reward", "=", "self", ".", "coherency_reward", "[", "idx", "]", "\n", "messages", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "message_seq_len", "=", "[", "]", "\n", "for", "item", "in", "example", ":", "\n", "            ", "text", "=", "item", "[", "'message'", "]", "\n", "label", "=", "item", "[", "'label'", "]", "\n", "text", "=", "self", ".", "__trunk", "(", "text", ",", "self", ".", "seq_max_len", ")", "\n", "text_seq_len", "=", "len", "(", "text", ")", "\n", "text", "=", "self", ".", "__pad", "(", "text", ",", "self", ".", "seq_max_len", ")", "\n", "messages", ".", "append", "(", "text", ")", "\n", "message_seq_len", ".", "append", "(", "text_seq_len", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.trainer.supervised_trainer": [[15, 84], ["torch.nn.DataParallel.to", "int", "data_loader.DatasetforMM", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "tqdm.tqdm", "torch.nn.DataParallel.train", "torch.nn.DataParallel.zero_grad", "torch.CrossEntropyLoss", "list", "torch.Adam", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "len", "torch.nn.DataParallel.parameters", "tuple", "torch.nn.DataParallel.", "nn.CrossEntropyLoss.", "tqdm.tqdm.set_description", "optim.Adam.zero_grad", "loss.mean.backward", "optim.Adam.step", "loss.mean.item", "len", "len", "loss.mean.mean", "logger.info", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "logger.info", "len", "t.to", "loss.mean.item", "torch.nn.DataParallel.state_dict"], "function", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.message-pair-classifier.bert_train.train"], ["\n", "\n", "def", "supervised_trainer", "(", "args", ",", "model", ",", "training_data", ",", "coherency_reward", ",", "speaker_reward", ",", "logger", ",", "optimizer", "=", "None", ")", ":", "\n", "    ", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "args", ".", "init_checkpoint", ")", ")", "\n", "# if args.n_gpu > 1:", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "if", "args", ".", "n_gpu", "==", "0", "or", "args", ".", "no_cuda", ":", "\n", "        ", "training_batch_size", "=", "args", ".", "per_gpu_batch_size", "\n", "", "else", ":", "\n", "        ", "training_batch_size", "=", "args", ".", "per_gpu_batch_size", "*", "args", ".", "n_gpu", "\n", "\n", "", "num_training_steps", "=", "int", "(", "args", ".", "epochs", "*", "len", "(", "training_data", ")", "/", "training_batch_size", ")", "\n", "\n", "train_dataset", "=", "DatasetforDisentanglement", "(", "\n", "training_data", ",", "coherency_reward", ",", "speaker_reward", ",", "args", ".", "seq_max_len", ",", "\n", "num_training_steps", "*", "training_batch_size", ",", "args", ".", "pad_id", ")", "\n", "\n", "# Train!", "\n", "logger", ".", "info", "(", "\"  ***** Running training *****  *\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "training_data", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %.2f\"", ",", "len", "(", "train_dataset", ")", "/", "len", "(", "training_data", ")", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "training_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "num_training_steps", ")", "\n", "\n", "train_sampler", "=", "SequentialSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "training_batch_size", ",", "\n", "collate_fn", "=", "utils", ".", "batch_list_to_batch_tensors", ")", "\n", "\n", "train_iterator", "=", "tqdm", "(", "\n", "train_dataloader", ",", "initial", "=", "0", ",", "\n", "desc", "=", "\"Iter (loss=X.XXX, lr=X.XXXXXXX)\"", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "global_step", "=", "0", "\n", "logging_loss", "=", "0.", "\n", "# loss_func = nn.CrossEntropyLoss()", "\n", "params", "=", "list", "(", "model", ".", "parameters", "(", ")", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "params", ",", "lr", "=", "args", ".", "lr", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "num_warmup_steps", ",", "\n", "num_training_steps", "=", "num_training_steps", ",", "last_epoch", "=", "-", "1", ")", "\n", "\n", "for", "batch", "in", "train_iterator", ":", "\n", "        ", "context_tensor", ",", "context_seq_len_tensor", ",", "context_len", ",", "coherency_reward", ",", "speaker_reward", "=", "batch", "\n", "context_tensor", "=", "context_tensor", ".", "to", "(", "args", ".", "device", ")", "\n", "# context_seq_len_tensor = context_seq_len_tensor.to(args.device)", "\n", "context_len", "=", "context_len", ".", "to", "(", "args", ".", "device", ")", "\n", "max_context_len", "=", "max", "(", "context_len", ")", "\n", "context_vector", "=", "model", ".", "module", ".", "message_encoder", "(", "context_tensor", ",", "context_seq_len_tensor", ")", "\n", "context_batch", "=", "model", ".", "module", ".", "build_context_batch", "(", "context_vector", ",", "context_len", ",", "max_context_len", ")", "\n", "\n", "batch_size", "=", "context_len", ".", "size", "(", ")", "[", "0", "]", "\n", "\n", "decision_sequence", "=", "torch", ".", "zeros", "(", "[", "batch_size", ",", "1", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "args", ".", "device", ")", "\n", "session_number", "=", "torch", ".", "ones", "(", "[", "batch_size", ",", "1", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "args", ".", "device", ")", "\n", "action_list", "=", "[", "[", "[", "None", ",", "None", ",", "None", "]", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "for", "step", "in", "range", "(", "1", ",", "max_context_len", ")", ":", "\n", "            ", "current_context", "=", "context_batch", "[", ":", ",", "0", ":", "step", ",", ":", "]", "\n", "current_message", "=", "context_batch", "[", ":", ",", "step", ",", ":", "]", "\n", "ret_value", "=", "model", ".", "module", ".", "get_random_decision", "(", "current_context", ",", "current_message", ",", "decision_sequence", ",", "session_number", ")", "\n", "action_list", "=", "policy", ".", "update_action_list", "(", "action_list", ",", "ret_value", ")", "\n", "current_decision", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.__init__": [[8, 15], ["torch.Module.__init__", "model.MessageEncoder", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__init__"], ["    ", "def", "__init__", "(", "self", ",", "rnn_cell", ",", "token_num", ",", "word_emb", ",", "hidden_size", ",", "emb_size", ",", "max_context_len", ",", "bidirectional", "=", "True", ",", "max_session_number", "=", "4", ")", ":", "\n", "        ", "super", "(", "MatchModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "message_encoder", "=", "MessageEncoder", "(", "rnn_cell", ",", "token_num", ",", "word_emb", ",", "hidden_size", ",", "emb_size", ",", "bidirectional", "=", "bidirectional", ")", "\n", "self", ".", "max_context_len", "=", "max_context_len", "\n", "self", ".", "attention_liearn", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ")", "\n", "self", ".", "max_session_number", "=", "max_session_number", "\n", "self", ".", "sigmoid_func", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.pad_item": [[16, 20], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "pad_item", "(", "self", ",", "context", ",", "length", ",", "hidden_size", ",", "device", ")", ":", "\n", "        ", "zero_item", "=", "torch", ".", "zeros", "(", "[", "length", ",", "hidden_size", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "padded_context", "=", "torch", ".", "cat", "(", "[", "context", ",", "zero_item", "]", ",", "dim", "=", "0", ")", "\n", "return", "padded_context", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.build_context_batch": [[21, 38], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "context_for_a_sample.size", "model.MatchModel.pad_item", "torch.cat.append", "torch.cat.append", "torch.cat.append", "model.MatchModel.unsqueeze", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "context_for_a_sample.get_device"], "methods", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.pad_item"], ["", "def", "build_context_batch", "(", "self", ",", "context", ",", "context_len", ",", "max_context_len", ")", ":", "\n", "        ", "start", "=", "0", "\n", "end", "=", "0", "\n", "context_batch", "=", "[", "]", "\n", "for", "one_len", "in", "context_len", ":", "\n", "            ", "start", "=", "end", "\n", "end", "=", "end", "+", "one_len", "\n", "context_for_a_sample", "=", "context", "[", "start", ":", "end", "]", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda:{}\"", ".", "format", "(", "context_for_a_sample", ".", "get_device", "(", ")", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "length", ",", "hidden_size", "=", "context_for_a_sample", ".", "size", "(", ")", "\n", "length", "=", "max_context_len", "-", "length", "\n", "\n", "context_with_padding", "=", "self", ".", "pad_item", "(", "context_for_a_sample", ",", "length", ",", "hidden_size", ",", "device", ")", "\n", "context_batch", ".", "append", "(", "context_with_padding", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "context_batch", "=", "torch", ".", "cat", "(", "context_batch", ",", "dim", "=", "0", ")", "\n", "return", "context_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.get_decision": [[39, 60], ["range", "context.size", "range", "max", "value.index", "ret_value.append", "model.MatchModel.attention_liearn().transpose", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "value.append", "torch.Softmax", "torch.Softmax", "torch.Softmax", "one_message.view", "torch.mm.squeeze", "torch.mm.squeeze", "torch.mm.squeeze", "model.MatchModel.attention_liearn"], "methods", ["None"], ["", "def", "get_random_decision", "(", "self", ",", "context", ",", "message", ",", "decision_sequence", ",", "session_number", ")", ":", "\n", "        ", "batch_size", "=", "context", ".", "size", "(", ")", "[", "0", "]", "\n", "ret_value", "=", "[", "]", "\n", "\n", "context_message_weight", "=", "self", ".", "attention_liearn", "(", "context", ")", ".", "transpose", "(", "2", ",", "1", ")", "\n", "context_attention_score", "=", "nn", ".", "Softmax", "(", "dim", "=", "2", ")", "(", "context_message_weight", ")", "\n", "attended_context_vector", "=", "torch", ".", "bmm", "(", "context_attention_score", ",", "context", ")", "\n", "new_session_scores", "=", "torch", ".", "bmm", "(", "attended_context_vector", ",", "message", ".", "view", "(", "batch_size", ",", "-", "1", ",", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "new_session_probs", "=", "self", ".", "sigmoid_func", "(", "new_session_scores", ")", "\n", "new_session_probs", "=", "torch", ".", "cat", "(", "[", "1", "-", "new_session_probs", ",", "new_session_probs", "]", ",", "dim", "=", "1", ")", "\n", "\n", "new_session_probs_dist", "=", "torch", ".", "distributions", ".", "Categorical", "(", "new_session_probs", ")", "# probs should be of size batch x classes", "\n", "sampled_new_session_action", "=", "new_session_probs_dist", ".", "sample", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "if", "sampled_new_session_action", "[", "i", "]", "==", "0", "and", "session_number", "[", "i", "]", "!=", "self", ".", "max_session_number", ":", "\n", "                ", "ret_value", ".", "append", "(", "[", "'new'", ",", "None", ",", "new_session_probs", "[", "i", ":", "i", "+", "1", "]", ",", "None", "]", ")", "\n", "continue", "\n", "", "current_sample_context", "=", "context", "[", "i", "]", "\n", "current_sample_message", "=", "message", "[", "i", "]", "\n", "current_sample_decision", "=", "decision_sequence", "[", "i", "]", "\n", "current_sample_logits", "=", "None", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.get_decision_v2": [[61, 88], ["range", "context.size", "model.MatchModel.attention_liearn().transpose", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "new_session_value.append", "range", "max", "value.index", "ret_value.append", "torch.Softmax", "torch.Softmax", "torch.Softmax", "one_message.view", "torch.mm.squeeze", "torch.mm.squeeze", "torch.mm.squeeze", "model.MatchModel.attention_liearn().transpose", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "value.append", "model.MatchModel.attention_liearn", "torch.Softmax", "torch.Softmax", "torch.Softmax", "one_message.view", "torch.mm.squeeze", "torch.mm.squeeze", "torch.mm.squeeze", "model.MatchModel.attention_liearn"], "methods", ["None"], ["for", "k", "in", "range", "(", "session_number", "[", "i", "]", ")", ":", "\n", "                ", "step_decision", "=", "current_sample_decision", "==", "k", "\n", "step_context", "=", "current_sample_context", "[", "step_decision", "]", "\n", "\n", "weight", "=", "self", ".", "attention_liearn", "(", "step_context", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "context_attention_score", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "weight", ")", "\n", "attended_context_vector", "=", "torch", ".", "mm", "(", "context_attention_score", ",", "step_context", ")", "\n", "score", "=", "torch", ".", "mm", "(", "attended_context_vector", ",", "current_sample_message", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "if", "current_sample_logits", "is", "None", ":", "\n", "                    ", "current_sample_logits", "=", "score", "\n", "", "else", ":", "\n", "                    ", "current_sample_logits", "=", "torch", ".", "cat", "(", "[", "current_sample_logits", ",", "score", "]", ",", "dim", "=", "0", ")", "\n", "", "", "current_sample_probs_dist", "=", "torch", ".", "distributions", ".", "Categorical", "(", "logits", "=", "current_sample_logits", ")", "\n", "current_sample_action", "=", "current_sample_probs_dist", ".", "sample", "(", ")", "\n", "selected_action_prob", "=", "self", ".", "sigmoid_func", "(", "current_sample_logits", "[", "current_sample_action", ":", "current_sample_action", "+", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "selected_action_prob", "=", "torch", ".", "cat", "(", "[", "1", "-", "selected_action_prob", ",", "selected_action_prob", "]", ",", "dim", "=", "1", ")", "\n", "ret_value", ".", "append", "(", "[", "'select'", ",", "current_sample_action", ",", "selected_action_prob", ",", "new_session_probs", "[", "i", ":", "i", "+", "1", "]", "]", ")", "\n", "", "return", "ret_value", "\n", "\n", "", "def", "build_context_batch_with_attention", "(", "self", ",", "context", ",", "context_len", ")", ":", "\n", "        ", "start", "=", "0", "\n", "end", "=", "0", "\n", "context_batch", "=", "[", "]", "\n", "for", "one_len", "in", "context_len", ":", "\n", "            ", "start", "=", "end", "\n", "end", "=", "end", "+", "one_len", "\n", "context_for_a_sample", "=", "context", "[", "start", ":", "end", "]", "\n", "weight", "=", "self", ".", "attention_liearn", "(", "context_for_a_sample", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.get_decision_v3": [[89, 124], ["range", "range", "context.size", "model.MatchModel.attention_liearn().transpose", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "new_session_value.append", "context.size", "range", "max", "value.index", "ret_value.append", "torch.Softmax", "torch.Softmax", "torch.Softmax", "one_message.view", "torch.mm.squeeze", "torch.mm.squeeze", "torch.mm.squeeze", "model.MatchModel.attention_liearn().transpose", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "value.append", "model.MatchModel.attention_liearn", "torch.Softmax", "torch.Softmax", "torch.Softmax", "one_message.view", "torch.mm.squeeze", "torch.mm.squeeze", "torch.mm.squeeze", "model.MatchModel.attention_liearn"], "methods", ["None"], ["context_attention_score", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "weight", ")", "\n", "attended_context_vector", "=", "torch", ".", "mm", "(", "context_attention_score", ",", "context_for_a_sample", ")", "\n", "context_batch", ".", "append", "(", "attended_context_vector", ")", "\n", "", "context_batch", "=", "torch", ".", "cat", "(", "context_batch", ",", "dim", "=", "0", ")", "\n", "return", "context_batch", "\n", "\n", "", "def", "forward", "(", "self", ",", "context", ",", "context_seq_len", ",", "context_len", ",", "current_message", "=", "None", ",", "\n", "current_message_seq_len", "=", "None", ",", "max_context_len", "=", "-", "1", ")", ":", "\n", "        ", "context_vector", "=", "self", ".", "message_encoder", "(", "context", ",", "context_seq_len", ")", "\n", "return", "context_vector", "\n", "\n", "# if inference:", "\n", "#     context_batch = self.build_context_batch(context_vector, context_len, max_context_len)", "\n", "#     return context_batch", "\n", "# else:", "\n", "context_batch", "=", "self", ".", "build_context_batch_with_attention", "(", "context_vector", ",", "context_len", ")", "\n", "current_message_vector", "=", "self", ".", "message_encoder", "(", "current_message", ",", "current_message_seq_len", ")", "\n", "\n", "batch_size", ",", "hidden_size", "=", "context_batch", ".", "size", "(", ")", "\n", "logit", "=", "torch", ".", "bmm", "(", "\n", "context_batch", ".", "view", "(", "batch_size", ",", "1", ",", "hidden_size", ")", ",", "current_message_vector", ".", "view", "(", "batch_size", ",", "hidden_size", ",", "1", ")", "\n", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "pos_output", "=", "nn", ".", "Sigmoid", "(", ")", "(", "logit", ")", "\n", "neg_output", "=", "1", "-", "pos_output", "\n", "output", "=", "torch", ".", "cat", "(", "[", "neg_output", ",", "pos_output", "]", ",", "dim", "=", "1", ")", "\n", "return", "output", "\n", "\n", "\n", "", "", "class", "MessageEncoder", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "rnn_cell", ",", "token_num", ",", "word_emb", ",", "hidden_size", ",", "emb_size", ",", "bidirectional", ",", "dropout_rate", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "MessageEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_emb", "=", "word_emb", "\n", "self", ".", "word_emb_matrix", "=", "nn", ".", "Embedding", "(", "token_num", ",", "emb_size", ")", "\n", "self", ".", "init_embedding", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout_rate", ")", "\n", "self", ".", "rnn_cell", "=", "rnn_cell", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.build_context_batch_with_attention": [[127, 141], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.MatchModel.attention_liearn().transpose", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.Softmax", "torch.Softmax", "torch.Softmax", "model.MatchModel.attention_liearn"], "methods", ["None"], ["if", "self", ".", "rnn_cell", "==", "'lstm'", ":", "\n", "            ", "self", ".", "encoder", "=", "nn", ".", "LSTM", "(", "emb_size", ",", "hidden_size", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "bidirectional", ")", "\n", "", "elif", "self", ".", "rnn_cell", "==", "'gru'", ":", "\n", "            ", "self", ".", "encoder", "=", "nn", ".", "GRU", "(", "emb_size", ",", "hidden_size", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "bidirectional", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Message encoder {} not implemented\"", ".", "format", "(", "self", ".", "rnn_cell", ")", ")", "\n", "\n", "", "if", "self", ".", "bidirectional", ":", "\n", "            ", "self", ".", "output_linear", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", ",", "hidden_size", ")", "\n", "\n", "", "", "def", "init_embedding", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "word_emb", "is", "None", ":", "\n", "            ", "self", ".", "word_emb_matrix", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "word_emb_matrix", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "word_emb", ")", ")", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.forward": [[142, 168], ["model.MatchModel.message_encoder", "model.MatchModel.build_context_batch_with_attention", "model.MatchModel.message_encoder", "model.MatchModel.size", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "model.MatchModel.view", "model.MatchModel.view"], "methods", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.build_context_batch_with_attention"], ["\n", "", "", "def", "forward", "(", "self", ",", "input_data", ",", "seq_len", ")", ":", "\n", "        ", "embeded_input", "=", "self", ".", "word_emb_matrix", "(", "input_data", ")", "\n", "embeded_input", "=", "self", ".", "dropout", "(", "embeded_input", ")", "\n", "\n", "packed_", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "embeded_input", ",", "seq_len", ",", "batch_first", "=", "True", ",", "enforce_sorted", "=", "False", ")", "\n", "\n", "if", "self", ".", "rnn_cell", "==", "'lstm'", ":", "\n", "            ", "_", ",", "hidden_state", "=", "self", ".", "encoder", "(", "packed_", ")", "\n", "h_state", "=", "hidden_state", "[", "0", "]", "\n", "", "elif", "self", ".", "rnn_cell", "==", "'gru'", ":", "\n", "            ", "_", ",", "h_state", "=", "self", ".", "encoder", "(", "packed_", ")", "\n", "\n", "", "if", "self", ".", "bidirectional", ":", "\n", "            ", "h_state_cat", "=", "torch", ".", "cat", "(", "[", "h_state", "[", "0", "]", ",", "h_state", "[", "1", "]", "]", ",", "dim", "=", "1", ")", "\n", "output_vec", "=", "self", ".", "output_linear", "(", "h_state_cat", ")", "\n", "", "return", "output_vec", "", "", "", ""]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MessageEncoder.__init__": [[172, 190], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "model.MessageEncoder.init_embedding", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.GRU", "torch.GRU", "torch.GRU", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__init__", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MessageEncoder.init_embedding"], []], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MessageEncoder.init_embedding": [[191, 196], ["model.MessageEncoder.word_emb_matrix.weight.data.uniform_", "model.MessageEncoder.word_emb_matrix.weight.data.copy_", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], []], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MessageEncoder.forward": [[197, 213], ["model.MessageEncoder.word_emb_matrix", "model.MessageEncoder.dropout", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "seq_len.cpu", "model.MessageEncoder.encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.MessageEncoder.output_linear", "model.MessageEncoder.encoder"], "methods", ["None"], []], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__init__": [[24, 29], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "training_data", ",", "seq_max_len", ",", "num_training_instances", ",", "pad_id", ")", ":", "\n", "        ", "self", ".", "training_data", "=", "training_data", "\n", "self", ".", "seq_max_len", "=", "seq_max_len", "\n", "self", ".", "num_training_instances", "=", "num_training_instances", "\n", "self", ".", "pad_id", "=", "pad_id", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__len__": [[30, 32], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_training_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__trunk": [[33, 37], ["len"], "methods", ["None"], ["", "def", "__trunk", "(", "self", ",", "ids", ",", "max_len", ")", ":", "\n", "        ", "if", "len", "(", "ids", ")", ">", "max_len", ":", "\n", "            ", "ids", "=", "ids", "[", ":", "max_len", "]", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__pad": [[38, 44], ["len", "len", "len"], "methods", ["None"], ["", "def", "__pad", "(", "self", ",", "ids", ",", "max_len", ")", ":", "\n", "        ", "if", "len", "(", "ids", ")", "<", "max_len", ":", "\n", "            ", "return", "ids", "+", "[", "self", ".", "pad_id", "]", "*", "(", "max_len", "-", "len", "(", "ids", ")", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "ids", ")", "==", "max_len", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__getitem__": [[45, 64], ["len", "disentangle_inference.DatasetforDisentanglement.__trunk", "len", "disentangle_inference.DatasetforDisentanglement.__pad", "messages.append", "message_seq_len.append", "labels.append", "speakers.append", "len"], "methods", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__trunk", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.DatasetforDisentanglement.__pad"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "idx", "=", "idx", "%", "len", "(", "self", ".", "training_data", ")", "\n", "example", "=", "self", ".", "training_data", "[", "idx", "]", "\n", "messages", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "message_seq_len", "=", "[", "]", "\n", "speakers", "=", "[", "]", "\n", "for", "item", "in", "example", ":", "\n", "            ", "text", "=", "item", "[", "'message'", "]", "\n", "label", "=", "item", "[", "'label'", "]", "\n", "speaker", "=", "item", "[", "'speaker'", "]", "\n", "text", "=", "self", ".", "__trunk", "(", "text", ",", "self", ".", "seq_max_len", ")", "\n", "text_seq_len", "=", "len", "(", "text", ")", "\n", "text", "=", "self", ".", "__pad", "(", "text", ",", "self", ".", "seq_max_len", ")", "\n", "messages", ".", "append", "(", "text", ")", "\n", "message_seq_len", ".", "append", "(", "text_seq_len", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "speakers", ".", "append", "(", "speaker", ")", "\n", "", "return", "messages", ",", "message_seq_len", ",", "labels", ",", "len", "(", "messages", ")", ",", "speakers", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.batch_list_to_batch_tensors": [[66, 78], ["list", "list", "torch.tensor", "list", "torch.tensor", "torch.tensor", "zip", "itertools.chain", "itertools.chain"], "function", ["None"], ["", "", "def", "batch_list_to_batch_tensors", "(", "batch", ")", ":", "\n", "    ", "new_batch", "=", "list", "(", "zip", "(", "*", "batch", ")", ")", "\n", "context", ",", "context_seq_len", ",", "label_id", ",", "context_len", ",", "speakers", "=", "new_batch", "\n", "\n", "context", "=", "list", "(", "itertools", ".", "chain", "(", "*", "context", ")", ")", "\n", "context_tensor", "=", "torch", ".", "tensor", "(", "context", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "context_seq_len", "=", "list", "(", "itertools", ".", "chain", "(", "*", "context_seq_len", ")", ")", "\n", "context_seq_len_tensor", "=", "torch", ".", "tensor", "(", "context_seq_len", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "\n", "context_len", "=", "torch", ".", "tensor", "(", "context_len", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "return", "context_tensor", ",", "context_seq_len_tensor", ",", "context_len", ",", "label_id", ",", "speakers", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.read_raw_data": [[80, 86], ["print", "print", "open", "json.load", "len"], "function", ["None"], ["", "def", "read_raw_data", "(", "data_path", ")", ":", "\n", "    ", "print", "(", "\"Reading original data ...\"", ")", "\n", "with", "open", "(", "data_path", ")", "as", "fin", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "fin", ")", "\n", "", "print", "(", "\"{} data instances read from the original dataset.\"", ".", "format", "(", "len", "(", "data", ")", ")", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.tokenize_data": [[88, 112], ["print", "tqdm.tqdm", "print", "logger.info", "tokenized_data.append", "message[].split", "one_dialogue.append", "len"], "function", ["None"], ["", "def", "tokenize_data", "(", "data", ",", "cached_features_file", ",", "tokenizer", ",", "logger", ")", ":", "\n", "    ", "print", "(", "\"Tokenizing data ...\"", ")", "\n", "tokenized_data", "=", "[", "]", "\n", "for", "item", "in", "tqdm", "(", "data", ")", ":", "\n", "        ", "one_dialogue", "=", "[", "]", "\n", "for", "message", "in", "item", ":", "\n", "            ", "speaker", "=", "message", "[", "'speaker'", "]", "\n", "text", "=", "message", "[", "'text'", "]", ".", "split", "(", ")", "\n", "label", "=", "message", "[", "'label'", "]", "\n", "one_dialogue", ".", "append", "(", "{", "\n", "'speaker'", ":", "speaker", ",", "\n", "'message'", ":", "text", ",", "\n", "'label'", ":", "label", "\n", "}", ")", "\n", "", "tokenized_data", ".", "append", "(", "one_dialogue", ")", "\n", "", "print", "(", "\"Saving tokenized data into cached file {}\"", ".", "format", "(", "cached_features_file", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\"{} tokenized data read.\"", ".", "format", "(", "len", "(", "tokenized_data", ")", ")", ")", "\n", "return", "tokenized_data", "\n", "\n", "\n", "", "def", "convert_data_to_id", "(", "data", ",", "word_dict", ",", "cached_features_file", ",", "logger", ")", ":", "\n", "    ", "data_id", "=", "[", "]", "\n", "for", "item", "in", "tqdm", "(", "data", ")", ":", "\n", "        ", "new_item", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.convert_data_to_id": [[114, 141], ["tqdm.tqdm", "print", "logger.info", "data_id.append", "new_item.append", "len", "message_id.append", "word_dict.get", "word_dict.get"], "function", ["None"], ["            ", "text", "=", "message", "[", "'message'", "]", "\n", "label", "=", "message", "[", "'label'", "]", "\n", "speaker", "=", "message", "[", "'speaker'", "]", "\n", "message_id", "=", "[", "]", "\n", "for", "token", "in", "text", ":", "\n", "                ", "message_id", ".", "append", "(", "word_dict", ".", "get", "(", "token", ",", "word_dict", ".", "get", "(", "'<UNK>'", ")", ")", ")", "\n", "", "new_item", ".", "append", "(", "{", "\n", "'message'", ":", "message_id", ",", "\n", "'label'", ":", "label", ",", "\n", "'speaker'", ":", "speaker", "\n", "}", ")", "\n", "", "data_id", ".", "append", "(", "new_item", ")", "\n", "", "print", "(", "\"Saving data id into cached file {}\"", ".", "format", "(", "cached_features_file", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\"{} data id read.\"", ".", "format", "(", "len", "(", "data_id", ")", ")", ")", "\n", "return", "data_id", "\n", "\n", "\n", "", "def", "get_max_context_length", "(", "data_id", ",", "logger", ")", ":", "\n", "    ", "print", "(", "\"Retrieving the maximum context length ...\"", ")", "\n", "context_length", "=", "0", "\n", "for", "item", "in", "tqdm", "(", "data_id", ")", ":", "\n", "        ", "context_length", "=", "max", "(", "len", "(", "item", ")", ",", "context_length", ")", "\n", "", "logger", ".", "info", "(", "\"Max context length: {}\"", ".", "format", "(", "context_length", ")", ")", "\n", "return", "context_length", "\n", "\n", "\n", "", "def", "write_result", "(", "labels", ",", "preds", ",", "args", ")", ":", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.get_max_context_length": [[143, 150], ["print", "tqdm.tqdm", "logger.info", "max", "len"], "function", ["None"], ["for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "        ", "one_pred", "=", "preds", "[", "i", "]", "\n", "one_label", "=", "labels", "[", "i", "]", "\n", "one_item", "=", "{", "\n", "'pred'", ":", "one_pred", ",", "\n", "'label'", ":", "one_label", "\n", "}", "\n", "results", "[", "i", "]", "=", "one_item", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.write_result": [[152, 166], ["range", "os.path.join", "len", "re.findall", "open", "json.dump"], "function", ["None"], ["filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "result_dir", ",", "\"{}_checkpoint_{}.json\"", ".", "format", "(", "args", ".", "data_type", ",", "checkpoint_num", ")", ")", "\n", "with", "open", "(", "filename", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "json", ".", "dump", "(", "results", ",", "fout", ",", "indent", "=", "2", ")", "\n", "\n", "\n", "", "", "def", "preprare", "(", "args", ")", ":", "\n", "    ", "args", ".", "data_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "data_name", ",", "'tokenized'", ",", "\"{}.json\"", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n", "args", ".", "cache_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "args", ".", "cache_dir", ")", "\n", "\n", "args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"disentanglement\"", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "args", ".", "result_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "args", ".", "result_dir", ")", "\n", "\n", "args", ".", "cached_input_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_type", ",", "args", ".", "cached_input_dir", ",", "args", ".", "data_name", ",", "\"disentanglement\"", ")", "\n", "args", ".", "log_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}_log.txt'", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.preprare": [[168, 193], ["os.path.join", "os.path.join", "os.path.join", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "logging.basicConfig", "logging.getLogger", "torch.device", "torch.cuda.device_count", "logging.getLogger.info", "transformers.BertTokenizer.from_pretrained", "json.dumps", "torch.cuda.is_available"], "function", ["None"], ["os", ".", "makedirs", "(", "args", ".", "cached_input_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "LOG_FORMAT", "=", "'%(asctime)s %(name)-12s %(levelname)-8s %(message)s'", "\n", "logging", ".", "basicConfig", "(", "format", "=", "LOG_FORMAT", ",", "level", "=", "logging", ".", "INFO", ",", "filename", "=", "args", ".", "log_file", ",", "filemode", "=", "'a'", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "logger", ".", "info", "(", "json", ".", "dumps", "(", "args", ".", "__dict__", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "args", ".", "device", "=", "device", "\n", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "'bert-base-uncased'", ")", "\n", "\n", "return", "logger", ",", "tokenizer", "\n", "\n", "\n", "", "def", "set_random_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "random_seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "random_seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "random_seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "random_seed", ")", "\n", "\n", "\n", "", "", "def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.set_random_seed": [[195, 201], ["random.seed", "torch.manual_seed", "numpy.random.seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["parser", ".", "add_argument", "(", "'--data_name'", ",", "type", "=", "str", ",", "default", "=", "\"movie\"", ")", "\n", "parser", ".", "add_argument", "(", "'--data_type'", ",", "type", "=", "str", ",", "choices", "=", "[", "'test'", ",", "'dev'", ",", "'train'", "]", ",", "default", "=", "\"dev\"", ")", "\n", "parser", ".", "add_argument", "(", "'--model_type'", ",", "type", "=", "str", ",", "default", "=", "\"process1\"", ")", "\n", "parser", ".", "add_argument", "(", "'--output_dir'", ",", "type", "=", "str", ",", "default", "=", "\"./output\"", ")", "\n", "parser", ".", "add_argument", "(", "'--result_dir'", ",", "type", "=", "str", ",", "default", "=", "\"disentangle_result/\"", ")", "\n", "parser", ".", "add_argument", "(", "'--cache_dir'", ",", "type", "=", "str", ",", "default", "=", "\"cached/\"", ")", "\n", "parser", ".", "add_argument", "(", "'--cached_input_dir'", ",", "type", "=", "str", ",", "default", "=", "\"cached_input\"", ")", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.get_args": [[203, 233], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["parser", ".", "add_argument", "(", "'--checkpoint'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--seq_max_len'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "\"the maximum length of a sequence\"", ")", "\n", "parser", ".", "add_argument", "(", "'--per_gpu_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "'--hidden_size'", ",", "type", "=", "int", ",", "default", "=", "300", ")", "\n", "parser", ".", "add_argument", "(", "'--emb_size'", ",", "type", "=", "int", ",", "default", "=", "300", ")", "\n", "parser", ".", "add_argument", "(", "'--max_session_number'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "\"--bidirectional\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether not to use bidirectional encoder\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--read_cached_input\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether not to read cached input\"", ")", "\n", "# parser.add_argument(\"--multiple_gpu\", action='store_true',", "\n", "#                     help=\"Whether not to use multiple gpu\")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether not to use CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_cell'", ",", "type", "=", "str", ",", "choices", "=", "[", "'gru'", ",", "'lstm'", "]", ",", "default", "=", "\"lstm\"", ")", "\n", "parser", ".", "add_argument", "(", "'--random_seed'", ",", "type", "=", "int", ",", "default", "=", "1234", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "\n", "logger", ",", "tokenizer", "=", "preprare", "(", "args", ")", "\n", "set_random_seed", "(", "args", ")", "\n", "\n", "raw_data", "=", "read_raw_data", "(", "args", ".", "data_path", ")", "\n", "# print items for debug", "\n", "for", "item", "in", "raw_data", "[", "0", ":", "2", "]", ":", "\n", "        ", "print", "(", "item", ")", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.main": [[235, 353], ["disentangle_inference.get_args", "disentangle_inference.preprare", "disentangle_inference.set_random_seed", "disentangle_inference.read_raw_data", "os.path.join", "disentangle_inference.tokenize_data", "torch.load", "os.path.join", "disentangle_inference.convert_data_to_id", "disentangle_inference.get_max_context_length", "print", "print", "tqdm.tqdm", "print", "list", "logger.info", "process1.model.MatchModel", "torch.nn.DataParallel", "torch.nn.DataParallel.load_state_dict", "torch.nn.DataParallel.to", "disentangle_inference.DatasetforDisentanglement", "logger.info", "logger.info", "logger.info", "torch.utils.data.DataLoader", "tqdm.tqdm", "torch.nn.DataParallel.eval", "disentangle_inference.write_result", "sorted", "os.path.join", "len", "torch.load", "len", "len", "context.to.to", "context_len.to.to", "max", "torch.nn.DataParallel.", "torch.nn.DataParallel.module.build_context_batch", "torch.zeros", "torch.ones", "range", "glob.glob", "model.module.build_context_batch.size", "torch.nn.DataParallel.module.get_decision_v2", "range", "torch.tensor().view", "torch.cat", "torch.cat.detach().cpu().numpy().tolist", "torch.cat.detach().cpu().numpy().tolist", "len", "torch.tensor().view.append", "torch.tensor", "torch.cat.detach().cpu().numpy", "range", "torch.cat.detach().cpu().numpy", "range", "speaker_list[].index", "torch.tensor().view.append", "torch.tensor().view.append", "torch.tensor().view.append", "torch.cat.detach().cpu", "torch.cat.detach().cpu", "session_number[].data.item", "torch.cat.detach", "torch.cat.detach"], "function", ["home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.get_args", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.preprare", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.set_random_seed", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.read_raw_data", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.tokenize_data", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.convert_data_to_id", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.get_max_context_length", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.disentangle_inference.write_result", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.build_context_batch", "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.model.MatchModel.get_decision_v2"], ["\n", "", "tokenized_data_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "cached_input_dir", ",", "'tokenized_{}.pt'", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n", "tokenized_data", "=", "tokenize_data", "(", "raw_data", ",", "tokenized_data_filename", ",", "tokenizer", ",", "logger", ")", "\n", "\n", "word_dict", "=", "torch", ".", "load", "(", "args", ".", "word_dict", ")", "\n", "args", ".", "pad_id", "=", "word_dict", "[", "'<PAD>'", "]", "\n", "\n", "word_emb_matrix", "=", "None", "\n", "\n", "data_id_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "cached_input_dir", ",", "'{}_data_id.pt'", ".", "format", "(", "args", ".", "data_type", ")", ")", "\n", "data_id", "=", "convert_data_to_id", "(", "tokenized_data", ",", "word_dict", ",", "data_id_filename", ",", "logger", ")", "\n", "\n", "args", ".", "max_context_len", "=", "get_max_context_length", "(", "data_id", ",", "logger", ")", "\n", "print", "(", "\"Max context length: {}\"", ".", "format", "(", "args", ".", "max_context_len", ")", ")", "\n", "\n", "if", "args", ".", "checkpoint", "==", "-", "1", ":", "\n", "        ", "checkpoints", "=", "list", "(", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "cache_dir", "+", "\"ckpt-*\"", ",", "recursive", "=", "True", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "checkpoints", "=", "[", "os", ".", "path", ".", "join", "(", "args", ".", "cache_dir", ",", "\"ckpt-{}.pkl\"", ".", "format", "(", "args", ".", "checkpoint", ")", ")", "]", "\n", "\n", "", "print", "(", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "tqdm", "(", "checkpoints", ")", ":", "\n", "        ", "args", ".", "checkpoint", "=", "checkpoint", "\n", "logger", ".", "info", "(", "\"{} results for checkpoint: {}\"", ".", "format", "(", "args", ".", "data_type", ",", "args", ".", "checkpoint", ")", ")", "\n", "model", "=", "MatchModel", "(", "args", ".", "rnn_cell", ",", "len", "(", "word_dict", ")", ",", "word_emb_matrix", ",", "\n", "args", ".", "hidden_size", ",", "args", ".", "emb_size", ",", "args", ".", "max_context_len", ",", "\n", "bidirectional", "=", "args", ".", "bidirectional", ",", "max_session_number", "=", "args", ".", "max_session_number", ",", "\n", "inference", "=", "True", ")", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "checkpoint", ")", ")", "\n", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "dev_dataset", "=", "DatasetforDisentanglement", "(", "data_id", ",", "args", ".", "seq_max_len", ",", "len", "(", "data_id", ")", ",", "args", ".", "pad_id", ")", "\n", "\n", "# Test!", "\n", "logger", ".", "info", "(", "\"  ***** Running Testing *****  *\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "dev_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_batch_size", ")", "\n", "\n", "dev_dataloader", "=", "DataLoader", "(", "\n", "dev_dataset", ",", "\n", "batch_size", "=", "args", ".", "per_gpu_batch_size", ",", "\n", "collate_fn", "=", "batch_list_to_batch_tensors", ")", "\n", "\n", "dev_iterator", "=", "tqdm", "(", "\n", "dev_dataloader", ",", "initial", "=", "0", ",", "\n", "desc", "=", "\"Iter (loss=X.XXX, lr=X.XXXXXXX)\"", ")", "\n", "\n", "preds", "=", "None", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "for", "batch", "in", "dev_iterator", ":", "\n", "            ", "context", ",", "context_seq_len", ",", "context_len", ",", "label", ",", "speakers", "=", "batch", "\n", "context", "=", "context", ".", "to", "(", "args", ".", "device", ")", "\n", "context_len", "=", "context_len", ".", "to", "(", "args", ".", "device", ")", "\n", "max_context_len", "=", "max", "(", "context_len", ")", "\n", "context_vector", "=", "model", "(", "context", ",", "context_seq_len", ",", "context_len", ")", "\n", "context_vector", "=", "model", ".", "module", ".", "build_context_batch", "(", "context_vector", ",", "context_len", ",", "max_context_len", ")", "\n", "\n", "batch_size", "=", "context_vector", ".", "size", "(", ")", "[", "0", "]", "\n", "\n", "decision_sequence", "=", "torch", ".", "zeros", "(", "[", "batch_size", ",", "1", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "args", ".", "device", ")", "\n", "session_number", "=", "torch", ".", "ones", "(", "[", "batch_size", ",", "1", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "args", ".", "device", ")", "\n", "for", "step", "in", "range", "(", "1", ",", "max_context_len", ")", ":", "\n", "                ", "current_context", "=", "context_vector", "[", ":", ",", "0", ":", "step", ",", ":", "]", "\n", "current_message", "=", "context_vector", "[", ":", ",", "step", ",", ":", "]", "\n", "values", ",", "new_session_value", "=", "model", ".", "module", ".", "get_decision_v2", "(", "current_context", ",", "current_message", ",", "decision_sequence", ",", "session_number", ")", "\n", "current_decision", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "max_num", ",", "max_value_index", "=", "values", "[", "i", "]", "\n", "new_session_score", "=", "new_session_value", "[", "i", "]", "\n", "speaker_list", "=", "speakers", "[", "i", "]", "\n", "flag", "=", "False", "\n", "if", "step", "<", "len", "(", "speaker_list", ")", ":", "\n", "                        ", "speaker", "=", "speaker_list", "[", "step", "]", "\n", "speaker_index", "=", "speaker_list", "[", ":", "step", "]", ".", "index", "(", "speaker", ")", "if", "speaker", "in", "speaker_list", "[", ":", "step", "]", "else", "-", "1", "\n", "if", "speaker_index", "!=", "-", "1", ":", "\n", "                            ", "flag", "=", "True", "\n", "one_decision", "=", "decision_sequence", "[", "i", "]", "[", "speaker_index", "]", "\n", "", "", "if", "flag", ":", "\n", "                        ", "current_decision", ".", "append", "(", "max_value_index", ")", "\n", "", "else", ":", "\n", "                        ", "if", "new_session_score", "<", "0", ":", "\n", "                            ", "if", "session_number", "[", "i", "]", "<", "args", ".", "max_session_number", ":", "\n", "                                ", "current_decision", ".", "append", "(", "session_number", "[", "i", "]", ".", "data", ".", "item", "(", ")", ")", "\n", "session_number", "[", "i", "]", "+=", "1", "\n", "", "else", ":", "\n", "                                ", "current_decision", ".", "append", "(", "max_value_index", ")", "\n", "", "", "else", ":", "\n", "                            ", "current_decision", ".", "append", "(", "max_value_index", ")", "\n", "", "", "", "current_decision", "=", "torch", ".", "tensor", "(", "current_decision", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "args", ".", "device", ")", ".", "view", "(", "batch_size", ",", "1", ")", "\n", "decision_sequence", "=", "torch", ".", "cat", "(", "[", "decision_sequence", ",", "current_decision", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "preds", "is", "None", ":", "\n", "                ", "preds", "=", "decision_sequence", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "preds", "=", "[", "preds", "[", "i", "]", "[", ":", "context_len", "[", "i", "]", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "out_labels", "=", "label", "\n", "", "else", ":", "\n", "                ", "one_preds", "=", "decision_sequence", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "one_preds", "=", "[", "one_preds", "[", "i", "]", "[", ":", "context_len", "[", "i", "]", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "preds", "+=", "one_preds", "\n", "out_labels", "+=", "label", "\n", "", "", "write_result", "(", "out_labels", ",", "preds", ",", "args", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "main", "(", ")", "", "", ""]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.read_raw_data": [[11, 17], ["print", "print", "open", "json.load", "len"], "function", ["None"], ["def", "read_raw_data", "(", "data_path", ")", ":", "\n", "    ", "print", "(", "\"Reading original data ...\"", ")", "\n", "with", "open", "(", "data_path", ")", "as", "fin", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "fin", ")", "\n", "", "print", "(", "\"{} data instances read from the original dataset.\"", ".", "format", "(", "len", "(", "data", ")", ")", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.get_max_context_length": [[19, 26], ["print", "tqdm.tqdm", "logger.info", "max", "len"], "function", ["None"], ["", "def", "tokenize_data", "(", "data", ",", "tokenizer", ")", ":", "\n", "    ", "print", "(", "\"Tokenizing data ...\"", ")", "\n", "tokenized_data", "=", "[", "]", "\n", "for", "item", "in", "tqdm", "(", "data", ")", ":", "\n", "        ", "one_dialogue", "=", "[", "]", "\n", "for", "message", "in", "item", ":", "\n", "            ", "speaker", "=", "message", "[", "'speaker'", "]", "\n", "text", "=", "message", "[", "'text'", "]", ".", "split", "(", ")", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.tokenize_data": [[28, 51], ["print", "tqdm.tqdm", "[].split", "tokenized_data.append", "message[].split", "new_history.append"], "function", ["None"], ["one_dialogue", ".", "append", "(", "{", "\n", "'speaker'", ":", "speaker", ",", "\n", "'message'", ":", "text", ",", "\n", "'label'", ":", "label", "\n", "}", ")", "\n", "", "tokenized_data", ".", "append", "(", "one_dialogue", ")", "\n", "\n", "", "print", "(", "\"{} tokenized data read.\"", ".", "format", "(", "len", "(", "tokenized_data", ")", ")", ")", "\n", "return", "tokenized_data", "\n", "\n", "\n", "", "def", "convert_data_to_id", "(", "data", ",", "word_dict", ")", ":", "\n", "    ", "print", "(", "\"Converting data to id ...\"", ")", "\n", "data_id", "=", "[", "]", "\n", "for", "item", "in", "tqdm", "(", "data", ")", ":", "\n", "        ", "new_item", "=", "[", "]", "\n", "for", "message", "in", "item", ":", "\n", "            ", "text", "=", "message", "[", "'message'", "]", "\n", "label", "=", "message", "[", "'label'", "]", "\n", "speaker", "=", "message", "[", "'speaker'", "]", "\n", "message_id", "=", "[", "word_dict", ".", "get", "(", "token", ",", "word_dict", ".", "get", "(", "'<UNK>'", ")", ")", "for", "token", "in", "text", "]", "\n", "new_item", ".", "append", "(", "{", "\n", "'message'", ":", "message_id", ",", "\n", "'label'", ":", "label", ",", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.get_word_dict": [[53, 87], ["os.path.exists", "logger.info", "print", "torch.load", "print", "dict", "tqdm.tqdm", "print", "logger.info", "print", "torch.save", "len", "len", "len", "len", "len", "len"], "function", ["None"], ["}", ")", "\n", "", "data_id", ".", "append", "(", "new_item", ")", "\n", "\n", "", "print", "(", "\"{} data id read.\"", ".", "format", "(", "len", "(", "data_id", ")", ")", ")", "\n", "return", "data_id", "\n", "\n", "\n", "", "def", "get_max_context_length", "(", "data_id", ")", ":", "\n", "    ", "print", "(", "\"Retrieving the maximum context length ...\"", ")", "\n", "context_length", "=", "0", "\n", "for", "item", "in", "tqdm", "(", "data_id", ")", ":", "\n", "        ", "context_length", "=", "max", "(", "len", "(", "item", ")", ",", "context_length", ")", "\n", "", "print", "(", "\"Max context length: {}\"", ".", "format", "(", "context_length", ")", ")", "\n", "return", "context_length", "\n", "\n", "\n", "", "def", "parse_reward", "(", "reward", ",", "data", ")", ":", "\n", "    ", "print", "(", "\"Parsing reward item ...\"", ")", "\n", "coherency_reward", "=", "[", "]", "\n", "speaker_reward", "=", "[", "]", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "data", ")", ")", ")", ":", "\n", "        ", "data_item", "=", "data", "[", "i", "]", "\n", "coherency_matrix", "=", "reward", "[", "i", "]", "[", "'reward'", "]", "\n", "assert", "coherency_matrix", ".", "shape", "[", "0", "]", "==", "len", "(", "data_item", ")", "\n", "speaker_matrix", "=", "np", ".", "zeros_like", "(", "coherency_matrix", ",", "dtype", "=", "float", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "data_item", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "data_item", ")", ")", ":", "\n", "                ", "speaker_1", "=", "data_item", "[", "i", "]", "[", "'speaker'", "]", "\n", "speaker_2", "=", "data_item", "[", "j", "]", "[", "'speaker'", "]", "\n", "val", "=", "1", "if", "speaker_1", "==", "speaker_2", "else", "0", "\n", "speaker_matrix", "[", "i", "]", "[", "j", "]", "=", "val", "\n", "", "", "coherency_reward", ".", "append", "(", "coherency_matrix", ")", "\n", "speaker_reward", ".", "append", "(", "speaker_matrix", ")", "\n", "", "return", "coherency_reward", ",", "speaker_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.convert_data_to_id": [[89, 121], ["os.path.exists", "logger.info", "print", "torch.load", "print", "tqdm.tqdm", "print", "torch.save", "torch.load.append", "len", "current_message_id.append", "context_history_id.append", "word_dict.get", "text_id.append", "word_dict.get", "word_dict.get", "word_dict.get"], "function", ["None"], ["", "def", "batch_list_to_batch_tensors", "(", "batch", ")", ":", "\n", "    ", "batch_tensors", "=", "[", "]", "\n", "for", "x", "in", "zip", "(", "*", "batch", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "batch_tensors", ".", "append", "(", "np", ".", "array", "(", "x", ")", ")", "\n", "", "else", ":", "\n", "            ", "batch_tensors", ".", "append", "(", "torch", ".", "tensor", "(", "x", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "", "", "return", "batch_tensors", "\n", "\n", "\n", "", "def", "batch_list_to_batch_tensors", "(", "batch", ")", ":", "\n", "    ", "new_batch", "=", "list", "(", "zip", "(", "*", "batch", ")", ")", "\n", "context", ",", "context_seq_len", ",", "_", ",", "context_len", ",", "coherency_reward", ",", "speaker_reward", "=", "new_batch", "\n", "\n", "context", "=", "list", "(", "itertools", ".", "chain", "(", "*", "context", ")", ")", "\n", "context_tensor", "=", "torch", ".", "tensor", "(", "context", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "context_seq_len", "=", "list", "(", "itertools", ".", "chain", "(", "*", "context_seq_len", ")", ")", "\n", "context_seq_len_tensor", "=", "torch", ".", "tensor", "(", "context_seq_len", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "context_len", "=", "torch", ".", "tensor", "(", "context_len", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "return", "context_tensor", ",", "context_seq_len_tensor", ",", "context_len", ",", "coherency_reward", ",", "speaker_reward", "\n", "", ""]], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.build_word_emb_matrix": [[123, 145], ["os.path.exists", "print", "torch.load", "print", "word_dict.items", "numpy.random.normal", "logger.info", "torch.save", "open", "tqdm.tqdm", "line.strip().split", "len", "len", "numpy.asarray", "line.strip", "float"], "function", ["None"], []], "home.repos.pwc.inspect_result.layneins_unsupervised_dialo_disentanglement.session-classifier.utils.batch_list_to_batch_tensors": [[147, 167], ["list", "list", "torch.tensor", "list", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "zip", "itertools.chain", "itertools.chain"], "function", ["None"], []]}