{"home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.__init__": [[7, 12], ["pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained", "text_processor.Text_Processor.tokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Tokenizer.convert_tokens_to_ids"], ["    ", "def", "__init__", "(", "self", ",", "word2id_path", ",", "max_uttr_num", ",", "max_uttr_len", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "word2id_path", ")", "# word2id_path refers to the bert path", "\n", "self", ".", "padding_idx", ",", "self", ".", "sep_idx", ",", "self", ".", "cls_idx", ",", "self", ".", "eou_idx", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "PAD", ",", "SEP", ",", "CLS", ",", "EOU", "]", ")", "\n", "self", ".", "max_uttr_num", ",", "self", ".", "max_uttr_len", "=", "max_uttr_num", ",", "max_uttr_len", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.process_context_id": [[13, 31], ["context_text.strip().split", "range", "text_processor.Text_Processor.tokenizer.convert_tokens_to_ids", "len", "context_token_list.extend", "context_seg_list.extend", "context_text.strip", "len", "range", "text_processor.Text_Processor.tokenizer.tokenize", "len", "text_processor.Text_Processor.tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Tokenizer.tokenize", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Tokenizer.tokenize"], ["", "def", "process_context_id", "(", "self", ",", "context_text", ")", ":", "\n", "        ", "context_text_list", "=", "context_text", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "'\\t'", ")", "\n", "context_token_list", "=", "[", "CLS", "]", "\n", "context_seg_list", "=", "[", "0", "]", "\n", "context_text_list", "=", "context_text_list", "[", "-", "self", ".", "max_uttr_num", ":", "]", "\n", "usr_id", "=", "0", "\n", "for", "text_idx", "in", "range", "(", "len", "(", "context_text_list", ")", ")", ":", "\n", "            ", "text", "=", "context_text_list", "[", "text_idx", "]", "\n", "if", "text_idx", "==", "len", "(", "context_text_list", ")", "-", "1", ":", "# the last utterance", "\n", "                ", "one_token_list", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "text", ")", "[", ":", "self", ".", "max_uttr_len", "]", "+", "[", "EOU", "]", "+", "[", "SEP", "]", "\n", "", "else", ":", "\n", "                ", "one_token_list", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "text", ")", "[", ":", "self", ".", "max_uttr_len", "]", "+", "[", "EOU", "]", "\n", "", "context_token_list", ".", "extend", "(", "one_token_list", ")", "\n", "one_seg_list", "=", "[", "usr_id", "for", "_", "in", "range", "(", "len", "(", "one_token_list", ")", ")", "]", "\n", "context_seg_list", ".", "extend", "(", "one_seg_list", ")", "\n", "usr_id", "=", "1", "-", "usr_id", "\n", "", "context_id_list", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "context_token_list", ")", "\n", "return", "context_id_list", ",", "context_seg_list", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.process_response_id": [[32, 37], ["text_processor.Text_Processor.tokenizer.tokenize", "text_processor.Text_Processor.tokenizer.convert_tokens_to_ids", "response_text.strip().strip", "response_text.strip"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Tokenizer.tokenize", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Tokenizer.convert_tokens_to_ids"], ["", "def", "process_response_id", "(", "self", ",", "response_text", ")", ":", "\n", "        ", "response_token_list", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "response_text", ".", "strip", "(", "'\\n'", ")", ".", "strip", "(", ")", ")", "[", ":", "self", ".", "max_uttr_len", "]", "\n", "response_token_list", "=", "response_token_list", "+", "[", "SEP", "]", "\n", "response_seg_list", "=", "[", "2", "for", "_", "in", "response_token_list", "]", "# this part will be masked out before BERT processing", "\n", "return", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "response_token_list", ")", ",", "response_seg_list", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.pad_token_id_list": [[38, 47], ["max", "len", "res_list.append", "len", "range"], "methods", ["None"], ["", "def", "pad_token_id_list", "(", "self", ",", "batch_token_id_list", ")", ":", "\n", "        ", "len_list", "=", "[", "len", "(", "item", ")", "for", "item", "in", "batch_token_id_list", "]", "\n", "max_len", "=", "max", "(", "len_list", ")", "\n", "res_list", "=", "[", "]", "\n", "for", "item", "in", "batch_token_id_list", ":", "\n", "            ", "len_diff", "=", "max_len", "-", "len", "(", "item", ")", "\n", "one_res", "=", "item", "+", "[", "self", ".", "padding_idx", "for", "_", "in", "range", "(", "len_diff", ")", "]", "\n", "res_list", ".", "append", "(", "one_res", ")", "\n", "", "return", "res_list", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.pad_seg_id_list": [[48, 57], ["max", "len", "res_list.append", "len", "range"], "methods", ["None"], ["", "def", "pad_seg_id_list", "(", "self", ",", "batch_seg_id_list", ")", ":", "\n", "        ", "len_list", "=", "[", "len", "(", "item", ")", "for", "item", "in", "batch_seg_id_list", "]", "\n", "max_len", "=", "max", "(", "len_list", ")", "\n", "res_list", "=", "[", "]", "\n", "for", "item", "in", "batch_seg_id_list", ":", "\n", "            ", "len_diff", "=", "max_len", "-", "len", "(", "item", ")", "\n", "one_res", "=", "item", "+", "[", "2", "for", "_", "in", "range", "(", "len_diff", ")", "]", "# 2 is for masking purpose", "\n", "res_list", ".", "append", "(", "one_res", ")", "\n", "", "return", "res_list", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.pad_uttr_id_list": [[58, 67], ["max", "len", "res_list.append", "len", "range"], "methods", ["None"], ["", "def", "pad_uttr_id_list", "(", "self", ",", "batch_uttr_id_list", ")", ":", "\n", "        ", "len_list", "=", "[", "len", "(", "item", ")", "for", "item", "in", "batch_uttr_id_list", "]", "\n", "max_len", "=", "max", "(", "len_list", ")", "\n", "res_list", "=", "[", "]", "\n", "for", "item", "in", "batch_uttr_id_list", ":", "\n", "            ", "len_diff", "=", "max_len", "-", "len", "(", "item", ")", "\n", "one_res", "=", "item", "+", "[", "1", "for", "_", "in", "range", "(", "len_diff", ")", "]", "# 2 is for masking purpose", "\n", "res_list", ".", "append", "(", "one_res", ")", "\n", "", "return", "res_list", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.process_batch_result": [[68, 93], ["len", "range", "batch_token_id_list.append", "batch_seg_id_list.append", "batch_uttr_response_seg_list.append", "text_processor.Text_Processor.pad_token_id_list", "text_processor.Text_Processor.pad_seg_id_list", "text_processor.Text_Processor.pad_uttr_id_list", "len", "len", "len", "len", "range", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.pad_token_id_list", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.pad_seg_id_list", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.pad_uttr_id_list"], ["", "def", "process_batch_result", "(", "self", ",", "batch_context_token_id_list", ",", "batch_context_seg_id_list", ",", "\n", "batch_response_token_id_list", ",", "batch_response_seg_id_list", ")", ":", "\n", "# batch_context_token_id_list: bsz x context_len", "\n", "# batch_response_token_id_list: bsz x response_len", "\n", "        ", "batch_token_id_list", ",", "batch_seg_id_list", "=", "[", "]", ",", "[", "]", "\n", "batch_uttr_response_seg_list", "=", "[", "]", "\n", "bsz", "=", "len", "(", "batch_context_token_id_list", ")", "\n", "for", "k", "in", "range", "(", "bsz", ")", ":", "\n", "            ", "one_context_token_id_list", ",", "one_context_seg_id_list", "=", "batch_context_token_id_list", "[", "k", "]", ",", "batch_context_seg_id_list", "[", "k", "]", "\n", "one_uttr_seg_list", "=", "[", "0", "for", "_", "in", "range", "(", "len", "(", "one_context_token_id_list", ")", ")", "]", "\n", "\n", "one_response_token_id_list", ",", "one_response_seg_id_list", "=", "batch_response_token_id_list", "[", "k", "]", ",", "batch_response_seg_id_list", "[", "k", "]", "\n", "\n", "one_token_id_res", "=", "one_context_token_id_list", "+", "one_response_token_id_list", "\n", "one_uttr_seg_list", "+=", "[", "1", "for", "_", "in", "range", "(", "len", "(", "one_response_token_id_list", ")", ")", "]", "\n", "one_seg_id_res", "=", "one_context_seg_id_list", "+", "one_response_seg_id_list", "\n", "assert", "len", "(", "one_token_id_res", ")", "==", "len", "(", "one_seg_id_res", ")", "\n", "assert", "len", "(", "one_uttr_seg_list", ")", "==", "len", "(", "one_seg_id_res", ")", "\n", "batch_token_id_list", ".", "append", "(", "one_token_id_res", ")", "\n", "batch_seg_id_list", ".", "append", "(", "one_seg_id_res", ")", "\n", "batch_uttr_response_seg_list", ".", "append", "(", "one_uttr_seg_list", ")", "\n", "", "return", "self", ".", "pad_token_id_list", "(", "batch_token_id_list", ")", ",", "self", ".", "pad_seg_id_list", "(", "batch_seg_id_list", ")", ",", "self", ".", "pad_uttr_id_list", "(", "batch_uttr_response_seg_list", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.learn.get_model_name": [[17, 23], ["os.listdir", "filename.startswith"], "function", ["None"], ["def", "get_model_name", "(", "root_dir", ",", "prefix", ")", ":", "\n", "    ", "for", "filename", "in", "os", ".", "listdir", "(", "root_dir", ")", ":", "\n", "        ", "if", "filename", ".", "startswith", "(", "prefix", ")", ":", "\n", "            ", "model_name", "=", "filename", "\n", "break", "\n", "", "", "return", "model_name", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.learn.transform_input": [[24, 32], ["torch.LongTensor", "torch.LongTensor", "res_list.append", "one_res.to.to"], "function", ["None"], ["", "def", "transform_input", "(", "list_of_batch_inp", ",", "device", "=", "None", ",", "use_cuda", "=", "False", ")", ":", "\n", "    ", "res_list", "=", "[", "]", "\n", "for", "item", "in", "list_of_batch_inp", ":", "\n", "        ", "one_res", "=", "torch", ".", "LongTensor", "(", "item", ")", "\n", "if", "use_cuda", ":", "\n", "            ", "one_res", "=", "one_res", ".", "to", "(", "device", ")", "\n", "", "res_list", ".", "append", "(", "one_res", ")", "\n", "", "return", "res_list", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.learn.hinge_loss": [[33, 37], ["torch.nn.functional.relu", "torch.nn.functional.relu", "torch.mean", "torch.mean", "torch.unsqueeze", "torch.unsqueeze"], "function", ["None"], ["", "def", "hinge_loss", "(", "scores", ",", "margin", ")", ":", "\n", "# y_pred: bsz x candi_num", "\n", "    ", "loss", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "margin", "-", "(", "torch", ".", "unsqueeze", "(", "scores", "[", ":", ",", "0", "]", ",", "-", "1", ")", "-", "scores", "[", ":", ",", "1", ":", "]", ")", ")", "\n", "return", "torch", ".", "mean", "(", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.learn.learn": [[38, 194], ["os.path.exists", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "transformers.AdamW.zero_grad", "model.train", "range", "os.makedirs", "int", "int", "model.parameters", "data.get_train_next_batch", "learn.transform_input", "learn.transform_input", "learn.transform_input", "model.compute_batch_loss.mean", "model.compute_batch_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "model.compute_batch_loss.item", "model.module.compute_batch_loss", "model.compute_batch_loss", "model.parameters", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "transformers.AdamW.zero_grad", "print", "model.eval", "model.train", "torch.no_grad", "torch.no_grad", "range", "utlis.compute_MAP", "utlis.compute_MRR", "utlis.compute_P1", "utlis.compute_R2_1", "utlis.compute_R10_k", "utlis.compute_R10_k", "utlis.compute_R10_k", "print", "print", "os.listdir", "sorted", "data.get_next_dev_batch", "learn.transform_input", "learn.transform_input", "learn.transform_input", "len", "model.batch_forward.detach().cpu().tolist", "valid_dev_score_list.extend", "valid_dev_label_list.extend", "len", "len", "print", "print", "fileData.items", "len", "range", "model.module.batch_forward", "model.batch_forward", "model.batch_forward.size", "torch.Size", "torch.Size", "print", "print", "torch.save", "torch.save", "torch.save", "torch.save", "os.stat", "operator.itemgetter", "len", "os.remove", "model.batch_forward.detach().cpu", "round", "print", "print", "Exception", "round", "model.module.state_dict", "model.state_dict", "model.batch_forward.detach", "round"], "function", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.dataloader.Data.get_train_next_batch", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.inference.transform_input", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.inference.transform_input", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.inference.transform_input", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.model.Model.compute_batch_loss", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.model.Model.compute_batch_loss", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.optimization.BertAdam.step", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.optimization.BertAdam.step", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_MAP", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_MRR", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_P1", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_R2_1", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_R10_k", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_R10_k", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_R10_k", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Data.get_next_dev_batch", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.inference.transform_input", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.inference.transform_input", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.inference.transform_input", "home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.batch_forward", "home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.batch_forward"], ["", "def", "learn", "(", "args", ",", "total_steps", ",", "data", ",", "model", ",", "train_mode", ",", "device", ",", "multi_gpu_training", ")", ":", "\n", "    ", "assert", "train_mode", "in", "[", "'pretrain'", ",", "'finetune'", "]", "\n", "assert", "args", ".", "corpus_name", "in", "[", "'douban'", ",", "'ubuntu'", ",", "'e-commerce'", "]", "\n", "\n", "directory", "=", "args", ".", "ckpt_path", "+", "'/'", "+", "train_mode", "+", "'/'", "\n", "import", "os", "\n", "if", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "        ", "pass", "\n", "", "else", ":", "# recursively construct directory", "\n", "        ", "os", ".", "makedirs", "(", "directory", ",", "exist_ok", "=", "True", ")", "\n", "\n", "#--- training part ---#", "\n", "", "batch_size", "=", "args", ".", "batch_size_per_gpu", "*", "args", ".", "number_of_gpu", "\n", "training_data_num", ",", "dev_data_num", "=", "data", ".", "train_num", ",", "data", ".", "dev_num", "\n", "train_step_num", "=", "int", "(", "training_data_num", "/", "batch_size", ")", "+", "1", "\n", "dev_step_num", "=", "int", "(", "dev_data_num", "/", "batch_size", ")", "+", "1", "\n", "max_dev_score", "=", "0.0", "\n", "\n", "optimizer", "=", "AdamW", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ")", "\n", "overall_update_steps", "=", "total_steps", "//", "args", ".", "gradient_accumulation_steps", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "overall_update_steps", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "batches_processed", "=", "0", "\n", "model", ".", "train", "(", ")", "\n", "for", "one_step", "in", "range", "(", "total_steps", ")", ":", "\n", "        ", "epoch", "=", "one_step", "//", "train_step_num", "\n", "loss_accumulated", "=", "0.", "\n", "batches_processed", "+=", "1", "\n", "\n", "train_list_of_batch_token_id_inp", ",", "train_list_of_batch_speaker_seg_id_inp", ",", "train_list_of_batch_uttr_seg_id_inp", "=", "data", ".", "get_train_next_batch", "(", "batch_size", ",", "args", ".", "negative_num", ")", "\n", "train_list_of_batch_token_id_inp", "=", "transform_input", "(", "train_list_of_batch_token_id_inp", ",", "device", "=", "device", ",", "use_cuda", "=", "True", ")", "\n", "train_list_of_batch_speaker_seg_id_inp", "=", "transform_input", "(", "train_list_of_batch_speaker_seg_id_inp", ",", "device", "=", "device", ",", "use_cuda", "=", "True", ")", "\n", "train_list_of_batch_uttr_seg_id_inp", "=", "transform_input", "(", "train_list_of_batch_uttr_seg_id_inp", ",", "device", "=", "device", ",", "use_cuda", "=", "True", ")", "\n", "\n", "'''\n        if multi_gpu_training:\n            train_batch_score = model.module.batch_forward(train_list_of_batch_token_id_inp, train_list_of_batch_speaker_seg_id_inp, \n                                                train_list_of_batch_uttr_seg_id_inp, is_training = True)\n        else:\n            train_batch_score = model.batch_forward(train_list_of_batch_token_id_inp, train_list_of_batch_speaker_seg_id_inp, \n                                                train_list_of_batch_uttr_seg_id_inp, is_training = True)\n        #print (train_batch_score.size())\n\n        train_loss = hinge_loss(train_batch_score, args.loss_margin)\n        '''", "\n", "if", "multi_gpu_training", ":", "\n", "            ", "train_loss", "=", "model", ".", "module", ".", "compute_batch_loss", "(", "args", ".", "loss_margin", ",", "train_list_of_batch_token_id_inp", ",", "\n", "train_list_of_batch_speaker_seg_id_inp", ",", "train_list_of_batch_uttr_seg_id_inp", ",", "is_training", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "train_loss", "=", "model", ".", "compute_batch_loss", "(", "args", ".", "loss_margin", ",", "train_list_of_batch_token_id_inp", ",", "\n", "train_list_of_batch_speaker_seg_id_inp", ",", "train_list_of_batch_uttr_seg_id_inp", ",", "is_training", "=", "True", ")", "\n", "\n", "", "train_loss", "=", "train_loss", ".", "mean", "(", ")", "\n", "train_loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "1.0", ")", "\n", "#optimizer.step()", "\n", "#scheduler.step()", "\n", "loss_accumulated", "+=", "train_loss", ".", "item", "(", ")", "\n", "\n", "if", "(", "one_step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", ":", "\n", "            ", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "if", "batches_processed", "%", "args", ".", "print_every", "==", "0", ":", "\n", "            ", "print", "(", "'At epoch %d, batch %d, loss %.5f, max combine score is %5f'", "%", "\n", "(", "epoch", ",", "batches_processed", ",", "loss_accumulated", "/", "batches_processed", ",", "max_dev_score", ")", ")", "\n", "loss_accumulated", "=", "0.", "\n", "\n", "", "if", "batches_processed", "%", "args", ".", "eval_every", "==", "0", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "dev_score_list", ",", "dev_label_list", "=", "[", "]", ",", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "for", "dev_step", "in", "range", "(", "dev_step_num", ")", ":", "\n", "                    ", "dev_list_of_batch_token_id_inp", ",", "dev_list_of_batch_speaker_seg_id_inp", ",", "dev_list_of_batch_uttr_seg_id_inp", ",", "dev_batch_candidate_response_label_list", "=", "data", ".", "get_next_dev_batch", "(", "batch_size", ")", "\n", "dev_list_of_batch_token_id_inp", "=", "transform_input", "(", "dev_list_of_batch_token_id_inp", ",", "device", "=", "device", ",", "use_cuda", "=", "True", ")", "\n", "dev_list_of_batch_speaker_seg_id_inp", "=", "transform_input", "(", "dev_list_of_batch_speaker_seg_id_inp", ",", "device", "=", "device", ",", "use_cuda", "=", "True", ")", "\n", "dev_list_of_batch_uttr_seg_id_inp", "=", "transform_input", "(", "dev_list_of_batch_uttr_seg_id_inp", ",", "device", "=", "device", ",", "use_cuda", "=", "True", ")", "\n", "if", "multi_gpu_training", ":", "\n", "                        ", "dev_batch_score", "=", "model", ".", "module", ".", "batch_forward", "(", "dev_list_of_batch_token_id_inp", ",", "dev_list_of_batch_speaker_seg_id_inp", ",", "\n", "dev_list_of_batch_uttr_seg_id_inp", ",", "is_training", "=", "False", ")", "\n", "", "else", ":", "\n", "                        ", "dev_batch_score", "=", "model", ".", "batch_forward", "(", "dev_list_of_batch_token_id_inp", ",", "dev_list_of_batch_speaker_seg_id_inp", ",", "\n", "dev_list_of_batch_uttr_seg_id_inp", ",", "is_training", "=", "False", ")", "\n", "", "candi_num", "=", "len", "(", "dev_list_of_batch_token_id_inp", ")", "\n", "assert", "dev_batch_score", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "batch_size", ",", "candi_num", "]", ")", "\n", "dev_batch_score", "=", "dev_batch_score", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "dev_score_list", "+=", "dev_batch_score", "\n", "dev_label_list", "+=", "dev_batch_candidate_response_label_list", "\n", "", "valid_dev_score_list", "=", "[", "]", "\n", "for", "item", "in", "dev_score_list", "[", ":", "data", ".", "dev_num", "]", ":", "\n", "                    ", "valid_dev_score_list", ".", "extend", "(", "item", ")", "\n", "", "valid_dev_label_list", "=", "[", "]", "\n", "for", "item", "in", "dev_label_list", "[", ":", "data", ".", "dev_num", "]", ":", "\n", "                    ", "valid_dev_label_list", ".", "extend", "(", "item", ")", "\n", "", "assert", "len", "(", "valid_dev_score_list", ")", "==", "len", "(", "valid_dev_label_list", ")", "\n", "\n", "MAP", "=", "compute_MAP", "(", "valid_dev_score_list", ",", "valid_dev_label_list", ",", "n", "=", "candi_num", ")", "\n", "MRR", "=", "compute_MRR", "(", "valid_dev_score_list", ",", "valid_dev_label_list", ",", "n", "=", "candi_num", ")", "\n", "P_1", "=", "compute_P1", "(", "valid_dev_score_list", ",", "valid_dev_label_list", ",", "n", "=", "candi_num", ")", "\n", "R2_1", "=", "compute_R2_1", "(", "valid_dev_score_list", ",", "valid_dev_label_list", ",", "n", "=", "candi_num", ")", "\n", "R10_1", "=", "compute_R10_k", "(", "valid_dev_score_list", ",", "valid_dev_label_list", ",", "n", "=", "candi_num", ",", "k", "=", "1", ")", "\n", "R10_2", "=", "compute_R10_k", "(", "valid_dev_score_list", ",", "valid_dev_label_list", ",", "n", "=", "candi_num", ",", "k", "=", "2", ")", "\n", "R10_5", "=", "compute_R10_k", "(", "valid_dev_score_list", ",", "valid_dev_label_list", ",", "n", "=", "candi_num", ",", "k", "=", "5", ")", "\n", "if", "args", ".", "corpus_name", "==", "'douban'", ":", "\n", "                    ", "curr_dev_score", "=", "MAP", "+", "MRR", "+", "P_1", "+", "R10_1", "+", "R10_2", "+", "R10_5", "\n", "print", "(", "'----------------------------------------------------------------'", ")", "\n", "print", "(", "'At epoch %d, batch %d, MAP is %5f, MRR is %5f, P_1 is %5f, R10_1 is %5f, \\\n                            R10_2 is %5f, R10_5 is %5f'", "%", "(", "epoch", ",", "batches_processed", ",", "MAP", ",", "MRR", ",", "P_1", ",", "R10_1", ",", "\n", "R10_2", ",", "R10_5", ")", ")", "\n", "save_name", "=", "'/epoch_%d_batch_%d_MAP_%.3f_MRR_%.3f_P_1_%.3f_R10_1_%.3f_R10_2_%.3f_R10_5_%.3f_combine_score_%.3f'", "%", "(", "epoch", ",", "batches_processed", ",", "MAP", ",", "MRR", ",", "P_1", ",", "R10_1", ",", "R10_2", ",", "R10_5", ",", "round", "(", "curr_dev_score", ",", "3", ")", ")", "\n", "", "elif", "corpus_name", "==", "'ubuntu'", ":", "\n", "                    ", "curr_dev_score", "=", "R2_1", "+", "R10_1", "+", "R10_2", "+", "R10_5", "\n", "print", "(", "'----------------------------------------------------------------'", ")", "\n", "print", "(", "'At epoch %d, batch %d, R2_1 is %5f, R10_1 is %5f, R10_2 is %5f, R10_5 is %5f'", "%", "\n", "(", "epoch", ",", "batches_processed", ",", "R2_1", ",", "R10_1", ",", "R10_2", ",", "R10_5", ")", ")", "\n", "save_name", "=", "'/epoch_%d_batch_%d_R2_1_%.3f_R10_1_%.3f_R10_2_%.3f_R10_5_%.3f_combine_score_%.3f'", "%", "(", "epoch", ",", "batches_processed", ",", "R2_1", ",", "R10_1", ",", "R10_2", ",", "R10_5", ",", "round", "(", "curr_dev_score", ",", "3", ")", ")", "\n", "", "elif", "corpus_name", "==", "'e-commerce'", ":", "\n", "                    ", "curr_dev_score", "=", "R10_1", "+", "R10_2", "+", "R10_5", "\n", "print", "(", "'----------------------------------------------------------------'", ")", "\n", "print", "(", "'At epoch %d, batch %d, R10_1 is %5f, R10_2 is %5f, R10_5 is %5f'", "%", "\n", "(", "epoch", ",", "batches_processed", ",", "R10_1", ",", "R10_2", ",", "R10_5", ")", ")", "\n", "save_name", "=", "'/epoch_%d_batch_%d_R10_1_%.3f_R10_2_%.3f_R10_5_%.3f_combine_score_%.3f'", "%", "(", "epoch", ",", "batches_processed", ",", "R10_1", ",", "R10_2", ",", "R10_5", ",", "round", "(", "curr_dev_score", ",", "3", ")", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "'Wrong Corpus Name!!!'", ")", "\n", "\n", "", "print", "(", "'At epoch %d, batch %d, curr combine score is %5f'", "%", "(", "epoch", ",", "batches_processed", ",", "curr_dev_score", ")", ")", "\n", "print", "(", "'----------------------------------------------------------------'", ")", "\n", "\n", "if", "curr_dev_score", ">", "max_dev_score", ":", "\n", "                    ", "if", "multi_gpu_training", ":", "\n", "                        ", "torch", ".", "save", "(", "{", "'args'", ":", "args", ",", "'model'", ":", "model", ".", "module", ".", "state_dict", "(", ")", "}", ",", "directory", "+", "save_name", ")", "\n", "", "else", ":", "\n", "                        ", "torch", ".", "save", "(", "{", "'args'", ":", "args", ",", "'model'", ":", "model", ".", "state_dict", "(", ")", "}", ",", "directory", "+", "save_name", ")", "\n", "", "max_dev_score", "=", "curr_dev_score", "\n", "", "else", ":", "\n", "                    ", "pass", "\n", "", "fileData", "=", "{", "}", "\n", "for", "fname", "in", "os", ".", "listdir", "(", "directory", ")", ":", "\n", "                    ", "fileData", "[", "fname", "]", "=", "os", ".", "stat", "(", "directory", "+", "'/'", "+", "fname", ")", ".", "st_mtime", "\n", "\n", "", "sortedFiles", "=", "sorted", "(", "fileData", ".", "items", "(", ")", ",", "key", "=", "itemgetter", "(", "1", ")", ")", "\n", "if", "len", "(", "sortedFiles", ")", "<", "1", ":", "\n", "                    ", "pass", "\n", "", "else", ":", "\n", "                    ", "delete", "=", "len", "(", "sortedFiles", ")", "-", "1", "\n", "for", "x", "in", "range", "(", "0", ",", "delete", ")", ":", "\n", "                        ", "os", ".", "remove", "(", "directory", "+", "'/'", "+", "sortedFiles", "[", "x", "]", "[", "0", "]", ")", "\n", "", "", "", "model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.learn.parse_config": [[195, 228], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "", "", "def", "parse_config", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# data configuration", "\n", "parser", ".", "add_argument", "(", "'--corpus_name'", ",", "type", "=", "str", ",", "help", "=", "\"The name of concerned corpus.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--train_context_path'", ",", "type", "=", "str", ",", "help", "=", "\"The file contains all training context.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--train_true_response_path'", ",", "type", "=", "str", ",", "help", "=", "\"The file contains all reference response.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--response_index_path'", ",", "type", "=", "str", ",", "help", "=", "\"The file contains all responses in the dataset.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--train_context_vec_file'", ",", "type", "=", "str", ",", "help", "=", "\"File contains context representations.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--all_response_vec_file'", ",", "type", "=", "str", ",", "help", "=", "\"File contains response representations.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_path'", ",", "type", "=", "str", ",", "help", "=", "\"Validation data path.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--bert_path'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--max_uttr_num'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "\"Maximum number of utterances in the context.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max_uttr_len'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "help", "=", "\"Maximum length of each utterance.\"", ")", "\n", "# mips configuration", "\n", "parser", ".", "add_argument", "(", "'--cutoff_threshold'", ",", "type", "=", "float", ",", "default", "=", "0.8", ")", "\n", "parser", ".", "add_argument", "(", "'--negative_selection_k'", ",", "type", "=", "int", ",", "default", "=", "50", ")", "\n", "# sampling configuration", "\n", "parser", ".", "add_argument", "(", "'--negative_num'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"Number of negative samples during training.\"", ")", "\n", "# learning configuration", "\n", "#parser.add_argument('--batch_size',type=int, default=4)", "\n", "parser", ".", "add_argument", "(", "\"--batch_size_per_gpu\"", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'Batch size for each gpu.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--number_of_gpu\"", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "\"Number of available GPUs.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "\"Number of steps for gradient accumulation during training.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "5e-6", ")", "\n", "parser", ".", "add_argument", "(", "'--loss_margin'", ",", "type", "=", "float", ",", "default", "=", "0.3", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrain_total_steps'", ",", "type", "=", "int", ",", "default", "=", "300000", ")", "\n", "parser", ".", "add_argument", "(", "'--finetune_total_steps'", ",", "type", "=", "int", ",", "default", "=", "100000", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "2000", ")", "\n", "parser", ".", "add_argument", "(", "'--print_every'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_every'", ",", "type", "=", "int", ",", "default", "=", "1000", ")", "\n", "parser", ".", "add_argument", "(", "'--ckpt_path'", ",", "type", "=", "str", ",", "help", "=", "\"Path to save the model checkpoints.\"", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.inference.get_model_name": [[18, 24], ["os.listdir", "filename.startswith"], "function", ["None"], ["def", "get_model_name", "(", "root_dir", ",", "prefix", ")", ":", "\n", "    ", "for", "filename", "in", "os", ".", "listdir", "(", "root_dir", ")", ":", "\n", "        ", "if", "filename", ".", "startswith", "(", "prefix", ")", ":", "\n", "            ", "model_name", "=", "filename", "\n", "break", "\n", "", "", "return", "model_name", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.inference.transform_input": [[25, 33], ["torch.LongTensor", "torch.LongTensor", "res_list.append", "one_res.to.to"], "function", ["None"], ["", "def", "transform_input", "(", "list_of_batch_inp", ",", "device", "=", "None", ",", "use_cuda", "=", "False", ")", ":", "\n", "    ", "res_list", "=", "[", "]", "\n", "for", "item", "in", "list_of_batch_inp", ":", "\n", "        ", "one_res", "=", "torch", ".", "LongTensor", "(", "item", ")", "\n", "if", "use_cuda", ":", "\n", "            ", "one_res", "=", "one_res", ".", "to", "(", "device", ")", "\n", "", "res_list", ".", "append", "(", "one_res", ")", "\n", "", "return", "res_list", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.inference.parse_config": [[34, 53], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "def", "parse_config", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# data configuration", "\n", "parser", ".", "add_argument", "(", "'--corpus_name'", ",", "type", "=", "str", ",", "help", "=", "\"The name of concerned corpus.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--train_context_path'", ",", "type", "=", "str", ",", "help", "=", "\"The file contains all training context.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--train_true_response_path'", ",", "type", "=", "str", ",", "help", "=", "\"The file contains all reference response.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--response_index_path'", ",", "type", "=", "str", ",", "help", "=", "\"The file contains all responses in the dataset.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--train_context_vec_file'", ",", "type", "=", "str", ",", "help", "=", "\"File contains context representations.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--all_response_vec_file'", ",", "type", "=", "str", ",", "help", "=", "\"File contains response representations.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_path'", ",", "type", "=", "str", ",", "help", "=", "\"Validation data path.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--bert_path'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--max_uttr_num'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "\"Maximum number of utterances in the context.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max_uttr_len'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "help", "=", "\"Maximum length of each utterance.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--negative_num'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"Number of negative samples during training.\"", ")", "\n", "# learning configuration", "\n", "#parser.add_argument('--batch_size',type=int, default=4)", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "type", "=", "int", ",", "help", "=", "'Inference batch size.'", ")", "\n", "parser", ".", "add_argument", "(", "'--ckpt_path'", ",", "type", "=", "str", ",", "help", "=", "\"Path to save the model checkpoints.\"", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.model.Model.__init__": [[14, 22], ["torch.nn.Module.__init__", "transformer.Seg_Embedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.Seg_Embedding"], ["    ", "def", "__init__", "(", "self", ",", "bert_model", ",", "padding_idx", ")", ":", "\n", "        ", "super", "(", "Model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bert_model", "=", "bert_model", "\n", "self", ".", "hidden_size", "=", "self", ".", "bert_model", ".", "config", ".", "hidden_size", "\n", "self", ".", "speaker_seg_embedding", "=", "Seg_Embedding", "(", "3", ",", "self", ".", "hidden_size", ")", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "final_linear", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "1", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "final_linear", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.model.Model.forward": [[23, 39], ["model.Model.speaker_seg_embedding", "batch_representation.size", "model.Model.final_linear", "batch_token_id_inp.eq", "model.Model.bert_model", "model.Model.bert_model.work", "batch_representation.transpose", "batch_cls_vec.size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "model.Model.size", "torch.Size", "torch.Size", "torch.Size", "torch.Size"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertModel.work"], ["", "def", "forward", "(", "self", ",", "batch_token_id_inp", ",", "batch_speaker_seg_id_inp", ",", "batch_uttr_seg_id_inp", ",", "is_training", ")", ":", "\n", "        ", "batch_speaker_seg_embeddings", "=", "self", ".", "speaker_seg_embedding", "(", "batch_speaker_seg_id_inp", ")", "\n", "#batch_mask = 1 - batch_token_id_inp.eq(self.padding_idx)", "\n", "batch_mask", "=", "~", "batch_token_id_inp", ".", "eq", "(", "self", ".", "padding_idx", ")", "\n", "if", "is_training", ":", "\n", "            ", "batch_representation", ",", "_", "=", "self", ".", "bert_model", "(", "batch_token_id_inp", ",", "batch_speaker_seg_embeddings", ",", "batch_speaker_seg_id_inp", ",", "\n", "token_type_ids", "=", "batch_uttr_seg_id_inp", ",", "attention_mask", "=", "batch_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "batch_representation", ",", "_", "=", "self", ".", "bert_model", ".", "work", "(", "batch_token_id_inp", ",", "batch_speaker_seg_embeddings", ",", "batch_speaker_seg_id_inp", ",", "\n", "token_type_ids", "=", "batch_uttr_seg_id_inp", ",", "attention_mask", "=", "batch_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "", "bsz", ",", "seqlen", ",", "_", "=", "batch_representation", ".", "size", "(", ")", "\n", "batch_cls_vec", "=", "batch_representation", ".", "transpose", "(", "0", ",", "1", ")", "[", "0", "]", "\n", "assert", "batch_cls_vec", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "self", ".", "hidden_size", "]", ")", "\n", "logits", "=", "self", ".", "final_linear", "(", "batch_cls_vec", ")", "\n", "assert", "logits", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "1", "]", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.model.Model.batch_forward": [[40, 55], ["len", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "list_of_batch_token_id_inp[].size", "model.Model.forward", "batch_score_list.append", "torch.cat.size", "torch.cat.size", "torch.Size", "torch.Size", "torch.Size", "torch.Size"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.forward"], ["", "def", "batch_forward", "(", "self", ",", "list_of_batch_token_id_inp", ",", "list_of_batch_speaker_seg_id_inp", ",", "list_of_batch_uttr_seg_id_inp", ",", "is_training", ")", ":", "\n", "# list_of_batch_token_id_inp: each item has size of bsz x seqlen_i", "\n", "# length of list_of_batch_token_id_inp is candi_num", "\n", "        ", "item_num", "=", "len", "(", "list_of_batch_token_id_inp", ")", "\n", "bsz", "=", "list_of_batch_token_id_inp", "[", "0", "]", ".", "size", "(", ")", "[", "0", "]", "\n", "batch_score_list", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "item_num", ")", ":", "\n", "            ", "batch_token_id_inp", "=", "list_of_batch_token_id_inp", "[", "k", "]", "\n", "batch_speaker_seg_id_inp", "=", "list_of_batch_speaker_seg_id_inp", "[", "k", "]", "\n", "batch_uttr_seg_id_inp", "=", "list_of_batch_uttr_seg_id_inp", "[", "k", "]", "\n", "one_score", "=", "self", ".", "forward", "(", "batch_token_id_inp", ",", "batch_speaker_seg_id_inp", ",", "batch_uttr_seg_id_inp", ",", "is_training", ")", "\n", "batch_score_list", ".", "append", "(", "one_score", ")", "\n", "", "batch_scores", "=", "torch", ".", "cat", "(", "batch_score_list", ",", "dim", "=", "-", "1", ")", "\n", "assert", "batch_scores", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "item_num", "]", ")", "\n", "return", "batch_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.model.Model.compute_batch_loss": [[56, 73], ["len", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.hinge_loss", "list_of_batch_token_id_inp[].size", "model.Model.forward", "batch_score_list.append", "torch.cat.size", "torch.cat.size", "torch.Size", "torch.Size", "torch.Size", "torch.Size"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.train.hinge_loss", "home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.forward"], ["", "def", "compute_batch_loss", "(", "self", ",", "margin", ",", "list_of_batch_token_id_inp", ",", "list_of_batch_speaker_seg_id_inp", ",", "\n", "list_of_batch_uttr_seg_id_inp", ",", "is_training", ")", ":", "\n", "# list_of_batch_token_id_inp: each item has size of bsz x seqlen_i", "\n", "# length of list_of_batch_token_id_inp is candi_num", "\n", "        ", "item_num", "=", "len", "(", "list_of_batch_token_id_inp", ")", "\n", "bsz", "=", "list_of_batch_token_id_inp", "[", "0", "]", ".", "size", "(", ")", "[", "0", "]", "\n", "batch_score_list", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "item_num", ")", ":", "\n", "            ", "batch_token_id_inp", "=", "list_of_batch_token_id_inp", "[", "k", "]", "\n", "batch_speaker_seg_id_inp", "=", "list_of_batch_speaker_seg_id_inp", "[", "k", "]", "\n", "batch_uttr_seg_id_inp", "=", "list_of_batch_uttr_seg_id_inp", "[", "k", "]", "\n", "one_score", "=", "self", ".", "forward", "(", "batch_token_id_inp", ",", "batch_speaker_seg_id_inp", ",", "batch_uttr_seg_id_inp", ",", "is_training", ")", "\n", "batch_score_list", ".", "append", "(", "one_score", ")", "\n", "", "batch_scores", "=", "torch", ".", "cat", "(", "batch_score_list", ",", "dim", "=", "-", "1", ")", "\n", "assert", "batch_scores", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "item_num", "]", ")", "\n", "batch_loss", "=", "hinge_loss", "(", "batch_scores", ",", "margin", ")", "\n", "return", "batch_loss", "", "", "", ""]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.model.hinge_loss": [[7, 11], ["torch.nn.functional.relu", "torch.nn.functional.relu", "torch.unsqueeze", "torch.unsqueeze"], "function", ["None"], ["def", "hinge_loss", "(", "scores", ",", "margin", ")", ":", "\n", "# y_pred: bsz x candi_num", "\n", "    ", "loss", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "margin", "-", "(", "torch", ".", "unsqueeze", "(", "scores", "[", ":", ",", "0", "]", ",", "-", "1", ")", "-", "scores", "[", ":", ",", "1", ":", "]", ")", ")", "\n", "return", "loss", "\n", "#return torch.mean(loss)", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.utlis.get_model_name": [[9, 15], ["os.listdir", "filename.startswith"], "function", ["None"], ["def", "get_model_name", "(", "root_dir", ",", "prefix", ")", ":", "\n", "    ", "for", "filename", "in", "os", ".", "listdir", "(", "root_dir", ")", ":", "\n", "        ", "if", "filename", ".", "startswith", "(", "prefix", ")", ":", "\n", "            ", "model_name", "=", "filename", "\n", "break", "\n", "", "", "return", "model_name", "\n", "# ------------------------------------------------------------------------------------- #", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.utlis.compute_Rn_k": [[17, 28], ["range", "len", "float", "numpy.asarray", "np.asarray.argsort"], "function", ["None"], ["", "def", "compute_Rn_k", "(", "scores", ",", "labels", ",", "n", "=", "2", ",", "k", "=", "1", ")", ":", "\n", "    ", "total", "=", "0", "\n", "correct", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "        ", "if", "labels", "[", "i", "]", "==", "1", ":", "\n", "            ", "total", "=", "total", "+", "1", "\n", "sublist", "=", "np", ".", "asarray", "(", "scores", "[", "i", ":", "i", "+", "n", "]", ")", "\n", "index", "=", "sublist", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "[", "0", ":", "k", "]", "\n", "if", "scores", "[", "i", "]", "in", "sublist", "[", "index", "]", ":", "\n", "                ", "correct", "=", "correct", "+", "1", "\n", "", "", "", "return", "float", "(", "correct", ")", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.utlis.compute_R2_1": [[29, 44], ["range", "len", "range", "numpy.asarray", "float", "len", "true_response_index.append", "np.asarray.argsort", "len", "numpy.intersect1d"], "function", ["None"], ["", "def", "compute_R2_1", "(", "scores", ",", "labels", ",", "n", "=", "10", ",", "k", "=", "1", ",", "m", "=", "2", ")", ":", "\n", "    ", "total", "=", "0", "\n", "correct", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "labels", ")", ",", "n", ")", ":", "\n", "        ", "total", "=", "total", "+", "1", "\n", "true_response_index", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "i", ",", "i", "+", "n", ")", ":", "\n", "            ", "if", "labels", "[", "j", "]", "==", "1", ":", "\n", "                ", "true_response_index", ".", "append", "(", "j", "-", "i", ")", "\n", "", "", "sublist", "=", "np", ".", "asarray", "(", "scores", "[", "i", ":", "i", "+", "m", "]", ")", "\n", "index", "=", "sublist", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "[", "0", ":", "k", "]", "\n", "# if len(np.intersect1d(index, true_response_index)) > 0:", "\n", "#         correct = correct + 1", "\n", "correct", "+=", "len", "(", "np", ".", "intersect1d", "(", "index", ",", "true_response_index", ")", ")", "*", "1.0", "/", "len", "(", "true_response_index", ")", "\n", "", "return", "float", "(", "correct", ")", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.utlis.compute_R10_k": [[45, 60], ["range", "len", "range", "numpy.asarray", "float", "len", "true_response_index.append", "np.asarray.argsort", "len", "numpy.intersect1d"], "function", ["None"], ["", "def", "compute_R10_k", "(", "scores", ",", "labels", ",", "n", "=", "10", ",", "k", "=", "1", ")", ":", "\n", "    ", "total", "=", "0", "\n", "correct", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "labels", ")", ",", "n", ")", ":", "\n", "        ", "total", "=", "total", "+", "1", "\n", "true_response_index", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "i", ",", "i", "+", "n", ")", ":", "\n", "            ", "if", "labels", "[", "j", "]", "==", "1", ":", "\n", "                ", "true_response_index", ".", "append", "(", "j", "-", "i", ")", "\n", "", "", "sublist", "=", "np", ".", "asarray", "(", "scores", "[", "i", ":", "i", "+", "n", "]", ")", "\n", "index", "=", "sublist", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "[", "0", ":", "k", "]", "\n", "# if len(np.intersect1d(index, true_response_index)) > 0:", "\n", "#         correct = correct + 1", "\n", "correct", "+=", "len", "(", "np", ".", "intersect1d", "(", "index", ",", "true_response_index", ")", ")", "*", "1.0", "/", "len", "(", "true_response_index", ")", "\n", "", "return", "float", "(", "correct", ")", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.utlis.compute_P1": [[61, 73], ["range", "len", "numpy.asarray", "float", "np.asarray.argsort"], "function", ["None"], ["", "def", "compute_P1", "(", "scores", ",", "labels", ",", "n", "=", "10", ")", ":", "\n", "    ", "'''precision at position 1'''", "\n", "total", "=", "0", "\n", "correct", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "labels", ")", ",", "n", ")", ":", "\n", "        ", "total", "=", "total", "+", "1", "\n", "sublist", "=", "np", ".", "asarray", "(", "scores", "[", "i", ":", "i", "+", "n", "]", ")", "\n", "index", "=", "sublist", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "p1", "=", "0.0", "\n", "if", "labels", "[", "i", "+", "index", "[", "0", "]", "]", "==", "1", ":", "p1", "=", "1.0", "\n", "correct", "+=", "p1", "\n", "", "return", "float", "(", "correct", ")", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.utlis.compute_MAP": [[74, 89], ["range", "len", "numpy.asarray", "enumerate", "float", "np.asarray.argsort"], "function", ["None"], ["", "def", "compute_MAP", "(", "scores", ",", "labels", ",", "n", "=", "10", ")", ":", "\n", "    ", "total", "=", "0", "\n", "correct", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "labels", ")", ",", "n", ")", ":", "\n", "        ", "total", "=", "total", "+", "1", "\n", "sublist", "=", "np", ".", "asarray", "(", "scores", "[", "i", ":", "i", "+", "n", "]", ")", "\n", "index", "=", "sublist", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "ap", "=", "0.0", "\n", "count", "=", "0", "\n", "for", "j", ",", "ans_index", "in", "enumerate", "(", "index", ")", ":", "\n", "            ", "if", "labels", "[", "i", "+", "ans_index", "]", "==", "1", ":", "\n", "                ", "count", "+=", "1", "\n", "ap", "+=", "count", "/", "(", "j", "+", "1.0", ")", "\n", "", "", "correct", "+=", "(", "ap", "/", "count", ")", "\n", "", "return", "float", "(", "correct", ")", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.utlis.compute_MRR": [[90, 104], ["range", "len", "numpy.asarray", "enumerate", "float", "np.asarray.argsort"], "function", ["None"], ["", "def", "compute_MRR", "(", "scores", ",", "labels", ",", "n", "=", "10", ")", ":", "\n", "    ", "total", "=", "0", "\n", "correct", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "labels", ")", ",", "n", ")", ":", "\n", "        ", "total", "=", "total", "+", "1", "\n", "sublist", "=", "np", ".", "asarray", "(", "scores", "[", "i", ":", "i", "+", "n", "]", ")", "\n", "index", "=", "sublist", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "ap", "=", "0.0", "\n", "for", "j", ",", "ans_index", "in", "enumerate", "(", "index", ")", ":", "\n", "            ", "if", "labels", "[", "i", "+", "ans_index", "]", "==", "1", ":", "\n", "                ", "ap", "+=", "1.0", "/", "(", "j", "+", "1.0", ")", "\n", "break", "\n", "", "", "correct", "+=", "ap", "\n", "", "return", "float", "(", "correct", ")", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.dataloader.Data.__init__": [[31, 120], ["text_processor.Text_Processor", "len", "print", "dataloader.load_all_response_id_list", "print", "print", "len", "dataloader.Data.load_dev_data", "len", "print", "open", "i.readlines", "len", "range", "len", "open", "i.readlines", "progressbar.ProgressBar", "progressbar.ProgressBar.start", "progressbar.ProgressBar.finish", "open", "i.readlines", "progressbar.ProgressBar", "progressbar.ProgressBar.start", "progressbar.ProgressBar.finish", "len", "len", "print", "lines[].strip", "dataloader.Data.index_response_text_list.append", "range", "range", "len", "l.strip", "dataloader.Data.text_processor.process_context_id", "dataloader.Data.train_context_id_list.append", "dataloader.Data.train_context_seg_list.append", "progressbar.ProgressBar.update", "len", "int", "dataloader.Data.train_true_response_index_list.append", "dataloader.Data.train_true_response_id_list.append", "dataloader.Data.train_true_response_seg_id_list.append", "progressbar.ProgressBar.update", "print", "print", "dataloader.load_pickle_file", "print", "dataloader.load_pickle_file", "Exception", "range", "range", "len", "l.strip", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.dataloader.load_all_response_id_list", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass_utlis.load_dev_data", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.process_context_id", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.load_pickle_file", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.load_pickle_file"], ["    ", "def", "__init__", "(", "self", ",", "train_context_path", ",", "train_true_response_id_path", ",", "train_response_index_path", ",", "\n", "dev_path", ",", "word2id_path", ",", "max_uttr_num", ",", "max_uttr_len", ",", "mips_config", ",", "negative_mode", ",", "\n", "train_context_vec_file", ",", "all_response_vec_file", ")", ":", "\n", "        ", "'''\n            max_uttr_num: maximum number of utterances contained in the context\n            max_uttr_len: maximum token number of every utterance and response\n        '''", "\n", "self", ".", "max_uttr_num", "=", "max_uttr_num", "\n", "self", ".", "max_uttr_len", "=", "max_uttr_len", "\n", "self", ".", "text_processor", "=", "Text_Processor", "(", "word2id_path", ",", "max_uttr_num", ",", "max_uttr_len", ")", "\n", "\n", "self", ".", "id_response_text_dict", "=", "{", "}", "\n", "self", ".", "index_response_text_list", "=", "[", "]", "\n", "with", "open", "(", "train_response_index_path", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "i", ":", "\n", "            ", "lines", "=", "i", ".", "readlines", "(", ")", "\n", "data_num", "=", "len", "(", "lines", ")", "\n", "for", "idx", "in", "range", "(", "data_num", ")", ":", "\n", "                ", "one_response", "=", "lines", "[", "idx", "]", ".", "strip", "(", "'\\n'", ")", "\n", "self", ".", "id_response_text_dict", "[", "idx", "]", "=", "one_response", "\n", "self", ".", "index_response_text_list", ".", "append", "(", "one_response", ")", "\n", "", "", "self", ".", "index_size", "=", "len", "(", "self", ".", "id_response_text_dict", ")", "\n", "print", "(", "'Size of the response index is %d'", "%", "self", ".", "index_size", ")", "\n", "self", ".", "all_response_id_list", ",", "self", ".", "all_response_seg_list", "=", "load_all_response_id_list", "(", "self", ".", "id_response_text_dict", ",", "self", ".", "text_processor", ")", "\n", "assert", "len", "(", "self", ".", "all_response_id_list", ")", "==", "self", ".", "index_size", "\n", "self", ".", "index_idx_list", "=", "[", "num", "for", "num", "in", "range", "(", "self", ".", "index_size", ")", "]", "\n", "self", ".", "index_response_idx_list", "=", "[", "num", "for", "num", "in", "range", "(", "len", "(", "self", ".", "id_response_text_dict", ")", ")", "]", "\n", "\n", "self", ".", "train_context_id_list", ",", "self", ".", "train_context_seg_list", "=", "[", "]", ",", "[", "]", "\n", "print", "(", "'Start loading training context...'", ")", "\n", "with", "open", "(", "train_context_path", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "i", ":", "\n", "            ", "lines", "=", "i", ".", "readlines", "(", ")", "\n", "p", "=", "progressbar", ".", "ProgressBar", "(", "len", "(", "lines", ")", ")", "\n", "p", ".", "start", "(", ")", "\n", "data_idx", "=", "0", "\n", "for", "l", "in", "lines", ":", "\n", "                ", "context_text", "=", "l", ".", "strip", "(", "'\\n'", ")", "\n", "one_context_id_list", ",", "one_context_seg_list", "=", "self", ".", "text_processor", ".", "process_context_id", "(", "context_text", ")", "\n", "self", ".", "train_context_id_list", ".", "append", "(", "one_context_id_list", ")", "\n", "self", ".", "train_context_seg_list", ".", "append", "(", "one_context_seg_list", ")", "\n", "p", ".", "update", "(", "data_idx", "+", "1", ")", "\n", "data_idx", "+=", "1", "\n", "", "p", ".", "finish", "(", ")", "\n", "\n", "", "self", ".", "train_true_response_id_list", ",", "self", ".", "train_true_response_seg_id_list", "=", "[", "]", ",", "[", "]", "\n", "self", ".", "train_true_response_index_list", "=", "[", "]", "\n", "print", "(", "'Start loading training true response...'", ")", "\n", "with", "open", "(", "train_true_response_id_path", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "i", ":", "\n", "            ", "lines", "=", "i", ".", "readlines", "(", ")", "\n", "p", "=", "progressbar", ".", "ProgressBar", "(", "len", "(", "lines", ")", ")", "\n", "p", ".", "start", "(", ")", "\n", "data_idx", "=", "0", "\n", "for", "l", "in", "lines", ":", "\n", "                ", "one_response_idx", "=", "int", "(", "l", ".", "strip", "(", "'\\n'", ")", ")", "\n", "self", ".", "train_true_response_index_list", ".", "append", "(", "one_response_idx", ")", "\n", "one_response_id_list", "=", "self", ".", "all_response_id_list", "[", "one_response_idx", "]", "\n", "one_response_seg_id_list", "=", "self", ".", "all_response_seg_list", "[", "one_response_idx", "]", "\n", "self", ".", "train_true_response_id_list", ".", "append", "(", "one_response_id_list", ")", "\n", "self", ".", "train_true_response_seg_id_list", ".", "append", "(", "one_response_seg_id_list", ")", "\n", "p", ".", "update", "(", "data_idx", "+", "1", ")", "\n", "data_idx", "+=", "1", "\n", "", "p", ".", "finish", "(", ")", "\n", "", "assert", "len", "(", "self", ".", "train_context_id_list", ")", "==", "len", "(", "self", ".", "train_true_response_id_list", ")", "\n", "self", ".", "train_num", "=", "len", "(", "self", ".", "train_context_id_list", ")", "\n", "\n", "self", ".", "negative_mode", "=", "negative_mode", "\n", "if", "negative_mode", "==", "'random_search'", ":", "\n", "            ", "print", "(", "'Do not use Instance-Level Curriculum Learning. Just Random Search.'", ")", "\n", "pass", "\n", "", "elif", "negative_mode", "==", "'mips_search'", ":", "\n", "            ", "print", "(", "'Use Instance-Level Curriculum Learning.'", ")", "\n", "self", ".", "cutoff_threshold", "=", "mips_config", "[", "'cutoff_threshold'", "]", "\n", "self", ".", "negative_selection_k", "=", "mips_config", "[", "'negative_selection_k'", "]", "\n", "print", "(", "'Loading context vectors...'", ")", "\n", "self", ".", "train_context_vec", "=", "load_pickle_file", "(", "train_context_vec_file", ")", "\n", "assert", "len", "(", "self", ".", "train_context_vec", ")", "==", "self", ".", "train_num", "\n", "print", "(", "'Loading response index vectors...'", ")", "\n", "self", ".", "index_response_vec", "=", "load_pickle_file", "(", "all_response_vec_file", ")", "\n", "assert", "len", "(", "self", ".", "index_response_vec", ")", "==", "len", "(", "self", ".", "index_response_text_list", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Wrong negative mode!!!'", ")", "\n", "\n", "", "self", ".", "dev_context_id_list", ",", "self", ".", "dev_context_seg_id_list", ",", "self", ".", "dev_candi_response_id_list", ",", "self", ".", "dev_candi_response_seg_id_list", ",", "self", ".", "dev_candi_response_label_list", "=", "self", ".", "load_dev_data", "(", "dev_path", ")", "\n", "self", ".", "dev_num", "=", "len", "(", "self", ".", "dev_context_id_list", ")", "\n", "\n", "print", "(", "'train number is %d, dev number is %d'", "%", "(", "self", ".", "train_num", ",", "self", ".", "dev_num", ")", ")", "\n", "self", ".", "train_idx_list", "=", "[", "j", "for", "j", "in", "range", "(", "self", ".", "train_num", ")", "]", "\n", "self", ".", "dev_idx_list", "=", "[", "j", "for", "j", "in", "range", "(", "self", ".", "dev_num", ")", "]", "\n", "self", ".", "dev_current_idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.dataloader.Data.select_response": [[121, 154], ["torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor.size", "torch.FloatTensor.size", "torch.FloatTensor.size", "torch.FloatTensor.size", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "candi_scores.masked_fill.masked_fill.masked_fill", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "batch_top_indexs.cpu().tolist.cpu().tolist.cpu().tolist", "range", "torch.unsqueeze.size", "torch.unsqueeze.size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "candi_scores.masked_fill.masked_fill.size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "float", "result_index.append", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "batch_top_indexs.cpu().tolist.cpu().tolist.cpu", "one_res.append"], "methods", ["None"], ["", "def", "select_response", "(", "self", ",", "context_vec", ",", "true_response_vec", ",", "candidate_response_vec", ",", "\n", "candidate_response_index", ",", "cutoff_threshold", ",", "top_k", ")", ":", "\n", "        ", "'''\n            context_vec: bsz x embed_dim\n            true_response_vec: bsz x embed_dim\n            candidate_response_vec: bsz x candi_num x embed_dim\n            candidate_response_index: bsz x candi_num\n        '''", "\n", "context_vec", "=", "torch", ".", "FloatTensor", "(", "context_vec", ")", "\n", "true_response_vec", "=", "torch", ".", "FloatTensor", "(", "true_response_vec", ")", "\n", "candidate_response_vec", "=", "torch", ".", "FloatTensor", "(", "candidate_response_vec", ")", "\n", "bsz", ",", "embed_dim", "=", "context_vec", ".", "size", "(", ")", "\n", "_", ",", "candi_num", ",", "_", "=", "candidate_response_vec", ".", "size", "(", ")", "\n", "true_scores", "=", "torch", ".", "sum", "(", "context_vec", "*", "true_response_vec", ",", "dim", "=", "-", "1", ")", ".", "view", "(", "bsz", ",", "1", ")", "\n", "x", "=", "torch", ".", "unsqueeze", "(", "context_vec", ",", "1", ")", "\n", "assert", "x", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "1", ",", "embed_dim", "]", ")", "\n", "y", "=", "candidate_response_vec", ".", "transpose", "(", "1", ",", "2", ")", "\n", "candi_scores", "=", "torch", ".", "matmul", "(", "x", ",", "y", ")", ".", "squeeze", "(", "1", ")", "\n", "assert", "candi_scores", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "candi_num", "]", ")", "\n", "score_threshold", "=", "cutoff_threshold", "*", "true_scores", "# do not allow too high score", "\n", "candi_scores", "=", "candi_scores", "-", "score_threshold", "\n", "candi_scores", "=", "candi_scores", ".", "masked_fill", "(", "candi_scores", ">", "0", ",", "float", "(", "'-inf'", ")", ")", "# mask out the high score part", "\n", "batch_top_scores", ",", "batch_top_indexs", "=", "torch", ".", "topk", "(", "candi_scores", ",", "k", "=", "top_k", ",", "dim", "=", "1", ")", "\n", "batch_top_indexs", "=", "batch_top_indexs", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "result_index", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "bsz", ")", ":", "\n", "            ", "one_select_index", "=", "batch_top_indexs", "[", "k", "]", "\n", "one_candi_index", "=", "candidate_response_index", "[", "k", "]", "\n", "one_res", "=", "[", "]", "\n", "for", "one_id", "in", "one_select_index", ":", "\n", "                ", "one_res", ".", "append", "(", "one_candi_index", "[", "one_id", "]", ")", "\n", "", "result_index", ".", "append", "(", "one_res", ")", "\n", "", "return", "result_index", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.dataloader.Data.select_top_k_response": [[155, 171], ["dataloader.Data.select_response", "batch_candi_response_vec.append", "numpy.array", "len"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Data.select_response"], ["", "def", "select_top_k_response", "(", "self", ",", "context_index_list", ",", "true_response_index_list", ",", "candi_response_index_list", ",", "top_k", ")", ":", "\n", "        ", "'''\n            context_index_list: bsz\n            true_response_index_list: bsz\n            candi_response_index_list: bsz x candi_num\n        '''", "\n", "batch_context_vec", "=", "[", "self", ".", "train_context_vec", "[", "one_id", "]", "for", "one_id", "in", "context_index_list", "]", "\n", "batch_true_response_vec", "=", "[", "self", ".", "index_response_vec", "[", "one_id", "]", "for", "one_id", "in", "true_response_index_list", "]", "\n", "batch_candi_response_vec", "=", "[", "]", "\n", "for", "index_list", "in", "candi_response_index_list", ":", "\n", "            ", "one_candi_response_vec", "=", "[", "self", ".", "index_response_vec", "[", "one_id", "]", "for", "one_id", "in", "index_list", "]", "\n", "batch_candi_response_vec", ".", "append", "(", "one_candi_response_vec", ")", "\n", "", "batch_select_response_index", "=", "self", ".", "select_response", "(", "batch_context_vec", ",", "batch_true_response_vec", ",", "batch_candi_response_vec", ",", "\n", "candi_response_index_list", ",", "self", ".", "cutoff_threshold", ",", "top_k", ")", "\n", "assert", "np", ".", "array", "(", "batch_select_response_index", ")", ".", "shape", "==", "(", "len", "(", "context_index_list", ")", ",", "top_k", ")", "\n", "return", "batch_select_response_index", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.dataloader.Data.get_train_next_batch": [[172, 244], ["random.sample", "dataloader.Data.text_processor.process_batch_result", "list_of_batch_token_id_inp.append", "list_of_batch_speaker_seg_id_inp.append", "list_of_batch_uttr_seg_id_inp.append", "range", "batch_context_id_list.append", "batch_context_seg_id_list.append", "batch_true_response_id_list.append", "batch_true_response_seg_id_list.append", "batch_true_response_index_list.append", "dataloader.Data.append", "len", "len", "range", "dataloader.Data.text_processor.process_batch_result", "list_of_batch_token_id_inp.append", "list_of_batch_speaker_seg_id_inp.append", "list_of_batch_uttr_seg_id_inp.append", "random.sample", "dataloader.Data.select_top_k_response", "Exception", "one_batch_neg_response_id_list.append", "one_batch_neg_response_seg_id_list.append", "random.sample", "Exception", "random.sample", "random.sample", "Exception"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.process_batch_result", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.process_batch_result", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Data.select_top_k_response"], ["", "def", "get_train_next_batch", "(", "self", ",", "batch_size", ",", "neg_num", ")", ":", "\n", "        ", "batch_idx_list", "=", "random", ".", "sample", "(", "self", ".", "train_idx_list", ",", "batch_size", ")", "\n", "batch_context_id_list", ",", "batch_context_seg_id_list", "=", "[", "]", ",", "[", "]", "\n", "batch_true_response_id_list", ",", "batch_true_response_seg_id_list", "=", "[", "]", ",", "[", "]", "\n", "batch_true_response_index_list", "=", "[", "]", "\n", "batch_sample_response_index_list", "=", "[", "]", "\n", "for", "idx", "in", "batch_idx_list", ":", "\n", "            ", "one_context_id_list", ",", "one_context_seg_id_list", "=", "self", ".", "train_context_id_list", "[", "idx", "]", ",", "self", ".", "train_context_seg_list", "[", "idx", "]", "\n", "batch_context_id_list", ".", "append", "(", "one_context_id_list", ")", "\n", "batch_context_seg_id_list", ".", "append", "(", "one_context_seg_id_list", ")", "\n", "\n", "one_true_response_id_list", ",", "one_true_response_seg_id_list", "=", "self", ".", "train_true_response_id_list", "[", "idx", "]", ",", "self", ".", "train_true_response_seg_id_list", "[", "idx", "]", "\n", "batch_true_response_id_list", ".", "append", "(", "one_true_response_id_list", ")", "\n", "batch_true_response_seg_id_list", ".", "append", "(", "one_true_response_seg_id_list", ")", "\n", "\n", "one_true_response_index", "=", "self", ".", "train_true_response_index_list", "[", "idx", "]", "\n", "batch_true_response_index_list", ".", "append", "(", "one_true_response_index", ")", "\n", "\n", "if", "self", ".", "negative_mode", "==", "'random_search'", ":", "\n", "                ", "random_idx_list", "=", "random", ".", "sample", "(", "self", ".", "index_idx_list", ",", "neg_num", ")", "\n", "", "elif", "self", ".", "negative_mode", "==", "'mips_search'", ":", "\n", "                ", "random_idx_list", "=", "random", ".", "sample", "(", "self", ".", "index_response_idx_list", ",", "self", ".", "negative_selection_k", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "'Wrong Search Method!!!'", ")", "\n", "\n", "", "while", "one_true_response_index", "in", "random_idx_list", ":", "\n", "                ", "if", "self", ".", "negative_mode", "==", "'random_search'", ":", "\n", "# random sampling negative cases", "\n", "                    ", "random_idx_list", "=", "random", ".", "sample", "(", "self", ".", "index_idx_list", ",", "neg_num", ")", "\n", "", "elif", "self", ".", "negative_mode", "==", "'mips_search'", ":", "\n", "                    ", "random_idx_list", "=", "random", ".", "sample", "(", "self", ".", "index_response_idx_list", ",", "self", ".", "negative_selection_k", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "'Wrong Search Method!!!'", ")", "\n", "", "", "batch_sample_response_index_list", ".", "append", "(", "random_idx_list", ")", "\n", "\n", "", "list_of_batch_token_id_inp", ",", "list_of_batch_speaker_seg_id_inp", ",", "list_of_batch_uttr_seg_id_inp", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "true_batch_token_id_list", ",", "true_batch_speaker_seg_id_list", ",", "true_batch_uttr_seg_id_list", "=", "self", ".", "text_processor", ".", "process_batch_result", "(", "batch_context_id_list", ",", "batch_context_seg_id_list", ",", "\n", "batch_true_response_id_list", ",", "batch_true_response_seg_id_list", ")", "\n", "list_of_batch_token_id_inp", ".", "append", "(", "true_batch_token_id_list", ")", "\n", "list_of_batch_speaker_seg_id_inp", ".", "append", "(", "true_batch_speaker_seg_id_list", ")", "\n", "list_of_batch_uttr_seg_id_inp", ".", "append", "(", "true_batch_uttr_seg_id_list", ")", "\n", "\n", "# instance level curriculum learning", "\n", "if", "self", ".", "negative_mode", "==", "'random_search'", ":", "\n", "            ", "pass", "\n", "", "elif", "self", ".", "negative_mode", "==", "'mips_search'", ":", "\n", "            ", "batch_context_index_list", "=", "batch_idx_list", "\n", "batch_sample_response_index_list", "=", "self", ".", "select_top_k_response", "(", "batch_context_index_list", ",", "\n", "batch_true_response_index_list", ",", "batch_sample_response_index_list", ",", "neg_num", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Wrong Search Method!!!'", ")", "\n", "\n", "# batch_sample_response_index_list: bsz x neg_num", "\n", "", "assert", "len", "(", "batch_sample_response_index_list", ")", "==", "batch_size", "\n", "assert", "len", "(", "batch_sample_response_index_list", "[", "0", "]", ")", "==", "neg_num", "\n", "for", "k", "in", "range", "(", "neg_num", ")", ":", "\n", "            ", "one_batch_neg_response_id_list", ",", "one_batch_neg_response_seg_id_list", "=", "[", "]", ",", "[", "]", "\n", "for", "j", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "one_neg_index", "=", "batch_sample_response_index_list", "[", "j", "]", "[", "k", "]", "\n", "one_neg_response_id", "=", "self", ".", "all_response_id_list", "[", "one_neg_index", "]", "\n", "one_batch_neg_response_id_list", ".", "append", "(", "one_neg_response_id", ")", "\n", "one_neg_response_seg_id", "=", "self", ".", "all_response_seg_list", "[", "one_neg_index", "]", "\n", "one_batch_neg_response_seg_id_list", ".", "append", "(", "one_neg_response_seg_id", ")", "\n", "", "neg_batch_token_id_list", ",", "neg_batch_speaker_seg_id_list", ",", "neg_batch_uttr_seg_id_list", "=", "self", ".", "text_processor", ".", "process_batch_result", "(", "batch_context_id_list", ",", "batch_context_seg_id_list", ",", "\n", "one_batch_neg_response_id_list", ",", "one_batch_neg_response_seg_id_list", ")", "\n", "list_of_batch_token_id_inp", ".", "append", "(", "neg_batch_token_id_list", ")", "\n", "list_of_batch_speaker_seg_id_inp", ".", "append", "(", "neg_batch_speaker_seg_id_list", ")", "\n", "list_of_batch_uttr_seg_id_inp", ".", "append", "(", "neg_batch_uttr_seg_id_list", ")", "\n", "", "return", "list_of_batch_token_id_inp", ",", "list_of_batch_speaker_seg_id_inp", ",", "list_of_batch_uttr_seg_id_inp", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.dataloader.Data.load_dev_data": [[245, 285], ["open", "i.readlines", "int", "print", "range", "dataloader.Data.text_processor.process_context_id", "all_context_id_list.append", "all_context_seg_id_list.append", "range", "all_candi_response_id_list.append", "all_candi_response_seg_id_list.append", "all_candi_response_label_list.append", "len", "print", "text.strip", "batch_text_list[].strip().split", "one_line.strip().split", "int", "one_candi_response_label_list.append", "dataloader.Data.text_processor.process_response_id", "one_candi_response_id_list.append", "one_candi_response_seg_id_list.append", "int", "batch_text_list[].strip", "one_line.strip"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.process_context_id", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.process_response_id"], ["", "def", "load_dev_data", "(", "self", ",", "path", ")", ":", "\n", "        ", "'''\n            each response candidate list contains 10 responses\n            each candidate response label list contains 10 labels\n        '''", "\n", "all_context_id_list", ",", "all_context_seg_id_list", "=", "[", "]", ",", "[", "]", "\n", "all_candi_response_id_list", ",", "all_candi_response_seg_id_list", "=", "[", "]", ",", "[", "]", "\n", "all_candi_response_label_list", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "i", ":", "\n", "            ", "lines", "=", "i", ".", "readlines", "(", ")", "\n", "test_data_num", "=", "int", "(", "len", "(", "lines", ")", "/", "10", ")", "\n", "print", "(", "'test data number is %d'", "%", "test_data_num", ")", "\n", "for", "i", "in", "range", "(", "test_data_num", ")", ":", "\n", "                ", "if", "i", "%", "int", "(", "test_data_num", "/", "10", ")", "==", "0", ":", "\n", "                    ", "print", "(", "'%d test instances have been loaded'", "%", "i", ")", "\n", "", "batch_text_list", "=", "lines", "[", "i", "*", "10", ":", "(", "i", "+", "1", ")", "*", "10", "]", "\n", "batch_text_list", "=", "[", "text", ".", "strip", "(", "'\\n'", ")", "for", "text", "in", "batch_text_list", "]", "\n", "one_context_text_list", "=", "batch_text_list", "[", "0", "]", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "'\\t'", ")", "[", "1", ":", "-", "1", "]", "\n", "one_context_text", "=", "'\\t'", ".", "join", "(", "one_context_text_list", ")", ".", "strip", "(", "'\\t'", ")", "\n", "one_context_id_list", ",", "one_context_seg_id_list", "=", "self", ".", "text_processor", ".", "process_context_id", "(", "one_context_text", ")", "\n", "all_context_id_list", ".", "append", "(", "one_context_id_list", ")", "\n", "all_context_seg_id_list", ".", "append", "(", "one_context_seg_id_list", ")", "\n", "\n", "start_idx", "=", "i", "*", "10", "\n", "one_candi_response_id_list", ",", "one_candi_response_seg_id_list", "=", "[", "]", ",", "[", "]", "\n", "one_candi_response_label_list", "=", "[", "]", "\n", "for", "candi_idx", "in", "range", "(", "start_idx", ",", "start_idx", "+", "10", ")", ":", "\n", "                    ", "one_line", "=", "lines", "[", "candi_idx", "]", "\n", "one_line_content_list", "=", "one_line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "'\\t'", ")", "\n", "one_candi_response_label", "=", "int", "(", "one_line_content_list", "[", "0", "]", ")", "\n", "one_candi_response_label_list", ".", "append", "(", "one_candi_response_label", ")", "\n", "one_candi_response_text", "=", "one_line_content_list", "[", "-", "1", "]", "\n", "one_rep_id", ",", "one_seg_id", "=", "self", ".", "text_processor", ".", "process_response_id", "(", "one_candi_response_text", ")", "\n", "one_candi_response_id_list", ".", "append", "(", "one_rep_id", ")", "\n", "one_candi_response_seg_id_list", ".", "append", "(", "one_seg_id", ")", "\n", "\n", "", "all_candi_response_id_list", ".", "append", "(", "one_candi_response_id_list", ")", "\n", "all_candi_response_seg_id_list", ".", "append", "(", "one_candi_response_seg_id_list", ")", "\n", "all_candi_response_label_list", ".", "append", "(", "one_candi_response_label_list", ")", "\n", "", "", "return", "all_context_id_list", ",", "all_context_seg_id_list", ",", "all_candi_response_id_list", ",", "all_candi_response_seg_id_list", ",", "all_candi_response_label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.dataloader.Data.get_next_dev_batch": [[286, 352], ["len", "range", "range", "range", "range", "dataloader.Data.text_processor.process_batch_result", "list_of_batch_token_id_inp.append", "list_of_batch_speaker_seg_id_inp.append", "list_of_batch_uttr_seg_id_inp.append", "batch_context_id_list.append", "batch_context_seg_id_list.append", "batch_candi_response_id_list.append", "batch_candi_response_seg_id_list.append", "batch_candi_response_label_list.append", "batch_context_id_list.append", "batch_context_seg_id_list.append", "batch_candi_response_id_list.append", "batch_candi_response_seg_id_list.append", "batch_candi_response_label_list.append", "one_batch_response_id_list.append", "one_batch_response_seg_id_list.append"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.process_batch_result"], ["", "def", "get_next_dev_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "'''\n            batch_context_id_list, batch_context_seg_list: bsz x context_len\n            batch_candi_response_id_list, batch_candi_response_seg_list: bsz x candi_num x response_len\n        '''", "\n", "batch_context_id_list", ",", "batch_context_seg_id_list", ",", "batch_candi_response_id_list", ",", "batch_candi_response_seg_id_list", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "batch_candi_response_label_list", "=", "[", "]", "\n", "\n", "if", "self", ".", "dev_current_idx", "+", "batch_size", "<", "self", ".", "dev_num", "-", "1", ":", "\n", "            ", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "curr_idx", "=", "self", ".", "dev_current_idx", "+", "i", "\n", "# context input", "\n", "one_context_id", "=", "self", ".", "dev_context_id_list", "[", "curr_idx", "]", "\n", "batch_context_id_list", ".", "append", "(", "one_context_id", ")", "\n", "one_context_seg_id", "=", "self", ".", "dev_context_seg_id_list", "[", "curr_idx", "]", "\n", "batch_context_seg_id_list", ".", "append", "(", "one_context_seg_id", ")", "\n", "\n", "# candidate response input", "\n", "one_candi_response_id", "=", "self", ".", "dev_candi_response_id_list", "[", "curr_idx", "]", "\n", "batch_candi_response_id_list", ".", "append", "(", "one_candi_response_id", ")", "\n", "one_candi_response_seg_id", "=", "self", ".", "dev_candi_response_seg_id_list", "[", "curr_idx", "]", "\n", "batch_candi_response_seg_id_list", ".", "append", "(", "one_candi_response_seg_id", ")", "\n", "\n", "one_candi_label", "=", "self", ".", "dev_candi_response_label_list", "[", "curr_idx", "]", "\n", "batch_candi_response_label_list", ".", "append", "(", "one_candi_label", ")", "\n", "", "self", ".", "dev_current_idx", "+=", "batch_size", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "curr_idx", "=", "self", ".", "dev_current_idx", "+", "i", "\n", "if", "curr_idx", ">", "self", ".", "dev_num", "-", "1", ":", "# \u5bf9dev_current_idx\u91cd\u65b0\u8d4b\u503c", "\n", "                    ", "curr_idx", "=", "0", "\n", "self", ".", "dev_current_idx", "=", "0", "\n", "", "else", ":", "\n", "                    ", "pass", "\n", "", "one_context_id", "=", "self", ".", "dev_context_id_list", "[", "curr_idx", "]", "\n", "batch_context_id_list", ".", "append", "(", "one_context_id", ")", "\n", "one_context_seg_id", "=", "self", ".", "dev_context_seg_id_list", "[", "curr_idx", "]", "\n", "batch_context_seg_id_list", ".", "append", "(", "one_context_seg_id", ")", "\n", "\n", "# candidate response input", "\n", "one_candi_response_id", "=", "self", ".", "dev_candi_response_id_list", "[", "curr_idx", "]", "\n", "batch_candi_response_id_list", ".", "append", "(", "one_candi_response_id", ")", "\n", "one_candi_response_seg_id", "=", "self", ".", "dev_candi_response_seg_id_list", "[", "curr_idx", "]", "\n", "batch_candi_response_seg_id_list", ".", "append", "(", "one_candi_response_seg_id", ")", "\n", "\n", "one_candi_label", "=", "self", ".", "dev_candi_response_label_list", "[", "curr_idx", "]", "\n", "batch_candi_response_label_list", ".", "append", "(", "one_candi_label", ")", "\n", "", "self", ".", "dev_current_idx", "=", "0", "\n", "\n", "", "list_of_batch_token_id_inp", ",", "list_of_batch_speaker_seg_id_inp", ",", "list_of_batch_uttr_seg_id_inp", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "candi_num", "=", "len", "(", "batch_candi_response_label_list", "[", "0", "]", ")", "\n", "for", "k", "in", "range", "(", "candi_num", ")", ":", "\n", "            ", "one_batch_response_id_list", ",", "one_batch_response_seg_id_list", "=", "[", "]", ",", "[", "]", "\n", "for", "j", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "one_response_id", "=", "batch_candi_response_id_list", "[", "j", "]", "[", "k", "]", "\n", "one_batch_response_id_list", ".", "append", "(", "one_response_id", ")", "\n", "one_response_seg_id", "=", "batch_candi_response_seg_id_list", "[", "j", "]", "[", "k", "]", "\n", "one_batch_response_seg_id_list", ".", "append", "(", "one_response_seg_id", ")", "\n", "", "batch_token_id_list", ",", "batch_speaker_seg_id_list", ",", "batch_uttr_seg_id_list", "=", "self", ".", "text_processor", ".", "process_batch_result", "(", "batch_context_id_list", ",", "batch_context_seg_id_list", ",", "\n", "one_batch_response_id_list", ",", "one_batch_response_seg_id_list", ")", "\n", "list_of_batch_token_id_inp", ".", "append", "(", "batch_token_id_list", ")", "\n", "list_of_batch_speaker_seg_id_inp", ".", "append", "(", "batch_speaker_seg_id_list", ")", "\n", "list_of_batch_uttr_seg_id_inp", ".", "append", "(", "batch_uttr_seg_id_list", ")", "\n", "", "return", "list_of_batch_token_id_inp", ",", "list_of_batch_speaker_seg_id_inp", ",", "list_of_batch_uttr_seg_id_inp", ",", "batch_candi_response_label_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.dataloader.load_pickle_file": [[9, 13], ["open", "pickle.load"], "function", ["None"], ["def", "load_pickle_file", "(", "in_f", ")", ":", "\n", "    ", "with", "open", "(", "in_f", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "data", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.dataloader.load_all_response_id_list": [[14, 29], ["print", "len", "progressbar.ProgressBar", "progressbar.ProgressBar.start", "range", "progressbar.ProgressBar.finish", "text_processor.process_response_id", "all_response_id_list.append", "all_response_seg_list.append", "progressbar.ProgressBar.update"], "function", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.text_processor.Text_Processor.process_response_id"], ["", "def", "load_all_response_id_list", "(", "id_response_dict", ",", "text_processor", ")", ":", "\n", "    ", "print", "(", "'Loading Response Index...'", ")", "\n", "all_response_id_list", "=", "[", "]", "\n", "all_response_seg_list", "=", "[", "]", "\n", "data_number", "=", "len", "(", "id_response_dict", ")", "\n", "p", "=", "progressbar", ".", "ProgressBar", "(", "data_number", ")", "\n", "p", ".", "start", "(", ")", "\n", "for", "idx", "in", "range", "(", "data_number", ")", ":", "\n", "        ", "one_response", "=", "id_response_dict", "[", "idx", "]", "\n", "one_response_id_list", ",", "one_response_seg_id_list", "=", "text_processor", ".", "process_response_id", "(", "one_response", ")", "\n", "all_response_id_list", ".", "append", "(", "one_response_id_list", ")", "\n", "all_response_seg_list", ".", "append", "(", "one_response_seg_id_list", ")", "\n", "p", ".", "update", "(", "idx", ")", "\n", "", "p", ".", "finish", "(", ")", "\n", "return", "all_response_id_list", ",", "all_response_seg_list", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.TransformerLayer.__init__": [[10, 23], ["torch.nn.Module.__init__", "transformer.MultiheadAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "transformer.TransformerLayer.reset_parameters", "transformer.MultiheadAttention", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", "=", "False", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "TransformerLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "ff_embed_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "ff_embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "attn_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "ff_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "with_external", "=", "with_external", "\n", "self", ".", "dropout", "=", "dropout", "\n", "if", "self", ".", "with_external", ":", "\n", "            ", "self", ".", "external_attn", "=", "MultiheadAttention", "(", "embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", ")", "\n", "self", ".", "external_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.TransformerLayer.reset_parameters": [[24, 29], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "fc1", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "fc2", ".", "weight", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "fc1", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "fc2", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.TransformerLayer.forward": [[30, 60], ["torch.dropout", "torch.dropout", "transformer.TransformerLayer.attn_layer_norm", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "transformer.TransformerLayer.fc2", "torch.dropout", "torch.dropout", "transformer.TransformerLayer.ff_layer_norm", "transformer.TransformerLayer.self_attn", "transformer.TransformerLayer.self_attn", "transformer.TransformerLayer.external_attn", "torch.dropout", "torch.dropout", "transformer.TransformerLayer.external_layer_norm", "transformer.TransformerLayer.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "kv", "=", "None", ",", "\n", "self_padding_mask", "=", "None", ",", "self_attn_mask", "=", "None", ",", "\n", "external_memories", "=", "None", ",", "external_padding_mask", "=", "None", ",", "\n", "need_weights", "=", "False", ")", ":", "\n", "# x: seq_len x bsz x embed_dim", "\n", "        ", "residual", "=", "x", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "x", ",", "self_attn", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "key_padding_mask", "=", "self_padding_mask", ",", "attn_mask", "=", "self_attn_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "", "else", ":", "\n", "            ", "x", ",", "self_attn", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "kv", ",", "value", "=", "kv", ",", "key_padding_mask", "=", "self_padding_mask", ",", "attn_mask", "=", "self_attn_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "attn_layer_norm", "(", "residual", "+", "x", ")", "\n", "\n", "if", "self", ".", "with_external", ":", "\n", "            ", "residual", "=", "x", "\n", "x", ",", "external_attn", "=", "self", ".", "external_attn", "(", "query", "=", "x", ",", "key", "=", "external_memories", ",", "value", "=", "external_memories", ",", "key_padding_mask", "=", "external_padding_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "external_layer_norm", "(", "residual", "+", "x", ")", "\n", "", "else", ":", "\n", "            ", "external_attn", "=", "None", "\n", "\n", "", "residual", "=", "x", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "ff_layer_norm", "(", "residual", "+", "x", ")", "\n", "\n", "return", "x", ",", "self_attn", ",", "external_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention.__init__": [[63, 78], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "transformer.MultiheadAttention.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "dropout", "=", "0.", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "MultiheadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "in_proj_weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ",", "embed_dim", ")", ")", "\n", "self", ".", "in_proj_bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ")", ")", "\n", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "weights_dropout", "=", "weights_dropout", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention.reset_parameters": [[79, 84], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "in_proj_weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "out_proj", ".", "weight", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "in_proj_bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention.forward": [[85, 161], ["query.size", "transformer.MultiheadAttention.contiguous().view().transpose", "transformer.MultiheadAttention.contiguous().view().transpose", "transformer.MultiheadAttention.contiguous().view().transpose", "transformer.MultiheadAttention.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.dropout.transpose().contiguous().view", "transformer.MultiheadAttention.out_proj", "query.data_ptr", "key.data_ptr", "value.data_ptr", "key.data_ptr", "value.data_ptr", "key.size", "value.size", "transformer.MultiheadAttention.in_proj_qkv", "transformer.MultiheadAttention.transpose", "list", "attn_weights.transpose.transpose.masked_fill", "attn_weights.transpose.transpose.view", "attn_weights.transpose.transpose.masked_fill_", "attn_weights.transpose.transpose.view", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "list", "attn_weights.transpose.transpose.view", "attn_weights.transpose.transpose.max", "attn_weights.transpose.transpose.transpose", "transformer.MultiheadAttention.in_proj_q", "transformer.MultiheadAttention.in_proj_kv", "transformer.MultiheadAttention.in_proj_q", "transformer.MultiheadAttention.in_proj_k", "transformer.MultiheadAttention.in_proj_v", "transformer.MultiheadAttention.contiguous().view", "transformer.MultiheadAttention.contiguous().view", "transformer.MultiheadAttention.contiguous().view", "attn_weights.transpose.transpose.size", "attn_mask.unsqueeze", "float", "key_padding_mask.transpose().unsqueeze().unsqueeze", "float", "torch.dropout.size", "torch.dropout.transpose().contiguous", "transformer.MultiheadAttention.contiguous", "transformer.MultiheadAttention.contiguous", "transformer.MultiheadAttention.contiguous", "key_padding_mask.transpose().unsqueeze", "torch.dropout.transpose", "key_padding_mask.transpose"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention.in_proj_qkv", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention.in_proj_kv", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention.in_proj_k", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention.in_proj_v"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "key_padding_mask", "=", "None", ",", "attn_mask", "=", "None", ",", "need_weights", "=", "False", ")", ":", "\n", "        ", "\"\"\" Input shape: Time x Batch x Channel\n            key_padding_mask: Time x batch\n            attn_mask:  tgt_len x src_len\n        \"\"\"", "\n", "qkv_same", "=", "query", ".", "data_ptr", "(", ")", "==", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "kv_same", "=", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "\n", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "key", ".", "size", "(", ")", "==", "value", ".", "size", "(", ")", "\n", "\n", "if", "qkv_same", ":", "\n", "# self-attention", "\n", "            ", "q", ",", "k", ",", "v", "=", "self", ".", "in_proj_qkv", "(", "query", ")", "\n", "", "elif", "kv_same", ":", "\n", "# encoder-decoder attention", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "k", ",", "v", "=", "self", ".", "in_proj_kv", "(", "key", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "k", "=", "self", ".", "in_proj_k", "(", "key", ")", "\n", "v", "=", "self", ".", "in_proj_v", "(", "value", ")", "\n", "", "q", "*=", "self", ".", "scaling", "\n", "\n", "\n", "q", "=", "q", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "k", "=", "k", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "v", "=", "v", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "src_len", "=", "k", ".", "size", "(", "1", ")", "\n", "# k,v: bsz*heads x src_len x dim", "\n", "# q: bsz*heads x tgt_len x dim ", "\n", "\n", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "assert", "list", "(", "attn_weights", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "]", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "masked_fill", "(", "\n", "attn_mask", ".", "unsqueeze", "(", "0", ")", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# don't attend to padding symbols", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_weights", ".", "masked_fill_", "(", "\n", "key_padding_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "\n", "", "attn_weights", "=", "F", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "self", ".", "weights_dropout", ":", "\n", "            ", "attn_weights", "=", "F", ".", "dropout", "(", "attn_weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "attn", "=", "torch", ".", "bmm", "(", "attn_weights", ",", "v", ")", "\n", "if", "not", "self", ".", "weights_dropout", ":", "\n", "            ", "attn", "=", "F", ".", "dropout", "(", "attn", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "assert", "list", "(", "attn", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", "]", "\n", "\n", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "attn", "=", "self", ".", "out_proj", "(", "attn", ")", "\n", "\n", "if", "need_weights", ":", "\n", "# maximum attention weight over heads ", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "attn_weights", ",", "_", "=", "attn_weights", ".", "max", "(", "dim", "=", "1", ")", "\n", "attn_weights", "=", "attn_weights", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "attn_weights", "=", "None", "\n", "\n", "", "return", "attn", ",", "(", "attn_weights", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention.in_proj_qkv": [[162, 164], ["transformer.MultiheadAttention._in_proj().chunk", "transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_qkv", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ")", ".", "chunk", "(", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention.in_proj_kv": [[165, 167], ["transformer.MultiheadAttention._in_proj().chunk", "transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_kv", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention.in_proj_q": [[168, 170], ["transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_q", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ",", "end", "=", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention.in_proj_k": [[171, 173], ["transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_k", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ",", "end", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention.in_proj_v": [[174, 176], ["transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_v", "(", "self", ",", "value", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "value", ",", "start", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.MultiheadAttention._in_proj": [[177, 184], ["torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "_in_proj", "(", "self", ",", "input", ",", "start", "=", "0", ",", "end", "=", "None", ")", ":", "\n", "        ", "weight", "=", "self", ".", "in_proj_weight", "\n", "bias", "=", "self", ".", "in_proj_bias", "\n", "weight", "=", "weight", "[", "start", ":", "end", ",", ":", "]", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "bias", "=", "bias", "[", "start", ":", "end", "]", "\n", "", "return", "F", ".", "linear", "(", "input", ",", "weight", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.SelfAttentionMask.__init__": [[198, 202], ["torch.nn.Module.__init__", "transformer.SelfAttentionMask.get_mask"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.SelfAttentionMask.get_mask"], ["    ", "def", "__init__", "(", "self", ",", "init_size", "=", "100", ",", "device", "=", "0", ")", ":", "\n", "        ", "super", "(", "SelfAttentionMask", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weights", "=", "SelfAttentionMask", ".", "get_mask", "(", "init_size", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.SelfAttentionMask.get_mask": [[203, 207], ["torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_mask", "(", "size", ")", ":", "\n", "        ", "weights", "=", "torch", ".", "triu", "(", "torch", ".", "ones", "(", "(", "size", ",", "size", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ",", "1", ")", "\n", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.SelfAttentionMask.forward": [[208, 213], ["transformer.SelfAttentionMask.weights[].cuda().detach", "transformer.SelfAttentionMask.get_mask", "transformer.SelfAttentionMask.weights.size", "transformer.SelfAttentionMask.weights[].cuda"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.SelfAttentionMask.get_mask"], ["", "def", "forward", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "self", ".", "weights", "is", "None", "or", "size", ">", "self", ".", "weights", ".", "size", "(", "0", ")", ":", "\n", "            ", "self", ".", "weights", "=", "SelfAttentionMask", ".", "get_mask", "(", "size", ")", "\n", "", "res", "=", "self", ".", "weights", "[", ":", "size", ",", ":", "size", "]", ".", "cuda", "(", "self", ".", "device", ")", ".", "detach", "(", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.LearnedPositionalEmbedding.__init__": [[217, 221], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "transformer.LearnedPositionalEmbedding.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.Embedding", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.Embedding", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.LearnedPositionalEmbedding.reset_parameters"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "init_size", "=", "1024", ")", ":", "\n", "        ", "super", "(", "LearnedPositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weights", "=", "nn", ".", "Embedding", "(", "init_size", ",", "embedding_dim", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.LearnedPositionalEmbedding.reset_parameters": [[222, 224], ["torch.nn.init.normal_", "torch.nn.init.normal_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "weights", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.LearnedPositionalEmbedding.forward": [[225, 233], ["input.size", "transformer.LearnedPositionalEmbedding.weights().unsqueeze().expand", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "positions.cuda.cuda.cuda", "input.get_device", "transformer.LearnedPositionalEmbedding.weights().unsqueeze", "transformer.LearnedPositionalEmbedding.weights"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "offset", "=", "0", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [seq_len x bsz].\"\"\"", "\n", "seq_len", ",", "bsz", "=", "input", ".", "size", "(", ")", "\n", "positions", "=", "(", "offset", "+", "torch", ".", "arange", "(", "seq_len", ")", ")", "\n", "if", "input", ".", "is_cuda", ":", "\n", "            ", "positions", "=", "positions", ".", "cuda", "(", "input", ".", "get_device", "(", ")", ")", "\n", "", "res", "=", "self", ".", "weights", "(", "positions", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.SinusoidalPositionalEmbedding.__init__": [[237, 245], ["torch.nn.Module.__init__", "transformer.SinusoidalPositionalEmbedding.get_embedding"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.SinusoidalPositionalEmbedding.get_embedding"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "init_size", "=", "1024", ",", "device", "=", "0", ")", ":", "\n", "        ", "super", "(", "SinusoidalPositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "init_size", ",", "\n", "embedding_dim", "\n", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.SinusoidalPositionalEmbedding.get_embedding": [[246, 260], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "math.log", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_embedding", "(", "num_embeddings", ",", "embedding_dim", ")", ":", "\n", "        ", "\"\"\"Build sinusoidal embeddings.\n        This matches the implementation in tensor2tensor, but differs slightly\n        from the description in Section 3.5 of \"Attention Is All You Need\".\n        \"\"\"", "\n", "half_dim", "=", "embedding_dim", "//", "2", "\n", "emb", "=", "math", ".", "log", "(", "10000", ")", "/", "(", "half_dim", "-", "1", ")", "\n", "emb", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "half_dim", ",", "dtype", "=", "torch", ".", "float", ")", "*", "-", "emb", ")", "\n", "emb", "=", "torch", ".", "arange", "(", "num_embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "1", ")", "*", "emb", ".", "unsqueeze", "(", "0", ")", "\n", "emb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "emb", ")", ",", "torch", ".", "cos", "(", "emb", ")", "]", ",", "dim", "=", "1", ")", ".", "view", "(", "num_embeddings", ",", "-", "1", ")", "\n", "if", "embedding_dim", "%", "2", "==", "1", ":", "\n", "            ", "emb", "=", "torch", ".", "cat", "(", "[", "emb", ",", "torch", ".", "zeros", "(", "num_embeddings", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.SinusoidalPositionalEmbedding.forward": [[261, 278], ["input.size", "transformer.SinusoidalPositionalEmbedding.get_embedding", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().expand().cuda().detach", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().expand().detach", "transformer.SinusoidalPositionalEmbedding.weights.size", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().expand().cuda", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().expand", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().expand", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze", "transformer.SinusoidalPositionalEmbedding.weights.index_select", "transformer.SinusoidalPositionalEmbedding.weights.index_select"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.SinusoidalPositionalEmbedding.get_embedding"], ["", "def", "forward", "(", "self", ",", "input", ",", "offset", "=", "0", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [seq_len x bsz].\"\"\"", "\n", "seq_len", ",", "bsz", "=", "input", ".", "size", "(", ")", "\n", "mx_position", "=", "seq_len", "+", "offset", "\n", "if", "self", ".", "weights", "is", "None", "or", "mx_position", ">", "self", ".", "weights", ".", "size", "(", "0", ")", ":", "\n", "# recompute/expand embeddings if needed", "\n", "            ", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "mx_position", ",", "\n", "self", ".", "embedding_dim", ",", "\n", ")", "\n", "\n", "", "positions", "=", "offset", "+", "torch", ".", "arange", "(", "seq_len", ")", "\n", "if", "input", ".", "is_cuda", ":", "\n", "            ", "res", "=", "self", ".", "weights", ".", "index_select", "(", "0", ",", "positions", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", ".", "cuda", "(", "self", ".", "device", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "            ", "res", "=", "self", ".", "weights", ".", "index_select", "(", "0", ",", "positions", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", ".", "detach", "(", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.Embedding": [[186, 191], ["torch.nn.Embedding", "torch.nn.init.normal_", "torch.nn.init.constant_"], "function", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.Seg_Embedding": [[192, 196], ["torch.nn.Embedding", "torch.nn.init.normal_"], "function", ["home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.Embedding"], ["", "def", "Seg_Embedding", "(", "num_embeddings", ",", "embedding_dim", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "embedding_dim", "**", "-", "0.5", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertConfig.__init__": [[69, 124], ["isinstance", "json.loads.items", "isinstance", "open", "json.loads", "ValueError", "reader.read"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", ",", "\n", "hidden_size", "=", "768", ",", "\n", "num_hidden_layers", "=", "12", ",", "\n", "num_attention_heads", "=", "12", ",", "\n", "intermediate_size", "=", "3072", ",", "\n", "hidden_act", "=", "\"gelu\"", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "type_vocab_size", "=", "2", ",", "\n", "initializer_range", "=", "0.02", ")", ":", "\n", "        ", "\"\"\"Constructs BertConfig.\n\n        Args:\n            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `BertModel`.\n            hidden_size: Size of the encoder layers and the pooler layer.\n            num_hidden_layers: Number of hidden layers in the Transformer encoder.\n            num_attention_heads: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n                layer in the Transformer encoder.\n            hidden_act: The non-linear activation function (function or string) in the\n                encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.\n            hidden_dropout_prob: The dropout probabilitiy for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            attention_probs_dropout_prob: The dropout ratio for the attention\n                probabilities.\n            max_position_embeddings: The maximum sequence length that this model might\n                ever be used with. Typically set this to something large just in case\n                (e.g., 512 or 1024 or 2048).\n            type_vocab_size: The vocabulary size of the `token_type_ids` passed into\n                `BertModel`.\n            initializer_range: The sttdev of the truncated_normal_initializer for\n                initializing all weight matrices.\n        \"\"\"", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_attention_heads", "=", "num_attention_heads", "\n", "self", ".", "hidden_act", "=", "hidden_act", "\n", "self", ".", "intermediate_size", "=", "intermediate_size", "\n", "self", ".", "hidden_dropout_prob", "=", "hidden_dropout_prob", "\n", "self", ".", "attention_probs_dropout_prob", "=", "attention_probs_dropout_prob", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "type_vocab_size", "=", "type_vocab_size", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertConfig.from_dict": [[126, 133], ["modeling.BertConfig", "json_object.items"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "BertConfig", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertConfig.from_json_file": [[134, 140], ["cls.from_dict", "open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertConfig.from_dict"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertConfig.__repr__": [[141, 143], ["str", "modeling.BertConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertConfig.to_dict": [[144, 148], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertConfig.to_json_string": [[149, 152], ["json.dumps", "modeling.BertConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertEmbeddings.__init__": [[175, 185], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.Embedding", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.Embedding", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.Embedding"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertEmbeddings.forward": [[186, 201], ["input_ids.size", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "modeling.BertEmbeddings.word_embeddings", "modeling.BertEmbeddings.position_embeddings", "modeling.BertEmbeddings.token_type_embeddings", "modeling.BertEmbeddings.LayerNorm", "modeling.BertEmbeddings.dropout", "torch.zeros_like", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ")", ":", "\n", "        ", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "", "words_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "words_embeddings", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertEmbeddings.work": [[202, 217], ["input_ids.size", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "modeling.BertEmbeddings.word_embeddings", "modeling.BertEmbeddings.position_embeddings", "modeling.BertEmbeddings.token_type_embeddings", "modeling.BertEmbeddings.LayerNorm", "torch.zeros_like", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["None"], ["", "def", "work", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ")", ":", "\n", "        ", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "", "words_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "words_embeddings", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "#embeddings = self.dropout(embeddings)", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertSelfAttention.__init__": [[221, 236], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "ValueError"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", ")", "\n", "", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores": [[237, 241], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertSelfAttention.forward": [[242, 269], ["modeling.BertSelfAttention.query", "modeling.BertSelfAttention.key", "modeling.BertSelfAttention.value", "modeling.BertSelfAttention.transpose_for_scores", "modeling.BertSelfAttention.transpose_for_scores", "modeling.BertSelfAttention.transpose_for_scores", "torch.matmul", "modeling.BertSelfAttention.dropout", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "modeling.BertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "return", "context_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertSelfAttention.work": [[270, 297], ["modeling.BertSelfAttention.query", "modeling.BertSelfAttention.key", "modeling.BertSelfAttention.value", "modeling.BertSelfAttention.transpose_for_scores", "modeling.BertSelfAttention.transpose_for_scores", "modeling.BertSelfAttention.transpose_for_scores", "torch.matmul", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "modeling.BertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores"], ["", "def", "work", "(", "self", ",", "hidden_states", ",", "attention_mask", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "#attention_probs = self.dropout(attention_probs)", "\n", "\n", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "return", "context_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertSelfOutput.__init__": [[300, 305], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertSelfOutput.forward": [[306, 311], ["modeling.BertSelfOutput.dense", "modeling.BertSelfOutput.dropout", "modeling.BertSelfOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertSelfOutput.work": [[312, 317], ["modeling.BertSelfOutput.dense", "modeling.BertSelfOutput.LayerNorm"], "methods", ["None"], ["", "def", "work", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "#hidden_states = self.dropout(hidden_states)", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertAttention.__init__": [[319, 323], ["torch.nn.Module.__init__", "modeling.BertSelfAttention", "modeling.BertSelfOutput"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertAttention.forward": [[324, 328], ["modeling.BertAttention.self", "modeling.BertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_tensor", ",", "attention_mask", ")", ":", "\n", "        ", "self_output", "=", "self", ".", "self", "(", "input_tensor", ",", "attention_mask", ")", "\n", "attention_output", "=", "self", ".", "output", "(", "self_output", ",", "input_tensor", ")", "\n", "return", "attention_output", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertAttention.work": [[329, 333], ["modeling.BertAttention.self.work", "modeling.BertAttention.output.work"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertModel.work", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertModel.work"], ["", "def", "work", "(", "self", ",", "input_tensor", ",", "attention_mask", ")", ":", "\n", "        ", "self_output", "=", "self", ".", "self", ".", "work", "(", "input_tensor", ",", "attention_mask", ")", "\n", "attention_output", "=", "self", ".", "output", ".", "work", "(", "self_output", ",", "input_tensor", ")", "\n", "return", "attention_output", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertIntermediate.__init__": [[336, 341], ["torch.nn.Module.__init__", "torch.nn.Linear", "isinstance"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertIntermediate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "else", "config", ".", "hidden_act", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertIntermediate.forward": [[342, 346], ["modeling.BertIntermediate.dense", "modeling.BertIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertOutput.__init__": [[349, 354], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertOutput.forward": [[355, 360], ["modeling.BertOutput.dense", "modeling.BertOutput.dropout", "modeling.BertOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertOutput.work": [[361, 366], ["modeling.BertOutput.dense", "modeling.BertOutput.LayerNorm"], "methods", ["None"], ["", "def", "work", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "#hidden_states = self.dropout(hidden_states)", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertLayer.__init__": [[369, 374], ["torch.nn.Module.__init__", "modeling.BertAttention", "modeling.BertIntermediate", "modeling.BertOutput"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "BertAttention", "(", "config", ")", "\n", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "BertOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertLayer.forward": [[375, 380], ["modeling.BertLayer.attention", "modeling.BertLayer.intermediate", "modeling.BertLayer.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ")", ":", "\n", "        ", "attention_output", "=", "self", ".", "attention", "(", "hidden_states", ",", "attention_mask", ")", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "return", "layer_output", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertLayer.work": [[381, 386], ["modeling.BertLayer.attention.work", "modeling.BertLayer.intermediate", "modeling.BertLayer.output.work"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertModel.work", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertModel.work"], ["", "def", "work", "(", "self", ",", "hidden_states", ",", "attention_mask", ")", ":", "\n", "        ", "attention_output", "=", "self", ".", "attention", ".", "work", "(", "hidden_states", ",", "attention_mask", ")", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", ".", "work", "(", "intermediate_output", ",", "attention_output", ")", "\n", "return", "layer_output", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertEncoder.__init__": [[389, 393], ["torch.nn.Module.__init__", "modeling.BertLayer", "torch.nn.ModuleList", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layer", "=", "BertLayer", "(", "config", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "layer", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertEncoder.forward": [[394, 403], ["layer_module", "all_encoder_layers.append", "all_encoder_layers.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "True", ")", ":", "\n", "        ", "all_encoder_layers", "=", "[", "]", "\n", "for", "layer_module", "in", "self", ".", "layer", ":", "\n", "            ", "hidden_states", "=", "layer_module", "(", "hidden_states", ",", "attention_mask", ")", "\n", "if", "output_all_encoded_layers", ":", "\n", "                ", "all_encoder_layers", ".", "append", "(", "hidden_states", ")", "\n", "", "", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "all_encoder_layers", ".", "append", "(", "hidden_states", ")", "\n", "", "return", "all_encoder_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertEncoder.work": [[404, 413], ["layer_module.work", "all_encoder_layers.append", "all_encoder_layers.append"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertModel.work"], ["", "def", "work", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "True", ")", ":", "\n", "        ", "all_encoder_layers", "=", "[", "]", "\n", "for", "layer_module", "in", "self", ".", "layer", ":", "\n", "            ", "hidden_states", "=", "layer_module", ".", "work", "(", "hidden_states", ",", "attention_mask", ")", "\n", "if", "output_all_encoded_layers", ":", "\n", "                ", "all_encoder_layers", ".", "append", "(", "hidden_states", ")", "\n", "", "", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "all_encoder_layers", ".", "append", "(", "hidden_states", ")", "\n", "", "return", "all_encoder_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertPooler.__init__": [[416, 420], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPooler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertPooler.forward": [[421, 428], ["modeling.BertPooler.dense", "modeling.BertPooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertPredictionHeadTransform.__init__": [[431, 437], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "isinstance"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPredictionHeadTransform", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "transform_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "else", "config", ".", "hidden_act", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertPredictionHeadTransform.forward": [[438, 443], ["modeling.BertPredictionHeadTransform.dense", "modeling.BertPredictionHeadTransform.transform_act_fn", "modeling.BertPredictionHeadTransform.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "transform_act_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertLMPredictionHead.__init__": [[446, 457], ["torch.nn.Module.__init__", "modeling.BertPredictionHeadTransform", "torch.nn.Linear", "torch.nn.Parameter", "bert_model_embedding_weights.size", "bert_model_embedding_weights.size", "torch.zeros", "bert_model_embedding_weights.size"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertLMPredictionHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "BertPredictionHeadTransform", "(", "config", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "bert_model_embedding_weights", ".", "size", "(", "1", ")", ",", "\n", "bert_model_embedding_weights", ".", "size", "(", "0", ")", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "decoder", ".", "weight", "=", "bert_model_embedding_weights", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "bert_model_embedding_weights", ".", "size", "(", "0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertLMPredictionHead.forward": [[458, 462], ["modeling.BertLMPredictionHead.transform", "modeling.BertLMPredictionHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transform", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "decoder", "(", "hidden_states", ")", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertOnlyMLMHead.__init__": [[465, 468], ["torch.nn.Module.__init__", "modeling.BertLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertOnlyMLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ",", "bert_model_embedding_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertOnlyMLMHead.forward": [[469, 472], ["modeling.BertOnlyMLMHead.predictions"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertOnlyNSPHead.__init__": [[475, 478], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOnlyNSPHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertOnlyNSPHead.forward": [[479, 482], ["modeling.BertOnlyNSPHead.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pooled_output", ")", ":", "\n", "        ", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertPreTrainingHeads.__init__": [[485, 489], ["torch.nn.Module.__init__", "modeling.BertLMPredictionHead", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertPreTrainingHeads", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ",", "bert_model_embedding_weights", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertPreTrainingHeads.forward": [[490, 494], ["modeling.BertPreTrainingHeads.predictions", "modeling.BertPreTrainingHeads.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ",", "pooled_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.PreTrainedBertModel.__init__": [[500, 510], ["torch.nn.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "PreTrainedBertModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "BertConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `BertConfig`. \"", "\n", "\"To create a model from a Google pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", ")", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.PreTrainedBertModel.init_bert_weights": [[511, 523], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.normal_", "module.weight.data.normal_"], "methods", ["None"], ["", "def", "init_bert_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "BertLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.PreTrainedBertModel.from_pretrained": [[524, 629], ["os.path.isdir", "os.path.join", "modeling.BertConfig.from_json_file", "logger.info", "cls", "torch.load.keys", "zip", "getattr", "torch.load.copy", "modeling.PreTrainedBertModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertConfig.from_json_file"], ["", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name", ",", "state_dict", "=", "None", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a PreTrainedBertModel from a pre-trained model file or a pytorch state dict.\n        Download and cache the pre-trained model file if needed.\n\n        Params:\n            pretrained_model_name: either:\n                - a str with the name of a pre-trained model to load selected in the list of:\n                    . `bert-base-uncased`\n                    . `bert-large-uncased`\n                    . `bert-base-cased`\n                    . `bert-base-multilingual`\n                    . `bert-base-chinese`\n                - a path or url to a pretrained model archive containing:\n                    . `bert_config.json` a configuration file for the model\n                    . `pytorch_model.bin` a PyTorch dump of a BertForPreTraining instance\n            cache_dir: an optional path to a folder in which the pre-trained models will be cached.\n            state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of Google pre-trained models\n            *inputs, **kwargs: additional input for the specific Bert class\n                (ex: num_labels for BertForSequenceClassification)\n        \"\"\"", "\n", "if", "pretrained_model_name", "in", "PRETRAINED_MODEL_ARCHIVE_MAP", ":", "\n", "            ", "archive_file", "=", "PRETRAINED_MODEL_ARCHIVE_MAP", "[", "pretrained_model_name", "]", "\n", "", "else", ":", "\n", "            ", "archive_file", "=", "pretrained_model_name", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading archive file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading archive file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "", "tempdir", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "resolved_archive_file", ")", ":", "\n", "            ", "serialization_dir", "=", "resolved_archive_file", "\n", "", "else", ":", "\n", "# Extract archive to temp dir", "\n", "            ", "tempdir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "logger", ".", "info", "(", "\"extracting archive file {} to temp dir {}\"", ".", "format", "(", "\n", "resolved_archive_file", ",", "tempdir", ")", ")", "\n", "with", "tarfile", ".", "open", "(", "resolved_archive_file", ",", "'r:gz'", ")", "as", "archive", ":", "\n", "                ", "archive", ".", "extractall", "(", "tempdir", ")", "\n", "", "serialization_dir", "=", "tempdir", "\n", "# Load config", "\n", "", "config_file", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "CONFIG_NAME", ")", "\n", "config", "=", "BertConfig", ".", "from_json_file", "(", "config_file", ")", "\n", "logger", ".", "info", "(", "\"Model config {}\"", ".", "format", "(", "config", ")", ")", "\n", "# Instantiate model.", "\n", "model", "=", "cls", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "state_dict", "is", "None", ":", "\n", "            ", "weights_path", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "WEIGHTS_NAME", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "weights_path", ")", "\n", "\n", "", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "new_key", "=", "None", "\n", "if", "'gamma'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "new_key", ":", "\n", "                ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "            ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "            ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                ", "if", "child", "is", "not", "None", ":", "\n", "                    ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "", "", "", "load", "(", "model", ",", "prefix", "=", "''", "if", "hasattr", "(", "model", ",", "'bert'", ")", "else", "'bert.'", ")", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "", "if", "tempdir", ":", "\n", "# Clean up temp dir", "\n", "            ", "shutil", ".", "rmtree", "(", "tempdir", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertModel.__init__": [[675, 681], ["modeling.PreTrainedBertModel.__init__", "modeling.BertEmbeddings", "modeling.BertEncoder", "modeling.BertPooler", "modeling.BertModel.apply"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertModel.forward": [[682, 721], ["torch.ones_like.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "modeling.BertModel.embeddings", "speaker_embeddings.masked_fill.masked_fill.masked_fill", "modeling.BertModel.encoder", "modeling.BertModel.pooler", "torch.ones_like", "torch.zeros_like", "speaker_embedding_input.unsqueeze().eq", "float", "speaker_embeddings.masked_fill.masked_fill.size", "modeling.BertModel.size", "torch.ones_like.unsqueeze", "next", "speaker_embedding_input.unsqueeze", "modeling.BertModel.parameters"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "speaker_embeddings", ",", "speaker_embedding_input", ",", "\n", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "output_all_encoded_layers", "=", "True", ")", ":", "\n", "        ", "'''\n            speaker_embeddings: bsz x seq_len x embed_dim\n            speaker_embedding_input: bsz x seq_len\n        '''", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones_like", "(", "input_ids", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids", ",", "token_type_ids", ")", "\n", "speaker_embeddings", "=", "speaker_embeddings", ".", "masked_fill", "(", "speaker_embedding_input", ".", "unsqueeze", "(", "-", "1", ")", ".", "eq", "(", "2", ")", ",", "float", "(", "0.0", ")", ")", "\n", "assert", "speaker_embeddings", ".", "size", "(", ")", "==", "embedding_output", ".", "size", "(", ")", "\n", "embedding_output", "=", "embedding_output", "+", "speaker_embeddings", "\n", "\n", "encoded_layers", "=", "self", ".", "encoder", "(", "embedding_output", ",", "\n", "extended_attention_mask", ",", "\n", "output_all_encoded_layers", "=", "output_all_encoded_layers", ")", "\n", "sequence_output", "=", "encoded_layers", "[", "-", "1", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "encoded_layers", "=", "encoded_layers", "[", "-", "1", "]", "\n", "", "return", "encoded_layers", ",", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertModel.work": [[722, 757], ["torch.ones_like.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "modeling.BertModel.embeddings.work", "speaker_embeddings.masked_fill.masked_fill.masked_fill", "modeling.BertModel.encoder.work", "modeling.BertModel.pooler", "torch.ones_like", "torch.zeros_like", "speaker_embedding_input.unsqueeze().eq", "float", "speaker_embeddings.masked_fill.masked_fill.size", "modeling.BertModel.size", "torch.ones_like.unsqueeze", "next", "speaker_embedding_input.unsqueeze", "modeling.BertModel.parameters"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertModel.work", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertModel.work"], ["", "def", "work", "(", "self", ",", "input_ids", ",", "speaker_embeddings", ",", "speaker_embedding_input", ",", "\n", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "output_all_encoded_layers", "=", "True", ")", ":", "\n", "        ", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones_like", "(", "input_ids", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "embedding_output", "=", "self", ".", "embeddings", ".", "work", "(", "input_ids", ",", "token_type_ids", ")", "\n", "speaker_embeddings", "=", "speaker_embeddings", ".", "masked_fill", "(", "speaker_embedding_input", ".", "unsqueeze", "(", "-", "1", ")", ".", "eq", "(", "2", ")", ",", "float", "(", "0.0", ")", ")", "\n", "assert", "speaker_embeddings", ".", "size", "(", ")", "==", "embedding_output", ".", "size", "(", ")", "\n", "embedding_output", "=", "embedding_output", "+", "speaker_embeddings", "\n", "\n", "encoded_layers", "=", "self", ".", "encoder", ".", "work", "(", "embedding_output", ",", "\n", "extended_attention_mask", ",", "\n", "output_all_encoded_layers", "=", "output_all_encoded_layers", ")", "\n", "sequence_output", "=", "encoded_layers", "[", "-", "1", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "encoded_layers", "=", "encoded_layers", "[", "-", "1", "]", "\n", "", "return", "encoded_layers", ",", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertForPreTraining.__init__": [[808, 813], ["modeling.PreTrainedBertModel.__init__", "modeling.BertModel", "modeling.BertPreTrainingHeads", "modeling.BertForPreTraining.apply"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForPreTraining", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertPreTrainingHeads", "(", "config", ",", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertForPreTraining.forward": [[814, 827], ["modeling.BertForPreTraining.bert", "modeling.BertForPreTraining.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "prediction_scores.view", "masked_lm_labels.view", "seq_relationship_score.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ",", "next_sentence_label", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "prediction_scores", ",", "seq_relationship_score", "=", "self", ".", "cls", "(", "sequence_output", ",", "pooled_output", ")", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", "and", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "total_loss", "=", "masked_lm_loss", "+", "next_sentence_loss", "\n", "return", "total_loss", "\n", "", "else", ":", "\n", "            ", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertForMaskedLM.__init__": [[871, 876], ["modeling.PreTrainedBertModel.__init__", "modeling.BertModel", "modeling.BertOnlyMLMHead", "modeling.BertForMaskedLM.apply"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyMLMHead", "(", "config", ",", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertForMaskedLM.forward": [[877, 888], ["modeling.BertForMaskedLM.bert", "modeling.BertForMaskedLM.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForMaskedLM.view", "masked_lm_labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "prediction_scores", "=", "self", ".", "cls", "(", "sequence_output", ")", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "masked_lm_loss", "\n", "", "else", ":", "\n", "            ", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertForNextSentencePrediction.__init__": [[933, 938], ["modeling.PreTrainedBertModel.__init__", "modeling.BertModel", "modeling.BertOnlyNSPHead", "modeling.BertForNextSentencePrediction.apply"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForNextSentencePrediction", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyNSPHead", "(", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertForNextSentencePrediction.forward": [[939, 950], ["modeling.BertForNextSentencePrediction.bert", "modeling.BertForNextSentencePrediction.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForNextSentencePrediction.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "next_sentence_label", "=", "None", ")", ":", "\n", "        ", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "seq_relationship_score", "=", "self", ".", "cls", "(", "pooled_output", ")", "\n", "\n", "if", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "next_sentence_loss", "\n", "", "else", ":", "\n", "            ", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertForSequenceClassification.__init__": [[997, 1004], ["modeling.PreTrainedBertModel.__init__", "modeling.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling.BertForSequenceClassification.apply"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "num_labels", "=", "2", ")", ":", "\n", "        ", "super", "(", "BertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_labels", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertForSequenceClassification.forward": [[1005, 1016], ["modeling.BertForSequenceClassification.bert", "modeling.BertForSequenceClassification.dropout", "modeling.BertForSequenceClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "loss", "\n", "", "else", ":", "\n", "            ", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertForMultipleChoice.__init__": [[1062, 1069], ["modeling.PreTrainedBertModel.__init__", "modeling.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling.BertForMultipleChoice.apply"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "num_choices", "=", "2", ")", ":", "\n", "        ", "super", "(", "BertForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_choices", "=", "num_choices", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertForMultipleChoice.forward": [[1070, 1085], ["input_ids.view", "token_type_ids.view", "attention_mask.view", "modeling.BertForMultipleChoice.bert", "modeling.BertForMultipleChoice.dropout", "modeling.BertForMultipleChoice.classifier", "modeling.BertForMultipleChoice.view", "input_ids.size", "token_type_ids.size", "attention_mask.size", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss."], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "\n", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "flat_input_ids", ",", "flat_token_type_ids", ",", "flat_attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_choices", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "return", "loss", "\n", "", "else", ":", "\n", "            ", "return", "reshaped_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertForTokenClassification.__init__": [[1132, 1139], ["modeling.PreTrainedBertModel.__init__", "modeling.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling.BertForTokenClassification.apply"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "num_labels", "=", "2", ")", ":", "\n", "        ", "super", "(", "BertForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_labels", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertForTokenClassification.forward": [[1140, 1151], ["modeling.BertForTokenClassification.bert", "modeling.BertForTokenClassification.dropout", "modeling.BertForTokenClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForTokenClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "loss", "\n", "", "else", ":", "\n", "            ", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertForQuestionAnswering.__init__": [[1208, 1215], ["modeling.PreTrainedBertModel.__init__", "modeling.BertModel", "torch.nn.Linear", "modeling.BertForQuestionAnswering.apply"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "# TODO check with Google if it's normal there is no dropout on the token classifier of SQuAD in the TF version", "\n", "# self.dropout = nn.Dropout(config.hidden_dropout_prob)", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertForQuestionAnswering.forward": [[1216, 1241], ["modeling.BertForQuestionAnswering.bert", "modeling.BertForQuestionAnswering.qa_outputs", "modeling.BertForQuestionAnswering.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "return", "total_loss", "\n", "", "else", ":", "\n", "            ", "return", "start_logits", ",", "end_logits", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.gelu": [[51, 57], ["torch.erf", "math.sqrt"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\"Implementation of the gelu activation function.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n    \"\"\"", "\n", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.swish": [[59, 61], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.convert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch": [[30, 88], ["os.path.abspath", "os.path.abspath", "print", "tensorflow.train.list_variables", "modeling.BertConfig.from_json_file", "print", "modeling.BertForPreTraining", "zip", "print", "torch.save", "print", "tensorflow.train.load_variable", "names.append", "arrays.append", "name.split.split", "any", "print", "torch.from_numpy", "modeling.BertForPreTraining.state_dict", "str", "print", "re.fullmatch", "getattr", "re.split", "getattr", "len", "int", "numpy.transpose", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.modeling.BertConfig.from_json_file"], ["def", "convert_tf_checkpoint_to_pytorch", "(", "tf_checkpoint_path", ",", "bert_config_file", ",", "pytorch_dump_path", ")", ":", "\n", "    ", "config_path", "=", "os", ".", "path", ".", "abspath", "(", "bert_config_file", ")", "\n", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "print", "(", "\"Converting TensorFlow checkpoint from {} with config at {}\"", ".", "format", "(", "tf_path", ",", "config_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "print", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ")", "\n", "\n", "# Initialise PyTorch model", "\n", "", "config", "=", "BertConfig", ".", "from_json_file", "(", "bert_config_file", ")", "\n", "print", "(", "\"Building PyTorch model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "model", "=", "BertForPreTraining", "(", "config", ")", "\n", "\n", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", ".", "split", "(", "'/'", ")", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "any", "(", "n", "in", "[", "\"adam_v\"", ",", "\"adam_m\"", "]", "for", "n", "in", "name", ")", ":", "\n", "            ", "print", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r'[A-Za-z]+_\\d+'", ",", "m_name", ")", ":", "\n", "                ", "l", "=", "re", ".", "split", "(", "r'_(\\d+)'", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "l", "=", "[", "m_name", "]", "\n", "", "if", "l", "[", "0", "]", "==", "'kernel'", "or", "l", "[", "0", "]", "==", "'gamma'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'output_bias'", "or", "l", "[", "0", "]", "==", "'beta'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'bias'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'output_weights'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "else", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "", "if", "len", "(", "l", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "if", "m_name", "[", "-", "11", ":", "]", "==", "'_embeddings'", ":", "\n", "            ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "m_name", "==", "'kernel'", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "print", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "\n", "# Save pytorch-model", "\n", "", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_dump_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.optimization.BertAdam.__init__": [[59, 78], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "required", ",", "warmup", "=", "-", "1", ",", "t_total", "=", "-", "1", ",", "schedule", "=", "'warmup_linear'", ",", "\n", "b1", "=", "0.9", ",", "b2", "=", "0.999", ",", "e", "=", "1e-6", ",", "weight_decay", "=", "0.01", ",", "\n", "max_grad_norm", "=", "1.0", ")", ":", "\n", "        ", "if", "lr", "is", "not", "required", "and", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "schedule", "not", "in", "SCHEDULES", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid schedule parameter: {}\"", ".", "format", "(", "schedule", ")", ")", "\n", "", "if", "not", "0.0", "<=", "warmup", "<", "1.0", "and", "not", "warmup", "==", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\"", ".", "format", "(", "warmup", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b1", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b1 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b1", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b2", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b2 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b2", ")", ")", "\n", "", "if", "not", "e", ">=", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {} - should be >= 0.0\"", ".", "format", "(", "e", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "schedule", "=", "schedule", ",", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "\n", "b1", "=", "b1", ",", "b2", "=", "b2", ",", "e", "=", "e", ",", "weight_decay", "=", "weight_decay", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "super", "(", "BertAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.optimization.BertAdam.get_lr": [[79, 93], ["lr.append", "len", "schedule_fct"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "lr", "=", "[", "]", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "return", "[", "0", "]", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "", "lr", ".", "append", "(", "lr_scheduled", ")", "\n", "", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.optimization.BertAdam.step": [[94, 163], ["closure", "next_m.mul_().add_", "next_v.mul_().addcmul_", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.nn.utils.clip_grad_norm_", "next_m.mul_", "next_v.mul_", "next_v.sqrt", "schedule_fct"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'next_m'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'next_v'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "next_m", ",", "next_v", "=", "state", "[", "'next_m'", "]", ",", "state", "[", "'next_v'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'b1'", "]", ",", "group", "[", "'b2'", "]", "\n", "\n", "# Add grad clipping", "\n", "if", "group", "[", "'max_grad_norm'", "]", ">", "0", ":", "\n", "                    ", "clip_grad_norm_", "(", "p", ",", "group", "[", "'max_grad_norm'", "]", ")", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "# In-place operations to update the averages at the same time", "\n", "", "next_m", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "next_v", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "update", "=", "next_m", "/", "(", "next_v", ".", "sqrt", "(", ")", "+", "group", "[", "'e'", "]", ")", "\n", "\n", "# Just adding the square of the weights to the loss function is *not*", "\n", "# the correct way of using L2 regularization/weight decay with Adam,", "\n", "# since that will interact with the m and v parameters in strange ways.", "\n", "#", "\n", "# Instead we want to decay the weights in a manner that doesn't interact", "\n", "# with the m/v parameters. This is equivalent to adding the square", "\n", "# of the weights to the loss with plain (non-momentum) SGD.", "\n", "if", "group", "[", "'weight_decay'", "]", ">", "0.0", ":", "\n", "                    ", "update", "+=", "group", "[", "'weight_decay'", "]", "*", "p", ".", "data", "\n", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "\n", "", "update_with_lr", "=", "lr_scheduled", "*", "update", "\n", "p", ".", "data", ".", "add_", "(", "-", "update_with_lr", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# step_size = lr_scheduled * math.sqrt(bias_correction2) / bias_correction1", "\n", "# No bias correction", "\n", "# bias_correction1 = 1 - beta1 ** state['step']", "\n", "# bias_correction2 = 1 - beta2 ** state['step']", "\n", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.optimization.warmup_cosine": [[23, 27], ["torch.cos"], "function", ["None"], ["def", "warmup_cosine", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "0.5", "*", "(", "1.0", "+", "torch", ".", "cos", "(", "math", ".", "pi", "*", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.optimization.warmup_constant": [[28, 32], ["None"], "function", ["None"], ["", "def", "warmup_constant", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.optimization.warmup_linear": [[33, 37], ["None"], "function", ["None"], ["", "def", "warmup_linear", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "1.0", "-", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.url_to_filename": [[30, 46], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["None"], ["def", "url_to_filename", "(", "url", ":", "str", ",", "etag", ":", "str", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "'utf-8'", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "'utf-8'", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "'.'", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.filename_to_url": [[48, 72], ["isinstance", "os.path.join", "str", "os.path.exists", "FileNotFoundError", "os.path.exists", "FileNotFoundError", "open", "json.load"], "function", ["None"], ["", "def", "filename_to_url", "(", "filename", ":", "str", ",", "cache_dir", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", "->", "Tuple", "[", "str", ",", "str", "]", ":", "\n", "    ", "\"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``FileNotFoundError`` if `filename` or its stored metadata do not exist.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_PRETRAINED_BERT_CACHE", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "\"file {} not found\"", ".", "format", "(", "cache_path", ")", ")", "\n", "\n", "", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "meta_path", ")", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "\"file {} not found\"", ".", "format", "(", "meta_path", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_path", ")", "as", "meta_file", ":", "\n", "        ", "metadata", "=", "json", ".", "load", "(", "meta_file", ")", "\n", "", "url", "=", "metadata", "[", "'url'", "]", "\n", "etag", "=", "metadata", "[", "'etag'", "]", "\n", "\n", "return", "url", ",", "etag", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.cached_path": [[74, 102], ["isinstance", "isinstance", "urllib.parse.urlparse", "str", "str", "file_utils.get_from_cache", "os.path.exists", "FileNotFoundError", "ValueError"], "function", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.get_from_cache"], ["", "def", "cached_path", "(", "url_or_filename", ":", "Union", "[", "str", ",", "Path", "]", ",", "cache_dir", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_PRETRAINED_BERT_CACHE", "\n", "", "if", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "\n", "if", "parsed", ".", "scheme", "in", "(", "'http'", ",", "'https'", ",", "'s3'", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "return", "get_from_cache", "(", "url_or_filename", ",", "cache_dir", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n", "# File, and it exists.", "\n", "        ", "return", "url_or_filename", "\n", "", "elif", "parsed", ".", "scheme", "==", "''", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "FileNotFoundError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.split_s3_path": [[104, 115], ["urllib.parse.urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["", "", "def", "split_s3_path", "(", "url", ":", "str", ")", "->", "Tuple", "[", "str", ",", "str", "]", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "s3_path", "=", "s3_path", "[", "1", ":", "]", "\n", "", "return", "bucket_name", ",", "s3_path", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.s3_request": [[117, 134], ["functools.wraps", "func", "int", "FileNotFoundError"], "function", ["None"], ["", "def", "s3_request", "(", "func", ":", "Callable", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ":", "str", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "FileNotFoundError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.s3_etag": [[136, 143], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Object"], "function", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ":", "str", ")", "->", "Optional", "[", "str", "]", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n", "return", "s3_object", ".", "e_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.s3_get": [[145, 151], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Bucket().download_fileobj", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ":", "str", ",", "temp_file", ":", "IO", ")", "->", "None", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.http_get": [[153, 163], ["requests.get", "requests.get.headers.get", "tqdm.tqdm", "requests.get.iter_content", "tqdm.tqdm.close", "int", "tqdm.tqdm.update", "temp_file.write", "len"], "function", ["None"], ["", "def", "http_get", "(", "url", ":", "str", ",", "temp_file", ":", "IO", ")", "->", "None", ":", "\n", "    ", "req", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "content_length", "=", "req", ".", "headers", ".", "get", "(", "'Content-Length'", ")", "\n", "total", "=", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "tqdm", "(", "unit", "=", "\"B\"", ",", "total", "=", "total", ")", "\n", "for", "chunk", "in", "req", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.get_from_cache": [[165, 222], ["isinstance", "os.makedirs", "url.startswith", "file_utils.url_to_filename", "os.path.join", "str", "file_utils.s3_etag", "requests.head", "requests.head.headers.get", "os.path.exists", "IOError", "tempfile.NamedTemporaryFile", "logger.info", "url.startswith", "temp_file.flush", "temp_file.seek", "logger.info", "logger.info", "logger.info", "file_utils.s3_get", "file_utils.http_get", "open", "shutil.copyfileobj", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.url_to_filename", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.s3_etag", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.s3_get", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.http_get"], ["", "def", "get_from_cache", "(", "url", ":", "str", ",", "cache_dir", ":", "Union", "[", "str", ",", "Path", "]", "=", "None", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding dataset in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_PRETRAINED_BERT_CACHE", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "cache_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Get eTag to add to filename, if it exists.", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "        ", "etag", "=", "s3_etag", "(", "url", ")", "\n", "", "else", ":", "\n", "        ", "response", "=", "requests", ".", "head", "(", "url", ",", "allow_redirects", "=", "True", ")", "\n", "if", "response", ".", "status_code", "!=", "200", ":", "\n", "            ", "raise", "IOError", "(", "\"HEAD request failed for url {} with status code {}\"", "\n", ".", "format", "(", "url", ",", "response", ".", "status_code", ")", ")", "\n", "", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "\n", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "temp_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s not found in cache, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", ")", "\n", "\n", "# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                ", "s3_get", "(", "url", ",", "temp_file", ")", "\n", "", "else", ":", "\n", "                ", "http_get", "(", "url", ",", "temp_file", ")", "\n", "\n", "# we are copying the file before closing it, so flush to avoid truncation", "\n", "", "temp_file", ".", "flush", "(", ")", "\n", "# shutil.copyfileobj() starts at the current position, so go to the start", "\n", "temp_file", ".", "seek", "(", "0", ")", "\n", "\n", "logger", ".", "info", "(", "\"copying %s to cache at %s\"", ",", "temp_file", ".", "name", ",", "cache_path", ")", "\n", "with", "open", "(", "cache_path", ",", "'wb'", ")", "as", "cache_file", ":", "\n", "                ", "shutil", ".", "copyfileobj", "(", "temp_file", ",", "cache_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"creating metadata file for %s\"", ",", "cache_path", ")", "\n", "meta", "=", "{", "'url'", ":", "url", ",", "'etag'", ":", "etag", "}", "\n", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "with", "open", "(", "meta_path", ",", "'w'", ")", "as", "meta_file", ":", "\n", "                ", "json", ".", "dump", "(", "meta", ",", "meta_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"removing temp file %s\"", ",", "temp_file", ".", "name", ")", "\n", "\n", "", "", "return", "cache_path", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.read_set_from_file": [[224, 234], ["set", "open", "set.add", "line.rstrip"], "function", ["None"], ["", "def", "read_set_from_file", "(", "filename", ":", "str", ")", "->", "Set", "[", "str", "]", ":", "\n", "    ", "'''\n    Extract a de-duped collection (set) of text from a file.\n    Expected file format is one item per line.\n    '''", "\n", "collection", "=", "set", "(", ")", "\n", "with", "open", "(", "filename", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "file_", ":", "\n", "        ", "for", "line", "in", "file_", ":", "\n", "            ", "collection", ".", "add", "(", "line", ".", "rstrip", "(", ")", ")", "\n", "", "", "return", "collection", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.get_file_extension": [[236, 240], ["os.path.splitext", "ext.lower"], "function", ["None"], ["", "def", "get_file_extension", "(", "path", ":", "str", ",", "dot", "=", "True", ",", "lower", ":", "bool", "=", "True", ")", ":", "\n", "    ", "ext", "=", "os", ".", "path", ".", "splitext", "(", "path", ")", "[", "1", "]", "\n", "ext", "=", "ext", "if", "dot", "else", "ext", "[", "1", ":", "]", "\n", "return", "ext", ".", "lower", "(", ")", "if", "lower", "else", "ext", "\n", "", ""]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BertTokenizer.__init__": [[68, 78], ["tokenization.load_vocab", "collections.OrderedDict", "tokenization.BasicTokenizer", "tokenization.WordpieceTokenizer", "os.path.isfile", "ValueError", "tokenization.BertTokenizer.vocab.items"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.load_vocab"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "do_lower_case", "=", "True", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "isfile", "(", "vocab_file", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Can't find a vocabulary file at path '{}'. To load the vocabulary from a Google pretrained \"", "\n", "\"model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "", "self", ".", "vocab", "=", "load_vocab", "(", "vocab_file", ")", "\n", "self", ".", "ids_to_tokens", "=", "collections", ".", "OrderedDict", "(", "\n", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "self", ".", "vocab", ".", "items", "(", ")", "]", ")", "\n", "self", ".", "basic_tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ")", "\n", "self", ".", "wordpiece_tokenizer", "=", "WordpieceTokenizer", "(", "vocab", "=", "self", ".", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BertTokenizer.tokenize": [[79, 85], ["tokenization.BertTokenizer.basic_tokenizer.tokenize", "tokenization.BertTokenizer.wordpiece_tokenizer.tokenize", "split_tokens.append"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Tokenizer.tokenize", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Tokenizer.tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "split_tokens", "=", "[", "]", "\n", "for", "token", "in", "self", ".", "basic_tokenizer", ".", "tokenize", "(", "text", ")", ":", "\n", "            ", "for", "sub_token", "in", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", ":", "\n", "                ", "split_tokens", ".", "append", "(", "sub_token", ")", "\n", "", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids": [[86, 95], ["ids.append", "ids.append"], "methods", ["None"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of tokens into ids using the vocab.\"\"\"", "\n", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "try", ":", "\n", "                ", "ids", ".", "append", "(", "self", ".", "vocab", "[", "token", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "                ", "ids", ".", "append", "(", "self", ".", "vocab", "[", "'[UNK]'", "]", ")", "\n", "", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BertTokenizer.convert_ids_to_tokens": [[97, 103], ["tokens.append"], "methods", ["None"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of ids in wordpiece tokens using the vocab.\"\"\"", "\n", "tokens", "=", "[", "]", "\n", "for", "i", "in", "ids", ":", "\n", "            ", "tokens", ".", "append", "(", "self", ".", "ids_to_tokens", "[", "i", "]", ")", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained": [[104, 136], ["os.path.isdir", "cls", "os.path.join", "file_utils.cached_path", "logger.info", "logger.info", "logger.error", "PRETRAINED_VOCAB_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.file_utils.cached_path"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a PreTrainedBertModel from a pre-trained model file.\n        Download and cache the pre-trained model file if needed.\n        \"\"\"", "\n", "if", "pretrained_model_name", "in", "PRETRAINED_VOCAB_ARCHIVE_MAP", ":", "\n", "            ", "vocab_file", "=", "PRETRAINED_VOCAB_ARCHIVE_MAP", "[", "pretrained_model_name", "]", "\n", "", "else", ":", "\n", "            ", "vocab_file", "=", "pretrained_model_name", "\n", "", "if", "os", ".", "path", ".", "isdir", "(", "vocab_file", ")", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "vocab_file", ",", "VOCAB_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_vocab_file", "=", "cached_path", "(", "vocab_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_VOCAB_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "vocab_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_vocab_file", "==", "vocab_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {}\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {} from cache at {}\"", ".", "format", "(", "\n", "vocab_file", ",", "resolved_vocab_file", ")", ")", "\n", "# Instantiate tokenizer.", "\n", "", "tokenizer", "=", "cls", "(", "resolved_vocab_file", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BasicTokenizer.__init__": [[141, 148], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "do_lower_case", "=", "True", ")", ":", "\n", "        ", "\"\"\"Constructs a BasicTokenizer.\n\n        Args:\n          do_lower_case: Whether to lower case the input.\n        \"\"\"", "\n", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BasicTokenizer.tokenize": [[149, 169], ["tokenization.BasicTokenizer._clean_text", "tokenization.BasicTokenizer._tokenize_chinese_chars", "tokenization.whitespace_tokenize", "tokenization.whitespace_tokenize", "split_tokens.extend", "tokenization.BasicTokenizer.lower", "tokenization.BasicTokenizer._run_strip_accents", "tokenization.BasicTokenizer._run_split_on_punc"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BasicTokenizer._clean_text", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BasicTokenizer._tokenize_chinese_chars", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_strip_accents", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_split_on_punc"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text.\"\"\"", "\n", "text", "=", "self", ".", "_clean_text", "(", "text", ")", "\n", "# This was added on November 1st, 2018 for the multilingual and Chinese", "\n", "# models. This is also applied to the English models now, but it doesn't", "\n", "# matter since the English models were not trained on any Chinese data", "\n", "# and generally don't have any Chinese data in them (there are Chinese", "\n", "# characters in the vocabulary because Wikipedia does have some Chinese", "\n", "# words in the English Wikipedia.).", "\n", "text", "=", "self", ".", "_tokenize_chinese_chars", "(", "text", ")", "\n", "orig_tokens", "=", "whitespace_tokenize", "(", "text", ")", "\n", "split_tokens", "=", "[", "]", "\n", "for", "token", "in", "orig_tokens", ":", "\n", "            ", "if", "self", ".", "do_lower_case", ":", "\n", "                ", "token", "=", "token", ".", "lower", "(", ")", "\n", "token", "=", "self", ".", "_run_strip_accents", "(", "token", ")", "\n", "", "split_tokens", ".", "extend", "(", "self", ".", "_run_split_on_punc", "(", "token", ")", ")", "\n", "\n", "", "output_tokens", "=", "whitespace_tokenize", "(", "\" \"", ".", "join", "(", "split_tokens", ")", ")", "\n", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_strip_accents": [[170, 180], ["unicodedata.normalize", "unicodedata.category", "output.append"], "methods", ["None"], ["", "def", "_run_strip_accents", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Strips accents from a piece of text.\"\"\"", "\n", "text", "=", "unicodedata", ".", "normalize", "(", "\"NFD\"", ",", "text", ")", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Mn\"", ":", "\n", "                ", "continue", "\n", "", "output", ".", "append", "(", "char", ")", "\n", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_split_on_punc": [[181, 200], ["list", "len", "tokenization._is_punctuation", "output.append", "output[].append", "output.append"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization._is_punctuation"], ["", "def", "_run_split_on_punc", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Splits punctuation on a piece of text.\"\"\"", "\n", "chars", "=", "list", "(", "text", ")", "\n", "i", "=", "0", "\n", "start_new_word", "=", "True", "\n", "output", "=", "[", "]", "\n", "while", "i", "<", "len", "(", "chars", ")", ":", "\n", "            ", "char", "=", "chars", "[", "i", "]", "\n", "if", "_is_punctuation", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "[", "char", "]", ")", "\n", "start_new_word", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "start_new_word", ":", "\n", "                    ", "output", ".", "append", "(", "[", "]", ")", "\n", "", "start_new_word", "=", "False", "\n", "output", "[", "-", "1", "]", ".", "append", "(", "char", ")", "\n", "", "i", "+=", "1", "\n", "\n", "", "return", "[", "\"\"", ".", "join", "(", "x", ")", "for", "x", "in", "output", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BasicTokenizer._tokenize_chinese_chars": [[201, 213], ["ord", "tokenization.BasicTokenizer._is_chinese_char", "output.append", "output.append", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BasicTokenizer._is_chinese_char"], ["", "def", "_tokenize_chinese_chars", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Adds whitespace around any CJK character.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "self", ".", "_is_chinese_char", "(", "cp", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "output", ".", "append", "(", "char", ")", "\n", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BasicTokenizer._is_chinese_char": [[214, 235], ["None"], "methods", ["None"], ["", "def", "_is_chinese_char", "(", "self", ",", "cp", ")", ":", "\n", "        ", "\"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"", "\n", "# This defines a \"chinese character\" as anything in the CJK Unicode block:", "\n", "#   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)", "\n", "#", "\n", "# Note that the CJK Unicode block is NOT all Japanese and Korean characters,", "\n", "# despite its name. The modern Korean Hangul alphabet is a different block,", "\n", "# as is Japanese Hiragana and Katakana. Those alphabets are used to write", "\n", "# space-separated words, so they are not treated specially and handled", "\n", "# like the all of the other languages.", "\n", "if", "(", "(", "cp", ">=", "0x4E00", "and", "cp", "<=", "0x9FFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x3400", "and", "cp", "<=", "0x4DBF", ")", "or", "#", "\n", "(", "cp", ">=", "0x20000", "and", "cp", "<=", "0x2A6DF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2A700", "and", "cp", "<=", "0x2B73F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B740", "and", "cp", "<=", "0x2B81F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B820", "and", "cp", "<=", "0x2CEAF", ")", "or", "\n", "(", "cp", ">=", "0xF900", "and", "cp", "<=", "0xFAFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2F800", "and", "cp", "<=", "0x2FA1F", ")", ")", ":", "#", "\n", "            ", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.BasicTokenizer._clean_text": [[236, 248], ["ord", "tokenization._is_whitespace", "tokenization._is_control", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization._is_whitespace", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization._is_control"], ["", "def", "_clean_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "cp", "==", "0", "or", "cp", "==", "0xfffd", "or", "_is_control", "(", "char", ")", ":", "\n", "                ", "continue", "\n", "", "if", "_is_whitespace", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__": [[253, 257], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocab", ",", "unk_token", "=", "\"[UNK]\"", ",", "max_input_chars_per_word", "=", "100", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "unk_token", "=", "unk_token", "\n", "self", ".", "max_input_chars_per_word", "=", "max_input_chars_per_word", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.tokenize": [[258, 308], ["tokenization.whitespace_tokenize", "list", "len", "output_tokens.append", "len", "len", "sub_tokens.append", "output_tokens.append", "output_tokens.extend"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.whitespace_tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text into its word pieces.\n\n        This uses a greedy longest-match-first algorithm to perform tokenization\n        using the given vocabulary.\n\n        For example:\n          input = \"unaffable\"\n          output = [\"un\", \"##aff\", \"##able\"]\n\n        Args:\n          text: A single token or whitespace separated tokens. This should have\n            already been passed through `BasicTokenizer.\n\n        Returns:\n          A list of wordpiece tokens.\n        \"\"\"", "\n", "\n", "output_tokens", "=", "[", "]", "\n", "for", "token", "in", "whitespace_tokenize", "(", "text", ")", ":", "\n", "            ", "chars", "=", "list", "(", "token", ")", "\n", "if", "len", "(", "chars", ")", ">", "self", ".", "max_input_chars_per_word", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "continue", "\n", "\n", "", "is_bad", "=", "False", "\n", "start", "=", "0", "\n", "sub_tokens", "=", "[", "]", "\n", "while", "start", "<", "len", "(", "chars", ")", ":", "\n", "                ", "end", "=", "len", "(", "chars", ")", "\n", "cur_substr", "=", "None", "\n", "while", "start", "<", "end", ":", "\n", "                    ", "substr", "=", "\"\"", ".", "join", "(", "chars", "[", "start", ":", "end", "]", ")", "\n", "if", "start", ">", "0", ":", "\n", "                        ", "substr", "=", "\"##\"", "+", "substr", "\n", "", "if", "substr", "in", "self", ".", "vocab", ":", "\n", "                        ", "cur_substr", "=", "substr", "\n", "break", "\n", "", "end", "-=", "1", "\n", "", "if", "cur_substr", "is", "None", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "sub_tokens", ".", "append", "(", "cur_substr", ")", "\n", "start", "=", "end", "\n", "\n", "", "if", "is_bad", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "", "else", ":", "\n", "                ", "output_tokens", ".", "extend", "(", "sub_tokens", ")", "\n", "", "", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.load_vocab": [[42, 55], ["collections.OrderedDict", "open", "reader.readline", "token.strip.strip"], "function", ["None"], ["def", "load_vocab", "(", "vocab_file", ")", ":", "\n", "    ", "\"\"\"Loads a vocabulary file into a dictionary.\"\"\"", "\n", "vocab", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "index", "=", "0", "\n", "with", "open", "(", "vocab_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "token", "=", "reader", ".", "readline", "(", ")", "\n", "if", "not", "token", ":", "\n", "                ", "break", "\n", "", "token", "=", "token", ".", "strip", "(", ")", "\n", "vocab", "[", "token", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization.whitespace_tokenize": [[57, 64], ["text.strip.strip", "text.strip.split"], "function", ["None"], ["", "def", "whitespace_tokenize", "(", "text", ")", ":", "\n", "    ", "\"\"\"Runs basic whitespace cleaning and splitting on a peice of text.\"\"\"", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "        ", "return", "[", "]", "\n", "", "tokens", "=", "text", ".", "split", "(", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization._is_whitespace": [[310, 320], ["unicodedata.category"], "function", ["None"], ["", "", "def", "_is_whitespace", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a whitespace character.\"\"\"", "\n", "# \\t, \\n, and \\r are technically contorl characters but we treat them", "\n", "# as whitespace since they are generally considered as such.", "\n", "if", "char", "==", "\" \"", "or", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Zs\"", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization._is_control": [[322, 332], ["unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_control", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a control character.\"\"\"", "\n", "# These are technically control characters but we count them as whitespace", "\n", "# characters.", "\n", "if", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "False", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"C\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.tokenization._is_punctuation": [[334, 348], ["ord", "unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_punctuation", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a punctuation character.\"\"\"", "\n", "cp", "=", "ord", "(", "char", ")", "\n", "# We treat all non-letter/number ASCII as punctuation.", "\n", "# Characters such as \"^\", \"$\", and \"`\" are not in the Unicode", "\n", "# Punctuation class but we treat them as punctuation anyways, for", "\n", "# consistency.", "\n", "if", "(", "(", "cp", ">=", "33", "and", "cp", "<=", "47", ")", "or", "(", "cp", ">=", "58", "and", "cp", "<=", "64", ")", "or", "\n", "(", "cp", ">=", "91", "and", "cp", "<=", "96", ")", "or", "(", "cp", ">=", "123", "and", "cp", "<=", "126", ")", ")", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"P\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "", ""]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_Rn_k": [[11, 22], ["range", "len", "float", "numpy.asarray", "np.asarray.argsort"], "function", ["None"], ["def", "compute_Rn_k", "(", "scores", ",", "labels", ",", "n", "=", "2", ",", "k", "=", "1", ")", ":", "\n", "    ", "total", "=", "0", "\n", "correct", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "        ", "if", "labels", "[", "i", "]", "==", "1", ":", "\n", "            ", "total", "=", "total", "+", "1", "\n", "sublist", "=", "np", ".", "asarray", "(", "scores", "[", "i", ":", "i", "+", "n", "]", ")", "\n", "index", "=", "sublist", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "[", "0", ":", "k", "]", "\n", "if", "scores", "[", "i", "]", "in", "sublist", "[", "index", "]", ":", "\n", "                ", "correct", "=", "correct", "+", "1", "\n", "", "", "", "return", "float", "(", "correct", ")", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_R2_1": [[23, 38], ["range", "len", "range", "numpy.asarray", "float", "len", "true_response_index.append", "np.asarray.argsort", "len", "numpy.intersect1d"], "function", ["None"], ["", "def", "compute_R2_1", "(", "scores", ",", "labels", ",", "n", "=", "10", ",", "k", "=", "1", ",", "m", "=", "2", ")", ":", "\n", "    ", "total", "=", "0", "\n", "correct", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "labels", ")", ",", "n", ")", ":", "\n", "        ", "total", "=", "total", "+", "1", "\n", "true_response_index", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "i", ",", "i", "+", "n", ")", ":", "\n", "            ", "if", "labels", "[", "j", "]", "==", "1", ":", "\n", "                ", "true_response_index", ".", "append", "(", "j", "-", "i", ")", "\n", "", "", "sublist", "=", "np", ".", "asarray", "(", "scores", "[", "i", ":", "i", "+", "m", "]", ")", "\n", "index", "=", "sublist", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "[", "0", ":", "k", "]", "\n", "# if len(np.intersect1d(index, true_response_index)) > 0:", "\n", "#         correct = correct + 1", "\n", "correct", "+=", "len", "(", "np", ".", "intersect1d", "(", "index", ",", "true_response_index", ")", ")", "*", "1.0", "/", "len", "(", "true_response_index", ")", "\n", "", "return", "float", "(", "correct", ")", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_R10_k": [[39, 54], ["range", "len", "range", "numpy.asarray", "float", "len", "true_response_index.append", "np.asarray.argsort", "len", "numpy.intersect1d"], "function", ["None"], ["", "def", "compute_R10_k", "(", "scores", ",", "labels", ",", "n", "=", "10", ",", "k", "=", "1", ")", ":", "\n", "    ", "total", "=", "0", "\n", "correct", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "labels", ")", ",", "n", ")", ":", "\n", "        ", "total", "=", "total", "+", "1", "\n", "true_response_index", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "i", ",", "i", "+", "n", ")", ":", "\n", "            ", "if", "labels", "[", "j", "]", "==", "1", ":", "\n", "                ", "true_response_index", ".", "append", "(", "j", "-", "i", ")", "\n", "", "", "sublist", "=", "np", ".", "asarray", "(", "scores", "[", "i", ":", "i", "+", "n", "]", ")", "\n", "index", "=", "sublist", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "[", "0", ":", "k", "]", "\n", "# if len(np.intersect1d(index, true_response_index)) > 0:", "\n", "#         correct = correct + 1", "\n", "correct", "+=", "len", "(", "np", ".", "intersect1d", "(", "index", ",", "true_response_index", ")", ")", "*", "1.0", "/", "len", "(", "true_response_index", ")", "\n", "", "return", "float", "(", "correct", ")", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_P1": [[55, 67], ["range", "len", "numpy.asarray", "float", "np.asarray.argsort"], "function", ["None"], ["", "def", "compute_P1", "(", "scores", ",", "labels", ",", "n", "=", "10", ")", ":", "\n", "    ", "'''precision at position 1'''", "\n", "total", "=", "0", "\n", "correct", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "labels", ")", ",", "n", ")", ":", "\n", "        ", "total", "=", "total", "+", "1", "\n", "sublist", "=", "np", ".", "asarray", "(", "scores", "[", "i", ":", "i", "+", "n", "]", ")", "\n", "index", "=", "sublist", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "p1", "=", "0.0", "\n", "if", "labels", "[", "i", "+", "index", "[", "0", "]", "]", "==", "1", ":", "p1", "=", "1.0", "\n", "correct", "+=", "p1", "\n", "", "return", "float", "(", "correct", ")", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_MAP": [[68, 83], ["range", "len", "numpy.asarray", "enumerate", "float", "np.asarray.argsort"], "function", ["None"], ["", "def", "compute_MAP", "(", "scores", ",", "labels", ",", "n", "=", "10", ")", ":", "\n", "    ", "total", "=", "0", "\n", "correct", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "labels", ")", ",", "n", ")", ":", "\n", "        ", "total", "=", "total", "+", "1", "\n", "sublist", "=", "np", ".", "asarray", "(", "scores", "[", "i", ":", "i", "+", "n", "]", ")", "\n", "index", "=", "sublist", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "ap", "=", "0.0", "\n", "count", "=", "0", "\n", "for", "j", ",", "ans_index", "in", "enumerate", "(", "index", ")", ":", "\n", "            ", "if", "labels", "[", "i", "+", "ans_index", "]", "==", "1", ":", "\n", "                ", "count", "+=", "1", "\n", "ap", "+=", "count", "/", "(", "j", "+", "1.0", ")", "\n", "", "", "correct", "+=", "(", "ap", "/", "count", ")", "\n", "", "return", "float", "(", "correct", ")", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_MRR": [[84, 98], ["range", "len", "numpy.asarray", "enumerate", "float", "np.asarray.argsort"], "function", ["None"], ["", "def", "compute_MRR", "(", "scores", ",", "labels", ",", "n", "=", "10", ")", ":", "\n", "    ", "total", "=", "0", "\n", "correct", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "labels", ")", ",", "n", ")", ":", "\n", "        ", "total", "=", "total", "+", "1", "\n", "sublist", "=", "np", ".", "asarray", "(", "scores", "[", "i", ":", "i", "+", "n", "]", ")", "\n", "index", "=", "sublist", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "ap", "=", "0.0", "\n", "for", "j", ",", "ans_index", "in", "enumerate", "(", "index", ")", ":", "\n", "            ", "if", "labels", "[", "i", "+", "ans_index", "]", "==", "1", ":", "\n", "                ", "ap", "+=", "1.0", "/", "(", "j", "+", "1.0", ")", "\n", "break", "\n", "", "", "correct", "+=", "ap", "\n", "", "return", "float", "(", "correct", ")", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.read_pkl_file": [[101, 108], ["time.time", "print", "open", "print", "pickle.load", "pickle.load", "time.time"], "function", ["None"], ["", "def", "read_pkl_file", "(", "filename", ",", "ed", "=", "None", ")", ":", "\n", "    ", "s_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'----------load {}----------'", ".", "format", "(", "filename", ")", ")", "\n", "with", "open", "(", "filename", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "data", "=", "pickle", ".", "load", "(", "f", ",", "encoding", "=", "ed", ")", "if", "ed", "else", "pickle", ".", "load", "(", "f", ")", "\n", "print", "(", "'----------loading finish, cost:{}sec----------'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "s_time", ")", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.inference.get_model_name": [[16, 22], ["os.listdir", "filename.startswith"], "function", ["None"], ["import", "progressbar", "\n", "\n", "def", "get_model_name", "(", "root_dir", ",", "prefix", ")", ":", "\n", "    ", "for", "filename", "in", "os", ".", "listdir", "(", "root_dir", ")", ":", "\n", "        ", "if", "filename", ".", "startswith", "(", "prefix", ")", ":", "\n", "            ", "model_name", "=", "filename", "\n", "break", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.inference.parse_config": [[24, 45], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["\n", "", "def", "transform_input", "(", "list_of_batch_inp", ",", "device", "=", "None", ",", "use_cuda", "=", "False", ")", ":", "\n", "    ", "res_list", "=", "[", "]", "\n", "for", "item", "in", "list_of_batch_inp", ":", "\n", "        ", "one_res", "=", "torch", ".", "LongTensor", "(", "item", ")", "\n", "if", "use_cuda", ":", "\n", "            ", "one_res", "=", "one_res", ".", "to", "(", "device", ")", "\n", "", "res_list", ".", "append", "(", "one_res", ")", "\n", "", "return", "res_list", "\n", "\n", "", "def", "parse_config", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# data configuration", "\n", "parser", ".", "add_argument", "(", "'--corpus_name'", ",", "type", "=", "str", ",", "help", "=", "\"The name of concerned corpus.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--train_context_path'", ",", "type", "=", "str", ",", "help", "=", "\"The file contains all training context.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--train_true_response_path'", ",", "type", "=", "str", ",", "help", "=", "\"The file contains all reference response.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--response_index_path'", ",", "type", "=", "str", ",", "help", "=", "\"The file contains all responses in the dataset.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--train_context_vec_file'", ",", "type", "=", "str", ",", "help", "=", "\"File contains context representations.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--all_response_vec_file'", ",", "type", "=", "str", ",", "help", "=", "\"File contains response representations.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_path'", ",", "type", "=", "str", ",", "help", "=", "\"Validation data path.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--bert_path'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--max_uttr_num'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "\"Maximum number of utterances in the context.\"", ")", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.inference.load_matching_model": [[46, 61], ["main_utlis.read_pkl_file", "len", "dataclass.Tokenizer", "print", "SMN", "dataclass.Tokenizer", "print", "MSN", "Exception"], "function", ["home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.read_pkl_file"], ["parser", ".", "add_argument", "(", "'--max_uttr_len'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "help", "=", "\"Maximum length of each utterance.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--negative_num'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"Number of negative samples during training.\"", ")", "\n", "# learning configuration", "\n", "#parser.add_argument('--batch_size',type=int, default=4)", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "type", "=", "int", ",", "help", "=", "'Inference batch size.'", ")", "\n", "parser", ".", "add_argument", "(", "'--ckpt_path'", ",", "type", "=", "str", ",", "help", "=", "\"Path to save the model checkpoints.\"", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "print", "(", "'Cuda is available.'", ")", "\n", "", "cuda_available", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n", "args", "=", "parse_config", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Tokenizer.__init__": [[17, 31], ["len", "print", "open", "i.readlines", "l.strip().split", "int", "l.strip"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "word2id_path", ")", ":", "\n", "        ", "self", ".", "word2id_dict", ",", "self", ".", "id2word_dict", "=", "{", "}", ",", "{", "}", "\n", "with", "open", "(", "word2id_path", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "i", ":", "\n", "            ", "lines", "=", "i", ".", "readlines", "(", ")", "\n", "for", "l", "in", "lines", ":", "\n", "                ", "content_list", "=", "l", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", ")", "\n", "token", "=", "content_list", "[", "0", "]", "\n", "idx", "=", "int", "(", "content_list", "[", "1", "]", ")", "\n", "self", ".", "word2id_dict", "[", "token", "]", "=", "idx", "\n", "self", ".", "id2word_dict", "[", "idx", "]", "=", "token", "\n", "", "", "self", ".", "vocab_size", "=", "len", "(", "self", ".", "word2id_dict", ")", "\n", "print", "(", "'vocab size is %d'", "%", "self", ".", "vocab_size", ")", "\n", "self", ".", "unk_idx", "=", "self", ".", "word2id_dict", "[", "UNK", "]", "\n", "self", ".", "padding_idx", "=", "self", ".", "word2id_dict", "[", "PAD", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Tokenizer.convert_tokens_to_ids": [[32, 40], ["res_list.append", "res_list.append"], "methods", ["None"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "token_list", ")", ":", "\n", "        ", "res_list", "=", "[", "]", "\n", "for", "token", "in", "token_list", ":", "\n", "            ", "try", ":", "\n", "                ", "res_list", ".", "append", "(", "self", ".", "word2id_dict", "[", "token", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "                ", "res_list", ".", "append", "(", "self", ".", "unk_idx", ")", "\n", "", "", "return", "res_list", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Tokenizer.convert_ids_to_tokens": [[41, 49], ["res_list.append", "res_list.append"], "methods", ["None"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "idx_list", ")", ":", "\n", "        ", "res_list", "=", "[", "]", "\n", "for", "idx", "in", "idx_list", ":", "\n", "            ", "try", ":", "\n", "                ", "res_list", ".", "append", "(", "self", ".", "id2word_dict", "[", "idx", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "                ", "res_list", ".", "append", "(", "UNK", ")", "\n", "", "", "return", "res_list", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Tokenizer.tokenize": [[50, 52], ["text.strip().strip().split", "text.strip().strip", "text.strip"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "return", "text", ".", "strip", "(", "'\\n'", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Data.__init__": [[54, 128], ["dataclass.Tokenizer", "dataclass_utlis.load_context_data", "len", "print", "print", "print", "print", "dataclass_utlis.load_dev_data", "len", "print", "open", "i.readlines", "open", "i.readlines", "progressbar.ProgressBar", "progressbar.ProgressBar.start", "range", "progressbar.ProgressBar.finish", "open", "i.readlines", "dataclass.Data.train_context_text_list.append", "len", "len", "lines[].strip", "dataclass.Data.index_response_text_list.append", "dataclass_utlis.process_text", "dataclass.Data.tokenizer.convert_tokens_to_ids", "progressbar.ProgressBar.update", "range", "int", "dataclass.Data.train_reference_response_index_list.append", "dataclass.Data.train_true_response_id_list.append", "numpy.array", "print", "print", "dataclass.load_pickle_file", "print", "dataclass.load_pickle_file", "Exception", "range", "range", "l.strip", "len", "l.strip", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass_utlis.load_context_data", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass_utlis.load_dev_data", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass_utlis.process_text", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.load_pickle_file", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.load_pickle_file"], ["    ", "def", "__init__", "(", "self", ",", "train_context_path", ",", "train_true_response_path", ",", "response_index_path", ",", "negative_num", ",", "\n", "dev_path", ",", "word2id_path", ",", "max_uttr_num", ",", "max_uttr_len", ",", "mips_config", ",", "negative_mode", ",", "train_context_vec_file", ",", "\n", "all_response_vec_file", ")", ":", "\n", "        ", "self", ".", "max_uttr_num", ",", "self", ".", "max_uttr_len", "=", "max_uttr_num", ",", "max_uttr_len", "\n", "self", ".", "negative_num", "=", "negative_num", "\n", "self", ".", "tokenizer", "=", "Tokenizer", "(", "word2id_path", ")", "\n", "\n", "self", ".", "train_context_id_list", "=", "load_context_data", "(", "train_context_path", ",", "self", ".", "max_uttr_num", ",", "\n", "self", ".", "max_uttr_len", ",", "self", ".", "tokenizer", ")", "\n", "self", ".", "train_context_text_list", "=", "[", "]", "\n", "with", "open", "(", "train_context_path", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "i", ":", "\n", "            ", "lines", "=", "i", ".", "readlines", "(", ")", "\n", "for", "l", "in", "lines", ":", "\n", "                ", "self", ".", "train_context_text_list", ".", "append", "(", "l", ".", "strip", "(", "'\\n'", ")", ")", "\n", "", "", "self", ".", "train_num", "=", "len", "(", "self", ".", "train_context_id_list", ")", "\n", "\n", "self", ".", "id_response_text_dict", "=", "{", "}", "\n", "self", ".", "id_response_id_dict", "=", "{", "}", "\n", "self", ".", "index_response_text_list", "=", "[", "]", "\n", "print", "(", "'Loading Response Index...'", ")", "\n", "with", "open", "(", "response_index_path", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "i", ":", "\n", "            ", "lines", "=", "i", ".", "readlines", "(", ")", "\n", "p", "=", "progressbar", ".", "ProgressBar", "(", "len", "(", "lines", ")", ")", "\n", "p", ".", "start", "(", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "lines", ")", ")", ":", "\n", "                ", "one_response_text", "=", "lines", "[", "idx", "]", ".", "strip", "(", "'\\n'", ")", "\n", "self", ".", "index_response_text_list", ".", "append", "(", "one_response_text", ")", "\n", "one_response_token_list", "=", "process_text", "(", "one_response_text", ",", "max_uttr_len", ",", "self", ".", "tokenizer", ")", "\n", "one_response_id_list", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "one_response_token_list", ")", "\n", "self", ".", "id_response_text_dict", "[", "idx", "]", "=", "one_response_text", "\n", "self", ".", "id_response_id_dict", "[", "idx", "]", "=", "one_response_id_list", "\n", "p", ".", "update", "(", "idx", "+", "1", ")", "\n", "", "p", ".", "finish", "(", ")", "\n", "", "print", "(", "'Response Index Loaded.'", ")", "\n", "self", ".", "index_response_idx_list", "=", "[", "num", "for", "num", "in", "range", "(", "len", "(", "self", ".", "id_response_text_dict", ")", ")", "]", "\n", "\n", "print", "(", "'Loading Reference Responses...'", ")", "\n", "self", ".", "train_true_response_id_list", "=", "[", "]", "\n", "self", ".", "train_reference_response_index_list", "=", "[", "]", "\n", "with", "open", "(", "train_true_response_path", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "i", ":", "\n", "            ", "lines", "=", "i", ".", "readlines", "(", ")", "\n", "for", "l", "in", "lines", ":", "\n", "                ", "one_id", "=", "int", "(", "l", ".", "strip", "(", "'\\n'", ")", ")", "\n", "self", ".", "train_reference_response_index_list", ".", "append", "(", "one_id", ")", "\n", "one_response_id_list", "=", "[", "self", ".", "id_response_id_dict", "[", "one_id", "]", "]", "\n", "self", ".", "train_true_response_id_list", ".", "append", "(", "one_response_id_list", ")", "\n", "", "", "assert", "np", ".", "array", "(", "self", ".", "train_true_response_id_list", ")", ".", "shape", "==", "(", "self", ".", "train_num", ",", "1", ",", "self", ".", "max_uttr_len", ")", "\n", "print", "(", "'Reference Responses Loaded.'", ")", "\n", "\n", "self", ".", "negative_mode", "=", "negative_mode", "\n", "if", "negative_mode", "==", "'random_search'", ":", "\n", "            ", "pass", "\n", "", "elif", "negative_mode", "==", "'mips_search'", ":", "\n", "            ", "print", "(", "'Use Instance-Level Curriculum Learning.'", ")", "\n", "self", ".", "cutoff_threshold", "=", "mips_config", "[", "'cutoff_threshold'", "]", "\n", "self", ".", "negative_selection_k", "=", "mips_config", "[", "'negative_selection_k'", "]", "\n", "print", "(", "'Loading context vectors...'", ")", "\n", "self", ".", "train_context_vec", "=", "load_pickle_file", "(", "train_context_vec_file", ")", "\n", "assert", "len", "(", "self", ".", "train_context_vec", ")", "==", "self", ".", "train_num", "\n", "print", "(", "'Loading response index vectors...'", ")", "\n", "self", ".", "index_response_vec", "=", "load_pickle_file", "(", "all_response_vec_file", ")", "\n", "assert", "len", "(", "self", ".", "index_response_vec", ")", "==", "len", "(", "self", ".", "index_response_text_list", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Wrong Negative Mode!!!'", ")", "\n", "\n", "", "self", ".", "dev_context_id_list", ",", "self", ".", "dev_candi_response_id_list", ",", "self", ".", "dev_candi_response_label_list", "=", "load_dev_data", "(", "dev_path", ",", "self", ".", "max_uttr_num", ",", "self", ".", "max_uttr_len", ",", "self", ".", "tokenizer", ")", "\n", "\n", "self", ".", "dev_num", "=", "len", "(", "self", ".", "dev_context_id_list", ")", "\n", "print", "(", "'train number is %d, dev number is %d'", "%", "(", "self", ".", "train_num", ",", "self", ".", "dev_num", ")", ")", "\n", "\n", "self", ".", "train_idx_list", "=", "[", "i", "for", "i", "in", "range", "(", "self", ".", "train_num", ")", "]", "\n", "self", ".", "dev_idx_list", "=", "[", "j", "for", "j", "in", "range", "(", "self", ".", "dev_num", ")", "]", "\n", "self", ".", "dev_current_idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Data.select_response": [[129, 162], ["torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor.size", "torch.FloatTensor.size", "torch.sum().view", "torch.unsqueeze", "torch.FloatTensor.transpose", "torch.matmul().squeeze", "candi_scores.masked_fill.masked_fill.masked_fill", "torch.topk", "batch_top_indexs.cpu().tolist.cpu().tolist.cpu().tolist", "range", "torch.unsqueeze.size", "torch.Size", "candi_scores.masked_fill.masked_fill.size", "torch.Size", "float", "result_index.append", "torch.sum", "torch.matmul", "batch_top_indexs.cpu().tolist.cpu().tolist.cpu", "one_res.append"], "methods", ["None"], ["", "def", "select_response", "(", "self", ",", "context_vec", ",", "true_response_vec", ",", "candidate_response_vec", ",", "candidate_response_index", ",", "\n", "cutoff_threshold", ",", "top_k", ")", ":", "\n", "        ", "'''\n            context_vec: bsz x embed_dim\n            true_response_vec: bsz x embed_dim\n            candidate_response_vec: bsz x candi_num x embed_dim\n            candidate_response_index: bsz x candi_num\n        '''", "\n", "context_vec", "=", "torch", ".", "FloatTensor", "(", "context_vec", ")", "\n", "true_response_vec", "=", "torch", ".", "FloatTensor", "(", "true_response_vec", ")", "\n", "candidate_response_vec", "=", "torch", ".", "FloatTensor", "(", "candidate_response_vec", ")", "\n", "bsz", ",", "embed_dim", "=", "context_vec", ".", "size", "(", ")", "\n", "_", ",", "candi_num", ",", "_", "=", "candidate_response_vec", ".", "size", "(", ")", "\n", "true_scores", "=", "torch", ".", "sum", "(", "context_vec", "*", "true_response_vec", ",", "dim", "=", "-", "1", ")", ".", "view", "(", "bsz", ",", "1", ")", "\n", "x", "=", "torch", ".", "unsqueeze", "(", "context_vec", ",", "1", ")", "\n", "assert", "x", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "1", ",", "embed_dim", "]", ")", "\n", "y", "=", "candidate_response_vec", ".", "transpose", "(", "1", ",", "2", ")", "\n", "candi_scores", "=", "torch", ".", "matmul", "(", "x", ",", "y", ")", ".", "squeeze", "(", "1", ")", "\n", "assert", "candi_scores", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "candi_num", "]", ")", "\n", "score_threshold", "=", "cutoff_threshold", "*", "true_scores", "# do not allow too high score", "\n", "candi_scores", "=", "candi_scores", "-", "score_threshold", "\n", "candi_scores", "=", "candi_scores", ".", "masked_fill", "(", "candi_scores", ">", "0", ",", "float", "(", "'-inf'", ")", ")", "# mask out the high score part", "\n", "batch_top_scores", ",", "batch_top_indexs", "=", "torch", ".", "topk", "(", "candi_scores", ",", "k", "=", "top_k", ",", "dim", "=", "1", ")", "\n", "batch_top_indexs", "=", "batch_top_indexs", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "result_index", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "bsz", ")", ":", "\n", "            ", "one_select_index", "=", "batch_top_indexs", "[", "k", "]", "\n", "one_candi_index", "=", "candidate_response_index", "[", "k", "]", "\n", "one_res", "=", "[", "]", "\n", "for", "one_id", "in", "one_select_index", ":", "\n", "                ", "one_res", ".", "append", "(", "one_candi_index", "[", "one_id", "]", ")", "\n", "", "result_index", ".", "append", "(", "one_res", ")", "\n", "", "return", "result_index", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Data.select_top_k_response": [[163, 179], ["dataclass.Data.select_response", "batch_candi_response_vec.append", "numpy.array", "len"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Data.select_response"], ["", "def", "select_top_k_response", "(", "self", ",", "context_index_list", ",", "true_response_index_list", ",", "candi_response_index_list", ",", "top_k", ")", ":", "\n", "        ", "'''\n            context_index_list: bsz\n            true_response_index_list: bsz\n            candi_response_index_list: bsz x candi_num\n        '''", "\n", "batch_context_vec", "=", "[", "self", ".", "train_context_vec", "[", "one_id", "]", "for", "one_id", "in", "context_index_list", "]", "\n", "batch_true_response_vec", "=", "[", "self", ".", "index_response_vec", "[", "one_id", "]", "for", "one_id", "in", "true_response_index_list", "]", "\n", "batch_candi_response_vec", "=", "[", "]", "\n", "for", "index_list", "in", "candi_response_index_list", ":", "\n", "            ", "one_candi_response_vec", "=", "[", "self", ".", "index_response_vec", "[", "one_id", "]", "for", "one_id", "in", "index_list", "]", "\n", "batch_candi_response_vec", ".", "append", "(", "one_candi_response_vec", ")", "\n", "", "batch_select_response_index", "=", "self", ".", "select_response", "(", "batch_context_vec", ",", "batch_true_response_vec", ",", "batch_candi_response_vec", ",", "\n", "candi_response_index_list", ",", "self", ".", "cutoff_threshold", ",", "top_k", ")", "\n", "assert", "np", ".", "array", "(", "batch_select_response_index", ")", ".", "shape", "==", "(", "len", "(", "context_index_list", ")", ",", "top_k", ")", "\n", "return", "batch_select_response_index", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Data.get_next_train_batch": [[180, 229], ["random.sample", "batch_context_id_list.append", "batch_true_response_id_list.append", "batch_true_response_index_list.append", "dataclass.Data.append", "batch_negative_response_id_list.append", "random.sample", "set", "dataclass.Data.select_top_k_response", "Exception", "numpy.array", "numpy.array", "numpy.array", "random.sample", "Exception", "random.sample", "random.sample", "Exception"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Data.select_top_k_response"], ["", "def", "get_next_train_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "batch_idx_list", "=", "random", ".", "sample", "(", "self", ".", "train_idx_list", ",", "batch_size", ")", "\n", "batch_context_id_list", ",", "batch_true_response_id_list", ",", "batch_negative_response_id_list", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "batch_sample_response_index_list", ",", "batch_true_response_index_list", "=", "[", "]", ",", "[", "]", "\n", "for", "idx", "in", "batch_idx_list", ":", "\n", "# context", "\n", "            ", "one_context_id_list", "=", "self", ".", "train_context_id_list", "[", "idx", "]", "\n", "batch_context_id_list", ".", "append", "(", "one_context_id_list", ")", "\n", "# true response", "\n", "one_true_response_id_list", "=", "self", ".", "train_true_response_id_list", "[", "idx", "]", "\n", "batch_true_response_id_list", ".", "append", "(", "one_true_response_id_list", ")", "\n", "\n", "one_true_response_index", "=", "self", ".", "train_reference_response_index_list", "[", "idx", "]", "\n", "batch_true_response_index_list", ".", "append", "(", "one_true_response_index", ")", "\n", "\n", "if", "self", ".", "negative_mode", "==", "'random_search'", ":", "\n", "# random sampling negative cases", "\n", "                ", "one_negative_sample_idx_list", "=", "random", ".", "sample", "(", "self", ".", "index_response_idx_list", ",", "self", ".", "negative_num", ")", "\n", "", "elif", "self", ".", "negative_mode", "==", "'mips_search'", ":", "\n", "                ", "one_negative_sample_idx_list", "=", "random", ".", "sample", "(", "self", ".", "index_response_idx_list", ",", "self", ".", "negative_selection_k", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "'Wrong Search Method!!!'", ")", "\n", "\n", "", "while", "one_true_response_index", "in", "set", "(", "one_negative_sample_idx_list", ")", ":", "\n", "                ", "if", "self", ".", "negative_mode", "==", "'random_search'", ":", "\n", "# random sampling negative cases", "\n", "                    ", "one_negative_sample_idx_list", "=", "random", ".", "sample", "(", "self", ".", "index_response_idx_list", ",", "self", ".", "negative_num", ")", "\n", "", "elif", "self", ".", "negative_mode", "==", "'mips_search'", ":", "\n", "                    ", "one_negative_sample_idx_list", "=", "random", ".", "sample", "(", "self", ".", "index_response_idx_list", ",", "self", ".", "negative_selection_k", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "'Wrong Search Method!!!'", ")", "\n", "", "", "batch_sample_response_index_list", ".", "append", "(", "one_negative_sample_idx_list", ")", "\n", "\n", "", "if", "self", ".", "negative_mode", "==", "'random_search'", ":", "\n", "            ", "pass", "\n", "", "elif", "self", ".", "negative_mode", "==", "'mips_search'", ":", "\n", "            ", "batch_context_index_list", "=", "batch_idx_list", "\n", "batch_sample_response_index_list", "=", "self", ".", "select_top_k_response", "(", "batch_context_index_list", ",", "batch_true_response_index_list", ",", "\n", "batch_sample_response_index_list", ",", "self", ".", "negative_num", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Wrong Search Method!!!'", ")", "\n", "\n", "", "for", "one_sample_index_list", "in", "batch_sample_response_index_list", ":", "\n", "            ", "one_sample_response_id", "=", "[", "self", ".", "id_response_id_dict", "[", "one_neg_id", "]", "for", "one_neg_id", "in", "one_sample_index_list", "]", "\n", "batch_negative_response_id_list", ".", "append", "(", "one_sample_response_id", ")", "\n", "", "assert", "np", ".", "array", "(", "batch_context_id_list", ")", ".", "shape", "==", "(", "batch_size", ",", "self", ".", "max_uttr_num", ",", "self", ".", "max_uttr_len", ")", "\n", "assert", "np", ".", "array", "(", "batch_true_response_id_list", ")", ".", "shape", "==", "(", "batch_size", ",", "1", ",", "self", ".", "max_uttr_len", ")", "\n", "assert", "np", ".", "array", "(", "batch_negative_response_id_list", ")", ".", "shape", "==", "(", "batch_size", ",", "self", ".", "negative_num", ",", "self", ".", "max_uttr_len", ")", "\n", "return", "batch_context_id_list", ",", "batch_true_response_id_list", ",", "batch_negative_response_id_list", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Data.get_next_dev_batch": [[230, 267], ["range", "range", "batch_context_list.append", "batch_candidate_response_list.append", "batch_candidate_response_label_list.append", "batch_context_list.append", "batch_candidate_response_list.append", "batch_candidate_response_label_list.append"], "methods", ["None"], ["", "def", "get_next_dev_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "'''\n            batch_context_list: bsz x uttr_num x uttr_len\n            batch_candidate_response_list: bsz x candi_num x uttr_len\n            batch_candidate_response_label_list: bsz x candi_num\n        '''", "\n", "batch_context_list", ",", "batch_candidate_response_list", ",", "batch_candidate_response_label_list", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "if", "self", ".", "dev_current_idx", "+", "batch_size", "<", "self", ".", "dev_num", "-", "1", ":", "\n", "            ", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "curr_idx", "=", "self", ".", "dev_current_idx", "+", "i", "\n", "one_context_id_list", "=", "self", ".", "dev_context_id_list", "[", "curr_idx", "]", "\n", "batch_context_list", ".", "append", "(", "one_context_id_list", ")", "\n", "\n", "one_candidate_response_id_list", "=", "self", ".", "dev_candi_response_id_list", "[", "curr_idx", "]", "\n", "batch_candidate_response_list", ".", "append", "(", "one_candidate_response_id_list", ")", "\n", "\n", "one_candidate_response_label_list", "=", "self", ".", "dev_candi_response_label_list", "[", "curr_idx", "]", "\n", "batch_candidate_response_label_list", ".", "append", "(", "one_candidate_response_label_list", ")", "\n", "", "self", ".", "dev_current_idx", "+=", "batch_size", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "curr_idx", "=", "self", ".", "dev_current_idx", "+", "i", "\n", "if", "curr_idx", ">", "self", ".", "dev_num", "-", "1", ":", "# \u5bf9dev_current_idx\u91cd\u65b0\u8d4b\u503c", "\n", "                    ", "curr_idx", "=", "0", "\n", "self", ".", "dev_current_idx", "=", "0", "\n", "", "else", ":", "\n", "                    ", "pass", "\n", "", "one_context_id_list", "=", "self", ".", "dev_context_id_list", "[", "curr_idx", "]", "\n", "batch_context_list", ".", "append", "(", "one_context_id_list", ")", "\n", "\n", "one_candidate_response_id_list", "=", "self", ".", "dev_candi_response_id_list", "[", "curr_idx", "]", "\n", "batch_candidate_response_list", ".", "append", "(", "one_candidate_response_id_list", ")", "\n", "\n", "one_candidate_response_label_list", "=", "self", ".", "dev_candi_response_label_list", "[", "curr_idx", "]", "\n", "batch_candidate_response_label_list", ".", "append", "(", "one_candidate_response_label_list", ")", "\n", "", "self", ".", "dev_current_idx", "=", "0", "\n", "", "return", "batch_context_list", ",", "batch_candidate_response_list", ",", "batch_candidate_response_label_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.load_pickle_file": [[11, 15], ["open", "pickle.load"], "function", ["None"], ["def", "load_pickle_file", "(", "in_f", ")", ":", "\n", "    ", "with", "open", "(", "in_f", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "data", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass_utlis.load_response_id_dict": [[11, 21], ["print", "open", "i.readlines", "print", "range", "len", "lines[].strip", "len", "len"], "function", ["None"], ["def", "load_response_id_dict", "(", "in_f", ")", ":", "\n", "    ", "id_response_dict", "=", "{", "}", "\n", "with", "open", "(", "in_f", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "i", ":", "\n", "        ", "lines", "=", "i", ".", "readlines", "(", ")", "\n", "print", "(", "'Size of response index is %d'", "%", "len", "(", "lines", ")", ")", "\n", "for", "one_id", "in", "range", "(", "len", "(", "lines", ")", ")", ":", "\n", "            ", "one_response", "=", "lines", "[", "one_id", "]", ".", "strip", "(", "'\\n'", ")", "\n", "id_response_dict", "[", "one_id", "]", "=", "one_response", "\n", "", "", "print", "(", "'Size of response index is %d'", "%", "len", "(", "id_response_dict", ")", ")", "\n", "return", "id_response_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass_utlis.process_text": [[23, 30], ["tokenizer.tokenize", "len", "len", "text.strip", "range"], "function", ["home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Tokenizer.tokenize"], ["", "def", "process_text", "(", "text", ",", "max_uttr_len", ",", "tokenizer", ")", ":", "\n", "#token_list = text.strip().split()", "\n", "    ", "token_list", "=", "tokenizer", ".", "tokenize", "(", "text", ".", "strip", "(", ")", ")", "[", ":", "max_uttr_len", "]", "\n", "len_diff", "=", "max_uttr_len", "-", "len", "(", "token_list", ")", "\n", "token_list", "=", "token_list", "+", "[", "PAD", "for", "_", "in", "range", "(", "len_diff", ")", "]", "\n", "assert", "len", "(", "token_list", ")", "==", "max_uttr_len", "\n", "return", "token_list", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass_utlis.process_context_text": [[31, 48], ["context_text.strip().split", "range", "dataclass_utlis.process_text", "res_list.append", "len", "res_list.append", "len", "len", "res_id_list.append", "range", "context_text.strip", "c_text.strip", "tokenizer.convert_tokens_to_ids"], "function", ["home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass_utlis.process_text", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Tokenizer.convert_tokens_to_ids"], ["", "def", "process_context_text", "(", "context_text", ",", "max_uttr_num", ",", "max_uttr_len", ",", "tokenizer", ")", ":", "\n", "    ", "padding_sen", "=", "[", "PAD", "for", "_", "in", "range", "(", "max_uttr_len", ")", "]", "\n", "context_text_list", "=", "context_text", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "context_text_list", "=", "context_text_list", "[", "-", "max_uttr_num", ":", "]", "\n", "res_list", "=", "[", "]", "\n", "for", "c_text", "in", "context_text_list", ":", "\n", "        ", "one_token_list", "=", "process_text", "(", "c_text", ".", "strip", "(", ")", ",", "max_uttr_len", ",", "tokenizer", ")", "\n", "res_list", ".", "append", "(", "one_token_list", ")", "\n", "", "len_diff", "=", "max_uttr_num", "-", "len", "(", "res_list", ")", "\n", "for", "_", "in", "range", "(", "len_diff", ")", ":", "\n", "        ", "res_list", ".", "append", "(", "padding_sen", ")", "\n", "", "assert", "len", "(", "res_list", ")", "==", "max_uttr_num", "\n", "assert", "len", "(", "res_list", "[", "0", "]", ")", "==", "max_uttr_len", "\n", "res_id_list", "=", "[", "]", "\n", "for", "one_token_list", "in", "res_list", ":", "\n", "        ", "res_id_list", ".", "append", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "one_token_list", ")", ")", "\n", "", "return", "res_id_list", "# max_uttr_num x max_uttr_len", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass_utlis.load_context_data": [[49, 67], ["open", "i.readlines", "print", "progressbar.ProgressBar", "progressbar.ProgressBar.start", "progressbar.ProgressBar.finish", "len", "l.strip().strip", "dataclass_utlis.process_context_text", "context_id_list.append", "progressbar.ProgressBar.update", "l.strip"], "function", ["home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass_utlis.process_context_text"], ["", "def", "load_context_data", "(", "in_f", ",", "max_uttr_num", ",", "max_uttr_len", ",", "tokenizer", ")", ":", "\n", "    ", "context_id_list", "=", "[", "]", "\n", "with", "open", "(", "in_f", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "i", ":", "\n", "        ", "lines", "=", "i", ".", "readlines", "(", ")", "\n", "data_idx", "=", "0", "\n", "print", "(", "'Loading Context Data...'", ")", "\n", "p", "=", "progressbar", ".", "ProgressBar", "(", "len", "(", "lines", ")", ")", "\n", "p", ".", "start", "(", ")", "\n", "for", "l", "in", "lines", ":", "\n", "#if data_idx % int(len(lines) / 5) == 0:", "\n", "#    print ('%d contexts have been loaded' % data_idx)", "\n", "            ", "one_context_text", "=", "l", ".", "strip", "(", "'\\n'", ")", ".", "strip", "(", ")", "\n", "one_context_id", "=", "process_context_text", "(", "one_context_text", ",", "max_uttr_num", ",", "max_uttr_len", ",", "tokenizer", ")", "\n", "context_id_list", ".", "append", "(", "one_context_id", ")", "\n", "p", ".", "update", "(", "data_idx", "+", "1", ")", "\n", "data_idx", "+=", "1", "\n", "", "p", ".", "finish", "(", ")", "\n", "", "return", "context_id_list", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass_utlis.load_dev_data": [[69, 110], ["open", "i.readlines", "int", "print", "print", "progressbar.ProgressBar", "progressbar.ProgressBar.start", "range", "progressbar.ProgressBar.finish", "print", "len", "progressbar.ProgressBar.update", "dataclass_utlis.process_context_text", "context_id_list.append", "range", "candi_response_id_list.append", "candi_response_label_list.append", "len", "text.strip", "batch_text_list[].strip().split", "one_line.strip().split", "int", "one_candi_response_label_list.append", "dataclass_utlis.process_text", "tokenizer.convert_tokens_to_ids", "one_candi_response_list.append", "batch_text_list[].strip", "one_line.strip"], "function", ["home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass_utlis.process_context_text", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass_utlis.process_text", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Tokenizer.convert_tokens_to_ids"], ["", "def", "load_dev_data", "(", "path", ",", "max_uttr_num", ",", "max_uttr_len", ",", "tokenizer", ")", ":", "\n", "    ", "'''\n        each response candidate list contains 10 responses\n        each candidate response label list contains 10 labels\n    '''", "\n", "context_id_list", ",", "candi_response_id_list", ",", "candi_response_label_list", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "i", ":", "\n", "        ", "lines", "=", "i", ".", "readlines", "(", ")", "\n", "test_data_num", "=", "int", "(", "len", "(", "lines", ")", "/", "10", ")", "\n", "print", "(", "'test data number is %d'", "%", "test_data_num", ")", "\n", "print", "(", "'Loading Test Data...'", ")", "\n", "p", "=", "progressbar", ".", "ProgressBar", "(", "len", "(", "lines", ")", ")", "\n", "p", ".", "start", "(", ")", "\n", "for", "i", "in", "range", "(", "test_data_num", ")", ":", "\n", "#if i % int(test_data_num / 10) == 0:", "\n", "#    print ('%d test instances have been loaded' % i)", "\n", "            ", "p", ".", "update", "(", "i", "+", "1", ")", "\n", "batch_text_list", "=", "lines", "[", "i", "*", "10", ":", "(", "i", "+", "1", ")", "*", "10", "]", "\n", "batch_text_list", "=", "[", "text", ".", "strip", "(", "'\\n'", ")", "for", "text", "in", "batch_text_list", "]", "\n", "one_context_text_list", "=", "batch_text_list", "[", "0", "]", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "'\\t'", ")", "[", "1", ":", "-", "1", "]", "\n", "one_context_text", "=", "'\\t'", ".", "join", "(", "one_context_text_list", ")", ".", "strip", "(", "'\\t'", ")", "\n", "one_context_id", "=", "process_context_text", "(", "one_context_text", ",", "max_uttr_num", ",", "max_uttr_len", ",", "tokenizer", ")", "\n", "context_id_list", ".", "append", "(", "one_context_id", ")", "\n", "# process candidate response", "\n", "start_idx", "=", "i", "*", "10", "\n", "one_candi_response_list", "=", "[", "]", "\n", "one_candi_response_label_list", "=", "[", "]", "\n", "for", "candi_idx", "in", "range", "(", "start_idx", ",", "start_idx", "+", "10", ")", ":", "\n", "                ", "one_line", "=", "lines", "[", "candi_idx", "]", "\n", "one_line_content_list", "=", "one_line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "'\\t'", ")", "\n", "one_candi_response_label", "=", "int", "(", "one_line_content_list", "[", "0", "]", ")", "\n", "one_candi_response_label_list", ".", "append", "(", "one_candi_response_label", ")", "\n", "one_candi_response_text", "=", "one_line_content_list", "[", "-", "1", "]", "\n", "one_candi_response_token_list", "=", "process_text", "(", "one_candi_response_text", ",", "max_uttr_len", ",", "tokenizer", ")", "\n", "one_candi_response_id_list", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "one_candi_response_token_list", ")", "\n", "one_candi_response_list", ".", "append", "(", "one_candi_response_id_list", ")", "\n", "", "candi_response_id_list", ".", "append", "(", "one_candi_response_list", ")", "\n", "candi_response_label_list", ".", "append", "(", "one_candi_response_label_list", ")", "\n", "", "p", ".", "finish", "(", ")", "\n", "print", "(", "'Test Data Loaded.'", ")", "\n", "", "return", "context_id_list", ",", "candi_response_id_list", ",", "candi_response_label_list", "\n", "", ""]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.train.get_model_name": [[15, 21], ["os.listdir", "filename.startswith"], "function", ["None"], ["def", "get_model_name", "(", "root_dir", ",", "prefix", ")", ":", "\n", "    ", "for", "filename", "in", "os", ".", "listdir", "(", "root_dir", ")", ":", "\n", "        ", "if", "filename", ".", "startswith", "(", "prefix", ")", ":", "\n", "            ", "model_name", "=", "filename", "\n", "break", "\n", "", "", "return", "model_name", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.train.hinge_loss": [[22, 26], ["torch.nn.functional.relu", "torch.nn.functional.relu", "torch.mean", "torch.mean", "torch.unsqueeze", "torch.unsqueeze"], "function", ["None"], ["", "def", "hinge_loss", "(", "scores", ",", "margin", ")", ":", "\n", "# y_pred: bsz x candi_num", "\n", "    ", "loss", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "margin", "-", "(", "torch", ".", "unsqueeze", "(", "scores", "[", ":", ",", "0", "]", ",", "-", "1", ")", "-", "scores", "[", ":", ",", "1", ":", "]", ")", ")", "\n", "return", "torch", ".", "mean", "(", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.train.learn": [[27, 136], ["os.path.exists", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "transformers.AdamW.zero_grad", "model.train", "range", "os.makedirs", "model.parameters", "int", "int", "int", "data.get_next_train_batch", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.cat", "torch.cat", "model.batch_forward", "train.hinge_loss", "hinge_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "hinge_loss.item", "model.parameters", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "transformers.AdamW.zero_grad", "print", "model.eval", "model.train", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.no_grad", "torch.no_grad", "range", "main_utlis.compute_MAP", "main_utlis.compute_MRR", "main_utlis.compute_P1", "main_utlis.compute_R10_k", "main_utlis.compute_R10_k", "main_utlis.compute_R10_k", "print", "print", "print", "print", "os.listdir", "sorted", "data.get_next_dev_batch", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda.size", "model.batch_forward", "dev_batch_score.detach().cpu().tolist.detach().cpu().tolist", "valid_dev_score_list.extend", "valid_dev_label_list.extend", "len", "len", "torch.save", "torch.save", "fileData.items", "len", "range", "dev_batch_score.detach().cpu().tolist.size", "torch.Size", "torch.Size", "os.stat", "operator.itemgetter", "len", "os.remove", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "dev_batch_score.detach().cpu().tolist.detach().cpu", "model.state_dict", "dev_batch_score.detach().cpu().tolist.detach", "round"], "function", ["home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Data.get_next_train_batch", "home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.batch_forward", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.train.hinge_loss", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.optimization.BertAdam.step", "home.repos.pwc.inspect_result.yxuansu_HCL.pytorch_pretrained_bert.optimization.BertAdam.step", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_MAP", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_MRR", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_P1", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_R10_k", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_R10_k", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.compute_R10_k", "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.dataclass.Data.get_next_dev_batch", "home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.batch_forward"], ["", "def", "learn", "(", "args", ",", "total_steps", ",", "data", ",", "model", ",", "train_mode", ",", "device", ")", ":", "\n", "    ", "assert", "train_mode", "in", "[", "'pretrain'", ",", "'finetune'", "]", "\n", "\n", "directory", "=", "args", ".", "ckpt_path", "+", "'/'", "+", "train_mode", "+", "'/'", "\n", "import", "os", "\n", "if", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "        ", "pass", "\n", "", "else", ":", "# recursively construct directory", "\n", "        ", "os", ".", "makedirs", "(", "directory", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "optimizer", "=", "AdamW", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ")", "\n", "total_update_steps", "=", "int", "(", "total_steps", "/", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "total_update_steps", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "#--- training part ---#", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "training_data_num", ",", "dev_data_num", "=", "data", ".", "train_num", ",", "data", ".", "dev_num", "\n", "train_step_num", "=", "int", "(", "training_data_num", "/", "batch_size", ")", "+", "1", "\n", "dev_step_num", "=", "int", "(", "dev_data_num", "/", "batch_size", ")", "+", "1", "\n", "max_dev_score", "=", "0.0", "\n", "\n", "batches_processed", "=", "0", "\n", "model", ".", "train", "(", ")", "\n", "for", "one_step", "in", "range", "(", "total_steps", ")", ":", "\n", "        ", "epoch", "=", "one_step", "//", "train_step_num", "\n", "loss_accumulated", "=", "0.", "\n", "batches_processed", "+=", "1", "\n", "\n", "train_batch_context_id_list", ",", "train_batch_true_response_id_list", ",", "train_batch_negative_response_id_list", "=", "data", ".", "get_next_train_batch", "(", "batch_size", ")", "\n", "train_batch_context_inp", "=", "torch", ".", "LongTensor", "(", "train_batch_context_id_list", ")", ".", "cuda", "(", "device", ")", "\n", "train_batch_true_response_inp", "=", "torch", ".", "LongTensor", "(", "train_batch_true_response_id_list", ")", ".", "cuda", "(", "device", ")", "\n", "train_batch_negative_response_inp", "=", "torch", ".", "LongTensor", "(", "train_batch_negative_response_id_list", ")", ".", "cuda", "(", "device", ")", "\n", "train_batch_response_inp", "=", "torch", ".", "cat", "(", "[", "train_batch_true_response_inp", ",", "train_batch_negative_response_inp", "]", ",", "dim", "=", "1", ")", "\n", "train_batch_score", "=", "model", ".", "batch_forward", "(", "train_batch_context_inp", ",", "train_batch_response_inp", ")", "\n", "train_loss", "=", "hinge_loss", "(", "train_batch_score", ",", "args", ".", "loss_margin", ")", "\n", "train_loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "1.0", ")", "\n", "#optimizer.step()", "\n", "#scheduler.step()", "\n", "loss_accumulated", "+=", "train_loss", ".", "item", "(", ")", "\n", "\n", "if", "(", "one_step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", ":", "\n", "            ", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "if", "batches_processed", "%", "args", ".", "print_every", "==", "0", ":", "\n", "            ", "print", "(", "'At epoch %d, batch %d, loss %.5f, max combine score is %5f'", "%", "\n", "(", "epoch", ",", "batches_processed", ",", "loss_accumulated", "/", "batches_processed", ",", "max_dev_score", ")", ")", "\n", "loss_accumulated", "=", "0.", "\n", "\n", "", "if", "batches_processed", "%", "args", ".", "eval_every", "==", "0", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "dev_score_list", ",", "dev_label_list", "=", "[", "]", ",", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "for", "dev_step", "in", "range", "(", "dev_step_num", ")", ":", "\n", "                    ", "dev_batch_context_list", ",", "dev_batch_candidate_response_list", ",", "dev_batch_candidate_response_label_list", "=", "data", ".", "get_next_dev_batch", "(", "batch_size", ")", "\n", "dev_batch_context_inp", "=", "torch", ".", "LongTensor", "(", "dev_batch_context_list", ")", ".", "cuda", "(", "device", ")", "\n", "dev_batch_candidate_response_inp", "=", "torch", ".", "LongTensor", "(", "dev_batch_candidate_response_list", ")", ".", "cuda", "(", "device", ")", "\n", "_", ",", "candi_num", ",", "_", "=", "dev_batch_candidate_response_inp", ".", "size", "(", ")", "\n", "dev_batch_score", "=", "model", ".", "batch_forward", "(", "dev_batch_context_inp", ",", "dev_batch_candidate_response_inp", ")", "\n", "assert", "dev_batch_score", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "batch_size", ",", "candi_num", "]", ")", "\n", "dev_batch_score", "=", "dev_batch_score", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "dev_score_list", "+=", "dev_batch_score", "\n", "dev_label_list", "+=", "dev_batch_candidate_response_label_list", "\n", "", "valid_dev_score_list", "=", "[", "]", "\n", "for", "item", "in", "dev_score_list", "[", ":", "data", ".", "dev_num", "]", ":", "\n", "                    ", "valid_dev_score_list", ".", "extend", "(", "item", ")", "\n", "", "valid_dev_label_list", "=", "[", "]", "\n", "for", "item", "in", "dev_label_list", "[", ":", "data", ".", "dev_num", "]", ":", "\n", "                    ", "valid_dev_label_list", ".", "extend", "(", "item", ")", "\n", "", "assert", "len", "(", "valid_dev_score_list", ")", "==", "len", "(", "valid_dev_label_list", ")", "\n", "\n", "MAP", "=", "compute_MAP", "(", "valid_dev_score_list", ",", "valid_dev_label_list", ",", "n", "=", "candi_num", ")", "\n", "MRR", "=", "compute_MRR", "(", "valid_dev_score_list", ",", "valid_dev_label_list", ",", "n", "=", "candi_num", ")", "\n", "P_1", "=", "compute_P1", "(", "valid_dev_score_list", ",", "valid_dev_label_list", ",", "n", "=", "candi_num", ")", "\n", "R10_1", "=", "compute_R10_k", "(", "valid_dev_score_list", ",", "valid_dev_label_list", ",", "n", "=", "candi_num", ",", "k", "=", "1", ")", "\n", "R10_2", "=", "compute_R10_k", "(", "valid_dev_score_list", ",", "valid_dev_label_list", ",", "n", "=", "candi_num", ",", "k", "=", "2", ")", "\n", "R10_5", "=", "compute_R10_k", "(", "valid_dev_score_list", ",", "valid_dev_label_list", ",", "n", "=", "candi_num", ",", "k", "=", "5", ")", "\n", "print", "(", "'----------------------------------------------------------------'", ")", "\n", "print", "(", "'At epoch %d, batch %d, MAP is %5f, MRR is %5f, P_1 is %5f, R10_1 is %5f, \\\n                        R10_2 is %5f, R10_5 is %5f'", "%", "(", "epoch", ",", "batches_processed", ",", "MAP", ",", "MRR", ",", "P_1", ",", "R10_1", ",", "\n", "R10_2", ",", "R10_5", ")", ")", "\n", "curr_dev_score", "=", "MAP", "+", "MRR", "+", "P_1", "+", "R10_1", "+", "R10_2", "+", "R10_5", "\n", "print", "(", "'At epoch %d, batch %d, curr combine score is %5f'", "%", "(", "epoch", ",", "batches_processed", ",", "curr_dev_score", ")", ")", "\n", "print", "(", "'----------------------------------------------------------------'", ")", "\n", "\n", "if", "curr_dev_score", ">", "max_dev_score", ":", "\n", "                    ", "torch", ".", "save", "(", "{", "'args'", ":", "args", ",", "'model'", ":", "model", ".", "state_dict", "(", ")", "}", ",", "\n", "directory", "+", "'/epoch_%d_batch_%d_MAP_%.3f_MRR_%.3f_P_1_%.3f_R10_1_%.3f_R10_2_%.3f_R10_5_%.3f_combine_score_%.3f'", "%", "(", "epoch", ",", "batches_processed", ",", "MAP", ",", "MRR", ",", "P_1", ",", "R10_1", ",", "R10_2", ",", "R10_5", ",", "round", "(", "curr_dev_score", ",", "3", ")", ")", ")", "\n", "max_dev_score", "=", "curr_dev_score", "\n", "", "else", ":", "\n", "                    ", "pass", "\n", "", "fileData", "=", "{", "}", "\n", "for", "fname", "in", "os", ".", "listdir", "(", "directory", ")", ":", "\n", "                    ", "fileData", "[", "fname", "]", "=", "os", ".", "stat", "(", "directory", "+", "'/'", "+", "fname", ")", ".", "st_mtime", "\n", "", "sortedFiles", "=", "sorted", "(", "fileData", ".", "items", "(", ")", ",", "key", "=", "itemgetter", "(", "1", ")", ")", "\n", "if", "len", "(", "sortedFiles", ")", "<", "1", ":", "\n", "                    ", "pass", "\n", "", "else", ":", "\n", "                    ", "delete", "=", "len", "(", "sortedFiles", ")", "-", "1", "\n", "for", "x", "in", "range", "(", "0", ",", "delete", ")", ":", "\n", "                        ", "os", ".", "remove", "(", "directory", "+", "'/'", "+", "sortedFiles", "[", "x", "]", "[", "0", "]", ")", "\n", "", "", "", "model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.train.parse_config": [[137, 168], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "", "", "def", "parse_config", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# data configuration", "\n", "parser", ".", "add_argument", "(", "'--train_context_path'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--train_true_response_path'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--response_index_path'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--train_context_vec_file'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--all_response_vec_file'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--negative_num'", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_path'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--word2id_path'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--max_uttr_num'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "'--max_uttr_len'", ",", "type", "=", "int", ",", "default", "=", "50", ")", "\n", "parser", ".", "add_argument", "(", "'--cutoff_threshold'", ",", "type", "=", "float", ",", "default", "=", "0.8", ")", "\n", "parser", ".", "add_argument", "(", "'--negative_selection_k'", ",", "type", "=", "int", ",", "default", "=", "50", ")", "\n", "# model configuration", "\n", "parser", ".", "add_argument", "(", "'--model_type'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--embedding_path'", ",", "type", "=", "str", ")", "\n", "# learning configuration", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "2e-4", ")", "\n", "parser", ".", "add_argument", "(", "'--loss_margin'", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrain_total_steps'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--finetune_total_steps'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_steps'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_id'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--print_every'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_every'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--ckpt_path'", ",", "type", "=", "str", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.train.load_matching_model": [[169, 184], ["main_utlis.read_pkl_file", "len", "dataclass.Tokenizer", "print", "SMN", "dataclass.Tokenizer", "print", "MSN", "Exception"], "function", ["home.repos.pwc.inspect_result.yxuansu_HCL.SMN_MSN.main_utlis.read_pkl_file"], ["", "def", "load_matching_model", "(", "args", ")", ":", "\n", "    ", "embedding_matrix", "=", "read_pkl_file", "(", "args", ".", "embedding_path", ",", "\"bytes\"", ")", "\n", "assert", "len", "(", "embedding_matrix", ")", "==", "Tokenizer", "(", "args", ".", "word2id_path", ")", ".", "vocab_size", "\n", "padding_idx", "=", "Tokenizer", "(", "args", ".", "word2id_path", ")", ".", "padding_idx", "\n", "if", "args", ".", "model_type", "==", "'SMN'", ":", "\n", "        ", "print", "(", "'Constructing new SMN model...'", ")", "\n", "from", "modules", ".", "smn", "import", "SMN", "\n", "model", "=", "SMN", "(", "embedding_matrix", ",", "match_type", "=", "0", ",", "max_num_utterances", "=", "args", ".", "max_uttr_num", ")", "\n", "", "elif", "args", ".", "model_type", "==", "'MSN'", ":", "\n", "        ", "print", "(", "'Constructing new MSN model...'", ")", "\n", "from", "modules", ".", "msn", "import", "MSN", "\n", "model", "=", "MSN", "(", "embedding_matrix", ",", "gru_hidden", "=", "300", ",", "padding_idx", "=", "padding_idx", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'Wrong Model Type!!!'", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.TransformerBlock.__init__": [[7, 17], ["torch.Module.__init__", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "msn.TransformerBlock.init_weights", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__", "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "is_layer_norm", "=", "False", ")", ":", "\n", "        ", "super", "(", "TransformerBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_layer_norm", "=", "is_layer_norm", "\n", "if", "is_layer_norm", ":", "\n", "            ", "self", ".", "layer_morm", "=", "nn", ".", "LayerNorm", "(", "normalized_shape", "=", "input_size", ")", "\n", "\n", "", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "input_size", ",", "input_size", ")", "\n", "self", ".", "linear2", "=", "nn", ".", "Linear", "(", "input_size", ",", "input_size", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.TransformerBlock.init_weights": [[18, 21], ["torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "init", ".", "xavier_normal_", "(", "self", ".", "linear1", ".", "weight", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "linear2", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.TransformerBlock.FFN": [[22, 24], ["msn.TransformerBlock.linear2", "msn.TransformerBlock.relu", "msn.TransformerBlock.linear1"], "methods", ["None"], ["", "def", "FFN", "(", "self", ",", "X", ")", ":", "\n", "        ", "return", "self", ".", "linear2", "(", "self", ".", "relu", "(", "self", ".", "linear1", "(", "X", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.TransformerBlock.forward": [[25, 39], ["torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.bmm", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "Q.bmm", "msn.TransformerBlock.layer_morm", "msn.TransformerBlock.layer_morm", "K.permute", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "msn.TransformerBlock.FFN", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "max", "msn.TransformerBlock.FFN", "Q.size", "max", "Q.size"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.TransformerBlock.FFN", "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.TransformerBlock.FFN"], ["", "def", "forward", "(", "self", ",", "Q", ",", "K", ",", "V", ",", "episilon", "=", "1e-8", ")", ":", "\n", "        ", "dk", "=", "torch", ".", "Tensor", "(", "[", "max", "(", "1.0", ",", "Q", ".", "size", "(", "-", "1", ")", ")", "]", ")", ".", "cuda", "(", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "torch", ".", "Tensor", "(", "[", "max", "(", "1.0", ",", "Q", ".", "size", "(", "-", "1", ")", ")", "]", ")", "\n", "\n", "Q_K", "=", "Q", ".", "bmm", "(", "K", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "/", "(", "torch", ".", "sqrt", "(", "dk", ")", "+", "episilon", ")", "\n", "Q_K_score", "=", "F", ".", "softmax", "(", "Q_K", ",", "dim", "=", "-", "1", ")", "# (batch_size, max_r_words, max_u_words)", "\n", "V_att", "=", "Q_K_score", ".", "bmm", "(", "V", ")", "\n", "\n", "if", "self", ".", "is_layer_norm", ":", "\n", "            ", "X", "=", "self", ".", "layer_morm", "(", "Q", "+", "V_att", ")", "# (batch_size, max_r_words, embedding_dim)", "\n", "output", "=", "self", ".", "layer_morm", "(", "self", ".", "FFN", "(", "X", ")", "+", "X", ")", "\n", "", "else", ":", "\n", "            ", "X", "=", "Q", "+", "V_att", "\n", "output", "=", "self", ".", "FFN", "(", "X", ")", "+", "X", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.Attention.__init__": [[41, 46], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "msn.Attention.init_weights"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__", "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "in_features", "=", "input_size", ",", "out_features", "=", "hidden_size", ")", "\n", "self", ".", "linear2", "=", "nn", ".", "Linear", "(", "in_features", "=", "hidden_size", ",", "out_features", "=", "1", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.Attention.init_weights": [[47, 50], ["torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "init", ".", "xavier_normal_", "(", "self", ".", "linear1", ".", "weight", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "linear2", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.Attention.forward": [[51, 59], ["torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "msn.Attention.linear2", "float", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "msn.Attention.linear1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "X", ",", "mask", "=", "None", ")", ":", "\n", "        ", "M", "=", "F", ".", "tanh", "(", "self", ".", "linear1", "(", "X", ")", ")", "# (batch_size, max_u_words, embedding_dim)", "\n", "M", "=", "self", ".", "linear2", "(", "M", ")", "\n", "M", "[", "~", "mask", "]", "=", "float", "(", "'-inf'", ")", "\n", "score", "=", "F", ".", "softmax", "(", "M", ",", "dim", "=", "1", ")", "# (batch_size, max_u_words, 1)", "\n", "\n", "output", "=", "(", "score", "*", "X", ")", ".", "sum", "(", "dim", "=", "1", ")", "# (batch_size, embedding_dim)", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.__init__": [[61, 104], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "msn.TransformerBlock", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "msn.TransformerBlock", "msn.TransformerBlock", "msn.TransformerBlock", "msn.TransformerBlock", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "msn.MSN.init_weights", "len", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.Embedding", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.Embedding", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.Embedding", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.Embedding", "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "word_embeddings", ",", "gru_hidden", ",", "padding_idx", ")", ":", "\n", "        ", "super", "(", "MSN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "word_embedding", "=", "nn", ".", "Embedding", "(", "num_embeddings", "=", "len", "(", "word_embeddings", ")", ",", "embedding_dim", "=", "200", ",", "\n", "padding_idx", "=", "padding_idx", ",", "_weight", "=", "torch", ".", "FloatTensor", "(", "word_embeddings", ")", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "word_embedding", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "\n", "self", ".", "alpha", "=", "0.5", "\n", "self", ".", "gamma", "=", "0.3", "\n", "self", ".", "selector_transformer", "=", "TransformerBlock", "(", "input_size", "=", "200", ")", "\n", "self", ".", "W_word", "=", "nn", ".", "Parameter", "(", "data", "=", "torch", ".", "Tensor", "(", "200", ",", "200", ",", "10", ")", ")", "\n", "self", ".", "v", "=", "nn", ".", "Parameter", "(", "data", "=", "torch", ".", "Tensor", "(", "10", ",", "1", ")", ")", "\n", "self", ".", "linear_word", "=", "nn", ".", "Linear", "(", "2", "*", "50", ",", "1", ")", "\n", "self", ".", "linear_score", "=", "nn", ".", "Linear", "(", "in_features", "=", "3", ",", "out_features", "=", "1", ")", "\n", "\n", "self", ".", "transformer_utt", "=", "TransformerBlock", "(", "input_size", "=", "200", ")", "\n", "self", ".", "transformer_res", "=", "TransformerBlock", "(", "input_size", "=", "200", ")", "\n", "self", ".", "transformer_ur", "=", "TransformerBlock", "(", "input_size", "=", "200", ")", "\n", "self", ".", "transformer_ru", "=", "TransformerBlock", "(", "input_size", "=", "200", ")", "\n", "\n", "self", ".", "A1", "=", "nn", ".", "Parameter", "(", "data", "=", "torch", ".", "Tensor", "(", "200", ",", "200", ")", ")", "\n", "self", ".", "A2", "=", "nn", ".", "Parameter", "(", "data", "=", "torch", ".", "Tensor", "(", "200", ",", "200", ")", ")", "\n", "self", ".", "A3", "=", "nn", ".", "Parameter", "(", "data", "=", "torch", ".", "Tensor", "(", "200", ",", "200", ")", ")", "\n", "\n", "self", ".", "cnn_2d_1", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "6", ",", "out_channels", "=", "16", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ")", "\n", "self", ".", "maxpooling1", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "self", ".", "cnn_2d_2", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "16", ",", "out_channels", "=", "32", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ")", "\n", "self", ".", "maxpooling2", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "self", ".", "cnn_2d_3", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "32", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ")", "\n", "self", ".", "maxpooling3", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "stride", "=", "(", "3", ",", "3", ")", ")", "\n", "\n", "self", ".", "affine2", "=", "nn", ".", "Linear", "(", "in_features", "=", "3", "*", "3", "*", "64", ",", "out_features", "=", "300", ")", "\n", "\n", "self", ".", "gru_acc", "=", "nn", ".", "GRU", "(", "input_size", "=", "300", ",", "hidden_size", "=", "gru_hidden", ",", "batch_first", "=", "True", ")", "\n", "# self.attention = Attention(input_size=300, hidden_size=300)", "\n", "self", ".", "affine_out", "=", "nn", ".", "Linear", "(", "in_features", "=", "gru_hidden", ",", "out_features", "=", "1", ")", "\n", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "#print(self)", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.forward": [[106, 129], ["msn.MSN.word_embedding", "msn.MSN.word_embedding", "msn.MSN.context_selector", "multi_context.view.view.size", "multi_context.view.view.view", "bR_embedding.view.view.size", "bR_embedding.view.view.unsqueeze().repeat", "bR_embedding.view.view.view", "msn.MSN.UR_Matching", "V.view.view.view", "msn.MSN.gru_acc", "msn.MSN.dropout", "msn.MSN.affine_out", "msn.MSN.squeeze().view", "bU.size", "bR_embedding.view.view.unsqueeze", "msn.MSN.squeeze"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.context_selector", "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.UR_Matching"], ["", "def", "forward", "(", "self", ",", "bU", ",", "bR", ")", ":", "\n", "        ", "bsz", "=", "bU", ".", "size", "(", ")", "[", "0", "]", "\n", "bU_embedding", "=", "self", ".", "word_embedding", "(", "bU", ")", "# + self.position_embedding(bU_pos) # * u_mask", "\n", "bR_embedding", "=", "self", ".", "word_embedding", "(", "bR", ")", "# + self.position_embedding(bR_pos) # * r_mask", "\n", "multi_context", "=", "self", ".", "context_selector", "(", "bU_embedding", ",", "hop", "=", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "\n", "su1", ",", "su2", ",", "su3", ",", "su4", "=", "multi_context", ".", "size", "(", ")", "\n", "multi_context", "=", "multi_context", ".", "view", "(", "-", "1", ",", "su3", ",", "su4", ")", "# (batch_size*max_utterances, max_u_words, embedding_dim)", "\n", "\n", "sr1", ",", "sr2", ",", "sr3", "=", "bR_embedding", ".", "size", "(", ")", "# (batch_size, max_r_words, embedding_dim)", "\n", "bR_embedding", "=", "bR_embedding", ".", "unsqueeze", "(", "dim", "=", "1", ")", ".", "repeat", "(", "1", ",", "su2", ",", "1", ",", "1", ")", "# (batch_size, max_utterances, max_r_words, embedding_dim)", "\n", "bR_embedding", "=", "bR_embedding", ".", "view", "(", "-", "1", ",", "sr2", ",", "sr3", ")", "# (batch_size*max_utterances, max_r_words, embedding_dim)", "\n", "\n", "V", "=", "self", ".", "UR_Matching", "(", "multi_context", ",", "bR_embedding", ")", "\n", "V", "=", "V", ".", "view", "(", "su1", ",", "su2", ",", "-", "1", ")", "# (bsz, max_utterances, 300)", "\n", "\n", "H", ",", "_", "=", "self", ".", "gru_acc", "(", "V", ")", "# (bsz, max_utterances, rnn2_hidden)", "\n", "# L = self.attention(V, u_mask_sent)", "\n", "L", "=", "self", ".", "dropout", "(", "H", "[", ":", ",", "-", "1", ",", ":", "]", ")", "\n", "\n", "#output = torch.sigmoid(self.affine_out(L))", "\n", "output", "=", "self", ".", "affine_out", "(", "L", ")", "\n", "return", "output", ".", "squeeze", "(", ")", ".", "view", "(", "bsz", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.batch_forward": [[130, 148], ["batch_response.size", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "msn.MSN.forward", "batch_score_list.append", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "one_batch_response.size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "msn.MSN.size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.forward"], ["", "def", "batch_forward", "(", "self", ",", "utterance", ",", "batch_response", ")", ":", "\n", "        ", "'''\n            utterance: bsz x max_uttr_num x max_uttr_len\n            batch_response: bsz x response_candi_num x max_uttr_len\n        '''", "\n", "batch_score_list", "=", "[", "]", "\n", "bsz", ",", "candi_num", ",", "max_uttr_len", "=", "batch_response", ".", "size", "(", ")", "\n", "batch_response_list", "=", "torch", ".", "unbind", "(", "batch_response", ",", "dim", "=", "1", ")", "\n", "assert", "len", "(", "batch_response_list", ")", "==", "candi_num", "\n", "for", "idx", "in", "range", "(", "candi_num", ")", ":", "\n", "            ", "one_batch_response", "=", "batch_response_list", "[", "idx", "]", "\n", "assert", "one_batch_response", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "max_uttr_len", "]", ")", "\n", "one_score", "=", "self", ".", "forward", "(", "utterance", ",", "one_batch_response", ")", "\n", "assert", "one_score", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "1", "]", ")", "\n", "batch_score_list", ".", "append", "(", "one_score", ")", "\n", "", "batch_score", "=", "torch", ".", "cat", "(", "batch_score_list", ",", "dim", "=", "-", "1", ")", "\n", "assert", "batch_score", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "candi_num", "]", ")", "\n", "return", "batch_score", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.batch_inference": [[149, 172], ["len", "len", "len", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "msn.MSN.forward().detach().cpu", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "batch_score_list.append", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.LongTensor().cuda.size", "torch.LongTensor().cuda.size", "torch.LongTensor().cuda.size", "torch.LongTensor().cuda.size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "msn.MSN.size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "msn.MSN.forward().detach", "msn.MSN.forward"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.forward"], ["", "def", "batch_inference", "(", "self", ",", "utterance", ",", "batch_response_list", ",", "inference_device", ")", ":", "\n", "        ", "'''\n            utterance: bsz x max_uttr_num x max_uttr_len\n            batch_response: bsz x response_candi_num x max_uttr_len\n            batch_response_list: candi_num x bsz x max_uttr_len; this is a list\n        '''", "\n", "batch_score_list", "=", "[", "]", "\n", "candi_num", "=", "len", "(", "batch_response_list", ")", "\n", "bsz", "=", "len", "(", "batch_response_list", "[", "0", "]", ")", "\n", "max_uttr_len", "=", "len", "(", "batch_response_list", "[", "0", "]", "[", "0", "]", ")", "\n", "#bsz, candi_num, max_uttr_len = batch_response.size()", "\n", "#batch_response_list = torch.unbind(batch_response, dim = 1)", "\n", "#assert len(batch_response_list) == candi_num", "\n", "for", "idx", "in", "range", "(", "candi_num", ")", ":", "\n", "            ", "one_batch_response", "=", "torch", ".", "LongTensor", "(", "batch_response_list", "[", "idx", "]", ")", ".", "cuda", "(", "inference_device", ")", "\n", "assert", "one_batch_response", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "max_uttr_len", "]", ")", "\n", "one_score", "=", "self", ".", "forward", "(", "utterance", ",", "one_batch_response", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "assert", "one_score", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "1", "]", ")", "\n", "batch_score_list", ".", "append", "(", "one_score", ")", "\n", "", "batch_score", "=", "torch", ".", "cat", "(", "batch_score_list", ",", "dim", "=", "-", "1", ")", "\n", "assert", "batch_score", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "candi_num", "]", ")", "\n", "return", "batch_score", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.init_weights": [[174, 190], ["torch.uniform_", "torch.uniform_", "torch.uniform_", "torch.uniform_", "torch.uniform_", "torch.uniform_", "torch.uniform_", "torch.uniform_", "torch.uniform_", "torch.uniform_", "torch.uniform_", "torch.uniform_", "torch.uniform_", "torch.uniform_", "torch.uniform_", "torch.uniform_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.xavier_normal_", "torch.orthogonal_", "torch.orthogonal_", "torch.orthogonal_", "torch.orthogonal_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "init", ".", "uniform_", "(", "self", ".", "W_word", ")", "\n", "init", ".", "uniform_", "(", "self", ".", "v", ")", "\n", "init", ".", "uniform_", "(", "self", ".", "linear_word", ".", "weight", ")", "\n", "init", ".", "uniform_", "(", "self", ".", "linear_score", ".", "weight", ")", "\n", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "A1", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "A2", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "A3", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "cnn_2d_1", ".", "weight", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "cnn_2d_2", ".", "weight", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "cnn_2d_3", ".", "weight", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "affine2", ".", "weight", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "affine_out", ".", "weight", ")", "\n", "for", "weights", "in", "[", "self", ".", "gru_acc", ".", "weight_hh_l0", ",", "self", ".", "gru_acc", ".", "weight_ih_l0", "]", ":", "\n", "            ", "init", ".", "orthogonal_", "(", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.word_selector": [[191, 199], ["torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.einsum().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.sqrt().cuda", "torch.sqrt().cuda", "torch.sqrt().cuda", "torch.sqrt().cuda", "torch.sqrt().cuda", "torch.sqrt().cuda", "torch.sqrt().cuda", "torch.sqrt().cuda", "torch.sqrt().cuda", "torch.sqrt().cuda", "torch.sqrt().cuda", "torch.sqrt().cuda", "torch.sqrt().cuda", "torch.sqrt().cuda", "torch.sqrt().cuda", "torch.sqrt().cuda", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "msn.MSN.linear_word().squeeze", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.einsum().squeeze.max", "torch.einsum().squeeze.max", "torch.einsum().squeeze.max", "torch.einsum().squeeze.max", "torch.einsum().squeeze.max", "torch.einsum().squeeze.max", "torch.einsum().squeeze.max", "torch.einsum().squeeze.max", "msn.MSN.linear_word", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "", "def", "word_selector", "(", "self", ",", "key", ",", "context", ")", ":", "\n", "        ", "dk", "=", "torch", ".", "sqrt", "(", "torch", ".", "Tensor", "(", "[", "200", "]", ")", ")", ".", "cuda", "(", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "torch", ".", "sqrt", "(", "torch", ".", "Tensor", "(", "[", "200", "]", ")", ")", "\n", "A", "=", "torch", ".", "tanh", "(", "torch", ".", "einsum", "(", "\"blrd,ddh,bud->blruh\"", ",", "(", "context", ",", "self", ".", "W_word", ",", "key", ")", ")", "/", "dk", ")", "\n", "A", "=", "torch", ".", "einsum", "(", "\"blruh,hp->blrup\"", ",", "(", "A", ",", "self", ".", "v", ")", ")", ".", "squeeze", "(", ")", "# b x l x u x u", "\n", "\n", "a", "=", "torch", ".", "cat", "(", "[", "A", ".", "max", "(", "dim", "=", "2", ")", "[", "0", "]", ",", "A", ".", "max", "(", "dim", "=", "3", ")", "[", "0", "]", "]", ",", "dim", "=", "-", "1", ")", "# b x l x 2u", "\n", "s1", "=", "torch", ".", "softmax", "(", "self", ".", "linear_word", "(", "a", ")", ".", "squeeze", "(", ")", ",", "dim", "=", "-", "1", ")", "# b x l", "\n", "return", "s1", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.utterance_selector": [[200, 205], ["key.mean.mean.mean", "context.mean.mean.mean", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "methods", ["None"], ["", "def", "utterance_selector", "(", "self", ",", "key", ",", "context", ")", ":", "\n", "        ", "key", "=", "key", ".", "mean", "(", "dim", "=", "1", ")", "\n", "context", "=", "context", ".", "mean", "(", "dim", "=", "2", ")", "\n", "s2", "=", "torch", ".", "einsum", "(", "\"bud,bd->bu\"", ",", "[", "context", ",", "key", "]", ")", "/", "(", "1e-6", "+", "torch", ".", "norm", "(", "context", ",", "dim", "=", "-", "1", ")", "*", "torch", ".", "norm", "(", "key", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "return", "s2", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.distance": [[206, 213], ["torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "A.norm", "C.norm", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "methods", ["None"], ["", "def", "distance", "(", "self", ",", "A", ",", "B", ",", "C", ",", "epsilon", "=", "1e-6", ")", ":", "\n", "        ", "M1", "=", "torch", ".", "einsum", "(", "\"bud,dd,brd->bur\"", ",", "[", "A", ",", "B", ",", "C", "]", ")", "\n", "\n", "A_norm", "=", "A", ".", "norm", "(", "dim", "=", "-", "1", ")", "\n", "C_norm", "=", "C", ".", "norm", "(", "dim", "=", "-", "1", ")", "\n", "M2", "=", "torch", ".", "einsum", "(", "\"bud,brd->bur\"", ",", "[", "A", ",", "C", "]", ")", "/", "(", "torch", ".", "einsum", "(", "\"bu,br->bur\"", ",", "[", "A_norm", ",", "C_norm", "]", ")", "+", "epsilon", ")", "\n", "return", "M1", ",", "M2", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.context_selector": [[214, 236], ["context.size", "context.view", "msn.MSN.selector_transformer", "context_.view.view.view", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "msn.MSN.linear_score().squeeze", "context[].mean", "msn.MSN.selector_transformer", "msn.MSN.word_selector", "msn.MSN.utterance_selector", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "msn.MSN.unsqueeze().unsqueeze", "msn.MSN.linear_score", "msn.MSN.sigmoid", "msn.MSN.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.word_selector", "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.utterance_selector"], ["", "def", "context_selector", "(", "self", ",", "context", ",", "hop", "=", "[", "1", ",", "2", ",", "3", "]", ")", ":", "\n", "        ", "su1", ",", "su2", ",", "su3", ",", "su4", "=", "context", ".", "size", "(", ")", "\n", "context_", "=", "context", ".", "view", "(", "-", "1", ",", "su3", ",", "su4", ")", "# (batch_size*max_utterances, max_u_words, embedding_dim)", "\n", "context_", "=", "self", ".", "selector_transformer", "(", "context_", ",", "context_", ",", "context_", ")", "\n", "context_", "=", "context_", ".", "view", "(", "su1", ",", "su2", ",", "su3", ",", "su4", ")", "\n", "\n", "multi_match_score", "=", "[", "]", "\n", "for", "hop_i", "in", "hop", ":", "\n", "            ", "key", "=", "context", "[", ":", ",", "10", "-", "hop_i", ":", ",", ":", ",", ":", "]", ".", "mean", "(", "dim", "=", "1", ")", "\n", "key", "=", "self", ".", "selector_transformer", "(", "key", ",", "key", ",", "key", ")", "\n", "\n", "s1", "=", "self", ".", "word_selector", "(", "key", ",", "context_", ")", "\n", "s2", "=", "self", ".", "utterance_selector", "(", "key", ",", "context_", ")", "\n", "s", "=", "self", ".", "alpha", "*", "s1", "+", "(", "1", "-", "self", ".", "alpha", ")", "*", "s2", "\n", "multi_match_score", ".", "append", "(", "s", ")", "\n", "\n", "", "multi_match_score", "=", "torch", ".", "stack", "(", "multi_match_score", ",", "dim", "=", "-", "1", ")", "\n", "match_score", "=", "self", ".", "linear_score", "(", "multi_match_score", ")", ".", "squeeze", "(", ")", "\n", "mask", "=", "(", "match_score", ".", "sigmoid", "(", ")", ">=", "self", ".", "gamma", ")", ".", "float", "(", ")", "\n", "match_score", "=", "match_score", "*", "mask", "\n", "context", "=", "context", "*", "match_score", ".", "unsqueeze", "(", "dim", "=", "-", "1", ")", ".", "unsqueeze", "(", "dim", "=", "-", "1", ")", "\n", "return", "context", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.get_Matching_Map": [[237, 250], ["msn.MSN.distance", "msn.MSN.transformer_utt", "msn.MSN.transformer_res", "msn.MSN.distance", "msn.MSN.transformer_ur", "msn.MSN.transformer_ru", "msn.MSN.distance", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.distance", "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.distance", "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.distance"], ["", "def", "get_Matching_Map", "(", "self", ",", "bU_embedding", ",", "bR_embedding", ")", ":", "\n", "        ", "M1", ",", "M2", "=", "self", ".", "distance", "(", "bU_embedding", ",", "self", ".", "A1", ",", "bR_embedding", ")", "\n", "\n", "Hu", "=", "self", ".", "transformer_utt", "(", "bU_embedding", ",", "bU_embedding", ",", "bU_embedding", ")", "\n", "Hr", "=", "self", ".", "transformer_res", "(", "bR_embedding", ",", "bR_embedding", ",", "bR_embedding", ")", "\n", "M3", ",", "M4", "=", "self", ".", "distance", "(", "Hu", ",", "self", ".", "A2", ",", "Hr", ")", "\n", "\n", "Hur", "=", "self", ".", "transformer_ur", "(", "bU_embedding", ",", "bR_embedding", ",", "bR_embedding", ")", "\n", "Hru", "=", "self", ".", "transformer_ru", "(", "bR_embedding", ",", "bU_embedding", ",", "bU_embedding", ")", "\n", "M5", ",", "M6", "=", "self", ".", "distance", "(", "Hur", ",", "self", ".", "A3", ",", "Hru", ")", "\n", "\n", "M", "=", "torch", ".", "stack", "(", "[", "M1", ",", "M2", ",", "M3", ",", "M4", ",", "M5", ",", "M6", "]", ",", "dim", "=", "1", ")", "# (bsz*max_utterances, channel, max_u_words, max_r_words)", "\n", "return", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.UR_Matching": [[251, 267], ["msn.MSN.get_Matching_Map", "msn.MSN.relu", "msn.MSN.maxpooling1", "msn.MSN.relu", "msn.MSN.maxpooling2", "msn.MSN.relu", "msn.MSN.maxpooling3", "Z.view.view.view", "msn.MSN.tanh", "msn.MSN.cnn_2d_1", "msn.MSN.cnn_2d_2", "msn.MSN.cnn_2d_3", "Z.view.view.size", "msn.MSN.affine2"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.msn.MSN.get_Matching_Map"], ["", "def", "UR_Matching", "(", "self", ",", "bU_embedding", ",", "bR_embedding", ")", ":", "\n", "        ", "M", "=", "self", ".", "get_Matching_Map", "(", "bU_embedding", ",", "bR_embedding", ")", "\n", "\n", "Z", "=", "self", ".", "relu", "(", "self", ".", "cnn_2d_1", "(", "M", ")", ")", "\n", "Z", "=", "self", ".", "maxpooling1", "(", "Z", ")", "\n", "\n", "Z", "=", "self", ".", "relu", "(", "self", ".", "cnn_2d_2", "(", "Z", ")", ")", "\n", "Z", "=", "self", ".", "maxpooling2", "(", "Z", ")", "\n", "\n", "Z", "=", "self", ".", "relu", "(", "self", ".", "cnn_2d_3", "(", "Z", ")", ")", "\n", "Z", "=", "self", ".", "maxpooling3", "(", "Z", ")", "\n", "\n", "Z", "=", "Z", ".", "view", "(", "Z", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# (bsz*max_utterances, *)", "\n", "\n", "V", "=", "self", ".", "tanh", "(", "self", ".", "affine2", "(", "Z", ")", ")", "# (bsz*max_utterances, 50)", "\n", "return", "V", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__": [[8, 55], ["torch.nn.Module.__init__", "len", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.GRU", "torch.nn.GRU", "smn.SMN.__init__.gru_weight_init"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.__init__", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.Embedding", "home.repos.pwc.inspect_result.yxuansu_HCL.SABERT.transformer.Embedding"], ["    ", "def", "__init__", "(", "self", ",", "emb_matrix", ",", "match_type", "=", "0", ",", "max_num_utterances", "=", "10", ")", ":", "\n", "        ", "super", "(", "SMN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "emb_dim", "=", "200", "\n", "self", ".", "hidden_dim", "=", "200", "\n", "self", ".", "vocab_size", "=", "len", "(", "emb_matrix", ")", "#400000", "\n", "self", ".", "layers_num", "=", "2", "\n", "self", ".", "match_type", "=", "match_type", "\n", "self", ".", "max_num_utterances", "=", "max_num_utterances", "\n", "\n", "def", "gru_weight_init", "(", "weights", ")", ":", "\n", "            ", "for", "l", "in", "weights", ":", "\n", "                ", "for", "weight", "in", "l", ":", "\n", "                    ", "if", "len", "(", "weight", ".", "shape", ")", ">=", "2", ":", "nn", ".", "init", ".", "orthogonal_", "(", "weight", ")", "\n", "", "", "", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", ",", "self", ".", "emb_dim", ")", "\n", "self", ".", "embedding", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "emb_matrix", ",", "dtype", "=", "torch", ".", "float32", ")", ")", "\n", "self", ".", "embedding", ".", "weight", ".", "requires_grad", "=", "False", "\n", "# utterance\u7684gru", "\n", "self", ".", "utterance_GRU", "=", "nn", ".", "GRU", "(", "self", ".", "emb_dim", ",", "self", ".", "hidden_dim", ",", "bidirectional", "=", "False", ",", "batch_first", "=", "True", ")", "\n", "gru_weight_init", "(", "self", ".", "utterance_GRU", ".", "all_weights", ")", "\n", "\n", "# response\u7684gru", "\n", "self", ".", "response_GRU", "=", "nn", ".", "GRU", "(", "self", ".", "emb_dim", ",", "self", ".", "hidden_dim", ",", "bidirectional", "=", "False", ",", "batch_first", "=", "True", ")", "\n", "gru_weight_init", "(", "self", ".", "response_GRU", ".", "all_weights", ")", "\n", "# \u5377\u79ef\u5c42\u7684\u5b9a\u4e49", "\n", "self", ".", "conv2d", "=", "nn", ".", "Conv2d", "(", "2", ",", "8", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ")", "\n", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "conv2d", ".", "weight", ")", "\n", "# \u8fdb\u5165Matching Accumulationmo\u6a21\u5757\u524d\uff0c\u8fdb\u884c\u7ef4\u5ea6\u6620\u5c04", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "16", "*", "16", "*", "8", ",", "50", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "linear", ".", "weight", ")", "\n", "\n", "self", ".", "matrix_A", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "[", "self", ".", "hidden_dim", ",", "self", ".", "hidden_dim", "]", ")", ")", "\n", "\n", "if", "self", ".", "match_type", "==", "1", ":", "\n", "            ", "self", ".", "static_match_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "[", "10", ",", "1", "]", ")", ")", "\n", "", "elif", "self", ".", "match_type", "==", "2", ":", "\n", "            ", "self", ".", "match_W11_matrix", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "[", "50", ",", "self", ".", "hidden_dim", "]", ")", ")", "\n", "self", ".", "match_W12_matrix", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "[", "50", ",", "50", "]", ")", ")", "\n", "self", ".", "match_b1", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "[", "50", "]", ")", ")", "\n", "self", ".", "ts", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "[", "50", ",", "1", "]", ")", ")", "\n", "\n", "\n", "", "self", ".", "final_GRU", "=", "nn", ".", "GRU", "(", "50", ",", "50", ",", "bidirectional", "=", "False", ",", "batch_first", "=", "True", ")", "\n", "gru_weight_init", "(", "self", ".", "final_GRU", ".", "all_weights", ")", "\n", "\n", "#self.final_linear = nn.Linear(50, 1)", "\n", "self", ".", "final_linear", "=", "nn", ".", "Linear", "(", "50", ",", "1", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "final_linear", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.forward": [[56, 118], ["smn.SMN.embedding", "smn.SMN.embedding", "all_utterance_embeddings.permute.permute.permute", "smn.SMN.response_GRU", "response_embeddings.permute.permute.permute", "response_GRU_embeddings.permute.permute.permute", "smn.SMN.final_GRU", "smn.SMN.final_linear", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "smn.SMN.utterance_GRU", "utterance_hidden.append", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "smn.SMN.conv2d", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "pooling_layer.view.view.view", "smn.SMN.linear", "torch.tanh", "torch.tanh", "matching_vectors.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "pooling_layer.view.view.size", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.tanh", "torch.tanh", "torch.softmax", "torch.softmax", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "smn.SMN.match_W11_matrix.permute", "smn.SMN.match_W12_matrix.permute", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "utterance", ",", "response", ")", ":", "\n", "        ", "'''\n            utterance:(self.batch_size, self.max_num_utterance, self.max_sentence_len)\n            response:(self.batch_size, self.max_sentence_len)\n        '''", "\n", "# (batch_size,10,50)-->(batch_size,10,50,200)", "\n", "all_utterance_embeddings", "=", "self", ".", "embedding", "(", "utterance", ")", "\n", "response_embeddings", "=", "self", ".", "embedding", "(", "response", ")", "\n", "\n", "# pytorch:(batch_size,10,50,200)-->(10,batch_size,50,200)", "\n", "all_utterance_embeddings", "=", "all_utterance_embeddings", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "\n", "response_GRU_embeddings", ",", "_", "=", "self", ".", "response_GRU", "(", "response_embeddings", ")", "# batch_size, 50, 200 --> batch_size, 50, 200", "\n", "response_embeddings", "=", "response_embeddings", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# batch_size, 50, 200 --> batch_size, 200, 50", "\n", "response_GRU_embeddings", "=", "response_GRU_embeddings", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# batch_size, 50, 200 --> batch_size, 200, 50", "\n", "matching_vectors", "=", "[", "]", "\n", "utterance_hidden", "=", "[", "]", "\n", "\n", "for", "utterance_embeddings", "in", "all_utterance_embeddings", ":", "\n", "            ", "matrix1", "=", "torch", ".", "matmul", "(", "utterance_embeddings", ",", "response_embeddings", ")", "#    --> batch_size, 50, 50", "\n", "\n", "utterance_GRU_embeddings", ",", "uhidden", "=", "self", ".", "utterance_GRU", "(", "utterance_embeddings", ")", "# batch_size, 50, 200 --> batch_size, 50, 200", "\n", "utterance_hidden", ".", "append", "(", "torch", ".", "squeeze", "(", "uhidden", ")", ")", "\n", "matrix2", "=", "torch", ".", "einsum", "(", "'aij,jk->aik'", ",", "(", "utterance_GRU_embeddings", ",", "self", ".", "matrix_A", ")", ")", "\n", "matrix2", "=", "torch", ".", "matmul", "(", "matrix2", ",", "response_GRU_embeddings", ")", "\n", "\n", "matrix", "=", "torch", ".", "stack", "(", "[", "matrix1", ",", "matrix2", "]", ",", "dim", "=", "1", ")", "\n", "# matrix:(batch_size,channel,seq_len,embedding_size)", "\n", "conv_layer", "=", "self", ".", "conv2d", "(", "matrix", ")", "\n", "# add activate function", "\n", "conv_layer", "=", "F", ".", "relu", "(", "conv_layer", ")", "\n", "\n", "pooling_layer", "=", "F", ".", "max_pool2d", "(", "conv_layer", ",", "kernel_size", "=", "3", ",", "stride", "=", "3", ")", "\n", "# flatten", "\n", "pooling_layer", "=", "pooling_layer", ".", "view", "(", "pooling_layer", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "matching_vector", "=", "self", ".", "linear", "(", "pooling_layer", ")", "\n", "# add activate function", "\n", "matching_vector", "=", "F", ".", "tanh", "(", "matching_vector", ")", "\n", "matching_vectors", ".", "append", "(", "matching_vector", ")", "\n", "# Matching Accumulation", "\n", "", "gru_output", ",", "last_hidden", "=", "self", ".", "final_GRU", "(", "torch", ".", "stack", "(", "matching_vectors", ",", "dim", "=", "1", ")", ")", "# batch_size, 10, 50 --> (batch_size, 10, 50) (1, batch_size, 50)", "\n", "if", "self", ".", "match_type", "==", "0", ":", "\n", "            ", "matching_output", "=", "last_hidden", "\n", "", "elif", "self", ".", "match_type", "==", "1", ":", "\n", "            ", "matching_output", "=", "torch", ".", "sum", "(", "gru_output", "*", "self", ".", "static_match_weight", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "f1", "=", "torch", ".", "matmul", "(", "torch", ".", "stack", "(", "utterance_hidden", ",", "dim", "=", "1", ")", ",", "self", ".", "match_W11_matrix", ".", "permute", "(", "1", ",", "0", ")", ")", "\n", "f2", "=", "torch", ".", "matmul", "(", "gru_output", ",", "self", ".", "match_W12_matrix", ".", "permute", "(", "1", ",", "0", ")", ")", "\n", "ti", "=", "F", ".", "tanh", "(", "f1", "+", "f2", "+", "self", ".", "match_b1", ")", "\n", "att", "=", "F", ".", "softmax", "(", "torch", ".", "matmul", "(", "ti", ",", "self", ".", "ts", ")", ",", "1", ")", "# batch_size, 10, 1", "\n", "matching_weight", "=", "torch", ".", "mul", "(", "att", ",", "gru_output", ")", "\n", "matching_output", "=", "torch", ".", "sum", "(", "matching_weight", ",", "1", ")", "\n", "\n", "# \u8f93\u51fa\u5c42", "\n", "#print (matching_output.size())", "\n", "# \u8f93\u51fa\u5c42", "\n", "", "logits", "=", "self", ".", "final_linear", "(", "torch", ".", "squeeze", "(", "matching_output", ")", ")", "\n", "\n", "# use CrossEntropyLoss,this loss function would accumulate softmax", "\n", "# y_pred = F.softmax(logits, -1)", "\n", "y_pred", "=", "logits", "# bsz x 1", "\n", "return", "y_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.batch_forward": [[119, 137], ["batch_response.size", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "smn.SMN.forward", "batch_score_list.append", "torch.cat.size", "torch.cat.size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "one_batch_response.size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "smn.SMN.size", "torch.Size", "torch.Size", "torch.Size", "torch.Size"], "methods", ["home.repos.pwc.inspect_result.yxuansu_HCL.modules.smn.SMN.forward"], ["", "def", "batch_forward", "(", "self", ",", "utterance", ",", "batch_response", ")", ":", "\n", "        ", "'''\n            utterance: bsz x max_uttr_num x max_uttr_len\n            batch_response: bsz x response_candi_num x max_uttr_len\n        '''", "\n", "batch_score_list", "=", "[", "]", "\n", "bsz", ",", "candi_num", ",", "max_uttr_len", "=", "batch_response", ".", "size", "(", ")", "\n", "batch_response_list", "=", "torch", ".", "unbind", "(", "batch_response", ",", "dim", "=", "1", ")", "\n", "assert", "len", "(", "batch_response_list", ")", "==", "candi_num", "\n", "for", "idx", "in", "range", "(", "candi_num", ")", ":", "\n", "            ", "one_batch_response", "=", "batch_response_list", "[", "idx", "]", "\n", "assert", "one_batch_response", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "max_uttr_len", "]", ")", "\n", "one_score", "=", "self", ".", "forward", "(", "utterance", ",", "one_batch_response", ")", "\n", "assert", "one_score", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "1", "]", ")", "\n", "batch_score_list", ".", "append", "(", "one_score", ")", "\n", "", "batch_score", "=", "torch", ".", "cat", "(", "batch_score_list", ",", "dim", "=", "-", "1", ")", "\n", "assert", "batch_score", ".", "size", "(", ")", "==", "torch", ".", "Size", "(", "[", "bsz", ",", "candi_num", "]", ")", "\n", "return", "batch_score", "\n", "", "", ""]]}