{"home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.speech-input.input_feature.AudioDataset.__init__": [[21, 61], ["open", "f.readlines", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "list_files.append", "x.strip().split", "open", "scipy._read_riff_chunk", "os.path.getsize", "os.path.getsize", "os.path.getsize", "os.path.getsize", "x.strip", "print", "print", "os.path.getsize", "os.path.getsize", "os.path.getsize", "os.path.getsize", "x.strip"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "files_path", ",", "audio_dir", ",", "transform", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            files_path (string): Path to the .txt file which the address of files are saved in it.\n            root_dir (string): Directory with all the audio files.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"", "\n", "\n", "# self.sound_files = [x.strip() for x in content]", "\n", "self", ".", "audio_dir", "=", "audio_dir", "\n", "self", ".", "transform", "=", "transform", "\n", "\n", "# Open the .txt file and create a list from each line.", "\n", "with", "open", "(", "files_path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "content", "=", "f", ".", "readlines", "(", ")", "\n", "# you may also want to remove whitespace characters like `\\n` at the end of each line", "\n", "", "list_files", "=", "[", "]", "\n", "for", "x", "in", "content", ":", "\n", "            ", "sound_file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "audio_dir", ",", "x", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "1", "]", ")", "\n", "try", ":", "\n", "                ", "with", "open", "(", "sound_file_path", ",", "'rb'", ")", "as", "f", ":", "\n", "                    ", "riff_size", ",", "_", "=", "wav", ".", "_read_riff_chunk", "(", "f", ")", "\n", "file_size", "=", "os", ".", "path", ".", "getsize", "(", "sound_file_path", ")", "\n", "\n", "# Assertion error.", "\n", "", "assert", "riff_size", "==", "file_size", "and", "os", ".", "path", ".", "getsize", "(", "sound_file_path", ")", ">", "1000", ",", "\"Bad file!\"", "\n", "\n", "# Add to list if file is OK!", "\n", "list_files", ".", "append", "(", "x", ".", "strip", "(", ")", ")", "\n", "", "except", "OSError", "as", "err", ":", "\n", "                ", "print", "(", "\"OS error: {0}\"", ".", "format", "(", "err", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "print", "(", "'file %s is corrupted!'", "%", "sound_file_path", ")", "\n", "# except:", "\n", "#     print(\"Unexpected error:\", sys.exc_info()[0])", "\n", "#     raise", "\n", "\n", "# Save the correct and healthy sound files to a list.", "\n", "", "", "self", ".", "sound_files", "=", "list_files", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.speech-input.input_feature.AudioDataset.__len__": [[62, 64], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sound_files", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.speech-input.input_feature.AudioDataset.__getitem__": [[65, 119], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "scipy.read", "sf.read", "speechpy.processing.stack_frames", "speechpy.feature.lmfe", "int", "speechpy.processing.power_spectrum", "input_feature.AudioDataset.transform", "input_feature.AudioDataset.sound_files[].split", "input_feature.AudioDataset.sound_files[].split"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "# Get the sound file path", "\n", "        ", "sound_file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "audio_dir", ",", "self", ".", "sound_files", "[", "idx", "]", ".", "split", "(", ")", "[", "1", "]", ")", "\n", "\n", "##############################", "\n", "### Reading and processing ###", "\n", "##############################", "\n", "\n", "# Reading .wav file", "\n", "fs", ",", "signal", "=", "wav", ".", "read", "(", "sound_file_path", ")", "\n", "\n", "# Reading .wav file", "\n", "import", "soundfile", "as", "sf", "\n", "signal", ",", "fs", "=", "sf", ".", "read", "(", "sound_file_path", ")", "\n", "\n", "###########################", "\n", "### Feature Extraction ####", "\n", "###########################", "\n", "\n", "# DEFAULTS:", "\n", "num_coefficient", "=", "40", "\n", "\n", "# Staching frames", "\n", "frames", "=", "speechpy", ".", "processing", ".", "stack_frames", "(", "signal", ",", "sampling_frequency", "=", "fs", ",", "frame_length", "=", "0.02", ",", "\n", "frame_stride", "=", "0.02", ",", "\n", "zero_padding", "=", "True", ")", "\n", "\n", "# # Extracting power spectrum (choosing 3 seconds and elimination of DC)", "\n", "power_spectrum", "=", "speechpy", ".", "processing", ".", "power_spectrum", "(", "frames", ",", "fft_points", "=", "2", "*", "num_coefficient", ")", "[", ":", ",", "1", ":", "]", "\n", "\n", "logenergy", "=", "speechpy", ".", "feature", ".", "lmfe", "(", "signal", ",", "sampling_frequency", "=", "fs", ",", "frame_length", "=", "0.02", ",", "frame_stride", "=", "0.02", ",", "\n", "num_filters", "=", "num_coefficient", ",", "fft_length", "=", "1024", ",", "low_frequency", "=", "0", ",", "\n", "high_frequency", "=", "None", ")", "\n", "\n", "\n", "########################", "\n", "### Handling sample ####", "\n", "########################", "\n", "\n", "# Label extraction", "\n", "label", "=", "int", "(", "self", ".", "sound_files", "[", "idx", "]", ".", "split", "(", ")", "[", "0", "]", ")", "\n", "\n", "sample", "=", "{", "'feature'", ":", "logenergy", ",", "'label'", ":", "label", "}", "\n", "\n", "########################", "\n", "### Post Processing ####", "\n", "########################", "\n", "if", "self", ".", "transform", ":", "\n", "            ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "", "else", ":", "\n", "            ", "feature", ",", "label", "=", "sample", "[", "'feature'", "]", ",", "sample", "[", "'label'", "]", "\n", "sample", "=", "feature", ",", "label", "\n", "\n", "", "return", "sample", "\n", "# return sample", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.speech-input.input_feature.CMVN.__call__": [[127, 135], ["speechpy.processing.cmvn"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "sample", ")", ":", "\n", "        ", "feature", ",", "label", "=", "sample", "[", "'feature'", "]", ",", "sample", "[", "'label'", "]", "\n", "\n", "# Mean variance normalization of the spectrum.", "\n", "# The following line should be Uncommented if cepstral mean variance normalization is desired!", "\n", "feature", "=", "speechpy", ".", "processing", ".", "cmvn", "(", "feature", ",", "variance_normalization", "=", "True", ")", "\n", "\n", "return", "{", "'feature'", ":", "feature", ",", "'label'", ":", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.speech-input.input_feature.Extract_Derivative.__call__": [[142, 149], ["speechpy.feature.extract_derivative_feature"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "sample", ")", ":", "\n", "        ", "feature", ",", "label", "=", "sample", "[", "'feature'", "]", ",", "sample", "[", "'label'", "]", "\n", "\n", "# Extract derivative features", "\n", "feature", "=", "speechpy", ".", "feature", ".", "extract_derivative_feature", "(", "feature", ")", "\n", "\n", "return", "{", "'feature'", ":", "feature", ",", "'label'", ":", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.speech-input.input_feature.Feature_Cube.__init__": [[159, 166], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cube_shape", ")", ":", "\n", "\n", "        ", "self", ".", "cube_shape", "=", "cube_shape", "\n", "if", "self", ".", "cube_shape", "!=", "None", ":", "\n", "            ", "self", ".", "num_frames", "=", "cube_shape", "[", "0", "]", "\n", "self", ".", "num_features", "=", "cube_shape", "[", "1", "]", "\n", "self", ".", "num_channels", "=", "cube_shape", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.speech-input.input_feature.Feature_Cube.__call__": [[168, 180], ["numpy.zeros"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "sample", ")", ":", "\n", "        ", "feature", ",", "label", "=", "sample", "[", "'feature'", "]", ",", "sample", "[", "'label'", "]", "\n", "\n", "if", "self", ".", "cube_shape", "!=", "None", ":", "\n", "            ", "feature_cube", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_frames", ",", "self", ".", "num_features", ",", "self", ".", "num_channels", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "feature_cube", "=", "feature", "[", "0", ":", "self", ".", "num_frames", ",", ":", ",", ":", "]", "\n", "", "else", ":", "\n", "            ", "feature_cube", "=", "feature", "\n", "\n", "\n", "# return {'feature': feature_cube, 'label': label}", "\n", "", "return", "{", "'feature'", ":", "feature_cube", "[", "None", ",", ":", ",", ":", ",", ":", "]", ",", "'label'", ":", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.speech-input.input_feature.ToOutput.__call__": [[187, 191], ["None"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "sample", ")", ":", "\n", "        ", "feature", ",", "label", "=", "sample", "[", "'feature'", "]", ",", "sample", "[", "'label'", "]", "\n", "\n", "return", "feature", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.speech-input.input_feature.Compose.__init__": [[205, 207], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.speech-input.input_feature.Compose.__call__": [[208, 212], ["t"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "img", "=", "t", "(", "img", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.speech-input.input_feature.Compose.__repr__": [[213, 220], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'('", "\n", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "format_string", "+=", "'\\n'", "\n", "format_string", "+=", "'    {0}'", ".", "format", "(", "t", ")", "\n", "", "format_string", "+=", "'\\n)'", "\n", "return", "format_string", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.training_evaluation.train._configure_learning_rate": [[147, 185], ["int", "tensorflow.train.exponential_decay", "tensorflow.constant", "tensorflow.train.polynomial_decay", "ValueError"], "function", ["None"], ["def", "_configure_learning_rate", "(", "num_samples_per_epoch", ",", "global_step", ")", ":", "\n", "    ", "\"\"\"Configures the learning rate.\n\n    Args:\n      num_samples_per_epoch: The number of samples in each epoch of training.\n      global_step: The global_step tensor.\n\n    Returns:\n      A `Tensor` representing the learning rate.\n\n    Raises:\n      ValueError: if\n    \"\"\"", "\n", "decay_steps", "=", "int", "(", "num_samples_per_epoch", "/", "FLAGS", ".", "batch_size", "*", "\n", "FLAGS", ".", "num_epochs_per_decay", ")", "\n", "if", "FLAGS", ".", "sync_replicas", ":", "\n", "        ", "decay_steps", "/=", "FLAGS", ".", "replicas_to_aggregate", "\n", "\n", "", "if", "FLAGS", ".", "learning_rate_decay_type", "==", "'exponential'", ":", "\n", "        ", "return", "tf", ".", "train", ".", "exponential_decay", "(", "FLAGS", ".", "learning_rate", ",", "\n", "global_step", ",", "\n", "decay_steps", ",", "\n", "FLAGS", ".", "learning_rate_decay_factor", ",", "\n", "staircase", "=", "True", ",", "\n", "name", "=", "'exponential_decay_learning_rate'", ")", "\n", "", "elif", "FLAGS", ".", "learning_rate_decay_type", "==", "'fixed'", ":", "\n", "        ", "return", "tf", ".", "constant", "(", "FLAGS", ".", "learning_rate", ",", "name", "=", "'fixed_learning_rate'", ")", "\n", "", "elif", "FLAGS", ".", "learning_rate_decay_type", "==", "'polynomial'", ":", "\n", "        ", "return", "tf", ".", "train", ".", "polynomial_decay", "(", "FLAGS", ".", "learning_rate", ",", "\n", "global_step", ",", "\n", "decay_steps", ",", "\n", "FLAGS", ".", "end_learning_rate", ",", "\n", "power", "=", "1.0", ",", "\n", "cycle", "=", "False", ",", "\n", "name", "=", "'polynomial_decay_learning_rate'", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'learning_rate_decay_type [%s] was not recognized'", ",", "\n", "FLAGS", ".", "learning_rate_decay_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.training_evaluation.train._configure_optimizer": [[187, 211], ["tensorflow.train.AdamOptimizer", "tensorflow.train.GradientDescentOptimizer", "ValueError"], "function", ["None"], ["", "", "def", "_configure_optimizer", "(", "learning_rate", ")", ":", "\n", "    ", "\"\"\"Configures the optimizer used for training.\n\n    Args:\n      learning_rate: A scalar or `Tensor` learning rate.\n\n    Returns:\n      An instance of an optimizer.\n\n    Raises:\n      ValueError: if FLAGS.optimizer is not recognized.\n    \"\"\"", "\n", "\n", "if", "FLAGS", ".", "optimizer", "==", "'adam'", ":", "\n", "        ", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "\n", "learning_rate", ",", "\n", "beta1", "=", "FLAGS", ".", "adam_beta1", ",", "\n", "beta2", "=", "FLAGS", ".", "adam_beta2", ",", "\n", "epsilon", "=", "FLAGS", ".", "opt_epsilon", ")", "\n", "", "elif", "FLAGS", ".", "optimizer", "==", "'sgd'", ":", "\n", "        ", "optimizer", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "learning_rate", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Optimizer [%s] was not recognized'", ",", "FLAGS", ".", "optimizer", ")", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.training_evaluation.train.average_gradients": [[213, 249], ["zip", "tensorflow.concat", "tensorflow.reduce_mean", "average_grads.append", "tensorflow.expand_dims", "grads.append"], "function", ["None"], ["", "def", "average_gradients", "(", "tower_grads", ")", ":", "\n", "    ", "\"\"\"Calculate the average gradient for each shared variable across all towers.\n\n    Note that this function provides a synchronization point across all towers.\n\n    Args:\n      tower_grads: List of lists of (gradient, variable) tuples. The outer list\n        is over individual gradients. The inner list is over the gradient\n        calculation for each tower.\n    Returns:\n       List of pairs of (gradient, variable) where the gradient has been averaged\n       across all towers.\n    \"\"\"", "\n", "average_grads", "=", "[", "]", "\n", "for", "grad_and_vars", "in", "zip", "(", "*", "tower_grads", ")", ":", "\n", "# Note that each grad_and_vars looks like the following:", "\n", "#   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))", "\n", "        ", "grads", "=", "[", "]", "\n", "for", "g", ",", "_", "in", "grad_and_vars", ":", "\n", "# Add 0 dimension to the gradients to represent the tower.", "\n", "            ", "expanded_g", "=", "tf", ".", "expand_dims", "(", "g", ",", "0", ")", "\n", "\n", "# Append on a 'tower' dimension which we will average over below.", "\n", "grads", ".", "append", "(", "expanded_g", ")", "\n", "\n", "# Average over the 'tower' dimension.", "\n", "", "grad", "=", "tf", ".", "concat", "(", "axis", "=", "0", ",", "values", "=", "grads", ")", "\n", "grad", "=", "tf", ".", "reduce_mean", "(", "grad", ",", "0", ")", "\n", "\n", "# Keep in mind that the Variables are redundant because they are shared", "\n", "# across towers. So .. we will just return the first tower's pointer to", "\n", "# the Variable.", "\n", "v", "=", "grad_and_vars", "[", "0", "]", "[", "1", "]", "\n", "grad_and_var", "=", "(", "grad", ",", "v", ")", "\n", "average_grads", ".", "append", "(", "grad_and_var", ")", "\n", "", "return", "average_grads", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.training_evaluation.train._get_variables_to_train": [[251, 267], ["tensorflow.trainable_variables", "tensorflow.get_collection", "variables_to_train.extend", "scope.strip", "FLAGS.trainable_scopes.split"], "function", ["None"], ["", "def", "_get_variables_to_train", "(", ")", ":", "\n", "    ", "\"\"\"Returns a list of variables to train.\n\n    Returns:\n      A list of variables to train by the optimizer.\n    \"\"\"", "\n", "if", "FLAGS", ".", "trainable_scopes", "is", "None", ":", "\n", "        ", "return", "tf", ".", "trainable_variables", "(", ")", "\n", "", "else", ":", "\n", "        ", "scopes", "=", "[", "scope", ".", "strip", "(", ")", "for", "scope", "in", "FLAGS", ".", "trainable_scopes", ".", "split", "(", "','", ")", "]", "\n", "\n", "", "variables_to_train", "=", "[", "]", "\n", "for", "scope", "in", "scopes", ":", "\n", "        ", "variables", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "scope", ")", "\n", "variables_to_train", ".", "extend", "(", "variables", ")", "\n", "", "return", "variables_to_train", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.training_evaluation.train.main": [[312, 664], ["tensorflow.logging.set_verbosity", "tensorflow.Graph", "tf.Graph.as_default", "tensorflow.device", "int", "int", "tensorflow.Variable", "train._configure_learning_rate", "train._configure_optimizer", "tensorflow.placeholder", "nets.nets_factory.get_network_fn", "nets.nets_factory.get_network_fn", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "train.average_gradients", "_configure_optimizer.apply_gradients", "tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.apply", "tensorflow.group", "set", "slim.get_model_variables", "set.add", "set.add", "set.add", "set", "tensorflow.summary.merge", "tensorflow.Session", "slim.get_variables_to_restore", "tensorflow.train.Saver", "tensorflow.train.Coordinator", "sess.run", "sess.run", "tensorflow.summary.FileWriter", "range", "tensorflow.variable_scope", "range", "tensorflow.trainable_variables", "tensorflow.get_collection", "set.add", "set.add", "set.add", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.get_collection", "list", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "range", "tf.train.Saver.save", "numpy.zeros", "numpy.zeros", "range", "numpy.zeros", "numpy.zeros", "numpy.zeros", "int", "range", "print", "tensorflow.get_variable_scope", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.histogram", "tensorflow.ConfigProto", "sess.run", "tf.summary.FileWriter.add_summary", "sess.run", "roc_curve.calculate_roc.calculate_eer_auc_ap", "tensorflow.device", "tensorflow.nn.zero_fraction", "tensorflow.nn.zero_fraction", "sess.run", "range", "range", "range", "roc_curve.calculate_roc.calculate_eer_auc_ap", "print", "float", "str", "tensorflow.name_scope", "nets_factory.get_network_fn.", "nets_factory.get_network_fn.", "tensorflow.sqrt", "auxiliary.losses.contrastive_loss", "tensorflow.get_variable_scope().reuse_variables", "_configure_optimizer.compute_gradients", "tower_grads.append", "print", "print", "print", "numpy.mean", "tensorflow.reduce_sum", "label_train.reshape", "label_test.reshape", "str", "tensorflow.pow", "tensorflow.get_variable_scope", "label_train.reshape", "label_keep.append", "label_keep.append", "sys.exc_info", "str", "numpy.mean", "tensorflow.subtract", "str", "str", "numpy.mean", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.training_evaluation.test._configure_learning_rate", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.training_evaluation.test._configure_optimizer", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.__init__.get_network_fn", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.__init__.get_network_fn", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.training_evaluation.test.average_gradients", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.roc_curve.calculate_roc.calculate_eer_auc_ap", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.roc_curve.calculate_roc.calculate_eer_auc_ap", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.auxiliary.losses.contrastive_loss"], ["def", "main", "(", "_", ")", ":", "\n", "\n", "\n", "    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "graph", ".", "as_default", "(", ")", ",", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "######################", "\n", "# Config model_deploy#", "\n", "######################", "\n", "\n", "# required from data", "\n", "        ", "num_samples_per_epoch", "=", "train_data", "[", "'mouth'", "]", ".", "shape", "[", "0", "]", "\n", "num_batches_per_epoch", "=", "int", "(", "num_samples_per_epoch", "/", "FLAGS", ".", "batch_size", ")", "\n", "\n", "num_samples_per_epoch_test", "=", "test_data", "[", "'mouth'", "]", ".", "shape", "[", "0", "]", "\n", "num_batches_per_epoch_test", "=", "int", "(", "num_samples_per_epoch_test", "/", "FLAGS", ".", "batch_size", ")", "\n", "\n", "# Create global_step", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "'global_step'", ",", "trainable", "=", "False", ")", "\n", "\n", "#########################################", "\n", "# Configure the larning rate. #", "\n", "#########################################", "\n", "learning_rate", "=", "_configure_learning_rate", "(", "num_samples_per_epoch", ",", "global_step", ")", "\n", "opt", "=", "_configure_optimizer", "(", "learning_rate", ")", "\n", "\n", "######################", "\n", "# Select the network #", "\n", "######################", "\n", "is_training", "=", "tf", ".", "placeholder", "(", "tf", ".", "bool", ")", "\n", "\n", "network_speech_fn", "=", "nets_factory", ".", "get_network_fn", "(", "\n", "FLAGS", ".", "model_speech_name", ",", "\n", "num_classes", "=", "2", ",", "\n", "weight_decay", "=", "FLAGS", ".", "weight_decay", ",", "\n", "is_training", "=", "is_training", ")", "\n", "\n", "network_mouth_fn", "=", "nets_factory", ".", "get_network_fn", "(", "\n", "FLAGS", ".", "model_mouth_name", ",", "\n", "num_classes", "=", "2", ",", "\n", "weight_decay", "=", "FLAGS", ".", "weight_decay", ",", "\n", "is_training", "=", "is_training", ")", "\n", "\n", "#####################################", "\n", "# Select the preprocessing function #", "\n", "#####################################", "\n", "\n", "# TODO: Do some preprocessing if necessary.", "\n", "\n", "##############################################################", "\n", "# Create a dataset provider that loads data from the dataset #", "\n", "##############################################################", "\n", "# with tf.device(deploy_config.inputs_device()):", "\n", "\"\"\"\n        Define the place holders and creating the batch tensor.\n        \"\"\"", "\n", "\n", "# Mouth spatial set", "\n", "INPUT_SEQ_LENGTH", "=", "9", "\n", "INPUT_HEIGHT", "=", "60", "\n", "INPUT_WIDTH", "=", "100", "\n", "INPUT_CHANNELS", "=", "1", "\n", "batch_mouth", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "\n", "[", "None", ",", "INPUT_SEQ_LENGTH", ",", "INPUT_HEIGHT", ",", "INPUT_WIDTH", ",", "INPUT_CHANNELS", "]", ")", ")", "\n", "\n", "# Speech spatial set", "\n", "INPUT_SEQ_LENGTH_SPEECH", "=", "15", "\n", "INPUT_HEIGHT_SPEECH", "=", "40", "\n", "INPUT_WIDTH_SPEECH", "=", "1", "\n", "INPUT_CHANNELS_SPEECH", "=", "3", "\n", "batch_speech", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "\n", "[", "None", ",", "INPUT_SEQ_LENGTH_SPEECH", ",", "INPUT_HEIGHT_SPEECH", ",", "INPUT_WIDTH_SPEECH", ",", "INPUT_CHANNELS_SPEECH", "]", ")", ")", "\n", "\n", "# Label", "\n", "batch_labels", "=", "tf", ".", "placeholder", "(", "tf", ".", "uint8", ",", "(", "None", ",", "1", ")", ")", "\n", "margin_imp_tensor", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", ")", ")", "\n", "\n", "################################", "\n", "## Feed forwarding to network ##", "\n", "################################", "\n", "tower_grads", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "FLAGS", ".", "num_clones", ")", ":", "\n", "                ", "with", "tf", ".", "device", "(", "'/gpu:%d'", "%", "i", ")", ":", "\n", "                    ", "with", "tf", ".", "name_scope", "(", "'%s_%d'", "%", "(", "'tower'", ",", "i", ")", ")", "as", "scope", ":", "\n", "                        ", "\"\"\"\n                        Two distance metric are defined:\n                           1 - distance_weighted: which is a weighted average of the distance between two structures.\n                           2 - distance_l2: which is the regular l2-norm of the two networks outputs.\n                        Place holders\n\n                        \"\"\"", "\n", "########################################", "\n", "######## Outputs of two networks #######", "\n", "########################################", "\n", "\n", "logits_speech", ",", "end_points_speech", "=", "network_speech_fn", "(", "batch_speech", ")", "\n", "logits_mouth", ",", "end_points_mouth", "=", "network_mouth_fn", "(", "batch_mouth", ")", "\n", "\n", "# # Uncomment if the output embedding is desired to be as |f(x)| = 1", "\n", "# logits_speech = tf.nn.l2_normalize(logits_speech, dim=1, epsilon=1e-12, name=None)", "\n", "# logits_mouth = tf.nn.l2_normalize(logits_mouth, dim=1, epsilon=1e-12, name=None)", "\n", "\n", "#################################################", "\n", "########### Loss Calculation ####################", "\n", "#################################################", "\n", "\n", "# ##### Weighted distance using a fully connected layer #####", "\n", "# distance_vector = tf.subtract(logits_speech, logits_mouth,  name=None)", "\n", "# distance_weighted = slim.fully_connected(distance_vector, 1, activation_fn=tf.nn.sigmoid,", "\n", "#                                          normalizer_fn=None,", "\n", "#                                          scope='fc_weighted')", "\n", "\n", "##### Euclidean distance ####", "\n", "distance_l2", "=", "tf", ".", "sqrt", "(", "\n", "tf", ".", "reduce_sum", "(", "tf", ".", "pow", "(", "tf", ".", "subtract", "(", "logits_speech", ",", "logits_mouth", ")", ",", "2", ")", ",", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "\n", "##### Contrastive loss ######", "\n", "loss", "=", "losses", ".", "contrastive_loss", "(", "batch_labels", ",", "distance_l2", ",", "margin_imp", "=", "margin_imp_tensor", ",", "\n", "scope", "=", "scope", ")", "\n", "\n", "# ##### call the optimizer ######", "\n", "# # TODO: call optimizer object outside of this gpu environment", "\n", "#", "\n", "# Reuse variables for the next tower.", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "\n", "# Calculate the gradients for the batch of data on this CIFAR tower.", "\n", "grads", "=", "opt", ".", "compute_gradients", "(", "loss", ")", "\n", "\n", "# Keep track of the gradients across all towers.", "\n", "tower_grads", ".", "append", "(", "grads", ")", "\n", "\n", "\n", "# Calculate the mean of each gradient.", "\n", "", "", "", "", "grads", "=", "average_gradients", "(", "tower_grads", ")", "\n", "\n", "# Apply the gradients to adjust the shared variables.", "\n", "apply_gradient_op", "=", "opt", ".", "apply_gradients", "(", "grads", ",", "global_step", "=", "global_step", ")", "\n", "\n", "# Track the moving averages of all trainable variables.", "\n", "MOVING_AVERAGE_DECAY", "=", "0.9999", "\n", "variable_averages", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "\n", "MOVING_AVERAGE_DECAY", ",", "global_step", ")", "\n", "variables_averages_op", "=", "variable_averages", ".", "apply", "(", "tf", ".", "trainable_variables", "(", ")", ")", "\n", "\n", "# Group all updates to into a single train op.", "\n", "train_op", "=", "tf", ".", "group", "(", "apply_gradient_op", ",", "variables_averages_op", ")", "\n", "\n", "#################################################", "\n", "########### Summary Section #####################", "\n", "#################################################", "\n", "\n", "# Gather initial summaries.", "\n", "summaries", "=", "set", "(", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "SUMMARIES", ")", ")", "\n", "\n", "# Add summaries for all end_points.", "\n", "for", "end_point", "in", "end_points_speech", ":", "\n", "            ", "x", "=", "end_points_speech", "[", "end_point", "]", "\n", "# summaries.add(tf.summary.histogram('activations_speech/' + end_point, x))", "\n", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "scalar", "(", "'sparsity_speech/'", "+", "end_point", ",", "\n", "tf", ".", "nn", ".", "zero_fraction", "(", "x", ")", ")", ")", "\n", "\n", "", "for", "end_point", "in", "end_points_mouth", ":", "\n", "            ", "x", "=", "end_points_mouth", "[", "end_point", "]", "\n", "# summaries.add(tf.summary.histogram('activations_mouth/' + end_point, x))", "\n", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "scalar", "(", "'sparsity_mouth/'", "+", "end_point", ",", "\n", "tf", ".", "nn", ".", "zero_fraction", "(", "x", ")", ")", ")", "\n", "\n", "# Add summaries for variables.", "\n", "", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "            ", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", ")", "\n", "\n", "# Add to parameters to summaries", "\n", "", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate", ")", ")", "\n", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "scalar", "(", "'global_step'", ",", "global_step", ")", ")", "\n", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "scalar", "(", "'eval/Loss'", ",", "loss", ")", ")", "\n", "summaries", "|=", "set", "(", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "SUMMARIES", ")", ")", "\n", "\n", "# Merge all summaries together.", "\n", "summary_op", "=", "tf", ".", "summary", ".", "merge", "(", "list", "(", "summaries", ")", ",", "name", "=", "'summary_op'", ")", "\n", "\n", "###########################", "\n", "######## Training #########", "\n", "###########################", "\n", "\n", "", "with", "tf", ".", "Session", "(", "graph", "=", "graph", ",", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", ")", "as", "sess", ":", "\n", "\n", "# Initialization of the network.", "\n", "        ", "variables_to_restore", "=", "slim", ".", "get_variables_to_restore", "(", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "variables_to_restore", ",", "max_to_keep", "=", "20", ")", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "\n", "# # Restore the model", "\n", "# saver.restore(sess, '/home/sina/TRAIN_LIPREAD/train_logs-1366')", "\n", "\n", "# op to write logs to Tensorboard", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "FLAGS", ".", "train_dir", ",", "graph", "=", "graph", ")", "\n", "\n", "#####################################", "\n", "############## TRAIN ################", "\n", "#####################################", "\n", "\n", "step", "=", "1", "\n", "for", "epoch", "in", "range", "(", "FLAGS", ".", "num_epochs", ")", ":", "\n", "\n", "# Loop over all batches", "\n", "\n", "            ", "for", "batch_num", "in", "range", "(", "num_batches_per_epoch", ")", ":", "\n", "                ", "step", "+=", "1", "\n", "start_idx", "=", "batch_num", "*", "FLAGS", ".", "batch_size", "\n", "end_idx", "=", "(", "batch_num", "+", "1", ")", "*", "FLAGS", ".", "batch_size", "\n", "speech_train", ",", "mouth_train", ",", "label_train", "=", "train_data", "[", "'speech'", "]", "[", "start_idx", ":", "end_idx", "]", ",", "train_data", "[", "'mouth'", "]", "[", "\n", "start_idx", ":", "end_idx", "]", ",", "train_label", "[", "\n", "start_idx", ":", "end_idx", "]", "\n", "\n", "# # # Standardalization for speech if necessary", "\n", "# speech_train = (speech_train - mean_speech) / std_speech", "\n", "#", "\n", "# # # Standardalization  for visual if necessary", "\n", "# mouth_train = (mouth_train - mean_mouth) / std_mouth", "\n", "\n", "#########################################################################", "\n", "################## Online Pair Selection Algorithm ######################", "\n", "#########################################################################", "\n", "online_pair_selection", "=", "True", "\n", "if", "online_pair_selection", ":", "\n", "                    ", "distance", "=", "sess", ".", "run", "(", "\n", "distance_l2", ",", "\n", "feed_dict", "=", "{", "is_training", ":", "False", ",", "batch_speech", ":", "speech_train", ",", "\n", "batch_mouth", ":", "mouth_train", ",", "\n", "batch_labels", ":", "label_train", ".", "reshape", "(", "[", "FLAGS", ".", "batch_size", ",", "1", "]", ")", "}", ")", "\n", "label_keep", "=", "[", "]", "\n", "\n", "###############################", "\n", "hard_margin", "=", "10", "\n", "\n", "# Max-Min distance in genuines", "\n", "max_gen", "=", "0", "\n", "min_gen", "=", "100", "\n", "for", "j", "in", "range", "(", "label_train", ".", "shape", "[", "0", "]", ")", ":", "\n", "                        ", "if", "label_train", "[", "j", "]", "==", "1", ":", "\n", "                            ", "if", "max_gen", "<", "distance", "[", "j", ",", "0", "]", ":", "\n", "                                ", "max_gen", "=", "distance", "[", "j", ",", "0", "]", "\n", "", "if", "min_gen", ">", "distance", "[", "j", ",", "0", "]", ":", "\n", "                                ", "min_gen", "=", "distance", "[", "j", ",", "0", "]", "\n", "\n", "# Min-Max distance in impostors", "\n", "", "", "", "min_imp", "=", "100", "\n", "max_imp", "=", "0", "\n", "for", "k", "in", "range", "(", "label_train", ".", "shape", "[", "0", "]", ")", ":", "\n", "                        ", "if", "label_train", "[", "k", "]", "==", "0", ":", "\n", "                            ", "if", "min_imp", ">", "distance", "[", "k", ",", "0", "]", ":", "\n", "                                ", "min_imp", "=", "distance", "[", "k", ",", "0", "]", "\n", "", "if", "max_imp", "<", "distance", "[", "k", ",", "0", "]", ":", "\n", "                                ", "max_imp", "=", "distance", "[", "k", ",", "0", "]", "\n", "\n", "### Keeping hard impostors and genuines", "\n", "", "", "", "for", "i", "in", "range", "(", "label_train", ".", "shape", "[", "0", "]", ")", ":", "\n", "# imposter", "\n", "                        ", "if", "label_train", "[", "i", "]", "==", "0", ":", "\n", "                            ", "if", "distance", "[", "i", ",", "0", "]", "<", "max_gen", "+", "hard_margin", ":", "\n", "                                ", "label_keep", ".", "append", "(", "i", ")", "\n", "", "", "elif", "label_train", "[", "i", "]", "==", "1", ":", "\n", "# if distance[i, 0] > min_imp - hard_margin:", "\n", "                            ", "label_keep", ".", "append", "(", "i", ")", "\n", "\n", "#### Choosing the pairs ######", "\n", "", "", "speech_train", "=", "speech_train", "[", "label_keep", "]", "\n", "mouth_train", "=", "mouth_train", "[", "label_keep", "]", "\n", "label_train", "=", "label_train", "[", "label_keep", "]", "\n", "\n", "############################################", "\n", "#### Running the training operation ########", "\n", "", "_", ",", "loss_value", ",", "score_dissimilarity", ",", "summary", ",", "training_step", ",", "_", "=", "sess", ".", "run", "(", "\n", "[", "train_op", ",", "loss", ",", "distance_l2", ",", "summary_op", ",", "global_step", ",", "is_training", "]", ",", "\n", "feed_dict", "=", "{", "is_training", ":", "True", ",", "margin_imp_tensor", ":", "100", ",", "\n", "batch_speech", ":", "speech_train", ",", "batch_mouth", ":", "mouth_train", ",", "\n", "batch_labels", ":", "label_train", ".", "reshape", "(", "[", "label_train", ".", "shape", "[", "0", "]", ",", "1", "]", ")", "}", ")", "\n", "summary_writer", ".", "add_summary", "(", "summary", ",", "epoch", "*", "num_batches_per_epoch", "+", "i", ")", "\n", "\n", "# try and error method is used to handle the error due to ROC calculation", "\n", "try", ":", "\n", "# Calculation of ROC", "\n", "                    ", "EER", ",", "AUC", ",", "AP", ",", "fpr", ",", "tpr", "=", "calculate_roc", ".", "calculate_eer_auc_ap", "(", "label_train", ",", "score_dissimilarity", ")", "\n", "\n", "if", "(", "batch_num", "+", "1", ")", "%", "FLAGS", ".", "log_every_n_steps", "==", "0", ":", "\n", "                        ", "print", "(", "\"Epoch \"", "+", "str", "(", "epoch", "+", "1", ")", "+", "\", Minibatch \"", "+", "str", "(", "\n", "batch_num", "+", "1", ")", "+", "\" of %d \"", "%", "num_batches_per_epoch", "+", "\", Minibatch Loss= \"", "+", "\"{:.6f}\"", ".", "format", "(", "loss_value", ")", "+", "\", EER= \"", "+", "\"{:.5f}\"", ".", "format", "(", "EER", ")", "+", "\", AUC= \"", "+", "\"{:.5f}\"", ".", "format", "(", "\n", "AUC", ")", "+", "\", AP= \"", "+", "\"{:.5f}\"", ".", "format", "(", "AP", ")", "+", "\", contrib = %d pairs\"", "%", "label_train", ".", "shape", "[", "0", "]", ")", "\n", "", "", "except", ":", "\n", "                    ", "print", "(", "\"Error: \"", ",", "sys", ".", "exc_info", "(", ")", "[", "0", "]", ")", "\n", "print", "(", "\"No contributing impostor pair!\"", ")", "\n", "\n", "# Save the model", "\n", "", "", "saver", ".", "save", "(", "sess", ",", "FLAGS", ".", "train_dir", ",", "global_step", "=", "training_step", ")", "\n", "\n", "###################################################", "\n", "############## TEST PER EACH EPOCH ################", "\n", "###################################################", "\n", "score_dissimilarity_vector", "=", "np", ".", "zeros", "(", "(", "FLAGS", ".", "batch_size", "*", "num_batches_per_epoch_test", ",", "1", ")", ")", "\n", "label_vector", "=", "np", ".", "zeros", "(", "(", "FLAGS", ".", "batch_size", "*", "num_batches_per_epoch_test", ",", "1", ")", ")", "\n", "\n", "# Loop over all batches", "\n", "for", "i", "in", "range", "(", "num_batches_per_epoch_test", ")", ":", "\n", "                ", "start_idx", "=", "i", "*", "FLAGS", ".", "batch_size", "\n", "end_idx", "=", "(", "i", "+", "1", ")", "*", "FLAGS", ".", "batch_size", "\n", "speech_test", ",", "mouth_test", ",", "label_test", "=", "test_data", "[", "'speech'", "]", "[", "start_idx", ":", "end_idx", "]", ",", "test_data", "[", "'mouth'", "]", "[", "\n", "start_idx", ":", "end_idx", "]", ",", "test_label", "[", "\n", "start_idx", ":", "end_idx", "]", "\n", "\n", "# # # Uncomment if standardalization is needed", "\n", "# # mean subtraction if necessary", "\n", "# speech_test = (speech_test - mean_speech) / std_speech", "\n", "# mouth_test = (mouth_test - mean_mouth) / std_mouth", "\n", "\n", "# Evaluation phase", "\n", "# WARNING: margin_imp_tensor has no effect here but it needs to be there because its tensor required a value to feed in!!", "\n", "loss_value", ",", "score_dissimilarity", ",", "_", "=", "sess", ".", "run", "(", "[", "loss", ",", "distance_l2", ",", "is_training", "]", ",", "\n", "feed_dict", "=", "{", "is_training", ":", "False", ",", "\n", "margin_imp_tensor", ":", "50", ",", "\n", "batch_speech", ":", "speech_test", ",", "\n", "batch_mouth", ":", "mouth_test", ",", "\n", "batch_labels", ":", "label_test", ".", "reshape", "(", "\n", "[", "FLAGS", ".", "batch_size", ",", "1", "]", ")", "}", ")", "\n", "if", "(", "i", "+", "1", ")", "%", "FLAGS", ".", "log_every_n_steps", "==", "0", ":", "\n", "                    ", "print", "(", "\"TESTING: Epoch \"", "+", "str", "(", "epoch", "+", "1", ")", "+", "\", Minibatch \"", "+", "str", "(", "\n", "i", "+", "1", ")", "+", "\" of %d \"", "%", "num_batches_per_epoch_test", ")", "\n", "", "score_dissimilarity_vector", "[", "start_idx", ":", "end_idx", "]", "=", "score_dissimilarity", "\n", "label_vector", "[", "start_idx", ":", "end_idx", "]", "=", "label_test", "\n", "\n", "##############################", "\n", "##### K-fold validation ######", "\n", "##############################", "\n", "", "K", "=", "10", "\n", "EER", "=", "np", ".", "zeros", "(", "(", "K", ",", "1", ")", ")", "\n", "AUC", "=", "np", ".", "zeros", "(", "(", "K", ",", "1", ")", ")", "\n", "AP", "=", "np", ".", "zeros", "(", "(", "K", ",", "1", ")", ")", "\n", "batch_k_validation", "=", "int", "(", "label_vector", ".", "shape", "[", "0", "]", "/", "float", "(", "K", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "K", ")", ":", "\n", "                ", "EER", "[", "i", ",", ":", "]", ",", "AUC", "[", "i", ",", ":", "]", ",", "AP", "[", "i", ",", ":", "]", ",", "fpr", ",", "tpr", "=", "calculate_roc", ".", "calculate_eer_auc_ap", "(", "\n", "label_vector", "[", "i", "*", "batch_k_validation", ":", "(", "i", "+", "1", ")", "*", "batch_k_validation", "]", ",", "\n", "score_dissimilarity_vector", "[", "i", "*", "batch_k_validation", ":", "(", "i", "+", "1", ")", "*", "batch_k_validation", "]", ")", "\n", "\n", "# Printing Equal Error Rate(EER), Area Under the Curve(AUC) and Average Precision(AP)", "\n", "", "print", "(", "\"TESTING: Epoch \"", "+", "str", "(", "epoch", "+", "1", ")", "+", "\", EER= \"", "+", "str", "(", "np", ".", "mean", "(", "EER", ",", "axis", "=", "0", ")", ")", "+", "\", AUC= \"", "+", "str", "(", "\n", "np", ".", "mean", "(", "AUC", ",", "axis", "=", "0", ")", ")", "+", "\", AP= \"", "+", "str", "(", "np", ".", "mean", "(", "AP", ",", "axis", "=", "0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.training_evaluation.test._configure_learning_rate": [[152, 190], ["int", "tensorflow.train.exponential_decay", "tensorflow.constant", "tensorflow.train.polynomial_decay", "ValueError"], "function", ["None"], ["def", "_configure_learning_rate", "(", "num_samples_per_epoch", ",", "global_step", ")", ":", "\n", "    ", "\"\"\"Configures the learning rate.\n\n    Args:\n      num_samples_per_epoch: The number of samples in each epoch of training.\n      global_step: The global_step tensor.\n\n    Returns:\n      A `Tensor` representing the learning rate.\n\n    Raises:\n      ValueError: if\n    \"\"\"", "\n", "decay_steps", "=", "int", "(", "num_samples_per_epoch", "/", "FLAGS", ".", "batch_size", "*", "\n", "FLAGS", ".", "num_epochs_per_decay", ")", "\n", "if", "FLAGS", ".", "sync_replicas", ":", "\n", "        ", "decay_steps", "/=", "FLAGS", ".", "replicas_to_aggregate", "\n", "\n", "", "if", "FLAGS", ".", "learning_rate_decay_type", "==", "'exponential'", ":", "\n", "        ", "return", "tf", ".", "train", ".", "exponential_decay", "(", "FLAGS", ".", "learning_rate", ",", "\n", "global_step", ",", "\n", "decay_steps", ",", "\n", "FLAGS", ".", "learning_rate_decay_factor", ",", "\n", "staircase", "=", "True", ",", "\n", "name", "=", "'exponential_decay_learning_rate'", ")", "\n", "", "elif", "FLAGS", ".", "learning_rate_decay_type", "==", "'fixed'", ":", "\n", "        ", "return", "tf", ".", "constant", "(", "FLAGS", ".", "learning_rate", ",", "name", "=", "'fixed_learning_rate'", ")", "\n", "", "elif", "FLAGS", ".", "learning_rate_decay_type", "==", "'polynomial'", ":", "\n", "        ", "return", "tf", ".", "train", ".", "polynomial_decay", "(", "FLAGS", ".", "learning_rate", ",", "\n", "global_step", ",", "\n", "decay_steps", ",", "\n", "FLAGS", ".", "end_learning_rate", ",", "\n", "power", "=", "1.0", ",", "\n", "cycle", "=", "False", ",", "\n", "name", "=", "'polynomial_decay_learning_rate'", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'learning_rate_decay_type [%s] was not recognized'", ",", "\n", "FLAGS", ".", "learning_rate_decay_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.training_evaluation.test._configure_optimizer": [[192, 216], ["tensorflow.train.AdamOptimizer", "tensorflow.train.GradientDescentOptimizer", "ValueError"], "function", ["None"], ["", "", "def", "_configure_optimizer", "(", "learning_rate", ")", ":", "\n", "    ", "\"\"\"Configures the optimizer used for training.\n\n    Args:\n      learning_rate: A scalar or `Tensor` learning rate.\n\n    Returns:\n      An instance of an optimizer.\n\n    Raises:\n      ValueError: if FLAGS.optimizer is not recognized.\n    \"\"\"", "\n", "\n", "if", "FLAGS", ".", "optimizer", "==", "'adam'", ":", "\n", "        ", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "\n", "learning_rate", ",", "\n", "beta1", "=", "FLAGS", ".", "adam_beta1", ",", "\n", "beta2", "=", "FLAGS", ".", "adam_beta2", ",", "\n", "epsilon", "=", "FLAGS", ".", "opt_epsilon", ")", "\n", "", "elif", "FLAGS", ".", "optimizer", "==", "'sgd'", ":", "\n", "        ", "optimizer", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "learning_rate", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Optimizer [%s] was not recognized'", ",", "FLAGS", ".", "optimizer", ")", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.training_evaluation.test.average_gradients": [[218, 254], ["zip", "tensorflow.concat", "tensorflow.reduce_mean", "average_grads.append", "tensorflow.expand_dims", "grads.append"], "function", ["None"], ["", "def", "average_gradients", "(", "tower_grads", ")", ":", "\n", "    ", "\"\"\"Calculate the average gradient for each shared variable across all towers.\n\n    Note that this function provides a synchronization point across all towers.\n\n    Args:\n      tower_grads: List of lists of (gradient, variable) tuples. The outer list\n        is over individual gradients. The inner list is over the gradient\n        calculation for each tower.\n    Returns:\n       List of pairs of (gradient, variable) where the gradient has been averaged\n       across all towers.\n    \"\"\"", "\n", "average_grads", "=", "[", "]", "\n", "for", "grad_and_vars", "in", "zip", "(", "*", "tower_grads", ")", ":", "\n", "# Note that each grad_and_vars looks like the following:", "\n", "#   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))", "\n", "        ", "grads", "=", "[", "]", "\n", "for", "g", ",", "_", "in", "grad_and_vars", ":", "\n", "# Add 0 dimension to the gradients to represent the tower.", "\n", "            ", "expanded_g", "=", "tf", ".", "expand_dims", "(", "g", ",", "0", ")", "\n", "\n", "# Append on a 'tower' dimension which we will average over below.", "\n", "grads", ".", "append", "(", "expanded_g", ")", "\n", "\n", "# Average over the 'tower' dimension.", "\n", "", "grad", "=", "tf", ".", "concat", "(", "axis", "=", "0", ",", "values", "=", "grads", ")", "\n", "grad", "=", "tf", ".", "reduce_mean", "(", "grad", ",", "0", ")", "\n", "\n", "# Keep in mind that the Variables are redundant because they are shared", "\n", "# across towers. So .. we will just return the first tower's pointer to", "\n", "# the Variable.", "\n", "v", "=", "grad_and_vars", "[", "0", "]", "[", "1", "]", "\n", "grad_and_var", "=", "(", "grad", ",", "v", ")", "\n", "average_grads", ".", "append", "(", "grad_and_var", ")", "\n", "", "return", "average_grads", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.training_evaluation.test._get_variables_to_train": [[256, 272], ["tensorflow.trainable_variables", "tensorflow.get_collection", "variables_to_train.extend", "scope.strip", "FLAGS.trainable_scopes.split"], "function", ["None"], ["", "def", "_get_variables_to_train", "(", ")", ":", "\n", "    ", "\"\"\"Returns a list of variables to train.\n\n    Returns:\n      A list of variables to train by the optimizer.\n    \"\"\"", "\n", "if", "FLAGS", ".", "trainable_scopes", "is", "None", ":", "\n", "        ", "return", "tf", ".", "trainable_variables", "(", ")", "\n", "", "else", ":", "\n", "        ", "scopes", "=", "[", "scope", ".", "strip", "(", ")", "for", "scope", "in", "FLAGS", ".", "trainable_scopes", ".", "split", "(", "','", ")", "]", "\n", "\n", "", "variables_to_train", "=", "[", "]", "\n", "for", "scope", "in", "scopes", ":", "\n", "        ", "variables", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "scope", ")", "\n", "variables_to_train", ".", "extend", "(", "variables", ")", "\n", "", "return", "variables_to_train", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.training_evaluation.test.main": [[317, 570], ["tensorflow.logging.set_verbosity", "tensorflow.Graph", "tf.Graph.as_default", "tensorflow.device", "int", "int", "tensorflow.Variable", "test._configure_learning_rate", "test._configure_optimizer", "tensorflow.placeholder", "nets.nets_factory.get_network_fn", "nets.nets_factory.get_network_fn", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "test.average_gradients", "_configure_optimizer.apply_gradients", "tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.apply", "tensorflow.group", "set", "slim.get_model_variables", "set.add", "set.add", "set", "tensorflow.summary.merge", "tensorflow.Session", "slim.get_variables_to_restore", "tensorflow.train.Saver", "tensorflow.train.Coordinator", "sess.run", "sess.run", "print", "tensorflow.train.latest_checkpoint", "tf.train.Saver.restore", "tensorflow.summary.FileWriter", "numpy.zeros", "numpy.zeros", "range", "numpy.zeros", "numpy.zeros", "numpy.zeros", "int", "range", "print", "tensorflow.variable_scope", "tensorflow.trainable_variables", "tensorflow.get_collection", "set.add", "set.add", "set.add", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.get_collection", "list", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "sess.run", "roc_curve.calculate_roc.calculate_eer_auc_ap", "tensorflow.get_variable_scope", "tensorflow.device", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.histogram", "tensorflow.ConfigProto", "print", "float", "str", "tensorflow.name_scope", "nets_factory.get_network_fn.", "nets_factory.get_network_fn.", "tensorflow.sqrt", "auxiliary.losses.contrastive_loss", "tensorflow.get_variable_scope().reuse_variables", "_configure_optimizer.compute_gradients", "tower_grads.append", "tensorflow.nn.zero_fraction", "tensorflow.nn.zero_fraction", "numpy.mean", "tensorflow.reduce_sum", "label_test.reshape", "str", "tensorflow.pow", "tensorflow.get_variable_scope", "str", "numpy.mean", "tensorflow.subtract", "str", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.training_evaluation.test._configure_learning_rate", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.training_evaluation.test._configure_optimizer", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.__init__.get_network_fn", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.__init__.get_network_fn", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.training_evaluation.test.average_gradients", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.roc_curve.calculate_roc.calculate_eer_auc_ap", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.auxiliary.losses.contrastive_loss"], ["def", "main", "(", "_", ")", ":", "\n", "\n", "\n", "    ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "graph", ".", "as_default", "(", ")", ",", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "######################", "\n", "# Config model_deploy#", "\n", "######################", "\n", "\n", "# required from data", "\n", "        ", "num_samples_per_epoch", "=", "train_data", "[", "'mouth'", "]", ".", "shape", "[", "0", "]", "\n", "num_batches_per_epoch", "=", "int", "(", "num_samples_per_epoch", "/", "FLAGS", ".", "batch_size", ")", "\n", "\n", "num_samples_per_epoch_test", "=", "test_data", "[", "'mouth'", "]", ".", "shape", "[", "0", "]", "\n", "num_batches_per_epoch_test", "=", "int", "(", "num_samples_per_epoch_test", "/", "FLAGS", ".", "batch_size", ")", "\n", "\n", "# Create global_step", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "'global_step'", ",", "trainable", "=", "False", ")", "\n", "\n", "#########################################", "\n", "# Configure the larning rate. #", "\n", "#########################################", "\n", "learning_rate", "=", "_configure_learning_rate", "(", "num_samples_per_epoch", ",", "global_step", ")", "\n", "opt", "=", "_configure_optimizer", "(", "learning_rate", ")", "\n", "\n", "######################", "\n", "# Select the network #", "\n", "######################", "\n", "is_training", "=", "tf", ".", "placeholder", "(", "tf", ".", "bool", ")", "\n", "\n", "network_speech_fn", "=", "nets_factory", ".", "get_network_fn", "(", "\n", "FLAGS", ".", "model_speech_name", ",", "\n", "num_classes", "=", "2", ",", "\n", "weight_decay", "=", "FLAGS", ".", "weight_decay", ",", "\n", "is_training", "=", "is_training", ")", "\n", "\n", "network_mouth_fn", "=", "nets_factory", ".", "get_network_fn", "(", "\n", "FLAGS", ".", "model_mouth_name", ",", "\n", "num_classes", "=", "2", ",", "\n", "weight_decay", "=", "FLAGS", ".", "weight_decay", ",", "\n", "is_training", "=", "is_training", ")", "\n", "\n", "#####################################", "\n", "# Select the preprocessing function #", "\n", "#####################################", "\n", "\n", "# TODO: Do some preprocessing if necessary.", "\n", "\n", "##############################################################", "\n", "# Create a dataset provider that loads data from the dataset #", "\n", "##############################################################", "\n", "# with tf.device(deploy_config.inputs_device()):", "\n", "\"\"\"\n        Define the place holders and creating the batch tensor.\n        \"\"\"", "\n", "\n", "# Mouth spatial set", "\n", "INPUT_SEQ_LENGTH", "=", "9", "\n", "INPUT_HEIGHT", "=", "60", "\n", "INPUT_WIDTH", "=", "100", "\n", "INPUT_CHANNELS", "=", "1", "\n", "batch_mouth", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "\n", "[", "None", ",", "INPUT_SEQ_LENGTH", ",", "INPUT_HEIGHT", ",", "INPUT_WIDTH", ",", "INPUT_CHANNELS", "]", ")", ")", "\n", "\n", "# Speech spatial set", "\n", "INPUT_SEQ_LENGTH_SPEECH", "=", "15", "\n", "INPUT_HEIGHT_SPEECH", "=", "40", "\n", "INPUT_WIDTH_SPEECH", "=", "1", "\n", "INPUT_CHANNELS_SPEECH", "=", "3", "\n", "batch_speech", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "\n", "[", "None", ",", "INPUT_SEQ_LENGTH_SPEECH", ",", "INPUT_HEIGHT_SPEECH", ",", "INPUT_WIDTH_SPEECH", ",", "INPUT_CHANNELS_SPEECH", "]", ")", ")", "\n", "\n", "# Label", "\n", "batch_labels", "=", "tf", ".", "placeholder", "(", "tf", ".", "uint8", ",", "(", "None", ",", "1", ")", ")", "\n", "margin_imp_tensor", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", ")", ")", "\n", "\n", "################################", "\n", "## Feed forwarding to network ##", "\n", "################################", "\n", "tower_grads", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "'/gpu:%d'", "%", "0", ")", ":", "\n", "                ", "with", "tf", ".", "name_scope", "(", "'%s_%d'", "%", "(", "'tower'", ",", "0", ")", ")", "as", "scope", ":", "\n", "                    ", "\"\"\"\n                    Two distance metric are defined:\n                       1 - distance_weighted: which is a weighted average of the distance between two structures.\n                       2 - distance_l2: which is the regular l2-norm of the two networks outputs.\n                    Place holders\n\n                    \"\"\"", "\n", "########################################", "\n", "######## Outputs of two networks #######", "\n", "########################################", "\n", "\n", "logits_speech", ",", "end_points_speech", "=", "network_speech_fn", "(", "batch_speech", ")", "\n", "logits_mouth", ",", "end_points_mouth", "=", "network_mouth_fn", "(", "batch_mouth", ")", "\n", "\n", "# # Uncomment if the output embedding is desired to be as |f(x)| = 1", "\n", "# logits_speech = tf.nn.l2_normalize(logits_speech, dim=1, epsilon=1e-12, name=None)", "\n", "# logits_mouth = tf.nn.l2_normalize(logits_mouth, dim=1, epsilon=1e-12, name=None)", "\n", "\n", "#################################################", "\n", "########### Loss Calculation ####################", "\n", "#################################################", "\n", "\n", "# ##### Weighted distance using a fully connected layer #####", "\n", "# distance_vector = tf.subtract(logits_speech, logits_mouth,  name=None)", "\n", "# distance_weighted = slim.fully_connected(distance_vector, 1, activation_fn=tf.nn.sigmoid,", "\n", "#                                          normalizer_fn=None,", "\n", "#                                          scope='fc_weighted')", "\n", "\n", "##### Euclidean distance ####", "\n", "distance_l2", "=", "tf", ".", "sqrt", "(", "\n", "tf", ".", "reduce_sum", "(", "tf", ".", "pow", "(", "tf", ".", "subtract", "(", "logits_speech", ",", "logits_mouth", ")", ",", "2", ")", ",", "1", ",", "keep_dims", "=", "True", ")", ")", "\n", "\n", "##### Contrastive loss ######", "\n", "loss", "=", "losses", ".", "contrastive_loss", "(", "batch_labels", ",", "distance_l2", ",", "margin_imp", "=", "margin_imp_tensor", ",", "\n", "scope", "=", "scope", ")", "\n", "\n", "# ##### call the optimizer ######", "\n", "# # TODO: call optimizer object outside of this gpu environment", "\n", "#", "\n", "# Reuse variables for the next tower.", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "\n", "# Calculate the gradients for the batch of data on this CIFAR tower.", "\n", "grads", "=", "opt", ".", "compute_gradients", "(", "loss", ")", "\n", "\n", "# Keep track of the gradients across all towers.", "\n", "tower_grads", ".", "append", "(", "grads", ")", "\n", "\n", "\n", "# Calculate the mean of each gradient.", "\n", "", "", "", "grads", "=", "average_gradients", "(", "tower_grads", ")", "\n", "\n", "# Apply the gradients to adjust the shared variables.", "\n", "apply_gradient_op", "=", "opt", ".", "apply_gradients", "(", "grads", ",", "global_step", "=", "global_step", ")", "\n", "\n", "# Track the moving averages of all trainable variables.", "\n", "MOVING_AVERAGE_DECAY", "=", "0.9999", "\n", "variable_averages", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "\n", "MOVING_AVERAGE_DECAY", ",", "global_step", ")", "\n", "variables_averages_op", "=", "variable_averages", ".", "apply", "(", "tf", ".", "trainable_variables", "(", ")", ")", "\n", "\n", "# Group all updates to into a single train op.", "\n", "train_op", "=", "tf", ".", "group", "(", "apply_gradient_op", ",", "variables_averages_op", ")", "\n", "\n", "#################################################", "\n", "########### Summary Section #####################", "\n", "#################################################", "\n", "\n", "# Gather initial summaries.", "\n", "summaries", "=", "set", "(", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "SUMMARIES", ")", ")", "\n", "\n", "# Add summaries for all end_points.", "\n", "for", "end_point", "in", "end_points_speech", ":", "\n", "            ", "x", "=", "end_points_speech", "[", "end_point", "]", "\n", "# summaries.add(tf.summary.histogram('activations_speech/' + end_point, x))", "\n", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "scalar", "(", "'sparsity_speech/'", "+", "end_point", ",", "\n", "tf", ".", "nn", ".", "zero_fraction", "(", "x", ")", ")", ")", "\n", "\n", "", "for", "end_point", "in", "end_points_mouth", ":", "\n", "            ", "x", "=", "end_points_mouth", "[", "end_point", "]", "\n", "# summaries.add(tf.summary.histogram('activations_mouth/' + end_point, x))", "\n", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "scalar", "(", "'sparsity_mouth/'", "+", "end_point", ",", "\n", "tf", ".", "nn", ".", "zero_fraction", "(", "x", ")", ")", ")", "\n", "\n", "# Add summaries for variables.", "\n", "", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "            ", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", ")", "\n", "\n", "# Add to parameters to summaries", "\n", "", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate", ")", ")", "\n", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "scalar", "(", "'eval/Loss'", ",", "loss", ")", ")", "\n", "summaries", "|=", "set", "(", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "SUMMARIES", ")", ")", "\n", "\n", "# Merge all summaries together.", "\n", "summary_op", "=", "tf", ".", "summary", ".", "merge", "(", "list", "(", "summaries", ")", ",", "name", "=", "'summary_op'", ")", "\n", "\n", "###########################", "\n", "######## Training #########", "\n", "###########################", "\n", "\n", "", "with", "tf", ".", "Session", "(", "graph", "=", "graph", ",", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", ")", "as", "sess", ":", "\n", "\n", "# Initialization of the network.", "\n", "        ", "variables_to_restore", "=", "slim", ".", "get_variables_to_restore", "(", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "variables_to_restore", ",", "max_to_keep", "=", "20", ")", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "\n", "# Restore the model", "\n", "print", "(", "'Loading from:'", ",", "FLAGS", ".", "checkpoint_dir", ")", "\n", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "checkpoint_dir", "=", "FLAGS", ".", "checkpoint_dir", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "latest_checkpoint", ")", "\n", "\n", "# op to write logs to Tensorboard", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "FLAGS", ".", "test_dir", ",", "graph", "=", "graph", ")", "\n", "\n", "###################################################", "\n", "############################ TEST  ################", "\n", "###################################################", "\n", "score_dissimilarity_vector", "=", "np", ".", "zeros", "(", "(", "FLAGS", ".", "batch_size", "*", "num_batches_per_epoch_test", ",", "1", ")", ")", "\n", "label_vector", "=", "np", ".", "zeros", "(", "(", "FLAGS", ".", "batch_size", "*", "num_batches_per_epoch_test", ",", "1", ")", ")", "\n", "\n", "# Loop over all batches", "\n", "for", "i", "in", "range", "(", "num_batches_per_epoch_test", ")", ":", "\n", "            ", "start_idx", "=", "i", "*", "FLAGS", ".", "batch_size", "\n", "end_idx", "=", "(", "i", "+", "1", ")", "*", "FLAGS", ".", "batch_size", "\n", "speech_test", ",", "mouth_test", ",", "label_test", "=", "test_data", "[", "'speech'", "]", "[", "start_idx", ":", "end_idx", "]", ",", "test_data", "[", "'mouth'", "]", "[", "\n", "start_idx", ":", "end_idx", "]", ",", "test_label", "[", "\n", "start_idx", ":", "end_idx", "]", "\n", "\n", "# # # Uncomment if standardalization is needed", "\n", "# # mean subtraction if necessary", "\n", "# speech_test = (speech_test - mean_speech) / std_speech", "\n", "# mouth_test = (mouth_test - mean_mouth) / std_mouth", "\n", "\n", "# Evaluation phase", "\n", "# WARNING: margin_imp_tensor has no effect here but it needs to be there because its tensor required a value to feed in!!", "\n", "loss_value", ",", "score_dissimilarity", ",", "_", "=", "sess", ".", "run", "(", "[", "loss", ",", "distance_l2", ",", "is_training", "]", ",", "\n", "feed_dict", "=", "{", "is_training", ":", "False", ",", "\n", "margin_imp_tensor", ":", "50", ",", "\n", "batch_speech", ":", "speech_test", ",", "\n", "batch_mouth", ":", "mouth_test", ",", "\n", "batch_labels", ":", "label_test", ".", "reshape", "(", "\n", "[", "FLAGS", ".", "batch_size", ",", "1", "]", ")", "}", ")", "\n", "if", "(", "i", "+", "1", ")", "%", "FLAGS", ".", "log_every_n_steps", "==", "0", ":", "\n", "                ", "print", "(", "\"TESTING:\"", "+", "\", Minibatch \"", "+", "str", "(", "\n", "i", "+", "1", ")", "+", "\" of %d \"", "%", "num_batches_per_epoch_test", ")", "\n", "", "score_dissimilarity_vector", "[", "start_idx", ":", "end_idx", "]", "=", "score_dissimilarity", "\n", "label_vector", "[", "start_idx", ":", "end_idx", "]", "=", "label_test", "\n", "\n", "##############################", "\n", "##### K-fold validation ######", "\n", "##############################", "\n", "", "K", "=", "10", "\n", "EER", "=", "np", ".", "zeros", "(", "(", "K", ",", "1", ")", ")", "\n", "AUC", "=", "np", ".", "zeros", "(", "(", "K", ",", "1", ")", ")", "\n", "AP", "=", "np", ".", "zeros", "(", "(", "K", ",", "1", ")", ")", "\n", "batch_k_validation", "=", "int", "(", "label_vector", ".", "shape", "[", "0", "]", "/", "float", "(", "K", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "K", ")", ":", "\n", "            ", "EER", "[", "i", ",", ":", "]", ",", "AUC", "[", "i", ",", ":", "]", ",", "AP", "[", "i", ",", ":", "]", ",", "fpr", ",", "tpr", "=", "calculate_roc", ".", "calculate_eer_auc_ap", "(", "\n", "label_vector", "[", "i", "*", "batch_k_validation", ":", "(", "i", "+", "1", ")", "*", "batch_k_validation", "]", ",", "\n", "score_dissimilarity_vector", "[", "i", "*", "batch_k_validation", ":", "(", "i", "+", "1", ")", "*", "batch_k_validation", "]", ")", "\n", "\n", "# Printing Equal Error Rate(EER), Area Under the Curve(AUC) and Average Precision(AP)", "\n", "", "print", "(", "\"TESTING:\"", "+", "\", EER= \"", "+", "str", "(", "np", ".", "mean", "(", "EER", ",", "axis", "=", "0", ")", ")", "+", "\", AUC= \"", "+", "str", "(", "\n", "np", ".", "mean", "(", "AUC", ",", "axis", "=", "0", ")", ")", "+", "\", AP= \"", "+", "str", "(", "np", ".", "mean", "(", "AP", ",", "axis", "=", "0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.auxiliary.losses.contrastive_loss": [[41, 64], ["tensorflow.python.framework.ops.name_scope", "tensorflow.python.ops.math_ops.cast", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.losses.compute_weighted_loss", "tensorflow.square", "tensorflow.square", "tensorflow.add", "tensorflow.maximum", "tensorflow.maximum"], "function", ["None"], ["def", "contrastive_loss", "(", "labels", ",", "logits", ",", "margin_gen", "=", "0", ",", "margin_imp", "=", "1", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"With this definition the loss will be calculated.\n        Args:\n          y: The labels.\n          distance: The distance vector between the output features..\n          batch_size: the batch size is necessary because the loss calculation would be over each batch.\n        Returns:\n          The total loss.\n    \"\"\"", "\n", "with", "ops", ".", "name_scope", "(", "scope", ",", "\"contrastive_loss\"", ",", "[", "labels", ",", "logits", "]", ")", "as", "scope", ":", "\n", "# logits.get_shape().assert_is_compatible_with(onehot_labels.get_shape())", "\n", "\n", "        ", "labels", "=", "math_ops", ".", "cast", "(", "labels", ",", "logits", ".", "dtype", ")", "\n", "\n", "# term_1 = tf.multiply(labels, tf.square(logits))", "\n", "term_1", "=", "tf", ".", "multiply", "(", "labels", ",", "tf", ".", "square", "(", "tf", ".", "maximum", "(", "(", "logits", "-", "margin_gen", ")", ",", "0", ")", ")", ")", "\n", "term_2", "=", "tf", ".", "multiply", "(", "1", "-", "labels", ",", "tf", ".", "square", "(", "tf", ".", "maximum", "(", "(", "margin_imp", "-", "logits", ")", ",", "0", ")", ")", ")", "\n", "\n", "# Contrastive", "\n", "Contrastive_Loss", "=", "tf", ".", "add", "(", "term_1", ",", "term_2", ")", "/", "2", "\n", "loss", "=", "tf", ".", "losses", ".", "compute_weighted_loss", "(", "Contrastive_Loss", ",", "scope", "=", "scope", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.roc_curve.PlotROC.Plot_ROC_Fn": [[15, 56], ["metrics.roc_curve", "metrics.roc_auc_score", "print", "print", "matplotlib.figure", "plt.figure.gca", "matplotlib.plot", "matplotlib.setp", "fig.gca.set_xticks", "fig.gca.set_yticks", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.grid", "matplotlib.show", "plt.figure.savefig", "float", "float", "numpy.arange", "numpy.arange", "numpy.abs().argmin", "numpy.abs"], "function", ["None"], ["def", "Plot_ROC_Fn", "(", "label", ",", "distance", ",", "phase", ")", ":", "\n", "\n", "    ", "fpr", ",", "tpr", ",", "thresholds", "=", "metrics", ".", "roc_curve", "(", "label", ",", "-", "distance", ",", "pos_label", "=", "1", ")", "\n", "AUC", "=", "metrics", ".", "roc_auc_score", "(", "label", ",", "-", "distance", ",", "average", "=", "'macro'", ",", "sample_weight", "=", "None", ")", "\n", "# AP = metrics.average_precision_score(label, -distance, average='macro', sample_weight=None)", "\n", "\n", "# Calculating EER", "\n", "intersect_x", "=", "fpr", "[", "np", ".", "abs", "(", "fpr", "-", "(", "1", "-", "tpr", ")", ")", ".", "argmin", "(", "0", ")", "]", "\n", "EER", "=", "intersect_x", "\n", "print", "(", "\"EER = \"", ",", "float", "(", "(", "\"{0:.%ie}\"", "%", "1", ")", ".", "format", "(", "intersect_x", ")", ")", ")", "\n", "\n", "# AUC(area under the curve) calculation", "\n", "print", "(", "\"AUC = \"", ",", "float", "(", "(", "\"{0:.%ie}\"", "%", "1", ")", ".", "format", "(", "AUC", ")", ")", ")", "\n", "\n", "# # AP(average precision) calculation.", "\n", "# # This score corresponds to the area under the precision-recall curve.", "\n", "# print(\"AP = \", float((\"{0:.%ie}\" % 1).format(AP)))", "\n", "\n", "# Plot the ROC", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax", "=", "fig", ".", "gca", "(", ")", "\n", "lines", "=", "plt", ".", "plot", "(", "fpr", ",", "tpr", ",", "label", "=", "'ROC Curve'", ")", "\n", "plt", ".", "setp", "(", "lines", ",", "linewidth", "=", "2", ",", "color", "=", "'r'", ")", "\n", "ax", ".", "set_xticks", "(", "np", ".", "arange", "(", "0", ",", "1.1", ",", "0.1", ")", ")", "\n", "ax", ".", "set_yticks", "(", "np", ".", "arange", "(", "0", ",", "1.1", ",", "0.1", ")", ")", "\n", "plt", ".", "title", "(", "phase", "+", "'_'", "+", "'ROC.jpg'", ")", "\n", "plt", ".", "xlabel", "(", "'False Positive Rate'", ")", "\n", "plt", ".", "ylabel", "(", "'True Positive Rate'", ")", "\n", "\n", "# # Cutting the floating number", "\n", "# AUC = '%.2f' % AUC", "\n", "# EER = '%.2f' % EER", "\n", "# # AP = '%.2f' % AP", "\n", "#", "\n", "# # Setting text to plot", "\n", "# # plt.text(0.5, 0.6, 'AP = ' + str(AP), fontdict=None)", "\n", "# plt.text(0.5, 0.5, 'AUC = ' + str(AUC), fontdict=None)", "\n", "# plt.text(0.5, 0.4, 'EER = ' + str(EER), fontdict=None)", "\n", "plt", ".", "grid", "(", ")", "\n", "plt", ".", "show", "(", ")", "\n", "fig", ".", "savefig", "(", "phase", "+", "'_'", "+", "'ROC.jpg'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.roc_curve.calculate_roc.calculate_eer_auc_ap": [[13, 24], ["metrics.roc_curve", "metrics.roc_auc_score", "metrics.average_precision_score", "numpy.abs().argmin", "numpy.abs"], "function", ["None"], ["def", "calculate_eer_auc_ap", "(", "label", ",", "distance", ")", ":", "\n", "\n", "    ", "fpr", ",", "tpr", ",", "thresholds", "=", "metrics", ".", "roc_curve", "(", "label", ",", "-", "distance", ",", "pos_label", "=", "1", ")", "\n", "AUC", "=", "metrics", ".", "roc_auc_score", "(", "label", ",", "-", "distance", ",", "average", "=", "'macro'", ",", "sample_weight", "=", "None", ")", "\n", "AP", "=", "metrics", ".", "average_precision_score", "(", "label", ",", "-", "distance", ",", "average", "=", "'macro'", ",", "sample_weight", "=", "None", ")", "\n", "\n", "# Calculating EER", "\n", "intersect_x", "=", "fpr", "[", "np", ".", "abs", "(", "fpr", "-", "(", "1", "-", "tpr", ")", ")", ".", "argmin", "(", "0", ")", "]", "\n", "EER", "=", "intersect_x", "\n", "\n", "return", "EER", ",", "AUC", ",", "AP", ",", "fpr", ",", "tpr", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.roc_curve.PlotPR.Plot_PR_Fn": [[14, 42], ["metrics.precision_recall_curve", "metrics.average_precision_score", "print", "matplotlib.figure", "plt.figure.gca", "matplotlib.plot", "matplotlib.setp", "fig.gca.set_xticks", "fig.gca.set_yticks", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.grid", "matplotlib.show", "plt.figure.savefig", "float", "numpy.arange", "numpy.arange"], "function", ["None"], ["def", "Plot_PR_Fn", "(", "label", ",", "distance", ",", "phase", ")", ":", "\n", "\n", "    ", "precision", ",", "recall", ",", "thresholds", "=", "metrics", ".", "precision_recall_curve", "(", "label", ",", "-", "distance", ",", "pos_label", "=", "1", ",", "sample_weight", "=", "None", ")", "\n", "AP", "=", "metrics", ".", "average_precision_score", "(", "label", ",", "-", "distance", ",", "average", "=", "'macro'", ",", "sample_weight", "=", "None", ")", "\n", "\n", "# AP(average precision) calculation.", "\n", "# This score corresponds to the area under the precision-recall curve.", "\n", "print", "(", "\"AP = \"", ",", "float", "(", "(", "\"{0:.%ie}\"", "%", "1", ")", ".", "format", "(", "AP", ")", ")", ")", "\n", "\n", "# Plot the ROC", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax", "=", "fig", ".", "gca", "(", ")", "\n", "lines", "=", "plt", ".", "plot", "(", "recall", ",", "precision", ",", "label", "=", "'ROC Curve'", ")", "\n", "plt", ".", "setp", "(", "lines", ",", "linewidth", "=", "2", ",", "color", "=", "'r'", ")", "\n", "ax", ".", "set_xticks", "(", "np", ".", "arange", "(", "0", ",", "1.1", ",", "0.1", ")", ")", "\n", "ax", ".", "set_yticks", "(", "np", ".", "arange", "(", "0", ",", "1.1", ",", "0.1", ")", ")", "\n", "plt", ".", "title", "(", "phase", "+", "'_'", "+", "'PR.jpg'", ")", "\n", "plt", ".", "xlabel", "(", "'Recall'", ")", "\n", "plt", ".", "ylabel", "(", "'Precision'", ")", "\n", "\n", "# Cutting the floating number", "\n", "AP", "=", "'%.2f'", "%", "AP", "\n", "\n", "# Setting text to plot", "\n", "# plt.text(0.5, 0.5, 'AP = ' + str(AP), fontdict=None)", "\n", "plt", ".", "grid", "(", ")", "\n", "plt", ".", "show", "(", ")", "\n", "fig", ".", "savefig", "(", "phase", "+", "'_'", "+", "'PR.jpg'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.roc_curve.PlotHIST.Plot_HIST_Fn": [[14, 33], ["range", "numpy.linspace", "matplotlib.figure", "matplotlib.hist", "matplotlib.hist", "matplotlib.legend", "matplotlib.title", "matplotlib.show", "plt.figure.savefig", "len", "numpy.amin", "numpy.amax", "gen_dissimilarity_original.append", "imp_dissimilarity_original.append"], "function", ["None"], ["def", "Plot_HIST_Fn", "(", "label", ",", "distance", ",", "phase", ",", "num_bins", "=", "50", ")", ":", "\n", "\n", "    ", "dissimilarity", "=", "distance", "[", ":", "]", "\n", "gen_dissimilarity_original", "=", "[", "]", "\n", "imp_dissimilarity_original", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "label", ")", ")", ":", "\n", "        ", "if", "label", "[", "i", "]", "==", "1", ":", "\n", "            ", "gen_dissimilarity_original", ".", "append", "(", "dissimilarity", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "            ", "imp_dissimilarity_original", ".", "append", "(", "dissimilarity", "[", "i", "]", ")", "\n", "\n", "", "", "bins", "=", "np", ".", "linspace", "(", "np", ".", "amin", "(", "distance", ")", ",", "np", ".", "amax", "(", "distance", ")", ",", "num_bins", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "hist", "(", "gen_dissimilarity_original", ",", "bins", ",", "alpha", "=", "0.5", ",", "facecolor", "=", "'blue'", ",", "normed", "=", "False", ",", "label", "=", "'gen_dist_original'", ")", "\n", "plt", ".", "hist", "(", "imp_dissimilarity_original", ",", "bins", ",", "alpha", "=", "0.5", ",", "facecolor", "=", "'red'", ",", "normed", "=", "False", ",", "label", "=", "'imp_dist_original'", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'upper right'", ")", "\n", "plt", ".", "title", "(", "phase", "+", "'_'", "+", "'OriginalFeatures_Histogram.jpg'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "fig", ".", "savefig", "(", "phase", "+", "'_'", "+", "'OriginalFeatures_Histogram.jpg'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_speech.lipread_speech_arg_scope": [[52, 70], ["slim.arg_scope", "slim.arg_scope", "tensorflow.contrib.layers.variance_scaling_initializer", "slim.l2_regularizer", "tensorflow.zeros_initializer"], "function", ["None"], ["def", "lipread_speech_arg_scope", "(", "is_training", ",", "weight_decay", "=", "0.0005", ",", ")", ":", "\n", "  ", "\"\"\"Defines the VGG arg scope.\n\n  Args:\n    weight_decay: The l2 regularization coefficient.\n\n  Returns:\n    An arg_scope.\n  \"\"\"", "\n", "# Add normalizer_fn=slim.batch_norm if Batch Normalization is required!", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv3d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "variance_scaling_initializer", "(", "factor", "=", "1.0", ",", "mode", "=", "'FAN_AVG'", ")", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", ",", "\n", "normalizer_fn", "=", "slim", ".", "batch_norm", ",", "\n", "biases_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv3d", "]", ",", "padding", "=", "'VALID'", ")", "as", "arg_sc", ":", "\n", "      ", "return", "arg_sc", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_speech.PReLU": [[71, 82], ["tensorflow.get_variable", "tensorflow.nn.relu", "input.get_shape", "tensorflow.constant_initializer", "abs"], "function", ["None"], ["", "", "", "def", "PReLU", "(", "input", ",", "scope", ")", ":", "\n", "  ", "\"\"\"\n  Similar to TFlearn implementation\n  :param input: input of the PReLU which is output of a layer.\n  :return: The output.\n  \"\"\"", "\n", "alphas", "=", "tf", ".", "get_variable", "(", "scope", ",", "input", ".", "get_shape", "(", ")", "[", "-", "1", "]", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "return", "tf", ".", "nn", ".", "relu", "(", "input", ")", "+", "alphas", "*", "(", "input", "-", "abs", "(", "input", ")", ")", "*", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_speech.speech_cnn_lstm": [[85, 162], ["tensorflow.variable_scope", "tensorflow.to_float", "slim.repeat", "lipread_speech.PReLU", "tensorflow.nn.max_pool3d", "slim.conv3d", "lipread_speech.PReLU", "slim.conv3d", "lipread_speech.PReLU", "tensorflow.nn.max_pool3d", "slim.conv3d", "lipread_speech.PReLU", "slim.conv3d", "lipread_speech.PReLU", "slim.conv3d", "lipread_speech.PReLU", "slim.conv3d", "lipread_speech.PReLU", "tensorflow.squeeze", "slim.conv3d", "tensorflow.squeeze", "tensorflow.contrib.rnn.core_rnn_cell.LSTMCell", "tensorflow.nn.dynamic_rnn"], "function", ["home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.PReLU", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.PReLU", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.PReLU", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.PReLU", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.PReLU", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.PReLU", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.PReLU"], ["def", "speech_cnn_lstm", "(", "inputs", ",", "\n", "num_classes", "=", "1000", ",", "\n", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.8", ",", "\n", "spatial_squeeze", "=", "True", ",", "\n", "scope", "=", "'speech_cnn'", ")", ":", "\n", "  ", "\"\"\"Oxford Net VGG 11-Layers version A Example.\n\n  Note: All the fully_connected layers have been transformed to conv3d layers.\n        To use in classification mode, resize input to 224x224.\n\n  Args:\n    inputs: a tensor of size [batch_size, height, width, channels].\n    num_classes: number of predicted classes.\n    is_training: whether or not the model is being trained.\n    dropout_keep_prob: the probability that activations are kept in the dropout\n      layers during training.\n    spatial_squeeze: whether or not should squeeze the spatial dimensions of the\n      outputs. Useful to remove unnecessary dimensions for classification.\n    scope: Optional scope for the variables.\n\n  Returns:\n    the last op containing the log predictions and end_points dict.\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'speech_cnn'", ",", "[", "inputs", "]", ")", "as", "sc", ":", "\n", "##### CNN part #####", "\n", "# Tensor(\"batch:0\", shape=(?, 15, 40, 1, 3), dtype=float32, device=/device:CPU:0)", "\n", "    ", "inputs", "=", "tf", ".", "to_float", "(", "inputs", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "inputs", ",", "1", ",", "slim", ".", "conv3d", ",", "16", ",", "[", "1", ",", "5", ",", "1", "]", ",", "scope", "=", "'conv1'", ")", "\n", "net", "=", "PReLU", "(", "net", ",", "'conv1_activation'", ")", "\n", "net", "=", "tf", ".", "nn", ".", "max_pool3d", "(", "net", ",", "strides", "=", "[", "1", ",", "1", ",", "2", ",", "1", ",", "1", "]", ",", "ksize", "=", "[", "1", ",", "1", ",", "2", ",", "1", ",", "1", "]", ",", "padding", "=", "'VALID'", ",", "name", "=", "'pool1'", ")", "\n", "\n", "net", "=", "slim", ".", "conv3d", "(", "net", ",", "32", ",", "[", "1", ",", "4", ",", "1", "]", ",", "scope", "=", "'conv21'", ")", "\n", "net", "=", "PReLU", "(", "net", ",", "'conv21_activation'", ")", "\n", "net", "=", "slim", ".", "conv3d", "(", "net", ",", "32", ",", "[", "1", ",", "4", ",", "1", "]", ",", "scope", "=", "'conv22'", ")", "\n", "net", "=", "PReLU", "(", "net", ",", "'conv22_activation'", ")", "\n", "net", "=", "tf", ".", "nn", ".", "max_pool3d", "(", "net", ",", "strides", "=", "[", "1", ",", "1", ",", "2", ",", "1", ",", "1", "]", ",", "ksize", "=", "[", "1", ",", "1", ",", "2", ",", "1", ",", "1", "]", ",", "padding", "=", "'VALID'", ",", "name", "=", "'pool2'", ")", "\n", "\n", "net", "=", "slim", ".", "conv3d", "(", "net", ",", "64", ",", "[", "1", ",", "3", ",", "1", "]", ",", "scope", "=", "'conv31'", ")", "\n", "net", "=", "PReLU", "(", "net", ",", "'conv31_activation'", ")", "\n", "net", "=", "slim", ".", "conv3d", "(", "net", ",", "64", ",", "[", "1", ",", "3", ",", "1", "]", ",", "scope", "=", "'conv32'", ")", "\n", "net", "=", "PReLU", "(", "net", ",", "'conv32_activation'", ")", "\n", "\n", "##### FC part #####", "\n", "# Use conv3d instead of fully_connected layers.", "\n", "net", "=", "slim", ".", "conv3d", "(", "net", ",", "128", ",", "[", "1", ",", "2", ",", "1", "]", ",", "padding", "=", "'VALID'", ",", "scope", "=", "'fc4'", ")", "\n", "net", "=", "PReLU", "(", "net", ",", "'fc4_activation'", ")", "\n", "# net = PReLU(net)", "\n", "# net = slim.dropout(net, dropout_keep_prob, is_training=is_training,", "\n", "#                    scope='dropout4')", "\n", "\n", "if", "LSTM_status", ":", "\n", "\n", "      ", "net", "=", "slim", ".", "conv3d", "(", "net", ",", "64", ",", "[", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "'VALID'", ",", "activation_fn", "=", "None", ",", "normalizer_fn", "=", "None", ",", "scope", "=", "'fc5'", ")", "\n", "net", "=", "PReLU", "(", "net", ",", "'fc5_activation'", ")", "\n", "\n", "# Tensor(\"tower_0/speech_cnn/fc6/squeezed:0\", shape=(?, 9, 128), dtype=float32, device=/device:GPU:0)", "\n", "net", "=", "tf", ".", "squeeze", "(", "net", ",", "[", "2", ",", "3", "]", ",", "name", "=", "'fc5/squeezed'", ")", "\n", "\n", "", "else", ":", "\n", "      ", "net", "=", "slim", ".", "conv3d", "(", "net", ",", "64", ",", "[", "15", ",", "1", ",", "1", "]", ",", "padding", "=", "'VALID'", ",", "activation_fn", "=", "None", ",", "normalizer_fn", "=", "None", ",", "scope", "=", "'fc5'", ")", "\n", "\n", "# Tensor(\"tower_0/speech_cnn/fc6/squeezed:0\", shape=(?, 9, 128), dtype=float32, device=/device:GPU:0)", "\n", "net", "=", "tf", ".", "squeeze", "(", "net", ",", "[", "1", ",", "2", ",", "3", "]", ",", "name", "=", "'fc5/squeezed'", ")", "\n", "\n", "", "if", "LSTM_status", ":", "\n", "##### LSTM-1 #####", "\n", "# use sequence_length=X_lengths argument in tf.nn.dynamic_rnn if necessary.", "\n", "      ", "cell_1", "=", "tf", ".", "contrib", ".", "rnn", ".", "core_rnn_cell", ".", "LSTMCell", "(", "num_units", "=", "128", ",", "state_is_tuple", "=", "True", ")", "\n", "outputs", ",", "last_states", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "cell", "=", "cell_1", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "inputs", "=", "net", ",", "\n", "scope", "=", "'LSTM-speech'", ")", "\n", "net", "=", "last_states", ".", "h", "\n", "\n", "", "return", "net", ",", "end_points", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.nets_factory.get_network_fn": [[38, 68], ["functools.wraps", "hasattr", "ValueError", "slim.arg_scope", "func"], "function", ["None"], ["def", "get_network_fn", "(", "name", ",", "num_classes", ",", "weight_decay", "=", "0.0", ",", "is_training", "=", "False", ")", ":", "\n", "  ", "\"\"\"Returns a network_fn such as `logits, end_points = network_fn(images)`.\n\n  Args:\n    name: The name of the network.\n    num_classes: The number of classes to use for classification.\n    weight_decay: The l2 coefficient for the model weights.\n    is_training: `True` if the model is being used for training and `False`\n      otherwise.\n\n  Returns:\n    network_fn: A function that applies the model to a batch of images. It has\n      the following signature:\n        logits, end_points = network_fn(images)\n  Raises:\n    ValueError: If network `name` is not recognized.\n  \"\"\"", "\n", "if", "name", "not", "in", "networks_map", ":", "\n", "    ", "raise", "ValueError", "(", "'Name of network unknown %s'", "%", "name", ")", "\n", "\n", "", "func", "=", "networks_map", "[", "name", "]", "\n", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "network_fn", "(", "images", ")", ":", "\n", "    ", "arg_scope", "=", "arg_scopes_map", "[", "name", "]", "(", "is_training", ",", "weight_decay", "=", "weight_decay", ")", "\n", "with", "slim", ".", "arg_scope", "(", "arg_scope", ")", ":", "\n", "      ", "return", "func", "(", "images", ",", "num_classes", ",", "is_training", "=", "is_training", ")", "\n", "", "", "if", "hasattr", "(", "func", ",", "'default_image_size'", ")", ":", "\n", "    ", "network_fn", ".", "default_image_size", "=", "func", ".", "default_image_size", "\n", "\n", "", "return", "network_fn", "\n", "", ""]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.__init__.get_network_fn": [[97, 127], ["functools.wraps", "hasattr", "ValueError", "slim.arg_scope", "func"], "function", ["None"], []], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.lipread_mouth_arg_scope": [[50, 68], ["slim.arg_scope", "slim.arg_scope", "tensorflow.contrib.layers.variance_scaling_initializer", "slim.l2_regularizer", "tensorflow.zeros_initializer"], "function", ["None"], ["def", "lipread_mouth_arg_scope", "(", "is_training", ",", "weight_decay", "=", "0.0005", ")", ":", "\n", "  ", "\"\"\"Defines the VGG arg scope.\n\n  Args:\n    weight_decay: The l2 regularization coefficient.\n\n  Returns:\n    An arg_scope.\n  \"\"\"", "\n", "# Add normalizer_fn=slim.batch_norm if Batch Normalization is required!", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv3d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "variance_scaling_initializer", "(", "factor", "=", "1.0", ",", "mode", "=", "'FAN_AVG'", ")", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", ",", "\n", "normalizer_fn", "=", "slim", ".", "batch_norm", ",", "\n", "biases_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv3d", "]", ",", "padding", "=", "'SAME'", ")", "as", "arg_sc", ":", "\n", "      ", "return", "arg_sc", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.PReLU": [[69, 80], ["tensorflow.get_variable", "tensorflow.nn.relu", "input.get_shape", "tensorflow.constant_initializer", "abs"], "function", ["None"], ["", "", "", "def", "PReLU", "(", "input", ",", "scope", ")", ":", "\n", "  ", "\"\"\"\n  Similar to TFlearn implementation\n  :param input: input of the PReLU which is output of a layer.\n  :return: The output.\n  \"\"\"", "\n", "alphas", "=", "tf", ".", "get_variable", "(", "scope", ",", "input", ".", "get_shape", "(", ")", "[", "-", "1", "]", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "return", "tf", ".", "nn", ".", "relu", "(", "input", ")", "+", "alphas", "*", "(", "input", "-", "abs", "(", "input", ")", ")", "*", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.mouth_cnn_lstm": [[82, 170], ["tensorflow.variable_scope", "tensorflow.to_float", "slim.repeat", "lipread_mouth.PReLU", "tensorflow.nn.max_pool3d", "slim.repeat", "lipread_mouth.PReLU", "tensorflow.nn.max_pool3d", "slim.conv3d", "lipread_mouth.PReLU", "slim.conv3d", "lipread_mouth.PReLU", "tensorflow.nn.max_pool3d", "slim.repeat", "lipread_mouth.PReLU", "tensorflow.nn.max_pool3d", "slim.repeat", "lipread_mouth.PReLU", "slim.conv3d", "lipread_mouth.PReLU", "tensorflow.squeeze", "slim.conv3d", "tensorflow.squeeze", "tensorflow.contrib.rnn.core_rnn_cell.LSTMCell", "tensorflow.nn.dynamic_rnn"], "function", ["home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.PReLU", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.PReLU", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.PReLU", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.PReLU", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.PReLU", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.PReLU", "home.repos.pwc.inspect_result.astorfi_lip-reading-deeplearning.nets.lipread_mouth.PReLU"], ["", "def", "mouth_cnn_lstm", "(", "inputs", ",", "\n", "num_classes", "=", "1000", ",", "\n", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.8", ",", "\n", "spatial_squeeze", "=", "True", ",", "\n", "scope", "=", "'mouth_cnn'", ")", ":", "\n", "  ", "\"\"\"Oxford Net VGG 11-Layers version A Example.\n\n  Note: All the fully_connected layers have been transformed to conv3d layers.\n        To use in classification mode, resize input to 224x224.\n\n  Args:\n    inputs: a tensor of size [batch_size, height, width, channels].\n    num_classes: number of predicted classes.\n    is_training: whether or not the model is being trained.\n    dropout_keep_prob: the probability that activations are kept in the dropout\n      layers during training.\n    spatial_squeeze: whether or not should squeeze the spatial dimensions of the\n      outputs. Useful to remove unnecessary dimensions for classification.\n    scope: Optional scope for the variables.\n\n  Returns:\n    the last op containing the log predictions and end_points dict.\n  \"\"\"", "\n", "\n", "end_points", "=", "{", "}", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'mouth_cnn'", ",", "[", "inputs", "]", ")", "as", "sc", ":", "\n", "# end_points_collection = sc.name + '_end_points'", "\n", "# # Collect outputs for conv3d, fully_connected and max_pool2d.", "\n", "# with slim.arg_scope([slim.conv3d, slim.max_pool2d],", "\n", "#                     outputs_collections=end_points_collection):", "\n", "\n", "##### Convolution Section #####", "\n", "# Tensor(\"batch:1\", shape=(?, 9, 60, 100, 1), dtype=float32, device=/device:CPU:0)", "\n", "    ", "inputs", "=", "tf", ".", "to_float", "(", "inputs", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "inputs", ",", "1", ",", "slim", ".", "conv3d", ",", "16", ",", "[", "1", ",", "3", ",", "3", "]", ",", "scope", "=", "'conv1'", ")", "\n", "net", "=", "PReLU", "(", "net", ",", "'conv1_activation'", ")", "\n", "net", "=", "tf", ".", "nn", ".", "max_pool3d", "(", "net", ",", "strides", "=", "[", "1", ",", "1", ",", "2", ",", "2", ",", "1", "]", ",", "ksize", "=", "[", "1", ",", "1", ",", "3", ",", "3", ",", "1", "]", ",", "padding", "=", "'VALID'", ",", "name", "=", "'pool1'", ")", "\n", "# net = slim.max_pool2d(net, [3, 3], scope='pool1')", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "1", ",", "slim", ".", "conv3d", ",", "32", ",", "[", "1", ",", "3", ",", "3", "]", ",", "scope", "=", "'conv2'", ")", "\n", "net", "=", "PReLU", "(", "net", ",", "'conv2_activation'", ")", "\n", "net", "=", "tf", ".", "nn", ".", "max_pool3d", "(", "net", ",", "strides", "=", "[", "1", ",", "1", ",", "2", ",", "2", ",", "1", "]", ",", "ksize", "=", "[", "1", ",", "1", ",", "3", ",", "3", ",", "1", "]", ",", "padding", "=", "'VALID'", ",", "name", "=", "'pool2'", ")", "\n", "\n", "net", "=", "slim", ".", "conv3d", "(", "net", ",", "64", ",", "[", "1", ",", "3", ",", "3", "]", ",", "scope", "=", "'conv31'", ")", "\n", "net", "=", "PReLU", "(", "net", ",", "'conv31_activation'", ")", "\n", "net", "=", "slim", ".", "conv3d", "(", "net", ",", "64", ",", "[", "1", ",", "3", ",", "3", "]", ",", "scope", "=", "'conv32'", ")", "\n", "net", "=", "PReLU", "(", "net", ",", "'conv32_activation'", ")", "\n", "\n", "net", "=", "tf", ".", "nn", ".", "max_pool3d", "(", "net", ",", "strides", "=", "[", "1", ",", "1", ",", "2", ",", "2", ",", "1", "]", ",", "ksize", "=", "[", "1", ",", "1", ",", "3", ",", "3", ",", "1", "]", ",", "padding", "=", "'VALID'", ",", "name", "=", "'pool3'", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "1", ",", "slim", ".", "conv3d", ",", "128", ",", "[", "1", ",", "3", ",", "3", "]", ",", "scope", "=", "'conv4'", ")", "\n", "net", "=", "PReLU", "(", "net", ",", "'conv4_activation'", ")", "\n", "net", "=", "tf", ".", "nn", ".", "max_pool3d", "(", "net", ",", "strides", "=", "[", "1", ",", "1", ",", "2", ",", "2", ",", "1", "]", ",", "ksize", "=", "[", "1", ",", "1", ",", "3", ",", "3", ",", "1", "]", ",", "padding", "=", "'VALID'", ",", "name", "=", "'pool4'", ")", "\n", "\n", "##### FC section #####", "\n", "# Use conv3d instead of fully_connected layers.", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "1", ",", "slim", ".", "conv3d", ",", "256", ",", "[", "1", ",", "2", ",", "5", "]", ",", "padding", "=", "'VALID'", ",", "scope", "=", "'fc5'", ")", "\n", "net", "=", "PReLU", "(", "net", ",", "'fc5_activation'", ")", "\n", "# net = PReLU(net)", "\n", "# net = slim.dropout(net, dropout_keep_prob, is_training=is_training,", "\n", "#                    scope='dropout5')", "\n", "\n", "\n", "if", "LSTM_status", ":", "\n", "\n", "      ", "net", "=", "slim", ".", "conv3d", "(", "net", ",", "64", ",", "[", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "'VALID'", ",", "activation_fn", "=", "None", ",", "normalizer_fn", "=", "None", ",", "scope", "=", "'fc6'", ")", "\n", "net", "=", "PReLU", "(", "net", ",", "'fc6_activation'", ")", "\n", "\n", "# Tensor(\"tower_0/speech_cnn/fc6/squeezed:0\", shape=(?, 9, 128), dtype=float32, device=/device:GPU:0)", "\n", "net", "=", "tf", ".", "squeeze", "(", "net", ",", "[", "2", ",", "3", "]", ",", "name", "=", "'fc6/squeezed'", ")", "\n", "\n", "", "else", ":", "\n", "      ", "net", "=", "slim", ".", "conv3d", "(", "net", ",", "64", ",", "[", "9", ",", "1", ",", "1", "]", ",", "padding", "=", "'VALID'", ",", "activation_fn", "=", "None", ",", "normalizer_fn", "=", "None", ",", "scope", "=", "'fc5'", ")", "\n", "\n", "# Tensor(\"tower_0/speech_cnn/fc6/squeezed:0\", shape=(?, 9, 128), dtype=float32, device=/device:GPU:0)", "\n", "net", "=", "tf", ".", "squeeze", "(", "net", ",", "[", "1", ",", "2", ",", "3", "]", ",", "name", "=", "'fc6/squeezed'", ")", "\n", "\n", "", "if", "LSTM_status", ":", "\n", "##### LSTM-1 #####", "\n", "# use sequence_length=X_lengths argument in tf.nn.dynamic_rnn if necessary.", "\n", "      ", "cell_1", "=", "tf", ".", "contrib", ".", "rnn", ".", "core_rnn_cell", ".", "LSTMCell", "(", "num_units", "=", "128", ",", "state_is_tuple", "=", "True", ")", "\n", "outputs", ",", "last_states", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "cell", "=", "cell_1", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "inputs", "=", "net", ",", "\n", "scope", "=", "'LSTM-mouth'", ")", "\n", "net", "=", "last_states", ".", "h", "\n", "\n", "", "return", "net", ",", "end_points", "\n", "\n"]]}