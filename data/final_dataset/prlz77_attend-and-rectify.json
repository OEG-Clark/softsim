{"home.repos.pwc.inspect_result.prlz77_attend-and-rectify.None.train_cifar.create_dataset": [[54, 71], ["torchvision.Compose", "torchvision.Compose", "getattr", "numpy.pad", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.RandomHorizontalFlip", "torchvision.RandomCrop", "numpy.array", "numpy.array"], "function", ["None"], ["def", "create_dataset", "(", "opt", ",", "train", ")", ":", "\n", "    ", "transform", "=", "T", ".", "Compose", "(", "[", "\n", "T", ".", "ToTensor", "(", ")", ",", "\n", "T", ".", "Normalize", "(", "np", ".", "array", "(", "[", "125.3", ",", "123.0", ",", "113.9", "]", ")", "/", "255.0", ",", "\n", "np", ".", "array", "(", "[", "63.0", ",", "62.1", ",", "66.7", "]", ")", "/", "255.0", ")", ",", "\n", "]", ")", "\n", "if", "train", ":", "\n", "        ", "transform", "=", "T", ".", "Compose", "(", "[", "\n", "T", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "T", ".", "RandomCrop", "(", "32", ")", ",", "\n", "transform", "\n", "]", ")", "\n", "\n", "", "ds", "=", "getattr", "(", "datasets", ",", "opt", ".", "dataset", ")", "(", "opt", ".", "dataroot", ",", "train", "=", "train", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "if", "train", ":", "\n", "        ", "ds", ".", "train_data", "=", "np", ".", "pad", "(", "ds", ".", "train_data", ",", "(", "(", "0", ",", "0", ")", ",", "(", "4", ",", "4", ")", ",", "(", "4", ",", "4", ")", ",", "(", "0", ",", "0", ")", ")", ",", "mode", "=", "'reflect'", ")", "\n", "", "return", "ds", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.None.train_cifar.main": [[73, 170], ["parser.parse_args", "utils.loggers.json_logger.JsonLogger", "utils.loggers.json_logger.JsonLogger.update", "os.path.dirname", "print", "train_cifar.main.create_iterator"], "function", ["home.repos.pwc.inspect_result.prlz77_attend-and-rectify.monitors.harakiri.Harakiri.update"], ["", "def", "main", "(", ")", ":", "\n", "    ", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "state", "=", "opt", ".", "__dict__", "\n", "log", "=", "JsonLogger", "(", "opt", ".", "save", ",", "rand_folder", "=", "True", ")", "\n", "log", ".", "update", "(", "state", ")", "\n", "state", "[", "'exp_dir'", "]", "=", "os", ".", "path", ".", "dirname", "(", "log", ".", "path", ")", "\n", "state", "[", "'start_lr'", "]", "=", "state", "[", "'lr'", "]", "\n", "state", "[", "\"training_time\"", "]", "=", "0", "\n", "\n", "print", "(", "'parsed options:'", ",", "vars", "(", "opt", ")", ")", "\n", "num_classes", "=", "10", "if", "opt", ".", "dataset", "==", "'CIFAR10'", "else", "100", "\n", "\n", "def", "create_iterator", "(", "train", ")", ":", "\n", "        ", "return", "DataLoader", "(", "create_dataset", "(", "opt", ",", "train", ")", ",", "batch_size", "=", "opt", ".", "batch_size", ",", "shuffle", "=", "train", ",", "\n", "num_workers", "=", "opt", ".", "nthread", ",", "pin_memory", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", ")", "\n", "\n", "", "train_loader", "=", "create_iterator", "(", "True", ")", "\n", "test_loader", "=", "create_iterator", "(", "False", ")", "\n", "\n", "model", "=", "WideResNet", "(", "opt", ".", "depth", ",", "opt", ".", "width", ",", "num_classes", ")", ".", "cuda", "(", ")", "\n", "if", "opt", ".", "ngpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "list", "(", "range", "(", "opt", ".", "ngpu", ")", ")", ")", "\n", "\n", "", "def", "create_optimizer", "(", "opt", ",", "lr", ")", ":", "\n", "        ", "print", "(", "'creating optimizer with lr = '", ",", "lr", ")", "\n", "return", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", ",", "0.9", ",", "weight_decay", "=", "opt", ".", "weight_decay", ")", "\n", "\n", "", "optimizer", "=", "create_optimizer", "(", "opt", ",", "opt", ".", "lr", ")", "\n", "\n", "state", "[", "\"epoch\"", "]", "=", "0", "\n", "if", "opt", ".", "resume", "!=", "''", ":", "\n", "        ", "state_dict", "=", "torch", ".", "load", "(", "opt", ".", "resume", ")", "\n", "state", "[", "\"epoch\"", "]", "=", "state_dict", "[", "'epoch'", "]", "\n", "state", "[", "\"training_time\"", "]", "=", "state_dict", "[", "\"training_time\"", "]", "\n", "optimizer", ".", "load_state_dict", "(", "state_dict", "[", "'optimizer'", "]", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", "[", "\"state_dict\"", "]", ")", "\n", "\n", "", "n_parameters", "=", "sum", "(", "[", "np", ".", "prod", "(", "p", ".", "size", "(", ")", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "print", "(", "'\\nTotal number of parameters:'", ",", "n_parameters", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "opt", ".", "save", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "opt", ".", "save", ")", "\n", "\n", "", "train_loss_meter", "=", "meter", ".", "Meter", "(", ")", "\n", "val_loss_meter", "=", "meter", ".", "Meter", "(", ")", "\n", "val_accuracy_meter", "=", "meter", ".", "Meter", "(", ")", "\n", "\n", "def", "train", "(", ")", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "train_loss_meter", ".", "reset", "(", ")", "\n", "for", "images", ",", "labels", "in", "train_loader", ":", "\n", "            ", "images", ",", "labels", "=", "Variable", "(", "images", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", ",", "Variable", "(", "labels", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "preds", "=", "model", "(", "images", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "preds", ",", "labels", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "state", "[", "\"training_time\"", "]", "=", "time", ".", "time", "(", ")", "-", "t", "\n", "train_loss_meter", ".", "update", "(", "float", "(", "loss", ")", ",", "labels", ".", "size", "(", "0", ")", ")", "\n", "", "state", "[", "\"train_loss\"", "]", "=", "train_loss_meter", ".", "mean", "(", ")", "\n", "\n", "", "def", "eval", "(", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "val_loss_meter", ".", "reset", "(", ")", "\n", "val_accuracy_meter", ".", "reset", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "images", ",", "labels", "in", "test_loader", ":", "\n", "                ", "images", ",", "labels", "=", "Variable", "(", "images", ")", ".", "cuda", "(", ")", ",", "Variable", "(", "labels", ")", ".", "cuda", "(", ")", "\n", "outputs", "=", "model", "(", "images", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "outputs", ",", "labels", ")", "\n", "val_loss_meter", ".", "update", "(", "float", "(", "loss", ")", ",", "outputs", ".", "size", "(", "0", ")", ")", "\n", "preds", "=", "outputs", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "val_accuracy_meter", ".", "update", "(", "float", "(", "(", "preds", "==", "labels", ")", ".", "float", "(", ")", ".", "sum", "(", ")", ")", ",", "outputs", ".", "size", "(", "0", ")", ")", "\n", "", "", "state", "[", "'val_loss'", "]", "=", "val_loss_meter", ".", "mean", "(", ")", "\n", "state", "[", "'val_accuracy'", "]", "=", "val_accuracy_meter", ".", "mean", "(", ")", "\n", "\n", "", "start_epoch", "=", "state", "[", "\"epoch\"", "]", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "opt", ".", "epochs", ")", ":", "\n", "        ", "state", "[", "\"epoch\"", "]", "=", "epoch", "\n", "train", "(", ")", "\n", "eval", "(", ")", "\n", "torch", ".", "save", "(", "dict", "(", "state_dict", "=", "model", ".", "state_dict", "(", ")", ",", "\n", "optimizer", "=", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "training_time", "=", "state", "[", "\"training_time\"", "]", ",", "\n", "epoch", "=", "epoch", "+", "1", ")", ",", "\n", "open", "(", "os", ".", "path", ".", "join", "(", "state", "[", "\"exp_dir\"", "]", ",", "'model.pt7'", ")", ",", "'wb'", ")", ")", "\n", "log", ".", "update", "(", "state", ")", "\n", "print", "(", "state", ")", "\n", "print", "(", "\"epoch: %d - Validation accuracy: %.03f\"", "%", "(", "epoch", ",", "state", "[", "\"val_accuracy\"", "]", ")", ")", "\n", "\n", "\n", "\n", "if", "(", "epoch", "+", "1", ")", "in", "opt", ".", "schedule", ":", "\n", "            ", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "*=", "opt", ".", "lr_decay_ratio", "\n", "", "state", "[", "'lr'", "]", "*=", "0.1", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.loggers.json_logger.JsonLogger.__init__": [[16, 31], ["os.path.join", "open", "json_logger.JsonLogger.output.write", "os.path.join", "os.makedirs", "datetime.datetime.now", "str().replace", "str", "datetime.datetime.now"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "path", ",", "rand_folder", "=", "False", ",", "duration", "=", "False", ")", ":", "\n", "        ", "\"\"\" Constructor.\n\n        Args:\n            path: json output path\n            unique_folder: create a unique folder with the current datetime\n        \"\"\"", "\n", "if", "rand_folder", ":", "\n", "            ", "path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ".", "replace", "(", "' '", ",", "'_'", ")", ")", "\n", "os", ".", "makedirs", "(", "path", ")", "\n", "", "self", ".", "path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'log.json'", ")", "\n", "self", ".", "output", "=", "open", "(", "self", ".", "path", ",", "'w+'", ")", "\n", "self", ".", "output", ".", "write", "(", "'[]'", ")", "\n", "self", ".", "first_time", "=", "True", "\n", "self", ".", "duration", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "if", "duration", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.loggers.json_logger.JsonLogger.update": [[32, 49], ["json_logger.JsonLogger.output.seek", "json.dump", "json_logger.JsonLogger.output.write", "json_logger.JsonLogger.output.flush", "str", "json_logger.JsonLogger.output.write", "json_logger.JsonLogger.output.tell", "datetime.datetime.now"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "state", ")", ":", "\n", "        ", "\"\"\" Update log status (outputs to file).\n\n        Args:\n            state (dict): the current model state.\n        \"\"\"", "\n", "if", "not", "(", "self", ".", "duration", "is", "False", ")", ":", "\n", "            ", "state", "[", "'duration'", "]", "=", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", "-", "self", ".", "duration", ")", "\n", "\n", "", "self", ".", "output", ".", "seek", "(", "self", ".", "output", ".", "tell", "(", ")", "-", "1", ",", "0", ")", "\n", "if", "not", "self", ".", "first_time", ":", "\n", "            ", "self", ".", "output", ".", "write", "(", "','", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "first_time", "=", "False", "\n", "", "json", ".", "dump", "(", "state", ",", "self", ".", "output", ")", "\n", "self", ".", "output", ".", "write", "(", "\"]\"", ")", "\n", "self", ".", "output", ".", "flush", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.monitors.meter.Meter.__init__": [[2, 5], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "count", "=", "0.", "\n", "self", ".", "total", "=", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.monitors.meter.Meter.update": [[6, 9], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "v", ",", "count", ")", ":", "\n", "        ", "self", ".", "count", "+=", "count", "\n", "self", ".", "total", "+=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.monitors.meter.Meter.mean": [[10, 12], ["None"], "methods", ["None"], ["", "def", "mean", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "total", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.monitors.meter.Meter.reset": [[13, 16], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "count", "=", "0", "\n", "self", ".", "total", "=", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.monitors.harakiri.Harakiri.__init__": [[10, 23], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "initial_value", "=", "0", ")", ":", "\n", "        ", "\"\"\" Constructor\n\n        Args:\n            initial_value: best value to compare with\n        \"\"\"", "\n", "self", ".", "best_value", "=", "initial_value", "\n", "self", ".", "buffer", "=", "[", "]", "\n", "self", ".", "test", "=", "lambda", ":", "1", "# The test consists in two bits: plateau_length_exceeded current_value_is_best (2^1 2^0)", "\n", "self", ".", "message", "=", "\"(Harakiri)\"", "\n", "self", ".", "waypoints", "=", "[", "]", "\n", "self", ".", "waypoint_callbacks", "=", "[", "]", "\n", "self", ".", "plateau_callbacks", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.monitors.harakiri.Harakiri.add_waypoint_callback": [[24, 31], ["harakiri.Harakiri.waypoint_callbacks.append"], "methods", ["None"], ["", "def", "add_waypoint_callback", "(", "self", ",", "callback", ")", ":", "\n", "        ", "\"\"\" Set a function to be called when a waypoint is violated\n\n        Args:\n            callback: a function reference\n        \"\"\"", "\n", "self", ".", "waypoint_callbacks", ".", "append", "(", "callback", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.monitors.harakiri.Harakiri.add_plateau_callback": [[32, 39], ["harakiri.Harakiri.plateau_callbacks.append"], "methods", ["None"], ["", "def", "add_plateau_callback", "(", "self", ",", "callback", ")", ":", "\n", "        ", "\"\"\" Set a function to be called when a plateau is violated\n\n        Args:\n            callback: a function reference\n        \"\"\"", "\n", "self", ".", "plateau_callbacks", ".", "append", "(", "callback", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.monitors.harakiri.Harakiri.add_waypoint": [[40, 48], ["harakiri.Harakiri.waypoints.append"], "methods", ["None"], ["", "def", "add_waypoint", "(", "self", ",", "condition", "=", "lambda", "epoch", ",", "value", ":", "True", ")", ":", "\n", "        ", "\"\"\" Add a condition that the training curve must accomplish. E.g. accuracy must always be higher than\n            0 after the first epoch.\n\n        Args:\n            condition (function): tester function. Returns True to continue training.\n        \"\"\"", "\n", "self", ".", "waypoints", ".", "append", "(", "condition", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.monitors.harakiri.Harakiri.set_max_plateau": [[49, 58], ["len"], "methods", ["None"], ["", "def", "set_max_plateau", "(", "self", ",", "plateau_length", ")", ":", "\n", "        ", "\"\"\" Sets harakiri to look for max values.\n\n        Args:\n            plateau_length: length of the plateau until seppuku\n        \"\"\"", "\n", "assert", "(", "plateau_length", ">=", "1", ")", "\n", "self", ".", "test", "=", "lambda", ":", "1", "*", "(", "self", ".", "best_value", ">", "self", ".", "buffer", "[", "-", "1", "]", ")", "+", "2", "*", "(", "len", "(", "self", ".", "buffer", ")", ">=", "plateau_length", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.monitors.harakiri.Harakiri.set_min_plateau": [[59, 68], ["len"], "methods", ["None"], ["", "def", "set_min_plateau", "(", "self", ",", "plateau_length", ")", ":", "\n", "        ", "\"\"\" Sets harakiri to look for max values\n\n        Args:\n            plateau_length: length of the plateau until seppuku\n        \"\"\"", "\n", "assert", "(", "plateau_length", ">=", "1", ")", "\n", "self", ".", "test", "=", "lambda", ":", "1", "*", "(", "self", ".", "best_value", "<", "self", ".", "buffer", "[", "-", "1", "]", ")", "+", "2", "*", "(", "len", "(", "self", ".", "buffer", ")", ">=", "plateau_length", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.monitors.harakiri.Harakiri.set_message": [[69, 76], ["None"], "methods", ["None"], ["", "def", "set_message", "(", "self", ",", "message", ")", ":", "\n", "        ", "\"\"\" Set the process last words\n\n        Args:\n            message: the last string of words\n        \"\"\"", "\n", "self", ".", "message", "=", "message", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.monitors.harakiri.Harakiri.update": [[77, 96], ["harakiri.Harakiri.buffer.append", "harakiri.Harakiri.test", "print", "sys.exit", "waypoint", "print", "sys.exit"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "epoch", ",", "value", ")", ":", "\n", "        ", "\"\"\" Tests the plateau condition given a new value\n\n        Args:\n            epoch (int or float): current epoch\n            value (int or float): value to test\n        \"\"\"", "\n", "for", "waypoint", "in", "self", ".", "waypoints", ":", "\n", "            ", "if", "not", "waypoint", "(", "epoch", ",", "value", ")", ":", "\n", "                ", "print", "(", "self", ".", "message", ",", "\"Waypoint fail.\"", ")", "\n", "sys", ".", "exit", "(", "0", ")", "\n", "", "", "self", ".", "buffer", ".", "append", "(", "value", ")", "\n", "test_v", "=", "self", ".", "test", "(", ")", "\n", "if", "test_v", "==", "3", ":", "\n", "            ", "print", "(", "self", ".", "message", ",", "\"Plateau reached.\"", ")", "\n", "sys", ".", "exit", "(", "0", ")", "\n", "", "elif", "test_v", "&", "1", "==", "0", ":", "\n", "            ", "self", ".", "buffer", "=", "[", "]", "\n", "self", ".", "best_value", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.modules.attention.Gate.__init__": [[19, 38], ["super().__init__", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.WideResNetAttention.__init__"], ["def", "__init__", "(", "self", ",", "in_ch", ",", "ngates", "=", "1", ",", "gate_depth", "=", "1", ")", ":", "\n", "        ", "\"\"\" Constructor\n\n        Args:\n            in_ch: number of input channels.\n        \"\"\"", "\n", "super", "(", "Gate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "gate_depth", "==", "1", ":", "\n", "            ", "self", ".", "gates", "=", "torch", ".", "nn", ".", "Linear", "(", "in_ch", ",", "ngates", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "gates", "=", "torch", ".", "nn", ".", "Linear", "(", "in_ch", "//", "2", ",", "ngates", ",", "bias", "=", "False", ")", "\n", "self", ".", "pre_gates", "=", "torch", ".", "nn", ".", "Linear", "(", "in_ch", ",", "in_ch", "//", "2", ",", "bias", "=", "False", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "pre_gates", ".", "weight", ".", "data", ")", "\n", "self", ".", "pre_bn", "=", "torch", ".", "nn", ".", "BatchNorm1d", "(", "in_ch", "//", "2", ")", "\n", "\n", "", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "gates", ".", "weight", ".", "data", ")", "\n", "self", ".", "bn", "=", "torch", ".", "nn", ".", "BatchNorm1d", "(", "ngates", ")", "\n", "\n", "self", ".", "gate_depth", "=", "gate_depth", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.modules.attention.Gate.forward": [[39, 52], ["torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "attention.Gate.bn", "attention.Gate.bn", "attention.Gate.gates", "attention.Gate.gates", "torch.relu", "torch.relu", "attention.Gate.pre_bn", "attention.Gate.pre_gates"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" Pytorch forward function\n\n        Args:\n            x: input Variable\n\n        Returns: gate value (Variable)\n\n        \"\"\"", "\n", "if", "self", ".", "gate_depth", "==", "1", ":", "\n", "            ", "return", "F", ".", "tanh", "(", "self", ".", "bn", "(", "self", ".", "gates", "(", "x", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "tanh", "(", "self", ".", "bn", "(", "self", ".", "gates", "(", "F", ".", "relu", "(", "self", ".", "pre_bn", "(", "self", ".", "pre_gates", "(", "x", ")", ")", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.modules.attention.AttentionHead.__init__": [[60, 74], ["super().__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "attention.AttentionHead.register_buffer", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.eye().reshape", "numpy.eye"], "methods", ["home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.WideResNetAttention.__init__"], ["def", "__init__", "(", "self", ",", "in_ch", ",", "nheads", "=", "1", ")", ":", "\n", "        ", "\"\"\" Constructor\n\n        Args:\n            in_ch: input feature map channels\n            nheads: number of attention masks\n        \"\"\"", "\n", "super", "(", "AttentionHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nheads", "=", "nheads", "\n", "self", ".", "conv", "=", "torch", ".", "nn", ".", "Conv2d", "(", "in_ch", ",", "nheads", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "conv", ".", "weight", ".", "data", ")", "\n", "self", ".", "register_buffer", "(", "\"diag\"", ",", "\n", "torch", ".", "from_numpy", "(", "\n", "1", "-", "np", ".", "eye", "(", "self", ".", "nheads", ",", "self", ".", "nheads", ")", ".", "reshape", "(", "1", ",", "self", ".", "nheads", ",", "self", ".", "nheads", ")", ")", ".", "float", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.modules.attention.AttentionHead.reg_loss": [[75, 85], ["attention.AttentionHead.att_mask.view", "attention.AttentionHead.att_mask.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attention.AttentionHead.transpose", "reg_loss.view"], "methods", ["None"], ["", "def", "reg_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\" Regularization Loss\n\n        Returns: a Variable with the inter-head regularization loss.\n\n        \"\"\"", "\n", "mask2loss", "=", "self", ".", "att_mask", ".", "view", "(", "self", ".", "att_mask", ".", "size", "(", "0", ")", ",", "self", ".", "nheads", ",", "-", "1", ")", "\n", "reg_loss", "=", "torch", ".", "bmm", "(", "mask2loss", ",", "mask2loss", ".", "transpose", "(", "1", ",", "2", ")", ")", "*", "torch", ".", "autograd", ".", "Variable", "(", "self", ".", "diag", ",", "\n", "requires_grad", "=", "False", ")", "\n", "return", "(", "reg_loss", ".", "view", "(", "-", "1", ")", "**", "2", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.modules.attention.AttentionHead.forward": [[86, 99], ["x.size", "torch.softmax().view", "torch.softmax().view", "torch.avg_pool2d", "torch.avg_pool2d", "torch.softmax", "torch.softmax", "attention.AttentionHead.conv().view", "attention.AttentionHead.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" Pytorch Forward\n\n        Args:\n            x: input feature map\n\n        Returns: the multiple attended feature maps\n\n        \"\"\"", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "x", ".", "size", "(", ")", "\n", "att_mask", "=", "F", ".", "softmax", "(", "self", ".", "conv", "(", "x", ")", ".", "view", "(", "b", ",", "self", ".", "nheads", ",", "w", "*", "h", ")", ",", "2", ")", ".", "view", "(", "b", ",", "self", ".", "nheads", ",", "h", ",", "w", ")", "\n", "self", ".", "att_mask", "=", "F", ".", "avg_pool2d", "(", "att_mask", ",", "2", ",", "2", ")", "\n", "return", "att_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.modules.attention.OutHead.__init__": [[107, 117], ["super().__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_"], "methods", ["home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.WideResNetAttention.__init__"], ["def", "__init__", "(", "self", ",", "in_ch", ",", "out_ch", ")", ":", "\n", "        ", "\"\"\" Constructor\n\n        Args:\n            in_ch: input feature map channels\n            nheads: number of attention masks\n        \"\"\"", "\n", "super", "(", "OutHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "torch", ".", "nn", ".", "Conv2d", "(", "in_ch", ",", "out_ch", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "conv", ".", "weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.modules.attention.OutHead.forward": [[118, 128], ["attention.OutHead.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" Pytorch Forward\n\n        Args:\n            x: input feature map\n\n        Returns: the multiple attended feature maps\n\n        \"\"\"", "\n", "return", "self", ".", "conv", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.modules.attention.AttentionModule.__init__": [[136, 159], ["super().__init__", "attention.AttentionHead", "attention.OutHead", "attention.OutHead"], "methods", ["home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.WideResNetAttention.__init__"], ["def", "__init__", "(", "self", ",", "in_ch", ",", "nlabels", ",", "nheads", "=", "1", ",", "reg_w", "=", "0.0", ",", "self_attention", "=", "True", ")", ":", "\n", "        ", "\"\"\" Constructor\n\n        Args:\n            in_ch: number of input feature map channels\n            h: input feature map height\n            w: input feature map width\n            nlabels: number of output classes\n            nheads: number of attention heads\n            has_gates: whether to use gating (recommended)\n            reg_w: inter-mask regularization weight\n        \"\"\"", "\n", "super", "(", "AttentionModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_ch", "=", "in_ch", "\n", "self", ".", "nlabels", "=", "nlabels", "\n", "self", ".", "nheads", "=", "nheads", "\n", "self", ".", "reg_w", "=", "reg_w", "\n", "self", ".", "self_attention", "=", "self_attention", "\n", "\n", "self", ".", "att_head", "=", "AttentionHead", "(", "in_ch", ",", "nheads", ")", "\n", "self", ".", "out_head", "=", "OutHead", "(", "in_ch", ",", "nlabels", "*", "nheads", ")", "\n", "if", "self", ".", "self_attention", ":", "\n", "            ", "self", ".", "score", "=", "OutHead", "(", "in_ch", ",", "nheads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.modules.attention.AttentionModule.reg_loss": [[160, 167], ["attention.AttentionModule.att_head.reg_loss"], "methods", ["home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.WideResNetAttention.reg_loss"], ["", "", "def", "reg_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\" Regularization loss\n\n        Returns: A Variable with the inter-mask regularization loss for this  Attention Module.\n\n        \"\"\"", "\n", "return", "self", ".", "att_head", ".", "reg_loss", "(", ")", "*", "self", ".", "reg_w", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.modules.attention.AttentionModule.forward": [[168, 187], ["x.size", "attention.AttentionModule.att_head().view", "attention.AttentionModule.score().view", "torch.softmax", "torch.softmax", "attention.AttentionModule.att_head", "torch.tanh", "torch.tanh", "attention.AttentionModule.out_head().view", "attention.AttentionModule.score", "attention.AttentionModule.out_head"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" Pytorch Forward\n\n        Args:\n            x: input feature map.\n\n        Returns: tuple with predictions and gates. Gets are set to None if disabled.\n\n        \"\"\"", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "x", ".", "size", "(", ")", "\n", "att_mask", "=", "self", ".", "att_head", "(", "x", ")", ".", "view", "(", "b", ",", "self", ".", "nheads", ",", "1", ",", "h", "*", "w", ")", "\n", "output", "=", "(", "self", ".", "out_head", "(", "x", ")", ".", "view", "(", "b", ",", "self", ".", "nheads", ",", "self", ".", "nlabels", ",", "h", "*", "w", ")", "*", "att_mask", ")", ".", "sum", "(", "3", ")", "\n", "if", "self", ".", "self_attention", ":", "\n", "            ", "scores", "=", "self", ".", "score", "(", "x", ")", ".", "view", "(", "b", ",", "self", ".", "nheads", ",", "1", ",", "h", "*", "w", ")", "\n", "scores", "=", "(", "scores", "*", "att_mask", ")", ".", "sum", "(", "3", ")", "\n", "scores", "=", "F", ".", "softmax", "(", "F", ".", "tanh", "(", "scores", ")", ",", "1", ")", "\n", "return", "(", "output", "*", "scores", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.modules.attention.AttentionModule.aggregate": [[188, 212], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax.mean", "torch.softmax().view", "torch.softmax().view", "torch.sigmoid().view", "torch.sigmoid().view", "torch.sigmoid().view.size", "torch.sigmoid().view.size", "torch.softmax", "torch.softmax", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid().view.sum"], "methods", ["home.repos.pwc.inspect_result.prlz77_attend-and-rectify.monitors.meter.Meter.mean"], ["", "", "@", "staticmethod", "\n", "def", "aggregate", "(", "outputs", ",", "gates", ",", "function", "=", "'softmax'", ")", ":", "\n", "        ", "\"\"\" Generates the final output after aggregating all the attention modules.\n\n        Args:\n            last_output: network output logits\n            last_gate: gate for the network output\n\n        Returns: final network prediction\n\n        \"\"\"", "\n", "outputs", "=", "torch", ".", "cat", "(", "outputs", ",", "1", ")", "\n", "outputs", "=", "F", ".", "log_softmax", "(", "outputs", ",", "dim", "=", "2", ")", "\n", "if", "gates", "is", "not", "None", ":", "\n", "            ", "if", "function", "==", "'softmax'", ":", "\n", "                ", "gates", "=", "F", ".", "softmax", "(", "gates", ",", "1", ")", ".", "view", "(", "gates", ".", "size", "(", "0", ")", ",", "-", "1", ",", "1", ")", "\n", "ret", "=", "(", "outputs", "*", "gates", ")", ".", "sum", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "gates", "=", "F", ".", "sigmoid", "(", "gates", ")", ".", "view", "(", "gates", ".", "size", "(", "0", ")", ",", "-", "1", ",", "1", ")", "\n", "ret", "=", "(", "outputs", "*", "gates", ")", ".", "sum", "(", "1", ")", "/", "(", "1e-6", "+", "gates", ".", "sum", "(", "1", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "ret", "=", "outputs", ".", "mean", "(", "1", ")", "\n", "\n", "", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar.Block.__init__": [[14, 26], ["super().__init__", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_"], "methods", ["home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.WideResNetAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ni", ",", "no", ",", "stride", ")", ":", "\n", "        ", "super", "(", "Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bn0", "=", "torch", ".", "nn", ".", "BatchNorm2d", "(", "ni", ")", "\n", "self", ".", "conv0", "=", "torch", ".", "nn", ".", "Conv2d", "(", "ni", ",", "no", ",", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "conv0", ".", "weight", ".", "data", ")", "\n", "self", ".", "bn1", "=", "torch", ".", "nn", ".", "BatchNorm2d", "(", "no", ")", "\n", "self", ".", "conv1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "no", ",", "no", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "conv1", ".", "weight", ".", "data", ")", "\n", "self", ".", "reduce", "=", "ni", "!=", "no", "\n", "if", "self", ".", "reduce", ":", "\n", "            ", "self", ".", "conv_reduce", "=", "torch", ".", "nn", ".", "Conv2d", "(", "ni", ",", "no", ",", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "conv_reduce", ".", "weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar.Block.forward": [[27, 36], ["torch.relu", "torch.relu", "wide_resnet_cifar.Block.conv0", "torch.relu", "torch.relu", "wide_resnet_cifar.Block.conv1", "wide_resnet_cifar.Block.bn0", "wide_resnet_cifar.Block.bn1", "wide_resnet_cifar.Block.conv_reduce"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "o1", "=", "F", ".", "relu", "(", "self", ".", "bn0", "(", "x", ")", ",", "inplace", "=", "True", ")", "\n", "y", "=", "self", ".", "conv0", "(", "o1", ")", "\n", "o2", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "y", ")", ",", "inplace", "=", "True", ")", "\n", "z", "=", "self", ".", "conv1", "(", "o2", ")", "\n", "if", "self", ".", "reduce", ":", "\n", "            ", "return", "z", "+", "self", ".", "conv_reduce", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "z", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar.Group.__init__": [[39, 44], ["super().__init__", "range", "wide_resnet_cifar.Group.__setattr__", "wide_resnet_cifar.Block"], "methods", ["home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.WideResNetAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ni", ",", "no", ",", "n", ",", "stride", ")", ":", "\n", "        ", "super", "(", "Group", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n", "=", "n", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "self", ".", "__setattr__", "(", "\"block_%d\"", "%", "i", ",", "Block", "(", "ni", "if", "i", "==", "0", "else", "no", ",", "no", ",", "stride", "if", "i", "==", "0", "else", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar.Group.forward": [[45, 49], ["range", "wide_resnet_cifar.Group.__getattr__"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "x", "=", "self", ".", "__getattr__", "(", "\"block_%d\"", "%", "i", ")", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar.WideResNet.__init__": [[52, 66], ["super().__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "wide_resnet_cifar.Group", "wide_resnet_cifar.Group", "wide_resnet_cifar.Group", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "int"], "methods", ["home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.WideResNetAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "depth", ",", "width", ",", "num_classes", ")", ":", "\n", "        ", "super", "(", "WideResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "(", "depth", "-", "4", ")", "%", "6", "==", "0", ",", "'depth should be 6n+4'", "\n", "self", ".", "n", "=", "(", "depth", "-", "4", ")", "//", "6", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "widths", "=", "[", "int", "(", "x", "*", "width", ")", "for", "x", "in", "[", "16", ",", "32", ",", "64", "]", "]", "\n", "self", ".", "conv0", "=", "torch", ".", "nn", ".", "Conv2d", "(", "3", ",", "16", ",", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "conv0", ".", "weight", ".", "data", ")", "\n", "self", ".", "group_0", "=", "Group", "(", "16", ",", "widths", "[", "0", "]", ",", "self", ".", "n", ",", "1", ")", "\n", "self", ".", "group_1", "=", "Group", "(", "widths", "[", "0", "]", ",", "widths", "[", "1", "]", ",", "self", ".", "n", ",", "2", ")", "\n", "self", ".", "group_2", "=", "Group", "(", "widths", "[", "1", "]", ",", "widths", "[", "2", "]", ",", "self", ".", "n", ",", "2", ")", "\n", "self", ".", "bn", "=", "torch", ".", "nn", ".", "BatchNorm2d", "(", "widths", "[", "2", "]", ")", "\n", "self", ".", "classifier", "=", "torch", ".", "nn", ".", "Linear", "(", "widths", "[", "2", "]", ",", "self", ".", "num_classes", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "classifier", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar.WideResNet.forward": [[67, 77], ["wide_resnet_cifar.WideResNet.conv0", "wide_resnet_cifar.WideResNet.group_0", "wide_resnet_cifar.WideResNet.group_1", "wide_resnet_cifar.WideResNet.group_2", "torch.relu", "torch.relu", "torch.avg_pool2d", "torch.avg_pool2d", "wide_resnet_cifar.WideResNet.view", "wide_resnet_cifar.WideResNet.classifier", "wide_resnet_cifar.WideResNet.bn", "wide_resnet_cifar.WideResNet.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv0", "(", "x", ")", "\n", "g0", "=", "self", ".", "group_0", "(", "x", ")", "\n", "g1", "=", "self", ".", "group_1", "(", "g0", ")", "\n", "g2", "=", "self", ".", "group_2", "(", "g1", ")", "\n", "o", "=", "F", ".", "relu", "(", "self", ".", "bn", "(", "g2", ")", ")", "\n", "o", "=", "F", ".", "avg_pool2d", "(", "o", ",", "8", ",", "1", ",", "0", ")", "\n", "o", "=", "o", ".", "view", "(", "o", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "o", "=", "self", ".", "classifier", "(", "o", ")", "\n", "return", "o", "\n", "", "", ""]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.Block.__init__": [[19, 42], ["super().__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_"], "methods", ["home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.WideResNetAttention.__init__"], ["def", "__init__", "(", "self", ",", "ni", ",", "no", ",", "stride", ",", "dropout", ",", "save_input", "=", "False", ")", ":", "\n", "        ", "\"\"\" Constructor\n\n        Args:\n            ni: input channels\n            no: output channels\n            stride: conv stride\n            dropout: dropout prob\n            save_input: retain input after batchnorm for later reuse\n        \"\"\"", "\n", "super", "(", "Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "conv0", "=", "torch", ".", "nn", ".", "Conv2d", "(", "ni", ",", "no", ",", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "conv0", ".", "weight", ".", "data", ")", "\n", "self", ".", "bn0", "=", "torch", ".", "nn", ".", "BatchNorm2d", "(", "ni", ")", "\n", "self", ".", "conv1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "no", ",", "no", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "torch", ".", "nn", ".", "BatchNorm2d", "(", "no", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "conv1", ".", "weight", ".", "data", ")", "\n", "self", ".", "reduce", "=", "ni", "!=", "no", "\n", "self", ".", "save_input", "=", "save_input", "\n", "if", "self", ".", "reduce", ":", "\n", "            ", "self", ".", "conv_reduce", "=", "torch", ".", "nn", ".", "Conv2d", "(", "ni", ",", "no", ",", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "conv_reduce", ".", "weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.Block.forward": [[43, 66], ["torch.relu", "torch.relu", "wide_resnet_cifar_attention.Block.conv0", "torch.relu", "torch.relu", "wide_resnet_cifar_attention.Block.conv1", "wide_resnet_cifar_attention.Block.bn0", "wide_resnet_cifar_attention.Block.bn1", "torch.dropout2d", "torch.dropout2d", "wide_resnet_cifar_attention.Block.conv_reduce"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" Pytorch Module forward\n\n        Args:\n            x: input\n\n        Returns: block(x)\n\n        \"\"\"", "\n", "block_input", "=", "F", ".", "relu", "(", "self", ".", "bn0", "(", "x", ")", ",", "True", ")", "\n", "\n", "if", "self", ".", "save_input", ":", "\n", "            ", "self", ".", "block_input", "=", "block_input", "\n", "\n", "", "y", "=", "self", ".", "conv0", "(", "block_input", ")", "\n", "o2", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "y", ")", ",", "inplace", "=", "True", ")", "\n", "if", "self", ".", "dropout", ">", "0", ":", "\n", "            ", "o2", "=", "F", ".", "dropout2d", "(", "o2", ",", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ",", "inplace", "=", "True", ")", "\n", "", "z", "=", "self", ".", "conv1", "(", "o2", ")", "\n", "if", "self", ".", "reduce", ":", "\n", "            ", "return", "z", "+", "self", ".", "conv_reduce", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "return", "z", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.Group.__init__": [[72, 87], ["super().__init__", "range", "wide_resnet_cifar_attention.Group.__setattr__", "wide_resnet_cifar_attention.Block"], "methods", ["home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.WideResNetAttention.__init__"], ["def", "__init__", "(", "self", ",", "ni", ",", "no", ",", "n", ",", "stride", ",", "dropout", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            ni: input channels\n            no: output channels\n            n: number of blocks\n            stride: stride\n            dropout: dropout prob\n        \"\"\"", "\n", "super", "(", "Group", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n", "=", "n", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "self", ".", "__setattr__", "(", "\"block_%d\"", "%", "i", ",", "\n", "Block", "(", "ni", "if", "i", "==", "0", "else", "no", ",", "no", ",", "stride", "if", "i", "==", "0", "else", "1", ",", "dropout", ",", "save_input", "=", "(", "i", "==", "0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.Group.forward": [[88, 100], ["range", "wide_resnet_cifar_attention.Group.__getattr__"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" Pytorch Module forward\n\n        Args:\n            x: input\n\n        Returns: group(x)\n\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "x", "=", "self", ".", "__getattr__", "(", "\"block_%d\"", "%", "i", ")", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.WideResNetAttention.__init__": [[106, 149], ["super().__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "wide_resnet_cifar_attention.Group", "wide_resnet_cifar_attention.Group", "wide_resnet_cifar_attention.Group", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "print", "modules.attention.Gate", "int", "modules.attention.AttentionModule", "wide_resnet_cifar_attention.WideResNetAttention.__setattr__", "range", "str"], "methods", ["home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.WideResNetAttention.__init__"], ["def", "__init__", "(", "self", ",", "depth", ",", "width", ",", "num_classes", ",", "dropout", ",", "attention_depth", ",", "attention_width", ",", "reg_w", "=", "0", ",", "\n", "attention_type", "=", "\"softmax\"", ")", ":", "\n", "        ", "\"\"\" Constructor\n\n        Args:\n            depth: network depth\n            width: network width\n            num_classes: number of output classes\n            dropout: dropout prob\n            attention_depth: number of attention modules\n            attention_width: number of attention heads per module\n            reg_w: multihead attention regularization coefficient\n            attention_type: gating function\n        \"\"\"", "\n", "super", "(", "WideResNetAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "(", "depth", "-", "4", ")", "%", "6", "==", "0", ",", "'depth should be 6n+4'", "\n", "self", ".", "n", "=", "(", "depth", "-", "4", ")", "//", "6", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "widths", "=", "[", "int", "(", "x", "*", "width", ")", "for", "x", "in", "[", "16", ",", "32", ",", "64", "]", "]", "\n", "self", ".", "conv0", "=", "torch", ".", "nn", ".", "Conv2d", "(", "3", ",", "16", ",", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn0", "=", "torch", ".", "nn", ".", "BatchNorm2d", "(", "16", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "conv0", ".", "weight", ".", "data", ")", "\n", "self", ".", "group_0", "=", "Group", "(", "16", ",", "widths", "[", "0", "]", ",", "self", ".", "n", ",", "1", ",", "dropout", ")", "\n", "self", ".", "group_1", "=", "Group", "(", "widths", "[", "0", "]", ",", "widths", "[", "1", "]", ",", "self", ".", "n", ",", "2", ",", "dropout", ")", "\n", "self", ".", "group_2", "=", "Group", "(", "widths", "[", "1", "]", ",", "widths", "[", "2", "]", ",", "self", ".", "n", ",", "2", ",", "dropout", ")", "\n", "self", ".", "bn_g2", "=", "torch", ".", "nn", ".", "BatchNorm2d", "(", "widths", "[", "2", "]", ")", "\n", "self", ".", "classifier", "=", "torch", ".", "nn", ".", "Linear", "(", "widths", "[", "2", "]", ",", "self", ".", "num_classes", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "classifier", ".", "weight", ")", "\n", "\n", "self", ".", "attention_depth", "=", "attention_depth", "\n", "self", ".", "attention_width", "=", "attention_width", "\n", "self", ".", "reg_w", "=", "reg_w", "\n", "self", ".", "attention_type", "=", "attention_type", "\n", "\n", "self", ".", "attention_layers", "=", "[", "2", "-", "i", "for", "i", "in", "range", "(", "self", ".", "attention_depth", ")", "]", "\n", "print", "(", "\"Attention after groups %s\"", "%", "(", "str", "(", "self", ".", "attention_layers", ")", ")", ")", "\n", "for", "i", "in", "self", ".", "attention_layers", ":", "\n", "            ", "att", "=", "AttentionModule", "(", "widths", "[", "i", "]", ",", "num_classes", ",", "attention_width", ",", "reg_w", ")", "\n", "self", ".", "__setattr__", "(", "\"att%d\"", "%", "(", "i", ")", ",", "att", ")", "\n", "\n", "", "ngates", "=", "self", ".", "attention_depth", "+", "1", "\n", "\n", "self", ".", "output_gate", "=", "Gate", "(", "widths", "[", "-", "1", "]", ",", "ngates", ",", "gate_depth", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.WideResNetAttention.reg_loss": [[150, 160], ["range", "wide_resnet_cifar_attention.WideResNetAttention.__getattr__().reg_loss", "wide_resnet_cifar_attention.WideResNetAttention.__getattr__"], "methods", ["home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.WideResNetAttention.reg_loss"], ["", "def", "reg_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\" Compute regularization loss\n\n        Returns: the total accumulated reg loss of the network\n\n        \"\"\"", "\n", "loss", "=", "0", "\n", "for", "i", "in", "range", "(", "self", ".", "attention_depth", ")", ":", "\n", "            ", "loss", "+=", "self", ".", "__getattr__", "(", "\"att%i\"", "%", "self", ".", "attention_layers", "[", "i", "]", ")", ".", "reg_loss", "(", ")", "\n", "", "return", "loss", "/", "self", ".", "attention_depth", "\n", "\n"]], "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.WideResNetAttention.forward": [[161, 195], ["torch.relu", "torch.relu", "wide_resnet_cifar_attention.WideResNetAttention.group_0", "wide_resnet_cifar_attention.WideResNetAttention.group_1", "torch.relu", "torch.relu", "torch.avg_pool2d", "torch.avg_pool2d", "o.view.view.view", "wide_resnet_cifar_attention.WideResNetAttention.output_gate", "attention_outputs.append", "modules.attention.AttentionModule.aggregate", "wide_resnet_cifar_attention.WideResNetAttention.bn0", "wide_resnet_cifar_attention.WideResNetAttention.bn_g2", "attention_outputs.append", "o.view.view.size", "wide_resnet_cifar_attention.WideResNetAttention.reg_loss", "wide_resnet_cifar_attention.WideResNetAttention.classifier().view", "wide_resnet_cifar_attention.WideResNetAttention.conv0", "wide_resnet_cifar_attention.WideResNetAttention.group_2", "o.view.view.size", "wide_resnet_cifar_attention.WideResNetAttention.__getattr__", "wide_resnet_cifar_attention.WideResNetAttention.classifier"], "methods", ["home.repos.pwc.inspect_result.prlz77_attend-and-rectify.modules.attention.AttentionModule.aggregate", "home.repos.pwc.inspect_result.prlz77_attend-and-rectify.models.wide_resnet_cifar_attention.WideResNetAttention.reg_loss"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" Pytorch Module forward\n\n        Args:\n            x: input\n\n        Returns: network(input)\n\n        \"\"\"", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "bn0", "(", "self", ".", "conv0", "(", "x", ")", ")", ",", "True", ")", "\n", "group0", "=", "self", ".", "group_0", "(", "x", ")", "\n", "group1", "=", "self", ".", "group_1", "(", "group0", ")", "\n", "group2", "=", "F", ".", "relu", "(", "self", ".", "bn_g2", "(", "self", ".", "group_2", "(", "group1", ")", ")", ",", "True", ")", "\n", "\n", "groups", "=", "[", "self", ".", "group_1", ".", "block_0", ".", "block_input", ",", "self", ".", "group_2", ".", "block_0", ".", "block_input", ",", "group2", "]", "\n", "attention_outputs", "=", "[", "]", "\n", "\n", "for", "i", "in", "self", ".", "attention_layers", ":", "\n", "            ", "attention_outputs", ".", "append", "(", "self", ".", "__getattr__", "(", "\"att%d\"", "%", "i", ")", "(", "groups", "[", "i", "]", ")", ")", "\n", "\n", "", "o", "=", "F", ".", "avg_pool2d", "(", "group2", ",", "8", ",", "1", ",", "0", ")", "\n", "o", "=", "o", ".", "view", "(", "o", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "gates", "=", "self", ".", "output_gate", "(", "o", ")", "\n", "\n", "if", "self", ".", "training", "and", "self", ".", "reg_w", ">", "0", ":", "\n", "            ", "reg_loss", "=", "self", ".", "reg_loss", "(", ")", "\n", "", "else", ":", "\n", "            ", "reg_loss", "=", "None", "\n", "\n", "", "attention_outputs", ".", "append", "(", "self", ".", "classifier", "(", "o", ")", ".", "view", "(", "o", ".", "size", "(", "0", ")", ",", "1", ",", "-", "1", ")", ")", "\n", "ret", "=", "AttentionModule", ".", "aggregate", "(", "attention_outputs", ",", "gates", ",", "self", ".", "attention_type", ")", "\n", "\n", "return", "ret", ",", "reg_loss", "\n", "", "", ""]]}