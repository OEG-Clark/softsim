{"home.repos.pwc.inspect_result.hkust-knowcomp_co2lm.finetune.run_rocstories.DataTrainingArguments.__post_init__": [[139, 146], ["run_rocstories.DataTrainingArguments.train_file.split", "run_rocstories.DataTrainingArguments.test_file.split"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "train_file", "is", "not", "None", ":", "\n", "            ", "extension", "=", "self", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\"csv\"", ",", "\"json\"", "]", ",", "\"`train_file` should be a csv or a json file.\"", "\n", "", "if", "self", ".", "test_file", "is", "not", "None", ":", "\n", "            ", "extension", "=", "self", ".", "test_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\"csv\"", ",", "\"json\"", "]", ",", "\"`validation_file` should be a csv or a json file.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_co2lm.finetune.run_rocstories.DataCollatorForMultipleChoice.__call__": [[180, 205], ["len", "len", "list", "run_rocstories.DataCollatorForMultipleChoice.tokenizer.pad", "torch.tensor", "itertools.chain", "v.view", "features[].keys", "int", "run_rocstories.DataCollatorForMultipleChoice.items", "feature.pop", "range", "feature.items"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "features", ")", ":", "\n", "        ", "label_name", "=", "\"label\"", "if", "\"label\"", "in", "features", "[", "0", "]", ".", "keys", "(", ")", "else", "\"labels\"", "\n", "#labels = [feature.pop(label_name) for feature in features]", "\n", "# reduce label to [0, num_classes-1]", "\n", "labels", "=", "[", "int", "(", "feature", ".", "pop", "(", "label_name", ")", ")", "-", "1", "for", "feature", "in", "features", "]", "\n", "batch_size", "=", "len", "(", "features", ")", "\n", "num_choices", "=", "len", "(", "features", "[", "0", "]", "[", "\"input_ids\"", "]", ")", "\n", "flattened_features", "=", "[", "\n", "[", "{", "k", ":", "v", "[", "i", "]", "for", "k", ",", "v", "in", "feature", ".", "items", "(", ")", "}", "for", "i", "in", "range", "(", "num_choices", ")", "]", "for", "feature", "in", "features", "\n", "]", "\n", "flattened_features", "=", "list", "(", "chain", "(", "*", "flattened_features", ")", ")", "\n", "\n", "batch", "=", "self", ".", "tokenizer", ".", "pad", "(", "\n", "flattened_features", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", "max_length", "=", "self", ".", "max_length", ",", "\n", "pad_to_multiple_of", "=", "self", ".", "pad_to_multiple_of", ",", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", ")", "\n", "\n", "# Un-flatten", "\n", "batch", "=", "{", "k", ":", "v", ".", "view", "(", "batch_size", ",", "num_choices", ",", "-", "1", ")", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", "}", "\n", "# Add back labels", "\n", "batch", "[", "\"labels\"", "]", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_co2lm.finetune.run_rocstories.main": [[207, 480], ["transformers.HfArgumentParser", "logging.basicConfig", "training_args.get_process_log_level", "logger.setLevel", "datasets.utils.logging.set_verbosity", "transformers.utils.logging.set_verbosity", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "logger.warning", "logger.info", "transformers.set_seed", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForMultipleChoice.from_pretrained", "transformers.Trainer", "dict", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "os.path.isdir", "transformers.trainer_utils.get_last_checkpoint", "datasets.load_dataset", "raw_datasets[].train_test_split", "datasets.load_dataset", "min", "list", "list", "AutoTokenizer.from_pretrained.", "run_rocstories.DataCollatorForMultipleChoice", "numpy.argmax", "transformers.Trainer.train", "transformers.Trainer.save_model", "min", "transformers.Trainer.log_metrics", "transformers.Trainer.save_metrics", "transformers.Trainer.save_state", "logger.info", "transformers.Trainer.evaluate", "min", "transformers.Trainer.log_metrics", "transformers.Trainer.save_metrics", "logger.info", "transformers.Trainer.log_metrics", "transformers.Trainer.save_metrics", "transformers.Trainer.push_to_hub", "transformers.Trainer.create_model_card", "len", "ValueError", "data_args.train_file.split", "bool", "range", "range", "logger.warning", "logger.warning", "itertools.chain", "itertools.chain", "ValueError", "min", "train_dataset.map.select", "training_args.main_process_first", "train_dataset.map.map", "min", "eval_dataset.map.select", "training_args.main_process_first", "eval_dataset.map.map", "len", "len", "len", "len", "training_args.main_process_first", "test_dataset.map.map", "transformers.Trainer.predict", "os.path.abspath", "logging.StreamHandler", "len", "logger.info", "range", "range", "tokenizer.items", "len", "range", "len", "range", "bool", "os.listdir", "len", "sep_token.join", "len", "range", "len"], "function", ["None"], ["", "", "def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "TrainingArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "# Setup logging", "\n", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "log_level", "=", "training_args", ".", "get_process_log_level", "(", ")", "\n", "logger", ".", "setLevel", "(", "log_level", ")", "\n", "datasets", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "logger", ".", "info", "(", "f\"Training/evaluation parameters {training_args}\"", ")", "\n", "\n", "# Detecting last checkpoint.", "\n", "last_checkpoint", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "training_args", ".", "output_dir", ")", "and", "training_args", ".", "do_train", "and", "not", "training_args", ".", "overwrite_output_dir", ":", "\n", "        ", "last_checkpoint", "=", "get_last_checkpoint", "(", "training_args", ".", "output_dir", ")", "\n", "if", "last_checkpoint", "is", "None", "and", "len", "(", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"", "\n", "\"Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "", "elif", "last_checkpoint", "is", "not", "None", "and", "training_args", ".", "resume_from_checkpoint", "is", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"", "\n", "\"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"", "\n", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "", "", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Get the datasets: you can either provide your own CSV/JSON/TXT training and evaluation files (see below)", "\n", "# or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/", "\n", "# (the dataset will be downloaded automatically from the datasets Hub).", "\n", "\n", "# For CSV/JSON files, this script will use the column called 'text' or the first column if no column called", "\n", "# 'text' is found. You can easily tweak this behavior (see below).", "\n", "\n", "# In distributed training, the load_dataset function guarantee that only one local process can concurrently", "\n", "# download the dataset.", "\n", "if", "data_args", ".", "train_file", "is", "not", "None", "or", "data_args", ".", "test_file", "is", "not", "None", ":", "\n", "        ", "data_files", "=", "{", "}", "\n", "if", "data_args", ".", "train_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"train\"", "]", "=", "data_args", ".", "train_file", "\n", "", "if", "data_args", ".", "test_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"test\"", "]", "=", "data_args", ".", "test_file", "\n", "", "extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "raw_datasets", "=", "load_dataset", "(", "\n", "extension", ",", "\n", "data_files", "=", "data_files", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "train_dev", "=", "raw_datasets", "[", "\"train\"", "]", ".", "train_test_split", "(", "test_size", "=", "100", ")", "\n", "", "else", ":", "\n", "# Downloading and loading the swag dataset from the hub.", "\n", "        ", "raw_datasets", "=", "load_dataset", "(", "\n", "\"swag\"", ",", "\n", "\"regular\"", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "# See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at", "\n", "# https://huggingface.co/docs/datasets/loading_datasets.html.", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "\n", "# Distributed training:", "\n", "# The .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "model_args", ".", "config_name", "if", "model_args", ".", "config_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "model_args", ".", "tokenizer_name", "if", "model_args", ".", "tokenizer_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "use_fast", "=", "model_args", ".", "use_fast_tokenizer", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "model", "=", "AutoModelForMultipleChoice", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "\n", "# rocstories have four sentences as contexts and two seconds as choices", "\n", "ending_names", "=", "[", "f\"RandomFifthSentenceQuiz{i}\"", "for", "i", "in", "range", "(", "1", ",", "3", ")", "]", "\n", "context_names", "=", "[", "f\"InputSentence{i}\"", "for", "i", "in", "range", "(", "1", ",", "5", ")", "]", "\n", "\n", "if", "data_args", ".", "max_seq_length", "is", "None", ":", "\n", "        ", "max_seq_length", "=", "tokenizer", ".", "model_max_length", "\n", "if", "max_seq_length", ">", "1024", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "f\"The tokenizer picked seems to have a very large `model_max_length` ({tokenizer.model_max_length}). \"", "\n", "\"Picking 1024 instead. You can change that default value by passing --max_seq_length xxx.\"", "\n", ")", "\n", "max_seq_length", "=", "1024", "\n", "", "", "else", ":", "\n", "        ", "if", "data_args", ".", "max_seq_length", ">", "tokenizer", ".", "model_max_length", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "f\"The max_seq_length passed ({data_args.max_seq_length}) is larger than the maximum length for the\"", "\n", "f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\"", "\n", ")", "\n", "", "max_seq_length", "=", "min", "(", "data_args", ".", "max_seq_length", ",", "tokenizer", ".", "model_max_length", ")", "\n", "\n", "# Preprocessing the datasets.", "\n", "", "def", "preprocess_function", "(", "examples", ")", ":", "\n", "\n", "        ", "sep_token", "=", "tokenizer", ".", "sep_token", "\n", "contexts", "=", "[", "[", "f\"{examples[cxt][i]}\"", "for", "cxt", "in", "context_names", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "examples", "[", "\"InputStoryid\"", "]", ")", ")", "]", "\n", "first_sentences", "=", "[", "[", "sep_token", ".", "join", "(", "context", ")", "]", "*", "2", "for", "context", "in", "contexts", "]", "\n", "second_sentences", "=", "[", "[", "f\"{examples[end][i]}\"", "for", "end", "in", "ending_names", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "examples", "[", "\"InputStoryid\"", "]", ")", ")", "]", "\n", "\n", "# Flatten out", "\n", "first_sentences", "=", "list", "(", "chain", "(", "*", "first_sentences", ")", ")", "\n", "second_sentences", "=", "list", "(", "chain", "(", "*", "second_sentences", ")", ")", "\n", "\n", "# Tokenize", "\n", "tokenized_examples", "=", "tokenizer", "(", "\n", "first_sentences", ",", "\n", "second_sentences", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "max_seq_length", ",", "\n", "padding", "=", "\"max_length\"", "if", "data_args", ".", "pad_to_max_length", "else", "False", ",", "\n", ")", "\n", "# Un-flatten", "\n", "return", "{", "k", ":", "[", "v", "[", "i", ":", "i", "+", "2", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "v", ")", ",", "2", ")", "]", "for", "k", ",", "v", "in", "tokenized_examples", ".", "items", "(", ")", "}", "\n", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "if", "\"train\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_train requires a train dataset\"", ")", "\n", "", "train_dataset", "=", "train_dev", "[", "\"train\"", "]", "\n", "if", "data_args", ".", "max_train_samples", "is", "not", "None", ":", "\n", "            ", "max_train_samples", "=", "min", "(", "len", "(", "train_dataset", ")", ",", "data_args", ".", "max_train_samples", ")", "\n", "train_dataset", "=", "train_dataset", ".", "select", "(", "range", "(", "max_train_samples", ")", ")", "\n", "", "with", "training_args", ".", "main_process_first", "(", "desc", "=", "\"train dataset map pre-processing\"", ")", ":", "\n", "            ", "train_dataset", "=", "train_dataset", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "\n", "", "", "if", "training_args", ".", "do_eval", ":", "\n", "#if \"validation\" not in raw_datasets:", "\n", "#    raise ValueError(\"--do_eval requires a validation dataset\")", "\n", "        ", "eval_dataset", "=", "train_dev", "[", "\"test\"", "]", "\n", "if", "data_args", ".", "max_eval_samples", "is", "not", "None", ":", "\n", "            ", "max_eval_samples", "=", "min", "(", "len", "(", "eval_dataset", ")", ",", "data_args", ".", "max_eval_samples", ")", "\n", "eval_dataset", "=", "eval_dataset", ".", "select", "(", "range", "(", "max_eval_samples", ")", ")", "\n", "", "with", "training_args", ".", "main_process_first", "(", "desc", "=", "\"validation dataset map pre-processing\"", ")", ":", "\n", "            ", "eval_dataset", "=", "eval_dataset", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "\n", "# Data collator", "\n", "", "", "data_collator", "=", "(", "\n", "default_data_collator", "\n", "if", "data_args", ".", "pad_to_max_length", "\n", "else", "DataCollatorForMultipleChoice", "(", "tokenizer", "=", "tokenizer", ",", "pad_to_multiple_of", "=", "8", "if", "training_args", ".", "fp16", "else", "None", ")", "\n", ")", "\n", "\n", "# Metric", "\n", "def", "compute_metrics", "(", "eval_predictions", ")", ":", "\n", "        ", "predictions", ",", "label_ids", "=", "eval_predictions", "\n", "preds", "=", "np", ".", "argmax", "(", "predictions", ",", "axis", "=", "1", ")", "\n", "return", "{", "\"accuracy\"", ":", "(", "preds", "==", "label_ids", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "}", "\n", "\n", "# Initialize our Trainer", "\n", "", "trainer", "=", "Trainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "train_dataset", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "eval_dataset", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", "compute_metrics", "=", "compute_metrics", ",", "\n", ")", "\n", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "if", "training_args", ".", "resume_from_checkpoint", "is", "not", "None", ":", "\n", "            ", "checkpoint", "=", "training_args", ".", "resume_from_checkpoint", "\n", "", "elif", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "checkpoint", "=", "last_checkpoint", "\n", "", "train_result", "=", "trainer", ".", "train", "(", "resume_from_checkpoint", "=", "checkpoint", ")", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "metrics", "=", "train_result", ".", "metrics", "\n", "\n", "max_train_samples", "=", "(", "\n", "data_args", ".", "max_train_samples", "if", "data_args", ".", "max_train_samples", "is", "not", "None", "else", "len", "(", "train_dataset", ")", "\n", ")", "\n", "metrics", "[", "\"train_samples\"", "]", "=", "min", "(", "max_train_samples", ",", "len", "(", "train_dataset", ")", ")", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"train\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"train\"", ",", "metrics", ")", "\n", "trainer", ".", "save_state", "(", ")", "\n", "\n", "# Evaluation", "\n", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "\n", "metrics", "=", "trainer", ".", "evaluate", "(", ")", "\n", "max_eval_samples", "=", "data_args", ".", "max_eval_samples", "if", "data_args", ".", "max_eval_samples", "is", "not", "None", "else", "len", "(", "eval_dataset", ")", "\n", "metrics", "[", "\"eval_samples\"", "]", "=", "min", "(", "max_eval_samples", ",", "len", "(", "eval_dataset", ")", ")", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"eval\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"eval\"", ",", "metrics", ")", "\n", "\n", "# Final prediction", "\n", "", "if", "training_args", ".", "do_predict", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Predict ***\"", ")", "\n", "\n", "test_dataset", "=", "raw_datasets", "[", "\"test\"", "]", "\n", "with", "training_args", ".", "main_process_first", "(", "desc", "=", "\"train dataset map pre-processing\"", ")", ":", "\n", "            ", "test_dataset", "=", "test_dataset", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "\n", "# trainer.predict: [predictions, label_ids, metrics]", "\n", "", "metrics", "=", "trainer", ".", "predict", "(", "test_dataset", ")", "[", "2", "]", "\n", "trainer", ".", "log_metrics", "(", "\"test\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"test\"", ",", "metrics", ")", "\n", "\n", "", "kwargs", "=", "dict", "(", "\n", "finetuned_from", "=", "model_args", ".", "model_name_or_path", ",", "\n", "tasks", "=", "\"multiple-choice\"", ",", "\n", "dataset_tags", "=", "\"swag\"", ",", "\n", "dataset_args", "=", "\"regular\"", ",", "\n", "dataset", "=", "\"SWAG\"", ",", "\n", "language", "=", "\"en\"", ",", "\n", ")", "\n", "\n", "if", "training_args", ".", "push_to_hub", ":", "\n", "        ", "trainer", ".", "push_to_hub", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "trainer", ".", "create_model_card", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_co2lm.pretrain.run_mlm.ModelArguments.__post_init__": [[105, 109], ["ValueError"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "config_overrides", "is", "not", "None", "and", "(", "self", ".", "config_name", "is", "not", "None", "or", "self", ".", "model_name_or_path", "is", "not", "None", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"--config_overrides can't be used in combination with --config_name or --model_name_or_path\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_co2lm.pretrain.run_mlm.DataTrainingArguments.__post_init__": [[172, 179], ["run_mlm.DataTrainingArguments.train_file.split", "run_mlm.DataTrainingArguments.validation_file.split"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "train_file", "is", "not", "None", ":", "\n", "            ", "extension", "=", "self", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\"csv\"", ",", "\"json\"", ",", "\"txt\"", "]", ",", "\"`train_file` should be a csv, a json or a txt file.\"", "\n", "", "if", "self", ".", "validation_file", "is", "not", "None", ":", "\n", "            ", "extension", "=", "self", ".", "validation_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\"csv\"", ",", "\"json\"", ",", "\"txt\"", "]", ",", "\"`validation_file` should be a csv, a json or a txt file.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_co2lm.pretrain.run_mlm.add_eventuality_references": [[181, 189], ["datasets.Dataset.from_dict", "open", "len", "len", "json.loads", "f.read().splitlines", "f.read", "len", "line.isspace"], "function", ["None"], ["", "", "", "def", "add_eventuality_references", "(", "dataset", ",", "ref_file", ")", ":", "\n", "    ", "with", "open", "(", "ref_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "refs", "=", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "if", "(", "len", "(", "line", ")", ">", "0", "and", "not", "line", ".", "isspace", "(", ")", ")", "]", "\n", "", "assert", "len", "(", "dataset", ")", "==", "len", "(", "refs", ")", "\n", "\n", "dataset_dict", "=", "{", "c", ":", "dataset", "[", "c", "]", "for", "c", "in", "dataset", ".", "column_names", "}", "\n", "dataset_dict", "[", "\"eventuality_ref\"", "]", "=", "refs", "\n", "return", "Dataset", ".", "from_dict", "(", "dataset_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_co2lm.pretrain.run_mlm.main": [[191, 421], ["transformers.HfArgumentParser", "logging.basicConfig", "logger.setLevel", "logger.warning", "transformers.trainer_utils.is_main_process", "logger.info", "transformers.set_seed", "AutoModelForMaskedLM.from_config.resize_token_embeddings", "datasets.load_dataset.map", "transformers.DataCollatorForWholeWordMask", "transformers.Trainer", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "os.path.isdir", "transformers.trainer_utils.get_last_checkpoint", "transformers.utils.logging.set_verbosity_info", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "datasets.load_dataset", "datasets.load_dataset", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForMaskedLM.from_pretrained", "logger.info", "transformers.AutoModelForMaskedLM.from_config", "len", "AutoTokenizer.from_pretrained.", "add_chinese_references", "add_chinese_references", "transformers.Trainer.train", "transformers.Trainer.save_model", "os.path.join", "transformers.Trainer.is_world_process_zero", "logger.info", "transformers.Trainer.evaluate", "math.exp", "os.path.join", "transformers.Trainer.is_world_process_zero", "len", "ValueError", "transformers.trainer_utils.is_main_process", "datasets.load_dataset.keys", "datasets.load_dataset", "datasets.load_dataset", "data_args.train_file.split", "transformers.AutoConfig.from_pretrained", "logger.warning", "transformers.AutoTokenizer.from_pretrained", "ValueError", "transformers.Trainer.state.save_to_json", "os.path.abspath", "len", "logger.info", "logging.StreamHandler", "logger.info", "AutoConfig.from_pretrained.update_from_string", "logger.info", "bool", "os.path.isdir", "open", "logger.info", "sorted", "os.path.join", "open", "logger.info", "sorted", "os.listdir", "bool", "trainer.train.metrics.items", "logger.info", "writer.write", "results.items", "logger.info", "writer.write", "len", "line.isspace"], "function", ["None"], ["", "def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "TrainingArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "# Detecting last checkpoint.", "\n", "", "last_checkpoint", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "training_args", ".", "output_dir", ")", "and", "training_args", ".", "do_train", "and", "not", "training_args", ".", "overwrite_output_dir", ":", "\n", "        ", "last_checkpoint", "=", "get_last_checkpoint", "(", "training_args", ".", "output_dir", ")", "\n", "if", "last_checkpoint", "is", "None", "and", "len", "(", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"", "\n", "\"Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "", "elif", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"", "\n", "\"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"", "\n", ")", "\n", "\n", "# Setup logging", "\n", "", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", "else", "logging", ".", "WARN", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "# Set the verbosity to info of the Transformers logger (on main process only):", "\n", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", ":", "\n", "        ", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity_info", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "training_args", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Get the datasets: you can either provide your own CSV/JSON/TXT training and evaluation files (see below)", "\n", "# or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/", "\n", "# (the dataset will be downloaded automatically from the datasets Hub).", "\n", "#", "\n", "# For CSV/JSON files, this script will use the column called 'text' or the first column if no column called", "\n", "# 'text' is found. You can easily tweak this behavior (see below).", "\n", "#", "\n", "# In distributed training, the load_dataset function guarantee that only one local process can concurrently", "\n", "# download the dataset.", "\n", "if", "data_args", ".", "dataset_name", "is", "not", "None", ":", "\n", "# Downloading and loading a dataset from the hub.", "\n", "        ", "datasets", "=", "load_dataset", "(", "data_args", ".", "dataset_name", ",", "data_args", ".", "dataset_config_name", ")", "\n", "if", "\"validation\"", "not", "in", "datasets", ".", "keys", "(", ")", ":", "\n", "            ", "datasets", "[", "\"validation\"", "]", "=", "load_dataset", "(", "\n", "data_args", ".", "dataset_name", ",", "\n", "data_args", ".", "dataset_config_name", ",", "\n", "split", "=", "f\"train[:{data_args.validation_split_percentage}%]\"", ",", "\n", ")", "\n", "datasets", "[", "\"train\"", "]", "=", "load_dataset", "(", "\n", "data_args", ".", "dataset_name", ",", "\n", "data_args", ".", "dataset_config_name", ",", "\n", "split", "=", "f\"train[{data_args.validation_split_percentage}%:]\"", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "        ", "data_files", "=", "{", "}", "\n", "if", "data_args", ".", "train_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"train\"", "]", "=", "data_args", ".", "train_file", "\n", "", "if", "data_args", ".", "validation_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"validation\"", "]", "=", "data_args", ".", "validation_file", "\n", "", "extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "if", "extension", "==", "\"txt\"", ":", "\n", "            ", "extension", "=", "\"text\"", "\n", "", "datasets", "=", "load_dataset", "(", "extension", ",", "data_files", "=", "data_files", ")", "\n", "# See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at", "\n", "# https://huggingface.co/docs/datasets/loading_datasets.html.", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "#", "\n", "# Distributed training:", "\n", "# The .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "", "config_kwargs", "=", "{", "\n", "\"cache_dir\"", ":", "model_args", ".", "cache_dir", ",", "\n", "\"revision\"", ":", "model_args", ".", "model_revision", ",", "\n", "\"use_auth_token\"", ":", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", "}", "\n", "if", "model_args", ".", "config_name", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_args", ".", "config_name", ",", "**", "config_kwargs", ")", "\n", "", "elif", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_args", ".", "model_name_or_path", ",", "**", "config_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "CONFIG_MAPPING", "[", "model_args", ".", "model_type", "]", "(", ")", "\n", "logger", ".", "warning", "(", "\"You are instantiating a new config instance from scratch.\"", ")", "\n", "if", "model_args", ".", "config_overrides", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Overriding config: {model_args.config_overrides}\"", ")", "\n", "config", ".", "update_from_string", "(", "model_args", ".", "config_overrides", ")", "\n", "logger", ".", "info", "(", "f\"New config: {config}\"", ")", "\n", "\n", "", "", "tokenizer_kwargs", "=", "{", "\n", "\"cache_dir\"", ":", "model_args", ".", "cache_dir", ",", "\n", "\"use_fast\"", ":", "model_args", ".", "use_fast_tokenizer", ",", "\n", "\"revision\"", ":", "model_args", ".", "model_revision", ",", "\n", "\"use_auth_token\"", ":", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", "}", "\n", "if", "model_args", ".", "tokenizer_name", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_args", ".", "tokenizer_name", ",", "**", "tokenizer_kwargs", ")", "\n", "", "elif", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_args", ".", "model_name_or_path", ",", "**", "tokenizer_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"You are instantiating a new tokenizer from scratch. This is not supported by this script.\"", "\n", "\"You can do it from another script, save it, and load it from here, using --tokenizer_name.\"", "\n", ")", "\n", "\n", "", "if", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "model", "=", "AutoModelForMaskedLM", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Training new model from scratch\"", ")", "\n", "model", "=", "AutoModelForMaskedLM", ".", "from_config", "(", "config", ")", "\n", "\n", "", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "# Preprocessing the datasets.", "\n", "# First we tokenize all the texts.", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "column_names", "=", "datasets", "[", "\"train\"", "]", ".", "column_names", "\n", "", "else", ":", "\n", "        ", "column_names", "=", "datasets", "[", "\"validation\"", "]", ".", "column_names", "\n", "", "text_column_name", "=", "\"text\"", "if", "\"text\"", "in", "column_names", "else", "column_names", "[", "0", "]", "\n", "\n", "padding", "=", "\"max_length\"", "if", "data_args", ".", "pad_to_max_length", "else", "False", "\n", "\n", "def", "tokenize_function", "(", "examples", ")", ":", "\n", "# Remove empty lines", "\n", "        ", "examples", "[", "\"text\"", "]", "=", "[", "line", "for", "line", "in", "examples", "[", "\"text\"", "]", "if", "len", "(", "line", ")", ">", "0", "and", "not", "line", ".", "isspace", "(", ")", "]", "\n", "return", "tokenizer", "(", "examples", "[", "\"text\"", "]", ",", "padding", "=", "padding", ",", "truncation", "=", "True", ",", "max_length", "=", "data_args", ".", "max_seq_length", ")", "\n", "\n", "", "tokenized_datasets", "=", "datasets", ".", "map", "(", "\n", "tokenize_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "[", "text_column_name", "]", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "\n", "# Add the chinese references if provided", "\n", "if", "data_args", ".", "train_ref_file", "is", "not", "None", ":", "\n", "        ", "tokenized_datasets", "[", "\"train\"", "]", "=", "add_chinese_references", "(", "tokenized_datasets", "[", "\"train\"", "]", ",", "data_args", ".", "train_ref_file", ")", "\n", "", "if", "data_args", ".", "validation_ref_file", "is", "not", "None", ":", "\n", "        ", "tokenized_datasets", "[", "\"validation\"", "]", "=", "add_chinese_references", "(", "\n", "tokenized_datasets", "[", "\"validation\"", "]", ",", "data_args", ".", "validation_ref_file", "\n", ")", "\n", "# If we have ref files, need to avoid it removed by trainer", "\n", "", "has_ref", "=", "data_args", ".", "train_ref_file", "or", "data_args", ".", "validation_ref_file", "\n", "if", "has_ref", ":", "\n", "        ", "training_args", ".", "remove_unused_columns", "=", "False", "\n", "\n", "# Data collator", "\n", "# This one will take care of randomly masking the tokens.", "\n", "", "data_collator", "=", "DataCollatorForWholeWordMask", "(", "tokenizer", "=", "tokenizer", ",", "mlm_probability", "=", "data_args", ".", "mlm_probability", ")", "\n", "\n", "# Initialize our Trainer", "\n", "trainer", "=", "Trainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "tokenized_datasets", "[", "\"train\"", "]", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "tokenized_datasets", "[", "\"validation\"", "]", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", ")", "\n", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "if", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "checkpoint", "=", "last_checkpoint", "\n", "", "elif", "model_args", ".", "model_name_or_path", "is", "not", "None", "and", "os", ".", "path", ".", "isdir", "(", "model_args", ".", "model_name_or_path", ")", ":", "\n", "            ", "checkpoint", "=", "model_args", ".", "model_name_or_path", "\n", "", "else", ":", "\n", "            ", "checkpoint", "=", "None", "\n", "", "train_result", "=", "trainer", ".", "train", "(", "resume_from_checkpoint", "=", "checkpoint", ")", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "\n", "output_train_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"train_results.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_train_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Train results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "train_result", ".", "metrics", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "# Need to save the state, since Trainer.save_model saves only the tokenizer with the model", "\n", "", "", "trainer", ".", "state", ".", "save_to_json", "(", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"trainer_state.json\"", ")", ")", "\n", "\n", "# Evaluation", "\n", "", "", "results", "=", "{", "}", "\n", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "\n", "eval_output", "=", "trainer", ".", "evaluate", "(", ")", "\n", "\n", "perplexity", "=", "math", ".", "exp", "(", "eval_output", "[", "\"eval_loss\"", "]", ")", "\n", "results", "[", "\"perplexity\"", "]", "=", "perplexity", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"eval_results_mlm_wwm.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "results", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hkust-knowcomp_co2lm.pretrain.run_mlm._mp_fn": [[423, 426], ["run_mlm.main"], "function", ["home.repos.pwc.inspect_result.hkust-knowcomp_co2lm.pretrain.run_mlm.main"], ["", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n"]]}