{"home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.main.main": [[25, 65], ["pickle.load", "pickle.load", "util.Data", "util.Data", "model.trans_to_cuda", "range", "open", "open", "model.DHCN", "print", "print", "model.train_test", "print", "print", "np.mean", "np.mean"], "function", ["home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.trans_to_cuda", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.train_test"], ["def", "main", "(", ")", ":", "\n", "    ", "train_data", "=", "pickle", ".", "load", "(", "open", "(", "'../datasets/'", "+", "opt", ".", "dataset", "+", "'/train.txt'", ",", "'rb'", ")", ")", "\n", "test_data", "=", "pickle", ".", "load", "(", "open", "(", "'../datasets/'", "+", "opt", ".", "dataset", "+", "'/test.txt'", ",", "'rb'", ")", ")", "\n", "\n", "if", "opt", ".", "dataset", "==", "'diginetica'", ":", "\n", "        ", "n_node", "=", "43097", "\n", "", "elif", "opt", ".", "dataset", "==", "'Tmall'", ":", "\n", "        ", "n_node", "=", "40727", "\n", "", "elif", "opt", ".", "dataset", "==", "'Nowplaying'", ":", "\n", "        ", "n_node", "=", "60416", "\n", "", "else", ":", "\n", "        ", "n_node", "=", "309", "\n", "", "train_data", "=", "Data", "(", "train_data", ",", "shuffle", "=", "True", ",", "n_node", "=", "n_node", ")", "\n", "test_data", "=", "Data", "(", "test_data", ",", "shuffle", "=", "True", ",", "n_node", "=", "n_node", ")", "\n", "model", "=", "trans_to_cuda", "(", "DHCN", "(", "adjacency", "=", "train_data", ".", "adjacency", ",", "n_node", "=", "n_node", ",", "lr", "=", "opt", ".", "lr", ",", "l2", "=", "opt", ".", "l2", ",", "beta", "=", "opt", ".", "beta", ",", "layers", "=", "opt", ".", "layer", ",", "emb_size", "=", "opt", ".", "embSize", ",", "batch_size", "=", "opt", ".", "batchSize", ",", "dataset", "=", "opt", ".", "dataset", ")", ")", "\n", "\n", "top_K", "=", "[", "5", ",", "10", ",", "20", "]", "\n", "best_results", "=", "{", "}", "\n", "for", "K", "in", "top_K", ":", "\n", "        ", "best_results", "[", "'epoch%d'", "%", "K", "]", "=", "[", "0", ",", "0", "]", "\n", "best_results", "[", "'metric%d'", "%", "K", "]", "=", "[", "0", ",", "0", "]", "\n", "\n", "", "for", "epoch", "in", "range", "(", "opt", ".", "epoch", ")", ":", "\n", "        ", "print", "(", "'-------------------------------------------------------'", ")", "\n", "print", "(", "'epoch: '", ",", "epoch", ")", "\n", "metrics", ",", "total_loss", "=", "train_test", "(", "model", ",", "train_data", ",", "test_data", ")", "\n", "for", "K", "in", "top_K", ":", "\n", "            ", "metrics", "[", "'hit%d'", "%", "K", "]", "=", "np", ".", "mean", "(", "metrics", "[", "'hit%d'", "%", "K", "]", ")", "*", "100", "\n", "metrics", "[", "'mrr%d'", "%", "K", "]", "=", "np", ".", "mean", "(", "metrics", "[", "'mrr%d'", "%", "K", "]", ")", "*", "100", "\n", "if", "best_results", "[", "'metric%d'", "%", "K", "]", "[", "0", "]", "<", "metrics", "[", "'hit%d'", "%", "K", "]", ":", "\n", "                ", "best_results", "[", "'metric%d'", "%", "K", "]", "[", "0", "]", "=", "metrics", "[", "'hit%d'", "%", "K", "]", "\n", "best_results", "[", "'epoch%d'", "%", "K", "]", "[", "0", "]", "=", "epoch", "\n", "", "if", "best_results", "[", "'metric%d'", "%", "K", "]", "[", "1", "]", "<", "metrics", "[", "'mrr%d'", "%", "K", "]", ":", "\n", "                ", "best_results", "[", "'metric%d'", "%", "K", "]", "[", "1", "]", "=", "metrics", "[", "'mrr%d'", "%", "K", "]", "\n", "best_results", "[", "'epoch%d'", "%", "K", "]", "[", "1", "]", "=", "epoch", "\n", "", "", "print", "(", "metrics", ")", "\n", "for", "K", "in", "top_K", ":", "\n", "            ", "print", "(", "'train_loss:\\t%.4f\\tRecall@%d: %.4f\\tMRR%d: %.4f\\tEpoch: %d,  %d'", "%", "\n", "(", "total_loss", ",", "K", ",", "best_results", "[", "'metric%d'", "%", "K", "]", "[", "0", "]", ",", "K", ",", "best_results", "[", "'metric%d'", "%", "K", "]", "[", "1", "]", ",", "\n", "best_results", "[", "'epoch%d'", "%", "K", "]", "[", "0", "]", ",", "best_results", "[", "'epoch%d'", "%", "K", "]", "[", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.HyperConv.__init__": [[25, 30], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.util.Data.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ",", "dataset", ",", "emb_size", "=", "100", ")", ":", "\n", "        ", "super", "(", "HyperConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "emb_size", "=", "emb_size", "\n", "self", ".", "layers", "=", "layers", "\n", "self", ".", "dataset", "=", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.HyperConv.forward": [[31, 42], ["range", "torch.sparse.mm", "torch.sparse.mm", "torch.sparse.mm", "torch.sparse.mm", "torch.sparse.mm", "torch.sparse.mm", "torch.sparse.mm", "torch.sparse.mm", "torch.sparse.mm", "final.append", "numpy.sum", "model.trans_to_cuda"], "methods", ["home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.trans_to_cuda"], ["", "def", "forward", "(", "self", ",", "adjacency", ",", "embedding", ")", ":", "\n", "        ", "item_embeddings", "=", "embedding", "\n", "item_embedding_layer0", "=", "item_embeddings", "\n", "final", "=", "[", "item_embedding_layer0", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "layers", ")", ":", "\n", "            ", "item_embeddings", "=", "torch", ".", "sparse", ".", "mm", "(", "trans_to_cuda", "(", "adjacency", ")", ",", "item_embeddings", ")", "\n", "final", ".", "append", "(", "item_embeddings", ")", "\n", "#  final1 = trans_to_cuda(torch.tensor([item.cpu().detach().numpy() for item in final]))", "\n", "#  item_embeddings = torch.sum(final1, 0)", "\n", "", "item_embeddings", "=", "np", ".", "sum", "(", "final", ",", "0", ")", "/", "(", "self", ".", "layers", "+", "1", ")", "\n", "return", "item_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.LineConv.__init__": [[45, 50], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.util.Data.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ",", "batch_size", ",", "emb_size", "=", "100", ")", ":", "\n", "        ", "super", "(", "LineConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "emb_size", "=", "emb_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "layers", "=", "layers", "\n", "", "def", "forward", "(", "self", ",", "item_embedding", ",", "D", ",", "A", ",", "session_item", ",", "session_len", ")", ":", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.LineConv.forward": [[50, 68], ["torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "model.trans_to_cuda", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.mm().float", "torch.mm().float", "torch.mm().float", "torch.mm().float", "torch.mm().float", "torch.mm().float", "torch.mm().float", "torch.mm().float", "torch.mm().float", "range", "len", "seq_h.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "session.append", "numpy.sum", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "item.cpu().detach().numpy", "item.cpu().detach", "item.cpu"], "methods", ["home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.trans_to_cuda"], ["", "def", "forward", "(", "self", ",", "item_embedding", ",", "D", ",", "A", ",", "session_item", ",", "session_len", ")", ":", "\n", "        ", "zeros", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "1", ",", "self", ".", "emb_size", ")", ".", "fill_", "(", "0", ")", "\n", "# zeros = torch.zeros([1,self.emb_size])", "\n", "item_embedding", "=", "torch", ".", "cat", "(", "[", "zeros", ",", "item_embedding", "]", ",", "0", ")", "\n", "seq_h", "=", "[", "]", "\n", "for", "i", "in", "torch", ".", "arange", "(", "len", "(", "session_item", ")", ")", ":", "\n", "            ", "seq_h", ".", "append", "(", "torch", ".", "index_select", "(", "item_embedding", ",", "0", ",", "session_item", "[", "i", "]", ")", ")", "\n", "", "seq_h1", "=", "trans_to_cuda", "(", "torch", ".", "tensor", "(", "[", "item", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "for", "item", "in", "seq_h", "]", ")", ")", "\n", "session_emb_lgcn", "=", "torch", ".", "div", "(", "torch", ".", "sum", "(", "seq_h1", ",", "1", ")", ",", "session_len", ")", "\n", "session", "=", "[", "session_emb_lgcn", "]", "\n", "DA", "=", "torch", ".", "mm", "(", "D", ",", "A", ")", ".", "float", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "layers", ")", ":", "\n", "            ", "session_emb_lgcn", "=", "torch", ".", "mm", "(", "DA", ",", "session_emb_lgcn", ")", "\n", "session", ".", "append", "(", "session_emb_lgcn", ")", "\n", "#session1 = trans_to_cuda(torch.tensor([item.cpu().detach().numpy() for item in session]))", "\n", "#session_emb_lgcn = torch.sum(session1, 0)", "\n", "", "session_emb_lgcn", "=", "np", ".", "sum", "(", "session", ",", "0", ")", "/", "(", "self", ".", "layers", "+", "1", ")", "\n", "return", "session_emb_lgcn", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.DHCN.__init__": [[71, 106], ["torch.nn.Module.__init__", "numpy.vstack", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.sparse.FloatTensor", "torch.sparse.FloatTensor", "torch.sparse.FloatTensor", "torch.sparse.FloatTensor", "torch.sparse.FloatTensor", "torch.sparse.FloatTensor", "torch.sparse.FloatTensor", "torch.sparse.FloatTensor", "torch.sparse.FloatTensor", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "model.HyperConv", "model.LineConv", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "model.DHCN.init_parameters", "numpy.delete", "numpy.delete", "numpy.delete", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "model.DHCN.parameters"], "methods", ["home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.util.Data.__init__", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.DHCN.init_parameters"], ["    ", "def", "__init__", "(", "self", ",", "adjacency", ",", "n_node", ",", "lr", ",", "layers", ",", "l2", ",", "beta", ",", "dataset", ",", "emb_size", "=", "100", ",", "batch_size", "=", "100", ")", ":", "\n", "        ", "super", "(", "DHCN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "emb_size", "=", "emb_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "n_node", "=", "n_node", "\n", "self", ".", "L2", "=", "l2", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "layers", "=", "layers", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "dataset", "=", "dataset", "\n", "\n", "values", "=", "adjacency", ".", "data", "\n", "indices", "=", "np", ".", "vstack", "(", "(", "adjacency", ".", "row", ",", "adjacency", ".", "col", ")", ")", "\n", "if", "dataset", "==", "'Nowplaying'", ":", "\n", "            ", "index_fliter", "=", "(", "values", "<", "0.05", ")", ".", "nonzero", "(", ")", "\n", "values", "=", "np", ".", "delete", "(", "values", ",", "index_fliter", ")", "\n", "indices1", "=", "np", ".", "delete", "(", "indices", "[", "0", "]", ",", "index_fliter", ")", "\n", "indices2", "=", "np", ".", "delete", "(", "indices", "[", "1", "]", ",", "index_fliter", ")", "\n", "indices", "=", "[", "indices1", ",", "indices2", "]", "\n", "", "i", "=", "torch", ".", "LongTensor", "(", "indices", ")", "\n", "v", "=", "torch", ".", "FloatTensor", "(", "values", ")", "\n", "shape", "=", "adjacency", ".", "shape", "\n", "adjacency", "=", "torch", ".", "sparse", ".", "FloatTensor", "(", "i", ",", "v", ",", "torch", ".", "Size", "(", "shape", ")", ")", "\n", "self", ".", "adjacency", "=", "adjacency", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "self", ".", "n_node", ",", "self", ".", "emb_size", ")", "\n", "self", ".", "pos_embedding", "=", "nn", ".", "Embedding", "(", "200", ",", "self", ".", "emb_size", ")", "\n", "self", ".", "HyperGraph", "=", "HyperConv", "(", "self", ".", "layers", ",", "dataset", ")", "\n", "self", ".", "LineGraph", "=", "LineConv", "(", "self", ".", "layers", ",", "self", ".", "batch_size", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "2", "*", "self", ".", "emb_size", ",", "self", ".", "emb_size", ")", "\n", "self", ".", "w_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "emb_size", ",", "1", ")", ")", "\n", "self", ".", "glu1", "=", "nn", ".", "Linear", "(", "self", ".", "emb_size", ",", "self", ".", "emb_size", ")", "\n", "self", ".", "glu2", "=", "nn", ".", "Linear", "(", "self", ".", "emb_size", ",", "self", ".", "emb_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "loss_function", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ")", "\n", "self", ".", "init_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.DHCN.init_parameters": [[107, 111], ["model.DHCN.parameters", "math.sqrt", "weight.data.uniform_"], "methods", ["None"], ["", "def", "init_parameters", "(", "self", ")", ":", "\n", "        ", "stdv", "=", "1.0", "/", "math", ".", "sqrt", "(", "self", ".", "emb_size", ")", "\n", "for", "weight", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "weight", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.DHCN.generate_sess_emb": [[113, 136], ["torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "mask.float().unsqueeze.float().unsqueeze.float().unsqueeze", "pos_emb.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "hs.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "model.DHCN.w_1", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "get", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "mask.float().unsqueeze.float().unsqueeze.float", "pos_emb.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "hs.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "model.DHCN.glu1", "model.DHCN.glu2", "list"], "methods", ["None"], ["", "", "def", "generate_sess_emb", "(", "self", ",", "item_embedding", ",", "session_item", ",", "session_len", ",", "reversed_sess_item", ",", "mask", ")", ":", "\n", "        ", "zeros", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "1", ",", "self", ".", "emb_size", ")", ".", "fill_", "(", "0", ")", "\n", "# zeros = torch.zeros(1, self.emb_size)", "\n", "item_embedding", "=", "torch", ".", "cat", "(", "[", "zeros", ",", "item_embedding", "]", ",", "0", ")", "\n", "get", "=", "lambda", "i", ":", "item_embedding", "[", "reversed_sess_item", "[", "i", "]", "]", "\n", "seq_h", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "self", ".", "batch_size", ",", "list", "(", "reversed_sess_item", ".", "shape", ")", "[", "1", "]", ",", "self", ".", "emb_size", ")", ".", "fill_", "(", "0", ")", "\n", "# seq_h = torch.zeros(self.batch_size, list(reversed_sess_item.shape)[1], self.emb_size)", "\n", "for", "i", "in", "torch", ".", "arange", "(", "session_item", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "seq_h", "[", "i", "]", "=", "get", "(", "i", ")", "\n", "", "hs", "=", "torch", ".", "div", "(", "torch", ".", "sum", "(", "seq_h", ",", "1", ")", ",", "session_len", ")", "\n", "mask", "=", "mask", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "len", "=", "seq_h", ".", "shape", "[", "1", "]", "\n", "pos_emb", "=", "self", ".", "pos_embedding", ".", "weight", "[", ":", "len", "]", "\n", "pos_emb", "=", "pos_emb", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "self", ".", "batch_size", ",", "1", ",", "1", ")", "\n", "\n", "hs", "=", "hs", ".", "unsqueeze", "(", "-", "2", ")", ".", "repeat", "(", "1", ",", "len", ",", "1", ")", "\n", "nh", "=", "self", ".", "w_1", "(", "torch", ".", "cat", "(", "[", "pos_emb", ",", "seq_h", "]", ",", "-", "1", ")", ")", "\n", "nh", "=", "torch", ".", "tanh", "(", "nh", ")", "\n", "nh", "=", "torch", ".", "sigmoid", "(", "self", ".", "glu1", "(", "nh", ")", "+", "self", ".", "glu2", "(", "hs", ")", ")", "\n", "beta", "=", "torch", ".", "matmul", "(", "nh", ",", "self", ".", "w_2", ")", "\n", "beta", "=", "beta", "*", "mask", "\n", "select", "=", "torch", ".", "sum", "(", "beta", "*", "seq_h", ",", "1", ")", "\n", "return", "select", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.DHCN.generate_sess_emb_npos": [[137, 160], ["torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.cuda.FloatTensor().fill_", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "mask.float().unsqueeze.float().unsqueeze.float().unsqueeze", "hs.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "get", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "mask.float().unsqueeze.float().unsqueeze.float", "hs.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "model.DHCN.glu1", "model.DHCN.glu2", "list"], "methods", ["None"], ["", "def", "generate_sess_emb_npos", "(", "self", ",", "item_embedding", ",", "session_item", ",", "session_len", ",", "reversed_sess_item", ",", "mask", ")", ":", "\n", "        ", "zeros", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "1", ",", "self", ".", "emb_size", ")", ".", "fill_", "(", "0", ")", "\n", "# zeros = torch.zeros(1, self.emb_size)", "\n", "item_embedding", "=", "torch", ".", "cat", "(", "[", "zeros", ",", "item_embedding", "]", ",", "0", ")", "\n", "get", "=", "lambda", "i", ":", "item_embedding", "[", "reversed_sess_item", "[", "i", "]", "]", "\n", "seq_h", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "self", ".", "batch_size", ",", "list", "(", "reversed_sess_item", ".", "shape", ")", "[", "1", "]", ",", "self", ".", "emb_size", ")", ".", "fill_", "(", "0", ")", "\n", "# seq_h = torch.zeros(self.batch_size, list(reversed_sess_item.shape)[1], self.emb_size)", "\n", "for", "i", "in", "torch", ".", "arange", "(", "session_item", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "seq_h", "[", "i", "]", "=", "get", "(", "i", ")", "\n", "", "hs", "=", "torch", ".", "div", "(", "torch", ".", "sum", "(", "seq_h", ",", "1", ")", ",", "session_len", ")", "\n", "mask", "=", "mask", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "len", "=", "seq_h", ".", "shape", "[", "1", "]", "\n", "# pos_emb = self.pos_embedding.weight[:len]", "\n", "# pos_emb = pos_emb.unsqueeze(0).repeat(self.batch_size, 1, 1)", "\n", "\n", "hs", "=", "hs", ".", "unsqueeze", "(", "-", "2", ")", ".", "repeat", "(", "1", ",", "len", ",", "1", ")", "\n", "nh", "=", "seq_h", "\n", "nh", "=", "torch", ".", "tanh", "(", "nh", ")", "\n", "nh", "=", "torch", ".", "sigmoid", "(", "self", ".", "glu1", "(", "nh", ")", "+", "self", ".", "glu2", "(", "hs", ")", ")", "\n", "beta", "=", "torch", ".", "matmul", "(", "nh", ",", "self", ".", "w_2", ")", "\n", "beta", "=", "beta", "*", "mask", "\n", "select", "=", "torch", ".", "sum", "(", "beta", "*", "seq_h", ",", "1", ")", "\n", "return", "select", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.DHCN.SSL": [[161, 178], ["model.DHCN.SSL.score"], "methods", ["None"], ["", "def", "SSL", "(", "self", ",", "sess_emb_hgnn", ",", "sess_emb_lgcn", ")", ":", "\n", "        ", "def", "row_shuffle", "(", "embedding", ")", ":", "\n", "            ", "corrupted_embedding", "=", "embedding", "[", "torch", ".", "randperm", "(", "embedding", ".", "size", "(", ")", "[", "0", "]", ")", "]", "\n", "return", "corrupted_embedding", "\n", "", "def", "row_column_shuffle", "(", "embedding", ")", ":", "\n", "            ", "corrupted_embedding", "=", "embedding", "[", "torch", ".", "randperm", "(", "embedding", ".", "size", "(", ")", "[", "0", "]", ")", "]", "\n", "corrupted_embedding", "=", "corrupted_embedding", "[", ":", ",", "torch", ".", "randperm", "(", "corrupted_embedding", ".", "size", "(", ")", "[", "1", "]", ")", "]", "\n", "return", "corrupted_embedding", "\n", "", "def", "score", "(", "x1", ",", "x2", ")", ":", "\n", "            ", "return", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "x1", ",", "x2", ")", ",", "1", ")", "\n", "\n", "", "pos", "=", "score", "(", "sess_emb_hgnn", ",", "sess_emb_lgcn", ")", "\n", "neg1", "=", "score", "(", "sess_emb_lgcn", ",", "row_column_shuffle", "(", "sess_emb_hgnn", ")", ")", "\n", "one", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "neg1", ".", "shape", "[", "0", "]", ")", ".", "fill_", "(", "1", ")", "\n", "# one = zeros = torch.ones(neg1.shape[0])", "\n", "con_loss", "=", "torch", ".", "sum", "(", "-", "torch", ".", "log", "(", "1e-8", "+", "torch", ".", "sigmoid", "(", "pos", ")", ")", "-", "torch", ".", "log", "(", "1e-8", "+", "(", "one", "-", "torch", ".", "sigmoid", "(", "neg1", ")", ")", ")", ")", "\n", "return", "con_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.DHCN.forward": [[179, 188], ["model.DHCN.HyperGraph", "model.DHCN.LineGraph", "model.DHCN.SSL", "model.DHCN.generate_sess_emb_npos", "model.DHCN.generate_sess_emb"], "methods", ["home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.DHCN.SSL", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.DHCN.generate_sess_emb_npos", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.DHCN.generate_sess_emb"], ["", "def", "forward", "(", "self", ",", "session_item", ",", "session_len", ",", "D", ",", "A", ",", "reversed_sess_item", ",", "mask", ")", ":", "\n", "        ", "item_embeddings_hg", "=", "self", ".", "HyperGraph", "(", "self", ".", "adjacency", ",", "self", ".", "embedding", ".", "weight", ")", "\n", "if", "self", ".", "dataset", "==", "'Tmall'", ":", "\n", "            ", "sess_emb_hgnn", "=", "self", ".", "generate_sess_emb_npos", "(", "item_embeddings_hg", ",", "session_item", ",", "session_len", ",", "reversed_sess_item", ",", "mask", ")", "\n", "", "else", ":", "\n", "            ", "sess_emb_hgnn", "=", "self", ".", "generate_sess_emb", "(", "item_embeddings_hg", ",", "session_item", ",", "session_len", ",", "reversed_sess_item", ",", "mask", ")", "\n", "", "session_emb_lg", "=", "self", ".", "LineGraph", "(", "self", ".", "embedding", ".", "weight", ",", "D", ",", "A", ",", "session_item", ",", "session_len", ")", "\n", "con_loss", "=", "self", ".", "SSL", "(", "sess_emb_hgnn", ",", "session_emb_lg", ")", "\n", "return", "item_embeddings_hg", ",", "sess_emb_hgnn", ",", "self", ".", "beta", "*", "con_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.trans_to_cuda": [[13, 18], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "variable.cuda"], "function", ["None"], ["def", "trans_to_cuda", "(", "variable", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "variable", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "variable", "\n", "", "", "def", "trans_to_cpu", "(", "variable", ")", ":", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.trans_to_cpu": [[18, 23], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "variable.cpu"], "function", ["None"], ["", "", "def", "trans_to_cpu", "(", "variable", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "variable", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "variable", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.find_k_largest": [[189, 220], ["numba.jit", "enumerate", "n_candidates.sort", "enumerate", "n_candidates.append", "int"], "function", ["None"], ["", "", "@", "jit", "(", "nopython", "=", "True", ")", "\n", "def", "find_k_largest", "(", "K", ",", "candidates", ")", ":", "\n", "    ", "n_candidates", "=", "[", "]", "\n", "for", "iid", ",", "score", "in", "enumerate", "(", "candidates", "[", ":", "K", "]", ")", ":", "\n", "        ", "n_candidates", ".", "append", "(", "(", "iid", ",", "score", ")", ")", "\n", "", "n_candidates", ".", "sort", "(", "key", "=", "lambda", "d", ":", "d", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "k_largest_scores", "=", "[", "item", "[", "1", "]", "for", "item", "in", "n_candidates", "]", "\n", "ids", "=", "[", "item", "[", "0", "]", "for", "item", "in", "n_candidates", "]", "\n", "# find the N biggest scores", "\n", "for", "iid", ",", "score", "in", "enumerate", "(", "candidates", ")", ":", "\n", "        ", "ind", "=", "K", "\n", "l", "=", "0", "\n", "r", "=", "K", "-", "1", "\n", "if", "k_largest_scores", "[", "r", "]", "<", "score", ":", "\n", "            ", "while", "r", ">=", "l", ":", "\n", "                ", "mid", "=", "int", "(", "(", "r", "-", "l", ")", "/", "2", ")", "+", "l", "\n", "if", "k_largest_scores", "[", "mid", "]", ">=", "score", ":", "\n", "                    ", "l", "=", "mid", "+", "1", "\n", "", "elif", "k_largest_scores", "[", "mid", "]", "<", "score", ":", "\n", "                    ", "r", "=", "mid", "-", "1", "\n", "", "if", "r", "<", "l", ":", "\n", "                    ", "ind", "=", "r", "\n", "break", "\n", "# move the items backwards", "\n", "", "", "", "if", "ind", "<", "K", "-", "2", ":", "\n", "            ", "k_largest_scores", "[", "ind", "+", "2", ":", "]", "=", "k_largest_scores", "[", "ind", "+", "1", ":", "-", "1", "]", "\n", "ids", "[", "ind", "+", "2", ":", "]", "=", "ids", "[", "ind", "+", "1", ":", "-", "1", "]", "\n", "", "if", "ind", "<", "K", "-", "1", ":", "\n", "            ", "k_largest_scores", "[", "ind", "+", "1", "]", "=", "score", "\n", "ids", "[", "ind", "+", "1", "]", "=", "iid", "\n", "", "", "return", "ids", "#,k_largest_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.forward": [[222, 235], ["data.get_slice", "data.get_overlap", "model.trans_to_cuda", "model.trans_to_cuda", "model.trans_to_cuda", "model.trans_to_cuda", "model.trans_to_cuda", "model.trans_to_cuda", "model.trans_to_cuda", "model", "torch.mm", "torch.mm", "torch.mm", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.transpose", "torch.transpose", "torch.transpose", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "function", ["home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.util.Data.get_slice", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.util.Data.get_overlap", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.trans_to_cuda", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.trans_to_cuda", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.trans_to_cuda", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.trans_to_cuda", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.trans_to_cuda", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.trans_to_cuda", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.trans_to_cuda"], ["", "def", "forward", "(", "model", ",", "i", ",", "data", ")", ":", "\n", "    ", "tar", ",", "session_len", ",", "session_item", ",", "reversed_sess_item", ",", "mask", "=", "data", ".", "get_slice", "(", "i", ")", "\n", "A_hat", ",", "D_hat", "=", "data", ".", "get_overlap", "(", "session_item", ")", "\n", "session_item", "=", "trans_to_cuda", "(", "torch", ".", "Tensor", "(", "session_item", ")", ".", "long", "(", ")", ")", "\n", "session_len", "=", "trans_to_cuda", "(", "torch", ".", "Tensor", "(", "session_len", ")", ".", "long", "(", ")", ")", "\n", "A_hat", "=", "trans_to_cuda", "(", "torch", ".", "Tensor", "(", "A_hat", ")", ")", "\n", "D_hat", "=", "trans_to_cuda", "(", "torch", ".", "Tensor", "(", "D_hat", ")", ")", "\n", "tar", "=", "trans_to_cuda", "(", "torch", ".", "Tensor", "(", "tar", ")", ".", "long", "(", ")", ")", "\n", "mask", "=", "trans_to_cuda", "(", "torch", ".", "Tensor", "(", "mask", ")", ".", "long", "(", ")", ")", "\n", "reversed_sess_item", "=", "trans_to_cuda", "(", "torch", ".", "Tensor", "(", "reversed_sess_item", ")", ".", "long", "(", ")", ")", "\n", "item_emb_hg", ",", "sess_emb_hgnn", ",", "con_loss", "=", "model", "(", "session_item", ",", "session_len", ",", "D_hat", ",", "A_hat", ",", "reversed_sess_item", ",", "mask", ")", "\n", "scores", "=", "torch", ".", "mm", "(", "sess_emb_hgnn", ",", "torch", ".", "transpose", "(", "item_emb_hg", ",", "1", ",", "0", ")", ")", "\n", "return", "tar", ",", "scores", ",", "con_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.train_test": [[237, 277], ["print", "torch.autograd.set_detect_anomaly", "torch.autograd.set_detect_anomaly", "torch.autograd.set_detect_anomaly", "train_data.generate_batch", "print", "print", "model.eval", "test_data.generate_batch", "datetime.datetime.now", "model.zero_grad", "model.forward", "model.loss_function", "model.loss_function.backward", "model.optimizer.step", "datetime.datetime.now", "model.forward", "trans_to_cpu().detach().numpy", "range", "numpy.array", "trans_to_cpu().detach().numpy", "np.array.append", "zip", "trans_to_cpu().detach", "model.find_k_largest", "trans_to_cpu().detach", "metrics[].append", "numpy.isin", "len", "metrics[].append", "metrics[].append", "model.trans_to_cpu", "model.trans_to_cpu", "numpy.where", "numpy.where"], "function", ["home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.util.Data.generate_batch", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.util.Data.generate_batch", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.forward", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.forward", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.find_k_largest", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.trans_to_cpu", "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.model.trans_to_cpu"], ["", "def", "train_test", "(", "model", ",", "train_data", ",", "test_data", ")", ":", "\n", "    ", "print", "(", "'start training: '", ",", "datetime", ".", "datetime", ".", "now", "(", ")", ")", "\n", "torch", ".", "autograd", ".", "set_detect_anomaly", "(", "True", ")", "\n", "total_loss", "=", "0.0", "\n", "slices", "=", "train_data", ".", "generate_batch", "(", "model", ".", "batch_size", ")", "\n", "for", "i", "in", "slices", ":", "\n", "        ", "model", ".", "zero_grad", "(", ")", "\n", "targets", ",", "scores", ",", "con_loss", "=", "forward", "(", "model", ",", "i", ",", "train_data", ")", "\n", "loss", "=", "model", ".", "loss_function", "(", "scores", "+", "1e-8", ",", "targets", ")", "\n", "loss", "=", "loss", "+", "con_loss", "\n", "loss", ".", "backward", "(", ")", "\n", "#        print(loss.item())", "\n", "model", ".", "optimizer", ".", "step", "(", ")", "\n", "total_loss", "+=", "loss", "\n", "", "print", "(", "'\\tLoss:\\t%.3f'", "%", "total_loss", ")", "\n", "top_K", "=", "[", "5", ",", "10", ",", "20", "]", "\n", "metrics", "=", "{", "}", "\n", "for", "K", "in", "top_K", ":", "\n", "        ", "metrics", "[", "'hit%d'", "%", "K", "]", "=", "[", "]", "\n", "metrics", "[", "'mrr%d'", "%", "K", "]", "=", "[", "]", "\n", "", "print", "(", "'start predicting: '", ",", "datetime", ".", "datetime", ".", "now", "(", ")", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "slices", "=", "test_data", ".", "generate_batch", "(", "model", ".", "batch_size", ")", "\n", "for", "i", "in", "slices", ":", "\n", "        ", "tar", ",", "scores", ",", "con_loss", "=", "forward", "(", "model", ",", "i", ",", "test_data", ")", "\n", "scores", "=", "trans_to_cpu", "(", "scores", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "index", "=", "[", "]", "\n", "for", "idd", "in", "range", "(", "model", ".", "batch_size", ")", ":", "\n", "            ", "index", ".", "append", "(", "find_k_largest", "(", "20", ",", "scores", "[", "idd", "]", ")", ")", "\n", "", "index", "=", "np", ".", "array", "(", "index", ")", "\n", "tar", "=", "trans_to_cpu", "(", "tar", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "for", "K", "in", "top_K", ":", "\n", "            ", "for", "prediction", ",", "target", "in", "zip", "(", "index", "[", ":", ",", ":", "K", "]", ",", "tar", ")", ":", "\n", "                ", "metrics", "[", "'hit%d'", "%", "K", "]", ".", "append", "(", "np", ".", "isin", "(", "target", ",", "prediction", ")", ")", "\n", "if", "len", "(", "np", ".", "where", "(", "prediction", "==", "target", ")", "[", "0", "]", ")", "==", "0", ":", "\n", "                    ", "metrics", "[", "'mrr%d'", "%", "K", "]", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "                    ", "metrics", "[", "'mrr%d'", "%", "K", "]", ".", "append", "(", "1", "/", "(", "np", ".", "where", "(", "prediction", "==", "target", ")", "[", "0", "]", "[", "0", "]", "+", "1", ")", ")", "\n", "", "", "", "", "return", "metrics", ",", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.util.Data.__init__": [[34, 49], ["numpy.asarray", "util.data_masks", "data_masks.T.multiply", "H.T.multiply", "numpy.dot", "numpy.dot.tocoo", "numpy.asarray", "len", "data_masks.sum().reshape", "H.sum().reshape", "data_masks.sum", "H.sum"], "methods", ["home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.util.data_masks"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "shuffle", "=", "False", ",", "n_node", "=", "None", ")", ":", "\n", "        ", "self", ".", "raw", "=", "np", ".", "asarray", "(", "data", "[", "0", "]", ")", "\n", "H_T", "=", "data_masks", "(", "self", ".", "raw", ",", "n_node", ")", "\n", "BH_T", "=", "H_T", ".", "T", ".", "multiply", "(", "1.0", "/", "H_T", ".", "sum", "(", "axis", "=", "1", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "\n", "BH_T", "=", "BH_T", ".", "T", "\n", "H", "=", "H_T", ".", "T", "\n", "DH", "=", "H", ".", "T", ".", "multiply", "(", "1.0", "/", "H", ".", "sum", "(", "axis", "=", "1", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "\n", "DH", "=", "DH", ".", "T", "\n", "DHBH_T", "=", "np", ".", "dot", "(", "DH", ",", "BH_T", ")", "\n", "\n", "self", ".", "adjacency", "=", "DHBH_T", ".", "tocoo", "(", ")", "\n", "self", ".", "n_node", "=", "n_node", "\n", "self", ".", "targets", "=", "np", ".", "asarray", "(", "data", "[", "1", "]", ")", "\n", "self", ".", "length", "=", "len", "(", "self", ".", "raw", ")", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.util.Data.get_overlap": [[50, 66], ["numpy.zeros", "range", "numpy.sum", "numpy.diag", "len", "set", "set.discard", "range", "numpy.diag", "numpy.array", "len", "len", "len", "set", "set.discard", "set.intersection", "float", "float", "len", "len", "len"], "methods", ["None"], ["", "def", "get_overlap", "(", "self", ",", "sessions", ")", ":", "\n", "        ", "matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "sessions", ")", ",", "len", "(", "sessions", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "sessions", ")", ")", ":", "\n", "            ", "seq_a", "=", "set", "(", "sessions", "[", "i", "]", ")", "\n", "seq_a", ".", "discard", "(", "0", ")", "\n", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "sessions", ")", ")", ":", "\n", "                ", "seq_b", "=", "set", "(", "sessions", "[", "j", "]", ")", "\n", "seq_b", ".", "discard", "(", "0", ")", "\n", "overlap", "=", "seq_a", ".", "intersection", "(", "seq_b", ")", "\n", "ab_set", "=", "seq_a", "|", "seq_b", "\n", "matrix", "[", "i", "]", "[", "j", "]", "=", "float", "(", "len", "(", "overlap", ")", ")", "/", "float", "(", "len", "(", "ab_set", ")", ")", "\n", "matrix", "[", "j", "]", "[", "i", "]", "=", "matrix", "[", "i", "]", "[", "j", "]", "\n", "", "", "matrix", "=", "matrix", "+", "np", ".", "diag", "(", "[", "1.0", "]", "*", "len", "(", "sessions", ")", ")", "\n", "degree", "=", "np", ".", "sum", "(", "np", ".", "array", "(", "matrix", ")", ",", "1", ")", "\n", "degree", "=", "np", ".", "diag", "(", "1.0", "/", "degree", ")", "\n", "return", "matrix", ",", "degree", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.util.Data.generate_batch": [[67, 79], ["int", "numpy.split", "numpy.arange", "numpy.arange", "numpy.random.shuffle", "numpy.arange"], "methods", ["None"], ["", "def", "generate_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "shuffled_arg", "=", "np", ".", "arange", "(", "self", ".", "length", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "shuffled_arg", ")", "\n", "self", ".", "raw", "=", "self", ".", "raw", "[", "shuffled_arg", "]", "\n", "self", ".", "targets", "=", "self", ".", "targets", "[", "shuffled_arg", "]", "\n", "", "n_batch", "=", "int", "(", "self", ".", "length", "/", "batch_size", ")", "\n", "if", "self", ".", "length", "%", "batch_size", "!=", "0", ":", "\n", "            ", "n_batch", "+=", "1", "\n", "", "slices", "=", "np", ".", "split", "(", "np", ".", "arange", "(", "n_batch", "*", "batch_size", ")", ",", "n_batch", ")", "\n", "slices", "[", "-", "1", "]", "=", "np", ".", "arange", "(", "self", ".", "length", "-", "batch_size", ",", "self", ".", "length", ")", "\n", "return", "slices", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.util.Data.get_slice": [[80, 98], ["numpy.max", "num_node.append", "session_len.append", "items.append", "mask.append", "reversed_sess_item.append", "len", "numpy.nonzero", "len", "list", "numpy.nonzero", "len", "reversed", "len", "len", "len"], "methods", ["None"], ["", "def", "get_slice", "(", "self", ",", "index", ")", ":", "\n", "        ", "items", ",", "num_node", "=", "[", "]", ",", "[", "]", "\n", "inp", "=", "self", ".", "raw", "[", "index", "]", "\n", "for", "session", "in", "inp", ":", "\n", "            ", "num_node", ".", "append", "(", "len", "(", "np", ".", "nonzero", "(", "session", ")", "[", "0", "]", ")", ")", "\n", "", "max_n_node", "=", "np", ".", "max", "(", "num_node", ")", "\n", "session_len", "=", "[", "]", "\n", "reversed_sess_item", "=", "[", "]", "\n", "mask", "=", "[", "]", "\n", "for", "session", "in", "inp", ":", "\n", "            ", "nonzero_elems", "=", "np", ".", "nonzero", "(", "session", ")", "[", "0", "]", "\n", "session_len", ".", "append", "(", "[", "len", "(", "nonzero_elems", ")", "]", ")", "\n", "items", ".", "append", "(", "session", "+", "(", "max_n_node", "-", "len", "(", "nonzero_elems", ")", ")", "*", "[", "0", "]", ")", "\n", "mask", ".", "append", "(", "[", "1", "]", "*", "len", "(", "nonzero_elems", ")", "+", "(", "max_n_node", "-", "len", "(", "nonzero_elems", ")", ")", "*", "[", "0", "]", ")", "\n", "reversed_sess_item", ".", "append", "(", "list", "(", "reversed", "(", "session", ")", ")", "+", "(", "max_n_node", "-", "len", "(", "nonzero_elems", ")", ")", "*", "[", "0", "]", ")", "\n", "\n", "\n", "", "return", "self", ".", "targets", "[", "index", "]", "-", "1", ",", "session_len", ",", "items", ",", "reversed_sess_item", ",", "mask", "\n", "", "", ""]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.util.data_masks": [[5, 19], ["indptr.append", "range", "scipy.sparse.csr_matrix", "len", "numpy.unique", "len", "indptr.append", "range", "indices.append", "data.append", "len"], "function", ["None"], ["def", "data_masks", "(", "all_sessions", ",", "n_node", ")", ":", "\n", "    ", "indptr", ",", "indices", ",", "data", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "indptr", ".", "append", "(", "0", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "all_sessions", ")", ")", ":", "\n", "        ", "session", "=", "np", ".", "unique", "(", "all_sessions", "[", "j", "]", ")", "\n", "length", "=", "len", "(", "session", ")", "\n", "s", "=", "indptr", "[", "-", "1", "]", "\n", "indptr", ".", "append", "(", "(", "s", "+", "length", ")", ")", "\n", "for", "i", "in", "range", "(", "length", ")", ":", "\n", "            ", "indices", ".", "append", "(", "session", "[", "i", "]", "-", "1", ")", "\n", "data", ".", "append", "(", "1", ")", "\n", "", "", "matrix", "=", "csr_matrix", "(", "(", "data", ",", "indices", ",", "indptr", ")", ",", "shape", "=", "(", "len", "(", "all_sessions", ")", ",", "n_node", ")", ")", "\n", "\n", "return", "matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.xiaxin1998_DHCN.None.util.split_validation": [[20, 32], ["len", "numpy.arange", "numpy.random.shuffle", "int", "numpy.round"], "function", ["None"], ["", "def", "split_validation", "(", "train_set", ",", "valid_portion", ")", ":", "\n", "    ", "train_set_x", ",", "train_set_y", "=", "train_set", "\n", "n_samples", "=", "len", "(", "train_set_x", ")", "\n", "sidx", "=", "np", ".", "arange", "(", "n_samples", ",", "dtype", "=", "'int32'", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "sidx", ")", "\n", "n_train", "=", "int", "(", "np", ".", "round", "(", "n_samples", "*", "(", "1.", "-", "valid_portion", ")", ")", ")", "\n", "valid_set_x", "=", "[", "train_set_x", "[", "s", "]", "for", "s", "in", "sidx", "[", "n_train", ":", "]", "]", "\n", "valid_set_y", "=", "[", "train_set_y", "[", "s", "]", "for", "s", "in", "sidx", "[", "n_train", ":", "]", "]", "\n", "train_set_x", "=", "[", "train_set_x", "[", "s", "]", "for", "s", "in", "sidx", "[", ":", "n_train", "]", "]", "\n", "train_set_y", "=", "[", "train_set_y", "[", "s", "]", "for", "s", "in", "sidx", "[", ":", "n_train", "]", "]", "\n", "\n", "return", "(", "train_set_x", ",", "train_set_y", ")", ",", "(", "valid_set_x", ",", "valid_set_y", ")", "\n", "\n"]]}