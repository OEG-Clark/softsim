{"home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn._infer_state_dtype": [[43, 71], ["tensorflow.python.util.nest.is_sequence", "all", "ValueError", "ValueError", "tensorflow.python.util.nest.flatten"], "function", ["None"], ["def", "_infer_state_dtype", "(", "explicit_dtype", ",", "state", ")", ":", "\n", "  ", "\"\"\"Infer the dtype of an RNN state.\n\n  Args:\n    explicit_dtype: explicitly declared dtype or None.\n    state: RNN's hidden state. Must be a Tensor or a nested iterable containing\n      Tensors.\n\n  Returns:\n    dtype: inferred dtype of hidden state.\n\n  Raises:\n    ValueError: if `state` has heterogeneous dtypes or is empty.\n  \"\"\"", "\n", "if", "explicit_dtype", "is", "not", "None", ":", "\n", "    ", "return", "explicit_dtype", "\n", "", "elif", "nest", ".", "is_sequence", "(", "state", ")", ":", "\n", "    ", "inferred_dtypes", "=", "[", "element", ".", "dtype", "for", "element", "in", "nest", ".", "flatten", "(", "state", ")", "]", "\n", "if", "not", "inferred_dtypes", ":", "\n", "      ", "raise", "ValueError", "(", "\"Unable to infer dtype from empty state.\"", ")", "\n", "", "all_same", "=", "all", "(", "[", "x", "==", "inferred_dtypes", "[", "0", "]", "for", "x", "in", "inferred_dtypes", "]", ")", "\n", "if", "not", "all_same", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "\"State has tensors of different inferred_dtypes. Unable to infer a \"", "\n", "\"single representative dtype.\"", ")", "\n", "", "return", "inferred_dtypes", "[", "0", "]", "\n", "", "else", ":", "\n", "    ", "return", "state", ".", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn.rnn": [[73, 224], ["isinstance", "TypeError", "tensorflow.python.util.nest.is_sequence", "TypeError", "ValueError", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.util.nest.is_sequence", "enumerate", "varscope.set_caching_device", "first_input.get_shape().with_rank_at_least", "tensorflow.python.util.nest.flatten", "cell.zero_state", "tensorflow.python.util.nest.flatten", "tuple", "tensorflow.python.util.nest.pack_sequence_as", "tensorflow.python.ops.math_ops.to_int32", "tensorflow.python.ops.math_ops.reduce_min", "tensorflow.python.ops.math_ops.reduce_max", "outputs.append", "first_input.get_shape", "flat_input.get_shape().with_rank_at_least", "fixed_batch_size.merge_with", "enumerate", "first_input.get_shape().with_rank_at_least", "tensorflow.python.ops.array_ops.shape", "ValueError", "_state_size_with_prefix", "tensorflow.python.ops.array_ops.zeros", "_state_size_with_prefix", "array_ops.zeros.set_shape", "varscope.reuse_variables", "cell", "rnn._rnn_step", "call_cell", "first_input.get_shape", "tensorflow.python.ops.array_ops.pack", "rnn._infer_state_dtype", "tensorflow.python.framework.tensor_shape.TensorShape", "rnn.rnn._create_zero_output"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.RNNCell.zero_state", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._state_size_with_prefix", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._state_size_with_prefix", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn._rnn_step", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn._infer_state_dtype"], ["", "", "def", "rnn", "(", "cell", ",", "inputs", ",", "initial_state", "=", "None", ",", "dtype", "=", "None", ",", "\n", "sequence_length", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates a recurrent neural network specified by RNNCell `cell`.\n\n  The simplest form of RNN network generated is:\n  ```py\n    state = cell.zero_state(...)\n    outputs = []\n    for input_ in inputs:\n      output, state = cell(input_, state)\n      outputs.append(output)\n    return (outputs, state)\n  ```\n  However, a few other options are available:\n\n  An initial state can be provided.\n  If the sequence_length vector is provided, dynamic calculation is performed.\n  This method of calculation does not compute the RNN steps past the maximum\n  sequence length of the minibatch (thus saving computational time),\n  and properly propagates the state at an example's sequence length\n  to the final state output.\n\n  The dynamic calculation performed is, at time t for batch row b,\n    (output, state)(b, t) =\n      (t >= sequence_length(b))\n        ? (zeros(cell.output_size), states(b, sequence_length(b) - 1))\n        : cell(input(b, t), state(b, t - 1))\n\n  Args:\n    cell: An instance of RNNCell.\n    inputs: A length T list of inputs, each a `Tensor` of shape\n      `[batch_size, input_size]`, or a nested tuple of such elements.\n    initial_state: (optional) An initial state for the RNN.\n      If `cell.state_size` is an integer, this must be\n      a `Tensor` of appropriate type and shape `[batch_size, cell.state_size]`.\n      If `cell.state_size` is a tuple, this should be a tuple of\n      tensors having shapes `[batch_size, s] for s in cell.state_size`.\n    dtype: (optional) The data type for the initial state and expected output.\n      Required if initial_state is not provided or RNN state has a heterogeneous\n      dtype.\n    sequence_length: Specifies the length of each sequence in inputs.\n      An int32 or int64 vector (tensor) size `[batch_size]`, values in `[0, T)`.\n    scope: VariableScope for the created subgraph; defaults to \"RNN\".\n\n  Returns:\n    A pair (outputs, state) where:\n      - outputs is a length T list of outputs (one for each input), or a nested\n        tuple of such elements.\n      - state is the final state\n\n  Raises:\n    TypeError: If `cell` is not an instance of RNNCell.\n    ValueError: If `inputs` is `None` or an empty list, or if the input depth\n      (column size) cannot be inferred from inputs via shape inference.\n  \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "cell", ",", "rnn_cell", ".", "RNNCell", ")", ":", "\n", "    ", "raise", "TypeError", "(", "\"cell must be an instance of RNNCell\"", ")", "\n", "", "if", "not", "nest", ".", "is_sequence", "(", "inputs", ")", ":", "\n", "    ", "raise", "TypeError", "(", "\"inputs must be a sequence\"", ")", "\n", "", "if", "not", "inputs", ":", "\n", "    ", "raise", "ValueError", "(", "\"inputs must not be empty\"", ")", "\n", "\n", "", "outputs", "=", "[", "]", "\n", "# Create a new scope in which the caching device is either", "\n", "# determined by the parent scope, or is set to place the cached", "\n", "# Variable using the same placement as for the rest of the RNN.", "\n", "with", "vs", ".", "variable_scope", "(", "scope", "or", "\"RNN\"", ")", "as", "varscope", ":", "\n", "    ", "if", "varscope", ".", "caching_device", "is", "None", ":", "\n", "      ", "varscope", ".", "set_caching_device", "(", "lambda", "op", ":", "op", ".", "device", ")", "\n", "\n", "# Obtain the first sequence of the input", "\n", "", "first_input", "=", "inputs", "\n", "while", "nest", ".", "is_sequence", "(", "first_input", ")", ":", "\n", "      ", "first_input", "=", "first_input", "[", "0", "]", "\n", "\n", "# Temporarily avoid EmbeddingWrapper and seq2seq badness", "\n", "# TODO(lukaszkaiser): remove EmbeddingWrapper", "\n", "", "if", "first_input", ".", "get_shape", "(", ")", ".", "ndims", "!=", "1", ":", "\n", "\n", "      ", "input_shape", "=", "first_input", ".", "get_shape", "(", ")", ".", "with_rank_at_least", "(", "2", ")", "\n", "fixed_batch_size", "=", "input_shape", "[", "0", "]", "\n", "\n", "flat_inputs", "=", "nest", ".", "flatten", "(", "inputs", ")", "\n", "for", "flat_input", "in", "flat_inputs", ":", "\n", "        ", "input_shape", "=", "flat_input", ".", "get_shape", "(", ")", ".", "with_rank_at_least", "(", "2", ")", "\n", "batch_size", ",", "input_size", "=", "input_shape", "[", "0", "]", ",", "input_shape", "[", "1", ":", "]", "\n", "fixed_batch_size", ".", "merge_with", "(", "batch_size", ")", "\n", "for", "i", ",", "size", "in", "enumerate", "(", "input_size", ")", ":", "\n", "          ", "if", "size", ".", "value", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Input size (dimension %d of inputs) must be accessible via \"", "\n", "\"shape inference, but saw value None.\"", "%", "i", ")", "\n", "", "", "", "", "else", ":", "\n", "      ", "fixed_batch_size", "=", "first_input", ".", "get_shape", "(", ")", ".", "with_rank_at_least", "(", "1", ")", "[", "0", "]", "\n", "\n", "", "if", "fixed_batch_size", ".", "value", ":", "\n", "      ", "batch_size", "=", "fixed_batch_size", ".", "value", "\n", "", "else", ":", "\n", "      ", "batch_size", "=", "array_ops", ".", "shape", "(", "first_input", ")", "[", "0", "]", "\n", "", "if", "initial_state", "is", "not", "None", ":", "\n", "      ", "state", "=", "initial_state", "\n", "", "else", ":", "\n", "      ", "if", "not", "dtype", ":", "\n", "        ", "raise", "ValueError", "(", "\"If no initial_state is provided, \"", "\n", "\"dtype must be specified\"", ")", "\n", "", "state", "=", "cell", ".", "zero_state", "(", "batch_size", ",", "dtype", ")", "\n", "\n", "", "if", "sequence_length", "is", "not", "None", ":", "# Prepare variables", "\n", "      ", "def", "_create_zero_output", "(", "output_size", ")", ":", "\n", "# convert int to TensorShape if necessary", "\n", "        ", "size", "=", "_state_size_with_prefix", "(", "output_size", ",", "prefix", "=", "[", "batch_size", "]", ")", "\n", "output", "=", "array_ops", ".", "zeros", "(", "\n", "array_ops", ".", "pack", "(", "size", ")", ",", "_infer_state_dtype", "(", "dtype", ",", "state", ")", ")", "\n", "shape", "=", "_state_size_with_prefix", "(", "\n", "output_size", ",", "prefix", "=", "[", "fixed_batch_size", ".", "value", "]", ")", "\n", "output", ".", "set_shape", "(", "tensor_shape", ".", "TensorShape", "(", "shape", ")", ")", "\n", "return", "output", "\n", "\n", "", "output_size", "=", "cell", ".", "output_size", "\n", "flat_output_size", "=", "nest", ".", "flatten", "(", "output_size", ")", "\n", "flat_zero_output", "=", "tuple", "(", "\n", "_create_zero_output", "(", "size", ")", "for", "size", "in", "flat_output_size", ")", "\n", "zero_output", "=", "nest", ".", "pack_sequence_as", "(", "structure", "=", "output_size", ",", "\n", "flat_sequence", "=", "flat_zero_output", ")", "\n", "\n", "sequence_length", "=", "math_ops", ".", "to_int32", "(", "sequence_length", ")", "\n", "min_sequence_length", "=", "math_ops", ".", "reduce_min", "(", "sequence_length", ")", "\n", "max_sequence_length", "=", "math_ops", ".", "reduce_max", "(", "sequence_length", ")", "\n", "\n", "", "for", "time", ",", "input_", "in", "enumerate", "(", "inputs", ")", ":", "\n", "      ", "if", "time", ">", "0", ":", "varscope", ".", "reuse_variables", "(", ")", "\n", "# pylint: disable=cell-var-from-loop", "\n", "call_cell", "=", "lambda", ":", "cell", "(", "input_", ",", "state", ")", "\n", "# pylint: enable=cell-var-from-loop", "\n", "if", "sequence_length", "is", "not", "None", ":", "\n", "        ", "(", "output", ",", "state", ")", "=", "_rnn_step", "(", "\n", "time", "=", "time", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "min_sequence_length", "=", "min_sequence_length", ",", "\n", "max_sequence_length", "=", "max_sequence_length", ",", "\n", "zero_output", "=", "zero_output", ",", "\n", "state", "=", "state", ",", "\n", "call_cell", "=", "call_cell", ",", "\n", "state_size", "=", "cell", ".", "state_size", ")", "\n", "", "else", ":", "\n", "        ", "(", "output", ",", "state", ")", "=", "call_cell", "(", ")", "\n", "\n", "", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "", "return", "(", "outputs", ",", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn.state_saving_rnn": [[226, 298], ["tensorflow.python.util.nest.is_sequence", "tensorflow.python.util.nest.is_sequence", "rnn.rnn", "ValueError", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.pack_sequence_as", "state_saver.state", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.pack_sequence_as", "len", "len", "ValueError", "state_saver.save_state", "state_saver.save_state", "tensorflow.python.ops.array_ops.identity", "zip", "str", "str", "state_saver.state", "len", "len"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn.rnn"], ["", "", "def", "state_saving_rnn", "(", "cell", ",", "inputs", ",", "state_saver", ",", "state_name", ",", "\n", "sequence_length", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"RNN that accepts a state saver for time-truncated RNN calculation.\n\n  Args:\n    cell: An instance of `RNNCell`.\n    inputs: A length T list of inputs, each a `Tensor` of shape\n      `[batch_size, input_size]`.\n    state_saver: A state saver object with methods `state` and `save_state`.\n    state_name: Python string or tuple of strings.  The name to use with the\n      state_saver. If the cell returns tuples of states (i.e.,\n      `cell.state_size` is a tuple) then `state_name` should be a tuple of\n      strings having the same length as `cell.state_size`.  Otherwise it should\n      be a single string.\n    sequence_length: (optional) An int32/int64 vector size [batch_size].\n      See the documentation for rnn() for more details about sequence_length.\n    scope: VariableScope for the created subgraph; defaults to \"RNN\".\n\n  Returns:\n    A pair (outputs, state) where:\n      outputs is a length T list of outputs (one for each input)\n      states is the final state\n\n  Raises:\n    TypeError: If `cell` is not an instance of RNNCell.\n    ValueError: If `inputs` is `None` or an empty list, or if the arity and\n     type of `state_name` does not match that of `cell.state_size`.\n  \"\"\"", "\n", "state_size", "=", "cell", ".", "state_size", "\n", "state_is_tuple", "=", "nest", ".", "is_sequence", "(", "state_size", ")", "\n", "state_name_tuple", "=", "nest", ".", "is_sequence", "(", "state_name", ")", "\n", "\n", "if", "state_is_tuple", "!=", "state_name_tuple", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"state_name should be the same type as cell.state_size.  \"", "\n", "\"state_name: %s, cell.state_size: %s\"", "\n", "%", "(", "str", "(", "state_name", ")", ",", "str", "(", "state_size", ")", ")", ")", "\n", "\n", "", "if", "state_is_tuple", ":", "\n", "    ", "state_name_flat", "=", "nest", ".", "flatten", "(", "state_name", ")", "\n", "state_size_flat", "=", "nest", ".", "flatten", "(", "state_size", ")", "\n", "\n", "if", "len", "(", "state_name_flat", ")", "!=", "len", "(", "state_size_flat", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"#elems(state_name) != #elems(state_size): %d vs. %d\"", "\n", "%", "(", "len", "(", "state_name_flat", ")", ",", "len", "(", "state_size_flat", ")", ")", ")", "\n", "\n", "", "initial_state", "=", "nest", ".", "pack_sequence_as", "(", "\n", "structure", "=", "state_size", ",", "\n", "flat_sequence", "=", "[", "state_saver", ".", "state", "(", "s", ")", "for", "s", "in", "state_name_flat", "]", ")", "\n", "", "else", ":", "\n", "    ", "initial_state", "=", "state_saver", ".", "state", "(", "state_name", ")", "\n", "\n", "", "(", "outputs", ",", "state", ")", "=", "rnn", "(", "cell", ",", "inputs", ",", "initial_state", "=", "initial_state", ",", "\n", "sequence_length", "=", "sequence_length", ",", "scope", "=", "scope", ")", "\n", "\n", "if", "state_is_tuple", ":", "\n", "    ", "flat_state", "=", "nest", ".", "flatten", "(", "state", ")", "\n", "state_name", "=", "nest", ".", "flatten", "(", "state_name", ")", "\n", "save_state", "=", "[", "state_saver", ".", "save_state", "(", "name", ",", "substate", ")", "\n", "for", "name", ",", "substate", "in", "zip", "(", "state_name", ",", "flat_state", ")", "]", "\n", "", "else", ":", "\n", "    ", "save_state", "=", "[", "state_saver", ".", "save_state", "(", "state_name", ",", "state", ")", "]", "\n", "\n", "", "with", "ops", ".", "control_dependencies", "(", "save_state", ")", ":", "\n", "    ", "last_output", "=", "outputs", "[", "-", "1", "]", "\n", "flat_last_output", "=", "nest", ".", "flatten", "(", "last_output", ")", "\n", "flat_last_output", "=", "[", "\n", "array_ops", ".", "identity", "(", "output", ")", "for", "output", "in", "flat_last_output", "]", "\n", "outputs", "[", "-", "1", "]", "=", "nest", ".", "pack_sequence_as", "(", "structure", "=", "last_output", ",", "\n", "flat_sequence", "=", "flat_last_output", ")", "\n", "\n", "", "return", "(", "outputs", ",", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn._rnn_step": [[301, 426], ["tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "zip", "zip", "tensorflow.python.util.nest.pack_sequence_as", "tensorflow.python.util.nest.pack_sequence_as", "tensorflow.python.ops.math_ops.select", "call_cell", "tensorflow.python.util.nest.assert_same_structure", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "tensorflow.python.ops.control_flow_ops.cond", "call_cell", "tensorflow.python.util.nest.assert_same_structure", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "rnn._rnn_step._copy_some_through"], "function", ["None"], ["", "def", "_rnn_step", "(", "\n", "time", ",", "sequence_length", ",", "min_sequence_length", ",", "max_sequence_length", ",", "\n", "zero_output", ",", "state", ",", "call_cell", ",", "state_size", ",", "skip_conditionals", "=", "False", ")", ":", "\n", "  ", "\"\"\"Calculate one step of a dynamic RNN minibatch.\n\n  Returns an (output, state) pair conditioned on the sequence_lengths.\n  When skip_conditionals=False, the pseudocode is something like:\n\n  if t >= max_sequence_length:\n    return (zero_output, state)\n  if t < min_sequence_length:\n    return call_cell()\n\n  # Selectively output zeros or output, old state or new state depending\n  # on if we've finished calculating each row.\n  new_output, new_state = call_cell()\n  final_output = np.vstack([\n    zero_output if time >= sequence_lengths[r] else new_output_r\n    for r, new_output_r in enumerate(new_output)\n  ])\n  final_state = np.vstack([\n    state[r] if time >= sequence_lengths[r] else new_state_r\n    for r, new_state_r in enumerate(new_state)\n  ])\n  return (final_output, final_state)\n\n  Args:\n    time: Python int, the current time step\n    sequence_length: int32 `Tensor` vector of size [batch_size]\n    min_sequence_length: int32 `Tensor` scalar, min of sequence_length\n    max_sequence_length: int32 `Tensor` scalar, max of sequence_length\n    zero_output: `Tensor` vector of shape [output_size]\n    state: Either a single `Tensor` matrix of shape `[batch_size, state_size]`,\n      or a list/tuple of such tensors.\n    call_cell: lambda returning tuple of (new_output, new_state) where\n      new_output is a `Tensor` matrix of shape `[batch_size, output_size]`.\n      new_state is a `Tensor` matrix of shape `[batch_size, state_size]`.\n    state_size: The `cell.state_size` associated with the state.\n    skip_conditionals: Python bool, whether to skip using the conditional\n      calculations.  This is useful for `dynamic_rnn`, where the input tensor\n      matches `max_sequence_length`, and using conditionals just slows\n      everything down.\n\n  Returns:\n    A tuple of (`final_output`, `final_state`) as given by the pseudocode above:\n      final_output is a `Tensor` matrix of shape [batch_size, output_size]\n      final_state is either a single `Tensor` matrix, or a tuple of such\n        matrices (matching length and shapes of input `state`).\n\n  Raises:\n    ValueError: If the cell returns a state tuple whose length does not match\n      that returned by `state_size`.\n  \"\"\"", "\n", "\n", "# Convert state to a list for ease of use", "\n", "flat_state", "=", "nest", ".", "flatten", "(", "state", ")", "\n", "flat_zero_output", "=", "nest", ".", "flatten", "(", "zero_output", ")", "\n", "\n", "def", "_copy_one_through", "(", "output", ",", "new_output", ")", ":", "\n", "    ", "copy_cond", "=", "(", "time", ">=", "sequence_length", ")", "\n", "return", "math_ops", ".", "select", "(", "copy_cond", ",", "output", ",", "new_output", ")", "\n", "\n", "", "def", "_copy_some_through", "(", "flat_new_output", ",", "flat_new_state", ")", ":", "\n", "# Use broadcasting select to determine which values should get", "\n", "# the previous state & zero output, and which values should get", "\n", "# a calculated state & output.", "\n", "    ", "flat_new_output", "=", "[", "\n", "_copy_one_through", "(", "zero_output", ",", "new_output", ")", "\n", "for", "zero_output", ",", "new_output", "in", "zip", "(", "flat_zero_output", ",", "flat_new_output", ")", "]", "\n", "flat_new_state", "=", "[", "\n", "_copy_one_through", "(", "state", ",", "new_state", ")", "\n", "for", "state", ",", "new_state", "in", "zip", "(", "flat_state", ",", "flat_new_state", ")", "]", "\n", "return", "flat_new_output", "+", "flat_new_state", "\n", "\n", "", "def", "_maybe_copy_some_through", "(", ")", ":", "\n", "    ", "\"\"\"Run RNN step.  Pass through either no or some past state.\"\"\"", "\n", "new_output", ",", "new_state", "=", "call_cell", "(", ")", "\n", "\n", "nest", ".", "assert_same_structure", "(", "state", ",", "new_state", ")", "\n", "\n", "flat_new_state", "=", "nest", ".", "flatten", "(", "new_state", ")", "\n", "flat_new_output", "=", "nest", ".", "flatten", "(", "new_output", ")", "\n", "return", "control_flow_ops", ".", "cond", "(", "\n", "# if t < min_seq_len: calculate and return everything", "\n", "time", "<", "min_sequence_length", ",", "lambda", ":", "flat_new_output", "+", "flat_new_state", ",", "\n", "# else copy some of it through", "\n", "lambda", ":", "_copy_some_through", "(", "flat_new_output", ",", "flat_new_state", ")", ")", "\n", "\n", "# TODO(ebrevdo): skipping these conditionals may cause a slowdown,", "\n", "# but benefits from removing cond() and its gradient.  We should", "\n", "# profile with and without this switch here.", "\n", "", "if", "skip_conditionals", ":", "\n", "# Instead of using conditionals, perform the selective copy at all time", "\n", "# steps.  This is faster when max_seq_len is equal to the number of unrolls", "\n", "# (which is typical for dynamic_rnn).", "\n", "    ", "new_output", ",", "new_state", "=", "call_cell", "(", ")", "\n", "nest", ".", "assert_same_structure", "(", "state", ",", "new_state", ")", "\n", "new_state", "=", "nest", ".", "flatten", "(", "new_state", ")", "\n", "new_output", "=", "nest", ".", "flatten", "(", "new_output", ")", "\n", "final_output_and_state", "=", "_copy_some_through", "(", "new_output", ",", "new_state", ")", "\n", "", "else", ":", "\n", "    ", "empty_update", "=", "lambda", ":", "flat_zero_output", "+", "flat_state", "\n", "final_output_and_state", "=", "control_flow_ops", ".", "cond", "(", "\n", "# if t >= max_seq_len: copy all state through, output zeros", "\n", "time", ">=", "max_sequence_length", ",", "empty_update", ",", "\n", "# otherwise calculation is required: copy some or all of it through", "\n", "_maybe_copy_some_through", ")", "\n", "\n", "", "if", "len", "(", "final_output_and_state", ")", "!=", "len", "(", "flat_zero_output", ")", "+", "len", "(", "flat_state", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\"Internal error: state and output were not concatenated \"", "\n", "\"correctly.\"", ")", "\n", "", "final_output", "=", "final_output_and_state", "[", ":", "len", "(", "flat_zero_output", ")", "]", "\n", "final_state", "=", "final_output_and_state", "[", "len", "(", "flat_zero_output", ")", ":", "]", "\n", "\n", "for", "output", ",", "flat_output", "in", "zip", "(", "final_output", ",", "flat_zero_output", ")", ":", "\n", "    ", "output", ".", "set_shape", "(", "flat_output", ".", "get_shape", "(", ")", ")", "\n", "", "for", "substate", ",", "flat_substate", "in", "zip", "(", "final_state", ",", "flat_state", ")", ":", "\n", "    ", "substate", ".", "set_shape", "(", "flat_substate", ".", "get_shape", "(", ")", ")", "\n", "\n", "", "final_output", "=", "nest", ".", "pack_sequence_as", "(", "\n", "structure", "=", "zero_output", ",", "flat_sequence", "=", "final_output", ")", "\n", "final_state", "=", "nest", ".", "pack_sequence_as", "(", "\n", "structure", "=", "state", ",", "flat_sequence", "=", "final_state", ")", "\n", "\n", "return", "final_output", ",", "final_state", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn._reverse_seq": [[428, 472], ["tuple", "zip", "list", "tensorflow.python.framework.tensor_shape.unknown_shape", "tensorflow.python.ops.array_ops.pack", "tensorflow.python.ops.array_ops.reverse_sequence", "tensorflow.python.ops.array_ops.unpack", "zip", "tensorflow.python.util.nest.pack_sequence_as", "reversed", "tensorflow.python.util.nest.flatten", "range", "tensor_shape.unknown_shape.merge_with", "input_.set_shape", "tensorflow.python.ops.math_ops.to_int64", "r.set_shape", "flat_result.append", "zip", "len", "input_.get_shape", "sequence[].get_shape"], "function", ["None"], ["", "def", "_reverse_seq", "(", "input_seq", ",", "lengths", ")", ":", "\n", "  ", "\"\"\"Reverse a list of Tensors up to specified lengths.\n\n  Args:\n    input_seq: Sequence of seq_len tensors of dimension (batch_size, n_features)\n               or nested tuples of tensors.\n    lengths:   A `Tensor` of dimension batch_size, containing lengths for each\n               sequence in the batch. If \"None\" is specified, simply reverses\n               the list.\n\n  Returns:\n    time-reversed sequence\n  \"\"\"", "\n", "if", "lengths", "is", "None", ":", "\n", "    ", "return", "list", "(", "reversed", "(", "input_seq", ")", ")", "\n", "\n", "", "flat_input_seq", "=", "tuple", "(", "nest", ".", "flatten", "(", "input_", ")", "for", "input_", "in", "input_seq", ")", "\n", "\n", "flat_results", "=", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "input_seq", ")", ")", "]", "\n", "for", "sequence", "in", "zip", "(", "*", "flat_input_seq", ")", ":", "\n", "    ", "input_shape", "=", "tensor_shape", ".", "unknown_shape", "(", "\n", "ndims", "=", "sequence", "[", "0", "]", ".", "get_shape", "(", ")", ".", "ndims", ")", "\n", "for", "input_", "in", "sequence", ":", "\n", "      ", "input_shape", ".", "merge_with", "(", "input_", ".", "get_shape", "(", ")", ")", "\n", "input_", ".", "set_shape", "(", "input_shape", ")", "\n", "\n", "# Join into (time, batch_size, depth)", "\n", "", "s_joined", "=", "array_ops", ".", "pack", "(", "sequence", ")", "\n", "\n", "# TODO(schuster, ebrevdo): Remove cast when reverse_sequence takes int32", "\n", "if", "lengths", "is", "not", "None", ":", "\n", "      ", "lengths", "=", "math_ops", ".", "to_int64", "(", "lengths", ")", "\n", "\n", "# Reverse along dimension 0", "\n", "", "s_reversed", "=", "array_ops", ".", "reverse_sequence", "(", "s_joined", ",", "lengths", ",", "0", ",", "1", ")", "\n", "# Split again into list", "\n", "result", "=", "array_ops", ".", "unpack", "(", "s_reversed", ")", "\n", "for", "r", ",", "flat_result", "in", "zip", "(", "result", ",", "flat_results", ")", ":", "\n", "      ", "r", ".", "set_shape", "(", "input_shape", ")", "\n", "flat_result", ".", "append", "(", "r", ")", "\n", "\n", "", "", "results", "=", "[", "nest", ".", "pack_sequence_as", "(", "structure", "=", "input_", ",", "flat_sequence", "=", "flat_result", ")", "\n", "for", "input_", ",", "flat_result", "in", "zip", "(", "input_seq", ",", "flat_results", ")", "]", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn.bidirectional_rnn": [[474, 558], ["rnn._reverse_seq", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "tuple", "tensorflow.python.util.nest.pack_sequence_as", "isinstance", "TypeError", "isinstance", "TypeError", "tensorflow.python.util.nest.is_sequence", "TypeError", "ValueError", "isinstance", "tensorflow.python.ops.variable_scope.variable_scope", "rnn.rnn", "tensorflow.python.ops.variable_scope.variable_scope", "rnn._reverse_seq", "rnn.rnn", "isinstance", "tensorflow.python.ops.array_ops.concat", "TypeError", "zip"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn._reverse_seq", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn.rnn", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn._reverse_seq", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn.rnn"], ["", "def", "bidirectional_rnn", "(", "cell_fw", ",", "cell_bw", ",", "inputs", ",", "\n", "initial_state_fw", "=", "None", ",", "initial_state_bw", "=", "None", ",", "\n", "dtype", "=", "None", ",", "sequence_length", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates a bidirectional recurrent neural network.\n\n  Similar to the unidirectional case above (rnn) but takes input and builds\n  independent forward and backward RNNs with the final forward and backward\n  outputs depth-concatenated, such that the output will have the format\n  [time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of\n  forward and backward cell must match. The initial state for both directions\n  is zero by default (but can be set optionally) and no intermediate states are\n  ever returned -- the network is fully unrolled for the given (passed in)\n  length(s) of the sequence(s) or completely unrolled if length(s) is not given.\n\n  Args:\n    cell_fw: An instance of RNNCell, to be used for forward direction.\n    cell_bw: An instance of RNNCell, to be used for backward direction.\n    inputs: A length T list of inputs, each a tensor of shape\n      [batch_size, input_size], or a nested tuple of such elements.\n    initial_state_fw: (optional) An initial state for the forward RNN.\n      This must be a tensor of appropriate type and shape\n      `[batch_size x cell_fw.state_size]`.\n      If `cell_fw.state_size` is a tuple, this should be a tuple of\n      tensors having shapes `[batch_size, s] for s in cell_fw.state_size`.\n    initial_state_bw: (optional) Same as for `initial_state_fw`, but using\n      the corresponding properties of `cell_bw`.\n    dtype: (optional) The data type for the initial state.  Required if\n      either of the initial states are not provided.\n    sequence_length: (optional) An int32/int64 vector, size `[batch_size]`,\n      containing the actual lengths for each of the sequences.\n    scope: VariableScope for the created subgraph; defaults to \"BiRNN\"\n\n  Returns:\n    A tuple (outputs, output_state_fw, output_state_bw) where:\n      outputs is a length `T` list of outputs (one for each input), which\n        are depth-concatenated forward and backward outputs.\n      output_state_fw is the final state of the forward rnn.\n      output_state_bw is the final state of the backward rnn.\n\n  Raises:\n    TypeError: If `cell_fw` or `cell_bw` is not an instance of `RNNCell`.\n    ValueError: If inputs is None or an empty list.\n  \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "cell_fw", ",", "rnn_cell", ".", "RNNCell", ")", ":", "\n", "    ", "raise", "TypeError", "(", "\"cell_fw must be an instance of RNNCell\"", ")", "\n", "", "if", "not", "isinstance", "(", "cell_bw", ",", "rnn_cell", ".", "RNNCell", ")", ":", "\n", "    ", "raise", "TypeError", "(", "\"cell_bw must be an instance of RNNCell\"", ")", "\n", "", "if", "not", "nest", ".", "is_sequence", "(", "inputs", ")", ":", "\n", "    ", "raise", "TypeError", "(", "\"inputs must be a sequence\"", ")", "\n", "", "if", "not", "inputs", ":", "\n", "    ", "raise", "ValueError", "(", "\"inputs must not be empty\"", ")", "\n", "\n", "", "if", "scope", "is", "None", ":", "\n", "    ", "name", "=", "\"BiRNN\"", "\n", "", "elif", "isinstance", "(", "scope", ",", "six", ".", "string_types", ")", ":", "\n", "    ", "name", "=", "scope", "\n", "", "elif", "isinstance", "(", "scope", ",", "vs", ".", "VariableScope", ")", ":", "\n", "    ", "name", "=", "scope", ".", "name", "\n", "", "else", ":", "\n", "    ", "raise", "TypeError", "(", "\"scope must be a string or an instance of VariableScope\"", ")", "\n", "\n", "# Forward direction", "\n", "", "with", "vs", ".", "variable_scope", "(", "name", "+", "\"_FW\"", ")", "as", "fw_scope", ":", "\n", "    ", "output_fw", ",", "output_state_fw", "=", "rnn", "(", "cell_fw", ",", "inputs", ",", "initial_state_fw", ",", "dtype", ",", "\n", "sequence_length", ",", "scope", "=", "fw_scope", ")", "\n", "\n", "# Backward direction", "\n", "", "with", "vs", ".", "variable_scope", "(", "name", "+", "\"_BW\"", ")", "as", "bw_scope", ":", "\n", "    ", "reversed_inputs", "=", "_reverse_seq", "(", "inputs", ",", "sequence_length", ")", "\n", "tmp", ",", "output_state_bw", "=", "rnn", "(", "cell_bw", ",", "reversed_inputs", ",", "initial_state_bw", ",", "\n", "dtype", ",", "sequence_length", ",", "scope", "=", "bw_scope", ")", "\n", "", "output_bw", "=", "_reverse_seq", "(", "tmp", ",", "sequence_length", ")", "\n", "# Concat each of the forward/backward outputs", "\n", "flat_output_fw", "=", "nest", ".", "flatten", "(", "output_fw", ")", "\n", "flat_output_bw", "=", "nest", ".", "flatten", "(", "output_bw", ")", "\n", "\n", "flat_outputs", "=", "tuple", "(", "array_ops", ".", "concat", "(", "1", ",", "[", "fw", ",", "bw", "]", ")", "\n", "for", "fw", ",", "bw", "in", "zip", "(", "flat_output_fw", ",", "flat_output_bw", ")", ")", "\n", "\n", "outputs", "=", "nest", ".", "pack_sequence_as", "(", "structure", "=", "output_fw", ",", "\n", "flat_sequence", "=", "flat_outputs", ")", "\n", "\n", "return", "(", "outputs", ",", "output_state_fw", ",", "output_state_bw", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn.bidirectional_dynamic_rnn": [[560, 688], ["tensorflow.python.ops.array_ops.reverse_sequence", "isinstance", "TypeError", "isinstance", "TypeError", "isinstance", "tensorflow.python.ops.variable_scope.variable_scope", "rnn.dynamic_rnn", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.ops.array_ops.reverse_sequence", "rnn.dynamic_rnn", "isinstance", "TypeError"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn.dynamic_rnn", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn.dynamic_rnn"], ["", "def", "bidirectional_dynamic_rnn", "(", "cell_fw", ",", "cell_bw", ",", "inputs", ",", "sequence_length", "=", "None", ",", "\n", "initial_state_fw", "=", "None", ",", "initial_state_bw", "=", "None", ",", "\n", "dtype", "=", "None", ",", "parallel_iterations", "=", "None", ",", "\n", "swap_memory", "=", "False", ",", "time_major", "=", "False", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates a dynamic version of bidirectional recurrent neural network.\n\n  Similar to the unidirectional case above (rnn) but takes input and builds\n  independent forward and backward RNNs. The input_size of forward and\n  backward cell must match. The initial state for both directions is zero by\n  default (but can be set optionally) and no intermediate states are ever\n  returned -- the network is fully unrolled for the given (passed in)\n  length(s) of the sequence(s) or completely unrolled if length(s) is not\n  given.\n\n  Args:\n    cell_fw: An instance of RNNCell, to be used for forward direction.\n    cell_bw: An instance of RNNCell, to be used for backward direction.\n    inputs: The RNN inputs.\n      If time_major == False (default), this must be a tensor of shape:\n        `[batch_size, max_time, input_size]`.\n      If time_major == True, this must be a tensor of shape:\n        `[max_time, batch_size, input_size]`.\n      [batch_size, input_size].\n    sequence_length: An int32/int64 vector, size `[batch_size]`,\n      containing the actual lengths for each of the sequences.\n    initial_state_fw: (optional) An initial state for the forward RNN.\n      This must be a tensor of appropriate type and shape\n      `[batch_size x cell_fw.state_size]`.\n      If `cell_fw.state_size` is a tuple, this should be a tuple of\n      tensors having shapes `[batch_size, s] for s in cell_fw.state_size`.\n    initial_state_bw: (optional) Same as for `initial_state_fw`, but using\n      the corresponding properties of `cell_bw`.\n    dtype: (optional) The data type for the initial states and expected output.\n      Required if initial_states are not provided or RNN states have a\n      heterogeneous dtype.\n    parallel_iterations: (Default: 32).  The number of iterations to run in\n      parallel.  Those operations which do not have any temporal dependency\n      and can be run in parallel, will be.  This parameter trades off\n      time for space.  Values >> 1 use more memory but take less time,\n      while smaller values use less memory but computations take longer.\n    swap_memory: Transparently swap the tensors produced in forward inference\n      but needed for back prop from GPU to CPU.  This allows training RNNs\n      which would typically not fit on a single GPU, with very minimal (or no)\n      performance penalty.\n    time_major: The shape format of the `inputs` and `outputs` Tensors.\n      If true, these `Tensors` must be shaped `[max_time, batch_size, depth]`.\n      If false, these `Tensors` must be shaped `[batch_size, max_time, depth]`.\n      Using `time_major = True` is a bit more efficient because it avoids\n      transposes at the beginning and end of the RNN calculation.  However,\n      most TensorFlow data is batch-major, so by default this function\n      accepts input and emits output in batch-major form.\n    dtype: (optional) The data type for the initial state.  Required if\n      initial_state is not provided.\n    sequence_length: An int32/int64 vector, size `[batch_size]`,\n      containing the actual lengths for each of the sequences.\n      either of the initial states are not provided.\n    scope: VariableScope for the created subgraph; defaults to \"BiRNN\"\n\n  Returns:\n    A tuple (outputs, output_states) where:\n      outputs: A tuple (output_fw, output_bw) containing the forward and\n        the backward rnn output `Tensor`.\n        If time_major == False (default),\n          output_fw will be a `Tensor` shaped:\n          `[batch_size, max_time, cell_fw.output_size]`\n          and output_bw will be a `Tensor` shaped:\n          `[batch_size, max_time, cell_bw.output_size]`.\n        If time_major == True,\n          output_fw will be a `Tensor` shaped:\n          `[max_time, batch_size, cell_fw.output_size]`\n          and output_bw will be a `Tensor` shaped:\n          `[max_time, batch_size, cell_bw.output_size]`.\n        It returns a tuple instead of a single concatenated `Tensor`, unlike\n        in the `bidirectional_rnn`. If the concatenated one is preferred,\n        the forward and backward outputs can be concatenated as\n        `tf.concat(2, outputs)`.\n      output_states: A tuple (output_state_fw, output_state_bw) containing\n        the forward and the backward final states of bidirectional rnn.\n\n  Raises:\n    TypeError: If `cell_fw` or `cell_bw` is not an instance of `RNNCell`.\n  \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "cell_fw", ",", "rnn_cell", ".", "RNNCell", ")", ":", "\n", "    ", "raise", "TypeError", "(", "\"cell_fw must be an instance of RNNCell\"", ")", "\n", "", "if", "not", "isinstance", "(", "cell_bw", ",", "rnn_cell", ".", "RNNCell", ")", ":", "\n", "    ", "raise", "TypeError", "(", "\"cell_bw must be an instance of RNNCell\"", ")", "\n", "\n", "", "if", "scope", "is", "None", ":", "\n", "    ", "name", "=", "\"BiRNN\"", "\n", "", "elif", "isinstance", "(", "scope", ",", "six", ".", "string_types", ")", ":", "\n", "    ", "name", "=", "scope", "\n", "", "elif", "isinstance", "(", "scope", ",", "vs", ".", "VariableScope", ")", ":", "\n", "    ", "name", "=", "scope", ".", "name", "\n", "", "else", ":", "\n", "    ", "raise", "TypeError", "(", "\"scope must be a string or an instance of VariableScope\"", ")", "\n", "\n", "# Forward direction", "\n", "", "with", "vs", ".", "variable_scope", "(", "name", "+", "\"_FW\"", ")", "as", "fw_scope", ":", "\n", "    ", "output_fw", ",", "output_state_fw", "=", "dynamic_rnn", "(", "\n", "cell", "=", "cell_fw", ",", "inputs", "=", "inputs", ",", "sequence_length", "=", "sequence_length", ",", "\n", "initial_state", "=", "initial_state_fw", ",", "dtype", "=", "dtype", ",", "\n", "parallel_iterations", "=", "parallel_iterations", ",", "swap_memory", "=", "swap_memory", ",", "\n", "time_major", "=", "time_major", ",", "scope", "=", "fw_scope", ")", "\n", "# Backward direction", "\n", "", "if", "not", "time_major", ":", "\n", "    ", "time_dim", "=", "1", "\n", "batch_dim", "=", "0", "\n", "", "else", ":", "\n", "    ", "time_dim", "=", "0", "\n", "batch_dim", "=", "1", "\n", "", "with", "vs", ".", "variable_scope", "(", "name", "+", "\"_BW\"", ")", "as", "bw_scope", ":", "\n", "    ", "inputs_reverse", "=", "array_ops", ".", "reverse_sequence", "(", "\n", "input", "=", "inputs", ",", "seq_lengths", "=", "sequence_length", ",", "\n", "seq_dim", "=", "time_dim", ",", "batch_dim", "=", "batch_dim", ")", "\n", "tmp", ",", "output_state_bw", "=", "dynamic_rnn", "(", "\n", "cell", "=", "cell_bw", ",", "inputs", "=", "inputs_reverse", ",", "sequence_length", "=", "sequence_length", ",", "\n", "initial_state", "=", "initial_state_bw", ",", "dtype", "=", "dtype", ",", "\n", "parallel_iterations", "=", "parallel_iterations", ",", "swap_memory", "=", "swap_memory", ",", "\n", "time_major", "=", "time_major", ",", "scope", "=", "bw_scope", ")", "\n", "", "output_bw", "=", "array_ops", ".", "reverse_sequence", "(", "\n", "input", "=", "tmp", ",", "seq_lengths", "=", "sequence_length", ",", "\n", "seq_dim", "=", "time_dim", ",", "batch_dim", "=", "batch_dim", ")", "\n", "\n", "outputs", "=", "(", "output_fw", ",", "output_bw", ")", "\n", "output_states", "=", "(", "output_state_fw", ",", "output_state_bw", ")", "\n", "\n", "return", "(", "outputs", ",", "output_states", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn.dynamic_rnn": [[690, 863], ["tensorflow.python.util.nest.flatten", "isinstance", "TypeError", "tuple", "tensorflow.python.ops.math_ops.to_int32", "tensorflow.python.ops.array_ops.identity", "tensorflow.python.ops.variable_scope.variable_scope", "tuple", "tensorflow.python.util.nest.pack_sequence_as", "rnn._dynamic_rnn_loop", "varscope.set_caching_device", "cell.zero_state", "tensorflow.python.ops.array_ops.shape", "tensorflow.python.ops.array_ops.pack", "tensorflow.python.ops.logging_ops.Assert", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.pack_sequence_as", "tensorflow.python.ops.array_ops.transpose", "tensorflow.python.ops.array_ops.shape", "input_[].get_shape", "batch_size.get_shape", "ValueError", "ValueError", "tensorflow.python.ops.math_ops.reduce_all", "tensorflow.python.framework.ops.control_dependencies", "tensorflow.python.ops.array_ops.identity", "tensorflow.python.ops.array_ops.transpose", "tensorflow.python.ops.math_ops.equal", "rnn.dynamic_rnn._assert_has_shape"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn._dynamic_rnn_loop", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.RNNCell.zero_state"], ["", "def", "dynamic_rnn", "(", "cell", ",", "inputs", ",", "sequence_length", "=", "None", ",", "initial_state", "=", "None", ",", "\n", "dtype", "=", "None", ",", "parallel_iterations", "=", "None", ",", "swap_memory", "=", "False", ",", "\n", "time_major", "=", "False", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates a recurrent neural network specified by RNNCell `cell`.\n\n  This function is functionally identical to the function `rnn` above, but\n  performs fully dynamic unrolling of `inputs`.\n\n  Unlike `rnn`, the input `inputs` is not a Python list of `Tensors`, one for\n  each frame.  Instead, `inputs` may be a single `Tensor` where\n  the maximum time is either the first or second dimension (see the parameter\n  `time_major`).  Alternatively, it may be a (possibly nested) tuple of\n  Tensors, each of them having matching batch and time dimensions.\n  The corresponding output is either a single `Tensor` having the same number\n  of time steps and batch size, or a (possibly nested) tuple of such tensors,\n  matching the nested structure of `cell.output_size`.\n\n  The parameter `sequence_length` is optional and is used to copy-through state\n  and zero-out outputs when past a batch element's sequence length. So it's more\n  for correctness than performance, unlike in rnn().\n\n  Args:\n    cell: An instance of RNNCell.\n    inputs: The RNN inputs.\n\n      If `time_major == False` (default), this must be a `Tensor` of shape:\n        `[batch_size, max_time, ...]`, or a nested tuple of such\n        elements.\n\n      If `time_major == True`, this must be a `Tensor` of shape:\n        `[max_time, batch_size, ...]`, or a nested tuple of such\n        elements.\n\n      This may also be a (possibly nested) tuple of Tensors satisfying\n      this property.  The first two dimensions must match across all the inputs,\n      but otherwise the ranks and other shape components may differ.\n      In this case, input to `cell` at each time-step will replicate the\n      structure of these tuples, except for the time dimension (from which the\n      time is taken).\n\n      The input to `cell` at each time step will be a `Tensor` or (possibly\n      nested) tuple of Tensors each with dimensions `[batch_size, ...]`.\n    sequence_length: (optional) An int32/int64 vector sized `[batch_size]`.\n    initial_state: (optional) An initial state for the RNN.\n      If `cell.state_size` is an integer, this must be\n      a `Tensor` of appropriate type and shape `[batch_size x cell.state_size]`.\n      If `cell.state_size` is a tuple, this should be a tuple of\n      tensors having shapes `[batch_size, s] for s in cell.state_size`.\n    dtype: (optional) The data type for the initial state and expected output.\n      Required if initial_state is not provided or RNN state has a heterogeneous\n      dtype.\n    parallel_iterations: (Default: 32).  The number of iterations to run in\n      parallel.  Those operations which do not have any temporal dependency\n      and can be run in parallel, will be.  This parameter trades off\n      time for space.  Values >> 1 use more memory but take less time,\n      while smaller values use less memory but computations take longer.\n    swap_memory: Transparently swap the tensors produced in forward inference\n      but needed for back prop from GPU to CPU.  This allows training RNNs\n      which would typically not fit on a single GPU, with very minimal (or no)\n      performance penalty.\n    time_major: The shape format of the `inputs` and `outputs` Tensors.\n      If true, these `Tensors` must be shaped `[max_time, batch_size, depth]`.\n      If false, these `Tensors` must be shaped `[batch_size, max_time, depth]`.\n      Using `time_major = True` is a bit more efficient because it avoids\n      transposes at the beginning and end of the RNN calculation.  However,\n      most TensorFlow data is batch-major, so by default this function\n      accepts input and emits output in batch-major form.\n    scope: VariableScope for the created subgraph; defaults to \"RNN\".\n\n  Returns:\n    A pair (outputs, state) where:\n\n      outputs: The RNN output `Tensor`.\n\n        If time_major == False (default), this will be a `Tensor` shaped:\n          `[batch_size, max_time, cell.output_size]`.\n\n        If time_major == True, this will be a `Tensor` shaped:\n          `[max_time, batch_size, cell.output_size]`.\n\n        Note, if `cell.output_size` is a (possibly nested) tuple of integers\n        or `TensorShape` objects, then `outputs` will be a tuple having the\n        same structure as `cell.output_size`, containing Tensors having shapes\n        corresponding to the shape data in `cell.output_size`.\n\n      state: The final state.  If `cell.state_size` is an int, this\n        will be shaped `[batch_size, cell.state_size]`.  If it is a\n        `TensorShape`, this will be shaped `[batch_size] + cell.state_size`.\n        If it is a (possibly nested) tuple of ints or `TensorShape`, this will\n        be a tuple having the corresponding shapes.\n\n  Raises:\n    TypeError: If `cell` is not an instance of RNNCell.\n    ValueError: If inputs is None or an empty list.\n  \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "cell", ",", "rnn_cell", ".", "RNNCell", ")", ":", "\n", "    ", "raise", "TypeError", "(", "\"cell must be an instance of RNNCell\"", ")", "\n", "\n", "# By default, time_major==False and inputs are batch-major: shaped", "\n", "#   [batch, time, depth]", "\n", "# For internal calculations, we transpose to [time, batch, depth]", "\n", "", "flat_input", "=", "nest", ".", "flatten", "(", "inputs", ")", "\n", "\n", "if", "not", "time_major", ":", "\n", "# (B,T,D) => (T,B,D)", "\n", "    ", "flat_input", "=", "tuple", "(", "array_ops", ".", "transpose", "(", "input_", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "for", "input_", "in", "flat_input", ")", "\n", "\n", "", "parallel_iterations", "=", "parallel_iterations", "or", "32", "\n", "if", "sequence_length", "is", "not", "None", ":", "\n", "    ", "sequence_length", "=", "math_ops", ".", "to_int32", "(", "sequence_length", ")", "\n", "sequence_length", "=", "array_ops", ".", "identity", "(", "# Just to find it in the graph.", "\n", "sequence_length", ",", "name", "=", "\"sequence_length\"", ")", "\n", "\n", "# Create a new scope in which the caching device is either", "\n", "# determined by the parent scope, or is set to place the cached", "\n", "# Variable using the same placement as for the rest of the RNN.", "\n", "", "with", "vs", ".", "variable_scope", "(", "scope", "or", "\"RNN\"", ")", "as", "varscope", ":", "\n", "    ", "if", "varscope", ".", "caching_device", "is", "None", ":", "\n", "      ", "varscope", ".", "set_caching_device", "(", "lambda", "op", ":", "op", ".", "device", ")", "\n", "", "input_shape", "=", "tuple", "(", "array_ops", ".", "shape", "(", "input_", ")", "for", "input_", "in", "flat_input", ")", "\n", "batch_size", "=", "input_shape", "[", "0", "]", "[", "1", "]", "\n", "\n", "for", "input_", "in", "input_shape", ":", "\n", "      ", "if", "input_", "[", "1", "]", ".", "get_shape", "(", ")", "!=", "batch_size", ".", "get_shape", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"All inputs should have the same batch size\"", ")", "\n", "\n", "", "", "if", "initial_state", "is", "not", "None", ":", "\n", "      ", "state", "=", "initial_state", "\n", "", "else", ":", "\n", "      ", "if", "not", "dtype", ":", "\n", "        ", "raise", "ValueError", "(", "\"If no initial_state is provided, dtype must be.\"", ")", "\n", "", "state", "=", "cell", ".", "zero_state", "(", "batch_size", ",", "dtype", ")", "\n", "\n", "", "def", "_assert_has_shape", "(", "x", ",", "shape", ")", ":", "\n", "      ", "x_shape", "=", "array_ops", ".", "shape", "(", "x", ")", "\n", "packed_shape", "=", "array_ops", ".", "pack", "(", "shape", ")", "\n", "return", "logging_ops", ".", "Assert", "(", "\n", "math_ops", ".", "reduce_all", "(", "math_ops", ".", "equal", "(", "x_shape", ",", "packed_shape", ")", ")", ",", "\n", "[", "\"Expected shape for Tensor %s is \"", "%", "x", ".", "name", ",", "\n", "packed_shape", ",", "\" but saw shape: \"", ",", "x_shape", "]", ")", "\n", "\n", "", "if", "sequence_length", "is", "not", "None", ":", "\n", "# Perform some shape validation", "\n", "      ", "with", "ops", ".", "control_dependencies", "(", "\n", "[", "_assert_has_shape", "(", "sequence_length", ",", "[", "batch_size", "]", ")", "]", ")", ":", "\n", "        ", "sequence_length", "=", "array_ops", ".", "identity", "(", "\n", "sequence_length", ",", "name", "=", "\"CheckSeqLen\"", ")", "\n", "\n", "", "", "inputs", "=", "nest", ".", "pack_sequence_as", "(", "structure", "=", "inputs", ",", "flat_sequence", "=", "flat_input", ")", "\n", "\n", "(", "outputs", ",", "final_state", ")", "=", "_dynamic_rnn_loop", "(", "\n", "cell", ",", "\n", "inputs", ",", "\n", "state", ",", "\n", "parallel_iterations", "=", "parallel_iterations", ",", "\n", "swap_memory", "=", "swap_memory", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "dtype", "=", "dtype", ")", "\n", "\n", "# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].", "\n", "# If we are performing batch-major calculations, transpose output back", "\n", "# to shape [batch, time, depth]", "\n", "if", "not", "time_major", ":", "\n", "# (T,B,D) => (B,T,D)", "\n", "      ", "flat_output", "=", "nest", ".", "flatten", "(", "outputs", ")", "\n", "flat_output", "=", "[", "array_ops", ".", "transpose", "(", "output", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "for", "output", "in", "flat_output", "]", "\n", "outputs", "=", "nest", ".", "pack_sequence_as", "(", "\n", "structure", "=", "outputs", ",", "flat_sequence", "=", "flat_output", ")", "\n", "\n", "", "return", "(", "outputs", ",", "final_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn._dynamic_rnn_loop": [[865, 1031], ["isinstance", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "tensorflow.python.ops.array_ops.shape", "tuple", "tuple", "tensorflow.python.util.nest.pack_sequence_as", "tensorflow.python.ops.array_ops.constant", "tuple", "tuple", "tuple", "tensorflow.python.ops.control_flow_ops.while_loop", "tuple", "zip", "tensorflow.python.util.nest.pack_sequence_as", "inputs_got_shape[].as_list", "_state_size_with_prefix", "tensorflow.python.ops.array_ops.zeros", "tensorflow.python.ops.math_ops.reduce_min", "tensorflow.python.ops.math_ops.reduce_max", "tensorflow.python.framework.ops.op_scope", "tensorflow.python.ops.tensor_array_ops.TensorArray", "tuple", "zip", "tensorflow.python.util.nest.pack_sequence_as", "tensorflow.python.util.nest.flatten", "tuple", "_state_size_with_prefix", "nest.flatten.set_shape", "input_.get_shape().with_rank_at_least", "shape[].is_fully_defined", "ValueError", "ValueError", "ValueError", "tensorflow.python.ops.array_ops.pack", "rnn._infer_state_dtype", "rnn._dynamic_rnn_loop._create_zero_arrays"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._state_size_with_prefix", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._state_size_with_prefix", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn._infer_state_dtype"], ["", "", "def", "_dynamic_rnn_loop", "(", "cell", ",", "\n", "inputs", ",", "\n", "initial_state", ",", "\n", "parallel_iterations", ",", "\n", "swap_memory", ",", "\n", "sequence_length", "=", "None", ",", "\n", "dtype", "=", "None", ")", ":", "\n", "  ", "\"\"\"Internal implementation of Dynamic RNN.\n\n  Args:\n    cell: An instance of RNNCell.\n    inputs: A `Tensor` of shape [time, batch_size, input_size], or a nested\n      tuple of such elements.\n    initial_state: A `Tensor` of shape `[batch_size, state_size]`, or if\n      `cell.state_size` is a tuple, then this should be a tuple of\n      tensors having shapes `[batch_size, s] for s in cell.state_size`.\n    parallel_iterations: Positive Python int.\n    swap_memory: A Python boolean\n    sequence_length: (optional) An `int32` `Tensor` of shape [batch_size].\n    dtype: (optional) Expected dtype of output. If not specified, inferred from\n      initial_state.\n\n  Returns:\n    Tuple `(final_outputs, final_state)`.\n    final_outputs:\n      A `Tensor` of shape `[time, batch_size, cell.output_size]`.  If\n      `cell.output_size` is a (possibly nested) tuple of ints or `TensorShape`\n      objects, then this returns a (possibly nsted) tuple of Tensors matching\n      the corresponding shapes.\n    final_state:\n      A `Tensor`, or possibly nested tuple of Tensors, matching in length\n      and shapes to `initial_state`.\n\n  Raises:\n    ValueError: If the input depth cannot be inferred via shape inference\n      from the inputs.\n  \"\"\"", "\n", "state", "=", "initial_state", "\n", "assert", "isinstance", "(", "parallel_iterations", ",", "int", ")", ",", "\"parallel_iterations must be int\"", "\n", "\n", "state_size", "=", "cell", ".", "state_size", "\n", "\n", "flat_input", "=", "nest", ".", "flatten", "(", "inputs", ")", "\n", "flat_output_size", "=", "nest", ".", "flatten", "(", "cell", ".", "output_size", ")", "\n", "\n", "# Construct an initial output", "\n", "input_shape", "=", "array_ops", ".", "shape", "(", "flat_input", "[", "0", "]", ")", "\n", "time_steps", "=", "input_shape", "[", "0", "]", "\n", "batch_size", "=", "input_shape", "[", "1", "]", "\n", "\n", "inputs_got_shape", "=", "tuple", "(", "input_", ".", "get_shape", "(", ")", ".", "with_rank_at_least", "(", "3", ")", "\n", "for", "input_", "in", "flat_input", ")", "\n", "\n", "const_time_steps", ",", "const_batch_size", "=", "inputs_got_shape", "[", "0", "]", ".", "as_list", "(", ")", "[", ":", "2", "]", "\n", "\n", "for", "shape", "in", "inputs_got_shape", ":", "\n", "    ", "if", "not", "shape", "[", "2", ":", "]", ".", "is_fully_defined", "(", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "\"Input size (depth of inputs) must be accessible via shape inference,\"", "\n", "\" but saw value None.\"", ")", "\n", "", "got_time_steps", "=", "shape", "[", "0", "]", "\n", "got_batch_size", "=", "shape", "[", "1", "]", "\n", "if", "const_time_steps", "!=", "got_time_steps", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "\"Time steps is not the same for all the elements in the input in a \"", "\n", "\"batch.\"", ")", "\n", "", "if", "const_batch_size", "!=", "got_batch_size", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "\"Batch_size is not the same for all the elements in the input.\"", ")", "\n", "\n", "# Prepare dynamic conditional copying of state & output", "\n", "", "", "def", "_create_zero_arrays", "(", "size", ")", ":", "\n", "    ", "size", "=", "_state_size_with_prefix", "(", "size", ",", "prefix", "=", "[", "batch_size", "]", ")", "\n", "return", "array_ops", ".", "zeros", "(", "\n", "array_ops", ".", "pack", "(", "size", ")", ",", "_infer_state_dtype", "(", "dtype", ",", "state", ")", ")", "\n", "\n", "", "flat_zero_output", "=", "tuple", "(", "_create_zero_arrays", "(", "output", ")", "\n", "for", "output", "in", "flat_output_size", ")", "\n", "zero_output", "=", "nest", ".", "pack_sequence_as", "(", "structure", "=", "cell", ".", "output_size", ",", "\n", "flat_sequence", "=", "flat_zero_output", ")", "\n", "\n", "if", "sequence_length", "is", "not", "None", ":", "\n", "    ", "min_sequence_length", "=", "math_ops", ".", "reduce_min", "(", "sequence_length", ")", "\n", "max_sequence_length", "=", "math_ops", ".", "reduce_max", "(", "sequence_length", ")", "\n", "\n", "", "time", "=", "array_ops", ".", "constant", "(", "0", ",", "dtype", "=", "dtypes", ".", "int32", ",", "name", "=", "\"time\"", ")", "\n", "\n", "with", "ops", ".", "op_scope", "(", "[", "]", ",", "\"dynamic_rnn\"", ")", "as", "scope", ":", "\n", "    ", "base_name", "=", "scope", "\n", "\n", "", "def", "_create_ta", "(", "name", ",", "dtype", ")", ":", "\n", "    ", "return", "tensor_array_ops", ".", "TensorArray", "(", "dtype", "=", "dtype", ",", "\n", "size", "=", "time_steps", ",", "\n", "tensor_array_name", "=", "base_name", "+", "name", ")", "\n", "\n", "", "output_ta", "=", "tuple", "(", "_create_ta", "(", "\"output_%d\"", "%", "i", ",", "\n", "_infer_state_dtype", "(", "dtype", ",", "state", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "flat_output_size", ")", ")", ")", "\n", "input_ta", "=", "tuple", "(", "_create_ta", "(", "\"input_%d\"", "%", "i", ",", "flat_input", "[", "0", "]", ".", "dtype", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "flat_input", ")", ")", ")", "\n", "\n", "input_ta", "=", "tuple", "(", "ta", ".", "unpack", "(", "input_", ")", "\n", "for", "ta", ",", "input_", "in", "zip", "(", "input_ta", ",", "flat_input", ")", ")", "\n", "\n", "def", "_time_step", "(", "time", ",", "output_ta_t", ",", "state", ")", ":", "\n", "    ", "\"\"\"Take a time step of the dynamic RNN.\n\n    Args:\n      time: int32 scalar Tensor.\n      output_ta_t: List of `TensorArray`s that represent the output.\n      state: nested tuple of vector tensors that represent the state.\n\n    Returns:\n      The tuple (time + 1, output_ta_t with updated flow, new_state).\n    \"\"\"", "\n", "\n", "input_t", "=", "tuple", "(", "ta", ".", "read", "(", "time", ")", "for", "ta", "in", "input_ta", ")", "\n", "# Restore some shape information", "\n", "for", "input_", ",", "shape", "in", "zip", "(", "input_t", ",", "inputs_got_shape", ")", ":", "\n", "      ", "input_", ".", "set_shape", "(", "shape", "[", "1", ":", "]", ")", "\n", "\n", "", "input_t", "=", "nest", ".", "pack_sequence_as", "(", "structure", "=", "inputs", ",", "flat_sequence", "=", "input_t", ")", "\n", "call_cell", "=", "lambda", ":", "cell", "(", "input_t", ",", "state", ")", "\n", "\n", "if", "sequence_length", "is", "not", "None", ":", "\n", "      ", "(", "output", ",", "new_state", ")", "=", "_rnn_step", "(", "\n", "time", "=", "time", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "min_sequence_length", "=", "min_sequence_length", ",", "\n", "max_sequence_length", "=", "max_sequence_length", ",", "\n", "zero_output", "=", "zero_output", ",", "\n", "state", "=", "state", ",", "\n", "call_cell", "=", "call_cell", ",", "\n", "state_size", "=", "state_size", ",", "\n", "skip_conditionals", "=", "True", ")", "\n", "", "else", ":", "\n", "      ", "(", "output", ",", "new_state", ")", "=", "call_cell", "(", ")", "\n", "\n", "# Pack state if using state tuples", "\n", "", "output", "=", "nest", ".", "flatten", "(", "output", ")", "\n", "\n", "output_ta_t", "=", "tuple", "(", "\n", "ta", ".", "write", "(", "time", ",", "out", ")", "for", "ta", ",", "out", "in", "zip", "(", "output_ta_t", ",", "output", ")", ")", "\n", "\n", "return", "(", "time", "+", "1", ",", "output_ta_t", ",", "new_state", ")", "\n", "\n", "", "_", ",", "output_final_ta", ",", "final_state", "=", "control_flow_ops", ".", "while_loop", "(", "\n", "cond", "=", "lambda", "time", ",", "*", "_", ":", "time", "<", "time_steps", ",", "\n", "body", "=", "_time_step", ",", "\n", "loop_vars", "=", "(", "time", ",", "output_ta", ",", "state", ")", ",", "\n", "parallel_iterations", "=", "parallel_iterations", ",", "\n", "swap_memory", "=", "swap_memory", ")", "\n", "\n", "# Unpack final output if not using output tuples.", "\n", "final_outputs", "=", "tuple", "(", "ta", ".", "pack", "(", ")", "for", "ta", "in", "output_final_ta", ")", "\n", "\n", "# Restore some shape information", "\n", "for", "output", ",", "output_size", "in", "zip", "(", "final_outputs", ",", "flat_output_size", ")", ":", "\n", "    ", "shape", "=", "_state_size_with_prefix", "(", "\n", "output_size", ",", "prefix", "=", "[", "const_time_steps", ",", "const_batch_size", "]", ")", "\n", "output", ".", "set_shape", "(", "shape", ")", "\n", "\n", "", "final_outputs", "=", "nest", ".", "pack_sequence_as", "(", "\n", "structure", "=", "cell", ".", "output_size", ",", "flat_sequence", "=", "final_outputs", ")", "\n", "\n", "return", "(", "final_outputs", ",", "final_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn.raw_rnn": [[1033, 1314], ["isinstance", "TypeError", "callable", "TypeError", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.framework.constant_op.constant", "loop_fn", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.assert_same_structure", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.pack_sequence_as", "tensorflow.python.util.nest.pack_sequence_as", "tensorflow.python.util.nest.pack_sequence_as", "tensorflow.python.ops.control_flow_ops.while_loop", "varscope.set_caching_device", "tensorflow.python.framework.constant_op.constant", "input_.get_shape", "static_batch_size.merge_with", "tensorflow.python.framework.ops.convert_to_tensor", "tensorflow.python.util.nest.flatten", "tensorflow.python.util.nest.flatten", "tensorflow.python.ops.tensor_array_ops.TensorArray", "tensorflow.python.ops.array_ops.zeros", "tensorflow.python.ops.math_ops.logical_not", "cell", "tensorflow.python.util.nest.assert_same_structure", "tensorflow.python.util.nest.assert_same_structure", "loop_fn", "tensorflow.python.util.nest.assert_same_structure", "tensorflow.python.util.nest.assert_same_structure", "rnn._rnn_step._copy_some_through"], "function", ["None"], ["", "def", "raw_rnn", "(", "cell", ",", "loop_fn", ",", "initial_state", ",", "\n", "parallel_iterations", "=", "None", ",", "swap_memory", "=", "False", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates an `RNN` specified by RNNCell `cell` and loop function `loop_fn`.\n\n  **NOTE: This method is still in testing, and the API may change.**\n\n  This function is a more primitive version of `dynamic_rnn` that provides\n  more direct access to the inputs each iteration.  It also provides more\n  control over when to start and finish reading the sequence, and\n  what to emit for the output.\n\n  For example, it can be used to implement the dynamic decoder of a seq2seq\n  model.\n\n  Instead of working with `Tensor` objects, most operations work with\n  `TensorArray` objects directly.\n\n  The operation of `raw_rnn`, in pseudo-code, is basically the following:\n  ```\n  emit_ta = TensorArray(dynamic_size=True, dtype=initial_state.dtype)\n  time = tf.constant(0, dtype=tf.int32)\n  (finished, next_input, _, loop_state) = loop_fn(\n      time=time, cell_output=None, loop_state=None)\n  state = initial_state\n  while not all(finished):\n    (output, next_state) = cell(next_input, state)\n    (next_finished, next_input, emit, loop_state) = loop_fn(\n        time=time + 1, cell_output=output, loop_state=loop_state)\n    # Emit zeros and copy forward state for minibatch entries that are finished.\n    state = tf.select(finished, state, next_state)\n    emit = tf.select(finished, tf.zeros_like(emit), emit)\n    emit_ta = emit_ta.write(time, emit)\n    # If any new minibatch entries are marked as finished, mark these\n    finished = tf.logical_or(finished, next_finished)\n    time += 1\n  return (emit_ta, state, loop_state)\n  ```\n\n  with the additional properties that output and state may be (possibly nested)\n  tuples, as determined by `cell.output_size` and `cell.state_size`, and\n  as a result the final `state` and `emit_ta` may themselves be tuples.\n\n  A simple implementation of `dynamic_rnn` via `raw_rnn` looks like this:\n\n  ```python\n  inputs = tf.placeholder(shape=(max_time, batch_size, input_depth),\n                          dtype=tf.float32)\n  sequence_length = tf.placeholder(shape=(batch_size,), dtype=tf.int32)\n  inputs_ta = tf.TensorArray(dtype=tf.float32, size=max_time)\n  inputs_ta = inputs_ta.unpack(inputs)\n\n  def loop_fn(time, cell_output, loop_state):\n    emit_output = cell_output  # == None for time == 0\n    elements_finished = (time >= sequence_length)\n    finished = tf.reduce_all(elements_finished)\n    next_input = tf.cond(\n        finished,\n        lambda: tf.zeros([batch_size, input_depth], dtype=tf.float32),\n        lambda: inputs_ta.read(time))\n    next_loop_state = None\n    return (elements_finished, next_input, emit_output, next_loop_state)\n\n  cell = tf.nn.rnn_cell.LSTMCell(num_units, state_is_tuple=True)\n  initial_state = cell.zero_state(batch_size, tf.float32)\n  outputs_ta, final_state, _ = raw_rnn(cell, loop_fn, initial_state)\n  outputs = outputs_ta.pack()\n  ```\n\n  Args:\n    cell: An instance of RNNCell.\n    loop_fn: A callable that takes inputs `(time, cell_output, loop_state)` and\n      returns the tuple `(finished, next_input, emit_output, next_loop_state)`.\n      Here `time` is an int32 scalar `Tensor`, `cell_output` is a\n      `Tensor` or (possibly nested) tuple of tensors as determined by\n      `cell.output_size`.  In addition, `finished` is a boolean `Tensor` of\n      shape `[batch_size]`, `next_input` is the next input to feed to `cell`,\n      and `emit_output` is the output to store for this iteration.  Note that\n      `emit_output` should be a `Tensor` or (possibly nested) tuple of tensors\n      with shapes and structure matching `cell.output_size` and `cell_output`\n      above.  The parameter `loop_state` and output `next_loop_state` may be\n      either a single or (possibly nested) tuple of tensors.  This paramter\n      may be ignored by `loop_fn` and the return value may be `None`.  If it\n      is not `None`, then the `loop_state` will be propagated through the RNN\n      loop, for use purely by `loop_fn` to keep track of its own state.\n      The `next_loop_state` parameter returned may be `None`.\n\n      The first call to `loop_fn` will be `time = 0`, `cell_output = None`,\n      and `loop_state = None`.  Its `emit_output` value in this case may be\n      either `None` or a (possibly nested) tuple structure of Tensors, e.g.,\n      `(tf.zeros(shape_0, dtype=dtype_0), tf.zeros(shape_1, dtype=dtype_1))`.\n      If this first `emit_output` return value is `None`,\n      then the `emit_ta` result of `raw_rnn` will have the same structure and\n      dtypes as `cell.output_size`.  Otherwise `emit_ta` will have the same\n      structure, shapes (prepended with a `batch_size` dimension), and dtypes\n      as `emit_output`.  The actual values returned for `emit_output` at this\n      initializing call are ignored.  Note, this emit structure must be\n      consistent across all time steps.\n\n    initial_state: An initial state for the RNN.\n      If `cell.state_size` is an integer, this must be\n      a `Tensor` of appropriate type and shape `[batch_size, cell.state_size]`.\n      If `cell.state_size` is a `TensorShape`, this must be a `Tensor` of\n      appropriate type and shape `[batch_size] + cell.state_size`.\n      If `cell.state_size` is a (possibly nested) tuple of ints or\n      `TensorShape`, this will be a tuple having the corresponding shapes.\n    parallel_iterations: (Default: 32).  The number of iterations to run in\n      parallel.  Those operations which do not have any temporal dependency\n      and can be run in parallel, will be.  This parameter trades off\n      time for space.  Values >> 1 use more memory but take less time,\n      while smaller values use less memory but computations take longer.\n    swap_memory: Transparently swap the tensors produced in forward inference\n      but needed for back prop from GPU to CPU.  This allows training RNNs\n      which would typically not fit on a single GPU, with very minimal (or no)\n      performance penalty.\n    scope: VariableScope for the created subgraph; defaults to \"RNN\".\n\n  Returns:\n    A tuple `(emit_ta, final_state, final_loop_state)` where:\n\n      `emit_ta`: The RNN output `TensorArray`.\n         If `loop_fn` returns a (possibly nested) set of Tensors for\n         `emit_output` during initialization, (inputs `time = 0`,\n         `cell_output = None`, and `loop_state = None`), then `emit_ta` will\n         have the same structure, dtypes, and shapes as `emit_output` instead.\n         If `loop_fn` returns `emit_output = None` during this call,\n         the structure of `cell.output_size` is used:\n\n         If `cell.output_size` is a (possibly nested) tuple of integers\n         or `TensorShape` objects, then `emit_ta` will be a tuple having the\n         same structure as `cell.output_size`, containing TensorArrays whose\n         elements' shapes correspond to the shape data in `cell.output_size`.\n\n      `final_state`: The final cell state.  If `cell.state_size` is an int, this\n        will be shaped `[batch_size, cell.state_size]`.  If it is a\n        `TensorShape`, this will be shaped `[batch_size] + cell.state_size`.\n        If it is a (possibly nested) tuple of ints or `TensorShape`, this will\n        be a tuple having the corresponding shapes.\n\n      `final_loop_state`: The final loop state as returned by `loop_fn`.\n\n  Raises:\n    TypeError: If `cell` is not an instance of RNNCell, or `loop_fn` is not\n      a `callable`.\n  \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "cell", ",", "rnn_cell", ".", "RNNCell", ")", ":", "\n", "    ", "raise", "TypeError", "(", "\"cell must be an instance of RNNCell\"", ")", "\n", "", "if", "not", "callable", "(", "loop_fn", ")", ":", "\n", "    ", "raise", "TypeError", "(", "\"loop_fn must be a callable\"", ")", "\n", "\n", "# Create a new scope in which the caching device is either", "\n", "# determined by the parent scope, or is set to place the cached", "\n", "# Variable using the same placement as for the rest of the RNN.", "\n", "", "with", "vs", ".", "variable_scope", "(", "scope", "or", "\"RNN\"", ")", "as", "varscope", ":", "\n", "    ", "if", "varscope", ".", "caching_device", "is", "None", ":", "\n", "      ", "varscope", ".", "set_caching_device", "(", "lambda", "op", ":", "op", ".", "device", ")", "\n", "\n", "", "time", "=", "constant_op", ".", "constant", "(", "0", ",", "dtype", "=", "dtypes", ".", "int32", ")", "\n", "(", "elements_finished", ",", "next_input", ",", "emit_structure", ",", "init_loop_state", ")", "=", "loop_fn", "(", "\n", "time", ",", "None", ",", "None", ")", "# time, cell_output, loop_state", "\n", "flat_input", "=", "nest", ".", "flatten", "(", "next_input", ")", "\n", "\n", "# Need a surrogate loop state for the while_loop if none is available.", "\n", "loop_state", "=", "(", "init_loop_state", "if", "init_loop_state", "is", "not", "None", "\n", "else", "constant_op", ".", "constant", "(", "0", ",", "dtype", "=", "dtypes", ".", "int32", ")", ")", "\n", "\n", "input_shape", "=", "[", "input_", ".", "get_shape", "(", ")", "for", "input_", "in", "flat_input", "]", "\n", "static_batch_size", "=", "input_shape", "[", "0", "]", "[", "0", "]", "\n", "\n", "for", "input_shape_i", "in", "input_shape", ":", "\n", "# Static verification that batch sizes all match", "\n", "      ", "static_batch_size", ".", "merge_with", "(", "input_shape_i", "[", "0", "]", ")", "\n", "\n", "", "batch_size", "=", "static_batch_size", ".", "value", "\n", "if", "batch_size", "is", "None", ":", "\n", "      ", "batch_size", "=", "array_ops", ".", "shape", "(", "flat_input", "[", "0", "]", ")", "[", "0", "]", "\n", "\n", "", "nest", ".", "assert_same_structure", "(", "initial_state", ",", "cell", ".", "state_size", ")", "\n", "state", "=", "initial_state", "\n", "flat_state", "=", "nest", ".", "flatten", "(", "state", ")", "\n", "flat_state", "=", "[", "ops", ".", "convert_to_tensor", "(", "s", ")", "for", "s", "in", "flat_state", "]", "\n", "state", "=", "nest", ".", "pack_sequence_as", "(", "structure", "=", "state", ",", "\n", "flat_sequence", "=", "flat_state", ")", "\n", "\n", "if", "emit_structure", "is", "not", "None", ":", "\n", "      ", "flat_emit_structure", "=", "nest", ".", "flatten", "(", "emit_structure", ")", "\n", "flat_emit_size", "=", "[", "emit", ".", "get_shape", "(", ")", "for", "emit", "in", "flat_emit_structure", "]", "\n", "flat_emit_dtypes", "=", "[", "emit", ".", "dtype", "for", "emit", "in", "flat_emit_structure", "]", "\n", "", "else", ":", "\n", "      ", "emit_structure", "=", "cell", ".", "output_size", "\n", "flat_emit_size", "=", "nest", ".", "flatten", "(", "emit_structure", ")", "\n", "flat_emit_dtypes", "=", "[", "flat_state", "[", "0", "]", ".", "dtype", "]", "*", "len", "(", "flat_emit_size", ")", "\n", "\n", "", "flat_emit_ta", "=", "[", "\n", "tensor_array_ops", ".", "TensorArray", "(", "\n", "dtype", "=", "dtype_i", ",", "dynamic_size", "=", "True", ",", "size", "=", "0", ",", "name", "=", "\"rnn_output_%d\"", "%", "i", ")", "\n", "for", "i", ",", "dtype_i", "in", "enumerate", "(", "flat_emit_dtypes", ")", "]", "\n", "emit_ta", "=", "nest", ".", "pack_sequence_as", "(", "structure", "=", "emit_structure", ",", "\n", "flat_sequence", "=", "flat_emit_ta", ")", "\n", "flat_zero_emit", "=", "[", "\n", "array_ops", ".", "zeros", "(", "\n", "_state_size_with_prefix", "(", "size_i", ",", "prefix", "=", "[", "batch_size", "]", ")", ",", "\n", "dtype_i", ")", "\n", "for", "size_i", ",", "dtype_i", "in", "zip", "(", "flat_emit_size", ",", "flat_emit_dtypes", ")", "]", "\n", "zero_emit", "=", "nest", ".", "pack_sequence_as", "(", "structure", "=", "emit_structure", ",", "\n", "flat_sequence", "=", "flat_zero_emit", ")", "\n", "\n", "def", "condition", "(", "unused_time", ",", "elements_finished", ",", "*", "_", ")", ":", "\n", "      ", "return", "math_ops", ".", "logical_not", "(", "math_ops", ".", "reduce_all", "(", "elements_finished", ")", ")", "\n", "\n", "", "def", "body", "(", "time", ",", "elements_finished", ",", "current_input", ",", "\n", "emit_ta", ",", "state", ",", "loop_state", ")", ":", "\n", "      ", "\"\"\"Internal while loop body for raw_rnn.\n\n      Args:\n        time: time scalar.\n        elements_finished: batch-size vector.\n        current_input: possibly nested tuple of input tensors.\n        emit_ta: possibly nested tuple of output TensorArrays.\n        state: possibly nested tuple of state tensors.\n        loop_state: possibly nested tuple of loop state tensors.\n\n      Returns:\n        Tuple having the same size as Args but with updated values.\n      \"\"\"", "\n", "(", "next_output", ",", "next_state", ")", "=", "cell", "(", "current_input", ",", "state", ")", "\n", "\n", "nest", ".", "assert_same_structure", "(", "state", ",", "next_state", ")", "\n", "nest", ".", "assert_same_structure", "(", "cell", ".", "output_size", ",", "next_output", ")", "\n", "\n", "next_time", "=", "time", "+", "1", "\n", "(", "next_finished", ",", "next_input", ",", "emit_output", ",", "next_loop_state", ")", "=", "loop_fn", "(", "\n", "next_time", ",", "next_output", ",", "loop_state", ")", "\n", "\n", "nest", ".", "assert_same_structure", "(", "current_input", ",", "next_input", ")", "\n", "nest", ".", "assert_same_structure", "(", "emit_ta", ",", "emit_output", ")", "\n", "\n", "# If loop_fn returns None for next_loop_state, just reuse the", "\n", "# previous one.", "\n", "loop_state", "=", "loop_state", "if", "next_loop_state", "is", "None", "else", "next_loop_state", "\n", "\n", "def", "_copy_some_through", "(", "current", ",", "candidate", ")", ":", "\n", "        ", "current_flat", "=", "nest", ".", "flatten", "(", "current", ")", "\n", "candidate_flat", "=", "nest", ".", "flatten", "(", "candidate", ")", "\n", "result_flat", "=", "[", "\n", "math_ops", ".", "select", "(", "elements_finished", ",", "current_i", ",", "candidate_i", ")", "\n", "for", "(", "current_i", ",", "candidate_i", ")", "in", "zip", "(", "current_flat", ",", "candidate_flat", ")", "]", "\n", "return", "nest", ".", "pack_sequence_as", "(", "\n", "structure", "=", "current", ",", "flat_sequence", "=", "result_flat", ")", "\n", "\n", "", "emit_output", "=", "_copy_some_through", "(", "zero_emit", ",", "emit_output", ")", "\n", "next_state", "=", "_copy_some_through", "(", "state", ",", "next_state", ")", "\n", "\n", "emit_output_flat", "=", "nest", ".", "flatten", "(", "emit_output", ")", "\n", "emit_ta_flat", "=", "nest", ".", "flatten", "(", "emit_ta", ")", "\n", "\n", "elements_finished", "=", "math_ops", ".", "logical_or", "(", "elements_finished", ",", "next_finished", ")", "\n", "\n", "emit_ta_flat", "=", "[", "\n", "ta", ".", "write", "(", "time", ",", "emit", ")", "\n", "for", "(", "ta", ",", "emit", ")", "in", "zip", "(", "emit_ta_flat", ",", "emit_output_flat", ")", "]", "\n", "\n", "emit_ta", "=", "nest", ".", "pack_sequence_as", "(", "\n", "structure", "=", "emit_structure", ",", "flat_sequence", "=", "emit_ta_flat", ")", "\n", "\n", "return", "(", "next_time", ",", "elements_finished", ",", "next_input", ",", "\n", "emit_ta", ",", "next_state", ",", "loop_state", ")", "\n", "\n", "", "returned", "=", "control_flow_ops", ".", "while_loop", "(", "\n", "condition", ",", "body", ",", "loop_vars", "=", "[", "\n", "time", ",", "elements_finished", ",", "next_input", ",", "\n", "emit_ta", ",", "state", ",", "loop_state", "]", ",", "\n", "parallel_iterations", "=", "parallel_iterations", ",", "\n", "swap_memory", "=", "swap_memory", ")", "\n", "\n", "(", "emit_ta", ",", "final_state", ",", "final_loop_state", ")", "=", "returned", "[", "-", "3", ":", "]", "\n", "\n", "if", "init_loop_state", "is", "None", ":", "\n", "      ", "final_loop_state", "=", "None", "\n", "\n", "", "return", "(", "emit_ta", ",", "final_state", ",", "final_loop_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.plot_confusion_matrix.plot_confusion_matrix": [[52, 103], ["matplotlib.subplots", "ax.imshow", "ax.set", "ax.set_xticks", "ax.set_yticks", "ax.grid", "ax.tick_params", "matplotlib.setp", "itertools.product", "itertools.product", "matplotlib.ylabel", "matplotlib.xlabel", "fig.tight_layout", "ax.get_xticklabels", "cm.astype", "cm.max", "range", "range", "ax.text", "range", "range", "ax.text", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.arange", "cm.sum", "round", "a.append", "numpy.sum", "len", "str", "round", "round"], "function", ["None"], ["def", "plot_confusion_matrix", "(", "cm", ",", "classes", ",", "\n", "normalize", "=", "False", ",", "\n", "title", "=", "'Confusion matrix'", ",", "\n", "cmap", "=", "plt", ".", "cm", ".", "Blues", ")", ":", "\n", "    ", "\"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "figsize", "=", "(", "4", ",", "4", ")", ")", "\n", "ax", ".", "imshow", "(", "cm", ",", "interpolation", "=", "'nearest'", ",", "cmap", "=", "cmap", ")", "\n", "#    plt.title(title,fontsize=12)", "\n", "#    plt.colorbar()", "\n", "ax", ".", "set", "(", "xticks", "=", "np", ".", "arange", "(", "cm", ".", "shape", "[", "1", "]", ")", ",", "\n", "yticks", "=", "np", ".", "arange", "(", "cm", ".", "shape", "[", "0", "]", ")", ",", "\n", "xticklabels", "=", "classes", ",", "yticklabels", "=", "classes", ",", "\n", "title", "=", "title", ",", "\n", "ylabel", "=", "'True label'", ",", "\n", "xlabel", "=", "'Predicted label'", ")", "\n", "\n", "# \u901a\u8fc7\u7ed8\u5236\u683c\u7f51\uff0c\u6a21\u62df\u6bcf\u4e2a\u5355\u5143\u683c\u7684\u8fb9\u6846", "\n", "ax", ".", "set_xticks", "(", "np", ".", "arange", "(", "cm", ".", "shape", "[", "1", "]", "+", "1", ")", "-", ".5", ",", "minor", "=", "True", ")", "\n", "ax", ".", "set_yticks", "(", "np", ".", "arange", "(", "cm", ".", "shape", "[", "0", "]", "+", "1", ")", "-", ".5", ",", "minor", "=", "True", ")", "\n", "ax", ".", "grid", "(", "which", "=", "\"minor\"", ",", "color", "=", "\"gray\"", ",", "linestyle", "=", "'-'", ",", "linewidth", "=", "0.2", ")", "\n", "ax", ".", "tick_params", "(", "which", "=", "\"minor\"", ",", "bottom", "=", "False", ",", "left", "=", "False", ")", "\n", "\n", "# \u5c06x\u8f74\u4e0a\u7684lables\u65cb\u8f6c45\u5ea6", "\n", "plt", ".", "setp", "(", "ax", ".", "get_xticklabels", "(", ")", ",", "rotation", "=", "45", ",", "ha", "=", "\"right\"", ",", "\n", "rotation_mode", "=", "\"anchor\"", ")", "\n", "\n", "\n", "#    tick_marks = np.arange(len(classes))", "\n", "#    ax.xticks(tick_marks, classes, rotation=45,fontsize=12)", "\n", "#    ax.yticks(np.arange(0,len(classes),1), classes,fontsize=12)", "\n", "a", "=", "[", "]", "\n", "cm_normalize", "=", "cm", ".", "astype", "(", "'float'", ")", "/", "cm", ".", "sum", "(", "axis", "=", "1", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "thresh", "=", "cm", ".", "max", "(", ")", "*", "0.5", "\n", "for", "i", ",", "j", "in", "itertools", ".", "product", "(", "range", "(", "cm", ".", "shape", "[", "0", "]", ")", ",", "range", "(", "cm", ".", "shape", "[", "1", "]", ")", ")", ":", "\n", "        ", "ax", ".", "text", "(", "j", ",", "i", ",", "round", "(", "cm", "[", "i", ",", "j", "]", ",", "2", ")", ",", "\n", "horizontalalignment", "=", "\"center\"", ",", "verticalalignment", "=", "\"top\"", ",", "\n", "color", "=", "\"white\"", "if", "cm", "[", "i", ",", "j", "]", ">", "thresh", "else", "\"black\"", ",", "fontsize", "=", "12", ")", "\n", "", "for", "i", ",", "j", "in", "itertools", ".", "product", "(", "range", "(", "cm_normalize", ".", "shape", "[", "0", "]", ")", ",", "range", "(", "cm_normalize", ".", "shape", "[", "1", "]", ")", ")", ":", "\n", "        ", "ax", ".", "text", "(", "j", ",", "i", ",", "str", "(", "round", "(", "cm_normalize", "[", "i", ",", "j", "]", "*", "100", ",", "2", ")", ")", "+", "'%'", ",", "\n", "horizontalalignment", "=", "\"center\"", ",", "verticalalignment", "=", "\"bottom\"", ",", "\n", "color", "=", "\"white\"", "if", "cm", "[", "i", ",", "j", "]", ">", "thresh", "else", "\"black\"", ",", "fontsize", "=", "12", ")", "\n", "if", "i", "==", "j", ":", "\n", "            ", "a", ".", "append", "(", "round", "(", "cm_normalize", "[", "i", ",", "j", "]", "*", "100", ",", "2", ")", ")", "\n", "\n", "", "", "plt", ".", "ylabel", "(", "'True label'", ",", "fontsize", "=", "15", ")", "\n", "plt", ".", "xlabel", "(", "'Predicted label'", ",", "fontsize", "=", "15", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "return", "(", "np", ".", "sum", "(", "a", ")", "/", "len", "(", "classes", ")", "/", "100", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fusionmodel.labelprocess": [[38, 44], ["len", "numpy.zeros", "enumerate", "int"], "function", ["None"], ["def", "labelprocess", "(", "label", ",", "n_class", "=", "n_classes", ")", ":", "\n", "    ", "label_length", "=", "len", "(", "label", ")", "\n", "label_matrix", "=", "np", ".", "zeros", "(", "(", "label_length", ",", "n_class", ")", ")", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "label", ")", ":", "\n", "       ", "label_matrix", "[", "i", ",", "int", "(", "j", ")", "]", "=", "1", "\n", "", "return", "label_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fusionmodel.next_batch": [[64, 82], ["min", "min", "len", "len", "len", "len", "min", "min", "min", "min", "len", "min", "min", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "next_batch", "(", "batch_size", ",", "train_x", ",", "train_y", ",", "newli_train", ",", "force", ")", ":", "\n", "    ", "global", "batchid_force", ",", "batchid_time", "\n", "if", "force", "==", "True", ":", "\n", "        ", "if", "batchid_force", "+", "batch_size", ">", "len", "(", "train_x", ")", ":", "\n", "           ", "batchid_force", "=", "0", "\n", "", "batch_data", "=", "(", "train_x", "[", "batchid_force", ":", "min", "(", "batchid_force", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", ",", ":", "]", ")", "\n", "batch_labels", "=", "(", "newli_train", "[", "batchid_force", ":", "min", "(", "batchid_force", "+", "batch_size", ",", "len", "(", "newli_train", ")", ")", ",", ":", "]", ")", "\n", "batch_labels_1d", "=", "(", "train_y", "[", "batchid_force", ":", "min", "(", "batchid_force", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", "]", ")", "\n", "batchid_force", "=", "min", "(", "batchid_force", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", "\n", "return", "batch_data", ",", "batch_labels", ",", "batch_labels_1d", "\n", "", "else", ":", "\n", "        ", "if", "batchid_time", "+", "batch_size", ">", "len", "(", "train_x", ")", ":", "\n", "           ", "batchid_time", "=", "0", "\n", "", "batch_data", "=", "(", "train_x", "[", "batchid_time", ":", "min", "(", "batchid_time", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", ",", ":", "]", ")", "\n", "batch_labels", "=", "(", "newli_train", "[", "batchid_time", ":", "min", "(", "batchid_time", "+", "batch_size", ",", "len", "(", "newli_train", ")", ")", ",", ":", "]", ")", "\n", "batch_labels_1d", "=", "(", "train_y", "[", "batchid_time", ":", "min", "(", "batchid_time", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", "]", ")", "\n", "batchid_time", "=", "min", "(", "batchid_time", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", "\n", "return", "batch_data", ",", "batch_labels", ",", "batch_labels_1d", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fusionmodel.RNN": [[85, 106], ["tensorflow.transpose", "tensorflow.reshape", "tensorflow.split", "rnn_cell_GRU.GRUCell", "rnn_cell_GRU.DropoutWrapper", "rnn_cell_GRU.MultiRNNCell", "rnn.rnn", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn.rnn"], ["", "", "def", "RNN", "(", "x", ",", "weights", ",", "biases", ",", "n_input", ")", ":", "\n", "    ", "x", "=", "tf", ".", "transpose", "(", "x", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "# Reshaping to (n_steps*batch_size, n_input)", "\n", "x", "=", "tf", ".", "reshape", "(", "tensor", "=", "x", ",", "shape", "=", "[", "-", "1", ",", "n_input", "]", ")", "\n", "# Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)", "\n", "x", "=", "tf", ".", "split", "(", "value", "=", "x", ",", "num_or_size_splits", "=", "n_steps", ",", "axis", "=", "0", ")", "\n", "# Define a lstm cell with tensorflow", "\n", "#lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1)", "\n", "lstm_cell", "=", "rnn_cell", ".", "GRUCell", "(", "n_hidden", ")", "\n", "#lstm_cell = rnn_cell.LSTMCell(n_hidden,use_peepholes=True)", "\n", "# avoid overfitting", "\n", "lstm_cell", "=", "rnn_cell", ".", "DropoutWrapper", "(", "lstm_cell", ",", "output_keep_prob", "=", "0.5", ")", "\n", "# 2 layers lstm", "\n", "#    num_units = [256, 256]", "\n", "#    cells = [rnn_cell.GRUCell(num_units=n) for n in num_units]", "\n", "#    lstm_cell = rnn_cell.MultiRNNCell(cells)", "\n", "lstm_cell", "=", "rnn_cell", ".", "MultiRNNCell", "(", "[", "lstm_cell", "]", "*", "2", ")", "\n", "# Get lstm cell output", "\n", "#    print(x)", "\n", "outputs", ",", "states", "=", "rnn", ".", "rnn", "(", "cell", "=", "lstm_cell", ",", "inputs", "=", "x", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "return", "tf", ".", "matmul", "(", "outputs", "[", "-", "1", "]", ",", "weights", ")", "+", "biases", ",", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fusionmodel.feature_connect": [[108, 117], ["numpy.array", "range", "int", "numpy.array", "range", "numpy.transpose", "numpy.concatenate", "numpy.transpose"], "function", ["None"], ["", "def", "feature_connect", "(", "a_time", ",", "a_force", ")", ":", "\n", "    ", "a", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "for", "j", "in", "range", "(", "int", "(", "11340", "/", "15", ")", ")", ":", "\n", "        ", "f", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "for", "i", "in", "range", "(", "15", ")", ":", "\n", "            ", "f", "=", "np", ".", "concatenate", "(", "(", "f", ",", "a_force", "[", "j", "*", "15", "+", "i", ",", ":", "]", ")", ",", "axis", "=", "0", ")", "if", "f", ".", "size", "else", "a_force", "[", "j", "*", "15", "+", "i", ",", ":", "]", "\n", "", "a", "=", "np", ".", "c_", "[", "a", ",", "f", "]", "if", "a", ".", "size", "else", "f", "\n", "#    np.savetxt('./feature_extract/fusionfeature_data.txt', np.c_[a_time,np.transpose(a)],fmt='%.4f')", "\n", "", "return", "np", ".", "c_", "[", "a_time", ",", "np", ".", "transpose", "(", "a", ")", "]", ",", "np", ".", "transpose", "(", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fusionmodel.DCCA": [[118, 137], ["deep_CCA_model.DeepCCA"], "function", ["None"], ["", "def", "DCCA", "(", ")", ":", "\n", "#   LSTM CCA", "\n", "    ", "outdim_size", "=", "10", "\n", "input_size1", "=", "n_hidden", "\n", "input_size2", "=", "n_hidden", "\n", "#    input_size2 = 256", "\n", "layer_sizes1", "=", "[", "1024", ",", "1024", ",", "1024", ",", "outdim_size", "]", "\n", "layer_sizes2", "=", "[", "1024", ",", "1024", ",", "1024", ",", "outdim_size", "]", "\n", "\n", "layer_sizes3", "=", "[", "1024", ",", "1024", ",", "1024", ",", "n_classes", "]", "\n", "layer_sizes4", "=", "[", "1024", ",", "1024", ",", "1024", ",", "n_classes", "]", "\n", "reg_par", "=", "1e-4", "\n", "use_all_singular_values", "=", "True", "\n", "dcca_model", "=", "DeepCCA", "(", "layer_sizes1", ",", "layer_sizes2", ",", "layer_sizes3", ",", "layer_sizes4", ",", "\n", "input_size1", ",", "input_size2", ",", "\n", "outdim_size", ",", "\n", "reg_par", ",", "use_all_singular_values", ")", "\n", "\n", "return", "dcca_model", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fusionmodel.softmax": [[138, 143], ["numpy.exp", "numpy.sum"], "function", ["None"], ["", "def", "softmax", "(", "x", ")", ":", "\n", "    ", "x_exp", "=", "np", ".", "exp", "(", "x", ")", "\n", "x_sum", "=", "np", ".", "sum", "(", "x_exp", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "s", "=", "x_exp", "/", "x_sum", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.HMMTrainer.__init__": [[81, 101], ["len", "hmmlearn.hmm.GaussianHMM", "hmmlearn.hmm.GMMHMM"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model_name", "=", "'GaussianHMM'", ",", "n_components", "=", "10", ",", "cov_type", "=", "'diag'", ",", "n_iter", "=", "100", ")", ":", "\n", "#\u6a21\u578b\u540d\u79f0 hmmlearn\u5b9e\u73b0\u4e86\u4e09\u79cdHMM\u6a21\u578b\u7c7b\uff0cGaussianHMM\u548cGMMHMM\u662f\u8fde\u7eed\u89c2\u6d4b\u72b6\u6001\u7684HMM\u6a21\u578b\uff0cMultinomialHMM\u662f\u79bb\u6563\u89c2\u6d4b\u72b6\u6001\u7684\u6a21\u578b", "\n", "        ", "self", ".", "model", "=", "None", "\n", "self", ".", "model_name", "=", "model_name", "\n", "#\u9690\u85cf\u72b6\u6001\u4e2a\u6570", "\n", "self", ".", "n_components", "=", "n_components", "\n", "#\u8f6c\u79fb\u77e9\u9635\u534f\u65b9\u5dee\u7c7b\u578b", "\n", "self", ".", "cov_type", "=", "cov_type", "\n", "#\u8bad\u7ec3\u8fed\u4ee3\u6b21\u6570", "\n", "self", ".", "n_iter", "=", "n_iter", "\n", "self", ".", "models", "=", "[", "]", "\n", "#        self.states = [\"als\", \"control\",\"hunt\", \"park\"]", "\n", "#        self.n_states = len(self.states)", "\n", "self", ".", "observations", "=", "[", "]", "\n", "self", ".", "n_observations", "=", "len", "(", "self", ".", "observations", ")", "\n", "if", "self", ".", "model_name", "==", "'GaussianHMM'", ":", "\n", "            ", "self", ".", "model", "=", "hmm", ".", "GaussianHMM", "(", "n_components", "=", "self", ".", "n_components", ",", "covariance_type", "=", "self", ".", "cov_type", ",", "n_iter", "=", "self", ".", "n_iter", ")", "\n", "", "else", ":", "\n", "#            self.model = hmm.MultinomialHMM(n_components=self.n_components, n_iter=self.n_iter, tol=0.01)", "\n", "            ", "self", ".", "model", "=", "hmm", ".", "GMMHMM", "(", "n_components", "=", "self", ".", "n_components", ",", "n_iter", "=", "self", ".", "n_iter", ",", "tol", "=", "0.01", ")", "\n", "#            raise TypeError('Invalid model type')", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.HMMTrainer.train": [[104, 107], ["numpy.seterr", "hmmexm.HMMTrainer.models.append", "hmmexm.HMMTrainer.model.fit"], "methods", ["None"], ["", "", "def", "train", "(", "self", ",", "X", ")", ":", "\n", "        ", "np", ".", "seterr", "(", "all", "=", "'ignore'", ")", "\n", "self", ".", "models", ".", "append", "(", "self", ".", "model", ".", "fit", "(", "X", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.HMMTrainer.get_score": [[109, 111], ["hmmexm.HMMTrainer.model.score"], "methods", ["None"], ["", "def", "get_score", "(", "self", ",", "input_data", ",", "label", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "score", "(", "input_data", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.hmm_model_create": [[113, 127], ["hmmexm.HMMTrainer", "HMMTrainer.model.fit", "hmm_models.append", "numpy.ones"], "function", ["None"], ["", "", "def", "hmm_model_create", "(", "data", ",", "hmm_models", ",", "class_label", ",", "n_components", "=", "10", ")", ":", "\n", "    ", "m", ",", "n", "=", "data", ".", "shape", "\n", "hmm_trainer", "=", "HMMTrainer", "(", ")", "\n", "#    class_labels=class_label * np.ones((m,1))", "\n", "hmm_trainer", ".", "model", ".", "fit", "(", "data", ",", "class_label", ")", "\n", "startprob", "=", "1", "/", "n_components", "*", "np", ".", "ones", "(", "(", "1", ",", "n_components", ")", ")", "\n", "hmm_trainer", ".", "model", ".", "startprob_", "=", "startprob", "[", "0", "]", "\n", "#    hmm_trainer.model.transmat_=  np.zeros((n_components, n_components)) ", "\n", "#    for i in range(n_components-1):", "\n", "#        hmm_trainer.model.transmat_[n_components-1,0]=1", "\n", "#        hmm_trainer.model.transmat_[i,i+1] = 1", "\n", "#    print(hmm_trainer.model.transmat_)", "\n", "#    hmm_trainer.model.emissionprob_= B_emissionprob", "\n", "hmm_models", ".", "append", "(", "(", "hmm_trainer", ",", "class_label", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.auto_data_split_fog": [[128, 146], ["sklearn.cross_validation.train_test_split", "sklearn.cross_validation.train_test_split", "sklearn.cross_validation.train_test_split", "trainsets_x.append", "trainsets_x.append", "trainsets_x.append", "testsets.append", "testsets.append"], "function", ["None"], ["", "def", "auto_data_split_fog", "(", "a", ",", "b", ")", ":", "\n", "    ", "trainsets_x", "=", "[", "]", "\n", "testsets", "=", "[", "]", "\n", "\n", "train_x1", ",", "test_x1", ",", "train_y1", ",", "test_y1", "=", "train_test_split", "(", "a", "[", "0", ":", "7650", ",", ":", "]", ",", "b", "[", "0", ":", "7650", "]", ",", "test_size", "=", "0.7", ")", "\n", "train_x2", ",", "test_x2", ",", "train_y2", ",", "test_y2", "=", "train_test_split", "(", "a", "[", "7650", ":", "11880", ",", ":", "]", ",", "b", "[", "7650", ":", "11880", "]", ",", "test_size", "=", "0.7", ")", "\n", "train_x3", ",", "test_x3", ",", "train_y3", ",", "test_y3", "=", "train_test_split", "(", "a", "[", "11880", ":", ",", ":", "]", ",", "b", "[", "11880", ":", "]", ",", "test_size", "=", "0.7", ")", "\n", "\n", "trainsets_x", ".", "append", "(", "train_x1", ")", "\n", "trainsets_x", ".", "append", "(", "train_x2", ")", "\n", "trainsets_x", ".", "append", "(", "train_x3", ")", "\n", "\n", "testsets_x", "=", "np", ".", "r_", "[", "test_x1", ",", "test_x2", ",", "test_x3", "]", "\n", "testsets_y", "=", "np", ".", "r_", "[", "test_y1", ",", "test_y2", ",", "test_y3", "]", "\n", "testsets", ".", "append", "(", "testsets_x", ")", "\n", "testsets", ".", "append", "(", "testsets_y", ")", "\n", "\n", "return", "trainsets_x", ",", "testsets", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.auto_data_split": [[148, 168], ["sklearn.cross_validation.train_test_split", "sklearn.cross_validation.train_test_split", "sklearn.cross_validation.train_test_split", "sklearn.cross_validation.train_test_split", "trainsets_x.append", "trainsets_x.append", "trainsets_x.append", "trainsets_x.append", "testsets.append", "testsets.append"], "function", ["None"], ["", "def", "auto_data_split", "(", "a", ",", "b", ")", ":", "\n", "    ", "trainsets_x", "=", "[", "]", "\n", "testsets", "=", "[", "]", "\n", "\n", "train_x1", ",", "test_x1", ",", "train_y1", ",", "test_y1", "=", "train_test_split", "(", "a", "[", "0", ":", "156", ",", ":", "]", ",", "b", "[", "0", ":", "156", "]", ",", "test_size", "=", "0.2", ")", "\n", "train_x2", ",", "test_x2", ",", "train_y2", ",", "test_y2", "=", "train_test_split", "(", "a", "[", "156", ":", "348", ",", ":", "]", ",", "b", "[", "156", ":", "348", "]", ",", "test_size", "=", "0.2", ")", "\n", "train_x3", ",", "test_x3", ",", "train_y3", ",", "test_y3", "=", "train_test_split", "(", "a", "[", "348", ":", "576", ",", ":", "]", ",", "b", "[", "348", ":", "576", "]", ",", "test_size", "=", "0.2", ")", "\n", "train_x4", ",", "test_x4", ",", "train_y4", ",", "test_y4", "=", "train_test_split", "(", "a", "[", "576", ":", "756", ",", ":", "]", ",", "b", "[", "576", ":", "756", "]", ",", "test_size", "=", "0.2", ")", "\n", "\n", "trainsets_x", ".", "append", "(", "train_x1", ")", "\n", "trainsets_x", ".", "append", "(", "train_x2", ")", "\n", "trainsets_x", ".", "append", "(", "train_x3", ")", "\n", "trainsets_x", ".", "append", "(", "train_x4", ")", "\n", "\n", "testsets_x", "=", "np", ".", "r_", "[", "test_x1", ",", "test_x2", ",", "test_x3", ",", "test_x4", "]", "\n", "testsets_y", "=", "np", ".", "r_", "[", "test_y1", ",", "test_y2", ",", "test_y3", ",", "test_y4", "]", "\n", "testsets", ".", "append", "(", "testsets_x", ")", "\n", "testsets", ".", "append", "(", "testsets_y", ")", "\n", "\n", "return", "trainsets_x", ",", "testsets", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.manul_data_split": [[170, 238], ["trainset1.append", "trainset1.append", "trainset1.append", "trainset1.append", "trainsets.append", "testsets.append", "trainset2.append", "trainset2.append", "trainset2.append", "trainset2.append", "trainsets.append", "testsets.append", "trainset3.append", "trainset3.append", "trainset3.append", "trainset3.append", "trainsets.append", "testsets.append", "trainset4.append", "trainset4.append", "trainset4.append", "trainset4.append", "trainsets.append", "testsets.append", "trainset5.append", "trainset5.append", "trainset5.append", "trainset5.append", "trainsets.append", "testsets.append"], "function", ["None"], ["", "def", "manul_data_split", "(", "a", ",", "b", ")", ":", "\n", "\n", "    ", "trainset1", "=", "[", "]", "\n", "trainset2", "=", "[", "]", "\n", "trainset3", "=", "[", "]", "\n", "trainset4", "=", "[", "]", "\n", "trainset5", "=", "[", "]", "\n", "trainsets", "=", "[", "]", "\n", "testsets", "=", "[", "]", "\n", "\n", "#    training data", "\n", "#    training set 1", "\n", "trainset1", ".", "append", "(", "a", "[", "0", ":", "125", ",", ":", "]", ")", "\n", "trainset1", ".", "append", "(", "a", "[", "156", ":", "310", ",", ":", "]", ")", "\n", "trainset1", ".", "append", "(", "a", "[", "348", ":", "530", ",", ":", "]", ")", "\n", "trainset1", ".", "append", "(", "a", "[", "576", ":", "720", ",", ":", "]", ")", "\n", "trainsets", ".", "append", "(", "trainset1", ")", "\n", "#    testing data 1", "\n", "test_x1", "=", "np", ".", "r_", "[", "a", "[", "125", ":", "156", ",", ":", "]", ",", "a", "[", "310", ":", "348", ",", ":", "]", ",", "a", "[", "530", ":", "576", ",", ":", "]", ",", "a", "[", "720", ":", "756", ",", ":", "]", "]", "\n", "test_y1", "=", "np", ".", "r_", "[", "b", "[", "125", ":", "156", "]", ",", "b", "[", "310", ":", "348", "]", ",", "b", "[", "530", ":", "576", "]", ",", "b", "[", "720", ":", "756", "]", "]", "\n", "testsets", ".", "append", "(", "[", "test_x1", ",", "test_y1", "]", ")", "\n", "\n", "#    training set 2", "\n", "trainset2", ".", "append", "(", "a", "[", "31", ":", "156", ",", ":", "]", ")", "\n", "trainset2", ".", "append", "(", "a", "[", "156", "+", "38", ":", "348", ",", ":", "]", ")", "\n", "trainset2", ".", "append", "(", "a", "[", "348", "+", "46", ":", "576", ",", ":", "]", ")", "\n", "trainset2", ".", "append", "(", "a", "[", "576", "+", "36", ":", "756", ",", ":", "]", ")", "\n", "trainsets", ".", "append", "(", "trainset2", ")", "\n", "#    testing data 2", "\n", "test_x2", "=", "np", ".", "r_", "[", "a", "[", "0", ":", "31", ",", ":", "]", ",", "a", "[", "156", ":", "156", "+", "38", ",", ":", "]", ",", "a", "[", "348", ":", "348", "+", "46", ",", ":", "]", ",", "a", "[", "576", ":", "576", "+", "36", ",", ":", "]", "]", "\n", "test_y2", "=", "np", ".", "r_", "[", "b", "[", "0", ":", "31", "]", ",", "b", "[", "156", ":", "156", "+", "38", "]", ",", "b", "[", "348", ":", "348", "+", "46", "]", ",", "b", "[", "576", ":", "576", "+", "36", "]", "]", "\n", "testsets", ".", "append", "(", "[", "test_x2", ",", "test_y2", "]", ")", "\n", "\n", "#    training set 3", "\n", "trainset3", ".", "append", "(", "a", "[", "10", ":", "125", "+", "10", ",", ":", "]", ")", "\n", "trainset3", ".", "append", "(", "a", "[", "156", "+", "10", ":", "310", "+", "10", ",", ":", "]", ")", "\n", "trainset3", ".", "append", "(", "a", "[", "348", "+", "10", ":", "530", "+", "10", ",", ":", "]", ")", "\n", "trainset3", ".", "append", "(", "a", "[", "576", "+", "10", ":", "720", "+", "10", ",", ":", "]", ")", "\n", "trainsets", ".", "append", "(", "trainset3", ")", "\n", "#    testing data 3", "\n", "test_x3", "=", "np", ".", "r_", "[", "a", "[", "0", ":", "10", ",", ":", "]", ",", "a", "[", "135", ":", "156", ",", ":", "]", ",", "a", "[", "156", ":", "166", ",", ":", "]", ",", "a", "[", "320", ":", "348", ",", ":", "]", ",", "a", "[", "348", ":", "358", ",", ":", "]", ",", "a", "[", "540", ":", "576", ",", ":", "]", ",", "a", "[", "576", ":", "586", ",", ":", "]", ",", "a", "[", "730", ":", "756", ",", ":", "]", "]", "\n", "test_y3", "=", "np", ".", "r_", "[", "b", "[", "0", ":", "10", "]", ",", "b", "[", "135", ":", "156", "]", ",", "b", "[", "156", ":", "166", "]", ",", "b", "[", "320", ":", "348", "]", ",", "b", "[", "348", ":", "358", "]", ",", "b", "[", "540", ":", "576", "]", ",", "b", "[", "576", ":", "586", "]", ",", "b", "[", "730", ":", "756", "]", "]", "\n", "testsets", ".", "append", "(", "[", "test_x3", ",", "test_y3", "]", ")", "\n", "\n", "#    training set 4", "\n", "trainset4", ".", "append", "(", "a", "[", "20", ":", "145", ",", ":", "]", ")", "\n", "trainset4", ".", "append", "(", "a", "[", "176", ":", "330", ",", ":", "]", ")", "\n", "trainset4", ".", "append", "(", "a", "[", "368", ":", "550", ",", ":", "]", ")", "\n", "trainset4", ".", "append", "(", "a", "[", "596", ":", "740", ",", ":", "]", ")", "\n", "trainsets", ".", "append", "(", "trainset4", ")", "\n", "#    testing data 4", "\n", "test_x4", "=", "np", ".", "r_", "[", "a", "[", "0", ":", "20", ",", ":", "]", ",", "a", "[", "145", ":", "156", ",", ":", "]", ",", "a", "[", "156", ":", "176", ",", ":", "]", ",", "a", "[", "330", ":", "348", ",", ":", "]", ",", "a", "[", "348", ":", "368", ",", ":", "]", ",", "a", "[", "550", ":", "576", ",", ":", "]", ",", "a", "[", "576", ":", "596", ",", ":", "]", ",", "a", "[", "740", ":", "756", ",", ":", "]", "]", "\n", "test_y4", "=", "np", ".", "r_", "[", "b", "[", "0", ":", "20", "]", ",", "b", "[", "145", ":", "156", "]", ",", "b", "[", "156", ":", "176", "]", ",", "b", "[", "330", ":", "348", "]", ",", "b", "[", "348", ":", "368", "]", ",", "b", "[", "550", ":", "576", "]", ",", "b", "[", "576", ":", "596", "]", ",", "b", "[", "740", ":", "756", "]", "]", "\n", "testsets", ".", "append", "(", "[", "test_x4", ",", "test_y4", "]", ")", "\n", "\n", "#    training set 5", "\n", "trainset5", ".", "append", "(", "a", "[", "30", ":", "155", ",", ":", "]", ")", "\n", "trainset5", ".", "append", "(", "a", "[", "186", ":", "340", ",", ":", "]", ")", "\n", "trainset5", ".", "append", "(", "a", "[", "378", ":", "560", ",", ":", "]", ")", "\n", "trainset5", ".", "append", "(", "a", "[", "606", ":", "750", ",", ":", "]", ")", "\n", "trainsets", ".", "append", "(", "trainset5", ")", "\n", "\n", "#    testing data 5", "\n", "test_x5", "=", "np", ".", "r_", "[", "a", "[", "0", ":", "30", ",", ":", "]", ",", "a", "[", "145", ":", "156", ",", ":", "]", ",", "a", "[", "156", ":", "176", ",", ":", "]", ",", "a", "[", "330", ":", "348", ",", ":", "]", ",", "a", "[", "348", ":", "368", ",", ":", "]", ",", "a", "[", "550", ":", "576", ",", ":", "]", ",", "a", "[", "576", ":", "596", ",", ":", "]", ",", "a", "[", "740", ":", "756", ",", ":", "]", "]", "\n", "test_y5", "=", "np", ".", "r_", "[", "b", "[", "0", ":", "30", "]", ",", "b", "[", "145", ":", "156", "]", ",", "b", "[", "156", ":", "176", "]", ",", "b", "[", "330", ":", "348", "]", ",", "b", "[", "348", ":", "368", "]", ",", "b", "[", "550", ":", "576", "]", ",", "b", "[", "576", ":", "596", "]", ",", "b", "[", "740", ":", "756", "]", "]", "\n", "testsets", ".", "append", "(", "[", "test_x5", ",", "test_y5", "]", ")", "\n", "\n", "return", "trainsets", ",", "testsets", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.softmax": [[239, 244], ["numpy.exp", "numpy.sum"], "function", ["None"], ["", "def", "softmax", "(", "x", ")", ":", "\n", "    ", "x_exp", "=", "np", ".", "exp", "(", "x", ")", "\n", "x_sum", "=", "np", ".", "sum", "(", "x_exp", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "s", "=", "x_exp", "/", "x_sum", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.hmm_3model_classification": [[245, 301], ["print", "hmmexm.auto_data_split_fog", "range", "numpy.mean", "time.clock", "hmmexm.hmm_model_create", "hmmexm.hmm_model_create", "hmmexm.hmm_model_create", "enumerate", "accuracys.append", "time.clock", "numpy.savetxt", "matplotlib.show", "print", "float", "predictlabel.append", "testlabel.append", "hmm_model.get_score", "int", "int", "int", "len", "j.reshape", "numpy.array"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.auto_data_split_fog", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.hmm_model_create", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.hmm_model_create", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.hmm_model_create", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.time_channel.HMMTrainer.get_score"], ["", "def", "hmm_3model_classification", "(", "a", ",", "b", ")", ":", "\n", "# combine the lda feature(2d) with ccafuse_data", "\n", "    ", "accuracys", "=", "[", "]", "\n", "#    hmm_temp = HMMTrainer()", "\n", "#    trainsets, testsets = manul_data_split(a,b)", "\n", "print", "(", "a", ".", "shape", ")", "\n", "trainsets", ",", "testsets", "=", "auto_data_split_fog", "(", "a", ",", "b", ")", "\n", "hmm_models", "=", "[", "]", "\n", "predictlabel", "=", "[", "]", "\n", "testlabel", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "1", ")", ":", "\n", "        ", "s_time", "=", "time", ".", "clock", "(", ")", "\n", "#    4 HMM model", "\n", "#    als HMM", "\n", "hmm_model_create", "(", "trainsets", "[", "0", "]", ",", "hmm_models", ",", "class_label", "=", "0", ")", "\n", "#    control HMM    ", "\n", "hmm_model_create", "(", "trainsets", "[", "1", "]", ",", "hmm_models", ",", "class_label", "=", "1", ")", "\n", "#    hunt HMM", "\n", "hmm_model_create", "(", "trainsets", "[", "2", "]", ",", "hmm_models", ",", "class_label", "=", "2", ")", "\n", "\n", "#    20% as testing dataset", "\n", "test_x", "=", "testsets", "[", "0", "]", "\n", "test_y", "=", "testsets", "[", "1", "]", "\n", "count", "=", "0", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "test_x", ")", ":", "\n", "            ", "max_score", "=", "float", "(", "'-inf'", ")", "\n", "output_label", "=", "0", "\n", "# \u8fed\u4ee3\u6240\u6709\u6a21\u578b ", "\n", "# \u5f97\u5206\u6700\u9ad8\u7684\u6a21\u578b\u5bf9\u5e94\u7684\u6807\u7b7e\uff0c\u5373\u4e3a\u8f93\u51fa\u6807\u7b7e\uff08\u8bc6\u522b\u503c\uff09", "\n", "for", "item", "in", "hmm_models", ":", "\n", "                ", "hmm_model", ",", "label", "=", "item", "\n", "score", "=", "hmm_model", ".", "get_score", "(", "j", ".", "reshape", "(", "1", ",", "-", "1", ")", ",", "np", ".", "array", "(", "[", "label", "]", ")", ")", "\n", "#            logprob, h = hmm_model.model.decode(j.reshape(-1, 1), algorithm=\"viterbi\")", "\n", "if", "score", ">", "max_score", ":", "\n", "                    ", "max_score", "=", "score", "\n", "output_label", "=", "label", "\n", "\n", "#        # \u6253\u5370\u8f93\u51fa", "\n", "", "", "predictlabel", ".", "append", "(", "output_label", ")", "\n", "testlabel", ".", "append", "(", "int", "(", "test_y", "[", "i", "]", ")", ")", "\n", "\n", "if", "int", "(", "output_label", ")", "==", "int", "(", "test_y", "[", "i", "]", ")", ":", "\n", "                ", "count", "=", "count", "+", "1", "\n", "", "", "accuracys", ".", "append", "(", "count", "/", "len", "(", "test_y", ")", ")", "\n", "e_time", "=", "time", ".", "clock", "(", ")", "\n", "np", ".", "savetxt", "(", "'predict_hmm_label.csv'", ",", "np", ".", "c_", "[", "testlabel", ",", "predictlabel", "]", ",", "fmt", "=", "'%.d'", ")", "\n", "#        cnf_matrix = confusion_matrix(testlabel, predictlabel)", "\n", "#        np.set_printoptions(precision=4)", "\n", "#        plt.figure()", "\n", "#        #        cnf_matrix=np.array([[1,0.,0.,0.],[0.,0.9655,0.0345,0.],[0.,0.0166,0.9834,0.],[0.,0.0042,0.0112,0.9846]])", "\n", "#        plot_confusion_matrix(cnf_matrix, classes=['2','2.5','3'], normalize=True,", "\n", "#                          title='Normalized confusion matrix')", "\n", "plt", ".", "show", "(", ")", "\n", "print", "(", "accuracys", ",", "e_time", "-", "s_time", ")", "\n", "", "return", "np", ".", "mean", "(", "accuracys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.hmm_4model_classification": [[305, 374], ["print", "hmmexm.auto_data_split", "range", "numpy.mean", "time.clock", "hmmexm.hmm_model_create", "hmmexm.hmm_model_create", "hmmexm.hmm_model_create", "hmmexm.hmm_model_create", "enumerate", "accuracys.append", "time.clock", "sklearn.metrics.confusion_matrix", "numpy.set_printoptions", "matplotlib.figure", "plot_confusion_matrix.plot_confusion_matrix", "matplotlib.show", "print", "float", "predictlabel.append", "testlabel.append", "hmm_model.get_score", "int", "int", "int", "len", "j.reshape", "numpy.array"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.auto_data_split", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.hmm_model_create", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.hmm_model_create", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.hmm_model_create", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.hmmexm.hmm_model_create", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.plot_confusion_matrix.plot_confusion_matrix", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.time_channel.HMMTrainer.get_score"], ["", "def", "hmm_4model_classification", "(", "a", ",", "b", ")", ":", "\n", "# combine the lda feature(2d) with ccafuse_data", "\n", "#    ldafeature=np.loadtxt('./feature_extract/ldafeature_data.txt')", "\n", "#    ldafeature=softmax(ldafeature)", "\n", "#    print(ldafeature)", "\n", "#    a=np.loadtxt(\"./feature_extract/ccafuse_data.txt\")", "\n", "#    b=np.loadtxt(\"./feature_extract/fusionfeature_label.txt\")", "\n", "#    a=np.c_[a,ldafeature]", "\n", "\n", "#    a_force=np.loadtxt(\"/home/zat/zresearch/lstm/lstm_test_improve/feature_extract/out256_fc_10s_11340.txt\")", "\n", "#    b_force=np.loadtxt(\"/home/zat/zresearch/lstm/lstm_test_improve/feature_extract/force_alignlabel_11340.txt\")", "\n", "#    a_time=np.loadtxt(\"/home/zat/zresearch/lstm/lstm_test_improve/feature_extract/out256_ts_10s.txt\")", "\n", "#    B_emissionprob=np.loadtxt(\"/home/zat/zresearch/lstm/lstm_test_improve/feature_extract/aftersoftmax_force_10s_11340.txt\")", "\n", "#    train_x,test_x,train_y,test_y = train_test_split(a,b,test_size=0.2)", "\n", "#    print(train_x.shape,test_x.shape)", "\n", "    ", "accuracys", "=", "[", "]", "\n", "#    hmm_temp = HMMTrainer()", "\n", "#    trainsets, testsets = manul_data_split(a,b)", "\n", "print", "(", "a", ".", "shape", ")", "\n", "trainsets", ",", "testsets", "=", "auto_data_split", "(", "a", ",", "b", ")", "\n", "hmm_models", "=", "[", "]", "\n", "predictlabel", "=", "[", "]", "\n", "testlabel", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "        ", "s_time", "=", "time", ".", "clock", "(", ")", "\n", "#    4 HMM model", "\n", "#    als HMM", "\n", "hmm_model_create", "(", "trainsets", "[", "0", "]", ",", "hmm_models", ",", "class_label", "=", "1", ")", "\n", "#    control HMM    ", "\n", "hmm_model_create", "(", "trainsets", "[", "1", "]", ",", "hmm_models", ",", "class_label", "=", "2", ")", "\n", "#    hunt HMM", "\n", "hmm_model_create", "(", "trainsets", "[", "2", "]", ",", "hmm_models", ",", "class_label", "=", "3", ")", "\n", "#    parkinson HMM", "\n", "hmm_model_create", "(", "trainsets", "[", "3", "]", ",", "hmm_models", ",", "class_label", "=", "4", ")", "\n", "#    20% as testing dataset", "\n", "test_x", "=", "testsets", "[", "0", "]", "\n", "test_y", "=", "testsets", "[", "1", "]", "\n", "count", "=", "0", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "test_x", ")", ":", "\n", "            ", "max_score", "=", "float", "(", "'-inf'", ")", "\n", "output_label", "=", "0", "\n", "# \u8fed\u4ee3\u6240\u6709\u6a21\u578b ", "\n", "# \u5f97\u5206\u6700\u9ad8\u7684\u6a21\u578b\u5bf9\u5e94\u7684\u6807\u7b7e\uff0c\u5373\u4e3a\u8f93\u51fa\u6807\u7b7e\uff08\u8bc6\u522b\u503c\uff09", "\n", "for", "item", "in", "hmm_models", ":", "\n", "                ", "hmm_model", ",", "label", "=", "item", "\n", "score", "=", "hmm_model", ".", "get_score", "(", "j", ".", "reshape", "(", "1", ",", "-", "1", ")", ",", "np", ".", "array", "(", "[", "label", "]", ")", ")", "\n", "#            logprob, h = hmm_model.model.decode(j.reshape(-1, 1), algorithm=\"viterbi\")", "\n", "if", "score", ">", "max_score", ":", "\n", "                    ", "max_score", "=", "score", "\n", "output_label", "=", "label", "\n", "\n", "#        # \u6253\u5370\u8f93\u51fa", "\n", "", "", "predictlabel", ".", "append", "(", "output_label", ")", "\n", "testlabel", ".", "append", "(", "int", "(", "test_y", "[", "i", "]", ")", ")", "\n", "\n", "if", "int", "(", "output_label", ")", "==", "int", "(", "test_y", "[", "i", "]", ")", ":", "\n", "                ", "count", "=", "count", "+", "1", "\n", "", "", "accuracys", ".", "append", "(", "count", "/", "len", "(", "test_y", ")", ")", "\n", "e_time", "=", "time", ".", "clock", "(", ")", "\n", "cnf_matrix", "=", "confusion_matrix", "(", "testlabel", ",", "predictlabel", ")", "\n", "np", ".", "set_printoptions", "(", "precision", "=", "4", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "#        cnf_matrix=np.array([[1,0.,0.,0.],[0.,0.9655,0.0345,0.],[0.,0.0166,0.9834,0.],[0.,0.0042,0.0112,0.9846]])", "\n", "plot_confusion_matrix", "(", "cnf_matrix", ",", "classes", "=", "[", "'CO'", ",", "'ALS'", ",", "'HD'", ",", "'PD'", "]", ",", "normalize", "=", "True", ",", "\n", "title", "=", "'Normalized confusion matrix'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "print", "(", "accuracys", ",", "e_time", "-", "s_time", ")", "\n", "", "return", "np", ".", "mean", "(", "accuracys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.load.DataSet.__init__": [[7, 48], ["tensorflow.as_dtype", "TypeError", "print", "images1.astype.astype.astype", "print", "images2.astype.astype.astype"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "images1", ",", "images2", ",", "labels", ",", "fake_data", "=", "False", ",", "one_hot", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", ":", "\n", "        ", "\"\"\"Construct a DataSet.\n        one_hot arg is used only if fake_data is true.  `dtype` can be either\n        `uint8` to leave the input as `[0, 255]`, or `float32` to rescale into\n        `[0, 1]`.\n        \"\"\"", "\n", "dtype", "=", "tf", ".", "as_dtype", "(", "dtype", ")", ".", "base_dtype", "\n", "if", "dtype", "not", "in", "(", "tf", ".", "uint8", ",", "tf", ".", "float32", ")", ":", "\n", "            ", "raise", "TypeError", "(", "'Invalid image dtype %r, expected uint8 or float32'", "%", "dtype", ")", "\n", "\n", "", "if", "fake_data", ":", "\n", "            ", "self", ".", "_num_examples", "=", "10000", "\n", "self", ".", "one_hot", "=", "one_hot", "\n", "", "else", ":", "\n", "            ", "assert", "images1", ".", "shape", "[", "0", "]", "==", "labels", ".", "shape", "[", "0", "]", ",", "(", "\n", "'images1.shape: %s labels.shape: %s'", "%", "(", "images1", ".", "shape", ",", "\n", "labels", ".", "shape", ")", ")", "\n", "assert", "images2", ".", "shape", "[", "0", "]", "==", "labels", ".", "shape", "[", "0", "]", ",", "(", "\n", "'images2.shape: %s labels.shape: %s'", "%", "(", "images2", ".", "shape", ",", "\n", "labels", ".", "shape", ")", ")", "\n", "self", ".", "_num_examples", "=", "images1", ".", "shape", "[", "0", "]", "\n", "# Convert shape from [num examples, rows, columns, depth]", "\n", "# to [num examples, rows*columns] (assuming depth == 1)", "\n", "#assert images.shape[3] == 1", "\n", "#images = images.reshape(images.shape[0],", "\n", "#                        images.shape[1] * images.shape[2])", "\n", "if", "dtype", "==", "tf", ".", "float32", "and", "images1", ".", "dtype", "!=", "np", ".", "float32", ":", "\n", "# Convert from [0, 255] -> [0.0, 1.0].", "\n", "                ", "print", "(", "\"type conversion view 1\"", ")", "\n", "images1", "=", "images1", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "if", "dtype", "==", "tf", ".", "float32", "and", "images2", ".", "dtype", "!=", "np", ".", "float32", ":", "\n", "                ", "print", "(", "\"type conversion view 2\"", ")", "\n", "images2", "=", "images2", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "", "self", ".", "_images1", "=", "images1", "\n", "self", ".", "_images2", "=", "images2", "\n", "self", ".", "_labels", "=", "labels", "\n", "self", ".", "_epochs_completed", "=", "0", "\n", "self", ".", "_index_in_epoch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.load.DataSet.images1": [[49, 52], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "images1", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_images1", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.load.DataSet.images2": [[53, 56], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "images2", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_images2", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.load.DataSet.labels": [[57, 60], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "labels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.load.DataSet.num_examples": [[61, 64], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_examples", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_examples", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.load.DataSet.epochs_completed": [[65, 68], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "epochs_completed", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_epochs_completed", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.load.DataSet.next_batch": [[69, 97], ["numpy.arange", "numpy.random.shuffle", "range", "range", "range"], "methods", ["None"], ["", "def", "next_batch", "(", "self", ",", "batch_size", ",", "fake_data", "=", "False", ")", ":", "\n", "        ", "\"\"\"Return the next `batch_size` examples from this data set.\"\"\"", "\n", "if", "fake_data", ":", "\n", "            ", "fake_image", "=", "[", "1", "]", "*", "784", "\n", "if", "self", ".", "one_hot", ":", "\n", "                ", "fake_label", "=", "[", "1", "]", "+", "[", "0", "]", "*", "9", "\n", "", "else", ":", "\n", "                ", "fake_label", "=", "0", "\n", "", "return", "[", "fake_image", "for", "_", "in", "range", "(", "batch_size", ")", "]", ",", "[", "fake_image", "for", "_", "in", "range", "(", "batch_size", ")", "]", ",", "[", "fake_label", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "", "start", "=", "self", ".", "_index_in_epoch", "\n", "self", ".", "_index_in_epoch", "+=", "batch_size", "\n", "if", "self", ".", "_index_in_epoch", ">", "self", ".", "_num_examples", ":", "\n", "# Finished epoch", "\n", "            ", "self", ".", "_epochs_completed", "+=", "1", "\n", "# Shuffle the data", "\n", "perm", "=", "np", ".", "arange", "(", "self", ".", "_num_examples", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "perm", ")", "\n", "self", ".", "_images1", "=", "self", ".", "_images1", "[", "perm", "]", "\n", "self", ".", "_images2", "=", "self", ".", "_images2", "[", "perm", "]", "\n", "self", ".", "_labels", "=", "self", ".", "_labels", "[", "perm", "]", "\n", "# Start next epoch", "\n", "start", "=", "0", "\n", "self", ".", "_index_in_epoch", "=", "batch_size", "\n", "assert", "batch_size", "<=", "self", ".", "_num_examples", "\n", "\n", "", "end", "=", "self", ".", "_index_in_epoch", "\n", "return", "self", ".", "_images1", "[", "start", ":", "end", "]", ",", "self", ".", "_images2", "[", "start", ":", "end", "]", ",", "self", ".", "_labels", "[", "start", ":", "end", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.load.feature_connect": [[99, 108], ["numpy.array", "range", "numpy.transpose", "int", "numpy.array", "range", "numpy.concatenate"], "function", ["None"], ["", "", "def", "feature_connect", "(", "a_time", ",", "a_force", ")", ":", "\n", "    ", "a", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "for", "j", "in", "range", "(", "int", "(", "11340", "/", "15", ")", ")", ":", "\n", "        ", "f", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "for", "i", "in", "range", "(", "15", ")", ":", "\n", "            ", "f", "=", "np", ".", "concatenate", "(", "(", "f", ",", "a_force", "[", "j", "*", "15", "+", "i", ",", ":", "]", ")", ",", "axis", "=", "0", ")", "if", "f", ".", "size", "else", "a_force", "[", "j", "*", "15", "+", "i", ",", ":", "]", "\n", "", "a", "=", "np", ".", "c_", "[", "a", ",", "f", "]", "if", "a", ".", "size", "else", "f", "\n", "#    np.savetxt('/home/zat/zresearch/lstm/lstm_test_improve/feature_extract/out256_15_force.txt', np.transpose(a),fmt='%.4f')", "\n", "", "return", "np", ".", "transpose", "(", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.load.read_timeforce": [[110, 126], ["numpy.loadtxt", "numpy.loadtxt", "numpy.loadtxt", "load.feature_connect", "load.DataSet", "load.DataSet", "load.DataSet"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.twochannels.feature_connect"], ["", "def", "read_timeforce", "(", ")", ":", "\n", "\n", "#    data=sio.loadmat('/home/zat/zresearch/lstm/lstm_test_improve/CCA/mnist_all.mat')", "\n", "    ", "X", "=", "np", ".", "loadtxt", "(", "'/home/zat/zresearch/lstm/lstm_test_improve/feature_extract/out256_time_10.txt'", ")", "\n", "Y", "=", "np", ".", "loadtxt", "(", "'/home/zat/zresearch/lstm/lstm_test_improve/feature_extract/out256_force_10.txt'", ")", "\n", "label", "=", "np", ".", "loadtxt", "(", "'/home/zat/zresearch/lstm/lstm_test_improve/feature_extract/fusionfeature_label.txt'", ")", "\n", "Y", "=", "feature_connect", "(", "X", ",", "Y", ")", "\n", "\n", "\n", "train", "=", "DataSet", "(", "X", ",", "Y", ",", "label", ")", "\n", "\n", "tune", "=", "DataSet", "(", "X", ",", "Y", ",", "label", ")", "\n", "\n", "test", "=", "DataSet", "(", "X", ",", "Y", ",", "label", ")", "\n", "\n", "return", "train", ",", "tune", ",", "test", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.load.read_xrmb": [[128, 139], ["scipy.loadmat", "load.DataSet", "load.DataSet", "load.DataSet"], "function", ["None"], ["", "def", "read_xrmb", "(", ")", ":", "\n", "\n", "    ", "data", "=", "sio", ".", "loadmat", "(", "'/share/data/speech-multiview/wwang5/cca/XRMBf2KALDI_window7_single.mat'", ")", "\n", "\n", "train", "=", "DataSet", "(", "data", "[", "'X1'", "]", ",", "data", "[", "'X2'", "]", ",", "data", "[", "'trainLabel'", "]", ")", "\n", "\n", "tune", "=", "DataSet", "(", "data", "[", "'XV1'", "]", ",", "data", "[", "'XV2'", "]", ",", "data", "[", "'tuneLabel'", "]", ")", "\n", "\n", "test", "=", "DataSet", "(", "data", "[", "'XTe1'", "]", ",", "data", "[", "'XTe2'", "]", ",", "data", "[", "'testLabel'", "]", ")", "\n", "\n", "return", "train", ",", "tune", ",", "test", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.load.read_flicker": [[141, 169], ["scipy.loadmat", "range", "load.DataSet", "load.DataSet", "load.DataSet", "scipy.loadmat", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.zeros", "numpy.zeros", "numpy.zeros", "len", "len", "len", "str"], "function", ["None"], ["", "def", "read_flicker", "(", ")", ":", "\n", "\n", "    ", "data", "=", "sio", ".", "loadmat", "(", "'/share/data/speech-multiview/wwang5/cca/VCCA/flicker/flicker_tensorflow_split1.mat'", ")", "\n", "X1", "=", "data", "[", "'X1'", "]", "\n", "X2", "=", "data", "[", "'X2'", "]", "\n", "XV1", "=", "data", "[", "'XV1'", "]", "\n", "XV2", "=", "data", "[", "'XV2'", "]", "\n", "XTe1", "=", "data", "[", "'XTe1'", "]", "\n", "XTe2", "=", "data", "[", "'XTe2'", "]", "\n", "\n", "for", "i", "in", "range", "(", "2", ",", "11", ")", ":", "\n", "\n", "        ", "data", "=", "sio", ".", "loadmat", "(", "'/share/data/speech-multiview/wwang5/cca/VCCA/flicker/flicker_tensorflow_split'", "+", "str", "(", "i", ")", "+", "'.mat'", ")", "\n", "\n", "X1", "=", "np", ".", "concatenate", "(", "[", "X1", ",", "data", "[", "'X1'", "]", "]", ")", "\n", "X2", "=", "np", ".", "concatenate", "(", "[", "X2", ",", "data", "[", "'X2'", "]", "]", ")", "\n", "XV1", "=", "np", ".", "concatenate", "(", "[", "XV1", ",", "data", "[", "'XV1'", "]", "]", ")", "\n", "XV2", "=", "np", ".", "concatenate", "(", "[", "XV2", ",", "data", "[", "'XV2'", "]", "]", ")", "\n", "XTe1", "=", "np", ".", "concatenate", "(", "[", "XTe1", ",", "data", "[", "'XTe1'", "]", "]", ")", "\n", "XTe2", "=", "np", ".", "concatenate", "(", "[", "XTe2", ",", "data", "[", "'XTe2'", "]", "]", ")", "\n", "\n", "", "train", "=", "DataSet", "(", "X1", ",", "X2", ",", "np", ".", "zeros", "(", "len", "(", "X1", ")", ")", ")", "\n", "\n", "tune", "=", "DataSet", "(", "XV1", ",", "XV2", ",", "np", ".", "zeros", "(", "len", "(", "XV1", ")", ")", ")", "\n", "\n", "test", "=", "DataSet", "(", "XTe1", ",", "XTe2", ",", "np", ".", "zeros", "(", "len", "(", "XTe1", ")", ")", ")", "\n", "\n", "return", "train", ",", "tune", ",", "test", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.multi_feature_ex.test_with_gaussian_samples_image": [[12, 21], ["numpy.array", "test_data.reshape.reshape", "print", "fishervector.FisherVectorGMM().fit", "len", "FisherVectorGMM().fit.predict", "print", "fishervector.FisherVectorGMM"], "function", ["None"], ["def", "test_with_gaussian_samples_image", "(", "data", ",", "n_kernels", ")", ":", "\n", "    ", "test_data", "=", "np", ".", "array", "(", "data", ")", "\n", "test_data", "=", "test_data", ".", "reshape", "(", "[", "test_data", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "1", "]", ")", "\n", "print", "(", "test_data", ".", "shape", ")", "\n", "fv_gmm", "=", "FisherVectorGMM", "(", "n_kernels", "=", "n_kernels", ")", ".", "fit", "(", "test_data", ")", "\n", "n_test_videos", "=", "len", "(", "data", ")", "\n", "fv", "=", "fv_gmm", ".", "predict", "(", "test_data", "[", ":", "n_test_videos", "]", ")", "\n", "print", "(", "fv", ".", "shape", ")", "\n", "return", "fv", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.multi_feature_ex.FFT": [[24, 29], ["numpy.fft.fft"], "function", ["None"], ["", "def", "FFT", "(", "a", ")", ":", "\n", "    ", "transy", "=", "np", ".", "fft", ".", "fft", "(", "a", ")", "\n", "#    plt.subplot(311),plt.plot(a),plt.title(\"Original\")  ", "\n", "#    plt.subplot(312),plt.plot(transy),plt.title(\"FFT\")  ", "\n", "return", "transy", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.multi_feature_ex.psfeatureTime": [[31, 57], ["data[].mean", "data[].var", "data[].std", "math.sqrt", "numpy.mean", "range", "numpy.mean", "pow", "math.sqrt", "abs().mean", "max", "max", "abs().mean", "max", "pow", "pow", "pow", "abs", "abs", "abs"], "function", ["None"], ["", "def", "psfeatureTime", "(", "data", ",", "p1", ",", "p2", ")", ":", "\n", "#\u5747\u503c", "\n", "    ", "df_mean", "=", "data", "[", "p1", ":", "p2", "]", ".", "mean", "(", ")", "\n", "#\u65b9\u5dee", "\n", "df_var", "=", "data", "[", "p1", ":", "p2", "]", ".", "var", "(", ")", "\n", "#\u6807\u51c6\u5dee", "\n", "df_std", "=", "data", "[", "p1", ":", "p2", "]", ".", "std", "(", ")", "\n", "#\u5747\u65b9\u6839", "\n", "df_rms", "=", "math", ".", "sqrt", "(", "pow", "(", "df_mean", ",", "2", ")", "+", "pow", "(", "df_std", ",", "2", ")", ")", "\n", "#\u504f\u5ea6", "\n", "df_skew", "=", "np", ".", "mean", "(", "(", "data", "[", "p1", ":", "p2", "]", "-", "df_mean", ")", "**", "3", ")", "\n", "#\u5ced\u5ea6", "\n", "df_kurt", "=", "np", ".", "mean", "(", "(", "data", "[", "p1", ":", "p2", "]", "-", "df_mean", ")", "**", "4", ")", "/", "pow", "(", "df_var", ",", "2", ")", "\n", "sum", "=", "0", "\n", "for", "i", "in", "range", "(", "p1", ",", "p2", ")", ":", "\n", "        ", "sum", "+=", "math", ".", "sqrt", "(", "abs", "(", "data", "[", "i", "]", ")", ")", "\n", "#\u6ce2\u5f62\u56e0\u5b50", "\n", "", "df_boxing", "=", "df_rms", "/", "(", "abs", "(", "data", "[", "p1", ":", "p2", "]", ")", ".", "mean", "(", ")", ")", "\n", "#\u5cf0\u503c\u56e0\u5b50", "\n", "df_fengzhi", "=", "(", "max", "(", "data", "[", "p1", ":", "p2", "]", ")", ")", "/", "df_rms", "\n", "#\u8109\u51b2\u56e0\u5b50", "\n", "df_maichong", "=", "(", "max", "(", "data", "[", "p1", ":", "p2", "]", ")", ")", "/", "(", "abs", "(", "data", "[", "p1", ":", "p2", "]", ")", ".", "mean", "(", ")", ")", "\n", "#\u88d5\u5ea6\u56e0\u5b50", "\n", "df_yudu", "=", "(", "max", "(", "data", "[", "p1", ":", "p2", "]", ")", ")", "/", "pow", "(", "(", "sum", "/", "(", "p2", "-", "p1", ")", ")", ",", "2", ")", "\n", "featuretime_list", "=", "[", "df_mean", ",", "df_rms", ",", "df_skew", ",", "df_kurt", ",", "df_boxing", ",", "df_fengzhi", ",", "df_maichong", ",", "df_yudu", "]", "\n", "return", "featuretime_list", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.RNNCell.__call__": [[112, 130], ["NotImplementedError"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Run this RNN cell on inputs, starting from the given state.\n\n    Args:\n      inputs: `2-D` tensor with shape `[batch_size x input_size]`.\n      state: if `self.state_size` is an integer, this should be a `2-D Tensor`\n        with shape `[batch_size x self.state_size]`.  Otherwise, if\n        `self.state_size` is a tuple of integers, this should be a tuple\n        with shapes `[batch_size x s] for s in self.state_size`.\n      scope: VariableScope for the created subgraph; defaults to class name.\n\n    Returns:\n      A pair containing:\n      - Output: A `2-D` tensor with shape `[batch_size x self.output_size]`.\n      - New state: Either a single `2-D` tensor, or a tuple of tensors matching\n        the arity and shapes of `state`.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", "\"Abstract method\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.RNNCell.state_size": [[131, 139], ["NotImplementedError"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "    ", "\"\"\"size(s) of state(s) used by this cell.\n\n    It can be represented by an Integer, a TensorShape or a tuple of Integers\n    or TensorShapes.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", "\"Abstract method\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.RNNCell.output_size": [[140, 144], ["NotImplementedError"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "    ", "\"\"\"Integer or TensorShape: size of outputs produced by this cell.\"\"\"", "\n", "raise", "NotImplementedError", "(", "\"Abstract method\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.RNNCell.zero_state": [[145, 178], ["tensorflow.python.util.nest.is_sequence", "tensorflow.python.util.nest.flatten", "zip", "tensorflow.python.util.nest.pack_sequence_as", "rnn_cell_GRU._state_size_with_prefix", "tensorflow.python.ops.array_ops.zeros", "tensorflow.python.ops.array_ops.zeros.set_shape", "tensorflow.python.ops.array_ops.zeros", "z.set_shape", "tensorflow.python.ops.array_ops.pack", "rnn_cell_GRU._state_size_with_prefix", "tensorflow.python.ops.array_ops.pack", "rnn_cell_GRU._state_size_with_prefix", "rnn_cell_GRU._state_size_with_prefix"], "methods", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._state_size_with_prefix", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._state_size_with_prefix", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._state_size_with_prefix", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._state_size_with_prefix"], ["", "def", "zero_state", "(", "self", ",", "batch_size", ",", "dtype", ")", ":", "\n", "    ", "\"\"\"Return zero-filled state tensor(s).\n\n    Args:\n      batch_size: int, float, or unit Tensor representing the batch size.\n      dtype: the data type to use for the state.\n\n    Returns:\n      If `state_size` is an int or TensorShape, then the return value is a\n      `N-D` tensor of shape `[batch_size x state_size]` filled with zeros.\n\n      If `state_size` is a nested list or tuple, then the return value is\n      a nested list or tuple (of the same structure) of `2-D` tensors with\n    the shapes `[batch_size x s]` for each s in `state_size`.\n    \"\"\"", "\n", "state_size", "=", "self", ".", "state_size", "\n", "if", "nest", ".", "is_sequence", "(", "state_size", ")", ":", "\n", "      ", "state_size_flat", "=", "nest", ".", "flatten", "(", "state_size", ")", "\n", "zeros_flat", "=", "[", "\n", "array_ops", ".", "zeros", "(", "\n", "array_ops", ".", "pack", "(", "_state_size_with_prefix", "(", "s", ",", "prefix", "=", "[", "batch_size", "]", ")", ")", ",", "\n", "dtype", "=", "dtype", ")", "\n", "for", "s", "in", "state_size_flat", "]", "\n", "for", "s", ",", "z", "in", "zip", "(", "state_size_flat", ",", "zeros_flat", ")", ":", "\n", "        ", "z", ".", "set_shape", "(", "_state_size_with_prefix", "(", "s", ",", "prefix", "=", "[", "None", "]", ")", ")", "\n", "", "zeros", "=", "nest", ".", "pack_sequence_as", "(", "structure", "=", "state_size", ",", "\n", "flat_sequence", "=", "zeros_flat", ")", "\n", "", "else", ":", "\n", "      ", "zeros_size", "=", "_state_size_with_prefix", "(", "state_size", ",", "prefix", "=", "[", "batch_size", "]", ")", "\n", "zeros", "=", "array_ops", ".", "zeros", "(", "array_ops", ".", "pack", "(", "zeros_size", ")", ",", "dtype", "=", "dtype", ")", "\n", "zeros", ".", "set_shape", "(", "_state_size_with_prefix", "(", "state_size", ",", "prefix", "=", "[", "None", "]", ")", ")", "\n", "\n", "", "return", "zeros", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.BasicRNNCell.__init__": [[183, 188], ["tensorflow.python.platform.tf_logging.warn"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_units", ",", "input_size", "=", "None", ",", "activation", "=", "tanh", ")", ":", "\n", "    ", "if", "input_size", "is", "not", "None", ":", "\n", "      ", "logging", ".", "warn", "(", "\"%s: The input_size parameter is deprecated.\"", ",", "self", ")", "\n", "", "self", ".", "_num_units", "=", "num_units", "\n", "self", ".", "_activation", "=", "activation", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.BasicRNNCell.state_size": [[189, 192], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.BasicRNNCell.output_size": [[193, 196], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.BasicRNNCell.__call__": [[197, 202], ["tensorflow.python.ops.variable_scope.variable_scope", "rnn_cell_GRU.BasicRNNCell._activation", "rnn_cell_GRU._linear", "type"], "methods", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._linear"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Most basic RNN: output = new_state = activation(W * input + U * state + B).\"\"\"", "\n", "with", "vs", ".", "variable_scope", "(", "scope", "or", "type", "(", "self", ")", ".", "__name__", ")", ":", "# \"BasicRNNCell\"", "\n", "      ", "output", "=", "self", ".", "_activation", "(", "_linear", "(", "[", "inputs", ",", "state", "]", ",", "self", ".", "_num_units", ",", "True", ")", ")", "\n", "", "return", "output", ",", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.GRUCell.__init__": [[207, 212], ["tensorflow.python.platform.tf_logging.warn"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_units", ",", "input_size", "=", "None", ",", "activation", "=", "tanh", ")", ":", "\n", "    ", "if", "input_size", "is", "not", "None", ":", "\n", "      ", "logging", ".", "warn", "(", "\"%s: The input_size parameter is deprecated.\"", ",", "self", ")", "\n", "", "self", ".", "_num_units", "=", "num_units", "\n", "self", ".", "_activation", "=", "activation", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.GRUCell.state_size": [[213, 216], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.GRUCell.output_size": [[217, 220], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.GRUCell.__call__": [[223, 248], ["tensorflow.python.ops.variable_scope.variable_scope", "rnn_cell_GRU.GRUCell._activation", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.ops.array_ops.split", "tensorflow.python.ops.variable_scope.variable_scope", "rnn_cell_GRU.GRUCell._activation", "rnn_cell_GRU._linear", "tensorflow.python.ops.math_ops.sigmoid", "tensorflow.python.ops.math_ops.sigmoid", "tensorflow.python.ops.math_ops.sigmoid", "rnn_cell_GRU._linear", "type", "rnn_cell_GRU._linear"], "methods", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._linear", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._linear", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._linear"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Gated recurrent unit (GRU) with nunits cells.\"\"\"", "\n", "with", "vs", ".", "variable_scope", "(", "scope", "or", "type", "(", "self", ")", ".", "__name__", ")", ":", "# \"GRUCell\"", "\n", "      ", "with", "vs", ".", "variable_scope", "(", "\"Gates\"", ")", ":", "# Reset gate and update gate.", "\n", "# We start with bias of 1.0 to not reset and not update. _linear(2d tensor,output) output: batch*hidden", "\n", "#        r, u = array_ops.split(1, 2, _linear([inputs, state],2 * self._num_units, True, 1.0))", "\n", "        ", "r", ",", "u", "=", "array_ops", ".", "split", "(", "value", "=", "_linear", "(", "[", "inputs", ",", "state", "]", ",", "2", "*", "self", ".", "_num_units", ",", "True", ",", "1.0", ")", ",", "num_or_size_splits", "=", "2", ",", "axis", "=", "1", ")", "\n", "r", ",", "u", "=", "sigmoid", "(", "r", ")", ",", "sigmoid", "(", "u", ")", "\n", "", "with", "vs", ".", "variable_scope", "(", "\"Candidate\"", ")", ":", "\n", "        ", "c", "=", "self", ".", "_activation", "(", "_linear", "(", "[", "inputs", ",", "r", "*", "state", "]", ",", "self", ".", "_num_units", ",", "True", ")", ")", "\n", "\n", "#basicoutput=BasicLSTMCell(20, forget_bias=1)", "\n", "", "ctempoutput", "=", "self", ".", "_activation", "(", "_linear", "(", "[", "inputs", ",", "state", "]", ",", "self", ".", "_num_units", ",", "True", ")", ")", "\n", "new_h", "=", "(", "u", "*", "state", "+", "(", "1", "-", "u", ")", "*", "c", ")", "*", "sigmoid", "(", "ctempoutput", ")", "\n", "#      new_h =  u * c + (1 - u) * state", "\n", "\n", "\n", "'''\n      basiclstm\n      ht = self._activation(array_ops.split(1, 1, _linear([inputs, state * sigmoid(u)], self._num_units, True)))\n      new_h = (1-sigmoid(r))* state + sigmoid(r)*ht\n      new_state = LSTMStateTuple(new_h)\n      '''", "\n", "\n", "return", "new_h", ",", "new_h", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.LSTMStateTuple.dtype": [[262, 269], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "dtype", "(", "self", ")", ":", "\n", "    ", "(", "h", ")", "=", "self", "\n", "#   if not c.dtype == h.dtype:", "\n", "#     raise TypeError(\"Inconsistent internal state: %s vs %s\" %", "\n", "#                     (str(c.dtype), str(h.dtype)))", "\n", "return", "h", ".", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.BasicLSTMCell.__init__": [[285, 307], ["tensorflow.python.platform.tf_logging.warn", "tensorflow.python.platform.tf_logging.warn"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_units", ",", "forget_bias", "=", "1.0", ",", "input_size", "=", "None", ",", "\n", "state_is_tuple", "=", "True", ",", "activation", "=", "tanh", ")", ":", "\n", "    ", "\"\"\"Initialize the basic LSTM cell.\n\n    Args:\n      num_units: int, The number of units in the LSTM cell.\n      forget_bias: float, The bias added to forget gates (see above).\n      input_size: Deprecated and unused.\n      state_is_tuple: If True, accepted and returned states are 2-tuples of\n        the `c_state` and `m_state`.  By default (False), they are concatenated\n        along the column axis.  This default behavior will soon be deprecated.\n      activation: Activation function of the inner states.\n    \"\"\"", "\n", "if", "not", "state_is_tuple", ":", "\n", "      ", "logging", ".", "warn", "(", "\"%s: Using a concatenated state is slower and will soon be \"", "\n", "\"deprecated.  Use state_is_tuple=True.\"", ",", "self", ")", "\n", "", "if", "input_size", "is", "not", "None", ":", "\n", "      ", "logging", ".", "warn", "(", "\"%s: The input_size parameter is deprecated.\"", ",", "self", ")", "\n", "", "self", ".", "_num_units", "=", "num_units", "\n", "self", ".", "_forget_bias", "=", "forget_bias", "\n", "self", ".", "_state_is_tuple", "=", "state_is_tuple", "\n", "self", ".", "_activation", "=", "activation", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.BasicLSTMCell.state_size": [[308, 312], ["rnn_cell_GRU.LSTMStateTuple"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "    ", "return", "(", "LSTMStateTuple", "(", "self", ".", "_num_units", ")", "\n", "if", "self", ".", "_state_is_tuple", "else", "self", ".", "_num_units", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.BasicLSTMCell.output_size": [[313, 316], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.BasicLSTMCell.__call__": [[317, 336], ["tensorflow.python.ops.variable_scope.variable_scope", "rnn_cell_GRU._linear", "tensorflow.python.ops.array_ops.split", "rnn_cell_GRU._linear", "rnn_cell_GRU.BasicLSTMCell._activation", "tensorflow.python.ops.array_ops.split", "tensorflow.python.ops.array_ops.split", "rnn_cell_GRU.LSTMStateTuple", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.math_ops.sigmoid", "type", "tensorflow.python.ops.math_ops.sigmoid", "tensorflow.python.ops.math_ops.sigmoid"], "methods", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._linear", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._linear"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Long short-term memory cell (LSTM).\"\"\"", "\n", "with", "vs", ".", "variable_scope", "(", "scope", "or", "type", "(", "self", ")", ".", "__name__", ")", ":", "# \"BasicLSTMCell\"", "\n", "# Parameters of gates are concatenated into one multiply for efficiency.", "\n", "      ", "if", "self", ".", "_state_is_tuple", ":", "\n", "        ", "h", "=", "state", "\n", "", "else", ":", "\n", "        ", "h", "=", "array_ops", ".", "split", "(", "1", ",", "1", ",", "state", ")", "\n", "", "concat", "=", "_linear", "(", "[", "inputs", ",", "h", "]", ",", "2", "*", "self", ".", "_num_units", ",", "True", ")", "\n", "z", ",", "r", "=", "array_ops", ".", "split", "(", "1", ",", "2", ",", "concat", ")", "\n", "concat", "=", "_linear", "(", "[", "inputs", ",", "h", "*", "sigmoid", "(", "r", ")", "]", ",", "self", ".", "_num_units", ",", "True", ")", "\n", "ht", "=", "self", ".", "_activation", "(", "array_ops", ".", "split", "(", "1", ",", "1", ",", "concat", ")", ")", "\n", "new_h", "=", "(", "1", "-", "sigmoid", "(", "z", ")", ")", "*", "h", "+", "sigmoid", "(", "z", ")", "*", "ht", "\n", "\n", "if", "self", ".", "_state_is_tuple", ":", "\n", "        ", "new_state", "=", "LSTMStateTuple", "(", "new_h", ")", "\n", "", "else", ":", "\n", "        ", "new_state", "=", "array_ops", ".", "concat", "(", "1", ",", "[", "new_h", "]", ")", "\n", "", "return", "new_h", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.LSTMCell.__init__": [[396, 456], ["tensorflow.python.platform.tf_logging.warn", "tensorflow.python.platform.tf_logging.warn", "rnn_cell_GRU.LSTMStateTuple", "rnn_cell_GRU.LSTMStateTuple"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_units", ",", "input_size", "=", "None", ",", "\n", "use_peepholes", "=", "False", ",", "cell_clip", "=", "None", ",", "\n", "initializer", "=", "None", ",", "num_proj", "=", "None", ",", "proj_clip", "=", "None", ",", "\n", "num_unit_shards", "=", "1", ",", "num_proj_shards", "=", "1", ",", "\n", "forget_bias", "=", "1.0", ",", "state_is_tuple", "=", "False", ",", "\n", "activation", "=", "tanh", ")", ":", "\n", "    ", "\"\"\"Initialize the parameters for an LSTM cell.\n\n    Args:\n      num_units: int, The number of units in the LSTM cell\n      input_size: Deprecated and unused.\n      use_peepholes: bool, set True to enable diagonal/peephole connections.\n      cell_clip: (optional) A float value, if provided the cell state is clipped\n        by this value prior to the cell output activation.\n      initializer: (optional) The initializer to use for the weight and\n        projection matrices.\n      num_proj: (optional) int, The output dimensionality for the projection\n        matrices.  If None, no projection is performed.\n      proj_clip: (optional) A float value.  If `num_proj > 0` and `proj_clip` is\n      provided, then the projected values are clipped elementwise to within\n      `[-proj_clip, proj_clip]`.\n      num_unit_shards: How to split the weight matrix.  If >1, the weight\n        matrix is stored across num_unit_shards.\n      num_proj_shards: How to split the projection matrix.  If >1, the\n        projection matrix is stored across num_proj_shards.\n      forget_bias: Biases of the forget gate are initialized by default to 1\n        in order to reduce the scale of forgetting at the beginning of\n        the training.\n      state_is_tuple: If True, accepted and returned states are 2-tuples of\n        the `c_state` and `m_state`.  By default (False), they are concatenated\n        along the column axis.  This default behavior will soon be deprecated.\n      activation: Activation function of the inner states.\n    \"\"\"", "\n", "if", "not", "state_is_tuple", ":", "\n", "      ", "logging", ".", "warn", "(", "\"%s: Using a concatenated state is slower and will soon be \"", "\n", "\"deprecated.  Use state_is_tuple=True.\"", ",", "self", ")", "\n", "", "if", "input_size", "is", "not", "None", ":", "\n", "      ", "logging", ".", "warn", "(", "\"%s: The input_size parameter is deprecated.\"", ",", "self", ")", "\n", "", "self", ".", "_num_units", "=", "num_units", "\n", "self", ".", "_use_peepholes", "=", "use_peepholes", "\n", "self", ".", "_cell_clip", "=", "cell_clip", "\n", "self", ".", "_initializer", "=", "initializer", "\n", "self", ".", "_num_proj", "=", "num_proj", "\n", "self", ".", "_proj_clip", "=", "proj_clip", "\n", "self", ".", "_num_unit_shards", "=", "num_unit_shards", "\n", "self", ".", "_num_proj_shards", "=", "num_proj_shards", "\n", "self", ".", "_forget_bias", "=", "forget_bias", "\n", "self", ".", "_state_is_tuple", "=", "state_is_tuple", "\n", "self", ".", "_activation", "=", "activation", "\n", "\n", "if", "num_proj", ":", "\n", "      ", "self", ".", "_state_size", "=", "(", "\n", "LSTMStateTuple", "(", "num_units", ",", "num_proj", ")", "\n", "if", "state_is_tuple", "else", "num_units", "+", "num_proj", ")", "\n", "self", ".", "_output_size", "=", "num_proj", "\n", "", "else", ":", "\n", "      ", "self", ".", "_state_size", "=", "(", "\n", "LSTMStateTuple", "(", "num_units", ",", "num_units", ")", "\n", "if", "state_is_tuple", "else", "2", "*", "num_units", ")", "\n", "self", ".", "_output_size", "=", "num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.LSTMCell.state_size": [[457, 460], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.LSTMCell.output_size": [[461, 464], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.LSTMCell.__call__": [[465, 557], ["tensorflow.python.ops.array_ops.slice", "tensorflow.python.ops.array_ops.slice", "inputs.get_shape().with_rank", "ValueError", "tensorflow.python.ops.variable_scope.variable_scope", "rnn_cell_GRU._get_concat_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.nn_ops.bias_add", "tensorflow.python.ops.array_ops.split", "rnn_cell_GRU.LSTMStateTuple", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.clip_ops.clip_by_value", "rnn_cell_GRU._get_concat_variable", "tensorflow.python.ops.math_ops.matmul", "inputs.get_shape", "tensorflow.python.ops.math_ops.sigmoid", "rnn_cell_GRU.LSTMCell._activation", "tensorflow.python.ops.math_ops.sigmoid", "rnn_cell_GRU.LSTMCell._activation", "tensorflow.python.ops.clip_ops.clip_by_value", "type", "tensorflow.python.ops.math_ops.sigmoid", "tensorflow.python.ops.math_ops.sigmoid", "rnn_cell_GRU.LSTMCell._activation", "tensorflow.python.ops.math_ops.sigmoid", "tensorflow.python.ops.math_ops.sigmoid", "rnn_cell_GRU.LSTMCell._activation"], "methods", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._get_concat_variable", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._get_concat_variable"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Run one step of LSTM.\n\n    Args:\n      inputs: input Tensor, 2D, batch x num_units.\n      state: if `state_is_tuple` is False, this must be a state Tensor,\n        `2-D, batch x state_size`.  If `state_is_tuple` is True, this must be a\n        tuple of state Tensors, both `2-D`, with column sizes `c_state` and\n        `m_state`.\n      scope: VariableScope for the created subgraph; defaults to \"LSTMCell\".\n\n    Returns:\n      A tuple containing:\n      - A `2-D, [batch x output_dim]`, Tensor representing the output of the\n        LSTM after reading `inputs` when previous state was `state`.\n        Here output_dim is:\n           num_proj if num_proj was set,\n           num_units otherwise.\n      - Tensor(s) representing the new state of LSTM after reading `inputs` when\n        the previous state was `state`.  Same type and shape(s) as `state`.\n\n    Raises:\n      ValueError: If input size cannot be inferred from inputs via\n        static shape inference.\n    \"\"\"", "\n", "num_proj", "=", "self", ".", "_num_units", "if", "self", ".", "_num_proj", "is", "None", "else", "self", ".", "_num_proj", "\n", "\n", "if", "self", ".", "_state_is_tuple", ":", "\n", "      ", "(", "c_prev", ",", "m_prev", ")", "=", "state", "\n", "", "else", ":", "\n", "      ", "c_prev", "=", "array_ops", ".", "slice", "(", "state", ",", "[", "0", ",", "0", "]", ",", "[", "-", "1", ",", "self", ".", "_num_units", "]", ")", "\n", "m_prev", "=", "array_ops", ".", "slice", "(", "state", ",", "[", "0", ",", "self", ".", "_num_units", "]", ",", "[", "-", "1", ",", "num_proj", "]", ")", "\n", "\n", "", "dtype", "=", "inputs", ".", "dtype", "\n", "input_size", "=", "inputs", ".", "get_shape", "(", ")", ".", "with_rank", "(", "2", ")", "[", "1", "]", "\n", "if", "input_size", ".", "value", "is", "None", ":", "\n", "      ", "raise", "ValueError", "(", "\"Could not infer input size from inputs.get_shape()[-1]\"", ")", "\n", "", "with", "vs", ".", "variable_scope", "(", "scope", "or", "type", "(", "self", ")", ".", "__name__", ",", "\n", "initializer", "=", "self", ".", "_initializer", ")", ":", "# \"LSTMCell\"", "\n", "      ", "concat_w", "=", "_get_concat_variable", "(", "\n", "\"W\"", ",", "[", "input_size", ".", "value", "+", "num_proj", ",", "4", "*", "self", ".", "_num_units", "]", ",", "\n", "dtype", ",", "self", ".", "_num_unit_shards", ")", "\n", "\n", "b", "=", "vs", ".", "get_variable", "(", "\n", "\"B\"", ",", "shape", "=", "[", "4", "*", "self", ".", "_num_units", "]", ",", "\n", "initializer", "=", "array_ops", ".", "zeros_initializer", ",", "dtype", "=", "dtype", ")", "\n", "\n", "# i = input_gate, j = new_input, f = forget_gate, o = output_gate", "\n", "cell_inputs", "=", "array_ops", ".", "concat", "(", "1", ",", "[", "inputs", ",", "m_prev", "]", ")", "\n", "lstm_matrix", "=", "nn_ops", ".", "bias_add", "(", "math_ops", ".", "matmul", "(", "cell_inputs", ",", "concat_w", ")", ",", "b", ")", "\n", "i", ",", "j", ",", "f", ",", "o", "=", "array_ops", ".", "split", "(", "1", ",", "4", ",", "lstm_matrix", ")", "\n", "\n", "# Diagonal connections", "\n", "if", "self", ".", "_use_peepholes", ":", "\n", "        ", "w_f_diag", "=", "vs", ".", "get_variable", "(", "\n", "\"W_F_diag\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", ")", "\n", "w_i_diag", "=", "vs", ".", "get_variable", "(", "\n", "\"W_I_diag\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", ")", "\n", "w_o_diag", "=", "vs", ".", "get_variable", "(", "\n", "\"W_O_diag\"", ",", "shape", "=", "[", "self", ".", "_num_units", "]", ",", "dtype", "=", "dtype", ")", "\n", "\n", "", "if", "self", ".", "_use_peepholes", ":", "\n", "        ", "c", "=", "(", "sigmoid", "(", "f", "+", "self", ".", "_forget_bias", "+", "w_f_diag", "*", "c_prev", ")", "*", "c_prev", "+", "\n", "sigmoid", "(", "i", "+", "w_i_diag", "*", "c_prev", ")", "*", "self", ".", "_activation", "(", "j", ")", ")", "\n", "", "else", ":", "\n", "        ", "c", "=", "(", "sigmoid", "(", "f", "+", "self", ".", "_forget_bias", ")", "*", "c_prev", "+", "sigmoid", "(", "i", ")", "*", "\n", "self", ".", "_activation", "(", "j", ")", ")", "\n", "\n", "", "if", "self", ".", "_cell_clip", "is", "not", "None", ":", "\n", "# pylint: disable=invalid-unary-operand-type", "\n", "        ", "c", "=", "clip_ops", ".", "clip_by_value", "(", "c", ",", "-", "self", ".", "_cell_clip", ",", "self", ".", "_cell_clip", ")", "\n", "# pylint: enable=invalid-unary-operand-type", "\n", "\n", "", "if", "self", ".", "_use_peepholes", ":", "\n", "        ", "m", "=", "sigmoid", "(", "o", "+", "w_o_diag", "*", "c", ")", "*", "self", ".", "_activation", "(", "c", ")", "\n", "", "else", ":", "\n", "        ", "m", "=", "sigmoid", "(", "o", ")", "*", "self", ".", "_activation", "(", "c", ")", "\n", "\n", "", "if", "self", ".", "_num_proj", "is", "not", "None", ":", "\n", "        ", "concat_w_proj", "=", "_get_concat_variable", "(", "\n", "\"W_P\"", ",", "[", "self", ".", "_num_units", ",", "self", ".", "_num_proj", "]", ",", "\n", "dtype", ",", "self", ".", "_num_proj_shards", ")", "\n", "\n", "m", "=", "math_ops", ".", "matmul", "(", "m", ",", "concat_w_proj", ")", "\n", "if", "self", ".", "_proj_clip", "is", "not", "None", ":", "\n", "# pylint: disable=invalid-unary-operand-type", "\n", "          ", "m", "=", "clip_ops", ".", "clip_by_value", "(", "m", ",", "-", "self", ".", "_proj_clip", ",", "self", ".", "_proj_clip", ")", "\n", "# pylint: enable=invalid-unary-operand-type", "\n", "\n", "", "", "", "new_state", "=", "(", "LSTMStateTuple", "(", "c", ",", "m", ")", "if", "self", ".", "_state_is_tuple", "\n", "else", "array_ops", ".", "concat", "(", "1", ",", "[", "c", ",", "m", "]", ")", ")", "\n", "return", "m", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.OutputProjectionWrapper.__init__": [[568, 585], ["isinstance", "TypeError", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cell", ",", "output_size", ")", ":", "\n", "    ", "\"\"\"Create a cell with output projection.\n\n    Args:\n      cell: an RNNCell, a projection to output_size is added to it.\n      output_size: integer, the size of the output after projection.\n\n    Raises:\n      TypeError: if cell is not an RNNCell.\n      ValueError: if output_size is not positive.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "cell", ",", "RNNCell", ")", ":", "\n", "      ", "raise", "TypeError", "(", "\"The parameter cell is not RNNCell.\"", ")", "\n", "", "if", "output_size", "<", "1", ":", "\n", "      ", "raise", "ValueError", "(", "\"Parameter output_size must be > 0: %d.\"", "%", "output_size", ")", "\n", "", "self", ".", "_cell", "=", "cell", "\n", "self", ".", "_output_size", "=", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.OutputProjectionWrapper.state_size": [[586, 589], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_cell", ".", "state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.OutputProjectionWrapper.output_size": [[590, 593], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.OutputProjectionWrapper.__call__": [[594, 601], ["rnn_cell_GRU.OutputProjectionWrapper._cell", "tensorflow.python.ops.variable_scope.variable_scope", "rnn_cell_GRU._linear", "type"], "methods", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._linear"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Run the cell and output projection on inputs, starting from state.\"\"\"", "\n", "output", ",", "res_state", "=", "self", ".", "_cell", "(", "inputs", ",", "state", ")", "\n", "# Default scope: \"OutputProjectionWrapper\"", "\n", "with", "vs", ".", "variable_scope", "(", "scope", "or", "type", "(", "self", ")", ".", "__name__", ")", ":", "\n", "      ", "projected", "=", "_linear", "(", "output", ",", "self", ".", "_output_size", ",", "True", ")", "\n", "", "return", "projected", ",", "res_state", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.InputProjectionWrapper.__init__": [[611, 628], ["tensorflow.python.platform.tf_logging.warn", "isinstance", "TypeError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cell", ",", "num_proj", ",", "input_size", "=", "None", ")", ":", "\n", "    ", "\"\"\"Create a cell with input projection.\n\n    Args:\n      cell: an RNNCell, a projection of inputs is added before it.\n      num_proj: Python integer.  The dimension to project to.\n      input_size: Deprecated and unused.\n\n    Raises:\n      TypeError: if cell is not an RNNCell.\n    \"\"\"", "\n", "if", "input_size", "is", "not", "None", ":", "\n", "      ", "logging", ".", "warn", "(", "\"%s: The input_size parameter is deprecated.\"", ",", "self", ")", "\n", "", "if", "not", "isinstance", "(", "cell", ",", "RNNCell", ")", ":", "\n", "      ", "raise", "TypeError", "(", "\"The parameter cell is not RNNCell.\"", ")", "\n", "", "self", ".", "_cell", "=", "cell", "\n", "self", ".", "_num_proj", "=", "num_proj", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.InputProjectionWrapper.state_size": [[629, 632], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_cell", ".", "state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.InputProjectionWrapper.output_size": [[633, 636], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_cell", ".", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.InputProjectionWrapper.__call__": [[637, 643], ["rnn_cell_GRU.InputProjectionWrapper._cell", "tensorflow.python.ops.variable_scope.variable_scope", "rnn_cell_GRU._linear", "type"], "methods", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._linear"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Run the input projection and then the cell.\"\"\"", "\n", "# Default scope: \"InputProjectionWrapper\"", "\n", "with", "vs", ".", "variable_scope", "(", "scope", "or", "type", "(", "self", ")", ".", "__name__", ")", ":", "\n", "      ", "projected", "=", "_linear", "(", "inputs", ",", "self", ".", "_num_proj", ",", "True", ")", "\n", "", "return", "self", ".", "_cell", "(", "projected", ",", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.DropoutWrapper.__init__": [[648, 680], ["isinstance", "TypeError", "isinstance", "ValueError", "isinstance", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cell", ",", "input_keep_prob", "=", "1.0", ",", "output_keep_prob", "=", "1.0", ",", "\n", "seed", "=", "None", ")", ":", "\n", "    ", "\"\"\"Create a cell with added input and/or output dropout.\n\n    Dropout is never used on the state.\n\n    Args:\n      cell: an RNNCell, a projection to output_size is added to it.\n      input_keep_prob: unit Tensor or float between 0 and 1, input keep\n        probability; if it is float and 1, no input dropout will be added.\n      output_keep_prob: unit Tensor or float between 0 and 1, output keep\n        probability; if it is float and 1, no output dropout will be added.\n      seed: (optional) integer, the randomness seed.\n\n    Raises:\n      TypeError: if cell is not an RNNCell.\n      ValueError: if keep_prob is not between 0 and 1.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "cell", ",", "RNNCell", ")", ":", "\n", "      ", "raise", "TypeError", "(", "\"The parameter cell is not a RNNCell.\"", ")", "\n", "", "if", "(", "isinstance", "(", "input_keep_prob", ",", "float", ")", "and", "\n", "not", "(", "input_keep_prob", ">=", "0.0", "and", "input_keep_prob", "<=", "1.0", ")", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"Parameter input_keep_prob must be between 0 and 1: %d\"", "\n", "%", "input_keep_prob", ")", "\n", "", "if", "(", "isinstance", "(", "output_keep_prob", ",", "float", ")", "and", "\n", "not", "(", "output_keep_prob", ">=", "0.0", "and", "output_keep_prob", "<=", "1.0", ")", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"Parameter output_keep_prob must be between 0 and 1: %d\"", "\n", "%", "output_keep_prob", ")", "\n", "", "self", ".", "_cell", "=", "cell", "\n", "self", ".", "_input_keep_prob", "=", "input_keep_prob", "\n", "self", ".", "_output_keep_prob", "=", "output_keep_prob", "\n", "self", ".", "_seed", "=", "seed", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.DropoutWrapper.state_size": [[681, 684], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_cell", ".", "state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.DropoutWrapper.output_size": [[685, 688], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_cell", ".", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.DropoutWrapper.__call__": [[689, 699], ["rnn_cell_GRU.DropoutWrapper._cell", "tensorflow.python.ops.nn_ops.dropout", "tensorflow.python.ops.nn_ops.dropout", "isinstance", "isinstance"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Run the cell with the declared dropouts.\"\"\"", "\n", "if", "(", "not", "isinstance", "(", "self", ".", "_input_keep_prob", ",", "float", ")", "or", "\n", "self", ".", "_input_keep_prob", "<", "1", ")", ":", "\n", "      ", "inputs", "=", "nn_ops", ".", "dropout", "(", "inputs", ",", "self", ".", "_input_keep_prob", ",", "seed", "=", "self", ".", "_seed", ")", "\n", "", "output", ",", "new_state", "=", "self", ".", "_cell", "(", "inputs", ",", "state", ",", "scope", ")", "\n", "if", "(", "not", "isinstance", "(", "self", ".", "_output_keep_prob", ",", "float", ")", "or", "\n", "self", ".", "_output_keep_prob", "<", "1", ")", ":", "\n", "      ", "output", "=", "nn_ops", ".", "dropout", "(", "output", ",", "self", ".", "_output_keep_prob", ",", "seed", "=", "self", ".", "_seed", ")", "\n", "", "return", "output", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.EmbeddingWrapper.__init__": [[710, 733], ["isinstance", "TypeError", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cell", ",", "embedding_classes", ",", "embedding_size", ",", "initializer", "=", "None", ")", ":", "\n", "    ", "\"\"\"Create a cell with an added input embedding.\n\n    Args:\n      cell: an RNNCell, an embedding will be put before its inputs.\n      embedding_classes: integer, how many symbols will be embedded.\n      embedding_size: integer, the size of the vectors we embed into.\n      initializer: an initializer to use when creating the embedding;\n        if None, the initializer from variable scope or a default one is used.\n\n    Raises:\n      TypeError: if cell is not an RNNCell.\n      ValueError: if embedding_classes is not positive.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "cell", ",", "RNNCell", ")", ":", "\n", "      ", "raise", "TypeError", "(", "\"The parameter cell is not RNNCell.\"", ")", "\n", "", "if", "embedding_classes", "<=", "0", "or", "embedding_size", "<=", "0", ":", "\n", "      ", "raise", "ValueError", "(", "\"Both embedding_classes and embedding_size must be > 0: \"", "\n", "\"%d, %d.\"", "%", "(", "embedding_classes", ",", "embedding_size", ")", ")", "\n", "", "self", ".", "_cell", "=", "cell", "\n", "self", ".", "_embedding_classes", "=", "embedding_classes", "\n", "self", ".", "_embedding_size", "=", "embedding_size", "\n", "self", ".", "_initializer", "=", "initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.EmbeddingWrapper.state_size": [[734, 737], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_cell", ".", "state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.EmbeddingWrapper.output_size": [[738, 741], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_cell", ".", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.EmbeddingWrapper.__call__": [[742, 767], ["rnn_cell_GRU.EmbeddingWrapper._cell", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.framework.ops.device", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.embedding_ops.embedding_lookup", "type", "tensorflow.python.ops.array_ops.reshape", "type", "tensorflow.python.ops.variable_scope.get_variable_scope", "math.sqrt", "tensorflow.python.ops.init_ops.random_uniform_initializer", "tensorflow.python.ops.variable_scope.get_variable_scope"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Run the cell on embedded inputs.\"\"\"", "\n", "with", "vs", ".", "variable_scope", "(", "scope", "or", "type", "(", "self", ")", ".", "__name__", ")", ":", "# \"EmbeddingWrapper\"", "\n", "      ", "with", "ops", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "        ", "if", "self", ".", "_initializer", ":", "\n", "          ", "initializer", "=", "self", ".", "_initializer", "\n", "", "elif", "vs", ".", "get_variable_scope", "(", ")", ".", "initializer", ":", "\n", "          ", "initializer", "=", "vs", ".", "get_variable_scope", "(", ")", ".", "initializer", "\n", "", "else", ":", "\n", "# Default initializer for embeddings should have variance=1.", "\n", "          ", "sqrt3", "=", "math", ".", "sqrt", "(", "3", ")", "# Uniform(-sqrt(3), sqrt(3)) has variance=1.", "\n", "initializer", "=", "init_ops", ".", "random_uniform_initializer", "(", "-", "sqrt3", ",", "sqrt3", ")", "\n", "\n", "", "if", "type", "(", "state", ")", "is", "tuple", ":", "\n", "          ", "data_type", "=", "state", "[", "0", "]", ".", "dtype", "\n", "", "else", ":", "\n", "          ", "data_type", "=", "state", ".", "dtype", "\n", "\n", "", "embedding", "=", "vs", ".", "get_variable", "(", "\n", "\"embedding\"", ",", "[", "self", ".", "_embedding_classes", ",", "self", ".", "_embedding_size", "]", ",", "\n", "initializer", "=", "initializer", ",", "\n", "dtype", "=", "data_type", ")", "\n", "embedded", "=", "embedding_ops", ".", "embedding_lookup", "(", "\n", "embedding", ",", "array_ops", ".", "reshape", "(", "inputs", ",", "[", "-", "1", "]", ")", ")", "\n", "", "", "return", "self", ".", "_cell", "(", "embedded", ",", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.MultiRNNCell.__init__": [[772, 794], ["ValueError", "any", "ValueError", "tensorflow.python.util.nest.is_sequence", "str"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cells", ",", "state_is_tuple", "=", "False", ")", ":", "\n", "    ", "\"\"\"Create a RNN cell composed sequentially of a number of RNNCells.\n\n    Args:\n      cells: list of RNNCells that will be composed in this order.\n      state_is_tuple: If True, accepted and returned states are n-tuples, where\n        `n = len(cells)`.  By default (False), the states are all\n        concatenated along the column axis.\n\n    Raises:\n      ValueError: if cells is empty (not allowed), or at least one of the cells\n        returns a state tuple but the flag `state_is_tuple` is `False`.\n    \"\"\"", "\n", "if", "not", "cells", ":", "\n", "      ", "raise", "ValueError", "(", "\"Must specify at least one cell for MultiRNNCell.\"", ")", "\n", "", "self", ".", "_cells", "=", "cells", "\n", "self", ".", "_state_is_tuple", "=", "state_is_tuple", "\n", "if", "not", "state_is_tuple", ":", "\n", "      ", "if", "any", "(", "nest", ".", "is_sequence", "(", "c", ".", "state_size", ")", "for", "c", "in", "self", ".", "_cells", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Some cells return tuples of states, but the flag \"", "\n", "\"state_is_tuple is not set.  State sizes are: %s\"", "\n", "%", "str", "(", "[", "c", ".", "state_size", "for", "c", "in", "self", ".", "_cells", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.MultiRNNCell.state_size": [[795, 801], ["tuple", "sum"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "_state_is_tuple", ":", "\n", "      ", "return", "tuple", "(", "cell", ".", "state_size", "for", "cell", "in", "self", ".", "_cells", ")", "\n", "", "else", ":", "\n", "      ", "return", "sum", "(", "[", "cell", ".", "state_size", "for", "cell", "in", "self", ".", "_cells", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.MultiRNNCell.output_size": [[802, 805], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_cells", "[", "-", "1", "]", ".", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU.MultiRNNCell.__call__": [[806, 829], ["tensorflow.python.ops.variable_scope.variable_scope", "enumerate", "tuple", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.variable_scope.variable_scope", "cell", "new_states.append", "type", "tensorflow.python.ops.array_ops.slice", "tensorflow.python.util.nest.is_sequence", "ValueError", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"Run this multi-layer cell on inputs, starting from state.\"\"\"", "\n", "with", "vs", ".", "variable_scope", "(", "scope", "or", "type", "(", "self", ")", ".", "__name__", ")", ":", "# \"MultiRNNCell\"", "\n", "      ", "cur_state_pos", "=", "0", "\n", "cur_inp", "=", "inputs", "\n", "new_states", "=", "[", "]", "\n", "for", "i", ",", "cell", "in", "enumerate", "(", "self", ".", "_cells", ")", ":", "\n", "        ", "with", "vs", ".", "variable_scope", "(", "\"Cell%d\"", "%", "i", ")", ":", "\n", "          ", "if", "self", ".", "_state_is_tuple", ":", "\n", "            ", "if", "not", "nest", ".", "is_sequence", "(", "state", ")", ":", "\n", "              ", "raise", "ValueError", "(", "\n", "\"Expected state to be a tuple of length %d, but received: %s\"", "\n", "%", "(", "len", "(", "self", ".", "state_size", ")", ",", "state", ")", ")", "\n", "", "cur_state", "=", "state", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "cur_state", "=", "array_ops", ".", "slice", "(", "\n", "state", ",", "[", "0", ",", "cur_state_pos", "]", ",", "[", "-", "1", ",", "cell", ".", "state_size", "]", ")", "\n", "cur_state_pos", "+=", "cell", ".", "state_size", "\n", "", "cur_inp", ",", "new_state", "=", "cell", "(", "cur_inp", ",", "cur_state", ")", "\n", "new_states", ".", "append", "(", "new_state", ")", "\n", "", "", "", "new_states", "=", "(", "tuple", "(", "new_states", ")", "if", "self", ".", "_state_is_tuple", "\n", "else", "array_ops", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "new_states", ")", ")", "\n", "return", "cur_inp", ",", "new_states", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._SlimRNNCell.__init__": [[834, 861], ["rnn_cell_GRU._SlimRNNCell._cell_fn", "init_output.get_shape", "init_state.get_shape", "callable", "TypeError", "ValueError", "ValueError", "init_output.get_shape.with_rank", "init_state.get_shape.with_rank"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cell_fn", ")", ":", "\n", "    ", "\"\"\"Create a SlimRNNCell from a cell_fn.\n\n    Args:\n      cell_fn: a function which takes (inputs, state, scope) and produces the\n        outputs and the new_state. Additionally when called with inputs=None and\n        state=None it should return (initial_outputs, initial_state).\n\n    Raises:\n      TypeError: if cell_fn is not callable\n      ValueError: if cell_fn cannot produce a valid initial state.\n    \"\"\"", "\n", "if", "not", "callable", "(", "cell_fn", ")", ":", "\n", "      ", "raise", "TypeError", "(", "\"cell_fn %s needs to be callable\"", ",", "cell_fn", ")", "\n", "", "self", ".", "_cell_fn", "=", "cell_fn", "\n", "self", ".", "_cell_name", "=", "cell_fn", ".", "func", ".", "__name__", "\n", "init_output", ",", "init_state", "=", "self", ".", "_cell_fn", "(", "None", ",", "None", ")", "\n", "output_shape", "=", "init_output", ".", "get_shape", "(", ")", "\n", "state_shape", "=", "init_state", ".", "get_shape", "(", ")", "\n", "self", ".", "_output_size", "=", "output_shape", ".", "with_rank", "(", "2", ")", "[", "1", "]", ".", "value", "\n", "self", ".", "_state_size", "=", "state_shape", ".", "with_rank", "(", "2", ")", "[", "1", "]", ".", "value", "\n", "if", "self", ".", "_output_size", "is", "None", ":", "\n", "      ", "raise", "ValueError", "(", "\"Initial output created by %s has invalid shape %s\"", "%", "\n", "(", "self", ".", "_cell_name", ",", "output_shape", ")", ")", "\n", "", "if", "self", ".", "_state_size", "is", "None", ":", "\n", "      ", "raise", "ValueError", "(", "\"Initial state created by %s has invalid shape %s\"", "%", "\n", "(", "self", ".", "_cell_name", ",", "state_shape", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._SlimRNNCell.state_size": [[862, 865], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._SlimRNNCell.output_size": [[866, 869], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._SlimRNNCell.__call__": [[870, 874], ["rnn_cell_GRU._SlimRNNCell._cell_fn"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "    ", "scope", "=", "scope", "or", "self", ".", "_cell_name", "\n", "output", ",", "state", "=", "self", ".", "_cell_fn", "(", "inputs", ",", "state", ",", "scope", "=", "scope", ")", "\n", "return", "output", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._state_size_with_prefix": [[66, 86], ["tensorflow.python.framework.tensor_shape.as_shape().as_list", "tensorflow.python.framework.tensor_shape.as_shape", "isinstance", "TypeError"], "function", ["None"], ["def", "_state_size_with_prefix", "(", "state_size", ",", "prefix", "=", "None", ")", ":", "\n", "  ", "\"\"\"Helper function that enables int or TensorShape shape specification.\n\n  This function takes a size specification, which can be an integer or a\n  TensorShape, and converts it into a list of integers. One may specify any\n  additional dimensions that precede the final state size specification.\n\n  Args:\n    state_size: TensorShape or int that specifies the size of a tensor.\n    prefix: optional additional list of dimensions to prepend.\n\n  Returns:\n    result_state_size: list of dimensions the resulting tensor size.\n  \"\"\"", "\n", "result_state_size", "=", "tensor_shape", ".", "as_shape", "(", "state_size", ")", ".", "as_list", "(", ")", "\n", "if", "prefix", "is", "not", "None", ":", "\n", "    ", "if", "not", "isinstance", "(", "prefix", ",", "list", ")", ":", "\n", "      ", "raise", "TypeError", "(", "\"prefix of _state_size_with_prefix should be a list.\"", ")", "\n", "", "result_state_size", "=", "prefix", "+", "result_state_size", "\n", "", "return", "result_state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._get_concat_variable": [[338, 354], ["rnn_cell_GRU._get_sharded_variable", "tensorflow.python.framework.ops.get_collection", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.framework.ops.add_to_collection", "len", "tensorflow.python.ops.variable_scope.get_variable_scope"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._get_sharded_variable"], ["", "", "", "def", "_get_concat_variable", "(", "name", ",", "shape", ",", "dtype", ",", "num_shards", ")", ":", "\n", "  ", "\"\"\"Get a sharded variable concatenated into one tensor.\"\"\"", "\n", "sharded_variable", "=", "_get_sharded_variable", "(", "name", ",", "shape", ",", "dtype", ",", "num_shards", ")", "\n", "if", "len", "(", "sharded_variable", ")", "==", "1", ":", "\n", "    ", "return", "sharded_variable", "[", "0", "]", "\n", "\n", "", "concat_name", "=", "name", "+", "\"/concat\"", "\n", "concat_full_name", "=", "vs", ".", "get_variable_scope", "(", ")", ".", "name", "+", "\"/\"", "+", "concat_name", "+", "\":0\"", "\n", "for", "value", "in", "ops", ".", "get_collection", "(", "ops", ".", "GraphKeys", ".", "CONCATENATED_VARIABLES", ")", ":", "\n", "    ", "if", "value", ".", "name", "==", "concat_full_name", ":", "\n", "      ", "return", "value", "\n", "\n", "", "", "concat_variable", "=", "array_ops", ".", "concat", "(", "0", ",", "sharded_variable", ",", "name", "=", "concat_name", ")", "\n", "ops", ".", "add_to_collection", "(", "ops", ".", "GraphKeys", ".", "CONCATENATED_VARIABLES", ",", "\n", "concat_variable", ")", "\n", "return", "concat_variable", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._get_sharded_variable": [[356, 372], ["int", "range", "ValueError", "math.floor", "shards.append", "tensorflow.python.ops.variable_scope.get_variable"], "function", ["None"], ["", "def", "_get_sharded_variable", "(", "name", ",", "shape", ",", "dtype", ",", "num_shards", ")", ":", "\n", "  ", "\"\"\"Get a list of sharded variables with the given dtype.\"\"\"", "\n", "if", "num_shards", ">", "shape", "[", "0", "]", ":", "\n", "    ", "raise", "ValueError", "(", "\"Too many shards: shape=%s, num_shards=%d\"", "%", "\n", "(", "shape", ",", "num_shards", ")", ")", "\n", "", "unit_shard_size", "=", "int", "(", "math", ".", "floor", "(", "shape", "[", "0", "]", "/", "num_shards", ")", ")", "\n", "remaining_rows", "=", "shape", "[", "0", "]", "-", "unit_shard_size", "*", "num_shards", "\n", "\n", "shards", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_shards", ")", ":", "\n", "    ", "current_size", "=", "unit_shard_size", "\n", "if", "i", "<", "remaining_rows", ":", "\n", "      ", "current_size", "+=", "1", "\n", "", "shards", ".", "append", "(", "vs", ".", "get_variable", "(", "name", "+", "\"_%d\"", "%", "i", ",", "[", "current_size", "]", "+", "shape", "[", "1", ":", "]", ",", "\n", "dtype", "=", "dtype", ")", ")", "\n", "", "return", "shards", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn_cell_GRU._linear": [[876, 927], ["ValueError", "tensorflow.python.util.nest.is_sequence", "a.get_shape().as_list", "tensorflow.python.ops.variable_scope.variable_scope", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.ops.variable_scope.get_variable", "tensorflow.python.util.nest.is_sequence", "len", "ValueError", "ValueError", "len", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.math_ops.matmul", "a.get_shape", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.init_ops.constant_initializer", "str", "str"], "function", ["None"], ["", "", "def", "_linear", "(", "args", ",", "output_size", ",", "bias", ",", "bias_start", "=", "0.0", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Linear map: sum_i(args[i] * W[i]), where W[i] is a variable.\n\n  Args:\n    args: a 2D Tensor or a list of 2D, batch x n, Tensors.\n    output_size: int, second dimension of W[i].\n    bias: boolean, whether to add a bias term or not.\n    bias_start: starting value to initialize the bias; 0 by default.\n    scope: VariableScope for the created subgraph; defaults to \"Linear\".\n\n  Returns:\n    A 2D Tensor with shape [batch x output_size] equal to\n    sum_i(args[i] * W[i]), where W[i]s are newly created matrices.\n\n  Raises:\n    ValueError: if some of the arguments has unspecified or wrong shape.\n  \"\"\"", "\n", "if", "args", "is", "None", "or", "(", "nest", ".", "is_sequence", "(", "args", ")", "and", "not", "args", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\"`args` must be specified\"", ")", "\n", "", "if", "not", "nest", ".", "is_sequence", "(", "args", ")", ":", "\n", "    ", "args", "=", "[", "args", "]", "\n", "\n", "# Calculate the total size of arguments on dimension 1.", "\n", "", "total_arg_size", "=", "0", "\n", "shapes", "=", "[", "a", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "for", "a", "in", "args", "]", "\n", "for", "shape", "in", "shapes", ":", "\n", "    ", "if", "len", "(", "shape", ")", "!=", "2", ":", "\n", "      ", "raise", "ValueError", "(", "\"Linear is expecting 2D arguments: %s\"", "%", "str", "(", "shapes", ")", ")", "\n", "", "if", "not", "shape", "[", "1", "]", ":", "\n", "      ", "raise", "ValueError", "(", "\"Linear expects shape[1] of arguments: %s\"", "%", "str", "(", "shapes", ")", ")", "\n", "", "else", ":", "\n", "      ", "total_arg_size", "+=", "shape", "[", "1", "]", "\n", "\n", "", "", "dtype", "=", "[", "a", ".", "dtype", "for", "a", "in", "args", "]", "[", "0", "]", "\n", "\n", "# Now the computation.", "\n", "with", "vs", ".", "variable_scope", "(", "scope", "or", "\"Linear\"", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "    ", "matrix", "=", "vs", ".", "get_variable", "(", "\n", "\"Matrix\"", ",", "[", "total_arg_size", ",", "output_size", "]", ",", "dtype", "=", "dtype", ")", "\n", "if", "len", "(", "args", ")", "==", "1", ":", "\n", "      ", "res", "=", "math_ops", ".", "matmul", "(", "args", "[", "0", "]", ",", "matrix", ")", "\n", "", "else", ":", "\n", "      ", "res", "=", "math_ops", ".", "matmul", "(", "array_ops", ".", "concat", "(", "values", "=", "args", ",", "axis", "=", "1", ")", ",", "matrix", ")", "\n", "", "if", "not", "bias", ":", "\n", "      ", "return", "res", "\n", "", "bias_term", "=", "vs", ".", "get_variable", "(", "\n", "\"Bias\"", ",", "[", "output_size", "]", ",", "\n", "dtype", "=", "dtype", ",", "\n", "initializer", "=", "init_ops", ".", "constant_initializer", "(", "\n", "bias_start", ",", "dtype", "=", "dtype", ")", ")", "\n", "", "return", "res", "+", "bias_term", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.bilstm.softmax": [[24, 30], ["numpy.exp", "numpy.sum"], "function", ["None"], ["def", "softmax", "(", "x", ")", ":", "\n", "    ", "x_exp", "=", "np", ".", "exp", "(", "x", ")", "\n", "#\u5982\u679c\u662f\u5217\u5411\u91cf\uff0c\u5219axis=0", "\n", "x_sum", "=", "np", ".", "sum", "(", "x_exp", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "s", "=", "x_exp", "/", "x_sum", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.bilstm.labelprocess": [[32, 38], ["len", "numpy.zeros", "enumerate", "int"], "function", ["None"], ["", "def", "labelprocess", "(", "label", ",", "n_class", "=", "n_classes", ")", ":", "\n", "    ", "label_length", "=", "len", "(", "label", ")", "\n", "label_matrix", "=", "np", ".", "zeros", "(", "(", "label_length", ",", "n_class", ")", ")", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "label", ")", ":", "\n", "       ", "label_matrix", "[", "i", ",", "int", "(", "j", ")", "]", "=", "1", "\n", "", "return", "label_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.bilstm.next_batch": [[39, 47], ["min", "len", "len", "min", "min", "len", "len"], "function", ["None"], ["", "def", "next_batch", "(", "batch_size", ",", "train_x", ",", "train_y", ")", ":", "\n", "    ", "global", "batchid", "\n", "if", "batchid", "+", "batch_size", ">", "len", "(", "train_x", ")", ":", "\n", "       ", "batchid", "=", "0", "\n", "", "batch_data", "=", "(", "train_x", "[", "batchid", ":", "min", "(", "batchid", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", ",", ":", "]", ")", "\n", "batch_labels", "=", "(", "train_y", "[", "batchid", ":", "min", "(", "batchid", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", "]", ")", "\n", "batchid", "=", "min", "(", "batchid", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", "\n", "return", "batch_data", ",", "batch_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.bilstm.BiRNN": [[78, 91], ["tensorflow.transpose", "tensorflow.reshape", "tensorflow.split", "tensorflow.contrib.rnn.GRUCell", "tensorflow.contrib.rnn.GRUCell", "tensorflow.contrib.rnn.static_bidirectional_rnn", "tensorflow.matmul"], "function", ["None"], ["def", "BiRNN", "(", "x", ",", "weights", ",", "biases", ")", ":", "\n", "\n", "    ", "x", "=", "tf", ".", "transpose", "(", "x", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", ",", "n_input", "]", ")", "\n", "x", "=", "tf", ".", "split", "(", "x", ",", "n_steps", ")", "\n", "lstm_fw_cell", "=", "GRUCell", "(", "n_hidden", ")", "\n", "lstm_bw_cell", "=", "GRUCell", "(", "n_hidden", ")", "\n", "#    lstm_fw_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias = 1.0)", "\n", "#    lstm_bw_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias = 1.0)", "\n", "outputs", ",", "_", ",", "_", "=", "tf", ".", "contrib", ".", "rnn", ".", "static_bidirectional_rnn", "(", "lstm_fw_cell", ",", "\n", "lstm_bw_cell", ",", "x", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "return", "tf", ".", "matmul", "(", "outputs", "[", "-", "1", "]", ",", "weights", ")", "+", "biases", ",", "outputs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.LDAclassifier.Iris_label": [[11, 14], ["None"], "function", ["None"], ["def", "Iris_label", "(", "s", ")", ":", "\n", "    ", "it", "=", "{", "b'Iris-setosa'", ":", "0", ",", "b'Iris-versicolor'", ":", "1", ",", "b'Iris-virginica'", ":", "2", "}", "\n", "return", "it", "[", "s", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.LDAclassifier.LDA_reduce_dimension": [[16, 108], ["list", "numpy.mean", "numpy.zeros", "numpy.dot", "numpy.zeros", "numpy.zeros", "numpy.linalg.eig", "numpy.argsort", "set", "numpy.array", "numpy.mean", "numpy.dot", "numpy.dot", "len", "len", "len", "len", "len", "len", "numpy.linalg.inv", "range", "len"], "function", ["None"], ["", "def", "LDA_reduce_dimension", "(", "X", ",", "y", ",", "nComponents", ")", ":", "\n", "    ", "'''\n    \u8f93\u5165\uff1aX\u4e3a\u6570\u636e\u96c6(m*n)\uff0cy\u4e3alabel(m*1)\uff0cnComponents\u4e3a\u76ee\u6807\u7ef4\u6570\n    \u8f93\u51fa\uff1aW \u77e9\u9635\uff08n * nComponents\uff09\n    '''", "\n", "#y1= set(y) #set():\u5254\u9664\u77e9\u9635y\u91cc\u7684\u91cd\u590d\u5143\u7d20,\u5316\u4e3a\u96c6\u5408\u7684\u5f62\u5f0f", "\n", "labels", "=", "list", "(", "set", "(", "y", ")", ")", "#list():\u5c06\u5176\u8f6c\u5316\u4e3a\u5217\u8868", "\n", "\"\"\"\n    eg:\n        >>> a=[3,2,1,2]\n        >>> set(a)\n        {1, 2, 3} \n        >>> list(set(a))\n        [1, 2, 3]\n        \n        >>> e=set(a)\n        >>> type(e)\n        <class 'set'> #\u96c6\u5408\n        >>> f=list(e)\n        >>> type(f)\n        <class 'list'>#\u5217\u8868\n    \"\"\"", "\n", "\n", "\n", "xClasses", "=", "{", "}", "#\u5b57\u5178", "\n", "for", "label", "in", "labels", ":", "\n", "       ", "xClasses", "[", "label", "]", "=", "np", ".", "array", "(", "[", "X", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "X", ")", ")", "if", "y", "[", "i", "]", "==", "label", "]", ")", "#list\u89e3\u6790", "\n", "", "\"\"\"\n    x=[1,2,3,4]\n    y=[5,6,7,8]\n    \u6211\u60f3\u8ba9\u7740\u4e24\u4e2alist\u4e2d\u7684\u5076\u6570\u5206\u522b\u76f8\u52a0\uff0c\u5e94\u8be5\u7ed3\u679c\u662f2+6,4+6,2+8,4+8\n    \u4e0b\u9762\u7528\u4e00\u53e5\u8bdd\u6765\u5199:\n    >>>[a + b for a in x for b in y if a%2 == 0 and b%2 ==0]  \n    \"\"\"", "\n", "\n", "#\u6574\u4f53\u5747\u503c", "\n", "meanAll", "=", "np", ".", "mean", "(", "X", ",", "axis", "=", "0", ")", "# \u6309\u5217\u6c42\u5747\u503c\uff0c\u7ed3\u679c\u4e3a1*n(\u884c\u5411\u91cf)", "\n", "meanClasses", "=", "{", "}", "\n", "\n", "#\u6c42\u5404\u7c7b\u5747\u503c", "\n", "for", "label", "in", "labels", ":", "\n", "        ", "meanClasses", "[", "label", "]", "=", "np", ".", "mean", "(", "xClasses", "[", "label", "]", ",", "axis", "=", "0", ")", "#1*n", "\n", "\n", "#\u5168\u5c40\u6563\u5ea6\u77e9\u9635", "\n", "", "St", "=", "np", ".", "zeros", "(", "(", "len", "(", "meanAll", ")", ",", "len", "(", "meanAll", ")", ")", ")", "\n", "St", "=", "np", ".", "dot", "(", "(", "X", "-", "meanAll", ")", ".", "T", ",", "X", "-", "meanAll", ")", "\n", "\n", "#\u6c42\u7c7b\u5185\u6563\u5ea6\u77e9\u9635", "\n", "# Sw=sum(np.dot((Xi-ui).T, Xi-ui))   i=1...m", "\n", "Sw", "=", "np", ".", "zeros", "(", "(", "len", "(", "meanAll", ")", ",", "len", "(", "meanAll", ")", ")", ")", "# n*n", "\n", "for", "i", "in", "labels", ":", "\n", "        ", "Sw", "+=", "np", ".", "dot", "(", "(", "xClasses", "[", "i", "]", "-", "meanClasses", "[", "i", "]", ")", ".", "T", ",", "(", "xClasses", "[", "i", "]", "-", "meanClasses", "[", "i", "]", ")", ")", "\n", "\n", "# \u6c42\u7c7b\u95f4\u6563\u5ea6\u77e9\u9635", "\n", "", "Sb", "=", "np", ".", "zeros", "(", "(", "len", "(", "meanAll", ")", ",", "len", "(", "meanAll", ")", ")", ")", "# n*n", "\n", "Sb", "=", "St", "-", "Sw", "\n", "\n", "#\u6c42\u7c7b\u95f4\u6563\u5ea6\u77e9\u9635", "\n", "# Sb=sum(len(Xj) * np.dot((uj-u).T,uj-u))  j=1...k", "\n", "# Sb=np.zeros((len(meanAll), len(meanAll) )) # n*n", "\n", "# for i in labels:", "\n", "#     Sb+= len(xClasses[i]) * np.dot( (meanClasses[i]-meanAll).T.reshape(len(meanAll),1),", "\n", "#                                     (meanClasses[i]-meanAll).reshape(1,len(meanAll))", "\n", "#                                )", "\n", "\n", "# \u8ba1\u7b97Sw-1*Sb\u7684\u7279\u5f81\u503c\u548c\u7279\u5f81\u77e9\u9635", "\n", "eigenValues", ",", "eigenVectors", "=", "np", ".", "linalg", ".", "eig", "(", "\n", "np", ".", "dot", "(", "np", ".", "linalg", ".", "inv", "(", "Sw", ")", ",", "Sb", ")", "\n", ")", "\n", "#\u63d0\u53d6\u524dnComponents\u4e2a\u7279\u5f81\u5411\u91cf", "\n", "sortedIndices", "=", "np", ".", "argsort", "(", "eigenValues", ")", "#\u7279\u5f81\u503c\u6392\u5e8f", "\n", "W", "=", "eigenVectors", "[", ":", ",", "sortedIndices", "[", ":", "-", "nComponents", "-", "1", ":", "-", "1", "]", "]", "# \u63d0\u53d6\u524dnComponents\u4e2a\u7279\u5f81\u5411\u91cf", "\n", "return", "W", "\n", "\n", "\"\"\"\n    np.argsort()\n    eg:\n    >>> x = np.array([3, 1, 2])\n    >>> np.argsort(x)\n    array([1, 2, 0])\n    Two-dimensional array:\n    >>> x = np.array([[0, 3], [2, 2]])\n    >>> x\n    array([[0, 3],\n           [2, 2]])\n    >>> np.argsort(x, axis=0)\n    array([[0, 1],\n           [1, 0]])\n    >>> np.argsort(x, axis=1)\n    array([[0, 1],\n           [0, 1]])\n    \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.LDAclassifier.lda_reduse_dimension": [[113, 151], ["numpy.loadtxt", "print", "sklearn.discriminant_analysis.LinearDiscriminantAnalysis", "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.fit", "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.transform", "sklearn.discriminant_analysis.LinearDiscriminantAnalysis.score", "print", "numpy.savetxt", "matplotlib.figure", "matplotlib.scatter", "matplotlib.title", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.show", "matplotlib.subplot", "plt.subplot.scatter", "plt.subplot.set_zlabel", "plt.subplot.set_ylabel", "plt.subplot.set_xlabel", "matplotlib.title", "matplotlib.show"], "function", ["None"], ["", "def", "lda_reduse_dimension", "(", "X", ")", ":", "\n", "#1.\u8bfb\u53d6\u6570\u636e\u96c6", "\n", "#    X = np.loadtxt(\"./feature_extract/fisherfeature_data.txt\")", "\n", "    ", "y", "=", "np", ".", "loadtxt", "(", "\"./tsfuse/lrts10slabel12fea.txt\"", ")", "\n", "print", "(", "X", ".", "shape", ")", "\n", "#    #2.LDA\u7279\u5f81\u63d0\u53d6", "\n", "#    W=LDA_reduce_dimension(X, y, 10) #\u5f97\u5230\u6295\u5f71\u77e9\u9635", "\n", "#    print(W.shape)", "\n", "#    newX=np.dot(X,W)# (m*n) *(n*k)=m*k", "\n", "#    print(newX.shape)", "\n", "#    #3.\u7ed8\u56fe", "\n", "#    # \u6307\u5b9a\u9ed8\u8ba4\u5b57\u4f53", "\n", "#    matplotlib.rcParams['font.sans-serif'] = ['SimHei']", "\n", "#    plt.figure(1)", "\n", "#    plt.scatter(newX[:,0],newX[:, 1],c=y,marker='o') #c=y,", "\n", "#    plt.title('Own LDA')", "\n", "\n", "\n", "#4.\u4e0esklearn\u81ea\u5e26\u5e93\u51fd\u6570\u5bf9\u6bd4", "\n", "lda_Sklearn", "=", "LinearDiscriminantAnalysis", "(", "n_components", "=", "3", ")", "\n", "lda_Sklearn", ".", "fit", "(", "X", ",", "y", ")", "\n", "newX1", "=", "lda_Sklearn", ".", "transform", "(", "X", ")", "\n", "lda_score", "=", "lda_Sklearn", ".", "score", "(", "X", ",", "y", ")", "\n", "print", "(", "lda_score", ")", "\n", "np", ".", "savetxt", "(", "'./feature_extract/ldafeature_data.txt'", ",", "newX1", ",", "fmt", "=", "'%.4f'", ")", "\n", "plt", ".", "figure", "(", "2", ")", "\n", "plt", ".", "scatter", "(", "newX1", "[", ":", ",", "0", "]", ",", "newX1", "[", ":", ",", "1", "]", ",", "marker", "=", "'o'", ",", "c", "=", "y", ")", "\n", "plt", ".", "title", "(", "'Dimension reduction result of LDA (2d)'", ",", "fontsize", "=", "20", ")", "\n", "plt", ".", "xticks", "(", "fontsize", "=", "15", ")", "\n", "plt", ".", "yticks", "(", "fontsize", "=", "15", ")", "\n", "plt", ".", "show", "(", ")", "\n", "ax", "=", "plt", ".", "subplot", "(", "111", ",", "projection", "=", "'3d'", ")", "\n", "ax", ".", "scatter", "(", "newX1", "[", ":", ",", "0", "]", ",", "newX1", "[", ":", ",", "1", "]", ",", "newX1", "[", ":", ",", "2", "]", ",", "c", "=", "y", ")", "\n", "ax", ".", "set_zlabel", "(", "'Z'", ",", "fontsize", "=", "15", ")", "\n", "ax", ".", "set_ylabel", "(", "'Y'", ",", "fontsize", "=", "15", ")", "\n", "ax", ".", "set_xlabel", "(", "'X'", ",", "fontsize", "=", "15", ")", "\n", "plt", ".", "title", "(", "'Dimension reduction result of LDA (3d)'", ",", "fontsize", "=", "20", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.deep_CCA_model.DeepCCA.__init__": [[26, 75], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "deep_CCA_model.DeepCCA.build_mlp_net", "deep_CCA_model.DeepCCA.build_mlp_net", "deep_CCA_model.DeepCCA.build_mlp_net", "deep_CCA_model.DeepCCA.build_mlp_net", "deep_CCA_model.DeepCCA.neg_correlation"], "methods", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.deep_CCA_model.DeepCCA.build_mlp_net", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.deep_CCA_model.DeepCCA.build_mlp_net", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.deep_CCA_model.DeepCCA.build_mlp_net", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.deep_CCA_model.DeepCCA.build_mlp_net", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.deep_CCA_model.DeepCCA.neg_correlation"], ["    ", "def", "__init__", "(", "self", ",", "layer_sizes1", ",", "\n", "layer_sizes2", ",", "layer_sizes3", ",", "layer_sizes4", ",", "input_size1", ",", "\n", "input_size2", ",", "outdim_size", ",", "reg_par", ",", "use_all_singular_values", ")", ":", "\n", "\n", "        ", "self", ".", "layer_sizes1", "=", "layer_sizes1", "# [1024, 1024, 1024, outdim_size]", "\n", "self", ".", "layer_sizes2", "=", "layer_sizes2", "# [1024, 1024, 1024, outdim_size]", "\n", "self", ".", "layer_sizes3", "=", "layer_sizes3", "\n", "self", ".", "layer_sizes4", "=", "layer_sizes4", "\n", "self", ".", "input_size1", "=", "input_size1", "\n", "self", ".", "input_size2", "=", "input_size2", "\n", "self", ".", "outdim_size", "=", "outdim_size", "\n", "#      MLP", "\n", "self", ".", "input_view1", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "input_size1", "]", ")", "\n", "self", ".", "input_view2", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "input_size2", "]", ")", "\n", "# tf Graph input cnn", "\n", "#        self.input_view1 = tf.placeholder(\"float\", [None, 256])", "\n", "#        self.input_view2 = tf.placeholder(\"float\", [None, 256])", "\n", "self", ".", "label1", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "52", "]", ")", "\n", "self", ".", "label2", "=", "tf", ".", "placeholder", "(", "\"float\"", ",", "[", "None", ",", "52", "]", ")", "\n", "\n", "#        # Define weights", "\n", "#        self.weights = {", "\n", "#            # 5x5 conv, 1 input, 32 outputs", "\n", "#            'wc1': tf.Variable(tf.random_normal([3, 3, 1, 32])),", "\n", "#            # 5x5 conv, 32 inputs, 64 outputs", "\n", "#            'wc2': tf.Variable(tf.random_normal([3, 3, 32, 64])),", "\n", "#            # fully connected, 7*7*64 inputs, 1024 outputs", "\n", "#            'wd1': tf.Variable(tf.random_normal([4*256, 1024])),", "\n", "#            # 1024 inputs, 10 outputs (class prediction)", "\n", "#            'cnnout': tf.Variable(tf.random_normal([4*4*64, 52])),", "\n", "#            'mlpout': tf.Variable(tf.random_normal([52, 52]))", "\n", "#        }", "\n", "#        self.biases = {", "\n", "#            'bc1': tf.Variable(tf.random_normal([32])),", "\n", "#            'bc2': tf.Variable(tf.random_normal([64])),", "\n", "#            'bd1': tf.Variable(tf.random_normal([1024])),", "\n", "#            'cnnout': tf.Variable(tf.random_normal([52]))", "\n", "#        }", "\n", "\n", "#       neural network mlp", "\n", "self", ".", "output_view1", "=", "self", ".", "build_mlp_net", "(", "self", ".", "input_view1", ",", "layer_sizes1", ",", "reg_par", ")", "\n", "self", ".", "output_view2", "=", "self", ".", "build_mlp_net", "(", "self", ".", "input_view2", ",", "layer_sizes2", ",", "reg_par", ")", "\n", "#        classification", "\n", "self", ".", "output_view1_class", "=", "self", ".", "build_mlp_net", "(", "self", ".", "input_view1", ",", "layer_sizes3", ",", "reg_par", ")", "\n", "self", ".", "output_view2_class", "=", "self", ".", "build_mlp_net", "(", "self", ".", "input_view2", ",", "layer_sizes4", ",", "reg_par", ")", "\n", "#       neural network CNN        ", "\n", "#        self.output_view1 = self.conv_net(self.input_view1,self.weights,self.biases)", "\n", "#        self.output_view2 = self.conv_net(self.input_view2,self.weights,self.biases)", "\n", "self", ".", "neg_corr", ",", "self", ".", "value", "=", "self", ".", "neg_correlation", "(", "self", ".", "output_view1", ",", "self", ".", "output_view2", ",", "use_all_singular_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.deep_CCA_model.DeepCCA.conv2d": [[79, 84], ["tensorflow.nn.conv2d", "tensorflow.nn.bias_add", "tensorflow.nn.relu"], "methods", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.deep_CCA_model.DeepCCA.conv2d"], ["", "def", "conv2d", "(", "self", ",", "x", ",", "W", ",", "b", ",", "strides", "=", "1", ")", ":", "\n", "# Conv2D wrapper, with bias and relu activation", "\n", "\t    ", "x", "=", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "W", ",", "strides", "=", "[", "1", ",", "strides", ",", "strides", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "x", "=", "tf", ".", "nn", ".", "bias_add", "(", "x", ",", "b", ")", "\n", "return", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.deep_CCA_model.DeepCCA.maxpool2d": [[85, 89], ["tensorflow.nn.max_pool"], "methods", ["None"], ["", "def", "maxpool2d", "(", "self", ",", "x", ",", "k", "=", "2", ")", ":", "\n", "# MaxPool2D wrapper", "\n", "\t    ", "return", "tf", ".", "nn", ".", "max_pool", "(", "x", ",", "ksize", "=", "[", "1", ",", "k", ",", "k", ",", "1", "]", ",", "strides", "=", "[", "1", ",", "k", ",", "k", ",", "1", "]", ",", "\n", "padding", "=", "'SAME'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.deep_CCA_model.DeepCCA.build_mlp_net": [[115, 130], ["enumerate", "keras.layers.Dense", "len", "keras.regularizers.l2"], "methods", ["None"], ["", "def", "build_mlp_net", "(", "self", ",", "input", ",", "layer_sizes", ",", "reg_par", ")", ":", "\n", "        ", "output", "=", "input", "\n", "for", "l_id", ",", "ls", "in", "enumerate", "(", "layer_sizes", ")", ":", "\n", "            ", "if", "l_id", "==", "len", "(", "layer_sizes", ")", "-", "1", ":", "\n", "                ", "activation", "=", "None", "\n", "kernel_initializer", "=", "my_init_others", "\n", "", "else", ":", "\n", "                ", "activation", "=", "tf", ".", "nn", ".", "sigmoid", "\n", "kernel_initializer", "=", "my_init_sigmoid", "\n", "\n", "", "output", "=", "Dense", "(", "ls", ",", "activation", "=", "activation", ",", "\n", "kernel_initializer", "=", "kernel_initializer", ",", "\n", "kernel_regularizer", "=", "l2", "(", "reg_par", ")", ")", "(", "output", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.deep_CCA_model.DeepCCA.neg_correlation": [[132, 185], ["tensorflow.transpose", "tensorflow.transpose", "tensorflow.linalg.eigh", "tensorflow.linalg.eigh", "tensorflow.where", "tensorflow.gather", "tensorflow.gather", "tensorflow.where", "tensorflow.gather", "tensorflow.gather", "tensorflow.matmul", "tensorflow.matmul", "print", "tensorflow.matmul", "tensorflow.shape", "tensorflow.matmul", "tensorflow.greater", "tensorflow.reshape", "tensorflow.greater", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.matmul.set_shape", "tensorflow.linalg.svd", "tensorflow.reduce_sum", "tensorflow.linalg.eigh", "tensorflow.where", "tensorflow.gather", "tensorflow.gather", "tensorflow.sqrt", "tensorflow.reduce_sum", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.eye", "tensorflow.matmul", "tensorflow.eye", "tensorflow.linalg.diag", "tensorflow.linalg.diag", "tensorflow.matmul", "tensorflow.greater", "tensorflow.reshape", "tensorflow.sqrt", "tensorflow.cast", "tensorflow.ones", "tensorflow.cast", "tensorflow.ones", "tensorflow.cast", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.nn.top_k", "tensorflow.cast", "tensorflow.cast", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "def", "neg_correlation", "(", "self", ",", "output1", ",", "output2", ",", "use_all_singular_values", ")", ":", "\n", "        ", "r1", "=", "1e-4", "\n", "r2", "=", "1e-4", "\n", "eps", "=", "1e-12", "\n", "\n", "# unpack (separate) the output of networks for view 1 and view 2", "\n", "H1", "=", "tf", ".", "transpose", "(", "output1", ")", "\n", "H2", "=", "tf", ".", "transpose", "(", "output2", ")", "\n", "\n", "m", "=", "tf", ".", "shape", "(", "H1", ")", "[", "1", "]", "\n", "H1bar", "=", "H1", "-", "(", "1.0", "/", "tf", ".", "cast", "(", "m", ",", "tf", ".", "float32", ")", ")", "*", "tf", ".", "matmul", "(", "H1", ",", "tf", ".", "ones", "(", "[", "m", ",", "m", "]", ")", ")", "\n", "H2bar", "=", "H2", "-", "(", "1.0", "/", "tf", ".", "cast", "(", "m", ",", "tf", ".", "float32", ")", ")", "*", "tf", ".", "matmul", "(", "H2", ",", "tf", ".", "ones", "(", "[", "m", ",", "m", "]", ")", ")", "\n", "SigmaHat12", "=", "(", "1.0", "/", "(", "tf", ".", "cast", "(", "m", ",", "tf", ".", "float32", ")", "-", "1", ")", ")", "*", "tf", ".", "matmul", "(", "H1bar", ",", "tf", ".", "transpose", "(", "H2bar", ")", ")", "\n", "SigmaHat11", "=", "(", "1.0", "/", "(", "tf", ".", "cast", "(", "m", ",", "tf", ".", "float32", ")", "-", "1", ")", ")", "*", "tf", ".", "matmul", "(", "H1bar", ",", "tf", ".", "transpose", "(", "H1bar", ")", ")", "+", "r1", "*", "tf", ".", "eye", "(", "self", ".", "outdim_size", ")", "\n", "SigmaHat22", "=", "(", "1.0", "/", "(", "tf", ".", "cast", "(", "m", ",", "tf", ".", "float32", ")", "-", "1", ")", ")", "*", "tf", ".", "matmul", "(", "H2bar", ",", "tf", ".", "transpose", "(", "H2bar", ")", ")", "+", "r2", "*", "tf", ".", "eye", "(", "self", ".", "outdim_size", ")", "\n", "\n", "# Calculating the root inverse of covariance matrices by using eigen decomposition", "\n", "[", "D1", ",", "V1", "]", "=", "tf", ".", "linalg", ".", "eigh", "(", "SigmaHat11", ")", "\n", "[", "D2", ",", "V2", "]", "=", "tf", ".", "linalg", ".", "eigh", "(", "SigmaHat22", ")", "\n", "\n", "# Added to increase stability", "\n", "posInd1", "=", "tf", ".", "where", "(", "tf", ".", "greater", "(", "D1", ",", "eps", ")", ")", "\n", "posInd1", "=", "tf", ".", "reshape", "(", "posInd1", ",", "[", "-", "1", ",", "tf", ".", "shape", "(", "posInd1", ")", "[", "0", "]", "]", ")", "[", "0", "]", "\n", "D1", "=", "tf", ".", "gather", "(", "D1", ",", "posInd1", ")", "\n", "V1", "=", "tf", ".", "gather", "(", "V1", ",", "posInd1", ")", "\n", "\n", "posInd2", "=", "tf", ".", "where", "(", "tf", ".", "greater", "(", "D2", ",", "eps", ")", ")", "\n", "posInd2", "=", "tf", ".", "reshape", "(", "posInd2", ",", "[", "-", "1", ",", "tf", ".", "shape", "(", "posInd2", ")", "[", "0", "]", "]", ")", "[", "0", "]", "\n", "D2", "=", "tf", ".", "gather", "(", "D2", ",", "posInd2", ")", "\n", "V2", "=", "tf", ".", "gather", "(", "V2", ",", "posInd2", ")", "\n", "\n", "SigmaHat11RootInv", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "V1", ",", "tf", ".", "linalg", ".", "diag", "(", "D1", "**", "-", "0.5", ")", ")", ",", "tf", ".", "transpose", "(", "V1", ")", ")", "\n", "SigmaHat22RootInv", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "V2", ",", "tf", ".", "linalg", ".", "diag", "(", "D2", "**", "-", "0.5", ")", ")", ",", "tf", ".", "transpose", "(", "V2", ")", ")", "\n", "print", "(", "SigmaHat22RootInv", ".", "shape", ")", "\n", "Tval", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "SigmaHat11RootInv", ",", "SigmaHat12", ")", ",", "SigmaHat22RootInv", ")", "\n", "value", "=", "None", "\n", "if", "use_all_singular_values", ":", "\n", "# all singular values are used to calculate the correlation", "\n", "# corr = tf.sqrt(tf.linalg.trace(tf.matmul(tf.transpose(Tval), Tval)))  ### The usage of \"sqrt\" here is wrong!!!", "\n", "            ", "Tval", ".", "set_shape", "(", "[", "self", ".", "outdim_size", ",", "self", ".", "outdim_size", "]", ")", "\n", "s", "=", "tf", ".", "linalg", ".", "svd", "(", "Tval", ",", "compute_uv", "=", "False", ")", "\n", "value", "=", "s", "\n", "corr", "=", "tf", ".", "reduce_sum", "(", "s", ")", "\n", "", "else", ":", "\n", "# just the top outdim_size singular values are used", "\n", "            ", "[", "U", ",", "V", "]", "=", "tf", ".", "linalg", ".", "eigh", "(", "tf", ".", "matmul", "(", "tf", ".", "transpose", "(", "Tval", ")", ",", "Tval", ")", ")", "\n", "non_critical_indexes", "=", "tf", ".", "where", "(", "tf", ".", "greater", "(", "U", ",", "eps", ")", ")", "\n", "non_critical_indexes", "=", "tf", ".", "reshape", "(", "non_critical_indexes", ",", "[", "-", "1", ",", "tf", ".", "shape", "(", "non_critical_indexes", ")", "[", "0", "]", "]", ")", "[", "0", "]", "\n", "U", "=", "tf", ".", "gather", "(", "U", ",", "non_critical_indexes", ")", "\n", "U", "=", "tf", ".", "gather", "(", "U", ",", "tf", ".", "nn", ".", "top_k", "(", "U", "[", ":", ",", "]", ")", ".", "indices", ")", "\n", "value", "=", "tf", ".", "sqrt", "(", "U", "[", "0", ":", "self", ".", "outdim_size", "]", ")", "\n", "corr", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "sqrt", "(", "U", "[", "0", ":", "self", ".", "outdim_size", "]", ")", ")", "\n", "", "return", "-", "corr", ",", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.deep_CCA_model.my_init_sigmoid": [[11, 17], ["keras.backend.random_uniform", "_compute_fans", "math.sqrt", "math.sqrt"], "function", ["None"], ["def", "my_init_sigmoid", "(", "shape", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "rnd", "=", "K", ".", "random_uniform", "(", "\n", "shape", ",", "0.", ",", "1.", ",", "dtype", ")", "\n", "from", "keras", ".", "initializers", "import", "_compute_fans", "\n", "fan_in", ",", "fan_out", "=", "_compute_fans", "(", "shape", ")", "\n", "return", "8.", "*", "(", "rnd", "-", "0.5", ")", "*", "math", ".", "sqrt", "(", "6", ")", "/", "math", ".", "sqrt", "(", "fan_in", "+", "fan_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.deep_CCA_model.my_init_others": [[18, 24], ["keras.backend.random_uniform", "_compute_fans", "math.sqrt"], "function", ["None"], ["", "def", "my_init_others", "(", "shape", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "rnd", "=", "K", ".", "random_uniform", "(", "\n", "shape", ",", "0.", ",", "1.", ",", "dtype", ")", "\n", "from", "keras", ".", "initializers", "import", "_compute_fans", "\n", "fan_in", ",", "fan_out", "=", "_compute_fans", "(", "shape", ")", "\n", "return", "2.", "*", "(", "rnd", "-", "0.5", ")", "/", "math", ".", "sqrt", "(", "fan_in", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.force_channel.HMMTrainer.__init__": [[88, 104], ["hmmlearn.hmm.GaussianHMM", "hmmlearn.hmm.GMMHMM"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model_name", "=", "'GaussianHMM'", ",", "n_components", "=", "10", ",", "cov_type", "=", "'diag'", ",", "n_iter", "=", "20", ")", ":", "\n", "#\u6a21\u578b\u540d\u79f0 hmmlearn\u5b9e\u73b0\u4e86\u4e09\u79cdHMM\u6a21\u578b\u7c7b\uff0cGaussianHMM\u548cGMMHMM\u662f\u8fde\u7eed\u89c2\u6d4b\u72b6\u6001\u7684HMM\u6a21\u578b\uff0cMultinomialHMM\u662f\u79bb\u6563\u89c2\u6d4b\u72b6\u6001\u7684\u6a21\u578b", "\n", "        ", "self", ".", "model", "=", "None", "\n", "self", ".", "model_name", "=", "model_name", "\n", "#\u9690\u85cf\u72b6\u6001\u4e2a\u6570", "\n", "self", ".", "n_components", "=", "n_components", "\n", "#\u8f6c\u79fb\u77e9\u9635\u534f\u65b9\u5dee\u7c7b\u578b", "\n", "self", ".", "cov_type", "=", "cov_type", "\n", "#\u8bad\u7ec3\u8fed\u4ee3\u6b21\u6570", "\n", "self", ".", "n_iter", "=", "n_iter", "\n", "self", ".", "models", "=", "[", "]", "\n", "if", "self", ".", "model_name", "==", "'GaussianHMM'", ":", "\n", "            ", "self", ".", "model", "=", "hmm", ".", "GaussianHMM", "(", "n_components", "=", "self", ".", "n_components", ",", "covariance_type", "=", "self", ".", "cov_type", ",", "n_iter", "=", "self", ".", "n_iter", ")", "\n", "", "else", ":", "\n", "#            self.model = hmm.MultinomialHMM(n_components=self.n_components, n_iter=self.n_iter, tol=0.01)", "\n", "            ", "self", ".", "model", "=", "hmm", ".", "GMMHMM", "(", "n_components", "=", "self", ".", "n_components", ",", "n_iter", "=", "self", ".", "n_iter", ",", "tol", "=", "0.01", ")", "\n", "#            raise TypeError('Invalid model type')", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.force_channel.HMMTrainer.train": [[107, 110], ["numpy.seterr", "force_channel.HMMTrainer.models.append", "force_channel.HMMTrainer.model.fit"], "methods", ["None"], ["", "", "def", "train", "(", "self", ",", "X", ")", ":", "\n", "        ", "np", ".", "seterr", "(", "all", "=", "'ignore'", ")", "\n", "self", ".", "models", ".", "append", "(", "self", ".", "model", ".", "fit", "(", "X", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.force_channel.HMMTrainer.get_score": [[112, 114], ["force_channel.HMMTrainer.model.score"], "methods", ["None"], ["", "def", "get_score", "(", "self", ",", "input_data", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "score", "(", "input_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.force_channel.next_batch": [[171, 180], ["min", "len", "len", "min", "min", "min", "len", "len", "len"], "function", ["None"], ["def", "next_batch", "(", "batch_size", ")", ":", "\n", "    ", "global", "batchid", "\n", "if", "batchid", "+", "batch_size", ">", "len", "(", "train_x", ")", ":", "\n", "       ", "batchid", "=", "0", "\n", "", "batch_data", "=", "(", "train_x", "[", "batchid", ":", "min", "(", "batchid", "+", "batch_size", ",", "len", "(", "newli_train", ")", ")", ",", ":", "]", ")", "\n", "batch_labels", "=", "(", "newli_train", "[", "batchid", ":", "min", "(", "batchid", "+", "batch_size", ",", "len", "(", "newli_train", ")", ")", ",", ":", "]", ")", "\n", "batch_labels_1d", "=", "(", "train_y", "[", "batchid", ":", "min", "(", "batchid", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", "]", ")", "\n", "batchid", "=", "min", "(", "batchid", "+", "batch_size", ",", "len", "(", "newli_train", ")", ")", "\n", "return", "batch_data", ",", "batch_labels", ",", "batch_labels_1d", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.force_channel.RNN": [[208, 233], ["tensorflow.transpose", "tensorflow.reshape", "tensorflow.split", "rnn_cell_GRU.GRUCell", "rnn_cell_GRU.DropoutWrapper", "rnn_cell_GRU.MultiRNNCell", "rnn.rnn", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn.rnn"], ["", "def", "RNN", "(", "x", ",", "weights", ",", "biases", ")", ":", "\n", "\n", "# Prepare data shape to match `rnn` function requirements", "\n", "# Current data input shape: (batch_size, n_steps, n_input)", "\n", "# Required shape: 'n_steps' tensors list of shape (batch_size, n_input)", "\n", "\n", "# Permuting batch_size and n_steps", "\n", "    ", "x", "=", "tf", ".", "transpose", "(", "x", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "# Reshaping to (n_steps*batch_size, n_input)", "\n", "x", "=", "tf", ".", "reshape", "(", "tensor", "=", "x", ",", "shape", "=", "[", "-", "1", ",", "n_input", "]", ")", "\n", "# Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)", "\n", "x", "=", "tf", ".", "split", "(", "value", "=", "x", ",", "num_or_size_splits", "=", "n_steps", ",", "axis", "=", "0", ")", "\n", "# Define a lstm cell with tensorflow", "\n", "#lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1)", "\n", "lstm_cell", "=", "rnn_cell", ".", "GRUCell", "(", "n_hidden", ")", "\n", "#lstm_cell = rnn_cell.LSTMCell(n_hidden,use_peepholes=True)", "\n", "# avoid overfitting", "\n", "lstm_cell", "=", "rnn_cell", ".", "DropoutWrapper", "(", "lstm_cell", ",", "output_keep_prob", "=", "0.5", ")", "\n", "# 2 layers lstm", "\n", "lstm_cell", "=", "rnn_cell", ".", "MultiRNNCell", "(", "[", "lstm_cell", "]", "*", "2", ")", "\n", "# Get lstm cell output", "\n", "outputs", ",", "states", "=", "rnn", ".", "rnn", "(", "cell", "=", "lstm_cell", ",", "inputs", "=", "x", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "# Linear activation, using rnn inner loop last output", "\n", "return", "tf", ".", "matmul", "(", "outputs", "[", "-", "1", "]", ",", "weights", "[", "'out'", "]", ")", "+", "biases", "[", "'out'", "]", ",", "outputs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.time_channel.HMMTrainer.__init__": [[90, 106], ["hmmlearn.hmm.GaussianHMM", "hmmlearn.hmm.GMMHMM"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model_name", "=", "'GaussianHMM'", ",", "n_components", "=", "10", ",", "cov_type", "=", "'diag'", ",", "n_iter", "=", "20", ")", ":", "\n", "#\u6a21\u578b\u540d\u79f0 hmmlearn\u5b9e\u73b0\u4e86\u4e09\u79cdHMM\u6a21\u578b\u7c7b\uff0cGaussianHMM\u548cGMMHMM\u662f\u8fde\u7eed\u89c2\u6d4b\u72b6\u6001\u7684HMM\u6a21\u578b\uff0cMultinomialHMM\u662f\u79bb\u6563\u89c2\u6d4b\u72b6\u6001\u7684\u6a21\u578b", "\n", "        ", "self", ".", "model", "=", "None", "\n", "self", ".", "model_name", "=", "model_name", "\n", "#\u9690\u85cf\u72b6\u6001\u4e2a\u6570", "\n", "self", ".", "n_components", "=", "n_components", "\n", "#\u8f6c\u79fb\u77e9\u9635\u534f\u65b9\u5dee\u7c7b\u578b", "\n", "self", ".", "cov_type", "=", "cov_type", "\n", "#\u8bad\u7ec3\u8fed\u4ee3\u6b21\u6570", "\n", "self", ".", "n_iter", "=", "n_iter", "\n", "self", ".", "models", "=", "[", "]", "\n", "if", "self", ".", "model_name", "==", "'GaussianHMM'", ":", "\n", "            ", "self", ".", "model", "=", "hmm", ".", "GaussianHMM", "(", "n_components", "=", "self", ".", "n_components", ",", "covariance_type", "=", "self", ".", "cov_type", ",", "n_iter", "=", "self", ".", "n_iter", ")", "\n", "", "else", ":", "\n", "#            self.model = hmm.MultinomialHMM(n_components=self.n_components, n_iter=self.n_iter, tol=0.01)", "\n", "            ", "self", ".", "model", "=", "hmm", ".", "GMMHMM", "(", "n_components", "=", "self", ".", "n_components", ",", "n_iter", "=", "self", ".", "n_iter", ",", "tol", "=", "0.01", ")", "\n", "#            raise TypeError('Invalid model type')", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.time_channel.HMMTrainer.train": [[109, 112], ["numpy.seterr", "time_channel.HMMTrainer.models.append", "time_channel.HMMTrainer.model.fit"], "methods", ["None"], ["", "", "def", "train", "(", "self", ",", "X", ")", ":", "\n", "        ", "np", ".", "seterr", "(", "all", "=", "'ignore'", ")", "\n", "self", ".", "models", ".", "append", "(", "self", ".", "model", ".", "fit", "(", "X", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.time_channel.HMMTrainer.get_score": [[114, 116], ["time_channel.HMMTrainer.model.score"], "methods", ["None"], ["", "def", "get_score", "(", "self", ",", "input_data", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "score", "(", "input_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.time_channel.next_batch": [[174, 183], ["min", "len", "len", "min", "min", "min", "len", "len", "len"], "function", ["None"], ["def", "next_batch", "(", "batch_size", ")", ":", "\n", "    ", "global", "batchid", "\n", "if", "batchid", "+", "batch_size", ">", "len", "(", "train_x", ")", ":", "\n", "       ", "batchid", "=", "0", "\n", "", "batch_data", "=", "(", "train_x", "[", "batchid", ":", "min", "(", "batchid", "+", "batch_size", ",", "len", "(", "newli_train", ")", ")", ",", ":", "]", ")", "\n", "batch_labels", "=", "(", "newli_train", "[", "batchid", ":", "min", "(", "batchid", "+", "batch_size", ",", "len", "(", "newli_train", ")", ")", ",", ":", "]", ")", "\n", "batch_labels_1d", "=", "(", "train_y", "[", "batchid", ":", "min", "(", "batchid", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", "]", ")", "\n", "batchid", "=", "min", "(", "batchid", "+", "batch_size", ",", "len", "(", "newli_train", ")", ")", "\n", "return", "batch_data", ",", "batch_labels", ",", "batch_labels_1d", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.time_channel.RNN": [[211, 236], ["tensorflow.transpose", "tensorflow.reshape", "tensorflow.split", "rnn_cell_GRU.GRUCell", "rnn_cell_GRU.DropoutWrapper", "rnn_cell_GRU.MultiRNNCell", "rnn.rnn", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn.rnn"], ["", "def", "RNN", "(", "x", ",", "weights", ",", "biases", ")", ":", "\n", "\n", "# Prepare data shape to match `rnn` function requirements", "\n", "# Current data input shape: (batch_size, n_steps, n_input)", "\n", "# Required shape: 'n_steps' tensors list of shape (batch_size, n_input)", "\n", "\n", "# Permuting batch_size and n_steps", "\n", "    ", "x", "=", "tf", ".", "transpose", "(", "x", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "# Reshaping to (n_steps*batch_size, n_input)", "\n", "x", "=", "tf", ".", "reshape", "(", "tensor", "=", "x", ",", "shape", "=", "[", "-", "1", ",", "n_input", "]", ")", "\n", "# Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)", "\n", "x", "=", "tf", ".", "split", "(", "value", "=", "x", ",", "num_or_size_splits", "=", "n_steps", ",", "axis", "=", "0", ")", "\n", "# Define a lstm cell with tensorflow", "\n", "#lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1)", "\n", "lstm_cell", "=", "rnn_cell", ".", "GRUCell", "(", "n_hidden", ")", "\n", "#lstm_cell = rnn_cell.LSTMCell(n_hidden,use_peepholes=True)", "\n", "# avoid overfitting", "\n", "lstm_cell", "=", "rnn_cell", ".", "DropoutWrapper", "(", "lstm_cell", ",", "output_keep_prob", "=", "0.5", ")", "\n", "# 2 layers lstm", "\n", "lstm_cell", "=", "rnn_cell", ".", "MultiRNNCell", "(", "[", "lstm_cell", "]", "*", "2", ")", "\n", "# Get lstm cell output", "\n", "outputs", ",", "states", "=", "rnn", ".", "rnn", "(", "cell", "=", "lstm_cell", ",", "inputs", "=", "x", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "# Linear activation, using rnn inner loop last output", "\n", "return", "tf", ".", "matmul", "(", "outputs", "[", "-", "1", "]", ",", "weights", "[", "'out'", "]", ")", "+", "biases", "[", "'out'", "]", ",", "outputs", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.dictionary": [[10, 16], ["cv2.EM", "cv2.EM.train", "numpy.float32", "numpy.float32", "cv2.EM.getMat", "cv2.EM.getMatVector", "numpy.float32", "cv2.EM.getMat"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.train"], ["def", "dictionary", "(", "descriptors", ",", "N", ")", ":", "\n", "\t", "em", "=", "cv2", ".", "EM", "(", "N", ")", "\n", "em", ".", "train", "(", "descriptors", ")", "\n", "\n", "return", "np", ".", "float32", "(", "em", ".", "getMat", "(", "\"means\"", ")", ")", ",", "np", ".", "float32", "(", "em", ".", "getMatVector", "(", "\"covs\"", ")", ")", ",", "np", ".", "float32", "(", "em", ".", "getMat", "(", "\"weights\"", ")", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.image_descriptors": [[17, 22], ["cv2.imread", "cv2.resize", "cv2.SIFT().detectAndCompute", "cv2.SIFT"], "function", ["None"], ["", "def", "image_descriptors", "(", "file", ")", ":", "\n", "\t", "img", "=", "cv2", ".", "imread", "(", "file", ",", "0", ")", "\n", "img", "=", "cv2", ".", "resize", "(", "img", ",", "(", "256", ",", "256", ")", ")", "\n", "_", ",", "descriptors", "=", "cv2", ".", "SIFT", "(", ")", ".", "detectAndCompute", "(", "img", ",", "None", ")", "\n", "return", "descriptors", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.folder_descriptors": [[23, 27], ["glob.glob", "print", "numpy.concatenate", "len", "fisher.image_descriptors"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.image_descriptors"], ["", "def", "folder_descriptors", "(", "folder", ")", ":", "\n", "\t", "files", "=", "glob", ".", "glob", "(", "folder", "+", "\"/*.jpg\"", ")", "\n", "print", "(", "\"Calculating descriptos. Number of images is\"", ",", "len", "(", "files", ")", ")", "\n", "return", "np", ".", "concatenate", "(", "[", "image_descriptors", "(", "file", ")", "for", "file", "in", "files", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.likelihood_moment": [[28, 31], ["numpy.power", "numpy.float32", "numpy.float32"], "function", ["None"], ["", "def", "likelihood_moment", "(", "x", ",", "ytk", ",", "moment", ")", ":", "\n", "\t", "x_moment", "=", "np", ".", "power", "(", "np", ".", "float32", "(", "x", ")", ",", "moment", ")", "if", "moment", ">", "0", "else", "np", ".", "float32", "(", "[", "1", "]", ")", "\n", "return", "x_moment", "*", "ytk", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.likelihood_statistics": [[32, 50], ["zip", "range", "range", "scipy.stats.multivariate_normal", "numpy.array", "len", "len", "range", "numpy.multiply", "len", "g_k.pdf", "numpy.sum", "fisher.likelihood_moment", "fisher.likelihood_moment", "fisher.likelihood_moment"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.likelihood_moment", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.likelihood_moment", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.likelihood_moment"], ["", "def", "likelihood_statistics", "(", "samples", ",", "means", ",", "covs", ",", "weights", ")", ":", "\n", "\t", "gaussians", ",", "s0", ",", "s1", ",", "s2", "=", "{", "}", ",", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "samples", "=", "zip", "(", "range", "(", "0", ",", "len", "(", "samples", ")", ")", ",", "samples", ")", "\n", "\n", "g", "=", "[", "multivariate_normal", "(", "mean", "=", "means", "[", "k", "]", ",", "cov", "=", "covs", "[", "k", "]", ")", "for", "k", "in", "range", "(", "0", ",", "len", "(", "weights", ")", ")", "]", "\n", "for", "index", ",", "x", "in", "samples", ":", "\n", "\t\t", "gaussians", "[", "index", "]", "=", "np", ".", "array", "(", "[", "g_k", ".", "pdf", "(", "x", ")", "for", "g_k", "in", "g", "]", ")", "\n", "\n", "", "for", "k", "in", "range", "(", "0", ",", "len", "(", "weights", ")", ")", ":", "\n", "\t\t", "s0", "[", "k", "]", ",", "s1", "[", "k", "]", ",", "s2", "[", "k", "]", "=", "0", ",", "0", ",", "0", "\n", "for", "index", ",", "x", "in", "samples", ":", "\n", "\t\t\t", "probabilities", "=", "np", ".", "multiply", "(", "gaussians", "[", "index", "]", ",", "weights", ")", "\n", "probabilities", "=", "probabilities", "/", "np", ".", "sum", "(", "probabilities", ")", "\n", "s0", "[", "k", "]", "=", "s0", "[", "k", "]", "+", "likelihood_moment", "(", "x", ",", "probabilities", "[", "k", "]", ",", "0", ")", "\n", "s1", "[", "k", "]", "=", "s1", "[", "k", "]", "+", "likelihood_moment", "(", "x", ",", "probabilities", "[", "k", "]", ",", "1", ")", "\n", "s2", "[", "k", "]", "=", "s2", "[", "k", "]", "+", "likelihood_moment", "(", "x", ",", "probabilities", "[", "k", "]", ",", "2", ")", "\n", "\n", "", "", "return", "s0", ",", "s1", ",", "s2", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.fisher_vector_weights": [[51, 53], ["numpy.float32", "numpy.sqrt", "range", "len"], "function", ["None"], ["", "def", "fisher_vector_weights", "(", "s0", ",", "s1", ",", "s2", ",", "means", ",", "covs", ",", "w", ",", "T", ")", ":", "\n", "\t", "return", "np", ".", "float32", "(", "[", "(", "(", "s0", "[", "k", "]", "-", "T", "*", "w", "[", "k", "]", ")", "/", "np", ".", "sqrt", "(", "w", "[", "k", "]", ")", ")", "for", "k", "in", "range", "(", "0", ",", "len", "(", "w", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.fisher_vector_means": [[54, 56], ["numpy.float32", "numpy.sqrt", "range", "len"], "function", ["None"], ["", "def", "fisher_vector_means", "(", "s0", ",", "s1", ",", "s2", ",", "means", ",", "sigma", ",", "w", ",", "T", ")", ":", "\n", "\t", "return", "np", ".", "float32", "(", "[", "(", "s1", "[", "k", "]", "-", "means", "[", "k", "]", "*", "s0", "[", "k", "]", ")", "/", "(", "np", ".", "sqrt", "(", "w", "[", "k", "]", "*", "sigma", "[", "k", "]", ")", ")", "for", "k", "in", "range", "(", "0", ",", "len", "(", "w", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.fisher_vector_sigma": [[57, 59], ["numpy.float32", "range", "numpy.sqrt", "len"], "function", ["None"], ["", "def", "fisher_vector_sigma", "(", "s0", ",", "s1", ",", "s2", ",", "means", ",", "sigma", ",", "w", ",", "T", ")", ":", "\n", "\t", "return", "np", ".", "float32", "(", "[", "(", "s2", "[", "k", "]", "-", "2", "*", "means", "[", "k", "]", "*", "s1", "[", "k", "]", "+", "(", "means", "[", "k", "]", "*", "means", "[", "k", "]", "-", "sigma", "[", "k", "]", ")", "*", "s0", "[", "k", "]", ")", "/", "(", "np", ".", "sqrt", "(", "2", "*", "w", "[", "k", "]", ")", "*", "sigma", "[", "k", "]", ")", "for", "k", "in", "range", "(", "0", ",", "len", "(", "w", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.normalize": [[60, 63], ["numpy.sqrt", "numpy.sign", "numpy.sqrt", "abs", "numpy.dot"], "function", ["None"], ["", "def", "normalize", "(", "fisher_vector", ")", ":", "\n", "\t", "v", "=", "np", ".", "sqrt", "(", "abs", "(", "fisher_vector", ")", ")", "*", "np", ".", "sign", "(", "fisher_vector", ")", "\n", "return", "v", "/", "np", ".", "sqrt", "(", "np", ".", "dot", "(", "v", ",", "v", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.fisher_vector": [[64, 74], ["fisher.likelihood_statistics", "numpy.float32", "fisher.fisher_vector_weights", "fisher.fisher_vector_means", "fisher.fisher_vector_sigma", "numpy.concatenate", "fisher.normalize", "numpy.diagonal", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "range"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.likelihood_statistics", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.fisher_vector_weights", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.fisher_vector_means", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.fisher_vector_sigma", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.normalize"], ["", "def", "fisher_vector", "(", "samples", ",", "means", ",", "covs", ",", "w", ")", ":", "\n", "\t", "s0", ",", "s1", ",", "s2", "=", "likelihood_statistics", "(", "samples", ",", "means", ",", "covs", ",", "w", ")", "\n", "T", "=", "samples", ".", "shape", "[", "0", "]", "\n", "covs", "=", "np", ".", "float32", "(", "[", "np", ".", "diagonal", "(", "covs", "[", "k", "]", ")", "for", "k", "in", "range", "(", "0", ",", "covs", ".", "shape", "[", "0", "]", ")", "]", ")", "\n", "a", "=", "fisher_vector_weights", "(", "s0", ",", "s1", ",", "s2", ",", "means", ",", "covs", ",", "w", ",", "T", ")", "\n", "b", "=", "fisher_vector_means", "(", "s0", ",", "s1", ",", "s2", ",", "means", ",", "covs", ",", "w", ",", "T", ")", "\n", "c", "=", "fisher_vector_sigma", "(", "s0", ",", "s1", ",", "s2", ",", "means", ",", "covs", ",", "w", ",", "T", ")", "\n", "fv", "=", "np", ".", "concatenate", "(", "[", "np", ".", "concatenate", "(", "a", ")", ",", "np", ".", "concatenate", "(", "b", ")", ",", "np", ".", "concatenate", "(", "c", ")", "]", ")", "\n", "fv", "=", "normalize", "(", "fv", ")", "\n", "return", "fv", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.generate_gmm": [[75, 89], ["numpy.concatenate", "print", "fisher.dictionary", "numpy.float32", "numpy.float32", "numpy.float32", "numpy.save", "numpy.save", "numpy.save", "fisher.folder_descriptors", "glob.glob", "zip", "zip", "zip", "range", "range", "range", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.dictionary", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.folder_descriptors"], ["", "def", "generate_gmm", "(", "input_folder", ",", "N", ")", ":", "\n", "\t", "words", "=", "np", ".", "concatenate", "(", "[", "folder_descriptors", "(", "folder", ")", "for", "folder", "in", "glob", ".", "glob", "(", "input_folder", "+", "'/*'", ")", "]", ")", "\n", "print", "(", "\"Training GMM of size\"", ",", "N", ")", "\n", "means", ",", "covs", ",", "weights", "=", "dictionary", "(", "words", ",", "N", ")", "\n", "#Throw away gaussians with weights that are too small:", "\n", "th", "=", "1.0", "/", "N", "\n", "means", "=", "np", ".", "float32", "(", "[", "m", "for", "k", ",", "m", "in", "zip", "(", "range", "(", "0", ",", "len", "(", "weights", ")", ")", ",", "means", ")", "if", "weights", "[", "k", "]", ">", "th", "]", ")", "\n", "covs", "=", "np", ".", "float32", "(", "[", "m", "for", "k", ",", "m", "in", "zip", "(", "range", "(", "0", ",", "len", "(", "weights", ")", ")", ",", "covs", ")", "if", "weights", "[", "k", "]", ">", "th", "]", ")", "\n", "weights", "=", "np", ".", "float32", "(", "[", "m", "for", "k", ",", "m", "in", "zip", "(", "range", "(", "0", ",", "len", "(", "weights", ")", ")", ",", "weights", ")", "if", "weights", "[", "k", "]", ">", "th", "]", ")", "\n", "\n", "np", ".", "save", "(", "\"means.gmm\"", ",", "means", ")", "\n", "np", ".", "save", "(", "\"covs.gmm\"", ",", "covs", ")", "\n", "np", ".", "save", "(", "\"weights.gmm\"", ",", "weights", ")", "\n", "return", "means", ",", "covs", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.get_fisher_vectors_from_folder": [[90, 93], ["glob.glob", "numpy.float32", "fisher.fisher_vector", "fisher.image_descriptors"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.fisher_vector", "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.image_descriptors"], ["", "def", "get_fisher_vectors_from_folder", "(", "folder", ",", "gmm", ")", ":", "\n", "\t", "files", "=", "glob", ".", "glob", "(", "folder", "+", "\"/*.jpg\"", ")", "\n", "return", "np", ".", "float32", "(", "[", "fisher_vector", "(", "image_descriptors", "(", "file", ")", ",", "*", "gmm", ")", "for", "file", "in", "files", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.fisher_features": [[94, 98], ["glob.glob", "fisher.get_fisher_vectors_from_folder"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.get_fisher_vectors_from_folder"], ["", "def", "fisher_features", "(", "folder", ",", "gmm", ")", ":", "\n", "\t", "folders", "=", "glob", ".", "glob", "(", "folder", "+", "\"/*\"", ")", "\n", "features", "=", "{", "f", ":", "get_fisher_vectors_from_folder", "(", "f", ",", "gmm", ")", "for", "f", "in", "folders", "}", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.train": [[99, 106], ["numpy.concatenate", "numpy.concatenate", "sklearn.svm.SVC", "svm.SVC.fit", "features.values", "numpy.float32", "zip", "len", "range", "features.values", "len"], "function", ["None"], ["", "def", "train", "(", "gmm", ",", "features", ")", ":", "\n", "\t", "X", "=", "np", ".", "concatenate", "(", "features", ".", "values", "(", ")", ")", "\n", "Y", "=", "np", ".", "concatenate", "(", "[", "np", ".", "float32", "(", "[", "i", "]", "*", "len", "(", "v", ")", ")", "for", "i", ",", "v", "in", "zip", "(", "range", "(", "0", ",", "len", "(", "features", ")", ")", ",", "features", ".", "values", "(", ")", ")", "]", ")", "\n", "\n", "clf", "=", "svm", ".", "SVC", "(", ")", "\n", "clf", ".", "fit", "(", "X", ",", "Y", ")", "\n", "return", "clf", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.success_rate": [[107, 113], ["print", "numpy.concatenate", "numpy.concatenate", "numpy.array", "float", "len", "features.values", "numpy.float32", "sum", "zip", "len", "range", "features.values", "len", "zip", "classifier.predict"], "function", ["None"], ["", "def", "success_rate", "(", "classifier", ",", "features", ")", ":", "\n", "\t", "print", "(", "\"Applying the classifier...\"", ")", "\n", "X", "=", "np", ".", "concatenate", "(", "np", ".", "array", "(", "features", ".", "values", "(", ")", ")", ")", "\n", "Y", "=", "np", ".", "concatenate", "(", "[", "np", ".", "float32", "(", "[", "i", "]", "*", "len", "(", "v", ")", ")", "for", "i", ",", "v", "in", "zip", "(", "range", "(", "0", ",", "len", "(", "features", ")", ")", ",", "features", ".", "values", "(", ")", ")", "]", ")", "\n", "res", "=", "float", "(", "sum", "(", "[", "a", "==", "b", "for", "a", ",", "b", "in", "zip", "(", "classifier", ".", "predict", "(", "X", ")", ",", "Y", ")", "]", ")", ")", "/", "len", "(", "Y", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.load_gmm": [[114, 117], ["map", "map", "load"], "function", ["None"], ["", "def", "load_gmm", "(", "folder", "=", "\"\"", ")", ":", "\n", "\t", "files", "=", "[", "\"means.gmm.npy\"", ",", "\"covs.gmm.npy\"", ",", "\"weights.gmm.npy\"", "]", "\n", "return", "map", "(", "lambda", "file", ":", "load", "(", "file", ")", ",", "map", "(", "lambda", "s", ":", "folder", "+", "\"/\"", ",", "files", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.fisher.get_args": [[118, 125], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'-d'", ",", "\"--dir\"", ",", "help", "=", "\"Directory with images\"", ",", "default", "=", "'.'", ")", "\n", "parser", ".", "add_argument", "(", "\"-g\"", ",", "\"--loadgmm\"", ",", "help", "=", "\"Load Gmm dictionary\"", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'-n'", ",", "\"--number\"", ",", "help", "=", "\"Number of words in dictionary\"", ",", "default", "=", "5", ",", "type", "=", "int", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.twochannels.labelprocess": [[38, 44], ["len", "numpy.zeros", "enumerate", "int"], "function", ["None"], ["def", "labelprocess", "(", "label", ",", "n_class", "=", "4", ")", ":", "\n", "    ", "label_length", "=", "len", "(", "label", ")", "\n", "label_matrix", "=", "np", ".", "zeros", "(", "(", "label_length", ",", "n_class", ")", ")", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "label", ")", ":", "\n", "       ", "label_matrix", "[", "i", ",", "n_class", "-", "int", "(", "j", ")", "]", "=", "1", "\n", "", "return", "label_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.twochannels.next_batch": [[46, 64], ["min", "min", "len", "len", "len", "len", "min", "min", "min", "min", "len", "min", "min", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "next_batch", "(", "batch_size", ",", "train_x", ",", "train_y", ",", "newli_train", ",", "force", ")", ":", "\n", "    ", "global", "batchid_force", ",", "batchid_time", "\n", "if", "force", "==", "True", ":", "\n", "        ", "if", "batchid_force", "+", "batch_size", ">", "len", "(", "train_x", ")", ":", "\n", "           ", "batchid_force", "=", "0", "\n", "", "batch_data", "=", "(", "train_x", "[", "batchid_force", ":", "min", "(", "batchid_force", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", ",", ":", "]", ")", "\n", "batch_labels", "=", "(", "newli_train", "[", "batchid_force", ":", "min", "(", "batchid_force", "+", "batch_size", ",", "len", "(", "newli_train", ")", ")", ",", ":", "]", ")", "\n", "batch_labels_1d", "=", "(", "train_y", "[", "batchid_force", ":", "min", "(", "batchid_force", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", "]", ")", "\n", "batchid_force", "=", "min", "(", "batchid_force", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", "\n", "return", "batch_data", ",", "batch_labels", ",", "batch_labels_1d", "\n", "", "else", ":", "\n", "        ", "if", "batchid_time", "+", "batch_size", ">", "len", "(", "train_x", ")", ":", "\n", "           ", "batchid_time", "=", "0", "\n", "", "batch_data", "=", "(", "train_x", "[", "batchid_time", ":", "min", "(", "batchid_time", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", ",", ":", "]", ")", "\n", "batch_labels", "=", "(", "newli_train", "[", "batchid_time", ":", "min", "(", "batchid_time", "+", "batch_size", ",", "len", "(", "newli_train", ")", ")", ",", ":", "]", ")", "\n", "batch_labels_1d", "=", "(", "train_y", "[", "batchid_time", ":", "min", "(", "batchid_time", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", "]", ")", "\n", "batchid_time", "=", "min", "(", "batchid_time", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", "\n", "return", "batch_data", ",", "batch_labels", ",", "batch_labels_1d", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.twochannels.RNN": [[67, 88], ["tensorflow.transpose", "tensorflow.reshape", "tensorflow.split", "rnn_cell_GRU.GRUCell", "rnn_cell_GRU.DropoutWrapper", "rnn_cell_GRU.MultiRNNCell", "rnn.rnn", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.rnn.rnn"], ["", "", "def", "RNN", "(", "x", ",", "weights", ",", "biases", ",", "n_input", ")", ":", "\n", "    ", "x", "=", "tf", ".", "transpose", "(", "x", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "# Reshaping to (n_steps*batch_size, n_input)", "\n", "x", "=", "tf", ".", "reshape", "(", "tensor", "=", "x", ",", "shape", "=", "[", "-", "1", ",", "n_input", "]", ")", "\n", "# Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)", "\n", "x", "=", "tf", ".", "split", "(", "value", "=", "x", ",", "num_or_size_splits", "=", "n_steps", ",", "axis", "=", "0", ")", "\n", "# Define a lstm cell with tensorflow", "\n", "#lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1)", "\n", "lstm_cell", "=", "rnn_cell", ".", "GRUCell", "(", "n_hidden", ")", "\n", "#lstm_cell = rnn_cell.LSTMCell(n_hidden,use_peepholes=True)", "\n", "# avoid overfitting", "\n", "lstm_cell", "=", "rnn_cell", ".", "DropoutWrapper", "(", "lstm_cell", ",", "output_keep_prob", "=", "0.5", ")", "\n", "# 2 layers lstm", "\n", "#    num_units = [256, 256]", "\n", "#    cells = [rnn_cell.GRUCell(num_units=n) for n in num_units]", "\n", "#    lstm_cell = rnn_cell.MultiRNNCell(cells)", "\n", "lstm_cell", "=", "rnn_cell", ".", "MultiRNNCell", "(", "[", "lstm_cell", "]", "*", "2", ")", "\n", "# Get lstm cell output", "\n", "#    print(x)", "\n", "outputs", ",", "states", "=", "rnn", ".", "rnn", "(", "cell", "=", "lstm_cell", ",", "inputs", "=", "x", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "return", "tf", ".", "matmul", "(", "outputs", "[", "-", "1", "]", ",", "weights", ")", "+", "biases", ",", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.twochannels.feature_connect": [[90, 99], ["numpy.array", "range", "int", "numpy.array", "range", "numpy.transpose", "numpy.concatenate", "numpy.transpose"], "function", ["None"], ["", "def", "feature_connect", "(", "a_time", ",", "a_force", ")", ":", "\n", "    ", "a", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "for", "j", "in", "range", "(", "int", "(", "11340", "/", "15", ")", ")", ":", "\n", "        ", "f", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "for", "i", "in", "range", "(", "15", ")", ":", "\n", "            ", "f", "=", "np", ".", "concatenate", "(", "(", "f", ",", "a_force", "[", "j", "*", "15", "+", "i", ",", ":", "]", ")", ",", "axis", "=", "0", ")", "if", "f", ".", "size", "else", "a_force", "[", "j", "*", "15", "+", "i", ",", ":", "]", "\n", "", "a", "=", "np", ".", "c_", "[", "a", ",", "f", "]", "if", "a", ".", "size", "else", "f", "\n", "#    np.savetxt('./feature_extract/fusionfeature_data.txt', np.c_[a_time,np.transpose(a)],fmt='%.4f')", "\n", "", "return", "np", ".", "c_", "[", "a_time", ",", "np", ".", "transpose", "(", "a", ")", "]", ",", "np", ".", "transpose", "(", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.twochannels.softmax": [[101, 106], ["numpy.exp", "numpy.sum"], "function", ["None"], ["", "def", "softmax", "(", "x", ")", ":", "\n", "    ", "x_exp", "=", "np", ".", "exp", "(", "x", ")", "\n", "x_sum", "=", "np", ".", "sum", "(", "x_exp", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "s", "=", "x_exp", "/", "x_sum", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.linear_cca.linear_cca": [[4, 43], ["numpy.mean", "numpy.mean", "numpy.linalg.eigh", "numpy.linalg.eigh", "numpy.dot", "numpy.dot", "numpy.dot", "numpy.linalg.svd", "numpy.dot", "numpy.dot", "numpy.tile", "numpy.tile", "numpy.dot", "numpy.dot", "numpy.dot", "numpy.dot", "numpy.dot", "numpy.identity", "numpy.dot", "numpy.identity", "numpy.diag", "numpy.diag"], "function", ["None"], ["def", "linear_cca", "(", "H1", ",", "H2", ",", "outdim_size", ")", ":", "\n", "    ", "\"\"\"\n    An implementation of linear CCA\n    # Arguments:\n        H1 and H2: the matrices containing the data for view 1 and view 2. Each row is a sample.\n        outdim_size: specifies the number of new features\n    # Returns\n        A and B: the linear transformation matrices \n        mean1 and mean2: the means of data for both views\n    \"\"\"", "\n", "r1", "=", "1e-4", "\n", "r2", "=", "1e-4", "\n", "\n", "m", "=", "H1", ".", "shape", "[", "0", "]", "\n", "o", "=", "H1", ".", "shape", "[", "1", "]", "\n", "\n", "mean1", "=", "numpy", ".", "mean", "(", "H1", ",", "axis", "=", "0", ")", "\n", "mean2", "=", "numpy", ".", "mean", "(", "H2", ",", "axis", "=", "0", ")", "\n", "H1bar", "=", "H1", "-", "numpy", ".", "tile", "(", "mean1", ",", "(", "m", ",", "1", ")", ")", "\n", "H2bar", "=", "H2", "-", "numpy", ".", "tile", "(", "mean2", ",", "(", "m", ",", "1", ")", ")", "\n", "\n", "SigmaHat12", "=", "(", "1.0", "/", "(", "m", "-", "1", ")", ")", "*", "numpy", ".", "dot", "(", "H1bar", ".", "T", ",", "H2bar", ")", "\n", "SigmaHat11", "=", "(", "1.0", "/", "(", "m", "-", "1", ")", ")", "*", "numpy", ".", "dot", "(", "H1bar", ".", "T", ",", "H1bar", ")", "+", "r1", "*", "numpy", ".", "identity", "(", "o", ")", "\n", "SigmaHat22", "=", "(", "1.0", "/", "(", "m", "-", "1", ")", ")", "*", "numpy", ".", "dot", "(", "H2bar", ".", "T", ",", "H2bar", ")", "+", "r2", "*", "numpy", ".", "identity", "(", "o", ")", "\n", "\n", "[", "D1", ",", "V1", "]", "=", "numpy", ".", "linalg", ".", "eigh", "(", "SigmaHat11", ")", "\n", "[", "D2", ",", "V2", "]", "=", "numpy", ".", "linalg", ".", "eigh", "(", "SigmaHat22", ")", "\n", "SigmaHat11RootInv", "=", "numpy", ".", "dot", "(", "numpy", ".", "dot", "(", "V1", ",", "numpy", ".", "diag", "(", "D1", "**", "-", "0.5", ")", ")", ",", "V1", ".", "T", ")", "\n", "SigmaHat22RootInv", "=", "numpy", ".", "dot", "(", "numpy", ".", "dot", "(", "V2", ",", "numpy", ".", "diag", "(", "D2", "**", "-", "0.5", ")", ")", ",", "V2", ".", "T", ")", "\n", "\n", "Tval", "=", "numpy", ".", "dot", "(", "numpy", ".", "dot", "(", "SigmaHat11RootInv", ",", "SigmaHat12", ")", ",", "SigmaHat22RootInv", ")", "\n", "\n", "[", "U", ",", "D", ",", "V", "]", "=", "numpy", ".", "linalg", ".", "svd", "(", "Tval", ")", "\n", "V", "=", "V", ".", "T", "\n", "A", "=", "numpy", ".", "dot", "(", "SigmaHat11RootInv", ",", "U", "[", ":", ",", "0", ":", "outdim_size", "]", ")", "\n", "B", "=", "numpy", ".", "dot", "(", "SigmaHat22RootInv", ",", "V", "[", ":", ",", "0", ":", "outdim_size", "]", ")", "\n", "D", "=", "D", "[", "0", ":", "outdim_size", "]", "\n", "\n", "return", "A", ",", "B", ",", "mean1", ",", "mean2", "\n", "", ""]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.cnn.labelprocess": [[19, 25], ["len", "numpy.zeros", "enumerate", "int"], "function", ["None"], ["def", "labelprocess", "(", "label", ",", "n_class", "=", "n_classes", ")", ":", "\n", "    ", "label_length", "=", "len", "(", "label", ")", "\n", "label_matrix", "=", "np", ".", "zeros", "(", "(", "label_length", ",", "n_class", ")", ")", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "label", ")", ":", "\n", "       ", "label_matrix", "[", "i", ",", "int", "(", "j", ")", "]", "=", "1", "\n", "", "return", "label_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.zhaoaite_CorrMNN.None.cnn.next_batch": [[26, 34], ["min", "len", "len", "min", "min", "len", "len"], "function", ["None"], ["", "def", "next_batch", "(", "batch_size", ",", "train_x", ",", "train_y", ")", ":", "\n", "    ", "global", "batchid", "\n", "if", "batchid", "+", "batch_size", ">", "len", "(", "train_x", ")", ":", "\n", "       ", "batchid", "=", "0", "\n", "", "batch_data", "=", "(", "train_x", "[", "batchid", ":", "min", "(", "batchid", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", ",", ":", "]", ")", "\n", "batch_labels", "=", "(", "train_y", "[", "batchid", ":", "min", "(", "batchid", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", "]", ")", "\n", "batchid", "=", "min", "(", "batchid", "+", "batch_size", ",", "len", "(", "train_y", ")", ")", "\n", "return", "batch_data", ",", "batch_labels", "\n", "\n"]]}