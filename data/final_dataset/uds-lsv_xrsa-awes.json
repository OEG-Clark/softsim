{"home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.Vocabulary.__init__": [[24, 35], ["nn_speech_models.Vocabulary._symbol2idx.items"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "symbol2idx", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args: symbol2idx (dict): a pre-existing map of symbols to indices\n        \"\"\"", "\n", "if", "symbol2idx", "is", "None", ":", "\n", "            ", "symbol2idx", "=", "{", "}", "\n", "\n", "", "self", ".", "_symbol2idx", "=", "symbol2idx", "\n", "\n", "self", ".", "_idx2symbol", "=", "{", "\n", "idx", ":", "symbol", "for", "symbol", ",", "idx", "in", "self", ".", "_symbol2idx", ".", "items", "(", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.Vocabulary.add_symbol": [[38, 52], ["len"], "methods", ["None"], ["", "def", "add_symbol", "(", "self", ",", "symbol", ")", ":", "\n", "        ", "\"\"\"Update mapping dicts based on the symbol.\n        Args: symbol (str): the item to add into the Vocabulary\n        Returns: index (int): the integer corresponding to the symbol\n        \"\"\"", "\n", "if", "symbol", "in", "self", ".", "_symbol2idx", ":", "\n", "            ", "index", "=", "self", ".", "_symbol2idx", "[", "symbol", "]", "\n", "\n", "", "else", ":", "\n", "            ", "index", "=", "len", "(", "self", ".", "_symbol2idx", ")", "\n", "self", ".", "_symbol2idx", "[", "symbol", "]", "=", "index", "\n", "self", ".", "_idx2symbol", "[", "index", "]", "=", "symbol", "\n", "\n", "", "return", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.Vocabulary.add_many": [[54, 60], ["nn_speech_models.Vocabulary.add_symbol"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.Vocabulary.add_symbol"], ["", "def", "add_many", "(", "self", ",", "symbols", ")", ":", "\n", "        ", "\"\"\"Add a list of symbols into the Vocabulary\n        Args: symbols (list): a list of string symbols\n        Returns: indices (list): a list of indices corresponding to the symbols\n        \"\"\"", "\n", "return", "[", "self", ".", "add_symbol", "(", "symbol", ")", "for", "symbol", "in", "symbols", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.Vocabulary.lookup_symbol": [[62, 69], ["None"], "methods", ["None"], ["", "def", "lookup_symbol", "(", "self", ",", "symbol", ")", ":", "\n", "        ", "\"\"\"Retrieve the index associated with the symbol\n\n        Args: symbol (str): the symbol to look up\n        Returns: index (int): the index corresponding to the symbol\n        \"\"\"", "\n", "return", "self", ".", "_symbol2idx", "[", "symbol", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.Vocabulary.lookup_index": [[71, 82], ["KeyError"], "methods", ["None"], ["", "def", "lookup_index", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return the symbol associated with the index\n\n        Args: index (int): the index to look up\n        Returns: symbol (str): the symbol corresponding to the index\n        Raises: KeyError: if the index is not in the Vocabulary\n        \"\"\"", "\n", "if", "index", "not", "in", "self", ".", "_idx2symbol", ":", "\n", "            ", "raise", "KeyError", "(", "f\"the index {index} is not in the Vocabulary.\"", ")", "\n", "\n", "", "return", "self", ".", "_idx2symbol", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.Vocabulary.__str__": [[84, 86], ["len"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "f\"<Vocabulary(size={len(self)})>\"", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.Vocabulary.__len__": [[87, 89], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_symbol2idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.SequenceVocabulary.__init__": [[95, 114], ["nn_speech_models.Vocabulary.__init__", "nn_speech_models.SequenceVocabulary.add_symbol", "nn_speech_models.SequenceVocabulary.add_symbol", "nn_speech_models.SequenceVocabulary.add_symbol", "nn_speech_models.SequenceVocabulary.add_symbol"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__", "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.Vocabulary.add_symbol", "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.Vocabulary.add_symbol", "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.Vocabulary.add_symbol", "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.Vocabulary.add_symbol"], ["def", "__init__", "(", "self", ",", "\n", "symbol2idx", "=", "None", ",", "\n", "unk_symbol", "=", "\"<UNK>\"", ",", "\n", "mask_symbol", "=", "\"<MASK>\"", ",", "\n", "begin_seq_symbol", "=", "\"<BEGIN>\"", ",", "\n", "end_seq_symbol", "=", "\"<END>\"", "\n", ")", ":", "\n", "\n", "        ", "super", "(", "SequenceVocabulary", ",", "self", ")", ".", "__init__", "(", "symbol2idx", ")", "\n", "\n", "self", ".", "_mask_symbol", "=", "mask_symbol", "\n", "self", ".", "_unk_symbol", "=", "unk_symbol", "\n", "self", ".", "_begin_seq_symbol", "=", "begin_seq_symbol", "\n", "self", ".", "_end_seq_symbol", "=", "end_seq_symbol", "\n", "\n", "self", ".", "mask_index", "=", "self", ".", "add_symbol", "(", "self", ".", "_mask_symbol", ")", "\n", "self", ".", "unk_index", "=", "self", ".", "add_symbol", "(", "self", ".", "_unk_symbol", ")", "\n", "self", ".", "begin_seq_index", "=", "self", ".", "add_symbol", "(", "self", ".", "_begin_seq_symbol", ")", "\n", "self", ".", "end_seq_index", "=", "self", ".", "add_symbol", "(", "self", ".", "_end_seq_symbol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.SequenceVocabulary.lookup_symbol": [[117, 131], ["nn_speech_models.SequenceVocabulary._symbol2idx.get"], "methods", ["None"], ["", "def", "lookup_symbol", "(", "self", ",", "symbol", ")", ":", "\n", "        ", "\"\"\"Retrieve the index associated with the symbol\n          or the UNK index if symbol isn't present.\n\n        Args: symbol (str): the symbol to look up\n        Returns: index (int): the index corresponding to the symbol\n        Notes:\n            `unk_index` needs to be >=0 (having been added into the Vocabulary)\n              for the UNK functionality\n        \"\"\"", "\n", "if", "self", ".", "unk_index", ">=", "0", ":", "\n", "            ", "return", "self", ".", "_symbol2idx", ".", "get", "(", "symbol", ",", "self", ".", "unk_index", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_symbol2idx", "[", "symbol", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordFeaturizer.__init__": [[137, 173], ["collections.Counter", "max", "nn_speech_models.SequenceVocabulary", "map", "nn_speech_models.WordFeaturizer.char_vocab.add_symbol", "max", "map"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.Vocabulary.add_symbol"], ["def", "__init__", "(", "self", ",", "\n", "data_dir", ",", "\n", "acoustic_features", ",", "\n", "max_num_frames", ",", "\n", "spectral_dim", ",", "\n", "word_vocab", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            data_dir (str): the path to the data on disk to read .npy files\n            acoustic_features (str): low-level speech features, e.g., MFCCs\n            max_num_frames (int): the max number of acoustic frames in input\n                the diff. (max_num_frames - num_frames) is padded with zeros\n            spectral_dim (int): the num of spectral components (default 13)\n        \"\"\"", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "acoustic_features", "=", "acoustic_features", "\n", "self", ".", "max_num_frames", "=", "max_num_frames", "\n", "self", ".", "spectral_dim", "=", "spectral_dim", "\n", "self", ".", "word_vocab", "=", "word_vocab", "\n", "\n", "# make char vocab", "\n", "all_chars", "=", "[", "c", "for", "w", "in", "self", ".", "word_vocab", "for", "c", "in", "w", "]", "\n", "#self.char_set = set(all_chars)", "\n", "\n", "char_counter", "=", "Counter", "(", "all_chars", ")", "\n", "\n", "max_word_len", "=", "max", "(", "map", "(", "len", ",", "self", ".", "word_vocab", ")", ")", "\n", "\n", "self", ".", "char_vocab", "=", "SequenceVocabulary", "(", ")", "\n", "\n", "for", "char", "in", "char_counter", ":", "\n", "            ", "self", ".", "char_vocab", ".", "add_symbol", "(", "char", ")", "\n", "\n", "\n", "", "self", ".", "max_symbol_sequence_len", "=", "max", "(", "map", "(", "len", ",", "self", ".", "word_vocab", ")", ")", "+", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordFeaturizer.get_acoustic_form": [[174, 232], ["int", "int", "sklearn.preprocessing.scale", "sklearn.preprocessing.scale", "sklearn.preprocessing.scale", "sklearn.preprocessing.scale", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros.float", "torch.zeros.float", "numpy.load", "torch.randint().item", "torch.randint().item", "torch.randint().item", "torch.randint().item", "nn_speech_models.WordFeaturizer.acoustic_features.lower", "torch.randint", "torch.randint", "torch.randint", "torch.randint"], "methods", ["None"], ["", "def", "get_acoustic_form", "(", "self", ",", "\n", "segment_ID", ",", "\n", "segment_start", ",", "\n", "segment_end", ",", "\n", "max_num_frames", "=", "None", ",", "\n", "spectral_dim", "=", "None", ",", "\n", "is_CAE", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Given a segment ID and other variables of spectral features,\n        return a low-level spectral representation of word segment (e.g., MFCCs)\n        Args:\n            segment_ID (str): segment ID, i.e., the ID of word segment\n            max_num_frames (int): max length of the (MFCC) vector sequence\n            spectral_dim (int): the num of spectral coefficient (default 13)\n\n        Returns:\n            low-level speech representation as a PyTorch Tensor\n            (torch.Tensor: max_num_frames x spectral_dim)\n        \"\"\"", "\n", "# these were added to enable differet uttr lengths during inference", "\n", "if", "max_num_frames", "is", "None", ":", "max_num_frames", "=", "self", ".", "max_num_frames", "\n", "if", "spectral_dim", "is", "None", ":", "spectral_dim", "=", "self", ".", "spectral_dim", "\n", "\n", "# path to feature matrix (e.g. MFCCs saved in .npy file)", "\n", "file_name", "=", "self", ".", "data_dir", "+", "segment_ID", "+", "'.'", "+", "self", ".", "acoustic_features", ".", "lower", "(", ")", "+", "'.npy'", "#", "\n", "\n", "# load feature representation from desk", "\n", "_start_frame", "=", "int", "(", "segment_start", "*", "100", ")", "\n", "_end_frame", "=", "int", "(", "segment_end", "*", "100", ")", "\n", "acoustic_segment", "=", "np", ".", "load", "(", "file_name", ")", "[", ":", ",", "_start_frame", ":", "_end_frame", "]", "\n", "\n", "# scale feuture vector to have zero mean and unit var", "\n", "acoustic_segment", "=", "sklearn", ".", "preprocessing", ".", "scale", "(", "acoustic_segment", ",", "axis", "=", "1", ")", "\n", "\n", "# get word length in num of frames", "\n", "segment_len", "=", "acoustic_segment", ".", "shape", "[", "1", "]", "\n", "\n", "# assert that the word segment length is less than max num frames", "\n", "assert", "segment_len", "<", "max_num_frames", ",", "f\"Error: max num of frames error {segment_len}, {max_num_frames}\"", "\n", "\n", "# convert to pytorch tensor", "\n", "acoustic_tensor", "=", "torch", ".", "from_numpy", "(", "acoustic_segment", ")", "\n", "\n", "# apply padding to the segment represenation", "\n", "acoustic_tensor_pad", "=", "torch", ".", "zeros", "(", "spectral_dim", ",", "max_num_frames", ")", "\n", "\n", "# sample a random start index", "\n", "_start_idx", "=", "1", "if", "is_CAE", "else", "torch", ".", "randint", "(", "1", "+", "max_num_frames", "-", "segment_len", ",", "(", "1", ",", ")", ")", ".", "item", "(", ")", "\n", "\n", "\n", "acoustic_tensor_pad", "[", ":", "spectral_dim", ",", "_start_idx", ":", "_start_idx", "+", "segment_len", "]", "=", "acoustic_tensor", "[", ":", "spectral_dim", ",", ":", "segment_len", "]", "\n", "\n", "\n", "return", "acoustic_tensor_pad", ".", "float", "(", ")", "# convert to float tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordFeaturizer.get_symbolic_form": [[233, 269], ["indices.extend", "indices.append", "numpy.zeros", "nn_speech_models.WordFeaturizer.char_vocab.lookup_symbol", "len", "len"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.SequenceVocabulary.lookup_symbol"], ["", "def", "get_symbolic_form", "(", "self", ",", "\n", "symbol_sequence", ",", "\n", "#vector_length=-1,", "\n", "add_language_tok", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Given a segment ID and flag for language token embedding\n        return the symbolic sequence of the word form\n        Args:\n            segment_ID (str): segment ID, i.e., the ID of word segment\n            add_language_tok (bool): whether or not to add language token\n\n        Returns:\n            char sequence\n            (torch.Tensor: max_num_frames x spectral_dim)\n        \"\"\"", "\n", "\n", "# add first symbol BEGIN", "\n", "indices", "=", "[", "self", ".", "char_vocab", ".", "begin_seq_index", "]", "\n", "\n", "# add other tokens", "\n", "indices", ".", "extend", "(", "\n", "self", ".", "char_vocab", ".", "lookup_symbol", "(", "char", ")", "for", "char", "in", "symbol_sequence", "\n", ")", "\n", "\n", "# add last symbol END", "\n", "indices", ".", "append", "(", "self", ".", "char_vocab", ".", "end_seq_index", ")", "\n", "\n", "#if vector_length < 0:", "\n", "#   vector_length = len(indices)", "\n", "\n", "index_sequence", "=", "np", ".", "zeros", "(", "self", ".", "max_symbol_sequence_len", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "index_sequence", "[", ":", "len", "(", "indices", ")", "]", "=", "indices", "\n", "index_sequence", "[", "len", "(", "indices", ")", ":", "]", "=", "self", ".", "char_vocab", ".", "mask_index", "\n", "\n", "return", "index_sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordNgramFeaturizer.__init__": [[275, 313], ["collections.Counter", "nn_speech_models.WordNgramFeaturizer.get_ngram_weight_vector", "len", "nn_speech_models.WordNgramFeaturizer.get_ngrams", "nn_speech_models.WordNgramFeaturizer.ngram_counter.most_common", "enumerate", "nn_speech_models.WordNgramFeaturizer.ngram2index.items"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordNgramFeaturizer.get_ngram_weight_vector", "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordNgramFeaturizer.get_ngrams"], ["def", "__init__", "(", "self", ",", "\n", "data_dir", ",", "\n", "acoustic_features", ",", "\n", "max_num_frames", ",", "\n", "spectral_dim", ",", "\n", "word_vocab", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            data_dir (str): the path to the data on disk to read .npy files\n            acoustic_features (str): low-level speech features, e.g., MFCCs\n            max_num_frames (int): the max number of acoustic frames in input\n                the diff. (max_num_frames - num_frames) is padded with zeros\n            spectral_dim (int): the num of spectral components (default 13)\n        \"\"\"", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "acoustic_features", "=", "acoustic_features", "\n", "self", ".", "max_num_frames", "=", "max_num_frames", "\n", "self", ".", "spectral_dim", "=", "spectral_dim", "\n", "self", ".", "word_vocab", "=", "word_vocab", "\n", "\n", "all_ngrams", "=", "[", "\n", "ngram", "for", "w", "in", "word_vocab", "for", "ngram", "in", "self", ".", "get_ngrams", "(", "w", ")", "\n", "]", "\n", "\n", "self", ".", "ngram_counter", "=", "Counter", "(", "all_ngrams", ")", "\n", "\n", "self", ".", "ngram_set", "=", "[", "\n", "g", "for", "g", ",", "c", "in", "self", ".", "ngram_counter", ".", "most_common", "(", ")", "\n", "if", "self", ".", "ngram_counter", "[", "g", "]", ">", "100", "\n", "]", "\n", "\n", "self", ".", "ngram_weight_vector", "=", "self", ".", "get_ngram_weight_vector", "(", ")", "\n", "\n", "self", ".", "ngram2index", "=", "{", "g", ":", "i", "for", "i", ",", "g", "in", "enumerate", "(", "self", ".", "ngram_set", ")", "}", "\n", "self", ".", "index2ngram", "=", "{", "i", ":", "g", "for", "g", ",", "i", "in", "self", ".", "ngram2index", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "ngram_vector_size", "=", "len", "(", "self", ".", "ngram2index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordNgramFeaturizer.get_ngram_weight_vector": [[315, 323], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "nn_speech_models.WordNgramFeaturizer.ngram_counter.most_common", "len"], "methods", ["None"], ["", "def", "get_ngram_weight_vector", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return weight vecotr for the ngrams\"\"\"", "\n", "\n", "ngram_weight_vector", "=", "[", "\n", "500", "/", "c", "for", "g", ",", "c", "in", "self", ".", "ngram_counter", ".", "most_common", "(", "len", "(", "self", ".", "ngram_set", ")", ")", "\n", "]", "\n", "\n", "return", "torch", ".", "tensor", "(", "ngram_weight_vector", ")", "#, dtype=torch.float32", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordNgramFeaturizer.get_ngrams": [[325, 347], ["word.split", "range", "range", "len", "len"], "methods", ["None"], ["", "def", "get_ngrams", "(", "self", ",", "word", ")", ":", "\n", "        ", "\"\"\"Get a word (str), return a list of ngrams in the word.\n        Example:\n            >>> get_ngrams('ka\u017ee')\n            ['k', 'a', '\u017e', 'e', '#k', 'ka', 'a\u017e', '\u017ee', 'e#', '#ka', 'ka\u017e', 'a\u017ee', '\u017ee#']\n\n        \"\"\"", "\n", "#print(word.encode('utf-8'))", "\n", "word", "=", "[", "'#'", "]", "+", "word", ".", "split", "(", ")", "+", "[", "'#'", "]", "\n", "# extract unigrams", "\n", "#n_1grams = [word[i - 1] for i in range(1, len(word) + 1)]", "\n", "\n", "# extract bigrams & trigrams", "\n", "# append pseudo-tokens to the beginning & end of the word", "\n", "#word = '#' + word + '#'", "\n", "n_2grams", "=", "[", "''", ".", "join", "(", "[", "word", "[", "i", "-", "1", "]", ",", "word", "[", "i", "]", "]", ")", "for", "i", "in", "range", "(", "1", ",", "len", "(", "word", ")", ")", "]", "\n", "n_3grams", "=", "[", "''", ".", "join", "(", "[", "word", "[", "i", "-", "2", "]", ",", "word", "[", "i", "-", "1", "]", ",", "word", "[", "i", "]", "]", ")", "for", "i", "in", "range", "(", "2", ",", "len", "(", "word", ")", ")", "]", "\n", "\n", "ngrams", "=", "n_2grams", "+", "n_3grams", "#n_1grams+ n_3grams", "\n", "\n", "\n", "return", "ngrams", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordNgramFeaturizer.get_ngram_set": [[349, 372], ["nn_speech_models.WordNgramFeaturizer.get_ngrams", "set", "len"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordNgramFeaturizer.get_ngrams"], ["", "def", "get_ngram_set", "(", "self", ",", "\n", "symbol_sequence", ",", "\n", "return_index", "=", "True", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Given a symbol sequence, return ngrams in the symbol sequence up to n=3.\n        Args:\n            segment_ID (str): segment ID, i.e., the ID of word segment\n\n        Returns:\n            ngrams (set)\n        \"\"\"", "\n", "\n", "assert", "len", "(", "symbol_sequence", ")", ">", "0", ",", "\"Word should have at least one char.\"", "\n", "\n", "symbol_ngrams", "=", "self", ".", "get_ngrams", "(", "symbol_sequence", ")", "\n", "\n", "item_ngram_set", "=", "set", "(", "c", "for", "c", "in", "symbol_ngrams", "if", "c", "in", "self", ".", "ngram_set", ")", "\n", "\n", "if", "return_index", ":", "\n", "            ", "return", "{", "self", ".", "ngram2index", "[", "g", "]", "for", "g", "in", "item_ngram_set", "}", "\n", "", "else", ":", "\n", "            ", "return", "item_ngram_set", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordNgramFeaturizer.vectorize_ngram_set": [[374, 384], ["nn_speech_models.WordNgramFeaturizer.get_ngram_set", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "range"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordNgramFeaturizer.get_ngram_set"], ["", "", "def", "vectorize_ngram_set", "(", "self", ",", "symbol_sequence", ")", ":", "\n", "        ", "\"\"\"Get Given a symbol sequence, return ngrams as a binary vector\"\"\"", "\n", "\n", "ngram_set_by_index", "=", "self", ".", "get_ngram_set", "(", "symbol_sequence", ")", "\n", "ngram_vector", "=", "[", "\n", "1", "if", "i", "in", "ngram_set_by_index", "else", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "self", ".", "ngram_vector_size", ")", "\n", "]", "\n", "\n", "return", "torch", ".", "tensor", "(", "ngram_vector", ",", "dtype", "=", "torch", ".", "float32", ")", "#.unsqueeze(dim=0)", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordNgramFeaturizer.get_acoustic_form": [[386, 450], ["int", "int", "sklearn.preprocessing.scale", "sklearn.preprocessing.scale", "sklearn.preprocessing.scale", "sklearn.preprocessing.scale", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.randint().item", "torch.randint().item", "torch.randint().item", "torch.randint().item", "numpy.load", "nn_speech_models.WordNgramFeaturizer.acoustic_features.lower", "torch.randint", "torch.randint", "torch.randint", "torch.randint"], "methods", ["None"], ["", "def", "get_acoustic_form", "(", "self", ",", "\n", "segment_ID", ",", "\n", "segment_start", ",", "\n", "segment_end", ",", "\n", "max_num_frames", "=", "None", ",", "\n", "spectral_dim", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Given a segment ID and other variables of spectral features,\n        return a low-level spectral representation of word segment (e.g., MFCCs)\n        Args:\n            segment_ID (str): segment ID, i.e., the ID of word segment\n            max_num_frames (int): max length of the (MFCC) vector sequence\n            spectral_dim (int): the num of spectral coefficient (default 13)\n\n        Returns:\n            low-level speech representation as a PyTorch Tensor\n            (torch.Tensor: max_num_frames x spectral_dim)\n        \"\"\"", "\n", "# these were added to enable differet uttr lengths during inference", "\n", "if", "max_num_frames", "is", "None", ":", "max_num_frames", "=", "self", ".", "max_num_frames", "\n", "if", "spectral_dim", "is", "None", ":", "spectral_dim", "=", "self", ".", "spectral_dim", "\n", "\n", "# path to feature matrix (e.g. MFCCs saved in .npy file)", "\n", "file_name", "=", "self", ".", "data_dir", "+", "segment_ID", "+", "'.'", "+", "self", ".", "acoustic_features", ".", "lower", "(", ")", "+", "'.npy'", "#", "\n", "#self.acoustic_features.lower() + '.norm.npy' #", "\n", "\n", "# load feature representation from desk", "\n", "_start_frame", "=", "int", "(", "segment_start", "*", "100", ")", "\n", "_end_frame", "=", "int", "(", "segment_end", "*", "100", ")", "\n", "acoustic_segment", "=", "np", ".", "load", "(", "file_name", ")", "[", ":", ",", "_start_frame", ":", "_end_frame", "]", "\n", "\n", "# scale feuture vector to have zero mean and unit var", "\n", "acoustic_segment", "=", "sklearn", ".", "preprocessing", ".", "scale", "(", "acoustic_segment", ",", "axis", "=", "1", ")", "\n", "\n", "#print(acoustic_segment[:, :1])", "\n", "\n", "# get word length in num of frames", "\n", "segment_len", "=", "acoustic_segment", ".", "shape", "[", "1", "]", "\n", "\n", "# assert that the word segment length is less than max num frames", "\n", "assert", "segment_len", "<", "max_num_frames", ",", "f\"Error: max num of frames error {segment_len}, {max_num_frames}\"", "\n", "\n", "# convert to pytorch tensor", "\n", "acoustic_tensor", "=", "torch", ".", "from_numpy", "(", "acoustic_segment", ")", "\n", "\n", "#print(acoustic_tensor[:, :1])", "\n", "\n", "# apply padding to the segment represenation", "\n", "acoustic_tensor_pad", "=", "torch", ".", "zeros", "(", "spectral_dim", ",", "max_num_frames", ")", "\n", "\n", "# sample a random start index", "\n", "_start_idx", "=", "torch", ".", "randint", "(", "1", "+", "max_num_frames", "-", "segment_len", ",", "(", "1", ",", ")", ")", ".", "item", "(", ")", "\n", "\n", "\n", "acoustic_tensor_pad", "[", ":", "spectral_dim", ",", "_start_idx", ":", "_start_idx", "+", "segment_len", "]", "=", "acoustic_tensor", "[", ":", "spectral_dim", ",", ":", "segment_len", "]", "\n", "\n", "#print(acoustic_tensor_pad[:, _start_idx:_start_idx + 1])", "\n", "\n", "\n", "return", "acoustic_tensor_pad", "#.float() # convert to float tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordDataset.__init__": [[454, 487], ["len", "len", "len", "print", "nn_speech_models.WordDataset.set_mode"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordPairDataset.set_mode"], ["    ", "def", "__init__", "(", "self", ",", "dataset_df", ",", "featurizer", ",", "ngram_featurizer", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_df (pandas.df): a pandas dataframe (label, split, file)\n            featurizer (SpeechFeaturizer): the speech featurizer\n        \"\"\"", "\n", "self", ".", "dataset_df", "=", "dataset_df", "\n", "self", ".", "_word_featurizer", "=", "featurizer", "\n", "\n", "# read data and make splits", "\n", "self", ".", "train_df", "=", "self", ".", "dataset_df", "[", "self", ".", "dataset_df", ".", "split", "==", "'TRA'", "]", "\n", "self", ".", "train_size", "=", "len", "(", "self", ".", "train_df", ")", "\n", "\n", "self", ".", "val_df", "=", "self", ".", "dataset_df", "[", "self", ".", "dataset_df", ".", "split", "==", "'DEV'", "]", "\n", "self", ".", "val_size", "=", "len", "(", "self", ".", "val_df", ")", "\n", "\n", "self", ".", "test_df", "=", "self", ".", "dataset_df", "[", "self", ".", "dataset_df", ".", "split", "==", "'EVA'", "]", "\n", "self", ".", "test_size", "=", "len", "(", "self", ".", "test_df", ")", "\n", "\n", "print", "(", "'Size of the splits (train, val, test): '", ",", "self", ".", "train_size", ",", "self", ".", "val_size", ",", "self", ".", "test_size", ")", "\n", "\n", "self", ".", "_lookup_dict", "=", "{", "\n", "'TRA'", ":", "(", "self", ".", "train_df", ",", "self", ".", "train_size", ")", ",", "\n", "'DEV'", ":", "(", "self", ".", "val_df", ",", "self", ".", "val_size", ")", ",", "\n", "'EVA'", ":", "(", "self", ".", "test_df", ",", "self", ".", "test_size", ")", "\n", "}", "\n", "\n", "# by default set mode to train", "\n", "self", ".", "set_mode", "(", "split", "=", "'TRA'", ")", "\n", "\n", "\n", "self", ".", "vectorize_ngrams", "=", "ngram_featurizer", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordDataset.set_mode": [[489, 493], ["None"], "methods", ["None"], ["", "def", "set_mode", "(", "self", ",", "split", "=", "'TRA'", ")", ":", "\n", "         ", "\"\"\"Set the mode using the split column in the dataframe. \"\"\"", "\n", "self", ".", "_target_split", "=", "split", "\n", "self", ".", "_target_df", ",", "self", ".", "_target_size", "=", "self", ".", "_lookup_dict", "[", "split", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordDataset.__len__": [[495, 498], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"Returns the number of the data points in the target split.\"", "\n", "return", "self", ".", "_target_size", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordDataset.__getitem__": [[500, 537], ["nn_speech_models.WordDataset._word_featurizer.get_acoustic_form", "nn_speech_models.WordDataset._word_featurizer.vectorize_ngram_set", "nn_speech_models.WordDataset._word_featurizer.get_symbolic_form"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordNgramFeaturizer.get_acoustic_form", "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordNgramFeaturizer.vectorize_ngram_set", "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordFeaturizer.get_symbolic_form"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        A data transformation code for one data point in the dataset.\n        Args:\n            index (int): the index to the data point in the target dataframe\n        Returns:\n            a dictionary holding the point representation, e.g.,\n                acoustic view (x_acoustic), orth view (x_orth)\n        \"\"\"", "\n", "\n", "speech_segment", "=", "self", ".", "_target_df", ".", "iloc", "[", "index", "]", "\n", "\n", "# get acoustic form of the word", "\n", "acoustic_word", "=", "self", ".", "_word_featurizer", ".", "get_acoustic_form", "(", "\n", "segment_ID", "=", "speech_segment", ".", "seg_id", ",", "\n", "segment_start", "=", "speech_segment", ".", "start", ",", "\n", "segment_end", "=", "speech_segment", ".", "end", "\n", ")", "\n", "\n", "# get symbolic form of the word", "\n", "if", "self", ".", "vectorize_ngrams", ":", "\n", "            ", "symbolic_word", "=", "self", ".", "_word_featurizer", ".", "vectorize_ngram_set", "(", "\n", "#speech_segment.orth", "\n", "speech_segment", ".", "IPA", "\n", ")", "\n", "\n", "\n", "", "else", ":", "\n", "            ", "symbolic_word", "=", "self", ".", "_word_featurizer", ".", "get_symbolic_form", "(", "\n", "speech_segment", ".", "IPA", "\n", ")", "\n", "\n", "", "return", "{", "\n", "'acoustic_word'", ":", "acoustic_word", ",", "\n", "'symbolic_word'", ":", "symbolic_word", ",", "\n", "'orth_sequence'", ":", "speech_segment", ".", "orth", ",", "\n", "'word_seg_id'", ":", "speech_segment", ".", "word_id", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordDataset.get_num_batches": [[539, 544], ["math.ceil", "len"], "methods", ["None"], ["", "def", "get_num_batches", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Given batch size (int), return the number of dataset batches (int)\n        \"\"\"", "\n", "return", "math", ".", "ceil", "(", "(", "len", "(", "self", ")", "/", "batch_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordPairDataset.__init__": [[548, 587], ["len", "len", "len", "print", "nn_speech_models.WordPairDataset.set_mode"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordPairDataset.set_mode"], ["    ", "def", "__init__", "(", "self", ",", "dataset_df", ",", "featurizer", ",", "is_AE", "=", "False", ",", "is_CAE", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_df (pandas.df): a pandas dataframe (label, split, file)\n            featurizer (SpeechFeaturizer): the speech featurizer\n        \"\"\"", "\n", "self", ".", "dataset_df", "=", "dataset_df", "\n", "self", ".", "_word_featurizer", "=", "featurizer", "\n", "\n", "\n", "# for CAE", "\n", "self", ".", "is_CAE", "=", "is_CAE", "\n", "\n", "# for AE", "\n", "self", ".", "is_AE", "=", "is_AE", "\n", "\n", "# read data and make splits", "\n", "self", ".", "train_df", "=", "self", ".", "dataset_df", "[", "self", ".", "dataset_df", ".", "split", "==", "'TRA'", "]", "\n", "self", ".", "train_size", "=", "len", "(", "self", ".", "train_df", ")", "\n", "\n", "self", ".", "val_df", "=", "self", ".", "dataset_df", "[", "self", ".", "dataset_df", ".", "split", "==", "'DEV'", "]", "\n", "self", ".", "val_size", "=", "len", "(", "self", ".", "val_df", ")", "\n", "\n", "self", ".", "test_df", "=", "self", ".", "dataset_df", "[", "self", ".", "dataset_df", ".", "split", "==", "'EVA'", "]", "\n", "self", ".", "test_size", "=", "len", "(", "self", ".", "test_df", ")", "\n", "\n", "\n", "print", "(", "'Size of the splits (train, val, test): '", ",", "self", ".", "train_size", ",", "self", ".", "val_size", ",", "self", ".", "test_size", ")", "\n", "\n", "self", ".", "_lookup_dict", "=", "{", "\n", "'TRA'", ":", "(", "self", ".", "train_df", ",", "self", ".", "train_size", ")", ",", "\n", "'DEV'", ":", "(", "self", ".", "val_df", ",", "self", ".", "val_size", ")", ",", "\n", "'EVA'", ":", "(", "self", ".", "test_df", ",", "self", ".", "test_size", ")", "\n", "}", "\n", "\n", "\n", "# by default set mode to train", "\n", "self", ".", "set_mode", "(", "split", "=", "'TRA'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordPairDataset.set_mode": [[590, 594], ["None"], "methods", ["None"], ["", "def", "set_mode", "(", "self", ",", "split", "=", "'TRA'", ")", ":", "\n", "         ", "\"\"\"Set the mode using the split column in the dataframe. \"\"\"", "\n", "self", ".", "_target_split", "=", "split", "\n", "self", ".", "_target_df", ",", "self", ".", "_target_size", "=", "self", ".", "_lookup_dict", "[", "split", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordPairDataset.__len__": [[596, 599], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"Returns the number of the data points in the target split.\"", "\n", "return", "self", ".", "_target_size", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordPairDataset.__getitem__": [[601, 656], ["nn_speech_models.WordPairDataset._word_featurizer.get_acoustic_form", "nn_speech_models.WordPairDataset._word_featurizer.get_acoustic_form", "nn_speech_models.WordPairDataset._word_featurizer.get_acoustic_form", "nn_speech_models.WordPairDataset._target_df[].sample"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordNgramFeaturizer.get_acoustic_form", "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordNgramFeaturizer.get_acoustic_form", "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordNgramFeaturizer.get_acoustic_form"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        A data transformation code for one data point in the dataset.\n        Args:\n            index (int): the index to the data point in the target dataframe\n        Returns:\n            a dictionary holding the point representation, e.g.,\n                acoustic view (x_acoustic), orth view (x_orth)\n        \"\"\"", "\n", "\n", "speech_segment_ank", "=", "self", ".", "_target_df", ".", "iloc", "[", "index", "]", "\n", "\n", "# get acoustic form of the anchor point", "\n", "acoustic_word_ank", "=", "self", ".", "_word_featurizer", ".", "get_acoustic_form", "(", "\n", "segment_ID", "=", "speech_segment_ank", ".", "seg_id", ",", "\n", "segment_start", "=", "speech_segment_ank", ".", "start", ",", "\n", "segment_end", "=", "speech_segment_ank", ".", "end", "\n", ")", "\n", "\n", "# get acoustic form of a positive point", "\n", "# first sample a row from the target dataframe with same orth word", "\n", "condition", "=", "(", "self", ".", "_target_df", ".", "orth", "==", "speech_segment_ank", ".", "orth", ")", "\n", "speech_segment_pos", "=", "self", ".", "_target_df", "[", "condition", "]", ".", "sample", "(", "n", "=", "1", ")", ".", "iloc", "[", "0", "]", "#, random_state=1", "\n", "\n", "# get acoustic form for the positive point", "\n", "\n", "if", "self", ".", "is_AE", ":", "\n", "            ", "acoustic_word_pos", "=", "self", ".", "_word_featurizer", ".", "get_acoustic_form", "(", "\n", "segment_ID", "=", "speech_segment_ank", ".", "seg_id", ",", "\n", "segment_start", "=", "speech_segment_ank", ".", "start", ",", "\n", "segment_end", "=", "speech_segment_ank", ".", "end", ",", "\n", "is_CAE", "=", "self", ".", "is_CAE", "\n", ")", "\n", "\n", "return", "{", "\n", "'acoustic_word_view_1'", ":", "acoustic_word_ank", ",", "\n", "'acoustic_word_view_2'", ":", "acoustic_word_pos", ",", "\n", "'orth_sequence'", ":", "speech_segment_ank", ".", "orth", ",", "\n", "'word_seg_id'", ":", "speech_segment_ank", ".", "word_id", "\n", "}", "\n", "\n", "\n", "", "else", ":", "\n", "            ", "acoustic_word_pos", "=", "self", ".", "_word_featurizer", ".", "get_acoustic_form", "(", "\n", "segment_ID", "=", "speech_segment_pos", ".", "seg_id", ",", "\n", "segment_start", "=", "speech_segment_pos", ".", "start", ",", "\n", "segment_end", "=", "speech_segment_pos", ".", "end", ",", "\n", "is_CAE", "=", "self", ".", "is_CAE", "\n", ")", "\n", "\n", "return", "{", "\n", "'anchor_acoustic_word'", ":", "acoustic_word_ank", ",", "\n", "'positive_acoustic_word'", ":", "acoustic_word_pos", ",", "\n", "'orth_sequence'", ":", "speech_segment_ank", ".", "orth", ",", "\n", "'word_seg_id'", ":", "speech_segment_ank", ".", "word_id", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordPairDataset.get_num_batches": [[660, 665], ["math.ceil", "len"], "methods", ["None"], ["", "", "def", "get_num_batches", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Given batch size (int), return the number of dataset batches (int)\n        \"\"\"", "\n", "return", "math", ".", "ceil", "(", "(", "len", "(", "self", ")", "/", "batch_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.FrameDropout.__init__": [[698, 706], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dropout_prob", "=", "0.2", ")", ":", "\n", "        ", "\"\"\"Applies dropout on the frame level so entire feature vector will be\n            evaluated to zero vector with probability p.\n        Args:\n            p (float): dropout probability\n        \"\"\"", "\n", "super", "(", "FrameDropout", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout_prob", "=", "dropout_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.FrameDropout.forward": [[707, 717], ["range", "torch.rand().item", "torch.rand().item", "torch.rand().item", "torch.rand().item", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_in", ")", ":", "\n", "        ", "_", ",", "_", ",", "sequence_dim", "=", "x_in", ".", "shape", "\n", "\n", "# randomly sample frame indecies to be dropped", "\n", "drop_frame_idx", "=", "[", "i", "for", "i", "in", "range", "(", "sequence_dim", ")", "if", "torch", ".", "rand", "(", "1", ")", ".", "item", "(", ")", "<", "self", ".", "dropout_prob", "]", "\n", "\n", "x_in", "[", ":", ",", ":", ",", "drop_frame_idx", "]", "=", "0", "\n", "\n", "return", "x_in", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.SpectralDropout.__init__": [[721, 730], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dropout_prob", "=", "0.2", ",", "feature_idx", "=", "None", ")", ":", "\n", "        ", "\"\"\"Applies dropout on the feature level so spectral component accross\n             vectors are replaced with zero (row-)vector with probability p.\n        Args:\n            p (float): dropout probability\n            feature_idx (int): to mask specific spectral coeff. during inference\n        \"\"\"", "\n", "super", "(", "SpectralDropout", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout_prob", "=", "dropout_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.SpectralDropout.forward": [[731, 741], ["range", "torch.rand().item", "torch.rand().item", "torch.rand().item", "torch.rand().item", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_in", ")", ":", "\n", "        ", "batch_size", ",", "spectral_dim", ",", "sequence_dim", "=", "x_in", ".", "shape", "\n", "\n", "# randomly sample frame indecies to be dropped", "\n", "drop_feature_idx", "=", "[", "i", "for", "i", "in", "range", "(", "spectral_dim", ")", "if", "torch", ".", "rand", "(", "1", ")", ".", "item", "(", ")", "<", "self", ".", "dropout_prob", "]", "\n", "\n", "x_in", "[", ":", ",", "drop_feature_idx", ",", ":", "]", "=", "0", "\n", "\n", "return", "x_in", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.FrameReverse.__init__": [[745, 748], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reverses the frame sequence in the input signal. \"\"\"", "\n", "super", "(", "FrameReverse", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.FrameReverse.forward": [[749, 756], ["reversed", "range"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_in", ")", ":", "\n", "        ", "batch_size", ",", "spectral_dim", ",", "sequence_dim", "=", "x_in", ".", "shape", "\n", "# reverse indicies", "\n", "reversed_idx", "=", "[", "i", "for", "i", "in", "reversed", "(", "range", "(", "sequence_dim", ")", ")", "]", "\n", "x_in", "[", ":", ",", ":", ",", "reversed_idx", "]", "=", "x_in", "\n", "\n", "return", "x_in", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.FrameShuffle.__init__": [[760, 763], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Shuffle the frame sequence in the input signal, given a bag size. \"\"\"", "\n", "super", "(", "FrameShuffle", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.FrameShuffle.forward": [[764, 783], ["list", "random.shuffle", "range", "range"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_in", ",", "bag_size", "=", "1", ")", ":", "\n", "        ", "batch_size", ",", "spectral_dim", ",", "seq_dim", "=", "x_in", ".", "shape", "\n", "\n", "# shuffle idicies according to bag of frames size", "\n", "# make the bags of frames", "\n", "seq_idx", "=", "list", "(", "range", "(", "seq_dim", ")", ")", "\n", "\n", "# here, a list of bags (lists) will be made", "\n", "frame_bags", "=", "[", "seq_idx", "[", "i", ":", "i", "+", "bag_size", "]", "for", "i", "in", "range", "(", "0", ",", "seq_dim", ",", "bag_size", ")", "]", "\n", "\n", "# shuffle the bags", "\n", "random", ".", "shuffle", "(", "frame_bags", ")", "\n", "\n", "# flatten the bags into a sequential list", "\n", "shuffled_idx", "=", "[", "idx", "for", "bag", "in", "frame_bags", "for", "idx", "in", "bag", "]", "\n", "\n", "x_in", "[", ":", ",", ":", ",", "shuffled_idx", "]", "=", "x_in", "\n", "\n", "return", "x_in", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.GaussianNoise.__init__": [[787, 790], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "stddev", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "stddev", "=", "stddev", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.GaussianNoise.forward": [[791, 795], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "x_in.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_in", ")", ":", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "return", "x_in", "+", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "randn", "(", "x_in", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", "*", "self", ".", "stddev", ")", "\n", "", "return", "x_in", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoder.__init__": [[801, 923], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "sum", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Sequential", "torch.Sequential", "torch.MaxPool1d", "torch.MaxPool1d", "torch.Sequential", "torch.Sequential", "torch.AvgPool1d", "torch.AvgPool1d"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["def", "__init__", "(", "self", ",", "\n", "spectral_dim", "=", "13", ",", "\n", "max_num_frames", "=", "384", ",", "\n", "num_channels", "=", "[", "128", ",", "256", ",", "512", "]", ",", "\n", "filter_sizes", "=", "[", "8", ",", "12", ",", "16", "]", ",", "\n", "stride_steps", "=", "[", "1", ",", "1", ",", "1", "]", ",", "\n", "output_dim", "=", "512", ",", "\n", "pooling_type", "=", "'max'", ",", "\n", "signal_dropout_prob", "=", "0.0", ",", "\n", "unit_dropout_prob", "=", "0.2", ",", "\n", "dropout_frames", "=", "False", ",", "\n", "dropout_spectral_features", "=", "False", ",", "\n", "mask_signal", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            spectral_dim (int): number of spectral coefficients\n            max_num_frames (int): max number of acoustic frames in input\n            num_channels (list): number of channels per each Conv layer\n            filter_sizes (list): size of filter/kernel per each Conv layer\n            stride_steps (list): strides per each Conv layer\n            pooling (str): pooling procedure, either 'max' or 'mean'\n            signal_dropout_prob (float): signal dropout probability, either\n                frame dropout or spectral feature dropout\n            signal_masking (bool):  whether to mask signal during inference\n\n            How to use example:\n            speech_enc = AcousticEncoder(\n                spectral_dim=13,\n                num_channels=[128, 256, 512],\n                filter_sizes=[5, 10, 10],\n                stride_steps=[1, 1, 1],\n                pooling_type='max',\n\n                # this will apply frame dropout with 0.2 prob\n                signal_dropout_prob=0.2,\n                dropout_frames=True,\n                dropout_spectral_features=False,\n                mask_signal= False\n            ):\n        \"\"\"", "\n", "super", "(", "AcousticEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "spectral_dim", "=", "spectral_dim", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "max_num_frames", "=", "max_num_frames", "\n", "# self.signal_dropout_prob = signal_dropout_prob", "\n", "self", ".", "unit_dropout_prob", "=", "unit_dropout_prob", "\n", "self", ".", "pooling_type", "=", "pooling_type", "\n", "# self.dropout_frames = dropout_frames", "\n", "# self.dropout_spectral_features = dropout_spectral_features", "\n", "# self.mask_signal = mask_signal", "\n", "\n", "# signal dropout_layer", "\n", "# if self.dropout_frames: # if frame dropout is enableed", "\n", "#     self.signal_dropout = FrameDropout(self.signal_dropout_prob)", "\n", "\n", "# elif self.dropout_spectral_features: # if spectral dropout is enabled", "\n", "#     self.signal_dropout = SpectralDropout(self.signal_dropout_prob)", "\n", "\n", "# # frame reversal layer", "\n", "# self.frame_reverse = FrameReverse()", "\n", "\n", "# # frame reversal layer", "\n", "# self.frame_shuffle = FrameShuffle()", "\n", "\n", "# # add noise layer", "\n", "# self.noise = GaussianNoise()", "\n", "\n", "# Convolutional layer  1", "\n", "self", ".", "conv1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "self", ".", "spectral_dim", ",", "\n", "out_channels", "=", "num_channels", "[", "0", "]", ",", "\n", "kernel_size", "=", "filter_sizes", "[", "0", "]", ",", "\n", "stride", "=", "stride_steps", "[", "0", "]", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "num_channels", "[", "0", "]", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "unit_dropout_prob", ")", "\n", ")", "\n", "\n", "# Convolutional layer  2", "\n", "self", ".", "conv2", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "num_channels", "[", "0", "]", ",", "\n", "out_channels", "=", "num_channels", "[", "1", "]", ",", "\n", "kernel_size", "=", "filter_sizes", "[", "1", "]", ",", "\n", "stride", "=", "stride_steps", "[", "1", "]", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "num_channels", "[", "1", "]", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "unit_dropout_prob", ")", "\n", ")", "\n", "\n", "# Convolutional layer  3", "\n", "self", ".", "conv3", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "num_channels", "[", "1", "]", ",", "\n", "out_channels", "=", "num_channels", "[", "2", "]", ",", "\n", "kernel_size", "=", "filter_sizes", "[", "2", "]", ",", "\n", "stride", "=", "stride_steps", "[", "2", "]", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "num_channels", "[", "2", "]", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "unit_dropout_prob", ")", "\n", ")", "\n", "\n", "# determine the output dimensionality of the resulting tensor", "\n", "# this only works if all stride steps are set to 1", "\n", "shrinking_dims", "=", "sum", "(", "[", "(", "i", "-", "1", ")", "for", "i", "in", "filter_sizes", "[", ":", "]", "]", ")", "\n", "out_dim", "=", "self", ".", "max_num_frames", "-", "shrinking_dims", "\n", "#print('out_dim', out_dim)", "\n", "\n", "if", "self", ".", "pooling_type", "==", "'max'", ":", "\n", "            ", "self", ".", "PoolLayer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "MaxPool1d", "(", "kernel_size", "=", "out_dim", ",", "stride", "=", "1", ")", ",", "\n", "#nn.Dropout(self.unit_dropout_prob)", "\n", ")", "\n", "\n", "\n", "", "elif", "self", ".", "pooling_type", "==", "'avg'", ":", "\n", "            ", "self", ".", "PoolLayer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "AvgPool1d", "(", "kernel_size", "=", "out_dim", ",", "stride", "=", "1", ")", ",", "\n", "#nn.Dropout(self.unit_dropout_prob)", "\n", ")", "\n", "", "else", ":", "\n", "#TODO: implement other statistical pooling approaches", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoder.forward": [[942, 992], ["nn_speech_models.AcousticEncoder.conv1", "nn_speech_models.AcousticEncoder.conv2", "nn_speech_models.AcousticEncoder.conv3", "nn_speech_models.AcousticEncoder.PoolLayer().squeeze", "nn_speech_models.AcousticEncoder.PoolLayer"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "\n", "x_in", ",", "\n", "frame_dropout", "=", "False", ",", "\n", "feature_dropout", "=", "False", ",", "\n", "return_all_vectors", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"The forward pass of the acoustic encoder\n\n        Args:\n            x_in (torch.Tensor): an input data tensor with the shape\n                (batch_size, spectral_dim, max_num_frames)\n            frame_dropout (bool): whether to mask out frames (inference)\n            feature_dropout (bool): whether to mask out features (inference)\n        Returns:\n            the resulting tensor. tensor.shape should be (batch, )\n        \"\"\"", "\n", "\n", "# apply signal dropout on the input (if any)", "\n", "# signal dropout, disabled on evaluating unless explicitly asked for", "\n", "# if self.training:", "\n", "#     x_in = self.signal_dropout(x_in)", "\n", "\n", "# signal masking during inference (explicit)", "\n", "# if self.eval and self.mask_signal:", "\n", "#     x_in = self.signal_dropout(x_in)", "\n", "\n", "\n", "conv1_f", "=", "self", ".", "conv1", "(", "x_in", ")", "\n", "conv2_f", "=", "self", ".", "conv2", "(", "conv1_f", ")", "\n", "#print(conv2_f.shape)", "\n", "conv3_f", "=", "self", ".", "conv3", "(", "conv2_f", ")", "\n", "\n", "# print(f\"conv1_f, {conv1_f.shape}\",", "\n", "#     f\"conv2_f, {conv2_f.shape}\",", "\n", "#     f\"conv3_f, {conv3_f.shape}\",", "\n", "# )", "\n", "\n", "# max pooling", "\n", "conv_features", "=", "self", ".", "PoolLayer", "(", "conv3_f", ")", ".", "squeeze", "(", "dim", "=", "2", ")", "\n", "\n", "#fc1_vec = self.fc1(conv_features)", "\n", "\n", "# final acoutic vector (output from the acoustic encoder)", "\n", "acoustic_embedding", "=", "conv_features", "#self.fc(conv_features) #  #conv_features  #self.fc(conv_features)", "\n", "\n", "\n", "if", "return_all_vectors", ":", "\n", "            ", "return", "conv_features", ",", "acoustic_embedding", "\n", "\n", "", "return", "acoustic_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.SymbolicEncoder.__init__": [[996, 1025], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.GRU", "torch.GRU"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "embedding_dim", "=", "64", ",", "\n", "hidden_state_dim", "=", "512", ",", "\n", "output_dim", "=", "1024", ",", "\n", "n_layers", "=", "1", ",", "\n", "vocab_size", "=", "95", ",", "\n", "dropout_prob", "=", "0.2", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            embedding_dim (int): dim of symbol embedding\n            hidden_state_dim (int): dim of recurrent hidden state\n            n_layers (int): number of layers in the recurrent model\n            dropout_prob (float): dropout probability\n        \"\"\"", "\n", "super", "(", "SymbolicEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_state_dim", "=", "hidden_state_dim", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "\n", "self", ".", "symbol_embeddings", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ")", "\n", "\n", "self", ".", "recurrent_layer", "=", "nn", ".", "GRU", "(", "\n", "embedding_dim", ",", "\n", "hidden_state_dim", ",", "\n", "n_layers", ",", "\n", "dropout", "=", "0.0", ",", "\n", "bidirectional", "=", "True", ",", "\n", "batch_first", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.SymbolicEncoder.forward": [[1036, 1073], ["nn_speech_models.SymbolicEncoder.symbol_embeddings", "nn_speech_models.SymbolicEncoder.recurrent_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "x_in", ",", "\n", "initial_hidden_state", "\n", ")", ":", "\n", "        ", "\"\"\"The forward pass of the encoder\n\n        Args:\n            x_in (torch.Tensor): an input data tensor.\n                x_in.shape should be (batch_size, embedding_dim, sequence_len)\n        Returns:\n            the resulting tensor. tensor.shape should be (batch, sequence_len)\n        \"\"\"", "\n", "\n", "# permute input for recurrent computation", "\n", "# switch between embedding_dim <-> sequence_len", "\n", "\n", "#print(x_in.shape)", "\n", "#x_in = torch.LongTensor(x_in) #x_in = x_in.long()", "\n", "\n", "embeddings", "=", "self", ".", "symbol_embeddings", "(", "x_in", ")", "\n", "\n", "#embeddings = embeddings.permute(0, 2, 1)", "\n", "\n", "#print('embeddings', embeddings.shape)", "\n", "\n", "# recurrent_vectors shape: [batch_size x sequence_len x hidden_state_dim]", "\n", "recurrent_vectors", ",", "h_n", "=", "self", ".", "recurrent_layer", "(", "embeddings", ",", "initial_hidden_state", ")", "\n", "\n", "\n", "# last_recurrent shape: [batch_size x 1 x 2*hidden_state_dim]", "\n", "# this returns the concat of the last hidden states in", "\n", "# the forward and reverse directions of the recurrence", "\n", "last_recurrent", "=", "recurrent_vectors", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "\n", "symbolic_embedding", "=", "last_recurrent", "#self.fc(last_recurrent)", "\n", "\n", "return", "symbolic_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.SymbolicEncoder.init_hidden": [[1074, 1086], ["torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "batch_size", ",", "device", ",", "bidirectional", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Given batch size & the device where the training of NN is taking place,\n        return a proper (zero) initialiization for the LSTM model as (h_0, c_0).\n        \"\"\"", "\n", "\n", "# each layers requires its own initial states,", "\n", "# if bidirctional, multiply by 2", "\n", "N", "=", "self", ".", "n_layers", "*", "2", "if", "bidirectional", "else", "self", ".", "n_layers", "\n", "\n", "state", "=", "torch", ".", "zeros", "(", "N", ",", "batch_size", ",", "self", ".", "hidden_state_dim", ")", ".", "to", "(", "device", ")", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.MultiViewEncoder.__init__": [[1092, 1101], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["def", "__init__", "(", "self", ",", "acoustic_encoder", ",", "symbolic_encoder", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            acoustic_encoder (SymbolicEncoder): module to get acoustic view\n            symbolic_encoder (AcousticEncoder): module to get symbolic view\n        \"\"\"", "\n", "super", "(", "MultiViewEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "acoustic_encoder", "=", "acoustic_encoder", "\n", "self", ".", "symbolic_encoder", "=", "symbolic_encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.MultiViewEncoder.forward": [[1103, 1126], ["nn_speech_models.MultiViewEncoder.symbolic_encoder.init_hidden", "nn_speech_models.MultiViewEncoder.symbolic_encoder", "nn_speech_models.MultiViewEncoder.acoustic_encoder.init_hidden", "nn_speech_models.MultiViewEncoder.acoustic_encoder"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoderBiGRU.init_hidden", "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoderBiGRU.init_hidden"], ["", "def", "forward", "(", "self", ",", "acoustic_in", ",", "symbolic_in", ",", "device", ")", ":", "\n", "\n", "        ", "batch_size", ",", "_", "=", "symbolic_in", ".", "shape", "\n", "\n", "_hidden_0", "=", "self", ".", "symbolic_encoder", ".", "init_hidden", "(", "\n", "batch_size", ",", "\n", "device", "=", "device", "\n", ")", "\n", "\n", "symbolic_view", "=", "self", ".", "symbolic_encoder", "(", "\n", "#torch.LongTensor(symbolic_in), #.unsqueeze(0)", "\n", "symbolic_in", ",", "\n", "_hidden_0", "\n", ")", "\n", "\n", "_hidden_0", "=", "self", ".", "acoustic_encoder", ".", "init_hidden", "(", "\n", "batch_size", ",", "\n", "device", "=", "device", "\n", ")", "\n", "\n", "acoustic_view", "=", "self", ".", "acoustic_encoder", "(", "acoustic_in", ",", "_hidden_0", ")", "\n", "\n", "return", "acoustic_view", ",", "symbolic_view", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.CLSpeechEncoder.__init__": [[1131, 1143], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["def", "__init__", "(", "self", ",", "acoustic_encoder", ",", "hidden_dim", ",", "num_classes", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            acoustic_encoder (AcousticEncoder): module to get acoustic view\n        \"\"\"", "\n", "super", "(", "CLSpeechEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "acoustic_encoder", "=", "acoustic_encoder", "\n", "\n", "self", ".", "cls_layers", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_features", "=", "hidden_dim", ",", "out_features", "=", "hidden_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "num_classes", ")", "\n", "#nn.Dropout(dropout_prob),", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.CLSpeechEncoder.forward": [[1151, 1177], ["nn_speech_models.CLSpeechEncoder.cls_layers", "nn_speech_models.CLSpeechEncoder.acoustic_encoder.init_hidden", "nn_speech_models.CLSpeechEncoder.acoustic_encoder", "nn_speech_models.CLSpeechEncoder.acoustic_encoder"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoderBiGRU.init_hidden"], ["", "def", "forward", "(", "self", ",", "acoustic_in", ",", "encoder_type", ",", "device", "=", "None", ",", "return_vector", "=", "False", ")", ":", "\n", "\n", "        ", "if", "encoder_type", "in", "[", "'LSTM'", ",", "'BiGRU'", ",", "'BiLSTM'", "]", ":", "\n", "# if a recurrent encoder, initial hidden state is required", "\n", "#print(acoustic_in.shape)", "\n", "            ", "batch_size", ",", "_", ",", "_", "=", "acoustic_in", ".", "shape", "\n", "\n", "_hidden_0", "=", "self", ".", "acoustic_encoder", ".", "init_hidden", "(", "\n", "batch_size", ",", "\n", "device", "=", "device", "\n", ")", "\n", "\n", "acoustic_emb", "=", "self", ".", "acoustic_encoder", "(", "\n", "acoustic_in", ",", "\n", "_hidden_0", "\n", ")", "\n", "", "else", ":", "\n", "            ", "acoustic_emb", "=", "self", ".", "acoustic_encoder", "(", "acoustic_in", ")", "\n", "\n", "", "logits", "=", "self", ".", "cls_layers", "(", "acoustic_emb", ")", "\n", "\n", "# pass through classification layer", "\n", "if", "return_vector", ":", "\n", "            ", "return", "logits", ",", "acoustic_emb", "\n", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordPairEncoder.__init__": [[1183, 1191], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["def", "__init__", "(", "self", ",", "acoustic_encoder", ",", "encoder_type", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            acoustic_encoder (AcousticEncoder): module to get acoustic view\n        \"\"\"", "\n", "super", "(", "WordPairEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "acoustic_encoder", "=", "acoustic_encoder", "\n", "self", ".", "encoder_type", "=", "encoder_type", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.WordPairEncoder.forward": [[1193, 1213], ["nn_speech_models.WordPairEncoder.acoustic_encoder.init_hidden", "nn_speech_models.WordPairEncoder.acoustic_encoder", "nn_speech_models.WordPairEncoder.acoustic_encoder", "nn_speech_models.WordPairEncoder.acoustic_encoder", "nn_speech_models.WordPairEncoder.acoustic_encoder"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoderBiGRU.init_hidden"], ["", "def", "forward", "(", "self", ",", "acoustic_ank", ",", "acoustic_pos", ",", "device", "=", "None", ")", ":", "\n", "\n", "        ", "if", "self", ".", "encoder_type", "in", "[", "'LSTM'", ",", "'BiGRU'", ",", "'BiLSTM'", "]", ":", "\n", "# if a recurrent encoder, initial hidden state is required", "\n", "#print(acoustic_ank.shape)", "\n", "            ", "batch_size", ",", "_", ",", "_", "=", "acoustic_ank", ".", "shape", "\n", "\n", "_hidden_0", "=", "self", ".", "acoustic_encoder", ".", "init_hidden", "(", "\n", "batch_size", ",", "\n", "device", "=", "device", "\n", ")", "\n", "\n", "acoustic_emb_ank", "=", "self", ".", "acoustic_encoder", "(", "acoustic_ank", ",", "_hidden_0", ")", "\n", "acoustic_emb_pos", "=", "self", ".", "acoustic_encoder", "(", "acoustic_pos", ",", "_hidden_0", ")", "\n", "", "else", ":", "\n", "            ", "acoustic_emb_ank", "=", "self", ".", "acoustic_encoder", "(", "acoustic_ank", ")", "\n", "acoustic_emb_pos", "=", "self", ".", "acoustic_encoder", "(", "acoustic_pos", ")", "\n", "\n", "\n", "", "return", "acoustic_emb_ank", ",", "acoustic_emb_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoderLSTM.__init__": [[1216, 1256], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM", "torch.Dropout", "torch.Dropout", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "spectral_dim", "=", "13", ",", "\n", "max_num_frames", "=", "384", ",", "\n", "hidden_state_dim", "=", "256", ",", "\n", "output_dim", "=", "512", ",", "\n", "n_layers", "=", "4", ",", "\n", "unit_dropout_prob", "=", "0.2", ",", "\n", "dropout_frames", "=", "False", ",", "\n", "dropout_spectral_features", "=", "False", ",", "\n", "mask_signal", "=", "False", ",", "\n", "dropout_prob", "=", "0.2", ",", "\n", "signal_dropout_prob", "=", "0.0", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            feature_dim (int): size of the feature vector\n            num_classes (int): num of classes or size the softmax layer\n            )\n        \"\"\"", "\n", "super", "(", "AcousticEncoderLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "hidden_state_dim", "=", "hidden_state_dim", "\n", "\n", "\n", "self", ".", "recurrent_layer", "=", "nn", ".", "LSTM", "(", "\n", "input_size", "=", "spectral_dim", ",", "\n", "hidden_size", "=", "hidden_state_dim", ",", "\n", "num_layers", "=", "n_layers", ",", "\n", "dropout", "=", "dropout_prob", ",", "\n", "bidirectional", "=", "False", ",", "\n", "batch_first", "=", "True", "\n", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout_prob", ")", "\n", "\n", "# fully connected layer", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_features", "=", "hidden_state_dim", ",", "out_features", "=", "output_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", "\n", "#nn.Dropout(dropout_prob)", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoderLSTM.forward": [[1260, 1307], ["x_in.permute.permute.float", "x_in.permute.permute.permute", "nn_speech_models.AcousticEncoderLSTM.recurrent_layer", "nn_speech_models.AcousticEncoderLSTM.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_in", ",", "initial_hidden_state", ")", ":", "\n", "        ", "\"\"\"The forward pass of the encoder\n\n        Args:\n            x_in (torch.Tensor): an input data tensor.\n                x_in.shape should be (batch_size, embedding_dim, sequence_len)\n        Returns:\n            the resulting tensor. tensor.shape should be (batch, sequence_len)\n        \"\"\"", "\n", "\n", "x_in", "=", "x_in", ".", "float", "(", ")", "\n", "\n", "# input = self.word_embeddings(input_sentence) # embedded input of shape = (batch_size, num_sequences,  embedding_length)", "\n", "# input = input.permute(1, 0, 2) # input.size() = (num_sequences, batch_size, embedding_length)", "\n", "\n", "# print(x_in.shape) >> torch.Size([256, 39, 128]) (batch, feature_dim, seq_len)", "\n", "\n", "# permute input for recurrent computation", "\n", "x_in", "=", "x_in", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "\n", "# print(x_in.shape) >> torch.Size([128, 256, 39])", "\n", "\n", "# LSTM Inputs: input, (h_0, c_0)", "\n", "# input of shape (seq_len, batch, input_size)", "\n", "# h_0 of shape (num_layers * num_directions, batch, hidden_size)", "\n", "# c_0 of shape (num_layers * num_directions, batch, hidden_size)", "\n", "\n", "# LSTM Outputs: output, (h_n, c_n)", "\n", "# output of shape (seq_len, batch, num_directions * hidden_size)", "\n", "# h_n of shape (num_layers * num_directions, batch, hidden_size)", "\n", "(", "h_0", ",", "c_0", ")", "=", "initial_hidden_state", "\n", "lstm_out", ",", "(", "h_n", ",", "c_n", ")", "=", "self", ".", "recurrent_layer", "(", "x_in", ",", "(", "h_0", ",", "c_0", ")", ")", "\n", "\n", "\n", "#lstm_vec =  self.dropout(lstm_out[:, -1, :]) #", "\n", "lstm_vec", "=", "lstm_out", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "#print(lstm_vec.shape)  >> torch.Size([256, 1024])", "\n", "\n", "#print('last_hidden', last_hidden.shape)", "\n", "\n", "#z = self.fc_layers(lstm_out)", "\n", "#print('z', z.shape)", "\n", "\n", "acoustic_embedding", "=", "self", ".", "fc", "(", "lstm_vec", ")", "\n", "\n", "return", "lstm_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoderLSTM.init_hidden": [[1309, 1325], ["torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "batch_size", ",", "device", ",", "bidirectional", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Given batch size & the device where the training of NN is taking place,\n        return a proper (zero) initialization for the LSTM model as (h_0, c_0).\n        \"\"\"", "\n", "\n", "# each layers requires its own initial states,", "\n", "# if bidirctional, multiply by 2", "\n", "N", "=", "self", ".", "n_layers", "if", "bidirectional", "else", "self", ".", "n_layers", "\n", "\n", "state", "=", "(", "\n", "torch", ".", "zeros", "(", "N", ",", "batch_size", ",", "self", ".", "hidden_state_dim", ")", ".", "to", "(", "device", ")", ",", "\n", "torch", ".", "zeros", "(", "N", ",", "batch_size", ",", "self", ".", "hidden_state_dim", ")", ".", "to", "(", "device", ")", ",", "\n", ")", "\n", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoderBiLSTM.__init__": [[1328, 1367], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "spectral_dim", "=", "13", ",", "\n", "max_num_frames", "=", "384", ",", "\n", "hidden_state_dim", "=", "256", ",", "\n", "output_dim", "=", "512", ",", "\n", "n_layers", "=", "4", ",", "\n", "unit_dropout_prob", "=", "0.2", ",", "\n", "dropout_frames", "=", "False", ",", "\n", "dropout_spectral_features", "=", "False", ",", "\n", "mask_signal", "=", "False", ",", "\n", "signal_dropout_prob", "=", "0.0", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            feature_dim (int): size of the feature vector\n            num_classes (int): num of classes or size the softmax layer\n            )\n        \"\"\"", "\n", "super", "(", "AcousticEncoderBiLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "hidden_state_dim", "=", "hidden_state_dim", "\n", "\n", "\n", "self", ".", "recurrent_layer", "=", "nn", ".", "LSTM", "(", "\n", "input_size", "=", "spectral_dim", ",", "\n", "hidden_size", "=", "hidden_state_dim", ",", "\n", "num_layers", "=", "n_layers", ",", "\n", "dropout", "=", "unit_dropout_prob", ",", "\n", "bidirectional", "=", "True", ",", "\n", "batch_first", "=", "True", "\n", ")", "\n", "\n", "#self.dropout = nn.Dropout(dropout_prob)", "\n", "\n", "# fully connected layer", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_features", "=", "2", "*", "hidden_state_dim", ",", "out_features", "=", "output_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", "\n", "#nn.Dropout(dropout_prob),", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoderBiLSTM.forward": [[1373, 1420], ["x_in.permute.permute.float", "x_in.permute.permute.permute", "nn_speech_models.AcousticEncoderBiLSTM.recurrent_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_in", ",", "initial_hidden_state", ")", ":", "\n", "        ", "\"\"\"The forward pass of the encoder\n\n        Args:\n            x_in (torch.Tensor): an input data tensor.\n                x_in.shape should be (batch_size, embedding_dim, sequence_len)\n        Returns:\n            the resulting tensor. tensor.shape should be (batch, sequence_len)\n        \"\"\"", "\n", "\n", "x_in", "=", "x_in", ".", "float", "(", ")", "\n", "\n", "# input = self.word_embeddings(input_sentence) # embedded input of shape = (batch_size, num_sequences,  embedding_length)", "\n", "# input = input.permute(1, 0, 2) # input.size() = (num_sequences, batch_size, embedding_length)", "\n", "\n", "# print(x_in.shape) >> torch.Size([256, 39, 128]) (batch, feature_dim, seq_len)", "\n", "\n", "# permute input for recurrent computation", "\n", "x_in", "=", "x_in", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "\n", "# print(x_in.shape) >> torch.Size([128, 256, 39])", "\n", "\n", "# LSTM Inputs: input, (h_0, c_0)", "\n", "# input of shape (seq_len, batch, input_size)", "\n", "# h_0 of shape (num_layers * num_directions, batch, hidden_size)", "\n", "# c_0 of shape (num_layers * num_directions, batch, hidden_size)", "\n", "\n", "# LSTM Outputs: output, (h_n, c_n)", "\n", "# output of shape (seq_len, batch, num_directions * hidden_size)", "\n", "# h_n of shape (num_layers * num_directions, batch, hidden_size)", "\n", "(", "h_0", ",", "c_0", ")", "=", "initial_hidden_state", "\n", "lstm_out", ",", "(", "h_n", ",", "c_n", ")", "=", "self", ".", "recurrent_layer", "(", "x_in", ",", "(", "h_0", ",", "c_0", ")", ")", "\n", "\n", "\n", "lstm_vec", "=", "lstm_out", "[", ":", ",", "-", "1", ",", ":", "]", "# self.dropout(lstm_out[:, -1, :]) #", "\n", "#lstm_vec = lstm_out[:, -1, :]", "\n", "#print(lstm_vec.shape)  >> torch.Size([256, 1024])", "\n", "\n", "#print('last_hidden', last_hidden.shape)", "\n", "\n", "#z = self.fc_layers(lstm_out)", "\n", "#print('z', z.shape)", "\n", "\n", "#acoustic_embedding = self.fc(lstm_vec)", "\n", "\n", "return", "lstm_vec", "#acoustic_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoderBiLSTM.init_hidden": [[1422, 1438], ["torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "batch_size", ",", "device", ",", "bidirectional", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Given batch size & the device where the training of NN is taking place,\n        return a proper (zero) initialization for the LSTM model as (h_0, c_0).\n        \"\"\"", "\n", "\n", "# each layers requires its own initial states,", "\n", "# if bidirctional, multiply by 2", "\n", "N", "=", "2", "*", "self", ".", "n_layers", "if", "bidirectional", "else", "self", ".", "n_layers", "\n", "\n", "state", "=", "(", "\n", "torch", ".", "zeros", "(", "N", ",", "batch_size", ",", "self", ".", "hidden_state_dim", ")", ".", "to", "(", "device", ")", ",", "\n", "torch", ".", "zeros", "(", "N", ",", "batch_size", ",", "self", ".", "hidden_state_dim", ")", ".", "to", "(", "device", ")", ",", "\n", ")", "\n", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoderBiGRU.__init__": [[1441, 1473], ["torch.Module.__init__", "torch.GRU", "torch.GRU"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "spectral_dim", "=", "13", ",", "\n", "max_num_frames", "=", "384", ",", "\n", "hidden_state_dim", "=", "256", ",", "\n", "output_dim", "=", "512", ",", "\n", "n_layers", "=", "4", ",", "\n", "unit_dropout_prob", "=", "0.2", ",", "\n", "dropout_frames", "=", "False", ",", "\n", "dropout_spectral_features", "=", "False", ",", "\n", "mask_signal", "=", "False", ",", "\n", "signal_dropout_prob", "=", "0.0", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            feature_dim (int): size of the feature vector\n            num_classes (int): num of classes or size the softmax layer\n            )\n        \"\"\"", "\n", "super", "(", "AcousticEncoderBiGRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "hidden_state_dim", "=", "hidden_state_dim", "\n", "self", ".", "unit_dropout_prob", "=", "unit_dropout_prob", "\n", "\n", "\n", "self", ".", "recurrent_layer", "=", "nn", ".", "GRU", "(", "\n", "input_size", "=", "spectral_dim", ",", "\n", "hidden_size", "=", "hidden_state_dim", ",", "\n", "num_layers", "=", "n_layers", ",", "\n", "dropout", "=", "unit_dropout_prob", ",", "\n", "bidirectional", "=", "True", ",", "\n", "batch_first", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoderBiGRU.forward": [[1488, 1533], ["x_in.permute.permute.float", "x_in.permute.permute.permute", "nn_speech_models.AcousticEncoderBiGRU.recurrent_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_in", ",", "initial_hidden_state", ")", ":", "\n", "        ", "\"\"\"The forward pass of the encoder\n\n        Args:\n            x_in (torch.Tensor): an input data tensor.\n                x_in.shape should be (batch_size, embedding_dim, sequence_len)\n        Returns:\n            the resulting tensor. tensor.shape should be (batch, sequence_len)\n        \"\"\"", "\n", "\n", "x_in", "=", "x_in", ".", "float", "(", ")", "\n", "\n", "# input = self.word_embeddings(input_sentence) # embedded input of shape = (batch_size, num_sequences,  embedding_length)", "\n", "# input = input.permute(1, 0, 2) # input.size() = (num_sequences, batch_size, embedding_length)", "\n", "\n", "# print(x_in.shape) >> torch.Size([256, 39, 128]) (batch, feature_dim, seq_len)", "\n", "\n", "# permute input for recurrent computation", "\n", "x_in", "=", "x_in", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "\n", "# print(x_in.shape) >> torch.Size([128, 256, 39])", "\n", "\n", "# GRU Inputs: input, h_0", "\n", "# input of shape (seq_len, batch, input_size)", "\n", "# h_0 of shape (num_layers * num_directions, batch, hidden_size)", "\n", "\n", "# GRU Outputs: output, h_n", "\n", "# output of shape (seq_len, batch, num_directions * hidden_size)", "\n", "# h_n of shape (num_layers * num_directions, batch, hidden_size)", "\n", "h_0", "=", "initial_hidden_state", "\n", "rec_out", ",", "h_n", "=", "self", ".", "recurrent_layer", "(", "x_in", ",", "h_0", ")", "\n", "\n", "rec_vec", "=", "rec_out", "[", ":", ",", "-", "1", ",", ":", "]", "#self.dropout(rec_out[:, -1, :]) #", "\n", "#lstm_vec = lstm_out[:, -1, :]", "\n", "#print(lstm_vec.shape)  >> torch.Size([256, 1024])", "\n", "\n", "#print('last_hidden', last_hidden.shape)", "\n", "\n", "#z = self.fc_layers(lstm_out)", "\n", "#print('z', z.shape)", "\n", "\n", "acoustic_embedding", "=", "rec_vec", "\n", "\n", "return", "acoustic_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoderBiGRU.init_hidden": [[1535, 1550], ["torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "batch_size", ",", "device", ",", "bidirectional", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Given batch size & the device where the training of NN is taking place,\n        return a proper (zero) initialization for the LSTM model as (h_0, c_0).\n        \"\"\"", "\n", "\n", "# each layers requires its own initial states,", "\n", "# if bidirctional, multiply by 2", "\n", "N", "=", "2", "*", "self", ".", "n_layers", "if", "bidirectional", "else", "self", ".", "n_layers", "\n", "\n", "state", "=", "(", "\n", "torch", ".", "zeros", "(", "N", ",", "batch_size", ",", "self", ".", "hidden_state_dim", ")", ".", "to", "(", "device", ")", "\n", ")", "\n", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.PhoneticDecoder.__init__": [[1554, 1580], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.GRUCell", "torch.GRUCell", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "embedding_dim", "=", "64", ",", "\n", "hidden_state_dim", "=", "512", ",", "\n", "n_layers", "=", "1", ",", "\n", "vocab_size", "=", "95", ",", "\n", "dropout_prob", "=", "0.2", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            embedding_dim (int): dim of phoneme embedding\n            hidden_state_dim (int): dim of recurrent hidden state\n            n_layers (int): number of layers in the recurrent model\n        \"\"\"", "\n", "super", "(", "PhoneticDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_state_dim", "=", "hidden_state_dim", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "\n", "self", ".", "phoneme_embeddings", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ")", "\n", "\n", "self", ".", "recurrent_layer", "=", "nn", ".", "GRUCell", "(", "\n", "input_size", "=", "embedding_dim", ",", "\n", "hidden_size", "=", "hidden_state_dim", "\n", ")", "\n", "\n", "self", ".", "fc_out", "=", "nn", ".", "Linear", "(", "hidden_state_dim", ",", "vocab_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.PhoneticDecoder.forward": [[1584, 1598], ["nn_speech_models.PhoneticDecoder.phoneme_embeddings", "nn_speech_models.PhoneticDecoder.recurrent_layer", "nn_speech_models.PhoneticDecoder.fc_out"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_in", ",", "previous_hidden", ")", ":", "\n", "\n", "# permute", "\n", "#print('x_in.shape', x_in.shape)", "\n", "\n", "#x_in = x_in.permute(1, 0)", "\n", "\n", "        ", "embedding", "=", "self", ".", "phoneme_embeddings", "(", "x_in", ")", "# self.dropout()", "\n", "\n", "hidden_state", "=", "self", ".", "recurrent_layer", "(", "embedding", ",", "previous_hidden", ")", "\n", "\n", "prediction", "=", "self", ".", "fc_out", "(", "hidden_state", ")", "\n", "\n", "return", "prediction", ",", "hidden_state", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.Seq2SeqEncoder.__init__": [[1602, 1624], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "acoustic_encoder", ",", "phonetic_decoder", ",", "encoder_type", "=", "'BiGRU'", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "super", "(", "Seq2SeqEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "acoustic_encoder", "=", "acoustic_encoder", "\n", "self", ".", "phonetic_decoder", "=", "phonetic_decoder", "\n", "self", ".", "encoder_type", "=", "encoder_type", "\n", "self", ".", "device", "=", "device", "\n", "\n", "output_dim", "=", "acoustic_encoder", ".", "output_dim", "\n", "word_embedding_dim", "=", "phonetic_decoder", ".", "hidden_state_dim", "\n", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "acoustic_encoder", ".", "unit_dropout_prob", ")", ",", "\n", "nn", ".", "Linear", "(", "in_features", "=", "output_dim", ",", "out_features", "=", "word_embedding_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "# nn.Dropout(acoustic_encoder.unit_dropout_prob),", "\n", "# nn.Linear(in_features=output_dim, out_features=output_dim),", "\n", "# nn.Tanh()", "\n", ")", "\n", "\n", "self", ".", "teacher_force", "=", "True", "\n", "self", ".", "teacher_forcing_ratio", "=", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.Seq2SeqEncoder.forward": [[1628, 1698], ["torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "nn_speech_models.Seq2SeqEncoder.acoustic_encoder.init_hidden", "nn_speech_models.Seq2SeqEncoder.fc", "nn_speech_models.Seq2SeqEncoder.fc", "nn_speech_models.Seq2SeqEncoder.phonetic_decoder", "output.argmax", "nn_speech_models.Seq2SeqEncoder.acoustic_encoder", "nn_speech_models.Seq2SeqEncoder.acoustic_encoder", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoderBiGRU.init_hidden"], ["", "def", "forward", "(", "self", ",", "acoustic_in", ",", "y_sequence_out", ",", "inference", "=", "False", ")", ":", "\n", "\n", "#src = [src len, batch size]", "\n", "#trg = [trg len, batch size]", "\n", "#teacher_forcing_ratio is probability to use teacher forcing", "\n", "#e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time", "\n", "\n", "#print('y_sequence_out', y_sequence_out.shape)", "\n", "\n", "        ", "batch_size", "=", "y_sequence_out", ".", "shape", "[", "0", "]", "\n", "\n", "if", "self", ".", "encoder_type", "in", "[", "'LSTM'", ",", "'BiGRU'", ",", "'BiLSTM'", "]", ":", "\n", "\n", "            ", "_hidden_0", "=", "self", ".", "acoustic_encoder", ".", "init_hidden", "(", "\n", "batch_size", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n", "\n", "acoustic_emb", "=", "self", ".", "fc", "(", "self", ".", "acoustic_encoder", "(", "acoustic_in", ",", "_hidden_0", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "acoustic_emb", "=", "self", ".", "fc", "(", "self", ".", "acoustic_encoder", "(", "acoustic_in", ")", ")", "#self.acoustic_encoder(acoustic_in) #", "\n", "\n", "", "if", "inference", ":", "\n", "            ", "return", "acoustic_emb", "\n", "\n", "# initialize decoder hidden state with acoustic vector", "\n", "", "decoder_hidden_state", "=", "acoustic_emb", "\n", "\n", "\n", "\n", "y_sequence_len", "=", "y_sequence_out", ".", "shape", "[", "1", "]", "\n", "\n", "\n", "output_vocab_size", "=", "self", ".", "phonetic_decoder", ".", "vocab_size", "\n", "\n", "#tensor to store decoder outputs", "\n", "outputs", "=", "torch", ".", "zeros", "(", "y_sequence_len", ",", "batch_size", ",", "output_vocab_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "#last hidden state of the encoder is used as the initial hidden state of the decoder", "\n", "#hidden_state = self.acoustic_encoder(acoustic_in)", "\n", "\n", "#first input to the decoder is the <BEGIN> token", "\n", "recurrent_input", "=", "y_sequence_out", "[", ":", ",", "0", "]", "\n", "\n", "#print(recurrent_input)", "\n", "\n", "for", "t", "in", "range", "(", "1", ",", "y_sequence_len", ")", ":", "\n", "\n", "#insert input token embedding, previous hidden", "\n", "#receive output tensor (predictions) and new hidden", "\n", "            ", "output", ",", "decoder_hidden_state", "=", "self", ".", "phonetic_decoder", "(", "recurrent_input", ",", "decoder_hidden_state", ")", "\n", "\n", "\n", "#print('output, decoder_hidden_state', output.shape, decoder_hidden_state.shape)", "\n", "\n", "#place predictions in a tensor holding predictions for each token", "\n", "outputs", "[", "t", "]", "=", "output", "\n", "\n", "#decide if we are going to use teacher forcing or not", "\n", "#teacher_force = random.random() < teacher_forcing_ratio", "\n", "\n", "#get the highest predicted token from our predictions", "\n", "top1", "=", "output", ".", "argmax", "(", "1", ")", "\n", "\n", "#if teacher forcing, use actual next token as next input", "\n", "#if not, use predicted token", "\n", "recurrent_input", "=", "top1", "#y_sequence_out[:,t] #if self.teacher_force else top1", "\n", "\n", "", "return", "outputs", ",", "acoustic_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticDecoder.__init__": [[1703, 1734], ["torch.Module.__init__", "torch.GRUCell", "torch.GRUCell", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "spectral_dim", "=", "13", ",", "\n", "max_num_frames", "=", "384", ",", "\n", "hidden_state_dim", "=", "256", ",", "\n", "output_dim", "=", "39", ",", "\n", "n_layers", "=", "2", ",", "\n", "unit_dropout_prob", "=", "0.2", ",", "\n", "dropout_frames", "=", "False", ",", "\n", "dropout_spectral_features", "=", "False", ",", "\n", "mask_signal", "=", "False", ",", "\n", "signal_dropout_prob", "=", "0.0", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            embedding_dim (int): dim of phoneme embedding\n            hidden_state_dim (int): dim of recurrent hidden state\n            n_layers (int): number of layers in the recurrent model\n        \"\"\"", "\n", "super", "(", "AcousticDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "hidden_state_dim", "=", "hidden_state_dim", "\n", "self", ".", "unit_dropout_prob", "=", "unit_dropout_prob", "\n", "\n", "\n", "self", ".", "recurrent_layer", "=", "nn", ".", "GRUCell", "(", "\n", "input_size", "=", "spectral_dim", ",", "# + hidden_state_dim,", "\n", "hidden_size", "=", "hidden_state_dim", "\n", ")", "\n", "\n", "self", ".", "fc_out", "=", "nn", ".", "Linear", "(", "hidden_state_dim", ",", "spectral_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticDecoder.forward": [[1738, 1754], ["nn_speech_models.AcousticDecoder.recurrent_layer", "nn_speech_models.AcousticDecoder.fc_out"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "spectral_vec", ",", "previous_hidden", ")", ":", "\n", "\n", "# permute", "\n", "#print('x_in.shape', x_in.shape)", "\n", "\n", "#x_in = x_in.permute(1, 0)", "\n", "\n", "#embedding = self.phoneme_embeddings(x_in) # self.dropout()", "\n", "\n", "#print('GRU: ', spectral_vec.shape, previous_hidden.shape)", "\n", "\n", "        ", "hidden_state", "=", "self", ".", "recurrent_layer", "(", "spectral_vec", ",", "previous_hidden", ")", "\n", "\n", "prediction", "=", "self", ".", "fc_out", "(", "hidden_state", ")", "\n", "\n", "return", "prediction", ",", "hidden_state", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__": [[1758, 1780], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "acoustic_encoder", ",", "acoustic_decoder", ",", "encoder_type", "=", "'BiGRU'", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "super", "(", "AutoEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "acoustic_encoder", "=", "acoustic_encoder", "\n", "self", ".", "acoustic_decoder", "=", "acoustic_decoder", "\n", "self", ".", "encoder_type", "=", "encoder_type", "\n", "self", ".", "device", "=", "device", "\n", "\n", "output_dim", "=", "acoustic_encoder", ".", "output_dim", "\n", "word_embedding_dim", "=", "acoustic_decoder", ".", "hidden_state_dim", "\n", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "acoustic_encoder", ".", "unit_dropout_prob", ")", ",", "\n", "nn", ".", "Linear", "(", "in_features", "=", "output_dim", ",", "out_features", "=", "word_embedding_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "# nn.Dropout(acoustic_encoder.unit_dropout_prob),", "\n", "# nn.Linear(in_features=output_dim, out_features=output_dim),", "\n", "# nn.Tanh()", "\n", ")", "\n", "\n", "self", ".", "teacher_force", "=", "True", "\n", "self", ".", "teacher_forcing_ratio", "=", "0.3", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AutoEncoder.forward": [[1784, 1860], ["torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "nn_speech_models.AutoEncoder.acoustic_encoder.init_hidden", "nn_speech_models.AutoEncoder.fc", "nn_speech_models.AutoEncoder.fc", "nn_speech_models.AutoEncoder.acoustic_decoder", "nn_speech_models.AutoEncoder.acoustic_encoder", "nn_speech_models.AutoEncoder.acoustic_encoder", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.rand().item", "torch.rand().item", "torch.rand().item", "torch.rand().item", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.AcousticEncoderBiGRU.init_hidden"], ["", "def", "forward", "(", "self", ",", "acoustic_in", ",", "y_sequence_out", ",", "inference", "=", "False", ")", ":", "\n", "\n", "#src = [src len, batch size]", "\n", "#trg = [trg len, batch size]", "\n", "#teacher_forcing_ratio is probability to use teacher forcing", "\n", "#e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time", "\n", "\n", "#print('y_sequence_out', y_sequence_out.shape)", "\n", "\n", "        ", "batch_size", "=", "y_sequence_out", ".", "shape", "[", "0", "]", "\n", "\n", "if", "self", ".", "encoder_type", "in", "[", "'LSTM'", ",", "'BiGRU'", ",", "'BiLSTM'", "]", ":", "\n", "\n", "            ", "_hidden_0", "=", "self", ".", "acoustic_encoder", ".", "init_hidden", "(", "\n", "batch_size", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n", "\n", "acoustic_emb", "=", "self", ".", "fc", "(", "self", ".", "acoustic_encoder", "(", "acoustic_in", ",", "_hidden_0", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "acoustic_emb", "=", "self", ".", "fc", "(", "self", ".", "acoustic_encoder", "(", "acoustic_in", ")", ")", "#self.acoustic_encoder(acoustic_in) #", "\n", "\n", "", "if", "inference", ":", "\n", "            ", "return", "acoustic_emb", "\n", "\n", "# initialize decoder hidden state with acoustic vector", "\n", "", "decoder_hidden_state", "=", "acoustic_emb", "\n", "\n", "\n", "\n", "y_sequence_len", "=", "y_sequence_out", ".", "shape", "[", "2", "]", "\n", "\n", "\n", "num_spectral_coefs", "=", "y_sequence_out", ".", "shape", "[", "1", "]", "\n", "\n", "#tensor to store decoder outputs", "\n", "outputs", "=", "torch", ".", "zeros", "(", "y_sequence_len", ",", "batch_size", ",", "num_spectral_coefs", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "#last hidden state of the encoder is used as the initial hidden state of the decoder", "\n", "#hidden_state = self.acoustic_encoder(acoustic_in)", "\n", "\n", "#first input to the decoder is the <BEGIN> token", "\n", "recurrent_input", "=", "y_sequence_out", "[", ":", ",", ":", ",", "0", "]", "#outputs[0]", "\n", "\n", "#print(recurrent_input)", "\n", "\n", "for", "t", "in", "range", "(", "1", ",", "y_sequence_len", ")", ":", "\n", "\n", "#insert input token embedding, previous hidden", "\n", "#receive output tensor (predictions) and new hidden", "\n", "\n", "#print('main:', recurrent_input.shape)", "\n", "#print('main:', acoustic_emb.shape)", "\n", "\n", "#x = torch.cat([acoustic_emb, recurrent_input], dim=1)#.view(-1)", "\n", "\n", "            ", "output", ",", "decoder_hidden_state", "=", "self", ".", "acoustic_decoder", "(", "recurrent_input", ",", "decoder_hidden_state", ")", "\n", "\n", "\n", "#print('output, decoder_hidden_state', output.shape, decoder_hidden_state.shape)", "\n", "\n", "#place predictions in a tensor holding predictions for each token", "\n", "outputs", "[", "t", "]", "=", "output", "\n", "\n", "#decide if we are going to use teacher forcing or not", "\n", "teacher_force", "=", "torch", ".", "rand", "(", "1", ")", ".", "item", "(", ")", "<", "self", ".", "teacher_forcing_ratio", "#torch.randint(1 + max_num_frames - segment_len, (1,)).item()", "\n", "\n", "#get the highest predicted token from our predictions", "\n", "#top1 = output.argmax(1)", "\n", "\n", "#if teacher forcing, use actual next token as next input", "\n", "#if not, use predicted token", "\n", "recurrent_input", "=", "y_sequence_out", "[", ":", ",", ":", ",", "t", "]", "if", "teacher_force", "else", "output", "\n", "\n", "", "return", "outputs", ",", "acoustic_emb", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.nn_speech_models.generate_batches": [[668, 689], ["torch.utils.data.DataLoader", "data_dict.items", "data_dict[].to"], "function", ["None"], ["", "", "def", "generate_batches", "(", "word_dataset", ",", "batch_size", ",", "shuffle_batches", "=", "True", ",", "\n", "drop_last_batch", "=", "True", ",", "device", "=", "\"cpu\"", ")", ":", "\n", "    ", "\"\"\"\n    A generator function which wraps the PyTorch DataLoader and ensures that\n      each tensor is on the right device (i.e., CPU or GPU).\n    \"\"\"", "\n", "dataloader", "=", "DataLoader", "(", "dataset", "=", "word_dataset", ",", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "shuffle_batches", ",", "drop_last", "=", "drop_last_batch", ")", "\n", "\n", "# for each batch, yield a dictionary with keys: A_word, O_word", "\n", "for", "data_dict", "in", "dataloader", ":", "\n", "# an dict object to yield in each iteration", "\n", "        ", "batch_data_dict", "=", "{", "}", "\n", "\n", "for", "name", ",", "_", "in", "data_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "name", "not", "in", "[", "'orth_sequence'", ",", "'word_seg_id'", "]", ":", "\n", "                ", "batch_data_dict", "[", "name", "]", "=", "data_dict", "[", "name", "]", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "                ", "batch_data_dict", "[", "name", "]", "=", "data_dict", "[", "name", "]", "\n", "\n", "", "", "yield", "batch_data_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.CKA.gram_linear": [[6, 16], ["x.dot"], "function", ["None"], ["def", "gram_linear", "(", "x", ")", ":", "\n", "    ", "\"\"\"Compute Gram (kernel) matrix for a linear kernel.\n\n    Args:\n    x: A num_examples x num_features matrix of features.\n\n    Returns:\n    A num_examples x num_examples Gram matrix of examples.\n    \"\"\"", "\n", "return", "x", ".", "dot", "(", "x", ".", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.CKA.gram_rbf": [[18, 35], ["x.dot", "numpy.diag", "numpy.median", "numpy.exp"], "function", ["None"], ["", "def", "gram_rbf", "(", "x", ",", "threshold", "=", "1.0", ")", ":", "\n", "    ", "\"\"\"Compute Gram (kernel) matrix for an RBF kernel.\n\n    Args:\n    x: A num_examples x num_features matrix of features.\n    threshold: Fraction of median Euclidean distance to use as RBF kernel\n      bandwidth. (This is the heuristic we use in the paper. There are other\n      possible ways to set the bandwidth; we didn't try them.)\n\n    Returns:\n    A num_examples x num_examples Gram matrix of examples.\n    \"\"\"", "\n", "dot_products", "=", "x", ".", "dot", "(", "x", ".", "T", ")", "\n", "sq_norms", "=", "np", ".", "diag", "(", "dot_products", ")", "\n", "sq_distances", "=", "-", "2", "*", "dot_products", "+", "sq_norms", "[", ":", ",", "None", "]", "+", "sq_norms", "[", "None", ",", ":", "]", "\n", "sq_median_distance", "=", "np", ".", "median", "(", "sq_distances", ")", "\n", "return", "np", ".", "exp", "(", "-", "sq_distances", "/", "(", "2", "*", "threshold", "**", "2", "*", "sq_median_distance", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.CKA.center_gram": [[37, 75], ["gram.copy.copy", "numpy.allclose", "ValueError", "numpy.fill_diagonal", "numpy.fill_diagonal", "numpy.mean", "numpy.sum", "numpy.sum", "numpy.mean"], "function", ["None"], ["", "def", "center_gram", "(", "gram", ",", "unbiased", "=", "False", ")", ":", "\n", "    ", "\"\"\"Center a symmetric Gram matrix.\n\n    This is equvialent to centering the (possibly infinite-dimensional) features\n    induced by the kernel before computing the Gram matrix.\n\n    Args:\n    gram: A num_examples x num_examples symmetric matrix.\n    unbiased: Whether to adjust the Gram matrix in order to compute an unbiased\n      estimate of HSIC. Note that this estimator may be negative.\n\n    Returns:\n    A symmetric matrix with centered columns and rows.\n    \"\"\"", "\n", "if", "not", "np", ".", "allclose", "(", "gram", ",", "gram", ".", "T", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Input must be a symmetric matrix.'", ")", "\n", "\n", "", "gram", "=", "gram", ".", "copy", "(", ")", "\n", "\n", "if", "unbiased", ":", "\n", "# This formulation of the U-statistic, from Szekely, G. J., & Rizzo, M.", "\n", "# L. (2014). Partial distance correlation with methods for dissimilarities.", "\n", "# The Annals of Statistics, 42(6), 2382-2412, seems to be more numerically", "\n", "# stable than the alternative from Song et al. (2007).", "\n", "        ", "n", "=", "gram", ".", "shape", "[", "0", "]", "\n", "np", ".", "fill_diagonal", "(", "gram", ",", "0", ")", "\n", "means", "=", "np", ".", "sum", "(", "gram", ",", "0", ",", "dtype", "=", "np", ".", "float64", ")", "/", "(", "n", "-", "2", ")", "\n", "means", "-=", "np", ".", "sum", "(", "means", ")", "/", "(", "2", "*", "(", "n", "-", "1", ")", ")", "\n", "gram", "-=", "means", "[", ":", ",", "None", "]", "\n", "gram", "-=", "means", "[", "None", ",", ":", "]", "\n", "np", ".", "fill_diagonal", "(", "gram", ",", "0", ")", "\n", "", "else", ":", "\n", "        ", "means", "=", "np", ".", "mean", "(", "gram", ",", "0", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "means", "-=", "np", ".", "mean", "(", "means", ")", "/", "2", "\n", "gram", "-=", "means", "[", ":", ",", "None", "]", "\n", "gram", "-=", "means", "[", "None", ",", ":", "]", "\n", "\n", "", "return", "gram", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.CKA.cka": [[77, 98], ["CKA.center_gram", "CKA.center_gram", "center_gram.ravel().dot", "numpy.linalg.norm", "numpy.linalg.norm", "center_gram.ravel", "center_gram.ravel"], "function", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.CKA.center_gram", "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.CKA.center_gram"], ["", "def", "cka", "(", "gram_x", ",", "gram_y", ",", "debiased", "=", "False", ")", ":", "\n", "    ", "\"\"\"Compute CKA.\n\n    Args:\n    gram_x: A num_examples x num_examples Gram matrix.\n    gram_y: A num_examples x num_examples Gram matrix.\n    debiased: Use unbiased estimator of HSIC. CKA may still be biased.\n\n    Returns:\n    The value of CKA between X and Y.\n    \"\"\"", "\n", "gram_x", "=", "center_gram", "(", "gram_x", ",", "unbiased", "=", "debiased", ")", "\n", "gram_y", "=", "center_gram", "(", "gram_y", ",", "unbiased", "=", "debiased", ")", "\n", "\n", "# Note: To obtain HSIC, this should be divided by (n-1)**2 (biased variant) or", "\n", "# n*(n-3) (unbiased variant), but this cancels for CKA.", "\n", "scaled_hsic", "=", "gram_x", ".", "ravel", "(", ")", ".", "dot", "(", "gram_y", ".", "ravel", "(", ")", ")", "\n", "\n", "normalization_x", "=", "np", ".", "linalg", ".", "norm", "(", "gram_x", ")", "\n", "normalization_y", "=", "np", ".", "linalg", ".", "norm", "(", "gram_y", ")", "\n", "return", "scaled_hsic", "/", "(", "normalization_x", "*", "normalization_y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.CKA._debiased_dot_product_similarity_helper": [[100, 109], ["sum_squared_rows_x.dot"], "function", ["None"], ["", "def", "_debiased_dot_product_similarity_helper", "(", "\n", "xty", ",", "sum_squared_rows_x", ",", "sum_squared_rows_y", ",", "squared_norm_x", ",", "squared_norm_y", ",", "\n", "n", ")", ":", "\n", "    ", "\"\"\"Helper for computing debiased dot product similarity (i.e. linear HSIC).\"\"\"", "\n", "# This formula can be derived by manipulating the unbiased estimator from", "\n", "# Song et al. (2007).", "\n", "return", "(", "\n", "xty", "-", "n", "/", "(", "n", "-", "2.", ")", "*", "sum_squared_rows_x", ".", "dot", "(", "sum_squared_rows_y", ")", "\n", "+", "squared_norm_x", "*", "squared_norm_y", "/", "(", "(", "n", "-", "1", ")", "*", "(", "n", "-", "2", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.CKA.feature_space_linear_cka": [[111, 152], ["numpy.linalg.norm", "numpy.linalg.norm", "numpy.mean", "numpy.mean", "numpy.linalg.norm", "features_x.T.dot", "features_y.T.dot", "numpy.einsum", "numpy.einsum", "numpy.sum", "numpy.sum", "CKA._debiased_dot_product_similarity_helper", "numpy.sqrt", "numpy.sqrt", "features_x.T.dot", "CKA._debiased_dot_product_similarity_helper", "CKA._debiased_dot_product_similarity_helper"], "function", ["home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.CKA._debiased_dot_product_similarity_helper", "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.CKA._debiased_dot_product_similarity_helper", "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.CKA._debiased_dot_product_similarity_helper"], ["", "def", "feature_space_linear_cka", "(", "features_x", ",", "features_y", ",", "debiased", "=", "False", ")", ":", "\n", "    ", "\"\"\"Compute CKA with a linear kernel, in feature space.\n\n    This is typically faster than computing the Gram matrix when there are fewer\n    features than examples.\n\n    Args:\n    features_x: A num_examples x num_features matrix of features.\n    features_y: A num_examples x num_features matrix of features.\n    debiased: Use unbiased estimator of dot product similarity. CKA may still be\n      biased. Note that this estimator may be negative.\n\n    Returns:\n    The value of CKA between X and Y.\n    \"\"\"", "\n", "features_x", "=", "features_x", "-", "np", ".", "mean", "(", "features_x", ",", "0", ",", "keepdims", "=", "True", ")", "\n", "features_y", "=", "features_y", "-", "np", ".", "mean", "(", "features_y", ",", "0", ",", "keepdims", "=", "True", ")", "\n", "\n", "dot_product_similarity", "=", "np", ".", "linalg", ".", "norm", "(", "features_x", ".", "T", ".", "dot", "(", "features_y", ")", ")", "**", "2", "\n", "normalization_x", "=", "np", ".", "linalg", ".", "norm", "(", "features_x", ".", "T", ".", "dot", "(", "features_x", ")", ")", "\n", "normalization_y", "=", "np", ".", "linalg", ".", "norm", "(", "features_y", ".", "T", ".", "dot", "(", "features_y", ")", ")", "\n", "\n", "if", "debiased", ":", "\n", "        ", "n", "=", "features_x", ".", "shape", "[", "0", "]", "\n", "# Equivalent to np.sum(features_x ** 2, 1) but avoids an intermediate array.", "\n", "sum_squared_rows_x", "=", "np", ".", "einsum", "(", "'ij,ij->i'", ",", "features_x", ",", "features_x", ")", "\n", "sum_squared_rows_y", "=", "np", ".", "einsum", "(", "'ij,ij->i'", ",", "features_y", ",", "features_y", ")", "\n", "squared_norm_x", "=", "np", ".", "sum", "(", "sum_squared_rows_x", ")", "\n", "squared_norm_y", "=", "np", ".", "sum", "(", "sum_squared_rows_y", ")", "\n", "\n", "dot_product_similarity", "=", "_debiased_dot_product_similarity_helper", "(", "\n", "dot_product_similarity", ",", "sum_squared_rows_x", ",", "sum_squared_rows_y", ",", "\n", "squared_norm_x", ",", "squared_norm_y", ",", "n", ")", "\n", "normalization_x", "=", "np", ".", "sqrt", "(", "_debiased_dot_product_similarity_helper", "(", "\n", "normalization_x", "**", "2", ",", "sum_squared_rows_x", ",", "sum_squared_rows_x", ",", "\n", "squared_norm_x", ",", "squared_norm_x", ",", "n", ")", ")", "\n", "normalization_y", "=", "np", ".", "sqrt", "(", "_debiased_dot_product_similarity_helper", "(", "\n", "normalization_y", "**", "2", ",", "sum_squared_rows_y", ",", "sum_squared_rows_y", ",", "\n", "squared_norm_y", ",", "squared_norm_y", ",", "n", ")", ")", "\n", "\n", "", "return", "dot_product_similarity", "/", "(", "normalization_x", "*", "normalization_y", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.train_utils.make_train_state": [[19, 31], ["None"], "function", ["None"], ["def", "make_train_state", "(", "args", ")", ":", "\n", "    ", "return", "{", "\n", "'stop_early'", ":", "False", ",", "\n", "'early_stopping_step'", ":", "0", ",", "\n", "'early_stopping_best_val'", ":", "1e8", ",", "\n", "'learning_rate'", ":", "args", "[", "'training_hyperparams'", "]", "[", "'learning_rate'", "]", ",", "\n", "'epoch_index'", ":", "0", ",", "\n", "'train_loss'", ":", "[", "]", ",", "\n", "'val_loss'", ":", "[", "]", ",", "\n", "'val_acoustic_mAP'", ":", "[", "]", ",", "\n", "'val_crossview_mAP'", ":", "[", "]", ",", "\n", "'model_filename'", ":", "args", "[", "'model_state_file'", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.train_utils.update_train_state": [[34, 76], ["torch.save", "torch.save", "model.state_dict", "str"], "function", ["None"], ["", "def", "update_train_state", "(", "args", ",", "model", ",", "train_state", ")", ":", "\n", "    ", "\"\"\"Handle the training state updates.\n    Components:\n     - Early Stopping: Prevent overfitting.\n     - Model Checkpoint: Model is saved if the model is better\n    :param args: main arguments\n    :param model: model to train\n    :param train_state: a dictionary representing the training state values\n    :returns:\n        a new train_state\n    \"\"\"", "\n", "# save model", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "train_state", "[", "'model_filename'", "]", "+", "'_'", "+", "str", "(", "train_state", "[", "'epoch_index'", "]", "+", "1", ")", "+", "'.pth'", ")", "\n", "\n", "# save model after first epoch", "\n", "if", "train_state", "[", "'epoch_index'", "]", "==", "0", ":", "\n", "        ", "train_state", "[", "'stop_early'", "]", "=", "False", "\n", "train_state", "[", "'best_val_acoustic_mAP'", "]", "=", "train_state", "[", "'val_acoustic_mAP'", "]", "[", "-", "1", "]", "\n", "\n", "# after first epoch check early stopping criteria", "\n", "", "elif", "train_state", "[", "'epoch_index'", "]", ">=", "1", ":", "\n", "        ", "score_mAP", "=", "train_state", "[", "'val_acoustic_mAP'", "]", "[", "-", "1", "]", "\n", "\n", "# if acc decreased, add one to early stopping criteria", "\n", "if", "score_mAP", "<=", "train_state", "[", "'best_val_acoustic_mAP'", "]", ":", "\n", "# Update step", "\n", "            ", "train_state", "[", "'early_stopping_step'", "]", "+=", "1", "\n", "\n", "", "else", ":", "# if acc improved", "\n", "            ", "train_state", "[", "'best_val_acoustic_mAP'", "]", "=", "train_state", "[", "'val_acoustic_mAP'", "]", "[", "-", "1", "]", "\n", "\n", "# Reset early stopping step", "\n", "train_state", "[", "'early_stopping_step'", "]", "=", "0", "\n", "\n", "# Stop early ?", "\n", "", "early_stop", "=", "train_state", "[", "'early_stopping_step'", "]", ">=", "args", "[", "'training_hyperparams'", "]", "[", "'early_stopping_criteria'", "]", "\n", "\n", "train_state", "[", "'stop_early'", "]", "=", "early_stop", "\n", "\n", "", "return", "train_state", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.train_utils.compute_accuracy": [[78, 83], ["y_pred.max", "torch.eq().sum().item", "torch.eq().sum().item", "torch.eq().sum", "torch.eq().sum", "len", "torch.eq", "torch.eq"], "function", ["None"], ["", "def", "compute_accuracy", "(", "y_pred", ",", "y_target", ")", ":", "\n", "#y_target = y_target.cpu()", "\n", "    ", "_", ",", "y_pred_indices", "=", "y_pred", ".", "max", "(", "dim", "=", "1", ")", "\n", "n_correct", "=", "torch", ".", "eq", "(", "y_pred_indices", ",", "y_target", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "n_correct", "/", "len", "(", "y_pred_indices", ")", "*", "100", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.train_utils.get_predictions_and_trues": [[85, 93], ["y_pred.max", "y_pred_indices.tolist", "y_target.tolist"], "function", ["None"], ["", "def", "get_predictions_and_trues", "(", "y_pred", ",", "y_target", ")", ":", "\n", "\t", "\"\"\"Return indecies of predictions. \"\"\"", "\n", "_", ",", "y_pred_indices", "=", "y_pred", ".", "max", "(", "dim", "=", "1", ")", "\n", "\n", "pred_labels", "=", "y_pred_indices", ".", "tolist", "(", ")", "\n", "true_labels", "=", "y_target", ".", "tolist", "(", ")", "\n", "\n", "return", "(", "pred_labels", ",", "true_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.train_utils.set_seed_everywhere": [[95, 100], ["numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed_everywhere", "(", "seed", ",", "cuda", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "cuda", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.train_utils.handle_dirs": [[102, 105], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "def", "handle_dirs", "(", "dirpath", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "dirpath", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.train_utils.get_hard_negatives": [[109, 206], ["index_mat.cpu().detach().numpy.cpu().detach().numpy", "query_mat.cpu().detach().numpy.cpu().detach().numpy", "faiss.normalize_L2", "faiss.normalize_L2", "faiss.IndexFlatIP", "faiss.IndexFlatIP.add", "faiss.IndexFlatIP.search", "numpy.vectorize", "np.vectorize.", "zip", "zip", "neg_list.append", "zip", "sorted_neg_by_index.append", "list", "enumerate", "index_mat.cpu().detach().numpy.cpu().detach", "query_mat.cpu().detach().numpy.cpu().detach", "enumerate", "filtering_func", "map", "zip", "print", "numpy.random.randint", "negative_indicies.append", "batch_items.append", "len", "index_mat.cpu().detach().numpy.cpu", "query_mat.cpu().detach().numpy.cpu", "str", "str"], "function", ["None"], ["", "", "def", "get_hard_negatives", "(", "index_mat", ",", "query_mat", ",", "labels", ",", "negative_strategy", "=", "'hard'", ",", "debug", "=", "False", ")", ":", "\n", "    ", "\"\"\"Get N, M, and L, return hard negatives\"\"\"", "\n", "\n", "index_mat", "=", "index_mat", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "query_mat", "=", "query_mat", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "faiss", ".", "normalize_L2", "(", "index_mat", ")", "\n", "\n", "faiss", ".", "normalize_L2", "(", "query_mat", ")", "\n", "\n", "d", "=", "index_mat", ".", "shape", "[", "1", "]", "# this should be the size of the embedding", "\n", "\n", "# build index", "\n", "faiss_idx", "=", "faiss", ".", "IndexFlatIP", "(", "d", ")", "\n", "faiss_idx", ".", "add", "(", "index_mat", ")", "\n", "\n", "k", "=", "index_mat", ".", "shape", "[", "0", "]", "# we want to see k nearest neighbors", "\n", "D", ",", "I", "=", "faiss_idx", ".", "search", "(", "query_mat", ",", "k", ")", "\n", "\n", "#print(I)", "\n", "#print(D)", "\n", "\n", "# get hard negative for each anchor point", "\n", "# with one constraint; the negative should not", "\n", "# correspond to the same label", "\n", "\n", "idx2label", "=", "{", "i", ":", "l", "for", "i", ",", "l", "in", "enumerate", "(", "labels", ")", "}", "\n", "\n", "#label2idx = {'_'.join([str(i),str(l)]):i for i, l in idx2label.items()}", "\n", "\n", "#print(label2idx)", "\n", "\n", "\n", "labeling_func", "=", "lambda", "i", ":", "idx2label", "[", "i", "]", "\n", "\n", "vfunc", "=", "np", ".", "vectorize", "(", "labeling_func", ")", "\n", "\n", "I2", "=", "vfunc", "(", "I", ")", "\n", "\n", "# [f(x) if condition else g(x) for x in sequence]", "\n", "filtering_func", "=", "lambda", "i", ",", "j_list", ":", "[", "1", "if", "i", "!=", "j", "else", "0", "for", "j", "in", "j_list", "]", "# else 0", "\n", "\n", "neg_list", "=", "[", "]", "\n", "\n", "for", "row", ",", "label", "in", "zip", "(", "I2", ",", "labels", ")", ":", "\n", "        ", "neg_list", ".", "append", "(", "filtering_func", "(", "label", ",", "row", ")", ")", "\n", "\n", "#print(neg_list)", "\n", "\n", "", "sorted_neg_by_index", "=", "[", "]", "\n", "\n", "for", "row1", ",", "row2", ",", "neg", "in", "zip", "(", "I", ",", "I2", ",", "neg_list", ")", ":", "\n", "\n", "        ", "batch_items", "=", "[", "]", "\n", "\n", "for", "w_idx", ",", "w_lbl", ",", "isNeg", "in", "zip", "(", "row1", ",", "row2", ",", "neg", ")", ":", "\n", "#print((w_idx, w_lbl, isSame), end=' ')", "\n", "\n", "            ", "if", "isNeg", ":", "\n", "                ", "batch_items", ".", "append", "(", "w_idx", ")", "\n", "\n", "", "", "sorted_neg_by_index", ".", "append", "(", "batch_items", ")", "\n", "#print()", "\n", "\n", "\n", "#for item in sorted_neg_by_index:", "\n", "#print(item)", "\n", "\n", "", "sorted_neg_by_label", "=", "[", "list", "(", "map", "(", "labeling_func", ",", "l", ")", ")", "for", "l", "in", "sorted_neg_by_index", "]", "\n", "\n", "#for item in zip(sorted_neg_by_label, sorted_neg_by_index):", "\n", "#print(item)", "\n", "\n", "if", "debug", ":", "\n", "        ", "for", "i", ",", "(", "negative_labels", ",", "negative_indicies", ")", "in", "enumerate", "(", "zip", "(", "sorted_neg_by_label", ",", "sorted_neg_by_index", ")", ")", ":", "\n", "            ", "print", "(", "f\"{i:<7}{idx2label[i]:<7} {label2word[idx2label[i]]:<10}\"", "\n", "f\"{' '.join(str(m) for m in negative_labels):<35}\"", "\n", "f\"{' '.join(str(m) for m in negative_indicies):<35}\"", ")", "\n", "#f\"\\t {' '.join(str(label2word[m]) for m in ll):<50}\")", "\n", "\n", "#print(f\"{i:<5} {word2label[w]:<5} {w:<10}\")", "\n", "\n", "\n", "\n", "", "", "if", "negative_strategy", "==", "'hard'", ":", "\n", "        ", "negative_indicies", "=", "[", "n", "[", "0", "]", "for", "n", "in", "sorted_neg_by_index", "]", "\n", "return", "negative_indicies", "\n", "\n", "", "if", "negative_strategy", "==", "'random'", ":", "\n", "        ", "negative_indicies", "=", "[", "]", "\n", "\n", "for", "row", "in", "sorted_neg_by_index", ":", "\n", "            ", "rand_idx", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "row", ")", ")", "\n", "\n", "negative_indicies", ".", "append", "(", "row", "[", "rand_idx", "]", ")", "\n", "\n", "", "return", "negative_indicies", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.train_utils.average_precision": [[209, 329], ["faiss.normalize_L2", "faiss.normalize_L2", "faiss.IndexFlatIP", "faiss.IndexFlatIP.add", "numpy.vectorize", "np.vectorize.", "zip", "faiss.IndexFlatIP.search", "faiss.IndexFlatIP.search", "print", "print", "range", "numpy.array", "AP_values.append", "print", "enumerate", "print", "print", "numpy.equal", "numpy.cumsum", "numpy.arange", "numpy.sum", "sum", "index2word[].encode", "print", "index2word[].encode", "range", "len", "len"], "function", ["None"], ["", "", "def", "average_precision", "(", "database_mat", ",", "query_mat", ",", "database_labels", ",", "query_labels", ",", "index2word", ",", "single_view", "=", "False", ")", ":", "\n", "    ", "\"\"\"Get two matrices and list of labels, return AP\"\"\"", "\n", "\n", "# L2 normalize to allow for cosine distance measure", "\n", "faiss", ".", "normalize_L2", "(", "database_mat", ")", "\n", "faiss", ".", "normalize_L2", "(", "query_mat", ")", "\n", "\n", "# d is the dim of the embedding", "\n", "d", "=", "database_mat", ".", "shape", "[", "1", "]", "\n", "\n", "# build index wuing FAISS", "\n", "faiss_index", "=", "faiss", ".", "IndexFlatIP", "(", "d", ")", "\n", "faiss_index", ".", "add", "(", "database_mat", ")", "\n", "#print(faiss_index.ntotal)", "\n", "\n", "# query the index", "\n", "k", "=", "database_mat", ".", "shape", "[", "0", "]", "# we want to see k nearest neighbors", "\n", "\n", "if", "single_view", ":", "\n", "        ", "D", ",", "ranked_candidates_by_index", "=", "faiss_index", ".", "search", "(", "query_mat", ",", "k", ")", "#[1:, :]", "\n", "\n", "", "else", ":", "\n", "        ", "D", ",", "ranked_candidates_by_index", "=", "faiss_index", ".", "search", "(", "query_mat", ",", "k", ")", "\n", "\n", "", "if", "single_view", ":", "\n", "        ", "print", "(", "ranked_candidates_by_index", "[", "0", "]", "[", ":", "10", "]", ")", "\n", "#     print(index2word[idx], end='\\t')", "\n", "# print()", "\n", "\n", "for", "d", "in", "D", "[", "0", "]", "[", ":", "10", "]", ":", "\n", "            ", "print", "(", "f\"{d:.9f}\"", ",", "end", "=", "'\\t'", ")", "\n", "", "print", "(", ")", "\n", "\n", "#print(len(database_labels))", "\n", "#print(database_mat[0])", "\n", "\n", "\n", "# make a dict for DB index -->  word label", "\n", "", "faiss_index_to_word_label", "=", "{", "i", ":", "l", "for", "i", ",", "l", "in", "enumerate", "(", "database_labels", ")", "}", "\n", "\n", "# make a function to obtain word label of the index, then vectorize", "\n", "get_word_label", "=", "lambda", "i", ":", "faiss_index_to_word_label", "[", "i", "]", "\n", "get_word_label", "=", "np", ".", "vectorize", "(", "get_word_label", ")", "\n", "\n", "\n", "ranked_candidates_by_word_label", "=", "get_word_label", "(", "ranked_candidates_by_index", ")", "\n", "if", "single_view", ":", "\n", "#print(index2word[database_labels[0]].encode('utf-8'))", "\n", "\n", "# for idx in ranked_candidates_by_word_label[0][:10]:", "\n", "#     print(index2word[idx].encode('utf-8'), end='\\t')", "\n", "\n", "# print()", "\n", "\n", "# print(index2word[database_labels[1]].encode('utf-8'))", "\n", "\n", "# for idx in ranked_candidates_by_word_label[1][:10]:", "\n", "#     print(index2word[idx].encode('utf-8'), end='\\t')", "\n", "# print()", "\n", "\n", "# print(index2word[database_labels[2]].encode('utf-8')) #.decode(sys.stdout.encoding)", "\n", "\n", "# for idx in ranked_candidates_by_word_label[2][:10]:", "\n", "#     print(index2word[idx].encode('utf-8'), end='\\t')", "\n", "# print()", "\n", "\n", "# print(index2word[database_labels[3]].encode('utf-8'))", "\n", "\n", "# for idx in ranked_candidates_by_word_label[3][:10]:", "\n", "#     print(index2word[idx].encode('utf-8'), end='\\t')", "\n", "# print()", "\n", "\n", "        ", "for", "i", "in", "range", "(", "20", ")", ":", "\n", "            ", "print", "(", "index2word", "[", "database_labels", "[", "i", "]", "]", ".", "encode", "(", "'utf-8'", ")", ")", "#.decode('utf-8')", "\n", "\n", "for", "idx", "in", "ranked_candidates_by_word_label", "[", "i", "]", "[", ":", "25", "]", ":", "\n", "                ", "print", "(", "index2word", "[", "idx", "]", ".", "encode", "(", "'utf-8'", ")", ",", "end", "=", "'\\t'", ")", "#.decode('utf-8')", "\n", "", "print", "(", ")", "\n", "\n", "\n", "\n", "", "", "AP_values", "=", "[", "]", "\n", "\n", "\n", "\n", "# loop over each query word and the ranked candidates", "\n", "for", "query_word", ",", "candidates", "in", "zip", "(", "query_labels", ",", "ranked_candidates_by_word_label", ")", ":", "\n", "# chech if single-view so the word vector of", "\n", "# the same sample is not included in the candidate list", "\n", "            ", "if", "single_view", ":", "\n", "\n", "# when sim is all 0, this does not hold! ", "\n", "                ", "candidates", "=", "candidates", "[", "1", ":", "]", "\n", "\n", "# if the query word has matching sample then go to next sample", "\n", "# this skips words that are not a part of a pair", "\n", "if", "query_word", "not", "in", "candidates", ":", "\n", "                    ", "continue", "\n", "\n", "#print('length:', len(candidates), 'Query:', query_word,  ' '.join(str(i) for i in candidates))", "\n", "\n", "#from random import shuffle", "\n", "#shuffle(candidates)", "\n", "\n", "# make a vector of the word label repeated as the candidate list", "\n", "", "", "target_word_label", "=", "np", ".", "array", "(", "\n", "[", "query_word", "for", "i", "in", "range", "(", "len", "(", "candidates", ")", ")", "]", "\n", ")", "\n", "\n", "# make a binary [0 1 .. ] array of whether word is a match", "\n", "matches", "=", "1", "*", "np", ".", "equal", "(", "target_word_label", ",", "candidates", ")", "\n", "\n", "# Calculate precision for this query word", "\n", "precision", "=", "np", ".", "cumsum", "(", "matches", ")", "/", "np", ".", "arange", "(", "1", ",", "len", "(", "matches", ")", "+", "1", ")", "\n", "\n", "AP", "=", "np", ".", "sum", "(", "precision", "*", "matches", ")", "/", "sum", "(", "matches", ")", "\n", "\n", "AP_values", ".", "append", "(", "AP", ")", "\n", "\n", "", "return", "AP_values", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.train_utils.compute_kendalls_tau": [[332, 408], ["faiss.normalize_L2", "faiss.normalize_L2", "print", "faiss.IndexFlatIP", "faiss.IndexFlatIP.add", "print", "faiss.IndexFlatIP.search", "print", "collections.defaultdict", "word2dist.keys", "collections.defaultdict", "word2dist.keys", "collections.defaultdict", "range", "enumerate", "len", "enumerate", "scipy.kendalltau", "scipy.spearmanr", "tau_values.append", "spr_values.append", "collections.defaultdict", "dict().items", "collections.defaultdict", "collections.defaultdict", "list", "phon_ranks.append", "cosd_ranks.append", "PWLD_rank2word[].items", "cos_rank2word[].items", "dict", "sorted", "word2dist[].items"], "function", ["None"], ["", "def", "compute_kendalls_tau", "(", "database_mat", ",", "query_mat", ",", "word2dist", ",", "index2word", ")", ":", "\n", "\n", "# L2 normalize to allow for cosine distance measure", "\n", "    ", "faiss", ".", "normalize_L2", "(", "database_mat", ")", "\n", "faiss", ".", "normalize_L2", "(", "query_mat", ")", "\n", "\n", "# d is the dim of the embedding", "\n", "d", "=", "database_mat", ".", "shape", "[", "1", "]", "\n", "\n", "# build index wuing FAISS", "\n", "print", "(", "'Build FAISS index ...'", ")", "\n", "faiss_index", "=", "faiss", ".", "IndexFlatIP", "(", "d", ")", "\n", "faiss_index", ".", "add", "(", "database_mat", ")", "\n", "#print(faiss_index.ntotal)", "\n", "\n", "# query the index", "\n", "k", "=", "database_mat", ".", "shape", "[", "0", "]", "# we want to see k nearest neighbors", "\n", "\n", "\n", "# perform search ", "\n", "print", "(", "'Query FAISS index ...'", ")", "\n", "D", ",", "I", "=", "faiss_index", ".", "search", "(", "query_mat", ",", "k", ")", "\n", "\n", "\n", "# compute rank by phonological distance ", "\n", "print", "(", "'Compute rank by PWLD similarity ...'", ")", "\n", "PWLD_rank2word", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", ")", ")", "\n", "\n", "for", "w1", "in", "word2dist", ".", "keys", "(", ")", ":", "\n", "\n", "        ", "for", "i", ",", "(", "w2", ",", "d", ")", "in", "enumerate", "(", "dict", "(", "sorted", "(", "word2dist", "[", "w1", "]", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "item", "[", "1", "]", ")", ")", ".", "items", "(", ")", ")", ":", "\n", "\n", "            ", "PWLD_rank2word", "[", "w1", "]", "[", "i", "]", "=", "w2", "\n", "\n", "\n", "# switch key vs value in PWLD_rank2word", "\n", "", "", "word2PWLD_rank", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", ")", ")", "\n", "\n", "for", "w1", "in", "word2dist", ".", "keys", "(", ")", ":", "\n", "        ", "word2PWLD_rank", "[", "w1", "]", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "PWLD_rank2word", "[", "w1", "]", ".", "items", "(", ")", "}", "\n", "\n", "\n", "# obtain rank by cosine similarity", "\n", "", "cos_rank2word", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", ")", ")", "\n", "\n", "for", "q_idx", "in", "range", "(", "len", "(", "I", ")", ")", ":", "\n", "\n", "        ", "for", "i", ",", "hit_idx", "in", "enumerate", "(", "I", "[", "q_idx", "]", ")", ":", "\n", "            ", "cos_rank2word", "[", "q_idx", "]", "[", "i", "]", "=", "index2word", "[", "hit_idx", "]", "\n", "\n", "\n", "# obtain kendall's tau for each word query", "\n", "", "", "tau_values", "=", "[", "]", "\n", "spr_values", "=", "[", "]", "\n", "word2tau", "=", "{", "}", "\n", "\n", "for", "dict_idx", "in", "cos_rank2word", ":", "\n", "\n", "        ", "phon_ranks", "=", "[", "]", "\n", "cosd_ranks", "=", "[", "]", "\n", "\n", "for", "rank", ",", "word", "in", "list", "(", "cos_rank2word", "[", "dict_idx", "]", ".", "items", "(", ")", ")", "[", "1", ":", "]", ":", "\n", "\n", "            ", "phon_ranks", ".", "append", "(", "word2PWLD_rank", "[", "index2word", "[", "dict_idx", "]", "]", "[", "word", "]", ")", "\n", "cosd_ranks", ".", "append", "(", "rank", ")", "\n", "\n", "", "tau", ",", "p_value", "=", "stats", ".", "kendalltau", "(", "cosd_ranks", ",", "phon_ranks", ")", "\n", "spr", ",", "p_value", "=", "stats", ".", "spearmanr", "(", "cosd_ranks", ",", "phon_ranks", ")", "\n", "\n", "word2tau", "[", "dict_idx", "]", "=", "tau", "\n", "\n", "tau_values", ".", "append", "(", "tau", ")", "\n", "spr_values", ".", "append", "(", "spr", ")", "\n", "\n", "\n", "", "return", "tau_values", ",", "spr_values", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.train_utils.compute_kendalls_tau_rsa": [[411, 494], ["faiss.normalize_L2", "faiss.normalize_L2", "faiss.normalize_L2", "print", "faiss.IndexFlatIP", "faiss.IndexFlatIP.add", "faiss.IndexFlatIP", "faiss.IndexFlatIP.add", "print", "faiss.IndexFlatIP.search", "print", "faiss.IndexFlatIP.search", "collections.defaultdict", "collections.defaultdict", "range", "range", "len", "enumerate", "len", "enumerate", "scipy.kendalltau", "scipy.spearmanr", "tau_values.append", "spr_values.append", "collections.defaultdict", "collections.defaultdict", "L1_ranks.append", "L2_ranks.append"], "function", ["None"], ["", "def", "compute_kendalls_tau_rsa", "(", "database_mat_1", ",", "database_mat_2", ",", "query_mat", ")", ":", "\n", "\n", "# L2 normalize to allow for cosine distance measure", "\n", "    ", "faiss", ".", "normalize_L2", "(", "database_mat_1", ")", "\n", "faiss", ".", "normalize_L2", "(", "database_mat_2", ")", "\n", "faiss", ".", "normalize_L2", "(", "query_mat", ")", "\n", "\n", "# d is the dim of the embedding", "\n", "d", "=", "database_mat_1", ".", "shape", "[", "1", "]", "\n", "\n", "# build index_1 using FAISS", "\n", "print", "(", "'Build FAISS index ...'", ")", "\n", "faiss_index_1", "=", "faiss", ".", "IndexFlatIP", "(", "d", ")", "\n", "faiss_index_1", ".", "add", "(", "database_mat_1", ")", "\n", "\n", "# build index_2 using FAISS", "\n", "faiss_index_2", "=", "faiss", ".", "IndexFlatIP", "(", "d", ")", "\n", "faiss_index_2", ".", "add", "(", "database_mat_2", ")", "\n", "\n", "\n", "\n", "# query the index", "\n", "k", "=", "database_mat_1", ".", "shape", "[", "0", "]", "# we want to see k nearest neighbors", "\n", "\n", "\n", "# perform search ", "\n", "print", "(", "'Query FAISS index_1 ...'", ")", "\n", "D1", ",", "I1", "=", "faiss_index_1", ".", "search", "(", "query_mat", ",", "k", ")", "\n", "\n", "print", "(", "'Query FAISS index_2 ...'", ")", "\n", "D2", ",", "I2", "=", "faiss_index_2", ".", "search", "(", "query_mat", ",", "k", ")", "\n", "\n", "\n", "# obtain rank by cosine similarity", "\n", "ordering_1", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", ")", ")", "\n", "ordering_2", "=", "defaultdict", "(", "lambda", ":", "defaultdict", "(", ")", ")", "\n", "\n", "\n", "# for each query q_idx, ordering_1 is hit_idx --> rank", "\n", "for", "q_idx", "in", "range", "(", "len", "(", "I1", ")", ")", ":", "\n", "        ", "for", "i", ",", "hit_idx", "in", "enumerate", "(", "I1", "[", "q_idx", "]", ")", ":", "\n", "            ", "ordering_1", "[", "q_idx", "]", "[", "hit_idx", "]", "=", "i", "\n", "\n", "# for each query q_idx, ordering_2 is hit_idx --> rank", "\n", "", "", "for", "q_idx", "in", "range", "(", "len", "(", "I2", ")", ")", ":", "\n", "        ", "for", "i", ",", "hit_idx", "in", "enumerate", "(", "I2", "[", "q_idx", "]", ")", ":", "\n", "            ", "ordering_2", "[", "q_idx", "]", "[", "hit_idx", "]", "=", "i", "\n", "\n", "\n", "\n", "\n", "# obtain kendall's tau for each word query", "\n", "", "", "tau_values", "=", "[", "]", "\n", "spr_values", "=", "[", "]", "\n", "#word2tau = {}", "\n", "\n", "for", "q_idx", "in", "ordering_1", ":", "# for each query ", "\n", "\n", "        ", "L1_ranks", "=", "[", "]", "\n", "L2_ranks", "=", "[", "]", "\n", "\n", "for", "hit", "in", "ordering_1", "[", "q_idx", "]", ":", "\n", "\n", "            ", "L1_ranks", ".", "append", "(", "ordering_1", "[", "q_idx", "]", "[", "hit", "]", ")", "\n", "L2_ranks", ".", "append", "(", "ordering_2", "[", "q_idx", "]", "[", "hit", "]", ")", "\n", "\n", "\n", "\n", "# for rank, word in list(ordering_1[dict_idx].items())[1:]:", "\n", "\n", "#     phon_ranks.append(word2PWLD_rank[index2word[dict_idx]][word])", "\n", "#     cosd_ranks.append(rank)", "\n", "\n", "", "tau", ",", "p_value", "=", "stats", ".", "kendalltau", "(", "L1_ranks", ",", "L2_ranks", ")", "\n", "spr", ",", "p_value", "=", "stats", ".", "spearmanr", "(", "L1_ranks", ",", "L2_ranks", ")", "\n", "\n", "#word2tau[dict_idx] = tau", "\n", "\n", "tau_values", ".", "append", "(", "tau", ")", "\n", "spr_values", ".", "append", "(", "spr", ")", "\n", "\n", "\n", "", "return", "tau_values", ",", "spr_values", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.train_utils.triplet_loss_func": [[496, 513], ["torch.relu", "torch.set_printoptions", "torch.set_printoptions", "F.relu.sum", "torch.tensor().cuda", "torch.tensor().cuda", "torch.cosine_similarity", "distance_function", "torch.tensor", "torch.tensor", "distance_function"], "function", ["None"], ["", "def", "triplet_loss_func", "(", "a", ",", "p", ",", "n", ",", "margin", "=", "0.4", ")", ":", "\n", "    ", "\"\"\"\n    Givne three tensors, return triplet margin loss.\n    \"\"\"", "\n", "\n", "# get batch size, if batch size == 1, return 0.0 loss", "\n", "m", "=", "a", ".", "shape", "[", "0", "]", "\n", "\n", "if", "m", "==", "1", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "0.0", ",", "requires_grad", "=", "True", ")", ".", "cuda", "(", ")", "\n", "\n", "", "distance_function", "=", "lambda", "x", ",", "y", ":", "1.0", "-", "F", ".", "cosine_similarity", "(", "x", ",", "y", ")", "\n", "\n", "loss", "=", "F", ".", "relu", "(", "margin", "+", "distance_function", "(", "a", ",", "p", ")", "-", "distance_function", "(", "a", ",", "n", ")", ")", "\n", "\n", "torch", ".", "set_printoptions", "(", "precision", "=", "14", ")", "\n", "return", "loss", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.train_utils.weights_init_uniform_rule": [[517, 526], ["classname.find", "m.weight.data.uniform_", "m.bias.data.fill_", "numpy.sqrt"], "function", ["None"], ["", "def", "weights_init_uniform_rule", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "# for every Linear layer in a model..", "\n", "if", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "# get the number of the inputs", "\n", "        ", "n", "=", "m", ".", "in_features", "\n", "y", "=", "1.0", "/", "np", ".", "sqrt", "(", "n", ")", "\n", "m", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "y", ",", "y", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uds-lsv_xrsa-awes.None.train_utils.weights_init_uniform": [[530, 537], ["classname.find", "m.weight.data.uniform_", "m.bias.data.fill_"], "function", ["None"], ["", "", "def", "weights_init_uniform", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "# for every Linear layer in a model..", "\n", "if", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "# apply a uniform distribution to the weights and a bias=0", "\n", "        ", "m", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "0.05", ",", "0.05", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "", ""]]}