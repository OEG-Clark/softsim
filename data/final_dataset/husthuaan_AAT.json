{"home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloaderraw.DataLoaderRaw.__init__": [[26, 83], ["opt.get", "opt.get", "opt.get", "opt.get", "dataloaderraw.DataLoaderRaw.my_resnet.load_state_dict", "misc.resnet_utils.myResnet", "dataloaderraw.DataLoaderRaw.my_resnet.cuda", "dataloaderraw.DataLoaderRaw.my_resnet.eval", "print", "print", "len", "print", "getattr", "torch.load", "len", "len", "print", "json.load", "enumerate", "print", "os.walk", "open", "os.path.join", "dataloaderraw.DataLoaderRaw.files.append", "dataloaderraw.DataLoaderRaw.ids.append", "f.rfind", "os.path.join", "dataloaderraw.DataLoaderRaw.__init__.isImage"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.load_state_dict"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "coco_json", "=", "opt", ".", "get", "(", "'coco_json'", ",", "''", ")", "\n", "self", ".", "folder_path", "=", "opt", ".", "get", "(", "'folder_path'", ",", "''", ")", "\n", "\n", "self", ".", "batch_size", "=", "opt", ".", "get", "(", "'batch_size'", ",", "1", ")", "\n", "self", ".", "seq_per_img", "=", "1", "\n", "\n", "# Load resnet", "\n", "self", ".", "cnn_model", "=", "opt", ".", "get", "(", "'cnn_model'", ",", "'resnet101'", ")", "\n", "self", ".", "my_resnet", "=", "getattr", "(", "misc", ".", "resnet", ",", "self", ".", "cnn_model", ")", "(", ")", "\n", "self", ".", "my_resnet", ".", "load_state_dict", "(", "torch", ".", "load", "(", "'./data/imagenet_weights/'", "+", "self", ".", "cnn_model", "+", "'.pth'", ")", ")", "\n", "self", ".", "my_resnet", "=", "myResnet", "(", "self", ".", "my_resnet", ")", "\n", "self", ".", "my_resnet", ".", "cuda", "(", ")", "\n", "self", ".", "my_resnet", ".", "eval", "(", ")", "\n", "\n", "\n", "\n", "# load the json file which contains additional information about the dataset", "\n", "print", "(", "'DataLoaderRaw loading images from folder: '", ",", "self", ".", "folder_path", ")", "\n", "\n", "self", ".", "files", "=", "[", "]", "\n", "self", ".", "ids", "=", "[", "]", "\n", "\n", "print", "(", "len", "(", "self", ".", "coco_json", ")", ")", "\n", "if", "len", "(", "self", ".", "coco_json", ")", ">", "0", ":", "\n", "            ", "print", "(", "'reading from '", "+", "opt", ".", "coco_json", ")", "\n", "# read in filenames from the coco-style json file", "\n", "self", ".", "coco_annotation", "=", "json", ".", "load", "(", "open", "(", "self", ".", "coco_json", ")", ")", "\n", "for", "k", ",", "v", "in", "enumerate", "(", "self", ".", "coco_annotation", "[", "'images'", "]", ")", ":", "\n", "                ", "fullpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "folder_path", ",", "v", "[", "'file_name'", "]", ")", "\n", "self", ".", "files", ".", "append", "(", "fullpath", ")", "\n", "self", ".", "ids", ".", "append", "(", "v", "[", "'id'", "]", ")", "\n", "", "", "else", ":", "\n", "# read in all the filenames from the folder", "\n", "            ", "print", "(", "'listing all images in directory '", "+", "self", ".", "folder_path", ")", "\n", "def", "isImage", "(", "f", ")", ":", "\n", "                ", "supportedExt", "=", "[", "'.jpg'", ",", "'.JPG'", ",", "'.jpeg'", ",", "'.JPEG'", ",", "'.png'", ",", "'.PNG'", ",", "'.ppm'", ",", "'.PPM'", "]", "\n", "for", "ext", "in", "supportedExt", ":", "\n", "                    ", "start_idx", "=", "f", ".", "rfind", "(", "ext", ")", "\n", "if", "start_idx", ">=", "0", "and", "start_idx", "+", "len", "(", "ext", ")", "==", "len", "(", "f", ")", ":", "\n", "                        ", "return", "True", "\n", "", "", "return", "False", "\n", "\n", "", "n", "=", "1", "\n", "for", "root", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "self", ".", "folder_path", ",", "topdown", "=", "False", ")", ":", "\n", "                ", "for", "file", "in", "files", ":", "\n", "                    ", "fullpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "folder_path", ",", "file", ")", "\n", "if", "isImage", "(", "fullpath", ")", ":", "\n", "                        ", "self", ".", "files", ".", "append", "(", "fullpath", ")", "\n", "self", ".", "ids", ".", "append", "(", "str", "(", "n", ")", ")", "# just order them sequentially", "\n", "n", "=", "n", "+", "1", "\n", "\n", "", "", "", "", "self", ".", "N", "=", "len", "(", "self", ".", "files", ")", "\n", "print", "(", "'DataLoaderRaw found '", ",", "self", ".", "N", ",", "' images'", ")", "\n", "\n", "self", ".", "iterator", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloaderraw.DataLoaderRaw.get_batch": [[84, 131], ["numpy.ndarray", "numpy.ndarray", "range", "numpy.ndarray.reshape", "skimage.io.imread", "skimage.io.imread", "skimage.io.imread", "skimage.io.imread", "torch.from_numpy().cuda", "preprocess", "tmp_fc.data.cpu().float().numpy", "tmp_att.data.cpu().float().numpy", "infos.append", "len", "numpy.concatenate", "img[].astype", "torch.no_grad", "dataloaderraw.DataLoaderRaw.my_resnet", "torch.from_numpy", "tmp_fc.data.cpu().float", "tmp_att.data.cpu().float", "numpy.concatenate.transpose", "tmp_fc.data.cpu", "tmp_att.data.cpu"], "methods", ["None"], ["", "def", "get_batch", "(", "self", ",", "split", ",", "batch_size", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "batch_size", "or", "self", ".", "batch_size", "\n", "\n", "# pick an index of the datapoint to load next", "\n", "fc_batch", "=", "np", ".", "ndarray", "(", "(", "batch_size", ",", "2048", ")", ",", "dtype", "=", "'float32'", ")", "\n", "att_batch", "=", "np", ".", "ndarray", "(", "(", "batch_size", ",", "14", ",", "14", ",", "2048", ")", ",", "dtype", "=", "'float32'", ")", "\n", "max_index", "=", "self", ".", "N", "\n", "wrapped", "=", "False", "\n", "infos", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "ri", "=", "self", ".", "iterator", "\n", "ri_next", "=", "ri", "+", "1", "\n", "if", "ri_next", ">=", "max_index", ":", "\n", "                ", "ri_next", "=", "0", "\n", "wrapped", "=", "True", "\n", "# wrap back around", "\n", "", "self", ".", "iterator", "=", "ri_next", "\n", "\n", "img", "=", "skimage", ".", "io", ".", "imread", "(", "self", ".", "files", "[", "ri", "]", ")", "\n", "\n", "if", "len", "(", "img", ".", "shape", ")", "==", "2", ":", "\n", "                ", "img", "=", "img", "[", ":", ",", ":", ",", "np", ".", "newaxis", "]", "\n", "img", "=", "np", ".", "concatenate", "(", "(", "img", ",", "img", ",", "img", ")", ",", "axis", "=", "2", ")", "\n", "\n", "", "img", "=", "img", "[", ":", ",", ":", ",", ":", "3", "]", ".", "astype", "(", "'float32'", ")", "/", "255.0", "\n", "img", "=", "torch", ".", "from_numpy", "(", "img", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ")", ".", "cuda", "(", ")", "\n", "img", "=", "preprocess", "(", "img", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "tmp_fc", ",", "tmp_att", "=", "self", ".", "my_resnet", "(", "img", ")", "\n", "\n", "", "fc_batch", "[", "i", "]", "=", "tmp_fc", ".", "data", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "\n", "att_batch", "[", "i", "]", "=", "tmp_att", ".", "data", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "info_struct", "=", "{", "}", "\n", "info_struct", "[", "'id'", "]", "=", "self", ".", "ids", "[", "ri", "]", "\n", "info_struct", "[", "'file_path'", "]", "=", "self", ".", "files", "[", "ri", "]", "\n", "infos", ".", "append", "(", "info_struct", ")", "\n", "\n", "", "data", "=", "{", "}", "\n", "data", "[", "'fc_feats'", "]", "=", "fc_batch", "\n", "data", "[", "'att_feats'", "]", "=", "att_batch", ".", "reshape", "(", "batch_size", ",", "-", "1", ",", "2048", ")", "\n", "data", "[", "'att_masks'", "]", "=", "None", "\n", "data", "[", "'bounds'", "]", "=", "{", "'it_pos_now'", ":", "self", ".", "iterator", ",", "'it_max'", ":", "self", ".", "N", ",", "'wrapped'", ":", "wrapped", "}", "\n", "data", "[", "'infos'", "]", "=", "infos", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloaderraw.DataLoaderRaw.reset_iterator": [[132, 134], ["None"], "methods", ["None"], ["", "def", "reset_iterator", "(", "self", ",", "split", ")", ":", "\n", "        ", "self", ".", "iterator", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloaderraw.DataLoaderRaw.get_vocab_size": [[135, 137], ["len"], "methods", ["None"], ["", "def", "get_vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ix_to_word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloaderraw.DataLoaderRaw.get_vocab": [[138, 140], ["None"], "methods", ["None"], ["", "def", "get_vocab", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "ix_to_word", "\n", "", "", ""]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.opts.parse_opt": [[3, 209], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "parse_opt", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# Data input settings", "\n", "parser", ".", "add_argument", "(", "'--input_json'", ",", "type", "=", "str", ",", "default", "=", "'data/coco.json'", ",", "\n", "help", "=", "'path to the json file containing additional info and vocab'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_fc_dir'", ",", "type", "=", "str", ",", "default", "=", "'data/cocotalk_fc'", ",", "\n", "help", "=", "'path to the directory containing the preprocessed fc feats'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_att_dir'", ",", "type", "=", "str", ",", "default", "=", "'data/cocotalk_att'", ",", "\n", "help", "=", "'path to the directory containing the preprocessed att feats'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_box_dir'", ",", "type", "=", "str", ",", "default", "=", "'data/cocotalk_box'", ",", "\n", "help", "=", "'path to the directory containing the boxes of att feats'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_label_h5'", ",", "type", "=", "str", ",", "default", "=", "'data/coco_label.h5'", ",", "\n", "help", "=", "'path to the h5file containing the preprocessed dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--start_from'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"\"\"continue training from saved model at this path. Path must contain files saved by previous training process: \n                        'infos.pkl'         : configuration;\n                        'checkpoint'        : paths to model file(s) (created by tf).\n                                              Note: this file contains absolute paths, be careful when moving files around;\n                        'model.ckpt-*'      : file(s) with model definition (created by tf)\n                    \"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'--cached_tokens'", ",", "type", "=", "str", ",", "default", "=", "'coco-train-idxs'", ",", "\n", "help", "=", "'Cached token file for calculating cider score during self critical training.'", ")", "\n", "\n", "# Model settings", "\n", "parser", ".", "add_argument", "(", "'--caption_model'", ",", "type", "=", "str", ",", "default", "=", "\"show_tell\"", ",", "\n", "help", "=", "'show_tell, show_attend_tell, all_img, fc, att2in, att2in2, att2all2, adaatt, adaattmo, topdown, stackatt, denseatt, transformer, aoa, aat'", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_size'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "\n", "help", "=", "'size of the rnn in number of hidden nodes in each layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'number of layers in the RNN'", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_type'", ",", "type", "=", "str", ",", "default", "=", "'lstm'", ",", "\n", "help", "=", "'rnn, gru, or lstm'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_encoding_size'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "\n", "help", "=", "'the encoding size of each token in the vocabulary, and the image.'", ")", "\n", "parser", ".", "add_argument", "(", "'--att_hid_size'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "\n", "help", "=", "'the hidden size of the attention MLP; only useful in show_attend_tell; 0 if not using hidden layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--fc_feat_size'", ",", "type", "=", "int", ",", "default", "=", "2048", ",", "\n", "help", "=", "'2048 for resnet, 4096 for vgg'", ")", "\n", "parser", ".", "add_argument", "(", "'--att_feat_size'", ",", "type", "=", "int", ",", "default", "=", "2048", ",", "\n", "help", "=", "'2048 for resnet, 512 for vgg'", ")", "\n", "parser", ".", "add_argument", "(", "'--logit_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'number of layers in the RNN'", ")", "\n", "\n", "\n", "parser", ".", "add_argument", "(", "'--use_bn'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'If 1, then do batch_normalization first in att_embed, if 2 then do bn both in the beginning and the end of att_embed'", ")", "\n", "\n", "\n", "# AAT settings", "\n", "parser", ".", "add_argument", "(", "'--max_att_steps'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "\n", "help", "=", "'maximun attention steps at each decoding step'", ")", "\n", "parser", ".", "add_argument", "(", "'--epsilon'", ",", "type", "=", "float", ",", "default", "=", "1e-4", ",", "\n", "help", "=", "'threshold'", ")", "\n", "parser", ".", "add_argument", "(", "'--aat_lambda'", ",", "type", "=", "float", ",", "default", "=", "1e-4", ",", "\n", "help", "=", "'penalty factor on attention steps'", ")", "\n", "\n", "# AoA settings", "\n", "parser", ".", "add_argument", "(", "'--mean_feats'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'use mean pooling of feats?'", ")", "\n", "parser", ".", "add_argument", "(", "'--refine'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'refining feature vectors?'", ")", "\n", "parser", ".", "add_argument", "(", "'--refine_aoa'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'use aoa in the refining module?'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_ff'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'keep feed-forward layer in the refining module?'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout_aoa'", ",", "type", "=", "float", ",", "default", "=", "0.3", ",", "\n", "help", "=", "'dropout_aoa in the refining module?'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--ctx_drop'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'apply dropout to the context vector before fed into LSTM?'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoder_type'", ",", "type", "=", "str", ",", "default", "=", "'AoA'", ",", "\n", "help", "=", "'AoA, LSTM, base'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_multi_head'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'use multi head attention? 0 for addictive single head; 1 for addictive multi head; 2 for productive multi head.'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_heads'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'number of attention heads?'", ")", "\n", "parser", ".", "add_argument", "(", "'--multi_head_scale'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'scale q,k,v?'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--use_warmup'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'warm up the learing rate?'", ")", "\n", "parser", ".", "add_argument", "(", "'--acc_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'accumulation steps'", ")", "\n", "\n", "\n", "# feature manipulation", "\n", "parser", ".", "add_argument", "(", "'--norm_att_feat'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'If normalize attention features'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_box'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'If use box features'", ")", "\n", "parser", ".", "add_argument", "(", "'--norm_box_feat'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'If use box, do we normalize box feature'", ")", "\n", "\n", "# Optimization: General", "\n", "parser", ".", "add_argument", "(", "'--max_epochs'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'number of epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "\n", "help", "=", "'minibatch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--grad_clip'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "#5.,", "\n", "help", "=", "'clip gradients at this value'", ")", "\n", "parser", ".", "add_argument", "(", "'--drop_prob_lm'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "'strength of dropout in the Language Model RNN'", ")", "\n", "parser", ".", "add_argument", "(", "'--self_critical_after'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'After what epoch do we start finetuning the CNN? (-1 = disable; never finetune, 0 = finetune from start)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seq_per_img'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'number of captions to sample for each image during training. Done for efficiency since CNN forward pass is expensive. E.g. coco has 5 sents/image'", ")", "\n", "\n", "# Sample related", "\n", "parser", ".", "add_argument", "(", "'--beam_size'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'used when sample_method = greedy, indicates number of beams in beam search. Usually 2 or 3 works well. More is not better. Set this to 1 for faster runtime but a bit worse performance.'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_length'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "\n", "help", "=", "'Maximum length during sampling'", ")", "\n", "parser", ".", "add_argument", "(", "'--length_penalty'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'wu_X or avg_X, X is the alpha'", ")", "\n", "parser", ".", "add_argument", "(", "'--block_trigrams'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'block repeated trigram.'", ")", "\n", "parser", ".", "add_argument", "(", "'--remove_bad_endings'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Remove bad endings'", ")", "\n", "\n", "#Optimization: for the Language Model", "\n", "parser", ".", "add_argument", "(", "'--optim'", ",", "type", "=", "str", ",", "default", "=", "'adam'", ",", "\n", "help", "=", "'what update to use? rmsprop|sgd|sgdmom|adagrad|adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "type", "=", "float", ",", "default", "=", "4e-4", ",", "\n", "help", "=", "'learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_decay_start'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'at what iteration to start decaying learning rate? (-1 = dont) (in epoch)'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_decay_every'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "'every how many iterations thereafter to drop LR?(in epoch)'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_decay_rate'", ",", "type", "=", "float", ",", "default", "=", "0.8", ",", "\n", "help", "=", "'every how many iterations thereafter to drop LR?(in epoch)'", ")", "\n", "parser", ".", "add_argument", "(", "'--optim_alpha'", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "\n", "help", "=", "'alpha for adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--optim_beta'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "'beta used for adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--optim_epsilon'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ",", "\n", "help", "=", "'epsilon that goes into denominator for smoothing'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "'weight_decay'", ")", "\n", "# Transformer", "\n", "parser", ".", "add_argument", "(", "'--label_smoothing'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--noamopt'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--noamopt_warmup'", ",", "type", "=", "int", ",", "default", "=", "2000", ",", "\n", "help", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--noamopt_factor'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--reduce_on_plateau'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "''", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--scheduled_sampling_start'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'at what iteration to start decay gt probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--scheduled_sampling_increase_every'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'every how many iterations thereafter to gt probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--scheduled_sampling_increase_prob'", ",", "type", "=", "float", ",", "default", "=", "0.05", ",", "\n", "help", "=", "'How much to update the prob'", ")", "\n", "parser", ".", "add_argument", "(", "'--scheduled_sampling_max_prob'", ",", "type", "=", "float", ",", "default", "=", "0.25", ",", "\n", "help", "=", "'Maximum scheduled sampling prob.'", ")", "\n", "\n", "\n", "# Evaluation/Checkpointing", "\n", "parser", ".", "add_argument", "(", "'--val_images_use'", ",", "type", "=", "int", ",", "default", "=", "3200", ",", "\n", "help", "=", "'how many images to use when periodically evaluating the validation loss? (-1 = all)'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_checkpoint_every'", ",", "type", "=", "int", ",", "default", "=", "2500", ",", "\n", "help", "=", "'how often to save a model checkpoint (in iterations)?'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_history_ckpt'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'If save checkpoints at every save point'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint_path'", ",", "type", "=", "str", ",", "default", "=", "'save'", ",", "\n", "help", "=", "'directory to store checkpointed models'", ")", "\n", "parser", ".", "add_argument", "(", "'--language_eval'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Evaluate language as well (1 = yes, 0 = no)? BLEU/CIDEr/METEOR/ROUGE_L? requires coco-caption code from Github.'", ")", "\n", "parser", ".", "add_argument", "(", "'--losses_log_every'", ",", "type", "=", "int", ",", "default", "=", "25", ",", "\n", "help", "=", "'How often do we snapshot losses, for inclusion in the progress dump? (0 = disable)'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_best_score'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Do we load previous best score when resuming training.'", ")", "\n", "\n", "# misc", "\n", "parser", ".", "add_argument", "(", "'--id'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'an id identifying this run/job. used in cross-val and appended when writing progress files'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_only'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'if true then use 80k, else use 110k'", ")", "\n", "\n", "\n", "# Reward", "\n", "parser", ".", "add_argument", "(", "'--cider_reward_weight'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "'The reward weight from cider'", ")", "\n", "parser", ".", "add_argument", "(", "'--bleu_reward_weight'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "'The reward weight from bleu4'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Check if args are valid", "\n", "assert", "args", ".", "rnn_size", ">", "0", ",", "\"rnn_size should be greater than 0\"", "\n", "assert", "args", ".", "num_layers", ">", "0", ",", "\"num_layers should be greater than 0\"", "\n", "assert", "args", ".", "input_encoding_size", ">", "0", ",", "\"input_encoding_size should be greater than 0\"", "\n", "assert", "args", ".", "batch_size", ">", "0", ",", "\"batch_size should be greater than 0\"", "\n", "assert", "args", ".", "drop_prob_lm", ">=", "0", "and", "args", ".", "drop_prob_lm", "<", "1", ",", "\"drop_prob_lm should be between 0 and 1\"", "\n", "assert", "args", ".", "seq_per_img", ">", "0", ",", "\"seq_per_img should be greater than 0\"", "\n", "assert", "args", ".", "beam_size", ">", "0", ",", "\"beam_size should be greater than 0\"", "\n", "assert", "args", ".", "save_checkpoint_every", ">", "0", ",", "\"save_checkpoint_every should be greater than 0\"", "\n", "assert", "args", ".", "losses_log_every", ">", "0", ",", "\"losses_log_every should be greater than 0\"", "\n", "assert", "args", ".", "language_eval", "==", "0", "or", "args", ".", "language_eval", "==", "1", ",", "\"language_eval should be 0 or 1\"", "\n", "assert", "args", ".", "load_best_score", "==", "0", "or", "args", ".", "load_best_score", "==", "1", ",", "\"language_eval should be 0 or 1\"", "\n", "assert", "args", ".", "train_only", "==", "0", "or", "args", ".", "train_only", "==", "1", ",", "\"language_eval should be 0 or 1\"", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.opts.add_eval_options": [[210, 273], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "add_eval_options", "(", "parser", ")", ":", "\n", "# Basic options", "\n", "    ", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'if > 0 then overrule, otherwise load from checkpoint.'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_images'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'how many images to use when periodically evaluating the loss? (-1 = all)'", ")", "\n", "parser", ".", "add_argument", "(", "'--language_eval'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Evaluate language as well (1 = yes, 0 = no)? BLEU/CIDEr/METEOR/ROUGE_L? requires coco-caption code from Github.'", ")", "\n", "parser", ".", "add_argument", "(", "'--dump_images'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Dump images into vis/imgs folder for vis? (1=yes,0=no)'", ")", "\n", "parser", ".", "add_argument", "(", "'--dump_json'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Dump json with predictions into vis folder? (1=yes,0=no)'", ")", "\n", "parser", ".", "add_argument", "(", "'--dump_path'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Write image paths along with predictions into vis json? (1=yes,0=no)'", ")", "\n", "\n", "# Sampling options", "\n", "parser", ".", "add_argument", "(", "'--sample_method'", ",", "type", "=", "str", ",", "default", "=", "'greedy'", ",", "\n", "help", "=", "'greedy; sample; gumbel; top<int>, top<0-1>'", ")", "\n", "parser", ".", "add_argument", "(", "'--beam_size'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'indicates number of beams in beam search. Usually 2 or 3 works well. More is not better. Set this to 1 for faster runtime but a bit worse performance.'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_length'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "\n", "help", "=", "'Maximum length during sampling'", ")", "\n", "parser", ".", "add_argument", "(", "'--length_penalty'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'wu_X or avg_X, X is the alpha'", ")", "\n", "parser", ".", "add_argument", "(", "'--group_size'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'used for diverse beam search. if group_size is 1, then it\\'s normal beam search'", ")", "\n", "parser", ".", "add_argument", "(", "'--diversity_lambda'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "'used for diverse beam search. Usually from 0.2 to 0.8. Higher value of lambda produces a more diverse list'", ")", "\n", "parser", ".", "add_argument", "(", "'--temperature'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'temperature when sampling from distributions (i.e. when sample_method = sample). Lower = \"safer\" predictions.'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoding_constraint'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'If 1, not allowing same word in a row'", ")", "\n", "parser", ".", "add_argument", "(", "'--block_trigrams'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'block repeated trigram.'", ")", "\n", "parser", ".", "add_argument", "(", "'--remove_bad_endings'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Remove bad endings'", ")", "\n", "# For evaluation on a folder of images:", "\n", "parser", ".", "add_argument", "(", "'--image_folder'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'If this is nonempty then will predict on the images in this folder path'", ")", "\n", "parser", ".", "add_argument", "(", "'--image_root'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'In case the image paths have to be preprended with a root path to an image folder'", ")", "\n", "# For evaluation on MSCOCO images from some split:", "\n", "parser", ".", "add_argument", "(", "'--input_fc_dir'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'path to the h5file containing the preprocessed dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_att_dir'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'path to the h5file containing the preprocessed dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_box_dir'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'path to the h5file containing the preprocessed dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_label_h5'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'path to the h5file containing the preprocessed dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_json'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'path to the json file containing additional info and vocab. empty = fetch from model checkpoint.'", ")", "\n", "parser", ".", "add_argument", "(", "'--split'", ",", "type", "=", "str", ",", "default", "=", "'test'", ",", "\n", "help", "=", "'if running on MSCOCO images, which split to use: val|test|train'", ")", "\n", "parser", ".", "add_argument", "(", "'--coco_json'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'if nonempty then use this file in DataLoaderRaw (see docs there). Used only in MSCOCO test evaluation, where we have a specific json file of only test set images.'", ")", "\n", "# misc", "\n", "parser", ".", "add_argument", "(", "'--id'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'an id identifying this run/job. used only if language_eval = 1 for appending to intermediate files'", ")", "\n", "parser", ".", "add_argument", "(", "'--verbose_beam'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'if we need to print out all beam search beams.'", ")", "\n", "parser", ".", "add_argument", "(", "'--verbose_loss'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'If calculate loss using ground truth during evaluation'", ")", "", "", ""]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.train.add_summary_value": [[31, 34], ["writer.add_scalar"], "function", ["None"], ["", "def", "add_summary_value", "(", "writer", ",", "key", ",", "value", ",", "iteration", ")", ":", "\n", "    ", "if", "writer", ":", "\n", "        ", "writer", ".", "add_scalar", "(", "key", ",", "value", ",", "iteration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.train.train": [[35, 286], ["misc.if_use_feat", "getattr", "dataloader.DataLoader", "utils.pickle_load.get", "utils.pickle_load.get", "utils.pickle_load.get", "utils.pickle_load.get", "utils.pickle_load.get", "utils.pickle_load.get", "utils.pickle_load.get", "utils.pickle_load.get", "dataloader.DataLoader.get_vocab", "models.setup().cuda", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "misc.loss_wrapper.LossWrapper", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel.train", "tb.SummaryWriter", "os.path.isfile", "dataloader.DataLoader.get_vocab", "utils.pickle_load.get", "misc.get_std_opt", "os.path.isfile", "utils.build_optimizer.load_state_dict", "os.path.join", "torch.save", "torch.save", "torch.save", "print", "os.path.join", "torch.save", "torch.save", "torch.save", "open", "misc.pickle_load", "os.path.join", "models.setup", "misc.build_optimizer", "misc.ReduceLROnPlateau", "misc.build_optimizer", "vars().get", "os.path.join", "torch.load", "torch.load", "torch.load", "len", "os.path.isdir", "os.makedirs", "models.setup().cuda.state_dict", "utils.build_optimizer.state_dict", "open", "misc.pickle_dump", "time.time", "dataloader.DataLoader.get_batch", "print", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "time.time", "torch.nn.DataParallel.", "model_out[].mean", "loss_sp.backward", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "model_out[].mean.item", "time.time", "print", "train.train.save_checkpoint"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.if_use_feat", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.get_vocab", "home.repos.pwc.inspect_result.husthuaan_AAT.None.train.train", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.get_vocab", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.get_std_opt", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.load_state_dict", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.pickle_load", "home.repos.pwc.inspect_result.husthuaan_AAT.models.__init__.setup", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.build_optimizer", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.build_optimizer", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.state_dict", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.state_dict", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.pickle_dump", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.get_batch"], ["", "", "def", "train", "(", "opt", ")", ":", "\n", "# Deal with feature things before anything", "\n", "    ", "opt", ".", "use_fc", ",", "opt", ".", "use_att", "=", "utils", ".", "if_use_feat", "(", "opt", ".", "caption_model", ")", "\n", "if", "opt", ".", "use_box", ":", "opt", ".", "att_feat_size", "=", "opt", ".", "att_feat_size", "+", "5", "\n", "\n", "acc_steps", "=", "getattr", "(", "opt", ",", "'acc_steps'", ",", "1", ")", "\n", "\n", "loader", "=", "DataLoader", "(", "opt", ")", "\n", "opt", ".", "vocab_size", "=", "loader", ".", "vocab_size", "\n", "opt", ".", "seq_length", "=", "loader", ".", "seq_length", "\n", "\n", "tb_summary_writer", "=", "tb", "and", "tb", ".", "SummaryWriter", "(", "opt", ".", "checkpoint_path", ")", "\n", "\n", "infos", "=", "{", "}", "\n", "histories", "=", "{", "}", "\n", "if", "opt", ".", "start_from", "is", "not", "None", ":", "\n", "# open old infos and check if models are compatible", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "'infos_'", "+", "opt", ".", "id", "+", "'.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "infos", "=", "utils", ".", "pickle_load", "(", "f", ")", "\n", "saved_model_opt", "=", "infos", "[", "'opt'", "]", "\n", "need_be_same", "=", "[", "\"caption_model\"", ",", "\"rnn_type\"", ",", "\"rnn_size\"", ",", "\"num_layers\"", "]", "\n", "for", "checkme", "in", "need_be_same", ":", "\n", "                ", "assert", "vars", "(", "saved_model_opt", ")", "[", "checkme", "]", "==", "vars", "(", "opt", ")", "[", "checkme", "]", ",", "\"Command line argument and saved model disagree on '%s' \"", "%", "checkme", "\n", "\n", "", "", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "'histories_'", "+", "opt", ".", "id", "+", "'.pkl'", ")", ")", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "'histories_'", "+", "opt", ".", "id", "+", "'.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "histories", "=", "utils", ".", "pickle_load", "(", "f", ")", "\n", "", "", "", "else", ":", "\n", "        ", "infos", "[", "'iter'", "]", "=", "0", "\n", "infos", "[", "'epoch'", "]", "=", "0", "\n", "infos", "[", "'iterators'", "]", "=", "loader", ".", "iterators", "\n", "infos", "[", "'split_ix'", "]", "=", "loader", ".", "split_ix", "\n", "infos", "[", "'vocab'", "]", "=", "loader", ".", "get_vocab", "(", ")", "\n", "", "infos", "[", "'opt'", "]", "=", "opt", "\n", "\n", "iteration", "=", "infos", ".", "get", "(", "'iter'", ",", "0", ")", "\n", "epoch", "=", "infos", ".", "get", "(", "'epoch'", ",", "0", ")", "\n", "\n", "val_result_history", "=", "histories", ".", "get", "(", "'val_result_history'", ",", "{", "}", ")", "\n", "loss_history", "=", "histories", ".", "get", "(", "'loss_history'", ",", "{", "}", ")", "\n", "lr_history", "=", "histories", ".", "get", "(", "'lr_history'", ",", "{", "}", ")", "\n", "ss_prob_history", "=", "histories", ".", "get", "(", "'ss_prob_history'", ",", "{", "}", ")", "\n", "\n", "loader", ".", "iterators", "=", "infos", ".", "get", "(", "'iterators'", ",", "loader", ".", "iterators", ")", "\n", "loader", ".", "split_ix", "=", "infos", ".", "get", "(", "'split_ix'", ",", "loader", ".", "split_ix", ")", "\n", "if", "opt", ".", "load_best_score", "==", "1", ":", "\n", "        ", "best_val_score", "=", "infos", ".", "get", "(", "'best_val_score'", ",", "None", ")", "\n", "\n", "", "opt", ".", "vocab", "=", "loader", ".", "get_vocab", "(", ")", "\n", "model", "=", "models", ".", "setup", "(", "opt", ")", ".", "cuda", "(", ")", "\n", "del", "opt", ".", "vocab", "\n", "dp_model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "lw_model", "=", "LossWrapper", "(", "model", ",", "opt", ")", "\n", "dp_lw_model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "lw_model", ")", "\n", "\n", "epoch_done", "=", "True", "\n", "# Assure in training mode", "\n", "dp_lw_model", ".", "train", "(", ")", "\n", "\n", "if", "opt", ".", "noamopt", ":", "\n", "        ", "assert", "opt", ".", "caption_model", "in", "[", "'transformer'", ",", "'aoa'", "]", ",", "'noamopt can only work with transformer'", "\n", "optimizer", "=", "utils", ".", "get_std_opt", "(", "model", ",", "factor", "=", "opt", ".", "noamopt_factor", ",", "warmup", "=", "opt", ".", "noamopt_warmup", ")", "\n", "optimizer", ".", "_step", "=", "iteration", "\n", "", "elif", "opt", ".", "reduce_on_plateau", ":", "\n", "        ", "optimizer", "=", "utils", ".", "build_optimizer", "(", "model", ".", "parameters", "(", ")", ",", "opt", ")", "\n", "optimizer", "=", "utils", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "3", ")", "\n", "", "else", ":", "\n", "        ", "optimizer", "=", "utils", ".", "build_optimizer", "(", "model", ".", "parameters", "(", ")", ",", "opt", ")", "\n", "# Load the optimizer", "\n", "", "if", "vars", "(", "opt", ")", ".", "get", "(", "'start_from'", ",", "None", ")", "is", "not", "None", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "\"optimizer.pth\"", ")", ")", ":", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "'optimizer.pth'", ")", ")", ")", "\n", "\n", "\n", "", "def", "save_checkpoint", "(", "model", ",", "infos", ",", "optimizer", ",", "histories", "=", "None", ",", "append", "=", "''", ")", ":", "\n", "        ", "if", "len", "(", "append", ")", ">", "0", ":", "\n", "            ", "append", "=", "'-'", "+", "append", "\n", "# if checkpoint_path doesn't exist", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "opt", ".", "checkpoint_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "opt", ".", "checkpoint_path", ")", "\n", "", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", ",", "'model%s.pth'", "%", "(", "append", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "checkpoint_path", ")", "\n", "print", "(", "\"model saved to {}\"", ".", "format", "(", "checkpoint_path", ")", ")", "\n", "optimizer_path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", ",", "'optimizer%s.pth'", "%", "(", "append", ")", ")", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "optimizer_path", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", ",", "'infos_'", "+", "opt", ".", "id", "+", "'%s.pkl'", "%", "(", "append", ")", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "utils", ".", "pickle_dump", "(", "infos", ",", "f", ")", "\n", "", "if", "histories", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", ",", "'histories_'", "+", "opt", ".", "id", "+", "'%s.pkl'", "%", "(", "append", ")", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "                ", "utils", ".", "pickle_dump", "(", "histories", ",", "f", ")", "\n", "\n", "", "", "", "try", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "if", "epoch_done", ":", "\n", "                ", "if", "not", "opt", ".", "noamopt", "and", "not", "opt", ".", "reduce_on_plateau", ":", "\n", "# Assign the learning rate", "\n", "                    ", "if", "epoch", ">", "opt", ".", "learning_rate_decay_start", "and", "opt", ".", "learning_rate_decay_start", ">=", "0", ":", "\n", "                        ", "frac", "=", "(", "epoch", "-", "opt", ".", "learning_rate_decay_start", ")", "//", "opt", ".", "learning_rate_decay_every", "\n", "decay_factor", "=", "opt", ".", "learning_rate_decay_rate", "**", "frac", "\n", "opt", ".", "current_lr", "=", "opt", ".", "learning_rate", "*", "decay_factor", "\n", "", "else", ":", "\n", "                        ", "opt", ".", "current_lr", "=", "opt", ".", "learning_rate", "\n", "", "utils", ".", "set_lr", "(", "optimizer", ",", "opt", ".", "current_lr", ")", "# set the decayed rate", "\n", "# Assign the scheduled sampling prob", "\n", "", "if", "epoch", ">", "opt", ".", "scheduled_sampling_start", "and", "opt", ".", "scheduled_sampling_start", ">=", "0", ":", "\n", "                    ", "frac", "=", "(", "epoch", "-", "opt", ".", "scheduled_sampling_start", ")", "//", "opt", ".", "scheduled_sampling_increase_every", "\n", "opt", ".", "ss_prob", "=", "min", "(", "opt", ".", "scheduled_sampling_increase_prob", "*", "frac", ",", "opt", ".", "scheduled_sampling_max_prob", ")", "\n", "model", ".", "ss_prob", "=", "opt", ".", "ss_prob", "\n", "\n", "# If start self critical training", "\n", "", "if", "opt", ".", "self_critical_after", "!=", "-", "1", "and", "epoch", ">=", "opt", ".", "self_critical_after", ":", "\n", "                    ", "sc_flag", "=", "True", "\n", "init_scorer", "(", "opt", ".", "cached_tokens", ")", "\n", "", "else", ":", "\n", "                    ", "sc_flag", "=", "False", "\n", "\n", "", "epoch_done", "=", "False", "\n", "\n", "", "start", "=", "time", ".", "time", "(", ")", "\n", "if", "(", "opt", ".", "use_warmup", "==", "1", ")", "and", "(", "iteration", "<", "opt", ".", "noamopt_warmup", ")", ":", "\n", "                ", "opt", ".", "current_lr", "=", "opt", ".", "learning_rate", "*", "(", "iteration", "+", "1", ")", "/", "opt", ".", "noamopt_warmup", "\n", "utils", ".", "set_lr", "(", "optimizer", ",", "opt", ".", "current_lr", ")", "\n", "# Load data from train split (0)", "\n", "", "data", "=", "loader", ".", "get_batch", "(", "'train'", ")", "\n", "print", "(", "'Read data:'", ",", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "\n", "if", "(", "iteration", "%", "acc_steps", "==", "0", ")", ":", "\n", "                ", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "tmp", "=", "[", "data", "[", "'fc_feats'", "]", ",", "data", "[", "'att_feats'", "]", ",", "data", "[", "'labels'", "]", ",", "data", "[", "'masks'", "]", ",", "data", "[", "'att_masks'", "]", "]", "\n", "tmp", "=", "[", "_", "if", "_", "is", "None", "else", "_", ".", "cuda", "(", ")", "for", "_", "in", "tmp", "]", "\n", "fc_feats", ",", "att_feats", ",", "labels", ",", "masks", ",", "att_masks", "=", "tmp", "\n", "\n", "model_out", "=", "dp_lw_model", "(", "fc_feats", ",", "att_feats", ",", "labels", ",", "masks", ",", "att_masks", ",", "data", "[", "'gts'", "]", ",", "torch", ".", "arange", "(", "0", ",", "len", "(", "data", "[", "'gts'", "]", ")", ")", ",", "sc_flag", ")", "\n", "\n", "loss", "=", "model_out", "[", "'loss'", "]", ".", "mean", "(", ")", "\n", "loss_sp", "=", "loss", "/", "acc_steps", "\n", "\n", "loss_sp", ".", "backward", "(", ")", "\n", "if", "(", "(", "iteration", "+", "1", ")", "%", "acc_steps", "==", "0", ")", ":", "\n", "                ", "utils", ".", "clip_gradient", "(", "optimizer", ",", "opt", ".", "grad_clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "train_loss", "=", "loss", ".", "item", "(", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "if", "not", "sc_flag", ":", "\n", "                ", "print", "(", "\"iter {} (epoch {}), train_loss = {:.3f}, time/batch = {:.3f}\"", ".", "format", "(", "iteration", ",", "epoch", ",", "train_loss", ",", "end", "-", "start", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"iter {} (epoch {}), avg_reward = {:.3f}, time/batch = {:.3f}\"", ".", "format", "(", "iteration", ",", "epoch", ",", "model_out", "[", "'reward'", "]", ".", "mean", "(", ")", ",", "end", "-", "start", ")", ")", "\n", "\n", "", "if", "opt", ".", "caption_model", "==", "'aat'", ":", "\n", "                ", "attention_steps", "=", "np", ".", "array", "(", "model_out", "[", "'att_step'", "]", ")", ".", "transpose", "(", ")", "\n", "avg_att_time", "=", "model_out", "[", "'avg_att_time'", "]", "\n", "loss_", "=", "model_out", "[", "'loss_'", "]", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "aat_loss", "=", "model_out", "[", "'aat_loss'", "]", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "print", "(", "\"AAT: loss_ = {:.3f}, att_loss = {:.3f}, avg_att_time = {:.3f}\"", ".", "format", "(", "loss_", ",", "aat_loss", ",", "avg_att_time", ")", ")", "\n", "print", "(", "attention_steps", "[", "0", "]", ")", "\n", "\n", "# Update the iteration and epoch", "\n", "", "iteration", "+=", "1", "\n", "if", "data", "[", "'bounds'", "]", "[", "'wrapped'", "]", ":", "\n", "                ", "epoch", "+=", "1", "\n", "epoch_done", "=", "True", "\n", "\n", "# Write the training loss summary", "\n", "", "if", "(", "iteration", "%", "opt", ".", "losses_log_every", "==", "0", ")", ":", "\n", "                ", "add_summary_value", "(", "tb_summary_writer", ",", "'train_loss'", ",", "train_loss", ",", "iteration", ")", "\n", "if", "opt", ".", "noamopt", ":", "\n", "                    ", "opt", ".", "current_lr", "=", "optimizer", ".", "rate", "(", ")", "\n", "", "elif", "opt", ".", "reduce_on_plateau", ":", "\n", "                    ", "opt", ".", "current_lr", "=", "optimizer", ".", "current_lr", "\n", "", "add_summary_value", "(", "tb_summary_writer", ",", "'learning_rate'", ",", "opt", ".", "current_lr", ",", "iteration", ")", "\n", "add_summary_value", "(", "tb_summary_writer", ",", "'scheduled_sampling_prob'", ",", "model", ".", "ss_prob", ",", "iteration", ")", "\n", "if", "sc_flag", ":", "\n", "                    ", "add_summary_value", "(", "tb_summary_writer", ",", "'avg_reward'", ",", "model_out", "[", "'reward'", "]", ".", "mean", "(", ")", ",", "iteration", ")", "\n", "\n", "", "if", "opt", ".", "caption_model", "==", "'aat'", ":", "\n", "                    ", "add_summary_value", "(", "tb_summary_writer", ",", "'loss_'", ",", "loss_", ",", "iteration", ")", "\n", "add_summary_value", "(", "tb_summary_writer", ",", "'aat_loss'", ",", "aat_loss", ",", "iteration", ")", "\n", "add_summary_value", "(", "tb_summary_writer", ",", "'avg_att_time'", ",", "avg_att_time", ",", "iteration", ")", "\n", "\n", "", "loss_history", "[", "iteration", "]", "=", "train_loss", "if", "not", "sc_flag", "else", "model_out", "[", "'reward'", "]", ".", "mean", "(", ")", "\n", "lr_history", "[", "iteration", "]", "=", "opt", ".", "current_lr", "\n", "ss_prob_history", "[", "iteration", "]", "=", "model", ".", "ss_prob", "\n", "\n", "# update infos", "\n", "", "infos", "[", "'iter'", "]", "=", "iteration", "\n", "infos", "[", "'epoch'", "]", "=", "epoch", "\n", "infos", "[", "'iterators'", "]", "=", "loader", ".", "iterators", "\n", "infos", "[", "'split_ix'", "]", "=", "loader", ".", "split_ix", "\n", "\n", "# make evaluation on validation set, and save model", "\n", "if", "(", "iteration", "%", "opt", ".", "save_checkpoint_every", "==", "0", ")", ":", "\n", "# eval model", "\n", "                ", "eval_kwargs", "=", "{", "'split'", ":", "'val'", ",", "\n", "'dataset'", ":", "opt", ".", "input_json", "}", "\n", "eval_kwargs", ".", "update", "(", "vars", "(", "opt", ")", ")", "\n", "val_loss", ",", "predictions", ",", "lang_stats", "=", "eval_utils", ".", "eval_split", "(", "\n", "dp_model", ",", "lw_model", ".", "crit", ",", "loader", ",", "eval_kwargs", ")", "\n", "\n", "if", "opt", ".", "reduce_on_plateau", ":", "\n", "                    ", "if", "'CIDEr'", "in", "lang_stats", ":", "\n", "                        ", "optimizer", ".", "scheduler_step", "(", "-", "lang_stats", "[", "'CIDEr'", "]", ")", "\n", "", "else", ":", "\n", "                        ", "optimizer", ".", "scheduler_step", "(", "val_loss", ")", "\n", "# Write validation result into summary", "\n", "", "", "add_summary_value", "(", "tb_summary_writer", ",", "'validation loss'", ",", "val_loss", ",", "iteration", ")", "\n", "if", "lang_stats", "is", "not", "None", ":", "\n", "                    ", "for", "k", ",", "v", "in", "lang_stats", ".", "items", "(", ")", ":", "\n", "                        ", "add_summary_value", "(", "tb_summary_writer", ",", "k", ",", "v", ",", "iteration", ")", "\n", "", "", "val_result_history", "[", "iteration", "]", "=", "{", "'loss'", ":", "val_loss", ",", "'lang_stats'", ":", "lang_stats", ",", "'predictions'", ":", "predictions", "}", "\n", "\n", "# Save model if is improving on validation result", "\n", "if", "opt", ".", "language_eval", "==", "1", ":", "\n", "                    ", "current_score", "=", "lang_stats", "[", "'CIDEr'", "]", "\n", "", "else", ":", "\n", "                    ", "current_score", "=", "-", "val_loss", "\n", "\n", "", "best_flag", "=", "False", "\n", "\n", "if", "best_val_score", "is", "None", "or", "current_score", ">", "best_val_score", ":", "\n", "                    ", "best_val_score", "=", "current_score", "\n", "best_flag", "=", "True", "\n", "\n", "# Dump miscalleous informations", "\n", "", "infos", "[", "'best_val_score'", "]", "=", "best_val_score", "\n", "histories", "[", "'val_result_history'", "]", "=", "val_result_history", "\n", "histories", "[", "'loss_history'", "]", "=", "loss_history", "\n", "histories", "[", "'lr_history'", "]", "=", "lr_history", "\n", "histories", "[", "'ss_prob_history'", "]", "=", "ss_prob_history", "\n", "\n", "save_checkpoint", "(", "model", ",", "infos", ",", "optimizer", ",", "histories", ")", "\n", "if", "opt", ".", "save_history_ckpt", ":", "\n", "                    ", "save_checkpoint", "(", "model", ",", "infos", ",", "optimizer", ",", "append", "=", "str", "(", "iteration", ")", ")", "\n", "\n", "", "if", "best_flag", ":", "\n", "                    ", "save_checkpoint", "(", "model", ",", "infos", ",", "optimizer", ",", "append", "=", "'best'", ")", "\n", "\n", "# Stop if reaching max epochs", "\n", "", "", "if", "epoch", ">=", "opt", ".", "max_epochs", "and", "opt", ".", "max_epochs", "!=", "-", "1", ":", "\n", "                ", "break", "\n", "", "", "", "except", "(", "RuntimeError", ",", "KeyboardInterrupt", ")", ":", "\n", "        ", "print", "(", "'Save ckpt on exception ...'", ")", "\n", "save_checkpoint", "(", "model", ",", "infos", ",", "optimizer", ")", "\n", "print", "(", "'Save ckpt done.'", ")", "\n", "stack_trace", "=", "traceback", ".", "format_exc", "(", ")", "\n", "print", "(", "stack_trace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.eval_utils.count_bad": [[21, 27], ["sen.split.split"], "function", ["None"], ["def", "count_bad", "(", "sen", ")", ":", "\n", "    ", "sen", "=", "sen", ".", "split", "(", "' '", ")", "\n", "if", "sen", "[", "-", "1", "]", "in", "bad_endings", ":", "\n", "        ", "return", "1", "\n", "", "else", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.eval_utils.language_eval": [[28, 73], ["sys.path.append", "os.path.join", "COCO", "COCO.getImgIds", "print", "json.dump", "COCO.loadRes", "COCOEvalCap", "coco.loadRes.getImgIds", "COCOEvalCap.evaluate", "COCOEvalCap.eval.items", "os.path.join", "os.path.isdir", "os.mkdir", "open", "sum", "float", "open", "json.dump", "len", "len", "len", "eval_utils.count_bad"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.eval_utils.count_bad"], ["", "", "def", "language_eval", "(", "dataset", ",", "preds", ",", "model_id", ",", "split", ")", ":", "\n", "    ", "import", "sys", "\n", "sys", ".", "path", ".", "append", "(", "\"coco-caption\"", ")", "\n", "if", "'coco'", "in", "dataset", ":", "\n", "        ", "annFile", "=", "'coco-caption/annotations/captions_val2014.json'", "\n", "", "elif", "'flickr30k'", "in", "dataset", "or", "'f30k'", "in", "dataset", ":", "\n", "        ", "annFile", "=", "'coco-caption/f30k_captions4eval.json'", "\n", "", "from", "pycocotools", ".", "coco", "import", "COCO", "\n", "from", "pycocoevalcap", ".", "eval", "import", "COCOEvalCap", "\n", "\n", "# encoder.FLOAT_REPR = lambda o: format(o, '.3f')", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "'eval_results'", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "'eval_results'", ")", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "'eval_results/'", ",", "'.cache_'", "+", "model_id", "+", "'_'", "+", "split", "+", "'.json'", ")", "\n", "\n", "coco", "=", "COCO", "(", "annFile", ")", "\n", "valids", "=", "coco", ".", "getImgIds", "(", ")", "\n", "\n", "# filter results to only those in MSCOCO validation set (will be about a third)", "\n", "preds_filt", "=", "[", "p", "for", "p", "in", "preds", "if", "p", "[", "'image_id'", "]", "in", "valids", "]", "\n", "print", "(", "'using %d/%d predictions'", "%", "(", "len", "(", "preds_filt", ")", ",", "len", "(", "preds", ")", ")", ")", "\n", "json", ".", "dump", "(", "preds_filt", ",", "open", "(", "cache_path", ",", "'w'", ")", ")", "# serialize to temporary json file. Sigh, COCO API...", "\n", "\n", "cocoRes", "=", "coco", ".", "loadRes", "(", "cache_path", ")", "\n", "cocoEval", "=", "COCOEvalCap", "(", "coco", ",", "cocoRes", ")", "\n", "cocoEval", ".", "params", "[", "'image_id'", "]", "=", "cocoRes", ".", "getImgIds", "(", ")", "\n", "cocoEval", ".", "evaluate", "(", ")", "\n", "\n", "# create output dictionary", "\n", "out", "=", "{", "}", "\n", "for", "metric", ",", "score", "in", "cocoEval", ".", "eval", ".", "items", "(", ")", ":", "\n", "        ", "out", "[", "metric", "]", "=", "score", "\n", "\n", "", "imgToEval", "=", "cocoEval", ".", "imgToEval", "\n", "for", "p", "in", "preds_filt", ":", "\n", "        ", "image_id", ",", "caption", "=", "p", "[", "'image_id'", "]", ",", "p", "[", "'caption'", "]", "\n", "imgToEval", "[", "image_id", "]", "[", "'caption'", "]", "=", "caption", "\n", "\n", "", "out", "[", "'bad_count_rate'", "]", "=", "sum", "(", "[", "count_bad", "(", "_", "[", "'caption'", "]", ")", "for", "_", "in", "preds_filt", "]", ")", "/", "float", "(", "len", "(", "preds_filt", ")", ")", "\n", "outfile_path", "=", "os", ".", "path", ".", "join", "(", "'eval_results/'", ",", "model_id", "+", "'_'", "+", "split", "+", "'.json'", ")", "\n", "with", "open", "(", "outfile_path", ",", "'w'", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "'overall'", ":", "out", ",", "'imgToEval'", ":", "imgToEval", "}", ",", "outfile", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.eval_utils.eval_split": [[74, 166], ["eval_kwargs.get", "eval_kwargs.get", "eval_kwargs.get", "eval_kwargs.get", "eval_kwargs.get", "eval_kwargs.get", "eval_kwargs.get", "eval_kwargs.get", "eval_kwargs.get", "str", "model.eval", "loader.reset_iterator", "model.train", "eval_kwargs.get", "loader.get_batch", "misc.decode_sequence", "enumerate", "range", "eval_utils.language_eval", "torch.no_grad", "torch.no_grad", "range", "loader.get_vocab", "predictions.append", "min", "predictions.pop", "print", "loader.get_batch.get", "torch.no_grad", "torch.no_grad", "crit().item", "_.cuda", "print", "print", "eval_kwargs.get", "eval_kwargs.get", "print", "os.system", "print", "_.cuda", "model", "crit", "numpy.arange", "numpy.arange", "str", "model", "numpy.arange", "len", "misc.decode_sequence", "os.path.join", "loader.get_vocab", "_[].unsqueeze"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.reset_iterator", "home.repos.pwc.inspect_result.husthuaan_AAT.None.train.train", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.get_batch", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.decode_sequence", "home.repos.pwc.inspect_result.husthuaan_AAT.None.eval_utils.language_eval", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.get_vocab", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.decode_sequence", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.get_vocab"], ["", "def", "eval_split", "(", "model", ",", "crit", ",", "loader", ",", "eval_kwargs", "=", "{", "}", ")", ":", "\n", "    ", "verbose", "=", "eval_kwargs", ".", "get", "(", "'verbose'", ",", "True", ")", "\n", "verbose_beam", "=", "eval_kwargs", ".", "get", "(", "'verbose_beam'", ",", "1", ")", "\n", "verbose_loss", "=", "eval_kwargs", ".", "get", "(", "'verbose_loss'", ",", "1", ")", "\n", "num_images", "=", "eval_kwargs", ".", "get", "(", "'num_images'", ",", "eval_kwargs", ".", "get", "(", "'val_images_use'", ",", "-", "1", ")", ")", "\n", "split", "=", "eval_kwargs", ".", "get", "(", "'split'", ",", "'val'", ")", "\n", "lang_eval", "=", "eval_kwargs", ".", "get", "(", "'language_eval'", ",", "0", ")", "\n", "dataset", "=", "eval_kwargs", ".", "get", "(", "'dataset'", ",", "'coco'", ")", "\n", "beam_size", "=", "eval_kwargs", ".", "get", "(", "'beam_size'", ",", "1", ")", "\n", "remove_bad_endings", "=", "eval_kwargs", ".", "get", "(", "'remove_bad_endings'", ",", "0", ")", "\n", "os", ".", "environ", "[", "\"REMOVE_BAD_ENDINGS\"", "]", "=", "str", "(", "remove_bad_endings", ")", "# Use this nasty way to make other code clean since it's a global configuration", "\n", "\n", "# Make sure in the evaluation mode", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "loader", ".", "reset_iterator", "(", "split", ")", "\n", "\n", "n", "=", "0", "\n", "loss", "=", "0", "\n", "loss_sum", "=", "0", "\n", "loss_evals", "=", "1e-8", "\n", "predictions", "=", "[", "]", "\n", "while", "True", ":", "\n", "        ", "data", "=", "loader", ".", "get_batch", "(", "split", ")", "\n", "n", "=", "n", "+", "loader", ".", "batch_size", "\n", "\n", "if", "data", ".", "get", "(", "'labels'", ",", "None", ")", "is", "not", "None", "and", "verbose_loss", ":", "\n", "# forward the model to get loss", "\n", "            ", "tmp", "=", "[", "data", "[", "'fc_feats'", "]", ",", "data", "[", "'att_feats'", "]", ",", "data", "[", "'labels'", "]", ",", "data", "[", "'masks'", "]", ",", "data", "[", "'att_masks'", "]", "]", "\n", "tmp", "=", "[", "_", ".", "cuda", "(", ")", "if", "_", "is", "not", "None", "else", "_", "for", "_", "in", "tmp", "]", "\n", "fc_feats", ",", "att_feats", ",", "labels", ",", "masks", ",", "att_masks", "=", "tmp", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "loss", "=", "crit", "(", "model", "(", "fc_feats", ",", "att_feats", ",", "labels", ",", "att_masks", ")", ",", "labels", "[", ":", ",", "1", ":", "]", ",", "masks", "[", ":", ",", "1", ":", "]", ")", ".", "item", "(", ")", "\n", "", "loss_sum", "=", "loss_sum", "+", "loss", "\n", "loss_evals", "=", "loss_evals", "+", "1", "\n", "\n", "# forward the model to also get generated samples for each image", "\n", "# Only leave one feature for each image, in case duplicate sample", "\n", "", "tmp", "=", "[", "data", "[", "'fc_feats'", "]", "[", "np", ".", "arange", "(", "loader", ".", "batch_size", ")", "*", "loader", ".", "seq_per_img", "]", ",", "\n", "data", "[", "'att_feats'", "]", "[", "np", ".", "arange", "(", "loader", ".", "batch_size", ")", "*", "loader", ".", "seq_per_img", "]", ",", "\n", "data", "[", "'att_masks'", "]", "[", "np", ".", "arange", "(", "loader", ".", "batch_size", ")", "*", "loader", ".", "seq_per_img", "]", "if", "data", "[", "'att_masks'", "]", "is", "not", "None", "else", "None", "]", "\n", "tmp", "=", "[", "_", ".", "cuda", "(", ")", "if", "_", "is", "not", "None", "else", "_", "for", "_", "in", "tmp", "]", "\n", "fc_feats", ",", "att_feats", ",", "att_masks", "=", "tmp", "\n", "# forward the model to also get generated samples for each image", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "seq", "=", "model", "(", "fc_feats", ",", "att_feats", ",", "att_masks", ",", "opt", "=", "eval_kwargs", ",", "mode", "=", "'sample'", ")", "[", "0", "]", ".", "data", "\n", "\n", "# Print beam search", "\n", "", "if", "beam_size", ">", "1", "and", "verbose_beam", ":", "\n", "            ", "for", "i", "in", "range", "(", "loader", ".", "batch_size", ")", ":", "\n", "                ", "print", "(", "'\\n'", ".", "join", "(", "[", "utils", ".", "decode_sequence", "(", "loader", ".", "get_vocab", "(", ")", ",", "_", "[", "'seq'", "]", ".", "unsqueeze", "(", "0", ")", ")", "[", "0", "]", "for", "_", "in", "model", ".", "done_beams", "[", "i", "]", "]", ")", ")", "\n", "print", "(", "'--'", "*", "10", ")", "\n", "", "", "sents", "=", "utils", ".", "decode_sequence", "(", "loader", ".", "get_vocab", "(", ")", ",", "seq", ")", "\n", "\n", "for", "k", ",", "sent", "in", "enumerate", "(", "sents", ")", ":", "\n", "            ", "entry", "=", "{", "'image_id'", ":", "data", "[", "'infos'", "]", "[", "k", "]", "[", "'id'", "]", ",", "'caption'", ":", "sent", "}", "\n", "if", "eval_kwargs", ".", "get", "(", "'dump_path'", ",", "0", ")", "==", "1", ":", "\n", "                ", "entry", "[", "'file_name'", "]", "=", "data", "[", "'infos'", "]", "[", "k", "]", "[", "'file_path'", "]", "\n", "", "predictions", ".", "append", "(", "entry", ")", "\n", "if", "eval_kwargs", ".", "get", "(", "'dump_images'", ",", "0", ")", "==", "1", ":", "\n", "# dump the raw image to vis/ folder", "\n", "                ", "cmd", "=", "'cp \"'", "+", "os", ".", "path", ".", "join", "(", "eval_kwargs", "[", "'image_root'", "]", ",", "data", "[", "'infos'", "]", "[", "k", "]", "[", "'file_path'", "]", ")", "+", "'\" vis/imgs/img'", "+", "str", "(", "len", "(", "predictions", ")", ")", "+", "'.jpg'", "# bit gross", "\n", "print", "(", "cmd", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "                ", "print", "(", "'image %s: %s'", "%", "(", "entry", "[", "'image_id'", "]", ",", "entry", "[", "'caption'", "]", ")", ")", "\n", "\n", "# if we wrapped around the split or used up val imgs budget then bail", "\n", "", "", "ix0", "=", "data", "[", "'bounds'", "]", "[", "'it_pos_now'", "]", "\n", "ix1", "=", "data", "[", "'bounds'", "]", "[", "'it_max'", "]", "\n", "if", "num_images", "!=", "-", "1", ":", "\n", "            ", "ix1", "=", "min", "(", "ix1", ",", "num_images", ")", "\n", "", "for", "i", "in", "range", "(", "n", "-", "ix1", ")", ":", "\n", "            ", "predictions", ".", "pop", "(", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "'evaluating validation preformance... %d/%d (%f)'", "%", "(", "ix0", "-", "1", ",", "ix1", ",", "loss", ")", ")", "\n", "\n", "", "if", "data", "[", "'bounds'", "]", "[", "'wrapped'", "]", ":", "\n", "            ", "break", "\n", "", "if", "num_images", ">=", "0", "and", "n", ">=", "num_images", ":", "\n", "            ", "break", "\n", "\n", "", "", "lang_stats", "=", "None", "\n", "if", "lang_eval", "==", "1", ":", "\n", "        ", "lang_stats", "=", "language_eval", "(", "dataset", ",", "predictions", ",", "eval_kwargs", "[", "'id'", "]", ",", "split", ")", "\n", "\n", "# Switch back to training mode", "\n", "", "model", ".", "train", "(", ")", "\n", "return", "loss_sum", "/", "loss_evals", ",", "predictions", ",", "lang_stats", "\n", "", ""]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.HybridLoader.__init__": [[24, 43], ["db_path.endswith", "lmdb.open", "db_path.endswith", "numpy.load", "torch.load", "torch.load", "torch.load", "torch.load", "print", "numpy.load", "os.path.isdir"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "db_path", ",", "ext", ")", ":", "\n", "        ", "self", ".", "db_path", "=", "db_path", "\n", "self", ".", "ext", "=", "ext", "\n", "if", "self", ".", "ext", "==", "'.npy'", ":", "\n", "            ", "self", ".", "loader", "=", "lambda", "x", ":", "np", ".", "load", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "loader", "=", "lambda", "x", ":", "np", ".", "load", "(", "x", ")", "[", "'feat'", "]", "\n", "", "if", "db_path", ".", "endswith", "(", "'.lmdb'", ")", ":", "\n", "            ", "self", ".", "db_type", "=", "'lmdb'", "\n", "self", ".", "env", "=", "lmdb", ".", "open", "(", "db_path", ",", "subdir", "=", "os", ".", "path", ".", "isdir", "(", "db_path", ")", ",", "\n", "readonly", "=", "True", ",", "lock", "=", "False", ",", "\n", "readahead", "=", "False", ",", "meminit", "=", "False", ")", "\n", "", "elif", "db_path", ".", "endswith", "(", "'.pth'", ")", ":", "# Assume a key,value dictionary", "\n", "            ", "self", ".", "db_type", "=", "'pth'", "\n", "self", ".", "feat_file", "=", "torch", ".", "load", "(", "db_path", ")", "\n", "self", ".", "loader", "=", "lambda", "x", ":", "x", "\n", "print", "(", "'HybridLoader: ext is ignored'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "db_type", "=", "'dir'", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.HybridLoader.get": [[44, 60], ["dataloader.HybridLoader.loader", "six.BytesIO", "env.begin", "txn.get", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get"], ["", "", "def", "get", "(", "self", ",", "key", ")", ":", "\n", "\n", "        ", "if", "self", ".", "db_type", "==", "'lmdb'", ":", "\n", "            ", "env", "=", "self", ".", "env", "\n", "with", "env", ".", "begin", "(", "write", "=", "False", ")", "as", "txn", ":", "\n", "                ", "byteflow", "=", "txn", ".", "get", "(", "key", ")", "\n", "", "f_input", "=", "six", ".", "BytesIO", "(", "byteflow", ")", "\n", "", "elif", "self", ".", "db_type", "==", "'pth'", ":", "\n", "            ", "f_input", "=", "self", ".", "feat_file", "[", "key", "]", "\n", "", "else", ":", "\n", "            ", "f_input", "=", "os", ".", "path", ".", "join", "(", "self", ".", "db_path", ",", "key", "+", "self", ".", "ext", ")", "\n", "\n", "# load image", "\n", "", "feat", "=", "self", ".", "loader", "(", "f_input", ")", "\n", "\n", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.reset_iterator": [[64, 68], ["dataloader.BlobFetcher"], "methods", ["None"], ["    ", "def", "reset_iterator", "(", "self", ",", "split", ")", ":", "\n", "        ", "del", "self", ".", "_prefetch_process", "[", "split", "]", "\n", "self", ".", "_prefetch_process", "[", "split", "]", "=", "BlobFetcher", "(", "split", ",", "self", ",", "split", "==", "'train'", ")", "\n", "self", ".", "iterators", "[", "split", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.get_vocab_size": [[69, 71], ["None"], "methods", ["None"], ["", "def", "get_vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.get_vocab": [[72, 74], ["None"], "methods", ["None"], ["", "def", "get_vocab", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "ix_to_word", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.get_seq_length": [[75, 77], ["None"], "methods", ["None"], ["", "def", "get_seq_length", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "seq_length", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.__init__": [[78, 153], ["getattr", "getattr", "getattr", "getattr", "getattr", "print", "json.load", "print", "dataloader.HybridLoader", "dataloader.HybridLoader", "dataloader.HybridLoader", "len", "print", "range", "print", "print", "print", "dataloader.DataLoader.iterators.keys", "atexit.register", "open", "len", "print", "h5py.File", "print", "len", "dataloader.BlobFetcher", "print", "dataloader.DataLoader.iterators.keys", "dataloader.DataLoader.split_ix[].append", "dataloader.DataLoader.split_ix[].append", "dataloader.DataLoader.split_ix[].append", "len", "len", "len", "dataloader.DataLoader.split_ix[].append", "dataloader.DataLoader.split_ix[].append", "dataloader.DataLoader.split_ix[].append", "dataloader.DataLoader.split_ix[].append"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "batch_size", "=", "self", ".", "opt", ".", "batch_size", "\n", "self", ".", "seq_per_img", "=", "opt", ".", "seq_per_img", "\n", "\n", "# feature related options", "\n", "self", ".", "use_fc", "=", "getattr", "(", "opt", ",", "'use_fc'", ",", "True", ")", "\n", "self", ".", "use_att", "=", "getattr", "(", "opt", ",", "'use_att'", ",", "True", ")", "\n", "self", ".", "use_box", "=", "getattr", "(", "opt", ",", "'use_box'", ",", "0", ")", "\n", "self", ".", "norm_att_feat", "=", "getattr", "(", "opt", ",", "'norm_att_feat'", ",", "0", ")", "\n", "self", ".", "norm_box_feat", "=", "getattr", "(", "opt", ",", "'norm_box_feat'", ",", "0", ")", "\n", "\n", "# load the json file which contains additional information about the dataset", "\n", "print", "(", "'DataLoader loading json file: '", ",", "opt", ".", "input_json", ")", "\n", "self", ".", "info", "=", "json", ".", "load", "(", "open", "(", "self", ".", "opt", ".", "input_json", ")", ")", "\n", "if", "'ix_to_word'", "in", "self", ".", "info", ":", "\n", "            ", "self", ".", "ix_to_word", "=", "self", ".", "info", "[", "'ix_to_word'", "]", "\n", "self", ".", "vocab_size", "=", "len", "(", "self", ".", "ix_to_word", ")", "\n", "print", "(", "'vocab size is '", ",", "self", ".", "vocab_size", ")", "\n", "\n", "# open the hdf5 file", "\n", "", "print", "(", "'DataLoader loading h5 file: '", ",", "opt", ".", "input_fc_dir", ",", "opt", ".", "input_att_dir", ",", "opt", ".", "input_box_dir", ",", "opt", ".", "input_label_h5", ")", "\n", "if", "self", ".", "opt", ".", "input_label_h5", "!=", "'none'", ":", "\n", "            ", "self", ".", "h5_label_file", "=", "h5py", ".", "File", "(", "self", ".", "opt", ".", "input_label_h5", ",", "'r'", ",", "driver", "=", "'core'", ")", "\n", "# load in the sequence data", "\n", "seq_size", "=", "self", ".", "h5_label_file", "[", "'labels'", "]", ".", "shape", "\n", "self", ".", "label", "=", "self", ".", "h5_label_file", "[", "'labels'", "]", "[", ":", "]", "\n", "self", ".", "seq_length", "=", "seq_size", "[", "1", "]", "\n", "print", "(", "'max sequence length in data is'", ",", "self", ".", "seq_length", ")", "\n", "# load the pointers in full to RAM (should be small enough)", "\n", "self", ".", "label_start_ix", "=", "self", ".", "h5_label_file", "[", "'label_start_ix'", "]", "[", ":", "]", "\n", "self", ".", "label_end_ix", "=", "self", ".", "h5_label_file", "[", "'label_end_ix'", "]", "[", ":", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "seq_length", "=", "1", "\n", "\n", "", "self", ".", "fc_loader", "=", "HybridLoader", "(", "self", ".", "opt", ".", "input_fc_dir", ",", "'.npy'", ")", "\n", "self", ".", "att_loader", "=", "HybridLoader", "(", "self", ".", "opt", ".", "input_att_dir", ",", "'.npz'", ")", "\n", "self", ".", "box_loader", "=", "HybridLoader", "(", "self", ".", "opt", ".", "input_box_dir", ",", "'.npy'", ")", "\n", "\n", "self", ".", "num_images", "=", "len", "(", "self", ".", "info", "[", "'images'", "]", ")", "# self.label_start_ix.shape[0]", "\n", "print", "(", "'read %d image features'", "%", "(", "self", ".", "num_images", ")", ")", "\n", "\n", "# separate out indexes for each of the provided splits", "\n", "self", ".", "split_ix", "=", "{", "'train'", ":", "[", "]", ",", "'val'", ":", "[", "]", ",", "'test'", ":", "[", "]", "}", "\n", "for", "ix", "in", "range", "(", "len", "(", "self", ".", "info", "[", "'images'", "]", ")", ")", ":", "\n", "            ", "img", "=", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", "\n", "if", "not", "'split'", "in", "img", ":", "\n", "                ", "self", ".", "split_ix", "[", "'train'", "]", ".", "append", "(", "ix", ")", "\n", "self", ".", "split_ix", "[", "'val'", "]", ".", "append", "(", "ix", ")", "\n", "self", ".", "split_ix", "[", "'test'", "]", ".", "append", "(", "ix", ")", "\n", "", "elif", "img", "[", "'split'", "]", "==", "'train'", ":", "\n", "                ", "self", ".", "split_ix", "[", "'train'", "]", ".", "append", "(", "ix", ")", "\n", "", "elif", "img", "[", "'split'", "]", "==", "'val'", ":", "\n", "                ", "self", ".", "split_ix", "[", "'val'", "]", ".", "append", "(", "ix", ")", "\n", "", "elif", "img", "[", "'split'", "]", "==", "'test'", ":", "\n", "                ", "self", ".", "split_ix", "[", "'test'", "]", ".", "append", "(", "ix", ")", "\n", "", "elif", "opt", ".", "train_only", "==", "0", ":", "# restval", "\n", "                ", "self", ".", "split_ix", "[", "'train'", "]", ".", "append", "(", "ix", ")", "\n", "\n", "", "", "print", "(", "'assigned %d images to split train'", "%", "len", "(", "self", ".", "split_ix", "[", "'train'", "]", ")", ")", "\n", "print", "(", "'assigned %d images to split val'", "%", "len", "(", "self", ".", "split_ix", "[", "'val'", "]", ")", ")", "\n", "print", "(", "'assigned %d images to split test'", "%", "len", "(", "self", ".", "split_ix", "[", "'test'", "]", ")", ")", "\n", "\n", "self", ".", "iterators", "=", "{", "'train'", ":", "0", ",", "'val'", ":", "0", ",", "'test'", ":", "0", "}", "\n", "\n", "self", ".", "_prefetch_process", "=", "{", "}", "# The three prefetch process", "\n", "for", "split", "in", "self", ".", "iterators", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "_prefetch_process", "[", "split", "]", "=", "BlobFetcher", "(", "split", ",", "self", ",", "split", "==", "'train'", ")", "\n", "# Terminate the child process when the parent exists", "\n", "", "def", "cleanup", "(", ")", ":", "\n", "            ", "print", "(", "'Terminating BlobFetcher'", ")", "\n", "for", "split", "in", "self", ".", "iterators", ".", "keys", "(", ")", ":", "\n", "                ", "del", "self", ".", "_prefetch_process", "[", "split", "]", "\n", "", "", "import", "atexit", "\n", "atexit", ".", "register", "(", "cleanup", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.get_captions": [[154, 172], ["numpy.zeros", "range", "random.randint", "random.randint"], "methods", ["None"], ["", "def", "get_captions", "(", "self", ",", "ix", ",", "seq_per_img", ")", ":", "\n", "# fetch the sequence labels", "\n", "        ", "ix1", "=", "self", ".", "label_start_ix", "[", "ix", "]", "-", "1", "#label_start_ix starts from 1", "\n", "ix2", "=", "self", ".", "label_end_ix", "[", "ix", "]", "-", "1", "\n", "ncap", "=", "ix2", "-", "ix1", "+", "1", "# number of captions available for this image", "\n", "assert", "ncap", ">", "0", ",", "'an image does not have any label. this can be handled but right now isn\\'t'", "\n", "\n", "if", "ncap", "<", "seq_per_img", ":", "\n", "# we need to subsample (with replacement)", "\n", "            ", "seq", "=", "np", ".", "zeros", "(", "[", "seq_per_img", ",", "self", ".", "seq_length", "]", ",", "dtype", "=", "'int'", ")", "\n", "for", "q", "in", "range", "(", "seq_per_img", ")", ":", "\n", "                ", "ixl", "=", "random", ".", "randint", "(", "ix1", ",", "ix2", ")", "\n", "seq", "[", "q", ",", ":", "]", "=", "self", ".", "label", "[", "ixl", ",", ":", "self", ".", "seq_length", "]", "\n", "", "", "else", ":", "\n", "            ", "ixl", "=", "random", ".", "randint", "(", "ix1", ",", "ix2", "-", "seq_per_img", "+", "1", ")", "\n", "seq", "=", "self", ".", "label", "[", "ixl", ":", "ixl", "+", "seq_per_img", ",", ":", "self", ".", "seq_length", "]", "\n", "\n", "", "return", "seq", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.get_batch": [[173, 248], ["range", "zip", "numpy.stack", "max", "numpy.zeros", "range", "numpy.zeros", "range", "numpy.vstack", "numpy.array", "numpy.zeros", "enumerate", "dataloader.DataLoader._prefetch_process[].get", "fc_batch.append", "att_batch.append", "numpy.zeros", "hasattr", "label_batch.append", "hasattr", "[].get", "infos.append", "sum", "len", "len", "data[].sum", "list", "len", "gts.append", "gts.append", "sorted", "map", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.items", "torch.items", "zip", "len", "type"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get"], ["", "def", "get_batch", "(", "self", ",", "split", ",", "batch_size", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "batch_size", "or", "self", ".", "batch_size", "\n", "seq_per_img", "=", "self", ".", "seq_per_img", "\n", "\n", "fc_batch", "=", "[", "]", "# np.ndarray((batch_size * seq_per_img, self.opt.fc_feat_size), dtype = 'float32')", "\n", "att_batch", "=", "[", "]", "# np.ndarray((batch_size * seq_per_img, 14, 14, self.opt.att_feat_size), dtype = 'float32')", "\n", "label_batch", "=", "[", "]", "#np.zeros([batch_size * seq_per_img, self.seq_length + 2], dtype = 'int')", "\n", "\n", "wrapped", "=", "False", "\n", "\n", "infos", "=", "[", "]", "\n", "gts", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "# fetch image", "\n", "            ", "tmp_fc", ",", "tmp_att", ",", "tmp_seq", ",", "ix", ",", "tmp_wrapped", "=", "self", ".", "_prefetch_process", "[", "split", "]", ".", "get", "(", ")", "\n", "if", "tmp_wrapped", ":", "\n", "                ", "wrapped", "=", "True", "\n", "\n", "", "fc_batch", ".", "append", "(", "tmp_fc", ")", "\n", "att_batch", ".", "append", "(", "tmp_att", ")", "\n", "\n", "tmp_label", "=", "np", ".", "zeros", "(", "[", "seq_per_img", ",", "self", ".", "seq_length", "+", "2", "]", ",", "dtype", "=", "'int'", ")", "\n", "if", "hasattr", "(", "self", ",", "'h5_label_file'", ")", ":", "\n", "                ", "tmp_label", "[", ":", ",", "1", ":", "self", ".", "seq_length", "+", "1", "]", "=", "tmp_seq", "\n", "", "label_batch", ".", "append", "(", "tmp_label", ")", "\n", "\n", "# Used for reward evaluation", "\n", "if", "hasattr", "(", "self", ",", "'h5_label_file'", ")", ":", "\n", "                ", "gts", ".", "append", "(", "self", ".", "label", "[", "self", ".", "label_start_ix", "[", "ix", "]", "-", "1", ":", "self", ".", "label_end_ix", "[", "ix", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "gts", ".", "append", "(", "[", "]", ")", "\n", "\n", "# record associated info as well", "\n", "", "info_dict", "=", "{", "}", "\n", "info_dict", "[", "'ix'", "]", "=", "ix", "\n", "info_dict", "[", "'id'", "]", "=", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", "[", "'id'", "]", "\n", "info_dict", "[", "'file_path'", "]", "=", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", ".", "get", "(", "'file_path'", ",", "''", ")", "\n", "infos", ".", "append", "(", "info_dict", ")", "\n", "\n", "# #sort by att_feat length", "\n", "# fc_batch, att_batch, label_batch, gts, infos = \\", "\n", "#     zip(*sorted(zip(fc_batch, att_batch, np.vsplit(label_batch, batch_size), gts, infos), key=lambda x: len(x[1]), reverse=True))", "\n", "", "fc_batch", ",", "att_batch", ",", "label_batch", ",", "gts", ",", "infos", "=", "zip", "(", "*", "sorted", "(", "zip", "(", "fc_batch", ",", "att_batch", ",", "label_batch", ",", "gts", ",", "infos", ")", ",", "key", "=", "lambda", "x", ":", "0", ",", "reverse", "=", "True", ")", ")", "\n", "data", "=", "{", "}", "\n", "data", "[", "'fc_feats'", "]", "=", "np", ".", "stack", "(", "sum", "(", "[", "[", "_", "]", "*", "seq_per_img", "for", "_", "in", "fc_batch", "]", ",", "[", "]", ")", ")", "\n", "# merge att_feats", "\n", "max_att_len", "=", "max", "(", "[", "_", ".", "shape", "[", "0", "]", "for", "_", "in", "att_batch", "]", ")", "\n", "data", "[", "'att_feats'", "]", "=", "np", ".", "zeros", "(", "[", "len", "(", "att_batch", ")", "*", "seq_per_img", ",", "max_att_len", ",", "att_batch", "[", "0", "]", ".", "shape", "[", "1", "]", "]", ",", "dtype", "=", "'float32'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "att_batch", ")", ")", ":", "\n", "            ", "data", "[", "'att_feats'", "]", "[", "i", "*", "seq_per_img", ":", "(", "i", "+", "1", ")", "*", "seq_per_img", ",", ":", "att_batch", "[", "i", "]", ".", "shape", "[", "0", "]", "]", "=", "att_batch", "[", "i", "]", "\n", "", "data", "[", "'att_masks'", "]", "=", "np", ".", "zeros", "(", "data", "[", "'att_feats'", "]", ".", "shape", "[", ":", "2", "]", ",", "dtype", "=", "'float32'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "att_batch", ")", ")", ":", "\n", "            ", "data", "[", "'att_masks'", "]", "[", "i", "*", "seq_per_img", ":", "(", "i", "+", "1", ")", "*", "seq_per_img", ",", ":", "att_batch", "[", "i", "]", ".", "shape", "[", "0", "]", "]", "=", "1", "\n", "# set att_masks to None if attention features have same length", "\n", "", "if", "data", "[", "'att_masks'", "]", ".", "sum", "(", ")", "==", "data", "[", "'att_masks'", "]", ".", "size", ":", "\n", "            ", "data", "[", "'att_masks'", "]", "=", "None", "\n", "\n", "", "data", "[", "'labels'", "]", "=", "np", ".", "vstack", "(", "label_batch", ")", "\n", "# generate mask", "\n", "nonzeros", "=", "np", ".", "array", "(", "list", "(", "map", "(", "lambda", "x", ":", "(", "x", "!=", "0", ")", ".", "sum", "(", ")", "+", "2", ",", "data", "[", "'labels'", "]", ")", ")", ")", "\n", "mask_batch", "=", "np", ".", "zeros", "(", "[", "data", "[", "'labels'", "]", ".", "shape", "[", "0", "]", ",", "self", ".", "seq_length", "+", "2", "]", ",", "dtype", "=", "'float32'", ")", "\n", "for", "ix", ",", "row", "in", "enumerate", "(", "mask_batch", ")", ":", "\n", "            ", "row", "[", ":", "nonzeros", "[", "ix", "]", "]", "=", "1", "\n", "", "data", "[", "'masks'", "]", "=", "mask_batch", "\n", "\n", "data", "[", "'gts'", "]", "=", "gts", "# all ground truth captions of each images", "\n", "data", "[", "'bounds'", "]", "=", "{", "'it_pos_now'", ":", "self", ".", "iterators", "[", "split", "]", ",", "'it_max'", ":", "len", "(", "self", ".", "split_ix", "[", "split", "]", ")", ",", "'wrapped'", ":", "wrapped", "}", "\n", "data", "[", "'infos'", "]", "=", "infos", "\n", "\n", "data", "=", "{", "k", ":", "torch", ".", "from_numpy", "(", "v", ")", "if", "type", "(", "v", ")", "is", "np", ".", "ndarray", "else", "v", "for", "k", ",", "v", "in", "data", ".", "items", "(", ")", "}", "# Turn all ndarray to torch tensor", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.__getitem__": [[252, 286], ["hasattr", "dataloader.DataLoader.att_loader.get", "numpy.stack.reshape", "numpy.zeros", "dataloader.DataLoader.fc_loader.get", "numpy.zeros", "dataloader.DataLoader.get_captions", "str", "dataloader.DataLoader.box_loader.get", "numpy.hsplit", "numpy.hstack", "numpy.hstack", "numpy.stack", "str", "numpy.linalg.norm", "str", "sorted", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.get_captions", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"This function returns a tuple that is further passed to collate_fn\n        \"\"\"", "\n", "ix", "=", "index", "#self.split_ix[index]", "\n", "if", "self", ".", "use_att", ":", "\n", "            ", "att_feat", "=", "self", ".", "att_loader", ".", "get", "(", "str", "(", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", "[", "'id'", "]", ")", ")", "\n", "# Reshape to K x C", "\n", "att_feat", "=", "att_feat", ".", "reshape", "(", "-", "1", ",", "att_feat", ".", "shape", "[", "-", "1", "]", ")", "\n", "if", "self", ".", "norm_att_feat", ":", "\n", "                ", "att_feat", "=", "att_feat", "/", "np", ".", "linalg", ".", "norm", "(", "att_feat", ",", "2", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "", "if", "self", ".", "use_box", ":", "\n", "                ", "box_feat", "=", "self", ".", "box_loader", ".", "get", "(", "str", "(", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", "[", "'id'", "]", ")", ")", "\n", "# devided by image width and height", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "np", ".", "hsplit", "(", "box_feat", ",", "4", ")", "\n", "h", ",", "w", "=", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", "[", "'height'", "]", ",", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", "[", "'width'", "]", "\n", "box_feat", "=", "np", ".", "hstack", "(", "(", "x1", "/", "w", ",", "y1", "/", "h", ",", "x2", "/", "w", ",", "y2", "/", "h", ",", "(", "x2", "-", "x1", ")", "*", "(", "y2", "-", "y1", ")", "/", "(", "w", "*", "h", ")", ")", ")", "# question? x2-x1+1??", "\n", "if", "self", ".", "norm_box_feat", ":", "\n", "                    ", "box_feat", "=", "box_feat", "/", "np", ".", "linalg", ".", "norm", "(", "box_feat", ",", "2", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "", "att_feat", "=", "np", ".", "hstack", "(", "[", "att_feat", ",", "box_feat", "]", ")", "\n", "# sort the features by the size of boxes", "\n", "att_feat", "=", "np", ".", "stack", "(", "sorted", "(", "att_feat", ",", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ",", "reverse", "=", "True", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "att_feat", "=", "np", ".", "zeros", "(", "(", "1", ",", "1", ",", "1", ")", ",", "dtype", "=", "'float32'", ")", "\n", "", "if", "self", ".", "use_fc", ":", "\n", "            ", "fc_feat", "=", "self", ".", "fc_loader", ".", "get", "(", "str", "(", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", "[", "'id'", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "fc_feat", "=", "np", ".", "zeros", "(", "(", "1", ")", ",", "dtype", "=", "'float32'", ")", "\n", "", "if", "hasattr", "(", "self", ",", "'h5_label_file'", ")", ":", "\n", "            ", "seq", "=", "self", ".", "get_captions", "(", "ix", ",", "self", ".", "seq_per_img", ")", "\n", "", "else", ":", "\n", "            ", "seq", "=", "None", "\n", "", "return", "(", "fc_feat", ",", "\n", "att_feat", ",", "seq", ",", "\n", "ix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.DataLoader.__len__": [[287, 289], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "info", "[", "'images'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.SubsetSampler.__init__": [[296, 298], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "indices", ")", ":", "\n", "        ", "self", ".", "indices", "=", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.SubsetSampler.__iter__": [[299, 301], ["range", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "indices", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "self", ".", "indices", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.SubsetSampler.__len__": [[302, 304], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.__init__": [[307, 314], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "split", ",", "dataloader", ",", "if_shuffle", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        db is a list of tuples containing: imcrop_name, caption, bbox_feat of gt box, imname\n        \"\"\"", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "dataloader", "=", "dataloader", "\n", "self", ".", "if_shuffle", "=", "if_shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.reset": [[316, 330], ["iter", "torch.DataLoader", "torch.DataLoader", "dataloader.SubsetSampler"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Two cases for this function to be triggered:\n        1. not hasattr(self, 'split_loader'): Resume from previous training. Create the dataset given the saved split_ix and iterator\n        2. wrapped: a new epoch, the split_ix and iterator have been updated in the get_minibatch_inds already.\n        \"\"\"", "\n", "# batch_size is 1, the merge is done in DataLoader class", "\n", "self", ".", "split_loader", "=", "iter", "(", "data", ".", "DataLoader", "(", "dataset", "=", "self", ".", "dataloader", ",", "\n", "batch_size", "=", "1", ",", "\n", "sampler", "=", "SubsetSampler", "(", "self", ".", "dataloader", ".", "split_ix", "[", "self", ".", "split", "]", "[", "self", ".", "dataloader", ".", "iterators", "[", "self", ".", "split", "]", ":", "]", ")", ",", "\n", "shuffle", "=", "False", ",", "\n", "pin_memory", "=", "True", ",", "\n", "num_workers", "=", "4", ",", "# 4 is usually enough", "\n", "collate_fn", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher._get_next_minibatch_inds": [[331, 347], ["len", "random.shuffle"], "methods", ["None"], ["", "def", "_get_next_minibatch_inds", "(", "self", ")", ":", "\n", "        ", "max_index", "=", "len", "(", "self", ".", "dataloader", ".", "split_ix", "[", "self", ".", "split", "]", ")", "\n", "wrapped", "=", "False", "\n", "\n", "ri", "=", "self", ".", "dataloader", ".", "iterators", "[", "self", ".", "split", "]", "\n", "ix", "=", "self", ".", "dataloader", ".", "split_ix", "[", "self", ".", "split", "]", "[", "ri", "]", "\n", "\n", "ri_next", "=", "ri", "+", "1", "\n", "if", "ri_next", ">=", "max_index", ":", "\n", "            ", "ri_next", "=", "0", "\n", "if", "self", ".", "if_shuffle", ":", "\n", "                ", "random", ".", "shuffle", "(", "self", ".", "dataloader", ".", "split_ix", "[", "self", ".", "split", "]", ")", "\n", "", "wrapped", "=", "True", "\n", "", "self", ".", "dataloader", ".", "iterators", "[", "self", ".", "split", "]", "=", "ri_next", "\n", "\n", "return", "ix", ",", "wrapped", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get": [[348, 360], ["dataloader.BlobFetcher._get_next_minibatch_inds", "dataloader.BlobFetcher.split_loader.next", "hasattr", "dataloader.BlobFetcher.reset", "dataloader.BlobFetcher.reset"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher._get_next_minibatch_inds", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.reset", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.reset"], ["", "def", "get", "(", "self", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "self", ",", "'split_loader'", ")", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "\n", "", "ix", ",", "wrapped", "=", "self", ".", "_get_next_minibatch_inds", "(", ")", "\n", "tmp", "=", "self", ".", "split_loader", ".", "next", "(", ")", "\n", "if", "wrapped", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "\n", "", "assert", "tmp", "[", "-", "1", "]", "==", "ix", ",", "\"ix not equal\"", "\n", "\n", "return", "tmp", "+", "[", "wrapped", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_ngrams.precook": [[33, 49], ["s.split", "collections.defaultdict", "xrange", "xrange", "tuple", "len"], "function", ["None"], ["def", "precook", "(", "s", ",", "n", "=", "4", ",", "out", "=", "False", ")", ":", "\n", "  ", "\"\"\"\n  Takes a string as input and returns an object that can be given to\n  either cook_refs or cook_test. This is optional: cook_refs and cook_test\n  can take string arguments as well.\n  :param s: string : sentence to be converted into ngrams\n  :param n: int    : number of ngrams for which representation is calculated\n  :return: term frequency vector for occuring ngrams\n  \"\"\"", "\n", "words", "=", "s", ".", "split", "(", ")", "\n", "counts", "=", "defaultdict", "(", "int", ")", "\n", "for", "k", "in", "xrange", "(", "1", ",", "n", "+", "1", ")", ":", "\n", "    ", "for", "i", "in", "xrange", "(", "len", "(", "words", ")", "-", "k", "+", "1", ")", ":", "\n", "      ", "ngram", "=", "tuple", "(", "words", "[", "i", ":", "i", "+", "k", "]", ")", "\n", "counts", "[", "ngram", "]", "+=", "1", "\n", "", "", "return", "counts", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_ngrams.cook_refs": [[50, 59], ["prepro_ngrams.precook"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_ngrams.precook"], ["", "def", "cook_refs", "(", "refs", ",", "n", "=", "4", ")", ":", "## lhuang: oracle will call with \"average\"", "\n", "    ", "'''Takes a list of reference sentences for a single segment\n    and returns an object that encapsulates everything that BLEU\n    needs to know about them.\n    :param refs: list of string : reference sentences for some image\n    :param n: int : number of ngrams for which (ngram) representation is calculated\n    :return: result (list of dict)\n    '''", "\n", "return", "[", "precook", "(", "ref", ",", "n", ")", "for", "ref", "in", "refs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_ngrams.create_crefs": [[60, 66], ["crefs.append", "prepro_ngrams.cook_refs"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_ngrams.cook_refs"], ["", "def", "create_crefs", "(", "refs", ")", ":", "\n", "  ", "crefs", "=", "[", "]", "\n", "for", "ref", "in", "refs", ":", "\n", "# ref is a list of 5 captions", "\n", "    ", "crefs", ".", "append", "(", "cook_refs", "(", "ref", ")", ")", "\n", "", "return", "crefs", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_ngrams.compute_doc_freq": [[67, 81], ["collections.defaultdict", "set", "ref.iteritems"], "function", ["None"], ["", "def", "compute_doc_freq", "(", "crefs", ")", ":", "\n", "  ", "'''\n  Compute term frequency for reference data.\n  This will be used to compute idf (inverse document frequency later)\n  The term frequency is stored in the object\n  :return: None\n  '''", "\n", "document_frequency", "=", "defaultdict", "(", "float", ")", "\n", "for", "refs", "in", "crefs", ":", "\n", "# refs, k ref captions of one image", "\n", "    ", "for", "ngram", "in", "set", "(", "[", "ngram", "for", "ref", "in", "refs", "for", "(", "ngram", ",", "count", ")", "in", "ref", ".", "iteritems", "(", ")", "]", ")", ":", "\n", "      ", "document_frequency", "[", "ngram", "]", "+=", "1", "\n", "# maxcounts[ngram] = max(maxcounts.get(ngram,0), count)", "\n", "", "", "return", "document_frequency", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_ngrams.build_dict": [[82, 111], ["print", "prepro_ngrams.compute_doc_freq", "prepro_ngrams.compute_doc_freq", "prepro_ngrams.create_crefs", "prepro_ngrams.create_crefs", "refs_words.append", "refs_idxs.append", "hasattr", "ref_words.append", "ref_idxs.append", "params.bpe.segment().strip().split", "params.bpe.segment().strip", "str", "params.bpe.segment"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_ngrams.compute_doc_freq", "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_ngrams.compute_doc_freq", "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_ngrams.create_crefs", "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_ngrams.create_crefs"], ["", "def", "build_dict", "(", "imgs", ",", "wtoi", ",", "params", ")", ":", "\n", "  ", "wtoi", "[", "'<eos>'", "]", "=", "0", "\n", "\n", "count_imgs", "=", "0", "\n", "\n", "refs_words", "=", "[", "]", "\n", "refs_idxs", "=", "[", "]", "\n", "for", "img", "in", "imgs", ":", "\n", "    ", "if", "(", "params", "[", "'split'", "]", "==", "img", "[", "'split'", "]", ")", "or", "(", "params", "[", "'split'", "]", "==", "'train'", "and", "img", "[", "'split'", "]", "==", "'restval'", ")", "or", "(", "params", "[", "'split'", "]", "==", "'all'", ")", ":", "\n", "#(params['split'] == 'val' and img['split'] == 'restval') or \\", "\n", "      ", "ref_words", "=", "[", "]", "\n", "ref_idxs", "=", "[", "]", "\n", "for", "sent", "in", "img", "[", "'sentences'", "]", ":", "\n", "        ", "if", "hasattr", "(", "params", ",", "'bpe'", ")", ":", "\n", "          ", "sent", "[", "'tokens'", "]", "=", "params", ".", "bpe", ".", "segment", "(", "' '", ".", "join", "(", "sent", "[", "'tokens'", "]", ")", ")", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "", "tmp_tokens", "=", "sent", "[", "'tokens'", "]", "+", "[", "'<eos>'", "]", "\n", "tmp_tokens", "=", "[", "_", "if", "_", "in", "wtoi", "else", "'UNK'", "for", "_", "in", "tmp_tokens", "]", "\n", "ref_words", ".", "append", "(", "' '", ".", "join", "(", "tmp_tokens", ")", ")", "\n", "ref_idxs", ".", "append", "(", "' '", ".", "join", "(", "[", "str", "(", "wtoi", "[", "_", "]", ")", "for", "_", "in", "tmp_tokens", "]", ")", ")", "\n", "", "refs_words", ".", "append", "(", "ref_words", ")", "\n", "refs_idxs", ".", "append", "(", "ref_idxs", ")", "\n", "count_imgs", "+=", "1", "\n", "", "", "print", "(", "'total imgs:'", ",", "count_imgs", ")", "\n", "\n", "ngram_words", "=", "compute_doc_freq", "(", "create_crefs", "(", "refs_words", ")", ")", "\n", "ngram_idxs", "=", "compute_doc_freq", "(", "create_crefs", "(", "refs_idxs", ")", ")", "\n", "return", "ngram_words", ",", "ngram_idxs", ",", "count_imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_ngrams.main": [[112, 137], ["json.load", "json.load", "prepro_ngrams.build_dict", "misc.pickle_dump", "misc.pickle_dump", "open", "open", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.close", "open", "open", "itow.items", "open", "f.write", "codecs.open", "apply_bpe.BPE"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_ngrams.build_dict", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.pickle_dump", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.pickle_dump"], ["", "def", "main", "(", "params", ")", ":", "\n", "\n", "  ", "imgs", "=", "json", ".", "load", "(", "open", "(", "params", "[", "'input_json'", "]", ",", "'r'", ")", ")", "\n", "dict_json", "=", "json", ".", "load", "(", "open", "(", "params", "[", "'dict_json'", "]", ",", "'r'", ")", ")", "\n", "itow", "=", "dict_json", "[", "'ix_to_word'", "]", "\n", "wtoi", "=", "{", "w", ":", "i", "for", "i", ",", "w", "in", "itow", ".", "items", "(", ")", "}", "\n", "\n", "# Load bpe", "\n", "if", "'bpe'", "in", "dict_json", ":", "\n", "    ", "import", "tempfile", "\n", "import", "codecs", "\n", "codes_f", "=", "tempfile", ".", "NamedTemporaryFile", "(", "delete", "=", "False", ")", "\n", "codes_f", ".", "close", "(", ")", "\n", "with", "open", "(", "codes_f", ".", "name", ",", "'w'", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "dict_json", "[", "'bpe'", "]", ")", "\n", "", "with", "codecs", ".", "open", "(", "codes_f", ".", "name", ",", "encoding", "=", "'UTF-8'", ")", "as", "codes", ":", "\n", "      ", "bpe", "=", "apply_bpe", ".", "BPE", "(", "codes", ")", "\n", "", "params", ".", "bpe", "=", "bpe", "\n", "\n", "", "imgs", "=", "imgs", "[", "'images'", "]", "\n", "\n", "ngram_words", ",", "ngram_idxs", ",", "ref_len", "=", "build_dict", "(", "imgs", ",", "wtoi", ",", "params", ")", "\n", "\n", "utils", ".", "pickle_dump", "(", "{", "'document_frequency'", ":", "ngram_words", ",", "'ref_len'", ":", "ref_len", "}", ",", "open", "(", "params", "[", "'output_pkl'", "]", "+", "'-words.p'", ",", "'w'", ")", ")", "\n", "utils", ".", "pickle_dump", "(", "{", "'document_frequency'", ":", "ngram_idxs", ",", "'ref_len'", ":", "ref_len", "}", ",", "open", "(", "params", "[", "'output_pkl'", "]", "+", "'-idxs.p'", ",", "'w'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_reference_json.main": [[39, 72], ["out.update", "enumerate", "json.dump", "print", "json.load", "out[].append", "enumerate", "open", "open", "out[].append", "img.get", "len"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get"], ["def", "main", "(", "params", ")", ":", "\n", "\n", "    ", "imgs", "=", "json", ".", "load", "(", "open", "(", "params", "[", "'input_json'", "]", "[", "0", "]", ",", "'r'", ")", ")", "[", "'images'", "]", "\n", "# tmp = []", "\n", "# for k in imgs.keys():", "\n", "#     for img in imgs[k]:", "\n", "#         img['filename'] = img['image_id']  # k+'/'+img['image_id']", "\n", "#         img['image_id'] = int(", "\n", "#             int(hashlib.sha256(img['image_id']).hexdigest(), 16) % sys.maxint)", "\n", "#         tmp.append(img)", "\n", "# imgs = tmp", "\n", "\n", "# create output json file", "\n", "out", "=", "{", "u'info'", ":", "{", "u'description'", ":", "u'This is stable 1.0 version of the 2014 MS COCO dataset.'", ",", "u'url'", ":", "u'http://mscoco.org'", ",", "u'version'", ":", "u'1.0'", ",", "u'year'", ":", "2014", ",", "u'contributor'", ":", "u'Microsoft COCO group'", ",", "u'date_created'", ":", "u'2015-01-27 09:11:52.357475'", "}", ",", "u'licenses'", ":", "[", "{", "u'url'", ":", "u'http://creativecommons.org/licenses/by-nc-sa/2.0/'", ",", "u'id'", ":", "1", ",", "u'name'", ":", "u'Attribution-NonCommercial-ShareAlike License'", "}", ",", "{", "u'url'", ":", "u'http://creativecommons.org/licenses/by-nc/2.0/'", ",", "u'id'", ":", "2", ",", "u'name'", ":", "u'Attribution-NonCommercial License'", "}", ",", "{", "u'url'", ":", "u'http://creativecommons.org/licenses/by-nc-nd/2.0/'", ",", "u'id'", ":", "3", ",", "u'name'", ":", "u'Attribution-NonCommercial-NoDerivs License'", "}", ",", "{", "u'url'", ":", "u'http://creativecommons.org/licenses/by/2.0/'", ",", "u'id'", ":", "4", ",", "u'name'", ":", "u'Attribution License'", "}", ",", "{", "u'url'", ":", "u'http://creativecommons.org/licenses/by-sa/2.0/'", ",", "u'id'", ":", "5", ",", "u'name'", ":", "u'Attribution-ShareAlike License'", "}", ",", "{", "u'url'", ":", "u'http://creativecommons.org/licenses/by-nd/2.0/'", ",", "u'id'", ":", "6", ",", "u'name'", ":", "u'Attribution-NoDerivs License'", "}", ",", "{", "u'url'", ":", "u'http://flickr.com/commons/usage/'", ",", "u'id'", ":", "7", ",", "u'name'", ":", "u'No known copyright restrictions'", "}", ",", "{", "u'url'", ":", "u'http://www.usa.gov/copyright.shtml'", ",", "u'id'", ":", "8", ",", "u'name'", ":", "u'United States Government Work'", "}", "]", ",", "u'type'", ":", "u'captions'", "}", "\n", "out", ".", "update", "(", "{", "'images'", ":", "[", "]", ",", "'annotations'", ":", "[", "]", "}", ")", "\n", "\n", "cnt", "=", "0", "\n", "empty_cnt", "=", "0", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "        ", "if", "img", "[", "'split'", "]", "==", "'train'", ":", "\n", "            ", "continue", "\n", "", "out", "[", "'images'", "]", ".", "append", "(", "\n", "{", "u'id'", ":", "img", ".", "get", "(", "'cocoid'", ",", "img", "[", "'imgid'", "]", ")", "}", ")", "\n", "for", "j", ",", "s", "in", "enumerate", "(", "img", "[", "'sentences'", "]", ")", ":", "\n", "            ", "if", "len", "(", "s", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "s", "=", "' '", ".", "join", "(", "s", "[", "'tokens'", "]", ")", "\n", "out", "[", "'annotations'", "]", ".", "append", "(", "\n", "{", "'image_id'", ":", "out", "[", "'images'", "]", "[", "-", "1", "]", "[", "'id'", "]", ",", "'caption'", ":", "s", ",", "'id'", ":", "cnt", "}", ")", "\n", "cnt", "+=", "1", "\n", "\n", "", "", "json", ".", "dump", "(", "out", ",", "open", "(", "params", "[", "'output_json'", "]", ",", "'w'", ")", ")", "\n", "print", "(", "'wrote '", ",", "params", "[", "'output_json'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.build_bpe_subword_nmt.build_vocab": [[49, 105], ["tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.close", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.close", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.close", "codecs.open", "enumerate", "codecs.open.close", "codecs.open", "subword_nmt.learn_bpe.get_vocabulary", "sorted", "print", "sorted.append", "print", "os.remove", "os.remove", "os.remove", "open", "txt_file.write", "codecs.open", "subword_nmt.learn_bpe.learn_bpe", "codecs.open", "subword_nmt.apply_bpe.BPE", "sorted.keys", "len", "open", "codes.read", "captions.append", "codecs.open", "codes.read.segment().strip", "img[].append", "codecs.open.write", "codecs.open.write", "bpe.segment().strip.split", "print", "codes.read.segment"], "function", ["None"], ["def", "build_vocab", "(", "imgs", ",", "params", ")", ":", "\n", "# count up the number of words", "\n", "  ", "captions", "=", "[", "]", "\n", "for", "img", "in", "imgs", ":", "\n", "    ", "for", "sent", "in", "img", "[", "'sentences'", "]", ":", "\n", "      ", "captions", ".", "append", "(", "' '", ".", "join", "(", "sent", "[", "'tokens'", "]", ")", ")", "\n", "", "", "captions", "=", "'\\n'", ".", "join", "(", "captions", ")", "\n", "all_captions", "=", "tempfile", ".", "NamedTemporaryFile", "(", "delete", "=", "False", ")", "\n", "all_captions", ".", "close", "(", ")", "\n", "with", "open", "(", "all_captions", ".", "name", ",", "'w'", ")", "as", "txt_file", ":", "\n", "    ", "txt_file", ".", "write", "(", "captions", ")", "\n", "\n", "#", "\n", "", "codecs_output", "=", "tempfile", ".", "NamedTemporaryFile", "(", "delete", "=", "False", ")", "\n", "codecs_output", ".", "close", "(", ")", "\n", "with", "codecs", ".", "open", "(", "codecs_output", ".", "name", ",", "'w'", ",", "encoding", "=", "'UTF-8'", ")", "as", "output", ":", "\n", "    ", "learn_bpe", ".", "learn_bpe", "(", "codecs", ".", "open", "(", "all_captions", ".", "name", ",", "encoding", "=", "'UTF-8'", ")", ",", "output", ",", "params", "[", "'symbol_count'", "]", ")", "\n", "\n", "", "with", "codecs", ".", "open", "(", "codecs_output", ".", "name", ",", "encoding", "=", "'UTF-8'", ")", "as", "codes", ":", "\n", "    ", "bpe", "=", "apply_bpe", ".", "BPE", "(", "codes", ")", "\n", "\n", "", "tmp", "=", "tempfile", ".", "NamedTemporaryFile", "(", "delete", "=", "False", ")", "\n", "tmp", ".", "close", "(", ")", "\n", "\n", "tmpout", "=", "codecs", ".", "open", "(", "tmp", ".", "name", ",", "'w'", ",", "encoding", "=", "'UTF-8'", ")", "\n", "\n", "for", "_", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "    ", "img", "[", "'final_captions'", "]", "=", "[", "]", "\n", "for", "sent", "in", "img", "[", "'sentences'", "]", ":", "\n", "      ", "txt", "=", "' '", ".", "join", "(", "sent", "[", "'tokens'", "]", ")", "\n", "txt", "=", "bpe", ".", "segment", "(", "txt", ")", ".", "strip", "(", ")", "\n", "img", "[", "'final_captions'", "]", ".", "append", "(", "txt", ".", "split", "(", "' '", ")", ")", "\n", "tmpout", ".", "write", "(", "txt", ")", "\n", "tmpout", ".", "write", "(", "'\\n'", ")", "\n", "if", "_", "<", "20", ":", "\n", "        ", "print", "(", "txt", ")", "\n", "\n", "", "", "", "tmpout", ".", "close", "(", ")", "\n", "tmpin", "=", "codecs", ".", "open", "(", "tmp", ".", "name", ",", "encoding", "=", "'UTF-8'", ")", "\n", "\n", "vocab", "=", "learn_bpe", ".", "get_vocabulary", "(", "tmpin", ")", "\n", "vocab", "=", "sorted", "(", "vocab", ".", "keys", "(", ")", ",", "key", "=", "lambda", "x", ":", "vocab", "[", "x", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "# Always insert UNK", "\n", "print", "(", "'inserting the special UNK token'", ")", "\n", "vocab", ".", "append", "(", "'UNK'", ")", "\n", "\n", "print", "(", "'Vocab size:'", ",", "len", "(", "vocab", ")", ")", "\n", "\n", "os", ".", "remove", "(", "all_captions", ".", "name", ")", "\n", "with", "open", "(", "codecs_output", ".", "name", ",", "'r'", ")", "as", "codes", ":", "\n", "    ", "bpe", "=", "codes", ".", "read", "(", ")", "\n", "", "os", ".", "remove", "(", "codecs_output", ".", "name", ")", "\n", "os", ".", "remove", "(", "tmp", ".", "name", ")", "\n", "\n", "return", "vocab", ",", "bpe", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.build_bpe_subword_nmt.encode_captions": [[106, 149], ["len", "sum", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.concatenate", "numpy.all", "print", "len", "numpy.zeros", "enumerate", "label_arrays.append", "len", "min", "enumerate", "len"], "function", ["None"], ["", "def", "encode_captions", "(", "imgs", ",", "params", ",", "wtoi", ")", ":", "\n", "  ", "\"\"\" \n  encode all captions into one large array, which will be 1-indexed.\n  also produces label_start_ix and label_end_ix which store 1-indexed \n  and inclusive (Lua-style) pointers to the first and last caption for\n  each image in the dataset.\n  \"\"\"", "\n", "\n", "max_length", "=", "params", "[", "'max_length'", "]", "\n", "N", "=", "len", "(", "imgs", ")", "\n", "M", "=", "sum", "(", "len", "(", "img", "[", "'final_captions'", "]", ")", "for", "img", "in", "imgs", ")", "# total number of captions", "\n", "\n", "label_arrays", "=", "[", "]", "\n", "label_start_ix", "=", "np", ".", "zeros", "(", "N", ",", "dtype", "=", "'uint32'", ")", "# note: these will be one-indexed", "\n", "label_end_ix", "=", "np", ".", "zeros", "(", "N", ",", "dtype", "=", "'uint32'", ")", "\n", "label_length", "=", "np", ".", "zeros", "(", "M", ",", "dtype", "=", "'uint32'", ")", "\n", "caption_counter", "=", "0", "\n", "counter", "=", "1", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "    ", "n", "=", "len", "(", "img", "[", "'final_captions'", "]", ")", "\n", "assert", "n", ">", "0", ",", "'error: some image has no captions'", "\n", "\n", "Li", "=", "np", ".", "zeros", "(", "(", "n", ",", "max_length", ")", ",", "dtype", "=", "'uint32'", ")", "\n", "for", "j", ",", "s", "in", "enumerate", "(", "img", "[", "'final_captions'", "]", ")", ":", "\n", "      ", "label_length", "[", "caption_counter", "]", "=", "min", "(", "max_length", ",", "len", "(", "s", ")", ")", "# record the length of this sequence", "\n", "caption_counter", "+=", "1", "\n", "for", "k", ",", "w", "in", "enumerate", "(", "s", ")", ":", "\n", "        ", "if", "k", "<", "max_length", ":", "\n", "          ", "Li", "[", "j", ",", "k", "]", "=", "wtoi", "[", "w", "]", "\n", "\n", "# note: word indices are 1-indexed, and captions are padded with zeros", "\n", "", "", "", "label_arrays", ".", "append", "(", "Li", ")", "\n", "label_start_ix", "[", "i", "]", "=", "counter", "\n", "label_end_ix", "[", "i", "]", "=", "counter", "+", "n", "-", "1", "\n", "\n", "counter", "+=", "n", "\n", "\n", "", "L", "=", "np", ".", "concatenate", "(", "label_arrays", ",", "axis", "=", "0", ")", "# put all the labels together", "\n", "assert", "L", ".", "shape", "[", "0", "]", "==", "M", ",", "'lengths don\\'t match? that\\'s weird'", "\n", "assert", "np", ".", "all", "(", "label_length", ">", "0", ")", ",", "'error: some caption had no words?'", "\n", "\n", "print", "(", "'encoded captions to array of size '", ",", "L", ".", "shape", ")", "\n", "return", "L", ",", "label_start_ix", ",", "label_end_ix", ",", "label_length", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.build_bpe_subword_nmt.main": [[150, 194], ["json.load", "random.seed", "build_bpe_subword_nmt.build_vocab", "build_bpe_subword_nmt.encode_captions", "len", "h5py.File", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.close", "enumerate", "json.dump", "print", "open", "out[].append", "open", "enumerate", "enumerate", "os.path.join", "PIL.Image.open", "os.path.join"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_labels.build_vocab", "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_labels.encode_captions"], ["", "def", "main", "(", "params", ")", ":", "\n", "\n", "  ", "imgs", "=", "json", ".", "load", "(", "open", "(", "params", "[", "'input_json'", "]", ",", "'r'", ")", ")", "\n", "imgs", "=", "imgs", "[", "'images'", "]", "\n", "\n", "seed", "(", "123", ")", "# make reproducible", "\n", "\n", "# create the vocab", "\n", "vocab", ",", "bpe", "=", "build_vocab", "(", "imgs", ",", "params", ")", "\n", "itow", "=", "{", "i", "+", "1", ":", "w", "for", "i", ",", "w", "in", "enumerate", "(", "vocab", ")", "}", "# a 1-indexed vocab translation table", "\n", "wtoi", "=", "{", "w", ":", "i", "+", "1", "for", "i", ",", "w", "in", "enumerate", "(", "vocab", ")", "}", "# inverse table", "\n", "\n", "# encode captions in large arrays, ready to ship to hdf5 file", "\n", "L", ",", "label_start_ix", ",", "label_end_ix", ",", "label_length", "=", "encode_captions", "(", "imgs", ",", "params", ",", "wtoi", ")", "\n", "\n", "# create output h5 file", "\n", "N", "=", "len", "(", "imgs", ")", "\n", "f_lb", "=", "h5py", ".", "File", "(", "params", "[", "'output_h5'", "]", "+", "'_label.h5'", ",", "\"w\"", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"labels\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "L", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"label_start_ix\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "label_start_ix", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"label_end_ix\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "label_end_ix", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"label_length\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "label_length", ")", "\n", "f_lb", ".", "close", "(", ")", "\n", "\n", "# create output json file", "\n", "out", "=", "{", "}", "\n", "out", "[", "'ix_to_word'", "]", "=", "itow", "# encode the (1-indexed) vocab", "\n", "out", "[", "'images'", "]", "=", "[", "]", "\n", "out", "[", "'bpe'", "]", "=", "bpe", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "\n", "    ", "jimg", "=", "{", "}", "\n", "jimg", "[", "'split'", "]", "=", "img", "[", "'split'", "]", "\n", "if", "'filename'", "in", "img", ":", "jimg", "[", "'file_path'", "]", "=", "os", ".", "path", ".", "join", "(", "img", "[", "'filepath'", "]", ",", "img", "[", "'filename'", "]", ")", "# copy it over, might need", "\n", "if", "'cocoid'", "in", "img", ":", "jimg", "[", "'id'", "]", "=", "img", "[", "'cocoid'", "]", "# copy over & mantain an id, if present (e.g. coco ids, useful)", "\n", "\n", "if", "params", "[", "'images_root'", "]", "!=", "''", ":", "\n", "      ", "with", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "params", "[", "'images_root'", "]", ",", "img", "[", "'filepath'", "]", ",", "img", "[", "'filename'", "]", ")", ")", "as", "_img", ":", "\n", "        ", "jimg", "[", "'width'", "]", ",", "jimg", "[", "'height'", "]", "=", "_img", ".", "size", "\n", "\n", "", "", "out", "[", "'images'", "]", ".", "append", "(", "jimg", ")", "\n", "\n", "", "json", ".", "dump", "(", "out", ",", "open", "(", "params", "[", "'output_json'", "]", ",", "'w'", ")", ")", "\n", "print", "(", "'wrote '", ",", "params", "[", "'output_json'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_labels.build_vocab": [[43, 94], ["sorted", "print", "print", "sum", "print", "sum", "print", "print", "print", "max", "print", "print", "sum", "range", "counts.values", "sent_lengths.keys", "sent_lengths.values", "print", "print", "vocab.append", "map", "counts.items", "counts.items", "len", "img[].append", "counts.items", "len", "len", "len", "sent_lengths.get", "counts.get", "len", "sent_lengths.get", "len", "counts.get", "sent_lengths.get"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get"], ["def", "build_vocab", "(", "imgs", ",", "params", ")", ":", "\n", "  ", "count_thr", "=", "params", "[", "'word_count_threshold'", "]", "\n", "\n", "# count up the number of words", "\n", "counts", "=", "{", "}", "\n", "for", "img", "in", "imgs", ":", "\n", "    ", "for", "sent", "in", "img", "[", "'sentences'", "]", ":", "\n", "      ", "for", "w", "in", "sent", "[", "'tokens'", "]", ":", "\n", "        ", "counts", "[", "w", "]", "=", "counts", ".", "get", "(", "w", ",", "0", ")", "+", "1", "\n", "", "", "", "cw", "=", "sorted", "(", "[", "(", "count", ",", "w", ")", "for", "w", ",", "count", "in", "counts", ".", "items", "(", ")", "]", ",", "reverse", "=", "True", ")", "\n", "print", "(", "'top words and their counts:'", ")", "\n", "print", "(", "'\\n'", ".", "join", "(", "map", "(", "str", ",", "cw", "[", ":", "20", "]", ")", ")", ")", "\n", "\n", "# print some stats", "\n", "total_words", "=", "sum", "(", "counts", ".", "values", "(", ")", ")", "\n", "print", "(", "'total words:'", ",", "total_words", ")", "\n", "bad_words", "=", "[", "w", "for", "w", ",", "n", "in", "counts", ".", "items", "(", ")", "if", "n", "<=", "count_thr", "]", "\n", "vocab", "=", "[", "w", "for", "w", ",", "n", "in", "counts", ".", "items", "(", ")", "if", "n", ">", "count_thr", "]", "\n", "bad_count", "=", "sum", "(", "counts", "[", "w", "]", "for", "w", "in", "bad_words", ")", "\n", "print", "(", "'number of bad words: %d/%d = %.2f%%'", "%", "(", "len", "(", "bad_words", ")", ",", "len", "(", "counts", ")", ",", "len", "(", "bad_words", ")", "*", "100.0", "/", "len", "(", "counts", ")", ")", ")", "\n", "print", "(", "'number of words in vocab would be %d'", "%", "(", "len", "(", "vocab", ")", ",", ")", ")", "\n", "print", "(", "'number of UNKs: %d/%d = %.2f%%'", "%", "(", "bad_count", ",", "total_words", ",", "bad_count", "*", "100.0", "/", "total_words", ")", ")", "\n", "\n", "# lets look at the distribution of lengths as well", "\n", "sent_lengths", "=", "{", "}", "\n", "for", "img", "in", "imgs", ":", "\n", "    ", "for", "sent", "in", "img", "[", "'sentences'", "]", ":", "\n", "      ", "txt", "=", "sent", "[", "'tokens'", "]", "\n", "nw", "=", "len", "(", "txt", ")", "\n", "sent_lengths", "[", "nw", "]", "=", "sent_lengths", ".", "get", "(", "nw", ",", "0", ")", "+", "1", "\n", "", "", "max_len", "=", "max", "(", "sent_lengths", ".", "keys", "(", ")", ")", "\n", "print", "(", "'max length sentence in raw data: '", ",", "max_len", ")", "\n", "print", "(", "'sentence length distribution (count, number of words):'", ")", "\n", "sum_len", "=", "sum", "(", "sent_lengths", ".", "values", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "max_len", "+", "1", ")", ":", "\n", "    ", "print", "(", "'%2d: %10d   %f%%'", "%", "(", "i", ",", "sent_lengths", ".", "get", "(", "i", ",", "0", ")", ",", "sent_lengths", ".", "get", "(", "i", ",", "0", ")", "*", "100.0", "/", "sum_len", ")", ")", "\n", "\n", "# lets now produce the final annotations", "\n", "", "if", "bad_count", ">", "0", ":", "\n", "# additional special UNK token we will use below to map infrequent words to", "\n", "    ", "print", "(", "'inserting the special UNK token'", ")", "\n", "vocab", ".", "append", "(", "'UNK'", ")", "\n", "\n", "", "for", "img", "in", "imgs", ":", "\n", "    ", "img", "[", "'final_captions'", "]", "=", "[", "]", "\n", "for", "sent", "in", "img", "[", "'sentences'", "]", ":", "\n", "      ", "txt", "=", "sent", "[", "'tokens'", "]", "\n", "caption", "=", "[", "w", "if", "counts", ".", "get", "(", "w", ",", "0", ")", ">", "count_thr", "else", "'UNK'", "for", "w", "in", "txt", "]", "\n", "img", "[", "'final_captions'", "]", ".", "append", "(", "caption", ")", "\n", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_labels.encode_captions": [[95, 138], ["len", "sum", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.concatenate", "numpy.all", "print", "len", "numpy.zeros", "enumerate", "label_arrays.append", "len", "min", "enumerate", "len"], "function", ["None"], ["", "def", "encode_captions", "(", "imgs", ",", "params", ",", "wtoi", ")", ":", "\n", "  ", "\"\"\" \n  encode all captions into one large array, which will be 1-indexed.\n  also produces label_start_ix and label_end_ix which store 1-indexed \n  and inclusive (Lua-style) pointers to the first and last caption for\n  each image in the dataset.\n  \"\"\"", "\n", "\n", "max_length", "=", "params", "[", "'max_length'", "]", "\n", "N", "=", "len", "(", "imgs", ")", "\n", "M", "=", "sum", "(", "len", "(", "img", "[", "'final_captions'", "]", ")", "for", "img", "in", "imgs", ")", "# total number of captions", "\n", "\n", "label_arrays", "=", "[", "]", "\n", "label_start_ix", "=", "np", ".", "zeros", "(", "N", ",", "dtype", "=", "'uint32'", ")", "# note: these will be one-indexed", "\n", "label_end_ix", "=", "np", ".", "zeros", "(", "N", ",", "dtype", "=", "'uint32'", ")", "\n", "label_length", "=", "np", ".", "zeros", "(", "M", ",", "dtype", "=", "'uint32'", ")", "\n", "caption_counter", "=", "0", "\n", "counter", "=", "1", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "    ", "n", "=", "len", "(", "img", "[", "'final_captions'", "]", ")", "\n", "assert", "n", ">", "0", ",", "'error: some image has no captions'", "\n", "\n", "Li", "=", "np", ".", "zeros", "(", "(", "n", ",", "max_length", ")", ",", "dtype", "=", "'uint32'", ")", "\n", "for", "j", ",", "s", "in", "enumerate", "(", "img", "[", "'final_captions'", "]", ")", ":", "\n", "      ", "label_length", "[", "caption_counter", "]", "=", "min", "(", "max_length", ",", "len", "(", "s", ")", ")", "# record the length of this sequence", "\n", "caption_counter", "+=", "1", "\n", "for", "k", ",", "w", "in", "enumerate", "(", "s", ")", ":", "\n", "        ", "if", "k", "<", "max_length", ":", "\n", "          ", "Li", "[", "j", ",", "k", "]", "=", "wtoi", "[", "w", "]", "\n", "\n", "# note: word indices are 1-indexed, and captions are padded with zeros", "\n", "", "", "", "label_arrays", ".", "append", "(", "Li", ")", "\n", "label_start_ix", "[", "i", "]", "=", "counter", "\n", "label_end_ix", "[", "i", "]", "=", "counter", "+", "n", "-", "1", "\n", "\n", "counter", "+=", "n", "\n", "\n", "", "L", "=", "np", ".", "concatenate", "(", "label_arrays", ",", "axis", "=", "0", ")", "# put all the labels together", "\n", "assert", "L", ".", "shape", "[", "0", "]", "==", "M", ",", "'lengths don\\'t match? that\\'s weird'", "\n", "assert", "np", ".", "all", "(", "label_length", ">", "0", ")", ",", "'error: some caption had no words?'", "\n", "\n", "print", "(", "'encoded captions to array of size '", ",", "L", ".", "shape", ")", "\n", "return", "L", ",", "label_start_ix", ",", "label_end_ix", ",", "label_length", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_labels.main": [[139, 185], ["json.load", "random.seed", "prepro_labels.build_vocab", "prepro_labels.encode_captions", "len", "h5py.File", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.close", "enumerate", "json.dump", "print", "open", "out[].append", "open", "enumerate", "enumerate", "os.path.join", "img.get", "PIL.Image.open", "os.path.join"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_labels.build_vocab", "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_labels.encode_captions", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get"], ["", "def", "main", "(", "params", ")", ":", "\n", "\n", "  ", "imgs", "=", "json", ".", "load", "(", "open", "(", "params", "[", "'input_json'", "]", ",", "'r'", ")", ")", "\n", "imgs", "=", "imgs", "[", "'images'", "]", "\n", "\n", "seed", "(", "123", ")", "# make reproducible", "\n", "\n", "# create the vocab", "\n", "vocab", "=", "build_vocab", "(", "imgs", ",", "params", ")", "\n", "itow", "=", "{", "i", "+", "1", ":", "w", "for", "i", ",", "w", "in", "enumerate", "(", "vocab", ")", "}", "# a 1-indexed vocab translation table", "\n", "wtoi", "=", "{", "w", ":", "i", "+", "1", "for", "i", ",", "w", "in", "enumerate", "(", "vocab", ")", "}", "# inverse table", "\n", "\n", "# encode captions in large arrays, ready to ship to hdf5 file", "\n", "L", ",", "label_start_ix", ",", "label_end_ix", ",", "label_length", "=", "encode_captions", "(", "imgs", ",", "params", ",", "wtoi", ")", "\n", "\n", "# create output h5 file", "\n", "N", "=", "len", "(", "imgs", ")", "\n", "f_lb", "=", "h5py", ".", "File", "(", "params", "[", "'output_h5'", "]", "+", "'_label.h5'", ",", "\"w\"", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"labels\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "L", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"label_start_ix\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "label_start_ix", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"label_end_ix\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "label_end_ix", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"label_length\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "label_length", ")", "\n", "f_lb", ".", "close", "(", ")", "\n", "\n", "# create output json file", "\n", "out", "=", "{", "}", "\n", "out", "[", "'ix_to_word'", "]", "=", "itow", "# encode the (1-indexed) vocab", "\n", "out", "[", "'images'", "]", "=", "[", "]", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "\n", "    ", "jimg", "=", "{", "}", "\n", "jimg", "[", "'split'", "]", "=", "img", "[", "'split'", "]", "\n", "if", "'filename'", "in", "img", ":", "jimg", "[", "'file_path'", "]", "=", "os", ".", "path", ".", "join", "(", "img", ".", "get", "(", "'filepath'", ",", "''", ")", ",", "img", "[", "'filename'", "]", ")", "# copy it over, might need", "\n", "if", "'cocoid'", "in", "img", ":", "\n", "      ", "jimg", "[", "'id'", "]", "=", "img", "[", "'cocoid'", "]", "# copy over & mantain an id, if present (e.g. coco ids, useful)", "\n", "", "elif", "'imgid'", "in", "img", ":", "\n", "      ", "jimg", "[", "'id'", "]", "=", "img", "[", "'imgid'", "]", "\n", "\n", "", "if", "params", "[", "'images_root'", "]", "!=", "''", ":", "\n", "      ", "with", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "params", "[", "'images_root'", "]", ",", "img", "[", "'filepath'", "]", ",", "img", "[", "'filename'", "]", ")", ")", "as", "_img", ":", "\n", "        ", "jimg", "[", "'width'", "]", ",", "jimg", "[", "'height'", "]", "=", "_img", ".", "size", "\n", "\n", "", "", "out", "[", "'images'", "]", ".", "append", "(", "jimg", ")", "\n", "\n", "", "json", ".", "dump", "(", "out", ",", "open", "(", "params", "[", "'output_json'", "]", ",", "'w'", ")", ")", "\n", "print", "(", "'wrote '", ",", "params", "[", "'output_json'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.scripts.prepro_feats.main": [[52, 92], ["net.load_state_dict", "misc.resnet_utils.myResnet", "misc.resnet_utils.myResnet.cuda", "misc.resnet_utils.myResnet.eval", "json.load", "len", "random.seed", "enumerate", "print", "getattr", "torch.load", "open", "os.path.isdir", "os.mkdir", "os.path.isdir", "os.mkdir", "skimage.io.imread", "torch.from_numpy().cuda", "preprocess", "numpy.save", "numpy.savez_compressed", "os.path.join", "os.path.join", "len", "numpy.concatenate", "np.concatenate.astype", "torch.no_grad", "misc.resnet_utils.myResnet.", "os.path.join", "tmp_fc.data.cpu().float().numpy", "os.path.join", "print", "torch.from_numpy", "str", "str", "tmp_att.data.cpu().float().numpy", "np.concatenate.transpose", "tmp_fc.data.cpu().float", "tmp_att.data.cpu().float", "tmp_fc.data.cpu", "tmp_att.data.cpu"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.load_state_dict"], ["def", "main", "(", "params", ")", ":", "\n", "  ", "net", "=", "getattr", "(", "resnet", ",", "params", "[", "'model'", "]", ")", "(", ")", "\n", "net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "params", "[", "'model_root'", "]", ",", "params", "[", "'model'", "]", "+", "'.pth'", ")", ")", ")", "\n", "my_resnet", "=", "myResnet", "(", "net", ")", "\n", "my_resnet", ".", "cuda", "(", ")", "\n", "my_resnet", ".", "eval", "(", ")", "\n", "\n", "imgs", "=", "json", ".", "load", "(", "open", "(", "params", "[", "'input_json'", "]", ",", "'r'", ")", ")", "\n", "imgs", "=", "imgs", "[", "'images'", "]", "\n", "N", "=", "len", "(", "imgs", ")", "\n", "\n", "seed", "(", "123", ")", "# make reproducible", "\n", "\n", "dir_fc", "=", "params", "[", "'output_dir'", "]", "+", "'_fc'", "\n", "dir_att", "=", "params", "[", "'output_dir'", "]", "+", "'_att'", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "dir_fc", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "dir_fc", ")", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "dir_att", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "dir_att", ")", "\n", "\n", "", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "# load the image", "\n", "    ", "I", "=", "skimage", ".", "io", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "params", "[", "'images_root'", "]", ",", "img", "[", "'filepath'", "]", ",", "img", "[", "'filename'", "]", ")", ")", "\n", "# handle grayscale input images", "\n", "if", "len", "(", "I", ".", "shape", ")", "==", "2", ":", "\n", "      ", "I", "=", "I", "[", ":", ",", ":", ",", "np", ".", "newaxis", "]", "\n", "I", "=", "np", ".", "concatenate", "(", "(", "I", ",", "I", ",", "I", ")", ",", "axis", "=", "2", ")", "\n", "\n", "", "I", "=", "I", ".", "astype", "(", "'float32'", ")", "/", "255.0", "\n", "I", "=", "torch", ".", "from_numpy", "(", "I", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ")", ".", "cuda", "(", ")", "\n", "I", "=", "preprocess", "(", "I", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "      ", "tmp_fc", ",", "tmp_att", "=", "my_resnet", "(", "I", ",", "params", "[", "'att_size'", "]", ")", "\n", "# write to pkl", "\n", "", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "dir_fc", ",", "str", "(", "img", "[", "'cocoid'", "]", ")", ")", ",", "tmp_fc", ".", "data", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", ")", "\n", "np", ".", "savez_compressed", "(", "os", ".", "path", ".", "join", "(", "dir_att", ",", "str", "(", "img", "[", "'cocoid'", "]", ")", ")", ",", "feat", "=", "tmp_att", ".", "data", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "if", "i", "%", "1000", "==", "0", ":", "\n", "      ", "print", "(", "'processing %d/%d (%.2f%% done)'", "%", "(", "i", ",", "N", ",", "i", "*", "100.0", "/", "N", ")", ")", "\n", "", "", "print", "(", "'wrote '", ",", "params", "[", "'output_dir'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AttModel.__init__": [[52, 93], ["CaptionModel.CaptionModel.__init__", "getattr", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "getattr", "torch.Linear", "torch.Linear", "torch.Linear", "getattr", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "int", "AttModel.AttModel.vocab.items", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "range", "reduce", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AttModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_size", "=", "opt", ".", "vocab_size", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "#self.rnn_type = opt.rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "num_layers", "=", "opt", ".", "num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "seq_length", "=", "getattr", "(", "opt", ",", "'max_length'", ",", "20", ")", "or", "opt", ".", "seq_length", "# maximum sample length", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "self", ".", "att_feat_size", "=", "opt", ".", "att_feat_size", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "\n", "self", ".", "use_bn", "=", "getattr", "(", "opt", ",", "'use_bn'", ",", "0", ")", "\n", "\n", "self", ".", "ss_prob", "=", "0.0", "# Schedule sampling probability", "\n", "\n", "self", ".", "embed", "=", "nn", ".", "Sequential", "(", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", "+", "1", ",", "self", ".", "input_encoding_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", ")", "\n", "self", ".", "fc_embed", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "fc_feat_size", ",", "self", ".", "rnn_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", ")", "\n", "self", ".", "att_embed", "=", "nn", ".", "Sequential", "(", "*", "(", "\n", "(", "(", "nn", ".", "BatchNorm1d", "(", "self", ".", "att_feat_size", ")", ",", ")", "if", "self", ".", "use_bn", "else", "(", ")", ")", "+", "\n", "(", "nn", ".", "Linear", "(", "self", ".", "att_feat_size", ",", "self", ".", "rnn_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", ")", "+", "\n", "(", "(", "nn", ".", "BatchNorm1d", "(", "self", ".", "rnn_size", ")", ",", ")", "if", "self", ".", "use_bn", "==", "2", "else", "(", ")", ")", ")", ")", "\n", "\n", "self", ".", "logit_layers", "=", "getattr", "(", "opt", ",", "'logit_layers'", ",", "1", ")", "\n", "if", "self", ".", "logit_layers", "==", "1", ":", "\n", "            ", "self", ".", "logit", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "vocab_size", "+", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "logit", "=", "[", "[", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Dropout", "(", "0.5", ")", "]", "for", "_", "in", "range", "(", "opt", ".", "logit_layers", "-", "1", ")", "]", "\n", "self", ".", "logit", "=", "nn", ".", "Sequential", "(", "*", "(", "reduce", "(", "lambda", "x", ",", "y", ":", "x", "+", "y", ",", "self", ".", "logit", ")", "+", "[", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "vocab_size", "+", "1", ")", "]", ")", ")", "\n", "", "self", ".", "ctx2att", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "att_hid_size", ")", "\n", "\n", "# For remove bad endding", "\n", "self", ".", "vocab", "=", "opt", ".", "vocab", "\n", "self", ".", "bad_endings_ix", "=", "[", "int", "(", "k", ")", "for", "k", ",", "v", "in", "self", ".", "vocab", ".", "items", "(", ")", "if", "v", "in", "bad_endings", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AttModel.init_hidden": [[94, 98], ["next", "AttModel.AttModel.parameters", "next.new_zeros", "next.new_zeros"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "weight", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "return", "(", "weight", ".", "new_zeros", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ",", "\n", "weight", ".", "new_zeros", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AttModel.clip_att": [[99, 106], ["att_masks[].contiguous.data.long().sum().max", "att_feats[].contiguous", "att_masks[].contiguous", "att_masks[].contiguous.data.long().sum", "att_masks[].contiguous.data.long"], "methods", ["None"], ["", "def", "clip_att", "(", "self", ",", "att_feats", ",", "att_masks", ")", ":", "\n", "# Clip the length of att_masks and att_feats to the maximum length", "\n", "        ", "if", "att_masks", "is", "not", "None", ":", "\n", "            ", "max_len", "=", "att_masks", ".", "data", ".", "long", "(", ")", ".", "sum", "(", "1", ")", ".", "max", "(", ")", "\n", "att_feats", "=", "att_feats", "[", ":", ",", ":", "max_len", "]", ".", "contiguous", "(", ")", "\n", "att_masks", "=", "att_masks", "[", ":", ",", ":", "max_len", "]", ".", "contiguous", "(", ")", "\n", "", "return", "att_feats", ",", "att_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AttModel._prepare_feature": [[107, 118], ["AttModel.AttModel.clip_att", "AttModel.AttModel.fc_embed", "AttModel.pack_wrapper", "AttModel.AttModel.ctx2att"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AttModel.clip_att", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.pack_wrapper"], ["", "def", "_prepare_feature", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "att_masks", ")", ":", "\n", "        ", "att_feats", ",", "att_masks", "=", "self", ".", "clip_att", "(", "att_feats", ",", "att_masks", ")", "\n", "\n", "# embed fc and att feats", "\n", "fc_feats", "=", "self", ".", "fc_embed", "(", "fc_feats", ")", "\n", "att_feats", "=", "pack_wrapper", "(", "self", ".", "att_embed", ",", "att_feats", ",", "att_masks", ")", "\n", "\n", "# Project the attention feats first to reduce memory and computation comsumptions.", "\n", "p_att_feats", "=", "self", ".", "ctx2att", "(", "att_feats", ")", "\n", "\n", "return", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AttModel._forward": [[119, 153], ["fc_feats.size", "AttModel.AttModel.init_hidden", "fc_feats.new_zeros", "AttModel.AttModel._prepare_feature", "range", "AttModel.AttModel.get_logprobs_state", "seq.size", "seq.size", "fc_feats.new().uniform_", "seq[].clone", "sample_mask.sum", "seq[].clone", "sample_mask.nonzero().view", "seq[].data.clone", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "seq[].data.clone.index_copy_", "seq[].sum", "fc_feats.new", "outputs[].detach", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "sample_mask.nonzero", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble._prepare_feature", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.get_logprobs_state"], ["", "def", "_forward", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "seq", ",", "att_masks", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "\n", "outputs", "=", "fc_feats", ".", "new_zeros", "(", "batch_size", ",", "seq", ".", "size", "(", "1", ")", "-", "1", ",", "self", ".", "vocab_size", "+", "1", ")", "\n", "\n", "# Prepare the features", "\n", "p_fc_feats", ",", "p_att_feats", ",", "pp_att_feats", ",", "p_att_masks", "=", "self", ".", "_prepare_feature", "(", "fc_feats", ",", "att_feats", ",", "att_masks", ")", "\n", "# pp_att_feats is used for attention, we cache it in advance to reduce computation cost", "\n", "\n", "for", "i", "in", "range", "(", "seq", ".", "size", "(", "1", ")", "-", "1", ")", ":", "\n", "            ", "if", "self", ".", "training", "and", "i", ">=", "1", "and", "self", ".", "ss_prob", ">", "0.0", ":", "# otherwiste no need to sample", "\n", "                ", "sample_prob", "=", "fc_feats", ".", "new", "(", "batch_size", ")", ".", "uniform_", "(", "0", ",", "1", ")", "\n", "sample_mask", "=", "sample_prob", "<", "self", ".", "ss_prob", "\n", "if", "sample_mask", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                    ", "sample_ind", "=", "sample_mask", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "data", ".", "clone", "(", ")", "\n", "#prob_prev = torch.exp(outputs[-1].data.index_select(0, sample_ind)) # fetch prev distribution: shape Nx(M+1)", "\n", "#it.index_copy_(0, sample_ind, torch.multinomial(prob_prev, 1).view(-1))", "\n", "# prob_prev = torch.exp(outputs[-1].data) # fetch prev distribution: shape Nx(M+1)", "\n", "prob_prev", "=", "torch", ".", "exp", "(", "outputs", "[", ":", ",", "i", "-", "1", "]", ".", "detach", "(", ")", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "it", ".", "index_copy_", "(", "0", ",", "sample_ind", ",", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "view", "(", "-", "1", ")", ".", "index_select", "(", "0", ",", "sample_ind", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "clone", "(", ")", "\n", "# break if all the sequences end", "\n", "", "if", "i", ">=", "1", "and", "seq", "[", ":", ",", "i", "]", ".", "sum", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "get_logprobs_state", "(", "it", ",", "p_fc_feats", ",", "p_att_feats", ",", "pp_att_feats", ",", "p_att_masks", ",", "state", ")", "\n", "outputs", "[", ":", ",", "i", "]", "=", "output", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AttModel.get_logprobs_state": [[154, 162], ["AttModel.AttModel.embed", "AttModel.AttModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "AttModel.AttModel.logit"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.logit"], ["", "def", "get_logprobs_state", "(", "self", ",", "it", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", ",", "state", ")", ":", "\n", "# 'it' contains a word index", "\n", "        ", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ",", "att_masks", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ",", "dim", "=", "1", ")", "\n", "\n", "return", "logprobs", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AttModel._sample_beam": [[163, 193], ["opt.get", "fc_feats.size", "AttModel.AttModel._prepare_feature", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "range", "AttModel.AttModel.init_hidden", "p_fc_feats[].expand", "p_att_feats[].expand().contiguous", "pp_att_feats[].expand().contiguous", "range", "AttModel.AttModel.beam_search", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "p_fc_feats.size", "p_att_masks[].expand().contiguous", "AttModel.AttModel.get_logprobs_state", "p_att_feats[].expand", "pp_att_feats[].expand", "fc_feats.new_zeros", "p_att_masks[].expand", "p_att_feats.size", "pp_att_feats.size", "p_att_masks.size"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble._prepare_feature", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.husthuaan_AAT.models.CaptionModel.CaptionModel.beam_search", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.get_logprobs_state"], ["", "def", "_sample_beam", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "att_masks", "=", "None", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "10", ")", "\n", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "\n", "p_fc_feats", ",", "p_att_feats", ",", "pp_att_feats", ",", "p_att_masks", "=", "self", ".", "_prepare_feature", "(", "fc_feats", ",", "att_feats", ",", "att_masks", ")", "\n", "\n", "assert", "beam_size", "<=", "self", ".", "vocab_size", "+", "1", ",", "'lets assume this for now, otherwise this corner case causes a few headaches down the road. can be dealt with in future if needed'", "\n", "seq", "=", "torch", ".", "LongTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", ".", "zero_", "(", ")", "\n", "seqLogprobs", "=", "torch", ".", "FloatTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", "\n", "# lets process every image independently for now, for simplicity", "\n", "\n", "self", ".", "done_beams", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "for", "k", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "state", "=", "self", ".", "init_hidden", "(", "beam_size", ")", "\n", "tmp_fc_feats", "=", "p_fc_feats", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "beam_size", ",", "p_fc_feats", ".", "size", "(", "1", ")", ")", "\n", "tmp_att_feats", "=", "p_att_feats", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "*", "(", "(", "beam_size", ",", ")", "+", "p_att_feats", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", "\n", "tmp_p_att_feats", "=", "pp_att_feats", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "*", "(", "(", "beam_size", ",", ")", "+", "pp_att_feats", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", "\n", "tmp_att_masks", "=", "p_att_masks", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "*", "(", "(", "beam_size", ",", ")", "+", "p_att_masks", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", "if", "att_masks", "is", "not", "None", "else", "None", "\n", "\n", "for", "t", "in", "range", "(", "1", ")", ":", "\n", "                ", "if", "t", "==", "0", ":", "# input <bos>", "\n", "                    ", "it", "=", "fc_feats", ".", "new_zeros", "(", "[", "beam_size", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "", "logprobs", ",", "state", "=", "self", ".", "get_logprobs_state", "(", "it", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "tmp_p_att_feats", ",", "tmp_att_masks", ",", "state", ")", "\n", "\n", "", "self", ".", "done_beams", "[", "k", "]", "=", "self", ".", "beam_search", "(", "state", ",", "logprobs", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "tmp_p_att_feats", ",", "tmp_att_masks", ",", "opt", "=", "opt", ")", "\n", "seq", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'seq'", "]", "# the first beam has highest cumulative score", "\n", "seqLogprobs", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'logps'", "]", "\n", "# return the samples and their log likelihoods", "\n", "", "return", "seq", ".", "transpose", "(", "0", ",", "1", ")", ",", "seqLogprobs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AttModel._sample": [[194, 277], ["opt.get", "opt.get", "opt.get", "opt.get", "opt.get", "opt.get", "fc_feats.size", "AttModel.AttModel.init_hidden", "AttModel.AttModel._prepare_feature", "fc_feats.new_zeros", "fc_feats.new_zeros", "range", "AttModel.AttModel._sample_beam", "AttModel.AttModel.get_logprobs_state", "AttModel.AttModel.sample_next_word", "sampleLogprobs.view", "fc_feats.new_zeros", "logprobs.new_zeros", "logprobs.new_zeros.scatter_", "logprobs.new_zeros", "numpy.isin", "float", "range", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "range", "unfinished.type_as", "unfinished.sum", "logprobs.size", "seq[].data.unsqueeze", "float", "logprobs.size", "seq[].data.cpu().numpy", "[].item", "[].item", "trigrams.append", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "[].item", "[].item", "seq[].data.cpu", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "logprobs.size", "numpy.isin.astype", "[].append"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble._prepare_feature", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel._sample_beam", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.get_logprobs_state", "home.repos.pwc.inspect_result.husthuaan_AAT.models.CaptionModel.CaptionModel.sample_next_word"], ["", "def", "_sample", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "att_masks", "=", "None", ",", "opt", "=", "{", "}", ")", ":", "\n", "\n", "        ", "sample_method", "=", "opt", ".", "get", "(", "'sample_method'", ",", "'greedy'", ")", "\n", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "1", ")", "\n", "temperature", "=", "opt", ".", "get", "(", "'temperature'", ",", "1.0", ")", "\n", "decoding_constraint", "=", "opt", ".", "get", "(", "'decoding_constraint'", ",", "0", ")", "\n", "block_trigrams", "=", "opt", ".", "get", "(", "'block_trigrams'", ",", "0", ")", "\n", "remove_bad_endings", "=", "opt", ".", "get", "(", "'remove_bad_endings'", ",", "0", ")", "\n", "if", "beam_size", ">", "1", ":", "\n", "            ", "return", "self", ".", "_sample_beam", "(", "fc_feats", ",", "att_feats", ",", "att_masks", ",", "opt", ")", "\n", "\n", "", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "\n", "p_fc_feats", ",", "p_att_feats", ",", "pp_att_feats", ",", "p_att_masks", "=", "self", ".", "_prepare_feature", "(", "fc_feats", ",", "att_feats", ",", "att_masks", ")", "\n", "\n", "trigrams", "=", "[", "]", "# will be a list of batch_size dictionaries", "\n", "\n", "seq", "=", "fc_feats", ".", "new_zeros", "(", "(", "batch_size", ",", "self", ".", "seq_length", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "seqLogprobs", "=", "fc_feats", ".", "new_zeros", "(", "batch_size", ",", "self", ".", "seq_length", ")", "\n", "for", "t", "in", "range", "(", "self", ".", "seq_length", "+", "1", ")", ":", "\n", "            ", "if", "t", "==", "0", ":", "# input <bos>", "\n", "                ", "it", "=", "fc_feats", ".", "new_zeros", "(", "batch_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "", "logprobs", ",", "state", "=", "self", ".", "get_logprobs_state", "(", "it", ",", "p_fc_feats", ",", "p_att_feats", ",", "pp_att_feats", ",", "p_att_masks", ",", "state", ")", "\n", "\n", "if", "decoding_constraint", "and", "t", ">", "0", ":", "\n", "                ", "tmp", "=", "logprobs", ".", "new_zeros", "(", "logprobs", ".", "size", "(", ")", ")", "\n", "tmp", ".", "scatter_", "(", "1", ",", "seq", "[", ":", ",", "t", "-", "1", "]", ".", "data", ".", "unsqueeze", "(", "1", ")", ",", "float", "(", "'-inf'", ")", ")", "\n", "logprobs", "=", "logprobs", "+", "tmp", "\n", "\n", "", "if", "remove_bad_endings", "and", "t", ">", "0", ":", "\n", "                ", "tmp", "=", "logprobs", ".", "new_zeros", "(", "logprobs", ".", "size", "(", ")", ")", "\n", "prev_bad", "=", "np", ".", "isin", "(", "seq", "[", ":", ",", "t", "-", "1", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "self", ".", "bad_endings_ix", ")", "\n", "# Impossible to generate remove_bad_endings", "\n", "tmp", "[", "torch", ".", "from_numpy", "(", "prev_bad", ".", "astype", "(", "'uint8'", ")", ")", ",", "0", "]", "=", "float", "(", "'-inf'", ")", "\n", "logprobs", "=", "logprobs", "+", "tmp", "\n", "\n", "# Mess with trigrams", "\n", "", "if", "block_trigrams", "and", "t", ">=", "3", ":", "\n", "# Store trigram generated at last step", "\n", "                ", "prev_two_batch", "=", "seq", "[", ":", ",", "t", "-", "3", ":", "t", "-", "1", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "# = seq.size(0)", "\n", "                    ", "prev_two", "=", "(", "prev_two_batch", "[", "i", "]", "[", "0", "]", ".", "item", "(", ")", ",", "prev_two_batch", "[", "i", "]", "[", "1", "]", ".", "item", "(", ")", ")", "\n", "current", "=", "seq", "[", "i", "]", "[", "t", "-", "1", "]", "\n", "if", "t", "==", "3", ":", "# initialize", "\n", "                        ", "trigrams", ".", "append", "(", "{", "prev_two", ":", "[", "current", "]", "}", ")", "# {LongTensor: list containing 1 int}", "\n", "", "elif", "t", ">", "3", ":", "\n", "                        ", "if", "prev_two", "in", "trigrams", "[", "i", "]", ":", "# add to list", "\n", "                            ", "trigrams", "[", "i", "]", "[", "prev_two", "]", ".", "append", "(", "current", ")", "\n", "", "else", ":", "# create list", "\n", "                            ", "trigrams", "[", "i", "]", "[", "prev_two", "]", "=", "[", "current", "]", "\n", "# Block used trigrams at next step", "\n", "", "", "", "prev_two_batch", "=", "seq", "[", ":", ",", "t", "-", "2", ":", "t", "]", "\n", "mask", "=", "torch", ".", "zeros", "(", "logprobs", ".", "size", "(", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "# batch_size x vocab_size", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "prev_two", "=", "(", "prev_two_batch", "[", "i", "]", "[", "0", "]", ".", "item", "(", ")", ",", "prev_two_batch", "[", "i", "]", "[", "1", "]", ".", "item", "(", ")", ")", "\n", "if", "prev_two", "in", "trigrams", "[", "i", "]", ":", "\n", "                        ", "for", "j", "in", "trigrams", "[", "i", "]", "[", "prev_two", "]", ":", "\n", "                            ", "mask", "[", "i", ",", "j", "]", "+=", "1", "\n", "# Apply mask to log probs", "\n", "#logprobs = logprobs - (mask * 1e9)", "\n", "", "", "", "alpha", "=", "2.0", "# = 4", "\n", "logprobs", "=", "logprobs", "+", "(", "mask", "*", "-", "0.693", "*", "alpha", ")", "# ln(1/2) * alpha (alpha -> infty works best)", "\n", "\n", "# sample the next word", "\n", "", "if", "t", "==", "self", ".", "seq_length", ":", "# skip if we achieve maximum length", "\n", "                ", "break", "\n", "", "it", ",", "sampleLogprobs", "=", "self", ".", "sample_next_word", "(", "logprobs", ",", "sample_method", ",", "temperature", ")", "\n", "\n", "# stop when all finished", "\n", "if", "t", "==", "0", ":", "\n", "                ", "unfinished", "=", "it", ">", "0", "\n", "", "else", ":", "\n", "                ", "unfinished", "=", "unfinished", "*", "(", "it", ">", "0", ")", "\n", "", "it", "=", "it", "*", "unfinished", ".", "type_as", "(", "it", ")", "\n", "seq", "[", ":", ",", "t", "]", "=", "it", "\n", "seqLogprobs", "[", ":", ",", "t", "]", "=", "sampleLogprobs", ".", "view", "(", "-", "1", ")", "\n", "# quit loop if all sequences have finished", "\n", "if", "unfinished", ".", "sum", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "seq", ",", "seqLogprobs", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AdaAtt_lstm.__init__": [[279, 306], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "range", "range"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "use_maxout", "=", "True", ")", ":", "\n", "        ", "super", "(", "AdaAtt_lstm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "#self.rnn_type = opt.rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "num_layers", "=", "opt", ".", "num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "self", ".", "att_feat_size", "=", "opt", ".", "att_feat_size", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "\n", "self", ".", "use_maxout", "=", "use_maxout", "\n", "\n", "# Build a LSTM", "\n", "self", ".", "w2h", "=", "nn", ".", "Linear", "(", "self", ".", "input_encoding_size", ",", "(", "4", "+", "(", "use_maxout", "==", "True", ")", ")", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "v2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "(", "4", "+", "(", "use_maxout", "==", "True", ")", ")", "*", "self", ".", "rnn_size", ")", "\n", "\n", "self", ".", "i2h", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "(", "4", "+", "(", "use_maxout", "==", "True", ")", ")", "*", "self", ".", "rnn_size", ")", "for", "_", "in", "range", "(", "self", ".", "num_layers", "-", "1", ")", "]", ")", "\n", "self", ".", "h2h", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "(", "4", "+", "(", "use_maxout", "==", "True", ")", ")", "*", "self", ".", "rnn_size", ")", "for", "_", "in", "range", "(", "self", ".", "num_layers", ")", "]", ")", "\n", "\n", "# Layers for getting the fake region", "\n", "if", "self", ".", "num_layers", "==", "1", ":", "\n", "            ", "self", ".", "r_w2h", "=", "nn", ".", "Linear", "(", "self", ".", "input_encoding_size", ",", "self", ".", "rnn_size", ")", "\n", "self", ".", "r_v2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "r_i2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", "\n", "", "self", ".", "r_h2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AdaAtt_lstm.forward": [[308, 365], ["range", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "all_input_sums.narrow", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "cs.append", "hs.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.dropout", "torch.dropout", "torch.dropout", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "all_input_sums.narrow", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "AttModel.AdaAtt_lstm.w2h", "AttModel.AdaAtt_lstm.v2h", "all_input_sums.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "AttModel.AdaAtt_lstm.r_i2h", "AttModel.AdaAtt_lstm.r_h2h", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "_.unsqueeze", "_.unsqueeze", "AttModel.AdaAtt_lstm.r_w2h", "AttModel.AdaAtt_lstm.r_v2h"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "xt", ",", "img_fc", ",", "state", ")", ":", "\n", "\n", "        ", "hs", "=", "[", "]", "\n", "cs", "=", "[", "]", "\n", "for", "L", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "# c,h from previous timesteps", "\n", "            ", "prev_h", "=", "state", "[", "0", "]", "[", "L", "]", "\n", "prev_c", "=", "state", "[", "1", "]", "[", "L", "]", "\n", "# the input to this layer", "\n", "if", "L", "==", "0", ":", "\n", "                ", "x", "=", "xt", "\n", "i2h", "=", "self", ".", "w2h", "(", "x", ")", "+", "self", ".", "v2h", "(", "img_fc", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "hs", "[", "-", "1", "]", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "self", ".", "drop_prob_lm", ",", "self", ".", "training", ")", "\n", "i2h", "=", "self", ".", "i2h", "[", "L", "-", "1", "]", "(", "x", ")", "\n", "\n", "", "all_input_sums", "=", "i2h", "+", "self", ".", "h2h", "[", "L", "]", "(", "prev_h", ")", "\n", "\n", "sigmoid_chunk", "=", "all_input_sums", ".", "narrow", "(", "1", ",", "0", ",", "3", "*", "self", ".", "rnn_size", ")", "\n", "sigmoid_chunk", "=", "torch", ".", "sigmoid", "(", "sigmoid_chunk", ")", "\n", "# decode the gates", "\n", "in_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "0", ",", "self", ".", "rnn_size", ")", "\n", "forget_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", "\n", "out_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", "*", "2", ",", "self", ".", "rnn_size", ")", "\n", "# decode the write inputs", "\n", "if", "not", "self", ".", "use_maxout", ":", "\n", "                ", "in_transform", "=", "torch", ".", "tanh", "(", "all_input_sums", ".", "narrow", "(", "1", ",", "3", "*", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", ")", "\n", "", "else", ":", "\n", "                ", "in_transform", "=", "all_input_sums", ".", "narrow", "(", "1", ",", "3", "*", "self", ".", "rnn_size", ",", "2", "*", "self", ".", "rnn_size", ")", "\n", "in_transform", "=", "torch", ".", "max", "(", "in_transform", ".", "narrow", "(", "1", ",", "0", ",", "self", ".", "rnn_size", ")", ",", "\n", "in_transform", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", ")", "\n", "# perform the LSTM update", "\n", "", "next_c", "=", "forget_gate", "*", "prev_c", "+", "in_gate", "*", "in_transform", "\n", "# gated cells form the output", "\n", "tanh_nex_c", "=", "torch", ".", "tanh", "(", "next_c", ")", "\n", "next_h", "=", "out_gate", "*", "tanh_nex_c", "\n", "if", "L", "==", "self", ".", "num_layers", "-", "1", ":", "\n", "                ", "if", "L", "==", "0", ":", "\n", "                    ", "i2h", "=", "self", ".", "r_w2h", "(", "x", ")", "+", "self", ".", "r_v2h", "(", "img_fc", ")", "\n", "", "else", ":", "\n", "                    ", "i2h", "=", "self", ".", "r_i2h", "(", "x", ")", "\n", "", "n5", "=", "i2h", "+", "self", ".", "r_h2h", "(", "prev_h", ")", "\n", "fake_region", "=", "torch", ".", "sigmoid", "(", "n5", ")", "*", "tanh_nex_c", "\n", "\n", "", "cs", ".", "append", "(", "next_c", ")", "\n", "hs", ".", "append", "(", "next_h", ")", "\n", "\n", "# set up the decoder", "\n", "", "top_h", "=", "hs", "[", "-", "1", "]", "\n", "top_h", "=", "F", ".", "dropout", "(", "top_h", ",", "self", ".", "drop_prob_lm", ",", "self", ".", "training", ")", "\n", "fake_region", "=", "F", ".", "dropout", "(", "fake_region", ",", "self", ".", "drop_prob_lm", ",", "self", ".", "training", ")", "\n", "\n", "state", "=", "(", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "0", ")", "for", "_", "in", "hs", "]", ",", "0", ")", ",", "\n", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "0", ")", "for", "_", "in", "cs", "]", ",", "0", ")", ")", "\n", "return", "top_h", ",", "fake_region", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AdaAtt_attention.__init__": [[367, 391], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AdaAtt_attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "#self.rnn_type = opt.rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "\n", "# fake region embed", "\n", "self", ".", "fr_linear", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "input_encoding_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", ")", "\n", "self", ".", "fr_embed", "=", "nn", ".", "Linear", "(", "self", ".", "input_encoding_size", ",", "self", ".", "att_hid_size", ")", "\n", "\n", "# h out embed", "\n", "self", ".", "ho_linear", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "input_encoding_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", ")", "\n", "self", ".", "ho_embed", "=", "nn", ".", "Linear", "(", "self", ".", "input_encoding_size", ",", "self", ".", "att_hid_size", ")", "\n", "\n", "self", ".", "alpha_net", "=", "nn", ".", "Linear", "(", "self", ".", "att_hid_size", ",", "1", ")", "\n", "self", ".", "att2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AdaAtt_attention.forward": [[392, 430], ["conv_feat.view.view.view", "conv_feat_embed.view.view.view", "AttModel.AdaAtt_attention.fr_linear", "AttModel.AdaAtt_attention.fr_embed", "AttModel.AdaAtt_attention.ho_linear", "AttModel.AdaAtt_attention.ho_embed", "AttModel.AdaAtt_attention.unsqueeze().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.dropout", "torch.dropout", "torch.dropout", "AttModel.AdaAtt_attention.alpha_net", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm.squeeze", "torch.bmm.squeeze", "torch.bmm.squeeze", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.dropout", "torch.dropout", "torch.dropout", "AttModel.AdaAtt_attention.size", "AttModel.AdaAtt_attention.size", "torch.dropout.view", "AttModel.AdaAtt_attention.view", "att_masks.view.view.view", "torch.softmax.unsqueeze", "AttModel.AdaAtt_attention.att2h", "conv_feat.view.view.numel", "conv_feat.view.view.size", "AttModel.AdaAtt_attention.unsqueeze", "AttModel.AdaAtt_attention.view", "AttModel.AdaAtt_attention.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.softmax.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h_out", ",", "fake_region", ",", "conv_feat", ",", "conv_feat_embed", ",", "att_masks", "=", "None", ")", ":", "\n", "\n", "# View into three dimensions", "\n", "        ", "att_size", "=", "conv_feat", ".", "numel", "(", ")", "//", "conv_feat", ".", "size", "(", "0", ")", "//", "self", ".", "rnn_size", "\n", "conv_feat", "=", "conv_feat", ".", "view", "(", "-", "1", ",", "att_size", ",", "self", ".", "rnn_size", ")", "\n", "conv_feat_embed", "=", "conv_feat_embed", ".", "view", "(", "-", "1", ",", "att_size", ",", "self", ".", "att_hid_size", ")", "\n", "\n", "# view neighbor from bach_size * neighbor_num x rnn_size to bach_size x rnn_size * neighbor_num", "\n", "fake_region", "=", "self", ".", "fr_linear", "(", "fake_region", ")", "\n", "fake_region_embed", "=", "self", ".", "fr_embed", "(", "fake_region", ")", "\n", "\n", "h_out_linear", "=", "self", ".", "ho_linear", "(", "h_out", ")", "\n", "h_out_embed", "=", "self", ".", "ho_embed", "(", "h_out_linear", ")", "\n", "\n", "txt_replicate", "=", "h_out_embed", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "h_out_embed", ".", "size", "(", "0", ")", ",", "att_size", "+", "1", ",", "h_out_embed", ".", "size", "(", "1", ")", ")", "\n", "\n", "img_all", "=", "torch", ".", "cat", "(", "[", "fake_region", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "input_encoding_size", ")", ",", "conv_feat", "]", ",", "1", ")", "\n", "img_all_embed", "=", "torch", ".", "cat", "(", "[", "fake_region_embed", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "input_encoding_size", ")", ",", "conv_feat_embed", "]", ",", "1", ")", "\n", "\n", "hA", "=", "torch", ".", "tanh", "(", "img_all_embed", "+", "txt_replicate", ")", "\n", "hA", "=", "F", ".", "dropout", "(", "hA", ",", "self", ".", "drop_prob_lm", ",", "self", ".", "training", ")", "\n", "\n", "hAflat", "=", "self", ".", "alpha_net", "(", "hA", ".", "view", "(", "-", "1", ",", "self", ".", "att_hid_size", ")", ")", "\n", "PI", "=", "F", ".", "softmax", "(", "hAflat", ".", "view", "(", "-", "1", ",", "att_size", "+", "1", ")", ",", "dim", "=", "1", ")", "\n", "\n", "if", "att_masks", "is", "not", "None", ":", "\n", "            ", "att_masks", "=", "att_masks", ".", "view", "(", "-", "1", ",", "att_size", ")", "\n", "PI", "=", "PI", "*", "torch", ".", "cat", "(", "[", "att_masks", "[", ":", ",", ":", "1", "]", ",", "att_masks", "]", ",", "1", ")", "# assume one one at the first time step.", "\n", "PI", "=", "PI", "/", "PI", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "", "visAtt", "=", "torch", ".", "bmm", "(", "PI", ".", "unsqueeze", "(", "1", ")", ",", "img_all", ")", "\n", "visAttdim", "=", "visAtt", ".", "squeeze", "(", "1", ")", "\n", "\n", "atten_out", "=", "visAttdim", "+", "h_out_linear", "\n", "\n", "h", "=", "torch", ".", "tanh", "(", "self", ".", "att2h", "(", "atten_out", ")", ")", "\n", "h", "=", "F", ".", "dropout", "(", "h", ",", "self", ".", "drop_prob_lm", ",", "self", ".", "training", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AdaAttCore.__init__": [[432, 436], ["torch.Module.__init__", "AttModel.AdaAtt_lstm", "AttModel.AdaAtt_attention"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "use_maxout", "=", "False", ")", ":", "\n", "        ", "super", "(", "AdaAttCore", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lstm", "=", "AdaAtt_lstm", "(", "opt", ",", "use_maxout", ")", "\n", "self", ".", "attention", "=", "AdaAtt_attention", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AdaAttCore.forward": [[437, 441], ["AttModel.AdaAttCore.lstm", "AttModel.AdaAttCore.attention"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.attention"], ["", "def", "forward", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ",", "att_masks", "=", "None", ")", ":", "\n", "        ", "h_out", ",", "p_out", ",", "state", "=", "self", ".", "lstm", "(", "xt", ",", "fc_feats", ",", "state", ")", "\n", "atten_out", "=", "self", ".", "attention", "(", "h_out", ",", "p_out", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", ")", "\n", "return", "atten_out", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.TopDownCore.__init__": [[443, 450], ["torch.Module.__init__", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "AttModel.Attention"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "use_maxout", "=", "False", ")", ":", "\n", "        ", "super", "(", "TopDownCore", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "\n", "self", ".", "att_lstm", "=", "nn", ".", "LSTMCell", "(", "opt", ".", "input_encoding_size", "+", "opt", ".", "rnn_size", "*", "2", ",", "opt", ".", "rnn_size", ")", "# we, fc, h^2_t-1", "\n", "self", ".", "lang_lstm", "=", "nn", ".", "LSTMCell", "(", "opt", ".", "rnn_size", "*", "2", ",", "opt", ".", "rnn_size", ")", "# h^1_t, \\hat v", "\n", "self", ".", "attention", "=", "Attention", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.TopDownCore.forward": [[451, 468], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "AttModel.TopDownCore.att_lstm", "AttModel.TopDownCore.attention", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "AttModel.TopDownCore.lang_lstm", "torch.dropout", "torch.dropout", "torch.dropout", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.attention"], ["", "def", "forward", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ",", "att_masks", "=", "None", ")", ":", "\n", "        ", "prev_h", "=", "state", "[", "0", "]", "[", "-", "1", "]", "\n", "att_lstm_input", "=", "torch", ".", "cat", "(", "[", "prev_h", ",", "fc_feats", ",", "xt", "]", ",", "1", ")", "\n", "\n", "h_att", ",", "c_att", "=", "self", ".", "att_lstm", "(", "att_lstm_input", ",", "(", "state", "[", "0", "]", "[", "0", "]", ",", "state", "[", "1", "]", "[", "0", "]", ")", ")", "\n", "\n", "att", "=", "self", ".", "attention", "(", "h_att", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", ")", "\n", "\n", "lang_lstm_input", "=", "torch", ".", "cat", "(", "[", "att", ",", "h_att", "]", ",", "1", ")", "\n", "# lang_lstm_input = torch.cat([att, F.dropout(h_att, self.drop_prob_lm, self.training)], 1) ?????", "\n", "\n", "h_lang", ",", "c_lang", "=", "self", ".", "lang_lstm", "(", "lang_lstm_input", ",", "(", "state", "[", "0", "]", "[", "1", "]", ",", "state", "[", "1", "]", "[", "1", "]", ")", ")", "\n", "\n", "output", "=", "F", ".", "dropout", "(", "h_lang", ",", "self", ".", "drop_prob_lm", ",", "self", ".", "training", ")", "\n", "state", "=", "(", "torch", ".", "stack", "(", "[", "h_att", ",", "h_lang", "]", ")", ",", "torch", ".", "stack", "(", "[", "c_att", ",", "c_lang", "]", ")", ")", "\n", "\n", "return", "output", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.StackAttCore.__init__": [[478, 496], ["torch.Module.__init__", "AttModel.Attention", "AttModel.Attention", "FCModel.LSTMCore", "FCModel.LSTMCore", "FCModel.LSTMCore", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "use_maxout", "=", "False", ")", ":", "\n", "        ", "super", "(", "StackAttCore", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "\n", "# self.att0 = Attention(opt)", "\n", "self", ".", "att1", "=", "Attention", "(", "opt", ")", "\n", "self", ".", "att2", "=", "Attention", "(", "opt", ")", "\n", "\n", "opt_input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "opt", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "+", "opt", ".", "rnn_size", "\n", "self", ".", "lstm0", "=", "LSTMCore", "(", "opt", ")", "# att_feat + word_embedding", "\n", "opt", ".", "input_encoding_size", "=", "opt", ".", "rnn_size", "*", "2", "\n", "self", ".", "lstm1", "=", "LSTMCore", "(", "opt", ")", "\n", "self", ".", "lstm2", "=", "LSTMCore", "(", "opt", ")", "\n", "opt", ".", "input_encoding_size", "=", "opt_input_encoding_size", "\n", "\n", "# self.emb1 = nn.Linear(opt.rnn_size, opt.rnn_size)", "\n", "self", ".", "emb2", "=", "nn", ".", "Linear", "(", "opt", ".", "rnn_size", ",", "opt", ".", "rnn_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.StackAttCore.forward": [[497, 506], ["AttModel.StackAttCore.lstm0", "AttModel.StackAttCore.att1", "AttModel.StackAttCore.lstm1", "AttModel.StackAttCore.att2", "AttModel.StackAttCore.lstm2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "AttModel.StackAttCore.emb2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "zip"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ",", "att_masks", "=", "None", ")", ":", "\n", "# att_res_0 = self.att0(state[0][-1], att_feats, p_att_feats, att_masks)", "\n", "        ", "h_0", ",", "state_0", "=", "self", ".", "lstm0", "(", "torch", ".", "cat", "(", "[", "xt", ",", "fc_feats", "]", ",", "1", ")", ",", "[", "state", "[", "0", "]", "[", "0", ":", "1", "]", ",", "state", "[", "1", "]", "[", "0", ":", "1", "]", "]", ")", "\n", "att_res_1", "=", "self", ".", "att1", "(", "h_0", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", ")", "\n", "h_1", ",", "state_1", "=", "self", ".", "lstm1", "(", "torch", ".", "cat", "(", "[", "h_0", ",", "att_res_1", "]", ",", "1", ")", ",", "[", "state", "[", "0", "]", "[", "1", ":", "2", "]", ",", "state", "[", "1", "]", "[", "1", ":", "2", "]", "]", ")", "\n", "att_res_2", "=", "self", ".", "att2", "(", "h_1", "+", "self", ".", "emb2", "(", "att_res_1", ")", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", ")", "\n", "h_2", ",", "state_2", "=", "self", ".", "lstm2", "(", "torch", ".", "cat", "(", "[", "h_1", ",", "att_res_2", "]", ",", "1", ")", ",", "[", "state", "[", "0", "]", "[", "2", ":", "3", "]", ",", "state", "[", "1", "]", "[", "2", ":", "3", "]", "]", ")", "\n", "\n", "return", "h_2", ",", "[", "torch", ".", "cat", "(", "_", ",", "0", ")", "for", "_", "in", "zip", "(", "state_0", ",", "state_1", ",", "state_2", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.DenseAttCore.__init__": [[508, 535], ["torch.Module.__init__", "AttModel.Attention", "AttModel.Attention", "FCModel.LSTMCore", "FCModel.LSTMCore", "FCModel.LSTMCore", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "use_maxout", "=", "False", ")", ":", "\n", "        ", "super", "(", "DenseAttCore", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "\n", "# self.att0 = Attention(opt)", "\n", "self", ".", "att1", "=", "Attention", "(", "opt", ")", "\n", "self", ".", "att2", "=", "Attention", "(", "opt", ")", "\n", "\n", "opt_input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "opt", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "+", "opt", ".", "rnn_size", "\n", "self", ".", "lstm0", "=", "LSTMCore", "(", "opt", ")", "# att_feat + word_embedding", "\n", "opt", ".", "input_encoding_size", "=", "opt", ".", "rnn_size", "*", "2", "\n", "self", ".", "lstm1", "=", "LSTMCore", "(", "opt", ")", "\n", "self", ".", "lstm2", "=", "LSTMCore", "(", "opt", ")", "\n", "opt", ".", "input_encoding_size", "=", "opt_input_encoding_size", "\n", "\n", "# self.emb1 = nn.Linear(opt.rnn_size, opt.rnn_size)", "\n", "self", ".", "emb2", "=", "nn", ".", "Linear", "(", "opt", ".", "rnn_size", ",", "opt", ".", "rnn_size", ")", "\n", "\n", "# fuse h_0 and h_1", "\n", "self", ".", "fusion1", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "opt", ".", "rnn_size", "*", "2", ",", "opt", ".", "rnn_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "opt", ".", "drop_prob_lm", ")", ")", "\n", "# fuse h_0, h_1 and h_2", "\n", "self", ".", "fusion2", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "opt", ".", "rnn_size", "*", "3", ",", "opt", ".", "rnn_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "opt", ".", "drop_prob_lm", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.DenseAttCore.forward": [[536, 545], ["AttModel.DenseAttCore.lstm0", "AttModel.DenseAttCore.att1", "AttModel.DenseAttCore.lstm1", "AttModel.DenseAttCore.att2", "AttModel.DenseAttCore.lstm2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "AttModel.DenseAttCore.fusion2", "AttModel.DenseAttCore.emb2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "AttModel.DenseAttCore.fusion1", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ",", "att_masks", "=", "None", ")", ":", "\n", "# att_res_0 = self.att0(state[0][-1], att_feats, p_att_feats, att_masks)", "\n", "        ", "h_0", ",", "state_0", "=", "self", ".", "lstm0", "(", "torch", ".", "cat", "(", "[", "xt", ",", "fc_feats", "]", ",", "1", ")", ",", "[", "state", "[", "0", "]", "[", "0", ":", "1", "]", ",", "state", "[", "1", "]", "[", "0", ":", "1", "]", "]", ")", "\n", "att_res_1", "=", "self", ".", "att1", "(", "h_0", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", ")", "\n", "h_1", ",", "state_1", "=", "self", ".", "lstm1", "(", "torch", ".", "cat", "(", "[", "h_0", ",", "att_res_1", "]", ",", "1", ")", ",", "[", "state", "[", "0", "]", "[", "1", ":", "2", "]", ",", "state", "[", "1", "]", "[", "1", ":", "2", "]", "]", ")", "\n", "att_res_2", "=", "self", ".", "att2", "(", "h_1", "+", "self", ".", "emb2", "(", "att_res_1", ")", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", ")", "\n", "h_2", ",", "state_2", "=", "self", ".", "lstm2", "(", "torch", ".", "cat", "(", "[", "self", ".", "fusion1", "(", "torch", ".", "cat", "(", "[", "h_0", ",", "h_1", "]", ",", "1", ")", ")", ",", "att_res_2", "]", ",", "1", ")", ",", "[", "state", "[", "0", "]", "[", "2", ":", "3", "]", ",", "state", "[", "1", "]", "[", "2", ":", "3", "]", "]", ")", "\n", "\n", "return", "self", ".", "fusion2", "(", "torch", ".", "cat", "(", "[", "h_0", ",", "h_1", ",", "h_2", "]", ",", "1", ")", ")", ",", "[", "torch", ".", "cat", "(", "_", ",", "0", ")", "for", "_", "in", "zip", "(", "state_0", ",", "state_1", ",", "state_2", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.Attention.__init__": [[547, 554], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "\n", "self", ".", "h2att", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "att_hid_size", ")", "\n", "self", ".", "alpha_net", "=", "nn", ".", "Linear", "(", "self", ".", "att_hid_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.Attention.forward": [[555, 576], ["p_att_feats.view", "AttModel.Attention.h2att", "att_h.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "dot.view.view.view", "AttModel.Attention.alpha_net", "dot.view.view.view", "torch.softmax", "torch.softmax", "torch.softmax", "att_feats.view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "att_feats.size", "att_feats.size", "att_feats.numel", "att_feats.size", "att_h.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "att_masks.view().float", "torch.softmax.sum", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax.unsqueeze", "att_masks.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", "=", "None", ")", ":", "\n", "# The p_att_feats here is already projected", "\n", "        ", "att_size", "=", "att_feats", ".", "numel", "(", ")", "//", "att_feats", ".", "size", "(", "0", ")", "//", "att_feats", ".", "size", "(", "-", "1", ")", "\n", "att", "=", "p_att_feats", ".", "view", "(", "-", "1", ",", "att_size", ",", "self", ".", "att_hid_size", ")", "\n", "\n", "att_h", "=", "self", ".", "h2att", "(", "h", ")", "# batch * att_hid_size", "\n", "att_h", "=", "att_h", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "att", ")", "# batch * att_size * att_hid_size", "\n", "dot", "=", "att", "+", "att_h", "# batch * att_size * att_hid_size", "\n", "dot", "=", "torch", ".", "tanh", "(", "dot", ")", "# batch * att_size * att_hid_size", "\n", "dot", "=", "dot", ".", "view", "(", "-", "1", ",", "self", ".", "att_hid_size", ")", "# (batch * att_size) * att_hid_size", "\n", "dot", "=", "self", ".", "alpha_net", "(", "dot", ")", "# (batch * att_size) * 1", "\n", "dot", "=", "dot", ".", "view", "(", "-", "1", ",", "att_size", ")", "# batch * att_size", "\n", "\n", "weight", "=", "F", ".", "softmax", "(", "dot", ",", "dim", "=", "1", ")", "# batch * att_size", "\n", "if", "att_masks", "is", "not", "None", ":", "\n", "            ", "weight", "=", "weight", "*", "att_masks", ".", "view", "(", "-", "1", ",", "att_size", ")", ".", "float", "(", ")", "\n", "weight", "=", "weight", "/", "weight", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "# normalize to 1", "\n", "", "att_feats_", "=", "att_feats", ".", "view", "(", "-", "1", ",", "att_size", ",", "att_feats", ".", "size", "(", "-", "1", ")", ")", "# batch * att_size * att_feat_size", "\n", "att_res", "=", "torch", ".", "bmm", "(", "weight", ".", "unsqueeze", "(", "1", ")", ",", "att_feats_", ")", ".", "squeeze", "(", "1", ")", "# batch * att_feat_size", "\n", "\n", "return", "att_res", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.Att2in2Core.__init__": [[578, 596], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "AttModel.Attention"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "Att2in2Core", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "#self.rnn_type = opt.rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "#self.num_layers = opt.num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "self", ".", "att_feat_size", "=", "opt", ".", "att_feat_size", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "\n", "# Build a LSTM", "\n", "self", ".", "a2c", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "2", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "i2h", "=", "nn", ".", "Linear", "(", "self", ".", "input_encoding_size", ",", "5", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "h2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "5", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", "\n", "\n", "self", ".", "attention", "=", "Attention", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.Att2in2Core.forward": [[597, 618], ["AttModel.Att2in2Core.attention", "all_input_sums.narrow", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "AttModel.Att2in2Core.dropout", "AttModel.Att2in2Core.i2h", "AttModel.Att2in2Core.h2h", "all_input_sums.narrow", "AttModel.Att2in2Core.a2c", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "next_h.unsqueeze", "next_c.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.attention"], ["", "def", "forward", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ",", "att_masks", "=", "None", ")", ":", "\n", "        ", "att_res", "=", "self", ".", "attention", "(", "state", "[", "0", "]", "[", "-", "1", "]", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", ")", "\n", "\n", "all_input_sums", "=", "self", ".", "i2h", "(", "xt", ")", "+", "self", ".", "h2h", "(", "state", "[", "0", "]", "[", "-", "1", "]", ")", "\n", "sigmoid_chunk", "=", "all_input_sums", ".", "narrow", "(", "1", ",", "0", ",", "3", "*", "self", ".", "rnn_size", ")", "\n", "sigmoid_chunk", "=", "torch", ".", "sigmoid", "(", "sigmoid_chunk", ")", "\n", "in_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "0", ",", "self", ".", "rnn_size", ")", "\n", "forget_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", "\n", "out_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", "*", "2", ",", "self", ".", "rnn_size", ")", "\n", "\n", "in_transform", "=", "all_input_sums", ".", "narrow", "(", "1", ",", "3", "*", "self", ".", "rnn_size", ",", "2", "*", "self", ".", "rnn_size", ")", "+", "self", ".", "a2c", "(", "att_res", ")", "\n", "in_transform", "=", "torch", ".", "max", "(", "in_transform", ".", "narrow", "(", "1", ",", "0", ",", "self", ".", "rnn_size", ")", ",", "\n", "in_transform", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", ")", "\n", "next_c", "=", "forget_gate", "*", "state", "[", "1", "]", "[", "-", "1", "]", "+", "in_gate", "*", "in_transform", "\n", "next_h", "=", "out_gate", "*", "torch", ".", "tanh", "(", "next_c", ")", "\n", "\n", "output", "=", "self", ".", "dropout", "(", "next_h", ")", "\n", "state", "=", "(", "next_h", ".", "unsqueeze", "(", "0", ")", ",", "next_c", ".", "unsqueeze", "(", "0", ")", ")", "\n", "return", "output", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.Att2inCore.__init__": [[620, 624], ["AttModel.Att2in2Core.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "Att2inCore", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "del", "self", ".", "a2c", "\n", "self", ".", "a2c", "=", "nn", ".", "Linear", "(", "self", ".", "att_feat_size", ",", "2", "*", "self", ".", "rnn_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.Att2all2Core.__init__": [[630, 648], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "AttModel.Attention"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "Att2all2Core", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "#self.rnn_type = opt.rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "#self.num_layers = opt.num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "self", ".", "att_feat_size", "=", "opt", ".", "att_feat_size", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "\n", "# Build a LSTM", "\n", "self", ".", "a2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "5", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "i2h", "=", "nn", ".", "Linear", "(", "self", ".", "input_encoding_size", ",", "5", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "h2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "5", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", "\n", "\n", "self", ".", "attention", "=", "Attention", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.Att2all2Core.forward": [[649, 669], ["AttModel.Att2all2Core.attention", "all_input_sums.narrow", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "all_input_sums.narrow", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "AttModel.Att2all2Core.dropout", "AttModel.Att2all2Core.a2h", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "next_h.unsqueeze", "next_c.unsqueeze", "AttModel.Att2all2Core.i2h", "AttModel.Att2all2Core.h2h"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.attention"], ["", "def", "forward", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ",", "att_masks", "=", "None", ")", ":", "\n", "        ", "att_res", "=", "self", ".", "attention", "(", "state", "[", "0", "]", "[", "-", "1", "]", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", ")", "\n", "\n", "all_input_sums", "=", "self", ".", "i2h", "(", "xt", ")", "+", "self", ".", "h2h", "(", "state", "[", "0", "]", "[", "-", "1", "]", ")", "+", "self", ".", "a2h", "(", "att_res", ")", "\n", "sigmoid_chunk", "=", "all_input_sums", ".", "narrow", "(", "1", ",", "0", ",", "3", "*", "self", ".", "rnn_size", ")", "\n", "sigmoid_chunk", "=", "torch", ".", "sigmoid", "(", "sigmoid_chunk", ")", "\n", "in_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "0", ",", "self", ".", "rnn_size", ")", "\n", "forget_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", "\n", "out_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", "*", "2", ",", "self", ".", "rnn_size", ")", "\n", "\n", "in_transform", "=", "all_input_sums", ".", "narrow", "(", "1", ",", "3", "*", "self", ".", "rnn_size", ",", "2", "*", "self", ".", "rnn_size", ")", "\n", "in_transform", "=", "torch", ".", "max", "(", "in_transform", ".", "narrow", "(", "1", ",", "0", ",", "self", ".", "rnn_size", ")", ",", "\n", "in_transform", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", ")", "\n", "next_c", "=", "forget_gate", "*", "state", "[", "1", "]", "[", "-", "1", "]", "+", "in_gate", "*", "in_transform", "\n", "next_h", "=", "out_gate", "*", "torch", ".", "tanh", "(", "next_c", ")", "\n", "\n", "output", "=", "self", ".", "dropout", "(", "next_h", ")", "\n", "state", "=", "(", "next_h", ".", "unsqueeze", "(", "0", ")", ",", "next_c", ".", "unsqueeze", "(", "0", ")", ")", "\n", "return", "output", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AdaAttModel.__init__": [[671, 674], ["AttModel.AttModel.__init__", "AttModel.AdaAttCore"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AdaAttModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "core", "=", "AdaAttCore", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AdaAttMOModel.__init__": [[677, 680], ["AttModel.AttModel.__init__", "AttModel.AdaAttCore"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AdaAttMOModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "core", "=", "AdaAttCore", "(", "opt", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.Att2in2Model.__init__": [[682, 687], ["AttModel.AttModel.__init__", "AttModel.Att2in2Core", "delattr"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "Att2in2Model", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "core", "=", "Att2in2Core", "(", "opt", ")", "\n", "delattr", "(", "self", ",", "'fc_embed'", ")", "\n", "self", ".", "fc_embed", "=", "lambda", "x", ":", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.Att2all2Model.__init__": [[689, 694], ["AttModel.AttModel.__init__", "AttModel.Att2all2Core", "delattr"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "Att2all2Model", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "core", "=", "Att2all2Core", "(", "opt", ")", "\n", "delattr", "(", "self", ",", "'fc_embed'", ")", "\n", "self", ".", "fc_embed", "=", "lambda", "x", ":", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.TopDownModel.__init__": [[696, 700], ["AttModel.AttModel.__init__", "AttModel.TopDownCore"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "TopDownModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "num_layers", "=", "2", "\n", "self", ".", "core", "=", "TopDownCore", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.StackAttModel.__init__": [[702, 706], ["AttModel.AttModel.__init__", "AttModel.StackAttCore"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "StackAttModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "num_layers", "=", "3", "\n", "self", ".", "core", "=", "StackAttCore", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.DenseAttModel.__init__": [[708, 712], ["AttModel.AttModel.__init__", "AttModel.DenseAttCore"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "DenseAttModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "num_layers", "=", "3", "\n", "self", ".", "core", "=", "DenseAttCore", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.Att2inModel.__init__": [[714, 723], ["AttModel.AttModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "AttModel.Att2inCore", "AttModel.Att2inModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "Att2inModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "del", "self", ".", "embed", ",", "self", ".", "fc_embed", ",", "self", ".", "att_embed", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", "+", "1", ",", "self", ".", "input_encoding_size", ")", "\n", "self", ".", "fc_embed", "=", "self", ".", "att_embed", "=", "lambda", "x", ":", "x", "\n", "del", "self", ".", "ctx2att", "\n", "self", ".", "ctx2att", "=", "nn", ".", "Linear", "(", "self", ".", "att_feat_size", ",", "self", ".", "att_hid_size", ")", "\n", "self", ".", "core", "=", "Att2inCore", "(", "opt", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.Att2inModel.init_weights": [[724, 729], ["AttModel.Att2inModel.embed.weight.data.uniform_", "AttModel.Att2inModel.logit.bias.data.fill_", "AttModel.Att2inModel.logit.weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "embed", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "logit", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "logit", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.NewFCModel.__init__": [[732, 741], ["AttModel.AttModel.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Embedding", "torch.Embedding", "torch.Embedding", "FCModel.LSTMCore", "delattr", "delattr"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "NewFCModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "fc_embed", "=", "nn", ".", "Linear", "(", "self", ".", "fc_feat_size", ",", "self", ".", "input_encoding_size", ")", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", "+", "1", ",", "self", ".", "input_encoding_size", ")", "\n", "self", ".", "_core", "=", "LSTMCore", "(", "opt", ")", "\n", "delattr", "(", "self", ",", "'att_embed'", ")", "\n", "self", ".", "att_embed", "=", "lambda", "x", ":", "x", "\n", "delattr", "(", "self", ",", "'ctx2att'", ")", "\n", "self", ".", "ctx2att", "=", "lambda", "x", ":", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.NewFCModel.core": [[742, 766], ["AttModel.NewFCModel._core", "AttModel.NewFCModel._core"], "methods", ["None"], ["", "def", "core", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ",", "att_masks", ")", ":", "\n", "# Step 0, feed the input image", "\n", "# if (self.training and state[0].is_leaf) or \\", "\n", "#     (not self.training and state[0].sum() == 0):", "\n", "#     _, state = self._core(fc_feats, state)", "\n", "# three cases", "\n", "# normal mle training", "\n", "# Sample", "\n", "# beam search (diverse beam search)", "\n", "# fixed captioning module.", "\n", "# is_first_step = (state[0]==0).all(2).all(0)", "\n", "# if is_first_step.all():", "\n", "#     _, state = self._core(fc_feats, state)", "\n", "# elif is_first_step.any():", "\n", "#     # This is mostly for diverse beam search I think", "\n", "#     new_state = torch.zeros_like(state)", "\n", "#     new_state[~is_first_step] = state[~is_first_step]", "\n", "#     _, state = self._core(fc_feats, state)", "\n", "#     new_state[is_first_step] = state[is_first_step]", "\n", "#     state = new_state", "\n", "        ", "if", "(", "state", "[", "0", "]", "==", "0", ")", ".", "all", "(", ")", ":", "\n", "# Let's forget about diverse beam search first", "\n", "            ", "_", ",", "state", "=", "self", ".", "_core", "(", "fc_feats", ",", "state", ")", "\n", "", "return", "self", ".", "_core", "(", "xt", ",", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.NewFCModel._prepare_feature": [[767, 771], ["AttModel.NewFCModel.fc_embed"], "methods", ["None"], ["", "def", "_prepare_feature", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "att_masks", ")", ":", "\n", "        ", "fc_feats", "=", "self", ".", "fc_embed", "(", "fc_feats", ")", "\n", "\n", "return", "fc_feats", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.LMModel.__init__": [[774, 784], ["AttModel.AttModel.__init__", "delattr", "torch.Embedding", "torch.Embedding", "torch.Embedding", "FCModel.LSTMCore", "delattr", "delattr", "x.new_zeros"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "LMModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "delattr", "(", "self", ",", "'fc_embed'", ")", "\n", "self", ".", "fc_embed", "=", "lambda", "x", ":", "x", ".", "new_zeros", "(", "x", ".", "shape", "[", "0", "]", ",", "self", ".", "input_encoding_size", ")", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", "+", "1", ",", "self", ".", "input_encoding_size", ")", "\n", "self", ".", "_core", "=", "LSTMCore", "(", "opt", ")", "\n", "delattr", "(", "self", ",", "'att_embed'", ")", "\n", "self", ".", "att_embed", "=", "lambda", "x", ":", "x", "\n", "delattr", "(", "self", ",", "'ctx2att'", ")", "\n", "self", ".", "ctx2att", "=", "lambda", "x", ":", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.LMModel.core": [[785, 790], ["AttModel.LMModel._core", "AttModel.LMModel._core"], "methods", ["None"], ["", "def", "core", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ",", "att_masks", ")", ":", "\n", "        ", "if", "(", "state", "[", "0", "]", "==", "0", ")", ".", "all", "(", ")", ":", "\n", "# Let's forget about diverse beam search first", "\n", "            ", "_", ",", "state", "=", "self", ".", "_core", "(", "fc_feats", ",", "state", ")", "\n", "", "return", "self", ".", "_core", "(", "xt", ",", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.LMModel._prepare_feature": [[791, 795], ["AttModel.LMModel.fc_embed"], "methods", ["None"], ["", "def", "_prepare_feature", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "att_masks", ")", ":", "\n", "        ", "fc_feats", "=", "self", ".", "fc_embed", "(", "fc_feats", ")", "\n", "\n", "return", "fc_feats", ",", "None", ",", "None", ",", "None", "", "", "", ""]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.sort_pack_padded_sequence": [[32, 38], ["torch.sort", "torch.sort", "torch.sort", "torch.nn.utils.rnn.pack_padded_sequence", "indices.clone", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange", "torch.arange", "torch.arange", "len"], "function", ["None"], ["def", "sort_pack_padded_sequence", "(", "input", ",", "lengths", ")", ":", "\n", "    ", "sorted_lengths", ",", "indices", "=", "torch", ".", "sort", "(", "lengths", ",", "descending", "=", "True", ")", "\n", "tmp", "=", "pack_padded_sequence", "(", "input", "[", "indices", "]", ",", "sorted_lengths", ",", "batch_first", "=", "True", ")", "\n", "inv_ix", "=", "indices", ".", "clone", "(", ")", "\n", "inv_ix", "[", "indices", "]", "=", "torch", ".", "arange", "(", "0", ",", "len", "(", "indices", ")", ")", ".", "type_as", "(", "inv_ix", ")", "\n", "return", "tmp", ",", "inv_ix", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.pad_unsort_packed_sequence": [[39, 43], ["torch.nn.utils.rnn.pad_packed_sequence"], "function", ["None"], ["", "def", "pad_unsort_packed_sequence", "(", "input", ",", "inv_ix", ")", ":", "\n", "    ", "tmp", ",", "_", "=", "pad_packed_sequence", "(", "input", ",", "batch_first", "=", "True", ")", "\n", "tmp", "=", "tmp", "[", "inv_ix", "]", "\n", "return", "tmp", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.pack_wrapper": [[44, 50], ["AttModel.sort_pack_padded_sequence", "AttModel.pad_unsort_packed_sequence", "module", "att_masks.data.long().sum", "torch.nn.utils.rnn.PackedSequence", "module", "att_masks.data.long"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.sort_pack_padded_sequence", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.pad_unsort_packed_sequence"], ["", "def", "pack_wrapper", "(", "module", ",", "att_feats", ",", "att_masks", ")", ":", "\n", "    ", "if", "att_masks", "is", "not", "None", ":", "\n", "        ", "packed", ",", "inv_ix", "=", "sort_pack_padded_sequence", "(", "att_feats", ",", "att_masks", ".", "data", ".", "long", "(", ")", ".", "sum", "(", "1", ")", ")", "\n", "return", "pad_unsort_packed_sequence", "(", "PackedSequence", "(", "module", "(", "packed", "[", "0", "]", ")", ",", "packed", "[", "1", "]", ")", ",", "inv_ix", ")", "\n", "", "else", ":", "\n", "        ", "return", "module", "(", "att_feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.CaptionModel.CaptionModel.__init__": [[23, 25], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "CaptionModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.CaptionModel.CaptionModel.forward": [[30, 35], ["kwargs.get", "getattr"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get"], ["", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "mode", "=", "kwargs", ".", "get", "(", "'mode'", ",", "'forward'", ")", "\n", "if", "'mode'", "in", "kwargs", ":", "\n", "            ", "del", "kwargs", "[", "'mode'", "]", "\n", "", "return", "getattr", "(", "self", ",", "'_'", "+", "mode", ")", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.CaptionModel.CaptionModel.beam_search": [[36, 190], ["opt.get", "opt.get", "opt.get", "opt.get", "opt.get", "opt.get", "misc.penalty_builder", "list", "list", "list", "range", "functools.reduce", "logprobs_table[].data.float.clone", "range", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "min", "range", "sorted", "range", "opt.get", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "zip", "init_logprobs.chunk", "range", "range", "ys.size", "range", "_.clone", "beam_seq[].clone", "beam_seq_logprobs[].clone", "range", "range", "range", "range", "range", "sorted", "range", "range", "ys[].item", "sorted.append", "len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "range", "_.chunk", "range", "logprobs_table[].data.float", "CaptionModel.CaptionModel.beam_search.add_diversity"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.penalty_builder", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get"], ["", "def", "beam_search", "(", "self", ",", "init_state", ",", "init_logprobs", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "\n", "# function computes the similarity score to be augmented", "\n", "        ", "def", "add_diversity", "(", "beam_seq_table", ",", "logprobsf", ",", "t", ",", "divm", ",", "diversity_lambda", ",", "bdash", ")", ":", "\n", "            ", "local_time", "=", "t", "-", "divm", "\n", "unaug_logprobsf", "=", "logprobsf", ".", "clone", "(", ")", "\n", "for", "prev_choice", "in", "range", "(", "divm", ")", ":", "\n", "                ", "prev_decisions", "=", "beam_seq_table", "[", "prev_choice", "]", "[", "local_time", "]", "\n", "for", "sub_beam", "in", "range", "(", "bdash", ")", ":", "\n", "                    ", "for", "prev_labels", "in", "range", "(", "bdash", ")", ":", "\n", "                        ", "logprobsf", "[", "sub_beam", "]", "[", "prev_decisions", "[", "prev_labels", "]", "]", "=", "logprobsf", "[", "sub_beam", "]", "[", "prev_decisions", "[", "prev_labels", "]", "]", "-", "diversity_lambda", "\n", "", "", "", "return", "unaug_logprobsf", "\n", "\n", "# does one step of classical beam search", "\n", "\n", "", "def", "beam_step", "(", "logprobsf", ",", "unaug_logprobsf", ",", "beam_size", ",", "t", ",", "beam_seq", ",", "beam_seq_logprobs", ",", "beam_logprobs_sum", ",", "state", ")", ":", "\n", "#INPUTS:", "\n", "#logprobsf: probabilities augmented after diversity", "\n", "#beam_size: obvious", "\n", "#t        : time instant", "\n", "#beam_seq : tensor contanining the beams", "\n", "#beam_seq_logprobs: tensor contanining the beam logprobs", "\n", "#beam_logprobs_sum: tensor contanining joint logprobs", "\n", "#OUPUTS:", "\n", "#beam_seq : tensor containing the word indices of the decoded captions", "\n", "#beam_seq_logprobs : log-probability of each decision made, same size as beam_seq", "\n", "#beam_logprobs_sum : joint log-probability of each beam", "\n", "\n", "            ", "ys", ",", "ix", "=", "torch", ".", "sort", "(", "logprobsf", ",", "1", ",", "True", ")", "\n", "candidates", "=", "[", "]", "\n", "cols", "=", "min", "(", "beam_size", ",", "ys", ".", "size", "(", "1", ")", ")", "\n", "rows", "=", "beam_size", "\n", "if", "t", "==", "0", ":", "\n", "                ", "rows", "=", "1", "\n", "", "for", "c", "in", "range", "(", "cols", ")", ":", "# for each column (word, essentially)", "\n", "                ", "for", "q", "in", "range", "(", "rows", ")", ":", "# for each beam expansion", "\n", "#compute logprob of expanding beam q with word in (sorted) position c", "\n", "                    ", "local_logprob", "=", "ys", "[", "q", ",", "c", "]", ".", "item", "(", ")", "\n", "candidate_logprob", "=", "beam_logprobs_sum", "[", "q", "]", "+", "local_logprob", "\n", "local_unaug_logprob", "=", "unaug_logprobsf", "[", "q", ",", "ix", "[", "q", ",", "c", "]", "]", "\n", "candidates", ".", "append", "(", "{", "'c'", ":", "ix", "[", "q", ",", "c", "]", ",", "'q'", ":", "q", ",", "'p'", ":", "candidate_logprob", ",", "'r'", ":", "local_unaug_logprob", "}", ")", "\n", "", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "'p'", "]", ")", "\n", "\n", "new_state", "=", "[", "_", ".", "clone", "(", ")", "for", "_", "in", "state", "]", "\n", "#beam_seq_prev, beam_seq_logprobs_prev", "\n", "if", "t", ">=", "1", ":", "\n", "#we''ll need these as reference when we fork beams around", "\n", "                ", "beam_seq_prev", "=", "beam_seq", "[", ":", "t", "]", ".", "clone", "(", ")", "\n", "beam_seq_logprobs_prev", "=", "beam_seq_logprobs", "[", ":", "t", "]", ".", "clone", "(", ")", "\n", "", "for", "vix", "in", "range", "(", "beam_size", ")", ":", "\n", "                ", "v", "=", "candidates", "[", "vix", "]", "\n", "#fork beam index q into index vix", "\n", "if", "t", ">=", "1", ":", "\n", "                    ", "beam_seq", "[", ":", "t", ",", "vix", "]", "=", "beam_seq_prev", "[", ":", ",", "v", "[", "'q'", "]", "]", "\n", "beam_seq_logprobs", "[", ":", "t", ",", "vix", "]", "=", "beam_seq_logprobs_prev", "[", ":", ",", "v", "[", "'q'", "]", "]", "\n", "#rearrange recurrent states", "\n", "", "for", "state_ix", "in", "range", "(", "len", "(", "new_state", ")", ")", ":", "\n", "#  copy over state in previous beam q to new beam at vix", "\n", "                    ", "new_state", "[", "state_ix", "]", "[", ":", ",", "vix", "]", "=", "state", "[", "state_ix", "]", "[", ":", ",", "v", "[", "'q'", "]", "]", "# dimension one is time step", "\n", "#append new end terminal at the end of this beam", "\n", "", "beam_seq", "[", "t", ",", "vix", "]", "=", "v", "[", "'c'", "]", "# c'th word is the continuation", "\n", "beam_seq_logprobs", "[", "t", ",", "vix", "]", "=", "v", "[", "'r'", "]", "# the raw logprob here", "\n", "beam_logprobs_sum", "[", "vix", "]", "=", "v", "[", "'p'", "]", "# the new (sum) logprob along this beam", "\n", "", "state", "=", "new_state", "\n", "return", "beam_seq", ",", "beam_seq_logprobs", ",", "beam_logprobs_sum", ",", "state", ",", "candidates", "\n", "\n", "# Start diverse_beam_search", "\n", "", "opt", "=", "kwargs", "[", "'opt'", "]", "\n", "temperature", "=", "opt", ".", "get", "(", "'temperature'", ",", "1", ")", "# This should not affect beam search, but will affect dbs", "\n", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "10", ")", "\n", "group_size", "=", "opt", ".", "get", "(", "'group_size'", ",", "1", ")", "\n", "diversity_lambda", "=", "opt", ".", "get", "(", "'diversity_lambda'", ",", "0.5", ")", "\n", "decoding_constraint", "=", "opt", ".", "get", "(", "'decoding_constraint'", ",", "0", ")", "\n", "remove_bad_endings", "=", "opt", ".", "get", "(", "'remove_bad_endings'", ",", "0", ")", "\n", "length_penalty", "=", "utils", ".", "penalty_builder", "(", "opt", ".", "get", "(", "'length_penalty'", ",", "''", ")", ")", "\n", "bdash", "=", "beam_size", "//", "group_size", "# beam per group", "\n", "\n", "# INITIALIZATIONS", "\n", "beam_seq_table", "=", "[", "torch", ".", "LongTensor", "(", "self", ".", "seq_length", ",", "bdash", ")", ".", "zero_", "(", ")", "for", "_", "in", "range", "(", "group_size", ")", "]", "\n", "beam_seq_logprobs_table", "=", "[", "torch", ".", "FloatTensor", "(", "self", ".", "seq_length", ",", "bdash", ")", ".", "zero_", "(", ")", "for", "_", "in", "range", "(", "group_size", ")", "]", "\n", "beam_logprobs_sum_table", "=", "[", "torch", ".", "zeros", "(", "bdash", ")", "for", "_", "in", "range", "(", "group_size", ")", "]", "\n", "\n", "# logprobs # logprobs predicted in last time step, shape (beam_size, vocab_size+1)", "\n", "done_beams_table", "=", "[", "[", "]", "for", "_", "in", "range", "(", "group_size", ")", "]", "\n", "# state_table = [list(torch.unbind(_)) for _ in torch.stack(init_state).chunk(group_size, 2)]", "\n", "state_table", "=", "list", "(", "zip", "(", "*", "[", "_", ".", "chunk", "(", "group_size", ",", "1", ")", "for", "_", "in", "init_state", "]", ")", ")", "\n", "logprobs_table", "=", "list", "(", "init_logprobs", ".", "chunk", "(", "group_size", ",", "0", ")", ")", "\n", "# END INIT", "\n", "\n", "# Chunk elements in the args", "\n", "args", "=", "list", "(", "args", ")", "\n", "if", "self", ".", "__class__", ".", "__name__", "==", "'AttEnsemble'", ":", "\n", "            ", "args", "=", "[", "[", "_", ".", "chunk", "(", "group_size", ")", "if", "_", "is", "not", "None", "else", "[", "None", "]", "*", "group_size", "for", "_", "in", "args_", "]", "for", "args_", "in", "args", "]", "# arg_name, model_name, group_name", "\n", "args", "=", "[", "[", "[", "args", "[", "j", "]", "[", "i", "]", "[", "k", "]", "for", "i", "in", "range", "(", "len", "(", "self", ".", "models", ")", ")", "]", "for", "j", "in", "range", "(", "len", "(", "args", ")", ")", "]", "for", "k", "in", "range", "(", "group_size", ")", "]", "# group_name, arg_name, model_name", "\n", "", "else", ":", "\n", "            ", "args", "=", "[", "_", ".", "chunk", "(", "group_size", ")", "if", "_", "is", "not", "None", "else", "[", "None", "]", "*", "group_size", "for", "_", "in", "args", "]", "\n", "args", "=", "[", "[", "args", "[", "i", "]", "[", "j", "]", "for", "i", "in", "range", "(", "len", "(", "args", ")", ")", "]", "for", "j", "in", "range", "(", "group_size", ")", "]", "\n", "\n", "", "for", "t", "in", "range", "(", "self", ".", "seq_length", "+", "group_size", "-", "1", ")", ":", "\n", "            ", "for", "divm", "in", "range", "(", "group_size", ")", ":", "\n", "                ", "if", "t", ">=", "divm", "and", "t", "<=", "self", ".", "seq_length", "+", "divm", "-", "1", ":", "\n", "# add diversity", "\n", "                    ", "logprobsf", "=", "logprobs_table", "[", "divm", "]", ".", "data", ".", "float", "(", ")", "\n", "# suppress previous word", "\n", "if", "decoding_constraint", "and", "t", "-", "divm", ">", "0", ":", "\n", "                        ", "logprobsf", ".", "scatter_", "(", "1", ",", "beam_seq_table", "[", "divm", "]", "[", "t", "-", "divm", "-", "1", "]", ".", "unsqueeze", "(", "1", ")", ".", "cuda", "(", ")", ",", "float", "(", "'-inf'", ")", ")", "\n", "", "if", "remove_bad_endings", "and", "t", "-", "divm", ">", "0", ":", "\n", "                        ", "logprobsf", "[", "torch", ".", "from_numpy", "(", "np", ".", "isin", "(", "beam_seq_table", "[", "divm", "]", "[", "t", "-", "divm", "-", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "self", ".", "bad_endings_ix", ")", ".", "astype", "(", "'uint8'", ")", ")", ",", "0", "]", "=", "float", "(", "'-inf'", ")", "\n", "# suppress UNK tokens in the decoding", "\n", "", "logprobsf", "[", ":", ",", "logprobsf", ".", "size", "(", "1", ")", "-", "1", "]", "=", "logprobsf", "[", ":", ",", "logprobsf", ".", "size", "(", "1", ")", "-", "1", "]", "-", "1000", "\n", "# diversity is added here", "\n", "# the function directly modifies the logprobsf values and hence, we need to return", "\n", "# the unaugmented ones for sorting the candidates in the end. # for historical", "\n", "# reasons :-)", "\n", "unaug_logprobsf", "=", "add_diversity", "(", "beam_seq_table", ",", "logprobsf", ",", "t", ",", "divm", ",", "diversity_lambda", ",", "bdash", ")", "\n", "\n", "# infer new beams", "\n", "beam_seq_table", "[", "divm", "]", ",", "beam_seq_logprobs_table", "[", "divm", "]", ",", "beam_logprobs_sum_table", "[", "divm", "]", ",", "state_table", "[", "divm", "]", ",", "candidates_divm", "=", "beam_step", "(", "logprobsf", ",", "\n", "unaug_logprobsf", ",", "\n", "bdash", ",", "\n", "t", "-", "divm", ",", "\n", "beam_seq_table", "[", "divm", "]", ",", "\n", "beam_seq_logprobs_table", "[", "divm", "]", ",", "\n", "beam_logprobs_sum_table", "[", "divm", "]", ",", "\n", "state_table", "[", "divm", "]", ")", "\n", "\n", "# if time's up... or if end token is reached then copy beams", "\n", "for", "vix", "in", "range", "(", "bdash", ")", ":", "\n", "                        ", "if", "beam_seq_table", "[", "divm", "]", "[", "t", "-", "divm", ",", "vix", "]", "==", "0", "or", "t", "==", "self", ".", "seq_length", "+", "divm", "-", "1", ":", "\n", "                            ", "final_beam", "=", "{", "\n", "'seq'", ":", "beam_seq_table", "[", "divm", "]", "[", ":", ",", "vix", "]", ".", "clone", "(", ")", ",", "\n", "'logps'", ":", "beam_seq_logprobs_table", "[", "divm", "]", "[", ":", ",", "vix", "]", ".", "clone", "(", ")", ",", "\n", "'unaug_p'", ":", "beam_seq_logprobs_table", "[", "divm", "]", "[", ":", ",", "vix", "]", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "\n", "'p'", ":", "beam_logprobs_sum_table", "[", "divm", "]", "[", "vix", "]", ".", "item", "(", ")", "\n", "}", "\n", "final_beam", "[", "'p'", "]", "=", "length_penalty", "(", "t", "-", "divm", "+", "1", ",", "final_beam", "[", "'p'", "]", ")", "\n", "done_beams_table", "[", "divm", "]", ".", "append", "(", "final_beam", ")", "\n", "# don't continue beams from finished sequences", "\n", "beam_logprobs_sum_table", "[", "divm", "]", "[", "vix", "]", "=", "-", "1000", "\n", "\n", "# move the current group one step forward in time", "\n", "\n", "", "", "it", "=", "beam_seq_table", "[", "divm", "]", "[", "t", "-", "divm", "]", "\n", "logprobs_table", "[", "divm", "]", ",", "state_table", "[", "divm", "]", "=", "self", ".", "get_logprobs_state", "(", "it", ".", "cuda", "(", ")", ",", "*", "(", "args", "[", "divm", "]", "+", "[", "state_table", "[", "divm", "]", "]", ")", ")", "\n", "logprobs_table", "[", "divm", "]", "=", "F", ".", "log_softmax", "(", "logprobs_table", "[", "divm", "]", "/", "temperature", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# all beams are sorted by their log-probabilities", "\n", "", "", "", "done_beams_table", "=", "[", "sorted", "(", "done_beams_table", "[", "i", "]", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "'p'", "]", ")", "[", ":", "bdash", "]", "for", "i", "in", "range", "(", "group_size", ")", "]", "\n", "done_beams", "=", "reduce", "(", "lambda", "a", ",", "b", ":", "a", "+", "b", ",", "done_beams_table", ")", "\n", "return", "done_beams", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.CaptionModel.CaptionModel.sample_next_word": [[192, 230], ["torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.distributions.Categorical().sample.view().long", "torch.distributions.Categorical().sample.view().long", "torch.distributions.Categorical().sample.view().long", "CaptionModel.CaptionModel.sample_next_word.gumbel_softmax_sample"], "methods", ["None"], ["", "def", "sample_next_word", "(", "self", ",", "logprobs", ",", "sample_method", ",", "temperature", ")", ":", "\n", "        ", "if", "sample_method", "==", "'greedy'", ":", "\n", "            ", "sampleLogprobs", ",", "it", "=", "torch", ".", "max", "(", "logprobs", ".", "data", ",", "1", ")", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "\n", "", "elif", "sample_method", "==", "'gumbel'", ":", "# gumbel softmax", "\n", "# ref: https://gist.github.com/yzh119/fd2146d2aeb329d067568a493b20172f", "\n", "            ", "def", "sample_gumbel", "(", "shape", ",", "eps", "=", "1e-20", ")", ":", "\n", "                ", "U", "=", "torch", ".", "rand", "(", "shape", ")", ".", "cuda", "(", ")", "\n", "return", "-", "torch", ".", "log", "(", "-", "torch", ".", "log", "(", "U", "+", "eps", ")", "+", "eps", ")", "\n", "", "def", "gumbel_softmax_sample", "(", "logits", ",", "temperature", ")", ":", "\n", "                ", "y", "=", "logits", "+", "sample_gumbel", "(", "logits", ".", "size", "(", ")", ")", "\n", "return", "F", ".", "log_softmax", "(", "y", "/", "temperature", ",", "dim", "=", "-", "1", ")", "\n", "", "_logprobs", "=", "gumbel_softmax_sample", "(", "logprobs", ",", "temperature", ")", "\n", "_", ",", "it", "=", "torch", ".", "max", "(", "_logprobs", ".", "data", ",", "1", ")", "\n", "sampleLogprobs", "=", "logprobs", ".", "gather", "(", "1", ",", "it", ".", "unsqueeze", "(", "1", ")", ")", "# gather the logprobs at sampled positions", "\n", "", "else", ":", "\n", "            ", "logprobs", "=", "logprobs", "/", "temperature", "\n", "if", "sample_method", ".", "startswith", "(", "'top'", ")", ":", "# topk sampling", "\n", "                ", "top_num", "=", "float", "(", "sample_method", "[", "3", ":", "]", ")", "\n", "if", "0", "<", "top_num", "<", "1", ":", "\n", "# nucleus sampling from # The Curious Case of Neural Text Degeneration", "\n", "                    ", "probs", "=", "F", ".", "softmax", "(", "logprobs", ",", "dim", "=", "1", ")", "\n", "sorted_probs", ",", "sorted_indices", "=", "torch", ".", "sort", "(", "probs", ",", "descending", "=", "True", ",", "dim", "=", "1", ")", "\n", "_cumsum", "=", "sorted_probs", ".", "cumsum", "(", "1", ")", "\n", "mask", "=", "_cumsum", "<", "top_num", "\n", "mask", "=", "torch", ".", "cat", "(", "[", "torch", ".", "ones_like", "(", "mask", "[", ":", ",", ":", "1", "]", ")", ",", "mask", "[", ":", ",", ":", "-", "1", "]", "]", ",", "1", ")", "\n", "sorted_probs", "=", "sorted_probs", "*", "mask", ".", "float", "(", ")", "\n", "sorted_probs", "=", "sorted_probs", "/", "sorted_probs", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "logprobs", ".", "scatter_", "(", "1", ",", "sorted_indices", ",", "sorted_probs", ".", "log", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "the_k", "=", "int", "(", "top_num", ")", "\n", "tmp", "=", "torch", ".", "empty_like", "(", "logprobs", ")", ".", "fill_", "(", "float", "(", "'-inf'", ")", ")", "\n", "topk", ",", "indices", "=", "torch", ".", "topk", "(", "logprobs", ",", "the_k", ",", "dim", "=", "1", ")", "\n", "tmp", "=", "tmp", ".", "scatter", "(", "1", ",", "indices", ",", "topk", ")", "\n", "logprobs", "=", "tmp", "\n", "", "", "it", "=", "torch", ".", "distributions", ".", "Categorical", "(", "logits", "=", "logprobs", ".", "detach", "(", ")", ")", ".", "sample", "(", ")", "\n", "sampleLogprobs", "=", "logprobs", ".", "gather", "(", "1", ",", "it", ".", "unsqueeze", "(", "1", ")", ")", "# gather the logprobs at sampled positions", "\n", "", "return", "it", ",", "sampleLogprobs", "", "", "", ""]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AoAModel.MultiHeadedDotAttention.__init__": [[17, 54], ["torch.Module.__init__", "TransformerModel.clones", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "TransformerModel.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.GLU", "torch.GLU", "torch.GLU", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.clones"], ["    ", "def", "__init__", "(", "self", ",", "h", ",", "d_model", ",", "dropout", "=", "0.1", ",", "scale", "=", "1", ",", "project_k_v", "=", "1", ",", "use_output_layer", "=", "1", ",", "do_aoa", "=", "0", ",", "norm_q", "=", "0", ",", "dropout_aoa", "=", "0.3", ")", ":", "\n", "        ", "super", "(", "MultiHeadedDotAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "d_model", "*", "scale", "%", "h", "==", "0", "\n", "# We assume d_v always equals d_k", "\n", "self", ".", "d_k", "=", "d_model", "*", "scale", "//", "h", "\n", "self", ".", "h", "=", "h", "\n", "\n", "# Do we need to do linear projections on K and V?", "\n", "self", ".", "project_k_v", "=", "project_k_v", "\n", "\n", "# normalize the query?", "\n", "if", "norm_q", ":", "\n", "            ", "self", ".", "norm", "=", "LayerNorm", "(", "d_model", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "norm", "=", "lambda", "x", ":", "x", "\n", "", "self", ".", "linears", "=", "clones", "(", "nn", ".", "Linear", "(", "d_model", ",", "d_model", "*", "scale", ")", ",", "1", "+", "2", "*", "project_k_v", ")", "\n", "\n", "# output linear layer after the multi-head attention?", "\n", "self", ".", "output_layer", "=", "nn", ".", "Linear", "(", "d_model", "*", "scale", ",", "d_model", ")", "\n", "\n", "# apply aoa after attention?", "\n", "self", ".", "use_aoa", "=", "do_aoa", "\n", "if", "self", ".", "use_aoa", ":", "\n", "            ", "self", ".", "aoa_layer", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "(", "1", "+", "scale", ")", "*", "d_model", ",", "2", "*", "d_model", ")", ",", "nn", ".", "GLU", "(", ")", ")", "\n", "# dropout to the input of AoA layer", "\n", "if", "dropout_aoa", ">", "0", ":", "\n", "                ", "self", ".", "dropout_aoa", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout_aoa", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "dropout_aoa", "=", "lambda", "x", ":", "x", "\n", "\n", "", "", "if", "self", ".", "use_aoa", "or", "not", "use_output_layer", ":", "\n", "# AoA doesn't need the output linear layer", "\n", "            ", "del", "self", ".", "output_layer", "\n", "self", ".", "output_layer", "=", "lambda", "x", ":", "x", "\n", "\n", "", "self", ".", "attn", "=", "None", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AoAModel.MultiHeadedDotAttention.forward": [[55, 98], ["query.squeeze.squeeze.size", "AoAModel.MultiHeadedDotAttention.norm", "TransformerModel.attention", "x.squeeze.squeeze.transpose().contiguous().view", "AoAModel.MultiHeadedDotAttention.output_layer", "mask.unsqueeze.unsqueeze.unsqueeze", "len", "query.squeeze.squeeze.unsqueeze", "key.view().transpose", "value.view().transpose", "AoAModel.MultiHeadedDotAttention.aoa_layer", "query.squeeze.squeeze.squeeze", "x.squeeze.squeeze.squeeze", "len", "mask.unsqueeze.unsqueeze.unsqueeze", "query.squeeze.squeeze.size", "l().view().transpose", "x.squeeze.squeeze.transpose().contiguous", "AoAModel.MultiHeadedDotAttention.dropout_aoa", "mask.unsqueeze.unsqueeze.size", "key.view", "value.view", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "l().view", "x.squeeze.squeeze.transpose", "l"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.attention"], ["", "def", "forward", "(", "self", ",", "query", ",", "value", ",", "key", ",", "mask", "=", "None", ")", ":", "\n", "        ", "if", "mask", "is", "not", "None", ":", "\n", "            ", "if", "len", "(", "mask", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "                ", "mask", "=", "mask", ".", "unsqueeze", "(", "-", "2", ")", "\n", "# Same mask applied to all h heads.", "\n", "", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "single_query", "=", "0", "\n", "if", "len", "(", "query", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "            ", "single_query", "=", "1", "\n", "query", "=", "query", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "nbatches", "=", "query", ".", "size", "(", "0", ")", "\n", "\n", "query", "=", "self", ".", "norm", "(", "query", ")", "\n", "\n", "# Do all the linear projections in batch from d_model => h x d_k ", "\n", "if", "self", ".", "project_k_v", "==", "0", ":", "\n", "            ", "query_", "=", "self", ".", "linears", "[", "0", "]", "(", "query", ")", ".", "view", "(", "nbatches", ",", "-", "1", ",", "self", ".", "h", ",", "self", ".", "d_k", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "key_", "=", "key", ".", "view", "(", "nbatches", ",", "-", "1", ",", "self", ".", "h", ",", "self", ".", "d_k", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "value_", "=", "value", ".", "view", "(", "nbatches", ",", "-", "1", ",", "self", ".", "h", ",", "self", ".", "d_k", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "", "else", ":", "\n", "            ", "query_", ",", "key_", ",", "value_", "=", "[", "l", "(", "x", ")", ".", "view", "(", "nbatches", ",", "-", "1", ",", "self", ".", "h", ",", "self", ".", "d_k", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "for", "l", ",", "x", "in", "zip", "(", "self", ".", "linears", ",", "(", "query", ",", "key", ",", "value", ")", ")", "]", "\n", "\n", "# Apply attention on all the projected vectors in batch. ", "\n", "", "x", ",", "self", ".", "attn", "=", "attention", "(", "query_", ",", "key_", ",", "value_", ",", "mask", "=", "mask", ",", "\n", "dropout", "=", "self", ".", "dropout", ")", "\n", "\n", "# \"Concat\" using a view", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "nbatches", ",", "-", "1", ",", "self", ".", "h", "*", "self", ".", "d_k", ")", "\n", "\n", "if", "self", ".", "use_aoa", ":", "\n", "# Apply AoA", "\n", "            ", "x", "=", "self", ".", "aoa_layer", "(", "self", ".", "dropout_aoa", "(", "torch", ".", "cat", "(", "[", "x", ",", "query", "]", ",", "-", "1", ")", ")", ")", "\n", "", "x", "=", "self", ".", "output_layer", "(", "x", ")", "\n", "\n", "if", "single_query", ":", "\n", "            ", "query", "=", "query", ".", "squeeze", "(", "1", ")", "\n", "x", "=", "x", ".", "squeeze", "(", "1", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AoAModel.AoA_Refiner_Layer.__init__": [[100, 109], ["torch.Module.__init__", "TransformerModel.clones", "TransformerModel.SublayerConnection"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.clones"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "self_attn", ",", "feed_forward", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "AoA_Refiner_Layer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "self_attn", "\n", "self", ".", "feed_forward", "=", "feed_forward", "\n", "self", ".", "use_ff", "=", "0", "\n", "if", "self", ".", "feed_forward", "is", "not", "None", ":", "\n", "            ", "self", ".", "use_ff", "=", "1", "\n", "", "self", ".", "sublayer", "=", "clones", "(", "SublayerConnection", "(", "size", ",", "dropout", ")", ",", "1", "+", "self", ".", "use_ff", ")", "\n", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AoAModel.AoA_Refiner_Layer.forward": [[110, 113], ["AoAModel.AoA_Refiner_Layer.self_attn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "x", "=", "self", ".", "sublayer", "[", "0", "]", "(", "x", ",", "lambda", "x", ":", "self", ".", "self_attn", "(", "x", ",", "x", ",", "x", ",", "mask", ")", ")", "\n", "return", "self", ".", "sublayer", "[", "-", "1", "]", "(", "x", ",", "self", ".", "feed_forward", ")", "if", "self", ".", "use_ff", "else", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AoAModel.AoA_Refiner_Core.__init__": [[115, 121], ["torch.Module.__init__", "AoAModel.MultiHeadedDotAttention", "AoAModel.AoA_Refiner_Layer", "TransformerModel.clones", "TransformerModel.LayerNorm", "getattr", "TransformerModel.PositionwiseFeedForward"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.clones"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AoA_Refiner_Core", ",", "self", ")", ".", "__init__", "(", ")", "\n", "attn", "=", "MultiHeadedDotAttention", "(", "opt", ".", "num_heads", ",", "opt", ".", "rnn_size", ",", "project_k_v", "=", "1", ",", "scale", "=", "opt", ".", "multi_head_scale", ",", "do_aoa", "=", "opt", ".", "refine_aoa", ",", "norm_q", "=", "0", ",", "dropout_aoa", "=", "getattr", "(", "opt", ",", "'dropout_aoa'", ",", "0.3", ")", ")", "\n", "layer", "=", "AoA_Refiner_Layer", "(", "opt", ".", "rnn_size", ",", "attn", ",", "PositionwiseFeedForward", "(", "opt", ".", "rnn_size", ",", "2048", ",", "0.1", ")", "if", "opt", ".", "use_ff", "else", "None", ",", "0.1", ")", "\n", "self", ".", "layers", "=", "clones", "(", "layer", ",", "6", ")", "\n", "self", ".", "norm", "=", "LayerNorm", "(", "layer", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AoAModel.AoA_Refiner_Core.forward": [[122, 126], ["AoAModel.AoA_Refiner_Core.norm", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ",", "mask", ")", "\n", "", "return", "self", ".", "norm", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AoAModel.AoA_Decoder_Core.__init__": [[128, 161], ["torch.Module.__init__", "getattr", "getattr", "getattr", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Sequential", "torch.Sequential", "torch.Sequential", "AoAModel.MultiHeadedDotAttention", "AttModel.AttModel.Attention", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.GLU", "torch.GLU", "torch.GLU", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AoA_Decoder_Core", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "d_model", "=", "opt", ".", "rnn_size", "\n", "self", ".", "use_multi_head", "=", "opt", ".", "use_multi_head", "\n", "self", ".", "multi_head_scale", "=", "opt", ".", "multi_head_scale", "\n", "self", ".", "use_ctx_drop", "=", "getattr", "(", "opt", ",", "'ctx_drop'", ",", "0", ")", "\n", "self", ".", "out_res", "=", "getattr", "(", "opt", ",", "'out_res'", ",", "0", ")", "\n", "self", ".", "decoder_type", "=", "getattr", "(", "opt", ",", "'decoder_type'", ",", "'AoA'", ")", "\n", "self", ".", "att_lstm", "=", "nn", ".", "LSTMCell", "(", "opt", ".", "input_encoding_size", "+", "opt", ".", "rnn_size", ",", "opt", ".", "rnn_size", ")", "# we, fc, h^2_t-1", "\n", "self", ".", "out_drop", "=", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", "\n", "\n", "if", "self", ".", "decoder_type", "==", "'AoA'", ":", "\n", "# AoA layer", "\n", "            ", "self", ".", "att2ctx", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "d_model", "*", "opt", ".", "multi_head_scale", "+", "opt", ".", "rnn_size", ",", "2", "*", "opt", ".", "rnn_size", ")", ",", "nn", ".", "GLU", "(", ")", ")", "\n", "", "elif", "self", ".", "decoder_type", "==", "'LSTM'", ":", "\n", "# LSTM layer", "\n", "            ", "self", ".", "att2ctx", "=", "nn", ".", "LSTMCell", "(", "self", ".", "d_model", "*", "opt", ".", "multi_head_scale", "+", "opt", ".", "rnn_size", ",", "opt", ".", "rnn_size", ")", "\n", "", "else", ":", "\n", "# Base linear layer", "\n", "            ", "self", ".", "att2ctx", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "d_model", "*", "opt", ".", "multi_head_scale", "+", "opt", ".", "rnn_size", ",", "opt", ".", "rnn_size", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "# if opt.use_multi_head == 1: # TODO, not implemented for now           ", "\n", "#     self.attention = MultiHeadedAddAttention(opt.num_heads, opt.d_model, scale=opt.multi_head_scale)", "\n", "", "if", "opt", ".", "use_multi_head", "==", "2", ":", "\n", "            ", "self", ".", "attention", "=", "MultiHeadedDotAttention", "(", "opt", ".", "num_heads", ",", "opt", ".", "rnn_size", ",", "project_k_v", "=", "0", ",", "scale", "=", "opt", ".", "multi_head_scale", ",", "use_output_layer", "=", "0", ",", "do_aoa", "=", "0", ",", "norm_q", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "attention", "=", "Attention", "(", "opt", ")", "\n", "\n", "", "if", "self", ".", "use_ctx_drop", ":", "\n", "            ", "self", ".", "ctx_drop", "=", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ctx_drop", "=", "lambda", "x", ":", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AoAModel.AoA_Decoder_Core.forward": [[162, 186], ["AoAModel.AoA_Decoder_Core.att_lstm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "AoAModel.AoA_Decoder_Core.out_drop", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "AoAModel.AoA_Decoder_Core.attention", "AoAModel.AoA_Decoder_Core.attention", "AoAModel.AoA_Decoder_Core.att2ctx", "AoAModel.AoA_Decoder_Core.att2ctx", "p_att_feats.narrow", "p_att_feats.narrow", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "AoAModel.AoA_Decoder_Core.ctx_drop"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.attention", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.attention"], ["", "", "def", "forward", "(", "self", ",", "xt", ",", "mean_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ",", "att_masks", "=", "None", ")", ":", "\n", "# state[0][1] is the context vector at the last step", "\n", "        ", "h_att", ",", "c_att", "=", "self", ".", "att_lstm", "(", "torch", ".", "cat", "(", "[", "xt", ",", "mean_feats", "+", "self", ".", "ctx_drop", "(", "state", "[", "0", "]", "[", "1", "]", ")", "]", ",", "1", ")", ",", "(", "state", "[", "0", "]", "[", "0", "]", ",", "state", "[", "1", "]", "[", "0", "]", ")", ")", "\n", "\n", "if", "self", ".", "use_multi_head", "==", "2", ":", "\n", "            ", "att", "=", "self", ".", "attention", "(", "h_att", ",", "p_att_feats", ".", "narrow", "(", "2", ",", "0", ",", "self", ".", "multi_head_scale", "*", "self", ".", "d_model", ")", ",", "p_att_feats", ".", "narrow", "(", "2", ",", "self", ".", "multi_head_scale", "*", "self", ".", "d_model", ",", "self", ".", "multi_head_scale", "*", "self", ".", "d_model", ")", ",", "att_masks", ")", "\n", "", "else", ":", "\n", "            ", "att", "=", "self", ".", "attention", "(", "h_att", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", ")", "\n", "\n", "", "ctx_input", "=", "torch", ".", "cat", "(", "[", "att", ",", "h_att", "]", ",", "1", ")", "\n", "if", "self", ".", "decoder_type", "==", "'LSTM'", ":", "\n", "            ", "output", ",", "c_logic", "=", "self", ".", "att2ctx", "(", "ctx_input", ",", "(", "state", "[", "0", "]", "[", "1", "]", ",", "state", "[", "1", "]", "[", "1", "]", ")", ")", "\n", "state", "=", "(", "torch", ".", "stack", "(", "(", "h_att", ",", "output", ")", ")", ",", "torch", ".", "stack", "(", "(", "c_att", ",", "c_logic", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "att2ctx", "(", "ctx_input", ")", "\n", "# save the context vector to state[0][1]", "\n", "state", "=", "(", "torch", ".", "stack", "(", "(", "h_att", ",", "output", ")", ")", ",", "torch", ".", "stack", "(", "(", "c_att", ",", "state", "[", "1", "]", "[", "1", "]", ")", ")", ")", "\n", "\n", "", "if", "self", ".", "out_res", ":", "\n", "# add residual connection", "\n", "            ", "output", "=", "output", "+", "h_att", "\n", "\n", "", "output", "=", "self", ".", "out_drop", "(", "output", ")", "\n", "return", "output", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AoAModel.AoAModel.__init__": [[188, 204], ["AttModel.AttModel.__init__", "getattr", "AoAModel.AoA_Decoder_Core", "torch.Linear", "torch.Linear", "torch.Linear", "AoAModel.AoA_Refiner_Core"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AoAModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "num_layers", "=", "2", "\n", "# mean pooling", "\n", "self", ".", "use_mean_feats", "=", "getattr", "(", "opt", ",", "'mean_feats'", ",", "1", ")", "\n", "if", "opt", ".", "use_multi_head", "==", "2", ":", "\n", "            ", "del", "self", ".", "ctx2att", "\n", "self", ".", "ctx2att", "=", "nn", ".", "Linear", "(", "opt", ".", "rnn_size", ",", "2", "*", "opt", ".", "multi_head_scale", "*", "opt", ".", "rnn_size", ")", "\n", "\n", "", "if", "self", ".", "use_mean_feats", ":", "\n", "            ", "del", "self", ".", "fc_embed", "\n", "", "if", "opt", ".", "refine", ":", "\n", "            ", "self", ".", "refiner", "=", "AoA_Refiner_Core", "(", "opt", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "refiner", "=", "lambda", "x", ",", "y", ":", "x", "\n", "", "self", ".", "core", "=", "AoA_Decoder_Core", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AoAModel.AoAModel._prepare_feature": [[206, 226], ["AoAModel.AoAModel.clip_att", "AttModel.AttModel.pack_wrapper", "AoAModel.AoAModel.refiner", "AoAModel.AoAModel.ctx2att", "AoAModel.AoAModel.fc_embed", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "att_masks.unsqueeze", "att_masks.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AttModel.clip_att", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.pack_wrapper"], ["", "def", "_prepare_feature", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "att_masks", ")", ":", "\n", "        ", "att_feats", ",", "att_masks", "=", "self", ".", "clip_att", "(", "att_feats", ",", "att_masks", ")", "\n", "\n", "# embed att feats", "\n", "att_feats", "=", "pack_wrapper", "(", "self", ".", "att_embed", ",", "att_feats", ",", "att_masks", ")", "\n", "att_feats", "=", "self", ".", "refiner", "(", "att_feats", ",", "att_masks", ")", "\n", "\n", "if", "self", ".", "use_mean_feats", ":", "\n", "# meaning pooling", "\n", "            ", "if", "att_masks", "is", "None", ":", "\n", "                ", "mean_feats", "=", "torch", ".", "mean", "(", "att_feats", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "mean_feats", "=", "(", "torch", ".", "sum", "(", "att_feats", "*", "att_masks", ".", "unsqueeze", "(", "-", "1", ")", ",", "1", ")", "/", "torch", ".", "sum", "(", "att_masks", ".", "unsqueeze", "(", "-", "1", ")", ",", "1", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "mean_feats", "=", "self", ".", "fc_embed", "(", "fc_feats", ")", "\n", "\n", "# Project the attention feats first to reduce memory and computation.", "\n", "", "p_att_feats", "=", "self", ".", "ctx2att", "(", "att_feats", ")", "\n", "\n", "return", "mean_feats", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", "", "", "", ""]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.EncoderDecoder.__init__": [[31, 38], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ",", "src_embed", ",", "tgt_embed", ",", "generator", ")", ":", "\n", "        ", "super", "(", "EncoderDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "src_embed", "=", "src_embed", "\n", "self", ".", "tgt_embed", "=", "tgt_embed", "\n", "self", ".", "generator", "=", "generator", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.EncoderDecoder.forward": [[39, 43], ["TransformerModel.EncoderDecoder.decode", "TransformerModel.EncoderDecoder.encode"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.EncoderDecoder.decode", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.EncoderDecoder.encode"], ["", "def", "forward", "(", "self", ",", "src", ",", "tgt", ",", "src_mask", ",", "tgt_mask", ")", ":", "\n", "        ", "\"Take in and process masked src and target sequences.\"", "\n", "return", "self", ".", "decode", "(", "self", ".", "encode", "(", "src", ",", "src_mask", ")", ",", "src_mask", ",", "\n", "tgt", ",", "tgt_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.EncoderDecoder.encode": [[44, 46], ["TransformerModel.EncoderDecoder.encoder", "TransformerModel.EncoderDecoder.src_embed"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "src", ",", "src_mask", ")", ":", "\n", "        ", "return", "self", ".", "encoder", "(", "self", ".", "src_embed", "(", "src", ")", ",", "src_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.EncoderDecoder.decode": [[47, 49], ["TransformerModel.EncoderDecoder.decoder", "TransformerModel.EncoderDecoder.tgt_embed"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "memory", ",", "src_mask", ",", "tgt", ",", "tgt_mask", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "(", "self", ".", "tgt_embed", "(", "tgt", ")", ",", "memory", ",", "src_mask", ",", "tgt_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.Generator.__init__": [[52, 55], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "vocab", ")", ":", "\n", "        ", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "d_model", ",", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.Generator.forward": [[56, 58], ["torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "TransformerModel.Generator.proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "F", ".", "log_softmax", "(", "self", ".", "proj", "(", "x", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.Encoder.__init__": [[65, 69], ["torch.Module.__init__", "TransformerModel.clones", "TransformerModel.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.clones"], ["def", "__init__", "(", "self", ",", "layer", ",", "N", ")", ":", "\n", "        ", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "clones", "(", "layer", ",", "N", ")", "\n", "self", ".", "norm", "=", "LayerNorm", "(", "layer", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.Encoder.forward": [[70, 75], ["TransformerModel.Encoder.norm", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "\"Pass the input (and mask) through each layer in turn.\"", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ",", "mask", ")", "\n", "", "return", "self", ".", "norm", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.LayerNorm.__init__": [[78, 83], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["def", "__init__", "(", "self", ",", "features", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", "LayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "a_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "features", ")", ")", "\n", "self", ".", "b_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "features", ")", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.LayerNorm.forward": [[84, 88], ["x.mean", "x.std"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "mean", "=", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "std", "=", "x", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "self", ".", "a_2", "*", "(", "x", "-", "mean", ")", "/", "(", "std", "+", "self", ".", "eps", ")", "+", "self", ".", "b_2", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.SublayerConnection.__init__": [[94, 98], ["torch.Module.__init__", "TransformerModel.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["def", "__init__", "(", "self", ",", "size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "SublayerConnection", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm", "=", "LayerNorm", "(", "size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.SublayerConnection.forward": [[99, 102], ["TransformerModel.SublayerConnection.dropout", "sublayer", "TransformerModel.SublayerConnection.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "sublayer", ")", ":", "\n", "        ", "\"Apply residual connection to any sublayer with the same size.\"", "\n", "return", "x", "+", "self", ".", "dropout", "(", "sublayer", "(", "self", ".", "norm", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.EncoderLayer.__init__": [[105, 111], ["torch.Module.__init__", "TransformerModel.clones", "TransformerModel.SublayerConnection"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.clones"], ["def", "__init__", "(", "self", ",", "size", ",", "self_attn", ",", "feed_forward", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "EncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "self_attn", "\n", "self", ".", "feed_forward", "=", "feed_forward", "\n", "self", ".", "sublayer", "=", "clones", "(", "SublayerConnection", "(", "size", ",", "dropout", ")", ",", "2", ")", "\n", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.EncoderLayer.forward": [[112, 116], ["TransformerModel.EncoderLayer.self_attn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "\"Follow Figure 1 (left) for connections.\"", "\n", "x", "=", "self", ".", "sublayer", "[", "0", "]", "(", "x", ",", "lambda", "x", ":", "self", ".", "self_attn", "(", "x", ",", "x", ",", "x", ",", "mask", ")", ")", "\n", "return", "self", ".", "sublayer", "[", "1", "]", "(", "x", ",", "self", ".", "feed_forward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.Decoder.__init__": [[119, 123], ["torch.Module.__init__", "TransformerModel.clones", "TransformerModel.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.clones"], ["def", "__init__", "(", "self", ",", "layer", ",", "N", ")", ":", "\n", "        ", "super", "(", "Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "clones", "(", "layer", ",", "N", ")", "\n", "self", ".", "norm", "=", "LayerNorm", "(", "layer", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.Decoder.forward": [[124, 128], ["TransformerModel.Decoder.norm", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "memory", ",", "src_mask", ",", "tgt_mask", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ",", "memory", ",", "src_mask", ",", "tgt_mask", ")", "\n", "", "return", "self", ".", "norm", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.DecoderLayer.__init__": [[131, 138], ["torch.Module.__init__", "TransformerModel.clones", "TransformerModel.SublayerConnection"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.clones"], ["def", "__init__", "(", "self", ",", "size", ",", "self_attn", ",", "src_attn", ",", "feed_forward", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "DecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "self_attn", "=", "self_attn", "\n", "self", ".", "src_attn", "=", "src_attn", "\n", "self", ".", "feed_forward", "=", "feed_forward", "\n", "self", ".", "sublayer", "=", "clones", "(", "SublayerConnection", "(", "size", ",", "dropout", ")", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.DecoderLayer.forward": [[139, 145], ["TransformerModel.DecoderLayer.self_attn", "TransformerModel.DecoderLayer.src_attn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "memory", ",", "src_mask", ",", "tgt_mask", ")", ":", "\n", "        ", "\"Follow Figure 1 (right) for connections.\"", "\n", "m", "=", "memory", "\n", "x", "=", "self", ".", "sublayer", "[", "0", "]", "(", "x", ",", "lambda", "x", ":", "self", ".", "self_attn", "(", "x", ",", "x", ",", "x", ",", "tgt_mask", ")", ")", "\n", "x", "=", "self", ".", "sublayer", "[", "1", "]", "(", "x", ",", "lambda", "x", ":", "self", ".", "src_attn", "(", "x", ",", "m", ",", "m", ",", "src_mask", ")", ")", "\n", "return", "self", ".", "sublayer", "[", "2", "]", "(", "x", ",", "self", ".", "feed_forward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.MultiHeadedAttention.__init__": [[165, 175], ["torch.Module.__init__", "TransformerModel.clones", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.clones"], ["    ", "def", "__init__", "(", "self", ",", "h", ",", "d_model", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "\"Take in model size and number of heads.\"", "\n", "super", "(", "MultiHeadedAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "d_model", "%", "h", "==", "0", "\n", "# We assume d_v always equals d_k", "\n", "self", ".", "d_k", "=", "d_model", "//", "h", "\n", "self", ".", "h", "=", "h", "\n", "self", ".", "linears", "=", "clones", "(", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ")", ",", "4", ")", "\n", "self", ".", "attn", "=", "None", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.MultiHeadedAttention.forward": [[176, 196], ["query.size", "TransformerModel.attention", "x.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "mask.unsqueeze.unsqueeze.unsqueeze", "l().view().transpose", "zip", "x.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "l().view", "x.transpose().contiguous().view.transpose().contiguous().view.transpose", "l"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.attention"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"Implements Figure 2\"", "\n", "if", "mask", "is", "not", "None", ":", "\n", "# Same mask applied to all h heads.", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "", "nbatches", "=", "query", ".", "size", "(", "0", ")", "\n", "\n", "# 1) Do all the linear projections in batch from d_model => h x d_k ", "\n", "query", ",", "key", ",", "value", "=", "[", "l", "(", "x", ")", ".", "view", "(", "nbatches", ",", "-", "1", ",", "self", ".", "h", ",", "self", ".", "d_k", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "for", "l", ",", "x", "in", "zip", "(", "self", ".", "linears", ",", "(", "query", ",", "key", ",", "value", ")", ")", "]", "\n", "\n", "# 2) Apply attention on all the projected vectors in batch. ", "\n", "x", ",", "self", ".", "attn", "=", "attention", "(", "query", ",", "key", ",", "value", ",", "mask", "=", "mask", ",", "\n", "dropout", "=", "self", ".", "dropout", ")", "\n", "\n", "# 3) \"Concat\" using a view and apply a final linear. ", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "nbatches", ",", "-", "1", ",", "self", ".", "h", "*", "self", ".", "d_k", ")", "\n", "return", "self", ".", "linears", "[", "-", "1", "]", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.PositionwiseFeedForward.__init__": [[199, 204], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "d_ff", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "PositionwiseFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_ff", ")", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_ff", ",", "d_model", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.PositionwiseFeedForward.forward": [[205, 207], ["TransformerModel.PositionwiseFeedForward.w_2", "TransformerModel.PositionwiseFeedForward.dropout", "torch.relu", "torch.relu", "torch.relu", "TransformerModel.PositionwiseFeedForward.w_1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "w_2", "(", "self", ".", "dropout", "(", "F", ".", "relu", "(", "self", ".", "w_1", "(", "x", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.Embeddings.__init__": [[209, 213], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "vocab", ")", ":", "\n", "        ", "super", "(", "Embeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lut", "=", "nn", ".", "Embedding", "(", "vocab", ",", "d_model", ")", "\n", "self", ".", "d_model", "=", "d_model", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.Embeddings.forward": [[214, 216], ["TransformerModel.Embeddings.lut", "math.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "lut", "(", "x", ")", "*", "math", ".", "sqrt", "(", "self", ".", "d_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.PositionalEncoding.__init__": [[219, 232], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze().float", "torch.arange().unsqueeze().float", "torch.arange().unsqueeze().float", "torch.arange().unsqueeze().float", "torch.arange().unsqueeze().float", "torch.arange().unsqueeze().float", "torch.arange().unsqueeze().float", "torch.arange().unsqueeze().float", "torch.arange().unsqueeze().float", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "pe.unsqueeze.unsqueeze.unsqueeze", "TransformerModel.PositionalEncoding.register_buffer", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "math.log"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "dropout", ",", "max_len", "=", "5000", ")", ":", "\n", "        ", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n", "# Compute the positional encodings once in log space.", "\n", "pe", "=", "torch", ".", "zeros", "(", "max_len", ",", "d_model", ")", "\n", "position", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "unsqueeze", "(", "1", ")", ".", "float", "(", ")", "\n", "div_term", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "0", ",", "d_model", ",", "2", ")", ".", "float", "(", ")", "*", "\n", "-", "(", "math", ".", "log", "(", "10000.0", ")", "/", "d_model", ")", ")", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", "*", "div_term", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", "*", "div_term", ")", "\n", "pe", "=", "pe", ".", "unsqueeze", "(", "0", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.PositionalEncoding.forward": [[233, 236], ["TransformerModel.PositionalEncoding.dropout", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "pe", "[", ":", ",", ":", "x", ".", "size", "(", "1", ")", "]", "\n", "return", "self", ".", "dropout", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.make_model": [[239, 260], ["TransformerModel.MultiHeadedAttention", "TransformerModel.PositionwiseFeedForward", "TransformerModel.PositionalEncoding", "TransformerModel.EncoderDecoder", "EncoderDecoder.parameters", "TransformerModel.Encoder", "TransformerModel.Decoder", "torch.Sequential", "torch.Sequential", "torch.Sequential", "TransformerModel.Generator", "TransformerModel.EncoderLayer", "TransformerModel.DecoderLayer", "TransformerModel.Embeddings", "c", "p.dim", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "c", "c", "c", "c", "c"], "methods", ["None"], ["    ", "def", "make_model", "(", "self", ",", "src_vocab", ",", "tgt_vocab", ",", "N", "=", "6", ",", "\n", "d_model", "=", "512", ",", "d_ff", "=", "2048", ",", "h", "=", "8", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "\"Helper: Construct a model from hyperparameters.\"", "\n", "c", "=", "copy", ".", "deepcopy", "\n", "attn", "=", "MultiHeadedAttention", "(", "h", ",", "d_model", ")", "\n", "ff", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_ff", ",", "dropout", ")", "\n", "position", "=", "PositionalEncoding", "(", "d_model", ",", "dropout", ")", "\n", "model", "=", "EncoderDecoder", "(", "\n", "Encoder", "(", "EncoderLayer", "(", "d_model", ",", "c", "(", "attn", ")", ",", "c", "(", "ff", ")", ",", "dropout", ")", ",", "N", ")", ",", "\n", "Decoder", "(", "DecoderLayer", "(", "d_model", ",", "c", "(", "attn", ")", ",", "c", "(", "attn", ")", ",", "\n", "c", "(", "ff", ")", ",", "dropout", ")", ",", "N", ")", ",", "\n", "lambda", "x", ":", "x", ",", "# nn.Sequential(Embeddings(d_model, src_vocab), c(position)),", "\n", "nn", ".", "Sequential", "(", "Embeddings", "(", "d_model", ",", "tgt_vocab", ")", ",", "c", "(", "position", ")", ")", ",", "\n", "Generator", "(", "d_model", ",", "tgt_vocab", ")", ")", "\n", "\n", "# This was important from their code. ", "\n", "# Initialize parameters with Glorot / fan_avg.", "\n", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "p", ")", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.__init__": [[261, 287], ["AttModel.AttModel.__init__", "delattr", "torch.Sequential", "torch.Sequential", "torch.Sequential", "delattr", "delattr", "delattr", "TransformerModel.TransformerModel.make_model", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.make_model"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "TransformerModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "# self.config = yaml.load(open(opt.config_file))", "\n", "# d_model = self.input_encoding_size # 512", "\n", "\n", "delattr", "(", "self", ",", "'att_embed'", ")", "\n", "self", ".", "att_embed", "=", "nn", ".", "Sequential", "(", "*", "(", "\n", "(", "(", "nn", ".", "BatchNorm1d", "(", "self", ".", "att_feat_size", ")", ",", ")", "if", "self", ".", "use_bn", "else", "(", ")", ")", "+", "\n", "(", "nn", ".", "Linear", "(", "self", ".", "att_feat_size", ",", "self", ".", "input_encoding_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", ")", "+", "\n", "(", "(", "nn", ".", "BatchNorm1d", "(", "self", ".", "input_encoding_size", ")", ",", ")", "if", "self", ".", "use_bn", "==", "2", "else", "(", ")", ")", ")", ")", "\n", "\n", "delattr", "(", "self", ",", "'embed'", ")", "\n", "self", ".", "embed", "=", "lambda", "x", ":", "x", "\n", "delattr", "(", "self", ",", "'fc_embed'", ")", "\n", "self", ".", "fc_embed", "=", "lambda", "x", ":", "x", "\n", "delattr", "(", "self", ",", "'logit'", ")", "\n", "del", "self", ".", "ctx2att", "\n", "\n", "tgt_vocab", "=", "self", ".", "vocab_size", "+", "1", "\n", "self", ".", "model", "=", "self", ".", "make_model", "(", "0", ",", "tgt_vocab", ",", "\n", "N", "=", "opt", ".", "num_layers", ",", "\n", "d_model", "=", "opt", ".", "input_encoding_size", ",", "\n", "d_ff", "=", "opt", ".", "rnn_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.logit": [[288, 290], ["TransformerModel.TransformerModel.model.generator.proj"], "methods", ["None"], ["", "def", "logit", "(", "self", ",", "x", ")", ":", "# unsafe way", "\n", "        ", "return", "self", ".", "model", ".", "generator", ".", "proj", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.init_hidden": [[291, 293], ["None"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel._prepare_feature": [[294, 300], ["TransformerModel.TransformerModel._prepare_feature_forward", "TransformerModel.TransformerModel.model.encode"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel._prepare_feature_forward", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.EncoderDecoder.encode"], ["", "def", "_prepare_feature", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "att_masks", ")", ":", "\n", "\n", "        ", "att_feats", ",", "seq", ",", "att_masks", ",", "seq_mask", "=", "self", ".", "_prepare_feature_forward", "(", "att_feats", ",", "att_masks", ")", "\n", "memory", "=", "self", ".", "model", ".", "encode", "(", "att_feats", ",", "att_masks", ")", "\n", "\n", "return", "fc_feats", "[", "...", ",", ":", "1", "]", ",", "att_feats", "[", "...", ",", ":", "1", "]", ",", "memory", ",", "att_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel._prepare_feature_forward": [[301, 322], ["TransformerModel.TransformerModel.clip_att", "AttModel.AttModel.pack_wrapper", "AttModel.pack_wrapper.new_ones.unsqueeze", "AttModel.AttModel.pack_wrapper.new_ones", "seq_mask.unsqueeze.unsqueeze.unsqueeze", "subsequent_mask().to", "TransformerModel.subsequent_mask", "seq.size"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.AttModel.clip_att", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttModel.pack_wrapper", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.subsequent_mask"], ["", "def", "_prepare_feature_forward", "(", "self", ",", "att_feats", ",", "att_masks", "=", "None", ",", "seq", "=", "None", ")", ":", "\n", "        ", "att_feats", ",", "att_masks", "=", "self", ".", "clip_att", "(", "att_feats", ",", "att_masks", ")", "\n", "\n", "att_feats", "=", "pack_wrapper", "(", "self", ".", "att_embed", ",", "att_feats", ",", "att_masks", ")", "\n", "\n", "if", "att_masks", "is", "None", ":", "\n", "            ", "att_masks", "=", "att_feats", ".", "new_ones", "(", "att_feats", ".", "shape", "[", ":", "2", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "att_masks", "=", "att_masks", ".", "unsqueeze", "(", "-", "2", ")", "\n", "\n", "if", "seq", "is", "not", "None", ":", "\n", "# crop the last one", "\n", "            ", "seq", "=", "seq", "[", ":", ",", ":", "-", "1", "]", "\n", "seq_mask", "=", "(", "seq", ".", "data", ">", "0", ")", "\n", "seq_mask", "[", ":", ",", "0", "]", "+=", "1", "\n", "\n", "seq_mask", "=", "seq_mask", ".", "unsqueeze", "(", "-", "2", ")", "\n", "seq_mask", "=", "seq_mask", "&", "subsequent_mask", "(", "seq", ".", "size", "(", "-", "1", ")", ")", ".", "to", "(", "seq_mask", ")", "\n", "", "else", ":", "\n", "            ", "seq_mask", "=", "None", "\n", "\n", "", "return", "att_feats", ",", "seq", ",", "att_masks", ",", "seq_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel._forward": [[323, 330], ["TransformerModel.TransformerModel._prepare_feature_forward", "TransformerModel.TransformerModel.model", "TransformerModel.TransformerModel.model.generator"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel._prepare_feature_forward"], ["", "def", "_forward", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "seq", ",", "att_masks", "=", "None", ")", ":", "\n", "        ", "att_feats", ",", "seq", ",", "att_masks", ",", "seq_mask", "=", "self", ".", "_prepare_feature_forward", "(", "att_feats", ",", "att_masks", ",", "seq", ")", "\n", "\n", "out", "=", "self", ".", "model", "(", "att_feats", ",", "seq", ",", "att_masks", ",", "seq_mask", ")", "\n", "\n", "outputs", "=", "self", ".", "model", ".", "generator", "(", "out", ")", "\n", "return", "outputs", "\n", "# return torch.cat([_.unsqueeze(1) for _ in outputs], 1)", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.core": [[332, 345], ["TransformerModel.TransformerModel.model.decode", "len", "it.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "subsequent_mask().to", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "it.unsqueeze", "TransformerModel.subsequent_mask", "torch.cat.size", "torch.cat.size", "torch.cat.size"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.EncoderDecoder.decode", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.subsequent_mask"], ["", "def", "core", "(", "self", ",", "it", ",", "fc_feats_ph", ",", "att_feats_ph", ",", "memory", ",", "state", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        state = [ys.unsqueeze(0)]\n        \"\"\"", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "            ", "ys", "=", "it", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "ys", "=", "torch", ".", "cat", "(", "[", "state", "[", "0", "]", "[", "0", "]", ",", "it", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "out", "=", "self", ".", "model", ".", "decode", "(", "memory", ",", "mask", ",", "\n", "ys", ",", "\n", "subsequent_mask", "(", "ys", ".", "size", "(", "1", ")", ")", "\n", ".", "to", "(", "memory", ".", "device", ")", ")", "\n", "return", "out", "[", ":", ",", "-", "1", "]", ",", "[", "ys", ".", "unsqueeze", "(", "0", ")", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.clones": [[59, 62], ["torch.ModuleList", "copy.deepcopy", "range"], "function", ["None"], ["", "", "def", "clones", "(", "module", ",", "N", ")", ":", "\n", "    ", "\"Produce N identical layers.\"", "\n", "return", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "module", ")", "for", "_", "in", "range", "(", "N", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.subsequent_mask": [[146, 151], ["numpy.triu().astype", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.triu", "numpy.ones"], "function", ["None"], ["", "", "def", "subsequent_mask", "(", "size", ")", ":", "\n", "    ", "\"Mask out subsequent positions.\"", "\n", "attn_shape", "=", "(", "1", ",", "size", ",", "size", ")", "\n", "subsequent_mask", "=", "np", ".", "triu", "(", "np", ".", "ones", "(", "attn_shape", ")", ",", "k", "=", "1", ")", ".", "astype", "(", "'uint8'", ")", "\n", "return", "torch", ".", "from_numpy", "(", "subsequent_mask", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.attention": [[152, 163], ["query.size", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "math.sqrt", "scores.masked_fill.masked_fill", "dropout", "torch.matmul", "torch.matmul", "torch.matmul", "key.transpose"], "function", ["None"], ["", "def", "attention", "(", "query", ",", "key", ",", "value", ",", "mask", "=", "None", ",", "dropout", "=", "None", ")", ":", "\n", "    ", "\"Compute 'Scaled Dot Product Attention'\"", "\n", "d_k", "=", "query", ".", "size", "(", "-", "1", ")", "\n", "scores", "=", "torch", ".", "matmul", "(", "query", ",", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "/", "math", ".", "sqrt", "(", "d_k", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "scores", "=", "scores", ".", "masked_fill", "(", "mask", "==", "0", ",", "-", "1e9", ")", "\n", "", "p_attn", "=", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "\n", "if", "dropout", "is", "not", "None", ":", "\n", "        ", "p_attn", "=", "dropout", "(", "p_attn", ")", "\n", "", "return", "torch", ".", "matmul", "(", "p_attn", ",", "value", ")", ",", "p_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AATModel.AATCore.__init__": [[19, 49], ["torch.Module.__init__", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "TransformerModel.LayerNorm", "TransformerModel.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "AoAModel.MultiHeadedDotAttention", "AttModel.AttModel.Attention"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AATCore", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "epsilon", "=", "opt", ".", "epsilon", "\n", "self", ".", "max_att_steps", "=", "opt", ".", "max_att_steps", "\n", "self", ".", "use_multi_head", "=", "opt", ".", "use_multi_head", "\n", "\n", "self", ".", "att_lstm", "=", "nn", ".", "LSTMCell", "(", "opt", ".", "input_encoding_size", "+", "opt", ".", "rnn_size", ",", "opt", ".", "rnn_size", ")", "\n", "\n", "self", ".", "confidence", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "opt", ".", "rnn_size", ",", "opt", ".", "rnn_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "opt", ".", "rnn_size", ",", "1", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "\n", "self", ".", "h2query", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "opt", ".", "rnn_size", "*", "2", ",", "opt", ".", "rnn_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "# if opt.use_multi_head == 1: # TODO, not implemented for now           ", "\n", "#     self.attention = MultiHeadedAddAttention(opt.num_heads, opt.d_model, scale=opt.multi_head_scale)", "\n", "if", "opt", ".", "use_multi_head", "==", "2", ":", "\n", "            ", "self", ".", "attention", "=", "MultiHeadedDotAttention", "(", "opt", ".", "num_heads", ",", "opt", ".", "rnn_size", ",", "project_k_v", "=", "0", ",", "scale", "=", "opt", ".", "multi_head_scale", ",", "use_output_layer", "=", "0", ",", "do_aoa", "=", "0", ",", "norm_q", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "attention", "=", "Attention", "(", "opt", ")", "\n", "\n", "", "self", ".", "lang_lstm", "=", "nn", ".", "LSTMCell", "(", "opt", ".", "rnn_size", "+", "opt", ".", "rnn_size", ",", "opt", ".", "rnn_size", ")", "\n", "\n", "self", ".", "norm_h", "=", "LayerNorm", "(", "opt", ".", "rnn_size", ")", "\n", "self", ".", "norm_c", "=", "LayerNorm", "(", "opt", ".", "rnn_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AATModel.AATCore.forward": [[50, 115], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "AATModel.AATCore.att_lstm", "AATModel.AATCore.norm_h", "AATModel.AATCore.confidence", "selector.any", "torch.dropout", "torch.dropout", "torch.dropout", "fc_feats.size", "fc_feats.data.new().zero_", "fc_feats.data.new().zero_", "fc_feats.data.new().zero_", "fc_feats.data.new().zero_", "fc_feats.data.new().zero_", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "AATModel.AATCore.h2query", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "AATModel.AATCore.lang_lstm", "AATModel.AATCore.norm_h", "AATModel.AATCore.norm_c", "selector.squeeze().float", "AATModel.AATCore.confidence", "fc_feats.data.new", "fc_feats.data.new", "fc_feats.data.new", "fc_feats.data.new", "fc_feats.data.new", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "AATModel.AATCore.attention", "AATModel.AATCore.attention", "selector.float", "selector.float", "selector.float", "selector.any", "p_att_feats.narrow", "p_att_feats.narrow", "selector.squeeze", "selector.float"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.attention", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.attention"], ["", "def", "forward", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ",", "att_masks", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "fc_feats", ".", "size", "(", ")", "[", "0", "]", "\n", "accum_conf", "=", "Variable", "(", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ",", "1", ")", ".", "zero_", "(", ")", ")", "\n", "self", ".", "att_step", "=", "Variable", "(", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "zero_", "(", ")", ")", "\n", "self", ".", "att_cost", "=", "Variable", "(", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "zero_", "(", ")", ")", "\n", "\n", "h_lang", "=", "Variable", "(", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ",", "self", ".", "rnn_size", ")", ".", "zero_", "(", ")", ")", "\n", "c_lang", "=", "Variable", "(", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ",", "self", ".", "rnn_size", ")", ".", "zero_", "(", ")", ")", "\n", "\n", "att_lstm_input", "=", "torch", ".", "cat", "(", "[", "fc_feats", "+", "state", "[", "0", "]", "[", "-", "1", "]", ",", "xt", "]", ",", "1", ")", "\n", "\n", "h_att", ",", "c_att", "=", "self", ".", "att_lstm", "(", "att_lstm_input", ",", "(", "state", "[", "0", "]", "[", "0", "]", ",", "state", "[", "1", "]", "[", "0", "]", ")", ")", "\n", "h_att", "=", "self", ".", "norm_h", "(", "h_att", ")", "\n", "\n", "p", "=", "self", ".", "confidence", "(", "h_att", ")", "\n", "\n", "self", ".", "att_cost", "+=", "(", "1", "+", "(", "1", "-", "p", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "selector", "=", "(", "p", "<", "1", "-", "self", ".", "epsilon", ")", ".", "data", "\n", "\n", "if", "selector", ".", "any", "(", ")", ":", "\n", "            ", "accum_conf", "+=", "p", "\n", "\n", "h_lang", "+=", "p", "*", "h_att", "\n", "c_lang", "+=", "p", "*", "state", "[", "1", "]", "[", "1", "]", "\n", "\n", "h_lang_", ",", "c_lang_", "=", "(", "state", "[", "0", "]", "[", "1", "]", ",", "state", "[", "1", "]", "[", "1", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "max_att_steps", ")", ":", "\n", "                ", "att_query", "=", "self", ".", "h2query", "(", "torch", ".", "cat", "(", "[", "h_lang_", ",", "h_att", "]", ",", "1", ")", ")", "\n", "if", "self", ".", "use_multi_head", "==", "2", ":", "\n", "                    ", "att_", "=", "self", ".", "attention", "(", "att_query", ",", "p_att_feats", ".", "narrow", "(", "2", ",", "0", ",", "self", ".", "rnn_size", ")", ",", "p_att_feats", ".", "narrow", "(", "2", ",", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", ",", "att_masks", ")", "\n", "", "else", ":", "\n", "                    ", "att_", "=", "self", ".", "attention", "(", "att_query", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", ")", "\n", "\n", "", "lang_lstm_input_", "=", "torch", ".", "cat", "(", "[", "att_", ",", "att_query", "]", ",", "1", ")", "\n", "h_lang_", ",", "c_lang_", "=", "self", ".", "lang_lstm", "(", "lang_lstm_input_", ",", "(", "h_lang_", ",", "c_lang_", ")", ")", "\n", "h_lang_", "=", "self", ".", "norm_h", "(", "h_lang_", ")", "\n", "c_lang_", "=", "self", ".", "norm_c", "(", "c_lang_", ")", "\n", "\n", "self", ".", "att_step", "+=", "selector", ".", "squeeze", "(", "1", ")", ".", "float", "(", ")", "\n", "p_", "=", "self", ".", "confidence", "(", "h_lang_", ")", "\n", "\n", "beta", "=", "p_", "*", "(", "1", "-", "accum_conf", ")", "\n", "accum_conf", "+=", "beta", "*", "selector", ".", "float", "(", ")", "\n", "h_lang", "+=", "beta", "*", "h_lang_", "*", "selector", ".", "float", "(", ")", "\n", "c_lang", "+=", "beta", "*", "c_lang_", "*", "selector", ".", "float", "(", ")", "\n", "\n", "self", ".", "att_cost", "+=", "(", "(", "1", "+", "(", "i", "+", "2", ")", "*", "(", "1", "-", "p_", ")", ")", "*", "selector", ".", "float", "(", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "selector", "=", "(", "accum_conf", "<", "1", "-", "self", ".", "epsilon", ")", ".", "data", "*", "selector", "\n", "\n", "if", "not", "selector", ".", "any", "(", ")", ":", "\n", "                    ", "break", "\n", "\n", "", "", "h_lang", "/=", "accum_conf", "\n", "c_lang", "/=", "accum_conf", "\n", "\n", "", "else", ":", "\n", "            ", "h_lang", "+=", "h_att", "\n", "c_lang", "+=", "state", "[", "1", "]", "[", "1", "]", "\n", "\n", "", "output", "=", "F", ".", "dropout", "(", "h_lang", ",", "self", ".", "drop_prob_lm", ",", "self", ".", "training", ")", "\n", "state", "=", "(", "torch", ".", "stack", "(", "[", "h_att", ",", "h_lang", "]", ")", ",", "torch", ".", "stack", "(", "[", "c_att", ",", "c_lang", "]", ")", ")", "\n", "\n", "return", "output", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AATModel.AATModel.__init__": [[117, 124], ["AttModel.AttModel.__init__", "AATModel.AATCore", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AATModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "num_layers", "=", "2", "\n", "if", "opt", ".", "use_multi_head", "==", "2", ":", "\n", "            ", "del", "self", ".", "ctx2att", "\n", "self", ".", "ctx2att", "=", "nn", ".", "Linear", "(", "opt", ".", "rnn_size", ",", "2", "*", "opt", ".", "rnn_size", ")", "\n", "", "self", ".", "core", "=", "AATCore", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AATModel.AATModel.forward": [[125, 132], ["kwargs.get", "getattr"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get"], ["", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "all_att_step", "=", "[", "]", "\n", "self", ".", "all_att_cost", "=", "[", "]", "\n", "mode", "=", "kwargs", ".", "get", "(", "'mode'", ",", "'forward'", ")", "\n", "if", "'mode'", "in", "kwargs", ":", "\n", "            ", "del", "kwargs", "[", "'mode'", "]", "\n", "", "return", "getattr", "(", "self", ",", "'_'", "+", "mode", ")", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AATModel.AATModel.get_logprobs_state": [[133, 144], ["AATModel.AATModel.embed", "AATModel.AATModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "AATModel.AATModel.all_att_step.append", "AATModel.AATModel.all_att_cost.append", "AATModel.AATModel.logit", "AATModel.AATModel.core.att_step.cpu().numpy", "AATModel.AATModel.core.att_step.cpu"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.logit"], ["", "def", "get_logprobs_state", "(", "self", ",", "it", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", ",", "state", ")", ":", "\n", "# 'it' contains a word index", "\n", "        ", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ",", "att_masks", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ",", "dim", "=", "1", ")", "\n", "\n", "self", ".", "all_att_step", ".", "append", "(", "self", ".", "core", ".", "att_step", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "self", ".", "all_att_cost", ".", "append", "(", "self", ".", "core", ".", "att_cost", ")", "\n", "\n", "return", "logprobs", ",", "state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.ShowTellModel.ShowTellModel.__init__": [[14, 34], ["CaptionModel.CaptionModel.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "ShowTellModel.ShowTellModel.init_weights", "getattr", "ShowTellModel.ShowTellModel.rnn_type.upper"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "ShowTellModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_size", "=", "opt", ".", "vocab_size", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "self", ".", "rnn_type", "=", "opt", ".", "rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "num_layers", "=", "opt", ".", "num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "seq_length", "=", "opt", ".", "seq_length", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "\n", "self", ".", "ss_prob", "=", "0.0", "# Schedule sampling probability", "\n", "\n", "self", ".", "img_embed", "=", "nn", ".", "Linear", "(", "self", ".", "fc_feat_size", ",", "self", ".", "input_encoding_size", ")", "\n", "self", ".", "core", "=", "getattr", "(", "nn", ",", "self", ".", "rnn_type", ".", "upper", "(", ")", ")", "(", "self", ".", "input_encoding_size", ",", "self", ".", "rnn_size", ",", "self", ".", "num_layers", ",", "bias", "=", "False", ",", "dropout", "=", "self", ".", "drop_prob_lm", ")", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", "+", "1", ",", "self", ".", "input_encoding_size", ")", "\n", "self", ".", "logit", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "vocab_size", "+", "1", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.ShowTellModel.ShowTellModel.init_weights": [[35, 40], ["ShowTellModel.ShowTellModel.embed.weight.data.uniform_", "ShowTellModel.ShowTellModel.logit.bias.data.fill_", "ShowTellModel.ShowTellModel.logit.weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "embed", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "logit", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "logit", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.ShowTellModel.ShowTellModel.init_hidden": [[41, 48], ["next", "weight.new_zeros", "ShowTellModel.ShowTellModel.parameters", "weight.new_zeros", "weight.new_zeros"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "weight", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "data", "\n", "if", "self", ".", "rnn_type", "==", "'lstm'", ":", "\n", "            ", "return", "(", "weight", ".", "new_zeros", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ",", "\n", "weight", ".", "new_zeros", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "weight", ".", "new_zeros", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.ShowTellModel.ShowTellModel._forward": [[49, 82], ["fc_feats.size", "ShowTellModel.ShowTellModel.init_hidden", "range", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "seq.size", "ShowTellModel.ShowTellModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "outputs.append", "ShowTellModel.ShowTellModel.img_embed", "ShowTellModel.ShowTellModel.embed", "ShowTellModel.ShowTellModel.unsqueeze", "ShowTellModel.ShowTellModel.logit", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fc_feats.data.new().uniform_", "seq[].clone", "ShowTellModel.ShowTellModel.dropout", "sample_mask.sum", "seq[].clone", "sample_mask.nonzero().view", "seq[].data.clone", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "seq[].data.clone.index_copy_", "seq[].data.sum", "torch.log_softmax.squeeze", "_.unsqueeze", "fc_feats.data.new", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "sample_mask.nonzero", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.logit"], ["", "", "def", "_forward", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "seq", ",", "att_masks", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "outputs", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "seq", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "xt", "=", "self", ".", "img_embed", "(", "fc_feats", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "training", "and", "i", ">=", "2", "and", "self", ".", "ss_prob", ">", "0.0", ":", "# otherwiste no need to sample", "\n", "                    ", "sample_prob", "=", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "uniform_", "(", "0", ",", "1", ")", "\n", "sample_mask", "=", "sample_prob", "<", "self", ".", "ss_prob", "\n", "if", "sample_mask", ".", "sum", "(", ")", "==", "0", ":", "\n", "                        ", "it", "=", "seq", "[", ":", ",", "i", "-", "1", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                        ", "sample_ind", "=", "sample_mask", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "it", "=", "seq", "[", ":", ",", "i", "-", "1", "]", ".", "data", ".", "clone", "(", ")", "\n", "#prob_prev = torch.exp(outputs[-1].data.index_select(0, sample_ind)) # fetch prev distribution: shape Nx(M+1)", "\n", "#it.index_copy_(0, sample_ind, torch.multinomial(prob_prev, 1).view(-1))", "\n", "prob_prev", "=", "torch", ".", "exp", "(", "outputs", "[", "-", "1", "]", ".", "data", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "it", ".", "index_copy_", "(", "0", ",", "sample_ind", ",", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "view", "(", "-", "1", ")", ".", "index_select", "(", "0", ",", "sample_ind", ")", ")", "\n", "", "", "else", ":", "\n", "                    ", "it", "=", "seq", "[", ":", ",", "i", "-", "1", "]", ".", "clone", "(", ")", "\n", "# break if all the sequences end", "\n", "", "if", "i", ">=", "2", "and", "seq", "[", ":", ",", "i", "-", "1", "]", ".", "data", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "break", "\n", "", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ".", "unsqueeze", "(", "0", ")", ",", "state", ")", "\n", "output", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "self", ".", "dropout", "(", "output", ".", "squeeze", "(", "0", ")", ")", ")", ",", "dim", "=", "1", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "outputs", "[", "1", ":", "]", "]", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.ShowTellModel.ShowTellModel.get_logprobs_state": [[83, 91], ["ShowTellModel.ShowTellModel.embed", "ShowTellModel.ShowTellModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "ShowTellModel.ShowTellModel.unsqueeze", "ShowTellModel.ShowTellModel.logit", "ShowTellModel.ShowTellModel.dropout", "output.squeeze"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.logit"], ["", "def", "get_logprobs_state", "(", "self", ",", "it", ",", "state", ")", ":", "\n", "# 'it' contains a word index", "\n", "        ", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ".", "unsqueeze", "(", "0", ")", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "self", ".", "dropout", "(", "output", ".", "squeeze", "(", "0", ")", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "return", "logprobs", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.ShowTellModel.ShowTellModel._sample_beam": [[92, 119], ["opt.get", "fc_feats.size", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "range", "ShowTellModel.ShowTellModel.init_hidden", "range", "ShowTellModel.ShowTellModel.beam_search", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "ShowTellModel.ShowTellModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "ShowTellModel.ShowTellModel.img_embed().expand", "ShowTellModel.ShowTellModel.unsqueeze", "ShowTellModel.ShowTellModel.logit", "fc_feats.data.new().long().zero_", "ShowTellModel.ShowTellModel.embed", "ShowTellModel.ShowTellModel.dropout", "ShowTellModel.ShowTellModel.img_embed", "output.squeeze", "fc_feats.data.new().long", "fc_feats.data.new"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.husthuaan_AAT.models.CaptionModel.CaptionModel.beam_search", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.logit", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed"], ["", "def", "_sample_beam", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "att_masks", "=", "None", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "10", ")", "\n", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "\n", "assert", "beam_size", "<=", "self", ".", "vocab_size", "+", "1", ",", "'lets assume this for now, otherwise this corner case causes a few headaches down the road. can be dealt with in future if needed'", "\n", "seq", "=", "torch", ".", "LongTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", ".", "zero_", "(", ")", "\n", "seqLogprobs", "=", "torch", ".", "FloatTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", "\n", "# lets process every image independently for now, for simplicity", "\n", "\n", "self", ".", "done_beams", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "for", "k", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "state", "=", "self", ".", "init_hidden", "(", "beam_size", ")", "\n", "for", "t", "in", "range", "(", "2", ")", ":", "\n", "                ", "if", "t", "==", "0", ":", "\n", "                    ", "xt", "=", "self", ".", "img_embed", "(", "fc_feats", "[", "k", ":", "k", "+", "1", "]", ")", ".", "expand", "(", "beam_size", ",", "self", ".", "input_encoding_size", ")", "\n", "", "elif", "t", "==", "1", ":", "# input <bos>", "\n", "                    ", "it", "=", "fc_feats", ".", "data", ".", "new", "(", "beam_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ".", "unsqueeze", "(", "0", ")", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "self", ".", "dropout", "(", "output", ".", "squeeze", "(", "0", ")", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "self", ".", "done_beams", "[", "k", "]", "=", "self", ".", "beam_search", "(", "state", ",", "logprobs", ",", "opt", "=", "opt", ")", "\n", "seq", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'seq'", "]", "# the first beam has highest cumulative score", "\n", "seqLogprobs", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'logps'", "]", "\n", "# return the samples and their log likelihoods", "\n", "", "return", "seq", ".", "transpose", "(", "0", ",", "1", ")", ",", "seqLogprobs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.ShowTellModel.ShowTellModel._sample": [[120, 171], ["opt.get", "opt.get", "opt.get", "fc_feats.size", "ShowTellModel.ShowTellModel.init_hidden", "fc_feats.new_zeros", "fc_feats.new_zeros", "range", "ShowTellModel.ShowTellModel.sample_beam", "ShowTellModel.ShowTellModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "ShowTellModel.ShowTellModel.img_embed", "ShowTellModel.ShowTellModel.embed", "ShowTellModel.ShowTellModel.unsqueeze", "ShowTellModel.ShowTellModel.logit", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "fc_feats.data.new().long().zero_.view().long", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.log_softmax.gather", "fc_feats.data.new().long().zero_.view().long", "F.log_softmax.gather.view", "fc_feats.data.new().long().zero_", "ShowTellModel.ShowTellModel.dropout", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "unfinished.type_as", "unfinished.sum", "output.squeeze", "fc_feats.data.new().long().zero_.view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "fc_feats.data.new().long().zero_.view", "fc_feats.data.new().long", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "fc_feats.data.new"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.husthuaan_AAT.models.OldModel.OldModel.sample_beam", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.logit"], ["", "def", "_sample", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "att_masks", "=", "None", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "sample_method", "=", "opt", ".", "get", "(", "'sample_method'", ",", "'greedy'", ")", "\n", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "1", ")", "\n", "temperature", "=", "opt", ".", "get", "(", "'temperature'", ",", "1.0", ")", "\n", "if", "beam_size", ">", "1", ":", "\n", "            ", "return", "self", ".", "sample_beam", "(", "fc_feats", ",", "att_feats", ",", "opt", ")", "\n", "\n", "", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "seq", "=", "fc_feats", ".", "new_zeros", "(", "batch_size", ",", "self", ".", "seq_length", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "seqLogprobs", "=", "fc_feats", ".", "new_zeros", "(", "batch_size", ",", "self", ".", "seq_length", ")", "\n", "for", "t", "in", "range", "(", "self", ".", "seq_length", "+", "2", ")", ":", "\n", "            ", "if", "t", "==", "0", ":", "\n", "                ", "xt", "=", "self", ".", "img_embed", "(", "fc_feats", ")", "\n", "", "else", ":", "\n", "                ", "if", "t", "==", "1", ":", "# input <bos>", "\n", "                    ", "it", "=", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ".", "unsqueeze", "(", "0", ")", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "self", ".", "dropout", "(", "output", ".", "squeeze", "(", "0", ")", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# sample the next word", "\n", "if", "t", "==", "self", ".", "seq_length", "+", "1", ":", "# skip if we achieve maximum length", "\n", "                ", "break", "\n", "", "if", "sample_method", "==", "'greedy'", ":", "\n", "                ", "sampleLogprobs", ",", "it", "=", "torch", ".", "max", "(", "logprobs", ".", "data", ",", "1", ")", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "temperature", "==", "1.0", ":", "\n", "                    ", "prob_prev", "=", "torch", ".", "exp", "(", "logprobs", ".", "data", ")", ".", "cpu", "(", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "", "else", ":", "\n", "# scale logprobs by temperature", "\n", "                    ", "prob_prev", "=", "torch", ".", "exp", "(", "torch", ".", "div", "(", "logprobs", ".", "data", ",", "temperature", ")", ")", ".", "cpu", "(", ")", "\n", "", "it", "=", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "cuda", "(", ")", "\n", "sampleLogprobs", "=", "logprobs", ".", "gather", "(", "1", ",", "it", ")", "# gather the logprobs at sampled positions", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "# and flatten indices for downstream processing", "\n", "\n", "", "if", "t", ">=", "1", ":", "\n", "# stop when all finished", "\n", "                ", "if", "t", "==", "1", ":", "\n", "                    ", "unfinished", "=", "it", ">", "0", "\n", "", "else", ":", "\n", "                    ", "unfinished", "=", "unfinished", "*", "(", "it", ">", "0", ")", "\n", "", "it", "=", "it", "*", "unfinished", ".", "type_as", "(", "it", ")", "\n", "seq", "[", ":", ",", "t", "-", "1", "]", "=", "it", "#seq[t] the input of t+2 time step", "\n", "seqLogprobs", "[", ":", ",", "t", "-", "1", "]", "=", "sampleLogprobs", ".", "view", "(", "-", "1", ")", "\n", "if", "unfinished", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "break", "\n", "\n", "", "", "", "return", "seq", ",", "seqLogprobs", "", "", "", ""]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.__init__": [[30, 41], ["CaptionModel.CaptionModel.CaptionModel.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "AttEnsemble.AttEnsemble.register_buffer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "models", ",", "weights", "=", "None", ")", ":", "\n", "        ", "CaptionModel", ".", "__init__", "(", "self", ")", "\n", "# super(AttEnsemble, self).__init__()", "\n", "\n", "self", ".", "models", "=", "nn", ".", "ModuleList", "(", "models", ")", "\n", "self", ".", "vocab_size", "=", "models", "[", "0", "]", ".", "vocab_size", "\n", "self", ".", "seq_length", "=", "models", "[", "0", "]", ".", "seq_length", "\n", "self", ".", "bad_endings_ix", "=", "models", "[", "0", "]", ".", "bad_endings_ix", "\n", "self", ".", "ss_prob", "=", "0", "\n", "weights", "=", "weights", "or", "[", "1.0", "]", "*", "len", "(", "self", ".", "models", ")", "\n", "self", ".", "register_buffer", "(", "'weights'", ",", "torch", ".", "tensor", "(", "weights", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.init_hidden": [[42, 45], ["AttEnsemble.AttEnsemble.pack_state", "m.init_hidden"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.pack_state", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_hidden"], ["", "def", "init_hidden", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "state", "=", "[", "m", ".", "init_hidden", "(", "batch_size", ")", "for", "m", "in", "self", ".", "models", "]", "\n", "return", "self", ".", "pack_state", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.pack_state": [[46, 49], ["sum", "len", "list"], "methods", ["None"], ["", "def", "pack_state", "(", "self", ",", "state", ")", ":", "\n", "        ", "self", ".", "state_lengths", "=", "[", "len", "(", "_", ")", "for", "_", "in", "state", "]", "\n", "return", "sum", "(", "[", "list", "(", "_", ")", "for", "_", "in", "state", "]", ",", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.unpack_state": [[50, 56], ["out.append"], "methods", ["None"], ["", "def", "unpack_state", "(", "self", ",", "state", ")", ":", "\n", "        ", "out", "=", "[", "]", "\n", "for", "l", "in", "self", ".", "state_lengths", ":", "\n", "            ", "out", ".", "append", "(", "state", "[", ":", "l", "]", ")", "\n", "state", "=", "state", "[", "l", ":", "]", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed": [[57, 59], ["m.embed"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed"], ["", "def", "embed", "(", "self", ",", "it", ")", ":", "\n", "        ", "return", "[", "m", ".", "embed", "(", "it", ")", "for", "m", "in", "self", ".", "models", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core": [[60, 62], ["zip", "m.core", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core"], ["", "def", "core", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "return", "zip", "(", "*", "[", "m", ".", "core", "(", "*", "_", ")", "for", "m", ",", "_", "in", "zip", "(", "self", ".", "models", ",", "zip", "(", "*", "args", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.get_logprobs_state": [[63, 72], ["AttEnsemble.AttEnsemble.embed", "AttEnsemble.AttEnsemble.unpack_state", "AttEnsemble.AttEnsemble.core", "torch.stack().mul().div().sum().log", "torch.stack().mul().div().sum().log", "torch.stack().mul().div().sum().log", "torch.stack().mul().div().sum().log", "torch.stack().mul().div().sum().log", "torch.stack().mul().div().sum().log", "torch.stack().mul().div().sum().log", "torch.stack().mul().div().sum().log", "torch.stack().mul().div().sum().log", "AttEnsemble.AttEnsemble.pack_state", "torch.stack().mul().div().sum", "torch.stack().mul().div().sum", "torch.stack().mul().div().sum", "torch.stack().mul().div().sum", "torch.stack().mul().div().sum", "torch.stack().mul().div().sum", "torch.stack().mul().div().sum", "torch.stack().mul().div().sum", "torch.stack().mul().div().sum", "torch.stack().mul().div", "torch.stack().mul().div", "torch.stack().mul().div", "torch.stack().mul().div", "torch.stack().mul().div", "torch.stack().mul().div", "torch.stack().mul().div", "torch.stack().mul().div", "torch.stack().mul().div", "AttEnsemble.AttEnsemble.weights.sum", "torch.stack().mul", "torch.stack().mul", "torch.stack().mul", "torch.stack().mul", "torch.stack().mul", "torch.stack().mul", "torch.stack().mul", "torch.stack().mul", "torch.stack().mul", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.softmax", "torch.softmax", "torch.softmax", "m.logit", "enumerate"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.unpack_state", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.pack_state", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.logit"], ["", "def", "get_logprobs_state", "(", "self", ",", "it", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "tmp_p_att_feats", ",", "tmp_att_masks", ",", "state", ")", ":", "\n", "# 'it' contains a word index", "\n", "        ", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "state", "=", "self", ".", "unpack_state", "(", "state", ")", "\n", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "tmp_p_att_feats", ",", "state", ",", "tmp_att_masks", ")", "\n", "logprobs", "=", "torch", ".", "stack", "(", "[", "F", ".", "softmax", "(", "m", ".", "logit", "(", "output", "[", "i", "]", ")", ",", "dim", "=", "1", ")", "for", "i", ",", "m", "in", "enumerate", "(", "self", ".", "models", ")", "]", ",", "2", ")", ".", "mul", "(", "self", ".", "weights", ")", ".", "div", "(", "self", ".", "weights", ".", "sum", "(", ")", ")", ".", "sum", "(", "-", "1", ")", ".", "log", "(", ")", "\n", "\n", "return", "logprobs", ",", "self", ".", "pack_state", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble._prepare_feature": [[73, 75], ["tuple", "zip", "m._prepare_feature"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble._prepare_feature"], ["", "def", "_prepare_feature", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "return", "tuple", "(", "zip", "(", "*", "[", "m", ".", "_prepare_feature", "(", "*", "args", ")", "for", "m", "in", "self", ".", "models", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble._sample_beam": [[89, 116], ["opt.get", "fc_feats.size", "AttEnsemble.AttEnsemble._prepare_feature", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "range", "AttEnsemble.AttEnsemble.init_hidden", "fc_feats[].data.new().long().zero_", "AttEnsemble.AttEnsemble.get_logprobs_state", "AttEnsemble.AttEnsemble.beam_search", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "[].expand", "[].expand().contiguous", "[].expand().contiguous", "fc_feats[].size", "enumerate", "enumerate", "enumerate", "[].expand().contiguous", "enumerate", "fc_feats[].data.new().long", "[].expand", "[].expand", "[].expand", "fc_feats[].data.new", "att_feats[].size", "p_att_feats[].size", "att_masks[].size"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble._prepare_feature", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.get_logprobs_state", "home.repos.pwc.inspect_result.husthuaan_AAT.models.CaptionModel.CaptionModel.beam_search"], ["", "def", "_sample_beam", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "att_masks", "=", "None", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "10", ")", "\n", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "\n", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "att_masks", "=", "self", ".", "_prepare_feature", "(", "fc_feats", ",", "att_feats", ",", "att_masks", ")", "\n", "\n", "assert", "beam_size", "<=", "self", ".", "vocab_size", "+", "1", ",", "'lets assume this for now, otherwise this corner case causes a few headaches down the road. can be dealt with in future if needed'", "\n", "seq", "=", "torch", ".", "LongTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", ".", "zero_", "(", ")", "\n", "seqLogprobs", "=", "torch", ".", "FloatTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", "\n", "# lets process every image independently for now, for simplicity", "\n", "\n", "self", ".", "done_beams", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "for", "k", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "state", "=", "self", ".", "init_hidden", "(", "beam_size", ")", "\n", "tmp_fc_feats", "=", "[", "fc_feats", "[", "i", "]", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "beam_size", ",", "fc_feats", "[", "i", "]", ".", "size", "(", "1", ")", ")", "for", "i", ",", "m", "in", "enumerate", "(", "self", ".", "models", ")", "]", "\n", "tmp_att_feats", "=", "[", "att_feats", "[", "i", "]", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "*", "(", "(", "beam_size", ",", ")", "+", "att_feats", "[", "i", "]", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", "for", "i", ",", "m", "in", "enumerate", "(", "self", ".", "models", ")", "]", "\n", "tmp_p_att_feats", "=", "[", "p_att_feats", "[", "i", "]", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "*", "(", "(", "beam_size", ",", ")", "+", "p_att_feats", "[", "i", "]", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", "for", "i", ",", "m", "in", "enumerate", "(", "self", ".", "models", ")", "]", "\n", "tmp_att_masks", "=", "[", "att_masks", "[", "i", "]", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "*", "(", "(", "beam_size", ",", ")", "+", "att_masks", "[", "i", "]", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", "if", "att_masks", "[", "i", "]", "is", "not", "None", "else", "att_masks", "[", "i", "]", "for", "i", ",", "m", "in", "enumerate", "(", "self", ".", "models", ")", "]", "\n", "\n", "it", "=", "fc_feats", "[", "0", "]", ".", "data", ".", "new", "(", "beam_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "logprobs", ",", "state", "=", "self", ".", "get_logprobs_state", "(", "it", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "tmp_p_att_feats", ",", "tmp_att_masks", ",", "state", ")", "\n", "\n", "self", ".", "done_beams", "[", "k", "]", "=", "self", ".", "beam_search", "(", "state", ",", "logprobs", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "tmp_p_att_feats", ",", "tmp_att_masks", ",", "opt", "=", "opt", ")", "\n", "seq", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'seq'", "]", "# the first beam has highest cumulative score", "\n", "seqLogprobs", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'logps'", "]", "\n", "# return the samples and their log likelihoods", "\n", "", "return", "seq", ".", "transpose", "(", "0", ",", "1", ")", ",", "seqLogprobs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# return the samples and their log likelihoods", ""]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.OldModel.OldModel.__init__": [[21, 41], ["CaptionModel.CaptionModel.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "OldModel.OldModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "OldModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_size", "=", "opt", ".", "vocab_size", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "self", ".", "rnn_type", "=", "opt", ".", "rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "num_layers", "=", "opt", ".", "num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "seq_length", "=", "opt", ".", "seq_length", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "self", ".", "att_feat_size", "=", "opt", ".", "att_feat_size", "\n", "\n", "self", ".", "ss_prob", "=", "0.0", "# Schedule sampling probability", "\n", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "self", ".", "fc_feat_size", ",", "self", ".", "num_layers", "*", "self", ".", "rnn_size", ")", "# feature to rnn_size", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", "+", "1", ",", "self", ".", "input_encoding_size", ")", "\n", "self", ".", "logit", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "vocab_size", "+", "1", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.OldModel.OldModel.init_weights": [[42, 47], ["OldModel.OldModel.embed.weight.data.uniform_", "OldModel.OldModel.logit.bias.data.fill_", "OldModel.OldModel.logit.weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "embed", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "logit", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "logit", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.OldModel.OldModel.init_hidden": [[48, 54], ["OldModel.OldModel.linear().view().transpose", "OldModel.OldModel.linear().view", "OldModel.OldModel.linear"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "fc_feats", ")", ":", "\n", "        ", "image_map", "=", "self", ".", "linear", "(", "fc_feats", ")", ".", "view", "(", "-", "1", ",", "self", ".", "num_layers", ",", "self", ".", "rnn_size", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "rnn_type", "==", "'lstm'", ":", "\n", "            ", "return", "(", "image_map", ",", "image_map", ")", "\n", "", "else", ":", "\n", "            ", "return", "image_map", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.OldModel.OldModel.forward": [[55, 87], ["fc_feats.size", "OldModel.OldModel.init_hidden", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "OldModel.OldModel.embed", "OldModel.OldModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "outputs.append", "seq.size", "fc_feats.data.new().uniform_", "seq[].clone", "OldModel.OldModel.logit", "_.unsqueeze", "sample_mask.sum", "seq[].clone", "sample_mask.nonzero().view", "seq[].data.clone", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "seq[].data.clone.index_copy_", "seq[].sum", "OldModel.OldModel.dropout", "fc_feats.data.new", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "sample_mask.nonzero", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.logit"], ["", "", "def", "forward", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "seq", ")", ":", "\n", "        ", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "fc_feats", ")", "\n", "\n", "outputs", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "seq", ".", "size", "(", "1", ")", "-", "1", ")", ":", "\n", "            ", "if", "self", ".", "training", "and", "i", ">=", "1", "and", "self", ".", "ss_prob", ">", "0.0", ":", "# otherwiste no need to sample", "\n", "                ", "sample_prob", "=", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "uniform_", "(", "0", ",", "1", ")", "\n", "sample_mask", "=", "sample_prob", "<", "self", ".", "ss_prob", "\n", "if", "sample_mask", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                    ", "sample_ind", "=", "sample_mask", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "data", ".", "clone", "(", ")", "\n", "#prob_prev = torch.exp(outputs[-1].data.index_select(0, sample_ind)) # fetch prev distribution: shape Nx(M+1)", "\n", "#it.index_copy_(0, sample_ind, torch.multinomial(prob_prev, 1).view(-1))", "\n", "prob_prev", "=", "torch", ".", "exp", "(", "outputs", "[", "-", "1", "]", ".", "data", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "it", ".", "index_copy_", "(", "0", ",", "sample_ind", ",", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "view", "(", "-", "1", ")", ".", "index_select", "(", "0", ",", "sample_ind", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "clone", "(", ")", "\n", "# break if all the sequences end", "\n", "", "if", "i", ">=", "1", "and", "seq", "[", ":", ",", "i", "]", ".", "sum", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "fc_feats", ",", "att_feats", ",", "state", ")", "\n", "output", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "self", ".", "dropout", "(", "output", ")", ")", ",", "dim", "=", "1", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "outputs", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.OldModel.OldModel.get_logprobs_state": [[88, 96], ["OldModel.OldModel.embed", "OldModel.OldModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "OldModel.OldModel.logit", "OldModel.OldModel.dropout"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.logit"], ["", "def", "get_logprobs_state", "(", "self", ",", "it", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "state", ")", ":", "\n", "# 'it' contains a word index", "\n", "        ", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "self", ".", "dropout", "(", "output", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "return", "logprobs", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.OldModel.OldModel.sample_beam": [[97, 130], ["opt.get", "fc_feats.size", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "range", "fc_feats[].expand", "att_feats[].expand().contiguous", "OldModel.OldModel.init_hidden", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "OldModel.OldModel.beam_search", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "OldModel.OldModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "att_feats[].expand", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "fc_feats.data.new().long().zero_", "OldModel.OldModel.embed", "OldModel.OldModel.logit", "OldModel.OldModel.dropout", "fc_feats.data.new().long", "att_feats.size", "fc_feats.data.new"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.husthuaan_AAT.models.CaptionModel.CaptionModel.beam_search", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.logit"], ["", "def", "sample_beam", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "10", ")", "\n", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "\n", "assert", "beam_size", "<=", "self", ".", "vocab_size", "+", "1", ",", "'lets assume this for now, otherwise this corner case causes a few headaches down the road. can be dealt with in future if needed'", "\n", "seq", "=", "torch", ".", "LongTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", ".", "zero_", "(", ")", "\n", "seqLogprobs", "=", "torch", ".", "FloatTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", "\n", "# lets process every image independently for now, for simplicity", "\n", "\n", "self", ".", "done_beams", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "for", "k", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "tmp_fc_feats", "=", "fc_feats", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "beam_size", ",", "self", ".", "fc_feat_size", ")", "\n", "tmp_att_feats", "=", "att_feats", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "*", "(", "(", "beam_size", ",", ")", "+", "att_feats", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", "\n", "\n", "state", "=", "self", ".", "init_hidden", "(", "tmp_fc_feats", ")", "\n", "\n", "beam_seq", "=", "torch", ".", "LongTensor", "(", "self", ".", "seq_length", ",", "beam_size", ")", ".", "zero_", "(", ")", "\n", "beam_seq_logprobs", "=", "torch", ".", "FloatTensor", "(", "self", ".", "seq_length", ",", "beam_size", ")", ".", "zero_", "(", ")", "\n", "beam_logprobs_sum", "=", "torch", ".", "zeros", "(", "beam_size", ")", "# running sum of logprobs for each beam", "\n", "done_beams", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "1", ")", ":", "\n", "                ", "if", "t", "==", "0", ":", "# input <bos>", "\n", "                    ", "it", "=", "fc_feats", ".", "data", ".", "new", "(", "beam_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "self", ".", "dropout", "(", "output", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "self", ".", "done_beams", "[", "k", "]", "=", "self", ".", "beam_search", "(", "state", ",", "logprobs", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "opt", "=", "opt", ")", "\n", "seq", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'seq'", "]", "# the first beam has highest cumulative score", "\n", "seqLogprobs", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'logps'", "]", "\n", "# return the samples and their log likelihoods", "\n", "", "return", "seq", ".", "transpose", "(", "0", ",", "1", ")", ",", "seqLogprobs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.OldModel.OldModel.sample": [[131, 177], ["opt.get", "opt.get", "opt.get", "fc_feats.size", "OldModel.OldModel.init_hidden", "range", "OldModel.OldModel.sample_beam", "OldModel.OldModel.embed", "OldModel.OldModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fc_feats.data.new().long().zero_", "seq.append", "seqLogprobs.append", "OldModel.OldModel.logit", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "it.view().long.view().long.view().long", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.log_softmax.gather", "it.view().long.view().long.view().long", "unfinished.sum", "unfinished.type_as", "F.log_softmax.gather.view", "OldModel.OldModel.dropout", "_.unsqueeze", "_.unsqueeze", "fc_feats.data.new().long", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "it.view().long.view().long.view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "it.view().long.view().long.view", "fc_feats.data.new", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.husthuaan_AAT.models.OldModel.OldModel.sample_beam", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.logit"], ["", "def", "sample", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "sample_method", "=", "opt", ".", "get", "(", "'sample_method'", ",", "'greedy'", ")", "\n", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "1", ")", "\n", "temperature", "=", "opt", ".", "get", "(", "'temperature'", ",", "1.0", ")", "\n", "if", "beam_size", ">", "1", ":", "\n", "            ", "return", "self", ".", "sample_beam", "(", "fc_feats", ",", "att_feats", ",", "opt", ")", "\n", "\n", "", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "fc_feats", ")", "\n", "\n", "seq", "=", "[", "]", "\n", "seqLogprobs", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "self", ".", "seq_length", "+", "1", ")", ":", "\n", "            ", "if", "t", "==", "0", ":", "# input <bos>", "\n", "                ", "it", "=", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "", "elif", "sample_method", "==", "'greedy'", ":", "\n", "                ", "sampleLogprobs", ",", "it", "=", "torch", ".", "max", "(", "logprobs", ".", "data", ",", "1", ")", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "temperature", "==", "1.0", ":", "\n", "                    ", "prob_prev", "=", "torch", ".", "exp", "(", "logprobs", ".", "data", ")", ".", "cpu", "(", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "", "else", ":", "\n", "# scale logprobs by temperature", "\n", "                    ", "prob_prev", "=", "torch", ".", "exp", "(", "torch", ".", "div", "(", "logprobs", ".", "data", ",", "temperature", ")", ")", ".", "cpu", "(", ")", "\n", "", "it", "=", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "cuda", "(", ")", "\n", "sampleLogprobs", "=", "logprobs", ".", "gather", "(", "1", ",", "it", ")", "# gather the logprobs at sampled positions", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "# and flatten indices for downstream processing", "\n", "\n", "", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "if", "t", ">=", "1", ":", "\n", "# stop when all finished", "\n", "                ", "if", "t", "==", "1", ":", "\n", "                    ", "unfinished", "=", "it", ">", "0", "\n", "", "else", ":", "\n", "                    ", "unfinished", "=", "unfinished", "*", "(", "it", ">", "0", ")", "\n", "", "if", "unfinished", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "break", "\n", "", "it", "=", "it", "*", "unfinished", ".", "type_as", "(", "it", ")", "\n", "seq", ".", "append", "(", "it", ")", "#seq[t] the input of t+2 time step", "\n", "seqLogprobs", ".", "append", "(", "sampleLogprobs", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "fc_feats", ",", "att_feats", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "self", ".", "dropout", "(", "output", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "seq", "]", ",", "1", ")", ",", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "seqLogprobs", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.OldModel.ShowAttendTellCore.__init__": [[180, 201], ["torch.Module.__init__", "getattr", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "OldModel.ShowAttendTellCore.rnn_type.upper"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "ShowAttendTellCore", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "self", ".", "rnn_type", "=", "opt", ".", "rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "num_layers", "=", "opt", ".", "num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "self", ".", "att_feat_size", "=", "opt", ".", "att_feat_size", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "\n", "self", ".", "rnn", "=", "getattr", "(", "nn", ",", "self", ".", "rnn_type", ".", "upper", "(", ")", ")", "(", "self", ".", "input_encoding_size", "+", "self", ".", "att_feat_size", ",", "\n", "self", ".", "rnn_size", ",", "self", ".", "num_layers", ",", "bias", "=", "False", ",", "dropout", "=", "self", ".", "drop_prob_lm", ")", "\n", "\n", "if", "self", ".", "att_hid_size", ">", "0", ":", "\n", "            ", "self", ".", "ctx2att", "=", "nn", ".", "Linear", "(", "self", ".", "att_feat_size", ",", "self", ".", "att_hid_size", ")", "\n", "self", ".", "h2att", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "att_hid_size", ")", "\n", "self", ".", "alpha_net", "=", "nn", ".", "Linear", "(", "self", ".", "att_hid_size", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ctx2att", "=", "nn", ".", "Linear", "(", "self", ".", "att_feat_size", ",", "1", ")", "\n", "self", ".", "h2att", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.OldModel.ShowAttendTellCore.forward": [[202, 228], ["att_feats.view", "torch.softmax", "torch.softmax", "torch.softmax", "att_feats.view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "OldModel.ShowAttendTellCore.rnn", "OldModel.ShowAttendTellCore.ctx2att", "att.view.view.view", "OldModel.ShowAttendTellCore.h2att", "att_h.expand_as.expand_as.unsqueeze().expand_as", "torch.tanh", "torch.tanh", "torch.tanh", "dot.view.view.view", "OldModel.ShowAttendTellCore.alpha_net", "dot.view.view.view", "att.view.view.view", "OldModel.ShowAttendTellCore.h2att", "att_h.expand_as.expand_as.expand_as", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "output.squeeze", "att_feats.numel", "att_feats.size", "OldModel.ShowAttendTellCore.ctx2att", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "att_h.expand_as.expand_as.unsqueeze", "torch.softmax.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "state", ")", ":", "\n", "        ", "att_size", "=", "att_feats", ".", "numel", "(", ")", "//", "att_feats", ".", "size", "(", "0", ")", "//", "self", ".", "att_feat_size", "\n", "att", "=", "att_feats", ".", "view", "(", "-", "1", ",", "self", ".", "att_feat_size", ")", "\n", "if", "self", ".", "att_hid_size", ">", "0", ":", "\n", "            ", "att", "=", "self", ".", "ctx2att", "(", "att", ")", "# (batch * att_size) * att_hid_size", "\n", "att", "=", "att", ".", "view", "(", "-", "1", ",", "att_size", ",", "self", ".", "att_hid_size", ")", "# batch * att_size * att_hid_size", "\n", "att_h", "=", "self", ".", "h2att", "(", "state", "[", "0", "]", "[", "-", "1", "]", ")", "# batch * att_hid_size", "\n", "att_h", "=", "att_h", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "att", ")", "# batch * att_size * att_hid_size", "\n", "dot", "=", "att", "+", "att_h", "# batch * att_size * att_hid_size", "\n", "dot", "=", "F", ".", "tanh", "(", "dot", ")", "# batch * att_size * att_hid_size", "\n", "dot", "=", "dot", ".", "view", "(", "-", "1", ",", "self", ".", "att_hid_size", ")", "# (batch * att_size) * att_hid_size", "\n", "dot", "=", "self", ".", "alpha_net", "(", "dot", ")", "# (batch * att_size) * 1", "\n", "dot", "=", "dot", ".", "view", "(", "-", "1", ",", "att_size", ")", "# batch * att_size", "\n", "", "else", ":", "\n", "            ", "att", "=", "self", ".", "ctx2att", "(", "att", ")", "(", "att", ")", "# (batch * att_size) * 1", "\n", "att", "=", "att", ".", "view", "(", "-", "1", ",", "att_size", ")", "# batch * att_size", "\n", "att_h", "=", "self", ".", "h2att", "(", "state", "[", "0", "]", "[", "-", "1", "]", ")", "# batch * 1", "\n", "att_h", "=", "att_h", ".", "expand_as", "(", "att", ")", "# batch * att_size", "\n", "dot", "=", "att_h", "+", "att", "# batch * att_size", "\n", "\n", "", "weight", "=", "F", ".", "softmax", "(", "dot", ",", "dim", "=", "1", ")", "\n", "att_feats_", "=", "att_feats", ".", "view", "(", "-", "1", ",", "att_size", ",", "self", ".", "att_feat_size", ")", "# batch * att_size * att_feat_size", "\n", "att_res", "=", "torch", ".", "bmm", "(", "weight", ".", "unsqueeze", "(", "1", ")", ",", "att_feats_", ")", ".", "squeeze", "(", "1", ")", "# batch * att_feat_size", "\n", "\n", "output", ",", "state", "=", "self", ".", "rnn", "(", "torch", ".", "cat", "(", "[", "xt", ",", "att_res", "]", ",", "1", ")", ".", "unsqueeze", "(", "0", ")", ",", "state", ")", "\n", "return", "output", ".", "squeeze", "(", "0", ")", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.OldModel.AllImgCore.__init__": [[230, 241], ["torch.Module.__init__", "getattr", "OldModel.AllImgCore.rnn_type.upper"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AllImgCore", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "self", ".", "rnn_type", "=", "opt", ".", "rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "num_layers", "=", "opt", ".", "num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "\n", "self", ".", "rnn", "=", "getattr", "(", "nn", ",", "self", ".", "rnn_type", ".", "upper", "(", ")", ")", "(", "self", ".", "input_encoding_size", "+", "self", ".", "fc_feat_size", ",", "\n", "self", ".", "rnn_size", ",", "self", ".", "num_layers", ",", "bias", "=", "False", ",", "dropout", "=", "self", ".", "drop_prob_lm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.OldModel.AllImgCore.forward": [[242, 245], ["OldModel.AllImgCore.rnn", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "output.squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "state", ")", ":", "\n", "        ", "output", ",", "state", "=", "self", ".", "rnn", "(", "torch", ".", "cat", "(", "[", "xt", ",", "fc_feats", "]", ",", "1", ")", ".", "unsqueeze", "(", "0", ")", ",", "state", ")", "\n", "return", "output", ".", "squeeze", "(", "0", ")", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.OldModel.ShowAttendTellModel.__init__": [[247, 250], ["OldModel.OldModel.__init__", "OldModel.ShowAttendTellCore"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "ShowAttendTellModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "core", "=", "ShowAttendTellCore", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.OldModel.AllImgModel.__init__": [[252, 255], ["OldModel.OldModel.__init__", "OldModel.AllImgCore"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AllImgModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "core", "=", "AllImgCore", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.LSTMCore.__init__": [[14, 24], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "LSTMCore", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "\n", "# Build a LSTM", "\n", "self", ".", "i2h", "=", "nn", ".", "Linear", "(", "self", ".", "input_encoding_size", ",", "5", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "h2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "5", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.LSTMCore.forward": [[25, 43], ["all_input_sums.narrow", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "FCModel.LSTMCore.dropout", "FCModel.LSTMCore.i2h", "FCModel.LSTMCore.h2h", "all_input_sums.narrow", "all_input_sums.narrow", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "next_h.unsqueeze", "next_c.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "xt", ",", "state", ")", ":", "\n", "\n", "        ", "all_input_sums", "=", "self", ".", "i2h", "(", "xt", ")", "+", "self", ".", "h2h", "(", "state", "[", "0", "]", "[", "-", "1", "]", ")", "\n", "sigmoid_chunk", "=", "all_input_sums", ".", "narrow", "(", "1", ",", "0", ",", "3", "*", "self", ".", "rnn_size", ")", "\n", "sigmoid_chunk", "=", "torch", ".", "sigmoid", "(", "sigmoid_chunk", ")", "\n", "in_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "0", ",", "self", ".", "rnn_size", ")", "\n", "forget_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", "\n", "out_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", "*", "2", ",", "self", ".", "rnn_size", ")", "\n", "\n", "in_transform", "=", "torch", ".", "max", "(", "all_input_sums", ".", "narrow", "(", "1", ",", "3", "*", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", ",", "\n", "all_input_sums", ".", "narrow", "(", "1", ",", "4", "*", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", ")", "\n", "next_c", "=", "forget_gate", "*", "state", "[", "1", "]", "[", "-", "1", "]", "+", "in_gate", "*", "in_transform", "\n", "next_h", "=", "out_gate", "*", "torch", ".", "tanh", "(", "next_c", ")", "\n", "\n", "output", "=", "self", ".", "dropout", "(", "next_h", ")", "\n", "state", "=", "(", "next_h", ".", "unsqueeze", "(", "0", ")", ",", "next_c", ".", "unsqueeze", "(", "0", ")", ")", "\n", "return", "output", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.__init__": [[45, 64], ["CaptionModel.CaptionModel.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "FCModel.LSTMCore", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "FCModel.FCModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "FCModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_size", "=", "opt", ".", "vocab_size", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "self", ".", "rnn_type", "=", "opt", ".", "rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "num_layers", "=", "opt", ".", "num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "seq_length", "=", "opt", ".", "seq_length", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "\n", "self", ".", "ss_prob", "=", "0.0", "# Schedule sampling probability", "\n", "\n", "self", ".", "img_embed", "=", "nn", ".", "Linear", "(", "self", ".", "fc_feat_size", ",", "self", ".", "input_encoding_size", ")", "\n", "self", ".", "core", "=", "LSTMCore", "(", "opt", ")", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", "+", "1", ",", "self", ".", "input_encoding_size", ")", "\n", "self", ".", "logit", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "vocab_size", "+", "1", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_weights": [[65, 70], ["FCModel.FCModel.embed.weight.data.uniform_", "FCModel.FCModel.logit.bias.data.fill_", "FCModel.FCModel.logit.weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "embed", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "logit", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "logit", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_hidden": [[71, 78], ["next", "FCModel.FCModel.parameters", "next.new_zeros", "next.new_zeros", "next.new_zeros"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "weight", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "if", "self", ".", "rnn_type", "==", "'lstm'", ":", "\n", "            ", "return", "(", "weight", ".", "new_zeros", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ",", "\n", "weight", ".", "new_zeros", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "weight", ".", "new_zeros", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel._forward": [[79, 112], ["fc_feats.size", "FCModel.FCModel.init_hidden", "range", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "seq.size", "FCModel.FCModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "outputs.append", "FCModel.FCModel.img_embed", "FCModel.FCModel.embed", "FCModel.FCModel.logit", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fc_feats.data.new().uniform_", "seq[].clone", "sample_mask.sum", "seq[].clone", "sample_mask.nonzero().view", "seq[].data.clone", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "seq[].data.clone.index_copy_", "seq[].sum", "_.unsqueeze", "fc_feats.data.new", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "sample_mask.nonzero", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.logit"], ["", "", "def", "_forward", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "seq", ",", "att_masks", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "outputs", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "seq", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "xt", "=", "self", ".", "img_embed", "(", "fc_feats", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "training", "and", "i", ">=", "2", "and", "self", ".", "ss_prob", ">", "0.0", ":", "# otherwiste no need to sample", "\n", "                    ", "sample_prob", "=", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "uniform_", "(", "0", ",", "1", ")", "\n", "sample_mask", "=", "sample_prob", "<", "self", ".", "ss_prob", "\n", "if", "sample_mask", ".", "sum", "(", ")", "==", "0", ":", "\n", "                        ", "it", "=", "seq", "[", ":", ",", "i", "-", "1", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                        ", "sample_ind", "=", "sample_mask", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "it", "=", "seq", "[", ":", ",", "i", "-", "1", "]", ".", "data", ".", "clone", "(", ")", "\n", "#prob_prev = torch.exp(outputs[-1].data.index_select(0, sample_ind)) # fetch prev distribution: shape Nx(M+1)", "\n", "#it.index_copy_(0, sample_ind, torch.multinomial(prob_prev, 1).view(-1))", "\n", "prob_prev", "=", "torch", ".", "exp", "(", "outputs", "[", "-", "1", "]", ".", "data", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "it", ".", "index_copy_", "(", "0", ",", "sample_ind", ",", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "view", "(", "-", "1", ")", ".", "index_select", "(", "0", ",", "sample_ind", ")", ")", "\n", "", "", "else", ":", "\n", "                    ", "it", "=", "seq", "[", ":", ",", "i", "-", "1", "]", ".", "clone", "(", ")", "\n", "# break if all the sequences end", "\n", "", "if", "i", ">=", "2", "and", "seq", "[", ":", ",", "i", "-", "1", "]", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "break", "\n", "", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "state", ")", "\n", "output", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ",", "dim", "=", "1", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "outputs", "[", "1", ":", "]", "]", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.get_logprobs_state": [[113, 121], ["FCModel.FCModel.embed", "FCModel.FCModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "FCModel.FCModel.logit"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.logit"], ["", "def", "get_logprobs_state", "(", "self", ",", "it", ",", "state", ")", ":", "\n", "# 'it' is contains a word index", "\n", "        ", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ",", "dim", "=", "1", ")", "\n", "\n", "return", "logprobs", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel._sample_beam": [[122, 149], ["opt.get", "fc_feats.size", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "range", "FCModel.FCModel.init_hidden", "range", "FCModel.FCModel.beam_search", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "FCModel.FCModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "FCModel.FCModel.img_embed().expand", "FCModel.FCModel.logit", "fc_feats.data.new().long().zero_", "FCModel.FCModel.embed", "FCModel.FCModel.img_embed", "fc_feats.data.new().long", "fc_feats.data.new"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.husthuaan_AAT.models.CaptionModel.CaptionModel.beam_search", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.logit", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed"], ["", "def", "_sample_beam", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "att_masks", "=", "None", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "10", ")", "\n", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "\n", "assert", "beam_size", "<=", "self", ".", "vocab_size", "+", "1", ",", "'lets assume this for now, otherwise this corner case causes a few headaches down the road. can be dealt with in future if needed'", "\n", "seq", "=", "torch", ".", "LongTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", ".", "zero_", "(", ")", "\n", "seqLogprobs", "=", "torch", ".", "FloatTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", "\n", "# lets process every image independently for now, for simplicity", "\n", "\n", "self", ".", "done_beams", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "for", "k", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "state", "=", "self", ".", "init_hidden", "(", "beam_size", ")", "\n", "for", "t", "in", "range", "(", "2", ")", ":", "\n", "                ", "if", "t", "==", "0", ":", "\n", "                    ", "xt", "=", "self", ".", "img_embed", "(", "fc_feats", "[", "k", ":", "k", "+", "1", "]", ")", ".", "expand", "(", "beam_size", ",", "self", ".", "input_encoding_size", ")", "\n", "", "elif", "t", "==", "1", ":", "# input <bos>", "\n", "                    ", "it", "=", "fc_feats", ".", "data", ".", "new", "(", "beam_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "self", ".", "done_beams", "[", "k", "]", "=", "self", ".", "beam_search", "(", "state", ",", "logprobs", ",", "opt", "=", "opt", ")", "\n", "seq", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'seq'", "]", "# the first beam has highest cumulative score", "\n", "seqLogprobs", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'logps'", "]", "\n", "# return the samples and their log likelihoods", "\n", "", "return", "seq", ".", "transpose", "(", "0", ",", "1", ")", ",", "seqLogprobs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel._sample": [[150, 201], ["opt.get", "opt.get", "opt.get", "fc_feats.size", "FCModel.FCModel.init_hidden", "fc_feats.new_zeros", "fc_feats.new_zeros", "range", "FCModel.FCModel._sample_beam", "FCModel.FCModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "FCModel.FCModel.img_embed", "FCModel.FCModel.embed", "FCModel.FCModel.logit", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "fc_feats.data.new().long().zero_.view().long", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.log_softmax.gather", "fc_feats.data.new().long().zero_.view().long", "F.log_softmax.gather.view", "fc_feats.data.new().long().zero_", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "unfinished.type_as", "unfinished.sum", "fc_feats.data.new().long().zero_.view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "fc_feats.data.new().long().zero_.view", "fc_feats.data.new().long", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "fc_feats.data.new"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.husthuaan_AAT.models.FCModel.FCModel._sample_beam", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.core", "home.repos.pwc.inspect_result.husthuaan_AAT.models.AttEnsemble.AttEnsemble.embed", "home.repos.pwc.inspect_result.husthuaan_AAT.models.TransformerModel.TransformerModel.logit"], ["", "def", "_sample", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "att_masks", "=", "None", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "sample_method", "=", "opt", ".", "get", "(", "'sample_method'", ",", "'greedy'", ")", "\n", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "1", ")", "\n", "temperature", "=", "opt", ".", "get", "(", "'temperature'", ",", "1.0", ")", "\n", "if", "beam_size", ">", "1", ":", "\n", "            ", "return", "self", ".", "_sample_beam", "(", "fc_feats", ",", "att_feats", ",", "opt", ")", "\n", "\n", "", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "seq", "=", "fc_feats", ".", "new_zeros", "(", "batch_size", ",", "self", ".", "seq_length", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "seqLogprobs", "=", "fc_feats", ".", "new_zeros", "(", "batch_size", ",", "self", ".", "seq_length", ")", "\n", "for", "t", "in", "range", "(", "self", ".", "seq_length", "+", "2", ")", ":", "\n", "            ", "if", "t", "==", "0", ":", "\n", "                ", "xt", "=", "self", ".", "img_embed", "(", "fc_feats", ")", "\n", "", "else", ":", "\n", "                ", "if", "t", "==", "1", ":", "# input <bos>", "\n", "                    ", "it", "=", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# sample the next_word", "\n", "if", "t", "==", "self", ".", "seq_length", "+", "1", ":", "# skip if we achieve maximum length", "\n", "                ", "break", "\n", "", "if", "sample_method", "==", "'greedy'", ":", "\n", "                ", "sampleLogprobs", ",", "it", "=", "torch", ".", "max", "(", "logprobs", ".", "data", ",", "1", ")", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "temperature", "==", "1.0", ":", "\n", "                    ", "prob_prev", "=", "torch", ".", "exp", "(", "logprobs", ".", "data", ")", ".", "cpu", "(", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "", "else", ":", "\n", "# scale logprobs by temperature", "\n", "                    ", "prob_prev", "=", "torch", ".", "exp", "(", "torch", ".", "div", "(", "logprobs", ".", "data", ",", "temperature", ")", ")", ".", "cpu", "(", ")", "\n", "", "it", "=", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "cuda", "(", ")", "\n", "sampleLogprobs", "=", "logprobs", ".", "gather", "(", "1", ",", "it", ")", "# gather the logprobs at sampled positions", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "# and flatten indices for downstream processing", "\n", "\n", "", "if", "t", ">=", "1", ":", "\n", "# stop when all finished", "\n", "                ", "if", "t", "==", "1", ":", "\n", "                    ", "unfinished", "=", "it", ">", "0", "\n", "", "else", ":", "\n", "                    ", "unfinished", "=", "unfinished", "*", "(", "it", ">", "0", ")", "\n", "", "it", "=", "it", "*", "unfinished", ".", "type_as", "(", "it", ")", "\n", "seq", "[", ":", ",", "t", "-", "1", "]", "=", "it", "#seq[t] the input of t+2 time step", "\n", "seqLogprobs", "[", ":", ",", "t", "-", "1", "]", "=", "sampleLogprobs", ".", "view", "(", "-", "1", ")", "\n", "if", "unfinished", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "break", "\n", "\n", "", "", "", "return", "seq", ",", "seqLogprobs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.husthuaan_AAT.models.__init__.setup": [[20, 72], ["FCModel.FCModel", "vars().get", "os.path.isdir", "os.path.isfile", "AATModel.AATModel.load_state_dict", "AttModel.LMModel", "os.path.join", "torch.load", "AttModel.NewFCModel", "vars", "os.path.join", "ShowTellModel.ShowTellModel", "AttModel.Att2inModel", "AttModel.Att2in2Model", "AttModel.Att2all2Model", "AttModel.AdaAttModel", "AttModel.AdaAttMOModel", "AttModel.TopDownModel", "AttModel.StackAttModel", "AttModel.DenseAttModel", "TransformerModel.TransformerModel", "AoAModel.AoAModel", "AATModel.AATModel", "Exception"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.dataloader.BlobFetcher.get", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.load_state_dict"], ["def", "setup", "(", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "caption_model", "==", "'fc'", ":", "\n", "        ", "model", "=", "FCModel", "(", "opt", ")", "\n", "", "elif", "opt", ".", "caption_model", "==", "'language_model'", ":", "\n", "        ", "model", "=", "LMModel", "(", "opt", ")", "\n", "", "elif", "opt", ".", "caption_model", "==", "'newfc'", ":", "\n", "        ", "model", "=", "NewFCModel", "(", "opt", ")", "\n", "", "elif", "opt", ".", "caption_model", "==", "'show_tell'", ":", "\n", "        ", "model", "=", "ShowTellModel", "(", "opt", ")", "\n", "# Att2in model in self-critical", "\n", "", "elif", "opt", ".", "caption_model", "==", "'att2in'", ":", "\n", "        ", "model", "=", "Att2inModel", "(", "opt", ")", "\n", "# Att2in model with two-layer MLP img embedding and word embedding", "\n", "", "elif", "opt", ".", "caption_model", "==", "'att2in2'", ":", "\n", "        ", "model", "=", "Att2in2Model", "(", "opt", ")", "\n", "", "elif", "opt", ".", "caption_model", "==", "'att2all2'", ":", "\n", "        ", "model", "=", "Att2all2Model", "(", "opt", ")", "\n", "# Adaptive Attention model from Knowing when to look", "\n", "", "elif", "opt", ".", "caption_model", "==", "'adaatt'", ":", "\n", "        ", "model", "=", "AdaAttModel", "(", "opt", ")", "\n", "# Adaptive Attention with maxout lstm", "\n", "", "elif", "opt", ".", "caption_model", "==", "'adaattmo'", ":", "\n", "        ", "model", "=", "AdaAttMOModel", "(", "opt", ")", "\n", "# Top-down attention model", "\n", "", "elif", "opt", ".", "caption_model", "==", "'topdown'", ":", "\n", "        ", "model", "=", "TopDownModel", "(", "opt", ")", "\n", "# StackAtt", "\n", "", "elif", "opt", ".", "caption_model", "==", "'stackatt'", ":", "\n", "        ", "model", "=", "StackAttModel", "(", "opt", ")", "\n", "# DenseAtt", "\n", "", "elif", "opt", ".", "caption_model", "==", "'denseatt'", ":", "\n", "        ", "model", "=", "DenseAttModel", "(", "opt", ")", "\n", "# Transformer", "\n", "", "elif", "opt", ".", "caption_model", "==", "'transformer'", ":", "\n", "        ", "model", "=", "TransformerModel", "(", "opt", ")", "\n", "# AoANet", "\n", "", "elif", "opt", ".", "caption_model", "==", "'aoa'", ":", "\n", "        ", "model", "=", "AoAModel", "(", "opt", ")", "\n", "# AAT    ", "\n", "", "elif", "opt", ".", "caption_model", "==", "'aat'", ":", "\n", "        ", "model", "=", "AATModel", "(", "opt", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"Caption model not supported: {}\"", ".", "format", "(", "opt", ".", "caption_model", ")", ")", "\n", "\n", "# check compatibility if training is continued from previously saved model", "\n", "", "if", "vars", "(", "opt", ")", ".", "get", "(", "'start_from'", ",", "None", ")", "is", "not", "None", ":", "\n", "# check if all necessary files exist ", "\n", "        ", "assert", "os", ".", "path", ".", "isdir", "(", "opt", ".", "start_from", ")", ",", "\" %s must be a a path\"", "%", "opt", ".", "start_from", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "\"infos_\"", "+", "opt", ".", "id", "+", "\".pkl\"", ")", ")", ",", "\"infos.pkl file does not exist in path %s\"", "%", "opt", ".", "start_from", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "'model.pth'", ")", ")", ")", "\n", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.loss_wrapper.LossWrapper.__init__": [[8, 17], ["super().__init__", "misc.RewardCriterion", "misc.LabelSmoothing", "misc.LanguageModelCriterion"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "opt", ")", ":", "\n", "        ", "super", "(", "LossWrapper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "model", "=", "model", "\n", "if", "opt", ".", "label_smoothing", ">", "0", ":", "\n", "            ", "self", ".", "crit", "=", "utils", ".", "LabelSmoothing", "(", "smoothing", "=", "opt", ".", "label_smoothing", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "crit", "=", "utils", ".", "LanguageModelCriterion", "(", ")", "\n", "", "self", ".", "rl_crit", "=", "utils", ".", "RewardCriterion", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.loss_wrapper.LossWrapper.forward": [[18, 51], ["loss_wrapper.LossWrapper.crit", "loss_wrapper.LossWrapper.model.eval", "loss_wrapper.LossWrapper.model.train", "loss_wrapper.LossWrapper.model", "loss_wrapper.LossWrapper.", "torch.from_numpy().float().to", "loss_wrapper.LossWrapper.rl_crit", "reward[].mean", "torch.stack().t", "loss_wrapper.LossWrapper.clone", "loss_wrapper.LossWrapper.model", "torch.no_grad", "loss_wrapper.LossWrapper.model", "mask_.cpu().numpy().sum", "gt_indices.tolist", "torch.from_numpy().float", "torch.stack", "torch.cat", "mask_.cpu().numpy", "torch.from_numpy", "numpy.array().transpose", "mask_.cpu().numpy", "torch.stack().t.size", "gen_result.new_ones", "torch.stack().t.size", "mask_.float", "mask_.cpu", "gen_result.size", "numpy.array", "mask_.cpu"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.None.train.train"], ["", "def", "forward", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "labels", ",", "masks", ",", "att_masks", ",", "gts", ",", "gt_indices", ",", "\n", "sc_flag", ")", ":", "\n", "        ", "out", "=", "{", "}", "\n", "if", "not", "sc_flag", ":", "\n", "            ", "loss", "=", "self", ".", "crit", "(", "self", ".", "model", "(", "fc_feats", ",", "att_feats", ",", "labels", ",", "att_masks", ")", ",", "labels", "[", ":", ",", "1", ":", "]", ",", "masks", "[", ":", ",", "1", ":", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "greedy_res", ",", "_", "=", "self", ".", "model", "(", "fc_feats", ",", "att_feats", ",", "att_masks", ",", "mode", "=", "'sample'", ")", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "gen_result", ",", "sample_logprobs", "=", "self", ".", "model", "(", "fc_feats", ",", "att_feats", ",", "att_masks", ",", "opt", "=", "{", "'sample_method'", ":", "'sample'", "}", ",", "mode", "=", "'sample'", ")", "\n", "\n", "gts", "=", "[", "gts", "[", "_", "]", "for", "_", "in", "gt_indices", ".", "tolist", "(", ")", "]", "\n", "reward", "=", "get_self_critical_reward", "(", "greedy_res", ",", "gts", ",", "gen_result", ",", "self", ".", "opt", ")", "\n", "reward", "=", "torch", ".", "from_numpy", "(", "reward", ")", ".", "float", "(", ")", ".", "to", "(", "gen_result", ".", "device", ")", "\n", "loss", "=", "self", ".", "rl_crit", "(", "sample_logprobs", ",", "gen_result", ".", "data", ",", "reward", ")", "\n", "out", "[", "'reward'", "]", "=", "reward", "[", ":", ",", "0", "]", ".", "mean", "(", ")", "\n", "\n", "", "if", "self", ".", "opt", ".", "caption_model", "==", "'aat'", ":", "\n", "            ", "all_aat_loss", "=", "torch", ".", "stack", "(", "self", ".", "model", ".", "all_att_cost", ")", ".", "t", "(", ")", "\n", "if", "not", "sc_flag", ":", "\n", "                ", "mask_", "=", "masks", "[", ":", ",", ":", "all_aat_loss", ".", "size", "(", ")", "[", "1", "]", "]", "\n", "", "else", ":", "\n", "                ", "mask_", "=", "(", "torch", ".", "cat", "(", "(", "gen_result", ".", "new_ones", "(", "gen_result", ".", "size", "(", "0", ")", ",", "1", ")", ",", "gen_result", ")", ",", "dim", "=", "1", ")", ">", "0", ")", "[", ":", ",", ":", "all_aat_loss", ".", "size", "(", ")", "[", "1", "]", "]", "\n", "", "aat_loss", "=", "(", "all_aat_loss", "*", "mask_", ".", "float", "(", ")", ")", ".", "sum", "(", "1", ")", ".", "mean", "(", ")", "\n", "out", "[", "'aat_loss'", "]", "=", "aat_loss", "\n", "out", "[", "'att_step'", "]", "=", "self", ".", "model", ".", "all_att_step", "\n", "out", "[", "'avg_att_time'", "]", "=", "(", "np", ".", "array", "(", "self", ".", "model", ".", "all_att_step", ")", ".", "transpose", "(", ")", "*", "mask_", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ".", "sum", "(", ")", "/", "mask_", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "sum", "(", ")", "\n", "out", "[", "'loss_'", "]", "=", "loss", ".", "clone", "(", ")", "\n", "loss", "+=", "self", ".", "opt", ".", "aat_lambda", "*", "aat_loss", "\n", "\n", "", "out", "[", "'loss'", "]", "=", "loss", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet.ResNet.__init__": [[7, 13], ["super().__init__", "torch.MaxPool2d", "torch.MaxPool2d", "range", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "num_classes", "=", "1000", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", "block", ",", "layers", ",", "num_classes", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "0", ",", "ceil_mode", "=", "True", ")", "# change", "\n", "for", "i", "in", "range", "(", "2", ",", "5", ")", ":", "\n", "            ", "getattr", "(", "self", ",", "'layer%d'", "%", "i", ")", "[", "0", "]", ".", "conv1", ".", "stride", "=", "(", "2", ",", "2", ")", "\n", "getattr", "(", "self", ",", "'layer%d'", "%", "i", ")", "[", "0", "]", ".", "conv2", ".", "stride", "=", "(", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet.resnet18": [[14, 24], ["resnet.ResNet", "ResNet.load_state_dict", "model_zoo.load_url"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.load_state_dict"], ["", "", "", "def", "resnet18", "(", "pretrained", "=", "False", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet18'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet.resnet34": [[26, 36], ["resnet.ResNet", "ResNet.load_state_dict", "model_zoo.load_url"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.load_state_dict"], ["", "def", "resnet34", "(", "pretrained", "=", "False", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-34 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet34'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet.resnet50": [[38, 48], ["resnet.ResNet", "ResNet.load_state_dict", "model_zoo.load_url"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.load_state_dict"], ["", "def", "resnet50", "(", "pretrained", "=", "False", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet50'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet.resnet101": [[50, 60], ["resnet.ResNet", "ResNet.load_state_dict", "model_zoo.load_url"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.load_state_dict"], ["", "def", "resnet101", "(", "pretrained", "=", "False", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet101'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet.resnet152": [[62, 72], ["resnet.ResNet", "ResNet.load_state_dict", "model_zoo.load_url"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.load_state_dict"], ["", "def", "resnet152", "(", "pretrained", "=", "False", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-152 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet152'", "]", ")", ")", "\n", "", "return", "model", "", "", ""]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.rewards.init_scorer": [[21, 26], ["pyciderevalcap.ciderD.ciderD.CiderD", "pycocoevalcap.bleu.bleu.Bleu"], "function", ["None"], ["def", "init_scorer", "(", "cached_tokens", ")", ":", "\n", "    ", "global", "CiderD_scorer", "\n", "CiderD_scorer", "=", "CiderD_scorer", "or", "CiderD", "(", "df", "=", "cached_tokens", ")", "\n", "global", "Bleu_scorer", "\n", "Bleu_scorer", "=", "Bleu_scorer", "or", "Bleu", "(", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.rewards.array_to_str": [[27, 34], ["range", "out.strip", "len", "str"], "function", ["None"], ["", "def", "array_to_str", "(", "arr", ")", ":", "\n", "    ", "out", "=", "''", "\n", "for", "i", "in", "range", "(", "len", "(", "arr", ")", ")", ":", "\n", "        ", "out", "+=", "str", "(", "arr", "[", "i", "]", ")", "+", "' '", "\n", "if", "arr", "[", "i", "]", "==", "0", ":", "\n", "            ", "break", "\n", "", "", "return", "out", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.rewards.get_self_critical_reward": [[35, 73], ["gen_result.data.cpu().numpy.size", "collections.OrderedDict", "gen_result.data.cpu().numpy.data.cpu().numpy", "greedy_res.data.cpu().numpy.data.cpu().numpy", "range", "range", "collections.OrderedDict", "range", "numpy.repeat", "len", "len", "CiderD_scorer.compute_score", "print", "Bleu_scorer.compute_score", "numpy.array", "print", "gen_result.data.cpu().numpy.data.cpu", "greedy_res.data.cpu().numpy.data.cpu", "rewards.array_to_str", "rewards.array_to_str", "rewards.array_to_str", "range", "range", "range", "range", "len"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.rewards.array_to_str", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.rewards.array_to_str", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.rewards.array_to_str"], ["", "def", "get_self_critical_reward", "(", "greedy_res", ",", "data_gts", ",", "gen_result", ",", "opt", ")", ":", "\n", "    ", "batch_size", "=", "gen_result", ".", "size", "(", "0", ")", "# batch_size = sample_size * seq_per_img", "\n", "seq_per_img", "=", "batch_size", "//", "len", "(", "data_gts", ")", "\n", "\n", "res", "=", "OrderedDict", "(", ")", "\n", "\n", "gen_result", "=", "gen_result", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "greedy_res", "=", "greedy_res", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "res", "[", "i", "]", "=", "[", "array_to_str", "(", "gen_result", "[", "i", "]", ")", "]", "\n", "", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "res", "[", "batch_size", "+", "i", "]", "=", "[", "array_to_str", "(", "greedy_res", "[", "i", "]", ")", "]", "\n", "\n", "", "gts", "=", "OrderedDict", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "data_gts", ")", ")", ":", "\n", "        ", "gts", "[", "i", "]", "=", "[", "array_to_str", "(", "data_gts", "[", "i", "]", "[", "j", "]", ")", "for", "j", "in", "range", "(", "len", "(", "data_gts", "[", "i", "]", ")", ")", "]", "\n", "\n", "", "res_", "=", "[", "{", "'image_id'", ":", "i", ",", "'caption'", ":", "res", "[", "i", "]", "}", "for", "i", "in", "range", "(", "2", "*", "batch_size", ")", "]", "\n", "res__", "=", "{", "i", ":", "res", "[", "i", "]", "for", "i", "in", "range", "(", "2", "*", "batch_size", ")", "}", "\n", "gts", "=", "{", "i", ":", "gts", "[", "i", "%", "batch_size", "//", "seq_per_img", "]", "for", "i", "in", "range", "(", "2", "*", "batch_size", ")", "}", "\n", "if", "opt", ".", "cider_reward_weight", ">", "0", ":", "\n", "        ", "_", ",", "cider_scores", "=", "CiderD_scorer", ".", "compute_score", "(", "gts", ",", "res_", ")", "\n", "print", "(", "'Cider scores:'", ",", "_", ")", "\n", "", "else", ":", "\n", "        ", "cider_scores", "=", "0", "\n", "", "if", "opt", ".", "bleu_reward_weight", ">", "0", ":", "\n", "        ", "_", ",", "bleu_scores", "=", "Bleu_scorer", ".", "compute_score", "(", "gts", ",", "res__", ")", "\n", "bleu_scores", "=", "np", ".", "array", "(", "bleu_scores", "[", "3", "]", ")", "\n", "print", "(", "'Bleu scores:'", ",", "_", "[", "3", "]", ")", "\n", "", "else", ":", "\n", "        ", "bleu_scores", "=", "0", "\n", "", "scores", "=", "opt", ".", "cider_reward_weight", "*", "cider_scores", "+", "opt", ".", "bleu_reward_weight", "*", "bleu_scores", "\n", "\n", "scores", "=", "scores", "[", ":", "batch_size", "]", "-", "scores", "[", "batch_size", ":", "]", "\n", "\n", "rewards", "=", "np", ".", "repeat", "(", "scores", "[", ":", ",", "np", ".", "newaxis", "]", ",", "gen_result", ".", "shape", "[", "1", "]", ",", "1", ")", "\n", "\n", "return", "rewards", "\n", "", ""]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.RewardCriterion.__init__": [[87, 89], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "RewardCriterion", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.RewardCriterion.forward": [[90, 99], ["to_contiguous().view", "to_contiguous().view", "to_contiguous().view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "utils.to_contiguous", "utils.to_contiguous", "utils.to_contiguous", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "to_contiguous().view.new().fill_", "to_contiguous().view.new", "to_contiguous().view.size"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.to_contiguous", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.to_contiguous", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.to_contiguous"], ["", "def", "forward", "(", "self", ",", "input", ",", "seq", ",", "reward", ")", ":", "\n", "        ", "input", "=", "to_contiguous", "(", "input", ")", ".", "view", "(", "-", "1", ")", "\n", "reward", "=", "to_contiguous", "(", "reward", ")", ".", "view", "(", "-", "1", ")", "\n", "mask", "=", "(", "seq", ">", "0", ")", ".", "float", "(", ")", "\n", "mask", "=", "to_contiguous", "(", "torch", ".", "cat", "(", "[", "mask", ".", "new", "(", "mask", ".", "size", "(", "0", ")", ",", "1", ")", ".", "fill_", "(", "1", ")", ",", "mask", "[", ":", ",", ":", "-", "1", "]", "]", ",", "1", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "output", "=", "-", "input", "*", "reward", "*", "mask", "\n", "output", "=", "torch", ".", "sum", "(", "output", ")", "/", "torch", ".", "sum", "(", "mask", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.LanguageModelCriterion.__init__": [[101, 103], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "LanguageModelCriterion", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.LanguageModelCriterion.forward": [[104, 113], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "input.gather().squeeze", "input.size", "input.size", "input.gather", "target.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ",", "mask", ")", ":", "\n", "# truncate to the same size", "\n", "        ", "target", "=", "target", "[", ":", ",", ":", "input", ".", "size", "(", "1", ")", "]", "\n", "mask", "=", "mask", "[", ":", ",", ":", "input", ".", "size", "(", "1", ")", "]", "\n", "\n", "output", "=", "-", "input", ".", "gather", "(", "2", ",", "target", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "*", "mask", "\n", "output", "=", "torch", ".", "sum", "(", "output", ")", "/", "torch", ".", "sum", "(", "mask", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.LabelSmoothing.__init__": [[116, 124], ["torch.Module.__init__", "torch.KLDivLoss", "torch.KLDivLoss", "torch.KLDivLoss"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["def", "__init__", "(", "self", ",", "size", "=", "0", ",", "padding_idx", "=", "0", ",", "smoothing", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "LabelSmoothing", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "criterion", "=", "nn", ".", "KLDivLoss", "(", "size_average", "=", "False", ",", "reduce", "=", "False", ")", "\n", "# self.padding_idx = padding_idx", "\n", "self", ".", "confidence", "=", "1.0", "-", "smoothing", "\n", "self", ".", "smoothing", "=", "smoothing", "\n", "# self.size = size", "\n", "self", ".", "true_dist", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.LabelSmoothing.forward": [[125, 145], ["to_contiguous().view", "to_contiguous().view", "to_contiguous().view", "to_contiguous().view.size", "to_contiguous().view.data.clone", "to_contiguous().view.data.clone.fill_", "to_contiguous().view.data.clone.scatter_", "to_contiguous().view.size", "to_contiguous().view.data.unsqueeze", "to_contiguous().view.sum", "utils.to_contiguous", "utils.to_contiguous", "utils.to_contiguous", "to_contiguous().view.size", "to_contiguous().view.size", "utils.LabelSmoothing.criterion().sum", "utils.LabelSmoothing.criterion"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.to_contiguous", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.to_contiguous", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.to_contiguous"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ",", "mask", ")", ":", "\n", "# truncate to the same size", "\n", "        ", "target", "=", "target", "[", ":", ",", ":", "input", ".", "size", "(", "1", ")", "]", "\n", "mask", "=", "mask", "[", ":", ",", ":", "input", ".", "size", "(", "1", ")", "]", "\n", "\n", "input", "=", "to_contiguous", "(", "input", ")", ".", "view", "(", "-", "1", ",", "input", ".", "size", "(", "-", "1", ")", ")", "\n", "target", "=", "to_contiguous", "(", "target", ")", ".", "view", "(", "-", "1", ")", "\n", "mask", "=", "to_contiguous", "(", "mask", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "# assert x.size(1) == self.size", "\n", "self", ".", "size", "=", "input", ".", "size", "(", "1", ")", "\n", "# true_dist = x.data.clone()", "\n", "true_dist", "=", "input", ".", "data", ".", "clone", "(", ")", "\n", "# true_dist.fill_(self.smoothing / (self.size - 2))", "\n", "true_dist", ".", "fill_", "(", "self", ".", "smoothing", "/", "(", "self", ".", "size", "-", "1", ")", ")", "\n", "true_dist", ".", "scatter_", "(", "1", ",", "target", ".", "data", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "confidence", ")", "\n", "# true_dist[:, self.padding_idx] = 0", "\n", "# mask = torch.nonzero(target.data == self.padding_idx)", "\n", "# self.true_dist = true_dist", "\n", "return", "(", "self", ".", "criterion", "(", "input", ",", "true_dist", ")", ".", "sum", "(", "1", ")", "*", "mask", ")", ".", "sum", "(", ")", "/", "mask", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.NoamOpt.__init__": [[205, 212], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_size", ",", "factor", ",", "warmup", ",", "optimizer", ")", ":", "\n", "        ", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "warmup", "=", "warmup", "\n", "self", ".", "factor", "=", "factor", "\n", "self", ".", "model_size", "=", "model_size", "\n", "self", ".", "_rate", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.NoamOpt.step": [[213, 221], ["utils.NoamOpt.rate", "utils.NoamOpt.optimizer.step"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.rate", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.step"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"Update parameters and rate\"", "\n", "self", ".", "_step", "+=", "1", "\n", "rate", "=", "self", ".", "rate", "(", ")", "\n", "for", "p", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "            ", "p", "[", "'lr'", "]", "=", "rate", "\n", "", "self", ".", "_rate", "=", "rate", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.NoamOpt.rate": [[222, 229], ["min"], "methods", ["None"], ["", "def", "rate", "(", "self", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"Implement `lrate` above\"", "\n", "if", "step", "is", "None", ":", "\n", "            ", "step", "=", "self", ".", "_step", "\n", "", "return", "self", ".", "factor", "*", "(", "self", ".", "model_size", "**", "(", "-", "0.5", ")", "*", "\n", "min", "(", "step", "**", "(", "-", "0.5", ")", ",", "step", "*", "self", ".", "warmup", "**", "(", "-", "1.5", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.NoamOpt.__getattr__": [[230, 232], ["getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "optimizer", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.__init__": [[235, 239], ["torch.lr_scheduler.ReduceLROnPlateau", "torch.lr_scheduler.ReduceLROnPlateau", "torch.lr_scheduler.ReduceLROnPlateau", "utils.get_lr"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.get_lr"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "mode", "=", "'min'", ",", "factor", "=", "0.1", ",", "patience", "=", "10", ",", "verbose", "=", "False", ",", "threshold", "=", "0.0001", ",", "threshold_mode", "=", "'rel'", ",", "cooldown", "=", "0", ",", "min_lr", "=", "0", ",", "eps", "=", "1e-08", ")", ":", "\n", "        ", "self", ".", "scheduler", "=", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", ",", "factor", ",", "patience", ",", "verbose", ",", "threshold", ",", "threshold_mode", ",", "cooldown", ",", "min_lr", ",", "eps", ")", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "current_lr", "=", "get_lr", "(", "optimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.step": [[240, 243], ["utils.ReduceLROnPlateau.optimizer.step"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.step"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"Update parameters and rate\"", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.scheduler_step": [[244, 247], ["utils.ReduceLROnPlateau.scheduler.step", "utils.get_lr"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.step", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.get_lr"], ["", "def", "scheduler_step", "(", "self", ",", "val", ")", ":", "\n", "        ", "self", ".", "scheduler", ".", "step", "(", "val", ")", "\n", "self", ".", "current_lr", "=", "get_lr", "(", "self", ".", "optimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.state_dict": [[248, 252], ["utils.ReduceLROnPlateau.scheduler.state_dict", "utils.ReduceLROnPlateau.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.state_dict", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "'current_lr'", ":", "self", ".", "current_lr", ",", "\n", "'scheduler_state_dict'", ":", "self", ".", "scheduler", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_state_dict'", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.load_state_dict": [[253, 263], ["utils.ReduceLROnPlateau.optimizer.load_state_dict", "utils.set_lr", "utils.ReduceLROnPlateau.scheduler.load_state_dict", "utils.ReduceLROnPlateau.optimizer.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.load_state_dict", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.set_lr", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.load_state_dict", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "if", "'current_lr'", "not", "in", "state_dict", ":", "\n", "# it's normal optimizer", "\n", "            ", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", ")", "\n", "set_lr", "(", "self", ".", "optimizer", ",", "self", ".", "current_lr", ")", "# use the lr fromt the option", "\n", "", "else", ":", "\n", "# it's a schduler", "\n", "            ", "self", ".", "current_lr", "=", "state_dict", "[", "'current_lr'", "]", "\n", "self", ".", "scheduler", ".", "load_state_dict", "(", "state_dict", "[", "'scheduler_state_dict'", "]", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", "[", "'optimizer_state_dict'", "]", ")", "\n", "# current_lr is actually useless in this case", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.rate": [[265, 272], ["min"], "methods", ["None"], ["", "", "def", "rate", "(", "self", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"Implement `lrate` above\"", "\n", "if", "step", "is", "None", ":", "\n", "            ", "step", "=", "self", ".", "_step", "\n", "", "return", "self", ".", "factor", "*", "(", "self", ".", "model_size", "**", "(", "-", "0.5", ")", "*", "\n", "min", "(", "step", "**", "(", "-", "0.5", ")", ",", "step", "*", "self", ".", "warmup", "**", "(", "-", "1.5", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.ReduceLROnPlateau.__getattr__": [[273, 275], ["getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ".", "optimizer", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.pickle_load": [[18, 28], ["six.moves.cPickle.load", "six.moves.cPickle.load"], "function", ["None"], ["def", "pickle_load", "(", "f", ")", ":", "\n", "    ", "\"\"\" Load a pickle.\n    Parameters\n    ----------\n    f: file-like object\n    \"\"\"", "\n", "if", "six", ".", "PY3", ":", "\n", "        ", "return", "cPickle", ".", "load", "(", "f", ",", "encoding", "=", "'latin-1'", ")", "\n", "", "else", ":", "\n", "        ", "return", "cPickle", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.pickle_dump": [[30, 41], ["six.moves.cPickle.dump", "six.moves.cPickle.dump"], "function", ["None"], ["", "", "def", "pickle_dump", "(", "obj", ",", "f", ")", ":", "\n", "    ", "\"\"\" Dump a pickle.\n    Parameters\n    ----------\n    obj: pickled object\n    f: file-like object\n    \"\"\"", "\n", "if", "six", ".", "PY3", ":", "\n", "        ", "return", "cPickle", ".", "dump", "(", "obj", ",", "f", ",", "protocol", "=", "2", ")", "\n", "", "else", ":", "\n", "        ", "return", "cPickle", ".", "dump", "(", "obj", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.if_use_feat": [[43, 54], ["None"], "function", ["None"], ["", "", "def", "if_use_feat", "(", "caption_model", ")", ":", "\n", "# Decide if load attention feature according to caption model", "\n", "    ", "if", "caption_model", "in", "[", "'show_tell'", ",", "'all_img'", ",", "'fc'", ",", "'newfc'", "]", ":", "\n", "        ", "use_att", ",", "use_fc", "=", "False", ",", "True", "\n", "", "elif", "caption_model", "==", "'language_model'", ":", "\n", "        ", "use_att", ",", "use_fc", "=", "False", ",", "False", "\n", "", "elif", "caption_model", "in", "[", "'topdown'", ",", "'aoa'", ",", "'aat'", "]", ":", "\n", "        ", "use_fc", ",", "use_att", "=", "True", ",", "True", "\n", "", "else", ":", "\n", "        ", "use_att", ",", "use_fc", "=", "True", ",", "False", "\n", "", "return", "use_fc", ",", "use_att", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.decode_sequence": [[56, 79], ["seq.size", "range", "range", "int", "out.append", "os.getenv", "txt.split", "range", "txt.replace", "len", "str", "len", "ix.item"], "function", ["None"], ["", "def", "decode_sequence", "(", "ix_to_word", ",", "seq", ")", ":", "\n", "    ", "N", ",", "D", "=", "seq", ".", "size", "(", ")", "\n", "out", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "        ", "txt", "=", "''", "\n", "for", "j", "in", "range", "(", "D", ")", ":", "\n", "            ", "ix", "=", "seq", "[", "i", ",", "j", "]", "\n", "if", "ix", ">", "0", ":", "\n", "                ", "if", "j", ">=", "1", ":", "\n", "                    ", "txt", "=", "txt", "+", "' '", "\n", "", "txt", "=", "txt", "+", "ix_to_word", "[", "str", "(", "ix", ".", "item", "(", ")", ")", "]", "\n", "", "else", ":", "\n", "                ", "break", "\n", "", "", "if", "int", "(", "os", ".", "getenv", "(", "'REMOVE_BAD_ENDINGS'", ",", "'0'", ")", ")", ":", "\n", "            ", "flag", "=", "0", "\n", "words", "=", "txt", ".", "split", "(", "' '", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "words", ")", ")", ":", "\n", "                ", "if", "words", "[", "-", "j", "-", "1", "]", "not", "in", "bad_endings", ":", "\n", "                    ", "flag", "=", "-", "j", "\n", "break", "\n", "", "", "txt", "=", "' '", ".", "join", "(", "words", "[", "0", ":", "len", "(", "words", ")", "+", "flag", "]", ")", "\n", "", "out", ".", "append", "(", "txt", ".", "replace", "(", "'@@ '", ",", "''", ")", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.to_contiguous": [[80, 85], ["tensor.is_contiguous", "tensor.contiguous"], "function", ["None"], ["", "def", "to_contiguous", "(", "tensor", ")", ":", "\n", "    ", "if", "tensor", ".", "is_contiguous", "(", ")", ":", "\n", "        ", "return", "tensor", "\n", "", "else", ":", "\n", "        ", "return", "tensor", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.set_lr": [[146, 149], ["None"], "function", ["None"], ["", "", "def", "set_lr", "(", "optimizer", ",", "lr", ")", ":", "\n", "    ", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.get_lr": [[150, 153], ["None"], "function", ["None"], ["", "", "def", "get_lr", "(", "optimizer", ")", ":", "\n", "    ", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "return", "group", "[", "'lr'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.clip_gradient": [[154, 158], ["param.grad.data.clamp_"], "function", ["None"], ["", "", "def", "clip_gradient", "(", "optimizer", ",", "grad_clip", ")", ":", "\n", "    ", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "for", "param", "in", "group", "[", "'params'", "]", ":", "\n", "            ", "param", ".", "grad", ".", "data", ".", "clamp_", "(", "-", "grad_clip", ",", "grad_clip", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.build_optimizer": [[159, 174], ["torch.RMSprop", "torch.Adagrad", "torch.SGD", "torch.SGD", "torch.SGD", "torch.Adam", "Exception"], "function", ["None"], ["", "", "", "def", "build_optimizer", "(", "params", ",", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "optim", "==", "'rmsprop'", ":", "\n", "        ", "return", "optim", ".", "RMSprop", "(", "params", ",", "opt", ".", "learning_rate", ",", "opt", ".", "optim_alpha", ",", "opt", ".", "optim_epsilon", ",", "weight_decay", "=", "opt", ".", "weight_decay", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'adagrad'", ":", "\n", "        ", "return", "optim", ".", "Adagrad", "(", "params", ",", "opt", ".", "learning_rate", ",", "weight_decay", "=", "opt", ".", "weight_decay", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'sgd'", ":", "\n", "        ", "return", "optim", ".", "SGD", "(", "params", ",", "opt", ".", "learning_rate", ",", "weight_decay", "=", "opt", ".", "weight_decay", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'sgdm'", ":", "\n", "        ", "return", "optim", ".", "SGD", "(", "params", ",", "opt", ".", "learning_rate", ",", "opt", ".", "optim_alpha", ",", "weight_decay", "=", "opt", ".", "weight_decay", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'sgdmom'", ":", "\n", "        ", "return", "optim", ".", "SGD", "(", "params", ",", "opt", ".", "learning_rate", ",", "opt", ".", "optim_alpha", ",", "weight_decay", "=", "opt", ".", "weight_decay", ",", "nesterov", "=", "True", ")", "\n", "", "elif", "opt", ".", "optim", "==", "'adam'", ":", "\n", "        ", "return", "optim", ".", "Adam", "(", "params", ",", "opt", ".", "learning_rate", ",", "(", "opt", ".", "optim_alpha", ",", "opt", ".", "optim_beta", ")", ",", "opt", ".", "optim_epsilon", ",", "weight_decay", "=", "opt", ".", "weight_decay", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"bad option opt.optim: {}\"", ".", "format", "(", "opt", ".", "optim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.penalty_builder": [[176, 185], ["penalty_config.split", "float", "utils.length_wu", "utils.length_average"], "function", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.length_wu", "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.length_average"], ["", "", "def", "penalty_builder", "(", "penalty_config", ")", ":", "\n", "    ", "if", "penalty_config", "==", "''", ":", "\n", "        ", "return", "lambda", "x", ",", "y", ":", "y", "\n", "", "pen_type", ",", "alpha", "=", "penalty_config", ".", "split", "(", "'_'", ")", "\n", "alpha", "=", "float", "(", "alpha", ")", "\n", "if", "pen_type", "==", "'wu'", ":", "\n", "        ", "return", "lambda", "x", ",", "y", ":", "length_wu", "(", "x", ",", "y", ",", "alpha", ")", "\n", "", "if", "pen_type", "==", "'avg'", ":", "\n", "        ", "return", "lambda", "x", ",", "y", ":", "length_average", "(", "x", ",", "y", ",", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.length_wu": [[186, 195], ["None"], "function", ["None"], ["", "", "def", "length_wu", "(", "length", ",", "logprobs", ",", "alpha", "=", "0.", ")", ":", "\n", "    ", "\"\"\"\n    NMT length re-ranking score from\n    \"Google's Neural Machine Translation System\" :cite:`wu2016google`.\n    \"\"\"", "\n", "\n", "modifier", "=", "(", "(", "(", "5", "+", "length", ")", "**", "alpha", ")", "/", "\n", "(", "(", "5", "+", "1", ")", "**", "alpha", ")", ")", "\n", "return", "(", "logprobs", "/", "modifier", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.length_average": [[196, 201], ["None"], "function", ["None"], ["", "def", "length_average", "(", "length", ",", "logprobs", ",", "alpha", "=", "0.", ")", ":", "\n", "    ", "\"\"\"\n    Returns the average probability of tokens in a sequence.\n    \"\"\"", "\n", "return", "logprobs", "/", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.utils.get_std_opt": [[276, 281], ["utils.NoamOpt", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "model.parameters"], "function", ["None"], ["", "", "def", "get_std_opt", "(", "model", ",", "factor", "=", "1", ",", "warmup", "=", "2000", ")", ":", "\n", "# return NoamOpt(model.tgt_embed[0].d_model, 2, 4000,", "\n", "#         torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))", "\n", "    ", "return", "NoamOpt", "(", "model", ".", "model", ".", "tgt_embed", "[", "0", "]", ".", "d_model", ",", "factor", ",", "warmup", ",", "\n", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "0", ",", "betas", "=", "(", "0.9", ",", "0.98", ")", ",", "eps", "=", "1e-9", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__": [[6, 9], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "resnet", ")", ":", "\n", "        ", "super", "(", "myResnet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "resnet", "=", "resnet", "\n", "\n"]], "home.repos.pwc.inspect_result.husthuaan_AAT.misc.resnet_utils.myResnet.forward": [[10, 27], ["img.unsqueeze", "resnet_utils.myResnet.resnet.conv1", "resnet_utils.myResnet.resnet.bn1", "resnet_utils.myResnet.resnet.relu", "resnet_utils.myResnet.resnet.maxpool", "resnet_utils.myResnet.resnet.layer1", "resnet_utils.myResnet.resnet.layer2", "resnet_utils.myResnet.resnet.layer3", "resnet_utils.myResnet.resnet.layer4", "resnet_utils.myResnet.mean().mean().squeeze", "torch.adaptive_avg_pool2d().squeeze().permute", "torch.adaptive_avg_pool2d().squeeze().permute", "torch.adaptive_avg_pool2d().squeeze().permute", "resnet_utils.myResnet.mean().mean", "torch.adaptive_avg_pool2d().squeeze", "torch.adaptive_avg_pool2d().squeeze", "torch.adaptive_avg_pool2d().squeeze", "resnet_utils.myResnet.mean", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "img", ",", "att_size", "=", "14", ")", ":", "\n", "        ", "x", "=", "img", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "x", "=", "self", ".", "resnet", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "resnet", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "resnet", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "resnet", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "resnet", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "resnet", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "resnet", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "resnet", ".", "layer4", "(", "x", ")", "\n", "\n", "fc", "=", "x", ".", "mean", "(", "3", ")", ".", "mean", "(", "2", ")", ".", "squeeze", "(", ")", "\n", "att", "=", "F", ".", "adaptive_avg_pool2d", "(", "x", ",", "[", "att_size", ",", "att_size", "]", ")", ".", "squeeze", "(", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ")", "\n", "\n", "return", "fc", ",", "att", "\n", "\n"]]}