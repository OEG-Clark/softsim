{"home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict.__init__": [[43, 48], ["preprocess.WordDict._init_dicts"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict._init_dicts"], ["    ", "def", "__init__", "(", "self", ",", "dicts", "=", "None", ")", ":", "\n", "        ", "if", "dicts", "==", "None", ":", "\n", "            ", "self", ".", "_init_dicts", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "word2index", ",", "self", ".", "index2word", ",", "self", ".", "word2count", ",", "self", ".", "n_words", "=", "dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict._init_dicts": [[49, 57], ["preprocess.WordDict.index2word.update", "preprocess.WordDict.word2index.update", "len"], "methods", ["None"], ["", "", "def", "_init_dicts", "(", "self", ")", ":", "\n", "        ", "self", ".", "word2index", "=", "{", "}", "\n", "self", ".", "index2word", "=", "{", "}", "\n", "self", ".", "word2count", "=", "{", "}", "\n", "self", ".", "index2word", ".", "update", "(", "RESERVED_I2W", ")", "\n", "self", ".", "word2index", ".", "update", "(", "RESERVED_W2I", ")", "\n", "\n", "self", ".", "n_words", "=", "len", "(", "RESERVED_I2W", ")", "# number of words in the dictionary", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict.add_sentence": [[58, 61], ["preprocess.WordDict.add_word"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict.add_word"], ["", "def", "add_sentence", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "for", "word", "in", "sentence", ":", "\n", "            ", "self", ".", "add_word", "(", "word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict.add_word": [[62, 74], ["None"], "methods", ["None"], ["", "", "def", "add_word", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "not", "word", "in", "RESERVED_W2I", ":", "\n", "            ", "if", "not", "word", "in", "self", ".", "word2index", ":", "\n", "#print(word)", "\n", "                ", "self", ".", "word2index", "[", "word", "]", "=", "self", ".", "n_words", "\n", "#print(self.n_words)", "\n", "#input()", "\n", "self", ".", "word2count", "[", "word", "]", "=", "1", "\n", "self", ".", "index2word", "[", "self", ".", "n_words", "]", "=", "word", "\n", "self", ".", "n_words", "+=", "1", "\n", "", "else", ":", "\n", "                ", "self", ".", "word2count", "[", "word", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict.remove_unknowns": [[75, 102], ["preprocess.WordDict.word2count.items", "preprocess.WordDict._init_dicts", "old_w2i.items", "unks.append"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict._init_dicts"], ["", "", "", "def", "remove_unknowns", "(", "self", ",", "cutoff", ")", ":", "\n", "# find unknown words", "\n", "        ", "unks", "=", "[", "]", "\n", "for", "word", ",", "count", "in", "self", ".", "word2count", ".", "items", "(", ")", ":", "\n", "            ", "if", "word", "not", "in", "RESERVED_W2I", "and", "count", "<=", "cutoff", ":", "\n", "                ", "unks", ".", "append", "(", "word", ")", "\n", "\n", "# remove unknown words", "\n", "", "", "for", "word", "in", "unks", ":", "\n", "            ", "del", "self", ".", "index2word", "[", "self", ".", "word2index", "[", "word", "]", "]", "\n", "del", "self", ".", "word2index", "[", "word", "]", "\n", "del", "self", ".", "word2count", "[", "word", "]", "\n", "\n", "# reformat dictionaries so keys get shifted to correspond to removed words", "\n", "", "old_w2i", "=", "self", ".", "word2index", "\n", "old_w2c", "=", "self", ".", "word2count", "\n", "self", ".", "_init_dicts", "(", ")", "\n", "for", "word", ",", "index", "in", "old_w2i", ".", "items", "(", ")", ":", "\n", "            ", "if", "word", "not", "in", "RESERVED_W2I", ":", "\n", "                ", "self", ".", "word2index", "[", "word", "]", "=", "self", ".", "n_words", "\n", "self", ".", "index2word", "[", "self", ".", "n_words", "]", "=", "word", "\n", "if", "word", "in", "old_w2c", ":", "\n", "                    ", "self", ".", "word2count", "[", "word", "]", "=", "old_w2c", "[", "word", "]", "\n", "", "self", ".", "n_words", "+=", "1", "\n", "", "", "self", ".", "n_words", "=", "self", ".", "n_words", "\n", "\n", "return", "unks", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict.to_indices": [[103, 111], ["indices.append", "indices.append"], "methods", ["None"], ["", "def", "to_indices", "(", "self", ",", "words", ")", ":", "\n", "        ", "indices", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "if", "word", "in", "self", ".", "word2index", ":", "\n", "                ", "indices", ".", "append", "(", "self", ".", "word2index", "[", "word", "]", ")", "\n", "", "else", ":", "\n", "                ", "indices", ".", "append", "(", "self", ".", "word2index", "[", "UNK", "]", ")", "\n", "", "", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict.to_words": [[112, 120], ["words.append", "words.append"], "methods", ["None"], ["", "def", "to_words", "(", "self", ",", "indices", ")", ":", "\n", "        ", "words", "=", "[", "]", "\n", "for", "index", "in", "indices", ":", "\n", "            ", "if", "index", "in", "self", ".", "index2word", ":", "\n", "                ", "words", ".", "append", "(", "self", ".", "index2word", "[", "index", "]", ")", "\n", "", "else", ":", "\n", "                ", "words", ".", "append", "(", "UNK", ")", "\n", "", "", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.unicode_to_ascii": [[122, 126], ["unicodedata.normalize", "unicodedata.category"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.normalize"], ["", "", "def", "unicode_to_ascii", "(", "s", ")", ":", "\n", "    ", "return", "''", ".", "join", "(", "\n", "c", "for", "c", "in", "unicodedata", ".", "normalize", "(", "'NFD'", ",", "s", ")", "\n", "if", "unicodedata", ".", "category", "(", "c", ")", "!=", "'Mn'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.normalize": [[128, 137], ["preprocess.unicode_to_ascii", "TOKENS.items", "re.sub", "re.sub", "re.sub.lower().strip", "re.sub", "re.sub.lower"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.unicode_to_ascii"], ["", "def", "normalize", "(", "s", ")", ":", "\n", "    ", "s", "=", "unicode_to_ascii", "(", "s", ".", "lower", "(", ")", ".", "strip", "(", ")", ")", "\n", "for", "token", ",", "flag", "in", "TOKENS", ".", "items", "(", ")", ":", "\n", "        ", "s", "=", "re", ".", "sub", "(", "token", ",", "flag", ",", "s", ")", "\n", "", "s", "=", "re", ".", "sub", "(", "r\"([.!?])\"", ",", "r\" \\1\"", ",", "s", ")", "\n", "#s = re.sub(r\"([!?])\", r\" \\1\", s)", "\n", "s", "=", "re", ".", "sub", "(", "r\"[^a-zA-Z.!?<>']+\"", ",", "r\" \"", ",", "s", ")", "\n", "#s = re.sub(r\"[^a-zA-Z0123456789.!?<>:;$=/*%&@#|~\\[\\]'\\-\\+]+\", r\" \", s)", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.separate": [[138, 140], ["s.split"], "function", ["None"], ["", "def", "separate", "(", "s", ",", "max_len", "=", "MAX_SENTENCE_LENGTH", ",", "separator", "=", "\" \"", ")", ":", "\n", "    ", "return", "s", ".", "split", "(", "separator", ")", "[", ":", "max_len", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.get_pairs": [[141, 159], ["print", "range", "len", "print", "len", "str", "pairs.append"], "function", ["None"], ["", "def", "get_pairs", "(", "lines", ")", ":", "\n", "    ", "pairs", "=", "[", "]", "\n", "msg", "=", "None", "\n", "resp", "=", "None", "\n", "addpair", "=", "False", "\n", "print", "(", "\"Collecting pairs of index lists.\"", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "lines", ")", ")", ":", "\n", "        ", "if", "not", "BRK", "in", "lines", "[", "i", "]", ":", "\n", "            ", "resp", "=", "lines", "[", "i", "]", "\n", "if", "addpair", "==", "True", ":", "\n", "                ", "pairs", ".", "append", "(", "[", "msg", ",", "resp", "]", ")", "\n", "", "msg", "=", "resp", "\n", "addpair", "=", "True", "\n", "", "else", ":", "\n", "            ", "addpair", "=", "False", "\n", "", "", "n_pairs", "=", "len", "(", "pairs", ")", "\n", "print", "(", "str", "(", "n_pairs", ")", "+", "\" pairs of index lists collected.\"", ")", "\n", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.get_validation_set": [[160, 174], ["len", "random.sample", "range", "print", "range", "train_set.append", "val_set.append"], "function", ["None"], ["", "def", "get_validation_set", "(", "pairs", ",", "val_size", ")", ":", "\n", "    ", "if", "val_size", "<=", "0", ":", "\n", "        ", "return", "pairs", ",", "None", "\n", "", "n", "=", "len", "(", "pairs", ")", "\n", "indices", "=", "random", ".", "sample", "(", "range", "(", "n", ")", ",", "val_size", ")", "\n", "train_set", "=", "[", "]", "\n", "val_set", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "if", "not", "i", "in", "indices", ":", "\n", "            ", "train_set", ".", "append", "(", "pairs", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "            ", "val_set", ".", "append", "(", "pairs", "[", "i", "]", ")", "\n", "", "", "print", "(", "\"Training and validation sets generated.\"", ")", "\n", "return", "train_set", ",", "val_set", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.tokenize": [[179, 181], ["wd.to_indices"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict.to_indices"], ["", "def", "tokenize", "(", "s", ",", "wd", ")", ":", "\n", "    ", "return", "wd", ".", "to_indices", "(", "s", ")", "+", "[", "EOS_INDEX", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.tokenize_pairs": [[182, 187], ["tokenized_pairs.append", "preprocess.tokenize"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.tokenize"], ["", "def", "tokenize_pairs", "(", "pairs", ",", "wd", ")", ":", "\n", "    ", "tokenized_pairs", "=", "[", "]", "\n", "for", "pair", "in", "pairs", ":", "\n", "        ", "tokenized_pairs", ".", "append", "(", "[", "tokenize", "(", "s", ",", "wd", ")", "for", "s", "in", "pair", "]", ")", "\n", "", "return", "tokenized_pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.pad_seq": [[189, 192], ["range", "len"], "function", ["None"], ["", "def", "pad_seq", "(", "seq", ",", "max_length", ")", ":", "\n", "    ", "seq", "+=", "[", "PAD_INDEX", "for", "i", "in", "range", "(", "max_length", "-", "len", "(", "seq", ")", ")", "]", "\n", "return", "seq", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.nli_batch_to_variable": [[193, 212], ["numpy.array().transpose", "numpy.array().transpose", "numpy.array", "sorted", "zip", "len", "preprocess.pad_seq", "len", "preprocess.pad_seq", "zip", "max", "max", "numpy.array", "numpy.array", "len"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.pad_seq", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.pad_seq"], ["", "def", "nli_batch_to_variable", "(", "text", ",", "hyp", ",", "label", ",", "sort", "=", "True", ")", ":", "\n", "    ", "if", "sort", ":", "\n", "# Zip into pairs, sort by length (descending), unzip", "\n", "        ", "batch", "=", "sorted", "(", "zip", "(", "text", ",", "hyp", ",", "label", ")", ",", "key", "=", "lambda", "p", ":", "len", "(", "p", "[", "0", "]", ")", ",", "reverse", "=", "True", ")", "\n", "text", ",", "hyp", ",", "label", "=", "zip", "(", "*", "batch", ")", "\n", "\n", "# For input and target sequences, get array of lengths and pad with 0s to max length", "\n", "", "text_lengths", "=", "[", "len", "(", "s", ")", "for", "s", "in", "text", "]", "\n", "text_padded", "=", "[", "pad_seq", "(", "s", ",", "max", "(", "text_lengths", ")", ")", "for", "s", "in", "text", "]", "\n", "\n", "hyp_lengths", "=", "[", "len", "(", "s", ")", "for", "s", "in", "hyp", "]", "\n", "hyp_padded", "=", "[", "pad_seq", "(", "s", ",", "max", "(", "hyp_lengths", ")", ")", "for", "s", "in", "hyp", "]", "\n", "\n", "# Turn padded arrays into (batch_size x max_len) tensors, transpose into (max_len x batch_size)", "\n", "text", "=", "np", ".", "array", "(", "text_padded", ",", "dtype", "=", "'long'", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "hyp", "=", "np", ".", "array", "(", "hyp_padded", ",", "dtype", "=", "'long'", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "label", "=", "np", ".", "array", "(", "label", ",", "dtype", "=", "'long'", ")", "\n", "\n", "return", "(", "text", ",", "text_lengths", ",", "hyp", ",", "hyp_lengths", ",", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.get_nli_batch": [[213, 231], ["enumerate", "batches.append", "preprocess.nli_batch_to_variable", "min", "min", "min"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.nli_batch_to_variable"], ["", "def", "get_nli_batch", "(", "batch_size", ",", "data", ")", ":", "\n", "    ", "batches", "=", "[", "]", "\n", "\n", "offset", "=", "0", "\n", "total_data", "=", "data", "[", "\"length\"", "]", "\n", "while", "offset", "<", "total_data", ":", "\n", "        ", "batch", "=", "[", "\n", "data", "[", "\"text\"", "]", "[", "offset", ":", "min", "(", "offset", "+", "batch_size", ",", "total_data", ")", "]", ",", "\n", "data", "[", "\"hyp\"", "]", "[", "offset", ":", "min", "(", "offset", "+", "batch_size", ",", "total_data", ")", "]", ",", "\n", "data", "[", "\"label\"", "]", "[", "offset", ":", "min", "(", "offset", "+", "batch_size", ",", "total_data", ")", "]", "\n", "]", "\n", "batches", ".", "append", "(", "batch", ")", "\n", "offset", "+=", "batch_size", "\n", "\n", "", "for", "i", ",", "batch", "in", "enumerate", "(", "batches", ")", ":", "\n", "        ", "batches", "[", "i", "]", "=", "nli_batch_to_variable", "(", "batch", "[", "0", "]", ",", "batch", "[", "1", "]", ",", "batch", "[", "2", "]", ")", "\n", "\n", "", "return", "batches", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.batch_pairs": [[232, 255], ["torch.autograd.Variable().transpose", "torch.autograd.Variable().transpose", "sorted", "zip", "len", "preprocess.pad_seq", "len", "preprocess.pad_seq", "input_var.cuda.cuda", "target_var.cuda.cuda", "zip", "max", "max", "torch.autograd.Variable", "torch.autograd.Variable", "torch.LongTensor", "torch.LongTensor", "len"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.pad_seq", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.pad_seq"], ["", "def", "batch_pairs", "(", "inputs", ",", "targets", ",", "sort", "=", "True", ")", ":", "\n", "    ", "if", "sort", ":", "\n", "# Zip into pairs, sort by length (descending), unzip", "\n", "        ", "seq_pairs", "=", "sorted", "(", "zip", "(", "inputs", ",", "targets", ")", ",", "key", "=", "lambda", "p", ":", "len", "(", "p", "[", "0", "]", ")", ",", "reverse", "=", "True", ")", "\n", "input_seqs", ",", "target_seqs", "=", "zip", "(", "*", "seq_pairs", ")", "\n", "", "else", ":", "\n", "        ", "input_seqs", ",", "target_seqs", "=", "inputs", ",", "targets", "\n", "\n", "# For input and target sequences, get array of lengths and pad with 0s to max length", "\n", "", "input_lengths", "=", "[", "len", "(", "s", ")", "for", "s", "in", "input_seqs", "]", "\n", "input_padded", "=", "[", "pad_seq", "(", "s", ",", "max", "(", "input_lengths", ")", ")", "for", "s", "in", "input_seqs", "]", "\n", "target_lengths", "=", "[", "len", "(", "s", ")", "for", "s", "in", "target_seqs", "]", "\n", "target_padded", "=", "[", "pad_seq", "(", "s", ",", "max", "(", "target_lengths", ")", ")", "for", "s", "in", "target_seqs", "]", "\n", "\n", "# Turn padded arrays into (batch_size x max_len) tensors, transpose into (max_len x batch_size)", "\n", "input_var", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "input_padded", ")", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "target_var", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "target_padded", ")", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "if", "USE_CUDA", ":", "\n", "        ", "input_var", "=", "input_var", ".", "cuda", "(", ")", "\n", "target_var", "=", "target_var", ".", "cuda", "(", ")", "\n", "\n", "", "return", "(", "input_var", ",", "input_lengths", ",", "target_var", ",", "target_lengths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.batches_by_length": [[256, 300], ["len", "int", "preprocess.bucketize", "len", "min", "range", "len", "input_seqs.append", "target_seqs.append", "preprocess.batch_pairs", "batches.append"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.bucketize", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.batch_pairs"], ["", "def", "batches_by_length", "(", "batch_size", ",", "pairs", ",", "max_sequence_length", ")", ":", "\n", "    ", "n_pairs", "=", "len", "(", "pairs", ")", "\n", "n_batches", "=", "int", "(", "n_pairs", "/", "batch_size", ")", "\n", "\n", "buckets", "=", "bucketize", "(", "pairs", ",", "max_sequence_length", "+", "1", ",", "key", "=", "lambda", "p", ":", "len", "(", "p", "[", "0", "]", ")", ")", "\n", "\n", "batches", "=", "[", "]", "\n", "done_all", "=", "False", "\n", "current_bucket", "=", "max_sequence_length", "\n", "current_index", "=", "0", "\n", "while", "not", "done_all", ":", "\n", "        ", "input_seqs", "=", "[", "]", "\n", "target_seqs", "=", "[", "]", "\n", "\n", "n_batch", "=", "batch_size", "\n", "\n", "done_batch", "=", "False", "\n", "while", "not", "done_batch", ":", "\n", "            ", "bucket", "=", "buckets", "[", "current_bucket", "]", "\n", "n_bucket", "=", "len", "(", "bucket", ")", "\n", "n_left", "=", "n_bucket", "-", "current_index", "\n", "n_current", "=", "min", "(", "n_batch", ",", "n_left", ")", "\n", "\n", "for", "i", "in", "range", "(", "current_index", ",", "current_index", "+", "n_current", ")", ":", "\n", "                ", "input_seq", ",", "target_seq", "=", "bucket", "[", "i", "]", "\n", "input_seqs", ".", "append", "(", "input_seq", ")", "\n", "target_seqs", ".", "append", "(", "target_seq", ")", "\n", "\n", "", "current_index", "+=", "n_current", "\n", "n_batch", "-=", "n_current", "\n", "\n", "if", "n_batch", ">", "0", ":", "\n", "                ", "if", "current_bucket", ">", "0", ":", "\n", "                    ", "current_bucket", "-=", "1", "\n", "current_index", "=", "0", "\n", "", "else", ":", "\n", "                    ", "done_all", "=", "True", "\n", "done_batch", "=", "True", "\n", "", "", "else", ":", "\n", "                ", "batch", "=", "batch_pairs", "(", "input_seqs", ",", "target_seqs", ")", "\n", "batches", ".", "append", "(", "batch", ")", "\n", "done_batch", "=", "True", "\n", "\n", "", "", "", "return", "batches", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.bucketize": [[303, 322], ["range", "len", "key", "sorted_list[].append", "range", "range", "len", "numpy.random.permutation", "range", "new_pairs.append"], "function", ["None"], ["", "def", "bucketize", "(", "raw_list", ",", "max_len", ",", "key", "=", "len", ",", "shuffled", "=", "True", ")", ":", "\n", "    ", "sorted_list", "=", "[", "[", "]", "for", "i", "in", "range", "(", "max_len", ")", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "raw_list", ")", ")", ":", "\n", "        ", "element", "=", "raw_list", "[", "i", "]", "\n", "val", "=", "key", "(", "element", ")", "\n", "sorted_list", "[", "val", "]", ".", "append", "(", "element", ")", "\n", "\n", "", "if", "shuffled", ":", "\n", "        ", "for", "i", "in", "range", "(", "max_len", ")", ":", "\n", "            ", "pairs_i", "=", "sorted_list", "[", "i", "]", "\n", "new_pairs", "=", "[", "]", "\n", "n", "=", "len", "(", "pairs_i", ")", "\n", "p", "=", "np", ".", "random", ".", "permutation", "(", "n", ")", "\n", "for", "j", "in", "range", "(", "n", ")", ":", "\n", "                ", "k", "=", "p", "[", "j", "]", "\n", "new_pairs", ".", "append", "(", "pairs_i", "[", "k", "]", ")", "\n", "", "sorted_list", "[", "i", "]", "=", "new_pairs", "\n", "\n", "", "", "return", "sorted_list", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.nli_random_batches": [[323, 342], ["int", "numpy.random.permutation", "range", "range", "batches.append", "text.append", "hyp.append", "label.append", "preprocess.nli_batch_to_variable"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.nli_batch_to_variable"], ["", "def", "nli_random_batches", "(", "batch_size", ",", "data", ")", ":", "\n", "    ", "n_batches", "=", "int", "(", "data", "[", "\"length\"", "]", "/", "batch_size", ")", "\n", "p", "=", "np", ".", "random", ".", "permutation", "(", "data", "[", "\"length\"", "]", ")", "\n", "\n", "batches", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_batches", ")", ":", "\n", "# Choose random pairs", "\n", "        ", "text", "=", "[", "]", "\n", "hyp", "=", "[", "]", "\n", "label", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "idx", "=", "p", "[", "i", "*", "batch_size", "+", "j", "]", "\n", "text", ".", "append", "(", "data", "[", "\"text\"", "]", "[", "idx", "]", ")", "\n", "hyp", ".", "append", "(", "data", "[", "\"hyp\"", "]", "[", "idx", "]", ")", "\n", "label", ".", "append", "(", "data", "[", "\"label\"", "]", "[", "idx", "]", ")", "\n", "\n", "", "batches", ".", "append", "(", "nli_batch_to_variable", "(", "text", ",", "hyp", ",", "label", ")", ")", "\n", "\n", "", "return", "batches", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.nli_batches": [[343, 364], ["range", "range", "batches.append", "text.append", "hyp.append", "label.append", "preprocess.nli_batch_to_variable"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.nli_batch_to_variable"], ["", "def", "nli_batches", "(", "batch_size", ",", "data", ")", ":", "\n", "    ", "n_batches", "=", "data", "[", "\"length\"", "]", "#assumes batch_size = 1", "\n", "\n", "batches", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_batches", ")", ":", "\n", "# Choose random pairs", "\n", "        ", "text", "=", "[", "]", "\n", "hyp", "=", "[", "]", "\n", "label", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "idx", "=", "i", "+", "j", "\n", "data", "[", "\"text\"", "]", "[", "idx", "]", "=", "[", "x", "for", "x", "in", "data", "[", "\"text\"", "]", "[", "idx", "]", "if", "x", "!=", "PAD_INDEX", "]", "\n", "data", "[", "\"hyp\"", "]", "[", "idx", "]", "=", "[", "x", "for", "x", "in", "data", "[", "\"hyp\"", "]", "[", "idx", "]", "if", "x", "!=", "PAD_INDEX", "]", "\n", "\n", "text", ".", "append", "(", "data", "[", "\"text\"", "]", "[", "idx", "]", ")", "\n", "hyp", ".", "append", "(", "data", "[", "\"hyp\"", "]", "[", "idx", "]", ")", "\n", "label", ".", "append", "(", "data", "[", "\"label\"", "]", "[", "idx", "]", ")", "\n", "\n", "", "batches", ".", "append", "(", "nli_batch_to_variable", "(", "text", ",", "hyp", ",", "label", ")", ")", "\n", "\n", "", "return", "batches", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.random_batches": [[365, 382], ["int", "numpy.random.permutation", "range", "len", "range", "batches.append", "len", "input_seqs.append", "target_seqs.append", "preprocess.batch_pairs"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.batch_pairs"], ["", "def", "random_batches", "(", "batch_size", ",", "pairs", ")", ":", "\n", "    ", "n_batches", "=", "int", "(", "len", "(", "pairs", ")", "/", "batch_size", ")", "\n", "p", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "pairs", ")", ")", "\n", "\n", "batches", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_batches", ")", ":", "\n", "        ", "input_seqs", "=", "[", "]", "\n", "target_seqs", "=", "[", "]", "\n", "# Choose random pairs", "\n", "for", "j", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "pair", "=", "pairs", "[", "p", "[", "i", "*", "batch_size", "+", "j", "]", "]", "\n", "input_seqs", ".", "append", "(", "pair", "[", "0", "]", ")", "\n", "target_seqs", ".", "append", "(", "pair", "[", "1", "]", ")", "\n", "\n", "", "batches", ".", "append", "(", "batch_pairs", "(", "input_seqs", ",", "target_seqs", ")", ")", "\n", "\n", "", "return", "batches", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.parse_query": [[384, 386], ["preprocess.tokenize", "preprocess.separate", "preprocess.normalize"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.tokenize", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.separate", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.normalize"], ["", "def", "parse_query", "(", "msg", ",", "wd", ")", ":", "\n", "    ", "return", "tokenize", "(", "separate", "(", "normalize", "(", "msg", ")", ")", ",", "wd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.clean_resp": [[388, 393], ["list", "RESERVED_W2I.keys", "rmv_tokens.keys"], "function", ["None"], ["", "def", "clean_resp", "(", "raw_resp", ",", "rmv_tokens", "=", "list", "(", "RESERVED_W2I", ".", "keys", "(", ")", ")", ")", ":", "\n", "    ", "if", "'<unk>'", "in", "rmv_tokens", ".", "keys", "(", ")", ":", "\n", "        ", "del", "rmv_tokens", "[", "'<unk>'", "]", "\n", "", "resp", "=", "[", "w", "for", "w", "in", "raw_resp", "if", "not", "w", "in", "rmv_tokens", "]", "\n", "return", "\" \"", ".", "join", "(", "resp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.remove_punctuation": [[395, 401], ["seq_out.append"], "function", ["None"], ["", "def", "remove_punctuation", "(", "sequence", ")", ":", "\n", "    ", "seq_out", "=", "[", "]", "\n", "for", "s", "in", "sequence", ":", "\n", "        ", "if", "not", "s", "in", "PUNCTUATION", ":", "\n", "            ", "seq_out", ".", "append", "(", "s", ")", "\n", "", "", "return", "seq_out", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.clean_seq": [[402, 408], ["seq_out.append"], "function", ["None"], ["", "def", "clean_seq", "(", "seq", ",", "remove_punctuation", "=", "False", ")", ":", "\n", "    ", "seq_out", "=", "[", "]", "\n", "for", "s", "in", "seq", ":", "\n", "        ", "if", "s", "not", "in", "RMV_TOKENS", "and", "(", "not", "remove_punctuation", "or", "s", "not", "in", "PUNCTUATION", ")", ":", "\n", "            ", "seq_out", ".", "append", "(", "s", ")", "\n", "", "", "return", "seq_out", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.import_csv": [[411, 433], ["preprocess.WordDict", "print", "print", "print", "print", "preprocess.WordDict.remove_unknowns", "print", "open", "str", "str", "str", "str", "preprocess.separate", "preprocess.WordDict.add_sentence", "lines.append", "len", "len", "preprocess.normalize"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict.remove_unknowns", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.separate", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict.add_sentence", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.normalize"], ["", "def", "import_csv", "(", "datafile", ",", "max_lines", "=", "-", "1", ",", "unk_thresh", "=", "5", ")", ":", "\n", "    ", "lines", "=", "[", "]", "\n", "wd", "=", "WordDict", "(", ")", "\n", "print", "(", "\"Reading input...\"", ")", "\n", "with", "open", "(", "datafile", ",", "'r'", ")", "as", "infile", ":", "\n", "        ", "count", "=", "0", "\n", "for", "line", "in", "infile", ":", "\n", "            ", "if", "max_lines", ">", "0", "and", "count", ">=", "max_lines", ":", "\n", "                ", "break", "\n", "", "split_line", "=", "separate", "(", "normalize", "(", "line", ")", ")", "\n", "wd", ".", "add_sentence", "(", "split_line", ")", "\n", "lines", ".", "append", "(", "split_line", ")", "\n", "count", "+=", "1", "\n", "", "", "print", "(", "\"Input read.\"", ")", "\n", "print", "(", "str", "(", "len", "(", "lines", ")", ")", ",", "\"total lines.\"", ")", "\n", "print", "(", "str", "(", "wd", ".", "n_words", ")", ",", "\"total unique words.\"", ")", "\n", "\n", "unks", "=", "wd", ".", "remove_unknowns", "(", "unk_thresh", ")", "\n", "\n", "print", "(", "str", "(", "len", "(", "unks", ")", ")", ",", "\"words removed.\"", ",", "str", "(", "wd", ".", "n_words", ")", ",", "\"words remaining in vocabulary.\"", ")", "\n", "\n", "return", "lines", ",", "wd", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.list_to_string": [[434, 436], ["None"], "function", ["None"], ["", "def", "list_to_string", "(", "msg", ")", ":", "\n", "    ", "return", "\",\"", ".", "join", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.export_pairs": [[437, 442], ["open", "open.close", "open.write", "preprocess.list_to_string", "preprocess.list_to_string"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.list_to_string", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.list_to_string"], ["", "def", "export_pairs", "(", "pairs", ",", "path", ")", ":", "\n", "    ", "outfile", "=", "open", "(", "path", ",", "'w'", ")", "\n", "for", "pair", "in", "pairs", ":", "\n", "        ", "outfile", ".", "write", "(", "\"--\\n\"", "+", "list_to_string", "(", "pair", "[", "0", "]", ")", "+", "\"\\n\"", "+", "list_to_string", "(", "pair", "[", "1", "]", ")", "+", "\"\\n\"", ")", "\n", "", "outfile", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.import_pairs": [[443, 456], ["open", "open.readline", "preprocess.separate", "preprocess.separate", "pairs.append", "preprocess.normalize", "preprocess.normalize", "open.readline", "open.readline"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.separate", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.separate", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.normalize", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.normalize"], ["", "def", "import_pairs", "(", "path", ")", ":", "\n", "    ", "infile", "=", "open", "(", "path", ",", "'r'", ")", "\n", "pairs", "=", "[", "]", "\n", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "        ", "delim", "=", "infile", ".", "readline", "(", ")", "\n", "if", "delim", "!=", "\"\"", ":", "\n", "            ", "msg", "=", "separate", "(", "normalize", "(", "infile", ".", "readline", "(", ")", ")", ")", "\n", "resp", "=", "separate", "(", "normalize", "(", "infile", ".", "readline", "(", ")", ")", ")", "\n", "pairs", ".", "append", "(", "(", "msg", ",", "resp", ")", ")", "\n", "", "else", ":", "\n", "            ", "done", "=", "True", "\n", "", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.get_lines": [[457, 472], ["print", "print", "print", "open", "str", "preprocess.separate", "lines.append", "len", "preprocess.normalize"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.separate", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.normalize"], ["", "def", "get_lines", "(", "datafile", ",", "max_lines", "=", "-", "1", ")", ":", "\n", "    ", "lines", "=", "[", "]", "\n", "print", "(", "\"Reading input...\"", ")", "\n", "with", "open", "(", "datafile", ",", "'r'", ")", "as", "infile", ":", "\n", "        ", "count", "=", "0", "\n", "for", "line", "in", "infile", ":", "\n", "            ", "if", "max_lines", ">", "0", "and", "count", ">=", "max_lines", ":", "\n", "                ", "break", "\n", "", "split_line", "=", "separate", "(", "normalize", "(", "line", ")", ")", "\n", "lines", ".", "append", "(", "split_line", ")", "\n", "count", "+=", "1", "\n", "", "", "print", "(", "\"Input read.\"", ")", "\n", "print", "(", "str", "(", "len", "(", "lines", ")", ")", ",", "\"total lines.\"", ")", "\n", "\n", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.nli_batches_without_label": [[474, 499], ["int", "range", "range", "range", "batches.append", "text.append", "hyp.append", "batches.append", "text.append", "hyp.append", "preprocess.nli_batch_to_variable_without_label", "preprocess.nli_batch_to_variable_without_label"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.nli_batch_to_variable_without_label", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.nli_batch_to_variable_without_label"], ["", "def", "nli_batches_without_label", "(", "batch_size", ",", "data", ")", ":", "\n", "    ", "n_batches", "=", "int", "(", "data", "[", "\"length\"", "]", "/", "batch_size", ")", "\n", "remaining", "=", "data", "[", "\"length\"", "]", "%", "batch_size", "\n", "\n", "batches", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_batches", ")", ":", "\n", "# Choose random pairs", "\n", "        ", "text", "=", "[", "]", "\n", "hyp", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "idx", "=", "i", "*", "batch_size", "+", "j", "\n", "text", ".", "append", "(", "data", "[", "\"text\"", "]", "[", "idx", "]", ")", "\n", "hyp", ".", "append", "(", "data", "[", "\"hyp\"", "]", "[", "idx", "]", ")", "\n", "\n", "", "batches", ".", "append", "(", "nli_batch_to_variable_without_label", "(", "text", ",", "hyp", ")", ")", "\n", "\n", "", "text", "=", "[", "]", "\n", "hyp", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "remaining", ")", ":", "\n", "        ", "idx", "=", "n_batches", "*", "batch_size", "+", "k", "\n", "text", ".", "append", "(", "data", "[", "\"text\"", "]", "[", "idx", "]", ")", "\n", "hyp", ".", "append", "(", "data", "[", "\"hyp\"", "]", "[", "idx", "]", ")", "\n", "", "if", "remaining", ">", "0", ":", "\n", "        ", "batches", ".", "append", "(", "nli_batch_to_variable_without_label", "(", "text", ",", "hyp", ")", ")", "\n", "", "return", "batches", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.nli_batch_to_variable_without_label": [[500, 518], ["numpy.array().transpose", "numpy.array().transpose", "sorted", "zip", "len", "preprocess.pad_seq", "len", "preprocess.pad_seq", "zip", "max", "max", "numpy.array", "numpy.array", "len"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.pad_seq", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.pad_seq"], ["", "def", "nli_batch_to_variable_without_label", "(", "text", ",", "hyp", ",", "sort", "=", "True", ")", ":", "\n", "    ", "if", "sort", ":", "\n", "# Zip into pairs, sort by length (descending), unzip", "\n", "        ", "batch", "=", "sorted", "(", "zip", "(", "text", ",", "hyp", ")", ",", "key", "=", "lambda", "p", ":", "len", "(", "p", "[", "0", "]", ")", ",", "reverse", "=", "True", ")", "\n", "text", ",", "hyp", "=", "zip", "(", "*", "batch", ")", "\n", "\n", "# For input and target sequences, get array of lengths and pad with 0s to max length", "\n", "", "text_lengths", "=", "[", "len", "(", "s", ")", "for", "s", "in", "text", "]", "\n", "text_padded", "=", "[", "pad_seq", "(", "s", ",", "max", "(", "text_lengths", ")", ")", "for", "s", "in", "text", "]", "\n", "\n", "hyp_lengths", "=", "[", "len", "(", "s", ")", "for", "s", "in", "hyp", "]", "\n", "hyp_padded", "=", "[", "pad_seq", "(", "s", ",", "max", "(", "hyp_lengths", ")", ")", "for", "s", "in", "hyp", "]", "\n", "\n", "# Turn padded arrays into (batch_size x max_len) tensors, transpose into (max_len x batch_size)", "\n", "text", "=", "np", ".", "array", "(", "text_padded", ",", "dtype", "=", "'long'", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "hyp", "=", "np", ".", "array", "(", "hyp_padded", ",", "dtype", "=", "'long'", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "\n", "return", "(", "text", ",", "text_lengths", ",", "hyp", ",", "hyp_lengths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.utils.load_glove_embeddings": [[35, 46], ["open", "np.zeros", "f.readlines", "torch.from_numpy().float", "torch.from_numpy().float", "line.split", "word2idx.get", "len", "np.array", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["def", "load_glove_embeddings", "(", "word2idx", ",", "embedding_dim", "=", "50", ")", ":", "\n", "    ", "with", "open", "(", "glove_path", ")", "as", "f", ":", "\n", "        ", "embeddings", "=", "np", ".", "zeros", "(", "(", "len", "(", "word2idx", ")", ",", "embedding_dim", ")", ")", "\n", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "values", "=", "line", ".", "split", "(", "\" \"", ")", "\n", "word", "=", "values", "[", "0", "]", "\n", "index", "=", "word2idx", ".", "get", "(", "word", ")", "\n", "if", "index", ":", "\n", "                ", "vector", "=", "np", ".", "array", "(", "values", "[", "1", ":", "]", ",", "dtype", "=", "'float32'", ")", "\n", "embeddings", "[", "index", "]", "=", "vector", "\n", "", "", "return", "torch", ".", "from_numpy", "(", "embeddings", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.utils.sequence_mask": [[48, 60], ["sequence_length.size", "torch.arange().long", "torch.arange().long", "torch.arange().long.unsqueeze().expand", "Variable", "sequence_length.unsqueeze().expand_as", "sequence_length.data.max", "seq_range_expand.cuda.cuda", "torch.arange", "torch.arange", "torch.arange().long.unsqueeze", "sequence_length.unsqueeze"], "function", ["None"], ["", "", "def", "sequence_mask", "(", "sequence_length", ",", "max_len", "=", "None", ")", ":", "\n", "    ", "if", "max_len", "is", "None", ":", "\n", "        ", "max_len", "=", "sequence_length", ".", "data", ".", "max", "(", ")", "\n", "", "batch_size", "=", "sequence_length", ".", "size", "(", "0", ")", "\n", "seq_range", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "long", "(", ")", "\n", "seq_range_expand", "=", "seq_range", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "max_len", ")", "\n", "seq_range_expand", "=", "Variable", "(", "seq_range_expand", ")", "\n", "if", "sequence_length", ".", "is_cuda", ":", "\n", "        ", "seq_range_expand", "=", "seq_range_expand", ".", "cuda", "(", ")", "\n", "", "seq_length_expand", "=", "(", "sequence_length", ".", "unsqueeze", "(", "1", ")", "\n", ".", "expand_as", "(", "seq_range_expand", ")", ")", "\n", "return", "seq_range_expand", "<", "seq_length_expand", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.utils.masked_cross_entropy": [[62, 95], ["logits.view", "torch.softmax", "torch.log_softmax", "target.view", "losses_flat.view", "utils.sequence_mask", "Variable().cuda", "Variable", "logits.size", "torch.gather", "torch.gather", "sequence_mask.float", "losses_flat.view.sum", "Variable.float().sum", "torch.LongTensor", "torch.LongTensor", "target.size", "target.size", "Variable", "Variable.float", "torch.LongTensor", "torch.LongTensor"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.utils.sequence_mask"], ["", "def", "masked_cross_entropy", "(", "logits", ",", "target", ",", "length", ")", ":", "\n", "    ", "if", "USE_CUDA", ":", "\n", "        ", "length", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "length", ")", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "length", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "length", ")", ")", "\n", "", "\"\"\"\n    Args:\n        logits: A Variable containing a FloatTensor of size\n            (batch, max_len, num_classes) which contains the\n            unnormalized probability for each class.\n        target: A Variable containing a LongTensor of size\n            (batch, max_len) which contains the index of the true\n            class for each corresponding step.\n        length: A Variable containing a LongTensor of size (batch,)\n            which contains the length of each data in a batch.\n\n    Returns:\n        loss: An average loss value masked by the length.\n    \"\"\"", "\n", "logits_flat", "=", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "testing_output_probs", "=", "F", ".", "softmax", "(", "logits_flat", ",", "dim", "=", "1", ")", "\n", "\n", "\n", "log_probs_flat", "=", "F", ".", "log_softmax", "(", "logits_flat", ",", "dim", "=", "1", ")", "\n", "target_flat", "=", "target", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "losses_flat", "=", "-", "torch", ".", "gather", "(", "log_probs_flat", ",", "dim", "=", "1", ",", "index", "=", "target_flat", ")", "\n", "losses", "=", "losses_flat", ".", "view", "(", "*", "target", ".", "size", "(", ")", ")", "\n", "mask", "=", "sequence_mask", "(", "sequence_length", "=", "length", ",", "max_len", "=", "target", ".", "size", "(", "1", ")", ")", "\n", "losses", "=", "losses", "*", "mask", ".", "float", "(", ")", "\n", "\n", "loss", "=", "losses", ".", "sum", "(", ")", "/", "length", ".", "float", "(", ")", ".", "sum", "(", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.utils.as_minutes": [[99, 103], ["math.floor"], "function", ["None"], ["", "def", "as_minutes", "(", "s", ")", ":", "\n", "    ", "m", "=", "math", ".", "floor", "(", "s", "/", "60", ")", "\n", "s", "-=", "m", "*", "60", "\n", "return", "'%dm %ds'", "%", "(", "m", ",", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.utils.time_since": [[105, 111], ["time.time", "utils.as_minutes", "utils.as_minutes"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.utils.as_minutes", "home.repos.pwc.inspect_result.nabihach_IDA.None.utils.as_minutes"], ["", "def", "time_since", "(", "since", ",", "percent", ")", ":", "\n", "    ", "now", "=", "time", ".", "time", "(", ")", "\n", "s", "=", "now", "-", "since", "\n", "es", "=", "s", "/", "(", "percent", ")", "\n", "rs", "=", "es", "-", "s", "\n", "return", "'%s (- %s)'", "%", "(", "as_minutes", "(", "s", ")", ",", "as_minutes", "(", "rs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.utils.init_save_pretrained_model": [[114, 126], ["datetime.datetime.now", "open", "vars", "open.write", "vars.items", "open.write", "open.close", "open.write", "str", "str"], "function", ["None"], ["", "def", "init_save_pretrained_model", "(", "args", ",", "model_dir", ")", ":", "\n", "    ", "t", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "\n", "log_file", "=", "open", "(", "model_dir", "+", "LOG_FILE", ",", "'a'", ")", "\n", "arg_dict", "=", "vars", "(", "args", ")", "\n", "log_file", ".", "write", "(", "\"=\"", "*", "20", "+", "\"\\nResuming Training with Parameters:\\n\"", ")", "\n", "for", "(", "arg", ",", "val", ")", "in", "arg_dict", ".", "items", "(", ")", ":", "\n", "        ", "log_file", ".", "write", "(", "str", "(", "arg", ")", "+", "\": \"", "+", "str", "(", "val", ")", "+", "'\\n'", ")", "\n", "", "log_file", ".", "write", "(", "\"\\n\"", ")", "\n", "log_file", ".", "close", "(", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.utils.save_logs": [[128, 137], ["open", "open.write", "open.close", "open.write", "open.write", "str", "str"], "function", ["None"], ["", "def", "save_logs", "(", "logs", ",", "path", ")", ":", "\n", "    ", "log_file", "=", "open", "(", "path", "+", "LOG_FILE", ",", "'a'", ")", "\n", "try", ":", "\n", "        ", "for", "log", "in", "logs", ":", "\n", "            ", "log_file", ".", "write", "(", "str", "(", "log", ")", ")", "\n", "", "", "except", "TypeError", ":", "\n", "        ", "log_file", ".", "write", "(", "str", "(", "logs", ")", ")", "\n", "", "log_file", ".", "write", "(", "\"\\n\"", ")", "\n", "log_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.utils.save_scores": [[138, 143], ["open", "open.write", "open.write", "open.close", "str"], "function", ["None"], ["", "def", "save_scores", "(", "scores", ",", "path", ")", ":", "\n", "    ", "score_file", "=", "open", "(", "path", "+", "SCORE_FILE", ",", "'a'", ")", "\n", "score_file", ".", "write", "(", "str", "(", "scores", ")", ")", "\n", "score_file", ".", "write", "(", "\"\\n\"", ")", "\n", "score_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.None.utils.masked_softmax2": [[144, 147], ["torch.softmax", "mask.float"], "function", ["None"], ["", "def", "masked_softmax2", "(", "vec", ",", "mask", ",", "dim", "=", "1", ")", ":", "\n", "    ", "fmin", "=", "FLOAT_MIN", "*", "(", "1", "-", "mask", ".", "float", "(", ")", ")", "#.float()", "\n", "return", "F", ".", "softmax", "(", "vec", "+", "fmin", ",", "dim", "=", "dim", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_train.init_parser": [[14, 36], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "init_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'NLI biLSTM model with progressive memory.'", ")", "\n", "parser", ".", "add_argument", "(", "'-max'", ",", "dest", "=", "'max_lines'", ",", "action", "=", "'store'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "'-e'", ",", "dest", "=", "'epochs'", ",", "action", "=", "'store'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "'-hs'", ",", "dest", "=", "'hidden_size'", ",", "action", "=", "'store'", ",", "type", "=", "int", ",", "default", "=", "300", ")", "\n", "parser", ".", "add_argument", "(", "'-bs'", ",", "dest", "=", "'batch_size'", ",", "action", "=", "'store'", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "'-lr'", ",", "dest", "=", "'learning_rate'", ",", "action", "=", "'store'", ",", "type", "=", "float", ",", "default", "=", "0.0003", ")", "\n", "parser", ".", "add_argument", "(", "'-l'", ",", "dest", "=", "'layers'", ",", "action", "=", "'store'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'-u'", ",", "dest", "=", "'unk_thresh'", ",", "action", "=", "'store'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'-s'", ",", "dest", "=", "'save_interval'", ",", "action", "=", "'store'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'-p'", ",", "dest", "=", "'patience'", ",", "action", "=", "'store'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "'-f'", ",", "dest", "=", "'annealing_factor'", ",", "action", "=", "'store'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "parser", ".", "add_argument", "(", "'-wd'", ",", "dest", "=", "'weight_decay'", ",", "action", "=", "'store'", ",", "type", "=", "float", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'-m'", ",", "dest", "=", "'model_type'", ",", "action", "=", "'store'", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'-t'", ",", "dest", "=", "'load_pretrained_model'", ",", "action", "=", "'store'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'-emb'", ",", "dest", "=", "'pretrained_embeddings'", ",", "action", "=", "'store'", ",", "type", "=", "bool", ",", "default", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'-g'", ",", "dest", "=", "'genre'", ",", "action", "=", "'store'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'-tl'", ",", "dest", "=", "'transfer_learning_mode'", ",", "action", "=", "'store'", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'-tg'", ",", "dest", "=", "'target_genre'", ",", "action", "=", "'store'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_train.is_valid_pretrained_model": [[37, 41], ["os.path.exists", "os.path.exists"], "function", ["None"], ["", "def", "is_valid_pretrained_model", "(", "model_name", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "MODEL_DIR", "+", "model_name", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_train.create_model": [[42, 84], ["nli_preprocessor.get_multinli_text_hyp_labels", "nli_preprocessor.genre_val_set", "nli_preprocessor.genre_val_set", "nli_model.init_save", "list", "nli_preprocessor.get_word_dict", "print", "nli_model.BiLSTMModel().init_model", "unmerged_sentences.extend", "itertools.chain.from_iterable", "nli_preprocessor.tokenize_sentences", "nli_preprocessor.tokenize_sentences", "NotImplementedError", "nli_model.BiLSTMModel"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_multinli_text_hyp_labels", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.genre_val_set", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.genre_val_set", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.init_save", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_word_dict", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.init_model", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.tokenize_sentences", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.tokenize_sentences"], ["", "def", "create_model", "(", "args", ")", ":", "\n", "# Fetch data", "\n", "    ", "train_set", "=", "nli_preprocessor", ".", "get_multinli_text_hyp_labels", "(", "max_lines", "=", "args", ".", "max_lines", ",", "genre", "=", "args", ".", "genre", ")", "\n", "# To get full training set of 392702 lines, use: train_set = nli_preprocessor.get_multinli_training_set(max_lines=args.max_lines)", "\n", "matched_val_set", "=", "nli_preprocessor", ".", "genre_val_set", "(", "'fiction'", ")", "\n", "\n", "#To get full matched validation set use: ", "\n", "#matched_val_set = nli_preprocessor.get_multinli_matched_val_set()", "\n", "\n", "mismatched_val_set", "=", "nli_preprocessor", ".", "genre_val_set", "(", "'government'", ")", "\n", "#To get full mismatched validation set use: ", "\n", "#mismatched_val_set = nli_preprocessor.get_multinli_mismatched_val_set()", "\n", "\n", "model_path", "=", "init_save", "(", "args", ",", "(", "train_set", ",", "matched_val_set", ",", "mismatched_val_set", ")", ")", "\n", "\n", "# Create WordDict from all data", "\n", "unmerged_sentences", "=", "[", "]", "\n", "for", "data", "in", "[", "train_set", ",", "matched_val_set", ",", "mismatched_val_set", "]", ":", "\n", "        ", "unmerged_sentences", ".", "extend", "(", "[", "data", "[", "\"text\"", "]", ",", "data", "[", "\"hyp\"", "]", "]", ")", "\n", "", "all_sentences", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "unmerged_sentences", ")", ")", "\n", "wd", "=", "nli_preprocessor", ".", "get_word_dict", "(", "all_sentences", ",", "args", ".", "max_lines", ",", "args", ".", "unk_thresh", ")", "\n", "\n", "# Tokenize sentences", "\n", "for", "data", "in", "[", "train_set", ",", "matched_val_set", ",", "mismatched_val_set", "]", ":", "\n", "        ", "data", "[", "\"text\"", "]", "=", "nli_preprocessor", ".", "tokenize_sentences", "(", "data", "[", "\"text\"", "]", ",", "wd", ")", "\n", "data", "[", "\"hyp\"", "]", "=", "nli_preprocessor", ".", "tokenize_sentences", "(", "data", "[", "\"hyp\"", "]", ",", "wd", ")", "\n", "\n", "", "print", "(", "\"Variables processed.\"", ")", "\n", "\n", "# Initialize the model", "\n", "if", "args", ".", "model_type", "==", "'GRU'", "or", "args", ".", "model_type", "==", "''", ":", "\n", "        ", "base_rnn", "=", "torch", ".", "nn", ".", "GRU", "\n", "", "elif", "args", ".", "model_type", "==", "'LSTM'", ":", "\n", "        ", "base_rnn", "=", "torch", ".", "nn", ".", "LSTM", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "model", "=", "BiLSTMModel", "(", ")", ".", "init_model", "(", "wd", ",", "args", ".", "hidden_size", ",", "args", ".", "layers", ",", "args", ".", "layers", ",", "base_rnn", ",", "args", ".", "pretrained_embeddings", ")", "\n", "\n", "val_set_dict", "=", "{", "\"matched_val\"", ":", "matched_val_set", ",", "\"mismatched_val\"", ":", "mismatched_val_set", "}", "\n", "\n", "return", "model", ",", "model_path", ",", "train_set", ",", "val_set_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_train.load_model": [[85, 122], ["nli_model.BiLSTMModel().import_state", "init_save_pretrained_model", "os.path.dirname", "os.path.dirname", "print", "model.add_new_vocabulary", "print", "model.encoder.add_target_pad", "nli_preprocessor.get_multinli_text_hyp_labels", "nli_preprocessor.genre_val_set", "nli_preprocessor.genre_val_set", "nli_model.save_new_train_val_sets", "nli_model.import_data", "nli_model.import_data", "nli_model.import_data", "nli_model.BiLSTMModel", "nli_preprocessor.tokenize_sentences", "nli_preprocessor.tokenize_sentences", "nli_preprocessor.tokenize_sentences", "nli_preprocessor.tokenize_sentences"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.import_state", "home.repos.pwc.inspect_result.nabihach_IDA.None.utils.init_save_pretrained_model", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.add_new_vocabulary", "home.repos.pwc.inspect_result.nabihach_IDA.nli.encoder.EncoderRNN.add_target_pad", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_multinli_text_hyp_labels", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.genre_val_set", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.genre_val_set", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.save_new_train_val_sets", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.import_data", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.import_data", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.import_data", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.tokenize_sentences", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.tokenize_sentences", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.tokenize_sentences", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.tokenize_sentences"], ["", "def", "load_model", "(", "args", ")", ":", "\n", "    ", "model_path", "=", "MODEL_DIR", "+", "args", ".", "load_pretrained_model", "\n", "model", ",", "initial_epoch", "=", "BiLSTMModel", "(", ")", ".", "import_state", "(", "model_path", ",", "load_epoch", "=", "True", ")", "\n", "model_dir", "=", "os", ".", "path", ".", "dirname", "(", "model_path", ")", "+", "\"/\"", "\n", "\n", "if", "args", ".", "transfer_learning_mode", "==", "True", ":", "\n", "        ", "print", "(", "\"Adding new vocabulary...\"", ")", "\n", "model", ".", "add_new_vocabulary", "(", "args", ".", "target_genre", ")", "\n", "print", "(", "\"Resizing memory pad ... \"", ")", "\n", "model", ".", "encoder", ".", "add_target_pad", "(", ")", "\n", "#model.encoder.add_target_pad_2() ---> Use this instead of line 94 if you want to add a 2nd target pad", "\n", "#model.encoder.add_target_pad_3() ---> Use this instead of line 94 if you want to add a 3rd target pad", "\n", "#model.encoder.add_target_pad_4() ---> Use this instead of line 94 if you want to add a 4th target pad       ", "\n", "train_set", "=", "nli_preprocessor", ".", "get_multinli_text_hyp_labels", "(", "max_lines", "=", "args", ".", "max_lines", ",", "genre", "=", "args", ".", "target_genre", ")", "\n", "# To use full matched validation set: use matched_val_set = nli_preprocessor.get_multinli_matched_val_set()", "\n", "matched_val_set", "=", "nli_preprocessor", ".", "genre_val_set", "(", "'fiction'", ")", "\n", "#To use full mismatched validation set use: mismatched_val_set = nli_preprocessor.get_multinli_mismatched_val_set()", "\n", "mismatched_val_set", "=", "nli_preprocessor", ".", "genre_val_set", "(", "'government'", ")", "\n", "for", "data", "in", "[", "train_set", ",", "matched_val_set", ",", "mismatched_val_set", "]", ":", "\n", "            ", "data", "[", "\"text\"", "]", "=", "nli_preprocessor", ".", "tokenize_sentences", "(", "data", "[", "\"text\"", "]", ",", "model", ".", "wd", ")", "\n", "data", "[", "\"hyp\"", "]", "=", "nli_preprocessor", ".", "tokenize_sentences", "(", "data", "[", "\"hyp\"", "]", ",", "model", ".", "wd", ")", "\n", "", "save_new_train_val_sets", "(", "(", "train_set", ",", "matched_val_set", ",", "mismatched_val_set", ")", ",", "model_dir", ")", "\n", "\n", "", "else", ":", "\n", "        ", "train_set", "=", "import_data", "(", "model_dir", "+", "\"/\"", "+", "TRAIN_FILE", ")", "\n", "matched_val_set", "=", "import_data", "(", "model_dir", "+", "\"/\"", "+", "VAL_1_FILE", ")", "\n", "mismatched_val_set", "=", "import_data", "(", "model_dir", "+", "\"/\"", "+", "VAL_2_FILE", ")", "\n", "\n", "# Tokenize sentences", "\n", "for", "data", "in", "[", "train_set", ",", "matched_val_set", ",", "mismatched_val_set", "]", ":", "\n", "            ", "data", "[", "\"text\"", "]", "=", "nli_preprocessor", ".", "tokenize_sentences", "(", "data", "[", "\"text\"", "]", ",", "model", ".", "wd", ")", "\n", "data", "[", "\"hyp\"", "]", "=", "nli_preprocessor", ".", "tokenize_sentences", "(", "data", "[", "\"hyp\"", "]", ",", "model", ".", "wd", ")", "\n", "\n", "", "", "init_save_pretrained_model", "(", "args", ",", "model_dir", ")", "\n", "val_set_dict", "=", "{", "\"matched_val\"", ":", "matched_val_set", ",", "\"mismatched_val\"", ":", "mismatched_val_set", "}", "\n", "\n", "return", "model", ",", "model_dir", ",", "initial_epoch", ",", "train_set", ",", "val_set_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.encoder.EncoderRNN.__init__": [[5, 58], ["nn.Module.__init__", "nn.Dropout", "encoder.EncoderRNN.base_rnn", "encoder.EncoderRNN.base_rnn", "nn.Linear", "nn.Linear", "nn.Linear", "nn.Linear", "nn.Embedding", "nn.Parameter", "print", "nn.Embedding", "pretrained_embeddings.size", "pretrained_embeddings.size"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "n_layers", "=", "1", ",", "dropout", "=", "0.0", ",", "base_rnn", "=", "nn", ".", "LSTM", ",", "pretrained_embeddings", "=", "None", ",", "dropout_p", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "EncoderRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_size", "=", "input_size", "#vocabulary size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "base_rnn", "=", "base_rnn", "\n", "self", ".", "dropout_p", "=", "dropout_p", "\n", "self", ".", "num_mem_slots", "=", "300", "\n", "self", ".", "mem_context_size", "=", "300", "\n", "\n", "if", "pretrained_embeddings", "is", "not", "None", ":", "\n", "\n", "            ", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "pretrained_embeddings", ".", "size", "(", "0", ")", ",", "pretrained_embeddings", ".", "size", "(", "1", ")", ")", "\n", "self", ".", "embedding", ".", "weight", "=", "nn", ".", "Parameter", "(", "pretrained_embeddings", ",", "requires_grad", "=", "True", ")", "\n", "print", "(", "\"GloVe embeddings added\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "input_size", ",", "hidden_size", ")", "\n", "\n", "\n", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout_p", ")", "\n", "self", ".", "forward_rnn", "=", "self", ".", "base_rnn", "(", "hidden_size", "+", "self", ".", "mem_context_size", ",", "hidden_size", ",", "n_layers", ")", "\n", "self", ".", "backward_rnn", "=", "self", ".", "base_rnn", "(", "hidden_size", "+", "self", ".", "mem_context_size", ",", "hidden_size", ",", "n_layers", ")", "\n", "\n", "self", ".", "target_mem_slots", "=", "500", "\n", "self", ".", "target_mem_slots_2", "=", "500", "\n", "self", ".", "target_mem_slots_3", "=", "500", "\n", "self", ".", "target_mem_slots_4", "=", "500", "\n", "\n", "self", ".", "M_k_fwd", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "self", ".", "num_mem_slots", ",", "bias", "=", "False", ")", "\n", "self", ".", "M_v_fwd", "=", "nn", ".", "Linear", "(", "self", ".", "num_mem_slots", ",", "self", ".", "mem_context_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "M_k_bkwd", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "self", ".", "num_mem_slots", ",", "bias", "=", "False", ")", "\n", "self", ".", "M_v_bkwd", "=", "nn", ".", "Linear", "(", "self", ".", "num_mem_slots", ",", "self", ".", "mem_context_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "M_k_fwd_target", "=", "None", "# --> When testing on 1st target or training for 2nd target pad, use self.M_k_fwd_target =  nn.Linear(hidden_size, self.target_mem_slots, bias=False)", "\n", "self", ".", "M_v_fwd_target", "=", "None", "# --> When testing on 1st target or training for 2nd target pad, use self.M_v_fwd_target =  nn.Linear(self.target_mem_slots, self.mem_context_size, bias=False)", "\n", "self", ".", "M_k_bkwd_target", "=", "None", "# --> When testing on 1st target or training for 2nd target pad, use self.M_k_bkwd_target = nn.Linear(hidden_size, self.target_mem_slots, bias=False)", "\n", "self", ".", "M_v_bkwd_target", "=", "None", "# --> When testing on 1st target or training for 2nd target pad, use self.M_v_bkwd_target = nn.Linear(self.target_mem_slots, self.mem_context_size, bias=False)", "\n", "\n", "self", ".", "M_k_fwd_target_2", "=", "None", "# --> When testing on 2nd target or training for 3rd target pad, use self.M_k_fwd_target_2 = nn.Linear(hidden_size, self.target_mem_slots, bias=False)", "\n", "self", ".", "M_v_fwd_target_2", "=", "None", "#  --> When testing on 2nd target or training for 3rd target pad, use self.M_v_fwd_target_2 = nn.Linear(self.target_mem_slots, self.mem_context_size, bias=False)", "\n", "self", ".", "M_k_bkwd_target_2", "=", "None", "# --> When testing on 2nd target or training for 3rd target pad, use self.M_k_bkwd_target_2 = nn.Linear(hidden_size, self.target_mem_slots, bias=False)", "\n", "self", ".", "M_v_bkwd_target_2", "=", "None", "# --> When testing on 2nd target or training for 3rd target pad, use self.M_v_bkwd_target_2 = nn.Linear(self.target_mem_slots, self.mem_context_size, bias=False)", "\n", "\n", "self", ".", "M_k_fwd_target_3", "=", "None", "# --> When testing on 3rd target or training for 4th target pad, use self.M_k_fwd_target_3 =  nn.Linear(hidden_size, self.target_mem_slots, bias=False)", "\n", "self", ".", "M_v_fwd_target_3", "=", "None", "#  --> When testing on 3rd target or training for 4th target pad, use self.M_v_fwd_target_3 = nn.Linear(self.target_mem_slots, self.mem_context_size, bias=False)", "\n", "self", ".", "M_k_bkwd_target_3", "=", "None", "# --> When testing on 3rd target or training for 4th target pad, use self.M_k_bkwd_target_3 =  nn.Linear(hidden_size, self.target_mem_slots, bias=False)", "\n", "self", ".", "M_v_bkwd_target_3", "=", "None", "# --> When testing on 3rd target or training for 4th target pad, use self.M_v_bkwd_target_3 =  nn.Linear(self.target_mem_slots, self.mem_context_size, bias=False)", "\n", "\n", "self", ".", "M_k_fwd_target_4", "=", "None", "# --> When testing on 4th target or training for 5th target pad, use self.M_k_fwd_target_4 =  nn.Linear(hidden_size, self.target_mem_slots, bias=False)", "\n", "self", ".", "M_v_fwd_target_4", "=", "None", "#  --> When testing on 4th target or training for 5th target pad, use self.M_v_fwd_target_4 = nn.Linear(self.target_mem_slots, self.mem_context_size, bias=False)", "\n", "self", ".", "M_k_bkwd_target_4", "=", "None", "# --> When testing on 4th target or training for 5th target pad, use self.M_k_bkwd_target_4 = nn.Linear(hidden_size, self.target_mem_slots, bias=False)", "\n", "self", ".", "M_v_bkwd_target_4", "=", "None", "# --> When testing on 4th target or training for 5th target pad, use self.M_v_bkwd_target_4 = nn.Linear(self.target_mem_slots, self.mem_context_size, bias=False)", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.encoder.EncoderRNN.add_target_pad": [[61, 72], ["nn.Linear", "nn.Linear", "nn.Linear", "nn.Linear", "encoder.EncoderRNN.M_k_fwd_target.cuda", "encoder.EncoderRNN.M_v_fwd_target.cuda", "encoder.EncoderRNN.M_k_bkwd_target.cuda", "encoder.EncoderRNN.M_v_bkwd_target.cuda"], "methods", ["None"], ["", "def", "add_target_pad", "(", "self", ")", ":", "\n", "        ", "self", ".", "M_k_fwd_target", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "self", ".", "target_mem_slots", ",", "bias", "=", "False", ")", "\n", "self", ".", "M_v_fwd_target", "=", "nn", ".", "Linear", "(", "self", ".", "target_mem_slots", ",", "self", ".", "mem_context_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "M_k_bkwd_target", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "self", ".", "target_mem_slots", ",", "bias", "=", "False", ")", "\n", "self", ".", "M_v_bkwd_target", "=", "nn", ".", "Linear", "(", "self", ".", "target_mem_slots", ",", "self", ".", "mem_context_size", ",", "bias", "=", "False", ")", "\n", "\n", "if", "USE_CUDA", ":", "\n", "            ", "self", ".", "M_k_fwd_target", "=", "self", ".", "M_k_fwd_target", ".", "cuda", "(", ")", "\n", "self", ".", "M_v_fwd_target", "=", "self", ".", "M_v_fwd_target", ".", "cuda", "(", ")", "\n", "self", ".", "M_k_bkwd_target", "=", "self", ".", "M_k_bkwd_target", ".", "cuda", "(", ")", "\n", "self", ".", "M_v_bkwd_target", "=", "self", ".", "M_v_bkwd_target", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.encoder.EncoderRNN.add_target_pad_2": [[73, 84], ["nn.Linear", "nn.Linear", "nn.Linear", "nn.Linear", "encoder.EncoderRNN.M_k_fwd_target_2.cuda", "encoder.EncoderRNN.M_v_fwd_target_2.cuda", "encoder.EncoderRNN.M_k_bkwd_target_2.cuda", "encoder.EncoderRNN.M_v_bkwd_target_2.cuda"], "methods", ["None"], ["", "", "def", "add_target_pad_2", "(", "self", ")", ":", "\n", "        ", "self", ".", "M_k_fwd_target_2", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "self", ".", "target_mem_slots_2", ",", "bias", "=", "False", ")", "\n", "self", ".", "M_v_fwd_target_2", "=", "nn", ".", "Linear", "(", "self", ".", "target_mem_slots_2", ",", "self", ".", "mem_context_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "M_k_bkwd_target_2", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "self", ".", "target_mem_slots_2", ",", "bias", "=", "False", ")", "\n", "self", ".", "M_v_bkwd_target_2", "=", "nn", ".", "Linear", "(", "self", ".", "target_mem_slots_2", ",", "self", ".", "mem_context_size", ",", "bias", "=", "False", ")", "\n", "\n", "if", "USE_CUDA", ":", "\n", "            ", "self", ".", "M_k_fwd_target_2", "=", "self", ".", "M_k_fwd_target_2", ".", "cuda", "(", ")", "\n", "self", ".", "M_v_fwd_target_2", "=", "self", ".", "M_v_fwd_target_2", ".", "cuda", "(", ")", "\n", "self", ".", "M_k_bkwd_target_2", "=", "self", ".", "M_k_bkwd_target_2", ".", "cuda", "(", ")", "\n", "self", ".", "M_v_bkwd_target_2", "=", "self", ".", "M_v_bkwd_target_2", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.encoder.EncoderRNN.add_target_pad_3": [[85, 96], ["nn.Linear", "nn.Linear", "nn.Linear", "nn.Linear", "encoder.EncoderRNN.M_k_fwd_target_3.cuda", "encoder.EncoderRNN.M_v_fwd_target_3.cuda", "encoder.EncoderRNN.M_k_bkwd_target_3.cuda", "encoder.EncoderRNN.M_v_bkwd_target_3.cuda"], "methods", ["None"], ["", "", "def", "add_target_pad_3", "(", "self", ")", ":", "\n", "        ", "self", ".", "M_k_fwd_target_3", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "self", ".", "target_mem_slots_3", ",", "bias", "=", "False", ")", "\n", "self", ".", "M_v_fwd_target_3", "=", "nn", ".", "Linear", "(", "self", ".", "target_mem_slots_3", ",", "self", ".", "mem_context_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "M_k_bkwd_target_3", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "self", ".", "target_mem_slots_3", ",", "bias", "=", "False", ")", "\n", "self", ".", "M_v_bkwd_target_3", "=", "nn", ".", "Linear", "(", "self", ".", "target_mem_slots_3", ",", "self", ".", "mem_context_size", ",", "bias", "=", "False", ")", "\n", "\n", "if", "USE_CUDA", ":", "\n", "            ", "self", ".", "M_k_fwd_target_3", "=", "self", ".", "M_k_fwd_target_3", ".", "cuda", "(", ")", "\n", "self", ".", "M_v_fwd_target_3", "=", "self", ".", "M_v_fwd_target_3", ".", "cuda", "(", ")", "\n", "self", ".", "M_k_bkwd_target_3", "=", "self", ".", "M_k_bkwd_target_3", ".", "cuda", "(", ")", "\n", "self", ".", "M_v_bkwd_target_3", "=", "self", ".", "M_v_bkwd_target_3", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.encoder.EncoderRNN.add_target_pad_4": [[97, 108], ["nn.Linear", "nn.Linear", "nn.Linear", "nn.Linear", "encoder.EncoderRNN.M_k_fwd_target_4.cuda", "encoder.EncoderRNN.M_v_fwd_target_4.cuda", "encoder.EncoderRNN.M_k_bkwd_target_4.cuda", "encoder.EncoderRNN.M_v_bkwd_target_4.cuda"], "methods", ["None"], ["", "", "def", "add_target_pad_4", "(", "self", ")", ":", "\n", "        ", "self", ".", "M_k_fwd_target_4", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "self", ".", "target_mem_slots_4", ",", "bias", "=", "False", ")", "\n", "self", ".", "M_v_fwd_target_4", "=", "nn", ".", "Linear", "(", "self", ".", "target_mem_slots_4", ",", "self", ".", "mem_context_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "M_k_bkwd_target_4", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "self", ".", "target_mem_slots_4", ",", "bias", "=", "False", ")", "\n", "self", ".", "M_v_bkwd_target_4", "=", "nn", ".", "Linear", "(", "self", ".", "target_mem_slots_4", ",", "self", ".", "mem_context_size", ",", "bias", "=", "False", ")", "\n", "\n", "if", "USE_CUDA", ":", "\n", "            ", "self", ".", "M_k_fwd_target_4", "=", "self", ".", "M_k_fwd_target_4", ".", "cuda", "(", ")", "\n", "self", ".", "M_v_fwd_target_4", "=", "self", ".", "M_v_fwd_target_4", ".", "cuda", "(", ")", "\n", "self", ".", "M_k_bkwd_target_4", "=", "self", ".", "M_k_bkwd_target_4", ".", "cuda", "(", ")", "\n", "self", ".", "M_v_bkwd_target_4", "=", "self", ".", "M_v_bkwd_target_4", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.encoder.EncoderRNN.forward": [[110, 302], ["input_seqs.size", "Variable", "sequence_mask().transpose().unsqueeze", "Variable", "Variable", "Variable", "Variable", "range", "range", "Variable", "range", "torch.LongTensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "lengths2.cuda.cuda.cuda", "mask.cuda.cuda.cuda", "forward_outs.cuda.cuda.cuda", "backward_outs.cuda.cuda.cuda", "forward_hiddens.cuda.cuda.cuda", "dummy_tensor.cuda.cuda.cuda", "encoder.EncoderRNN.embedding", "encoder.EncoderRNN.dropout", "embedded.unsqueeze.unsqueeze.unsqueeze", "torch.tanh", "torch.tanh.squeeze", "encoder.EncoderRNN.embedding", "encoder.EncoderRNN.dropout", "embedded.unsqueeze.unsqueeze.unsqueeze", "torch.tanh", "mask[].unsqueeze().expand_as", "torch.tanh.squeeze", "mask.cuda.cuda.float", "mask.cuda.cuda.float", "torch.zeros", "hiddens_out.cuda.cuda.cuda", "sequence_mask().transpose", "torch.sum().view", "torch.div", "torch.cat", "encoder.EncoderRNN.forward_rnn", "torch.cat", "encoder.EncoderRNN.forward_rnn", "torch.sum().view", "torch.div", "torch.cat", "encoder.EncoderRNN.backward_rnn", "torch.cat", "encoder.EncoderRNN.backward_rnn", "mask[].unsqueeze().expand_as.float", "torch.exp", "torch.sum().view.expand", "encoder.EncoderRNN.M_v_fwd", "memory_context.cuda.cuda.cuda", "torch.exp", "torch.sum().view.expand", "encoder.EncoderRNN.M_v_bkwd", "memory_context.cuda.cuda.cuda", "mask[].unsqueeze", "sequence_mask", "encoder.EncoderRNN.M_k_fwd", "torch.exp", "torch.exp", "torch.cat", "torch.sum", "torch.cat.size", "encoder.EncoderRNN.M_v_fwd", "encoder.EncoderRNN.M_v_fwd_target", "memory_context.cuda.cuda.unsqueeze", "encoder.EncoderRNN.M_k_bkwd", "torch.exp", "torch.exp", "torch.cat", "torch.sum", "torch.cat.size", "encoder.EncoderRNN.M_v_bkwd", "encoder.EncoderRNN.M_v_bkwd_target", "memory_context.cuda.cuda.unsqueeze", "hidden_f.squeeze", "encoder.EncoderRNN.M_k_fwd", "encoder.EncoderRNN.M_k_fwd_target", "torch.exp", "torch.exp", "torch.exp", "torch.cat", "encoder.EncoderRNN.M_v_fwd", "encoder.EncoderRNN.M_v_fwd_target", "encoder.EncoderRNN.M_v_fwd_target_2", "hidden_b.squeeze", "encoder.EncoderRNN.M_k_bkwd", "encoder.EncoderRNN.M_k_bkwd_target", "torch.exp", "torch.exp", "torch.exp", "torch.cat", "encoder.EncoderRNN.M_v_bkwd", "encoder.EncoderRNN.M_v_bkwd_target", "encoder.EncoderRNN.M_v_bkwd_target_2", "hidden_f.squeeze", "hidden_f.squeeze", "encoder.EncoderRNN.M_k_fwd", "encoder.EncoderRNN.M_k_fwd_target", "encoder.EncoderRNN.M_k_fwd_target_2", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat", "encoder.EncoderRNN.M_v_fwd", "encoder.EncoderRNN.M_v_fwd_target", "encoder.EncoderRNN.M_v_fwd_target_2", "encoder.EncoderRNN.M_v_fwd_target_3", "encoder.EncoderRNN.M_v_fwd", "encoder.EncoderRNN.M_v_fwd_target", "encoder.EncoderRNN.M_v_fwd_target_2", "encoder.EncoderRNN.M_v_fwd_target_3", "encoder.EncoderRNN.M_v_fwd_target_4", "hidden_b.squeeze", "hidden_b.squeeze", "encoder.EncoderRNN.M_k_bkwd", "encoder.EncoderRNN.M_k_bkwd_target", "encoder.EncoderRNN.M_k_bkwd_target_2", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat", "encoder.EncoderRNN.M_v_bkwd", "encoder.EncoderRNN.M_v_bkwd_target", "encoder.EncoderRNN.M_v_bkwd_target_2", "encoder.EncoderRNN.M_v_bkwd_target_3", "encoder.EncoderRNN.M_v_bkwd", "encoder.EncoderRNN.M_v_bkwd_target", "encoder.EncoderRNN.M_v_bkwd_target_2", "encoder.EncoderRNN.M_v_bkwd_target_3", "encoder.EncoderRNN.M_v_bkwd_target_4", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "encoder.EncoderRNN.M_k_fwd", "encoder.EncoderRNN.M_k_fwd_target", "encoder.EncoderRNN.M_k_fwd_target_2", "encoder.EncoderRNN.M_k_fwd_target_3", "encoder.EncoderRNN.M_k_fwd", "encoder.EncoderRNN.M_k_fwd_target", "encoder.EncoderRNN.M_k_fwd_target_2", "encoder.EncoderRNN.M_k_fwd_target_3", "encoder.EncoderRNN.M_k_fwd_target_4", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "encoder.EncoderRNN.M_k_bkwd", "encoder.EncoderRNN.M_k_bkwd_target", "encoder.EncoderRNN.M_k_bkwd_target_2", "encoder.EncoderRNN.M_k_bkwd_target_3", "encoder.EncoderRNN.M_k_bkwd", "encoder.EncoderRNN.M_k_bkwd_target", "encoder.EncoderRNN.M_k_bkwd_target_2", "encoder.EncoderRNN.M_k_bkwd_target_3", "encoder.EncoderRNN.M_k_bkwd_target_4", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze", "hidden_f.squeeze"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.None.utils.sequence_mask"], ["", "", "def", "forward", "(", "self", ",", "input_seqs", ",", "input_lengths", ",", "hidden_f", "=", "None", ",", "hidden_b", "=", "None", ")", ":", "\n", "        ", "max_input_length", ",", "batch_size", "=", "input_seqs", ".", "size", "(", ")", "\n", "\n", "lengths2", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "input_lengths", ")", ")", "\n", "mask", "=", "sequence_mask", "(", "lengths2", ",", "max_len", "=", "max_input_length", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "forward_outs", "=", "Variable", "(", "torch", ".", "zeros", "(", "max_input_length", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ")", "\n", "backward_outs", "=", "Variable", "(", "torch", ".", "zeros", "(", "max_input_length", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ")", "\n", "forward_hiddens", "=", "Variable", "(", "torch", ".", "zeros", "(", "max_input_length", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ")", "\n", "dummy_tensor", "=", "Variable", "(", "torch", ".", "zeros", "(", "1", ",", "batch_size", ",", "self", ".", "mem_context_size", ")", ")", "\n", "\n", "if", "USE_CUDA", ":", "\n", "            ", "lengths2", "=", "lengths2", ".", "cuda", "(", ")", "\n", "mask", "=", "mask", ".", "cuda", "(", ")", "\n", "forward_outs", "=", "forward_outs", ".", "cuda", "(", ")", "\n", "backward_outs", "=", "backward_outs", ".", "cuda", "(", ")", "\n", "forward_hiddens", "=", "forward_hiddens", ".", "cuda", "(", ")", "\n", "dummy_tensor", "=", "dummy_tensor", ".", "cuda", "(", ")", "\n", "\n", "#forward pass", "\n", "", "for", "i", "in", "range", "(", "max_input_length", ")", ":", "\n", "            ", "seq_i", "=", "input_seqs", "[", "i", "]", "\n", "embedded", "=", "self", ".", "embedding", "(", "seq_i", ")", "\n", "embedded", "=", "self", ".", "dropout", "(", "embedded", ")", "\n", "embedded", "=", "embedded", ".", "unsqueeze", "(", "0", ")", "# S=1 x B x N", "\n", "\n", "\n", "# Calculate attention from memory:", "\n", "######################################", "\n", "if", "hidden_f", "is", "not", "None", ":", "\n", "                ", "if", "self", ".", "M_k_fwd_target", "is", "None", ":", "\n", "                    ", "alpha_tilde", "=", "torch", ".", "exp", "(", "self", ".", "M_k_fwd", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "# batch x num_slots", "\n", "", "elif", "self", ".", "M_k_fwd_target", "is", "not", "None", "and", "self", ".", "M_k_fwd_target_2", "is", "None", ":", "\n", "                    ", "alpha_source", "=", "torch", ".", "exp", "(", "self", ".", "M_k_fwd", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target", "=", "torch", ".", "exp", "(", "self", ".", "M_k_fwd_target", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_tilde", "=", "torch", ".", "cat", "(", "(", "alpha_source", ",", "alpha_target", ")", ",", "1", ")", "# batch x (old+new slots)", "\n", "", "elif", "self", ".", "M_k_fwd_target", "is", "not", "None", "and", "self", ".", "M_k_fwd_target_2", "is", "not", "None", "and", "self", ".", "M_k_fwd_target_3", "is", "None", ":", "\n", "                    ", "alpha_source", "=", "torch", ".", "exp", "(", "self", ".", "M_k_fwd", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target", "=", "torch", ".", "exp", "(", "self", ".", "M_k_fwd_target", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target_2", "=", "torch", ".", "exp", "(", "self", ".", "M_k_fwd_target_2", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_tilde", "=", "torch", ".", "cat", "(", "(", "alpha_source", ",", "alpha_target", ",", "alpha_target_2", ")", ",", "1", ")", "\n", "", "elif", "self", ".", "M_k_fwd_target", "is", "not", "None", "and", "self", ".", "M_k_fwd_target_2", "is", "not", "None", "and", "self", ".", "M_k_fwd_target_3", "is", "not", "None", "and", "self", ".", "M_k_fwd_target_4", "is", "None", ":", "\n", "                    ", "alpha_source", "=", "torch", ".", "exp", "(", "self", ".", "M_k_fwd", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target", "=", "torch", ".", "exp", "(", "self", ".", "M_k_fwd_target", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target_2", "=", "torch", ".", "exp", "(", "self", ".", "M_k_fwd_target_2", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target_3", "=", "torch", ".", "exp", "(", "self", ".", "M_k_fwd_target_3", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_tilde", "=", "torch", ".", "cat", "(", "(", "alpha_source", ",", "alpha_target", ",", "alpha_target_2", ",", "alpha_target_3", ")", ",", "1", ")", "\n", "", "else", ":", "\n", "                    ", "alpha_source", "=", "torch", ".", "exp", "(", "self", ".", "M_k_fwd", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target", "=", "torch", ".", "exp", "(", "self", ".", "M_k_fwd_target", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target_2", "=", "torch", ".", "exp", "(", "self", ".", "M_k_fwd_target_2", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target_3", "=", "torch", ".", "exp", "(", "self", ".", "M_k_fwd_target_3", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target_4", "=", "torch", ".", "exp", "(", "self", ".", "M_k_fwd_target_4", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_tilde", "=", "torch", ".", "cat", "(", "(", "alpha_source", ",", "alpha_target", ",", "alpha_target_2", ",", "alpha_target_3", ",", "alpha_target_4", ")", ",", "1", ")", "\n", "\n", "", "alpha_sum", "=", "torch", ".", "sum", "(", "alpha_tilde", ",", "dim", "=", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", "# batch x 1", "\n", "alpha", "=", "torch", ".", "div", "(", "alpha_tilde", ",", "alpha_sum", ".", "expand", "(", "alpha_tilde", ".", "size", "(", ")", ")", ")", "# batch x num_slots", "\n", "\n", "if", "self", ".", "M_v_fwd_target", "is", "None", ":", "\n", "                    ", "memory_context", "=", "self", ".", "M_v_fwd", "(", "alpha", ")", "# batch x context", "\n", "", "elif", "self", ".", "M_v_fwd_target", "is", "not", "None", "and", "self", ".", "M_v_fwd_target_2", "is", "None", ":", "\n", "                    ", "mem_context_source", "=", "self", ".", "M_v_fwd", "(", "alpha", "[", ":", ",", ":", "self", ".", "num_mem_slots", "]", ")", "# batch x old_slots", "\n", "mem_context_target", "=", "self", ".", "M_v_fwd_target", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", ":", "]", ")", "\n", "memory_context", "=", "mem_context_source", "+", "mem_context_target", "\n", "", "elif", "self", ".", "M_v_fwd_target", "is", "not", "None", "and", "self", ".", "M_v_fwd_target_2", "is", "not", "None", "and", "self", ".", "M_v_fwd_target_3", "is", "None", ":", "\n", "                    ", "mem_context_source", "=", "self", ".", "M_v_fwd", "(", "alpha", "[", ":", ",", ":", "self", ".", "num_mem_slots", "]", ")", "# batch x old_slots", "\n", "mem_context_target", "=", "self", ".", "M_v_fwd_target", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "]", ")", "\n", "mem_context_target_2", "=", "self", ".", "M_v_fwd_target_2", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", "]", ")", "\n", "memory_context", "=", "mem_context_source", "+", "mem_context_target", "+", "mem_context_target_2", "\n", "", "elif", "self", ".", "M_v_fwd_target", "is", "not", "None", "and", "self", ".", "M_v_fwd_target_2", "is", "not", "None", "and", "self", ".", "M_v_fwd_target_3", "is", "not", "None", "and", "self", ".", "M_v_fwd_target_4", "is", "None", ":", "\n", "                    ", "mem_context_source", "=", "self", ".", "M_v_fwd", "(", "alpha", "[", ":", ",", ":", "self", ".", "num_mem_slots", "]", ")", "\n", "mem_context_target", "=", "self", ".", "M_v_fwd_target", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "]", ")", "\n", "mem_context_target_2", "=", "self", ".", "M_v_fwd_target_2", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", "]", ")", "\n", "mem_context_target_3", "=", "self", ".", "M_v_fwd_target_3", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", "+", "self", ".", "target_mem_slots_3", "]", ")", "\n", "memory_context", "=", "mem_context_source", "+", "mem_context_target", "+", "mem_context_target_2", "+", "mem_context_target_3", "\n", "", "else", ":", "\n", "                    ", "mem_context_source", "=", "self", ".", "M_v_fwd", "(", "alpha", "[", ":", ",", ":", "self", ".", "num_mem_slots", "]", ")", "\n", "mem_context_target", "=", "self", ".", "M_v_fwd_target", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "]", ")", "\n", "mem_context_target_2", "=", "self", ".", "M_v_fwd_target_2", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", "]", ")", "\n", "mem_context_target_3", "=", "self", ".", "M_v_fwd_target_3", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", "+", "self", ".", "target_mem_slots_3", "]", ")", "\n", "mem_context_target_4", "=", "self", ".", "M_v_fwd_target_4", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", "+", "self", ".", "target_mem_slots_3", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", "+", "self", ".", "target_mem_slots_3", "+", "self", ".", "target_mem_slots_4", "]", ")", "\n", "memory_context", "=", "mem_context_source", "+", "mem_context_target", "+", "mem_context_target_2", "+", "mem_context_target_3", "+", "mem_context_target_4", "\n", "\n", "", "if", "USE_CUDA", ":", "\n", "                    ", "memory_context", "=", "memory_context", ".", "cuda", "(", ")", "\n", "######################################", "\n", "\n", "", "rnn_input", "=", "torch", ".", "cat", "(", "(", "embedded", ",", "memory_context", ".", "unsqueeze", "(", "0", ")", ")", ",", "2", ")", "\n", "output_f", ",", "hidden_f_new", "=", "self", ".", "forward_rnn", "(", "rnn_input", ",", "hidden_f", ")", "\n", "", "else", ":", "\n", "                ", "rnn_input", "=", "torch", ".", "cat", "(", "(", "embedded", ",", "dummy_tensor", ")", ",", "2", ")", "\n", "output_f", ",", "hidden_f_new", "=", "self", ".", "forward_rnn", "(", "rnn_input", ",", "hidden_f", ")", "\n", "\n", "", "output_f", "=", "torch", ".", "tanh", "(", "output_f", ")", "\n", "hidden_f", "=", "hidden_f_new", "\n", "forward_hiddens", "[", "i", ",", ":", ",", ":", "]", "=", "hidden_f", "[", "-", "1", ",", ":", ",", ":", "]", "\n", "forward_outs", "[", "i", "]", "=", "output_f", ".", "squeeze", "(", "0", ")", "\n", "\n", "#backward pass", "\n", "", "for", "i", "in", "range", "(", "1", ",", "max_input_length", "+", "1", ")", ":", "\n", "            ", "seq_i", "=", "input_seqs", "[", "-", "i", "]", "\n", "embedded", "=", "self", ".", "embedding", "(", "seq_i", ")", "\n", "embedded", "=", "self", ".", "dropout", "(", "embedded", ")", "\n", "embedded", "=", "embedded", ".", "unsqueeze", "(", "0", ")", "# S=1 x B x N", "\n", "\n", "\n", "# Calculate attention from memory:", "\n", "######################################", "\n", "if", "hidden_b", "is", "not", "None", ":", "\n", "                ", "if", "self", ".", "M_k_bkwd_target", "is", "None", ":", "\n", "                    ", "alpha_tilde", "=", "torch", ".", "exp", "(", "self", ".", "M_k_bkwd", "(", "hidden_b", ".", "squeeze", "(", "0", ")", ")", ")", "# batch x num_slots", "\n", "", "elif", "self", ".", "M_k_bkwd_target", "is", "not", "None", "and", "self", ".", "M_k_bkwd_target_2", "is", "None", ":", "\n", "                    ", "alpha_source", "=", "torch", ".", "exp", "(", "self", ".", "M_k_bkwd", "(", "hidden_b", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target", "=", "torch", ".", "exp", "(", "self", ".", "M_k_bkwd_target", "(", "hidden_b", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_tilde", "=", "torch", ".", "cat", "(", "(", "alpha_source", ",", "alpha_target", ")", ",", "1", ")", "\n", "", "elif", "self", ".", "M_k_bkwd_target", "is", "not", "None", "and", "self", ".", "M_k_bkwd_target_2", "is", "not", "None", "and", "self", ".", "M_k_bkwd_target_3", "is", "None", ":", "\n", "                    ", "alpha_source", "=", "torch", ".", "exp", "(", "self", ".", "M_k_bkwd", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target", "=", "torch", ".", "exp", "(", "self", ".", "M_k_bkwd_target", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target_2", "=", "torch", ".", "exp", "(", "self", ".", "M_k_bkwd_target_2", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_tilde", "=", "torch", ".", "cat", "(", "(", "alpha_source", ",", "alpha_target", ",", "alpha_target_2", ")", ",", "1", ")", "\n", "", "elif", "self", ".", "M_k_bkwd_target", "is", "not", "None", "and", "self", ".", "M_k_bkwd_target_2", "is", "not", "None", "and", "self", ".", "M_k_bkwd_target_3", "is", "not", "None", "and", "self", ".", "M_k_bkwd_target_4", "is", "None", ":", "\n", "                    ", "alpha_source", "=", "torch", ".", "exp", "(", "self", ".", "M_k_bkwd", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target", "=", "torch", ".", "exp", "(", "self", ".", "M_k_bkwd_target", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target_2", "=", "torch", ".", "exp", "(", "self", ".", "M_k_bkwd_target_2", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target_3", "=", "torch", ".", "exp", "(", "self", ".", "M_k_bkwd_target_3", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_tilde", "=", "torch", ".", "cat", "(", "(", "alpha_source", ",", "alpha_target", ",", "alpha_target_2", ",", "alpha_target_3", ")", ",", "1", ")", "\n", "", "else", ":", "\n", "                    ", "alpha_source", "=", "torch", ".", "exp", "(", "self", ".", "M_k_bkwd", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target", "=", "torch", ".", "exp", "(", "self", ".", "M_k_bkwd_target", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target_2", "=", "torch", ".", "exp", "(", "self", ".", "M_k_bkwd_target_2", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target_3", "=", "torch", ".", "exp", "(", "self", ".", "M_k_bkwd_target_3", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_target_4", "=", "torch", ".", "exp", "(", "self", ".", "M_k_bkwd_target_4", "(", "hidden_f", ".", "squeeze", "(", "0", ")", ")", ")", "\n", "alpha_tilde", "=", "torch", ".", "cat", "(", "(", "alpha_source", ",", "alpha_target", ",", "alpha_target_2", ",", "alpha_target_3", ",", "alpha_target_4", ")", ",", "1", ")", "\n", "\n", "", "alpha_sum", "=", "torch", ".", "sum", "(", "alpha_tilde", ",", "dim", "=", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", "# batch x 1", "\n", "alpha", "=", "torch", ".", "div", "(", "alpha_tilde", ",", "alpha_sum", ".", "expand", "(", "alpha_tilde", ".", "size", "(", ")", ")", ")", "# batch x num_slots", "\n", "if", "self", ".", "M_v_bkwd_target", "is", "None", ":", "\n", "                    ", "memory_context", "=", "self", ".", "M_v_bkwd", "(", "alpha", ")", "# batch x context", "\n", "", "elif", "self", ".", "M_v_bkwd_target", "is", "not", "None", "and", "self", ".", "M_v_bkwd_target_2", "is", "None", ":", "\n", "                    ", "mem_context_source", "=", "self", ".", "M_v_bkwd", "(", "alpha", "[", ":", ",", ":", "self", ".", "num_mem_slots", "]", ")", "\n", "mem_context_target", "=", "self", ".", "M_v_bkwd_target", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", ":", "]", ")", "\n", "memory_context", "=", "mem_context_source", "+", "mem_context_target", "\n", "\n", "", "elif", "self", ".", "M_v_bkwd_target", "is", "not", "None", "and", "self", ".", "M_v_bkwd_target_2", "is", "not", "None", "and", "self", ".", "M_v_bkwd_target_3", "is", "None", ":", "\n", "                    ", "mem_context_source", "=", "self", ".", "M_v_bkwd", "(", "alpha", "[", ":", ",", ":", "self", ".", "num_mem_slots", "]", ")", "\n", "mem_context_target", "=", "self", ".", "M_v_bkwd_target", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "]", ")", "\n", "mem_context_target_2", "=", "self", ".", "M_v_bkwd_target_2", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", "]", ")", "\n", "memory_context", "=", "mem_context_source", "+", "mem_context_target", "+", "mem_context_target_2", "\n", "", "elif", "self", ".", "M_v_bkwd_target", "is", "not", "None", "and", "self", ".", "M_v_bkwd_target_2", "is", "not", "None", "and", "self", ".", "M_v_bkwd_target_3", "is", "not", "None", "and", "self", ".", "M_v_bkwd_target_4", "is", "None", ":", "\n", "                    ", "mem_context_source", "=", "self", ".", "M_v_bkwd", "(", "alpha", "[", ":", ",", ":", "self", ".", "num_mem_slots", "]", ")", "\n", "mem_context_target", "=", "self", ".", "M_v_bkwd_target", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "]", ")", "\n", "mem_context_target_2", "=", "self", ".", "M_v_bkwd_target_2", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", "]", ")", "\n", "mem_context_target_3", "=", "self", ".", "M_v_bkwd_target_3", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", "+", "self", ".", "target_mem_slots_3", "]", ")", "\n", "memory_context", "=", "mem_context_source", "+", "mem_context_target", "+", "mem_context_target_2", "+", "mem_context_target_3", "\n", "", "else", ":", "\n", "                    ", "mem_context_source", "=", "self", ".", "M_v_bkwd", "(", "alpha", "[", ":", ",", ":", "self", ".", "num_mem_slots", "]", ")", "\n", "mem_context_target", "=", "self", ".", "M_v_bkwd_target", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "]", ")", "\n", "mem_context_target_2", "=", "self", ".", "M_v_bkwd_target_2", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", "]", ")", "\n", "mem_context_target_3", "=", "self", ".", "M_v_bkwd_target_3", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", "+", "self", ".", "target_mem_slots_3", "]", ")", "\n", "mem_context_target_4", "=", "self", ".", "M_v_bkwd_target_4", "(", "alpha", "[", ":", ",", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", "+", "self", ".", "target_mem_slots_3", ":", "self", ".", "num_mem_slots", "+", "self", ".", "target_mem_slots", "+", "self", ".", "target_mem_slots_2", "+", "self", ".", "target_mem_slots_3", "+", "self", ".", "target_mem_slots_4", "]", ")", "\n", "memory_context", "=", "mem_context_source", "+", "mem_context_target", "+", "mem_context_target_2", "+", "mem_context_target_3", "+", "mem_context_target_4", "\n", "\n", "\n", "", "if", "USE_CUDA", ":", "\n", "                    ", "memory_context", "=", "memory_context", ".", "cuda", "(", ")", "\n", "######################################", "\n", "\n", "", "rnn_input", "=", "torch", ".", "cat", "(", "(", "embedded", ",", "memory_context", ".", "unsqueeze", "(", "0", ")", ")", ",", "2", ")", "\n", "output_b", ",", "hidden_b_new", "=", "self", ".", "backward_rnn", "(", "rnn_input", ",", "hidden_b", ")", "\n", "", "else", ":", "\n", "                ", "rnn_input", "=", "torch", ".", "cat", "(", "(", "embedded", ",", "dummy_tensor", ")", ",", "2", ")", "\n", "output_b", ",", "hidden_b_new", "=", "self", ".", "backward_rnn", "(", "rnn_input", ",", "hidden_b", ")", "\n", "\n", "", "output_b", "=", "torch", ".", "tanh", "(", "output_b", ")", "\n", "hidden_b", "=", "hidden_b_new", "\n", "back_mask", "=", "mask", "[", "-", "i", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "hidden_b", ")", "\n", "hidden_b", "=", "hidden_b", "*", "back_mask", ".", "float", "(", ")", "\n", "backward_outs", "[", "-", "i", "]", "=", "output_b", ".", "squeeze", "(", "0", ")", "\n", "\n", "", "masked_forward_outs", "=", "forward_outs", "*", "mask", ".", "float", "(", ")", "\n", "masked_backward_outs", "=", "backward_outs", "*", "mask", ".", "float", "(", ")", "\n", "masked_output", "=", "masked_forward_outs", "+", "masked_backward_outs", "#S x B x H", "\n", "\n", "hiddens_out", "=", "Variable", "(", "torch", ".", "zeros", "(", "2", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ")", "\n", "if", "USE_CUDA", ":", "\n", "            ", "hiddens_out", "=", "hiddens_out", ".", "cuda", "(", ")", "\n", "", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "hiddens_out", "[", "0", ",", "i", ",", ":", "]", "=", "forward_hiddens", "[", "input_lengths", "[", "i", "]", "-", "1", ",", "i", ",", ":", "]", "\n", "\n", "", "hiddens_out", "[", "1", ",", ":", ",", ":", "]", "=", "hidden_b", "[", "-", "1", ",", ":", ",", ":", "]", "\n", "\n", "return", "masked_forward_outs", ",", "masked_backward_outs", ",", "hiddens_out", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.encoder.EncoderRNN.init_hidden": [[304, 311], ["encoder.EncoderRNN._init_LSTM", "encoder.EncoderRNN._init_GRU", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.encoder.EncoderRNN._init_LSTM", "home.repos.pwc.inspect_result.nabihach_IDA.nli.encoder.EncoderRNN._init_GRU"], ["", "def", "init_hidden", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "self", ".", "base_rnn", "==", "nn", ".", "LSTM", ":", "\n", "            ", "return", "self", ".", "_init_LSTM", "(", "batch_size", ")", "\n", "", "elif", "self", ".", "base_rnn", "==", "nn", ".", "GRU", ":", "\n", "            ", "return", "self", ".", "_init_GRU", "(", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.encoder.EncoderRNN._init_GRU": [[312, 318], ["Variable", "torch.zeros", "Variable.cuda"], "methods", ["None"], ["", "", "def", "_init_GRU", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "result", "=", "Variable", "(", "torch", ".", "zeros", "(", "1", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ")", "\n", "if", "USE_CUDA", ":", "\n", "            ", "return", "result", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.encoder.EncoderRNN._init_LSTM": [[319, 325], ["Variable", "Variable", "result.cuda", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "", "def", "_init_LSTM", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "result", "=", "(", "Variable", "(", "torch", ".", "zeros", "(", "1", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ")", ",", "Variable", "(", "torch", ".", "zeros", "(", "1", ",", "batch_size", ",", "self", ".", "hidden_size", ")", ")", ")", "\n", "if", "USE_CUDA", ":", "\n", "            ", "return", "result", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.encoder.EncoderRNN.extend_embedding_layer": [[327, 342], ["load_glove_embeddings", "nn.Embedding", "nn.Parameter", "torch.cat", "nn.Embedding", "nn.Parameter", "new_embedding_layer.cuda.cuda.cuda", "added_rows.cuda.cuda.cuda", "encoder.EncoderRNN.embedding.cuda"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.None.utils.load_glove_embeddings"], ["", "", "def", "extend_embedding_layer", "(", "self", ",", "w2i_dict", ",", "num_new_words", ")", ":", "\n", "        ", "glove_vecs", "=", "load_glove_embeddings", "(", "w2i_dict", ",", "self", ".", "hidden_size", ")", "\n", "\n", "new_embedding_layer", "=", "nn", ".", "Embedding", "(", "self", ".", "input_size", "+", "num_new_words", ",", "self", ".", "hidden_size", ")", "\n", "new_embedding_layer", ".", "weight", "=", "nn", ".", "Parameter", "(", "glove_vecs", ",", "requires_grad", "=", "True", ")", "\n", "added_rows", "=", "new_embedding_layer", ".", "weight", "[", "self", ".", "input_size", ":", ",", ":", "]", "\n", "if", "USE_CUDA", ":", "\n", "            ", "new_embedding_layer", "=", "new_embedding_layer", ".", "cuda", "(", ")", "\n", "added_rows", "=", "added_rows", ".", "cuda", "(", ")", "\n", "", "final_weights", "=", "torch", ".", "cat", "(", "(", "self", ".", "embedding", ".", "weight", ",", "added_rows", ")", ",", "0", ")", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "self", ".", "input_size", "+", "num_new_words", ",", "self", ".", "hidden_size", ")", "\n", "self", ".", "embedding", ".", "weight", "=", "nn", ".", "Parameter", "(", "final_weights", ".", "data", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "input_size", "=", "self", ".", "input_size", "+", "num_new_words", "\n", "if", "USE_CUDA", ":", "\n", "            ", "self", ".", "embedding", "=", "self", ".", "embedding", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.__init__": [[61, 65], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "BiLSTMModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "base_rnn", "=", "None", "\n", "self", ".", "wd", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.init_model": [[66, 91], ["encoder.EncoderRNN", "torch.nn.Sequential", "print", "load_glove_embeddings", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Softmax", "nli_model.BiLSTMModel.encoder.parameters", "nli_model.BiLSTMModel.mlp.parameters", "nli_model.BiLSTMModel.encoder.cuda", "nli_model.BiLSTMModel.mlp.cuda", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.None.utils.load_glove_embeddings"], ["", "def", "init_model", "(", "self", ",", "wd", ",", "hidden_size", ",", "e_layers", ",", "d_layers", ",", "base_rnn", ",", "pretrained_embeddings", "=", "None", ",", "dropout_p", "=", "0.1", ")", ":", "\n", "\n", "        ", "self", ".", "base_rnn", "=", "base_rnn", "\n", "self", ".", "wd", "=", "wd", "\n", "self", ".", "dropout_p", "=", "dropout_p", "\n", "if", "pretrained_embeddings", "is", "True", ":", "\n", "            ", "print", "(", "\"Loading GloVe Embeddings ...\"", ")", "\n", "pretrained_embeddings", "=", "load_glove_embeddings", "(", "wd", ".", "word2index", ",", "hidden_size", ")", "\n", "\n", "", "self", ".", "encoder", "=", "EncoderRNN", "(", "wd", ".", "n_words", ",", "hidden_size", ",", "n_layers", "=", "e_layers", ",", "base_rnn", "=", "base_rnn", ",", "pretrained_embeddings", "=", "pretrained_embeddings", ")", "\n", "\n", "self", ".", "mlp", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Linear", "(", "int", "(", "hidden_size", "*", "8", ")", ",", "int", "(", "hidden_size", ")", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", ")", ",", "\n", "torch", ".", "nn", ".", "Dropout", "(", "dropout_p", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "int", "(", "hidden_size", ")", ",", "3", ")", ",", "\n", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", ")", "\n", "self", ".", "parameter_list", "=", "[", "self", ".", "encoder", ".", "parameters", "(", ")", ",", "self", ".", "mlp", ".", "parameters", "(", ")", "]", "\n", "\n", "if", "USE_CUDA", ":", "\n", "            ", "self", ".", "encoder", "=", "self", ".", "encoder", ".", "cuda", "(", ")", "\n", "self", ".", "mlp", "=", "self", ".", "mlp", ".", "cuda", "(", ")", "\n", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.forward": [[92, 116], ["text_batch.size", "nli_model.BiLSTMModel.encoder", "nli_model.BiLSTMModel.encoder", "torch.cat", "torch.cat", "torch.cat", "nli_model.BiLSTMModel.mlp", "torch.abs"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ",", "inference", "=", "False", ")", ":", "\n", "# Convert batch from numpy to torch", "\n", "        ", "if", "inference", "is", "True", ":", "\n", "            ", "text_batch", ",", "text_lengths", ",", "hyp_batch", ",", "hyp_lengths", "=", "batch", "\n", "", "else", ":", "\n", "            ", "text_batch", ",", "text_lengths", ",", "hyp_batch", ",", "hyp_lengths", ",", "labels", "=", "batch", "\n", "", "batch_size", "=", "text_batch", ".", "size", "(", "1", ")", "\n", "\n", "# Pass the input batch through the encoder", "\n", "text_enc_fwd_outputs", ",", "text_enc_bkwd_outputs", ",", "text_encoder_hidden", "=", "self", ".", "encoder", "(", "text_batch", ",", "text_lengths", ")", "\n", "hyp_enc_fwd_outputs", ",", "hyp_enc_bkwd_outputs", ",", "hyp_encoder_hidden", "=", "self", ".", "encoder", "(", "hyp_batch", ",", "hyp_lengths", ")", "\n", "\n", "last_text_enc_fwd", "=", "text_enc_fwd_outputs", "[", "-", "1", ",", ":", ",", ":", "]", "\n", "last_text_enc_bkwd", "=", "text_enc_bkwd_outputs", "[", "0", ",", ":", ",", ":", "]", "\n", "last_text_enc", "=", "torch", ".", "cat", "(", "(", "last_text_enc_fwd", ",", "last_text_enc_bkwd", ")", ",", "dim", "=", "1", ")", "\n", "last_hyp_enc_fwd", "=", "hyp_enc_fwd_outputs", "[", "-", "1", ",", ":", ",", ":", "]", "\n", "last_hyp_enc_bkwd", "=", "hyp_enc_bkwd_outputs", "[", "0", ",", ":", ",", ":", "]", "\n", "last_hyp_enc", "=", "torch", ".", "cat", "(", "(", "last_hyp_enc_fwd", ",", "last_hyp_enc_bkwd", ")", ",", "dim", "=", "1", ")", "\n", "\n", "mult_feature", ",", "diff_feature", "=", "last_text_enc", "*", "last_hyp_enc", ",", "torch", ".", "abs", "(", "last_text_enc", "-", "last_hyp_enc", ")", "\n", "\n", "features", "=", "torch", ".", "cat", "(", "[", "last_text_enc", ",", "last_hyp_enc", ",", "mult_feature", ",", "diff_feature", "]", ",", "dim", "=", "1", ")", "\n", "outputs", "=", "self", ".", "mlp", "(", "features", ")", "# B x 3", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.get_loss_for_batch": [[117, 125], ["nli_model.BiLSTMModel.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss."], "methods", ["None"], ["", "def", "get_loss_for_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "labels", "=", "batch", "[", "-", "1", "]", "\n", "outputs", "=", "self", "(", "batch", ")", "\n", "\n", "loss_fn", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fn", "(", "outputs", ",", "labels", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.torch_batch_from_numpy_batch": [[126, 137], ["list", "torch.autograd.Variable", "torch.from_numpy", "var.cuda.cuda.cuda"], "methods", ["None"], ["", "def", "torch_batch_from_numpy_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch", "=", "list", "(", "batch", ")", "\n", "\n", "variable_indices", "=", "[", "0", ",", "2", ",", "4", "]", "# tuple indices of variables need to be converted", "\n", "for", "i", "in", "variable_indices", ":", "\n", "            ", "var", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "batch", "[", "i", "]", ")", ")", "\n", "if", "USE_CUDA", ":", "\n", "                ", "var", "=", "var", ".", "cuda", "(", ")", "\n", "", "batch", "[", "i", "]", "=", "var", "\n", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.train_batch": [[139, 147], ["nli_model.BiLSTMModel.train", "nli_model.BiLSTMModel.torch_batch_from_numpy_batch", "nli_model.BiLSTMModel.get_loss_for_batch", "nli_model.BiLSTMModel.backward", "nli_model.BiLSTMModel.item"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.torch_batch_from_numpy_batch", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.get_loss_for_batch"], ["", "def", "train_batch", "(", "self", ",", "batch", ",", "tl_mode", "=", "False", ")", ":", "\n", "        ", "self", ".", "train", "(", ")", "\n", "\n", "batch", "=", "self", ".", "torch_batch_from_numpy_batch", "(", "batch", ")", "\n", "loss", "=", "self", ".", "get_loss_for_batch", "(", "batch", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "return", "loss", ".", "item", "(", ")", "#loss.data[0]", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.validate": [[148, 153], ["nli_model.BiLSTMModel.eval", "nli_model.BiLSTMModel.torch_batch_from_numpy_batch", "nli_model.BiLSTMModel.get_loss_for_batch().item", "nli_model.BiLSTMModel.get_loss_for_batch"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.torch_batch_from_numpy_batch", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.get_loss_for_batch"], ["", "def", "validate", "(", "self", ",", "batch", ")", ":", "\n", "        ", "self", ".", "eval", "(", ")", "\n", "\n", "batch", "=", "self", ".", "torch_batch_from_numpy_batch", "(", "batch", ")", "\n", "return", "self", ".", "get_loss_for_batch", "(", "batch", ")", ".", "item", "(", ")", "#.data[0]", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.score": [[154, 167], ["nli_batches", "tqdm.tqdm.tqdm", "nli_model.BiLSTMModel.torch_batch_from_numpy_batch", "nli_model.BiLSTMModel._acc_for_batch", "len"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.nli_batches", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.torch_batch_from_numpy_batch", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel._acc_for_batch"], ["", "def", "score", "(", "self", ",", "data", ")", ":", "\n", "        ", "batch_size", "=", "1", "\n", "batches", "=", "nli_batches", "(", "batch_size", ",", "data", ")", "\n", "\n", "total_correct", "=", "0", "\n", "for", "batch", "in", "tqdm", "(", "batches", ")", ":", "\n", "            ", "batch", "=", "self", ".", "torch_batch_from_numpy_batch", "(", "batch", ")", "\n", "num_correct", "=", "self", ".", "_acc_for_batch", "(", "batch", ")", "\n", "total_correct", "+=", "num_correct", "\n", "\n", "", "acc", "=", "total_correct", "/", "(", "len", "(", "batches", ")", "*", "batch_size", ")", "\n", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel._acc_for_batch": [[168, 184], ["nli_model.BiLSTMModel.eval", "nli_model.BiLSTMModel.", "torch.nonzero", "nli_model.BiLSTMModel.max", "labels.size", "torch.nonzero.size"], "methods", ["None"], ["", "def", "_acc_for_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "'''\n        :param batch:\n        :return: The number of correct predictions in a batch\n        '''", "\n", "self", ".", "eval", "(", ")", "\n", "\n", "outputs", "=", "self", "(", "batch", ")", "\n", "predictions", "=", "outputs", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "\n", "labels", "=", "batch", "[", "-", "1", "]", "\n", "\n", "num_error", "=", "torch", ".", "nonzero", "(", "labels", "-", "predictions", ")", "\n", "num_correct", "=", "labels", ".", "size", "(", "0", ")", "-", "num_error", ".", "size", "(", "0", ")", "\n", "\n", "return", "num_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.export_state": [[185, 232], ["print", "torch.save", "torch.save", "open", "pickle.dump", "open.close", "open", "pickle.dump", "open.close", "open", "pickle.dump", "open.close", "open", "open.write", "open.close", "print", "tarfile.open", "tarfile.open.close", "print", "os.getcwd", "nli_model.BiLSTMModel.encoder.state_dict", "nli_model.BiLSTMModel.mlp.state_dict", "open.write", "tarfile.open.add", "os.remove", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "export_state", "(", "self", ",", "dir", ",", "label", ",", "epoch", "=", "-", "1", ")", ":", "\n", "        ", "print", "(", "\"Saving models.\"", ")", "\n", "\n", "cwd", "=", "os", ".", "getcwd", "(", ")", "+", "'/'", "\n", "\n", "enc_out", "=", "dir", "+", "ENC_1_FILE", "\n", "mlp_out", "=", "dir", "+", "MLP_FILE", "\n", "i2w_out", "=", "dir", "+", "I2W_FILE", "\n", "w2i_out", "=", "dir", "+", "W2I_FILE", "\n", "w2c_out", "=", "dir", "+", "W2C_FILE", "\n", "inf_out", "=", "dir", "+", "INF_FILE", "\n", "\n", "torch", ".", "save", "(", "self", ".", "encoder", ".", "state_dict", "(", ")", ",", "enc_out", ")", "\n", "torch", ".", "save", "(", "self", ".", "mlp", ".", "state_dict", "(", ")", ",", "mlp_out", ")", "\n", "\n", "i2w", "=", "open", "(", "i2w_out", ",", "'wb'", ")", "\n", "pickle", ".", "dump", "(", "self", ".", "wd", ".", "index2word", ",", "i2w", ")", "\n", "i2w", ".", "close", "(", ")", "\n", "w2i", "=", "open", "(", "w2i_out", ",", "'wb'", ")", "\n", "pickle", ".", "dump", "(", "self", ".", "wd", ".", "word2index", ",", "w2i", ")", "\n", "w2i", ".", "close", "(", ")", "\n", "w2c", "=", "open", "(", "w2c_out", ",", "'wb'", ")", "\n", "pickle", ".", "dump", "(", "self", ".", "wd", ".", "word2count", ",", "w2c", ")", "\n", "w2c", ".", "close", "(", ")", "\n", "\n", "info", "=", "open", "(", "inf_out", ",", "'w'", ")", "\n", "using_lstm", "=", "1", "if", "self", ".", "base_rnn", "==", "nn", ".", "LSTM", "else", "0", "\n", "info", ".", "write", "(", "str", "(", "self", ".", "encoder", ".", "hidden_size", ")", "+", "\"\\n\"", "+", "str", "(", "self", ".", "encoder", ".", "n_layers", ")", "+", "\"\\n\"", "+", "\n", "str", "(", "self", ".", "wd", ".", "n_words", ")", "+", "\"\\n\"", "+", "str", "(", "using_lstm", ")", ")", "\n", "if", "epoch", ">", "0", ":", "\n", "            ", "info", ".", "write", "(", "\"\\n\"", "+", "str", "(", "epoch", ")", ")", "\n", "", "info", ".", "close", "(", ")", "\n", "\n", "files", "=", "[", "enc_out", ",", "mlp_out", ",", "i2w_out", ",", "w2i_out", ",", "w2c_out", ",", "inf_out", "]", "\n", "\n", "\n", "print", "(", "\"Bundling models\"", ")", "\n", "\n", "tf", "=", "tarfile", ".", "open", "(", "cwd", "+", "dir", "+", "label", ",", "mode", "=", "'w'", ")", "\n", "for", "file", "in", "files", ":", "\n", "            ", "tf", ".", "add", "(", "file", ")", "\n", "", "tf", ".", "close", "(", ")", "\n", "\n", "for", "file", "in", "files", ":", "\n", "            ", "os", ".", "remove", "(", "file", ")", "\n", "\n", "", "print", "(", "\"Finished saving models.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.import_state": [[234, 294], ["print", "tarfile.open", "tarfile.open.getmembers", "open", "open.readlines", "open", "open", "open", "pickle.load", "pickle.load", "pickle.load", "WordDict", "open.close", "open.close", "open.close", "encoder.EncoderRNN", "torch.nn.Sequential", "nli_model.BiLSTMModel.encoder.eval", "nli_model.BiLSTMModel.mlp.eval", "tarfile.open.close", "print", "os.getcwd", "member.isreg", "int", "int", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Softmax", "nli_model.BiLSTMModel.encoder.load_state_dict", "nli_model.BiLSTMModel.mlp.load_state_dict", "nli_model.BiLSTMModel.encoder.load_state_dict", "nli_model.BiLSTMModel.mlp.load_state_dict", "nli_model.BiLSTMModel.encoder.cuda", "nli_model.BiLSTMModel.mlp.cuda", "nli_model.BiLSTMModel.encoder.parameters", "nli_model.BiLSTMModel.mlp.parameters", "os.path.basename", "tarfile.open.extract", "int", "int", "int", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["None"], ["", "def", "import_state", "(", "self", ",", "model_file", ",", "active_dir", "=", "TEMP_DIR", ",", "load_epoch", "=", "False", ")", ":", "\n", "        ", "print", "(", "\"Loading models.\"", ")", "\n", "cwd", "=", "os", ".", "getcwd", "(", ")", "+", "'/'", "\n", "tf", "=", "tarfile", ".", "open", "(", "model_file", ")", "\n", "\n", "# extract directly to current model directory", "\n", "for", "member", "in", "tf", ".", "getmembers", "(", ")", ":", "\n", "            ", "if", "member", ".", "isreg", "(", ")", ":", "\n", "                ", "member", ".", "name", "=", "os", ".", "path", ".", "basename", "(", "member", ".", "name", ")", "\n", "tf", ".", "extract", "(", "member", ",", "path", "=", "active_dir", ")", "\n", "\n", "", "", "info", "=", "open", "(", "active_dir", "+", "INF_FILE", ",", "'r'", ")", "\n", "lns", "=", "info", ".", "readlines", "(", ")", "\n", "hidden_size", ",", "e_layers", ",", "n_words", ",", "using_lstm", "=", "[", "int", "(", "i", ")", "for", "i", "in", "lns", "[", ":", "4", "]", "]", "\n", "\n", "if", "load_epoch", ":", "\n", "            ", "epoch", "=", "int", "(", "lns", "[", "-", "1", "]", ")", "\n", "\n", "", "i2w", "=", "open", "(", "cwd", "+", "TEMP_DIR", "+", "I2W_FILE", ",", "'rb'", ")", "\n", "w2i", "=", "open", "(", "cwd", "+", "TEMP_DIR", "+", "W2I_FILE", ",", "'rb'", ")", "\n", "w2c", "=", "open", "(", "cwd", "+", "TEMP_DIR", "+", "W2C_FILE", ",", "'rb'", ")", "\n", "i2w_dict", "=", "pickle", ".", "load", "(", "i2w", ")", "\n", "w2i_dict", "=", "pickle", ".", "load", "(", "w2i", ")", "\n", "w2c_dict", "=", "pickle", ".", "load", "(", "w2c", ")", "\n", "wd", "=", "WordDict", "(", "dicts", "=", "[", "w2i_dict", ",", "i2w_dict", ",", "w2c_dict", ",", "n_words", "]", ")", "\n", "w2i", ".", "close", "(", ")", "\n", "i2w", ".", "close", "(", ")", "\n", "w2c", ".", "close", "(", ")", "\n", "\n", "self", ".", "base_rnn", "=", "nn", ".", "LSTM", "if", "using_lstm", "==", "1", "else", "nn", ".", "GRU", "\n", "self", ".", "wd", "=", "wd", "\n", "self", ".", "encoder", "=", "EncoderRNN", "(", "wd", ".", "n_words", ",", "hidden_size", ",", "n_layers", "=", "e_layers", ",", "base_rnn", "=", "self", ".", "base_rnn", ")", "\n", "self", ".", "mlp", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Linear", "(", "int", "(", "hidden_size", "*", "8", ")", ",", "int", "(", "hidden_size", ")", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", ")", ",", "\n", "torch", ".", "nn", ".", "Dropout", "(", "0.1", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "int", "(", "hidden_size", ")", ",", "3", ")", ",", "\n", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", ")", "\n", "if", "not", "USE_CUDA", ":", "\n", "            ", "self", ".", "encoder", ".", "load_state_dict", "(", "torch", ".", "load", "(", "cwd", "+", "TEMP_DIR", "+", "ENC_1_FILE", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "self", ".", "mlp", ".", "load_state_dict", "(", "torch", ".", "load", "(", "cwd", "+", "TEMP_DIR", "+", "MLP_FILE", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "encoder", ".", "load_state_dict", "(", "torch", ".", "load", "(", "cwd", "+", "TEMP_DIR", "+", "ENC_1_FILE", ")", ")", "\n", "self", ".", "mlp", ".", "load_state_dict", "(", "torch", ".", "load", "(", "cwd", "+", "TEMP_DIR", "+", "MLP_FILE", ")", ")", "\n", "self", ".", "encoder", "=", "self", ".", "encoder", ".", "cuda", "(", ")", "\n", "self", ".", "mlp", "=", "self", ".", "mlp", ".", "cuda", "(", ")", "\n", "\n", "", "self", ".", "encoder", ".", "eval", "(", ")", "\n", "self", ".", "mlp", ".", "eval", "(", ")", "\n", "\n", "self", ".", "parameter_list", "=", "[", "self", ".", "encoder", ".", "parameters", "(", ")", ",", "self", ".", "mlp", ".", "parameters", "(", ")", "]", "\n", "tf", ".", "close", "(", ")", "\n", "\n", "print", "(", "\"Loaded models.\"", ")", "\n", "\n", "if", "load_epoch", ":", "\n", "            ", "return", "self", ",", "epoch", "\n", "", "else", ":", "\n", "            ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.torch_batch_from_numpy_batch_without_label": [[296, 307], ["list", "torch.autograd.Variable", "torch.from_numpy", "var.cuda.cuda.cuda"], "methods", ["None"], ["", "", "def", "torch_batch_from_numpy_batch_without_label", "(", "self", ",", "batch", ")", ":", "\n", "        ", "batch", "=", "list", "(", "batch", ")", "\n", "\n", "variable_indices", "=", "[", "0", ",", "2", "]", "\n", "for", "i", "in", "variable_indices", ":", "\n", "            ", "var", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "batch", "[", "i", "]", ")", ")", "\n", "if", "USE_CUDA", ":", "\n", "                ", "var", "=", "var", ".", "cuda", "(", ")", "\n", "", "batch", "[", "i", "]", "=", "var", "\n", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.predict": [[308, 320], ["nli_batches_without_label", "tqdm.tqdm.tqdm", "torch.cat", "nli_model.BiLSTMModel.torch_batch_from_numpy_batch_without_label", "nli_model.BiLSTMModel.", "predictions.append", "nli_model.BiLSTMModel.max"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.nli_batches_without_label", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.torch_batch_from_numpy_batch_without_label"], ["", "def", "predict", "(", "self", ",", "data", ")", ":", "\n", "        ", "batch_size", "=", "1", "\n", "batches", "=", "nli_batches_without_label", "(", "batch_size", ",", "data", ")", "\n", "\n", "predictions", "=", "[", "]", "\n", "for", "batch", "in", "tqdm", "(", "batches", ")", ":", "\n", "            ", "batch", "=", "self", ".", "torch_batch_from_numpy_batch_without_label", "(", "batch", ")", "\n", "outputs", "=", "self", "(", "batch", ",", "inference", "=", "True", ")", "\n", "pred", "=", "outputs", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "predictions", ".", "append", "(", "pred", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "predictions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.add_new_vocabulary": [[321, 343], ["print", "nli_preprocessor.get_multinli_text_hyp_labels", "nli_preprocessor.get_multinli_matched_val_set", "list", "print", "print", "nli_model.BiLSTMModel.encoder.extend_embedding_layer", "unmerged_sentences.extend", "itertools.chain.from_iterable", "nli_model.BiLSTMModel.wd.add_sentence", "str", "str"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_multinli_text_hyp_labels", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_multinli_matched_val_set", "home.repos.pwc.inspect_result.nabihach_IDA.nli.encoder.EncoderRNN.extend_embedding_layer", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict.add_sentence"], ["", "def", "add_new_vocabulary", "(", "self", ",", "genre", ")", ":", "\n", "        ", "old_vocab_size", "=", "self", ".", "wd", ".", "n_words", "\n", "print", "(", "\"Previous vocabulary size: \"", "+", "str", "(", "old_vocab_size", ")", ")", "\n", "\n", "train_set", "=", "nli_preprocessor", ".", "get_multinli_text_hyp_labels", "(", "genre", "=", "genre", ")", "#nli_preprocessor.get_multinli_training_set(max_lines=args.max_lines)", "\n", "matched_val_set", "=", "nli_preprocessor", ".", "get_multinli_matched_val_set", "(", ")", "#genre_val_set(genre)", "\n", "\n", "unmerged_sentences", "=", "[", "]", "\n", "for", "data", "in", "[", "train_set", ",", "matched_val_set", "]", ":", "\n", "            ", "unmerged_sentences", ".", "extend", "(", "[", "data", "[", "\"text\"", "]", ",", "data", "[", "\"hyp\"", "]", "]", ")", "\n", "", "all_sentences", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "unmerged_sentences", ")", ")", "\n", "\n", "for", "line", "in", "all_sentences", ":", "\n", "            ", "self", ".", "wd", ".", "add_sentence", "(", "line", ")", "\n", "\n", "", "print", "(", "\"New vocabulary size: \"", "+", "str", "(", "self", ".", "wd", ".", "n_words", ")", ")", "\n", "\n", "print", "(", "\"Extending the Embedding layer with new vocabulary...\"", ")", "\n", "num_new_words", "=", "self", ".", "wd", ".", "n_words", "-", "old_vocab_size", "\n", "self", ".", "encoder", ".", "extend_embedding_layer", "(", "self", ".", "wd", ".", "word2index", ",", "num_new_words", ")", "\n", "\n", "self", ".", "new_vocab_size", "=", "num_new_words", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.freeze_source_params": [[344, 353], ["nli_model.BiLSTMModel.named_parameters", "nli_model.BiLSTMModel.named_parameters", "print"], "methods", ["None"], ["", "def", "freeze_source_params", "(", "self", ")", ":", "\n", "        ", "for", "name", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "\"rnn\"", "in", "name", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "if", "(", "\"M_k\"", "in", "name", "or", "\"M_v\"", "in", "name", ")", "and", "\"target_4\"", "not", "in", "name", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "for", "name", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "param", ".", "requires_grad", "is", "True", ":", "\n", "                ", "print", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.import_data": [[17, 22], ["open", "pickle.load", "open.close"], "function", ["None"], ["def", "import_data", "(", "path", ")", ":", "\n", "    ", "f", "=", "open", "(", "path", ",", "'rb'", ")", "\n", "data", "=", "pickle", ".", "load", "(", "f", ")", "\n", "f", ".", "close", "(", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.export_data": [[23, 27], ["open", "pickle.dump", "open.close"], "function", ["None"], ["", "def", "export_data", "(", "data", ",", "path", ")", ":", "\n", "    ", "f", "=", "open", "(", "path", ",", "'wb'", ")", "\n", "pickle", ".", "dump", "(", "data", ",", "f", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.init_save": [[28, 51], ["datetime.datetime.now", "open", "vars", "open.write", "vars.items", "open.write", "open.close", "print", "nli_model.export_data", "nli_model.export_data", "nli_model.export_data", "print", "str", "os.path.isdir", "os.mkdir", "open.write", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.export_data", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.export_data", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.export_data"], ["", "def", "init_save", "(", "args", ",", "data", ",", "model_dir", "=", "MODEL_DIR", ")", ":", "\n", "    ", "t", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "timestamp", "=", "str", "(", "t", ".", "day", ")", "+", "\"_\"", "+", "str", "(", "t", ".", "hour", ")", "+", "\"_\"", "+", "str", "(", "t", ".", "minute", ")", "\n", "path", "=", "model_dir", "+", "\"mnli_\"", "+", "timestamp", "+", "\"/\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "path", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "path", ")", "\n", "\n", "", "log_file", "=", "open", "(", "path", "+", "LOG_FILE", ",", "'a'", ")", "\n", "arg_dict", "=", "vars", "(", "args", ")", "\n", "log_file", ".", "write", "(", "\"Training Parameters:\\n\"", ")", "\n", "for", "(", "arg", ",", "val", ")", "in", "arg_dict", ".", "items", "(", ")", ":", "\n", "        ", "log_file", ".", "write", "(", "str", "(", "arg", ")", "+", "\": \"", "+", "str", "(", "val", ")", "+", "'\\n'", ")", "\n", "", "log_file", ".", "write", "(", "\"\\n\"", ")", "\n", "log_file", ".", "close", "(", ")", "\n", "print", "(", "\"Model parameters saved.\"", ")", "\n", "\n", "train", ",", "val_1", ",", "val_2", "=", "data", "\n", "export_data", "(", "train", ",", "path", "+", "TRAIN_FILE", ")", "\n", "export_data", "(", "val_1", ",", "path", "+", "VAL_1_FILE", ")", "\n", "export_data", "(", "val_2", ",", "path", "+", "VAL_2_FILE", ")", "\n", "print", "(", "\"Training and validation sets saved.\"", ")", "\n", "\n", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.save_new_train_val_sets": [[52, 58], ["nli_model.export_data", "nli_model.export_data", "nli_model.export_data", "print"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.export_data", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.export_data", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.export_data"], ["", "def", "save_new_train_val_sets", "(", "data", ",", "model_dir", "=", "MODEL_DIR", ")", ":", "\n", "    ", "train", ",", "val_1", ",", "val_2", "=", "data", "\n", "export_data", "(", "train", ",", "model_dir", "+", "TRAIN_FILE", ")", "\n", "export_data", "(", "val_1", ",", "model_dir", "+", "VAL_1_FILE", ")", "\n", "export_data", "(", "val_2", ",", "model_dir", "+", "VAL_2_FILE", ")", "\n", "print", "(", "\"New training and validation sets saved.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.tokenize_sentences": [[10, 14], ["tokenize_sentence", "wd.to_indices"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict.to_indices"], ["def", "tokenize_sentences", "(", "sentences", ",", "wd", ")", ":", "\n", "    ", "tokenize_sentence", "=", "lambda", "s", ":", "wd", ".", "to_indices", "(", "s", ")", "+", "[", "preprocess", ".", "EOS_INDEX", "]", "\n", "\n", "return", "[", "tokenize_sentence", "(", "s", ")", "for", "s", "in", "sentences", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_word_dict": [[15, 32], ["print", "preprocess.WordDict", "enumerate", "print", "preprocess.WordDict.remove_unknowns", "print", "preprocess.WordDict.add_sentence", "str", "str", "str", "len"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict.remove_unknowns", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.WordDict.add_sentence"], ["", "def", "get_word_dict", "(", "sentences", ",", "max_lines", "=", "-", "1", ",", "unk_thresh", "=", "1", ")", ":", "\n", "    ", "print", "(", "\"Generating WordDict\"", ")", "\n", "wd", "=", "preprocess", ".", "WordDict", "(", ")", "\n", "\n", "for", "i", ",", "sentence", "in", "enumerate", "(", "sentences", ")", ":", "\n", "        ", "if", "max_lines", ">", "0", "and", "i", ">=", "max_lines", ":", "\n", "            ", "break", "\n", "\n", "", "wd", ".", "add_sentence", "(", "sentence", ")", "\n", "\n", "", "print", "(", "str", "(", "wd", ".", "n_words", ")", ",", "\"total unique words.\"", ")", "\n", "\n", "unks", "=", "wd", ".", "remove_unknowns", "(", "unk_thresh", ")", "\n", "\n", "print", "(", "str", "(", "len", "(", "unks", ")", ")", ",", "\"words removed.\"", ",", "str", "(", "wd", ".", "n_words", ")", ",", "\"words remaining in vocabulary.\"", ")", "\n", "\n", "return", "wd", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.valid_label": [[33, 36], ["None"], "function", ["None"], ["", "def", "valid_label", "(", "label", ")", ":", "\n", "    ", "labels", "=", "[", "'entailment'", ",", "'neutral'", ",", "'contradiction'", "]", "\n", "return", "label", "in", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.label_to_vector": [[37, 46], ["Exception", "str"], "function", ["None"], ["", "def", "label_to_vector", "(", "label", ")", ":", "\n", "    ", "if", "label", "==", "'entailment'", ":", "\n", "        ", "return", "0", "\n", "", "elif", "label", "==", "'neutral'", ":", "\n", "        ", "return", "1", "\n", "", "elif", "label", "==", "'contradiction'", ":", "\n", "        ", "return", "2", "\n", "\n", "", "raise", "Exception", "(", "'Unknown label:'", "+", "str", "(", "label", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.genre_val_set": [[47, 50], ["nli_preprocessor.get_nli_text_hyp_labels", "str"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_nli_text_hyp_labels"], ["", "def", "genre_val_set", "(", "genre", ")", ":", "\n", "    ", "genre_val_path", "=", "\"nli/data/raw/multinli_0.9/val_\"", "+", "str", "(", "genre", ")", "+", "\".jsonl\"", "\n", "return", "get_nli_text_hyp_labels", "(", "genre_val_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.genre_test_set": [[51, 54], ["nli_preprocessor.get_nli_text_hyp_labels", "str"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_nli_text_hyp_labels"], ["", "def", "genre_test_set", "(", "genre", ")", ":", "\n", "    ", "genre_test_path", "=", "\"nli/data/raw/multinli_0.9/test_\"", "+", "str", "(", "genre", ")", "+", "\".jsonl\"", "\n", "return", "get_nli_text_hyp_labels", "(", "genre_test_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_multinli_test_set_matched": [[55, 58], ["nli_preprocessor.get_nli_text_hyp"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_nli_text_hyp"], ["", "def", "get_multinli_test_set_matched", "(", "max_lines", "=", "-", "1", ")", ":", "\n", "    ", "multinli_test_path", "=", "\"nli/data/raw/multinli_0.9/multinli_0.9_test_matched_unlabeled.jsonl\"", "\n", "return", "get_nli_text_hyp", "(", "multinli_test_path", ",", "max_lines", "=", "max_lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_multinli_test_set_mismatched": [[59, 62], ["nli_preprocessor.get_nli_text_hyp"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_nli_text_hyp"], ["", "def", "get_multinli_test_set_mismatched", "(", "max_lines", "=", "-", "1", ")", ":", "\n", "    ", "multinli_test_path", "=", "\"nli/data/raw/multinli_0.9/multinli_0.9_test_mismatched_unlabeled.jsonl\"", "\n", "return", "get_nli_text_hyp", "(", "multinli_test_path", ",", "max_lines", "=", "max_lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_multinli_training_set": [[64, 67], ["nli_preprocessor.get_nli_text_hyp_labels"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_nli_text_hyp_labels"], ["", "def", "get_multinli_training_set", "(", "max_lines", "=", "-", "1", ")", ":", "\n", "    ", "multinli_train_path", "=", "\"nli/data/raw/multinli_0.9/multinli_0.9_train.jsonl\"", "\n", "return", "get_nli_text_hyp_labels", "(", "multinli_train_path", ",", "max_lines", "=", "max_lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_multinli_matched_val_set": [[68, 71], ["nli_preprocessor.get_nli_text_hyp_labels"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_nli_text_hyp_labels"], ["", "def", "get_multinli_matched_val_set", "(", ")", ":", "\n", "    ", "multinli_dev_matched_path", "=", "\"nli/data/raw/multinli_0.9/multinli_0.9_dev_matched.jsonl\"", "\n", "return", "get_nli_text_hyp_labels", "(", "multinli_dev_matched_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_multinli_mismatched_val_set": [[72, 75], ["nli_preprocessor.get_nli_text_hyp_labels"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_nli_text_hyp_labels"], ["", "def", "get_multinli_mismatched_val_set", "(", ")", ":", "\n", "    ", "multinli_dev_mismatched_path", "=", "\"nli/data/raw/multinli_0.9/multinli_0.9_dev_mismatched.jsonl\"", "\n", "return", "get_nli_text_hyp_labels", "(", "multinli_dev_mismatched_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.dev_matched_text_hyp_labels": [[76, 89], ["nli_preprocessor.get_nli_text_hyp_labels", "data[].map"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_nli_text_hyp_labels"], ["", "def", "dev_matched_text_hyp_labels", "(", "max_lines", "=", "-", "1", ",", "num_genres", "=", "-", "1", ",", "genre", "=", "None", ")", ":", "\n", "    ", "multinli_path", "=", "\"nli/data/raw/multinli_0.9/multinli_0.9_dev_matched.jsonl\"", "\n", "\n", "data_filter", "=", "None", "\n", "\n", "all_genres", "=", "[", "'fiction'", ",", "'government'", ",", "'slate'", ",", "'telephone'", ",", "'travel'", ",", "'9/11'", ",", "'face-to-face'", ",", "'letters'", ",", "'oup'", ",", "'verbatim'", "]", "\n", "if", "genre", "is", "not", "None", ":", "\n", "        ", "sel_genres", "=", "[", "genre", "]", "\n", "", "else", ":", "\n", "        ", "sel_genres", "=", "all_genres", "\n", "", "data_filter", "=", "lambda", "data", ":", "data", "[", "'genre'", "]", ".", "map", "(", "lambda", "genre", ":", "genre", "in", "sel_genres", ")", "\n", "\n", "return", "get_nli_text_hyp_labels", "(", "multinli_path", ",", "max_lines", "=", "max_lines", ",", "data_filter", "=", "data_filter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.dev_mismatched_text_hyp_labels": [[90, 103], ["nli_preprocessor.get_nli_text_hyp_labels", "data[].map"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_nli_text_hyp_labels"], ["", "def", "dev_mismatched_text_hyp_labels", "(", "max_lines", "=", "-", "1", ",", "num_genres", "=", "-", "1", ",", "genre", "=", "None", ")", ":", "\n", "    ", "multinli_path", "=", "\"nli/data/raw/multinli_0.9/multinli_0.9_dev_mismatched.jsonl\"", "\n", "\n", "data_filter", "=", "None", "\n", "\n", "all_genres", "=", "[", "'fiction'", ",", "'government'", ",", "'slate'", ",", "'telephone'", ",", "'travel'", ",", "'9/11'", ",", "'face-to-face'", ",", "'letters'", ",", "'oup'", ",", "'verbatim'", "]", "\n", "if", "genre", "is", "not", "None", ":", "\n", "        ", "sel_genres", "=", "[", "genre", "]", "\n", "", "else", ":", "\n", "        ", "sel_genres", "=", "all_genres", "\n", "", "data_filter", "=", "lambda", "data", ":", "data", "[", "'genre'", "]", ".", "map", "(", "lambda", "genre", ":", "genre", "in", "sel_genres", ")", "\n", "\n", "return", "get_nli_text_hyp_labels", "(", "multinli_path", ",", "max_lines", "=", "max_lines", ",", "data_filter", "=", "data_filter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_multinli_text_hyp_labels": [[106, 119], ["nli_preprocessor.get_nli_text_hyp_labels", "data[].map"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_nli_text_hyp_labels"], ["", "def", "get_multinli_text_hyp_labels", "(", "max_lines", "=", "-", "1", ",", "num_genres", "=", "-", "1", ",", "genre", "=", "None", ")", ":", "\n", "    ", "multinli_path", "=", "\"nli/data/raw/multinli_0.9/multinli_0.9_train.jsonl\"", "\n", "\n", "data_filter", "=", "None", "\n", "#if num_genres > 0:", "\n", "all_genres", "=", "[", "'fiction'", ",", "'government'", ",", "'slate'", ",", "'telephone'", ",", "'travel'", "]", "\n", "if", "genre", "is", "not", "None", ":", "\n", "        ", "sel_genres", "=", "[", "genre", "]", "#['travel'] #all_genres[:num_genres]", "\n", "", "else", ":", "\n", "        ", "sel_genres", "=", "all_genres", "\n", "", "data_filter", "=", "lambda", "data", ":", "data", "[", "'genre'", "]", ".", "map", "(", "lambda", "genre", ":", "genre", "in", "sel_genres", ")", "\n", "\n", "return", "get_nli_text_hyp_labels", "(", "multinli_path", ",", "max_lines", "=", "max_lines", ",", "data_filter", "=", "data_filter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_nli_text_hyp": [[121, 140], ["pandas.read_json", "valid_df[].map", "valid_df[].map", "len", "preprocess.separate", "nli_df[].notnull", "preprocess.normalize", "len", "data_filter"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.separate", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.normalize"], ["", "def", "get_nli_text_hyp", "(", "path_to_nli_dataset", ",", "max_lines", "=", "-", "1", ",", "data_filter", "=", "None", ")", ":", "\n", "\n", "    ", "nli_df", "=", "pd", ".", "read_json", "(", "path_to_nli_dataset", ",", "lines", "=", "True", ")", "\n", "\n", "valid_df", "=", "nli_df", "[", "nli_df", "[", "'sentence2'", "]", ".", "notnull", "(", ")", "]", "\n", "if", "data_filter", "is", "not", "None", ":", "\n", "        ", "valid_df", "=", "valid_df", "[", "data_filter", "(", "valid_df", ")", "]", "\n", "\n", "", "reformat_sentence", "=", "lambda", "original_sentence", ":", "preprocess", ".", "separate", "(", "preprocess", ".", "normalize", "(", "original_sentence", ")", ")", "\n", "\n", "text_sentences", "=", "valid_df", "[", "'sentence1'", "]", ".", "map", "(", "reformat_sentence", ")", "\n", "hyp_sentences", "=", "valid_df", "[", "'sentence2'", "]", ".", "map", "(", "reformat_sentence", ")", "\n", "\n", "if", "0", "<", "max_lines", "and", "max_lines", "<=", "len", "(", "text_sentences", ")", ":", "\n", "        ", "text_sentences", ",", "hyp_sentences", "=", "text_sentences", "[", ":", "max_lines", "]", ",", "hyp_sentences", "[", ":", "max_lines", "]", "\n", "\n", "", "length", "=", "len", "(", "text_sentences", ")", "\n", "#print(length)", "\n", "return", "{", "\"text\"", ":", "text_sentences", ",", "\"hyp\"", ":", "hyp_sentences", ",", "\"length\"", ":", "length", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.get_nli_text_hyp_labels": [[142, 162], ["pandas.read_json", "valid_df[].map", "valid_df[].map", "valid_df[].map().tolist", "len", "print", "preprocess.separate", "preprocess.normalize", "valid_df[].map", "len", "nli_df[].notnull", "nli_df[].map", "data_filter"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.separate", "home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.normalize"], ["", "def", "get_nli_text_hyp_labels", "(", "path_to_nli_dataset", ",", "max_lines", "=", "-", "1", ",", "data_filter", "=", "None", ")", ":", "\n", "\n", "    ", "nli_df", "=", "pd", ".", "read_json", "(", "path_to_nli_dataset", ",", "lines", "=", "True", ")", "\n", "\n", "valid_df", "=", "nli_df", "[", "nli_df", "[", "'sentence2'", "]", ".", "notnull", "(", ")", "&", "nli_df", "[", "'gold_label'", "]", ".", "map", "(", "valid_label", ")", "]", "\n", "if", "data_filter", "is", "not", "None", ":", "\n", "        ", "valid_df", "=", "valid_df", "[", "data_filter", "(", "valid_df", ")", "]", "\n", "\n", "", "reformat_sentence", "=", "lambda", "original_sentence", ":", "preprocess", ".", "separate", "(", "preprocess", ".", "normalize", "(", "original_sentence", ")", ")", "\n", "\n", "text_sentences", "=", "valid_df", "[", "'sentence1'", "]", ".", "map", "(", "reformat_sentence", ")", "\n", "hyp_sentences", "=", "valid_df", "[", "'sentence2'", "]", ".", "map", "(", "reformat_sentence", ")", "\n", "labels", "=", "valid_df", "[", "'gold_label'", "]", ".", "map", "(", "label_to_vector", ")", ".", "tolist", "(", ")", "\n", "\n", "if", "0", "<", "max_lines", "and", "max_lines", "<=", "len", "(", "text_sentences", ")", ":", "\n", "        ", "text_sentences", ",", "hyp_sentences", ",", "labels", "=", "text_sentences", "[", ":", "max_lines", "]", ",", "hyp_sentences", "[", ":", "max_lines", "]", ",", "labels", "[", ":", "max_lines", "]", "\n", "\n", "", "length", "=", "len", "(", "text_sentences", ")", "\n", "print", "(", "length", ")", "\n", "return", "{", "\"text\"", ":", "text_sentences", ",", "\"hyp\"", ":", "hyp_sentences", ",", "\"label\"", ":", "labels", ",", "\"length\"", ":", "length", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler.__init__": [[11, 42], ["filter", "torch.Adam", "torch.Adam", "torch.ReduceLROnPlateau", "torch.ReduceLROnPlateau", "nli_training_handler.TrainingHandler.optim.append", "nli_training_handler.TrainingHandler.sched.append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "train_set", ",", "val_set_dict", ",", "learning_rate", ",", "save_dir", ",", "patience", "=", "10", ",", "annealing_factor", "=", "0.1", ",", "\n", "weight_decay", "=", "0.01", ",", "clip", "=", "5.0", ",", "tf_ratio", "=", "1.0", ",", "initial_epoch", "=", "0", ")", ":", "\n", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "train_set", "=", "train_set", "\n", "self", ".", "val_set_dict", "=", "val_set_dict", "\n", "\n", "self", ".", "clip", "=", "clip", "\n", "self", ".", "tf_ratio", "=", "tf_ratio", "\n", "self", ".", "save_dir", "=", "save_dir", "\n", "\n", "self", ".", "initial_epoch", "=", "initial_epoch", "\n", "self", ".", "epoch", "=", "initial_epoch", "\n", "self", ".", "lr", "=", "learning_rate", "\n", "\n", "self", ".", "optim", "=", "[", "]", "\n", "self", ".", "sched", "=", "[", "]", "\n", "for", "parameter", "in", "self", ".", "model", ".", "parameter_list", ":", "\n", "\n", "# Initialize optimizers", "\n", "            ", "filtered_parameter", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "parameter", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "filtered_parameter", ",", "lr", "=", "learning_rate", ")", "\n", "\n", "# Add schedulers to reduce the learning rate if the loss plateaus", "\n", "scheduler", "=", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "'min'", ",", "factor", "=", "annealing_factor", ",", "\n", "patience", "=", "patience", ")", "\n", "\n", "self", ".", "optim", ".", "append", "(", "optimizer", ")", "\n", "self", ".", "sched", ".", "append", "(", "scheduler", ")", "\n", "\n", "", "self", ".", "losses", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler.train_model": [[43, 97], ["print", "time.time", "print", "get_nli_batch", "len", "tqdm.tqdm.tqdm", "nli_training_handler.TrainingHandler.losses.append", "range", "nli_training_handler.TrainingHandler._train_iter", "nli_training_handler.TrainingHandler._get_val_loss", "loss_dict.update", "nli_training_handler.TrainingHandler._save_checkpoint", "nli_training_handler.TrainingHandler._print_log", "nli_training_handler.TrainingHandler._save_checkpoint", "str", "time_since", "str"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.get_nli_batch", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler._train_iter", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler._get_val_loss", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler._save_checkpoint", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler._print_log", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler._save_checkpoint", "home.repos.pwc.inspect_result.nabihach_IDA.None.utils.time_since"], ["", "def", "train_model", "(", "self", ",", "epochs", ",", "batch_size", ",", "print_interval", "=", "1", ",", "save_interval", "=", "-", "1", ",", "tl_mode", "=", "False", ")", ":", "\n", "        ", "eca", "=", "0", "\n", "dca", "=", "0", "\n", "\n", "loss_total", "=", "0", "\n", "\n", "print", "(", "\"Beginning training...\"", ")", "\n", "if", "tl_mode", "is", "True", ":", "\n", "            ", "print", "(", "\"Transfer Learning mode is ON...\"", ")", "\n", "", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "target_epoch", "=", "self", ".", "initial_epoch", "+", "epochs", "\n", "\n", "while", "self", ".", "epoch", "<", "target_epoch", ":", "\n", "            ", "self", ".", "epoch", "+=", "1", "\n", "\n", "# Get training data for this cycle", "\n", "batches", "=", "get_nli_batch", "(", "batch_size", ",", "self", ".", "train_set", ")", "\n", "\n", "n_batches", "=", "len", "(", "batches", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "n_batches", ")", ")", ":", "\n", "                ", "loss", ",", "gradients", "=", "self", ".", "_train_iter", "(", "batches", "[", "i", "]", ",", "tl_mode", "=", "tl_mode", ")", "\n", "\n", "loss_total", "+=", "loss", "\n", "\n", "", "loss_avg", "=", "loss_total", "/", "n_batches", "\n", "loss_total", "=", "0", "\n", "\n", "loss_dict", "=", "{", "\"train\"", ":", "loss_avg", "}", "\n", "\n", "# Calculate validation loss", "\n", "if", "self", ".", "val_set_dict", "is", "not", "None", ":", "\n", "                ", "val_loss_avg", "=", "self", ".", "_get_val_loss", "(", ")", "\n", "loss_dict", ".", "update", "(", "val_loss_avg", ")", "\n", "\n", "", "self", ".", "losses", ".", "append", "(", "loss_dict", ")", "\n", "\n", "# Print progress and loss every X epochs", "\n", "if", "print_interval", ">", "0", ":", "\n", "                ", "if", "self", ".", "epoch", "%", "print_interval", "==", "0", ":", "\n", "                    ", "print_summary", "=", "'-'", "*", "40", "+", "'\\nEPOCH #%d SUMMARY:\\nTotal time spent (time left): %s, Loss: %s'", "%", "(", "self", ".", "epoch", ",", "time_since", "(", "start", ",", "(", "self", ".", "epoch", "-", "self", ".", "initial_epoch", ")", "/", "epochs", ")", ",", "loss_dict", ")", "\n", "self", ".", "_print_log", "(", "print_summary", ")", "\n", "\n", "# Calculate BLEU score and save checkpoint every Y epochs", "\n", "", "", "if", "self", ".", "epoch", "<", "target_epoch", ":", "\n", "                ", "if", "save_interval", ">", "0", ":", "\n", "                    ", "if", "self", ".", "epoch", "%", "save_interval", "==", "0", ":", "\n", "                        ", "name", "=", "\"_\"", "+", "str", "(", "self", ".", "epoch", ")", "+", "\".tar\"", "\n", "self", ".", "_save_checkpoint", "(", "self", ".", "save_dir", ",", "name", ")", "\n", "", "", "", "else", ":", "\n", "                ", "name", "=", "\"_\"", "+", "str", "(", "self", ".", "epoch", ")", "+", "\".tar\"", "\n", "self", ".", "_save_checkpoint", "(", "self", ".", "save_dir", ",", "name", ",", "save_loss", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler._train_iter": [[98, 118], ["nli_training_handler.TrainingHandler.model.train_batch", "torch.zero_grad", "torch.zero_grad", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "gradients.append", "torch.step", "torch.step"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.train_batch"], ["", "", "", "def", "_train_iter", "(", "self", ",", "batch", ",", "tl_mode", "=", "False", ")", ":", "\n", "# Zero the gradients at the start of the training pass", "\n", "\n", "        ", "for", "optim", "in", "self", ".", "optim", ":", "\n", "            ", "optim", ".", "zero_grad", "(", ")", "\n", "\n", "# Run the train function", "\n", "", "loss", "=", "self", ".", "model", ".", "train_batch", "(", "batch", ")", "\n", "\n", "# Clip gradient norms", "\n", "gradients", "=", "[", "]", "\n", "for", "parameters", "in", "self", ".", "model", ".", "parameter_list", ":", "\n", "           ", "clipped_gradient", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "parameters", ",", "self", ".", "clip", ")", "\n", "gradients", ".", "append", "(", "clipped_gradient", ")", "\n", "\n", "# Update parameters with optimizers", "\n", "", "for", "optim", "in", "self", ".", "optim", ":", "\n", "            ", "optim", ".", "step", "(", ")", "\n", "\n", "", "return", "loss", ",", "gradients", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler._get_loss": [[119, 129], ["nli_random_batches", "len", "range", "nli_training_handler.TrainingHandler.model.validate"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.None.preprocess.nli_random_batches", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.validate"], ["", "def", "_get_loss", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "loss_total", "=", "0.0", "\n", "batch_size", "=", "32", "\n", "batches", "=", "nli_random_batches", "(", "batch_size", ",", "dataset", ")", "\n", "n_batches", "=", "len", "(", "batches", ")", "\n", "for", "i", "in", "range", "(", "n_batches", ")", ":", "\n", "            ", "loss", "=", "self", ".", "model", ".", "validate", "(", "batches", "[", "i", "]", ")", "\n", "loss_total", "+=", "loss", "\n", "", "loss_avg", "=", "loss_total", "/", "n_batches", "\n", "return", "loss_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler._get_val_loss": [[130, 137], ["nli_training_handler.TrainingHandler._get_loss"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler._get_loss"], ["", "def", "_get_val_loss", "(", "self", ")", ":", "\n", "        ", "val_loss_dict", "=", "{", "}", "\n", "for", "val_name", "in", "self", ".", "val_set_dict", ":", "\n", "            ", "val_set", "=", "self", ".", "val_set_dict", "[", "val_name", "]", "\n", "val_loss_dict", "[", "val_name", "]", "=", "self", ".", "_get_loss", "(", "val_set", ")", "\n", "\n", "", "return", "val_loss_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler._print_log": [[138, 144], ["save_logs", "print", "enumerate", "save_logs", "print"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.None.utils.save_logs", "home.repos.pwc.inspect_result.nabihach_IDA.None.utils.save_logs"], ["", "def", "_print_log", "(", "self", ",", "print_summary", ")", ":", "\n", "        ", "save_logs", "(", "print_summary", ",", "self", ".", "save_dir", ")", "\n", "print", "(", "print_summary", ")", "\n", "for", "i", ",", "p", "in", "enumerate", "(", "self", ".", "optim", "[", "1", "]", ".", "param_groups", ")", ":", "\n", "            ", "save_logs", "(", "p", "[", "'lr'", "]", ",", "self", ".", "save_dir", ")", "\n", "print", "(", "'LR: '", ",", "p", "[", "'lr'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler._save_checkpoint": [[145, 165], ["print", "save_scores", "nli_training_handler.TrainingHandler.model.export_state", "nli_training_handler.TrainingHandler.model.score", "nli_training_handler.TrainingHandler._save_losses", "nli_training_handler.TrainingHandler._plot_losses().savefig", "nli_training_handler.TrainingHandler._plot_losses"], "methods", ["home.repos.pwc.inspect_result.nabihach_IDA.None.utils.save_scores", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.export_state", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.score", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler._save_losses", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler._plot_losses"], ["", "", "def", "_save_checkpoint", "(", "self", ",", "save_dir", ",", "name", ",", "save_loss", "=", "False", ")", ":", "\n", "        ", "accuracy", "=", "{", "}", "\n", "\n", "for", "val_name", "in", "self", ".", "val_set_dict", ":", "\n", "            ", "val_set", "=", "self", ".", "val_set_dict", "[", "val_name", "]", "\n", "accuracy", "[", "val_name", "]", "=", "self", ".", "model", ".", "score", "(", "val_set", ")", "\n", "\n", "", "print", "(", "\"Accuracy:\"", ",", "accuracy", ")", "\n", "save_scores", "(", "accuracy", ",", "save_dir", ")", "\n", "\n", "if", "save_loss", "==", "True", ":", "\n", "            ", "fig_out", "=", "save_dir", "+", "FIG_FILE", "\n", "df_out", "=", "save_dir", "+", "LOSS_FILE", "\n", "\n", "self", ".", "_save_losses", "(", "df_out", ")", "\n", "if", "not", "USE_CUDA", ":", "\n", "                ", "(", "self", ".", "_plot_losses", "(", "df_out", ")", ")", ".", "savefig", "(", "fig_out", ")", "\n", "\n", "# Save model checkpoint", "\n", "", "", "self", ".", "model", ".", "export_state", "(", "save_dir", ",", "name", ",", "epoch", "=", "self", ".", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler._plot_losses": [[166, 184], ["matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.legend", "matplotlib.xlabel", "matplotlib.ylabel", "open", "csv.reader", "train_losses.append", "val_losses.append", "float", "float"], "methods", ["None"], ["", "def", "_plot_losses", "(", "self", ",", "path", ")", ":", "\n", "        ", "train_losses", "=", "[", "]", "\n", "val_losses", "=", "[", "]", "\n", "\n", "#read the loss file", "\n", "with", "open", "(", "path", ",", "'rt'", ")", "as", "loss_file", ":", "\n", "            ", "loss_rows", "=", "csv", ".", "reader", "(", "loss_file", ",", "delimiter", "=", "','", ")", "\n", "for", "row", "in", "loss_rows", ":", "\n", "                ", "train_losses", ".", "append", "(", "float", "(", "row", "[", "0", "]", ")", ")", "\n", "val_losses", ".", "append", "(", "float", "(", "row", "[", "1", "]", ")", ")", "\n", "\n", "", "", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "plot", "(", "train_losses", ",", "color", "=", "'red'", ",", "label", "=", "'Train_loss'", ",", "marker", "=", "'o'", ")", "\n", "plt", ".", "plot", "(", "val_losses", ",", "color", "=", "'blue'", ",", "label", "=", "'Val_loss'", ",", "marker", "=", "'o'", ")", "\n", "plt", ".", "legend", "(", "loc", "=", "'upper right'", ",", "frameon", "=", "False", ")", "\n", "plt", ".", "xlabel", "(", "'Epochs'", ")", "\n", "plt", ".", "ylabel", "(", "'Cross-Entropy Loss'", ")", "\n", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_training_handler.TrainingHandler._save_losses": [[185, 190], ["open", "range", "open.close", "len", "open.write", "str", "str"], "methods", ["None"], ["", "def", "_save_losses", "(", "self", ",", "path", ")", ":", "\n", "        ", "outfile", "=", "open", "(", "path", ",", "'a'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "train_losses", ")", ")", ":", "\n", "            ", "outfile", ".", "write", "(", "str", "(", "self", ".", "train_losses", "[", "i", "]", ")", "+", "','", "+", "str", "(", "self", ".", "val_losses", "[", "i", "]", ")", "+", "\"\\n\"", ")", "\n", "", "outfile", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.nabihach_IDA.nli.test_nli.load_model": [[5, 20], ["nli_model.BiLSTMModel().import_state", "nli_preprocessor.genre_test_set", "nli_preprocessor.tokenize_sentences", "nli_preprocessor.tokenize_sentences", "print", "os.path.dirname", "model.score", "nli_model.BiLSTMModel"], "function", ["home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.import_state", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.genre_test_set", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.tokenize_sentences", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_preprocessor.tokenize_sentences", "home.repos.pwc.inspect_result.nabihach_IDA.nli.nli_model.BiLSTMModel.score"], ["def", "load_model", "(", "file_name", ",", "test_genre", ")", ":", "\n", "    ", "model_path", "=", "MODEL_DIR", "+", "file_name", "\n", "model", ",", "initial_epoch", "=", "BiLSTMModel", "(", ")", ".", "import_state", "(", "model_path", ",", "load_epoch", "=", "True", ")", "\n", "model_dir", "=", "os", ".", "path", ".", "dirname", "(", "model_path", ")", "+", "\"/\"", "\n", "\n", "test_set", "=", "nli_preprocessor", ".", "genre_test_set", "(", "test_genre", ")", "\n", "#test_set = nli_preprocessor.dev_matched_text_hyp_labels(genre=test_genre)", "\n", "#test_set = nli_preprocessor.get_multinli_matched_val_set()", "\n", "#test_set = nli_preprocessor.dev_mismatched_text_hyp_labels(genre=test_genre)", "\n", "#test_set = nli_preprocessor.get_multinli_mismatched_val_set()", "\n", "#test_set = nli_preprocessor.get_multinli_text_hyp_labels(genre=test_genre)", "\n", "# Tokenize sentences", "\n", "test_set", "[", "\"text\"", "]", "=", "nli_preprocessor", ".", "tokenize_sentences", "(", "test_set", "[", "\"text\"", "]", ",", "model", ".", "wd", ")", "\n", "test_set", "[", "\"hyp\"", "]", "=", "nli_preprocessor", ".", "tokenize_sentences", "(", "test_set", "[", "\"hyp\"", "]", ",", "model", ".", "wd", ")", "\n", "print", "(", "model", ".", "score", "(", "test_set", ")", ")", "\n", "\n"]]}