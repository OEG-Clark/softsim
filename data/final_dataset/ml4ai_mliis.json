{"home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.parse_args": [[31, 78], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns an argument parser object for image segmentation training script.\n    \"\"\"", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Train segmentation model via SGD.\"", ")", "\n", "\n", "# Data", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "help", "=", "\"Path to folder containing tfrecords\"", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--fp_k_test_set\"", ",", "help", "=", "\"Hold out the test task for the fp-k classes.\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_on_val_set\"", ",", "help", "=", "\"If speced, will train on train shards and test on val shards, else will train on both train and val and test on test.\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "# Model", "\n", "parser", ".", "add_argument", "(", "'--model_name'", ",", "\n", "help", "=", "\"Name of the model architecture to meta-train. Must be in the set: {}.\"", ".", "format", "(", "SUPPORTED_MODELS", ")", ",", "required", "=", "False", ",", "\n", "default", "=", "'EfficientLab'", ")", "\n", "parser", ".", "add_argument", "(", "\"--rsd\"", ",", "help", "=", "\"List of integers specifying the 1-indexed reduction endpionts from EfficientNet to input into the lightweight skip decoding layers of EfficientLab.\"", ",", "type", "=", "int", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--feature_extractor_name\"", ",", "help", "=", "\"efficientnet-b0 or efficientnet-b3\"", ",", "type", "=", "str", ",", "default", "=", "\"efficientnet-b0\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--image_size\"", ",", "help", "=", "\"size of image in pixels. images assumed to square\"", ",", "type", "=", "int", ",", "default", "=", "224", ")", "\n", "parser", ".", "add_argument", "(", "\"--seperate_background_channel\"", ",", "help", "=", "\"Whether or not to make a mutually exclusive background channel.\"", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "\n", "# Training", "\n", "parser", ".", "add_argument", "(", "\"--restore_efficient_net_weights_from\"", ",", "help", "=", "\"path to dir to restore efficientnet weights from\"", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--sgd'", ",", "help", "=", "'use vanilla SGD instead of Adam'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--loss_name'", ",", "help", "=", "'Name of the loss function to use. Should be cross_entropy, cross_entropy_dice, or ce_dice'", ",", "default", "=", "'ce_dice'", ")", "\n", "parser", ".", "add_argument", "(", "\"--l2\"", ",", "help", "=", "\"Applies l2 weight decay to all weights in network\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--augment\"", ",", "help", "=", "\"Apply augmentations to training data\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--final_layer_dropout_rate\"", ",", "help", "=", "\"Probability to dropout inputs at final layer.\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "help", "=", "'Training batch size'", ",", "default", "=", "64", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "help", "=", "'Number of training epochs'", ",", "default", "=", "200", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--steps_per_epoch\"", ",", "help", "=", "\"Number of gradient steps to take per epoch. If unspecified will be determined from batch size and number of examples.\"", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "0.005", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--final_learning_rate\"", ",", "default", "=", "5e-7", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--label_smoothing\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ")", "\n", "\n", "\n", "# Evaluation", "\n", "parser", ".", "add_argument", "(", "\"--val_batches\"", ",", "default", "=", "20", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained'", ",", "help", "=", "'Evaluate a pre-trained model.'", ",", "\n", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_interval'", ",", "help", "=", "'Training steps per evaluation'", ",", "default", "=", "2", ",", "type", "=", "int", ")", "\n", "\n", "# Misc. config", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "help", "=", "'random seed'", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "help", "=", "'Checkpoint directory to write to (or restore from).'", ",", "default", "=", "'/tmp/model_checkpoint'", ",", "type", "=", "str", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.get_model_kwargs": [[81, 108], ["parsed_args.model_name.lower", "ValueError", "functools.partial"], "function", ["None"], ["", "def", "get_model_kwargs", "(", "parsed_args", ")", ":", "\n", "    ", "\"\"\"\n    Build the kwargs for model constructors from the\n    parsed command-line arguments.\n    \"\"\"", "\n", "parsed_args", ".", "model_name", "=", "parsed_args", ".", "model_name", ".", "lower", "(", ")", "\n", "if", "parsed_args", ".", "model_name", "not", "in", "SUPPORTED_MODELS", ":", "\n", "        ", "raise", "ValueError", "(", "\"Model name must be in the set: {}\"", ".", "format", "(", "SUPPORTED_MODELS", ")", ")", "\n", "", "res", "=", "{", "'learning_rate'", ":", "parsed_args", ".", "learning_rate", "}", "\n", "restore_ckpt_dir", "=", "parsed_args", ".", "restore_efficient_net_weights_from", "\n", "res", "[", "\"restore_ckpt_dir\"", "]", "=", "restore_ckpt_dir", "\n", "if", "parsed_args", ".", "lsd", ":", "\n", "        ", "res", "[", "\"rsd\"", "]", "=", "parsed_args", ".", "lsd", "\n", "", "res", "[", "\"feature_extractor_name\"", "]", "=", "parsed_args", ".", "feature_extractor_name", "\n", "res", "[", "\"l2\"", "]", "=", "parsed_args", ".", "l2", "\n", "res", "[", "\"final_layer_dropout_rate\"", "]", "=", "parsed_args", ".", "final_layer_dropout_rate", "\n", "res", "[", "\"label_smoothing\"", "]", "=", "parsed_args", ".", "label_smoothing", "\n", "if", "\"dice\"", "not", "in", "parsed_args", ".", "loss_name", ":", "\n", "        ", "res", "[", "\"dice\"", "]", "=", "False", "\n", "", "if", "parsed_args", ".", "sgd", ":", "\n", "        ", "res", "[", "'optimizer'", "]", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "\n", "", "else", ":", "\n", "        ", "res", "[", "'optimizer'", "]", "=", "partial", "(", "tf", ".", "train", ".", "AdamOptimizer", ",", "beta1", "=", "0", ")", "\n", "", "res", "[", "'loss_name'", "]", "=", "parsed_args", ".", "loss_name", "\n", "res", "[", "\"n_rows\"", "]", "=", "parsed_args", ".", "image_size", "\n", "res", "[", "\"n_cols\"", "]", "=", "parsed_args", ".", "image_size", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.after_step": [[110, 113], ["None"], "function", ["None"], ["", "def", "after_step", "(", ")", ":", "\n", "    ", "\"\"\"Function to be called after a step of gradient descent\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.after_epoch": [[115, 118], ["None"], "function", ["None"], ["", "def", "after_epoch", "(", ")", ":", "\n", "    ", "\"\"\"Function to be called after an epoch\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.get_train_test_shards_from_dir": [[120, 135], ["os.listdir", "len", "len", "len", "len", "set().intersection", "os.path.join", "os.path.join", "set", "len", "len", "set", "set", "set"], "function", ["None"], ["", "def", "get_train_test_shards_from_dir", "(", "data_dir", ",", "ext", ":", "str", "=", "\".tfrecord.gzip\"", ",", "test_on_val_set", ":", "bool", "=", "False", ")", ":", "\n", "    ", "all_shards", "=", "os", ".", "listdir", "(", "data_dir", ")", "\n", "all_shards", "=", "[", "x", "for", "x", "in", "all_shards", "if", "ext", "in", "x", "]", "\n", "train_shards", "=", "[", "x", "for", "x", "in", "all_shards", "if", "TEST_ID", "not", "in", "x", "]", "\n", "test_shards", "=", "[", "x", "for", "x", "in", "all_shards", "if", "TRAIN_ID", "not", "in", "x", "]", "\n", "\n", "if", "test_on_val_set", ":", "\n", "        ", "train_shards", "=", "[", "x", "for", "x", "in", "train_shards", "if", "VAL_ID", "not", "in", "x", "]", "\n", "test_shards", "=", "[", "x", "for", "x", "in", "all_shards", "if", "VAL_ID", "in", "x", "]", "\n", "assert", "len", "(", "set", "(", "train_shards", "+", "test_shards", ")", ")", "==", "len", "(", "all_shards", ")", "-", "len", "(", "[", "x", "for", "x", "in", "all_shards", "if", "TEST_ID", "in", "x", "]", ")", "\n", "", "else", ":", "\n", "        ", "assert", "len", "(", "set", "(", "train_shards", "+", "test_shards", ")", ")", "==", "len", "(", "all_shards", ")", "\n", "\n", "", "assert", "len", "(", "set", "(", "test_shards", ")", ".", "intersection", "(", "set", "(", "train_shards", ")", ")", ")", "==", "0", "\n", "return", "[", "os", ".", "path", ".", "join", "(", "data_dir", ",", "x", ")", "for", "x", "in", "train_shards", "]", ",", "[", "os", ".", "path", ".", "join", "(", "data_dir", ",", "x", ")", "for", "x", "in", "test_shards", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.get_training_data": [[137, 152], ["joint_train.get_train_test_shards_from_dir", "joint_train.data.input_fn.TFRecordSegmentationDataset", "joint_train.data.input_fn.TFRecordSegmentationDataset.make_dataset", "augmenters.np_augmenters.Augmenter", "functools.partial", "functools.partial"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.get_train_test_shards_from_dir", "home.repos.pwc.inspect_result.ml4ai_mliis.data.input_fn.make_dataset"], ["", "def", "get_training_data", "(", "data_dir", ":", "str", ",", "num_classes", ":", "int", ",", "batch_size", ":", "int", ",", "image_size", ":", "int", ",", "ext", ":", "str", "=", "\".tfrecord.gzip\"", ",", "augment", ":", "bool", "=", "False", ",", "seperate_background_channel", ":", "bool", "=", "True", ",", "test_on_val_set", ":", "bool", "=", "False", ")", "->", "Tuple", "[", "tf", ".", "Tensor", ",", "tf", ".", "Tensor", ",", "tf", ".", "Operation", "]", ":", "\n", "    ", "train_shards", ",", "test_shards", "=", "get_train_test_shards_from_dir", "(", "data_dir", ",", "ext", ",", "test_on_val_set", "=", "test_on_val_set", ")", "\n", "\n", "if", "augment", ":", "\n", "        ", "if", "seperate_background_channel", ":", "\n", "            ", "mask_filled_translate", "=", "partial", "(", "translate", ",", "mask_fill", "=", "[", "1", "]", "+", "[", "0", "]", "*", "num_classes", ")", "\n", "", "else", ":", "\n", "            ", "mask_filled_translate", "=", "partial", "(", "translate", ",", "mask_fill", "=", "[", "0", "]", "*", "num_classes", ")", "\n", "\n", "", "augmenter", "=", "Augmenter", "(", "aug_funcs", "=", "[", "mask_filled_translate", ",", "fliplr", ",", "additive_gaussian_noise", ",", "exposure", "]", ")", "\n", "", "else", ":", "\n", "        ", "augmenter", "=", "None", "\n", "", "dataset", "=", "TFRecordSegmentationDataset", "(", "tfrecord_paths", "=", "train_shards", ",", "image_width", "=", "image_size", ",", "mask_channels", "=", "num_classes", ",", "augmenter", "=", "augmenter", ",", "seperate_background_channel", "=", "seperate_background_channel", ")", "\n", "dataset", ",", "ds_init_op", "=", "dataset", ".", "make_dataset", "(", "batch_size", ")", "\n", "return", "dataset", ",", "ds_init_op", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.train": [[154, 246], ["isinstance", "isinstance", "print", "tensorflow.train.Saver", "print", "sess.run", "print", "tf.train.Saver.save", "tensorflow.summary.FileWriter", "range", "print", "print", "print", "os.path.exists", "os.mkdir", "print", "model.restore_model", "os.path.join", "os.path.join", "tensorflow.RunOptions", "time.time", "print", "joint_train.main.lr_fn", "print", "range", "print", "utils.util.log_estimated_time_remaining", "print", "print", "tensorflow.global_variables_initializer().run", "sess.run", "print", "print", "tensorflow.global_variables_initializer().run", "sess.run", "print", "joint_train.iou_callback", "print", "print", "print", "ious.append", "print", "tf.train.Saver.save", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "sess.run", "os.path.join", "time.time", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "sess.run"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.mkdir", "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.restore_model", "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.log_estimated_time_remaining", "home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.iou_callback"], ["", "def", "train", "(", "sess", ":", "tf", ".", "Session", ",", "model", ":", "EfficientLab", ",", "dataset_init_op", ":", "tf", ".", "Operation", ",", "epochs", ":", "int", ",", "steps_per_epoch", ":", "int", ",", "images", ",", "masks", ",", "save_dir", ":", "str", ",", "lr_fn", ":", "Callable", ",", "restore_ckpt_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "val_batches", ":", "int", "=", "20", ",", "save_checkpoint_every_n_epochs", ":", "int", "=", "2", ",", "time_deadline", "=", "None", ",", "max_checkpoints_to_keep", ":", "int", "=", "2", ",", "eval_interval", ":", "int", "=", "2", ",", "report_allocated_tensors_on_oom", ":", "bool", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n\n    Args:\n        sess:\n        model:\n        dataset_init_op:\n        epochs:\n        steps_per_epoch:\n        images:\n        masks:\n        save_dir:\n        lr_fn: A function that takes in the epoch number and returns the learning rate. For constant, learning rate, define a lambda: lr_fn = lambda i: lr\n        val_batches: Number of batches to evaluate at the end of each epoch\n        save_checkpoint_every_n_epochs:\n        time_deadline:\n        max_checkpoints_to_keep:\n\n    Returns:\n\n    \"\"\"", "\n", "assert", "isinstance", "(", "epochs", ",", "int", ")", "\n", "assert", "isinstance", "(", "steps_per_epoch", ",", "int", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "save_dir", ")", "\n", "", "print", "(", "\"Logging to {}\"", ".", "format", "(", "save_dir", ")", ")", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "max_checkpoints_to_keep", ")", "\n", "\n", "if", "restore_ckpt_dir", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"Restoring from checkpoint {}\"", ".", "format", "(", "restore_ckpt_dir", ")", ")", "\n", "model", ".", "restore_model", "(", "sess", ",", "restore_ckpt_dir", ",", "filter_to_scopes", "=", "[", "model", ".", "feature_extractor_name", "]", ")", "\n", "\n", "", "try", ":", "\n", "        ", "if", "not", "model", ".", "variables_initialized", ":", "\n", "            ", "print", "(", "\"Initializing variables.\"", ")", "\n", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "", "", "except", "AttributeError", ":", "\n", "        ", "print", "(", "\"Model does not explicitly track whether variable initialization has already been run on the graph at attribute .variables_initialized.\"", ")", "\n", "print", "(", "\"Initializing variables.\"", ")", "\n", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "", "print", "(", "\"Training...\"", ")", "\n", "sess", ".", "run", "(", "dataset_init_op", ")", "\n", "\n", "print", "(", "\"Saving graph definition to {}.\"", ".", "format", "(", "save_dir", ")", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'model.ckpt'", ")", ",", "global_step", "=", "0", ")", "\n", "tf", ".", "summary", ".", "FileWriter", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'train'", ")", ",", "sess", ".", "graph", ")", "\n", "\n", "if", "report_allocated_tensors_on_oom", ":", "\n", "        ", "run_opts", "=", "tf", ".", "RunOptions", "(", "report_tensor_allocations_upon_oom", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "run_opts", "=", "None", "\n", "\n", "", "ious", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "epochs", ")", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'Epoch: '", ",", "i", ")", "\n", "lr", "=", "lr_fn", "(", "i", ")", "\n", "print", "(", "\"lr: \"", ",", "lr", ")", "\n", "for", "_", "in", "range", "(", "steps_per_epoch", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "_", "=", "sess", ".", "run", "(", "model", ".", "minimize_op", ",", "feed_dict", "=", "{", "model", ".", "lr_ph", ":", "lr", "}", ",", "options", "=", "run_opts", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "sess", ".", "run", "(", "dataset_init_op", ",", "options", "=", "run_opts", ")", "\n", "", "", "print", "(", "\"Finished epoch {} with {} steps.\"", ".", "format", "(", "i", ",", "steps_per_epoch", ")", ")", "\n", "epoch_minutes", "=", "log_estimated_time_remaining", "(", "start_time", ",", "i", ",", "epochs", ",", "unit_name", "=", "\"epoch\"", ")", "\n", "iters_per_sec", "=", "steps_per_epoch", "/", "(", "epoch_minutes", "*", "60", ")", "\n", "print", "(", "\"Iterations per second: {}\"", ".", "format", "(", "iters_per_sec", ")", ")", "\n", "\n", "if", "i", "%", "eval_interval", "==", "0", ":", "\n", "# TODO implement val set accuracy callback", "\n", "            ", "print", "(", "\"Validating\"", ")", "\n", "iou", ",", "loss", "=", "iou_callback", "(", "sess", ",", "model", ",", "val_batches", ",", "run_opts", ")", "\n", "print", "(", "\"Loss: {}\"", ".", "format", "(", "loss", ")", ")", "\n", "print", "(", "\"IoU on epoch {} estimated on {} batches:\"", ".", "format", "(", "i", ",", "val_batches", ")", ")", "\n", "print", "(", "iou", ")", "\n", "ious", ".", "append", "(", "iou", ")", "\n", "\n", "", "if", "i", "%", "save_checkpoint_every_n_epochs", "==", "0", "or", "i", "==", "epochs", "-", "1", ":", "\n", "            ", "print", "(", "\"Saving checkpoint to {}.\"", ".", "format", "(", "save_dir", ")", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'model.ckpt'", ")", ",", "global_step", "=", "i", ")", "\n", "\n", "", "if", "time_deadline", "is", "not", "None", "and", "time", ".", "time", "(", ")", ">", "time_deadline", ":", "\n", "            ", "break", "\n", "\n", "", "", "print", "(", "\"Training complete. History:\"", ")", "\n", "print", "(", "\"Train set Intersection over Union (IoU):\"", ")", "\n", "print", "(", "ious", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.iou_callback": [[248, 259], ["range", "numpy.nanmean", "numpy.nanmean", "sess.run", "ious.append", "losses.append", "joint_train.compute_iou_metric"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.compute_iou_metric"], ["", "def", "iou_callback", "(", "sess", ",", "model", ":", "EfficientLab", ",", "val_batches", ",", "run_opts", ")", ":", "\n", "    ", "ious", "=", "[", "]", "\n", "losses", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "val_batches", ")", ":", "\n", "        ", "images", ",", "preds", ",", "labels", ",", "loss", "=", "sess", ".", "run", "(", "[", "model", ".", "input_ph", ",", "model", ".", "predictions", ",", "model", ".", "label_ph", ",", "model", ".", "loss", "]", ",", "options", "=", "run_opts", ",", "feed_dict", "=", "{", "model", ".", "is_training_ph", ":", "False", "}", ")", "\n", "# viz(images, preds, labels)", "\n", "ious", ".", "append", "(", "compute_iou_metric", "(", "preds", ",", "labels", ")", ")", "\n", "losses", ".", "append", "(", "loss", ")", "\n", "", "iou", "=", "np", ".", "nanmean", "(", "ious", ")", "\n", "loss", "=", "np", ".", "nanmean", "(", "losses", ")", "\n", "return", "iou", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.compute_iou_metric": [[261, 268], ["numpy.nanmean", "len", "len", "len", "meta_learners.supervised_reptile.supervised_reptile.reptile.Gecko._iou", "range"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko._iou"], ["", "def", "compute_iou_metric", "(", "predictions", ":", "np", ".", "ndarray", ",", "labels", ":", "np", ".", "ndarray", ")", ":", "\n", "    ", "assert", "len", "(", "predictions", ")", "==", "len", "(", "labels", ")", "\n", "assert", "len", "(", "predictions", ".", "shape", ")", "==", "4", "\n", "# Pass prediction and label arrays to _iou:", "\n", "iou", "=", "[", "Gecko", ".", "_iou", "(", "predictions", "[", "i", "]", ",", "labels", "[", "i", "]", ",", "class_of_interest_channel", "=", "None", ")", "for", "i", "in", "range", "(", "predictions", ".", "shape", "[", "0", "]", ")", "]", "\n", "iou", "=", "np", ".", "nanmean", "(", "iou", ")", "\n", "return", "iou", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.viz": [[270, 293], ["len", "range", "plt.figure", "plt.imshow", "plt.show", "plot_mask", "print", "plt.figure", "plt.imshow", "plt.show", "print", "plot_mask", "print", "plot_mask"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.utils.debug_tf_dataset.plot_mask", "home.repos.pwc.inspect_result.ml4ai_mliis.utils.debug_tf_dataset.plot_mask", "home.repos.pwc.inspect_result.ml4ai_mliis.utils.debug_tf_dataset.plot_mask"], ["", "def", "viz", "(", "images", ",", "preds", ",", "labels", ")", ":", "\n", "    ", "from", "utils", ".", "debug_tf_dataset", "import", "plot_mask", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "\n", "images", "=", "images", "/", "255.", "\n", "\n", "if", "len", "(", "images", ".", "shape", ")", "==", "4", ":", "\n", "        ", "for", "j", "in", "range", "(", "images", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "print", "(", "\"image\"", ")", "\n", "plt", ".", "figure", "(", "j", ")", "\n", "plt", ".", "imshow", "(", "images", "[", "j", "]", ")", "\n", "plt", ".", "show", "(", ")", "\n", "print", "(", "\"label mask\"", ")", "\n", "mask_j", "=", "labels", "[", "j", "]", "\n", "k", "=", "plot_mask", "(", "mask_j", ",", "j", "+", "1", ")", "\n", "print", "(", "\"predicted mask\"", ")", "\n", "pred", "=", "preds", "[", "j", "]", "\n", "plot_mask", "(", "pred", ",", "j", "+", "2", ",", "channel_index", "=", "k", ")", "\n", "", "", "else", ":", "\n", "        ", "plt", ".", "figure", "(", "0", ")", "\n", "plt", ".", "imshow", "(", "images", ")", "\n", "plt", ".", "show", "(", ")", "\n", "plot_mask", "(", "labels", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.main": [[295, 344], ["time.time", "joint_train.parse_args", "sorted", "len", "joint_train.get_training_data", "joint_train.get_model_kwargs", "models.efficientlab.EfficientLab", "print", "time.time", "print", "list", "len", "len", "len", "int", "tensorflow.Session", "joint_train.train", "set().intersection", "set", "set", "set"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.parse_args", "home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.get_training_data", "home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.get_model_kwargs", "home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.train"], ["", "", "def", "main", "(", ")", ":", "\n", "# Reference: https://github.com/SMHendryx/tf-segmentation-trainer/blob/master/train.py", "\n", "    ", "start", "=", "time", ".", "time", "(", ")", "\n", "# Args:", "\n", "args", "=", "parse_args", "(", ")", "\n", "data_dir", "=", "args", ".", "data_dir", "\n", "learning_rate", "=", "args", ".", "learning_rate", "\n", "final_learning_rate", "=", "args", ".", "final_learning_rate", "\n", "epochs", "=", "args", ".", "epochs", "\n", "\n", "#all_classes, train_classes = get_classes_from_dir(data_dir, ext=\".tfrecord.gzip\")", "\n", "\n", "train_classes", ",", "test_classes", "=", "TRAIN_TASK_IDS", ",", "TEST_TASK_IDS", "\n", "\n", "all_classes", "=", "sorted", "(", "list", "(", "train_classes", "+", "test_classes", ")", ")", "\n", "\n", "if", "args", ".", "fp_k_test_set", ":", "\n", "        ", "test_classes", "=", "FP_K_TEST_TASK_IDS", "\n", "train_classes", "=", "[", "x", "for", "x", "in", "all_classes", "if", "x", "not", "in", "test_classes", "]", "\n", "\n", "", "assert", "len", "(", "set", "(", "test_classes", ")", ".", "intersection", "(", "set", "(", "train_classes", ")", ")", ")", "==", "0", ",", "\"train-test class names overlap\"", "\n", "assert", "len", "(", "train_classes", "+", "test_classes", ")", "==", "len", "(", "set", "(", "all_classes", ")", ")", "\n", "\n", "num_classes", "=", "len", "(", "all_classes", ")", "\n", "next_element", ",", "dataset_init_op", "=", "get_training_data", "(", "data_dir", ",", "num_classes", "=", "num_classes", ",", "batch_size", "=", "args", ".", "batch_size", ",", "image_size", "=", "args", ".", "image_size", ",", "augment", "=", "args", ".", "augment", ",", "seperate_background_channel", "=", "args", ".", "seperate_background_channel", ",", "test_on_val_set", "=", "args", ".", "test_on_val_set", ")", "\n", "images", "=", "next_element", "[", "0", "]", "\n", "masks", "=", "next_element", "[", "1", "]", "\n", "\n", "model_kwargs", "=", "get_model_kwargs", "(", "args", ")", "\n", "restore_ckpt_dir", "=", "model_kwargs", "[", "\"restore_ckpt_dir\"", "]", "\n", "model", "=", "EfficientLab", "(", "images", "=", "images", ",", "labels", "=", "masks", ",", "n_classes", "=", "num_classes", ",", "seperate_background_channel", "=", "args", ".", "seperate_background_channel", ",", "binary_iou_loss", "=", "False", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "args", ".", "steps_per_epoch", "is", "None", ":", "\n", "        ", "steps_per_epoch", "=", "int", "(", "760", "*", "10", "//", "args", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "        ", "steps_per_epoch", "=", "args", ".", "steps_per_epoch", "\n", "\n", "", "def", "lr_fn", "(", "i", ",", "epochs", "=", "epochs", ",", "initial_lr", "=", "learning_rate", ",", "final_lr", "=", "final_learning_rate", ")", ":", "\n", "        ", "frac_done", "=", "i", "/", "epochs", "\n", "cur_lr", "=", "frac_done", "*", "final_lr", "+", "(", "1", "-", "frac_done", ")", "*", "initial_lr", "\n", "return", "cur_lr", "\n", "\n", "", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "train", "(", "sess", ",", "model", ",", "dataset_init_op", ",", "args", ".", "epochs", ",", "steps_per_epoch", "=", "steps_per_epoch", ",", "save_dir", "=", "args", ".", "checkpoint", ",", "\n", "lr_fn", "=", "lr_fn", ",", "val_batches", "=", "args", ".", "val_batches", ",", "images", "=", "images", ",", "masks", "=", "masks", ",", "eval_interval", "=", "args", ".", "eval_interval", ",", "restore_ckpt_dir", "=", "restore_ckpt_dir", ")", "\n", "\n", "", "print", "(", "\"Finished training\"", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Experiment took {} hours\"", ".", "format", "(", "(", "end", "-", "start", ")", "/", "3600.", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.None.run_metasegnet.main": [[28, 211], ["logger.info", "datetime.datetime.now", "print", "meta_learners.args.argument_parser().parse_args", "random.seed", "print", "print", "argument_parser().parse_args.model_name.lower", "print", "print", "print", "print", "utils.util.validate_datasets", "datetime.datetime.now", "print", "meta_learners.args.model_kwargs", "models.efficientlab.EfficientLab", "ValueError", "print", "print", "meta_learners.metaseg.read_fp_k_shot_dataset", "print", "tensorflow.Session", "meta_learners.args.evaluate_kwargs", "meta_learners.args.argument_parser", "meta_learners.args.model_kwargs", "meta_learners.args.train_kwargs", "numpy.sum", "print", "meta_learners.metaseg.read_fss_1000_dataset", "meta_learners.metaseg.read_fss_1000_dataset", "print", "print", "print", "train_fn", "print", "meta_learners.supervised_reptile.supervised_reptile.eval.optimize_update_hyperparams", "copy.deepcopy", "meta_learners.supervised_reptile.supervised_reptile.eval.run_k_shot_learning_curves_experiment", "print", "print", "evaluate_fn", "print", "print", "print", "os.path.join", "print", "meta_learners.args.model_kwargs", "len", "len", "len", "print", "print", "models.efficientlab.EfficientLab.restore_model", "utils.util.latest_checkpoint", "print", "tensorflow.train.Saver().restore", "print", "models.efficientlab.EfficientLab.restore_model", "utils.util.latest_checkpoint", "print", "tensorflow.train.Saver().restore", "len", "print", "meta_learners.args.train_kwargs", "train_fn", "evaluate_fn", "print", "open", "json.dump", "numpy.prod", "len", "meta_learners.args.train_kwargs", "meta_learners.args.hyper_search_kwargs", "os.path.join", "v.get_shape().as_list", "tensorflow.trainable_variables", "tensorflow.train.Saver", "tensorflow.train.Saver", "v.get_shape"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.None.joint_train.parse_args", "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.validate_datasets", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.model_kwargs", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg.read_fp_k_shot_dataset", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.evaluate_kwargs", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.argument_parser", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.model_kwargs", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.train_kwargs", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg.read_fss_1000_dataset", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg.read_fss_1000_dataset", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.eval.optimize_update_hyperparams", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.eval.run_k_shot_learning_curves_experiment", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.model_kwargs", "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.restore_model", "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.latest_checkpoint", "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.restore_model", "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.latest_checkpoint", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.train_kwargs", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.train_kwargs", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.hyper_search_kwargs"], ["def", "main", "(", ")", ":", "\n", "    ", "\"\"\"\n    Load data and train an image segmentation model on it.\n    \"\"\"", "\n", "verbose", "=", "True", "\n", "eval_train_tasks", "=", "True", "\n", "logger", ".", "info", "(", "\"Running image segmentation meta-learning...\"", ")", "\n", "start_time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "print", "(", "\"Experiment started at: {}\"", ".", "format", "(", "start_time", ")", ")", "\n", "\n", "args", "=", "argument_parser", "(", ")", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "optimize_update_hyperparms_on_val_set", ":", "\n", "        ", "assert", "args", ".", "num_val_tasks", ">", "0", ",", "\"Must specify number of validation tasks greater than 0 to optimize update hyperparams.\"", "\n", "\n", "", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "global", "DATA_DIR", "\n", "DATA_DIR", "=", "args", ".", "data_dir", "\n", "\n", "print", "(", "'Defining model architecture:'", ")", "\n", "loss_name", "=", "model_kwargs", "(", "args", ")", "[", "'loss_name'", "]", "\n", "print", "(", "'Using loss {}'", ".", "format", "(", "loss_name", ")", ")", "\n", "args", ".", "model_name", "=", "args", ".", "model_name", ".", "lower", "(", ")", "\n", "lr_scheduler", "=", "None", "\n", "if", "args", ".", "model_name", "==", "\"efficientlab\"", ":", "\n", "        ", "restore_ckpt_dir", "=", "model_kwargs", "(", "args", ")", "[", "\"restore_ckpt_dir\"", "]", "\n", "model", "=", "EfficientLab", "(", "**", "model_kwargs", "(", "args", ")", ")", "\n", "initial_lr", "=", "args", ".", "learning_rate", "\n", "total_inner_steps", "=", "train_kwargs", "(", "args", ")", "[", "\"eval_inner_iters\"", "]", "\n", "lr_scheduler_name", "=", "args", ".", "learning_rate_scheduler", "\n", "if", "supported_learning_rate_schedulers", "[", "lr_scheduler_name", "]", "is", "not", "None", ":", "\n", "            ", "if", "\"step\"", "in", "lr_scheduler_name", ":", "\n", "                ", "lr_sched_kwargs", "=", "{", "\"decay_rate\"", ":", "args", ".", "step_decay_rate", ",", "\"decay_after_n_steps\"", ":", "args", ".", "decay_after_n_steps", "}", "\n", "", "else", ":", "\n", "                ", "lr_sched_kwargs", "=", "{", "}", "\n", "", "lr_scheduler", "=", "supported_learning_rate_schedulers", "[", "lr_scheduler_name", "]", "(", "initial_lr", ",", "total_inner_steps", ",", "**", "lr_sched_kwargs", ")", "\n", "", "else", ":", "\n", "            ", "lr_scheduler", "=", "None", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"model_name must be in {}\"", ".", "format", "(", "SUPPORTED_MODELS", ")", ")", "\n", "", "print", "(", "'{} instantiated.'", ".", "format", "(", "args", ".", "model_name", ")", ")", "\n", "print", "(", "\"Model contains {} trainable parameters.\"", ".", "format", "(", "np", ".", "sum", "(", "[", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "]", ")", ")", ")", "\n", "\n", "# Define the meta-learner:", "\n", "print", "(", "\"Meta-learning with algorithm:\"", ")", "\n", "if", "args", ".", "foml", ":", "\n", "        ", "print", "(", "\"FOMAML\"", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Reptile\"", ")", "\n", "", "train_fn", ",", "evaluate_fn", "=", "train_gecko", ",", "evaluate_gecko", "\n", "\n", "# Get the meta-learning dataset. Each item in train_set and test_set is a task:", "\n", "print", "(", "\"Setting up meta-learning dataset\"", ")", "\n", "serially_eval_all_test_tasks", "=", "args", ".", "serially_eval_all_test_tasks", "\n", "if", "args", ".", "run_k_shot_learning_curves_experiment", ":", "\n", "        ", "test_set", ",", "test_task_names", "=", "read_fp_k_shot_dataset", "(", "DATA_DIR", ",", "image_size", "=", "args", ".", "image_size", ")", "\n", "val_set", "=", "None", "\n", "train_set", "=", "None", "\n", "", "elif", "args", ".", "fp_k_test_set", ":", "\n", "        ", "print", "(", "\"Holding out FP-k classes: {}\"", ".", "format", "(", "FP_K_TEST_TASK_IDS", ")", ")", "\n", "dataset", "=", "read_fss_1000_dataset", "(", "DATA_DIR", ",", "num_val_tasks", "=", "args", ".", "num_val_tasks", ",", "test_task_ids", "=", "FP_K_TEST_TASK_IDS", ")", "\n", "train_set", ",", "val_set", ",", "test_set", ",", "train_task_names", ",", "val_task_names", ",", "test_task_names", "=", "dataset", "\n", "if", "len", "(", "val_set", ")", "==", "0", ":", "\n", "            ", "val_set", "=", "None", "\n", "", "", "else", ":", "\n", "        ", "dataset", "=", "read_fss_1000_dataset", "(", "DATA_DIR", ",", "num_val_tasks", "=", "args", ".", "num_val_tasks", ")", "\n", "train_set", ",", "val_set", ",", "test_set", ",", "train_task_names", ",", "val_task_names", ",", "test_task_names", "=", "dataset", "\n", "if", "len", "(", "val_set", ")", "==", "0", ":", "\n", "            ", "val_set", "=", "None", "\n", "\n", "", "", "validate_datasets", "(", "args", ",", "train_set", ",", "val_set", ",", "test_set", ")", "\n", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Found {} testing tasks:'", ".", "format", "(", "len", "(", "test_set", ")", ")", ")", "\n", "for", "test_task", "in", "test_set", ":", "\n", "            ", "print", "(", "\"{}\"", ".", "format", "(", "test_task", ".", "name", ")", ")", "\n", "", "if", "train_set", "is", "not", "None", ":", "\n", "            ", "print", "(", "'Found {} training tasks:'", ".", "format", "(", "len", "(", "train_set", ")", ")", ")", "\n", "for", "train_task", "in", "train_set", ":", "\n", "                ", "print", "(", "\"{}\"", ".", "format", "(", "train_task", ".", "name", ")", ")", "\n", "\n", "", "", "", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "if", "args", ".", "model_name", "==", "\"efficientlab\"", ":", "\n", "            ", "if", "restore_ckpt_dir", "is", "not", "None", "and", "not", "args", ".", "pretrained", ":", "\n", "                ", "print", "(", "\"Restoring from checkpoint {}\"", ".", "format", "(", "restore_ckpt_dir", ")", ")", "\n", "model", ".", "restore_model", "(", "sess", ",", "restore_ckpt_dir", ",", "filter_to_scopes", "=", "[", "model", ".", "feature_extractor_name", "]", ")", "\n", "", "", "if", "not", "args", ".", "pretrained", ":", "\n", "            ", "print", "(", "\"Meta-training...\"", ")", "\n", "\n", "if", "args", ".", "continue_training_from_checkpoint", "is", "not", "None", ":", "\n", "                ", "continue_training_from_checkpoint", "=", "latest_checkpoint", "(", "args", ".", "continue_training_from_checkpoint", ")", "\n", "print", "(", "'Continuing meta-training from checkpoint: {}'", ".", "format", "(", "continue_training_from_checkpoint", ")", ")", "\n", "tf", ".", "train", ".", "Saver", "(", ")", ".", "restore", "(", "sess", ",", "continue_training_from_checkpoint", ")", "\n", "model", ".", "variables_initialized", "=", "True", "\n", "\n", "", "_", "=", "train_fn", "(", "sess", ",", "model", ",", "train_set", ",", "val_set", "or", "test_set", ",", "args", ".", "checkpoint", ",", "lr_scheduler", "=", "lr_scheduler", ",", "\n", "augment", "=", "args", ".", "augment", ",", "**", "train_kwargs", "(", "args", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "args", ".", "do_not_restore_final_layer_weights", ":", "\n", "                ", "print", "(", "'Restoring from checkpoint: {}'", ".", "format", "(", "args", ".", "checkpoint", ")", ")", "\n", "# model.restore_model(sess, args.checkpoint, filter_to_scopes=[model.feature_extractor_name, model.feature_decoder_name], filter_out_scope=model.final_layer_scope, convert_ckpt_to_rel_path=True)", "\n", "model", ".", "restore_model", "(", "sess", ",", "args", ".", "checkpoint", ",", "filter_out_scope", "=", "model", ".", "final_layer_scope", ",", "convert_ckpt_to_rel_path", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "checkpoint", "=", "latest_checkpoint", "(", "args", ".", "checkpoint", ")", "\n", "print", "(", "'Restoring from checkpoint: {}'", ".", "format", "(", "checkpoint", ")", ")", "\n", "tf", ".", "train", ".", "Saver", "(", ")", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "\n", "", "", "eval_kwargs", "=", "evaluate_kwargs", "(", "args", ")", "\n", "\n", "if", "args", ".", "optimize_update_hyperparms_on_val_set", ":", "\n", "            ", "print", "(", "\"Optimizing the update routine hyperparams on the val set\"", ")", "\n", "assert", "len", "(", "val_set", ")", ">", "0", ",", "\"Dev set has no tasks\"", "\n", "save_fine_tuned_checkpoints_test", "=", "eval_kwargs", "[", "\"save_fine_tuned_checkpoints\"", "]", "\n", "eval_kwargs", "[", "\"save_fine_tuned_checkpoints\"", "]", "=", "False", "\n", "num_train_val_data_splits_to_sample_per_config", "=", "1", "if", "args", ".", "fss_1000", "else", "4", "\n", "estimated_lr", ",", "estimated_steps", "=", "optimize_update_hyperparams", "(", "sess", ",", "model", ",", "val_set", ",", "\n", "lr_scheduler", "=", "lr_scheduler", ",", "\n", "serially_eval_all_tasks", "=", "serially_eval_all_test_tasks", ",", "\n", "num_configs_to_sample", "=", "args", ".", "num_configs_to_sample", ",", "save_dir", "=", "args", ".", "checkpoint", ",", "\n", "results_csv_name", "=", "args", ".", "uho_results_csv_name", ",", "\n", "num_train_val_data_splits_to_sample_per_config", "=", "num_train_val_data_splits_to_sample_per_config", ",", "\n", "max_steps", "=", "args", ".", "max_steps", ",", "min_steps", "=", "args", ".", "min_steps", ",", "\n", "b", "=", "args", ".", "uho_outer_iters", ",", "**", "eval_kwargs", ",", "**", "hyper_search_kwargs", "(", "args", ")", ")", "\n", "eval_kwargs", "[", "\"save_fine_tuned_checkpoints\"", "]", "=", "save_fine_tuned_checkpoints_test", "\n", "eval_kwargs", "[", "\"eval_inner_iters\"", "]", "=", "estimated_steps", "\n", "eval_kwargs", "[", "\"lr\"", "]", "=", "estimated_lr", "\n", "\n", "# Optionally meta-fine-tune on train + val sets here with optimal params, for small number of meta-iters", "\n", "# (e.g. 200, which is ~1.33 epochs on FSS-1000), and meta-step-final", "\n", "if", "args", ".", "meta_fine_tune_steps_on_train_val", ">", "0", ":", "\n", "                ", "print", "(", "\"Fine-tuning meta-learned init for {} meta-steps with optimized hyperparameters.\"", ".", "format", "(", "args", ".", "meta_fine_tune_steps_on_train_val", ")", ")", "\n", "training_params", "=", "train_kwargs", "(", "args", ")", "\n", "training_params", "[", "\"inner_iters\"", "]", "=", "estimated_steps", "\n", "training_params", "[", "\"lr\"", "]", "=", "estimated_lr", "\n", "training_params", "[", "\"meta_step_size\"", "]", "=", "training_params", "[", "\"meta_step_size_final\"", "]", "\n", "_", "=", "train_fn", "(", "sess", ",", "model", ",", "train_set", "+", "val_set", ",", "test_set", ",", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint", ",", "\"fine-tuned_on_train_val_with_optimized_update_hyperparams\"", ")", ",", "\n", "lr_scheduler", "=", "lr_scheduler", ",", "augment", "=", "args", ".", "augment", ",", "**", "training_params", ")", "\n", "\n", "", "", "del", "eval_kwargs", "[", "\"eval_tasks_with_median_early_stopping_iterations\"", "]", "\n", "\n", "if", "args", ".", "run_k_shot_learning_curves_experiment", ":", "\n", "            ", "k_shot_eval_kwargs", "=", "copy", ".", "deepcopy", "(", "eval_kwargs", ")", "\n", "del", "k_shot_eval_kwargs", "[", "\"save_fine_tuned_checkpoints\"", "]", "\n", "del", "k_shot_eval_kwargs", "[", "\"save_fine_tuned_checkpoints_dir\"", "]", "\n", "run_k_shot_learning_curves_experiment", "(", "sess", ",", "model", ",", "test_set", ",", "lr_scheduler", "=", "lr_scheduler", ",", "iter_range", "=", "args", ".", "k_shot_iter_range", ",", "**", "k_shot_eval_kwargs", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Evaluating {}-shot learning on training tasks.'", ".", "format", "(", "args", ".", "shots", ")", ")", "\n", "if", "eval_train_tasks", ":", "\n", "                ", "save_fine_tuned_checkpoints_test", "=", "eval_kwargs", "[", "\"save_fine_tuned_checkpoints\"", "]", "\n", "eval_kwargs", "[", "\"save_fine_tuned_checkpoints\"", "]", "=", "args", ".", "save_fine_tuned_checkpoints_train", "\n", "mean_train_iou", ",", "_", "=", "evaluate_fn", "(", "sess", ",", "model", ",", "train_set", ",", "visualize_predicted_segmentations", "=", "False", ",", "\n", "lr_scheduler", "=", "lr_scheduler", ",", "serially_eval_all_tasks", "=", "False", ",", "\n", "**", "eval_kwargs", ")", "\n", "eval_kwargs", "[", "\"save_fine_tuned_checkpoints\"", "]", "=", "save_fine_tuned_checkpoints_test", "\n", "\n", "", "if", "args", ".", "eval_val_tasks", ":", "\n", "                ", "test_set", "=", "val_set", "\n", "test_task_names", "=", "val_task_names", "\n", "test_set_string", "=", "\"val\"", "\n", "", "else", ":", "\n", "                ", "test_set_string", "=", "\"test\"", "\n", "", "print", "(", "'Evaluating {}-shot learning on meta-{} tasks.'", ".", "format", "(", "args", ".", "shots", ",", "test_set_string", ")", ")", "\n", "mean_test_iou", ",", "task_name_iou_map", "=", "evaluate_fn", "(", "sess", ",", "model", ",", "test_set", ",", "visualize_predicted_segmentations", "=", "False", ",", "\n", "lr_scheduler", "=", "lr_scheduler", ",", "\n", "serially_eval_all_tasks", "=", "serially_eval_all_test_tasks", ",", "**", "eval_kwargs", ")", "\n", "\n", "print", "(", "\"Evaluated meta-{} tasks:\"", ".", "format", "(", "test_set_string", ")", ")", "\n", "print", "(", "task_name_iou_map", ")", "\n", "if", "eval_train_tasks", ":", "\n", "                ", "print", "(", "\"Mean meta-train IoU: {}\"", ".", "format", "(", "mean_train_iou", ")", ")", "\n", "# Do NOT change this print (it's used to grep logs):", "\n", "", "print", "(", "\"Mean IoU over all meta-test tasks: {}\"", ".", "format", "(", "mean_test_iou", ")", ")", "\n", "\n", "# Write results out:", "\n", "results_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint", ",", "\"meta-test_results.json\"", ")", "\n", "with", "open", "(", "results_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "task_name_iou_map", ",", "f", ")", "\n", "", "print", "(", "\"Wrote results to {}\"", ".", "format", "(", "results_path", ")", ")", "\n", "\n", "\n", "", "", "end_time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "print", "(", "\"Experiment finished at: {}, taking {}\"", ".", "format", "(", "end_time", ",", "end_time", "-", "start_time", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.viz.plot_mask_on_image": [[8, 19], ["numpy.ma.masked_where", "plt.subplots", "ax1.imshow", "ax1.imshow", "plt.show"], "function", ["None"], ["def", "plot_mask_on_image", "(", "image", ":", "np", ".", "ndarray", ",", "mask", ":", "np", ".", "ndarray", ",", "truth_value", ":", "int", "=", "1.0", ",", "alpha", "=", "0.75", ",", "scale_to_0_1", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "    ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "import", "matplotlib", ".", "cm", "as", "cm", "\n", "\n", "if", "scale_to_0_1", ":", "\n", "        ", "image", "/=", "255.", "\n", "", "masked", "=", "np", ".", "ma", ".", "masked_where", "(", "mask", "!=", "truth_value", ",", "mask", ")", "\n", "fig", ",", "ax1", "=", "plt", ".", "subplots", "(", ")", "\n", "ax1", ".", "imshow", "(", "image", ")", "\n", "ax1", ".", "imshow", "(", "masked", ",", "interpolation", "=", "'none'", ",", "alpha", "=", "alpha", ",", "cmap", "=", "cm", ".", "jet", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.viz._plot_two_images": [[21, 31], ["plt.figure", "plt.subplot", "plt.imshow", "plt.subplot", "plt.imshow", "plt.show"], "function", ["None"], ["", "def", "_plot_two_images", "(", "A", ",", "B", ")", ":", "\n", "    ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "\n", "plt", ".", "figure", "(", ")", "\n", "\n", "plt", ".", "subplot", "(", "121", ")", "\n", "plt", ".", "imshow", "(", "A", ")", "\n", "plt", ".", "subplot", "(", "122", ")", "\n", "plt", ".", "imshow", "(", "B", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.viz._save_plot_two_images": [[33, 46], ["plt.figure", "plt.subplot", "plt.imshow", "plt.subplot", "plt.imshow", "plt.savefig", "plt.close"], "function", ["None"], ["", "def", "_save_plot_two_images", "(", "A", ",", "B", ",", "fname", ")", ":", "\n", "    ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "\n", "plt", ".", "subplot", "(", "121", ")", "\n", "plt", ".", "imshow", "(", "A", ")", "\n", "plt", ".", "subplot", "(", "122", ")", "\n", "plt", ".", "imshow", "(", "B", ")", "\n", "\n", "plt", ".", "savefig", "(", "fname", ")", "\n", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.viz.savefig_mask_on_image": [[48, 86], ["image.copy.copy", "mask.copy.copy", "print", "numpy.ma.masked_where", "plt.gca().set_axis_off", "plt.subplots_adjust", "plt.margins", "plt.gca().xaxis.set_major_locator", "plt.gca().yaxis.set_major_locator", "plt.subplots", "ax1.imshow", "ax1.imshow", "plt.axis", "os.path.exists", "os.makedirs", "ValueError", "image.copy.astype", "mask.copy.astype", "plt.NullLocator", "plt.NullLocator", "plt.savefig", "print", "plt.close", "print", "plt.show", "os.path.dirname", "os.path.dirname", "plt.gca", "plt.gca", "plt.gca"], "function", ["None"], ["", "def", "savefig_mask_on_image", "(", "image", ":", "np", ".", "ndarray", ",", "mask", ":", "np", ".", "ndarray", ",", "truth_value", ":", "int", "=", "1", ",", "alpha", "=", "0.5", ",", "save_path", "=", "None", ")", "->", "None", ":", "\n", "    ", "\"\"\"Plot mask on image for binary segmentation.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "dirname", "(", "save_path", ")", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "save_path", ")", ")", "\n", "", "from", "matplotlib", "import", "pyplot", "as", "plt", ",", "cm", "as", "cm", "# Import locally to avoid errors when matplotlib is not available", "\n", "image", "=", "image", ".", "copy", "(", ")", "\n", "mask", "=", "mask", ".", "copy", "(", ")", "\n", "if", "truth_value", "not", "in", "{", "1", ",", "255", "}", ":", "\n", "        ", "raise", "ValueError", "(", "\"Foreground class should be 1 or 255\"", ")", "\n", "", "print", "(", "\"mask.shape: {}\"", ".", "format", "(", "mask", ".", "shape", ")", ")", "\n", "if", "mask", ".", "shape", "[", "2", "]", "==", "2", ":", "# Get the second channel", "\n", "        ", "mask", "=", "mask", "[", ":", ",", ":", ",", "1", "]", "\n", "", "if", "truth_value", "==", "1", ":", "\n", "        ", "mask", "*=", "255", "\n", "truth_value", "=", "255", "\n", "", "image", ",", "mask", "=", "image", ".", "astype", "(", "int", ")", ",", "mask", ".", "astype", "(", "int", ")", "\n", "masked", "=", "np", ".", "ma", ".", "masked_where", "(", "mask", "!=", "truth_value", ",", "mask", ")", "\n", "\n", "plt", ".", "gca", "(", ")", ".", "set_axis_off", "(", ")", "\n", "plt", ".", "subplots_adjust", "(", "top", "=", "1", ",", "bottom", "=", "0", ",", "right", "=", "1", ",", "left", "=", "0", ",", "\n", "hspace", "=", "0", ",", "wspace", "=", "0", ")", "\n", "plt", ".", "margins", "(", "0", ",", "0", ")", "\n", "plt", ".", "gca", "(", ")", ".", "xaxis", ".", "set_major_locator", "(", "plt", ".", "NullLocator", "(", ")", ")", "\n", "plt", ".", "gca", "(", ")", ".", "yaxis", ".", "set_major_locator", "(", "plt", ".", "NullLocator", "(", ")", ")", "\n", "\n", "fig", ",", "ax1", "=", "plt", ".", "subplots", "(", ")", "\n", "ax1", ".", "imshow", "(", "image", ")", "\n", "ax1", ".", "imshow", "(", "masked", ",", "interpolation", "=", "'none'", ",", "alpha", "=", "alpha", ",", "cmap", "=", "cm", ".", "autumn", ")", "# cm.jet", "\n", "plt", ".", "axis", "(", "'off'", ")", "\n", "\n", "if", "save_path", ":", "\n", "        ", "plt", ".", "savefig", "(", "save_path", ",", "bbox_inches", "=", "0", ",", "\n", "pad_inches", "=", "0", ")", "\n", "print", "(", "\"saved figure to {}\"", ".", "format", "(", "save_path", ")", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"No path speced to save to.\"", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.viz.savefig_batch_mask_on_image": [[88, 115], ["enumerate", "zip", "image.copy.copy", "mask.copy.copy", "print", "numpy.ma.masked_where", "plt.subplots", "ax1.imshow", "ax1.imshow", "ValueError", "image.copy.astype", "mask.copy.astype", "plt.savefig", "print", "plt.close", "print", "str"], "function", ["None"], ["", "", "def", "savefig_batch_mask_on_image", "(", "images", ",", "masks", ",", "truth_value", ":", "int", "=", "1", ",", "alpha", "=", "0.75", ",", "save_path_bn", "=", "None", ",", "ext", "=", "\".png\"", ")", "->", "None", ":", "\n", "    ", "\"\"\"Plot mask on image for binary segmentation.\"\"\"", "\n", "from", "matplotlib", "import", "pyplot", "as", "plt", ",", "cm", "as", "cm", "# Import locally to avoid errors when matplotlib is not available", "\n", "for", "i", ",", "image_mask", "in", "enumerate", "(", "zip", "(", "images", ",", "masks", ")", ")", ":", "\n", "        ", "image", ",", "mask", "=", "image_mask", "\n", "image", "=", "image", ".", "copy", "(", ")", "\n", "mask", "=", "mask", ".", "copy", "(", ")", "\n", "if", "truth_value", "not", "in", "{", "1", ",", "255", "}", ":", "\n", "            ", "raise", "ValueError", "(", "\"Foreground class should be 1 or 255\"", ")", "\n", "", "print", "(", "\"mask.shape: {}\"", ".", "format", "(", "mask", ".", "shape", ")", ")", "\n", "if", "mask", ".", "shape", "[", "2", "]", "==", "2", ":", "# Get the second channel", "\n", "            ", "mask", "=", "mask", "[", ":", ",", ":", ",", "1", "]", "\n", "", "if", "truth_value", "==", "1", ":", "\n", "            ", "mask", "*=", "255", "\n", "_truth_value", "=", "255", "\n", "", "image", ",", "mask", "=", "image", ".", "astype", "(", "int", ")", ",", "mask", ".", "astype", "(", "int", ")", "\n", "masked", "=", "np", ".", "ma", ".", "masked_where", "(", "mask", "!=", "_truth_value", ",", "mask", ")", "\n", "fig", ",", "ax1", "=", "plt", ".", "subplots", "(", ")", "\n", "ax1", ".", "imshow", "(", "image", ")", "\n", "ax1", ".", "imshow", "(", "masked", ",", "interpolation", "=", "'none'", ",", "alpha", "=", "alpha", ",", "cmap", "=", "cm", ".", "jet", ")", "\n", "if", "save_path_bn", ":", "\n", "            ", "save_path", "=", "save_path_bn", "+", "\"_\"", "+", "str", "(", "i", ")", "+", "ext", "\n", "plt", ".", "savefig", "(", "save_path", ")", "\n", "print", "(", "\"saved figure to {}\"", ".", "format", "(", "save_path", ")", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"No path speced to save to.\"", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.hash_np_array": [[17, 22], ["hashlib.sha256", "hashlib.sha256.update", "hashlib.sha256.digest", "a.tostring"], "function", ["None"], ["def", "hash_np_array", "(", "a", ":", "np", ".", "array", ")", "->", "bytes", ":", "\n", "    ", "\"\"\"Returns the sha-256 hash bytes of a stringified numpy array.\"\"\"", "\n", "m", "=", "hashlib", ".", "sha256", "(", ")", "\n", "m", ".", "update", "(", "a", ".", "tostring", "(", ")", ")", "\n", "return", "m", ".", "digest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.count_examples_in_tfrecords": [[24, 34], ["tensorflow.python_io.TFRecordOptions", "isinstance", "list", "tensorflow.Session", "tensorflow.python_io.tf_record_iterator"], "function", ["None"], ["", "def", "count_examples_in_tfrecords", "(", "paths", ":", "List", "[", "str", "]", ")", "->", "int", ":", "\n", "    ", "if", "not", "isinstance", "(", "paths", ",", "list", ")", ":", "\n", "        ", "paths", "=", "list", "(", "paths", ")", "\n", "", "options", "=", "tf", ".", "python_io", ".", "TFRecordOptions", "(", "tf", ".", "python_io", ".", "TFRecordCompressionType", ".", "GZIP", ")", "\n", "c", "=", "0", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "for", "fn", "in", "paths", ":", "\n", "            ", "for", "record", "in", "tf", ".", "python_io", ".", "tf_record_iterator", "(", "fn", ",", "options", "=", "options", ")", ":", "\n", "                ", "c", "+=", "1", "\n", "", "", "", "return", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.count_unique_task_examples": [[36, 40], ["glob.glob", "util.count_examples_in_tfrecords", "os.path.join"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.count_examples_in_tfrecords"], ["", "def", "count_unique_task_examples", "(", "dir", ":", "str", ",", "task_name", ":", "str", ")", "->", "int", ":", "\n", "    ", "shards", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "\"*.tfrecord*\"", ")", ")", "\n", "shards", "=", "[", "x", "for", "x", "in", "shards", "if", "task_name", "in", "x", "]", "\n", "return", "count_examples_in_tfrecords", "(", "shards", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.latest_checkpoint": [[42, 51], ["re.compile", "os.path.join", "tensorflow.train.latest_checkpoint", "open", "f.readline", "re.compile.findall", "os.path.join", "re.escape"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.latest_checkpoint"], ["", "def", "latest_checkpoint", "(", "checkpoint_dir", ":", "str", ",", "ckpt_prefix", ":", "str", "=", "\"model.ckpt\"", ",", "return_relative", ":", "bool", "=", "True", ")", "->", "str", ":", "\n", "    ", "if", "return_relative", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "\"checkpoint\"", ")", ")", "as", "f", ":", "\n", "            ", "text", "=", "f", ".", "readline", "(", ")", "\n", "", "pattern", "=", "re", ".", "compile", "(", "re", ".", "escape", "(", "ckpt_prefix", "+", "\"-\"", ")", "+", "r\"[0-9]+\"", ")", "\n", "basename", "=", "pattern", ".", "findall", "(", "text", ")", "[", "0", "]", "\n", "return", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "basename", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "train", ".", "latest_checkpoint", "(", "checkpoint_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.get_list_of_tensor_names": [[53, 57], ["sess.as_default", "tensorflow.get_default_graph", "tf.get_default_graph.get_operations", "op.values"], "function", ["None"], ["", "", "def", "get_list_of_tensor_names", "(", "sess", ":", "tf", ".", "Session", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "sess", ".", "as_default", "(", ")", "\n", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", "return", "[", "t", ".", "name", "for", "op", "in", "graph", ".", "get_operations", "(", ")", "for", "t", "in", "op", ".", "values", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.get_list_of_node_shapes": [[59, 63], ["sess.graph.as_graph_def"], "function", ["None"], ["", "def", "get_list_of_node_shapes", "(", "sess", ":", "tf", ".", "Session", ")", "->", "List", ":", "\n", "    ", "with", "sess", ":", "\n", "        ", "graph_def", "=", "sess", ".", "graph", ".", "as_graph_def", "(", "add_shapes", "=", "True", ")", "\n", "return", "[", "n", ".", "_output_shapes", "for", "n", "in", "graph_def", ".", "node", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.mkdir": [[65, 70], ["os.makedirs"], "function", ["None"], ["", "", "def", "mkdir", "(", "path", ")", ":", "\n", "    ", "\"\"\"\n    Recursive create dir at `path` if `path` does not exist.\n    \"\"\"", "\n", "os", ".", "makedirs", "(", "path", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.save_fine_tuned_checkpoint": [[72, 82], ["util.mkdir", "tensorflow.train.Saver", "tf.train.Saver.save", "print", "ValueError", "os.path.join", "os.path.join", "str"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.mkdir"], ["", "def", "save_fine_tuned_checkpoint", "(", "save_fine_tuned_checkpoint_dir", ":", "str", ",", "sess", ":", "Session", ",", "step", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "eval_sample_num", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "    ", "if", "save_fine_tuned_checkpoint_dir", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Must specify directory in which to save fine-tuned checkpoints if saving them.\"", ")", "\n", "", "if", "eval_sample_num", "is", "not", "None", ":", "\n", "        ", "save_fine_tuned_checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "save_fine_tuned_checkpoint_dir", ",", "str", "(", "eval_sample_num", ")", ")", "\n", "", "mkdir", "(", "save_fine_tuned_checkpoint_dir", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "save_fine_tuned_checkpoint_dir", ",", "'model.ckpt'", ")", ",", "global_step", "=", "step", ")", "\n", "print", "(", "\"Saved fine-tuned checkpoint to {}.\"", ".", "format", "(", "save_fine_tuned_checkpoint_dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.get_training_set_hash_map": [[84, 92], ["util.hash_np_array", "util.hash_np_array"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.hash_np_array", "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.hash_np_array"], ["", "def", "get_training_set_hash_map", "(", "training_set", ":", "List", "[", "Tuple", "]", ")", "->", "Dict", "[", "bytes", ",", "bytes", "]", ":", "\n", "    ", "\"\"\"Returns a dict mapping sha-256 of image to sha-256 of corresponding mask.\"\"\"", "\n", "hash_map", "=", "{", "}", "\n", "for", "pair", "in", "training_set", ":", "\n", "        ", "image_hash", "=", "hash_np_array", "(", "pair", "[", "0", "]", ")", "\n", "mask_hash", "=", "hash_np_array", "(", "pair", "[", "1", "]", ")", "\n", "hash_map", "[", "image_hash", "]", "=", "mask_hash", "\n", "", "return", "hash_map", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.log_estimated_time_remaining": [[94, 99], ["print", "print", "time.time"], "function", ["None"], ["", "def", "log_estimated_time_remaining", "(", "start_time", ",", "cur_step", ",", "total_steps", ",", "unit_name", "=", "\"meta-step\"", ")", ":", "\n", "    ", "elapsed", "=", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", "/", "60.", "\n", "print", "(", "\"This {} took:\"", ".", "format", "(", "unit_name", ")", ",", "elapsed", ",", "\"minutes.\"", ")", "\n", "print", "(", "'Estimated training hours remaining:%.4f'", "%", "(", "(", "total_steps", "-", "cur_step", ")", "*", "elapsed", "/", "60.", ")", ")", "\n", "return", "elapsed", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.get_image_paths": [[101, 103], ["util.is_image_file"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.is_image_file"], ["", "def", "get_image_paths", "(", "list_of_paths", ")", ":", "\n", "    ", "return", "[", "x", "for", "x", "in", "list_of_paths", "if", "is_image_file", "(", "x", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.is_image_file": [[105, 111], ["os.path.splitext"], "function", ["None"], ["", "def", "is_image_file", "(", "path", ")", ":", "\n", "    ", "_", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "path", ")", "\n", "if", "ext", "in", "[", "'.jpg'", ",", "'.jpeg'", ",", "'.png'", ",", "'.tiff'", ",", "'.tif'", ",", "'.bmp'", ",", "\".mat\"", "]", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.initialize_uninitialized_vars": [[113, 122], ["list", "warnings.warn", "print", "session.run", "tensorflow.global_variables", "tensorflow.variables_initializer", "tensorflow.get_variable", "session.run", "tensorflow.report_uninitialized_variables"], "function", ["None"], ["", "", "def", "initialize_uninitialized_vars", "(", "session", ",", "list_of_variables", "=", "None", ")", ":", "\n", "    ", "if", "list_of_variables", "is", "None", ":", "\n", "        ", "list_of_variables", "=", "tf", ".", "global_variables", "(", ")", "\n", "", "uninitialized_variables", "=", "list", "(", "tf", ".", "get_variable", "(", "name", ")", "for", "name", "in", "\n", "session", ".", "run", "(", "tf", ".", "report_uninitialized_variables", "(", "list_of_variables", ")", ")", ")", "\n", "warnings", ".", "warn", "(", "\"Initializing the following variables: {}\"", ".", "format", "(", "uninitialized_variables", ")", ")", "\n", "print", "(", "\"Initializing the following variables: {}\"", ".", "format", "(", "uninitialized_variables", ")", ")", "\n", "session", ".", "run", "(", "tf", ".", "variables_initializer", "(", "uninitialized_variables", ")", ")", "\n", "return", "uninitialized_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.validate_datasets": [[124, 131], ["len", "len", "len", "ValueError"], "function", ["None"], ["", "def", "validate_datasets", "(", "args", ",", "train_set", ",", "val_set", ",", "test_set", ")", ":", "\n", "    ", "if", "not", "args", ".", "pretrained", "and", "not", "args", ".", "run_k_shot_learning_curves_experiment", ":", "\n", "        ", "assert", "len", "(", "train_set", ")", ">", "0", ",", "\"Training set must have examples.\"", "\n", "", "assert", "len", "(", "test_set", ")", ">", "0", ",", "\"Test set must have examples.\"", "\n", "if", "args", ".", "eval_val_tasks", "and", "val_set", "is", "not", "None", ":", "\n", "        ", "if", "len", "(", "val_set", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Val set has no tasks to evaluate\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.ci95": [[133, 137], ["numpy.std", "numpy.sqrt", "len"], "function", ["None"], ["", "", "", "def", "ci95", "(", "a", ":", "Union", "[", "List", "[", "float", "]", ",", "np", ".", "ndarray", "]", ")", ":", "\n", "    ", "\"\"\"Computes the 95% confidence interval of the array `a`.\"\"\"", "\n", "sigma", "=", "np", ".", "std", "(", "a", ")", "\n", "return", "1.96", "*", "sigma", "/", "np", ".", "sqrt", "(", "len", "(", "a", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.runtime_metrics": [[139, 143], ["util.ci95", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.ci95"], ["", "def", "runtime_metrics", "(", "runtimes", ":", "List", "[", "Union", "[", "float", ",", "int", "]", "]", ")", ":", "\n", "    ", "\"\"\"runtimes is a list of time it takes to process one image\"\"\"", "\n", "ci", "=", "ci95", "(", "runtimes", ")", "\n", "return", "np", ".", "mean", "(", "runtimes", ")", ",", "ci", "\n", "", ""]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.debug_tf_dataset.debug": [[7, 24], ["tensorflow.data.Iterator.from_structure", "tf.data.Iterator.from_structure.get_next", "tf.data.Iterator.from_structure.make_initializer", "tensorflow.Session", "sess.run", "debug_tf_dataset.viz", "pdb.set_trace", "sess.run", "print"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.utils.debug_tf_dataset.viz"], ["def", "debug", "(", "dataset", ")", ":", "\n", "    ", "\"\"\"Debugging utility for tf.data.Dataset.\"\"\"", "\n", "iterator", "=", "tf", ".", "data", ".", "Iterator", ".", "from_structure", "(", "\n", "dataset", ".", "output_types", ",", "dataset", ".", "output_shapes", ")", "\n", "next_element", "=", "iterator", ".", "get_next", "(", ")", "\n", "\n", "ds_init_op", "=", "iterator", ".", "make_initializer", "(", "dataset", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "ds_init_op", ")", "\n", "viz", "(", "sess", ",", "next_element", ")", "\n", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "res", "=", "sess", ".", "run", "(", "next_element", ")", "\n", "# for i in range(len(res)):", "\n", "#     print(\"IoU of label with itself:\")", "\n", "#     print(Gecko._iou(res[i][1], res[i][1], class_of_interest_channel=None))", "\n", "print", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.debug_tf_dataset.plot_mask": [[26, 45], ["plt.figure", "plt.imshow", "plt.show", "range", "print", "print", "print", "Gecko._iou", "numpy.sum", "mask_j.copy", "mask_j.copy"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko._iou"], ["", "", "def", "plot_mask", "(", "mask_j", ":", "np", ".", "ndarray", ",", "figure_index", "=", "0", ",", "channel_index", ":", "Optional", "[", "int", "]", "=", "None", ",", "test_iou_of_label", ":", "bool", "=", "False", ")", ":", "\n", "    ", "if", "test_iou_of_label", ":", "\n", "        ", "from", "meta_learners", ".", "supervised_reptile", ".", "supervised_reptile", ".", "reptile", "import", "Gecko", "\n", "", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "plt", ".", "figure", "(", "figure_index", ")", "\n", "if", "channel_index", "is", "None", ":", "\n", "        ", "for", "k", "in", "range", "(", "mask_j", ".", "shape", "[", "2", "]", ")", ":", "\n", "            ", "if", "np", ".", "sum", "(", "mask_j", "[", ":", ",", ":", ",", "k", "]", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "break", "\n", "", "print", "(", "\"class at channel {}\"", ".", "format", "(", "k", ")", ")", "\n", "", "else", ":", "\n", "        ", "k", "=", "channel_index", "\n", "", "plt", ".", "imshow", "(", "mask_j", "[", ":", ",", ":", ",", "k", "]", ")", "\n", "plt", ".", "show", "(", ")", "\n", "if", "test_iou_of_label", ":", "\n", "        ", "print", "(", "\"IoU of label with itself:\"", ")", "\n", "print", "(", "Gecko", ".", "_iou", "(", "mask_j", ".", "copy", "(", ")", ",", "mask_j", ".", "copy", "(", ")", ",", "class_of_interest_channel", "=", "None", ",", "round_labels", "=", "True", ")", ")", "\n", "", "return", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.utils.debug_tf_dataset.viz": [[47, 70], ["range", "sess.run", "res[].astype", "print", "pdb.set_trace", "len", "range", "plt.figure", "plt.imshow", "plt.show", "debug_tf_dataset.plot_mask", "plt.figure", "plt.imshow", "plt.show", "debug_tf_dataset.plot_mask"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.utils.debug_tf_dataset.plot_mask", "home.repos.pwc.inspect_result.ml4ai_mliis.utils.debug_tf_dataset.plot_mask"], ["", "def", "viz", "(", "sess", ",", "next_element", ",", "num_to_viz", "=", "20", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "\n", "for", "i", "in", "range", "(", "num_to_viz", ")", ":", "\n", "            ", "res", "=", "sess", ".", "run", "(", "next_element", ")", "\n", "image", "=", "res", "[", "0", "]", ".", "astype", "(", "int", ")", "\n", "mask", "=", "res", "[", "1", "]", "\n", "if", "len", "(", "image", ".", "shape", ")", "==", "4", ":", "\n", "                ", "for", "j", "in", "range", "(", "image", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "plt", ".", "figure", "(", "i", "+", "j", ")", "\n", "plt", ".", "imshow", "(", "image", "[", "j", "]", ")", "\n", "plt", ".", "show", "(", ")", "\n", "mask_j", "=", "mask", "[", "j", "]", "\n", "plot_mask", "(", "mask_j", ",", "i", "+", "j", ")", "\n", "", "", "else", ":", "\n", "                ", "plt", ".", "figure", "(", "i", ")", "\n", "plt", ".", "imshow", "(", "image", ")", "\n", "plt", ".", "show", "(", ")", "\n", "plot_mask", "(", "mask", ",", "i", ")", "\n", "", "", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "e", ")", "\n", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.Augmenter.__init__": [[137, 143], ["print", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "aug_funcs", "=", "None", ")", ":", "\n", "        ", "if", "aug_funcs", "is", "None", ":", "\n", "            ", "aug_funcs", "=", "cur_aug_funcs", "\n", "", "self", ".", "aug_funcs", "=", "aug_funcs", "\n", "self", ".", "prob_to_return_original", "=", "1.", "/", "(", "len", "(", "aug_funcs", ")", "+", "1", ")", "\n", "print", "(", "\"Initialized image segmentation augmenter.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.Augmenter.apply_augmentations": [[144, 161], ["random.shuffle", "numpy.random.randint", "numpy.random.rand", "image.copy", "mask.copy", "fn", "len"], "methods", ["None"], ["", "def", "apply_augmentations", "(", "self", ",", "image", ",", "mask", ",", "prob_to_return_original", "=", "0.0", ",", "return_image_mask_in_list", ":", "bool", "=", "True", ")", ":", "# 0.5", "\n", "        ", "if", "prob_to_return_original", "is", "not", "None", ":", "\n", "            ", "prob", "=", "prob_to_return_original", "\n", "", "else", ":", "\n", "            ", "prob", "=", "self", ".", "prob_to_return_original", "\n", "", "if", "np", ".", "random", ".", "rand", "(", ")", "<=", "prob", ":", "\n", "            ", "return", "image", ",", "mask", "\n", "", "image", ",", "mask", "=", "image", ".", "copy", "(", ")", ",", "mask", ".", "copy", "(", ")", "\n", "shuffle", "(", "self", ".", "aug_funcs", ")", "\n", "# Apply some or all of them in the shuffled order", "\n", "num_to_apply", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "len", "(", "self", ".", "aug_funcs", ")", "+", "1", ")", "\n", "for", "fn", "in", "self", ".", "aug_funcs", "[", ":", "num_to_apply", "]", ":", "\n", "            ", "image", ",", "mask", "=", "fn", "(", "image", ",", "mask", ")", "\n", "", "if", "return_image_mask_in_list", ":", "\n", "            ", "return", "[", "image", ",", "mask", "]", "\n", "", "else", ":", "\n", "            ", "return", "image", ",", "mask", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.additive_gaussian_noise": [[9, 13], ["numpy.abs", "numpy.random.normal", "numpy.random.normal", "numpy.clip().astype", "mask.astype", "numpy.clip"], "function", ["None"], ["def", "additive_gaussian_noise", "(", "image", ",", "mask", ",", "mean_sd", "=", "5.1", ")", ":", "\n", "    ", "sd", "=", "np", ".", "abs", "(", "np", ".", "random", ".", "normal", "(", "mean_sd", ",", "1", ",", "1", ")", ")", "\n", "noise", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "sd", ",", "image", ".", "shape", ")", "\n", "return", "np", ".", "clip", "(", "image", "+", "noise", ",", "0.", ",", "255.", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "mask", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.exposure": [[15, 19], ["numpy.abs", "numpy.random.normal", "numpy.random.normal", "numpy.clip().astype", "mask.astype", "numpy.clip"], "function", ["None"], ["", "def", "exposure", "(", "image", ",", "mask", ",", "mean_sd", "=", "12.75", ")", ":", "\n", "    ", "sd", "=", "np", ".", "abs", "(", "np", ".", "random", ".", "normal", "(", "mean_sd", ",", "1", ",", "1", ")", ")", "\n", "noise", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "sd", ",", "1", ")", "\n", "return", "np", ".", "clip", "(", "image", "+", "noise", ",", "0.", ",", "255.", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "mask", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.random_eraser": [[21, 37], ["numpy.random.uniform", "int", "int", "numpy.random.randint", "numpy.random.randint", "numpy.random.uniform", "numpy.sqrt", "numpy.sqrt", "input_img.astype", "mask.astype", "numpy.random.uniform"], "function", ["None"], ["", "def", "random_eraser", "(", "input_img", ",", "mask", ",", "s_l", "=", "0.02", ",", "s_h", "=", "0.10", ",", "r_1", "=", "0.3", ",", "r_2", "=", "1", "/", "0.3", ",", "v_l", "=", "0", ",", "v_h", "=", "255", ")", ":", "\n", "    ", "\"\"\"\n    Random eraser https://arxiv.org/pdf/1708.04896.pdf\n    Adapted for image segmentation and speed from: https://github.com/yu4u/mixup-generator/blob/master/random_eraser.py\n    \"\"\"", "\n", "img_h", ",", "img_w", ",", "_", "=", "input_img", ".", "shape", "\n", "s", "=", "np", ".", "random", ".", "uniform", "(", "s_l", ",", "s_h", ")", "*", "img_h", "*", "img_w", "\n", "r", "=", "np", ".", "random", ".", "uniform", "(", "r_1", ",", "r_2", ")", "\n", "w", "=", "int", "(", "np", ".", "sqrt", "(", "s", "/", "r", ")", ")", "\n", "h", "=", "int", "(", "np", ".", "sqrt", "(", "s", "*", "r", ")", ")", "\n", "top", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "img_h", ")", "\n", "left", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "img_w", ")", "\n", "c", "=", "np", ".", "random", ".", "uniform", "(", "v_l", ",", "v_h", ")", "\n", "input_img", "[", "top", ":", "top", "+", "h", ",", "left", ":", "left", "+", "w", ",", ":", "]", "=", "c", "\n", "mask", "[", "top", ":", "top", "+", "h", ",", "left", ":", "left", "+", "w", ",", ":", "]", "=", "[", "1", ",", "0", "]", "# Set the background to true, foreground to false", "\n", "return", "input_img", ".", "astype", "(", "np", ".", "float32", ")", ",", "mask", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.fliplr": [[39, 43], ["numpy.fliplr", "numpy.fliplr", "np.fliplr.astype", "np.fliplr.astype"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.fliplr", "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.fliplr"], ["", "def", "fliplr", "(", "image", ",", "mask", ")", ":", "\n", "    ", "image", "=", "np", ".", "fliplr", "(", "image", ")", "\n", "mask", "=", "np", ".", "fliplr", "(", "mask", ")", "\n", "return", "image", ".", "astype", "(", "np", ".", "float32", ")", ",", "mask", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.shift_img_lr": [[45, 63], ["numpy.roll", "numpy.roll", "numpy.random.uniform", "numpy.random.uniform", "numpy.np.float32", "numpy.np.float32"], "function", ["None"], ["", "def", "shift_img_lr", "(", "image", ",", "shift", ",", "roll", ",", "right", ",", "fill", ":", "Optional", "[", "Union", "[", "int", ",", "List", "[", "int", "]", "]", "]", "=", "None", ")", ":", "\n", "    ", "if", "right", ":", "\n", "        ", "image", "=", "np", ".", "roll", "(", "image", ",", "shift", ",", "0", ")", "\n", "if", "not", "roll", ":", "\n", "            ", "if", "fill", "is", "not", "None", ":", "\n", "                ", "left_fill", "=", "fill", "\n", "", "else", ":", "\n", "                ", "left_fill", "=", "np", ".", "random", ".", "uniform", "(", "0", ",", "255", ",", "image", ".", "shape", "[", "2", "]", ")", "\n", "", "image", "[", ":", ",", ":", "shift", "]", "=", "left_fill", "\n", "", "", "else", ":", "\n", "        ", "image", "=", "np", ".", "roll", "(", "image", ",", "-", "shift", ",", "0", ")", "\n", "if", "not", "roll", ":", "\n", "            ", "if", "fill", "is", "not", "None", ":", "\n", "                ", "right_fill", "=", "fill", "\n", "", "else", ":", "\n", "                ", "right_fill", "=", "np", ".", "random", ".", "uniform", "(", "0", ",", "255", ",", "image", ".", "shape", "[", "2", "]", ")", "\n", "", "image", "[", ":", ",", "-", "shift", ":", "]", "=", "right_fill", "\n", "", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.shift_img_ud": [[65, 83], ["numpy.roll", "numpy.roll", "numpy.random.uniform", "numpy.random.uniform"], "function", ["None"], ["", "def", "shift_img_ud", "(", "image", ",", "shift", ",", "roll", ",", "up", ",", "fill", ":", "Optional", "[", "Union", "[", "int", ",", "List", "[", "int", "]", "]", "]", "=", "None", ")", ":", "\n", "    ", "if", "up", ":", "\n", "        ", "image", "=", "np", ".", "roll", "(", "image", ",", "shift", ",", "1", ")", "\n", "if", "not", "roll", ":", "\n", "            ", "if", "fill", "is", "not", "None", ":", "\n", "                ", "low_fill", "=", "fill", "\n", "", "else", ":", "\n", "                ", "low_fill", "=", "np", ".", "random", ".", "uniform", "(", "0", ",", "255", ",", "image", ".", "shape", "[", "2", "]", ")", "\n", "", "image", "[", "-", "shift", ":", ",", ":", "]", "=", "low_fill", "\n", "", "", "else", ":", "\n", "        ", "image", "=", "np", ".", "roll", "(", "image", ",", "-", "shift", ",", "1", ")", "\n", "if", "not", "roll", ":", "\n", "            ", "if", "fill", "is", "not", "None", ":", "\n", "                ", "top_fill", "=", "fill", "\n", "", "else", ":", "\n", "                ", "top_fill", "=", "np", ".", "random", ".", "uniform", "(", "0", ",", "255", ",", "image", ".", "shape", "[", "2", "]", ")", "\n", "", "image", "[", ":", "shift", ",", ":", "]", "=", "top_fill", "\n", "", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.translate": [[85, 98], ["random.getrandbits", "random.getrandbits", "random.getrandbits", "numpy.random.randint", "np_augmenters.shift_img_ud", "np_augmenters.shift_img_ud", "np_augmenters.shift_img_lr", "np_augmenters.shift_img_lr", "shift_img_lr.astype", "shift_img_lr.astype"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.shift_img_ud", "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.shift_img_ud", "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.shift_img_lr", "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.shift_img_lr"], ["", "def", "translate", "(", "image", ",", "mask", ",", "max_shift", "=", "23", ",", "mask_fill", "=", "[", "1", ",", "0", "]", ")", ":", "# TODO: try larger max_shift", "\n", "    ", "\"\"\"Randomly jitter an image horizontally or vertically.\"\"\"", "\n", "vert", "=", "random", ".", "getrandbits", "(", "1", ")", "\n", "direction", "=", "random", ".", "getrandbits", "(", "1", ")", "\n", "shift", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "max_shift", "+", "1", ",", "1", ")", "[", "0", "]", "\n", "roll", "=", "random", ".", "getrandbits", "(", "1", ")", "\n", "if", "vert", ":", "\n", "        ", "image", "=", "shift_img_ud", "(", "image", ",", "shift", ",", "roll", ",", "direction", ")", "\n", "mask", "=", "shift_img_ud", "(", "mask", ",", "shift", ",", "roll", ",", "direction", ",", "fill", "=", "mask_fill", ")", "\n", "", "else", ":", "\n", "        ", "image", "=", "shift_img_lr", "(", "image", ",", "shift", ",", "roll", ",", "direction", ")", "\n", "mask", "=", "shift_img_lr", "(", "mask", ",", "shift", ",", "roll", ",", "direction", ",", "fill", "=", "mask_fill", ")", "\n", "", "return", "image", ".", "astype", "(", "np", ".", "float32", ")", ",", "mask", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.rotate_img_mask": [[100, 130], ["numpy.random.randint", "scipy.ndimage.rotate", "scipy.ndimage.rotate", "random.sample", "random.getrandbits", "numpy.random.randint", "numpy.random.randint"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character.sample"], ["", "def", "rotate_img_mask", "(", "image", ",", "mask", ",", "max_angle", ":", "int", "=", "45", ",", "mask_fill", "=", "[", "1", ",", "0", "]", ")", ":", "\n", "    ", "angle", "=", "np", ".", "random", ".", "randint", "(", "-", "max_angle", ",", "max_angle", ")", "\n", "mode", "=", "random", ".", "sample", "(", "[", "'reflect'", ",", "'constant'", ",", "'mirror'", ",", "'wrap'", "]", ",", "1", ")", "[", "0", "]", "\n", "reshape", "=", "False", "\n", "\n", "fill_with_noise", "=", "False", "\n", "\n", "if", "mode", "==", "\"constant\"", ":", "\n", "        ", "if", "random", ".", "getrandbits", "(", "1", ")", ":", "\n", "            ", "cval", "=", "-", "256", "\n", "fill_with_noise", "=", "True", "\n", "", "else", ":", "\n", "            ", "cval", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "256", ")", "\n", "", "", "else", ":", "\n", "        ", "cval", "=", "0", "\n", "\n", "", "image", "=", "rotate", "(", "image", ",", "angle", "=", "angle", ",", "reshape", "=", "reshape", ",", "mode", "=", "mode", ",", "cval", "=", "cval", ")", "\n", "\n", "if", "mode", "==", "\"constant\"", "and", "fill_with_noise", ":", "\n", "        ", "bg", "=", "image", "==", "-", "256", "\n", "noise", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "256", ",", "size", "=", "image", ".", "shape", ")", "\n", "image", "[", "bg", "]", "=", "noise", "[", "bg", "]", "\n", "\n", "", "cval", "=", "-", "256", "\n", "mask", "=", "rotate", "(", "mask", ",", "angle", "=", "angle", ",", "reshape", "=", "reshape", ",", "mode", "=", "mode", ",", "cval", "=", "cval", ",", "order", "=", "0", ")", "\n", "if", "mode", "==", "\"constant\"", ":", "\n", "        ", "bg", "=", "mask", "[", ":", ",", ":", ",", "0", "]", "==", "-", "256", "\n", "mask", "[", "bg", "]", "=", "mask_fill", "\n", "\n", "", "return", "image", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.__init__": [[23, 110], ["print", "tensorflow.shape", "tensorflow.reshape", "tensorflow.placeholder_with_default", "efficientlab.EfficientLab.build_model", "tensorflow.placeholder", "print", "isinstance", "print", "tensorflow.placeholder", "print", "isinstance", "print", "ValueError", "print", "tensorflow.placeholder_with_default", "tensorflow.keras.layers.Dropout", "type", "type", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.build_model"], ["def", "__init__", "(", "self", ",", "images", ":", "Optional", "[", "tf", ".", "Tensor", "]", "=", "None", ",", "labels", ":", "Optional", "[", "tf", ".", "Tensor", "]", "=", "None", ",", "is_training", ":", "bool", "=", "True", ",", "n_classes", "=", "1", ",", "n_rows", "=", "224", ",", "n_cols", "=", "224", ",", "\n", "spatial_pyramid_pooling", ":", "bool", "=", "False", ",", "skip_decoding", ":", "bool", "=", "False", ",", "\n", "feature_extractor_name", ":", "str", "=", "\"efficientnet-b0\"", ",", "l2", ":", "bool", "=", "True", ",", "l1", ":", "bool", "=", "False", ",", "\n", "darc1", ":", "bool", "=", "False", ",", "final_layer_dropout_rate", ":", "Optional", "[", "float", "]", "=", "0.2", ",", "dice", ":", "bool", "=", "True", ",", "\n", "optimizer", ":", "Optional", "[", "tf", ".", "train", ".", "Optimizer", "]", "=", "None", ",", "rsd", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "[", "2", "]", ",", "disable_lsd_residual_connections", ":", "bool", "=", "False", ",", "seperate_background_channel", ":", "bool", "=", "True", ",", "binary_iou_loss", ":", "bool", "=", "True", ",", "**", "optim_kwargs", ")", ":", "\n", "        ", "if", "optimizer", "is", "None", ":", "\n", "            ", "optimizer", "=", "DEFAULT_OPTIMIZER", "\n", "", "print", "(", "\"Using optimizer {}\"", ".", "format", "(", "optimizer", ")", ")", "\n", "self", ".", "optimizer_class", "=", "optimizer", "\n", "self", ".", "n_input_channels", "=", "3", "\n", "self", ".", "n_input_rows", "=", "n_rows", "\n", "self", ".", "n_input_cols", "=", "n_cols", "\n", "self", ".", "binary_iou_loss", "=", "binary_iou_loss", "# IoU loss term will be for 2 channel masks.", "\n", "self", ".", "seperate_background_channel", "=", "seperate_background_channel", "\n", "if", "self", ".", "seperate_background_channel", ":", "\n", "            ", "self", ".", "n_output_channels", "=", "n_classes", "+", "1", "# Add 1 for background class", "\n", "", "else", ":", "\n", "            ", "self", ".", "n_output_channels", "=", "n_classes", "\n", "", "if", "images", "is", "None", ":", "\n", "            ", "self", ".", "input_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "\"X\"", ",", "shape", "=", "(", "None", ",", "self", ".", "n_input_rows", ",", "self", ".", "n_input_cols", ",", "\n", "self", ".", "n_input_channels", ")", ")", "\n", "print", "(", "\"Input placeholder: {}\"", ".", "format", "(", "self", ".", "input_ph", ")", ")", "\n", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "images", ",", "tf", ".", "Tensor", ")", ",", "\"images must be of type tf.Tensor but is {}\"", ".", "format", "(", "type", "(", "images", ")", ")", "\n", "self", ".", "input_ph", "=", "images", "\n", "print", "(", "\"Input images: {}\"", ".", "format", "(", "self", ".", "input_ph", ")", ")", "\n", "", "self", ".", "input_shape", "=", "tf", ".", "shape", "(", "self", ".", "input_ph", ")", "\n", "\n", "if", "labels", "is", "None", ":", "\n", "            ", "self", ".", "label_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "\"Y\"", ",", "shape", "=", "(", "None", ",", "self", ".", "n_input_rows", ",", "self", ".", "n_input_cols", ",", "\n", "self", ".", "n_output_channels", ")", ")", "\n", "print", "(", "\"Label placeholder: {}\"", ".", "format", "(", "self", ".", "label_ph", ")", ")", "\n", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "labels", ",", "tf", ".", "Tensor", ")", ",", "\"labels must be of type tf.Tensor but is {}\"", ".", "format", "(", "type", "(", "labels", ")", ")", "\n", "self", ".", "label_ph", "=", "labels", "\n", "print", "(", "\"Labels: {}\"", ".", "format", "(", "self", ".", "label_ph", ")", ")", "\n", "\n", "", "self", ".", "flat_label_ph", "=", "tf", ".", "reshape", "(", "self", ".", "label_ph", ",", "[", "-", "1", ",", "self", ".", "n_output_channels", "]", ")", "\n", "self", ".", "is_training_ph", "=", "tf", ".", "placeholder_with_default", "(", "is_training", ",", "shape", "=", "(", ")", ")", "\n", "\n", "self", ".", "l2", "=", "l2", "\n", "self", ".", "l1", "=", "l1", "\n", "self", ".", "darc1", "=", "darc1", "\n", "self", ".", "dice", "=", "dice", "# Will cause model to be trained with soft dice loss function", "\n", "\n", "supported_feature_extractors", "=", "[", "\"efficientnet-b0\"", ",", "\"efficientnet-b3\"", "]", "\n", "if", "feature_extractor_name", "not", "in", "supported_feature_extractors", ":", "\n", "            ", "raise", "ValueError", "(", "\"feature_extractor_name must be in {} but is: {}\"", ".", "format", "(", "supported_feature_extractors", ",", "\n", "feature_extractor_name", ")", ")", "\n", "", "self", ".", "feature_extractor_name", "=", "feature_extractor_name", "\n", "if", "self", ".", "feature_extractor_name", "==", "\"efficientnet-b0\"", ":", "\n", "            ", "self", ".", "aspp_dimension", "=", "112", "\n", "self", ".", "max_block_num", "=", "10", "\n", "", "elif", "self", ".", "feature_extractor_name", "==", "\"efficientnet-b3\"", ":", "\n", "            ", "self", ".", "aspp_dimension", "=", "136", "\n", "self", ".", "max_block_num", "=", "17", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Feature extractor must be in {} to have aspp dimension defined.\"", ".", "format", "(", "supported_feature_extractors", ")", ")", "\n", "\n", "", "self", ".", "feature_decoder_name", "=", "FEATURE_DECODER_SCOPE_NAME", "\n", "\n", "self", ".", "spatial_pyramid_pooling", "=", "spatial_pyramid_pooling", "# DeepLab style atrous spatial pyramid pooling", "\n", "self", ".", "skip_decoding", "=", "skip_decoding", "# DeepLab v3+ style decoder", "\n", "\n", "self", ".", "rsd", "=", "rsd", "# Our improved decoder", "\n", "self", ".", "disable_lsd_residual_connections", "=", "disable_lsd_residual_connections", "\n", "\n", "self", ".", "final_layer_scope", "=", "self", ".", "feature_decoder_name", "+", "\"/\"", "+", "FINAL_LAYER_WEIGHTS_NAME", "\n", "\n", "self", ".", "feature_extractor", "=", "self", ".", "build_efficientnet", "\n", "\n", "self", ".", "final_layer_dropout_rate_ph", "=", "final_layer_dropout_rate", "\n", "if", "self", ".", "final_layer_dropout_rate_ph", "is", "not", "None", "and", "self", ".", "final_layer_dropout_rate_ph", ">", "0", ":", "\n", "            ", "print", "(", "\"Using dropout at final layer with drop rate {}\"", ".", "format", "(", "self", ".", "final_layer_dropout_rate_ph", ")", ")", "\n", "self", ".", "final_layer_dropout_rate_ph", "=", "tf", ".", "placeholder_with_default", "(", "self", ".", "final_layer_dropout_rate_ph", ",", "shape", "=", "(", ")", ")", "\n", "self", ".", "_final_layer_dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "self", ".", "final_layer_dropout_rate_ph", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_final_layer_dropout", "=", "None", "\n", "\n", "", "self", ".", "weights_initializer", "=", "conv_kernel_initializer", "\n", "self", ".", "final_layer_weights_initializer", "=", "self", ".", "weights_initializer", "\n", "\n", "# Explicitly track state of whether or not variables have been initialized:", "\n", "self", ".", "variables_initialized", "=", "False", "\n", "\n", "self", ".", "lr_ph", "=", "None", "# set in build optimizer", "\n", "self", ".", "build_model", "(", "self", ".", "input_ph", ",", "**", "optim_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.build_model": [[111, 120], ["tensorflow.constant", "tensorflow.constant", "efficientlab.EfficientLab.encode", "efficientlab.EfficientLab.decode", "efficientlab.EfficientLab.build_optimizer"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.BlockDecoder.encode", "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.BlockDecoder.decode", "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.utils.build_optimizer"], ["", "def", "build_model", "(", "self", ",", "features", ",", "**", "optim_kwargs", ")", ":", "\n", "        ", "\"\"\"Build model with input features (images) in range [0, 255].\"\"\"", "\n", "features", "-=", "tf", ".", "constant", "(", "MEAN_RGB", ",", "shape", "=", "[", "1", ",", "1", ",", "3", "]", ",", "dtype", "=", "features", ".", "dtype", ")", "\n", "features", "/=", "tf", ".", "constant", "(", "STDDEV_RGB", ",", "shape", "=", "[", "1", ",", "1", ",", "3", "]", ",", "dtype", "=", "features", ".", "dtype", ")", "\n", "# TODO: could implement graph code augmentation here. Wrap in tf.cond(self.is_training_ph, lambda _features: augment_batch(_features), lambda: features)", "\n", "embedded_image", ",", "skip_connections", "=", "self", ".", "encode", "(", "features", ")", "\n", "self", ".", "probabilities", "=", "self", ".", "decode", "(", "embedded_image", ",", "skip_connections", ")", "\n", "self", ".", "build_optimizer", "(", "**", "optim_kwargs", ")", "\n", "return", "self", ".", "probabilities", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.encode": [[121, 125], ["efficientlab.EfficientLab.feature_extractor"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "image", ")", ":", "\n", "        ", "\"\"\"Encodes an image into an embedding.\"\"\"", "\n", "embedded_image", ",", "skip_connections", "=", "self", ".", "feature_extractor", "(", "image", ")", "\n", "return", "embedded_image", ",", "skip_connections", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.decode": [[126, 178], ["tensorflow.variable_scope", "print", "tensorflow.layers.conv2d", "tensorflow.image.resize_images", "tensorflow.reshape", "tensorflow.nn.softmax", "efficientlab.EfficientLab._probabilities_to_classes", "efficientlab.EfficientLab.aspp", "print", "sorted", "efficientlab.EfficientLab._final_layer_dropout", "tensorflow.variable_scope", "tensorflow.image.resize_images", "tensorflow.layers.conv2d", "tensorflow.layers.batch_normalization", "tensorflow.nn.swish", "tensorflow.concat", "efficientlab.EfficientLab.sep_conv", "efficientlab.EfficientLab.sep_conv", "len", "print", "efficientlab.EfficientLab.residual_skip_decoder"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab._probabilities_to_classes", "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.aspp", "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.sep_conv", "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.sep_conv", "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.residual_skip_decoder"], ["", "def", "decode", "(", "self", ",", "embedded_image", ":", "tf", ".", "Tensor", ",", "skip_connections", ":", "List", "[", "tf", ".", "Tensor", "]", ")", "->", "tf", ".", "Tensor", ":", "\n", "        ", "\"\"\"Decodes an embedded image into segmentation probabilities.\"\"\"", "\n", "skip_connection", "=", "skip_connections", "[", "1", "]", "\n", "with", "tf", ".", "variable_scope", "(", "\"decode\"", ")", ":", "\n", "            ", "if", "self", ".", "spatial_pyramid_pooling", ":", "\n", "                ", "embedded_image", "=", "self", ".", "aspp", "(", "embedded_image", ")", "\n", "\n", "", "if", "self", ".", "skip_decoding", ":", "# DeepLab style decoding", "\n", "                ", "print", "(", "\"Refining decoding with skip connections.\"", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"decode_skip_connections\"", ")", ":", "\n", "                    ", "decoded", "=", "tf", ".", "image", ".", "resize_images", "(", "embedded_image", ",", "self", ".", "input_shape", "[", "1", ":", "3", "]", "//", "4", ",", "\n", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BILINEAR", ",", "align_corners", "=", "True", ")", "\n", "# Allow twice as many features for encoder features in decoding:", "\n", "decoded_skip_dim", "=", "self", ".", "aspp_dimension", "//", "2", "\n", "decoded_skip", "=", "tf", ".", "layers", ".", "conv2d", "(", "skip_connection", ",", "filters", "=", "decoded_skip_dim", ",", "kernel_size", "=", "[", "1", ",", "1", "]", ",", "\n", "padding", "=", "\"SAME\"", ",", "use_bias", "=", "False", ")", "\n", "decoded_skip", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "decoded_skip", ",", "training", "=", "True", ")", "\n", "decoded_skip", "=", "tf", ".", "nn", ".", "swish", "(", "decoded_skip", ")", "\n", "\n", "decoded", "=", "tf", ".", "concat", "(", "[", "decoded", ",", "decoded_skip", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Apply depth-wise separable convolution and residual connections:", "\n", "decoded", "=", "self", ".", "sep_conv", "(", "decoded", ",", "self", ".", "aspp_dimension", "+", "decoded_skip_dim", ",", "kernel_size", "=", "3", ")", "# + decoded", "\n", "decoded", "=", "self", ".", "sep_conv", "(", "decoded", ",", "self", ".", "aspp_dimension", "+", "decoded_skip_dim", ",", "kernel_size", "=", "3", ")", "# + decoded", "\n", "", "", "else", ":", "\n", "                ", "decoded", "=", "embedded_image", "\n", "\n", "# Loop though list of reduction indices for building the rsd upsampling layers", "\n", "", "if", "self", ".", "rsd", "is", "not", "None", "and", "len", "(", "self", ".", "rsd", ")", ">", "0", ":", "\n", "                ", "for", "i", "in", "sorted", "(", "self", ".", "rsd", ",", "reverse", "=", "True", ")", ":", "\n", "                    ", "reduction_index", "=", "i", "-", "1", "\n", "print", "(", "\"Building residual skip decoder with reduction {}\"", ".", "format", "(", "i", ")", ")", "\n", "decoded", "=", "self", ".", "residual_skip_decoder", "(", "decoded", ",", "skip_connections", "[", "reduction_index", "]", ",", "\n", "num_output_filters", "=", "self", ".", "aspp_dimension", ",", "var_scope_index", "=", "reduction_index", ")", "\n", "\n", "", "", "if", "self", ".", "_final_layer_dropout", "is", "not", "None", ":", "\n", "                ", "decoded", "=", "self", ".", "_final_layer_dropout", "(", "decoded", ",", "training", "=", "self", ".", "is_training_ph", ")", "\n", "\n", "", "print", "(", "\"final feature tensor: {}\"", ".", "format", "(", "decoded", ")", ")", "\n", "decoded", "=", "tf", ".", "layers", ".", "conv2d", "(", "decoded", ",", "self", ".", "n_output_channels", ",", "[", "1", ",", "1", "]", ",", "padding", "=", "\"SAME\"", ",", "activation", "=", "None", ",", "\n", "name", "=", "FINAL_LAYER_WEIGHTS_NAME", ",", "kernel_initializer", "=", "self", ".", "final_layer_weights_initializer", ",", "\n", "use_bias", "=", "True", ")", "\n", "\n", "# If using variable sized images in a batch, will have to implement something like this using map_fn:", "\n", "# https://stackoverflow.com/questions/48755945/resize-images-with-a-batch", "\n", "self", ".", "logits", "=", "tf", ".", "image", ".", "resize_images", "(", "decoded", ",", "self", ".", "input_shape", "[", "1", ":", "3", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BILINEAR", ",", "\n", "align_corners", "=", "True", ")", "\n", "self", ".", "flat_logits", "=", "tf", ".", "reshape", "(", "self", ".", "logits", ",", "[", "-", "1", ",", "self", ".", "n_output_channels", "]", ")", "\n", "probs", "=", "tf", ".", "nn", ".", "softmax", "(", "self", ".", "logits", ")", "\n", "\n", "self", ".", "predictions", "=", "self", ".", "_probabilities_to_classes", "(", "probs", ")", "\n", "return", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.residual_skip_decoder": [[179, 232], ["print", "print", "tensorflow.layers.conv2d", "tensorflow.nn.swish", "tensorflow.layers.batch_normalization", "tensorflow.shape", "tensorflow.reduce_mean", "tensorflow.tile", "tensorflow.variable_scope", "tensorflow.image.resize_images", "tensorflow.concat", "print", "print", "efficientlab.EfficientLab.residual_skip_decoder.conv_nl_bn_branch"], "methods", ["None"], ["", "", "def", "residual_skip_decoder", "(", "self", ",", "embedded_image", ":", "tf", ".", "Tensor", ",", "skip_connection", ":", "tf", ".", "Tensor", ",", "\n", "conv_over_contatenated_features", ":", "bool", "=", "True", ",", "num_output_filters", ":", "int", "=", "112", ",", "var_scope_index", ":", "int", "=", "0", ",", "\n", ")", "->", "tf", ".", "Tensor", ":", "\n", "        ", "print", "(", "\"Building residual skip decoding module.\"", ")", "\n", "print", "(", "\"Skip connection tensor: {}\"", ".", "format", "(", "skip_connection", ")", ")", "\n", "\n", "def", "conv_nl_bn_branch", "(", "features", ",", "num_filters", ",", "kernel_size", ",", "dilation_rate", "=", "1", ")", ":", "\n", "            ", "features", "=", "tf", ".", "layers", ".", "conv2d", "(", "features", ",", "filters", "=", "num_filters", ",", "kernel_size", "=", "[", "kernel_size", ",", "kernel_size", "]", ",", "\n", "dilation_rate", "=", "[", "dilation_rate", ",", "dilation_rate", "]", ",", "padding", "=", "\"SAME\"", ",", "\n", "use_bias", "=", "True", ")", "\n", "features", "=", "tf", ".", "nn", ".", "swish", "(", "features", ")", "\n", "return", "tf", ".", "layers", ".", "batch_normalization", "(", "features", ",", "training", "=", "self", ".", "is_training_ph", ")", "\n", "\n", "", "def", "pool_image_features", "(", "features", ")", ":", "\n", "            ", "\"\"\"Computes mean embedded image.\"\"\"", "\n", "input_shape", "=", "tf", ".", "shape", "(", "features", ")", "\n", "features", "=", "tf", ".", "reduce_mean", "(", "features", ",", "axis", "=", "[", "1", ",", "2", "]", ",", "keep_dims", "=", "True", ")", "\n", "features", "=", "tf", ".", "tile", "(", "features", ",", "multiples", "=", "[", "1", ",", "input_shape", "[", "1", "]", ",", "input_shape", "[", "2", "]", ",", "1", "]", ")", "\n", "return", "features", "\n", "\n", "", "legacy_var_scope_name", "=", "False", "# FIXME: delete these conditionals and use only one var scope naming pattern.", "\n", "if", "legacy_var_scope_name", ":", "\n", "            ", "var_scope_name", "=", "\"decode_skip_connections\"", "\n", "", "else", ":", "\n", "            ", "var_scope_name", "=", "\"decode_skip_connections_{}\"", ".", "format", "(", "var_scope_index", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "var_scope_name", ")", ":", "\n", "            ", "upsampled", "=", "tf", ".", "image", ".", "resize_images", "(", "embedded_image", ",", "tf", ".", "shape", "(", "skip_connection", ")", "[", "1", ":", "3", "]", ",", "\n", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BILINEAR", ",", "align_corners", "=", "True", ")", "\n", "\n", "decoded", "=", "tf", ".", "concat", "(", "[", "upsampled", ",", "skip_connection", "]", ",", "axis", "=", "-", "1", ")", "\n", "print", "(", "\"Concatenated deep and skip feature maps: {}\"", ".", "format", "(", "decoded", ")", ")", "\n", "\n", "if", "conv_over_contatenated_features", ":", "\n", "                ", "print", "(", "\"Convolving over concatenated feature maps in decoding layers.\"", ")", "\n", "if", "upsampled", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "!=", "num_output_filters", ":", "\n", "                    ", "print", "(", "\"Increasing upsampled skip connection number of filters with 1x1 conv.\"", ")", "\n", "upsampled", "=", "conv_nl_bn_branch", "(", "upsampled", ",", "num_output_filters", ",", "1", ",", "1", ")", "\n", "\n", "", "num_decoded_filters", "=", "upsampled", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "branch_0", "=", "conv_nl_bn_branch", "(", "decoded", ",", "num_decoded_filters", ",", "1", ")", "\n", "branch_1", "=", "conv_nl_bn_branch", "(", "decoded", ",", "num_decoded_filters", ",", "3", ",", "2", ")", "\n", "branch_2", "=", "pool_image_features", "(", "decoded", ")", "\n", "\n", "pyramid", "=", "tf", ".", "concat", "(", "[", "branch_0", ",", "branch_1", ",", "branch_2", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "decoded", "=", "conv_nl_bn_branch", "(", "pyramid", ",", "num_output_filters", ",", "3", ")", "\n", "\n", "if", "not", "self", ".", "disable_lsd_residual_connections", ":", "\n", "                    ", "print", "(", "\"Building residual connection in RSD module.\"", ")", "\n", "# Residual connection", "\n", "decoded", "+=", "upsampled", "\n", "\n", "", "", "return", "decoded", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.build_efficientnet": [[234, 247], ["models.efficientnet.efficientnet_builder.build_model_base"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.build_model_base"], ["", "", "def", "build_efficientnet", "(", "self", ",", "image", ")", "->", "Tuple", "[", "tf", ".", "Tensor", ",", "List", "[", "tf", ".", "Tensor", "]", "]", ":", "\n", "        ", "\"\"\"\n        Returns EfficientNet embedded image and skip connections.\n\n        Use endpoints['reduction_i'] for detection/segmentation, as the last intermediate feature with reduction level i. For example, if input image has resolution 224x224, then:\n        endpoints['reduction_1'] has resolution 112x112\n        endpoints['reduction_2'] has resolution 56x56\n        endpoints['reduction_3'] has resolution 28x28\n        endpoints['reduction_4'] has resolution 14x14\n        endpoints['reduction_5'] has resolution 7x7\n        \"\"\"", "\n", "features", ",", "endpoints", "=", "efficientnet_builder", ".", "build_model_base", "(", "image", ",", "self", ".", "feature_extractor_name", ",", "training", "=", "self", ".", "is_training_ph", ",", "max_block_num", "=", "self", ".", "max_block_num", ")", "\n", "return", "endpoints", "[", "'reduction_4'", "]", ",", "[", "endpoints", "[", "'reduction_1'", "]", ",", "endpoints", "[", "'reduction_2'", "]", ",", "endpoints", "[", "'reduction_3'", "]", ",", "endpoints", "[", "'reduction_4'", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.aspp": [[248, 290], ["print", "tensorflow.variable_scope", "tensorflow.shape", "tensorflow.concat", "tensorflow.layers.conv2d", "tensorflow.nn.swish", "tensorflow.layers.dropout", "tensorflow.variable_scope", "tensorflow.layers.conv2d", "tensorflow.nn.swish", "tensorflow.layers.dropout", "tensorflow.variable_scope", "tensorflow.layers.conv2d", "tensorflow.nn.swish", "tensorflow.layers.dropout", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.layers.conv2d", "tensorflow.layers.dropout", "tensorflow.nn.swish", "tensorflow.image.resize_images"], "methods", ["None"], ["", "def", "aspp", "(", "self", ",", "inputs", ",", "dropout_rate", "=", "0.5", ",", "residual_connection", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Auto-DeepLab style Atrous Spatial Pyramid Pooling with dropout in place of batch norm, potentially with residual\n        connection.\n         \"\"\"", "\n", "print", "(", "\"Building atrous spatial pyramid pooling layers.\"", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"spatial_pyramid_pooling\"", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "input_shape", "=", "tf", ".", "shape", "(", "inputs", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"branch_0\"", ")", ":", "\n", "                ", "b0", "=", "tf", ".", "layers", ".", "conv2d", "(", "inputs", ",", "self", ".", "aspp_dimension", ",", "[", "1", ",", "1", "]", ",", "use_bias", "=", "True", ",", "padding", "=", "\"SAME\"", ")", "\n", "b0", "=", "tf", ".", "nn", ".", "swish", "(", "b0", ")", "\n", "b0", "=", "tf", ".", "layers", ".", "dropout", "(", "b0", ",", "rate", "=", "dropout_rate", ",", "training", "=", "self", ".", "is_training_ph", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"branch_1\"", ")", ":", "\n", "# Following auto-deeplab, atrous convolution with rate = 96/(downsample_factor)", "\n", "# which equals 6 where downsample_factor = 16 (4 halvings).", "\n", "                ", "b1", "=", "tf", ".", "layers", ".", "conv2d", "(", "inputs", ",", "self", ".", "aspp_dimension", ",", "3", ",", "dilation_rate", "=", "6", ",", "use_bias", "=", "True", ",", "padding", "=", "\"SAME\"", ")", "\n", "b1", "=", "tf", ".", "nn", ".", "swish", "(", "b1", ")", "\n", "b1", "=", "tf", ".", "layers", ".", "dropout", "(", "b1", ",", "rate", "=", "dropout_rate", ",", "training", "=", "self", ".", "is_training_ph", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"branch_2\"", ")", ":", "\n", "# mean embedded image:", "\n", "                ", "b2", "=", "tf", ".", "reduce_mean", "(", "inputs", ",", "axis", "=", "[", "1", ",", "2", "]", ")", "\n", "b2", "=", "tf", ".", "expand_dims", "(", "b2", ",", "-", "1", ")", "\n", "b2", "=", "tf", ".", "expand_dims", "(", "b2", ",", "-", "1", ")", "\n", "b2", "=", "tf", ".", "layers", ".", "conv2d", "(", "b2", ",", "self", ".", "aspp_dimension", ",", "[", "1", ",", "1", "]", ",", "use_bias", "=", "True", ",", "padding", "=", "\"SAME\"", ")", "\n", "b2", "=", "tf", ".", "layers", ".", "dropout", "(", "b2", ",", "rate", "=", "dropout_rate", ",", "training", "=", "self", ".", "is_training_ph", ")", "\n", "b2", "=", "tf", ".", "nn", ".", "swish", "(", "b2", ")", "\n", "b2", "=", "tf", ".", "image", ".", "resize_images", "(", "b2", ",", "input_shape", "[", "1", ":", "3", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BILINEAR", ",", "align_corners", "=", "True", ")", "\n", "\n", "", "x", "=", "tf", ".", "concat", "(", "[", "b2", ",", "b1", ",", "b0", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "output_embedding_dim", "=", "self", ".", "aspp_dimension", "\n", "\n", "x", "=", "tf", ".", "layers", ".", "conv2d", "(", "x", ",", "output_embedding_dim", ",", "[", "1", ",", "1", "]", ",", "padding", "=", "\"SAME\"", ",", "use_bias", "=", "True", ")", "\n", "x", "=", "tf", ".", "nn", ".", "swish", "(", "x", ")", "\n", "x", "=", "tf", ".", "layers", ".", "dropout", "(", "x", ",", "rate", "=", "dropout_rate", ",", "training", "=", "self", ".", "is_training_ph", ")", "\n", "\n", "if", "residual_connection", ":", "\n", "                ", "x", "+=", "inputs", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab._probabilities_to_classes": [[291, 293], ["tensorflow.cast", "tensorflow.to_float"], "methods", ["None"], ["", "", "def", "_probabilities_to_classes", "(", "self", ",", "probabilities", ",", "thresh", "=", "0.5", ")", ":", "\n", "        ", "return", "tf", ".", "cast", "(", "tf", ".", "to_float", "(", "probabilities", ">", "thresh", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.build_optimizer": [[294, 318], ["print", "tensorflow.reduce_mean", "efficientlab.EfficientLab._iou", "print", "tensorflow.placeholder_with_default", "efficientlab.EfficientLab.optimizer_class", "tensorflow.get_collection", "tensorflow.losses.softmax_cross_entropy", "efficientlab.EfficientLab._soft_dice", "print", "models.regularizers.darc1_term", "print", "models.regularizers.l2_term", "print", "models.regularizers.l1_term", "tensorflow.control_dependencies", "efficientlab.EfficientLab.optimizer.minimize"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko._iou", "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab._soft_dice", "home.repos.pwc.inspect_result.ml4ai_mliis.models.regularizers.darc1_term", "home.repos.pwc.inspect_result.ml4ai_mliis.models.regularizers.l2_term", "home.repos.pwc.inspect_result.ml4ai_mliis.models.regularizers.l1_term"], ["", "def", "build_optimizer", "(", "self", ",", "**", "optim_kwargs", ")", ":", "\n", "        ", "print", "(", "\"Label smoothing epsilon: {}\"", ".", "format", "(", "optim_kwargs", "[", "\"label_smoothing\"", "]", ")", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "losses", ".", "softmax_cross_entropy", "(", "self", ".", "flat_label_ph", ",", "logits", "=", "self", ".", "flat_logits", ",", "label_smoothing", "=", "optim_kwargs", "[", "\"label_smoothing\"", "]", ")", ")", "\n", "self", ".", "iou", "=", "self", ".", "_iou", "(", "self", ".", "label_ph", ",", "self", ".", "probabilities", ")", "\n", "print", "(", "\"Defining optimizer with default learning rate: {}\"", ".", "format", "(", "optim_kwargs", "[", "\"learning_rate\"", "]", ")", ")", "\n", "self", ".", "lr_ph", "=", "tf", ".", "placeholder_with_default", "(", "optim_kwargs", "[", "\"learning_rate\"", "]", ",", "shape", "=", "[", "]", ")", "\n", "self", ".", "optimizer", "=", "self", ".", "optimizer_class", "(", "learning_rate", "=", "self", ".", "lr_ph", ")", "\n", "if", "self", ".", "dice", ":", "\n", "            ", "loss", "=", "self", ".", "_soft_dice", "(", "loss", ",", "self", ".", "iou", ")", "\n", "", "if", "self", ".", "darc1", ":", "\n", "            ", "print", "(", "\"Adding darc1 term to loss\"", ")", "\n", "loss", "+=", "darc1_term", "(", "self", ".", "logits", ")", "\n", "", "if", "self", ".", "l2", ":", "\n", "            ", "print", "(", "\"Adding l2 weight decay term to loss\"", ")", "\n", "loss", "+=", "l2_term", "(", ")", "\n", "", "if", "self", ".", "l1", ":", "\n", "            ", "print", "(", "\"Adding l1 weight decay term to loss\"", ")", "\n", "loss", "+=", "l1_term", "(", ")", "\n", "", "self", ".", "loss", "=", "loss", "\n", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "update_ops", ")", ":", "\n", "            ", "self", ".", "minimize_op", "=", "self", ".", "optimizer", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab._soft_dice": [[319, 328], ["print", "tensorflow.log"], "methods", ["None"], ["", "", "def", "_soft_dice", "(", "self", ",", "cross_entropy_loss", ":", "tf", ".", "Tensor", ",", "iou", ":", "tf", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Implements cross entropy minus the log of the dice.\n        BCE - ln(dice)\n        ref: http://blog.kaggle.com/2017/12/22/carvana-image-masking-first-place-interview/\n        \"\"\"", "\n", "print", "(", "\"Defining soft dice loss = CE - ln(dice)\"", ")", "\n", "dice", "=", "(", "2.", "*", "iou", ")", "/", "(", "iou", "+", "1.", ")", "\n", "return", "cross_entropy_loss", "-", "tf", ".", "log", "(", "dice", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab._binary_iou": [[329, 354], ["print", "tensorflow.reshape", "tensorflow.reshape", "efficientlab.EfficientLab._compute_iou", "Y_hat.get_shape().as_list", "Y_hat.get_shape"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab._compute_iou"], ["", "def", "_binary_iou", "(", "self", ",", "Y_true", ",", "Y_hat", ",", "epsilon", "=", "1e-7", ",", "true_class_in_first_channel", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Returns the intersection over union score of the batch for binary segmentation problems\n\n        intesection = Y_hat.flatten() * Y_true.flatten()\n        IOU = (intersection + epsilon) / (Y_hat.sum() + Y_true.sum() - intersection + epsilon)\n\n        :param Y_true: (4-D array): (N, H, W, 2)\n        :param Y_hat: (4-D array): (N, H, W, 2)\n        :return: floating point IoU score\n        \"\"\"", "\n", "if", "true_class_in_first_channel", ":", "\n", "            ", "Y_true_single_channel", "=", "Y_true", "[", ":", ",", ":", ",", ":", ",", "0", "]", "\n", "Y_hat_single_channel", "=", "Y_hat", "[", ":", ",", ":", ",", ":", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "Y_true_single_channel", "=", "Y_true", "[", ":", ",", ":", ",", ":", ",", "1", "]", "\n", "Y_hat_single_channel", "=", "Y_hat", "[", ":", ",", ":", ",", ":", ",", "1", "]", "\n", "\n", "", "print", "(", "\"_iou tensors:\"", ")", "\n", "height", ",", "width", ",", "_", "=", "Y_hat", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "\n", "pred_flat", "=", "tf", ".", "reshape", "(", "Y_hat_single_channel", ",", "[", "-", "1", ",", "height", "*", "width", "]", ")", "\n", "true_flat", "=", "tf", ".", "reshape", "(", "Y_true_single_channel", ",", "[", "-", "1", ",", "height", "*", "width", "]", ")", "\n", "\n", "return", "self", ".", "_compute_iou", "(", "true_flat", ",", "pred_flat", ",", "epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab._iou": [[355, 383], ["print", "print", "tensorflow.reshape", "tensorflow.reshape", "efficientlab.EfficientLab._compute_iou", "efficientlab.EfficientLab._binary_iou", "Y_hat.get_shape().as_list", "Y_hat.get_shape"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab._compute_iou", "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab._binary_iou"], ["", "def", "_iou", "(", "self", ",", "Y_true", ",", "Y_hat", ",", "epsilon", "=", "1e-7", ",", "exclude_bg_channel", ":", "bool", "=", "False", ")", "->", "tf", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Returns the intersection over union score of the batch for image segmentation problems\n\n        intesection = Y_hat.flatten() * Y_true.flatten()\n        IOU = (intersection + epsilon) / (Y_hat.sum() + Y_true.sum() - intersection + epsilon)\n\n        :param Y_true: (4-D array): (N, H, W, C)\n        :param Y_hat: (4-D array): (N, H, W, C)\n        :return: floating point IoU score\n        \"\"\"", "\n", "if", "self", ".", "binary_iou_loss", ":", "\n", "            ", "return", "self", ".", "_binary_iou", "(", "Y_true", ",", "Y_hat", ",", "epsilon", ")", "\n", "\n", "# multi_class_iou", "\n", "", "if", "self", ".", "seperate_background_channel", "and", "exclude_bg_channel", ":", "\n", "            ", "Y_true", "=", "Y_true", "[", ":", ",", ":", ",", ":", ",", "1", ":", "]", "# Background class is assumed to be in first channel, so we skip it", "\n", "Y_hat", "=", "Y_hat", "[", ":", ",", ":", ",", ":", ",", "1", ":", "]", "\n", "\n", "", "print", "(", "\"_iou tensors:\"", ")", "\n", "height", ",", "width", ",", "depth", "=", "Y_hat", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "print", "(", "\"height: {}, width: {}, depth: {}\"", ".", "format", "(", "height", ",", "width", ",", "depth", ")", ")", "\n", "\n", "pred_flat", "=", "tf", ".", "reshape", "(", "Y_hat", ",", "[", "-", "1", ",", "height", "*", "width", "*", "depth", "]", ")", "\n", "true_flat", "=", "tf", ".", "reshape", "(", "Y_true", ",", "[", "-", "1", ",", "height", "*", "width", "*", "depth", "]", ")", "\n", "# -> shape=(batch, height * width * depth)", "\n", "\n", "return", "self", ".", "_compute_iou", "(", "true_flat", ",", "pred_flat", ",", "epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab._compute_iou": [[385, 397], ["print", "print", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "methods", ["None"], ["", "def", "_compute_iou", "(", "self", ",", "true", ",", "pred", ",", "epsilon", "=", "1e-7", ")", ":", "\n", "        ", "\"\"\"\n        Compute the IoU between two unrolled tensors of shape=(batch, d),\n        where d is the number of scalars to compare.\n        \"\"\"", "\n", "print", "(", "'pred_flat: {}'", ".", "format", "(", "pred", ")", ")", "\n", "print", "(", "'true_flat: {}'", ".", "format", "(", "true", ")", ")", "\n", "\n", "intersection", "=", "tf", ".", "reduce_sum", "(", "pred", "*", "true", ",", "axis", "=", "1", ")", "\n", "denominator", "=", "tf", ".", "reduce_sum", "(", "pred", ",", "axis", "=", "1", ")", "+", "tf", ".", "reduce_sum", "(", "true", ",", "axis", "=", "1", ")", "-", "intersection", "\n", "\n", "return", "tf", ".", "reduce_mean", "(", "(", "intersection", "+", "epsilon", ")", "/", "(", "denominator", "+", "epsilon", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.restore_model": [[398, 444], ["sess.run", "sess.run", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print", "print", "isinstance", "isinstance", "tensorflow.global_variables_initializer", "utils.util.latest_checkpoint", "tensorflow.train.latest_checkpoint", "tensorflow.train.ExponentialMovingAverage", "tensorflow.global_variables", "list", "tensorflow.train.ExponentialMovingAverage.variables_to_restore", "tensorflow.train.ExponentialMovingAverage.apply", "list", "tensorflow.global_variables_initializer", "tensorflow.train.Saver", "tensorflow.train.Saver.save", "tensorflow.trainable_variables", "tensorflow.get_collection", "set", "set", "sess.run", "len", "list.append", "tensorflow.global_variables", "tf.train.ExponentialMovingAverage.variables_to_restore.items", "key.startswith", "tf.train.ExponentialMovingAverage.variables_to_restore.items", "any", "tf.train.ExponentialMovingAverage.variables_to_restore.items", "any", "key.startswith", "key.startswith", "key.startswith"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.latest_checkpoint", "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.latest_checkpoint"], ["", "def", "restore_model", "(", "self", ",", "sess", ",", "ckpt_dir", ",", "enable_ema", "=", "False", ",", "export_ckpt", "=", "None", ",", "filter_to_scopes", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "filter_out_scope", ":", "Optional", "[", "str", "]", "=", "None", ",", "convert_ckpt_to_rel_path", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"Restore variables from checkpoint dir.\"\"\"", "\n", "assert", "isinstance", "(", "filter_to_scopes", ",", "list", ")", "or", "filter_to_scopes", "is", "None", "\n", "assert", "isinstance", "(", "filter_out_scope", ",", "str", ")", "or", "filter_out_scope", "is", "None", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "if", "convert_ckpt_to_rel_path", ":", "\n", "            ", "checkpoint", "=", "latest_checkpoint", "(", "ckpt_dir", ",", "return_relative", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "ckpt_dir", ")", "\n", "", "if", "enable_ema", ":", "\n", "            ", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "0.0", ")", "\n", "ema_vars", "=", "tf", ".", "trainable_variables", "(", ")", "+", "tf", ".", "get_collection", "(", "'moving_vars'", ")", "\n", "for", "v", "in", "tf", ".", "global_variables", "(", ")", ":", "\n", "                ", "if", "'moving_mean'", "in", "v", ".", "name", "or", "'moving_variance'", "in", "v", ".", "name", ":", "\n", "                    ", "ema_vars", ".", "append", "(", "v", ")", "\n", "", "", "ema_vars", "=", "list", "(", "set", "(", "ema_vars", ")", ")", "\n", "var_dict", "=", "ema", ".", "variables_to_restore", "(", "ema_vars", ")", "\n", "ema_assign_op", "=", "ema", ".", "apply", "(", "ema_vars", ")", "\n", "", "else", ":", "\n", "            ", "var_dict", "=", "{", "}", "\n", "for", "v", "in", "list", "(", "set", "(", "tf", ".", "global_variables", "(", ")", ")", ")", ":", "\n", "                ", "var_dict", "[", "v", ".", "op", ".", "name", "]", "=", "v", "\n", "\n", "", "ema_assign_op", "=", "None", "\n", "\n", "", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "if", "filter_to_scopes", "is", "None", "and", "filter_out_scope", "is", "not", "None", ":", "\n", "            ", "var_dict", "=", "{", "key", ":", "value", "for", "key", ",", "value", "in", "var_dict", ".", "items", "(", ")", "if", "not", "key", ".", "startswith", "(", "filter_out_scope", ")", "}", "\n", "", "elif", "filter_to_scopes", "is", "not", "None", "and", "filter_out_scope", "is", "not", "None", ":", "\n", "            ", "var_dict", "=", "{", "key", ":", "value", "for", "key", ",", "value", "in", "var_dict", ".", "items", "(", ")", "if", "any", "(", "[", "key", ".", "startswith", "(", "x", ")", "for", "x", "in", "filter_to_scopes", "]", ")", "and", "not", "key", ".", "startswith", "(", "filter_out_scope", ")", "}", "\n", "", "elif", "filter_to_scopes", "is", "not", "None", ":", "\n", "            ", "var_dict", "=", "{", "key", ":", "value", "for", "key", ",", "value", "in", "var_dict", ".", "items", "(", ")", "if", "any", "(", "[", "key", ".", "startswith", "(", "x", ")", "for", "x", "in", "filter_to_scopes", "]", ")", "}", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_dict", ",", "max_to_keep", "=", "1", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "\n", "self", ".", "variables_initialized", "=", "True", "\n", "print", "(", "\"Variables initialized\"", ")", "\n", "\n", "if", "export_ckpt", ":", "\n", "            ", "if", "ema_assign_op", "is", "not", "None", ":", "\n", "                ", "sess", ".", "run", "(", "ema_assign_op", ")", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "2", ")", "\n", "saver", ".", "save", "(", "sess", ",", "export_ckpt", ")", "\n", "", "print", "(", "\"{} variables restored\"", ".", "format", "(", "len", "(", "var_dict", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.EfficientLab.sep_conv": [[445, 475], ["tensorflow.layers.batch_normalization", "tensorflow.nn.swish", "tensorflow.layers.conv2d", "tensorflow.nn.swish", "tensorflow.keras.layers.DepthwiseConv2D", "tensorflow.layers.batch_normalization"], "methods", ["None"], ["", "def", "sep_conv", "(", "self", ",", "inputs", ":", "tf", ".", "Tensor", ",", "\n", "filters", ":", "int", ",", "\n", "kernel_size", ":", "int", ",", "\n", "strides", ":", "int", "=", "1", ",", "\n", "dilation_rate", ":", "int", "=", "1", ",", "\n", "depth_multiplier", ":", "int", "=", "1", "\n", ")", "->", "tf", ".", "Tensor", ":", "\n", "        ", "\"\"\"Depth-wise separable convolution\"\"\"", "\n", "# Depth-wise convolution phase:", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "DepthwiseConv2D", "(", "\n", "[", "kernel_size", ",", "kernel_size", "]", ",", "\n", "depth_multiplier", "=", "depth_multiplier", ",", "\n", "strides", "=", "strides", ",", "\n", "dilation_rate", "=", "dilation_rate", ",", "\n", "padding", "=", "\"SAME\"", ",", "\n", "use_bias", "=", "False", ",", "\n", "depthwise_initializer", "=", "self", ".", "weights_initializer", ")", "(", "inputs", ")", "\n", "x", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "x", ",", "training", "=", "True", ")", "\n", "x", "=", "tf", ".", "nn", ".", "swish", "(", "x", ")", "\n", "\n", "# Output phase:", "\n", "x", "=", "tf", ".", "layers", ".", "conv2d", "(", "\n", "x", ",", "\n", "filters", ",", "\n", "kernel_size", "=", "[", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "1", "]", ",", "\n", "kernel_initializer", "=", "self", ".", "weights_initializer", ",", "\n", "padding", "=", "\"SAME\"", ",", "\n", "use_bias", "=", "False", ")", "\n", "return", "tf", ".", "nn", ".", "swish", "(", "tf", ".", "layers", ".", "batch_normalization", "(", "x", ",", "training", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.glorot_uniform_initializer": [[477, 495], ["print", "int", "int", "print", "print", "numpy.sqrt", "tensorflow.random_uniform"], "function", ["None"], ["", "", "def", "glorot_uniform_initializer", "(", "shape", ",", "dtype", "=", "None", ",", "partition_info", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    The Glorot uniform initializer, also called Xavier uniform initializer.\n\n    It draws samples from a uniform distribution within [-limit, limit]\n    where `limit` is `sqrt(6 / (fan_in + fan_out))`\n    where `fan_in` is the number of input units in the weight tensor\n    and `fan_out` is the number of output units in the weight tensor.\n    \"\"\"", "\n", "print", "(", "\"Initializing tensor with Glorot uniform.\"", ")", "\n", "del", "partition_info", "\n", "kernel_height", ",", "kernel_width", ",", "in_filters", ",", "out_filters", "=", "shape", "\n", "fan_in", "=", "int", "(", "kernel_height", "*", "kernel_width", "*", "in_filters", ")", "\n", "fan_out", "=", "int", "(", "kernel_height", "*", "kernel_width", "*", "out_filters", ")", "\n", "print", "(", "\"fan_in {}\"", ".", "format", "(", "fan_in", ")", ")", "\n", "print", "(", "\"fan_out {}\"", ".", "format", "(", "fan_out", ")", ")", "\n", "limit", "=", "np", ".", "sqrt", "(", "6.", "/", "fan_in", "+", "fan_out", ")", "\n", "return", "tf", ".", "random_uniform", "(", "shape", ",", "-", "limit", ",", "limit", ",", "dtype", "=", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.efficientlab.glorot_normal_initializer": [[497, 523], ["print", "int", "int", "print", "print", "tensorflow.random_normal", "numpy.sqrt"], "function", ["None"], ["", "def", "glorot_normal_initializer", "(", "shape", ",", "dtype", "=", "None", ",", "partition_info", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    The Glorot normal initializer, also called Xavier normal initializer.\n\n    Draws samples from a normal distribution centered on 0\n    with standard deviation given by\n    `stddev = sqrt(2 / (fan_in + fan_out))` where `fan_in` is the number\n    of input units in the weight tensor and `fan_out` is the number of\n    output units in the weight tensor.\n    Args:\n        shape:\n        dtype:\n        partition_info:\n\n    Returns:\n        An initialization for the variable\n    \"\"\"", "\n", "print", "(", "\"Initializing tensor with Glorot normal.\"", ")", "\n", "del", "partition_info", "\n", "kernel_height", ",", "kernel_width", ",", "in_filters", ",", "out_filters", "=", "shape", "\n", "fan_in", "=", "int", "(", "kernel_height", "*", "kernel_width", "*", "in_filters", ")", "\n", "fan_out", "=", "int", "(", "kernel_height", "*", "kernel_width", "*", "out_filters", ")", "\n", "print", "(", "\"fan_in {}\"", ".", "format", "(", "fan_in", ")", ")", "\n", "print", "(", "\"fan_out {}\"", ".", "format", "(", "fan_out", ")", ")", "\n", "return", "tf", ".", "random_normal", "(", "\n", "shape", ",", "mean", "=", "0.0", ",", "stddev", "=", "np", ".", "sqrt", "(", "2.0", "/", "(", "fan_in", "+", "fan_out", ")", ")", ",", "dtype", "=", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.regularizers.l2_term": [[4, 11], ["tensorflow.identity", "tensorflow.add_n", "tensorflow.nn.l2_loss", "tensorflow.trainable_variables"], "function", ["None"], ["def", "l2_term", "(", "weight_decay", "=", "0.0005", ")", ":", "\n", "    ", "\"\"\"\n    L2 loss on trainable variables.\n    Adapted from tensorflow tpu efficientnet implementation\n    \"\"\"", "\n", "return", "tf", ".", "identity", "(", "weight_decay", "*", "tf", ".", "add_n", "(", "[", "tf", ".", "nn", ".", "l2_loss", "(", "v", ")", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "if", "'batch_normalization'", "not", "in", "v", ".", "name", "]", ")", ",", "name", "=", "\"l2\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.regularizers.l1_term": [[13, 19], ["tensorflow.identity", "tensorflow.add_n", "tensorflow.reduce_sum", "tensorflow.math.abs", "tensorflow.trainable_variables"], "function", ["None"], ["", "def", "l1_term", "(", "weight_decay", "=", "0.0005", ")", ":", "\n", "    ", "\"\"\"\n    L1 loss on trainable variables.\n    \"\"\"", "\n", "return", "tf", ".", "identity", "(", "weight_decay", "*", "tf", ".", "add_n", "(", "[", "tf", ".", "reduce_sum", "(", "tf", ".", "math", ".", "abs", "(", "v", ")", ")", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "if", "'batch_normalization'", "not", "in", "v", ".", "name", "]", ")", ",", "name", "=", "\"l1\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.regularizers.darc1_term": [[20, 23], ["tensorflow.identity", "tensorflow.reduce_max", "tensorflow.reduce_sum", "tensorflow.abs"], "function", ["None"], ["", "def", "darc1_term", "(", "logits", ",", "weight", "=", "0.0005", ")", ":", "\n", "    ", "\"\"\"Assumes batch dim is first.\"\"\"", "\n", "return", "tf", ".", "identity", "(", "weight", "*", "tf", ".", "reduce_max", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "abs", "(", "logits", ")", ",", "axis", "=", "0", ")", ",", "name", "=", "\"darc1\"", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.lr_schedulers.LRScheduler.__init__": [[7, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "initial_lr", ":", "float", ",", "total_steps", ":", "int", ")", ":", "\n", "        ", "self", ".", "initial_lr", "=", "initial_lr", "\n", "self", ".", "total_steps", "=", "total_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.lr_schedulers.LRScheduler.anneal_lr": [[11, 14], ["None"], "methods", ["None"], ["", "def", "anneal_lr", "(", "self", ",", "cur_step", ":", "int", ")", ":", "\n", "        ", "\"\"\"Implemented by subclass\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.lr_schedulers.LRScheduler.cur_lr": [[15, 18], ["lr_schedulers.LRScheduler.anneal_lr"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.models.lr_schedulers.StepDecay.anneal_lr"], ["", "def", "cur_lr", "(", "self", ",", "cur_step", ")", ":", "\n", "        ", "lr", "=", "self", ".", "anneal_lr", "(", "cur_step", ")", "\n", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.lr_schedulers.CosineLRScheduler.__init__": [[22, 24], ["lr_schedulers.LRScheduler.__init__"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character.__init__"], ["    ", "def", "__init__", "(", "self", ",", "initial_lr", ":", "float", ",", "total_steps", ":", "int", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "initial_lr", ",", "total_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.lr_schedulers.CosineLRScheduler.anneal_lr": [[25, 29], ["numpy.max", "numpy.cos"], "methods", ["None"], ["", "def", "anneal_lr", "(", "self", ",", "cur_step", ":", "int", ",", "min_to_decay_to", ":", "float", "=", "0.0", ")", ":", "\n", "        ", "lr", "=", "0.5", "*", "self", ".", "initial_lr", "*", "(", "1", "+", "np", ".", "cos", "(", "np", ".", "pi", "*", "cur_step", "/", "self", ".", "total_steps", ")", ")", "\n", "lr", "=", "np", ".", "max", "(", "[", "lr", ",", "min_to_decay_to", "]", ")", "\n", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.lr_schedulers.StepDecay.__init__": [[33, 39], ["lr_schedulers.LRScheduler.__init__"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character.__init__"], ["    ", "def", "__init__", "(", "self", ",", "initial_lr", ":", "float", ",", "total_steps", ":", "Optional", "[", "int", "]", "=", "None", ",", "decay_rate", ":", "float", "=", "0.5", ",", "decay_after_n_steps", ":", "int", "=", "5", ",", "min_lr", ":", "float", "=", "1e-7", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "initial_lr", ",", "total_steps", ")", "\n", "assert", "decay_rate", "is", "not", "None", "and", "decay_after_n_steps", "is", "not", "None", "\n", "self", ".", "decay_rate", "=", "decay_rate", "\n", "self", ".", "decay_after_n_steps", "=", "decay_after_n_steps", "\n", "self", ".", "min_lr", "=", "min_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.models.lr_schedulers.StepDecay.anneal_lr": [[40, 49], ["None"], "methods", ["None"], ["", "def", "anneal_lr", "(", "self", ",", "cur_step", ":", "int", ",", "decay_rate", ":", "Optional", "[", "float", "]", "=", "None", ",", "decay_after_n_steps", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "if", "decay_after_n_steps", "is", "None", ":", "\n", "            ", "decay_after_n_steps", "=", "self", ".", "decay_after_n_steps", "\n", "", "if", "decay_rate", "is", "None", ":", "\n", "            ", "decay_rate", "=", "self", ".", "decay_rate", "\n", "", "m", "=", "cur_step", "//", "decay_after_n_steps", "\n", "lr", "=", "self", ".", "initial_lr", "*", "(", "decay_rate", "**", "m", ")", "\n", "lr", "=", "self", ".", "min_lr", "if", "lr", "<", "self", ".", "min_lr", "else", "lr", "\n", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.BlockDecoder._decode_block_string": [[48, 72], ["isinstance", "block_string.split", "models.efficientnet.efficientnet_model.BlockArgs", "re.split", "ValueError", "len", "len", "int", "int", "int", "int", "int", "float", "int", "int", "int"], "methods", ["None"], ["def", "_decode_block_string", "(", "self", ",", "block_string", ")", ":", "\n", "    ", "\"\"\"Gets a block through a string notation of arguments.\"\"\"", "\n", "assert", "isinstance", "(", "block_string", ",", "str", ")", "\n", "ops", "=", "block_string", ".", "split", "(", "'_'", ")", "\n", "options", "=", "{", "}", "\n", "for", "op", "in", "ops", ":", "\n", "      ", "splits", "=", "re", ".", "split", "(", "r'(\\d.*)'", ",", "op", ")", "\n", "if", "len", "(", "splits", ")", ">=", "2", ":", "\n", "        ", "key", ",", "value", "=", "splits", "[", ":", "2", "]", "\n", "options", "[", "key", "]", "=", "value", "\n", "\n", "", "", "if", "'s'", "not", "in", "options", "or", "len", "(", "options", "[", "'s'", "]", ")", "!=", "2", ":", "\n", "      ", "raise", "ValueError", "(", "'Strides options should be a pair of integers.'", ")", "\n", "\n", "", "return", "efficientnet_model", ".", "BlockArgs", "(", "\n", "kernel_size", "=", "int", "(", "options", "[", "'k'", "]", ")", ",", "\n", "num_repeat", "=", "int", "(", "options", "[", "'r'", "]", ")", ",", "\n", "input_filters", "=", "int", "(", "options", "[", "'i'", "]", ")", ",", "\n", "output_filters", "=", "int", "(", "options", "[", "'o'", "]", ")", ",", "\n", "expand_ratio", "=", "int", "(", "options", "[", "'e'", "]", ")", ",", "\n", "id_skip", "=", "(", "'noskip'", "not", "in", "block_string", ")", ",", "\n", "se_ratio", "=", "float", "(", "options", "[", "'se'", "]", ")", "if", "'se'", "in", "options", "else", "None", ",", "\n", "strides", "=", "[", "int", "(", "options", "[", "'s'", "]", "[", "0", "]", ")", ",", "int", "(", "options", "[", "'s'", "]", "[", "1", "]", ")", "]", ",", "\n", "conv_type", "=", "int", "(", "options", "[", "'c'", "]", ")", "if", "'c'", "in", "options", "else", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.BlockDecoder._encode_block_string": [[73, 89], ["args.append", "args.append"], "methods", ["None"], ["", "def", "_encode_block_string", "(", "self", ",", "block", ")", ":", "\n", "    ", "\"\"\"Encodes a block to a string.\"\"\"", "\n", "args", "=", "[", "\n", "'r%d'", "%", "block", ".", "num_repeat", ",", "\n", "'k%d'", "%", "block", ".", "kernel_size", ",", "\n", "'s%d%d'", "%", "(", "block", ".", "strides", "[", "0", "]", ",", "block", ".", "strides", "[", "1", "]", ")", ",", "\n", "'e%s'", "%", "block", ".", "expand_ratio", ",", "\n", "'i%d'", "%", "block", ".", "input_filters", ",", "\n", "'o%d'", "%", "block", ".", "output_filters", ",", "\n", "'c%d'", "%", "block", ".", "conv_type", ",", "\n", "]", "\n", "if", "block", ".", "se_ratio", ">", "0", "and", "block", ".", "se_ratio", "<=", "1", ":", "\n", "      ", "args", ".", "append", "(", "'se%s'", "%", "block", ".", "se_ratio", ")", "\n", "", "if", "block", ".", "id_skip", "is", "False", ":", "\n", "      ", "args", ".", "append", "(", "'noskip'", ")", "\n", "", "return", "'_'", ".", "join", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.BlockDecoder.decode": [[90, 110], ["isinstance", "efficientnet_builder.BlockDecoder._decode_block_string", "blocks_args.append", "print"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.BlockDecoder._decode_block_string"], ["", "def", "decode", "(", "self", ",", "string_list", ",", "max_block_num", "=", "None", ")", ":", "\n", "    ", "\"\"\"Decodes a list of string notations to specify blocks inside the network.\n\n    Args:\n      string_list: a list of strings, each string is a notation of block.\n\n    Returns:\n      A list of namedtuples to represent blocks arguments.\n    \"\"\"", "\n", "assert", "isinstance", "(", "string_list", ",", "list", ")", "\n", "blocks_args", "=", "[", "]", "\n", "num_blocks", "=", "0", "\n", "for", "block_string", "in", "string_list", ":", "\n", "      ", "block_args", "=", "self", ".", "_decode_block_string", "(", "block_string", ")", "\n", "num_blocks", "+=", "block_args", ".", "num_repeat", "\n", "if", "max_block_num", "is", "not", "None", "and", "num_blocks", ">", "max_block_num", "+", "1", ":", "# account for zero-indexed blocks", "\n", "          ", "print", "(", "\"more blocks than max_block_num. Stopping graph construction of more blocks at {} blocks.\"", ".", "format", "(", "max_block_num", ")", ")", "\n", "break", "\n", "", "blocks_args", ".", "append", "(", "block_args", ")", "\n", "", "return", "blocks_args", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.BlockDecoder.encode": [[111, 123], ["block_strings.append", "efficientnet_builder.BlockDecoder._encode_block_string"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.BlockDecoder._encode_block_string"], ["", "def", "encode", "(", "self", ",", "blocks_args", ")", ":", "\n", "    ", "\"\"\"Encodes a list of Blocks to a list of strings.\n\n    Args:\n      blocks_args: A list of namedtuples to represent blocks arguments.\n    Returns:\n      a list of strings, each string is a notation of block.\n    \"\"\"", "\n", "block_strings", "=", "[", "]", "\n", "for", "block", "in", "blocks_args", ":", "\n", "      ", "block_strings", ".", "append", "(", "self", ".", "_encode_block_string", "(", "block", ")", ")", "\n", "", "return", "block_strings", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.efficientnet_params": [[29, 43], ["None"], "function", ["None"], ["def", "efficientnet_params", "(", "model_name", ")", ":", "\n", "  ", "\"\"\"Get efficientnet params based on model name.\"\"\"", "\n", "params_dict", "=", "{", "\n", "# (width_coefficient, depth_coefficient, resolution, dropout_rate)", "\n", "'efficientnet-b0'", ":", "(", "1.0", ",", "1.0", ",", "224", ",", "0.2", ")", ",", "\n", "'efficientnet-b1'", ":", "(", "1.0", ",", "1.1", ",", "240", ",", "0.2", ")", ",", "\n", "'efficientnet-b2'", ":", "(", "1.1", ",", "1.2", ",", "260", ",", "0.3", ")", ",", "\n", "'efficientnet-b3'", ":", "(", "1.2", ",", "1.4", ",", "300", ",", "0.3", ")", ",", "\n", "'efficientnet-b4'", ":", "(", "1.4", ",", "1.8", ",", "380", ",", "0.4", ")", ",", "\n", "'efficientnet-b5'", ":", "(", "1.6", ",", "2.2", ",", "456", ",", "0.4", ")", ",", "\n", "'efficientnet-b6'", ":", "(", "1.8", ",", "2.6", ",", "528", ",", "0.5", ")", ",", "\n", "'efficientnet-b7'", ":", "(", "2.0", ",", "3.1", ",", "600", ",", "0.5", ")", ",", "\n", "}", "\n", "return", "params_dict", "[", "model_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.efficientnet": [[125, 150], ["models.efficientnet.efficientnet_model.GlobalParams", "efficientnet_builder.BlockDecoder", "efficientnet_builder.BlockDecoder.decode"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.BlockDecoder.decode"], ["", "", "def", "efficientnet", "(", "width_coefficient", "=", "None", ",", "\n", "depth_coefficient", "=", "None", ",", "\n", "dropout_rate", "=", "0.2", ",", "\n", "drop_connect_rate", "=", "0.2", ",", "max_block_num", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates an efficientnet model.\"\"\"", "\n", "blocks_args", "=", "[", "\n", "'r1_k3_s11_e1_i32_o16_se0.25'", ",", "'r2_k3_s22_e6_i16_o24_se0.25'", ",", "\n", "'r2_k5_s22_e6_i24_o40_se0.25'", ",", "'r3_k3_s22_e6_i40_o80_se0.25'", ",", "\n", "'r3_k5_s11_e6_i80_o112_se0.25'", ",", "'r4_k5_s22_e6_i112_o192_se0.25'", ",", "\n", "'r1_k3_s11_e6_i192_o320_se0.25'", ",", "\n", "]", "\n", "global_params", "=", "efficientnet_model", ".", "GlobalParams", "(", "\n", "batch_norm_momentum", "=", "0.99", ",", "\n", "batch_norm_epsilon", "=", "1e-3", ",", "\n", "dropout_rate", "=", "dropout_rate", ",", "\n", "drop_connect_rate", "=", "drop_connect_rate", ",", "\n", "data_format", "=", "'channels_last'", ",", "\n", "num_classes", "=", "1000", ",", "\n", "width_coefficient", "=", "width_coefficient", ",", "\n", "depth_coefficient", "=", "depth_coefficient", ",", "\n", "depth_divisor", "=", "8", ",", "\n", "min_depth", "=", "None", ",", "\n", "relu_fn", "=", "tf", ".", "nn", ".", "swish", ")", "\n", "decoder", "=", "BlockDecoder", "(", ")", "\n", "return", "decoder", ".", "decode", "(", "blocks_args", ",", "max_block_num", ")", ",", "global_params", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.get_model_params": [[152, 170], ["model_name.startswith", "tensorflow.logging.info", "tensorflow.logging.info", "efficientnet_builder.efficientnet_params", "efficientnet_builder.efficientnet", "NotImplementedError", "global_params._replace._replace"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.efficientnet_params", "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.efficientnet"], ["", "def", "get_model_params", "(", "model_name", ",", "override_params", ",", "max_block_num", "=", "None", ")", ":", "\n", "  ", "\"\"\"Get the block args and global params for a given model.\"\"\"", "\n", "if", "model_name", ".", "startswith", "(", "'efficientnet'", ")", ":", "\n", "    ", "width_coefficient", ",", "depth_coefficient", ",", "_", ",", "dropout_rate", "=", "(", "\n", "efficientnet_params", "(", "model_name", ")", ")", "\n", "blocks_args", ",", "global_params", "=", "efficientnet", "(", "\n", "width_coefficient", ",", "depth_coefficient", ",", "dropout_rate", ",", "max_block_num", "=", "max_block_num", ")", "\n", "", "else", ":", "\n", "    ", "raise", "NotImplementedError", "(", "'model name is not pre-defined: %s'", "%", "model_name", ")", "\n", "\n", "", "if", "override_params", ":", "\n", "# ValueError will be raised here if override_params has fields not included", "\n", "# in global_params.", "\n", "    ", "global_params", "=", "global_params", ".", "_replace", "(", "**", "override_params", ")", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "'global_params= %s'", ",", "global_params", ")", "\n", "tf", ".", "logging", ".", "info", "(", "'blocks_args= %s'", ",", "blocks_args", ")", "\n", "return", "blocks_args", ",", "global_params", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.build_model": [[172, 215], ["isinstance", "efficientnet_builder.get_model_params", "tensorflow.identity", "os.path.join", "tensorflow.variable_scope", "models.efficientnet.efficientnet_model.Model", "efficientnet_model.Model.", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "tensorflow.gfile.GFile", "tensorflow.logging.info", "f.write", "f.write", "f.write", "str", "str"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.get_model_params"], ["", "def", "build_model", "(", "images", ",", "\n", "model_name", ",", "\n", "training", ",", "\n", "override_params", "=", "None", ",", "\n", "model_dir", "=", "None", ")", ":", "\n", "  ", "\"\"\"A helper functiion to creates a model and returns predicted logits.\n\n  Args:\n    images: input images tensor.\n    model_name: string, the predefined model name.\n    training: boolean, whether the model is constructed for training.\n    override_params: A dictionary of params for overriding. Fields must exist in\n      efficientnet_model.GlobalParams.\n    model_dir: string, optional model dir for saving configs.\n\n  Returns:\n    logits: the logits tensor of classes.\n    endpoints: the endpoints for each layer.\n\n  Raises:\n    When model_name specified an undefined model, raises NotImplementedError.\n    When override_params has invalid fields, raises ValueError.\n  \"\"\"", "\n", "assert", "isinstance", "(", "images", ",", "tf", ".", "Tensor", ")", "\n", "blocks_args", ",", "global_params", "=", "get_model_params", "(", "model_name", ",", "override_params", ")", "\n", "\n", "if", "model_dir", ":", "\n", "    ", "param_file", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'model_params.txt'", ")", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "param_file", ")", ":", "\n", "      ", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "model_dir", ")", ":", "\n", "        ", "tf", ".", "gfile", ".", "MakeDirs", "(", "model_dir", ")", "\n", "", "with", "tf", ".", "gfile", ".", "GFile", "(", "param_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "tf", ".", "logging", ".", "info", "(", "'writing to %s'", "%", "param_file", ")", "\n", "f", ".", "write", "(", "'model_name= %s\\n\\n'", "%", "model_name", ")", "\n", "f", ".", "write", "(", "'global_params= %s\\n\\n'", "%", "str", "(", "global_params", ")", ")", "\n", "f", ".", "write", "(", "'blocks_args= %s\\n\\n'", "%", "str", "(", "blocks_args", ")", ")", "\n", "\n", "", "", "", "with", "tf", ".", "variable_scope", "(", "model_name", ")", ":", "\n", "    ", "model", "=", "efficientnet_model", ".", "Model", "(", "blocks_args", ",", "global_params", ")", "\n", "logits", "=", "model", "(", "images", ",", "training", "=", "training", ")", "\n", "\n", "", "logits", "=", "tf", ".", "identity", "(", "logits", ",", "'logits'", ")", "\n", "return", "logits", ",", "model", ".", "endpoints", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.build_model_base": [[217, 244], ["isinstance", "efficientnet_builder.get_model_params", "tensorflow.identity", "tensorflow.variable_scope", "models.efficientnet.efficientnet_model.Model", "efficientnet_model.Model."], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_builder.get_model_params"], ["", "def", "build_model_base", "(", "images", ",", "model_name", ",", "training", ",", "override_params", "=", "None", ",", "max_block_num", "=", "None", ")", ":", "\n", "  ", "\"\"\"A helper functiion to create a base model and return global_pool.\n\n  Args:\n    images: input images tensor.\n    model_name: string, the model name of a pre-defined MnasNet.\n    training: boolean, whether the model is constructed for training.\n    override_params: A dictionary of params for overriding. Fields must exist in\n      mnasnet_model.GlobalParams.\n\n  Returns:\n    features: global pool features.\n    endpoints: the endpoints for each layer.\n\n  Raises:\n    When model_name specified an undefined model, raises NotImplementedError.\n    When override_params has invalid fields, raises ValueError.\n  \"\"\"", "\n", "assert", "isinstance", "(", "images", ",", "tf", ".", "Tensor", ")", "\n", "blocks_args", ",", "global_params", "=", "get_model_params", "(", "model_name", ",", "override_params", ",", "max_block_num", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "model_name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "    ", "model", "=", "efficientnet_model", ".", "Model", "(", "blocks_args", ",", "global_params", ")", "\n", "features", "=", "model", "(", "images", ",", "training", "=", "training", ",", "features_only", "=", "True", ")", "\n", "\n", "", "features", "=", "tf", ".", "identity", "(", "features", ",", "'global_pool'", ")", "\n", "return", "features", ",", "model", ".", "endpoints", "\n", "", ""]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.MBConvBlock.__init__": [[140, 166], ["efficientnet_model.MBConvBlock._build"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.Model._build"], ["def", "__init__", "(", "self", ",", "block_args", ",", "global_params", ")", ":", "\n", "    ", "\"\"\"Initializes a MBConv block.\n\n    Args:\n      block_args: BlockArgs, arguments to create a Block.\n      global_params: GlobalParams, a set of global parameters.\n    \"\"\"", "\n", "self", ".", "_block_args", "=", "block_args", "\n", "self", ".", "_batch_norm_momentum", "=", "global_params", ".", "batch_norm_momentum", "\n", "self", ".", "_batch_norm_epsilon", "=", "global_params", ".", "batch_norm_epsilon", "\n", "self", ".", "_data_format", "=", "global_params", ".", "data_format", "\n", "if", "self", ".", "_data_format", "==", "'channels_first'", ":", "\n", "      ", "self", ".", "_channel_axis", "=", "1", "\n", "self", ".", "_spatial_dims", "=", "[", "2", ",", "3", "]", "\n", "", "else", ":", "\n", "      ", "self", ".", "_channel_axis", "=", "-", "1", "\n", "self", ".", "_spatial_dims", "=", "[", "1", ",", "2", "]", "\n", "\n", "", "self", ".", "_relu_fn", "=", "global_params", ".", "relu_fn", "or", "tf", ".", "nn", ".", "swish", "\n", "self", ".", "_has_se", "=", "(", "self", ".", "_block_args", ".", "se_ratio", "is", "not", "None", ")", "and", "(", "\n", "self", ".", "_block_args", ".", "se_ratio", ">", "0", ")", "and", "(", "self", ".", "_block_args", ".", "se_ratio", "<=", "1", ")", "\n", "\n", "self", ".", "endpoints", "=", "None", "\n", "\n", "# Builds the block according to arguments.", "\n", "self", ".", "_build", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.MBConvBlock.block_args": [[167, 169], ["None"], "methods", ["None"], ["", "def", "block_args", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_block_args", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.MBConvBlock._build": [[170, 237], ["models.efficientnet.utils.DepthwiseConv2D", "batchnorm", "tensorflow.layers.Conv2D", "batchnorm", "tensorflow.layers.Conv2D", "batchnorm", "max", "tensorflow.layers.Conv2D", "tensorflow.layers.Conv2D", "int"], "methods", ["None"], ["", "def", "_build", "(", "self", ")", ":", "\n", "    ", "\"\"\"Builds block according to the arguments.\"\"\"", "\n", "filters", "=", "self", ".", "_block_args", ".", "input_filters", "*", "self", ".", "_block_args", ".", "expand_ratio", "\n", "if", "self", ".", "_block_args", ".", "expand_ratio", "!=", "1", ":", "\n", "# Expansion phase:", "\n", "      ", "self", ".", "_expand_conv", "=", "tf", ".", "layers", ".", "Conv2D", "(", "\n", "filters", ",", "\n", "kernel_size", "=", "[", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "1", "]", ",", "\n", "kernel_initializer", "=", "conv_kernel_initializer", ",", "\n", "padding", "=", "'same'", ",", "\n", "data_format", "=", "self", ".", "_data_format", ",", "\n", "use_bias", "=", "False", ")", "\n", "self", ".", "_bn0", "=", "batchnorm", "(", "\n", "axis", "=", "self", ".", "_channel_axis", ",", "\n", "momentum", "=", "self", ".", "_batch_norm_momentum", ",", "\n", "epsilon", "=", "self", ".", "_batch_norm_epsilon", ")", "\n", "\n", "", "kernel_size", "=", "self", ".", "_block_args", ".", "kernel_size", "\n", "# Depth-wise convolution phase:", "\n", "self", ".", "_depthwise_conv", "=", "utils", ".", "DepthwiseConv2D", "(", "\n", "[", "kernel_size", ",", "kernel_size", "]", ",", "\n", "strides", "=", "self", ".", "_block_args", ".", "strides", ",", "\n", "depthwise_initializer", "=", "conv_kernel_initializer", ",", "\n", "padding", "=", "'same'", ",", "\n", "data_format", "=", "self", ".", "_data_format", ",", "\n", "use_bias", "=", "False", ")", "\n", "self", ".", "_bn1", "=", "batchnorm", "(", "\n", "axis", "=", "self", ".", "_channel_axis", ",", "\n", "momentum", "=", "self", ".", "_batch_norm_momentum", ",", "\n", "epsilon", "=", "self", ".", "_batch_norm_epsilon", ")", "\n", "\n", "if", "self", ".", "_has_se", ":", "\n", "      ", "num_reduced_filters", "=", "max", "(", "\n", "1", ",", "int", "(", "self", ".", "_block_args", ".", "input_filters", "*", "self", ".", "_block_args", ".", "se_ratio", ")", ")", "\n", "# Squeeze and Excitation layer.", "\n", "self", ".", "_se_reduce", "=", "tf", ".", "layers", ".", "Conv2D", "(", "\n", "num_reduced_filters", ",", "\n", "kernel_size", "=", "[", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "1", "]", ",", "\n", "kernel_initializer", "=", "conv_kernel_initializer", ",", "\n", "padding", "=", "'same'", ",", "\n", "data_format", "=", "self", ".", "_data_format", ",", "\n", "use_bias", "=", "True", ")", "\n", "self", ".", "_se_expand", "=", "tf", ".", "layers", ".", "Conv2D", "(", "\n", "filters", ",", "\n", "kernel_size", "=", "[", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "1", "]", ",", "\n", "kernel_initializer", "=", "conv_kernel_initializer", ",", "\n", "padding", "=", "'same'", ",", "\n", "data_format", "=", "self", ".", "_data_format", ",", "\n", "use_bias", "=", "True", ")", "\n", "\n", "# Output phase:", "\n", "", "filters", "=", "self", ".", "_block_args", ".", "output_filters", "\n", "self", ".", "_project_conv", "=", "tf", ".", "layers", ".", "Conv2D", "(", "\n", "filters", ",", "\n", "kernel_size", "=", "[", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "1", "]", ",", "\n", "kernel_initializer", "=", "conv_kernel_initializer", ",", "\n", "padding", "=", "'same'", ",", "\n", "data_format", "=", "self", ".", "_data_format", ",", "\n", "use_bias", "=", "False", ")", "\n", "self", ".", "_bn2", "=", "batchnorm", "(", "\n", "axis", "=", "self", ".", "_channel_axis", ",", "\n", "momentum", "=", "self", ".", "_batch_norm_momentum", ",", "\n", "epsilon", "=", "self", ".", "_batch_norm_epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.MBConvBlock._call_se": [[238, 252], ["tensorflow.reduce_mean", "efficientnet_model.MBConvBlock._se_expand", "tensorflow.logging.info", "efficientnet_model.MBConvBlock._relu_fn", "tensorflow.sigmoid", "efficientnet_model.MBConvBlock._se_reduce"], "methods", ["None"], ["", "def", "_call_se", "(", "self", ",", "input_tensor", ")", ":", "\n", "    ", "\"\"\"Call Squeeze and Excitation layer.\n\n    Args:\n      input_tensor: Tensor, a single input tensor for Squeeze/Excitation layer.\n\n    Returns:\n      A output tensor, which should have the same shape as input.\n    \"\"\"", "\n", "se_tensor", "=", "tf", ".", "reduce_mean", "(", "input_tensor", ",", "self", ".", "_spatial_dims", ",", "keepdims", "=", "True", ")", "\n", "se_tensor", "=", "self", ".", "_se_expand", "(", "self", ".", "_relu_fn", "(", "self", ".", "_se_reduce", "(", "se_tensor", ")", ")", ")", "\n", "tf", ".", "logging", ".", "info", "(", "'Built Squeeze and Excitation with tensor shape: %s'", "%", "\n", "(", "se_tensor", ".", "shape", ")", ")", "\n", "return", "tf", ".", "sigmoid", "(", "se_tensor", ")", "*", "input_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.MBConvBlock.call": [[253, 291], ["tensorflow.logging.info", "tensorflow.logging.info", "efficientnet_model.MBConvBlock._relu_fn", "tensorflow.logging.info", "efficientnet_model.MBConvBlock._bn2", "tensorflow.logging.info", "efficientnet_model.MBConvBlock._relu_fn", "efficientnet_model.MBConvBlock._bn1", "efficientnet_model.MBConvBlock._project_conv", "efficientnet_model.MBConvBlock._bn0", "efficientnet_model.MBConvBlock._depthwise_conv", "tensorflow.variable_scope", "efficientnet_model.MBConvBlock._call_se", "all", "tensorflow.add", "efficientnet_model.MBConvBlock._expand_conv", "models.efficientnet.utils.drop_connect"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.MBConvBlock._call_se", "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.utils.drop_connect"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "True", ",", "drop_connect_rate", "=", "None", ")", ":", "\n", "    ", "\"\"\"Implementation of call().\n\n    Args:\n      inputs: the inputs tensor.\n      training: boolean, whether the model is constructed for training.\n      drop_connect_rate: float, between 0 to 1, drop connect rate.\n\n    Returns:\n      A output tensor.\n    \"\"\"", "\n", "tf", ".", "logging", ".", "info", "(", "'Block input: %s shape: %s'", "%", "(", "inputs", ".", "name", ",", "inputs", ".", "shape", ")", ")", "\n", "if", "self", ".", "_block_args", ".", "expand_ratio", "!=", "1", ":", "\n", "      ", "x", "=", "self", ".", "_relu_fn", "(", "self", ".", "_bn0", "(", "self", ".", "_expand_conv", "(", "inputs", ")", ",", "training", "=", "training", ")", ")", "\n", "", "else", ":", "\n", "      ", "x", "=", "inputs", "\n", "", "tf", ".", "logging", ".", "info", "(", "'Expand: %s shape: %s'", "%", "(", "x", ".", "name", ",", "x", ".", "shape", ")", ")", "\n", "\n", "x", "=", "self", ".", "_relu_fn", "(", "self", ".", "_bn1", "(", "self", ".", "_depthwise_conv", "(", "x", ")", ",", "training", "=", "training", ")", ")", "\n", "tf", ".", "logging", ".", "info", "(", "'DWConv: %s shape: %s'", "%", "(", "x", ".", "name", ",", "x", ".", "shape", ")", ")", "\n", "\n", "if", "self", ".", "_has_se", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'se'", ")", ":", "\n", "        ", "x", "=", "self", ".", "_call_se", "(", "x", ")", "\n", "\n", "", "", "self", ".", "endpoints", "=", "{", "'expansion_output'", ":", "x", "}", "\n", "\n", "x", "=", "self", ".", "_bn2", "(", "self", ".", "_project_conv", "(", "x", ")", ",", "training", "=", "training", ")", "\n", "if", "self", ".", "_block_args", ".", "id_skip", ":", "\n", "      ", "if", "all", "(", "\n", "s", "==", "1", "for", "s", "in", "self", ".", "_block_args", ".", "strides", "\n", ")", "and", "self", ".", "_block_args", ".", "input_filters", "==", "self", ".", "_block_args", ".", "output_filters", ":", "\n", "# only apply drop_connect if skip presents.", "\n", "        ", "if", "drop_connect_rate", ":", "\n", "          ", "x", "=", "utils", ".", "drop_connect", "(", "x", ",", "training", ",", "drop_connect_rate", ")", "\n", "", "x", "=", "tf", ".", "add", "(", "x", ",", "inputs", ")", "\n", "", "", "tf", ".", "logging", ".", "info", "(", "'Project: %s shape: %s'", "%", "(", "x", ".", "name", ",", "x", ".", "shape", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.Model.__init__": [[299, 319], ["super().__init__", "efficientnet_model.Model._build", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character.__init__", "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.Model._build"], ["def", "__init__", "(", "self", ",", "blocks_args", "=", "None", ",", "global_params", "=", "None", ")", ":", "\n", "    ", "\"\"\"Initializes an `Model` instance.\n\n    Args:\n      blocks_args: A list of BlockArgs to construct block modules.\n      global_params: GlobalParams, a set of global parameters.\n\n    Raises:\n      ValueError: when blocks_args is not specified as a list.\n    \"\"\"", "\n", "super", "(", "Model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "blocks_args", ",", "list", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'blocks_args should be a list.'", ")", "\n", "", "self", ".", "_global_params", "=", "global_params", "\n", "self", ".", "_blocks_args", "=", "blocks_args", "\n", "self", ".", "_relu_fn", "=", "global_params", ".", "relu_fn", "or", "tf", ".", "nn", ".", "swish", "\n", "\n", "self", ".", "endpoints", "=", "None", "\n", "\n", "self", ".", "_build", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.Model._get_conv_block": [[320, 325], ["None"], "methods", ["None"], ["", "def", "_get_conv_block", "(", "self", ",", "conv_type", ")", ":", "\n", "    ", "conv_block_map", "=", "{", "\n", "0", ":", "MBConvBlock", "\n", "}", "\n", "return", "conv_block_map", "[", "conv_type", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.Model._build": [[326, 395], ["tensorflow.layers.Conv2D", "batchnorm", "tensorflow.layers.Conv2D", "batchnorm", "tensorflow.keras.layers.GlobalAveragePooling2D", "tensorflow.layers.Dense", "block_args._replace._replace._replace", "efficientnet_model.Model._get_conv_block", "efficientnet_model.Model._blocks.append", "six.moves.xrange", "tensorflow.keras.layers.Dropout", "efficientnet_model.Model.", "block_args._replace._replace._replace", "efficientnet_model.Model._blocks.append", "efficientnet_model.round_filters", "efficientnet_model.round_filters", "efficientnet_model.round_filters", "efficientnet_model.round_filters", "efficientnet_model.round_repeats", "efficientnet_model.Model."], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.Model._get_conv_block", "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.round_filters", "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.round_filters", "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.round_filters", "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.round_filters", "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.round_repeats"], ["", "def", "_build", "(", "self", ")", ":", "\n", "    ", "\"\"\"Builds a model.\"\"\"", "\n", "self", ".", "_blocks", "=", "[", "]", "\n", "# Builds blocks.", "\n", "for", "block_args", "in", "self", ".", "_blocks_args", ":", "\n", "      ", "assert", "block_args", ".", "num_repeat", ">", "0", "\n", "# Update block input and output filters based on depth multiplier.", "\n", "block_args", "=", "block_args", ".", "_replace", "(", "\n", "input_filters", "=", "round_filters", "(", "block_args", ".", "input_filters", ",", "\n", "self", ".", "_global_params", ")", ",", "\n", "output_filters", "=", "round_filters", "(", "block_args", ".", "output_filters", ",", "\n", "self", ".", "_global_params", ")", ",", "\n", "num_repeat", "=", "round_repeats", "(", "block_args", ".", "num_repeat", ",", "self", ".", "_global_params", ")", ")", "\n", "\n", "# The first block needs to take care of stride and filter size increase.", "\n", "conv_block", "=", "self", ".", "_get_conv_block", "(", "block_args", ".", "conv_type", ")", "\n", "self", ".", "_blocks", ".", "append", "(", "conv_block", "(", "block_args", ",", "self", ".", "_global_params", ")", ")", "\n", "if", "block_args", ".", "num_repeat", ">", "1", ":", "\n", "# pylint: disable=protected-access", "\n", "        ", "block_args", "=", "block_args", ".", "_replace", "(", "\n", "input_filters", "=", "block_args", ".", "output_filters", ",", "strides", "=", "[", "1", ",", "1", "]", ")", "\n", "# pylint: enable=protected-access", "\n", "", "for", "_", "in", "xrange", "(", "block_args", ".", "num_repeat", "-", "1", ")", ":", "\n", "        ", "self", ".", "_blocks", ".", "append", "(", "conv_block", "(", "block_args", ",", "self", ".", "_global_params", ")", ")", "\n", "\n", "", "", "batch_norm_momentum", "=", "self", ".", "_global_params", ".", "batch_norm_momentum", "\n", "batch_norm_epsilon", "=", "self", ".", "_global_params", ".", "batch_norm_epsilon", "\n", "if", "self", ".", "_global_params", ".", "data_format", "==", "'channels_first'", ":", "\n", "      ", "channel_axis", "=", "1", "\n", "", "else", ":", "\n", "      ", "channel_axis", "=", "-", "1", "\n", "\n", "# Stem part.", "\n", "", "self", ".", "_conv_stem", "=", "tf", ".", "layers", ".", "Conv2D", "(", "\n", "filters", "=", "round_filters", "(", "32", ",", "self", ".", "_global_params", ")", ",", "\n", "kernel_size", "=", "[", "3", ",", "3", "]", ",", "\n", "strides", "=", "[", "2", ",", "2", "]", ",", "\n", "kernel_initializer", "=", "conv_kernel_initializer", ",", "\n", "padding", "=", "'same'", ",", "\n", "data_format", "=", "self", ".", "_global_params", ".", "data_format", ",", "\n", "use_bias", "=", "False", ")", "\n", "self", ".", "_bn0", "=", "batchnorm", "(", "\n", "axis", "=", "channel_axis", ",", "\n", "momentum", "=", "batch_norm_momentum", ",", "\n", "epsilon", "=", "batch_norm_epsilon", ")", "\n", "\n", "# Head part.", "\n", "self", ".", "_conv_head", "=", "tf", ".", "layers", ".", "Conv2D", "(", "\n", "filters", "=", "round_filters", "(", "1280", ",", "self", ".", "_global_params", ")", ",", "\n", "kernel_size", "=", "[", "1", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "1", "]", ",", "\n", "kernel_initializer", "=", "conv_kernel_initializer", ",", "\n", "padding", "=", "'same'", ",", "\n", "use_bias", "=", "False", ")", "\n", "self", ".", "_bn1", "=", "batchnorm", "(", "\n", "axis", "=", "channel_axis", ",", "\n", "momentum", "=", "batch_norm_momentum", ",", "\n", "epsilon", "=", "batch_norm_epsilon", ")", "\n", "\n", "self", ".", "_avg_pooling", "=", "tf", ".", "keras", ".", "layers", ".", "GlobalAveragePooling2D", "(", "\n", "data_format", "=", "self", ".", "_global_params", ".", "data_format", ")", "\n", "# Dropout is called here at graph construction time", "\n", "if", "self", ".", "_global_params", ".", "dropout_rate", ">", "0", ":", "\n", "      ", "self", ".", "_dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "self", ".", "_global_params", ".", "dropout_rate", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "_dropout", "=", "None", "\n", "", "self", ".", "_fc", "=", "tf", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "_global_params", ".", "num_classes", ",", "\n", "kernel_initializer", "=", "dense_kernel_initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.Model.call": [[396, 454], ["tensorflow.logging.info", "enumerate", "tensorflow.variable_scope", "efficientnet_model.Model._relu_fn", "efficientnet_model.Model._bn0", "tensorflow.variable_scope", "block.call", "tensorflow.variable_scope", "efficientnet_model.Model._relu_fn", "efficientnet_model.Model._avg_pooling", "efficientnet_model.Model._fc", "efficientnet_model.Model._conv_stem", "tensorflow.logging.info", "six.iteritems", "efficientnet_model.Model._bn1", "efficientnet_model.Model._dropout", "len", "float", "len", "efficientnet_model.Model._conv_head", "efficientnet_model.Model._blocks[].block_args"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.Model.call", "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.MBConvBlock.block_args"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "True", ",", "features_only", "=", "None", ")", ":", "\n", "    ", "\"\"\"Implementation of call().\n\n    Args:\n      inputs: input tensors.\n      training: boolean, whether the model is constructed for training.\n      features_only: build the base feature network only.\n\n    Returns:\n      output tensors.\n    \"\"\"", "\n", "outputs", "=", "None", "\n", "self", ".", "endpoints", "=", "{", "}", "\n", "# Calls Stem layers", "\n", "with", "tf", ".", "variable_scope", "(", "'stem'", ")", ":", "\n", "      ", "outputs", "=", "self", ".", "_relu_fn", "(", "\n", "self", ".", "_bn0", "(", "self", ".", "_conv_stem", "(", "inputs", ")", ",", "training", "=", "training", ")", ")", "\n", "", "tf", ".", "logging", ".", "info", "(", "'Built stem layers with output shape: %s'", "%", "outputs", ".", "shape", ")", "\n", "self", ".", "endpoints", "[", "'stem'", "]", "=", "outputs", "\n", "\n", "# Calls blocks.", "\n", "reduction_idx", "=", "0", "\n", "for", "idx", ",", "block", "in", "enumerate", "(", "self", ".", "_blocks", ")", ":", "\n", "      ", "is_reduction", "=", "False", "\n", "if", "(", "(", "idx", "==", "len", "(", "self", ".", "_blocks", ")", "-", "1", ")", "or", "\n", "self", ".", "_blocks", "[", "idx", "+", "1", "]", ".", "block_args", "(", ")", ".", "strides", "[", "0", "]", ">", "1", ")", ":", "\n", "        ", "is_reduction", "=", "True", "\n", "reduction_idx", "+=", "1", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'blocks_%s'", "%", "idx", ")", ":", "\n", "        ", "drop_rate", "=", "self", ".", "_global_params", ".", "drop_connect_rate", "\n", "if", "drop_rate", ":", "\n", "          ", "drop_rate", "*=", "float", "(", "idx", ")", "/", "len", "(", "self", ".", "_blocks", ")", "\n", "tf", ".", "logging", ".", "info", "(", "'block_%s drop_connect_rate: %s'", "%", "(", "idx", ",", "drop_rate", ")", ")", "\n", "", "outputs", "=", "block", ".", "call", "(", "\n", "outputs", ",", "training", "=", "training", ",", "drop_connect_rate", "=", "drop_rate", ")", "\n", "self", ".", "endpoints", "[", "'block_%s'", "%", "idx", "]", "=", "outputs", "\n", "if", "is_reduction", ":", "\n", "          ", "self", ".", "endpoints", "[", "'reduction_%s'", "%", "reduction_idx", "]", "=", "outputs", "\n", "", "if", "block", ".", "endpoints", ":", "\n", "          ", "for", "k", ",", "v", "in", "six", ".", "iteritems", "(", "block", ".", "endpoints", ")", ":", "\n", "            ", "self", ".", "endpoints", "[", "'block_%s/%s'", "%", "(", "idx", ",", "k", ")", "]", "=", "v", "\n", "if", "is_reduction", ":", "\n", "              ", "self", ".", "endpoints", "[", "'reduction_%s/%s'", "%", "(", "reduction_idx", ",", "k", ")", "]", "=", "v", "\n", "", "", "", "", "", "self", ".", "endpoints", "[", "'global_pool'", "]", "=", "outputs", "\n", "\n", "if", "not", "features_only", ":", "\n", "# Calls final layers and returns logits.", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'head'", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "_relu_fn", "(", "\n", "self", ".", "_bn1", "(", "self", ".", "_conv_head", "(", "outputs", ")", ",", "training", "=", "training", ")", ")", "\n", "outputs", "=", "self", ".", "_avg_pooling", "(", "outputs", ")", "\n", "if", "self", ".", "_dropout", ":", "\n", "          ", "outputs", "=", "self", ".", "_dropout", "(", "outputs", ",", "training", "=", "training", ")", "\n", "", "self", ".", "endpoints", "[", "'global_pool'", "]", "=", "outputs", "\n", "outputs", "=", "self", ".", "_fc", "(", "outputs", ")", "\n", "self", ".", "endpoints", "[", "'head'", "]", "=", "outputs", "\n", "", "", "return", "outputs", "", "", "", ""]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.conv_kernel_initializer": [[61, 83], ["int", "tensorflow.random_normal", "numpy.sqrt"], "function", ["None"], ["def", "conv_kernel_initializer", "(", "shape", ",", "dtype", "=", "None", ",", "partition_info", "=", "None", ")", ":", "\n", "  ", "\"\"\"Initialization for convolutional kernels.\n\n  The main difference with tf.variance_scaling_initializer is that\n  tf.variance_scaling_initializer uses a truncated normal with an uncorrected\n  standard deviation, whereas here we use a normal distribution. Similarly,\n  tf.contrib.layers.variance_scaling_initializer uses a truncated normal with\n  a corrected standard deviation.\n\n  Args:\n    shape: shape of variable\n    dtype: dtype of variable\n    partition_info: unused\n\n  Returns:\n    an initialization for the variable\n  \"\"\"", "\n", "del", "partition_info", "\n", "kernel_height", ",", "kernel_width", ",", "_", ",", "out_filters", "=", "shape", "\n", "fan_out", "=", "int", "(", "kernel_height", "*", "kernel_width", "*", "out_filters", ")", "\n", "return", "tf", ".", "random_normal", "(", "\n", "shape", ",", "mean", "=", "0.0", ",", "stddev", "=", "np", ".", "sqrt", "(", "2.0", "/", "fan_out", ")", ",", "dtype", "=", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.dense_kernel_initializer": [[85, 104], ["tensorflow.random_uniform", "numpy.sqrt"], "function", ["None"], ["", "def", "dense_kernel_initializer", "(", "shape", ",", "dtype", "=", "None", ",", "partition_info", "=", "None", ")", ":", "\n", "  ", "\"\"\"Initialization for dense kernels.\n\n  This initialization is equal to\n    tf.variance_scaling_initializer(scale=1.0/3.0, mode='fan_out',\n                                    distribution='uniform').\n  It is written out explicitly here for clarity.\n\n  Args:\n    shape: shape of variable\n    dtype: dtype of variable\n    partition_info: unused\n\n  Returns:\n    an initialization for the variable\n  \"\"\"", "\n", "del", "partition_info", "\n", "init_range", "=", "1.0", "/", "np", ".", "sqrt", "(", "shape", "[", "1", "]", ")", "\n", "return", "tf", ".", "random_uniform", "(", "shape", ",", "-", "init_range", ",", "init_range", ",", "dtype", "=", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.round_filters": [[106, 123], ["max", "tensorflow.logging.info", "int", "int"], "function", ["None"], ["", "def", "round_filters", "(", "filters", ",", "global_params", ")", ":", "\n", "  ", "\"\"\"Round number of filters based on depth multiplier.\"\"\"", "\n", "orig_f", "=", "filters", "\n", "multiplier", "=", "global_params", ".", "width_coefficient", "\n", "divisor", "=", "global_params", ".", "depth_divisor", "\n", "min_depth", "=", "global_params", ".", "min_depth", "\n", "if", "not", "multiplier", ":", "\n", "    ", "return", "filters", "\n", "\n", "", "filters", "*=", "multiplier", "\n", "min_depth", "=", "min_depth", "or", "divisor", "\n", "new_filters", "=", "max", "(", "min_depth", ",", "int", "(", "filters", "+", "divisor", "/", "2", ")", "//", "divisor", "*", "divisor", ")", "\n", "# Make sure that round down does not go down by more than 10%.", "\n", "if", "new_filters", "<", "0.9", "*", "filters", ":", "\n", "    ", "new_filters", "+=", "divisor", "\n", "", "tf", ".", "logging", ".", "info", "(", "'round_filter input={} output={}'", ".", "format", "(", "orig_f", ",", "new_filters", ")", ")", "\n", "return", "int", "(", "new_filters", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.efficientnet_model.round_repeats": [[125, 131], ["int", "math.ceil"], "function", ["None"], ["", "def", "round_repeats", "(", "repeats", ",", "global_params", ")", ":", "\n", "  ", "\"\"\"Round number of filters based on depth multiplier.\"\"\"", "\n", "multiplier", "=", "global_params", ".", "depth_coefficient", "\n", "if", "not", "multiplier", ":", "\n", "    ", "return", "repeats", "\n", "", "return", "int", "(", "math", ".", "ceil", "(", "multiplier", "*", "repeats", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.utils.TpuBatchNormalization.__init__": [[91, 95], ["super().__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character.__init__"], ["def", "__init__", "(", "self", ",", "fused", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "fused", "in", "(", "True", ",", "None", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'TpuBatchNormalization does not support fused=True.'", ")", "\n", "", "super", "(", "TpuBatchNormalization", ",", "self", ")", ".", "__init__", "(", "fused", "=", "fused", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.utils.TpuBatchNormalization._cross_replica_average": [[96, 110], ["tensorflow.contrib.tpu.python.tpu.tpu_function.get_tpu_context", "tensorflow.contrib.tpu.python.ops.tpu_ops.cross_replica_sum", "tensorflow.cast", "ValueError", "range", "range"], "methods", ["None"], ["", "def", "_cross_replica_average", "(", "self", ",", "t", ",", "num_shards_per_group", ")", ":", "\n", "    ", "\"\"\"Calculates the average value of input tensor across TPU replicas.\"\"\"", "\n", "num_shards", "=", "tpu_function", ".", "get_tpu_context", "(", ")", ".", "number_of_shards", "\n", "group_assignment", "=", "None", "\n", "if", "num_shards_per_group", ">", "1", ":", "\n", "      ", "if", "num_shards", "%", "num_shards_per_group", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "'num_shards: %d mod shards_per_group: %d, should be 0'", "\n", "%", "(", "num_shards", ",", "num_shards_per_group", ")", ")", "\n", "", "num_groups", "=", "num_shards", "//", "num_shards_per_group", "\n", "group_assignment", "=", "[", "[", "\n", "x", "for", "x", "in", "range", "(", "num_shards", ")", "if", "x", "//", "num_shards_per_group", "==", "y", "\n", "]", "for", "y", "in", "range", "(", "num_groups", ")", "]", "\n", "", "return", "tpu_ops", ".", "cross_replica_sum", "(", "t", ",", "group_assignment", ")", "/", "tf", ".", "cast", "(", "\n", "num_shards_per_group", ",", "t", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.utils.TpuBatchNormalization._moments": [[111, 135], ["super()._moments", "tensorflow.logging.info", "max", "tensorflow.math.square", "utils.TpuBatchNormalization._cross_replica_average", "utils.TpuBatchNormalization._cross_replica_average", "tensorflow.contrib.tpu.python.tpu.tpu_function.get_tpu_context", "tensorflow.math.square"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.utils.TpuBatchNormalization._moments", "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.utils.TpuBatchNormalization._cross_replica_average", "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.utils.TpuBatchNormalization._cross_replica_average"], ["", "def", "_moments", "(", "self", ",", "inputs", ",", "reduction_axes", ",", "keep_dims", ")", ":", "\n", "    ", "\"\"\"Compute the mean and variance: it overrides the original _moments.\"\"\"", "\n", "shard_mean", ",", "shard_variance", "=", "super", "(", "TpuBatchNormalization", ",", "self", ")", ".", "_moments", "(", "\n", "inputs", ",", "reduction_axes", ",", "keep_dims", "=", "keep_dims", ")", "\n", "\n", "num_shards", "=", "tpu_function", ".", "get_tpu_context", "(", ")", ".", "number_of_shards", "or", "1", "\n", "if", "num_shards", "<=", "8", ":", "# Skip cross_replica for 2x2 or smaller slices.", "\n", "      ", "num_shards_per_group", "=", "1", "\n", "", "else", ":", "\n", "      ", "num_shards_per_group", "=", "max", "(", "8", ",", "num_shards", "//", "8", ")", "\n", "", "tf", ".", "logging", ".", "info", "(", "'TpuBatchNormalization with num_shards_per_group %s'", ",", "\n", "num_shards_per_group", ")", "\n", "if", "num_shards_per_group", ">", "1", ":", "\n", "# Compute variance using: Var[X]= E[X^2] - E[X]^2.", "\n", "      ", "shard_square_of_mean", "=", "tf", ".", "math", ".", "square", "(", "shard_mean", ")", "\n", "shard_mean_of_square", "=", "shard_variance", "+", "shard_square_of_mean", "\n", "group_mean", "=", "self", ".", "_cross_replica_average", "(", "\n", "shard_mean", ",", "num_shards_per_group", ")", "\n", "group_mean_of_square", "=", "self", ".", "_cross_replica_average", "(", "\n", "shard_mean_of_square", ",", "num_shards_per_group", ")", "\n", "group_variance", "=", "group_mean_of_square", "-", "tf", ".", "math", ".", "square", "(", "group_mean", ")", "\n", "return", "(", "group_mean", ",", "group_variance", ")", "\n", "", "else", ":", "\n", "      ", "return", "(", "shard_mean", ",", "shard_variance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.utils.build_learning_rate": [[30, 62], ["tensorflow.train.exponential_decay", "tensorflow.logging.info", "int", "tensorflow.cond", "tensorflow.cast", "tensorflow.cast", "tensorflow.cos", "tensorflow.cast"], "function", ["None"], ["def", "build_learning_rate", "(", "initial_lr", ",", "\n", "global_step", ",", "\n", "steps_per_epoch", "=", "None", ",", "\n", "lr_decay_type", "=", "'exponential'", ",", "\n", "decay_factor", "=", "0.97", ",", "\n", "decay_epochs", "=", "2.4", ",", "\n", "total_steps", "=", "None", ",", "\n", "warmup_epochs", "=", "5", ")", ":", "\n", "  ", "\"\"\"Build learning rate.\"\"\"", "\n", "if", "lr_decay_type", "==", "'exponential'", ":", "\n", "    ", "assert", "steps_per_epoch", "is", "not", "None", "\n", "decay_steps", "=", "steps_per_epoch", "*", "decay_epochs", "\n", "lr", "=", "tf", ".", "train", ".", "exponential_decay", "(", "\n", "initial_lr", ",", "global_step", ",", "decay_steps", ",", "decay_factor", ",", "staircase", "=", "True", ")", "\n", "", "elif", "lr_decay_type", "==", "'cosine'", ":", "\n", "    ", "assert", "total_steps", "is", "not", "None", "\n", "lr", "=", "0.5", "*", "initial_lr", "*", "(", "\n", "1", "+", "tf", ".", "cos", "(", "np", ".", "pi", "*", "tf", ".", "cast", "(", "global_step", ",", "tf", ".", "float32", ")", "/", "total_steps", ")", ")", "\n", "", "elif", "lr_decay_type", "==", "'constant'", ":", "\n", "    ", "lr", "=", "initial_lr", "\n", "", "else", ":", "\n", "    ", "assert", "False", ",", "'Unknown lr_decay_type : %s'", "%", "lr_decay_type", "\n", "\n", "", "if", "warmup_epochs", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "'Learning rate warmup_epochs: %d'", "%", "warmup_epochs", ")", "\n", "warmup_steps", "=", "int", "(", "warmup_epochs", "*", "steps_per_epoch", ")", "\n", "warmup_lr", "=", "(", "\n", "initial_lr", "*", "tf", ".", "cast", "(", "global_step", ",", "tf", ".", "float32", ")", "/", "tf", ".", "cast", "(", "\n", "warmup_steps", ",", "tf", ".", "float32", ")", ")", "\n", "lr", "=", "tf", ".", "cond", "(", "global_step", "<", "warmup_steps", ",", "lambda", ":", "warmup_lr", ",", "lambda", ":", "lr", ")", "\n", "\n", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.utils.build_optimizer": [[64, 85], ["tensorflow.logging.info", "tensorflow.train.GradientDescentOptimizer", "tensorflow.logging.info", "tensorflow.train.MomentumOptimizer", "tensorflow.logging.info", "tensorflow.train.RMSPropOptimizer", "tensorflow.logging.fatal"], "function", ["None"], ["", "def", "build_optimizer", "(", "learning_rate", ",", "\n", "optimizer_name", "=", "'rmsprop'", ",", "\n", "decay", "=", "0.9", ",", "\n", "epsilon", "=", "0.001", ",", "\n", "momentum", "=", "0.9", ")", ":", "\n", "  ", "\"\"\"Build optimizer.\"\"\"", "\n", "if", "optimizer_name", "==", "'sgd'", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "'Using SGD optimizer'", ")", "\n", "optimizer", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "learning_rate", "=", "learning_rate", ")", "\n", "", "elif", "optimizer_name", "==", "'momentum'", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "'Using Momentum optimizer'", ")", "\n", "optimizer", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "\n", "learning_rate", "=", "learning_rate", ",", "momentum", "=", "momentum", ")", "\n", "", "elif", "optimizer_name", "==", "'rmsprop'", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "'Using RMSProp optimizer'", ")", "\n", "optimizer", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "learning_rate", ",", "decay", ",", "momentum", ",", "\n", "epsilon", ")", "\n", "", "else", ":", "\n", "    ", "tf", ".", "logging", ".", "fatal", "(", "'Unknown optimizer:'", ",", "optimizer_name", ")", "\n", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.utils.drop_connect": [[137, 155], ["isinstance", "tensorflow.random_uniform", "tensorflow.floor", "utils.drop_connect_cond", "tensorflow.shape", "tensorflow.div"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.utils.drop_connect_cond"], ["", "", "", "def", "drop_connect", "(", "inputs", ",", "is_training", ",", "drop_connect_rate", ")", ":", "\n", "  ", "\"\"\"Apply drop connect.\"\"\"", "\n", "if", "isinstance", "(", "is_training", ",", "tf", ".", "Tensor", ")", ":", "\n", "    ", "return", "drop_connect_cond", "(", "inputs", ",", "is_training", ",", "drop_connect_rate", ")", "\n", "", "if", "not", "is_training", ":", "\n", "    ", "return", "inputs", "\n", "\n", "# Compute keep_prob", "\n", "# TODO(tanmingxing): add support for training progress.", "\n", "", "keep_prob", "=", "1.0", "-", "drop_connect_rate", "\n", "\n", "# Compute drop_connect tensor", "\n", "batch_size", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "random_tensor", "=", "keep_prob", "\n", "random_tensor", "+=", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "1", ",", "1", ",", "1", "]", ",", "dtype", "=", "inputs", ".", "dtype", ")", "\n", "binary_tensor", "=", "tf", ".", "floor", "(", "random_tensor", ")", "\n", "output", "=", "tf", ".", "div", "(", "inputs", ",", "keep_prob", ")", "*", "binary_tensor", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.utils.drop_connect_cond": [[157, 171], ["tensorflow.cond", "tensorflow.random_uniform", "tensorflow.floor", "tensorflow.shape", "tensorflow.div", "utils.drop_connect_cond.dropc"], "function", ["None"], ["", "def", "drop_connect_cond", "(", "inputs", ",", "is_training", ",", "drop_connect_rate", ")", ":", "\n", "  ", "\"\"\"Apply drop connect.\"\"\"", "\n", "def", "dropc", "(", "_inputs", ",", "_rate", ")", ":", "\n", "# Compute keep_prob", "\n", "    ", "keep_prob", "=", "1.0", "-", "_rate", "\n", "\n", "# Compute drop_connect tensor", "\n", "batch_size", "=", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", "\n", "random_tensor", "=", "keep_prob", "\n", "random_tensor", "+=", "tf", ".", "random_uniform", "(", "[", "batch_size", ",", "1", ",", "1", ",", "1", "]", ",", "dtype", "=", "_inputs", ".", "dtype", ")", "\n", "binary_tensor", "=", "tf", ".", "floor", "(", "random_tensor", ")", "\n", "return", "tf", ".", "div", "(", "_inputs", ",", "keep_prob", ")", "*", "binary_tensor", "\n", "\n", "", "return", "tf", ".", "cond", "(", "is_training", ",", "lambda", ":", "dropc", "(", "inputs", ",", "drop_connect_rate", ")", ",", "lambda", ":", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.efficientnet.utils.archive_ckpt": [[173, 216], ["os.path.split", "os.path.join", "float", "tensorflow.gfile.Exists", "tensorflow.gfile.Glob", "os.path.join", "tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "tensorflow.train.generate_checkpoint_state_proto", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.logging.info", "tensorflow.gfile.DeleteRecursively", "os.path.join", "tensorflow.gfile.Copy", "tensorflow.gfile.GFile", "f.write", "tensorflow.gfile.GFile", "f.write", "tensorflow.gfile.GFile", "f.write", "tensorflow.gfile.GFile", "float", "os.path.basename", "os.path.join", "str", "os.path.join", "f.read"], "function", ["None"], ["", "def", "archive_ckpt", "(", "ckpt_eval", ",", "ckpt_objective", ",", "ckpt_path", ")", ":", "\n", "  ", "\"\"\"Archive a checkpoint if the metric is better.\"\"\"", "\n", "ckpt_dir", ",", "ckpt_name", "=", "os", ".", "path", ".", "split", "(", "ckpt_path", ")", "\n", "\n", "saved_objective_path", "=", "os", ".", "path", ".", "join", "(", "ckpt_dir", ",", "'best_objective.txt'", ")", "\n", "saved_objective", "=", "float", "(", "'-inf'", ")", "\n", "if", "tf", ".", "gfile", ".", "Exists", "(", "saved_objective_path", ")", ":", "\n", "    ", "with", "tf", ".", "gfile", ".", "GFile", "(", "saved_objective_path", ",", "'r'", ")", "as", "f", ":", "\n", "      ", "saved_objective", "=", "float", "(", "f", ".", "read", "(", ")", ")", "\n", "", "", "if", "saved_objective", ">", "ckpt_objective", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "'Ckpt %s is worse than %s'", ",", "ckpt_objective", ",", "saved_objective", ")", "\n", "return", "False", "\n", "\n", "", "filenames", "=", "tf", ".", "gfile", ".", "Glob", "(", "ckpt_path", "+", "'.*'", ")", "\n", "if", "filenames", "is", "None", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "'No files to copy for checkpoint %s'", ",", "ckpt_path", ")", "\n", "return", "False", "\n", "\n", "# Clear the old folder.", "\n", "", "dst_dir", "=", "os", ".", "path", ".", "join", "(", "ckpt_dir", ",", "'archive'", ")", "\n", "if", "tf", ".", "gfile", ".", "Exists", "(", "dst_dir", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "dst_dir", ")", "\n", "", "tf", ".", "gfile", ".", "MakeDirs", "(", "dst_dir", ")", "\n", "\n", "# Write checkpoints.", "\n", "for", "f", "in", "filenames", ":", "\n", "    ", "dest", "=", "os", ".", "path", ".", "join", "(", "dst_dir", ",", "os", ".", "path", ".", "basename", "(", "f", ")", ")", "\n", "tf", ".", "gfile", ".", "Copy", "(", "f", ",", "dest", ",", "overwrite", "=", "True", ")", "\n", "", "ckpt_state", "=", "tf", ".", "train", ".", "generate_checkpoint_state_proto", "(", "\n", "dst_dir", ",", "\n", "model_checkpoint_path", "=", "ckpt_name", ",", "\n", "all_model_checkpoint_paths", "=", "[", "ckpt_name", "]", ")", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "os", ".", "path", ".", "join", "(", "dst_dir", ",", "'checkpoint'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "    ", "f", ".", "write", "(", "str", "(", "ckpt_state", ")", ")", "\n", "", "with", "tf", ".", "gfile", ".", "GFile", "(", "os", ".", "path", ".", "join", "(", "dst_dir", ",", "'best_eval.txt'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "    ", "f", ".", "write", "(", "'%s'", "%", "ckpt_eval", ")", "\n", "\n", "# Update the best objective.", "\n", "", "with", "tf", ".", "gfile", ".", "GFile", "(", "saved_objective_path", ",", "'w'", ")", "as", "f", ":", "\n", "    ", "f", ".", "write", "(", "'%f'", "%", "ckpt_objective", ")", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "'Copying checkpoint %s to %s'", ",", "ckpt_path", ",", "dst_dir", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.input_fn.TFRecordSegmentationDataset.__init__": [[25, 50], ["len", "tensorflow.constant", "print"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tfrecord_paths", ":", "List", "[", "str", "]", ",", "image_width", ":", "int", ",", "\n", "image_channels", "=", "3", ",", "mask_channels", "=", "1", ",", "seed", "=", "0", ",", "augmenter", ":", "Optional", "[", "Augmenter", "]", "=", "None", ",", "seperate_background_channel", ":", "bool", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Image segmentation tf.data.Dataset constructor for batching from tfrecords.\n        Args:\n            tfrecord_paths: list of paths to tfrecords\n            image_width: side of images and masks (all images and masks assumed to be square and of the same size)\n            image_channels: Int number of channels in the images.\n            mask_channels: Int number of channels in the masks.\n            seed: Integer seed for the RNG in the data pipeline.\n            augmenter: An object with an apply_augmentations method that will be wrapped with tf.py_func and applied to input examples\n        \"\"\"", "\n", "self", ".", "tfrecord_paths", "=", "tfrecord_paths", "\n", "self", ".", "num_shards", "=", "len", "(", "self", ".", "tfrecord_paths", ")", "\n", "self", ".", "tfrecord_paths_tensor", "=", "tf", ".", "constant", "(", "self", ".", "tfrecord_paths", ")", "\n", "self", ".", "image_width", "=", "image_width", "\n", "self", ".", "image_channels", "=", "image_channels", "\n", "if", "seperate_background_channel", ":", "\n", "            ", "mask_channels", "+=", "1", "\n", "", "self", ".", "mask_channels", "=", "mask_channels", "\n", "print", "(", "\"building dataset with labels with {} mask channels\"", ".", "format", "(", "self", ".", "mask_channels", ")", ")", "\n", "self", ".", "serialized_image_raw_dtype", "=", "_NP_TO_TF_DTYPES", "[", "SERIALIZED_DTYPE", "]", "\n", "self", ".", "serialized_mask_raw_dtype", "=", "_NP_TO_TF_DTYPES", "[", "SERIALIZED_DTYPE", "]", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "augmenter", "=", "augmenter", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.input_fn.TFRecordSegmentationDataset.make_dataset": [[51, 99], ["print", "tensorflow.data.Dataset.from_tensor_slices", "dataset.map.map.repeat", "dataset.map.map.shuffle", "dataset.map.map.interleave", "dataset.map.map.map", "dataset.map.map.shuffle", "dataset.map.map.batch", "dataset.map.map.prefetch", "tensorflow.data.Iterator.from_structure", "tensorflow.data.Iterator.from_structure.get_next", "tensorflow.data.Iterator.from_structure.make_initializer", "dataset.map.map.map", "dataset.map.map.map", "tensorflow.data.TFRecordDataset", "input_fn.TFRecordSegmentationDataset._parse_example", "input_fn.TFRecordSegmentationDataset.augmenter.apply_augmentations", "tensorflow.py_func", "tensorflow.reshape", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.input_fn.TFRecordSegmentationDataset._parse_example", "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.Augmenter.apply_augmentations"], ["", "def", "make_dataset", "(", "self", ",", "batch_size", "=", "8", ",", "num_parallel_calls", "=", "_NUM_SUBPROCESSES", ",", "num_concurrent_reads", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Parse tfrecords from paths, shuffle and batch.\n        the next element in dataset op and the dataset initializer op.\n        Args:\n            batch_size: Number of images/masks in each batch returned.\n            num_parallel_calls: Number of parallel subprocesses for Dataset.map calls.\n            num_concurrent_reads: Interleave reading from this number of tfrecords. Sets `cycle_length` param to\n                interleave. If unspecified, will be set to the number of shards.\n        Returns:\n            next_element: A tensor with shape [2], where next_element[0]\n                          is image batch, next_element[1] is the corresponding\n                          mask batch.\n            init_op: Data initializer op, needs to be executed in a session\n                     for the data queue to be filled up and the next_element op\n                     to yield batches.\n        \"\"\"", "\n", "print", "(", "\"Making dataset from shards {}\"", ".", "format", "(", "self", ".", "tfrecord_paths", ")", ")", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "self", ".", "tfrecord_paths", ")", "\n", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "dataset", "=", "dataset", ".", "shuffle", "(", "self", ".", "num_shards", ")", "\n", "if", "num_concurrent_reads", "is", "None", ":", "\n", "            ", "num_concurrent_reads", "=", "self", ".", "num_shards", "\n", "", "dataset", "=", "dataset", ".", "interleave", "(", "\n", "lambda", "filename", ":", "tf", ".", "data", ".", "TFRecordDataset", "(", "filename", ",", "compression_type", "=", "_COMPRESSION_TYPE", ",", "buffer_size", "=", "_DEFAULT_READER_BUFFER_SIZE_BYTES", ")", ",", "\n", "cycle_length", "=", "num_concurrent_reads", ",", "block_length", "=", "1", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "lambda", "record", ":", "self", ".", "_parse_example", "(", "record", ")", ",", "num_parallel_calls", "=", "num_parallel_calls", ")", "\n", "\n", "if", "self", ".", "augmenter", "is", "not", "None", ":", "\n", "            ", "apply_augs", "=", "lambda", "i", ",", "m", ":", "self", ".", "augmenter", ".", "apply_augmentations", "(", "i", ",", "m", ",", "return_image_mask_in_list", "=", "False", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "image", ",", "mask", ":", "tf", ".", "py_func", "(", "apply_augs", ",", "[", "image", ",", "mask", "]", ",", "[", "tf", ".", "float32", ",", "tf", ".", "float32", "]", ")", ",", "\n", "num_parallel_calls", "=", "num_parallel_calls", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "lambda", "image", ",", "mask", ":", "(", "\n", "tf", ".", "reshape", "(", "image", ",", "(", "self", ".", "image_width", ",", "self", ".", "image_width", ",", "self", ".", "image_channels", ")", ")", ",", "\n", "tf", ".", "reshape", "(", "mask", ",", "(", "self", ".", "image_width", ",", "self", ".", "image_width", ",", "self", ".", "mask_channels", ")", ")", ")", ",", "\n", "num_parallel_calls", "=", "num_parallel_calls", ")", "\n", "\n", "", "dataset", "=", "dataset", ".", "shuffle", "(", "_SHUFFLE_BUFFER_SIZE", ")", "\n", "dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "dataset", "=", "dataset", ".", "prefetch", "(", "_PREFETCH_BUFFER_SIZE", ")", "\n", "# debug(dataset)  # Uncomment to visualize examples", "\n", "iterator", "=", "tf", ".", "data", ".", "Iterator", ".", "from_structure", "(", "\n", "dataset", ".", "output_types", ",", "dataset", ".", "output_shapes", ")", "\n", "next_element", "=", "iterator", ".", "get_next", "(", ")", "\n", "ds_init_op", "=", "iterator", ".", "make_initializer", "(", "dataset", ")", "\n", "\n", "return", "next_element", ",", "ds_init_op", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.input_fn.TFRecordSegmentationDataset._parse_example": [[100, 134], ["tensorflow.parse_single_example", "tensorflow.decode_raw", "tensorflow.reshape", "tensorflow.cast", "tensorflow.decode_raw", "tensorflow.reshape", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.cast"], "methods", ["None"], ["", "def", "_parse_example", "(", "self", ",", "example", ",", "scale_to_0_1", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Parse a TF Example into corresponding image and mask.\n\n        Positive class is assumed to be encoded as the int value 255 in tfrecords.\n\n        Args:\n            record_name: name of the tfrecord indicating the class\n            example: Batch of TF Example protos.\n            image_width: Width to resize to of image and mask, assumed to be same as height.\n            scale_to_0_1: if True, scale images by dividing by 255.\n\n        Returns:\n            A pair of 3 channel float images and n-channel float segmentation masks.\n            The first channel in the masks will be the background, the rest\n            will be the classes of interest.\n        \"\"\"", "\n", "\n", "features", "=", "{", "\n", "'image'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "'mask'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "}", "\n", "parsed_example", "=", "tf", ".", "parse_single_example", "(", "example", ",", "features", ")", "\n", "\n", "image", "=", "tf", ".", "decode_raw", "(", "parsed_example", "[", "'image'", "]", ",", "self", ".", "serialized_image_raw_dtype", ")", "\n", "image", "=", "tf", ".", "reshape", "(", "image", ",", "(", "self", ".", "image_width", ",", "self", ".", "image_width", ",", "self", ".", "image_channels", ")", ")", "\n", "image", "=", "tf", ".", "cast", "(", "image", ",", "tf", ".", "float32", ")", "\n", "if", "scale_to_0_1", ":", "\n", "            ", "image", "/=", "255.", "\n", "\n", "", "mask", "=", "tf", ".", "decode_raw", "(", "parsed_example", "[", "'mask'", "]", ",", "self", ".", "serialized_mask_raw_dtype", ")", "\n", "mask", "=", "tf", ".", "reshape", "(", "mask", ",", "(", "self", ".", "image_width", ",", "self", ".", "image_width", ",", "self", ".", "mask_channels", ")", ")", "\n", "mask", "=", "tf", ".", "cast", "(", "mask", ",", "tf", ".", "float32", ")", "/", "255.", "\n", "return", "image", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.input_fn.parse_example": [[28, 66], ["tensorflow.parse_single_example", "tensorflow.decode_raw", "tensorflow.reshape", "tensorflow.cast", "tensorflow.decode_raw", "tensorflow.reshape", "tensorflow.stack", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.cast"], "function", ["None"], ["\n", "self", ".", "tfrecord_paths", "=", "tfrecord_paths", "\n", "self", ".", "num_shards", "=", "len", "(", "self", ".", "tfrecord_paths", ")", "\n", "self", ".", "tfrecord_paths_tensor", "=", "tf", ".", "constant", "(", "self", ".", "tfrecord_paths", ")", "\n", "self", ".", "image_width", "=", "image_width", "\n", "self", ".", "image_channels", "=", "image_channels", "\n", "if", "seperate_background_channel", ":", "\n", "            ", "mask_channels", "+=", "1", "\n", "", "self", ".", "mask_channels", "=", "mask_channels", "\n", "print", "(", "\"building dataset with labels with {} mask channels\"", ".", "format", "(", "self", ".", "mask_channels", ")", ")", "\n", "self", ".", "serialized_image_raw_dtype", "=", "_NP_TO_TF_DTYPES", "[", "SERIALIZED_DTYPE", "]", "\n", "self", ".", "serialized_mask_raw_dtype", "=", "_NP_TO_TF_DTYPES", "[", "SERIALIZED_DTYPE", "]", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "augmenter", "=", "augmenter", "\n", "\n", "", "def", "make_dataset", "(", "self", ",", "batch_size", "=", "8", ",", "num_parallel_calls", "=", "_NUM_SUBPROCESSES", ",", "num_concurrent_reads", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.input_fn.load_from_tfrecords": [[121, 142], ["tensorflow.python_io.TFRecordOptions", "tensorflow.python_io.tf_record_iterator", "examples.append", "input_fn.parse_example"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.input_fn.parse_example"], ["}", "\n", "parsed_example", "=", "tf", ".", "parse_single_example", "(", "example", ",", "features", ")", "\n", "\n", "image", "=", "tf", ".", "decode_raw", "(", "parsed_example", "[", "'image'", "]", ",", "self", ".", "serialized_image_raw_dtype", ")", "\n", "image", "=", "tf", ".", "reshape", "(", "image", ",", "(", "self", ".", "image_width", ",", "self", ".", "image_width", ",", "self", ".", "image_channels", ")", ")", "\n", "image", "=", "tf", ".", "cast", "(", "image", ",", "tf", ".", "float32", ")", "\n", "if", "scale_to_0_1", ":", "\n", "            ", "image", "/=", "255.", "\n", "\n", "", "mask", "=", "tf", ".", "decode_raw", "(", "parsed_example", "[", "'mask'", "]", ",", "self", ".", "serialized_mask_raw_dtype", ")", "\n", "mask", "=", "tf", ".", "reshape", "(", "mask", ",", "(", "self", ".", "image_width", ",", "self", ".", "image_width", ",", "self", ".", "mask_channels", ")", ")", "\n", "mask", "=", "tf", ".", "cast", "(", "mask", ",", "tf", ".", "float32", ")", "/", "255.", "\n", "return", "image", ",", "mask", "\n", "\n", "\n", "", "", "def", "parse_example", "(", "example", ",", "image_width", ":", "int", "=", "224", ",", "image_channels", ":", "int", "=", "3", ",", "mask_channels", ":", "int", "=", "1000", ",", "scale_to_0_1", ":", "bool", "=", "False", ",", "serialized_mask_raw_dtype", "=", "tf", ".", "float64", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.input_fn.make_dataset": [[68, 119], ["tensorflow.data.Dataset.list_files", "dataset.prefetch.repeat", "dataset.prefetch.shuffle", "dataset.prefetch.interleave", "dataset.prefetch.map", "dataset.prefetch.batch", "dataset.prefetch.prefetch", "print", "tensorflow.data.TFRecordDataset", "input_fn.parse_example"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.input_fn.parse_example"], ["print", "(", "\"Making dataset from shards {}\"", ".", "format", "(", "self", ".", "tfrecord_paths", ")", ")", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "self", ".", "tfrecord_paths", ")", "\n", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "dataset", "=", "dataset", ".", "shuffle", "(", "self", ".", "num_shards", ")", "\n", "if", "num_concurrent_reads", "is", "None", ":", "\n", "            ", "num_concurrent_reads", "=", "self", ".", "num_shards", "\n", "", "dataset", "=", "dataset", ".", "interleave", "(", "\n", "lambda", "filename", ":", "tf", ".", "data", ".", "TFRecordDataset", "(", "filename", ",", "compression_type", "=", "_COMPRESSION_TYPE", ",", "buffer_size", "=", "_DEFAULT_READER_BUFFER_SIZE_BYTES", ")", ",", "\n", "cycle_length", "=", "num_concurrent_reads", ",", "block_length", "=", "1", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "lambda", "record", ":", "self", ".", "_parse_example", "(", "record", ")", ",", "num_parallel_calls", "=", "num_parallel_calls", ")", "\n", "\n", "if", "self", ".", "augmenter", "is", "not", "None", ":", "\n", "            ", "apply_augs", "=", "lambda", "i", ",", "m", ":", "self", ".", "augmenter", ".", "apply_augmentations", "(", "i", ",", "m", ",", "return_image_mask_in_list", "=", "False", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "\n", "lambda", "image", ",", "mask", ":", "tf", ".", "py_func", "(", "apply_augs", ",", "[", "image", ",", "mask", "]", ",", "[", "tf", ".", "float32", ",", "tf", ".", "float32", "]", ")", ",", "\n", "num_parallel_calls", "=", "num_parallel_calls", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "lambda", "image", ",", "mask", ":", "(", "\n", "tf", ".", "reshape", "(", "image", ",", "(", "self", ".", "image_width", ",", "self", ".", "image_width", ",", "self", ".", "image_channels", ")", ")", ",", "\n", "tf", ".", "reshape", "(", "mask", ",", "(", "self", ".", "image_width", ",", "self", ".", "image_width", ",", "self", ".", "mask_channels", ")", ")", ")", ",", "\n", "num_parallel_calls", "=", "num_parallel_calls", ")", "\n", "\n", "", "dataset", "=", "dataset", ".", "shuffle", "(", "_SHUFFLE_BUFFER_SIZE", ")", "\n", "dataset", "=", "dataset", ".", "batch", "(", "batch_size", ")", "\n", "dataset", "=", "dataset", ".", "prefetch", "(", "_PREFETCH_BUFFER_SIZE", ")", "\n", "# debug(dataset)  # Uncomment to visualize examples", "\n", "iterator", "=", "tf", ".", "data", ".", "Iterator", ".", "from_structure", "(", "\n", "dataset", ".", "output_types", ",", "dataset", ".", "output_shapes", ")", "\n", "next_element", "=", "iterator", ".", "get_next", "(", ")", "\n", "ds_init_op", "=", "iterator", ".", "make_initializer", "(", "dataset", ")", "\n", "\n", "return", "next_element", ",", "ds_init_op", "\n", "\n", "", "def", "_parse_example", "(", "self", ",", "example", ",", "scale_to_0_1", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Parse a TF Example into corresponding image and mask.\n\n        Positive class is assumed to be encoded as the int value 255 in tfrecords.\n\n        Args:\n            record_name: name of the tfrecord indicating the class\n            example: Batch of TF Example protos.\n            image_width: Width to resize to of image and mask, assumed to be same as height.\n            scale_to_0_1: if True, scale images by dividing by 255.\n\n        Returns:\n            A pair of 3 channel float images and n-channel float segmentation masks.\n            The first channel in the masks will be the background, the rest\n            will be the classes of interest.\n        \"\"\"", "\n", "\n", "features", "=", "{", "\n", "'image'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_utils.split_train_test_tasks": [[8, 20], ["range", "fss_1000_utils.assert_train_test_split", "isinstance", "list", "sorted", "random.shuffle", "test_set.append", "sorted.pop"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg.assert_train_test_split"], ["def", "split_train_test_tasks", "(", "all_tasks", ":", "List", "[", "str", "]", ",", "n_test", ",", "reproducbile_splits", ":", "bool", "=", "False", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "all_tasks", ",", "list", ")", ":", "\n", "        ", "all_tasks", "=", "list", "(", "all_tasks", ")", "\n", "", "if", "reproducbile_splits", ":", "\n", "        ", "all_tasks", "=", "sorted", "(", "all_tasks", ")", "\n", "", "else", ":", "\n", "        ", "random", ".", "shuffle", "(", "all_tasks", ")", "\n", "", "test_set", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_test", ")", ":", "\n", "        ", "test_set", ".", "append", "(", "all_tasks", ".", "pop", "(", ")", ")", "\n", "", "assert_train_test_split", "(", "all_tasks", ",", "test_set", ")", "\n", "return", "all_tasks", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_utils.assert_train_test_split": [[22, 25], ["None"], "function", ["None"], ["", "def", "assert_train_test_split", "(", "train", ",", "test", ")", ":", "\n", "    ", "for", "i", "in", "test", ":", "\n", "        ", "assert", "i", "not", "in", "train", ",", "\"train-test leakage\"", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_utils.get_fss_tasks": [[27, 29], ["glob.glob", "os.path.join"], "function", ["None"], ["", "", "def", "get_fss_tasks", "(", "data_dir", ")", ":", "\n", "    ", "return", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"*.tfrecord*\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_utils.get_fss_test_set": [[31, 38], ["os.path.dirname", "os.path.join", "open", "line.rstrip"], "function", ["None"], ["", "def", "get_fss_test_set", "(", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "path", "=", "\"fss_test_set.txt\"", "# File containing the test examples from the FSS-1000 authors.", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "path", ")", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "file", ":", "\n", "        ", "tasks", "=", "[", "line", ".", "rstrip", "(", "\"\\n\"", ")", "for", "line", "in", "file", "]", "\n", "", "return", "tasks", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_utils.get_fss_train_set": [[40, 47], ["os.path.dirname", "os.path.join", "open", "line.rstrip"], "function", ["None"], ["", "def", "get_fss_train_set", "(", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "path", "=", "\"fss_train_set.txt\"", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "path", ")", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "file", ":", "\n", "        ", "tasks", "=", "[", "line", ".", "rstrip", "(", "\"\\n\"", ")", "for", "line", "in", "file", "]", "\n", "", "return", "tasks", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_utils.get_fp_k_test_set": [[49, 56], ["os.path.dirname", "os.path.join", "open", "line.rstrip"], "function", ["None"], ["", "def", "get_fp_k_test_set", "(", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "path", "=", "\"fp-k_test_set.txt\"", "# File containing the test examples from the FSS-1000 authors.", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "path", ")", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "file", ":", "\n", "        ", "tasks", "=", "[", "line", ".", "rstrip", "(", "\"\\n\"", ")", "for", "line", "in", "file", "]", "\n", "", "return", "tasks", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.parse_arguments": [[28, 52], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "sys.argv"], "function", ["None"], ["def", "parse_arguments", "(", "argv", ")", ":", "\n", "    ", "\"\"\"Parses command line arguments.\"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Writes FSS-1000 images to TFRecords.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--input_dir'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "'Absolute path to base directory of the FSS-1000 dataset.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--tfrecord_dir'", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'Directory to write tfrecords to.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--overwrite'", ",", "\n", "required", "=", "False", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Overwrite existing tfrecords?'", ")", "\n", "parser", ".", "add_argument", "(", "\"--compress\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--fp_k_test_set\"", ",", "help", "=", "\"Hold out the test task for the fp-k classes.\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_val_tasks\"", ",", "help", "=", "\"Number of validation tasks to hold out in addition to the 240 test tasks.\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "args", ",", "_", "=", "parser", ".", "parse_known_args", "(", "args", "=", "argv", "[", "1", ":", "]", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.get_fss_dir_paths": [[54, 56], ["glob.glob", "os.path.join"], "function", ["None"], ["", "def", "get_fss_dir_paths", "(", "data_dir", ")", ":", "\n", "    ", "return", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"*/\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.get_image_mask_pairs": [[58, 68], ["glob.glob", "os.path.join", "mask.replace", "os.path.exists", "image_mask_pairs.append", "warnings.warn"], "function", ["None"], ["", "def", "get_image_mask_pairs", "(", "task", ":", "str", ",", "image_ext", ":", "str", "=", "\".jpg\"", ",", "mask_ext", ":", "str", "=", "\".png\"", ")", "->", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", ":", "\n", "    ", "masks", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "task", ",", "\"*\"", "+", "mask_ext", ")", ")", "\n", "image_mask_pairs", "=", "[", "]", "\n", "for", "mask", "in", "masks", ":", "\n", "        ", "image", "=", "mask", ".", "replace", "(", "mask_ext", ",", "image_ext", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "image", ")", ":", "\n", "            ", "image_mask_pairs", ".", "append", "(", "(", "image", ",", "mask", ")", ")", "\n", "", "else", ":", "\n", "            ", "warnings", ".", "warn", "(", "\"No corresponding image found for mask: {}\"", ".", "format", "(", "mask", ")", ")", "\n", "", "", "return", "image_mask_pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.main": [[70, 111], ["print", "time.time", "print", "fss_1000_image_to_joint_tfrecord_shards.parse_arguments", "fss_1000_image_to_joint_tfrecord_shards.get_fss_train_test_absolute_dir_paths", "data.fss_1000_utils.split_train_test_tasks", "zip", "print", "print", "fss_1000_image_to_joint_tfrecord_shards.mkdir", "os.path.join", "len", "print", "image_mask_pairs.extend", "len", "len", "fss_1000_image_to_joint_tfrecord_shards.get_image_mask_pairs", "fss_1000_image_to_joint_tfrecord_shards.write_tfrecords", "print", "os.path.exists", "time.time"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.parse_arguments", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.get_fss_train_test_absolute_dir_paths", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_utils.split_train_test_tasks", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.mkdir", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.get_image_mask_pairs", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.write_tfrecords"], ["", "def", "main", "(", ")", ":", "\n", "    ", "\"\"\"Write images to TFRecords.\"\"\"", "\n", "print", "(", "\"Converting FSS-1000 image-mask pairs to tfrecord shards.\"", ")", "\n", "dry_run", "=", "False", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "start", ")", "\n", "args", "=", "parse_arguments", "(", "sys", ".", "argv", ")", "\n", "if", "args", ".", "compress", ":", "\n", "        ", "ext", "=", "\".tfrecord.gzip\"", "\n", "", "else", ":", "\n", "        ", "ext", "=", "\".tfrecord\"", "\n", "\n", "", "if", "args", ".", "fp_k_test_set", ":", "\n", "        ", "test_task_ids", "=", "FP_K_TEST_TASK_IDS", "\n", "", "else", ":", "\n", "        ", "test_task_ids", "=", "TEST_TASK_IDS", "\n", "\n", "", "train_dirs", ",", "test_dirs", ",", "all_classes", "=", "get_fss_train_test_absolute_dir_paths", "(", "args", ".", "input_dir", ",", "test_task_ids", "=", "test_task_ids", ")", "\n", "\n", "train_dirs", ",", "val_dirs", "=", "split_train_test_tasks", "(", "train_dirs", ",", "args", ".", "num_val_tasks", ",", "reproducbile_splits", "=", "True", ")", "\n", "\n", "assert", "len", "(", "train_dirs", ")", "+", "len", "(", "val_dirs", ")", "+", "len", "(", "test_dirs", ")", "==", "TOTAL_NUM_FSS_CLASSES", "\n", "\n", "if", "not", "dry_run", ":", "\n", "        ", "mkdir", "(", "args", ".", "tfrecord_dir", ")", "\n", "\n", "", "for", "set_name", ",", "paths", "in", "zip", "(", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", ",", "[", "train_dirs", ",", "val_dirs", ",", "test_dirs", "]", ")", ":", "\n", "        ", "image_mask_pairs", "=", "[", "]", "\n", "for", "folder", "in", "paths", ":", "\n", "            ", "print", "(", "\"folder: {}\"", ".", "format", "(", "folder", ")", ")", "\n", "image_mask_pairs", ".", "extend", "(", "get_image_mask_pairs", "(", "folder", ")", ")", "\n", "\n", "", "tfrecord_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "tfrecord_dir", ",", "set_name", "+", "ext", ")", "\n", "\n", "if", "not", "dry_run", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "tfrecord_filename", ")", "or", "args", ".", "overwrite", ":", "\n", "                ", "write_tfrecords", "(", "tfrecord_filename", ",", "image_mask_pairs", ",", "all_classes", ",", "compress", "=", "args", ".", "compress", ")", "\n", "print", "(", "\"Wrote tfrecord file to {}\"", ".", "format", "(", "tfrecord_filename", ")", ")", "\n", "\n", "", "", "", "print", "(", "\"Finished.\"", ")", "\n", "print", "(", "\"Took {} minutes.\"", ".", "format", "(", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60.0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.get_fss_train_test_absolute_dir_paths": [[113, 121], ["fss_1000_image_to_joint_tfrecord_shards.get_classes_from_subdirs", "list", "list", "set", "sorted", "set", "set", "len", "len", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.get_classes_from_subdirs"], ["", "def", "get_fss_train_test_absolute_dir_paths", "(", "data_dir", ",", "test_task_ids", ":", "List", "[", "str", "]", "=", "TEST_TASK_IDS", ")", ":", "\n", "    ", "expected_classes", "=", "TOTAL_NUM_FSS_CLASSES", "\n", "all_classes", "=", "get_classes_from_subdirs", "(", "data_dir", ",", "expected_classes", ")", "\n", "train_classes", "=", "list", "(", "set", "(", "all_classes", ")", "-", "set", "(", "test_task_ids", ")", ")", "\n", "test_classes", "=", "list", "(", "set", "(", "test_task_ids", ")", ")", "\n", "assert", "len", "(", "train_classes", ")", "+", "len", "(", "test_classes", ")", "==", "expected_classes", "\n", "\n", "return", "[", "os", ".", "path", ".", "join", "(", "data_dir", ",", "x", ")", "for", "x", "in", "train_classes", "]", ",", "[", "os", ".", "path", ".", "join", "(", "data_dir", ",", "x", ")", "for", "x", "in", "test_classes", "]", ",", "sorted", "(", "all_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.get_classes_from_subdirs": [[123, 132], ["os.listdir", "sorted", "len", "print", "pdb.set_trace", "os.path.isdir", "os.path.join"], "function", ["None"], ["", "def", "get_classes_from_subdirs", "(", "data_dir", ",", "expected_num_classes", ":", "int", ")", ":", "\n", "    ", "\"\"\"Get the classes from the names of the subdirectories\"\"\"", "\n", "all_classes", "=", "os", ".", "listdir", "(", "data_dir", ")", "\n", "all_classes", "=", "[", "x", "for", "x", "in", "all_classes", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "x", ")", ")", "]", "\n", "if", "len", "(", "all_classes", ")", "!=", "expected_num_classes", ":", "\n", "        ", "print", "(", "\"length of found classes does not equal number of expected classes\"", ")", "\n", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "", "all_classes", "=", "sorted", "(", "all_classes", ")", "\n", "return", "all_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.mkdir": [[134, 140], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "def", "mkdir", "(", "path", ")", ":", "\n", "    ", "\"\"\"\n    Recursive create dir at `path` if `path` does not exist.\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.one_hot_encode": [[142, 160], ["len", "class_names.index", "numpy.zeros"], "function", ["None"], ["", "", "def", "one_hot_encode", "(", "mask", ",", "class_name", ":", "str", ",", "class_names", ":", "List", "[", "str", "]", ",", "image_width", ":", "int", "=", "IMAGE_DIMS", ",", "truth_value", ":", "int", "=", "255", ",", "seperate_background_channel", ":", "bool", "=", "True", ")", ":", "\n", "    ", "if", "seperate_background_channel", ":", "\n", "        ", "background", "=", "truth_value", "-", "mask", "\n", "\n", "", "n_classes", "=", "len", "(", "class_names", ")", "\n", "i", "=", "class_names", ".", "index", "(", "class_name", ")", "\n", "\n", "if", "seperate_background_channel", ":", "\n", "        ", "n_classes", "+=", "1", "\n", "i", "+=", "1", "\n", "\n", "", "all_classes", "=", "np", ".", "zeros", "(", "[", "image_width", ",", "image_width", ",", "n_classes", "]", ")", "\n", "all_classes", "[", ":", ",", ":", ",", "i", "]", "=", "mask", "\n", "\n", "if", "seperate_background_channel", ":", "\n", "        ", "all_classes", "[", ":", ",", ":", ",", "0", "]", "=", "background", "\n", "\n", "", "return", "all_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.image_to_feature": [[162, 188], ["imageio.imread", "os.path.basename", "one_hot_encode.astype", "tensorflow.train.BytesList", "tensorflow.train.Feature", "print", "fss_1000_image_to_joint_tfrecord_shards.one_hot_encode", "pathlib.Path", "len", "one_hot_encode.tobytes"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.one_hot_encode"], ["", "def", "image_to_feature", "(", "image_filename", ",", "take_first_channel", "=", "False", ",", "one_hot_encode_mask", "=", "False", ",", "all_classes", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "serialize_as", "=", "SERIALIZED_DTYPE", ")", ":", "\n", "    ", "\"\"\"\n    Converts target image to a bytes feature.\n\n    Args:\n        image_filename: Full path of image with image type extension.\n        take_first_channel: Set to True for masks.\n\n    Returns:\n        TF bytes Feature for the image.\n    \"\"\"", "\n", "im", "=", "imageio", ".", "imread", "(", "image_filename", ")", "\n", "class_name", "=", "os", ".", "path", ".", "basename", "(", "Path", "(", "image_filename", ")", ".", "parent", ")", "\n", "img_shape", "=", "im", ".", "shape", "\n", "height", ",", "width", "=", "im", ".", "shape", "[", "0", "]", ",", "im", ".", "shape", "[", "1", "]", "\n", "if", "height", "!=", "IMAGE_DIMS", "or", "width", "!=", "IMAGE_DIMS", ":", "\n", "        ", "print", "(", "\"{} is not of expected image dimensions. Skipping this sample\"", ".", "format", "(", "image_filename", ")", ")", "\n", "return", "None", "\n", "", "if", "take_first_channel", ":", "\n", "        ", "if", "len", "(", "img_shape", ")", ">", "2", ":", "\n", "            ", "im", "=", "im", "[", ":", ",", ":", ",", "0", "]", "\n", "", "", "if", "one_hot_encode_mask", ":", "\n", "        ", "im", "=", "one_hot_encode", "(", "im", ",", "class_name", "=", "class_name", ",", "class_names", "=", "all_classes", ")", "\n", "", "im", "=", "im", ".", "astype", "(", "serialize_as", ")", "\n", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "im", ".", "tobytes", "(", ")", "]", ")", "\n", "return", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "bytes_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.make_example": [[190, 202], ["fss_1000_image_to_joint_tfrecord_shards.image_to_feature", "tensorflow.train.Features", "tensorflow.train.Example", "fss_1000_image_to_joint_tfrecord_shards.image_to_feature"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.image_to_feature", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.image_to_feature"], ["", "def", "make_example", "(", "image_filename", ",", "mask_filename", ",", "all_classes", ")", ":", "\n", "    ", "\"\"\"Collect TF Features into a TF Example.\"\"\"", "\n", "image", "=", "image_to_feature", "(", "image_filename", ")", "\n", "mask", "=", "image_to_feature", "(", "mask_filename", ",", "take_first_channel", "=", "True", ",", "one_hot_encode_mask", "=", "True", ",", "all_classes", "=", "all_classes", ")", ",", "\n", "if", "(", "image", "is", "None", ")", "or", "(", "mask", "is", "None", ")", ":", "\n", "        ", "return", "None", "\n", "", "feature", "=", "{", "\n", "'image'", ":", "image", ",", "\n", "'mask'", ":", "mask", ",", "\n", "}", "\n", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "feature", ")", "\n", "return", "tf", ".", "train", ".", "Example", "(", "features", "=", "features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.image_mask_are_valid": [[204, 216], ["all", "imageio.imread", "fss_1000_image_to_joint_tfrecord_shards.image_mask_are_valid._valid"], "function", ["None"], ["", "def", "image_mask_are_valid", "(", "image", ":", "str", ",", "mask", ":", "str", ")", "->", "bool", ":", "\n", "    ", "def", "_valid", "(", "image_filename", ")", ":", "\n", "        ", "im", "=", "imageio", ".", "imread", "(", "image_filename", ")", "\n", "height", ",", "width", "=", "im", ".", "shape", "[", "0", "]", ",", "im", ".", "shape", "[", "1", "]", "\n", "if", "height", "!=", "IMAGE_DIMS", "or", "width", "!=", "IMAGE_DIMS", ":", "\n", "            ", "print", "(", "\"{} is not of expected image dimensions. Skipping this sample\"", ".", "format", "(", "image_filename", ")", ")", "\n", "return", "False", "\n", "", "return", "True", "\n", "", "res", "=", "[", "_valid", "(", "x", ")", "for", "x", "in", "[", "image", ",", "mask", "]", "]", "\n", "if", "all", "(", "res", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.chunks": [[218, 222], ["range", "len"], "function", ["None"], ["", "def", "chunks", "(", "lst", ",", "n", ")", ":", "\n", "    ", "\"\"\"Yield successive n-sized chunks from lst.\"\"\"", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "lst", ")", ",", "n", ")", ":", "\n", "        ", "yield", "lst", "[", "i", ":", "i", "+", "n", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.write_tfrecords": [[224, 246], ["isinstance", "random.shuffle", "len", "int", "enumerate", "min", "list", "math.ceil", "shard_filename_pairs[].append", "multiprocessing.pool.Pool", "pool.starmap", "isinstance", "ValueError", "range", "range", "zip", "float", "float", "itertools.repeat", "itertools.repeat", "type"], "function", ["None"], ["", "", "def", "write_tfrecords", "(", "tfrecord_basename", ",", "filename_pairs", ",", "all_classes", ":", "List", "[", "str", "]", ",", "max_examples", ":", "int", "=", "200", ",", "compress", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Write tfrecord shards in parallel\"\"\"", "\n", "if", "isinstance", "(", "filename_pairs", ",", "zip", ")", ":", "\n", "        ", "filename_pairs", "=", "list", "(", "filename_pairs", ")", "\n", "", "elif", "not", "isinstance", "(", "filename_pairs", ",", "list", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"filename_pairs must be list or zip object but is {}\"", ".", "format", "(", "type", "(", "filename_pairs", ")", ")", ")", "\n", "", "random", ".", "shuffle", "(", "filename_pairs", ")", "\n", "num_examples", "=", "len", "(", "filename_pairs", ")", "\n", "\n", "num_shards", "=", "int", "(", "math", ".", "ceil", "(", "float", "(", "num_examples", ")", "/", "float", "(", "max_examples", ")", ")", ")", "\n", "record_names", "=", "[", "'%s-%05i-of-%05i'", "%", "(", "tfrecord_basename", ",", "n", "+", "1", ",", "num_shards", ")", "for", "n", "in", "range", "(", "num_shards", ")", "]", "\n", "\n", "shard_filename_pairs", "=", "[", "[", "]", "for", "_", "in", "range", "(", "num_shards", ")", "]", "\n", "for", "n", ",", "filename_pair", "in", "enumerate", "(", "filename_pairs", ")", ":", "\n", "        ", "sublist_index", "=", "n", "%", "num_shards", "\n", "shard_filename_pairs", "[", "sublist_index", "]", ".", "append", "(", "filename_pair", ")", "\n", "\n", "", "iterable", "=", "[", "(", "fn", ",", "fn_pairs", ",", "ac", ",", "compress_bool", ")", "for", "fn", ",", "fn_pairs", ",", "ac", ",", "compress_bool", "in", "zip", "(", "record_names", ",", "shard_filename_pairs", ",", "repeat", "(", "all_classes", ")", ",", "repeat", "(", "compress", ")", ")", "]", "\n", "\n", "num_processes", "=", "min", "(", "num_shards", ",", "MAX_NUM_PROCESSES", ")", "\n", "with", "Pool", "(", "num_processes", ")", "as", "pool", ":", "\n", "        ", "pool", ".", "starmap", "(", "write_tfrecord", ",", "iterable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.write_tfrecord": [[248, 278], ["print", "tensorflow.python_io.TFRecordWriter", "enumerate", "tf.python_io.TFRecordWriter.close", "print", "tensorflow.python_io.TFRecordOptions", "fss_1000_image_to_joint_tfrecord_shards.make_example", "make_example.SerializeToString", "tf.python_io.TFRecordWriter.write", "fss_1000_image_to_joint_tfrecord_shards.image_mask_are_valid"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.make_example", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.image_mask_are_valid"], ["", "", "def", "write_tfrecord", "(", "tfrecord_filename", ",", "filename_pairs", ",", "all_classes", ":", "List", "[", "str", "]", ",", "compress", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Write TFExamples containing images and masks to TFRecord(s).\n\n    Args:\n      tfrecord_filename: Filename to write record to, full path and extension.\n      filename_pairs: List of (image_filename, mask_filename) tuples.\n      all_classes: Dict mapping string to integer index\n    \"\"\"", "\n", "print", "(", "\"Writing examples to tfrecord at {}\"", ".", "format", "(", "tfrecord_filename", ")", ")", "\n", "if", "compress", ":", "\n", "        ", "options", "=", "tf", ".", "python_io", ".", "TFRecordOptions", "(", "\n", "compression_type", "=", "tf", ".", "python_io", ".", "TFRecordCompressionType", ".", "GZIP", ")", "\n", "", "else", ":", "\n", "        ", "options", "=", "None", "\n", "", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "\n", "tfrecord_filename", ",", "\n", "options", ")", "\n", "for", "n", ",", "filename_pair", "in", "enumerate", "(", "filename_pairs", ")", ":", "\n", "        ", "image_filename", ",", "mask_filename", "=", "filename_pair", "\n", "if", "not", "image_mask_are_valid", "(", "image_filename", ",", "mask_filename", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "example", "=", "make_example", "(", "image_filename", ",", "mask_filename", ",", "all_classes", ")", "\n", "\n", "if", "example", "is", "None", ":", "\n", "            ", "continue", "\n", "", "serialized_example", "=", "example", ".", "SerializeToString", "(", ")", "\n", "writer", ".", "write", "(", "serialized_example", ")", "\n", "", "writer", ".", "close", "(", ")", "\n", "print", "(", "\"Examples written to {}\"", ".", "format", "(", "tfrecord_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_joint_tfrecord_shards.old_write_tfrecord": [[280, 321], ["tensorflow.python_io.TFRecordOptions", "isinstance", "random.shuffle", "len", "int", "enumerate", "print", "list", "math.ceil", "tensorflow.python_io.TFRecordWriter", "fss_1000_image_to_joint_tfrecord_shards.make_example", "make_example.SerializeToString", "writer.write", "writer.close", "isinstance", "ValueError", "range", "fss_1000_image_to_joint_tfrecord_shards.image_mask_are_valid", "float", "float", "type"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.make_example", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.image_mask_are_valid"], ["", "def", "old_write_tfrecord", "(", "tfrecord_filename", ",", "filename_pairs", ",", "all_classes", ":", "List", "[", "str", "]", ",", "max_examples", ":", "int", "=", "200", ")", ":", "\n", "    ", "\"\"\"Write TFExamples containing images and masks to TFRecord(s).\n\n    Args:\n      tfrecord_filename: Filename to write record to, full path and extension.\n      filename_pairs: List of (image_filename, mask_filename) tuples.\n      all_classes: Dict mapping string to integer index\n      max_examples: Maximum number of examples to write to each TFRecord shard.\n    \"\"\"", "\n", "options", "=", "tf", ".", "python_io", ".", "TFRecordOptions", "(", "\n", "compression_type", "=", "tf", ".", "python_io", ".", "TFRecordCompressionType", ".", "GZIP", ")", "\n", "if", "isinstance", "(", "filename_pairs", ",", "zip", ")", ":", "\n", "        ", "filename_pairs", "=", "list", "(", "filename_pairs", ")", "\n", "", "elif", "not", "isinstance", "(", "filename_pairs", ",", "list", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"filename_pairs must be list or zip object but is {}\"", ".", "format", "(", "type", "(", "filename_pairs", ")", ")", ")", "\n", "", "random", ".", "shuffle", "(", "filename_pairs", ")", "\n", "num_examples", "=", "len", "(", "filename_pairs", ")", "\n", "# Casting for consistent behavior in python 2 and 3.", "\n", "num_shards", "=", "int", "(", "math", ".", "ceil", "(", "float", "(", "num_examples", ")", "/", "float", "(", "max_examples", ")", ")", ")", "\n", "writers", "=", "[", "\n", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "\n", "'%s-%05i-of-%05i'", "%", "(", "tfrecord_filename", ",", "n", "+", "1", ",", "num_shards", ")", ",", "\n", "options", ",", "\n", ")", "for", "n", "in", "range", "(", "num_shards", ")", "\n", "]", "\n", "\n", "for", "n", ",", "filename_pair", "in", "enumerate", "(", "filename_pairs", ")", ":", "\n", "        ", "writer", "=", "writers", "[", "n", "%", "num_shards", "]", "\n", "image_filename", ",", "mask_filename", "=", "filename_pair", "\n", "if", "not", "image_mask_are_valid", "(", "image_filename", ",", "mask_filename", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "example", "=", "make_example", "(", "image_filename", ",", "mask_filename", ",", "all_classes", ")", "\n", "\n", "if", "example", "is", "None", ":", "\n", "            ", "continue", "\n", "", "serialized_example", "=", "example", ".", "SerializeToString", "(", ")", "\n", "writer", ".", "write", "(", "serialized_example", ")", "\n", "", "for", "writer", "in", "writers", ":", "\n", "        ", "writer", ".", "close", "(", ")", "\n", "", "print", "(", "\"Examples written to {}\"", ".", "format", "(", "tfrecord_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.parse_arguments": [[23, 44], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "sys.argv"], "function", ["None"], ["def", "parse_arguments", "(", "argv", ")", ":", "\n", "    ", "\"\"\"Parses command line arguments.\"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Writes FSS-1000 images to TFRecords.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--input_dir'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "'Absolute path to base directory of the FSS-1000 dataset.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--tfrecord_dir'", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'Directory to write tfrecords to.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--overwrite'", ",", "\n", "required", "=", "False", ",", "\n", "default", "=", "False", ",", "\n", "type", "=", "bool", ",", "\n", "help", "=", "'Overwrite existing tfrecords?'", ")", "\n", "args", ",", "_", "=", "parser", ".", "parse_known_args", "(", "args", "=", "argv", "[", "1", ":", "]", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.get_fss_dir_paths": [[46, 48], ["glob.glob", "os.path.join"], "function", ["None"], ["", "def", "get_fss_dir_paths", "(", "data_dir", ")", ":", "\n", "    ", "return", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"*/\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.get_image_mask_pairs": [[50, 60], ["glob.glob", "os.path.join", "mask.replace", "os.path.exists", "image_mask_pairs.append", "warnings.warn"], "function", ["None"], ["", "def", "get_image_mask_pairs", "(", "task", ":", "str", ",", "image_ext", ":", "str", "=", "\".jpg\"", ",", "mask_ext", ":", "str", "=", "\".png\"", ")", "->", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", ":", "\n", "    ", "masks", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "task", ",", "\"*\"", "+", "mask_ext", ")", ")", "\n", "image_mask_pairs", "=", "[", "]", "\n", "for", "mask", "in", "masks", ":", "\n", "        ", "image", "=", "mask", ".", "replace", "(", "mask_ext", ",", "image_ext", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "image", ")", ":", "\n", "            ", "image_mask_pairs", ".", "append", "(", "(", "image", ",", "mask", ")", ")", "\n", "", "else", ":", "\n", "            ", "warnings", ".", "warn", "(", "\"No corresponding image found for mask: {}\"", ".", "format", "(", "mask", ")", ")", "\n", "", "", "return", "image_mask_pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.main": [[62, 89], ["print", "time.time", "print", "fss_1000_image_to_tfrecord.parse_arguments", "fss_1000_image_to_tfrecord.get_fss_dir_paths", "print", "print", "print", "fss_1000_image_to_tfrecord.mkdir", "fss_1000_image_to_tfrecord.get_image_mask_pairs", "os.path.basename", "print", "os.path.join", "len", "task.rstrip", "fss_1000_image_to_tfrecord.write_tfrecord", "print", "os.path.exists", "time.time"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.parse_arguments", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.get_fss_dir_paths", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.mkdir", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.get_image_mask_pairs", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.write_tfrecord"], ["", "def", "main", "(", ")", ":", "\n", "    ", "\"\"\"Write images to TFRecords.\"\"\"", "\n", "print", "(", "\"Converting FSS-1000 image-mask pairs to tfrecords, one per task.\"", ")", "\n", "dry_run", "=", "False", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "start", ")", "\n", "args", "=", "parse_arguments", "(", "sys", ".", "argv", ")", "\n", "\n", "task_dirs", "=", "get_fss_dir_paths", "(", "args", ".", "input_dir", ")", "\n", "print", "(", "\"{} tasks found\"", ".", "format", "(", "len", "(", "task_dirs", ")", ")", ")", "\n", "\n", "if", "not", "dry_run", ":", "\n", "        ", "mkdir", "(", "args", ".", "tfrecord_dir", ")", "\n", "\n", "", "for", "task", "in", "task_dirs", ":", "\n", "        ", "image_mask_pairs", "=", "get_image_mask_pairs", "(", "task", ")", "\n", "task_name", "=", "os", ".", "path", ".", "basename", "(", "task", ".", "rstrip", "(", "\"/\"", ")", ")", "\n", "print", "(", "\"Processing task: {}\"", ".", "format", "(", "task_name", ")", ")", "\n", "tfrecord_filename", "=", "os", ".", "path", ".", "join", "(", "args", ".", "tfrecord_dir", ",", "task_name", "+", "\".tfrecord.gzip\"", ")", "\n", "\n", "if", "not", "dry_run", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "tfrecord_filename", ")", "or", "args", ".", "overwrite", ":", "\n", "                ", "write_tfrecord", "(", "tfrecord_filename", ",", "image_mask_pairs", ")", "\n", "print", "(", "\"Wrote tfrecord file to {}\"", ".", "format", "(", "tfrecord_filename", ")", ")", "\n", "\n", "", "", "", "print", "(", "\"Finished.\"", ")", "\n", "print", "(", "\"Took {} minutes.\"", ".", "format", "(", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60.0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.mkdir": [[91, 97], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "def", "mkdir", "(", "path", ")", ":", "\n", "    ", "\"\"\"\n    Recursive create dir at `path` if `path` does not exist.\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.image_to_feature": [[99, 121], ["imageio.imread", "tensorflow.train.BytesList", "tensorflow.train.Feature", "print", "len", "imageio.imread.tobytes"], "function", ["None"], ["", "", "def", "image_to_feature", "(", "image_filename", ",", "take_first_channel", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Converts target image to a bytes feature.\n\n    Args:\n        image_filename: Full path of image with image type extension.\n        take_first_channel: Set to True for masks.\n\n    Returns:\n        TF bytes Feature for the image.\n    \"\"\"", "\n", "im", "=", "imageio", ".", "imread", "(", "image_filename", ")", "\n", "img_shape", "=", "im", ".", "shape", "\n", "height", ",", "width", "=", "im", ".", "shape", "[", "0", "]", ",", "im", ".", "shape", "[", "1", "]", "\n", "if", "height", "!=", "IMAGE_DIMS", "or", "width", "!=", "IMAGE_DIMS", ":", "\n", "        ", "print", "(", "\"{} is not of expected image dimensions. Skipping this sample\"", ".", "format", "(", "image_filename", ")", ")", "\n", "return", "None", "\n", "", "if", "take_first_channel", ":", "\n", "        ", "if", "len", "(", "img_shape", ")", ">", "2", ":", "\n", "            ", "im", "=", "im", "[", ":", ",", ":", ",", "0", "]", "\n", "", "", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "im", ".", "tobytes", "(", ")", "]", ")", "\n", "return", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "bytes_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.make_example": [[123, 135], ["fss_1000_image_to_tfrecord.image_to_feature", "tensorflow.train.Features", "tensorflow.train.Example", "fss_1000_image_to_tfrecord.image_to_feature"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.image_to_feature", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.image_to_feature"], ["", "def", "make_example", "(", "image_filename", ",", "mask_filename", ")", ":", "\n", "    ", "\"\"\"Collect TF Features into a TF Example.\"\"\"", "\n", "image", "=", "image_to_feature", "(", "image_filename", ")", "\n", "mask", "=", "image_to_feature", "(", "mask_filename", ",", "take_first_channel", "=", "True", ")", ",", "\n", "if", "(", "image", "is", "None", ")", "or", "(", "mask", "is", "None", ")", ":", "\n", "        ", "return", "None", "\n", "", "feature", "=", "{", "\n", "'image'", ":", "image", ",", "\n", "'mask'", ":", "mask", ",", "\n", "}", "\n", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "feature", ")", "\n", "return", "tf", ".", "train", ".", "Example", "(", "features", "=", "features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.image_mask_are_valid": [[137, 149], ["all", "imageio.imread", "fss_1000_image_to_tfrecord.image_mask_are_valid._valid"], "function", ["None"], ["", "def", "image_mask_are_valid", "(", "image", ":", "str", ",", "mask", ":", "str", ")", "->", "bool", ":", "\n", "    ", "def", "_valid", "(", "image_filename", ")", ":", "\n", "        ", "im", "=", "imageio", ".", "imread", "(", "image_filename", ")", "\n", "height", ",", "width", "=", "im", ".", "shape", "[", "0", "]", ",", "im", ".", "shape", "[", "1", "]", "\n", "if", "height", "!=", "IMAGE_DIMS", "or", "width", "!=", "IMAGE_DIMS", ":", "\n", "            ", "print", "(", "\"{} is not of expected image dimensions. Skipping this sample\"", ".", "format", "(", "image_filename", ")", ")", "\n", "return", "False", "\n", "", "return", "True", "\n", "", "res", "=", "[", "_valid", "(", "x", ")", "for", "x", "in", "[", "image", ",", "mask", "]", "]", "\n", "if", "all", "(", "res", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.write_tfrecord": [[151, 179], ["tensorflow.python_io.TFRecordOptions", "isinstance", "random.shuffle", "tensorflow.python_io.TFRecordWriter", "tf.python_io.TFRecordWriter.close", "print", "list", "fss_1000_image_to_tfrecord.make_example", "make_example.SerializeToString", "tf.python_io.TFRecordWriter.write", "isinstance", "ValueError", "fss_1000_image_to_tfrecord.image_mask_are_valid", "type"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.make_example", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.image_mask_are_valid"], ["", "def", "write_tfrecord", "(", "tfrecord_filename", ",", "filename_pairs", ",", "max_examples", "=", "None", ")", ":", "\n", "    ", "\"\"\"Write TFExamples containing images and masks to TFRecord(s).\n\n    Args:\n        tfrecord_filename: Filename to write record to, full path and extension.\n        filename_pairs: List of (image_filename, mask_filename) tuples.\n        max_examples: Maximum number of examples to write to each TFRecord shard.\n    \"\"\"", "\n", "options", "=", "tf", ".", "python_io", ".", "TFRecordOptions", "(", "\n", "compression_type", "=", "tf", ".", "python_io", ".", "TFRecordCompressionType", ".", "GZIP", ")", "\n", "if", "isinstance", "(", "filename_pairs", ",", "zip", ")", ":", "\n", "        ", "filename_pairs", "=", "list", "(", "filename_pairs", ")", "\n", "", "elif", "not", "isinstance", "(", "filename_pairs", ",", "list", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"filename_pairs must be list or zip object but is {}\"", ".", "format", "(", "type", "(", "filename_pairs", ")", ")", ")", "\n", "", "random", ".", "shuffle", "(", "filename_pairs", ")", "# Shuffle examples within a task.", "\n", "\n", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "tfrecord_filename", ",", "options", "=", "options", ")", "\n", "i", "=", "0", "\n", "for", "filename_pair", "in", "filename_pairs", ":", "\n", "        ", "image_filename", ",", "mask_filename", "=", "filename_pair", "\n", "if", "not", "image_mask_are_valid", "(", "image_filename", ",", "mask_filename", ")", ":", "\n", "            ", "continue", "\n", "", "example", "=", "make_example", "(", "image_filename", ",", "mask_filename", ")", "\n", "serialized_example", "=", "example", ".", "SerializeToString", "(", ")", "\n", "writer", ".", "write", "(", "serialized_example", ")", "\n", "i", "+=", "1", "\n", "", "writer", ".", "close", "(", ")", "\n", "print", "(", "\"{} examples written to {}\"", ".", "format", "(", "i", ",", "tfrecord_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.VariableState.__init__": [[62, 69], ["tensorflow.group", "tensorflow.placeholder", "tensorflow.assign", "zip", "v.get_shape"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "session", ",", "variables", ")", ":", "\n", "        ", "self", ".", "_session", "=", "session", "\n", "self", ".", "_variables", "=", "variables", "\n", "self", ".", "_placeholders", "=", "[", "tf", ".", "placeholder", "(", "v", ".", "dtype", ".", "base_dtype", ",", "shape", "=", "v", ".", "get_shape", "(", ")", ")", "\n", "for", "v", "in", "variables", "]", "\n", "assigns", "=", "[", "tf", ".", "assign", "(", "v", ",", "p", ")", "for", "v", ",", "p", "in", "zip", "(", "self", ".", "_variables", ",", "self", ".", "_placeholders", ")", "]", "\n", "self", ".", "_assign_op", "=", "tf", ".", "group", "(", "*", "assigns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.VariableState.export_variables": [[70, 75], ["variables.VariableState._session.run"], "methods", ["None"], ["", "def", "export_variables", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Save the current variables.\n        \"\"\"", "\n", "return", "self", ".", "_session", ".", "run", "(", "self", ".", "_variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.VariableState.import_variables": [[76, 81], ["variables.VariableState._session.run", "dict", "zip"], "methods", ["None"], ["", "def", "import_variables", "(", "self", ",", "values", ")", ":", "\n", "        ", "\"\"\"\n        Restore the variables.\n        \"\"\"", "\n", "self", ".", "_session", ".", "run", "(", "self", ".", "_assign_op", ",", "feed_dict", "=", "dict", "(", "zip", "(", "self", ".", "_placeholders", ",", "values", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.interpolate_vars": [[9, 14], ["variables.add_vars", "variables.scale_vars", "variables.subtract_vars"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.add_vars", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.scale_vars", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.subtract_vars"], ["def", "interpolate_vars", "(", "old_vars", ",", "new_vars", ",", "epsilon", ")", ":", "\n", "    ", "\"\"\"\n    Interpolate between two sequences of variables.\n    \"\"\"", "\n", "return", "add_vars", "(", "old_vars", ",", "scale_vars", "(", "subtract_vars", "(", "new_vars", ",", "old_vars", ")", ",", "epsilon", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.average_vars": [[16, 24], ["zip", "res.append", "numpy.mean"], "function", ["None"], ["", "def", "average_vars", "(", "var_seqs", ")", ":", "\n", "    ", "\"\"\"\n    Average a sequence of variable sequences.\n    \"\"\"", "\n", "res", "=", "[", "]", "\n", "for", "variables", "in", "zip", "(", "*", "var_seqs", ")", ":", "\n", "        ", "res", ".", "append", "(", "np", ".", "mean", "(", "variables", ",", "axis", "=", "0", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.subtract_vars": [[26, 32], ["zip"], "function", ["None"], ["", "def", "subtract_vars", "(", "var_seq_1", ",", "var_seq_2", ")", ":", "\n", "    ", "\"\"\"\n    Subtract `var_seq_2` from `var_seq_1`.\n    \"\"\"", "\n", "# import pdb; pdb.set_trace()", "\n", "return", "[", "v1", "-", "v2", "for", "v1", ",", "v2", "in", "zip", "(", "var_seq_1", ",", "var_seq_2", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.add_vars": [[34, 39], ["zip"], "function", ["None"], ["", "def", "add_vars", "(", "var_seq_1", ",", "var_seq_2", ")", ":", "\n", "    ", "\"\"\"\n    Add two variable sequences.\n    \"\"\"", "\n", "return", "[", "v1", "+", "v2", "for", "v1", ",", "v2", "in", "zip", "(", "var_seq_1", ",", "var_seq_2", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.scale_vars": [[41, 46], ["None"], "function", ["None"], ["", "def", "scale_vars", "(", "var_seq", ",", "scale", ")", ":", "\n", "    ", "\"\"\"\n    Scale a variable sequence.\n    \"\"\"", "\n", "return", "[", "v", "*", "scale", "for", "v", "in", "var_seq", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.weight_decay": [[48, 56], ["tensorflow.group", "tensorflow.trainable_variables", "tensorflow.assign"], "function", ["None"], ["", "def", "weight_decay", "(", "rate", ",", "variables", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Create an Op that performs weight decay.\n    \"\"\"", "\n", "if", "variables", "is", "None", ":", "\n", "        ", "variables", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "", "ops", "=", "[", "tf", ".", "assign", "(", "var", ",", "var", "*", "rate", ")", "for", "var", "in", "variables", "]", "\n", "return", "tf", ".", "group", "(", "*", "ops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.EarlyStopper.__init__": [[29, 49], ["print"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "patience", ":", "int", "=", "10", ",", "metric_should_increase", ":", "bool", "=", "True", ",", "min_steps", ":", "int", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            patience: How many steps to continue training if eval does not improve.\n            metric_should_increase: If True, metric is expected to increase (i.e. set to True for accuracy or IoU,\n                False for a loss function such as cross entropy.\n        \"\"\"", "\n", "self", ".", "patience", "=", "patience", "\n", "self", ".", "metric_should_increase", "=", "metric_should_increase", "\n", "if", "metric_should_increase", ":", "\n", "            ", "self", ".", "eval_operator", "=", "operator", ".", "gt", "\n", "", "else", ":", "\n", "            ", "self", ".", "eval_operator", "=", "operator", ".", "lt", "\n", "", "self", ".", "_best_metric", "=", "None", "\n", "self", ".", "_best_num_steps", "=", "None", "\n", "self", ".", "num_evals_without_improving", "=", "0", "\n", "self", ".", "min_steps", "=", "min_steps", "\n", "if", "min_steps", ">", "0", ":", "\n", "            ", "self", ".", "_best_num_steps", "=", "min_steps", "\n", "", "print", "(", "\"Built EarlyStopper with patience {}\"", ".", "format", "(", "self", ".", "patience", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.EarlyStopper.continue_training": [[50, 63], ["hyperparam_search.EarlyStopper.eval_operator"], "methods", ["None"], ["", "def", "continue_training", "(", "self", ",", "metric", ",", "total_steps_taken", ")", ":", "\n", "        ", "if", "total_steps_taken", "<=", "self", ".", "min_steps", ":", "\n", "            ", "self", ".", "_best_metric", "=", "metric", "\n", "return", "True", "\n", "", "elif", "self", ".", "_best_metric", "is", "None", "or", "self", ".", "eval_operator", "(", "metric", ",", "self", ".", "_best_metric", ")", ":", "\n", "            ", "self", ".", "num_evals_without_improving", "=", "0", "\n", "self", ".", "_best_metric", "=", "metric", "\n", "self", ".", "_best_num_steps", "=", "total_steps_taken", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_evals_without_improving", "+=", "1", "\n", "if", "self", ".", "num_evals_without_improving", ">", "self", ".", "patience", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.EarlyStopper.best_metric": [[64, 66], ["None"], "methods", ["None"], ["", "def", "best_metric", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_best_metric", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.EarlyStopper.best_num_steps": [[67, 69], ["None"], "methods", ["None"], ["", "def", "best_num_steps", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_best_num_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.run_m": [[71, 92], ["range", "eval_fn", "all_task_ids.extend", "all_num_steps.extend", "all_metrics.extend"], "function", ["None"], ["", "", "def", "run_m", "(", "eval_fn", ":", "Callable", ",", "params", ":", "Dict", ",", "m", ":", "int", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    Calls `eval_fn` with `params`, returns results. Assumes that eval_fn returns a tuple of:\n        (list of task IDs, list of iterations, and list of metrics).\n\n    Args:\n        eval_fn: A callable that takes `params` and returns a tuple of:\n            (list of task IDs, list of iterations, and list of metrics).\n        params: kwargs fed into eval_fn call\n        m: Number of times to eval_fn(**params).\n\n    Returns:\n        The metrics returned by running eval_fn with params\n    \"\"\"", "\n", "all_task_ids", ",", "all_num_steps", ",", "all_metrics", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "_", "in", "range", "(", "m", ")", ":", "\n", "        ", "task_ids", ",", "num_steps", ",", "metrics", "=", "eval_fn", "(", "**", "params", ")", "\n", "all_task_ids", ".", "extend", "(", "task_ids", ")", "\n", "all_num_steps", ".", "extend", "(", "num_steps", ")", "\n", "all_metrics", ".", "extend", "(", "metrics", ")", "\n", "", "return", "all_task_ids", ",", "all_num_steps", ",", "all_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.save_results": [[94, 131], ["print", "pandas.DataFrame", "os.path.exists", "pd.DataFrame.to_csv", "print", "config.items", "formatted[].extend", "formatted[].extend", "formatted[].extend", "formatted[].extend", "os.path.exists", "range", "range", "len", "len"], "function", ["None"], ["", "def", "save_results", "(", "results", ":", "List", "[", "Tuple", "[", "Dict", ",", "Tuple", "[", "List", ",", "List", ",", "List", "]", "]", "]", ",", "path", ":", "str", ",", "metric_name", ":", "str", "=", "\"mIoU\"", ",", "append_if_exists", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Takes the results and saves them to csv\"\"\"", "\n", "print", "(", "\"Saving results to {}\"", ".", "format", "(", "path", ")", ")", "\n", "# Format results to make a dataframe:", "\n", "formatted", "=", "{", "\"task_ID\"", ":", "[", "]", ",", "\"best_num_steps\"", ":", "[", "]", ",", "metric_name", ":", "[", "]", "}", "\n", "for", "result", "in", "results", ":", "\n", "        ", "config", ",", "config_results", "=", "result", "\n", "task_ids", ",", "num_steps", ",", "metrics", "=", "config_results", "\n", "\n", "for", "key", ",", "val", "in", "config", ".", "items", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "formatted", "[", "key", "]", ".", "extend", "(", "[", "val", "for", "_", "in", "range", "(", "len", "(", "task_ids", ")", ")", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "                ", "formatted", "[", "key", "]", "=", "[", "val", "for", "_", "in", "range", "(", "len", "(", "task_ids", ")", ")", "]", "\n", "\n", "", "", "formatted", "[", "\"task_ID\"", "]", ".", "extend", "(", "task_ids", ")", "\n", "formatted", "[", "\"best_num_steps\"", "]", ".", "extend", "(", "num_steps", ")", "\n", "formatted", "[", "metric_name", "]", ".", "extend", "(", "metrics", ")", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "formatted", ")", "\n", "mode", "=", "\"w\"", "\n", "header", "=", "True", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "if", "not", "append_if_exists", ":", "\n", "            ", "i", "=", "0", "\n", "while", "True", ":", "\n", "                ", "new_path", "=", "path", "+", "\"_{}\"", ".", "format", "(", "i", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "new_path", ")", ":", "\n", "                    ", "break", "\n", "", "i", "+=", "1", "\n", "", "path", "=", "new_path", "\n", "mode", "=", "\"w\"", "\n", "header", "=", "True", "\n", "", "else", ":", "\n", "            ", "mode", "=", "\"a\"", "\n", "header", "=", "False", "\n", "", "", "df", ".", "to_csv", "(", "path", ",", "index", "=", "False", ",", "mode", "=", "mode", ",", "header", "=", "header", ")", "\n", "print", "(", "\"Saved optimization raw results to {}\"", ".", "format", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.compute_best_configuration": [[133, 155], ["print", "print", "print", "numpy.mean", "eval_operator", "int", "numpy.median"], "function", ["None"], ["", "def", "compute_best_configuration", "(", "results_list", ",", "metric_should_increase", "=", "True", ")", ":", "\n", "    ", "if", "metric_should_increase", ":", "\n", "        ", "eval_operator", "=", "operator", ".", "gt", "\n", "best_metric", "=", "-", "np", ".", "inf", "\n", "", "else", ":", "\n", "        ", "eval_operator", "=", "operator", ".", "lt", "\n", "best_metric", "=", "np", ".", "inf", "\n", "\n", "", "for", "sampled_config", ",", "results", "in", "results_list", ":", "\n", "        ", "task_ids", ",", "num_steps", ",", "metrics", "=", "results", "\n", "miou_across_tasks", "=", "np", ".", "mean", "(", "metrics", ")", "\n", "if", "eval_operator", "(", "miou_across_tasks", ",", "best_metric", ")", ":", "\n", "            ", "best_config", "=", "sampled_config", "\n", "best_metric", "=", "miou_across_tasks", "\n", "m_best_num_steps", "=", "np", ".", "median", "(", "num_steps", ")", "\n", "best_step_num", "=", "m_best_num_steps", "\n", "\n", "", "", "print", "(", "\"Best mIoU found: {}\"", ".", "format", "(", "best_metric", ")", ")", "\n", "print", "(", "\"with median iteration: {}\"", ".", "format", "(", "best_step_num", ")", ")", "\n", "print", "(", "\"and config: {}\"", ".", "format", "(", "best_config", ")", ")", "\n", "\n", "return", "best_config", ",", "int", "(", "best_step_num", ")", ",", "best_metric", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.log_opt_progress": [[157, 164], ["print", "print", "hyperparam_search.save_results", "numpy.nanmean"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.save_results"], ["", "def", "log_opt_progress", "(", "hyperparams", ",", "results_i", ",", "task_ids", ",", "num_steps", ",", "metrics", ",", "save_results_to", ")", ":", "\n", "    ", "print", "(", "\"Results for hyperparams {}: task IDs: {}, best num steps: {}, mIoUs: {}\"", ".", "format", "(", "hyperparams", ",", "task_ids", ",", "num_steps", ",", "\n", "metrics", ")", ")", "\n", "print", "(", "\"mean mIoU: {}\"", ".", "format", "(", "np", ".", "nanmean", "(", "metrics", ")", ")", ")", "\n", "\n", "if", "save_results_to", "is", "not", "None", ":", "\n", "        ", "save_results", "(", "[", "results_i", "]", ",", "save_results_to", ",", "append_if_exists", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.insert_sampled_into_full_set_of_hyperparams": [[166, 170], ["sampled.items"], "function", ["None"], ["", "", "def", "insert_sampled_into_full_set_of_hyperparams", "(", "sampled", ",", "hyperparams", ")", "->", "Dict", ":", "\n", "    ", "for", "key", ",", "val", "in", "sampled", ".", "items", "(", ")", ":", "\n", "        ", "hyperparams", "[", "key", "]", "=", "val", "\n", "", "return", "hyperparams", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.get_dim_type": [[172, 182], ["isinstance", "isinstance", "isinstance", "ValueError", "type"], "function", ["None"], ["", "def", "get_dim_type", "(", "value", ":", "List", "[", "Any", "]", ")", ":", "\n", "    ", "value", "=", "value", "[", "0", "]", "\n", "if", "isinstance", "(", "value", ",", "float", ")", ":", "\n", "        ", "return", "Real", "\n", "", "elif", "isinstance", "(", "value", ",", "int", ")", ":", "\n", "        ", "return", "Integer", "\n", "", "elif", "isinstance", "(", "value", ",", "str", ")", ":", "\n", "        ", "return", "Categorical", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Value must be float, int, or str, but {} is {}\"", ".", "format", "(", "value", ",", "type", "(", "value", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.gp_update_hyperparameter_optimization": [[184, 250], ["search_key_ranges.keys", "print", "skopt.Optimizer", "range", "hyperparam_search.compute_best_configuration", "int", "hyperparam_search.get_dim_type", "print", "print", "skopt.Optimizer.ask", "print", "hyperparam_search.insert_sampled_into_full_set_of_hyperparams", "hyperparam_search.run_m", "numpy.nanmean", "print", "skopt.Optimizer.tell", "results.append", "hyperparam_search.log_opt_progress", "search_key_ranges.items", "search_key_ranges.items", "zip"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.compute_best_configuration", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.get_dim_type", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.insert_sampled_into_full_set_of_hyperparams", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.run_m", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.log_opt_progress"], ["", "", "def", "gp_update_hyperparameter_optimization", "(", "eval_fn", ":", "Callable", ",", "hyperparams", ":", "Dict", ",", "search_key_ranges", ":", "Dict", ",", "n", ":", "int", ",", "\n", "save_results_to", ":", "Optional", "[", "str", "]", "=", "\"gp_hyper_param_search_results.csv\"", ",", "m", ":", "int", "=", "1", ",", "\n", "metric_should_increase", ":", "bool", "=", "True", ",", "metric_name", ":", "str", "=", "\"mIoU\"", ",", "base", ":", "int", "=", "2", ",", "\n", "n_initial_points", ":", "Optional", "[", "int", "]", "=", "None", ",", "prior", ":", "str", "=", "\"log-uniform\"", ")", ":", "\n", "    ", "\"\"\"\n    Multitask hyperparameter search with Gaussian process regression of values in search_key_ranges.\n    Calls `eval_fn` with `params`, replacing values in `params` with expected improvement maximizing values sampled from\n     the ranges in `search_key_ranges` for the keys that are in both `params` and `search_key_ranges`.\n\n    Args:\n        eval_fn: The function to call with params that returns a metric.\n        hyperparams: Dictionary of kwargs that must be specified to call eval_fn.\n        search_key_ranges: Dictionary mapping a key in params to a range to sample from.\n        n: number of hyperparameter configurations to sample.\n        m: number of train-val splits datasets to sample\n        metric_should_increase: If true\n        prior: Sample points from this distribution. E.g., \"log-uniform\" sample from a log scaled uniform distribution.\n\n    Returns:\n        Tuple of the sampled values in a dictionary with the same keys as search_key_ranges and the resulting metric.\n    \"\"\"", "\n", "for", "key", "in", "search_key_ranges", ".", "keys", "(", ")", ":", "\n", "        ", "assert", "key", "in", "hyperparams", ",", "\"key: {} not in hyperparams: {}\"", ".", "format", "(", "key", ",", "hyperparams", ")", "\n", "\n", "", "if", "n_initial_points", "is", "None", ":", "\n", "        ", "n_initial_points", "=", "int", "(", "n", "/", "2", ")", "\n", "", "print", "(", "\"Sampling {} points initially at random.\"", ".", "format", "(", "n_initial_points", ")", ")", "\n", "\n", "search_dim_types", "=", "{", "key", ":", "get_dim_type", "(", "val", ")", "for", "key", ",", "val", "in", "search_key_ranges", ".", "items", "(", ")", "}", "\n", "\n", "dims", "=", "[", "search_dim_types", "[", "key", "]", "(", "domain", "[", "0", "]", ",", "domain", "[", "1", "]", ",", "prior", "=", "prior", ",", "base", "=", "base", ",", "name", "=", "key", ")", "for", "key", ",", "domain", "in", "search_key_ranges", ".", "items", "(", ")", "if", "domain", "[", "0", "]", "!=", "domain", "[", "1", "]", "]", "\n", "dim_names", "=", "[", "dim", ".", "name", "for", "dim", "in", "dims", "]", "\n", "opt", "=", "Optimizer", "(", "\n", "dims", ",", "\n", "\"GP\"", ",", "# Estimate metric as a function of lr using a Gaussian Process.", "\n", "acq_func", "=", "'EI'", ",", "# Use Expected Improvement as an acquisition function.", "\n", "acq_optimizer", "=", "\"lbfgs\"", ",", "# Draw random samples from GP then optimize to find best lr to suggest.", "\n", "n_initial_points", "=", "n_initial_points", ",", "# First points will be completely random to avoid exploiting too early.", "\n", ")", "\n", "\n", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "print", "(", "\"Running configuration sample {} of {}.\"", ".", "format", "(", "i", "+", "1", ",", "n", ")", ")", "\n", "print", "(", "\"With sampled hyperparams:\"", ")", "\n", "sampled_list", "=", "opt", ".", "ask", "(", ")", "\n", "sampled", "=", "{", "name", ":", "x", "for", "name", ",", "x", "in", "zip", "(", "dim_names", ",", "sampled_list", ")", "}", "\n", "print", "(", "sampled", ")", "\n", "\n", "hyperparams", "=", "insert_sampled_into_full_set_of_hyperparams", "(", "sampled", ",", "hyperparams", ")", "\n", "\n", "task_ids", ",", "num_steps", ",", "metrics", "=", "run_m", "(", "eval_fn", ",", "hyperparams", ",", "m", ")", "\n", "\n", "# Most recent metric observed for given params", "\n", "objective", "=", "np", ".", "nanmean", "(", "metrics", ")", "\n", "if", "metric_should_increase", ":", "\n", "            ", "objective", "*=", "-", "1", "\n", "", "print", "(", "\"Objective value at sample {} of {}: {}\"", ".", "format", "(", "i", "+", "1", ",", "n", ",", "objective", ")", ")", "\n", "opt_result", "=", "opt", ".", "tell", "(", "sampled_list", ",", "objective", ")", "\n", "\n", "results_i", "=", "(", "sampled", ",", "(", "task_ids", ",", "num_steps", ",", "metrics", ")", ")", "\n", "results", ".", "append", "(", "results_i", ")", "\n", "log_opt_progress", "(", "hyperparams", ",", "results_i", ",", "task_ids", ",", "num_steps", ",", "metrics", ",", "save_results_to", ")", "\n", "\n", "", "best_config", ",", "expected_best_step_num", ",", "best_metric", "=", "compute_best_configuration", "(", "results", ",", "metric_should_increase", ")", "\n", "\n", "return", "best_config", ",", "expected_best_step_num", ",", "best_metric", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.lr_droprate_aug_rate_batch_size_gp_search": [[252, 282], ["hyperparam_search.gp_update_hyperparameter_optimization", "float", "float", "float", "float", "float", "float", "int", "int", "float", "int"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.gp_update_hyperparameter_optimization"], ["", "def", "lr_droprate_aug_rate_batch_size_gp_search", "(", "eval_fn", ":", "Callable", ",", "params", ":", "Dict", ",", "lr_name", ":", "str", "=", "LEARNING_RATE_NAME", ",", "lr_search_range_low", ":", "float", "=", "0.0005", ",", "lr_search_range_high", ":", "float", "=", "0.05", ",", "\n", "droprate_name", ":", "str", "=", "DROPOUT_RATE_NAME", ",", "drop_rate_search_range_low", ":", "float", "=", "0.2", ",", "drop_rate_search_range_high", ":", "float", "=", "0.2", ",", "\n", "aug_rate_name", ":", "str", "=", "AUG_RATE_NAME", ",", "aug_rate_search_range_low", ":", "float", "=", "0.5", ",", "aug_rate_search_range_high", ":", "float", "=", "0.5", ",", "\n", "batch_size_name", ":", "str", "=", "BATCH_SIZE_NAME", ",", "batch_size_search_range_low", ":", "int", "=", "8", ",", "batch_size_search_range_high", ":", "int", "=", "8", ",", "\n", "n", ":", "int", "=", "100", ",", "\n", "save_results_to", ":", "str", "=", "\"hyper_param_search_results.csv\"", ",", "m", ":", "int", "=", "1", ",", "\n", "metric_should_increase", ":", "bool", "=", "True", ",", "metric_name", ":", "str", "=", "\"mIoU\"", ")", "->", "Tuple", "[", "float", ",", "int", "]", ":", "\n", "    ", "\"\"\"\n    Performs search over learning rates by randomly sampling within range and successively reducing the range based on\n    top x percent of results. Returns the best learning rate and expected number of iterations.\n    \"\"\"", "\n", "lr_range", "=", "[", "float", "(", "lr_search_range_low", ")", ",", "float", "(", "lr_search_range_high", ")", "]", "\n", "if", "lr_range", "[", "0", "]", ">", "lr_range", "[", "1", "]", ":", "\n", "        ", "lr_range", "[", "0", "]", ",", "lr_range", "[", "1", "]", "=", "lr_range", "[", "1", "]", ",", "lr_range", "[", "0", "]", "\n", "", "drop_range", "=", "[", "float", "(", "drop_rate_search_range_low", ")", ",", "float", "(", "drop_rate_search_range_high", ")", "]", "\n", "if", "drop_range", "[", "0", "]", ">", "drop_range", "[", "1", "]", ":", "\n", "        ", "drop_range", "[", "0", "]", ",", "drop_range", "[", "1", "]", "=", "drop_range", "[", "1", "]", ",", "drop_range", "[", "0", "]", "\n", "", "aug_range", "=", "[", "float", "(", "aug_rate_search_range_low", ")", ",", "float", "(", "aug_rate_search_range_high", ")", "]", "\n", "if", "aug_range", "[", "0", "]", ">", "aug_range", "[", "1", "]", ":", "\n", "        ", "aug_range", "[", "0", "]", ",", "aug_range", "[", "1", "]", "=", "aug_range", "[", "1", "]", ",", "aug_range", "[", "0", "]", "\n", "", "batch_range", "=", "[", "int", "(", "batch_size_search_range_low", ")", ",", "int", "(", "batch_size_search_range_high", ")", "]", "\n", "if", "batch_range", "[", "0", "]", ">", "batch_range", "[", "1", "]", ":", "\n", "        ", "batch_range", "[", "0", "]", ",", "batch_range", "[", "1", "]", "=", "batch_range", "[", "1", "]", ",", "batch_range", "[", "0", "]", "\n", "\n", "", "search_key_ranges", "=", "{", "lr_name", ":", "lr_range", ",", "droprate_name", ":", "drop_range", ",", "aug_rate_name", ":", "aug_range", ",", "batch_size_name", ":", "batch_range", "}", "\n", "\n", "best_config", ",", "expected_best_step_num", ",", "_", ",", "_", "=", "gp_update_hyperparameter_optimization", "(", "eval_fn", "=", "eval_fn", ",", "hyperparams", "=", "params", ",", "search_key_ranges", "=", "search_key_ranges", ",", "n", "=", "n", ",", "\n", "save_results_to", "=", "save_results_to", ",", "m", "=", "m", ",", "metric_should_increase", "=", "metric_should_increase", ",", "metric_name", "=", "metric_name", ")", "\n", "\n", "return", "float", "(", "best_config", "[", "lr_name", "]", ")", ",", "int", "(", "expected_best_step_num", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.argument_parser": [[16, 119], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "models.lr_schedulers.supported_learning_rate_schedulers.keys"], "function", ["None"], ["def", "argument_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Get an argument parser for a training script.\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "'--fine-tune-task'", ",", "help", "=", "'Fine-tune meta-learned init on specified task.'", ",", "type", "=", "str", ",", "\n", "required", "=", "False", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--fine-tuned-checkpoint'", ",", "help", "=", "'Directory to save fine-tuned checkpoint to'", ",", "type", "=", "str", ",", "\n", "required", "=", "False", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained'", ",", "help", "=", "'Continue training or evaluate a pre-trained model.'", ",", "\n", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "help", "=", "'random seed'", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "help", "=", "'checkpoint directory'", ",", "default", "=", "'model_checkpoint'", ")", "\n", "parser", ".", "add_argument", "(", "'--classes'", ",", "help", "=", "'number of classes per inner task'", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--shots'", ",", "help", "=", "'number of examples per class at meta-test time'", ",", "default", "=", "5", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--train-shots'", ",", "help", "=", "'shots in a training batch'", ",", "default", "=", "5", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--inner-batch'", ",", "help", "=", "'inner batch size'", ",", "default", "=", "8", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--inner-iters'", ",", "help", "=", "'inner iterations'", ",", "default", "=", "8", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--replacement'", ",", "help", "=", "'sample with replacement'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning-rate'", ",", "help", "=", "'Adam step size'", ",", "default", "=", "1e-3", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--meta-step'", ",", "help", "=", "'meta-training step size'", ",", "default", "=", "0.1", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--meta-step-final'", ",", "help", "=", "'meta-training step size by the end'", ",", "\n", "default", "=", "0.1", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--meta-batch'", ",", "help", "=", "'meta-training batch size'", ",", "default", "=", "5", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--meta-iters'", ",", "help", "=", "'meta-training iterations'", ",", "default", "=", "400000", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-batch'", ",", "help", "=", "'eval inner batch size'", ",", "default", "=", "8", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-iters'", ",", "help", "=", "'eval inner iterations'", ",", "default", "=", "4", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-samples'", ",", "help", "=", "'evaluation samples'", ",", "default", "=", "200", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-interval'", ",", "help", "=", "'train steps per eval'", ",", "default", "=", "10", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "help", "=", "'weight decay rate'", ",", "default", "=", "1", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--transductive'", ",", "help", "=", "'evaluate all samples at once'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--foml'", ",", "help", "=", "'use FOML instead of Reptile'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--foml-tail'", ",", "help", "=", "'number of shots for the final mini-batch in FOML'", ",", "\n", "default", "=", "None", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--sgd'", ",", "help", "=", "'use vanilla SGD instead of Adam'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_unet_encoding_stacks'", ",", "help", "=", "'Number of U-net encoding stacks.'", ",", "required", "=", "False", ",", "type", "=", "int", ",", "\n", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "'--data-dir'", ",", "help", "=", "'Path to directory housing meta-learning data.'", ")", "\n", "parser", ".", "add_argument", "(", "'--loss_name'", ",", "help", "=", "'Name of the loss function to use. Should be cross_entropy, soft_iou, or bce_dice'", ",", "default", "=", "'cross_entropy'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_fine_tuned_checkpoints'", ",", "help", "=", "\"If speced, save fine-tuned weights for test-set tasks.\"", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_fine_tuned_checkpoints_train'", ",", "help", "=", "\"If speced, save fine-tuned weights for train-set tasks.\"", ",", "\n", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_fine_tuned_checkpoints_dir'", ",", "help", "=", "\"Directory in which to save fine-tuned weights during evaluation.\"", ",", "required", "=", "False", ",", "default", "=", "'/tmp/checkpoints/fine-tuned'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_name'", ",", "\n", "help", "=", "\"Name of the model architecture to meta-train. Must be in the set: {}.\"", ".", "format", "(", "SUPPORTED_MODELS", ")", ",", "required", "=", "False", ",", "\n", "default", "=", "'efficientlab'", ")", "\n", "parser", ".", "add_argument", "(", "\"--start_num_feature_maps_power\"", ",", "help", "=", "\"2 ** start_num_feature_maps_power will be the number of channels in the first layer\"", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "parser", ".", "add_argument", "(", "\"--restore_efficient_net_weights_from\"", ",", "help", "=", "\"path to dir to restore efficientnet weights from\"", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--spatial_pyramid_pooling\"", ",", "help", "=", "\"Use AutoDeepLab style spatial pyramid pooling layers. On default, applies mobilenetV2 spp, which is just 1x1 concatenated with image-level feature.\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--skip_decoding\"", ",", "\n", "help", "=", "\"Use DeepLab v3+ style long skip connection and seperable convs in the decoder layer.\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--rsd\"", ",", "help", "=", "\"List of integers specifying the 1-indexed reduction endpionts from EfficientNet to input into the lightweight skip decoding layers of EfficientLab.\"", ",", "type", "=", "int", ",", "nargs", "=", "\"+\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--feature_extractor_name\"", ",", "help", "=", "\"efficientnet-b0 or efficientnet-b3\"", ",", "type", "=", "str", ",", "default", "=", "\"efficientnet-b0\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate_scheduler\"", ",", "help", "=", "\"Inner loop learning rate scheduler. Should be one of {}\"", ".", "format", "(", "supported_learning_rate_schedulers", ".", "keys", "(", ")", ")", ",", "type", "=", "str", ",", "action", "=", "\"store\"", ",", "required", "=", "False", ",", "default", "=", "\"fixed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--step_decay_rate\"", ",", "type", "=", "float", ",", "required", "=", "False", ",", "default", "=", "0.5", ")", "\n", "parser", ".", "add_argument", "(", "\"--decay_after_n_steps\"", ",", "type", "=", "int", ",", "required", "=", "False", ",", "default", "=", "5", ")", "\n", "parser", ".", "add_argument", "(", "\"--l2\"", ",", "help", "=", "\"Applies l2 weight decay to all weights in network\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--l1\"", ",", "help", "=", "\"Applies l1 weight decay to all weights in network\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--darc1\"", ",", "help", "=", "\"Applies darc1 regularizer to final activations of network\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--augment\"", ",", "help", "=", "\"Apply augmentations to training data\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--final_layer_dropout_rate\"", ",", "help", "=", "\"Probability to dropout inputs at final layer.\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "\"--image_size\"", ",", "help", "=", "\"size of image in pixels. images assumed to square\"", ",", "type", "=", "int", ",", "default", "=", "320", ")", "\n", "parser", ".", "add_argument", "(", "\"--label_smoothing\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--continue_training_from_checkpoint\"", ",", "help", "=", "\"Continue training from this checkpoint\"", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--fss_1000\"", ",", "help", "=", "\"Train and val with the FSS-1000 dataset.\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_val_tasks\"", ",", "help", "=", "\"Number of validation tasks to held out in addition to the 240 test tasks.\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_val_tasks\"", ",", "\n", "help", "=", "\"If speced, will run final validation procedures on val-set as opposed to test set.\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--serially_eval_all_test_tasks\"", ",", "help", "=", "\"Evaluate all tasks in test set in serial. \"", "\n", "\"Set serially_eval_all_tasks to True when running large experiments and set --eval-samples to a small int. \"", "\n", "\"Code will evaluate `eval_samples * num_test_tasks` models at the end of meta-training\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--optimize_update_hyperparms_on_val_set\"", ",", "help", "=", "\"Search over update procedure hyperparams on the val set.\"", "\n", "\"tasks, returning the best learning rate and expected best number of adaptation iterations.\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_configs_to_sample\"", ",", "help", "=", "\"Number of configurations to randomly sample and evaluate if optimizing update hyperparams\"", ",", "default", "=", "100", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--meta_fine_tune_steps_on_train_val\"", ",", "help", "=", "\"Run meta-fine tuning on train-val after optimizing hyperparams on val set.\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--uho_outer_iters\"", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr_search_range_low\"", ",", "default", "=", "0.0005", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr_search_range_high\"", ",", "default", "=", "0.05", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--drop_rate_search_range_low\"", ",", "default", "=", "0.2", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--drop_rate_search_range_high\"", ",", "default", "=", "0.2", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--aug_rate_search_range_low\"", ",", "default", "=", "0.5", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--aug_rate_search_range_high\"", ",", "default", "=", "0.5", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size_search_range_low\"", ",", "default", "=", "8", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size_search_range_high\"", ",", "default", "=", "8", ",", "type", "=", "int", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--run_k_shot_learning_curves_experiment\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"If speced, will run the k-shot learning experiments, \"", "\n", "\"evaluating a model across a range of k-shot examples.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--fp_k_test_set\"", ",", "help", "=", "\"Hold out the test task for the fp-k classes.\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--disable_rsd_residual_connections\"", ",", "help", "=", "\"Do not use residual connections in rsd modules.\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_not_restore_final_layer_weights\"", ",", "help", "=", "\"When restoring model from checkpoint, do not restore the final layer weights.\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_tasks_with_median_early_stopping_iterations\"", ",", "help", "=", "\"If this and hyperparam search provided, will eval all tasks with the median number of early stopping iters.\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_steps\"", ",", "help", "=", "\"min inner iters to train for UHO.\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "help", "=", "\"max inner iters to train for UHO.\"", ",", "type", "=", "int", ",", "default", "=", "80", ")", "\n", "parser", ".", "add_argument", "(", "\"--k_shot_iter_range\"", ",", "help", "=", "\"List of iterations to evaluate each k-shot at if running k-shot learning curves experiment\"", ",", "nargs", "=", "'+'", ",", "type", "=", "int", ",", "required", "=", "False", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--sample_foml_train_val_with_replacement\"", ",", "help", "=", "\"If true, will sample train set and val set of tail shots with replacement\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--aug_rate\"", ",", "help", "=", "\"Probability to augment image mask pair\"", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "parser", ".", "add_argument", "(", "\"--uho_results_csv_name\"", ",", "help", "=", "\"Path to write hyperparam search results to.\"", ",", "type", "=", "str", ",", "default", "=", "\"val-set_hyper_param_search_results.csv\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--uho_estimator\"", ",", "default", "=", "\"GP\"", ",", "type", "=", "str", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.model_kwargs": [[121, 161], ["parsed_args.model_name.lower", "ValueError", "functools.partial"], "function", ["None"], ["", "def", "model_kwargs", "(", "parsed_args", ")", ":", "\n", "    ", "\"\"\"\n    Build the kwargs for model constructors from the\n    parsed command-line arguments.\n    \"\"\"", "\n", "parsed_args", ".", "model_name", "=", "parsed_args", ".", "model_name", ".", "lower", "(", ")", "\n", "if", "parsed_args", ".", "model_name", "not", "in", "SUPPORTED_MODELS", ":", "\n", "        ", "raise", "ValueError", "(", "\"Model name must be in the set: {} but is {}\"", ".", "format", "(", "SUPPORTED_MODELS", ",", "parsed_args", ".", "model_name", ")", ")", "\n", "", "res", "=", "{", "'learning_rate'", ":", "parsed_args", ".", "learning_rate", "}", "\n", "if", "parsed_args", ".", "model_name", "==", "\"efficientlab\"", ":", "\n", "        ", "restore_ckpt_dir", "=", "parsed_args", ".", "restore_efficient_net_weights_from", "\n", "res", "[", "\"restore_ckpt_dir\"", "]", "=", "restore_ckpt_dir", "\n", "if", "parsed_args", ".", "spatial_pyramid_pooling", ":", "\n", "            ", "res", "[", "\"spatial_pyramid_pooling\"", "]", "=", "True", "\n", "", "if", "parsed_args", ".", "skip_decoding", ":", "\n", "            ", "res", "[", "\"skip_decoding\"", "]", "=", "True", "\n", "", "if", "parsed_args", ".", "rsd", ":", "\n", "            ", "res", "[", "\"rsd\"", "]", "=", "parsed_args", ".", "rsd", "\n", "", "else", ":", "\n", "            ", "res", "[", "\"rsd\"", "]", "=", "None", "\n", "", "res", "[", "\"feature_extractor_name\"", "]", "=", "parsed_args", ".", "feature_extractor_name", "\n", "res", "[", "\"l2\"", "]", "=", "parsed_args", ".", "l2", "\n", "res", "[", "\"l1\"", "]", "=", "parsed_args", ".", "l1", "\n", "res", "[", "\"darc1\"", "]", "=", "parsed_args", ".", "darc1", "\n", "res", "[", "\"final_layer_dropout_rate\"", "]", "=", "parsed_args", ".", "final_layer_dropout_rate", "\n", "res", "[", "\"label_smoothing\"", "]", "=", "parsed_args", ".", "label_smoothing", "\n", "if", "\"dice\"", "not", "in", "parsed_args", ".", "loss_name", ":", "\n", "            ", "res", "[", "\"dice\"", "]", "=", "False", "\n", "", "if", "parsed_args", ".", "disable_rsd_residual_connections", ":", "\n", "            ", "res", "[", "\"disable_rsd_residual_connections\"", "]", "=", "True", "\n", "", "", "if", "parsed_args", ".", "sgd", ":", "\n", "        ", "res", "[", "'optimizer'", "]", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "\n", "", "else", ":", "\n", "        ", "res", "[", "'optimizer'", "]", "=", "partial", "(", "tf", ".", "train", ".", "AdamOptimizer", ",", "beta1", "=", "0", ")", "\n", "", "res", "[", "'loss_name'", "]", "=", "parsed_args", ".", "loss_name", "\n", "res", "[", "'n_unet_encoding_stacks'", "]", "=", "parsed_args", ".", "n_unet_encoding_stacks", "\n", "res", "[", "'start_num_feature_maps_power'", "]", "=", "parsed_args", ".", "start_num_feature_maps_power", "\n", "res", "[", "\"n_rows\"", "]", "=", "parsed_args", ".", "image_size", "\n", "res", "[", "\"n_cols\"", "]", "=", "parsed_args", ".", "image_size", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.hyper_search_kwargs": [[163, 177], ["None"], "function", ["None"], ["", "def", "hyper_search_kwargs", "(", "pa", ")", ":", "\n", "    ", "assert", "pa", ".", "uho_estimator", "in", "SUPPORTED_SEARCH_ALGS", ",", "\"{} not in supported hyperparam search algs {}\"", ".", "format", "(", "pa", ".", "uho_estimator", ",", "SUPPORTED_SEARCH_ALGS", ")", "\n", "res", "=", "{", "\n", "\"lr_search_range_low\"", ":", "pa", ".", "lr_search_range_low", ",", "\n", "\"lr_search_range_high\"", ":", "pa", ".", "lr_search_range_high", ",", "\n", "\"drop_rate_search_range_low\"", ":", "pa", ".", "drop_rate_search_range_low", ",", "\n", "\"drop_rate_search_range_high\"", ":", "pa", ".", "drop_rate_search_range_high", ",", "\n", "\"aug_rate_search_range_low\"", ":", "pa", ".", "aug_rate_search_range_low", ",", "\n", "\"aug_rate_search_range_high\"", ":", "pa", ".", "aug_rate_search_range_high", ",", "\n", "\"batch_size_search_range_low\"", ":", "pa", ".", "batch_size_search_range_low", ",", "\n", "\"batch_size_search_range_high\"", ":", "pa", ".", "batch_size_search_range_high", ",", "\n", "\"estimator\"", ":", "pa", ".", "uho_estimator", "\n", "}", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.optim_kwargs": [[178, 184], ["None"], "function", ["None"], ["", "def", "optim_kwargs", "(", "parsed_args", ")", ":", "\n", "    ", "res", "=", "{", "\n", "\"learning_rate\"", ":", "parsed_args", ".", "learning_rate", ",", "\n", "\"label_smoothing\"", ":", "parsed_args", ".", "label_smoothing", "\n", "}", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.train_kwargs": [[187, 212], ["ValueError", "args._args_meta_fn", "models.lr_schedulers.supported_learning_rate_schedulers.keys"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args._args_meta_fn"], ["", "def", "train_kwargs", "(", "parsed_args", ")", ":", "\n", "    ", "\"\"\"\n    Build kwargs for the train() function from the parsed\n    command-line arguments.\n    \"\"\"", "\n", "if", "parsed_args", ".", "learning_rate_scheduler", "not", "in", "supported_learning_rate_schedulers", ":", "\n", "        ", "raise", "ValueError", "(", "\"Learning rate scheduler, {}, not in supported set: {}\"", ".", "format", "(", "parsed_args", ".", "learning_rate_scheduler", ",", "supported_learning_rate_schedulers", ".", "keys", "(", ")", ")", ")", "\n", "", "return", "{", "\n", "'num_classes'", ":", "parsed_args", ".", "classes", ",", "\n", "'num_shots'", ":", "parsed_args", ".", "shots", ",", "\n", "'train_shots'", ":", "(", "parsed_args", ".", "train_shots", "or", "None", ")", ",", "\n", "'inner_batch_size'", ":", "parsed_args", ".", "inner_batch", ",", "\n", "'inner_iters'", ":", "parsed_args", ".", "inner_iters", ",", "\n", "'replacement'", ":", "parsed_args", ".", "replacement", ",", "\n", "'meta_step_size'", ":", "parsed_args", ".", "meta_step", ",", "\n", "'meta_step_size_final'", ":", "parsed_args", ".", "meta_step_final", ",", "\n", "'meta_batch_size'", ":", "parsed_args", ".", "meta_batch", ",", "\n", "'meta_iters'", ":", "parsed_args", ".", "meta_iters", ",", "\n", "'eval_inner_batch_size'", ":", "parsed_args", ".", "eval_batch", ",", "\n", "'eval_inner_iters'", ":", "parsed_args", ".", "eval_iters", ",", "\n", "'eval_interval'", ":", "parsed_args", ".", "eval_interval", ",", "\n", "'weight_decay_rate'", ":", "parsed_args", ".", "weight_decay", ",", "\n", "'transductive'", ":", "parsed_args", ".", "transductive", ",", "\n", "'meta_fn'", ":", "_args_meta_fn", "(", "parsed_args", ")", ",", "\n", "\"aug_rate\"", ":", "parsed_args", ".", "aug_rate", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.evaluate_kwargs": [[215, 236], ["args._args_meta_fn"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args._args_meta_fn"], ["", "def", "evaluate_kwargs", "(", "parsed_args", ")", ":", "\n", "    ", "\"\"\"\n    Build kwargs for the evaluate() function from the\n    parsed command-line arguments.\n    \"\"\"", "\n", "return", "{", "\n", "'num_classes'", ":", "parsed_args", ".", "classes", ",", "\n", "'num_shots'", ":", "parsed_args", ".", "shots", ",", "\n", "'eval_inner_batch_size'", ":", "parsed_args", ".", "eval_batch", ",", "\n", "'eval_inner_iters'", ":", "parsed_args", ".", "eval_iters", ",", "\n", "'replacement'", ":", "parsed_args", ".", "replacement", ",", "\n", "'weight_decay_rate'", ":", "parsed_args", ".", "weight_decay", ",", "\n", "'num_samples'", ":", "parsed_args", ".", "eval_samples", ",", "\n", "'transductive'", ":", "parsed_args", ".", "transductive", ",", "\n", "'save_fine_tuned_checkpoints'", ":", "parsed_args", ".", "save_fine_tuned_checkpoints", ",", "\n", "'save_fine_tuned_checkpoints_dir'", ":", "parsed_args", ".", "save_fine_tuned_checkpoints_dir", ",", "\n", "'meta_fn'", ":", "_args_meta_fn", "(", "parsed_args", ")", ",", "\n", "\"augment\"", ":", "parsed_args", ".", "augment", ",", "\n", "'lr'", ":", "None", ",", "# Defined in model kwargs or estimated after meta-training.", "\n", "\"eval_tasks_with_median_early_stopping_iterations\"", ":", "parsed_args", ".", "eval_tasks_with_median_early_stopping_iterations", ",", "\n", "\"aug_rate\"", ":", "parsed_args", ".", "aug_rate", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.train_gecko_kwargs": [[240, 262], ["args._args_gecko"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args._args_gecko"], ["", "def", "train_gecko_kwargs", "(", "parsed_args", ")", ":", "\n", "    ", "\"\"\"\n    Build kwargs for the train() function from the parsed\n    command-line arguments.\n    \"\"\"", "\n", "return", "{", "\n", "'num_classes'", ":", "parsed_args", ".", "classes", ",", "\n", "'num_shots'", ":", "parsed_args", ".", "shots", ",", "\n", "'train_shots'", ":", "(", "parsed_args", ".", "train_shots", "or", "None", ")", ",", "\n", "'inner_batch_size'", ":", "parsed_args", ".", "inner_batch", ",", "\n", "'inner_iters'", ":", "parsed_args", ".", "inner_iters", ",", "\n", "'replacement'", ":", "parsed_args", ".", "replacement", ",", "\n", "'meta_step_size'", ":", "parsed_args", ".", "meta_step", ",", "\n", "'meta_step_size_final'", ":", "parsed_args", ".", "meta_step_final", ",", "\n", "'meta_batch_size'", ":", "parsed_args", ".", "meta_batch", ",", "\n", "'meta_iters'", ":", "parsed_args", ".", "meta_iters", ",", "\n", "'eval_inner_batch_size'", ":", "parsed_args", ".", "eval_batch", ",", "\n", "'eval_inner_iters'", ":", "parsed_args", ".", "eval_iters", ",", "\n", "'eval_interval'", ":", "parsed_args", ".", "eval_interval", ",", "\n", "'weight_decay_rate'", ":", "parsed_args", ".", "weight_decay", ",", "\n", "'transductive'", ":", "parsed_args", ".", "transductive", ",", "\n", "'reptile_fn'", ":", "_args_gecko", "(", "parsed_args", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.evaluate_gecko_kwargs": [[265, 282], ["args._args_gecko"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args._args_gecko"], ["", "def", "evaluate_gecko_kwargs", "(", "parsed_args", ")", ":", "\n", "    ", "\"\"\"\n    Build kwargs for the evaluate() function from the\n    parsed command-line arguments.\n    \"\"\"", "\n", "return", "{", "\n", "'num_classes'", ":", "parsed_args", ".", "classes", ",", "\n", "'num_shots'", ":", "parsed_args", ".", "shots", ",", "\n", "'eval_inner_batch_size'", ":", "parsed_args", ".", "eval_batch", ",", "\n", "'eval_inner_iters'", ":", "parsed_args", ".", "eval_iters", ",", "\n", "'replacement'", ":", "parsed_args", ".", "replacement", ",", "\n", "'weight_decay_rate'", ":", "parsed_args", ".", "weight_decay", ",", "\n", "'num_samples'", ":", "parsed_args", ".", "eval_samples", ",", "\n", "'transductive'", ":", "parsed_args", ".", "transductive", ",", "\n", "'save_fine_tuned_checkpoints'", ":", "parsed_args", ".", "save_fine_tuned_checkpoints", ",", "\n", "'save_fine_tuned_checkpoints_dir'", ":", "parsed_args", ".", "save_fine_tuned_checkpoints_dir", ",", "\n", "'reptile_fn'", ":", "_args_gecko", "(", "parsed_args", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args._args_meta_fn": [[285, 289], ["functools.partial"], "function", ["None"], ["", "def", "_args_meta_fn", "(", "parsed_args", ")", ":", "\n", "    ", "if", "parsed_args", ".", "foml", ":", "\n", "        ", "return", "partial", "(", "FOMLIS", ",", "train_shots", "=", "parsed_args", ".", "train_shots", ",", "tail_shots", "=", "parsed_args", ".", "foml_tail", ",", "sample_train_val_with_replacement", "=", "parsed_args", ".", "sample_foml_train_val_with_replacement", ")", "\n", "", "return", "Gecko", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args._args_gecko": [[291, 295], ["functools.partial"], "function", ["None"], ["", "def", "_args_gecko", "(", "parsed_args", ")", ":", "\n", "    ", "if", "parsed_args", ".", "foml", ":", "\n", "        ", "return", "partial", "(", "FOMLIS", ",", "train_shots", "=", "parsed_args", ".", "train_shots", ",", "tail_shots", "=", "parsed_args", ".", "foml_tail", ",", "sample_train_val_with_replacement", "=", "parsed_args", ".", "sample_foml_train_val_with_replacement", ")", "\n", "", "return", "Gecko", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.args.str_to_bool": [[297, 304], ["v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["", "def", "str_to_bool", "(", "v", ")", ":", "\n", "    ", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg.BinarySegmentationTask.__init__": [[186, 213], ["metaseg.BinarySegmentationTask.iterator.make_initializer", "metaseg.BinarySegmentationTask.iterator.get_next", "data.input_fn.make_dataset", "data.input_fn.make_dataset", "print", "tensorflow.data.Iterator.from_structure", "print"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.input_fn.make_dataset", "home.repos.pwc.inspect_result.ml4ai_mliis.data.input_fn.make_dataset"], ["def", "__init__", "(", "self", ",", "\n", "tfrecord_paths", ",", "\n", "iterator", "=", "None", ",", "\n", "batch_size", "=", "32", ",", "\n", "seed", "=", "None", ",", "\n", "name", ":", "str", "=", "None", ",", "\n", "image_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "verbose", ":", "bool", "=", "False", ")", ":", "\n", "        ", "self", ".", "tfrecord_paths", "=", "tfrecord_paths", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n", "\n", "if", "image_size", "is", "not", "None", ":", "\n", "            ", "dataset", "=", "input_fn", ".", "make_dataset", "(", "self", ".", "tfrecord_paths", ",", "self", ".", "batch_size", ",", "image_width", "=", "image_size", ")", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "input_fn", ".", "make_dataset", "(", "self", ".", "tfrecord_paths", ",", "self", ".", "batch_size", ")", "\n", "", "if", "not", "iterator", ":", "\n", "            ", "print", "(", "\"making new iterator in BinarySegmentationTask.__init__ for task: {}\"", ".", "format", "(", "name", ")", ")", "\n", "iterator", "=", "tf", ".", "data", ".", "Iterator", ".", "from_structure", "(", "dataset", ".", "output_types", ",", "\n", "dataset", ".", "output_shapes", ")", "\n", "", "self", ".", "iterator", "=", "iterator", "\n", "self", ".", "_initialization_op", "=", "self", ".", "iterator", ".", "make_initializer", "(", "dataset", ")", "\n", "self", ".", "_next_element", "=", "self", ".", "iterator", ".", "get_next", "(", ")", "\n", "\n", "self", ".", "name", "=", "name", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"BinarySegmentationTask for data {} will return batches of size {}\"", ".", "format", "(", "self", ".", "name", ",", "self", ".", "batch_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg.BinarySegmentationTask.sample": [[214, 231], ["sess.run", "sess.run", "ValueError", "zip"], "methods", ["None"], ["", "", "def", "sample", "(", "self", ",", "sess", ",", "num_images", ",", "verbose", "=", "False", ")", "->", "List", "[", "List", "[", "np", ".", "array", "]", "]", ":", "\n", "        ", "\"\"\"\n        Sample tuple of (image, label) from tfrecords\n        Args:\n            sess: tf session\n        Returns:\n            A sequence of (image, label) pairs\n        \"\"\"", "\n", "if", "num_images", ">", "self", ".", "batch_size", ":", "\n", "            ", "raise", "ValueError", "(", "\"Tried to sample {} examples.Cannot sample more than {} examples that generator was initialized with.\"", ".", "format", "(", "num_images", ",", "self", ".", "batch_size", ")", ")", "\n", "\n", "# Reinitialize iterator with this task's dataset, then fetch one batch.", "\n", "", "sess", ".", "run", "(", "self", ".", "_initialization_op", ")", "\n", "# Fetch a batch of size self.batch_size of images and corresponding masks:", "\n", "images", ",", "masks", "=", "sess", ".", "run", "(", "self", ".", "_next_element", ")", "\n", "\n", "return", "[", "[", "image", ",", "mask", "]", "for", "image", ",", "mask", "in", "zip", "(", "images", "[", ":", "num_images", "]", ",", "masks", "[", ":", "num_images", "]", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg.read_fss_1000_dataset": [[24, 122], ["data.fss_1000_utils.get_fss_tasks", "data.fss_1000_utils.split_train_test_tasks", "print", "print", "print", "print", "data.fss_1000_utils.split_train_test_tasks", "all", "all", "os.path.basename", "train_task_names.append", "utils.util.count_examples_in_tfrecords", "metaseg.BinarySegmentationTask", "train_tasks.append", "os.path.basename", "val_task_names.append", "utils.util.count_examples_in_tfrecords", "metaseg.BinarySegmentationTask", "val_tasks.append", "os.path.basename", "test_task_names.append", "utils.util.count_examples_in_tfrecords", "metaseg.BinarySegmentationTask", "test_tasks.append", "os.path.basename().replace", "len", "len", "len", "print", "print", "print", "print", "print", "print", "test_shards.append", "train_shards.append", "os.path.basename", "os.path.basename().replace", "os.path.basename().replace", "os.path.basename", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_utils.get_fss_tasks", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_utils.split_train_test_tasks", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_utils.split_train_test_tasks", "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.count_examples_in_tfrecords", "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.count_examples_in_tfrecords", "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.count_examples_in_tfrecords"], ["def", "read_fss_1000_dataset", "(", "data_dir", ":", "str", ",", "\n", "num_val_tasks", ":", "int", "=", "0", ",", "\n", "num_test_tasks", ":", "int", "=", "240", ",", "\n", "test_task_ids", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "TEST_TASK_IDS", ",", "\n", "image_size", ":", "Optional", "[", "int", "]", "=", "224", "\n", ")", "->", "Tuple", "[", "List", "[", "\"BinarySegmentationTask\"", "]", ",", "List", "[", "\"BinarySegmentationTask\"", "]", ",", "List", "[", "\"BinarySegmentationTask\"", "]", ",", "\n", "List", "[", "str", "]", ",", "List", "[", "str", "]", ",", "List", "[", "str", "]", "]", ":", "\n", "    ", "\"\"\"\n    Reads in the FSS-1000 meta-learning image segmentation dataset. Assumes each task is in a shard.\n    Args:\n        data_dir: a directory containing tfrecords files for each semantic class.\n\n    Returns:\n        Tuple of (train_tasks, val_tasks, test_tasks, train_task_names, val_task_names, test_task_names).\n        First three objects are instances of BinarySegmentationTask.\n    \"\"\"", "\n", "verbose", "=", "False", "\n", "\n", "all_tasks", "=", "get_fss_tasks", "(", "data_dir", ")", "\n", "\n", "if", "test_task_ids", "is", "None", ":", "\n", "        ", "train_shards", ",", "test_shards", "=", "split_train_test_tasks", "(", "all_tasks", ",", "num_test_tasks", ")", "\n", "", "else", ":", "\n", "        ", "train_shards", ",", "test_shards", "=", "[", "]", ",", "[", "]", "\n", "for", "task", "in", "all_tasks", ":", "\n", "            ", "comparer", "=", "os", ".", "path", ".", "basename", "(", "task", ")", ".", "replace", "(", "\".tfrecord.gzip\"", ",", "\"\"", ")", "\n", "if", "comparer", "in", "test_task_ids", ":", "\n", "                ", "test_shards", ".", "append", "(", "task", ")", "\n", "", "else", ":", "\n", "                ", "train_shards", ".", "append", "(", "task", ")", "\n", "", "", "assert", "all", "(", "[", "os", ".", "path", ".", "basename", "(", "x", ")", ".", "replace", "(", "\".tfrecord.gzip\"", ",", "\"\"", ")", "in", "test_task_ids", "for", "x", "in", "test_shards", "]", ")", ",", "\"Test shard not in test_task_ids\"", "\n", "assert", "all", "(", "[", "not", "os", ".", "path", ".", "basename", "(", "x", ")", ".", "replace", "(", "\".tfrecord.gzip\"", ",", "\"\"", ")", "in", "test_task_ids", "for", "x", "in", "train_shards", "]", ")", ",", "\"Test set task found in train shards\"", "\n", "\n", "", "train_shards", ",", "val_shards", "=", "split_train_test_tasks", "(", "train_shards", ",", "num_val_tasks", ",", "reproducbile_splits", "=", "True", ")", "\n", "\n", "print", "(", "\"{} training tasks, {} val tasks, {} test tasks.\"", ".", "format", "(", "len", "(", "train_shards", ")", ",", "len", "(", "val_shards", ")", ",", "len", "(", "test_shards", ")", ")", ")", "\n", "\n", "train_tasks", ",", "val_tasks", ",", "test_tasks", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "iterator", "=", "None", "\n", "\n", "print", "(", "\"Building FSS-1000 training task samplers...\"", ")", "\n", "train_task_names", "=", "[", "]", "\n", "for", "task", "in", "train_shards", ":", "\n", "        ", "task_name", "=", "os", ".", "path", ".", "basename", "(", "task", ")", "\n", "train_task_names", ".", "append", "(", "task_name", ")", "\n", "batch_size", "=", "count_examples_in_tfrecords", "(", "[", "task", "]", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"{} examples in task {}\"", ".", "format", "(", "batch_size", ",", "task_name", ")", ")", "\n", "", "few_shot_seg_task", "=", "BinarySegmentationTask", "(", "\n", "iterator", "=", "iterator", ",", "\n", "tfrecord_paths", "=", "task", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "name", "=", "task_name", ",", "\n", "image_size", "=", "image_size", ",", "\n", "verbose", "=", "False", ")", "\n", "# Initialize all tasks using the same iterator.", "\n", "if", "not", "iterator", ":", "\n", "            ", "print", "(", "\"making new iterator in read_dataset for task: {}\"", ".", "format", "(", "task_name", ")", ")", "\n", "iterator", "=", "few_shot_seg_task", ".", "iterator", "\n", "", "train_tasks", ".", "append", "(", "few_shot_seg_task", ")", "\n", "\n", "", "print", "(", "\"Building FSS-1000 val task samplers...\"", ")", "\n", "val_task_names", "=", "[", "]", "\n", "for", "task", "in", "val_shards", ":", "\n", "        ", "task_name", "=", "os", ".", "path", ".", "basename", "(", "task", ")", "\n", "val_task_names", ".", "append", "(", "task_name", ")", "\n", "batch_size", "=", "count_examples_in_tfrecords", "(", "[", "task", "]", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"Meta-val task: {}\"", ".", "format", "(", "task_name", ")", ")", "\n", "print", "(", "\"{} examples in task {}\"", ".", "format", "(", "batch_size", ",", "task_name", ")", ")", "\n", "", "few_shot_seg_task", "=", "BinarySegmentationTask", "(", "\n", "iterator", "=", "iterator", ",", "\n", "tfrecord_paths", "=", "task", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "name", "=", "task_name", ",", "\n", "image_size", "=", "image_size", ",", "\n", "verbose", "=", "False", ")", "\n", "val_tasks", ".", "append", "(", "few_shot_seg_task", ")", "\n", "\n", "", "print", "(", "\"Building FSS-1000 test task samplers...\"", ")", "\n", "test_task_names", "=", "[", "]", "\n", "for", "task", "in", "test_shards", ":", "\n", "        ", "task_name", "=", "os", ".", "path", ".", "basename", "(", "task", ")", "\n", "test_task_names", ".", "append", "(", "task_name", ")", "\n", "batch_size", "=", "count_examples_in_tfrecords", "(", "[", "task", "]", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"Meta-test task: {}\"", ".", "format", "(", "task_name", ")", ")", "\n", "print", "(", "\"{} examples in task {}\"", ".", "format", "(", "batch_size", ",", "task_name", ")", ")", "\n", "", "few_shot_seg_task", "=", "BinarySegmentationTask", "(", "\n", "iterator", "=", "iterator", ",", "\n", "tfrecord_paths", "=", "task", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "name", "=", "task_name", ",", "\n", "image_size", "=", "image_size", ",", "\n", "verbose", "=", "False", ")", "\n", "test_tasks", ".", "append", "(", "few_shot_seg_task", ")", "\n", "\n", "", "return", "train_tasks", ",", "val_tasks", ",", "test_tasks", ",", "train_task_names", ",", "val_task_names", ",", "test_task_names", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg.read_fp_k_shot_dataset": [[124, 179], ["data.fss_1000_utils.get_fss_tasks", "print", "print", "enumerate", "print", "test_task_names.append", "utils.util.count_examples_in_tfrecords", "metaseg.BinarySegmentationTask", "test_tasks.append", "len", "synonym.replace.replace", "task_shards.extend", "task_globs.append", "print", "print", "print", "os.path.join", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_utils.get_fss_tasks", "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.count_examples_in_tfrecords"], ["", "def", "read_fp_k_shot_dataset", "(", "data_dir", ":", "str", ",", "\n", "all_task_names", "=", "DEFAULT_K_SHOT_SET", ",", "\n", "image_size", ":", "Optional", "[", "int", "]", "=", "224", "\n", ")", "->", "Tuple", "[", "List", "[", "\"BinarySegmentationTask\"", "]", ",", "List", "[", "str", "]", "]", ":", "\n", "    ", "\"\"\"\n    Reads in the FP-k-shot meta-learning image segmentation dataset, which contains FSS-1000 and PASCAL-5^i classes.\n    Args:\n        data_dir: a directory containing tfrecords files for each semantic class.\n        all_task_names: list of set of synonyms defining the tasks.\n    Returns:\n        BinarySegmentationTask objects for the tasks in `tasks`.\n    \"\"\"", "\n", "verbose", "=", "True", "\n", "\n", "all_tasks", "=", "get_fss_tasks", "(", "data_dir", ")", "\n", "\n", "print", "(", "\"{} tasks found.\"", ".", "format", "(", "len", "(", "all_tasks", ")", ")", ")", "\n", "\n", "test_tasks", "=", "[", "]", "\n", "iterator", "=", "None", "\n", "\n", "print", "(", "\"Building k-shot-FSS-1000 test task samplers...\"", ")", "\n", "test_task_names", "=", "[", "]", "\n", "for", "synonyms", "in", "all_task_names", ":", "\n", "        ", "task_shards", "=", "[", "]", "\n", "task_globs", "=", "[", "]", "\n", "for", "i", ",", "synonym", "in", "enumerate", "(", "synonyms", ")", ":", "\n", "            ", "synonym", "=", "synonym", ".", "replace", "(", "\" \"", ",", "\"\"", ")", "\n", "if", "i", "==", "0", ":", "\n", "                ", "task_name", "=", "synonym", "\n", "print", "(", "\"Processing task: {}\"", ".", "format", "(", "task_name", ")", ")", "\n", "", "syn_shards", "=", "[", "x", "for", "x", "in", "all_tasks", "if", "synonym", "in", "os", ".", "path", ".", "basename", "(", "x", ")", "]", "\n", "task_shards", ".", "extend", "(", "syn_shards", ")", "\n", "task_globs", ".", "append", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"{}*.tfrecord*\"", ".", "format", "(", "synonym", ")", ")", ")", "\n", "\n", "", "print", "(", "\"task shards: {}\"", ".", "format", "(", "task_shards", ")", ")", "\n", "\n", "test_task_names", ".", "append", "(", "task_name", ")", "\n", "batch_size", "=", "count_examples_in_tfrecords", "(", "task_shards", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"{} examples in task {}\"", ".", "format", "(", "batch_size", ",", "task_name", ")", ")", "\n", "", "few_shot_seg_task", "=", "BinarySegmentationTask", "(", "\n", "iterator", "=", "iterator", ",", "\n", "tfrecord_paths", "=", "task_globs", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "name", "=", "task_name", ",", "\n", "image_size", "=", "image_size", ",", "\n", "verbose", "=", "False", ")", "\n", "# Initialize all tasks using the same iterator.", "\n", "if", "not", "iterator", ":", "\n", "            ", "print", "(", "\"making new iterator in read_dataset for task: {}\"", ".", "format", "(", "task_name", ")", ")", "\n", "iterator", "=", "few_shot_seg_task", ".", "iterator", "\n", "", "test_tasks", ".", "append", "(", "few_shot_seg_task", ")", "\n", "\n", "", "return", "test_tasks", ",", "test_task_names", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg._sample_mini_image_segmentation_dataset": [[233, 256], ["list", "random.sample", "warnings.warn", "class_obj.sample", "class_obj.sample"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character.sample", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character.sample", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character.sample"], ["", "", "def", "_sample_mini_image_segmentation_dataset", "(", "sess", ",", "dataset", ",", "num_classes", ",", "num_shots", ",", "return_task_name", ":", "bool", "=", "False", ")", "->", "Union", "[", "list", ",", "Tuple", "[", "list", ",", "str", "]", "]", ":", "\n", "    ", "\"\"\"\n    Samples a binary, image segmentation task from a dataset with num_shots examples.\n    num_classes currently ignored\n\n    Returns:\n      An iterable of (input, label) tuples of length num_shots.\n    \"\"\"", "\n", "l", "=", "list", "(", "dataset", ")", "\n", "\n", "# Sample random task:", "\n", "class_obj", "=", "random", ".", "sample", "(", "l", ",", "1", ")", "[", "0", "]", "\n", "\n", "# print(\"Sampled task: {}\".format(class_obj.name))", "\n", "\n", "if", "num_shots", ">", "class_obj", ".", "batch_size", ":", "# Account for fewer examples available than num_shots", "\n", "        ", "warnings", ".", "warn", "(", "\"Requested {} examples but dataset can return max of {} examples.\"", ".", "format", "(", "num_shots", ",", "class_obj", ".", "batch_size", ")", ")", "\n", "num_shots", "=", "class_obj", ".", "batch_size", "\n", "\n", "", "if", "not", "return_task_name", ":", "\n", "        ", "return", "class_obj", ".", "sample", "(", "sess", ",", "num_shots", ")", "\n", "", "else", ":", "\n", "        ", "return", "class_obj", ".", "sample", "(", "sess", ",", "num_shots", ")", ",", "class_obj", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg._mini_batches": [[258, 303], ["list", "len", "ValueError", "range", "random.shuffle", "random.sample", "random.sample.append", "augmenter.apply_augmentations", "len", "augmenter.apply_augmentations", "_cur_batch.append"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character.sample", "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.Augmenter.apply_augmentations", "home.repos.pwc.inspect_result.ml4ai_mliis.augmenters.np_augmenters.Augmenter.apply_augmentations"], ["", "", "def", "_mini_batches", "(", "samples", ",", "batch_size", ",", "num_batches", ",", "replacement", ":", "bool", "=", "False", ",", "augmenter", ":", "Optional", "[", "Augmenter", "]", "=", "None", ",", "aug_rate", ":", "Optional", "[", "float", "]", "=", "None", ",", ")", ":", "\n", "    ", "\"\"\"\n    Generate mini-batches from some data.\n    Args:\n      replacement: bool. If False, loop through all examples before sampling an example again.\n    Returns:\n      An iterable of sequences of (input, label) pairs,\n        where each sequence is a mini-batch.\n    \"\"\"", "\n", "if", "aug_rate", "is", "not", "None", ":", "\n", "        ", "prob_to_return_original", "=", "1.0", "-", "aug_rate", "\n", "", "else", ":", "\n", "        ", "prob_to_return_original", "=", "None", "\n", "", "samples", "=", "list", "(", "samples", ")", "\n", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "'No samples to sample. `samples` has no length: {}'", ".", "format", "(", "samples", ")", ")", "\n", "", "if", "replacement", ":", "\n", "        ", "for", "_", "in", "range", "(", "num_batches", ")", ":", "\n", "            ", "cur_batch", "=", "random", ".", "sample", "(", "samples", ",", "batch_size", ")", "\n", "if", "augmenter", "is", "not", "None", ":", "\n", "                ", "_cur_batch", "=", "[", "]", "\n", "for", "sample", "in", "cur_batch", ":", "\n", "                    ", "sample", "=", "augmenter", ".", "apply_augmentations", "(", "sample", "[", "0", "]", ",", "sample", "[", "1", "]", ",", "prob_to_return_original", ")", "\n", "_cur_batch", ".", "append", "(", "sample", ")", "\n", "", "cur_batch", "=", "_cur_batch", "\n", "", "yield", "cur_batch", "\n", "", "return", "\n", "", "cur_batch", "=", "[", "]", "\n", "batch_count", "=", "0", "\n", "# i = 0", "\n", "while", "True", ":", "\n", "        ", "random", ".", "shuffle", "(", "samples", ")", "\n", "for", "sample", "in", "samples", ":", "\n", "            ", "if", "augmenter", "is", "not", "None", ":", "\n", "                ", "sample", "=", "augmenter", ".", "apply_augmentations", "(", "sample", "[", "0", "]", ",", "sample", "[", "1", "]", ",", "prob_to_return_original", ")", "\n", "# savefig_mask_on_image(sample[0], sample[1], save_path=os.path.join(\"augs\",  str(i) + \".png\"))", "\n", "# i += 1", "\n", "", "cur_batch", ".", "append", "(", "sample", ")", "\n", "if", "len", "(", "cur_batch", ")", "<", "batch_size", ":", "\n", "                ", "continue", "\n", "", "yield", "cur_batch", "\n", "cur_batch", "=", "[", "]", "\n", "batch_count", "+=", "1", "\n", "if", "batch_count", "==", "num_batches", ":", "\n", "                ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg.assert_train_test_split": [[305, 311], ["set", "set.add", "utils.util.hash_np_array", "utils.util.hash_np_array"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.hash_np_array", "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.hash_np_array"], ["", "", "", "", "def", "assert_train_test_split", "(", "train_set", ",", "test_set", ")", ":", "\n", "    ", "train_hashes", "=", "set", "(", ")", "\n", "for", "image", ",", "_", "in", "train_set", ":", "\n", "        ", "train_hashes", ".", "add", "(", "hash_np_array", "(", "image", ")", ")", "\n", "", "for", "image", ",", "_", "in", "test_set", ":", "\n", "        ", "assert", "hash_np_array", "(", "image", ")", "not", "in", "train_hashes", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg._sample_train_test_segmentation_with_replacement": [[313, 319], ["numpy.random.randint", "numpy.random.randint", "len", "len"], "function", ["None"], ["", "", "def", "_sample_train_test_segmentation_with_replacement", "(", "samples", ":", "List", ",", "train_shots", ":", "int", "=", "5", ",", "test_shots", ":", "int", "=", "5", ")", ":", "\n", "    ", "indices", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "samples", ")", ",", "size", "=", "train_shots", ")", "\n", "train_set", "=", "[", "samples", "[", "x", "]", "for", "x", "in", "indices", "]", "\n", "indices", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "samples", ")", ",", "size", "=", "test_shots", ")", "\n", "test_set", "=", "[", "samples", "[", "x", "]", "for", "x", "in", "indices", "]", "\n", "return", "train_set", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg._split_train_test_segmentation": [[321, 344], ["list", "random.shuffle", "metaseg.assert_train_test_split"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg.assert_train_test_split"], ["", "def", "_split_train_test_segmentation", "(", "samples", ",", "test_shots", "=", "1", ",", "test_train_test_split", ":", "bool", "=", "False", ",", "shuffle_before_split", ":", "bool", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Split a few-shot task into a train and a test set.\n\n    Args:\n      samples: an iterable of (input, label) pairs. Should already be shuffled.\n      test_shots: the number of examples per class in the\n        test set.\n\n    Returns:\n      A tuple (train, test), where train and test are\n        sequences of (input, label) pairs.\n    \"\"\"", "\n", "samples", "=", "list", "(", "samples", ")", "[", ":", "]", "\n", "\n", "if", "shuffle_before_split", ":", "\n", "        ", "random", ".", "shuffle", "(", "samples", ")", "\n", "\n", "", "train_set", "=", "samples", "[", ":", "-", "test_shots", "]", "\n", "test_set", "=", "samples", "[", "-", "test_shots", ":", "]", "\n", "if", "test_train_test_split", ":", "\n", "        ", "assert_train_test_split", "(", "train_set", ",", "test_set", ")", "\n", "", "return", "train_set", ",", "test_set", "\n", "", ""]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.models.OmniglotModel.__init__": [[25, 39], ["tensorflow.placeholder", "tensorflow.reshape", "range", "tensorflow.reshape", "tensorflow.layers.dense", "tensorflow.placeholder", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.argmax", "optimizer().minimize", "tensorflow.layers.conv2d", "tensorflow.layers.batch_normalization", "tensorflow.nn.relu", "int", "optimizer", "numpy.prod", "tensorflow.nn.relu.get_shape"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_classes", ",", "optimizer", "=", "DEFAULT_OPTIMIZER", ",", "**", "optim_kwargs", ")", ":", "\n", "        ", "self", ".", "input_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "28", ",", "28", ")", ")", "\n", "out", "=", "tf", ".", "reshape", "(", "self", ".", "input_ph", ",", "(", "-", "1", ",", "28", ",", "28", ",", "1", ")", ")", "\n", "for", "_", "in", "range", "(", "4", ")", ":", "\n", "            ", "out", "=", "tf", ".", "layers", ".", "conv2d", "(", "out", ",", "64", ",", "3", ",", "strides", "=", "2", ",", "padding", "=", "'same'", ")", "\n", "out", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "out", ",", "training", "=", "True", ")", "\n", "out", "=", "tf", ".", "nn", ".", "relu", "(", "out", ")", "\n", "", "out", "=", "tf", ".", "reshape", "(", "out", ",", "(", "-", "1", ",", "int", "(", "np", ".", "prod", "(", "out", ".", "get_shape", "(", ")", "[", "1", ":", "]", ")", ")", ")", ")", "\n", "self", ".", "logits", "=", "tf", ".", "layers", ".", "dense", "(", "out", ",", "num_classes", ")", "\n", "self", ".", "label_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", ")", ")", "\n", "self", ".", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "labels", "=", "self", ".", "label_ph", ",", "\n", "logits", "=", "self", ".", "logits", ")", "\n", "self", ".", "predictions", "=", "tf", ".", "argmax", "(", "self", ".", "logits", ",", "axis", "=", "-", "1", ")", "\n", "self", ".", "minimize_op", "=", "optimizer", "(", "**", "optim_kwargs", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.models.MiniImageNetModel.__init__": [[45, 60], ["tensorflow.placeholder", "range", "tensorflow.reshape", "tensorflow.layers.dense", "tensorflow.placeholder", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.argmax", "optimizer().minimize", "tensorflow.layers.conv2d", "tensorflow.layers.batch_normalization", "tensorflow.layers.max_pooling2d", "tensorflow.nn.relu", "int", "optimizer", "numpy.prod", "tensorflow.nn.relu.get_shape"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_classes", ",", "optimizer", "=", "DEFAULT_OPTIMIZER", ",", "**", "optim_kwargs", ")", ":", "\n", "        ", "self", ".", "input_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "84", ",", "84", ",", "3", ")", ")", "\n", "out", "=", "self", ".", "input_ph", "\n", "for", "_", "in", "range", "(", "4", ")", ":", "\n", "            ", "out", "=", "tf", ".", "layers", ".", "conv2d", "(", "out", ",", "32", ",", "3", ",", "padding", "=", "'same'", ")", "\n", "out", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "out", ",", "training", "=", "True", ")", "\n", "out", "=", "tf", ".", "layers", ".", "max_pooling2d", "(", "out", ",", "2", ",", "2", ",", "padding", "=", "'same'", ")", "\n", "out", "=", "tf", ".", "nn", ".", "relu", "(", "out", ")", "\n", "", "out", "=", "tf", ".", "reshape", "(", "out", ",", "(", "-", "1", ",", "int", "(", "np", ".", "prod", "(", "out", ".", "get_shape", "(", ")", "[", "1", ":", "]", ")", ")", ")", ")", "\n", "self", ".", "logits", "=", "tf", ".", "layers", ".", "dense", "(", "out", ",", "num_classes", ")", "\n", "self", ".", "label_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "shape", "=", "(", "None", ",", ")", ")", "\n", "self", ".", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "labels", "=", "self", ".", "label_ph", ",", "\n", "logits", "=", "self", ".", "logits", ")", "\n", "self", ".", "predictions", "=", "tf", ".", "argmax", "(", "self", ".", "logits", ",", "axis", "=", "-", "1", ")", "\n", "self", ".", "minimize_op", "=", "optimizer", "(", "**", "optim_kwargs", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko.__init__": [[32, 63], ["meta_learners.variables.VariableState", "meta_learners.variables.VariableState", "print", "print", "tensorflow.get_collection", "augmenters.np_augmenters.Augmenter", "print", "print", "tensorflow.trainable_variables"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "session", ",", "variables", "=", "None", ",", "transductive", "=", "False", ",", "pre_step_op", "=", "None", ",", "lr_scheduler", "=", "None", ",", "augment", ":", "bool", "=", "False", ",", "aug_rate", ":", "Optional", "[", "float", "]", "=", "None", ")", ":", "\n", "        ", "self", ".", "session", "=", "session", "\n", "self", ".", "_model_state", "=", "VariableState", "(", "self", ".", "session", ",", "variables", "or", "tf", ".", "trainable_variables", "(", ")", ")", "\n", "self", ".", "_full_state", "=", "VariableState", "(", "self", ".", "session", ",", "\n", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ")", ")", "\n", "self", ".", "_transductive", "=", "transductive", "\n", "self", ".", "_pre_step_op", "=", "pre_step_op", "\n", "\n", "self", ".", "eval_sample_number", "=", "0", "\n", "\n", "# a learning rate scheduler class with a .cur_lr method", "\n", "self", ".", "lr_scheduler", "=", "lr_scheduler", "\n", "if", "augment", ":", "\n", "            ", "self", ".", "augmenter", "=", "Augmenter", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "augmenter", "=", "None", "\n", "", "self", ".", "aug_rate", "=", "aug_rate", "\n", "print", "(", "\"Augmentation rate {}\"", ".", "format", "(", "self", ".", "aug_rate", ")", ")", "\n", "\n", "if", "self", ".", "_transductive", ":", "\n", "            ", "print", "(", "\"Using transduction in meta-learning.\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Not using transduction in meta-learning.\"", ")", "\n", "\n", "# if self._pre_step_op:", "\n", "#     print(\"Using pre meta-step op:\")", "\n", "#     print(self._pre_step_op)", "\n", "\n", "", "self", ".", "meta_fn", "=", "\"Reptile\"", "\n", "\n", "print", "(", "\"Reptile meta-learning session instantiated.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko.train_step": [[64, 126], ["reptile.Gecko._model_state.export_variables", "range", "meta_learners.variables.average_vars", "reptile.Gecko._model_state.import_variables", "meta_learners.metaseg._sample_mini_image_segmentation_dataset", "enumerate", "meta_learners.variables.average_vars.append", "reptile.Gecko._model_state.import_variables", "meta_learners.variables.interpolate_vars", "print", "meta_learners.metaseg._mini_batches", "zip", "reptile.Gecko._model_state.export_variables", "print", "reptile.Gecko.session.run", "reptile.Gecko.session.run", "reptile.Gecko.session.run", "reptile.Gecko.session.run", "reptile.Gecko.lr_scheduler.cur_lr"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.VariableState.export_variables", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.average_vars", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.VariableState.import_variables", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg._sample_mini_image_segmentation_dataset", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.VariableState.import_variables", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.interpolate_vars", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.FOMLIS._mini_batches", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.VariableState.export_variables", "home.repos.pwc.inspect_result.ml4ai_mliis.models.lr_schedulers.LRScheduler.cur_lr"], ["", "def", "train_step", "(", "self", ",", "\n", "dataset", ",", "\n", "input_ph", ",", "\n", "label_ph", ",", "\n", "minimize_op", ",", "\n", "num_classes", ",", "\n", "num_shots", ",", "\n", "inner_batch_size", ",", "\n", "inner_iters", ",", "\n", "replacement", ",", "\n", "meta_step_size", ",", "\n", "meta_batch_size", ",", "\n", "lr_ph", "=", "None", ",", "\n", "lr", "=", "None", ",", "\n", "verbose", "=", "False", ",", ")", ":", "\n", "        ", "\"\"\"\n        Perform a Reptile training step.\n\n        Args:\n          dataset: a sequence of data classes, where each data\n            class has a sample(n) method.\n          input_ph: placeholder for a batch of samples.\n          label_ph: placeholder for a batch of labels.\n          minimize_op: TensorFlow Op to minimize a loss on the\n            batch specified by input_ph and label_ph.\n          num_classes: number of segmentation classes. Currently ignored.\n          num_shots: number of examples per data class.\n          inner_batch_size: batch size for every inner-loop\n            training iteration.\n          inner_iters: number of inner-loop iterations.\n          replacement: sample with replacement.\n          meta_step_size: interpolation coefficient.\n          meta_batch_size: how many inner-loops to run.\n          lr_ph: learning rate placeholder for schedule learning rates\n        \"\"\"", "\n", "# Hardcode binary Gecko:", "\n", "num_classes", "=", "1", "\n", "\n", "old_vars", "=", "self", ".", "_model_state", ".", "export_variables", "(", ")", "\n", "new_vars", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "meta_batch_size", ")", ":", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "'Sampling new task.'", ")", "\n", "", "mini_dataset", "=", "_sample_mini_image_segmentation_dataset", "(", "self", ".", "session", ",", "dataset", ",", "num_classes", ",", "num_shots", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "_mini_batches", "(", "mini_dataset", ",", "inner_batch_size", ",", "inner_iters", ",", "replacement", ",", "augmenter", "=", "self", ".", "augmenter", ")", ")", ":", "\n", "                ", "if", "verbose", ":", "\n", "                    ", "print", "(", "'Sampling new mini_batch.'", ")", "\n", "", "inputs", ",", "labels", "=", "zip", "(", "*", "batch", ")", "\n", "if", "self", ".", "_pre_step_op", ":", "\n", "                    ", "self", ".", "session", ".", "run", "(", "self", ".", "_pre_step_op", ")", "\n", "", "if", "(", "lr_ph", "is", "not", "None", ")", "and", "(", "lr", "is", "not", "None", ")", ":", "\n", "                    ", "self", ".", "session", ".", "run", "(", "minimize_op", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", ",", "label_ph", ":", "labels", ",", "\n", "lr_ph", ":", "lr", "}", ")", "\n", "", "if", "(", "lr_ph", "is", "not", "None", ")", "and", "(", "self", ".", "lr_scheduler", "is", "not", "None", ")", ":", "\n", "                    ", "self", ".", "session", ".", "run", "(", "minimize_op", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", ",", "label_ph", ":", "labels", ",", "\n", "lr_ph", ":", "self", ".", "lr_scheduler", ".", "cur_lr", "(", "cur_step", "=", "i", ")", "}", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "session", ".", "run", "(", "minimize_op", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", ",", "label_ph", ":", "labels", "}", ")", "\n", "", "", "new_vars", ".", "append", "(", "self", ".", "_model_state", ".", "export_variables", "(", ")", ")", "\n", "self", ".", "_model_state", ".", "import_variables", "(", "old_vars", ")", "\n", "", "new_vars", "=", "average_vars", "(", "new_vars", ")", "\n", "self", ".", "_model_state", ".", "import_variables", "(", "interpolate_vars", "(", "old_vars", ",", "new_vars", ",", "meta_step_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko.evaluate": [[127, 234], ["print", "print", "enumerate", "numpy.nanmean", "print", "print", "random.shuffle", "meta_learners.metaseg._sample_mini_image_segmentation_dataset", "task_names.append", "print", "meta_learners.metaseg._split_train_test_segmentation", "reptile.Gecko._evaluate", "ious.append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg._sample_mini_image_segmentation_dataset", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg._split_train_test_segmentation", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko._evaluate"], ["", "def", "evaluate", "(", "self", ",", "\n", "dataset", ",", "\n", "input_ph", ",", "\n", "label_ph", ",", "\n", "minimize_op", ",", "\n", "predictions", ",", "\n", "num_classes", ",", "\n", "num_shots", ",", "\n", "inner_batch_size", ",", "\n", "inner_iters", ",", "\n", "replacement", ",", "\n", "eval_all_tasks", "=", "False", ",", "\n", "num_tasks_to_sample", "=", "1", ",", "\n", "test_shots", "=", "DEFAULT_NUM_TEST_EXAMPLES", ",", "\n", "verbose", "=", "False", ",", "\n", "save_fine_tuned_checkpoints", "=", "False", ",", "\n", "save_fine_tuned_checkpoints_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "eval_sample_num", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "is_training_ph", ":", "Optional", "[", "tf", ".", "Tensor", "]", "=", "None", ",", "\n", "lr_ph", ":", "Optional", "[", "tf", ".", "Tensor", "]", "=", "None", ",", "\n", "lr", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "drop_rate_ph", ":", "Optional", "[", "tf", ".", "Tensor", "]", "=", "None", ",", "\n", "drop_rate", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "aug_rate", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", ")", "->", "Tuple", "[", "float", ",", "Dict", "[", "str", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        Run a single evaluation of training the image segmentation model on new tasks.\n\n        Samples a few-shot learning task and measures\n        performance with mean Intersection over Union (IoU)\n\n        Args:\n          dataset: a list of data classes, where each data\n            class has a sample(n) method.\n          input_ph: placeholder for a batch of samples.\n          label_ph: placeholder for a batch of labels.\n          minimize_op: TensorFlow Op to minimize a loss on the\n            batch specified by input_ph and label_ph.\n          predictions: a Tensor of floating point image mask/label scores.\n          num_classes: number of data classes to sample. Parameter is currently ignored.\n          num_shots: number of examples per data class.\n          inner_batch_size: batch size for every inner-loop\n            training iteration.\n          inner_iters: number of inner-loop iterations.\n          replacement: sample with replacement.\n          eval_all_tasks: evaluate a few shot problem for all tasks in `dataset`\n          test_shots: number of images to evaluate segmentation performance on.\n          lr_ph: learning rate placeholder for scheduling the learning rate in the inner loop\n\n        Returns:\n          Mean Intersection over Union\n        \"\"\"", "\n", "print", "(", "\"Evaluating {} meta-learning.\"", ".", "format", "(", "self", ".", "meta_fn", ")", ")", "\n", "\n", "if", "aug_rate", "is", "None", ":", "\n", "            ", "aug_rate", "=", "self", ".", "aug_rate", "\n", "\n", "", "if", "eval_all_tasks", ":", "\n", "            ", "sampled_tasks", "=", "dataset", "\n", "", "else", ":", "\n", "            ", "random", ".", "shuffle", "(", "dataset", ")", "\n", "sampled_tasks", "=", "dataset", "[", ":", "num_tasks_to_sample", "]", "\n", "\n", "", "print", "(", "\"Evaluating {} {}-shot tasks.\"", ".", "format", "(", "len", "(", "sampled_tasks", ")", ",", "num_shots", ")", ")", "\n", "\n", "task_names", "=", "[", "]", "\n", "ious", "=", "[", "]", "\n", "task_iou_map", "=", "{", "}", "\n", "for", "i", ",", "sampled_task", "in", "enumerate", "(", "sampled_tasks", ")", ":", "\n", "            ", "sampled_task", ",", "task_name", "=", "_sample_mini_image_segmentation_dataset", "(", "self", ".", "session", ",", "[", "sampled_task", "]", ",", "num_classes", ",", "\n", "num_shots", "+", "test_shots", ",", "\n", "return_task_name", "=", "True", ")", "\n", "task_names", ".", "append", "(", "task_name", ")", "\n", "print", "(", "\"Evaluating {}\"", ".", "format", "(", "task_name", ")", ")", "\n", "\n", "train_set", ",", "test_set", "=", "_split_train_test_segmentation", "(", "sampled_task", ",", "test_shots", ")", "# , test_train_test_split=True)", "\n", "\n", "task_iou", "=", "self", ".", "_evaluate", "(", "\n", "train_set", "=", "train_set", ",", "\n", "test_set", "=", "test_set", ",", "\n", "input_ph", "=", "input_ph", ",", "\n", "label_ph", "=", "label_ph", ",", "\n", "minimize_op", "=", "minimize_op", ",", "\n", "predictions", "=", "predictions", ",", "\n", "inner_batch_size", "=", "inner_batch_size", ",", "\n", "inner_iters", "=", "inner_iters", ",", "\n", "replacement", "=", "replacement", ",", "\n", "verbose", "=", "verbose", ",", "\n", "save_fine_tuned_checkpoints", "=", "save_fine_tuned_checkpoints", ",", "\n", "save_fine_tuned_checkpoints_dir", "=", "save_fine_tuned_checkpoints_dir", ",", "\n", "eval_sample_num", "=", "eval_sample_num", ",", "\n", "is_training_ph", "=", "is_training_ph", ",", "\n", "lr_ph", "=", "lr_ph", ",", "\n", "lr", "=", "lr", ",", "\n", "task_name", "=", "task_name", ",", "\n", "drop_rate_ph", "=", "drop_rate_ph", ",", "\n", "drop_rate", "=", "drop_rate", ",", "\n", "aug_rate", "=", "aug_rate", ",", "\n", ")", "\n", "ious", ".", "append", "(", "task_iou", ")", "\n", "task_iou_map", "[", "task_name", "]", "=", "task_iou", "\n", "\n", "", "mean_iou_score", "=", "np", ".", "nanmean", "(", "ious", ")", "\n", "print", "(", "\"Evaluated {} task/s\"", ".", "format", "(", "len", "(", "sampled_tasks", ")", ")", ")", "\n", "print", "(", "'Mean IoU from train on {} images and evaluate on {} test images: {}'", ".", "format", "(", "num_shots", ",", "test_shots", ",", "\n", "mean_iou_score", ")", ")", "\n", "return", "mean_iou_score", ",", "task_iou_map", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko._evaluate": [[235, 295], ["reptile.Gecko._full_state.export_variables", "enumerate", "reptile.Gecko._test_predictions", "numpy.nanmean", "print", "reptile.Gecko._full_state.import_variables", "meta_learners.metaseg._mini_batches", "zip", "os.path.join", "utils.util.save_fine_tuned_checkpoint", "reptile.Gecko._iou", "print", "reptile.Gecko.session.run", "reptile.Gecko.session.run", "range", "reptile.Gecko.session.run", "len", "reptile.Gecko.session.run", "reptile.Gecko.session.run", "reptile.Gecko.lr_scheduler.cur_lr"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.VariableState.export_variables", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko._test_predictions", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.VariableState.import_variables", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.FOMLIS._mini_batches", "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.save_fine_tuned_checkpoint", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko._iou", "home.repos.pwc.inspect_result.ml4ai_mliis.models.lr_schedulers.LRScheduler.cur_lr"], ["", "def", "_evaluate", "(", "self", ",", "\n", "train_set", ",", "\n", "test_set", ",", "\n", "input_ph", ",", "\n", "label_ph", ",", "\n", "minimize_op", ",", "\n", "predictions", ",", "\n", "inner_batch_size", ",", "\n", "inner_iters", ",", "\n", "replacement", ",", "\n", "verbose", "=", "False", ",", "\n", "save_fine_tuned_checkpoints", "=", "False", ",", "\n", "save_fine_tuned_checkpoints_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "eval_sample_num", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "is_training_ph", ":", "Optional", "[", "tf", ".", "Tensor", "]", "=", "None", ",", "\n", "lr_ph", ":", "Optional", "[", "tf", ".", "Tensor", "]", "=", "None", ",", "\n", "lr", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "drop_rate_ph", ":", "Optional", "[", "tf", ".", "Tensor", "]", "=", "None", ",", "\n", "drop_rate", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "aug_rate", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "task_name", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Evaluates a single task's train-test split.\"\"\"", "\n", "old_vars", "=", "self", ".", "_full_state", ".", "export_variables", "(", ")", "# keep vars in memory to reimport later", "\n", "\n", "# Fine-tune to task:", "\n", "for", "inner_iter", ",", "batch", "in", "enumerate", "(", "_mini_batches", "(", "train_set", ",", "inner_batch_size", ",", "num_batches", "=", "inner_iters", ",", "\n", "replacement", "=", "replacement", ",", "augmenter", "=", "self", ".", "augmenter", ",", "aug_rate", "=", "aug_rate", ")", ")", ":", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "'Training on batch in eval task.'", ")", "\n", "", "inputs", ",", "labels", "=", "zip", "(", "*", "batch", ")", "\n", "if", "self", ".", "_pre_step_op", ":", "\n", "                ", "self", ".", "session", ".", "run", "(", "self", ".", "_pre_step_op", ")", "\n", "\n", "", "if", "(", "lr_ph", "is", "not", "None", ")", "and", "(", "lr", "is", "not", "None", ")", "and", "(", "drop_rate_ph", "is", "not", "None", ")", "and", "(", "drop_rate", "is", "not", "None", ")", ":", "\n", "                ", "self", ".", "session", ".", "run", "(", "minimize_op", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", ",", "label_ph", ":", "labels", ",", "drop_rate_ph", ":", "drop_rate", ",", "\n", "lr_ph", ":", "lr", "}", ")", "\n", "", "elif", "(", "lr_ph", "is", "not", "None", ")", "and", "(", "lr", "is", "not", "None", ")", ":", "\n", "                ", "self", ".", "session", ".", "run", "(", "minimize_op", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", ",", "label_ph", ":", "labels", ",", "\n", "lr_ph", ":", "lr", "}", ")", "\n", "", "elif", "(", "lr_ph", "is", "not", "None", ")", "and", "(", "self", ".", "lr_scheduler", "is", "not", "None", ")", ":", "\n", "                ", "self", ".", "session", ".", "run", "(", "minimize_op", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", ",", "label_ph", ":", "labels", ",", "\n", "lr_ph", ":", "self", ".", "lr_scheduler", ".", "cur_lr", "(", "cur_step", "=", "inner_iter", ")", "}", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "session", ".", "run", "(", "minimize_op", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", ",", "label_ph", ":", "labels", "}", ")", "\n", "\n", "", "", "if", "save_fine_tuned_checkpoints", ":", "\n", "            ", "checkpoint_dir_to_save_to", "=", "os", ".", "path", ".", "join", "(", "save_fine_tuned_checkpoints_dir", ",", "task_name", ")", "\n", "save_fine_tuned_checkpoint", "(", "save_fine_tuned_checkpoint_dir", "=", "checkpoint_dir_to_save_to", ",", "\n", "sess", "=", "self", ".", "session", ",", "step", "=", "inner_iter", ",", "\n", "eval_sample_num", "=", "eval_sample_num", ")", "\n", "\n", "", "test_preds", "=", "self", ".", "_test_predictions", "(", "train_set", ",", "test_set", ",", "input_ph", ",", "predictions", ",", "is_training_ph", ",", "task_name", "=", "task_name", ")", "\n", "\n", "# Pass prediction and label arrays to _iou:", "\n", "class_iou", "=", "[", "self", ".", "_iou", "(", "test_preds", "[", "j", "]", ",", "test_set", "[", "j", "]", "[", "1", "]", ")", "for", "j", "in", "range", "(", "len", "(", "test_preds", ")", ")", "]", "\n", "class_iou", "=", "np", ".", "nanmean", "(", "class_iou", ")", "\n", "print", "(", "\"Mean task IoU: {}\"", ".", "format", "(", "class_iou", ")", ")", "\n", "self", ".", "_full_state", ".", "import_variables", "(", "old_vars", ")", "\n", "return", "class_iou", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko.evaluate_with_early_stopping": [[296, 392], ["print", "print", "print", "print", "random.shuffle", "enumerate", "int", "print", "reptile.Gecko.evaluate", "task_iou_map.keys", "task_iou_map.values", "numpy.nanmean", "len", "meta_learners.metaseg._sample_mini_image_segmentation_dataset", "task_iou_map.keys.append", "meta_learners.metaseg._split_train_test_segmentation", "reptile.Gecko._early_stopping_learn", "task_iou_map.values.append", "num_steps.append", "numpy.median", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko.evaluate", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg._sample_mini_image_segmentation_dataset", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg._split_train_test_segmentation", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko._early_stopping_learn"], ["", "def", "evaluate_with_early_stopping", "(", "self", ",", "\n", "dataset", ",", "\n", "input_ph", ",", "\n", "label_ph", ",", "\n", "minimize_op", ",", "\n", "predictions", ",", "\n", "num_classes", ",", "\n", "num_shots", ",", "\n", "inner_batch_size", ",", "\n", "min_steps", ",", "\n", "max_steps", ",", "\n", "replacement", ",", "\n", "eval_all_tasks", "=", "False", ",", "\n", "num_tasks_to_sample", "=", "20", ",", "\n", "test_shots", "=", "DEFAULT_NUM_TEST_EXAMPLES", ",", "\n", "is_training_ph", ":", "Optional", "[", "tf", ".", "Tensor", "]", "=", "None", ",", "\n", "lr_ph", ":", "Optional", "[", "tf", ".", "Tensor", "]", "=", "None", ",", "\n", "lr", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "drop_rate_ph", ":", "Optional", "[", "tf", ".", "Tensor", "]", "=", "None", ",", "\n", "drop_rate", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "aug_rate", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "eval_tasks_with_median_early_stopping_iterations", ":", "bool", "=", "False", ",", "# speed up by setting to False", "\n", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "List", "[", "int", "]", ",", "List", "[", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        Samples few-shot learning tasks, splitting into test and val sets and measures\n        performance with mean Intersection over Union (IoU) on the val set.\n\n        Returns:\n          List of task names, list of best num steps, and IoU scores.\n        \"\"\"", "\n", "print", "(", "\"Evaluating {} meta-learning.\"", ".", "format", "(", "self", ".", "meta_fn", ")", ")", "\n", "if", "eval_all_tasks", ":", "\n", "            ", "sampled_tasks", "=", "dataset", "\n", "", "else", ":", "\n", "            ", "random", ".", "shuffle", "(", "dataset", ")", "\n", "sampled_tasks", "=", "dataset", "[", ":", "num_tasks_to_sample", "]", "\n", "\n", "", "print", "(", "\"Evaluating {} {}-shot tasks.\"", ".", "format", "(", "len", "(", "sampled_tasks", ")", ",", "num_shots", ")", ")", "\n", "\n", "task_names", "=", "[", "]", "\n", "ious", "=", "[", "]", "\n", "if", "min_steps", "!=", "max_steps", ":", "\n", "            ", "num_steps", "=", "[", "]", "\n", "for", "i", ",", "sampled_task", "in", "enumerate", "(", "sampled_tasks", ")", ":", "\n", "                ", "sampled_task", ",", "task_name", "=", "_sample_mini_image_segmentation_dataset", "(", "self", ".", "session", ",", "[", "sampled_task", "]", ",", "num_classes", ",", "\n", "num_shots", "+", "test_shots", ",", "\n", "return_task_name", "=", "True", ")", "\n", "task_names", ".", "append", "(", "task_name", ")", "\n", "\n", "train_set", ",", "test_set", "=", "_split_train_test_segmentation", "(", "sampled_task", ",", "test_shots", ")", "\n", "\n", "# Fine-tune to task:", "\n", "best_n_steps", ",", "best_miou", "=", "self", ".", "_early_stopping_learn", "(", "train_set", ",", "test_set", ",", "input_ph", ",", "label_ph", ",", "minimize_op", ",", "\n", "predictions", ",", "inner_batch_size", ",", "min_steps", "=", "min_steps", ",", "\n", "max_steps", "=", "max_steps", ",", "\n", "replacement", "=", "replacement", ",", "is_training_ph", "=", "is_training_ph", ",", "lr_ph", "=", "lr_ph", ",", "lr_scheduler", "=", "self", ".", "lr_scheduler", ",", "lr", "=", "lr", ",", "\n", "drop_rate_ph", "=", "drop_rate_ph", ",", "drop_rate", "=", "drop_rate", ",", "aug_rate", "=", "aug_rate", ")", "\n", "ious", ".", "append", "(", "best_miou", ")", "\n", "num_steps", ".", "append", "(", "best_n_steps", ")", "\n", "", "estimated_best_num_steps", "=", "int", "(", "np", ".", "median", "(", "num_steps", ")", ")", "\n", "", "else", ":", "\n", "            ", "estimated_best_num_steps", "=", "min_steps", "\n", "num_steps", "=", "[", "estimated_best_num_steps", "]", "*", "len", "(", "sampled_tasks", ")", "\n", "\n", "# Conditionally evaluate all samples with np.median(num_steps):", "\n", "", "if", "eval_tasks_with_median_early_stopping_iterations", "or", "min_steps", "==", "max_steps", ":", "\n", "            ", "print", "(", "\"Estimated best number of steps {}\"", ".", "format", "(", "estimated_best_num_steps", ")", ")", "\n", "mean_iou_score", ",", "task_iou_map", "=", "self", ".", "evaluate", "(", "dataset", "=", "sampled_tasks", ",", "\n", "input_ph", "=", "input_ph", ",", "\n", "label_ph", "=", "label_ph", ",", "\n", "minimize_op", "=", "minimize_op", ",", "\n", "predictions", "=", "predictions", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "num_shots", "=", "num_shots", ",", "\n", "inner_batch_size", "=", "inner_batch_size", ",", "\n", "inner_iters", "=", "estimated_best_num_steps", ",", "\n", "replacement", "=", "replacement", ",", "\n", "eval_all_tasks", "=", "eval_all_tasks", ",", "\n", "num_tasks_to_sample", "=", "num_tasks_to_sample", ",", "\n", "test_shots", "=", "test_shots", ",", "\n", "is_training_ph", "=", "is_training_ph", ",", "\n", "lr_ph", "=", "lr_ph", ",", "\n", "lr", "=", "lr", ",", "\n", "drop_rate_ph", "=", "drop_rate_ph", ",", "\n", "drop_rate", "=", "drop_rate", ",", "\n", "aug_rate", "=", "aug_rate", ",", "\n", ")", "\n", "task_names", "=", "task_iou_map", ".", "keys", "(", ")", "\n", "ious", "=", "task_iou_map", ".", "values", "(", ")", "\n", "", "else", ":", "\n", "            ", "mean_iou_score", "=", "np", ".", "nanmean", "(", "ious", ")", "\n", "\n", "", "print", "(", "\"Evaluated {} task/s\"", ".", "format", "(", "len", "(", "sampled_tasks", ")", ")", ")", "\n", "print", "(", "'Mean IoU from train on {} images and evaluate on {} test images: {}'", ".", "format", "(", "num_shots", ",", "test_shots", ",", "\n", "mean_iou_score", ")", ")", "\n", "return", "task_names", ",", "num_steps", ",", "ious", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko.evaluate_m_k_shot_ranges_all_tasks": [[393, 408], ["len", "len", "range", "reptile.Gecko.evaluate_k_shot_range", "print", "results.extend", "ks.extend", "zip"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko.evaluate_k_shot_range"], ["", "def", "evaluate_m_k_shot_ranges_all_tasks", "(", "self", ",", "tasks", ",", "k_range", ",", "m", ",", "input_ph", ",", "label_ph", ",", "minimize_op", ",", "predictions", ",", "inner_batch_size", ",", "\n", "inner_iters", ",", "replacement", ",", "is_training_ph", "=", "None", ",", "lr_ph", "=", "None", ",", "lr", "=", "None", ",", "test_samples", "=", "20", ",", "iter_range", "=", "DEFAULT_ITER_RANGE", ",", "aug_rate", ":", "float", "=", "0.5", ")", ":", "\n", "        ", "assert", "len", "(", "iter_range", ")", "==", "len", "(", "k_range", ")", "\n", "params", "=", "{", "\"input_ph\"", ":", "input_ph", ",", "\"label_ph\"", ":", "label_ph", ",", "\"minimize_op\"", ":", "minimize_op", ",", "\"predictions\"", ":", "predictions", ",", "\n", "\"inner_batch_size\"", ":", "inner_batch_size", ",", "\"inner_iters\"", ":", "inner_iters", ",", "\"replacement\"", ":", "replacement", ",", "\n", "\"is_training_ph\"", ":", "is_training_ph", ",", "\"lr_ph\"", ":", "lr_ph", ",", "\"lr\"", ":", "lr", ",", "\"aug_rate\"", ":", "aug_rate", "}", "\n", "ks", "=", "[", "]", "\n", "results", "=", "[", "]", "\n", "for", "task", "in", "tasks", ":", "\n", "            ", "for", "_", "in", "range", "(", "m", ")", ":", "\n", "                ", "res", "=", "self", ".", "evaluate_k_shot_range", "(", "task", ",", "k_range", "=", "k_range", ",", "iter_range", "=", "iter_range", ",", "test_samples", "=", "test_samples", ",", "**", "params", ")", "\n", "print", "(", "\"k-shot results {}\"", ".", "format", "(", "{", "k", ":", "r", "for", "k", ",", "r", "in", "zip", "(", "k_range", ",", "res", ")", "}", ")", ")", "\n", "results", ".", "extend", "(", "res", ")", "\n", "ks", ".", "extend", "(", "k_range", ")", "\n", "", "", "return", "ks", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko.evaluate_k_shot_range": [[409, 442], ["meta_learners.metaseg._sample_mini_image_segmentation_dataset", "meta_learners.metaseg._split_train_test_segmentation", "enumerate", "print", "print", "reptile.Gecko._evaluate", "mious.append", "max", "int", "print", "meta_learners.metaseg._split_train_test_segmentation", "reptile.Gecko._early_stopping_learn"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg._sample_mini_image_segmentation_dataset", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg._split_train_test_segmentation", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko._evaluate", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg._split_train_test_segmentation", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko._early_stopping_learn"], ["", "def", "evaluate_k_shot_range", "(", "self", ",", "task", ",", "k_range", ",", "iter_range", "=", "DEFAULT_ITER_RANGE", ",", "test_samples", "=", "20", ",", "early_stopping_min_val_samples", "=", "5", ",", "esimate_inner_iters_with_early_stoppping", ":", "bool", "=", "True", ",", "**", "params", ")", ":", "\n", "        ", "\"\"\"Evaluates k-shot learning results for a single task over a range of ks.\"\"\"", "\n", "\n", "mious", "=", "[", "]", "\n", "\n", "sampled_task", ",", "task_name", "=", "_sample_mini_image_segmentation_dataset", "(", "self", ".", "session", ",", "[", "task", "]", ",", "num_classes", "=", "1", ",", "\n", "num_shots", "=", "max", "(", "k_range", ")", "+", "test_samples", ",", "\n", "return_task_name", "=", "True", ")", "\n", "training_examples", ",", "test_set", "=", "_split_train_test_segmentation", "(", "sampled_task", ",", "test_shots", "=", "test_samples", ")", "\n", "\n", "for", "i", ",", "k", "in", "enumerate", "(", "k_range", ")", ":", "\n", "            ", "print", "(", "\"Evaluating {}-shot learning\"", ".", "format", "(", "k", ")", ")", "\n", "train_set", "=", "training_examples", "[", ":", "k", "]", "\n", "\n", "if", "esimate_inner_iters_with_early_stoppping", ":", "\n", "# if k >= test_samples * 2:", "\n", "#     early_stopping_min_val_samples = test_samples", "\n", "\n", "                ", "if", "k", ">=", "early_stopping_min_val_samples", "*", "2", ":", "\n", "                    ", "val_shots", "=", "int", "(", "0.2", "*", "k", ")", "# Use 20% of training dataset for validating against during ES", "\n", "print", "(", "\"Split training dataset into {} train shots and {} val shots for early stopping to estimate number of steps.\"", ".", "format", "(", "k", "-", "val_shots", ",", "val_shots", ")", ")", "\n", "d_tr", ",", "d_val", "=", "_split_train_test_segmentation", "(", "train_set", ",", "test_shots", "=", "val_shots", ")", "\n", "inner_iters", ",", "_", "=", "self", ".", "_early_stopping_learn", "(", "d_tr", ",", "d_val", ",", "min_steps", "=", "1", ",", "max_steps", "=", "500", ",", "**", "params", ")", "\n", "params", "[", "\"inner_iters\"", "]", "=", "inner_iters", "\n", "", "", "else", ":", "\n", "                ", "params", "[", "\"inner_iters\"", "]", "=", "iter_range", "[", "i", "]", "\n", "", "task_iou", "=", "self", ".", "_evaluate", "(", "train_set", ",", "test_set", ",", "**", "params", ")", "\n", "\n", "mious", ".", "append", "(", "task_iou", ")", "\n", "\n", "", "print", "(", "\"Evaluated task {} over k-range {}\"", ".", "format", "(", "task_name", ",", "k_range", ")", ")", "\n", "\n", "return", "mious", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko._early_stopping_learn": [[443, 481], ["reptile.Gecko._full_state.export_variables", "meta_learners.hyperparam_search.EarlyStopper", "enumerate", "meta_learners.hyperparam_search.EarlyStopper.best_num_steps", "meta_learners.hyperparam_search.EarlyStopper.best_metric", "print", "reptile.Gecko._full_state.import_variables", "ValueError", "meta_learners.metaseg._mini_batches", "zip", "reptile.Gecko._test_predictions", "numpy.nanmean", "reptile.Gecko.session.run", "reptile.Gecko.session.run", "reptile.Gecko._iou", "meta_learners.hyperparam_search.EarlyStopper.continue_training", "reptile.Gecko.session.run", "range", "reptile.Gecko.session.run", "reptile.Gecko.session.run", "len", "lr_scheduler.cur_lr"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.VariableState.export_variables", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.EarlyStopper.best_num_steps", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.EarlyStopper.best_metric", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.VariableState.import_variables", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.FOMLIS._mini_batches", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko._test_predictions", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko._iou", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.EarlyStopper.continue_training", "home.repos.pwc.inspect_result.ml4ai_mliis.models.lr_schedulers.LRScheduler.cur_lr"], ["", "def", "_early_stopping_learn", "(", "self", ",", "train_set", ",", "val_set", ",", "input_ph", ",", "label_ph", ",", "minimize_op", ",", "predictions", ",", "inner_batch_size", ",", "\n", "min_steps", ",", "max_steps", ",", "replacement", ",", "is_training_ph", "=", "None", ",", "lr_ph", "=", "None", ",", "lr_scheduler", "=", "None", ",", "lr", "=", "None", ",", "\n", "drop_rate_ph", "=", "None", ",", "drop_rate", "=", "None", ",", "patience", "=", "50", ",", "inner_iters", "=", "None", ",", "aug_rate", ":", "Optional", "[", "float", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"Estimates number of steps to take when learning a new task.\"\"\"", "\n", "del", "inner_iters", "\n", "old_vars", "=", "self", ".", "_full_state", ".", "export_variables", "(", ")", "# keep vars in memory to reimport later", "\n", "if", "lr_scheduler", "is", "not", "None", "and", "lr", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Only lr_scheduler or lr should be speced. Not both.\"", ")", "\n", "\n", "", "early_stopper", "=", "EarlyStopper", "(", "patience", ",", "min_steps", "=", "min_steps", ")", "\n", "for", "inner_iter", ",", "batch", "in", "enumerate", "(", "_mini_batches", "(", "train_set", ",", "inner_batch_size", ",", "num_batches", "=", "max_steps", ",", "\n", "replacement", "=", "replacement", ",", "augmenter", "=", "self", ".", "augmenter", ",", "aug_rate", "=", "aug_rate", ")", ")", ":", "\n", "            ", "inputs", ",", "labels", "=", "zip", "(", "*", "batch", ")", "\n", "if", "self", ".", "_pre_step_op", ":", "\n", "                ", "self", ".", "session", ".", "run", "(", "self", ".", "_pre_step_op", ")", "\n", "", "if", "(", "lr_ph", "is", "not", "None", ")", "and", "(", "lr", "is", "not", "None", ")", "and", "(", "drop_rate_ph", "is", "not", "None", ")", "and", "(", "drop_rate", "is", "not", "None", ")", ":", "\n", "                ", "self", ".", "session", ".", "run", "(", "minimize_op", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", ",", "label_ph", ":", "labels", ",", "drop_rate_ph", ":", "drop_rate", ",", "\n", "lr_ph", ":", "lr", "}", ")", "\n", "", "elif", "(", "lr_ph", "is", "not", "None", ")", "and", "(", "lr", "is", "not", "None", ")", ":", "\n", "                ", "self", ".", "session", ".", "run", "(", "minimize_op", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", ",", "label_ph", ":", "labels", ",", "\n", "lr_ph", ":", "lr", "}", ")", "\n", "", "elif", "(", "lr_ph", "is", "not", "None", ")", "and", "(", "lr_scheduler", "is", "not", "None", ")", ":", "\n", "                ", "self", ".", "session", ".", "run", "(", "minimize_op", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", ",", "label_ph", ":", "labels", ",", "\n", "lr_ph", ":", "lr_scheduler", ".", "cur_lr", "(", "cur_step", "=", "inner_iter", ")", "}", ")", "\n", "", "else", ":", "# Use hyperparam defaults:", "\n", "                ", "self", ".", "session", ".", "run", "(", "minimize_op", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", ",", "label_ph", ":", "labels", "}", ")", "\n", "\n", "", "test_preds", "=", "self", ".", "_test_predictions", "(", "train_set", ",", "val_set", ",", "input_ph", ",", "predictions", ",", "is_training_ph", ")", "\n", "\n", "ious", "=", "[", "self", ".", "_iou", "(", "test_preds", "[", "j", "]", ",", "val_set", "[", "j", "]", "[", "1", "]", ")", "for", "j", "in", "range", "(", "len", "(", "test_preds", ")", ")", "]", "\n", "miou", "=", "np", ".", "nanmean", "(", "ious", ")", "\n", "if", "not", "early_stopper", ".", "continue_training", "(", "miou", ",", "inner_iter", "+", "1", ")", ":", "\n", "                ", "break", "\n", "", "", "best_num_steps", "=", "early_stopper", ".", "best_num_steps", "(", ")", "\n", "best_iou", "=", "early_stopper", ".", "best_metric", "(", ")", "\n", "print", "(", "\"Best iteration found: {}, with mean-IoU {}\"", ".", "format", "(", "best_num_steps", ",", "best_iou", ")", ")", "\n", "self", ".", "_full_state", ".", "import_variables", "(", "old_vars", ")", "\n", "return", "best_num_steps", ",", "best_iou", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko._test_predictions": [[482, 525], ["bool", "zip", "zip", "reptile.Gecko.append", "reptile.Gecko.session.run", "reptile.Gecko.session.run", "enumerate", "zip", "utils.viz.savefig_mask_on_image", "reptile.Gecko.session.run", "reptile.Gecko.session.run"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.utils.viz.savefig_mask_on_image"], ["", "def", "_test_predictions", "(", "self", ",", "train_set", ",", "test_set", ",", "input_ph", ",", "predictions", ",", "is_training_ph", "=", "None", ",", "task_name", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Run the operations to evaluate `predictions` tensor from the graph on the `test_set`.\n\n        Args:\n            train_set: training examples (for non-transductive eval)\n            test_set: test examples to predict the labels of\n            input_ph: input placeholder to the graph\n            predictions: predictions tensor to evaluate\n            is_training_ph: placeholder which will switch operations from training to testing modes.\n        Returns:\n            Prediction arrays\n        \"\"\"", "\n", "# To save predictions run in shell: export SAVE_PREDICTIONS=1", "\n", "try", ":", "\n", "            ", "save_vized_predictions", "=", "bool", "(", "os", ".", "environ", "[", "\"SAVE_PREDICTIONS\"", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "save_vized_predictions", "=", "False", "\n", "", "if", "self", ".", "_transductive", ":", "\n", "            ", "inputs", ",", "_", "=", "zip", "(", "*", "test_set", ")", "\n", "if", "is_training_ph", "is", "None", ":", "\n", "                ", "res", "=", "self", ".", "session", ".", "run", "(", "predictions", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", "}", ")", "\n", "", "else", ":", "\n", "# Use estimated population mean and variances for batch norm by setting is_training_ph to False (which also turns off dropout):", "\n", "                ", "res", "=", "self", ".", "session", ".", "run", "(", "predictions", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", ",", "is_training_ph", ":", "False", "}", ")", "\n", "\n", "", "if", "save_vized_predictions", ":", "\n", "                ", "for", "i", ",", "query_prediction", "in", "enumerate", "(", "zip", "(", "inputs", ",", "res", ")", ")", ":", "\n", "                    ", "query", ",", "prediction", "=", "query_prediction", "\n", "task_name", "=", "\"\"", "if", "task_name", "is", "None", "else", "task_name", "\n", "save_path", "=", "\"predictions/prediction_{}_{}.jpeg\"", ".", "format", "(", "task_name", ",", "i", ")", "\n", "savefig_mask_on_image", "(", "query", ",", "prediction", ",", "save_path", "=", "save_path", ")", "\n", "", "", "return", "res", "\n", "", "res", "=", "[", "]", "\n", "for", "test_sample", "in", "test_set", ":", "\n", "            ", "inputs", ",", "_", "=", "zip", "(", "*", "train_set", ")", "\n", "inputs", "+=", "(", "test_sample", "[", "0", "]", ",", ")", "\n", "if", "is_training_ph", "is", "not", "None", ":", "\n", "                ", "predicted_mask", "=", "self", ".", "session", ".", "run", "(", "predictions", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", ",", "is_training_ph", ":", "False", "}", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "predicted_mask", "=", "self", ".", "session", ".", "run", "(", "predictions", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", "}", ")", "[", "-", "1", "]", "\n", "", "res", ".", "append", "(", "predicted_mask", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko._iou": [[526, 550], ["numpy.round", "numpy.logical_and", "numpy.logical_or", "len", "ValueError", "ValueError", "numpy.round", "numpy.sum", "numpy.sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_iou", "(", "prediction", ":", "np", ".", "array", ",", "label", ":", "np", ".", "array", ",", "epsilon", ":", "float", "=", "1e-7", ",", "class_of_interest_channel", ":", "Optional", "[", "Union", "[", "int", ",", "slice", "]", "]", "=", "1", ",", "round_labels", ":", "bool", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Return the intersection over union score of two binary arrays. Intended for single images, not batches.\n        Args:\n            prediction: floating point array of predictions of shape [rows, columns, 2]\n            label: boolean array of labels of shape [rows, columns, 2]\n            epsilon: small floating point value to avoid divided by zero error in the event that there is no union (no predictions, no labels)\n        \"\"\"", "\n", "if", "len", "(", "prediction", ".", "shape", ")", ">", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"Function is intended for single image masks, not batches.\"", ")", "\n", "", "if", "prediction", ".", "shape", "!=", "label", ".", "shape", ":", "\n", "            ", "raise", "ValueError", "(", "\"prediction shape and label shape must be equal but are: {} and {} respectively.\"", ".", "format", "(", "prediction", ".", "shape", ",", "label", ".", "shape", ")", ")", "\n", "", "if", "class_of_interest_channel", "is", "not", "None", ":", "\n", "            ", "prediction", "=", "prediction", "[", ":", ",", ":", ",", "class_of_interest_channel", "]", "\n", "label", "=", "label", "[", ":", ",", ":", ",", "class_of_interest_channel", "]", "\n", "\n", "", "prediction", "=", "np", ".", "round", "(", "prediction", ")", "\n", "if", "round_labels", ":", "\n", "            ", "label", "=", "np", ".", "round", "(", "label", ")", "\n", "\n", "", "intersection", "=", "np", ".", "logical_and", "(", "prediction", ",", "label", ")", "\n", "union", "=", "np", ".", "logical_or", "(", "label", ",", "prediction", ")", "\n", "return", "(", "np", ".", "sum", "(", "intersection", ")", "+", "epsilon", ")", "/", "(", "np", ".", "sum", "(", "union", ")", "+", "epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.FOMLIS.__init__": [[586, 604], ["reptile.Gecko.__init__", "print", "print"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "train_shots", ":", "Optional", "[", "int", "]", "=", "None", ",", "tail_shots", ":", "Optional", "[", "int", "]", "=", "None", ",", "sample_train_val_with_replacement", ":", "bool", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Create a first-order MAML session.\n\n        Args:\n          args: args for Reptile.\n          tail_shots: if specified, this is the number of\n            examples per class to reserve for the final\n            mini-batch.\n          kwargs: kwargs for Reptile.\n        \"\"\"", "\n", "super", "(", "FOMLIS", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "train_shots", "=", "train_shots", "-", "tail_shots", "if", "tail_shots", "is", "not", "None", "else", "train_shots", "\n", "self", ".", "tail_shots", "=", "tail_shots", "\n", "self", ".", "sample_train_val_with_replacement", "=", "sample_train_val_with_replacement", "\n", "if", "sample_train_val_with_replacement", ":", "\n", "            ", "print", "(", "\"Sampling train val with replacement.\"", ")", "\n", "", "print", "(", "\"Specializing meta-learner to FOMAML.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.FOMLIS.train_step": [[605, 648], ["reptile.FOMLIS._model_state.export_variables", "range", "meta_learners.variables.average_vars", "reptile.FOMLIS._model_state.import_variables", "meta_learners.metaseg._sample_mini_image_segmentation_dataset", "reptile.FOMLIS._mini_batches", "enumerate", "updates.append", "reptile.FOMLIS._model_state.import_variables", "meta_learners.variables.add_vars", "print", "zip", "meta_learners.variables.subtract_vars", "meta_learners.variables.scale_vars", "print", "reptile.FOMLIS._model_state.export_variables", "reptile.FOMLIS.session.run", "reptile.FOMLIS.session.run", "reptile.FOMLIS.session.run", "reptile.FOMLIS._model_state.export_variables"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.VariableState.export_variables", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.average_vars", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.VariableState.import_variables", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg._sample_mini_image_segmentation_dataset", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.FOMLIS._mini_batches", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.VariableState.import_variables", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.add_vars", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.subtract_vars", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.scale_vars", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.VariableState.export_variables", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.VariableState.export_variables"], ["", "def", "train_step", "(", "self", ",", "\n", "dataset", ",", "\n", "input_ph", ",", "\n", "label_ph", ",", "\n", "minimize_op", ",", "\n", "num_classes", ",", "\n", "num_shots", ",", "\n", "inner_batch_size", ",", "\n", "inner_iters", ",", "\n", "replacement", ",", "\n", "meta_step_size", ",", "\n", "meta_batch_size", ",", "\n", "verbose", "=", "False", ",", "\n", "lr_ph", "=", "None", ",", "\n", "lr", "=", "None", ",", "\n", ")", ":", "\n", "        ", "old_vars", "=", "self", ".", "_model_state", ".", "export_variables", "(", ")", "\n", "updates", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "meta_batch_size", ")", ":", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "'Sampling new task.'", ")", "\n", "", "mini_dataset", "=", "_sample_mini_image_segmentation_dataset", "(", "self", ".", "session", ",", "dataset", ",", "num_classes", ",", "\n", "num_shots", ")", "\n", "mini_batches", "=", "self", ".", "_mini_batches", "(", "mini_dataset", ",", "inner_batch_size", ",", "inner_iters", ",", "\n", "replacement", ")", "\n", "\n", "for", "j", ",", "batch", "in", "enumerate", "(", "mini_batches", ")", ":", "\n", "                ", "if", "verbose", ":", "\n", "                    ", "print", "(", "'Sampling new mini_batch.'", ")", "\n", "", "inputs", ",", "labels", "=", "zip", "(", "*", "batch", ")", "\n", "if", "j", "==", "inner_iters", "-", "1", ":", "\n", "                    ", "last_backup", "=", "self", ".", "_model_state", ".", "export_variables", "(", ")", "\n", "", "if", "self", ".", "_pre_step_op", ":", "\n", "                    ", "self", ".", "session", ".", "run", "(", "self", ".", "_pre_step_op", ")", "\n", "", "if", "(", "lr_ph", "is", "not", "None", ")", "and", "(", "lr", "is", "not", "None", ")", ":", "\n", "                    ", "self", ".", "session", ".", "run", "(", "minimize_op", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", ",", "label_ph", ":", "labels", ",", "\n", "lr_ph", ":", "lr", "}", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "session", ".", "run", "(", "minimize_op", ",", "feed_dict", "=", "{", "input_ph", ":", "inputs", ",", "label_ph", ":", "labels", "}", ")", "\n", "", "", "updates", ".", "append", "(", "subtract_vars", "(", "self", ".", "_model_state", ".", "export_variables", "(", ")", ",", "last_backup", ")", ")", "\n", "self", ".", "_model_state", ".", "import_variables", "(", "old_vars", ")", "\n", "", "update", "=", "average_vars", "(", "updates", ")", "\n", "self", ".", "_model_state", ".", "import_variables", "(", "add_vars", "(", "old_vars", ",", "scale_vars", "(", "update", ",", "meta_step_size", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.FOMLIS._mini_batches": [[649, 664], ["meta_learners.metaseg._mini_batches", "meta_learners.metaseg._mini_batches", "meta_learners.metaseg._sample_train_test_segmentation_with_replacement", "meta_learners.metaseg._split_train_test_segmentation"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.FOMLIS._mini_batches", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.FOMLIS._mini_batches", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg._sample_train_test_segmentation_with_replacement", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.metaseg._split_train_test_segmentation"], ["", "def", "_mini_batches", "(", "self", ",", "mini_dataset", ",", "inner_batch_size", ",", "inner_iters", ",", "replacement", ")", ":", "\n", "        ", "\"\"\"\n        Generate inner-loop mini-batches for the task.\n        \"\"\"", "\n", "if", "self", ".", "tail_shots", "is", "None", ":", "\n", "            ", "for", "value", "in", "_mini_batches", "(", "mini_dataset", ",", "inner_batch_size", ",", "inner_iters", ",", "replacement", ",", "augmenter", "=", "self", ".", "augmenter", ",", "aug_rate", "=", "self", ".", "aug_rate", ")", ":", "\n", "                ", "yield", "value", "\n", "", "return", "\n", "", "if", "self", ".", "sample_train_val_with_replacement", ":", "\n", "            ", "train", ",", "tail", "=", "_sample_train_test_segmentation_with_replacement", "(", "mini_dataset", ",", "train_shots", "=", "self", ".", "train_shots", ",", "test_shots", "=", "self", ".", "tail_shots", ")", "\n", "", "else", ":", "\n", "            ", "train", ",", "tail", "=", "_split_train_test_segmentation", "(", "mini_dataset", ",", "test_shots", "=", "self", ".", "tail_shots", ")", "\n", "", "for", "batch", "in", "_mini_batches", "(", "train", ",", "inner_batch_size", ",", "inner_iters", "-", "1", ",", "replacement", ",", "augmenter", "=", "self", ".", "augmenter", ",", "aug_rate", "=", "self", ".", "aug_rate", ")", ":", "\n", "            ", "yield", "batch", "\n", "", "yield", "tail", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.measure": [[555, 563], ["numpy.logical_and().sum", "numpy.logical_and().sum", "numpy.logical_and().sum", "numpy.logical_and().sum", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.logical_not", "numpy.logical_not", "numpy.logical_not", "numpy.logical_not"], "function", ["None"], ["", "", "def", "measure", "(", "y_in", ",", "pred_in", ",", "thresh", ":", "float", "=", ".5", ")", ":", "\n", "    ", "y", "=", "y_in", ">", "thresh", "\n", "pred", "=", "pred_in", ">", "thresh", "\n", "tp", "=", "np", ".", "logical_and", "(", "y", ",", "pred", ")", ".", "sum", "(", ")", "\n", "tn", "=", "np", ".", "logical_and", "(", "np", ".", "logical_not", "(", "y", ")", ",", "np", ".", "logical_not", "(", "pred", ")", ")", ".", "sum", "(", ")", "\n", "fp", "=", "np", ".", "logical_and", "(", "np", ".", "logical_not", "(", "y", ")", ",", "pred", ")", ".", "sum", "(", ")", "\n", "fn", "=", "np", ".", "logical_and", "(", "y", ",", "np", ".", "logical_not", "(", "pred", ")", ")", ".", "sum", "(", ")", "\n", "return", "tp", ",", "tn", ",", "fp", ",", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.iou_img": [[565, 567], ["float", "max"], "function", ["None"], ["", "def", "iou_img", "(", "tp", ",", "fp", ",", "fn", ")", ":", "\n", "    ", "return", "tp", "/", "float", "(", "max", "(", "tp", "+", "fp", "+", "fn", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile._sample_mini_dataset": [[666, 678], ["list", "random.shuffle", "enumerate", "class_obj.sample"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character.sample"], ["", "", "def", "_sample_mini_dataset", "(", "dataset", ",", "num_classes", ",", "num_shots", ")", ":", "\n", "    ", "\"\"\"\n    Sample a few shot task from a dataset.\n\n    Returns:\n      An iterable of (input, label) pairs.\n    \"\"\"", "\n", "shuffled", "=", "list", "(", "dataset", ")", "\n", "random", ".", "shuffle", "(", "shuffled", ")", "\n", "for", "class_idx", ",", "class_obj", "in", "enumerate", "(", "shuffled", "[", ":", "num_classes", "]", ")", ":", "\n", "        ", "for", "sample", "in", "class_obj", ".", "sample", "(", "num_shots", ")", ":", "\n", "            ", "yield", "(", "sample", ",", "class_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile._split_train_test": [[680, 706], ["list", "set", "range", "len", "IndexError", "enumerate", "len", "test_set.append"], "function", ["None"], ["", "", "", "def", "_split_train_test", "(", "samples", ",", "test_shots", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    Split a few-shot task into a train and a test set.\n\n    Args:\n      samples: an iterable of (input, label) pairs.\n      test_shots: the number of examples per class in the\n        test set.\n\n    Returns:\n      A tuple (train, test), where train and test are\n        sequences of (input, label) pairs.\n    \"\"\"", "\n", "train_set", "=", "list", "(", "samples", ")", "\n", "test_set", "=", "[", "]", "\n", "labels", "=", "set", "(", "item", "[", "1", "]", "for", "item", "in", "train_set", ")", "\n", "for", "_", "in", "range", "(", "test_shots", ")", ":", "\n", "        ", "for", "label", "in", "labels", ":", "\n", "            ", "for", "i", ",", "item", "in", "enumerate", "(", "train_set", ")", ":", "\n", "                ", "if", "item", "[", "1", "]", "==", "label", ":", "\n", "                    ", "del", "train_set", "[", "i", "]", "\n", "test_set", ".", "append", "(", "item", ")", "\n", "break", "\n", "", "", "", "", "if", "len", "(", "test_set", ")", "<", "len", "(", "labels", ")", "*", "test_shots", ":", "\n", "        ", "raise", "IndexError", "(", "'not enough examples of each class for test set'", ")", "\n", "", "return", "train_set", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.eval.evaluate_gecko": [[18, 91], ["print", "print", "meta_fn", "range", "list", "utils.util.ci95", "numpy.nanmean", "print", "print", "numpy.nanmean", "print", "print", "print", "print", "print", "meta_learners.variables.weight_decay", "meta_fn.evaluate", "task_iou_map_i.items", "mean_ious.append", "itertools.chain", "len", "numpy.count_nonzero", "task_iou_map[].append", "task_iou_map.values", "numpy.isnan"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.ci95", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.weight_decay", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko.evaluate"], ["def", "evaluate_gecko", "(", "sess", ",", "\n", "model", ",", "\n", "dataset", ",", "\n", "num_classes", "=", "1", ",", "\n", "num_shots", "=", "5", ",", "\n", "eval_inner_batch_size", "=", "5", ",", "\n", "eval_inner_iters", "=", "50", ",", "\n", "replacement", "=", "False", ",", "\n", "num_samples", "=", "100", ",", "\n", "transductive", "=", "False", ",", "\n", "weight_decay_rate", "=", "1", ",", "\n", "meta_fn", "=", "Gecko", ",", "\n", "visualize_predicted_segmentations", "=", "True", ",", "\n", "save_fine_tuned_checkpoints", "=", "False", ",", "\n", "save_fine_tuned_checkpoints_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "lr_scheduler", "=", "None", ",", "\n", "lr", "=", "None", ",", "\n", "augment", "=", "False", ",", "\n", "serially_eval_all_tasks", ":", "bool", "=", "False", ",", "\n", "aug_rate", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", ")", "->", "Tuple", "[", "float", ",", "Dict", "[", "str", ",", "List", "[", "float", "]", "]", "]", ":", "\n", "    ", "\"\"\"\n    Evaluates an image segmentation model on a dataset.\n    \"\"\"", "\n", "print", "(", "\"Evaluating with eval_inner_iters: {}\"", ".", "format", "(", "eval_inner_iters", ")", ")", "\n", "print", "(", "\"Evaluating with lr: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "\n", "if", "save_fine_tuned_checkpoints", ":", "\n", "        ", "print", "(", "\"Saving fine-tuned checkpoints to {}\"", ".", "format", "(", "save_fine_tuned_checkpoints_dir", ")", ")", "\n", "", "if", "weight_decay_rate", "!=", "1", ":", "\n", "        ", "pre_step_op", "=", "weight_decay", "(", "weight_decay_rate", ")", "\n", "", "else", ":", "\n", "        ", "pre_step_op", "=", "None", "# no need to just multiply all vars by 1.", "\n", "", "gecko", "=", "meta_fn", "(", "sess", ",", "\n", "transductive", "=", "transductive", ",", "\n", "pre_step_op", "=", "pre_step_op", ",", "\n", "lr_scheduler", "=", "lr_scheduler", ",", "\n", "augment", "=", "augment", ",", "\n", "aug_rate", "=", "aug_rate", ")", "\n", "\n", "mean_ious", "=", "[", "]", "\n", "task_iou_map", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "num_samples", ")", ":", "\n", "        ", "mean_iou", ",", "task_iou_map_i", "=", "gecko", ".", "evaluate", "(", "dataset", ",", "model", ".", "input_ph", ",", "model", ".", "label_ph", ",", "\n", "model", ".", "minimize_op", ",", "model", ".", "predictions", ",", "\n", "num_classes", "=", "num_classes", ",", "num_shots", "=", "num_shots", ",", "\n", "inner_batch_size", "=", "eval_inner_batch_size", ",", "\n", "inner_iters", "=", "eval_inner_iters", ",", "replacement", "=", "replacement", ",", "\n", "eval_all_tasks", "=", "serially_eval_all_tasks", ",", "\n", "save_fine_tuned_checkpoints", "=", "save_fine_tuned_checkpoints", ",", "\n", "save_fine_tuned_checkpoints_dir", "=", "save_fine_tuned_checkpoints_dir", ",", "\n", "eval_sample_num", "=", "i", ",", "is_training_ph", "=", "model", ".", "is_training_ph", ",", "lr_ph", "=", "model", ".", "lr_ph", ",", "lr", "=", "lr", ",", ")", "\n", "for", "key", ",", "val", "in", "task_iou_map_i", ".", "items", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "task_iou_map", "[", "key", "]", ".", "append", "(", "val", ")", "\n", "", "except", "KeyError", ":", "\n", "                ", "task_iou_map", "[", "key", "]", "=", "[", "val", "]", "\n", "", "", "mean_ious", ".", "append", "(", "mean_iou", ")", "\n", "\n", "", "all_ious", "=", "list", "(", "itertools", ".", "chain", "(", "*", "task_iou_map", ".", "values", "(", ")", ")", ")", "\n", "ninety_five_perc_ci", "=", "ci95", "(", "all_ious", ")", "\n", "\n", "mean_of_all_task_splits", "=", "np", ".", "nanmean", "(", "all_ious", ")", "\n", "print", "(", "\"Mean of all {} task-splits: {} +/- 95% CI: {}\"", ".", "format", "(", "len", "(", "all_ious", ")", ",", "mean_of_all_task_splits", ",", "ninety_five_perc_ci", ")", ")", "\n", "\n", "print", "(", "\"{} NaN values out of total number of samples: {}\"", ".", "format", "(", "np", ".", "count_nonzero", "(", "np", ".", "isnan", "(", "mean_ious", ")", ")", ",", "num_samples", ")", ")", "\n", "mean_iou", "=", "np", ".", "nanmean", "(", "mean_ious", ")", "\n", "print", "(", "\"Mean of samples:\"", ")", "\n", "print", "(", "\"{} mean IoU, +/- 95% CI: {}\"", ".", "format", "(", "mean_iou", ",", "ninety_five_perc_ci", ")", ")", "\n", "print", "(", "\"Evaluated with eval_inner_iters: {}\"", ".", "format", "(", "eval_inner_iters", ")", ")", "\n", "print", "(", "\"Evaluated with lr: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "\n", "return", "mean_iou", ",", "task_iou_map", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.eval.optimize_update_hyperparams": [[93, 186], ["meta_fn", "os.path.splitext", "print", "meta_learners.variables.weight_decay", "print", "os.path.join", "meta_learners.hyperparam_search.lr_droprate_aug_rate_batch_size_gp_search", "ValueError"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.weight_decay", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.hyperparam_search.lr_droprate_aug_rate_batch_size_gp_search"], ["", "def", "optimize_update_hyperparams", "(", "sess", ",", "\n", "model", ",", "\n", "dataset", ",", "\n", "num_classes", "=", "1", ",", "\n", "num_shots", "=", "5", ",", "\n", "eval_inner_batch_size", "=", "5", ",", "\n", "eval_inner_iters", "=", "5", ",", "\n", "replacement", "=", "False", ",", "\n", "num_samples", "=", "100", ",", "\n", "transductive", "=", "False", ",", "\n", "weight_decay_rate", "=", "1", ",", "\n", "meta_fn", "=", "Gecko", ",", "\n", "save_fine_tuned_checkpoints", "=", "False", ",", "\n", "save_fine_tuned_checkpoints_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "lr_scheduler", "=", "None", ",", "\n", "lr", "=", "None", ",", "\n", "lr_search_range_low", ":", "float", "=", "0.0005", ",", "\n", "lr_search_range_high", ":", "float", "=", "0.05", ",", "\n", "drop_rate", "=", "None", ",", "\n", "drop_rate_search_range_low", ":", "float", "=", "0.1", ",", "\n", "drop_rate_search_range_high", ":", "float", "=", "0.8", ",", "\n", "aug_rate", ":", "float", "=", "0.5", ",", "\n", "aug_rate_search_range_low", ":", "float", "=", "0.5", ",", "\n", "aug_rate_search_range_high", ":", "float", "=", "0.5", ",", "\n", "batch_size_search_range_low", ":", "int", "=", "8", ",", "\n", "batch_size_search_range_high", ":", "int", "=", "8", ",", "\n", "augment", "=", "False", ",", "\n", "serially_eval_all_tasks", ":", "bool", "=", "True", ",", "\n", "min_steps", ":", "int", "=", "0", ",", "\n", "max_steps", ":", "int", "=", "80", ",", "\n", "num_configs_to_sample", "=", "100", ",", "\n", "num_train_val_data_splits_to_sample_per_config", "=", "1", ",", "\n", "save_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "# Dir in which to save results csv.", "\n", "results_csv_name", ":", "str", "=", "\"GP_val-set_hyper_param_search_results.csv\"", ",", "\n", "eval_tasks_with_median_early_stopping_iterations", ":", "bool", "=", "False", ",", "\n", "estimator", ":", "str", "=", "\"GP\"", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Evaluates an image segmentation model on a dataset.\n    \"\"\"", "\n", "supported_estimators", "=", "{", "\"GP\"", "}", "\n", "assert", "estimator", "in", "supported_estimators", "\n", "\n", "if", "save_fine_tuned_checkpoints", ":", "\n", "        ", "print", "(", "\"Saving fine-tuned checkpoints to {}\"", ".", "format", "(", "save_fine_tuned_checkpoints_dir", ")", ")", "\n", "", "if", "weight_decay_rate", "!=", "1", ":", "\n", "        ", "pre_step_op", "=", "weight_decay", "(", "weight_decay_rate", ")", "\n", "", "else", ":", "\n", "        ", "pre_step_op", "=", "None", "# no need to just multiply all vars by 1.", "\n", "", "gecko", "=", "meta_fn", "(", "sess", ",", "\n", "transductive", "=", "transductive", ",", "\n", "pre_step_op", "=", "pre_step_op", ",", "\n", "lr_scheduler", "=", "lr_scheduler", ",", "\n", "augment", "=", "augment", ")", "\n", "\n", "params", "=", "{", "\"dataset\"", ":", "dataset", ",", "\"input_ph\"", ":", "model", ".", "input_ph", ",", "\"label_ph\"", ":", "model", ".", "label_ph", ",", "\n", "\"minimize_op\"", ":", "model", ".", "minimize_op", ",", "\"predictions\"", ":", "model", ".", "predictions", ",", "\"num_classes\"", ":", "num_classes", ",", "\n", "\"num_shots\"", ":", "num_shots", ",", "\"inner_batch_size\"", ":", "eval_inner_batch_size", ",", "\n", "\"replacement\"", ":", "replacement", ",", "\"eval_all_tasks\"", ":", "serially_eval_all_tasks", ",", "\"is_training_ph\"", ":", "model", ".", "is_training_ph", ",", "# serially_eval_all_tasks", "\n", "\"lr_ph\"", ":", "model", ".", "lr_ph", ",", "LEARNING_RATE_NAME", ":", "lr", ",", "\"drop_rate_ph\"", ":", "model", ".", "final_layer_dropout_rate_ph", ",", "DROPOUT_RATE_NAME", ":", "drop_rate", ",", "AUG_RATE_NAME", ":", "aug_rate", ",", "\n", "\"eval_tasks_with_median_early_stopping_iterations\"", ":", "eval_tasks_with_median_early_stopping_iterations", ",", "\"min_steps\"", ":", "min_steps", ",", "\"max_steps\"", ":", "max_steps", ",", "\n", "}", "\n", "\n", "eval_fn", "=", "gecko", ".", "evaluate_with_early_stopping", "\n", "\n", "if", "eval_tasks_with_median_early_stopping_iterations", ":", "\n", "        ", "print", "(", "\"Evaluating val-set tasks with median iterations returned by early stopping.\"", ")", "\n", "\n", "", "before_ext", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "results_csv_name", ")", "\n", "before_ext", "+=", "\"_{}-shot\"", ".", "format", "(", "num_shots", ")", "\n", "results_csv_name", "=", "before_ext", "+", "ext", "\n", "if", "save_dir", "is", "not", "None", ":", "\n", "        ", "save_results_to", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "results_csv_name", ")", "\n", "", "else", ":", "\n", "        ", "save_results_to", "=", "results_csv_name", "\n", "\n", "", "if", "estimator", "==", "\"GP\"", ":", "\n", "        ", "best_lr", ",", "expected_best_step_num", "=", "lr_droprate_aug_rate_batch_size_gp_search", "(", "eval_fn", ",", "params", ",", "\n", "lr_search_range_low", "=", "lr_search_range_low", ",", "\n", "lr_search_range_high", "=", "lr_search_range_high", ",", "\n", "drop_rate_search_range_low", "=", "drop_rate_search_range_low", ",", "\n", "drop_rate_search_range_high", "=", "drop_rate_search_range_high", ",", "\n", "aug_rate_search_range_low", "=", "aug_rate_search_range_low", ",", "\n", "aug_rate_search_range_high", "=", "aug_rate_search_range_high", ",", "\n", "batch_size_search_range_low", "=", "batch_size_search_range_low", ",", "\n", "batch_size_search_range_high", "=", "batch_size_search_range_high", ",", "\n", "n", "=", "num_configs_to_sample", ",", "\n", "m", "=", "num_train_val_data_splits_to_sample_per_config", ",", "\n", "save_results_to", "=", "save_results_to", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unsupported hyperparameter optimizer estimator {}. `estimator` must be in {}\"", ".", "format", "(", "estimator", ",", "supported_estimators", ")", ")", "\n", "\n", "", "return", "best_lr", ",", "expected_best_step_num", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.eval.run_k_shot_learning_curves_experiment": [[190, 242], ["print", "print", "meta_fn", "meta_fn.evaluate_m_k_shot_ranges_all_tasks", "print", "print", "print", "print", "print", "pandas.DataFrame", "pd.DataFrame.to_csv", "meta_learners.variables.weight_decay", "os.path.isfile", "pd.DataFrame.to_csv", "pd.DataFrame.to_csv"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko.evaluate_m_k_shot_ranges_all_tasks", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.weight_decay"], ["def", "run_k_shot_learning_curves_experiment", "(", "sess", ",", "\n", "model", ",", "\n", "dataset", ",", "\n", "num_classes", "=", "1", ",", "\n", "num_shots", "=", "5", ",", "\n", "eval_inner_batch_size", "=", "8", ",", "\n", "eval_inner_iters", "=", "5", ",", "\n", "replacement", "=", "False", ",", "\n", "num_samples", "=", "100", ",", "\n", "transductive", "=", "True", ",", "\n", "weight_decay_rate", "=", "1", ",", "\n", "meta_fn", "=", "Gecko", ",", "\n", "lr_scheduler", "=", "None", ",", "\n", "lr", "=", "None", ",", "\n", "augment", "=", "True", ",", "\n", "aug_rate", ":", "float", "=", "0.5", ",", "\n", "csv_outpath", "=", "\"k-shot-results.csv\"", ",", "# None,", "\n", "iter_range", "=", "DEFAULT_ITER_RANGE", ",", "\n", ")", ":", "\n", "    ", "print", "(", "\"Running k-shot learning curves experiment over k-ranges {} and dataset {}\"", ".", "format", "(", "DEFAULT_K_RANGE", ",", "[", "x", ".", "name", "for", "x", "in", "dataset", "]", ")", ")", "\n", "if", "iter_range", "is", "None", ":", "\n", "        ", "iter_range", "=", "DEFAULT_ITER_RANGE", "\n", "", "print", "(", "\"Using iter range {}\"", ".", "format", "(", "iter_range", ")", ")", "\n", "\n", "gecko", "=", "meta_fn", "(", "sess", ",", "\n", "transductive", "=", "transductive", ",", "\n", "pre_step_op", "=", "weight_decay", "(", "weight_decay_rate", ")", ",", "\n", "lr_scheduler", "=", "lr_scheduler", ",", "\n", "augment", "=", "augment", ",", "\n", "aug_rate", "=", "aug_rate", ")", "\n", "\n", "ks", ",", "results", "=", "gecko", ".", "evaluate_m_k_shot_ranges_all_tasks", "(", "tasks", "=", "dataset", ",", "k_range", "=", "DEFAULT_K_RANGE", ",", "m", "=", "num_samples", ",", "input_ph", "=", "model", ".", "input_ph", ",", "\n", "label_ph", "=", "model", ".", "label_ph", ",", "minimize_op", "=", "model", ".", "minimize_op", ",", "predictions", "=", "model", ".", "predictions", ",", "\n", "inner_batch_size", "=", "eval_inner_batch_size", ",", "\n", "inner_iters", "=", "eval_inner_iters", ",", "replacement", "=", "replacement", ",", "is_training_ph", "=", "model", ".", "is_training_ph", ",", "\n", "lr_ph", "=", "model", ".", "lr_ph", ",", "lr", "=", "lr", ",", "test_samples", "=", "20", ",", "iter_range", "=", "iter_range", ",", "aug_rate", "=", "aug_rate", ")", "\n", "\n", "print", "(", "\"k-shot learning curve results:\"", ")", "\n", "print", "(", "\"ks:\"", ")", "\n", "print", "(", "ks", ")", "\n", "print", "(", "\"IoUs\"", ")", "\n", "print", "(", "results", ")", "\n", "\n", "if", "csv_outpath", "is", "not", "None", ":", "\n", "        ", "df", "=", "pd", ".", "DataFrame", "(", "{", "\"k\"", ":", "ks", ",", "\"mIoU\"", ":", "results", "}", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "csv_outpath", ")", ":", "\n", "            ", "df", ".", "to_csv", "(", "csv_outpath", ",", "index", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "df", ".", "to_csv", "(", "csv_outpath", ",", "mode", "=", "\"a\"", ",", "header", "=", "False", ")", "\n", "\n", "", "df", ".", "to_csv", "(", "csv_outpath", ",", "index", "=", "False", ")", "\n", "", "return", "ks", ",", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.train.train_gecko": [[18, 136], ["tensorflow.train.Saver", "meta_fn", "tensorflow.placeholder", "tensorflow.summary.scalar", "tensorflow.summary.merge_all", "tensorflow.summary.FileWriter", "tensorflow.summary.FileWriter", "range", "os.path.exists", "os.mkdir", "os.path.join", "tensorflow.train.Saver", "meta_learners.variables.weight_decay", "os.path.join", "os.path.join", "time.time", "print", "print", "print", "meta_fn.train_step", "utils.util.log_estimated_time_remaining", "os.path.exists", "os.mkdir", "print", "tensorflow.global_variables_initializer().run", "sess.run", "print", "print", "tensorflow.global_variables_initializer().run", "sess.run", "print", "log_fn", "print", "tf.train.Saver.save", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "meta_fn.evaluate", "sess.run", "writer.add_summary", "tensorflow.Summary", "writer.add_summary", "writer.flush", "mean_ious.append", "print", "print", "tf.train.Saver.save", "os.path.join", "time.time", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "os.path.join", "tensorflow.Summary.Value"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.mkdir", "home.repos.pwc.inspect_result.ml4ai_mliis.meta_learners.variables.weight_decay", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.FOMLIS.train_step", "home.repos.pwc.inspect_result.ml4ai_mliis.utils.util.log_estimated_time_remaining", "home.repos.pwc.inspect_result.ml4ai_mliis.data.fss_1000_image_to_tfrecord.mkdir", "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.reptile.Gecko.evaluate"], ["def", "train_gecko", "(", "sess", ",", "\n", "model", ",", "\n", "train_set", ",", "\n", "test_set", ",", "\n", "save_dir", ",", "\n", "num_classes", "=", "5", ",", "\n", "num_shots", "=", "5", ",", "\n", "inner_batch_size", "=", "5", ",", "\n", "inner_iters", "=", "20", ",", "\n", "replacement", "=", "False", ",", "\n", "meta_step_size", "=", "0.1", ",", "\n", "meta_step_size_final", "=", "0.1", ",", "\n", "meta_batch_size", "=", "1", ",", "\n", "meta_iters", "=", "10000", ",", "\n", "eval_inner_batch_size", "=", "5", ",", "\n", "eval_inner_iters", "=", "50", ",", "\n", "eval_interval", "=", "10", ",", "\n", "weight_decay_rate", "=", "1", ",", "\n", "time_deadline", "=", "None", ",", "\n", "train_shots", "=", "None", ",", "\n", "transductive", "=", "False", ",", "\n", "meta_fn", "=", "Gecko", ",", "\n", "log_fn", "=", "print", ",", "\n", "save_checkpoint_every_n_meta_iters", "=", "100", ",", "\n", "max_checkpoints_to_keep", "=", "2", ",", "\n", "augment", "=", "False", ",", "\n", "lr_scheduler", "=", "None", ",", "\n", "lr", "=", "None", ",", "\n", "save_best_seen", "=", "False", ",", "\n", "num_tasks_to_eval", "=", "100", ",", "\n", "aug_rate", ":", "Optional", "[", "float", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Train a model on a dataset.\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "save_dir", ")", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "max_checkpoints_to_keep", ")", "\n", "\n", "if", "save_best_seen", ":", "\n", "        ", "best_save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"best_eval\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "best_save_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "best_save_dir", ")", "\n", "", "best_saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "1", ")", "\n", "", "best_eval_iou", "=", "-", "np", ".", "inf", "\n", "\n", "if", "weight_decay_rate", "!=", "1", ":", "\n", "        ", "pre_step_op", "=", "weight_decay", "(", "weight_decay_rate", ")", "\n", "", "else", ":", "\n", "        ", "pre_step_op", "=", "None", "# no need to just multiply all vars by 1.", "\n", "", "reptile", "=", "meta_fn", "(", "sess", ",", "\n", "transductive", "=", "transductive", ",", "\n", "pre_step_op", "=", "pre_step_op", ",", "lr_scheduler", "=", "lr_scheduler", ",", "augment", "=", "augment", ",", "aug_rate", "=", "aug_rate", ")", "\n", "iou_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'IoU'", ",", "iou_ph", ")", "\n", "merged", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "train_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'train'", ")", ",", "sess", ".", "graph", ")", "\n", "test_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'test'", ")", ",", "sess", ".", "graph", ")", "\n", "try", ":", "\n", "        ", "if", "not", "model", ".", "variables_initialized", ":", "\n", "            ", "print", "(", "\"Initializing variables.\"", ")", "\n", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "", "", "except", "AttributeError", ":", "\n", "        ", "print", "(", "\"Model does not explicitly track whether variable initialization has already been run on the graph.\"", ")", "\n", "print", "(", "\"Initializing variables.\"", ")", "\n", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "\n", "", "for", "i", "in", "range", "(", "meta_iters", ")", ":", "\n", "        ", "begin_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'Reptile training step {} of {}'", ".", "format", "(", "i", "+", "1", ",", "meta_iters", ")", ")", "\n", "frac_done", "=", "i", "/", "meta_iters", "\n", "print", "(", "'{} done'", ".", "format", "(", "frac_done", ")", ")", "\n", "cur_meta_step_size", "=", "frac_done", "*", "meta_step_size_final", "+", "(", "1", "-", "frac_done", ")", "*", "meta_step_size", "\n", "print", "(", "\"Current meta-step size: {}\"", ".", "format", "(", "cur_meta_step_size", ")", ")", "\n", "reptile", ".", "train_step", "(", "train_set", ",", "model", ".", "input_ph", ",", "model", ".", "label_ph", ",", "model", ".", "minimize_op", ",", "\n", "num_classes", "=", "num_classes", ",", "num_shots", "=", "(", "train_shots", "or", "num_shots", ")", ",", "\n", "inner_batch_size", "=", "inner_batch_size", ",", "inner_iters", "=", "inner_iters", ",", "\n", "replacement", "=", "replacement", ",", "\n", "meta_step_size", "=", "cur_meta_step_size", ",", "meta_batch_size", "=", "meta_batch_size", ",", "lr_ph", "=", "model", ".", "lr_ph", ",", "lr", "=", "lr", ",", ")", "\n", "# call Gecko.evaluate to track progress:", "\n", "if", "i", "%", "eval_interval", "==", "0", ":", "\n", "            ", "print", "(", "'Evaluating training performance.'", ")", "\n", "# track accuracy with mean intersection over union:", "\n", "mean_ious", "=", "[", "]", "\n", "for", "dataset", ",", "writer", "in", "[", "(", "train_set", ",", "train_writer", ")", ",", "(", "test_set", ",", "test_writer", ")", "]", ":", "\n", "                ", "mean_iou", ",", "_", "=", "reptile", ".", "evaluate", "(", "dataset", ",", "model", ".", "input_ph", ",", "model", ".", "label_ph", ",", "\n", "model", ".", "minimize_op", ",", "model", ".", "predictions", ",", "\n", "num_classes", "=", "num_classes", ",", "num_shots", "=", "num_shots", ",", "\n", "inner_batch_size", "=", "eval_inner_batch_size", ",", "\n", "inner_iters", "=", "eval_inner_iters", ",", "replacement", "=", "replacement", ",", "\n", "eval_all_tasks", "=", "False", ",", "\n", "num_tasks_to_sample", "=", "num_tasks_to_eval", ",", "\n", "save_fine_tuned_checkpoints", "=", "False", ",", "is_training_ph", "=", "model", ".", "is_training_ph", ",", "\n", "lr_ph", "=", "model", ".", "lr_ph", ")", "\n", "summary", "=", "sess", ".", "run", "(", "merged", ",", "feed_dict", "=", "{", "iou_ph", ":", "mean_iou", "}", ")", "\n", "writer", ".", "add_summary", "(", "summary", ",", "i", ")", "\n", "# Log the learning rate:", "\n", "summary", "=", "tf", ".", "Summary", "(", "value", "=", "[", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "\"meta_step_size\"", ",", "simple_value", "=", "cur_meta_step_size", ")", "]", ")", "\n", "writer", ".", "add_summary", "(", "summary", ",", "i", ")", "\n", "writer", ".", "flush", "(", ")", "\n", "mean_ious", ".", "append", "(", "mean_iou", ")", "\n", "", "log_fn", "(", "'Train step %d: train=%f test=%f'", "%", "(", "i", ",", "mean_ious", "[", "0", "]", ",", "mean_ious", "[", "1", "]", ")", ")", "\n", "\n", "if", "save_best_seen", "and", "mean_ious", "[", "1", "]", ">", "best_eval_iou", ":", "\n", "                ", "best_eval_iou", "=", "mean_ious", "[", "1", "]", "\n", "print", "(", "\"Highest test-set evaluation IoU seen at step {}: {}\"", ".", "format", "(", "i", ",", "best_eval_iou", ")", ")", "\n", "print", "(", "\"Saving checkpoint to {}.\"", ".", "format", "(", "best_save_dir", ")", ")", "\n", "best_saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "best_save_dir", ",", "'model.ckpt'", ")", ",", "global_step", "=", "i", ")", "\n", "\n", "", "", "if", "i", "%", "save_checkpoint_every_n_meta_iters", "==", "0", "or", "i", "==", "meta_iters", "-", "1", ":", "# save checkpoint every n (should be 100) meta-iters and final meta-iter", "\n", "            ", "print", "(", "\"Saving checkpoint to {}.\"", ".", "format", "(", "save_dir", ")", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'model.ckpt'", ")", ",", "global_step", "=", "i", ")", "\n", "", "if", "time_deadline", "is", "not", "None", "and", "time", ".", "time", "(", ")", ">", "time_deadline", ":", "\n", "            ", "break", "\n", "", "log_estimated_time_remaining", "(", "begin_time", ",", "i", ",", "meta_iters", ")", "\n", "", "return", "reptile", "\n", "", ""]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.miniimagenet.ImageNetClass.__init__": [[41, 44], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dir_path", ")", ":", "\n", "        ", "self", ".", "dir_path", "=", "dir_path", "\n", "self", ".", "_cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.miniimagenet.ImageNetClass.sample": [[45, 59], ["random.shuffle", "images.append", "os.listdir", "f.endswith", "miniimagenet.ImageNetClass._read_image"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character._read_image"], ["", "def", "sample", "(", "self", ",", "num_images", ")", ":", "\n", "        ", "\"\"\"\n        Sample images (as numpy arrays) from the class.\n\n        Returns:\n          A sequence of 84x84x3 numpy arrays.\n          Each pixel ranges from 0 to 1.\n        \"\"\"", "\n", "names", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "self", ".", "dir_path", ")", "if", "f", ".", "endswith", "(", "'.JPEG'", ")", "]", "\n", "random", ".", "shuffle", "(", "names", ")", "\n", "images", "=", "[", "]", "\n", "for", "name", "in", "names", "[", ":", "num_images", "]", ":", "\n", "            ", "images", ".", "append", "(", "self", ".", "_read_image", "(", "name", ")", ")", "\n", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.miniimagenet.ImageNetClass._read_image": [[60, 67], ["open", "PIL.Image.open().resize().convert", "numpy.array", "miniimagenet.ImageNetClass._read_image", "miniimagenet.ImageNetClass._cache[].astype", "os.path.join", "PIL.Image.open().resize", "PIL.Image.open"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character._read_image"], ["", "def", "_read_image", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "name", "in", "self", ".", "_cache", ":", "\n", "            ", "return", "self", ".", "_cache", "[", "name", "]", ".", "astype", "(", "'float32'", ")", "/", "0xff", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "dir_path", ",", "name", ")", ",", "'rb'", ")", "as", "in_file", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "in_file", ")", ".", "resize", "(", "(", "84", ",", "84", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "self", ".", "_cache", "[", "name", "]", "=", "np", ".", "array", "(", "img", ")", "\n", "return", "self", ".", "_read_image", "(", "name", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.miniimagenet.read_dataset": [[16, 28], ["tuple", "miniimagenet._read_classes", "os.path.join"], "function", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.miniimagenet._read_classes"], ["def", "read_dataset", "(", "data_dir", ")", ":", "\n", "    ", "\"\"\"\n    Read the Mini-ImageNet dataset.\n\n    Args:\n      data_dir: directory containing Mini-ImageNet.\n\n    Returns:\n      A tuple (train, val, test) of sequences of\n        ImageNetClass instances.\n    \"\"\"", "\n", "return", "tuple", "(", "_read_classes", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "x", ")", ")", "for", "x", "in", "[", "'train'", ",", "'val'", ",", "'test'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.miniimagenet._read_classes": [[29, 35], ["miniimagenet.ImageNetClass", "os.path.join", "os.listdir", "f.startswith"], "function", ["None"], ["", "def", "_read_classes", "(", "dir_path", ")", ":", "\n", "    ", "\"\"\"\n    Read the WNID directories in a directory.\n    \"\"\"", "\n", "return", "[", "ImageNetClass", "(", "os", ".", "path", ".", "join", "(", "dir_path", ",", "f", ")", ")", "for", "f", "in", "os", ".", "listdir", "(", "dir_path", ")", "\n", "if", "f", ".", "startswith", "(", "'n'", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character.__init__": [[70, 74], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dir_path", ",", "rotation", "=", "0", ")", ":", "\n", "        ", "self", ".", "dir_path", "=", "dir_path", "\n", "self", ".", "rotation", "=", "rotation", "\n", "self", ".", "_cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character.sample": [[75, 89], ["random.shuffle", "images.append", "os.listdir", "f.endswith", "omniglot.Character._read_image", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character._read_image"], ["", "def", "sample", "(", "self", ",", "num_images", ")", ":", "\n", "        ", "\"\"\"\n        Sample images (as numpy arrays) from the class.\n\n        Returns:\n          A sequence of 28x28 numpy arrays.\n          Each pixel ranges from 0 to 1.\n        \"\"\"", "\n", "names", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "self", ".", "dir_path", ")", "if", "f", ".", "endswith", "(", "'.png'", ")", "]", "\n", "random", ".", "shuffle", "(", "names", ")", "\n", "images", "=", "[", "]", "\n", "for", "name", "in", "names", "[", ":", "num_images", "]", ":", "\n", "            ", "images", ".", "append", "(", "self", ".", "_read_image", "(", "os", ".", "path", ".", "join", "(", "self", ".", "dir_path", ",", "name", ")", ")", ")", "\n", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.Character._read_image": [[90, 97], ["open", "PIL.Image.open().resize().rotate", "numpy.array().astype", "PIL.Image.open().resize", "numpy.array", "PIL.Image.open"], "methods", ["None"], ["", "def", "_read_image", "(", "self", ",", "path", ")", ":", "\n", "        ", "if", "path", "in", "self", ".", "_cache", ":", "\n", "            ", "return", "self", ".", "_cache", "[", "path", "]", "\n", "", "with", "open", "(", "path", ",", "'rb'", ")", "as", "in_file", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "in_file", ")", ".", "resize", "(", "(", "28", ",", "28", ")", ")", ".", "rotate", "(", "self", ".", "rotation", ")", "\n", "self", ".", "_cache", "[", "path", "]", "=", "np", ".", "array", "(", "img", ")", ".", "astype", "(", "'float32'", ")", "\n", "return", "self", ".", "_cache", "[", "path", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.read_dataset": [[15, 36], ["sorted", "os.listdir", "os.path.join", "sorted", "os.path.isdir", "os.listdir", "char_name.startswith", "omniglot.Character", "os.path.join"], "function", ["None"], ["def", "read_dataset", "(", "data_dir", ")", ":", "\n", "    ", "\"\"\"\n    Iterate over the characters in a data directory.\n\n    Args:\n      data_dir: a directory of alphabet directories.\n\n    Returns:\n      An iterable over Characters.\n\n    The dataset is unaugmented and not split up into\n    training and test sets.\n    \"\"\"", "\n", "for", "alphabet_name", "in", "sorted", "(", "os", ".", "listdir", "(", "data_dir", ")", ")", ":", "\n", "        ", "alphabet_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "alphabet_name", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "alphabet_dir", ")", ":", "\n", "            ", "continue", "\n", "", "for", "char_name", "in", "sorted", "(", "os", ".", "listdir", "(", "alphabet_dir", ")", ")", ":", "\n", "            ", "if", "not", "char_name", ".", "startswith", "(", "'character'", ")", ":", "\n", "                ", "continue", "\n", "", "yield", "Character", "(", "os", ".", "path", ".", "join", "(", "alphabet_dir", ",", "char_name", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.split_dataset": [[37, 50], ["list", "random.shuffle"], "function", ["None"], ["", "", "", "def", "split_dataset", "(", "dataset", ",", "num_train", "=", "1200", ")", ":", "\n", "    ", "\"\"\"\n    Split the dataset into a training and test set.\n\n    Args:\n      dataset: an iterable of Characters.\n\n    Returns:\n      A tuple (train, test) of Character sequences.\n    \"\"\"", "\n", "all_data", "=", "list", "(", "dataset", ")", "\n", "random", ".", "shuffle", "(", "all_data", ")", "\n", "return", "all_data", "[", ":", "num_train", "]", ",", "all_data", "[", "num_train", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ml4ai_mliis.supervised_reptile.omniglot.augment_dataset": [[51, 64], ["omniglot.Character"], "function", ["None"], ["", "def", "augment_dataset", "(", "dataset", ")", ":", "\n", "    ", "\"\"\"\n    Augment the dataset by adding 90 degree rotations.\n\n    Args:\n      dataset: an iterable of Characters.\n\n    Returns:\n      An iterable of augmented Characters.\n    \"\"\"", "\n", "for", "character", "in", "dataset", ":", "\n", "        ", "for", "rotation", "in", "[", "0", ",", "90", ",", "180", ",", "270", "]", ":", "\n", "            ", "yield", "Character", "(", "character", ".", "dir_path", ",", "rotation", "=", "rotation", ")", "\n", "\n"]]}