{"home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.None.multiling_eval.show_topics": [[11, 15], ["enumerate", "print", "print"], "function", ["None"], ["def", "show_topics", "(", "topic_list", ")", ":", "\n", "    ", "for", "idx", ",", "topic_tokens", "in", "enumerate", "(", "topic_list", ")", ":", "\n", "        ", "print", "(", "idx", ")", "\n", "print", "(", "' '", ".", "join", "(", "topic_tokens", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.None.topic_inference.show_topics": [[8, 12], ["enumerate", "print", "print"], "function", ["None"], ["def", "show_topics", "(", "topic_list", ")", ":", "\n", "    ", "for", "idx", ",", "topic_tokens", "in", "enumerate", "(", "topic_list", ")", ":", "\n", "        ", "print", "(", "idx", ")", "\n", "print", "(", "' '", ".", "join", "(", "topic_tokens", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.None.perplexity.show_topics": [[10, 14], ["enumerate", "print", "print"], "function", ["None"], ["def", "show_topics", "(", "topic_list", ")", ":", "\n", "    ", "for", "idx", ",", "topic_tokens", "in", "enumerate", "(", "topic_list", ")", ":", "\n", "        ", "print", "(", "idx", ")", "\n", "print", "(", "' '", ".", "join", "(", "topic_tokens", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.None.model_topics._confirm_org": [[15, 21], ["tweet.keys"], "function", ["None"], ["def", "_confirm_org", "(", "tweet", ")", ":", "\n", "# ensure tweet is not a RT or QT", "\n", "    ", "if", "'retweeted_status'", "not", "in", "tweet", ".", "keys", "(", ")", "and", "tweet", "[", "'is_quote_status'", "]", "is", "False", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.None.model_topics.print_topics": [[22, 27], ["count_vectorizer.get_feature_names", "enumerate", "print", "print", "topic.argsort"], "function", ["None"], ["", "", "def", "print_topics", "(", "model", ",", "count_vectorizer", ",", "n_top_words", ")", ":", "\n", "    ", "words", "=", "count_vectorizer", ".", "get_feature_names", "(", ")", "\n", "for", "topic_idx", ",", "topic", "in", "enumerate", "(", "model", ".", "components_", ")", ":", "\n", "        ", "print", "(", "\"\\Topic #{}:\"", ".", "format", "(", "topic_idx", ")", ")", "\n", "print", "(", "\" \"", ".", "join", "(", "[", "words", "[", "i", "]", "for", "i", "in", "topic", ".", "argsort", "(", ")", "[", ":", "-", "n_top_words", "-", "1", ":", "-", "1", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.None.sample_docs_per_topic.load_topics": [[12, 18], ["open", "topic_list.append", "int", "topic.strip"], "function", ["None"], ["def", "load_topics", "(", "topic_file", ")", ":", "\n", "    ", "topic_list", "=", "[", "]", "\n", "with", "open", "(", "topic_file", ",", "'r'", ")", "as", "topics", ":", "\n", "        ", "for", "topic", "in", "topics", ":", "\n", "            ", "topic_list", ".", "append", "(", "int", "(", "topic", ".", "strip", "(", ")", ")", ")", "\n", "", "", "return", "topic_list", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.graphing.conf_mat.load_topics": [[10, 16], ["open", "topic_list.append", "int", "topic.strip"], "function", ["None"], ["def", "load_topics", "(", "topic_file", ")", ":", "\n", "    ", "topic_list", "=", "[", "]", "\n", "with", "open", "(", "topic_file", ",", "'r'", ")", "as", "topics", ":", "\n", "        ", "for", "topic", "in", "topics", ":", "\n", "            ", "topic_list", ".", "append", "(", "int", "(", "topic", ".", "strip", "(", ")", ")", ")", "\n", "", "", "return", "topic_list", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.graphing.hist.load_topics": [[10, 16], ["open", "topic_list.append", "int", "topic.strip"], "function", ["None"], ["def", "load_topics", "(", "topic_file", ")", ":", "\n", "    ", "topic_list", "=", "[", "]", "\n", "with", "open", "(", "topic_file", ",", "'r'", ")", "as", "topics", ":", "\n", "        ", "for", "topic", "in", "topics", ":", "\n", "            ", "topic_list", ".", "append", "(", "int", "(", "topic", ".", "strip", "(", ")", ")", ")", "\n", "", "", "return", "topic_list", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.graphing.scatter.load_topics": [[11, 17], ["open", "topic_list.append", "int", "topic.strip"], "function", ["None"], ["def", "load_topics", "(", "topic_file", ")", ":", "\n", "    ", "topic_list", "=", "[", "]", "\n", "with", "open", "(", "topic_file", ",", "'r'", ")", "as", "topics", ":", "\n", "        ", "for", "topic", "in", "topics", ":", "\n", "            ", "topic_list", ".", "append", "(", "int", "(", "topic", ".", "strip", "(", ")", ")", ")", "\n", "", "", "return", "topic_list", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.graphing.scatter.func": [[18, 21], ["numpy.log"], "function", ["None"], ["", "def", "func", "(", "x", ",", "a", ",", "b", ",", "c", ")", ":", "\n", "# return a * np.exp(-b * x) + c", "\n", "  ", "return", "a", "*", "np", ".", "log", "(", "b", "*", "x", ")", "+", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.tests.test_contextualized_topic_models.root_dir": [[19, 22], ["os.path.dirname", "os.path.abspath"], "function", ["None"], ["@", "pytest", ".", "fixture", "\n", "def", "root_dir", "(", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.tests.test_contextualized_topic_models.data_dir": [[23, 26], ["None"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "\n", "def", "data_dir", "(", "root_dir", ")", ":", "\n", "    ", "return", "root_dir", "+", "\"/../contextualized_topic_models/data/\"", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.tests.test_contextualized_topic_models.test_shape_checks": [[27, 36], ["contextualized_topic_models.utils.data_preparation.TextHandler", "contextualized_topic_models.utils.data_preparation.TextHandler.prepare", "open", "pickle.load", "len", "len", "contextualized_topic_models.utils.data_preparation.TextHandler.bow.todense"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.TextHandler.prepare", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.load"], ["", "def", "test_shape_checks", "(", "data_dir", ")", ":", "\n", "    ", "handler", "=", "TextHandler", "(", "data_dir", "+", "\"gnews/GoogleNews.txt\"", ")", "\n", "handler", ".", "prepare", "(", ")", "# create vocabulary and training data", "\n", "\n", "# load BERT data", "\n", "with", "open", "(", "data_dir", "+", "\"gnews/bert_embeddings_gnews\"", ",", "\"rb\"", ")", "as", "filino", ":", "\n", "        ", "training_bert", "=", "pickle", ".", "load", "(", "filino", ")", "\n", "\n", "", "assert", "len", "(", "training_bert", ")", "==", "len", "(", "handler", ".", "bow", ".", "todense", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.tests.test_contextualized_topic_models.test_training_with_saved_data": [[37, 55], ["contextualized_topic_models.utils.data_preparation.TextHandler", "contextualized_topic_models.utils.data_preparation.TextHandler.prepare", "contextualized_topic_models.datasets.dataset.CTMDataset", "contextualized_topic_models.models.ctm.CTM", "contextualized_topic_models.models.ctm.CTM.fit", "print", "contextualized_topic_models.models.ctm.CTM.get_thetas", "open", "pickle.load", "contextualized_topic_models.models.ctm.CTM.get_topics", "len"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.TextHandler.prepare", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.fit", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.get_thetas", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.load", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.get_topics"], ["", "def", "test_training_with_saved_data", "(", "data_dir", ")", ":", "\n", "    ", "handler", "=", "TextHandler", "(", "data_dir", "+", "\"gnews/GoogleNews.txt\"", ")", "\n", "handler", ".", "prepare", "(", ")", "# create vocabulary and training data", "\n", "\n", "# load BERT data", "\n", "with", "open", "(", "data_dir", "+", "\"gnews/bert_embeddings_gnews\"", ",", "\"rb\"", ")", "as", "filino", ":", "\n", "        ", "training_bert", "=", "pickle", ".", "load", "(", "filino", ")", "\n", "\n", "", "training_dataset", "=", "CTMDataset", "(", "handler", ".", "bow", ",", "training_bert", ",", "handler", ".", "idx2token", ")", "\n", "\n", "ctm", "=", "CTM", "(", "input_size", "=", "len", "(", "handler", ".", "vocab", ")", ",", "bert_input_size", "=", "768", ",", "num_epochs", "=", "1", ",", "inference_type", "=", "\"combined\"", ",", "\n", "n_components", "=", "5", ")", "\n", "\n", "ctm", ".", "fit", "(", "training_dataset", ")", "# run the model", "\n", "\n", "print", "(", "ctm", ".", "get_topics", "(", "2", ")", ")", "\n", "\n", "ctm", ".", "get_thetas", "(", "training_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.tests.test_contextualized_topic_models.test_embeddings_from_scratch": [[57, 69], ["contextualized_topic_models.utils.data_preparation.TextHandler", "contextualized_topic_models.utils.data_preparation.TextHandler.prepare", "numpy.array_equal", "contextualized_topic_models.utils.data_preparation.bert_embeddings_from_file", "contextualized_topic_models.utils.data_preparation.TextHandler.bow.todense", "numpy.array", "len", "len", "contextualized_topic_models.utils.data_preparation.TextHandler.bow.todense"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.TextHandler.prepare", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.bert_embeddings_from_file"], ["", "def", "test_embeddings_from_scratch", "(", "data_dir", ")", ":", "\n", "\n", "    ", "handler", "=", "TextHandler", "(", "data_dir", "+", "\"sample_text_document\"", ")", "\n", "handler", ".", "prepare", "(", ")", "# create vocabulary and training data", "\n", "\n", "assert", "np", ".", "array_equal", "(", "handler", ".", "bow", ".", "todense", "(", ")", ",", "np", ".", "array", "(", "[", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "0", ",", "1", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "2", "]", "]", ")", ")", "\n", "\n", "train_bert", "=", "bert_embeddings_from_file", "(", "data_dir", "+", "'sample_text_document'", ",", "\"distiluse-base-multilingual-cased\"", ")", "\n", "\n", "assert", "len", "(", "train_bert", ")", "==", "len", "(", "handler", ".", "bow", ".", "todense", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.tests.test_contextualized_topic_models.test_training": [[70, 87], ["contextualized_topic_models.utils.data_preparation.TextHandler", "contextualized_topic_models.utils.data_preparation.TextHandler.prepare", "contextualized_topic_models.utils.data_preparation.bert_embeddings_from_file", "contextualized_topic_models.datasets.dataset.CTMDataset", "contextualized_topic_models.models.ctm.CTM", "contextualized_topic_models.models.ctm.CTM.fit", "contextualized_topic_models.models.ctm.CTM.get_topic_lists", "contextualized_topic_models.models.ctm.CTM.get_thetas", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.TextHandler.prepare", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.bert_embeddings_from_file", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.fit", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.get_topic_lists", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.get_thetas"], ["", "def", "test_training", "(", "data_dir", ")", ":", "\n", "    ", "handler", "=", "TextHandler", "(", "data_dir", "+", "\"sample_text_document\"", ")", "\n", "handler", ".", "prepare", "(", ")", "# create vocabulary and training data", "\n", "\n", "train_bert", "=", "bert_embeddings_from_file", "(", "data_dir", "+", "'sample_text_document'", ",", "\n", "\"distiluse-base-multilingual-cased\"", ")", "\n", "\n", "training_dataset", "=", "CTMDataset", "(", "handler", ".", "bow", ",", "train_bert", ",", "handler", ".", "idx2token", ")", "\n", "\n", "ctm", "=", "CTM", "(", "input_size", "=", "len", "(", "handler", ".", "vocab", ")", ",", "bert_input_size", "=", "512", ",", "num_epochs", "=", "1", ",", "inference_type", "=", "\"combined\"", ",", "\n", "n_components", "=", "5", ")", "\n", "ctm", ".", "fit", "(", "training_dataset", ")", "# run the model", "\n", "topics", "=", "ctm", ".", "get_topic_lists", "(", "2", ")", "\n", "assert", "len", "(", "topics", ")", "==", "5", "\n", "\n", "thetas", "=", "ctm", ".", "get_thetas", "(", "training_dataset", ")", "\n", "assert", "len", "(", "thetas", ")", "==", "len", "(", "train_bert", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.tests.test_contextualized_topic_models.test_training_from_lists": [[89, 109], ["contextualized_topic_models.utils.data_preparation.TextHandler", "contextualized_topic_models.utils.data_preparation.TextHandler.prepare", "contextualized_topic_models.utils.data_preparation.bert_embeddings_from_list", "contextualized_topic_models.datasets.dataset.CTMDataset", "contextualized_topic_models.models.ctm.CTM", "contextualized_topic_models.models.ctm.CTM.fit", "contextualized_topic_models.models.ctm.CTM.get_topic_lists", "contextualized_topic_models.models.ctm.CTM.get_thetas", "open", "filino.readlines", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.TextHandler.prepare", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.bert_embeddings_from_list", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.fit", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.get_topic_lists", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.get_thetas"], ["", "def", "test_training_from_lists", "(", "data_dir", ")", ":", "\n", "\n", "    ", "with", "open", "(", "data_dir", "+", "'sample_text_document'", ")", "as", "filino", ":", "\n", "        ", "data", "=", "filino", ".", "readlines", "(", ")", "\n", "\n", "", "handler", "=", "TextHandler", "(", "sentences", "=", "data", ")", "\n", "handler", ".", "prepare", "(", ")", "# create vocabulary and training data", "\n", "\n", "train_bert", "=", "bert_embeddings_from_list", "(", "data", ",", "\"distiluse-base-multilingual-cased\"", ")", "\n", "training_dataset", "=", "CTMDataset", "(", "handler", ".", "bow", ",", "train_bert", ",", "handler", ".", "idx2token", ")", "\n", "\n", "ctm", "=", "CTM", "(", "input_size", "=", "len", "(", "handler", ".", "vocab", ")", ",", "bert_input_size", "=", "512", ",", "num_epochs", "=", "1", ",", "inference_type", "=", "\"combined\"", ",", "\n", "n_components", "=", "5", ")", "\n", "ctm", ".", "fit", "(", "training_dataset", ")", "# run the model", "\n", "topics", "=", "ctm", ".", "get_topic_lists", "(", "2", ")", "\n", "\n", "assert", "len", "(", "topics", ")", "==", "5", "\n", "thetas", "=", "ctm", ".", "get_thetas", "(", "training_dataset", ")", "\n", "\n", "assert", "len", "(", "thetas", ")", "==", "len", "(", "train_bert", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.tests.test_contextualized_topic_models.test_preprocessing": [[111, 120], ["contextualized_topic_models.utils.preprocessing.SimplePreprocessing", "contextualized_topic_models.utils.preprocessing.SimplePreprocessing.preprocess", "line.strip", "len", "len", "len", "len", "len", "open().readlines", "open"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.preprocessing.SimplePreprocessing.preprocess"], ["", "def", "test_preprocessing", "(", "data_dir", ")", ":", "\n", "    ", "docs", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "open", "(", "data_dir", "+", "\"gnews/GoogleNews.txt\"", ",", "'r'", ")", ".", "readlines", "(", ")", "]", "\n", "sp", "=", "SimplePreprocessing", "(", "docs", ")", "\n", "prep_corpus", ",", "unprepr_corpus", ",", "vocab", "=", "sp", ".", "preprocess", "(", ")", "\n", "\n", "assert", "len", "(", "prep_corpus", ")", "==", "len", "(", "unprepr_corpus", ")", "# prep docs must have the same size as the unprep docs", "\n", "assert", "len", "(", "prep_corpus", ")", "<=", "len", "(", "docs", ")", "# preprocessed docs must be less than or equal the original docs", "\n", "\n", "assert", "len", "(", "vocab", ")", "<=", "sp", ".", "vocabulary_size", "# check vocabulary size", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.topics.training_topic.sent_tokenize": [[27, 33], ["langcodes.Language().language_name().lower", "nltk.tokenize.sent_tokenize", "langcodes.Language().language_name", "nltk.tokenize.sent_tokenize", "langcodes.Language"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.topics.training_mldoc.sent_tokenize", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.topics.training_mldoc.sent_tokenize"], ["def", "sent_tokenize", "(", "text", ",", "lang", "=", "'en'", ")", ":", "\n", "    ", "lang", "=", "langcodes", ".", "Language", "(", "lang", ")", ".", "language_name", "(", ")", ".", "lower", "(", ")", "\n", "try", ":", "\n", "        ", "return", "nltk_sent_tokenize", "(", "text", ",", "language", "=", "lang", ")", "\n", "", "except", ":", "\n", "        ", "return", "nltk_sent_tokenize", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.topics.training_mldoc.sent_tokenize": [[27, 33], ["langcodes.Language().language_name().lower", "nltk.tokenize.sent_tokenize", "langcodes.Language().language_name", "nltk.tokenize.sent_tokenize", "langcodes.Language"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.topics.training_mldoc.sent_tokenize", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.topics.training_mldoc.sent_tokenize"], ["def", "sent_tokenize", "(", "text", ",", "lang", "=", "'en'", ")", ":", "\n", "    ", "lang", "=", "langcodes", ".", "Language", "(", "lang", ")", ".", "language_name", "(", ")", ".", "lower", "(", ")", "\n", "try", ":", "\n", "        ", "return", "nltk_sent_tokenize", "(", "text", ",", "language", "=", "lang", ")", "\n", "", "except", ":", "\n", "        ", "return", "nltk_sent_tokenize", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.TextHandler.__init__": [[47, 54], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "file_name", ")", ":", "\n", "        ", "self", ".", "file_name", "=", "file_name", "\n", "self", ".", "vocab_dict", "=", "{", "}", "\n", "self", ".", "vocab", "=", "[", "]", "\n", "self", ".", "index_dd", "=", "None", "\n", "self", ".", "idx2token", "=", "None", "\n", "self", ".", "bow", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.TextHandler.load_text_file": [[55, 65], ["open", "filino.readlines"], "methods", ["None"], ["", "def", "load_text_file", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Loads a text file\n        :param text_file:\n        :return:\n        \"\"\"", "\n", "with", "open", "(", "self", ".", "file_name", ",", "\"r\"", ")", "as", "filino", ":", "\n", "            ", "data", "=", "filino", ".", "readlines", "(", ")", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.TextHandler.prepare": [[66, 84], ["data_preparation.TextHandler.load_text_file", "concatenate_text.strip.strip.strip", "list", "list", "numpy.array", "data_preparation.get_bag_of_words", "line.strip.strip.strip", "set", "zip", "list", "len", "concatenate_text.strip.strip.split", "range", "map", "data_preparation.TextHandler.vocab_dict.items", "len", "numpy.array", "list", "map", "y.split"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.TextHandler.load_text_file", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.get_bag_of_words"], ["", "def", "prepare", "(", "self", ")", ":", "\n", "        ", "data", "=", "self", ".", "load_text_file", "(", ")", "\n", "\n", "concatenate_text", "=", "\"\"", "\n", "for", "line", "in", "data", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "concatenate_text", "+=", "line", "+", "\" \"", "\n", "", "concatenate_text", "=", "concatenate_text", ".", "strip", "(", ")", "\n", "\n", "self", ".", "vocab", "=", "list", "(", "set", "(", "concatenate_text", ".", "split", "(", ")", ")", ")", "\n", "\n", "for", "index", ",", "vocab", "in", "list", "(", "zip", "(", "range", "(", "0", ",", "len", "(", "self", ".", "vocab", ")", ")", ",", "self", ".", "vocab", ")", ")", ":", "\n", "            ", "self", ".", "vocab_dict", "[", "vocab", "]", "=", "index", "\n", "\n", "", "self", ".", "index_dd", "=", "np", ".", "array", "(", "list", "(", "map", "(", "lambda", "y", ":", "np", ".", "array", "(", "list", "(", "map", "(", "lambda", "x", ":", "\n", "self", ".", "vocab_dict", "[", "x", "]", ",", "y", ".", "split", "(", ")", ")", ")", ")", ",", "data", ")", ")", ")", "\n", "self", ".", "idx2token", "=", "{", "v", ":", "k", "for", "(", "k", ",", "v", ")", "in", "self", ".", "vocab_dict", ".", "items", "(", ")", "}", "\n", "self", ".", "bow", "=", "get_bag_of_words", "(", "self", ".", "index_dd", ",", "len", "(", "self", ".", "vocab", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.get_bag_of_words": [[7, 12], ["numpy.array", "numpy.bincount", "x[].astype", "numpy.sum", "numpy.array", "numpy.array"], "function", ["None"], ["def", "get_bag_of_words", "(", "data", ",", "min_length", ")", ":", "\n", "\n", "    ", "vect", "=", "[", "np", ".", "bincount", "(", "x", "[", "x", "!=", "np", ".", "array", "(", "None", ")", "]", ".", "astype", "(", "'int'", ")", ",", "minlength", "=", "min_length", ")", "\n", "for", "x", "in", "data", "if", "np", ".", "sum", "(", "x", "[", "x", "!=", "np", ".", "array", "(", "None", ")", "]", ")", "!=", "0", "]", "\n", "return", "np", ".", "array", "(", "vect", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.bert_embeddings_from_file": [[14, 21], ["sentence_transformers.SentenceTransformer", "numpy.array", "open", "list", "sentence_transformers.SentenceTransformer.encode", "map", "filino.readlines"], "function", ["None"], ["", "def", "bert_embeddings_from_file", "(", "text_file", ",", "sbert_model_to_load", ")", ":", "\n", "    ", "model", "=", "SentenceTransformer", "(", "sbert_model_to_load", ")", "\n", "\n", "with", "open", "(", "text_file", ",", "encoding", "=", "\"latin\"", ")", "as", "filino", ":", "\n", "        ", "train_text", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", ",", "filino", ".", "readlines", "(", ")", ")", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "model", ".", "encode", "(", "train_text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.bert_embeddings_from_list": [[23, 26], ["sentence_transformers.SentenceTransformer", "numpy.array", "sentence_transformers.SentenceTransformer.encode"], "function", ["None"], ["", "def", "bert_embeddings_from_list", "(", "texts", ",", "sbert_model_to_load", ")", ":", "\n", "    ", "model", "=", "SentenceTransformer", "(", "sbert_model_to_load", ")", "\n", "return", "np", ".", "array", "(", "model", ".", "encode", "(", "texts", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.data_preparation.labels_from_file": [[27, 43], ["os.path.isfile", "open", "json.loads", "labels.append", "topic_to_int.keys"], "function", ["None"], ["", "def", "labels_from_file", "(", "json_file", ")", ":", "\n", "    ", "assert", "os", ".", "path", ".", "isfile", "(", "json_file", ")", "\n", "\n", "topic_to_int", "=", "{", "}", "\n", "labels", "=", "[", "]", "\n", "num_labels", "=", "0", "\n", "with", "open", "(", "json_file", ",", "'r'", ")", "as", "json_lines", ":", "\n", "        ", "for", "json_str", "in", "json_lines", ":", "\n", "            ", "json_obj", "=", "json", ".", "loads", "(", "json_str", ")", "\n", "this_label", "=", "json_obj", "[", "'label'", "]", "\n", "if", "this_label", "not", "in", "topic_to_int", ".", "keys", "(", ")", ":", "\n", "                ", "topic_to_int", "[", "this_label", "]", "=", "num_labels", "\n", "num_labels", "+=", "1", "\n", "", "labels", ".", "append", "(", "topic_to_int", "[", "this_label", "]", ")", "\n", "\n", "", "", "return", "labels", ",", "num_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.preprocessing.SimplePreprocessing.__init__": [[10, 20], ["set", "nltk.corpus.stopwords.words"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "documents", ",", "stopwords_language", "=", "'english'", ",", "vocabulary_size", "=", "2000", ")", ":", "\n", "        ", "\"\"\"\n\n        :param documents:\n        :param stopwords_language:\n        :param vocabulary_size: the number of most frequent words to include in the documents. Infrequent words will be discarded from the list of preprocessed documents\n        \"\"\"", "\n", "self", ".", "documents", "=", "documents", "\n", "self", ".", "stopwords", "=", "set", "(", "stop_words", ".", "words", "(", "stopwords_language", ")", ")", "\n", "self", ".", "vocabulary_size", "=", "vocabulary_size", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.utils.preprocessing.SimplePreprocessing.preprocess": [[21, 48], ["sklearn.feature_extraction.text.CountVectorizer", "sklearn.feature_extraction.text.CountVectorizer.fit_transform", "set", "enumerate", "doc.lower", "doc.translate", "sklearn.feature_extraction.text.CountVectorizer.get_feature_names", "list", "str.maketrans", "len", "preprocessed_docs.append", "unpreprocessed_docs.append", "len", "doc.split", "doc.split", "len"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Note that if after filtering some documents do not contain words we remove them. That is why we return also the\n        list of unpreprocessed documents.\n\n        :return: preprocessed documents, unpreprocessed documents and the vocabulary list\n        \"\"\"", "\n", "preprocessed_docs_tmp", "=", "self", ".", "documents", "\n", "preprocessed_docs_tmp", "=", "[", "doc", ".", "lower", "(", ")", "for", "doc", "in", "preprocessed_docs_tmp", "]", "\n", "preprocessed_docs_tmp", "=", "[", "doc", ".", "translate", "(", "\n", "str", ".", "maketrans", "(", "string", ".", "punctuation", ",", "' '", "*", "len", "(", "string", ".", "punctuation", ")", ")", ")", "for", "doc", "in", "preprocessed_docs_tmp", "]", "\n", "preprocessed_docs_tmp", "=", "[", "' '", ".", "join", "(", "[", "w", "for", "w", "in", "doc", ".", "split", "(", ")", "if", "len", "(", "w", ")", ">", "0", "and", "w", "not", "in", "self", ".", "stopwords", "]", ")", "\n", "for", "doc", "in", "preprocessed_docs_tmp", "]", "\n", "\n", "vectorizer", "=", "CountVectorizer", "(", "max_features", "=", "self", ".", "vocabulary_size", ",", "token_pattern", "=", "r'\\b[a-zA-Z]{2,}\\b'", ")", "\n", "vectorizer", ".", "fit_transform", "(", "preprocessed_docs_tmp", ")", "\n", "vocabulary", "=", "set", "(", "vectorizer", ".", "get_feature_names", "(", ")", ")", "\n", "preprocessed_docs_tmp", "=", "[", "' '", ".", "join", "(", "[", "w", "for", "w", "in", "doc", ".", "split", "(", ")", "if", "w", "in", "vocabulary", "]", ")", "\n", "for", "doc", "in", "preprocessed_docs_tmp", "]", "\n", "\n", "preprocessed_docs", ",", "unpreprocessed_docs", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "doc", "in", "enumerate", "(", "preprocessed_docs_tmp", ")", ":", "\n", "            ", "if", "len", "(", "doc", ")", ">", "0", ":", "\n", "                ", "preprocessed_docs", ".", "append", "(", "doc", ")", "\n", "unpreprocessed_docs", ".", "append", "(", "self", ".", "documents", "[", "i", "]", ")", "\n", "\n", "", "", "return", "preprocessed_docs", ",", "unpreprocessed_docs", ",", "list", "(", "vocabulary", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.datasets.dataset.CTMDataset.__init__": [[10, 23], ["len", "len", "Exception"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "X", ",", "X_bert", ",", "idx2token", ")", ":", "\n", "        ", "\"\"\"\n        Args\n            X : array-like, shape=(n_samples, n_features)\n                Document word matrix.\n        \"\"\"", "\n", "if", "len", "(", "X", ")", "!=", "len", "(", "X_bert", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"Wait! BoW and Contextual Embeddings have different sizes! \"", "\n", "\"You might want to check if the BoW preparation method has removed some documents. \"", ")", "\n", "\n", "", "self", ".", "X", "=", "X", "\n", "self", ".", "X_bert", "=", "X_bert", "\n", "self", ".", "idx2token", "=", "idx2token", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.datasets.dataset.CTMDataset.__len__": [[24, 27], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return length of dataset.\"\"\"", "\n", "return", "len", "(", "self", ".", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.datasets.dataset.CTMDataset.__getitem__": [[28, 34], ["torch.FloatTensor", "torch.FloatTensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "\"\"\"Return sample from dataset at index i.\"\"\"", "\n", "X", "=", "torch", ".", "FloatTensor", "(", "self", ".", "X", "[", "i", "]", ")", "\n", "X_bert", "=", "torch", ".", "FloatTensor", "(", "self", ".", "X_bert", "[", "i", "]", ")", "\n", "\n", "return", "{", "'X'", ":", "X", ",", "'X_bert'", ":", "X_bert", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.datasets.dataset.CTMDatasetTopReg.__init__": [[40, 56], ["len", "len", "Exception", "len", "len", "Exception"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "X", ",", "X_bert", ",", "idx2token", ",", "labels", ")", ":", "\n", "        ", "\"\"\"\n        Args\n            X : array-like, shape=(n_samples, n_features)\n                Document word matrix.\n        \"\"\"", "\n", "if", "len", "(", "X", ")", "!=", "len", "(", "X_bert", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"Wait! BoW and Contextual Embeddings have different sizes! \"", "\n", "\"You might want to check if the BoW preparation method has removed some documents. \"", ")", "\n", "", "if", "len", "(", "X", ")", "!=", "len", "(", "labels", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"Text and labels have different sizes!\"", ")", "\n", "\n", "", "self", ".", "X", "=", "X", "\n", "self", ".", "X_bert", "=", "X_bert", "\n", "self", ".", "idx2token", "=", "idx2token", "\n", "self", ".", "labels", "=", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.datasets.dataset.CTMDatasetTopReg.__len__": [[57, 60], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return length of dataset.\"\"\"", "\n", "return", "len", "(", "self", ".", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.datasets.dataset.CTMDatasetTopReg.__getitem__": [[61, 68], ["torch.FloatTensor", "torch.FloatTensor", "torch.LongTensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "\"\"\"Return sample from dataset at index i.\"\"\"", "\n", "X", "=", "torch", ".", "FloatTensor", "(", "self", ".", "X", "[", "i", "]", ")", "\n", "X_bert", "=", "torch", ".", "FloatTensor", "(", "self", ".", "X_bert", "[", "i", "]", ")", "\n", "label", "=", "torch", ".", "LongTensor", "(", "[", "self", ".", "labels", "[", "i", "]", "]", ")", "\n", "\n", "return", "{", "'X'", ":", "X", ",", "'X_bert'", ":", "X_bert", ",", "'label'", ":", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.__init__": [[22, 125], ["multiprocessing.cpu_count", "isinstance", "isinstance", "isinstance", "contextualized_topic_models.networks.decoding_network.DecoderNetwork", "float", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.optim.lr_scheduler.ReduceLROnPlateau", "ctm.CTM.model.cuda", "ctm.CTM.model.parameters", "torch.optim.SGD", "torch.optim.SGD", "ctm.CTM.model.parameters"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_size", ",", "bert_input_size", ",", "inference_type", ",", "n_components", "=", "10", ",", "model_type", "=", "'prodLDA'", ",", "\n", "hidden_sizes", "=", "(", "100", ",", "100", ")", ",", "activation", "=", "'softplus'", ",", "dropout", "=", "0.2", ",", "\n", "learn_priors", "=", "True", ",", "batch_size", "=", "64", ",", "lr", "=", "2e-3", ",", "momentum", "=", "0.99", ",", "\n", "solver", "=", "'adam'", ",", "num_epochs", "=", "100", ",", "reduce_on_plateau", "=", "False", ",", "nb_labels", "=", "None", ",", "nll_lambda", "=", "1.0", ",", "\n", "num_data_loader_workers", "=", "mp", ".", "cpu_count", "(", ")", ")", ":", "\n", "        ", "\"\"\"\n        Initialize CTM model.\n\n        Args\n            input_size : int, dimension of input\n            n_components : int, number of topic components, (default 10)\n            model_type : string, 'prodLDA' or 'LDA' (default 'prodLDA')\n            hidden_sizes : tuple, length = n_layers, (default (100, 100))\n            activation : string, 'softplus', 'relu', (default 'softplus')\n            dropout : float, dropout to use (default 0.2)\n            learn_priors : bool, make priors a learnable parameter (default True)\n            batch_size : int, size of batch to use for training (default 64)\n            lr : float, learning rate to use for training (default 2e-3)\n            momentum : float, momentum to use for training (default 0.99)\n            solver : string, optimizer 'adam' or 'sgd' (default 'adam')\n            num_epochs : int, number of epochs to train for, (default 100)\n            reduce_on_plateau : bool, reduce learning rate by 10x on plateau of 10 epochs (default False)\n            num_data_loader_workers : int, number of data loader workers (default cpu_count). set it to 0 if you are\n            using Windows\n        \"\"\"", "\n", "assert", "isinstance", "(", "input_size", ",", "int", ")", "and", "input_size", ">", "0", ",", "\"input_size must by type int > 0.\"", "\n", "assert", "isinstance", "(", "n_components", ",", "int", ")", "and", "input_size", ">", "0", ",", "\"n_components must by type int > 0.\"", "\n", "assert", "model_type", "in", "[", "'LDA'", ",", "'prodLDA'", "]", ",", "\"model must be 'LDA' or 'prodLDA'.\"", "\n", "assert", "isinstance", "(", "hidden_sizes", ",", "tuple", ")", ",", "\"hidden_sizes must be type tuple.\"", "\n", "assert", "activation", "in", "[", "'softplus'", ",", "'relu'", "]", ",", "\"activation must be 'softplus' or 'relu'.\"", "\n", "assert", "dropout", ">=", "0", ",", "\"dropout must be >= 0.\"", "\n", "assert", "isinstance", "(", "learn_priors", ",", "bool", ")", ",", "\"learn_priors must be boolean.\"", "\n", "assert", "isinstance", "(", "batch_size", ",", "int", ")", "and", "batch_size", ">", "0", ",", "\"batch_size must be int > 0.\"", "\n", "assert", "lr", ">", "0", ",", "\"lr must be > 0.\"", "\n", "assert", "isinstance", "(", "momentum", ",", "float", ")", "and", "momentum", ">", "0", "and", "momentum", "<=", "1", ",", "\"momentum must be 0 < float <= 1.\"", "\n", "assert", "solver", "in", "[", "'adam'", ",", "'sgd'", "]", ",", "\"solver must be 'adam' or 'sgd'.\"", "\n", "assert", "isinstance", "(", "reduce_on_plateau", ",", "bool", ")", ",", "\"reduce_on_plateau must be type bool.\"", "\n", "assert", "isinstance", "(", "num_data_loader_workers", ",", "int", ")", "and", "num_data_loader_workers", ">=", "0", ",", "\"num_data_loader_workers must by type int >= 0. set 0 if you are using windows\"", "\n", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "n_components", "=", "n_components", "\n", "self", ".", "model_type", "=", "model_type", "\n", "self", ".", "hidden_sizes", "=", "hidden_sizes", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "learn_priors", "=", "learn_priors", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "bert_size", "=", "bert_input_size", "\n", "self", ".", "momentum", "=", "momentum", "\n", "self", ".", "solver", "=", "solver", "\n", "self", ".", "num_epochs", "=", "num_epochs", "\n", "self", ".", "reduce_on_plateau", "=", "reduce_on_plateau", "\n", "self", ".", "nb_labels", "=", "nb_labels", "\n", "self", ".", "nll_lambda", "=", "nll_lambda", "\n", "self", ".", "num_data_loader_workers", "=", "num_data_loader_workers", "\n", "\n", "# init inference avitm network", "\n", "self", ".", "model", "=", "DecoderNetwork", "(", "\n", "input_size", ",", "self", ".", "bert_size", ",", "inference_type", ",", "n_components", ",", "model_type", ",", "hidden_sizes", ",", "activation", ",", "\n", "dropout", ",", "learn_priors", ",", "nb_labels", "=", "self", ".", "nb_labels", ")", "\n", "\n", "# init optimizer", "\n", "if", "self", ".", "solver", "==", "'adam'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "betas", "=", "(", "self", ".", "momentum", ",", "0.99", ")", ")", "\n", "", "elif", "self", ".", "solver", "==", "'sgd'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "SGD", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "momentum", "=", "self", ".", "momentum", ")", "\n", "\n", "# init lr scheduler", "\n", "", "if", "self", ".", "reduce_on_plateau", ":", "\n", "            ", "self", ".", "scheduler", "=", "ReduceLROnPlateau", "(", "self", ".", "optimizer", ",", "patience", "=", "10", ")", "\n", "\n", "# performance attributes", "\n", "", "self", ".", "best_loss_train", "=", "float", "(", "'inf'", ")", "\n", "\n", "# training atributes", "\n", "self", ".", "model_dir", "=", "None", "\n", "self", ".", "train_data", "=", "None", "\n", "self", ".", "nn_epoch", "=", "None", "\n", "\n", "# learned topics", "\n", "self", ".", "best_components", "=", "None", "\n", "\n", "# Use cuda if available", "\n", "# TODO: set manually to cpu", "\n", "#if torch.cuda.is_available():", "\n", "#    self.USE_CUDA = True", "\n", "#else:", "\n", "self", ".", "USE_CUDA", "=", "False", "\n", "\n", "if", "self", ".", "USE_CUDA", ":", "\n", "            ", "self", ".", "model", "=", "self", ".", "model", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM._loss": [[126, 154], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "loss.sum", "prior_variance.log().sum", "posterior_log_variance.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.nll_loss", "torch.nll_loss", "loss.sum", "doc_log_probs.view", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "prior_variance.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["None"], ["", "", "def", "_loss", "(", "self", ",", "inputs", ",", "word_dists", ",", "prior_mean", ",", "prior_variance", ",", "\n", "posterior_mean", ",", "posterior_variance", ",", "posterior_log_variance", ",", "doc_log_probs", ",", "labels", ")", ":", "\n", "\n", "# KL term", "\n", "# var division term", "\n", "        ", "var_division", "=", "torch", ".", "sum", "(", "posterior_variance", "/", "prior_variance", ",", "dim", "=", "1", ")", "\n", "# diff means term", "\n", "diff_means", "=", "prior_mean", "-", "posterior_mean", "\n", "diff_term", "=", "torch", ".", "sum", "(", "\n", "(", "diff_means", "*", "diff_means", ")", "/", "prior_variance", ",", "dim", "=", "1", ")", "\n", "# logvar det division term", "\n", "logvar_det_division", "=", "prior_variance", ".", "log", "(", ")", ".", "sum", "(", ")", "-", "posterior_log_variance", ".", "sum", "(", "dim", "=", "1", ")", "\n", "# combine terms", "\n", "KL", "=", "0.5", "*", "(", "\n", "var_division", "+", "diff_term", "-", "self", ".", "n_components", "+", "logvar_det_division", ")", "\n", "\n", "# Reconstruction term", "\n", "RL", "=", "-", "torch", ".", "sum", "(", "inputs", "*", "torch", ".", "log", "(", "word_dists", "+", "1e-10", ")", ",", "dim", "=", "1", ")", "\n", "\n", "if", "doc_log_probs", "is", "not", "None", ":", "\n", "            ", "NLL", "=", "F", ".", "nll_loss", "(", "doc_log_probs", ".", "view", "(", "-", "1", ",", "self", ".", "nb_labels", ")", ",", "torch", ".", "squeeze", "(", "labels", ")", ")", "\n", "loss", "=", "KL", "+", "RL", "+", "(", "self", ".", "nll_lambda", "*", "NLL", ")", "\n", "return", "loss", ".", "sum", "(", ")", "\n", "\n", "", "loss", "=", "KL", "+", "RL", "\n", "\n", "return", "loss", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM._train_epoch": [[155, 194], ["ctm.CTM.model.train", "ctm.CTM.model.zero_grad", "ctm.CTM.model", "ctm.CTM._loss", "ctm.CTM.backward", "ctm.CTM.optimizer.step", "ctm.CTM.item", "X.cuda.cuda.cuda", "X_bert.cuda.cuda.cuda", "X.cuda.cuda.size"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM._loss"], ["", "def", "_train_epoch", "(", "self", ",", "loader", ")", ":", "\n", "        ", "\"\"\"Train epoch.\"\"\"", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "train_loss", "=", "0", "\n", "samples_processed", "=", "0", "\n", "\n", "for", "batch_samples", "in", "loader", ":", "\n", "# batch_size x vocab_size", "\n", "            ", "X", "=", "batch_samples", "[", "'X'", "]", "\n", "X_bert", "=", "batch_samples", "[", "'X_bert'", "]", "\n", "if", "self", ".", "nb_labels", "is", "not", "None", ":", "\n", "                ", "labels", "=", "batch_samples", "[", "'label'", "]", "\n", "", "else", ":", "\n", "                ", "labels", "=", "None", "\n", "\n", "", "if", "self", ".", "USE_CUDA", ":", "\n", "                ", "X", "=", "X", ".", "cuda", "(", ")", "\n", "X_bert", "=", "X_bert", ".", "cuda", "(", ")", "\n", "\n", "# forward pass", "\n", "", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "prior_mean", ",", "prior_variance", ",", "posterior_mean", ",", "posterior_variance", ",", "posterior_log_variance", ",", "word_dists", ",", "doc_log_probs", "=", "self", ".", "model", "(", "X", ",", "X_bert", ")", "\n", "\n", "# backward pass", "\n", "loss", "=", "self", ".", "_loss", "(", "\n", "X", ",", "word_dists", ",", "prior_mean", ",", "prior_variance", ",", "\n", "posterior_mean", ",", "posterior_variance", ",", "posterior_log_variance", ",", "doc_log_probs", ",", "labels", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# compute train loss", "\n", "samples_processed", "+=", "X", ".", "size", "(", ")", "[", "0", "]", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "", "train_loss", "/=", "samples_processed", "\n", "\n", "return", "samples_processed", ",", "train_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.fit": [[195, 255], ["print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "datetime.datetime.now", "ctm.CTM._train_epoch", "datetime.datetime.now", "print", "ctm.CTM.save", "len"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM._train_epoch", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.save"], ["", "def", "fit", "(", "self", ",", "train_dataset", ",", "save_dir", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Train the AVITM model.\n\n        Args\n            train_dataset : PyTorch Dataset classs for training data.\n            val_dataset : PyTorch Dataset classs for validation data.\n            save_dir : directory to save checkpoint models to.\n        \"\"\"", "\n", "# Print settings to output file", "\n", "print", "(", "\"Settings: \\n\\\n               N Components: {}\\n\\\n               Topic Prior Mean: {}\\n\\\n               Topic Prior Variance: {}\\n\\\n               Model Type: {}\\n\\\n               Hidden Sizes: {}\\n\\\n               Activation: {}\\n\\\n               Dropout: {}\\n\\\n               Learn Priors: {}\\n\\\n               Learning Rate: {}\\n\\\n               Momentum: {}\\n\\\n               Reduce On Plateau: {}\\n\\\n               Save Dir: {}\"", ".", "format", "(", "\n", "self", ".", "n_components", ",", "0.0", ",", "\n", "1.", "-", "(", "1.", "/", "self", ".", "n_components", ")", ",", "self", ".", "model_type", ",", "\n", "self", ".", "hidden_sizes", ",", "self", ".", "activation", ",", "self", ".", "dropout", ",", "self", ".", "learn_priors", ",", "\n", "self", ".", "lr", ",", "self", ".", "momentum", ",", "self", ".", "reduce_on_plateau", ",", "save_dir", ")", ")", "\n", "\n", "self", ".", "model_dir", "=", "save_dir", "\n", "self", ".", "train_data", "=", "train_dataset", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "self", ".", "train_data", ",", "batch_size", "=", "self", ".", "batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "self", ".", "num_data_loader_workers", ")", "\n", "\n", "# init training variables", "\n", "train_loss", "=", "0", "\n", "samples_processed", "=", "0", "\n", "\n", "# train loop", "\n", "for", "epoch", "in", "range", "(", "self", ".", "num_epochs", ")", ":", "\n", "            ", "self", ".", "nn_epoch", "=", "epoch", "\n", "# train epoch", "\n", "s", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "sp", ",", "train_loss", "=", "self", ".", "_train_epoch", "(", "train_loader", ")", "\n", "samples_processed", "+=", "sp", "\n", "e", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "\n", "# report", "\n", "print", "(", "\"Epoch: [{}/{}]\\tSamples: [{}/{}]\\tTrain Loss: {}\\tTime: {}\"", ".", "format", "(", "\n", "epoch", "+", "1", ",", "self", ".", "num_epochs", ",", "samples_processed", ",", "\n", "len", "(", "self", ".", "train_data", ")", "*", "self", ".", "num_epochs", ",", "train_loss", ",", "e", "-", "s", ")", ")", "\n", "\n", "# save best", "\n", "if", "train_loss", "<", "self", ".", "best_loss_train", ":", "\n", "                ", "self", ".", "best_loss_train", "=", "train_loss", "\n", "self", ".", "best_components", "=", "self", ".", "model", ".", "beta", "\n", "\n", "if", "save_dir", "is", "not", "None", ":", "\n", "                    ", "self", ".", "save", "(", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.test": [[257, 330], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "datetime.datetime.now", "ctm.CTM.model.eval", "numpy.exp", "datetime.datetime.now", "print", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "ctm.CTM.model.zero_grad", "ctm.CTM.model", "ctm.CTM._loss", "ctm.CTM.item", "float", "X.cuda.cuda.cuda", "X_bert.cuda.cuda.cuda"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM._loss"], ["", "", "", "", "def", "test", "(", "self", ",", "test_dataset", ",", "num_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Test a CTM; get perplexity on held-out test_dataset.\n\n        Args\n            test_dataset : PyTorch Dataset classs for training data.\n        \"\"\"", "\n", "# Print settings to output file", "\n", "\"\"\"\n        print(\"Settings: \\n\\\n               N Components: {}\\n\\\n               Topic Prior Mean: {}\\n\\\n               Topic Prior Variance: {}\\n\\\n               Model Type: {}\\n\\\n               Hidden Sizes: {}\\n\\\n               Activation: {}\\n\\\n               Dropout: {}\\n\\\n               Learn Priors: {}\\n\\\n               Learning Rate: {}\\n\\\n               Momentum: {}\\n\\\n               Reduce On Plateau: {}\\n\\\n               Save Dir: {}\".format(\n                   self.n_components, 0.0,\n                   1. - (1./self.n_components), self.model_type,\n                   self.hidden_sizes, self.activation, self.dropout, self.learn_priors,\n                   self.lr, self.momentum, self.reduce_on_plateau, save_dir))\n        \"\"\"", "\n", "\n", "test_loader", "=", "DataLoader", "(", "\n", "test_dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "self", ".", "num_data_loader_workers", ")", "\n", "\n", "# init training variables", "\n", "test_loss", "=", "0", "\n", "samples_processed", "=", "0", "\n", "\n", "# testing", "\n", "s", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch_samples", "in", "test_loader", ":", "\n", "# batch_size x vocab_size", "\n", "                ", "X", "=", "batch_samples", "[", "'X'", "]", "\n", "X_bert", "=", "batch_samples", "[", "'X_bert'", "]", "\n", "if", "self", ".", "nb_labels", "is", "not", "None", ":", "\n", "                    ", "labels", "=", "batch_samples", "[", "'label'", "]", "\n", "", "else", ":", "\n", "                    ", "labels", "=", "None", "\n", "\n", "", "if", "self", ".", "USE_CUDA", ":", "\n", "                    ", "X", "=", "X", ".", "cuda", "(", ")", "\n", "X_bert", "=", "X_bert", ".", "cuda", "(", ")", "\n", "\n", "# forward pass", "\n", "", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "prior_mean", ",", "prior_variance", ",", "posterior_mean", ",", "posterior_variance", ",", "posterior_log_variance", ",", "word_dists", ",", "doc_log_probs", "=", "self", ".", "model", "(", "X", ",", "X_bert", ")", "\n", "\n", "# backward pass", "\n", "loss", "=", "self", ".", "_loss", "(", "\n", "X", ",", "word_dists", ",", "prior_mean", ",", "prior_variance", ",", "\n", "posterior_mean", ",", "posterior_variance", ",", "posterior_log_variance", ",", "doc_log_probs", ",", "labels", ")", "\n", "\n", "# compute train loss", "\n", "# samples_processed += X.size()[0]", "\n", "test_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "# test_loss /= samples_processed", "\n", "", "", "perplexity", "=", "np", ".", "exp", "(", "test_loss", "/", "float", "(", "num_tokens", ")", ")", "\n", "e", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "print", "(", "\"Perplexity: {}\\tTime: {}\"", ".", "format", "(", "\n", "perplexity", ",", "e", "-", "s", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.get_thetas": [[331, 360], ["ctm.CTM.model.eval", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "numpy.sum", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "final_thetas.append", "X.cuda.cuda.reshape", "ctm.CTM.model.zero_grad", "collect_theta.extend", "numpy.array", "X.cuda.cuda.cuda", "X_bert.cuda.cuda.cuda", "ctm.CTM.model.get_theta().cpu().numpy().tolist", "ctm.CTM.model.get_theta().cpu().numpy", "ctm.CTM.model.get_theta().cpu", "ctm.CTM.model.get_theta"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.networks.decoding_network.DecoderNetwork.get_theta"], ["", "def", "get_thetas", "(", "self", ",", "dataset", ",", "n_samples", "=", "20", ")", ":", "\n", "        ", "\"\"\"Predict input.\"\"\"", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "self", ".", "num_data_loader_workers", ")", "\n", "\n", "final_thetas", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "n_samples", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "collect_theta", "=", "[", "]", "\n", "for", "batch_samples", "in", "loader", ":", "\n", "# batch_size x vocab_size", "\n", "                    ", "X", "=", "batch_samples", "[", "'X'", "]", "\n", "X", "=", "X", ".", "reshape", "(", "X", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "X_bert", "=", "batch_samples", "[", "'X_bert'", "]", "\n", "\n", "if", "self", ".", "USE_CUDA", ":", "\n", "                        ", "X", "=", "X", ".", "cuda", "(", ")", "\n", "X_bert", "=", "X_bert", ".", "cuda", "(", ")", "\n", "\n", "# forward pass", "\n", "", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "collect_theta", ".", "extend", "(", "self", ".", "model", ".", "get_theta", "(", "X", ",", "X_bert", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "", "final_thetas", ".", "append", "(", "np", ".", "array", "(", "collect_theta", ")", ")", "\n", "\n", "", "", "return", "np", ".", "sum", "(", "final_thetas", ",", "axis", "=", "0", ")", "/", "n_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.predict": [[362, 392], ["ctm.CTM.model.eval", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ctm.CTM.model.zero_grad", "ctm.CTM.model", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "X.cuda.cuda.cuda", "X_bert.cuda.cuda.cuda"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "dataset", ",", "k", "=", "10", ")", ":", "\n", "        ", "\"\"\"Predict input.\"\"\"", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "self", ".", "num_data_loader_workers", ")", "\n", "\n", "preds", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "batch_samples", "in", "loader", ":", "\n", "# batch_size x vocab_size", "\n", "                ", "X", "=", "batch_samples", "[", "'X'", "]", "\n", "X_bert", "=", "batch_samples", "[", "'X_bert'", "]", "\n", "\n", "if", "self", ".", "USE_CUDA", ":", "\n", "                    ", "X", "=", "X", ".", "cuda", "(", ")", "\n", "X_bert", "=", "X_bert", ".", "cuda", "(", ")", "\n", "\n", "# forward pass", "\n", "", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "word_dists", ",", "_", "=", "self", ".", "model", "(", "X", ",", "X_bert", ")", "\n", "\n", "_", ",", "indices", "=", "torch", ".", "sort", "(", "word_dists", ",", "dim", "=", "1", ")", "\n", "preds", "+=", "[", "indices", "[", ":", ",", ":", "k", "]", "]", "\n", "\n", "", "preds", "=", "torch", ".", "cat", "(", "preds", ",", "dim", "=", "0", ")", "\n", "\n", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.score": [[393, 404], ["NotImplementedError", "ctm.CTM._get_coherence", "ValueError"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM._get_coherence"], ["", "def", "score", "(", "self", ",", "scorer", "=", "'coherence'", ",", "k", "=", "10", ",", "topics", "=", "5", ")", ":", "\n", "        ", "\"\"\"Score model.\"\"\"", "\n", "if", "scorer", "==", "'perplexity'", ":", "\n", "# score = perplexity_score(truth, preds)", "\n", "            ", "raise", "NotImplementedError", "(", "\"Not implemented yet.\"", ")", "\n", "", "elif", "scorer", "==", "'coherence'", ":", "\n", "            ", "score", "=", "self", ".", "_get_coherence", "(", "k", ",", "topics", "=", "topics", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown score type!\"", ")", "\n", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM._get_coherence": [[405, 427], ["numpy.mean", "print", "numpy.random.randint", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "print", "float", "idxs.cpu().numpy", "print", "requests.get", "idxs.cpu"], "methods", ["None"], ["", "def", "_get_coherence", "(", "self", ",", "k", "=", "10", ",", "topics", "=", "5", ")", ":", "\n", "        ", "\"\"\"Get coherence using palmetto web service.\"\"\"", "\n", "component_dists", "=", "self", ".", "best_components", "\n", "base_url", "=", "'https://palmetto.demos.dice-research.org/service/cv?words='", "\n", "scores", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "topics", ":", "\n", "            ", "print", "(", "i", ")", "\n", "t", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "n_components", ")", "\n", "_", ",", "idxs", "=", "torch", ".", "topk", "(", "component_dists", "[", "t", "]", ",", "k", ")", "\n", "component_words", "=", "[", "self", ".", "train_data", ".", "idx2token", "[", "idx", "]", "\n", "for", "idx", "in", "idxs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "]", "\n", "url", "=", "base_url", "+", "'%20'", ".", "join", "(", "component_words", ")", "\n", "print", "(", "url", ")", "\n", "try", ":", "\n", "                ", "score", "=", "float", "(", "requests", ".", "get", "(", "url", ",", "timeout", "=", "300", ")", ".", "content", ")", "\n", "scores", "+=", "[", "score", "]", "\n", "i", "+=", "1", "\n", "", "except", "requests", ".", "exceptions", ".", "Timeout", ":", "\n", "                ", "print", "(", "\"Attempted scoring timed out.  Trying again.\"", ")", "\n", "continue", "\n", "", "", "return", "np", ".", "mean", "(", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.get_topics": [[428, 444], ["collections.defaultdict", "range", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "idxs.cpu().numpy", "idxs.cpu"], "methods", ["None"], ["", "def", "get_topics", "(", "self", ",", "k", "=", "10", ")", ":", "\n", "        ", "\"\"\"\n        Retrieve topic words.\n\n        Args\n            k : (int) number of words to return per topic, default 10.\n        \"\"\"", "\n", "assert", "k", "<=", "self", ".", "input_size", ",", "\"k must be <= input size.\"", "\n", "component_dists", "=", "self", ".", "best_components", "\n", "topics", "=", "defaultdict", "(", "list", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_components", ")", ":", "\n", "            ", "_", ",", "idxs", "=", "torch", ".", "topk", "(", "component_dists", "[", "i", "]", ",", "k", ")", "\n", "component_words", "=", "[", "self", ".", "train_data", ".", "idx2token", "[", "idx", "]", "\n", "for", "idx", "in", "idxs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "]", "\n", "topics", "[", "i", "]", "=", "component_words", "\n", "", "return", "topics", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.get_topic_lists": [[445, 461], ["range", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "topics.append", "idxs.cpu().numpy", "idxs.cpu"], "methods", ["None"], ["", "def", "get_topic_lists", "(", "self", ",", "k", "=", "10", ")", ":", "\n", "        ", "\"\"\"\n        Retrieve the lists of topic words.\n\n        Args\n            k : (int) number of words to return per topic, default 10.\n        \"\"\"", "\n", "assert", "k", "<=", "self", ".", "input_size", ",", "\"k must be <= input size.\"", "\n", "component_dists", "=", "self", ".", "best_components", "\n", "topics", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n_components", ")", ":", "\n", "            ", "_", ",", "idxs", "=", "torch", ".", "topk", "(", "component_dists", "[", "i", "]", ",", "k", ")", "\n", "component_words", "=", "[", "self", ".", "train_data", ".", "idx2token", "[", "idx", "]", "\n", "for", "idx", "in", "idxs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "]", "\n", "topics", ".", "append", "(", "component_words", ")", "\n", "", "return", "topics", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM._format_file": [[462, 469], ["None"], "methods", ["None"], ["", "def", "_format_file", "(", "self", ")", ":", "\n", "        ", "model_dir", "=", "\"AVITM_nc_{}_tpm_{}_tpv_{}_hs_{}_ac_{}_do_{}_lr_{}_mo_{}_rp_{}\"", ".", "format", "(", "self", ".", "n_components", ",", "0.0", ",", "1", "-", "(", "1.", "/", "self", ".", "n_components", ")", ",", "\n", "self", ".", "model_type", ",", "self", ".", "hidden_sizes", ",", "self", ".", "activation", ",", "\n", "self", ".", "dropout", ",", "self", ".", "lr", ",", "self", ".", "momentum", ",", "\n", "self", ".", "reduce_on_plateau", ")", "\n", "return", "model_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.save": [[470, 488], ["ctm.CTM._format_file", "os.path.join", "os.path.isdir", "os.makedirs", "open", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.join", "os.path.join", "ctm.CTM.model.state_dict"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM._format_file", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.save", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.save", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.save", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.save"], ["", "def", "save", "(", "self", ",", "models_dir", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Save model.\n\n        Args\n            models_dir: path to directory for saving NN models.\n        \"\"\"", "\n", "if", "(", "self", ".", "model", "is", "not", "None", ")", "and", "(", "models_dir", "is", "not", "None", ")", ":", "\n", "\n", "            ", "model_dir", "=", "self", ".", "_format_file", "(", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "models_dir", ",", "model_dir", ")", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "models_dir", ",", "model_dir", ")", ")", "\n", "\n", "", "filename", "=", "\"epoch_{}\"", ".", "format", "(", "self", ".", "nn_epoch", ")", "+", "'.pth'", "\n", "fileloc", "=", "os", ".", "path", ".", "join", "(", "models_dir", ",", "model_dir", ",", "filename", ")", "\n", "with", "open", "(", "fileloc", ",", "'wb'", ")", "as", "file", ":", "\n", "                ", "torch", ".", "save", "(", "{", "'state_dict'", ":", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "'dcue_dict'", ":", "self", ".", "__dict__", "}", ",", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.load": [[489, 507], ["os.path.join", "checkpoint[].items", "ctm.CTM.model.load_state_dict", "open", "torch.load", "torch.load", "torch.load", "torch.load", "setattr", "str"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.load", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.load", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.load", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.load"], ["", "", "", "def", "load", "(", "self", ",", "model_dir", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Load a previously trained model.\n\n        Args\n            model_dir: directory where models are saved.\n            epoch: epoch of model to load.\n        \"\"\"", "\n", "epoch_file", "=", "\"epoch_\"", "+", "str", "(", "epoch", ")", "+", "\".pth\"", "\n", "model_file", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "epoch_file", ")", "\n", "with", "open", "(", "model_file", ",", "'rb'", ")", "as", "model_dict", ":", "\n", "            ", "checkpoint", "=", "torch", ".", "load", "(", "model_dict", ")", "\n", "\n", "", "for", "(", "k", ",", "v", ")", "in", "checkpoint", "[", "'dcue_dict'", "]", ".", "items", "(", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "k", ",", "v", ")", "\n", "\n", "# self._init_nn() #TODO implement this method", "\n", "", "self", ".", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.networks.decoding_network.DecoderNetwork.__init__": [[14, 92], ["torch.nn.Module.__init__", "isinstance", "isinstance", "torch.tensor", "torch.tensor", "torch.Tensor", "torch.nn.Parameter", "torch.nn.init.xavier_uniform_", "torch.nn.BatchNorm1d", "torch.nn.Dropout", "isinstance", "contextualized_topic_models.networks.inference_network.ContextualInferenceNetwork", "torch.nn.Parameter", "torch.nn.Parameter", "contextualized_topic_models.networks.inference_network.CombinedInferenceNetwork", "contextualized_topic_models.networks.inference_network.ProdLDA", "Exception"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CentroidDistance.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "bert_size", ",", "infnet", ",", "n_components", "=", "10", ",", "model_type", "=", "'prodLDA'", ",", "\n", "hidden_sizes", "=", "(", "100", ",", "100", ")", ",", "activation", "=", "'softplus'", ",", "dropout", "=", "0.2", ",", "\n", "learn_priors", "=", "True", ",", "nb_labels", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialize InferenceNetwork.\n\n        Args\n            input_size : int, dimension of input\n            n_components : int, number of topic components, (default 10)\n            model_type : string, 'prodLDA' or 'LDA' (default 'prodLDA')\n            hidden_sizes : tuple, length = n_layers, (default (100, 100))\n            activation : string, 'softplus', 'relu', (default 'softplus')\n            learn_priors : bool, make priors learnable parameter\n        \"\"\"", "\n", "super", "(", "DecoderNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "input_size", ",", "int", ")", ",", "\"input_size must by type int.\"", "\n", "assert", "isinstance", "(", "n_components", ",", "int", ")", "and", "n_components", ">", "0", ",", "\"n_components must be type int > 0.\"", "\n", "assert", "model_type", "in", "[", "'prodLDA'", ",", "'LDA'", "]", ",", "\"model type must be 'prodLDA' or 'LDA'\"", "\n", "assert", "isinstance", "(", "hidden_sizes", ",", "tuple", ")", ",", "\"hidden_sizes must be type tuple.\"", "\n", "assert", "activation", "in", "[", "'softplus'", ",", "'relu'", "]", ",", "\"activation must be 'softplus' or 'relu'.\"", "\n", "assert", "dropout", ">=", "0", ",", "\"dropout must be >= 0.\"", "\n", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "n_components", "=", "n_components", "\n", "self", ".", "model_type", "=", "model_type", "\n", "self", ".", "hidden_sizes", "=", "hidden_sizes", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "learn_priors", "=", "learn_priors", "\n", "self", ".", "nb_labels", "=", "nb_labels", "\n", "\n", "if", "infnet", "==", "\"contextual\"", ":", "\n", "            ", "self", ".", "inf_net", "=", "ContextualInferenceNetwork", "(", "\n", "input_size", ",", "bert_size", ",", "n_components", ",", "hidden_sizes", ",", "activation", ",", "nb_labels", "=", "self", ".", "nb_labels", ")", "\n", "", "elif", "infnet", "==", "\"combined\"", ":", "\n", "            ", "self", ".", "inf_net", "=", "CombinedInferenceNetwork", "(", "\n", "input_size", ",", "bert_size", ",", "n_components", ",", "hidden_sizes", ",", "activation", ")", "\n", "", "elif", "infnet", "==", "\"prodlda_baseline\"", ":", "\n", "            ", "self", ".", "inf_net", "=", "ProdLDA", "(", "\n", "input_size", ",", "bert_size", ",", "n_components", ",", "hidden_sizes", ",", "activation", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Missing infnet parameter, options are contextual and combined'", ")", "\n", "\n", "# init prior parameters", "\n", "# \\mu_1k = log \\alpha_k + 1/K \\sum_i log \\alpha_i;", "\n", "# \\alpha = 1 \\forall \\alpha", "\n", "", "topic_prior_mean", "=", "0.0", "\n", "self", ".", "prior_mean", "=", "torch", ".", "tensor", "(", "\n", "[", "topic_prior_mean", "]", "*", "n_components", ")", "\n", "#if torch.cuda.is_available():", "\n", "#    self.prior_mean = self.prior_mean.cuda()", "\n", "if", "self", ".", "learn_priors", ":", "\n", "            ", "self", ".", "prior_mean", "=", "nn", ".", "Parameter", "(", "self", ".", "prior_mean", ")", "\n", "\n", "# \\Sigma_1kk = 1 / \\alpha_k (1 - 2/K) + 1/K^2 \\sum_i 1 / \\alpha_k;", "\n", "# \\alpha = 1 \\forall \\alpha", "\n", "", "topic_prior_variance", "=", "1.", "-", "(", "1.", "/", "self", ".", "n_components", ")", "\n", "self", ".", "prior_variance", "=", "torch", ".", "tensor", "(", "\n", "[", "topic_prior_variance", "]", "*", "n_components", ")", "\n", "#if torch.cuda.is_available():", "\n", "#    self.prior_variance = self.prior_variance.cuda()", "\n", "if", "self", ".", "learn_priors", ":", "\n", "            ", "self", ".", "prior_variance", "=", "nn", ".", "Parameter", "(", "self", ".", "prior_variance", ")", "\n", "\n", "", "self", ".", "beta", "=", "torch", ".", "Tensor", "(", "n_components", ",", "input_size", ")", "\n", "#if torch.cuda.is_available():", "\n", "#    self.beta = self.beta.cuda()", "\n", "self", ".", "beta", "=", "nn", ".", "Parameter", "(", "self", ".", "beta", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "beta", ")", "\n", "\n", "self", ".", "beta_batchnorm", "=", "nn", ".", "BatchNorm1d", "(", "input_size", ",", "affine", "=", "False", ")", "\n", "\n", "# dropout on theta", "\n", "self", ".", "drop_theta", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.networks.decoding_network.DecoderNetwork.reparameterize": [[93, 99], ["torch.exp", "torch.randn_like", "torch.randn_like.mul().add_", "torch.randn_like.mul"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "reparameterize", "(", "mu", ",", "logvar", ")", ":", "\n", "        ", "\"\"\"Reparameterize the theta distribution.\"\"\"", "\n", "std", "=", "torch", ".", "exp", "(", "0.5", "*", "logvar", ")", "\n", "eps", "=", "torch", ".", "randn_like", "(", "std", ")", "\n", "return", "eps", ".", "mul", "(", "std", ")", ".", "add_", "(", "mu", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.networks.decoding_network.DecoderNetwork.forward": [[100, 130], ["decoding_network.DecoderNetwork.inf_net", "torch.exp", "torch.nn.functional.softmax", "decoding_network.DecoderNetwork.drop_theta", "decoding_network.DecoderNetwork.reparameterize", "torch.nn.functional.log_softmax", "torch.nn.functional.softmax", "decoding_network.DecoderNetwork.beta_batchnorm", "torch.nn.functional.softmax", "torch.matmul", "torch.matmul", "decoding_network.DecoderNetwork.beta_batchnorm"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.networks.decoding_network.DecoderNetwork.reparameterize"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_bert", ")", ":", "\n", "        ", "\"\"\"Forward pass.\"\"\"", "\n", "# batch_size x n_components", "\n", "posterior_mu", ",", "posterior_log_sigma", ",", "doc_logits", "=", "self", ".", "inf_net", "(", "x", ",", "x_bert", ")", "\n", "posterior_sigma", "=", "torch", ".", "exp", "(", "posterior_log_sigma", ")", "\n", "\n", "# generate samples from theta", "\n", "theta", "=", "F", ".", "softmax", "(", "\n", "self", ".", "reparameterize", "(", "posterior_mu", ",", "posterior_log_sigma", ")", ",", "dim", "=", "1", ")", "\n", "theta", "=", "self", ".", "drop_theta", "(", "theta", ")", "\n", "\n", "if", "doc_logits", "is", "not", "None", ":", "\n", "            ", "doc_log_probs", "=", "F", ".", "log_softmax", "(", "doc_logits", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "doc_log_probs", "=", "None", "\n", "\n", "# prodLDA vs LDA", "\n", "", "if", "self", ".", "model_type", "==", "'prodLDA'", ":", "\n", "# in: batch_size x input_size x n_components", "\n", "            ", "word_dist", "=", "F", ".", "softmax", "(", "\n", "self", ".", "beta_batchnorm", "(", "torch", ".", "matmul", "(", "theta", ",", "self", ".", "beta", ")", ")", ",", "dim", "=", "1", ")", "\n", "# word_dist: batch_size x input_size", "\n", "", "elif", "self", ".", "model_type", "==", "'LDA'", ":", "\n", "# simplex constrain on Beta", "\n", "            ", "beta", "=", "F", ".", "softmax", "(", "self", ".", "beta_batchnorm", "(", "self", ".", "beta", ")", ",", "dim", "=", "1", ")", "\n", "word_dist", "=", "torch", ".", "matmul", "(", "theta", ",", "beta", ")", "\n", "# word_dist: batch_size x input_size", "\n", "\n", "", "return", "self", ".", "prior_mean", ",", "self", ".", "prior_variance", ",", "posterior_mu", ",", "posterior_sigma", ",", "posterior_log_sigma", ",", "word_dist", ",", "doc_log_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.networks.decoding_network.DecoderNetwork.get_theta": [[131, 142], ["torch.no_grad", "decoding_network.DecoderNetwork.inf_net", "torch.exp", "torch.nn.functional.softmax", "decoding_network.DecoderNetwork.reparameterize"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.networks.decoding_network.DecoderNetwork.reparameterize"], ["", "def", "get_theta", "(", "self", ",", "x", ",", "x_bert", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# batch_size x n_components", "\n", "            ", "posterior_mu", ",", "posterior_log_sigma", ",", "doc_logits", "=", "self", ".", "inf_net", "(", "x", ",", "x_bert", ")", "\n", "posterior_sigma", "=", "torch", ".", "exp", "(", "posterior_log_sigma", ")", "\n", "\n", "# generate samples from theta", "\n", "theta", "=", "F", ".", "softmax", "(", "\n", "self", ".", "reparameterize", "(", "posterior_mu", ",", "posterior_log_sigma", ")", ",", "dim", "=", "1", ")", "\n", "\n", "return", "theta", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.networks.inference_network.ContextualInferenceNetwork.__init__": [[12, 61], ["torch.nn.Module.__init__", "isinstance", "isinstance", "isinstance", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.Dropout", "torch.nn.Softplus", "collections.OrderedDict", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Sequential", "enumerate", "torch.nn.Linear", "zip"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CentroidDistance.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "bert_size", ",", "output_size", ",", "hidden_sizes", ",", "\n", "activation", "=", "'softplus'", ",", "dropout", "=", "0.2", ",", "nb_labels", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialize InferenceNetwork.\n\n        Args\n            input_size : int, dimension of input\n            output_size : int, dimension of output\n            hidden_sizes : tuple, length = n_layers\n            activation : string, 'softplus' or 'relu', default 'softplus'\n            dropout : float, default 0.2, default 0.2\n        \"\"\"", "\n", "super", "(", "ContextualInferenceNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "input_size", ",", "int", ")", ",", "\"input_size must by type int.\"", "\n", "assert", "isinstance", "(", "output_size", ",", "int", ")", ",", "\"output_size must be type int.\"", "\n", "assert", "isinstance", "(", "hidden_sizes", ",", "tuple", ")", ",", "\"hidden_sizes must be type tuple.\"", "\n", "assert", "activation", "in", "[", "'softplus'", ",", "'relu'", "]", ",", "\"activation must be 'softplus' or 'relu'.\"", "\n", "assert", "dropout", ">=", "0", ",", "\"dropout must be >= 0.\"", "\n", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "hidden_sizes", "=", "hidden_sizes", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "nb_labels", "=", "nb_labels", "\n", "\n", "if", "activation", "==", "'softplus'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Softplus", "(", ")", "\n", "", "elif", "activation", "==", "'relu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "", "self", ".", "input_layer", "=", "nn", ".", "Linear", "(", "input_size", "+", "input_size", ",", "hidden_sizes", "[", "0", "]", ")", "\n", "self", ".", "adapt_bert", "=", "nn", ".", "Linear", "(", "bert_size", ",", "hidden_sizes", "[", "0", "]", ")", "\n", "\n", "self", ".", "hiddens", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'l_{}'", ".", "format", "(", "i", ")", ",", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "h_in", ",", "h_out", ")", ",", "self", ".", "activation", ")", ")", "\n", "for", "i", ",", "(", "h_in", ",", "h_out", ")", "in", "enumerate", "(", "zip", "(", "hidden_sizes", "[", ":", "-", "1", "]", ",", "hidden_sizes", "[", "1", ":", "]", ")", ")", "]", ")", ")", "\n", "\n", "if", "self", ".", "nb_labels", "is", "not", "None", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_sizes", "[", "-", "1", "]", ",", "self", ".", "nb_labels", ")", "\n", "\n", "", "self", ".", "f_mu", "=", "nn", ".", "Linear", "(", "hidden_sizes", "[", "-", "1", "]", ",", "output_size", ")", "\n", "self", ".", "f_mu_batchnorm", "=", "nn", ".", "BatchNorm1d", "(", "output_size", ",", "affine", "=", "False", ")", "\n", "\n", "self", ".", "f_sigma", "=", "nn", ".", "Linear", "(", "hidden_sizes", "[", "-", "1", "]", ",", "output_size", ")", "\n", "self", ".", "f_sigma_batchnorm", "=", "nn", ".", "BatchNorm1d", "(", "output_size", ",", "affine", "=", "False", ")", "\n", "\n", "self", ".", "dropout_enc", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.networks.inference_network.ContextualInferenceNetwork.forward": [[62, 77], ["inference_network.ContextualInferenceNetwork.adapt_bert", "inference_network.ContextualInferenceNetwork.activation", "inference_network.ContextualInferenceNetwork.hiddens", "inference_network.ContextualInferenceNetwork.dropout_enc", "inference_network.ContextualInferenceNetwork.f_mu_batchnorm", "inference_network.ContextualInferenceNetwork.f_sigma_batchnorm", "inference_network.ContextualInferenceNetwork.f_mu", "inference_network.ContextualInferenceNetwork.f_sigma"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_bert", ")", ":", "\n", "        ", "\"\"\"Forward pass.\"\"\"", "\n", "x_bert", "=", "self", ".", "adapt_bert", "(", "x_bert", ")", "\n", "\n", "x", "=", "self", ".", "activation", "(", "x_bert", ")", "\n", "x", "=", "self", ".", "hiddens", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_enc", "(", "x", ")", "\n", "#if self.nb_labels is not None:", "\n", "#    logits = self.classifier(x)", "\n", "#else:", "\n", "logits", "=", "None", "\n", "mu", "=", "self", ".", "f_mu_batchnorm", "(", "self", ".", "f_mu", "(", "x", ")", ")", "\n", "log_sigma", "=", "self", ".", "f_sigma_batchnorm", "(", "self", ".", "f_sigma", "(", "x", ")", ")", "\n", "\n", "return", "mu", ",", "log_sigma", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.networks.inference_network.CombinedInferenceNetwork.__init__": [[85, 131], ["torch.nn.Module.__init__", "isinstance", "isinstance", "isinstance", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.Dropout", "torch.nn.Softplus", "collections.OrderedDict", "torch.nn.ReLU", "torch.nn.Sequential", "enumerate", "torch.nn.Linear", "zip"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CentroidDistance.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "bert_size", ",", "output_size", ",", "hidden_sizes", ",", "\n", "activation", "=", "'softplus'", ",", "dropout", "=", "0.2", ")", ":", "\n", "        ", "\"\"\"\n        Initialize InferenceNetwork.\n\n        Args\n            input_size : int, dimension of input\n            output_size : int, dimension of output\n            hidden_sizes : tuple, length = n_layers\n            activation : string, 'softplus' or 'relu', default 'softplus'\n            dropout : float, default 0.2, default 0.2\n        \"\"\"", "\n", "super", "(", "CombinedInferenceNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "input_size", ",", "int", ")", ",", "\"input_size must by type int.\"", "\n", "assert", "isinstance", "(", "output_size", ",", "int", ")", ",", "\"output_size must be type int.\"", "\n", "assert", "isinstance", "(", "hidden_sizes", ",", "tuple", ")", ",", "\"hidden_sizes must be type tuple.\"", "\n", "assert", "activation", "in", "[", "'softplus'", ",", "'relu'", "]", ",", "\"activation must be 'softplus' or 'relu'.\"", "\n", "assert", "dropout", ">=", "0", ",", "\"dropout must be >= 0.\"", "\n", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "hidden_sizes", "=", "hidden_sizes", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "if", "activation", "==", "'softplus'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Softplus", "(", ")", "\n", "", "elif", "activation", "==", "'relu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "", "self", ".", "input_layer", "=", "nn", ".", "Linear", "(", "input_size", "+", "input_size", ",", "hidden_sizes", "[", "0", "]", ")", "\n", "self", ".", "adapt_bert", "=", "nn", ".", "Linear", "(", "bert_size", ",", "input_size", ")", "\n", "self", ".", "bert_layer", "=", "nn", ".", "Linear", "(", "hidden_sizes", "[", "0", "]", ",", "hidden_sizes", "[", "0", "]", ")", "\n", "\n", "self", ".", "hiddens", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'l_{}'", ".", "format", "(", "i", ")", ",", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "h_in", ",", "h_out", ")", ",", "self", ".", "activation", ")", ")", "\n", "for", "i", ",", "(", "h_in", ",", "h_out", ")", "in", "enumerate", "(", "zip", "(", "hidden_sizes", "[", ":", "-", "1", "]", ",", "hidden_sizes", "[", "1", ":", "]", ")", ")", "]", ")", ")", "\n", "\n", "self", ".", "f_mu", "=", "nn", ".", "Linear", "(", "hidden_sizes", "[", "-", "1", "]", ",", "output_size", ")", "\n", "self", ".", "f_mu_batchnorm", "=", "nn", ".", "BatchNorm1d", "(", "output_size", ",", "affine", "=", "False", ")", "\n", "\n", "self", ".", "f_sigma", "=", "nn", ".", "Linear", "(", "hidden_sizes", "[", "-", "1", "]", ",", "output_size", ")", "\n", "self", ".", "f_sigma_batchnorm", "=", "nn", ".", "BatchNorm1d", "(", "output_size", ",", "affine", "=", "False", ")", "\n", "\n", "self", ".", "dropout_enc", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.networks.inference_network.CombinedInferenceNetwork.forward": [[132, 145], ["inference_network.CombinedInferenceNetwork.adapt_bert", "torch.cat", "inference_network.CombinedInferenceNetwork.input_layer", "inference_network.CombinedInferenceNetwork.activation", "inference_network.CombinedInferenceNetwork.hiddens", "inference_network.CombinedInferenceNetwork.dropout_enc", "inference_network.CombinedInferenceNetwork.f_mu_batchnorm", "inference_network.CombinedInferenceNetwork.f_sigma_batchnorm", "inference_network.CombinedInferenceNetwork.f_mu", "inference_network.CombinedInferenceNetwork.f_sigma"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_bert", ")", ":", "\n", "        ", "\"\"\"Forward pass.\"\"\"", "\n", "x_bert", "=", "self", ".", "adapt_bert", "(", "x_bert", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "x_bert", ")", ",", "1", ")", "\n", "x", "=", "self", ".", "input_layer", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "hiddens", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_enc", "(", "x", ")", "\n", "mu", "=", "self", ".", "f_mu_batchnorm", "(", "self", ".", "f_mu", "(", "x", ")", ")", "\n", "log_sigma", "=", "self", ".", "f_sigma_batchnorm", "(", "self", ".", "f_sigma", "(", "x", ")", ")", "\n", "\n", "return", "mu", ",", "log_sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.networks.inference_network.ProdLDA.__init__": [[151, 196], ["torch.nn.Module.__init__", "isinstance", "isinstance", "isinstance", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.Dropout", "torch.nn.Softplus", "collections.OrderedDict", "torch.nn.ReLU", "torch.nn.Sequential", "enumerate", "torch.nn.Linear", "zip"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CentroidDistance.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "bert_size", ",", "output_size", ",", "hidden_sizes", ",", "\n", "activation", "=", "'softplus'", ",", "dropout", "=", "0.2", ")", ":", "\n", "        ", "\"\"\"\n        Initialize InferenceNetwork.\n\n        Args\n            input_size : int, dimension of input\n            output_size : int, dimension of output\n            hidden_sizes : tuple, length = n_layers\n            activation : string, 'softplus' or 'relu', default 'softplus'\n            dropout : float, default 0.2, default 0.2\n        \"\"\"", "\n", "super", "(", "ProdLDA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "input_size", ",", "int", ")", ",", "\"input_size must by type int.\"", "\n", "assert", "isinstance", "(", "output_size", ",", "int", ")", ",", "\"output_size must be type int.\"", "\n", "assert", "isinstance", "(", "hidden_sizes", ",", "tuple", ")", ",", "\"hidden_sizes must be type tuple.\"", "\n", "assert", "activation", "in", "[", "'softplus'", ",", "'relu'", "]", ",", "\"activation must be 'softplus' or 'relu'.\"", "\n", "assert", "dropout", ">=", "0", ",", "\"dropout must be >= 0.\"", "\n", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "hidden_sizes", "=", "hidden_sizes", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "if", "activation", "==", "'softplus'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Softplus", "(", ")", "\n", "", "elif", "activation", "==", "'relu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "", "self", ".", "input_layer", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_sizes", "[", "0", "]", ")", "\n", "self", ".", "bert_layer", "=", "nn", ".", "Linear", "(", "hidden_sizes", "[", "0", "]", ",", "hidden_sizes", "[", "0", "]", ")", "\n", "\n", "self", ".", "hiddens", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'l_{}'", ".", "format", "(", "i", ")", ",", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "h_in", ",", "h_out", ")", ",", "self", ".", "activation", ")", ")", "\n", "for", "i", ",", "(", "h_in", ",", "h_out", ")", "in", "enumerate", "(", "zip", "(", "hidden_sizes", "[", ":", "-", "1", "]", ",", "hidden_sizes", "[", "1", ":", "]", ")", ")", "]", ")", ")", "\n", "\n", "self", ".", "f_mu", "=", "nn", ".", "Linear", "(", "hidden_sizes", "[", "-", "1", "]", ",", "output_size", ")", "\n", "self", ".", "f_mu_batchnorm", "=", "nn", ".", "BatchNorm1d", "(", "output_size", ",", "affine", "=", "False", ")", "\n", "\n", "self", ".", "f_sigma", "=", "nn", ".", "Linear", "(", "hidden_sizes", "[", "-", "1", "]", ",", "output_size", ")", "\n", "self", ".", "f_sigma_batchnorm", "=", "nn", ".", "BatchNorm1d", "(", "output_size", ",", "affine", "=", "False", ")", "\n", "\n", "self", ".", "dropout_enc", "=", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.networks.inference_network.ProdLDA.forward": [[197, 213], ["inference_network.ProdLDA.input_layer", "inference_network.ProdLDA.activation", "inference_network.ProdLDA.hiddens", "inference_network.ProdLDA.dropout_enc", "inference_network.ProdLDA.f_mu_batchnorm", "inference_network.ProdLDA.f_sigma_batchnorm", "inference_network.ProdLDA.f_mu", "inference_network.ProdLDA.f_sigma"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_bert", ")", ":", "\n", "        ", "\"\"\"Forward pass.\"\"\"", "\n", "x", "=", "self", ".", "input_layer", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "hiddens", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout_enc", "(", "x", ")", "\n", "mu", "=", "self", ".", "f_mu_batchnorm", "(", "self", ".", "f_mu", "(", "x", ")", ")", "\n", "log_sigma", "=", "self", ".", "f_sigma_batchnorm", "(", "self", ".", "f_sigma", "(", "x", ")", ")", "\n", "\n", "#if self.nb_labels is not None:", "\n", "#    logits = self.classifier(x)", "\n", "#else:", "\n", "logits", "=", "None", "\n", "\n", "return", "mu", ",", "log_sigma", ",", "logits", "", "", "", ""]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.wiki.model_mallet_wiki.print_topics": [[18, 23], ["count_vectorizer.get_feature_names", "enumerate", "print", "print", "topic.argsort"], "function", ["None"], ["def", "print_topics", "(", "model", ",", "count_vectorizer", ",", "n_top_words", ")", ":", "\n", "    ", "words", "=", "count_vectorizer", ".", "get_feature_names", "(", ")", "\n", "for", "topic_idx", ",", "topic", "in", "enumerate", "(", "model", ".", "components_", ")", ":", "\n", "        ", "print", "(", "\"\\Topic #{}:\"", ".", "format", "(", "topic_idx", ")", ")", "\n", "print", "(", "\" \"", ".", "join", "(", "[", "words", "[", "i", "]", "for", "i", "in", "topic", ".", "argsort", "(", ")", "[", ":", "-", "n_top_words", "-", "1", ":", "-", "1", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.Measure.__init__": [[14, 16], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.Measure.score": [[17, 19], ["None"], "methods", ["None"], ["", "def", "score", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.TopicDiversity.__init__": [[22, 25], ["measures.Measure.__init__"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CentroidDistance.__init__"], ["    ", "def", "__init__", "(", "self", ",", "topics", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "topics", "=", "topics", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.TopicDiversity.score": [[26, 39], ["len", "Exception", "set", "unique_words.union.union.union", "len", "set", "len"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "topk", "=", "25", ")", ":", "\n", "        ", "\"\"\"\n        :param topk: topk words on which the topic diversity will be computed\n        :return:\n        \"\"\"", "\n", "if", "topk", ">", "len", "(", "self", ".", "topics", "[", "0", "]", ")", ":", "\n", "            ", "raise", "Exception", "(", "'Words in topics are less than topk'", ")", "\n", "", "else", ":", "\n", "            ", "unique_words", "=", "set", "(", ")", "\n", "for", "t", "in", "self", ".", "topics", ":", "\n", "                ", "unique_words", "=", "unique_words", ".", "union", "(", "set", "(", "t", "[", ":", "topk", "]", ")", ")", "\n", "", "td", "=", "len", "(", "unique_words", ")", "/", "(", "topk", "*", "len", "(", "self", ".", "topics", ")", ")", "\n", "return", "td", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CoherenceNPMI.__init__": [[42, 47], ["measures.Measure.__init__", "gensim.corpora.dictionary.Dictionary"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CentroidDistance.__init__"], ["    ", "def", "__init__", "(", "self", ",", "topics", ",", "texts", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "topics", "=", "topics", "\n", "self", ".", "texts", "=", "texts", "\n", "self", ".", "dictionary", "=", "Dictionary", "(", "self", ".", "texts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CoherenceNPMI.score": [[48, 62], ["len", "Exception", "gensim.models.coherencemodel.CoherenceModel", "gensim.models.coherencemodel.CoherenceModel.get_coherence"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "topk", "=", "10", ")", ":", "\n", "        ", "\"\"\"\n        :param topics: a list of lists of the top-k words\n        :param texts: (list of lists of strings) represents the corpus on which the empirical frequencies of words are\n        computed\n        :param topk: how many most likely words to consider in the evaluation\n        :return:\n        \"\"\"", "\n", "if", "topk", ">", "len", "(", "self", ".", "topics", "[", "0", "]", ")", ":", "\n", "            ", "raise", "Exception", "(", "'Words in topics are less than topk'", ")", "\n", "", "else", ":", "\n", "            ", "npmi", "=", "CoherenceModel", "(", "topics", "=", "self", ".", "topics", ",", "texts", "=", "self", ".", "texts", ",", "dictionary", "=", "self", ".", "dictionary", ",", "\n", "coherence", "=", "'c_npmi'", ",", "topn", "=", "topk", ")", "\n", "return", "npmi", ".", "get_coherence", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CoherenceWordEmbeddings.__init__": [[65, 79], ["measures.Measure.__init__", "gensim.load", "gensim.models.KeyedVectors.load_word2vec_format"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CentroidDistance.__init__", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.load"], ["    ", "def", "__init__", "(", "self", ",", "topics", ",", "word2vec_path", "=", "None", ",", "binary", "=", "False", ")", ":", "\n", "        ", "'''\n        :param topics: a list of lists of the top-n most likely words\n        :param word2vec_path: if word2vec_file is specified, it retrieves the word embeddings file (in word2vec format) to\n         compute similarities between words, otherwise 'word2vec-google-news-300' is downloaded\n        :param binary: if the word2vec file is binary\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "topics", "=", "topics", "\n", "self", ".", "binary", "=", "binary", "\n", "if", "word2vec_path", "is", "None", ":", "\n", "            ", "self", ".", "wv", "=", "api", ".", "load", "(", "'word2vec-google-news-300'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "wv", "=", "KeyedVectors", ".", "load_word2vec_format", "(", "word2vec_path", ",", "binary", "=", "binary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CoherenceWordEmbeddings.score": [[80, 97], ["len", "Exception", "enumerate", "numpy.mean", "len", "itertools.combinations", "arrays.append", "numpy.mean", "local_simi.append", "measures.CoherenceWordEmbeddings.wv.similarity"], "methods", ["None"], ["", "", "def", "score", "(", "self", ",", "topk", "=", "10", ",", "binary", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param topk: how many most likely words to consider in the evaluation\n        :return: topic coherence computed on the word embeddings similarities\n        \"\"\"", "\n", "if", "topk", ">", "len", "(", "self", ".", "topics", "[", "0", "]", ")", ":", "\n", "            ", "raise", "Exception", "(", "'Words in topics are less than topk'", ")", "\n", "", "else", ":", "\n", "            ", "arrays", "=", "[", "]", "\n", "for", "index", ",", "topic", "in", "enumerate", "(", "self", ".", "topics", ")", ":", "\n", "                ", "if", "len", "(", "topic", ")", ">", "0", ":", "\n", "                    ", "local_simi", "=", "[", "]", "\n", "for", "word1", ",", "word2", "in", "itertools", ".", "combinations", "(", "topic", "[", "0", ":", "topk", "]", ",", "2", ")", ":", "\n", "                        ", "if", "word1", "in", "self", ".", "wv", ".", "vocab", "and", "word2", "in", "self", ".", "wv", ".", "vocab", ":", "\n", "                            ", "local_simi", ".", "append", "(", "self", ".", "wv", ".", "similarity", "(", "word1", ",", "word2", ")", ")", "\n", "", "", "arrays", ".", "append", "(", "np", ".", "mean", "(", "local_simi", ")", ")", "\n", "", "", "return", "np", ".", "mean", "(", "arrays", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.InvertedRBO.__init__": [[100, 103], ["measures.Measure.__init__"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CentroidDistance.__init__"], ["    ", "def", "__init__", "(", "self", ",", "topics", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "topics", "=", "topics", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.InvertedRBO.score": [[104, 119], ["len", "Exception", "itertools.combinations", "collect.append", "numpy.mean", "contextualized_topic_models.evaluation.rbo.rbo.rbo"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.rbo"], ["", "def", "score", "(", "self", ",", "topk", "=", "10", ",", "weight", "=", "0.9", ")", ":", "\n", "        ", "'''\n        :param weight: p (float), default 1.0: Weight of each agreement at depth d:\n        p**(d-1). When set to 1.0, there is no weight, the rbo returns to average overlap.\n        :param topic_list: a list of lists of words\n        :return: rank_biased_overlap over the topics\n        '''", "\n", "if", "topk", ">", "len", "(", "self", ".", "topics", "[", "0", "]", ")", ":", "\n", "            ", "raise", "Exception", "(", "'Words in topics are less than topk'", ")", "\n", "", "else", ":", "\n", "            ", "collect", "=", "[", "]", "\n", "for", "list1", ",", "list2", "in", "itertools", ".", "combinations", "(", "self", ".", "topics", ",", "2", ")", ":", "\n", "                ", "rbo_val", "=", "rbo", ".", "rbo", "(", "list1", "[", ":", "topk", "]", ",", "list2", "[", ":", "topk", "]", ",", "p", "=", "weight", ")", "[", "2", "]", "\n", "collect", ".", "append", "(", "rbo_val", ")", "\n", "", "return", "1", "-", "np", ".", "mean", "(", "collect", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.Matches.__init__": [[121, 132], ["len", "len", "Exception"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "doc_distribution_original_language", ",", "doc_distribution_unseen_language", ")", ":", "\n", "        ", "\"\"\"\n         :param doc_distribution_original_language: numpy array of the topical distribution of\n         the documents in the original language (dim: num docs x num topics)\n         :param doc_distribution_unseen_language: numpy array of the topical distribution of the\n          documents in an unseen language (dim: num docs x num topics)\n         \"\"\"", "\n", "self", ".", "orig_lang_docs", "=", "doc_distribution_original_language", "\n", "self", ".", "unseen_lang_docs", "=", "doc_distribution_unseen_language", "\n", "if", "len", "(", "self", ".", "orig_lang_docs", ")", "!=", "len", "(", "self", ".", "unseen_lang_docs", ")", ":", "\n", "            ", "raise", "Exception", "(", "'Distributions of the comparable documents must have the same length'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.Matches.score": [[133, 143], ["zip", "len", "numpy.argmax", "numpy.argmax"], "methods", ["None"], ["", "", "def", "score", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :return: proportion of matches between the predicted topic in the original language and\n        the predicted topic in the unseen language of the document distributions\n        \"\"\"", "\n", "matches", "=", "0", "\n", "for", "d1", ",", "d2", "in", "zip", "(", "self", ".", "orig_lang_docs", ",", "self", ".", "unseen_lang_docs", ")", ":", "\n", "            ", "if", "np", ".", "argmax", "(", "d1", ")", "==", "np", ".", "argmax", "(", "d2", ")", ":", "\n", "                ", "matches", "=", "matches", "+", "1", "\n", "", "", "return", "matches", "/", "len", "(", "self", ".", "unseen_lang_docs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.KLDivergence.__init__": [[146, 157], ["len", "len", "Exception"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "doc_distribution_original_language", ",", "doc_distribution_unseen_language", ")", ":", "\n", "        ", "\"\"\"\n         :param doc_distribution_original_language: numpy array of the topical distribution of \n         the documents in the original language (dim: num docs x num topics)\n         :param doc_distribution_unseen_language: numpy array of the topical distribution of the\n          documents in an unseen language (dim: num docs x num topics)\n         \"\"\"", "\n", "self", ".", "orig_lang_docs", "=", "doc_distribution_original_language", "\n", "self", ".", "unseen_lang_docs", "=", "doc_distribution_unseen_language", "\n", "if", "len", "(", "self", ".", "orig_lang_docs", ")", "!=", "len", "(", "self", ".", "unseen_lang_docs", ")", ":", "\n", "            ", "raise", "Exception", "(", "'Distributions of the comparable documents must have the same length'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.KLDivergence.score": [[158, 166], ["zip", "len", "measures.kl_div"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.kl_div"], ["", "", "def", "score", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :return: average kullback leibler divergence between the distributions\n        \"\"\"", "\n", "kl_mean", "=", "0", "\n", "for", "d1", ",", "d2", "in", "zip", "(", "self", ".", "orig_lang_docs", ",", "self", ".", "unseen_lang_docs", ")", ":", "\n", "            ", "kl_mean", "=", "kl_mean", "+", "kl_div", "(", "d1", ",", "d2", ")", "\n", "", "return", "kl_mean", "/", "len", "(", "self", ".", "unseen_lang_docs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CentroidDistance.__init__": [[175, 199], ["len", "len", "Exception", "gensim.load", "gensim.models.KeyedVectors.load_word2vec_format"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.models.ctm.CTM.load"], ["    ", "def", "__init__", "(", "self", ",", "doc_distribution_original_language", ",", "doc_distribution_unseen_language", ",", "topics", ",", "\n", "word2vec_path", "=", "None", ",", "binary", "=", "True", ",", "topk", "=", "10", ")", ":", "\n", "        ", "\"\"\"\n         :param doc_distribution_original_language: numpy array of the topical distribution of the\n         documents in the original language (dim: num docs x num topics)\n         :param doc_distribution_unseen_language: numpy array of the topical distribution of the\n         documents in an unseen language (dim: num docs x num topics)\n         :param topics: a list of lists of the top-n most likely words\n         :param word2vec_path: if word2vec_file is specified, it retrieves the word embeddings\n         file (in word2vec format) to compute similarities between words, otherwise\n         'word2vec-google-news-300' is downloaded\n         :param binary: if the word2vec file is binary\n         :param topk: max number of topical words\n         \"\"\"", "\n", "self", ".", "topics", "=", "[", "t", "[", ":", "topk", "]", "for", "t", "in", "topics", "]", "\n", "self", ".", "orig_lang_docs", "=", "doc_distribution_original_language", "\n", "self", ".", "unseen_lang_docs", "=", "doc_distribution_unseen_language", "\n", "if", "len", "(", "self", ".", "orig_lang_docs", ")", "!=", "len", "(", "self", ".", "unseen_lang_docs", ")", ":", "\n", "            ", "raise", "Exception", "(", "'Distributions of the comparable documents must have the same length'", ")", "\n", "\n", "", "if", "word2vec_path", "is", "None", ":", "\n", "            ", "self", ".", "wv", "=", "api", ".", "load", "(", "'word2vec-google-news-300'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "wv", "=", "KeyedVectors", ".", "load_word2vec_format", "(", "word2vec_path", ",", "binary", "=", "binary", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CentroidDistance.score": [[200, 215], ["zip", "measures.CentroidDistance.get_centroid", "measures.CentroidDistance.get_centroid", "len", "scipy.spatial.distance.cosine", "numpy.argmax", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CentroidDistance.get_centroid", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CentroidDistance.get_centroid"], ["", "", "def", "score", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :return: average centroid distance between the words of the most likely topic of the\n        document distributions\n        \"\"\"", "\n", "cd", "=", "0", "\n", "for", "d1", ",", "d2", "in", "zip", "(", "self", ".", "orig_lang_docs", ",", "self", ".", "unseen_lang_docs", ")", ":", "\n", "            ", "top_words_orig", "=", "self", ".", "topics", "[", "np", ".", "argmax", "(", "d1", ")", "]", "\n", "top_words_unseen", "=", "self", ".", "topics", "[", "np", ".", "argmax", "(", "d2", ")", "]", "\n", "\n", "centroid_lang", "=", "self", ".", "get_centroid", "(", "top_words_orig", ")", "\n", "centroid_en", "=", "self", ".", "get_centroid", "(", "top_words_unseen", ")", "\n", "\n", "cd", "+=", "(", "1", "-", "cosine", "(", "centroid_lang", ",", "centroid_en", ")", ")", "\n", "", "return", "cd", "/", "len", "(", "self", ".", "unseen_lang_docs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.CentroidDistance.get_centroid": [[216, 223], ["sum", "numpy.linalg.norm", "vector_list.append", "measures.CentroidDistance.wv.get_vector"], "methods", ["None"], ["", "def", "get_centroid", "(", "self", ",", "word_list", ")", ":", "\n", "        ", "vector_list", "=", "[", "]", "\n", "for", "word", "in", "word_list", ":", "\n", "            ", "if", "word", "in", "self", ".", "wv", ".", "vocab", ":", "\n", "                ", "vector_list", ".", "append", "(", "self", ".", "wv", ".", "get_vector", "(", "word", ")", ")", "\n", "", "", "vec", "=", "sum", "(", "vector_list", ")", "\n", "return", "vec", "/", "np", ".", "linalg", ".", "norm", "(", "vec", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.evaluation.measures.kl_div": [[168, 172], ["numpy.asarray", "numpy.asarray", "numpy.sum", "numpy.where", "numpy.log"], "function", ["None"], ["", "", "def", "kl_div", "(", "a", ",", "b", ")", ":", "\n", "    ", "a", "=", "np", ".", "asarray", "(", "a", ",", "dtype", "=", "np", ".", "float", ")", "\n", "b", "=", "np", ".", "asarray", "(", "b", ",", "dtype", "=", "np", ".", "float", ")", "\n", "return", "np", ".", "sum", "(", "np", ".", "where", "(", "a", "!=", "0", ",", "a", "*", "np", ".", "log", "(", "a", "/", "b", ")", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo._round": [[44, 49], ["isinstance", "RBO", "round", "rbo._round", "rbo._round", "rbo._round"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo._round", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo._round", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo._round"], ["def", "_round", "(", "obj", ")", ":", "\n", "    ", "if", "isinstance", "(", "obj", ",", "RBO", ")", ":", "\n", "        ", "return", "RBO", "(", "_round", "(", "obj", ".", "min", ")", ",", "_round", "(", "obj", ".", "res", ")", ",", "_round", "(", "obj", ".", "ext", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "round", "(", "obj", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.set_at_depth": [[51, 59], ["set", "isinstance", "set.update", "set.add"], "function", ["None"], ["", "", "def", "set_at_depth", "(", "lst", ",", "depth", ")", ":", "\n", "    ", "ans", "=", "set", "(", ")", "\n", "for", "v", "in", "lst", "[", ":", "depth", "]", ":", "\n", "        ", "if", "isinstance", "(", "v", ",", "set", ")", ":", "\n", "            ", "ans", ".", "update", "(", "v", ")", "\n", "", "else", ":", "\n", "            ", "ans", ".", "add", "(", "v", ")", "\n", "", "", "return", "ans", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.raw_overlap": [[61, 67], ["rbo.set_at_depth", "rbo.set_at_depth", "len", "len", "len", "set1.intersection"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.set_at_depth", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.set_at_depth"], ["", "def", "raw_overlap", "(", "list1", ",", "list2", ",", "depth", ")", ":", "\n", "    ", "\"\"\"Overlap as defined in the article.\n\n    \"\"\"", "\n", "set1", ",", "set2", "=", "set_at_depth", "(", "list1", ",", "depth", ")", ",", "set_at_depth", "(", "list2", ",", "depth", ")", "\n", "return", "len", "(", "set1", ".", "intersection", "(", "set2", ")", ")", ",", "len", "(", "set1", ")", ",", "len", "(", "set2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.overlap": [[69, 97], ["rbo.agreement", "min", "len", "len"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.agreement"], ["", "def", "overlap", "(", "list1", ",", "list2", ",", "depth", ")", ":", "\n", "    ", "\"\"\"Overlap which accounts for possible ties.\n\n    This isn't mentioned in the paper but should be used in the ``rbo*()``\n    functions below, otherwise overlap at a given depth might be > depth which\n    inflates the result.\n\n    There are no guidelines in the paper as to what's a good way to calculate\n    this, but a good guess is agreement scaled by the minimum between the\n    requested depth and the lengths of the considered lists (overlap shouldn't\n    be larger than the number of ranks in the shorter list, otherwise results\n    are conspicuously wrong when the lists are of unequal lengths -- rbo_ext is\n    not between rbo_min and rbo_min + rbo_res.\n\n    >>> overlap(\"abcd\", \"abcd\", 3)\n    3.0\n\n    >>> overlap(\"abcd\", \"abcd\", 5)\n    4.0\n\n    >>> overlap([\"a\", {\"b\", \"c\"}, \"d\"], [\"a\", {\"b\", \"c\"}, \"d\"], 2)\n    2.0\n\n    >>> overlap([\"a\", {\"b\", \"c\"}, \"d\"], [\"a\", {\"b\", \"c\"}, \"d\"], 3)\n    3.0\n\n    \"\"\"", "\n", "return", "agreement", "(", "list1", ",", "list2", ",", "depth", ")", "*", "min", "(", "depth", ",", "len", "(", "list1", ")", ",", "len", "(", "list2", ")", ")", "\n", "# NOTE: comment the preceding and uncomment the following line if you want", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.agreement": [[102, 121], ["rbo.raw_overlap"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.raw_overlap"], ["", "def", "agreement", "(", "list1", ",", "list2", ",", "depth", ")", ":", "\n", "    ", "\"\"\"Proportion of shared values between two sorted lists at given depth.\n\n    >>> _round(agreement(\"abcde\", \"abdcf\", 1))\n    1.0\n    >>> _round(agreement(\"abcde\", \"abdcf\", 3))\n    0.667\n    >>> _round(agreement(\"abcde\", \"abdcf\", 4))\n    1.0\n    >>> _round(agreement(\"abcde\", \"abdcf\", 5))\n    0.8\n    >>> _round(agreement([{1, 2}, 3], [1, {2, 3}], 1))\n    0.667\n    >>> _round(agreement([{1, 2}, 3], [1, {2, 3}], 2))\n    1.0\n\n    \"\"\"", "\n", "len_intersection", ",", "len_set1", ",", "len_set2", "=", "raw_overlap", "(", "list1", ",", "list2", ",", "depth", ")", "\n", "return", "2", "*", "len_intersection", "/", "(", "len_set1", "+", "len_set2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.cumulative_agreement": [[123, 125], ["rbo.agreement", "range"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.agreement"], ["", "def", "cumulative_agreement", "(", "list1", ",", "list2", ",", "depth", ")", ":", "\n", "    ", "return", "(", "agreement", "(", "list1", ",", "list2", ",", "d", ")", "for", "d", "in", "range", "(", "1", ",", "depth", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.average_overlap": [[127, 148], ["min", "sum", "len", "len", "rbo.cumulative_agreement"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.cumulative_agreement"], ["", "def", "average_overlap", "(", "list1", ",", "list2", ",", "depth", "=", "None", ")", ":", "\n", "    ", "\"\"\"Calculate average overlap between ``list1`` and ``list2``.\n\n    >>> _round(average_overlap(\"abcdefg\", \"zcavwxy\", 1))\n    0.0\n    >>> _round(average_overlap(\"abcdefg\", \"zcavwxy\", 2))\n    0.0\n    >>> _round(average_overlap(\"abcdefg\", \"zcavwxy\", 3))\n    0.222\n    >>> _round(average_overlap(\"abcdefg\", \"zcavwxy\", 4))\n    0.292\n    >>> _round(average_overlap(\"abcdefg\", \"zcavwxy\", 5))\n    0.313\n    >>> _round(average_overlap(\"abcdefg\", \"zcavwxy\", 6))\n    0.317\n    >>> _round(average_overlap(\"abcdefg\", \"zcavwxy\", 7))\n    0.312\n\n    \"\"\"", "\n", "depth", "=", "min", "(", "len", "(", "list1", ")", ",", "len", "(", "list2", ")", ")", "if", "depth", "is", "None", "else", "depth", "\n", "return", "sum", "(", "cumulative_agreement", "(", "list1", ",", "list2", ",", "depth", ")", ")", "/", "depth", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.rbo_at_k": [[150, 156], ["enumerate", "min", "rbo.cumulative_agreement", "sum", "len", "len"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.cumulative_agreement"], ["", "def", "rbo_at_k", "(", "list1", ",", "list2", ",", "p", ",", "depth", "=", "None", ")", ":", "\n", "# ``p**d`` here instead of ``p**(d - 1)`` because enumerate starts at", "\n", "# 0", "\n", "    ", "depth", "=", "min", "(", "len", "(", "list1", ")", ",", "len", "(", "list2", ")", ")", "if", "depth", "is", "None", "else", "depth", "\n", "d_a", "=", "enumerate", "(", "cumulative_agreement", "(", "list1", ",", "list2", ",", "depth", ")", ")", "\n", "return", "(", "1", "-", "p", ")", "*", "sum", "(", "p", "**", "d", "*", "a", "for", "(", "d", ",", "a", ")", "in", "d_a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.rbo_min": [[158, 176], ["rbo.overlap", "sum", "min", "math.log", "len", "len", "range", "rbo.overlap"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.overlap", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.overlap"], ["", "def", "rbo_min", "(", "list1", ",", "list2", ",", "p", ",", "depth", "=", "None", ")", ":", "\n", "    ", "\"\"\"Tight lower bound on RBO.\n\n    See equation (11) in paper.\n\n    >>> _round(rbo_min(\"abcdefg\", \"abcdefg\", .9))\n    0.767\n    >>> _round(rbo_min(\"abcdefgh\", \"abcdefg\", .9))\n    0.767\n\n    \"\"\"", "\n", "depth", "=", "min", "(", "len", "(", "list1", ")", ",", "len", "(", "list2", ")", ")", "if", "depth", "is", "None", "else", "depth", "\n", "x_k", "=", "overlap", "(", "list1", ",", "list2", ",", "depth", ")", "\n", "log_term", "=", "x_k", "*", "math", ".", "log", "(", "1", "-", "p", ")", "\n", "sum_term", "=", "sum", "(", "\n", "p", "**", "d", "/", "d", "*", "(", "overlap", "(", "list1", ",", "list2", ",", "d", ")", "-", "x_k", ")", "for", "d", "in", "range", "(", "1", ",", "depth", "+", "1", ")", "\n", ")", "\n", "return", "(", "1", "-", "p", ")", "/", "p", "*", "(", "sum_term", "-", "log_term", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.rbo_res": [[178, 204], ["sorted", "rbo.overlap", "int", "len", "len", "math.ceil", "sum", "sum", "math.log", "sum", "range", "range", "range"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.overlap"], ["", "def", "rbo_res", "(", "list1", ",", "list2", ",", "p", ")", ":", "\n", "    ", "\"\"\"Upper bound on residual overlap beyond evaluated depth.\n\n    See equation (30) in paper.\n\n    NOTE: The doctests weren't verified against manual computations but seem\n    plausible. In particular, for identical lists, ``rbo_min()`` and\n    ``rbo_res()`` should add up to 1, which is the case.\n\n    >>> _round(rbo_res(\"abcdefg\", \"abcdefg\", .9))\n    0.233\n    >>> _round(rbo_res(\"abcdefg\", \"abcdefghijklmnopqrstuvwxyz\", .9))\n    0.239\n\n    \"\"\"", "\n", "S", ",", "L", "=", "sorted", "(", "(", "list1", ",", "list2", ")", ",", "key", "=", "len", ")", "\n", "s", ",", "l", "=", "len", "(", "S", ")", ",", "len", "(", "L", ")", "\n", "x_l", "=", "overlap", "(", "list1", ",", "list2", ",", "l", ")", "\n", "# since overlap(...) can be fractional in the general case of ties and f", "\n", "# must be an integer --> math.ceil()", "\n", "f", "=", "int", "(", "math", ".", "ceil", "(", "l", "+", "s", "-", "x_l", ")", ")", "\n", "# upper bound of range() is non-inclusive, therefore + 1 is needed", "\n", "term1", "=", "s", "*", "sum", "(", "p", "**", "d", "/", "d", "for", "d", "in", "range", "(", "s", "+", "1", ",", "f", "+", "1", ")", ")", "\n", "term2", "=", "l", "*", "sum", "(", "p", "**", "d", "/", "d", "for", "d", "in", "range", "(", "l", "+", "1", ",", "f", "+", "1", ")", ")", "\n", "term3", "=", "x_l", "*", "(", "math", ".", "log", "(", "1", "/", "(", "1", "-", "p", ")", ")", "-", "sum", "(", "p", "**", "d", "/", "d", "for", "d", "in", "range", "(", "1", ",", "f", "+", "1", ")", ")", ")", "\n", "return", "p", "**", "s", "+", "p", "**", "l", "-", "p", "**", "f", "-", "(", "1", "-", "p", ")", "/", "p", "*", "(", "term1", "+", "term2", "+", "term3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.rbo_ext": [[206, 233], ["sorted", "rbo.overlap", "rbo.overlap", "sum", "sum", "len", "len", "rbo.agreement", "range", "range"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.overlap", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.overlap", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.agreement"], ["", "def", "rbo_ext", "(", "list1", ",", "list2", ",", "p", ")", ":", "\n", "    ", "\"\"\"RBO point estimate based on extrapolating observed overlap.\n\n    See equation (32) in paper.\n\n    NOTE: The doctests weren't verified against manual computations but seem\n    plausible.\n\n    >>> _round(rbo_ext(\"abcdefg\", \"abcdefg\", .9))\n    1.0\n    >>> _round(rbo_ext(\"abcdefg\", \"bacdefg\", .9))\n    0.9\n\n    \"\"\"", "\n", "S", ",", "L", "=", "sorted", "(", "(", "list1", ",", "list2", ")", ",", "key", "=", "len", ")", "\n", "s", ",", "l", "=", "len", "(", "S", ")", ",", "len", "(", "L", ")", "\n", "x_l", "=", "overlap", "(", "list1", ",", "list2", ",", "l", ")", "\n", "x_s", "=", "overlap", "(", "list1", ",", "list2", ",", "s", ")", "\n", "# the paper says overlap(..., d) / d, but it should be replaced by", "\n", "# agreement(..., d) defined as per equation (28) so that ties are handled", "\n", "# properly (otherwise values > 1 will be returned)", "\n", "# sum1 = sum(p**d * overlap(list1, list2, d)[0] / d for d in range(1, l + 1))", "\n", "sum1", "=", "sum", "(", "p", "**", "d", "*", "agreement", "(", "list1", ",", "list2", ",", "d", ")", "for", "d", "in", "range", "(", "1", ",", "l", "+", "1", ")", ")", "\n", "sum2", "=", "sum", "(", "p", "**", "d", "*", "x_s", "*", "(", "d", "-", "s", ")", "/", "s", "/", "d", "for", "d", "in", "range", "(", "s", "+", "1", ",", "l", "+", "1", ")", ")", "\n", "term1", "=", "(", "1", "-", "p", ")", "/", "p", "*", "(", "sum1", "+", "sum2", ")", "\n", "term2", "=", "p", "**", "l", "*", "(", "(", "x_l", "-", "x_s", ")", "/", "l", "+", "x_s", "/", "s", ")", "\n", "return", "term1", "+", "term2", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.rbo": [[235, 253], ["RBO", "ValueError", "rbo.rbo_min", "rbo.rbo_res", "rbo.rbo_ext"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.rbo_min", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.rbo_res", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.rbo_ext"], ["", "def", "rbo", "(", "list1", ",", "list2", ",", "p", ")", ":", "\n", "    ", "\"\"\"Complete RBO analysis (lower bound, residual, point estimate).\n\n    ``list`` arguments should be already correctly sorted iterables and each\n    item should either be an atomic value or a set of values tied for that\n    rank. ``p`` is the probability of looking for overlap at rank k + 1 after\n    having examined rank k.\n\n    >>> lst1 = [{\"c\", \"a\"}, \"b\", \"d\"]\n    >>> lst2 = [\"a\", {\"c\", \"b\"}, \"d\"]\n    >>> _round(rbo(lst1, lst2, p=.9))\n    RBO(min=0.489, res=0.477, ext=0.967)\n\n    \"\"\"", "\n", "if", "not", "0", "<=", "p", "<=", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"The ``p`` parameter must be between 0 and 1.\"", ")", "\n", "", "args", "=", "(", "list1", ",", "list2", ",", "p", ")", "\n", "return", "RBO", "(", "rbo_min", "(", "*", "args", ")", ",", "rbo_res", "(", "*", "args", ")", ",", "rbo_ext", "(", "*", "args", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.sort_dict": [[255, 293], ["dct.items", "bisect.bisect_left", "len", "scores.append", "items.append", "isinstance", "scores.insert", "items.insert", "existing_item.add"], "function", ["None"], ["", "def", "sort_dict", "(", "dct", ",", "*", ",", "ascending", "=", "False", ")", ":", "\n", "    ", "\"\"\"Sort keys in ``dct`` according to their corresponding values.\n\n    Sorts in descending order by default, because the values are\n    typically scores, i.e. the higher the better. Specify\n    ``ascending=True`` if the values are ranks, or some sort of score\n    where lower values are better.\n\n    Ties are handled by creating sets of tied keys at the given position\n    in the sorted list.\n\n    >>> dct = dict(a=1, b=2, c=1, d=3)\n    >>> list(sort_dict(dct)) == ['d', 'b', {'a', 'c'}]\n    True\n    >>> list(sort_dict(dct, ascending=True)) == [{'a', 'c'}, 'b', 'd']\n    True\n\n    \"\"\"", "\n", "scores", "=", "[", "]", "\n", "items", "=", "[", "]", "\n", "# items should be unique, scores don't have to", "\n", "for", "item", ",", "score", "in", "dct", ".", "items", "(", ")", ":", "\n", "        ", "if", "not", "ascending", ":", "\n", "            ", "score", "*=", "-", "1", "\n", "", "i", "=", "bisect_left", "(", "scores", ",", "score", ")", "\n", "if", "i", "==", "len", "(", "scores", ")", ":", "\n", "            ", "scores", ".", "append", "(", "score", ")", "\n", "items", ".", "append", "(", "item", ")", "\n", "", "elif", "scores", "[", "i", "]", "==", "score", ":", "\n", "            ", "existing_item", "=", "items", "[", "i", "]", "\n", "if", "isinstance", "(", "existing_item", ",", "set", ")", ":", "\n", "                ", "existing_item", ".", "add", "(", "item", ")", "\n", "", "else", ":", "\n", "                ", "items", "[", "i", "]", "=", "{", "existing_item", ",", "item", "}", "\n", "", "", "else", ":", "\n", "            ", "scores", ".", "insert", "(", "i", ",", "score", ")", "\n", "items", ".", "insert", "(", "i", ",", "item", ")", "\n", "", "", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.rbo_dict": [[295, 317], ["rbo.rbo", "rbo.sort_dict", "rbo.sort_dict"], "function", ["home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.rbo", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.sort_dict", "home.repos.pwc.inspect_result.aaronmueller_contextualized-topic-models.rbo.rbo.sort_dict"], ["", "def", "rbo_dict", "(", "dict1", ",", "dict2", ",", "p", ",", "*", ",", "sort_ascending", "=", "False", ")", ":", "\n", "    ", "\"\"\"Wrapper around ``rbo()`` for dict input.\n\n    Each dict maps items to be sorted to the score according to which\n    they should be sorted. The RBO analysis is then performed on the\n    resulting sorted lists.\n\n    The sort is descending by default, because scores are typically the\n    higher the better, but this can be overridden by specifying\n    ``sort_ascending=True``.\n\n    >>> dct1 = dict(a=1, b=2, c=1, d=3)\n    >>> dct2 = dict(a=1, b=2, c=2, d=3)\n    >>> _round(rbo_dict(dct1, dct2, p=.9, sort_ascending=True))\n    RBO(min=0.489, res=0.477, ext=0.967)\n\n    \"\"\"", "\n", "list1", ",", "list2", "=", "(", "\n", "sort_dict", "(", "dict1", ",", "ascending", "=", "sort_ascending", ")", ",", "\n", "sort_dict", "(", "dict2", ",", "ascending", "=", "sort_ascending", ")", ",", "\n", ")", "\n", "return", "rbo", "(", "list1", ",", "list2", ",", "p", ")", "\n", "\n"]]}