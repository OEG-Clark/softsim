{"home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.model_vgg.VGG_FeatureExtractor.__init__": [[22, 40], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "int", "int", "int", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.Synth12Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_channel", "=", "1", ",", "output_channel", "=", "512", ")", ":", "\n", "        ", "super", "(", "VGG_FeatureExtractor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_channel", "=", "[", "int", "(", "output_channel", "/", "8", ")", ",", "int", "(", "output_channel", "/", "4", ")", ",", "\n", "int", "(", "output_channel", "/", "2", ")", ",", "output_channel", "]", "# [64, 128, 256, 512]", "\n", "self", ".", "ConvNet", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "input_channel", ",", "self", ".", "output_channel", "[", "0", "]", ",", "3", ",", "1", ",", "1", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", ",", "# 64x16x50", "\n", "nn", ".", "Conv2d", "(", "self", ".", "output_channel", "[", "0", "]", ",", "self", ".", "output_channel", "[", "1", "]", ",", "3", ",", "1", ",", "1", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", ",", "# 128x8x25", "\n", "nn", ".", "Conv2d", "(", "self", ".", "output_channel", "[", "1", "]", ",", "self", ".", "output_channel", "[", "2", "]", ",", "3", ",", "1", ",", "1", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ",", "# 256x8x25", "\n", "nn", ".", "Conv2d", "(", "self", ".", "output_channel", "[", "2", "]", ",", "self", ".", "output_channel", "[", "2", "]", ",", "3", ",", "1", ",", "1", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "(", "2", ",", "1", ")", ",", "(", "2", ",", "1", ")", ")", ",", "# 256x4x25", "\n", "nn", ".", "Conv2d", "(", "self", ".", "output_channel", "[", "2", "]", ",", "self", ".", "output_channel", "[", "3", "]", ",", "3", ",", "1", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "output_channel", "[", "3", "]", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ",", "# 512x4x25", "\n", "nn", ".", "Conv2d", "(", "self", ".", "output_channel", "[", "3", "]", ",", "self", ".", "output_channel", "[", "3", "]", ",", "3", ",", "1", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "output_channel", "[", "3", "]", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "(", "2", ",", "1", ")", ",", "(", "2", ",", "1", ")", ")", ",", "# 512x2x25", "\n", "nn", ".", "Conv2d", "(", "self", ".", "output_channel", "[", "3", "]", ",", "self", ".", "output_channel", "[", "3", "]", ",", "2", ",", "1", ",", "0", ")", ",", "nn", ".", "ReLU", "(", "True", ")", ")", "# 512x1x24", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.model_vgg.VGG_FeatureExtractor.forward": [[41, 43], ["model_vgg.VGG_FeatureExtractor.ConvNet"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "self", ".", "ConvNet", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.model_vgg.VGGQuantized_FeatureExtractor.__init__": [[48, 70], ["torch.nn.Module.__init__", "torch.quantization.get_default_qat_qconfig", "torch.quantization.get_default_qat_qconfig", "torch.nn.Sequential", "torch.nn.Sequential", "torch.quantization.QuantStub", "torch.quantization.QuantStub", "torch.quantization.DeQuantStub", "torch.quantization.DeQuantStub", "int", "int", "int", "torch.nn.intrinsic.qat.ConvReLU2d", "torch.nn.intrinsic.qat.ConvReLU2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.intrinsic.qat.ConvReLU2d", "torch.nn.intrinsic.qat.ConvReLU2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.intrinsic.qat.ConvReLU2d", "torch.nn.intrinsic.qat.ConvReLU2d", "torch.nn.intrinsic.qat.ConvReLU2d", "torch.nn.intrinsic.qat.ConvReLU2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.intrinsic.qat.ConvBnReLU2d", "torch.nn.intrinsic.qat.ConvBnReLU2d", "torch.nn.intrinsic.qat.ConvBnReLU2d", "torch.nn.intrinsic.qat.ConvBnReLU2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.intrinsic.qat.ConvReLU2d", "torch.nn.intrinsic.qat.ConvReLU2d"], "methods", ["home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.Synth12Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_channel", "=", "1", ",", "output_channel", "=", "512", ",", "qatconfig", "=", "'fbgemm'", ")", ":", "\n", "        ", "super", "(", "VGGQuantized_FeatureExtractor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_channel", "=", "[", "int", "(", "output_channel", "/", "8", ")", ",", "int", "(", "output_channel", "/", "4", ")", ",", "\n", "int", "(", "output_channel", "/", "2", ")", ",", "output_channel", "]", "# [64, 128, 256, 512]", "\n", "\n", "self", ".", "qconfig", "=", "quantization", ".", "get_default_qat_qconfig", "(", "qatconfig", ")", "\n", "\n", "self", ".", "ConvNet", "=", "nn", ".", "Sequential", "(", "\n", "qat", ".", "ConvReLU2d", "(", "input_channel", ",", "self", ".", "output_channel", "[", "0", "]", ",", "3", ",", "1", ",", "1", ",", "qconfig", "=", "self", ".", "qconfig", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", ",", "# 64x16x50", "\n", "qat", ".", "ConvReLU2d", "(", "self", ".", "output_channel", "[", "0", "]", ",", "self", ".", "output_channel", "[", "1", "]", ",", "3", ",", "1", ",", "1", ",", "qconfig", "=", "self", ".", "qconfig", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", ",", "# 128x8x25", "\n", "qat", ".", "ConvReLU2d", "(", "self", ".", "output_channel", "[", "1", "]", ",", "self", ".", "output_channel", "[", "2", "]", ",", "3", ",", "1", ",", "1", ",", "qconfig", "=", "self", ".", "qconfig", ")", ",", "# 256x8x25", "\n", "qat", ".", "ConvReLU2d", "(", "self", ".", "output_channel", "[", "2", "]", ",", "self", ".", "output_channel", "[", "2", "]", ",", "3", ",", "1", ",", "1", ",", "qconfig", "=", "self", ".", "qconfig", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "(", "2", ",", "1", ")", ",", "(", "2", ",", "1", ")", ")", ",", "# 256x4x25", "\n", "qat", ".", "ConvBnReLU2d", "(", "self", ".", "output_channel", "[", "2", "]", ",", "self", ".", "output_channel", "[", "3", "]", ",", "3", ",", "1", ",", "1", ",", "bias", "=", "False", ",", "qconfig", "=", "self", ".", "qconfig", ")", ",", "# 512x4x25", "\n", "qat", ".", "ConvBnReLU2d", "(", "self", ".", "output_channel", "[", "3", "]", ",", "self", ".", "output_channel", "[", "3", "]", ",", "3", ",", "1", ",", "1", ",", "bias", "=", "False", ",", "qconfig", "=", "self", ".", "qconfig", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "(", "2", ",", "1", ")", ",", "(", "2", ",", "1", ")", ")", ",", "# 512x2x25", "\n", "qat", ".", "ConvReLU2d", "(", "self", ".", "output_channel", "[", "3", "]", ",", "self", ".", "output_channel", "[", "3", "]", ",", "2", ",", "1", ",", "0", ",", "qconfig", "=", "self", ".", "qconfig", ")", ")", "# 512x1x24", "\n", "\n", "self", ".", "quant", "=", "quantization", ".", "QuantStub", "(", ")", "\n", "self", ".", "dequant", "=", "quantization", ".", "DeQuantStub", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.model_vgg.VGGQuantized_FeatureExtractor.forward": [[71, 76], ["model_vgg.VGGQuantized_FeatureExtractor.quant", "model_vgg.VGGQuantized_FeatureExtractor.ConvNet", "model_vgg.VGGQuantized_FeatureExtractor.dequant"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "quant", "(", "x", ")", "\n", "x", "=", "self", ".", "ConvNet", "(", "x", ")", "\n", "x", "=", "self", ".", "dequant", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.model_vgg.BidirectionalLSTM.__init__": [[141, 146], ["torch.nn.Module.__init__", "torch.nn.LSTM", "torch.nn.LSTM"], "methods", ["home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.Synth12Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "hidden_size", ")", ":", "\n", "        ", "super", "(", "BidirectionalLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "out_channels", "=", "hidden_size", "*", "2", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "in_channels", ",", "hidden_size", ",", "bidirectional", "=", "True", ",", "num_layers", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.model_vgg.BidirectionalLSTM.forward": [[147, 156], ["x.permute.permute.squeeze", "x.permute.permute.permute", "model_vgg.BidirectionalLSTM.lstm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "C", ",", "H", ",", "W", "=", "x", ".", "shape", "\n", "assert", "H", "==", "1", ",", "\"the height of conv must be 1\"", "\n", "x", "=", "x", ".", "squeeze", "(", "axis", "=", "2", ")", "\n", "x", "=", "x", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "# (NTC)(width, batch, channels)", "\n", "x", ",", "_", "=", "self", ".", "lstm", "(", "x", ")", "\n", "\n", "#print(\"Output size: \" + str(x.shape))", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.model_vgg.CRNN.__init__": [[161, 181], ["torch.nn.Module.__init__", "model_vgg.BidirectionalLSTM", "torch.nn.Linear", "torch.nn.Linear", "model_vgg.VGG_FeatureExtractor", "model_vgg.VGGQuantized_FeatureExtractor", "torch.quantization.prepare_qat", "torch.quantization.prepare_qat", "model_vgg.CRNN._initialize_weights", "model_vgg.CRNN._initialize_weights_qat"], "methods", ["home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.Synth12Dataset.__init__", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.model_vgg.CRNN._initialize_weights", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.model_vgg.CRNN._initialize_weights_qat"], ["    ", "def", "__init__", "(", "self", ",", "nclass", ",", "hidden_size", "=", "256", ",", "qatconfig", "=", "None", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "CRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "#VGG backbone", "\n", "if", "qatconfig", "is", "None", ":", "\n", "            ", "self", ".", "backbone", "=", "VGG_FeatureExtractor", "(", ")", "\n", "\n", "", "else", ":", "\n", "# Quantization aware training config", "\n", "            ", "self", ".", "backbone", "=", "VGGQuantized_FeatureExtractor", "(", "qatconfig", "=", "qatconfig", ")", "\n", "self", ".", "backbone", "=", "quantization", ".", "prepare_qat", "(", "self", ".", "backbone", ")", "\n", "\n", "#importing rnn", "\n", "", "self", ".", "rnn", "=", "BidirectionalLSTM", "(", "512", ",", "hidden_size", ")", "\n", "self", ".", "embedding", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", ",", "nclass", ",", "bias", "=", "bias", ")", "\n", "\n", "if", "qatconfig", "is", "None", ":", "\n", "            ", "self", ".", "_initialize_weights", "(", "bias", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_initialize_weights_qat", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.model_vgg.CRNN.forward": [[183, 201], ["x.view.view.float", "model_vgg.CRNN.backbone", "model_vgg.CRNN.rnn", "x.view.view.size", "x.view.view.view", "model_vgg.CRNN.embedding", "x.view.view.view"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "#print(input.shape)", "\n", "        ", "x", "=", "x", ".", "float", "(", ")", "\n", "\n", "# conv features", "\n", "x", "=", "self", ".", "backbone", "(", "x", ")", "\n", "x", "=", "self", ".", "rnn", "(", "x", ")", "\n", "#print(\"RNN output shape: \" + str(x.shape))", "\n", "\n", "T", ",", "b", ",", "h", "=", "x", ".", "size", "(", ")", "\n", "x", "=", "x", ".", "view", "(", "T", "*", "b", ",", "h", ")", "\n", "x", "=", "self", ".", "embedding", "(", "x", ")", "# [T * b, nOut]", "\n", "#print(\"Embedding output shape: \" + str(x.shape))", "\n", "x", "=", "x", ".", "view", "(", "T", ",", "b", ",", "-", "1", ")", "\n", "#print(\"Output size: \" + str(x.shape))", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.model_vgg.CRNN._initialize_weights": [[202, 215], ["model_vgg.CRNN.named_modules", "isinstance", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "isinstance", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.ones_", "torch.nn.init.ones_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "isinstance", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.zeros_", "torch.nn.init.zeros_"], "methods", ["None"], ["", "def", "_initialize_weights", "(", "self", ",", "bias", "=", "True", ")", ":", "\n", "        ", "for", "name", ",", "m", "in", "self", ".", "named_modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "ones_", "(", "m", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "0", ",", "0.01", ")", "\n", "if", "name", "!=", "\"embedding\"", "or", "(", "name", "==", "\"embedding\"", "and", "bias", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.model_vgg.CRNN._initialize_weights_qat": [[216, 225], ["model_vgg.CRNN.modules", "isinstance", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "isinstance", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.zeros_", "torch.nn.init.zeros_"], "methods", ["None"], ["", "", "", "", "def", "_initialize_weights_qat", "(", "self", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "(", "qat", ".", "ConvReLU2d", ",", "qat", ".", "ConvBnReLU2d", ")", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "0", ",", "0.01", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.model_vgg.get_crnn": [[228, 231], ["model_vgg.CRNN"], "function", ["None"], ["", "", "", "", "def", "get_crnn", "(", "n_class", ",", "qatconfig", "=", "None", ",", "bias", "=", "True", ")", ":", "\n", "\n", "    ", "return", "CRNN", "(", "n_class", ",", "qatconfig", "=", "qatconfig", ",", "bias", "=", "bias", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train.train": [[138, 342], ["torch.lr_scheduler.CosineAnnealingWarmRestarts", "range", "student_model.train", "print", "enumerate", "optim.lr_scheduler.CosineAnnealingWarmRestarts.step", "print", "print", "utils_common2.recognition_metrics", "print", "print", "print", "print", "print", "print", "print", "print", "pandas.DataFrame", "pd.DataFrame.to_csv", "train.validate", "optim.lr_scheduler.CosineAnnealingWarmRestarts.step", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "tqdm.tqdm", "inp.to.to", "inp.to.size", "idx.detach().numpy", "list", "utils_common2.get_padded_labels", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "labels.detach().numpy.to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.to", "criterion", "criterion.item", "optimizer.zero_grad", "criterion.backward", "optimizer.step", "preds.transpose().contiguous().detach().cpu().numpy.max", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach().cpu().numpy", "labels.detach().numpy.detach().numpy", "range", "open", "zip", "sklearn.metrics.classification_report", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "print", "print", "print", "print", "print", "print", "pandas.DataFrame", "student_model.state_dict", "inp.to.float", "student_model", "len", "utils_common2.decode_prediction", "zip", "utils_common2.decode_prediction", "utils_common2.decode_prediction", "pred_.append", "label_.append", "fout.write", "fout.write", "fout.write", "fout.write", "pandas.ExcelWriter", "pandas.DataFrame().T.sort_values().to_excel", "open", "zip", "print", "idx.detach", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach().cpu", "labels.detach().numpy.detach", "y_pred.append", "y_true.append", "numpy.arange", "fout.write", "fout.write", "fout.write", "fout.write", "preds.transpose().contiguous().detach().cpu().numpy.size", "pandas.DataFrame().T.sort_values", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach", "len", "inv_grapheme_dict.items", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous", "pandas.DataFrame", "preds.transpose().contiguous().detach().cpu().numpy.transpose"], "function", ["home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train_student3.train", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.recognition_metrics", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train_student3.validate", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.get_padded_labels", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction"], ["def", "train", "(", "epochs", "=", "30", ",", "lr", "=", "0.001", ")", ":", "\n", "\n", "    ", "\"\"\"\n    During Quantization Aware Training, the LR should be 1-10% of the LR used for training without quantization\n    \"\"\"", "\n", "\n", "#optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr, momentum=0.9, dampening=0, weight_decay=1e-05)", "\n", "\n", "\n", "# https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html", "\n", "# new_lr = lr * factor", "\n", "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.9, patience=2, threshold=0.01, min_lr=0.0001, verbose=True)", "\n", "# scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[7, 25], gamma=0.5, verbose=True)", "\n", "scheduler", "=", "optim", ".", "lr_scheduler", ".", "CosineAnnealingWarmRestarts", "(", "optimizer", ",", "T_0", "=", "15", ",", "T_mult", "=", "1", ",", "eta_min", "=", "0.0001", ")", "\n", "#early_stopping = EarlyStopping(patience=10, verbose=True)", "\n", "\n", "for", "epoch", "in", "range", "(", "0", ",", "100", ")", ":", "\n", "\n", "        ", "student_model", ".", "train", "(", ")", "\n", "\n", "\n", "#necessary variables", "\n", "y_true", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "pred_", "=", "[", "]", "\n", "label_", "=", "[", "]", "\n", "\n", "total_wer", "=", "0", "\n", "\n", "print", "(", "\"***Epoch: {}***\"", ".", "format", "(", "epoch", ")", ")", "\n", "batch_loss", "=", "0", "\n", "#lr = 0.002", "\n", "alpha", "=", "0.3", "\n", "for", "i", ",", "(", "inp", ",", "img_names", ",", "idx", ")", "in", "enumerate", "(", "tqdm", "(", "train_loader", ")", ")", ":", "\n", "\n", "\n", "            ", "inp", "=", "inp", ".", "to", "(", "device", ")", "\n", "inp", "=", "inp", ".", "float", "(", ")", "/", "255.", "\n", "batch_size", "=", "inp", ".", "size", "(", "0", ")", "\n", "idxs", "=", "idx", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "img_names", "=", "list", "(", "img_names", ")", "\n", "#print(idxs)", "\n", "#print(labels_tr)", "\n", "words", ",", "labels", ",", "labels_size", "=", "get_padded_labels", "(", "idxs", ",", "words_tr", ",", "labels_tr", ",", "lengths_tr", ")", "\n", "#print(words)", "\n", "#print(labels)", "\n", "#print(inp.shape)", "\n", "\n", "#teacher_preds = pred_teacher(teacher_model,labels)", "\n", "#teacher_preds = teacher_preds.cuda()", "\n", "#teacher_preds = teacher_model(inp)", "\n", "#teacher_preds.to(device) ", "\n", "#print(teacher_preds.shape)", "\n", "#print(teacher_preds[3][0][0])", "\n", "#soft_targets = F.log_softmax(teacher_preds /3)", "\n", "#print(soft_targets.shape)", "\n", "#print(teacher_preds)", "\n", "\n", "preds", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "student_model", "(", "inp", ")", ",", "dim", "=", "2", ")", "\n", "#preds = torch.nn.functional.log_softmax(model(inp), dim=2)", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "labels", ".", "to", "(", "device", ")", "\n", "labels_size", "=", "torch", ".", "tensor", "(", "labels_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "labels_size", ".", "to", "(", "device", ")", "\n", "preds_size", "=", "torch", ".", "tensor", "(", "[", "preds", ".", "size", "(", "0", ")", "]", "*", "batch_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "preds_size", ".", "to", "(", "device", ")", "\n", "\n", "#np_arr = preds.cpu().detach().numpy()", "\n", "#preds = torch.from_numpy(np_arr)", "\n", "\n", "#print(preds.shape)", "\n", "#print(preds[3][0][0])", "\n", "#soft_preds = F.log_softmax(preds / 3)", "\n", "#print(soft_preds.shape)", "\n", "\n", "#kl_div_loss = F.kl_div(soft_preds, soft_targets)", "\n", "\n", "\n", "loss", "=", "criterion", "(", "preds", ",", "labels", ",", "preds_size", ",", "labels_size", ")", "\n", "\n", "#ctc_loss = criterion(preds, labels, preds_size, labels_size)", "\n", "\n", "#loss = ((1 - alpha) * ctc_loss)  +  (alpha * kl_div_loss  * (3** 2))", "\n", "#print(loss.item())", "\n", "batch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "_", ",", "preds", "=", "preds", ".", "max", "(", "2", ")", "\n", "preds", "=", "preds", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "labels", "=", "labels", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "preds", ")", ")", ":", "\n", "                ", "decoded", ",", "_", "=", "decode_prediction", "(", "preds", "[", "i", "]", ",", "inv_grapheme_dict", ")", "\n", "for", "x", ",", "y", "in", "zip", "(", "decoded", ",", "labels", "[", "i", "]", ")", ":", "\n", "                    ", "y_pred", ".", "append", "(", "x", ")", "\n", "#print(x)", "\n", "#print('t')", "\n", "#print(y)", "\n", "y_true", ".", "append", "(", "y", ")", "\n", "", "_", ",", "decoded_pred_", "=", "decode_prediction", "(", "preds", "[", "i", "]", ",", "inv_grapheme_dict", ")", "\n", "#print(inv_grapheme_dict)", "\n", "_", ",", "decoded_label_", "=", "decode_prediction", "(", "labels", "[", "i", "]", ",", "inv_grapheme_dict", ",", "gt", "=", "True", ")", "\n", "#print(decoded_label_)", "\n", "\n", "pred_", ".", "append", "(", "decoded_pred_", ")", "\n", "\n", "label_", ".", "append", "(", "decoded_label_", ")", "\n", "#print(pred_)", "\n", "\n", "", "", "scheduler", ".", "step", "(", ")", "\n", "\n", "train_loss", "=", "batch_loss", "/", "train_batch_s", "\n", "print", "(", "\"Epoch Training loss: \"", ",", "train_loss", ")", "#batch_size denominator 32", "\n", "\n", "print", "(", "\"\\n\"", ")", "\n", "rec_results", "=", "recognition_metrics", "(", "pred_", ",", "label_", ",", "file_name", "=", "\"results.csv\"", ")", "\n", "print", "(", "'\\n'", ")", "\n", "#print(pred_)", "\n", "#print(label_)", "\n", "print", "(", "\"Absolute Word Match Count: %d\"", "%", "rec_results", "[", "'abs_match'", "]", ")", "\n", "print", "(", "\"Word Recognition Rate (WRR): %.4f\"", "%", "rec_results", "[", "'wrr'", "]", ")", "\n", "print", "(", "\"Normal Edit Distance (NED): %.4f\"", "%", "rec_results", "[", "'total_ned'", "]", ")", "\n", "print", "(", "\"Character Recognition Rate (CRR): %.4f\"", "%", "rec_results", "[", "'crr'", "]", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "print", "(", "\"End of Epoch \"", ",", "epoch", ")", "\n", "print", "(", "\"\\n\\n\"", ")", "\n", "\n", "with", "open", "(", "\"./bnhtrdtrain/init3/results_training.txt\"", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "for", "x", ",", "y", "in", "zip", "(", "pred_", ",", "label_", ")", ":", "\n", "                ", "fout", ".", "write", "(", "\"True: {}\"", ".", "format", "(", "y", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "fout", ".", "write", "(", "\"Pred: {}\"", ".", "format", "(", "x", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "", "", "metrics", "=", "pd", ".", "DataFrame", "(", "[", "{", "'epoch'", ":", "epoch", ",", "\n", "'crr'", ":", "rec_results", "[", "'crr'", "]", ",", "\n", "'wrr'", ":", "rec_results", "[", "'wrr'", "]", ",", "\n", "'ned'", ":", "rec_results", "[", "'total_ned'", "]", ",", "\n", "'abs_match'", ":", "rec_results", "[", "'abs_match'", "]", ",", "\n", "'train_loss'", ":", "train_loss", "\n", "}", "]", ")", "\n", "\n", "metrics", ".", "to_csv", "(", "\"./bnhtrdtrain/init3/metrics_training.csv\"", ",", "\n", "mode", "=", "(", "'w'", "if", "epoch", "==", "0", "else", "'a'", ")", ",", "index", "=", "False", ",", "header", "=", "(", "True", "if", "epoch", "==", "0", "else", "False", ")", ")", "\n", "\n", "\n", "#change in number of labels", "\n", "try", ":", "\n", "            ", "report", "=", "classification_report", "(", "y_true", ",", "y_pred", ",", "labels", "=", "np", ".", "arange", "(", "1", ",", "len", "(", "inv_grapheme_dict", ")", "+", "1", ")", ",", "\n", "zero_division", "=", "0", ",", "output_dict", "=", "True", ",", "target_names", "=", "[", "v", "for", "k", ",", "v", "in", "inv_grapheme_dict", ".", "items", "(", ")", "]", ")", "\n", "f1_micro", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'micro'", ",", "zero_division", "=", "0", ")", "\n", "f1_macro", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'macro'", ",", "zero_division", "=", "0", ")", "\n", "accuracy", "=", "accuracy_score", "(", "y_true", ",", "y_pred", ")", "\n", "\n", "#Absolute word matching", "\n", "#abs_correct = absolute_word_match(pred_, label_)", "\n", "\n", "#print(\"Absolute Word Match Count: {}\".format(abs_correct))", "\n", "#print(\"Absolute Word Match Percentage: %.4f\" % (abs_correct / num_train_samples))", "\n", "print", "(", "\"Training Accuracy: %.4f\"", "%", "accuracy", ")", "\n", "print", "(", "\"Training F1 Micro Score: %.4f\"", "%", "f1_micro", ")", "\n", "print", "(", "\"Training F1 Macro Score: %.4f\"", "%", "f1_macro", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "print", "(", "\"End of Training FOR Epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "print", "(", "\"\\n\\n\"", ")", "\n", "\n", "##################### Generate Training Report ##############################", "\n", "\n", "with", "pd", ".", "ExcelWriter", "(", "\"./bnhtrdtrain/init3/classification_report_training.xlsx\"", ",", "engine", "=", "'openpyxl'", ",", "mode", "=", "(", "'w'", "if", "epoch", "==", "0", "else", "'a'", ")", ")", "as", "writer", ":", "\n", "                ", "pd", ".", "DataFrame", "(", "report", ")", ".", "T", ".", "sort_values", "(", "by", "=", "'support'", ",", "ascending", "=", "False", ")", ".", "to_excel", "(", "writer", ",", "sheet_name", "=", "'epoch{}'", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "", "with", "open", "(", "\"./bnhtrdtrain/init3/results_training.txt\"", ",", "'w'", ")", "as", "fout", ":", "\n", "                ", "for", "x", ",", "y", "in", "zip", "(", "pred_", ",", "label_", ")", ":", "\n", "                    ", "fout", ".", "write", "(", "\"True: {}\"", ".", "format", "(", "y", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "fout", ".", "write", "(", "\"Pred: {}\"", ".", "format", "(", "x", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "", "", "metrics", "=", "pd", ".", "DataFrame", "(", "[", "{", "'epoch'", ":", "epoch", ",", "\n", "'accuracy'", ":", "accuracy", ",", "\n", "'train_loss'", ":", "train_loss", ",", "\n", "\n", "'f1_micro'", ":", "f1_micro", ",", "\n", "'f1_macro'", ":", "f1_macro", ",", "\n", "\n", "}", "]", ")", "\n", "\n", "", "except", ":", "\n", "            ", "print", "(", "'error'", ")", "\n", "\n", "#############################################################################", "\n", "\n", "\n", "", "valid_loss", "=", "validate", "(", "epoch", ",", "valid_batch_s", ",", "train_loss", ")", "\n", "#early_stopping(valid_loss, student_model)", "\n", "\n", "#if early_stopping.early_stop:", "\n", "#print(\"Early stopping\")", "\n", "#break", "\n", "\n", "scheduler", ".", "step", "(", ")", "\n", "torch", ".", "save", "(", "student_model", ".", "state_dict", "(", ")", ",", "'./bnhtrdtrain/init3/epoch{}.pth'", ".", "format", "(", "epoch", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train.validate": [[343, 488], ["student_model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "print", "enumerate", "print", "print", "utils_common2.recognition_metrics", "print", "print", "print", "print", "print", "print", "print", "print", "pandas.DataFrame", "pd.DataFrame.to_csv", "sklearn.metrics.accuracy_score", "print", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "print", "print", "print", "print", "print", "print", "tqdm.tqdm", "inp.to.to", "inp.to.size", "idx.detach().numpy", "list", "utils_common2.get_padded_labels", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "labels.detach().numpy.to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.to", "criterion", "criterion.item", "preds.transpose().contiguous().detach().cpu().numpy.max", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach().cpu().numpy", "labels.detach().numpy.detach().numpy", "range", "open", "zip", "sklearn.metrics.classification_report", "pandas.DataFrame", "inp.to.float", "student_model", "len", "utils_common2.decode_prediction", "zip", "utils_common2.decode_prediction", "utils_common2.decode_prediction", "pred_.append", "label_.append", "fout.write", "fout.write", "fout.write", "fout.write", "print", "pandas.ExcelWriter", "pandas.DataFrame().T.sort_values().to_excel", "open", "zip", "print", "idx.detach", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach().cpu", "labels.detach().numpy.detach", "y_pred.append", "y_true.append", "numpy.arange", "fout.write", "fout.write", "fout.write", "fout.write", "preds.transpose().contiguous().detach().cpu().numpy.size", "pandas.DataFrame().T.sort_values", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach", "len", "inv_grapheme_dict.items", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous", "pandas.DataFrame", "preds.transpose().contiguous().detach().cpu().numpy.transpose"], "function", ["home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.recognition_metrics", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.get_padded_labels", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction"], ["", "", "def", "validate", "(", "epoch", ",", "valid_batch_s", ",", "train_loss", ")", ":", "\n", "\n", "# evaluate model:", "\n", "    ", "student_model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y_true", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "pred_", "=", "[", "]", "\n", "label_", "=", "[", "]", "\n", "\n", "total_wer", "=", "0", "\n", "\n", "print", "(", "\"***Epoch: {}***\"", ".", "format", "(", "epoch", ")", ")", "\n", "batch_loss", "=", "0", "\n", "for", "i", ",", "(", "inp", ",", "img_names", ",", "idx", ")", "in", "enumerate", "(", "tqdm", "(", "validation_loader", ")", ")", ":", "\n", "\n", "            ", "inp", "=", "inp", ".", "to", "(", "device", ")", "\n", "inp", "=", "inp", ".", "float", "(", ")", "/", "255.", "\n", "batch_size", "=", "inp", ".", "size", "(", "0", ")", "\n", "idxs", "=", "idx", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "img_names", "=", "list", "(", "img_names", ")", "\n", "words", ",", "labels", ",", "labels_size", "=", "get_padded_labels", "(", "idxs", ",", "words_val", ",", "labels_val", ",", "lengths_val", ")", "\n", "\n", "preds", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "student_model", "(", "inp", ")", ",", "dim", "=", "2", ")", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "labels", ".", "to", "(", "device", ")", "\n", "labels_size", "=", "torch", ".", "tensor", "(", "labels_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "labels_size", ".", "to", "(", "device", ")", "\n", "preds_size", "=", "torch", ".", "tensor", "(", "[", "preds", ".", "size", "(", "0", ")", "]", "*", "batch_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "preds_size", ".", "to", "(", "device", ")", "\n", "\n", "#validation loss", "\n", "loss", "=", "criterion", "(", "preds", ",", "labels", ",", "preds_size", ",", "labels_size", ")", "\n", "#print(loss)", "\n", "batch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "#print(loss.item())", "\n", "\n", "_", ",", "preds", "=", "preds", ".", "max", "(", "2", ")", "\n", "preds", "=", "preds", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "labels", "=", "labels", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "preds", ")", ")", ":", "\n", "                ", "decoded", ",", "_", "=", "decode_prediction", "(", "preds", "[", "i", "]", ",", "inv_grapheme_dict", ")", "\n", "for", "x", ",", "y", "in", "zip", "(", "decoded", ",", "labels", "[", "i", "]", ")", ":", "\n", "                    ", "y_pred", ".", "append", "(", "x", ")", "\n", "y_true", ".", "append", "(", "y", ")", "\n", "", "_", ",", "decoded_pred_", "=", "decode_prediction", "(", "preds", "[", "i", "]", ",", "inv_grapheme_dict", ")", "\n", "#print(inv_grapheme_dict)", "\n", "_", ",", "decoded_label_", "=", "decode_prediction", "(", "labels", "[", "i", "]", ",", "inv_grapheme_dict", ",", "gt", "=", "True", ")", "\n", "#print(decoded_label_)", "\n", "\n", "pred_", ".", "append", "(", "decoded_pred_", ")", "\n", "label_", ".", "append", "(", "decoded_label_", ")", "\n", "\n", "", "", "valid_loss", "=", "batch_loss", "/", "valid_batch_s", "\n", "print", "(", "\"Epoch Validation loss: \"", ",", "valid_loss", ")", "#batch_size denominator 32", "\n", "print", "(", "\"\\n\"", ")", "\n", "rec_results", "=", "recognition_metrics", "(", "pred_", ",", "label_", ",", "file_name", "=", "\"results.csv\"", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "#print(pred_)", "\n", "#print(label_)", "\n", "print", "(", "\"Absolute Word Match Count: %d\"", "%", "rec_results", "[", "'abs_match'", "]", ")", "\n", "print", "(", "\"Word Recognition Rate (WRR): %.4f\"", "%", "rec_results", "[", "'wrr'", "]", ")", "\n", "print", "(", "\"Normal Edit Distance (NED): %.4f\"", "%", "rec_results", "[", "'total_ned'", "]", ")", "\n", "print", "(", "\"Character Recognition Rate (CRR): %.4f\"", "%", "rec_results", "[", "'crr'", "]", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "print", "(", "\"End of Epoch \"", ",", "epoch", ")", "\n", "print", "(", "\"\\n\\n\"", ")", "\n", "\n", "with", "open", "(", "\"./bnhtrdtrain/init3/results_validation.txt\"", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "for", "x", ",", "y", "in", "zip", "(", "pred_", ",", "label_", ")", ":", "\n", "                ", "fout", ".", "write", "(", "\"True: {}\"", ".", "format", "(", "y", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "fout", ".", "write", "(", "\"Pred: {}\"", ".", "format", "(", "x", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "", "", "metrics", "=", "pd", ".", "DataFrame", "(", "[", "{", "'epoch'", ":", "epoch", ",", "\n", "'crr'", ":", "rec_results", "[", "'crr'", "]", ",", "\n", "'wrr'", ":", "rec_results", "[", "'wrr'", "]", ",", "\n", "'ned'", ":", "rec_results", "[", "'total_ned'", "]", ",", "\n", "'abs_match'", ":", "rec_results", "[", "'abs_match'", "]", ",", "\n", "'train_loss'", ":", "train_loss", "\n", "}", "]", ")", "\n", "\n", "metrics", ".", "to_csv", "(", "\"./bnhtrdtrain/init3/metrics_validation.csv\"", ",", "\n", "mode", "=", "(", "'w'", "if", "epoch", "==", "0", "else", "'a'", ")", ",", "index", "=", "False", ",", "header", "=", "(", "True", "if", "epoch", "==", "0", "else", "False", ")", ")", "\n", "\n", "\n", "accuracy", "=", "accuracy_score", "(", "y_true", ",", "y_pred", ")", "\n", "print", "(", "'accuracy '", ",", "accuracy", ")", "\n", "\n", "#change in number of labels", "\n", "try", ":", "\n", "            ", "report", "=", "classification_report", "(", "y_true", ",", "y_pred", ",", "labels", "=", "np", ".", "arange", "(", "1", ",", "len", "(", "inv_grapheme_dict", ")", "+", "1", ")", ",", "\n", "zero_division", "=", "0", ",", "output_dict", "=", "True", ",", "target_names", "=", "[", "v", "for", "k", ",", "v", "in", "inv_grapheme_dict", ".", "items", "(", ")", "]", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "'error'", ")", "\n", "", "f1_micro", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'micro'", ",", "zero_division", "=", "0", ")", "\n", "f1_macro", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'macro'", ",", "zero_division", "=", "0", ")", "\n", "accuracy", "=", "accuracy_score", "(", "y_true", ",", "y_pred", ")", "\n", "\n", "\n", "#Absolute word matching", "\n", "#abs_correct = absolute_word_match(pred_, label_)", "\n", "\n", "#print(\"Absolute Word Match Count: {}\".format(abs_correct))", "\n", "#print(\"Abs Match Percentage: %.4f\" % (abs_correct / num_valid_samples))", "\n", "print", "(", "\"Accuracy: %.4f\"", "%", "accuracy", ")", "\n", "print", "(", "\"F1 Micro Score: %.4f\"", "%", "f1_micro", ")", "\n", "print", "(", "\"F1 Macro Score: %.4f\"", "%", "f1_macro", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "print", "(", "\"End of Epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "print", "(", "\"\\n\\n\"", ")", "\n", "\n", "##################### Generate Validation Report ##############################", "\n", "try", ":", "\n", "            ", "with", "pd", ".", "ExcelWriter", "(", "\"./bnhtrdtrain/init2/classification_report_validation.xlsx\"", ",", "engine", "=", "'openpyxl'", ",", "mode", "=", "(", "'w'", "if", "epoch", "==", "0", "else", "'a'", ")", ")", "as", "writer", ":", "\n", "                ", "pd", ".", "DataFrame", "(", "report", ")", ".", "T", ".", "sort_values", "(", "by", "=", "'support'", ",", "ascending", "=", "False", ")", ".", "to_excel", "(", "writer", ",", "sheet_name", "=", "'epoch{}'", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "", "with", "open", "(", "\"./bnhtrdtrain/init3/results_validation.txt\"", ",", "'w'", ")", "as", "fout", ":", "\n", "                ", "for", "x", ",", "y", "in", "zip", "(", "pred_", ",", "label_", ")", ":", "\n", "                    ", "fout", ".", "write", "(", "\"True: {}\"", ".", "format", "(", "y", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "fout", ".", "write", "(", "\"Pred: {}\"", ".", "format", "(", "x", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "", "", "metrics", "=", "pd", ".", "DataFrame", "(", "[", "{", "'epoch'", ":", "epoch", ",", "\n", "'accuracy'", ":", "accuracy", ",", "\n", "'train_loss'", ":", "train_loss", ",", "\n", "'valid_loss'", ":", "valid_loss", ",", "\n", "\n", "'f1_micro'", ":", "f1_micro", ",", "\n", "'f1_macro'", ":", "f1_macro", "\n", "\n", "}", "]", ")", "\n", "# metrics.to_csv(\"./bnhtrdtrain/init3/metrics_validation.csv\", ", "\n", "#                mode=('w' if epoch==0 else 'a'), index=False, header=(True if epoch==0 else False))", "\n", "\n", "", "except", ":", "\n", "            ", "print", "(", "'error'", ")", "\n", "\n", "###############################################################################", "\n", "\n", "", "return", "valid_loss", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.normalize_word": [[10, 29], ["word.replace.replace", "word.replace.replace", "word.replace.replace", "word.replace.replace", "word.replace.replace", "word.replace.replace", "word.replace.replace", "word.replace.replace", "word.replace.replace"], "function", ["None"], ["def", "normalize_word", "(", "word", ")", ":", "\n", "\n", "    ", "if", "'\u09c7\u09be'", "in", "word", ":", "word", "=", "word", ".", "replace", "(", "'\u09c7\u09be'", ",", "'\u09cb'", ")", "\n", "\n", "if", "'\u09d7'", "in", "word", ":", "\n", "        ", "if", "'\u09c7\u09d7'", "in", "word", ":", "word", "=", "word", ".", "replace", "(", "'\u09c7\u09d7'", ",", "'\u09cc'", ")", "\n", "else", ":", "word", "=", "word", ".", "replace", "(", "'\u09d7'", ",", "'\u09c0'", ")", "# '\u09d7' without '\u09c7' is replaced by '\u09c0'", "\n", "\n", "", "if", "'\u09bc'", "in", "word", ":", "\n", "        ", "if", "'\u09ac\u09bc'", "in", "word", ":", "word", "=", "word", ".", "replace", "(", "'\u09ac\u09bc'", ",", "'\u09b0'", ")", "\n", "if", "'\u09af\u09bc'", "in", "word", ":", "word", "=", "word", ".", "replace", "(", "'\u09af\u09bc'", ",", "'\u09df'", ")", "\n", "if", "'\u09a1\u09bc'", "in", "word", ":", "word", "=", "word", ".", "replace", "(", "'\u09a1\u09bc'", ",", "'\u09dc'", ")", "\n", "if", "'\u09a2\u09bc'", "in", "word", ":", "word", "=", "word", ".", "replace", "(", "'\u09a2\u09bc'", ",", "'\u09dd'", ")", "\n", "if", "'\u09bc'", "in", "word", ":", "word", "=", "word", ".", "replace", "(", "'\u09bc'", ",", "''", ")", "# discard any other '\u09bc' without '\u09ac'/'\u09af'/'\u09a1'/'\u09a2'", "\n", "\n", "# visually similar '\u09f7' (Bengali Currency Numerator Four) is replaced by '\u0964' (Devanagari Danda)", "\n", "", "if", "'\u09f7'", "in", "word", ":", "word", "=", "word", ".", "replace", "(", "'\u09f7'", ",", "'\u0964'", ")", "\n", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.ads_grapheme_extraction": [[33, 126], ["len", "chars.append", "len", "chars.append", "chars.append", "chars.append", "len", "chars.append", "chars.append", "len", "chars.append", "len", "len", "len", "chars.append", "chars.append", "chars.append", "len", "len", "chars.append", "len"], "function", ["None"], ["", "def", "ads_grapheme_extraction", "(", "word", ")", ":", "\n", "\n", "    ", "forms_cluster", "=", "{", "'\u0995'", ":", "[", "'\u0995'", ",", "'\u099f'", ",", "'\u09a4'", ",", "'\u09a8'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b0'", ",", "'\u09b2'", ",", "'\u09b7'", ",", "'\u09b8'", "]", ",", "\n", "'\u0997'", ":", "[", "'\u0997'", ",", "'\u09a7'", ",", "'\u09a8'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b2'", "]", ",", "\n", "'\u0998'", ":", "[", "'\u09a8'", "]", ",", "\n", "'\u0999'", ":", "[", "'\u0995'", ",", "'\u0996'", ",", "'\u0997'", ",", "'\u0998'", ",", "'\u09ae'", "]", ",", "\n", "'\u099a'", ":", "[", "'\u099a'", ",", "'\u099b'", ",", "'\u099e'", "]", ",", "\n", "'\u099c'", ":", "[", "'\u099c'", ",", "'\u099d'", ",", "'\u099e'", ",", "'\u09ac'", "]", ",", "\n", "'\u099e'", ":", "[", "'\u099a'", ",", "'\u099b'", ",", "'\u099c'", ",", "'\u099d'", "]", ",", "\n", "'\u099f'", ":", "[", "'\u099f'", ",", "'\u09ac'", "]", ",", "\n", "'\u09a1'", ":", "[", "'\u09a1'", "]", ",", "\n", "'\u09a3'", ":", "[", "'\u099f'", ",", "'\u09a0'", ",", "'\u09a1'", ",", "'\u09a2'", ",", "'\u09a3'", ",", "'\u09ac'", ",", "'\u09ae'", "]", ",", "\n", "'\u09a4'", ":", "[", "'\u09a4'", ",", "'\u09a5'", ",", "'\u09a8'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b0'", "]", ",", "\n", "'\u09a5'", ":", "[", "'\u09ac'", "]", ",", "\n", "'\u09a6'", ":", "[", "'\u0997'", ",", "'\u0998'", ",", "'\u09a6'", ",", "'\u09a7'", ",", "'\u09ac'", ",", "'\u09ad'", ",", "'\u09ae'", "]", ",", "\n", "'\u09a7'", ":", "[", "'\u09a8'", ",", "'\u09ac'", "]", ",", "\n", "'\u09a8'", ":", "[", "'\u099c'", ",", "'\u099f'", ",", "'\u09a0'", ",", "'\u09a1'", ",", "'\u09a4'", ",", "'\u09a5'", ",", "'\u09a6'", ",", "'\u09a7'", ",", "'\u09a8'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b8'", "]", ",", "\n", "'\u09aa'", ":", "[", "'\u099f'", ",", "'\u09a4'", ",", "'\u09a8'", ",", "'\u09aa'", ",", "'\u09b2'", ",", "'\u09b8'", "]", ",", "\n", "'\u09ab'", ":", "[", "'\u099f'", ",", "'\u09b2'", "]", ",", "\n", "'\u09ac'", ":", "[", "'\u099c'", ",", "'\u09a6'", ",", "'\u09a7'", ",", "'\u09ac'", ",", "'\u09ad'", ",", "'\u09b2'", "]", ",", "\n", "'\u09ad'", ":", "[", "'\u09b0'", "]", ",", "\n", "'\u09ae'", ":", "[", "'\u09a8'", ",", "'\u09aa'", ",", "'\u09ab'", ",", "'\u09ac'", ",", "'\u09ad'", ",", "'\u09ae'", ",", "'\u09b2'", "]", ",", "\n", "'\u09b2'", ":", "[", "'\u0995'", ",", "'\u0997'", ",", "'\u099f'", ",", "'\u09a1'", ",", "'\u09aa'", ",", "'\u09ab'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b2'", ",", "'\u09b8'", "]", ",", "\n", "'\u09b6'", ":", "[", "'\u099a'", ",", "'\u099b'", ",", "'\u09a4'", ",", "'\u09a8'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b2'", "]", ",", "\n", "'\u09b7'", ":", "[", "'\u0995'", ",", "'\u099f'", ",", "'\u09a0'", ",", "'\u09a3'", ",", "'\u09aa'", ",", "'\u09ab'", ",", "'\u09ac'", ",", "'\u09ae'", "]", ",", "\n", "'\u09b8'", ":", "[", "'\u0995'", ",", "'\u0996'", ",", "'\u099f'", ",", "'\u09a4'", ",", "'\u09a5'", ",", "'\u09a8'", ",", "'\u09aa'", ",", "'\u09ab'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b2'", "]", ",", "\n", "'\u09b9'", ":", "[", "'\u09a3'", ",", "'\u09a8'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b2'", "]", ",", "\n", "'\u09a1\u09bc'", ":", "[", "'\u0997'", "]", "}", "\n", "\n", "forms_tripple_cluster", "=", "{", "'\u0995\u09cd\u09b7'", ":", "[", "'\u09a3'", ",", "'\u09ae'", "]", ",", "'\u0999\u09cd\u0995'", ":", "[", "'\u09b7'", "]", ",", "'\u099a\u09cd\u099b'", ":", "[", "'\u09ac'", "]", ",", "'\u099c\u09cd\u099c'", ":", "[", "'\u09ac'", "]", ",", "\n", "'\u09a4\u09cd\u09a4'", ":", "[", "'\u09ac'", "]", ",", "'\u09a6\u09cd\u09a6'", ":", "[", "'\u09ac'", "]", ",", "'\u09a6\u09cd\u09a7'", ":", "[", "'\u09ac'", "]", ",", "'\u09a6\u09cd\u09ad'", ":", "[", "'\u09b0'", "]", ",", "\n", "'\u09a8\u09cd\u09a4'", ":", "[", "'\u09ac'", "]", ",", "'\u09a8\u09cd\u09a6'", ":", "[", "'\u09ac'", "]", ",", "'\u09ae\u09cd\u09aa'", ":", "[", "'\u09b2'", "]", ",", "'\u09ae\u09cd\u09ad'", ":", "[", "'\u09b0'", "]", ",", "\n", "'\u09b7\u09cd\u0995'", ":", "[", "'\u09b0'", "]", ",", "'\u09b8\u09cd\u0995'", ":", "[", "'\u09b0'", "]", ",", "'\u09b8\u09cd\u09a4'", ":", "[", "'\u09ac'", ",", "'\u09b0'", "]", ",", "'\u09b8\u09cd\u09aa'", ":", "[", "'\u09b2'", "]", "}", "\n", "\n", "chars", "=", "[", "]", "\n", "i", "=", "0", "\n", "adjust", "=", "0", "\n", "\n", "while", "(", "i", "<", "len", "(", "word", ")", ")", ":", "\n", "        ", "if", "i", "+", "1", "<", "len", "(", "word", ")", "and", "word", "[", "i", "+", "1", "]", "==", "'\u09cd'", ":", "\n", "            ", "if", "word", "[", "i", "]", "==", "'\u09b0'", ":", "\n", "                ", "chars", ".", "append", "(", "'\u09b0\u09cd'", ")", "\n", "adjust", "=", "0", "\n", "i", "+=", "2", "\n", "", "elif", "i", "+", "2", "<", "len", "(", "word", ")", "and", "word", "[", "i", "+", "2", "]", "==", "'\u09af'", ":", "\n", "                ", "chars", ".", "append", "(", "word", "[", "i", "-", "adjust", ":", "i", "+", "1", "]", ")", "\n", "chars", ".", "append", "(", "'\u09cd\u09af'", ")", "\n", "adjust", "=", "0", "\n", "i", "+=", "3", "\n", "", "elif", "i", "+", "2", "<", "len", "(", "word", ")", "and", "word", "[", "i", "+", "2", "]", "==", "'\u09b0'", ":", "\n", "# Treat '\u09cd\u09b0' as a seperate grapheme", "\n", "                ", "chars", ".", "append", "(", "word", "[", "i", "-", "adjust", ":", "i", "+", "1", "]", ")", "\n", "chars", ".", "append", "(", "'\u09cd\u09b0'", ")", "\n", "# Keep '\u09cd\u09b0' icluded in the cluster", "\n", "# chars.append(word[i-adjust:i+3])", "\n", "if", "i", "+", "3", "<", "len", "(", "word", ")", "and", "word", "[", "i", "+", "3", "]", "==", "'\u09cd'", "and", "i", "+", "4", "<", "len", "(", "word", ")", "and", "word", "[", "i", "+", "4", "]", "==", "'\u09af'", ":", "\n", "                    ", "chars", ".", "append", "(", "'\u09cd\u09af'", ")", "\n", "i", "+=", "5", "\n", "", "else", ":", "\n", "                    ", "i", "+=", "3", "\n", "", "adjust", "=", "0", "\n", "", "elif", "i", "+", "2", "<", "len", "(", "word", ")", "and", "adjust", "!=", "0", "and", "word", "[", "i", "-", "adjust", ":", "i", "+", "1", "]", "in", "forms_tripple_cluster", "and", "word", "[", "i", "+", "2", "]", "in", "forms_tripple_cluster", "[", "word", "[", "i", "-", "adjust", ":", "i", "+", "1", "]", "]", ":", "\n", "                ", "if", "i", "+", "3", "<", "len", "(", "word", ")", "and", "word", "[", "i", "+", "3", "]", "==", "'\u09cd'", ":", "\n", "                    ", "adjust", "+=", "2", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "chars", ".", "append", "(", "word", "[", "i", "-", "adjust", ":", "i", "+", "3", "]", ")", "\n", "adjust", "=", "0", "\n", "i", "+=", "3", "\n", "", "", "elif", "i", "+", "2", "<", "len", "(", "word", ")", "and", "adjust", "==", "0", "and", "word", "[", "i", "]", "in", "forms_cluster", "and", "word", "[", "i", "+", "2", "]", "in", "forms_cluster", "[", "word", "[", "i", "]", "]", ":", "\n", "                ", "if", "i", "+", "3", "<", "len", "(", "word", ")", "and", "word", "[", "i", "+", "3", "]", "==", "'\u09cd'", ":", "\n", "                    ", "adjust", "+=", "2", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "chars", ".", "append", "(", "word", "[", "i", "-", "adjust", ":", "i", "+", "3", "]", ")", "\n", "adjust", "=", "0", "\n", "i", "+=", "3", "\n", "", "", "else", ":", "\n", "                ", "chars", ".", "append", "(", "word", "[", "i", "-", "adjust", ":", "i", "+", "1", "]", ")", "\n", "chars", ".", "append", "(", "'\u09cd'", ")", "\n", "adjust", "=", "0", "\n", "i", "+=", "2", "\n", "\n", "", "", "else", ":", "\n", "            ", "chars", ".", "append", "(", "word", "[", "i", ":", "i", "+", "1", "]", ")", "\n", "i", "+=", "1", "\n", "\n", "\n", "#print(word)", "\n", "#print(chars)", "\n", "\n", "", "", "return", "chars", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.vds_grapheme_extraction": [[129, 233], ["len", "chars.append", "len", "len", "chars.append", "chars.append", "chars.append", "len", "chars.append", "chars.append", "chars.append", "len", "len", "chars.append", "len"], "function", ["None"], ["", "def", "vds_grapheme_extraction", "(", "word", ")", ":", "\n", "\n", "    ", "consonants", "=", "[", "'\u0995'", ",", "'\u0996'", ",", "'\u0997'", ",", "'\u0998'", ",", "'\u0999'", ",", "'\u099a'", ",", "'\u099b'", ",", "'\u099c'", ",", "'\u099d'", ",", "'\u099e'", ",", "'\u099f'", ",", "'\u09a0'", ",", "'\u09a1'", ",", "'\u09a2'", ",", "'\u09a3'", ",", "'\u09a4'", ",", "'\u09a5'", ",", "'\u09a6'", ",", "\n", "'\u09a7'", ",", "'\u09a8'", ",", "'\u09aa'", ",", "'\u09ab'", ",", "'\u09ac'", ",", "'\u09ad'", ",", "'\u09ae'", ",", "'\u09af'", ",", "'\u09b0'", ",", "'\u09b2'", ",", "'\u09b6'", ",", "'\u09b7'", ",", "'\u09b8'", ",", "'\u09b9'", ",", "'\u09a1\u09bc'", ",", "'\u09a2\u09bc'", ",", "'\u09af\u09bc'", "]", "\n", "\n", "forms_cluster", "=", "{", "'\u0995'", ":", "[", "'\u0995'", ",", "'\u099f'", ",", "'\u09a4'", ",", "'\u09a8'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b0'", ",", "'\u09b2'", ",", "'\u09b7'", ",", "'\u09b8'", "]", ",", "\n", "'\u0996'", ":", "[", "'\u09b0'", "]", ",", "\n", "'\u0997'", ":", "[", "'\u0997'", ",", "'\u09a7'", ",", "'\u09a8'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b0'", ",", "'\u09b2'", "]", ",", "\n", "'\u0998'", ":", "[", "'\u09a8'", ",", "'\u09b0'", "]", ",", "\n", "'\u0999'", ":", "[", "'\u0995'", ",", "'\u0996'", ",", "'\u0997'", ",", "'\u0998'", ",", "'\u09ae'", ",", "'\u09b0'", "]", ",", "\n", "'\u099a'", ":", "[", "'\u099a'", ",", "'\u099b'", ",", "'\u099e'", ",", "'\u09b0'", "]", ",", "\n", "'\u099b'", ":", "[", "'\u09b0'", "]", ",", "\n", "'\u099c'", ":", "[", "'\u099c'", ",", "'\u099d'", ",", "'\u099e'", ",", "'\u09ac'", ",", "'\u09b0'", "]", ",", "\n", "'\u099d'", ":", "[", "'\u09b0'", "]", ",", "\n", "'\u099e'", ":", "[", "'\u099a'", ",", "'\u099b'", ",", "'\u099c'", ",", "'\u099d'", ",", "'\u09b0'", "]", ",", "\n", "'\u099f'", ":", "[", "'\u099f'", ",", "'\u09ac'", ",", "'\u09b0'", "]", ",", "\n", "'\u09a0'", ":", "[", "'\u09b0'", "]", ",", "\n", "'\u09a1'", ":", "[", "'\u09a1'", ",", "'\u09b0'", "]", ",", "\n", "'\u09a2'", ":", "[", "'\u09b0'", "]", ",", "\n", "'\u09a3'", ":", "[", "'\u099f'", ",", "'\u09a0'", ",", "'\u09a1'", ",", "'\u09a2'", ",", "'\u09a3'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b0'", "]", ",", "\n", "'\u09a4'", ":", "[", "'\u09a4'", ",", "'\u09a5'", ",", "'\u09a8'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b0'", "]", ",", "\n", "'\u09a5'", ":", "[", "'\u09ac'", ",", "'\u09b0'", "]", ",", "\n", "'\u09a6'", ":", "[", "'\u0997'", ",", "'\u0998'", ",", "'\u09a6'", ",", "'\u09a7'", ",", "'\u09ac'", ",", "'\u09ad'", ",", "'\u09ae'", ",", "'\u09b0'", "]", ",", "\n", "'\u09a7'", ":", "[", "'\u09a8'", ",", "'\u09ac'", ",", "'\u09b0'", "]", ",", "\n", "'\u09a8'", ":", "[", "'\u099c'", ",", "'\u099f'", ",", "'\u09a0'", ",", "'\u09a1'", ",", "'\u09a4'", ",", "'\u09a5'", ",", "'\u09a6'", ",", "'\u09a7'", ",", "'\u09a8'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b0'", ",", "'\u09b8'", "]", ",", "\n", "'\u09aa'", ":", "[", "'\u099f'", ",", "'\u09a4'", ",", "'\u09a8'", ",", "'\u09aa'", ",", "'\u09b2'", ",", "'\u09b0'", ",", "'\u09b8'", "]", ",", "\n", "'\u09ab'", ":", "[", "'\u099f'", ",", "'\u09b0'", ",", "'\u09b2'", "]", ",", "\n", "'\u09ac'", ":", "[", "'\u099c'", ",", "'\u09a6'", ",", "'\u09a7'", ",", "'\u09ac'", ",", "'\u09ad'", ",", "'\u09b0'", ",", "'\u09b2'", "]", ",", "\n", "'\u09ad'", ":", "[", "'\u09b0'", "]", ",", "\n", "'\u09ae'", ":", "[", "'\u09a8'", ",", "'\u09aa'", ",", "'\u09ab'", ",", "'\u09ac'", ",", "'\u09ad'", ",", "'\u09ae'", ",", "'\u09b0'", ",", "'\u09b2'", "]", ",", "\n", "'\u09af'", ":", "[", "'\u09b0'", "]", ",", "\n", "'\u09b0'", ":", "[", "'\u0995'", ",", "'\u0996'", ",", "'\u0997'", ",", "'\u0998'", ",", "'\u0999'", ",", "'\u099a'", ",", "'\u099b'", ",", "'\u099c'", ",", "'\u099d'", ",", "'\u099e'", ",", "'\u099f'", ",", "'\u09a0'", ",", "'\u09a1'", ",", "'\u09a2'", ",", "'\u09a3'", ",", "'\u09a4'", ",", "'\u09a5'", ",", "'\u09a6'", ",", "\n", "'\u09a7'", ",", "'\u09a8'", ",", "'\u09aa'", ",", "'\u09ab'", ",", "'\u09ac'", ",", "'\u09ad'", ",", "'\u09ae'", ",", "'\u09af'", ",", "'\u09b0'", ",", "'\u09b2'", ",", "'\u09b6'", ",", "'\u09b7'", ",", "'\u09b8'", ",", "'\u09b9'", ",", "'\u09dc'", ",", "'\u09dd'", ",", "'\u09df'", "]", ",", "\n", "'\u09b2'", ":", "[", "'\u0995'", ",", "'\u0997'", ",", "'\u099f'", ",", "'\u09a1'", ",", "'\u09aa'", ",", "'\u09ab'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b0'", ",", "'\u09b2'", ",", "'\u09b8'", "]", ",", "\n", "'\u09b6'", ":", "[", "'\u099a'", ",", "'\u099b'", ",", "'\u09a4'", ",", "'\u09a8'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b0'", ",", "'\u09b2'", "]", ",", "\n", "'\u09b7'", ":", "[", "'\u0995'", ",", "'\u099f'", ",", "'\u09a0'", ",", "'\u09a3'", ",", "'\u09aa'", ",", "'\u09ab'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b0'", "]", ",", "\n", "'\u09b8'", ":", "[", "'\u0995'", ",", "'\u0996'", ",", "'\u099f'", ",", "'\u09a4'", ",", "'\u09a5'", ",", "'\u09a8'", ",", "'\u09aa'", ",", "'\u09ab'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b0'", ",", "'\u09b2'", "]", ",", "\n", "'\u09b9'", ":", "[", "'\u09a3'", ",", "'\u09a8'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b0'", ",", "'\u09b2'", "]", ",", "\n", "'\u09dc'", ":", "[", "'\u0997'", ",", "'\u09b0'", "]", ",", "\n", "'\u09dd'", ":", "[", "'\u09b0'", "]", ",", "\n", "'\u09df'", ":", "[", "'\u09b0'", "]", "}", "\n", "\n", "\n", "forms_tripple_cluster", "=", "{", "'\u0995\u09cd\u099f'", ":", "[", "'\u09b0'", "]", ",", "'\u0995\u09cd\u09a4'", ":", "[", "'\u09b0'", "]", ",", "'\u0995\u09cd\u09b7'", ":", "[", "'\u09a3'", ",", "'\u09ae'", ",", "'\u09b0'", "]", ",", "'\u0999\u09cd\u0995'", ":", "[", "'\u09b7'", ",", "'\u09b0'", "]", ",", "'\u099a\u09cd\u099b'", ":", "[", "'\u09ac'", ",", "'\u09b0'", "]", ",", "'\u099c\u09cd\u099c'", ":", "[", "'\u09ac'", "]", ",", "\n", "'\u09a3\u09cd\u09a1'", ":", "[", "'\u09b0'", "]", ",", "'\u09a4\u09cd\u09a4'", ":", "[", "'\u09ac'", "]", ",", "'\u09a6\u09cd\u09a6'", ":", "[", "'\u09ac'", "]", ",", "'\u09a6\u09cd\u09a7'", ":", "[", "'\u09ac'", "]", ",", "'\u09a6\u09cd\u09ad'", ":", "[", "'\u09b0'", "]", ",", "'\u09a8\u09cd\u099f'", ":", "[", "'\u09b0'", "]", ",", "'\u09a8\u09cd\u09a1'", ":", "[", "'\u09b0'", "]", ",", "'\u09a8\u09cd\u09a4'", ":", "[", "'\u09ac'", ",", "'\u09b0'", "]", ",", "\n", "'\u09a8\u09cd\u09a6'", ":", "[", "'\u09ac'", ",", "'\u09b0'", "]", ",", "'\u09a8\u09cd\u09a7'", ":", "[", "'\u09b0'", "]", ",", "'\u09ae\u09cd\u09aa'", ":", "[", "'\u09b0'", ",", "'\u09b2'", "]", ",", "'\u09ae\u09cd\u09ad'", ":", "[", "'\u09b0'", "]", ",", "\n", "'\u09b7\u09cd\u0995'", ":", "[", "'\u09b0'", "]", ",", "'\u09b8\u09cd\u0995'", ":", "[", "'\u09b0'", "]", ",", "'\u09b7\u09cd\u099f'", ":", "[", "'\u09b0'", "]", ",", "'\u09b8\u09cd\u099f'", ":", "[", "'\u09b0'", "]", ",", "'\u09b8\u09cd\u09a4'", ":", "[", "'\u09ac'", ",", "'\u09b0'", "]", ",", "'\u09b7\u09cd\u09aa'", ":", "[", "'\u09b0'", "]", ",", "'\u09b8\u09cd\u09aa'", ":", "[", "'\u09b0'", ",", "'\u09b2'", "]", ",", "\n", "# refs", "\n", "'\u09b0\u09cd\u0995'", ":", "[", "'\u09b0'", ",", "'\u099f'", ",", "'\u09a4'", ",", "'\u09b2'", ",", "'\u09b7'", ",", "'\u09b8'", "]", ",", "'\u09b0\u09cd\u0996'", ":", "[", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u0997'", ":", "[", "'\u09ac'", ",", "'\u09b2'", ",", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u0998'", ":", "[", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u0999'", ":", "[", "'\u0995'", ",", "'\u0997'", ",", "'\u09b0'", "]", ",", "\n", "'\u09b0\u09cd\u099a'", ":", "[", "'\u099a'", ",", "'\u099b'", ",", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u099b'", ":", "[", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u099c'", ":", "[", "'\u099c'", ",", "'\u099e'", ",", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u099d'", ":", "[", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u099e'", ":", "[", "'\u099c'", ",", "'\u09b0'", "]", ",", "\n", "'\u09b0\u09cd\u099f'", ":", "[", "'\u099f'", ",", "'\u09ae'", ",", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09a0'", ":", "[", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09a1'", ":", "[", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09a2'", ":", "[", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09a3'", ":", "[", "'\u09a1'", ",", "'\u09a8'", ",", "'\u09b0'", "]", ",", "\n", "'\u09b0\u09cd\u09a4'", ":", "[", "'\u09a4'", ",", "'\u09a5'", ",", "'\u09a8'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09a5'", ":", "[", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09a6'", ":", "[", "'\u099c'", ",", "'\u09a5'", ",", "'\u09a6'", ",", "'\u09a7'", ",", "'\u09ac'", ",", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09a7'", ":", "[", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b0'", "]", ",", "\n", "'\u09b0\u09cd\u09a8'", ":", "[", "'\u099f'", ",", "'\u09a1'", ",", "'\u09a4'", ",", "'\u09a6'", ",", "'\u09a8'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b8'", ",", "'\u09b0'", "]", ",", "\n", "'\u09b0\u09cd\u09aa'", ":", "[", "'\u0995'", ",", "'\u09aa'", ",", "'\u09b8'", ",", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09ab'", ":", "[", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09ac'", ":", "[", "'\u099c'", ",", "'\u09ac'", ",", "'\u09b2'", ",", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09ad'", ":", "[", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09ae'", ":", "[", "'\u09aa'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b0'", "]", ",", "\n", "'\u09b0\u09cd\u09af'", ":", "[", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09b0'", ":", "[", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09b2'", ":", "[", "'\u09b0'", ",", "'\u099f'", ",", "'\u09a1'", ",", "'\u09b8'", "]", ",", "'\u09b0\u09cd\u09b6'", ":", "[", "'\u099a'", ",", "'\u09a8'", ",", "'\u09ac'", ",", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09b7'", ":", "[", "'\u0995'", ",", "'\u099f'", ",", "'\u09a3'", ",", "'\u09aa'", ",", "'\u09ae'", ",", "'\u09b0'", "]", ",", "\n", "'\u09b0\u09cd\u09b8'", ":", "[", "'\u0995'", ",", "'\u099a'", ",", "'\u099f'", ",", "'\u09a4'", ",", "'\u09a5'", ",", "'\u09aa'", ",", "'\u09ab'", ",", "'\u09ac'", ",", "'\u09ae'", ",", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09b9'", ":", "[", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09a1\u09bc'", ":", "[", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09a2\u09bc'", ":", "[", "'\u09b0'", "]", ",", "'\u09b0\u09cd\u09af\u09bc'", ":", "[", "'\u09b0'", "]", "}", "\n", "\n", "\n", "chars", "=", "[", "]", "\n", "i", "=", "0", "\n", "adjust", "=", "0", "\n", "\n", "while", "(", "i", "<", "len", "(", "word", ")", ")", ":", "\n", "        ", "if", "i", "+", "1", "<", "len", "(", "word", ")", "and", "word", "[", "i", "+", "1", "]", "==", "'\u09cd'", ":", "\n", "            ", "if", "i", "+", "2", "<", "len", "(", "word", ")", "and", "word", "[", "i", "+", "2", "]", "==", "'\u09af'", ":", "\n", "                ", "if", "word", "[", "i", "]", "in", "consonants", ":", "\n", "                    ", "chars", ".", "append", "(", "word", "[", "i", "-", "adjust", ":", "i", "+", "3", "]", ")", "\n", "", "else", ":", "\n", "                    ", "chars", ".", "append", "(", "word", "[", "i", "-", "adjust", ":", "i", "+", "1", "]", ")", "\n", "chars", ".", "append", "(", "'\u09cd\u09af'", ")", "\n", "", "adjust", "=", "0", "\n", "i", "+=", "3", "\n", "", "elif", "i", "+", "2", "<", "len", "(", "word", ")", "and", "adjust", "!=", "0", "and", "word", "[", "i", "-", "adjust", ":", "i", "+", "1", "]", "in", "forms_tripple_cluster", "and", "word", "[", "i", "+", "2", "]", "in", "forms_tripple_cluster", "[", "word", "[", "i", "-", "adjust", ":", "i", "+", "1", "]", "]", ":", "\n", "                ", "if", "i", "+", "3", "<", "len", "(", "word", ")", "and", "word", "[", "i", "+", "3", "]", "==", "'\u09cd'", ":", "\n", "                    ", "adjust", "+=", "2", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "chars", ".", "append", "(", "word", "[", "i", "-", "adjust", ":", "i", "+", "3", "]", ")", "\n", "adjust", "=", "0", "\n", "i", "+=", "3", "\n", "", "", "elif", "i", "+", "2", "<", "len", "(", "word", ")", "and", "adjust", "==", "0", "and", "word", "[", "i", "]", "in", "forms_cluster", "and", "word", "[", "i", "+", "2", "]", "in", "forms_cluster", "[", "word", "[", "i", "]", "]", ":", "\n", "                ", "if", "i", "+", "3", "<", "len", "(", "word", ")", "and", "word", "[", "i", "+", "3", "]", "==", "'\u09cd'", ":", "\n", "                    ", "adjust", "+=", "2", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "chars", ".", "append", "(", "word", "[", "i", "-", "adjust", ":", "i", "+", "3", "]", ")", "\n", "adjust", "=", "0", "\n", "i", "+=", "3", "\n", "", "", "else", ":", "\n", "                ", "chars", ".", "append", "(", "word", "[", "i", "-", "adjust", ":", "i", "+", "1", "]", ")", "\n", "chars", ".", "append", "(", "'\u09cd'", ")", "\n", "adjust", "=", "0", "\n", "i", "+=", "2", "\n", "\n", "", "", "else", ":", "\n", "            ", "chars", ".", "append", "(", "word", "[", "i", ":", "i", "+", "1", "]", ")", "\n", "i", "+=", "1", "\n", "\n", "\n", "#print(word)", "\n", "#print(chars)", "\n", "\n", "", "", "return", "chars", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.naive_grapheme_extraction": [[237, 240], ["list"], "function", ["None"], ["", "def", "naive_grapheme_extraction", "(", "word", ")", ":", "\n", "\n", "    ", "return", "list", "(", "word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.preproc_apurba_data": [[243, 279], ["pandas.read_csv", "print", "tqdm.tqdm", "range", "str", "curr_word.strip.strip", "extract_graphemes", "len", "inv_grapheme_dict.items", "len", "ValueError", "curr_label.append", "curr_label.append"], "function", ["None"], ["", "def", "preproc_apurba_data", "(", "csv_path", ",", "inv_grapheme_dict", ",", "representation", "=", "'ads'", ")", ":", "\n", "\n", "    ", "labels", "=", "{", "}", "\n", "words", "=", "{", "}", "\n", "lengths", "=", "{", "}", "\n", "grapheme_dict", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "inv_grapheme_dict", ".", "items", "(", ")", "}", "\n", "labels_file", "=", "pd", ".", "read_csv", "(", "csv_path", ")", "\n", "\n", "if", "representation", "==", "'ads'", ":", "\n", "        ", "extract_graphemes", "=", "ads_grapheme_extraction", "\n", "", "elif", "representation", "==", "'vds'", ":", "\n", "        ", "extract_graphemes", "=", "vds_grapheme_extraction", "\n", "", "elif", "representation", "==", "'naive'", ":", "\n", "        ", "extract_graphemes", "=", "naive_grapheme_extraction", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid chracter representation method. Must be one of ads, vds or naive.\"", ")", "\n", "\n", "\n", "", "print", "(", "\"\\nPreprocessing data:\"", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "labels_file", ")", ")", ")", ":", "\n", "        ", "curr_word", "=", "str", "(", "labels_file", ".", "iloc", "[", "i", "]", "[", "'Word'", "]", ")", "\n", "curr_word", "=", "curr_word", ".", "strip", "(", ")", "\n", "aid", "=", "labels_file", ".", "iloc", "[", "i", "]", "[", "'id'", "]", "\n", "\n", "curr_label", "=", "[", "]", "\n", "words", "[", "aid", "]", "=", "curr_word", "\n", "graphemes", "=", "extract_graphemes", "(", "curr_word", ")", "\n", "for", "grapheme", "in", "graphemes", ":", "\n", "            ", "if", "grapheme", "not", "in", "grapheme_dict", ":", "\n", "                ", "curr_label", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "curr_label", ".", "append", "(", "grapheme_dict", "[", "grapheme", "]", ")", "\n", "", "", "lengths", "[", "aid", "]", "=", "len", "(", "curr_label", ")", "\n", "labels", "[", "aid", "]", "=", "curr_label", "\n", "\n", "", "return", "words", ",", "labels", ",", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.count_parameters": [[282, 293], ["prettytable.PrettyTable", "model.named_parameters", "print", "print", "parameter.numel", "prettytable.PrettyTable.add_row"], "function", ["None"], ["", "def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "table", "=", "PrettyTable", "(", "[", "\"Modules\"", ",", "\"Parameters\"", "]", ")", "\n", "total_params", "=", "0", "\n", "for", "name", ",", "parameter", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "not", "parameter", ".", "requires_grad", ":", "continue", "\n", "param", "=", "parameter", ".", "numel", "(", ")", "\n", "table", ".", "add_row", "(", "[", "name", ",", "param", "]", ")", "\n", "total_params", "+=", "param", "\n", "", "print", "(", "table", ")", "\n", "print", "(", "f\"Total Trainable Params: {total_params}\"", ")", "\n", "return", "total_params", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.get_padded_labels": [[296, 314], ["range", "batch_labels.append", "batch_words.append", "batch_lengths.append", "max", "len", "len", "len", "len"], "function", ["None"], ["", "def", "get_padded_labels", "(", "idxs", ",", "words", ",", "labels", ",", "lengths", ")", ":", "\n", "    ", "batch_labels", "=", "[", "]", "\n", "batch_lengths", "=", "[", "]", "\n", "batch_words", "=", "[", "]", "\n", "maxlen", "=", "0", "\n", "for", "idx", "in", "idxs", ":", "\n", "        ", "batch_labels", ".", "append", "(", "labels", "[", "idx", "]", ")", "\n", "batch_words", ".", "append", "(", "words", "[", "idx", "]", ")", "\n", "batch_lengths", ".", "append", "(", "len", "(", "labels", "[", "idx", "]", ")", ")", "\n", "maxlen", "=", "max", "(", "len", "(", "labels", "[", "idx", "]", ")", ",", "maxlen", ")", "\n", "\n", "#changed [1]*(maxlen-len(batch_labels[i])) to [0]*(maxlen-len(batch_labels[i]))", "\n", "#Alls good", "\n", "", "for", "i", "in", "range", "(", "len", "(", "batch_labels", ")", ")", ":", "\n", "#before stable", "\n", "        ", "batch_labels", "[", "i", "]", "=", "batch_labels", "[", "i", "]", "+", "[", "0", "]", "*", "(", "maxlen", "-", "len", "(", "batch_labels", "[", "i", "]", ")", ")", "\n", "\n", "", "return", "batch_words", ",", "batch_labels", ",", "batch_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction": [[318, 346], ["range", "range", "len", "len", "grapheme_list.append", "pred_list.append", "grapheme_list.append", "pred_list.append", "inv_grapheme_dict.get", "inv_grapheme_dict.get"], "function", ["None"], ["", "def", "decode_prediction", "(", "preds", ",", "inv_grapheme_dict", ",", "raw", "=", "False", ",", "gt", "=", "False", ")", ":", "\n", "    ", "grapheme_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "\n", "#print(preds)", "\n", "\n", "if", "(", "not", "gt", ")", ":", "\n", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "preds", ")", ")", ":", "\n", "            ", "if", "preds", "[", "i", "]", "!=", "0", "and", "(", "not", "(", "i", ">", "0", "and", "preds", "[", "i", "-", "1", "]", "==", "preds", "[", "i", "]", ")", ")", ":", "\n", "                ", "grapheme_list", ".", "append", "(", "inv_grapheme_dict", ".", "get", "(", "preds", "[", "i", "]", ")", ")", "\n", "pred_list", ".", "append", "(", "preds", "[", "i", "]", ")", "\n", "", "", "", "else", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "preds", ")", ")", ":", "\n", "            ", "if", "preds", "[", "i", "]", "!=", "0", "and", "preds", "[", "i", "]", "!=", "1", ":", "\n", "                ", "grapheme_list", ".", "append", "(", "inv_grapheme_dict", ".", "get", "(", "preds", "[", "i", "]", ")", ")", "\n", "pred_list", ".", "append", "(", "preds", "[", "i", "]", ")", "\n", "\n", "##################Cases that hold None types####################", "\n", "# #print(pred_list)", "\n", "# if(len(pred_list) != 0):", "\n", "#     return pred_list, ''.join(grapheme_list)", "\n", "# else:", "\n", "#     return None", "\n", "\n", "#print(pred_list)", "\n", "\n", "", "", "", "return", "pred_list", ",", "''", ".", "join", "(", "grapheme_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.recognition_metrics": [[349, 402], ["enumerate", "zip", "Levenshtein.distance", "max", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "print", "print", "print", "print", "len", "len", "res_dict[].append", "res_dict[].append", "res_dict[].append", "res_dict[].append", "res_dict[].append", "len"], "function", ["None"], ["", "def", "recognition_metrics", "(", "predictions", ",", "labels", ",", "vis_res", "=", "False", ",", "file_name", "=", "\"results.csv\"", ",", "verbose", "=", "False", ")", ":", "\n", "\n", "    ", "all_num", "=", "0", "\n", "correct_num", "=", "0", "\n", "norm_edit_dis", "=", "0.0", "\n", "total_edit_dist", "=", "0.0", "\n", "total_length", "=", "0", "\n", "\n", "if", "vis_res", ":", "\n", "        ", "res_dict", "=", "{", "'index'", ":", "[", "]", ",", "'label'", ":", "[", "]", ",", "'pred'", ":", "[", "]", ",", "'edit_dist'", ":", "[", "]", ",", "'label_len'", ":", "[", "]", "}", "\n", "\n", "", "for", "i", ",", "(", "pred", ",", "label", ")", "in", "enumerate", "(", "zip", "(", "predictions", ",", "labels", ")", ")", ":", "\n", "# pred = pred.replace(\" \", \"\")", "\n", "# target = target.replace(\" \", \"\")", "\n", "        ", "edit_dist", "=", "Levenshtein", ".", "distance", "(", "pred", ",", "label", ")", "\n", "max_len", "=", "max", "(", "len", "(", "pred", ")", ",", "len", "(", "label", ")", ",", "1", ")", "\n", "\n", "norm_edit_dis", "+=", "edit_dist", "/", "max_len", "\n", "\n", "total_edit_dist", "+=", "edit_dist", "\n", "total_length", "+=", "max_len", "\n", "\n", "if", "edit_dist", "==", "0", ":", "\n", "            ", "correct_num", "+=", "1", "\n", "", "all_num", "+=", "1", "\n", "\n", "if", "vis_res", ":", "\n", "            ", "res_dict", "[", "'index'", "]", ".", "append", "(", "i", ")", "\n", "res_dict", "[", "'label'", "]", ".", "append", "(", "label", ")", "\n", "res_dict", "[", "'pred'", "]", ".", "append", "(", "pred", ")", "\n", "res_dict", "[", "'edit_dist'", "]", ".", "append", "(", "edit_dist", ")", "\n", "res_dict", "[", "'label_len'", "]", ".", "append", "(", "len", "(", "label", ")", ")", "\n", "\n", "", "", "if", "vis_res", ":", "\n", "        ", "res_df", "=", "pd", ".", "DataFrame", "(", "res_dict", ")", "\n", "res_df", ".", "to_csv", "(", "\"./results/\"", "+", "file_name", ",", "mode", "=", "'w'", ",", "index", "=", "False", ",", "header", "=", "True", ")", "\n", "\n", "", "results", "=", "{", "\n", "'abs_match'", ":", "correct_num", ",", "\n", "'wrr'", ":", "correct_num", "/", "all_num", ",", "\n", "'total_ned'", ":", "norm_edit_dis", ",", "\n", "'crr'", ":", "1", "-", "total_edit_dist", "/", "total_length", "\n", "}", "\n", "\n", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"Absolute Word Match Count: %d\"", "%", "results", "[", "'abs_match'", "]", ")", "\n", "print", "(", "\"Word Recognition Rate (WRR): %.4f\"", "%", "results", "[", "'wrr'", "]", ")", "\n", "print", "(", "\"Total Normal Edit Distance (NED): %.4f\"", "%", "results", "[", "'total_ned'", "]", ")", "\n", "print", "(", "\"Character Recognition Rate (CRR): %.4f\"", "%", "results", "[", "'crr'", "]", ")", "\n", "print", "(", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.test.test": [[158, 269], ["model.eval", "torch.no_grad", "print", "enumerate", "print", "print", "utils_common.recognition_metrics", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "sklearn.metrics.classification_report", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "pandas.DataFrame().T.sort_values().to_csv", "tqdm.tqdm", "inp.to.to", "inp.to.size", "idx.detach().numpy", "list", "utils_common.get_padded_labels", "torch.tensor", "labels.detach().numpy.to", "torch.tensor", "torch.tensor.to", "torch.nn.functional.log_softmax", "torch.tensor", "torch.tensor.to", "criterion", "criterion.item", "preds.transpose().contiguous().detach().cpu().numpy.max", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach().cpu().numpy", "labels.detach().numpy.detach().numpy", "zip", "open", "f.write", "open", "zip", "len", "inp.to.float", "model", "utils_common.decode_prediction", "zip", "utils_common.decode_prediction", "utils_common.decode_prediction", "decoded_preds.append", "decoded_labels.append", "json.dumps", "fout.write", "fout.write", "fout.write", "fout.write", "numpy.arange", "pandas.DataFrame().T.sort_values", "idx.detach", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach().cpu", "labels.detach().numpy.detach", "y_pred.append", "y_true.append", "preds.transpose().contiguous().detach().cpu().numpy.size", "len", "inv_grapheme_dict.items", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach", "pandas.DataFrame", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous", "preds.transpose().contiguous().detach().cpu().numpy.transpose"], "function", ["home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.recognition_metrics", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.get_padded_labels", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction"], ["def", "test", "(", "model", ")", ":", "\n", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y_true", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "decoded_preds", "=", "[", "]", "\n", "decoded_labels", "=", "[", "]", "\n", "pred_", "=", "[", "]", "\n", "label_", "=", "[", "]", "\n", "\n", "total_wer", "=", "0", "\n", "\n", "print", "(", "\"***Epoch: {}***\"", ".", "format", "(", "args", ".", "epoch", ")", ")", "\n", "batch_loss", "=", "0", "\n", "for", "i", ",", "(", "inp", ",", "img_names", ",", "idx", ")", "in", "enumerate", "(", "tqdm", "(", "inference_loader", ")", ")", ":", "\n", "\n", "            ", "inp", "=", "inp", ".", "to", "(", "device", ")", "\n", "inp", "=", "inp", ".", "float", "(", ")", "/", "255.", "\n", "batch_size", "=", "inp", ".", "size", "(", "0", ")", "\n", "idxs", "=", "idx", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "img_names", "=", "list", "(", "img_names", ")", "\n", "words", ",", "labels", ",", "labels_size", "=", "get_padded_labels", "(", "idxs", ",", "words_te", ",", "labels_te", ",", "lengths_te", ")", "\n", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "labels", ".", "to", "(", "device", ")", "\n", "labels_size", "=", "torch", ".", "tensor", "(", "labels_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "labels_size", ".", "to", "(", "device", ")", "\n", "\n", "preds", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "model", "(", "inp", ")", ",", "dim", "=", "2", ")", "\n", "preds_size", "=", "torch", ".", "tensor", "(", "[", "preds", ".", "size", "(", "0", ")", "]", "*", "batch_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "preds_size", ".", "to", "(", "device", ")", "\n", "#print(preds.shape)", "\n", "#validation loss", "\n", "\n", "loss", "=", "criterion", "(", "preds", ",", "labels", ",", "preds_size", ",", "labels_size", ")", "\n", "#print(loss)", "\n", "batch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "_", ",", "preds", "=", "preds", ".", "max", "(", "2", ")", "\n", "\n", "\n", "preds", "=", "preds", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "labels", "=", "labels", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "\n", "for", "pred", ",", "label", "in", "zip", "(", "preds", ",", "labels", ")", ":", "\n", "#print(labels)", "\n", "\n", "                ", "decoded", ",", "_", "=", "decode_prediction", "(", "pred", ",", "inv_grapheme_dict", ")", "\n", "#_, decoded_label_ = decode_prediction(labels[i], inv_grapheme_dict, gt=True)", "\n", "for", "x", ",", "y", "in", "zip", "(", "decoded", ",", "label", ")", ":", "\n", "\n", "                    ", "y_pred", ".", "append", "(", "x", ")", "\n", "y_true", ".", "append", "(", "y", ")", "\n", "\n", "", "_", ",", "decoded_pred", "=", "decode_prediction", "(", "pred", ",", "inv_grapheme_dict", ")", "\n", "_", ",", "decoded_label", "=", "decode_prediction", "(", "label", ",", "inv_grapheme_dict", ",", "gt", "=", "True", ")", "\n", "# print(\"Pred: \" + decoded_pred)", "\n", "# print(\"Truth: \" + decoded_label)", "\n", "\n", "decoded_preds", ".", "append", "(", "decoded_pred", ")", "\n", "decoded_labels", ".", "append", "(", "decoded_label", ")", "\n", "\n", "\n", "", "", "valid_loss", "=", "batch_loss", "/", "batch_size", "\n", "print", "(", "\"Epoch Validation loss: \"", ",", "valid_loss", ")", "\n", "print", "(", ")", "\n", "\n", "rec_results", "=", "recognition_metrics", "(", "decoded_preds", ",", "decoded_labels", ",", "file_name", "=", "\"results.csv\"", ")", "\n", "\n", "print", "(", "\"End of Epoch {}\"", ".", "format", "(", "args", ".", "epoch", ")", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "print", "(", "\"Absolute Word Match Count: %d\"", "%", "rec_results", "[", "'abs_match'", "]", ")", "\n", "print", "(", "\"Word Recognition Rate (WRR): %.4f\"", "%", "rec_results", "[", "'wrr'", "]", ")", "\n", "print", "(", "\"Normal Edit Distance (NED): %.4f\"", "%", "rec_results", "[", "'total_ned'", "]", ")", "\n", "print", "(", "\"Character Recognition Rate (CRR): %.4f\"", "%", "rec_results", "[", "'crr'", "]", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "\n", "print", "(", "\"\\n\\n\"", ")", "\n", "\n", "with", "open", "(", "result_path", "+", "kd_type", "+", "\"_result.txt\"", ",", "mode", "=", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "rec_results", ")", ")", "\n", "\n", "", "with", "open", "(", "result_path", "+", "kd_type", "+", "\"_words.txt\"", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "for", "x", ",", "y", "in", "zip", "(", "decoded_preds", ",", "decoded_labels", ")", ":", "\n", "                ", "fout", ".", "write", "(", "\"True: {}\"", ".", "format", "(", "y", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "fout", ".", "write", "(", "\"Pred: {}\"", ".", "format", "(", "x", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "# report = classification_report(y_true, y_pred, labels=np.arange(1, len(inv_grapheme_dict)+1), ", "\n", "#                                zero_division=0, output_dict=True, target_names=[v for k, v in inv_grapheme_dict.items()])", "\n", "# pd.DataFrame(report).T.sort_values(by='support', ascending=False).to_excel(\"./results/classification_report_test.xlsx\")", "\n", "", "", "print", "(", "len", "(", "y_true", ")", ")", "\n", "print", "(", "y_true", "[", "0", "]", ")", "\n", "print", "(", "y_pred", "[", "0", "]", ")", "\n", "report", "=", "classification_report", "(", "y_true", ",", "y_pred", ",", "labels", "=", "np", ".", "arange", "(", "1", ",", "len", "(", "inv_grapheme_dict", ")", "+", "1", ")", ",", "\n", "zero_division", "=", "0", ",", "output_dict", "=", "True", ",", "target_names", "=", "[", "v", "for", "k", ",", "v", "in", "inv_grapheme_dict", ".", "items", "(", ")", "]", ")", "\n", "f1_micro", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'micro'", ",", "zero_division", "=", "0", ")", "\n", "f1_macro", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'macro'", ",", "zero_division", "=", "0", ")", "\n", "accuracy", "=", "accuracy_score", "(", "y_true", ",", "y_pred", ")", "\n", "\n", "\n", "\n", "##################### Generate Training Report ##############################", "\n", "\n", "# with pd.ExcelWriter(\"classification_report_training.xlsx\", engine='openpyxl', mode='w' ) as writer:  ", "\n", "#     pd.DataFrame(report).T.sort_values(by='support', ascending=False).to_excel(writer, sheet_name='epoch97')", "\n", "\n", "pd", ".", "DataFrame", "(", "report", ")", ".", "T", ".", "sort_values", "(", "by", "=", "'support'", ",", "ascending", "=", "False", ")", ".", "to_csv", "(", "result_path", "+", "kd_type", "+", "'.csv'", ",", "encoding", "=", "'utf-8'", ",", "header", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_test.preproc_test_data": [[13, 52], ["os.listdir", "sorted", "print", "enumerate", "tqdm.tqdm", "utils_common.normalize_word", "words.append", "extract_graphemes", "lengths.append", "labels.append", "inv_grapheme_dict.items", "len", "int", "ValueError", "name.split", "curr_label.append", "curr_label.append", "x.split"], "function", ["home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.normalize_word"], ["def", "preproc_test_data", "(", "data_dir", ",", "inv_grapheme_dict", ",", "representation", "=", "'ads'", ")", ":", "\n", "\n", "    ", "labels", "=", "[", "]", "\n", "words", "=", "[", "]", "\n", "lengths", "=", "[", "]", "\n", "grapheme_dict", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "inv_grapheme_dict", ".", "items", "(", ")", "}", "\n", "filenames", "=", "os", ".", "listdir", "(", "data_dir", ")", "\n", "filenames", "=", "sorted", "(", "filenames", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", ")", "\n", "\n", "if", "representation", "==", "'ads'", ":", "\n", "        ", "extract_graphemes", "=", "ads_grapheme_extraction", "\n", "", "elif", "representation", "==", "'vds'", ":", "\n", "        ", "extract_graphemes", "=", "vds_grapheme_extraction", "\n", "", "elif", "representation", "==", "'naive'", ":", "\n", "        ", "extract_graphemes", "=", "naive_grapheme_extraction", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid chracter representation method. Must be one of ads, vds or naive.\"", ")", "\n", "\n", "", "print", "(", "\"\\nPreprocessing test data:\"", ")", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "tqdm", "(", "filenames", ")", ")", ":", "\n", "        ", "curr_word", "=", "name", ".", "split", "(", "'_'", ")", "[", "1", "]", "[", ":", "-", "4", "]", "\n", "#print(curr_word)", "\n", "curr_word", "=", "normalize_word", "(", "curr_word", ")", "\n", "# print(curr_word)", "\n", "curr_label", "=", "[", "]", "\n", "words", ".", "append", "(", "curr_word", ")", "\n", "\n", "graphemes", "=", "extract_graphemes", "(", "curr_word", ")", "\n", "\n", "for", "grapheme", "in", "graphemes", ":", "\n", "            ", "if", "grapheme", "not", "in", "grapheme_dict", ":", "\n", "                ", "curr_label", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "curr_label", ".", "append", "(", "grapheme_dict", "[", "grapheme", "]", ")", "\n", "", "", "lengths", ".", "append", "(", "len", "(", "curr_label", ")", ")", "\n", "\n", "labels", ".", "append", "(", "curr_label", ")", "\n", "\n", "", "return", "words", ",", "labels", ",", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_test.preproc_synth_test_data": [[55, 97], ["sorted", "print", "enumerate", "open", "labels_dict.keys", "tqdm.tqdm", "utils_common.normalize_word", "words.append", "extract_graphemes", "lengths.append", "labels.append", "inv_grapheme_dict.items", "line.strip", "len", "mapping.split", "int", "ValueError", "curr_label.append", "curr_label.append", "x.split"], "function", ["home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.normalize_word"], ["", "def", "preproc_synth_test_data", "(", "labels_file", ",", "inv_grapheme_dict", ",", "representation", "=", "'ads'", ")", ":", "\n", "    ", "labels", "=", "[", "]", "\n", "words", "=", "[", "]", "\n", "lengths", "=", "[", "]", "\n", "grapheme_dict", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "inv_grapheme_dict", ".", "items", "(", ")", "}", "\n", "\n", "with", "open", "(", "labels_file", ",", "'r'", ")", "as", "file", ":", "\n", "        ", "mappings", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "file", "]", "\n", "\n", "", "labels_dict", "=", "{", "filename", ":", "label", "for", "filename", ",", "label", "in", "(", "mapping", ".", "split", "(", "\" \"", ",", "1", ")", "for", "mapping", "in", "mappings", ")", "}", "\n", "filenames", "=", "sorted", "(", "labels_dict", ".", "keys", "(", ")", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", ")", "\n", "\n", "if", "representation", "==", "'ads'", ":", "\n", "        ", "extract_graphemes", "=", "ads_grapheme_extraction", "\n", "", "elif", "representation", "==", "'vds'", ":", "\n", "        ", "extract_graphemes", "=", "vds_grapheme_extraction", "\n", "", "elif", "representation", "==", "'naive'", ":", "\n", "        ", "extract_graphemes", "=", "naive_grapheme_extraction", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid chracter representation method. Must be one of ads, vds or naive.\"", ")", "\n", "\n", "", "print", "(", "\"\\nPreprocessing synthetic test training data:\"", ")", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "tqdm", "(", "filenames", ")", ")", ":", "\n", "\n", "# Get labels from labels dict", "\n", "        ", "curr_word", "=", "labels_dict", "[", "name", "]", "\n", "curr_word", "=", "normalize_word", "(", "curr_word", ")", "\n", "# print(curr_word)", "\n", "curr_label", "=", "[", "]", "\n", "words", ".", "append", "(", "curr_word", ")", "\n", "\n", "graphemes", "=", "extract_graphemes", "(", "curr_word", ")", "\n", "\n", "for", "grapheme", "in", "graphemes", ":", "\n", "            ", "if", "grapheme", "not", "in", "grapheme_dict", ":", "\n", "                ", "curr_label", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "curr_label", ".", "append", "(", "grapheme_dict", "[", "grapheme", "]", ")", "\n", "", "", "lengths", ".", "append", "(", "len", "(", "curr_label", ")", ")", "\n", "labels", ".", "append", "(", "curr_label", ")", "\n", "\n", "", "return", "words", ",", "labels", ",", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_test.generate_html": [[100, 125], ["dominate.document", "range", "open", "open.write", "open.close", "h1", "dominate.document.render", "h2", "p", "a", "img", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "generate_html", "(", "image_folder", ",", "num_samples", ",", "label", ",", "pred", ",", "file_namelist", ")", ":", "\n", "\n", "    ", "doc", "=", "dominate", ".", "document", "(", "title", "=", "'Inference of Certain model'", ")", "\n", "\n", "#set folder name", "\n", "#image_folder = 'ict_big_mixed_1'", "\n", "image_folder", "=", "image_folder", "\n", "\n", "with", "doc", ":", "\n", "        ", "h1", "(", "image_folder", "+", "\"_Model_\"", "+", "\"VGG_CRNN_Inference\"", ")", "#set Title", "\n", "\n", "", "for", "i", "in", "range", "(", "num_samples", ")", ":", "#set number of images", "\n", "        ", "width", "=", "165", "\n", "height", "=", "60", "\n", "if", "label", "[", "i", "]", "==", "pred", "[", "i", "]", ":", "\n", "            ", "with", "doc", ":", "\n", "                ", "h2", "(", "\"Ground Truth: \"", "+", "label", "[", "i", "]", "+", "\"\\t \"", "+", "\"Prediction: \"", "+", "pred", "[", "i", "]", ")", "\n", "with", "p", "(", ")", ":", "\n", "                    ", "with", "a", "(", "href", "=", "os", ".", "path", ".", "join", "(", "image_folder", ",", "file_namelist", "[", "i", "]", ")", ")", ":", "\n", "                        ", "img", "(", "style", "=", "\"width:%dpx height:%dpx\"", "%", "(", "width", ",", "height", ")", ",", "src", "=", "os", ".", "path", ".", "join", "(", "image_folder", ",", "file_namelist", "[", "i", "]", ")", ")", "\n", "\n", "", "", "", "", "", "html_file", "=", "'./results/test/visualization.html'", "\n", "f", "=", "open", "(", "html_file", ",", "'wt'", ")", "\n", "f", ".", "write", "(", "doc", ".", "render", "(", ")", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_test.generate_html_from_csv": [[128, 151], ["dominate.document", "pandas.read_csv", "range", "open", "open.write", "open.close", "os.path.join", "h1", "dominate.document.render", "h2", "p", "a", "img", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "generate_html_from_csv", "(", "image_folder", ",", "csv_path", ",", "num_samples", ",", "label", ",", "pred", ")", ":", "\n", "\n", "    ", "doc", "=", "dominate", ".", "document", "(", "title", "=", "'Inference of Certain model'", ")", "\n", "\n", "csv_file", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "image_folder", ",", "csv_path", ")", ")", "\n", "\n", "with", "doc", ":", "\n", "        ", "h1", "(", "\"_Model_\"", "+", "\"VGG_CRNN_Inference\"", ")", "#set Title", "\n", "\n", "", "for", "i", "in", "range", "(", "num_samples", ")", ":", "#set number of images", "\n", "        ", "width", "=", "165", "\n", "height", "=", "60", "\n", "if", "label", "[", "i", "]", "!=", "pred", "[", "i", "]", ":", "\n", "            ", "with", "doc", ":", "\n", "                ", "h2", "(", "\"Ground Truth: \"", "+", "label", "[", "i", "]", "+", "\"\\t \"", "+", "\"Prediction: \"", "+", "pred", "[", "i", "]", ")", "\n", "with", "p", "(", ")", ":", "\n", "                    ", "with", "a", "(", "href", "=", "os", ".", "path", ".", "join", "(", "image_folder", ",", "csv_file", ".", "iloc", "[", "i", "]", "[", "'Image Path'", "]", ")", ")", ":", "\n", "                        ", "img", "(", "style", "=", "\"width:%dpx height:%dpx\"", "%", "(", "width", ",", "height", ")", ",", "src", "=", "os", ".", "path", ".", "join", "(", "image_folder", ",", "csv_file", ".", "iloc", "[", "i", "]", "[", "'Image Path'", "]", ")", ")", "\n", "\n", "", "", "", "", "", "html_file", "=", "'./results/test/visualization.html'", "\n", "f", "=", "open", "(", "html_file", ",", "'wt'", ")", "\n", "f", ".", "write", "(", "doc", ".", "render", "(", ")", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_test.print_model_size": [[154, 158], ["torch.save", "print", "os.remove", "model.state_dict", "os.path.getsize"], "function", ["None"], ["", "def", "print_model_size", "(", "model", ")", ":", "\n", "    ", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "\"temp.p\"", ")", "\n", "print", "(", "'Model Size (MB):'", ",", "os", ".", "path", ".", "getsize", "(", "\"temp.p\"", ")", "/", "1e6", ")", "\n", "os", ".", "remove", "(", "'temp.p'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_test.run_benchmark": [[161, 179], ["model.eval", "enumerate", "print", "images.to.to", "time.time", "model", "time.time", "images.to.size"], "function", ["None"], ["", "def", "run_benchmark", "(", "model", ",", "img_loader", ",", "device", ")", ":", "\n", "    ", "elapsed", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "num_batches", "=", "5", "\n", "# Run the scripted model on a few batches of images", "\n", "for", "i", ",", "(", "images", ",", "_", ",", "_", ")", "in", "enumerate", "(", "img_loader", ")", ":", "\n", "        ", "images", "=", "images", ".", "to", "(", "device", ")", "\n", "if", "i", "<", "num_batches", ":", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "output", "=", "model", "(", "images", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "elapsed", "=", "elapsed", "+", "(", "end", "-", "start", ")", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "num_images", "=", "images", ".", "size", "(", ")", "[", "0", "]", "*", "num_batches", "\n", "\n", "print", "(", "'Inference time: %3.0f ms'", "%", "(", "elapsed", "/", "num_images", "*", "1000", ")", ")", "\n", "return", "elapsed", "\n", "", ""]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train_student.Net.__init__": [[116, 124], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.Synth12Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "1", ",", "32", ",", "3", ",", "1", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "3", ",", "1", ")", "\n", "self", ".", "dropout1", "=", "nn", ".", "Dropout", "(", "0.25", ")", "\n", "self", ".", "dropout2", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "12544", ",", "512", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "512", ",", "classn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train_student.Net.forward": [[125, 139], ["train_student.Net.conv1", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "train_student.Net.conv2", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "train_student.Net.dropout1", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "train_student.Net.fc1", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "train_student.Net.dropout2", "train_student.Net.fc2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "F", ".", "max_pool2d", "(", "x", ",", "2", ")", "\n", "x", "=", "self", ".", "dropout1", "(", "x", ")", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout2", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "#output = F.log_softmax(x, dim=1)", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train_student.load_image": [[288, 307], ["PIL.Image.open", "torchvision.transforms.Compose", "[].unsqueeze", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.Grayscale", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "transforms.Compose."], "function", ["None"], ["def", "load_image", "(", "img_path", ")", ":", "\n", "    ", "''' Load in and transform an image'''", "\n", "image", "=", "Image", ".", "open", "(", "img_path", ")", "\n", "\n", "\n", "# VGG-16 Takes 224x224 images as input, so we resize all of them and convert data to a normalized torch.FloatTensor    ", "\n", "in_transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "Resize", "(", "32", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "32", ")", ",", "\n", "transforms", ".", "Grayscale", "(", "num_output_channels", "=", "1", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", "]", ",", "\n", "std", "=", "[", "0.229", "]", ")", "]", ")", "\n", "\n", "# discard the transparent, alpha channel (that's the :3) and add the batch dimension", "\n", "\n", "image", "=", "in_transform", "(", "image", ")", "[", ":", "3", ",", ":", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", "\n", "#print(image.shape)", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train_student.pred_teacher": [[378, 467], ["model_transfer.to", "model_transfer.eval", "torch.cat().reshape", "torch.cat().reshape", "torch.cat().reshape", "torch.cat().reshape", "torch.cat().reshape", "torch.cat().reshape", "y.transpose.transpose", "y.transpose.to", "list", "len", "int", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.cpu().detach().numpy", "numpy.tile().reshape", "arr[].reshape", "range", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "batch_pred.append", "len", "filter", "predicts.append", "print", "numpy.concatenate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.cpu().detach", "numpy.tile", "torch.cat.cpu"], "function", ["None"], ["", "def", "pred_teacher", "(", "model_transfer", ",", "batch", ")", ":", "\n", "    ", "model_transfer", ".", "to", "(", "device", ")", "\n", "model_transfer", ".", "eval", "(", ")", "\n", "batch_pred", "=", "[", "]", "\n", "ik", "=", "0", "\n", "# batch list of words", "\n", "for", "ax", "in", "batch", ":", "\n", "#print(ax)", "\n", "# remove padded levels", "\n", "        ", "ax", "=", "list", "(", "filter", "(", "lambda", "a", ":", "a", "!=", "0", ",", "ax", ")", ")", "\n", "#print(ax)", "\n", "#val = len(ax)", "\n", "#a=[2,4,6]", "\n", "# add skip token", "\n", "#ax = list(chain(*[lst[i:i+n] + [ele] if len(lst[i:i+n]) == n else lst[i:i+n] for i in (0, len(lst), n)]))", "\n", "#print(ax)", "\n", "\n", "# list of predicted words for a batch without 31 time steps", "\n", "predicts", "=", "[", "]", "\n", "\n", "# ax list of labels for a word", "\n", "for", "i", "in", "ax", ":", "\n", "            ", "k", "=", "f'{i:03}'", "\n", "#idd = 'pre-processed2/valid/'+str(k)", "\n", "#imgpath = glob.glob('pre-processed2/valid/'+str(k)+'/*.jpg')", "\n", "#imgpath = imgpath[0]", "\n", "#print(imgpath)", "\n", "#image = load_image(imgpath)", "\n", "\n", "#if use_cuda:", "\n", "#image = image.cuda()", "\n", "\n", "predict", "=", "dicti", "[", "k", "]", "\n", "\n", "\n", "#predict = torch.add(predict, 1)", "\n", "#predict.to(device)", "\n", "predicts", ".", "append", "(", "predict", ")", "\n", "\n", "#pre = predict.data.cpu().argmax()", "\n", "#print(pre)", "\n", "#print(predict.shape)", "\n", "\n", "", "div", "=", "len", "(", "ax", ")", "\n", "if", "(", "div", "==", "0", ")", ":", "\n", "            ", "print", "(", "div", ")", "\n", "", "cop", "=", "int", "(", "31", "/", "div", ")", "\n", "add", "=", "31", "%", "div", "\n", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "predicts", ")", "\n", "#x = x.repeat(cop,1).reshape(div*cop,197)", "\n", "npy", "=", "x", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "arr", "=", "np", ".", "tile", "(", "npy", ",", "cop", ")", ".", "reshape", "(", "div", "*", "cop", ",", "classn", ")", "\n", "new_row", "=", "arr", "[", "-", "1", "]", ".", "reshape", "(", "1", ",", "classn", ")", "\n", "for", "i", "in", "range", "(", "add", ")", ":", "\n", "            ", "arr", "=", "np", ".", "concatenate", "(", "(", "arr", ",", "new_row", ")", ",", "axis", "=", "0", ")", "\n", "#x = torch.cat((x, x[-1].unsqueeze(dim=0)), 0)", "\n", "", "'''\n        if add != 0:\n            try:\n                \n\n\n                for i in range(add):\n                    arr = np.concatenate((arr, new_row), axis=0)\n                    x = torch.cat((x, x[-1].unsqueeze(dim=0)), 0)\n            except:\n                print(div)\n                print(' tarpor' )\n                print(cop)'''", "\n", "\n", "\n", "\n", "tensors", "=", "torch", ".", "from_numpy", "(", "arr", ")", "\n", "#tensors.to(device)", "\n", "# list of word preds with 31 time steps", "\n", "batch_pred", ".", "append", "(", "tensors", ")", "\n", "\n", "", "y", "=", "torch", ".", "cat", "(", "batch_pred", ")", ".", "reshape", "(", "len", "(", "batch", ")", ",", "31", ",", "classn", ")", "\n", "y", "=", "y", ".", "transpose", "(", "0", ",", "1", ")", "\n", "y", ".", "to", "(", "device", ")", "\n", "'''\n    np_arr = y.cpu().detach().numpy()\n    np_arr = np_arr.reshape(31,len(batch),201)\n    y = torch.from_numpy(np_arr)\n    y.to(device)'''", "\n", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train_student.newkldiv": [[468, 480], ["range", "torch.cat().reshape", "torch.cat().reshape", "torch.cat().reshape", "torch.cat().reshape", "torch.cat().reshape", "torch.cat().reshape", "loss.mean.mean", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "loss.mean.append", "torch.KLDivLoss", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "function", ["None"], ["", "def", "newkldiv", "(", "stud", ",", "teach", ")", ":", "\n", "\n", "    ", "loss", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "31", ")", ":", "\n", "        ", "s", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "stud", "[", "i", "]", "/", "t", ",", "dim", "=", "2", ")", "\n", "t", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "teach", "[", "i", "]", "/", "t", ",", "dim", "=", "2", ")", "\n", "kldiv", "=", "nn", ".", "KLDivLoss", "(", "reduction", "=", "'batchmean'", ")", "(", "s", ",", "t", ")", "\n", "loss", ".", "append", "(", "kldiv", ")", "\n", "", "loss", "=", "torch", ".", "cat", "(", "loss", ")", ".", "reshape", "(", "31", ")", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "return", "loss", ".", "cuda", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train_student.train": [[517, 734], ["torch.lr_scheduler.CosineAnnealingWarmRestarts", "range", "student_model.train", "print", "enumerate", "optim.lr_scheduler.CosineAnnealingWarmRestarts.step", "print", "print", "utils_common.recognition_metrics", "print", "print", "print", "print", "print", "print", "print", "print", "pandas.DataFrame", "pd.DataFrame.to_csv", "train_student.validate", "optim.lr_scheduler.CosineAnnealingWarmRestarts.step", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "tqdm.tqdm", "inp.to.to", "inp.to.size", "idx.detach().numpy", "list", "utils_common.get_padded_labels", "train_student.pred_teacher", "teacher_preds.cuda.cuda", "student_model", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "labels.detach().numpy.to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.to", "criterion", "loss.item", "optimizer.zero_grad", "loss.backward", "optimizer.step", "preds.transpose().contiguous().detach().cpu().numpy.max", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach().cpu().numpy", "labels.detach().numpy.detach().numpy", "zip", "open", "zip", "sklearn.metrics.classification_report", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "print", "print", "print", "print", "print", "print", "pandas.DataFrame", "student_model.state_dict", "inp.to.float", "torch.KLDivLoss", "utils_common.decode_prediction", "zip", "utils_common.decode_prediction", "utils_common.decode_prediction", "decoded_preds.append", "decoded_labels.append", "fout.write", "fout.write", "fout.write", "fout.write", "pandas.ExcelWriter", "pandas.DataFrame().T.sort_values().to_excel", "open", "zip", "print", "idx.detach", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach().cpu", "labels.detach().numpy.detach", "y_pred.append", "y_true.append", "numpy.arange", "fout.write", "fout.write", "fout.write", "fout.write", "preds.transpose().contiguous().detach().cpu().numpy.size", "pandas.DataFrame().T.sort_values", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach", "len", "inv_grapheme_dict.items", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous", "pandas.DataFrame", "preds.transpose().contiguous().detach().cpu().numpy.transpose"], "function", ["home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train_student3.train", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.recognition_metrics", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train_student3.validate", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.get_padded_labels", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train_student.pred_teacher", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction"], ["def", "train", "(", "epochs", "=", "30", ",", "lr", "=", "0.0003", ")", ":", "#lr=0.001", "\n", "\n", "    ", "\"\"\"\n    During Quantization Aware Training, the LR should be 1-10% of the LR used for training without quantization\n    \"\"\"", "\n", "\n", "#optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr, momentum=0.9, dampening=0, w", "\n", "\n", "# https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html", "\n", "# new_lr = lr * factor", "\n", "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.9, patience=2, threshold=0.01, min_lr=0.0001, verbose=True)", "\n", "# scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[7, 25], gamma=0.5, verbose=True)", "\n", "scheduler", "=", "optim", ".", "lr_scheduler", ".", "CosineAnnealingWarmRestarts", "(", "optimizer", ",", "T_0", "=", "15", ",", "T_mult", "=", "1", ",", "eta_min", "=", "0.0001", ")", "\n", "\n", "#early_stopping = EarlyStopping(patience=10, verbose=True)", "\n", "for", "epoch", "in", "range", "(", "0", ",", "100", ")", ":", "\n", "\n", "        ", "student_model", ".", "train", "(", ")", "\n", "\n", "#necessary variables", "\n", "y_true", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "pred_", "=", "[", "]", "\n", "label_", "=", "[", "]", "\n", "decoded_preds", "=", "[", "]", "\n", "decoded_labels", "=", "[", "]", "\n", "\n", "total_wer", "=", "0", "\n", "\n", "print", "(", "\"***Epoch: {}***\"", ".", "format", "(", "epoch", ")", ")", "\n", "batch_loss", "=", "0", "\n", "#lr = 0.002", "\n", "# t = 2", "\n", "alpha", "=", "0.5", "\n", "for", "i", ",", "(", "inp", ",", "img_names", ",", "idx", ")", "in", "enumerate", "(", "tqdm", "(", "train_loader", ")", ")", ":", "\n", "\n", "\n", "            ", "inp", "=", "inp", ".", "to", "(", "device", ")", "\n", "inp", "=", "inp", ".", "float", "(", ")", "/", "255.", "\n", "batch_size", "=", "inp", ".", "size", "(", "0", ")", "\n", "idxs", "=", "idx", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "img_names", "=", "list", "(", "img_names", ")", "\n", "words", ",", "labels", ",", "labels_size", "=", "get_padded_labels", "(", "idxs", ",", "words_tr", ",", "labels_tr", ",", "lengths_tr", ")", "\n", "\n", "#print(inp.shape)", "\n", "\n", "teacher_preds", "=", "pred_teacher", "(", "teacher_model", ",", "labels", ")", "\n", "teacher_preds", "=", "teacher_preds", ".", "cuda", "(", ")", "\n", "\n", "#teacher_preds = teacher_model(inp)", "\n", "#teacher_preds.to(device) ", "\n", "#print(teacher_preds.shape)", "\n", "#print(teacher_preds[3][0][0])", "\n", "# soft_targets = F.log_softmax(teacher_preds /3)", "\n", "#print(soft_targets.shape)", "\n", "#print(teacher_preds)", "\n", "\n", "z_score", "=", "student_model", "(", "inp", ")", "\n", "\n", "preds", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "z_score", ",", "dim", "=", "2", ")", "\n", "pr", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "z_score", "/", "t", ",", "dim", "=", "2", ")", "\n", "#preds = torch.nn.functional.log_softmax(model(inp), dim=2)", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "labels", ".", "to", "(", "device", ")", "\n", "labels_size", "=", "torch", ".", "tensor", "(", "labels_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "labels_size", ".", "to", "(", "device", ")", "\n", "preds_size", "=", "torch", ".", "tensor", "(", "[", "preds", ".", "size", "(", "0", ")", "]", "*", "batch_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "preds_size", ".", "to", "(", "device", ")", "\n", "#print(preds[3][0])", "\n", "#np_arr = preds.cpu().detach().numpy()", "\n", "#preds = torch.from_numpy(np_arr)", "\n", "\n", "#print(preds.shape)", "\n", "#print(preds[3][0][0])", "\n", "# soft_preds = F.log_softmax(preds / t)", "\n", "#print(soft_preds.shape)", "\n", "\n", "#kl_div_loss = F.kl_div(soft_preds, soft_targets)", "\n", "#kl_div_loss = ", "\n", "\n", "#print(kl_div_loss)", "\n", "\n", "\n", "#loss = criterion(preds, labels, preds_size, labels_size)", "\n", "\n", "ctc_loss", "=", "criterion", "(", "preds", ",", "labels", ",", "preds_size", ",", "labels_size", ")", "\n", "\n", "#loss =  nn.KLDivLoss()(pr , teacher_preds) * ( 1- alpha)  + ctc_loss * alpha", "\n", "ty", "=", "nn", ".", "KLDivLoss", "(", ")", "(", "pr", ",", "teacher_preds", ")", "\n", "#ty = ty.cuda()", "\n", "loss", "=", "ty", "*", "(", "t", "*", "t", "*", "2.0", "+", "alpha", ")", "+", "ctc_loss", "*", "(", "1.", "-", "alpha", ")", "\n", "#print(loss.item())", "\n", "batch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "_", ",", "preds", "=", "preds", ".", "max", "(", "2", ")", "\n", "preds", "=", "preds", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "labels", "=", "labels", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "\n", "\n", "for", "pred", ",", "label", "in", "zip", "(", "preds", ",", "labels", ")", ":", "\n", "                ", "decoded", ",", "_", "=", "decode_prediction", "(", "pred", ",", "inv_grapheme_dict", ")", "\n", "#_, decoded_label_ = decode_prediction(labels[i], inv_grapheme_dict, gt=True)", "\n", "for", "x", ",", "y", "in", "zip", "(", "decoded", ",", "label", ")", ":", "\n", "\n", "                    ", "y_pred", ".", "append", "(", "x", ")", "\n", "\n", "\n", "y_true", ".", "append", "(", "y", ")", "\n", "\n", "", "_", ",", "decoded_pred", "=", "decode_prediction", "(", "pred", ",", "inv_grapheme_dict", ")", "\n", "_", ",", "decoded_label", "=", "decode_prediction", "(", "label", ",", "inv_grapheme_dict", ",", "gt", "=", "True", ")", "\n", "# print(\"Pred: \" + decoded_pred)", "\n", "# print(\"Truth: \" + decoded_label)", "\n", "\n", "decoded_preds", ".", "append", "(", "decoded_pred", ")", "\n", "decoded_labels", ".", "append", "(", "decoded_label", ")", "\n", "#print(pred_)", "\n", "\n", "", "", "scheduler", ".", "step", "(", ")", "\n", "\n", "train_loss", "=", "batch_loss", "/", "train_batch_s", "\n", "print", "(", "\"Epoch Training loss: \"", ",", "train_loss", ")", "#batch_size denominator 32", "\n", "\n", "print", "(", "\"\\n\"", ")", "\n", "rec_results", "=", "recognition_metrics", "(", "decoded_preds", ",", "decoded_labels", ",", "file_name", "=", "\"results.csv\"", ")", "\n", "print", "(", "'\\n'", ")", "\n", "#print(pred_)", "\n", "#print(label_)", "\n", "print", "(", "\"Absolute Word Match Count: %d\"", "%", "rec_results", "[", "'abs_match'", "]", ")", "\n", "print", "(", "\"Word Recognition Rate (WRR): %.4f\"", "%", "rec_results", "[", "'wrr'", "]", ")", "\n", "print", "(", "\"Normal Edit Distance (NED): %.4f\"", "%", "rec_results", "[", "'total_ned'", "]", ")", "\n", "print", "(", "\"Character Recognition Rate (CRR): %.4f\"", "%", "rec_results", "[", "'crr'", "]", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "print", "(", "\"End of Epoch \"", ",", "epoch", ")", "\n", "print", "(", "\"\\n\\n\"", ")", "\n", "\n", "with", "open", "(", "\"./\"", "+", "path", "+", "\"/results_training.txt\"", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "for", "x", ",", "y", "in", "zip", "(", "pred_", ",", "label_", ")", ":", "\n", "                ", "fout", ".", "write", "(", "\"True: {}\"", ".", "format", "(", "y", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "fout", ".", "write", "(", "\"Pred: {}\"", ".", "format", "(", "x", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "", "", "metrics", "=", "pd", ".", "DataFrame", "(", "[", "{", "'epoch'", ":", "epoch", ",", "\n", "'crr'", ":", "rec_results", "[", "'crr'", "]", ",", "\n", "'wrr'", ":", "rec_results", "[", "'wrr'", "]", ",", "\n", "'ned'", ":", "rec_results", "[", "'total_ned'", "]", ",", "\n", "'abs_match'", ":", "rec_results", "[", "'abs_match'", "]", ",", "\n", "'train_loss'", ":", "train_loss", "\n", "}", "]", ")", "\n", "\n", "metrics", ".", "to_csv", "(", "\"./\"", "+", "path", "+", "\"/metrics_training.csv\"", ",", "\n", "mode", "=", "(", "'w'", "if", "epoch", "==", "0", "else", "'a'", ")", ",", "index", "=", "False", ",", "header", "=", "(", "True", "if", "epoch", "==", "0", "else", "False", ")", ")", "\n", "\n", "\n", "#total_wer, _ = compute_wer(pred_, label_)", "\n", "#print(\"Total AED Word Error Rate (Training): %.4f\" % total_wer)", "\n", "\n", "#change in number of labels", "\n", "try", ":", "\n", "            ", "report", "=", "classification_report", "(", "y_true", ",", "y_pred", ",", "labels", "=", "np", ".", "arange", "(", "1", ",", "len", "(", "inv_grapheme_dict", ")", "+", "1", ")", ",", "\n", "zero_division", "=", "0", ",", "output_dict", "=", "True", ",", "target_names", "=", "[", "v", "for", "k", ",", "v", "in", "inv_grapheme_dict", ".", "items", "(", ")", "]", ")", "\n", "f1_micro", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'micro'", ",", "zero_division", "=", "0", ")", "\n", "f1_macro", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'macro'", ",", "zero_division", "=", "0", ")", "\n", "accuracy", "=", "accuracy_score", "(", "y_true", ",", "y_pred", ")", "\n", "#change in number of labels", "\n", "\n", "\n", "#Absolute word matching", "\n", "#abs_correct = absolute_word_match(pred_, label_)", "\n", "\n", "#print(\"Absolute Word Match Count: {}\".format(abs_correct))", "\n", "#print(\"Absolute Word Match Percentage: %.4f\" % (abs_correct / num_train_samples))", "\n", "print", "(", "\"Training Accuracy: %.4f\"", "%", "accuracy", ")", "\n", "print", "(", "\"Training F1 Micro Score: %.4f\"", "%", "f1_micro", ")", "\n", "print", "(", "\"Training F1 Macro Score: %.4f\"", "%", "f1_macro", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "print", "(", "\"End of Training FOR Epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "print", "(", "\"\\n\\n\"", ")", "\n", "\n", "##################### Generate Training Report ##############################", "\n", "\n", "with", "pd", ".", "ExcelWriter", "(", "\"./\"", "+", "path", "+", "\"/classification_report_training.xlsx\"", ",", "engine", "=", "'openpyxl'", ",", "mode", "=", "(", "'w'", "if", "epoch", "==", "0", "else", "'a'", ")", ")", "as", "writer", ":", "\n", "                ", "pd", ".", "DataFrame", "(", "report", ")", ".", "T", ".", "sort_values", "(", "by", "=", "'support'", ",", "ascending", "=", "False", ")", ".", "to_excel", "(", "writer", ",", "sheet_name", "=", "'epoch{}'", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "", "with", "open", "(", "\"./\"", "+", "path", "+", "\"/results_training.txt\"", ",", "'w'", ")", "as", "fout", ":", "\n", "                ", "for", "x", ",", "y", "in", "zip", "(", "pred_", ",", "label_", ")", ":", "\n", "                    ", "fout", ".", "write", "(", "\"True: {}\"", ".", "format", "(", "y", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "fout", ".", "write", "(", "\"Pred: {}\"", ".", "format", "(", "x", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "", "", "metrics", "=", "pd", ".", "DataFrame", "(", "[", "{", "'epoch'", ":", "epoch", ",", "\n", "'accuracy'", ":", "accuracy", ",", "\n", "'train_loss'", ":", "train_loss", ",", "\n", "\n", "'f1_micro'", ":", "f1_micro", ",", "\n", "'f1_macro'", ":", "f1_macro", "\n", "\n", "}", "]", ")", "\n", "\n", "", "except", ":", "\n", "            ", "print", "(", "'error'", ")", "\n", "#############################################################################'''", "\n", "\n", "", "valid_loss", "=", "validate", "(", "epoch", ",", "valid_batch_s", ",", "train_loss", ")", "\n", "#early_stopping(valid_loss, student_model)", "\n", "\n", "#if early_stopping.early_stop:", "\n", "#print(\"Early stopping\")", "\n", "#break", "\n", "scheduler", ".", "step", "(", ")", "\n", "torch", ".", "save", "(", "student_model", ".", "state_dict", "(", ")", ",", "'./'", "+", "path", "+", "'/epoch{}.pth'", ".", "format", "(", "epoch", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train_student.validate": [[735, 884], ["student_model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "print", "enumerate", "print", "print", "utils_common.recognition_metrics", "print", "print", "print", "print", "print", "print", "print", "print", "pandas.DataFrame", "pd.DataFrame.to_csv", "sklearn.metrics.accuracy_score", "print", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "print", "print", "print", "print", "print", "print", "tqdm.tqdm", "inp.to.to", "inp.to.size", "idx.detach().numpy", "list", "utils_common.get_padded_labels", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "labels.detach().numpy.to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.to", "criterion", "criterion.item", "preds.transpose().contiguous().detach().cpu().numpy.max", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach().cpu().numpy", "labels.detach().numpy.detach().numpy", "range", "open", "zip", "sklearn.metrics.classification_report", "pandas.DataFrame", "inp.to.float", "student_model", "len", "utils_common.decode_prediction", "zip", "utils_common.decode_prediction", "utils_common.decode_prediction", "pred_.append", "label_.append", "fout.write", "fout.write", "fout.write", "fout.write", "print", "pandas.ExcelWriter", "pandas.DataFrame().T.sort_values().to_excel", "open", "zip", "print", "idx.detach", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach().cpu", "labels.detach().numpy.detach", "y_pred.append", "y_true.append", "numpy.arange", "fout.write", "fout.write", "fout.write", "fout.write", "preds.transpose().contiguous().detach().cpu().numpy.size", "pandas.DataFrame().T.sort_values", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach", "len", "inv_grapheme_dict.items", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous", "pandas.DataFrame", "preds.transpose().contiguous().detach().cpu().numpy.transpose"], "function", ["home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.recognition_metrics", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.get_padded_labels", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction"], ["", "", "def", "validate", "(", "epoch", ",", "valid_batch_s", ",", "train_loss", ")", ":", "\n", "\n", "# evaluate model:", "\n", "    ", "student_model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y_true", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "pred_", "=", "[", "]", "\n", "label_", "=", "[", "]", "\n", "\n", "total_wer", "=", "0", "\n", "\n", "print", "(", "\"***Epoch: {}***\"", ".", "format", "(", "epoch", ")", ")", "\n", "batch_loss", "=", "0", "\n", "for", "i", ",", "(", "inp", ",", "img_names", ",", "idx", ")", "in", "enumerate", "(", "tqdm", "(", "validation_loader", ")", ")", ":", "\n", "\n", "            ", "inp", "=", "inp", ".", "to", "(", "device", ")", "\n", "inp", "=", "inp", ".", "float", "(", ")", "/", "255.0", "\n", "batch_size", "=", "inp", ".", "size", "(", "0", ")", "\n", "idxs", "=", "idx", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "img_names", "=", "list", "(", "img_names", ")", "\n", "words", ",", "labels", ",", "labels_size", "=", "get_padded_labels", "(", "idxs", ",", "words_val", ",", "labels_val", ",", "lengths_val", ")", "\n", "\n", "preds", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "student_model", "(", "inp", ")", ",", "dim", "=", "2", ")", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "labels", ".", "to", "(", "device", ")", "\n", "labels_size", "=", "torch", ".", "tensor", "(", "labels_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "labels_size", ".", "to", "(", "device", ")", "\n", "preds_size", "=", "torch", ".", "tensor", "(", "[", "preds", ".", "size", "(", "0", ")", "]", "*", "batch_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "preds_size", ".", "to", "(", "device", ")", "\n", "\n", "#validation loss", "\n", "loss", "=", "criterion", "(", "preds", ",", "labels", ",", "preds_size", ",", "labels_size", ")", "\n", "#print(loss)", "\n", "batch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "#print(loss.item())", "\n", "\n", "_", ",", "preds", "=", "preds", ".", "max", "(", "2", ")", "\n", "preds", "=", "preds", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "labels", "=", "labels", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "preds", ")", ")", ":", "\n", "                ", "decoded", ",", "_", "=", "decode_prediction", "(", "preds", "[", "i", "]", ",", "inv_grapheme_dict", ")", "\n", "for", "x", ",", "y", "in", "zip", "(", "decoded", ",", "labels", "[", "i", "]", ")", ":", "\n", "                    ", "y_pred", ".", "append", "(", "x", ")", "\n", "\n", "y_true", ".", "append", "(", "y", ")", "\n", "", "_", ",", "decoded_pred_", "=", "decode_prediction", "(", "preds", "[", "i", "]", ",", "inv_grapheme_dict", ")", "\n", "#print(inv_grapheme_dict)", "\n", "_", ",", "decoded_label_", "=", "decode_prediction", "(", "labels", "[", "i", "]", ",", "inv_grapheme_dict", ",", "gt", "=", "True", ")", "\n", "#print(decoded_label_)", "\n", "\n", "pred_", ".", "append", "(", "decoded_pred_", ")", "\n", "label_", ".", "append", "(", "decoded_label_", ")", "\n", "\n", "", "", "valid_loss", "=", "batch_loss", "/", "valid_batch_s", "\n", "print", "(", "\"Epoch Validation loss: \"", ",", "valid_loss", ")", "#batch_size denominator 32", "\n", "print", "(", "\"\\n\"", ")", "\n", "rec_results", "=", "recognition_metrics", "(", "pred_", ",", "label_", ",", "file_name", "=", "\"results.csv\"", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "#print(pred_)", "\n", "#print(label_)", "\n", "print", "(", "\"Absolute Word Match Count: %d\"", "%", "rec_results", "[", "'abs_match'", "]", ")", "\n", "print", "(", "\"Word Recognition Rate (WRR): %.4f\"", "%", "rec_results", "[", "'wrr'", "]", ")", "\n", "print", "(", "\"Normal Edit Distance (NED): %.4f\"", "%", "rec_results", "[", "'total_ned'", "]", ")", "\n", "print", "(", "\"Character Recognition Rate (CRR): %.4f\"", "%", "rec_results", "[", "'crr'", "]", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "print", "(", "\"End of Epoch \"", ",", "epoch", ")", "\n", "print", "(", "\"\\n\\n\"", ")", "\n", "\n", "with", "open", "(", "\"./\"", "+", "path", "+", "\"/results_validation.txt\"", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "for", "x", ",", "y", "in", "zip", "(", "pred_", ",", "label_", ")", ":", "\n", "                ", "fout", ".", "write", "(", "\"True: {}\"", ".", "format", "(", "y", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "fout", ".", "write", "(", "\"Pred: {}\"", ".", "format", "(", "x", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "", "", "metrics", "=", "pd", ".", "DataFrame", "(", "[", "{", "'epoch'", ":", "epoch", ",", "\n", "'crr'", ":", "rec_results", "[", "'crr'", "]", ",", "\n", "'wrr'", ":", "rec_results", "[", "'wrr'", "]", ",", "\n", "'ned'", ":", "rec_results", "[", "'total_ned'", "]", ",", "\n", "'abs_match'", ":", "rec_results", "[", "'abs_match'", "]", ",", "\n", "'train_loss'", ":", "train_loss", "\n", "}", "]", ")", "\n", "\n", "metrics", ".", "to_csv", "(", "\"./\"", "+", "path", "+", "\"/metrics_validation.csv\"", ",", "\n", "mode", "=", "(", "'w'", "if", "epoch", "==", "0", "else", "'a'", ")", ",", "index", "=", "False", ",", "header", "=", "(", "True", "if", "epoch", "==", "0", "else", "False", ")", ")", "\n", "\n", "#total_wer, _ = compute_wer(pred_, label_)", "\n", "#print(\"Total AED Word Error Rate: %.4f\" % total_wer)", "\n", "accuracy", "=", "accuracy_score", "(", "y_true", ",", "y_pred", ")", "\n", "print", "(", "'accuracy '", ",", "accuracy", ")", "\n", "\n", "#change in number of labels", "\n", "try", ":", "\n", "            ", "report", "=", "classification_report", "(", "y_true", ",", "y_pred", ",", "labels", "=", "np", ".", "arange", "(", "1", ",", "len", "(", "inv_grapheme_dict", ")", "+", "1", ")", ",", "\n", "zero_division", "=", "0", ",", "output_dict", "=", "True", ",", "target_names", "=", "[", "v", "for", "k", ",", "v", "in", "inv_grapheme_dict", ".", "items", "(", ")", "]", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "'error'", ")", "\n", "", "f1_micro", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'micro'", ",", "zero_division", "=", "0", ")", "\n", "f1_macro", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'macro'", ",", "zero_division", "=", "0", ")", "\n", "accuracy", "=", "accuracy_score", "(", "y_true", ",", "y_pred", ")", "\n", "\n", "\n", "#Absolute word matching", "\n", "#abs_correct = absolute_word_match(pred_, label_)", "\n", "\n", "#print(\"Absolute Word Match Count: {}\".format(abs_correct))", "\n", "#print(\"Abs Match Percentage: %.4f\" % (abs_correct / num_valid_samples))", "\n", "print", "(", "\"Accuracy: %.4f\"", "%", "accuracy", ")", "\n", "print", "(", "\"F1 Micro Score: %.4f\"", "%", "f1_micro", ")", "\n", "print", "(", "\"F1 Macro Score: %.4f\"", "%", "f1_macro", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "print", "(", "\"End of Epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "print", "(", "\"\\n\\n\"", ")", "\n", "\n", "##################### Generate Validation Report ##############################", "\n", "\n", "try", ":", "\n", "\n", "            ", "with", "pd", ".", "ExcelWriter", "(", "\"./\"", "+", "path", "+", "\"/classification_report_validation.xlsx\"", ",", "engine", "=", "'openpyxl'", ",", "mode", "=", "(", "'w'", "if", "epoch", "==", "0", "else", "'a'", ")", ")", "as", "writer", ":", "\n", "                ", "pd", ".", "DataFrame", "(", "report", ")", ".", "T", ".", "sort_values", "(", "by", "=", "'support'", ",", "ascending", "=", "False", ")", ".", "to_excel", "(", "writer", ",", "sheet_name", "=", "'epoch{}'", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "", "with", "open", "(", "\"./\"", "+", "path", "+", "\"/results_validation.txt\"", ",", "'w'", ")", "as", "fout", ":", "\n", "                ", "for", "x", ",", "y", "in", "zip", "(", "pred_", ",", "label_", ")", ":", "\n", "                    ", "fout", ".", "write", "(", "\"True: {}\"", ".", "format", "(", "y", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "fout", ".", "write", "(", "\"Pred: {}\"", ".", "format", "(", "x", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "", "", "metrics", "=", "pd", ".", "DataFrame", "(", "[", "{", "'epoch'", ":", "epoch", ",", "\n", "'accuracy'", ":", "accuracy", ",", "\n", "'train_loss'", ":", "train_loss", ",", "\n", "'valid_loss'", ":", "valid_loss", ",", "\n", "\n", "'f1_micro'", ":", "f1_micro", ",", "\n", "'f1_macro'", ":", "f1_macro", ",", "\n", "\n", "}", "]", ")", "\n", "\n", "#metrics.to_csv(\"./bnhtrdtrain/normalkd1/metrics_validation.csv\", ", "\n", "#mode=('w' if epoch==0 else 'a'), index=False, header=(True if epoch==0 else False)) ", "\n", "", "except", ":", "\n", "            ", "print", "(", "'error'", ")", "\n", "\n", "###############################################################################", "\n", "\n", "", "return", "valid_loss", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_train.preproc_synth_train_data": [[10, 59], ["sorted", "print", "enumerate", "open", "labels_dict.keys", "tqdm.tqdm", "utils_common.normalize_word", "words.append", "extract_graphemes", "lengths.append", "labels.append", "line.strip", "len", "grapheme_dict.items", "mapping.split", "int", "ValueError", "curr_label.append", "curr_label.append", "x.split"], "function", ["home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.normalize_word"], ["def", "preproc_synth_train_data", "(", "labels_file", ",", "representation", "=", "'ADS'", ")", ":", "\n", "    ", "grapheme_dict", "=", "{", "}", "\n", "labels", "=", "[", "]", "\n", "words", "=", "[", "]", "\n", "lengths", "=", "[", "]", "\n", "count", "=", "1", "\n", "\n", "with", "open", "(", "labels_file", ",", "'r'", ")", "as", "file", ":", "\n", "        ", "mappings", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "file", "]", "\n", "\n", "", "labels_dict", "=", "{", "filename", ":", "label", "for", "filename", ",", "label", "in", "(", "mapping", ".", "split", "(", ")", "for", "mapping", "in", "mappings", ")", "}", "\n", "filenames", "=", "sorted", "(", "labels_dict", ".", "keys", "(", ")", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", ")", "\n", "\n", "if", "representation", "==", "'ads'", ":", "\n", "        ", "extract_graphemes", "=", "ads_grapheme_extraction", "\n", "", "elif", "representation", "==", "'vds'", ":", "\n", "        ", "extract_graphemes", "=", "vds_grapheme_extraction", "\n", "", "elif", "representation", "==", "'naive'", ":", "\n", "        ", "extract_graphemes", "=", "naive_grapheme_extraction", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid chracter representation method. Must be one of ads, vds or naive.\"", ")", "\n", "\n", "#grapheme_dict[' '] = 1", "\n", "\n", "", "print", "(", "\"\\nPreprocessing synthetic training data:\"", ")", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "tqdm", "(", "filenames", ")", ")", ":", "\n", "\n", "# Get labels from labels dict", "\n", "        ", "curr_word", "=", "labels_dict", "[", "name", "]", "\n", "curr_word", "=", "normalize_word", "(", "curr_word", ")", "\n", "# print(curr_word)", "\n", "curr_label", "=", "[", "]", "\n", "words", ".", "append", "(", "curr_word", ")", "\n", "\n", "graphemes", "=", "extract_graphemes", "(", "curr_word", ")", "\n", "\n", "for", "grapheme", "in", "graphemes", ":", "\n", "            ", "if", "grapheme", "not", "in", "grapheme_dict", ":", "\n", "                ", "grapheme_dict", "[", "grapheme", "]", "=", "count", "\n", "curr_label", ".", "append", "(", "count", ")", "\n", "count", "+=", "1", "\n", "", "else", ":", "\n", "                ", "curr_label", ".", "append", "(", "grapheme_dict", "[", "grapheme", "]", ")", "\n", "", "", "lengths", ".", "append", "(", "len", "(", "curr_label", ")", ")", "\n", "labels", ".", "append", "(", "curr_label", ")", "\n", "\n", "\n", "", "inv_grapheme_dict", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "grapheme_dict", ".", "items", "(", ")", "}", "\n", "return", "inv_grapheme_dict", ",", "words", ",", "labels", ",", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_train.preproc_synth_valid_data": [[62, 104], ["sorted", "print", "enumerate", "open", "labels_dict.keys", "tqdm.tqdm", "utils_common.normalize_word", "words.append", "extract_graphemes", "lengths.append", "labels.append", "inv_grapheme_dict.items", "line.strip", "len", "mapping.split", "int", "ValueError", "curr_label.append", "curr_label.append", "x.split"], "function", ["home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.normalize_word"], ["", "def", "preproc_synth_valid_data", "(", "labels_file", ",", "inv_grapheme_dict", ",", "representation", "=", "'ADS'", ")", ":", "\n", "    ", "labels", "=", "[", "]", "\n", "words", "=", "[", "]", "\n", "lengths", "=", "[", "]", "\n", "grapheme_dict", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "inv_grapheme_dict", ".", "items", "(", ")", "}", "\n", "\n", "with", "open", "(", "labels_file", ",", "'r'", ")", "as", "file", ":", "\n", "        ", "mappings", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "file", "]", "\n", "\n", "", "labels_dict", "=", "{", "filename", ":", "label", "for", "filename", ",", "label", "in", "(", "mapping", ".", "split", "(", ")", "for", "mapping", "in", "mappings", ")", "}", "\n", "filenames", "=", "sorted", "(", "labels_dict", ".", "keys", "(", ")", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", ")", "\n", "\n", "if", "representation", "==", "'ads'", ":", "\n", "        ", "extract_graphemes", "=", "ads_grapheme_extraction", "\n", "", "elif", "representation", "==", "'vds'", ":", "\n", "        ", "extract_graphemes", "=", "vds_grapheme_extraction", "\n", "", "elif", "representation", "==", "'naive'", ":", "\n", "        ", "extract_graphemes", "=", "naive_grapheme_extraction", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid chracter representation method. Must be one of ads, vds or naive.\"", ")", "\n", "\n", "", "print", "(", "\"\\nPreprocessing synthetic validation training data:\"", ")", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "tqdm", "(", "filenames", ")", ")", ":", "\n", "\n", "# Get labels from labels dict", "\n", "        ", "curr_word", "=", "labels_dict", "[", "name", "]", "\n", "curr_word", "=", "normalize_word", "(", "curr_word", ")", "\n", "# print(curr_word)", "\n", "curr_label", "=", "[", "]", "\n", "words", ".", "append", "(", "curr_word", ")", "\n", "\n", "graphemes", "=", "extract_graphemes", "(", "curr_word", ")", "\n", "\n", "for", "grapheme", "in", "graphemes", ":", "\n", "            ", "if", "grapheme", "not", "in", "grapheme_dict", ":", "\n", "                ", "curr_label", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "curr_label", ".", "append", "(", "grapheme_dict", "[", "grapheme", "]", ")", "\n", "", "", "lengths", ".", "append", "(", "len", "(", "curr_label", ")", ")", "\n", "labels", ".", "append", "(", "curr_label", ")", "\n", "\n", "", "return", "words", ",", "labels", ",", "lengths", "\n", "", ""]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train_student3.train": [[145, 348], ["torch.lr_scheduler.CosineAnnealingWarmRestarts", "range", "student_model.train", "print", "enumerate", "optim.lr_scheduler.CosineAnnealingWarmRestarts.step", "print", "print", "utils_common2.recognition_metrics", "print", "print", "print", "print", "print", "print", "print", "print", "pandas.DataFrame", "pd.DataFrame.to_csv", "train_student3.validate", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "tqdm.tqdm", "inp.to.to", "inp.to.size", "idx.detach().numpy", "list", "utils_common2.get_padded_labels", "student_model", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "labels.detach().numpy.to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.to", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax.cpu().data.numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "kl.cuda.cuda", "criterion", "loss.item", "optimizer.zero_grad", "loss.backward", "optimizer.step", "preds.transpose().contiguous().detach().cpu().numpy.max", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach().cpu().numpy", "labels.detach().numpy.detach().numpy", "range", "open", "zip", "sklearn.metrics.classification_report", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "print", "print", "print", "print", "print", "print", "pandas.DataFrame", "student_model.state_dict", "inp.to.float", "torch.KLDivLoss", "len", "utils_common2.decode_prediction", "zip", "utils_common2.decode_prediction", "utils_common2.decode_prediction", "pred_.append", "label_.append", "fout.write", "fout.write", "fout.write", "fout.write", "pandas.ExcelWriter", "pandas.DataFrame().T.sort_values().to_excel", "open", "zip", "print", "idx.detach", "teacher_model2", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach().cpu", "labels.detach().numpy.detach", "y_pred.append", "y_true.append", "numpy.arange", "fout.write", "fout.write", "fout.write", "fout.write", "preds.transpose().contiguous().detach().cpu().numpy.size", "torch.nn.functional.softmax.cpu", "pandas.DataFrame().T.sort_values", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach", "len", "inv_grapheme_dict.items", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous", "pandas.DataFrame", "preds.transpose().contiguous().detach().cpu().numpy.transpose"], "function", ["home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train_student3.train", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.recognition_metrics", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train_student3.validate", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.get_padded_labels", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction"], ["def", "train", "(", "epochs", "=", "30", ",", "lr", "=", "0.0003", ")", ":", "#lr=0.001", "\n", "\n", "    ", "\"\"\"\n    During Quantization Aware Training, the LR should be 1-10% of the LR used for training without quantization\n    \"\"\"", "\n", "\n", "#optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr, momentum=0.9, dampening=0, weight_decay=1e-05)", "\n", "\n", "# https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.ReduceLROnPlateau.html", "\n", "# new_lr = lr * factor", "\n", "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.9, patience=2, threshold=0.01, min_lr=0.0001, verbose=True)", "\n", "# scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[7, 25], gamma=0.5, verbose=True)", "\n", "scheduler", "=", "optim", ".", "lr_scheduler", ".", "CosineAnnealingWarmRestarts", "(", "optimizer", ",", "T_0", "=", "15", ",", "T_mult", "=", "1", ",", "eta_min", "=", "0.0001", ")", "\n", "#early_stopping = EarlyStopping(patience=10, verbose=True)", "\n", "\n", "for", "epoch", "in", "range", "(", "0", ",", "100", ")", ":", "\n", "\n", "        ", "student_model", ".", "train", "(", ")", "\n", "\n", "#necessary variables", "\n", "y_true", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "pred_", "=", "[", "]", "\n", "label_", "=", "[", "]", "\n", "\n", "total_wer", "=", "0", "\n", "\n", "print", "(", "\"***Epoch: {}***\"", ".", "format", "(", "epoch", ")", ")", "\n", "batch_loss", "=", "0", "\n", "# lr = 0.002", "\n", "t", "=", "2", "\n", "alpha", "=", "0.5", "\n", "for", "i", ",", "(", "inp", ",", "img_names", ",", "idx", ")", "in", "enumerate", "(", "tqdm", "(", "train_loader", ")", ")", ":", "\n", "\n", "            ", "inp", "=", "inp", ".", "to", "(", "device", ")", "\n", "inp", "=", "inp", ".", "float", "(", ")", "/", "255.0", "\n", "batch_size", "=", "inp", ".", "size", "(", "0", ")", "\n", "idxs", "=", "idx", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "img_names", "=", "list", "(", "img_names", ")", "\n", "words", ",", "labels", ",", "labels_size", "=", "get_padded_labels", "(", "idxs", ",", "words_tr", ",", "labels_tr", ",", "lengths_tr", ")", "\n", "#print(words)", "\n", "#print(labels)", "\n", "#print(inp.shape)", "\n", "\n", "#teacher_preds = pred_teacher(teacher_model,labels)", "\n", "#teacher_preds = teacher_preds.cuda()", "\n", "#teacher_preds = teacher_model(inp)", "\n", "#teacher_preds.to(device) ", "\n", "#print(teacher_preds.shape)", "\n", "#print(teacher_preds[3][0][0])", "\n", "#soft_targets = F.log_softmax(teacher_preds /3)", "\n", "#print(soft_targets.shape)", "\n", "#print(teacher_preds)", "\n", "z_score", "=", "student_model", "(", "inp", ")", "\n", "\n", "preds", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "z_score", ",", "dim", "=", "2", ")", "\n", "pr", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "z_score", "/", "t", ",", "dim", "=", "2", ")", "\n", "#preds = torch.nn.functional.log_softmax(model(inp), dim=2)", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "labels", ".", "to", "(", "device", ")", "\n", "labels_size", "=", "torch", ".", "tensor", "(", "labels_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "labels_size", ".", "to", "(", "device", ")", "\n", "preds_size", "=", "torch", ".", "tensor", "(", "[", "preds", ".", "size", "(", "0", ")", "]", "*", "batch_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "preds_size", ".", "to", "(", "device", ")", "\n", "\n", "#teacher model 2", "\n", "\n", "preds2", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "teacher_model2", "(", "inp", ")", "/", "t", ",", "dim", "=", "2", ")", "\n", "#preds2 = preds2.cuda()", "\n", "kl", "=", "preds2", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "kl", "=", "torch", ".", "from_numpy", "(", "kl", ")", "\n", "kl", "=", "kl", ".", "cuda", "(", ")", "\n", "#div = F.softmax(kl/t)", "\n", "#div = div.cuda()", "\n", "#loss = criterion(preds, labels, preds_size, labels_size)'''", "\n", "\n", "ctc_loss", "=", "criterion", "(", "preds", ",", "labels", ",", "preds_size", ",", "labels_size", ")", "\n", "#(nn.KLDivLoss()(F.log_softmax(preds / t), F.softmax(teacher_preds/t))+nn.KLDivLoss()(F.log_softmax(preds / t), F.softmax(preds2/t)) ) * (t*t * 2.0 + alpha)  + +nn.KLDivLoss()(F.log_softmax(preds / t), F.softmax(preds2/t))", "\n", "ty", "=", "nn", ".", "KLDivLoss", "(", ")", "(", "pr", ",", "kl", ")", "\n", "\n", "loss", "=", "ty", "*", "(", "t", "*", "t", "*", "2.0", "+", "alpha", ")", "+", "ctc_loss", "*", "(", "1.", "-", "alpha", ")", "\n", "#print(loss.item())", "\n", "batch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "_", ",", "preds", "=", "preds", ".", "max", "(", "2", ")", "\n", "preds", "=", "preds", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "labels", "=", "labels", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "preds", ")", ")", ":", "\n", "                ", "decoded", ",", "_", "=", "decode_prediction", "(", "preds", "[", "i", "]", ",", "inv_grapheme_dict", ")", "\n", "for", "x", ",", "y", "in", "zip", "(", "decoded", ",", "labels", "[", "i", "]", ")", ":", "\n", "                    ", "y_pred", ".", "append", "(", "x", ")", "\n", "#print(x)", "\n", "#print('t')", "\n", "#print(y)", "\n", "y_true", ".", "append", "(", "y", ")", "\n", "", "_", ",", "decoded_pred_", "=", "decode_prediction", "(", "preds", "[", "i", "]", ",", "inv_grapheme_dict", ")", "\n", "#print(inv_grapheme_dict)", "\n", "_", ",", "decoded_label_", "=", "decode_prediction", "(", "labels", "[", "i", "]", ",", "inv_grapheme_dict", ",", "gt", "=", "True", ")", "\n", "#print(decoded_label_)", "\n", "\n", "pred_", ".", "append", "(", "decoded_pred_", ")", "\n", "\n", "label_", ".", "append", "(", "decoded_label_", ")", "\n", "#print(pred_)", "\n", "\n", "", "", "scheduler", ".", "step", "(", ")", "\n", "\n", "train_loss", "=", "batch_loss", "/", "train_batch_s", "\n", "print", "(", "\"Epoch Training loss: \"", ",", "train_loss", ")", "#batch_size denominator 32", "\n", "\n", "print", "(", "\"\\n\"", ")", "\n", "rec_results", "=", "recognition_metrics", "(", "pred_", ",", "label_", ",", "file_name", "=", "\"results.csv\"", ")", "\n", "print", "(", "'\\n'", ")", "\n", "#print(pred_)", "\n", "#print(label_)", "\n", "print", "(", "\"Absolute Word Match Count: %d\"", "%", "rec_results", "[", "'abs_match'", "]", ")", "\n", "print", "(", "\"Word Recognition Rate (WRR): %.4f\"", "%", "rec_results", "[", "'wrr'", "]", ")", "\n", "print", "(", "\"Normal Edit Distance (NED): %.4f\"", "%", "rec_results", "[", "'total_ned'", "]", ")", "\n", "print", "(", "\"Character Recognition Rate (CRR): %.4f\"", "%", "rec_results", "[", "'crr'", "]", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "print", "(", "\"End of Epoch \"", ",", "epoch", ")", "\n", "print", "(", "\"\\n\\n\"", ")", "\n", "\n", "with", "open", "(", "\"./\"", "+", "path", "+", "\"/results_training.txt\"", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "for", "x", ",", "y", "in", "zip", "(", "pred_", ",", "label_", ")", ":", "\n", "                ", "fout", ".", "write", "(", "\"True: {}\"", ".", "format", "(", "y", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "fout", ".", "write", "(", "\"Pred: {}\"", ".", "format", "(", "x", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "", "", "metrics", "=", "pd", ".", "DataFrame", "(", "[", "{", "'epoch'", ":", "epoch", ",", "\n", "'crr'", ":", "rec_results", "[", "'crr'", "]", ",", "\n", "'wrr'", ":", "rec_results", "[", "'wrr'", "]", ",", "\n", "'ned'", ":", "rec_results", "[", "'total_ned'", "]", ",", "\n", "'abs_match'", ":", "rec_results", "[", "'abs_match'", "]", ",", "\n", "'train_loss'", ":", "train_loss", "\n", "}", "]", ")", "\n", "\n", "metrics", ".", "to_csv", "(", "\"./\"", "+", "path", "+", "\"/metrics_training.csv\"", ",", "\n", "mode", "=", "(", "'w'", "if", "epoch", "==", "0", "else", "'a'", ")", ",", "index", "=", "False", ",", "header", "=", "(", "True", "if", "epoch", "==", "0", "else", "False", ")", ")", "\n", "\n", "\n", "#total_wer, _ = compute_wer(pred_, label_)", "\n", "#print(\"Total AED Word Error Rate (Training): %.4f\" % total_wer)", "\n", "\n", "#change in number of labels", "\n", "try", ":", "\n", "            ", "report", "=", "classification_report", "(", "y_true", ",", "y_pred", ",", "labels", "=", "np", ".", "arange", "(", "1", ",", "len", "(", "inv_grapheme_dict", ")", "+", "1", ")", ",", "\n", "zero_division", "=", "0", ",", "output_dict", "=", "True", ",", "target_names", "=", "[", "v", "for", "k", ",", "v", "in", "inv_grapheme_dict", ".", "items", "(", ")", "]", ")", "\n", "f1_micro", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'micro'", ",", "zero_division", "=", "0", ")", "\n", "f1_macro", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'macro'", ",", "zero_division", "=", "0", ")", "\n", "accuracy", "=", "accuracy_score", "(", "y_true", ",", "y_pred", ")", "\n", "\n", "#Absolute word matching", "\n", "#abs_correct = absolute_word_match(pred_, label_)", "\n", "\n", "#print(\"Absolute Word Match Count: {}\".format(abs_correct))", "\n", "#print(\"Absolute Word Match Percentage: %.4f\" % (abs_correct / num_train_samples))", "\n", "print", "(", "\"Training Accuracy: %.4f\"", "%", "accuracy", ")", "\n", "print", "(", "\"Training F1 Micro Score: %.4f\"", "%", "f1_micro", ")", "\n", "print", "(", "\"Training F1 Macro Score: %.4f\"", "%", "f1_macro", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "print", "(", "\"End of Training FOR Epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "print", "(", "\"\\n\\n\"", ")", "\n", "\n", "##################### Generate Training Report ##############################", "\n", "\n", "with", "pd", ".", "ExcelWriter", "(", "\"./\"", "+", "path", "+", "\"/classification_report_training.xlsx\"", ",", "engine", "=", "'openpyxl'", ",", "mode", "=", "(", "'w'", "if", "epoch", "==", "0", "else", "'a'", ")", ")", "as", "writer", ":", "\n", "                ", "pd", ".", "DataFrame", "(", "report", ")", ".", "T", ".", "sort_values", "(", "by", "=", "'support'", ",", "ascending", "=", "False", ")", ".", "to_excel", "(", "writer", ",", "sheet_name", "=", "'epoch{}'", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "", "with", "open", "(", "\"./\"", "+", "path", "+", "\"/results_training.txt\"", ",", "'w'", ")", "as", "fout", ":", "\n", "                ", "for", "x", ",", "y", "in", "zip", "(", "pred_", ",", "label_", ")", ":", "\n", "                    ", "fout", ".", "write", "(", "\"True: {}\"", ".", "format", "(", "y", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "fout", ".", "write", "(", "\"Pred: {}\"", ".", "format", "(", "x", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "", "", "metrics", "=", "pd", ".", "DataFrame", "(", "[", "{", "'epoch'", ":", "epoch", ",", "\n", "'accuracy'", ":", "accuracy", ",", "\n", "'train_loss'", ":", "train_loss", ",", "\n", "\n", "'f1_micro'", ":", "f1_micro", ",", "\n", "'f1_macro'", ":", "f1_macro", "\n", "\n", "}", "]", ")", "\n", "\n", "", "except", ":", "\n", "            ", "print", "(", "'error'", ")", "\n", "#############################################################################'''", "\n", "\n", "", "valid_loss", "=", "validate", "(", "epoch", ",", "valid_batch_s", ",", "train_loss", ")", "\n", "#early_stopping(valid_loss, student_model)", "\n", "\n", "#if early_stopping.early_stop:", "\n", "#print(\"Early stopping\")", "\n", "#break", "\n", "\n", "#scheduler.step()", "\n", "torch", ".", "save", "(", "student_model", ".", "state_dict", "(", ")", ",", "'./'", "+", "path", "+", "'/epoch{}.pth'", ".", "format", "(", "epoch", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.train_student3.validate": [[349, 501], ["student_model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "print", "enumerate", "print", "print", "utils_common2.recognition_metrics", "print", "print", "print", "print", "print", "print", "print", "print", "pandas.DataFrame", "pd.DataFrame.to_csv", "sklearn.metrics.accuracy_score", "print", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "print", "print", "print", "print", "print", "print", "tqdm.tqdm", "inp.to.to", "inp.to.size", "idx.detach().numpy", "list", "utils_common2.get_padded_labels", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "labels.detach().numpy.to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.to", "criterion", "criterion.item", "preds.transpose().contiguous().detach().cpu().numpy.max", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach().cpu().numpy", "labels.detach().numpy.detach().numpy", "zip", "open", "zip", "sklearn.metrics.classification_report", "pandas.DataFrame", "inp.to.float", "student_model", "utils_common2.decode_prediction", "zip", "utils_common2.decode_prediction", "utils_common2.decode_prediction", "decoded_preds.append", "decoded_labels.append", "fout.write", "fout.write", "fout.write", "fout.write", "print", "pandas.ExcelWriter", "pandas.DataFrame().T.sort_values().to_excel", "open", "zip", "print", "idx.detach", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach().cpu", "labels.detach().numpy.detach", "y_pred.append", "y_true.append", "numpy.arange", "fout.write", "fout.write", "fout.write", "fout.write", "preds.transpose().contiguous().detach().cpu().numpy.size", "pandas.DataFrame().T.sort_values", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous().detach", "len", "inv_grapheme_dict.items", "preds.transpose().contiguous().detach().cpu().numpy.transpose().contiguous", "pandas.DataFrame", "preds.transpose().contiguous().detach().cpu().numpy.transpose"], "function", ["home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.recognition_metrics", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.get_padded_labels", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction", "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.utils_common.decode_prediction"], ["", "", "def", "validate", "(", "epoch", ",", "valid_batch_s", ",", "train_loss", ")", ":", "\n", "\n", "# evaluate model:", "\n", "    ", "student_model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y_true", "=", "[", "]", "\n", "y_pred", "=", "[", "]", "\n", "pred_", "=", "[", "]", "\n", "label_", "=", "[", "]", "\n", "decoded_preds", "=", "[", "]", "\n", "decoded_labels", "=", "[", "]", "\n", "total_wer", "=", "0", "\n", "\n", "print", "(", "\"***Epoch: {}***\"", ".", "format", "(", "epoch", ")", ")", "\n", "batch_loss", "=", "0", "\n", "for", "i", ",", "(", "inp", ",", "img_names", ",", "idx", ")", "in", "enumerate", "(", "tqdm", "(", "validation_loader", ")", ")", ":", "\n", "\n", "            ", "inp", "=", "inp", ".", "to", "(", "device", ")", "\n", "inp", "=", "inp", ".", "float", "(", ")", "/", "255.0", "\n", "batch_size", "=", "inp", ".", "size", "(", "0", ")", "\n", "idxs", "=", "idx", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "img_names", "=", "list", "(", "img_names", ")", "\n", "words", ",", "labels", ",", "labels_size", "=", "get_padded_labels", "(", "idxs", ",", "words_val", ",", "labels_val", ",", "lengths_val", ")", "\n", "\n", "preds", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "student_model", "(", "inp", ")", ",", "dim", "=", "2", ")", "\n", "labels", "=", "torch", ".", "tensor", "(", "labels", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "labels", ".", "to", "(", "device", ")", "\n", "labels_size", "=", "torch", ".", "tensor", "(", "labels_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "labels_size", ".", "to", "(", "device", ")", "\n", "preds_size", "=", "torch", ".", "tensor", "(", "[", "preds", ".", "size", "(", "0", ")", "]", "*", "batch_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "preds_size", ".", "to", "(", "device", ")", "\n", "\n", "#validation loss", "\n", "loss", "=", "criterion", "(", "preds", ",", "labels", ",", "preds_size", ",", "labels_size", ")", "\n", "#print(loss)", "\n", "batch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "#print(loss.item())", "\n", "\n", "_", ",", "preds", "=", "preds", ".", "max", "(", "2", ")", "\n", "preds", "=", "preds", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "labels", "=", "labels", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "for", "pred", ",", "label", "in", "zip", "(", "preds", ",", "labels", ")", ":", "\n", "                ", "decoded", ",", "_", "=", "decode_prediction", "(", "pred", ",", "inv_grapheme_dict", ")", "\n", "#_, decoded_label_ = decode_prediction(labels[i], inv_grapheme_dict, gt=True)", "\n", "for", "x", ",", "y", "in", "zip", "(", "decoded", ",", "label", ")", ":", "\n", "\n", "                    ", "y_pred", ".", "append", "(", "x", ")", "\n", "y_true", ".", "append", "(", "y", ")", "\n", "\n", "", "_", ",", "decoded_pred", "=", "decode_prediction", "(", "pred", ",", "inv_grapheme_dict", ")", "\n", "_", ",", "decoded_label", "=", "decode_prediction", "(", "label", ",", "inv_grapheme_dict", ",", "gt", "=", "True", ")", "\n", "# print(\"Pred: \" + decoded_pred)", "\n", "# print(\"Truth: \" + decoded_label)", "\n", "\n", "decoded_preds", ".", "append", "(", "decoded_pred", ")", "\n", "decoded_labels", ".", "append", "(", "decoded_label", ")", "\n", "\n", "", "", "valid_loss", "=", "batch_loss", "/", "valid_batch_s", "\n", "print", "(", "\"Epoch Validation loss: \"", ",", "valid_loss", ")", "#batch_size denominator 32", "\n", "print", "(", "\"\\n\"", ")", "\n", "rec_results", "=", "recognition_metrics", "(", "decoded_preds", ",", "decoded_labels", ",", "file_name", "=", "\"results.csv\"", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "#print(pred_)", "\n", "#print(label_)", "\n", "print", "(", "\"Absolute Word Match Count: %d\"", "%", "rec_results", "[", "'abs_match'", "]", ")", "\n", "print", "(", "\"Word Recognition Rate (WRR): %.4f\"", "%", "rec_results", "[", "'wrr'", "]", ")", "\n", "print", "(", "\"Normal Edit Distance (NED): %.4f\"", "%", "rec_results", "[", "'total_ned'", "]", ")", "\n", "print", "(", "\"Character Recognition Rate (CRR): %.4f\"", "%", "rec_results", "[", "'crr'", "]", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "print", "(", "\"End of Epoch \"", ",", "epoch", ")", "\n", "print", "(", "\"\\n\\n\"", ")", "\n", "\n", "with", "open", "(", "\"./\"", "+", "path", "+", "\"/results_validation.txt\"", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "for", "x", ",", "y", "in", "zip", "(", "pred_", ",", "label_", ")", ":", "\n", "                ", "fout", ".", "write", "(", "\"True: {}\"", ".", "format", "(", "y", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "fout", ".", "write", "(", "\"Pred: {}\"", ".", "format", "(", "x", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "", "", "metrics", "=", "pd", ".", "DataFrame", "(", "[", "{", "'epoch'", ":", "epoch", ",", "\n", "'crr'", ":", "rec_results", "[", "'crr'", "]", ",", "\n", "'wrr'", ":", "rec_results", "[", "'wrr'", "]", ",", "\n", "'ned'", ":", "rec_results", "[", "'total_ned'", "]", ",", "\n", "'abs_match'", ":", "rec_results", "[", "'abs_match'", "]", ",", "\n", "'train_loss'", ":", "train_loss", "\n", "}", "]", ")", "\n", "\n", "metrics", ".", "to_csv", "(", "\"./\"", "+", "path", "+", "\"/metrics_validation.csv\"", ",", "\n", "mode", "=", "(", "'w'", "if", "epoch", "==", "0", "else", "'a'", ")", ",", "index", "=", "False", ",", "header", "=", "(", "True", "if", "epoch", "==", "0", "else", "False", ")", ")", "\n", "\n", "#total_wer, _ = compute_wer(pred_, label_)", "\n", "#print(\"Total AED Word Error Rate: %.4f\" % total_wer)", "\n", "accuracy", "=", "accuracy_score", "(", "y_true", ",", "y_pred", ")", "\n", "print", "(", "'accuracy '", ",", "accuracy", ")", "\n", "\n", "#change in number of labels", "\n", "try", ":", "\n", "            ", "report", "=", "classification_report", "(", "y_true", ",", "y_pred", ",", "labels", "=", "np", ".", "arange", "(", "1", ",", "len", "(", "inv_grapheme_dict", ")", "+", "1", ")", ",", "\n", "zero_division", "=", "0", ",", "output_dict", "=", "True", ",", "target_names", "=", "[", "v", "for", "k", ",", "v", "in", "inv_grapheme_dict", ".", "items", "(", ")", "]", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "'error'", ")", "\n", "", "f1_micro", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'micro'", ",", "zero_division", "=", "0", ")", "\n", "f1_macro", "=", "f1_score", "(", "y_true", ",", "y_pred", ",", "average", "=", "'macro'", ",", "zero_division", "=", "0", ")", "\n", "accuracy", "=", "accuracy_score", "(", "y_true", ",", "y_pred", ")", "\n", "\n", "\n", "#Absolute word matching", "\n", "#abs_correct = absolute_word_match(pred_, label_)", "\n", "\n", "#print(\"Absolute Word Match Count: {}\".format(abs_correct))", "\n", "#print(\"Abs Match Percentage: %.4f\" % (abs_correct / num_valid_samples))", "\n", "print", "(", "\"Accuracy: %.4f\"", "%", "accuracy", ")", "\n", "print", "(", "\"F1 Micro Score: %.4f\"", "%", "f1_micro", ")", "\n", "print", "(", "\"F1 Macro Score: %.4f\"", "%", "f1_macro", ")", "\n", "print", "(", "\"\\n\"", ")", "\n", "print", "(", "\"End of Epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "print", "(", "\"\\n\\n\"", ")", "\n", "\n", "##################### Generate Validation Report ##############################", "\n", "\n", "try", ":", "\n", "\n", "            ", "with", "pd", ".", "ExcelWriter", "(", "\"./\"", "+", "path", "+", "\"/classification_report_validation.xlsx\"", ",", "engine", "=", "'openpyxl'", ",", "mode", "=", "(", "'w'", "if", "epoch", "==", "0", "else", "'a'", ")", ")", "as", "writer", ":", "\n", "                ", "pd", ".", "DataFrame", "(", "report", ")", ".", "T", ".", "sort_values", "(", "by", "=", "'support'", ",", "ascending", "=", "False", ")", ".", "to_excel", "(", "writer", ",", "sheet_name", "=", "'epoch{}'", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "", "with", "open", "(", "\"./\"", "+", "path", "+", "\"/results_validation.txt\"", ",", "'w'", ")", "as", "fout", ":", "\n", "                ", "for", "x", ",", "y", "in", "zip", "(", "pred_", ",", "label_", ")", ":", "\n", "                    ", "fout", ".", "write", "(", "\"True: {}\"", ".", "format", "(", "y", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "fout", ".", "write", "(", "\"Pred: {}\"", ".", "format", "(", "x", ")", ")", "\n", "fout", ".", "write", "(", "\"\\n\\n\"", ")", "\n", "\n", "", "", "metrics", "=", "pd", ".", "DataFrame", "(", "[", "{", "'epoch'", ":", "epoch", ",", "\n", "'accuracy'", ":", "accuracy", ",", "\n", "'train_loss'", ":", "train_loss", ",", "\n", "'valid_loss'", ":", "valid_loss", ",", "\n", "\n", "'f1_micro'", ":", "f1_micro", ",", "\n", "'f1_macro'", ":", "f1_macro", ",", "\n", "\n", "}", "]", ")", "\n", "\n", "#metrics.to_csv(\"./bnhtrdtrain/normalkd1/metrics_validation.csv\", ", "\n", "#mode=('w' if epoch==0 else 'a'), index=False, header=(True if epoch==0 else False)) ", "\n", "", "except", ":", "\n", "            ", "print", "(", "'error'", ")", "\n", "\n", "###############################################################################", "\n", "\n", "", "return", "valid_loss", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.SynthDataset.__init__": [[10, 17], ["sorted", "os.listdir", "int", "x.split"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "img_dir", ",", "transform", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "img_dir", "=", "img_dir", "\n", "self", ".", "inp_h", "=", "32", "\n", "self", ".", "inp_w", "=", "128", "\n", "self", ".", "img_names", "=", "sorted", "(", "os", ".", "listdir", "(", "img_dir", ")", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.SynthDataset.__len__": [[18, 20], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "img_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.SynthDataset.__getitem__": [[21, 40], ["cv2.imread", "cv2.cvtColor", "cv2.resize", "numpy.reshape", "image.transpose.transpose.transpose", "os.path.join", "datasets.SynthDataset.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "img_name", "=", "self", ".", "img_names", "[", "idx", "]", "\n", "# print(img_name)", "\n", "image", "=", "cv2", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "self", ".", "img_dir", ",", "img_name", ")", ")", "\n", "image", "=", "cv2", ".", "cvtColor", "(", "image", ",", "cv2", ".", "COLOR_BGR2GRAY", ")", "\n", "img_h", ",", "img_w", "=", "image", ".", "shape", "\n", "image", "=", "cv2", ".", "resize", "(", "image", ",", "(", "0", ",", "0", ")", ",", "fx", "=", "self", ".", "inp_w", "/", "img_w", ",", "fy", "=", "self", ".", "inp_h", "/", "img_h", ",", "interpolation", "=", "cv2", ".", "INTER_CUBIC", ")", "\n", "#print(image.shape)", "\n", "image", "=", "np", ".", "reshape", "(", "image", ",", "(", "self", ".", "inp_h", ",", "self", ".", "inp_w", ",", "1", ")", ")", "\n", "#print(image.shape)", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "image", "=", "self", ".", "transform", "(", "image", "=", "image", ")", "[", "\"image\"", "]", "\n", "return", "image", ",", "img_name", ",", "idx", "\n", "\n", "", "image", "=", "image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "#print(image.shape)", "\n", "\n", "return", "image", ",", "img_name", ",", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.TestDataset.__init__": [[44, 53], ["sorted", "os.listdir", "int", "x.split"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "img_dir", ",", "transform", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "img_dir", "=", "img_dir", "\n", "# self.text_dir = text_dir", "\n", "self", ".", "inp_h", "=", "32", "\n", "self", ".", "inp_w", "=", "128", "\n", "self", ".", "img_names", "=", "sorted", "(", "os", ".", "listdir", "(", "img_dir", ")", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", ")", "\n", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.TestDataset.__len__": [[54, 56], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "img_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.TestDataset.__getitem__": [[57, 78], ["cv2.imread", "cv2.cvtColor", "cv2.resize", "numpy.reshape", "image.transpose.transpose.transpose", "os.path.join", "datasets.TestDataset.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "img_name", "=", "self", ".", "img_names", "[", "idx", "]", "\n", "# print(img_name)", "\n", "image", "=", "cv2", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "self", ".", "img_dir", ",", "img_name", ")", ")", "\n", "image", "=", "cv2", ".", "cvtColor", "(", "image", ",", "cv2", ".", "COLOR_BGR2GRAY", ")", "\n", "\n", "img_h", ",", "img_w", "=", "image", ".", "shape", "\n", "\n", "image", "=", "cv2", ".", "resize", "(", "image", ",", "(", "0", ",", "0", ")", ",", "fx", "=", "self", ".", "inp_w", "/", "img_w", ",", "fy", "=", "self", ".", "inp_h", "/", "img_h", ",", "interpolation", "=", "cv2", ".", "INTER_CUBIC", ")", "\n", "#print(image.shape)", "\n", "image", "=", "np", ".", "reshape", "(", "image", ",", "(", "self", ".", "inp_h", ",", "self", ".", "inp_w", ",", "1", ")", ")", "\n", "#print(image.shape)", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "image", "=", "self", ".", "transform", "(", "image", "=", "image", ")", "[", "\"image\"", "]", "\n", "return", "image", ",", "img_name", ",", "idx", "\n", "\n", "", "image", "=", "image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "#print(image.shape)", "\n", "\n", "return", "image", ",", "img_name", ",", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.ApurbaDataset.__init__": [[82, 90], ["pandas.read_csv"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "img_dir", ",", "csv_path", ",", "transform", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "img_dir", "=", "img_dir", "\n", "self", ".", "inp_h", "=", "32", "\n", "self", ".", "inp_w", "=", "128", "\n", "self", ".", "images", "=", "pd", ".", "read_csv", "(", "csv_path", ")", "\n", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.ApurbaDataset.__len__": [[91, 93], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "images", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.ApurbaDataset.__getitem__": [[94, 116], ["os.path.join", "cv2.imread", "cv2.cvtColor", "cv2.resize", "numpy.reshape", "image.transpose.transpose.transpose", "datasets.ApurbaDataset.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "img_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "img_dir", ",", "self", ".", "images", ".", "iloc", "[", "idx", "]", "[", "'Image Path'", "]", ")", "\n", "label", "=", "self", ".", "images", ".", "iloc", "[", "idx", "]", "[", "'Word'", "]", "\n", "aid", "=", "self", ".", "images", ".", "iloc", "[", "idx", "]", "[", "'id'", "]", "\n", "image", "=", "cv2", ".", "imread", "(", "img_path", ")", "\n", "image", "=", "cv2", ".", "cvtColor", "(", "image", ",", "cv2", ".", "COLOR_BGR2GRAY", ")", "\n", "\n", "img_h", ",", "img_w", "=", "image", ".", "shape", "\n", "\n", "image", "=", "cv2", ".", "resize", "(", "image", ",", "(", "0", ",", "0", ")", ",", "fx", "=", "self", ".", "inp_w", "/", "img_w", ",", "fy", "=", "self", ".", "inp_h", "/", "img_h", ",", "interpolation", "=", "cv2", ".", "INTER_CUBIC", ")", "\n", "#print(image.shape)", "\n", "image", "=", "np", ".", "reshape", "(", "image", ",", "(", "self", ".", "inp_h", ",", "self", ".", "inp_w", ",", "1", ")", ")", "\n", "#print(image.shape)", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "image", "=", "self", ".", "transform", "(", "image", "=", "image", ")", "[", "\"image\"", "]", "\n", "return", "image", ",", "label", ",", "aid", "\n", "\n", "", "image", "=", "image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "#print(image.shape)", "\n", "\n", "return", "image", ",", "label", ",", "aid", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.Synth12Dataset.__init__": [[120, 128], ["sorted", "os.listdir", "int", "x.split"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "img_dir", ",", "transform", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "img_dir", "=", "img_dir", "\n", "self", ".", "inp_h", "=", "32", "\n", "self", ".", "inp_w", "=", "128", "\n", "self", ".", "img_names", "=", "sorted", "(", "os", ".", "listdir", "(", "img_dir", ")", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", ")", "\n", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.Synth12Dataset.__len__": [[129, 131], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "img_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.apurba-nsu-rnd-lab_lila-boti.None.datasets.Synth12Dataset.__getitem__": [[132, 153], ["cv2.imread", "cv2.cvtColor", "cv2.resize", "numpy.reshape", "image.transpose.transpose.transpose", "os.path.join", "datasets.Synth12Dataset.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "img_name", "=", "self", ".", "img_names", "[", "idx", "]", "\n", "# print(img_name)", "\n", "image", "=", "cv2", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "self", ".", "img_dir", ",", "img_name", ")", ")", "\n", "image", "=", "cv2", ".", "cvtColor", "(", "image", ",", "cv2", ".", "COLOR_BGR2GRAY", ")", "\n", "\n", "img_h", ",", "img_w", "=", "image", ".", "shape", "\n", "\n", "image", "=", "cv2", ".", "resize", "(", "image", ",", "(", "0", ",", "0", ")", ",", "fx", "=", "self", ".", "inp_w", "/", "img_w", ",", "fy", "=", "self", ".", "inp_h", "/", "img_h", ",", "interpolation", "=", "cv2", ".", "INTER_CUBIC", ")", "\n", "#print(image.shape)", "\n", "image", "=", "np", ".", "reshape", "(", "image", ",", "(", "self", ".", "inp_h", ",", "self", ".", "inp_w", ",", "1", ")", ")", "\n", "#print(image.shape)", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "image", "=", "self", ".", "transform", "(", "image", "=", "image", ")", "[", "\"image\"", "]", "\n", "return", "image", ",", "img_name", ",", "idx", "\n", "\n", "", "image", "=", "image", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "#print(image.shape)", "\n", "\n", "return", "image", ",", "img_name", ",", "idx", "", "", "", ""]]}