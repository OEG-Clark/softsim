{"home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address": [[38, 40], ["uuid.uuid4"], "methods", ["None"], ["  ", "def", "get_unix_address", "(", "self", ")", ":", "\n", "    ", "return", "'unix:/tmp/%s'", "%", "uuid", ".", "uuid4", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_simple": [[41, 55], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_simple", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "self", ".", "assertAllEqual", "(", "43", ",", "client", ".", "foo", "(", "42", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_simple_two_calls": [[58, 73], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "ops_test.OpsTest.assertAllEqual", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "seed_rl.grpc.python.ops.Client.foo", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_simple_two_calls", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "self", ".", "assertAllEqual", "(", "43", ",", "client", ".", "foo", "(", "42", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "44", ",", "client", ".", "foo", "(", "43", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_empty_input": [[74, 88], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "seed_rl.grpc.python.ops.Client.foo"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_empty_input", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "]", ")", "\n", "def", "foo", "(", ")", ":", "\n", "      ", "return", "42", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "self", ".", "assertAllEqual", "(", "42", ",", "client", ".", "foo", "(", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_empty_output": [[89, 103], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_empty_output", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "[", "]", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "self", ".", "assertAllEqual", "(", "[", "]", ",", "client", ".", "foo", "(", "42", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_no_output": [[104, 118], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "ops_test.OpsTest.assertIsNone", "seed_rl.grpc.python.ops.Server.shutdown", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_no_output", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "pass", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "self", ".", "assertIsNone", "(", "client", ".", "foo", "(", "42", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_large_tensor": [[119, 135], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.fill", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.TensorSpec", "list"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_large_tensor", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "t", "=", "tf", ".", "fill", "(", "[", "10", ",", "1024", ",", "1024", "]", ",", "1", ")", "# 40MB", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", "+", "list", "(", "t", ".", "shape", ")", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "self", ".", "assertAllEqual", "(", "t", "+", "1", ",", "client", ".", "foo", "(", "t", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_create_variable": [[136, 159], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "ops_test.OpsTest.assertAllEqual", "ops_test.OpsTest.assertAllEqual", "state[].assign", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "state[].read_value", "seed_rl.grpc.python.ops.Client.foo", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.device", "tensorflow.device", "tensorflow.Variable", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_create_variable", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "state", "=", "[", "None", "]", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "if", "state", "[", "0", "]", "is", "None", ":", "\n", "        ", "with", "tf", ".", "device", "(", "'/device:CPU:0'", ")", ":", "\n", "          ", "state", "[", "0", "]", "=", "tf", ".", "Variable", "(", "42", ")", "\n", "", "", "with", "tf", ".", "device", "(", "'/device:CPU:0'", ")", ":", "\n", "        ", "return", "x", "+", "state", "[", "0", "]", "\n", "\n", "", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "self", ".", "assertAllEqual", "(", "42", ",", "state", "[", "0", "]", ".", "read_value", "(", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "43", ",", "client", ".", "foo", "(", "1", ")", ")", "\n", "state", "[", "0", "]", ".", "assign", "(", "0", ")", "\n", "self", ".", "assertAllEqual", "(", "1", ",", "client", ".", "foo", "(", "1", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_wait_for_server": [[160, 181], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Client", "concurrent.futures.ThreadPoolExecutor", "executor.submit", "time.sleep", "seed_rl.grpc.python.ops.Server.start", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "executor.submit.result().foo", "tensorflow.TensorSpec", "executor.submit.result"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_wait_for_server", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "\n", "def", "create_client", "(", ")", ":", "\n", "      ", "result", "=", "ops", ".", "Client", "(", "address", ")", "\n", "return", "result", "\n", "\n", "", "with", "futures", ".", "ThreadPoolExecutor", "(", "max_workers", "=", "1", ")", "as", "executor", ":", "\n", "      ", "f", "=", "executor", ".", "submit", "(", "create_client", ")", "\n", "\n", "time", ".", "sleep", "(", "2", ")", "\n", "server", ".", "start", "(", ")", "\n", "self", ".", "assertAllEqual", "(", "43", ",", "f", ".", "result", "(", ")", ".", "foo", "(", "42", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_wait_for_server2": [[182, 203], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Client", "ops_test.OpsTest.assertAllEqual", "concurrent.futures.ThreadPoolExecutor", "executor.submit", "time.sleep", "seed_rl.grpc.python.ops.Server.start", "executor.submit.result", "seed_rl.grpc.python.ops.Server.shutdown", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "", "def", "test_wait_for_server2", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "\n", "def", "create_and_send", "(", ")", ":", "\n", "      ", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "self", ".", "assertAllEqual", "(", "43", ",", "client", ".", "foo", "(", "42", ")", ")", "\n", "\n", "", "with", "futures", ".", "ThreadPoolExecutor", "(", "max_workers", "=", "1", ")", "as", "executor", ":", "\n", "      ", "f", "=", "executor", ".", "submit", "(", "create_and_send", ")", "\n", "\n", "time", ".", "sleep", "(", "2", ")", "\n", "server", ".", "start", "(", ")", "\n", "f", ".", "result", "(", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_upvalue": [[204, 220], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.constant", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "", "def", "test_upvalue", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "a", "=", "tf", ".", "constant", "(", "2", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "/", "a", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "self", ".", "assertAllEqual", "(", "21", ",", "client", ".", "foo", "(", "42", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_queue": [[221, 242], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.queue.FIFOQueue", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "seed_rl.grpc.python.ops.Client.foo", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "tensorflow.queue.FIFOQueue.dequeue", "tensorflow.queue.FIFOQueue.enqueue_many", "tensorflow.queue.FIFOQueue.enqueue", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.dequeue", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.enqueue_many", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.enqueue"], ["", "def", "test_queue", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "q", "=", "tf", ".", "queue", ".", "FIFOQueue", "(", "1", ",", "[", "tf", ".", "int32", "]", ",", "[", "(", ")", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "if", "x", ".", "shape", "==", "(", "1", ",", ")", ":", "\n", "        ", "q", ".", "enqueue_many", "(", "[", "x", "]", ")", "\n", "", "else", ":", "\n", "        ", "q", ".", "enqueue", "(", "[", "x", "]", ")", "\n", "", "return", "x", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "client", ".", "foo", "(", "42", ")", "\n", "self", ".", "assertAllEqual", "(", "42", ",", "q", ".", "dequeue", "(", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_string": [[243, 257], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "tensorflow.strings.join", "seed_rl.grpc.python.ops.Client.hello", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_string", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "string", ")", "]", ")", "\n", "def", "hello", "(", "x", ")", ":", "\n", "      ", "return", "tf", ".", "strings", ".", "join", "(", "[", "x", ",", "' world'", "]", ")", "\n", "\n", "", "server", ".", "bind", "(", "hello", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "self", ".", "assertAllEqual", "(", "b'hello world'", ",", "client", ".", "hello", "(", "'hello'", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_client_non_scalar_server_address": [[258, 262], ["ops_test.OpsTest.assertRaisesRegex", "seed_rl.grpc.python.ops.Client"], "methods", ["None"], ["", "def", "test_client_non_scalar_server_address", "(", "self", ")", ":", "\n", "    ", "with", "self", ".", "assertRaisesRegex", "(", "tf", ".", "errors", ".", "InvalidArgumentError", ",", "\n", "'server_address must be a scalar'", ")", ":", "\n", "      ", "ops", ".", "Client", "(", "[", "'localhost:8000'", ",", "'localhost:8001'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_server_non_vector_server_addresses": [[263, 267], ["ops_test.OpsTest.assertRaisesRegex", "seed_rl.grpc.python.ops.Server"], "methods", ["None"], ["", "", "def", "test_server_non_vector_server_addresses", "(", "self", ")", ":", "\n", "    ", "with", "self", ".", "assertRaisesRegex", "(", "tf", ".", "errors", ".", "InvalidArgumentError", ",", "\n", "'server_addresses must be a vector'", ")", ":", "\n", "      ", "ops", ".", "Server", "(", "[", "[", "'localhost:8000'", ",", "'localhost:8001'", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_not_bound": [[268, 274], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "ops_test.OpsTest.assertRaisesRegex", "seed_rl.grpc.python.ops.Server.start"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start"], ["", "", "def", "test_not_bound", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "with", "self", ".", "assertRaisesRegex", "(", "tf", ".", "errors", ".", "UnavailableError", ",", "\n", "'No function was bound'", ")", ":", "\n", "      ", "server", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_binding_function_twice": [[275, 287], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "ops_test.OpsTest.assertRaisesRegex", "seed_rl.grpc.python.ops.Server.bind"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind"], ["", "", "def", "test_binding_function_twice", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "]", ")", "\n", "def", "foo", "(", ")", ":", "\n", "      ", "return", "42", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "with", "self", ".", "assertRaisesRegex", "(", "tf", ".", "errors", ".", "InvalidArgumentError", ",", "\n", "'Function \\'foo\\' was bound twice.'", ")", ":", "\n", "      ", "server", ".", "bind", "(", "foo", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_starting_twice": [[288, 302], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "ops_test.OpsTest.assertRaisesRegex", "seed_rl.grpc.python.ops.Server.start", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start"], ["", "", "def", "test_starting_twice", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "\n", "server", ".", "start", "(", ")", "\n", "with", "self", ".", "assertRaisesRegex", "(", "tf", ".", "errors", ".", "InvalidArgumentError", ",", "\n", "'Server is already started'", ")", ":", "\n", "      ", "server", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_invalid_number_of_arguments": [[303, 319], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "seed_rl.grpc.python.ops.Server.shutdown", "ops_test.OpsTest.assertRaisesRegex", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "", "def", "test_invalid_number_of_arguments", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "with", "self", ".", "assertRaisesRegex", "(", "tf", ".", "errors", ".", "InvalidArgumentError", ",", "\n", "'Expects 1 arguments, but 2 is provided'", ")", ":", "\n", "      ", "client", ".", "foo", "(", "[", "42", ",", "43", "]", ")", "\n", "", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_invalid_type": [[320, 337], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "seed_rl.grpc.python.ops.Server.shutdown", "ops_test.OpsTest.assertRaisesRegex", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_invalid_type", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "with", "self", ".", "assertRaisesRegex", "(", "\n", "tf", ".", "errors", ".", "InvalidArgumentError", ",", "\n", "r'Expects arg\\[0\\] to be int32 but string is provided'", ")", ":", "\n", "      ", "client", ".", "foo", "(", "'foo'", ")", "\n", "", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_failing_function": [[338, 355], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "seed_rl.grpc.python.ops.Server.shutdown", "tensorflow.assert_equal", "ops_test.OpsTest.assertRaisesRegex", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_failing_function", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "tf", ".", "assert_equal", "(", "1", ",", "x", ")", "# Will fail.", "\n", "return", "x", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "with", "self", ".", "assertRaisesRegex", "(", "tf", ".", "errors", ".", "InvalidArgumentError", ",", "\n", "'assertion failed'", ")", ":", "\n", "      ", "client", ".", "foo", "(", "42", ")", "\n", "", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_nests": [[356, 383], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.nest.map_structure", "tensorflow.nest.assert_same_structure", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "tensorflow.TensorSpec", "Some", "tensorflow.nest.map_structure", "Some", "Some", "tensorflow.nest.flatten", "tensorflow.nest.flatten", "tensorflow.TensorSpec", "t.numpy", "tensorflow.TensorSpec", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_nests", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "signature", "=", "(", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ",", "name", "=", "'arg1'", ")", ",", "\n", "Some", "(", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ",", "name", "=", "'arg2'", ")", ",", "[", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ",", "name", "=", "'arg3'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ",", "name", "=", "'arg4'", ")", "\n", "]", ")", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "signature", ")", "\n", "def", "foo", "(", "*", "args", ")", ":", "\n", "      ", "return", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "t", "+", "1", ",", "args", ")", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "inputs", "=", "(", "1", ",", "Some", "(", "2", ",", "[", "3", ",", "4", "]", ")", ")", "\n", "expected_outputs", "=", "(", "2", ",", "Some", "(", "3", ",", "[", "4", ",", "5", "]", ")", ")", "\n", "outputs", "=", "client", ".", "foo", "(", "inputs", ")", "\n", "outputs", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "t", ".", "numpy", "(", ")", ",", "outputs", ")", "\n", "tf", ".", "nest", ".", "assert_same_structure", "(", "expected_outputs", ",", "outputs", ")", "\n", "self", ".", "assertAllEqual", "(", "\n", "tf", ".", "nest", ".", "flatten", "(", "expected_outputs", ")", ",", "tf", ".", "nest", ".", "flatten", "(", "outputs", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_call_after_shutdown": [[384, 399], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "seed_rl.grpc.python.ops.Server.shutdown", "ops_test.OpsTest.assertRaisesRegex", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_call_after_shutdown", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "with", "self", ".", "assertRaisesRegex", "(", "tf", ".", "errors", ".", "UnavailableError", ",", "'server closed'", ")", ":", "\n", "      ", "client", ".", "foo", "(", "42", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_shutdown_while_in_call": [[400, 422], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "threading.Event", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "tensorflow.py_function", "tensorflow.py_function", "concurrent.futures.ThreadPoolExecutor", "executor.submit", "threading.Event.wait", "seed_rl.grpc.python.ops.Server.shutdown", "ops_test.OpsTest.assertRaisesRegex", "executor.submit.result", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "", "def", "test_shutdown_while_in_call", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "is_waiting", "=", "threading", ".", "Event", "(", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "tf", ".", "py_function", "(", "is_waiting", ".", "set", ",", "[", "]", ",", "[", "]", ")", "\n", "tf", ".", "py_function", "(", "time", ".", "sleep", ",", "[", "1", "]", ",", "[", "]", ")", "\n", "return", "x", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "with", "futures", ".", "ThreadPoolExecutor", "(", "max_workers", "=", "1", ")", "as", "executor", ":", "\n", "      ", "f", "=", "executor", ".", "submit", "(", "client", ".", "foo", ",", "42", ")", "\n", "is_waiting", ".", "wait", "(", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "with", "self", ".", "assertRaisesRegex", "(", "tf", ".", "errors", ".", "UnavailableError", ",", "'server closed'", ")", ":", "\n", "        ", "f", ".", "result", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_shutdown_while_in_blocking_call": [[423, 452], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.queue.FIFOQueue", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "tensorflow.queue.FIFOQueue.enqueue", "tensorflow.queue.FIFOQueue.enqueue", "tensorflow.queue.FIFOQueue.enqueue", "concurrent.futures.ThreadPoolExecutor", "executor.submit", "tensorflow.queue.FIFOQueue.dequeue", "seed_rl.grpc.python.ops.Server.shutdown", "executor.submit.result", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.enqueue", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.enqueue", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.enqueue", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.dequeue", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "", "", "def", "test_shutdown_while_in_blocking_call", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "q", "=", "tf", ".", "queue", ".", "FIFOQueue", "(", "1", ",", "[", "tf", ".", "int32", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "q", ".", "enqueue", "(", "x", ")", "\n", "q", ".", "enqueue", "(", "x", ")", "\n", "q", ".", "enqueue", "(", "x", ")", "\n", "return", "x", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "with", "futures", ".", "ThreadPoolExecutor", "(", "max_workers", "=", "1", ")", "as", "executor", ":", "\n", "      ", "f", "=", "executor", ".", "submit", "(", "client", ".", "foo", ",", "42", ")", "\n", "q", ".", "dequeue", "(", ")", "# Wait for function to be called.", "\n", "server", ".", "shutdown", "(", ")", "\n", "try", ":", "\n", "        ", "f", ".", "result", "(", ")", "\n", "# Non-deterministic if server manage to send CancelledError before", "\n", "# shutting down or not.", "\n", "", "except", "tf", ".", "errors", ".", "CancelledError", ":", "\n", "        ", "pass", "\n", "", "except", "tf", ".", "errors", ".", "UnavailableError", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_deletion_while_in_blocking_call": [[453, 482], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.queue.FIFOQueue", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "tensorflow.queue.FIFOQueue.enqueue", "tensorflow.queue.FIFOQueue.enqueue", "tensorflow.queue.FIFOQueue.enqueue", "concurrent.futures.ThreadPoolExecutor", "executor.submit", "tensorflow.queue.FIFOQueue.dequeue", "executor.submit.result", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.enqueue", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.enqueue", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.enqueue", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.dequeue"], ["", "", "", "def", "test_deletion_while_in_blocking_call", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "q", "=", "tf", ".", "queue", ".", "FIFOQueue", "(", "1", ",", "[", "tf", ".", "int32", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "q", ".", "enqueue", "(", "x", ")", "\n", "q", ".", "enqueue", "(", "x", ")", "\n", "q", ".", "enqueue", "(", "x", ")", "\n", "return", "x", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "with", "futures", ".", "ThreadPoolExecutor", "(", "max_workers", "=", "1", ")", "as", "executor", ":", "\n", "      ", "f", "=", "executor", ".", "submit", "(", "client", ".", "foo", ",", "42", ")", "\n", "q", ".", "dequeue", "(", ")", "# Wait for function to be called.", "\n", "del", "server", "\n", "try", ":", "\n", "        ", "f", ".", "result", "(", ")", "\n", "# Non-deterministic if server manage to send CancelledError before", "\n", "# shutting down or not.", "\n", "", "except", "tf", ".", "errors", ".", "CancelledError", ":", "\n", "        ", "pass", "\n", "", "except", "tf", ".", "errors", ".", "UnavailableError", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_call_after_shutdown_and_start": [[483, 502], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.queue.FIFOQueue", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Server.shutdown", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "tensorflow.queue.FIFOQueue.enqueue", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.enqueue"], ["", "", "", "def", "test_call_after_shutdown_and_start", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "q", "=", "tf", ".", "queue", ".", "FIFOQueue", "(", "1", ",", "[", "tf", ".", "int32", "]", ")", "# To test cancellation is reset.", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "q", ".", "enqueue", "(", "x", ")", "\n", "return", "x", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "self", ".", "assertAllEqual", "(", "43", ",", "client", ".", "foo", "(", "42", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_no_batching_when_output_rank0": [[503, 523], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "ops_test.OpsTest.assertRaisesRegex", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.TensorSpec", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start"], ["", "def", "test_no_batching_when_output_rank0", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "\n", "tf", ".", "TensorSpec", "(", "[", "2", "]", ",", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "2", "]", ",", "tf", ".", "int32", ")", "\n", "]", ")", "\n", "def", "foo", "(", "unused_x", ",", "unused_y", ")", ":", "\n", "      ", "return", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "with", "self", ".", "assertRaisesRegex", "(", "\n", "tf", ".", "errors", ".", "InvalidArgumentError", ",", "\n", "r'Expects arg\\[0\\] to have shape with 1 dimension\\(s\\), '", "\n", "r'but had shape \\[\\]'", ")", ":", "\n", "      ", "client", ".", "foo", "(", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_shutdown_waiting_for_full_batch": [[524, 542], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "concurrent.futures.ThreadPoolExecutor", "executor.submit", "time.sleep", "seed_rl.grpc.python.ops.Server.shutdown", "ops_test.OpsTest.assertRaisesRegex", "executor.submit.result", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "", "def", "test_shutdown_waiting_for_full_batch", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "2", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "with", "futures", ".", "ThreadPoolExecutor", "(", "max_workers", "=", "1", ")", "as", "executor", ":", "\n", "      ", "f", "=", "executor", ".", "submit", "(", "client", ".", "foo", ",", "42", ")", "\n", "time", ".", "sleep", "(", "1", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "with", "self", ".", "assertRaisesRegex", "(", "tf", ".", "errors", ".", "UnavailableError", ",", "'server closed'", ")", ":", "\n", "        ", "f", ".", "result", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_two_clients": [[543, 563], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "seed_rl.grpc.python.ops.Client", "seed_rl.grpc.python.ops.Server.shutdown", "concurrent.futures.ThreadPoolExecutor", "executor.submit", "executor.submit", "ops_test.OpsTest.assertAllEqual", "ops_test.OpsTest.assertAllEqual", "executor.submit.result", "executor.submit.result", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "", "", "def", "test_two_clients", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "client2", "=", "ops", ".", "Client", "(", "address", ")", "\n", "with", "futures", ".", "ThreadPoolExecutor", "(", "max_workers", "=", "2", ")", "as", "executor", ":", "\n", "      ", "f0", "=", "executor", ".", "submit", "(", "client", ".", "foo", ",", "42", ")", "\n", "f1", "=", "executor", ".", "submit", "(", "client2", ".", "foo", ",", "44", ")", "\n", "\n", "self", ".", "assertAllEqual", "(", "43", ",", "f0", ".", "result", "(", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "45", ",", "f1", ".", "result", "(", ")", ")", "\n", "", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_not_fully_specified_outputs": [[564, 594], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Server.shutdown", "tensorflow.equal", "seed_rl.grpc.python.ops.Client", "concurrent.futures.ThreadPoolExecutor", "executor.submit", "executor.submit", "executor.submit.result", "executor.submit.result", "tensorflow.zeros", "tensorflow.equal", "ops_test.OpsTest.assertRaisesRegex", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_not_fully_specified_outputs", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "2", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "if", "tf", ".", "equal", "(", "x", "[", "0", "]", ",", "0", ")", ":", "\n", "        ", "return", "tf", ".", "zeros", "(", "[", "]", ")", "\n", "", "elif", "tf", ".", "equal", "(", "x", "[", "0", "]", ",", "1", ")", ":", "\n", "        ", "return", "tf", ".", "zeros", "(", "[", "2", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "zeros", "(", "[", "1", "]", ")", "\n", "\n", "", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "def", "client", "(", ")", ":", "\n", "      ", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "with", "self", ".", "assertRaisesRegex", "(", "\n", "tf", ".", "errors", ".", "InvalidArgumentError", ",", "\n", "'Output must be at least rank 1 when batching is enabled'", ")", ":", "\n", "        ", "client", ".", "foo", "(", "0", ")", "\n", "\n", "", "", "with", "futures", ".", "ThreadPoolExecutor", "(", "max_workers", "=", "2", ")", "as", "executor", ":", "\n", "      ", "f1", "=", "executor", ".", "submit", "(", "client", ")", "\n", "f2", "=", "executor", ".", "submit", "(", "client", ")", "\n", "f1", ".", "result", "(", ")", "\n", "f2", ".", "result", "(", ")", "\n", "\n", "", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_not_fully_specified_outputs2": [[595, 611], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "tensorflow.py_function", "result.set_shape", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_not_fully_specified_outputs2", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "1", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "result", ",", "=", "tf", ".", "py_function", "(", "lambda", "x", ":", "x", ",", "[", "x", "]", ",", "[", "tf", ".", "int32", "]", ")", "\n", "result", ".", "set_shape", "(", "[", "None", "]", ")", "\n", "return", "result", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "self", ".", "assertAllEqual", "(", "42", ",", "client", ".", "foo", "(", "42", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_invalid_shape": [[612, 631], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "seed_rl.grpc.python.ops.Server.shutdown", "ops_test.OpsTest.assertRaisesRegex", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.zeros", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_invalid_shape", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "4", ",", "3", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "with", "self", ".", "assertRaisesRegex", "(", "\n", "tf", ".", "errors", ".", "InvalidArgumentError", ",", "\n", "r'Expects arg\\[0\\] to have shape with suffix \\[3\\], '", "\n", "r'but had shape \\[3,4\\]'", ")", ":", "\n", "      ", "client", ".", "foo", "(", "tf", ".", "zeros", "(", "[", "3", ",", "4", "]", ",", "tf", ".", "int32", ")", ")", "# Shape [3, 4], not [4, 3]", "\n", "\n", "", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_stress_test": [[632, 665], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "six.moves.range", "concurrent.futures.ThreadPoolExecutor", "enumerate", "six.moves.range", "ops_test.OpsTest.assertAllEqual", "executor.submit", "concurrent.futures.as_completed", "f.result", "tensorflow.TensorSpec", "client.foo", "seed_rl.grpc.python.ops.Server.shutdown"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_stress_test", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "5", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "num_clients", "=", "10", "\n", "num_calls", "=", "100", "\n", "clients", "=", "[", "ops", ".", "Client", "(", "address", ")", "for", "_", "in", "range", "(", "num_clients", ")", "]", "\n", "\n", "def", "do_calls", "(", "client", ")", ":", "\n", "      ", "for", "i", "in", "range", "(", "num_calls", ")", ":", "\n", "        ", "self", ".", "assertAllEqual", "(", "i", "+", "1", ",", "client", ".", "foo", "(", "i", ")", ")", "\n", "\n", "", "", "with", "futures", ".", "ThreadPoolExecutor", "(", "max_workers", "=", "num_clients", ")", "as", "executor", ":", "\n", "      ", "fs", "=", "[", "executor", ".", "submit", "(", "do_calls", ",", "client", ")", "for", "client", "in", "clients", "]", "\n", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "futures", ".", "as_completed", "(", "fs", ")", ",", "0", ")", ":", "\n", "        ", "f", ".", "result", "(", ")", "\n", "if", "i", "==", "num_clients", "//", "2", ":", "\n", "# Shutdown after at least half the clients have completed. Not", "\n", "# possible to wait on all because the last batch may not be filled up", "\n", "# so it can't complete.", "\n", "          ", "try", ":", "\n", "            ", "server", ".", "shutdown", "(", ")", "\n", "", "except", "tf", ".", "errors", ".", "UnavailableError", ":", "\n", "            ", "pass", "\n", "", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_tpu": [[666, 688], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "seed_rl.grpc.python.ops.Client.foo", "ops_test.OpsTest.assertAllEqual", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "tensorflow.device", "tensorflow.Variable", "tensorflow.device", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "", "", "", "def", "test_tpu", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "with", "tf", ".", "device", "(", "'/device:CPU:0'", ")", ":", "\n", "      ", "a", "=", "tf", ".", "Variable", "(", "1", ")", "\n", "\n", "", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "with", "tf", ".", "device", "(", "'/device:CPU:0'", ")", ":", "\n", "        ", "b", "=", "a", "+", "1", "\n", "c", "=", "x", "+", "1", "\n", "", "return", "x", "+", "b", ",", "c", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "a", ",", "b", "=", "client", ".", "foo", "(", "42", ")", "\n", "self", ".", "assertAllEqual", "(", "44", ",", "a", ")", "\n", "self", ".", "assertAllEqual", "(", "43", ",", "b", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_tpu_tf_function_same_device": [[689, 715], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "seed_rl.grpc.python.ops.Client.foo", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "tensorflow.device", "tensorflow.Variable", "tensorflow.device", "tensorflow.device", "ops_test.OpsTest.test_tpu_tf_function_same_device.get_a_plus_one"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_tpu_tf_function_same_device", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "with", "tf", ".", "device", "(", "'/device:CPU:0'", ")", ":", "\n", "      ", "a", "=", "tf", ".", "Variable", "(", "1", ")", "\n", "\n", "", "with", "tf", ".", "device", "(", "'/device:CPU:0'", ")", ":", "\n", "\n", "      ", "@", "tf", ".", "function", "\n", "def", "get_a_plus_one", "(", ")", ":", "\n", "        ", "return", "a", "+", "1", "\n", "\n", "", "", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "with", "tf", ".", "device", "(", "'/device:CPU:0'", ")", ":", "\n", "        ", "b", "=", "x", "+", "get_a_plus_one", "(", ")", "\n", "", "return", "b", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "a", "=", "client", ".", "foo", "(", "1", ")", "\n", "self", ".", "assertAllEqual", "(", "4", ",", "a", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_bind_multiple_functions": [[716, 739], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "ops_test.OpsTest.assertAllEqual", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "seed_rl.grpc.python.ops.Client.foo", "seed_rl.grpc.python.ops.Client.bar", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_bind_multiple_functions", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "+", "1", "\n", "\n", "", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "\n", "]", ")", "\n", "def", "bar", "(", "x", ",", "y", ")", ":", "\n", "      ", "return", "x", "*", "y", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "bind", "(", "bar", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "self", ".", "assertAllEqual", "(", "43", ",", "client", ".", "foo", "(", "42", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "100", ",", "client", ".", "bar", "(", "10", ",", "10", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_variable_out_of_scope": [[740, 759], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "ops_test.OpsTest.test_variable_out_of_scope.bind"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind"], ["", "def", "test_variable_out_of_scope", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "def", "bind", "(", ")", ":", "\n", "      ", "a", "=", "tf", ".", "Variable", "(", "1", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "        ", "return", "x", "+", "a", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "", "bind", "(", ")", "\n", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "self", ".", "assertAllEqual", "(", "43", ",", "client", ".", "foo", "(", "42", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_batch_auto_detection": [[760, 775], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Client", "tensorflow.constant", "ops_test.OpsTest.assertAllEqual", "seed_rl.grpc.python.ops.Server.shutdown", "seed_rl.grpc.python.ops.Client.foo", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_batch_auto_detection", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "2", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "t", "=", "tf", ".", "constant", "(", "[", "1", ",", "2", "]", ")", "\n", "self", ".", "assertAllEqual", "(", "t", "+", "1", ",", "client", ".", "foo", "(", "t", ")", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.test_client_side_batching": [[776, 800], ["ops_test.OpsTest.get_unix_address", "seed_rl.grpc.python.ops.Server", "tensorflow.function", "seed_rl.grpc.python.ops.Server.bind", "seed_rl.grpc.python.ops.Server.start", "seed_rl.grpc.python.ops.Server.shutdown", "seed_rl.grpc.python.ops.Client", "seed_rl.grpc.python.ops.Client.foo", "concurrent.futures.ThreadPoolExecutor", "executor.submit", "executor.submit", "ops_test.OpsTest.assertAllEqual", "ops_test.OpsTest.assertAllEqual", "numpy.array", "numpy.array", "executor.submit.result", "executor.submit.result", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops_test.OpsTest.get_unix_address", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["", "def", "test_client_side_batching", "(", "self", ")", ":", "\n", "    ", "address", "=", "self", ".", "get_unix_address", "(", ")", "\n", "server", "=", "ops", ".", "Server", "(", "[", "address", "]", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "tf", ".", "TensorSpec", "(", "[", "4", "]", ",", "tf", ".", "int32", ")", "]", ")", "\n", "def", "foo", "(", "x", ")", ":", "\n", "      ", "return", "x", "+", "1", "\n", "\n", "", "server", ".", "bind", "(", "foo", ")", "\n", "server", ".", "start", "(", ")", "\n", "\n", "def", "client", "(", "x", ")", ":", "\n", "      ", "client", "=", "ops", ".", "Client", "(", "address", ")", "\n", "return", "client", ".", "foo", "(", "x", ")", "\n", "\n", "# Both clients send batches of size 2 to the server, the server is expected", "\n", "# to process it as a batch of size 4.", "\n", "", "with", "futures", ".", "ThreadPoolExecutor", "(", "max_workers", "=", "2", ")", "as", "executor", ":", "\n", "      ", "f1", "=", "executor", ".", "submit", "(", "client", ",", "np", ".", "array", "(", "[", "42", ",", "43", "]", ",", "np", ".", "int32", ")", ")", "\n", "f2", "=", "executor", ".", "submit", "(", "client", ",", "np", ".", "array", "(", "[", "142", ",", "143", "]", ",", "np", ".", "int32", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "f1", ".", "result", "(", ")", ",", "[", "43", ",", "44", "]", ")", "\n", "self", ".", "assertAllEqual", "(", "f2", ".", "result", "(", ")", ",", "[", "143", ",", "144", "]", ")", "\n", "\n", "", "server", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.__init__": [[40, 60], ["seed_rl.grpc.python.ops_wrapper.gen_grpc_ops.grpc_server_resource_handle_op", "tensorflow.python.ops.resource_variable_ops.EagerResourceDeleter", "seed_rl.grpc.python.ops_wrapper.gen_grpc_ops.create_grpc_server", "tensorflow.executing_eagerly", "ValueError", "tensorflow.python.eager.context.shared_name", "tensorflow.python.eager.context.context"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "server_addresses", ")", ":", "\n", "    ", "\"\"\"Creates and starts the gRPC server.\n\n    Args:\n      server_addresses: A list of strings containing one or more server\n        addresses.\n    \"\"\"", "\n", "if", "not", "tf", ".", "executing_eagerly", "(", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"Only eager mode is currently supported.\"", ")", "\n", "\n", "", "self", ".", "_handle", "=", "gen_grpc_ops", ".", "grpc_server_resource_handle_op", "(", "\n", "shared_name", "=", "context", ".", "shared_name", "(", "None", ")", ")", "\n", "# Delete the resource when this object is deleted.", "\n", "self", ".", "_resource_deleter", "=", "resource_variable_ops", ".", "EagerResourceDeleter", "(", "\n", "handle", "=", "self", ".", "_handle", ",", "handle_device", "=", "context", ".", "context", "(", ")", ".", "device_name", ")", "\n", "gen_grpc_ops", ".", "create_grpc_server", "(", "self", ".", "_handle", ",", "server_addresses", ")", "\n", "\n", "# References to tf.Variable's, etc. used in a tf.function to prevent them", "\n", "# from being deallocated.", "\n", "self", ".", "_keep_alive", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind": [[61, 110], ["enumerate", "isinstance", "ops.Server._keep_alive.append", "f.get_concrete_function.get_concrete_function.get_concrete_function", "tensorflow.python.saved_model.nested_structure_coder.StructureCoder", "tensorflow.python.saved_model.nested_structure_coder.StructureCoder.encode_structure", "seed_rl.grpc.python.ops_wrapper.gen_grpc_ops.grpc_server_bind", "ValueError", "tensorflow.nest.map_structure", "tensorflow.nest.flatten", "tensorflow.nest.flatten", "nested_structure_coder.StructureCoder.encode_structure.SerializeToString"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append"], ["", "def", "bind", "(", "self", ",", "fn", ")", ":", "\n", "    ", "\"\"\"Binds a tf.function to the server.\n\n     If the first dimension of all\n     arguments is equal (=N) then batching support is enabled, using N as\n     a batch dimension. In such case when client does a call with a single\n     element (batching dimention skipped), N independent client calls will be\n     batched to construct an input for a single invocation of `fn`.\n     If the signature of parameters provided by the client matches\n     `input_signature`, `fn` is executed immediatelly without batching.\n\n    Args:\n      fn: The @tf.function wrapped function or a list of such functions, with\n        `input_signature` set. When a list of functions is provided,\n        they are called in a round-robin manner.\n\n    Returns:\n      A tf.Operation.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "fn", ",", "collections", ".", "Iterable", ")", ":", "\n", "      ", "fn", "=", "[", "fn", "]", "\n", "\n", "", "for", "i", ",", "f", "in", "enumerate", "(", "fn", ")", ":", "\n", "      ", "if", "f", ".", "input_signature", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"tf.function must have input_signature set.\"", ")", "\n", "\n", "", "self", ".", "_keep_alive", ".", "append", "(", "f", ".", "python_function", ")", "\n", "\n", "fn_name", "=", "f", ".", "__name__", "\n", "f", "=", "f", ".", "get_concrete_function", "(", ")", "\n", "input_shapes", "=", "[", "\n", "t", ".", "shape", "for", "t", "in", "tf", ".", "nest", ".", "flatten", "(", "f", ".", "structured_input_signature", ")", "\n", "]", "\n", "if", "f", ".", "structured_outputs", "is", "None", ":", "\n", "        ", "output_specs", "=", "None", "\n", "", "else", ":", "\n", "        ", "output_specs", "=", "tf", ".", "nest", ".", "map_structure", "(", "type_spec", ".", "type_spec_from_value", ",", "\n", "f", ".", "structured_outputs", ")", "\n", "", "encoder", "=", "nested_structure_coder", ".", "StructureCoder", "(", ")", "\n", "output_specs_proto", "=", "encoder", ".", "encode_structure", "(", "output_specs", ")", "\n", "gen_grpc_ops", ".", "grpc_server_bind", "(", "\n", "handle", "=", "self", ".", "_handle", ",", "\n", "captures", "=", "f", ".", "captured_inputs", ",", "\n", "fn_name", "=", "fn_name", ",", "\n", "fn", "=", "f", ",", "\n", "first_bind", "=", "(", "i", "==", "0", ")", ",", "\n", "input_shapes", "=", "input_shapes", ",", "\n", "output_shapes", "=", "tf", ".", "nest", ".", "flatten", "(", "f", ".", "output_shapes", ")", ",", "\n", "output_specs", "=", "output_specs_proto", ".", "SerializeToString", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.start": [[111, 113], ["seed_rl.grpc.python.ops_wrapper.gen_grpc_ops.grpc_server_start"], "methods", ["None"], ["", "", "def", "start", "(", "self", ")", ":", "\n", "    ", "return", "gen_grpc_ops", ".", "grpc_server_start", "(", "handle", "=", "self", ".", "_handle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.shutdown": [[114, 116], ["seed_rl.grpc.python.ops_wrapper.gen_grpc_ops.grpc_server_shutdown"], "methods", ["None"], ["", "def", "shutdown", "(", "self", ")", ":", "\n", "    ", "return", "gen_grpc_ops", ".", "grpc_server_shutdown", "(", "handle", "=", "self", ".", "_handle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Client.__init__": [[124, 147], ["seed_rl.grpc.python.ops_wrapper.gen_grpc_ops.grpc_client_resource_handle_op", "tensorflow.python.ops.resource_variable_ops.EagerResourceDeleter", "seed_rl.grpc.python.ops_wrapper.gen_grpc_ops.create_grpc_client().numpy", "seed_rl.grpc.service_pb2.MethodOutputSignature", "tensorflow.core.protobuf.struct_pb2.StructuredValue", "tensorflow.executing_eagerly", "ValueError", "seed_rl.grpc.service_pb2.MethodOutputSignature.ParseFromString", "tensorflow.python.saved_model.nested_structure_coder.StructureCoder", "tensorflow.core.protobuf.struct_pb2.StructuredValue.ParseFromString", "tensorflow.python.saved_model.nested_structure_coder.StructureCoder.decode_proto", "ops.Client._add_method", "tensorflow.python.eager.context.shared_name", "seed_rl.grpc.python.ops_wrapper.gen_grpc_ops.create_grpc_client", "tensorflow.python.eager.context.context"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Client._add_method"], ["def", "__init__", "(", "self", ",", "server_address", ")", ":", "\n", "    ", "\"\"\"Creates and starts the gRPC client.\n\n    Args:\n      server_address: A string containing the server address.\n    \"\"\"", "\n", "if", "not", "tf", ".", "executing_eagerly", "(", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"Only eager mode is currently supported.\"", ")", "\n", "\n", "", "self", ".", "_handle", "=", "gen_grpc_ops", ".", "grpc_client_resource_handle_op", "(", "\n", "shared_name", "=", "context", ".", "shared_name", "(", "None", ")", ")", "\n", "self", ".", "_resource_deleter", "=", "resource_variable_ops", ".", "EagerResourceDeleter", "(", "\n", "handle", "=", "self", ".", "_handle", ",", "handle_device", "=", "context", ".", "context", "(", ")", ".", "device_name", ")", "\n", "method_signatures", "=", "gen_grpc_ops", ".", "create_grpc_client", "(", "self", ".", "_handle", ",", "\n", "server_address", ")", ".", "numpy", "(", ")", "\n", "m", "=", "service_pb2", ".", "MethodOutputSignature", "(", ")", "\n", "v", "=", "struct_pb2", ".", "StructuredValue", "(", ")", "\n", "for", "sig", "in", "method_signatures", ":", "\n", "      ", "assert", "m", ".", "ParseFromString", "(", "sig", ")", "\n", "decoder", "=", "nested_structure_coder", ".", "StructureCoder", "(", ")", "\n", "assert", "v", ".", "ParseFromString", "(", "m", ".", "output_specs", ")", "\n", "decoded_output_specs", "=", "decoder", ".", "decode_proto", "(", "v", ")", "\n", "self", ".", "_add_method", "(", "m", ".", "name", ",", "decoded_output_specs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Client._add_method": [[148, 167], ["setattr", "tensorflow.nest.flatten", "seed_rl.grpc.python.ops_wrapper.gen_grpc_ops.grpc_client_call", "types.MethodType", "tensorflow.nest.flatten", "tensorflow.nest.pack_sequence_as"], "methods", ["None"], ["", "", "def", "_add_method", "(", "self", ",", "name", ",", "output_specs", ")", ":", "\n", "    ", "\"\"\"Adds a method to the client.\"\"\"", "\n", "flat_output_dtypes", "=", "[", "s", ".", "dtype", "for", "s", "in", "tf", ".", "nest", ".", "flatten", "(", "output_specs", "or", "[", "]", ")", "]", "\n", "\n", "def", "call", "(", "self", ",", "*", "inputs", ")", ":", "\n", "      ", "\"\"\"Makes a call to the server.\"\"\"", "\n", "\n", "flat_inputs", "=", "tf", ".", "nest", ".", "flatten", "(", "inputs", ")", "\n", "flat_outputs", "=", "gen_grpc_ops", ".", "grpc_client_call", "(", "\n", "fn_name", "=", "name", ",", "\n", "handle", "=", "self", ".", "_handle", ",", "\n", "input_list", "=", "flat_inputs", ",", "\n", "Toutput_list", "=", "flat_output_dtypes", ")", "\n", "if", "output_specs", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "nest", ".", "pack_sequence_as", "(", "output_specs", ",", "flat_outputs", ")", "\n", "\n", "", "", "setattr", "(", "self", ",", "name", ",", "types", ".", "MethodType", "(", "call", ",", "self", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.vtrace_main.create_agent": [[65, 75], ["seed_rl.agents.vtrace.networks.MLPandLSTM", "seed_rl.common.normalizer.NormalizeObservationsWrapper", "seed_rl.common.normalizer.Normalizer"], "function", ["None"], ["def", "create_agent", "(", "unused_action_space", ",", "unused_env_observation_space", ",", "\n", "parametric_action_distribution", ")", ":", "\n", "  ", "policy", "=", "networks", ".", "MLPandLSTM", "(", "\n", "parametric_action_distribution", ",", "\n", "mlp_sizes", "=", "[", "FLAGS", ".", "mlp_size", "]", "*", "FLAGS", ".", "n_mlp_layers", ",", "\n", "lstm_sizes", "=", "[", "FLAGS", ".", "lstm_size", "]", "*", "FLAGS", ".", "n_lstm_layers", ")", "\n", "if", "FLAGS", ".", "normalize_observations", ":", "\n", "    ", "policy", "=", "normalizer", ".", "NormalizeObservationsWrapper", "(", "policy", ",", "\n", "normalizer", ".", "Normalizer", "(", ")", ")", "\n", "", "return", "policy", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.vtrace_main.create_optimizer": [[77, 81], ["tensorflow.keras.optimizers.Adam"], "function", ["None"], ["", "def", "create_optimizer", "(", "unused_final_iteration", ")", ":", "\n", "  ", "learning_rate_fn", "=", "lambda", "iteration", ":", "FLAGS", ".", "learning_rate", "\n", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "FLAGS", ".", "learning_rate", ")", "\n", "return", "optimizer", ",", "learning_rate_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.vtrace_main.main": [[83, 100], ["seed_rl.mujoco.env.create_environment", "len", "absl.app.UsageError", "seed_rl.common.actor.actor_loop", "seed_rl.agents.vtrace.learner.learner_loop", "ValueError"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.create_environment", "home.repos.pwc.inspect_result.google-research_seed_rl.common.actor.actor_loop", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.learner_loop"], ["", "def", "main", "(", "argv", ")", ":", "\n", "  ", "create_environment", "=", "lambda", "task", ",", "config", ":", "env", ".", "create_environment", "(", "\n", "env_name", "=", "config", ".", "env_name", ",", "\n", "discretization", "=", "config", ".", "discretization", ",", "\n", "n_actions_per_dim", "=", "config", ".", "n_actions_per_dim", ",", "\n", "action_ratio", "=", "config", ".", "action_ratio", ")", "\n", "\n", "if", "len", "(", "argv", ")", ">", "1", ":", "\n", "    ", "raise", "app", ".", "UsageError", "(", "'Too many command-line arguments.'", ")", "\n", "", "if", "FLAGS", ".", "run_mode", "==", "'actor'", ":", "\n", "    ", "actor", ".", "actor_loop", "(", "create_environment", ")", "\n", "", "elif", "FLAGS", ".", "run_mode", "==", "'learner'", ":", "\n", "    ", "learner", ".", "learner_loop", "(", "create_environment", ",", "\n", "create_agent", ",", "\n", "create_optimizer", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'Unsupported run mode {}'", ".", "format", "(", "FLAGS", ".", "run_mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.sac_main.create_agent": [[67, 77], ["seed_rl.agents.sac.networks.ActorCriticMLP", "seed_rl.common.normalizer.NormalizeObservationsWrapper", "seed_rl.common.normalizer.Normalizer"], "function", ["None"], ["def", "create_agent", "(", "unused_action_space", ",", "unused_env_observation_space", ",", "\n", "parametric_action_distribution", ")", ":", "\n", "  ", "policy", "=", "networks", ".", "ActorCriticMLP", "(", "\n", "parametric_action_distribution", ",", "\n", "n_critics", "=", "FLAGS", ".", "n_critics", ",", "\n", "mlp_sizes", "=", "[", "FLAGS", ".", "mlp_size", "]", "*", "FLAGS", ".", "n_mlp_layers", ")", "\n", "if", "FLAGS", ".", "normalize_observations", ":", "\n", "    ", "policy", "=", "normalizer", ".", "NormalizeObservationsWrapper", "(", "policy", ",", "\n", "normalizer", ".", "Normalizer", "(", ")", ")", "\n", "", "return", "policy", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.sac_main.create_optimizer": [[79, 83], ["tensorflow.keras.optimizers.Adam"], "function", ["None"], ["", "def", "create_optimizer", "(", "unused_final_iteration", ")", ":", "\n", "  ", "learning_rate_fn", "=", "lambda", "iteration", ":", "FLAGS", ".", "learning_rate", "\n", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "FLAGS", ".", "learning_rate", ")", "\n", "return", "optimizer", ",", "learning_rate_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.sac_main.main": [[85, 102], ["seed_rl.mujoco.env.create_environment", "len", "absl.app.UsageError", "seed_rl.common.actor.actor_loop", "seed_rl.agents.sac.learner.learner_loop", "ValueError"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.create_environment", "home.repos.pwc.inspect_result.google-research_seed_rl.common.actor.actor_loop", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.learner_loop"], ["", "def", "main", "(", "argv", ")", ":", "\n", "  ", "create_environment", "=", "lambda", "task", ",", "config", ":", "env", ".", "create_environment", "(", "\n", "env_name", "=", "config", ".", "env_name", ",", "\n", "discretization", "=", "config", ".", "discretization", ",", "\n", "n_actions_per_dim", "=", "config", ".", "n_actions_per_dim", ",", "\n", "action_ratio", "=", "config", ".", "action_ratio", ")", "\n", "\n", "if", "len", "(", "argv", ")", ">", "1", ":", "\n", "    ", "raise", "app", ".", "UsageError", "(", "'Too many command-line arguments.'", ")", "\n", "", "if", "FLAGS", ".", "run_mode", "==", "'actor'", ":", "\n", "    ", "actor", ".", "actor_loop", "(", "create_environment", ")", "\n", "", "elif", "FLAGS", ".", "run_mode", "==", "'learner'", ":", "\n", "    ", "learner", ".", "learner_loop", "(", "create_environment", ",", "\n", "create_agent", ",", "\n", "create_optimizer", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'Unsupported run mode {}'", ".", "format", "(", "FLAGS", ".", "run_mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.ToyEnv.__init__": [[26, 36], ["gym.spaces.Box", "gym.spaces.Box"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "horizon", "=", "3", ",", "n_actions", "=", "3", ")", ":", "\n", "    ", "\"\"\"Initialize environment.\n\n    Args:\n      horizon: number of timesteps the observations have to be remembered.\n      n_actions: dimensionality of actions.\n    \"\"\"", "\n", "self", ".", "horizon", "=", "horizon", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "[", "n_actions", "+", "1", "]", ")", "\n", "self", ".", "action_space", "=", "gym", ".", "spaces", ".", "Box", "(", "-", "1", ",", "1", ",", "[", "n_actions", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.ToyEnv._get_obs": [[37, 41], ["numpy.random.uniform().astype", "numpy.concatenate().astype", "numpy.random.uniform", "numpy.concatenate"], "methods", ["None"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "    ", "self", ".", "_obs", "=", "np", ".", "random", ".", "uniform", "(", "\n", "-", "1", ",", "1", ",", "size", "=", "self", ".", "observation_space", ".", "shape", "[", "0", "]", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "return", "np", ".", "concatenate", "(", "[", "self", ".", "_obs", ",", "[", "0.", "]", "]", ",", "axis", "=", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.ToyEnv.step": [[42, 47], ["toy_env.ToyEnv.action_space.contains", "numpy.clip", "float", "toy_env.ToyEnv._get_obs", "sum"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.BitFlippingEnv._get_obs"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "assert", "self", ".", "action_space", ".", "contains", "(", "np", ".", "clip", "(", "action", ",", "-", "1", ",", "1", ")", ")", "\n", "self", ".", "t", "+=", "1", "\n", "reward", "=", "-", "float", "(", "sum", "(", "(", "action", "-", "self", ".", "_obs", ")", "**", "2", ")", ")", "\n", "return", "self", ".", "_get_obs", "(", ")", ",", "reward", ",", "self", ".", "t", ">=", "self", ".", "horizon", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.ToyEnv.reset": [[48, 51], ["toy_env.ToyEnv._get_obs"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.BitFlippingEnv._get_obs"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "self", ".", "t", "=", "0", "\n", "return", "self", ".", "_get_obs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.ToyEnv.render": [[52, 54], ["None"], "methods", ["None"], ["", "def", "render", "(", "self", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.ToyMemoryEnv.__init__": [[59, 70], ["gym.spaces.Box", "gym.spaces.Box"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "horizon", "=", "3", ",", "n_actions", "=", "3", ")", ":", "\n", "    ", "\"\"\"Initialize environment.\n\n    Args:\n      horizon: number of timesteps we need to retain observations in memory.\n      n_actions: dimensionality of actions.\n    \"\"\"", "\n", "self", ".", "horizon", "=", "horizon", "\n", "self", ".", "n_actions", "=", "n_actions", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "[", "n_actions", "+", "1", "]", ")", "\n", "self", ".", "action_space", "=", "gym", ".", "spaces", ".", "Box", "(", "-", "1", ",", "1", ",", "[", "n_actions", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.ToyMemoryEnv._get_obs": [[71, 77], ["numpy.concatenate().astype", "numpy.zeros", "numpy.concatenate"], "methods", ["None"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "t", "<", "self", ".", "horizon", ":", "\n", "      ", "return", "np", ".", "concatenate", "(", "[", "self", ".", "memory", "[", "self", ".", "t", "]", ",", "[", "0.", "]", "]", ",", "\n", "axis", "=", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "      ", "return", "np", ".", "zeros", "(", "self", ".", "n_actions", "+", "1", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.ToyMemoryEnv.step": [[78, 88], ["toy_env.ToyMemoryEnv.action_space.contains", "float", "toy_env.ToyMemoryEnv._get_obs", "numpy.zeros", "float", "sum"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.BitFlippingEnv._get_obs"], ["", "", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "assert", "self", ".", "action_space", ".", "contains", "(", "action", ")", "\n", "if", "self", ".", "t", "==", "2", "*", "self", ".", "horizon", ":", "\n", "      ", "return", "np", ".", "zeros", "(", "self", ".", "n_actions", "+", "1", ")", ",", "0.", ",", "True", ",", "None", "\n", "", "if", "self", ".", "t", "<", "self", ".", "horizon", ":", "\n", "      ", "reward", "=", "float", "(", "0.", ")", "\n", "", "else", ":", "\n", "      ", "reward", "=", "-", "float", "(", "sum", "(", "(", "action", "-", "self", ".", "memory", "[", "self", ".", "t", "-", "self", ".", "horizon", "]", ")", "**", "2", ")", ")", "\n", "", "self", ".", "t", "+=", "1", "\n", "return", "self", ".", "_get_obs", "(", ")", ",", "reward", ",", "False", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.ToyMemoryEnv.reset": [[89, 94], ["numpy.random.uniform().astype", "toy_env.ToyMemoryEnv._get_obs", "numpy.random.uniform"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.BitFlippingEnv._get_obs"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "self", ".", "memory", "=", "np", ".", "random", ".", "uniform", "(", "\n", "-", "1", ",", "1", ",", "size", "=", "(", "self", ".", "horizon", ",", "self", ".", "n_actions", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "self", ".", "t", "=", "0", "\n", "return", "self", ".", "_get_obs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.ToyMemoryEnv.render": [[95, 97], ["None"], "methods", ["None"], ["", "def", "render", "(", "self", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.BitFlippingEnv.__init__": [[105, 113], ["gym.spaces.Dict", "gym.spaces.Discrete", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "n_bits", "=", "10", ",", "horizon", "=", "20", ")", ":", "\n", "    ", "self", ".", "_n_bits", "=", "n_bits", "\n", "self", ".", "_horizon", "=", "horizon", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Dict", "(", "\n", "achieved_goal", "=", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "0", ",", "high", "=", "1", ",", "shape", "=", "[", "n_bits", "]", ")", ",", "\n", "desired_goal", "=", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "0", ",", "high", "=", "1", ",", "shape", "=", "[", "n_bits", "]", ")", ",", "\n", "observation", "=", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "0", ",", "high", "=", "1", ",", "shape", "=", "[", "horizon", "+", "1", "]", ")", ")", "\n", "self", ".", "action_space", "=", "gym", ".", "spaces", ".", "Discrete", "(", "n_bits", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.BitFlippingEnv.reset": [[114, 119], ["numpy.random.randint().astype", "numpy.random.randint().astype", "toy_env.BitFlippingEnv._get_obs", "numpy.random.randint", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.BitFlippingEnv._get_obs"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "self", ".", "state", "=", "np", ".", "random", ".", "randint", "(", "2", ",", "size", "=", "self", ".", "_n_bits", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "self", ".", "goal", "=", "np", ".", "random", ".", "randint", "(", "2", ",", "size", "=", "self", ".", "_n_bits", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "self", ".", "t", "=", "0", "\n", "return", "self", ".", "_get_obs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.BitFlippingEnv._get_obs": [[120, 126], ["toy_env.BitFlippingEnv.observation_space.contains", "collections.OrderedDict", "toy_env.BitFlippingEnv.state.copy", "toy_env.BitFlippingEnv.goal.copy", "tensorflow.one_hot().numpy", "sorted", "obs.items", "tensorflow.one_hot"], "methods", ["None"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "    ", "obs", "=", "{", "'achieved_goal'", ":", "self", ".", "state", ".", "copy", "(", ")", ",", "\n", "'desired_goal'", ":", "self", ".", "goal", ".", "copy", "(", ")", ",", "\n", "'observation'", ":", "tf", ".", "one_hot", "(", "self", ".", "t", ",", "self", ".", "_horizon", "+", "1", ")", ".", "numpy", "(", ")", "}", "\n", "assert", "self", ".", "observation_space", ".", "contains", "(", "obs", ")", "\n", "return", "collections", ".", "OrderedDict", "(", "sorted", "(", "obs", ".", "items", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.BitFlippingEnv.step": [[127, 134], ["toy_env.BitFlippingEnv.action_space.contains", "toy_env.BitFlippingEnv.compute_reward", "toy_env.BitFlippingEnv._get_obs"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.BitFlippingEnv.compute_reward", "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.BitFlippingEnv._get_obs"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "assert", "self", ".", "action_space", ".", "contains", "(", "action", ")", "\n", "if", "action", "!=", "self", ".", "_n_bits", ":", "\n", "      ", "self", ".", "state", "[", "action", "]", "=", "1", "-", "self", ".", "state", "[", "action", "]", "\n", "", "self", ".", "t", "+=", "1", "\n", "reward", "=", "self", ".", "compute_reward", "(", "self", ".", "state", ",", "self", ".", "goal", ")", "\n", "return", "self", ".", "_get_obs", "(", ")", ",", "reward", ",", "self", ".", "t", ">=", "self", ".", "_horizon", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.toy_env.BitFlippingEnv.compute_reward": [[135, 138], ["tensorflow.clip_by_value", "tensorflow.reduce_sum", "tensorflow.cast"], "methods", ["None"], ["", "def", "compute_reward", "(", "self", ",", "achieved_goal", ",", "desired_goal", ",", "info", "=", "None", ")", ":", "\n", "    ", "return", "tf", ".", "clip_by_value", "(", "tf", ".", "reduce_sum", "(", "\n", "-", "tf", ".", "cast", "(", "achieved_goal", "!=", "desired_goal", ",", "tf", ".", "float32", ")", ",", "axis", "=", "-", "1", ")", ",", "-", "1", ",", "0", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.ppo_main.orthogonal_gain_sqrt2": [[75, 78], ["tensorflow.keras.initializers.Orthogonal"], "function", ["None"], ["@", "gin", ".", "configurable", "\n", "def", "orthogonal_gain_sqrt2", "(", ")", ":", "\n", "  ", "return", "tf", ".", "keras", ".", "initializers", ".", "Orthogonal", "(", "1.41421356237", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.ppo_main.orthogonal_gain_0dot01": [[80, 83], ["tensorflow.keras.initializers.Orthogonal"], "function", ["None"], ["", "@", "gin", ".", "configurable", "\n", "def", "orthogonal_gain_0dot01", "(", ")", ":", "\n", "  ", "return", "tf", ".", "keras", ".", "initializers", ".", "Orthogonal", "(", "0.01", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.ppo_main.create_optimizer": [[85, 92], ["tensorflow.keras.optimizers.schedules.PolynomialDecay", "optimizer_fn"], "function", ["None"], ["", "@", "gin", ".", "configurable", "\n", "def", "create_optimizer", "(", "final_iteration", ",", "optimizer_fn", ")", ":", "\n", "  ", "learning_rate_fn", "=", "tf", ".", "keras", ".", "optimizers", ".", "schedules", ".", "PolynomialDecay", "(", "\n", "FLAGS", ".", "learning_rate", ",", "final_iteration", ",", "\n", "FLAGS", ".", "lr_decay_multiplier", "*", "FLAGS", ".", "learning_rate", ")", "\n", "optimizer", "=", "optimizer_fn", "(", "learning_rate_fn", ")", "\n", "return", "optimizer", ",", "learning_rate_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.ppo_main.create_agent": [[94, 98], ["seed_rl.agents.policy_gradient.modules.continuous_control_agent.ContinuousControlAgent"], "function", ["None"], ["", "def", "create_agent", "(", "unused_action_space", ",", "unused_observation_space", ",", "\n", "parametric_action_distribution", ")", ":", "\n", "  ", "return", "continuous_control_agent", ".", "ContinuousControlAgent", "(", "\n", "parametric_action_distribution", "=", "parametric_action_distribution", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.ppo_main.main": [[100, 142], ["FLAGS.flags_into_string", "gin.parse_config_files_and_bindings", "gin.parse_config_files_and_bindings", "absl.logging.info", "tensorflow.io.gfile.copy", "seed_rl.mujoco.env.create_environment", "seed_rl.common.actor.actor_loop", "s.replace", "tempfile.mkstemp", "seed_rl.common.utils.init_learner_multi_host", "seed_rl.agents.policy_gradient.learner.learner_loop", "ValueError", "seed_rl.agents.policy_gradient.learner_flags.training_config_from_flags", "tensorflow.io.gfile.GFile", "f.write", "tensorflow.io.gfile.GFile", "f.write", "continuous_action_config", "os.path.join", "os.path.join", "gin.operative_config_str", "gin.operative_config_str"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.create_environment", "home.repos.pwc.inspect_result.google-research_seed_rl.common.actor.actor_loop", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.replace", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.init_learner_multi_host", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.learner_loop", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner_flags.training_config_from_flags", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.LevelCache.write", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.LevelCache.write", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.continuous_action_config"], ["", "def", "main", "(", "unused_argv", ")", ":", "\n", "# Save the string flags now as we modify them later.", "\n", "  ", "string_flags", "=", "FLAGS", ".", "flags_into_string", "(", ")", "\n", "gin", ".", "parse_config_files_and_bindings", "(", "\n", "[", "FLAGS", ".", "gin_config", "]", "if", "FLAGS", ".", "gin_config", "else", "[", "]", ",", "\n", "# Gin uses slashes to denote scopes but XM doesn't allow slashes in", "\n", "# parameter names so we use __ instead and convert it to slashes here.", "\n", "[", "s", ".", "replace", "(", "'__'", ",", "'/'", ")", "for", "s", "in", "FLAGS", ".", "gin_bindings", "]", ")", "\n", "gym_kwargs", "=", "{", "}", "\n", "if", "FLAGS", ".", "mujoco_model", ":", "\n", "    ", "local_mujoco_model", "=", "tempfile", ".", "mkstemp", "(", "\n", "prefix", "=", "'mujoco_model'", ",", "suffix", "=", "'.xml'", ")", "[", "1", "]", "\n", "logging", ".", "info", "(", "'Copying remote model %s to local file %s'", ",", "FLAGS", ".", "mujoco_model", ",", "\n", "local_mujoco_model", ")", "\n", "tf", ".", "io", ".", "gfile", ".", "copy", "(", "FLAGS", ".", "mujoco_model", ",", "local_mujoco_model", ",", "overwrite", "=", "True", ")", "\n", "gym_kwargs", "[", "'model_path'", "]", "=", "local_mujoco_model", "\n", "\n", "", "create_environment", "=", "lambda", "task", ",", "config", ":", "env", ".", "create_environment", "(", "\n", "env_name", "=", "config", ".", "env_name", ",", "\n", "discretization", "=", "'none'", ",", "\n", "n_actions_per_dim", "=", "11", ",", "\n", "action_ratio", "=", "30", ",", "\n", "gym_kwargs", "=", "gym_kwargs", ")", "\n", "\n", "if", "FLAGS", ".", "run_mode", "==", "'actor'", ":", "\n", "    ", "actor", ".", "actor_loop", "(", "create_environment", ")", "\n", "", "elif", "FLAGS", ".", "run_mode", "==", "'learner'", ":", "\n", "    ", "logdir", "=", "FLAGS", ".", "logdir", "\n", "settings", "=", "utils", ".", "init_learner_multi_host", "(", "FLAGS", ".", "num_training_tpus", ")", "\n", "learner", ".", "learner_loop", "(", "\n", "create_environment", ",", "\n", "create_agent", ",", "\n", "create_optimizer", ",", "\n", "learner_flags", ".", "training_config_from_flags", "(", ")", ",", "\n", "settings", ",", "\n", "action_distribution_config", "=", "continuous_action_config", "(", ")", ")", "\n", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "os", ".", "path", ".", "join", "(", "logdir", ",", "'learner_flags.txt'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "string_flags", ")", "\n", "", "with", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "os", ".", "path", ".", "join", "(", "logdir", ",", "'learner.gin'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "gin", ".", "operative_config_str", "(", ")", ")", "\n", "", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'Unsupported run mode {}'", ".", "format", "(", "FLAGS", ".", "run_mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.environment_test.EnvironmentTest.run_environment": [[26, 32], ["environment.reset", "range", "environment.step", "environment.action_space.sample", "environment.reset"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.step", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset"], ["  ", "def", "run_environment", "(", "self", ",", "environment", ")", ":", "\n", "    ", "environment", ".", "reset", "(", ")", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "      ", "_", ",", "_", ",", "done", ",", "_", "=", "environment", ".", "step", "(", "environment", ".", "action_space", ".", "sample", "(", ")", ")", "\n", "if", "done", ":", "\n", "        ", "environment", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.environment_test.EnvironmentTest.test_mujoco_env": [[33, 38], ["environment_test.EnvironmentTest.run_environment", "seed_rl.mujoco.env.create_environment"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.environment_test.EnvironmentTest.run_environment", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.create_environment"], ["", "", "", "def", "test_mujoco_env", "(", "self", ")", ":", "\n", "    ", "for", "discretization", "in", "[", "'none'", ",", "'log'", ",", "'lin'", "]", ":", "\n", "      ", "self", ".", "run_environment", "(", "\n", "env", ".", "create_environment", "(", "\n", "'HalfCheetah-v2'", ",", "discretization", "=", "discretization", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.environment_test.EnvironmentTest.test_toy_envs": [[39, 42], ["environment_test.EnvironmentTest.run_environment", "environment_test.EnvironmentTest.run_environment", "seed_rl.mujoco.env.create_environment", "seed_rl.mujoco.env.create_environment"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.environment_test.EnvironmentTest.run_environment", "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.environment_test.EnvironmentTest.run_environment", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.create_environment", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.create_environment"], ["", "", "def", "test_toy_envs", "(", "self", ")", ":", "\n", "    ", "self", ".", "run_environment", "(", "env", ".", "create_environment", "(", "'toy_env'", ")", ")", "\n", "self", ".", "run_environment", "(", "env", ".", "create_environment", "(", "'toy_memory_env'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.env.SinglePrecisionWrapper.__init__": [[32, 45], ["gym.Wrapper.__init__", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "    ", "\"\"\"Initialize the wrapper.\n\n    Args:\n      env: MujocoEnv to be wrapped.\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "\n", "self", ".", "observation_space", ".", "low", ",", "\n", "self", ".", "observation_space", ".", "high", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "num_steps", "=", "0", "\n", "self", ".", "max_episode_steps", "=", "self", ".", "env", ".", "spec", ".", "max_episode_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.env.SinglePrecisionWrapper.reset": [[46, 49], ["env.SinglePrecisionWrapper.env.reset().astype", "env.SinglePrecisionWrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "self", ".", "num_steps", "=", "0", "\n", "return", "self", ".", "env", ".", "reset", "(", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.env.SinglePrecisionWrapper.step": [[50, 60], ["env.SinglePrecisionWrapper.env.step", "isinstance", "float.astype", "float", "obs.astype"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "self", ".", "num_steps", "+=", "1", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "if", "self", ".", "num_steps", ">=", "self", ".", "max_episode_steps", ":", "\n", "      ", "done", "=", "True", "\n", "", "if", "isinstance", "(", "reward", ",", "np", ".", "ndarray", ")", ":", "\n", "      ", "reward", "=", "reward", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "      ", "reward", "=", "float", "(", "reward", ")", "\n", "", "return", "obs", ".", "astype", "(", "np", ".", "float32", ")", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.mujoco.env.create_environment": [[62, 111], ["seed_rl.common.env_wrappers.UniformBoundActionSpaceWrapper", "seed_rl.mujoco.toy_env.ToyEnv", "seed_rl.common.env_wrappers.DiscretizeEnvWrapper", "seed_rl.mujoco.toy_env.ToyMemoryEnv", "seed_rl.mujoco.toy_env.BitFlippingEnv", "gym.spec", "gym.spec.make", "env.SinglePrecisionWrapper"], "function", ["None"], ["", "", "def", "create_environment", "(", "env_name", ",", "\n", "discretization", "=", "'none'", ",", "\n", "n_actions_per_dim", "=", "11", ",", "\n", "action_ratio", "=", "30.", ",", "\n", "gym_kwargs", "=", "None", ")", ":", "\n", "  ", "\"\"\"Create environment from OpenAI Gym.\n\n  Actions are rescaled to the range [-1, 1] and optionally discretized.\n\n  Args:\n    env_name: environment name from OpenAI Gym. You can also use 'toy_env' or\n      'toy_memory_env' to get very simple environments which can be used for\n      sanity testing RL algorithms.\n    discretization: 'none', 'lin' or 'log'. Values other than 'none' cause\n      action coordinates to be discretized into n_actions_per_dim buckets.\n      Buckets are spaced linearly between the bounds if 'lin' mode is used and\n      logarithmically for 'log' mode.\n    n_actions_per_dim: the number of buckets per action coordinate if\n      discretization is used.\n    action_ratio: the ratio between the highest and the lowest positive action\n      for logarithmic action discretization.\n    gym_kwargs: Kwargs to pass to the gym environment contructor.\n\n  Returns:\n    wrapped environment\n  \"\"\"", "\n", "\n", "assert", "FLAGS", ".", "num_action_repeats", "==", "1", ",", "'Only action repeat of 1 is supported.'", "\n", "\n", "if", "env_name", "==", "'toy_env'", ":", "\n", "    ", "env", "=", "toy_env", ".", "ToyEnv", "(", ")", "\n", "", "elif", "env_name", "==", "'toy_memory_env'", ":", "\n", "    ", "env", "=", "toy_env", ".", "ToyMemoryEnv", "(", ")", "\n", "", "elif", "env_name", "==", "'bit_flip'", ":", "\n", "    ", "return", "toy_env", ".", "BitFlippingEnv", "(", ")", "\n", "", "else", ":", "# mujoco", "\n", "    ", "gym_kwargs", "=", "gym_kwargs", "if", "gym_kwargs", "else", "{", "}", "\n", "gym_spec", "=", "gym", ".", "spec", "(", "env_name", ")", "\n", "env", "=", "gym_spec", ".", "make", "(", "**", "gym_kwargs", ")", "\n", "env", "=", "SinglePrecisionWrapper", "(", "env", ")", "\n", "\n", "# rescale actions so that all bounds are [-1, 1]", "\n", "", "env", "=", "env_wrappers", ".", "UniformBoundActionSpaceWrapper", "(", "env", ")", "\n", "# optionally discretize actions", "\n", "if", "discretization", "!=", "'none'", ":", "\n", "    ", "env", "=", "env_wrappers", ".", "DiscretizeEnvWrapper", "(", "env", ",", "n_actions_per_dim", ",", "\n", "discretization", ",", "action_ratio", ")", "\n", "\n", "", "return", "env", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.gcp.run.get_py_main": [[35, 38], ["os.path.join"], "function", ["None"], ["def", "get_py_main", "(", ")", ":", "\n", "  ", "return", "os", ".", "path", ".", "join", "(", "'/seed_rl'", ",", "FLAGS", ".", "environment", ",", "\n", "FLAGS", ".", "agent", "+", "'_main.py'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.gcp.run.run_learner": [[40, 52], ["[].split", "executor.submit", "run.get_py_main", "args.extend", "config.get().get", "config.get", "sys.argv.index"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.gcp.run.get_py_main"], ["", "def", "run_learner", "(", "executor", ",", "config", ")", ":", "\n", "  ", "\"\"\"Runs learner job using executor.\"\"\"", "\n", "_", ",", "master_port", "=", "config", ".", "get", "(", "'cluster'", ")", ".", "get", "(", "'master'", ")", "[", "0", "]", ".", "split", "(", "':'", ",", "1", ")", "\n", "args", "=", "[", "\n", "'python'", ",", "get_py_main", "(", ")", ",", "\n", "'--run_mode=learner'", ",", "\n", "'--server_address=[::]:{}'", ".", "format", "(", "master_port", ")", ",", "\n", "'--num_envs={}'", ".", "format", "(", "FLAGS", ".", "workers", "*", "FLAGS", ".", "actors_per_worker", ")", "\n", "]", "\n", "if", "'--'", "in", "sys", ".", "argv", ":", "\n", "    ", "args", ".", "extend", "(", "sys", ".", "argv", "[", "sys", ".", "argv", ".", "index", "(", "'--'", ")", "+", "1", ":", "]", ")", "\n", "", "return", "executor", ".", "submit", "(", "subprocess", ".", "check_call", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.gcp.run.run_actor": [[54, 69], ["config.get().get", "args.append", "executor.submit", "config.get().get", "run.get_py_main", "args.extend", "config.get", "config.get", "sys.argv.index"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.gcp.run.get_py_main"], ["", "def", "run_actor", "(", "executor", ",", "config", ",", "actor_id", ")", ":", "\n", "  ", "\"\"\"Runs actor job using executor.\"\"\"", "\n", "master_addr", "=", "config", ".", "get", "(", "'cluster'", ")", ".", "get", "(", "'master'", ")", "[", "0", "]", "\n", "args", "=", "[", "\n", "'python'", ",", "get_py_main", "(", ")", ",", "\n", "'--run_mode=actor'", ",", "\n", "'--server_address={}'", ".", "format", "(", "master_addr", ")", ",", "\n", "'--num_envs={}'", ".", "format", "(", "FLAGS", ".", "workers", "*", "FLAGS", ".", "actors_per_worker", ")", "\n", "]", "\n", "worker_index", "=", "config", ".", "get", "(", "'task'", ")", ".", "get", "(", "'index'", ")", "\n", "args", ".", "append", "(", "'--task={}'", ".", "format", "(", "worker_index", "*", "FLAGS", ".", "actors_per_worker", "+", "\n", "actor_id", ")", ")", "\n", "if", "'--'", "in", "sys", ".", "argv", ":", "\n", "    ", "args", ".", "extend", "(", "sys", ".", "argv", "[", "sys", ".", "argv", ".", "index", "(", "'--'", ")", "+", "1", ":", "]", ")", "\n", "", "return", "executor", ".", "submit", "(", "subprocess", ".", "check_call", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.gcp.run.main": [[71, 90], ["os.environ.get", "absl.logging.info", "json.loads", "json.loads.get().get", "concurrent.futures.ThreadPoolExecutor", "futures.append", "range", "f.result", "json.loads.get", "run.run_learner", "futures.append", "run.run_actor"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.gcp.run.run_learner", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.gcp.run.run_actor"], ["", "def", "main", "(", "_", ")", ":", "\n", "  ", "tf_config", "=", "os", ".", "environ", ".", "get", "(", "'TF_CONFIG'", ",", "None", ")", "\n", "logging", ".", "info", "(", "tf_config", ")", "\n", "config", "=", "json", ".", "loads", "(", "tf_config", ")", "\n", "job_type", "=", "config", ".", "get", "(", "'task'", ",", "{", "}", ")", ".", "get", "(", "'type'", ")", "\n", "os", ".", "environ", "[", "'PYTHONPATH'", "]", "=", "'/'", "\n", "os", ".", "environ", "[", "'LD_LIBRARY_PATH'", "]", "=", "os", ".", "environ", "[", "\n", "'LD_LIBRARY_PATH'", "]", "+", "':/root/.mujoco/mjpro150/bin'", "\n", "executor", "=", "concurrent", ".", "futures", ".", "ThreadPoolExecutor", "(", "\n", "max_workers", "=", "FLAGS", ".", "actors_per_worker", ")", "\n", "futures", "=", "[", "]", "\n", "if", "job_type", "==", "'master'", ":", "\n", "    ", "futures", ".", "append", "(", "run_learner", "(", "executor", ",", "config", ")", ")", "\n", "", "else", ":", "\n", "    ", "assert", "job_type", "==", "'worker'", ",", "'Unexpected task type: {}'", ".", "format", "(", "job_type", ")", "\n", "for", "actor_id", "in", "range", "(", "FLAGS", ".", "actors_per_worker", ")", ":", "\n", "      ", "futures", ".", "append", "(", "run_actor", "(", "executor", ",", "config", ",", "actor_id", ")", ")", "\n", "", "", "for", "f", "in", "futures", ":", "\n", "    ", "f", ".", "result", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner_test.LearnerTest.test_apply_epsilon_greedy": [[32, 59], ["tensorflow.random.set_seed", "tensorflow.range", "tensorflow.reduce_sum().numpy", "learner_test.LearnerTest.assertLess", "learner_test.LearnerTest.assertGreater", "learner_test.LearnerTest.assertEqual", "tensorflow.function", "tensorflow.reduce_sum().numpy", "tensorflow.zeros", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.math.greater_equal", "tensorflow.cast", "tensorflow.logical_or", "tensorflow.math.greater_equal", "tensorflow.equal"], "methods", ["None"], ["  ", "def", "test_apply_epsilon_greedy", "(", "self", ")", ":", "\n", "    ", "tf", ".", "random", ".", "set_seed", "(", "5", ")", "\n", "num_actors", "=", "10000", "\n", "epsilon", "=", "0.4", "\n", "# Actions from network are negative, random actions are non-negative. This", "\n", "# allows distinguishing where an action comes from.", "\n", "action", "=", "tf", ".", "range", "(", "-", "num_actors", ",", "0", ")", "\n", "new_action", "=", "tf", ".", "function", "(", "learner", ".", "apply_epsilon_greedy", ")", "(", "\n", "action", ",", "\n", "# We always pick the first actor which has an epsilon of 0.4", "\n", "env_ids", "=", "tf", ".", "zeros", "(", "[", "num_actors", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "num_training_envs", "=", "10", ",", "\n", "num_eval_envs", "=", "0", ",", "\n", "eval_epsilon", "=", "0", ",", "\n", "num_actions", "=", "200", ")", "\n", "num_random_actions", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "cast", "(", "tf", ".", "math", ".", "greater_equal", "(", "new_action", ",", "0", ")", ",", "tf", ".", "int32", ")", ")", ".", "numpy", "(", ")", "\n", "self", ".", "assertLess", "(", "num_random_actions", ",", "num_actors", "*", "epsilon", "*", "1.3", ")", "\n", "self", ".", "assertGreater", "(", "num_random_actions", ",", "num_actors", "*", "epsilon", "*", "0.7", ")", "\n", "# Check that new actions are either random actions, or equal to the input", "\n", "# actions.", "\n", "self", ".", "assertEqual", "(", "\n", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "cast", "(", "tf", ".", "logical_or", "(", "\n", "tf", ".", "math", ".", "greater_equal", "(", "new_action", ",", "0", ")", ",", "\n", "tf", ".", "equal", "(", "new_action", ",", "action", ")", ")", ",", "tf", ".", "int32", ")", ")", ".", "numpy", "(", ")", ",", "\n", "num_actors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner_test.LearnerTest.test_get_envs_epsilon": [[60, 71], ["learner_test.LearnerTest.assertAllClose", "learner_test.LearnerTest.assertAllClose", "learner_test.LearnerTest.assertAllClose", "tensorflow.function", "tensorflow.range"], "methods", ["None"], ["", "def", "test_get_envs_epsilon", "(", "self", ")", ":", "\n", "    ", "epsilons", "=", "tf", ".", "function", "(", "learner", ".", "get_envs_epsilon", ")", "(", "\n", "tf", ".", "range", "(", "20", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "num_training_envs", "=", "10", ",", "\n", "num_eval_envs", "=", "10", ",", "\n", "eval_epsilon", "=", "1e-3", ")", "\n", "# Eval epsilons.", "\n", "self", ".", "assertAllClose", "(", "epsilons", "[", "10", ":", "]", ",", "[", "1e-3", "]", "*", "10", ")", "\n", "# Training epsilons.", "\n", "self", ".", "assertAllClose", "(", "epsilons", "[", "0", "]", ",", "0.4", ")", "\n", "self", ".", "assertAllClose", "(", "epsilons", "[", "9", "]", ",", "0.4", "**", "8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner_test.LearnerTest._create_env_output": [[74, 83], ["seed_rl.common.utils.EnvOutput", "tensorflow.random.uniform", "tensorflow.cast", "learner_test.LearnerTest._random_obs", "tensorflow.zeros", "tensorflow.ones", "tensorflow.random.uniform"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.AgentsTest._random_obs"], ["", "def", "_create_env_output", "(", "self", ",", "batch_size", ",", "unroll_length", ")", ":", "\n", "    ", "return", "utils", ".", "EnvOutput", "(", "\n", "reward", "=", "tf", ".", "random", ".", "uniform", "(", "[", "unroll_length", ",", "batch_size", "]", ")", ",", "\n", "done", "=", "tf", ".", "cast", "(", "tf", ".", "random", ".", "uniform", "(", "[", "unroll_length", ",", "batch_size", "]", ",", "\n", "maxval", "=", "2", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "bool", ")", ",", "\n", "observation", "=", "self", ".", "_random_obs", "(", "batch_size", ",", "unroll_length", ")", ",", "\n", "abandoned", "=", "tf", ".", "zeros", "(", "[", "unroll_length", ",", "batch_size", "]", ",", "dtype", "=", "tf", ".", "bool", ")", ",", "\n", "episode_step", "=", "tf", ".", "ones", "(", "[", "unroll_length", ",", "batch_size", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner_test.LearnerTest._random_obs": [[84, 89], ["tensorflow.cast", "tensorflow.random.uniform"], "methods", ["None"], ["", "def", "_random_obs", "(", "self", ",", "batch_size", ",", "unroll_length", ")", ":", "\n", "    ", "return", "tf", ".", "cast", "(", "\n", "tf", ".", "random", ".", "uniform", "(", "[", "unroll_length", ",", "batch_size", "]", "+", "OBS_SHAPE", ",", "\n", "maxval", "=", "256", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner_test.LearnerTest._create_agent_outputs": [[90, 95], ["seed_rl.atari.networks.AgentOutput", "tensorflow.random.uniform", "tensorflow.random.uniform"], "methods", ["None"], ["", "def", "_create_agent_outputs", "(", "self", ",", "batch_size", ",", "unroll_length", ",", "num_actions", ")", ":", "\n", "    ", "return", "networks", ".", "AgentOutput", "(", "\n", "action", "=", "tf", ".", "random", ".", "uniform", "(", "[", "unroll_length", ",", "batch_size", "]", ",", "\n", "maxval", "=", "num_actions", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "q_values", "=", "tf", ".", "random", ".", "uniform", "(", "[", "unroll_length", ",", "batch_size", ",", "num_actions", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner_test.LearnerTest.test_compute_loss_basic": [[96, 113], ["seed_rl.atari.networks.DuelingLSTMDQNNet", "tensorflow.random.uniform", "tensorflow.function", "seed_rl.atari.networks.DuelingLSTMDQNNet", "seed_rl.atari.networks.DuelingLSTMDQNNet.initial_state", "learner_test.LearnerTest._create_env_output", "learner_test.LearnerTest._create_agent_outputs"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state", "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner_test.LearnerTest._create_env_output", "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner_test.LearnerTest._create_agent_outputs"], ["", "def", "test_compute_loss_basic", "(", "self", ")", ":", "\n", "    ", "\"\"\"Basic test to exercise learner.compute_loss_and_priorities().\"\"\"", "\n", "batch_size", "=", "32", "\n", "num_actions", "=", "3", "\n", "unroll_length", "=", "10", "\n", "training_agent", "=", "networks", ".", "DuelingLSTMDQNNet", "(", "num_actions", ",", "OBS_SHAPE", ")", "\n", "prev_actions", "=", "tf", ".", "random", ".", "uniform", "(", "\n", "[", "unroll_length", ",", "batch_size", "]", ",", "maxval", "=", "2", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "tf", ".", "function", "(", "learner", ".", "compute_loss_and_priorities", ")", "(", "\n", "training_agent", ",", "\n", "networks", ".", "DuelingLSTMDQNNet", "(", "num_actions", ",", "OBS_SHAPE", ")", ",", "\n", "training_agent", ".", "initial_state", "(", "batch_size", ")", ",", "\n", "prev_actions", ",", "\n", "self", ".", "_create_env_output", "(", "batch_size", ",", "unroll_length", ")", ",", "\n", "self", ".", "_create_agent_outputs", "(", "batch_size", ",", "unroll_length", ",", "num_actions", ")", ",", "\n", "0.99", ",", "\n", "burn_in", "=", "5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner_test.LearnerTest.test_value_function_rescaling": [[114, 141], ["numpy.linspace", "learner_test.LearnerTest.assertAllEqual", "learner_test.LearnerTest.assertAllGreater", "learner_test.LearnerTest.assertAllLess", "learner_test.LearnerTest.assertAllEqual", "learner_test.LearnerTest.assertAllClose", "learner_test.LearnerTest.assertAllClose", "learner_test.LearnerTest.assertAllClose", "seed_rl.agents.r2d2.learner.value_function_rescaling", "seed_rl.agents.r2d2.learner.value_function_rescaling", "seed_rl.agents.r2d2.learner.value_function_rescaling", "seed_rl.agents.r2d2.learner.inverse_value_function_rescaling", "seed_rl.agents.r2d2.learner.value_function_rescaling", "tensorflow.constant", "seed_rl.agents.r2d2.learner.inverse_value_function_rescaling", "tensorflow.constant", "seed_rl.agents.r2d2.learner.inverse_value_function_rescaling", "tensorflow.constant", "tensorflow.constant", "seed_rl.agents.r2d2.learner.value_function_rescaling"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.value_function_rescaling", "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.value_function_rescaling", "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.value_function_rescaling", "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.inverse_value_function_rescaling", "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.value_function_rescaling", "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.inverse_value_function_rescaling", "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.inverse_value_function_rescaling", "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.value_function_rescaling"], ["", "def", "test_value_function_rescaling", "(", "self", ")", ":", "\n", "    ", "for", "x", "in", "np", ".", "linspace", "(", "-", "100.", ",", "100.", ")", ":", "\n", "      ", "self", ".", "assertAllClose", "(", "\n", "learner", ".", "inverse_value_function_rescaling", "(", "\n", "learner", ".", "value_function_rescaling", "(", "x", ")", ")", ",", "\n", "x", ")", "\n", "", "self", ".", "assertAllEqual", "(", "\n", "learner", ".", "value_function_rescaling", "(", "0.", ")", ",", "0", ")", "\n", "self", ".", "assertAllGreater", "(", "\n", "learner", ".", "value_function_rescaling", "(", "1000.", ")", ",", "10.", ")", "\n", "self", ".", "assertAllLess", "(", "\n", "learner", ".", "value_function_rescaling", "(", "-", "1000.", ")", ",", "-", "10.", ")", "\n", "self", ".", "assertAllEqual", "(", "\n", "learner", ".", "inverse_value_function_rescaling", "(", "0.", ")", ",", "0", ")", "\n", "\n", "# Higher dimensional inputs:", "\n", "self", ".", "assertAllClose", "(", "\n", "learner", ".", "value_function_rescaling", "(", "\n", "tf", ".", "constant", "(", "[", "0.", ",", "3.", ",", "-", "3.", "]", ")", ")", ",", "\n", "tf", ".", "constant", "(", "[", "0.", ",", "1", "+", "3e-3", ",", "-", "1", "-", "3e-3", "]", ")", ")", "\n", "# We need a fairly high absolute precision tolerance. The re-scaling is not", "\n", "# very stable numerically.", "\n", "self", ".", "assertAllClose", "(", "\n", "learner", ".", "inverse_value_function_rescaling", "(", "\n", "tf", ".", "constant", "(", "[", "0.", ",", "1", "+", "3e-3", ",", "-", "1", "-", "3e-3", "]", ")", ")", ",", "\n", "tf", ".", "constant", "(", "[", "0.", ",", "3", ",", "-", "3", "]", ")", ",", "\n", "atol", "=", "2e-4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner_test.LearnerTest.test_n_step_bellman_target_one_step": [[142, 152], ["learner_test.LearnerTest.assertAllClose", "tensorflow.function", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "test_n_step_bellman_target_one_step", "(", "self", ")", ":", "\n", "    ", "targets", "=", "tf", ".", "function", "(", "learner", ".", "n_step_bellman_target", ")", "(", "\n", "rewards", "=", "np", ".", "array", "(", "[", "[", "1.", ",", "2.", ",", "3.", "]", "]", ",", "np", ".", "float32", ")", ".", "T", ",", "\n", "done", "=", "np", ".", "array", "(", "[", "[", "False", "]", "*", "3", "]", ")", ".", "T", ",", "\n", "q_target", "=", "np", ".", "array", "(", "[", "[", "100", ",", "200", ",", "300", "]", "]", ",", "np", ".", "float32", ")", ".", "T", ",", "\n", "gamma", "=", "0.9", ",", "\n", "n_steps", "=", "1", ")", "\n", "self", ".", "assertAllClose", "(", "\n", "targets", ",", "\n", "np", ".", "array", "(", "[", "[", "1", "+", "0.9", "*", "100", ",", "2", "+", "0.9", "*", "200", ",", "3", "+", "0.9", "*", "300", "]", "]", ")", ".", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner_test.LearnerTest.test_n_step_bellman_target_one_step_with_done": [[153, 162], ["learner_test.LearnerTest.assertAllClose", "tensorflow.function", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "test_n_step_bellman_target_one_step_with_done", "(", "self", ")", ":", "\n", "    ", "targets", "=", "tf", ".", "function", "(", "learner", ".", "n_step_bellman_target", ")", "(", "\n", "rewards", "=", "np", ".", "array", "(", "[", "[", "1.", ",", "2.", ",", "3.", "]", "]", ",", "np", ".", "float32", ")", ".", "T", ",", "\n", "done", "=", "np", ".", "array", "(", "[", "[", "False", ",", "True", ",", "False", "]", "]", ")", ".", "T", ",", "\n", "q_target", "=", "np", ".", "array", "(", "[", "[", "100", ",", "200", ",", "300", "]", "]", ",", "np", ".", "float32", ")", ".", "T", ",", "\n", "gamma", "=", "0.9", ",", "\n", "n_steps", "=", "1", ")", "\n", "self", ".", "assertAllClose", "(", "targets", ",", "\n", "np", ".", "array", "(", "[", "[", "1", "+", "0.9", "*", "100", ",", "2", ",", "3", "+", "0.9", "*", "300", "]", "]", ")", ".", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner_test.LearnerTest.test_n_step_bellman_target_two_steps": [[163, 177], ["learner_test.LearnerTest.assertAllClose", "tensorflow.function", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "test_n_step_bellman_target_two_steps", "(", "self", ")", ":", "\n", "    ", "targets", "=", "tf", ".", "function", "(", "learner", ".", "n_step_bellman_target", ")", "(", "\n", "rewards", "=", "np", ".", "array", "(", "[", "[", "1.", ",", "2.", ",", "3.", "]", "]", ",", "np", ".", "float32", ")", ".", "T", ",", "\n", "done", "=", "np", ".", "array", "(", "[", "[", "False", ",", "False", ",", "False", "]", "]", ")", ".", "T", ",", "\n", "q_target", "=", "np", ".", "array", "(", "[", "[", "100", ",", "200", ",", "300", "]", "]", ",", "np", ".", "float32", ")", ".", "T", ",", "\n", "gamma", "=", "0.9", ",", "\n", "n_steps", "=", "2", ")", "\n", "self", ".", "assertAllClose", "(", "\n", "targets", ",", "\n", "np", ".", "array", "(", "[", "[", "\n", "1", "+", "0.9", "*", "2", "+", "0.9", "**", "2", "*", "200", ",", "\n", "2", "+", "0.9", "*", "3", "+", "0.9", "**", "2", "*", "300", ",", "\n", "# Last target is actually 1-step.", "\n", "3", "+", "0.9", "*", "300", ",", "\n", "]", "]", ")", ".", "T", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner_test.LearnerTest.test_n_step_bellman_target_three_steps_done": [[179, 198], ["learner_test.LearnerTest.assertAllClose", "tensorflow.function", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "test_n_step_bellman_target_three_steps_done", "(", "self", ")", ":", "\n", "    ", "targets", "=", "tf", ".", "function", "(", "learner", ".", "n_step_bellman_target", ")", "(", "\n", "rewards", "=", "np", ".", "array", "(", "[", "[", "1.", ",", "2.", ",", "3.", ",", "4.", ",", "5.", ",", "6.", ",", "7.", "]", "]", ",", "np", ".", "float32", ")", ".", "T", ",", "\n", "done", "=", "np", ".", "array", "(", "[", "[", "False", ",", "False", ",", "False", ",", "True", ",", "False", ",", "False", ",", "False", "]", "]", ")", ".", "T", ",", "\n", "q_target", "=", "np", ".", "array", "(", "[", "[", "100", ",", "200", ",", "300", ",", "400", ",", "500", ",", "600", ",", "700", "]", "]", ",", "np", ".", "float32", ")", ".", "T", ",", "\n", "gamma", "=", "0.9", ",", "\n", "n_steps", "=", "3", ")", "\n", "self", ".", "assertAllClose", "(", "\n", "targets", ",", "\n", "np", ".", "array", "(", "[", "[", "\n", "1", "+", "0.9", "*", "2", "+", "0.9", "**", "2", "*", "3", "+", "0.9", "**", "3", "*", "300", ",", "\n", "2", "+", "0.9", "*", "3", "+", "0.9", "**", "2", "*", "4", ",", "\n", "3", "+", "0.9", "*", "4", ",", "\n", "4", ",", "\n", "5", "+", "0.9", "*", "6", "+", "0.9", "**", "2", "*", "7", "+", "0.9", "**", "3", "*", "700", ",", "\n", "# Actually 2-step.", "\n", "6", "+", "0.9", "*", "7", "+", "0.9", "**", "2", "*", "700", ",", "\n", "# Actually 1-step.", "\n", "7", "+", "0.9", "*", "700", ",", "\n", "]", "]", ")", ".", "T", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.get_replay_insertion_batch_size": [[113, 118], ["int", "int"], "function", ["None"], ["def", "get_replay_insertion_batch_size", "(", "per_replica", "=", "False", ")", ":", "\n", "  ", "if", "per_replica", ":", "\n", "    ", "return", "int", "(", "FLAGS", ".", "batch_size", "/", "FLAGS", ".", "replay_ratio", "/", "FLAGS", ".", "num_training_tpus", ")", "\n", "", "else", ":", "\n", "    ", "return", "int", "(", "FLAGS", ".", "batch_size", "/", "FLAGS", ".", "replay_ratio", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.get_num_training_envs": [[120, 122], ["None"], "function", ["None"], ["", "", "def", "get_num_training_envs", "(", ")", ":", "\n", "  ", "return", "FLAGS", ".", "num_envs", "-", "FLAGS", ".", "num_eval_envs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.is_training_env": [[124, 127], ["learner.get_num_training_envs"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.get_num_training_envs"], ["", "def", "is_training_env", "(", "env_id", ")", ":", "\n", "  ", "\"\"\"Training environment IDs are in range [0, num_training_envs).\"\"\"", "\n", "return", "env_id", "<", "get_num_training_envs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.get_envs_epsilon": [[129, 150], ["tensorflow.concat", "tensorflow.gather", "tensorflow.math.pow", "tensorflow.constant", "tensorflow.linspace"], "function", ["None"], ["", "def", "get_envs_epsilon", "(", "env_ids", ",", "num_training_envs", ",", "num_eval_envs", ",", "eval_epsilon", ")", ":", "\n", "  ", "\"\"\"Per-environment epsilon as in Apex and R2D2.\n\n  Args:\n    env_ids: <int32>[inference_batch_size], the environment task IDs (in range\n      [0, num_training_envs+num_eval_envs)).\n    num_training_envs: Number of training environments. Training environments\n      should have IDs in [0, num_training_envs).\n    num_eval_envs: Number of evaluation environments. Eval environments should\n      have IDs in [num_training_envs, num_training_envs + num_eval_envs).\n    eval_epsilon: Epsilon used for eval environments.\n\n  Returns:\n    A 1D float32 tensor with one epsilon for each input environment ID.\n  \"\"\"", "\n", "# <float32>[num_training_envs + num_eval_envs]", "\n", "epsilons", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "math", ".", "pow", "(", "0.4", ",", "tf", ".", "linspace", "(", "1.", ",", "8.", ",", "num", "=", "num_training_envs", ")", ")", ",", "\n", "tf", ".", "constant", "(", "[", "eval_epsilon", "]", "*", "num_eval_envs", ")", "]", ",", "\n", "axis", "=", "0", ")", "\n", "return", "tf", ".", "gather", "(", "epsilons", ",", "env_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.apply_epsilon_greedy": [[152, 178], ["learner.get_envs_epsilon", "tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.where", "tensorflow.shape", "tensorflow.math.less"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.get_envs_epsilon"], ["", "def", "apply_epsilon_greedy", "(", "actions", ",", "env_ids", ",", "num_training_envs", ",", "\n", "num_eval_envs", ",", "eval_epsilon", ",", "num_actions", ")", ":", "\n", "  ", "\"\"\"Epsilon-greedy: randomly replace actions with given probability.\n\n  Args:\n    actions: <int32>[batch_size] tensor with one action per environment.\n    env_ids: <int32>[inference_batch_size], the environment task IDs (in range\n      [0, num_envs)).\n    num_training_envs: Number of training environments.\n    num_eval_envs: Number of eval environments.\n    eval_epsilon: Epsilon used for eval environments.\n    num_actions: Number of environment actions.\n\n  Returns:\n    A new <int32>[batch_size] tensor with one action per environment. With\n    probability epsilon, the new action is random, and with probability (1 -\n    epsilon), the action is unchanged, where epsilon is chosen for each\n    environment.\n  \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "actions", ")", "[", "0", "]", "\n", "epsilons", "=", "get_envs_epsilon", "(", "env_ids", ",", "num_training_envs", ",", "num_eval_envs", ",", "\n", "eval_epsilon", ")", "\n", "random_actions", "=", "tf", ".", "random", ".", "uniform", "(", "[", "batch_size", "]", ",", "maxval", "=", "num_actions", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", "\n", "probs", "=", "tf", ".", "random", ".", "uniform", "(", "shape", "=", "[", "batch_size", "]", ")", "\n", "return", "tf", ".", "where", "(", "tf", ".", "math", ".", "less", "(", "probs", ",", "epsilons", ")", ",", "random_actions", ",", "actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.value_function_rescaling": [[180, 184], ["tensorflow.math.sign", "tensorflow.math.sqrt", "tensorflow.math.abs"], "function", ["None"], ["", "def", "value_function_rescaling", "(", "x", ")", ":", "\n", "  ", "\"\"\"Value function rescaling per R2D2 paper, table 2.\"\"\"", "\n", "eps", "=", "FLAGS", ".", "value_function_rescaling_epsilon", "\n", "return", "tf", ".", "math", ".", "sign", "(", "x", ")", "*", "(", "tf", ".", "math", ".", "sqrt", "(", "tf", ".", "math", ".", "abs", "(", "x", ")", "+", "1.", ")", "-", "1.", ")", "+", "eps", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.inverse_value_function_rescaling": [[186, 193], ["tensorflow.math.sign", "tensorflow.math.square", "tensorflow.math.sqrt", "tensorflow.math.abs"], "function", ["None"], ["", "def", "inverse_value_function_rescaling", "(", "x", ")", ":", "\n", "  ", "\"\"\"See Proposition A.2 in paper \"Observe and Look Further\".\"\"\"", "\n", "eps", "=", "FLAGS", ".", "value_function_rescaling_epsilon", "\n", "return", "tf", ".", "math", ".", "sign", "(", "x", ")", "*", "(", "\n", "tf", ".", "math", ".", "square", "(", "(", "(", "tf", ".", "math", ".", "sqrt", "(", "\n", "1.", "+", "4.", "*", "eps", "*", "(", "tf", ".", "math", ".", "abs", "(", "x", ")", "+", "1.", "+", "eps", ")", ")", ")", "-", "1.", ")", "/", "(", "2.", "*", "eps", ")", ")", "-", "\n", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.n_step_bellman_target": [[195, 256], ["tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "range", "tensorflow.zeros_like", "range", "tensorflow.zeros_like", "tensorflow.zeros_like", "tensorflow.cast"], "function", ["None"], ["", "def", "n_step_bellman_target", "(", "rewards", ",", "done", ",", "q_target", ",", "gamma", ",", "n_steps", ")", ":", "\n", "  ", "r\"\"\"Computes n-step Bellman targets.\n\n  See section 2.3 of R2D2 paper (which does not mention the logic around end of\n  episode).\n\n  Args:\n    rewards: <float32>[time, batch_size] tensor. This is r_t in the equations\n      below.\n    done: <bool>[time, batch_size] tensor. This is done_t in the equations\n      below. done_t should be true if the episode is done just after\n      experimenting reward r_t.\n    q_target: <float32>[time, batch_size] tensor. This is Q_target(s_{t+1}, a*)\n      (where a* is an action chosen by the caller).\n    gamma: Exponential RL discounting.\n    n_steps: The number of steps to look ahead for computing the Bellman\n      targets.\n\n  Returns:\n    y_t targets as <float32>[time, batch_size] tensor.\n    When n_steps=1, this is just:\n\n    $$r_t + gamma * (1 - done_t) * Q_{target}(s_{t+1}, a^*)$$\n\n    In the general case, this is:\n\n    $$(\\sum_{i=0}^{n-1} \\gamma ^ {i} * notdone_{t, i-1} * r_{t + i}) +\n      \\gamma ^ n * notdone_{t, n-1} * Q_{target}(s_{t + n}, a^*) $$\n\n    where notdone_{t,i} is defined as:\n\n    $$notdone_{t,i} = \\prod_{k=0}^{k=i}(1 - done_{t+k})$$\n\n    The last n_step-1 targets cannot be computed with n_step returns, since we\n    run out of Q_{target}(s_{t+n}). Instead, they will use n_steps-1, .., 1 step\n    returns. For those last targets, the last Q_{target}(s_{t}, a^*) is re-used\n    multiple times.\n  \"\"\"", "\n", "# We append n_steps - 1 times the last q_target. They are divided by gamma **", "\n", "# k to correct for the fact that they are at a 'fake' indice, and will", "\n", "# therefore end up being multiplied back by gamma ** k in the loop below.", "\n", "# We prepend 0s that will be discarded at the first iteration below.", "\n", "bellman_target", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "zeros_like", "(", "q_target", "[", "0", ":", "1", "]", ")", ",", "q_target", "]", "+", "\n", "[", "q_target", "[", "-", "1", ":", "]", "/", "gamma", "**", "k", "\n", "for", "k", "in", "range", "(", "1", ",", "n_steps", ")", "]", ",", "\n", "axis", "=", "0", ")", "\n", "# Pad with n_steps 0s. They will be used to compute the last n_steps-1", "\n", "# targets (having 0 values is important).", "\n", "done", "=", "tf", ".", "concat", "(", "[", "done", "]", "+", "[", "tf", ".", "zeros_like", "(", "done", "[", "0", ":", "1", "]", ")", "]", "*", "n_steps", ",", "axis", "=", "0", ")", "\n", "rewards", "=", "tf", ".", "concat", "(", "[", "rewards", "]", "+", "[", "tf", ".", "zeros_like", "(", "rewards", "[", "0", ":", "1", "]", ")", "]", "*", "n_steps", ",", "\n", "axis", "=", "0", ")", "\n", "# Iteratively build the n_steps targets. After the i-th iteration (1-based),", "\n", "# bellman_target is effectively the i-step returns.", "\n", "for", "_", "in", "range", "(", "n_steps", ")", ":", "\n", "    ", "rewards", "=", "rewards", "[", ":", "-", "1", "]", "\n", "done", "=", "done", "[", ":", "-", "1", "]", "\n", "bellman_target", "=", "(", "\n", "rewards", "+", "gamma", "*", "(", "1.", "-", "tf", ".", "cast", "(", "done", ",", "tf", ".", "float32", ")", ")", "*", "bellman_target", "[", "1", ":", "]", ")", "\n", "\n", "", "return", "bellman_target", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.compute_loss_and_priorities_from_agent_outputs": [[258, 331], ["tensorflow.one_hot", "tensorflow.reduce_sum", "tensorflow.one_hot", "learner.inverse_value_function_rescaling", "tensorflow.stop_gradient", "learner.value_function_rescaling", "tensorflow.abs", "tensorflow.shape", "tensorflow.reduce_sum", "learner.n_step_bellman_target", "tensorflow.reduce_sum", "tensorflow.reduce_max", "tensorflow.reduce_mean", "tensorflow.math.square"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.inverse_value_function_rescaling", "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.value_function_rescaling", "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.n_step_bellman_target"], ["", "def", "compute_loss_and_priorities_from_agent_outputs", "(", "\n", "training_agent_output", ",", "\n", "target_agent_output", ",", "\n", "env_outputs", ",", "\n", "agent_outputs", ",", "\n", "gamma", ",", "eta", "=", "0.9", ")", ":", "\n", "  ", "\"\"\"Computes the loss to optimize and the new priorities.\n\n  This implements the n-step double DQN loss with the Q function computed on\n  sequences of transitions.\n\n  Args:\n    training_agent_output: AgentOutput where tensors have [unroll_length,\n      batch_size] front dimensions. Used for the Q values that should be\n      learned, and for computing the max over next actions as part of\n      double-DQN.\n    target_agent_output: AgentOutput used to compute the double-DQN target.\n    env_outputs: EnvOutputs where tensors have [unroll_length, batch_size]\n      additional front dimensions.\n    agent_outputs: AgentOutputs where tensors have [unroll_length, batch_size]\n      additional front dimensions.\n    gamma: RL discounting factor.\n    eta: float, parameter for balancing mean and max TD errors over a sequence\n      of transitions for computing its new priority.\n\n  Returns:\n    A pair:\n      - The loss for each unroll. Shape <float32>[batch_size]\n      - The new priorities for each unroll. Shape <float32>[batch_size].\n  \"\"\"", "\n", "num_actions", "=", "tf", ".", "shape", "(", "training_agent_output", ".", "q_values", ")", "[", "2", "]", "\n", "# <float32>[time, batch_size, num_actions].", "\n", "replay_action_one_hot", "=", "tf", ".", "one_hot", "(", "agent_outputs", ".", "action", ",", "num_actions", ",", "1.", ",", "0.", ")", "\n", "# This is Q(s, a), where a is the action played (can come from the agent or be", "\n", "# random). This is what we learn.", "\n", "# <float32>[time, batch_size].", "\n", "replay_q", "=", "tf", ".", "reduce_sum", "(", "\n", "training_agent_output", ".", "q_values", "*", "replay_action_one_hot", ",", "axis", "=", "2", ")", "\n", "\n", "# [time, batch_size, num_actions]", "\n", "best_actions_one_hot", "=", "tf", ".", "one_hot", "(", "\n", "training_agent_output", ".", "action", ",", "num_actions", ",", "1.", ",", "0.", ")", "\n", "# This is Q'(s) = h^(-1)(Q_target(s, \\argmax_a Q(s, a)))", "\n", "# [time, batch_size]", "\n", "qtarget_max", "=", "inverse_value_function_rescaling", "(", "tf", ".", "reduce_sum", "(", "\n", "target_agent_output", ".", "q_values", "*", "best_actions_one_hot", ",", "\n", "axis", "=", "2", ")", ")", "\n", "\n", "# [time, batch_size]", "\n", "bellman_target", "=", "tf", ".", "stop_gradient", "(", "n_step_bellman_target", "(", "\n", "env_outputs", ".", "reward", ",", "\n", "env_outputs", ".", "done", ",", "\n", "qtarget_max", ",", "\n", "gamma", ",", "\n", "FLAGS", ".", "n_steps", ")", ")", "\n", "\n", "# replay_q is actually Q(s_{t+1}, a_{t+1}), so we need to shift the targets.", "\n", "bellman_target", "=", "bellman_target", "[", "1", ":", ",", "...", "]", "\n", "\n", "replay_q", "=", "replay_q", "[", ":", "-", "1", ",", "...", "]", "\n", "\n", "bellman_target", "=", "value_function_rescaling", "(", "bellman_target", ")", "\n", "# [time, batch_size]", "\n", "abs_td_errors", "=", "tf", ".", "abs", "(", "bellman_target", "-", "replay_q", ")", "\n", "\n", "# [batch_size]", "\n", "priorities", "=", "(", "eta", "*", "tf", ".", "reduce_max", "(", "abs_td_errors", ",", "axis", "=", "0", ")", "+", "\n", "(", "1", "-", "eta", ")", "*", "tf", ".", "reduce_mean", "(", "abs_td_errors", ",", "axis", "=", "0", ")", ")", "\n", "\n", "# Sums over time dimension.", "\n", "loss", "=", "0.5", "*", "tf", ".", "reduce_sum", "(", "tf", ".", "math", ".", "square", "(", "abs_td_errors", ")", ",", "axis", "=", "0", ")", "\n", "\n", "return", "loss", ",", "priorities", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.compute_loss_and_priorities": [[333, 385], ["training_agent", "target_agent", "learner.compute_loss_and_priorities_from_agent_outputs", "seed_rl.common.utils.split_structure", "seed_rl.common.utils.split_structure", "training_agent", "tensorflow.nest.map_structure", "target_agent"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.compute_loss_and_priorities_from_agent_outputs", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.split_structure", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.split_structure"], ["", "def", "compute_loss_and_priorities", "(", "\n", "training_agent", ",", "target_agent", ",", "\n", "agent_state", ",", "prev_actions", ",", "env_outputs", ",", "agent_outputs", ",", "\n", "gamma", ",", "burn_in", ")", ":", "\n", "  ", "\"\"\"Computes the loss to optimize and the new priorities.\n\n  This implements the n-step double DQN loss with the Q function computed on\n  sequences of transitions.\n\n  Args:\n    training_agent: Keras Model representing the training agent's network.\n    target_agent: Keras Model representing the target agent's network.\n    agent_state: Batched agent recurrent state at the beginning of each unroll.\n    prev_actions: <int32>[unroll_length, batch_size]. This is the action played\n      in the environment before each corresponding \"env_outputs\" (i.e. after\n      epsilon-greedy policy is applied).\n    env_outputs: EnvOutputs where tensors have [unroll_length, batch_size]\n      additional front dimensions.\n    agent_outputs: AgentOutputs where tensors have [unroll_length, batch_size]\n      additional front dimensions.\n    gamma: RL discounting factor.\n    burn_in: Number of time steps on which we update each recurrent state\n      without computing the loss nor propagating gradients.\n\n  Returns:\n    A pair:\n      - The loss for each unroll. Shape <float32>[batch_size]\n      - The new priorities for each unroll. Shape <float32>[batch_size].\n  \"\"\"", "\n", "if", "burn_in", ":", "\n", "    ", "agent_input_prefix", ",", "agent_input_suffix", "=", "utils", ".", "split_structure", "(", "\n", "(", "prev_actions", ",", "env_outputs", ")", ",", "burn_in", ")", "\n", "_", ",", "agent_outputs_suffix", "=", "utils", ".", "split_structure", "(", "agent_outputs", ",", "burn_in", ")", "\n", "_", ",", "training_state", "=", "training_agent", "(", "\n", "agent_input_prefix", ",", "agent_state", ",", "unroll", "=", "True", ")", "\n", "training_state", "=", "tf", ".", "nest", ".", "map_structure", "(", "tf", ".", "stop_gradient", ",", "training_state", ")", "\n", "_", ",", "target_state", "=", "target_agent", "(", "agent_input_prefix", ",", "agent_state", ",", "unroll", "=", "True", ")", "\n", "", "else", ":", "\n", "    ", "agent_input_suffix", "=", "(", "prev_actions", ",", "env_outputs", ")", "\n", "agent_outputs_suffix", "=", "agent_outputs", "\n", "training_state", "=", "agent_state", "\n", "target_state", "=", "agent_state", "\n", "\n", "# Agent outputs have fields with shape [time, batch_size, <field_shape>].", "\n", "", "training_agent_output", ",", "_", "=", "training_agent", "(", "\n", "agent_input_suffix", ",", "training_state", ",", "unroll", "=", "True", ")", "\n", "target_agent_output", ",", "_", "=", "target_agent", "(", "\n", "agent_input_suffix", ",", "target_state", ",", "unroll", "=", "True", ")", "\n", "_", ",", "env_outputs_suffix", "=", "agent_input_suffix", "\n", "return", "compute_loss_and_priorities_from_agent_outputs", "(", "\n", "training_agent_output", ",", "target_agent_output", ",", "env_outputs_suffix", ",", "\n", "agent_outputs_suffix", ",", "gamma", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.create_dataset": [[387, 469], ["strategy.experimental_distribute_datasets_from_function", "ctx.get_per_replica_batch_size", "learner.get_replay_insertion_batch_size", "tensorflow.cast", "tensorflow.cast", "tensorflow.constant", "replay_buffer.sample", "sampled_unrolls._replace._replace", "sampled_unrolls._replace._replace", "tensorflow.nest.flatten", "tensorflow.data.Dataset.from_tensors().repeat", "tf.data.Dataset.from_tensors().repeat.map", "unroll_queue.dequeue_many", "replay_buffer.insert", "tensorflow.equal", "tensorflow.equal", "SampledUnrolls", "tensorflow.summary.histogram", "tensorflow.print", "seed_rl.common.utils.make_time_major", "seed_rl.common.utils.make_time_major", "seed_rl.common.utils.make_time_major", "encode", "tensorflow.data.Dataset.from_tensors", "learner.create_dataset.dequeue"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.sac.learner.get_replay_insertion_batch_size", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.dequeue_many", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.PrioritizedReplay.insert", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.make_time_major", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.make_time_major", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.make_time_major", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.dequeue"], ["", "def", "create_dataset", "(", "unroll_queue", ",", "replay_buffer", ",", "strategy", ",", "batch_size", ",", "\n", "priority_exponent", ",", "encode", ")", ":", "\n", "  ", "\"\"\"Creates a dataset sampling from replay buffer.\n\n  This dataset will consume a batch of unrolls from 'unroll_queue', add it to\n  the replay buffer, and sample a batch of unrolls from it.\n\n  Args:\n    unroll_queue: Queue of 'Unroll' elements.\n    replay_buffer: Replay buffer of 'Unroll' elements.\n    strategy: A `distribute_lib.Strategy`.\n    batch_size: Batch size used for consuming the unroll queue and sampling from\n      the replay buffer.\n    priority_exponent: Priority exponent used for sampling from the replay\n      buffer.\n    encode: Function to encode the data for TPU, etc.\n\n  Returns:\n    A \"distributed `Dataset`\", which acts like a `tf.data.Dataset` except it\n    produces \"PerReplica\" values. Each iteration of the dataset produces\n    flattened `SampledUnrolls` structures where per-timestep tensors have front\n    dimensions [unroll_length, batch_size_per_replica].\n  \"\"\"", "\n", "\n", "@", "tf", ".", "function", "\n", "def", "dequeue", "(", "ctx", ")", ":", "\n", "    ", "\"\"\"Inserts into and samples from the replay buffer.\n\n    Args:\n      ctx: tf.distribute.InputContext.\n\n    Returns:\n      A flattened `SampledUnrolls` structures where per-timestep tensors have\n      front dimensions [unroll_length, batch_size_per_replica].\n    \"\"\"", "\n", "per_replica_batch_size", "=", "ctx", ".", "get_per_replica_batch_size", "(", "batch_size", ")", "\n", "insertion_batch_size", "=", "get_replay_insertion_batch_size", "(", "per_replica", "=", "True", ")", "\n", "\n", "print_every", "=", "tf", ".", "cast", "(", "\n", "insertion_batch_size", "*", "\n", "(", "1", "+", "FLAGS", ".", "replay_buffer_min_size", "//", "50", "//", "insertion_batch_size", ")", ",", "\n", "tf", ".", "int64", ")", "\n", "log_summary_every", "=", "tf", ".", "cast", "(", "insertion_batch_size", "*", "500", ",", "tf", ".", "int64", ")", "\n", "\n", "while", "tf", ".", "constant", "(", "True", ")", ":", "\n", "# Each tensor in 'unrolls' has shape [insertion_batch_size, unroll_length,", "\n", "# <field-specific dimensions>].", "\n", "      ", "unrolls", "=", "unroll_queue", ".", "dequeue_many", "(", "insertion_batch_size", ")", "\n", "# The replay buffer is not threadsafe (and making it thread-safe might", "\n", "# slow it down), which is why we insert and sample in a single thread, and", "\n", "# use TF Queues for passing data between threads.", "\n", "replay_buffer", ".", "insert", "(", "unrolls", ",", "unrolls", ".", "priority", ")", "\n", "if", "tf", ".", "equal", "(", "replay_buffer", ".", "num_inserted", "%", "log_summary_every", ",", "0", ")", ":", "\n", "# Unfortunately, there is no tf.summary(log_every_n_sec).", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "'initial_priorities'", ",", "unrolls", ".", "priority", ")", "\n", "", "if", "replay_buffer", ".", "num_inserted", ">=", "FLAGS", ".", "replay_buffer_min_size", ":", "\n", "        ", "break", "\n", "\n", "", "if", "tf", ".", "equal", "(", "replay_buffer", ".", "num_inserted", "%", "print_every", ",", "0", ")", ":", "\n", "        ", "tf", ".", "print", "(", "'Waiting for the replay buffer to fill up. '", "\n", "'It currently has'", ",", "replay_buffer", ".", "num_inserted", ",", "\n", "'elements, waiting for at least'", ",", "FLAGS", ".", "replay_buffer_min_size", ",", "\n", "'elements'", ")", "\n", "\n", "", "", "sampled_indices", ",", "weights", ",", "sampled_unrolls", "=", "replay_buffer", ".", "sample", "(", "\n", "per_replica_batch_size", ",", "priority_exponent", ")", "\n", "sampled_unrolls", "=", "sampled_unrolls", ".", "_replace", "(", "\n", "prev_actions", "=", "utils", ".", "make_time_major", "(", "sampled_unrolls", ".", "prev_actions", ")", ",", "\n", "env_outputs", "=", "utils", ".", "make_time_major", "(", "sampled_unrolls", ".", "env_outputs", ")", ",", "\n", "agent_outputs", "=", "utils", ".", "make_time_major", "(", "sampled_unrolls", ".", "agent_outputs", ")", ")", "\n", "sampled_unrolls", "=", "sampled_unrolls", ".", "_replace", "(", "\n", "env_outputs", "=", "encode", "(", "sampled_unrolls", ".", "env_outputs", ")", ")", "\n", "# tf.data.Dataset treats list leafs as tensors, so we need to flatten and", "\n", "# repack.", "\n", "return", "tf", ".", "nest", ".", "flatten", "(", "SampledUnrolls", "(", "\n", "sampled_unrolls", ",", "sampled_indices", ",", "weights", ")", ")", "\n", "\n", "", "def", "dataset_fn", "(", "ctx", ")", ":", "\n", "    ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensors", "(", "0", ")", ".", "repeat", "(", "None", ")", "\n", "return", "dataset", ".", "map", "(", "lambda", "_", ":", "dequeue", "(", "ctx", ")", ")", "\n", "\n", "", "return", "strategy", ".", "experimental_distribute_datasets_from_function", "(", "dataset_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.validate_config": [[471, 478], ["seed_rl.common.utils.validate_learner_config"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.validate_learner_config"], ["", "def", "validate_config", "(", ")", ":", "\n", "  ", "utils", ".", "validate_learner_config", "(", "FLAGS", ")", "\n", "assert", "FLAGS", ".", "n_steps", ">=", "1", ",", "'--n_steps < 1 does not make sense.'", "\n", "assert", "FLAGS", ".", "num_envs", ">", "FLAGS", ".", "num_eval_envs", ",", "(", "\n", "'Total number of environments ({}) should be greater than number of '", "\n", "'environments reserved to eval ({})'", ".", "format", "(", "\n", "FLAGS", ".", "num_envs", ",", "FLAGS", ".", "num_eval_envs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.r2d2.learner.learner_loop": [[480, 910], ["absl.logging.info", "learner.validate_config", "seed_rl.common.utils.init_learner", "create_env_fn", "seed_rl.common.utils.EnvOutput", "tensorflow.TensorSpec", "create_agent_fn", "create_agent_fn", "create_agent_fn.initial_state", "tensorflow.nest.map_structure", "tensorflow.nest.map_structure", "encode", "tensorflow.nest.map_structure", "tensorflow.summary.create_file_writer", "tensorflow.train.Checkpoint", "tensorflow.train.CheckpointManager", "seed_rl.grpc.Server", "seed_rl.common.utils.UnrollStore", "seed_rl.common.utils.Aggregator", "seed_rl.common.utils.Aggregator", "seed_rl.common.utils.Aggregator", "seed_rl.common.utils.Aggregator", "seed_rl.common.utils.Aggregator", "Unroll", "seed_rl.common.utils.StructuredFIFOQueue", "EpisodeInfo", "seed_rl.common.utils.StructuredFIFOQueue", "seed_rl.common.utils.PrioritizedReplay", "tensorflow.Variable", "tensorflow.nest.map_structure", "tensorflow.function", "grpc.Server.start", "tf.train.CheckpointManager.save", "grpc.Server.shutdown", "utils.StructuredFIFOQueue.close", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "strategy.scope", "learner.learner_loop.create_variables"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.validate_config", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.init_learner", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.close"], ["", "def", "learner_loop", "(", "create_env_fn", ",", "create_agent_fn", ",", "create_optimizer_fn", ")", ":", "\n", "  ", "\"\"\"Main learner loop.\n\n  Args:\n    create_env_fn: Callable that must return a newly created environment. The\n      callable takes the task ID as argument - an arbitrary task ID of 0 will be\n      passed by the learner. The returned environment should follow GYM's API.\n      It is only used for infering tensor shapes. This environment will not be\n      used to generate experience.\n    create_agent_fn: Function that must create a new tf.Module with the neural\n      network that outputs actions, Q values and new agent state given the\n      environment observations and previous agent state. See\n      atari.agents.DuelingLSTMDQNNet for an example. The factory function takes\n      as input the environment output specs and the number of possible actions\n      in the env.\n    create_optimizer_fn: Function that takes the final iteration as argument\n      and must return a tf.keras.optimizers.Optimizer and a\n      tf.keras.optimizers.schedules.LearningRateSchedule.\n  \"\"\"", "\n", "logging", ".", "info", "(", "'Starting learner loop'", ")", "\n", "validate_config", "(", ")", "\n", "settings", "=", "utils", ".", "init_learner", "(", "FLAGS", ".", "num_training_tpus", ")", "\n", "strategy", ",", "inference_devices", ",", "training_strategy", ",", "encode", ",", "decode", "=", "settings", "\n", "env", "=", "create_env_fn", "(", "0", ",", "FLAGS", ")", "\n", "env_output_specs", "=", "utils", ".", "EnvOutput", "(", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "float32", ",", "'reward'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "bool", ",", "'done'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "env", ".", "observation_space", ".", "shape", ",", "env", ".", "observation_space", ".", "dtype", ",", "\n", "'observation'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "bool", ",", "'abandoned'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ",", "'episode_step'", ")", ",", "\n", ")", "\n", "action_specs", "=", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ",", "'action'", ")", "\n", "num_actions", "=", "env", ".", "action_space", ".", "n", "\n", "agent_input_specs", "=", "(", "action_specs", ",", "env_output_specs", ")", "\n", "\n", "# Initialize agent and variables.", "\n", "agent", "=", "create_agent_fn", "(", "env_output_specs", ",", "num_actions", ")", "\n", "target_agent", "=", "create_agent_fn", "(", "env_output_specs", ",", "num_actions", ")", "\n", "initial_agent_state", "=", "agent", ".", "initial_state", "(", "1", ")", "\n", "agent_state_specs", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "tf", ".", "TensorSpec", "(", "t", ".", "shape", "[", "1", ":", "]", ",", "t", ".", "dtype", ")", ",", "initial_agent_state", ")", "\n", "input_", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "s", ":", "tf", ".", "zeros", "(", "[", "1", "]", "+", "list", "(", "s", ".", "shape", ")", ",", "s", ".", "dtype", ")", ",", "agent_input_specs", ")", "\n", "input_", "=", "encode", "(", "input_", ")", "\n", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "\n", "    ", "@", "tf", ".", "function", "\n", "def", "create_variables", "(", "*", "args", ")", ":", "\n", "      ", "return", "agent", "(", "*", "decode", "(", "args", ")", ")", "\n", "\n", "", "@", "tf", ".", "function", "\n", "def", "create_target_agent_variables", "(", "*", "args", ")", ":", "\n", "      ", "return", "target_agent", "(", "*", "decode", "(", "args", ")", ")", "\n", "\n", "# The first call to Keras models to create varibales for agent and target.", "\n", "", "initial_agent_output", ",", "_", "=", "create_variables", "(", "input_", ",", "initial_agent_state", ")", "\n", "create_target_agent_variables", "(", "input_", ",", "initial_agent_state", ")", "\n", "\n", "@", "tf", ".", "function", "\n", "def", "update_target_agent", "(", ")", ":", "\n", "      ", "\"\"\"Synchronizes training and target agent variables.\"\"\"", "\n", "variables", "=", "agent", ".", "trainable_variables", "\n", "target_variables", "=", "target_agent", ".", "trainable_variables", "\n", "assert", "len", "(", "target_variables", ")", "==", "len", "(", "variables", ")", ",", "(", "\n", "'Mismatch in number of net tensors: {} != {}'", ".", "format", "(", "\n", "len", "(", "target_variables", ")", ",", "len", "(", "variables", ")", ")", ")", "\n", "for", "target_var", ",", "source_var", "in", "zip", "(", "target_variables", ",", "variables", ")", ":", "\n", "        ", "target_var", ".", "assign", "(", "source_var", ")", "\n", "\n", "# Create optimizer.", "\n", "", "", "iter_frame_ratio", "=", "(", "\n", "get_replay_insertion_batch_size", "(", ")", "*", "\n", "FLAGS", ".", "unroll_length", "*", "FLAGS", ".", "num_action_repeats", ")", "\n", "final_iteration", "=", "int", "(", "\n", "math", ".", "ceil", "(", "FLAGS", ".", "total_environment_frames", "/", "iter_frame_ratio", ")", ")", "\n", "optimizer", ",", "learning_rate_fn", "=", "create_optimizer_fn", "(", "final_iteration", ")", "\n", "\n", "\n", "iterations", "=", "optimizer", ".", "iterations", "\n", "optimizer", ".", "_create_hypers", "(", ")", "\n", "optimizer", ".", "_create_slots", "(", "agent", ".", "trainable_variables", ")", "\n", "\n", "# ON_READ causes the replicated variable to act as independent variables for", "\n", "# each replica.", "\n", "temp_grads", "=", "[", "\n", "tf", ".", "Variable", "(", "tf", ".", "zeros_like", "(", "v", ")", ",", "trainable", "=", "False", ",", "\n", "synchronization", "=", "tf", ".", "VariableSynchronization", ".", "ON_READ", ")", "\n", "for", "v", "in", "agent", ".", "trainable_variables", "\n", "]", "\n", "\n", "", "@", "tf", ".", "function", "\n", "def", "minimize", "(", "iterator", ")", ":", "\n", "    ", "\"\"\"Computes and applies gradients.\n\n    Args:\n      iterator: An iterator of distributed dataset that produces `PerReplica`.\n\n    Returns:\n      A tuple:\n        - priorities, the new priorities. Shape <float32>[batch_size].\n        - indices, the indices for updating priorities. Shape\n        <int32>[batch_size].\n        - gradient_norm_before_clip, a scalar.\n    \"\"\"", "\n", "data", "=", "next", "(", "iterator", ")", "\n", "\n", "def", "compute_gradients", "(", "args", ")", ":", "\n", "      ", "\"\"\"A function to pass to `Strategy` for gradient computation.\"\"\"", "\n", "args", "=", "decode", "(", "args", ",", "data", ")", "\n", "args", "=", "tf", ".", "nest", ".", "pack_sequence_as", "(", "SampledUnrolls", "(", "unroll_specs", ",", "0", ",", "0", ")", ",", "args", ")", "\n", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "# loss: [batch_size]", "\n", "# priorities: [batch_size]", "\n", "        ", "loss", ",", "priorities", "=", "compute_loss_and_priorities", "(", "\n", "agent", ",", "\n", "target_agent", ",", "\n", "args", ".", "unrolls", ".", "agent_state", ",", "\n", "args", ".", "unrolls", ".", "prev_actions", ",", "\n", "args", ".", "unrolls", ".", "env_outputs", ",", "\n", "args", ".", "unrolls", ".", "agent_outputs", ",", "\n", "gamma", "=", "FLAGS", ".", "discounting", ",", "\n", "burn_in", "=", "FLAGS", ".", "burn_in", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", "*", "args", ".", "importance_weights", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "agent", ".", "trainable_variables", ")", "\n", "gradient_norm_before_clip", "=", "tf", ".", "linalg", ".", "global_norm", "(", "grads", ")", "\n", "if", "FLAGS", ".", "clip_norm", ":", "\n", "        ", "grads", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "\n", "grads", ",", "FLAGS", ".", "clip_norm", ",", "use_norm", "=", "gradient_norm_before_clip", ")", "\n", "\n", "", "for", "t", ",", "g", "in", "zip", "(", "temp_grads", ",", "grads", ")", ":", "\n", "        ", "t", ".", "assign", "(", "g", ")", "\n", "\n", "", "return", "loss", ",", "priorities", ",", "args", ".", "indices", ",", "gradient_norm_before_clip", "\n", "\n", "", "loss", ",", "priorities", ",", "indices", ",", "gradient_norm_before_clip", "=", "(", "\n", "training_strategy", ".", "run", "(", "compute_gradients", ",", "(", "data", ",", ")", ")", ")", "\n", "loss", "=", "training_strategy", ".", "experimental_local_results", "(", "loss", ")", "[", "0", "]", "\n", "\n", "def", "apply_gradients", "(", "loss", ")", ":", "\n", "      ", "optimizer", ".", "apply_gradients", "(", "zip", "(", "temp_grads", ",", "agent", ".", "trainable_variables", ")", ")", "\n", "return", "loss", "\n", "\n", "\n", "", "loss", "=", "strategy", ".", "run", "(", "apply_gradients", ",", "(", "loss", ",", ")", ")", "\n", "\n", "# convert PerReplica to a Tensor", "\n", "if", "not", "isinstance", "(", "priorities", ",", "tf", ".", "Tensor", ")", ":", "\n", "\n", "      ", "priorities", "=", "tf", ".", "reshape", "(", "tf", ".", "stack", "(", "priorities", ".", "values", ")", ",", "[", "-", "1", "]", ")", "\n", "indices", "=", "tf", ".", "reshape", "(", "tf", ".", "stack", "(", "indices", ".", "values", ")", ",", "[", "-", "1", "]", ")", "\n", "gradient_norm_before_clip", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "stack", "(", "gradient_norm_before_clip", ".", "values", ")", ",", "[", "-", "1", "]", ")", "\n", "gradient_norm_before_clip", "=", "tf", ".", "reduce_max", "(", "gradient_norm_before_clip", ")", "\n", "\n", "", "return", "loss", ",", "priorities", ",", "indices", ",", "gradient_norm_before_clip", "\n", "\n", "", "agent_output_specs", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "tf", ".", "TensorSpec", "(", "t", ".", "shape", "[", "1", ":", "]", ",", "t", ".", "dtype", ")", ",", "initial_agent_output", ")", "\n", "# Logging.", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "create_file_writer", "(", "\n", "FLAGS", ".", "logdir", ",", "flush_millis", "=", "20000", ",", "max_queue", "=", "1000", ")", "\n", "\n", "# Setup checkpointing and restore checkpoint.", "\n", "\n", "ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "agent", "=", "agent", ",", "target_agent", "=", "target_agent", ",", "optimizer", "=", "optimizer", ")", "\n", "manager", "=", "tf", ".", "train", ".", "CheckpointManager", "(", "\n", "ckpt", ",", "FLAGS", ".", "logdir", ",", "max_to_keep", "=", "1", ",", "keep_checkpoint_every_n_hours", "=", "6", ")", "\n", "last_ckpt_time", "=", "0", "# Force checkpointing of the initial model.", "\n", "if", "manager", ".", "latest_checkpoint", ":", "\n", "    ", "logging", ".", "info", "(", "'Restoring checkpoint: %s'", ",", "manager", ".", "latest_checkpoint", ")", "\n", "ckpt", ".", "restore", "(", "manager", ".", "latest_checkpoint", ")", ".", "assert_consumed", "(", ")", "\n", "last_ckpt_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "server", "=", "grpc", ".", "Server", "(", "[", "FLAGS", ".", "server_address", "]", ")", "\n", "\n", "# Buffer of incomplete unrolls. Filled during inference with new transitions.", "\n", "# This only contains data from training environments.", "\n", "store", "=", "utils", ".", "UnrollStore", "(", "\n", "get_num_training_envs", "(", ")", ",", "FLAGS", ".", "unroll_length", ",", "\n", "(", "action_specs", ",", "env_output_specs", ",", "agent_output_specs", ")", ",", "\n", "num_overlapping_steps", "=", "FLAGS", ".", "burn_in", ")", "\n", "env_run_ids", "=", "utils", ".", "Aggregator", "(", "FLAGS", ".", "num_envs", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int64", ",", "'run_ids'", ")", ")", "\n", "info_specs", "=", "(", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int64", ",", "'episode_num_frames'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "float32", ",", "'episode_returns'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "float32", ",", "'episode_raw_returns'", ")", ",", "\n", ")", "\n", "env_infos", "=", "utils", ".", "Aggregator", "(", "FLAGS", ".", "num_envs", ",", "info_specs", ",", "'env_infos'", ")", "\n", "\n", "# First agent state in an unroll.", "\n", "first_agent_states", "=", "utils", ".", "Aggregator", "(", "\n", "FLAGS", ".", "num_envs", ",", "agent_state_specs", ",", "'first_agent_states'", ")", "\n", "\n", "# Current agent state and action.", "\n", "agent_states", "=", "utils", ".", "Aggregator", "(", "\n", "FLAGS", ".", "num_envs", ",", "agent_state_specs", ",", "'agent_states'", ")", "\n", "actions", "=", "utils", ".", "Aggregator", "(", "FLAGS", ".", "num_envs", ",", "action_specs", ",", "'actions'", ")", "\n", "\n", "unroll_specs", "=", "Unroll", "(", "agent_state_specs", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "float32", ",", "'priority'", ")", ",", "\n", "*", "store", ".", "unroll_specs", ")", "\n", "# Queue of complete unrolls. Filled by the inference threads, and consumed by", "\n", "# the tf.data.Dataset thread.", "\n", "unroll_queue", "=", "utils", ".", "StructuredFIFOQueue", "(", "\n", "FLAGS", ".", "unroll_queue_max_size", ",", "unroll_specs", ")", "\n", "episode_info_specs", "=", "EpisodeInfo", "(", "*", "(", "\n", "info_specs", "+", "(", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ",", "'env_ids'", ")", ",", ")", ")", ")", "\n", "info_queue", "=", "utils", ".", "StructuredFIFOQueue", "(", "-", "1", ",", "episode_info_specs", ")", "\n", "\n", "replay_buffer", "=", "utils", ".", "PrioritizedReplay", "(", "FLAGS", ".", "replay_buffer_size", ",", "\n", "unroll_specs", ",", "\n", "FLAGS", ".", "importance_sampling_exponent", ")", "\n", "\n", "def", "add_batch_size", "(", "ts", ")", ":", "\n", "    ", "return", "tf", ".", "TensorSpec", "(", "[", "FLAGS", ".", "inference_batch_size", "]", "+", "list", "(", "ts", ".", "shape", ")", ",", "\n", "ts", ".", "dtype", ",", "ts", ".", "name", ")", "\n", "", "inference_iteration", "=", "tf", ".", "Variable", "(", "-", "1", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "inference_specs", "=", "(", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ",", "'env_id'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int64", ",", "'run_id'", ")", ",", "\n", "env_output_specs", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "float32", ",", "'raw_reward'", ")", ",", "\n", ")", "\n", "inference_specs", "=", "tf", ".", "nest", ".", "map_structure", "(", "add_batch_size", ",", "inference_specs", ")", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "inference_specs", ")", "\n", "def", "inference", "(", "env_ids", ",", "run_ids", ",", "env_outputs", ",", "raw_rewards", ")", ":", "\n", "    ", "\"\"\"Agent inference.\n\n    This evaluates the agent policy on the provided environment data (reward,\n    done, observation), and store appropriate data to feed the main training\n    loop.\n\n    Args:\n      env_ids: <int32>[inference_batch_size], the environment task IDs (in range\n        [0, num_tasks)).\n      run_ids: <int64>[inference_batch_size], the environment run IDs.\n        Environment generates a random int64 run id at startup, so this can be\n        used to detect the environment jobs that restarted.\n      env_outputs: Follows env_output_specs, but with the inference_batch_size\n        added as first dimension. These are the actual environment outputs\n        (reward, done, observation).\n      raw_rewards: <float32>[inference_batch_size], representing the raw reward\n        of each step.\n\n    Returns:\n      A tensor <int32>[inference_batch_size] with one action for each\n        environment.\n    \"\"\"", "\n", "# Reset the environments that had their first run or crashed.", "\n", "previous_run_ids", "=", "env_run_ids", ".", "read", "(", "env_ids", ")", "\n", "env_run_ids", ".", "replace", "(", "env_ids", ",", "run_ids", ")", "\n", "reset_indices", "=", "tf", ".", "where", "(", "tf", ".", "not_equal", "(", "previous_run_ids", ",", "run_ids", ")", ")", "[", ":", ",", "0", "]", "\n", "envs_needing_reset", "=", "tf", ".", "gather", "(", "env_ids", ",", "reset_indices", ")", "\n", "if", "tf", ".", "not_equal", "(", "tf", ".", "shape", "(", "envs_needing_reset", ")", "[", "0", "]", ",", "0", ")", ":", "\n", "      ", "tf", ".", "print", "(", "'Environments needing reset:'", ",", "envs_needing_reset", ")", "\n", "", "env_infos", ".", "reset", "(", "envs_needing_reset", ")", "\n", "store", ".", "reset", "(", "tf", ".", "gather", "(", "\n", "envs_needing_reset", ",", "\n", "tf", ".", "where", "(", "is_training_env", "(", "envs_needing_reset", ")", ")", "[", ":", ",", "0", "]", ")", ")", "\n", "initial_agent_states", "=", "agent", ".", "initial_state", "(", "\n", "tf", ".", "shape", "(", "envs_needing_reset", ")", "[", "0", "]", ")", "\n", "first_agent_states", ".", "replace", "(", "envs_needing_reset", ",", "initial_agent_states", ")", "\n", "agent_states", ".", "replace", "(", "envs_needing_reset", ",", "initial_agent_states", ")", "\n", "actions", ".", "reset", "(", "envs_needing_reset", ")", "\n", "\n", "tf", ".", "debugging", ".", "assert_non_positive", "(", "\n", "tf", ".", "cast", "(", "env_outputs", ".", "abandoned", ",", "tf", ".", "int32", ")", ",", "\n", "'Abandoned done states are not supported in R2D2.'", ")", "\n", "\n", "# Update steps and return.", "\n", "env_infos", ".", "add", "(", "env_ids", ",", "(", "0", ",", "env_outputs", ".", "reward", ",", "raw_rewards", ")", ")", "\n", "done_ids", "=", "tf", ".", "gather", "(", "env_ids", ",", "tf", ".", "where", "(", "env_outputs", ".", "done", ")", "[", ":", ",", "0", "]", ")", "\n", "done_episodes_info", "=", "env_infos", ".", "read", "(", "done_ids", ")", "\n", "info_queue", ".", "enqueue_many", "(", "EpisodeInfo", "(", "*", "(", "done_episodes_info", "+", "(", "done_ids", ",", ")", ")", ")", ")", "\n", "env_infos", ".", "reset", "(", "done_ids", ")", "\n", "env_infos", ".", "add", "(", "env_ids", ",", "(", "FLAGS", ".", "num_action_repeats", ",", "0.", ",", "0.", ")", ")", "\n", "\n", "# Inference.", "\n", "prev_actions", "=", "actions", ".", "read", "(", "env_ids", ")", "\n", "input_", "=", "encode", "(", "(", "prev_actions", ",", "env_outputs", ")", ")", "\n", "prev_agent_states", "=", "agent_states", ".", "read", "(", "env_ids", ")", "\n", "def", "make_inference_fn", "(", "inference_device", ")", ":", "\n", "      ", "def", "device_specific_inference_fn", "(", ")", ":", "\n", "        ", "with", "tf", ".", "device", "(", "inference_device", ")", ":", "\n", "          ", "@", "tf", ".", "function", "\n", "def", "agent_inference", "(", "*", "args", ")", ":", "\n", "            ", "return", "agent", "(", "*", "decode", "(", "args", ")", ")", "\n", "\n", "", "return", "agent_inference", "(", "input_", ",", "prev_agent_states", ")", "\n", "\n", "", "", "return", "device_specific_inference_fn", "\n", "\n", "# Distribute the inference calls among the inference cores.", "\n", "", "branch_index", "=", "tf", ".", "cast", "(", "\n", "inference_iteration", ".", "assign_add", "(", "1", ")", "%", "len", "(", "inference_devices", ")", ",", "tf", ".", "int32", ")", "\n", "agent_outputs", ",", "curr_agent_states", "=", "tf", ".", "switch_case", "(", "branch_index", ",", "{", "\n", "i", ":", "make_inference_fn", "(", "inference_device", ")", "\n", "for", "i", ",", "inference_device", "in", "enumerate", "(", "inference_devices", ")", "\n", "}", ")", "\n", "\n", "agent_outputs", "=", "agent_outputs", ".", "_replace", "(", "\n", "action", "=", "apply_epsilon_greedy", "(", "\n", "agent_outputs", ".", "action", ",", "env_ids", ",", "\n", "get_num_training_envs", "(", ")", ",", "\n", "FLAGS", ".", "num_eval_envs", ",", "FLAGS", ".", "eval_epsilon", ",", "num_actions", ")", ")", "\n", "\n", "# Append the latest outputs to the unroll, only for experience coming from", "\n", "# training environments (IDs < num_training_envs), and insert completed", "\n", "# unrolls in queue.", "\n", "# <int64>[num_training_envs]", "\n", "training_indices", "=", "tf", ".", "where", "(", "is_training_env", "(", "env_ids", ")", ")", "[", ":", ",", "0", "]", "\n", "training_env_ids", "=", "tf", ".", "gather", "(", "env_ids", ",", "training_indices", ")", "\n", "training_prev_actions", ",", "training_env_outputs", ",", "training_agent_outputs", "=", "(", "\n", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "s", ":", "tf", ".", "gather", "(", "s", ",", "training_indices", ")", ",", "\n", "(", "prev_actions", ",", "env_outputs", ",", "agent_outputs", ")", ")", ")", "\n", "\n", "append_to_store", "=", "(", "\n", "training_prev_actions", ",", "training_env_outputs", ",", "training_agent_outputs", ")", "\n", "completed_ids", ",", "completed_unrolls", "=", "store", ".", "append", "(", "\n", "training_env_ids", ",", "append_to_store", ")", "\n", "_", ",", "unrolled_env_outputs", ",", "unrolled_agent_outputs", "=", "completed_unrolls", "\n", "unrolled_agent_states", "=", "first_agent_states", ".", "read", "(", "completed_ids", ")", "\n", "\n", "# Only use the suffix of the unrolls that is actually used for training. The", "\n", "# prefix is only used for burn-in of agent state at training time.", "\n", "_", ",", "agent_outputs_suffix", "=", "utils", ".", "split_structure", "(", "\n", "utils", ".", "make_time_major", "(", "unrolled_agent_outputs", ")", ",", "FLAGS", ".", "burn_in", ")", "\n", "_", ",", "env_outputs_suffix", "=", "utils", ".", "split_structure", "(", "\n", "\n", "utils", ".", "make_time_major", "(", "unrolled_env_outputs", ")", ",", "FLAGS", ".", "burn_in", ")", "\n", "_", ",", "initial_priorities", "=", "compute_loss_and_priorities_from_agent_outputs", "(", "\n", "# We don't use the outputs from a separated target network for computing", "\n", "# initial priorities.", "\n", "agent_outputs_suffix", ",", "\n", "agent_outputs_suffix", ",", "\n", "env_outputs_suffix", ",", "\n", "agent_outputs_suffix", ",", "\n", "gamma", "=", "FLAGS", ".", "discounting", ")", "\n", "\n", "unrolls", "=", "Unroll", "(", "unrolled_agent_states", ",", "initial_priorities", ",", "\n", "*", "completed_unrolls", ")", "\n", "unroll_queue", ".", "enqueue_many", "(", "unrolls", ")", "\n", "first_agent_states", ".", "replace", "(", "completed_ids", ",", "\n", "agent_states", ".", "read", "(", "completed_ids", ")", ")", "\n", "\n", "# Update current state.", "\n", "agent_states", ".", "replace", "(", "env_ids", ",", "curr_agent_states", ")", "\n", "actions", ".", "replace", "(", "env_ids", ",", "agent_outputs", ".", "action", ")", "\n", "\n", "# Return environment actions to environments.", "\n", "return", "agent_outputs", ".", "action", "\n", "\n", "", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "    ", "server", ".", "bind", "(", "inference", ")", "\n", "", "server", ".", "start", "(", ")", "\n", "\n", "# Execute learning and track performance.", "\n", "with", "summary_writer", ".", "as_default", "(", ")", ",", "concurrent", ".", "futures", ".", "ThreadPoolExecutor", "(", "max_workers", "=", "1", ")", "as", "executor", ":", "\n", "    ", "log_future", "=", "executor", ".", "submit", "(", "lambda", ":", "None", ")", "# No-op future.", "\n", "tf", ".", "summary", ".", "experimental", ".", "set_step", "(", "iterations", "*", "iter_frame_ratio", ")", "\n", "dataset", "=", "create_dataset", "(", "unroll_queue", ",", "replay_buffer", ",", "training_strategy", ",", "\n", "FLAGS", ".", "batch_size", ",", "FLAGS", ".", "priority_exponent", ",", "encode", ")", "\n", "it", "=", "iter", "(", "dataset", ")", "\n", "\n", "last_num_env_frames", "=", "iterations", "*", "iter_frame_ratio", "\n", "last_log_time", "=", "time", ".", "time", "(", ")", "\n", "max_gradient_norm_before_clip", "=", "0.", "\n", "while", "iterations", "<", "final_iteration", ":", "\n", "      ", "num_env_frames", "=", "iterations", "*", "iter_frame_ratio", "\n", "tf", ".", "summary", ".", "experimental", ".", "set_step", "(", "num_env_frames", ")", "\n", "\n", "if", "iterations", ".", "numpy", "(", ")", "%", "FLAGS", ".", "update_target_every_n_step", "==", "0", ":", "\n", "        ", "update_target_agent", "(", ")", "\n", "\n", "# Save checkpoint.", "\n", "", "current_time", "=", "time", ".", "time", "(", ")", "\n", "if", "current_time", "-", "last_ckpt_time", ">=", "FLAGS", ".", "save_checkpoint_secs", ":", "\n", "        ", "manager", ".", "save", "(", ")", "\n", "last_ckpt_time", "=", "current_time", "\n", "\n", "", "def", "log", "(", "num_env_frames", ")", ":", "\n", "        ", "\"\"\"Logs environment summaries.\"\"\"", "\n", "summary_writer", ".", "set_as_default", "(", ")", "\n", "tf", ".", "summary", ".", "experimental", ".", "set_step", "(", "num_env_frames", ")", "\n", "episode_info", "=", "info_queue", ".", "dequeue_many", "(", "info_queue", ".", "size", "(", ")", ")", "\n", "for", "n", ",", "r", ",", "_", ",", "env_id", "in", "zip", "(", "*", "episode_info", ")", ":", "\n", "          ", "is_training", "=", "is_training_env", "(", "env_id", ")", "\n", "logging", ".", "info", "(", "\n", "'Return: %f Frames: %i Env id: %i (%s) Iteration: %i'", ",", "\n", "r", ",", "n", ",", "env_id", ",", "\n", "'training'", "if", "is_training", "else", "'eval'", ",", "\n", "iterations", ".", "numpy", "(", ")", ")", "\n", "if", "not", "is_training", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "'eval/episode_return'", ",", "r", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'eval/episode_frames'", ",", "n", ")", "\n", "", "", "", "log_future", ".", "result", "(", ")", "# Raise exception if any occurred in logging.", "\n", "log_future", "=", "executor", ".", "submit", "(", "log", ",", "num_env_frames", ")", "\n", "\n", "_", ",", "priorities", ",", "indices", ",", "gradient_norm", "=", "minimize", "(", "it", ")", "\n", "\n", "replay_buffer", ".", "update_priorities", "(", "indices", ",", "priorities", ")", "\n", "# Max of gradient norms (before clipping) since last tf.summary export.", "\n", "max_gradient_norm_before_clip", "=", "max", "(", "gradient_norm", ".", "numpy", "(", ")", ",", "\n", "max_gradient_norm_before_clip", ")", "\n", "if", "current_time", "-", "last_log_time", ">=", "120", ":", "\n", "        ", "df", "=", "tf", ".", "cast", "(", "num_env_frames", "-", "last_num_env_frames", ",", "tf", ".", "float32", ")", "\n", "dt", "=", "time", ".", "time", "(", ")", "-", "last_log_time", "\n", "tf", ".", "summary", ".", "scalar", "(", "'num_environment_frames/sec (actors)'", ",", "df", "/", "dt", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'num_environment_frames/sec (learner)'", ",", "\n", "df", "/", "dt", "*", "FLAGS", ".", "replay_ratio", ")", "\n", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate_fn", "(", "iterations", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'replay_buffer_num_inserted'", ",", "\n", "replay_buffer", ".", "num_inserted", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'unroll_queue_size'", ",", "unroll_queue", ".", "size", "(", ")", ")", "\n", "\n", "last_num_env_frames", ",", "last_log_time", "=", "num_env_frames", ",", "time", ".", "time", "(", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "'updated_priorities'", ",", "priorities", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'max_gradient_norm_before_clip'", ",", "\n", "max_gradient_norm_before_clip", ")", "\n", "max_gradient_norm_before_clip", "=", "0.", "\n", "\n", "", "", "", "manager", ".", "save", "(", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "unroll_queue", ".", "close", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.vtrace.networks.MLPandLSTM.__init__": [[28, 50], ["tensorflow.Module.__init__", "tensorflow.keras.Sequential", "tensorflow.keras.layers.StackedRNNCells", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LSTMCell"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "parametric_action_distribution", ",", "mlp_sizes", ",", "lstm_sizes", ")", ":", "\n", "    ", "\"\"\"Creates an MLP followed by a stacked LSTM agent.\n\n    Args:\n      parametric_action_distribution: an object of ParametricDistribution class\n        specifing a parametric distribution over actions to be used\n      mlp_sizes: list of integers with sizes of hidden MLP layers\n      lstm_sizes: list of integers with sizes of LSTM layers\n    \"\"\"", "\n", "super", "(", "MLPandLSTM", ",", "self", ")", ".", "__init__", "(", "name", "=", "'MLPandLSTM'", ")", "\n", "self", ".", "_parametric_action_distribution", "=", "parametric_action_distribution", "\n", "\n", "# MLP", "\n", "mlp_layers", "=", "[", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "size", ",", "'relu'", ")", "for", "size", "in", "mlp_sizes", "]", "\n", "self", ".", "_mlp", "=", "tf", ".", "keras", ".", "Sequential", "(", "mlp_layers", ")", "\n", "# stacked LSTM", "\n", "lstm_cells", "=", "[", "tf", ".", "keras", ".", "layers", ".", "LSTMCell", "(", "size", ")", "for", "size", "in", "lstm_sizes", "]", "\n", "self", ".", "_core", "=", "tf", ".", "keras", ".", "layers", ".", "StackedRNNCells", "(", "lstm_cells", ")", "\n", "# Layers for _head.", "\n", "self", ".", "_policy_logits", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "parametric_action_distribution", ".", "param_size", ",", "name", "=", "'policy_logits'", ")", "\n", "self", ".", "_baseline", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "1", ",", "name", "=", "'baseline'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.vtrace.networks.MLPandLSTM.initial_state": [[51, 54], ["networks.MLPandLSTM._core.get_initial_state"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "initial_state", "(", "self", ",", "batch_size", ")", ":", "\n", "    ", "return", "self", ".", "_core", ".", "get_initial_state", "(", "batch_size", "=", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.vtrace.networks.MLPandLSTM._head": [[55, 63], ["networks.MLPandLSTM._policy_logits", "tensorflow.squeeze", "networks.MLPandLSTM._parametric_action_distribution.sample", "AgentOutput", "networks.MLPandLSTM._baseline"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], ["", "def", "_head", "(", "self", ",", "core_output", ")", ":", "\n", "    ", "policy_logits", "=", "self", ".", "_policy_logits", "(", "core_output", ")", "\n", "baseline", "=", "tf", ".", "squeeze", "(", "self", ".", "_baseline", "(", "core_output", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Sample an action from the policy.", "\n", "action", "=", "self", ".", "_parametric_action_distribution", ".", "sample", "(", "policy_logits", ")", "\n", "\n", "return", "AgentOutput", "(", "action", ",", "policy_logits", ",", "baseline", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.vtrace.networks.MLPandLSTM.get_action": [[69, 72], ["networks.MLPandLSTM.__call__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.__call__"], ["", "@", "tf", ".", "function", "\n", "def", "get_action", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "self", ".", "__call__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.vtrace.networks.MLPandLSTM.__call__": [[73, 102], ["networks.MLPandLSTM._unroll", "tensorflow.nest.map_structure", "tensorflow.nest.map_structure", "tensorflow.expand_dims", "tensorflow.squeeze"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep._unroll"], ["", "def", "__call__", "(", "self", ",", "prev_actions", ",", "env_outputs", ",", "core_state", ",", "unroll", "=", "False", ",", "\n", "is_training", "=", "False", ")", ":", "\n", "    ", "\"\"\"Runs the agent.\n\n    Args:\n      prev_actions: Previous action. Not used by this agent.\n      env_outputs: Structure with reward, done and observation fields. Only\n        observation field is used by this agent. It should have the shape\n        [time, batch_size, observation_size].\n      core_state: Agent state.\n      unroll: Should be True if inputs contain the time dimension and False\n        otherwise.\n      is_training: Whether we are in the loss computation. Not used by this\n        agent.\n    Returns:\n      A structure with action, policy_logits and baseline.\n    \"\"\"", "\n", "if", "not", "unroll", ":", "\n", "# Add time dimension.", "\n", "      ", "prev_actions", ",", "env_outputs", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "tf", ".", "expand_dims", "(", "t", ",", "0", ")", ",", "(", "prev_actions", ",", "env_outputs", ")", ")", "\n", "\n", "", "outputs", ",", "core_state", "=", "self", ".", "_unroll", "(", "prev_actions", ",", "env_outputs", ",", "core_state", ")", "\n", "\n", "if", "not", "unroll", ":", "\n", "# Remove time dimension.", "\n", "      ", "outputs", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "tf", ".", "squeeze", "(", "t", ",", "0", ")", ",", "outputs", ")", "\n", "\n", "", "return", "outputs", ",", "core_state", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.vtrace.networks.MLPandLSTM._unroll": [[103, 122], ["networks.MLPandLSTM._mlp", "networks.MLPandLSTM._core.get_initial_state", "zip", "tensorflow.stack", "tensorflow.unstack", "tensorflow.unstack", "tensorflow.nest.map_structure", "networks.MLPandLSTM._core", "core_output_list.append", "seed_rl.common.utils.batch_apply", "tensorflow.shape", "tensorflow.where", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.batch_apply"], ["", "def", "_unroll", "(", "self", ",", "unused_prev_actions", ",", "env_outputs", ",", "core_state", ")", ":", "\n", "    ", "unused_reward", ",", "done", ",", "observation", ",", "_", ",", "_", "=", "env_outputs", "\n", "observation", "=", "self", ".", "_mlp", "(", "observation", ")", "\n", "\n", "initial_core_state", "=", "self", ".", "_core", ".", "get_initial_state", "(", "\n", "batch_size", "=", "tf", ".", "shape", "(", "observation", ")", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "core_output_list", "=", "[", "]", "\n", "for", "input_", ",", "d", "in", "zip", "(", "tf", ".", "unstack", "(", "observation", ")", ",", "tf", ".", "unstack", "(", "done", ")", ")", ":", "\n", "# If the episode ended, the core state should be reset before the next.", "\n", "      ", "core_state", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "x", ",", "y", ",", "d", "=", "d", ":", "tf", ".", "where", "(", "\n", "tf", ".", "reshape", "(", "d", ",", "[", "d", ".", "shape", "[", "0", "]", "]", "+", "[", "1", "]", "*", "(", "x", ".", "shape", ".", "rank", "-", "1", ")", ")", ",", "x", ",", "y", ")", ",", "\n", "initial_core_state", ",", "\n", "core_state", ")", "\n", "core_output", ",", "core_state", "=", "self", ".", "_core", "(", "input_", ",", "core_state", ")", "\n", "core_output_list", ".", "append", "(", "core_output", ")", "\n", "", "outputs", "=", "tf", ".", "stack", "(", "core_output_list", ")", "\n", "\n", "return", "utils", ".", "batch_apply", "(", "self", ".", "_head", ",", "(", "outputs", ",", ")", ")", ",", "core_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.vtrace.learner.compute_loss": [[73, 160], ["agent", "tensorflow.nest.map_structure", "tensorflow.nest.map_structure", "tensorflow.nest.map_structure", "parametric_action_distribution.log_prob", "parametric_action_distribution.log_prob", "seed_rl.common.vtrace.from_importance_weights", "tensorflow.reduce_mean", "logger.log_session", "logger.log", "logger.log", "logger.log", "logger.log", "logger.log", "logger.log", "logger.log", "parametric_action_distribution.create_dist", "hasattr", "logger.log", "logger.log", "logger.log", "logger.log", "tensorflow.clip_by_value", "tensorflow.cast", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "parametric_action_distribution.entropy", "tensorflow.stop_gradient", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.sqrt", "logger.log", "tensorflow.reduce_max", "agent.entropy_cost", "tensorflow.reduce_mean", "tensorflow.square", "agent.entropy_cost", "agent.entropy_cost", "tensorflow.stop_gradient", "agent.entropy_cost", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.abs", "tensorflow.stop_gradient", "tensorflow.square", "tensorflow.reduce_mean"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.google-research_seed_rl.common.vtrace.from_importance_weights", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log_session", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.create_dist", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.entropy", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log"], ["'time steps on which we update each stored RNN state '", "\n", "'before computing the actual loss. The effective length '", "\n", "'of unrolls will be burn_in + unroll_length, and two '", "\n", "'consecutive unrolls will overlap on burn_in steps.'", ")", "\n", "flags", ".", "DEFINE_float", "(", "'importance_sampling_exponent'", ",", "0.6", ",", "\n", "'Exponent used when computing the importance sampling '", "\n", "'correction. 0 means no importance sampling correction. '", "\n", "'1 means full importance sampling correction.'", ")", "\n", "flags", ".", "DEFINE_float", "(", "'clip_norm'", ",", "40", ",", "'We clip gradient norm to this value.'", ")", "\n", "flags", ".", "DEFINE_float", "(", "'value_function_rescaling_epsilon'", ",", "1e-3", ",", "\n", "'Epsilon used for value function rescaling.'", ")", "\n", "flags", ".", "DEFINE_integer", "(", "'n_steps'", ",", "5", ",", "\n", "'n-step returns: how far ahead we look for computing the '", "\n", "'Bellman targets.'", ")", "\n", "flags", ".", "DEFINE_float", "(", "'discounting'", ",", ".997", ",", "'Discounting factor.'", ")", "\n", "\n", "# Eval settings", "\n", "flags", ".", "DEFINE_float", "(", "'eval_epsilon'", ",", "1e-3", ",", "\n", "'Epsilon (as in epsilon-greedy) used for evaluation.'", ")", "\n", "\n", "FLAGS", "=", "flags", ".", "FLAGS", "\n", "\n", "Unroll", "=", "collections", ".", "namedtuple", "(", "\n", "'Unroll'", ",", "'agent_state priority prev_actions env_outputs agent_outputs'", ")", "\n", "\n", "# Unrolls sampled from the replay buffer. Contains the corresponding indices in", "\n", "# the replay buffer and importance weights.", "\n", "SampledUnrolls", "=", "collections", ".", "namedtuple", "(", "\n", "'SampledUnrolls'", ",", "'unrolls indices importance_weights'", ")", "\n", "\n", "# Information about a finished episode.", "\n", "EpisodeInfo", "=", "collections", ".", "namedtuple", "(", "\n", "'EpisodeInfo'", ",", "\n", "# num_frames: length of the episode in number of frames.", "\n", "# returns: Sum of undiscounted rewards experienced in the episode.", "\n", "# raw_returns: Sum of raw rewards experienced in the episode.", "\n", "# env_ids: ID of the environment that generated this episode.", "\n", "'num_frames returns raw_returns env_ids'", ")", "\n", "\n", "\n", "def", "get_replay_insertion_batch_size", "(", "per_replica", "=", "False", ")", ":", "\n", "  ", "if", "per_replica", ":", "\n", "    ", "return", "int", "(", "FLAGS", ".", "batch_size", "/", "FLAGS", ".", "replay_ratio", "/", "FLAGS", ".", "num_training_tpus", ")", "\n", "", "else", ":", "\n", "    ", "return", "int", "(", "FLAGS", ".", "batch_size", "/", "FLAGS", ".", "replay_ratio", ")", "\n", "\n", "\n", "", "", "def", "get_num_training_envs", "(", ")", ":", "\n", "  ", "return", "FLAGS", ".", "num_envs", "-", "FLAGS", ".", "num_eval_envs", "\n", "\n", "\n", "", "def", "is_training_env", "(", "env_id", ")", ":", "\n", "  ", "\"\"\"Training environment IDs are in range [0, num_training_envs).\"\"\"", "\n", "return", "env_id", "<", "get_num_training_envs", "(", ")", "\n", "\n", "\n", "", "def", "get_envs_epsilon", "(", "env_ids", ",", "num_training_envs", ",", "num_eval_envs", ",", "eval_epsilon", ")", ":", "\n", "  ", "\"\"\"Per-environment epsilon as in Apex and R2D2.\n\n  Args:\n    env_ids: <int32>[inference_batch_size], the environment task IDs (in range\n      [0, num_training_envs+num_eval_envs)).\n    num_training_envs: Number of training environments. Training environments\n      should have IDs in [0, num_training_envs).\n    num_eval_envs: Number of evaluation environments. Eval environments should\n      have IDs in [num_training_envs, num_training_envs + num_eval_envs).\n    eval_epsilon: Epsilon used for eval environments.\n\n  Returns:\n    A 1D float32 tensor with one epsilon for each input environment ID.\n  \"\"\"", "\n", "# <float32>[num_training_envs + num_eval_envs]", "\n", "epsilons", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "math", ".", "pow", "(", "0.4", ",", "tf", ".", "linspace", "(", "1.", ",", "8.", ",", "num", "=", "num_training_envs", ")", ")", ",", "\n", "tf", ".", "constant", "(", "[", "eval_epsilon", "]", "*", "num_eval_envs", ")", "]", ",", "\n", "axis", "=", "0", ")", "\n", "return", "tf", ".", "gather", "(", "epsilons", ",", "env_ids", ")", "\n", "\n", "\n", "", "def", "apply_epsilon_greedy", "(", "actions", ",", "env_ids", ",", "num_training_envs", ",", "\n", "num_eval_envs", ",", "eval_epsilon", ",", "num_actions", ")", ":", "\n", "  "]], "home.repos.pwc.inspect_result.google-research_seed_rl.vtrace.learner.validate_config": [[166, 168], ["seed_rl.common.utils.validate_learner_config"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.validate_learner_config"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.vtrace.learner.learner_loop": [[170, 484], ["absl.logging.info", "learner.validate_config", "seed_rl.common.utils.init_learner_multi_host", "create_env_fn", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "seed_rl.common.utils.EnvOutput", "tensorflow.TensorSpec", "create_agent_fn", "create_agent_fn.initial_state", "tensorflow.nest.map_structure", "tensorflow.nest.map_structure", "encode", "tensorflow.nest.map_structure", "tensorflow.train.Checkpoint", "tensorflow.train.CheckpointManager", "tensorflow.summary.create_file_writer", "seed_rl.common.utils.ProgressLogger", "seed_rl.common.utils.StructuredFIFOQueue", "enumerate", "training_strategy.experimental_distribute_datasets_from_function", "iter", "utils.ProgressLogger.start", "utils.ProgressLogger.shutdown", "tf.train.CheckpointManager.save", "tensorflow.saved_model.save", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "strategy.scope", "learner.learner_loop.create_variables"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.validate_config", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.init_learner_multi_host", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], ["\n", "batch_size", "=", "tf", ".", "shape", "(", "actions", ")", "[", "0", "]", "\n", "epsilons", "=", "get_envs_epsilon", "(", "env_ids", ",", "num_training_envs", ",", "num_eval_envs", ",", "\n", "eval_epsilon", ")", "\n", "random_actions", "=", "tf", ".", "random", ".", "uniform", "(", "[", "batch_size", "]", ",", "maxval", "=", "num_actions", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", "\n", "probs", "=", "tf", ".", "random", ".", "uniform", "(", "shape", "=", "[", "batch_size", "]", ")", "\n", "return", "tf", ".", "where", "(", "tf", ".", "math", ".", "less", "(", "probs", ",", "epsilons", ")", ",", "random_actions", ",", "actions", ")", "\n", "\n", "\n", "", "def", "value_function_rescaling", "(", "x", ")", ":", "\n", "  ", "\"\"\"Value function rescaling per R2D2 paper, table 2.\"\"\"", "\n", "eps", "=", "FLAGS", ".", "value_function_rescaling_epsilon", "\n", "return", "tf", ".", "math", ".", "sign", "(", "x", ")", "*", "(", "tf", ".", "math", ".", "sqrt", "(", "tf", ".", "math", ".", "abs", "(", "x", ")", "+", "1.", ")", "-", "1.", ")", "+", "eps", "*", "x", "\n", "\n", "\n", "", "def", "inverse_value_function_rescaling", "(", "x", ")", ":", "\n", "  ", "\"\"\"See Proposition A.2 in paper \"Observe and Look Further\".\"\"\"", "\n", "eps", "=", "FLAGS", ".", "value_function_rescaling_epsilon", "\n", "return", "tf", ".", "math", ".", "sign", "(", "x", ")", "*", "(", "\n", "tf", ".", "math", ".", "square", "(", "(", "(", "tf", ".", "math", ".", "sqrt", "(", "\n", "1.", "+", "4.", "*", "eps", "*", "(", "tf", ".", "math", ".", "abs", "(", "x", ")", "+", "1.", "+", "eps", ")", ")", ")", "-", "1.", ")", "/", "(", "2.", "*", "eps", ")", ")", "-", "\n", "1.", ")", "\n", "\n", "\n", "", "def", "n_step_bellman_target", "(", "rewards", ",", "done", ",", "q_target", ",", "gamma", ",", "n_steps", ")", ":", "\n", "  ", "r\"\"\"Computes n-step Bellman targets.\n\n  See section 2.3 of R2D2 paper (which does not mention the logic around end of\n  episode).\n\n  Args:\n    rewards: <float32>[time, batch_size] tensor. This is r_t in the equations\n      below.\n    done: <bool>[time, batch_size] tensor. This is done_t in the equations\n      below. done_t should be true if the episode is done just after\n      experimenting reward r_t.\n    q_target: <float32>[time, batch_size] tensor. This is Q_target(s_{t+1}, a*)\n      (where a* is an action chosen by the caller).\n    gamma: Exponential RL discounting.\n    n_steps: The number of steps to look ahead for computing the Bellman\n      targets.\n\n  Returns:\n    y_t targets as <float32>[time, batch_size] tensor.\n    When n_steps=1, this is just:\n\n    $$r_t + gamma * (1 - done_t) * Q_{target}(s_{t+1}, a^*)$$\n\n    In the general case, this is:\n\n    $$(\\sum_{i=0}^{n-1} \\gamma ^ {i} * notdone_{t, i-1} * r_{t + i}) +\n      \\gamma ^ n * notdone_{t, n-1} * Q_{target}(s_{t + n}, a^*) $$\n\n    where notdone_{t,i} is defined as:\n\n    $$notdone_{t,i} = \\prod_{k=0}^{k=i}(1 - done_{t+k})$$\n\n    The last n_step-1 targets cannot be computed with n_step returns, since we\n    run out of Q_{target}(s_{t+n}). Instead, they will use n_steps-1, .., 1 step\n    returns. For those last targets, the last Q_{target}(s_{t}, a^*) is re-used\n    multiple times.\n  \"\"\"", "\n", "# We append n_steps - 1 times the last q_target. They are divided by gamma **", "\n", "# k to correct for the fact that they are at a 'fake' indice, and will", "\n", "# therefore end up being multiplied back by gamma ** k in the loop below.", "\n", "# We prepend 0s that will be discarded at the first iteration below.", "\n", "bellman_target", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "zeros_like", "(", "q_target", "[", "0", ":", "1", "]", ")", ",", "q_target", "]", "+", "\n", "[", "q_target", "[", "-", "1", ":", "]", "/", "gamma", "**", "k", "\n", "for", "k", "in", "range", "(", "1", ",", "n_steps", ")", "]", ",", "\n", "axis", "=", "0", ")", "\n", "# Pad with n_steps 0s. They will be used to compute the last n_steps-1", "\n", "# targets (having 0 values is important).", "\n", "done", "=", "tf", ".", "concat", "(", "[", "done", "]", "+", "[", "tf", ".", "zeros_like", "(", "done", "[", "0", ":", "1", "]", ")", "]", "*", "n_steps", ",", "axis", "=", "0", ")", "\n", "rewards", "=", "tf", ".", "concat", "(", "[", "rewards", "]", "+", "[", "tf", ".", "zeros_like", "(", "rewards", "[", "0", ":", "1", "]", ")", "]", "*", "n_steps", ",", "\n", "axis", "=", "0", ")", "\n", "# Iteratively build the n_steps targets. After the i-th iteration (1-based),", "\n", "# bellman_target is effectively the i-step returns.", "\n", "for", "_", "in", "range", "(", "n_steps", ")", ":", "\n", "    ", "rewards", "=", "rewards", "[", ":", "-", "1", "]", "\n", "done", "=", "done", "[", ":", "-", "1", "]", "\n", "bellman_target", "=", "(", "\n", "rewards", "+", "gamma", "*", "(", "1.", "-", "tf", ".", "cast", "(", "done", ",", "tf", ".", "float32", ")", ")", "*", "bellman_target", "[", "1", ":", "]", ")", "\n", "\n", "", "return", "bellman_target", "\n", "\n", "\n", "", "def", "compute_loss_and_priorities_from_agent_outputs", "(", "\n", "training_agent_output", ",", "\n", "target_agent_output", ",", "\n", "env_outputs", ",", "\n", "agent_outputs", ",", "\n", "gamma", ",", "eta", "=", "0.9", ")", ":", "\n", "  ", "\"\"\"Computes the loss to optimize and the new priorities.\n\n  This implements the n-step double DQN loss with the Q function computed on\n  sequences of transitions.\n\n  Args:\n    training_agent_output: AgentOutput where tensors have [unroll_length,\n      batch_size] front dimensions. Used for the Q values that should be\n      learned, and for computing the max over next actions as part of\n      double-DQN.\n    target_agent_output: AgentOutput used to compute the double-DQN target.\n    env_outputs: EnvOutputs where tensors have [unroll_length, batch_size]\n      additional front dimensions.\n    agent_outputs: AgentOutputs where tensors have [unroll_length, batch_size]\n      additional front dimensions.\n    gamma: RL discounting factor.\n    eta: float, parameter for balancing mean and max TD errors over a sequence\n      of transitions for computing its new priority.\n\n  Returns:\n    A pair:\n      - The loss for each unroll. Shape <float32>[batch_size]\n      - The new priorities for each unroll. Shape <float32>[batch_size].\n  \"\"\"", "\n", "num_actions", "=", "tf", ".", "shape", "(", "training_agent_output", ".", "q_values", ")", "[", "2", "]", "\n", "# <float32>[time, batch_size, num_actions].", "\n", "replay_action_one_hot", "=", "tf", ".", "one_hot", "(", "agent_outputs", ".", "action", ",", "num_actions", ",", "1.", ",", "0.", ")", "\n", "# This is Q(s, a), where a is the action played (can come from the agent or be", "\n", "# random). This is what we learn.", "\n", "# <float32>[time, batch_size].", "\n", "replay_q", "=", "tf", ".", "reduce_sum", "(", "\n", "training_agent_output", ".", "q_values", "*", "replay_action_one_hot", ",", "axis", "=", "2", ")", "\n", "\n", "# [time, batch_size, num_actions]", "\n", "best_actions_one_hot", "=", "tf", ".", "one_hot", "(", "\n", "training_agent_output", ".", "action", ",", "num_actions", ",", "1.", ",", "0.", ")", "\n", "# This is Q'(s) = h^(-1)(Q_target(s, \\argmax_a Q(s, a)))", "\n", "# [time, batch_size]", "\n", "qtarget_max", "=", "inverse_value_function_rescaling", "(", "tf", ".", "reduce_sum", "(", "\n", "target_agent_output", ".", "q_values", "*", "best_actions_one_hot", ",", "\n", "axis", "=", "2", ")", ")", "\n", "\n", "# [time, batch_size]", "\n", "bellman_target", "=", "tf", ".", "stop_gradient", "(", "n_step_bellman_target", "(", "\n", "env_outputs", ".", "reward", ",", "\n", "env_outputs", ".", "done", ",", "\n", "qtarget_max", ",", "\n", "gamma", ",", "\n", "FLAGS", ".", "n_steps", ")", ")", "\n", "\n", "# replay_q is actually Q(s_{t+1}, a_{t+1}), so we need to shift the targets.", "\n", "bellman_target", "=", "bellman_target", "[", "1", ":", ",", "...", "]", "\n", "\n", "replay_q", "=", "replay_q", "[", ":", "-", "1", ",", "...", "]", "\n", "\n", "bellman_target", "=", "value_function_rescaling", "(", "bellman_target", ")", "\n", "# [time, batch_size]", "\n", "abs_td_errors", "=", "tf", ".", "abs", "(", "bellman_target", "-", "replay_q", ")", "\n", "\n", "# [batch_size]", "\n", "priorities", "=", "(", "eta", "*", "tf", ".", "reduce_max", "(", "abs_td_errors", ",", "axis", "=", "0", ")", "+", "\n", "(", "1", "-", "eta", ")", "*", "tf", ".", "reduce_mean", "(", "abs_td_errors", ",", "axis", "=", "0", ")", ")", "\n", "\n", "# Sums over time dimension.", "\n", "loss", "=", "0.5", "*", "tf", ".", "reduce_sum", "(", "tf", ".", "math", ".", "square", "(", "abs_td_errors", ")", ",", "axis", "=", "0", ")", "\n", "\n", "return", "loss", ",", "priorities", "\n", "\n", "\n", "", "def", "compute_loss_and_priorities", "(", "\n", "training_agent", ",", "target_agent", ",", "\n", "agent_state", ",", "prev_actions", ",", "env_outputs", ",", "agent_outputs", ",", "\n", "gamma", ",", "burn_in", ")", ":", "\n", "  ", "\"\"\"Computes the loss to optimize and the new priorities.\n\n  This implements the n-step double DQN loss with the Q function computed on\n  sequences of transitions.\n\n  Args:\n    training_agent: Keras Model representing the training agent's network.\n    target_agent: Keras Model representing the target agent's network.\n    agent_state: Batched agent recurrent state at the beginning of each unroll.\n    prev_actions: <int32>[unroll_length, batch_size]. This is the action played\n      in the environment before each corresponding \"env_outputs\" (i.e. after\n      epsilon-greedy policy is applied).\n    env_outputs: EnvOutputs where tensors have [unroll_length, batch_size]\n      additional front dimensions.\n    agent_outputs: AgentOutputs where tensors have [unroll_length, batch_size]\n      additional front dimensions.\n    gamma: RL discounting factor.\n    burn_in: Number of time steps on which we update each recurrent state\n      without computing the loss nor propagating gradients.\n\n  Returns:\n    A pair:\n      - The loss for each unroll. Shape <float32>[batch_size]\n      - The new priorities for each unroll. Shape <float32>[batch_size].\n  \"\"\"", "\n", "if", "burn_in", ":", "\n", "    ", "agent_input_prefix", ",", "agent_input_suffix", "=", "utils", ".", "split_structure", "(", "\n", "(", "prev_actions", ",", "env_outputs", ")", ",", "burn_in", ")", "\n", "_", ",", "agent_outputs_suffix", "=", "utils", ".", "split_structure", "(", "agent_outputs", ",", "burn_in", ")", "\n", "_", ",", "training_state", "=", "training_agent", "(", "\n", "agent_input_prefix", ",", "agent_state", ",", "unroll", "=", "True", ")", "\n", "training_state", "=", "tf", ".", "nest", ".", "map_structure", "(", "tf", ".", "stop_gradient", ",", "training_state", ")", "\n", "_", ",", "target_state", "=", "target_agent", "(", "agent_input_prefix", ",", "agent_state", ",", "unroll", "=", "True", ")", "\n", "", "else", ":", "\n", "    ", "agent_input_suffix", "=", "(", "prev_actions", ",", "env_outputs", ")", "\n", "agent_outputs_suffix", "=", "agent_outputs", "\n", "training_state", "=", "agent_state", "\n", "target_state", "=", "agent_state", "\n", "\n", "# Agent outputs have fields with shape [time, batch_size, <field_shape>].", "\n", "", "training_agent_output", ",", "_", "=", "training_agent", "(", "\n", "agent_input_suffix", ",", "training_state", ",", "unroll", "=", "True", ")", "\n", "target_agent_output", ",", "_", "=", "target_agent", "(", "\n", "agent_input_suffix", ",", "target_state", ",", "unroll", "=", "True", ")", "\n", "_", ",", "env_outputs_suffix", "=", "agent_input_suffix", "\n", "return", "compute_loss_and_priorities_from_agent_outputs", "(", "\n", "training_agent_output", ",", "target_agent_output", ",", "env_outputs_suffix", ",", "\n", "agent_outputs_suffix", ",", "gamma", ")", "\n", "\n", "\n", "", "def", "create_dataset", "(", "unroll_queue", ",", "replay_buffer", ",", "strategy", ",", "batch_size", ",", "\n", "priority_exponent", ",", "encode", ")", ":", "\n", "  ", "\"\"\"Creates a dataset sampling from replay buffer.\n\n  This dataset will consume a batch of unrolls from 'unroll_queue', add it to\n  the replay buffer, and sample a batch of unrolls from it.\n\n  Args:\n    unroll_queue: Queue of 'Unroll' elements.\n    replay_buffer: Replay buffer of 'Unroll' elements.\n    strategy: A `distribute_lib.Strategy`.\n    batch_size: Batch size used for consuming the unroll queue and sampling from\n      the replay buffer.\n    priority_exponent: Priority exponent used for sampling from the replay\n      buffer.\n    encode: Function to encode the data for TPU, etc.\n\n  Returns:\n    A \"distributed `Dataset`\", which acts like a `tf.data.Dataset` except it\n    produces \"PerReplica\" values. Each iteration of the dataset produces\n    flattened `SampledUnrolls` structures where per-timestep tensors have front\n    dimensions [unroll_length, batch_size_per_replica].\n  \"\"\"", "\n", "\n", "@", "tf", ".", "function", "\n", "def", "dequeue", "(", "ctx", ")", ":", "\n", "    ", "\"\"\"Inserts into and samples from the replay buffer.\n\n    Args:\n      ctx: tf.distribute.InputContext.\n\n    Returns:\n      A flattened `SampledUnrolls` structures where per-timestep tensors have\n      front dimensions [unroll_length, batch_size_per_replica].\n    \"\"\"", "\n", "per_replica_batch_size", "=", "ctx", ".", "get_per_replica_batch_size", "(", "batch_size", ")", "\n", "insertion_batch_size", "=", "get_replay_insertion_batch_size", "(", "per_replica", "=", "True", ")", "\n", "\n", "print_every", "=", "tf", ".", "cast", "(", "\n", "insertion_batch_size", "*", "\n", "(", "1", "+", "FLAGS", ".", "replay_buffer_min_size", "//", "50", "//", "insertion_batch_size", ")", ",", "\n", "tf", ".", "int64", ")", "\n", "log_summary_every", "=", "tf", ".", "cast", "(", "insertion_batch_size", "*", "500", ",", "tf", ".", "int64", ")", "\n", "\n", "while", "tf", ".", "constant", "(", "True", ")", ":", "\n", "# Each tensor in 'unrolls' has shape [insertion_batch_size, unroll_length,", "\n", "# <field-specific dimensions>].", "\n", "      ", "unrolls", "=", "unroll_queue", ".", "dequeue_many", "(", "insertion_batch_size", ")", "\n", "# The replay buffer is not threadsafe (and making it thread-safe might", "\n", "# slow it down), which is why we insert and sample in a single thread, and", "\n", "# use TF Queues for passing data between threads.", "\n", "replay_buffer", ".", "insert", "(", "unrolls", ",", "unrolls", ".", "priority", ")", "\n", "if", "tf", ".", "equal", "(", "replay_buffer", ".", "num_inserted", "%", "log_summary_every", ",", "0", ")", ":", "\n", "# Unfortunately, there is no tf.summary(log_every_n_sec).", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "'initial_priorities'", ",", "unrolls", ".", "priority", ")", "\n", "", "if", "replay_buffer", ".", "num_inserted", ">=", "FLAGS", ".", "replay_buffer_min_size", ":", "\n", "        ", "break", "\n", "\n", "", "if", "tf", ".", "equal", "(", "replay_buffer", ".", "num_inserted", "%", "print_every", ",", "0", ")", ":", "\n", "        ", "tf", ".", "print", "(", "'Waiting for the replay buffer to fill up. '", "\n", "'It currently has'", ",", "replay_buffer", ".", "num_inserted", ",", "\n", "'elements, waiting for at least'", ",", "FLAGS", ".", "replay_buffer_min_size", ",", "\n", "'elements'", ")", "\n", "\n", "", "", "sampled_indices", ",", "weights", ",", "sampled_unrolls", "=", "replay_buffer", ".", "sample", "(", "\n", "per_replica_batch_size", ",", "priority_exponent", ")", "\n", "sampled_unrolls", "=", "sampled_unrolls", ".", "_replace", "(", "\n", "prev_actions", "=", "utils", ".", "make_time_major", "(", "sampled_unrolls", ".", "prev_actions", ")", ",", "\n", "env_outputs", "=", "utils", ".", "make_time_major", "(", "sampled_unrolls", ".", "env_outputs", ")", ",", "\n", "agent_outputs", "=", "utils", ".", "make_time_major", "(", "sampled_unrolls", ".", "agent_outputs", ")", ")", "\n", "sampled_unrolls", "=", "sampled_unrolls", ".", "_replace", "(", "\n", "env_outputs", "=", "encode", "(", "sampled_unrolls", ".", "env_outputs", ")", ")", "\n", "# tf.data.Dataset treats list leafs as tensors, so we need to flatten and", "\n", "# repack.", "\n", "return", "tf", ".", "nest", ".", "flatten", "(", "SampledUnrolls", "(", "\n", "sampled_unrolls", ",", "sampled_indices", ",", "weights", ")", ")", "\n", "\n", "", "def", "dataset_fn", "(", "ctx", ")", ":", "\n", "    ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensors", "(", "0", ")", ".", "repeat", "(", "None", ")", "\n", "return", "dataset", ".", "map", "(", "lambda", "_", ":", "dequeue", "(", "ctx", ")", ")", "\n", "\n", "", "return", "strategy", ".", "experimental_distribute_datasets_from_function", "(", "dataset_fn", ")", "\n", "\n", "\n", "", "def", "validate_config", "(", ")", ":", "\n", "  ", "utils", ".", "validate_learner_config", "(", "FLAGS", ")", "\n", "assert", "FLAGS", ".", "n_steps", ">=", "1", ",", "'--n_steps < 1 does not make sense.'", "\n", "assert", "FLAGS", ".", "num_envs", ">", "FLAGS", ".", "num_eval_envs", ",", "(", "\n", "'Total number of environments ({}) should be greater than number of '", "\n", "'environments reserved to eval ({})'", ".", "format", "(", "\n", "FLAGS", ".", "num_envs", ",", "FLAGS", ".", "num_eval_envs", ")", ")", "\n", "\n", "\n", "", "def", "learner_loop", "(", "create_env_fn", ",", "create_agent_fn", ",", "create_optimizer_fn", ")", ":", "\n", "  "]], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticMLP.__init__": [[35, 65], ["tensorflow.Module.__init__", "networks.create_mlp", "networks.create_mlp", "networks.create_mlp", "range"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__", "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.create_mlp", "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.create_mlp", "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.create_mlp"], ["\n", "super", "(", "MLPandLSTM", ",", "self", ")", ".", "__init__", "(", "name", "=", "'MLPandLSTM'", ")", "\n", "self", ".", "_parametric_action_distribution", "=", "parametric_action_distribution", "\n", "\n", "# MLP", "\n", "mlp_layers", "=", "[", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "size", ",", "'relu'", ")", "for", "size", "in", "mlp_sizes", "]", "\n", "self", ".", "_mlp", "=", "tf", ".", "keras", ".", "Sequential", "(", "mlp_layers", ")", "\n", "# stacked LSTM", "\n", "lstm_cells", "=", "[", "tf", ".", "keras", ".", "layers", ".", "LSTMCell", "(", "size", ")", "for", "size", "in", "lstm_sizes", "]", "\n", "self", ".", "_core", "=", "tf", ".", "keras", ".", "layers", ".", "StackedRNNCells", "(", "lstm_cells", ")", "\n", "# Layers for _head.", "\n", "self", ".", "_policy_logits", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "parametric_action_distribution", ".", "param_size", ",", "name", "=", "'policy_logits'", ")", "\n", "self", ".", "_baseline", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "1", ",", "name", "=", "'baseline'", ")", "\n", "\n", "", "@", "tf", ".", "function", "\n", "def", "initial_state", "(", "self", ",", "batch_size", ")", ":", "\n", "    ", "return", "self", ".", "_core", ".", "get_initial_state", "(", "batch_size", "=", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "def", "_head", "(", "self", ",", "core_output", ")", ":", "\n", "    ", "policy_logits", "=", "self", ".", "_policy_logits", "(", "core_output", ")", "\n", "baseline", "=", "tf", ".", "squeeze", "(", "self", ".", "_baseline", "(", "core_output", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Sample an action from the policy.", "\n", "action", "=", "self", ".", "_parametric_action_distribution", ".", "sample", "(", "policy_logits", ")", "\n", "\n", "return", "AgentOutput", "(", "action", ",", "policy_logits", ",", "baseline", ")", "\n", "\n", "# Not clear why, but if \"@tf.function\" declarator is placed directly onto", "\n", "# __call__, training fails with \"uninitialized variable *baseline\".", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticMLP.initial_state": [[66, 69], ["None"], "methods", ["None"], ["# when running on multiple learning tpu cores.", "\n", "\n", "\n", "", "@", "tf", ".", "function", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticMLP._concat_obs": [[70, 73], ["tensorflow.concat", "tensorflow.nest.flatten"], "methods", ["None"], ["def", "get_action", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "self", ".", "__call__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "__call__", "(", "self", ",", "prev_actions", ",", "env_outputs", ",", "core_state", ",", "unroll", "=", "False", ",", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticMLP.get_Q": [[74, 97], ["networks.ActorCriticMLP._concat_obs", "tensorflow.cast", "tensorflow.concat", "tensorflow.concat", "len", "len", "critic"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM._concat_obs"], ["is_training", "=", "False", ")", ":", "\n", "    ", "\"\"\"Runs the agent.\n\n    Args:\n      prev_actions: Previous action. Not used by this agent.\n      env_outputs: Structure with reward, done and observation fields. Only\n        observation field is used by this agent. It should have the shape\n        [time, batch_size, observation_size].\n      core_state: Agent state.\n      unroll: Should be True if inputs contain the time dimension and False\n        otherwise.\n      is_training: Whether we are in the loss computation. Not used by this\n        agent.\n    Returns:\n      A structure with action, policy_logits and baseline.\n    \"\"\"", "\n", "if", "not", "unroll", ":", "\n", "# Add time dimension.", "\n", "      ", "prev_actions", ",", "env_outputs", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "tf", ".", "expand_dims", "(", "t", ",", "0", ")", ",", "(", "prev_actions", ",", "env_outputs", ")", ")", "\n", "\n", "", "outputs", ",", "core_state", "=", "self", ".", "_unroll", "(", "prev_actions", ",", "env_outputs", ",", "core_state", ")", "\n", "\n", "if", "not", "unroll", ":", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticMLP.get_V": [[98, 106], ["tensorflow.squeeze", "networks.ActorCriticMLP._v_mlp", "networks.ActorCriticMLP._concat_obs"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM._concat_obs"], ["# Remove time dimension.", "\n", "      ", "outputs", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "tf", ".", "squeeze", "(", "t", ",", "0", ")", ",", "outputs", ")", "\n", "\n", "", "return", "outputs", ",", "core_state", "\n", "\n", "", "def", "_unroll", "(", "self", ",", "unused_prev_actions", ",", "env_outputs", ",", "core_state", ")", ":", "\n", "    ", "unused_reward", ",", "done", ",", "observation", ",", "_", ",", "_", "=", "env_outputs", "\n", "observation", "=", "self", ".", "_mlp", "(", "observation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticMLP.get_action_params": [[107, 114], ["networks.ActorCriticMLP._actor_mlp", "networks.ActorCriticMLP._concat_obs"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM._concat_obs"], ["initial_core_state", "=", "self", ".", "_core", ".", "get_initial_state", "(", "\n", "batch_size", "=", "tf", ".", "shape", "(", "observation", ")", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "core_output_list", "=", "[", "]", "\n", "for", "input_", ",", "d", "in", "zip", "(", "tf", ".", "unstack", "(", "observation", ")", ",", "tf", ".", "unstack", "(", "done", ")", ")", ":", "\n", "# If the episode ended, the core state should be reset before the next.", "\n", "      ", "core_state", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "x", ",", "y", ",", "d", "=", "d", ":", "tf", ".", "where", "(", "\n", "tf", ".", "reshape", "(", "d", ",", "[", "d", ".", "shape", "[", "0", "]", "]", "+", "[", "1", "]", "*", "(", "x", ".", "shape", ".", "rank", "-", "1", ")", ")", ",", "x", ",", "y", ")", ",", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticMLP.get_action": [[120, 123], ["networks.ActorCriticMLP.__call__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.__call__"], ["\n", "return", "utils", ".", "batch_apply", "(", "self", ".", "_head", ",", "(", "outputs", ",", ")", ")", ",", "core_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticMLP.__call__": [[124, 141], ["networks.ActorCriticMLP.get_action_params", "networks.ActorCriticMLP._action_distribution.sample"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_action_params", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.LSTMwithFeedForwardBranch.__init__": [[149, 177], ["tensorflow.Module.__init__", "networks.create_mlp", "networks.create_mlp", "networks.create_mlp", "tensorflow.keras.layers.StackedRNNCells", "tensorflow.keras.layers.LSTMCell"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__", "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.create_mlp", "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.create_mlp", "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.create_mlp"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.LSTMwithFeedForwardBranch.initial_state": [[178, 180], ["networks.LSTMwithFeedForwardBranch._core.get_initial_state"], "methods", ["None"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.LSTMwithFeedForwardBranch.__call__": [[181, 222], ["networks.LSTMwithFeedForwardBranch._pre_mlp", "networks.LSTMwithFeedForwardBranch.initial_state", "zip", "tensorflow.stack", "networks.LSTMwithFeedForwardBranch._ff_mlp", "tensorflow.concat", "networks.LSTMwithFeedForwardBranch._post_mlp", "tensorflow.unstack", "tensorflow.unstack", "tensorflow.nest.map_structure", "networks.LSTMwithFeedForwardBranch._core", "core_output_list.append", "tensorflow.shape", "tensorflow.where", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM.__init__": [[230, 257], ["tensorflow.Module.__init__", "networks.ActorCriticLSTM.__init__.create_net"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM.initial_state": [[258, 261], ["net.initial_state"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM._concat_obs": [[262, 266], ["tensorflow.concat", "tensorflow.nest.flatten"], "methods", ["None"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM._run_net": [[267, 289], ["tensorflow.nest.is_nested", "networks.ActorCriticLSTM._concat_obs", "tensorflow.concat", "net", "env_output.observation.copy", "len", "len", "networks.ActorCriticLSTM._concat_obs", "env_output.observation.keys", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM._concat_obs", "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM._concat_obs"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM.get_Q": [[290, 314], ["networks.ActorCriticLSTM._concat_obs", "tensorflow.concat", "tensorflow.concat", "len", "len", "networks.ActorCriticLSTM._run_net", "zip", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM._concat_obs", "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM._run_net"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM.get_V": [[315, 324], ["tensorflow.squeeze", "networks.ActorCriticLSTM._run_net"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM._run_net"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM.get_action_params": [[325, 334], ["networks.ActorCriticLSTM._run_net"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM._run_net"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM.get_action": [[340, 343], ["networks.ActorCriticLSTM.__call__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.__call__"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM.__call__": [[344, 373], ["networks.ActorCriticLSTM._unroll", "tensorflow.nest.map_structure", "tensorflow.expand_dims", "tensorflow.nest.map_structure", "tensorflow.expand_dims", "tensorflow.squeeze"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep._unroll"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM._unroll": [[374, 383], ["networks.ActorCriticLSTM.get_action_params", "networks.ActorCriticLSTM._action_distribution.sample", "networks.ActorCriticLSTM._run_net", "zip"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_action_params", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample", "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.ActorCriticLSTM._run_net"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks.create_mlp": [[20, 29], ["tensorflow.keras.Sequential", "enumerate", "tf.keras.Sequential.add", "tensorflow.keras.layers.Dense", "len"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.add"], ["\n", "AgentOutput", "=", "collections", ".", "namedtuple", "(", "'AgentOutput'", ",", "\n", "'action policy_logits baseline'", ")", "\n", "\n", "\n", "class", "MLPandLSTM", "(", "tf", ".", "Module", ")", ":", "\n", "  ", "\"\"\"MLP+stacked LSTM Agent.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "parametric_action_distribution", ",", "mlp_sizes", ",", "lstm_sizes", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.networks_test.NetworkTest.test_actor_critic_lstm": [[28, 80], ["seed_rl.common.parametric_distribution.normal_tanh_distribution", "seed_rl.agents.sac.networks.ActorCriticLSTM", "seed_rl.common.utils.EnvOutput", "tensorflow.random.normal", "tensorflow.random.normal", "seed_rl.agents.sac.networks.ActorCriticLSTM.initial_state", "seed_rl.agents.sac.networks.ActorCriticLSTM.get_V", "seed_rl.agents.sac.networks.ActorCriticLSTM.get_Q", "range", "tensorflow.stack", "tensorflow.stack", "networks_test.NetworkTest.assertAllClose", "networks_test.NetworkTest.assertAllClose", "tensorflow.nest.map_structure", "tensorflow.nest.map_structure", "tensorflow.stack.append", "tensorflow.stack.append", "seed_rl.agents.sac.networks.ActorCriticLSTM.", "tensorflow.random.normal", "tensorflow.random.normal", "tensorflow.cast", "tensorflow.zeros", "tensorflow.ones", "tensorflow.random.uniform", "seed_rl.agents.sac.networks.ActorCriticLSTM.get_V", "seed_rl.agents.sac.networks.ActorCriticLSTM.get_Q"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.normal_tanh_distribution", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_V", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_Q", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_V", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_Q"], ["  ", "def", "test_actor_critic_lstm", "(", "self", ")", ":", "\n", "    ", "n_steps", "=", "100", "\n", "batch_size", "=", "10", "\n", "obs_size", "=", "15", "\n", "action_size", "=", "3", "\n", "\n", "action_dist", "=", "parametric_distribution", ".", "normal_tanh_distribution", "(", "action_size", ")", "\n", "agent", "=", "networks", ".", "ActorCriticLSTM", "(", "\n", "action_dist", ",", "\n", "n_critics", "=", "2", ",", "\n", "lstm_sizes", "=", "[", "10", ",", "20", "]", ",", "\n", "pre_mlp_sizes", "=", "[", "30", ",", "40", "]", ",", "\n", "post_mlp_sizes", "=", "[", "50", "]", ",", "\n", "ff_mlp_sizes", "=", "[", "25", ",", "35", ",", "45", "]", ")", "\n", "env_output", "=", "utils", ".", "EnvOutput", "(", "\n", "observation", "=", "tf", ".", "random", ".", "normal", "(", "(", "n_steps", ",", "batch_size", ",", "obs_size", ")", ")", ",", "\n", "reward", "=", "tf", ".", "random", ".", "normal", "(", "(", "n_steps", ",", "batch_size", ")", ")", ",", "\n", "done", "=", "tf", ".", "cast", "(", "tf", ".", "random", ".", "uniform", "(", "(", "n_steps", ",", "batch_size", ")", ",", "0", ",", "1", ")", ",", "tf", ".", "bool", ")", ",", "\n", "abandoned", "=", "tf", ".", "zeros", "(", "(", "n_steps", ",", "batch_size", ")", ",", "dtype", "=", "tf", ".", "bool", ")", ",", "\n", "episode_step", "=", "tf", ".", "ones", "(", "(", "n_steps", ",", "batch_size", ")", ",", "dtype", "=", "tf", ".", "int32", ")", ")", "\n", "prev_action", "=", "tf", ".", "random", ".", "normal", "(", "(", "n_steps", ",", "batch_size", ",", "action_size", ")", ")", "\n", "action", "=", "tf", ".", "random", ".", "normal", "(", "(", "n_steps", ",", "batch_size", ",", "action_size", ")", ")", "\n", "state", "=", "agent", ".", "initial_state", "(", "10", ")", "\n", "\n", "# Run in one call.", "\n", "v_one_call", "=", "agent", ".", "get_V", "(", "prev_action", ",", "env_output", ",", "state", ")", "\n", "q_one_call", "=", "agent", ".", "get_Q", "(", "prev_action", ",", "env_output", ",", "state", ",", "action", ")", "\n", "\n", "# Run step-by-step.", "\n", "v_many_calls", "=", "[", "]", "\n", "q_many_calls", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_steps", ")", ":", "\n", "\n", "      ", "env_output_i", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "t", "[", "i", "]", ",", "env_output", ")", "\n", "expanded_env_output_i", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "t", "[", "i", ",", "tf", ".", "newaxis", "]", ",", "\n", "env_output", ")", "\n", "v_many_calls", ".", "append", "(", "\n", "agent", ".", "get_V", "(", "prev_action", "[", "i", ",", "tf", ".", "newaxis", "]", ",", "\n", "expanded_env_output_i", ",", "\n", "state", ")", "[", "0", "]", ")", "\n", "q_many_calls", ".", "append", "(", "\n", "agent", ".", "get_Q", "(", "prev_action", "[", "i", ",", "tf", ".", "newaxis", "]", ",", "\n", "expanded_env_output_i", ",", "\n", "state", ",", "\n", "action", "[", "i", ",", "tf", ".", "newaxis", "]", ")", "[", "0", "]", ")", "\n", "unused_action", ",", "state", "=", "agent", "(", "prev_action", "[", "i", "]", ",", "env_output_i", ",", "state", ")", "\n", "", "v_many_calls", "=", "tf", ".", "stack", "(", "v_many_calls", ")", "\n", "q_many_calls", "=", "tf", ".", "stack", "(", "q_many_calls", ")", "\n", "\n", "# Check if results are the same.", "\n", "self", ".", "assertAllClose", "(", "v_one_call", ",", "v_many_calls", ",", "1e-4", ",", "1e-4", ")", "\n", "self", ".", "assertAllClose", "(", "q_one_call", ",", "q_many_calls", ",", "1e-4", ",", "1e-4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.learner.compute_loss": [[110, 222], ["tensorflow.nest.map_structure", "agent", "agent.get_action_params", "parametric_action_distribution.sample", "parametric_action_distribution.entropy", "agent.get_V", "tensorflow.stop_gradient", "tensorflow.reduce_mean", "agent.get_Q", "tensorflow.stop_gradient", "tensorflow.reduce_mean", "logger.log_session", "logger.log", "logger.log", "logger.log", "logger.log", "logger.log", "logger.log", "logger.log", "logger.log", "parametric_action_distribution.create_dist", "hasattr", "logger.log", "logger.log", "logger.log", "tensorflow.cast", "tensorflow.clip_by_value", "tensorflow.nest.map_structure", "env_outputs.observation.copy", "tensorflow.concat", "tensorflow.GradientTape", "tape.watch", "agent.get_Q", "parametric_action_distribution.log_prob", "tensorflow.reduce_min", "tensorflow.square", "agent.get_action_params", "parametric_action_distribution.sample", "tensorflow.reduce_min", "tensorflow.expand_dims", "tensorflow.square", "tensorflow.reduce_mean", "tensorflow.sqrt", "tensorflow.reduce_mean", "tensorflow.sqrt", "logger.log", "tensorflow.reduce_max", "agent.entropy_cost", "env_outputs._replace", "tape.gradient", "tensorflow.stop_gradient", "tensorflow.reduce_mean", "target_agent.get_Q", "parametric_action_distribution.entropy", "agent.entropy_cost", "tensorflow.stop_gradient", "agent.entropy_cost", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.abs", "tensorflow.stop_gradient", "tensorflow.reduce_mean", "tensorflow.stop_gradient", "tensorflow.reduce_mean", "tensorflow.math.reduce_std", "tensorflow.reduce_mean", "tensorflow.stop_gradient", "target_agent.get_V", "tensorflow.square", "tensorflow.square", "agent.entropy_cost", "agent.entropy_cost", "agent.entropy_cost", "tensorflow.reduce_mean", "tensorflow.stop_gradient"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_action_params", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.entropy", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_V", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_Q", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log_session", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.create_dist", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_Q", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_action_params", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_Q", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.entropy", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_V"], ["'num_frames returns raw_returns env_ids'", ")", "\n", "\n", "\n", "def", "get_replay_insertion_batch_size", "(", "per_replica", "=", "False", ")", ":", "\n", "  ", "if", "per_replica", ":", "\n", "    ", "return", "int", "(", "FLAGS", ".", "batch_size", "/", "FLAGS", ".", "replay_ratio", "/", "FLAGS", ".", "num_training_tpus", ")", "\n", "", "else", ":", "\n", "    ", "return", "int", "(", "FLAGS", ".", "batch_size", "/", "FLAGS", ".", "replay_ratio", ")", "\n", "\n", "\n", "", "", "def", "get_num_training_envs", "(", ")", ":", "\n", "  ", "return", "FLAGS", ".", "num_envs", "-", "FLAGS", ".", "num_eval_envs", "\n", "\n", "\n", "", "def", "is_training_env", "(", "env_id", ")", ":", "\n", "  ", "\"\"\"Training environment IDs are in range [0, num_training_envs).\"\"\"", "\n", "return", "env_id", "<", "get_num_training_envs", "(", ")", "\n", "\n", "\n", "", "def", "get_envs_epsilon", "(", "env_ids", ",", "num_training_envs", ",", "num_eval_envs", ",", "eval_epsilon", ")", ":", "\n", "  ", "\"\"\"Per-environment epsilon as in Apex and R2D2.\n\n  Args:\n    env_ids: <int32>[inference_batch_size], the environment task IDs (in range\n      [0, num_training_envs+num_eval_envs)).\n    num_training_envs: Number of training environments. Training environments\n      should have IDs in [0, num_training_envs).\n    num_eval_envs: Number of evaluation environments. Eval environments should\n      have IDs in [num_training_envs, num_training_envs + num_eval_envs).\n    eval_epsilon: Epsilon used for eval environments.\n\n  Returns:\n    A 1D float32 tensor with one epsilon for each input environment ID.\n  \"\"\"", "\n", "# <float32>[num_training_envs + num_eval_envs]", "\n", "epsilons", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "math", ".", "pow", "(", "0.4", ",", "tf", ".", "linspace", "(", "1.", ",", "8.", ",", "num", "=", "num_training_envs", ")", ")", ",", "\n", "tf", ".", "constant", "(", "[", "eval_epsilon", "]", "*", "num_eval_envs", ")", "]", ",", "\n", "axis", "=", "0", ")", "\n", "return", "tf", ".", "gather", "(", "epsilons", ",", "env_ids", ")", "\n", "\n", "\n", "", "def", "apply_epsilon_greedy", "(", "actions", ",", "env_ids", ",", "num_training_envs", ",", "\n", "num_eval_envs", ",", "eval_epsilon", ",", "num_actions", ")", ":", "\n", "  ", "\"\"\"Epsilon-greedy: randomly replace actions with given probability.\n\n  Args:\n    actions: <int32>[batch_size] tensor with one action per environment.\n    env_ids: <int32>[inference_batch_size], the environment task IDs (in range\n      [0, num_envs)).\n    num_training_envs: Number of training environments.\n    num_eval_envs: Number of eval environments.\n    eval_epsilon: Epsilon used for eval environments.\n    num_actions: Number of environment actions.\n\n  Returns:\n    A new <int32>[batch_size] tensor with one action per environment. With\n    probability epsilon, the new action is random, and with probability (1 -\n    epsilon), the action is unchanged, where epsilon is chosen for each\n    environment.\n  \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "actions", ")", "[", "0", "]", "\n", "epsilons", "=", "get_envs_epsilon", "(", "env_ids", ",", "num_training_envs", ",", "num_eval_envs", ",", "\n", "eval_epsilon", ")", "\n", "random_actions", "=", "tf", ".", "random", ".", "uniform", "(", "[", "batch_size", "]", ",", "maxval", "=", "num_actions", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", "\n", "probs", "=", "tf", ".", "random", ".", "uniform", "(", "shape", "=", "[", "batch_size", "]", ")", "\n", "return", "tf", ".", "where", "(", "tf", ".", "math", ".", "less", "(", "probs", ",", "epsilons", ")", ",", "random_actions", ",", "actions", ")", "\n", "\n", "\n", "", "def", "value_function_rescaling", "(", "x", ")", ":", "\n", "  ", "\"\"\"Value function rescaling per R2D2 paper, table 2.\"\"\"", "\n", "eps", "=", "FLAGS", ".", "value_function_rescaling_epsilon", "\n", "return", "tf", ".", "math", ".", "sign", "(", "x", ")", "*", "(", "tf", ".", "math", ".", "sqrt", "(", "tf", ".", "math", ".", "abs", "(", "x", ")", "+", "1.", ")", "-", "1.", ")", "+", "eps", "*", "x", "\n", "\n", "\n", "", "def", "inverse_value_function_rescaling", "(", "x", ")", ":", "\n", "  ", "\"\"\"See Proposition A.2 in paper \"Observe and Look Further\".\"\"\"", "\n", "eps", "=", "FLAGS", ".", "value_function_rescaling_epsilon", "\n", "return", "tf", ".", "math", ".", "sign", "(", "x", ")", "*", "(", "\n", "tf", ".", "math", ".", "square", "(", "(", "(", "tf", ".", "math", ".", "sqrt", "(", "\n", "1.", "+", "4.", "*", "eps", "*", "(", "tf", ".", "math", ".", "abs", "(", "x", ")", "+", "1.", "+", "eps", ")", ")", ")", "-", "1.", ")", "/", "(", "2.", "*", "eps", ")", ")", "-", "\n", "1.", ")", "\n", "\n", "\n", "", "def", "n_step_bellman_target", "(", "rewards", ",", "done", ",", "q_target", ",", "gamma", ",", "n_steps", ")", ":", "\n", "  "]], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.learner.create_dataset": [[228, 293], ["strategy.experimental_distribute_datasets_from_function", "ctx.get_per_replica_batch_size", "tensorflow.constant", "replay_buffer.sample", "sampled_unrolls._replace._replace", "sampled_unrolls._replace._replace", "tensorflow.nest.flatten", "tensorflow.data.Dataset.from_tensors().repeat", "tf.data.Dataset.from_tensors().repeat.map", "learner.get_replay_insertion_batch_size", "unroll_queue.dequeue_many", "replay_buffer.insert", "seed_rl.common.utils.make_time_major", "seed_rl.common.utils.make_time_major", "seed_rl.common.utils.make_time_major", "encode", "tensorflow.data.Dataset.from_tensors", "learner.create_dataset.dequeue"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample", "home.repos.pwc.inspect_result.google-research_seed_rl.sac.learner.get_replay_insertion_batch_size", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.dequeue_many", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.PrioritizedReplay.insert", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.make_time_major", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.make_time_major", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.make_time_major", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.dequeue"], ["\n", "# We append n_steps - 1 times the last q_target. They are divided by gamma **", "\n", "# k to correct for the fact that they are at a 'fake' indice, and will", "\n", "# therefore end up being multiplied back by gamma ** k in the loop below.", "\n", "# We prepend 0s that will be discarded at the first iteration below.", "\n", "bellman_target", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "zeros_like", "(", "q_target", "[", "0", ":", "1", "]", ")", ",", "q_target", "]", "+", "\n", "[", "q_target", "[", "-", "1", ":", "]", "/", "gamma", "**", "k", "\n", "for", "k", "in", "range", "(", "1", ",", "n_steps", ")", "]", ",", "\n", "axis", "=", "0", ")", "\n", "# Pad with n_steps 0s. They will be used to compute the last n_steps-1", "\n", "# targets (having 0 values is important).", "\n", "done", "=", "tf", ".", "concat", "(", "[", "done", "]", "+", "[", "tf", ".", "zeros_like", "(", "done", "[", "0", ":", "1", "]", ")", "]", "*", "n_steps", ",", "axis", "=", "0", ")", "\n", "rewards", "=", "tf", ".", "concat", "(", "[", "rewards", "]", "+", "[", "tf", ".", "zeros_like", "(", "rewards", "[", "0", ":", "1", "]", ")", "]", "*", "n_steps", ",", "\n", "axis", "=", "0", ")", "\n", "# Iteratively build the n_steps targets. After the i-th iteration (1-based),", "\n", "# bellman_target is effectively the i-step returns.", "\n", "for", "_", "in", "range", "(", "n_steps", ")", ":", "\n", "    ", "rewards", "=", "rewards", "[", ":", "-", "1", "]", "\n", "done", "=", "done", "[", ":", "-", "1", "]", "\n", "bellman_target", "=", "(", "\n", "rewards", "+", "gamma", "*", "(", "1.", "-", "tf", ".", "cast", "(", "done", ",", "tf", ".", "float32", ")", ")", "*", "bellman_target", "[", "1", ":", "]", ")", "\n", "\n", "", "return", "bellman_target", "\n", "\n", "\n", "", "def", "compute_loss_and_priorities_from_agent_outputs", "(", "\n", "training_agent_output", ",", "\n", "target_agent_output", ",", "\n", "env_outputs", ",", "\n", "agent_outputs", ",", "\n", "gamma", ",", "eta", "=", "0.9", ")", ":", "\n", "  ", "\"\"\"Computes the loss to optimize and the new priorities.\n\n  This implements the n-step double DQN loss with the Q function computed on\n  sequences of transitions.\n\n  Args:\n    training_agent_output: AgentOutput where tensors have [unroll_length,\n      batch_size] front dimensions. Used for the Q values that should be\n      learned, and for computing the max over next actions as part of\n      double-DQN.\n    target_agent_output: AgentOutput used to compute the double-DQN target.\n    env_outputs: EnvOutputs where tensors have [unroll_length, batch_size]\n      additional front dimensions.\n    agent_outputs: AgentOutputs where tensors have [unroll_length, batch_size]\n      additional front dimensions.\n    gamma: RL discounting factor.\n    eta: float, parameter for balancing mean and max TD errors over a sequence\n      of transitions for computing its new priority.\n\n  Returns:\n    A pair:\n      - The loss for each unroll. Shape <float32>[batch_size]\n      - The new priorities for each unroll. Shape <float32>[batch_size].\n  \"\"\"", "\n", "num_actions", "=", "tf", ".", "shape", "(", "training_agent_output", ".", "q_values", ")", "[", "2", "]", "\n", "# <float32>[time, batch_size, num_actions].", "\n", "replay_action_one_hot", "=", "tf", ".", "one_hot", "(", "agent_outputs", ".", "action", ",", "num_actions", ",", "1.", ",", "0.", ")", "\n", "# This is Q(s, a), where a is the action played (can come from the agent or be", "\n", "# random). This is what we learn.", "\n", "# <float32>[time, batch_size].", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.learner.get_replay_insertion_batch_size": [[295, 307], ["int"], "function", ["None"], ["training_agent_output", ".", "q_values", "*", "replay_action_one_hot", ",", "axis", "=", "2", ")", "\n", "\n", "# [time, batch_size, num_actions]", "\n", "best_actions_one_hot", "=", "tf", ".", "one_hot", "(", "\n", "training_agent_output", ".", "action", ",", "num_actions", ",", "1.", ",", "0.", ")", "\n", "# This is Q'(s) = h^(-1)(Q_target(s, \\argmax_a Q(s, a)))", "\n", "# [time, batch_size]", "\n", "qtarget_max", "=", "inverse_value_function_rescaling", "(", "tf", ".", "reduce_sum", "(", "\n", "target_agent_output", ".", "q_values", "*", "best_actions_one_hot", ",", "\n", "axis", "=", "2", ")", ")", "\n", "\n", "# [time, batch_size]", "\n", "bellman_target", "=", "tf", ".", "stop_gradient", "(", "n_step_bellman_target", "(", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.learner.validate_config": [[309, 322], ["seed_rl.common.utils.validate_learner_config", "learner.get_replay_insertion_batch_size", "learner.get_replay_insertion_batch_size"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.validate_learner_config", "home.repos.pwc.inspect_result.google-research_seed_rl.sac.learner.get_replay_insertion_batch_size", "home.repos.pwc.inspect_result.google-research_seed_rl.sac.learner.get_replay_insertion_batch_size"], ["env_outputs", ".", "done", ",", "\n", "qtarget_max", ",", "\n", "gamma", ",", "\n", "FLAGS", ".", "n_steps", ")", ")", "\n", "\n", "# replay_q is actually Q(s_{t+1}, a_{t+1}), so we need to shift the targets.", "\n", "bellman_target", "=", "bellman_target", "[", "1", ":", ",", "...", "]", "\n", "\n", "replay_q", "=", "replay_q", "[", ":", "-", "1", ",", "...", "]", "\n", "\n", "bellman_target", "=", "value_function_rescaling", "(", "bellman_target", ")", "\n", "# [time, batch_size]", "\n", "abs_td_errors", "=", "tf", ".", "abs", "(", "bellman_target", "-", "replay_q", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.sac.learner.learner_loop": [[324, 651], ["absl.logging.info", "learner.validate_config", "seed_rl.common.utils.init_learner", "create_env_fn", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "seed_rl.common.utils.EnvOutput", "tensorflow.TensorSpec", "create_agent_fn", "create_agent_fn", "create_agent_fn.initial_state", "tensorflow.nest.map_structure", "tensorflow.nest.map_structure", "tensorflow.nest.map_structure", "encode", "encode", "tensorflow.train.Checkpoint", "tensorflow.train.CheckpointManager", "tensorflow.summary.create_file_writer", "seed_rl.common.utils.ProgressLogger", "seed_rl.grpc.Server", "seed_rl.common.utils.UnrollStore", "seed_rl.common.utils.Aggregator", "seed_rl.common.utils.Aggregator", "seed_rl.common.utils.Aggregator", "seed_rl.common.utils.Aggregator", "seed_rl.common.utils.Aggregator", "Unroll", "seed_rl.common.utils.StructuredFIFOQueue", "seed_rl.common.utils.StructuredFIFOQueue", "tensorflow.Variable", "tensorflow.nest.map_structure", "tensorflow.function", "grpc.Server.start", "learner.create_dataset", "iter", "utils.ProgressLogger.start", "utils.ProgressLogger.shutdown", "tf.train.CheckpointManager.save", "tensorflow.saved_model.save", "grpc.Server.shutdown", "utils.StructuredFIFOQueue.close", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.nest.map_structure", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "strategy.scope", "learner.learner_loop.initialize_agent_variables"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.validate_config", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.init_learner", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.create_dataset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.close"], ["priorities", "=", "(", "eta", "*", "tf", ".", "reduce_max", "(", "abs_td_errors", ",", "axis", "=", "0", ")", "+", "\n", "(", "1", "-", "eta", ")", "*", "tf", ".", "reduce_mean", "(", "abs_td_errors", ",", "axis", "=", "0", ")", ")", "\n", "\n", "# Sums over time dimension.", "\n", "loss", "=", "0.5", "*", "tf", ".", "reduce_sum", "(", "tf", ".", "math", ".", "square", "(", "abs_td_errors", ")", ",", "axis", "=", "0", ")", "\n", "\n", "return", "loss", ",", "priorities", "\n", "\n", "\n", "", "def", "compute_loss_and_priorities", "(", "\n", "training_agent", ",", "target_agent", ",", "\n", "agent_state", ",", "prev_actions", ",", "env_outputs", ",", "agent_outputs", ",", "\n", "gamma", ",", "burn_in", ")", ":", "\n", "  ", "\"\"\"Computes the loss to optimize and the new priorities.\n\n  This implements the n-step double DQN loss with the Q function computed on\n  sequences of transitions.\n\n  Args:\n    training_agent: Keras Model representing the training agent's network.\n    target_agent: Keras Model representing the target agent's network.\n    agent_state: Batched agent recurrent state at the beginning of each unroll.\n    prev_actions: <int32>[unroll_length, batch_size]. This is the action played\n      in the environment before each corresponding \"env_outputs\" (i.e. after\n      epsilon-greedy policy is applied).\n    env_outputs: EnvOutputs where tensors have [unroll_length, batch_size]\n      additional front dimensions.\n    agent_outputs: AgentOutputs where tensors have [unroll_length, batch_size]\n      additional front dimensions.\n    gamma: RL discounting factor.\n    burn_in: Number of time steps on which we update each recurrent state\n      without computing the loss nor propagating gradients.\n\n  Returns:\n    A pair:\n      - The loss for each unroll. Shape <float32>[batch_size]\n      - The new priorities for each unroll. Shape <float32>[batch_size].\n  \"\"\"", "\n", "if", "burn_in", ":", "\n", "    ", "agent_input_prefix", ",", "agent_input_suffix", "=", "utils", ".", "split_structure", "(", "\n", "(", "prev_actions", ",", "env_outputs", ")", ",", "burn_in", ")", "\n", "_", ",", "agent_outputs_suffix", "=", "utils", ".", "split_structure", "(", "agent_outputs", ",", "burn_in", ")", "\n", "_", ",", "training_state", "=", "training_agent", "(", "\n", "agent_input_prefix", ",", "agent_state", ",", "unroll", "=", "True", ")", "\n", "training_state", "=", "tf", ".", "nest", ".", "map_structure", "(", "tf", ".", "stop_gradient", ",", "training_state", ")", "\n", "_", ",", "target_state", "=", "target_agent", "(", "agent_input_prefix", ",", "agent_state", ",", "unroll", "=", "True", ")", "\n", "", "else", ":", "\n", "    ", "agent_input_suffix", "=", "(", "prev_actions", ",", "env_outputs", ")", "\n", "agent_outputs_suffix", "=", "agent_outputs", "\n", "training_state", "=", "agent_state", "\n", "target_state", "=", "agent_state", "\n", "\n", "# Agent outputs have fields with shape [time, batch_size, <field_shape>].", "\n", "", "training_agent_output", ",", "_", "=", "training_agent", "(", "\n", "agent_input_suffix", ",", "training_state", ",", "unroll", "=", "True", ")", "\n", "target_agent_output", ",", "_", "=", "target_agent", "(", "\n", "agent_input_suffix", ",", "target_state", ",", "unroll", "=", "True", ")", "\n", "_", ",", "env_outputs_suffix", "=", "agent_input_suffix", "\n", "return", "compute_loss_and_priorities_from_agent_outputs", "(", "\n", "training_agent_output", ",", "target_agent_output", ",", "env_outputs_suffix", ",", "\n", "agent_outputs_suffix", ",", "gamma", ")", "\n", "\n", "\n", "", "def", "create_dataset", "(", "unroll_queue", ",", "replay_buffer", ",", "strategy", ",", "batch_size", ",", "\n", "priority_exponent", ",", "encode", ")", ":", "\n", "  ", "\"\"\"Creates a dataset sampling from replay buffer.\n\n  This dataset will consume a batch of unrolls from 'unroll_queue', add it to\n  the replay buffer, and sample a batch of unrolls from it.\n\n  Args:\n    unroll_queue: Queue of 'Unroll' elements.\n    replay_buffer: Replay buffer of 'Unroll' elements.\n    strategy: A `distribute_lib.Strategy`.\n    batch_size: Batch size used for consuming the unroll queue and sampling from\n      the replay buffer.\n    priority_exponent: Priority exponent used for sampling from the replay\n      buffer.\n    encode: Function to encode the data for TPU, etc.\n\n  Returns:\n    A \"distributed `Dataset`\", which acts like a `tf.data.Dataset` except it\n    produces \"PerReplica\" values. Each iteration of the dataset produces\n    flattened `SampledUnrolls` structures where per-timestep tensors have front\n    dimensions [unroll_length, batch_size_per_replica].\n  \"\"\"", "\n", "\n", "@", "tf", ".", "function", "\n", "def", "dequeue", "(", "ctx", ")", ":", "\n", "    ", "\"\"\"Inserts into and samples from the replay buffer.\n\n    Args:\n      ctx: tf.distribute.InputContext.\n\n    Returns:\n      A flattened `SampledUnrolls` structures where per-timestep tensors have\n      front dimensions [unroll_length, batch_size_per_replica].\n    \"\"\"", "\n", "per_replica_batch_size", "=", "ctx", ".", "get_per_replica_batch_size", "(", "batch_size", ")", "\n", "insertion_batch_size", "=", "get_replay_insertion_batch_size", "(", "per_replica", "=", "True", ")", "\n", "\n", "print_every", "=", "tf", ".", "cast", "(", "\n", "insertion_batch_size", "*", "\n", "(", "1", "+", "FLAGS", ".", "replay_buffer_min_size", "//", "50", "//", "insertion_batch_size", ")", ",", "\n", "tf", ".", "int64", ")", "\n", "log_summary_every", "=", "tf", ".", "cast", "(", "insertion_batch_size", "*", "500", ",", "tf", ".", "int64", ")", "\n", "\n", "while", "tf", ".", "constant", "(", "True", ")", ":", "\n", "# Each tensor in 'unrolls' has shape [insertion_batch_size, unroll_length,", "\n", "# <field-specific dimensions>].", "\n", "      ", "unrolls", "=", "unroll_queue", ".", "dequeue_many", "(", "insertion_batch_size", ")", "\n", "# The replay buffer is not threadsafe (and making it thread-safe might", "\n", "# slow it down), which is why we insert and sample in a single thread, and", "\n", "# use TF Queues for passing data between threads.", "\n", "replay_buffer", ".", "insert", "(", "unrolls", ",", "unrolls", ".", "priority", ")", "\n", "if", "tf", ".", "equal", "(", "replay_buffer", ".", "num_inserted", "%", "log_summary_every", ",", "0", ")", ":", "\n", "# Unfortunately, there is no tf.summary(log_every_n_sec).", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "'initial_priorities'", ",", "unrolls", ".", "priority", ")", "\n", "", "if", "replay_buffer", ".", "num_inserted", ">=", "FLAGS", ".", "replay_buffer_min_size", ":", "\n", "        ", "break", "\n", "\n", "", "if", "tf", ".", "equal", "(", "replay_buffer", ".", "num_inserted", "%", "print_every", ",", "0", ")", ":", "\n", "        ", "tf", ".", "print", "(", "'Waiting for the replay buffer to fill up. '", "\n", "'It currently has'", ",", "replay_buffer", ".", "num_inserted", ",", "\n", "'elements, waiting for at least'", ",", "FLAGS", ".", "replay_buffer_min_size", ",", "\n", "'elements'", ")", "\n", "\n", "", "", "sampled_indices", ",", "weights", ",", "sampled_unrolls", "=", "replay_buffer", ".", "sample", "(", "\n", "per_replica_batch_size", ",", "priority_exponent", ")", "\n", "sampled_unrolls", "=", "sampled_unrolls", ".", "_replace", "(", "\n", "prev_actions", "=", "utils", ".", "make_time_major", "(", "sampled_unrolls", ".", "prev_actions", ")", ",", "\n", "env_outputs", "=", "utils", ".", "make_time_major", "(", "sampled_unrolls", ".", "env_outputs", ")", ",", "\n", "agent_outputs", "=", "utils", ".", "make_time_major", "(", "sampled_unrolls", ".", "agent_outputs", ")", ")", "\n", "sampled_unrolls", "=", "sampled_unrolls", ".", "_replace", "(", "\n", "env_outputs", "=", "encode", "(", "sampled_unrolls", ".", "env_outputs", ")", ")", "\n", "# tf.data.Dataset treats list leafs as tensors, so we need to flatten and", "\n", "# repack.", "\n", "return", "tf", ".", "nest", ".", "flatten", "(", "SampledUnrolls", "(", "\n", "sampled_unrolls", ",", "sampled_indices", ",", "weights", ")", ")", "\n", "\n", "", "def", "dataset_fn", "(", "ctx", ")", ":", "\n", "    ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensors", "(", "0", ")", ".", "repeat", "(", "None", ")", "\n", "return", "dataset", ".", "map", "(", "lambda", "_", ":", "dequeue", "(", "ctx", ")", ")", "\n", "\n", "", "return", "strategy", ".", "experimental_distribute_datasets_from_function", "(", "dataset_fn", ")", "\n", "\n", "\n", "", "def", "validate_config", "(", ")", ":", "\n", "  ", "utils", ".", "validate_learner_config", "(", "FLAGS", ")", "\n", "assert", "FLAGS", ".", "n_steps", ">=", "1", ",", "'--n_steps < 1 does not make sense.'", "\n", "assert", "FLAGS", ".", "num_envs", ">", "FLAGS", ".", "num_eval_envs", ",", "(", "\n", "'Total number of environments ({}) should be greater than number of '", "\n", "'environments reserved to eval ({})'", ".", "format", "(", "\n", "FLAGS", ".", "num_envs", ",", "FLAGS", ".", "num_eval_envs", ")", ")", "\n", "\n", "\n", "", "def", "learner_loop", "(", "create_env_fn", ",", "create_agent_fn", ",", "create_optimizer_fn", ")", ":", "\n", "  ", "\"\"\"Main learner loop.\n\n  Args:\n    create_env_fn: Callable that must return a newly created environment. The\n      callable takes the task ID as argument - an arbitrary task ID of 0 will be\n      passed by the learner. The returned environment should follow GYM's API.\n      It is only used for infering tensor shapes. This environment will not be\n      used to generate experience.\n    create_agent_fn: Function that must create a new tf.Module with the neural\n      network that outputs actions, Q values and new agent state given the\n      environment observations and previous agent state. See\n      atari.agents.DuelingLSTMDQNNet for an example. The factory function takes\n      as input the environment output specs and the number of possible actions\n      in the env.\n    create_optimizer_fn: Function that takes the final iteration as argument\n      and must return a tf.keras.optimizers.Optimizer and a\n      tf.keras.optimizers.schedules.LearningRateSchedule.\n  \"\"\"", "\n", "logging", ".", "info", "(", "'Starting learner loop'", ")", "\n", "validate_config", "(", ")", "\n", "settings", "=", "utils", ".", "init_learner", "(", "FLAGS", ".", "num_training_tpus", ")", "\n", "strategy", ",", "inference_devices", ",", "training_strategy", ",", "encode", ",", "decode", "=", "settings", "\n", "env", "=", "create_env_fn", "(", "0", ",", "FLAGS", ")", "\n", "env_output_specs", "=", "utils", ".", "EnvOutput", "(", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "float32", ",", "'reward'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "bool", ",", "'done'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "env", ".", "observation_space", ".", "shape", ",", "env", ".", "observation_space", ".", "dtype", ",", "\n", "'observation'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "bool", ",", "'abandoned'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ",", "'episode_step'", ")", ",", "\n", ")", "\n", "action_specs", "=", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ",", "'action'", ")", "\n", "num_actions", "=", "env", ".", "action_space", ".", "n", "\n", "agent_input_specs", "=", "(", "action_specs", ",", "env_output_specs", ")", "\n", "\n", "# Initialize agent and variables.", "\n", "agent", "=", "create_agent_fn", "(", "env_output_specs", ",", "num_actions", ")", "\n", "target_agent", "=", "create_agent_fn", "(", "env_output_specs", ",", "num_actions", ")", "\n", "initial_agent_state", "=", "agent", ".", "initial_state", "(", "1", ")", "\n", "agent_state_specs", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "tf", ".", "TensorSpec", "(", "t", ".", "shape", "[", "1", ":", "]", ",", "t", ".", "dtype", ")", ",", "initial_agent_state", ")", "\n", "input_", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "s", ":", "tf", ".", "zeros", "(", "[", "1", "]", "+", "list", "(", "s", ".", "shape", ")", ",", "s", ".", "dtype", ")", ",", "agent_input_specs", ")", "\n", "input_", "=", "encode", "(", "input_", ")", "\n", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "\n", "    ", "@", "tf", ".", "function", "\n", "def", "create_variables", "(", "*", "args", ")", ":", "\n", "      ", "return", "agent", "(", "*", "decode", "(", "args", ")", ")", "\n", "\n", "", "@", "tf", ".", "function", "\n", "def", "create_target_agent_variables", "(", "*", "args", ")", ":", "\n", "      ", "return", "target_agent", "(", "*", "decode", "(", "args", ")", ")", "\n", "\n", "# The first call to Keras models to create varibales for agent and target.", "\n", "", "initial_agent_output", ",", "_", "=", "create_variables", "(", "input_", ",", "initial_agent_state", ")", "\n", "create_target_agent_variables", "(", "input_", ",", "initial_agent_state", ")", "\n", "\n", "@", "tf", ".", "function", "\n", "def", "update_target_agent", "(", ")", ":", "\n", "      ", "\"\"\"Synchronizes training and target agent variables.\"\"\"", "\n", "variables", "=", "agent", ".", "trainable_variables", "\n", "target_variables", "=", "target_agent", ".", "trainable_variables", "\n", "assert", "len", "(", "target_variables", ")", "==", "len", "(", "variables", ")", ",", "(", "\n", "'Mismatch in number of net tensors: {} != {}'", ".", "format", "(", "\n", "len", "(", "target_variables", ")", ",", "len", "(", "variables", ")", ")", ")", "\n", "for", "target_var", ",", "source_var", "in", "zip", "(", "target_variables", ",", "variables", ")", ":", "\n", "        ", "target_var", ".", "assign", "(", "source_var", ")", "\n", "\n", "# Create optimizer.", "\n", "", "", "iter_frame_ratio", "=", "(", "\n", "get_replay_insertion_batch_size", "(", ")", "*", "\n", "FLAGS", ".", "unroll_length", "*", "FLAGS", ".", "num_action_repeats", ")", "\n", "final_iteration", "=", "int", "(", "\n", "math", ".", "ceil", "(", "FLAGS", ".", "total_environment_frames", "/", "iter_frame_ratio", ")", ")", "\n", "optimizer", ",", "learning_rate_fn", "=", "create_optimizer_fn", "(", "final_iteration", ")", "\n", "\n", "\n", "iterations", "=", "optimizer", ".", "iterations", "\n", "optimizer", ".", "_create_hypers", "(", ")", "\n", "optimizer", ".", "_create_slots", "(", "agent", ".", "trainable_variables", ")", "\n", "\n", "# ON_READ causes the replicated variable to act as independent variables for", "\n", "# each replica.", "\n", "temp_grads", "=", "[", "\n", "tf", ".", "Variable", "(", "tf", ".", "zeros_like", "(", "v", ")", ",", "trainable", "=", "False", ",", "\n", "synchronization", "=", "tf", ".", "VariableSynchronization", ".", "ON_READ", ")", "\n", "for", "v", "in", "agent", ".", "trainable_variables", "\n", "]", "\n", "\n", "", "@", "tf", ".", "function", "\n", "def", "minimize", "(", "iterator", ")", ":", "\n", "    ", "\"\"\"Computes and applies gradients.\n\n    Args:\n      iterator: An iterator of distributed dataset that produces `PerReplica`.\n\n    Returns:\n      A tuple:\n        - priorities, the new priorities. Shape <float32>[batch_size].\n        - indices, the indices for updating priorities. Shape\n        <int32>[batch_size].\n        - gradient_norm_before_clip, a scalar.\n    \"\"\"", "\n", "data", "=", "next", "(", "iterator", ")", "\n", "\n", "def", "compute_gradients", "(", "args", ")", ":", "\n", "      ", "\"\"\"A function to pass to `Strategy` for gradient computation.\"\"\"", "\n", "args", "=", "decode", "(", "args", ",", "data", ")", "\n", "args", "=", "tf", ".", "nest", ".", "pack_sequence_as", "(", "SampledUnrolls", "(", "unroll_specs", ",", "0", ",", "0", ")", ",", "args", ")", "\n", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "# loss: [batch_size]", "\n", "# priorities: [batch_size]", "\n", "        ", "loss", ",", "priorities", "=", "compute_loss_and_priorities", "(", "\n", "agent", ",", "\n", "target_agent", ",", "\n", "args", ".", "unrolls", ".", "agent_state", ",", "\n", "args", ".", "unrolls", ".", "prev_actions", ",", "\n", "args", ".", "unrolls", ".", "env_outputs", ",", "\n", "args", ".", "unrolls", ".", "agent_outputs", ",", "\n", "gamma", "=", "FLAGS", ".", "discounting", ",", "\n", "burn_in", "=", "FLAGS", ".", "burn_in", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", "*", "args", ".", "importance_weights", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "agent", ".", "trainable_variables", ")", "\n", "gradient_norm_before_clip", "=", "tf", ".", "linalg", ".", "global_norm", "(", "grads", ")", "\n", "if", "FLAGS", ".", "clip_norm", ":", "\n", "        ", "grads", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "\n", "grads", ",", "FLAGS", ".", "clip_norm", ",", "use_norm", "=", "gradient_norm_before_clip", ")", "\n", "\n", "", "for", "t", ",", "g", "in", "zip", "(", "temp_grads", ",", "grads", ")", ":", "\n", "        ", "t", ".", "assign", "(", "g", ")", "\n", "\n", "", "return", "loss", ",", "priorities", ",", "args", ".", "indices", ",", "gradient_norm_before_clip", "\n", "\n", "", "loss", ",", "priorities", ",", "indices", ",", "gradient_norm_before_clip", "=", "(", "\n", "training_strategy", ".", "run", "(", "compute_gradients", ",", "(", "data", ",", ")", ")", ")", "\n", "loss", "=", "training_strategy", ".", "experimental_local_results", "(", "loss", ")", "[", "0", "]", "\n", "\n", "def", "apply_gradients", "(", "loss", ")", ":", "\n", "      ", "optimizer", ".", "apply_gradients", "(", "zip", "(", "temp_grads", ",", "agent", ".", "trainable_variables", ")", ")", "\n", "return", "loss", "\n", "\n", "\n", "", "loss", "=", "strategy", ".", "run", "(", "apply_gradients", ",", "(", "loss", ",", ")", ")", "\n", "\n", "# convert PerReplica to a Tensor", "\n", "if", "not", "isinstance", "(", "priorities", ",", "tf", ".", "Tensor", ")", ":", "\n", "\n", "      ", "priorities", "=", "tf", ".", "reshape", "(", "tf", ".", "stack", "(", "priorities", ".", "values", ")", ",", "[", "-", "1", "]", ")", "\n", "indices", "=", "tf", ".", "reshape", "(", "tf", ".", "stack", "(", "indices", ".", "values", ")", ",", "[", "-", "1", "]", ")", "\n", "gradient_norm_before_clip", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "stack", "(", "gradient_norm_before_clip", ".", "values", ")", ",", "[", "-", "1", "]", ")", "\n", "gradient_norm_before_clip", "=", "tf", ".", "reduce_max", "(", "gradient_norm_before_clip", ")", "\n", "\n", "", "return", "loss", ",", "priorities", ",", "indices", ",", "gradient_norm_before_clip", "\n", "\n", "", "agent_output_specs", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "tf", ".", "TensorSpec", "(", "t", ".", "shape", "[", "1", ":", "]", ",", "t", ".", "dtype", ")", ",", "initial_agent_output", ")", "\n", "# Logging.", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "create_file_writer", "(", "\n", "FLAGS", ".", "logdir", ",", "flush_millis", "=", "20000", ",", "max_queue", "=", "1000", ")", "\n", "\n", "# Setup checkpointing and restore checkpoint.", "\n", "\n", "ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "agent", "=", "agent", ",", "target_agent", "=", "target_agent", ",", "optimizer", "=", "optimizer", ")", "\n", "manager", "=", "tf", ".", "train", ".", "CheckpointManager", "(", "\n", "ckpt", ",", "FLAGS", ".", "logdir", ",", "max_to_keep", "=", "1", ",", "keep_checkpoint_every_n_hours", "=", "6", ")", "\n", "last_ckpt_time", "=", "0", "# Force checkpointing of the initial model.", "\n", "if", "manager", ".", "latest_checkpoint", ":", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner_config.TrainingConfig.num_training_envs": [[105, 108], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "num_training_envs", "(", "self", ")", "->", "int", ":", "\n", "    ", "return", "self", ".", "num_envs", "-", "self", ".", "num_eval_envs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner_config.TrainingConfig.is_training_env": [[109, 112], ["None"], "methods", ["None"], ["", "def", "is_training_env", "(", "self", ",", "env_id", ")", "->", "bool", ":", "\n", "    ", "\"\"\"Training env IDs are in range [0, num_training_envs).\"\"\"", "\n", "return", "env_id", "<", "self", ".", "num_training_envs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.eval_utils.Evaluator.__init__": [[33, 47], ["seed_rl.common.utils.StructuredFIFOQueue", "collections.defaultdict", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "EpisodeInfo", "tuple", "range", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "print_episode_summaries", ",", "log_episode_frequency", "=", "1", ")", ":", "\n", "    ", "self", ".", "log_episode_frequency", "=", "log_episode_frequency", "\n", "self", ".", "info_specs", "=", "(", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "string", ",", "'eval_name'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int64", ",", "'episode_num_frames'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "float32", ",", "'episode_returns'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "float32", ",", "'episode_raw_returns'", ")", ",", "\n", ")", "\n", "self", ".", "episode_info_queue", "=", "utils", ".", "StructuredFIFOQueue", "(", "\n", "-", "1", ",", "EpisodeInfo", "(", "*", "self", ".", "info_specs", ")", ")", "\n", "# A map from env eval name to 4 lists that contain EpisodeInfo stats.", "\n", "self", ".", "eval_data", "=", "collections", ".", "defaultdict", "(", "\n", "lambda", ":", "tuple", "(", "[", "[", "]", "for", "_", "in", "range", "(", "len", "(", "EpisodeInfo", ".", "_fields", ")", ")", "]", ")", ")", "\n", "self", ".", "print_episode_summaries", "=", "print_episode_summaries", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.eval_utils.Evaluator.add": [[48, 51], ["eval_utils.Evaluator.episode_info_queue.enqueue", "EpisodeInfo"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.enqueue"], ["", "def", "add", "(", "self", ",", "data", ")", ":", "\n", "    ", "\"\"\"Adds data (which should have self.info_specs signature) to the queue.\"\"\"", "\n", "self", ".", "episode_info_queue", ".", "enqueue", "(", "EpisodeInfo", "(", "*", "data", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.eval_utils.Evaluator.add_many": [[52, 60], ["eval_utils.Evaluator.episode_info_queue.enqueue_many", "EpisodeInfo"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.enqueue_many"], ["", "def", "add_many", "(", "self", ",", "data", ")", ":", "\n", "    ", "\"\"\"Adds data (several items) to the queue.\n\n    Args:\n      data: tuple with shape self.info_specs with an additional batch front\n        dimension.\n    \"\"\"", "\n", "self", ".", "episode_info_queue", ".", "enqueue_many", "(", "EpisodeInfo", "(", "*", "data", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.eval_utils.Evaluator.reset": [[61, 65], ["eval_utils.Evaluator.eval_data.clear", "eval_utils.Evaluator.episode_info_queue.size", "eval_utils.Evaluator.episode_info_queue.dequeue_many", "eval_utils.Evaluator.episode_info_queue.size"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.dequeue_many"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "self", ".", "eval_data", ".", "clear", "(", ")", "\n", "while", "self", ".", "episode_info_queue", ".", "size", "(", ")", ":", "\n", "      ", "self", ".", "episode_info_queue", ".", "dequeue_many", "(", "self", ".", "episode_info_queue", ".", "size", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.eval_utils.Evaluator.process": [[66, 114], ["eval_utils.Evaluator.episode_info_queue.dequeue_many", "zip", "eval_utils.Evaluator.eval_data.items", "eval_utils.Evaluator.episode_info_queue.size", "EpisodeInfo", "EpisodeInfo.eval_name.numpy", "range", "range", "EpisodeInfo.episode_returns.numpy", "EpisodeInfo.episode_raw_returns.numpy", "EpisodeInfo.episode_num_frames.numpy", "absl.logging.info", "len", "[].append", "len", "episode_info[].numpy", "len", "tensorflow.reduce_mean", "tensorflow.math.reduce_std", "value[].clear", "tensorflow.constant", "key.decode", "tensorflow.summary.scalar", "tensorflow.summary.scalar"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.dequeue_many", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append"], ["", "", "def", "process", "(", "self", ",", "write_tf_summaries", "=", "True", ")", ":", "\n", "    ", "\"\"\"Processes the data from the queue.\n\n    The following steps are executed:\n     - stats are logged if print_episode_summaries is enabled\n     - stats are groupped into buckets of size >= self.log_episode_frequency\n       and then dumped as tf.summary.scalar and also returned in a dictionary.\n\n    Args:\n      write_tf_summaries: should TF.summaries be written on top of returning\n        stats.\n\n    Returns:\n        Evaluation stats.\n    \"\"\"", "\n", "episode_stats", "=", "self", ".", "episode_info_queue", ".", "dequeue_many", "(", "\n", "self", ".", "episode_info_queue", ".", "size", "(", ")", ")", "\n", "episode_summary_stats", "=", "{", "}", "\n", "\n", "for", "episode_info", "in", "zip", "(", "*", "episode_stats", ")", ":", "\n", "      ", "epinfo", "=", "EpisodeInfo", "(", "*", "episode_info", ")", "\n", "eval_name", "=", "epinfo", ".", "eval_name", ".", "numpy", "(", ")", "\n", "\n", "if", "self", ".", "print_episode_summaries", ":", "\n", "        ", "episode_returns", "=", "epinfo", ".", "episode_returns", ".", "numpy", "(", ")", "\n", "episode_raw_returns", "=", "epinfo", ".", "episode_raw_returns", ".", "numpy", "(", ")", "\n", "episode_num_frames", "=", "epinfo", ".", "episode_num_frames", ".", "numpy", "(", ")", "\n", "logging", ".", "info", "(", "'Return: %f Raw return: %f (key_prefix=\"%s\") Frames: %i'", ",", "\n", "episode_returns", ",", "episode_raw_returns", ",", "eval_name", ",", "\n", "episode_num_frames", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "1", ",", "len", "(", "EpisodeInfo", ".", "_fields", ")", ")", ":", "\n", "        ", "self", ".", "eval_data", "[", "eval_name", "]", "[", "i", "]", ".", "append", "(", "episode_info", "[", "i", "]", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "for", "key", ",", "value", "in", "self", ".", "eval_data", ".", "items", "(", ")", ":", "\n", "      ", "for", "i", "in", "range", "(", "1", ",", "len", "(", "EpisodeInfo", ".", "_fields", ")", ")", ":", "\n", "        ", "if", "len", "(", "value", "[", "i", "]", ")", ">=", "self", ".", "log_episode_frequency", ":", "\n", "          ", "v_mean", "=", "tf", ".", "reduce_mean", "(", "value", "[", "i", "]", ")", "\n", "v_std", "=", "tf", ".", "math", ".", "reduce_std", "(", "tf", ".", "constant", "(", "value", "[", "i", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "name", "=", "key", ".", "decode", "(", "'utf-8'", ")", "+", "EpisodeInfo", ".", "_fields", "[", "i", "]", "\n", "name_std", "=", "name", "+", "'_std'", "\n", "value", "[", "i", "]", ".", "clear", "(", ")", "\n", "if", "write_tf_summaries", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "name", ",", "v_mean", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "name_std", ",", "v_std", ")", "\n", "", "episode_summary_stats", "[", "name", "]", "=", "v_mean", "\n", "episode_summary_stats", "[", "name_std", "]", "=", "v_std", "\n", "", "", "", "return", "episode_summary_stats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner_flags.unroll_length_from_flags": [[95, 116], ["ValueError", "ValueError"], "function", ["None"], ["def", "unroll_length_from_flags", "(", ")", "->", "int", ":", "\n", "  ", "\"\"\"Returns the unroll length from the flags.\"\"\"", "\n", "if", "FLAGS", ".", "unroll_length", ">", "0", ":", "\n", "    ", "return", "FLAGS", ".", "unroll_length", "\n", "\n", "", "step_size_transitions", "=", "None", "\n", "if", "FLAGS", ".", "step_size_transitions", ">", "0", ":", "\n", "    ", "step_size_transitions", "=", "FLAGS", ".", "step_size_transitions", "\n", "", "elif", "FLAGS", ".", "batch_size_transitions", ">", "0", "and", "FLAGS", ".", "batches_per_step", ">", "0", ":", "\n", "    ", "step_size_transitions", "=", "(", "\n", "FLAGS", ".", "batch_size_transitions", "*", "FLAGS", ".", "batches_per_step", ")", "\n", "\n", "", "if", "step_size_transitions", "is", "None", ":", "\n", "    ", "raise", "ValueError", "(", "'Either flag `step_size_transitions` should be set or both'", "\n", "' flags `batch_size_transitions` and `batches_per_step` '", "\n", "'should be set.'", ")", "\n", "\n", "", "if", "step_size_transitions", "%", "FLAGS", ".", "num_envs", "!=", "0", ":", "\n", "    ", "raise", "ValueError", "(", "'Flag `step_size_transitions` needs to be divisible by'", "\n", "' the flag `num_envs`.'", ")", "\n", "", "return", "step_size_transitions", "//", "FLAGS", ".", "num_envs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner_flags.batch_size_from_flags": [[118, 129], ["ValueError", "learner_flags.unroll_length_from_flags", "ValueError"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner_flags.unroll_length_from_flags"], ["", "def", "batch_size_from_flags", "(", ")", "->", "int", ":", "\n", "  ", "\"\"\"Returns the batch size from flags.\"\"\"", "\n", "if", "FLAGS", ".", "batch_size", ">", "0", "and", "FLAGS", ".", "batch_size_transitions", "==", "0", ":", "\n", "    ", "return", "FLAGS", ".", "batch_size", "\n", "", "if", "FLAGS", ".", "batch_size", "==", "0", "and", "FLAGS", ".", "batch_size_transitions", ">", "0", ":", "\n", "    ", "unroll_length", "=", "unroll_length_from_flags", "(", ")", "\n", "if", "FLAGS", ".", "batch_size_transitions", "%", "unroll_length", "!=", "0", ":", "\n", "      ", "raise", "ValueError", "(", "'Flag `batch_size_transitions` needs to be divisible by'", "\n", "' the flag `unroll_length`.'", ")", "\n", "", "return", "FLAGS", ".", "batch_size_transitions", "//", "unroll_length", "\n", "", "raise", "ValueError", "(", "'Exactly one of the flags `batch_size_transitions` and '", "\n", "'`batch_size` needs to be non-zero.'", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner_flags.batches_per_step_from_flags": [[146, 166], ["learner_flags.batch_size_from_flags", "ValueError", "learner_flags.unroll_length_from_flags", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner_flags.batch_size_from_flags", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner_flags.unroll_length_from_flags"], ["def", "batches_per_step_from_flags", "(", ")", "->", "int", ":", "\n", "  ", "\"\"\"Returns the number of batches per step from flags.\"\"\"", "\n", "batch_size", "=", "batch_size_from_flags", "(", ")", "\n", "if", "(", "FLAGS", ".", "batches_per_step", ">", "0", "and", "FLAGS", ".", "step_size_unroll", "==", "0", "and", "\n", "FLAGS", ".", "step_size_transitions", "==", "0", ")", ":", "\n", "    ", "return", "FLAGS", ".", "batches_per_step", "\n", "", "if", "(", "FLAGS", ".", "batches_per_step", "==", "0", "and", "FLAGS", ".", "step_size_unroll", ">", "0", "and", "\n", "FLAGS", ".", "step_size_transitions", "==", "0", ")", ":", "\n", "    ", "if", "FLAGS", ".", "step_size_unroll", "%", "batch_size", "!=", "0", ":", "\n", "      ", "raise", "ValueError", "(", "'Flag `step_size_unroll` needs to be divisible by'", "\n", "' the `batch_size`.'", ")", "\n", "", "return", "FLAGS", ".", "step_size_unroll", "//", "batch_size", "\n", "", "if", "(", "FLAGS", ".", "batches_per_step", "==", "0", "and", "FLAGS", ".", "step_size_unroll", "==", "0", "and", "\n", "FLAGS", ".", "step_size_transitions", ">", "0", ")", ":", "\n", "    ", "unroll_length", "=", "unroll_length_from_flags", "(", ")", "\n", "if", "FLAGS", ".", "step_size_transitions", "%", "(", "batch_size", "*", "unroll_length", ")", "!=", "0", ":", "\n", "      ", "raise", "ValueError", "(", "'Flag `step_size_transitions` needs to be divisible by'", "\n", "' the `batch_size` x `unroll_length`.'", ")", "\n", "", "return", "FLAGS", ".", "step_size_transitions", "//", "(", "batch_size", "*", "unroll_length", ")", "\n", "", "raise", "ValueError", "(", "'Exactly one of the flags `batches_per_step`, '", "\n", "'`step_size_unroll` and `step_size_transitions` needs to be '", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner_flags.training_config_from_flags": [[183, 210], ["seed_rl.agents.policy_gradient.learner_config.TrainingConfig", "learner_flags.batch_size_from_flags", "learner_flags.batches_per_step_from_flags", "learner_flags.unroll_length_from_flags"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner_flags.batch_size_from_flags", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner_flags.batches_per_step_from_flags", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner_flags.unroll_length_from_flags"], ["def", "training_config_from_flags", "(", ")", "->", "learner_config", ".", "TrainingConfig", ":", "\n", "  ", "\"\"\"Returns training config from the command line flags.\"\"\"", "\n", "return", "learner_config", ".", "TrainingConfig", "(", "\n", "batch_mode", "=", "FLAGS", ".", "batch_mode", ",", "\n", "batch_size", "=", "batch_size_from_flags", "(", ")", ",", "\n", "batches_per_step", "=", "batches_per_step_from_flags", "(", ")", ",", "\n", "block_inference_on_training", "=", "FLAGS", ".", "block_inference_on_training", ",", "\n", "clip_norm", "=", "FLAGS", ".", "clip_norm", ",", "\n", "env_batch_size", "=", "FLAGS", ".", "env_batch_size", ",", "\n", "env_name", "=", "FLAGS", ".", "env_name", ",", "\n", "epochs_per_step", "=", "FLAGS", ".", "epochs_per_step", ",", "\n", "inference_batch_size", "=", "FLAGS", ".", "inference_batch_size", ",", "\n", "log_episode_frequency", "=", "FLAGS", ".", "log_episode_frequency", ",", "\n", "num_action_repeats", "=", "FLAGS", ".", "num_action_repeats", ",", "\n", "num_envs", "=", "FLAGS", ".", "num_envs", ",", "\n", "num_eval_envs", "=", "FLAGS", ".", "num_eval_envs", ",", "\n", "print_episode_summaries", "=", "FLAGS", ".", "print_episode_summaries", ",", "\n", "profile_inference_return", "=", "FLAGS", ".", "profile_inference_return", ",", "\n", "summary_flush_seconds", "=", "FLAGS", ".", "summary_flush_seconds", ",", "\n", "summary_max_queue_size", "=", "FLAGS", ".", "summary_max_queue_size", ",", "\n", "total_environment_frames", "=", "FLAGS", ".", "total_environment_frames", ",", "\n", "unroll_length", "=", "unroll_length_from_flags", "(", ")", ",", "\n", "num_checkpoints", "=", "FLAGS", ".", "num_checkpoints", ",", "\n", "num_saved_models", "=", "FLAGS", ".", "num_saved_models", ",", "\n", "prefetch_batches", "=", "FLAGS", ".", "prefetch_batches", ",", "\n", "server_address", "=", "FLAGS", ".", "server_address", ",", "\n", "save_checkpoint_secs", "=", "FLAGS", ".", "save_checkpoint_secs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.__init__": [[103, 420], ["learner.validate_config", "int", "tensorflow.Variable", "seed_rl.common.utils.ProgressLogger", "create_env_fn", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "seed_rl.common.utils.EnvOutput", "tensorflow.TensorSpec", "learner.Learner.build_new_agent", "learner.Learner.build_new_agent", "learner.Learner.inference_agent.initial_state", "tensorflow.nest.map_structure", "tensorflow.nest.map_structure", "learner.Learner.encode", "tensorflow.nest.map_structure", "tensorflow.nest.map_structure", "learner.Learner.__init__.add_batch_size"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.validate_config", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.build_new_agent", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.build_new_agent", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state"], ["# Information about a finished episode.", "\n", "EpisodeInfo", "=", "collections", ".", "namedtuple", "(", "\n", "'EpisodeInfo'", ",", "\n", "# num_frames: length of the episode in number of frames.", "\n", "# returns: Sum of undiscounted rewards experienced in the episode.", "\n", "# raw_returns: Sum of raw rewards experienced in the episode.", "\n", "# env_ids: ID of the environment that generated this episode.", "\n", "'num_frames returns raw_returns env_ids'", ")", "\n", "\n", "\n", "def", "get_replay_insertion_batch_size", "(", "per_replica", "=", "False", ")", ":", "\n", "  ", "if", "per_replica", ":", "\n", "    ", "return", "int", "(", "FLAGS", ".", "batch_size", "/", "FLAGS", ".", "replay_ratio", "/", "FLAGS", ".", "num_training_tpus", ")", "\n", "", "else", ":", "\n", "    ", "return", "int", "(", "FLAGS", ".", "batch_size", "/", "FLAGS", ".", "replay_ratio", ")", "\n", "\n", "\n", "", "", "def", "get_num_training_envs", "(", ")", ":", "\n", "  ", "return", "FLAGS", ".", "num_envs", "-", "FLAGS", ".", "num_eval_envs", "\n", "\n", "\n", "", "def", "is_training_env", "(", "env_id", ")", ":", "\n", "  ", "\"\"\"Training environment IDs are in range [0, num_training_envs).\"\"\"", "\n", "return", "env_id", "<", "get_num_training_envs", "(", ")", "\n", "\n", "\n", "", "def", "get_envs_epsilon", "(", "env_ids", ",", "num_training_envs", ",", "num_eval_envs", ",", "eval_epsilon", ")", ":", "\n", "  ", "\"\"\"Per-environment epsilon as in Apex and R2D2.\n\n  Args:\n    env_ids: <int32>[inference_batch_size], the environment task IDs (in range\n      [0, num_training_envs+num_eval_envs)).\n    num_training_envs: Number of training environments. Training environments\n      should have IDs in [0, num_training_envs).\n    num_eval_envs: Number of evaluation environments. Eval environments should\n      have IDs in [num_training_envs, num_training_envs + num_eval_envs).\n    eval_epsilon: Epsilon used for eval environments.\n\n  Returns:\n    A 1D float32 tensor with one epsilon for each input environment ID.\n  \"\"\"", "\n", "# <float32>[num_training_envs + num_eval_envs]", "\n", "epsilons", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "math", ".", "pow", "(", "0.4", ",", "tf", ".", "linspace", "(", "1.", ",", "8.", ",", "num", "=", "num_training_envs", ")", ")", ",", "\n", "tf", ".", "constant", "(", "[", "eval_epsilon", "]", "*", "num_eval_envs", ")", "]", ",", "\n", "axis", "=", "0", ")", "\n", "return", "tf", ".", "gather", "(", "epsilons", ",", "env_ids", ")", "\n", "\n", "\n", "", "def", "apply_epsilon_greedy", "(", "actions", ",", "env_ids", ",", "num_training_envs", ",", "\n", "num_eval_envs", ",", "eval_epsilon", ",", "num_actions", ")", ":", "\n", "  ", "\"\"\"Epsilon-greedy: randomly replace actions with given probability.\n\n  Args:\n    actions: <int32>[batch_size] tensor with one action per environment.\n    env_ids: <int32>[inference_batch_size], the environment task IDs (in range\n      [0, num_envs)).\n    num_training_envs: Number of training environments.\n    num_eval_envs: Number of eval environments.\n    eval_epsilon: Epsilon used for eval environments.\n    num_actions: Number of environment actions.\n\n  Returns:\n    A new <int32>[batch_size] tensor with one action per environment. With\n    probability epsilon, the new action is random, and with probability (1 -\n    epsilon), the action is unchanged, where epsilon is chosen for each\n    environment.\n  \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "actions", ")", "[", "0", "]", "\n", "epsilons", "=", "get_envs_epsilon", "(", "env_ids", ",", "num_training_envs", ",", "num_eval_envs", ",", "\n", "eval_epsilon", ")", "\n", "random_actions", "=", "tf", ".", "random", ".", "uniform", "(", "[", "batch_size", "]", ",", "maxval", "=", "num_actions", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", "\n", "probs", "=", "tf", ".", "random", ".", "uniform", "(", "shape", "=", "[", "batch_size", "]", ")", "\n", "return", "tf", ".", "where", "(", "tf", ".", "math", ".", "less", "(", "probs", ",", "epsilons", ")", ",", "random_actions", ",", "actions", ")", "\n", "\n", "\n", "", "def", "value_function_rescaling", "(", "x", ")", ":", "\n", "  ", "\"\"\"Value function rescaling per R2D2 paper, table 2.\"\"\"", "\n", "eps", "=", "FLAGS", ".", "value_function_rescaling_epsilon", "\n", "return", "tf", ".", "math", ".", "sign", "(", "x", ")", "*", "(", "tf", ".", "math", ".", "sqrt", "(", "tf", ".", "math", ".", "abs", "(", "x", ")", "+", "1.", ")", "-", "1.", ")", "+", "eps", "*", "x", "\n", "\n", "\n", "", "def", "inverse_value_function_rescaling", "(", "x", ")", ":", "\n", "  ", "\"\"\"See Proposition A.2 in paper \"Observe and Look Further\".\"\"\"", "\n", "eps", "=", "FLAGS", ".", "value_function_rescaling_epsilon", "\n", "return", "tf", ".", "math", ".", "sign", "(", "x", ")", "*", "(", "\n", "tf", ".", "math", ".", "square", "(", "(", "(", "tf", ".", "math", ".", "sqrt", "(", "\n", "1.", "+", "4.", "*", "eps", "*", "(", "tf", ".", "math", ".", "abs", "(", "x", ")", "+", "1.", "+", "eps", ")", ")", ")", "-", "1.", ")", "/", "(", "2.", "*", "eps", ")", ")", "-", "\n", "1.", ")", "\n", "\n", "\n", "", "def", "n_step_bellman_target", "(", "rewards", ",", "done", ",", "q_target", ",", "gamma", ",", "n_steps", ")", ":", "\n", "  ", "r\"\"\"Computes n-step Bellman targets.\n\n  See section 2.3 of R2D2 paper (which does not mention the logic around end of\n  episode).\n\n  Args:\n    rewards: <float32>[time, batch_size] tensor. This is r_t in the equations\n      below.\n    done: <bool>[time, batch_size] tensor. This is done_t in the equations\n      below. done_t should be true if the episode is done just after\n      experimenting reward r_t.\n    q_target: <float32>[time, batch_size] tensor. This is Q_target(s_{t+1}, a*)\n      (where a* is an action chosen by the caller).\n    gamma: Exponential RL discounting.\n    n_steps: The number of steps to look ahead for computing the Bellman\n      targets.\n\n  Returns:\n    y_t targets as <float32>[time, batch_size] tensor.\n    When n_steps=1, this is just:\n\n    $$r_t + gamma * (1 - done_t) * Q_{target}(s_{t+1}, a^*)$$\n\n    In the general case, this is:\n\n    $$(\\sum_{i=0}^{n-1} \\gamma ^ {i} * notdone_{t, i-1} * r_{t + i}) +\n      \\gamma ^ n * notdone_{t, n-1} * Q_{target}(s_{t + n}, a^*) $$\n\n    where notdone_{t,i} is defined as:\n\n    $$notdone_{t,i} = \\prod_{k=0}^{k=i}(1 - done_{t+k})$$\n\n    The last n_step-1 targets cannot be computed with n_step returns, since we\n    run out of Q_{target}(s_{t+n}). Instead, they will use n_steps-1, .., 1 step\n    returns. For those last targets, the last Q_{target}(s_{t}, a^*) is re-used\n    multiple times.\n  \"\"\"", "\n", "# We append n_steps - 1 times the last q_target. They are divided by gamma **", "\n", "# k to correct for the fact that they are at a 'fake' indice, and will", "\n", "# therefore end up being multiplied back by gamma ** k in the loop below.", "\n", "# We prepend 0s that will be discarded at the first iteration below.", "\n", "bellman_target", "=", "tf", ".", "concat", "(", "\n", "[", "tf", ".", "zeros_like", "(", "q_target", "[", "0", ":", "1", "]", ")", ",", "q_target", "]", "+", "\n", "[", "q_target", "[", "-", "1", ":", "]", "/", "gamma", "**", "k", "\n", "for", "k", "in", "range", "(", "1", ",", "n_steps", ")", "]", ",", "\n", "axis", "=", "0", ")", "\n", "# Pad with n_steps 0s. They will be used to compute the last n_steps-1", "\n", "# targets (having 0 values is important).", "\n", "done", "=", "tf", ".", "concat", "(", "[", "done", "]", "+", "[", "tf", ".", "zeros_like", "(", "done", "[", "0", ":", "1", "]", ")", "]", "*", "n_steps", ",", "axis", "=", "0", ")", "\n", "rewards", "=", "tf", ".", "concat", "(", "[", "rewards", "]", "+", "[", "tf", ".", "zeros_like", "(", "rewards", "[", "0", ":", "1", "]", ")", "]", "*", "n_steps", ",", "\n", "axis", "=", "0", ")", "\n", "# Iteratively build the n_steps targets. After the i-th iteration (1-based),", "\n", "# bellman_target is effectively the i-step returns.", "\n", "for", "_", "in", "range", "(", "n_steps", ")", ":", "\n", "    ", "rewards", "=", "rewards", "[", ":", "-", "1", "]", "\n", "done", "=", "done", "[", ":", "-", "1", "]", "\n", "bellman_target", "=", "(", "\n", "rewards", "+", "gamma", "*", "(", "1.", "-", "tf", ".", "cast", "(", "done", ",", "tf", ".", "float32", ")", ")", "*", "bellman_target", "[", "1", ":", "]", ")", "\n", "\n", "", "return", "bellman_target", "\n", "\n", "\n", "", "def", "compute_loss_and_priorities_from_agent_outputs", "(", "\n", "training_agent_output", ",", "\n", "target_agent_output", ",", "\n", "env_outputs", ",", "\n", "agent_outputs", ",", "\n", "gamma", ",", "eta", "=", "0.9", ")", ":", "\n", "  ", "\"\"\"Computes the loss to optimize and the new priorities.\n\n  This implements the n-step double DQN loss with the Q function computed on\n  sequences of transitions.\n\n  Args:\n    training_agent_output: AgentOutput where tensors have [unroll_length,\n      batch_size] front dimensions. Used for the Q values that should be\n      learned, and for computing the max over next actions as part of\n      double-DQN.\n    target_agent_output: AgentOutput used to compute the double-DQN target.\n    env_outputs: EnvOutputs where tensors have [unroll_length, batch_size]\n      additional front dimensions.\n    agent_outputs: AgentOutputs where tensors have [unroll_length, batch_size]\n      additional front dimensions.\n    gamma: RL discounting factor.\n    eta: float, parameter for balancing mean and max TD errors over a sequence\n      of transitions for computing its new priority.\n\n  Returns:\n    A pair:\n      - The loss for each unroll. Shape <float32>[batch_size]\n      - The new priorities for each unroll. Shape <float32>[batch_size].\n  \"\"\"", "\n", "num_actions", "=", "tf", ".", "shape", "(", "training_agent_output", ".", "q_values", ")", "[", "2", "]", "\n", "# <float32>[time, batch_size, num_actions].", "\n", "replay_action_one_hot", "=", "tf", ".", "one_hot", "(", "agent_outputs", ".", "action", ",", "num_actions", ",", "1.", ",", "0.", ")", "\n", "# This is Q(s, a), where a is the action played (can come from the agent or be", "\n", "# random). This is what we learn.", "\n", "# <float32>[time, batch_size].", "\n", "replay_q", "=", "tf", ".", "reduce_sum", "(", "\n", "training_agent_output", ".", "q_values", "*", "replay_action_one_hot", ",", "axis", "=", "2", ")", "\n", "\n", "# [time, batch_size, num_actions]", "\n", "best_actions_one_hot", "=", "tf", ".", "one_hot", "(", "\n", "training_agent_output", ".", "action", ",", "num_actions", ",", "1.", ",", "0.", ")", "\n", "# This is Q'(s) = h^(-1)(Q_target(s, \\argmax_a Q(s, a)))", "\n", "# [time, batch_size]", "\n", "qtarget_max", "=", "inverse_value_function_rescaling", "(", "tf", ".", "reduce_sum", "(", "\n", "target_agent_output", ".", "q_values", "*", "best_actions_one_hot", ",", "\n", "axis", "=", "2", ")", ")", "\n", "\n", "# [time, batch_size]", "\n", "bellman_target", "=", "tf", ".", "stop_gradient", "(", "n_step_bellman_target", "(", "\n", "env_outputs", ".", "reward", ",", "\n", "env_outputs", ".", "done", ",", "\n", "qtarget_max", ",", "\n", "gamma", ",", "\n", "FLAGS", ".", "n_steps", ")", ")", "\n", "\n", "# replay_q is actually Q(s_{t+1}, a_{t+1}), so we need to shift the targets.", "\n", "bellman_target", "=", "bellman_target", "[", "1", ":", ",", "...", "]", "\n", "\n", "replay_q", "=", "replay_q", "[", ":", "-", "1", ",", "...", "]", "\n", "\n", "bellman_target", "=", "value_function_rescaling", "(", "bellman_target", ")", "\n", "# [time, batch_size]", "\n", "abs_td_errors", "=", "tf", ".", "abs", "(", "bellman_target", "-", "replay_q", ")", "\n", "\n", "# [batch_size]", "\n", "priorities", "=", "(", "eta", "*", "tf", ".", "reduce_max", "(", "abs_td_errors", ",", "axis", "=", "0", ")", "+", "\n", "(", "1", "-", "eta", ")", "*", "tf", ".", "reduce_mean", "(", "abs_td_errors", ",", "axis", "=", "0", ")", ")", "\n", "\n", "# Sums over time dimension.", "\n", "loss", "=", "0.5", "*", "tf", ".", "reduce_sum", "(", "tf", ".", "math", ".", "square", "(", "abs_td_errors", ")", ",", "axis", "=", "0", ")", "\n", "\n", "return", "loss", ",", "priorities", "\n", "\n", "\n", "", "def", "compute_loss_and_priorities", "(", "\n", "training_agent", ",", "target_agent", ",", "\n", "agent_state", ",", "prev_actions", ",", "env_outputs", ",", "agent_outputs", ",", "\n", "gamma", ",", "burn_in", ")", ":", "\n", "  ", "\"\"\"Computes the loss to optimize and the new priorities.\n\n  This implements the n-step double DQN loss with the Q function computed on\n  sequences of transitions.\n\n  Args:\n    training_agent: Keras Model representing the training agent's network.\n    target_agent: Keras Model representing the target agent's network.\n    agent_state: Batched agent recurrent state at the beginning of each unroll.\n    prev_actions: <int32>[unroll_length, batch_size]. This is the action played\n      in the environment before each corresponding \"env_outputs\" (i.e. after\n      epsilon-greedy policy is applied).\n    env_outputs: EnvOutputs where tensors have [unroll_length, batch_size]\n      additional front dimensions.\n    agent_outputs: AgentOutputs where tensors have [unroll_length, batch_size]\n      additional front dimensions.\n    gamma: RL discounting factor.\n    burn_in: Number of time steps on which we update each recurrent state\n      without computing the loss nor propagating gradients.\n\n  Returns:\n    A pair:\n      - The loss for each unroll. Shape <float32>[batch_size]\n      - The new priorities for each unroll. Shape <float32>[batch_size].\n  \"\"\"", "\n", "if", "burn_in", ":", "\n", "    ", "agent_input_prefix", ",", "agent_input_suffix", "=", "utils", ".", "split_structure", "(", "\n", "(", "prev_actions", ",", "env_outputs", ")", ",", "burn_in", ")", "\n", "_", ",", "agent_outputs_suffix", "=", "utils", ".", "split_structure", "(", "agent_outputs", ",", "burn_in", ")", "\n", "_", ",", "training_state", "=", "training_agent", "(", "\n", "agent_input_prefix", ",", "agent_state", ",", "unroll", "=", "True", ")", "\n", "training_state", "=", "tf", ".", "nest", ".", "map_structure", "(", "tf", ".", "stop_gradient", ",", "training_state", ")", "\n", "_", ",", "target_state", "=", "target_agent", "(", "agent_input_prefix", ",", "agent_state", ",", "unroll", "=", "True", ")", "\n", "", "else", ":", "\n", "    ", "agent_input_suffix", "=", "(", "prev_actions", ",", "env_outputs", ")", "\n", "agent_outputs_suffix", "=", "agent_outputs", "\n", "training_state", "=", "agent_state", "\n", "target_state", "=", "agent_state", "\n", "\n", "# Agent outputs have fields with shape [time, batch_size, <field_shape>].", "\n", "", "training_agent_output", ",", "_", "=", "training_agent", "(", "\n", "agent_input_suffix", ",", "training_state", ",", "unroll", "=", "True", ")", "\n", "target_agent_output", ",", "_", "=", "target_agent", "(", "\n", "agent_input_suffix", ",", "target_state", ",", "unroll", "=", "True", ")", "\n", "_", ",", "env_outputs_suffix", "=", "agent_input_suffix", "\n", "return", "compute_loss_and_priorities_from_agent_outputs", "(", "\n", "training_agent_output", ",", "target_agent_output", ",", "env_outputs_suffix", ",", "\n", "agent_outputs_suffix", ",", "gamma", ")", "\n", "\n", "\n", "", "def", "create_dataset", "(", "unroll_queue", ",", "replay_buffer", ",", "strategy", ",", "batch_size", ",", "\n", "priority_exponent", ",", "encode", ")", ":", "\n", "  ", "\"\"\"Creates a dataset sampling from replay buffer.\n\n  This dataset will consume a batch of unrolls from 'unroll_queue', add it to\n  the replay buffer, and sample a batch of unrolls from it.\n\n  Args:\n    unroll_queue: Queue of 'Unroll' elements.\n    replay_buffer: Replay buffer of 'Unroll' elements.\n    strategy: A `distribute_lib.Strategy`.\n    batch_size: Batch size used for consuming the unroll queue and sampling from\n      the replay buffer.\n    priority_exponent: Priority exponent used for sampling from the replay\n      buffer.\n    encode: Function to encode the data for TPU, etc.\n\n  Returns:\n    A \"distributed `Dataset`\", which acts like a `tf.data.Dataset` except it\n    produces \"PerReplica\" values. Each iteration of the dataset produces\n    flattened `SampledUnrolls` structures where per-timestep tensors have front\n    dimensions [unroll_length, batch_size_per_replica].\n  \"\"\"", "\n", "\n", "@", "tf", ".", "function", "\n", "def", "dequeue", "(", "ctx", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.__del__": [[421, 424], ["host.unroll_queue.close"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.close"], ["\n", "per_replica_batch_size", "=", "ctx", ".", "get_per_replica_batch_size", "(", "batch_size", ")", "\n", "insertion_batch_size", "=", "get_replay_insertion_batch_size", "(", "per_replica", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.build_new_agent": [[425, 429], ["learner.Learner.create_agent_fn"], "methods", ["None"], ["print_every", "=", "tf", ".", "cast", "(", "\n", "insertion_batch_size", "*", "\n", "(", "1", "+", "FLAGS", ".", "replay_buffer_min_size", "//", "50", "//", "insertion_batch_size", ")", ",", "\n", "tf", ".", "int64", ")", "\n", "log_summary_every", "=", "tf", ".", "cast", "(", "insertion_batch_size", "*", "500", ",", "tf", ".", "int64", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.random_agent_variables": [[430, 435], ["learner.Learner.build_new_agent", "learner.Learner.inference_agent.initial_state", "learner.Learner.", "learner.Learner.decode"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.build_new_agent", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state"], ["\n", "while", "tf", ".", "constant", "(", "True", ")", ":", "\n", "# Each tensor in 'unrolls' has shape [insertion_batch_size, unroll_length,", "\n", "# <field-specific dimensions>].", "\n", "      ", "unrolls", "=", "unroll_queue", ".", "dequeue_many", "(", "insertion_batch_size", ")", "\n", "# The replay buffer is not threadsafe (and making it thread-safe might", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.generate_save_action_steps": [[436, 472], ["set", "set", "set", "sorted", "points.append", "numpy.linspace", "numpy.linspace", "numpy.linspace", "set.union", "SaveActionPoint", "points.append", "SaveActionPoint"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append"], ["# slow it down), which is why we insert and sample in a single thread, and", "\n", "# use TF Queues for passing data between threads.", "\n", "replay_buffer", ".", "insert", "(", "unrolls", ",", "unrolls", ".", "priority", ")", "\n", "if", "tf", ".", "equal", "(", "replay_buffer", ".", "num_inserted", "%", "log_summary_every", ",", "0", ")", ":", "\n", "# Unfortunately, there is no tf.summary(log_every_n_sec).", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "'initial_priorities'", ",", "unrolls", ".", "priority", ")", "\n", "", "if", "replay_buffer", ".", "num_inserted", ">=", "FLAGS", ".", "replay_buffer_min_size", ":", "\n", "        ", "break", "\n", "\n", "", "if", "tf", ".", "equal", "(", "replay_buffer", ".", "num_inserted", "%", "print_every", ",", "0", ")", ":", "\n", "        ", "tf", ".", "print", "(", "'Waiting for the replay buffer to fill up. '", "\n", "'It currently has'", ",", "replay_buffer", ".", "num_inserted", ",", "\n", "'elements, waiting for at least'", ",", "FLAGS", ".", "replay_buffer_min_size", ",", "\n", "'elements'", ")", "\n", "\n", "", "", "sampled_indices", ",", "weights", ",", "sampled_unrolls", "=", "replay_buffer", ".", "sample", "(", "\n", "per_replica_batch_size", ",", "priority_exponent", ")", "\n", "sampled_unrolls", "=", "sampled_unrolls", ".", "_replace", "(", "\n", "prev_actions", "=", "utils", ".", "make_time_major", "(", "sampled_unrolls", ".", "prev_actions", ")", ",", "\n", "env_outputs", "=", "utils", ".", "make_time_major", "(", "sampled_unrolls", ".", "env_outputs", ")", ",", "\n", "agent_outputs", "=", "utils", ".", "make_time_major", "(", "sampled_unrolls", ".", "agent_outputs", ")", ")", "\n", "sampled_unrolls", "=", "sampled_unrolls", ".", "_replace", "(", "\n", "env_outputs", "=", "encode", "(", "sampled_unrolls", ".", "env_outputs", ")", ")", "\n", "# tf.data.Dataset treats list leafs as tensors, so we need to flatten and", "\n", "# repack.", "\n", "return", "tf", ".", "nest", ".", "flatten", "(", "SampledUnrolls", "(", "\n", "sampled_unrolls", ",", "sampled_indices", ",", "weights", ")", ")", "\n", "\n", "", "def", "dataset_fn", "(", "ctx", ")", ":", "\n", "    ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensors", "(", "0", ")", ".", "repeat", "(", "None", ")", "\n", "return", "dataset", ".", "map", "(", "lambda", "_", ":", "dequeue", "(", "ctx", ")", ")", "\n", "\n", "", "return", "strategy", ".", "experimental_distribute_datasets_from_function", "(", "dataset_fn", ")", "\n", "\n", "\n", "", "def", "validate_config", "(", ")", ":", "\n", "  ", "utils", ".", "validate_learner_config", "(", "FLAGS", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.run_eval": [[473, 515], ["absl.logging.info", "learner.Learner.start_actor_loops", "learner.Learner.finalize", "host.deterministic_inference.assign", "host.store_unrolls_on_inference.assign", "learner.Learner.evaluator.process", "time.sleep", "host.deterministic_inference.assign", "host.store_unrolls_on_inference.assign"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.start_actor_loops", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.finalize", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.eval_utils.Evaluator.process"], ["assert", "FLAGS", ".", "n_steps", ">=", "1", ",", "'--n_steps < 1 does not make sense.'", "\n", "assert", "FLAGS", ".", "num_envs", ">", "FLAGS", ".", "num_eval_envs", ",", "(", "\n", "'Total number of environments ({}) should be greater than number of '", "\n", "'environments reserved to eval ({})'", ".", "format", "(", "\n", "FLAGS", ".", "num_envs", ",", "FLAGS", ".", "num_eval_envs", ")", ")", "\n", "\n", "\n", "", "def", "learner_loop", "(", "create_env_fn", ",", "create_agent_fn", ",", "create_optimizer_fn", ")", ":", "\n", "  ", "\"\"\"Main learner loop.\n\n  Args:\n    create_env_fn: Callable that must return a newly created environment. The\n      callable takes the task ID as argument - an arbitrary task ID of 0 will be\n      passed by the learner. The returned environment should follow GYM's API.\n      It is only used for infering tensor shapes. This environment will not be\n      used to generate experience.\n    create_agent_fn: Function that must create a new tf.Module with the neural\n      network that outputs actions, Q values and new agent state given the\n      environment observations and previous agent state. See\n      atari.agents.DuelingLSTMDQNNet for an example. The factory function takes\n      as input the environment output specs and the number of possible actions\n      in the env.\n    create_optimizer_fn: Function that takes the final iteration as argument\n      and must return a tf.keras.optimizers.Optimizer and a\n      tf.keras.optimizers.schedules.LearningRateSchedule.\n  \"\"\"", "\n", "logging", ".", "info", "(", "'Starting learner loop'", ")", "\n", "validate_config", "(", ")", "\n", "settings", "=", "utils", ".", "init_learner", "(", "FLAGS", ".", "num_training_tpus", ")", "\n", "strategy", ",", "inference_devices", ",", "training_strategy", ",", "encode", ",", "decode", "=", "settings", "\n", "env", "=", "create_env_fn", "(", "0", ",", "FLAGS", ")", "\n", "env_output_specs", "=", "utils", ".", "EnvOutput", "(", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "float32", ",", "'reward'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "bool", ",", "'done'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "env", ".", "observation_space", ".", "shape", ",", "env", ".", "observation_space", ".", "dtype", ",", "\n", "'observation'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "bool", ",", "'abandoned'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ",", "'episode_step'", ")", ",", "\n", ")", "\n", "action_specs", "=", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ",", "'action'", ")", "\n", "num_actions", "=", "env", ".", "action_space", ".", "n", "\n", "agent_input_specs", "=", "(", "action_specs", ",", "env_output_specs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.run_training": [[516, 586], ["absl.logging.info", "learner.Learner.start_actor_loops", "learner.Learner.generate_save_action_steps", "sum", "time.time", "learner.Learner.logger.shutdown", "learner.Learner.finalize", "TrainingResult", "learner.Learner.logger.start", "learner.Learner.minimize_loop", "learner.Learner.minimize_loop", "learner.Learner.logger.start", "max", "min", "learner.Learner.minimize_loop", "len", "tensorflow.constant", "tensorflow.constant", "time.time", "absl.logging.info", "time.time", "tensorflow.constant", "learner.Learner.get_state_fn", "snapshots.append", "learner.Learner.save_model", "learner.Learner.save_checkpoint", "math.ceil", "range", "Snapshot", "time.time", "learner.Learner.save_checkpoint", "steps_done.numpy", "steps_done.numpy"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.start_actor_loops", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.generate_save_action_steps", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.finalize", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.minimize_loop", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.minimize_loop", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.minimize_loop", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.get_state_fn", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.save_model", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.save_checkpoint", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.save_checkpoint"], ["# Initialize agent and variables.", "\n", "agent", "=", "create_agent_fn", "(", "env_output_specs", ",", "num_actions", ")", "\n", "target_agent", "=", "create_agent_fn", "(", "env_output_specs", ",", "num_actions", ")", "\n", "initial_agent_state", "=", "agent", ".", "initial_state", "(", "1", ")", "\n", "agent_state_specs", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "tf", ".", "TensorSpec", "(", "t", ".", "shape", "[", "1", ":", "]", ",", "t", ".", "dtype", ")", ",", "initial_agent_state", ")", "\n", "input_", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "s", ":", "tf", ".", "zeros", "(", "[", "1", "]", "+", "list", "(", "s", ".", "shape", ")", ",", "s", ".", "dtype", ")", ",", "agent_input_specs", ")", "\n", "input_", "=", "encode", "(", "input_", ")", "\n", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "\n", "    ", "@", "tf", ".", "function", "\n", "def", "create_variables", "(", "*", "args", ")", ":", "\n", "      ", "return", "agent", "(", "*", "decode", "(", "args", ")", ")", "\n", "\n", "", "@", "tf", ".", "function", "\n", "def", "create_target_agent_variables", "(", "*", "args", ")", ":", "\n", "      ", "return", "target_agent", "(", "*", "decode", "(", "args", ")", ")", "\n", "\n", "# The first call to Keras models to create varibales for agent and target.", "\n", "", "initial_agent_output", ",", "_", "=", "create_variables", "(", "input_", ",", "initial_agent_state", ")", "\n", "create_target_agent_variables", "(", "input_", ",", "initial_agent_state", ")", "\n", "\n", "@", "tf", ".", "function", "\n", "def", "update_target_agent", "(", ")", ":", "\n", "      ", "\"\"\"Synchronizes training and target agent variables.\"\"\"", "\n", "variables", "=", "agent", ".", "trainable_variables", "\n", "target_variables", "=", "target_agent", ".", "trainable_variables", "\n", "assert", "len", "(", "target_variables", ")", "==", "len", "(", "variables", ")", ",", "(", "\n", "'Mismatch in number of net tensors: {} != {}'", ".", "format", "(", "\n", "len", "(", "target_variables", ")", ",", "len", "(", "variables", ")", ")", ")", "\n", "for", "target_var", ",", "source_var", "in", "zip", "(", "target_variables", ",", "variables", ")", ":", "\n", "        ", "target_var", ".", "assign", "(", "source_var", ")", "\n", "\n", "# Create optimizer.", "\n", "", "", "iter_frame_ratio", "=", "(", "\n", "get_replay_insertion_batch_size", "(", ")", "*", "\n", "FLAGS", ".", "unroll_length", "*", "FLAGS", ".", "num_action_repeats", ")", "\n", "final_iteration", "=", "int", "(", "\n", "math", ".", "ceil", "(", "FLAGS", ".", "total_environment_frames", "/", "iter_frame_ratio", ")", ")", "\n", "optimizer", ",", "learning_rate_fn", "=", "create_optimizer_fn", "(", "final_iteration", ")", "\n", "\n", "\n", "iterations", "=", "optimizer", ".", "iterations", "\n", "optimizer", ".", "_create_hypers", "(", ")", "\n", "optimizer", ".", "_create_slots", "(", "agent", ".", "trainable_variables", ")", "\n", "\n", "# ON_READ causes the replicated variable to act as independent variables for", "\n", "# each replica.", "\n", "temp_grads", "=", "[", "\n", "tf", ".", "Variable", "(", "tf", ".", "zeros_like", "(", "v", ")", ",", "trainable", "=", "False", ",", "\n", "synchronization", "=", "tf", ".", "VariableSynchronization", ".", "ON_READ", ")", "\n", "for", "v", "in", "agent", ".", "trainable_variables", "\n", "]", "\n", "\n", "", "@", "tf", ".", "function", "\n", "def", "minimize", "(", "iterator", ")", ":", "\n", "    ", "\"\"\"Computes and applies gradients.\n\n    Args:\n      iterator: An iterator of distributed dataset that produces `PerReplica`.\n\n    Returns:\n      A tuple:\n        - priorities, the new priorities. Shape <float32>[batch_size].\n        - indices, the indices for updating priorities. Shape\n        <int32>[batch_size].\n        - gradient_norm_before_clip, a scalar.\n    \"\"\"", "\n", "data", "=", "next", "(", "iterator", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.get_state_fn": [[587, 616], ["learner.Learner.training_strategy.scope", "LearnerState", "zip", "zip", "zip", "learner.Learner.training_strategy.run", "dest.assign", "dest.assign", "learner.Learner.optimizer.variables", "dest.assign", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "learner.Learner.optimizer.variables"], "methods", ["None"], ["\n", "def", "compute_gradients", "(", "args", ")", ":", "\n", "      ", "\"\"\"A function to pass to `Strategy` for gradient computation.\"\"\"", "\n", "args", "=", "decode", "(", "args", ",", "data", ")", "\n", "args", "=", "tf", ".", "nest", ".", "pack_sequence_as", "(", "SampledUnrolls", "(", "unroll_specs", ",", "0", ",", "0", ")", ",", "args", ")", "\n", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "# loss: [batch_size]", "\n", "# priorities: [batch_size]", "\n", "        ", "loss", ",", "priorities", "=", "compute_loss_and_priorities", "(", "\n", "agent", ",", "\n", "target_agent", ",", "\n", "args", ".", "unrolls", ".", "agent_state", ",", "\n", "args", ".", "unrolls", ".", "prev_actions", ",", "\n", "args", ".", "unrolls", ".", "env_outputs", ",", "\n", "args", ".", "unrolls", ".", "agent_outputs", ",", "\n", "gamma", "=", "FLAGS", ".", "discounting", ",", "\n", "burn_in", "=", "FLAGS", ".", "burn_in", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", "*", "args", ".", "importance_weights", ")", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "loss", ",", "agent", ".", "trainable_variables", ")", "\n", "gradient_norm_before_clip", "=", "tf", ".", "linalg", ".", "global_norm", "(", "grads", ")", "\n", "if", "FLAGS", ".", "clip_norm", ":", "\n", "        ", "grads", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "\n", "grads", ",", "FLAGS", ".", "clip_norm", ",", "use_norm", "=", "gradient_norm_before_clip", ")", "\n", "\n", "", "for", "t", ",", "g", "in", "zip", "(", "temp_grads", ",", "grads", ")", ":", "\n", "        ", "t", ".", "assign", "(", "g", ")", "\n", "\n", "", "return", "loss", ",", "priorities", ",", "args", ".", "indices", ",", "gradient_norm_before_clip", "\n", "\n", "", "loss", ",", "priorities", ",", "indices", ",", "gradient_norm_before_clip", "=", "(", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.prepare_for_run": [[617, 717], ["learner.Learner.training_iterations.assign", "tensorflow.train.Checkpoint", "tensorflow.train.CheckpointManager", "learner.Learner.logger.reset", "learner.Learner.training_strategy.run", "learner.Learner.strategy.run", "learner.Learner.evaluator.reset", "absl.logging.info", "learner.Learner.ckpt.restore().assert_existing_objects_matched", "tensorflow.summary.create_file_writer", "learner.Learner.init_server", "host.completed_unrolls.assign", "unroll_queue.size", "isinstance", "unroll_queue.dequeue_up_to", "learner.Learner.ckpt.restore", "absl.logging.info", "learner.Learner.ckpt.restore().assert_existing_objects_matched", "learner.Learner.training_iterations.assign", "learner.Learner.training_iterations.read_value", "unroll_queue.size", "learner.Learner.training_strategy.scope", "learner.Learner.ckpt.restore", "learner.Learner.copy_to_training_agent_variables", "learner.Learner.copy_to_loss_fn_variables", "learner.Learner.copy_to_optimizer_variables"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.init_server"], ["training_strategy", ".", "run", "(", "compute_gradients", ",", "(", "data", ",", ")", ")", ")", "\n", "loss", "=", "training_strategy", ".", "experimental_local_results", "(", "loss", ")", "[", "0", "]", "\n", "\n", "def", "apply_gradients", "(", "loss", ")", ":", "\n", "      ", "optimizer", ".", "apply_gradients", "(", "zip", "(", "temp_grads", ",", "agent", ".", "trainable_variables", ")", ")", "\n", "return", "loss", "\n", "\n", "\n", "", "loss", "=", "strategy", ".", "run", "(", "apply_gradients", ",", "(", "loss", ",", ")", ")", "\n", "\n", "# convert PerReplica to a Tensor", "\n", "if", "not", "isinstance", "(", "priorities", ",", "tf", ".", "Tensor", ")", ":", "\n", "\n", "      ", "priorities", "=", "tf", ".", "reshape", "(", "tf", ".", "stack", "(", "priorities", ".", "values", ")", ",", "[", "-", "1", "]", ")", "\n", "indices", "=", "tf", ".", "reshape", "(", "tf", ".", "stack", "(", "indices", ".", "values", ")", ",", "[", "-", "1", "]", ")", "\n", "gradient_norm_before_clip", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "stack", "(", "gradient_norm_before_clip", ".", "values", ")", ",", "[", "-", "1", "]", ")", "\n", "gradient_norm_before_clip", "=", "tf", ".", "reduce_max", "(", "gradient_norm_before_clip", ")", "\n", "\n", "", "return", "loss", ",", "priorities", ",", "indices", ",", "gradient_norm_before_clip", "\n", "\n", "", "agent_output_specs", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "tf", ".", "TensorSpec", "(", "t", ".", "shape", "[", "1", ":", "]", ",", "t", ".", "dtype", ")", ",", "initial_agent_output", ")", "\n", "# Logging.", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "create_file_writer", "(", "\n", "FLAGS", ".", "logdir", ",", "flush_millis", "=", "20000", ",", "max_queue", "=", "1000", ")", "\n", "\n", "# Setup checkpointing and restore checkpoint.", "\n", "\n", "ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "\n", "agent", "=", "agent", ",", "target_agent", "=", "target_agent", ",", "optimizer", "=", "optimizer", ")", "\n", "manager", "=", "tf", ".", "train", ".", "CheckpointManager", "(", "\n", "ckpt", ",", "FLAGS", ".", "logdir", ",", "max_to_keep", "=", "1", ",", "keep_checkpoint_every_n_hours", "=", "6", ")", "\n", "last_ckpt_time", "=", "0", "# Force checkpointing of the initial model.", "\n", "if", "manager", ".", "latest_checkpoint", ":", "\n", "    ", "logging", ".", "info", "(", "'Restoring checkpoint: %s'", ",", "manager", ".", "latest_checkpoint", ")", "\n", "ckpt", ".", "restore", "(", "manager", ".", "latest_checkpoint", ")", ".", "assert_consumed", "(", ")", "\n", "last_ckpt_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "server", "=", "grpc", ".", "Server", "(", "[", "FLAGS", ".", "server_address", "]", ")", "\n", "\n", "# Buffer of incomplete unrolls. Filled during inference with new transitions.", "\n", "# This only contains data from training environments.", "\n", "store", "=", "utils", ".", "UnrollStore", "(", "\n", "get_num_training_envs", "(", ")", ",", "FLAGS", ".", "unroll_length", ",", "\n", "(", "action_specs", ",", "env_output_specs", ",", "agent_output_specs", ")", ",", "\n", "num_overlapping_steps", "=", "FLAGS", ".", "burn_in", ")", "\n", "env_run_ids", "=", "utils", ".", "Aggregator", "(", "FLAGS", ".", "num_envs", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int64", ",", "'run_ids'", ")", ")", "\n", "info_specs", "=", "(", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int64", ",", "'episode_num_frames'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "float32", ",", "'episode_returns'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "float32", ",", "'episode_raw_returns'", ")", ",", "\n", ")", "\n", "env_infos", "=", "utils", ".", "Aggregator", "(", "FLAGS", ".", "num_envs", ",", "info_specs", ",", "'env_infos'", ")", "\n", "\n", "# First agent state in an unroll.", "\n", "first_agent_states", "=", "utils", ".", "Aggregator", "(", "\n", "FLAGS", ".", "num_envs", ",", "agent_state_specs", ",", "'first_agent_states'", ")", "\n", "\n", "# Current agent state and action.", "\n", "agent_states", "=", "utils", ".", "Aggregator", "(", "\n", "FLAGS", ".", "num_envs", ",", "agent_state_specs", ",", "'agent_states'", ")", "\n", "actions", "=", "utils", ".", "Aggregator", "(", "FLAGS", ".", "num_envs", ",", "action_specs", ",", "'actions'", ")", "\n", "\n", "unroll_specs", "=", "Unroll", "(", "agent_state_specs", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "float32", ",", "'priority'", ")", ",", "\n", "*", "store", ".", "unroll_specs", ")", "\n", "# Queue of complete unrolls. Filled by the inference threads, and consumed by", "\n", "# the tf.data.Dataset thread.", "\n", "unroll_queue", "=", "utils", ".", "StructuredFIFOQueue", "(", "\n", "FLAGS", ".", "unroll_queue_max_size", ",", "unroll_specs", ")", "\n", "episode_info_specs", "=", "EpisodeInfo", "(", "*", "(", "\n", "info_specs", "+", "(", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ",", "'env_ids'", ")", ",", ")", ")", ")", "\n", "info_queue", "=", "utils", ".", "StructuredFIFOQueue", "(", "-", "1", ",", "episode_info_specs", ")", "\n", "\n", "replay_buffer", "=", "utils", ".", "PrioritizedReplay", "(", "FLAGS", ".", "replay_buffer_size", ",", "\n", "unroll_specs", ",", "\n", "FLAGS", ".", "importance_sampling_exponent", ")", "\n", "\n", "def", "add_batch_size", "(", "ts", ")", ":", "\n", "    ", "return", "tf", ".", "TensorSpec", "(", "[", "FLAGS", ".", "inference_batch_size", "]", "+", "list", "(", "ts", ".", "shape", ")", ",", "\n", "ts", ".", "dtype", ",", "ts", ".", "name", ")", "\n", "", "inference_iteration", "=", "tf", ".", "Variable", "(", "-", "1", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "inference_specs", "=", "(", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ",", "'env_id'", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int64", ",", "'run_id'", ")", ",", "\n", "env_output_specs", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "float32", ",", "'raw_reward'", ")", ",", "\n", ")", "\n", "inference_specs", "=", "tf", ".", "nest", ".", "map_structure", "(", "add_batch_size", ",", "inference_specs", ")", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "inference_specs", ")", "\n", "def", "inference", "(", "env_ids", ",", "run_ids", ",", "env_outputs", ",", "raw_rewards", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.finalize": [[718, 727], ["learner.Learner.stop_actor_loops", "learner.Learner.manager.save", "tensorflow.saved_model.save", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.stop_actor_loops"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.done": [[728, 732], ["None"], "methods", ["None"], ["\n", "# Reset the environments that had their first run or crashed.", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.copy_to_temp_per_replica_variables": [[733, 749], ["zip", "tensorflow.where", "tmp.assign", "tensorflow.distribute.get_replica_context", "tensorflow.zeros_like"], "methods", ["None"], ["previous_run_ids", "=", "env_run_ids", ".", "read", "(", "env_ids", ")", "\n", "env_run_ids", ".", "replace", "(", "env_ids", ",", "run_ids", ")", "\n", "reset_indices", "=", "tf", ".", "where", "(", "tf", ".", "not_equal", "(", "previous_run_ids", ",", "run_ids", ")", ")", "[", ":", ",", "0", "]", "\n", "envs_needing_reset", "=", "tf", ".", "gather", "(", "env_ids", ",", "reset_indices", ")", "\n", "if", "tf", ".", "not_equal", "(", "tf", ".", "shape", "(", "envs_needing_reset", ")", "[", "0", "]", ",", "0", ")", ":", "\n", "      ", "tf", ".", "print", "(", "'Environments needing reset:'", ",", "envs_needing_reset", ")", "\n", "", "env_infos", ".", "reset", "(", "envs_needing_reset", ")", "\n", "store", ".", "reset", "(", "tf", ".", "gather", "(", "\n", "envs_needing_reset", ",", "\n", "tf", ".", "where", "(", "is_training_env", "(", "envs_needing_reset", ")", ")", "[", ":", ",", "0", "]", ")", ")", "\n", "initial_agent_states", "=", "agent", ".", "initial_state", "(", "\n", "tf", ".", "shape", "(", "envs_needing_reset", ")", "[", "0", "]", ")", "\n", "first_agent_states", ".", "replace", "(", "envs_needing_reset", ",", "initial_agent_states", ")", "\n", "agent_states", ".", "replace", "(", "envs_needing_reset", ",", "initial_agent_states", ")", "\n", "actions", ".", "reset", "(", "envs_needing_reset", ")", "\n", "\n", "tf", ".", "debugging", ".", "assert_non_positive", "(", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.copy_to_inference_variables": [[750, 770], ["tensorflow.distribute.get_replica_context().merge_call", "strategy.extended.batch_reduce_to", "zip", "zip", "strategy.extended.update", "tensorflow.distribute.get_replica_context"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.update"], ["tf", ".", "cast", "(", "env_outputs", ".", "abandoned", ",", "tf", ".", "int32", ")", ",", "\n", "'Abandoned done states are not supported in R2D2.'", ")", "\n", "\n", "# Update steps and return.", "\n", "env_infos", ".", "add", "(", "env_ids", ",", "(", "0", ",", "env_outputs", ".", "reward", ",", "raw_rewards", ")", ")", "\n", "done_ids", "=", "tf", ".", "gather", "(", "env_ids", ",", "tf", ".", "where", "(", "env_outputs", ".", "done", ")", "[", ":", ",", "0", "]", ")", "\n", "done_episodes_info", "=", "env_infos", ".", "read", "(", "done_ids", ")", "\n", "info_queue", ".", "enqueue_many", "(", "EpisodeInfo", "(", "*", "(", "done_episodes_info", "+", "(", "done_ids", ",", ")", ")", ")", ")", "\n", "env_infos", ".", "reset", "(", "done_ids", ")", "\n", "env_infos", ".", "add", "(", "env_ids", ",", "(", "FLAGS", ".", "num_action_repeats", ",", "0.", ",", "0.", ")", ")", "\n", "\n", "# Inference.", "\n", "prev_actions", "=", "actions", ".", "read", "(", "env_ids", ")", "\n", "input_", "=", "encode", "(", "(", "prev_actions", ",", "env_outputs", ")", ")", "\n", "prev_agent_states", "=", "agent_states", ".", "read", "(", "env_ids", ")", "\n", "def", "make_inference_fn", "(", "inference_device", ")", ":", "\n", "      ", "def", "device_specific_inference_fn", "(", ")", ":", "\n", "        ", "with", "tf", ".", "device", "(", "inference_device", ")", ":", "\n", "          ", "@", "tf", ".", "function", "\n", "def", "agent_inference", "(", "*", "args", ")", ":", "\n", "            ", "return", "agent", "(", "*", "decode", "(", "args", ")", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.create_dataset": [[771, 808], ["learner.Learner.training_strategy.experimental_distribute_datasets_from_function", "tensorflow.nest.map_structure", "env_outputs._replace._replace._replace", "env_outputs._replace._replace._replace", "tensorflow.nest.flatten", "tensorflow.data.Dataset.from_tensors().repeat", "tensorflow.data.Dataset.from_tensors().repeat.map", "learner.Learner.create_dataset.dequeue"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.dequeue"], ["\n", "", "return", "agent_inference", "(", "input_", ",", "prev_agent_states", ")", "\n", "\n", "", "", "return", "device_specific_inference_fn", "\n", "\n", "# Distribute the inference calls among the inference cores.", "\n", "", "branch_index", "=", "tf", ".", "cast", "(", "\n", "inference_iteration", ".", "assign_add", "(", "1", ")", "%", "len", "(", "inference_devices", ")", ",", "tf", ".", "int32", ")", "\n", "agent_outputs", ",", "curr_agent_states", "=", "tf", ".", "switch_case", "(", "branch_index", ",", "{", "\n", "i", ":", "make_inference_fn", "(", "inference_device", ")", "\n", "for", "i", ",", "inference_device", "in", "enumerate", "(", "inference_devices", ")", "\n", "}", ")", "\n", "\n", "agent_outputs", "=", "agent_outputs", ".", "_replace", "(", "\n", "action", "=", "apply_epsilon_greedy", "(", "\n", "agent_outputs", ".", "action", ",", "env_ids", ",", "\n", "get_num_training_envs", "(", ")", ",", "\n", "FLAGS", ".", "num_eval_envs", ",", "FLAGS", ".", "eval_epsilon", ",", "num_actions", ")", ")", "\n", "\n", "# Append the latest outputs to the unroll, only for experience coming from", "\n", "# training environments (IDs < num_training_envs), and insert completed", "\n", "# unrolls in queue.", "\n", "# <int64>[num_training_envs]", "\n", "training_indices", "=", "tf", ".", "where", "(", "is_training_env", "(", "env_ids", ")", ")", "[", ":", ",", "0", "]", "\n", "training_env_ids", "=", "tf", ".", "gather", "(", "env_ids", ",", "training_indices", ")", "\n", "training_prev_actions", ",", "training_env_outputs", ",", "training_agent_outputs", "=", "(", "\n", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "s", ":", "tf", ".", "gather", "(", "s", ",", "training_indices", ")", ",", "\n", "(", "prev_actions", ",", "env_outputs", ",", "agent_outputs", ")", ")", ")", "\n", "\n", "append_to_store", "=", "(", "\n", "training_prev_actions", ",", "training_env_outputs", ",", "training_agent_outputs", ")", "\n", "completed_ids", ",", "completed_unrolls", "=", "store", ".", "append", "(", "\n", "training_env_ids", ",", "append_to_store", ")", "\n", "_", ",", "unrolled_env_outputs", ",", "unrolled_agent_outputs", "=", "completed_unrolls", "\n", "unrolled_agent_states", "=", "first_agent_states", ".", "read", "(", "completed_ids", ")", "\n", "\n", "# Only use the suffix of the unrolls that is actually used for training. The", "\n", "# prefix is only used for burn-in of agent state at training time.", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.pull_batch_from_unroll_queue": [[809, 837], ["learner.Learner.training_strategy.experimental_distribute_values_from_function", "tensorflow.nest.map_structure", "env_outputs._replace._replace._replace", "env_outputs._replace._replace._replace", "tensorflow.nest.flatten", "len", "len", "tensorflow.stack", "seed_rl.common.utils.make_time_major", "seed_rl.common.utils.make_time_major", "seed_rl.common.utils.make_time_major", "learner.Learner.encode", "learner.Learner.hosts[].unroll_queue.dequeue", "range"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.make_time_major", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.make_time_major", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.make_time_major", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.dequeue"], ["_", ",", "agent_outputs_suffix", "=", "utils", ".", "split_structure", "(", "\n", "utils", ".", "make_time_major", "(", "unrolled_agent_outputs", ")", ",", "FLAGS", ".", "burn_in", ")", "\n", "_", ",", "env_outputs_suffix", "=", "utils", ".", "split_structure", "(", "\n", "\n", "utils", ".", "make_time_major", "(", "unrolled_env_outputs", ")", ",", "FLAGS", ".", "burn_in", ")", "\n", "_", ",", "initial_priorities", "=", "compute_loss_and_priorities_from_agent_outputs", "(", "\n", "# We don't use the outputs from a separated target network for computing", "\n", "# initial priorities.", "\n", "agent_outputs_suffix", ",", "\n", "agent_outputs_suffix", ",", "\n", "env_outputs_suffix", ",", "\n", "agent_outputs_suffix", ",", "\n", "gamma", "=", "FLAGS", ".", "discounting", ")", "\n", "\n", "unrolls", "=", "Unroll", "(", "unrolled_agent_states", ",", "initial_priorities", ",", "\n", "*", "completed_unrolls", ")", "\n", "unroll_queue", ".", "enqueue_many", "(", "unrolls", ")", "\n", "first_agent_states", ".", "replace", "(", "completed_ids", ",", "\n", "agent_states", ".", "read", "(", "completed_ids", ")", ")", "\n", "\n", "# Update current state.", "\n", "agent_states", ".", "replace", "(", "env_ids", ",", "curr_agent_states", ")", "\n", "actions", ".", "replace", "(", "env_ids", ",", "agent_outputs", ".", "action", ")", "\n", "\n", "# Return environment actions to environments.", "\n", "return", "agent_outputs", ".", "action", "\n", "\n", "", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "    ", "server", ".", "bind", "(", "inference", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.minimize": [[838, 890], ["absl.logging.info", "training_strategy.run", "learner.Learner.logger.step_end", "absl.logging.info", "next", "learner.Learner.pull_batch_from_unroll_queue", "learner.Learner.decode", "tensorflow.nest.pack_sequence_as", "hasattr", "seed_rl.agents.policy_gradient.modules.ppo_training_step_utils.ppo_training_step", "learner.Learner.copy_to_temp_per_replica_variables", "training_strategy.experimental_local_results", "tensorflow.control_dependencies", "learner.Learner.strategy.run", "learner.Learner.training_iterations.assign_add", "learner.Learner.training_agent.update_observation_normalization_statistics"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.step_end", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.pull_batch_from_unroll_queue", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.ppo_training_step_utils.ppo_training_step", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.copy_to_temp_per_replica_variables", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent.update_observation_normalization_statistics"], ["", "server", ".", "start", "(", ")", "\n", "\n", "# Execute learning and track performance.", "\n", "with", "summary_writer", ".", "as_default", "(", ")", ",", "concurrent", ".", "futures", ".", "ThreadPoolExecutor", "(", "max_workers", "=", "1", ")", "as", "executor", ":", "\n", "    ", "log_future", "=", "executor", ".", "submit", "(", "lambda", ":", "None", ")", "# No-op future.", "\n", "tf", ".", "summary", ".", "experimental", ".", "set_step", "(", "iterations", "*", "iter_frame_ratio", ")", "\n", "dataset", "=", "create_dataset", "(", "unroll_queue", ",", "replay_buffer", ",", "training_strategy", ",", "\n", "FLAGS", ".", "batch_size", ",", "FLAGS", ".", "priority_exponent", ",", "encode", ")", "\n", "it", "=", "iter", "(", "dataset", ")", "\n", "\n", "last_num_env_frames", "=", "iterations", "*", "iter_frame_ratio", "\n", "last_log_time", "=", "time", ".", "time", "(", ")", "\n", "max_gradient_norm_before_clip", "=", "0.", "\n", "while", "iterations", "<", "final_iteration", ":", "\n", "      ", "num_env_frames", "=", "iterations", "*", "iter_frame_ratio", "\n", "tf", ".", "summary", ".", "experimental", ".", "set_step", "(", "num_env_frames", ")", "\n", "\n", "if", "iterations", ".", "numpy", "(", ")", "%", "FLAGS", ".", "update_target_every_n_step", "==", "0", ":", "\n", "        ", "update_target_agent", "(", ")", "\n", "\n", "# Save checkpoint.", "\n", "", "current_time", "=", "time", ".", "time", "(", ")", "\n", "if", "current_time", "-", "last_ckpt_time", ">=", "FLAGS", ".", "save_checkpoint_secs", ":", "\n", "        ", "manager", ".", "save", "(", ")", "\n", "last_ckpt_time", "=", "current_time", "\n", "\n", "", "def", "log", "(", "num_env_frames", ")", ":", "\n", "        ", "\"\"\"Logs environment summaries.\"\"\"", "\n", "summary_writer", ".", "set_as_default", "(", ")", "\n", "tf", ".", "summary", ".", "experimental", ".", "set_step", "(", "num_env_frames", ")", "\n", "episode_info", "=", "info_queue", ".", "dequeue_many", "(", "info_queue", ".", "size", "(", ")", ")", "\n", "for", "n", ",", "r", ",", "_", ",", "env_id", "in", "zip", "(", "*", "episode_info", ")", ":", "\n", "          ", "is_training", "=", "is_training_env", "(", "env_id", ")", "\n", "logging", ".", "info", "(", "\n", "'Return: %f Frames: %i Env id: %i (%s) Iteration: %i'", ",", "\n", "r", ",", "n", ",", "env_id", ",", "\n", "'training'", "if", "is_training", "else", "'eval'", ",", "\n", "iterations", ".", "numpy", "(", ")", ")", "\n", "if", "not", "is_training", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "'eval/episode_return'", ",", "r", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'eval/episode_frames'", ",", "n", ")", "\n", "", "", "", "log_future", ".", "result", "(", ")", "# Raise exception if any occurred in logging.", "\n", "log_future", "=", "executor", ".", "submit", "(", "log", ",", "num_env_frames", ")", "\n", "\n", "_", ",", "priorities", ",", "indices", ",", "gradient_norm", "=", "minimize", "(", "it", ")", "\n", "\n", "replay_buffer", ".", "update_priorities", "(", "indices", ",", "priorities", ")", "\n", "# Max of gradient norms (before clipping) since last tf.summary export.", "\n", "max_gradient_norm_before_clip", "=", "max", "(", "gradient_norm", ".", "numpy", "(", ")", ",", "\n", "max_gradient_norm_before_clip", ")", "\n", "if", "current_time", "-", "last_log_time", ">=", "120", ":", "\n", "        ", "df", "=", "tf", ".", "cast", "(", "num_env_frames", "-", "last_num_env_frames", ",", "tf", ".", "float32", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.minimize_loop": [[891, 896], ["tensorflow.cast", "learner.Learner.training_iterations.read_value", "learner.Learner.minimize"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.minimize"], ["dt", "=", "time", ".", "time", "(", ")", "-", "last_log_time", "\n", "tf", ".", "summary", ".", "scalar", "(", "'num_environment_frames/sec (actors)'", ",", "df", "/", "dt", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'num_environment_frames/sec (learner)'", ",", "\n", "df", "/", "dt", "*", "FLAGS", ".", "replay_ratio", ")", "\n", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate_fn", "(", "iterations", ")", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.init_server": [[897, 1126], ["enumerate", "tensorflow.device", "absl.logging.info", "seed_rl.grpc.Server", "tensorflow.function", "tensorflow.function", "tensorflow.function", "tensorflow.math.floordiv", "tensorflow.function", "tensorflow.function", "host.unroll_queue.enqueue_many", "learner.Learner.strategy.scope", "seed_rl.grpc.Server.bind", "seed_rl.grpc.Server.bind", "seed_rl.grpc.Server.bind", "seed_rl.grpc.Server.bind", "learner.Learner.training_iterations.read_value", "tensorflow.reduce_sum", "learner.Learner.logger.log_session", "learner.Learner.logger.step_end", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "learner.Learner.evaluator.add_many", "learner.Learner.evaluator.add_many", "host.inference_iterations.assign_add", "host.env_run_ids.read", "tensorflow.not_equal", "tensorflow.boolean_mask", "seed_rl.common.utils.get_non_dying_envs", "host.env_run_ids.replace", "tensorflow.not_equal", "learner.Learner.inference_agent.initial_state", "host.agent_states.replace", "host.actions.reset", "host.actions.read", "learner.Learner.encode", "host.agent_states.read", "host.agent_states.replace", "host.actions.replace", "learner.Learner.evaluator.add", "Unroll", "learner.Learner.init_server.get_config_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.enqueue_many", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.python.ops.Server.bind", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log_session", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.step_end", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.eval_utils.Evaluator.add_many", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.eval_utils.Evaluator.add_many", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.read", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.get_non_dying_envs", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.replace", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.replace", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.read", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.read", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.replace", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.replace", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.add"], ["tf", ".", "summary", ".", "scalar", "(", "'replay_buffer_num_inserted'", ",", "\n", "replay_buffer", ".", "num_inserted", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'unroll_queue_size'", ",", "unroll_queue", ".", "size", "(", ")", ")", "\n", "\n", "last_num_env_frames", ",", "last_log_time", "=", "num_env_frames", ",", "time", ".", "time", "(", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "'updated_priorities'", ",", "priorities", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'max_gradient_norm_before_clip'", ",", "\n", "max_gradient_norm_before_clip", ")", "\n", "max_gradient_norm_before_clip", "=", "0.", "\n", "\n", "", "", "", "manager", ".", "save", "(", ")", "\n", "server", ".", "shutdown", "(", ")", "\n", "unroll_queue", ".", "close", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.start_actor_loops": [[1127, 1133], ["tensorflow.device", "host.server.start"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.stop_actor_loops": [[1134, 1142], ["host.server.shutdown"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.save_checkpoint": [[1143, 1148], ["learner.Learner.manager.save", "absl.logging.info"], "methods", ["None"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.save_model": [[1149, 1165], ["tensorflow.saved_model.save", "os.path.join", "os.path.join", "str"], "methods", ["None"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.additional_logs": [[1166, 1192], ["tensorflow.summary.scalar", "tensorflow.summary.scalar", "time.time", "tensorflow.reduce_sum", "learner.Learner.evaluator.process", "learner.Learner.learning_rate_fn", "learner.Learner.hosts[].unroll_queue.size", "tensorflow.cast", "tensorflow.summary.scalar"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.eval_utils.Evaluator.process"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.validate_config": [[69, 78], ["len", "seed_rl.common.utils.validate_learner_config"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.validate_learner_config"], ["flags", ".", "DEFINE_integer", "(", "'unroll_queue_max_size'", ",", "100", ",", "\n", "'Max size of the unroll queue'", ")", "\n", "flags", ".", "DEFINE_integer", "(", "'burn_in'", ",", "40", ",", "\n", "'Length of the RNN burn-in prefix. This is the number of '", "\n", "'time steps on which we update each stored RNN state '", "\n", "'before computing the actual loss. The effective length '", "\n", "'of unrolls will be burn_in + unroll_length, and two '", "\n", "'consecutive unrolls will overlap on burn_in steps.'", ")", "\n", "flags", ".", "DEFINE_float", "(", "'importance_sampling_exponent'", ",", "0.6", ",", "\n", "'Exponent used when computing the importance sampling '", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.learner_loop": [[1194, 1234], ["learner.Learner", "learner.Learner.prepare_for_run", "learner.Learner.run_training"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.prepare_for_run", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.run_training"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module._LoggingDict.__init__": [[48, 50], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dict_", ")", ":", "\n", "    ", "self", ".", "_dict", "=", "dict_", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module._LoggingDict.__setitem__": [[51, 53], ["None"], "methods", ["None"], ["", "def", "__setitem__", "(", "self", ",", "key", ",", "item", ")", ":", "\n", "    ", "self", ".", "_dict", "[", "key", "]", "=", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module._LoggingDict.__getitem__": [[54, 56], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "key", ")", ":", "\n", "    ", "return", "self", ".", "_dict", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module._LoggingDict.__repr__": [[57, 59], ["repr"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "    ", "return", "repr", "(", "self", ".", "_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module._LoggingDict.__len__": [[60, 62], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "self", ".", "_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module._LoggingDict.__delitem__": [[63, 65], ["None"], "methods", ["None"], ["", "def", "__delitem__", "(", "self", ",", "key", ")", ":", "\n", "    ", "del", "self", ".", "_dict", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module._LoggingDict.__getattr__": [[66, 68], ["getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "    ", "return", "getattr", "(", "self", ".", "_dict", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module._LoggingDict.__contains__": [[69, 71], ["None"], "methods", ["None"], ["", "def", "__contains__", "(", "self", ",", "item", ")", ":", "\n", "    ", "return", "item", "in", "self", ".", "_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module._LoggingDict.__iter__": [[72, 74], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "    ", "return", "iter", "(", "self", ".", "_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module.LoggingModule.log": [[80, 88], ["ValueError", "tensorflow.is_tensor", "ValueError"], "methods", ["None"], ["def", "log", "(", "self", ",", "key", ",", "tensor", ")", ":", "\n", "    ", "\"\"\"Registers `tensor` as `key` for logging.\"\"\"", "\n", "if", "self", ".", "_logging_dict", "is", "not", "None", ":", "\n", "      ", "if", "key", "in", "self", ".", "_logging_dict", ":", "\n", "        ", "raise", "ValueError", "(", "'Logging key already exists in current contex.'", ")", "\n", "", "if", "not", "tf", ".", "is_tensor", "(", "tensor", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'`tensor` needs to be a Tensor.'", ")", "\n", "", "self", ".", "_logging_dict", "[", "key", "]", "=", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module.LoggingModule.set_logging_dict": [[89, 97], ["logging_module._LoggingDict", "isinstance", "ValueError", "logging_module.ModuleAlreadyTapedError", "str"], "methods", ["None"], ["", "", "def", "set_logging_dict", "(", "self", ",", "logging_dict", ")", ":", "\n", "    ", "\"\"\"Sets the logging dict.\"\"\"", "\n", "if", "not", "isinstance", "(", "logging_dict", ",", "dict", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'`logging_dict` is not a dict.'", ")", "\n", "", "if", "self", ".", "_logging_dict", "is", "not", "None", ":", "\n", "      ", "raise", "ModuleAlreadyTapedError", "(", "'Submodule `%s` is already taped.'", "%", "\n", "str", "(", "self", ")", ")", "\n", "", "self", ".", "_logging_dict", "=", "_LoggingDict", "(", "logging_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module.LoggingModule.unset_logging_dict": [[98, 101], ["None"], "methods", ["None"], ["", "def", "unset_logging_dict", "(", "self", ")", ":", "\n", "    ", "\"\"\"Unsets the current logging dict.\"\"\"", "\n", "self", ".", "_logging_dict", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module.LoggingTape.__init__": [[113, 126], ["isinstance", "list", "list"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tracked_modules", ")", ":", "\n", "    ", "\"\"\"Creates a LoggingTape.\n\n    Args:\n      tracked_modules: Specifies a list of tf.Modules from which tensors should\n        be collected for logging (if they are LoggingModules) Can either be a\n        list of tf.Modules or a single tf.Module, in which case the tracked set\n        of modules consists of the tf.Module and its set of submodules at\n        construction time of the LoggingTape.\n    \"\"\"", "\n", "if", "isinstance", "(", "tracked_modules", ",", "tf", ".", "Module", ")", ":", "\n", "      ", "tracked_modules", "=", "[", "tracked_modules", "]", "+", "list", "(", "tracked_modules", ".", "submodules", ")", "\n", "", "self", ".", "_tracked_modules", "=", "list", "(", "tracked_modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module.LoggingTape.__enter__": [[127, 135], ["collections.OrderedDict", "submodule.set_logging_dict", "isinstance"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module.LoggingModule.set_logging_dict"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "    ", "\"\"\"Enters the context manager.\"\"\"", "\n", "logged_tensors", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "submodule", "in", "self", ".", "_tracked_modules", ":", "\n", "      ", "if", "not", "isinstance", "(", "submodule", ",", "LoggingModule", ")", ":", "\n", "        ", "continue", "\n", "", "submodule", ".", "set_logging_dict", "(", "logged_tensors", ")", "\n", "", "return", "logged_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module.LoggingTape.__exit__": [[136, 143], ["submodule.unset_logging_dict", "isinstance"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module.LoggingModule.unset_logging_dict"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_value", ",", "traceback", ")", ":", "\n", "    ", "\"\"\"Exits the context manager.\"\"\"", "\n", "del", "exc_type", ",", "exc_value", ",", "traceback", "\n", "for", "submodule", "in", "self", ".", "_tracked_modules", ":", "\n", "      ", "if", "not", "isinstance", "(", "submodule", ",", "LoggingModule", ")", ":", "\n", "        ", "continue", "\n", "", "submodule", ".", "unset_logging_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.AdvantagePreprocessorTest.test_normalization": [[24, 30], ["tensorflow.constant", "policy_losses_test.AdvantagePreprocessorTest.assertAllClose", "policy_losses_test.AdvantagePreprocessorTest.assertAllClose", "tensorflow.reduce_mean", "tensorflow.math.reduce_std", "seed_rl.agents.policy_gradient.modules.policy_losses.AdvantagePreprocessor"], "methods", ["None"], ["  ", "def", "test_normalization", "(", "self", ")", ":", "\n", "    ", "adv", "=", "tf", ".", "constant", "(", "[", "1.5", ",", "4.", ",", "123.", ",", "-", "3.", "]", ")", "\n", "adv", "=", "policy_losses", ".", "AdvantagePreprocessor", "(", "normalize", "=", "True", ")", "(", "adv", ")", "[", "0", "]", "\n", "assert", "adv", ".", "shape", "==", "(", "4", ",", ")", "\n", "self", ".", "assertAllClose", "(", "tf", ".", "reduce_mean", "(", "adv", ")", ",", "0.", ")", "\n", "self", ".", "assertAllClose", "(", "tf", ".", "math", ".", "reduce_std", "(", "adv", ")", ",", "1", ",", "atol", "=", "0.01", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.AdvantagePreprocessorTest.test_only_positive": [[31, 35], ["tensorflow.constant", "policy_losses_test.AdvantagePreprocessorTest.assertAllClose", "seed_rl.agents.policy_gradient.modules.policy_losses.AdvantagePreprocessor"], "methods", ["None"], ["", "def", "test_only_positive", "(", "self", ")", ":", "\n", "    ", "adv", "=", "tf", ".", "constant", "(", "[", "1.5", ",", "4.", ",", "123.", ",", "-", "3.", "]", ")", "\n", "adv", "=", "policy_losses", ".", "AdvantagePreprocessor", "(", "only_positive", "=", "True", ")", "(", "adv", ")", "[", "0", "]", "\n", "self", ".", "assertAllClose", "(", "adv", ",", "[", "1.5", ",", "4.", ",", "123.", ",", "0.", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.AdvantagePreprocessorTest.test_only_top_half": [[36, 40], ["tensorflow.constant", "policy_losses_test.AdvantagePreprocessorTest.assertAllClose", "seed_rl.agents.policy_gradient.modules.policy_losses.AdvantagePreprocessor"], "methods", ["None"], ["", "def", "test_only_top_half", "(", "self", ")", ":", "\n", "    ", "adv", "=", "tf", ".", "constant", "(", "[", "1.5", ",", "4.", ",", "123.", ",", "-", "3.", "]", ")", "\n", "adv", "=", "policy_losses", ".", "AdvantagePreprocessor", "(", "only_top_half", "=", "True", ")", "(", "adv", ")", "[", "0", "]", "\n", "self", ".", "assertAllClose", "(", "adv", ",", "[", "0.", ",", "4.", ",", "123.", ",", "0.", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.GeneralizedAdvantagePolicyLossTest.setUp": [[44, 49], ["super().setUp", "tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.random.uniform"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.TPUEncodeTest.setUp"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "setUp", "(", ")", "\n", "self", ".", "adv", "=", "tf", ".", "random", ".", "uniform", "(", "[", "100", "]", ",", "maxval", "=", "2", ")", "\n", "self", ".", "pi", "=", "tf", ".", "random", ".", "uniform", "(", "[", "100", "]", ",", "maxval", "=", "2", ")", "\n", "self", ".", "mu", "=", "tf", ".", "random", ".", "uniform", "(", "[", "100", "]", ",", "maxval", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad": [[50, 58], ["tensorflow.GradientTape", "t.watch", "t.gradient", "policy_losses_test.GeneralizedAdvantagePolicyLossTest.test_ppo.loss", "tensorflow.math.log", "tensorflow.math.log"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log"], ["", "def", "_loss_grad", "(", "self", ",", "loss", ",", "feed_log_probs", ")", ":", "\n", "    ", "with", "tf", ".", "GradientTape", "(", ")", "as", "t", ":", "\n", "      ", "t", ".", "watch", "(", "self", ".", "pi", ")", "\n", "return", "t", ".", "gradient", "(", "\n", "loss", "(", "self", ".", "adv", ",", "\n", "tf", ".", "math", ".", "log", "(", "self", ".", "pi", ")", "if", "feed_log_probs", "else", "self", ".", "pi", ",", "\n", "tf", ".", "math", ".", "log", "(", "self", ".", "mu", ")", "if", "feed_log_probs", "else", "self", ".", "mu", ",", "None", ",", "None", ",", "\n", "None", ")", ",", "self", ".", "pi", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.GeneralizedAdvantagePolicyLossTest.test_pg": [[59, 64], ["policy_losses_test.GeneralizedAdvantagePolicyLossTest.assertAllClose", "policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad", "policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad", "tensorflow.reduce_mean", "seed_rl.agents.policy_gradient.modules.policy_losses.pg", "tensorflow.math.log"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.pg", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log"], ["", "", "def", "test_pg", "(", "self", ")", ":", "\n", "    ", "loss", "=", "lambda", "adv", ",", "pi", ",", "mu", ",", "d1", ",", "d2", ",", "d3", ":", "-", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "math", ".", "log", "(", "pi", ")", "*", "adv", ")", "\n", "self", ".", "assertAllClose", "(", "self", ".", "_loss_grad", "(", "policy_losses", ".", "pg", "(", ")", ",", "True", ")", ",", "\n", "self", ".", "_loss_grad", "(", "loss", ",", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.GeneralizedAdvantagePolicyLossTest.test_vtrace": [[65, 70], ["policy_losses_test.GeneralizedAdvantagePolicyLossTest.assertAllClose", "policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad", "policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad", "tensorflow.reduce_mean", "seed_rl.agents.policy_gradient.modules.policy_losses.vtrace", "tensorflow.stop_gradient", "tensorflow.maximum"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.vtrace"], ["", "def", "test_vtrace", "(", "self", ")", ":", "\n", "    ", "loss", "=", "lambda", "adv", ",", "pi", ",", "mu", ",", "d1", ",", "d2", ",", "d3", ":", "-", "tf", ".", "reduce_mean", "(", "\n", "pi", "/", "tf", ".", "stop_gradient", "(", "tf", ".", "maximum", "(", "mu", ",", "pi", ")", ")", "*", "adv", ")", "\n", "self", ".", "assertAllClose", "(", "self", ".", "_loss_grad", "(", "policy_losses", ".", "vtrace", "(", ")", ",", "True", ")", ",", "\n", "self", ".", "_loss_grad", "(", "loss", ",", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.GeneralizedAdvantagePolicyLossTest.test_ppo": [[71, 78], ["policy_losses_test.GeneralizedAdvantagePolicyLossTest.assertAllClose", "tensorflow.clip_by_value", "policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad", "policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad", "tensorflow.reduce_mean", "seed_rl.agents.policy_gradient.modules.policy_losses.ppo", "tensorflow.minimum"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.ppo"], ["", "def", "test_ppo", "(", "self", ")", ":", "\n", "    ", "def", "loss", "(", "adv", ",", "pi", ",", "mu", ",", "*", "unused_args", ")", ":", "\n", "      ", "rho", "=", "pi", "/", "mu", "\n", "rho_clipped", "=", "tf", ".", "clip_by_value", "(", "rho", ",", "1", "/", "1.2", ",", "1.2", ")", "\n", "return", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "minimum", "(", "rho", "*", "adv", ",", "rho_clipped", "*", "adv", ")", ")", "\n", "", "self", ".", "assertAllClose", "(", "self", ".", "_loss_grad", "(", "policy_losses", ".", "ppo", "(", "epsilon", "=", "0.2", ")", ",", "True", ")", ",", "\n", "self", ".", "_loss_grad", "(", "loss", ",", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.GeneralizedAdvantagePolicyLossTest.test_awr": [[79, 85], ["policy_losses_test.GeneralizedAdvantagePolicyLossTest.assertAllClose", "policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad", "policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad", "tensorflow.reduce_mean", "seed_rl.agents.policy_gradient.modules.policy_losses.awr", "tensorflow.math.log", "tensorflow.exp"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses_test.GeneralizedAdvantagePolicyLossTest._loss_grad", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.awr", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log"], ["", "def", "test_awr", "(", "self", ")", ":", "\n", "    ", "loss", "=", "lambda", "adv", ",", "pi", ",", "mu", ",", "d1", ",", "d2", ",", "d3", ":", "-", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "math", ".", "log", "(", "pi", ")", "*", "tf", ".", "exp", "(", "adv", "/", "5.", ")", ")", "\n", "self", ".", "assertAllClose", "(", "self", ".", "_loss_grad", "(", "policy_losses", ".", "awr", "(", "beta", "=", "5.", ",", "\n", "w_max", "=", "1e9", ")", ",", "True", ")", ",", "\n", "self", ".", "_loss_grad", "(", "loss", ",", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_regularizers.KLPolicyRegularizer.__init__": [[32, 52], ["coefficients.items", "isinstance", "seed_rl.agents.policy_gradient.modules.constraints.FixedCoefficient"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "coefficients", ")", ":", "\n", "    ", "\"\"\"Creates the regularizer.\n\n    Args:\n       kl_pi_mu: Coefficient for KL(current_policy||behaviour_policy) loss. It\n         can be a float or a Coefficient object. Defaults to 0.\n       kl_mu_pi: Coefficient for KL(behaviour_policy||current_policy) loss.\n       entropy: Coefficient for entropy bonus. If a constraint is used, than\n         the constraint is -entropy < threshold so the higher the threshold,\n         the lower the entropy.\n       kl_ref_pi: Coefficient for the KL between a reference distribution and\n         the current one. The reference distribution is defined as one which is\n         parametrized by zeros, i.e. uniform for categorical distributions\n         and tanh(N(0, softplus(0))) for NormalSquashedDistribution.\n    \"\"\"", "\n", "self", ".", "coefficients", "=", "coefficients", "\n", "for", "key", ",", "coe", "in", "coefficients", ".", "items", "(", ")", ":", "\n", "      ", "assert", "key", "in", "[", "'kl_pi_mu'", ",", "'kl_mu_pi'", ",", "'entropy'", ",", "'kl_ref_pi'", "]", "\n", "if", "not", "isinstance", "(", "coe", ",", "constraints", ".", "Coefficient", ")", ":", "\n", "        ", "self", ".", "coefficients", "[", "key", "]", "=", "constraints", ".", "FixedCoefficient", "(", "coe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_regularizers.KLPolicyRegularizer.__call__": [[53, 90], ["tensorflow.zeros", "tensorflow.constant", "policy_regularizers.KLPolicyRegularizer.coefficients.items", "dist().kl_divergence", "dist().kl_divergence", "dist().kl_divergence", "losses.items", "coe.scale_loss", "coe.adjustment_loss", "policy_regularizers.KLPolicyRegularizer.log", "policy_regularizers.KLPolicyRegularizer.log", "tensorflow.constant.shape.as_list", "dist", "dist", "dist", "dist().entropy", "policy_regularizers.KLPolicyRegularizer.log", "policy_regularizers.KLPolicyRegularizer.log", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "dist", "dist", "dist", "coe", "tensorflow.zeros_like", "dist"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.kl_divergence", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.kl_divergence", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.kl_divergence", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints.Coefficient.scale_loss", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints.LagrangeInequalityCoefficient.adjustment_loss", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.entropy", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log"], ["", "", "", "def", "__call__", "(", "self", ",", "parametric_action_distribution", ",", "pi_logits", ",", "mu_logits", ",", "\n", "actions", ",", "with_logging", "=", "True", ")", ":", "\n", "    ", "assert", "pi_logits", ".", "shape", "==", "mu_logits", ".", "shape", "\n", "dist", "=", "parametric_action_distribution", "\n", "\n", "losses", "=", "{", "\n", "'kl_pi_mu'", ":", "\n", "dist", "(", "pi_logits", ")", ".", "kl_divergence", "(", "dist", "(", "mu_logits", ")", ")", ",", "\n", "'kl_mu_pi'", ":", "\n", "dist", "(", "mu_logits", ")", ".", "kl_divergence", "(", "dist", "(", "pi_logits", ")", ")", ",", "\n", "'kl_ref_pi'", ":", "\n", "dist", "(", "tf", ".", "zeros_like", "(", "pi_logits", ")", ")", ".", "kl_divergence", "(", "dist", "(", "pi_logits", ")", ")", ",", "\n", "'entropy'", ":", "\n", "-", "dist", "(", "pi_logits", ")", ".", "entropy", "(", ")", "\n", "}", "\n", "\n", "if", "with_logging", ":", "\n", "      ", "for", "key", ",", "val", "in", "losses", ".", "items", "(", ")", ":", "\n", "        ", "self", ".", "log", "(", "'KLPolicyRegularizer/%s'", "%", "key", ",", "\n", "val", "*", "(", "-", "1", "if", "key", "==", "'entropy'", "else", "1", ")", ")", "\n", "\n", "", "", "per_step_loss", "=", "tf", ".", "zeros", "(", "pi_logits", ".", "shape", "[", ":", "-", "1", "]", ",", "tf", ".", "float32", ")", "\n", "global_loss", "=", "tf", ".", "constant", "(", "0.", ",", "tf", ".", "float32", ")", "\n", "for", "key", ",", "coe", "in", "self", ".", "coefficients", ".", "items", "(", ")", ":", "\n", "      ", "loss", "=", "losses", "[", "key", "]", "\n", "assert", "loss", ".", "shape", "==", "per_step_loss", ".", "shape", "\n", "if", "with_logging", ":", "\n", "        ", "self", ".", "log", "(", "'KLPolicyRegularizer/%s/coefficient'", "%", "key", ",", "coe", "(", ")", ")", "\n", "", "per_step_loss", "+=", "coe", ".", "scale_loss", "(", "loss", ")", "\n", "global_loss", "+=", "coe", ".", "adjustment_loss", "(", "tf", ".", "reduce_mean", "(", "loss", ")", ")", "\n", "", "if", "with_logging", ":", "\n", "      ", "self", ".", "log", "(", "'KLPolicyRegularizer/per_step_loss'", ",", "\n", "tf", ".", "reduce_mean", "(", "per_step_loss", ")", ")", "\n", "self", ".", "log", "(", "'KLPolicyRegularizer/global_loss'", ",", "global_loss", ")", "\n", "", "assert", "per_step_loss", ".", "shape", "==", "pi_logits", ".", "shape", "[", ":", "-", "1", "]", "\n", "assert", "not", "global_loss", ".", "shape", ".", "as_list", "(", ")", "\n", "return", "per_step_loss", ",", "global_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent_test.ContinuousControlTest.test_configuration": [[85, 89], ["absl.testing.parameterized.parameters", "continuous_control_agent_test.ContinuousControlTest._setup_agent", "continuous_control_agent_test.ContinuousControlTest._call_from_strategy", "list", "continuous_control_agent_test._combinations"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent_test.ContinuousControlTest._setup_agent", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent_test.ContinuousControlTest._call_from_strategy", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent_test._combinations"], ["@", "parameterized", ".", "parameters", "(", "list", "(", "_combinations", "(", ")", ")", ")", "\n", "def", "test_configuration", "(", "self", ",", "kwargs", ")", ":", "\n", "    ", "agent", ",", "strategy", "=", "self", ".", "_setup_agent", "(", "kwargs", ")", "\n", "self", ".", "_call_from_strategy", "(", "agent", ",", "strategy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent_test.ContinuousControlTest._setup_agent": [[90, 101], ["seed_rl.agents.policy_gradient.modules.continuous_control_agent.ContinuousControlAgent", "seed_rl.agents.policy_gradient.modules.test_utils.create_distribution_strategy", "continuous_control_agent_test.ContinuousControlTest.assertEqual", "seed_rl.common.parametric_distribution.normal_tanh_distribution", "seed_rl.agents.policy_gradient.modules.test_utils.create_distribution_strategy.scope", "tensorflow.function", "tensorflow.function.", "continuous_control_agent_test._dummy_input"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.create_distribution_strategy", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.normal_tanh_distribution", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent_test._dummy_input"], ["", "def", "_setup_agent", "(", "self", ",", "kwargs", ")", ":", "\n", "    ", "\"\"\"Sets up the agent and a distribution strategy to run.\"\"\"", "\n", "agent", "=", "continuous_control_agent", ".", "ContinuousControlAgent", "(", "\n", "parametric_distribution", ".", "normal_tanh_distribution", "(", "20", ")", ",", "**", "kwargs", ")", "\n", "strategy", "=", "test_utils", ".", "create_distribution_strategy", "(", "\n", "use_tpu", "=", "self", ".", "primary_device", "==", "'TPU'", ")", "\n", "self", ".", "assertEqual", "(", "strategy", ".", "num_replicas_in_sync", ",", "2", ")", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "wrapped_f", "=", "tf", ".", "function", "(", "agent", ".", "__call__", ")", "\n", "wrapped_f", "(", "*", "_dummy_input", "(", "False", ")", ",", "unroll", "=", "False", ",", "is_training", "=", "True", ")", "\n", "", "return", "agent", ",", "strategy", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent_test.ContinuousControlTest._call_from_strategy": [[102, 108], ["strategy.run", "agent", "continuous_control_agent_test._dummy_input"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent_test._dummy_input"], ["", "def", "_call_from_strategy", "(", "self", ",", "agent", ",", "strategy", ")", ":", "\n", "    ", "\"\"\"Updates the normalization statistics via the strategy.\"\"\"", "\n", "@", "tf", ".", "function", "\n", "def", "_run_on_tpu", "(", ")", ":", "\n", "      ", "return", "agent", "(", "*", "_dummy_input", "(", "True", ")", ",", "unroll", "=", "True", ",", "is_training", "=", "True", ")", "\n", "", "strategy", ".", "run", "(", "_run_on_tpu", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent_test._dummy_rnn_core_state": [[29, 34], ["tensorflow.keras.layers.StackedRNNCells", "tf.keras.layers.StackedRNNCells.get_initial_state", "tensorflow.keras.layers.LSTMCell"], "function", ["None"], ["def", "_dummy_rnn_core_state", "(", "batch_size", ")", ":", "\n", "  ", "lstm_sizes", "=", "[", "256", "]", "\n", "lstm_cells", "=", "[", "tf", ".", "keras", ".", "layers", ".", "LSTMCell", "(", "size", ")", "for", "size", "in", "lstm_sizes", "]", "\n", "rnn", "=", "tf", ".", "keras", ".", "layers", ".", "StackedRNNCells", "(", "lstm_cells", ")", "\n", "return", "rnn", ".", "get_initial_state", "(", "batch_size", "=", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent_test._dummy_input": [[36, 50], ["tensorflow.zeros", "seed_rl.common.utils.EnvOutput", "continuous_control_agent_test._dummy_rnn_core_state", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent_test._dummy_rnn_core_state"], ["", "def", "_dummy_input", "(", "unroll", ")", ":", "\n", "  ", "\"\"\"Returns a dummy tuple that can be fed into an agent.\"\"\"", "\n", "batch_size", "=", "15", "\n", "base_shape", "=", "[", "6", ",", "batch_size", "]", "if", "unroll", "else", "[", "batch_size", "]", "\n", "prev_actions", "=", "tf", ".", "zeros", "(", "base_shape", "+", "[", "10", "]", ",", "tf", ".", "float32", ")", "\n", "# Create the environment output.", "\n", "env_outputs", "=", "utils", ".", "EnvOutput", "(", "\n", "reward", "=", "tf", ".", "zeros", "(", "base_shape", ",", "tf", ".", "float32", ")", ",", "\n", "done", "=", "tf", ".", "zeros", "(", "base_shape", ",", "tf", ".", "bool", ")", ",", "\n", "observation", "=", "tf", ".", "zeros", "(", "base_shape", "+", "[", "17", "]", ",", "tf", ".", "float32", ")", ",", "\n", "abandoned", "=", "tf", ".", "zeros", "(", "base_shape", ",", "tf", ".", "bool", ")", ",", "\n", "episode_step", "=", "tf", ".", "zeros", "(", "base_shape", ",", "tf", ".", "bool", ")", ")", "\n", "core_state", "=", "_dummy_rnn_core_state", "(", "batch_size", "=", "batch_size", ")", "\n", "return", "(", "prev_actions", ",", "env_outputs", ")", ",", "core_state", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent_test._combinations": [[52, 74], ["seed_rl.agents.policy_gradient.modules.input_normalization.InputNormalization", "tensorflow.keras.initializers.Orthogonal", "tensorflow.keras.initializers.Orthogonal", "tensorflow.keras.initializers.Orthogonal", "seed_rl.agents.policy_gradient.modules.running_statistics.EMAMeanStd"], "function", ["None"], ["", "def", "_combinations", "(", ")", ":", "\n", "  ", "\"\"\"Yields dictionaries with all constructor arguments to be tested.\"\"\"", "\n", "yield", "{", "}", ",", "\n", "yield", "{", "'shared'", ":", "True", "}", ",", "\n", "yield", "{", "'residual_connections'", ":", "True", "}", ",", "\n", "yield", "{", "'correct_observations'", ":", "True", "}", ",", "\n", "yield", "{", "'observation_normalizer'", ":", "input_normalization", ".", "InputNormalization", "(", "\n", "running_statistics", ".", "EMAMeanStd", "(", ")", ")", "}", ",", "\n", "yield", "{", "'num_layers_policy'", ":", "4", "}", ",", "\n", "yield", "{", "'num_layers_value'", ":", "4", "}", ",", "\n", "yield", "{", "'num_units_policy'", ":", "128", "}", ",", "\n", "yield", "{", "'num_units_value'", ":", "128", "}", ",", "\n", "yield", "{", "'activation'", ":", "tf", ".", "sin", "}", ",", "\n", "yield", "{", "'activation'", ":", "tf", ".", "keras", ".", "activations", ".", "relu", "}", ",", "\n", "yield", "{", "'kernel_init'", ":", "tf", ".", "keras", ".", "initializers", ".", "Orthogonal", "(", ")", "}", ",", "\n", "yield", "{", "'last_kernel_init_value_scaling'", ":", "0.1", "}", ",", "\n", "yield", "{", "'last_kernel_init_policy_scaling'", ":", "0.1", "}", ",", "\n", "yield", "{", "'last_kernel_init_value'", ":", "tf", ".", "keras", ".", "initializers", ".", "Orthogonal", "(", ")", "}", ",", "\n", "yield", "{", "'last_kernel_init_policy'", ":", "tf", ".", "keras", ".", "initializers", ".", "Orthogonal", "(", ")", "}", ",", "\n", "yield", "{", "'layer_normalizer'", ":", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "}", ",", "\n", "yield", "{", "'std_independent_of_input'", ":", "True", "}", ",", "\n", "yield", "{", "'num_layers_rnn'", ":", "1", "}", ",", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent_test.setUpModule": [[76, 79], ["seed_rl.agents.policy_gradient.modules.test_utils.simulate_two_devices"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.simulate_two_devices"], ["", "def", "setUpModule", "(", ")", ":", "\n", "# We want our tests to run on several devices with a mirrored strategy.", "\n", "  ", "test_utils", ".", "simulate_two_devices", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.ppo_training_step_utils.ppo_training_step": [[21, 68], ["ppo_training_step_utils.single_epoch", "tensorflow.range", "ppo_training_step_utils.compute_advantages_and_split", "ppo_training_step_utils.single_epoch", "ppo_training_step_utils.compute_advantages_and_split"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.ppo_training_step_utils.single_epoch", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.ppo_training_step_utils.compute_advantages_and_split", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.ppo_training_step_utils.single_epoch", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.ppo_training_step_utils.compute_advantages_and_split"], ["def", "ppo_training_step", "(", "\n", "epochs_per_step", ",", "loss_fn", ",", "args", ",", "batch_mode", ",", "training_strategy", ",", "\n", "virtual_batch_size", ",", "unroll_length", ",", "batches_per_step", ",", "clip_norm", ",", "\n", "optimizer", ",", "logger", ")", ":", "\n", "  ", "\"\"\"Performs a PPO training step, running epochs_per_step times over the data.\n\n  Args:\n    epochs_per_step: The number of epochs to perform over the virtual batch.\n    loss_fn: Policy loss class.\n    args: Unroll struct with tensors whose leading dimensions are time and\n      batch_size * batches_per_step (except for the core state which does not\n      have a time leading dimension).\n    batch_mode: How to handle minibatches: go over the same minibatches\n      multiple times (repeat), shuffle unrolls in each epoch (shuffle) or\n      compute the advantages once and then split the unrolls into individual\n      transitions which are then shuffled (split).\n      split_with_advantages_recomputation works like split but the advantages\n      are recomputed at the beginning of each pass over the data.'\n    training_strategy: TF distribute strategy.\n    virtual_batch_size: batch_size * batches_per_step.\n    unroll_length: length of one unroll in agent steps.\n    batches_per_step: How many mini batches to pass over in a training step.\n    clip_norm: value to clip the gradient global norm to.\n    optimizer: tf.keras.optimizers.Optimizer.\n    logger: SEED logger.\n\n  Returns:\n    Loss and log (SEED log session) of the training step.\n  \"\"\"", "\n", "orig_args", "=", "args", "\n", "if", "batch_mode", "in", "[", "'split'", ",", "'split_with_advantage_recomputation'", "]", ":", "\n", "    ", "args", "=", "compute_advantages_and_split", "(", "loss_fn", ",", "orig_args", ")", "\n", "\n", "# tf.range loops can not create new variables so we first run a single", "\n", "# epoch to create the logs.", "\n", "", "loss", ",", "logs", "=", "single_epoch", "(", "loss_fn", ",", "args", ",", "batch_mode", ",", "training_strategy", ",", "\n", "virtual_batch_size", ",", "unroll_length", ",", "\n", "batches_per_step", ",", "clip_norm", ",", "optimizer", ",", "\n", "logger", ")", "\n", "for", "_", "in", "tf", ".", "range", "(", "epochs_per_step", "-", "1", ")", ":", "\n", "    ", "if", "batch_mode", "==", "'split_with_advantage_recomputation'", ":", "\n", "      ", "args", "=", "compute_advantages_and_split", "(", "loss_fn", ",", "orig_args", ")", "\n", "", "loss", ",", "logs", "=", "single_epoch", "(", "loss_fn", ",", "args", ",", "batch_mode", ",", "training_strategy", ",", "\n", "virtual_batch_size", ",", "unroll_length", ",", "\n", "batches_per_step", ",", "clip_norm", ",", "optimizer", ",", "\n", "logger", ")", "\n", "", "return", "loss", ",", "logs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.ppo_training_step_utils.compute_advantages_and_split": [[71, 102], ["loss_fn.compute_advantages", "tensorflow.nest.map_structure", "tensorflow.nest.map_structure", "ValueError", "tensorflow.reshape"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.generalized_onpolicy_loss.GeneralizedOnPolicyLoss.compute_advantages"], ["", "def", "compute_advantages_and_split", "(", "loss_fn", ",", "input_args", ")", ":", "\n", "  ", "\"\"\"Computes advantages and split tensors into transitions.\n\n  Args:\n    loss_fn: Policy loss providing a compute_advantages method.\n    input_args: Unroll struct with tensors whose leading dimensions are time and\n      batch_size * batches_per_step.\n\n  Returns:\n    output_args: Tuple containing (agent_state, prev_actions, env_outputs,\n          agent_outputs, normalized_targets, normalized_advantages). It\n          corresponds to input_args with the last step removed from each tensor,\n          and the advantages, split into individual transitions (i.e., each\n          tensor from input_args [T,B] becomes [1, (T-1)*B])\n  \"\"\"", "\n", "if", "input_args", ".", "agent_state", "!=", "(", ")", ":", "\n", "    ", "raise", "ValueError", "(", "'Agent state is not supported for split_* batch modes. '", "\n", "'Use shuffle or repeat batch modes.'", ")", "\n", "", "advantages", "=", "loss_fn", ".", "compute_advantages", "(", "*", "input_args", ")", "\n", "\n", "# Last timestep is only used for bootstrapping for advantage estimation", "\n", "# so we can remove it here.", "\n", "output_args", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "t", "[", ":", "-", "1", "]", ",", "input_args", ")", "\n", "output_args", "+=", "advantages", "\n", "\n", "# Split into individual transitions.", "\n", "def", "unroll2transitions", "(", "t", ")", ":", "# [T, B] -> [1, T * B]", "\n", "    ", "return", "tf", ".", "reshape", "(", "t", ",", "[", "1", ",", "t", ".", "shape", "[", "0", "]", "*", "t", ".", "shape", "[", "1", "]", "]", "+", "t", ".", "shape", "[", "2", ":", "]", ")", "\n", "\n", "", "output_args", "=", "tf", ".", "nest", ".", "map_structure", "(", "unroll2transitions", ",", "output_args", ")", "\n", "return", "output_args", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.ppo_training_step_utils.single_epoch": [[105, 221], ["tensorflow.nest.map_structure", "enumerate", "tensorflow.range", "tensorflow.split", "tensorflow.nest.flatten", "tensorflow.random.shuffle", "batch_mode.startswith", "tape.gradient", "tensorflow.linalg.global_norm", "logger.log", "logger.log", "optimizer.apply_gradients", "ppo_training_step_utils.single_epoch.train_on_minibatch"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log"], ["", "def", "single_epoch", "(", "loss_fn", ",", "args", ",", "batch_mode", ",", "training_strategy", ",", "\n", "virtual_batch_size", ",", "unroll_length", ",", "batches_per_step", ",", "clip_norm", ",", "\n", "optimizer", ",", "logger", ")", ":", "\n", "  ", "\"\"\"Computes a single training epoch in PPO.\n\n  Args:\n    loss_fn: Policy loss class.\n    args: Unroll struct (or unroll and advantages) with tensors whose leading\n      dimensions are time and batch_size * batches_per_step, unless batch_mode\n      is `split` or `split_with_advantage_recomputation`. In that case, it is\n      the output of compute_advantages_and_split (with leading dimensions\n      [1, batch_size * batches_per_step * unroll_length]).\n    batch_mode: How to handle minibatches: go over the same minibatches\n      multiple times (repeat), shuffle unrolls in each epoch (shuffle) or\n      compute the advantages once and then split the unrolls into individual\n      transitions which are then shuffled (split).\n      split_with_advantages_recomputation works like split but the advantages\n      are recomputed at the beginning of each pass over the data.'\n    training_strategy: TF distribute strategy.\n    virtual_batch_size: batch_size * batches_per_step.\n    unroll_length: length of one unroll in agent steps.\n    batches_per_step: How many mini batches to pass over in a training step.\n    clip_norm: value to clip the gradient global norm to.\n    optimizer: tf.keras.optimizers.Optimizer.\n    logger: SEED logger.\n\n  Returns:\n    Loss and log (SEED log session) of the epoch.\n  \"\"\"", "\n", "\n", "# Check if shapes are correct.", "\n", "front_shapes", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "list", "(", "t", ".", "shape", "[", ":", "2", "]", ")", ",", "\n", "tf", ".", "nest", ".", "flatten", "(", "args", ")", ")", "\n", "# All tensors apart from agent_state have leading dimensions [time, batch]", "\n", "# while agent_state has no time dimension.", "\n", "timesteps", ",", "batch_size", "=", "front_shapes", "[", "-", "1", "]", "\n", "for", "i", ",", "shape", "in", "enumerate", "(", "front_shapes", ")", ":", "\n", "    ", "if", "shape", "[", "0", "]", "!=", "batch_size", "and", "shape", "!=", "[", "timesteps", ",", "batch_size", "]", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "f'Loss argument {i} expected to have leading dimensions '", "\n", "f'[time, batch] ([{timesteps}, {batch_size}]) or [batch] '", "\n", "f'(in the case of memory state) but encountered a tensor with '", "\n", "f'leading dimensions {shape}'", ")", "\n", "", "", "if", "batch_mode", "in", "[", "'split'", ",", "'split_with_advantage_recomputation'", "]", ":", "\n", "    ", "if", "timesteps", "!=", "1", ":", "\n", "      ", "raise", "ValueError", "(", "f'Unexpected timesteps {timesteps}'", ")", "\n", "", "if", "(", "training_strategy", ".", "num_replicas_in_sync", "*", "batch_size", "!=", "\n", "virtual_batch_size", "*", "unroll_length", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "f'Batch size mismatch '", "\n", "f'{training_strategy.num_replicas_in_sync * batch_size} vs '", "\n", "f'{virtual_batch_size * unroll_length}'", ")", "\n", "", "", "else", ":", "\n", "    ", "if", "timesteps", "!=", "unroll_length", "+", "1", ":", "\n", "      ", "raise", "ValueError", "(", "f'Timesteps mismatch {timesteps} vs {unroll_length + 1}'", ")", "\n", "", "if", "(", "training_strategy", ".", "num_replicas_in_sync", "*", "batch_size", "!=", "\n", "virtual_batch_size", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "f'Batch size mismatch '", "\n", "f'{training_strategy.num_replicas_in_sync * batch_size} vs '", "\n", "f'{virtual_batch_size}'", ")", "\n", "# Split into minibatches.", "\n", "", "", "indices", "=", "tf", ".", "range", "(", "batch_size", ")", "\n", "if", "batch_mode", "!=", "'repeat'", ":", "\n", "    ", "indices", "=", "tf", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "\n", "", "@", "tf", ".", "function", "\n", "def", "train_on_minibatch", "(", "indices", ",", "logger", ")", ":", "\n", "    ", "if", "batch_mode", ".", "startswith", "(", "'split'", ")", ":", "\n", "      ", "agent_state", "=", "args", "[", "0", "]", "\n", "if", "agent_state", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'Split batch mode is not supported for models with memory. '", "\n", "'Use --batch_mode=shuffle.'", ")", "\n", "", "minibatch", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "tf", ".", "gather", "(", "t", ",", "indices", ",", "axis", "=", "1", ")", ",", "\n", "args", ")", "\n", "", "else", ":", "\n", "# All tensors apart from agent_state have leading dimensions [time, batch]", "\n", "# while agent_state has no time dimension.", "\n", "# We add a dummy time dimension to it here...", "\n", "      ", "expanded_args", "=", "args", ".", "_replace", "(", "\n", "agent_state", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "t", "[", "tf", ".", "newaxis", ",", "...", "]", ",", "\n", "args", ".", "agent_state", ")", ")", "\n", "minibatch", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "tf", ".", "gather", "(", "t", ",", "indices", ",", "axis", "=", "1", ")", ",", "\n", "expanded_args", ")", "\n", "# ...and remove it here.", "\n", "minibatch", "=", "minibatch", ".", "_replace", "(", "\n", "agent_state", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "tf", ".", "squeeze", "(", "t", ",", "axis", "=", "0", ")", ",", "\n", "minibatch", ".", "agent_state", ")", ")", "\n", "\n", "", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "      ", "with", "logging_module", ".", "LoggingTape", "(", "loss_fn", ")", "as", "logs_dict", ":", "\n", "        ", "loss", "=", "loss_fn", "(", "*", "minibatch", ")", "\n", "", "session", "=", "logger", ".", "log_session_from_dict", "(", "logs_dict", ")", "\n", "# Normalizers may have unused compensation variables so we need", "\n", "# unconnected_gradients=tf.UnconnectedGradients.ZERO to avoid getting Nones", "\n", "# for them.", "\n", "", "grads", "=", "tape", ".", "gradient", "(", "\n", "loss", ",", "loss_fn", ".", "trainable_variables", ",", "\n", "unconnected_gradients", "=", "tf", ".", "UnconnectedGradients", ".", "ZERO", ")", "\n", "\n", "gradient_norm_before_clip", "=", "tf", ".", "linalg", ".", "global_norm", "(", "grads", ")", "\n", "if", "clip_norm", "is", "not", "None", ":", "\n", "      ", "grads", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "\n", "grads", ",", "clip_norm", ",", "use_norm", "=", "gradient_norm_before_clip", ")", "\n", "", "logger", ".", "log", "(", "session", ",", "'grad/norm'", ",", "gradient_norm_before_clip", ")", "\n", "logger", ".", "log", "(", "session", ",", "'grad/trainable_variables'", ",", "\n", "tf", ".", "linalg", ".", "global_norm", "(", "loss_fn", ".", "trainable_variables", ")", ")", "\n", "optimizer", ".", "apply_gradients", "(", "zip", "(", "grads", ",", "loss_fn", ".", "trainable_variables", ")", ")", "\n", "return", "loss", ",", "session", "\n", "\n", "# Train.", "\n", "", "for", "minibatch_indices", "in", "tf", ".", "split", "(", "indices", ",", "batches_per_step", ")", ":", "\n", "    ", "loss", ",", "session", "=", "train_on_minibatch", "(", "minibatch_indices", ",", "logger", ")", "\n", "\n", "", "return", "loss", ",", "session", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent.__init__": [[35, 183], ["tensorflow.Module.__init__", "continuous_control_agent._rescale_initializer", "continuous_control_agent._rescale_initializer", "tensorflow.keras.Sequential", "tensorflow.keras.Sequential", "tensorflow.keras.Sequential", "layer_normalizer", "continuous_control_agent.ContinuousControlAgent._policy.add", "continuous_control_agent.ContinuousControlAgent._value.add", "seed_rl.agents.policy_gradient.modules.input_normalization.InputNormalization", "continuous_control_agent._add_layers", "continuous_control_agent._add_layers", "continuous_control_agent._add_layers", "tensorflow.keras.layers.StackedRNNCells", "continuous_control_agent._Layer", "continuous_control_agent.ContinuousControlAgent._policy.add", "layer_normalizer", "continuous_control_agent._Layer", "seed_rl.agents.policy_gradient.modules.running_statistics.FixedMeanStd", "ValueError", "ValueError", "tensorflow.keras.layers.LSTMCell", "continuous_control_agent._ConcatTrainableTensor", "tensorflow.zeros"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent._rescale_initializer", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent._rescale_initializer", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.add", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.add", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent._add_layers", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent._add_layers", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent._add_layers", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.add"], ["def", "__init__", "(", "self", ",", "\n", "parametric_action_distribution", ",", "\n", "observation_normalizer", "=", "None", ",", "\n", "num_layers_policy", "=", "3", ",", "\n", "num_layers_value", "=", "3", ",", "\n", "num_layers_rnn", "=", "0", ",", "\n", "num_units_policy", "=", "256", ",", "\n", "num_units_value", "=", "256", ",", "\n", "num_units_rnn", "=", "256", ",", "\n", "layer_normalizer", "=", "None", ",", "\n", "shared", "=", "False", ",", "\n", "residual_connections", "=", "False", ",", "\n", "activation", "=", "None", ",", "\n", "kernel_init", "=", "'glorot_uniform'", ",", "\n", "last_kernel_init_value", "=", "None", ",", "\n", "last_kernel_init_value_scaling", "=", "None", ",", "\n", "last_kernel_init_policy", "=", "None", ",", "\n", "last_kernel_init_policy_scaling", "=", "None", ",", "\n", "correct_observations", "=", "False", ",", "\n", "std_independent_of_input", "=", "False", ",", "\n", "input_clipping", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates the ContinuousControlAgent.\n\n    Args:\n      parametric_action_distribution: SEED distribution used for the actions.\n      observation_normalizer: InputNormalization instance used to normalize\n        observations or None for no normalization.\n      num_layers_policy: Integer with the number of hidden layers in the policy\n        MLP. Needs to be the same as `num_layers_value` if shared=True.\n      num_layers_value: Integer with the number of hidden layers in the value\n        MLP. If None, the number of layers is the same as in the policy.\n        Needs to be the same as `num_layers_policy` if shared=True.\n      num_layers_rnn: Number of RNN layers.\n      num_units_policy: Integer with the number of hidden units in the policy\n        MLP. Needs to be the same as `num_units_value` if shared=True.\n      num_units_value: Integer with the number of hidden units in the value\n        MLP. If None, the number of units is the same as in the policy.\n        Needs to be the same as `num_units_policy` if shared=True.\n      num_units_rnn: Integer with the number of hidden units in the RNN.\n      layer_normalizer: Function that returns a tf.keras.Layer instance used to\n        normalize observations or None for no layer normalization.\n      shared: Boolean indicating whether the MLPs (except the heads) should be\n        shared for the value and the policy networks.\n      residual_connections: Boolean indicating whether residual connections\n        should be added to all the layers except the first and last ones in the\n        MLPs.\n      activation: Activation function to be passed to the dense layers in the\n        MLPs or None (in which case the swish activation function is used).\n      kernel_init: tf.keras.initializers.Initializer instance used to initialize\n        the dense layers of the MLPs.\n      last_kernel_init_value: tf.keras.initializers.Initializer instance used to\n        initialize the last dense layers of the value MLP or None (in which case\n        `kernel_init` is used).\n      last_kernel_init_value_scaling: None or a float that is used to rescale\n        the initial weights of the value network.\n      last_kernel_init_policy: tf.keras.initializers.Initializer instance used\n        to initialize the last dense layers of the policy MLP or None (in which\n        case `kernel_init` is used).\n      last_kernel_init_policy_scaling: None or a float that is used to rescale\n        the initial weights of the policy network.\n      correct_observations: Boolean indicating if changes in the\n        `observation_normalizer` due to updates should be compensated in\n        trainable compensation variables.\n      std_independent_of_input: If a Gaussian action distribution is used,\n        this parameter makes the standard deviation trainable but independent\n        of the policy input.\n      input_clipping: None or float that is used to clip input values to range\n        [-input_clipping, input_clipping] after (potential) input normalization.\n    \"\"\"", "\n", "super", "(", "ContinuousControlAgent", ",", "self", ")", ".", "__init__", "(", "name", "=", "'continuous_control'", ")", "\n", "\n", "# Default values.", "\n", "if", "observation_normalizer", "is", "None", ":", "\n", "# No input normalization.", "\n", "      ", "observation_normalizer", "=", "input_normalization", ".", "InputNormalization", "(", "\n", "running_statistics", ".", "FixedMeanStd", "(", ")", ")", "\n", "\n", "", "if", "activation", "is", "None", ":", "\n", "      ", "activation", "=", "swish", "\n", "\n", "", "if", "last_kernel_init_value", "is", "None", ":", "\n", "      ", "last_kernel_init_value", "=", "kernel_init", "\n", "", "last_kernel_init_value", "=", "_rescale_initializer", "(", "\n", "last_kernel_init_value", ",", "last_kernel_init_value_scaling", ")", "\n", "\n", "if", "last_kernel_init_policy", "is", "None", ":", "\n", "      ", "last_kernel_init_policy", "=", "kernel_init", "\n", "", "last_kernel_init_policy", "=", "_rescale_initializer", "(", "\n", "last_kernel_init_policy", ",", "last_kernel_init_policy_scaling", ")", "\n", "\n", "if", "layer_normalizer", "is", "None", ":", "\n", "      ", "layer_normalizer", "=", "lambda", ":", "(", "lambda", "x", ":", "x", ")", "\n", "\n", "# Parameters and layers for unroll.", "\n", "", "self", ".", "_parametric_action_distribution", "=", "parametric_action_distribution", "\n", "self", ".", "observation_normalizer", "=", "observation_normalizer", "\n", "self", ".", "_correct_observations", "=", "correct_observations", "\n", "\n", "# Build the required submodules.", "\n", "self", ".", "_shared", "=", "tf", ".", "keras", ".", "Sequential", "(", ")", "\n", "self", ".", "_policy", "=", "tf", ".", "keras", ".", "Sequential", "(", ")", "\n", "self", ".", "_value", "=", "tf", ".", "keras", ".", "Sequential", "(", ")", "\n", "\n", "# Build the torso(s).", "\n", "num_layers_value", "=", "num_layers_value", "or", "num_layers_policy", "\n", "num_units_value", "=", "num_units_value", "or", "num_units_policy", "\n", "if", "shared", ":", "\n", "      ", "if", "num_layers_value", "!=", "num_layers_policy", ":", "\n", "        ", "raise", "ValueError", "(", "'If shared=True, num_layers_value needs to be equal to'", "\n", "' num_layers_policy'", ")", "\n", "", "if", "num_units_value", "!=", "num_units_policy", ":", "\n", "        ", "raise", "ValueError", "(", "'If shared=True, num_units_value needs to be equal to'", "\n", "' num_units_policy'", ")", "\n", "", "_add_layers", "(", "self", ".", "_shared", ",", "num_layers_value", ",", "num_units_value", ",", "kernel_init", ",", "\n", "activation", ",", "layer_normalizer", ",", "residual_connections", ")", "\n", "", "else", ":", "\n", "      ", "_add_layers", "(", "self", ".", "_policy", ",", "\n", "num_layers_policy", ",", "num_units_policy", ",", "kernel_init", ",", "activation", ",", "\n", "layer_normalizer", ",", "residual_connections", ")", "\n", "_add_layers", "(", "self", ".", "_value", ",", "num_layers_value", ",", "num_units_value", ",", "kernel_init", ",", "\n", "activation", ",", "layer_normalizer", ",", "residual_connections", ")", "\n", "\n", "# Build the recurrent layers (if needed).", "\n", "", "if", "num_layers_rnn", ":", "\n", "      ", "lstm_sizes", "=", "[", "num_units_rnn", "]", "*", "num_layers_rnn", "\n", "lstm_cells", "=", "[", "tf", ".", "keras", ".", "layers", ".", "LSTMCell", "(", "size", ")", "for", "size", "in", "lstm_sizes", "]", "\n", "self", ".", "_rnn", "=", "tf", ".", "keras", ".", "layers", ".", "StackedRNNCells", "(", "lstm_cells", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "_rnn", "=", "None", "\n", "\n", "# Build the policy head.", "\n", "", "normalizer_policy", "=", "layer_normalizer", "(", ")", "\n", "policy_output_size", "=", "self", ".", "_parametric_action_distribution", ".", "param_size", "\n", "if", "std_independent_of_input", ":", "\n", "      ", "policy_output_size", "//=", "2", "\n", "", "self", ".", "_policy", ".", "add", "(", "\n", "_Layer", "(", "policy_output_size", ",", "\n", "last_kernel_init_policy", ",", "lambda", "x", ":", "x", ",", "normalizer_policy", ",", "False", ")", ")", "\n", "if", "std_independent_of_input", ":", "\n", "      ", "self", ".", "_policy", ".", "add", "(", "_ConcatTrainableTensor", "(", "tf", ".", "zeros", "(", "policy_output_size", ",", "\n", "tf", ".", "float32", ")", ")", ")", "\n", "\n", "# Build the value head.", "\n", "", "normalizer_value", "=", "normalizer_policy", "if", "shared", "else", "layer_normalizer", "(", ")", "\n", "self", ".", "_value", ".", "add", "(", "\n", "_Layer", "(", "1", ",", "last_kernel_init_value", ",", "lambda", "x", ":", "x", ",", "normalizer_value", ",", "False", ")", ")", "\n", "\n", "self", ".", "_input_clipping", "=", "input_clipping", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent.initial_state": [[184, 189], ["continuous_control_agent.ContinuousControlAgent._rnn.get_initial_state"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "initial_state", "(", "self", ",", "batch_size", ")", ":", "\n", "    ", "if", "self", ".", "_rnn", "is", "None", ":", "\n", "      ", "return", "(", ")", "\n", "", "return", "self", ".", "_rnn", ".", "get_initial_state", "(", "batch_size", "=", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent.get_action": [[193, 196], ["continuous_control_agent.ContinuousControlAgent.__call__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.__call__"], ["", "@", "tf", ".", "function", "\n", "def", "get_action", "(", "self", ",", "input_", ",", "core_state", ")", ":", "\n", "    ", "return", "self", ".", "__call__", "(", "input_", ",", "core_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent.update_observation_normalization_statistics": [[197, 205], ["continuous_control_agent.ContinuousControlAgent.observation_normalizer.update_normalization_statistics"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.update_normalization_statistics"], ["", "def", "update_observation_normalization_statistics", "(", "self", ",", "observations", ")", ":", "\n", "    ", "\"\"\"Updates the observation normalization statistics.\n\n    Args:\n      observations: a batch of observations with shape [time, batch_size,\n      obs_size].\n    \"\"\"", "\n", "self", ".", "observation_normalizer", ".", "update_normalization_statistics", "(", "observations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent.__call__": [[206, 269], ["continuous_control_agent.ContinuousControlAgent.observation_normalizer.init_normalization_stats", "ValueError", "seed_rl.common.utils.batch_apply", "continuous_control_agent.ContinuousControlAgent._apply_rnn", "seed_rl.common.utils.batch_apply", "continuous_control_agent.ContinuousControlAgent._flat_apply_pre_lstm", "tensorflow.nest.map_structure", "continuous_control_agent.ContinuousControlAgent._apply_rnn", "tensorflow.nest.map_structure", "continuous_control_agent.ContinuousControlAgent._flat_apply_post_lstm", "seed_rl.common.utils.batch_apply", "continuous_control_agent.ContinuousControlAgent._flat_apply_no_lstm", "tensorflow.expand_dims", "tensorflow.squeeze"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization.InputNormalization.init_normalization_stats", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.batch_apply", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent._apply_rnn", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.batch_apply", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent._flat_apply_pre_lstm", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent._apply_rnn", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent._flat_apply_post_lstm", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.batch_apply", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent._flat_apply_no_lstm"], ["", "def", "__call__", "(", "self", ",", "input_", ",", "core_state", ",", "unroll", "=", "False", ",", "is_training", "=", "False", ")", ":", "\n", "    ", "\"\"\"Applies the network.\n\n    Args:\n      input_: A pair (prev_actions: <int32>[batch_size], env_outputs: EnvOutput\n        structure where each tensor has a [batch_size] front dimension). When\n        unroll is True, an unroll (sequence of transitions) is expected, and\n        those tensors are expected to have [time, batch_size] front dimensions.\n      core_state: Opaque (batched) recurrent state structure corresponding to\n        the beginning of the input sequence of transitions.\n      unroll: Whether the input is an unroll (sequence of transitions) or just a\n        single (batched) transition.\n      is_training: Enables normalization statistics updates (when unroll is\n        True).\n\n    Returns:\n      A pair:\n        - agent_output: AgentOutput structure. Tensors have front dimensions\n          [batch_size] or [time, batch_size] depending on the value of 'unroll'.\n        - core_state: Opaque (batched) recurrent state structure.\n    \"\"\"", "\n", "_", ",", "env_outputs", "=", "input_", "\n", "\n", "# We first handle initializing and (potentially) updating normalization", "\n", "# statistics.  We only update during the gradient update steps.", "\n", "# `is_training` is slightly misleading as it is also True during inference", "\n", "# steps in the training phase. We hence also require unroll=True which", "\n", "# indicates gradient updates.", "\n", "training_model_update", "=", "is_training", "and", "unroll", "\n", "data", "=", "env_outputs", "[", "2", "]", "\n", "if", "not", "self", ".", "observation_normalizer", ".", "initialized", ":", "\n", "      ", "if", "training_model_update", ":", "\n", "        ", "raise", "ValueError", "(", "'It seems unlikely that stats should be updated in the'", "\n", "' same call where the stats are initialized.'", ")", "\n", "", "self", ".", "observation_normalizer", ".", "init_normalization_stats", "(", "data", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "", "if", "self", ".", "_rnn", "is", "not", "None", ":", "\n", "\n", "      ", "if", "unroll", ":", "\n", "        ", "representations", "=", "utils", ".", "batch_apply", "(", "self", ".", "_flat_apply_pre_lstm", ",", "\n", "(", "env_outputs", ",", ")", ")", "\n", "representations", ",", "core_state", "=", "self", ".", "_apply_rnn", "(", "\n", "representations", ",", "core_state", ",", "env_outputs", ".", "done", ")", "\n", "outputs", "=", "utils", ".", "batch_apply", "(", "self", ".", "_flat_apply_post_lstm", ",", "\n", "(", "representations", ",", ")", ")", "\n", "", "else", ":", "\n", "        ", "representations", "=", "self", ".", "_flat_apply_pre_lstm", "(", "env_outputs", ")", "\n", "representations", ",", "done", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "tf", ".", "expand_dims", "(", "t", ",", "0", ")", ",", "\n", "(", "representations", ",", "env_outputs", ".", "done", ")", ")", "\n", "representations", ",", "core_state", "=", "self", ".", "_apply_rnn", "(", "\n", "representations", ",", "core_state", ",", "done", ")", "\n", "representations", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "tf", ".", "squeeze", "(", "t", ",", "0", ")", ",", "representations", ")", "\n", "outputs", "=", "self", ".", "_flat_apply_post_lstm", "(", "representations", ")", "\n", "", "", "else", ":", "\n", "# Simplify.", "\n", "      ", "if", "unroll", ":", "\n", "        ", "outputs", "=", "utils", ".", "batch_apply", "(", "self", ".", "_flat_apply_no_lstm", ",", "(", "env_outputs", ",", ")", ")", "\n", "", "else", ":", "\n", "        ", "outputs", "=", "self", ".", "_flat_apply_no_lstm", "(", "env_outputs", ")", "\n", "\n", "", "", "return", "outputs", ",", "core_state", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent._apply_rnn": [[270, 301], ["continuous_control_agent.ContinuousControlAgent._rnn.get_initial_state", "zip", "tensorflow.stack", "tensorflow.shape", "tensorflow.unstack", "tensorflow.unstack", "tensorflow.nest.map_structure", "continuous_control_agent.ContinuousControlAgent._rnn", "core_output_list.append", "tensorflow.where", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append"], ["", "def", "_apply_rnn", "(", "self", ",", "representations", ",", "core_state", ",", "done", ")", ":", "\n", "    ", "\"\"\"Apply the recurrent part of the network.\n\n    Args:\n      representations: The representations coming out of the non-recurrent\n        part of the network, tensor of size [num_timesteps, batch_size, depth].\n      core_state: The recurrent state, given as nested structure of\n        sub-states. Each sub-states is of size [batch_size, substate_depth].\n      done: Tensor of size [num_timesteps, batch_size] which indicates\n        the end of a trajectory.\n\n    Returns:\n      A pair holding the representations coming out of the RNN (tensor of size\n      [num_timesteps, batch_size, depth]) and the updated RNN state (same size\n      as the input core_state.\n    \"\"\"", "\n", "batch_size", "=", "tf", ".", "shape", "(", "representations", ")", "[", "1", "]", "\n", "initial_core_state", "=", "self", ".", "_rnn", ".", "get_initial_state", "(", "\n", "batch_size", "=", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "core_output_list", "=", "[", "]", "\n", "for", "input_", ",", "d", "in", "zip", "(", "tf", ".", "unstack", "(", "representations", ")", ",", "tf", ".", "unstack", "(", "done", ")", ")", ":", "\n", "# If the episode ended, the core state should be reset before the next.", "\n", "      ", "core_state", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "x", ",", "y", ",", "d", "=", "d", ":", "tf", ".", "where", "(", "\n", "tf", ".", "reshape", "(", "d", ",", "[", "d", ".", "shape", "[", "0", "]", "]", "+", "[", "1", "]", "*", "(", "x", ".", "shape", ".", "rank", "-", "1", ")", ")", ",", "x", ",", "y", ")", ",", "\n", "initial_core_state", ",", "\n", "core_state", ")", "\n", "core_output", ",", "core_state", "=", "self", ".", "_rnn", "(", "input_", ",", "core_state", ")", "\n", "core_output_list", ".", "append", "(", "core_output", ")", "\n", "", "outputs", "=", "tf", ".", "stack", "(", "core_output_list", ")", "\n", "return", "outputs", ",", "core_state", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent._flat_apply_pre_lstm": [[302, 318], ["continuous_control_agent.ContinuousControlAgent.observation_normalizer.normalize", "continuous_control_agent.ContinuousControlAgent._shared", "tensorflow.clip_by_value", "continuous_control_agent.ContinuousControlAgent.observation_normalizer.correct"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization.InputNormalization.correct"], ["", "def", "_flat_apply_pre_lstm", "(", "self", ",", "env_outputs", ")", ":", "\n", "    ", "_", ",", "_", ",", "observations", ",", "_", ",", "_", "=", "env_outputs", "\n", "\n", "# Input normalization.", "\n", "observations", "=", "self", ".", "observation_normalizer", ".", "normalize", "(", "observations", ")", "\n", "if", "self", ".", "_input_clipping", "is", "not", "None", ":", "\n", "      ", "observations", "=", "tf", ".", "clip_by_value", "(", "\n", "observations", ",", "\n", "-", "self", ".", "_input_clipping", ",", "\n", "self", ".", "_input_clipping", ")", "\n", "", "if", "self", ".", "_correct_observations", ":", "\n", "      ", "observations", "=", "self", ".", "observation_normalizer", ".", "correct", "(", "observations", ")", "\n", "\n", "# The actual MLPs with the different heads.", "\n", "", "representations", "=", "self", ".", "_shared", "(", "observations", ")", "\n", "return", "representations", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent._flat_apply_no_lstm": [[319, 323], ["continuous_control_agent.ContinuousControlAgent._flat_apply_pre_lstm", "continuous_control_agent.ContinuousControlAgent._flat_apply_post_lstm"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent._flat_apply_pre_lstm", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent._flat_apply_post_lstm"], ["", "def", "_flat_apply_no_lstm", "(", "self", ",", "env_outputs", ")", ":", "\n", "    ", "\"\"\"Applies the modules.\"\"\"", "\n", "representations", "=", "self", ".", "_flat_apply_pre_lstm", "(", "env_outputs", ")", "\n", "return", "self", ".", "_flat_apply_post_lstm", "(", "representations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.ContinuousControlAgent._flat_apply_post_lstm": [[324, 333], ["continuous_control_agent.ContinuousControlAgent._value", "continuous_control_agent.ContinuousControlAgent._policy", "tensorflow.squeeze", "continuous_control_agent.ContinuousControlAgent._parametric_action_distribution().sample", "AgentOutput", "continuous_control_agent.ContinuousControlAgent._parametric_action_distribution"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], ["", "def", "_flat_apply_post_lstm", "(", "self", ",", "representations", ")", ":", "\n", "    ", "values", "=", "self", ".", "_value", "(", "representations", ")", "\n", "logits", "=", "self", ".", "_policy", "(", "representations", ")", "\n", "\n", "baselines", "=", "tf", ".", "squeeze", "(", "values", ",", "axis", "=", "-", "1", ")", "\n", "\n", "new_action", "=", "self", ".", "_parametric_action_distribution", "(", "logits", ")", ".", "sample", "(", "seed", "=", "None", ")", "\n", "\n", "return", "AgentOutput", "(", "new_action", ",", "logits", ",", "baselines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent._Layer.__init__": [[353, 361], ["super().__init__", "tensorflow.keras.layers.Dense"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "num_units", ",", "kernel_init", ",", "activation", ",", "normalizer", ",", "\n", "residual_connection", ")", ":", "\n", "    ", "\"\"\"Creates a _Layer.\"\"\"", "\n", "super", "(", "_Layer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "num_units", ",", "kernel_initializer", "=", "kernel_init", ",", "activation", "=", "activation", ")", "\n", "self", ".", "normalizer", "=", "normalizer", "\n", "self", ".", "residual_connection", "=", "residual_connection", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent._Layer.call": [[362, 365], ["continuous_control_agent._Layer.dense", "continuous_control_agent._Layer.normalizer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "tensor", ")", ":", "\n", "    ", "new_tensor", "=", "self", ".", "dense", "(", "self", ".", "normalizer", "(", "tensor", ")", ")", "\n", "return", "tensor", "+", "new_tensor", "if", "self", ".", "residual_connection", "else", "new_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent._ConcatTrainableTensor.__init__": [[370, 375], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "init_value", ")", ":", "\n", "    ", "\"\"\"Creates a layer.\"\"\"", "\n", "super", "(", "_ConcatTrainableTensor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "init_value", ".", "ndim", "==", "1", "\n", "self", ".", "init_value", "=", "init_value", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent._ConcatTrainableTensor.build": [[376, 378], ["tensorflow.Variable"], "methods", ["None"], ["", "def", "build", "(", "self", ",", "shape", ")", ":", "\n", "    ", "self", ".", "var", "=", "tf", ".", "Variable", "(", "self", ".", "init_value", ",", "trainable", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent._ConcatTrainableTensor.call": [[379, 384], ["tensorflow.concat", "tensorflow.broadcast_to"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "tensor", ")", ":", "\n", "    ", "return", "tf", ".", "concat", "(", "values", "=", "[", "\n", "tensor", ",", "\n", "tf", ".", "broadcast_to", "(", "self", ".", "var", ",", "tensor", ".", "shape", "[", ":", "-", "1", "]", "+", "self", ".", "var", ".", "shape", ")", "\n", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent.swish": [[335, 339], ["tensorflow.multiply", "tensorflow.nn.sigmoid"], "function", ["None"], ["", "", "@", "gin", ".", "configurable", "\n", "def", "swish", "(", "input_activation", ")", ":", "\n", "  ", "\"\"\"Swish activation function.\"\"\"", "\n", "return", "tf", ".", "multiply", "(", "input_activation", ",", "tf", ".", "nn", ".", "sigmoid", "(", "input_activation", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent._add_layers": [[341, 348], ["range", "sequential.add", "continuous_control_agent._Layer", "normalizer"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.add"], ["", "def", "_add_layers", "(", "sequential", ",", "num_layers", ",", "num_units", ",", "kernel_init", ",", "activation", ",", "\n", "normalizer", ",", "residual_connections", ")", ":", "\n", "  ", "\"\"\"Adds several layers to a tf.keras.Sequential instance.\"\"\"", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "    ", "sequential", ".", "add", "(", "\n", "_Layer", "(", "num_units", ",", "kernel_init", ",", "activation", ",", "normalizer", "(", ")", ",", "\n", "False", "if", "i", "==", "0", "else", "residual_connections", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.continuous_control_agent._rescale_initializer": [[386, 394], ["isinstance", "tensorflow.keras.initializers.get", "tf.keras.initializers.get."], "function", ["None"], ["", "", "def", "_rescale_initializer", "(", "initializer", ",", "rescale", ")", ":", "\n", "  ", "if", "rescale", "is", "None", ":", "\n", "    ", "return", "initializer", "\n", "", "if", "isinstance", "(", "initializer", ",", "str", ")", ":", "\n", "    ", "initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "get", "(", "initializer", ")", "\n", "", "def", "rescaled_initializer", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "rescale", "*", "initializer", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "rescaled_initializer", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization_test.EMANormalizationTest._setup_input_normalization": [[32, 42], ["seed_rl.agents.policy_gradient.modules.running_statistics.EMAMeanStd", "seed_rl.agents.policy_gradient.modules.input_normalization.InputNormalization", "seed_rl.agents.policy_gradient.modules.test_utils.create_distribution_strategy", "input_normalization_test.EMANormalizationTest.assertEqual", "seed_rl.agents.policy_gradient.modules.test_utils.create_distribution_strategy.scope", "seed_rl.agents.policy_gradient.modules.input_normalization.InputNormalization.init_normalization_stats"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.create_distribution_strategy", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization.InputNormalization.init_normalization_stats"], ["def", "_setup_input_normalization", "(", "self", ",", "beta", ",", "size", ")", ":", "\n", "    ", "\"\"\"Sets up the input normalizer and a distribution strategy to run.\"\"\"", "\n", "mean_std_tracker", "=", "running_statistics", ".", "EMAMeanStd", "(", "beta", "=", "beta", ")", "\n", "input_normalizer", "=", "input_normalization", ".", "InputNormalization", "(", "mean_std_tracker", ")", "\n", "strategy", "=", "test_utils", ".", "create_distribution_strategy", "(", "\n", "use_tpu", "=", "self", ".", "primary_device", "==", "'TPU'", ")", "\n", "self", ".", "assertEqual", "(", "strategy", ".", "num_replicas_in_sync", ",", "2", ")", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "input_normalizer", ".", "init_normalization_stats", "(", "size", ")", "\n", "", "return", "input_normalizer", ",", "strategy", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization_test.EMANormalizationTest._update_normalization_statistics": [[43, 51], ["tensorflow.data.Dataset.from_tensors", "iter", "next", "tensorflow.function", "strategy.run", "strategy.experimental_distribute_dataset"], "methods", ["None"], ["", "def", "_update_normalization_statistics", "(", "self", ",", "input_normalizer", ",", "strategy", ",", "\n", "inputs", ")", ":", "\n", "    ", "\"\"\"Updates the normalization statistics via the strategy.\"\"\"", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensors", "(", "inputs", ")", "\n", "dataset_iterator", "=", "iter", "(", "strategy", ".", "experimental_distribute_dataset", "(", "dataset", ")", ")", "\n", "distributed_values", "=", "next", "(", "dataset_iterator", ")", "\n", "f", "=", "tf", ".", "function", "(", "input_normalizer", ".", "update_normalization_statistics", ")", "\n", "strategy", ".", "run", "(", "f", ",", "(", "distributed_values", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization_test.EMANormalizationTest.test_normalization": [[52, 68], ["input_normalization_test.EMANormalizationTest._setup_input_normalization", "tensorflow.reshape", "input_normalization_test.EMANormalizationTest._update_normalization_statistics", "tensorflow.reduce_mean", "tensorflow.math.reduce_std", "input_normalization_test.EMANormalizationTest.assertAllClose", "input_normalization_test.EMANormalizationTest.assertAllClose", "tensorflow.range", "strategy.scope", "input_normalizer.normalize", "tensorflow.zeros_like", "tensorflow.ones_like"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization_test.EMANormalizationTest._setup_input_normalization", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest._update_normalization_statistics", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize"], ["", "def", "test_normalization", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the normalization works.\"\"\"", "\n", "input_normalizer", ",", "strategy", "=", "self", ".", "_setup_input_normalization", "(", "1.", ",", "10", ")", "\n", "\n", "# Apply update.", "\n", "inputs", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "200", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "(", "20", ",", "10", ")", ")", "\n", "self", ".", "_update_normalization_statistics", "(", "input_normalizer", ",", "strategy", ",", "inputs", ")", "\n", "\n", "# Verify that normalization works correctly.", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "normalized", "=", "input_normalizer", ".", "normalize", "(", "inputs", ")", "\n", "\n", "", "mean", "=", "tf", ".", "reduce_mean", "(", "normalized", ",", "0", ")", "\n", "std", "=", "tf", ".", "math", ".", "reduce_std", "(", "normalized", ",", "0", ")", "\n", "self", ".", "assertAllClose", "(", "mean", ",", "tf", ".", "zeros_like", "(", "mean", ")", ")", "\n", "self", ".", "assertAllClose", "(", "std", ",", "tf", ".", "ones_like", "(", "std", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization_test.EMANormalizationTest.test_variables": [[69, 74], ["input_normalization_test.EMANormalizationTest._setup_input_normalization", "input_normalization_test.EMANormalizationTest.assertLen", "input_normalization_test.EMANormalizationTest.assertLen"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization_test.EMANormalizationTest._setup_input_normalization"], ["", "def", "test_variables", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that we have the correct number of variables.\"\"\"", "\n", "input_normalizer", ",", "_", "=", "self", ".", "_setup_input_normalization", "(", ".5", ",", "10", ")", "\n", "self", ".", "assertLen", "(", "input_normalizer", ".", "variables", ",", "4", ")", "\n", "self", ".", "assertLen", "(", "input_normalizer", ".", "trainable_variables", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization_test.EMANormalizationTest.test_invariance": [[75, 96], ["input_normalization_test.EMANormalizationTest._setup_input_normalization", "tensorflow.reshape", "input_normalization_test.EMANormalizationTest._update_normalization_statistics", "input_normalization_test.EMANormalizationTest.assertAllClose", "tensorflow.range", "strategy.scope", "input_normalizer.normalize", "input_normalizer.correct", "strategy.scope", "input_normalizer.normalize", "input_normalizer.correct"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization_test.EMANormalizationTest._setup_input_normalization", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest._update_normalization_statistics", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization.InputNormalization.correct", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization.InputNormalization.correct"], ["", "def", "test_invariance", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the update keeps the convolution invariant.\"\"\"", "\n", "input_normalizer", ",", "strategy", "=", "self", ".", "_setup_input_normalization", "(", ".5", ",", "10", ")", "\n", "inputs", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "200", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "(", "20", ",", "10", ")", ")", "\n", "\n", "# Run the convolution of `normalize(...)` and `correct(...)` *before* the", "\n", "# update of the statistics.", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "before", "=", "input_normalizer", ".", "normalize", "(", "inputs", ")", "\n", "before", "=", "input_normalizer", ".", "correct", "(", "before", ")", "\n", "\n", "", "self", ".", "_update_normalization_statistics", "(", "input_normalizer", ",", "strategy", ",", "inputs", ")", "\n", "\n", "# Run the convolution of `normalize(...)` and `correct(...)` *after* the", "\n", "# update of the statistics.", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "after", "=", "input_normalizer", ".", "normalize", "(", "inputs", ")", "\n", "after", "=", "input_normalizer", ".", "correct", "(", "after", ")", "\n", "\n", "# Verify that the update is correct.", "\n", "", "self", ".", "assertAllClose", "(", "before", ",", "after", ",", "rtol", "=", "1e-5", ",", "atol", "=", "1e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization_test.setUpModule": [[23, 26], ["seed_rl.agents.policy_gradient.modules.test_utils.simulate_two_devices"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.simulate_two_devices"], ["def", "setUpModule", "(", ")", ":", "\n", "# We want our tests to run on several devices with a mirrored strategy.", "\n", "  ", "test_utils", ".", "simulate_two_devices", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.AdvantagePreprocessor.__init__": [[28, 43], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "normalize", "=", "False", ",", "only_positive", "=", "False", ",", "only_top_half", "=", "False", ",", "\n", "offset", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates the advantage preprocessor.\n\n    Args:\n      normalize: Whether to normalize adventages to have mean 0 and std 1 in\n        each batch.\n      only_positive: Whether to only take positive advantages.\n      only_top_half: Whether to only take top half of advantages in each batch.\n      offset: A value added to advantages (after normalization).\n    \"\"\"", "\n", "self", ".", "normalize", "=", "normalize", "\n", "self", ".", "only_positive", "=", "only_positive", "\n", "self", ".", "only_top_half", "=", "only_top_half", "\n", "self", ".", "offset", "=", "offset", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.AdvantagePreprocessor.__call__": [[44, 68], ["tensorflow.ones_like", "tensorflow.reduce_mean", "tensorflow.reshape", "tensorflow.math.reduce_min", "tensorflow.cast", "tensorflow.cast", "tensorflow.math.reduce_std", "tensorflow.math.top_k"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "advantages", ")", ":", "\n", "    ", "\"\"\"Processes the advantages.\n\n    Args:\n       advantages: A tensor with advantages.\n\n    Returns:\n       Processed advantages and a tf.float32 tensor of the same shape\n       with 0s and 1s indicating which advantages should be used.\n    \"\"\"", "\n", "mask", "=", "tf", ".", "ones_like", "(", "advantages", ")", "\n", "if", "self", ".", "normalize", ":", "\n", "      ", "advantages", "-=", "tf", ".", "reduce_mean", "(", "advantages", ")", "\n", "advantages", "/=", "tf", ".", "math", ".", "reduce_std", "(", "advantages", ")", "+", "1e-8", "\n", "", "if", "self", ".", "only_top_half", ":", "\n", "      ", "flat", "=", "tf", ".", "reshape", "(", "advantages", ",", "[", "-", "1", "]", ")", "\n", "median", "=", "tf", ".", "math", ".", "reduce_min", "(", "tf", ".", "math", ".", "top_k", "(", "flat", ",", "k", "=", "flat", ".", "shape", "[", "0", "]", "//", "2", ",", "\n", "sorted", "=", "False", ")", "[", "0", "]", ")", "\n", "mask", "*=", "tf", ".", "cast", "(", "advantages", ">=", "median", ",", "tf", ".", "float32", ")", "\n", "", "if", "self", ".", "only_positive", ":", "\n", "      ", "mask", "*=", "tf", ".", "cast", "(", "advantages", ">", "0.", ",", "tf", ".", "float32", ")", "\n", "", "if", "self", ".", "offset", "is", "not", "None", ":", "\n", "      ", "advantages", "+=", "self", ".", "offset", "\n", "", "return", "mask", "*", "advantages", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.GeneralizedAdvantagePolicyLoss.__init__": [[77, 108], ["policy_losses.AdvantagePreprocessor"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "advantage_preprocessor", "=", "None", ",", "\n", "use_importance_weights", "=", "False", ",", "\n", "max_importance_weight", "=", "None", ",", "\n", "ppo_epsilon", "=", "None", ",", "\n", "max_advantage", "=", "None", ",", "\n", "advantage_transformation", "=", "None", ",", "\n", "temperature", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates the loss.\n\n    Args:\n       advantage_preprocessor: An object (of AdvantagePreprocessor class) used\n         to process the advantages.\n       use_importance_weights: Whether to use importance sampling weights.\n       max_importance_weight: Bigger importance weights are clipped.\n       ppo_epsilon: If not None, than PPO-style pessimistic clipping is used.\n       max_advantage: Bigger advantages are clipped. Clipping happens\n         between scaling and applying the transformation.\n       advantage_transformation: A function applied to advantages.\n       temperature: If not None, than MPO/AWR-style advantages exponentiation\n         is performed. This argument should be a Coefficient object which\n         provides the temperature for the exponentiation.\n    \"\"\"", "\n", "self", ".", "advantage_preprocessor", "=", "(", "advantage_preprocessor", "or", "\n", "AdvantagePreprocessor", "(", ")", ")", "\n", "self", ".", "use_importance_weights", "=", "use_importance_weights", "\n", "self", ".", "max_importance_weight", "=", "max_importance_weight", "\n", "self", ".", "max_advantage", "=", "max_advantage", "\n", "self", ".", "advantage_transformation", "=", "advantage_transformation", "\n", "self", ".", "ppo_epsilon", "=", "ppo_epsilon", "\n", "self", ".", "temperature", "=", "temperature", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.GeneralizedAdvantagePolicyLoss.__call__": [[109, 185], ["policy_losses.GeneralizedAdvantagePolicyLoss.log", "policy_losses.GeneralizedAdvantagePolicyLoss.log", "policy_losses.GeneralizedAdvantagePolicyLoss.log", "policy_losses.GeneralizedAdvantagePolicyLoss.log", "policy_losses.GeneralizedAdvantagePolicyLoss.advantage_preprocessor", "policy_losses.GeneralizedAdvantagePolicyLoss.log", "tensorflow.reduce_max", "tensorflow.reduce_min", "policy_losses.GeneralizedAdvantagePolicyLoss.log", "policy_losses.GeneralizedAdvantagePolicyLoss.log", "policy_losses.GeneralizedAdvantagePolicyLoss.log", "tensorflow.stop_gradient", "policy_losses.GeneralizedAdvantagePolicyLoss.log", "tensorflow.reduce_mean", "tensorflow.abs", "policy_losses.GeneralizedAdvantagePolicyLoss.log", "policy_losses.GeneralizedAdvantagePolicyLoss.log", "tensorflow.stop_gradient", "tensorflow.cast", "tensorflow.minimum", "policy_losses.GeneralizedAdvantagePolicyLoss.log", "tensorflow.exp", "policy_losses.GeneralizedAdvantagePolicyLoss.log", "policy_losses.GeneralizedAdvantagePolicyLoss.temperature.adjustment_loss", "policy_losses.GeneralizedAdvantagePolicyLoss.temperature", "tensorflow.stop_gradient", "tensorflow.minimum", "policy_losses.GeneralizedAdvantagePolicyLoss.log", "policy_losses.GeneralizedAdvantagePolicyLoss.advantage_transformation", "tensorflow.minimum", "tensorflow.math.log", "tensorflow.cast", "tensorflow.math.reduce_logsumexp", "tensorflow.math.log", "policy_losses.GeneralizedAdvantagePolicyLoss.temperature", "tensorflow.cast", "tensorflow.math.log", "tensorflow.math.log", "tensorflow.math.log", "tensorflow.reduce_sum"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints.LagrangeInequalityCoefficient.adjustment_loss", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log"], ["", "def", "__call__", "(", "self", ",", "advantages", ",", "target_action_log_probs", ",", "\n", "behaviour_action_log_probs", ",", "actions", ",", "target_logits", ",", "\n", "behaviour_logits", ",", "parametric_action_distribution", "=", "None", ")", ":", "\n", "    ", "self", ".", "log", "(", "'GeneralizedAdvantagePolicyLoss/advantages'", ",", "advantages", ")", "\n", "self", ".", "log", "(", "'GeneralizedAdvantagePolicyLoss/abs_advantages'", ",", "\n", "tf", ".", "abs", "(", "advantages", ")", ")", "\n", "self", ".", "log", "(", "'GeneralizedAdvantagePolicyLoss/log_pi'", ",", "target_action_log_probs", ")", "\n", "self", ".", "log", "(", "'GeneralizedAdvantagePolicyLoss/log_mu'", ",", "\n", "behaviour_action_log_probs", ")", "\n", "advantages", ",", "mask", "=", "self", ".", "advantage_preprocessor", "(", "advantages", ")", "\n", "\n", "# advantage transformation (e.g. AWR/V-MPO)", "\n", "if", "self", ".", "advantage_transformation", "is", "not", "None", ":", "\n", "      ", "assert", "self", ".", "temperature", "is", "not", "None", "\n", "self", ".", "log", "(", "'GeneralizedAdvantagePolicyLoss/temperature'", ",", "self", ".", "temperature", "(", ")", ")", "\n", "advantages", "=", "advantages", "/", "tf", ".", "stop_gradient", "(", "self", ".", "temperature", "(", ")", ")", "\n", "if", "self", ".", "max_advantage", "is", "not", "None", ":", "\n", "        ", "advantages", "=", "tf", ".", "minimum", "(", "advantages", ",", "self", ".", "max_advantage", ")", "\n", "self", ".", "log", "(", "'GeneralizedAdvantagePolicyLoss/p_clipped_advantage'", ",", "\n", "tf", ".", "cast", "(", "advantages", "==", "self", ".", "max_advantage", ",", "tf", ".", "float32", ")", ")", "\n", "", "advantages_before_transformation", "=", "advantages", "\n", "advantages", "=", "mask", "*", "self", ".", "advantage_transformation", "(", "advantages", ")", "\n", "self", ".", "log", "(", "'GeneralizedAdvantagePolicyLoss/transformed_advantages'", ",", "\n", "advantages", ")", "\n", "", "else", ":", "\n", "      ", "if", "self", ".", "max_advantage", "is", "not", "None", ":", "\n", "        ", "advantages", "=", "tf", ".", "minimum", "(", "advantages", ",", "self", ".", "max_advantage", ")", "\n", "", "advantages", "*=", "mask", "\n", "\n", "", "self", ".", "log", "(", "'GeneralizedAdvantagePolicyLoss/processed_advantages'", ",", "advantages", ")", "\n", "max_adv", "=", "tf", ".", "reduce_max", "(", "mask", "*", "advantages", "+", "(", "1.", "-", "mask", ")", "*", "-", "1e9", ")", "\n", "min_adv", "=", "tf", ".", "reduce_min", "(", "mask", "*", "advantages", "+", "(", "1.", "-", "mask", ")", "*", "1e9", ")", "\n", "self", ".", "log", "(", "'GeneralizedAdvantagePolicyLoss/processed_advantages_min'", ",", "min_adv", ")", "\n", "self", ".", "log", "(", "'GeneralizedAdvantagePolicyLoss/processed_advantages_max'", ",", "max_adv", ")", "\n", "self", ".", "log", "(", "'GeneralizedAdvantagePolicyLoss/processed_advantages_range'", ",", "\n", "max_adv", "-", "min_adv", ")", "\n", "\n", "# PG loss", "\n", "loss", "=", "-", "target_action_log_probs", "*", "tf", ".", "stop_gradient", "(", "advantages", ")", "\n", "\n", "# importance sampling weights", "\n", "log_rho", "=", "target_action_log_probs", "-", "behaviour_action_log_probs", "\n", "log_rho", "=", "tf", ".", "stop_gradient", "(", "log_rho", ")", "\n", "if", "self", ".", "ppo_epsilon", "is", "not", "None", ":", "\n", "# This is written differently that the standard PPO loss but should give", "\n", "# the same gradient.", "\n", "      ", "clip_pos_mask", "=", "(", "(", "advantages", ">", "0", ")", "&", "\n", "(", "log_rho", ">", "tf", ".", "math", ".", "log", "(", "1", "+", "self", ".", "ppo_epsilon", ")", ")", ")", "\n", "clip_neg_mask", "=", "(", "(", "advantages", "<", "0", ")", "&", "\n", "(", "log_rho", "<", "-", "tf", ".", "math", ".", "log", "(", "1", "+", "self", ".", "ppo_epsilon", ")", ")", ")", "\n", "loss_mask", "=", "tf", ".", "cast", "(", "~", "(", "clip_pos_mask", "|", "clip_neg_mask", ")", ",", "tf", ".", "float32", ")", "\n", "loss", "*=", "loss_mask", "\n", "log_rho", "*=", "loss_mask", "# to avoid overflow in exp", "\n", "", "if", "self", ".", "max_importance_weight", "is", "not", "None", ":", "\n", "      ", "log_rho", "=", "tf", ".", "minimum", "(", "log_rho", ",", "tf", ".", "math", ".", "log", "(", "self", ".", "max_importance_weight", ")", ")", "\n", "self", ".", "log", "(", "'GeneralizedAdvantagePolicyLoss/p_clipped_iw'", ",", "\n", "tf", ".", "cast", "(", "log_rho", "==", "tf", ".", "math", ".", "log", "(", "self", ".", "max_importance_weight", ")", ",", "\n", "tf", ".", "float32", ")", ")", "\n", "", "self", ".", "log", "(", "'GeneralizedAdvantagePolicyLoss/log_rho'", ",", "log_rho", ")", "\n", "if", "self", ".", "use_importance_weights", ":", "\n", "      ", "loss", "*=", "tf", ".", "exp", "(", "log_rho", ")", "\n", "\n", "", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "\n", "if", "self", ".", "advantage_transformation", "is", "not", "None", ":", "# temperature adjustment", "\n", "# This is KL between nonparametric target distribution and behavioral one.", "\n", "# Eq. (4) in V-MPO paper.", "\n", "      ", "advantages", "=", "advantages_before_transformation", "\n", "advantages", "*=", "mask", "\n", "advantages", "-=", "(", "1.", "-", "mask", ")", "*", "1e3", "# will be 0 after exp", "\n", "kl", "=", "tf", ".", "math", ".", "reduce_logsumexp", "(", "advantages", ")", "-", "tf", ".", "math", ".", "log", "(", "\n", "tf", ".", "reduce_sum", "(", "mask", ")", "+", "1e-3", ")", "\n", "self", ".", "log", "(", "'GeneralizedAdvantagePolicyLoss/mpo_kl'", ",", "kl", ")", "\n", "loss", "+=", "self", ".", "temperature", ".", "adjustment_loss", "(", "kl", ")", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.pg": [[187, 190], ["policy_losses.GeneralizedAdvantagePolicyLoss"], "function", ["None"], ["", "", "@", "gin", ".", "configurable", "\n", "def", "pg", "(", ")", ":", "\n", "  ", "return", "GeneralizedAdvantagePolicyLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.vtrace": [[192, 197], ["policy_losses.GeneralizedAdvantagePolicyLoss"], "function", ["None"], ["", "@", "gin", ".", "configurable", "\n", "def", "vtrace", "(", "max_importance_weight", "=", "1.", ")", ":", "\n", "  ", "return", "GeneralizedAdvantagePolicyLoss", "(", "\n", "use_importance_weights", "=", "True", ",", "\n", "max_importance_weight", "=", "max_importance_weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.ppo": [[199, 207], ["policy_losses.GeneralizedAdvantagePolicyLoss", "policy_losses.AdvantagePreprocessor"], "function", ["None"], ["", "@", "gin", ".", "configurable", "\n", "def", "ppo", "(", "epsilon", ",", "normalize_advantages", "=", "False", ",", "advantage_offset", "=", "None", ")", ":", "\n", "  ", "return", "GeneralizedAdvantagePolicyLoss", "(", "\n", "use_importance_weights", "=", "True", ",", "\n", "ppo_epsilon", "=", "epsilon", ",", "\n", "advantage_preprocessor", "=", "AdvantagePreprocessor", "(", "\n", "normalize", "=", "normalize_advantages", ",", "\n", "offset", "=", "advantage_offset", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.awr": [[209, 215], ["policy_losses.GeneralizedAdvantagePolicyLoss", "seed_rl.agents.policy_gradient.modules.constraints.FixedCoefficient", "tensorflow.math.log"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log"], ["", "@", "gin", ".", "configurable", "\n", "def", "awr", "(", "beta", ",", "w_max", ")", ":", "\n", "  ", "return", "GeneralizedAdvantagePolicyLoss", "(", "\n", "advantage_transformation", "=", "tf", ".", "exp", ",", "\n", "temperature", "=", "constraints", ".", "FixedCoefficient", "(", "beta", ")", ",", "\n", "max_advantage", "=", "tf", ".", "math", ".", "log", "(", "w_max", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.bc_logp": [[217, 222], ["policy_losses.GeneralizedAdvantagePolicyLoss", "seed_rl.agents.policy_gradient.modules.constraints.FixedCoefficient", "tensorflow.constant"], "function", ["None"], ["", "def", "bc_logp", "(", ")", ":", "\n", "  ", "return", "GeneralizedAdvantagePolicyLoss", "(", "\n", "advantage_transformation", "=", "lambda", "x", ":", "tf", ".", "constant", "(", "\n", "1", ",", "dtype", "=", "x", ".", "dtype", ",", "shape", "=", "x", ".", "shape", ")", ",", "\n", "temperature", "=", "constraints", ".", "FixedCoefficient", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.softmax_all_dims": [[224, 229], ["tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.softmax"], "function", ["None"], ["", "@", "gin", ".", "configurable", "\n", "def", "softmax_all_dims", "(", "t", ")", ":", "\n", "# Softmax with reduction across all axes.", "\n", "  ", "flat", "=", "tf", ".", "reshape", "(", "t", ",", "[", "-", "1", "]", ")", "\n", "return", "tf", ".", "reshape", "(", "tf", ".", "nn", ".", "softmax", "(", "flat", ")", ",", "t", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.vmpo": [[231, 241], ["policy_losses.GeneralizedAdvantagePolicyLoss", "policy_losses.AdvantagePreprocessor", "seed_rl.agents.policy_gradient.modules.constraints.LagrangeInequalityCoefficient"], "function", ["None"], ["", "@", "gin", ".", "configurable", "\n", "def", "vmpo", "(", "e_n", ")", ":", "\n", "# Backward KL regularizer needs to be added separately to get full V-MPO.", "\n", "  ", "return", "GeneralizedAdvantagePolicyLoss", "(", "\n", "advantage_transformation", "=", "softmax_all_dims", ",", "\n", "advantage_preprocessor", "=", "AdvantagePreprocessor", "(", "only_top_half", "=", "True", ")", ",", "\n", "temperature", "=", "constraints", ".", "LagrangeInequalityCoefficient", "(", "\n", "threshold", "=", "e_n", ",", "\n", "adjustment_speed", "=", "10", ",", "\n", "init_variables", "=", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.repeat_positive_advantages": [[243, 248], ["policy_losses.awr"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.awr"], ["", "@", "gin", ".", "configurable", "\n", "def", "repeat_positive_advantages", "(", ")", ":", "\n", "# This is supervised learning on actions with positive advantages.", "\n", "# Both, AWR and V-MPO have this behaviour in the limit (beta->0 or e_n->0).", "\n", "  ", "return", "awr", "(", "beta", "=", "1e-6", ",", "w_max", "=", "1.", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.generalized_onpolicy_loss_test._DummyAgent.__call__": [[40, 48], ["tensorflow.ones", "tensorflow.ones", "tensorflow.ones", "_AgentOutput"], "methods", ["None"], ["  ", "def", "__call__", "(", "self", ",", "input_", ",", "core_state", ",", "unroll", "=", "False", ",", "is_training", "=", "False", ")", ":", "\n", "# prev_actions, env_outputs = input_", "\n", "    ", "action", "=", "tf", ".", "ones", "(", "(", "_NUM_UNROLLS", ",", "_NUM_BATCH", ",", "_NUM_ACTIONS", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "policy_logits", "=", "tf", ".", "ones", "(", "(", "_NUM_UNROLLS", ",", "_NUM_BATCH", ",", "2", "*", "_NUM_ACTIONS", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "baseline", "=", "tf", ".", "ones", "(", "(", "_NUM_UNROLLS", ",", "_NUM_BATCH", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "return", "_AgentOutput", "(", "action", ",", "policy_logits", ",", "baseline", ")", ",", "core_state", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.generalized_onpolicy_loss_test._DummyPolicyLoss.__call__": [[52, 55], ["tensorflow.reduce_mean", "tensorflow.exp"], "methods", ["None"], ["  ", "def", "__call__", "(", "self", ",", "advantages_", ",", "target_action_log_probs", ",", "\n", "behaviour_action_log_probs", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "tf", ".", "reduce_mean", "(", "advantages_", "*", "tf", ".", "exp", "(", "target_action_log_probs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.generalized_onpolicy_loss_test._DummyRegularizationLoss.__call__": [[59, 62], ["parametric_action_distribution().entropy", "parametric_action_distribution"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.entropy"], ["  ", "def", "__call__", "(", "self", ",", "parametric_action_distribution", ",", "target_action_logits", ",", "\n", "behaviour_action_logits", ",", "actions", ")", ":", "\n", "    ", "return", "parametric_action_distribution", "(", "target_action_logits", ")", ".", "entropy", "(", ")", ",", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.generalized_onpolicy_loss_test.GeneralizedOnPolicyLossTest.setUp": [[67, 76], ["super().setUp", "seed_rl.agents.policy_gradient.modules.popart.PopArt", "seed_rl.agents.policy_gradient.modules.popart.PopArt.init", "seed_rl.agents.policy_gradient.modules.generalized_onpolicy_loss.GeneralizedOnPolicyLoss", "seed_rl.agents.policy_gradient.modules.running_statistics.AverageMeanStd", "generalized_onpolicy_loss_test._DummyAgent", "seed_rl.agents.policy_gradient.modules.advantages.GAE", "generalized_onpolicy_loss_test._DummyPolicyLoss", "generalized_onpolicy_loss_test._DummyRegularizationLoss", "seed_rl.common.parametric_distribution.normal_tanh_distribution"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.TPUEncodeTest.setUp", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.init", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.normal_tanh_distribution"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "setUp", "(", ")", "\n", "reward_normalizer", "=", "popart", ".", "PopArt", "(", "running_statistics", ".", "AverageMeanStd", "(", ")", ")", "\n", "reward_normalizer", ".", "init", "(", ")", "\n", "self", ".", "_loss", "=", "generalized_onpolicy_loss", ".", "GeneralizedOnPolicyLoss", "(", "\n", "_DummyAgent", "(", ")", ",", "reward_normalizer", ",", "\n", "parametric_distribution", ".", "normal_tanh_distribution", "(", "\n", "_NUM_ACTIONS", ")", ".", "create_dist", ",", "advantages", ".", "GAE", "(", "lambda_", "=", "0.95", ")", ",", "\n", "_DummyPolicyLoss", "(", ")", ",", "0.97", ",", "_DummyRegularizationLoss", "(", ")", ",", "0.2", ",", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.generalized_onpolicy_loss_test.GeneralizedOnPolicyLossTest.test_one": [[77, 93], ["tensorflow.zeros", "tensorflow.zeros", "tensorflow.ones", "tensorflow.ones", "tensorflow.ones", "_AgentOutput", "generalized_onpolicy_loss_test.GeneralizedOnPolicyLossTest._loss", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros"], "methods", ["None"], ["", "def", "test_one", "(", "self", ")", ":", "\n", "    ", "agent_state", "=", "tf", ".", "zeros", "(", "(", "_NUM_UNROLLS", ",", "_NUM_BATCH", ",", "_NUM_CORE_STATE", ")", ",", "\n", "tf", ".", "float32", ")", "\n", "prev_actions", "=", "tf", ".", "zeros", "(", "(", "_NUM_BATCH", ",", "_NUM_CORE_STATE", ")", ",", "tf", ".", "float32", ")", "\n", "env_outputs", "=", "(", "tf", ".", "zeros", "(", "(", "_NUM_UNROLLS", ",", "_NUM_BATCH", ")", ",", "tf", ".", "float32", ")", ",", "\n", "tf", ".", "zeros", "(", "(", "_NUM_UNROLLS", ",", "_NUM_BATCH", ")", ",", "tf", ".", "bool", ")", ",", "\n", "tf", ".", "zeros", "(", "(", "_NUM_UNROLLS", ",", "_NUM_BATCH", ",", "17", ")", ",", "tf", ".", "float32", ")", ",", "\n", "tf", ".", "zeros", "(", "(", "_NUM_UNROLLS", ",", "_NUM_BATCH", ")", ",", "tf", ".", "bool", ")", ",", "\n", "tf", ".", "zeros", "(", "(", "_NUM_UNROLLS", ",", "_NUM_BATCH", ")", ",", "tf", ".", "bool", ")", ")", "\n", "action", "=", "tf", ".", "ones", "(", "(", "_NUM_UNROLLS", ",", "_NUM_BATCH", ",", "_NUM_ACTIONS", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "policy_logits", "=", "tf", ".", "ones", "(", "(", "_NUM_UNROLLS", ",", "_NUM_BATCH", ",", "2", "*", "_NUM_ACTIONS", ")", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "baseline", "=", "tf", ".", "ones", "(", "(", "_NUM_UNROLLS", ",", "_NUM_BATCH", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "agent_outputs", "=", "_AgentOutput", "(", "action", ",", "policy_logits", ",", "baseline", ")", "\n", "self", ".", "_loss", "(", "agent_state", ",", "prev_actions", ",", "env_outputs", ",", "agent_outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization.InputNormalization.__init__": [[49, 63], ["isinstance", "ValueError", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mean_std_tracker", ")", ":", "\n", "    ", "\"\"\"Creates a InputNormalization.\n\n    Args:\n      mean_std_tracker: Instance of running_statistics.MeanStd used for tracking\n        the mean and the standard deviation.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "mean_std_tracker", ",", "running_statistics", ".", "MeanStd", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "f'`mean_std_tracker` needs to be an instance of MeanStd, '", "\n", "f'got {type(mean_std_tracker)}'", ")", "\n", "", "self", ".", "mean_std_tracker", "=", "mean_std_tracker", "\n", "self", ".", "compensation_mean", "=", "None", "\n", "self", ".", "compensation_std", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization.InputNormalization.initialized": [[64, 68], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "initialized", "(", "self", ")", ":", "\n", "    ", "\"\"\"Boolean indicating if the module is initialized.\"\"\"", "\n", "return", "self", ".", "compensation_mean", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization.InputNormalization.init_normalization_stats": [[69, 93], ["input_normalization.InputNormalization.mean_std_tracker.init", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.zeros", "tensorflow.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.init"], ["", "def", "init_normalization_stats", "(", "self", ",", "input_size", ")", ":", "\n", "    ", "\"\"\"Initializes normalization variables.\n\n    This is done explicitly in a manual step since variables need to be created\n    under the correct distribution strategy scope.\n\n    Args:\n      input_size: Integer with dimensionality of input.\n    \"\"\"", "\n", "self", ".", "mean_std_tracker", ".", "init", "(", "input_size", ")", "\n", "self", ".", "compensation_mean", "=", "tf", ".", "Variable", "(", "\n", "name", "=", "'running_mean'", ",", "\n", "shape", "=", "[", "input_size", "]", ",", "\n", "trainable", "=", "True", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initial_value", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "input_size", "]", ")", ",", "\n", "aggregation", "=", "tf", ".", "VariableAggregation", ".", "MEAN", ")", "\n", "self", ".", "compensation_std", "=", "tf", ".", "Variable", "(", "\n", "name", "=", "'running_std'", ",", "\n", "shape", "=", "[", "input_size", "]", ",", "\n", "trainable", "=", "True", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initial_value", "=", "tf", ".", "ones", "(", "shape", "=", "[", "input_size", "]", ")", ",", "\n", "aggregation", "=", "tf", ".", "VariableAggregation", ".", "MEAN", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization.InputNormalization.normalize": [[94, 104], ["input_normalization.InputNormalization.mean_std_tracker.normalize"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize"], ["", "def", "normalize", "(", "self", ",", "x", ")", ":", "\n", "    ", "\"\"\"Normalizes input values x using past target statistics.\n\n    Args:\n      x: <float32>[(...), size] tensor.\n\n    Returns:\n      <float32>[(...), size] normalized tensor.\n    \"\"\"", "\n", "return", "self", ".", "mean_std_tracker", ".", "normalize", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization.InputNormalization.correct": [[105, 115], ["None"], "methods", ["None"], ["", "def", "correct", "(", "self", ",", "x", ")", ":", "\n", "    ", "\"\"\"Corrects a normalized input x using compensation parameters.\n\n    Args:\n      x: <float32>[(...), size] tensor.\n\n    Returns:\n      <float32>[(...), size] corrected tensor.\n    \"\"\"", "\n", "return", "self", ".", "compensation_std", "*", "x", "+", "self", ".", "compensation_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization.InputNormalization.update_normalization_statistics": [[116, 134], ["input_normalization.InputNormalization.mean_std_tracker.get_mean_std", "input_normalization.InputNormalization.mean_std_tracker.update", "input_normalization.InputNormalization.mean_std_tracker.get_mean_std", "input_normalization.InputNormalization.compensation_mean.assign", "input_normalization.InputNormalization.compensation_std.assign"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.get_mean_std", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.update", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.get_mean_std"], ["", "def", "update_normalization_statistics", "(", "self", ",", "data", ")", ":", "\n", "    ", "\"\"\"Updates normalization statistics.\n\n    Args:\n      data: <float32>[(...), size].\n    \"\"\"", "\n", "# Update the running statistics.", "\n", "mean1", ",", "std1", "=", "self", ".", "mean_std_tracker", ".", "get_mean_std", "(", ")", "\n", "self", ".", "mean_std_tracker", ".", "update", "(", "data", ")", "\n", "mean2", ",", "std2", "=", "self", ".", "mean_std_tracker", ".", "get_mean_std", "(", ")", "\n", "\n", "# Update the compensation parameters based on means and standard deviations", "\n", "# before and after the statistics update.", "\n", "new_compensation_std", "=", "std2", "/", "std1", "*", "self", ".", "compensation_std", "\n", "new_compensation_mean", "=", "(", "self", ".", "compensation_mean", "+", "\n", "self", ".", "compensation_std", "/", "std1", "*", "(", "mean2", "-", "mean1", ")", ")", "\n", "self", ".", "compensation_mean", ".", "assign", "(", "new_compensation_mean", ")", "\n", "self", ".", "compensation_std", ".", "assign", "(", "new_compensation_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.input_normalization.InputNormalization.get_mean_std": [[135, 137], ["input_normalization.InputNormalization.mean_std_tracker.get_mean_std"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.get_mean_std"], ["", "def", "get_mean_std", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "mean_std_tracker", ".", "get_mean_std", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.generalized_onpolicy_loss.GeneralizedOnPolicyLoss.__init__": [[29, 58], ["tensorflow.keras.losses.Huber", "tensorflow.keras.losses.MeanSquaredError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "agent", ",", "reward_normalizer", ",", "parametric_action_distribution", ",", "\n", "advantage_estimator", ",", "policy_loss", ",", "discount_factor", ",", "\n", "regularizer", "=", "None", ",", "max_abs_reward", "=", "None", ",", "\n", "handle_abandoned_episodes_properly", "=", "True", ",", "\n", "huber_delta", "=", "None", ",", "value_ppo_style_clip_eps", "=", "None", ",", "\n", "baseline_cost", "=", "1.", ",", "include_regularization_in_returns", "=", "False", ",", "\n", "frame_skip", "=", "1", ",", "reward_scaling", "=", "1.0", ")", ":", "\n", "    ", "\"\"\"Creates a GeneralizedOnPolicyLoss.\"\"\"", "\n", "self", ".", "_agent", "=", "agent", "\n", "self", ".", "_reward_normalizer", "=", "reward_normalizer", "\n", "self", ".", "_parametric_action_distribution", "=", "parametric_action_distribution", "\n", "self", ".", "_advantage_estimator", "=", "advantage_estimator", "\n", "self", ".", "_policy_loss", "=", "policy_loss", "\n", "self", ".", "_regularizer", "=", "regularizer", "\n", "self", ".", "_max_abs_reward", "=", "max_abs_reward", "\n", "self", ".", "_reward_scaling", "=", "reward_scaling", "\n", "self", ".", "_baseline_cost", "=", "baseline_cost", "\n", "# Provided here so that it is shared.", "\n", "self", ".", "_discount_factor", "=", "discount_factor", "\n", "self", ".", "_frame_skip", "=", "frame_skip", "\n", "self", ".", "_handle_abandoned_episodes_properly", "=", "handle_abandoned_episodes_properly", "\n", "self", ".", "_value_ppo_style_clip_eps", "=", "value_ppo_style_clip_eps", "\n", "self", ".", "_include_regularization_in_returns", "=", "include_regularization_in_returns", "\n", "if", "huber_delta", "is", "not", "None", ":", "\n", "      ", "self", ".", "v_loss_fn", "=", "tf", ".", "keras", ".", "losses", ".", "Huber", "(", "\n", "delta", "=", "huber_delta", ",", "reduction", "=", "tf", ".", "keras", ".", "losses", ".", "Reduction", ".", "NONE", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "v_loss_fn", "=", "tf", ".", "keras", ".", "losses", ".", "MeanSquaredError", "(", "\n", "reduction", "=", "tf", ".", "keras", ".", "losses", ".", "Reduction", ".", "NONE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.generalized_onpolicy_loss.GeneralizedOnPolicyLoss.init": [[59, 64], ["hasattr", "module.init", "inspect.signature"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.init"], ["", "", "def", "init", "(", "self", ")", ":", "\n", "    ", "for", "module", "in", "self", ".", "submodules", ":", "\n", "      ", "if", "hasattr", "(", "module", ",", "'init'", ")", ":", "\n", "        ", "if", "not", "inspect", ".", "signature", "(", "module", ".", "init", ")", ".", "parameters", ":", "\n", "          ", "module", ".", "init", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.generalized_onpolicy_loss.GeneralizedOnPolicyLoss.compute_advantages": [[65, 142], ["tensorflow.nest.map_structure", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._agent", "tensorflow.nest.map_structure", "tensorflow.nest.map_structure", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._parametric_action_distribution().log_prob", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._parametric_action_distribution().log_prob", "tensorflow.logical_and", "tensorflow.logical_and", "range", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._advantage_estimator", "tensorflow.clip_by_value", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._reward_normalizer.correct_prediction", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._reward_normalizer.unnormalize_prediction", "tensorflow.zeros_like", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._regularizer", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._reward_normalizer.normalize_target", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._reward_normalizer.normalize_advantage", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._reward_normalizer.update_normalization_statistics", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._parametric_action_distribution", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._parametric_action_distribution"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.correct_prediction", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.unnormalize_prediction", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.normalize_target", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.normalize_advantage", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.update_normalization_statistics"], ["", "", "", "", "def", "compute_advantages", "(", "self", ",", "agent_state", ",", "prev_actions", ",", "env_outputs", ",", "\n", "agent_outputs", ",", "return_learner_outputs", "=", "False", ")", ":", "\n", "# Extract rewards and done information.", "\n", "    ", "rewards", ",", "done", ",", "_", ",", "abandoned", ",", "_", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "t", "[", "1", ":", "]", ",", "\n", "env_outputs", ")", "\n", "if", "self", ".", "_max_abs_reward", "is", "not", "None", ":", "\n", "      ", "rewards", "=", "tf", ".", "clip_by_value", "(", "rewards", ",", "-", "self", ".", "_max_abs_reward", ",", "\n", "self", ".", "_max_abs_reward", ")", "\n", "", "rewards", "*=", "self", ".", "_reward_scaling", "\n", "\n", "# Compute the outputs of the neural networks on the learner.", "\n", "learner_outputs", ",", "_", "=", "self", ".", "_agent", "(", "(", "prev_actions", ",", "env_outputs", ")", ",", "\n", "agent_state", ",", "\n", "unroll", "=", "True", ",", "\n", "is_training", "=", "True", ")", "\n", "\n", "# At this point, we have unroll length + 1 steps. The last step is only used", "\n", "# as bootstrap value, so it's removed.", "\n", "agent_outputs", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "t", "[", ":", "-", "1", "]", ",", "agent_outputs", ")", "\n", "learner_v", "=", "learner_outputs", ".", "baseline", "# current value function", "\n", "learner_outputs", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "t", "[", ":", "-", "1", "]", ",", "learner_outputs", ")", "\n", "\n", "target_action_log_probs", "=", "self", ".", "_parametric_action_distribution", "(", "\n", "learner_outputs", ".", "policy_logits", ")", ".", "log_prob", "(", "agent_outputs", ".", "action", ")", "\n", "behaviour_action_log_probs", "=", "self", ".", "_parametric_action_distribution", "(", "\n", "agent_outputs", ".", "policy_logits", ")", ".", "log_prob", "(", "agent_outputs", ".", "action", ")", "\n", "\n", "# Compute the advantages.", "\n", "\n", "if", "self", ".", "_reward_normalizer", ":", "\n", "      ", "corrected_predictions", "=", "self", ".", "_reward_normalizer", ".", "correct_prediction", "(", "\n", "learner_v", ")", "\n", "unnormalized_predictions", "=", "self", ".", "_reward_normalizer", ".", "unnormalize_prediction", "(", "\n", "corrected_predictions", ")", "\n", "", "else", ":", "\n", "      ", "corrected_predictions", "=", "learner_v", "\n", "unnormalized_predictions", "=", "learner_v", "\n", "", "if", "not", "self", ".", "_handle_abandoned_episodes_properly", ":", "\n", "      ", "abandoned", "=", "tf", ".", "zeros_like", "(", "abandoned", ")", "\n", "", "done_terminated", "=", "tf", ".", "logical_and", "(", "done", ",", "~", "abandoned", ")", "\n", "done_abandoned", "=", "tf", ".", "logical_and", "(", "done", ",", "abandoned", ")", "\n", "\n", "if", "self", ".", "_include_regularization_in_returns", "and", "self", ".", "_regularizer", ":", "\n", "      ", "additional_rewards", ",", "_", "=", "self", ".", "_regularizer", "(", "\n", "self", ".", "_parametric_action_distribution", ",", "\n", "learner_outputs", ".", "policy_logits", ",", "\n", "agent_outputs", ".", "policy_logits", ",", "\n", "agent_outputs", ".", "action", ",", "with_logging", "=", "False", ")", "\n", "assert", "rewards", ".", "shape", "==", "additional_rewards", ".", "shape", "\n", "rewards", "+=", "additional_rewards", "\n", "\n", "# tf.math.pow does not work on TPU so we compute it manually.", "\n", "", "adjusted_discount_factor", "=", "1.", "\n", "for", "_", "in", "range", "(", "self", ".", "_frame_skip", ")", ":", "\n", "      ", "adjusted_discount_factor", "*=", "self", ".", "_discount_factor", "\n", "\n", "", "vs", ",", "advantages", "=", "self", ".", "_advantage_estimator", "(", "\n", "unnormalized_predictions", ",", "\n", "rewards", ",", "done_terminated", ",", "\n", "done_abandoned", ",", "\n", "adjusted_discount_factor", ",", "\n", "target_action_log_probs", ",", "\n", "behaviour_action_log_probs", ")", "\n", "\n", "if", "self", ".", "_reward_normalizer", ":", "\n", "      ", "normalized_targets", "=", "self", ".", "_reward_normalizer", ".", "normalize_target", "(", "vs", ")", "\n", "normalized_advantages", "=", "self", ".", "_reward_normalizer", ".", "normalize_advantage", "(", "\n", "advantages", ")", "\n", "self", ".", "_reward_normalizer", ".", "update_normalization_statistics", "(", "vs", ")", "\n", "", "else", ":", "\n", "      ", "normalized_targets", "=", "vs", "\n", "normalized_advantages", "=", "advantages", "\n", "\n", "", "outputs", "=", "(", "normalized_targets", ",", "normalized_advantages", ")", "\n", "if", "return_learner_outputs", ":", "\n", "      ", "outputs", "+=", "(", "learner_outputs", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.generalized_onpolicy_loss.GeneralizedOnPolicyLoss.__call__": [[143, 227], ["generalized_onpolicy_loss.GeneralizedOnPolicyLoss._parametric_action_distribution().log_prob", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._parametric_action_distribution().log_prob", "tensorflow.reduce_mean", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss.log", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss.log", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss.log", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss.v_loss_fn", "tensorflow.reduce_mean", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss.compute_advantages", "tensorflow.nest.map_structure", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._agent", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._reward_normalizer.correct_prediction", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._reward_normalizer.correct_prediction", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._policy_loss", "tensorflow.abs", "tensorflow.clip_by_value", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss.v_loss_fn", "tensorflow.maximum", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._regularizer", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._parametric_action_distribution", "generalized_onpolicy_loss.GeneralizedOnPolicyLoss._parametric_action_distribution", "tensorflow.reduce_mean"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.generalized_onpolicy_loss.GeneralizedOnPolicyLoss.compute_advantages", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.correct_prediction", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.correct_prediction"], ["", "def", "__call__", "(", "self", ",", "agent_state", ",", "prev_actions", ",", "env_outputs", ",", "agent_outputs", ",", "\n", "normalized_targets", "=", "None", ",", "normalized_advantages", "=", "None", ")", ":", "\n", "    ", "\"\"\"Computes the loss.\"\"\"", "\n", "if", "normalized_targets", "is", "None", ":", "\n", "      ", "normalized_targets", ",", "normalized_advantages", ",", "learner_outputs", "=", "self", ".", "compute_advantages", "(", "\n", "agent_state", ",", "prev_actions", ",", "env_outputs", ",", "agent_outputs", ",", "\n", "return_learner_outputs", "=", "True", ")", "\n", "# The last timestep is only used for computing advantages so we", "\n", "# remove it here.", "\n", "agent_state", ",", "prev_actions", ",", "env_outputs", ",", "agent_outputs", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "t", "[", ":", "-", "1", "]", ",", "\n", "(", "agent_state", ",", "prev_actions", ",", "env_outputs", ",", "agent_outputs", ")", ")", "\n", "", "else", ":", "# Advantages are already precomputed.", "\n", "      ", "learner_outputs", ",", "_", "=", "self", ".", "_agent", "(", "(", "prev_actions", ",", "env_outputs", ")", ",", "\n", "agent_state", ",", "\n", "unroll", "=", "True", ",", "\n", "is_training", "=", "True", ")", "\n", "\n", "", "target_action_log_probs", "=", "self", ".", "_parametric_action_distribution", "(", "\n", "learner_outputs", ".", "policy_logits", ")", ".", "log_prob", "(", "agent_outputs", ".", "action", ")", "\n", "behaviour_action_log_probs", "=", "self", ".", "_parametric_action_distribution", "(", "\n", "agent_outputs", ".", "policy_logits", ")", ".", "log_prob", "(", "agent_outputs", ".", "action", ")", "\n", "\n", "# Compute the advantages.", "\n", "if", "self", ".", "_reward_normalizer", ":", "\n", "      ", "corrected_predictions", "=", "self", ".", "_reward_normalizer", ".", "correct_prediction", "(", "\n", "learner_outputs", ".", "baseline", ")", "\n", "old_corrected_predictions", "=", "self", ".", "_reward_normalizer", ".", "correct_prediction", "(", "\n", "agent_outputs", ".", "baseline", ")", "\n", "", "else", ":", "\n", "      ", "corrected_predictions", "=", "learner_outputs", ".", "baseline", "\n", "old_corrected_predictions", "=", "agent_outputs", ".", "baseline", "\n", "\n", "# Compute the advantage-based loss.", "\n", "", "policy_loss", "=", "tf", ".", "reduce_mean", "(", "\n", "self", ".", "_policy_loss", "(", "\n", "normalized_advantages", ",", "\n", "target_action_log_probs", ",", "\n", "behaviour_action_log_probs", ",", "\n", "actions", "=", "agent_outputs", ".", "action", ",", "\n", "target_logits", "=", "learner_outputs", ".", "policy_logits", ",", "\n", "behaviour_logits", "=", "agent_outputs", ".", "policy_logits", ",", "\n", "parametric_action_distribution", "=", "self", ".", "_parametric_action_distribution", ")", "\n", ")", "\n", "\n", "# Value function loss", "\n", "v_error", "=", "normalized_targets", "-", "corrected_predictions", "\n", "self", ".", "log", "(", "'GeneralizedOnPolicyLoss/V_error'", ",", "v_error", ")", "\n", "self", ".", "log", "(", "'GeneralizedOnPolicyLoss/abs_V_error'", ",", "tf", ".", "abs", "(", "v_error", ")", ")", "\n", "self", ".", "log", "(", "'GeneralizedOnPolicyLoss/corrected_predictions'", ",", "\n", "corrected_predictions", ")", "\n", "# Huber loss reduces the last dimension so we add a dummy one here.", "\n", "normalized_targets", "=", "normalized_targets", "[", "...", ",", "tf", ".", "newaxis", "]", "\n", "corrected_predictions", "=", "corrected_predictions", "[", "...", ",", "tf", ".", "newaxis", "]", "\n", "v_loss", "=", "self", ".", "v_loss_fn", "(", "normalized_targets", ",", "corrected_predictions", ")", "\n", "\n", "# PPO-style value loss clipping", "\n", "if", "self", ".", "_value_ppo_style_clip_eps", "is", "not", "None", ":", "\n", "      ", "old_corrected_predictions", "=", "old_corrected_predictions", "[", "...", ",", "tf", ".", "newaxis", "]", "\n", "clipped_corrected_predictions", "=", "tf", ".", "clip_by_value", "(", "\n", "corrected_predictions", ",", "\n", "old_corrected_predictions", "-", "self", ".", "_value_ppo_style_clip_eps", ",", "\n", "old_corrected_predictions", "+", "self", ".", "_value_ppo_style_clip_eps", ")", "\n", "clipped_v_loss", "=", "self", ".", "v_loss_fn", "(", "normalized_targets", ",", "\n", "clipped_corrected_predictions", ")", "\n", "v_loss", "=", "tf", ".", "maximum", "(", "v_loss", ",", "clipped_v_loss", ")", "\n", "", "v_loss", "=", "tf", ".", "reduce_mean", "(", "v_loss", ")", "\n", "\n", "# Compute the regularization loss.", "\n", "if", "self", ".", "_regularizer", ":", "\n", "      ", "per_step_regularization", ",", "regularization_loss", "=", "self", ".", "_regularizer", "(", "\n", "self", ".", "_parametric_action_distribution", ",", "\n", "learner_outputs", ".", "policy_logits", ",", "\n", "agent_outputs", ".", "policy_logits", ",", "\n", "agent_outputs", ".", "action", ")", "\n", "if", "not", "self", ".", "_include_regularization_in_returns", ":", "\n", "        ", "regularization_loss", "+=", "tf", ".", "reduce_mean", "(", "per_step_regularization", ")", "\n", "", "", "else", ":", "\n", "      ", "regularization_loss", "=", "0.", "\n", "\n", "", "total_loss", "=", "policy_loss", "+", "self", ".", "_baseline_cost", "*", "v_loss", "+", "regularization_loss", "\n", "return", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.generalized_onpolicy_loss.PolicyLoss.__call__": [[232, 249], ["NotImplementedError"], "methods", ["None"], ["@", "abc", ".", "abstractmethod", "\n", "def", "__call__", "(", "self", ",", "advantages", ",", "target_action_log_probs", ",", "\n", "behaviour_action_log_probs", ")", ":", "\n", "    ", "r\"\"\"Computes policy loss.\n\n    Args:\n      advantages: A float32 tensor of shape [T, B] of advantages.\n      target_action_log_probs: A float32 tensor of shape [T, B] with\n        log-probabilities of taking the action by the current policy\n      behaviour_action_log_probs: A float32 tensor of shape [T, B] with\n        log-probabilities of taking the action by the behavioural policy\n\n\n    Returns:\n      A float32 tensor of shape [T, B] with the policy loss.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", "'`__call__()` is not implemented!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.generalized_onpolicy_loss.RegularizationLoss.__call__": [[254, 272], ["NotImplementedError"], "methods", ["None"], ["@", "abc", ".", "abstractmethod", "\n", "def", "__call__", "(", "self", ",", "parametric_action_distribution", ",", "target_action_logits", ",", "\n", "behaviour_action_logits", ",", "actions", ")", ":", "\n", "    ", "r\"\"\"Computes regularization loss.\n\n    Args:\n      parametric_action_distribution: Parametric action distribution.\n      target_action_logits: A float32 tensor of shape [T, B, A] with\n        the logits of the target policy.\n      behaviour_action_logits: A float32 tensor of shape [T, B, A] with\n        the logits of the behavioural policy.\n      actions: A float32 tensor of shape [T, B, A] with the actions taken by the\n        behaviour policy.\n\n    Returns:\n      A float32 tensor of shape [T, B] with the regularization loss.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", "'`__call__()` is not implemented!'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints_test.LagrangeInequalityCoefficientTest.test_ineqaulity_constraint": [[24, 34], ["seed_rl.agents.policy_gradient.modules.constraints.LagrangeInequalityCoefficient", "tensorflow.Variable", "tensorflow.keras.optimizers.Adam", "range", "constraints_test.LagrangeInequalityCoefficientTest.assertAllClose", "tensorflow.keras.optimizers.Adam.minimize", "seed_rl.agents.policy_gradient.modules.constraints.LagrangeInequalityCoefficient.adjustment_loss", "seed_rl.agents.policy_gradient.modules.constraints.LagrangeInequalityCoefficient.scale_loss", "tensorflow.square"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.Learner.minimize", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints.LagrangeInequalityCoefficient.adjustment_loss", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints.Coefficient.scale_loss"], ["  ", "def", "test_ineqaulity_constraint", "(", "self", ")", ":", "\n", "    ", "multiplier", "=", "constraints", ".", "LagrangeInequalityCoefficient", "(", "threshold", "=", "2", ")", "\n", "x", "=", "tf", ".", "Variable", "(", "1.23", ")", "\n", "def", "loss", "(", ")", ":", "\n", "      ", "return", "(", "multiplier", ".", "scale_loss", "(", "tf", ".", "square", "(", "x", ")", ")", "-", "x", "\n", "+", "multiplier", ".", "adjustment_loss", "(", "x", ")", ")", "\n", "", "opt", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "0.01", ")", "\n", "for", "_", "in", "range", "(", "1000", ")", ":", "\n", "      ", "opt", ".", "minimize", "(", "loss", ",", "multiplier", ".", "trainable_variables", "+", "(", "x", ",", ")", ")", "\n", "", "self", ".", "assertAllClose", "(", "x", ",", "2.", ",", "atol", "=", "0.01", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.EMAMeanStdTest._setup_normalizer": [[34, 43], ["seed_rl.agents.policy_gradient.modules.running_statistics.EMAMeanStd", "seed_rl.agents.policy_gradient.modules.test_utils.create_distribution_strategy", "running_statistics_test.EMAMeanStdTest.assertEqual", "seed_rl.agents.policy_gradient.modules.test_utils.create_distribution_strategy.scope", "seed_rl.agents.policy_gradient.modules.running_statistics.EMAMeanStd.init"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.create_distribution_strategy", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.init"], ["def", "_setup_normalizer", "(", "self", ",", "beta", ",", "size", ")", ":", "\n", "    ", "\"\"\"Sets up the input normalizer and a distribution strategy to run.\"\"\"", "\n", "normalizer", "=", "running_statistics", ".", "EMAMeanStd", "(", "beta", "=", "beta", ")", "\n", "strategy", "=", "test_utils", ".", "create_distribution_strategy", "(", "\n", "use_tpu", "=", "self", ".", "primary_device", "==", "'TPU'", ")", "\n", "self", ".", "assertEqual", "(", "strategy", ".", "num_replicas_in_sync", ",", "2", ")", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "normalizer", ".", "init", "(", "size", ")", "\n", "", "return", "normalizer", ",", "strategy", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.EMAMeanStdTest._update": [[44, 51], ["tensorflow.data.Dataset.from_tensors", "iter", "next", "tensorflow.function", "strategy.run", "strategy.experimental_distribute_dataset"], "methods", ["None"], ["", "def", "_update", "(", "self", ",", "normalizer", ",", "strategy", ",", "tensor", ")", ":", "\n", "    ", "\"\"\"Updates the normalization statistics via the strategy.\"\"\"", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensors", "(", "tensor", ")", "\n", "dataset_iterator", "=", "iter", "(", "strategy", ".", "experimental_distribute_dataset", "(", "dataset", ")", ")", "\n", "distributed_values", "=", "next", "(", "dataset_iterator", ")", "\n", "f", "=", "tf", ".", "function", "(", "normalizer", ".", "update", ")", "\n", "strategy", ".", "run", "(", "f", ",", "(", "distributed_values", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.EMAMeanStdTest.test_moment_update": [[52, 65], ["running_statistics_test.EMAMeanStdTest._setup_normalizer", "tensorflow.reshape", "running_statistics_test.EMAMeanStdTest._update", "running_statistics_test.EMAMeanStdTest.assertAllClose", "running_statistics_test.EMAMeanStdTest.assertAllClose", "tensorflow.range", "tensorflow.reduce_mean", "tensorflow.reduce_mean"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._update"], ["", "def", "test_moment_update", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the normalization moments are correctly updated.\"\"\"", "\n", "normalizer", ",", "strategy", "=", "self", ".", "_setup_normalizer", "(", ".5", ",", "10", ")", "\n", "\n", "# Apply update.", "\n", "tensor", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "200", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "(", "20", ",", "10", ")", ")", "\n", "self", ".", "_update", "(", "normalizer", ",", "strategy", ",", "tensor", ")", "\n", "\n", "# Verify that update is correct.", "\n", "target_first_moment", "=", "0.5", "*", "tf", ".", "reduce_mean", "(", "tensor", ",", "0", ")", "\n", "self", ".", "assertAllClose", "(", "normalizer", ".", "first_moment", ",", "target_first_moment", ")", "\n", "target_second_moment", "=", "0.5", "+", "0.5", "*", "tf", ".", "reduce_mean", "(", "tensor", "**", "2", ",", "0", ")", "\n", "self", ".", "assertAllClose", "(", "normalizer", ".", "second_moment", ",", "target_second_moment", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.EMAMeanStdTest.test_normalization": [[66, 82], ["running_statistics_test.EMAMeanStdTest._setup_normalizer", "tensorflow.reshape", "running_statistics_test.EMAMeanStdTest._update", "tensorflow.reduce_mean", "tensorflow.math.reduce_std", "running_statistics_test.EMAMeanStdTest.assertAllClose", "running_statistics_test.EMAMeanStdTest.assertAllClose", "tensorflow.range", "strategy.scope", "normalizer.normalize", "tensorflow.zeros_like", "tensorflow.ones_like"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._update", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize"], ["", "def", "test_normalization", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the normalization works.\"\"\"", "\n", "normalizer", ",", "strategy", "=", "self", ".", "_setup_normalizer", "(", "1.", ",", "10", ")", "\n", "\n", "# Apply update.", "\n", "tensor", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "200", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "(", "20", ",", "10", ")", ")", "\n", "self", ".", "_update", "(", "normalizer", ",", "strategy", ",", "tensor", ")", "\n", "\n", "# Verify that normalization works correctly.", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "normalized", "=", "normalizer", ".", "normalize", "(", "tensor", ")", "\n", "\n", "", "mean", "=", "tf", ".", "reduce_mean", "(", "normalized", ",", "0", ")", "\n", "std", "=", "tf", ".", "math", ".", "reduce_std", "(", "normalized", ",", "0", ")", "\n", "self", ".", "assertAllClose", "(", "mean", ",", "tf", ".", "zeros_like", "(", "mean", ")", ")", "\n", "self", ".", "assertAllClose", "(", "std", ",", "tf", ".", "ones_like", "(", "std", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.EMAMeanStdTest.test_variables": [[83, 88], ["running_statistics_test.EMAMeanStdTest._setup_normalizer", "running_statistics_test.EMAMeanStdTest.assertLen", "running_statistics_test.EMAMeanStdTest.assertEmpty"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer"], ["", "def", "test_variables", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that we have the correct number of variables.\"\"\"", "\n", "normalizer", ",", "_", "=", "self", ".", "_setup_normalizer", "(", ".5", ",", "10", ")", "\n", "self", ".", "assertLen", "(", "normalizer", ".", "variables", ",", "2", ")", "\n", "self", ".", "assertEmpty", "(", "normalizer", ".", "trainable_variables", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.EMAMeanStdTest.test_invertible": [[89, 103], ["running_statistics_test.EMAMeanStdTest._setup_normalizer", "tensorflow.reshape", "running_statistics_test.EMAMeanStdTest._update", "running_statistics_test.EMAMeanStdTest.assertAllClose", "tensorflow.range", "strategy.scope", "normalizer.normalize", "normalizer.unnormalize"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._update", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.unnormalize"], ["", "def", "test_invertible", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the normalization is invertible.\"\"\"", "\n", "normalizer", ",", "strategy", "=", "self", ".", "_setup_normalizer", "(", ".5", ",", "10", ")", "\n", "tensor", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "200", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "(", "20", ",", "10", ")", ")", "\n", "\n", "# Apply update.", "\n", "self", ".", "_update", "(", "normalizer", ",", "strategy", ",", "tensor", ")", "\n", "\n", "# Verify that update is correct.", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "normalized", "=", "normalizer", ".", "normalize", "(", "tensor", ")", "\n", "inverted", "=", "normalizer", ".", "unnormalize", "(", "normalized", ")", "\n", "\n", "", "self", ".", "assertAllClose", "(", "tensor", ",", "inverted", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.AverageMeanStdTest._setup_normalizer": [[109, 121], ["seed_rl.agents.policy_gradient.modules.running_statistics.AverageMeanStd", "seed_rl.agents.policy_gradient.modules.test_utils.create_distribution_strategy", "running_statistics_test.AverageMeanStdTest.assertEqual", "args.update", "seed_rl.agents.policy_gradient.modules.test_utils.create_distribution_strategy.scope", "seed_rl.agents.policy_gradient.modules.running_statistics.AverageMeanStd.init"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.create_distribution_strategy", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.update", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.init"], ["def", "_setup_normalizer", "(", "self", ",", "size", ",", "std_min_value", "=", "None", ")", ":", "\n", "    ", "\"\"\"Sets up the input normalizer and a distribution strategy to run.\"\"\"", "\n", "args", "=", "{", "}", "\n", "if", "std_min_value", "is", "not", "None", ":", "\n", "      ", "args", ".", "update", "(", "std_min_value", "=", "std_min_value", ")", "\n", "", "normalizer", "=", "running_statistics", ".", "AverageMeanStd", "(", "**", "args", ")", "\n", "strategy", "=", "test_utils", ".", "create_distribution_strategy", "(", "\n", "use_tpu", "=", "self", ".", "primary_device", "==", "'TPU'", ")", "\n", "self", ".", "assertEqual", "(", "strategy", ".", "num_replicas_in_sync", ",", "2", ")", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "normalizer", ".", "init", "(", "size", ")", "\n", "", "return", "normalizer", ",", "strategy", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.AverageMeanStdTest._update": [[122, 129], ["tensorflow.data.Dataset.from_tensors", "iter", "next", "tensorflow.function", "strategy.run", "strategy.experimental_distribute_dataset"], "methods", ["None"], ["", "def", "_update", "(", "self", ",", "normalizer", ",", "strategy", ",", "tensor", ")", ":", "\n", "    ", "\"\"\"Updates the normalization statistics via the strategy.\"\"\"", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensors", "(", "tensor", ")", "\n", "dataset_iterator", "=", "iter", "(", "strategy", ".", "experimental_distribute_dataset", "(", "dataset", ")", ")", "\n", "distributed_values", "=", "next", "(", "dataset_iterator", ")", "\n", "f", "=", "tf", ".", "function", "(", "normalizer", ".", "update", ")", "\n", "strategy", ".", "run", "(", "f", ",", "(", "distributed_values", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.AverageMeanStdTest.test_normalization": [[130, 148], ["running_statistics_test.AverageMeanStdTest._setup_normalizer", "tensorflow.reshape", "tensorflow.split", "running_statistics_test.AverageMeanStdTest._update", "running_statistics_test.AverageMeanStdTest._update", "tensorflow.reduce_mean", "tensorflow.math.reduce_std", "running_statistics_test.AverageMeanStdTest.assertAllClose", "running_statistics_test.AverageMeanStdTest.assertAllClose", "tensorflow.range", "strategy.scope", "normalizer.normalize", "tensorflow.zeros_like", "tensorflow.ones_like"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._update", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._update", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize"], ["", "def", "test_normalization", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the normalization works.\"\"\"", "\n", "normalizer", ",", "strategy", "=", "self", ".", "_setup_normalizer", "(", "10", ")", "\n", "\n", "# Apply two updates to make sure that everything works as intended.", "\n", "tensor", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "200", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "(", "20", ",", "10", ")", ")", "\n", "tensor1", ",", "tensor2", "=", "tf", ".", "split", "(", "tensor", ",", "2", ",", "axis", "=", "0", ")", "\n", "self", ".", "_update", "(", "normalizer", ",", "strategy", ",", "tensor1", ")", "\n", "self", ".", "_update", "(", "normalizer", ",", "strategy", ",", "tensor2", ")", "\n", "\n", "# Verify that normalization works correctly.", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "normalized", "=", "normalizer", ".", "normalize", "(", "tensor", ")", "\n", "\n", "", "mean", "=", "tf", ".", "reduce_mean", "(", "normalized", ",", "0", ")", "\n", "std", "=", "tf", ".", "math", ".", "reduce_std", "(", "normalized", ",", "0", ")", "\n", "self", ".", "assertAllClose", "(", "mean", ",", "tf", ".", "zeros_like", "(", "mean", ")", ")", "\n", "self", ".", "assertAllClose", "(", "std", ",", "tf", ".", "ones_like", "(", "std", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.AverageMeanStdTest.test_variables": [[149, 154], ["running_statistics_test.AverageMeanStdTest._setup_normalizer", "running_statistics_test.AverageMeanStdTest.assertLen", "running_statistics_test.AverageMeanStdTest.assertEmpty"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer"], ["", "def", "test_variables", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that we have the correct number of variables.\"\"\"", "\n", "normalizer", ",", "_", "=", "self", ".", "_setup_normalizer", "(", "10", ")", "\n", "self", ".", "assertLen", "(", "normalizer", ".", "variables", ",", "4", ")", "\n", "self", ".", "assertEmpty", "(", "normalizer", ".", "trainable_variables", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.AverageMeanStdTest.test_invertible": [[155, 169], ["running_statistics_test.AverageMeanStdTest._setup_normalizer", "tensorflow.reshape", "running_statistics_test.AverageMeanStdTest._update", "running_statistics_test.AverageMeanStdTest.assertAllClose", "tensorflow.range", "strategy.scope", "normalizer.normalize", "normalizer.unnormalize"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._update", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.unnormalize"], ["", "def", "test_invertible", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the normalization is invertible.\"\"\"", "\n", "normalizer", ",", "strategy", "=", "self", ".", "_setup_normalizer", "(", "10", ")", "\n", "tensor", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "200", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "(", "20", ",", "10", ")", ")", "\n", "\n", "# Apply update.", "\n", "self", ".", "_update", "(", "normalizer", ",", "strategy", ",", "tensor", ")", "\n", "\n", "# Verify that update is correct.", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "normalized", "=", "normalizer", ".", "normalize", "(", "tensor", ")", "\n", "inverted", "=", "normalizer", ".", "unnormalize", "(", "normalized", ")", "\n", "\n", "", "self", ".", "assertAllClose", "(", "tensor", ",", "inverted", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.AverageMeanStdTest.test_init": [[170, 177], ["running_statistics_test.AverageMeanStdTest._setup_normalizer", "normalizer.get_mean_std", "running_statistics_test.AverageMeanStdTest.assertAllClose", "running_statistics_test.AverageMeanStdTest.assertAllClose", "tensorflow.zeros_like", "tensorflow.ones_like"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.get_mean_std"], ["", "def", "test_init", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the mean and standard deviation are initialized to 0 and 1.\"\"\"", "\n", "normalizer", ",", "_", "=", "self", ".", "_setup_normalizer", "(", "10", ")", "\n", "mean", ",", "std", "=", "normalizer", ".", "get_mean_std", "(", ")", "\n", "\n", "self", ".", "assertAllClose", "(", "mean", ",", "tf", ".", "zeros_like", "(", "mean", ")", ")", "\n", "self", ".", "assertAllClose", "(", "std", ",", "tf", ".", "ones_like", "(", "std", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.AverageMeanStdTest.test_init2": [[178, 185], ["running_statistics_test.AverageMeanStdTest._setup_normalizer", "normalizer.get_mean_std", "running_statistics_test.AverageMeanStdTest.assertAllClose", "running_statistics_test.AverageMeanStdTest.assertAllClose", "tensorflow.zeros_like", "tensorflow.ones_like"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.get_mean_std"], ["", "def", "test_init2", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the mean and standard deviation are initialized to 0 and 1.\"\"\"", "\n", "normalizer", ",", "_", "=", "self", ".", "_setup_normalizer", "(", "10", ",", "std_min_value", "=", "0.1", ")", "\n", "mean", ",", "std", "=", "normalizer", ".", "get_mean_std", "(", ")", "\n", "\n", "self", ".", "assertAllClose", "(", "mean", ",", "tf", ".", "zeros_like", "(", "mean", ")", ")", "\n", "self", ".", "assertAllClose", "(", "std", ",", "tf", ".", "ones_like", "(", "std", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.TwoLevelAverageMeanStdTest._setup_normalizer": [[191, 201], ["seed_rl.agents.policy_gradient.modules.running_statistics.TwoLevelAverageMeanStd", "seed_rl.agents.policy_gradient.modules.test_utils.create_distribution_strategy", "running_statistics_test.TwoLevelAverageMeanStdTest.assertEqual", "seed_rl.agents.policy_gradient.modules.test_utils.create_distribution_strategy.scope", "seed_rl.agents.policy_gradient.modules.running_statistics.TwoLevelAverageMeanStd.init"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.create_distribution_strategy", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.init"], ["def", "_setup_normalizer", "(", "self", ",", "size", ",", "buffer_size", "=", "1e5", ")", ":", "\n", "    ", "\"\"\"Sets up the input normalizer and a distribution strategy to run.\"\"\"", "\n", "normalizer", "=", "running_statistics", ".", "TwoLevelAverageMeanStd", "(", "\n", "buffer_size", "=", "buffer_size", ")", "\n", "strategy", "=", "test_utils", ".", "create_distribution_strategy", "(", "\n", "use_tpu", "=", "self", ".", "primary_device", "==", "'TPU'", ")", "\n", "self", ".", "assertEqual", "(", "strategy", ".", "num_replicas_in_sync", ",", "2", ")", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "normalizer", ".", "init", "(", "size", ")", "\n", "", "return", "normalizer", ",", "strategy", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.TwoLevelAverageMeanStdTest._update": [[202, 209], ["tensorflow.data.Dataset.from_tensors", "iter", "next", "tensorflow.function", "strategy.run", "strategy.experimental_distribute_dataset"], "methods", ["None"], ["", "def", "_update", "(", "self", ",", "normalizer", ",", "strategy", ",", "tensor", ")", ":", "\n", "    ", "\"\"\"Updates the normalization statistics via the strategy.\"\"\"", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensors", "(", "tensor", ")", "\n", "dataset_iterator", "=", "iter", "(", "strategy", ".", "experimental_distribute_dataset", "(", "dataset", ")", ")", "\n", "distributed_values", "=", "next", "(", "dataset_iterator", ")", "\n", "f", "=", "tf", ".", "function", "(", "normalizer", ".", "update", ")", "\n", "strategy", ".", "run", "(", "f", ",", "(", "distributed_values", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.TwoLevelAverageMeanStdTest.test_normalization": [[210, 228], ["running_statistics_test.TwoLevelAverageMeanStdTest._setup_normalizer", "tensorflow.reshape", "tensorflow.split", "running_statistics_test.TwoLevelAverageMeanStdTest._update", "running_statistics_test.TwoLevelAverageMeanStdTest._update", "tensorflow.reduce_mean", "tensorflow.math.reduce_std", "running_statistics_test.TwoLevelAverageMeanStdTest.assertAllClose", "running_statistics_test.TwoLevelAverageMeanStdTest.assertAllClose", "tensorflow.range", "strategy.scope", "normalizer.normalize", "tensorflow.zeros_like", "tensorflow.ones_like"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._update", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._update", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize"], ["", "def", "test_normalization", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the normalization works.\"\"\"", "\n", "normalizer", ",", "strategy", "=", "self", ".", "_setup_normalizer", "(", "10", ")", "\n", "\n", "# Apply two updates to make sure that everything works as intended.", "\n", "tensor", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "200", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "(", "20", ",", "10", ")", ")", "\n", "tensor1", ",", "tensor2", "=", "tf", ".", "split", "(", "tensor", ",", "2", ",", "axis", "=", "0", ")", "\n", "self", ".", "_update", "(", "normalizer", ",", "strategy", ",", "tensor1", ")", "\n", "self", ".", "_update", "(", "normalizer", ",", "strategy", ",", "tensor2", ")", "\n", "\n", "# Verify that normalization works correctly.", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "normalized", "=", "normalizer", ".", "normalize", "(", "tensor", ")", "\n", "\n", "", "mean", "=", "tf", ".", "reduce_mean", "(", "normalized", ",", "0", ")", "\n", "std", "=", "tf", ".", "math", ".", "reduce_std", "(", "normalized", ",", "0", ")", "\n", "self", ".", "assertAllClose", "(", "mean", ",", "tf", ".", "zeros_like", "(", "mean", ")", ")", "\n", "self", ".", "assertAllClose", "(", "std", ",", "tf", ".", "ones_like", "(", "std", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.TwoLevelAverageMeanStdTest.test_normalization_two_levels": [[229, 257], ["absl.testing.parameterized.parameters", "tensorflow.print", "running_statistics_test.TwoLevelAverageMeanStdTest._setup_normalizer", "tensorflow.random.set_seed", "tensorflow.reduce_mean", "tensorflow.math.reduce_std", "running_statistics_test.TwoLevelAverageMeanStdTest.assertAllClose", "running_statistics_test.TwoLevelAverageMeanStdTest.assertAllClose", "tensorflow.random.normal", "running_statistics_test.TwoLevelAverageMeanStdTest._update", "strategy.scope", "normalizer.normalize", "tensorflow.zeros_like", "tensorflow.ones_like", "range", "tensorflow.reshape", "tensorflow.stack"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._update", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize"], ["", "@", "parameterized", ".", "parameters", "(", "\n", "{", "'num_updates'", ":", "3", "}", ",", "\n", "{", "'num_updates'", ":", "9", "}", ",", "\n", "{", "'num_updates'", ":", "10", "}", ",", "\n", "{", "'num_updates'", ":", "11", "}", ",", "\n", "{", "'num_updates'", ":", "19", "}", ",", "\n", "{", "'num_updates'", ":", "20", "}", ",", "\n", "{", "'num_updates'", ":", "21", "}", ",", "\n", "{", "'num_updates'", ":", "25", "}", ",", "\n", ")", "\n", "def", "test_normalization_two_levels", "(", "self", ",", "num_updates", ")", ":", "\n", "    ", "\"\"\"Tests normalization when the stats buffer is reset multiple times.\"\"\"", "\n", "tf", ".", "print", "(", "'Num updates:'", ",", "num_updates", ")", "\n", "normalizer", ",", "strategy", "=", "self", ".", "_setup_normalizer", "(", "10", ",", "buffer_size", "=", "10", ")", "\n", "tf", ".", "random", ".", "set_seed", "(", "123", ")", "\n", "tensors", "=", "[", "tf", ".", "random", ".", "normal", "(", "[", "10", ",", "10", "]", ")", "for", "_", "in", "range", "(", "num_updates", ")", "]", "\n", "\n", "for", "tensor", "in", "tensors", ":", "\n", "      ", "self", ".", "_update", "(", "normalizer", ",", "strategy", ",", "tensor", ")", "\n", "\n", "# Verify that normalization works correctly.", "\n", "", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "normalized", "=", "normalizer", ".", "normalize", "(", "tf", ".", "reshape", "(", "tf", ".", "stack", "(", "tensors", ")", ",", "[", "-", "1", ",", "10", "]", ")", ")", "\n", "\n", "", "mean", "=", "tf", ".", "reduce_mean", "(", "normalized", ",", "0", ")", "\n", "std", "=", "tf", ".", "math", ".", "reduce_std", "(", "normalized", ",", "0", ")", "\n", "self", ".", "assertAllClose", "(", "mean", ",", "tf", ".", "zeros_like", "(", "mean", ")", ")", "\n", "self", ".", "assertAllClose", "(", "std", ",", "tf", ".", "ones_like", "(", "std", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.TwoLevelAverageMeanStdTest.test_variables": [[258, 263], ["running_statistics_test.TwoLevelAverageMeanStdTest._setup_normalizer", "running_statistics_test.TwoLevelAverageMeanStdTest.assertLen", "running_statistics_test.TwoLevelAverageMeanStdTest.assertEmpty"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer"], ["", "def", "test_variables", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that we have the correct number of variables.\"\"\"", "\n", "normalizer", ",", "_", "=", "self", ".", "_setup_normalizer", "(", "10", ")", "\n", "self", ".", "assertLen", "(", "normalizer", ".", "variables", ",", "8", ")", "\n", "self", ".", "assertEmpty", "(", "normalizer", ".", "trainable_variables", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.TwoLevelAverageMeanStdTest.test_invertible": [[264, 278], ["running_statistics_test.TwoLevelAverageMeanStdTest._setup_normalizer", "tensorflow.reshape", "running_statistics_test.TwoLevelAverageMeanStdTest._update", "running_statistics_test.TwoLevelAverageMeanStdTest.assertAllClose", "tensorflow.range", "strategy.scope", "normalizer.normalize", "normalizer.unnormalize"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._update", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.unnormalize"], ["", "def", "test_invertible", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the normalization is invertible.\"\"\"", "\n", "normalizer", ",", "strategy", "=", "self", ".", "_setup_normalizer", "(", "10", ")", "\n", "tensor", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "200", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "(", "20", ",", "10", ")", ")", "\n", "\n", "# Apply update.", "\n", "self", ".", "_update", "(", "normalizer", ",", "strategy", ",", "tensor", ")", "\n", "\n", "# Verify that update is correct.", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "normalized", "=", "normalizer", ".", "normalize", "(", "tensor", ")", "\n", "inverted", "=", "normalizer", ".", "unnormalize", "(", "normalized", ")", "\n", "\n", "", "self", ".", "assertAllClose", "(", "tensor", ",", "inverted", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.TwoLevelAverageMeanStdTest.test_init": [[279, 286], ["running_statistics_test.TwoLevelAverageMeanStdTest._setup_normalizer", "normalizer.get_mean_std", "running_statistics_test.TwoLevelAverageMeanStdTest.assertAllClose", "running_statistics_test.TwoLevelAverageMeanStdTest.assertAllClose", "tensorflow.zeros_like", "tensorflow.ones_like"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.get_mean_std"], ["", "def", "test_init", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the mean and standard deviation are initialized to 0 and 1.\"\"\"", "\n", "normalizer", ",", "_", "=", "self", ".", "_setup_normalizer", "(", "10", ")", "\n", "mean", ",", "std", "=", "normalizer", ".", "get_mean_std", "(", ")", "\n", "\n", "self", ".", "assertAllClose", "(", "mean", ",", "tf", ".", "zeros_like", "(", "mean", ")", ")", "\n", "self", ".", "assertAllClose", "(", "std", ",", "tf", ".", "ones_like", "(", "std", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer": [[292, 301], ["seed_rl.agents.policy_gradient.modules.running_statistics.FixedMeanStd", "seed_rl.agents.policy_gradient.modules.test_utils.create_distribution_strategy", "running_statistics_test.FixedMeanStdTest.assertEqual", "seed_rl.agents.policy_gradient.modules.test_utils.create_distribution_strategy.scope", "seed_rl.agents.policy_gradient.modules.running_statistics.FixedMeanStd.init"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.create_distribution_strategy", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.init"], ["def", "_setup_normalizer", "(", "self", ",", "size", ",", "mean", ",", "std", ")", ":", "\n", "    ", "\"\"\"Sets up the input normalizer and a distribution strategy to run.\"\"\"", "\n", "normalizer", "=", "running_statistics", ".", "FixedMeanStd", "(", "mean", ",", "std", ")", "\n", "strategy", "=", "test_utils", ".", "create_distribution_strategy", "(", "\n", "use_tpu", "=", "self", ".", "primary_device", "==", "'TPU'", ")", "\n", "self", ".", "assertEqual", "(", "strategy", ".", "num_replicas_in_sync", ",", "2", ")", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "normalizer", ".", "init", "(", "size", ")", "\n", "", "return", "normalizer", ",", "strategy", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._update": [[302, 309], ["tensorflow.data.Dataset.from_tensors", "iter", "next", "tensorflow.function", "strategy.run", "strategy.experimental_distribute_dataset"], "methods", ["None"], ["", "def", "_update", "(", "self", ",", "normalizer", ",", "strategy", ",", "tensor", ")", ":", "\n", "    ", "\"\"\"Updates the normalization statistics via the strategy.\"\"\"", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensors", "(", "tensor", ")", "\n", "dataset_iterator", "=", "iter", "(", "strategy", ".", "experimental_distribute_dataset", "(", "dataset", ")", ")", "\n", "distributed_values", "=", "next", "(", "dataset_iterator", ")", "\n", "f", "=", "tf", ".", "function", "(", "normalizer", ".", "update", ")", "\n", "strategy", ".", "run", "(", "f", ",", "(", "distributed_values", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest.test_normalization": [[310, 329], ["running_statistics_test.FixedMeanStdTest._setup_normalizer", "tensorflow.reshape", "running_statistics_test.FixedMeanStdTest._update", "running_statistics_test.FixedMeanStdTest.assertAllClose", "running_statistics_test.FixedMeanStdTest.assertAllClose", "tensorflow.range", "strategy.scope", "normalizer.normalize", "strategy.scope", "normalizer.normalize"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._update", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize"], ["", "def", "test_normalization", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the normalization works.\"\"\"", "\n", "normalizer", ",", "strategy", "=", "self", ".", "_setup_normalizer", "(", "10", ",", "1.", ",", "10.", ")", "\n", "tensor", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "200", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "(", "20", ",", "10", ")", ")", "\n", "\n", "# Get the result before the update step.", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "before", "=", "normalizer", ".", "normalize", "(", "tensor", ")", "\n", "\n", "# Apply an update (should have no effect).", "\n", "", "self", ".", "_update", "(", "normalizer", ",", "strategy", ",", "tensor", ")", "\n", "\n", "# Get the result after the update step.", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "after", "=", "normalizer", ".", "normalize", "(", "tensor", ")", "\n", "\n", "", "shouldbe", "=", "(", "tensor", "-", "1.", ")", "/", "10.", "\n", "self", ".", "assertAllClose", "(", "before", ",", "shouldbe", ")", "\n", "self", ".", "assertAllClose", "(", "after", ",", "shouldbe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest.test_variables": [[330, 335], ["running_statistics_test.FixedMeanStdTest._setup_normalizer", "running_statistics_test.FixedMeanStdTest.assertEmpty", "running_statistics_test.FixedMeanStdTest.assertEmpty"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer"], ["", "def", "test_variables", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that we have the correct number of variables.\"\"\"", "\n", "normalizer", ",", "_", "=", "self", ".", "_setup_normalizer", "(", "10", ",", "1.", ",", "10.", ")", "\n", "self", ".", "assertEmpty", "(", "normalizer", ".", "variables", ",", "0", ")", "\n", "self", ".", "assertEmpty", "(", "normalizer", ".", "trainable_variables", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest.test_invertible": [[336, 350], ["running_statistics_test.FixedMeanStdTest._setup_normalizer", "tensorflow.reshape", "running_statistics_test.FixedMeanStdTest._update", "running_statistics_test.FixedMeanStdTest.assertAllClose", "tensorflow.range", "strategy.scope", "normalizer.normalize", "normalizer.unnormalize"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._setup_normalizer", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.FixedMeanStdTest._update", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.unnormalize"], ["", "def", "test_invertible", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the normalization is invertible.\"\"\"", "\n", "normalizer", ",", "strategy", "=", "self", ".", "_setup_normalizer", "(", "10", ",", "1.", ",", "10.", ")", "\n", "tensor", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "200", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "(", "20", ",", "10", ")", ")", "\n", "\n", "# Apply update.", "\n", "self", ".", "_update", "(", "normalizer", ",", "strategy", ",", "tensor", ")", "\n", "\n", "# Verify that update is correct.", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "normalized", "=", "normalizer", ".", "normalize", "(", "tensor", ")", "\n", "inverted", "=", "normalizer", ".", "unnormalize", "(", "normalized", ")", "\n", "\n", "", "self", ".", "assertAllClose", "(", "tensor", ",", "inverted", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics_test.setUpModule": [[25, 28], ["seed_rl.agents.policy_gradient.modules.test_utils.simulate_two_devices"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.simulate_two_devices"], ["def", "setUpModule", "(", ")", ":", "\n", "# We want our tests to run on several devices with a mirrored strategy.", "\n", "  ", "test_utils", ".", "simulate_two_devices", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.TestCase.setUp": [[35, 59], ["super().setUp", "frozenset", "absl.logging.info", "absl.logging.info", "tensorflow.config.list_physical_devices", "tensorflow.config.list_logical_devices", "tensorflow.device", "test_utils.TestCase._device.__enter__", "tensorflow.config.experimental.list_logical_devices", "tensorflow.tpu.experimental.initialize_tpu_system"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.TPUEncodeTest.setUp", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.nullcontext.__enter__"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "setUp", "(", ")", "\n", "\n", "# Enable autograph strict mode - any autograph errors will trigger an error", "\n", "# rather than falling back to no conversion.", "\n", "os", ".", "environ", "[", "\"AUTOGRAPH_STRICT_CONVERSION\"", "]", "=", "\"1\"", "\n", "\n", "self", ".", "_device_types", "=", "frozenset", "(", "\n", "d", ".", "device_type", "for", "d", "in", "tf", ".", "config", ".", "experimental", ".", "list_logical_devices", "(", ")", ")", "\n", "self", ".", "on_tpu", "=", "\"TPU\"", "in", "self", ".", "_device_types", "\n", "logging", ".", "info", "(", "\"Physical devices: %s\"", ",", "tf", ".", "config", ".", "list_physical_devices", "(", ")", ")", "\n", "logging", ".", "info", "(", "\"Logical devices: %s\"", ",", "tf", ".", "config", ".", "list_logical_devices", "(", ")", ")", "\n", "\n", "# Initialize the TPU system once and only once.", "\n", "global", "tpu_initialized", "\n", "if", "tpu_initialized", "is", "None", ":", "\n", "      ", "with", "tpu_initialized_lock", ":", "\n", "        ", "if", "tpu_initialized", "is", "None", "and", "self", ".", "on_tpu", ":", "\n", "          ", "tf", ".", "tpu", ".", "experimental", ".", "initialize_tpu_system", "(", ")", "\n", "", "tpu_initialized", "=", "True", "\n", "\n", "", "", "if", "self", ".", "ENTER_PRIMARY_DEVICE", ":", "\n", "      ", "self", ".", "_device", "=", "tf", ".", "device", "(", "\"/device:%s:0\"", "%", "self", ".", "primary_device", ")", "\n", "self", ".", "_device", ".", "__enter__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.TestCase.tearDown": [[60, 65], ["super().tearDown", "test_utils.TestCase._device.__exit__", "sys.exc_info"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.TestCase.tearDown", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.nullcontext.__exit__"], ["", "", "def", "tearDown", "(", "self", ")", ":", "\n", "    ", "super", "(", ")", ".", "tearDown", "(", ")", "\n", "if", "self", ".", "ENTER_PRIMARY_DEVICE", ":", "\n", "      ", "self", ".", "_device", ".", "__exit__", "(", "*", "sys", ".", "exc_info", "(", ")", ")", "\n", "del", "self", ".", "_device", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.TestCase.primary_device": [[66, 74], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "primary_device", "(", "self", ")", "->", "str", ":", "\n", "    ", "if", "\"TPU\"", "in", "self", ".", "_device_types", ":", "\n", "      ", "return", "\"TPU\"", "\n", "", "elif", "\"GPU\"", "in", "self", ".", "_device_types", ":", "\n", "      ", "return", "\"GPU\"", "\n", "", "else", ":", "\n", "      ", "return", "\"CPU\"", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.simulate_two_devices": [[76, 108], ["absl.logging.error", "tensorflow.config.list_physical_devices", "tensorflow.config.experimental.set_virtual_device_configuration", "absl.logging.info", "tensorflow.config.list_physical_devices", "len", "tensorflow.config.experimental.VirtualDeviceConfiguration", "tensorflow.config.experimental.VirtualDeviceConfiguration"], "function", ["None"], ["", "", "", "def", "simulate_two_devices", "(", "device_types", ":", "Iterable", "[", "str", "]", "=", "(", "\"GPU\"", ",", "\"CPU\"", ")", ")", ":", "\n", "  ", "\"\"\"Splits the primary device (CPU/GPU) into two virtual devices.\n\n  Call this inside the setUpModule() before TF has the chance to initialize\n  the primary device.\n  It will first try splitting the first GPU (if available). If no GPU is\n  available it will split the first CPU device.\n\n  Args:\n    device_types: List of devices for which should be split (if available).\n  \"\"\"", "\n", "for", "device_type", "in", "device_types", ":", "\n", "    ", "devices", "=", "tf", ".", "config", ".", "list_physical_devices", "(", "device_type", "=", "device_type", ")", "\n", "if", "not", "devices", ":", "\n", "      ", "continue", "\n", "", "assert", "len", "(", "devices", ")", "==", "1", ",", "devices", "\n", "# For GPUs we should adjust the memory limit. GPUs on Forge have 16 GB,", "\n", "# but 2 * 4 GB should be enough for tests.", "\n", "memory_limit", "=", "4096", "if", "device_type", "==", "\"GPU\"", "else", "None", "# MB", "\n", "tf", ".", "config", ".", "experimental", ".", "set_virtual_device_configuration", "(", "\n", "devices", "[", "0", "]", ",", "[", "\n", "tf", ".", "config", ".", "experimental", ".", "VirtualDeviceConfiguration", "(", "\n", "memory_limit", "=", "memory_limit", ")", ",", "\n", "tf", ".", "config", ".", "experimental", ".", "VirtualDeviceConfiguration", "(", "\n", "memory_limit", "=", "memory_limit", ")", "\n", "]", ")", "\n", "logging", ".", "info", "(", "\"Split %s into two virtual devices with memory limit %s.\"", ",", "\n", "devices", "[", "0", "]", ",", "memory_limit", ")", "\n", "return", "\n", "", "logging", ".", "error", "(", "\n", "\"Did not split any device into two device, physical devices: %s\"", ",", "\n", "tf", ".", "config", ".", "list_physical_devices", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils._get_gpu_or_cpu_devices": [[110, 119], ["ValueError", "tensorflow.config.experimental.list_logical_devices", "tensorflow.config.experimental.list_logical_devices"], "function", ["None"], ["", "def", "_get_gpu_or_cpu_devices", "(", ")", "->", "Optional", "[", "List", "[", "str", "]", "]", ":", "\n", "  ", "\"\"\"Get the list of GPU or CPU devicen (prefering GPUs).\"\"\"", "\n", "for", "device_type", "in", "[", "\"GPU\"", ",", "\"CPU\"", "]", ":", "\n", "    ", "devices", "=", "tf", ".", "config", ".", "experimental", ".", "list_logical_devices", "(", "\n", "device_type", "=", "device_type", ")", "\n", "if", "devices", ":", "\n", "      ", "return", "[", "d", ".", "name", "for", "d", "in", "devices", "]", "\n", "", "", "raise", "ValueError", "(", "\n", "\"Could not find any logical devices of type GPU or CPU, logical devices: \"", "\n", "f\"{tf.config.experimental.list_logical_devices()}\"", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.create_distribution_strategy": [[128, 151], ["absl.logging.info", "absl.logging.info", "tensorflow.distribute.cluster_resolver.TPUClusterResolver", "tensorflow.tpu.experimental.initialize_tpu_system", "tensorflow.distribute.experimental.TPUStrategy", "test_utils._get_gpu_or_cpu_devices", "tensorflow.config.list_logical_devices", "len", "tensorflow.distribute.OneDeviceStrategy", "tensorflow.distribute.MirroredStrategy"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils._get_gpu_or_cpu_devices"], ["def", "create_distribution_strategy", "(", "use_tpu", ":", "bool", ")", "->", "DistributionStrategy", ":", "\n", "  ", "\"\"\"Create a distribution strategy.\n\n  Args:\n   use_tpu: Uses a TPU strategy.\n\n  Returns:\n    Distribution strategy.\n  \"\"\"", "\n", "if", "use_tpu", ":", "\n", "    ", "resolver", "=", "tf", ".", "distribute", ".", "cluster_resolver", ".", "TPUClusterResolver", "(", "tpu", "=", "\"local\"", ")", "\n", "tf", ".", "tpu", ".", "experimental", ".", "initialize_tpu_system", "(", "resolver", ")", "\n", "strategy", "=", "tf", ".", "distribute", ".", "experimental", ".", "TPUStrategy", "(", "resolver", ")", "\n", "", "else", ":", "\n", "    ", "devices", "=", "_get_gpu_or_cpu_devices", "(", ")", "\n", "if", "len", "(", "devices", ")", "==", "1", ":", "\n", "      ", "strategy", "=", "tf", ".", "distribute", ".", "OneDeviceStrategy", "(", "devices", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "      ", "strategy", "=", "tf", ".", "distribute", ".", "MirroredStrategy", "(", "devices", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "\"Devices: %s\"", ",", "tf", ".", "config", ".", "list_logical_devices", "(", ")", ")", "\n", "logging", ".", "info", "(", "\"Distribution strategy: %s\"", ",", "strategy", ")", "\n", "return", "strategy", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints.Coefficient.init": [[26, 29], ["None"], "methods", ["None"], ["def", "init", "(", "self", ")", ":", "\n", "    ", "\"\"\"Initializes TF variables (if any).\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints.Coefficient.__call__": [[30, 34], ["NotImplementedError"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "__call__", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns the value of the coefficient.\"\"\"", "\n", "raise", "NotImplementedError", "(", "'__call__() not implemented!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints.Coefficient.adjustment_loss": [[35, 46], ["NotImplementedError"], "methods", ["None"], ["", "def", "adjustment_loss", "(", "self", ",", "reference_value", ")", ":", "\n", "    ", "\"\"\"Loss for coefficient adjustment.\n\n    Args:\n       reference_value: Adaptive coefficients may depend on this value, e.g.\n          for a Lagrange multiplier for an inequality constraint this would\n          be the variable we are trying to constrain.\n    Returns:\n       Loss which should be minimized to adjust the coefficient.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", "'adjustment_loss() not implemented'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints.Coefficient.scale_loss": [[47, 50], ["tensorflow.stop_gradient", "constraints.Coefficient."], "methods", ["None"], ["", "def", "scale_loss", "(", "self", ",", "unscaled_loss", ")", ":", "\n", "    ", "\"\"\"Scales the given loss by the coefficient.\"\"\"", "\n", "return", "tf", ".", "stop_gradient", "(", "self", "(", ")", ")", "*", "unscaled_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints.FixedCoefficient.__init__": [[56, 59], ["tensorflow.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "value", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "value", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints.FixedCoefficient.__call__": [[60, 62], ["tensorflow.convert_to_tensor"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "    ", "return", "tf", ".", "convert_to_tensor", "(", "self", ".", "value", ",", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints.FixedCoefficient.adjustment_loss": [[63, 65], ["tensorflow.constant"], "methods", ["None"], ["", "def", "adjustment_loss", "(", "self", ",", "reference_value", ")", ":", "\n", "    ", "return", "tf", ".", "constant", "(", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints.LagrangeInequalityCoefficient.__init__": [[90, 115], ["tensorflow.Module.__init__", "constraints.LagrangeInequalityCoefficient.init"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.init"], ["def", "__init__", "(", "self", ",", "threshold", ",", "\n", "init_alpha", "=", "1.", ",", "\n", "alpha_range", "=", "(", "1e-6", ",", "1e6", ")", ",", "\n", "adjustment_speed", "=", "1.", ",", "\n", "init_variables", "=", "True", ")", ":", "\n", "    ", "\"\"\"Creates a constraint.\n\n    Args:\n      threshold: Maximum value that the constrained variable should not exceed.\n      init_alpha: Initial value of the penalty coefficient (i.e. Lagrange\n        multiplier).\n      alpha_range: A pair of floats with min and max allowed values for alpha.\n      adjustment_speed: A float controlling how fast alpha is adjusted.\n      init_variables: Whether to create the variables in the constructor.\n        If False, than you will have to call init() manually before calling\n        any other methods of this object.\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "threshold", "=", "threshold", "\n", "self", ".", "init_alpha", "=", "init_alpha", "\n", "self", ".", "alpha_range", "=", "alpha_range", "\n", "self", ".", "adjustment_speed", "=", "adjustment_speed", "\n", "assert", "alpha_range", "[", "0", "]", ">=", "0", "\n", "if", "init_variables", ":", "\n", "      ", "self", ".", "init", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints.LagrangeInequalityCoefficient.init": [[116, 129], ["hasattr", "tensorflow.Variable", "tensorflow.clip_by_value", "tensorflow.math.log", "tensorflow.math.log"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log"], ["", "", "def", "init", "(", "self", ")", ":", "\n", "    ", "if", "hasattr", "(", "self", ",", "'param'", ")", ":", "\n", "      ", "return", "\n", "", "mul", "=", "self", ".", "adjustment_speed", "\n", "def", "constraint", "(", "v", ")", ":", "\n", "      ", "return", "tf", ".", "clip_by_value", "(", "\n", "v", ",", "\n", "*", "[", "tf", ".", "math", ".", "log", "(", "c", ")", "/", "mul", "for", "c", "in", "self", ".", "alpha_range", "]", ")", "\n", "", "self", ".", "param", "=", "tf", ".", "Variable", "(", "\n", "tf", ".", "math", ".", "log", "(", "self", ".", "init_alpha", ")", "/", "mul", ",", "\n", "constraint", "=", "constraint", ",", "\n", "trainable", "=", "True", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints.LagrangeInequalityCoefficient.__call__": [[130, 132], ["tensorflow.exp"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "    ", "return", "tf", ".", "exp", "(", "self", ".", "adjustment_speed", "*", "self", ".", "param", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.constraints.LagrangeInequalityCoefficient.adjustment_loss": [[133, 136], ["constraints.LagrangeInequalityCoefficient.", "tensorflow.stop_gradient", "tensorflow.reduce_mean"], "methods", ["None"], ["", "def", "adjustment_loss", "(", "self", ",", "reference_value", ")", ":", "\n", "    ", "return", "self", "(", ")", "*", "tf", ".", "stop_gradient", "(", "self", ".", "threshold", "-", "\n", "tf", ".", "reduce_mean", "(", "reference_value", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_regularizers_test.PolicyRegularizer.test_continuous_action": [[27, 42], ["seed_rl.agents.policy_gradient.modules.policy_regularizers.KLPolicyRegularizer", "seed_rl.agents.policy_gradient.modules.policy_regularizers.KLPolicyRegularizer.set_logging_dict", "seed_rl.common.parametric_distribution.normal_tanh_distribution", "tensorflow.random.normal", "tensorflow.random.normal", "tensorflow.random.normal", "seed_rl.agents.policy_gradient.modules.policy_regularizers.KLPolicyRegularizer.", "seed_rl.agents.policy_gradient.modules.policy_regularizers.KLPolicyRegularizer.unset_logging_dict", "policy_regularizers_test.PolicyRegularizer.assertIn", "seed_rl.agents.policy_gradient.modules.constraints.LagrangeInequalityCoefficient"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module.LoggingModule.set_logging_dict", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.normal_tanh_distribution", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module.LoggingModule.unset_logging_dict"], ["  ", "def", "test_continuous_action", "(", "self", ")", ":", "\n", "    ", "my_log_dict", "=", "{", "}", "\n", "regularizer", "=", "policy_regularizers", ".", "KLPolicyRegularizer", "(", "\n", "kl_pi_mu", "=", "1.2", ",", "\n", "kl_mu_pi", "=", "constraints", ".", "LagrangeInequalityCoefficient", "(", "threshold", "=", "1e-3", ")", ",", "\n", "entropy", "=", "0.3", ",", "\n", "kl_ref_pi", "=", "0.2", ")", "\n", "regularizer", ".", "set_logging_dict", "(", "my_log_dict", ")", "\n", "distribution", "=", "parametric_distribution", ".", "normal_tanh_distribution", "(", "7", ")", "\n", "pi_logits", "=", "tf", ".", "random", ".", "normal", "(", "(", "10", ",", "20", ",", "14", ")", ")", "\n", "mu_logits", "=", "tf", ".", "random", ".", "normal", "(", "(", "10", ",", "20", ",", "14", ")", ")", "\n", "actions", "=", "tf", ".", "random", ".", "normal", "(", "(", "10", ",", "20", ",", "7", ")", ")", "\n", "regularizer", "(", "distribution", ",", "pi_logits", ",", "mu_logits", ",", "actions", ")", "\n", "regularizer", ".", "unset_logging_dict", "(", ")", "\n", "self", ".", "assertIn", "(", "'KLPolicyRegularizer/kl_ref_pi'", ",", "my_log_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_regularizers_test.PolicyRegularizer.test_discrete_actions": [[43, 59], ["seed_rl.agents.policy_gradient.modules.policy_regularizers.KLPolicyRegularizer", "seed_rl.agents.policy_gradient.modules.policy_regularizers.KLPolicyRegularizer.set_logging_dict", "seed_rl.common.parametric_distribution.multi_categorical_distribution", "tensorflow.random.normal", "tensorflow.random.normal", "tensorflow.zeros", "seed_rl.agents.policy_gradient.modules.policy_regularizers.KLPolicyRegularizer.", "seed_rl.agents.policy_gradient.modules.policy_regularizers.KLPolicyRegularizer.unset_logging_dict", "policy_regularizers_test.PolicyRegularizer.assertNotIn", "seed_rl.agents.policy_gradient.modules.constraints.LagrangeInequalityCoefficient"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module.LoggingModule.set_logging_dict", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.multi_categorical_distribution", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module.LoggingModule.unset_logging_dict"], ["", "def", "test_discrete_actions", "(", "self", ")", ":", "\n", "    ", "my_log_dict", "=", "{", "}", "\n", "regularizer", "=", "policy_regularizers", ".", "KLPolicyRegularizer", "(", "\n", "kl_pi_mu", "=", "1.2", ",", "\n", "kl_mu_pi", "=", "1.0", ",", "\n", "entropy", "=", "constraints", ".", "LagrangeInequalityCoefficient", "(", "threshold", "=", "1e-3", ")", ",", "\n", "kl_ref_pi", "=", "1.3", ")", "\n", "regularizer", ".", "set_logging_dict", "(", "my_log_dict", ")", "\n", "distribution", "=", "parametric_distribution", ".", "multi_categorical_distribution", "(", "\n", "7", ",", "11", ",", "tf", ".", "int32", ")", "\n", "pi_logits", "=", "tf", ".", "random", ".", "normal", "(", "(", "10", ",", "20", ",", "7", "*", "11", ")", ")", "\n", "mu_logits", "=", "tf", ".", "random", ".", "normal", "(", "(", "10", ",", "20", ",", "7", "*", "11", ")", ")", "\n", "actions", "=", "tf", ".", "zeros", "(", "(", "10", ",", "20", ",", "7", ")", ",", "tf", ".", "int32", ")", "\n", "regularizer", "(", "distribution", ",", "pi_logits", ",", "mu_logits", ",", "actions", ")", "\n", "regularizer", ".", "unset_logging_dict", "(", ")", "\n", "self", ".", "assertNotIn", "(", "'KLPolicyRegularizer/kl_mu_pi_mean'", ",", "my_log_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.__init__": [[67, 84], ["isinstance", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mean_std_tracker", ",", "compensate", "=", "True", ")", ":", "\n", "    ", "\"\"\"Creates a PopArt.\n\n    Args:\n      mean_std_tracker: Instance of running_statistics.MeanStd used for tracking\n        the mean and the standard deviation.\n      compensate: Whether to introduce a trainbale linear transform which\n        compensates for normalization. If False, correct_prediction is\n        an identity mapping.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "mean_std_tracker", ",", "running_statistics", ".", "MeanStd", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'`mean_std_tracker` needs to be an instance of MeanStd.'", ")", "\n", "", "self", ".", "mean_std_tracker", "=", "mean_std_tracker", "\n", "self", ".", "compensate", "=", "compensate", "\n", "self", ".", "compensation_mean", "=", "None", "\n", "self", ".", "compensation_std", "=", "None", "\n", "self", ".", "initialized", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.init": [[85, 110], ["popart.PopArt.mean_std_tracker.init", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.zeros", "tensorflow.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.init"], ["", "def", "init", "(", "self", ")", ":", "\n", "    ", "\"\"\"Initializes normalization variables.\n\n    This is done explicitly in a manual step since variables need to be created\n    under the correct distribution strategy scope.\n    \"\"\"", "\n", "if", "self", ".", "initialized", ":", "\n", "      ", "return", "\n", "", "self", ".", "mean_std_tracker", ".", "init", "(", "1", ")", "\n", "if", "self", ".", "compensate", ":", "\n", "      ", "self", ".", "compensation_mean", "=", "tf", ".", "Variable", "(", "\n", "name", "=", "'running_mean'", ",", "\n", "shape", "=", "[", "]", ",", "\n", "trainable", "=", "True", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initial_value", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "]", ")", ",", "\n", "aggregation", "=", "tf", ".", "VariableAggregation", ".", "MEAN", ")", "\n", "self", ".", "compensation_std", "=", "tf", ".", "Variable", "(", "\n", "name", "=", "'running_std'", ",", "\n", "shape", "=", "[", "]", ",", "\n", "trainable", "=", "True", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initial_value", "=", "tf", ".", "ones", "(", "shape", "=", "[", "]", ")", ",", "\n", "aggregation", "=", "tf", ".", "VariableAggregation", ".", "MEAN", ")", "\n", "", "self", ".", "initialized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.normalize_target": [[111, 122], ["popart.PopArt.mean_std_tracker.normalize", "tensorflow.squeeze", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize"], ["", "def", "normalize_target", "(", "self", ",", "x", ")", ":", "\n", "    ", "\"\"\"Normalizes target values x using past target statistics.\n\n    Args:\n      x: <float32> tensor.\n\n    Returns:\n      <float32> normalized tensor.\n    \"\"\"", "\n", "vector", "=", "self", ".", "mean_std_tracker", ".", "normalize", "(", "tf", ".", "expand_dims", "(", "x", ",", "-", "1", ")", ")", "\n", "return", "tf", ".", "squeeze", "(", "vector", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.normalize_advantage": [[123, 136], ["popart.PopArt.mean_std_tracker.get_mean_std"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.get_mean_std"], ["", "def", "normalize_advantage", "(", "self", ",", "x", ")", ":", "\n", "    ", "\"\"\"Normalizes advantage values x using past target statistics.\n\n    Args:\n      x: <float32> tensor.\n\n    Returns:\n      <float32> normalized tensor.\n    \"\"\"", "\n", "# Advantage values are differences, thus we only need to divide by the", "\n", "# standard deviation.", "\n", "_", ",", "std", "=", "self", ".", "mean_std_tracker", ".", "get_mean_std", "(", ")", "\n", "return", "x", "/", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.correct_prediction": [[137, 150], ["None"], "methods", ["None"], ["", "def", "correct_prediction", "(", "self", ",", "x", ")", ":", "\n", "    ", "\"\"\"Corrects a prediction x using compensation parameters.\n\n    Args:\n      x: <float32> tensor.\n\n    Returns:\n      <float32> corrected tensor.\n    \"\"\"", "\n", "if", "self", ".", "compensate", ":", "\n", "      ", "return", "self", ".", "compensation_std", "*", "x", "+", "self", ".", "compensation_mean", "\n", "", "else", ":", "\n", "      ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.unnormalize_prediction": [[151, 162], ["popart.PopArt.mean_std_tracker.unnormalize", "tensorflow.squeeze", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.unnormalize"], ["", "", "def", "unnormalize_prediction", "(", "self", ",", "x", ")", ":", "\n", "    ", "\"\"\"Unnormalizes a corrected prediction x using past target statistics.\n\n    Args:\n      x: <float32>[batch,] tensor.\n\n    Returns:\n      <float32>[batch] unnormalized tensor.\n    \"\"\"", "\n", "vector", "=", "self", ".", "mean_std_tracker", ".", "unnormalize", "(", "tf", ".", "expand_dims", "(", "x", ",", "-", "1", ")", ")", "\n", "return", "tf", ".", "squeeze", "(", "vector", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.update_normalization_statistics": [[163, 184], ["popart.PopArt.mean_std_tracker.get_mean_std", "popart.PopArt.mean_std_tracker.update", "popart.PopArt.mean_std_tracker.get_mean_std", "popart.PopArt.log", "popart.PopArt.log", "tensorflow.expand_dims", "popart.PopArt.compensation_mean.assign", "popart.PopArt.compensation_std.assign", "tensorflow.squeeze", "tensorflow.squeeze"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.get_mean_std", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.update", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.get_mean_std", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log"], ["", "def", "update_normalization_statistics", "(", "self", ",", "data", ")", ":", "\n", "    ", "\"\"\"Updates running statistics and compensation statistics.\n\n    Args:\n      data: <float32>[time, batch_size].\n    \"\"\"", "\n", "# Update the running statistics.", "\n", "mean1", ",", "std1", "=", "self", ".", "mean_std_tracker", ".", "get_mean_std", "(", ")", "\n", "self", ".", "mean_std_tracker", ".", "update", "(", "tf", ".", "expand_dims", "(", "data", ",", "-", "1", ")", ")", "\n", "mean2", ",", "std2", "=", "self", ".", "mean_std_tracker", ".", "get_mean_std", "(", ")", "\n", "\n", "self", ".", "log", "(", "'PopArt/mean'", ",", "mean2", ")", "\n", "self", ".", "log", "(", "'PopArt/std'", ",", "std2", ")", "\n", "\n", "if", "self", ".", "compensate", ":", "\n", "# Update the compensation parameters.", "\n", "      ", "new_compensation_std", "=", "std1", "/", "std2", "*", "self", ".", "compensation_std", "\n", "new_compensation_mean", "=", "(", "mean1", "-", "mean2", "+", "\n", "std1", "*", "self", ".", "compensation_mean", ")", "/", "std2", "\n", "self", ".", "compensation_mean", ".", "assign", "(", "tf", ".", "squeeze", "(", "new_compensation_mean", ",", "-", "1", ")", ")", "\n", "self", ".", "compensation_std", ".", "assign", "(", "tf", ".", "squeeze", "(", "new_compensation_std", ",", "-", "1", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.ppo_training_step_utils_test.PPOUtilsTest.test_split": [[41, 62], ["Unroll", "seed_rl.agents.policy_gradient.modules.ppo_training_step_utils.compute_advantages_and_split", "ppo_training_step_utils_test.PPOUtilsTest.assertEqual", "ppo_training_step_utils_test.PPOUtilsTest.assertLen", "tensorflow.zeros", "DummyLoss", "len", "tensorflow.zeros", "tensorflow.zeros"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.ppo_training_step_utils.compute_advantages_and_split"], ["  ", "def", "test_split", "(", "self", ")", ":", "\n", "# tensor dims", "\n", "    ", "timesteps", "=", "3", "\n", "batch_size", "=", "2", "\n", "observation_size", "=", "2", "\n", "\n", "class", "DummyLoss", ":", "\n", "\n", "      ", "def", "compute_advantages", "(", "self", ",", "*", "_", ")", ":", "\n", "        ", "return", "(", "tf", ".", "zeros", "(", "shape", "=", "(", "timesteps", "-", "1", ",", "batch_size", ",", "observation_size", ")", ")", ",", "\n", "tf", ".", "zeros", "(", "shape", "=", "(", "timesteps", "-", "1", ",", "batch_size", ",", "observation_size", ")", ")", ")", "\n", "\n", "", "", "input_args", "=", "Unroll", "(", "\n", "(", ")", ",", "(", ")", ",", "(", ")", ",", "tf", ".", "zeros", "(", "shape", "=", "(", "timesteps", ",", "batch_size", ",", "observation_size", ")", ")", ")", "\n", "output_args", "=", "ppo_training_step_utils", ".", "compute_advantages_and_split", "(", "\n", "DummyLoss", "(", ")", ",", "input_args", ")", "\n", "\n", "self", ".", "assertEqual", "(", "output_args", "[", "3", "]", ".", "shape", ",", "\n", "(", "1", ",", "(", "timesteps", "-", "1", ")", "*", "batch_size", ",", "observation_size", ")", ")", "\n", "# Checks that the advantages have been appended.", "\n", "self", ".", "assertLen", "(", "output_args", ",", "len", "(", "input_args", ")", "+", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.ppo_training_step_utils_test.PPOUtilsTest.test_ppo_training_step": [[63, 152], ["absl.testing.parameterized.parameters", "gym.spaces.Box", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "seed_rl.agents.policy_gradient.modules.continuous_control_agent.ContinuousControlAgent", "tensorflow.zeros", "tensorflow.reshape", "seed_rl.common.utils.EnvOutput", "seed_rl.agents.policy_gradient.modules.continuous_control_agent.ContinuousControlAgent.", "Unroll", "seed_rl.agents.policy_gradient.modules.generalized_onpolicy_loss.GeneralizedOnPolicyLoss", "seed_rl.agents.policy_gradient.modules.generalized_onpolicy_loss.GeneralizedOnPolicyLoss.init", "seed_rl.agents.policy_gradient.modules.ppo_training_step_utils.ppo_training_step", "tensorflow.stack", "tensorflow.zeros", "seed_rl.agents.policy_gradient.modules.continuous_control_agent.ContinuousControlAgent.initial_state", "seed_rl.agents.policy_gradient.modules.popart.PopArt", "seed_rl.agents.policy_gradient.modules.advantages.GAE", "seed_rl.agents.policy_gradient.modules.policy_losses.ppo", "tensorflow.random.uniform", "tensorflow.zeros", "tensorflow.zeros_like", "tensorflow.ones", "seed_rl.agents.policy_gradient.modules.running_statistics.FixedMeanStd", "seed_rl.agents.policy_gradient.modules.policy_regularizers.KLPolicyRegularizer", "DummyStrategy", "tensorflow.keras.optimizers.Adam", "seed_rl.common.utils.ProgressLogger", "gym.spaces.Box.sample", "range"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.init", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.ppo_training_step_utils.ppo_training_step", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.policy_losses.ppo", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], ["", "@", "parameterized", ".", "parameters", "(", "[", "\n", "{", "\n", "'batch_mode'", ":", "'repeat'", ",", "\n", "'use_agent_state'", ":", "False", ",", "\n", "}", ",", "\n", "{", "\n", "'batch_mode'", ":", "'repeat'", ",", "\n", "'use_agent_state'", ":", "True", ",", "\n", "}", ",", "\n", "{", "\n", "'batch_mode'", ":", "'shuffle'", ",", "\n", "'use_agent_state'", ":", "False", ",", "\n", "}", ",", "\n", "{", "\n", "'batch_mode'", ":", "'shuffle'", ",", "\n", "'use_agent_state'", ":", "True", ",", "\n", "}", ",", "\n", "{", "\n", "'batch_mode'", ":", "'split'", ",", "\n", "'use_agent_state'", ":", "False", ",", "\n", "}", ",", "\n", "{", "\n", "'batch_mode'", ":", "'split_with_advantage_recomputation'", ",", "\n", "'use_agent_state'", ":", "False", ",", "\n", "}", ",", "\n", "]", ")", "\n", "def", "test_ppo_training_step", "(", "self", ",", "batch_mode", ",", "use_agent_state", ")", ":", "\n", "    ", "action_space", "=", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "-", "1", ",", "high", "=", "1", ",", "shape", "=", "[", "128", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "distribution", "=", "(", "\n", "parametric_distribution", ".", "get_parametric_distribution_for_action_space", "(", "\n", "action_space", ")", ")", "\n", "training_agent", "=", "continuous_control_agent", ".", "ContinuousControlAgent", "(", "\n", "distribution", ")", "\n", "virtual_bs", "=", "32", "\n", "unroll_length", "=", "5", "\n", "batches_per_step", "=", "4", "\n", "done", "=", "tf", ".", "zeros", "(", "[", "unroll_length", ",", "virtual_bs", "]", ",", "dtype", "=", "tf", ".", "bool", ")", "\n", "prev_actions", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "stack", "(", "[", "action_space", ".", "sample", "(", ")", "\n", "for", "_", "in", "range", "(", "unroll_length", "*", "virtual_bs", ")", "]", ")", ",", "\n", "[", "unroll_length", ",", "virtual_bs", ",", "-", "1", "]", ")", "\n", "env_outputs", "=", "utils", ".", "EnvOutput", "(", "\n", "reward", "=", "tf", ".", "random", ".", "uniform", "(", "[", "unroll_length", ",", "virtual_bs", "]", ")", ",", "\n", "done", "=", "done", ",", "\n", "observation", "=", "tf", ".", "zeros", "(", "[", "unroll_length", ",", "virtual_bs", ",", "128", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "abandoned", "=", "tf", ".", "zeros_like", "(", "done", ")", ",", "\n", "episode_step", "=", "tf", ".", "ones", "(", "[", "unroll_length", ",", "virtual_bs", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ")", "\n", "if", "use_agent_state", ":", "\n", "      ", "core_state", "=", "tf", ".", "zeros", "(", "[", "virtual_bs", ",", "64", "]", ")", "\n", "", "else", ":", "\n", "      ", "core_state", "=", "training_agent", ".", "initial_state", "(", "virtual_bs", ")", "\n", "", "agent_outputs", ",", "_", "=", "training_agent", "(", "(", "prev_actions", ",", "env_outputs", ")", ",", "\n", "core_state", ",", "\n", "unroll", "=", "True", ")", "\n", "args", "=", "Unroll", "(", "core_state", ",", "prev_actions", ",", "env_outputs", ",", "agent_outputs", ")", "\n", "\n", "class", "DummyStrategy", ":", "\n", "\n", "      ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "num_replicas_in_sync", "=", "1", "\n", "\n", "", "", "loss_fn", "=", "generalized_onpolicy_loss", ".", "GeneralizedOnPolicyLoss", "(", "\n", "training_agent", ",", "\n", "popart", ".", "PopArt", "(", "running_statistics", ".", "FixedMeanStd", "(", ")", ",", "compensate", "=", "False", ")", ",", "\n", "distribution", ",", "\n", "ga_advantages", ".", "GAE", "(", "lambda_", "=", "0.9", ")", ",", "\n", "policy_losses", ".", "ppo", "(", "0.9", ")", ",", "\n", "discount_factor", "=", "0.99", ",", "\n", "regularizer", "=", "policy_regularizers", ".", "KLPolicyRegularizer", "(", "entropy", "=", "0.5", ")", ",", "\n", "baseline_cost", "=", "0.5", ",", "\n", "max_abs_reward", "=", "None", ",", "\n", "frame_skip", "=", "1", ",", "\n", "reward_scaling", "=", "10", ")", "\n", "loss_fn", ".", "init", "(", ")", "\n", "loss", ",", "logs", "=", "ppo_training_step_utils", ".", "ppo_training_step", "(", "\n", "epochs_per_step", "=", "8", ",", "\n", "loss_fn", "=", "loss_fn", ",", "\n", "args", "=", "args", ",", "\n", "batch_mode", "=", "batch_mode", ",", "\n", "training_strategy", "=", "DummyStrategy", "(", ")", ",", "\n", "virtual_batch_size", "=", "virtual_bs", ",", "\n", "unroll_length", "=", "unroll_length", "-", "1", ",", "\n", "batches_per_step", "=", "batches_per_step", ",", "\n", "clip_norm", "=", "50.", ",", "\n", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "1e-3", ")", ",", "\n", "logger", "=", "utils", ".", "ProgressLogger", "(", ")", ")", "\n", "del", "loss", "\n", "del", "logs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest._setup": [[32, 41], ["seed_rl.agents.policy_gradient.modules.popart.PopArt", "seed_rl.agents.policy_gradient.modules.test_utils.create_distribution_strategy", "popart_test.PopArtTest.assertEqual", "seed_rl.agents.policy_gradient.modules.running_statistics.EMAMeanStd", "seed_rl.agents.policy_gradient.modules.test_utils.create_distribution_strategy.scope", "seed_rl.agents.policy_gradient.modules.popart.PopArt.init"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.create_distribution_strategy", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.init"], ["def", "_setup", "(", "self", ",", "beta", ")", ":", "\n", "    ", "\"\"\"Sets up the reward normalizer and a distribution strategy to run.\"\"\"", "\n", "reward_normalizer", "=", "popart", ".", "PopArt", "(", "running_statistics", ".", "EMAMeanStd", "(", "beta", ")", ")", "\n", "strategy", "=", "test_utils", ".", "create_distribution_strategy", "(", "\n", "use_tpu", "=", "self", ".", "primary_device", "==", "'TPU'", ")", "\n", "self", ".", "assertEqual", "(", "strategy", ".", "num_replicas_in_sync", ",", "2", ")", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "reward_normalizer", ".", "init", "(", ")", "\n", "", "return", "reward_normalizer", ",", "strategy", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest._update_normalization_statistics": [[42, 50], ["tensorflow.data.Dataset.from_tensors", "iter", "next", "tensorflow.function", "strategy.run", "strategy.experimental_distribute_dataset"], "methods", ["None"], ["", "def", "_update_normalization_statistics", "(", "self", ",", "reward_normalizer", ",", "strategy", ",", "\n", "targets", ")", ":", "\n", "    ", "\"\"\"Updates the normalization statistics via the strategy.\"\"\"", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensors", "(", "targets", ")", "\n", "dataset_iterator", "=", "iter", "(", "strategy", ".", "experimental_distribute_dataset", "(", "dataset", ")", ")", "\n", "distributed_values", "=", "next", "(", "dataset_iterator", ")", "\n", "f", "=", "tf", ".", "function", "(", "reward_normalizer", ".", "update_normalization_statistics", ")", "\n", "strategy", ".", "run", "(", "f", ",", "(", "distributed_values", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest.test_normalization": [[51, 64], ["popart_test.PopArtTest._setup", "tensorflow.range", "popart_test.PopArtTest._update_normalization_statistics", "popart_test.PopArtTest.assertAllClose", "popart_test.PopArtTest.assertAllClose", "strategy.scope", "reward_normalizer.normalize_target", "tensorflow.reduce_mean", "tensorflow.math.reduce_std"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest._setup", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest._update_normalization_statistics", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.normalize_target"], ["", "def", "test_normalization", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the normalization works.\"\"\"", "\n", "reward_normalizer", ",", "strategy", "=", "self", ".", "_setup", "(", "1.", ")", "\n", "\n", "# Apply update.", "\n", "targets", "=", "tf", ".", "range", "(", "20", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "_update_normalization_statistics", "(", "reward_normalizer", ",", "strategy", ",", "targets", ")", "\n", "\n", "# Verify that normalization works correctly.", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "normalized", "=", "reward_normalizer", ".", "normalize_target", "(", "targets", ")", "\n", "", "self", ".", "assertAllClose", "(", "tf", ".", "reduce_mean", "(", "normalized", ")", ",", "0.", ")", "\n", "self", ".", "assertAllClose", "(", "tf", ".", "math", ".", "reduce_std", "(", "normalized", ")", ",", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest.test_variables": [[65, 70], ["popart_test.PopArtTest._setup", "popart_test.PopArtTest.assertLen", "popart_test.PopArtTest.assertLen"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest._setup"], ["", "def", "test_variables", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests tha we have the correct number of variables.\"\"\"", "\n", "reward_normalizer", ",", "_", "=", "self", ".", "_setup", "(", ".5", ")", "\n", "self", ".", "assertLen", "(", "reward_normalizer", ".", "variables", ",", "4", ")", "\n", "self", ".", "assertLen", "(", "reward_normalizer", ".", "trainable_variables", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest.test_invariance": [[71, 92], ["popart_test.PopArtTest._setup", "tensorflow.range", "popart_test.PopArtTest._update_normalization_statistics", "popart_test.PopArtTest.assertAllClose", "strategy.scope", "reward_normalizer.correct_prediction", "reward_normalizer.unnormalize_prediction", "strategy.scope", "reward_normalizer.correct_prediction", "reward_normalizer.unnormalize_prediction"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest._setup", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest._update_normalization_statistics", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.correct_prediction", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.unnormalize_prediction", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.correct_prediction", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.unnormalize_prediction"], ["", "def", "test_invariance", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the update keeps the convolution invariant.\"\"\"", "\n", "reward_normalizer", ",", "strategy", "=", "self", ".", "_setup", "(", ".5", ")", "\n", "targets", "=", "tf", ".", "range", "(", "20", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# Run the convolution of `correct_prediction(...)` and", "\n", "# `unnormalize_prediction(...)` before the update of the statistics.", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "before", "=", "reward_normalizer", ".", "correct_prediction", "(", "targets", ")", "\n", "before", "=", "reward_normalizer", ".", "unnormalize_prediction", "(", "before", ")", "\n", "\n", "", "self", ".", "_update_normalization_statistics", "(", "reward_normalizer", ",", "strategy", ",", "targets", ")", "\n", "\n", "# Run the convolution of `correct_prediction(...)` and", "\n", "# `unnormalize_prediction(...)` after the update of the statistics.", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "after", "=", "reward_normalizer", ".", "correct_prediction", "(", "targets", ")", "\n", "after", "=", "reward_normalizer", ".", "unnormalize_prediction", "(", "after", ")", "\n", "\n", "# Verify that update is correct.", "\n", "", "self", ".", "assertAllClose", "(", "before", ",", "after", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest.test_invertible": [[93, 107], ["popart_test.PopArtTest._setup", "tensorflow.range", "popart_test.PopArtTest._update_normalization_statistics", "popart_test.PopArtTest.assertAllClose", "strategy.scope", "reward_normalizer.normalize_target", "reward_normalizer.unnormalize_prediction"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest._setup", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest._update_normalization_statistics", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.normalize_target", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.unnormalize_prediction"], ["", "def", "test_invertible", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the normalization is invertible.\"\"\"", "\n", "reward_normalizer", ",", "strategy", "=", "self", ".", "_setup", "(", ".5", ")", "\n", "\n", "# Apply update.", "\n", "targets", "=", "tf", ".", "range", "(", "20", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "_update_normalization_statistics", "(", "reward_normalizer", ",", "strategy", ",", "targets", ")", "\n", "\n", "# Verify that update is correct.", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "normalized", "=", "reward_normalizer", ".", "normalize_target", "(", "targets", ")", "\n", "inverted", "=", "reward_normalizer", ".", "unnormalize_prediction", "(", "normalized", ")", "\n", "\n", "", "self", ".", "assertAllClose", "(", "targets", ",", "inverted", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest.test_advantage": [[108, 126], ["popart_test.PopArtTest._setup", "tensorflow.range", "popart_test.PopArtTest._update_normalization_statistics", "popart_test.PopArtTest.assertAllClose", "tensorflow.reverse", "strategy.scope", "reward_normalizer.normalize_advantage", "reward_normalizer.normalize_target", "tensorflow.reverse"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest._setup", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.PopArtTest._update_normalization_statistics", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.normalize_advantage", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart.PopArt.normalize_target"], ["", "def", "test_advantage", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the advantage normalization works.\"\"\"", "\n", "reward_normalizer", ",", "strategy", "=", "self", ".", "_setup", "(", ".5", ")", "\n", "\n", "# Apply update.", "\n", "targets", "=", "tf", ".", "range", "(", "20", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "_update_normalization_statistics", "(", "reward_normalizer", ",", "strategy", ",", "targets", ")", "\n", "\n", "# Verify that normalization works correctly by seeing if the unnormalized", "\n", "# advantage of normalized targets is the same as the normalized advantage", "\n", "# of the unnormalized targets.", "\n", "advantage", "=", "targets", "-", "tf", ".", "reverse", "(", "targets", ",", "[", "0", "]", ")", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "normalized_advantage", "=", "reward_normalizer", ".", "normalize_advantage", "(", "advantage", ")", "\n", "normalized_targets", "=", "reward_normalizer", ".", "normalize_target", "(", "targets", ")", "\n", "\n", "", "self", ".", "assertAllClose", "(", "normalized_advantage", ",", "\n", "normalized_targets", "-", "tf", ".", "reverse", "(", "normalized_targets", ",", "[", "0", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.popart_test.setUpModule": [[23, 26], ["seed_rl.agents.policy_gradient.modules.test_utils.simulate_two_devices"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.test_utils.simulate_two_devices"], ["def", "setUpModule", "(", ")", ":", "\n", "# We want our tests to run on several devices with a mirrored strategy.", "\n", "  ", "test_utils", ".", "simulate_two_devices", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages_test.GAETest.test_discount_one_lambda_one": [[29, 49], ["tensorflow.reshape", "tensorflow.zeros", "tensorflow.zeros_like", "tensorflow.zeros_like", "seed_rl.agents.policy_gradient.modules.advantages.gae", "tensorflow.broadcast_to", "advantages_test.GAETest.assertAllClose", "advantages_test.GAETest.assertAllClose", "tensorflow.range", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.gae"], ["  ", "def", "test_discount_one_lambda_one", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests the case where lambda_ and discounts are 1 with zero rewards.\n\n    In this case, the target should be just the bootstrap values for each time\n    step.\n    \"\"\"", "\n", "values", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "210", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "(", "21", ",", "10", ")", ")", "\n", "rewards", "=", "tf", ".", "zeros", "(", "(", "20", ",", "10", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "done_terminated", "=", "tf", ".", "zeros_like", "(", "rewards", ",", "dtype", "=", "tf", ".", "bool", ")", "\n", "done_abandoned", "=", "tf", ".", "zeros_like", "(", "rewards", ",", "dtype", "=", "tf", ".", "bool", ")", "\n", "\n", "tested_targets", ",", "tested_advantages", "=", "advantages", ".", "gae", "(", "\n", "values", ",", "rewards", ",", "done_terminated", ",", "done_abandoned", ",", "discount_factor", "=", "1.", ",", "\n", "lambda_", "=", "1.", ")", "\n", "\n", "real_targets", "=", "tf", ".", "broadcast_to", "(", "tf", ".", "expand_dims", "(", "values", "[", "-", "1", "]", ",", "0", ")", ",", "(", "20", ",", "10", ")", ")", "\n", "real_advantages", "=", "real_targets", "-", "values", "[", ":", "-", "1", "]", "\n", "\n", "self", ".", "assertAllClose", "(", "tested_targets", ",", "real_targets", ")", "\n", "self", ".", "assertAllClose", "(", "tested_advantages", ",", "real_advantages", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages_test.GAETest.test_zero_discount": [[50, 63], ["tensorflow.reshape", "tensorflow.zeros", "tensorflow.zeros_like", "tensorflow.zeros_like", "seed_rl.agents.policy_gradient.modules.advantages.gae", "advantages_test.GAETest.assertAllClose", "advantages_test.GAETest.assertAllClose", "tensorflow.range"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.gae"], ["", "def", "test_zero_discount", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests the case where all the value comes from the immediate rewards.\"\"\"", "\n", "rewards", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "200", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "(", "20", ",", "10", ")", ")", "\n", "values", "=", "tf", ".", "zeros", "(", "(", "21", ",", "10", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "done_terminated", "=", "tf", ".", "zeros_like", "(", "rewards", ",", "dtype", "=", "tf", ".", "bool", ")", "\n", "done_abandoned", "=", "tf", ".", "zeros_like", "(", "rewards", ",", "dtype", "=", "tf", ".", "bool", ")", "\n", "\n", "tested_targets", ",", "tested_advantages", "=", "advantages", ".", "gae", "(", "\n", "values", ",", "rewards", ",", "done_terminated", ",", "done_abandoned", ",", "discount_factor", "=", "0.", ",", "\n", "lambda_", "=", "1.", ")", "\n", "\n", "self", ".", "assertAllClose", "(", "tested_targets", ",", "rewards", ")", "\n", "self", ".", "assertAllClose", "(", "tested_advantages", ",", "rewards", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages_test.GAETest.test_lambda_zero": [[64, 85], ["tensorflow.reshape", "tensorflow.ones", "tensorflow.zeros_like", "tensorflow.zeros_like", "seed_rl.agents.policy_gradient.modules.advantages.gae", "advantages_test.GAETest.assertAllClose", "advantages_test.GAETest.assertAllClose", "tensorflow.range"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.gae"], ["", "def", "test_lambda_zero", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests the case where lambda_ is zero.\n\n    In this case the value is the sum of rewards and discounted next-step\n    value/bootstrap value.\n    \"\"\"", "\n", "\n", "values", "=", "tf", ".", "reshape", "(", "tf", ".", "range", "(", "210", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "(", "21", ",", "10", ")", ")", "\n", "rewards", "=", "tf", ".", "ones", "(", "(", "20", ",", "10", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "done_terminated", "=", "tf", ".", "zeros_like", "(", "rewards", ",", "dtype", "=", "tf", ".", "bool", ")", "\n", "done_abandoned", "=", "tf", ".", "zeros_like", "(", "rewards", ",", "dtype", "=", "tf", ".", "bool", ")", "\n", "\n", "tested_targets", ",", "tested_advantages", "=", "advantages", ".", "gae", "(", "\n", "values", ",", "rewards", ",", "done_terminated", ",", "done_abandoned", ",", "discount_factor", "=", ".97", ",", "\n", "lambda_", "=", "0.", ")", "\n", "real_targets", "=", "rewards", "+", "0.97", "*", "values", "[", "1", ":", "]", "\n", "real_advantages", "=", "real_targets", "-", "values", "[", ":", "-", "1", "]", "\n", "\n", "self", ".", "assertAllClose", "(", "tested_targets", ",", "real_targets", ",", "rtol", "=", "1e-5", ",", "atol", "=", "1e-5", ")", "\n", "self", ".", "assertAllClose", "(", "tested_advantages", ",", "real_advantages", ",", "rtol", "=", "1e-5", ",", "\n", "atol", "=", "1e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages_test.GAETest.test_done": [[86, 125], ["absl.testing.parameterized.named_parameters", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "seed_rl.agents.policy_gradient.modules.advantages.gae", "tensorflow.convert_to_tensor", "advantages_test.GAETest.assertAllClose", "advantages_test.GAETest.assertAllClose", "tensorflow.convert_to_tensor", "tensorflow.zeros_like", "tensorflow.convert_to_tensor", "tensorflow.zeros_like"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.gae"], ["", "@", "parameterized", ".", "named_parameters", "(", "\n", "(", "'terminated'", ",", "True", ")", ",", "\n", "(", "'abandoned'", ",", "False", ")", ")", "\n", "def", "test_done", "(", "self", ",", "terminated", ")", ":", "\n", "    ", "\"\"\"Tests that done values are handled correctly.\n\n    Args:\n      terminated: Bool indicating if done_terminated should be set. Otherwise,\n        done_abandoned is set.\n    \"\"\"", "\n", "# We generate a case where there is a standard transition, a reset (either", "\n", "# due to termination or abandonment), and then another standard transition.", "\n", "values", "=", "tf", ".", "convert_to_tensor", "(", "[", "[", "1.", "]", ",", "[", "2.", "]", ",", "[", "3.", "]", ",", "[", "4.", "]", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "rewards", "=", "tf", ".", "convert_to_tensor", "(", "[", "[", ".1", "]", ",", "[", ".2", "]", ",", "[", ".3", "]", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "active_transition", "=", "[", "[", "False", "]", ",", "[", "True", "]", ",", "[", "False", "]", "]", "\n", "if", "terminated", ":", "\n", "      ", "done_terminated", "=", "tf", ".", "convert_to_tensor", "(", "active_transition", ",", "dtype", "=", "tf", ".", "bool", ")", "\n", "done_abandoned", "=", "tf", ".", "zeros_like", "(", "rewards", ",", "dtype", "=", "tf", ".", "bool", ")", "\n", "", "else", ":", "\n", "      ", "done_abandoned", "=", "tf", ".", "convert_to_tensor", "(", "active_transition", ",", "dtype", "=", "tf", ".", "bool", ")", "\n", "done_terminated", "=", "tf", ".", "zeros_like", "(", "rewards", ",", "dtype", "=", "tf", ".", "bool", ")", "\n", "\n", "# We compute the  results using the tested function.", "\n", "", "tested_targets", ",", "tested_advantages", "=", "advantages", ".", "gae", "(", "\n", "values", ",", "rewards", ",", "done_terminated", ",", "done_abandoned", ",", "discount_factor", "=", ".97", ",", "\n", "lambda_", "=", ".5", ")", "\n", "\n", "# We compute the real solution for this case by hand.", "\n", "delta1", "=", "rewards", "[", "0", "]", "[", "0", "]", "+", ".97", "*", "values", "[", "1", "]", "[", "0", "]", "-", "values", "[", "0", "]", "[", "0", "]", "\n", "delta2", "=", "(", "rewards", "[", "1", "]", "[", "0", "]", "-", "values", "[", "1", "]", "[", "0", "]", ")", "if", "terminated", "else", "0.", "\n", "delta3", "=", "rewards", "[", "2", "]", "[", "0", "]", "+", ".97", "*", "values", "[", "3", "]", "[", "0", "]", "-", "values", "[", "2", "]", "[", "0", "]", "\n", "\n", "real_advantages", "=", "[", "[", "delta1", "+", ".97", "*", ".5", "*", "delta2", "]", ",", "[", "delta2", "]", ",", "[", "delta3", "]", "]", "\n", "real_advantages", "=", "tf", ".", "convert_to_tensor", "(", "real_advantages", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "real_targets", "=", "real_advantages", "+", "values", "[", ":", "-", "1", "]", "\n", "\n", "self", ".", "assertAllClose", "(", "tested_targets", ",", "real_targets", ",", "rtol", "=", "1e-5", ",", "atol", "=", "1e-5", ")", "\n", "self", ".", "assertAllClose", "(", "tested_advantages", ",", "real_advantages", ",", "rtol", "=", "1e-5", ",", "\n", "atol", "=", "1e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages_test.VTraceTest.test_vtrace_vs_seed": [[129, 151], ["tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.cast", "tensorflow.zeros_like", "seed_rl.agents.policy_gradient.modules.advantages.vtrace", "seed_rl.common.vtrace.from_importance_weights", "advantages_test.VTraceTest.assertAllClose", "tensorflow_probability.distributions.Bernoulli().sample", "tensorflow.cast", "tensorflow_probability.distributions.Bernoulli"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.vtrace", "home.repos.pwc.inspect_result.google-research_seed_rl.common.vtrace.from_importance_weights", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], ["  ", "def", "test_vtrace_vs_seed", "(", "self", ")", ":", "\n", "    ", "values", "=", "tf", ".", "random", ".", "uniform", "(", "(", "21", ",", "10", ")", ",", "maxval", "=", "3", ")", "\n", "rewards", "=", "tf", ".", "random", ".", "uniform", "(", "(", "20", ",", "10", ")", ",", "maxval", "=", "3", ")", "\n", "target_action_log_probs", "=", "tf", ".", "random", ".", "uniform", "(", "(", "20", ",", "10", ")", ",", "minval", "=", "-", "2", ",", "maxval", "=", "2", ")", "\n", "behaviour_action_log_probs", "=", "tf", ".", "random", ".", "uniform", "(", "(", "20", ",", "10", ")", ",", "minval", "=", "-", "2", ",", "\n", "maxval", "=", "2", ")", "\n", "done_terminated", "=", "tf", ".", "cast", "(", "\n", "tfp", ".", "distributions", ".", "Bernoulli", "(", "0.05", ")", ".", "sample", "(", "(", "20", ",", "10", ")", ")", ",", "tf", ".", "bool", ")", "\n", "done_abandoned", "=", "tf", ".", "zeros_like", "(", "rewards", ",", "dtype", "=", "tf", ".", "bool", ")", "\n", "\n", "tested_targets", ",", "unused_tested_advantages", "=", "advantages", ".", "vtrace", "(", "\n", "values", ",", "rewards", ",", "\n", "done_terminated", ",", "done_abandoned", ",", "0.99", ",", "\n", "target_action_log_probs", ",", "behaviour_action_log_probs", ",", "\n", "lambda_", "=", "0.95", ")", "\n", "\n", "seed_output", "=", "vtrace", ".", "from_importance_weights", "(", "\n", "target_action_log_probs", ",", "behaviour_action_log_probs", ",", "\n", "0.99", "*", "tf", ".", "cast", "(", "~", "done_terminated", ",", "tf", ".", "float32", ")", ",", "rewards", ",", "\n", "values", "[", ":", "-", "1", "]", ",", "values", "[", "-", "1", "]", ",", "lambda_", "=", "0.95", ")", "\n", "\n", "self", ".", "assertAllClose", "(", "tested_targets", ",", "seed_output", ".", "vs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages_test.NStepTest.test_nstep_vs_gae": [[164, 188], ["tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.cast", "tensorflow.cast", "advantages_test.NStepTest.assertAllClose", "advantages_test.NStepTest.assertAllClose", "tensorflow_probability.distributions.Bernoulli().sample", "tensorflow_probability.distributions.Bernoulli().sample", "seed_rl.agents.policy_gradient.modules.advantages.NStep", "seed_rl.agents.policy_gradient.modules.advantages.GAE", "tensorflow_probability.distributions.Bernoulli", "tensorflow_probability.distributions.Bernoulli"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], ["  ", "def", "test_nstep_vs_gae", "(", "self", ")", ":", "\n", "# inf-step return should be the same as GAE with lambda=1.", "\n", "    ", "values", "=", "tf", ".", "random", ".", "uniform", "(", "(", "21", ",", "10", ")", ",", "maxval", "=", "3", ")", "\n", "rewards", "=", "tf", ".", "random", ".", "uniform", "(", "(", "20", ",", "10", ")", ",", "maxval", "=", "3", ")", "\n", "target_action_log_probs", "=", "tf", ".", "random", ".", "uniform", "(", "(", "20", ",", "10", ")", ",", "minval", "=", "-", "2", ",", "maxval", "=", "2", ")", "\n", "behaviour_action_log_probs", "=", "tf", ".", "random", ".", "uniform", "(", "(", "20", ",", "10", ")", ",", "minval", "=", "-", "2", ",", "\n", "maxval", "=", "2", ")", "\n", "done_terminated", "=", "tf", ".", "cast", "(", "\n", "tfp", ".", "distributions", ".", "Bernoulli", "(", "probs", "=", "0.2", ")", ".", "sample", "(", "(", "20", ",", "10", ")", ")", ",", "tf", ".", "bool", ")", "\n", "done_abandoned", "=", "tf", ".", "cast", "(", "\n", "tfp", ".", "distributions", ".", "Bernoulli", "(", "probs", "=", "0.2", ")", ".", "sample", "(", "(", "20", ",", "10", ")", ")", ",", "tf", ".", "bool", ")", "\n", "\n", "nstep_targets", ",", "nstep_advantages", "=", "advantages", ".", "NStep", "(", "n", "=", "10000", ")", "(", "\n", "values", ",", "rewards", ",", "\n", "done_terminated", ",", "done_abandoned", ",", "0.99", ",", "\n", "target_action_log_probs", ",", "behaviour_action_log_probs", ")", "\n", "\n", "gae_targets", ",", "gae_advantages", "=", "advantages", ".", "GAE", "(", "lambda_", "=", "1.", ")", "(", "\n", "values", ",", "rewards", ",", "\n", "done_terminated", ",", "done_abandoned", ",", "0.99", ",", "\n", "target_action_log_probs", ",", "behaviour_action_log_probs", ")", "\n", "\n", "self", ".", "assertAllClose", "(", "nstep_targets", ",", "gae_targets", ")", "\n", "self", ".", "assertAllClose", "(", "nstep_advantages", ",", "gae_advantages", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages_test.NStepTest.test_1step_returns": [[189, 214], ["tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.cast", "tensorflow.cast", "advantages_test.NStepTest.assertAllClose", "advantages_test.NStepTest.assertAllClose", "tensorflow_probability.distributions.Bernoulli().sample", "tensorflow_probability.distributions.Bernoulli().sample", "seed_rl.agents.policy_gradient.modules.advantages.NStep", "tensorflow.cast", "tensorflow_probability.distributions.Bernoulli", "tensorflow_probability.distributions.Bernoulli", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], ["", "def", "test_1step_returns", "(", "self", ")", ":", "\n", "    ", "values", "=", "tf", ".", "random", ".", "uniform", "(", "(", "201", ",", "10", ")", ",", "maxval", "=", "3", ")", "\n", "rewards", "=", "tf", ".", "random", ".", "uniform", "(", "(", "200", ",", "10", ")", ",", "maxval", "=", "3", ")", "\n", "target_action_log_probs", "=", "tf", ".", "random", ".", "uniform", "(", "(", "200", ",", "10", ")", ",", "minval", "=", "-", "2", ",", "maxval", "=", "2", ")", "\n", "behaviour_action_log_probs", "=", "tf", ".", "random", ".", "uniform", "(", "(", "200", ",", "10", ")", ",", "minval", "=", "-", "2", ",", "\n", "maxval", "=", "2", ")", "\n", "done_terminated", "=", "tf", ".", "cast", "(", "\n", "tfp", ".", "distributions", ".", "Bernoulli", "(", "probs", "=", "0.2", ")", ".", "sample", "(", "(", "200", ",", "10", ")", ")", ",", "tf", ".", "bool", ")", "\n", "done_abandoned", "=", "tf", ".", "cast", "(", "\n", "tfp", ".", "distributions", ".", "Bernoulli", "(", "probs", "=", "0.2", ")", ".", "sample", "(", "(", "200", ",", "10", ")", ")", ",", "tf", ".", "bool", ")", "\n", "\n", "nstep_targets", ",", "nstep_advantages", "=", "advantages", ".", "NStep", "(", "n", "=", "1", ")", "(", "\n", "values", ",", "rewards", ",", "\n", "done_terminated", ",", "done_abandoned", ",", "0.99", ",", "\n", "target_action_log_probs", ",", "behaviour_action_log_probs", ")", "\n", "\n", "correct_targets", "=", "rewards", "+", "0.99", "*", "tf", ".", "cast", "(", "\n", "~", "done_terminated", ",", "tf", ".", "float32", ")", "*", "values", "[", "1", ":", "]", "\n", "correct_targets", "+=", "tf", ".", "cast", "(", "done_abandoned", ",", "tf", ".", "float32", ")", "*", "(", "\n", "values", "[", ":", "-", "1", "]", "-", "correct_targets", ")", "\n", "correct_advantages", "=", "correct_targets", "-", "values", "[", ":", "-", "1", "]", "\n", "\n", "self", ".", "assertAllClose", "(", "nstep_targets", ",", "correct_targets", ",", "rtol", "=", "3e-5", ",", "atol", "=", "3e-5", ")", "\n", "self", ".", "assertAllClose", "(", "nstep_advantages", ",", "correct_advantages", ",", "\n", "rtol", "=", "3e-5", ",", "atol", "=", "3e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages_test.NStepTest.test_nstep_terminated": [[215, 248], ["tensorflow.cast", "tensorflow.zeros_like", "tensorflow.zeros_like", "tensorflow.reshape", "tensorflow.zeros_like", "tensorflow.reshape", "advantages_test.NStepTest.assertAllClose", "advantages_test.NStepTest.assertAllClose", "tensorflow.reshape", "tensorflow.cast", "seed_rl.agents.policy_gradient.modules.advantages.NStep", "tensorflow.range"], "methods", ["None"], ["", "def", "test_nstep_terminated", "(", "self", ")", ":", "\n", "    ", "values", "=", "tf", ".", "cast", "(", "tf", ".", "reshape", "(", "1", "+", "tf", ".", "range", "(", "11", ")", ",", "(", "11", ",", "1", ")", ")", ",", "tf", ".", "float32", ")", "\n", "rewards", "=", "values", "[", ":", "-", "1", "]", "*", "0.1", "\n", "target_action_log_probs", "=", "tf", ".", "zeros_like", "(", "rewards", ")", "\n", "behaviour_action_log_probs", "=", "tf", ".", "zeros_like", "(", "rewards", ")", "\n", "done_terminated", "=", "[", "0", ",", "1", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "1", "]", "\n", "done_terminated", "=", "tf", ".", "reshape", "(", "tf", ".", "cast", "(", "done_terminated", ",", "tf", ".", "bool", ")", ",", "(", "10", ",", "1", ")", ")", "\n", "done_abandoned", "=", "tf", ".", "zeros_like", "(", "done_terminated", ")", "\n", "\n", "nstep_targets", ",", "nstep_advantages", "=", "advantages", ".", "NStep", "(", "n", "=", "3", ")", "(", "\n", "values", ",", "rewards", ",", "\n", "done_terminated", ",", "done_abandoned", ",", "0.99", ",", "\n", "target_action_log_probs", ",", "behaviour_action_log_probs", ")", "\n", "d", "=", "0.99", "\n", "d2", "=", "d", "*", "d", "\n", "d3", "=", "d", "*", "d", "*", "d", "\n", "\n", "correct_targets", "=", "[", "0.1", "+", "d", "*", "0.2", ",", "\n", "0.2", ",", "\n", "0.3", "+", "d", "*", "0.4", ",", "\n", "0.4", ",", "\n", "0.5", "+", "d", "*", "0.6", "+", "d2", "*", "0.7", "+", "d3", "*", "8.", ",", "\n", "0.6", "+", "d", "*", "0.7", "+", "d2", "*", "0.8", "+", "d3", "*", "9.", ",", "\n", "0.7", "+", "d", "*", "0.8", "+", "d2", "*", "0.9", ",", "\n", "0.8", "+", "d", "*", "0.9", ",", "\n", "0.9", ",", "\n", "1.", "]", "\n", "correct_targets", "=", "tf", ".", "reshape", "(", "correct_targets", ",", "(", "10", ",", "1", ")", ")", "\n", "correct_advantages", "=", "correct_targets", "-", "values", "[", ":", "-", "1", "]", "\n", "\n", "self", ".", "assertAllClose", "(", "nstep_targets", ",", "correct_targets", ",", "rtol", "=", "3e-5", ",", "atol", "=", "3e-5", ")", "\n", "self", ".", "assertAllClose", "(", "nstep_advantages", ",", "correct_advantages", ",", "\n", "rtol", "=", "3e-5", ",", "atol", "=", "3e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages_test.NStepTest.test_nstep_abandoned": [[249, 282], ["tensorflow.cast", "tensorflow.zeros_like", "tensorflow.zeros_like", "tensorflow.reshape", "tensorflow.zeros_like", "tensorflow.reshape", "advantages_test.NStepTest.assertAllClose", "advantages_test.NStepTest.assertAllClose", "tensorflow.reshape", "tensorflow.cast", "seed_rl.agents.policy_gradient.modules.advantages.NStep", "tensorflow.range"], "methods", ["None"], ["", "def", "test_nstep_abandoned", "(", "self", ")", ":", "\n", "    ", "values", "=", "tf", ".", "cast", "(", "tf", ".", "reshape", "(", "1", "+", "tf", ".", "range", "(", "11", ")", ",", "(", "11", ",", "1", ")", ")", ",", "tf", ".", "float32", ")", "\n", "rewards", "=", "values", "[", ":", "-", "1", "]", "*", "0.1", "\n", "target_action_log_probs", "=", "tf", ".", "zeros_like", "(", "rewards", ")", "\n", "behaviour_action_log_probs", "=", "tf", ".", "zeros_like", "(", "rewards", ")", "\n", "done_abandoned", "=", "[", "0", ",", "1", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "1", "]", "\n", "done_abandoned", "=", "tf", ".", "reshape", "(", "tf", ".", "cast", "(", "done_abandoned", ",", "tf", ".", "bool", ")", ",", "(", "10", ",", "1", ")", ")", "\n", "done_terminated", "=", "tf", ".", "zeros_like", "(", "done_abandoned", ")", "\n", "\n", "nstep_targets", ",", "nstep_advantages", "=", "advantages", ".", "NStep", "(", "n", "=", "3", ")", "(", "\n", "values", ",", "rewards", ",", "\n", "done_terminated", ",", "done_abandoned", ",", "0.99", ",", "\n", "target_action_log_probs", ",", "behaviour_action_log_probs", ")", "\n", "d", "=", "0.99", "\n", "d2", "=", "d", "*", "d", "\n", "d3", "=", "d", "*", "d", "*", "d", "\n", "\n", "correct_targets", "=", "[", "0.1", "+", "d", "*", "2", ",", "\n", "2.", ",", "\n", "0.3", "+", "d", "*", "4", ",", "\n", "4.", ",", "\n", "0.5", "+", "d", "*", "0.6", "+", "d2", "*", "0.7", "+", "d3", "*", "8.", ",", "\n", "0.6", "+", "d", "*", "0.7", "+", "d2", "*", "0.8", "+", "d3", "*", "9.", ",", "\n", "0.7", "+", "d", "*", "0.8", "+", "d2", "*", "9.", ",", "\n", "0.8", "+", "d", "*", "9.", ",", "\n", "9.", ",", "\n", "10.", "]", "\n", "correct_targets", "=", "tf", ".", "reshape", "(", "correct_targets", ",", "(", "10", ",", "1", ")", ")", "\n", "correct_advantages", "=", "correct_targets", "-", "values", "[", ":", "-", "1", "]", "\n", "\n", "self", ".", "assertAllClose", "(", "nstep_targets", ",", "correct_targets", ",", "rtol", "=", "3e-5", ",", "atol", "=", "3e-5", ")", "\n", "self", ".", "assertAllClose", "(", "nstep_advantages", ",", "correct_advantages", ",", "\n", "rtol", "=", "3e-5", ",", "atol", "=", "3e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.AdvantageEstimator.__call__": [[135, 169], ["NotImplementedError"], "methods", ["None"], ["@", "abc", ".", "abstractmethod", "\n", "def", "__call__", "(", "self", ",", "values", ",", "rewards", ",", "done_terminated", ",", "done_abandoned", ",", "\n", "discount_factor", ",", "target_action_log_probs", ",", "\n", "behaviour_action_log_probs", ")", ":", "\n", "    ", "r\"\"\"Computes advantages and value function targets.\n\n    Args:\n      values: A float32 tensor of shape [T+1, B] with the value function\n        estimates wrt. the target policy, i.e., for the time steps, i, i+1,\n        ..., i+T.\n      rewards: A float32 tensor of shape [T, B] containing rewards generated by\n        following the behaviour policy after time steps i, i+1, ..., i+T-1.\n      done_terminated: A boolean tensor of shape [T, B] signifying if the agent\n        terminated after the actions in steps i, i+1, ..., i+T-1. This is\n        equivalent to going into a terminal state with infinite rewards of 0.\n      done_abandoned: A boolean tensor of shape [T, B] signifying if the agent\n        did not further act after the actions in steps i, i+1, ..., i+T-1. This\n        is not the same as termination and can be used if the maximum episode\n        length is reached. This will set the advantage of that state to zero and\n        the target value to the input value (which generally results in a zero\n        gradient).\n      discount_factor: Float with the discount factor to be used.\n      target_action_log_probs: A float32 tensor of shape [T, B] with\n        log-probabilities of taking the action by the current policy\n      behaviour_action_log_probs: A float32 tensor of shape [T, B] with\n        log-probabilities of taking the action by the behavioural policy\n\n\n    Returns:\n      A float32 tensor of shape [T, B] with value targets that can be used to\n        train a baseline (V(x_t) - vs_t)^2.\n      A float32 tensor of shape [T, B] of advantages.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", "'`__call__()` is not implemented!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.GAE.__init__": [[174, 177], ["tensorflow.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["  ", "def", "__init__", "(", "self", ",", "lambda_", ",", "name", "=", "'gam'", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lambda_", "=", "lambda_", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.GAE.__call__": [[178, 180], ["advantages.gae"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.gae"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "gae", "(", "*", "args", ",", "**", "kwargs", ",", "lambda_", "=", "self", ".", "lambda_", ",", "name", "=", "self", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.VTrace.__init__": [[185, 189], ["tensorflow.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["  ", "def", "__init__", "(", "self", ",", "lambda_", ",", "max_importance_weight", "=", "1.", ",", "name", "=", "'vtrace'", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "name", ")", "\n", "self", ".", "lambda_", "=", "lambda_", "\n", "self", ".", "max_importance_weight", "=", "max_importance_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.VTrace.__call__": [[190, 194], ["advantages.vtrace"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.vtrace"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "vtrace", "(", "*", "args", ",", "**", "kwargs", ",", "\n", "max_importance_weight", "=", "self", ".", "max_importance_weight", ",", "\n", "lambda_", "=", "self", ".", "lambda_", ",", "name", "=", "self", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.NStep.__init__": [[200, 203], ["tensorflow.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "n", ",", "name", "=", "'nstep2'", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "name", ")", "\n", "self", ".", "n", "=", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.NStep.__call__": [[204, 263], ["tensorflow.name_scope", "int", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.ones", "tensorflow.zeros", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "range", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.stop_gradient", "tensorflow.stop_gradient"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "values", ",", "rewards", ",", "done_terminated", ",", "done_abandoned", ",", "\n", "discount_factor", ",", "target_action_log_probs", ",", "\n", "behaviour_action_log_probs", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "self", ".", "name", ")", ":", "\n", "# We compute the n-step returns in min(n, unroll_length) steps.", "\n", "      ", "unroll_length", "=", "int", "(", "rewards", ".", "shape", "[", "0", "]", ")", "\n", "eff_n", "=", "self", ".", "n", "if", "self", ".", "n", "<", "unroll_length", "else", "unroll_length", "\n", "\n", "# We pad the dimension with n-1 additional values with abandon=True so", "\n", "# that we don't have to handle the last n-1 steps differently.", "\n", "values_pad", "=", "tf", ".", "zeros", "(", "(", "eff_n", "-", "1", ",", "values", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "done_terminated_pad", "=", "tf", ".", "zeros", "(", "(", "eff_n", "-", "1", ",", "values", ".", "shape", "[", "1", "]", ")", ",", "\n", "dtype", "=", "tf", ".", "bool", ")", "\n", "done_abandoned_pad", "=", "tf", ".", "ones", "(", "(", "eff_n", "-", "1", ",", "values", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "tf", ".", "bool", ")", "\n", "rewards_pad", "=", "tf", ".", "zeros", "(", "(", "eff_n", "-", "1", ",", "values", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "nvalues", "=", "tf", ".", "concat", "(", "[", "values", ",", "values_pad", "]", ",", "axis", "=", "0", ")", "\n", "ndone_terminated", "=", "tf", ".", "concat", "(", "[", "done_terminated", ",", "done_terminated_pad", "]", ",", "\n", "axis", "=", "0", ")", "\n", "ndone_abandoned", "=", "tf", ".", "concat", "(", "[", "done_abandoned", ",", "done_abandoned_pad", "]", ",", "axis", "=", "0", ")", "\n", "nrewards", "=", "tf", ".", "concat", "(", "[", "rewards", ",", "rewards_pad", "]", ",", "axis", "=", "0", ")", "\n", "\n", "future_value", "=", "nvalues", "[", "eff_n", ":", "]", "\n", "\n", "window_size", "=", "rewards", ".", "shape", "[", "0", "]", "\n", "\n", "for", "i", "in", "range", "(", "eff_n", ")", ":", "\n", "# Extract relevant sub tensors.", "\n", "        ", "start", "=", "eff_n", "-", "i", "-", "1", "\n", "end", "=", "start", "+", "window_size", "\n", "rel_n_values", "=", "nvalues", "[", "start", ":", "end", "]", "\n", "rel_rewards", "=", "nrewards", "[", "start", ":", "end", "]", "\n", "rel_done_terminated", "=", "ndone_terminated", "[", "start", ":", "end", "]", "\n", "rel_done_abandoned", "=", "ndone_abandoned", "[", "start", ":", "end", "]", "\n", "\n", "# We compute the targets with special handling of episodes", "\n", "# which ended. We consider two cases:", "\n", "# - Termination: In this case, the agent took a decision that led to", "\n", "#     proper termination of the episode. In this case, the future value", "\n", "#     of the policy is enforced to be zero. This is done by setting the", "\n", "#     next step bootstrapping value to zero and not to the next value", "\n", "#     function (which is the value of the state after the reset).", "\n", "not_terminated_mask", "=", "tf", ".", "cast", "(", "~", "rel_done_terminated", ",", "tf", ".", "float32", ")", "\n", "next_step_bootstrap", "=", "not_terminated_mask", "*", "future_value", "\n", "\n", "# - Abandonment: The current episode was abandoned, e.g., due to a", "\n", "#     maximum episode length (or padding). If the policy would have", "\n", "#     continued, it would have continued to obtain rewards. We handle", "\n", "#     this by setting the value to the current value.", "\n", "not_abandoned_mask", "=", "tf", ".", "cast", "(", "~", "rel_done_abandoned", ",", "tf", ".", "float32", ")", "\n", "abandoned_mask", "=", "tf", ".", "cast", "(", "rel_done_abandoned", ",", "tf", ".", "float32", ")", "\n", "\n", "one_step_bootstrap", "=", "rel_rewards", "+", "discount_factor", "*", "next_step_bootstrap", "\n", "\n", "future_value", "=", "(", "not_abandoned_mask", "*", "one_step_bootstrap", "+", "\n", "abandoned_mask", "*", "rel_n_values", ")", "\n", "\n", "", "advantages", "=", "future_value", "-", "values", "[", ":", "-", "1", "]", "\n", "return", "tf", ".", "stop_gradient", "(", "future_value", ")", ",", "tf", ".", "stop_gradient", "(", "advantages", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.vtrace": [[28, 109], ["tensorflow.name_scope", "tensorflow.minimum", "tensorflow.exp", "tensorflow.cast", "tensorflow.cast", "tensorflow.zeros_like", "range", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.math.log", "tf.convert_to_tensor.append", "tf.convert_to_tensor.append", "tensorflow.stop_gradient", "tensorflow.stop_gradient", "int"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append"], ["def", "vtrace", "(", "values", ",", "rewards", ",", "done_terminated", ",", "done_abandoned", ",", "discount_factor", ",", "\n", "target_action_log_probs", ",", "behaviour_action_log_probs", ",", "lambda_", "=", "1.0", ",", "\n", "max_importance_weight", "=", "1.", ",", "name", "=", "'vtrace'", ")", ":", "\n", "  ", "r\"\"\"Calculates V-trace value targets and advantages.\n\n  Args:\n    values: A float32 tensor of shape [T+1, B] with the value function estimates\n      wrt. the target policy, i.e., for the time steps, i, i+1, ..., i+T.\n    rewards: A float32 tensor of shape [T, B] containing rewards generated by\n      following the behaviour policy after time steps i, i+1, ..., i+T-1.\n    done_terminated: A boolean tensor of shape [T, B] signifying if the agent\n      terminated after the actions in steps i, i+1, ..., i+T-1. This is\n      equivalent to going into a terminal state with infinite rewards of 0.\n    done_abandoned: A boolean tensor of shape [T, B] signifying if the agent did\n      not further act after the actions in steps i, i+1, ..., i+T-1. This is not\n      the same as termination and can be used if the maximum episode length is\n      reached. This will set the advantage of that state to zero and the target\n      value to the input value (which generally results in a zero gradient).\n    discount_factor: Float with the discount factor to be used.\n    target_action_log_probs: A float32 tensor of shape [T, B] with\n      log-probabilities of taking the action by the current policy.\n    behaviour_action_log_probs: A float32 tensor of shape [T, B] with\n      log-probabilities of taking the action by the behavioural policy.\n    lambda_: Float that determines the mix between 1-step (lambda_=0) and n-step\n      (lambda_=1) bootstrapping\n    max_importance_weight: Bigger importance weights are clipped.\n    name: String with the name scope that all operations will be created in.\n\n  Returns:\n    A float32 tensor of shape [T, B] with value targets that can be used to\n      train a baseline (V(x_t) - vs_t)^2.\n    A float32 tensor of shape [T, B] of advantages.\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "name", ")", ":", "\n", "# Compute importance sampling weights.", "\n", "    ", "log_rhos", "=", "target_action_log_probs", "-", "behaviour_action_log_probs", "\n", "log_rhos", "=", "tf", ".", "minimum", "(", "log_rhos", ",", "tf", ".", "math", ".", "log", "(", "max_importance_weight", ")", ")", "\n", "rhos", "=", "tf", ".", "exp", "(", "log_rhos", ")", "\n", "\n", "# We compute the temporal differences with special handling of episodes", "\n", "# which ended. We consider two cases:", "\n", "# - Termination: In this case, the agent took a decision that led to proper", "\n", "#     termination of the episode. In this case, the future value of the", "\n", "#     policy is enforced to be zero. This is done by setting the next step", "\n", "#     bootstrapping value to zero and not to the next value function (which", "\n", "#     is the value of the state after the reset).", "\n", "not_terminated_mask", "=", "tf", ".", "cast", "(", "~", "done_terminated", ",", "tf", ".", "float32", ")", "\n", "next_step_bootstrap", "=", "not_terminated_mask", "*", "values", "[", "1", ":", "]", "\n", "\n", "# - Abandonment: The current episode was abandoned, e.g., due to a maximum", "\n", "#     epsiode length. If the policy would have continued, it would have", "\n", "#     continued to obtain rewards. We handle this by setting the temporal", "\n", "#     difference and thus the advantage to zero.", "\n", "not_abandoned_mask", "=", "tf", ".", "cast", "(", "~", "done_abandoned", ",", "tf", ".", "float32", ")", "\n", "deltas", "=", "rewards", "+", "discount_factor", "*", "next_step_bootstrap", "-", "values", "[", ":", "-", "1", "]", "\n", "deltas", "*=", "not_abandoned_mask", "\n", "\n", "# For both cases, we do not propagate future temporal differences as they", "\n", "# relate to different episodes.", "\n", "propagate_future", "=", "not_terminated_mask", "*", "not_abandoned_mask", "\n", "\n", "# We accumulate temporal differences by iterating backwards in time and", "\n", "# computing advantages as we go using dynamic programming.", "\n", "accumulator", "=", "tf", ".", "zeros_like", "(", "values", "[", "0", "]", ")", "\n", "targets", "=", "[", "]", "\n", "advantages", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "int", "(", "rewards", ".", "shape", "[", "0", "]", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "      ", "future", "=", "propagate_future", "[", "i", "]", "*", "discount_factor", "*", "lambda_", "*", "accumulator", "\n", "# For advantages we don't use importance weights because this is", "\n", "# the advantage exactly for the action which was taken.", "\n", "advantages", ".", "append", "(", "deltas", "[", "i", "]", "+", "future", ")", "\n", "# On the other hand, the accumulator corresponds to the value for the", "\n", "# current state so both terms are multiplied by rho.", "\n", "accumulator", "=", "rhos", "[", "i", "]", "*", "(", "deltas", "[", "i", "]", "+", "future", ")", "\n", "targets", ".", "append", "(", "values", "[", "i", "]", "+", "accumulator", ")", "\n", "\n", "# We need to return targets and values with stopped gradients, as we do not", "\n", "# want to differentiate through the generalized advantage estimator.", "\n", "", "targets", "=", "tf", ".", "convert_to_tensor", "(", "targets", "[", ":", ":", "-", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "advantages", "=", "tf", ".", "convert_to_tensor", "(", "advantages", "[", ":", ":", "-", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "return", "tf", ".", "stop_gradient", "(", "targets", ")", ",", "tf", ".", "stop_gradient", "(", "advantages", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.gae": [[113, 130], ["advantages.vtrace", "tensorflow.zeros_like", "tensorflow.zeros_like"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.advantages.vtrace"], ["", "", "def", "gae", "(", "values", ",", "rewards", ",", "done_terminated", ",", "done_abandoned", ",", "discount_factor", ",", "\n", "target_action_log_probs", "=", "None", ",", "behaviour_action_log_probs", "=", "None", ",", "\n", "lambda_", "=", "1.0", ",", "name", "=", "'gae'", ")", ":", "\n", "  ", "\"\"\"Generalized Advantages Estimator.\n\n  Args:\n    See V-trace above.\n\n  Returns:\n    A float32 tensor of shape [T, B] with value targets that can be used to\n      train a baseline (V(x_t) - vs_t)^2.\n    A float32 tensor of shape [T, B] of advantages.\n  \"\"\"", "\n", "return", "vtrace", "(", "values", ",", "rewards", ",", "done_terminated", ",", "done_abandoned", ",", "\n", "discount_factor", ",", "\n", "tf", ".", "zeros_like", "(", "rewards", ")", ",", "tf", ".", "zeros_like", "(", "rewards", ")", ",", "\n", "lambda_", ",", "1.", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.init": [[26, 34], ["NotImplementedError"], "methods", ["None"], ["@", "abc", ".", "abstractmethod", "\n", "def", "init", "(", "self", ",", "size", ")", ":", "\n", "    ", "\"\"\"Initializes normalization variables.\n\n    Args:\n      size: Integer with the dimensionality of the tracked tensor.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", "'`init` is not implemented.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.normalize": [[35, 46], ["running_statistics.MeanStd.get_mean_std"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.get_mean_std"], ["", "def", "normalize", "(", "self", ",", "x", ")", ":", "\n", "    ", "\"\"\"Normalizes target values x using past target statistics.\n\n    Args:\n      x: <float32>[(...), size] tensor.\n\n    Returns:\n      <float32>[(...), size] normalized tensor.\n    \"\"\"", "\n", "mean", ",", "std", "=", "self", ".", "get_mean_std", "(", ")", "\n", "return", "(", "x", "-", "mean", ")", "/", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.unnormalize": [[47, 58], ["running_statistics.MeanStd.get_mean_std"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.get_mean_std"], ["", "def", "unnormalize", "(", "self", ",", "x", ")", ":", "\n", "    ", "\"\"\"Unnormalizes a corrected prediction x using past target statistics.\n\n    Args:\n      x: <float32>[(...), size] tensor.\n\n    Returns:\n      <float32>[(...), size] unnormalized tensor.\n    \"\"\"", "\n", "mean", ",", "std", "=", "self", ".", "get_mean_std", "(", ")", "\n", "return", "std", "*", "x", "+", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.update": [[59, 67], ["NotImplementedError"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "update", "(", "self", ",", "data", ")", ":", "\n", "    ", "\"\"\"Updates normalization statistics.\n\n    Args:\n      data: <float32>[(...), size].\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", "'`update` is not implemented.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.MeanStd.get_mean_std": [[68, 72], ["NotImplementedError"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "get_mean_std", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns mean and standard deviation for current statistics.\"\"\"", "\n", "raise", "NotImplementedError", "(", "'`get_mean_std` is not implemented.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.EMAMeanStd.__init__": [[86, 101], ["tensorflow.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "beta", "=", "1e-2", ",", "std_min_value", "=", "1e-6", ",", "std_max_value", "=", "1e6", ")", ":", "\n", "    ", "\"\"\"Creates a EMAMeanVariance.\n\n    Args:\n      beta: Float that determines how fast parameters are updated via the\n        formula `new_parameters = (1-beta)* old_parameters + beta*batch_mean`.\n      std_min_value: Float with the minimum value for the standard deviation.\n      std_max_value: Float with the maximum value for the standard deviation.\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_beta", "=", "beta", "\n", "self", ".", "_std_min_value", "=", "std_min_value", "\n", "self", ".", "_std_max_value", "=", "std_max_value", "\n", "self", ".", "first_moment", "=", "None", "\n", "self", ".", "second_moment", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.EMAMeanStd.init": [[102, 122], ["tensorflow.Variable", "tensorflow.Variable", "tensorflow.zeros", "tensorflow.ones"], "methods", ["None"], ["", "def", "init", "(", "self", ",", "size", ")", ":", "\n", "    ", "\"\"\"Initializes normalization variables.\n\n    Args:\n      size: Integer with the dimensionality of the tracked tensor.\n    \"\"\"", "\n", "self", ".", "first_moment", "=", "tf", ".", "Variable", "(", "\n", "name", "=", "'first_moment'", ",", "\n", "shape", "=", "[", "size", "]", ",", "\n", "trainable", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initial_value", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "size", "]", ")", ",", "\n", "aggregation", "=", "tf", ".", "VariableAggregation", ".", "MEAN", ")", "\n", "self", ".", "second_moment", "=", "tf", ".", "Variable", "(", "\n", "name", "=", "'second_moment'", ",", "\n", "shape", "=", "[", "size", "]", ",", "\n", "trainable", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initial_value", "=", "tf", ".", "ones", "(", "shape", "=", "[", "size", "]", ")", ",", "\n", "aggregation", "=", "tf", ".", "VariableAggregation", ".", "MEAN", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.EMAMeanStd.update": [[123, 148], ["tensorflow.reduce_mean", "tensorflow.reduce_mean", "running_statistics.EMAMeanStd.first_moment.assign_add", "running_statistics.EMAMeanStd.second_moment.assign_add", "list", "range"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "data", ")", ":", "\n", "    ", "\"\"\"Updates normalization statistics.\n\n    Args:\n      data: <float32>[(...), size].\n    \"\"\"", "\n", "# Reduce tensors along all the dimensions except the last ones.", "\n", "reduce_dims", "=", "list", "(", "range", "(", "data", ".", "shape", ".", "rank", ")", ")", "[", ":", "-", "1", "]", "\n", "batch_first_moment", "=", "tf", ".", "reduce_mean", "(", "data", ",", "reduce_dims", ")", "\n", "batch_second_moment", "=", "tf", ".", "reduce_mean", "(", "data", "**", "2", ",", "reduce_dims", ")", "\n", "\n", "# Updates the tracked moments. We do this by computing the difference to the", "\n", "# the current value as that allows us to use mean aggregation to make it", "\n", "# work with replicated tensors (e.g., when using multiple TPU cores), i.e.,", "\n", "#     new_moment = old_moment + beta*mean(data - old_moment)", "\n", "# where the mean is a mean across different replica and within the", "\n", "# mini-batches of each replica.", "\n", "first_moment_diff", "=", "self", ".", "_beta", "*", "(", "batch_first_moment", "-", "self", ".", "first_moment", ")", "\n", "second_moment_diff", "=", "self", ".", "_beta", "*", "(", "batch_second_moment", "-", "self", ".", "second_moment", ")", "\n", "\n", "# The following two assign_adds will average their arguments across", "\n", "# different replicas as the underlying variables have", "\n", "# `aggregation=tf.VariableAggregation.MEAN` set.", "\n", "self", ".", "first_moment", ".", "assign_add", "(", "first_moment_diff", ")", "\n", "self", ".", "second_moment", ".", "assign_add", "(", "second_moment_diff", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.EMAMeanStd.get_mean_std": [[149, 157], ["tensorflow.sqrt", "tensorflow.clip_by_value"], "methods", ["None"], ["", "def", "get_mean_std", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns mean and standard deviation for current statistics.\"\"\"", "\n", "std", "=", "tf", ".", "sqrt", "(", "self", ".", "second_moment", "-", "self", ".", "first_moment", "**", "2", ")", "\n", "std", "=", "tf", ".", "clip_by_value", "(", "std", ",", "self", ".", "_std_min_value", ",", "self", ".", "_std_max_value", ")", "\n", "# Multiplication with one converts the variable to a tensor with the value", "\n", "# at the time this function is called. This is important if the python", "\n", "# reference is passed around and the variables are changed in the meantime.", "\n", "return", "self", ".", "first_moment", "*", "1.", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.AverageMeanStd.__init__": [[204, 218], ["tensorflow.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "std_min_value", "=", "1e-6", ",", "std_max_value", "=", "1e6", ")", ":", "\n", "    ", "\"\"\"Creates a AverageMeanStd.\n\n    Args:\n      std_min_value: Float with the minimum value for the standard deviation.\n      std_max_value: Float with the maximum value for the standard deviation.\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_std_min_value", "=", "std_min_value", "\n", "self", ".", "_std_max_value", "=", "std_max_value", "\n", "self", ".", "observation_count", "=", "None", "\n", "self", ".", "update_count", "=", "None", "\n", "self", ".", "mean", "=", "None", "\n", "self", ".", "summed_variance", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.AverageMeanStd.init": [[219, 253], ["tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros"], "methods", ["None"], ["", "def", "init", "(", "self", ",", "size", ")", ":", "\n", "    ", "\"\"\"Initializes normalization variables.\n\n    Args:\n      size: Integer with the dimensionality of the tracked tensor.\n    \"\"\"", "\n", "self", ".", "observation_count", "=", "tf", ".", "Variable", "(", "\n", "name", "=", "'observation_count'", ",", "\n", "shape", "=", "[", "size", "]", ",", "\n", "trainable", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initial_value", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "size", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "aggregation", "=", "tf", ".", "VariableAggregation", ".", "SUM", ")", "\n", "self", ".", "update_count", "=", "tf", ".", "Variable", "(", "\n", "name", "=", "'update_count'", ",", "\n", "shape", "=", "[", "]", ",", "\n", "trainable", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "int32", ",", "\n", "initial_value", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "aggregation", "=", "tf", ".", "VariableAggregation", ".", "ONLY_FIRST_REPLICA", ")", "\n", "self", ".", "mean", "=", "tf", ".", "Variable", "(", "\n", "name", "=", "'mean'", ",", "\n", "shape", "=", "[", "size", "]", ",", "\n", "trainable", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initial_value", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "size", "]", ")", ",", "\n", "aggregation", "=", "tf", ".", "VariableAggregation", ".", "SUM", ")", "\n", "self", ".", "summed_variance", "=", "tf", ".", "Variable", "(", "\n", "name", "=", "'summed_variance'", ",", "\n", "shape", "=", "[", "size", "]", ",", "\n", "trainable", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "initial_value", "=", "tf", ".", "zeros", "(", "shape", "=", "[", "size", "]", ")", ",", "\n", "aggregation", "=", "tf", ".", "VariableAggregation", ".", "SUM", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.AverageMeanStd.merge": [[254, 280], ["tensorflow.distribute.get_replica_context", "tensorflow.constant", "running_statistics.merge_means", "running_statistics.merge_summed_variances", "running_statistics.AverageMeanStd.mean.assign", "running_statistics.AverageMeanStd.observation_count.assign_add", "running_statistics.AverageMeanStd.summed_variance.assign", "running_statistics.AverageMeanStd.update_count.assign_add"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.merge_means", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.merge_summed_variances"], ["", "def", "merge", "(", "self", ",", "other", ",", "alpha", "=", "1.", ")", ":", "\n", "    ", "\"\"\"Merges with the stats from another AverageMeanStd, in-place.\n\n    Args:\n      other: An AverageMeanStd to merge into self.\n      alpha: Performs a reset when alpha=1, no-op when alpha=0. We need this to\n        work-around tensorflow limitations regarding mixing synchronization\n        points and conditions.\n    \"\"\"", "\n", "ctx", "=", "tf", ".", "distribute", ".", "get_replica_context", "(", ")", "\n", "num_replicas", "=", "tf", ".", "constant", "(", "ctx", ".", "num_replicas_in_sync", ",", "tf", ".", "float32", ")", "\n", "new_mean", "=", "merge_means", "(", "self", ".", "mean", ",", "other", ".", "mean", ",", "self", ".", "observation_count", ",", "\n", "other", ".", "observation_count", ")", "\n", "new_summed_variance", "=", "merge_summed_variances", "(", "\n", "self", ".", "summed_variance", ",", "other", ".", "summed_variance", ",", "self", ".", "mean", ",", "other", ".", "mean", ",", "\n", "new_mean", ",", "self", ".", "observation_count", ",", "other", ".", "observation_count", ")", "\n", "# We need to divide by the number of replicas since those variables are", "\n", "# aggregated with cross-replica sums.", "\n", "self", ".", "mean", ".", "assign", "(", "\n", "(", "alpha", "*", "new_mean", "+", "(", "1.", "-", "alpha", ")", "*", "self", ".", "mean", ")", "/", "num_replicas", ")", "\n", "self", ".", "observation_count", ".", "assign_add", "(", "alpha", "*", "other", ".", "observation_count", "/", "\n", "num_replicas", ")", "\n", "self", ".", "summed_variance", ".", "assign", "(", "\n", "(", "alpha", "*", "new_summed_variance", "+", "\n", "(", "1.", "-", "alpha", ")", "*", "self", ".", "summed_variance", ")", "/", "num_replicas", ")", "\n", "self", ".", "update_count", ".", "assign_add", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.AverageMeanStd.reset": [[281, 302], ["tensorflow.distribute.get_replica_context", "tensorflow.constant", "running_statistics.AverageMeanStd.mean.assign", "running_statistics.AverageMeanStd.observation_count.assign", "running_statistics.AverageMeanStd.summed_variance.assign", "running_statistics.AverageMeanStd.update_count.assign", "tensorflow.cast", "tensorflow.cast"], "methods", ["None"], ["", "def", "reset", "(", "self", ",", "alpha", "=", "1.", ")", ":", "\n", "    ", "\"\"\"Resets the aggregator.\n\n    Args:\n      alpha: Performs a reset when alpha=1, no-op when alpha=0. We need this to\n        work-around tensorflow limitations regarding mixing synchronization\n        points and conditions.\n    \"\"\"", "\n", "ctx", "=", "tf", ".", "distribute", ".", "get_replica_context", "(", ")", "\n", "num_replicas", "=", "tf", ".", "constant", "(", "ctx", ".", "num_replicas_in_sync", ",", "tf", ".", "float32", ")", "\n", "# We need to divide by the number of replicas since those variables are", "\n", "# aggregated with cross-replica sums.", "\n", "self", ".", "mean", ".", "assign", "(", "(", "1.", "-", "alpha", ")", "*", "self", ".", "mean", "/", "num_replicas", ")", "\n", "self", ".", "observation_count", ".", "assign", "(", "\n", "(", "1.", "-", "alpha", ")", "*", "self", ".", "observation_count", "/", "num_replicas", ")", "\n", "self", ".", "summed_variance", ".", "assign", "(", "\n", "(", "1.", "-", "alpha", ")", "*", "self", ".", "summed_variance", "/", "num_replicas", ")", "\n", "# Remember, ONLY_FIRST_REPLICA aggregation.", "\n", "self", ".", "update_count", ".", "assign", "(", "\n", "tf", ".", "cast", "(", "(", "1.", "-", "alpha", ")", "*", "tf", ".", "cast", "(", "self", ".", "update_count", ",", "tf", ".", "float32", ")", ",", "\n", "tf", ".", "int32", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.AverageMeanStd.update": [[303, 329], ["tensorflow.ones_like", "tensorflow.reduce_sum", "running_statistics.AverageMeanStd.observation_count.assign_add", "running_statistics.AverageMeanStd.update_count.assign_add", "tensorflow.reduce_sum", "tensorflow.cast", "running_statistics.AverageMeanStd.mean.assign_add", "tensorflow.reduce_sum", "running_statistics.AverageMeanStd.summed_variance.assign_add", "list", "tensorflow.cast", "range"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "data", ")", ":", "\n", "    ", "\"\"\"Updates normalization statistics.\n\n    Args:\n      data: <float32>[(...), size].\n    \"\"\"", "\n", "# Reduce tensors along all the dimensions except the last ones.", "\n", "reduce_dims", "=", "list", "(", "range", "(", "data", ".", "shape", ".", "rank", ")", ")", "[", ":", "-", "1", "]", "\n", "\n", "# Update the observations counts.", "\n", "count", "=", "tf", ".", "ones_like", "(", "data", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "aggregated_count", "=", "tf", ".", "reduce_sum", "(", "count", ",", "reduce_dims", ")", "\n", "# SUM across replicas.", "\n", "self", ".", "observation_count", ".", "assign_add", "(", "tf", ".", "cast", "(", "aggregated_count", ",", "tf", ".", "float32", ")", ")", "\n", "self", ".", "update_count", ".", "assign_add", "(", "1", ")", "\n", "# Update the mean.", "\n", "diff_to_old_mean", "=", "data", "-", "self", ".", "mean", "\n", "mean_update", "=", "tf", ".", "reduce_sum", "(", "diff_to_old_mean", ",", "reduce_dims", ")", "\n", "mean_update", "/=", "tf", ".", "cast", "(", "self", ".", "observation_count", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "mean", ".", "assign_add", "(", "mean_update", ")", "\n", "\n", "# Update the variance.", "\n", "diff_to_new_mean", "=", "data", "-", "self", ".", "mean", "\n", "variance_update", "=", "diff_to_old_mean", "*", "diff_to_new_mean", "\n", "variance_update", "=", "tf", ".", "reduce_sum", "(", "variance_update", ",", "reduce_dims", ")", "\n", "self", ".", "summed_variance", ".", "assign_add", "(", "variance_update", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.AverageMeanStd.get_mean_std": [[330, 343], ["tensorflow.maximum", "tensorflow.cast", "tensorflow.maximum", "tensorflow.sqrt", "tensorflow.clip_by_value"], "methods", ["None"], ["", "def", "get_mean_std", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns mean and standard deviation for current statistics.\"\"\"", "\n", "# The following clipping guarantees an initial variance of one.", "\n", "minval", "=", "self", ".", "_std_min_value", "*", "self", ".", "_std_min_value", "\n", "eff_var", "=", "tf", ".", "maximum", "(", "minval", ",", "self", ".", "summed_variance", ")", "\n", "eff_count", "=", "tf", ".", "cast", "(", "self", ".", "observation_count", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "eff_count", "=", "tf", ".", "maximum", "(", "minval", ",", "eff_count", ")", "\n", "std", "=", "tf", ".", "sqrt", "(", "eff_var", "/", "eff_count", ")", "\n", "std", "=", "tf", ".", "clip_by_value", "(", "std", ",", "self", ".", "_std_min_value", ",", "self", ".", "_std_max_value", ")", "\n", "# Multiplication with one converts the variable to a tensor with the value", "\n", "# at the time this function is called. This is important if the python", "\n", "# reference is passed around and the variables are changed in the meantime.", "\n", "return", "self", ".", "mean", "*", "1.", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.FixedMeanStd.__init__": [[349, 360], ["tensorflow.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "mean", "=", "0.", ",", "std", "=", "1.", ")", ":", "\n", "    ", "\"\"\"Creates a FixedMeanStd.\n\n    Args:\n      mean: Float with the fixed mean.\n      std: Float with the fixed standard deviation.\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_mean", "=", "mean", "\n", "self", ".", "_std", "=", "std", "\n", "self", ".", "_size", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.FixedMeanStd.init": [[361, 368], ["None"], "methods", ["None"], ["", "def", "init", "(", "self", ",", "size", ")", ":", "\n", "    ", "\"\"\"Initializes normalization variables.\n\n    Args:\n      size: Integer with the dimensionality of the tracked tensor.\n    \"\"\"", "\n", "self", ".", "_size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.FixedMeanStd.update": [[369, 376], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "data", ")", ":", "\n", "    ", "\"\"\"Updates normalization statistics.\n\n    Args:\n      data: <float32>[(...), size].\n    \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.FixedMeanStd.get_mean_std": [[377, 383], ["tensorflow.ones", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor"], "methods", ["None"], ["", "def", "get_mean_std", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns mean and standard deviation for current statistics.\"\"\"", "\n", "vec", "=", "tf", ".", "ones", "(", "(", "self", ".", "_size", ",", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "mean", "=", "tf", ".", "convert_to_tensor", "(", "self", ".", "_mean", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "std", "=", "tf", ".", "convert_to_tensor", "(", "self", ".", "_std", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "return", "mean", "*", "vec", ",", "std", "*", "vec", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.__init__": [[405, 422], ["tensorflow.Module.__init__", "running_statistics.AverageMeanStd", "running_statistics.AverageMeanStd", "int", "float", "float"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "std_min_value", "=", "1e-6", ",", "std_max_value", "=", "1e6", ",", "buffer_size", "=", "1e5", ")", ":", "\n", "    ", "\"\"\"Init.\n\n    Args:\n      std_min_value: Clip the returned std by this lower bound.\n      std_max_value: Clip the returned std by this upper bound.\n      buffer_size: Number of updates to perform on the buffer AverageMeanStd\n        before it's reset. AverageMeanStd uses float32s with ~24bit precision,\n        so a default of 1e5 makes sense. It leaves about 7bits of precision for\n        each variance added to summed_variance.\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "average_mean_std", "=", "AverageMeanStd", "(", "0.", ",", "float", "(", "'inf'", ")", ")", "\n", "self", ".", "average_mean_std_buffer", "=", "AverageMeanStd", "(", "0.", ",", "float", "(", "'inf'", ")", ")", "\n", "self", ".", "_std_min_value", "=", "std_min_value", "\n", "self", ".", "_std_max_value", "=", "std_max_value", "\n", "self", ".", "buffer_size", "=", "int", "(", "buffer_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.init": [[423, 431], ["running_statistics.TwoLevelAverageMeanStd.average_mean_std.init", "running_statistics.TwoLevelAverageMeanStd.average_mean_std_buffer.init"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.init", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.init"], ["", "def", "init", "(", "self", ",", "size", ")", ":", "\n", "    ", "\"\"\"Initializes normalization variables.\n\n    Args:\n      size: (integer) size of the tracked tensor.\n    \"\"\"", "\n", "self", ".", "average_mean_std", ".", "init", "(", "size", ")", "\n", "self", ".", "average_mean_std_buffer", ".", "init", "(", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.update": [[432, 444], ["running_statistics.TwoLevelAverageMeanStd.average_mean_std_buffer.update", "tensorflow.cast", "running_statistics.TwoLevelAverageMeanStd.average_mean_std.merge", "running_statistics.TwoLevelAverageMeanStd.average_mean_std_buffer.reset", "tensorflow.math.greater_equal"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.update", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.AverageMeanStd.merge", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset"], ["", "def", "update", "(", "self", ",", "data", ")", ":", "\n", "    ", "\"\"\"Updates normalization statistics.\n\n    Args:\n      data: <float32>[(...), size].\n    \"\"\"", "\n", "self", ".", "average_mean_std_buffer", ".", "update", "(", "data", ")", "\n", "reset_buffer", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "math", ".", "greater_equal", "(", "self", ".", "average_mean_std_buffer", ".", "update_count", ",", "\n", "self", ".", "buffer_size", ")", ",", "tf", ".", "float32", ")", "\n", "self", ".", "average_mean_std", ".", "merge", "(", "self", ".", "average_mean_std_buffer", ",", "reset_buffer", ")", "\n", "self", ".", "average_mean_std_buffer", ".", "reset", "(", "reset_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.TwoLevelAverageMeanStd.get_mean_std": [[445, 470], ["tensorflow.reduce_any", "tensorflow.clip_by_value", "tensorflow.equal", "tensorflow.zeros_like", "tensorflow.ones_like", "running_statistics.merge_means", "running_statistics.merge_summed_variances", "tensorflow.maximum", "tensorflow.sqrt"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.merge_means", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.merge_summed_variances"], ["", "@", "tf", ".", "function", "\n", "def", "get_mean_std", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns mean and standard deviation for current statistics.\"\"\"", "\n", "mean", "=", "self", ".", "average_mean_std", ".", "mean", "\n", "count", "=", "self", ".", "average_mean_std", ".", "observation_count", "\n", "mean_buffer", "=", "self", ".", "average_mean_std_buffer", ".", "mean", "\n", "count_buffer", "=", "self", ".", "average_mean_std_buffer", ".", "observation_count", "\n", "total_count", "=", "count", "+", "count_buffer", "\n", "# All elements of 'total_count' have the same value.", "\n", "if", "tf", ".", "reduce_any", "(", "tf", ".", "equal", "(", "total_count", ",", "0.", ")", ")", ":", "\n", "      ", "merged_mean", "=", "tf", ".", "zeros_like", "(", "mean", ")", "\n", "merged_std", "=", "tf", ".", "ones_like", "(", "mean", ")", "\n", "", "else", ":", "\n", "      ", "merged_mean", "=", "merge_means", "(", "mean", ",", "mean_buffer", ",", "count", ",", "count_buffer", ")", "\n", "merged_summed_variance", "=", "merge_summed_variances", "(", "\n", "self", ".", "average_mean_std", ".", "summed_variance", ",", "\n", "self", ".", "average_mean_std_buffer", ".", "summed_variance", ",", "mean", ",", "mean_buffer", ",", "\n", "merged_mean", ",", "count", ",", "count_buffer", ")", "\n", "# Due to precision issues, merged_summed_variance can be slightly", "\n", "# negative.", "\n", "merged_summed_variance", "=", "tf", ".", "maximum", "(", "0.", ",", "merged_summed_variance", ")", "\n", "merged_std", "=", "tf", ".", "sqrt", "(", "merged_summed_variance", "/", "total_count", ")", "\n", "", "clipped_std", "=", "tf", ".", "clip_by_value", "(", "merged_std", ",", "self", ".", "_std_min_value", ",", "\n", "self", ".", "_std_max_value", ")", "\n", "return", "merged_mean", ",", "clipped_std", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.merge_summed_variances": [[159, 176], ["tensorflow.square", "tensorflow.square"], "function", ["None"], ["", "", "def", "merge_summed_variances", "(", "v1", ",", "v2", ",", "mu1", ",", "mu2", ",", "merged_mean", ",", "n1", ",", "n2", ")", ":", "\n", "  ", "\"\"\"Computes the (summed) variance of a combined series.\n\n  Args:\n    v1: summed variance of the first series.\n    v2: summed variance of the second series.\n    mu1: mean of the first series.\n    mu2: mean of the second series.\n    merged_mean: mean for the combined series.\n    n1: Number of datapoints in the first series.\n    n2: Number of datapoints in the second series.\n\n  Returns:\n    The summed variance for the combined series.\n  \"\"\"", "\n", "return", "(", "v1", "+", "n1", "*", "tf", ".", "square", "(", "mu1", "-", "merged_mean", ")", "+", "v2", "+", "\n", "n2", "*", "tf", ".", "square", "(", "mu2", "-", "merged_mean", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.running_statistics.merge_means": [[178, 182], ["None"], "function", ["None"], ["", "def", "merge_means", "(", "mu1", ",", "mu2", ",", "n1", ",", "n2", ")", ":", "\n", "  ", "\"\"\"Merges means. Requires n1 + n2 > 0.\"\"\"", "\n", "total", "=", "n1", "+", "n2", "\n", "return", "(", "n1", "*", "mu1", "+", "n2", "*", "mu2", ")", "/", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module_test._LoggingModule.dummy_function": [[25, 27], ["logging_module_test._LoggingModule.log", "tensorflow.reduce_mean"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log"], ["  ", "def", "dummy_function", "(", "self", ",", "tensor", ")", ":", "\n", "    ", "self", ".", "log", "(", "'test'", ",", "tf", ".", "reduce_mean", "(", "tensor", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module_test._OtherModule.__init__": [[31, 33], ["logging_module_test._LoggingModule"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "self", ".", "_inner_module", "=", "_LoggingModule", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module_test._OtherModule.dummy_function": [[34, 36], ["logging_module_test._OtherModule._inner_module.dummy_function"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module_test._OtherModule.dummy_function"], ["", "def", "dummy_function", "(", "self", ",", "tensor", ")", ":", "\n", "    ", "self", ".", "_inner_module", ".", "dummy_function", "(", "tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module_test._WrappingModule.__init__": [[40, 42], ["logging_module_test._OtherModule"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "self", ".", "other_module", "=", "_OtherModule", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module_test._WrappingModule.step": [[43, 48], ["seed_rl.agents.policy_gradient.modules.logging_module.LoggingTape", "logging_module_test._WrappingModule.other_module.dummy_function"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module_test._OtherModule.dummy_function"], ["", "@", "tf", ".", "function", "\n", "def", "step", "(", "self", ",", "tensor", ")", ":", "\n", "    ", "with", "logging_module", ".", "LoggingTape", "(", "self", ".", "other_module", ")", "as", "logged_tensors", ":", "\n", "      ", "self", ".", "other_module", ".", "dummy_function", "(", "tensor", ")", "\n", "", "return", "logged_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module_test.LoggingModuleTest.test_log_no_op": [[52, 56], ["logging_module_test._LoggingModule", "logging_module_test._LoggingModule.dummy_function", "tensorflow.zeros"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module_test._OtherModule.dummy_function"], ["  ", "def", "test_log_no_op", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the default no-op log method.\"\"\"", "\n", "module", "=", "_LoggingModule", "(", ")", "\n", "module", ".", "dummy_function", "(", "tf", ".", "zeros", "(", "(", "20", ",", "10", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module_test.LoggingModuleTest.test_log_to_dict": [[57, 67], ["tensorflow.range", "logging_module_test._LoggingModule", "_LoggingModule.set_logging_dict", "logging_module_test._LoggingModule.dummy_function", "_LoggingModule.unset_logging_dict", "logging_module_test.LoggingModuleTest.assertAllClose", "tensorflow.reduce_mean"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module.LoggingModule.set_logging_dict", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module_test._OtherModule.dummy_function", "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module.LoggingModule.unset_logging_dict"], ["", "def", "test_log_to_dict", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that we can log to an external dictionary.\"\"\"", "\n", "my_dict", "=", "{", "}", "\n", "tensor", "=", "tf", ".", "range", "(", "(", "200", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "module", "=", "_LoggingModule", "(", ")", "\n", "module", ".", "set_logging_dict", "(", "my_dict", ")", "\n", "module", ".", "dummy_function", "(", "tensor", ")", "\n", "module", ".", "unset_logging_dict", "(", ")", "\n", "\n", "self", ".", "assertAllClose", "(", "my_dict", "[", "'test'", "]", ",", "tf", ".", "reduce_mean", "(", "tensor", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.modules.logging_module_test.LoggingTapeTest.test_tf_function": [[71, 78], ["logging_module_test._WrappingModule", "tensorflow.range", "tensorflow.ones", "logging_module_test.LoggingTapeTest.assertAllClose", "logging_module_test.LoggingTapeTest.assertAllClose", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "logging_module_test._WrappingModule.step", "logging_module_test._WrappingModule.step"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.step", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.step"], ["  ", "def", "test_tf_function", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that by default the log method is a no-op.\"\"\"", "\n", "module", "=", "_WrappingModule", "(", ")", "\n", "tensor1", "=", "tf", ".", "range", "(", "(", "200", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "tensor2", "=", "tf", ".", "ones", "(", "(", "200", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "assertAllClose", "(", "module", ".", "step", "(", "tensor1", ")", "[", "'test'", "]", ",", "tf", ".", "reduce_mean", "(", "tensor1", ")", ")", "\n", "self", ".", "assertAllClose", "(", "module", ".", "step", "(", "tensor2", ")", "[", "'test'", "]", ",", "tf", ".", "reduce_mean", "(", "tensor2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks.DuelingLSTMDQNNet.__init__": [[230, 255], ["tensorflow.Module.__init__", "tensorflow.keras.Sequential", "tensorflow.keras.Sequential", "tensorflow.keras.Sequential", "tensorflow.keras.layers.LSTMCell", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Flatten", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks.DuelingLSTMDQNNet.initial_state": [[256, 262], ["AgentState", "networks.DuelingLSTMDQNNet._core.get_initial_state", "networks.initial_frame_stacking_state"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks.initial_frame_stacking_state"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks.DuelingLSTMDQNNet._torso": [[263, 272], ["networks.DuelingLSTMDQNNet._body", "tensorflow.one_hot", "tensorflow.concat", "tensorflow.expand_dims"], "methods", ["None"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks.DuelingLSTMDQNNet._head": [[273, 286], ["networks.DuelingLSTMDQNNet._value", "networks.DuelingLSTMDQNNet._advantage", "tensorflow.reduce_mean", "tensorflow.cast", "AgentOutput", "tensorflow.argmax"], "methods", ["None"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks.DuelingLSTMDQNNet.__call__": [[287, 319], ["networks.DuelingLSTMDQNNet._unroll", "tensorflow.nest.map_structure", "tensorflow.nest.map_structure", "tensorflow.expand_dims", "tensorflow.squeeze"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep._unroll"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks.DuelingLSTMDQNNet._unroll": [[320, 341], ["tensorflow.cast", "networks.DuelingLSTMDQNNet.initial_state", "networks.stack_frames", "env_outputs._replace._replace._replace", "seed_rl.common.utils.batch_apply", "networks._unroll_cell", "seed_rl.common.utils.batch_apply", "AgentState", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.stack_frames", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.batch_apply", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks._unroll_cell", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.batch_apply"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks.initial_frame_stacking_state": [[32, 55], ["tensorflow.zeros", "tensorflow.concat", "tensorflow.math.reduce_prod"], "function", ["None"], ["\n", "super", "(", "MLPandLSTM", ",", "self", ")", ".", "__init__", "(", "name", "=", "'MLPandLSTM'", ")", "\n", "self", ".", "_parametric_action_distribution", "=", "parametric_action_distribution", "\n", "\n", "# MLP", "\n", "mlp_layers", "=", "[", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "size", ",", "'relu'", ")", "for", "size", "in", "mlp_sizes", "]", "\n", "self", ".", "_mlp", "=", "tf", ".", "keras", ".", "Sequential", "(", "mlp_layers", ")", "\n", "# stacked LSTM", "\n", "lstm_cells", "=", "[", "tf", ".", "keras", ".", "layers", ".", "LSTMCell", "(", "size", ")", "for", "size", "in", "lstm_sizes", "]", "\n", "self", ".", "_core", "=", "tf", ".", "keras", ".", "layers", ".", "StackedRNNCells", "(", "lstm_cells", ")", "\n", "# Layers for _head.", "\n", "self", ".", "_policy_logits", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "parametric_action_distribution", ".", "param_size", ",", "name", "=", "'policy_logits'", ")", "\n", "self", ".", "_baseline", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "1", ",", "name", "=", "'baseline'", ")", "\n", "\n", "", "@", "tf", ".", "function", "\n", "def", "initial_state", "(", "self", ",", "batch_size", ")", ":", "\n", "    ", "return", "self", ".", "_core", ".", "get_initial_state", "(", "batch_size", "=", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "def", "_head", "(", "self", ",", "core_output", ")", ":", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks.stack_frames": [[57, 174], ["tensorflow.reshape", "range", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.where", "tensorflow.bitwise.left_shift", "tensorflow.reduce_sum", "tensorflow.reshape", "ValueError", "ValueError", "ValueError", "ValueError", "unstacked_state.append", "tensorflow.zeros", "tensorflow.reshape", "len", "done_masks.append", "tensorflow.zeros_like", "tensorflow.cast", "tensorflow.cast", "tensorflow.math.logical_or", "obs_shape.num_elements", "tensorflow.bitwise.bitwise_and", "tensorflow.reshape", "range", "tensorflow.pad", "range", "tensorflow.bitwise.right_shift"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append"], ["baseline", "=", "tf", ".", "squeeze", "(", "self", ".", "_baseline", "(", "core_output", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Sample an action from the policy.", "\n", "action", "=", "self", ".", "_parametric_action_distribution", ".", "sample", "(", "policy_logits", ")", "\n", "\n", "return", "AgentOutput", "(", "action", ",", "policy_logits", ",", "baseline", ")", "\n", "\n", "# Not clear why, but if \"@tf.function\" declarator is placed directly onto", "\n", "# __call__, training fails with \"uninitialized variable *baseline\".", "\n", "# when running on multiple learning tpu cores.", "\n", "\n", "\n", "", "@", "tf", ".", "function", "\n", "def", "get_action", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "self", ".", "__call__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "__call__", "(", "self", ",", "prev_actions", ",", "env_outputs", ",", "core_state", ",", "unroll", "=", "False", ",", "\n", "is_training", "=", "False", ")", ":", "\n", "    ", "\"\"\"Runs the agent.\n\n    Args:\n      prev_actions: Previous action. Not used by this agent.\n      env_outputs: Structure with reward, done and observation fields. Only\n        observation field is used by this agent. It should have the shape\n        [time, batch_size, observation_size].\n      core_state: Agent state.\n      unroll: Should be True if inputs contain the time dimension and False\n        otherwise.\n      is_training: Whether we are in the loss computation. Not used by this\n        agent.\n    Returns:\n      A structure with action, policy_logits and baseline.\n    \"\"\"", "\n", "if", "not", "unroll", ":", "\n", "# Add time dimension.", "\n", "      ", "prev_actions", ",", "env_outputs", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "tf", ".", "expand_dims", "(", "t", ",", "0", ")", ",", "(", "prev_actions", ",", "env_outputs", ")", ")", "\n", "\n", "", "outputs", ",", "core_state", "=", "self", ".", "_unroll", "(", "prev_actions", ",", "env_outputs", ",", "core_state", ")", "\n", "\n", "if", "not", "unroll", ":", "\n", "# Remove time dimension.", "\n", "      ", "outputs", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "tf", ".", "squeeze", "(", "t", ",", "0", ")", ",", "outputs", ")", "\n", "\n", "", "return", "outputs", ",", "core_state", "\n", "\n", "", "def", "_unroll", "(", "self", ",", "unused_prev_actions", ",", "env_outputs", ",", "core_state", ")", ":", "\n", "    ", "unused_reward", ",", "done", ",", "observation", ",", "_", ",", "_", "=", "env_outputs", "\n", "observation", "=", "self", ".", "_mlp", "(", "observation", ")", "\n", "\n", "initial_core_state", "=", "self", ".", "_core", ".", "get_initial_state", "(", "\n", "batch_size", "=", "tf", ".", "shape", "(", "observation", ")", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "core_output_list", "=", "[", "]", "\n", "for", "input_", ",", "d", "in", "zip", "(", "tf", ".", "unstack", "(", "observation", ")", ",", "tf", ".", "unstack", "(", "done", ")", ")", ":", "\n", "# If the episode ended, the core state should be reset before the next.", "\n", "      ", "core_state", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "x", ",", "y", ",", "d", "=", "d", ":", "tf", ".", "where", "(", "\n", "tf", ".", "reshape", "(", "d", ",", "[", "d", ".", "shape", "[", "0", "]", "]", "+", "[", "1", "]", "*", "(", "x", ".", "shape", ".", "rank", "-", "1", ")", ")", ",", "x", ",", "y", ")", ",", "\n", "initial_core_state", ",", "\n", "core_state", ")", "\n", "core_output", ",", "core_state", "=", "self", ".", "_core", "(", "input_", ",", "core_state", ")", "\n", "core_output_list", ".", "append", "(", "core_output", ")", "\n", "", "outputs", "=", "tf", ".", "stack", "(", "core_output_list", ")", "\n", "\n", "return", "utils", ".", "batch_apply", "(", "self", ".", "_head", ",", "(", "outputs", ",", ")", ")", ",", "core_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks._unroll_cell": [[176, 219], ["tensorflow.unstack", "tensorflow.unstack", "zip", "len", "len", "len", "len", "tensorflow.nest.map_structure", "recurrent_cell", "stacked_outputs.append", "tensorflow.stack", "tensorflow.where", "tensorflow.reshape"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.AgentsTest._random_obs": [[57, 62], ["tensorflow.cast", "tensorflow.random.uniform"], "methods", ["None"], ["v_many_calls", "=", "[", "]", "\n", "q_many_calls", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_steps", ")", ":", "\n", "\n", "      ", "env_output_i", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "t", "[", "i", "]", ",", "env_output", ")", "\n", "expanded_env_output_i", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "t", "[", "i", ",", "tf", ".", "newaxis", "]", ",", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.AgentsTest._create_agent_input": [[63, 76], ["tensorflow.cast", "tensorflow.random.uniform", "tensorflow.random.uniform", "seed_rl.common.utils.EnvOutput", "tensorflow.random.uniform", "networks_test.AgentsTest._random_obs", "tensorflow.zeros_like", "tensorflow.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.AgentsTest._random_obs"], ["env_output", ")", "\n", "v_many_calls", ".", "append", "(", "\n", "agent", ".", "get_V", "(", "prev_action", "[", "i", ",", "tf", ".", "newaxis", "]", ",", "\n", "expanded_env_output_i", ",", "\n", "state", ")", "[", "0", "]", ")", "\n", "q_many_calls", ".", "append", "(", "\n", "agent", ".", "get_Q", "(", "prev_action", "[", "i", ",", "tf", ".", "newaxis", "]", ",", "\n", "expanded_env_output_i", ",", "\n", "state", ",", "\n", "action", "[", "i", ",", "tf", ".", "newaxis", "]", ")", "[", "0", "]", ")", "\n", "unused_action", ",", "state", "=", "agent", "(", "prev_action", "[", "i", "]", ",", "env_output_i", ",", "state", ")", "\n", "", "v_many_calls", "=", "tf", ".", "stack", "(", "v_many_calls", ")", "\n", "q_many_calls", "=", "tf", ".", "stack", "(", "q_many_calls", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.AgentsTest.test_basic": [[77, 84], ["seed_rl.atari.networks.DuelingLSTMDQNNet", "seed_rl.atari.networks.DuelingLSTMDQNNet.initial_state", "seed_rl.atari.networks.DuelingLSTMDQNNet.", "networks_test.AgentsTest._create_agent_input"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.AgentsTest._create_agent_input"], ["# Check if results are the same.", "\n", "self", ".", "assertAllClose", "(", "v_one_call", ",", "v_many_calls", ",", "1e-4", ",", "1e-4", ")", "\n", "self", ".", "assertAllClose", "(", "q_one_call", ",", "q_many_calls", ",", "1e-4", ",", "1e-4", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "'__main__'", ":", "\n", "  ", "tf", ".", "test", ".", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.AgentsTest.test_basic_no_frame_stack": [[85, 94], ["seed_rl.atari.networks.DuelingLSTMDQNNet", "seed_rl.atari.networks.DuelingLSTMDQNNet.initial_state", "unittest.patch.object", "seed_rl.atari.networks.DuelingLSTMDQNNet.", "networks_test.AgentsTest.assertEqual", "networks_test.AgentsTest._create_agent_input"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.AgentsTest._create_agent_input"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.AgentsTest.test_basic_frame_stacking": [[95, 104], ["seed_rl.atari.networks.DuelingLSTMDQNNet", "seed_rl.atari.networks.DuelingLSTMDQNNet.initial_state", "unittest.patch.object", "seed_rl.atari.networks.DuelingLSTMDQNNet.", "networks_test.AgentsTest.assertEqual", "networks_test.AgentsTest._create_agent_input"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.AgentsTest._create_agent_input"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.AgentsTest.check_core_input_shape": [[105, 118], ["seed_rl.atari.networks.DuelingLSTMDQNNet", "seed_rl.atari.networks.DuelingLSTMDQNNet.initial_state", "unittest.patch.object", "seed_rl.atari.networks.DuelingLSTMDQNNet.", "networks_test.AgentsTest.assertEqual", "networks_test.AgentsTest._create_agent_input"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.AgentsTest._create_agent_input"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.AgentsTest.test_unroll_cell": [[119, 153], ["seed_rl.atari.networks._unroll_cell", "networks_test.AgentsTest.assertAllEqual", "seed_rl.atari.networks._unroll_cell", "networks_test.AgentsTest.assertAllEqual", "seed_rl.atari.networks._unroll_cell", "networks_test.AgentsTest.assertEqual", "networks_test.AgentsTest.assertAllEqual", "networks_test.AgentsTest.assertAllEqual", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks._unroll_cell", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks._unroll_cell", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks._unroll_cell"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.AgentsTest.test_unroll_cell_done": [[154, 185], ["seed_rl.atari.networks._unroll_cell", "networks_test.AgentsTest.assertAllEqual", "seed_rl.atari.networks._unroll_cell", "networks_test.AgentsTest.assertAllEqual", "seed_rl.atari.networks._unroll_cell", "networks_test.AgentsTest.assertEqual", "networks_test.AgentsTest.assertAllEqual", "networks_test.AgentsTest.assertAllEqual", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks._unroll_cell", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks._unroll_cell", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks._unroll_cell"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.AgentsTest.test_stack_frames": [[186, 218], ["networks_test.stack_frames", "networks_test.AgentsTest.assertAllEqual", "networks_test.stack_frames", "networks_test.AgentsTest.assertAllEqual", "networks_test.stack_frames", "networks_test.AgentsTest.assertEqual", "networks_test.AgentsTest.assertAllEqual", "networks_test.AgentsTest.assertAllEqual", "seed_rl.atari.networks.DuelingLSTMDQNNet().initial_state", "seed_rl.atari.networks.DuelingLSTMDQNNet"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.stack_frames", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.stack_frames", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.stack_frames", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.AgentsTest.test_stack_frames_done": [[219, 248], ["networks_test.stack_frames", "networks_test.AgentsTest.assertAllEqual", "networks_test.stack_frames", "networks_test.AgentsTest.assertAllEqual", "networks_test.stack_frames", "networks_test.AgentsTest.assertEqual", "networks_test.AgentsTest.assertAllEqual", "networks_test.AgentsTest.assertAllEqual", "seed_rl.atari.networks.DuelingLSTMDQNNet().initial_state", "seed_rl.atari.networks.DuelingLSTMDQNNet"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.stack_frames", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.stack_frames", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.stack_frames", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.stack_fn": [[26, 44], ["tensorflow.concat"], "function", ["None"], ["class", "NetworkTest", "(", "tf", ".", "test", ".", "TestCase", ")", ":", "\n", "\n", "  ", "def", "test_actor_critic_lstm", "(", "self", ")", ":", "\n", "    ", "n_steps", "=", "100", "\n", "batch_size", "=", "10", "\n", "obs_size", "=", "15", "\n", "action_size", "=", "3", "\n", "\n", "action_dist", "=", "parametric_distribution", ".", "normal_tanh_distribution", "(", "action_size", ")", "\n", "agent", "=", "networks", ".", "ActorCriticLSTM", "(", "\n", "action_dist", ",", "\n", "n_critics", "=", "2", ",", "\n", "lstm_sizes", "=", "[", "10", ",", "20", "]", ",", "\n", "pre_mlp_sizes", "=", "[", "30", ",", "40", "]", ",", "\n", "post_mlp_sizes", "=", "[", "50", "]", ",", "\n", "ff_mlp_sizes", "=", "[", "25", ",", "35", ",", "45", "]", ")", "\n", "env_output", "=", "utils", ".", "EnvOutput", "(", "\n", "observation", "=", "tf", ".", "random", ".", "normal", "(", "(", "n_steps", ",", "batch_size", ",", "obs_size", ")", ")", ",", "\n", "reward", "=", "tf", ".", "random", ".", "normal", "(", "(", "n_steps", ",", "batch_size", ")", ")", ",", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.stack_frames": [[46, 53], ["seed_rl.atari.networks.stack_frames", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.atari.networks_test.stack_frames"], ["abandoned", "=", "tf", ".", "zeros", "(", "(", "n_steps", ",", "batch_size", ")", ",", "dtype", "=", "tf", ".", "bool", ")", ",", "\n", "episode_step", "=", "tf", ".", "ones", "(", "(", "n_steps", ",", "batch_size", ")", ",", "dtype", "=", "tf", ".", "int32", ")", ")", "\n", "prev_action", "=", "tf", ".", "random", ".", "normal", "(", "(", "n_steps", ",", "batch_size", ",", "action_size", ")", ")", "\n", "action", "=", "tf", ".", "random", ".", "normal", "(", "(", "n_steps", ",", "batch_size", ",", "action_size", ")", ")", "\n", "state", "=", "agent", ".", "initial_state", "(", "10", ")", "\n", "\n", "# Run in one call.", "\n", "v_one_call", "=", "agent", ".", "get_V", "(", "prev_action", ",", "env_output", ",", "state", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing.__init__": [[45, 85], ["ValueError", "ValueError", "numpy.empty", "numpy.empty"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "environment", ",", "frame_skip", "=", "4", ",", "terminal_on_life_loss", "=", "False", ",", "\n", "screen_size", "=", "84", ",", "max_random_noops", "=", "0", ")", ":", "\n", "    ", "\"\"\"Constructor for an Atari 2600 preprocessor.\n\n    Args:\n      environment: Gym environment whose observations are preprocessed.\n      frame_skip: int, the frequency at which the agent experiences the game.\n      terminal_on_life_loss: bool, If True, the step() method returns\n        is_terminal=True whenever a life is lost. See Mnih et al. 2015.\n      screen_size: int, size of a resized Atari 2600 frame.\n      max_random_noops: int, maximum number of no-ops to apply at the beginning\n        of each episode to reduce determinism. These no-ops are applied at a\n        low-level, before frame skipping.\n\n    Raises:\n      ValueError: if frame_skip or screen_size are not strictly positive.\n    \"\"\"", "\n", "if", "frame_skip", "<=", "0", ":", "\n", "      ", "raise", "ValueError", "(", "'Frame skip should be strictly positive, got {}'", ".", "\n", "format", "(", "frame_skip", ")", ")", "\n", "", "if", "screen_size", "<=", "0", ":", "\n", "      ", "raise", "ValueError", "(", "'Target screen size should be strictly positive, got {}'", ".", "\n", "format", "(", "screen_size", ")", ")", "\n", "\n", "", "self", ".", "environment", "=", "environment", "\n", "self", ".", "terminal_on_life_loss", "=", "terminal_on_life_loss", "\n", "self", ".", "frame_skip", "=", "frame_skip", "\n", "self", ".", "screen_size", "=", "screen_size", "\n", "self", ".", "max_random_noops", "=", "max_random_noops", "\n", "\n", "obs_dims", "=", "self", ".", "environment", ".", "observation_space", "\n", "# Stores temporary observations used for pooling over two successive", "\n", "# frames.", "\n", "self", ".", "screen_buffer", "=", "[", "\n", "np", ".", "empty", "(", "(", "obs_dims", ".", "shape", "[", "0", "]", ",", "obs_dims", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "np", ".", "uint8", ")", ",", "\n", "np", ".", "empty", "(", "(", "obs_dims", ".", "shape", "[", "0", "]", ",", "obs_dims", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "]", "\n", "\n", "self", ".", "game_over", "=", "False", "\n", "self", ".", "lives", "=", "0", "# Will need to be set by reset().", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing.observation_space": [[86, 92], ["gym.spaces.box.Box"], "methods", ["None"], ["", "@", "property", "\n", "def", "observation_space", "(", "self", ")", ":", "\n", "# Return the observation space adjusted to match the shape of the processed", "\n", "# observations.", "\n", "    ", "return", "Box", "(", "low", "=", "0", ",", "high", "=", "255", ",", "shape", "=", "(", "self", ".", "screen_size", ",", "self", ".", "screen_size", ",", "1", ")", ",", "\n", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing.action_space": [[93, 96], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_space", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "environment", ".", "action_space", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing.reward_range": [[97, 100], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "reward_range", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "environment", ".", "reward_range", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing.metadata": [[101, 104], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "metadata", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "environment", ".", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing.close": [[105, 107], ["atari_preprocessing.AtariPreprocessing.environment.close"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "environment", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing.apply_random_noops": [[108, 119], ["atari_preprocessing.AtariPreprocessing.environment.np_random.randint", "range", "atari_preprocessing.AtariPreprocessing.environment.step", "atari_preprocessing.AtariPreprocessing.environment.reset"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.step", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset"], ["", "def", "apply_random_noops", "(", "self", ")", ":", "\n", "    ", "\"\"\"Steps self.environment with random no-ops.\"\"\"", "\n", "if", "self", ".", "max_random_noops", "<=", "0", ":", "\n", "      ", "return", "\n", "# Other no-ops implementations actually always do at least 1 no-op. We", "\n", "# follow them.", "\n", "", "no_ops", "=", "self", ".", "environment", ".", "np_random", ".", "randint", "(", "1", ",", "self", ".", "max_random_noops", "+", "1", ")", "\n", "for", "_", "in", "range", "(", "no_ops", ")", ":", "\n", "      ", "_", ",", "_", ",", "game_over", ",", "_", "=", "self", ".", "environment", ".", "step", "(", "0", ")", "\n", "if", "game_over", ":", "\n", "        ", "self", ".", "environment", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing.reset": [[120, 134], ["atari_preprocessing.AtariPreprocessing.environment.reset", "atari_preprocessing.AtariPreprocessing.apply_random_noops", "atari_preprocessing.AtariPreprocessing.environment.ale.lives", "atari_preprocessing.AtariPreprocessing._fetch_grayscale_observation", "atari_preprocessing.AtariPreprocessing.screen_buffer[].fill", "atari_preprocessing.AtariPreprocessing._pool_and_resize"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing.apply_random_noops", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing._fetch_grayscale_observation", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing._pool_and_resize"], ["", "", "", "def", "reset", "(", "self", ")", ":", "\n", "    ", "\"\"\"Resets the environment.\n\n    Returns:\n      observation: numpy array, the initial observation emitted by the\n        environment.\n    \"\"\"", "\n", "self", ".", "environment", ".", "reset", "(", ")", "\n", "self", ".", "apply_random_noops", "(", ")", "\n", "\n", "self", ".", "lives", "=", "self", ".", "environment", ".", "ale", ".", "lives", "(", ")", "\n", "self", ".", "_fetch_grayscale_observation", "(", "self", ".", "screen_buffer", "[", "0", "]", ")", "\n", "self", ".", "screen_buffer", "[", "1", "]", ".", "fill", "(", "0", ")", "\n", "return", "self", ".", "_pool_and_resize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing.render": [[135, 151], ["atari_preprocessing.AtariPreprocessing.environment.render"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.BatchedEnvironment.render"], ["", "def", "render", "(", "self", ",", "mode", ")", ":", "\n", "    ", "\"\"\"Renders the current screen, before preprocessing.\n\n    This calls the Gym API's render() method.\n\n    Args:\n      mode: Mode argument for the environment's render() method.\n        Valid values (str) are:\n          'rgb_array': returns the raw ALE image.\n          'human': renders to display via the Gym renderer.\n\n    Returns:\n      if mode='rgb_array': numpy array, the most recent screen.\n      if mode='human': bool, whether the rendering was successful.\n    \"\"\"", "\n", "return", "self", ".", "environment", ".", "render", "(", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing.step": [[152, 200], ["range", "atari_preprocessing.AtariPreprocessing._pool_and_resize", "atari_preprocessing.AtariPreprocessing.environment.step", "atari_preprocessing.AtariPreprocessing.environment.ale.lives", "atari_preprocessing.AtariPreprocessing._fetch_grayscale_observation"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing._pool_and_resize", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.step", "home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing._fetch_grayscale_observation"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "\"\"\"Applies the given action in the environment.\n\n    Remarks:\n\n      * If a terminal state (from life loss or episode end) is reached, this may\n        execute fewer than self.frame_skip steps in the environment.\n      * Furthermore, in this case the returned observation may not contain valid\n        image data and should be ignored.\n\n    Args:\n      action: The action to be executed.\n\n    Returns:\n      observation: numpy array, the observation following the action.\n      reward: float, the reward following the action.\n      is_terminal: bool, whether the environment has reached a terminal state.\n        This is true when a life is lost and terminal_on_life_loss, or when the\n        episode is over.\n      info: Gym API's info data structure.\n    \"\"\"", "\n", "accumulated_reward", "=", "0.", "\n", "\n", "for", "time_step", "in", "range", "(", "self", ".", "frame_skip", ")", ":", "\n", "# We bypass the Gym observation altogether and directly fetch the", "\n", "# grayscale image from the ALE. This is a little faster.", "\n", "      ", "_", ",", "reward", ",", "game_over", ",", "info", "=", "self", ".", "environment", ".", "step", "(", "action", ")", "\n", "accumulated_reward", "+=", "reward", "\n", "\n", "if", "self", ".", "terminal_on_life_loss", ":", "\n", "        ", "new_lives", "=", "self", ".", "environment", ".", "ale", ".", "lives", "(", ")", "\n", "is_terminal", "=", "game_over", "or", "new_lives", "<", "self", ".", "lives", "\n", "self", ".", "lives", "=", "new_lives", "\n", "", "else", ":", "\n", "        ", "is_terminal", "=", "game_over", "\n", "\n", "", "if", "is_terminal", ":", "\n", "        ", "break", "\n", "# We max-pool over the last two frames, in grayscale.", "\n", "", "elif", "time_step", ">=", "self", ".", "frame_skip", "-", "2", ":", "\n", "        ", "t", "=", "time_step", "-", "(", "self", ".", "frame_skip", "-", "2", ")", "\n", "self", ".", "_fetch_grayscale_observation", "(", "self", ".", "screen_buffer", "[", "t", "]", ")", "\n", "\n", "# Pool the last two observations.", "\n", "", "", "observation", "=", "self", ".", "_pool_and_resize", "(", ")", "\n", "\n", "self", ".", "game_over", "=", "game_over", "\n", "return", "observation", ",", "accumulated_reward", ",", "is_terminal", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing._fetch_grayscale_observation": [[201, 214], ["atari_preprocessing.AtariPreprocessing.environment.ale.getScreenGrayscale"], "methods", ["None"], ["", "def", "_fetch_grayscale_observation", "(", "self", ",", "output", ")", ":", "\n", "    ", "\"\"\"Returns the current observation in grayscale.\n\n    The returned observation is stored in 'output'.\n\n    Args:\n      output: numpy array, screen buffer to hold the returned observation.\n\n    Returns:\n      observation: numpy array, the current observation in grayscale.\n    \"\"\"", "\n", "self", ".", "environment", ".", "ale", ".", "getScreenGrayscale", "(", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.atari_preprocessing.AtariPreprocessing._pool_and_resize": [[215, 233], ["cv2.resize", "numpy.asarray", "numpy.expand_dims", "numpy.maximum"], "methods", ["None"], ["", "def", "_pool_and_resize", "(", "self", ")", ":", "\n", "    ", "\"\"\"Transforms two frames into a Nature DQN observation.\n\n    For efficiency, the transformation is done in-place in self.screen_buffer.\n\n    Returns:\n      transformed_screen: numpy array, pooled, resized screen.\n    \"\"\"", "\n", "# Pool if there are enough screens to do so.", "\n", "if", "self", ".", "frame_skip", ">", "1", ":", "\n", "      ", "np", ".", "maximum", "(", "self", ".", "screen_buffer", "[", "0", "]", ",", "self", ".", "screen_buffer", "[", "1", "]", ",", "\n", "out", "=", "self", ".", "screen_buffer", "[", "0", "]", ")", "\n", "\n", "", "transformed_image", "=", "cv2", ".", "resize", "(", "self", ".", "screen_buffer", "[", "0", "]", ",", "\n", "(", "self", ".", "screen_size", ",", "self", ".", "screen_size", ")", ",", "\n", "interpolation", "=", "cv2", ".", "INTER_LINEAR", ")", "\n", "int_image", "=", "np", ".", "asarray", "(", "transformed_image", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "return", "np", ".", "expand_dims", "(", "int_image", ",", "axis", "=", "2", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.environment_test.EnvironmentTest.test_run_step": [[28, 33], ["seed_rl.atari.env.create_environment", "seed_rl.atari.env.create_environment.reset", "seed_rl.atari.env.create_environment.step", "seed_rl.atari.env.create_environment.close"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.create_environment", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.step", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.close"], ["for", "_", "in", "range", "(", "100", ")", ":", "\n", "      ", "_", ",", "_", ",", "done", ",", "_", "=", "environment", ".", "step", "(", "environment", ".", "action_space", ".", "sample", "(", ")", ")", "\n", "if", "done", ":", "\n", "        ", "environment", ".", "reset", "(", ")", "\n", "\n", "", "", "", "def", "test_mujoco_env", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.r2d2_main.create_agent": [[42, 45], ["seed_rl.atari.networks.DuelingLSTMDQNNet"], "function", ["None"], ["def", "create_agent", "(", "env_output_specs", ",", "num_actions", ")", ":", "\n", "  ", "return", "networks", ".", "DuelingLSTMDQNNet", "(", "\n", "num_actions", ",", "env_output_specs", ".", "observation", ".", "shape", ",", "FLAGS", ".", "stack_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.r2d2_main.create_optimizer": [[47, 52], ["tensorflow.keras.optimizers.Adam"], "function", ["None"], ["", "def", "create_optimizer", "(", "unused_final_iteration", ")", ":", "\n", "  ", "learning_rate_fn", "=", "lambda", "iteration", ":", "FLAGS", ".", "learning_rate", "\n", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "FLAGS", ".", "learning_rate", ",", "\n", "epsilon", "=", "FLAGS", ".", "adam_epsilon", ")", "\n", "return", "optimizer", ",", "learning_rate_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.r2d2_main.main": [[54, 65], ["len", "absl.app.UsageError", "seed_rl.common.actor.actor_loop", "seed_rl.agents.r2d2.learner.learner_loop", "ValueError"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.actor.actor_loop", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.learner_loop"], ["", "def", "main", "(", "argv", ")", ":", "\n", "  ", "if", "len", "(", "argv", ")", ">", "1", ":", "\n", "    ", "raise", "app", ".", "UsageError", "(", "'Too many command-line arguments.'", ")", "\n", "", "if", "FLAGS", ".", "run_mode", "==", "'actor'", ":", "\n", "    ", "actor", ".", "actor_loop", "(", "env", ".", "create_environment", ")", "\n", "", "elif", "FLAGS", ".", "run_mode", "==", "'learner'", ":", "\n", "    ", "learner", ".", "learner_loop", "(", "env", ".", "create_environment", ",", "\n", "create_agent", ",", "\n", "create_optimizer", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'Unsupported run mode {}'", ".", "format", "(", "FLAGS", ".", "run_mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.atari.env.create_environment": [[42, 61], ["absl.logging.info", "gym.make", "gym.wrappers.TimeLimit.seed", "gym.wrappers.TimeLimit", "seed_rl.atari.atari_preprocessing.AtariPreprocessing", "isinstance", "ValueError", "type"], "function", ["None"], ["dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "num_steps", "=", "0", "\n", "self", ".", "max_episode_steps", "=", "self", ".", "env", ".", "spec", ".", "max_episode_steps", "\n", "\n", "", "def", "reset", "(", "self", ")", ":", "\n", "    ", "self", ".", "num_steps", "=", "0", "\n", "return", "self", ".", "env", ".", "reset", "(", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "self", ".", "num_steps", "+=", "1", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "if", "self", ".", "num_steps", ">=", "self", ".", "max_episode_steps", ":", "\n", "      ", "done", "=", "True", "\n", "", "if", "isinstance", "(", "reward", ",", "np", ".", "ndarray", ")", ":", "\n", "      ", "reward", "=", "reward", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "      ", "reward", "=", "float", "(", "reward", ")", "\n", "", "return", "obs", ".", "astype", "(", "np", ".", "float32", ")", ",", "reward", ",", "done", ",", "info", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.normalizer_test.NormalizerTest.test_normalization": [[24, 36], ["seed_rl.common.normalizer.Normalizer", "tensorflow.random.uniform", "range", "seed_rl.common.normalizer.Normalizer.", "tensorflow.debugging.assert_near", "tensorflow.debugging.assert_near", "seed_rl.common.normalizer.Normalizer.update", "tensorflow.reduce_mean", "tensorflow.zeros", "tensorflow.math.reduce_std", "tensorflow.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.update"], ["  ", "def", "test_normalization", "(", "self", ")", ":", "\n", "    ", "norm", "=", "normalizer", ".", "Normalizer", "(", "eps", "=", "0.", ",", "clip_range", "=", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ")", ")", "\n", "data", "=", "tf", ".", "random", ".", "uniform", "(", "(", "100", ",", "32", ")", ")", "\n", "for", "_", "in", "range", "(", "5", ")", ":", "\n", "      ", "norm", ".", "update", "(", "data", ")", "\n", "", "normalized", "=", "norm", "(", "data", ")", "\n", "tf", ".", "debugging", ".", "assert_near", "(", "tf", ".", "reduce_mean", "(", "normalized", ",", "axis", "=", "0", ")", ",", "\n", "tf", ".", "zeros", "(", "32", ")", ",", "\n", "atol", "=", "1e-4", ")", "\n", "tf", ".", "debugging", ".", "assert_near", "(", "tf", ".", "math", ".", "reduce_std", "(", "normalized", ",", "axis", "=", "0", ")", ",", "\n", "tf", ".", "ones", "(", "32", ")", ",", "\n", "atol", "=", "1e-4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.normalizer_test.NormalizerTest.test_normalizer_many_replicas": [[37, 71], ["tensorflow.distribute.cluster_resolver.TPUClusterResolver", "tensorflow.distribute.experimental.TPUStrategy", "tensorflow.tpu.experimental.initialize_tpu_system", "tensorflow.tpu.experimental.DeviceAssignment.build", "tensorflow.distribute.experimental.TPUStrategy", "tensorflow.random.uniform", "range", "seed_rl.common.normalizer.Normalizer.", "tensorflow.debugging.assert_near", "tensorflow.debugging.assert_near", "tensorflow.distribute.experimental.TPUStrategy.scope", "seed_rl.common.normalizer.Normalizer", "seed_rl.common.normalizer.Normalizer.", "seed_rl.common.normalizer.Normalizer.update", "tensorflow.distribute.experimental.TPUStrategy.run", "seed_rl.common.normalizer.Normalizer.finish_update", "tensorflow.reduce_mean", "tensorflow.zeros", "tensorflow.math.reduce_std", "tensorflow.ones", "tensorflow.distribute.experimental.TPUStrategy.experimental_local_results", "tensorflow.debugging.assert_equal", "tensorflow.norm"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.build", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.update", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.finish_update"], ["", "def", "test_normalizer_many_replicas", "(", "self", ")", ":", "\n", "    ", "resolver", "=", "tf", ".", "distribute", ".", "cluster_resolver", ".", "TPUClusterResolver", "(", "''", ")", "\n", "strategy", "=", "tf", ".", "distribute", ".", "experimental", ".", "TPUStrategy", "(", "resolver", ")", "\n", "topology", "=", "tf", ".", "tpu", ".", "experimental", ".", "initialize_tpu_system", "(", "resolver", ")", "\n", "training_da", "=", "tf", ".", "tpu", ".", "experimental", ".", "DeviceAssignment", ".", "build", "(", "\n", "topology", ",", "num_replicas", "=", "1", ")", "\n", "training_strategy", "=", "tf", ".", "distribute", ".", "experimental", ".", "TPUStrategy", "(", "\n", "resolver", ",", "device_assignment", "=", "training_da", ")", "\n", "\n", "data", "=", "tf", ".", "random", ".", "uniform", "(", "(", "100", ",", "32", ")", ")", "\n", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "norm", "=", "normalizer", ".", "Normalizer", "(", "eps", "=", "0.", ",", "clip_range", "=", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ")", ")", "\n", "norm", "(", "data", ")", "# create the variables", "\n", "\n", "", "@", "tf", ".", "function", "\n", "def", "training_step", "(", ")", ":", "\n", "      ", "norm", ".", "update", "(", "data", ",", "only_accumulate", "=", "True", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "5", ")", ":", "\n", "      ", "training_strategy", ".", "run", "(", "training_step", ")", "\n", "norm", ".", "finish_update", "(", ")", "\n", "\n", "", "normalized", "=", "norm", "(", "data", ")", "\n", "tf", ".", "debugging", ".", "assert_near", "(", "tf", ".", "reduce_mean", "(", "normalized", ",", "axis", "=", "0", ")", ",", "\n", "tf", ".", "zeros", "(", "32", ")", ",", "\n", "atol", "=", "1e-4", ")", "\n", "tf", ".", "debugging", ".", "assert_near", "(", "tf", ".", "math", ".", "reduce_std", "(", "normalized", ",", "axis", "=", "0", ")", ",", "\n", "tf", ".", "ones", "(", "32", ")", ",", "\n", "atol", "=", "1e-4", ")", "\n", "\n", "for", "var", "in", "[", "norm", ".", "steps_acc", ",", "norm", ".", "sum_acc", ",", "norm", ".", "sumsq_acc", "]", ":", "\n", "      ", "var", "=", "training_strategy", ".", "experimental_local_results", "(", "var", ")", "\n", "tf", ".", "debugging", ".", "assert_equal", "(", "tf", ".", "norm", "(", "var", ")", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.agents_test.AgentsTest.test_agent_is_checkpointable": [[25, 48], ["seed_rl.dmlab.networks.ImpalaDeep", "agents_test._run_actor", "os.path.join", "tensorflow.train.Checkpoint", "tensorflow.train.Checkpoint.save", "agents_test._run_actor", "tensorflow.train.latest_checkpoint", "tensorflow.train.Checkpoint.restore().assert_consumed", "agents_test._run_actor", "agents_test.AgentsTest.assertEqual", "agents_test.AgentsTest.assertAllEqual", "agents_test.AgentsTest.assertNotAllEqual", "v.assign_add", "len", "tensorflow.broadcast_to", "tensorflow.train.Checkpoint.restore"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.tests.agents_test._run_actor", "home.repos.pwc.inspect_result.google-research_seed_rl.tests.agents_test._run_actor", "home.repos.pwc.inspect_result.google-research_seed_rl.tests.agents_test._run_actor"], ["  ", "def", "test_agent_is_checkpointable", "(", "self", ")", ":", "\n", "    ", "agent", "=", "networks", ".", "ImpalaDeep", "(", "9", ")", "\n", "output0", "=", "_run_actor", "(", "agent", ")", "\n", "\n", "checkpoint_dir", "=", "'/tmp/training_checkpoints'", "\n", "checkpoint_prefix", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "'model.ckpt'", ")", "\n", "ckpt", "=", "tf", ".", "train", ".", "Checkpoint", "(", "agent", "=", "agent", ")", "\n", "\n", "ckpt", ".", "save", "(", "file_prefix", "=", "checkpoint_prefix", ")", "\n", "\n", "for", "v", "in", "agent", ".", "trainable_variables", ":", "\n", "      ", "v", ".", "assign_add", "(", "tf", ".", "broadcast_to", "(", "1.", ",", "v", ".", "shape", ")", ")", "\n", "\n", "", "output1", "=", "_run_actor", "(", "agent", ")", "\n", "\n", "ckpt_path", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "checkpoint_dir", ")", "\n", "ckpt", ".", "restore", "(", "ckpt_path", ")", ".", "assert_consumed", "(", ")", "\n", "\n", "output2", "=", "_run_actor", "(", "agent", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "agent", ".", "trainable_variables", ")", ",", "39", ")", "\n", "self", ".", "assertAllEqual", "(", "output0", "[", "0", "]", ".", "policy_logits", ",", "output2", "[", "0", "]", ".", "policy_logits", ")", "\n", "self", ".", "assertNotAllEqual", "(", "output0", "[", "0", "]", ".", "policy_logits", ",", "output1", "[", "0", "]", ".", "policy_logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.agents_test._run_actor": [[50, 60], ["agent.initial_state", "tensorflow.ones", "agent", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.zeros"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state"], ["", "", "def", "_run_actor", "(", "agent", ")", ":", "\n", "  ", "initial_agent_state", "=", "agent", ".", "initial_state", "(", "1", ")", "\n", "observation", "=", "tf", ".", "ones", "(", "\n", "shape", "=", "(", "1", ",", "72", ",", "96", ",", "3", ")", ",", "\n", "dtype", "=", "tf", ".", "uint8", ",", "\n", ")", "\n", "initial_env_output", "=", "(", "tf", ".", "constant", "(", "[", "2.", "]", ")", ",", "tf", ".", "constant", "(", "[", "False", "]", ")", ",", "observation", ",", "\n", "tf", ".", "constant", "(", "[", "False", "]", ")", ",", "tf", ".", "constant", "(", "[", "1", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ",", ")", "\n", "return", "agent", "(", "tf", ".", "zeros", "(", "[", "1", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "initial_env_output", ",", "\n", "initial_agent_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.vtrace_test.LogProbsFromLogitsAndActionsTest.test_log_probs_from_logits_and_actions": [[88, 116], ["numpy.random.randint", "seed_rl.common.parametric_distribution.categorical_distribution", "seed_rl.common.parametric_distribution.categorical_distribution.log_prob", "vtrace_test.LogProbsFromLogitsAndActionsTest.test_log_probs_from_logits_and_actions.index_with_mask"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.categorical_distribution", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.log_prob"], ["  ", "def", "test_log_probs_from_logits_and_actions", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests log_probs_from_logits_and_actions.\"\"\"", "\n", "batch_size", "=", "2", "\n", "seq_len", "=", "7", "\n", "num_actions", "=", "3", "\n", "\n", "policy_logits", "=", "_shaped_arange", "(", "seq_len", ",", "batch_size", ",", "num_actions", ")", "+", "10", "\n", "actions", "=", "np", ".", "random", ".", "randint", "(", "\n", "0", ",", "num_actions", "-", "1", ",", "size", "=", "(", "seq_len", ",", "batch_size", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "categorical_distribution", "=", "parametric_distribution", ".", "categorical_distribution", "(", "\n", "num_actions", ",", "'int32'", ")", "\n", "action_log_probs_tensor", "=", "categorical_distribution", ".", "log_prob", "(", "\n", "policy_logits", ",", "actions", ")", "\n", "\n", "# Ground Truth", "\n", "# Using broadcasting to create a mask that indexes action logits", "\n", "action_index_mask", "=", "actions", "[", "...", ",", "None", "]", "==", "np", ".", "arange", "(", "num_actions", ")", "\n", "\n", "def", "index_with_mask", "(", "array", ",", "mask", ")", ":", "\n", "      ", "return", "array", "[", "mask", "]", ".", "reshape", "(", "*", "array", ".", "shape", "[", ":", "-", "1", "]", ")", "\n", "\n", "# Note: Normally log(softmax) is not a good idea because it's not", "\n", "# numerically stable. However, in this test we have well-behaved values.", "\n", "", "ground_truth_v", "=", "index_with_mask", "(", "\n", "np", ".", "log", "(", "_softmax", "(", "policy_logits", ")", ")", ",", "action_index_mask", ")", "\n", "\n", "self", ".", "assertAllClose", "(", "ground_truth_v", ",", "action_log_probs_tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.vtrace_test.VtraceTest.test_vtrace": [[120, 146], ["seed_rl.common.vtrace.from_importance_weights", "vtrace_test._ground_truth_calculation", "vtrace_test.VtraceTest.assertAllClose", "vtrace_test._shaped_arange", "tensorflow.zeros_like", "numpy.array", "vtrace_test._shaped_arange", "vtrace_test._shaped_arange", "vtrace_test._shaped_arange", "range", "range"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.vtrace.from_importance_weights", "home.repos.pwc.inspect_result.google-research_seed_rl.tests.vtrace_test._ground_truth_calculation", "home.repos.pwc.inspect_result.google-research_seed_rl.tests.vtrace_test._shaped_arange", "home.repos.pwc.inspect_result.google-research_seed_rl.tests.vtrace_test._shaped_arange", "home.repos.pwc.inspect_result.google-research_seed_rl.tests.vtrace_test._shaped_arange", "home.repos.pwc.inspect_result.google-research_seed_rl.tests.vtrace_test._shaped_arange"], ["  ", "def", "test_vtrace", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests V-trace against ground truth data calculated in python.\"\"\"", "\n", "batch_size", "=", "5", "\n", "seq_len", "=", "5", "\n", "\n", "# Create log_rhos such that rho will span from near-zero to above the", "\n", "# clipping thresholds. In particular, calculate log_rhos in [-2.5, 2.5),", "\n", "# so that rho is in approx [0.08, 12.2).", "\n", "log_rhos", "=", "_shaped_arange", "(", "seq_len", ",", "batch_size", ")", "/", "(", "batch_size", "*", "seq_len", ")", "\n", "log_rhos", "=", "5", "*", "(", "log_rhos", "-", "0.5", ")", "# [0.0, 1.0) -> [-2.5, 2.5).", "\n", "values", "=", "{", "\n", "'behaviour_action_log_probs'", ":", "tf", ".", "zeros_like", "(", "log_rhos", ")", ",", "\n", "'target_action_log_probs'", ":", "log_rhos", ",", "\n", "# T, B where B_i: [0.9 / (i+1)] * T", "\n", "'discounts'", ":", "np", ".", "array", "(", "[", "[", "0.9", "/", "(", "b", "+", "1", ")", "for", "b", "in", "range", "(", "batch_size", ")", "]", "\n", "for", "_", "in", "range", "(", "seq_len", ")", "]", ")", ",", "\n", "'rewards'", ":", "_shaped_arange", "(", "seq_len", ",", "batch_size", ")", ",", "\n", "'values'", ":", "_shaped_arange", "(", "seq_len", ",", "batch_size", ")", "/", "batch_size", ",", "\n", "'bootstrap_value'", ":", "_shaped_arange", "(", "batch_size", ")", "+", "1.0", ",", "\n", "'clip_rho_threshold'", ":", "3.7", ",", "\n", "'clip_pg_rho_threshold'", ":", "2.2", ",", "\n", "}", "\n", "\n", "output", "=", "vtrace", ".", "from_importance_weights", "(", "**", "values", ")", "\n", "ground_truth_v", "=", "_ground_truth_calculation", "(", "**", "values", ")", "\n", "self", ".", "assertAllClose", "(", "output", ",", "ground_truth_v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.vtrace_test._shaped_arange": [[31, 34], ["numpy.arange().reshape", "numpy.arange", "numpy.prod"], "function", ["None"], ["def", "_shaped_arange", "(", "*", "shape", ")", ":", "\n", "  ", "\"\"\"Runs np.arange, converts to float and reshapes.\"\"\"", "\n", "return", "np", ".", "arange", "(", "np", ".", "prod", "(", "shape", ")", ",", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "*", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.vtrace_test._softmax": [[36, 39], ["numpy.exp", "numpy.sum", "numpy.exp"], "function", ["None"], ["", "def", "_softmax", "(", "logits", ")", ":", "\n", "  ", "\"\"\"Applies softmax non-linearity on inputs.\"\"\"", "\n", "return", "np", ".", "exp", "(", "logits", ")", "/", "np", ".", "sum", "(", "np", ".", "exp", "(", "logits", ")", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.vtrace_test._ground_truth_calculation": [[41, 83], ["len", "numpy.exp", "numpy.minimum", "numpy.concatenate", "range", "numpy.stack", "seed_rl.common.vtrace.VTraceReturns", "numpy.minimum", "numpy.minimum", "numpy.copy", "range", "np.stack.append", "numpy.concatenate", "numpy.prod", "numpy.prod"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append"], ["", "def", "_ground_truth_calculation", "(", "discounts", ",", "behaviour_action_log_probs", ",", "\n", "target_action_log_probs", ",", "rewards", ",", "values", ",", "\n", "bootstrap_value", ",", "clip_rho_threshold", ",", "\n", "clip_pg_rho_threshold", ")", ":", "\n", "  ", "\"\"\"Calculates the ground truth for V-trace in Python/Numpy.\"\"\"", "\n", "log_rhos", "=", "target_action_log_probs", "-", "behaviour_action_log_probs", "\n", "vs", "=", "[", "]", "\n", "seq_len", "=", "len", "(", "discounts", ")", "\n", "rhos", "=", "np", ".", "exp", "(", "log_rhos", ")", "\n", "cs", "=", "np", ".", "minimum", "(", "rhos", ",", "1.0", ")", "\n", "clipped_rhos", "=", "rhos", "\n", "if", "clip_rho_threshold", ":", "\n", "    ", "clipped_rhos", "=", "np", ".", "minimum", "(", "rhos", ",", "clip_rho_threshold", ")", "\n", "", "clipped_pg_rhos", "=", "rhos", "\n", "if", "clip_pg_rho_threshold", ":", "\n", "    ", "clipped_pg_rhos", "=", "np", ".", "minimum", "(", "rhos", ",", "clip_pg_rho_threshold", ")", "\n", "\n", "# This is a very inefficient way to calculate the V-trace ground truth.", "\n", "# We calculate it this way because it is close to the mathematical notation of", "\n", "# V-trace.", "\n", "# v_s = V(x_s)", "\n", "#       + \\sum^{T-1}_{t=s} \\gamma^{t-s}", "\n", "#         * \\prod_{i=s}^{t-1} c_i", "\n", "#         * \\rho_t (r_t + \\gamma V(x_{t+1}) - V(x_t))", "\n", "# Note that when we take the product over c_i, we write `s:t` as the notation", "\n", "# of the paper is inclusive of the `t-1`, but Python is exclusive.", "\n", "# Also note that np.prod([]) == 1.", "\n", "", "values_t_plus_1", "=", "np", ".", "concatenate", "(", "[", "values", ",", "bootstrap_value", "[", "None", ",", ":", "]", "]", ",", "axis", "=", "0", ")", "\n", "for", "s", "in", "range", "(", "seq_len", ")", ":", "\n", "    ", "v_s", "=", "np", ".", "copy", "(", "values", "[", "s", "]", ")", "# Very important copy.", "\n", "for", "t", "in", "range", "(", "s", ",", "seq_len", ")", ":", "\n", "      ", "v_s", "+=", "(", "\n", "np", ".", "prod", "(", "discounts", "[", "s", ":", "t", "]", ",", "axis", "=", "0", ")", "*", "np", ".", "prod", "(", "cs", "[", "s", ":", "t", "]", ",", "\n", "axis", "=", "0", ")", "*", "clipped_rhos", "[", "t", "]", "*", "\n", "(", "rewards", "[", "t", "]", "+", "discounts", "[", "t", "]", "*", "values_t_plus_1", "[", "t", "+", "1", "]", "-", "values", "[", "t", "]", ")", ")", "\n", "", "vs", ".", "append", "(", "v_s", ")", "\n", "", "vs", "=", "np", ".", "stack", "(", "vs", ",", "axis", "=", "0", ")", "\n", "pg_advantages", "=", "(", "\n", "clipped_pg_rhos", "*", "(", "rewards", "+", "discounts", "*", "np", ".", "concatenate", "(", "\n", "[", "vs", "[", "1", ":", "]", ",", "bootstrap_value", "[", "None", ",", ":", "]", "]", ",", "axis", "=", "0", ")", "-", "values", ")", ")", "\n", "\n", "return", "vtrace", ".", "VTraceReturns", "(", "vs", "=", "vs", ",", "pg_advantages", "=", "pg_advantages", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.NonDyingEnvsTest.test_basic": [[28, 35], ["seed_rl.common.utils.get_non_dying_envs", "utils_test.NonDyingEnvsTest.assertAllEqual", "utils_test.NonDyingEnvsTest.assertAllEqual", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.get_non_dying_envs"], ["  ", "def", "test_basic", "(", "self", ")", ":", "\n", "    ", "nondying_envs_mask", ",", "nondying_env_ids", "=", "utils", ".", "get_non_dying_envs", "(", "\n", "envs_needing_reset", "=", "tf", ".", "constant", "(", "[", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "reset_mask", "=", "tf", ".", "constant", "(", "[", "False", ",", "False", "]", ")", ",", "\n", "env_ids", "=", "tf", ".", "constant", "(", "[", "0", ",", "1", "]", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "nondying_envs_mask", ",", "[", "True", ",", "True", "]", ")", "\n", "self", ".", "assertAllEqual", "(", "nondying_env_ids", ",", "[", "0", ",", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.NonDyingEnvsTest.test_has_resets": [[36, 43], ["seed_rl.common.utils.get_non_dying_envs", "utils_test.NonDyingEnvsTest.assertAllEqual", "utils_test.NonDyingEnvsTest.assertAllEqual", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.get_non_dying_envs"], ["", "def", "test_has_resets", "(", "self", ")", ":", "\n", "    ", "nondying_envs_mask", ",", "nondying_env_ids", "=", "utils", ".", "get_non_dying_envs", "(", "\n", "envs_needing_reset", "=", "tf", ".", "constant", "(", "[", "6", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "reset_mask", "=", "tf", ".", "constant", "(", "[", "False", ",", "True", "]", ")", ",", "\n", "env_ids", "=", "tf", ".", "constant", "(", "[", "5", ",", "6", "]", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "nondying_envs_mask", ",", "[", "True", ",", "True", "]", ")", "\n", "self", ".", "assertAllEqual", "(", "nondying_env_ids", ",", "[", "5", ",", "6", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.NonDyingEnvsTest.test_has_dying_env": [[44, 51], ["seed_rl.common.utils.get_non_dying_envs", "utils_test.NonDyingEnvsTest.assertAllEqual", "utils_test.NonDyingEnvsTest.assertAllEqual", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.get_non_dying_envs"], ["", "def", "test_has_dying_env", "(", "self", ")", ":", "\n", "    ", "nondying_envs_mask", ",", "nondying_env_ids", "=", "utils", ".", "get_non_dying_envs", "(", "\n", "envs_needing_reset", "=", "tf", ".", "constant", "(", "[", "6", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "reset_mask", "=", "tf", ".", "constant", "(", "[", "False", ",", "False", ",", "True", ",", "False", "]", ")", ",", "\n", "env_ids", "=", "tf", ".", "constant", "(", "[", "0", ",", "5", ",", "6", ",", "6", "]", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "nondying_envs_mask", ",", "[", "True", ",", "True", ",", "True", ",", "False", "]", ")", "\n", "self", ".", "assertAllEqual", "(", "nondying_env_ids", ",", "[", "0", ",", "5", ",", "6", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.NonDyingEnvsTest.test_repeated_dying_envs": [[52, 58], ["utils_test.NonDyingEnvsTest.assertRaises", "seed_rl.common.utils.get_non_dying_envs", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.get_non_dying_envs"], ["", "def", "test_repeated_dying_envs", "(", "self", ")", ":", "\n", "    ", "with", "self", ".", "assertRaises", "(", "tf", ".", "errors", ".", "InvalidArgumentError", ")", ":", "\n", "      ", "utils", ".", "get_non_dying_envs", "(", "\n", "envs_needing_reset", "=", "tf", ".", "constant", "(", "[", "6", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "reset_mask", "=", "tf", ".", "constant", "(", "[", "False", ",", "False", ",", "False", ",", "True", ",", "True", "]", ")", ",", "\n", "env_ids", "=", "tf", ".", "constant", "(", "[", "0", ",", "5", ",", "6", ",", "6", ",", "6", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.NonDyingEnvsTest.test_multiple_new_transitions": [[59, 68], ["utils_test.NonDyingEnvsTest.assertRaises", "seed_rl.common.utils.get_non_dying_envs", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.get_non_dying_envs"], ["", "", "def", "test_multiple_new_transitions", "(", "self", ")", ":", "\n", "    ", "with", "self", ".", "assertRaises", "(", "tf", ".", "errors", ".", "InvalidArgumentError", ")", ":", "\n", "      ", "utils", ".", "get_non_dying_envs", "(", "\n", "# Such duplicate will happen a given actor has 2 new transitions with", "\n", "# new run IDs (e.g. restarted twice while the same inference batch is", "\n", "# being processed).", "\n", "envs_needing_reset", "=", "tf", ".", "constant", "(", "[", "1", ",", "1", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "reset_mask", "=", "tf", ".", "constant", "(", "[", "False", ",", "True", ",", "True", ",", "False", "]", ")", ",", "\n", "env_ids", "=", "tf", ".", "constant", "(", "[", "0", ",", "1", ",", "1", ",", "2", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.UnrollStoreTest.test_duplicate_actor_id": [[72, 79], ["seed_rl.common.utils.UnrollStore", "utils_test.UnrollStoreTest.assertRaises", "seed_rl.common.utils.UnrollStore.append", "tensorflow.TensorSpec", "tensorflow.constant", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append"], ["  ", "def", "test_duplicate_actor_id", "(", "self", ")", ":", "\n", "    ", "store", "=", "utils", ".", "UnrollStore", "(", "\n", "num_envs", "=", "2", ",", "unroll_length", "=", "3", ",", "timestep_specs", "=", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", ")", "\n", "with", "self", ".", "assertRaises", "(", "tf", ".", "errors", ".", "InvalidArgumentError", ")", ":", "\n", "      ", "store", ".", "append", "(", "\n", "tf", ".", "constant", "(", "[", "2", ",", "2", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "constant", "(", "[", "42", ",", "43", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.UnrollStoreTest.test_full": [[80, 161], ["seed_rl.common.utils.UnrollStore", "tensorflow.data.Dataset.from_generator", "dataset.batch.batch.batch", "iter", "next", "seed_rl.common.utils.UnrollStore.reset", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "utils_test.UnrollStoreTest.assertAllEqual", "next", "seed_rl.common.utils.UnrollStore.reset", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "utils_test.UnrollStoreTest.assertAllEqual", "next", "seed_rl.common.utils.UnrollStore.reset", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "utils_test.UnrollStoreTest.assertAllEqual", "next", "seed_rl.common.utils.UnrollStore.reset", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "utils_test.UnrollStoreTest.assertAllEqual", "next", "seed_rl.common.utils.UnrollStore.reset", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "utils_test.UnrollStoreTest.assertAllEqual", "next", "seed_rl.common.utils.UnrollStore.reset", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "utils_test.UnrollStoreTest.assertAllEqual", "next", "seed_rl.common.utils.UnrollStore.reset", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "utils_test.UnrollStoreTest.assertAllEqual", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.constant", "tensorflow.constant", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.constant", "tensorflow.constant", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append"], ["", "", "def", "test_full", "(", "self", ")", ":", "\n", "    ", "store", "=", "utils", ".", "UnrollStore", "(", "\n", "num_envs", "=", "4", ",", "unroll_length", "=", "3", ",", "timestep_specs", "=", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", ")", "\n", "\n", "def", "gen", "(", ")", ":", "\n", "      ", "yield", "False", ",", "0", ",", "10", "\n", "yield", "False", ",", "2", ",", "30", "\n", "yield", "False", ",", "1", ",", "20", "\n", "\n", "yield", "False", ",", "0", ",", "11", "\n", "yield", "False", ",", "2", ",", "31", "\n", "yield", "False", ",", "3", ",", "40", "\n", "\n", "yield", "False", ",", "0", ",", "12", "\n", "yield", "False", ",", "2", ",", "32", "\n", "yield", "False", ",", "3", ",", "41", "\n", "\n", "yield", "False", ",", "0", ",", "13", "# Unroll: 10, 11, 12, 13", "\n", "yield", "False", ",", "1", ",", "21", "\n", "yield", "True", ",", "2", ",", "33", "# No unroll because of reset", "\n", "\n", "yield", "False", ",", "0", ",", "14", "\n", "yield", "False", ",", "2", ",", "34", "\n", "yield", "False", ",", "3", ",", "42", "\n", "\n", "yield", "False", ",", "0", ",", "15", "\n", "yield", "False", ",", "1", ",", "22", "\n", "yield", "False", ",", "2", ",", "35", "\n", "\n", "yield", "False", ",", "0", ",", "16", "# Unroll: 13, 14, 15, 16", "\n", "yield", "False", ",", "1", ",", "23", "# Unroll: 20, 21, 22, 23", "\n", "yield", "False", ",", "2", ",", "36", "# Unroll: 33, 34, 35, 36", "\n", "\n", "", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "gen", ",", "(", "tf", ".", "bool", ",", "tf", ".", "int32", ",", "tf", ".", "int32", ")", ",", "\n", "(", "[", "]", ",", "[", "]", ",", "[", "]", ")", ")", "\n", "dataset", "=", "dataset", ".", "batch", "(", "3", ",", "drop_remainder", "=", "True", ")", "\n", "i", "=", "iter", "(", "dataset", ")", "\n", "\n", "should_reset", ",", "env_ids", ",", "values", "=", "next", "(", "i", ")", "\n", "store", ".", "reset", "(", "env_ids", "[", "should_reset", "]", ")", "\n", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "env_ids", ",", "values", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "zeros", "(", "[", "0", "]", ")", ",", "completed_ids", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "zeros", "(", "[", "0", ",", "4", "]", ")", ",", "unrolls", ")", "\n", "\n", "should_reset", ",", "env_ids", ",", "values", "=", "next", "(", "i", ")", "\n", "store", ".", "reset", "(", "env_ids", "[", "should_reset", "]", ")", "\n", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "env_ids", ",", "values", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "zeros", "(", "[", "0", "]", ")", ",", "completed_ids", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "zeros", "(", "[", "0", ",", "4", "]", ")", ",", "unrolls", ")", "\n", "\n", "should_reset", ",", "env_ids", ",", "values", "=", "next", "(", "i", ")", "\n", "store", ".", "reset", "(", "env_ids", "[", "should_reset", "]", ")", "\n", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "env_ids", ",", "values", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "zeros", "(", "[", "0", "]", ")", ",", "completed_ids", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "zeros", "(", "[", "0", ",", "4", "]", ")", ",", "unrolls", ")", "\n", "\n", "should_reset", ",", "env_ids", ",", "values", "=", "next", "(", "i", ")", "\n", "store", ".", "reset", "(", "env_ids", "[", "should_reset", "]", ")", "\n", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "env_ids", ",", "values", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "constant", "(", "[", "0", "]", ")", ",", "completed_ids", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "constant", "(", "[", "[", "10", ",", "11", ",", "12", ",", "13", "]", "]", ")", ",", "unrolls", ")", "\n", "\n", "should_reset", ",", "env_ids", ",", "values", "=", "next", "(", "i", ")", "\n", "store", ".", "reset", "(", "env_ids", "[", "should_reset", "]", ")", "\n", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "env_ids", ",", "values", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "zeros", "(", "[", "0", "]", ")", ",", "completed_ids", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "zeros", "(", "[", "0", ",", "4", "]", ")", ",", "unrolls", ")", "\n", "\n", "should_reset", ",", "env_ids", ",", "values", "=", "next", "(", "i", ")", "\n", "store", ".", "reset", "(", "env_ids", "[", "should_reset", "]", ")", "\n", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "env_ids", ",", "values", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "zeros", "(", "[", "0", "]", ")", ",", "completed_ids", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "zeros", "(", "[", "0", ",", "4", "]", ")", ",", "unrolls", ")", "\n", "\n", "should_reset", ",", "env_ids", ",", "values", "=", "next", "(", "i", ")", "\n", "store", ".", "reset", "(", "env_ids", "[", "should_reset", "]", ")", "\n", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "env_ids", ",", "values", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "constant", "(", "[", "0", ",", "1", ",", "2", "]", ")", ",", "completed_ids", ")", "\n", "self", ".", "assertAllEqual", "(", "\n", "tf", ".", "constant", "(", "[", "[", "13", ",", "14", ",", "15", ",", "16", "]", ",", "[", "20", ",", "21", ",", "22", ",", "23", "]", ",", "[", "33", ",", "34", ",", "35", ",", "36", "]", "]", ")", ",", "\n", "unrolls", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.UnrollStoreTest.test_structure": [[162, 190], ["collections.namedtuple", "seed_rl.common.utils.UnrollStore", "range", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "utils_test.UnrollStoreTest.assertAllEqual", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "utils_test.UnrollStoreTest.assertAllEqual", "tensorflow.range", "collections.namedtuple.", "tensorflow.range", "collections.namedtuple.", "collections.namedtuple.", "tensorflow.range", "collections.namedtuple.", "tensorflow.constant", "collections.namedtuple.", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.TensorSpec", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append"], ["", "def", "test_structure", "(", "self", ")", ":", "\n", "    ", "named_tuple", "=", "collections", ".", "namedtuple", "(", "'named_tuple'", ",", "'x y'", ")", "\n", "num_envs", "=", "2", "\n", "unroll_length", "=", "10", "\n", "store", "=", "utils", ".", "UnrollStore", "(", "\n", "num_envs", "=", "num_envs", ",", "\n", "unroll_length", "=", "unroll_length", ",", "\n", "timestep_specs", "=", "named_tuple", "(", "\n", "x", "=", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", ",", "y", "=", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", ")", ")", "\n", "for", "_", "in", "range", "(", "unroll_length", ")", ":", "\n", "      ", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "\n", "tf", ".", "range", "(", "num_envs", ")", ",", "\n", "named_tuple", "(", "\n", "tf", ".", "zeros", "(", "[", "num_envs", "]", ",", "tf", ".", "int32", ")", ",", "tf", ".", "zeros", "(", "[", "num_envs", "]", ",", "tf", ".", "int32", ")", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "constant", "(", "(", ")", ")", ",", "completed_ids", ")", "\n", "self", ".", "assertAllEqual", "(", "\n", "named_tuple", "(", "\n", "tf", ".", "zeros", "(", "[", "0", ",", "unroll_length", "+", "1", "]", ")", ",", "\n", "tf", ".", "zeros", "(", "[", "0", ",", "unroll_length", "+", "1", "]", ")", ")", ",", "unrolls", ")", "\n", "", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "\n", "tf", ".", "range", "(", "num_envs", ")", ",", "\n", "named_tuple", "(", "\n", "tf", ".", "zeros", "(", "[", "num_envs", "]", ",", "tf", ".", "int32", ")", ",", "tf", ".", "zeros", "(", "[", "num_envs", "]", ",", "tf", ".", "int32", ")", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "range", "(", "num_envs", ")", ",", "completed_ids", ")", "\n", "self", ".", "assertAllEqual", "(", "\n", "named_tuple", "(", "\n", "tf", ".", "zeros", "(", "[", "num_envs", ",", "unroll_length", "+", "1", "]", ")", ",", "\n", "tf", ".", "zeros", "(", "[", "num_envs", ",", "unroll_length", "+", "1", "]", ")", ")", ",", "unrolls", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.UnrollStoreTest.test_overlap_2": [[191, 272], ["seed_rl.common.utils.UnrollStore", "tensorflow.data.Dataset.from_generator", "dataset.batch.batch.batch", "iter", "next", "seed_rl.common.utils.UnrollStore.reset", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "next", "seed_rl.common.utils.UnrollStore.reset", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "next", "seed_rl.common.utils.UnrollStore.reset", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "utils_test.UnrollStoreTest.assertAllEqual", "next", "seed_rl.common.utils.UnrollStore.reset", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "next", "seed_rl.common.utils.UnrollStore.reset", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "utils_test.UnrollStoreTest.assertAllEqual", "next", "seed_rl.common.utils.UnrollStore.reset", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "next", "seed_rl.common.utils.UnrollStore.reset", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "utils_test.UnrollStoreTest.assertAllEqual", "next", "seed_rl.common.utils.UnrollStore.reset", "seed_rl.common.utils.UnrollStore.append", "utils_test.UnrollStoreTest.assertAllEqual", "utils_test.UnrollStoreTest.assertAllEqual", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.constant", "tensorflow.constant", "tensorflow.zeros", "tensorflow.constant", "tensorflow.constant", "tensorflow.zeros", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append"], ["", "def", "test_overlap_2", "(", "self", ")", ":", "\n", "    ", "store", "=", "utils", ".", "UnrollStore", "(", "\n", "num_envs", "=", "2", ",", "\n", "unroll_length", "=", "2", ",", "\n", "timestep_specs", "=", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", ",", "\n", "num_overlapping_steps", "=", "2", ")", "\n", "\n", "def", "gen", "(", ")", ":", "\n", "      ", "yield", "False", ",", "0", ",", "10", "\n", "yield", "False", ",", "1", ",", "20", "\n", "\n", "yield", "False", ",", "0", ",", "11", "\n", "yield", "False", ",", "1", ",", "21", "\n", "\n", "yield", "False", ",", "0", ",", "12", "# Unroll: 0, 0, 10, 11, 12", "\n", "yield", "True", ",", "1", ",", "22", "\n", "\n", "yield", "False", ",", "0", ",", "13", "\n", "yield", "False", ",", "1", ",", "23", "\n", "\n", "yield", "False", ",", "0", ",", "14", "# Unroll: 10, 11, 12, 13, 14", "\n", "yield", "False", ",", "1", ",", "24", "# Unroll: 0, 0, 22, 23, 24", "\n", "\n", "yield", "True", ",", "0", ",", "15", "\n", "yield", "False", ",", "1", ",", "25", "\n", "\n", "yield", "False", ",", "0", ",", "16", "\n", "yield", "False", ",", "1", ",", "26", "# Unroll: 22, 23, 24, 25, 26", "\n", "\n", "yield", "False", ",", "0", ",", "17", "# Unroll: 0, 0, 15, 16, 17", "\n", "yield", "False", ",", "1", ",", "27", "\n", "\n", "", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "gen", ",", "(", "tf", ".", "bool", ",", "tf", ".", "int32", ",", "tf", ".", "int32", ")", ",", "\n", "(", "[", "]", ",", "[", "]", ",", "[", "]", ")", ")", "\n", "dataset", "=", "dataset", ".", "batch", "(", "2", ",", "drop_remainder", "=", "True", ")", "\n", "i", "=", "iter", "(", "dataset", ")", "\n", "\n", "should_reset", ",", "env_ids", ",", "values", "=", "next", "(", "i", ")", "\n", "store", ".", "reset", "(", "env_ids", "[", "should_reset", "]", ")", "\n", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "env_ids", ",", "values", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "zeros", "(", "[", "0", "]", ")", ",", "completed_ids", ")", "\n", "\n", "should_reset", ",", "env_ids", ",", "values", "=", "next", "(", "i", ")", "\n", "store", ".", "reset", "(", "env_ids", "[", "should_reset", "]", ")", "\n", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "env_ids", ",", "values", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "zeros", "(", "[", "0", "]", ")", ",", "completed_ids", ")", "\n", "\n", "should_reset", ",", "env_ids", ",", "values", "=", "next", "(", "i", ")", "\n", "store", ".", "reset", "(", "env_ids", "[", "should_reset", "]", ")", "\n", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "env_ids", ",", "values", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "constant", "(", "[", "0", "]", ")", ",", "completed_ids", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "constant", "(", "[", "[", "0", ",", "0", ",", "10", ",", "11", ",", "12", "]", "]", ")", ",", "unrolls", ")", "\n", "\n", "should_reset", ",", "env_ids", ",", "values", "=", "next", "(", "i", ")", "\n", "store", ".", "reset", "(", "env_ids", "[", "should_reset", "]", ")", "\n", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "env_ids", ",", "values", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "zeros", "(", "[", "0", "]", ")", ",", "completed_ids", ")", "\n", "\n", "should_reset", ",", "env_ids", ",", "values", "=", "next", "(", "i", ")", "\n", "store", ".", "reset", "(", "env_ids", "[", "should_reset", "]", ")", "\n", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "env_ids", ",", "values", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "constant", "(", "[", "0", ",", "1", "]", ")", ",", "completed_ids", ")", "\n", "self", ".", "assertAllEqual", "(", "\n", "tf", ".", "constant", "(", "[", "[", "10", ",", "11", ",", "12", ",", "13", ",", "14", "]", ",", "[", "0", ",", "0", ",", "22", ",", "23", ",", "24", "]", "]", ")", ",", "unrolls", ")", "\n", "\n", "should_reset", ",", "env_ids", ",", "values", "=", "next", "(", "i", ")", "\n", "store", ".", "reset", "(", "env_ids", "[", "should_reset", "]", ")", "\n", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "env_ids", ",", "values", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "zeros", "(", "[", "0", "]", ")", ",", "completed_ids", ")", "\n", "\n", "should_reset", ",", "env_ids", ",", "values", "=", "next", "(", "i", ")", "\n", "store", ".", "reset", "(", "env_ids", "[", "should_reset", "]", ")", "\n", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "env_ids", ",", "values", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "constant", "(", "[", "1", "]", ")", ",", "completed_ids", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "constant", "(", "[", "[", "22", ",", "23", ",", "24", ",", "25", ",", "26", "]", "]", ")", ",", "unrolls", ")", "\n", "\n", "should_reset", ",", "env_ids", ",", "values", "=", "next", "(", "i", ")", "\n", "store", ".", "reset", "(", "env_ids", "[", "should_reset", "]", ")", "\n", "completed_ids", ",", "unrolls", "=", "store", ".", "append", "(", "env_ids", ",", "values", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "constant", "(", "[", "0", "]", ")", ",", "completed_ids", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "constant", "(", "[", "[", "0", ",", "0", ",", "15", ",", "16", ",", "17", "]", "]", ")", ",", "unrolls", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.AggregatorTest.test_full": [[276, 287], ["seed_rl.common.utils.Aggregator", "utils_test.AggregatorTest.assertAllEqual", "seed_rl.common.utils.Aggregator.add", "utils_test.AggregatorTest.assertAllEqual", "utils_test.AggregatorTest.assertAllEqual", "seed_rl.common.utils.Aggregator.reset", "utils_test.AggregatorTest.assertAllEqual", "seed_rl.common.utils.Aggregator.replace", "utils_test.AggregatorTest.assertAllEqual", "seed_rl.common.utils.Aggregator.read", "tensorflow.convert_to_tensor", "seed_rl.common.utils.Aggregator.read", "seed_rl.common.utils.Aggregator.read", "seed_rl.common.utils.Aggregator.read", "tensorflow.convert_to_tensor", "seed_rl.common.utils.Aggregator.read", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.add", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.replace", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.read", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.read", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.read", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.read", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.read"], ["  ", "def", "test_full", "(", "self", ")", ":", "\n", "    ", "agg", "=", "utils", ".", "Aggregator", "(", "num_envs", "=", "4", ",", "specs", "=", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", ")", "\n", "\n", "self", ".", "assertAllEqual", "(", "[", "0", ",", "0", ",", "0", ",", "0", "]", ",", "agg", ".", "read", "(", "[", "0", ",", "1", ",", "2", ",", "3", "]", ")", ")", "\n", "agg", ".", "add", "(", "[", "0", ",", "1", "]", ",", "tf", ".", "convert_to_tensor", "(", "[", "42", ",", "43", "]", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "[", "42", ",", "43", "]", ",", "agg", ".", "read", "(", "[", "0", ",", "1", "]", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "[", "42", ",", "43", ",", "0", ",", "0", "]", ",", "agg", ".", "read", "(", "[", "0", ",", "1", ",", "2", ",", "3", "]", ")", ")", "\n", "agg", ".", "reset", "(", "[", "0", "]", ")", "\n", "self", ".", "assertAllEqual", "(", "[", "0", ",", "43", ",", "0", ",", "0", "]", ",", "agg", ".", "read", "(", "[", "0", ",", "1", ",", "2", ",", "3", "]", ")", ")", "\n", "agg", ".", "replace", "(", "[", "0", ",", "2", "]", ",", "tf", ".", "convert_to_tensor", "(", "[", "1", ",", "2", "]", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "[", "1", ",", "43", ",", "2", ",", "0", "]", ",", "agg", ".", "read", "(", "[", "0", ",", "1", ",", "2", ",", "3", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.BatchApplyTest.test_simple": [[291, 302], ["seed_rl.common.utils.batch_apply", "utils_test.BatchApplyTest.assertAllEqual", "utils_test.BatchApplyTest.assertAllEqual", "tensorflow.constant", "tensorflow.constant", "tensorflow.reduce_sum", "tensorflow.reduce_max", "tensorflow.constant", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.batch_apply"], ["  ", "def", "test_simple", "(", "self", ")", ":", "\n", "\n", "    ", "def", "f", "(", "a", ",", "b", ")", ":", "\n", "      ", "return", "tf", ".", "reduce_sum", "(", "a", ",", "axis", "=", "-", "1", ")", ",", "tf", ".", "reduce_max", "(", "b", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "a_sum", ",", "b_max", "=", "utils", ".", "batch_apply", "(", "f", ",", "(", "\n", "tf", ".", "constant", "(", "[", "[", "[", "0", ",", "1", "]", ",", "[", "2", ",", "3", "]", "]", ",", "[", "[", "4", ",", "5", "]", ",", "[", "6", ",", "7", "]", "]", "]", ")", ",", "\n", "tf", ".", "constant", "(", "[", "[", "[", "8", ",", "9", "]", ",", "[", "10", ",", "11", "]", "]", ",", "[", "[", "12", ",", "13", "]", ",", "[", "14", ",", "15", "]", "]", "]", ")", ",", "\n", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "constant", "(", "[", "[", "1", ",", "5", "]", ",", "[", "9", ",", "13", "]", "]", ")", ",", "a_sum", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "constant", "(", "[", "[", "9", ",", "11", "]", ",", "[", "13", ",", "15", "]", "]", ")", ",", "b_max", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.PrioritizedReplayTest.test_simple": [[306, 324], ["seed_rl.common.utils.PrioritizedReplay", "seed_rl.common.utils.PrioritizedReplay.insert", "utils_test.PrioritizedReplayTest.assertAllEqual", "seed_rl.common.utils.PrioritizedReplay.sample", "utils_test.PrioritizedReplayTest.assertAllEqual", "utils_test.PrioritizedReplayTest.assertAllEqual", "seed_rl.common.utils.PrioritizedReplay.sample", "utils_test.PrioritizedReplayTest.assertAllEqual", "utils_test.PrioritizedReplayTest.assertAllEqual", "tensorflow.constant", "tensorflow.constant", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.PrioritizedReplay.insert", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], ["  ", "def", "test_simple", "(", "self", ")", ":", "\n", "    ", "rb", "=", "utils", ".", "PrioritizedReplay", "(", "\n", "size", "=", "2", ",", "\n", "specs", "=", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", ",", "\n", "importance_sampling_exponent", "=", ".5", ")", "\n", "\n", "insert_indices", "=", "rb", ".", "insert", "(", "tf", ".", "constant", "(", "[", "1", ",", "2", "]", ")", ",", "tf", ".", "constant", "(", "[", "1.", ",", "1.", "]", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "[", "0", ",", "1", "]", ",", "insert_indices", ")", "\n", "\n", "sampled_indices", ",", "weights", ",", "sampled_values", "=", "rb", ".", "sample", "(", "2", ",", ".5", ")", "\n", "\n", "self", ".", "assertAllEqual", "(", "sampled_indices", "+", "1", ",", "sampled_values", ")", "\n", "self", ".", "assertAllEqual", "(", "[", "1.", ",", "1.", "]", ",", "weights", ")", "\n", "\n", "sampled_indices", ",", "weights", ",", "sampled_values", "=", "rb", ".", "sample", "(", "2", ",", "0", ")", "\n", "\n", "self", ".", "assertAllEqual", "(", "sampled_indices", "+", "1", ",", "sampled_values", ")", "\n", "self", ".", "assertAllEqual", "(", "[", "1.", ",", "1.", "]", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.PrioritizedReplayTest.test_nests": [[325, 336], ["tensorflow.nest.map_structure", "seed_rl.common.utils.PrioritizedReplay", "seed_rl.common.utils.PrioritizedReplay.insert", "seed_rl.common.utils.PrioritizedReplay.sample", "tensorflow.nest.map_structure", "tensorflow.TensorSpec", "tensorflow.constant", "tensorflow.TensorSpec", "tensorflow.zeros"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.PrioritizedReplay.insert", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], ["", "def", "test_nests", "(", "self", ")", ":", "\n", "    ", "specs", "=", "(", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", ",", "[", "tf", ".", "TensorSpec", "(", "[", "2", "]", ",", "tf", ".", "int64", ")", "]", ")", "\n", "zeros", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "ts", ":", "tf", ".", "zeros", "(", "[", "1", "]", "+", "ts", ".", "shape", ",", "ts", ".", "dtype", ")", ",", "\n", "specs", ")", "\n", "rb", "=", "utils", ".", "PrioritizedReplay", "(", "\n", "size", "=", "2", ",", "specs", "=", "specs", ",", "importance_sampling_exponent", "=", ".5", ")", "\n", "\n", "_", "=", "rb", ".", "insert", "(", "zeros", ",", "tf", ".", "constant", "(", "[", "1.", "]", ")", ")", "\n", "_", ",", "_", ",", "sampled_values", "=", "rb", ".", "sample", "(", "1", ",", ".5", ")", "\n", "\n", "tf", ".", "nest", ".", "map_structure", "(", "self", ".", "assertAllEqual", ",", "zeros", ",", "sampled_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.PrioritizedReplayTest.test_update_priorities": [[337, 352], ["seed_rl.common.utils.PrioritizedReplay", "seed_rl.common.utils.PrioritizedReplay.insert", "utils_test.PrioritizedReplayTest.assertAllEqual", "seed_rl.common.utils.PrioritizedReplay.update_priorities", "seed_rl.common.utils.PrioritizedReplay.sample", "utils_test.PrioritizedReplayTest.assertAllEqual", "utils_test.PrioritizedReplayTest.assertAllEqual", "utils_test.PrioritizedReplayTest.assertAllEqual", "tensorflow.constant", "tensorflow.constant", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.PrioritizedReplay.insert", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.PrioritizedReplay.update_priorities", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], ["", "def", "test_update_priorities", "(", "self", ")", ":", "\n", "    ", "rb", "=", "utils", ".", "PrioritizedReplay", "(", "\n", "size", "=", "2", ",", "\n", "specs", "=", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", ",", "\n", "importance_sampling_exponent", "=", ".5", ")", "\n", "insert_indices", "=", "rb", ".", "insert", "(", "tf", ".", "constant", "(", "[", "1", ",", "2", "]", ")", ",", "tf", ".", "constant", "(", "[", "1.", ",", "1.", "]", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "[", "0", ",", "1", "]", ",", "insert_indices", ")", "\n", "\n", "rb", ".", "update_priorities", "(", "[", "0", "]", ",", "[", "100", "]", ")", "\n", "\n", "sampled_indices", ",", "weights", ",", "sampled_values", "=", "rb", ".", "sample", "(", "2", ",", ".5", ")", "\n", "\n", "self", ".", "assertAllEqual", "(", "[", "0", ",", "0", "]", ",", "sampled_indices", ")", "\n", "self", ".", "assertAllEqual", "(", "[", "1", ",", "1", "]", ",", "sampled_values", ")", "\n", "self", ".", "assertAllEqual", "(", "[", "1.", ",", "1.", "]", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.PrioritizedReplayTest.test_initial_priorities": [[353, 366], ["tensorflow.random.set_seed", "seed_rl.common.utils.PrioritizedReplay", "seed_rl.common.utils.PrioritizedReplay.insert", "seed_rl.common.utils.PrioritizedReplay.sample", "collections.Counter", "utils_test.PrioritizedReplayTest.assertGreater", "utils_test.PrioritizedReplayTest.assertLess", "tensorflow.constant", "tensorflow.constant", "sampled_values.numpy", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.PrioritizedReplay.insert", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], ["", "def", "test_initial_priorities", "(", "self", ")", ":", "\n", "    ", "tf", ".", "random", ".", "set_seed", "(", "5", ")", "\n", "rb", "=", "utils", ".", "PrioritizedReplay", "(", "\n", "size", "=", "2", ",", "\n", "specs", "=", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", ",", "\n", "importance_sampling_exponent", "=", ".5", ")", "\n", "rb", ".", "insert", "(", "tf", ".", "constant", "(", "[", "1", ",", "2", "]", ")", ",", "tf", ".", "constant", "(", "[", "0.1", ",", "0.9", "]", ")", ")", "\n", "\n", "num_sampled", "=", "1000", "\n", "_", ",", "_", ",", "sampled_values", "=", "rb", ".", "sample", "(", "num_sampled", ",", "1", ")", "\n", "counted_values", "=", "collections", ".", "Counter", "(", "sampled_values", ".", "numpy", "(", ")", ")", "\n", "self", ".", "assertGreater", "(", "counted_values", "[", "1", "]", ",", "num_sampled", "*", "0.1", "*", "0.7", ")", "\n", "self", ".", "assertLess", "(", "counted_values", "[", "1", "]", ",", "num_sampled", "*", "0.1", "*", "1.3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.PrioritizedReplayTest._check_weights": [[367, 376], ["zip", "utils_test.PrioritizedReplayTest.assertAllClose", "utils_test.PrioritizedReplayTest.assertAllClose", "v.numpy", "v.numpy", "v.numpy"], "methods", ["None"], ["", "def", "_check_weights", "(", "self", ",", "sampled_weights", ",", "sampled_values", ",", "expected_weights", ")", ":", "\n", "    ", "actual_weights", "=", "[", "None", ",", "None", "]", "\n", "for", "w", ",", "v", "in", "zip", "(", "sampled_weights", ",", "sampled_values", ")", ":", "\n", "      ", "if", "actual_weights", "[", "v", ".", "numpy", "(", ")", "]", "is", "None", ":", "\n", "        ", "actual_weights", "[", "v", ".", "numpy", "(", ")", "]", "=", "w", "\n", "", "else", ":", "\n", "        ", "self", ".", "assertAllClose", "(", "actual_weights", "[", "v", ".", "numpy", "(", ")", "]", ",", "w", ",", "\n", "msg", "=", "'v={}'", ".", "format", "(", "v", ")", ")", "\n", "", "", "self", ".", "assertAllClose", "(", "actual_weights", ",", "expected_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.PrioritizedReplayTest.test_importance_sampling_weights1": [[377, 391], ["tensorflow.random.set_seed", "seed_rl.common.utils.PrioritizedReplay", "seed_rl.common.utils.PrioritizedReplay.insert", "seed_rl.common.utils.PrioritizedReplay.sample", "numpy.array", "numpy.max", "utils_test.PrioritizedReplayTest._check_weights", "tensorflow.constant", "tensorflow.constant", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.PrioritizedReplay.insert", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample", "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.PrioritizedReplayTest._check_weights"], ["", "def", "test_importance_sampling_weights1", "(", "self", ")", ":", "\n", "    ", "tf", ".", "random", ".", "set_seed", "(", "5", ")", "\n", "rb", "=", "utils", ".", "PrioritizedReplay", "(", "\n", "size", "=", "2", ",", "\n", "specs", "=", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", ",", "\n", "importance_sampling_exponent", "=", "1", ")", "\n", "rb", ".", "insert", "(", "tf", ".", "constant", "(", "[", "0", ",", "1", "]", ")", ",", "tf", ".", "constant", "(", "[", "0.3", ",", "0.9", "]", ")", ")", "\n", "_", ",", "weights", ",", "sampled_values", "=", "rb", ".", "sample", "(", "100", ",", "1", ")", "\n", "expected_weights", "=", "np", ".", "array", "(", "[", "\n", "(", "0.3", "+", "0.9", ")", "/", "0.3", ",", "\n", "(", "0.3", "+", "0.9", ")", "/", "0.9", ",", "\n", "]", ")", "\n", "expected_weights", "/=", "np", ".", "max", "(", "expected_weights", ")", "\n", "self", ".", "_check_weights", "(", "weights", ",", "sampled_values", ",", "expected_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.PrioritizedReplayTest.test_importance_sampling_weights2": [[392, 406], ["tensorflow.random.set_seed", "seed_rl.common.utils.PrioritizedReplay", "seed_rl.common.utils.PrioritizedReplay.insert", "seed_rl.common.utils.PrioritizedReplay.sample", "numpy.array", "numpy.max", "utils_test.PrioritizedReplayTest._check_weights", "tensorflow.constant", "tensorflow.constant", "tensorflow.TensorSpec"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.PrioritizedReplay.insert", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample", "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.PrioritizedReplayTest._check_weights"], ["", "def", "test_importance_sampling_weights2", "(", "self", ")", ":", "\n", "    ", "tf", ".", "random", ".", "set_seed", "(", "5", ")", "\n", "rb", "=", "utils", ".", "PrioritizedReplay", "(", "\n", "size", "=", "2", ",", "\n", "specs", "=", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ")", ",", "\n", "importance_sampling_exponent", "=", ".3", ")", "\n", "rb", ".", "insert", "(", "tf", ".", "constant", "(", "[", "0", ",", "1", "]", ")", ",", "tf", ".", "constant", "(", "[", "0.3", ",", "0.9", "]", ")", ")", "\n", "_", ",", "weights", ",", "sampled_values", "=", "rb", ".", "sample", "(", "100", ",", ".7", ")", "\n", "\n", "inv_sampling_probs", "=", "np", ".", "array", "(", "[", "(", "(", "0.3", "**", ".7", "+", "0.9", "**", ".7", ")", "/", "0.3", "**", ".7", ")", ",", "\n", "(", "(", "0.3", "**", ".7", "+", "0.9", "**", ".7", ")", "/", "0.9", "**", ".7", ")", "]", ")", "\n", "expected_weights", "=", "inv_sampling_probs", "**", ".3", "\n", "expected_weights", "/=", "np", ".", "max", "(", "expected_weights", ")", "\n", "self", ".", "_check_weights", "(", "weights", ",", "sampled_values", ",", "expected_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.HindsightExperienceReplayTest.wrap": [[412, 424], ["collections.namedtuple", "collections.namedtuple.", "seed_rl.common.utils.EnvOutput", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.ones"], "methods", ["None"], ["  ", "def", "wrap", "(", "self", ",", "x", ",", "y", "=", "None", ")", ":", "\n", "    ", "unroll", "=", "collections", ".", "namedtuple", "(", "'unroll'", ",", "'env_outputs'", ")", "\n", "return", "unroll", "(", "\n", "env_outputs", "=", "utils", ".", "EnvOutput", "(", "\n", "observation", "=", "{", "\n", "'achieved_goal'", ":", "x", ",", "\n", "'desired_goal'", ":", "y", "if", "(", "y", "is", "not", "None", ")", "else", "x", "\n", "}", ",", "\n", "done", "=", "tf", ".", "zeros", "(", "x", ".", "shape", "[", ":", "-", "1", "]", ",", "tf", ".", "bool", ")", ",", "\n", "reward", "=", "tf", ".", "zeros", "(", "x", ".", "shape", "[", ":", "-", "1", "]", ",", "tf", ".", "float32", ")", ",", "\n", "abandoned", "=", "tf", ".", "zeros", "(", "x", ".", "shape", "[", ":", "-", "1", "]", ",", "tf", ".", "bool", ")", ",", "\n", "episode_step", "=", "tf", ".", "ones", "(", "x", ".", "shape", "[", ":", "-", "1", "]", ",", "tf", ".", "int32", ")", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.HindsightExperienceReplayTest.compute_reward_fn": [[425, 427], ["tensorflow.norm", "tensorflow.cast"], "methods", ["None"], ["", "def", "compute_reward_fn", "(", "self", ",", "achieved_goal", ",", "desired_goal", ")", ":", "\n", "    ", "return", "tf", ".", "norm", "(", "tf", ".", "cast", "(", "achieved_goal", "-", "desired_goal", ",", "tf", ".", "float32", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.HindsightExperienceReplayTest.test_subsampling": [[428, 451], ["seed_rl.common.utils.HindsightExperienceReplay", "seed_rl.common.utils.HindsightExperienceReplay.insert", "tensorflow.squeeze", "range", "utils_test.HindsightExperienceReplayTest.wrap", "tensorflow.constant", "utils_test.HindsightExperienceReplayTest.wrap", "tensorflow.constant", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "seed_rl.common.utils.HindsightExperienceReplay.sample"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.PrioritizedReplay.insert", "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.HindsightExperienceReplayTest.wrap", "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.HindsightExperienceReplayTest.wrap", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], ["", "def", "test_subsampling", "(", "self", ")", ":", "\n", "    ", "rb", "=", "utils", ".", "HindsightExperienceReplay", "(", "\n", "size", "=", "2", ",", "\n", "specs", "=", "self", ".", "wrap", "(", "tf", ".", "TensorSpec", "(", "[", "5", ",", "1", "]", ",", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "5", ",", "1", "]", ",", "tf", ".", "int32", ")", ")", ",", "\n", "importance_sampling_exponent", "=", "1", ",", "\n", "unroll_length", "=", "2", ",", "\n", "compute_reward_fn", "=", "self", ".", "compute_reward_fn", ",", "\n", "substitution_probability", "=", "0.", "\n", ")", "\n", "\n", "rb", ".", "insert", "(", "self", ".", "wrap", "(", "tf", ".", "constant", "(", "[", "[", "[", "10", "]", ",", "[", "20", "]", ",", "[", "30", "]", ",", "[", "40", "]", ",", "[", "50", "]", "]", "]", ")", ")", ",", "\n", "tf", ".", "constant", "(", "[", "1.", "]", ")", ")", "\n", "\n", "samples", "=", "rb", ".", "sample", "(", "1000", ",", "1.", ")", "[", "-", "1", "]", ".", "env_outputs", ".", "observation", "[", "'achieved_goal'", "]", "\n", "assert", "samples", ".", "shape", "==", "(", "1000", ",", "3", ",", "1", ")", "\n", "samples", "=", "tf", ".", "squeeze", "(", "samples", ",", "axis", "=", "-", "1", ")", "\n", "for", "i", "in", "range", "(", "samples", ".", "shape", "[", "0", "]", ")", ":", "\n", "      ", "assert", "samples", "[", "i", "]", "[", "0", "]", "in", "[", "10", ",", "20", ",", "30", "]", "\n", "assert", "samples", "[", "i", "]", "[", "1", "]", "==", "samples", "[", "i", "]", "[", "0", "]", "+", "10", "\n", "assert", "samples", "[", "i", "]", "[", "2", "]", "==", "samples", "[", "i", "]", "[", "0", "]", "+", "20", "\n", "", "for", "val", "in", "[", "10", ",", "20", ",", "30", "]", ":", "\n", "      ", "assert", "(", "samples", "[", ":", ",", "0", "]", "==", "val", ")", ".", "numpy", "(", ")", ".", "any", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.HindsightExperienceReplayTest.test_goal_substitution": [[452, 485], ["seed_rl.common.utils.HindsightExperienceReplay", "seed_rl.common.utils.HindsightExperienceReplay.insert", "tensorflow.nest.map_structure", "set", "range", "utils_test.HindsightExperienceReplayTest.wrap", "tensorflow.constant", "range", "len", "utils_test.HindsightExperienceReplayTest.wrap", "tensorflow.constant", "tensorflow.constant", "set.add", "tensorflow.TensorSpec", "tensorflow.TensorSpec", "seed_rl.common.utils.HindsightExperienceReplay.sample", "goal.numpy"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.PrioritizedReplay.insert", "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.HindsightExperienceReplayTest.wrap", "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.HindsightExperienceReplayTest.wrap", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.add", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], ["", "", "def", "test_goal_substitution", "(", "self", ")", ":", "\n", "    ", "rb", "=", "utils", ".", "HindsightExperienceReplay", "(", "\n", "size", "=", "2", ",", "\n", "specs", "=", "self", ".", "wrap", "(", "tf", ".", "TensorSpec", "(", "[", "5", ",", "2", "]", ",", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "[", "5", ",", "2", "]", ",", "tf", ".", "int32", ")", ")", ",", "\n", "importance_sampling_exponent", "=", "1", ",", "\n", "unroll_length", "=", "4", ",", "\n", "compute_reward_fn", "=", "self", ".", "compute_reward_fn", ",", "\n", "substitution_probability", "=", "1.", "\n", ")", "\n", "\n", "rb", ".", "insert", "(", "self", ".", "wrap", "(", "\n", "tf", ".", "constant", "(", "[", "[", "[", "10", ",", "10", "]", ",", "[", "20", ",", "20", "]", ",", "[", "30", ",", "30", "]", ",", "[", "40", ",", "40", "]", ",", "[", "50", ",", "50", "]", "]", "]", ")", ",", "\n", "tf", ".", "constant", "(", "[", "[", "[", "100", ",", "100", "]", ",", "[", "200", ",", "200", "]", ",", "[", "300", ",", "300", "]", ",", "[", "400", ",", "400", "]", ",", "\n", "[", "500", ",", "500", "]", "]", "]", ")", ",", "\n", ")", ",", "\n", "tf", ".", "constant", "(", "[", "1.", "]", ")", ")", "\n", "\n", "samples", "=", "rb", ".", "sample", "(", "1000", ",", "1.", ")", "[", "-", "1", "]", ".", "env_outputs", ".", "observation", "\n", "for", "key", "in", "[", "'achieved_goal'", ",", "'desired_goal'", "]", ":", "\n", "      ", "assert", "samples", "[", "key", "]", ".", "shape", "==", "(", "1000", ",", "5", ",", "2", ")", "\n", "assert", "(", "samples", "[", "key", "]", "[", "...", ",", "0", "]", "==", "samples", "[", "key", "]", "[", "...", ",", "1", "]", ")", ".", "numpy", "(", ")", ".", "all", "(", ")", "\n", "", "samples", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "t", "[", "...", ",", "0", "]", ",", "samples", ")", "\n", "diffs", "=", "set", "(", ")", "\n", "for", "i", "in", "range", "(", "samples", "[", "'achieved_goal'", "]", ".", "shape", "[", "0", "]", ")", ":", "\n", "      ", "assert", "(", "samples", "[", "'achieved_goal'", "]", "[", "i", "]", "==", "[", "10", ",", "20", ",", "30", ",", "40", ",", "50", "]", ")", ".", "numpy", "(", ")", ".", "all", "(", ")", "\n", "for", "t", "in", "range", "(", "5", ")", ":", "\n", "        ", "goal", "=", "samples", "[", "'desired_goal'", "]", "[", "i", "]", "[", "t", "]", "\n", "assert", "goal", "in", "[", "10", ",", "20", ",", "30", ",", "40", ",", "50", "]", "\n", "goal", "//=", "10", "\n", "assert", "goal", ">", "t", "+", "1", "or", "t", "==", "4", "\n", "diffs", ".", "add", "(", "goal", ".", "numpy", "(", ")", "-", "t", "-", "1", ")", "\n", "", "", "assert", "len", "(", "diffs", ")", "==", "5", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.TPUEncodeTest.setUp": [[489, 511], ["super().setUp", "tensorflow.random.uniform", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.random.uniform"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.TPUEncodeTest.setUp"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "TPUEncodeTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "self", ".", "data", "=", "(", "\n", "# Supported on TPU", "\n", "tf", ".", "random", ".", "uniform", "(", "[", "128", "]", ",", "maxval", "=", "100000", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "# Not supported on TPU", "\n", "tf", ".", "cast", "(", "\n", "tf", ".", "random", ".", "uniform", "(", "[", "128", "]", ",", "maxval", "=", "65535", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "tf", ".", "uint16", ")", ",", "\n", "# Not supported on TPU", "\n", "tf", ".", "cast", "(", "\n", "tf", ".", "random", ".", "uniform", "(", "[", "64", ",", "84", ",", "84", ",", "4", "]", ",", "maxval", "=", "256", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "uint8", ")", ",", "\n", "# Not supported on TPU", "\n", "tf", ".", "cast", "(", "tf", ".", "random", ".", "uniform", "(", "[", "1", "]", ",", "maxval", "=", "256", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "tf", ".", "uint8", ")", ",", "\n", "# Not supported on TPU", "\n", "tf", ".", "cast", "(", "\n", "tf", ".", "random", ".", "uniform", "(", "[", "100", ",", "128", ",", "1", ",", "1", ",", "1", "]", ",", "maxval", "=", "256", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "uint8", ")", ",", "\n", "# Not supported on TPU", "\n", "tf", ".", "cast", "(", "\n", "tf", ".", "random", ".", "uniform", "(", "[", "128", ",", "100", ",", "1", ",", "1", ",", "1", "]", ",", "maxval", "=", "256", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "uint8", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.TPUEncodeTest.test_simple": [[513, 525], ["seed_rl.common.utils.tpu_encode", "seed_rl.common.utils.tpu_decode", "utils_test.TPUEncodeTest.assertEqual", "utils_test.TPUEncodeTest.assertIsInstance", "utils_test.TPUEncodeTest.assertEqual", "utils_test.TPUEncodeTest.assertIsInstance", "utils_test.TPUEncodeTest.assertIsInstance", "zip", "utils_test.TPUEncodeTest.assertAllEqual"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.tpu_encode", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.tpu_decode"], ["", "def", "test_simple", "(", "self", ")", ":", "\n", "    ", "encoded", "=", "utils", ".", "tpu_encode", "(", "self", ".", "data", ")", "\n", "decoded", "=", "utils", ".", "tpu_decode", "(", "encoded", ")", "\n", "\n", "self", ".", "assertEqual", "(", "tf", ".", "int32", ",", "encoded", "[", "1", "]", ".", "dtype", ")", "\n", "self", ".", "assertIsInstance", "(", "encoded", "[", "2", "]", ",", "utils", ".", "TPUEncodedUInt8", ")", "\n", "self", ".", "assertEqual", "(", "tf", ".", "bfloat16", ",", "encoded", "[", "3", "]", ".", "dtype", ")", "\n", "self", ".", "assertIsInstance", "(", "encoded", "[", "4", "]", ",", "utils", ".", "TPUEncodedUInt8", ")", "\n", "self", ".", "assertIsInstance", "(", "encoded", "[", "5", "]", ",", "utils", ".", "TPUEncodedUInt8", ")", "\n", "\n", "for", "a", ",", "b", "in", "zip", "(", "decoded", ",", "self", ".", "data", ")", ":", "\n", "      ", "self", ".", "assertAllEqual", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.TPUEncodeTest.test_dataset": [[526, 537], ["tensorflow.data.Dataset.from_generator", "dataset.map.map.map", "seed_rl.common.utils.tpu_decode", "zip", "list", "utils_test.TPUEncodeTest.assertAllEqual", "seed_rl.common.utils.tpu_encode"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.tpu_decode", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.tpu_encode"], ["", "", "def", "test_dataset", "(", "self", ")", ":", "\n", "    ", "def", "gen", "(", ")", ":", "\n", "      ", "yield", "0", "\n", "\n", "", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "gen", ",", "tf", ".", "int64", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "lambda", "_", ":", "utils", ".", "tpu_encode", "(", "self", ".", "data", ")", ")", "\n", "encoded", "=", "list", "(", "dataset", ")", "[", "0", "]", "\n", "decoded", "=", "utils", ".", "tpu_decode", "(", "encoded", ")", "\n", "\n", "for", "a", ",", "b", "in", "zip", "(", "decoded", ",", "self", ".", "data", ")", ":", "\n", "      ", "self", ".", "assertAllEqual", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.TPUEncodeTest.test_strategy": [[538, 566], ["absl.testing.parameterized.parameters", "tensorflow.distribute.cluster_resolver.TPUClusterResolver", "tensorflow.tpu.experimental.initialize_tpu_system", "tensorflow.tpu.experimental.DeviceAssignment.build", "tensorflow.distribute.experimental.TPUStrategy", "tensorflow.distribute.experimental.TPUStrategy.experimental_distribute_datasets_from_function", "next", "tensorflow.distribute.experimental.TPUStrategy.run", "tensorflow.nest.map_structure", "zip", "tensorflow.data.Dataset.from_generator", "tensorflow.data.Dataset.from_generator.map", "iter", "tensorflow.function", "utils_test.TPUEncodeTest.assertAllEqual", "seed_rl.common.utils.tpu_encode", "seed_rl.common.utils.tpu_decode", "tensorflow.distribute.experimental.TPUStrategy.experimental_local_results"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.build", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.tpu_encode", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.tpu_decode"], ["", "", "@", "parameterized", ".", "parameters", "(", "(", "1", ",", ")", ",", "(", "2", ",", ")", ")", "\n", "def", "test_strategy", "(", "self", ",", "num_cores", ")", ":", "\n", "    ", "resolver", "=", "tf", ".", "distribute", ".", "cluster_resolver", ".", "TPUClusterResolver", "(", "''", ")", "\n", "topology", "=", "tf", ".", "tpu", ".", "experimental", ".", "initialize_tpu_system", "(", "resolver", ")", "\n", "da", "=", "tf", ".", "tpu", ".", "experimental", ".", "DeviceAssignment", ".", "build", "(", "topology", ",", "\n", "num_replicas", "=", "num_cores", ")", "\n", "strategy", "=", "tf", ".", "distribute", ".", "experimental", ".", "TPUStrategy", "(", "\n", "resolver", ",", "device_assignment", "=", "da", ")", "\n", "\n", "def", "dataset_fn", "(", "unused_ctx", ")", ":", "\n", "      ", "def", "gen", "(", ")", ":", "\n", "        ", "yield", "0", "\n", "yield", "1", "\n", "\n", "", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "gen", ",", "(", "tf", ".", "int64", ")", ")", "\n", "return", "dataset", ".", "map", "(", "lambda", "_", ":", "utils", ".", "tpu_encode", "(", "self", ".", "data", ")", ")", "\n", "\n", "", "dataset", "=", "strategy", ".", "experimental_distribute_datasets_from_function", "(", "\n", "dataset_fn", ")", "\n", "encoded", "=", "next", "(", "iter", "(", "dataset", ")", ")", "\n", "\n", "decoded", "=", "strategy", ".", "run", "(", "\n", "tf", ".", "function", "(", "lambda", "args", ":", "utils", ".", "tpu_decode", "(", "args", ",", "encoded", ")", ")", ",", "(", "encoded", ",", ")", ")", "\n", "decoded", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "strategy", ".", "experimental_local_results", "(", "t", ")", "[", "0", "]", ",", "decoded", ")", "\n", "\n", "for", "a", ",", "b", "in", "zip", "(", "decoded", ",", "self", ".", "data", ")", ":", "\n", "      ", "self", ".", "assertAllEqual", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.SplitStructureTest.test_basic": [[570, 578], ["seed_rl.common.utils.split_structure", "utils_test.SplitStructureTest.assertAllEqual", "utils_test.SplitStructureTest.assertAllEqual", "utils_test.SplitStructureTest.assertAllEqual", "utils_test.SplitStructureTest.assertAllEqual", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.split_structure"], ["  ", "def", "test_basic", "(", "self", ")", ":", "\n", "    ", "prefix", ",", "suffix", "=", "utils", ".", "split_structure", "(", "\n", "[", "tf", ".", "constant", "(", "[", "1", ",", "2", ",", "3", "]", ")", ",", "\n", "tf", ".", "constant", "(", "[", "[", "4", ",", "5", "]", ",", "[", "6", ",", "7", "]", ",", "[", "8", ",", "9", "]", "]", ")", "]", ",", "1", ")", "\n", "self", ".", "assertAllEqual", "(", "prefix", "[", "0", "]", ",", "tf", ".", "constant", "(", "[", "1", "]", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "prefix", "[", "1", "]", ",", "tf", ".", "constant", "(", "[", "[", "4", ",", "5", "]", "]", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "suffix", "[", "0", "]", ",", "tf", ".", "constant", "(", "[", "2", ",", "3", "]", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "suffix", "[", "1", "]", ",", "tf", ".", "constant", "(", "[", "[", "6", ",", "7", "]", ",", "[", "8", ",", "9", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.SplitStructureTest.test_zero_length_prefix": [[579, 583], ["seed_rl.common.utils.split_structure", "utils_test.SplitStructureTest.assertAllEqual", "utils_test.SplitStructureTest.assertAllEqual", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.split_structure"], ["", "def", "test_zero_length_prefix", "(", "self", ")", ":", "\n", "    ", "prefix", ",", "suffix", "=", "utils", ".", "split_structure", "(", "tf", ".", "constant", "(", "[", "1", ",", "2", ",", "3", "]", ")", ",", "0", ")", "\n", "self", ".", "assertAllEqual", "(", "prefix", ",", "tf", ".", "constant", "(", "[", "]", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "suffix", ",", "tf", ".", "constant", "(", "[", "1", ",", "2", ",", "3", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.MakeTimeMajorTest.test_static": [[587, 591], ["tensorflow.constant", "utils_test.MakeTimeMajorTest.assertAllEqual", "seed_rl.common.utils.make_time_major", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.make_time_major"], ["  ", "def", "test_static", "(", "self", ")", ":", "\n", "    ", "x", "=", "tf", ".", "constant", "(", "[", "[", "[", "1", ",", "2", "]", ",", "[", "3", ",", "4", "]", "]", ",", "[", "[", "5", ",", "6", "]", ",", "[", "7", ",", "8", "]", "]", "]", ")", "\n", "self", ".", "assertAllEqual", "(", "utils", ".", "make_time_major", "(", "x", ")", ",", "\n", "tf", ".", "constant", "(", "[", "[", "[", "1", ",", "2", "]", ",", "[", "5", ",", "6", "]", "]", ",", "[", "[", "3", ",", "4", "]", ",", "[", "7", ",", "8", "]", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.MakeTimeMajorTest.test_dynamic": [[592, 597], ["tensorflow.py_function", "utils_test.MakeTimeMajorTest.assertAllEqual", "seed_rl.common.utils.make_time_major", "tensorflow.constant", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.make_time_major"], ["", "def", "test_dynamic", "(", "self", ")", ":", "\n", "    ", "x", ",", "=", "tf", ".", "py_function", "(", "lambda", ":", "np", ".", "array", "(", "[", "[", "[", "1", ",", "2", "]", ",", "[", "3", ",", "4", "]", "]", ",", "[", "[", "5", ",", "6", "]", ",", "[", "7", ",", "8", "]", "]", "]", ")", ",", "\n", "[", "]", ",", "[", "tf", ".", "int32", "]", ")", "\n", "self", ".", "assertAllEqual", "(", "utils", ".", "make_time_major", "(", "x", ")", ",", "\n", "tf", ".", "constant", "(", "[", "[", "[", "1", ",", "2", "]", ",", "[", "5", ",", "6", "]", "]", ",", "[", "[", "3", ",", "4", "]", ",", "[", "7", ",", "8", "]", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.MakeTimeMajorTest.test_uint16": [[598, 601], ["tensorflow.constant", "utils_test.MakeTimeMajorTest.assertAllEqual", "seed_rl.common.utils.make_time_major", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.make_time_major"], ["", "def", "test_uint16", "(", "self", ")", ":", "\n", "    ", "x", "=", "tf", ".", "constant", "(", "[", "[", "1", ",", "2", "]", ",", "[", "3", ",", "4", "]", "]", ",", "tf", ".", "uint16", ")", "\n", "self", ".", "assertAllEqual", "(", "utils", ".", "make_time_major", "(", "x", ")", ",", "tf", ".", "constant", "(", "[", "[", "1", ",", "3", "]", ",", "[", "2", ",", "4", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.MakeTimeMajorTest.test_nest": [[602, 607], ["seed_rl.common.utils.make_time_major", "utils_test.MakeTimeMajorTest.assertAllEqual", "utils_test.MakeTimeMajorTest.assertAllEqual", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.make_time_major"], ["", "def", "test_nest", "(", "self", ")", ":", "\n", "    ", "x", "=", "(", "tf", ".", "constant", "(", "[", "[", "1", ",", "2", "]", ",", "[", "3", ",", "4", "]", "]", ")", ",", "tf", ".", "constant", "(", "[", "[", "1", "]", ",", "[", "2", "]", "]", ")", ")", "\n", "a", ",", "b", "=", "utils", ".", "make_time_major", "(", "x", ")", "\n", "self", ".", "assertAllEqual", "(", "a", ",", "tf", ".", "constant", "(", "[", "[", "1", ",", "3", "]", ",", "[", "2", ",", "4", "]", "]", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "b", ",", "tf", ".", "constant", "(", "[", "[", "1", ",", "2", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.MinimizeTest.test_minimize": [[611, 651], ["absl.testing.parameterized.parameters", "tensorflow.distribute.cluster_resolver.TPUClusterResolver", "tensorflow.distribute.experimental.TPUStrategy", "tensorflow.tpu.experimental.initialize_tpu_system", "tensorflow.tpu.experimental.DeviceAssignment.build", "tensorflow.distribute.experimental.TPUStrategy", "tensorflow.distribute.experimental.TPUStrategy.run", "tensorflow.keras.optimizers.SGD", "tensorflow.distribute.experimental.TPUStrategy.run", "utils_test.MinimizeTest.assertAllClose", "tensorflow.distribute.experimental.TPUStrategy.scope", "tensorflow.Variable", "tensorflow.Variable", "tape.gradient", "tensorflow.Variable.assign", "tensorflow.distribute.experimental.TPUStrategy.experimental_local_results", "tensorflow.keras.optimizers.SGD.apply_gradients", "v.read_value", "tensorflow.zeros_like", "tensorflow.GradientTape", "tape.watch", "tensorflow.distribute.experimental.TPUStrategy.experimental_local_results"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.build"], ["  ", "@", "parameterized", ".", "parameters", "(", "(", "1", ",", ")", ",", "(", "2", ",", ")", ")", "\n", "def", "test_minimize", "(", "self", ",", "num_training_tpus", ")", ":", "\n", "    ", "resolver", "=", "tf", ".", "distribute", ".", "cluster_resolver", ".", "TPUClusterResolver", "(", "''", ")", "\n", "strategy", "=", "tf", ".", "distribute", ".", "experimental", ".", "TPUStrategy", "(", "resolver", ")", "\n", "topology", "=", "tf", ".", "tpu", ".", "experimental", ".", "initialize_tpu_system", "(", "resolver", ")", "\n", "training_da", "=", "tf", ".", "tpu", ".", "experimental", ".", "DeviceAssignment", ".", "build", "(", "\n", "topology", ",", "num_replicas", "=", "num_training_tpus", ")", "\n", "training_strategy", "=", "tf", ".", "distribute", ".", "experimental", ".", "TPUStrategy", "(", "\n", "resolver", ",", "device_assignment", "=", "training_da", ")", "\n", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "a", "=", "tf", ".", "Variable", "(", "1.", ",", "trainable", "=", "True", ")", "\n", "temp_grad", "=", "tf", ".", "Variable", "(", "\n", "tf", ".", "zeros_like", "(", "a", ")", ",", "\n", "trainable", "=", "False", ",", "\n", "synchronization", "=", "tf", ".", "VariableSynchronization", ".", "ON_READ", ")", "\n", "\n", "", "@", "tf", ".", "function", "\n", "def", "compute_gradients", "(", ")", ":", "\n", "      ", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "        ", "tape", ".", "watch", "(", "a", ")", "\n", "loss", "=", "a", "*", "2", "\n", "", "g", "=", "tape", ".", "gradient", "(", "loss", ",", "a", ")", "\n", "temp_grad", ".", "assign", "(", "g", ")", "\n", "return", "loss", "\n", "\n", "", "loss", "=", "training_strategy", ".", "run", "(", "compute_gradients", ",", "(", ")", ")", "\n", "loss", "=", "training_strategy", ".", "experimental_local_results", "(", "loss", ")", "[", "0", "]", "\n", "\n", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "SGD", "(", ".1", ")", "\n", "@", "tf", ".", "function", "\n", "def", "apply_gradients", "(", "_", ")", ":", "\n", "      ", "optimizer", ".", "apply_gradients", "(", "[", "(", "temp_grad", ",", "a", ")", "]", ")", "\n", "\n", "", "strategy", ".", "run", "(", "apply_gradients", ",", "(", "loss", ",", ")", ")", "\n", "\n", "a_values", "=", "[", "v", ".", "read_value", "(", ")", "for", "v", "in", "strategy", ".", "experimental_local_results", "(", "a", ")", "]", "\n", "\n", "expected_a", "=", "1.", "-", "num_training_tpus", "*", ".2", "\n", "self", ".", "assertAllClose", "(", "[", "expected_a", ",", "expected_a", "]", ",", "a_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.tests.utils_test.ProgressLoggerTest.test_logger": [[655, 674], ["seed_rl.common.utils.ProgressLogger", "seed_rl.common.utils.ProgressLogger.start", "seed_rl.common.utils.ProgressLogger._log", "tensorflow.function", "utils_test.ProgressLoggerTest.test_logger.log_something"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger._log"], ["  ", "def", "test_logger", "(", "self", ")", ":", "\n", "    ", "logger", "=", "utils", ".", "ProgressLogger", "(", ")", "\n", "logger", ".", "start", "(", ")", "\n", "logger", ".", "_log", "(", ")", "\n", "\n", "@", "tf", ".", "function", "(", "input_signature", "=", "(", "tf", ".", "TensorSpec", "(", "[", "]", ",", "tf", ".", "int32", ",", "'value'", ")", ",", ")", ")", "\n", "def", "log_something", "(", "value", ")", ":", "\n", "      ", "session", "=", "logger", ".", "log_session", "(", ")", "\n", "logger", ".", "log", "(", "session", ",", "'value_1'", ",", "value", ")", "\n", "logger", ".", "log", "(", "session", ",", "'value_2'", ",", "value", "+", "1", ")", "\n", "logger", ".", "step_end", "(", "session", ")", "\n", "\n", "", "log_something", "(", "tf", ".", "constant", "(", "10", ")", ")", "\n", "logger", ".", "_log", "(", ")", "\n", "self", ".", "assertAllEqual", "(", "logger", ".", "ready_values", ".", "read_value", "(", ")", ",", "tf", ".", "constant", "(", "[", "10", ",", "11", "]", ")", ")", "\n", "log_something", "(", "tf", ".", "constant", "(", "15", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "logger", ".", "ready_values", ".", "read_value", "(", ")", ",", "tf", ".", "constant", "(", "[", "15", ",", "16", "]", ")", ")", "\n", "logger", ".", "_log", "(", ")", "\n", "logger", ".", "shutdown", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.football.vtrace_main.create_agent": [[37, 40], ["seed_rl.football.networks.GFootball"], "function", ["None"], ["# Network settings.", "\n", "flags", ".", "DEFINE_integer", "(", "'n_mlp_layers'", ",", "2", ",", "'Number of MLP hidden layers.'", ")", "\n", "flags", ".", "DEFINE_integer", "(", "'mlp_size'", ",", "64", ",", "'Sizes of each of MLP hidden layer.'", ")", "\n", "flags", ".", "DEFINE_integer", "(", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.football.vtrace_main.create_optimizer": [[42, 46], ["tensorflow.keras.optimizers.Adam"], "function", ["None"], ["'Number of LSTM layers. LSTM layers afre applied after MLP layers.'", ")", "\n", "flags", ".", "DEFINE_integer", "(", "'lstm_size'", ",", "64", ",", "'Sizes of each LSTM layer.'", ")", "\n", "flags", ".", "DEFINE_bool", "(", "'normalize_observations'", ",", "False", ",", "'Whether to normalize'", "\n", "'observations by subtracting mean and dividing by stddev.'", ")", "\n", "# Environment settings.", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.football.vtrace_main.main": [[48, 59], ["len", "absl.app.UsageError", "seed_rl.common.actor.actor_loop", "seed_rl.agents.vtrace.learner.learner_loop", "ValueError"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.actor.actor_loop", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.learner_loop"], ["'Name of the environment from OpenAI Gym.'", ")", "\n", "flags", ".", "DEFINE_enum", "(", "\n", "'discretization'", ",", "'none'", ",", "[", "'none'", ",", "'lin'", ",", "'log'", "]", ",", "'Values other than '", "\n", "'\"none\" cause action coordinates to be discretized into n_actions_per_dim '", "\n", "'buckets. Buckets are spaced linearly between the bounds if \"lin\" mode is '", "\n", "'used and logarithmically for \"log\" mode.'", ")", "\n", "flags", ".", "DEFINE_integer", "(", "\n", "'n_actions_per_dim'", ",", "11", ",", "'The number of buckets per action coordinate if '", "\n", "'discretization is used.'", ")", "\n", "flags", ".", "DEFINE_float", "(", "\n", "'action_ratio'", ",", "30.", ",", "\n", "'The ratio between the highest and the lowest positive '", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.football.networks._Stack.__init__": [[30, 49], ["tensorflow.Module.__init__", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.MaxPool2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "range", "range"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["\n", "super", "(", "MLPandLSTM", ",", "self", ")", ".", "__init__", "(", "name", "=", "'MLPandLSTM'", ")", "\n", "self", ".", "_parametric_action_distribution", "=", "parametric_action_distribution", "\n", "\n", "# MLP", "\n", "mlp_layers", "=", "[", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "size", ",", "'relu'", ")", "for", "size", "in", "mlp_sizes", "]", "\n", "self", ".", "_mlp", "=", "tf", ".", "keras", ".", "Sequential", "(", "mlp_layers", ")", "\n", "# stacked LSTM", "\n", "lstm_cells", "=", "[", "tf", ".", "keras", ".", "layers", ".", "LSTMCell", "(", "size", ")", "for", "size", "in", "lstm_sizes", "]", "\n", "self", ".", "_core", "=", "tf", ".", "keras", ".", "layers", ".", "StackedRNNCells", "(", "lstm_cells", ")", "\n", "# Layers for _head.", "\n", "self", ".", "_policy_logits", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "parametric_action_distribution", ".", "param_size", ",", "name", "=", "'policy_logits'", ")", "\n", "self", ".", "_baseline", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "1", ",", "name", "=", "'baseline'", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.football.networks._Stack.__call__": [[51, 66], ["networks._Stack._conv", "networks._Stack._max_pool", "zip", "tensorflow.nn.relu", "res_conv0", "tensorflow.nn.relu", "res_conv1"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "initial_state", "(", "self", ",", "batch_size", ")", ":", "\n", "    ", "return", "self", ".", "_core", ".", "get_initial_state", "(", "batch_size", "=", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "def", "_head", "(", "self", ",", "core_output", ")", ":", "\n", "    ", "policy_logits", "=", "self", ".", "_policy_logits", "(", "core_output", ")", "\n", "baseline", "=", "tf", ".", "squeeze", "(", "self", ".", "_baseline", "(", "core_output", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Sample an action from the policy.", "\n", "action", "=", "self", ".", "_parametric_action_distribution", ".", "sample", "(", "policy_logits", ")", "\n", "\n", "return", "AgentOutput", "(", "action", ",", "policy_logits", ",", "baseline", ")", "\n", "\n", "# Not clear why, but if \"@tf.function\" declarator is placed directly onto", "\n", "# __call__, training fails with \"uninitialized variable *baseline\".", "\n", "# when running on multiple learning tpu cores.", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.football.networks.GFootball.__init__": [[74, 95], ["tensorflow.Module.__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "networks._Stack"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["is_training", "=", "False", ")", ":", "\n", "    ", "\"\"\"Runs the agent.\n\n    Args:\n      prev_actions: Previous action. Not used by this agent.\n      env_outputs: Structure with reward, done and observation fields. Only\n        observation field is used by this agent. It should have the shape\n        [time, batch_size, observation_size].\n      core_state: Agent state.\n      unroll: Should be True if inputs contain the time dimension and False\n        otherwise.\n      is_training: Whether we are in the loss computation. Not used by this\n        agent.\n    Returns:\n      A structure with action, policy_logits and baseline.\n    \"\"\"", "\n", "if", "not", "unroll", ":", "\n", "# Add time dimension.", "\n", "      ", "prev_actions", ",", "env_outputs", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "tf", ".", "expand_dims", "(", "t", ",", "0", ")", ",", "(", "prev_actions", ",", "env_outputs", ")", ")", "\n", "\n", "", "outputs", ",", "core_state", "=", "self", ".", "_unroll", "(", "prev_actions", ",", "env_outputs", ",", "core_state", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.football.networks.GFootball.initial_state": [[96, 98], ["None"], "methods", ["None"], ["\n", "if", "not", "unroll", ":", "\n", "# Remove time dimension.", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.football.networks.GFootball._torso": [[99, 114], ["seed_rl.football.observation.unpackbits", "tensorflow.nn.relu", "networks.GFootball._conv_to_linear", "tensorflow.nn.relu", "stack", "tensorflow.keras.layers.Flatten"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.football.observation.unpackbits"], ["      ", "outputs", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "tf", ".", "squeeze", "(", "t", ",", "0", ")", ",", "outputs", ")", "\n", "\n", "", "return", "outputs", ",", "core_state", "\n", "\n", "", "def", "_unroll", "(", "self", ",", "unused_prev_actions", ",", "env_outputs", ",", "core_state", ")", ":", "\n", "    ", "unused_reward", ",", "done", ",", "observation", ",", "_", ",", "_", "=", "env_outputs", "\n", "observation", "=", "self", ".", "_mlp", "(", "observation", ")", "\n", "\n", "initial_core_state", "=", "self", ".", "_core", ".", "get_initial_state", "(", "\n", "batch_size", "=", "tf", ".", "shape", "(", "observation", ")", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "core_output_list", "=", "[", "]", "\n", "for", "input_", ",", "d", "in", "zip", "(", "tf", ".", "unstack", "(", "observation", ")", ",", "tf", ".", "unstack", "(", "done", ")", ")", ":", "\n", "# If the episode ended, the core state should be reset before the next.", "\n", "      ", "core_state", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "x", ",", "y", ",", "d", "=", "d", ":", "tf", ".", "where", "(", "\n", "tf", ".", "reshape", "(", "d", ",", "[", "d", ".", "shape", "[", "0", "]", "]", "+", "[", "1", "]", "*", "(", "x", ".", "shape", ".", "rank", "-", "1", ")", ")", ",", "x", ",", "y", ")", ",", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.football.networks.GFootball._head": [[115, 123], ["networks.GFootball._policy_logits", "tensorflow.squeeze", "networks.GFootball._parametric_action_distribution.sample", "AgentOutput", "networks.GFootball._baseline"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], ["initial_core_state", ",", "\n", "core_state", ")", "\n", "core_output", ",", "core_state", "=", "self", ".", "_core", "(", "input_", ",", "core_state", ")", "\n", "core_output_list", ".", "append", "(", "core_output", ")", "\n", "", "outputs", "=", "tf", ".", "stack", "(", "core_output_list", ")", "\n", "\n", "return", "utils", ".", "batch_apply", "(", "self", ".", "_head", ",", "(", "outputs", ",", ")", ")", ",", "core_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.football.networks.GFootball.get_action": [[129, 132], ["networks.GFootball.__call__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.__call__"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.football.networks.GFootball.__call__": [[133, 147], ["networks.GFootball._unroll", "tensorflow.nest.map_structure", "tensorflow.nest.map_structure", "tensorflow.expand_dims", "tensorflow.squeeze"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep._unroll"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.football.networks.GFootball._unroll": [[148, 151], ["seed_rl.common.utils.batch_apply", "seed_rl.common.utils.batch_apply"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.batch_apply", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.batch_apply"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.football.observation_test.UtilsTest.test_packed_bits": [[27, 55], ["absl.testing.parameterized.parameters", "gym.make", "gym.make.reset", "range", "gym.make.close", "gym.make.step", "tensorflow.cast", "seed_rl.football.observation.PackedBitsObservation.observation", "tensorflow.convert_to_tensor", "seed_rl.football.observation.unpackbits", "seed_rl.football.observation.unpackbits", "observation_test.UtilsTest.assertAllEqual", "observation_test.UtilsTest.assertAllEqual", "observation_test.UtilsTest.assertAllEqual", "observation_test.UtilsTest.assertAllEqual", "gym.make.action_space.sample", "numpy.array", "seed_rl.common.utils.tpu_encode", "tensorflow.math.reduce_sum", "tensorflow.math.reduce_sum", "gym.make.reset"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.close", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.step", "home.repos.pwc.inspect_result.google-research_seed_rl.football.observation.PackedBitsObservation.observation", "home.repos.pwc.inspect_result.google-research_seed_rl.football.observation.unpackbits", "home.repos.pwc.inspect_result.google-research_seed_rl.football.observation.unpackbits", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.tpu_encode", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset"], ["  ", "@", "parameterized", ".", "parameters", "(", "\n", "(", "False", ")", ",", "\n", "(", "True", ")", ",", "\n", ")", "\n", "def", "test_packed_bits", "(", "self", ",", "stacked", ")", ":", "\n", "    ", "env", "=", "gym", ".", "make", "(", "\n", "'gfootball:GFootball-11_vs_11_easy_stochastic-SMM-v0'", ",", "stacked", "=", "stacked", ")", "\n", "env", ".", "reset", "(", ")", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "      ", "obs", ",", "_", ",", "done", ",", "_", "=", "env", ".", "step", "(", "env", ".", "action_space", ".", "sample", "(", ")", ")", "\n", "\n", "baseline_obs", "=", "tf", ".", "cast", "(", "np", ".", "array", "(", "obs", ")", ",", "tf", ".", "float32", ")", "\n", "\n", "packed_obs", "=", "observation", ".", "PackedBitsObservation", ".", "observation", "(", "env", ",", "obs", ")", "\n", "packed_obs", "=", "tf", ".", "convert_to_tensor", "(", "packed_obs", ")", "\n", "tpu_obs", "=", "observation", ".", "unpackbits", "(", "utils", ".", "tpu_encode", "(", "packed_obs", ")", ")", "\n", "non_tpu_obs", "=", "observation", ".", "unpackbits", "(", "packed_obs", ")", "\n", "# baseline_obs has less than 16 channels, so first channels should", "\n", "# correspond to baseline_obs and then all the rest should be 0", "\n", "self", ".", "assertAllEqual", "(", "baseline_obs", ",", "tpu_obs", "[", "...", ",", ":", "obs", ".", "shape", "[", "-", "1", "]", "]", ")", "\n", "self", ".", "assertAllEqual", "(", "baseline_obs", ",", "non_tpu_obs", "[", "...", ",", ":", "obs", ".", "shape", "[", "-", "1", "]", "]", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "math", ".", "reduce_sum", "(", "tpu_obs", "[", "...", ",", "obs", ".", "shape", "[", "-", "1", "]", ":", "]", ")", ",", "0", ")", "\n", "self", ".", "assertAllEqual", "(", "tf", ".", "math", ".", "reduce_sum", "(", "non_tpu_obs", "[", "...", ",", "obs", ".", "shape", "[", "-", "1", "]", ":", "]", ")", ",", "\n", "0", ")", "\n", "\n", "if", "done", ":", "\n", "        ", "env", ".", "reset", "(", ")", "\n", "", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.football.observation.PackedBitsObservation.__init__": [[31, 38], ["gym.ObservationWrapper.__init__", "gym.spaces.Box", "numpy.iinfo"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "    ", "super", "(", "PackedBitsObservation", ",", "self", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "\n", "low", "=", "0", ",", "high", "=", "np", ".", "iinfo", "(", "np", ".", "uint16", ")", ".", "max", ",", "\n", "shape", "=", "env", ".", "observation_space", ".", "shape", "[", ":", "-", "1", "]", "+", "(", "(", "env", ".", "observation_space", ".", "shape", "[", "-", "1", "]", "+", "15", ")", "//", "16", ",", ")", ",", "\n", "dtype", "=", "np", ".", "uint16", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.football.observation.PackedBitsObservation.observation": [[39, 46], ["numpy.packbits", "numpy.pad.view", "numpy.pad"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "observation", ")", ":", "\n", "    ", "data", "=", "np", ".", "packbits", "(", "observation", ",", "axis", "=", "-", "1", ")", "# This packs to uint8", "\n", "# Now we want to pack pairs of uint8 into uint16's.", "\n", "# We first need to ensure that the last dimension has even size.", "\n", "if", "data", ".", "shape", "[", "-", "1", "]", "%", "2", "==", "1", ":", "\n", "      ", "data", "=", "np", ".", "pad", "(", "data", ",", "[", "(", "0", ",", "0", ")", "]", "*", "(", "data", ".", "ndim", "-", "1", ")", "+", "[", "(", "0", ",", "1", ")", "]", ",", "'constant'", ")", "\n", "", "return", "data", ".", "view", "(", "np", ".", "uint16", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.football.observation.unpackbits": [[48, 64], ["tensorflow.test.is_gpu_available", "observation.unpackbits._"], "function", ["None"], ["", "", "def", "unpackbits", "(", "frame", ")", ":", "\n", "  ", "def", "_", "(", "frame", ")", ":", "\n", "# Unpack each uint16 into 16 bits", "\n", "    ", "bit_patterns", "=", "[", "\n", "2", "**", "7", ",", "2", "**", "6", ",", "2", "**", "5", ",", "2", "**", "4", ",", "2", "**", "3", ",", "2", "**", "2", ",", "2", "**", "1", ",", "2", "**", "0", ",", "2", "**", "15", ",", "2", "**", "14", ",", "2", "**", "13", ",", "\n", "2", "**", "12", ",", "2", "**", "11", ",", "2", "**", "10", ",", "2", "**", "9", ",", "2", "**", "8", "\n", "]", "\n", "frame", "=", "tf", ".", "bitwise", ".", "bitwise_and", "(", "frame", "[", "...", ",", "tf", ".", "newaxis", "]", ",", "bit_patterns", ")", "\n", "frame", "=", "tf", ".", "cast", "(", "tf", ".", "cast", "(", "frame", ",", "tf", ".", "bool", ")", ",", "tf", ".", "float32", ")", "*", "255", "\n", "# Reshape to the right size.", "\n", "frame", "=", "tf", ".", "reshape", "(", "frame", ",", "frame", ".", "shape", "[", ":", "-", "2", "]", "+", "(", "frame", ".", "shape", "[", "-", "2", "]", "*", "frame", ".", "shape", "[", "-", "1", "]", ",", ")", ")", "\n", "return", "frame", "\n", "", "if", "tf", ".", "test", ".", "is_gpu_available", "(", ")", ":", "\n", "    ", "return", "tf", ".", "xla", ".", "experimental", ".", "compile", "(", "_", ",", "[", "frame", "]", ")", "[", "0", "]", "\n", "", "return", "_", "(", "frame", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.football.environment_test.EnvironmentTest.test_run_step": [[26, 31], ["seed_rl.football.env.create_environment", "seed_rl.football.env.create_environment.reset", "seed_rl.football.env.create_environment.step", "seed_rl.football.env.create_environment.close"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.create_environment", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.step", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.close"], ["  ", "def", "run_environment", "(", "self", ",", "environment", ")", ":", "\n", "    ", "environment", ".", "reset", "(", ")", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "      ", "_", ",", "_", ",", "done", ",", "_", "=", "environment", ".", "step", "(", "environment", ".", "action_space", ".", "sample", "(", ")", ")", "\n", "if", "done", ":", "\n", "        ", "environment", ".", "reset", "(", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.football.env.create_environment": [[35, 50], ["absl.logging.info", "gym.make", "seed_rl.football.observation.PackedBitsObservation"], "function", ["None"], ["\n", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "\n", "self", ".", "observation_space", ".", "low", ",", "\n", "self", ".", "observation_space", ".", "high", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "num_steps", "=", "0", "\n", "self", ".", "max_episode_steps", "=", "self", ".", "env", ".", "spec", ".", "max_episode_steps", "\n", "\n", "", "def", "reset", "(", "self", ")", ":", "\n", "    ", "self", ".", "num_steps", "=", "0", "\n", "return", "self", ".", "env", ".", "reset", "(", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "def", "step", "(", "self", ",", "action", ")", ":", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.vtrace.from_importance_weights": [[34, 149], ["tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tf.convert_to_tensor.shape.assert_has_rank", "tf.convert_to_tensor.shape.assert_has_rank", "tf.convert_to_tensor.shape.assert_has_rank", "tf.convert_to_tensor.shape.assert_has_rank", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tf.convert_to_tensor.shape.assert_has_rank", "tf.convert_to_tensor.shape.assert_has_rank", "tensorflow.name_scope", "tensorflow.exp", "tensorflow.minimum", "tensorflow.convert_to_tensor", "tensorflow.concat", "tensorflow.zeros_like", "range", "tensorflow.add", "tensorflow.concat", "VTraceReturns", "tensorflow.minimum", "vs_minus_v_xs.append", "tensorflow.minimum", "tensorflow.expand_dims", "int", "tensorflow.expand_dims", "tensorflow.stop_gradient", "tensorflow.stop_gradient"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.add", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append"], ["def", "from_importance_weights", "(", "\n", "target_action_log_probs", ",", "behaviour_action_log_probs", ",", "\n", "discounts", ",", "rewards", ",", "values", ",", "bootstrap_value", ",", "\n", "clip_rho_threshold", "=", "1.0", ",", "clip_pg_rho_threshold", "=", "1.0", ",", "lambda_", "=", "1.0", ",", "\n", "name", "=", "'vtrace_from_importance_weights'", ")", ":", "\n", "  ", "r\"\"\"V-trace from log importance weights.\n\n  Calculates V-trace actor critic targets as described in\n\n  \"IMPALA: Scalable Distributed Deep-RL with\n  Importance Weighted Actor-Learner Architectures\"\n  by Espeholt, Soyer, Munos et al.\n\n  In the notation used throughout documentation and comments, T refers to the\n  time dimension ranging from 0 to T-1. B refers to the batch size and\n  NUM_ACTIONS refers to the number of actions. This code also supports the\n  case where all tensors have the same number of additional dimensions, e.g.,\n  `rewards` is [T, B, C], `values` is [T, B, C], `bootstrap_value` is [B, C].\n\n  Args:\n    target_action_log_probs: A float32 tensor of shape [T, B] with\n      log-probabilities of taking the action by the current policy\n    behaviour_action_log_probs: A float32 tensor of shape [T, B] with\n      log-probabilities of taking the action by the behavioural policy\n    discounts: A float32 tensor of shape [T, B] with discounts encountered when\n      following the behaviour policy.\n    rewards: A float32 tensor of shape [T, B] containing rewards generated by\n      following the behaviour policy.\n    values: A float32 tensor of shape [T, B] with the value function estimates\n      wrt. the target policy.\n    bootstrap_value: A float32 of shape [B] with the value function estimate at\n      time T.\n    clip_rho_threshold: A scalar float32 tensor with the clipping threshold for\n      importance weights (rho) when calculating the baseline targets (vs).\n      rho^bar in the paper. If None, no clipping is applied.\n    clip_pg_rho_threshold: A scalar float32 tensor with the clipping threshold\n      on rho_s in \\rho_s \\delta log \\pi(a|x) (r + \\gamma v_{s+1} - V(x_s)). If\n      None, no clipping is applied.\n    lambda_: Mix between 1-step (lambda_=0) and n-step (lambda_=1). See Remark 2\n      in paper. Defaults to lambda_=1.\n    name: The name scope that all V-trace operations will be created in.\n\n  Returns:\n    A VTraceReturns namedtuple (vs, pg_advantages) where:\n      vs: A float32 tensor of shape [T, B]. Can be used as target to\n        train a baseline (V(x_t) - vs_t)^2.\n      pg_advantages: A float32 tensor of shape [T, B]. Can be used as the\n        advantage in the calculation of policy gradients.\n  \"\"\"", "\n", "\n", "log_rhos", "=", "target_action_log_probs", "-", "behaviour_action_log_probs", "\n", "\n", "log_rhos", "=", "tf", ".", "convert_to_tensor", "(", "log_rhos", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "discounts", "=", "tf", ".", "convert_to_tensor", "(", "discounts", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "rewards", "=", "tf", ".", "convert_to_tensor", "(", "rewards", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "values", "=", "tf", ".", "convert_to_tensor", "(", "values", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "bootstrap_value", "=", "tf", ".", "convert_to_tensor", "(", "bootstrap_value", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "if", "clip_rho_threshold", "is", "not", "None", ":", "\n", "    ", "clip_rho_threshold", "=", "tf", ".", "convert_to_tensor", "(", "clip_rho_threshold", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "if", "clip_pg_rho_threshold", "is", "not", "None", ":", "\n", "    ", "clip_pg_rho_threshold", "=", "tf", ".", "convert_to_tensor", "(", "clip_pg_rho_threshold", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# Make sure tensor ranks are consistent.", "\n", "", "rho_rank", "=", "log_rhos", ".", "shape", ".", "ndims", "# Usually 2.", "\n", "values", ".", "shape", ".", "assert_has_rank", "(", "rho_rank", ")", "\n", "bootstrap_value", ".", "shape", ".", "assert_has_rank", "(", "rho_rank", "-", "1", ")", "\n", "discounts", ".", "shape", ".", "assert_has_rank", "(", "rho_rank", ")", "\n", "rewards", ".", "shape", ".", "assert_has_rank", "(", "rho_rank", ")", "\n", "if", "clip_rho_threshold", "is", "not", "None", ":", "\n", "    ", "clip_rho_threshold", ".", "shape", ".", "assert_has_rank", "(", "0", ")", "\n", "", "if", "clip_pg_rho_threshold", "is", "not", "None", ":", "\n", "    ", "clip_pg_rho_threshold", ".", "shape", ".", "assert_has_rank", "(", "0", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "name", ")", ":", "\n", "    ", "rhos", "=", "tf", ".", "exp", "(", "log_rhos", ")", "\n", "if", "clip_rho_threshold", "is", "not", "None", ":", "\n", "      ", "clipped_rhos", "=", "tf", ".", "minimum", "(", "clip_rho_threshold", ",", "rhos", ",", "name", "=", "'clipped_rhos'", ")", "\n", "", "else", ":", "\n", "      ", "clipped_rhos", "=", "rhos", "\n", "\n", "", "cs", "=", "tf", ".", "minimum", "(", "1.0", ",", "rhos", ",", "name", "=", "'cs'", ")", "\n", "cs", "*=", "tf", ".", "convert_to_tensor", "(", "lambda_", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# Append bootstrapped value to get [v1, ..., v_t+1]", "\n", "values_t_plus_1", "=", "tf", ".", "concat", "(", "\n", "[", "values", "[", "1", ":", "]", ",", "tf", ".", "expand_dims", "(", "bootstrap_value", ",", "0", ")", "]", ",", "axis", "=", "0", ")", "\n", "deltas", "=", "clipped_rhos", "*", "(", "rewards", "+", "discounts", "*", "values_t_plus_1", "-", "values", ")", "\n", "\n", "acc", "=", "tf", ".", "zeros_like", "(", "bootstrap_value", ")", "\n", "vs_minus_v_xs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "int", "(", "discounts", ".", "shape", "[", "0", "]", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "      ", "discount", ",", "c", ",", "delta", "=", "discounts", "[", "i", "]", ",", "cs", "[", "i", "]", ",", "deltas", "[", "i", "]", "\n", "acc", "=", "delta", "+", "discount", "*", "c", "*", "acc", "\n", "vs_minus_v_xs", ".", "append", "(", "acc", ")", "\n", "", "vs_minus_v_xs", "=", "vs_minus_v_xs", "[", ":", ":", "-", "1", "]", "\n", "\n", "# Add V(x_s) to get v_s.", "\n", "vs", "=", "tf", ".", "add", "(", "vs_minus_v_xs", ",", "values", ",", "name", "=", "'vs'", ")", "\n", "\n", "# Advantage for policy gradient.", "\n", "vs_t_plus_1", "=", "tf", ".", "concat", "(", "[", "\n", "vs", "[", "1", ":", "]", ",", "tf", ".", "expand_dims", "(", "bootstrap_value", ",", "0", ")", "]", ",", "axis", "=", "0", ")", "\n", "if", "clip_pg_rho_threshold", "is", "not", "None", ":", "\n", "      ", "clipped_pg_rhos", "=", "tf", ".", "minimum", "(", "clip_pg_rho_threshold", ",", "rhos", ",", "\n", "name", "=", "'clipped_pg_rhos'", ")", "\n", "", "else", ":", "\n", "      ", "clipped_pg_rhos", "=", "rhos", "\n", "", "pg_advantages", "=", "(", "\n", "clipped_pg_rhos", "*", "(", "rewards", "+", "discounts", "*", "vs_t_plus_1", "-", "values", ")", ")", "\n", "\n", "# Make sure no gradients backpropagated through the returned values.", "\n", "return", "VTraceReturns", "(", "vs", "=", "tf", ".", "stop_gradient", "(", "vs", ")", ",", "\n", "pg_advantages", "=", "tf", ".", "stop_gradient", "(", "pg_advantages", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.profiling.Aggregator.__init__": [[27, 29], ["profiling.Aggregator.reset"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.profiling.Aggregator.reset": [[30, 33], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "self", ".", "sum", "=", "0.", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.profiling.Aggregator.average": [[34, 36], ["None"], "methods", ["None"], ["", "def", "average", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "sum", "/", "self", ".", "count", "if", "self", ".", "count", "else", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.profiling.Aggregator.add": [[37, 40], ["None"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "v", ")", ":", "\n", "    ", "self", ".", "sum", "+=", "v", "\n", "self", ".", "count", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.profiling.ExportingTimer.__init__": [[62, 65], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "summary_name", ",", "aggregation_window_size", ")", ":", "\n", "    ", "self", ".", "summary_name", "=", "summary_name", "\n", "self", ".", "aggregation_window_size", "=", "aggregation_window_size", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.profiling.ExportingTimer.__enter__": [[66, 69], ["time.time"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "    ", "self", ".", "start_time_s", "=", "time", ".", "time", "(", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.profiling.ExportingTimer.__exit__": [[70, 77], ["aggregator.add", "time.time", "tensorflow.summary.scalar", "aggregator.reset", "aggregator.average"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.add", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.common.profiling.Aggregator.average"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_value", ",", "traceback", ")", ":", "\n", "    ", "self", ".", "elapsed_s", "=", "time", ".", "time", "(", ")", "-", "self", ".", "start_time_s", "\n", "aggregator", "=", "self", ".", "aggregators", "[", "self", ".", "summary_name", "]", "\n", "aggregator", ".", "add", "(", "self", ".", "elapsed_s", ")", "\n", "if", "aggregator", ".", "count", ">=", "self", ".", "aggregation_window_size", ":", "\n", "      ", "tf", ".", "summary", ".", "scalar", "(", "self", ".", "summary_name", ",", "aggregator", ".", "average", "(", ")", ")", "\n", "aggregator", ".", "reset", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.__init__": [[24, 36], ["tensorflow.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "eps", "=", "0.001", ",", "clip_range", "=", "(", "-", "5", ",", "5", ")", ")", ":", "\n", "    ", "\"\"\"Initialize the normalizer.\n\n    Args:\n      eps: A constant added to the standard deviation of data before\n        normalization.\n      clip_range: Normalized values are clipped to this range.\n    \"\"\"", "\n", "super", "(", "Normalizer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "clip_range", "=", "clip_range", "\n", "self", ".", "initialized", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.build": [[37, 70], ["normalizer.Normalizer.build.get_variable"], "methods", ["None"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "    ", "assert", "not", "self", ".", "initialized", "\n", "self", ".", "initialized", "=", "True", "\n", "\n", "size", "=", "input_shape", "[", "-", "1", "]", "\n", "def", "get_variable", "(", "name", ",", "initial_value", ",", "local", ")", ":", "\n", "      ", "if", "local", ":", "\n", "# ON_READ causes the replicated variable to act as independent variables", "\n", "# for each replica. The variable only gets aggregated if it is read", "\n", "# in cross-replica context, which may happen e.g. when the normalizer", "\n", "# is checkpointed.", "\n", "        ", "return", "tf", ".", "Variable", "(", "name", "=", "name", ",", "\n", "initial_value", "=", "initial_value", ",", "\n", "trainable", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "synchronization", "=", "tf", ".", "VariableSynchronization", ".", "ON_READ", ",", "\n", "aggregation", "=", "tf", ".", "VariableAggregation", ".", "MEAN", ")", "\n", "", "else", ":", "# mirrored variable, same value on each replica", "\n", "        ", "return", "tf", ".", "Variable", "(", "name", "=", "name", ",", "\n", "initial_value", "=", "initial_value", ",", "\n", "trainable", "=", "False", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "# local accumulators", "\n", "", "", "self", ".", "steps_acc", "=", "get_variable", "(", "'steps_acc'", ",", "0", ",", "local", "=", "True", ")", "\n", "self", ".", "sum_acc", "=", "get_variable", "(", "'sum_acc'", ",", "tf", ".", "zeros", "(", "shape", "=", "[", "size", "]", ")", ",", "local", "=", "True", ")", "\n", "self", ".", "sumsq_acc", "=", "get_variable", "(", "'sumsq_acc'", ",", "tf", ".", "zeros", "(", "shape", "=", "[", "size", "]", ")", ",", "\n", "local", "=", "True", ")", "\n", "# mirrored variables", "\n", "self", ".", "steps", "=", "get_variable", "(", "'steps'", ",", "0", ",", "local", "=", "False", ")", "\n", "self", ".", "sum", "=", "get_variable", "(", "'sum'", ",", "tf", ".", "zeros", "(", "shape", "=", "[", "size", "]", ")", ",", "local", "=", "False", ")", "\n", "self", ".", "sumsq", "=", "get_variable", "(", "'sumsq'", ",", "tf", ".", "zeros", "(", "shape", "=", "[", "size", "]", ")", ",", "local", "=", "False", ")", "\n", "self", ".", "mean", "=", "get_variable", "(", "'mean'", ",", "tf", ".", "zeros", "(", "shape", "=", "[", "size", "]", ")", ",", "local", "=", "False", ")", "\n", "self", ".", "std", "=", "get_variable", "(", "'std'", ",", "tf", ".", "zeros", "(", "shape", "=", "[", "size", "]", ")", ",", "local", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.update": [[71, 97], ["tensorflow.reshape", "normalizer.Normalizer.steps_acc.assign_add", "normalizer.Normalizer.sum_acc.assign_add", "normalizer.Normalizer.sumsq_acc.assign_add", "normalizer.Normalizer.build", "len", "float", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "normalizer.Normalizer.finish_update", "tensorflow.reduce_prod", "tensorflow.square"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.build", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.finish_update"], ["", "def", "update", "(", "self", ",", "input_", ",", "only_accumulate", "=", "False", ")", ":", "\n", "    ", "\"\"\"Update normalization statistics.\n\n    Args:\n      input_: A tensor. All dimensions apart from the last one are treated\n        as batch dimensions.\n      only_accumulate: If True, only local accumulators are updated and the\n        normalization is not affected. Use this option if running on TPU.\n        In this case, you need to call `finish_update` method in cross-replica\n        context later to update the normalization.\n    \"\"\"", "\n", "if", "not", "self", ".", "initialized", ":", "\n", "      ", "self", ".", "build", "(", "input_", ".", "shape", ")", "\n", "\n", "# reshape to 2 dimensions", "\n", "", "shape", "=", "input_", ".", "shape", "\n", "input_", "=", "tf", ".", "reshape", "(", "input_", ",", "[", "tf", ".", "reduce_prod", "(", "shape", "[", ":", "-", "1", "]", ")", ",", "shape", "[", "-", "1", "]", "]", ")", "\n", "assert", "len", "(", "input_", ".", "shape", ")", "==", "2", "\n", "\n", "# update local accumulators", "\n", "self", ".", "steps_acc", ".", "assign_add", "(", "float", "(", "input_", ".", "shape", "[", "0", "]", ")", ")", "\n", "self", ".", "sum_acc", ".", "assign_add", "(", "tf", ".", "reduce_sum", "(", "input_", ",", "axis", "=", "0", ")", ")", "\n", "self", ".", "sumsq_acc", ".", "assign_add", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "input_", ")", ",", "axis", "=", "0", ")", ")", "\n", "\n", "if", "not", "only_accumulate", ":", "\n", "      ", "self", ".", "finish_update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.finish_update": [[98, 123], ["tensorflow.distribute.get_replica_context().all_reduce", "normalizer.Normalizer.steps_acc.assign", "normalizer.Normalizer.sum_acc.assign", "normalizer.Normalizer.sumsq_acc.assign", "normalizer.Normalizer.steps.assign_add", "normalizer.Normalizer.sum.assign_add", "normalizer.Normalizer.sumsq.assign_add", "normalizer.Normalizer.mean.assign", "normalizer.Normalizer.std.assign", "tensorflow.zeros_like", "tensorflow.zeros_like", "tensorflow.zeros_like", "tensorflow.sqrt", "tensorflow.distribute.get_replica_context", "tensorflow.maximum", "tensorflow.square"], "methods", ["None"], ["", "", "def", "finish_update", "(", "self", ")", ":", "\n", "    ", "\"\"\"Update the normalization (mean and std) based on local accumulators.\n\n    You only need to call this method manually if `update` was called with\n    `only_accumulate=True` (usually on a TPU). This method needs to be called\n    in cross-replica context (i.e. not inside Strategy.run).\n    \"\"\"", "\n", "# sum the accumulators accross all replicas", "\n", "step_increment", ",", "sum_increment", ",", "sumsq_increment", "=", "(", "\n", "tf", ".", "distribute", ".", "get_replica_context", "(", ")", ".", "all_reduce", "(", "\n", "tf", ".", "distribute", ".", "ReduceOp", ".", "SUM", ",", "\n", "[", "self", ".", "steps_acc", ",", "self", ".", "sum_acc", ",", "self", ".", "sumsq_acc", "]", ")", ")", "\n", "\n", "# zero the accumulators", "\n", "self", ".", "steps_acc", ".", "assign", "(", "tf", ".", "zeros_like", "(", "self", ".", "steps_acc", ")", ")", "\n", "self", ".", "sum_acc", ".", "assign", "(", "tf", ".", "zeros_like", "(", "self", ".", "sum_acc", ")", ")", "\n", "self", ".", "sumsq_acc", ".", "assign", "(", "tf", ".", "zeros_like", "(", "self", ".", "sumsq_acc", ")", ")", "\n", "\n", "# update the normalization", "\n", "self", ".", "steps", ".", "assign_add", "(", "step_increment", ")", "\n", "self", ".", "sum", ".", "assign_add", "(", "sum_increment", ")", "\n", "self", ".", "sumsq", ".", "assign_add", "(", "sumsq_increment", ")", "\n", "self", ".", "mean", ".", "assign", "(", "self", ".", "sum", "/", "self", ".", "steps", ")", "\n", "self", ".", "std", ".", "assign", "(", "tf", ".", "sqrt", "(", "tf", ".", "maximum", "(", "\n", "0.", ",", "(", "self", ".", "sumsq", "/", "self", ".", "steps", ")", "-", "tf", ".", "square", "(", "self", ".", "mean", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.__call__": [[124, 146], ["tensorflow.reshape", "tensorflow.clip_by_value", "tensorflow.reshape", "normalizer.Normalizer.build", "len", "tensorflow.reduce_prod"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.build"], ["", "def", "__call__", "(", "self", ",", "input_", ")", ":", "\n", "    ", "\"\"\"Normalize the tensor.\n\n    Args:\n      input_: tensor to be normalizer. All dimensions apart from the last one\n        are treated as batch dimensions.\n\n    Returns:\n      a tensor of the same shape and dtype as input_.\n    \"\"\"", "\n", "if", "not", "self", ".", "initialized", ":", "\n", "      ", "self", ".", "build", "(", "input_", ".", "shape", ")", "\n", "# reshape to 2 dimensions", "\n", "", "shape", "=", "input_", ".", "shape", "\n", "input_", "=", "tf", ".", "reshape", "(", "input_", ",", "[", "tf", ".", "reduce_prod", "(", "shape", "[", ":", "-", "1", "]", ")", ",", "shape", "[", "-", "1", "]", "]", ")", "\n", "assert", "len", "(", "input_", ".", "shape", ")", "==", "2", "\n", "# normalize", "\n", "input_", "-=", "self", ".", "mean", "[", "tf", ".", "newaxis", ",", ":", "]", "\n", "input_", "/=", "self", ".", "std", "[", "tf", ".", "newaxis", ",", ":", "]", "+", "self", ".", "eps", "\n", "input_", "=", "tf", ".", "clip_by_value", "(", "input_", ",", "*", "self", ".", "clip_range", ")", "\n", "# reshape to the original shape", "\n", "return", "tf", ".", "reshape", "(", "input_", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.get_logs": [[147, 153], ["dict", "range"], "methods", ["None"], ["", "def", "get_logs", "(", "self", ")", ":", "\n", "    ", "logs", "=", "dict", "(", ")", "\n", "for", "key", ",", "var", "in", "[", "(", "'mean'", ",", "self", ".", "mean", ")", ",", "(", "'std'", ",", "self", ".", "std", ")", "]", ":", "\n", "      ", "for", "i", "in", "range", "(", "var", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "logs", "[", "'%s/%d'", "%", "(", "key", ",", "i", ")", "]", "=", "var", "[", "i", "]", "\n", "", "", "return", "logs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.__init__": [[161, 164], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "policy", ",", "normalizer", ")", ":", "\n", "    ", "self", ".", "policy", "=", "policy", "\n", "self", ".", "normalizer", "=", "normalizer", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper._norm_env_output": [[165, 173], ["tensorflow.nest.flatten", "normalizer.NormalizeObservationsWrapper.normalizer", "tensorflow.split", "tensorflow.nest.pack_sequence_as", "zip", "env_outputs._replace", "tensorflow.concat", "tensorflow.nest.flatten", "tensorflow.nest.flatten"], "methods", ["None"], ["", "def", "_norm_env_output", "(", "self", ",", "env_outputs", ")", ":", "\n", "    ", "flat", "=", "tf", ".", "nest", ".", "flatten", "(", "env_outputs", ".", "observation", ")", "\n", "normalized", "=", "self", ".", "normalizer", "(", "tf", ".", "concat", "(", "values", "=", "flat", ",", "axis", "=", "-", "1", ")", ")", "\n", "normalized", "=", "tf", ".", "split", "(", "normalized", ",", "[", "t", ".", "shape", "[", "-", "1", "]", "for", "t", "in", "flat", "]", ",", "axis", "=", "-", "1", ")", "\n", "normalized", "=", "tf", ".", "nest", ".", "pack_sequence_as", "(", "env_outputs", ".", "observation", ",", "normalized", ")", "\n", "for", "a", ",", "b", "in", "zip", "(", "tf", ".", "nest", ".", "flatten", "(", "flat", ")", ",", "tf", ".", "nest", ".", "flatten", "(", "normalized", ")", ")", ":", "\n", "      ", "assert", "a", ".", "shape", "==", "b", ".", "shape", "\n", "", "return", "env_outputs", ".", "_replace", "(", "observation", "=", "normalized", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.initial_state": [[174, 177], ["normalizer.NormalizeObservationsWrapper.policy.initial_state"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state"], ["", "@", "tf", ".", "function", "\n", "def", "initial_state", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "self", ".", "policy", ".", "initial_state", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_action": [[183, 186], ["normalizer.NormalizeObservationsWrapper.__call__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.__call__"], ["", "@", "tf", ".", "function", "\n", "def", "get_action", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "self", ".", "__call__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.__call__": [[187, 196], ["normalizer.NormalizeObservationsWrapper.policy", "tensorflow.nest.flatten", "normalizer.NormalizeObservationsWrapper.normalizer.update", "normalizer.NormalizeObservationsWrapper._norm_env_output", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.update", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper._norm_env_output"], ["", "def", "__call__", "(", "self", ",", "prev_actions", ",", "env_outputs", ",", "*", "args", ",", "\n", "is_training", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "is_training", ":", "\n", "      ", "flat", "=", "tf", ".", "nest", ".", "flatten", "(", "env_outputs", ".", "observation", ")", "\n", "self", ".", "normalizer", ".", "update", "(", "tf", ".", "concat", "(", "values", "=", "flat", ",", "axis", "=", "-", "1", ")", ",", "\n", "only_accumulate", "=", "True", ")", "\n", "\n", "", "return", "self", ".", "policy", "(", "prev_actions", ",", "self", ".", "_norm_env_output", "(", "env_outputs", ")", ",", "*", "args", ",", "\n", "is_training", "=", "is_training", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.end_of_training_step_callback": [[197, 199], ["normalizer.NormalizeObservationsWrapper.normalizer.finish_update"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.Normalizer.finish_update"], ["", "def", "end_of_training_step_callback", "(", "self", ")", ":", "\n", "    ", "self", ".", "normalizer", ".", "finish_update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_Q": [[201, 204], ["normalizer.NormalizeObservationsWrapper.policy.get_Q", "normalizer.NormalizeObservationsWrapper._norm_env_output"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_Q", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper._norm_env_output"], ["", "def", "get_Q", "(", "self", ",", "prev_action", ",", "env_output", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "self", ".", "policy", ".", "get_Q", "(", "\n", "prev_action", ",", "self", ".", "_norm_env_output", "(", "env_output", ")", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_V": [[205, 208], ["normalizer.NormalizeObservationsWrapper.policy.get_V", "normalizer.NormalizeObservationsWrapper._norm_env_output"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_V", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper._norm_env_output"], ["", "def", "get_V", "(", "self", ",", "prev_action", ",", "env_output", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "self", ".", "policy", ".", "get_V", "(", "\n", "prev_action", ",", "self", ".", "_norm_env_output", "(", "env_output", ")", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_action_params": [[209, 212], ["normalizer.NormalizeObservationsWrapper.policy.get_action_params", "normalizer.NormalizeObservationsWrapper._norm_env_output"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper.get_action_params", "home.repos.pwc.inspect_result.google-research_seed_rl.common.normalizer.NormalizeObservationsWrapper._norm_env_output"], ["", "def", "get_action_params", "(", "self", ",", "prev_action", ",", "env_output", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "self", ".", "policy", ".", "get_action_params", "(", "\n", "prev_action", ",", "self", ".", "_norm_env_output", "(", "env_output", ")", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.__init__": [[34, 48], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "param_size", ",", "\n", "create_dist", ")", ":", "\n", "    ", "\"\"\"Abstract class for parametric (action) distribution.\n\n    Specifies how to transform distribution parameters (i.e. actor output)\n    into a distribution over actions.\n\n    Args:\n      param_size: Size of the parameters for the distribution\n      create_dist: Function from parameters to tf Distribution.\n    \"\"\"", "\n", "self", ".", "_param_size", "=", "param_size", "\n", "self", ".", "_create_dist", "=", "create_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.create_dist": [[49, 52], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "create_dist", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_create_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.__call__": [[53, 55], ["parametric_distribution.ParametricDistribution.create_dist"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.create_dist"], ["", "def", "__call__", "(", "self", ",", "params", ")", ":", "\n", "    ", "return", "self", ".", "create_dist", "(", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.param_size": [[56, 59], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "param_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_param_size", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.reparametrizable": [[60, 65], ["parametric_distribution.ParametricDistribution._create_dist", "tensorflow.zeros"], "methods", ["None"], ["", "@", "property", "\n", "def", "reparametrizable", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_create_dist", "(", "tf", ".", "zeros", "(", "\n", "(", "self", ".", "_param_size", ",", "\n", ")", ")", ")", ".", "reparameterization_type", "==", "tfd", ".", "FULLY_REPARAMETERIZED", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.sample": [[66, 68], ["parametric_distribution.ParametricDistribution._create_dist().sample", "parametric_distribution.ParametricDistribution._create_dist"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], ["", "def", "sample", "(", "self", ",", "parameters", ")", ":", "\n", "    ", "return", "self", ".", "_create_dist", "(", "parameters", ")", ".", "sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.log_prob": [[69, 71], ["parametric_distribution.ParametricDistribution._create_dist().log_prob", "parametric_distribution.ParametricDistribution._create_dist"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.log_prob"], ["", "def", "log_prob", "(", "self", ",", "parameters", ",", "actions", ")", ":", "\n", "    ", "return", "self", ".", "_create_dist", "(", "parameters", ")", ".", "log_prob", "(", "actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.entropy": [[72, 75], ["parametric_distribution.ParametricDistribution._create_dist().entropy", "parametric_distribution.ParametricDistribution._create_dist"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.entropy"], ["", "def", "entropy", "(", "self", ",", "parameters", ")", ":", "\n", "    ", "\"\"\"Return the entropy of the given distribution.\"\"\"", "\n", "return", "self", ".", "_create_dist", "(", "parameters", ")", ".", "entropy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.kl_divergence": [[76, 81], ["parametric_distribution.ParametricDistribution._create_dist", "parametric_distribution.ParametricDistribution._create_dist", "tfd.kl_divergence"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.kl_divergence"], ["", "def", "kl_divergence", "(", "self", ",", "parameters_a", ",", "parameters_b", ")", ":", "\n", "    ", "\"\"\"Return KL divergence between the two distributions.\"\"\"", "\n", "dist_a", "=", "self", ".", "_create_dist", "(", "parameters_a", ")", "\n", "dist_b", "=", "self", ".", "_create_dist", "(", "parameters_b", ")", "\n", "return", "tfd", ".", "kl_divergence", "(", "dist_a", ",", "dist_b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.__init__": [[127, 155], ["tfd.TransformedDistribution.__init__", "parametric_distribution.TanhTransformedDistribution.bijector.inverse", "tensorflow.math.log", "parametric_distribution.TanhTransformedDistribution.distribution.log_cdf", "parametric_distribution.TanhTransformedDistribution.distribution.log_survival_function", "tensorflow_probability.bijectors.Tanh"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log"], ["def", "__init__", "(", "self", ",", "distribution", ",", "threshold", "=", ".999", ",", "validate_args", "=", "False", ")", ":", "\n", "    ", "\"\"\"Initialize the distribution.\n\n    Args:\n      distribution: The distribution to transform.\n      threshold: Clipping value of the action when computing the logprob.\n      validate_args: Passed to super class.\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "distribution", "=", "distribution", ",", "\n", "bijector", "=", "tfp", ".", "bijectors", ".", "Tanh", "(", ")", ",", "\n", "validate_args", "=", "validate_args", ")", "\n", "# Computes the log of the average probability distribution outside the", "\n", "# clipping range, i.e. on the interval [-inf, -atanh(threshold)] for", "\n", "# log_prob_left and [atanh(threshold), inf] for log_prob_right.", "\n", "self", ".", "_threshold", "=", "threshold", "\n", "inverse_threshold", "=", "self", ".", "bijector", ".", "inverse", "(", "threshold", ")", "\n", "# Let epsilon = 1 - threshold", "\n", "# average(pdf) on [threshold, 1] = probability([threshold, 1])/epsilon", "\n", "# So log(average(pdf)) = log(probability) - log(epsilon)", "\n", "log_epsilon", "=", "tf", ".", "math", ".", "log", "(", "1.", "-", "threshold", ")", "\n", "# Those 2 values are differentiable w.r.t. model parameters, such that the", "\n", "# gradient is defined everywhere.", "\n", "# There won't be any gradient w.r.t the action though.", "\n", "self", ".", "_log_prob_left", "=", "self", ".", "distribution", ".", "log_cdf", "(", "\n", "-", "inverse_threshold", ")", "-", "log_epsilon", "\n", "self", ".", "_log_prob_right", "=", "self", ".", "distribution", ".", "log_survival_function", "(", "\n", "inverse_threshold", ")", "-", "log_epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.log_prob": [[156, 166], ["tensorflow.clip_by_value", "tensorflow.where", "tensorflow.where", "super().log_prob"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.log_prob"], ["", "def", "log_prob", "(", "self", ",", "event", ")", ":", "\n", "# Without this clip there would be NaNs in the inner tf.where and that", "\n", "# causes issues for some reasons.", "\n", "    ", "event", "=", "tf", ".", "clip_by_value", "(", "event", ",", "-", "self", ".", "_threshold", ",", "self", ".", "_threshold", ")", "\n", "# The inverse image of {threshold} is the interval [atanh(threshold), inf]", "\n", "# which has a probability of \"log_prob_right\" under the given distribution.", "\n", "return", "tf", ".", "where", "(", "\n", "event", "<=", "-", "self", ".", "_threshold", ",", "self", ".", "_log_prob_left", ",", "\n", "tf", ".", "where", "(", "event", ">=", "self", ".", "_threshold", ",", "self", ".", "_log_prob_right", ",", "\n", "super", "(", ")", ".", "log_prob", "(", "event", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.mode": [[167, 169], ["parametric_distribution.TanhTransformedDistribution.bijector.forward", "parametric_distribution.TanhTransformedDistribution.distribution.mode"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.mode"], ["", "def", "mode", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "bijector", ".", "forward", "(", "self", ".", "distribution", ".", "mode", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.mean": [[170, 172], ["parametric_distribution.TanhTransformedDistribution.bijector.forward", "parametric_distribution.TanhTransformedDistribution.distribution.mean"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.mean"], ["", "def", "mean", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "bijector", ".", "forward", "(", "self", ".", "distribution", ".", "mean", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.entropy": [[173, 178], ["parametric_distribution.TanhTransformedDistribution.distribution.entropy", "parametric_distribution.TanhTransformedDistribution.bijector.forward_log_det_jacobian", "parametric_distribution.TanhTransformedDistribution.distribution.sample"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.entropy", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], ["", "def", "entropy", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "# We return an estimation using a single sample of the log_det_jacobian.", "\n", "# We can still do some backpropagation with this estimate.", "\n", "    ", "return", "self", ".", "distribution", ".", "entropy", "(", ")", "+", "self", ".", "bijector", ".", "forward_log_det_jacobian", "(", "\n", "self", ".", "distribution", ".", "sample", "(", "seed", "=", "seed", ")", ",", "event_ndims", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ClippedIdentity.__init__": [[213, 217], ["tensorflow.name_scope", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "validate_args", "=", "False", ",", "name", "=", "'clipped_identity'", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "name", ")", "as", "name", ":", "\n", "      ", "super", "(", "ClippedIdentity", ",", "self", ")", ".", "__init__", "(", "\n", "validate_args", "=", "validate_args", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ClippedIdentity._is_increasing": [[218, 221], ["None"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "_is_increasing", "(", "cls", ")", ":", "\n", "    ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ClippedIdentity._forward": [[222, 224], ["tensorflow.clip_by_value"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "tf", ".", "clip_by_value", "(", "x", ",", "-", "1.", ",", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.categorical_distribution": [[83, 98], ["parametric_distribution.ParametricDistribution", "tfd.Categorical"], "function", ["None"], ["", "", "def", "categorical_distribution", "(", "n_actions", ",", "dtype", ")", ":", "\n", "  ", "\"\"\"Initialize the categorical distribution.\n\n  Args:\n    n_actions: the number of actions available.\n    dtype: dtype of actions, usually int32 or int64.\n\n  Returns:\n    A tuple (param size, fn(params) -> distribution)\n  \"\"\"", "\n", "\n", "def", "create_dist", "(", "parameters", ")", ":", "\n", "    ", "return", "tfd", ".", "Categorical", "(", "logits", "=", "parameters", ",", "dtype", "=", "dtype", ")", "\n", "\n", "", "return", "ParametricDistribution", "(", "n_actions", ",", "create_dist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.multi_categorical_distribution": [[100, 121], ["parametric_distribution.ParametricDistribution", "tensorflow.reshape", "tfd.Independent", "tfd.Categorical"], "function", ["None"], ["", "def", "multi_categorical_distribution", "(", "n_dimensions", ",", "n_actions_per_dim", ",", "dtype", ")", ":", "\n", "  ", "\"\"\"Initialize the categorical distribution.\n\n  Args:\n    n_dimensions: the dimensionality of actions.\n    n_actions_per_dim: number of actions available per dimension.\n    dtype: dtype of actions, usually int32 or int64.\n\n  Returns:\n    A tuple (param size, fn(params) -> distribution)\n  \"\"\"", "\n", "\n", "def", "create_dist", "(", "parameters", ")", ":", "\n", "    ", "batch_shape", "=", "parameters", ".", "shape", "[", ":", "-", "1", "]", "\n", "logits_shape", "=", "[", "n_dimensions", ",", "n_actions_per_dim", "]", "\n", "logits", "=", "tf", ".", "reshape", "(", "parameters", ",", "batch_shape", "+", "logits_shape", ")", "\n", "return", "tfd", ".", "Independent", "(", "\n", "tfd", ".", "Categorical", "(", "logits", "=", "logits", ",", "dtype", "=", "dtype", ")", ",", "\n", "reinterpreted_batch_ndims", "=", "1", ")", "\n", "\n", "", "return", "ParametricDistribution", "(", "n_dimensions", "*", "n_actions_per_dim", ",", "create_dist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution._kl_transformed": [[180, 185], ["tensorflow_probability.python.distributions.kullback_leibler.RegisterKL", "tensorflow_probability.python.distributions.kullback_leibler.kl_divergence"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.kl_divergence"], ["", "", "@", "kullback_leibler", ".", "RegisterKL", "(", "TanhTransformedDistribution", ",", "\n", "TanhTransformedDistribution", ")", "\n", "def", "_kl_transformed", "(", "a", ",", "b", ",", "name", "=", "'kl_transformed'", ")", ":", "\n", "  ", "return", "kullback_leibler", ".", "kl_divergence", "(", "\n", "a", ".", "distribution", ",", "b", ".", "distribution", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.softplus_default_std_fn": [[187, 189], ["tensorflow.nn.softplus"], "function", ["None"], ["", "def", "softplus_default_std_fn", "(", "scale", ")", ":", "\n", "  ", "return", "tf", ".", "nn", ".", "softplus", "(", "scale", ")", "+", "1e-3", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.normal_tanh_distribution": [[191, 203], ["parametric_distribution.ParametricDistribution", "tensorflow.split", "gaussian_std_fn", "tfd.Normal", "tfd.Independent", "parametric_distribution.TanhTransformedDistribution"], "function", ["None"], ["", "def", "normal_tanh_distribution", "(", "num_actions", ",", "\n", "gaussian_std_fn", "=", "softplus_default_std_fn", ")", ":", "\n", "  ", "\"\"\"Normal distribution postprocessed by a tanh.\"\"\"", "\n", "\n", "def", "create_dist", "(", "parameters", ")", ":", "\n", "    ", "loc", ",", "scale", "=", "tf", ".", "split", "(", "parameters", ",", "2", ",", "axis", "=", "-", "1", ")", "\n", "scale", "=", "gaussian_std_fn", "(", "scale", ")", "\n", "normal_dist", "=", "tfd", ".", "Normal", "(", "loc", "=", "loc", ",", "scale", "=", "scale", ")", "\n", "return", "tfd", ".", "Independent", "(", "\n", "TanhTransformedDistribution", "(", "normal_dist", ")", ",", "reinterpreted_batch_ndims", "=", "1", ")", "\n", "\n", "", "return", "ParametricDistribution", "(", "2", "*", "num_actions", ",", "create_dist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.normal_clipped_distribution": [[228, 240], ["parametric_distribution.ParametricDistribution", "tensorflow.split", "gaussian_std_fn", "tfd.Normal", "tfd.Independent", "CLIPPED_IDENTITY"], "function", ["None"], ["def", "normal_clipped_distribution", "(", "num_actions", ",", "\n", "gaussian_std_fn", "=", "softplus_default_std_fn", ")", ":", "\n", "  ", "\"\"\"Normal distribution postprocessed by a clipped identity.\"\"\"", "\n", "\n", "def", "create_dist", "(", "parameters", ")", ":", "\n", "    ", "loc", ",", "scale", "=", "tf", ".", "split", "(", "parameters", ",", "2", ",", "axis", "=", "-", "1", ")", "\n", "scale", "=", "gaussian_std_fn", "(", "scale", ")", "\n", "normal_dist", "=", "tfd", ".", "Normal", "(", "loc", "=", "loc", ",", "scale", "=", "scale", ")", "\n", "return", "tfd", ".", "Independent", "(", "\n", "CLIPPED_IDENTITY", "(", "normal_dist", ")", ",", "reinterpreted_batch_ndims", "=", "1", ")", "\n", "\n", "", "return", "ParametricDistribution", "(", "2", "*", "num_actions", ",", "create_dist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.deterministic_tanh_distribution": [[242, 250], ["parametric_distribution.ParametricDistribution", "tfd.Independent", "parametric_distribution.TanhTransformedDistribution", "tfd.Deterministic"], "function", ["None"], ["", "def", "deterministic_tanh_distribution", "(", "num_actions", ")", ":", "\n", "\n", "  ", "def", "create_dist", "(", "parameters", ")", ":", "\n", "    ", "return", "tfd", ".", "Independent", "(", "\n", "TanhTransformedDistribution", "(", "tfd", ".", "Deterministic", "(", "loc", "=", "parameters", ")", ")", ",", "\n", "reinterpreted_batch_ndims", "=", "1", ")", "\n", "\n", "", "return", "ParametricDistribution", "(", "num_actions", ",", "create_dist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.joint_distribution": [[252, 276], ["parametric_distribution.ParametricDistribution", "tensorflow.split", "tfd.Blockwise", "sum", "dist", "zip"], "function", ["None"], ["", "def", "joint_distribution", "(", "parametric_distributions", ",", "\n", "dtype_override", "=", "tf", ".", "float32", ")", ":", "\n", "  ", "\"\"\"Initialize the distribution.\n\n  Args:\n    parametric_distributions: A list of ParametricDistributions.\n    dtype_override: The type to output the actions in.\n\n  Returns:\n    A tuple (param size, fn(params) -> distribution)\n  \"\"\"", "\n", "param_sizes", "=", "[", "\n", "dist", ".", "param_size", "for", "dist", "in", "parametric_distributions", "\n", "]", "\n", "\n", "def", "create_dist", "(", "parameters", ")", ":", "\n", "    ", "split_params", "=", "tf", ".", "split", "(", "parameters", ",", "param_sizes", ",", "axis", "=", "-", "1", ")", "\n", "dists", "=", "[", "\n", "dist", "(", "param", ")", "\n", "for", "(", "dist", ",", "param", ")", "in", "zip", "(", "parametric_distributions", ",", "split_params", ")", "\n", "]", "\n", "return", "tfd", ".", "Blockwise", "(", "dists", ",", "dtype_override", "=", "dtype_override", ")", "\n", "\n", "", "return", "ParametricDistribution", "(", "sum", "(", "param_sizes", ")", ",", "create_dist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.check_multi_discrete_space": [[278, 281], ["min", "max", "ValueError"], "function", ["None"], ["", "def", "check_multi_discrete_space", "(", "space", ")", ":", "\n", "  ", "if", "min", "(", "space", ".", "nvec", ")", "!=", "max", "(", "space", ".", "nvec", ")", ":", "\n", "    ", "raise", "ValueError", "(", "'space nvec must be constant: {}'", ".", "format", "(", "space", ".", "nvec", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.check_box_space": [[283, 291], ["any", "any", "len", "ValueError", "ValueError"], "function", ["None"], ["", "", "def", "check_box_space", "(", "space", ")", ":", "\n", "  ", "assert", "len", "(", "space", ".", "shape", ")", "==", "1", ",", "space", ".", "shape", "\n", "if", "any", "(", "l", "!=", "-", "1", "for", "l", "in", "space", ".", "low", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "f'Learner only supports actions bounded to [-1,1]: {space.low}'", ")", "\n", "", "if", "any", "(", "h", "!=", "1", "for", "h", "in", "space", ".", "high", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "f'Learner only supports actions bounded to [-1,1]: {space.high}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space": [[293, 333], ["isinstance", "parametric_distribution.categorical_distribution", "isinstance", "parametric_distribution.check_multi_discrete_space", "parametric_distribution.multi_categorical_distribution", "isinstance", "parametric_distribution.check_box_space", "isinstance", "len", "parametric_distribution.ContinuousDistributionConfig", "parametric_distribution.normal_tanh_distribution", "parametric_distribution.joint_distribution", "ValueError", "parametric_distribution.normal_clipped_distribution", "ValueError", "parametric_distribution.get_parametric_distribution_for_action_space"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.categorical_distribution", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.check_multi_discrete_space", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.multi_categorical_distribution", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.check_box_space", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.normal_tanh_distribution", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.joint_distribution", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.normal_clipped_distribution", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space"], ["", "", "def", "get_parametric_distribution_for_action_space", "(", "action_space", ",", "\n", "continuous_config", "=", "None", ")", ":", "\n", "  ", "\"\"\"Returns an action distribution parametrization based on the action space.\n\n  Args:\n    action_space: action space of the environment\n    continuous_config: Configuration for the continuous action distribution\n      (used when needed by the action space)..\n  \"\"\"", "\n", "if", "isinstance", "(", "action_space", ",", "gym", ".", "spaces", ".", "Discrete", ")", ":", "\n", "    ", "return", "categorical_distribution", "(", "action_space", ".", "n", ",", "dtype", "=", "action_space", ".", "dtype", ")", "\n", "", "elif", "isinstance", "(", "action_space", ",", "gym", ".", "spaces", ".", "MultiDiscrete", ")", ":", "\n", "    ", "check_multi_discrete_space", "(", "action_space", ")", "\n", "return", "multi_categorical_distribution", "(", "\n", "n_dimensions", "=", "len", "(", "action_space", ".", "nvec", ")", ",", "\n", "n_actions_per_dim", "=", "action_space", ".", "nvec", "[", "0", "]", ",", "\n", "dtype", "=", "action_space", ".", "dtype", ")", "\n", "", "elif", "isinstance", "(", "action_space", ",", "gym", ".", "spaces", ".", "Box", ")", ":", "# continuous actions", "\n", "    ", "check_box_space", "(", "action_space", ")", "\n", "if", "continuous_config", "is", "None", ":", "\n", "      ", "continuous_config", "=", "ContinuousDistributionConfig", "(", ")", "\n", "", "if", "continuous_config", ".", "postprocessor", "==", "'Tanh'", ":", "\n", "      ", "return", "normal_tanh_distribution", "(", "\n", "num_actions", "=", "action_space", ".", "shape", "[", "0", "]", ",", "\n", "gaussian_std_fn", "=", "continuous_config", ".", "gaussian_std_fn", ")", "\n", "", "elif", "continuous_config", ".", "postprocessor", "==", "'ClippedIdentity'", ":", "\n", "      ", "return", "normal_clipped_distribution", "(", "\n", "num_actions", "=", "action_space", ".", "shape", "[", "0", "]", ",", "\n", "gaussian_std_fn", "=", "continuous_config", ".", "gaussian_std_fn", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "f'Postprocessor {continuous_config.postprocessor} not supported.'", ")", "\n", "", "", "elif", "isinstance", "(", "action_space", ",", "gym", ".", "spaces", ".", "Tuple", ")", ":", "# mixed actions", "\n", "    ", "return", "joint_distribution", "(", "[", "\n", "get_parametric_distribution_for_action_space", "(", "subspace", ",", "\n", "continuous_config", ")", "\n", "for", "subspace", "in", "action_space", "\n", "]", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "f'Unsupported action space {action_space}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.safe_exp": [[335, 343], ["tensorflow.exp", "tensorflow.clip_by_value"], "function", ["None"], ["", "", "@", "tf", ".", "custom_gradient", "\n", "def", "safe_exp", "(", "x", ")", ":", "\n", "  ", "e", "=", "tf", ".", "exp", "(", "tf", ".", "clip_by_value", "(", "x", ",", "-", "15", ",", "15", ")", ")", "\n", "\n", "def", "grad", "(", "dy", ")", ":", "\n", "    ", "return", "dy", "*", "e", "\n", "\n", "", "return", "e", ",", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.safe_exp_std_fn": [[345, 350], ["tensorflow.math.log", "abs", "parametric_distribution.safe_exp", "fn"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.safe_exp"], ["", "def", "safe_exp_std_fn", "(", "std_for_zero_param", ":", "float", ",", "min_std", ")", ":", "\n", "  ", "std_shift", "=", "tf", ".", "math", ".", "log", "(", "std_for_zero_param", "-", "min_std", ")", "\n", "fn", "=", "lambda", "scale", ":", "safe_exp", "(", "scale", "+", "std_shift", ")", "+", "min_std", "\n", "assert", "abs", "(", "fn", "(", "0", ")", "-", "std_for_zero_param", ")", "<", "1e-3", "\n", "return", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.softplus_std_fn": [[352, 357], ["tensorflow_probability.math.softplus_inverse", "abs", "tensorflow.nn.softplus", "fn"], "function", ["None"], ["", "def", "softplus_std_fn", "(", "std_for_zero_param", ":", "float", ",", "min_std", ":", "float", ")", ":", "\n", "  ", "std_shift", "=", "tfp", ".", "math", ".", "softplus_inverse", "(", "std_for_zero_param", "-", "min_std", ")", "\n", "fn", "=", "lambda", "scale", ":", "tf", ".", "nn", ".", "softplus", "(", "scale", "+", "std_shift", ")", "+", "min_std", "\n", "assert", "abs", "(", "fn", "(", "0", ")", "-", "std_for_zero_param", ")", "<", "1e-3", "\n", "return", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.continuous_action_config": [[376, 413], ["parametric_distribution.ContinuousDistributionConfig", "float", "parametric_distribution.safe_exp_std_fn", "parametric_distribution.softplus_std_fn", "ValueError"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.safe_exp_std_fn", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.softplus_std_fn"], ["", "def", "continuous_action_config", "(", "\n", "action_min_gaussian_std", ":", "float", "=", "1e-3", ",", "\n", "action_gaussian_std_fn", ":", "str", "=", "'softplus'", ",", "\n", "action_std_for_zero_param", ":", "float", "=", "1", ",", "\n", "action_postprocessor", ":", "str", "=", "'Tanh'", ")", "->", "ContinuousDistributionConfig", ":", "\n", "  ", "\"\"\"Configures continuous distributions from numerical and string inputs.\n\n  Currently, only NormalSquashedDistribution is supported. The default\n  configuration corresponds to a normal distribution with standard deviation\n  computed from params using an unshifted softplus, followed by tanh.\n  Args:\n    action_min_gaussian_std: minimal standard deviation.\n    action_gaussian_std_fn: transform for standard deviation parameters.\n    action_std_for_zero_param: shifts the transform to get this std when\n      parameters are zero.\n    action_postprocessor: the non-linearity applied to the sample from the\n      gaussian.\n\n  Returns:\n    A continuous distribution setup, with the parameters transform\n    to get the standard deviation applied with a shift, as configured.\n  \"\"\"", "\n", "config", "=", "ContinuousDistributionConfig", "(", ")", "\n", "\n", "config", ".", "min_gaussian_std", "=", "float", "(", "action_min_gaussian_std", ")", "\n", "if", "action_gaussian_std_fn", "==", "'safe_exp'", ":", "\n", "    ", "config", ".", "gaussian_std_fn", "=", "safe_exp_std_fn", "(", "action_std_for_zero_param", ",", "\n", "config", ".", "min_gaussian_std", ")", "\n", "", "elif", "action_gaussian_std_fn", "==", "'softplus'", ":", "\n", "    ", "config", ".", "gaussian_std_fn", "=", "softplus_std_fn", "(", "action_std_for_zero_param", ",", "\n", "config", ".", "min_gaussian_std", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'Flag `action_gaussian_std_fn` only supports safe_exp and'", "\n", "f' softplus, got: {action_gaussian_std_fn}'", ")", "\n", "\n", "", "config", ".", "postprocessor", "=", "action_postprocessor", "\n", "return", "config", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.UniformBoundActionSpaceWrapper.__init__": [[48, 64], ["gym.Wrapper.__init__", "isinstance", "gym.spaces.Box", "numpy.ones", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "    ", "\"\"\"Initialize the wrapper.\n\n    Args:\n      env: Environment to be wrapped. It must have an action space of type\n        gym.spaces.Box.\n    \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "assert", "isinstance", "(", "env", ".", "action_space", ",", "gym", ".", "spaces", ".", "Box", ")", "\n", "assert", "env", ".", "action_space", ".", "dtype", "==", "np", ".", "float32", "\n", "n_action_dim", "=", "env", ".", "action_space", ".", "shape", "[", "0", "]", "\n", "self", ".", "half_range", "=", "(", "env", ".", "action_space", ".", "high", "-", "env", ".", "action_space", ".", "low", ")", "/", "2.", "\n", "self", ".", "center", "=", "env", ".", "action_space", ".", "low", "+", "self", ".", "half_range", "\n", "self", ".", "action_space", "=", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "-", "np", ".", "ones", "(", "n_action_dim", ")", ",", "\n", "high", "=", "np", ".", "ones", "(", "n_action_dim", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.UniformBoundActionSpaceWrapper.step": [[65, 70], ["numpy.clip", "env_wrappers.UniformBoundActionSpaceWrapper.env.step", "numpy.abs().max", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "assert", "np", ".", "abs", "(", "action", ")", ".", "max", "(", ")", "<", "1.00001", ",", "'Action: %s'", "%", "action", "\n", "action", "=", "np", ".", "clip", "(", "action", ",", "-", "1", ",", "1", ")", "\n", "action", "=", "self", ".", "center", "+", "action", "*", "self", ".", "half_range", "\n", "return", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.DiscretizeEnvWrapper.__init__": [[75, 115], ["gym.spaces.MultiDiscrete", "isinstance", "len", "numpy.linspace", "numpy.concatenate", "numpy.log", "numpy.log", "numpy.linspace", "numpy.exp", "numpy.exp", "numpy.flip"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log"], ["def", "__init__", "(", "self", ",", "env", ",", "n_actions_per_dim", ",", "discretization", "=", "'lin'", ",", "\n", "action_ratio", "=", "None", ")", ":", "\n", "    ", "\"\"\"\"Discretize actions.\n\n    Args:\n      env: Environment to be wrapped.\n      n_actions_per_dim: The number of buckets per action dimension.\n      discretization: Discretization mode, can be 'lin' or 'log',\n        'lin' spaces buckets linearly between low and high while 'log'\n        spaces them logarithmically.\n      action_ratio: The ratio of the highest and lowest positive action\n        for logarithim discretization.\n    \"\"\"", "\n", "\n", "self", ".", "env", "=", "env", "\n", "assert", "len", "(", "env", ".", "action_space", ".", "shape", ")", "==", "1", "\n", "dim_action", "=", "env", ".", "action_space", ".", "shape", "[", "0", "]", "\n", "self", ".", "action_space", "=", "gym", ".", "spaces", ".", "MultiDiscrete", "(", "[", "n_actions_per_dim", "]", "*", "\n", "dim_action", ")", "\n", "self", ".", "observation_space", "=", "env", ".", "observation_space", "\n", "high", "=", "env", ".", "action_space", ".", "high", "\n", "if", "isinstance", "(", "high", ",", "float", ")", ":", "\n", "      ", "assert", "env", ".", "action_space", ".", "low", "==", "-", "high", "\n", "", "else", ":", "\n", "      ", "high", "=", "high", "[", "0", "]", "\n", "assert", "(", "env", ".", "action_space", ".", "high", "==", "[", "high", "]", "*", "dim_action", ")", ".", "all", "(", ")", "\n", "assert", "(", "env", ".", "action_space", ".", "low", "==", "-", "env", ".", "action_space", ".", "high", ")", ".", "all", "(", ")", "\n", "", "if", "discretization", "==", "'log'", ":", "\n", "      ", "assert", "n_actions_per_dim", "%", "2", "==", "1", ",", "(", "\n", "'The number of actions per dimension '", "\n", "'has to be odd for logarithmic discretization.'", ")", "\n", "assert", "action_ratio", "is", "not", "None", "\n", "log_range", "=", "np", ".", "linspace", "(", "np", ".", "log", "(", "high", "/", "action_ratio", ")", ",", "\n", "np", ".", "log", "(", "high", ")", ",", "\n", "n_actions_per_dim", "//", "2", ")", "\n", "self", ".", "action_set", "=", "np", ".", "concatenate", "(", "[", "-", "np", ".", "exp", "(", "np", ".", "flip", "(", "log_range", ")", ")", ",", "\n", "[", "0.", "]", ",", "\n", "np", ".", "exp", "(", "log_range", ")", "]", ")", "\n", "", "elif", "discretization", "==", "'lin'", ":", "\n", "      ", "self", ".", "action_set", "=", "np", ".", "linspace", "(", "-", "high", ",", "high", ",", "n_actions_per_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.DiscretizeEnvWrapper.step": [[116, 122], ["env_wrappers.DiscretizeEnvWrapper.action_space.contains", "numpy.take", "env_wrappers.DiscretizeEnvWrapper.env.action_space.contains", "env_wrappers.DiscretizeEnvWrapper.env.step"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.step"], ["", "", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "assert", "self", ".", "action_space", ".", "contains", "(", "action", ")", "\n", "action", "=", "np", ".", "take", "(", "self", ".", "action_set", ",", "action", ")", "\n", "assert", "self", ".", "env", ".", "action_space", ".", "contains", "(", "action", ")", "\n", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "return", "obs", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.DiscretizeEnvWrapper.reset": [[123, 125], ["env_wrappers.DiscretizeEnvWrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.DiscretizeEnvWrapper.render": [[126, 128], ["env_wrappers.DiscretizeEnvWrapper.env.render"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.BatchedEnvironment.render"], ["", "def", "render", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "self", ".", "env", ".", "render", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.BatchedEnvironment.__init__": [[133, 151], ["numpy.array", "create_env_fn", "range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "create_env_fn", ",", "batch_size", ",", "id_offset", ",", "config", ")", ":", "\n", "    ", "\"\"\"Initialize the wrapper.\n\n    Args:\n      create_env_fn: A function to create environment instances.\n      batch_size: The number of environment instances to create.\n      id_offset: The offset for environment ids. Environments receive sequential\n        ids starting from this offset.\n      config: Config object defining configuration of the environment\n    \"\"\"", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "# Note: some environments require an argument to be of a native Python", "\n", "# numeric type. If we create env_ids as a numpy array, its elements will", "\n", "# be of type np.int32. So we create it as a plain Python array first.", "\n", "env_ids", "=", "[", "id_offset", "+", "i", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "self", ".", "_envs", "=", "[", "create_env_fn", "(", "id", ",", "config", ")", "for", "id", "in", "env_ids", "]", "\n", "self", ".", "_env_ids", "=", "np", ".", "array", "(", "env_ids", ",", "np", ".", "int32", ")", "\n", "self", ".", "_obs", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.BatchedEnvironment.env_ids": [[152, 155], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "env_ids", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_env_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.BatchedEnvironment.envs": [[156, 159], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "envs", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_envs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.BatchedEnvironment._mapped_obs": [[160, 173], ["tensorflow.nest.map_structure", "numpy.array"], "methods", ["None"], ["", "@", "property", "\n", "def", "_mapped_obs", "(", "self", ")", ":", "\n", "    ", "\"\"\"Maps observations to preserve the original structure.\n\n    This is needed to support environments that return structured observations.\n    For example, gym.GoalEnv has `observation`, `desired_goal`, and\n    `achieved_goal` elements in its observations. In this case the batched\n    observations would contain the same three elements batched by element.\n\n    Returns:\n      Mapped observations.\n    \"\"\"", "\n", "return", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "*", "args", ":", "np", ".", "array", "(", "args", ")", ",", "*", "self", ".", "_obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.BatchedEnvironment.step": [[174, 184], ["numpy.zeros", "numpy.zeros", "range", "env_wrappers.BatchedEnvironment._envs[].step"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.step"], ["", "def", "step", "(", "self", ",", "action_batch", ")", ":", "\n", "    ", "\"\"\"Does one step for all batched environments sequentially.\"\"\"", "\n", "num_envs", "=", "self", ".", "_batch_size", "\n", "rewards", "=", "np", ".", "zeros", "(", "num_envs", ",", "np", ".", "float32", ")", "\n", "dones", "=", "np", ".", "zeros", "(", "num_envs", ",", "np", ".", "bool", ")", "\n", "infos", "=", "[", "None", "]", "*", "num_envs", "\n", "for", "i", "in", "range", "(", "num_envs", ")", ":", "\n", "      ", "self", ".", "_obs", "[", "i", "]", ",", "rewards", "[", "i", "]", ",", "dones", "[", "i", "]", ",", "infos", "[", "i", "]", "=", "self", ".", "_envs", "[", "i", "]", ".", "step", "(", "\n", "action_batch", "[", "i", "]", ")", "\n", "", "return", "self", ".", "_mapped_obs", ",", "rewards", ",", "dones", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.BatchedEnvironment.reset": [[185, 190], ["env.reset"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "\"\"\"Reset all environments.\"\"\"", "\n", "observations", "=", "[", "env", ".", "reset", "(", ")", "for", "env", "in", "self", ".", "_envs", "]", "\n", "self", ".", "_obs", "=", "observations", "\n", "return", "self", ".", "_mapped_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.BatchedEnvironment.reset_if_done": [[191, 207], ["range", "len", "env_wrappers.BatchedEnvironment.envs[].reset"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset"], ["", "def", "reset_if_done", "(", "self", ",", "done", ")", ":", "\n", "    ", "\"\"\"Reset the environments for which 'done' is True.\n\n    Args:\n      done: An array that specifies which environments are 'done', meaning their\n        episode is terminated.\n\n    Returns:\n      Observations for all environments.\n    \"\"\"", "\n", "assert", "self", ".", "_obs", "is", "not", "None", ",", "'reset_if_done() called before reset()'", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_envs", ")", ")", ":", "\n", "      ", "if", "done", "[", "i", "]", ":", "\n", "        ", "self", ".", "_obs", "[", "i", "]", "=", "self", ".", "envs", "[", "i", "]", ".", "reset", "(", ")", "\n", "\n", "", "", "return", "self", ".", "_mapped_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.BatchedEnvironment.render": [[208, 211], ["env_wrappers.BatchedEnvironment._envs[].render"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.BatchedEnvironment.render"], ["", "def", "render", "(", "self", ",", "mode", "=", "'human'", ",", "**", "kwargs", ")", ":", "\n", "# Render only the first one", "\n", "    ", "self", ".", "_envs", "[", "0", "]", ".", "render", "(", "mode", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.BatchedEnvironment.close": [[212, 215], ["env.close"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "    ", "for", "env", "in", "self", ".", "_envs", ":", "\n", "      ", "env", ".", "close", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.spec_to_box": [[26, 36], ["hasattr", "gym.spaces.Box", "numpy.array", "numpy.array", "gym.spaces.Box", "hasattr", "ValueError"], "function", ["None"], ["def", "spec_to_box", "(", "spec", ")", ":", "\n", "  ", "minimum", ",", "maximum", "=", "-", "np", ".", "inf", ",", "np", ".", "inf", "\n", "if", "hasattr", "(", "spec", ",", "'minimum'", ")", ":", "\n", "    ", "if", "not", "hasattr", "(", "spec", ",", "'maximum'", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'spec has minimum but no maximum: {}'", ".", "format", "(", "spec", ")", ")", "\n", "", "minimum", "=", "np", ".", "array", "(", "spec", ".", "minimum", ",", "np", ".", "float32", ")", "\n", "maximum", "=", "np", ".", "array", "(", "spec", ".", "maximum", ",", "np", ".", "float32", ")", "\n", "return", "gym", ".", "spaces", ".", "Box", "(", "minimum", ",", "maximum", ")", "\n", "\n", "", "return", "gym", ".", "spaces", ".", "Box", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ",", "shape", "=", "spec", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.flatten_and_concatenate_obs": [[38, 41], ["numpy.concatenate", "obs.astype().flatten", "obs_dict.values", "obs.astype"], "function", ["None"], ["", "def", "flatten_and_concatenate_obs", "(", "obs_dict", ")", ":", "\n", "  ", "return", "np", ".", "concatenate", "(", "\n", "[", "obs", ".", "astype", "(", "np", ".", "float32", ")", ".", "flatten", "(", ")", "for", "obs", "in", "obs_dict", ".", "values", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.__init__": [[122, 147], ["tensorflow.Module.__init__", "tensorflow.nest.map_structure", "tensorflow.Variable", "tensorflow.zeros", "tensorflow.Variable", "tensorflow.fill", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "\n", "num_envs", ",", "\n", "unroll_length", ",", "\n", "timestep_specs", ",", "\n", "num_overlapping_steps", "=", "0", ",", "\n", "name", "=", "'UnrollStore'", ")", ":", "\n", "    ", "super", "(", "UnrollStore", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "with", "self", ".", "name_scope", ":", "\n", "      ", "self", ".", "_full_length", "=", "num_overlapping_steps", "+", "unroll_length", "+", "1", "\n", "\n", "def", "create_unroll_variable", "(", "spec", ")", ":", "\n", "        ", "z", "=", "tf", ".", "zeros", "(", "\n", "[", "num_envs", ",", "self", ".", "_full_length", "]", "+", "spec", ".", "shape", ".", "dims", ",", "dtype", "=", "spec", ".", "dtype", ")", "\n", "return", "tf", ".", "Variable", "(", "z", ",", "trainable", "=", "False", ",", "name", "=", "spec", ".", "name", ")", "\n", "\n", "", "self", ".", "_unroll_length", "=", "unroll_length", "\n", "self", ".", "_num_overlapping_steps", "=", "num_overlapping_steps", "\n", "self", ".", "_state", "=", "tf", ".", "nest", ".", "map_structure", "(", "create_unroll_variable", ",", "\n", "timestep_specs", ")", "\n", "# For each environment, the index into the environment dimension of the", "\n", "# tensors in self._state where we should add the next element.", "\n", "self", ".", "_index", "=", "tf", ".", "Variable", "(", "\n", "tf", ".", "fill", "(", "[", "num_envs", "]", ",", "tf", ".", "constant", "(", "num_overlapping_steps", ",", "tf", ".", "int32", ")", ")", ",", "\n", "trainable", "=", "False", ",", "\n", "name", "=", "'index'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.unroll_specs": [[148, 152], ["tensorflow.nest.map_structure", "tensorflow.TensorSpec"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "unroll_specs", "(", "self", ")", ":", "\n", "    ", "return", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "v", ":", "tf", ".", "TensorSpec", "(", "v", ".", "shape", "[", "1", ":", "]", ",", "v", ".", "dtype", ")", ",", "\n", "self", ".", "_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append": [[153, 197], ["tensorflow.debugging.assert_equal", "tensorflow.nest.map_structure", "utils.UnrollStore._index.sparse_read", "tensorflow.stack", "zip", "utils.UnrollStore._index.scatter_add", "utils.UnrollStore._complete_unrolls", "tensorflow.shape", "tensorflow.shape", "tensorflow.nest.flatten", "tensorflow.nest.flatten", "s.scatter_nd_update", "tensorflow.IndexedSlices", "tensorflow.debugging.assert_equal", "tensorflow.unique", "tensorflow.shape", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore._complete_unrolls"], ["", "@", "tf", ".", "function", "\n", "@", "tf", ".", "Module", ".", "with_name_scope", "\n", "def", "append", "(", "self", ",", "env_ids", ",", "values", ")", ":", "\n", "    ", "\"\"\"Appends values and returns completed unrolls.\n\n    Args:\n      env_ids: 1D tensor with the list of environment IDs for which we append\n        data.\n        There must not be duplicates.\n      values: Values to add for each environment. This is a structure\n        (in the tf.nest sense) of tensors following \"timestep_specs\", with a\n        batch front dimension which must be equal to the length of 'env_ids'.\n\n    Returns:\n      A pair of:\n        - 1D tensor of the environment IDs of the completed unrolls.\n        - Completed unrolls. This is a structure of tensors following\n          'timestep_specs', with added front dimensions: [num_completed_unrolls,\n          num_overlapping_steps + unroll_length + 1].\n    \"\"\"", "\n", "tf", ".", "debugging", ".", "assert_equal", "(", "\n", "tf", ".", "shape", "(", "env_ids", ")", ",", "\n", "tf", ".", "shape", "(", "tf", ".", "unique", "(", "env_ids", ")", "[", "0", "]", ")", ",", "\n", "message", "=", "f'Duplicate environment ids in store {self.name}'", ")", "\n", "\n", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "s", ":", "tf", ".", "debugging", ".", "assert_equal", "(", "\n", "tf", ".", "shape", "(", "env_ids", ")", "[", "0", "]", ",", "\n", "tf", ".", "shape", "(", "s", ")", "[", "0", "]", ",", "\n", "message", "=", "(", "f'Batch dimension must equal the number of environments '", "\n", "f'in store {self.name}.'", ")", ")", ",", "\n", "values", ")", "\n", "\n", "\n", "curr_indices", "=", "self", ".", "_index", ".", "sparse_read", "(", "env_ids", ")", "\n", "unroll_indices", "=", "tf", ".", "stack", "(", "[", "env_ids", ",", "curr_indices", "]", ",", "axis", "=", "-", "1", ")", "\n", "for", "s", ",", "v", "in", "zip", "(", "tf", ".", "nest", ".", "flatten", "(", "self", ".", "_state", ")", ",", "tf", ".", "nest", ".", "flatten", "(", "values", ")", ")", ":", "\n", "      ", "s", ".", "scatter_nd_update", "(", "unroll_indices", ",", "v", ")", "\n", "\n", "# Intentionally not protecting against out-of-bounds to make it possible to", "\n", "# detect completed unrolls.", "\n", "", "self", ".", "_index", ".", "scatter_add", "(", "tf", ".", "IndexedSlices", "(", "1", ",", "env_ids", ")", ")", "\n", "\n", "return", "self", ".", "_complete_unrolls", "(", "env_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.reset": [[198, 226], ["utils.UnrollStore._index.scatter_update", "tensorflow.reshape", "tensorflow.tile", "tensorflow.stack", "tensorflow.nest.flatten", "tensorflow.IndexedSlices", "tensorflow.tile", "tensorflow.range", "tensorflow.zeros", "s.scatter_nd_update", "tensorflow.expand_dims", "tensorflow.concat", "tensorflow.cast", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "@", "tf", ".", "Module", ".", "with_name_scope", "\n", "def", "reset", "(", "self", ",", "env_ids", ")", ":", "\n", "    ", "\"\"\"Resets state.\n\n    Note, this is only intended to be called when environments need to be reset\n    after preemptions. Not at episode boundaries.\n\n    Args:\n      env_ids: The environments that need to have their state reset.\n    \"\"\"", "\n", "self", ".", "_index", ".", "scatter_update", "(", "\n", "tf", ".", "IndexedSlices", "(", "self", ".", "_num_overlapping_steps", ",", "env_ids", ")", ")", "\n", "\n", "# The following code is the equivalent of:", "\n", "# s[env_ids, :j] = 0", "\n", "j", "=", "self", ".", "_num_overlapping_steps", "\n", "repeated_env_ids", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "cast", "(", "env_ids", ",", "tf", ".", "int64", ")", ",", "-", "1", ")", ",", "[", "1", ",", "j", "]", ")", ",", "[", "-", "1", "]", ")", "\n", "\n", "repeated_range", "=", "tf", ".", "tile", "(", "tf", ".", "range", "(", "j", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "[", "tf", ".", "shape", "(", "env_ids", ")", "[", "0", "]", "]", ")", "\n", "indices", "=", "tf", ".", "stack", "(", "[", "repeated_env_ids", ",", "repeated_range", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "for", "s", "in", "tf", ".", "nest", ".", "flatten", "(", "self", ".", "_state", ")", ":", "\n", "      ", "z", "=", "tf", ".", "zeros", "(", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "repeated_env_ids", ")", ",", "\n", "s", ".", "shape", "[", "2", ":", "]", "]", ",", "axis", "=", "0", ")", ",", "s", ".", "dtype", ")", "\n", "s", ".", "scatter_nd_update", "(", "indices", ",", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore._complete_unrolls": [[227, 258], ["utils.UnrollStore._index.sparse_read", "tensorflow.gather", "tensorflow.cast", "tensorflow.nest.map_structure", "tensorflow.tile", "tensorflow.tile", "tensorflow.reshape", "tensorflow.stack", "tensorflow.stack", "tensorflow.nest.flatten", "utils.UnrollStore._index.scatter_update", "tensorflow.range", "tensorflow.range", "tensorflow.tile", "s.scatter_nd_update", "tensorflow.IndexedSlices", "tensorflow.where", "s.sparse_read", "tensorflow.expand_dims", "s.gather_nd", "tensorflow.equal", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "", "def", "_complete_unrolls", "(", "self", ",", "env_ids", ")", ":", "\n", "# Environment with unrolls that are now complete and should be returned.", "\n", "    ", "env_indices", "=", "self", ".", "_index", ".", "sparse_read", "(", "env_ids", ")", "\n", "env_ids", "=", "tf", ".", "gather", "(", "\n", "env_ids", ",", "\n", "tf", ".", "where", "(", "tf", ".", "equal", "(", "env_indices", ",", "self", ".", "_full_length", ")", ")", "[", ":", ",", "0", "]", ")", "\n", "env_ids", "=", "tf", ".", "cast", "(", "env_ids", ",", "tf", ".", "int64", ")", "\n", "unrolls", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "s", ":", "s", ".", "sparse_read", "(", "env_ids", ")", ",", "\n", "self", ".", "_state", ")", "\n", "\n", "# Store last transitions as the first in the next unroll.", "\n", "# The following code is the equivalent of:", "\n", "# s[env_ids, :j] = s[env_ids, -j:]", "\n", "j", "=", "self", ".", "_num_overlapping_steps", "+", "1", "\n", "repeated_start_range", "=", "tf", ".", "tile", "(", "tf", ".", "range", "(", "j", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "[", "tf", ".", "shape", "(", "env_ids", ")", "[", "0", "]", "]", ")", "\n", "repeated_end_range", "=", "tf", ".", "tile", "(", "\n", "tf", ".", "range", "(", "self", ".", "_full_length", "-", "j", ",", "self", ".", "_full_length", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "[", "tf", ".", "shape", "(", "env_ids", ")", "[", "0", "]", "]", ")", "\n", "repeated_env_ids", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "env_ids", ",", "-", "1", ")", ",", "[", "1", ",", "j", "]", ")", ",", "[", "-", "1", "]", ")", "\n", "start_indices", "=", "tf", ".", "stack", "(", "[", "repeated_env_ids", ",", "repeated_start_range", "]", ",", "-", "1", ")", "\n", "end_indices", "=", "tf", ".", "stack", "(", "[", "repeated_env_ids", ",", "repeated_end_range", "]", ",", "-", "1", ")", "\n", "\n", "for", "s", "in", "tf", ".", "nest", ".", "flatten", "(", "self", ".", "_state", ")", ":", "\n", "      ", "s", ".", "scatter_nd_update", "(", "start_indices", ",", "s", ".", "gather_nd", "(", "end_indices", ")", ")", "\n", "\n", "", "self", ".", "_index", ".", "scatter_update", "(", "\n", "tf", ".", "IndexedSlices", "(", "1", "+", "self", ".", "_num_overlapping_steps", ",", "env_ids", ")", ")", "\n", "\n", "return", "env_ids", ",", "unrolls", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.PrioritizedReplay.__init__": [[267, 276], ["tensorflow.Module.__init__", "tensorflow.Variable", "tensorflow.nest.map_structure", "tensorflow.Variable", "tensorflow.zeros", "tensorflow.Variable", "tensorflow.zeros"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "size", ",", "specs", ",", "importance_sampling_exponent", ",", "\n", "name", "=", "'PrioritizedReplay'", ")", ":", "\n", "    ", "super", "(", "PrioritizedReplay", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "self", ".", "_priorities", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "size", "]", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "_buffer", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "ts", ":", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "size", "]", "+", "ts", ".", "shape", ",", "dtype", "=", "ts", ".", "dtype", ")", ")", ",", "\n", "specs", ")", "\n", "self", ".", "num_inserted", "=", "tf", ".", "Variable", "(", "0", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "self", ".", "_importance_sampling_exponent", "=", "importance_sampling_exponent", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.PrioritizedReplay.insert": [[277, 311], ["tensorflow.nest.assert_same_structure", "tensorflow.nest.map_structure", "tensorflow.nest.map_structure", "utils.PrioritizedReplay.num_inserted.assign_add", "utils.PrioritizedReplay._priorities.batch_scatter_update", "tensorflow.range", "tensorflow.IndexedSlices", "b.batch_scatter_update", "tensorflow.nest.flatten", "tensorflow.IndexedSlices"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "@", "tf", ".", "Module", ".", "with_name_scope", "\n", "def", "insert", "(", "self", ",", "values", ",", "priorities", ")", ":", "\n", "    ", "\"\"\"FIFO insertion/removal.\n\n    Args:\n      values: The batched values to insert. The tensors must be of the same\n        shape and dtype as the `specs` provided in the constructor, except\n        including a batch dimension.\n      priorities: <float32>[batch_size] tensor with the priorities of the\n        elements we insert.\n    Returns:\n      The indices of the inserted values.\n    \"\"\"", "\n", "tf", ".", "nest", ".", "assert_same_structure", "(", "values", ",", "self", ".", "_buffer", ")", "\n", "values", "=", "tf", ".", "nest", ".", "map_structure", "(", "tf", ".", "convert_to_tensor", ",", "values", ")", "\n", "append_size", "=", "tf", ".", "nest", ".", "flatten", "(", "values", ")", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "start_index", "=", "self", ".", "num_inserted", "\n", "end_index", "=", "start_index", "+", "append_size", "\n", "\n", "# Wrap around insertion.", "\n", "size", "=", "self", ".", "_priorities", ".", "shape", "[", "0", "]", "\n", "insert_indices", "=", "tf", ".", "range", "(", "start_index", ",", "end_index", ")", "%", "size", "\n", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "b", ",", "v", ":", "b", ".", "batch_scatter_update", "(", "\n", "tf", ".", "IndexedSlices", "(", "v", ",", "insert_indices", ")", ")", ",", "\n", "self", ".", "_buffer", ",", "\n", "values", ")", "\n", "self", ".", "num_inserted", ".", "assign_add", "(", "append_size", ")", "\n", "\n", "self", ".", "_priorities", ".", "batch_scatter_update", "(", "\n", "tf", ".", "IndexedSlices", "(", "priorities", ",", "insert_indices", ")", ")", "\n", "\n", "return", "insert_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.PrioritizedReplay.sample": [[312, 357], ["tensorflow.debugging.assert_greater_equal", "tensorflow.minimum", "tensorflow.nest.map_structure", "tensorflow.constant", "tensorflow.cast", "tensorflow.random.uniform", "tensorflow.ones_like", "tensorflow.reduce_sum", "tensorflow.reduce_max", "tensorflow.random.categorical", "b.sparse_read", "tensorflow.gather", "tensorflow.math.log", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log"], ["", "@", "tf", ".", "function", "\n", "@", "tf", ".", "Module", ".", "with_name_scope", "\n", "def", "sample", "(", "self", ",", "num_samples", ",", "priority_exp", ")", ":", "\n", "    ", "r\"\"\"Samples items from the replay buffer, using priorities.\n\n    Args:\n      num_samples: int, number of replay items to sample.\n      priority_exp: Priority exponent. Every item i in the replay buffer will be\n        sampled with probability:\n         priority[i] ** priority_exp /\n             sum(priority[j] ** priority_exp, j \\in [0, num_items))\n        Set this to 0 in order to get uniform sampling.\n\n    Returns:\n      Tuple of:\n        - indices: An int64 tensor of shape [num_samples] with the indices in\n          the replay buffer of the sampled items.\n        - weights: A float32 tensor of shape [num_samples] with the normalized\n          weights of the sampled items.\n        - sampled_values: A nested structure following the spec passed in the\n          contructor, where each tensor has an added front batch dimension equal\n          to 'num_samples'.\n    \"\"\"", "\n", "tf", ".", "debugging", ".", "assert_greater_equal", "(", "\n", "self", ".", "num_inserted", ",", "\n", "tf", ".", "constant", "(", "0", ",", "tf", ".", "int64", ")", ",", "\n", "message", "=", "'Cannot sample if replay buffer is empty'", ")", "\n", "size", "=", "self", ".", "_priorities", ".", "shape", "[", "0", "]", "\n", "limit", "=", "tf", ".", "minimum", "(", "tf", ".", "cast", "(", "size", ",", "tf", ".", "int64", ")", ",", "self", ".", "num_inserted", ")", "\n", "if", "priority_exp", "==", "0", ":", "\n", "      ", "indices", "=", "tf", ".", "random", ".", "uniform", "(", "[", "num_samples", "]", ",", "maxval", "=", "limit", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "weights", "=", "tf", ".", "ones_like", "(", "indices", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "      ", "prob", "=", "self", ".", "_priorities", "[", ":", "limit", "]", "**", "priority_exp", "\n", "prob", "/=", "tf", ".", "reduce_sum", "(", "prob", ")", "\n", "indices", "=", "tf", ".", "random", ".", "categorical", "(", "[", "tf", ".", "math", ".", "log", "(", "prob", ")", "]", ",", "num_samples", ")", "[", "0", "]", "\n", "# Importance weights.", "\n", "weights", "=", "(", "(", "(", "1.", "/", "tf", ".", "cast", "(", "limit", ",", "tf", ".", "float32", ")", ")", "/", "\n", "tf", ".", "gather", "(", "prob", ",", "indices", ")", ")", "**", "\n", "self", ".", "_importance_sampling_exponent", ")", "\n", "weights", "/=", "tf", ".", "reduce_max", "(", "weights", ")", "# Normalize.", "\n", "\n", "", "sampled_values", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "b", ":", "b", ".", "sparse_read", "(", "indices", ")", ",", "self", ".", "_buffer", ")", "\n", "return", "indices", ",", "weights", ",", "sampled_values", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.PrioritizedReplay.update_priorities": [[358, 371], ["utils.PrioritizedReplay._priorities.batch_scatter_update", "tensorflow.IndexedSlices"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "@", "tf", ".", "Module", ".", "with_name_scope", "\n", "def", "update_priorities", "(", "self", ",", "indices", ",", "priorities", ")", ":", "\n", "    ", "\"\"\"Updates the priorities of the items with the given indices.\n\n    Args:\n      indices: <int64>[batch_size] tensor with the indices of the items to\n        update. If duplicate indices are provided, the priority that will be set\n        among possible ones is not specified.\n      priorities: <float32>[batch_size] tensor with the new priorities.\n    \"\"\"", "\n", "\n", "self", ".", "_priorities", ".", "batch_scatter_update", "(", "tf", ".", "IndexedSlices", "(", "priorities", ",", "indices", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.__init__": [[384, 394], ["utils.PrioritizedReplay.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "size", ",", "specs", ",", "importance_sampling_exponent", ",", "\n", "compute_reward_fn", ",", "\n", "unroll_length", ",", "\n", "substitution_probability", ",", "\n", "name", "=", "'HindsightExperienceReplay'", ")", ":", "\n", "    ", "super", "(", "HindsightExperienceReplay", ",", "self", ")", ".", "__init__", "(", "\n", "size", ",", "specs", ",", "importance_sampling_exponent", ",", "name", ")", "\n", "self", ".", "_compute_reward_fn", "=", "compute_reward_fn", "\n", "self", ".", "_unroll_length", "=", "unroll_length", "\n", "self", ".", "_substitution_probability", "=", "substitution_probability", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample": [[395, 459], ["utils.PrioritizedReplay.sample", "utils.HindsightExperienceReplay.sample.compute_goal_reward"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.HindsightExperienceReplay.sample"], ["", "@", "tf", ".", "Module", ".", "with_name_scope", "\n", "def", "sample", "(", "self", ",", "num_samples", ",", "priority_exp", ")", ":", "\n", "    ", "indices", ",", "weights", ",", "sampled_values", "=", "super", "(", "\n", "HindsightExperienceReplay", ",", "self", ")", ".", "sample", "(", "num_samples", ",", "priority_exp", ")", "\n", "\n", "observation", "=", "sampled_values", ".", "env_outputs", ".", "observation", "\n", "batch_size", ",", "time_horizon", "=", "observation", "[", "'achieved_goal'", "]", ".", "shape", "[", ":", "2", "]", "\n", "\n", "def", "compute_goal_reward", "(", ")", ":", "\n", "# reward[batch][time] is the reward on transition from timestep time-1", "\n", "# to time. This function outputs incorrect rewards for the last transition", "\n", "# in each episode but we filter such cases later.", "\n", "      ", "goal_reward", "=", "self", ".", "_compute_reward_fn", "(", "\n", "achieved_goal", "=", "observation", "[", "'achieved_goal'", "]", "[", ":", ",", "1", ":", "]", ",", "\n", "desired_goal", "=", "observation", "[", "'desired_goal'", "]", "[", ":", ",", ":", "-", "1", "]", ")", "\n", "return", "tf", ".", "concat", "(", "values", "=", "[", "goal_reward", "[", ":", ",", ":", "1", "]", "*", "np", ".", "nan", ",", "goal_reward", "]", ",", "\n", "axis", "=", "1", ")", "\n", "\n", "# Substitute goals.", "\n", "", "old_goal_reward", "=", "compute_goal_reward", "(", ")", "\n", "assert", "old_goal_reward", ".", "shape", "==", "observation", "[", "'achieved_goal'", "]", ".", "shape", "[", ":", "-", "1", "]", "\n", "goal_ind", "=", "tf", ".", "concat", "(", "\n", "values", "=", "[", "tf", ".", "random", ".", "uniform", "(", "(", "batch_size", ",", "1", ")", ",", "min", "(", "t", "+", "1", ",", "time_horizon", "-", "1", ")", ",", "\n", "time_horizon", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "for", "t", "in", "range", "(", "time_horizon", ")", "]", ",", "axis", "=", "1", ")", "\n", "substituted_goal", "=", "tf", ".", "gather", "(", "observation", "[", "'achieved_goal'", "]", ",", "\n", "goal_ind", ",", "axis", "=", "1", ",", "batch_dims", "=", "1", ")", "\n", "mask", "=", "tf", ".", "cast", "(", "tfp", ".", "distributions", ".", "Bernoulli", "(", "\n", "probs", "=", "self", ".", "_substitution_probability", "*", "\n", "tf", ".", "ones", "(", "goal_ind", ".", "shape", ")", ")", ".", "sample", "(", ")", ",", "observation", "[", "'desired_goal'", "]", ".", "dtype", ")", "\n", "# We don't substitute goals for the last states in each episodes because we", "\n", "# don't store the next states for them.", "\n", "mask", "*=", "tf", ".", "cast", "(", "~", "sampled_values", ".", "env_outputs", ".", "done", ",", "\n", "observation", "[", "'desired_goal'", "]", ".", "dtype", ")", "\n", "mask", "=", "mask", "[", "...", ",", "tf", ".", "newaxis", "]", "\n", "observation", "[", "'desired_goal'", "]", "=", "(", "\n", "mask", "*", "substituted_goal", "+", "(", "1", "-", "mask", ")", "*", "observation", "[", "'desired_goal'", "]", ")", "\n", "\n", "# Substitude reward", "\n", "new_goal_reward", "=", "compute_goal_reward", "(", ")", "\n", "assert", "new_goal_reward", ".", "shape", "==", "observation", "[", "'achieved_goal'", "]", ".", "shape", "[", ":", "-", "1", "]", "\n", "sampled_values", "=", "sampled_values", ".", "_replace", "(", "\n", "env_outputs", "=", "sampled_values", ".", "env_outputs", ".", "_replace", "(", "\n", "reward", "=", "sampled_values", ".", "env_outputs", ".", "reward", "+", "\n", "(", "new_goal_reward", "-", "old_goal_reward", ")", "*", "tf", ".", "cast", "(", "\n", "~", "sampled_values", ".", "env_outputs", ".", "done", ",", "tf", ".", "float32", ")", "\n", ")", ")", "\n", "\n", "# Subsample unrolls of length unroll_length + 1.", "\n", "assert", "time_horizon", ">=", "self", ".", "_unroll_length", "+", "1", "\n", "\n", "unroll_begin_ind", "=", "tf", ".", "random", ".", "uniform", "(", "\n", "(", "batch_size", ",", ")", ",", "0", ",", "time_horizon", "-", "self", ".", "_unroll_length", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "unroll_inds", "=", "unroll_begin_ind", "[", ":", ",", "tf", ".", "newaxis", "]", "+", "tf", ".", "math", ".", "cumsum", "(", "\n", "tf", ".", "ones", "(", "(", "batch_size", ",", "self", ".", "_unroll_length", "+", "1", ")", ",", "tf", ".", "int32", ")", ",", "\n", "axis", "=", "1", ",", "exclusive", "=", "True", ")", "\n", "subsampled_values", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "tf", ".", "gather", "(", "t", ",", "unroll_inds", ",", "axis", "=", "1", ",", "batch_dims", "=", "1", ")", ",", "\n", "sampled_values", ")", "\n", "if", "hasattr", "(", "sampled_values", ",", "'agent_state'", ")", ":", "# do not subsample the state", "\n", "      ", "subsampled_values", "=", "subsampled_values", ".", "_replace", "(", "\n", "agent_state", "=", "sampled_values", ".", "agent_state", ")", "\n", "\n", "", "return", "indices", ",", "weights", ",", "subsampled_values", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.__init__": [[464, 479], ["tensorflow.Module.__init__", "tensorflow.nest.map_structure", "tensorflow.zeros", "tensorflow.Variable"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "num_envs", ",", "specs", ",", "name", "=", "'Aggregator'", ")", ":", "\n", "    ", "\"\"\"Inits an Aggregator.\n\n    Args:\n      num_envs: int, number of environments.\n      specs: Structure (as defined by tf.nest) of tf.TensorSpecs that will be\n        stored for each environment.\n      name: Name of the scope for the operations.\n    \"\"\"", "\n", "super", "(", "Aggregator", ",", "self", ")", ".", "__init__", "(", "name", "=", "name", ")", "\n", "def", "create_variable", "(", "spec", ")", ":", "\n", "      ", "z", "=", "tf", ".", "zeros", "(", "[", "num_envs", "]", "+", "spec", ".", "shape", ".", "dims", ",", "dtype", "=", "spec", ".", "dtype", ")", "\n", "return", "tf", ".", "Variable", "(", "z", ",", "trainable", "=", "False", ",", "name", "=", "spec", ".", "name", ")", "\n", "\n", "", "self", ".", "_state", "=", "tf", ".", "nest", ".", "map_structure", "(", "create_variable", ",", "specs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.reset": [[480, 486], ["tensorflow.name_scope", "tensorflow.nest.flatten", "s.scatter_update", "tensorflow.IndexedSlices"], "methods", ["None"], ["", "@", "tf", ".", "Module", ".", "with_name_scope", "\n", "def", "reset", "(", "self", ",", "env_ids", ")", ":", "\n", "    ", "\"\"\"Fills the tensors for the given environments with zeros.\"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "'Aggregator_reset'", ")", ":", "\n", "      ", "for", "s", "in", "tf", ".", "nest", ".", "flatten", "(", "self", ".", "_state", ")", ":", "\n", "        ", "s", ".", "scatter_update", "(", "tf", ".", "IndexedSlices", "(", "0", ",", "env_ids", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.add": [[487, 501], ["tensorflow.nest.assert_same_structure", "zip", "tensorflow.nest.flatten", "tensorflow.nest.flatten", "s.scatter_add", "tensorflow.IndexedSlices"], "methods", ["None"], ["", "", "", "@", "tf", ".", "Module", ".", "with_name_scope", "\n", "def", "add", "(", "self", ",", "env_ids", ",", "values", ")", ":", "\n", "    ", "\"\"\"In-place adds values to the state associated to the given environments.\n\n    Args:\n      env_ids: 1D tensor with the environment IDs we want to add values to.\n      values: A structure of tensors following the input spec, with an added\n        first dimension that must either have the same size as 'env_ids', or\n        should not exist (in which case, the value is broadcasted to all\n        environment ids).\n    \"\"\"", "\n", "tf", ".", "nest", ".", "assert_same_structure", "(", "values", ",", "self", ".", "_state", ")", "\n", "for", "s", ",", "v", "in", "zip", "(", "tf", ".", "nest", ".", "flatten", "(", "self", ".", "_state", ")", ",", "tf", ".", "nest", ".", "flatten", "(", "values", ")", ")", ":", "\n", "      ", "s", ".", "scatter_add", "(", "tf", ".", "IndexedSlices", "(", "v", ",", "env_ids", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.read": [[502, 516], ["tensorflow.nest.map_structure", "s.sparse_read"], "methods", ["None"], ["", "", "@", "tf", ".", "Module", ".", "with_name_scope", "\n", "def", "read", "(", "self", ",", "env_ids", ")", ":", "\n", "    ", "\"\"\"Reads the values corresponding to a list of environments.\n\n    Args:\n      env_ids: 1D tensor with the list of environment IDs we want to read.\n\n    Returns:\n      A structure of tensors with the same shapes as the input specs. A\n      dimension is added in front of each tensor, with size equal to the number\n      of env_ids provided.\n    \"\"\"", "\n", "return", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "s", ":", "s", ".", "sparse_read", "(", "env_ids", ")", ",", "\n", "self", ".", "_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.replace": [[517, 544], ["tensorflow.debugging.assert_rank", "tensorflow.debugging.Assert", "tensorflow.nest.assert_same_structure", "zip", "tensorflow.reduce_all", "tensorflow.nest.flatten", "tensorflow.nest.flatten", "s.scatter_update", "tensorflow.equal", "tensorflow.IndexedSlices", "tensorflow.shape", "tensorflow.shape", "tensorflow.unique"], "methods", ["None"], ["", "@", "tf", ".", "Module", ".", "with_name_scope", "\n", "def", "replace", "(", "self", ",", "env_ids", ",", "values", ",", "debug_op_name", "=", "''", ",", "debug_tensors", "=", "None", ")", ":", "\n", "    ", "\"\"\"Replaces the state associated to the given environments.\n\n    Args:\n      env_ids: 1D tensor with the list of environment IDs.\n      values: A structure of tensors following the input spec, with an added\n        first dimension that must either have the same size as 'env_ids', or\n        should not exist (in which case, the value is broadcasted to all\n        environment ids).\n      debug_op_name: Debug name for the operation.\n      debug_tensors: List of tensors to print when the assert fails.\n    \"\"\"", "\n", "tf", ".", "debugging", ".", "assert_rank", "(", "\n", "env_ids", ",", "1", ",", "\n", "message", "=", "f'Invalid rank for aggregator {self.name}'", ")", "\n", "tf", ".", "debugging", ".", "Assert", "(", "\n", "tf", ".", "reduce_all", "(", "tf", ".", "equal", "(", "\n", "tf", ".", "shape", "(", "env_ids", ")", ",", "tf", ".", "shape", "(", "tf", ".", "unique", "(", "env_ids", ")", "[", "0", "]", ")", ")", ")", ",", "\n", "data", "=", "[", "env_ids", ",", "\n", "(", "f'Duplicate environment ids in Aggregator: {self.name} with '", "\n", "f'op name \"{debug_op_name}\"'", ")", "]", "+", "(", "debug_tensors", "or", "[", "]", ")", ",", "\n", "summarize", "=", "4096", ",", "\n", "name", "=", "f'assert_no_dups_{self.name}'", ")", "\n", "tf", ".", "nest", ".", "assert_same_structure", "(", "values", ",", "self", ".", "_state", ")", "\n", "for", "s", ",", "v", "in", "zip", "(", "tf", ".", "nest", ".", "flatten", "(", "self", ".", "_state", ")", ",", "tf", ".", "nest", ".", "flatten", "(", "values", ")", ")", ":", "\n", "      ", "s", ".", "scatter_update", "(", "tf", ".", "IndexedSlices", "(", "v", ",", "env_ids", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.__init__": [[549, 585], ["set", "tensorflow.Variable", "tensorflow.Variable", "utils.ProgressLogger.reset", "tensorflow.TensorShape"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset"], ["def", "__init__", "(", "self", ",", "\n", "summary_writer", "=", "None", ",", "\n", "initial_period", "=", "0.1", ",", "\n", "period_factor", "=", "1.01", ",", "\n", "max_period", "=", "10.0", ",", "\n", "starting_step", "=", "0", ")", ":", "\n", "    ", "\"\"\"Constructs ProgressLogger.\n\n    Args:\n      summary_writer: Tensorflow summary writer to use.\n      initial_period: Initial logging period in seconds\n        (how often logging happens).\n      period_factor: Factor by which logging period is\n        multiplied after each iteration (exponential back-off).\n      max_period: Maximal logging period in seconds\n        (the end of exponential back-off).\n      starting_step: Step from which to start the summary writer.\n    \"\"\"", "\n", "# summary_writer, last_log_{time, step} are set in reset() function.", "\n", "self", ".", "summary_writer", "=", "None", "\n", "self", ".", "last_log_time", "=", "None", "\n", "self", ".", "last_log_step", "=", "0", "\n", "self", ".", "period", "=", "initial_period", "\n", "self", ".", "period_factor", "=", "period_factor", "\n", "self", ".", "max_period", "=", "max_period", "\n", "# Array of strings with names of values to be logged.", "\n", "self", ".", "log_keys", "=", "[", "]", "\n", "self", ".", "log_keys_set", "=", "set", "(", ")", "\n", "self", ".", "step_cnt", "=", "tf", ".", "Variable", "(", "-", "1", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "self", ".", "ready_values", "=", "tf", ".", "Variable", "(", "[", "-", "1.0", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "shape", "=", "tf", ".", "TensorShape", "(", "None", ")", ")", "\n", "self", ".", "logger_thread", "=", "None", "\n", "self", ".", "logging_callback", "=", "None", "\n", "self", ".", "terminator", "=", "None", "\n", "self", ".", "reset", "(", "summary_writer", ",", "starting_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.reset": [[586, 598], ["utils.ProgressLogger.step_cnt.assign", "utils.ProgressLogger.ready_values.assign", "timeit.default_timer"], "methods", ["None"], ["", "def", "reset", "(", "self", ",", "summary_writer", "=", "None", ",", "starting_step", "=", "0", ")", ":", "\n", "    ", "\"\"\"Resets the progress logger.\n\n    Args:\n      summary_writer: Tensorflow summary writer to use.\n      starting_step: Step from which to start the summary writer.\n    \"\"\"", "\n", "self", ".", "summary_writer", "=", "summary_writer", "\n", "self", ".", "step_cnt", ".", "assign", "(", "starting_step", ")", "\n", "self", ".", "ready_values", ".", "assign", "(", "[", "-", "1.0", "]", ")", "\n", "self", ".", "last_log_time", "=", "timeit", ".", "default_timer", "(", ")", "\n", "self", ".", "last_log_step", "=", "starting_step", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start": [[599, 605], ["threading.Event", "threading.Thread", "utils.ProgressLogger.logger_thread.start"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.start"], ["", "def", "start", "(", "self", ",", "logging_callback", "=", "None", ")", ":", "\n", "    ", "assert", "self", ".", "logger_thread", "is", "None", "\n", "self", ".", "logging_callback", "=", "logging_callback", "\n", "self", ".", "terminator", "=", "threading", ".", "Event", "(", ")", "\n", "self", ".", "logger_thread", "=", "threading", ".", "Thread", "(", "target", "=", "self", ".", "_logging_loop", ")", "\n", "self", ".", "logger_thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.shutdown": [[606, 611], ["utils.ProgressLogger.terminator.set", "utils.ProgressLogger.logger_thread.join"], "methods", ["None"], ["", "def", "shutdown", "(", "self", ")", ":", "\n", "    ", "assert", "self", ".", "logger_thread", "\n", "self", ".", "terminator", ".", "set", "(", ")", "\n", "self", ".", "logger_thread", ".", "join", "(", ")", "\n", "self", ".", "logger_thread", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log_session": [[612, 614], ["None"], "methods", ["None"], ["", "def", "log_session", "(", "self", ")", ":", "\n", "    ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log": [[615, 622], ["session.append", "utils.ProgressLogger.log_keys.append", "utils.ProgressLogger.log_keys_set.add"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.Aggregator.add"], ["", "def", "log", "(", "self", ",", "session", ",", "name", ",", "value", ")", ":", "\n", "# this is a python op so it happens only when this tf.function is compiled", "\n", "    ", "if", "name", "not", "in", "self", ".", "log_keys_set", ":", "\n", "      ", "self", ".", "log_keys", ".", "append", "(", "name", ")", "\n", "self", ".", "log_keys_set", ".", "add", "(", "name", ")", "\n", "# this is a TF op.", "\n", "", "session", ".", "append", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log_session_from_dict": [[623, 628], ["utils.ProgressLogger.log_session", "utils.ProgressLogger.log"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log_session", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.log"], ["", "def", "log_session_from_dict", "(", "self", ",", "dic", ")", ":", "\n", "    ", "session", "=", "self", ".", "log_session", "(", ")", "\n", "for", "key", "in", "dic", ":", "\n", "      ", "self", ".", "log", "(", "session", ",", "key", ",", "dic", "[", "key", "]", ")", "\n", "", "return", "session", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger.step_end": [[629, 638], ["utils.ProgressLogger.ready_values.assign", "utils.ProgressLogger.step_cnt.assign_add", "logs.append", "tensorflow.reduce_mean", "tensorflow.cast", "strategy.experimental_local_results"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append"], ["", "def", "step_end", "(", "self", ",", "session", ",", "strategy", "=", "None", ",", "step_increment", "=", "1", ")", ":", "\n", "    ", "logs", "=", "[", "]", "\n", "for", "value", "in", "session", ":", "\n", "      ", "if", "strategy", ":", "\n", "        ", "value", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "\n", "strategy", ".", "experimental_local_results", "(", "value", ")", "[", "0", "]", ",", "tf", ".", "float32", ")", ")", "\n", "", "logs", ".", "append", "(", "value", ")", "\n", "", "self", ".", "ready_values", ".", "assign", "(", "logs", ")", "\n", "self", ".", "step_cnt", ".", "assign_add", "(", "step_increment", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger._log": [[639, 663], ["timeit.default_timer", "utils.ProgressLogger.step_cnt.read_value", "utils.ProgressLogger.ready_values.read_value().numpy", "tensorflow.summary.experimental.set_step", "zip", "tensorflow.cast", "tensorflow.summary.scalar", "len", "len", "utils.ProgressLogger.summary_writer.set_as_default", "utils.ProgressLogger.numpy", "utils.ProgressLogger.logging_callback", "tensorflow.summary.scalar", "utils.ProgressLogger.ready_values.read_value"], "methods", ["None"], ["", "def", "_log", "(", "self", ")", ":", "\n", "    ", "\"\"\"Perform single round of logging.\"\"\"", "\n", "logging_time", "=", "timeit", ".", "default_timer", "(", ")", "\n", "step_cnt", "=", "self", ".", "step_cnt", ".", "read_value", "(", ")", "\n", "if", "step_cnt", "==", "self", ".", "last_log_step", ":", "\n", "      ", "return", "\n", "", "values", "=", "self", ".", "ready_values", ".", "read_value", "(", ")", ".", "numpy", "(", ")", "\n", "if", "values", "[", "0", "]", "==", "-", "1", ":", "\n", "      ", "return", "\n", "", "assert", "len", "(", "values", ")", "==", "len", "(", "\n", "self", ".", "log_keys", "\n", ")", ",", "'Mismatch between number of keys and values to log: %r vs %r'", "%", "(", "\n", "values", ",", "self", ".", "log_keys", ")", "\n", "if", "self", ".", "summary_writer", ":", "\n", "      ", "self", ".", "summary_writer", ".", "set_as_default", "(", ")", "\n", "", "tf", ".", "summary", ".", "experimental", ".", "set_step", "(", "step_cnt", ".", "numpy", "(", ")", ")", "\n", "if", "self", ".", "logging_callback", ":", "\n", "      ", "self", ".", "logging_callback", "(", ")", "\n", "", "for", "key", ",", "value", "in", "zip", "(", "self", ".", "log_keys", ",", "values", ")", ":", "\n", "      ", "tf", ".", "summary", ".", "scalar", "(", "key", ",", "value", ")", "\n", "", "dt", "=", "logging_time", "-", "self", ".", "last_log_time", "\n", "df", "=", "tf", ".", "cast", "(", "step_cnt", "-", "self", ".", "last_log_step", ",", "tf", ".", "float32", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'speed/steps_per_sec'", ",", "df", "/", "dt", ")", "\n", "self", ".", "last_log_time", ",", "self", ".", "last_log_step", "=", "logging_time", ",", "step_cnt", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger._logging_loop": [[664, 678], ["timeit.default_timer", "utils.ProgressLogger.terminator.isSet", "timeit.default_timer", "min", "utils.ProgressLogger.terminator.wait", "utils.ProgressLogger._log", "absl.logging.fatal", "max"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.ProgressLogger._log"], ["", "def", "_logging_loop", "(", "self", ")", ":", "\n", "    ", "\"\"\"Loop being run in a separate thread.\"\"\"", "\n", "last_log_try", "=", "timeit", ".", "default_timer", "(", ")", "\n", "while", "not", "self", ".", "terminator", ".", "isSet", "(", ")", ":", "\n", "      ", "try", ":", "\n", "        ", "self", ".", "_log", "(", ")", "\n", "", "except", "Exception", ":", "\n", "        ", "logging", ".", "fatal", "(", "'Logging failed.'", ",", "exc_info", "=", "True", ")", "\n", "", "now", "=", "timeit", ".", "default_timer", "(", ")", "\n", "elapsed", "=", "now", "-", "last_log_try", "\n", "last_log_try", "=", "now", "\n", "self", ".", "period", "=", "min", "(", "self", ".", "period_factor", "*", "self", ".", "period", ",", "\n", "self", ".", "max_period", ")", "\n", "self", ".", "terminator", ".", "wait", "(", "timeout", "=", "max", "(", "0", ",", "self", ".", "period", "-", "elapsed", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.__init__": [[683, 693], ["tensorflow.nest.flatten", "super().__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["def", "__init__", "(", "self", ",", "\n", "capacity", ",", "\n", "specs", ",", "\n", "shared_name", "=", "None", ",", "\n", "name", "=", "'structured_fifo_queue'", ")", ":", "\n", "    ", "self", ".", "_specs", "=", "specs", "\n", "self", ".", "_flattened_specs", "=", "tf", ".", "nest", ".", "flatten", "(", "specs", ")", "\n", "dtypes", "=", "[", "ts", ".", "dtype", "for", "ts", "in", "self", ".", "_flattened_specs", "]", "\n", "shapes", "=", "[", "ts", ".", "shape", "for", "ts", "in", "self", ".", "_flattened_specs", "]", "\n", "super", "(", "StructuredFIFOQueue", ",", "self", ")", ".", "__init__", "(", "capacity", ",", "dtypes", ",", "shapes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.dequeue": [[694, 697], ["super().dequeue", "tensorflow.nest.pack_sequence_as"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.dequeue"], ["", "def", "dequeue", "(", "self", ",", "name", "=", "None", ")", ":", "\n", "    ", "result", "=", "super", "(", "StructuredFIFOQueue", ",", "self", ")", ".", "dequeue", "(", "name", "=", "name", ")", "\n", "return", "tf", ".", "nest", ".", "pack_sequence_as", "(", "self", ".", "_specs", ",", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.dequeue_many": [[698, 702], ["super().dequeue_many", "tensorflow.nest.pack_sequence_as"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.dequeue_many"], ["", "def", "dequeue_many", "(", "self", ",", "batch_size", ",", "name", "=", "None", ")", ":", "\n", "    ", "result", "=", "super", "(", "StructuredFIFOQueue", ",", "self", ")", ".", "dequeue_many", "(", "\n", "batch_size", ",", "name", "=", "name", ")", "\n", "return", "tf", ".", "nest", ".", "pack_sequence_as", "(", "self", ".", "_specs", ",", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.enqueue": [[703, 707], ["tensorflow.nest.assert_same_structure", "super().enqueue", "tensorflow.nest.flatten"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.enqueue"], ["", "def", "enqueue", "(", "self", ",", "vals", ",", "name", "=", "None", ")", ":", "\n", "    ", "tf", ".", "nest", ".", "assert_same_structure", "(", "vals", ",", "self", ".", "_specs", ")", "\n", "return", "super", "(", "StructuredFIFOQueue", ",", "self", ")", ".", "enqueue", "(", "\n", "tf", ".", "nest", ".", "flatten", "(", "vals", ")", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.enqueue_many": [[708, 712], ["tensorflow.nest.assert_same_structure", "super().enqueue_many", "tensorflow.nest.flatten"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.StructuredFIFOQueue.enqueue_many"], ["", "def", "enqueue_many", "(", "self", ",", "vals", ",", "name", "=", "None", ")", ":", "\n", "    ", "tf", ".", "nest", ".", "assert_same_structure", "(", "vals", ",", "self", ".", "_specs", ")", "\n", "return", "super", "(", "StructuredFIFOQueue", ",", "self", ")", ".", "enqueue_many", "(", "\n", "tf", ".", "nest", ".", "flatten", "(", "vals", ")", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedUInt8Spec.__init__": [[767, 770], ["tensorflow.TensorSpec"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "encoded_shape", ",", "original_shape", ")", ":", "\n", "    ", "self", ".", "_value_specs", "=", "(", "tf", ".", "TensorSpec", "(", "encoded_shape", ",", "tf", ".", "uint32", ")", ",", ")", "\n", "self", ".", "original_shape", "=", "original_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedUInt8Spec._component_specs": [[771, 774], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_component_specs", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_value_specs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedUInt8Spec._to_components": [[775, 777], ["None"], "methods", ["None"], ["", "def", "_to_components", "(", "self", ",", "value", ")", ":", "\n", "    ", "return", "(", "value", ".", "encoded", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedUInt8Spec._from_components": [[778, 780], ["utils.TPUEncodedUInt8"], "methods", ["None"], ["", "def", "_from_components", "(", "self", ",", "components", ")", ":", "\n", "    ", "return", "TPUEncodedUInt8", "(", "components", "[", "0", "]", ",", "self", ".", "original_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedUInt8Spec._serialize": [[781, 783], ["None"], "methods", ["None"], ["", "def", "_serialize", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_value_specs", "[", "0", "]", ".", "shape", ",", "self", ".", "original_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedUInt8Spec._to_legacy_output_types": [[784, 786], ["None"], "methods", ["None"], ["", "def", "_to_legacy_output_types", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_value_specs", "[", "0", "]", ".", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedUInt8Spec._to_legacy_output_shapes": [[787, 789], ["None"], "methods", ["None"], ["", "def", "_to_legacy_output_shapes", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_value_specs", "[", "0", "]", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedUInt8Spec.value_type": [[790, 793], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "value_type", "(", "self", ")", ":", "\n", "    ", "return", "TPUEncodedUInt8", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedUInt8.__init__": [[797, 801], ["utils.TPUEncodedUInt8Spec", "tensorflow.TensorShape"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "encoded", ",", "shape", ")", ":", "\n", "    ", "self", ".", "encoded", "=", "encoded", "\n", "self", ".", "original_shape", "=", "shape", "\n", "self", ".", "_spec", "=", "TPUEncodedUInt8Spec", "(", "encoded", ".", "shape", ",", "tf", ".", "TensorShape", "(", "shape", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedUInt8._type_spec": [[802, 805], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_type_spec", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedF32Spec.__init__": [[814, 817], ["tensorflow.TensorSpec"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "encoded_shape", ",", "original_shape", ")", ":", "\n", "    ", "self", ".", "_value_specs", "=", "(", "tf", ".", "TensorSpec", "(", "encoded_shape", ",", "tf", ".", "float32", ")", ",", ")", "\n", "self", ".", "original_shape", "=", "original_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedF32Spec._component_specs": [[818, 821], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_component_specs", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_value_specs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedF32Spec._to_components": [[822, 824], ["None"], "methods", ["None"], ["", "def", "_to_components", "(", "self", ",", "value", ")", ":", "\n", "    ", "return", "(", "value", ".", "encoded", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedF32Spec._from_components": [[825, 827], ["utils.TPUEncodedF32"], "methods", ["None"], ["", "def", "_from_components", "(", "self", ",", "components", ")", ":", "\n", "    ", "return", "TPUEncodedF32", "(", "components", "[", "0", "]", ",", "self", ".", "original_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedF32Spec._serialize": [[828, 830], ["None"], "methods", ["None"], ["", "def", "_serialize", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_value_specs", "[", "0", "]", ".", "shape", ",", "self", ".", "original_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedF32Spec._to_legacy_output_types": [[831, 833], ["None"], "methods", ["None"], ["", "def", "_to_legacy_output_types", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_value_specs", "[", "0", "]", ".", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedF32Spec._to_legacy_output_shapes": [[834, 836], ["None"], "methods", ["None"], ["", "def", "_to_legacy_output_shapes", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_value_specs", "[", "0", "]", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedF32Spec.value_type": [[837, 840], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "value_type", "(", "self", ")", ":", "\n", "    ", "return", "TPUEncodedF32", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedF32.__init__": [[844, 848], ["utils.TPUEncodedF32Spec", "tensorflow.TensorShape"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "encoded", ",", "shape", ")", ":", "\n", "    ", "self", ".", "encoded", "=", "encoded", "\n", "self", ".", "original_shape", "=", "shape", "\n", "self", ".", "_spec", "=", "TPUEncodedF32Spec", "(", "encoded", ".", "shape", ",", "tf", ".", "TensorShape", "(", "shape", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.TPUEncodedF32._type_spec": [[849, 852], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_type_spec", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.nullcontext.__init__": [[961, 964], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwds", ")", ":", "\n", "    ", "del", "args", "# unused", "\n", "del", "kwds", "# unused", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.nullcontext.__enter__": [[965, 967], ["None"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "    ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.nullcontext.__exit__": [[968, 970], ["None"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_value", ",", "traceback", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.init_learner_multi_host": [[53, 108], ["tensorflow.config.experimental.list_logical_devices", "tensorflow.distribute.cluster_resolver.TPUClusterResolver", "tensorflow.tpu.experimental.initialize_tpu_system", "tensorflow.distribute.experimental.TPUStrategy", "tensorflow.tpu.experimental.DeviceAssignment", "tensorflow.distribute.experimental.TPUStrategy", "MultiHostSettings", "tensorflow.device().__enter__", "tensorflow.config.experimental.list_logical_devices", "tensorflow.distribute.OneDeviceStrategy", "MultiHostSettings", "tf.tpu.experimental.initialize_tpu_system.cpu_device_name_at_coordinates", "training_coordinates.extend", "hosts.append", "tensorflow.device", "tensorflow.nest.pack_sequence_as", "tf.tpu.experimental.initialize_tpu_system.tpu_device_name_at_coordinates"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.nullcontext.__enter__", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append"], ["def", "init_learner_multi_host", "(", "num_training_tpus", ":", "int", ")", ":", "\n", "  ", "\"\"\"Performs common learner initialization including multi-host setting.\n\n  In multi-host setting, this function will enter a loop for secondary learners\n  until the primary learner signals end of training.\n\n  Args:\n    num_training_tpus: Number of training TPUs.\n\n  Returns:\n    A MultiHostSettings object.\n  \"\"\"", "\n", "tpu", "=", "''", "\n", "job_name", "=", "None", "\n", "\n", "\n", "if", "tf", ".", "config", ".", "experimental", ".", "list_logical_devices", "(", "'TPU'", ")", ":", "\n", "    ", "resolver", "=", "tf", ".", "distribute", ".", "cluster_resolver", ".", "TPUClusterResolver", "(", "\n", "tpu", "=", "tpu", ",", "job_name", "=", "job_name", ")", "\n", "topology", "=", "tf", ".", "tpu", ".", "experimental", ".", "initialize_tpu_system", "(", "resolver", ")", "\n", "strategy", "=", "tf", ".", "distribute", ".", "experimental", ".", "TPUStrategy", "(", "resolver", ")", "\n", "\n", "assert", "num_training_tpus", "%", "topology", ".", "num_tasks", "==", "0", "\n", "num_training_tpus_per_task", "=", "num_training_tpus", "//", "topology", ".", "num_tasks", "\n", "\n", "hosts", "=", "[", "]", "\n", "training_coordinates", "=", "[", "]", "\n", "for", "per_host_coordinates", "in", "topology", ".", "device_coordinates", ":", "\n", "      ", "host", "=", "topology", ".", "cpu_device_name_at_coordinates", "(", "\n", "per_host_coordinates", "[", "0", "]", ",", "job", "=", "job_name", ")", "\n", "task_training_coordinates", "=", "(", "\n", "per_host_coordinates", "[", ":", "num_training_tpus_per_task", "]", ")", "\n", "training_coordinates", ".", "extend", "(", "[", "[", "c", "]", "for", "c", "in", "task_training_coordinates", "]", ")", "\n", "\n", "inference_coordinates", "=", "per_host_coordinates", "[", "num_training_tpus_per_task", ":", "]", "\n", "hosts", ".", "append", "(", "(", "host", ",", "[", "\n", "topology", ".", "tpu_device_name_at_coordinates", "(", "c", ",", "job", "=", "job_name", ")", "\n", "for", "c", "in", "inference_coordinates", "\n", "]", ")", ")", "\n", "\n", "", "training_da", "=", "tf", ".", "tpu", ".", "experimental", ".", "DeviceAssignment", "(", "topology", ",", "\n", "training_coordinates", ")", "\n", "training_strategy", "=", "tf", ".", "distribute", ".", "experimental", ".", "TPUStrategy", "(", "\n", "resolver", ",", "device_assignment", "=", "training_da", ")", "\n", "return", "MultiHostSettings", "(", "strategy", ",", "hosts", ",", "training_strategy", ",", "tpu_encode", ",", "\n", "tpu_decode", ")", "\n", "", "else", ":", "\n", "    ", "tf", ".", "device", "(", "'/cpu'", ")", ".", "__enter__", "(", ")", "\n", "any_gpu", "=", "tf", ".", "config", ".", "experimental", ".", "list_logical_devices", "(", "'GPU'", ")", "\n", "device_name", "=", "'/device:GPU:0'", "if", "any_gpu", "else", "'/device:CPU:0'", "\n", "strategy", "=", "tf", ".", "distribute", ".", "OneDeviceStrategy", "(", "device", "=", "device_name", ")", "\n", "enc", "=", "lambda", "x", ":", "x", "\n", "dec", "=", "lambda", "x", ",", "s", "=", "None", ":", "x", "if", "s", "is", "None", "else", "tf", ".", "nest", ".", "pack_sequence_as", "(", "s", ",", "x", ")", "\n", "return", "MultiHostSettings", "(", "\n", "strategy", ",", "[", "(", "'/cpu'", ",", "[", "device_name", "]", ")", "]", ",", "strategy", ",", "enc", ",", "dec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.init_learner": [[110, 117], ["utils.init_learner_multi_host", "Settings", "len", "ValueError", "len"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.init_learner_multi_host"], ["", "", "def", "init_learner", "(", "num_training_tpus", ")", ":", "\n", "  ", "\"\"\"Performs common learner initialization.\"\"\"", "\n", "settings", "=", "init_learner_multi_host", "(", "num_training_tpus", ")", "\n", "if", "len", "(", "settings", ".", "hosts", ")", "!=", "1", ":", "\n", "    ", "raise", "ValueError", "(", "f'Invalid number of hosts: {len(settings.hosts)}'", ")", "\n", "", "return", "Settings", "(", "settings", ".", "strategy", ",", "settings", ".", "hosts", "[", "0", "]", "[", "1", "]", ",", "\n", "settings", ".", "training_strategy", ",", "settings", ".", "encode", ",", "settings", ".", "decode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.batch_apply": [[714, 733], ["tensorflow.nest.map_structure", "fn", "tensorflow.nest.map_structure", "tensorflow.reshape", "int", "tensorflow.reshape", "t.shape[].as_list", "t.shape[].as_list", "tensorflow.nest.flatten"], "function", ["None"], ["", "", "def", "batch_apply", "(", "fn", ",", "inputs", ")", ":", "\n", "  ", "\"\"\"Folds time into the batch dimension, runs fn() and unfolds the result.\n\n  Args:\n    fn: Function that takes as input the n tensors of the tf.nest structure,\n      with shape [time*batch, <remaining shape>], and returns a tf.nest\n      structure of batched tensors.\n    inputs: tf.nest structure of n [time, batch, <remaining shape>] tensors.\n\n  Returns:\n    tf.nest structure of [time, batch, <fn output shape>]. Structure is\n    determined by the output of fn.\n  \"\"\"", "\n", "time_to_batch_fn", "=", "lambda", "t", ":", "tf", ".", "reshape", "(", "t", ",", "[", "-", "1", "]", "+", "t", ".", "shape", "[", "2", ":", "]", ".", "as_list", "(", ")", ")", "\n", "batched", "=", "tf", ".", "nest", ".", "map_structure", "(", "time_to_batch_fn", ",", "inputs", ")", "\n", "output", "=", "fn", "(", "*", "batched", ")", "\n", "prefix", "=", "[", "int", "(", "tf", ".", "nest", ".", "flatten", "(", "inputs", ")", "[", "0", "]", ".", "shape", "[", "0", "]", ")", ",", "-", "1", "]", "\n", "batch_to_time_fn", "=", "lambda", "t", ":", "tf", ".", "reshape", "(", "t", ",", "prefix", "+", "t", ".", "shape", "[", "1", ":", "]", ".", "as_list", "(", ")", ")", "\n", "return", "tf", ".", "nest", ".", "map_structure", "(", "batch_to_time_fn", ",", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.make_time_major": [[735, 762], ["tensorflow.nest.map_structure", "tensorflow.rank", "tensorflow.transpose", "tf.transpose.set_shape", "tensorflow.concat", "tensorflow.TensorShape().concatenate", "tensorflow.xla.experimental.compile", "tensorflow.range", "tensorflow.TensorShape"], "function", ["None"], ["", "def", "make_time_major", "(", "x", ")", ":", "\n", "  ", "\"\"\"Transposes the batch and time dimensions of a nest of Tensors.\n\n  If an input tensor has rank < 2 it returns the original tensor. Retains as\n  much of the static shape information as possible.\n\n  Args:\n    x: A nest of Tensors.\n\n  Returns:\n    x transposed along the first two dimensions.\n  \"\"\"", "\n", "\n", "def", "transpose", "(", "t", ")", ":", "\n", "    ", "t_static_shape", "=", "t", ".", "shape", "\n", "if", "t_static_shape", ".", "rank", "is", "not", "None", "and", "t_static_shape", ".", "rank", "<", "2", ":", "\n", "      ", "return", "t", "\n", "\n", "", "t_rank", "=", "tf", ".", "rank", "(", "t", ")", "\n", "t_t", "=", "tf", ".", "transpose", "(", "t", ",", "tf", ".", "concat", "(", "(", "[", "1", ",", "0", "]", ",", "tf", ".", "range", "(", "2", ",", "t_rank", ")", ")", ",", "axis", "=", "0", ")", ")", "\n", "t_t", ".", "set_shape", "(", "\n", "tf", ".", "TensorShape", "(", "[", "t_static_shape", "[", "1", "]", ",", "\n", "t_static_shape", "[", "0", "]", "]", ")", ".", "concatenate", "(", "t_static_shape", "[", "2", ":", "]", ")", ")", "\n", "return", "t_t", "\n", "\n", "", "return", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "tf", ".", "xla", ".", "experimental", ".", "compile", "(", "transpose", ",", "[", "t", "]", ")", "[", "0", "]", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.num_divisible": [[858, 860], ["sum"], "function", ["None"], ["def", "num_divisible", "(", "v", ",", "m", ")", ":", "\n", "  ", "return", "sum", "(", "[", "1", "for", "x", "in", "v", "if", "x", "%", "m", "==", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.tpu_encode": [[862, 907], ["tensorflow.nest.map_structure", "t.shape.num_elements", "tensorflow.reshape", "tensorflow.bitcast", "tensorflow.reshape", "utils.TPUEncodedUInt8", "tensorflow.xla.experimental.compile", "absl.logging.warning", "tensorflow.cast", "tensorflow.cast", "tensorflow.transpose", "tensorflow.reshape", "utils.TPUEncodedF32", "list", "range", "utils.num_divisible", "utils.num_divisible"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.num_divisible", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.num_divisible"], ["", "def", "tpu_encode", "(", "ts", ")", ":", "\n", "  ", "\"\"\"Encodes a nest of Tensors in a suitable way for TPUs.\n\n  TPUs do not support tf.uint8, tf.uint16 and other data types. Furthermore,\n  the speed of transfer and device reshapes depend on the shape of the data.\n  This function tries to optimize the data encoding for a number of use cases.\n\n  Should be used on CPU before sending data to TPU and in conjunction with\n  `tpu_decode` after the data is transferred.\n\n  Args:\n    ts: A tf.nest of Tensors.\n\n  Returns:\n    A tf.nest of encoded Tensors.\n  \"\"\"", "\n", "\n", "def", "visit", "(", "t", ")", ":", "\n", "    ", "num_elements", "=", "t", ".", "shape", ".", "num_elements", "(", ")", "\n", "# We need a multiple of 128 elements: encoding reduces the number of", "\n", "# elements by a factor 4 (packing uint8s into uint32s), and first thing", "\n", "# decode does is to reshape with a 32 minor-most dimension.", "\n", "if", "(", "t", ".", "dtype", "==", "tf", ".", "uint8", "and", "num_elements", "is", "not", "None", "and", "\n", "num_elements", "%", "128", "==", "0", ")", ":", "\n", "# For details of these transformations, see b/137182262.", "\n", "      ", "x", "=", "tf", ".", "xla", ".", "experimental", ".", "compile", "(", "\n", "lambda", "x", ":", "tf", ".", "transpose", "(", "x", ",", "list", "(", "range", "(", "1", ",", "t", ".", "shape", ".", "rank", ")", ")", "+", "[", "0", "]", ")", ",", "[", "t", "]", ")", "[", "0", "]", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", ",", "4", "]", ")", "\n", "x", "=", "tf", ".", "bitcast", "(", "x", ",", "tf", ".", "uint32", ")", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", "]", ")", "\n", "return", "TPUEncodedUInt8", "(", "x", ",", "t", ".", "shape", ")", "\n", "", "elif", "t", ".", "dtype", "==", "tf", ".", "uint8", ":", "\n", "      ", "logging", ".", "warning", "(", "'Inefficient uint8 transfer with shape: %s'", ",", "t", ".", "shape", ")", "\n", "return", "tf", ".", "cast", "(", "t", ",", "tf", ".", "bfloat16", ")", "\n", "", "elif", "t", ".", "dtype", "==", "tf", ".", "uint16", ":", "\n", "      ", "return", "tf", ".", "cast", "(", "t", ",", "tf", ".", "int32", ")", "\n", "", "elif", "(", "t", ".", "dtype", "==", "tf", ".", "float32", "and", "t", ".", "shape", ".", "rank", ">", "1", "and", "not", "\n", "(", "num_divisible", "(", "t", ".", "shape", ".", "dims", ",", "128", ")", ">=", "1", "and", "\n", "num_divisible", "(", "t", ".", "shape", ".", "dims", ",", "8", ")", ">=", "2", ")", ")", ":", "\n", "      ", "x", "=", "tf", ".", "reshape", "(", "t", ",", "[", "-", "1", "]", ")", "\n", "return", "TPUEncodedF32", "(", "x", ",", "t", ".", "shape", ")", "\n", "", "else", ":", "\n", "      ", "return", "t", "\n", "\n", "", "", "return", "tf", ".", "nest", ".", "map_structure", "(", "visit", ",", "ts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.tpu_decode": [[909, 945], ["tensorflow.nest.map_structure", "isinstance", "isinstance", "tensorflow.reshape", "tensorflow.broadcast_to", "tensorflow.reshape", "tensorflow.bitwise.bitwise_and", "tensorflow.bitwise.right_shift", "tensorflow.reshape", "tensorflow.transpose", "isinstance", "isinstance", "list", "numpy.array", "tensorflow.reshape", "range", "numpy.argsort", "isinstance"], "function", ["None"], ["", "def", "tpu_decode", "(", "ts", ",", "structure", "=", "None", ")", ":", "\n", "  ", "\"\"\"Decodes a nest of Tensors encoded with tpu_encode.\n\n  Args:\n    ts: A nest of Tensors or TPUEncodedUInt8 composite tensors.\n    structure: If not None, a nest of Tensors or TPUEncodedUInt8 composite\n      tensors (possibly within PerReplica's) that are only used to recreate the\n      structure of `ts` which then should be a list without composite tensors.\n\n  Returns:\n    A nest of decoded tensors packed as `structure` if available, otherwise\n    packed as `ts`.\n  \"\"\"", "\n", "def", "visit", "(", "t", ",", "s", ")", ":", "\n", "    ", "s", "=", "s", ".", "values", "[", "0", "]", "if", "isinstance", "(", "s", ",", "values_lib", ".", "PerReplica", ")", "else", "s", "\n", "if", "isinstance", "(", "s", ",", "TPUEncodedUInt8", ")", ":", "\n", "      ", "x", "=", "t", ".", "encoded", "if", "isinstance", "(", "t", ",", "TPUEncodedUInt8", ")", "else", "t", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", ",", "32", ",", "1", "]", ")", "\n", "x", "=", "tf", ".", "broadcast_to", "(", "x", ",", "x", ".", "shape", "[", ":", "-", "1", "]", "+", "[", "4", "]", ")", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", ",", "128", "]", ")", "\n", "x", "=", "tf", ".", "bitwise", ".", "bitwise_and", "(", "x", ",", "[", "0xFF", ",", "0xFF00", ",", "0xFF0000", ",", "0xFF000000", "]", "*", "32", ")", "\n", "x", "=", "tf", ".", "bitwise", ".", "right_shift", "(", "x", ",", "[", "0", ",", "8", ",", "16", ",", "24", "]", "*", "32", ")", "\n", "rank", "=", "s", ".", "original_shape", ".", "rank", "\n", "perm", "=", "[", "rank", "-", "1", "]", "+", "list", "(", "range", "(", "rank", "-", "1", ")", ")", "\n", "inverted_shape", "=", "np", ".", "array", "(", "s", ".", "original_shape", ")", "[", "np", ".", "argsort", "(", "perm", ")", "]", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "inverted_shape", ")", "\n", "x", "=", "tf", ".", "transpose", "(", "x", ",", "perm", ")", "\n", "return", "x", "\n", "", "elif", "isinstance", "(", "s", ",", "TPUEncodedF32", ")", ":", "\n", "      ", "x", "=", "t", ".", "encoded", "if", "isinstance", "(", "t", ",", "TPUEncodedF32", ")", "else", "t", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "s", ".", "original_shape", ")", "\n", "return", "x", "\n", "", "else", ":", "\n", "      ", "return", "t", "\n", "\n", "", "", "return", "tf", ".", "nest", ".", "map_structure", "(", "visit", ",", "ts", ",", "structure", "or", "ts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.split_structure": [[947, 957], ["tensorflow.nest.flatten", "tensorflow.split", "tensorflow.nest.pack_sequence_as", "tensorflow.nest.pack_sequence_as", "tensorflow.shape"], "function", ["None"], ["", "def", "split_structure", "(", "structure", ",", "prefix_length", ",", "axis", "=", "0", ")", ":", "\n", "  ", "\"\"\"Splits in two a tf.nest structure of tensors along the first axis.\"\"\"", "\n", "flattened", "=", "tf", ".", "nest", ".", "flatten", "(", "structure", ")", "\n", "split", "=", "[", "tf", ".", "split", "(", "x", ",", "[", "prefix_length", ",", "tf", ".", "shape", "(", "x", ")", "[", "axis", "]", "-", "prefix_length", "]", ",", "\n", "axis", "=", "axis", ")", "\n", "for", "x", "in", "flattened", "]", "\n", "flattened_prefix", "=", "[", "pair", "[", "0", "]", "for", "pair", "in", "split", "]", "\n", "flattened_suffix", "=", "[", "pair", "[", "1", "]", "for", "pair", "in", "split", "]", "\n", "return", "(", "tf", ".", "nest", ".", "pack_sequence_as", "(", "structure", ",", "flattened_prefix", ")", ",", "\n", "tf", ".", "nest", ".", "pack_sequence_as", "(", "structure", ",", "flattened_suffix", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.tensor_spec_from_gym_space": [[972, 987], ["tensorflow.TensorSpec", "tensorflow.TensorSpec", "isinstance", "ValueError", "len", "ValueError"], "function", ["None"], ["", "", "def", "tensor_spec_from_gym_space", "(", "space", ",", "name", ")", ":", "\n", "  ", "\"\"\"Get a TensorSpec from a gym spec.\"\"\"", "\n", "if", "space", ".", "shape", "is", "not", "None", ":", "\n", "    ", "return", "tf", ".", "TensorSpec", "(", "space", ".", "shape", ",", "space", ".", "dtype", ",", "name", ")", "\n", "", "if", "not", "isinstance", "(", "space", ",", "gym", ".", "spaces", ".", "Tuple", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "'Space \\'{}\\' is not a tuple: unknown shape.'", ".", "format", "(", "space", ")", ")", "\n", "", "num_elements", "=", "0", "\n", "for", "s", "in", "space", ":", "\n", "    ", "if", "len", "(", "s", ".", "shape", ")", "!=", "1", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "'Only 1 dimension subspaces are handled for tuple spaces: {}'", ".", "format", "(", "\n", "space", ")", ")", "\n", "", "num_elements", "+=", "s", ".", "shape", "[", "0", "]", "\n", "", "return", "tf", ".", "TensorSpec", "(", "(", "num_elements", ",", ")", ",", "tf", ".", "float32", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.validate_learner_config": [[989, 1003], ["max"], "function", ["None"], ["", "def", "validate_learner_config", "(", "config", ",", "num_hosts", "=", "1", ")", ":", "\n", "  ", "\"\"\"Shared part of learner config validation.\"\"\"", "\n", "assert", "config", ".", "num_envs", ">", "0", "\n", "assert", "config", ".", "env_batch_size", ">", "0", "\n", "if", "config", ".", "inference_batch_size", "==", "-", "1", ":", "\n", "    ", "config", ".", "inference_batch_size", "=", "max", "(", "config", ".", "env_batch_size", ",", "\n", "config", ".", "num_envs", "//", "(", "2", "*", "num_hosts", ")", ")", "\n", "", "assert", "config", ".", "inference_batch_size", ">", "0", "\n", "assert", "config", ".", "inference_batch_size", "%", "config", ".", "env_batch_size", "==", "0", ",", "(", "\n", "'Learner-side batch size (=%d) must be exact multiple of the '", "\n", "'actor-side batch size (=%d).'", "%", "\n", "(", "config", ".", "inference_batch_size", ",", "config", ".", "env_batch_size", ")", ")", "\n", "assert", "config", ".", "num_envs", ">=", "config", ".", "inference_batch_size", "*", "num_hosts", ",", "(", "\n", "'Inference batch size is bigger than the number of environments.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.get_non_dying_envs": [[1005, 1060], ["tensorflow.reduce_any", "tensorflow.logical_and", "tensorflow.reduce_sum", "tensorflow.not_equal", "tensorflow.logical_not", "tensorflow.boolean_mask", "tensorflow.unique_with_counts", "tensorflow.debugging.Assert", "tensorflow.equal", "tensorflow.logical_not", "tensorflow.cast", "tensorflow.print", "tensorflow.equal", "tensorflow.expand_dims", "tensorflow.boolean_mask", "tensorflow.shape", "tensorflow.shape", "tensorflow.gather", "tensorflow.where"], "function", ["None"], ["", "def", "get_non_dying_envs", "(", "envs_needing_reset", ",", "reset_mask", ",", "env_ids", ")", ":", "\n", "  ", "\"\"\"Returns which transitions are valid or generated before an env. restarted.\n\n  Args:\n    envs_needing_reset: <int32>[num_envs_needing_reset] tensor with the IDs\n      of the environments that need a reset.\n    reset_mask: <bool>[inference_batch_size] tensor that contains True for\n      transitions that triggered an environment reset (i.e. transition whose\n      run_id does not match the previously store run_id for the corresponding\n      environment).\n    env_ids: <int32>[inference_batch_size] tensor of environment ID for each\n      transition in the inference batch.\n\n  Returns:\n    A pair:\n      - <bool>[inference_batch_size] tensor, True when the transition comes from\n        a non-dying actor. False for the transitions generated by an environment\n        before the transition that triggered a reset. This will typically be the\n        last generated transitions before an environment restarts.\n      - <int32>[num_nondying_envs] tensor, IDs of the envs that are not dying.\n  \"\"\"", "\n", "# <bool>[inference_batch_size] with True for all transitions coming from", "\n", "# environments that need a reset. Contrary to 'reset_mask' this covers *all*", "\n", "# transitions from the environments that have one transition that triggered", "\n", "# a reset, while 'reset_mask' only contains True for the transitions that", "\n", "# triggered a reset.", "\n", "envs_needing_reset_mask", "=", "tf", ".", "reduce_any", "(", "\n", "tf", ".", "equal", "(", "env_ids", ",", "tf", ".", "expand_dims", "(", "envs_needing_reset", ",", "-", "1", ")", ")", ",", "\n", "axis", "=", "0", ")", "\n", "dying_envs_mask", "=", "tf", ".", "logical_and", "(", "\n", "envs_needing_reset_mask", ",", "\n", "tf", ".", "logical_not", "(", "reset_mask", ")", ")", "\n", "num_dying_envs", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "cast", "(", "dying_envs_mask", ",", "tf", ".", "int32", ")", ")", "\n", "if", "tf", ".", "not_equal", "(", "num_dying_envs", ",", "0", ")", ":", "\n", "    ", "tf", ".", "print", "(", "'Found'", ",", "num_dying_envs", ",", "'transitions from dying environments. '", "\n", "'Dying environment IDs:'", ",", "\n", "tf", ".", "boolean_mask", "(", "env_ids", ",", "dying_envs_mask", ")", ",", "\n", "'Dying environments mask:'", ",", "dying_envs_mask", ")", "\n", "", "nondying_envs_mask", "=", "tf", ".", "logical_not", "(", "dying_envs_mask", ")", "\n", "nondying_env_ids", "=", "tf", ".", "boolean_mask", "(", "env_ids", ",", "nondying_envs_mask", ")", "\n", "unique_nondying_env_ids", ",", "_", ",", "unique_nondying_env_ids_count", "=", "(", "\n", "tf", ".", "unique_with_counts", "(", "nondying_env_ids", ")", ")", "\n", "# If this fires, a single inference batch contains at least two transitions", "\n", "# with' the same env_id, even after filtering transitions from dying actors.", "\n", "# This can mean that an actor restarted twice while the same inference batch", "\n", "# was being filled.", "\n", "tf", ".", "debugging", ".", "Assert", "(", "\n", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "nondying_env_ids", ")", "[", "0", "]", ",", "\n", "tf", ".", "shape", "(", "unique_nondying_env_ids", ")", "[", "0", "]", ")", ",", "\n", "data", "=", "[", "\n", "tf", ".", "gather", "(", "unique_nondying_env_ids", ",", "\n", "tf", ".", "where", "(", "unique_nondying_env_ids_count", ">=", "2", ")", "[", ":", "0", "]", ")", ",", "\n", "nondying_env_ids", "]", ",", "\n", "summarize", "=", "4096", ")", "\n", "return", "nondying_envs_mask", ",", "nondying_env_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.config_from_flags": [[1062, 1072], ["FLAGS.__flags.keys"], "function", ["None"], ["", "def", "config_from_flags", "(", ")", ":", "\n", "  ", "\"\"\"Generates training config from flags.\n\n  Returns:\n    Generated training config.\n  \"\"\"", "\n", "config", "=", "{", "}", "\n", "for", "key", "in", "FLAGS", ".", "__flags", ".", "keys", "(", ")", ":", "\n", "    ", "config", "[", "key", "]", "=", "FLAGS", "[", "key", "]", ".", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.serialize_config": [[1074, 1091], ["isinstance", "tensorflow.constant", "FLAGS.__flags.keys", "tensorflow.constant", "pickle.dumps", "pickle.dumps"], "function", ["None"], ["", "def", "serialize_config", "(", "config", ")", ":", "\n", "  ", "\"\"\"Serializes training config, so that it can be send over SEED's GRPC.\n\n  Args:\n    config: config to serialize.\n\n  Returns:\n    Tensor representing serialized training config.\n  \"\"\"", "\n", "if", "isinstance", "(", "config", ",", "flags", ".", "_flagvalues", ".", "FlagValues", ")", ":", "\n", "    ", "skip_keys", "=", "{", "'run_mode'", "}", "\n", "output", "=", "{", "}", "\n", "for", "key", "in", "FLAGS", ".", "__flags", ".", "keys", "(", ")", ":", "\n", "      ", "if", "FLAGS", "[", "key", "]", ".", "value", "!=", "FLAGS", "[", "key", "]", ".", "default", "and", "key", "not", "in", "skip_keys", ":", "\n", "        ", "output", "[", "key", "]", "=", "FLAGS", "[", "key", "]", ".", "value", "\n", "", "", "return", "tf", ".", "constant", "(", "pickle", ".", "dumps", "(", "output", ")", ")", "\n", "", "return", "tf", ".", "constant", "(", "pickle", ".", "dumps", "(", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.update_config": [[1093, 1111], ["pickle.loads", "isinstance", "client.get_config", "client.get_config.numpy"], "function", ["None"], ["", "def", "update_config", "(", "current_config", ",", "client", ")", ":", "\n", "  ", "\"\"\"Updates current config with information from the Learner.\n\n  Args:\n    current_config: config to update.\n    client: Learner's client object used to retrieve updated config.\n  \"\"\"", "\n", "try", ":", "\n", "    ", "update", "=", "client", ".", "get_config", "(", ")", "\n", "", "except", "AttributeError", ":", "\n", "# Getting configuration is not supported by the Learner.", "\n", "    ", "return", "\n", "", "update", "=", "pickle", ".", "loads", "(", "update", ".", "numpy", "(", ")", ")", "\n", "if", "isinstance", "(", "update", ",", "dict", ")", ":", "\n", "    ", "for", "key", ",", "value", "in", "update", ":", "\n", "      ", "current_config", "[", "key", "]", "=", "value", "\n", "", "", "else", ":", "\n", "    ", "current_config", "=", "update", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution_test.ParametricDistributionTest.create_box_space": [[28, 30], ["gym.spaces.Box", "numpy.array", "numpy.array"], "methods", ["None"], ["  ", "def", "create_box_space", "(", "self", ")", ":", "\n", "    ", "return", "spaces", ".", "Box", "(", "np", ".", "array", "(", "[", "-", "1", ",", "-", "1", ",", "-", "1", "]", ")", ",", "np", ".", "array", "(", "[", "1", ",", "1", ",", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution_test.ParametricDistributionTest.create_multidiscrete_space": [[31, 33], ["gym.spaces.MultiDiscrete"], "methods", ["None"], ["", "def", "create_multidiscrete_space", "(", "self", ")", ":", "\n", "    ", "return", "spaces", ".", "MultiDiscrete", "(", "[", "4", ",", "4", ",", "4", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution_test.ParametricDistributionTest.create_tuple_space": [[34, 37], ["gym.spaces.Tuple", "parametric_distribution_test.ParametricDistributionTest.create_box_space", "parametric_distribution_test.ParametricDistributionTest.create_multidiscrete_space"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution_test.ParametricDistributionTest.create_box_space", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution_test.ParametricDistributionTest.create_multidiscrete_space"], ["", "def", "create_tuple_space", "(", "self", ")", ":", "\n", "    ", "return", "spaces", ".", "Tuple", "(", "\n", "(", "self", ".", "create_box_space", "(", ")", ",", "self", ".", "create_multidiscrete_space", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution_test.ParametricDistributionTest.test_joint_distribution_shape": [[38, 49], ["seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "tensorflow.zeros", "parametric_distribution_test.ParametricDistributionTest.assertFalse", "parametric_distribution_test.ParametricDistributionTest.assertEqual", "parametric_distribution_test.ParametricDistributionTest.create_tuple_space", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space.entropy", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space."], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution_test.ParametricDistributionTest.create_tuple_space", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.entropy"], ["", "def", "test_joint_distribution_shape", "(", "self", ")", ":", "\n", "    ", "joint_distribution", "=", "parametric_distribution", ".", "get_parametric_distribution_for_action_space", "(", "\n", "self", ".", "create_tuple_space", "(", ")", ")", "\n", "\n", "batch_shape", "=", "[", "3", ",", "2", "]", "\n", "parameters_shape", "=", "[", "3", "*", "2", "+", "3", "*", "4", "]", "\n", "\n", "parameters", "=", "tf", ".", "zeros", "(", "batch_shape", "+", "parameters_shape", ")", "\n", "self", ".", "assertFalse", "(", "joint_distribution", ".", "reparametrizable", ")", "\n", "self", ".", "assertEqual", "(", "\n", "joint_distribution", "(", "parameters", ")", ".", "entropy", "(", ")", ".", "shape", ",", "batch_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution_test.ParametricDistributionTest.test_joint_distribution_logprob": [[50, 85], ["seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "numpy.array", "numpy.array", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space.log_prob", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space.log_prob", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "tensorflow.convert_to_tensor", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space.log_prob", "parametric_distribution_test.ParametricDistributionTest.assertAllClose", "parametric_distribution_test.ParametricDistributionTest.create_tuple_space", "parametric_distribution_test.ParametricDistributionTest.create_box_space", "parametric_distribution_test.ParametricDistributionTest.create_multidiscrete_space", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space.", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space.", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space."], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.log_prob", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution_test.ParametricDistributionTest.create_tuple_space", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution_test.ParametricDistributionTest.create_box_space", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution_test.ParametricDistributionTest.create_multidiscrete_space"], ["", "def", "test_joint_distribution_logprob", "(", "self", ")", ":", "\n", "    ", "joint_distribution", "=", "parametric_distribution", ".", "get_parametric_distribution_for_action_space", "(", "\n", "self", ".", "create_tuple_space", "(", ")", ")", "\n", "parameters", "=", "np", ".", "array", "(", "[", "0.", ",", "0.", ",", "0.", ",", "# Normal locs", "\n", ".1", ",", ".2", ",", ".3", ",", "# Normal scales", "\n", "1", ",", "0", ",", "0", ",", "0", ",", "# Discrete action 1", "\n", "0", ",", "1", ",", "0", ",", "0", ",", "# Discrete action 2", "\n", "0", ",", "0", ",", "1", ",", "0", "]", ",", "# Discrete action 3", "\n", "np", ".", "float32", ")", "\n", "actions", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "2", "]", ",", "\n", "[", "0", ",", "0", ",", ".99", ",", "0", ",", "1", ",", "2", "]", ",", "\n", "[", "0", ",", ".99", ",", "0", ",", "0", ",", "1", ",", "2", "]", ",", "\n", "[", ".99", ",", "0", ",", "0", ",", "0", ",", "1", ",", "2", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "3", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "2", ",", "2", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "0", ",", "2", ",", "3", "]", ",", "\n", "[", "0", ",", "0", ",", "0", ",", "1", ",", "2", ",", "3", "]", "]", ",", "np", ".", "float32", ")", "\n", "continuous_actions", "=", "actions", "[", ":", ",", ":", "3", "]", "\n", "discrete_actions", "=", "actions", "[", ":", ",", "3", ":", "]", "\n", "\n", "log_probs", "=", "joint_distribution", "(", "parameters", ")", ".", "log_prob", "(", "actions", ")", "\n", "\n", "normaltanh_dist", "=", "parametric_distribution", ".", "get_parametric_distribution_for_action_space", "(", "\n", "self", ".", "create_box_space", "(", ")", ")", "\n", "continuous_parameters", "=", "parameters", "[", ":", "6", "]", "\n", "continuous_log_probs", "=", "normaltanh_dist", "(", "continuous_parameters", ")", ".", "log_prob", "(", "\n", "continuous_actions", ")", "\n", "\n", "multidiscrete_dist", "=", "parametric_distribution", ".", "get_parametric_distribution_for_action_space", "(", "\n", "self", ".", "create_multidiscrete_space", "(", ")", ")", "\n", "discrete_parameters", "=", "tf", ".", "convert_to_tensor", "(", "parameters", "[", "6", ":", "]", ")", "\n", "discrete_log_probs", "=", "multidiscrete_dist", "(", "discrete_parameters", ")", ".", "log_prob", "(", "\n", "discrete_actions", ")", "\n", "\n", "self", ".", "assertAllClose", "(", "log_probs", ",", "continuous_log_probs", "+", "discrete_log_probs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution_test.ParametricDistributionTest.test_clipped_distribution_kl": [[86, 102], ["seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space.", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space.", "parametric_distribution_test.ParametricDistributionTest.assertEqual", "parametric_distribution_test.ParametricDistributionTest.create_box_space", "numpy.ones", "parametric_distribution_test.ParametricDistributionTest.create_box_space", "numpy.ones", "parametric_distribution.get_parametric_distribution_for_action_space.kl_divergence", "seed_rl.common.parametric_distribution.continuous_action_config", "seed_rl.common.parametric_distribution.continuous_action_config"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.get_parametric_distribution_for_action_space", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution_test.ParametricDistributionTest.create_box_space", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution_test.ParametricDistributionTest.create_box_space", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.ParametricDistribution.kl_divergence", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.continuous_action_config", "home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.continuous_action_config"], ["", "def", "test_clipped_distribution_kl", "(", "self", ")", ":", "\n", "    ", "clipped_distribution", "=", "parametric_distribution", ".", "get_parametric_distribution_for_action_space", "(", "\n", "self", ".", "create_box_space", "(", ")", ",", "\n", "continuous_config", "=", "parametric_distribution", ".", "continuous_action_config", "(", "\n", "action_postprocessor", "=", "'ClippedIdentity'", ")", ")", "\n", "\n", "dist", "=", "clipped_distribution", "(", "np", ".", "ones", "(", "(", "6", ",", ")", ",", "np", ".", "float32", ")", ")", "\n", "\n", "clipped_distribution2", "=", "parametric_distribution", ".", "get_parametric_distribution_for_action_space", "(", "\n", "self", ".", "create_box_space", "(", ")", ",", "\n", "continuous_config", "=", "parametric_distribution", ".", "continuous_action_config", "(", "\n", "action_postprocessor", "=", "'ClippedIdentity'", ")", ")", "\n", "dist2", "=", "clipped_distribution2", "(", "np", ".", "ones", "(", "(", "6", ",", ")", ",", "np", ".", "float32", ")", ")", "\n", "\n", "self", ".", "assertEqual", "(", "\n", "dist", ".", "kl_divergence", "(", "dist2", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.actor.are_summaries_enabled": [[41, 43], ["None"], "function", ["None"], ["def", "are_summaries_enabled", "(", ")", ":", "\n", "  ", "return", "FLAGS", ".", "task", "<", "FLAGS", ".", "num_actors_with_summaries", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.common.actor.actor_loop": [[45, 186], ["absl.logging.info", "actor.are_summaries_enabled", "tensorflow.summary.create_file_writer", "tensorflow.summary.create_noop_writer", "tf.summary.create_noop_writer.as_default", "os.path.join", "seed_rl.grpc.Client", "seed_rl.common.utils.update_config", "seed_rl.common.env_wrappers.BatchedEnvironment", "numpy.random.randint", "env_wrappers.BatchedEnvironment.reset", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "timer_cls", "timeit.default_timer", "tensorflow.summary.experimental.set_step", "seed_rl.common.utils.EnvOutput", "range", "absl.logging.info", "env_wrappers.BatchedEnvironment.close", "grpc.Client.inference", "timer_cls", "env_wrappers.BatchedEnvironment.step", "env_wrappers.BatchedEnvironment.render", "float", "timer_cls", "env_wrappers.BatchedEnvironment.reset_if_done", "env_wrappers.BatchedEnvironment.render", "numpy.iinfo", "client.inference.numpy", "timeit.default_timer", "seed_rl.common.utils.EnvOutput", "absl.logging.info", "numpy.array", "numpy.array", "grpc.Client.inference"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.actor.are_summaries_enabled", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.update_config", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.close", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.step", "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.BatchedEnvironment.render", "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.BatchedEnvironment.reset_if_done", "home.repos.pwc.inspect_result.google-research_seed_rl.common.env_wrappers.BatchedEnvironment.render"], ["", "def", "actor_loop", "(", "create_env_fn", ",", "config", "=", "None", ",", "log_period", "=", "1", ")", ":", "\n", "  ", "\"\"\"Main actor loop.\n\n  Args:\n    create_env_fn: Callable (taking the task ID as argument) that must return a\n      newly created environment.\n    config: Configuration of the training.\n    log_period: How often to log in seconds.\n  \"\"\"", "\n", "if", "not", "config", ":", "\n", "    ", "config", "=", "FLAGS", "\n", "", "env_batch_size", "=", "FLAGS", ".", "env_batch_size", "\n", "logging", ".", "info", "(", "'Starting actor loop. Task: %r. Environment batch size: %r'", ",", "\n", "FLAGS", ".", "task", ",", "env_batch_size", ")", "\n", "is_rendering_enabled", "=", "FLAGS", ".", "render", "and", "FLAGS", ".", "task", "==", "0", "\n", "if", "are_summaries_enabled", "(", ")", ":", "\n", "    ", "summary_writer", "=", "tf", ".", "summary", ".", "create_file_writer", "(", "\n", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "logdir", ",", "'actor_{}'", ".", "format", "(", "FLAGS", ".", "task", ")", ")", ",", "\n", "flush_millis", "=", "20000", ",", "max_queue", "=", "1000", ")", "\n", "timer_cls", "=", "profiling", ".", "ExportingTimer", "\n", "", "else", ":", "\n", "    ", "summary_writer", "=", "tf", ".", "summary", ".", "create_noop_writer", "(", ")", "\n", "timer_cls", "=", "utils", ".", "nullcontext", "\n", "\n", "", "actor_step", "=", "0", "\n", "with", "summary_writer", ".", "as_default", "(", ")", ":", "\n", "    ", "while", "True", ":", "\n", "      ", "try", ":", "\n", "# Client to communicate with the learner.", "\n", "        ", "client", "=", "grpc", ".", "Client", "(", "FLAGS", ".", "server_address", ")", "\n", "utils", ".", "update_config", "(", "config", ",", "client", ")", "\n", "batched_env", "=", "env_wrappers", ".", "BatchedEnvironment", "(", "\n", "create_env_fn", ",", "env_batch_size", ",", "FLAGS", ".", "task", "*", "env_batch_size", ",", "config", ")", "\n", "\n", "env_id", "=", "batched_env", ".", "env_ids", "\n", "run_id", "=", "np", ".", "random", ".", "randint", "(", "\n", "low", "=", "0", ",", "\n", "high", "=", "np", ".", "iinfo", "(", "np", ".", "int64", ")", ".", "max", ",", "\n", "size", "=", "env_batch_size", ",", "\n", "dtype", "=", "np", ".", "int64", ")", "\n", "observation", "=", "batched_env", ".", "reset", "(", ")", "\n", "reward", "=", "np", ".", "zeros", "(", "env_batch_size", ",", "np", ".", "float32", ")", "\n", "raw_reward", "=", "np", ".", "zeros", "(", "env_batch_size", ",", "np", ".", "float32", ")", "\n", "done", "=", "np", ".", "zeros", "(", "env_batch_size", ",", "np", ".", "bool", ")", "\n", "abandoned", "=", "np", ".", "zeros", "(", "env_batch_size", ",", "np", ".", "bool", ")", "\n", "\n", "global_step", "=", "0", "\n", "episode_step", "=", "np", ".", "zeros", "(", "env_batch_size", ",", "np", ".", "int32", ")", "\n", "episode_return", "=", "np", ".", "zeros", "(", "env_batch_size", ",", "np", ".", "float32", ")", "\n", "episode_raw_return", "=", "np", ".", "zeros", "(", "env_batch_size", ",", "np", ".", "float32", ")", "\n", "episode_step_sum", "=", "0", "\n", "episode_return_sum", "=", "0", "\n", "episode_raw_return_sum", "=", "0", "\n", "episodes_in_report", "=", "0", "\n", "\n", "elapsed_inference_s_timer", "=", "timer_cls", "(", "'actor/elapsed_inference_s'", ",", "1000", ")", "\n", "last_log_time", "=", "timeit", ".", "default_timer", "(", ")", "\n", "last_global_step", "=", "0", "\n", "while", "True", ":", "\n", "          ", "tf", ".", "summary", ".", "experimental", ".", "set_step", "(", "actor_step", ")", "\n", "env_output", "=", "utils", ".", "EnvOutput", "(", "reward", ",", "done", ",", "observation", ",", "\n", "abandoned", ",", "episode_step", ")", "\n", "with", "elapsed_inference_s_timer", ":", "\n", "            ", "action", "=", "client", ".", "inference", "(", "env_id", ",", "run_id", ",", "env_output", ",", "raw_reward", ")", "\n", "", "with", "timer_cls", "(", "'actor/elapsed_env_step_s'", ",", "1000", ")", ":", "\n", "            ", "observation", ",", "reward", ",", "done", ",", "info", "=", "batched_env", ".", "step", "(", "action", ".", "numpy", "(", ")", ")", "\n", "", "if", "is_rendering_enabled", ":", "\n", "            ", "batched_env", ".", "render", "(", ")", "\n", "", "for", "i", "in", "range", "(", "env_batch_size", ")", ":", "\n", "            ", "episode_step", "[", "i", "]", "+=", "1", "\n", "episode_return", "[", "i", "]", "+=", "reward", "[", "i", "]", "\n", "raw_reward", "[", "i", "]", "=", "float", "(", "(", "info", "[", "i", "]", "or", "{", "}", ")", ".", "get", "(", "'score_reward'", ",", "\n", "reward", "[", "i", "]", ")", ")", "\n", "episode_raw_return", "[", "i", "]", "+=", "raw_reward", "[", "i", "]", "\n", "# If the info dict contains an entry abandoned=True and the", "\n", "# episode was ended (done=True), then we need to specially handle", "\n", "# the final transition as per the explanations below.", "\n", "abandoned", "[", "i", "]", "=", "(", "info", "[", "i", "]", "or", "{", "}", ")", ".", "get", "(", "'abandoned'", ",", "False", ")", "\n", "assert", "done", "[", "i", "]", "if", "abandoned", "[", "i", "]", "else", "True", "\n", "if", "done", "[", "i", "]", ":", "\n", "# If the episode was abandoned, we need to report the final", "\n", "# transition including the final observation as if the episode has", "\n", "# not terminated yet. This way, learning algorithms can use the", "\n", "# transition for learning.", "\n", "              ", "if", "abandoned", "[", "i", "]", ":", "\n", "# We do not signal yet that the episode was abandoned. This will", "\n", "# happen for the transition from the terminal state to the", "\n", "# resetted state.", "\n", "                ", "assert", "env_batch_size", "==", "1", "and", "i", "==", "0", ",", "(", "\n", "'Mixing of batched and non-batched inference calls is not '", "\n", "'yet supported'", ")", "\n", "env_output", "=", "utils", ".", "EnvOutput", "(", "reward", ",", "\n", "np", ".", "array", "(", "[", "False", "]", ")", ",", "observation", ",", "\n", "np", ".", "array", "(", "[", "False", "]", ")", ",", "episode_step", ")", "\n", "with", "elapsed_inference_s_timer", ":", "\n", "# action is ignored", "\n", "                  ", "client", ".", "inference", "(", "env_id", ",", "run_id", ",", "env_output", ",", "raw_reward", ")", "\n", "", "reward", "[", "i", "]", "=", "0.0", "\n", "raw_reward", "[", "i", "]", "=", "0.0", "\n", "\n", "# Periodically log statistics.", "\n", "", "current_time", "=", "timeit", ".", "default_timer", "(", ")", "\n", "episode_step_sum", "+=", "episode_step", "[", "i", "]", "\n", "episode_return_sum", "+=", "episode_return", "[", "i", "]", "\n", "episode_raw_return_sum", "+=", "episode_raw_return", "[", "i", "]", "\n", "global_step", "+=", "episode_step", "[", "i", "]", "\n", "episodes_in_report", "+=", "1", "\n", "if", "current_time", "-", "last_log_time", ">=", "log_period", ":", "\n", "                ", "logging", ".", "info", "(", "\n", "'Actor steps: %i, Return: %f Raw return: %f '", "\n", "'Episode steps: %f, Speed: %f steps/s'", ",", "global_step", ",", "\n", "episode_return_sum", "/", "episodes_in_report", ",", "\n", "episode_raw_return_sum", "/", "episodes_in_report", ",", "\n", "episode_step_sum", "/", "episodes_in_report", ",", "\n", "(", "global_step", "-", "last_global_step", ")", "/", "\n", "(", "current_time", "-", "last_log_time", ")", ")", "\n", "last_global_step", "=", "global_step", "\n", "episode_return_sum", "=", "0", "\n", "episode_raw_return_sum", "=", "0", "\n", "episode_step_sum", "=", "0", "\n", "episodes_in_report", "=", "0", "\n", "last_log_time", "=", "current_time", "\n", "\n", "", "episode_step", "[", "i", "]", "=", "0", "\n", "episode_return", "[", "i", "]", "=", "0", "\n", "episode_raw_return", "[", "i", "]", "=", "0", "\n", "\n", "# Finally, we reset the episode which will report the transition", "\n", "# from the terminal state to the resetted state in the next loop", "\n", "# iteration (with zero rewards).", "\n", "", "", "with", "timer_cls", "(", "'actor/elapsed_env_reset_s'", ",", "10", ")", ":", "\n", "            ", "observation", "=", "batched_env", ".", "reset_if_done", "(", "done", ")", "\n", "\n", "", "if", "is_rendering_enabled", "and", "done", "[", "0", "]", ":", "\n", "            ", "batched_env", ".", "render", "(", ")", "\n", "\n", "", "actor_step", "+=", "1", "\n", "", "", "except", "(", "tf", ".", "errors", ".", "UnavailableError", ",", "tf", ".", "errors", ".", "CancelledError", ")", ":", "\n", "        ", "logging", ".", "info", "(", "'Inference call failed. This is normal at the end of '", "\n", "'training.'", ")", "\n", "batched_env", ".", "close", "(", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.vtrace_main.create_agent": [[41, 44], ["seed_rl.dmlab.networks.ImpalaDeep"], "function", ["None"], ["'n_lstm_layers'", ",", "0", ",", "\n", "'Number of LSTM layers. LSTM layers afre applied after MLP layers.'", ")", "\n", "flags", ".", "DEFINE_integer", "(", "'lstm_size'", ",", "64", ",", "'Sizes of each LSTM layer.'", ")", "\n", "flags", ".", "DEFINE_bool", "(", "'normalize_observations'", ",", "False", ",", "'Whether to normalize'", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.vtrace_main.create_optimizer": [[46, 52], ["tensorflow.keras.optimizers.schedules.PolynomialDecay", "tensorflow.keras.optimizers.Adam"], "function", ["None"], ["# Environment settings.", "\n", "flags", ".", "DEFINE_string", "(", "'env_name'", ",", "'HalfCheetah-v2'", ",", "\n", "'Name of the environment from OpenAI Gym.'", ")", "\n", "flags", ".", "DEFINE_enum", "(", "\n", "'discretization'", ",", "'none'", ",", "[", "'none'", ",", "'lin'", ",", "'log'", "]", ",", "'Values other than '", "\n", "'\"none\" cause action coordinates to be discretized into n_actions_per_dim '", "\n", "'buckets. Buckets are spaced linearly between the bounds if \"lin\" mode is '", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.vtrace_main.main": [[54, 65], ["len", "absl.app.UsageError", "seed_rl.common.actor.actor_loop", "seed_rl.agents.vtrace.learner.learner_loop", "ValueError"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.actor.actor_loop", "home.repos.pwc.inspect_result.google-research_seed_rl.policy_gradient.learner.learner_loop"], ["flags", ".", "DEFINE_integer", "(", "\n", "'n_actions_per_dim'", ",", "11", ",", "'The number of buckets per action coordinate if '", "\n", "'discretization is used.'", ")", "\n", "flags", ".", "DEFINE_float", "(", "\n", "'action_ratio'", ",", "30.", ",", "\n", "'The ratio between the highest and the lowest positive '", "\n", "'action for logarithmic action discretization.'", ")", "\n", "\n", "FLAGS", "=", "flags", ".", "FLAGS", "\n", "\n", "\n", "def", "create_agent", "(", "unused_action_space", ",", "unused_env_observation_space", ",", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks._Stack.__init__": [[29, 44], ["tensorflow.Module.__init__", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.MaxPool2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "range", "range"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["    ", "\"\"\"Creates an MLP followed by a stacked LSTM agent.\n\n    Args:\n      parametric_action_distribution: an object of ParametricDistribution class\n        specifing a parametric distribution over actions to be used\n      mlp_sizes: list of integers with sizes of hidden MLP layers\n      lstm_sizes: list of integers with sizes of LSTM layers\n    \"\"\"", "\n", "super", "(", "MLPandLSTM", ",", "self", ")", ".", "__init__", "(", "name", "=", "'MLPandLSTM'", ")", "\n", "self", ".", "_parametric_action_distribution", "=", "parametric_action_distribution", "\n", "\n", "# MLP", "\n", "mlp_layers", "=", "[", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "size", ",", "'relu'", ")", "for", "size", "in", "mlp_sizes", "]", "\n", "self", ".", "_mlp", "=", "tf", ".", "keras", ".", "Sequential", "(", "mlp_layers", ")", "\n", "# stacked LSTM", "\n", "lstm_cells", "=", "[", "tf", ".", "keras", ".", "layers", ".", "LSTMCell", "(", "size", ")", "for", "size", "in", "lstm_sizes", "]", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks._Stack.__call__": [[46, 61], ["networks._Stack._conv", "networks._Stack._max_pool", "zip", "tensorflow.nn.relu", "res_conv0", "tensorflow.nn.relu", "res_conv1"], "methods", ["None"], ["# Layers for _head.", "\n", "self", ".", "_policy_logits", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "parametric_action_distribution", ".", "param_size", ",", "name", "=", "'policy_logits'", ")", "\n", "self", ".", "_baseline", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "1", ",", "name", "=", "'baseline'", ")", "\n", "\n", "", "@", "tf", ".", "function", "\n", "def", "initial_state", "(", "self", ",", "batch_size", ")", ":", "\n", "    ", "return", "self", ".", "_core", ".", "get_initial_state", "(", "batch_size", "=", "batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "def", "_head", "(", "self", ",", "core_output", ")", ":", "\n", "    ", "policy_logits", "=", "self", ".", "_policy_logits", "(", "core_output", ")", "\n", "baseline", "=", "tf", ".", "squeeze", "(", "self", ".", "_baseline", "(", "core_output", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Sample an action from the policy.", "\n", "action", "=", "self", ".", "_parametric_action_distribution", ".", "sample", "(", "policy_logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.__init__": [[72, 90], ["tensorflow.Module.__init__", "tensorflow.keras.layers.LSTMCell", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "networks._Stack"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__"], ["\n", "", "def", "__call__", "(", "self", ",", "prev_actions", ",", "env_outputs", ",", "core_state", ",", "unroll", "=", "False", ",", "\n", "is_training", "=", "False", ")", ":", "\n", "    ", "\"\"\"Runs the agent.\n\n    Args:\n      prev_actions: Previous action. Not used by this agent.\n      env_outputs: Structure with reward, done and observation fields. Only\n        observation field is used by this agent. It should have the shape\n        [time, batch_size, observation_size].\n      core_state: Agent state.\n      unroll: Should be True if inputs contain the time dimension and False\n        otherwise.\n      is_training: Whether we are in the loss computation. Not used by this\n        agent.\n    Returns:\n      A structure with action, policy_logits and baseline.\n    \"\"\"", "\n", "if", "not", "unroll", ":", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.initial_state": [[91, 93], ["networks.ImpalaDeep._core.get_initial_state"], "methods", ["None"], ["# Add time dimension.", "\n", "      ", "prev_actions", ",", "env_outputs", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "t", ":", "tf", ".", "expand_dims", "(", "t", ",", "0", ")", ",", "(", "prev_actions", ",", "env_outputs", ")", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep._torso": [[94, 115], ["tensorflow.cast", "tensorflow.nn.relu", "networks.ImpalaDeep._conv_to_linear", "tensorflow.nn.relu", "tensorflow.expand_dims", "tensorflow.one_hot", "tensorflow.concat", "stack", "tensorflow.keras.layers.Flatten", "tensorflow.clip_by_value"], "methods", ["None"], ["\n", "", "outputs", ",", "core_state", "=", "self", ".", "_unroll", "(", "prev_actions", ",", "env_outputs", ",", "core_state", ")", "\n", "\n", "if", "not", "unroll", ":", "\n", "# Remove time dimension.", "\n", "      ", "outputs", "=", "tf", ".", "nest", ".", "map_structure", "(", "lambda", "t", ":", "tf", ".", "squeeze", "(", "t", ",", "0", ")", ",", "outputs", ")", "\n", "\n", "", "return", "outputs", ",", "core_state", "\n", "\n", "", "def", "_unroll", "(", "self", ",", "unused_prev_actions", ",", "env_outputs", ",", "core_state", ")", ":", "\n", "    ", "unused_reward", ",", "done", ",", "observation", ",", "_", ",", "_", "=", "env_outputs", "\n", "observation", "=", "self", ".", "_mlp", "(", "observation", ")", "\n", "\n", "initial_core_state", "=", "self", ".", "_core", ".", "get_initial_state", "(", "\n", "batch_size", "=", "tf", ".", "shape", "(", "observation", ")", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "core_output_list", "=", "[", "]", "\n", "for", "input_", ",", "d", "in", "zip", "(", "tf", ".", "unstack", "(", "observation", ")", ",", "tf", ".", "unstack", "(", "done", ")", ")", ":", "\n", "# If the episode ended, the core state should be reset before the next.", "\n", "      ", "core_state", "=", "tf", ".", "nest", ".", "map_structure", "(", "\n", "lambda", "x", ",", "y", ",", "d", "=", "d", ":", "tf", ".", "where", "(", "\n", "tf", ".", "reshape", "(", "d", ",", "[", "d", ".", "shape", "[", "0", "]", "]", "+", "[", "1", "]", "*", "(", "x", ".", "shape", ".", "rank", "-", "1", ")", ")", ",", "x", ",", "y", ")", ",", "\n", "initial_core_state", ",", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep._head": [[116, 125], ["networks.ImpalaDeep._policy_logits", "tensorflow.squeeze", "tensorflow.random.categorical", "tensorflow.squeeze", "AgentOutput", "networks.ImpalaDeep._baseline"], "methods", ["None"], ["core_state", ")", "\n", "core_output", ",", "core_state", "=", "self", ".", "_core", "(", "input_", ",", "core_state", ")", "\n", "core_output_list", ".", "append", "(", "core_output", ")", "\n", "", "outputs", "=", "tf", ".", "stack", "(", "core_output_list", ")", "\n", "\n", "return", "utils", ".", "batch_apply", "(", "self", ".", "_head", ",", "(", "outputs", ",", ")", ")", ",", "core_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.get_action": [[131, 134], ["networks.ImpalaDeep.__call__"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.__call__"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep.__call__": [[135, 151], ["networks.ImpalaDeep._unroll", "tensorflow.nest.map_structure", "tensorflow.nest.map_structure", "tensorflow.expand_dims", "tensorflow.squeeze"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep._unroll"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.networks.ImpalaDeep._unroll": [[152, 172], ["seed_rl.common.utils.batch_apply", "networks.ImpalaDeep._core.get_initial_state", "zip", "tensorflow.stack", "tensorflow.unstack", "tensorflow.unstack", "tensorflow.nest.map_structure", "networks.ImpalaDeep._core", "core_output_list.append", "seed_rl.common.utils.batch_apply", "tensorflow.shape", "tensorflow.where", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.batch_apply", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.UnrollStore.append", "home.repos.pwc.inspect_result.google-research_seed_rl.common.utils.batch_apply"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.games.human_normalized_score": [[160, 173], ["numpy.mean"], "function", ["home.repos.pwc.inspect_result.google-research_seed_rl.common.parametric_distribution.TanhTransformedDistribution.mean"], ["def", "human_normalized_score", "(", "game", ",", "returns", ")", ":", "\n", "  ", "\"\"\"Computes human normalized score.\n\n  Args:\n    game: The DeepMind Lab game.\n    returns: A list of episode returns.\n\n  Returns:\n    A float with the human normalized score in percentage.\n  \"\"\"", "\n", "human", "=", "HUMAN_SCORES", "[", "game", "]", "\n", "random", "=", "RANDOM_SCORES", "[", "game", "]", "\n", "return", "(", "np", ".", "mean", "(", "returns", ")", "-", "random", ")", "/", "(", "human", "-", "random", ")", "*", "100", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.environment_test.EnvironmentTest.test_run_step": [[29, 34], ["seed_rl.dmlab.env.create_environment", "seed_rl.dmlab.env.create_environment.reset", "seed_rl.dmlab.env.create_environment.step", "seed_rl.dmlab.env.create_environment.close"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.create_environment", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.step", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.close"], ["      ", "_", ",", "_", ",", "done", ",", "_", "=", "environment", ".", "step", "(", "environment", ".", "action_space", ".", "sample", "(", ")", ")", "\n", "if", "done", ":", "\n", "        ", "environment", ".", "reset", "(", ")", "\n", "\n", "", "", "", "def", "test_mujoco_env", "(", "self", ")", ":", "\n", "    ", "for", "discretization", "in", "[", "'none'", ",", "'log'", ",", "'lin'", "]", ":", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.LevelCache.__init__": [[60, 62], ["None"], "methods", ["None"], ["\n", "\n", "", "", "def", "create_environment", "(", "env_name", ",", "\n"]], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.LevelCache.get_path": [[63, 67], ["hashlib.md5().hexdigest", "os.path.join", "hashlib.md5", "hashlib.md5().hexdigest.encode"], "methods", ["None"], ["discretization", "=", "'none'", ",", "\n", "n_actions_per_dim", "=", "11", ",", "\n", "action_ratio", "=", "30.", ",", "\n", "gym_kwargs", "=", "None", ")", ":", "\n", "  "]], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.LevelCache.fetch": [[68, 75], ["env.LevelCache.get_path", "tensorflow.io.gfile.copy"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.LevelCache.get_path"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.LevelCache.write": [[76, 81], ["env.LevelCache.get_path", "tensorflow.io.gfile.exists", "tensorflow.io.gfile.makedirs", "tensorflow.io.gfile.copy", "os.path.dirname"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.LevelCache.get_path"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.__init__": [[86, 116], ["numpy.random.RandomState", "deepmind_lab.Lab", "gym.spaces.Discrete", "gym.spaces.Box", "deepmind_lab.set_runfiles_path", "len", "env.LevelCache", "str", "config.items"], "methods", ["None"], ["\n", "\n", "assert", "FLAGS", ".", "num_action_repeats", "==", "1", ",", "'Only action repeat of 1 is supported.'", "\n", "\n", "if", "env_name", "==", "'toy_env'", ":", "\n", "    ", "env", "=", "toy_env", ".", "ToyEnv", "(", ")", "\n", "", "elif", "env_name", "==", "'toy_memory_env'", ":", "\n", "    ", "env", "=", "toy_env", ".", "ToyMemoryEnv", "(", ")", "\n", "", "elif", "env_name", "==", "'bit_flip'", ":", "\n", "    ", "return", "toy_env", ".", "BitFlippingEnv", "(", ")", "\n", "", "else", ":", "# mujoco", "\n", "    ", "gym_kwargs", "=", "gym_kwargs", "if", "gym_kwargs", "else", "{", "}", "\n", "gym_spec", "=", "gym", ".", "spec", "(", "env_name", ")", "\n", "env", "=", "gym_spec", ".", "make", "(", "**", "gym_kwargs", ")", "\n", "env", "=", "SinglePrecisionWrapper", "(", "env", ")", "\n", "\n", "# rescale actions so that all bounds are [-1, 1]", "\n", "", "env", "=", "env_wrappers", ".", "UniformBoundActionSpaceWrapper", "(", "env", ")", "\n", "# optionally discretize actions", "\n", "if", "discretization", "!=", "'none'", ":", "\n", "    ", "env", "=", "env_wrappers", ".", "DiscretizeEnvWrapper", "(", "env", ",", "n_actions_per_dim", ",", "\n", "discretization", ",", "action_ratio", ")", "\n", "\n", "", "return", "env", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab._observation": [[117, 119], ["env.DmLab._env.observations"], "methods", ["None"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset": [[120, 123], ["env.DmLab._env.reset", "env.DmLab._observation", "env.DmLab._random_state.randint"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.reset", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab._observation"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.step": [[124, 130], ["numpy.array", "env.DmLab._env.step", "env.DmLab._env.is_running", "env.DmLab._observation"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.step", "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab._observation"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.close": [[131, 133], ["env.DmLab._env.close"], "methods", ["home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.DmLab.close"], []], "home.repos.pwc.inspect_result.google-research_seed_rl.dmlab.env.create_environment": [[135, 147], ["absl.logging.info", "env.DmLab"], "function", ["None"], []]}