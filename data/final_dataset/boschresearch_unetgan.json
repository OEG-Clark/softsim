{"home.repos.pwc.inspect_result.boschresearch_unetgan.None.spectral.SpectralNorm.__init__": [[16, 23], ["torch.nn.Module.__init__", "spectral.SpectralNorm._made_params", "spectral.SpectralNorm._make_params"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.spectral.SpectralNorm._made_params", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.spectral.SpectralNorm._make_params"], ["    ", "def", "__init__", "(", "self", ",", "module", ",", "name", "=", "'weight'", ",", "power_iterations", "=", "1", ")", ":", "\n", "        ", "super", "(", "SpectralNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "power_iterations", "=", "power_iterations", "\n", "if", "not", "self", ".", "_made_params", "(", ")", ":", "\n", "            ", "self", ".", "_make_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.spectral.SpectralNorm._update_u_v": [[24, 37], ["getattr", "getattr", "getattr", "range", "getattr.dot", "setattr", "spectral.l2normalize", "spectral.l2normalize", "getattr.view().mv", "torch.mv", "torch.mv", "torch.mv", "torch.mv", "torch.mv", "torch.mv", "torch.mv", "torch.mv", "getattr.dot.expand_as", "torch.t", "torch.t", "torch.t", "torch.t", "getattr.view", "getattr.view", "getattr.view"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.spectral.l2normalize", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.spectral.l2normalize"], ["", "", "def", "_update_u_v", "(", "self", ")", ":", "\n", "        ", "u", "=", "getattr", "(", "self", ".", "module", ",", "self", ".", "name", "+", "\"_u\"", ")", "\n", "v", "=", "getattr", "(", "self", ".", "module", ",", "self", ".", "name", "+", "\"_v\"", ")", "\n", "w", "=", "getattr", "(", "self", ".", "module", ",", "self", ".", "name", "+", "\"_bar\"", ")", "\n", "\n", "height", "=", "w", ".", "data", ".", "shape", "[", "0", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "power_iterations", ")", ":", "\n", "            ", "v", ".", "data", "=", "l2normalize", "(", "torch", ".", "mv", "(", "torch", ".", "t", "(", "w", ".", "view", "(", "height", ",", "-", "1", ")", ".", "data", ")", ",", "u", ".", "data", ")", ")", "\n", "u", ".", "data", "=", "l2normalize", "(", "torch", ".", "mv", "(", "w", ".", "view", "(", "height", ",", "-", "1", ")", ".", "data", ",", "v", ".", "data", ")", ")", "\n", "\n", "# sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))", "\n", "", "sigma", "=", "u", ".", "dot", "(", "w", ".", "view", "(", "height", ",", "-", "1", ")", ".", "mv", "(", "v", ")", ")", "\n", "setattr", "(", "self", ".", "module", ",", "self", ".", "name", ",", "w", "/", "sigma", ".", "expand_as", "(", "w", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.spectral.SpectralNorm._made_params": [[38, 46], ["getattr", "getattr", "getattr"], "methods", ["None"], ["", "def", "_made_params", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "u", "=", "getattr", "(", "self", ".", "module", ",", "self", ".", "name", "+", "\"_u\"", ")", "\n", "v", "=", "getattr", "(", "self", ".", "module", ",", "self", ".", "name", "+", "\"_v\"", ")", "\n", "w", "=", "getattr", "(", "self", ".", "module", ",", "self", ".", "name", "+", "\"_bar\"", ")", "\n", "return", "True", "\n", "", "except", "AttributeError", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.spectral.SpectralNorm._make_params": [[48, 65], ["getattr", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "spectral.l2normalize", "spectral.l2normalize", "torch.nn.Parameter", "torch.nn.Parameter", "spectral.SpectralNorm.module.register_parameter", "spectral.SpectralNorm.module.register_parameter", "spectral.SpectralNorm.module.register_parameter", "getattr.data.new().normal_", "getattr.data.new().normal_", "getattr.view", "getattr.data.new", "getattr.data.new"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.spectral.l2normalize", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.spectral.l2normalize"], ["", "", "def", "_make_params", "(", "self", ")", ":", "\n", "        ", "w", "=", "getattr", "(", "self", ".", "module", ",", "self", ".", "name", ")", "\n", "\n", "height", "=", "w", ".", "data", ".", "shape", "[", "0", "]", "\n", "width", "=", "w", ".", "view", "(", "height", ",", "-", "1", ")", ".", "data", ".", "shape", "[", "1", "]", "\n", "\n", "u", "=", "Parameter", "(", "w", ".", "data", ".", "new", "(", "height", ")", ".", "normal_", "(", "0", ",", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "v", "=", "Parameter", "(", "w", ".", "data", ".", "new", "(", "width", ")", ".", "normal_", "(", "0", ",", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "u", ".", "data", "=", "l2normalize", "(", "u", ".", "data", ")", "\n", "v", ".", "data", "=", "l2normalize", "(", "v", ".", "data", ")", "\n", "w_bar", "=", "Parameter", "(", "w", ".", "data", ")", "\n", "\n", "del", "self", ".", "module", ".", "_parameters", "[", "self", ".", "name", "]", "\n", "\n", "self", ".", "module", ".", "register_parameter", "(", "self", ".", "name", "+", "\"_u\"", ",", "u", ")", "\n", "self", ".", "module", ".", "register_parameter", "(", "self", ".", "name", "+", "\"_v\"", ",", "v", ")", "\n", "self", ".", "module", ".", "register_parameter", "(", "self", ".", "name", "+", "\"_bar\"", ",", "w_bar", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.spectral.SpectralNorm.forward": [[67, 70], ["spectral.SpectralNorm._update_u_v", "spectral.SpectralNorm.module.forward"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.spectral.SpectralNorm._update_u_v", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.WrapInception.forward"], ["", "def", "forward", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "_update_u_v", "(", ")", "\n", "return", "self", ".", "module", ".", "forward", "(", "*", "args", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.spectral.l2normalize": [[11, 13], ["v.norm"], "function", ["None"], ["def", "l2normalize", "(", "v", ",", "eps", "=", "1e-12", ")", ":", "\n", "    ", "return", "v", "/", "(", "v", ".", "norm", "(", ")", "+", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train_fns.dummy_training_function": [[22, 26], ["None"], "function", ["None"], ["def", "dummy_training_function", "(", ")", ":", "\n", "    ", "def", "train", "(", "x", ",", "y", ")", ":", "\n", "        ", "return", "{", "}", "\n", "", "return", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train_fns.BCEloss": [[27, 31], ["torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "d_real_target.expand_as", "d_fake_target.expand_as"], "function", ["None"], ["", "def", "BCEloss", "(", "D_fake", ",", "D_real", ",", "d_real_target", ",", "d_fake_target", ")", ":", "\n", "    ", "real", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "D_real", ",", "d_real_target", ".", "expand_as", "(", "D_real", ")", ")", "\n", "fake", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "D_fake", ",", "d_fake_target", ".", "expand_as", "(", "D_fake", ")", ")", "\n", "return", "real", ",", "fake", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train_fns.BCEfakeloss": [[32, 34], ["torch.binary_cross_entropy_with_logits", "target.expand_as"], "function", ["None"], ["", "def", "BCEfakeloss", "(", "D_fake", ",", "target", ")", ":", "\n", "    ", "return", "F", ".", "binary_cross_entropy_with_logits", "(", "D_fake", ",", "target", ".", "expand_as", "(", "D_fake", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train_fns.GAN_training_function": [[35, 296], ["G.optim.zero_grad", "D.optim.zero_grad", "int", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "functools.partial", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "functools.partial", "range", "G.optim.zero_grad", "z_.sample_", "y_.sample_", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "range", "G.optim.step", "float", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "utils.toggle_grad", "utils.toggle_grad", "D.optim.zero_grad", "range", "D.optim.step", "utils.toggle_grad", "utils.toggle_grad", "GD", "functools.partial.", "functools.partial.", "fake_loss.detach().item", "fake_loss.detach().item", "G_loss.detach().item", "G_loss.backward", "print", "utils.ortho", "ema.update", "float", "float", "float", "float", "float", "float", "float", "torch.split.size", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "z_.sample_", "y_.sample_", "torch.tensor().cuda.detach().item", "torch.tensor().cuda.detach().item", "D_loss.backward", "print", "utils.ortho", "float", "float", "float", "float", "float", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.rand().detach().item", "torch.rand().detach().item", "torch.rand().detach().item", "GD", "functools.partial.", "D_loss_real_2d.detach().item", "D_loss_fake_2d.detach().item", "D_mixed.view", "target_map.view", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack.mean().detach().item", "functools.partial.", "D_loss_real_middle.detach().item", "D_loss_fake_middle.detach().item", "torch.binary_cross_entropy_with_logits", "mixed_middle_loss.mean().detach().item", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "float", "fake_loss.detach", "fake_loss.detach", "G_loss.detach", "GD", "GD", "min", "matplotlib.pyplot.figure", "torchvision.utils.make_grid", "m.cpu().numpy.permute", "m.cpu().numpy.cpu().numpy", "matplotlib.pyplot.imshow", "matplotlib.pyplot.figure", "matplotlib.pyplot.figure", "torchvision.utils.make_grid", "m.cpu().numpy.permute", "m.cpu().numpy.cpu().numpy", "matplotlib.pyplot.imshow", "matplotlib.pyplot.figure", "matplotlib.pyplot.figure", "torchvision.utils.make_grid", "m.cpu().numpy.permute", "m.cpu().numpy.cpu().numpy", "matplotlib.pyplot.imshow", "matplotlib.pyplot.figure", "torchvision.utils.make_grid", "m.cpu().numpy.permute", "m.cpu().numpy.cpu().numpy", "matplotlib.pyplot.imshow", "matplotlib.pyplot.title", "matplotlib.pyplot.show", "matplotlib.pyplot.figure", "D_fake.view", "D_real.view", "D_mixed.size", "torch.binary_cross_entropy_with_logits", "mix_list.append", "torch.tensor().cuda.expand_as", "torch.tensor().cuda.detach", "torch.tensor().cuda.detach", "consistency_loss.float().detach().item", "mix_loss.mean.mean", "torch.rand().detach", "torch.rand().detach", "torch.rand().detach", "D_loss_real_2d.detach", "D_loss_fake_2d.detach", "D_mixed[].view", "target_map[].view", "torch.stack.mean().detach", "D_loss_real_middle.detach", "D_loss_fake_middle.detach", "mixed_middle_loss.mean().detach", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.mse_loss", "G.shared.parameters", "m.cpu().numpy.cpu", "m.cpu().numpy.cpu", "m.cpu().numpy.cpu", "m.cpu().numpy.cpu", "consistency_loss.float().detach", "torch.rand", "torch.rand", "torch.rand", "torch.stack.mean", "mixed_middle_loss.mean", "consistency_loss.float"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Adam16.step", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.toggle_grad", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.toggle_grad", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Adam16.step", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.toggle_grad", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.toggle_grad", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.ortho", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.ema.update", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.ortho"], ["", "def", "GAN_training_function", "(", "G", ",", "D", ",", "GD", ",", "z_", ",", "y_", ",", "ema", ",", "state_dict", ",", "config", ")", ":", "\n", "    ", "def", "train", "(", "x", ",", "y", ",", "epoch", ",", "batch_size", ",", "target_map", "=", "None", ",", "r_mixup", "=", "0.0", ")", ":", "\n", "        ", "G", ".", "optim", ".", "zero_grad", "(", ")", "\n", "D", ".", "optim", ".", "zero_grad", "(", ")", "\n", "\n", "if", "config", "[", "\"unet_mixup\"", "]", ":", "\n", "            ", "real_target", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", ".", "cuda", "(", ")", "\n", "fake_target", "=", "torch", ".", "tensor", "(", "[", "0.0", "]", ")", ".", "cuda", "(", ")", "\n", "\n", "", "if", "config", "[", "\"unet_mixup\"", "]", "and", "not", "config", "[", "\"full_batch_mixup\"", "]", ":", "\n", "            ", "use_mixup_in_this_round", "=", "True", "\n", "", "elif", "config", "[", "\"unet_mixup\"", "]", "and", "config", "[", "\"full_batch_mixup\"", "]", ":", "\n", "            ", "use_mixup_in_this_round", "=", "torch", ".", "rand", "(", "1", ")", ".", "detach", "(", ")", ".", "item", "(", ")", "<", "r_mixup", "\n", "", "else", ":", "\n", "            ", "use_mixup_in_this_round", "=", "False", "\n", "\n", "", "out", "=", "{", "}", "\n", "\n", "skip_normal_real_fake_loss", "=", "(", "use_mixup_in_this_round", "and", "config", "[", "\"full_batch_mixup\"", "]", ")", "\n", "\n", "n_d_accu", "=", "config", "[", "'num_D_accumulations'", "]", "\n", "\n", "split_size", "=", "int", "(", "x", ".", "size", "(", "0", ")", "/", "n_d_accu", ")", "\n", "\n", "x", "=", "torch", ".", "split", "(", "x", ",", "split_size", ")", "\n", "y", "=", "torch", ".", "split", "(", "y", ",", "split_size", ")", "\n", "\n", "d_real_target", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", ".", "cuda", "(", ")", "\n", "d_fake_target", "=", "torch", ".", "tensor", "(", "[", "0.0", "]", ")", ".", "cuda", "(", ")", "\n", "\n", "discriminator_loss", "=", "functools", ".", "partial", "(", "BCEloss", ",", "d_real_target", "=", "d_real_target", ",", "d_fake_target", "=", "d_fake_target", ")", "\n", "mix_fake_target", "=", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", ".", "cuda", "(", ")", "\n", "fake_loss", "=", "functools", ".", "partial", "(", "BCEfakeloss", ",", "target", "=", "mix_fake_target", ")", "\n", "\n", "# Optionally toggle D and G's \"require_grad\"", "\n", "if", "config", "[", "'toggle_grads'", "]", ":", "\n", "            ", "utils", ".", "toggle_grad", "(", "D", ",", "True", ")", "\n", "utils", ".", "toggle_grad", "(", "G", ",", "False", ")", "\n", "\n", "", "for", "step_index", "in", "range", "(", "config", "[", "'num_D_steps'", "]", ")", ":", "\n", "            ", "counter", "=", "0", "\n", "# If accumulating gradients, loop multiple times before an optimizer step", "\n", "D", ".", "optim", ".", "zero_grad", "(", ")", "\n", "\n", "for", "accumulation_index", "in", "range", "(", "n_d_accu", ")", ":", "\n", "\n", "                ", "z_", ".", "sample_", "(", ")", "\n", "y_", ".", "sample_", "(", ")", "\n", "\n", "if", "use_mixup_in_this_round", ":", "\n", "\n", "                    ", "if", "(", "not", "config", "[", "\"full_batch_mixup\"", "]", ")", "or", "(", "config", "[", "\"full_batch_mixup\"", "]", "and", "(", "config", "[", "\"consistency_loss_and_augmentation\"", "]", "or", "config", "[", "\"consistency_loss\"", "]", ")", ")", ":", "\n", "\n", "                        ", "D_fake", ",", "D_real", ",", "D_mixed", ",", "G_z", ",", "mixed", ",", "D_middle_fake", ",", "D_middle_real", ",", "D_middle_mixed", ",", "target_map", "=", "GD", "(", "z_", "[", ":", "batch_size", "]", ",", "y_", "[", ":", "batch_size", "]", ",", "\n", "x", "[", "counter", "]", ",", "y", "[", "counter", "]", ",", "train_G", "=", "False", ",", "\n", "split_D", "=", "config", "[", "'split_D'", "]", ",", "mixup", "=", "True", ",", "target_map", "=", "target_map", ")", "# mixup can be true because weight is set to 0 when no mixup is used", "\n", "", "else", ":", "\n", "                        ", "D_mixed", ",", "G_z", ",", "mixed", ",", "D_middle_mixed", ",", "target_map", "=", "GD", "(", "z_", "[", ":", "batch_size", "]", ",", "y_", "[", ":", "batch_size", "]", ",", "\n", "x", "[", "counter", "]", ",", "y", "[", "counter", "]", ",", "train_G", "=", "False", ",", "return_G_z", "=", "True", ",", "\n", "split_D", "=", "config", "[", "'split_D'", "]", ",", "mixup", "=", "True", ",", "mixup_only", "=", "True", ",", "target_map", "=", "target_map", ")", "\n", "\n", "", "if", "config", "[", "\"slow_mixup\"", "]", "and", "not", "config", "[", "\"full_batch_mixup\"", "]", ":", "\n", "                        ", "mixup_coeff", "=", "min", "(", "1.0", ",", "epoch", "/", "config", "[", "\"warmup_epochs\"", "]", ")", "#use without full batch mixup", "\n", "", "else", ":", "\n", "                        ", "mixup_coeff", "=", "1.0", "\n", "\n", "", "if", "config", "[", "\"display_mixed_batch\"", "]", ":", "\n", "# This can help for debugging", "\n", "                        ", "plt", ".", "figure", "(", ")", "\n", "m", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "mixed", ",", "nrow", "=", "5", ",", "padding", "=", "2", ",", "normalize", "=", "True", ")", "\n", "m", "=", "m", ".", "permute", "(", "1", ",", "2", ",", "0", ")", "\n", "m", "=", "m", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "plt", ".", "imshow", "(", "m", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "m", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "G_z", ",", "nrow", "=", "5", ",", "padding", "=", "2", ",", "normalize", "=", "True", ")", "\n", "m", "=", "m", ".", "permute", "(", "1", ",", "2", ",", "0", ")", "\n", "m", "=", "m", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "plt", ".", "imshow", "(", "m", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "m", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "x", "[", "counter", "]", ",", "nrow", "=", "5", ",", "padding", "=", "2", ",", "normalize", "=", "True", ")", "\n", "m", "=", "m", ".", "permute", "(", "1", ",", "2", ",", "0", ")", "\n", "m", "=", "m", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "plt", ".", "imshow", "(", "m", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "m", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "target_map", ",", "nrow", "=", "5", ",", "padding", "=", "2", ")", "\n", "m", "=", "m", ".", "permute", "(", "1", ",", "2", ",", "0", ")", "\n", "m", "=", "m", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "plt", ".", "imshow", "(", "m", ")", "\n", "plt", ".", "title", "(", "\"mix\"", ")", "\n", "plt", ".", "show", "(", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "\n", "", "", "else", ":", "\n", "                    ", "D_fake", ",", "D_real", ",", "G_z", ",", "D_middle_fake", ",", "D_middle_real", "=", "GD", "(", "z_", "[", ":", "batch_size", "]", ",", "y_", "[", ":", "batch_size", "]", ",", "\n", "x", "[", "counter", "]", ",", "y", "[", "counter", "]", ",", "train_G", "=", "False", ",", "\n", "split_D", "=", "config", "[", "'split_D'", "]", ")", "\n", "\n", "\n", "\n", "", "if", "not", "skip_normal_real_fake_loss", ":", "\n", "                    ", "D_loss_real_2d", ",", "D_loss_fake_2d", "=", "discriminator_loss", "(", "D_fake", ".", "view", "(", "-", "1", ")", ",", "D_real", ".", "view", "(", "-", "1", ")", ")", "\n", "D_loss_real_2d_item", "=", "D_loss_real_2d", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "D_loss_fake_2d_item", "=", "D_loss_fake_2d", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "if", "use_mixup_in_this_round", "and", "(", "config", "[", "\"consistency_loss\"", "]", "or", "config", "[", "\"consistency_loss_and_augmentation\"", "]", ")", ":", "\n", "                    ", "mix", "=", "D_real", "*", "target_map", "+", "D_fake", "*", "(", "1", "-", "target_map", ")", "\n", "\n", "", "if", "use_mixup_in_this_round", ":", "\n", "\n", "                    ", "D_mixed_flattened", "=", "D_mixed", ".", "view", "(", "-", "1", ")", "\n", "target_map_flattend", "=", "target_map", ".", "view", "(", "-", "1", ")", "\n", "\n", "mix_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "D_mixed", ".", "size", "(", "0", ")", ")", ":", "\n", "# MIXUP LOSS 2D", "\n", "                        ", "mix2d_i", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "D_mixed", "[", "i", "]", ".", "view", "(", "-", "1", ")", ",", "target_map", "[", "i", "]", ".", "view", "(", "-", "1", ")", ")", "\n", "mix_list", ".", "append", "(", "mix2d_i", ")", "\n", "\n", "", "D_loss_mixed_2d", "=", "torch", ".", "stack", "(", "mix_list", ")", "\n", "#-> D_loss_mixed_2d.mean() is taken later", "\n", "\n", "D_loss_mixed_2d_item", "=", "D_loss_mixed_2d", ".", "mean", "(", ")", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "#D_loss_mixed_2d = D_loss_mixed_2d.view(D_mixed.size()).mean([2,3])", "\n", "\n", "", "if", "not", "skip_normal_real_fake_loss", ":", "\n", "                    ", "D_loss_real_middle", ",", "D_loss_fake_middle", "=", "discriminator_loss", "(", "D_middle_fake", ",", "D_middle_real", ")", "\n", "\n", "D_loss_real_middle_item", "=", "D_loss_real_middle", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "D_loss_fake_middle_item", "=", "D_loss_fake_middle", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "if", "use_mixup_in_this_round", "and", "not", "config", "[", "\"consistency_loss\"", "]", ":", "\n", "# consistency loss is only concerned with segmenter output", "\n", "\n", "#target for mixed encoder loss is fake", "\n", "                    ", "mix_bce", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "D_middle_mixed", ",", "fake_target", ".", "expand_as", "(", "D_middle_mixed", ")", ",", "reduction", "=", "\"none\"", ")", "\n", "\n", "mixed_middle_loss", "=", "mixup_coeff", "*", "mix_bce", "\n", "mixed_middle_loss_item", "=", "mixed_middle_loss", ".", "mean", "(", ")", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "if", "skip_normal_real_fake_loss", ":", "\n", "                    ", "D_loss_real", "=", "torch", ".", "tensor", "(", "[", "0.0", "]", ")", ".", "cuda", "(", ")", "\n", "D_loss_fake", "=", "torch", ".", "tensor", "(", "[", "0.0", "]", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "                    ", "D_loss_real", "=", "D_loss_real_2d", "+", "D_loss_real_middle", "\n", "D_loss_fake", "=", "D_loss_fake_2d", "+", "D_loss_fake_middle", "\n", "\n", "", "D_loss_real_item", "=", "D_loss_real", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "D_loss_fake_item", "=", "D_loss_fake", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "\n", "D_loss", "=", "0.5", "*", "D_loss_real", "+", "0.5", "*", "D_loss_fake", "\n", "\n", "if", "use_mixup_in_this_round", ":", "\n", "                    ", "if", "config", "[", "\"consistency_loss\"", "]", "or", "config", "[", "\"consistency_loss_and_augmentation\"", "]", ":", "\n", "                        ", "consistency_loss", "=", "mixup_coeff", "*", "1.0", "*", "F", ".", "mse_loss", "(", "D_mixed", ",", "mix", ")", "\n", "consistency_loss_item", "=", "consistency_loss", ".", "float", "(", ")", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "if", "not", "config", "[", "\"consistency_loss\"", "]", ":", "\n", "# GAN loss from cutmix augmentation (=/= consitency loss)", "\n", "                        ", "mix_loss", "=", "D_loss_mixed_2d", "+", "mixed_middle_loss", "\n", "mix_loss", "=", "mix_loss", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                        ", "mix_loss", "=", "0.0", "\n", "\n", "", "if", "config", "[", "\"consistency_loss\"", "]", ":", "\n", "                        ", "mix_loss", "=", "consistency_loss", "\n", "", "elif", "config", "[", "\"consistency_loss_and_augmentation\"", "]", ":", "\n", "                        ", "mix_loss", "=", "mix_loss", "+", "consistency_loss", "\n", "\n", "", "D_loss", "=", "D_loss", "+", "mix_loss", "\n", "\n", "", "D_loss", "=", "D_loss", "/", "float", "(", "config", "[", "'num_D_accumulations'", "]", ")", "\n", "\n", "D_loss", ".", "backward", "(", ")", "\n", "counter", "+=", "1", "\n", "\n", "# Optionally apply ortho reg in D", "\n", "", "if", "config", "[", "'D_ortho'", "]", ">", "0.0", ":", "\n", "# Debug print to indicate we're using ortho reg in D.", "\n", "                ", "print", "(", "'using modified ortho reg in D'", ")", "\n", "utils", ".", "ortho", "(", "D", ",", "config", "[", "'D_ortho'", "]", ")", "\n", "\n", "", "D", ".", "optim", ".", "step", "(", ")", "\n", "del", "D_loss", "\n", "\n", "# Optionally toggle \"requires_grad\"", "\n", "", "if", "config", "[", "'toggle_grads'", "]", ":", "\n", "            ", "utils", ".", "toggle_grad", "(", "D", ",", "False", ")", "\n", "utils", ".", "toggle_grad", "(", "G", ",", "True", ")", "\n", "\n", "######################################", "\n", "# G-step", "\n", "######################################", "\n", "# Zero G's gradients by default before training G, for safety", "\n", "", "G", ".", "optim", ".", "zero_grad", "(", ")", "\n", "counter", "=", "0", "\n", "\n", "z_", ".", "sample_", "(", ")", "\n", "y_", ".", "sample_", "(", ")", "\n", "\n", "z__", "=", "torch", ".", "split", "(", "z_", ",", "split_size", ")", "#batch_size)", "\n", "y__", "=", "torch", ".", "split", "(", "y_", ",", "split_size", ")", "#batch_size)", "\n", "\n", "# If accumulating gradients, loop multiple times", "\n", "for", "accumulation_index", "in", "range", "(", "config", "[", "'num_G_accumulations'", "]", ")", ":", "\n", "\n", "            ", "G_fake", ",", "G_fake_middle", "=", "GD", "(", "z__", "[", "counter", "]", ",", "y__", "[", "counter", "]", ",", "train_G", "=", "True", ",", "split_D", "=", "config", "[", "'split_D'", "]", ",", "reference_x", "=", "x", "[", "counter", "]", ")", "\n", "\n", "G_loss_fake_2d", "=", "fake_loss", "(", "G_fake", ")", "\n", "G_loss_fake_middle", "=", "fake_loss", "(", "G_fake_middle", ")", "\n", "G_loss", "=", "0.5", "*", "G_loss_fake_middle", "+", "0.5", "*", "G_loss_fake_2d", "\n", "G_loss", "=", "G_loss", "/", "float", "(", "config", "[", "'num_G_accumulations'", "]", ")", "\n", "\n", "G_loss_fake_middle_item", "=", "G_loss_fake_middle", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "G_loss_fake_2d_item", "=", "G_loss_fake_2d", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "G_loss_item", "=", "G_loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "\n", "G_loss", ".", "backward", "(", ")", "\n", "counter", "+=", "1", "\n", "\n", "# Optionally apply modified ortho reg in G", "\n", "", "if", "config", "[", "'G_ortho'", "]", ">", "0.0", ":", "\n", "            ", "print", "(", "'using modified ortho reg in G'", ")", "# Debug print to indicate we're using ortho reg in G", "\n", "# Don't ortho reg shared, it makes no sense. Really we should blacklist any embeddings for this", "\n", "utils", ".", "ortho", "(", "G", ",", "config", "[", "'G_ortho'", "]", ",", "\n", "blacklist", "=", "[", "param", "for", "param", "in", "G", ".", "shared", ".", "parameters", "(", ")", "]", ")", "\n", "\n", "\n", "", "G", ".", "optim", ".", "step", "(", ")", "\n", "del", "G_loss", "\n", "\n", "# If we have an ema, update it, regardless of if we test with it or not", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "            ", "ema", ".", "update", "(", "state_dict", "[", "'itr'", "]", ")", "\n", "\n", "\n", "# save intermediate losses", "\n", "", "if", "use_mixup_in_this_round", "and", "(", "config", "[", "\"consistency_loss\"", "]", "or", "config", "[", "\"consistency_loss_and_augmentation\"", "]", ")", "and", "config", "[", "\"num_D_steps\"", "]", ">", "0", ":", "\n", "            ", "out", "[", "\"consistency\"", "]", "=", "float", "(", "consistency_loss_item", ")", "\n", "\n", "", "out", "[", "'G_loss'", "]", "=", "float", "(", "G_loss_item", ")", "\n", "if", "not", "(", "config", "[", "\"full_batch_mixup\"", "]", "and", "use_mixup_in_this_round", ")", "and", "config", "[", "\"num_D_steps\"", "]", ">", "0", ":", "\n", "            ", "out", "[", "'D_loss_real'", "]", "=", "float", "(", "D_loss_real_item", ")", "\n", "out", "[", "'D_loss_fake'", "]", "=", "float", "(", "D_loss_fake_item", ")", "\n", "\n", "", "if", "use_mixup_in_this_round", "and", "not", "config", "[", "\"consistency_loss\"", "]", "and", "config", "[", "\"num_D_steps\"", "]", ">", "0", ":", "\n", "            ", "out", "[", "\"mixed_middle_loss\"", "]", "=", "float", "(", "mixed_middle_loss_item", ")", "\n", "out", "[", "\"D_loss_mixed_2d\"", "]", "=", "float", "(", "D_loss_mixed_2d_item", ")", "\n", "\n", "", "if", "not", "(", "config", "[", "\"full_batch_mixup\"", "]", "and", "use_mixup_in_this_round", ")", ":", "\n", "            ", "if", "config", "[", "\"num_D_steps\"", "]", ">", "0", ":", "\n", "                ", "out", "[", "\"D_loss_real_middle\"", "]", "=", "float", "(", "D_loss_real_middle_item", ")", "\n", "out", "[", "\"D_loss_fake_middle\"", "]", "=", "float", "(", "D_loss_fake_middle_item", ")", "\n", "out", "[", "\"D_loss_real_2d\"", "]", "=", "float", "(", "D_loss_real_2d_item", ")", "\n", "out", "[", "\"D_loss_fake_2d\"", "]", "=", "float", "(", "D_loss_fake_2d_item", ")", "\n", "", "out", "[", "\"G_loss_fake_middle\"", "]", "=", "float", "(", "G_loss_fake_middle_item", ")", "\n", "out", "[", "\"G_loss_fake_2d\"", "]", "=", "float", "(", "G_loss_fake_2d_item", ")", "\n", "\n", "", "return", "out", "\n", "", "return", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train_fns.save_and_sample": [[301, 427], ["utils.save_weights", "utils.save_weights", "print", "utils.accumulate_standing_stats", "torch.no_grad", "torch.no_grad", "torch.no_grad", "os.path.isdir", "os.mkdir", "torchvision.utils.save_image", "torch.no_grad", "torch.no_grad", "torch.no_grad", "D", "torch.sigmoid", "torch.sigmoid", "F.sigmoid.mean", "s.view.view", "c.view.view", "torch.cat", "torch.cat", "torch.cat", "cs.round.cpu().numpy", "cs.round.round", "range", "torchvision.utils.save_image", "utils.sample_sheet", "which_G.float().cpu", "F.sigmoid.clone", "F.sigmoid.clone", "s_fake.view.view", "s_real.view.view", "torch.cat", "torch.cat", "torch.cat", "cs_real.round.cpu().numpy", "cs_real.round.round", "torch.cat", "torch.cat", "torch.cat", "cs_fake.round.cpu().numpy", "cs_fake.round.round", "torch.cat", "torch.cat", "torch.cat", "cs_mix.round.cpu().numpy", "cs_mix.round.round", "F.sigmoid.size", "F.sigmoid.float().cpu", "zip", "torch.parallel.data_parallel", "which_G", "int", "c.view.view", "s.view.view", "cs.round.cpu", "s_real.view.sum", "target_map.sum", "s_fake.view.sum", "D_map[].min", "D_map[].max", "int", "utils.interp_sheet", "which_G.shared", "which_G.float", "c.view.size", "s.view.size", "c.view.view", "s_real.view.view", "cs_real.round.cpu", "c.view.view", "s_fake.view.view", "cs_fake.round.cpu", "c.view.view", "s_real.view.view", "s_fake.view.view", "cs_mix.round.cpu", "F.sigmoid.float", "which_G.shared", "c.view.size", "s_real.view.size", "c.view.size", "s_fake.view.size", "c.view.size", "s_real.view.size", "s_fake.view.size"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.save_weights", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.save_weights", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.accumulate_standing_stats", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.sample_sheet", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.interp_sheet"], ["def", "save_and_sample", "(", "G", ",", "D", ",", "G_ema", ",", "z_", ",", "y_", ",", "fixed_z", ",", "fixed_y", ",", "\n", "state_dict", ",", "config", ",", "experiment_name", ",", "sample_only", "=", "False", ",", "use_real", "=", "False", ",", "real_batch", "=", "None", ",", "\n", "id", "=", "\"\"", ",", "mixed", "=", "False", ",", "target_map", "=", "None", ")", ":", "\n", "    ", "if", "not", "sample_only", ":", "\n", "        ", "utils", ".", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "experiment_name", ",", "None", ",", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "# Save an additional copy to mitigate accidental corruption if process", "\n", "# is killed during a save (it's happened to me before -.-)", "\n", "if", "config", "[", "'num_save_copies'", "]", ">", "0", ":", "\n", "            ", "utils", ".", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "experiment_name", ",", "\n", "'copy%d'", "%", "state_dict", "[", "'save_num'", "]", ",", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "state_dict", "[", "'save_num'", "]", "=", "(", "state_dict", "[", "'save_num'", "]", "+", "1", ")", "%", "config", "[", "'num_save_copies'", "]", "\n", "", "", "else", ":", "\n", "# Use EMA G for samples or non-EMA?", "\n", "        ", "which_G", "=", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", "\n", "\n", "# Accumulate standing statistics?", "\n", "if", "config", "[", "'accumulate_stats'", "]", ":", "\n", "            ", "print", "(", "\"accumulating stats!\"", ")", "\n", "utils", ".", "accumulate_standing_stats", "(", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", ",", "\n", "z_", ",", "y_", ",", "config", "[", "'n_classes'", "]", ",", "\n", "config", "[", "'num_standing_accumulations'", "]", ")", "\n", "\n", "# Save a random sample sheet with fixed z and y", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "use_real", ":", "\n", "                ", "fixed_Gz", "=", "real_batch", "\n", "experiment_name", "+=", "\"_real\"", "\n", "", "else", ":", "\n", "                ", "if", "config", "[", "'parallel'", "]", ":", "\n", "                    ", "fixed_Gz", "=", "nn", ".", "parallel", ".", "data_parallel", "(", "which_G", ",", "(", "fixed_z", ",", "which_G", ".", "shared", "(", "fixed_y", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "fixed_Gz", "=", "which_G", "(", "fixed_z", ",", "which_G", ".", "shared", "(", "fixed_y", ")", ")", "\n", "\n", "\n", "", "", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "'%s/%s'", "%", "(", "config", "[", "'samples_root'", "]", ",", "experiment_name", ")", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "'%s/%s'", "%", "(", "config", "[", "'samples_root'", "]", ",", "experiment_name", ")", ")", "\n", "", "image_filename", "=", "'%s/%s/fixed_samples%d'", "%", "(", "config", "[", "'samples_root'", "]", ",", "experiment_name", ",", "state_dict", "[", "'itr'", "]", ")", "\n", "image_filename", "+=", "id", "+", "\".jpg\"", "\n", "\n", "if", "not", "(", "state_dict", "[", "\"itr\"", "]", ">", "config", "[", "\"sample_every\"", "]", "and", "use_real", "and", "not", "mixed", ")", ":", "\n", "            ", "torchvision", ".", "utils", ".", "save_image", "(", "fixed_Gz", ".", "float", "(", ")", ".", "cpu", "(", ")", ",", "image_filename", ",", "\n", "nrow", "=", "int", "(", "fixed_Gz", ".", "shape", "[", "0", "]", "**", "0.5", ")", ",", "normalize", "=", "True", ")", "\n", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "D_map", ",", "c", "=", "D", "(", "fixed_Gz", ",", "fixed_y", ")", "\n", "D_map", "=", "F", ".", "sigmoid", "(", "D_map", ")", "\n", "c", "=", "F", ".", "sigmoid", "(", "c", ")", "\n", "\n", "s", "=", "D_map", ".", "mean", "(", "[", "2", ",", "3", "]", ")", "\n", "s", "=", "s", ".", "view", "(", "-", "1", ")", "\n", "c", "=", "c", ".", "view", "(", "-", "1", ")", "\n", "cs", "=", "torch", ".", "cat", "(", "(", "c", ".", "view", "(", "c", ".", "size", "(", "0", ")", ",", "1", ")", ",", "s", ".", "view", "(", "s", ".", "size", "(", "0", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "cs", "=", "cs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "cs", "=", "cs", ".", "round", "(", "3", ")", "\n", "if", "mixed", ":", "\n", "                ", "s_real", "=", "D_map", ".", "clone", "(", ")", "\n", "s_real", "=", "s_real", "*", "target_map", "# all fakes are zero now", "\n", "s_real", "=", "s_real", ".", "sum", "(", "[", "2", ",", "3", "]", ")", "/", "target_map", ".", "sum", "(", "[", "2", ",", "3", "]", ")", "\n", "\n", "s_fake", "=", "D_map", ".", "clone", "(", ")", "\n", "s_fake", "=", "s_fake", "*", "(", "1", "-", "target_map", ")", "# all real are zero now", "\n", "s_fake", "=", "s_fake", ".", "sum", "(", "[", "2", ",", "3", "]", ")", "/", "(", "1", "-", "target_map", ")", ".", "sum", "(", "[", "2", ",", "3", "]", ")", "\n", "\n", "s_fake", "=", "s_fake", ".", "view", "(", "-", "1", ")", "\n", "s_real", "=", "s_real", ".", "view", "(", "-", "1", ")", "\n", "\n", "cs_real", "=", "torch", ".", "cat", "(", "(", "c", ".", "view", "(", "c", ".", "size", "(", "0", ")", ",", "1", ")", ",", "s_real", ".", "view", "(", "s_real", ".", "size", "(", "0", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "cs_real", "=", "cs_real", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "cs_real", "=", "cs_real", ".", "round", "(", "3", ")", "\n", "\n", "cs_fake", "=", "torch", ".", "cat", "(", "(", "c", ".", "view", "(", "c", ".", "size", "(", "0", ")", ",", "1", ")", ",", "s_fake", ".", "view", "(", "s_fake", ".", "size", "(", "0", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "cs_fake", "=", "cs_fake", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "cs_fake", "=", "cs_fake", ".", "round", "(", "3", ")", "\n", "\n", "cs_mix", "=", "torch", ".", "cat", "(", "(", "c", ".", "view", "(", "c", ".", "size", "(", "0", ")", ",", "1", ")", ",", "s_real", ".", "view", "(", "s_real", ".", "size", "(", "0", ")", ",", "1", ")", ",", "s_fake", ".", "view", "(", "s_fake", ".", "size", "(", "0", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "cs_mix", "=", "cs_mix", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "cs_mix", "=", "cs_mix", ".", "round", "(", "3", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "D_map", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "D_map", "[", "i", "]", "=", "D_map", "[", "i", "]", "-", "D_map", "[", "i", "]", ".", "min", "(", ")", "\n", "D_map", "[", "i", "]", "=", "D_map", "[", "i", "]", "/", "D_map", "[", "i", "]", ".", "max", "(", ")", "\n", "\n", "", "image_filename", "=", "'%s/%s/fixed_samples_D%d'", "%", "(", "config", "[", "'samples_root'", "]", ",", "experiment_name", ",", "state_dict", "[", "'itr'", "]", ")", "\n", "image_filename", "+=", "id", "+", "\".jpg\"", "\n", "torchvision", ".", "utils", ".", "save_image", "(", "D_map", ".", "float", "(", ")", ".", "cpu", "(", ")", ",", "image_filename", ",", "\n", "nrow", "=", "int", "(", "fixed_Gz", ".", "shape", "[", "0", "]", "**", "0.5", ")", ",", "normalize", "=", "False", ")", "\n", "\n", "\n", "", "if", "config", "[", "\"resolution\"", "]", "==", "128", ":", "\n", "            ", "num_per_sheet", "=", "16", "\n", "num_midpoints", "=", "8", "\n", "", "elif", "config", "[", "\"resolution\"", "]", "==", "256", ":", "\n", "            ", "num_per_sheet", "=", "8", "\n", "num_midpoints", "=", "4", "\n", "", "elif", "config", "[", "\"resolution\"", "]", "==", "64", ":", "\n", "            ", "num_per_sheet", "=", "32", "\n", "num_midpoints", "=", "16", "\n", "\n", "", "if", "not", "use_real", ":", "\n", "# For now, every time we save, also save sample sheets", "\n", "            ", "utils", ".", "sample_sheet", "(", "which_G", ",", "\n", "classes_per_sheet", "=", "utils", ".", "classes_per_sheet_dict", "[", "config", "[", "'dataset'", "]", "]", ",", "\n", "num_classes", "=", "config", "[", "'n_classes'", "]", ",", "\n", "samples_per_class", "=", "10", ",", "parallel", "=", "config", "[", "'parallel'", "]", ",", "\n", "samples_root", "=", "config", "[", "'samples_root'", "]", ",", "\n", "experiment_name", "=", "experiment_name", ",", "\n", "folder_number", "=", "state_dict", "[", "'itr'", "]", ",", "\n", "z_", "=", "z_", ")", "\n", "# Also save interp sheets", "\n", "if", "config", "[", "\"dataset\"", "]", "==", "\"coco\"", ":", "\n", "                ", "for", "fix_z", ",", "fix_y", "in", "zip", "(", "[", "False", ",", "False", ",", "True", "]", ",", "[", "False", ",", "True", ",", "False", "]", ")", ":", "\n", "                    ", "utils", ".", "interp_sheet", "(", "which_G", ",", "\n", "num_per_sheet", "=", "num_per_sheet", ",", "\n", "num_midpoints", "=", "num_midpoints", ",", "\n", "num_classes", "=", "config", "[", "'n_classes'", "]", ",", "\n", "parallel", "=", "config", "[", "'parallel'", "]", ",", "\n", "samples_root", "=", "config", "[", "'samples_root'", "]", ",", "\n", "experiment_name", "=", "experiment_name", ",", "\n", "folder_number", "=", "state_dict", "[", "'itr'", "]", ",", "\n", "sheet_number", "=", "0", ",", "\n", "fix_z", "=", "fix_z", ",", "fix_y", "=", "fix_y", ",", "device", "=", "'cuda'", ",", "config", "=", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train_fns.test": [[433, 472], ["print", "get_inception_metrics", "print", "utils.accumulate_standing_stats", "max", "min", "test_log.log", "print", "utils.save_weights", "max", "min", "test_log.log", "int", "float", "float", "float", "print", "utils.save_weights", "int", "float", "float", "float"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.accumulate_standing_stats", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.save_weights", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.save_weights"], ["def", "test", "(", "G", ",", "D", ",", "G_ema", ",", "z_", ",", "y_", ",", "state_dict", ",", "config", ",", "sample", ",", "get_inception_metrics", ",", "\n", "experiment_name", ",", "test_log", ",", "moments", "=", "\"train\"", ")", ":", "\n", "    ", "print", "(", "'Gathering inception metrics...'", ")", "\n", "if", "config", "[", "'accumulate_stats'", "]", ":", "\n", "        ", "utils", ".", "accumulate_standing_stats", "(", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", ",", "\n", "z_", ",", "y_", ",", "config", "[", "'n_classes'", "]", ",", "\n", "config", "[", "'num_standing_accumulations'", "]", ")", "\n", "", "IS_mean", ",", "IS_std", ",", "FID", "=", "get_inception_metrics", "(", "sample", ",", "config", "[", "'num_inception_images'", "]", ",", "num_splits", "=", "10", ")", "\n", "print", "(", "'Itr %d: PYTORCH UNOFFICIAL Inception Score is %3.3f +/- %3.3f, PYTORCH UNOFFICIAL FID is %5.4f'", "%", "(", "state_dict", "[", "'itr'", "]", ",", "IS_mean", ",", "IS_std", ",", "FID", ")", ")", "\n", "# If improved over previous best metric, save approrpiate copy", "\n", "if", "moments", "==", "\"train\"", ":", "\n", "        ", "if", "(", "(", "config", "[", "'which_best'", "]", "==", "'IS'", "and", "IS_mean", ">", "state_dict", "[", "'best_IS'", "]", ")", "\n", "or", "(", "config", "[", "'which_best'", "]", "==", "'FID'", "and", "FID", "<", "state_dict", "[", "'best_FID'", "]", ")", ")", ":", "\n", "            ", "print", "(", "'%s improved over previous best, saving checkpoint...'", "%", "config", "[", "'which_best'", "]", ")", "\n", "utils", ".", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "experiment_name", ",", "'tr_best%d'", "%", "state_dict", "[", "'save_best_num'", "]", ",", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "state_dict", "[", "'save_best_num'", "]", "=", "(", "state_dict", "[", "'save_best_num'", "]", "+", "1", ")", "%", "config", "[", "'num_best_copies'", "]", "\n", "", "state_dict", "[", "'best_IS'", "]", "=", "max", "(", "state_dict", "[", "'best_IS'", "]", ",", "IS_mean", ")", "\n", "state_dict", "[", "'best_FID'", "]", "=", "min", "(", "state_dict", "[", "'best_FID'", "]", ",", "FID", ")", "\n", "# Log results to file", "\n", "test_log", ".", "log", "(", "itr", "=", "int", "(", "state_dict", "[", "'itr'", "]", ")", ",", "IS_mean", "=", "float", "(", "IS_mean", ")", ",", "\n", "IS_std", "=", "float", "(", "IS_std", ")", ",", "FID", "=", "float", "(", "FID", ")", ")", "\n", "", "elif", "moments", "==", "\"test\"", ":", "\n", "        ", "if", "(", "(", "config", "[", "'which_best'", "]", "==", "'IS'", "and", "IS_mean", ">", "state_dict", "[", "'best_IS_test'", "]", ")", "\n", "or", "(", "config", "[", "'which_best'", "]", "==", "'FID'", "and", "FID", "<", "state_dict", "[", "'best_FID_test'", "]", ")", ")", ":", "\n", "            ", "print", "(", "'%s improved over previous best, saving checkpoint...'", "%", "config", "[", "'which_best'", "]", ")", "\n", "utils", ".", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "config", "[", "'weights_root'", "]", ",", "\n", "experiment_name", ",", "'te_best%d'", "%", "state_dict", "[", "'save_best_num'", "]", ",", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "\n", "state_dict", "[", "'save_best_num'", "]", "=", "(", "state_dict", "[", "'save_best_num'", "]", "+", "1", ")", "%", "config", "[", "'num_best_copies'", "]", "\n", "", "state_dict", "[", "'best_IS_test'", "]", "=", "max", "(", "state_dict", "[", "'best_IS_test'", "]", ",", "IS_mean", ")", "\n", "state_dict", "[", "'best_FID_test'", "]", "=", "min", "(", "state_dict", "[", "'best_FID_test'", "]", ",", "FID", ")", "\n", "# Log results to file", "\n", "test_log", ".", "log", "(", "itr", "=", "int", "(", "state_dict", "[", "'itr'", "]", ")", ",", "IS_mean_test", "=", "float", "(", "IS_mean", ")", ",", "\n", "IS_std_test", "=", "float", "(", "IS_std", ")", ",", "FID_test", "=", "float", "(", "FID", ")", ")", "\n", "\n", "", "return", "IS_mean", ",", "IS_std", ",", "FID", "\n", "", ""]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.BigGAN.Generator.__init__": [[43, 207], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Module.__init__", "functools.partial", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "BigGAN.G_arch", "functools.partial", "functools.partial", "functools.partial", "BigGAN.Generator.which_embedding", "layers.identity", "BigGAN.Generator.which_linear", "BigGAN.Generator.which_linear", "len", "layers.bn", "BigGAN.Generator.which_conv", "BigGAN.Generator.init_weights", "print", "utils.Adam16", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "len", "functools.partial", "print", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "layers.GBlock", "layers.Attention", "BigGAN.Generator.parameters", "BigGAN.Generator.parameters", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.BigGAN.G_arch", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.BigGAN.Unet_Discriminator.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "G_ch", "=", "64", ",", "dim_z", "=", "128", ",", "bottom_width", "=", "4", ",", "resolution", "=", "128", ",", "\n", "G_kernel_size", "=", "3", ",", "G_attn", "=", "'64'", ",", "n_classes", "=", "1000", ",", "\n", "num_G_SVs", "=", "1", ",", "num_G_SV_itrs", "=", "1", ",", "\n", "G_shared", "=", "True", ",", "shared_dim", "=", "0", ",", "hier", "=", "False", ",", "\n", "cross_replica", "=", "False", ",", "mybn", "=", "False", ",", "\n", "G_activation", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", ",", "\n", "G_lr", "=", "5e-5", ",", "G_B1", "=", "0.0", ",", "G_B2", "=", "0.999", ",", "adam_eps", "=", "1e-8", ",", "\n", "BN_eps", "=", "1e-5", ",", "SN_eps", "=", "1e-12", ",", "G_mixed_precision", "=", "False", ",", "G_fp16", "=", "False", ",", "\n", "G_init", "=", "'ortho'", ",", "skip_init", "=", "False", ",", "no_optim", "=", "False", ",", "\n", "G_param", "=", "'SN'", ",", "norm_style", "=", "'bn'", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Channel width mulitplier", "\n", "self", ".", "ch", "=", "G_ch", "\n", "# Dimensionality of the latent space", "\n", "self", ".", "dim_z", "=", "dim_z", "\n", "# The initial spatial dimensions", "\n", "self", ".", "bottom_width", "=", "bottom_width", "\n", "# Resolution of the output", "\n", "self", ".", "resolution", "=", "resolution", "\n", "# Kernel size?", "\n", "self", ".", "kernel_size", "=", "G_kernel_size", "\n", "# Attention?", "\n", "self", ".", "attention", "=", "G_attn", "\n", "# number of classes, for use in categorical conditional generation", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "# Use shared embeddings?", "\n", "self", ".", "G_shared", "=", "G_shared", "\n", "# Dimensionality of the shared embedding? Unused if not using G_shared", "\n", "self", ".", "shared_dim", "=", "shared_dim", "if", "shared_dim", ">", "0", "else", "dim_z", "\n", "# Hierarchical latent space?", "\n", "self", ".", "hier", "=", "hier", "\n", "# Cross replica batchnorm?", "\n", "self", ".", "cross_replica", "=", "cross_replica", "\n", "# Use my batchnorm?", "\n", "self", ".", "mybn", "=", "mybn", "\n", "# nonlinearity for residual blocks", "\n", "self", ".", "activation", "=", "G_activation", "\n", "# Initialization style", "\n", "self", ".", "init", "=", "G_init", "\n", "# Parameterization style", "\n", "self", ".", "G_param", "=", "G_param", "\n", "# Normalization style", "\n", "self", ".", "norm_style", "=", "norm_style", "\n", "# Epsilon for BatchNorm?", "\n", "self", ".", "BN_eps", "=", "BN_eps", "\n", "# Epsilon for Spectral Norm?", "\n", "self", ".", "SN_eps", "=", "SN_eps", "\n", "# fp16?", "\n", "self", ".", "fp16", "=", "G_fp16", "\n", "# Architecture dict", "\n", "self", ".", "arch", "=", "G_arch", "(", "self", ".", "ch", ",", "self", ".", "attention", ")", "[", "resolution", "]", "\n", "\n", "self", ".", "unconditional", "=", "kwargs", "[", "\"unconditional\"", "]", "\n", "\n", "# If using hierarchical latents, adjust z", "\n", "if", "self", ".", "hier", ":", "\n", "# Number of places z slots into", "\n", "            ", "self", ".", "num_slots", "=", "len", "(", "self", ".", "arch", "[", "'in_channels'", "]", ")", "+", "1", "\n", "self", ".", "z_chunk_size", "=", "(", "self", ".", "dim_z", "//", "self", ".", "num_slots", ")", "\n", "\n", "if", "not", "self", ".", "unconditional", ":", "\n", "                ", "self", ".", "dim_z", "=", "self", ".", "z_chunk_size", "*", "self", ".", "num_slots", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "num_slots", "=", "1", "\n", "self", ".", "z_chunk_size", "=", "0", "\n", "\n", "# Which convs, batchnorms, and linear layers to use", "\n", "", "if", "self", ".", "G_param", "==", "'SN'", ":", "\n", "            ", "self", ".", "which_conv", "=", "functools", ".", "partial", "(", "layers", ".", "SNConv2d", ",", "\n", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "\n", "num_svs", "=", "num_G_SVs", ",", "num_itrs", "=", "num_G_SV_itrs", ",", "\n", "eps", "=", "self", ".", "SN_eps", ")", "\n", "self", ".", "which_linear", "=", "functools", ".", "partial", "(", "layers", ".", "SNLinear", ",", "\n", "num_svs", "=", "num_G_SVs", ",", "num_itrs", "=", "num_G_SV_itrs", ",", "\n", "eps", "=", "self", ".", "SN_eps", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "which_conv", "=", "functools", ".", "partial", "(", "nn", ".", "Conv2d", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "which_linear", "=", "nn", ".", "Linear", "\n", "\n", "# We use a non-spectral-normed embedding here regardless;", "\n", "# For some reason applying SN to G's embedding seems to randomly cripple G", "\n", "", "self", ".", "which_embedding", "=", "nn", ".", "Embedding", "\n", "\n", "if", "self", ".", "unconditional", ":", "\n", "            ", "bn_linear", "=", "nn", ".", "Linear", "\n", "input_size", "=", "self", ".", "dim_z", "+", "(", "self", ".", "shared_dim", "if", "self", ".", "G_shared", "else", "0", ")", "\n", "", "else", ":", "\n", "            ", "bn_linear", "=", "(", "functools", ".", "partial", "(", "self", ".", "which_linear", ",", "bias", "=", "False", ")", "if", "self", ".", "G_shared", "\n", "else", "self", ".", "which_embedding", ")", "\n", "\n", "input_size", "=", "(", "self", ".", "shared_dim", "+", "self", ".", "z_chunk_size", "if", "self", ".", "G_shared", "\n", "else", "self", ".", "n_classes", ")", "\n", "", "self", ".", "which_bn", "=", "functools", ".", "partial", "(", "layers", ".", "ccbn", ",", "\n", "which_linear", "=", "bn_linear", ",", "\n", "cross_replica", "=", "self", ".", "cross_replica", ",", "\n", "mybn", "=", "self", ".", "mybn", ",", "\n", "input_size", "=", "input_size", ",", "\n", "norm_style", "=", "self", ".", "norm_style", ",", "\n", "eps", "=", "self", ".", "BN_eps", ",", "\n", "self_modulation", "=", "self", ".", "unconditional", ")", "\n", "\n", "\n", "# Prepare model", "\n", "# If not using shared embeddings, self.shared is just a passthrough", "\n", "self", ".", "shared", "=", "(", "self", ".", "which_embedding", "(", "n_classes", ",", "self", ".", "shared_dim", ")", "if", "G_shared", "\n", "else", "layers", ".", "identity", "(", ")", ")", "\n", "# First linear layer", "\n", "if", "self", ".", "unconditional", ":", "\n", "            ", "self", ".", "linear", "=", "self", ".", "which_linear", "(", "self", ".", "dim_z", ",", "self", ".", "arch", "[", "'in_channels'", "]", "[", "0", "]", "*", "(", "self", ".", "bottom_width", "**", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "linear", "=", "self", ".", "which_linear", "(", "self", ".", "dim_z", "//", "self", ".", "num_slots", ",", "\n", "self", ".", "arch", "[", "'in_channels'", "]", "[", "0", "]", "*", "(", "self", ".", "bottom_width", "**", "2", ")", ")", "\n", "\n", "# self.blocks is a doubly-nested list of modules, the outer loop intended", "\n", "# to be over blocks at a given resolution (resblocks and/or self-attention)", "\n", "# while the inner loop is over a given block", "\n", "", "self", ".", "blocks", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "len", "(", "self", ".", "arch", "[", "'out_channels'", "]", ")", ")", ":", "\n", "\n", "\n", "            ", "self", ".", "blocks", "+=", "[", "[", "layers", ".", "GBlock", "(", "in_channels", "=", "self", ".", "arch", "[", "'in_channels'", "]", "[", "index", "]", ",", "\n", "out_channels", "=", "self", ".", "arch", "[", "'out_channels'", "]", "[", "index", "]", ",", "\n", "which_conv", "=", "self", ".", "which_conv", ",", "\n", "which_bn", "=", "self", ".", "which_bn", ",", "\n", "activation", "=", "self", ".", "activation", ",", "\n", "upsample", "=", "(", "functools", ".", "partial", "(", "F", ".", "interpolate", ",", "scale_factor", "=", "2", ")", "\n", "if", "self", ".", "arch", "[", "'upsample'", "]", "[", "index", "]", "else", "None", ")", ")", "]", "]", "\n", "\n", "# If attention on this block, attach it to the end", "\n", "if", "self", ".", "arch", "[", "'attention'", "]", "[", "self", ".", "arch", "[", "'resolution'", "]", "[", "index", "]", "]", ":", "\n", "                ", "print", "(", "'Adding attention layer in G at resolution %d'", "%", "self", ".", "arch", "[", "'resolution'", "]", "[", "index", "]", ")", "\n", "self", ".", "blocks", "[", "-", "1", "]", "+=", "[", "layers", ".", "Attention", "(", "self", ".", "arch", "[", "'out_channels'", "]", "[", "index", "]", ",", "self", ".", "which_conv", ")", "]", "\n", "\n", "# Turn self.blocks into a ModuleList so that it's all properly registered.", "\n", "", "", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "ModuleList", "(", "block", ")", "for", "block", "in", "self", ".", "blocks", "]", ")", "\n", "\n", "# output layer: batchnorm-relu-conv.", "\n", "# Consider using a non-spectral conv here", "\n", "self", ".", "output_layer", "=", "nn", ".", "Sequential", "(", "layers", ".", "bn", "(", "self", ".", "arch", "[", "'out_channels'", "]", "[", "-", "1", "]", ",", "\n", "cross_replica", "=", "self", ".", "cross_replica", ",", "\n", "mybn", "=", "self", ".", "mybn", ")", ",", "\n", "self", ".", "activation", ",", "\n", "self", ".", "which_conv", "(", "self", ".", "arch", "[", "'out_channels'", "]", "[", "-", "1", "]", ",", "3", ")", ")", "\n", "\n", "# Initialize weights. Optionally skip init for testing.", "\n", "if", "not", "skip_init", ":", "\n", "            ", "self", ".", "init_weights", "(", ")", "\n", "\n", "# Set up optimizer", "\n", "# If this is an EMA copy, no need for an optim, so just return now", "\n", "", "if", "no_optim", ":", "\n", "            ", "return", "\n", "", "self", ".", "lr", ",", "self", ".", "B1", ",", "self", ".", "B2", ",", "self", ".", "adam_eps", "=", "G_lr", ",", "G_B1", ",", "G_B2", ",", "adam_eps", "\n", "if", "G_mixed_precision", ":", "\n", "            ", "print", "(", "'Using fp16 adam in G...'", ")", "\n", "import", "utils", "\n", "self", ".", "optim", "=", "utils", ".", "Adam16", "(", "params", "=", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "\n", "betas", "=", "(", "self", ".", "B1", ",", "self", ".", "B2", ")", ",", "weight_decay", "=", "0", ",", "\n", "eps", "=", "self", ".", "adam_eps", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "optim", "=", "optim", ".", "Adam", "(", "params", "=", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "\n", "betas", "=", "(", "self", ".", "B1", ",", "self", ".", "B2", ")", ",", "weight_decay", "=", "0", ",", "\n", "eps", "=", "self", ".", "adam_eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.BigGAN.Generator.init_weights": [[213, 229], ["BigGAN.Generator.modules", "print", "isinstance", "isinstance", "isinstance", "sum", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "p.data.nelement", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "print", "module.parameters"], "methods", ["None"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "self", ".", "param_count", "=", "0", "\n", "for", "module", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "(", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", "\n", "or", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "\n", "or", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "                ", "if", "self", ".", "init", "==", "'ortho'", ":", "\n", "                    ", "init", ".", "orthogonal_", "(", "module", ".", "weight", ")", "\n", "", "elif", "self", ".", "init", "==", "'N02'", ":", "\n", "                    ", "init", ".", "normal_", "(", "module", ".", "weight", ",", "0", ",", "0.02", ")", "\n", "", "elif", "self", ".", "init", "in", "[", "'glorot'", ",", "'xavier'", "]", ":", "\n", "                    ", "init", ".", "xavier_uniform_", "(", "module", ".", "weight", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'Init style not recognized...'", ")", "\n", "", "self", ".", "param_count", "+=", "sum", "(", "[", "p", ".", "data", ".", "nelement", "(", ")", "for", "p", "in", "module", ".", "parameters", "(", ")", "]", ")", "\n", "", "", "print", "(", "'Param count for G'", "'s initialized parameters: %d'", "%", "self", ".", "param_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.BigGAN.Generator.forward": [[234, 264], ["BigGAN.Generator.linear", "block.view", "enumerate", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "block.size", "BigGAN.Generator.output_layer", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "block", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "len", "range"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "z", ",", "y", ")", ":", "\n", "# If hierarchical, concatenate zs and ys", "\n", "        ", "if", "self", ".", "hier", ":", "\n", "# faces", "\n", "            ", "if", "self", ".", "unconditional", ":", "\n", "                ", "ys", "=", "[", "z", "for", "_", "in", "range", "(", "self", ".", "num_slots", ")", "]", "\n", "", "else", ":", "\n", "                ", "zs", "=", "torch", ".", "split", "(", "z", ",", "self", ".", "z_chunk_size", ",", "1", ")", "\n", "z", "=", "zs", "[", "0", "]", "\n", "\n", "ys", "=", "[", "torch", ".", "cat", "(", "[", "y", ",", "item", "]", ",", "1", ")", "for", "item", "in", "zs", "[", "1", ":", "]", "]", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "unconditional", ":", "\n", "                ", "ys", "=", "[", "None", "]", "*", "len", "(", "self", ".", "blocks", ")", "\n", "", "else", ":", "\n", "                ", "ys", "=", "[", "y", "]", "*", "len", "(", "self", ".", "blocks", ")", "\n", "\n", "# First linear layer", "\n", "", "", "h", "=", "self", ".", "linear", "(", "z", ")", "\n", "# Reshape", "\n", "h", "=", "h", ".", "view", "(", "h", ".", "size", "(", "0", ")", ",", "-", "1", ",", "self", ".", "bottom_width", ",", "self", ".", "bottom_width", ")", "\n", "\n", "# Loop over blocks", "\n", "for", "index", ",", "blocklist", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "# Second inner loop in case block has multiple layers", "\n", "            ", "for", "block", "in", "blocklist", ":", "\n", "                ", "h", "=", "block", "(", "h", ",", "ys", "[", "index", "]", ")", "\n", "\n", "# Apply batchnorm-relu-conv-tanh at output", "\n", "", "", "return", "torch", ".", "tanh", "(", "self", ".", "output_layer", "(", "h", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.BigGAN.Unet_Discriminator.__init__": [[315, 448], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "BigGAN.Unet_Discriminator.blocks.append", "BigGAN.Unet_Discriminator.which_linear", "BigGAN.Unet_Discriminator.which_linear", "print", "BigGAN.Unet_Discriminator.named_parameters", "BigGAN.D_unet_arch", "functools.partial", "functools.partial", "functools.partial", "len", "BigGAN.Unet_Discriminator.which_embedding", "BigGAN.Unet_Discriminator.which_embedding", "BigGAN.Unet_Discriminator.init_weights", "print", "print", "utils.Adam16", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "print", "print", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "param.size", "layers.Attention", "BigGAN.Unet_Discriminator.parameters", "BigGAN.Unet_Discriminator.parameters", "layers.DBlock", "functools.partial", "layers.GBlock2", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.BigGAN.D_unet_arch", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.BigGAN.Unet_Discriminator.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "D_ch", "=", "64", ",", "D_wide", "=", "True", ",", "resolution", "=", "128", ",", "\n", "D_kernel_size", "=", "3", ",", "D_attn", "=", "'64'", ",", "n_classes", "=", "1000", ",", "\n", "num_D_SVs", "=", "1", ",", "num_D_SV_itrs", "=", "1", ",", "D_activation", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", ",", "\n", "D_lr", "=", "2e-4", ",", "D_B1", "=", "0.0", ",", "D_B2", "=", "0.999", ",", "adam_eps", "=", "1e-8", ",", "\n", "SN_eps", "=", "1e-12", ",", "output_dim", "=", "1", ",", "D_mixed_precision", "=", "False", ",", "D_fp16", "=", "False", ",", "\n", "D_init", "=", "'ortho'", ",", "skip_init", "=", "False", ",", "D_param", "=", "'SN'", ",", "decoder_skip_connection", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Unet_Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "\n", "# Width multiplier", "\n", "self", ".", "ch", "=", "D_ch", "\n", "# Use Wide D as in BigGAN and SA-GAN or skinny D as in SN-GAN?", "\n", "self", ".", "D_wide", "=", "D_wide", "\n", "# Resolution", "\n", "self", ".", "resolution", "=", "resolution", "\n", "# Kernel size", "\n", "self", ".", "kernel_size", "=", "D_kernel_size", "\n", "# Attention?", "\n", "self", ".", "attention", "=", "D_attn", "\n", "# Number of classes", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "# Activation", "\n", "self", ".", "activation", "=", "D_activation", "\n", "# Initialization style", "\n", "self", ".", "init", "=", "D_init", "\n", "# Parameterization style", "\n", "self", ".", "D_param", "=", "D_param", "\n", "# Epsilon for Spectral Norm?", "\n", "self", ".", "SN_eps", "=", "SN_eps", "\n", "# Fp16?", "\n", "self", ".", "fp16", "=", "D_fp16", "\n", "\n", "\n", "\n", "if", "self", ".", "resolution", "==", "128", ":", "\n", "            ", "self", ".", "save_features", "=", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", "\n", "", "elif", "self", ".", "resolution", "==", "256", ":", "\n", "            ", "self", ".", "save_features", "=", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", "\n", "\n", "", "self", ".", "out_channel_multiplier", "=", "1", "#4", "\n", "# Architecture", "\n", "self", ".", "arch", "=", "D_unet_arch", "(", "self", ".", "ch", ",", "self", ".", "attention", ",", "out_channel_multiplier", "=", "self", ".", "out_channel_multiplier", ")", "[", "resolution", "]", "\n", "\n", "self", ".", "unconditional", "=", "kwargs", "[", "\"unconditional\"", "]", "\n", "\n", "# Which convs, batchnorms, and linear layers to use", "\n", "# No option to turn off SN in D right now", "\n", "if", "self", ".", "D_param", "==", "'SN'", ":", "\n", "            ", "self", ".", "which_conv", "=", "functools", ".", "partial", "(", "layers", ".", "SNConv2d", ",", "\n", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "\n", "num_svs", "=", "num_D_SVs", ",", "num_itrs", "=", "num_D_SV_itrs", ",", "\n", "eps", "=", "self", ".", "SN_eps", ")", "\n", "self", ".", "which_linear", "=", "functools", ".", "partial", "(", "layers", ".", "SNLinear", ",", "\n", "num_svs", "=", "num_D_SVs", ",", "num_itrs", "=", "num_D_SV_itrs", ",", "\n", "eps", "=", "self", ".", "SN_eps", ")", "\n", "\n", "self", ".", "which_embedding", "=", "functools", ".", "partial", "(", "layers", ".", "SNEmbedding", ",", "\n", "num_svs", "=", "num_D_SVs", ",", "num_itrs", "=", "num_D_SV_itrs", ",", "\n", "eps", "=", "self", ".", "SN_eps", ")", "\n", "# Prepare model", "\n", "# self.blocks is a doubly-nested list of modules, the outer loop intended", "\n", "# to be over blocks at a given resolution (resblocks and/or self-attention)", "\n", "", "self", ".", "blocks", "=", "[", "]", "\n", "\n", "for", "index", "in", "range", "(", "len", "(", "self", ".", "arch", "[", "'out_channels'", "]", ")", ")", ":", "\n", "\n", "            ", "if", "self", ".", "arch", "[", "\"downsample\"", "]", "[", "index", "]", ":", "\n", "                ", "self", ".", "blocks", "+=", "[", "[", "layers", ".", "DBlock", "(", "in_channels", "=", "self", ".", "arch", "[", "'in_channels'", "]", "[", "index", "]", ",", "\n", "out_channels", "=", "self", ".", "arch", "[", "'out_channels'", "]", "[", "index", "]", ",", "\n", "which_conv", "=", "self", ".", "which_conv", ",", "\n", "wide", "=", "self", ".", "D_wide", ",", "\n", "activation", "=", "self", ".", "activation", ",", "\n", "preactivation", "=", "(", "index", ">", "0", ")", ",", "\n", "downsample", "=", "(", "nn", ".", "AvgPool2d", "(", "2", ")", "if", "self", ".", "arch", "[", "'downsample'", "]", "[", "index", "]", "else", "None", ")", ")", "]", "]", "\n", "\n", "", "elif", "self", ".", "arch", "[", "\"upsample\"", "]", "[", "index", "]", ":", "\n", "                ", "upsample_function", "=", "(", "functools", ".", "partial", "(", "F", ".", "interpolate", ",", "scale_factor", "=", "2", ",", "mode", "=", "\"nearest\"", ")", "#mode=nearest is default", "\n", "if", "self", ".", "arch", "[", "'upsample'", "]", "[", "index", "]", "else", "None", ")", "\n", "\n", "self", ".", "blocks", "+=", "[", "[", "layers", ".", "GBlock2", "(", "in_channels", "=", "self", ".", "arch", "[", "'in_channels'", "]", "[", "index", "]", ",", "\n", "out_channels", "=", "self", ".", "arch", "[", "'out_channels'", "]", "[", "index", "]", ",", "\n", "which_conv", "=", "self", ".", "which_conv", ",", "\n", "#which_bn=self.which_bn,", "\n", "activation", "=", "self", ".", "activation", ",", "\n", "upsample", "=", "upsample_function", ",", "skip_connection", "=", "True", ")", "]", "]", "\n", "\n", "# If attention on this block, attach it to the end", "\n", "", "attention_condition", "=", "index", "<", "5", "\n", "if", "self", ".", "arch", "[", "'attention'", "]", "[", "self", ".", "arch", "[", "'resolution'", "]", "[", "index", "]", "]", "and", "attention_condition", ":", "#index < 5", "\n", "                ", "print", "(", "'Adding attention layer in D at resolution %d'", "%", "self", ".", "arch", "[", "'resolution'", "]", "[", "index", "]", ")", "\n", "print", "(", "\"index = \"", ",", "index", ")", "\n", "self", ".", "blocks", "[", "-", "1", "]", "+=", "[", "layers", ".", "Attention", "(", "self", ".", "arch", "[", "'out_channels'", "]", "[", "index", "]", ",", "\n", "self", ".", "which_conv", ")", "]", "\n", "\n", "\n", "# Turn self.blocks into a ModuleList so that it's all properly registered.", "\n", "", "", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "ModuleList", "(", "block", ")", "for", "block", "in", "self", ".", "blocks", "]", ")", "\n", "\n", "\n", "last_layer", "=", "nn", ".", "Conv2d", "(", "self", ".", "ch", "*", "self", ".", "out_channel_multiplier", ",", "1", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "blocks", ".", "append", "(", "last_layer", ")", "\n", "#", "\n", "# Linear output layer. The output dimension is typically 1, but may be", "\n", "# larger if we're e.g. turning this into a VAE with an inference output", "\n", "self", ".", "linear", "=", "self", ".", "which_linear", "(", "self", ".", "arch", "[", "'out_channels'", "]", "[", "-", "1", "]", ",", "output_dim", ")", "\n", "\n", "self", ".", "linear_middle", "=", "self", ".", "which_linear", "(", "16", "*", "self", ".", "ch", ",", "output_dim", ")", "\n", "# Embedding for projection discrimination", "\n", "#if not kwargs[\"agnostic_unet\"] and not kwargs[\"unconditional\"]:", "\n", "#    self.embed = self.which_embedding(self.n_classes, self.arch['out_channels'][-1]+extra)", "\n", "if", "not", "kwargs", "[", "\"unconditional\"", "]", ":", "\n", "            ", "self", ".", "embed_middle", "=", "self", ".", "which_embedding", "(", "self", ".", "n_classes", ",", "16", "*", "self", ".", "ch", ")", "\n", "self", ".", "embed", "=", "self", ".", "which_embedding", "(", "self", ".", "n_classes", ",", "self", ".", "arch", "[", "'out_channels'", "]", "[", "-", "1", "]", ")", "\n", "\n", "# Initialize weights", "\n", "", "if", "not", "skip_init", ":", "\n", "            ", "self", ".", "init_weights", "(", ")", "\n", "\n", "###", "\n", "", "print", "(", "\"_____params______\"", ")", "\n", "for", "name", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "print", "(", "name", ",", "param", ".", "size", "(", ")", ")", "\n", "\n", "# Set up optimizer", "\n", "", "self", ".", "lr", ",", "self", ".", "B1", ",", "self", ".", "B2", ",", "self", ".", "adam_eps", "=", "D_lr", ",", "D_B1", ",", "D_B2", ",", "adam_eps", "\n", "if", "D_mixed_precision", ":", "\n", "            ", "print", "(", "'Using fp16 adam in D...'", ")", "\n", "import", "utils", "\n", "self", ".", "optim", "=", "utils", ".", "Adam16", "(", "params", "=", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "\n", "betas", "=", "(", "self", ".", "B1", ",", "self", ".", "B2", ")", ",", "weight_decay", "=", "0", ",", "eps", "=", "self", ".", "adam_eps", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "optim", "=", "optim", ".", "Adam", "(", "params", "=", "self", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "\n", "betas", "=", "(", "self", ".", "B1", ",", "self", ".", "B2", ")", ",", "weight_decay", "=", "0", ",", "eps", "=", "self", ".", "adam_eps", ")", "\n", "# LR scheduling, left here for forward compatibility", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.BigGAN.Unet_Discriminator.init_weights": [[453, 469], ["BigGAN.Unet_Discriminator.modules", "print", "isinstance", "isinstance", "isinstance", "sum", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "p.data.nelement", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "print", "module.parameters"], "methods", ["None"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "self", ".", "param_count", "=", "0", "\n", "for", "module", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "(", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", "\n", "or", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "\n", "or", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "                ", "if", "self", ".", "init", "==", "'ortho'", ":", "\n", "                    ", "init", ".", "orthogonal_", "(", "module", ".", "weight", ")", "\n", "", "elif", "self", ".", "init", "==", "'N02'", ":", "\n", "                    ", "init", ".", "normal_", "(", "module", ".", "weight", ",", "0", ",", "0.02", ")", "\n", "", "elif", "self", ".", "init", "in", "[", "'glorot'", ",", "'xavier'", "]", ":", "\n", "                    ", "init", ".", "xavier_uniform_", "(", "module", ".", "weight", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'Init style not recognized...'", ")", "\n", "", "self", ".", "param_count", "+=", "sum", "(", "[", "p", ".", "data", ".", "nelement", "(", ")", "for", "p", "in", "module", ".", "parameters", "(", ")", "]", ")", "\n", "", "", "print", "(", "'Param count for D'", "'s initialized parameters: %d'", "%", "self", ".", "param_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.BigGAN.Unet_Discriminator.forward": [[472, 537], ["residual_features.append", "enumerate", "out.view.view.view", "BigGAN.Unet_Discriminator.embed", "emb.view().expand_as.view().expand_as.view().expand_as", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "out.view.view.size", "block", "residual_features.append", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "BigGAN.Unet_Discriminator.linear_middle", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "BigGAN.Unet_Discriminator.activation", "BigGAN.Unet_Discriminator.embed_middle", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "emb.view().expand_as.view().expand_as.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "emb.view().expand_as.view().expand_as.size", "emb.view().expand_as.view().expand_as.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ")", ":", "\n", "# Stick x into h for cleaner for loops without flow control", "\n", "        ", "h", "=", "x", "\n", "\n", "residual_features", "=", "[", "]", "\n", "residual_features", ".", "append", "(", "x", ")", "\n", "# Loop over blocks", "\n", "\n", "for", "index", ",", "blocklist", "in", "enumerate", "(", "self", ".", "blocks", "[", ":", "-", "1", "]", ")", ":", "\n", "            ", "if", "self", ".", "resolution", "==", "128", ":", "\n", "                ", "if", "index", "==", "6", ":", "\n", "                    ", "h", "=", "torch", ".", "cat", "(", "(", "h", ",", "residual_features", "[", "4", "]", ")", ",", "dim", "=", "1", ")", "\n", "", "elif", "index", "==", "7", ":", "\n", "                    ", "h", "=", "torch", ".", "cat", "(", "(", "h", ",", "residual_features", "[", "3", "]", ")", ",", "dim", "=", "1", ")", "\n", "", "elif", "index", "==", "8", ":", "#", "\n", "                    ", "h", "=", "torch", ".", "cat", "(", "(", "h", ",", "residual_features", "[", "2", "]", ")", ",", "dim", "=", "1", ")", "\n", "", "elif", "index", "==", "9", ":", "#", "\n", "                    ", "h", "=", "torch", ".", "cat", "(", "(", "h", ",", "residual_features", "[", "1", "]", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "", "if", "self", ".", "resolution", "==", "256", ":", "\n", "                ", "if", "index", "==", "7", ":", "\n", "                    ", "h", "=", "torch", ".", "cat", "(", "(", "h", ",", "residual_features", "[", "5", "]", ")", ",", "dim", "=", "1", ")", "\n", "", "elif", "index", "==", "8", ":", "\n", "                    ", "h", "=", "torch", ".", "cat", "(", "(", "h", ",", "residual_features", "[", "4", "]", ")", ",", "dim", "=", "1", ")", "\n", "", "elif", "index", "==", "9", ":", "#", "\n", "                    ", "h", "=", "torch", ".", "cat", "(", "(", "h", ",", "residual_features", "[", "3", "]", ")", ",", "dim", "=", "1", ")", "\n", "", "elif", "index", "==", "10", ":", "#", "\n", "                    ", "h", "=", "torch", ".", "cat", "(", "(", "h", ",", "residual_features", "[", "2", "]", ")", ",", "dim", "=", "1", ")", "\n", "", "elif", "index", "==", "11", ":", "\n", "                    ", "h", "=", "torch", ".", "cat", "(", "(", "h", ",", "residual_features", "[", "1", "]", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "", "for", "block", "in", "blocklist", ":", "\n", "                ", "h", "=", "block", "(", "h", ")", "\n", "\n", "", "if", "index", "in", "self", ".", "save_features", "[", ":", "-", "1", "]", ":", "\n", "                ", "residual_features", ".", "append", "(", "h", ")", "\n", "\n", "", "if", "index", "==", "self", ".", "save_features", "[", "-", "1", "]", ":", "\n", "# Apply global sum pooling as in SN-GAN", "\n", "                ", "h_", "=", "torch", ".", "sum", "(", "self", ".", "activation", "(", "h", ")", ",", "[", "2", ",", "3", "]", ")", "\n", "# Get initial class-unconditional output", "\n", "bottleneck_out", "=", "self", ".", "linear_middle", "(", "h_", ")", "\n", "# Get projection of final featureset onto class vectors and add to evidence", "\n", "if", "self", ".", "unconditional", ":", "\n", "                    ", "projection", "=", "0", "\n", "", "else", ":", "\n", "# this is the bottleneck classifier c", "\n", "                    ", "emb_mid", "=", "self", ".", "embed_middle", "(", "y", ")", "\n", "projection", "=", "torch", ".", "sum", "(", "emb_mid", "*", "h_", ",", "1", ",", "keepdim", "=", "True", ")", "\n", "", "bottleneck_out", "=", "bottleneck_out", "+", "projection", "\n", "\n", "", "", "out", "=", "self", ".", "blocks", "[", "-", "1", "]", "(", "h", ")", "\n", "\n", "if", "self", ".", "unconditional", ":", "\n", "            ", "proj", "=", "0", "\n", "", "else", ":", "\n", "            ", "emb", "=", "self", ".", "embed", "(", "y", ")", "\n", "emb", "=", "emb", ".", "view", "(", "emb", ".", "size", "(", "0", ")", ",", "emb", ".", "size", "(", "1", ")", ",", "1", ",", "1", ")", ".", "expand_as", "(", "h", ")", "\n", "proj", "=", "torch", ".", "sum", "(", "emb", "*", "h", ",", "1", ",", "keepdim", "=", "True", ")", "\n", "################", "\n", "", "out", "=", "out", "+", "proj", "\n", "\n", "out", "=", "out", ".", "view", "(", "out", ".", "size", "(", "0", ")", ",", "1", ",", "self", ".", "resolution", ",", "self", ".", "resolution", ")", "\n", "\n", "return", "out", ",", "bottleneck_out", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.BigGAN.G_D.__init__": [[542, 548], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__"], ["    ", "def", "__init__", "(", "self", ",", "G", ",", "D", ",", "config", ")", ":", "\n", "        ", "super", "(", "G_D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "G", "=", "G", "\n", "self", ".", "D", "=", "D", "\n", "\n", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.BigGAN.G_D.forward": [[549, 639], ["BigGAN.G_D.D", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "BigGAN.G_D.G", "x.size", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "BigGAN.G_D.G.shared", "G_z.half.half.float", "G_z.half.half.half", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.float", "torch.cat.float", "torch.cat.float", "torch.cat.float", "mixed_y.float", "torch.cat.long", "torch.cat.long", "torch.cat.long", "torch.cat.long", "mixed_y.long"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "z", ",", "gy", ",", "x", "=", "None", ",", "dy", "=", "None", ",", "train_G", "=", "False", ",", "return_G_z", "=", "False", ",", "\n", "split_D", "=", "False", ",", "dw1", "=", "[", "]", ",", "dw2", "=", "[", "]", ",", "reference_x", "=", "None", ",", "mixup", "=", "False", ",", "mixup_only", "=", "False", ",", "target_map", "=", "None", ")", ":", "\n", "\n", "        ", "if", "mixup", ":", "\n", "            ", "gy", "=", "dy", "\n", "#why? so the mixup samples consist of same class", "\n", "\n", "# If training G, enable grad tape", "\n", "", "with", "torch", ".", "set_grad_enabled", "(", "train_G", ")", ":", "\n", "\n", "            ", "G_z", "=", "self", ".", "G", "(", "z", ",", "self", ".", "G", ".", "shared", "(", "gy", ")", ")", "\n", "# Cast as necessary", "\n", "if", "self", ".", "G", ".", "fp16", "and", "not", "self", ".", "D", ".", "fp16", ":", "\n", "                ", "G_z", "=", "G_z", ".", "float", "(", ")", "\n", "", "if", "self", ".", "D", ".", "fp16", "and", "not", "self", ".", "G", ".", "fp16", ":", "\n", "                ", "G_z", "=", "G_z", ".", "half", "(", ")", "\n", "\n", "", "", "if", "mixup", ":", "\n", "            ", "initial_x_size", "=", "x", ".", "size", "(", "0", ")", "\n", "\n", "mixed", "=", "target_map", "*", "x", "+", "(", "1", "-", "target_map", ")", "*", "G_z", "\n", "mixed_y", "=", "dy", "\n", "\n", "\n", "", "if", "not", "mixup_only", ":", "\n", "# we get here in the cutmix cons extra case", "\n", "            ", "D_input", "=", "torch", ".", "cat", "(", "[", "G_z", ",", "x", "]", ",", "0", ")", "if", "x", "is", "not", "None", "else", "G_z", "\n", "D_class", "=", "torch", ".", "cat", "(", "[", "gy", ",", "dy", "]", ",", "0", ")", "if", "dy", "is", "not", "None", "else", "gy", "\n", "dmap", "=", "torch", ".", "tensor", "(", "[", "]", ")", "\n", "if", "mixup", ":", "\n", "#we get here in the cutmix  \"consistency loss and augmentation\" case, if \"mixup\" is true for the current round (depends on p mixup)", "\n", "                ", "D_input", "=", "torch", ".", "cat", "(", "[", "D_input", ",", "mixed", "]", ",", "0", ")", "\n", "if", "self", ".", "config", "[", "\"dataset\"", "]", "!=", "\"coco_animals\"", ":", "\n", "                    ", "D_class", "=", "torch", ".", "cat", "(", "[", "D_class", ".", "float", "(", ")", ",", "mixed_y", ".", "float", "(", ")", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "                    ", "D_class", "=", "torch", ".", "cat", "(", "[", "D_class", ".", "long", "(", ")", ",", "mixed_y", ".", "long", "(", ")", "]", ",", "0", ")", "\n", "", "", "", "else", ":", "\n", "#not reached in cutmix \"consistency loss and augmentation\"", "\n", "            ", "D_input", "=", "mixed", "\n", "D_class", "=", "mixed_y", "\n", "dmap", "=", "torch", ".", "tensor", "(", "[", "]", ")", "\n", "\n", "del", "G_z", "\n", "del", "x", "\n", "G_z", "=", "None", "\n", "x", "=", "None", "\n", "\n", "", "D_out", ",", "D_middle", "=", "self", ".", "D", "(", "D_input", ",", "D_class", ")", "\n", "\n", "del", "D_input", "\n", "del", "D_class", "\n", "\n", "\n", "if", "x", "is", "not", "None", ":", "\n", "\n", "            ", "if", "not", "mixup", ":", "\n", "                ", "out", "=", "torch", ".", "split", "(", "D_out", ",", "[", "G_z", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "0", "]", "]", ")", "# D_fake, D_real", "\n", "", "else", ":", "\n", "                ", "out", "=", "torch", ".", "split", "(", "D_out", ",", "[", "G_z", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "0", "]", ",", "mixed", ".", "shape", "[", "0", "]", "]", ")", "# D_fake, D_real, D_mixed", "\n", "", "out", "=", "out", "+", "(", "G_z", ",", ")", "\n", "if", "mixup", ":", "\n", "                ", "out", "=", "out", "+", "(", "mixed", ",", ")", "\n", "\n", "", "if", "not", "mixup", ":", "\n", "                ", "D_middle", "=", "torch", ".", "split", "(", "D_middle", ",", "[", "G_z", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "0", "]", "]", ")", "# D_middle_fake, D_middle_real", "\n", "", "else", ":", "\n", "                ", "D_middle", "=", "torch", ".", "split", "(", "D_middle", ",", "[", "G_z", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "0", "]", ",", "mixed", ".", "shape", "[", "0", "]", "]", ")", "\n", "", "out", "=", "out", "+", "D_middle", "\n", "###return target map as well", "\n", "if", "mixup", ":", "\n", "                ", "out", "=", "out", "+", "(", "target_map", ",", ")", "\n", "\n", "", "return", "out", "\n", "\n", "\n", "", "else", ":", "\n", "#in mixup# you arrive here", "\n", "            ", "out", "=", "(", "D_out", ",", ")", "\n", "\n", "if", "return_G_z", ":", "\n", "                ", "out", "=", "out", "+", "(", "G_z", ",", ")", "\n", "", "if", "mixup_only", ":", "\n", "                ", "out", "=", "out", "+", "(", "mixed", ",", ")", "\n", "\n", "", "out", "=", "out", "+", "(", "D_middle", ",", ")", "\n", "##return target map as well", "\n", "if", "mixup", ":", "\n", "                ", "out", "=", "out", "+", "(", "target_map", ",", ")", "\n", "\n", "", "return", "out", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.BigGAN.G_arch": [[25, 41], ["range", "range", "int", "int", "attention.split", "attention.split"], "function", ["None"], ["def", "G_arch", "(", "ch", "=", "64", ",", "attention", "=", "'64'", ",", "ksize", "=", "'333333'", ",", "dilation", "=", "'111111'", ")", ":", "\n", "    ", "arch", "=", "{", "}", "\n", "\n", "arch", "[", "256", "]", "=", "{", "'in_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "16", ",", "8", ",", "8", ",", "4", ",", "2", "]", "]", ",", "\n", "'out_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "8", ",", "8", ",", "4", ",", "2", ",", "1", "]", "]", ",", "\n", "'upsample'", ":", "[", "True", "]", "*", "6", ",", "\n", "'resolution'", ":", "[", "8", ",", "16", ",", "32", ",", "64", ",", "128", ",", "256", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "(", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "3", ",", "9", ")", "}", "}", "\n", "arch", "[", "128", "]", "=", "{", "'in_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "16", ",", "8", ",", "4", ",", "2", "]", "]", ",", "\n", "'out_channels'", ":", "[", "ch", "*", "item", "for", "item", "in", "[", "16", ",", "8", ",", "4", ",", "2", ",", "1", "]", "]", ",", "\n", "'upsample'", ":", "[", "True", "]", "*", "5", ",", "\n", "'resolution'", ":", "[", "8", ",", "16", ",", "32", ",", "64", ",", "128", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "(", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "3", ",", "8", ")", "}", "}", "\n", "return", "arch", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.BigGAN.D_arch": [[267, 282], ["range", "range", "int", "int", "attention.split", "attention.split"], "function", ["None"], ["", "", "def", "D_arch", "(", "ch", "=", "64", ",", "attention", "=", "'64'", ",", "ksize", "=", "'333333'", ",", "dilation", "=", "'111111'", ")", ":", "\n", "    ", "arch", "=", "{", "}", "\n", "arch", "[", "256", "]", "=", "{", "'in_channels'", ":", "[", "3", "]", "+", "[", "ch", "*", "item", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "8", ",", "16", "]", "]", ",", "\n", "'out_channels'", ":", "[", "item", "*", "ch", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "8", ",", "16", ",", "16", "]", "]", ",", "\n", "'downsample'", ":", "[", "True", "]", "*", "6", "+", "[", "False", "]", ",", "\n", "'resolution'", ":", "[", "128", ",", "64", ",", "32", ",", "16", ",", "8", ",", "4", ",", "4", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", "\n", "for", "i", "in", "range", "(", "2", ",", "8", ")", "}", "}", "\n", "arch", "[", "128", "]", "=", "{", "'in_channels'", ":", "[", "3", "]", "+", "[", "ch", "*", "item", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "16", "]", "]", ",", "\n", "'out_channels'", ":", "[", "item", "*", "ch", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "16", ",", "16", "]", "]", ",", "\n", "'downsample'", ":", "[", "True", "]", "*", "5", "+", "[", "False", "]", ",", "\n", "'resolution'", ":", "[", "64", ",", "32", ",", "16", ",", "8", ",", "4", ",", "4", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", "\n", "for", "i", "in", "range", "(", "2", ",", "8", ")", "}", "}", "\n", "return", "arch", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.BigGAN.D_unet_arch": [[283, 311], ["range", "range", "int", "int", "attention.split", "attention.split"], "function", ["None"], ["", "def", "D_unet_arch", "(", "ch", "=", "64", ",", "attention", "=", "'64'", ",", "ksize", "=", "'333333'", ",", "dilation", "=", "'111111'", ",", "out_channel_multiplier", "=", "1", ")", ":", "\n", "    ", "arch", "=", "{", "}", "\n", "\n", "n", "=", "2", "\n", "\n", "ocm", "=", "out_channel_multiplier", "\n", "\n", "# covers bigger perceptual fields", "\n", "arch", "[", "128", "]", "=", "{", "'in_channels'", ":", "[", "3", "]", "+", "[", "ch", "*", "item", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "16", ",", "8", "*", "n", ",", "4", "*", "2", ",", "2", "*", "2", ",", "1", "*", "2", ",", "1", "]", "]", ",", "\n", "'out_channels'", ":", "[", "item", "*", "ch", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "16", ",", "8", ",", "4", ",", "2", ",", "1", ",", "1", "]", "]", ",", "\n", "'downsample'", ":", "[", "True", "]", "*", "5", "+", "[", "False", "]", "*", "5", ",", "\n", "'upsample'", ":", "[", "False", "]", "*", "5", "+", "[", "True", "]", "*", "5", ",", "\n", "'resolution'", ":", "[", "64", ",", "32", ",", "16", ",", "8", ",", "4", ",", "8", ",", "16", ",", "32", ",", "64", ",", "128", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", "\n", "for", "i", "in", "range", "(", "2", ",", "11", ")", "}", "}", "\n", "\n", "\n", "arch", "[", "256", "]", "=", "{", "'in_channels'", ":", "[", "3", "]", "+", "[", "ch", "*", "item", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "8", ",", "16", ",", "8", "*", "2", ",", "8", "*", "2", ",", "4", "*", "2", ",", "2", "*", "2", ",", "1", "*", "2", ",", "1", "]", "]", ",", "\n", "'out_channels'", ":", "[", "item", "*", "ch", "for", "item", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "8", ",", "16", ",", "8", ",", "8", ",", "4", ",", "2", ",", "1", ",", "1", "]", "]", ",", "\n", "'downsample'", ":", "[", "True", "]", "*", "6", "+", "[", "False", "]", "*", "6", ",", "\n", "'upsample'", ":", "[", "False", "]", "*", "6", "+", "[", "True", "]", "*", "6", ",", "\n", "'resolution'", ":", "[", "128", ",", "64", ",", "32", ",", "16", ",", "8", ",", "4", ",", "8", ",", "16", ",", "32", ",", "64", ",", "128", ",", "256", "]", ",", "\n", "'attention'", ":", "{", "2", "**", "i", ":", "2", "**", "i", "in", "[", "int", "(", "item", ")", "for", "item", "in", "attention", ".", "split", "(", "'_'", ")", "]", "\n", "for", "i", "in", "range", "(", "2", ",", "13", ")", "}", "}", "\n", "\n", "\n", "\n", "return", "arch", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception.InceptionV3.__init__": [[22, 107], ["torch.Module.__init__", "sorted", "max", "torch.ModuleList", "torch.ModuleList", "torchvision.models.inception_v3", "models.inception_v3.InceptionV3.blocks.append", "models.inception_v3.InceptionV3.parameters", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Sequential", "torch.Sequential", "models.inception_v3.InceptionV3.blocks.append", "models.inception_v3.InceptionV3.blocks.append", "models.inception_v3.InceptionV3.blocks.append", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sequential", "torch.Sequential"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__"], ["def", "__init__", "(", "self", ",", "\n", "output_blocks", "=", "[", "DEFAULT_BLOCK_INDEX", "]", ",", "\n", "resize_input", "=", "True", ",", "\n", "normalize_input", "=", "True", ",", "\n", "requires_grad", "=", "False", ")", ":", "\n", "        ", "\"\"\"Build pretrained InceptionV3\n\n        Parameters\n        ----------\n        output_blocks : list of int\n            Indices of blocks to return features of. Possible values are:\n                - 0: corresponds to output of first max pooling\n                - 1: corresponds to output of second max pooling\n                - 2: corresponds to output which is fed to aux classifier\n                - 3: corresponds to output of final average pooling\n        resize_input : bool\n            If true, bilinearly resizes input to width and height 299 before\n            feeding input to model. As the network without fully connected\n            layers is fully convolutional, it should be able to handle inputs\n            of arbitrary size, so resizing might not be strictly needed\n        normalize_input : bool\n            If true, scales the input from range (0, 1) to the range the\n            pretrained Inception network expects, namely (-1, 1)\n        requires_grad : bool\n            If true, parameters of the model require gradient. Possibly useful\n            for finetuning the network\n        \"\"\"", "\n", "super", "(", "InceptionV3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "resize_input", "=", "resize_input", "\n", "self", ".", "normalize_input", "=", "normalize_input", "\n", "self", ".", "output_blocks", "=", "sorted", "(", "output_blocks", ")", "\n", "self", ".", "last_needed_block", "=", "max", "(", "output_blocks", ")", "\n", "\n", "assert", "self", ".", "last_needed_block", "<=", "3", ",", "'Last possible output block index is 3'", "\n", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "inception", "=", "models", ".", "inception_v3", "(", "pretrained", "=", "True", ")", "\n", "\n", "# Block 0: input to maxpool1", "\n", "block0", "=", "[", "\n", "inception", ".", "Conv2d_1a_3x3", ",", "\n", "inception", ".", "Conv2d_2a_3x3", ",", "\n", "inception", ".", "Conv2d_2b_3x3", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block0", ")", ")", "\n", "\n", "# Block 1: maxpool1 to maxpool2", "\n", "if", "self", ".", "last_needed_block", ">=", "1", ":", "\n", "            ", "block1", "=", "[", "\n", "inception", ".", "Conv2d_3b_1x1", ",", "\n", "inception", ".", "Conv2d_4a_3x3", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block1", ")", ")", "\n", "\n", "# Block 2: maxpool2 to aux classifier", "\n", "", "if", "self", ".", "last_needed_block", ">=", "2", ":", "\n", "            ", "block2", "=", "[", "\n", "inception", ".", "Mixed_5b", ",", "\n", "inception", ".", "Mixed_5c", ",", "\n", "inception", ".", "Mixed_5d", ",", "\n", "inception", ".", "Mixed_6a", ",", "\n", "inception", ".", "Mixed_6b", ",", "\n", "inception", ".", "Mixed_6c", ",", "\n", "inception", ".", "Mixed_6d", ",", "\n", "inception", ".", "Mixed_6e", ",", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block2", ")", ")", "\n", "\n", "# Block 3: aux classifier to final avgpool", "\n", "", "if", "self", ".", "last_needed_block", ">=", "3", ":", "\n", "            ", "block3", "=", "[", "\n", "inception", ".", "Mixed_7a", ",", "\n", "inception", ".", "Mixed_7b", ",", "\n", "inception", ".", "Mixed_7c", ",", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "output_size", "=", "(", "1", ",", "1", ")", ")", "\n", "]", "\n", "self", ".", "blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block3", ")", ")", "\n", "\n", "", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception.InceptionV3.forward": [[108, 143], ["enumerate", "torch.interpolate", "torch.interpolate", "block", "outp.append"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "\"\"\"Get Inception feature maps\n\n        Parameters\n        ----------\n        inp : torch.autograd.Variable\n            Input tensor of shape Bx3xHxW. Values are expected to be in\n            range (0, 1)\n\n        Returns\n        -------\n        List of torch.autograd.Variable, corresponding to the selected output\n        block, sorted ascending by index\n        \"\"\"", "\n", "outp", "=", "[", "]", "\n", "x", "=", "inp", "\n", "\n", "if", "self", ".", "resize_input", ":", "\n", "            ", "x", "=", "F", ".", "interpolate", "(", "x", ",", "\n", "size", "=", "(", "299", ",", "299", ")", ",", "\n", "mode", "=", "'bilinear'", ",", "\n", "align_corners", "=", "False", ")", "\n", "\n", "", "if", "self", ".", "normalize_input", ":", "\n", "            ", "x", "=", "2", "*", "x", "-", "1", "# Scale from range (0, 1) to range (-1, 1)", "\n", "\n", "", "for", "idx", ",", "block", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "            ", "x", "=", "block", "(", "x", ")", "\n", "if", "idx", "in", "self", ".", "output_blocks", ":", "\n", "                ", "outp", ".", "append", "(", "x", ")", "\n", "\n", "", "if", "idx", "==", "self", ".", "last_needed_block", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "outp", "\n", "", "", ""]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.fid_score.get_activations": [[72, 139], ["model.eval", "numpy.empty", "tqdm", "print", "len", "print", "len", "len", "range", "numpy.array", "images.transpose.transpose", "torch.from_numpy().type", "torch.nn.functional.adaptive_avg_pool2d.cpu().data.numpy().reshape", "print", "len", "print", "batch.cuda.cuda", "model", "torch.nn.functional.adaptive_avg_pool2d", "imageio.imread().astype", "torch.from_numpy", "torch.nn.functional.adaptive_avg_pool2d.cpu().data.numpy", "imageio.imread", "str", "torch.nn.functional.adaptive_avg_pool2d.cpu"], "function", ["None"], ["def", "get_activations", "(", "files", ",", "model", ",", "batch_size", "=", "50", ",", "dims", "=", "2048", ",", "\n", "cuda", "=", "False", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "\"\"\"Calculates the activations of the pool_3 layer for all images.\n\n    Params:\n    -- files       : List of image files paths\n    -- model       : Instance of inception model\n    -- batch_size  : Batch size of images for the model to process at once.\n                     Make sure that the number of samples is a multiple of\n                     the batch size, otherwise some samples are ignored. This\n                     behavior is retained to match the original FID score\n                     implementation.\n    -- dims        : Dimensionality of features returned by Inception\n    -- cuda        : If set to True, use GPU\n    -- verbose     : If set to True and parameter out_step is given, the number\n                     of calculated batches is reported.\n    Returns:\n    -- A numpy array of dimension (num images, dims) that contains the\n       activations of the given tensor when feeding inception with the\n       query tensor.\n    \"\"\"", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "len", "(", "files", ")", "%", "batch_size", "!=", "0", ":", "\n", "        ", "print", "(", "(", "'Warning: number of images is not a multiple of the '", "\n", "'batch size. Some samples are going to be ignored.'", ")", ")", "\n", "", "if", "batch_size", ">", "len", "(", "files", ")", ":", "\n", "        ", "print", "(", "(", "'Warning: batch size is bigger than the data size. '", "\n", "'Setting batch size to data size'", ")", ")", "\n", "batch_size", "=", "len", "(", "files", ")", "\n", "#print(batch_size)", "\n", "", "n_batches", "=", "len", "(", "files", ")", "//", "batch_size", "\n", "n_used_imgs", "=", "n_batches", "*", "batch_size", "\n", "\n", "pred_arr", "=", "np", ".", "empty", "(", "(", "n_used_imgs", ",", "dims", ")", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "n_batches", ")", ")", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "'\\rPropagating batch %d/%d'", "%", "(", "i", "+", "1", ",", "n_batches", ")", ",", "\n", "end", "=", "''", ",", "flush", "=", "True", ")", "\n", "", "start", "=", "i", "*", "batch_size", "\n", "end", "=", "start", "+", "batch_size", "\n", "\n", "images", "=", "np", ".", "array", "(", "[", "imread", "(", "str", "(", "f", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "for", "f", "in", "files", "[", "start", ":", "end", "]", "]", ")", "\n", "\n", "# Reshape to (n_images, 3, height, width)", "\n", "images", "=", "images", ".", "transpose", "(", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "images", "/=", "255", "\n", "\n", "batch", "=", "torch", ".", "from_numpy", "(", "images", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "if", "cuda", ":", "\n", "            ", "batch", "=", "batch", ".", "cuda", "(", ")", "\n", "\n", "", "pred", "=", "model", "(", "batch", ")", "[", "0", "]", "\n", "\n", "# If model output is not scalar, apply global spatial average pooling.", "\n", "# This happens if you choose a dimensionality not equal 2048.", "\n", "if", "pred", ".", "shape", "[", "2", "]", "!=", "1", "or", "pred", ".", "shape", "[", "3", "]", "!=", "1", ":", "\n", "            ", "pred", "=", "adaptive_avg_pool2d", "(", "pred", ",", "output_size", "=", "(", "1", ",", "1", ")", ")", "\n", "\n", "", "pred_arr", "[", "start", ":", "end", "]", "=", "pred", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "' done'", ")", "\n", "\n", "", "return", "pred_arr", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.fid_score.calculate_frechet_distance": [[141, 196], ["numpy.atleast_1d", "numpy.atleast_1d", "numpy.atleast_2d", "numpy.atleast_2d", "scipy.linalg.sqrtm", "numpy.iscomplexobj", "numpy.trace", "np.atleast_2d.dot", "numpy.isfinite().all", "print", "scipy.linalg.sqrtm", "numpy.eye", "numpy.allclose", "numpy.max", "ValueError", "numpy.trace", "numpy.isfinite", "numpy.abs", "diff.dot", "numpy.trace", "numpy.diagonal"], "function", ["None"], ["", "def", "calculate_frechet_distance", "(", "mu1", ",", "sigma1", ",", "mu2", ",", "sigma2", ",", "eps", "=", "1e-6", ")", ":", "\n", "    ", "\"\"\"Numpy implementation of the Frechet Distance.\n    The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n    and X_2 ~ N(mu_2, C_2) is\n            d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n\n    Stable version by Dougal J. Sutherland.\n\n    Params:\n    -- mu1   : Numpy array containing the activations of a layer of the\n               inception net (like returned by the function 'get_predictions')\n               for generated samples.\n    -- mu2   : The sample mean over activations, precalculated on an\n               representative data set.\n    -- sigma1: The covariance matrix over activations for generated samples.\n    -- sigma2: The covariance matrix over activations, precalculated on an\n               representative data set.\n\n    Returns:\n    --   : The Frechet Distance.\n    \"\"\"", "\n", "\n", "mu1", "=", "np", ".", "atleast_1d", "(", "mu1", ")", "\n", "mu2", "=", "np", ".", "atleast_1d", "(", "mu2", ")", "\n", "\n", "sigma1", "=", "np", ".", "atleast_2d", "(", "sigma1", ")", "\n", "sigma2", "=", "np", ".", "atleast_2d", "(", "sigma2", ")", "\n", "\n", "assert", "mu1", ".", "shape", "==", "mu2", ".", "shape", ",", "'Training and test mean vectors have different lengths'", "\n", "assert", "sigma1", ".", "shape", "==", "sigma2", ".", "shape", ",", "'Training and test covariances have different dimensions'", "\n", "\n", "diff", "=", "mu1", "-", "mu2", "\n", "\n", "# Product might be almost singular", "\n", "covmean", ",", "_", "=", "linalg", ".", "sqrtm", "(", "sigma1", ".", "dot", "(", "sigma2", ")", ",", "disp", "=", "False", ")", "\n", "if", "not", "np", ".", "isfinite", "(", "covmean", ")", ".", "all", "(", ")", ":", "\n", "        ", "msg", "=", "(", "'fid calculation produces singular product; '", "\n", "'adding %s to diagonal of cov estimates'", ")", "%", "eps", "\n", "print", "(", "msg", ")", "\n", "offset", "=", "np", ".", "eye", "(", "sigma1", ".", "shape", "[", "0", "]", ")", "*", "eps", "\n", "covmean", "=", "linalg", ".", "sqrtm", "(", "(", "sigma1", "+", "offset", ")", ".", "dot", "(", "sigma2", "+", "offset", ")", ")", "\n", "\n", "# Numerical error might give slight imaginary component", "\n", "", "if", "np", ".", "iscomplexobj", "(", "covmean", ")", ":", "\n", "        ", "if", "not", "np", ".", "allclose", "(", "np", ".", "diagonal", "(", "covmean", ")", ".", "imag", ",", "0", ",", "atol", "=", "1e-3", ")", ":", "\n", "            ", "m", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "covmean", ".", "imag", ")", ")", "\n", "raise", "ValueError", "(", "'Imaginary component {}'", ".", "format", "(", "m", ")", ")", "\n", "", "covmean", "=", "covmean", ".", "real", "\n", "\n", "", "tr_covmean", "=", "np", ".", "trace", "(", "covmean", ")", "\n", "\n", "return", "(", "diff", ".", "dot", "(", "diff", ")", "+", "np", ".", "trace", "(", "sigma1", ")", "+", "\n", "np", ".", "trace", "(", "sigma2", ")", "-", "2", "*", "tr_covmean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.fid_score.calculate_activation_statistics": [[198, 221], ["fid_score.get_activations", "numpy.mean", "numpy.cov"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.fid_score.get_activations"], ["", "def", "calculate_activation_statistics", "(", "files", ",", "model", ",", "batch_size", "=", "50", ",", "\n", "dims", "=", "2048", ",", "cuda", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculation of the statistics used by the FID.\n    Params:\n    -- files       : List of image files paths\n    -- model       : Instance of inception model\n    -- batch_size  : The images numpy array is split into batches with\n                     batch size batch_size. A reasonable batch size\n                     depends on the hardware.\n    -- dims        : Dimensionality of features returned by Inception\n    -- cuda        : If set to True, use GPU\n    -- verbose     : If set to True and parameter out_step is given, the\n                     number of calculated batches is reported.\n    Returns:\n    -- mu    : The mean over samples of the activations of the pool_3 layer of\n               the inception model.\n    -- sigma : The covariance matrix of the activations of the pool_3 layer of\n               the inception model.\n    \"\"\"", "\n", "act", "=", "get_activations", "(", "files", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ",", "verbose", ")", "\n", "mu", "=", "np", ".", "mean", "(", "act", ",", "axis", "=", "0", ")", "\n", "sigma", "=", "np", ".", "cov", "(", "act", ",", "rowvar", "=", "False", ")", "\n", "return", "mu", ",", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.fid_score._compute_statistics_of_path": [[223, 235], ["pathlib.Path.endswith", "numpy.load", "np.load.close", "pathlib.Path", "fid_score.calculate_activation_statistics", "list", "list", "pathlib.Path.glob", "pathlib.Path.glob"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.fid_score.calculate_activation_statistics"], ["", "def", "_compute_statistics_of_path", "(", "path", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ")", ":", "\n", "    ", "if", "path", ".", "endswith", "(", "'.npz'", ")", ":", "\n", "        ", "f", "=", "np", ".", "load", "(", "path", ")", "\n", "m", ",", "s", "=", "f", "[", "'mu'", "]", "[", ":", "]", ",", "f", "[", "'sigma'", "]", "[", ":", "]", "\n", "f", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "        ", "path", "=", "pathlib", ".", "Path", "(", "path", ")", "\n", "files", "=", "list", "(", "path", ".", "glob", "(", "'*.jpg'", ")", ")", "+", "list", "(", "path", ".", "glob", "(", "'*.png'", ")", ")", "\n", "m", ",", "s", "=", "calculate_activation_statistics", "(", "files", ",", "model", ",", "batch_size", ",", "\n", "dims", ",", "cuda", ")", "\n", "\n", "", "return", "m", ",", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.fid_score._compute_statistics_of_tensor": [[236, 267], ["model.eval", "numpy.empty", "torch.utils.data.DataLoader", "enumerate", "numpy.mean", "numpy.cov", "tensor.size", "tqdm", "torch.nn.functional.adaptive_avg_pool2d.cpu().data.numpy().reshape", "batch.cuda.cuda", "model", "torch.nn.functional.adaptive_avg_pool2d", "torch.nn.functional.adaptive_avg_pool2d.cpu().data.numpy", "torch.nn.functional.adaptive_avg_pool2d.cpu"], "function", ["None"], ["", "def", "_compute_statistics_of_tensor", "(", "tensor", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "\n", "n_batches", "=", "tensor", ".", "size", "(", "0", ")", "//", "batch_size", "\n", "n_used_imgs", "=", "n_batches", "*", "batch_size", "\n", "\n", "pred_arr", "=", "np", ".", "empty", "(", "(", "n_used_imgs", ",", "dims", ")", ")", "\n", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "tensor", ",", "batch_size", "=", "batch_size", ",", "drop_last", "=", "True", ")", "\n", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "tqdm", "(", "dataloader", ")", ")", ":", "\n", "\n", "        ", "start", "=", "i", "*", "batch_size", "\n", "end", "=", "start", "+", "batch_size", "\n", "\n", "if", "cuda", ":", "\n", "            ", "batch", "=", "batch", ".", "cuda", "(", ")", "\n", "\n", "", "pred", "=", "model", "(", "batch", ")", "[", "0", "]", "\n", "# If model output is not scalar, apply global spatial average pooling.", "\n", "# This happens if you choose a dimensionality not equal 2048.", "\n", "if", "pred", ".", "shape", "[", "2", "]", "!=", "1", "or", "pred", ".", "shape", "[", "3", "]", "!=", "1", ":", "\n", "            ", "pred", "=", "adaptive_avg_pool2d", "(", "pred", ",", "output_size", "=", "(", "1", ",", "1", ")", ")", "\n", "\n", "", "pred_arr", "[", "start", ":", "end", "]", "=", "pred", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "reshape", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "", "act", "=", "pred_arr", "\n", "mu", "=", "np", ".", "mean", "(", "act", ",", "axis", "=", "0", ")", "\n", "sigma", "=", "np", ".", "cov", "(", "act", ",", "rowvar", "=", "False", ")", "\n", "\n", "return", "mu", ",", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.fid_score.calculate_fid_given_paths": [[269, 292], ["print", "inception.InceptionV3", "inception.InceptionV3.cuda", "torch.no_grad", "fid_score._compute_statistics_of_tensor", "fid_score._compute_statistics_of_path", "fid_score.calculate_frechet_distance", "os.path.exists", "RuntimeError", "torch.rand"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.fid_score._compute_statistics_of_tensor", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.fid_score._compute_statistics_of_path", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.fid_score.calculate_frechet_distance"], ["", "def", "calculate_fid_given_paths", "(", "paths", ",", "batch_size", ",", "cuda", ",", "dims", ")", ":", "\n", "    ", "\"\"\"Calculates the FID of two paths\"\"\"", "\n", "for", "p", "in", "paths", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "p", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Invalid path: %s'", "%", "p", ")", "\n", "\n", "", "", "block_idx", "=", "InceptionV3", ".", "BLOCK_INDEX_BY_DIM", "[", "dims", "]", "\n", "\n", "print", "(", "\"block_idx \"", ",", "block_idx", ")", "\n", "\n", "model", "=", "InceptionV3", "(", "[", "block_idx", "]", ")", "\n", "\n", "\n", "if", "cuda", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "m1", ",", "s1", "=", "_compute_statistics_of_tensor", "(", "torch", ".", "rand", "(", "100", ",", "3", ",", "256", ",", "256", ")", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ")", "#_compute_statistics_of_path(paths[0], model, batch_size, dims, cuda)", "\n", "m2", ",", "s2", "=", "_compute_statistics_of_path", "(", "paths", "[", "1", "]", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ")", "\n", "\n", "fid_value", "=", "calculate_frechet_distance", "(", "m1", ",", "s1", ",", "m2", ",", "s2", ")", "\n", "\n", "", "return", "fid_value", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.fid_score.calculate_fid_given_paths_or_tensor": [[293, 327], ["isinstance", "isinstance", "inception.InceptionV3", "inception.InceptionV3.cuda", "torch.no_grad", "function1", "function2", "fid_score.calculate_frechet_distance"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.fid_score.calculate_frechet_distance"], ["", "def", "calculate_fid_given_paths_or_tensor", "(", "input1", ",", "input2", ",", "batch_size", ",", "cuda", ",", "dims", ",", "config", ")", ":", "\n", "    ", "\"\"\"Calculates the FID of two paths.\n    Added in 2019 for unet-gan project\"\"\"", "\n", "\n", "if", "isinstance", "(", "input1", ",", "str", ")", ":", "\n", "        ", "function1", "=", "_compute_statistics_of_path", "\n", "", "else", ":", "\n", "        ", "function1", "=", "_compute_statistics_of_tensor", "\n", "\n", "", "if", "isinstance", "(", "input2", ",", "str", ")", ":", "\n", "        ", "function2", "=", "_compute_statistics_of_path", "\n", "", "else", ":", "\n", "        ", "function2", "=", "_compute_statistics_of_tensor", "\n", "\n", "\n", "", "block_idx", "=", "InceptionV3", ".", "BLOCK_INDEX_BY_DIM", "[", "dims", "]", "\n", "\n", "if", "config", "[", "\"si\"", "]", ":", "\n", "        ", "pass", "\n", "", "else", ":", "\n", "        ", "pass", "\n", "\n", "", "model", "=", "InceptionV3", "(", "[", "block_idx", "]", ")", "\n", "\n", "if", "cuda", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "m1", ",", "s1", "=", "function1", "(", "input1", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ")", "\n", "m2", ",", "s2", "=", "function2", "(", "input2", ",", "model", ",", "batch_size", ",", "dims", ",", "cuda", ")", "\n", "\n", "fid_value", "=", "calculate_frechet_distance", "(", "m1", ",", "s1", ",", "m2", ",", "s2", ")", "\n", "\n", "", "return", "fid_value", "\n", "", ""]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train.getsize": [[51, 67], ["isinstance", "set", "TypeError", "gc.get_referents", "str", "set.add", "sys.getsizeof", "need_referents.append", "type", "isinstance", "id", "id"], "function", ["None"], ["def", "getsize", "(", "obj", ")", ":", "\n", "    ", "\"\"\"sum size of object & members.\"\"\"", "\n", "if", "isinstance", "(", "obj", ",", "BLACKLIST", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'getsize() does not take argument of type: '", "+", "str", "(", "type", "(", "obj", ")", ")", ")", "\n", "", "seen_ids", "=", "set", "(", ")", "\n", "size", "=", "0", "\n", "objects", "=", "[", "obj", "]", "\n", "while", "objects", ":", "\n", "        ", "need_referents", "=", "[", "]", "\n", "for", "obj", "in", "objects", ":", "\n", "            ", "if", "not", "isinstance", "(", "obj", ",", "BLACKLIST", ")", "and", "id", "(", "obj", ")", "not", "in", "seen_ids", ":", "\n", "                ", "seen_ids", ".", "add", "(", "id", "(", "obj", ")", ")", "\n", "size", "+=", "sys", ".", "getsizeof", "(", "obj", ")", "\n", "need_referents", ".", "append", "(", "obj", ")", "\n", "", "", "objects", "=", "get_referents", "(", "*", "need_referents", ")", "\n", "", "return", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train.find_between": [[72, 74], ["[].split", "s.split"], "function", ["None"], ["", "def", "find_between", "(", "s", ",", "start", ",", "end", ")", ":", "\n", "    ", "return", "(", "s", ".", "split", "(", "start", ")", ")", "[", "1", "]", ".", "split", "(", "end", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train.requires_grad": [[77, 80], ["model.parameters"], "function", ["None"], ["", "def", "requires_grad", "(", "model", ",", "flag", "=", "True", ")", ":", "\n", "    ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "p", ".", "requires_grad", "=", "flag", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train.run": [[81, 471], ["print", "torchvision.utils.update_config_roots", "torchvision.utils.seed_rng", "torchvision.utils.prepare_root", "print", "__import__", "print", "print", "sorted", "__import__.Generator().to", "__import__.Unet_Discriminator().to", "__import__.G_D", "print", "print", "print", "max", "int", "torchvision.utils.prepare_z_y", "print", "torchvision.utils.MetricsLogger", "print", "torchvision.utils.MyLogger", "torchvision.utils.write_metadata", "print", "inception_utils.prepare_inception_metrics", "torchvision.utils.prepare_z_y", "fixed_z.sample_", "fixed_y.sample_", "functools.partial", "print", "range", "print", "torchvision.utils.name_from_config", "utils.update_config_roots.keys", "print", "print", "__import__.Generator().to", "torchvision.utils.ema", "print", "G.half.half", "print", "D.half.half", "print", "print", "torch.DataParallel", "patch_replication_callback", "torchvision.transforms.Compose", "print", "PyTorchDatasets.FFHQ", "torch.utils.data.DataLoader", "train_fns.GAN_training_function", "train_fns.dummy_training_function", "enumerate", "__import__.Generator", "__import__.Unet_Discriminator", "G_ema.half.half", "print", "torchvision.utils.load_weights", "torchvision.transforms.Compose", "PyTorchDatasets.Celeba", "torch.utils.data.DataLoader", "G.half.train", "D.half.train", "train_fns.dummy_training_function.", "__import__.Generator", "print", "torchvision.utils.load_weights", "G_ema.half.load_state_dict", "torchvision.transforms.Scale", "torchvision.transforms.CenterCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Compose", "PyTorchDatasets.CocoAnimals", "torch.utils.data.DataLoader", "torchvision.utils.progress", "tqdm", "print", "G_ema.half.train", "int", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "print", "utils.MyLogger.log", "utils.MyLogger.log", "train_fns.test", "inception_metrics_dict[].append", "inception_metrics_dict[].append", "inception_metrics_dict[].append", "sum", "G.half.state_dict", "torchvision.transforms.Scale", "torchvision.transforms.CenterCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "x.to().half", "y.to().view", "x.to", "y.to().view", "min", "print", "G.half.eval", "train_fns.save_and_sample", "print", "G.half.eval", "train_fns.save_and_sample", "train_fns.save_and_sample", "print", "print", "torchvision.utils.accumulate_standing_stats", "open", "pickle.dump", "print", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "x.size", "mixup.CutMix().cuda().view", "int", "int", "G_ema.half.eval", "G_ema.half.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "PyTorchDatasets.CocoAnimals.fixed_batch", "os.path.join", "os.path.join", "p.data.nelement", "x.to", "y.to", "y.to", "range", "torchvision.utils.get_SVs", "torchvision.utils.get_SVs", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "int", "torchvision.utils.accumulate_standing_stats", "net.parameters", "mixup.CutMix().cuda", "min", "PyTorchDatasets.CocoAnimals.fixed_batch", "torch.parallel.data_parallel", "train_fns.save_and_sample", "PyTorchDatasets.CocoAnimals.fixed_batch", "torch.parallel.data_parallel", "train_fns.save_and_sample", "torch.cat.size", "mixup.CutMix", "fixed_z.size", "which_G.shared", "which_G.shared"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.update_config_roots", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.seed_rng", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.prepare_root", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.to", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.to", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.prepare_z_y", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.write_metadata", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.prepare_inception_metrics", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.prepare_z_y", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.name_from_config", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.to", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train_fns.GAN_training_function", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train_fns.dummy_training_function", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.load_weights", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.load_weights", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Adam16.load_state_dict", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.progress", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train_fns.test", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.to", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train_fns.save_and_sample", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train_fns.save_and_sample", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train_fns.save_and_sample", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.accumulate_standing_stats", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.Celeba.fixed_batch", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.to", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.to", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.to", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.get_SVs", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.get_SVs", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.accumulate_standing_stats", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.Celeba.fixed_batch", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train_fns.save_and_sample", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.Celeba.fixed_batch", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train_fns.save_and_sample", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.mixup.CutMix"], ["", "", "def", "run", "(", "config", ")", ":", "\n", "\n", "    ", "import", "train_fns", "\n", "\n", "if", "config", "[", "\"dataset\"", "]", "==", "\"coco_animals\"", ":", "\n", "        ", "folders", "=", "[", "'bird'", ",", "'cat'", ",", "'dog'", ",", "'horse'", ",", "'sheep'", ",", "'cow'", ",", "'elephant'", ",", "'monkey'", ",", "'zebra'", ",", "'giraffe'", "]", "\n", "\n", "# Update the config dict as necessary This is for convenience, to add settings derived from the user-specified configuration into the", "\n", "# config-dict (e.g. inferring the number of classes and size of the images from the dataset, passing in a pytorch object for the", "\n", "# activation specified as a string)", "\n", "", "config", "[", "'resolution'", "]", "=", "utils", ".", "imsize_dict", "[", "config", "[", "'dataset'", "]", "]", "\n", "print", "(", "\"RESOLUTION: \"", ",", "config", "[", "'resolution'", "]", ")", "\n", "config", "[", "'n_classes'", "]", "=", "utils", ".", "nclass_dict", "[", "config", "[", "'dataset'", "]", "]", "\n", "config", "[", "'G_activation'", "]", "=", "utils", ".", "activation_dict", "[", "config", "[", "'G_nl'", "]", "]", "\n", "config", "[", "'D_activation'", "]", "=", "utils", ".", "activation_dict", "[", "config", "[", "'D_nl'", "]", "]", "\n", "# By default, skip init if resuming training.", "\n", "if", "config", "[", "'resume'", "]", ":", "\n", "        ", "print", "(", "'Skipping initialization for training resumption...'", ")", "\n", "config", "[", "'skip_init'", "]", "=", "True", "\n", "", "config", "=", "utils", ".", "update_config_roots", "(", "config", ")", "\n", "device", "=", "'cuda'", "\n", "# Seed RNG", "\n", "utils", ".", "seed_rng", "(", "config", "[", "'seed'", "]", ")", "\n", "# Prepare root folders if necessary", "\n", "utils", ".", "prepare_root", "(", "config", ")", "\n", "# Setup cudnn.benchmark for free speed, but only if not more than 4 gpus are used", "\n", "if", "\"4\"", "not", "in", "config", "[", "\"gpus\"", "]", ":", "\n", "        ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "", "print", "(", "\":::::::::::/nCUDNN BENCHMARK\"", ",", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", ",", "\"::::::::::::::\"", ")", "\n", "# Import the model--this line allows us to dynamically select different files.", "\n", "model", "=", "__import__", "(", "config", "[", "'model'", "]", ")", "\n", "experiment_name", "=", "(", "config", "[", "'experiment_name'", "]", "if", "config", "[", "'experiment_name'", "]", "\n", "else", "utils", ".", "name_from_config", "(", "config", ")", ")", "\n", "print", "(", "'Experiment name is %s'", "%", "experiment_name", ")", "\n", "print", "(", "\"::: weights saved at \"", ",", "'/'", ".", "join", "(", "[", "config", "[", "'weights_root'", "]", ",", "experiment_name", "]", ")", ")", "\n", "# Next, build the model", "\n", "keys", "=", "sorted", "(", "config", ".", "keys", "(", ")", ")", "\n", "for", "k", "in", "keys", ":", "\n", "        ", "print", "(", "k", ",", "\": \"", ",", "config", "[", "k", "]", ")", "\n", "", "G", "=", "model", ".", "Generator", "(", "**", "config", ")", ".", "to", "(", "device", ")", "\n", "\n", "D", "=", "model", ".", "Unet_Discriminator", "(", "**", "config", ")", ".", "to", "(", "device", ")", "\n", "\n", "# If using EMA, prepare it", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "        ", "print", "(", "'Preparing EMA for G with decay of {}'", ".", "format", "(", "config", "[", "'ema_decay'", "]", ")", ")", "\n", "G_ema", "=", "model", ".", "Generator", "(", "**", "{", "**", "config", ",", "'skip_init'", ":", "True", ",", "\n", "'no_optim'", ":", "True", "}", ")", ".", "to", "(", "device", ")", "\n", "ema", "=", "utils", ".", "ema", "(", "G", ",", "G_ema", ",", "config", "[", "'ema_decay'", "]", ",", "config", "[", "'ema_start'", "]", ")", "\n", "", "else", ":", "\n", "        ", "G_ema", ",", "ema", "=", "None", ",", "None", "\n", "# FP16?", "\n", "", "if", "config", "[", "'G_fp16'", "]", ":", "\n", "        ", "print", "(", "'Casting G to float16...'", ")", "\n", "G", "=", "G", ".", "half", "(", ")", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "            ", "G_ema", "=", "G_ema", ".", "half", "(", ")", "\n", "", "", "if", "config", "[", "'D_fp16'", "]", ":", "\n", "        ", "print", "(", "'Casting D to fp16...'", ")", "\n", "D", "=", "D", ".", "half", "(", ")", "\n", "# Consider automatically reducing SN_eps?", "\n", "\n", "", "GD", "=", "model", ".", "G_D", "(", "G", ",", "D", ",", "config", ")", "\n", "print", "(", "G", ")", "\n", "print", "(", "D", ")", "\n", "print", "(", "'Number of params in G: {} D: {}'", ".", "format", "(", "\n", "*", "[", "sum", "(", "[", "p", ".", "data", ".", "nelement", "(", ")", "for", "p", "in", "net", ".", "parameters", "(", ")", "]", ")", "for", "net", "in", "[", "G", ",", "D", "]", "]", ")", ")", "\n", "\n", "# Prepare noise and randomly sampled label arrays Allow for different batch sizes in G", "\n", "G_batch_size", "=", "max", "(", "config", "[", "'G_batch_size'", "]", ",", "config", "[", "'batch_size'", "]", ")", "\n", "G_batch_size", "=", "int", "(", "G_batch_size", "*", "config", "[", "\"num_G_accumulations\"", "]", ")", "\n", "z_", ",", "y_", "=", "utils", ".", "prepare_z_y", "(", "G_batch_size", ",", "G", ".", "dim_z", ",", "config", "[", "'n_classes'", "]", ",", "\n", "device", "=", "device", ",", "fp16", "=", "config", "[", "'G_fp16'", "]", ")", "\n", "\n", "\n", "\n", "# Prepare state dict, which holds things like epoch # and itr #", "\n", "state_dict", "=", "{", "'itr'", ":", "0", ",", "'epoch'", ":", "0", ",", "'save_num'", ":", "0", ",", "'save_best_num'", ":", "0", ",", "\n", "'best_IS'", ":", "0", ",", "'best_FID'", ":", "999999", ",", "'config'", ":", "config", "}", "\n", "# If loading from a pre-trained model, load weights", "\n", "if", "config", "[", "'resume'", "]", ":", "\n", "        ", "print", "(", "'Loading weights...'", ")", "\n", "if", "config", "[", "\"epoch_id\"", "]", "!=", "\"\"", ":", "\n", "            ", "epoch_id", "=", "config", "[", "\"epoch_id\"", "]", "\n", "\n", "", "try", ":", "\n", "            ", "print", "(", "\"LOADING EMA\"", ")", "\n", "utils", ".", "load_weights", "(", "G", ",", "D", ",", "state_dict", ",", "\n", "config", "[", "'weights_root'", "]", ",", "experiment_name", ",", "config", ",", "epoch_id", ",", "\n", "config", "[", "'load_weights'", "]", "if", "config", "[", "'load_weights'", "]", "else", "None", ",", "\n", "G_ema", "if", "config", "[", "'ema'", "]", "else", "None", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "\"Ema weight wasn't found, copying G weights to G_ema instead\"", ")", "\n", "utils", ".", "load_weights", "(", "G", ",", "D", ",", "state_dict", ",", "\n", "config", "[", "'weights_root'", "]", ",", "experiment_name", ",", "config", ",", "epoch_id", ",", "\n", "config", "[", "'load_weights'", "]", "if", "config", "[", "'load_weights'", "]", "else", "None", ",", "\n", "None", ")", "\n", "G_ema", ".", "load_state_dict", "(", "G", ".", "state_dict", "(", ")", ")", "\n", "\n", "", "print", "(", "\"loaded weigths\"", ")", "\n", "\n", "\n", "\n", "# If parallel, parallelize the GD module", "\n", "", "if", "config", "[", "'parallel'", "]", ":", "\n", "        ", "GD", "=", "nn", ".", "DataParallel", "(", "GD", ")", "\n", "", "if", "config", "[", "'cross_replica'", "]", ":", "\n", "        ", "patch_replication_callback", "(", "GD", ")", "\n", "# Prepare loggers for stats; metrics holds test metrics, lmetrics holds any desired training metrics.", "\n", "", "test_metrics_fname", "=", "'%s/%s_log.jsonl'", "%", "(", "config", "[", "'logs_root'", "]", ",", "\n", "experiment_name", ")", "\n", "train_metrics_fname", "=", "'%s/%s'", "%", "(", "config", "[", "'logs_root'", "]", ",", "experiment_name", ")", "\n", "print", "(", "'Inception Metrics will be saved to {}'", ".", "format", "(", "test_metrics_fname", ")", ")", "\n", "test_log", "=", "utils", ".", "MetricsLogger", "(", "test_metrics_fname", ",", "\n", "reinitialize", "=", "(", "not", "config", "[", "'resume'", "]", ")", ")", "\n", "print", "(", "'Training Metrics will be saved to {}'", ".", "format", "(", "train_metrics_fname", ")", ")", "\n", "train_log", "=", "utils", ".", "MyLogger", "(", "train_metrics_fname", ",", "\n", "reinitialize", "=", "(", "not", "config", "[", "'resume'", "]", ")", ",", "\n", "logstyle", "=", "config", "[", "'logstyle'", "]", ")", "\n", "# Write metadata", "\n", "utils", ".", "write_metadata", "(", "config", "[", "'logs_root'", "]", ",", "experiment_name", ",", "config", ",", "state_dict", ")", "\n", "# Prepare data; the Discriminator's batch size is all that needs to be passed to the dataloader, as G doesn't require dataloading. Note", "\n", "# that at every loader iteration we pass in enough data to complete a full D iteration (regardless of number of D steps and accumulations)", "\n", "D_batch_size", "=", "(", "config", "[", "'batch_size'", "]", "*", "config", "[", "'num_D_steps'", "]", "\n", "*", "config", "[", "'num_D_accumulations'", "]", ")", "\n", "\n", "\n", "\n", "if", "config", "[", "\"dataset\"", "]", "==", "\"FFHQ\"", ":", "\n", "\n", "        ", "root", "=", "config", "[", "\"data_folder\"", "]", "\n", "root_perm", "=", "config", "[", "\"data_folder\"", "]", "\n", "\n", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "Scale", "(", "config", "[", "\"resolution\"", "]", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "config", "[", "\"resolution\"", "]", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "[", "0.5", ",", "0.5", ",", "0.5", "]", ",", "[", "0.5", ",", "0.5", ",", "0.5", "]", ")", ",", "\n", "]", "\n", ")", "\n", "\n", "batch_size", "=", "config", "[", "'batch_size'", "]", "\n", "print", "(", "\"rooooot:\"", ",", "root", ")", "\n", "dataset", "=", "FFHQ", "(", "root", "=", "root", ",", "transform", "=", "transform", ",", "batch_size", "=", "batch_size", "*", "config", "[", "\"num_D_accumulations\"", "]", ",", "imsize", "=", "config", "[", "\"resolution\"", "]", ")", "\n", "data_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", ",", "shuffle", "=", "True", ",", "drop_last", "=", "True", ")", "\n", "loaders", "=", "[", "data_loader", "]", "\n", "\n", "", "elif", "config", "[", "\"dataset\"", "]", "==", "\"celeba128\"", ":", "\n", "\n", "        ", "root", "=", "config", "[", "\"data_folder\"", "]", "#", "\n", "root_perm", "=", "config", "[", "\"data_folder\"", "]", "\n", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "Scale", "(", "config", "[", "\"resolution\"", "]", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "config", "[", "\"resolution\"", "]", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "[", "0.5", ",", "0.5", ",", "0.5", "]", ",", "[", "0.5", ",", "0.5", ",", "0.5", "]", ")", ",", "\n", "]", "\n", ")", "\n", "\n", "batch_size", "=", "config", "[", "'batch_size'", "]", "\n", "dataset", "=", "Celeba", "(", "root", "=", "root", ",", "transform", "=", "transform", ",", "batch_size", "=", "batch_size", "*", "config", "[", "\"num_D_accumulations\"", "]", ",", "imsize", "=", "config", "[", "\"resolution\"", "]", ")", "\n", "data_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", ",", "shuffle", "=", "True", ",", "drop_last", "=", "True", ")", "\n", "loaders", "=", "[", "data_loader", "]", "\n", "\n", "\n", "", "elif", "config", "[", "\"dataset\"", "]", "==", "\"coco_animals\"", ":", "\n", "\n", "        ", "batch_size", "=", "config", "[", "'batch_size'", "]", "\n", "\n", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "Resize", "(", "config", "[", "\"resolution\"", "]", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "config", "[", "\"resolution\"", "]", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "#transforms.ColorJitter(brightness=0.01, contrast=0.01, saturation=0.01, hue=0.01),", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "classes", "=", "[", "'bird'", ",", "'cat'", ",", "'dog'", ",", "'horse'", ",", "'sheep'", ",", "'cow'", ",", "'elephant'", ",", "'monkey'", ",", "'zebra'", ",", "'giraffe'", "]", "\n", "\n", "root", "=", "config", "[", "\"data_folder\"", "]", "\n", "root_perm", "=", "config", "[", "\"data_folder\"", "]", "\n", "\n", "dataset", "=", "CocoAnimals", "(", "root", "=", "root", ",", "batch_size", "=", "batch_size", "*", "config", "[", "\"num_D_accumulations\"", "]", ",", "classes", "=", "classes", ",", "transform", "=", "transform", ",", "imsize", "=", "config", "[", "\"resolution\"", "]", ")", "\n", "data_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "*", "config", "[", "\"num_D_accumulations\"", "]", ",", "drop_last", "=", "True", ",", "num_workers", "=", "1", ")", "#,shuffle=False)", "\n", "loaders", "=", "[", "data_loader", "]", "\n", "\n", "\n", "", "print", "(", "\"Loaded \"", ",", "config", "[", "\"dataset\"", "]", ")", "\n", "inception_metrics_dict", "=", "{", "\"fid\"", ":", "[", "]", ",", "\"is_mean\"", ":", "[", "]", ",", "\"is_std\"", ":", "[", "]", "}", "\n", "\n", "\n", "# Prepare inception metrics: FID and IS", "\n", "get_inception_metrics", "=", "inception_utils", ".", "prepare_inception_metrics", "(", "config", "[", "'dataset'", "]", ",", "config", "[", "'parallel'", "]", ",", "config", "[", "'no_fid'", "]", ",", "use_torch", "=", "False", ")", "\n", "\n", "# Prepare a fixed z & y to see individual sample evolution throghout training", "\n", "fixed_z", ",", "fixed_y", "=", "utils", ".", "prepare_z_y", "(", "G_batch_size", ",", "G", ".", "dim_z", ",", "\n", "config", "[", "'n_classes'", "]", ",", "device", "=", "device", ",", "\n", "fp16", "=", "config", "[", "'G_fp16'", "]", ")", "\n", "fixed_z", ".", "sample_", "(", ")", "\n", "fixed_y", ".", "sample_", "(", ")", "\n", "\n", "# Loaders are loaded, prepare the training function", "\n", "if", "config", "[", "'which_train_fn'", "]", "==", "'GAN'", ":", "\n", "        ", "train", "=", "train_fns", ".", "GAN_training_function", "(", "G", ",", "D", ",", "GD", ",", "z_", ",", "y_", ",", "\n", "ema", ",", "state_dict", ",", "config", ")", "\n", "# Else, assume debugging and use the dummy train fn", "\n", "", "else", ":", "\n", "        ", "train", "=", "train_fns", ".", "dummy_training_function", "(", ")", "\n", "# Prepare Sample function for use with inception metrics", "\n", "", "sample", "=", "functools", ".", "partial", "(", "utils", ".", "sample", ",", "\n", "G", "=", "(", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "\n", "else", "G", ")", ",", "\n", "z_", "=", "z_", ",", "y_", "=", "y_", ",", "config", "=", "config", ")", "\n", "\n", "\n", "\n", "if", "config", "[", "\"debug\"", "]", ":", "\n", "        ", "loss_steps", "=", "10", "\n", "", "else", ":", "\n", "        ", "loss_steps", "=", "100", "\n", "\n", "", "print", "(", "'Beginning training at epoch %d...'", "%", "state_dict", "[", "'epoch'", "]", ")", "\n", "\n", "\n", "# Train for specified number of epochs, although we mostly track G iterations.", "\n", "warmup_epochs", "=", "config", "[", "\"warmup_epochs\"", "]", "\n", "\n", "\n", "for", "epoch", "in", "range", "(", "state_dict", "[", "'epoch'", "]", ",", "config", "[", "'num_epochs'", "]", ")", ":", "\n", "        ", "if", "config", "[", "\"progress_bar\"", "]", ":", "\n", "            ", "if", "config", "[", "'pbar'", "]", "==", "'mine'", ":", "\n", "                ", "pbar", "=", "utils", ".", "progress", "(", "loaders", "[", "0", "]", ",", "displaytype", "=", "'s1k'", "if", "config", "[", "'use_multiepoch_sampler'", "]", "else", "'eta'", ")", "\n", "", "else", ":", "\n", "                ", "pbar", "=", "tqdm", "(", "loaders", "[", "0", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "pbar", "=", "loaders", "[", "0", "]", "\n", "\n", "", "target_map", "=", "None", "\n", "\n", "\n", "\n", "for", "i", ",", "batch_data", "in", "enumerate", "(", "pbar", ")", ":", "\n", "            ", "x", "=", "batch_data", "[", "0", "]", "\n", "y", "=", "batch_data", "[", "1", "]", "\n", "#H = batch_data[2]", "\n", "\n", "\n", "# Increment the iteration counter", "\n", "state_dict", "[", "'itr'", "]", "+=", "1", "\n", "if", "config", "[", "\"debug\"", "]", "and", "state_dict", "[", "'itr'", "]", ">", "config", "[", "\"stop_it\"", "]", ":", "\n", "                ", "print", "(", "\"code didn't break :)\"", ")", "\n", "#exit(0)", "\n", "break", "#better for profiling", "\n", "# Make sure G and D are in training mode, just in case they got set to eval For D, which typically doesn't have BN, this shouldn't", "\n", "# matter much.", "\n", "", "G", ".", "train", "(", ")", "\n", "D", ".", "train", "(", ")", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "                ", "G_ema", ".", "train", "(", ")", "\n", "", "if", "config", "[", "'D_fp16'", "]", ":", "\n", "                ", "x", ",", "y", "=", "x", ".", "to", "(", "device", ")", ".", "half", "(", ")", ",", "y", ".", "to", "(", "device", ")", ".", "view", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "x", ",", "y", "=", "x", ".", "to", "(", "device", ")", ",", "y", ".", "to", "(", "device", ")", ".", "view", "(", "-", "1", ")", "\n", "", "x", ".", "requires_grad", "=", "False", "\n", "y", ".", "requires_grad", "=", "False", "\n", "\n", "\n", "\n", "if", "config", "[", "\"unet_mixup\"", "]", ":", "\n", "# Here we load cutmix masks for every image in the batch", "\n", "                ", "n_mixed", "=", "int", "(", "x", ".", "size", "(", "0", ")", "/", "config", "[", "\"num_D_accumulations\"", "]", ")", "\n", "target_map", "=", "torch", ".", "cat", "(", "[", "CutMix", "(", "config", "[", "\"resolution\"", "]", ")", ".", "cuda", "(", ")", ".", "view", "(", "1", ",", "1", ",", "config", "[", "\"resolution\"", "]", ",", "config", "[", "\"resolution\"", "]", ")", "for", "_", "in", "range", "(", "n_mixed", ")", "]", ",", "dim", "=", "0", ")", "\n", "\n", "\n", "", "if", "config", "[", "\"slow_mixup\"", "]", "and", "config", "[", "\"full_batch_mixup\"", "]", ":", "\n", "# r_mixup is the chance that we select a mixed batch instead of", "\n", "# a normal batch. This only happens in the setting full_batch_mixup.", "\n", "# Otherwise the mixed loss is calculated on top of the normal batch.", "\n", "                ", "r_mixup", "=", "0.5", "*", "min", "(", "1.0", ",", "state_dict", "[", "\"epoch\"", "]", "/", "warmup_epochs", ")", "# r is at most 50%, after reaching warmup_epochs", "\n", "", "elif", "not", "config", "[", "\"slow_mixup\"", "]", "and", "config", "[", "\"full_batch_mixup\"", "]", ":", "\n", "                ", "r_mixup", "=", "0.5", "\n", "", "else", ":", "\n", "                ", "r_mixup", "=", "0.0", "\n", "\n", "", "metrics", "=", "train", "(", "x", ",", "y", ",", "state_dict", "[", "\"epoch\"", "]", ",", "batch_size", ",", "target_map", "=", "target_map", ",", "r_mixup", "=", "r_mixup", ")", "\n", "\n", "\n", "if", "(", "i", "+", "1", ")", "%", "200", "==", "0", ":", "\n", "# print this just to have some peace of mind that the model is training", "\n", "                ", "print", "(", "\"alive and well at \"", ",", "state_dict", "[", "'itr'", "]", ")", "\n", "\n", "", "if", "(", "i", "+", "1", ")", "%", "20", "==", "0", ":", "\n", "#try:", "\n", "                ", "train_log", ".", "log", "(", "itr", "=", "int", "(", "state_dict", "[", "'itr'", "]", ")", ",", "**", "metrics", ")", "\n", "#except:", "\n", "#    print(\"ouch\")", "\n", "# Every sv_log_interval, log singular values", "\n", "", "if", "(", "config", "[", "'sv_log_interval'", "]", ">", "0", ")", "and", "(", "not", "(", "state_dict", "[", "'itr'", "]", "%", "config", "[", "'sv_log_interval'", "]", ")", ")", ":", "\n", "\n", "                ", "train_log", ".", "log", "(", "itr", "=", "int", "(", "state_dict", "[", "'itr'", "]", ")", ",", "\n", "**", "{", "**", "utils", ".", "get_SVs", "(", "G", ",", "'G'", ")", ",", "**", "utils", ".", "get_SVs", "(", "D", ",", "'D'", ")", "}", ")", "\n", "\n", "# Save weights and copies as configured at specified interval", "\n", "", "if", "not", "(", "state_dict", "[", "'itr'", "]", "%", "config", "[", "'save_every'", "]", ")", ":", "\n", "\n", "                ", "if", "config", "[", "'G_eval_mode'", "]", ":", "\n", "                    ", "print", "(", "'Switchin G to eval mode...'", ")", "\n", "G", ".", "eval", "(", ")", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "                        ", "G_ema", ".", "eval", "(", ")", "\n", "", "train_fns", ".", "save_and_sample", "(", "G", ",", "D", ",", "G_ema", ",", "z_", ",", "y_", ",", "fixed_z", ",", "fixed_y", ",", "\n", "state_dict", ",", "config", ",", "experiment_name", ",", "sample_only", "=", "False", ")", "\n", "\n", "", "", "go_ahead_and_sample", "=", "(", "not", "(", "state_dict", "[", "'itr'", "]", "%", "config", "[", "'sample_every'", "]", ")", ")", "or", "(", "state_dict", "[", "'itr'", "]", "<", "1001", "and", "not", "(", "state_dict", "[", "'itr'", "]", "%", "100", ")", ")", "\n", "\n", "if", "go_ahead_and_sample", ":", "\n", "\n", "                ", "if", "config", "[", "'G_eval_mode'", "]", ":", "\n", "                    ", "print", "(", "'Switchin G to eval mode...'", ")", "\n", "G", ".", "eval", "(", ")", "\n", "if", "config", "[", "'ema'", "]", ":", "\n", "                        ", "G_ema", ".", "eval", "(", ")", "\n", "\n", "", "train_fns", ".", "save_and_sample", "(", "G", ",", "D", ",", "G_ema", ",", "z_", ",", "y_", ",", "fixed_z", ",", "fixed_y", ",", "\n", "state_dict", ",", "config", ",", "experiment_name", ",", "sample_only", "=", "True", ")", "\n", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                        ", "real_batch", "=", "dataset", ".", "fixed_batch", "(", ")", "\n", "", "train_fns", ".", "save_and_sample", "(", "G", ",", "D", ",", "G_ema", ",", "z_", ",", "y_", ",", "fixed_z", ",", "fixed_y", ",", "\n", "state_dict", ",", "config", ",", "experiment_name", ",", "sample_only", "=", "True", ",", "use_real", "=", "True", ",", "real_batch", "=", "real_batch", ")", "\n", "\n", "# also, visualize mixed images and the decoder predicitions", "\n", "if", "config", "[", "\"unet_mixup\"", "]", ":", "\n", "                        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "                            ", "n", "=", "int", "(", "min", "(", "target_map", ".", "size", "(", "0", ")", ",", "fixed_z", ".", "size", "(", "0", ")", "/", "2", ")", ")", "\n", "which_G", "=", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", "\n", "utils", ".", "accumulate_standing_stats", "(", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", ",", "\n", "z_", ",", "y_", ",", "config", "[", "'n_classes'", "]", ",", "\n", "config", "[", "'num_standing_accumulations'", "]", ")", "\n", "\n", "if", "config", "[", "\"dataset\"", "]", "==", "\"coco_animals\"", ":", "\n", "                                ", "real_batch", ",", "real_y", "=", "dataset", ".", "fixed_batch", "(", "return_labels", "=", "True", ")", "\n", "\n", "fixed_Gz", "=", "nn", ".", "parallel", ".", "data_parallel", "(", "which_G", ",", "(", "fixed_z", "[", ":", "n", "]", ",", "which_G", ".", "shared", "(", "real_y", "[", ":", "n", "]", ")", ")", ")", "\n", "mixed", "=", "target_map", "[", ":", "n", "]", "*", "real_batch", "[", ":", "n", "]", "+", "(", "1", "-", "target_map", "[", ":", "n", "]", ")", "*", "fixed_Gz", "\n", "train_fns", ".", "save_and_sample", "(", "G", ",", "D", ",", "G_ema", ",", "z_", "[", ":", "n", "]", ",", "y_", "[", ":", "n", "]", ",", "fixed_z", "[", ":", "n", "]", ",", "fixed_y", "[", ":", "n", "]", ",", "\n", "state_dict", ",", "config", ",", "experiment_name", "+", "\"_mix\"", ",", "sample_only", "=", "True", ",", "use_real", "=", "True", ",", "real_batch", "=", "mixed", ",", "mixed", "=", "True", ",", "target_map", "=", "target_map", "[", ":", "n", "]", ")", "\n", "\n", "", "else", ":", "\n", "                                ", "real_batch", "=", "dataset", ".", "fixed_batch", "(", ")", "\n", "fixed_Gz", "=", "nn", ".", "parallel", ".", "data_parallel", "(", "which_G", ",", "(", "fixed_z", "[", ":", "n", "]", ",", "which_G", ".", "shared", "(", "fixed_z", "[", ":", "n", "]", ")", ")", ")", "#####shouldnt that be fixed_y?", "\n", "\n", "mixed", "=", "target_map", "[", ":", "n", "]", "*", "real_batch", "[", ":", "n", "]", "+", "(", "1", "-", "target_map", "[", ":", "n", "]", ")", "*", "fixed_Gz", "\n", "train_fns", ".", "save_and_sample", "(", "G", ",", "D", ",", "G_ema", ",", "z_", "[", ":", "n", "]", ",", "y_", "[", ":", "n", "]", ",", "fixed_z", "[", ":", "n", "]", ",", "fixed_y", "[", ":", "n", "]", ",", "\n", "state_dict", ",", "config", ",", "experiment_name", "+", "\"_mix\"", ",", "sample_only", "=", "True", ",", "use_real", "=", "True", ",", "real_batch", "=", "mixed", ",", "mixed", "=", "True", ",", "target_map", "=", "target_map", "[", ":", "n", "]", ")", "\n", "\n", "\n", "# Test every specified interval", "\n", "", "", "", "", "", "if", "not", "(", "state_dict", "[", "'itr'", "]", "%", "config", "[", "'test_every'", "]", ")", ":", "\n", "#if state_dict['itr'] % 100 == 0:", "\n", "                ", "if", "config", "[", "'G_eval_mode'", "]", ":", "\n", "                  ", "print", "(", "'Switchin G to eval mode...'", ")", "\n", "\n", "", "is_mean", ",", "is_std", ",", "fid", "=", "train_fns", ".", "test", "(", "G", ",", "D", ",", "G_ema", ",", "z_", ",", "y_", ",", "state_dict", ",", "config", ",", "sample", ",", "get_inception_metrics", ",", "experiment_name", ",", "test_log", ",", "moments", "=", "\"train\"", ")", "\n", "###", "\n", "#  Here, the bn statistics are updated", "\n", "###", "\n", "if", "config", "[", "'accumulate_stats'", "]", ":", "\n", "                    ", "print", "(", "\"accumulate stats\"", ")", "\n", "utils", ".", "accumulate_standing_stats", "(", "G_ema", "if", "config", "[", "'ema'", "]", "and", "config", "[", "'use_ema'", "]", "else", "G", ",", "\n", "z_", ",", "y_", ",", "config", "[", "'n_classes'", "]", ",", "config", "[", "'num_standing_accumulations'", "]", ")", "\n", "\n", "", "inception_metrics_dict", "[", "\"is_mean\"", "]", ".", "append", "(", "(", "state_dict", "[", "'itr'", "]", ",", "is_mean", ")", ")", "\n", "inception_metrics_dict", "[", "\"is_std\"", "]", ".", "append", "(", "(", "state_dict", "[", "'itr'", "]", ",", "is_std", ")", ")", "\n", "inception_metrics_dict", "[", "\"fid\"", "]", ".", "append", "(", "(", "state_dict", "[", "'itr'", "]", ",", "fid", ")", ")", "\n", "\n", "", "if", "(", "i", "+", "1", ")", "%", "loss_steps", "==", "0", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "config", "[", "\"base_root\"", "]", ",", "\"logs/inception_metrics_\"", "+", "config", "[", "\"random_number_string\"", "]", "+", "\".p\"", ")", ",", "\"wb\"", ")", "as", "h", ":", "\n", "                    ", "pickle", ".", "dump", "(", "inception_metrics_dict", ",", "h", ")", "\n", "print", "(", "\"saved FID and IS at\"", ",", "os", ".", "path", ".", "join", "(", "config", "[", "\"base_root\"", "]", ",", "\"logs/inception_metrics_\"", "+", "config", "[", "\"random_number_string\"", "]", "+", "\".p\"", ")", ")", "\n", "\n", "\n", "# Increment epoch counter at end of epoch", "\n", "", "", "", "state_dict", "[", "'epoch'", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.train.main": [[472, 514], ["torchvision.utils.prepare_parser", "vars", "len", "os.path.join", "sorted", "print", "train.run", "utils.prepare_parser.parse_args", "config[].replace", "os.path.isdir", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "print", "vars.keys", "print", "str", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "str().ljust", "int", "str", "numpy.random.rand"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.prepare_parser", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.calculate_inception_moments.run"], ["", "", "def", "main", "(", ")", ":", "\n", "\n", "# parse command line and run", "\n", "    ", "parser", "=", "utils", ".", "prepare_parser", "(", ")", "\n", "config", "=", "vars", "(", "parser", ".", "parse_args", "(", ")", ")", "\n", "\n", "if", "config", "[", "\"gpus\"", "]", "!=", "\"\"", ":", "\n", "        ", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "config", "[", "\"gpus\"", "]", "\n", "", "random_number_string", "=", "str", "(", "int", "(", "np", ".", "random", ".", "rand", "(", ")", "*", "1000000", ")", ")", "+", "\"_\"", "+", "config", "[", "\"id\"", "]", "\n", "config", "[", "\"stop_it\"", "]", "=", "99999999999999", "\n", "\n", "\n", "if", "config", "[", "\"debug\"", "]", ":", "\n", "        ", "config", "[", "\"save_every\"", "]", "=", "30", "\n", "config", "[", "\"sample_every\"", "]", "=", "20", "\n", "config", "[", "\"test_every\"", "]", "=", "20", "\n", "config", "[", "\"num_epochs\"", "]", "=", "1", "\n", "config", "[", "\"stop_it\"", "]", "=", "35", "\n", "config", "[", "\"slow_mixup\"", "]", "=", "False", "\n", "\n", "", "config", "[", "\"num_gpus\"", "]", "=", "len", "(", "config", "[", "\"gpus\"", "]", ".", "replace", "(", "\",\"", ",", "\"\"", ")", ")", "\n", "\n", "config", "[", "\"random_number_string\"", "]", "=", "random_number_string", "\n", "new_root", "=", "os", ".", "path", ".", "join", "(", "config", "[", "\"base_root\"", "]", ",", "random_number_string", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "new_root", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "new_root", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "new_root", ",", "\"samples\"", ")", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "new_root", ",", "\"weights\"", ")", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "new_root", ",", "\"data\"", ")", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "new_root", ",", "\"logs\"", ")", ")", "\n", "print", "(", "\"created \"", ",", "new_root", ")", "\n", "", "config", "[", "\"base_root\"", "]", "=", "new_root", "\n", "\n", "\n", "keys", "=", "sorted", "(", "config", ".", "keys", "(", ")", ")", "\n", "print", "(", "\"config\"", ")", "\n", "for", "k", "in", "keys", ":", "\n", "        ", "print", "(", "str", "(", "k", ")", ".", "ljust", "(", "30", ",", "\".\"", ")", ",", "config", "[", "k", "]", ")", "\n", "\n", "\n", "\n", "", "run", "(", "config", ")", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.identity.forward": [[51, 53], ["None"], "methods", ["None"], ["  ", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "    ", "return", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.SN.__init__": [[56, 69], ["range", "layers.SN.register_buffer", "layers.SN.register_buffer", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "num_svs", ",", "num_itrs", ",", "num_outputs", ",", "transpose", "=", "False", ",", "eps", "=", "1e-12", ")", ":", "\n", "# Number of power iterations per step", "\n", "    ", "self", ".", "num_itrs", "=", "num_itrs", "\n", "# Number of singular values", "\n", "self", ".", "num_svs", "=", "num_svs", "\n", "# Transposed?", "\n", "self", ".", "transpose", "=", "transpose", "\n", "# Epsilon value for avoiding divide-by-0", "\n", "self", ".", "eps", "=", "eps", "\n", "# Register a singular vector for each sv", "\n", "for", "i", "in", "range", "(", "self", ".", "num_svs", ")", ":", "\n", "      ", "self", ".", "register_buffer", "(", "'u%d'", "%", "i", ",", "torch", ".", "randn", "(", "1", ",", "num_outputs", ")", ")", "\n", "self", ".", "register_buffer", "(", "'sv%d'", "%", "i", ",", "torch", ".", "ones", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.SN.u": [[71, 74], ["getattr", "range"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "u", "(", "self", ")", ":", "\n", "    ", "return", "[", "getattr", "(", "self", ",", "'u%d'", "%", "i", ")", "for", "i", "in", "range", "(", "self", ".", "num_svs", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.SN.sv": [[77, 80], ["getattr", "range"], "methods", ["None"], ["", "@", "property", "\n", "def", "sv", "(", "self", ")", ":", "\n", "   ", "return", "[", "getattr", "(", "self", ",", "'sv%d'", "%", "i", ")", "for", "i", "in", "range", "(", "self", ".", "num_svs", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.SN.W_": [[82, 95], ["layers.SN.weight.view", "range", "layers.SN.weight.size", "W_mat.t.t.t", "layers.power_iteration", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.power_iteration"], ["", "def", "W_", "(", "self", ")", ":", "\n", "    ", "W_mat", "=", "self", ".", "weight", ".", "view", "(", "self", ".", "weight", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "if", "self", ".", "transpose", ":", "\n", "      ", "W_mat", "=", "W_mat", ".", "t", "(", ")", "\n", "# Apply num_itrs power iterations", "\n", "", "for", "_", "in", "range", "(", "self", ".", "num_itrs", ")", ":", "\n", "      ", "svs", ",", "us", ",", "vs", "=", "power_iteration", "(", "W_mat", ",", "self", ".", "u", ",", "update", "=", "self", ".", "training", ",", "eps", "=", "self", ".", "eps", ")", "\n", "# Update the svs", "\n", "", "if", "self", ".", "training", ":", "\n", "      ", "with", "torch", ".", "no_grad", "(", ")", ":", "# Make sure to do this in a no_grad() context or you'll get memory leaks!", "\n", "        ", "for", "i", ",", "sv", "in", "enumerate", "(", "svs", ")", ":", "\n", "          ", "self", ".", "sv", "[", "i", "]", "[", ":", "]", "=", "sv", "\n", "", "", "", "return", "self", ".", "weight", "/", "svs", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.SNConv2d.__init__": [[98, 104], ["torch.Conv2d.__init__", "torch.Conv2d.__init__", "torch.Conv2d.__init__", "torch.Conv2d.__init__", "layers.SN.__init__"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__"], ["  ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "True", ",", "\n", "num_svs", "=", "1", ",", "num_itrs", "=", "1", ",", "eps", "=", "1e-12", ")", ":", "\n", "    ", "nn", ".", "Conv2d", ".", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "\n", "padding", ",", "dilation", ",", "groups", ",", "bias", ")", "\n", "SN", ".", "__init__", "(", "self", ",", "num_svs", ",", "num_itrs", ",", "out_channels", ",", "eps", "=", "eps", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.SNConv2d.forward": [[104, 107], ["torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "layers.SNConv2d.W_"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.SN.W_"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "F", ".", "conv2d", "(", "x", ",", "self", ".", "W_", "(", ")", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "", "def", "forward_wo_sn", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.SNConv2d.forward_wo_sn": [[107, 110], ["torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d"], "methods", ["None"], ["", "def", "forward_wo_sn", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "F", ".", "conv2d", "(", "x", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.SNLinear.__init__": [[114, 118], ["torch.Linear.__init__", "torch.Linear.__init__", "torch.Linear.__init__", "torch.Linear.__init__", "layers.SN.__init__"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__"], ["  ", "def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "bias", "=", "True", ",", "\n", "num_svs", "=", "1", ",", "num_itrs", "=", "1", ",", "eps", "=", "1e-12", ")", ":", "\n", "    ", "nn", ".", "Linear", ".", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "bias", ")", "\n", "SN", ".", "__init__", "(", "self", ",", "num_svs", ",", "num_itrs", ",", "out_features", ",", "eps", "=", "eps", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.SNLinear.forward": [[118, 120], ["torch.linear", "torch.linear", "torch.linear", "torch.linear", "layers.SNLinear.W_"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.SN.W_"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "F", ".", "linear", "(", "x", ",", "self", ".", "W_", "(", ")", ",", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.SNEmbedding.__init__": [[126, 136], ["torch.Embedding.__init__", "torch.Embedding.__init__", "torch.Embedding.__init__", "torch.Embedding.__init__", "layers.SN.__init__"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__"], ["  ", "def", "__init__", "(", "self", ",", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "None", ",", "\n", "max_norm", "=", "None", ",", "norm_type", "=", "2", ",", "scale_grad_by_freq", "=", "False", ",", "\n", "sparse", "=", "False", ",", "_weight", "=", "None", ",", "\n", "num_svs", "=", "1", ",", "num_itrs", "=", "1", ",", "eps", "=", "1e-12", ")", ":", "\n", "    ", "nn", ".", "Embedding", ".", "__init__", "(", "self", ",", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ",", "\n", "max_norm", ",", "norm_type", ",", "scale_grad_by_freq", ",", "\n", "sparse", ",", "_weight", ")", "\n", "\n", "\n", "SN", ".", "__init__", "(", "self", ",", "num_svs", ",", "num_itrs", ",", "num_embeddings", ",", "eps", "=", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.SNEmbedding.forward": [[137, 139], ["torch.embedding", "torch.embedding", "torch.embedding", "torch.embedding", "layers.SNEmbedding.W_"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.SN.W_"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "F", ".", "embedding", "(", "x", ",", "self", ".", "W_", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.Attention.__init__": [[148, 159], ["torch.Module.__init__", "layers.Attention.which_conv", "layers.Attention.which_conv", "layers.Attention.which_conv", "layers.Attention.which_conv", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__"], ["  ", "def", "__init__", "(", "self", ",", "ch", ",", "which_conv", "=", "SNConv2d", ",", "name", "=", "'attention'", ")", ":", "\n", "    ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Channel multiplier", "\n", "self", ".", "ch", "=", "ch", "\n", "self", ".", "which_conv", "=", "which_conv", "\n", "self", ".", "theta", "=", "self", ".", "which_conv", "(", "self", ".", "ch", ",", "self", ".", "ch", "//", "8", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "phi", "=", "self", ".", "which_conv", "(", "self", ".", "ch", ",", "self", ".", "ch", "//", "8", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "g", "=", "self", ".", "which_conv", "(", "self", ".", "ch", ",", "self", ".", "ch", "//", "2", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "o", "=", "self", ".", "which_conv", "(", "self", ".", "ch", "//", "2", ",", "self", ".", "ch", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "# Learnable gain parameter", "\n", "self", ".", "gamma", "=", "P", "(", "torch", ".", "tensor", "(", "0.", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.Attention.forward": [[159, 173], ["layers.Attention.theta", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "theta.view.view.view", "phi.view.view.view", "g.view.view.view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "layers.Attention.o", "layers.Attention.phi", "layers.Attention.g", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "theta.view.view.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ")", ":", "\n", "# Apply convs", "\n", "    ", "theta", "=", "self", ".", "theta", "(", "x", ")", "\n", "phi", "=", "F", ".", "max_pool2d", "(", "self", ".", "phi", "(", "x", ")", ",", "[", "2", ",", "2", "]", ")", "\n", "g", "=", "F", ".", "max_pool2d", "(", "self", ".", "g", "(", "x", ")", ",", "[", "2", ",", "2", "]", ")", "\n", "# Perform reshapes", "\n", "theta", "=", "theta", ".", "view", "(", "-", "1", ",", "self", ".", "ch", "//", "8", ",", "x", ".", "shape", "[", "2", "]", "*", "x", ".", "shape", "[", "3", "]", ")", "\n", "phi", "=", "phi", ".", "view", "(", "-", "1", ",", "self", ".", "ch", "//", "8", ",", "x", ".", "shape", "[", "2", "]", "*", "x", ".", "shape", "[", "3", "]", "//", "4", ")", "\n", "g", "=", "g", ".", "view", "(", "-", "1", ",", "self", ".", "ch", "//", "2", ",", "x", ".", "shape", "[", "2", "]", "*", "x", ".", "shape", "[", "3", "]", "//", "4", ")", "\n", "# Matmul and softmax to get attention maps", "\n", "beta", "=", "F", ".", "softmax", "(", "torch", ".", "bmm", "(", "theta", ".", "transpose", "(", "1", ",", "2", ")", ",", "phi", ")", ",", "-", "1", ")", "\n", "# Attention map times g path", "\n", "o", "=", "self", ".", "o", "(", "torch", ".", "bmm", "(", "g", ",", "beta", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "view", "(", "-", "1", ",", "self", ".", "ch", "//", "2", ",", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "3", "]", ")", ")", "\n", "return", "self", ".", "gamma", "*", "o", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.myBN.__init__": [[216, 230], ["torch.Module.__init__", "layers.myBN.register_buffer", "layers.myBN.register_buffer", "layers.myBN.register_buffer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__"], ["  ", "def", "__init__", "(", "self", ",", "num_channels", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ")", ":", "\n", "    ", "super", "(", "myBN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# momentum for updating running stats", "\n", "self", ".", "momentum", "=", "momentum", "\n", "# epsilon to avoid dividing by 0", "\n", "self", ".", "eps", "=", "eps", "\n", "# Momentum", "\n", "self", ".", "momentum", "=", "momentum", "\n", "# Register buffers", "\n", "self", ".", "register_buffer", "(", "'stored_mean'", ",", "torch", ".", "zeros", "(", "num_channels", ")", ")", "\n", "self", ".", "register_buffer", "(", "'stored_var'", ",", "torch", ".", "ones", "(", "num_channels", ")", ")", "\n", "self", ".", "register_buffer", "(", "'accumulation_counter'", ",", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "# Accumulate running means and vars", "\n", "self", ".", "accumulate_standing", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.myBN.reset_stats": [[232, 236], ["None"], "methods", ["None"], ["", "def", "reset_stats", "(", "self", ")", ":", "\n", "    ", "self", ".", "stored_mean", "[", ":", "]", "=", "0", "\n", "self", ".", "stored_var", "[", ":", "]", "=", "0", "\n", "self", ".", "accumulation_counter", "[", ":", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.myBN.forward": [[237, 259], ["layers.manual_bn", "layers.myBN.stored_mean.view", "layers.myBN.stored_var.view", "layers.fused_bn"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.manual_bn", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.fused_bn"], ["", "def", "forward", "(", "self", ",", "x", ",", "gain", ",", "bias", ")", ":", "\n", "    ", "if", "self", ".", "training", ":", "\n", "      ", "out", ",", "mean", ",", "var", "=", "manual_bn", "(", "x", ",", "gain", ",", "bias", ",", "return_mean_var", "=", "True", ",", "eps", "=", "self", ".", "eps", ")", "\n", "# If accumulating standing stats, increment them", "\n", "if", "self", ".", "accumulate_standing", ":", "\n", "        ", "self", ".", "stored_mean", "[", ":", "]", "=", "self", ".", "stored_mean", "+", "mean", ".", "data", "\n", "self", ".", "stored_var", "[", ":", "]", "=", "self", ".", "stored_var", "+", "var", ".", "data", "\n", "self", ".", "accumulation_counter", "+=", "1.0", "\n", "# If not accumulating standing stats, take running averages", "\n", "", "else", ":", "\n", "        ", "self", ".", "stored_mean", "[", ":", "]", "=", "self", ".", "stored_mean", "*", "(", "1", "-", "self", ".", "momentum", ")", "+", "mean", "*", "self", ".", "momentum", "\n", "self", ".", "stored_var", "[", ":", "]", "=", "self", ".", "stored_var", "*", "(", "1", "-", "self", ".", "momentum", ")", "+", "var", "*", "self", ".", "momentum", "\n", "", "return", "out", "\n", "# If not in training mode, use the stored statistics", "\n", "", "else", ":", "\n", "      ", "mean", "=", "self", ".", "stored_mean", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "var", "=", "self", ".", "stored_var", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "# If using standing stats, divide them by the accumulation counter", "\n", "if", "self", ".", "accumulate_standing", ":", "\n", "        ", "mean", "=", "mean", "/", "self", ".", "accumulation_counter", "\n", "var", "=", "var", "/", "self", ".", "accumulation_counter", "\n", "", "return", "fused_bn", "(", "x", ",", "mean", ",", "var", ",", "gain", ",", "bias", ",", "self", ".", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.ccbn.__init__": [[281, 310], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "which_linear", "which_linear", "layers.myBN", "which_linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "which_linear", "which_linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "which_linear", "layers.ccbn.register_buffer", "layers.ccbn.register_buffer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__"], ["  ", "def", "__init__", "(", "self", ",", "output_size", ",", "input_size", ",", "which_linear", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "\n", "cross_replica", "=", "False", ",", "mybn", "=", "False", ",", "norm_style", "=", "'bn'", ",", "self_modulation", "=", "False", ")", ":", "\n", "    ", "super", "(", "ccbn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_size", ",", "self", ".", "input_size", "=", "output_size", ",", "input_size", "\n", "# Prepare gain and bias layers", "\n", "if", "self_modulation", ":", "\n", "        ", "self", ".", "gain", "=", "nn", ".", "Sequential", "(", "which_linear", "(", "input_size", ",", "input_size", ",", "bias", "=", "True", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "which_linear", "(", "input_size", ",", "output_size", ",", "bias", "=", "False", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Sequential", "(", "which_linear", "(", "input_size", ",", "input_size", ",", "bias", "=", "True", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "which_linear", "(", "input_size", ",", "output_size", ",", "bias", "=", "False", ")", ")", "\n", "", "else", ":", "\n", "        ", "self", ".", "gain", "=", "which_linear", "(", "input_size", ",", "output_size", ")", "\n", "self", ".", "bias", "=", "which_linear", "(", "input_size", ",", "output_size", ")", "\n", "# epsilon to avoid dividing by 0", "\n", "", "self", ".", "eps", "=", "eps", "\n", "# Momentum", "\n", "self", ".", "momentum", "=", "momentum", "\n", "# Use cross-replica batchnorm?", "\n", "self", ".", "cross_replica", "=", "cross_replica", "\n", "# Use my batchnorm?", "\n", "self", ".", "mybn", "=", "mybn", "\n", "# Norm style?", "\n", "self", ".", "norm_style", "=", "norm_style", "\n", "\n", "#if self.cross_replica:", "\n", "#  self.bn = SyncBN2d(output_size, eps=self.eps, momentum=self.momentum, affine=False)", "\n", "if", "self", ".", "mybn", ":", "\n", "      ", "self", ".", "bn", "=", "myBN", "(", "output_size", ",", "self", ".", "eps", ",", "self", ".", "momentum", ")", "\n", "", "elif", "self", ".", "norm_style", "in", "[", "'bn'", ",", "'in'", "]", ":", "\n", "      ", "self", ".", "register_buffer", "(", "'stored_mean'", ",", "torch", ".", "zeros", "(", "output_size", ")", ")", "\n", "self", ".", "register_buffer", "(", "'stored_var'", ",", "torch", ".", "ones", "(", "output_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.ccbn.forward": [[312, 332], ["layers.ccbn.bias().view", "y.size", "y.size", "layers.ccbn.bn", "layers.ccbn.bias", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm", "layers.ccbn.gain", "torch.instance_norm", "torch.instance_norm", "torch.instance_norm", "torch.instance_norm", "layers.groupnorm"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.groupnorm"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "# Calculate class-conditional gains and biases", "\n", "    ", "gain", "=", "(", "1", "+", "self", ".", "gain", "(", "y", ")", ")", ".", "view", "(", "y", ".", "size", "(", "0", ")", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "bias", "=", "self", ".", "bias", "(", "y", ")", ".", "view", "(", "y", ".", "size", "(", "0", ")", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "# If using my batchnorm", "\n", "if", "self", ".", "mybn", "or", "self", ".", "cross_replica", ":", "\n", "      ", "return", "self", ".", "bn", "(", "x", ",", "gain", "=", "gain", ",", "bias", "=", "bias", ")", "\n", "# else:", "\n", "", "else", ":", "\n", "      ", "if", "self", ".", "norm_style", "==", "'bn'", ":", "\n", "        ", "out", "=", "F", ".", "batch_norm", "(", "x", ",", "self", ".", "stored_mean", ",", "self", ".", "stored_var", ",", "None", ",", "None", ",", "\n", "self", ".", "training", ",", "0.1", ",", "self", ".", "eps", ")", "\n", "", "elif", "self", ".", "norm_style", "==", "'in'", ":", "\n", "        ", "out", "=", "F", ".", "instance_norm", "(", "x", ",", "self", ".", "stored_mean", ",", "self", ".", "stored_var", ",", "None", ",", "None", ",", "\n", "self", ".", "training", ",", "0.1", ",", "self", ".", "eps", ")", "\n", "", "elif", "self", ".", "norm_style", "==", "'gn'", ":", "\n", "        ", "out", "=", "groupnorm", "(", "x", ",", "self", ".", "normstyle", ")", "\n", "", "elif", "self", ".", "norm_style", "==", "'nonorm'", ":", "\n", "        ", "out", "=", "x", "\n", "", "return", "out", "*", "gain", "+", "bias", "\n", "", "", "def", "extra_repr", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.ccbn.extra_repr": [[332, 336], ["s.format"], "methods", ["None"], ["", "", "def", "extra_repr", "(", "self", ")", ":", "\n", "    ", "s", "=", "'out: {output_size}, in: {input_size},'", "\n", "s", "+=", "' cross_replica={cross_replica}'", "\n", "return", "s", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.bn.__init__": [[340, 364], ["torch.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "SyncBN2d", "layers.myBN", "layers.bn.register_buffer", "layers.bn.register_buffer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__"], ["  ", "def", "__init__", "(", "self", ",", "output_size", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "\n", "cross_replica", "=", "False", ",", "mybn", "=", "False", ")", ":", "\n", "    ", "super", "(", "bn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "# Prepare gain and bias layers", "\n", "self", ".", "gain", "=", "P", "(", "torch", ".", "ones", "(", "output_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "bias", "=", "P", "(", "torch", ".", "zeros", "(", "output_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "# epsilon to avoid dividing by 0", "\n", "self", ".", "eps", "=", "eps", "\n", "# Momentum", "\n", "self", ".", "momentum", "=", "momentum", "\n", "# Use cross-replica batchnorm?", "\n", "self", ".", "cross_replica", "=", "cross_replica", "\n", "# Use my batchnorm?", "\n", "self", ".", "mybn", "=", "mybn", "\n", "\n", "if", "self", ".", "cross_replica", ":", "\n", "      ", "self", ".", "bn", "=", "SyncBN2d", "(", "output_size", ",", "eps", "=", "self", ".", "eps", ",", "momentum", "=", "self", ".", "momentum", ",", "affine", "=", "False", ")", "\n", "", "elif", "mybn", ":", "\n", "      ", "self", ".", "bn", "=", "myBN", "(", "output_size", ",", "self", ".", "eps", ",", "self", ".", "momentum", ")", "\n", "# Register buffers if neither of the above", "\n", "", "else", ":", "\n", "      ", "self", ".", "register_buffer", "(", "'stored_mean'", ",", "torch", ".", "zeros", "(", "output_size", ")", ")", "\n", "self", ".", "register_buffer", "(", "'stored_var'", ",", "torch", ".", "ones", "(", "output_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.bn.forward": [[365, 373], ["layers.bn.gain.view", "layers.bn.bias.view", "layers.bn.bn", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm", "torch.batch_norm"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ")", ":", "\n", "    ", "if", "self", ".", "cross_replica", "or", "self", ".", "mybn", ":", "\n", "      ", "gain", "=", "self", ".", "gain", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "bias", "=", "self", ".", "bias", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "return", "self", ".", "bn", "(", "x", ",", "gain", "=", "gain", ",", "bias", "=", "bias", ")", "\n", "", "else", ":", "\n", "      ", "return", "F", ".", "batch_norm", "(", "x", ",", "self", ".", "stored_mean", ",", "self", ".", "stored_var", ",", "self", ".", "gain", ",", "\n", "self", ".", "bias", ",", "self", ".", "training", ",", "self", ".", "momentum", ",", "self", ".", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.GBlock.__init__": [[382, 403], ["torch.Module.__init__", "layers.GBlock.which_conv", "layers.GBlock.which_conv", "layers.GBlock.which_bn", "layers.GBlock.which_bn", "layers.GBlock.which_conv"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__"], ["  ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "\n", "which_conv", "=", "nn", ".", "Conv2d", ",", "which_bn", "=", "bn", ",", "activation", "=", "None", ",", "\n", "upsample", "=", "None", ")", ":", "\n", "    ", "super", "(", "GBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_channels", ",", "self", ".", "out_channels", "=", "in_channels", ",", "out_channels", "\n", "self", ".", "which_conv", ",", "self", ".", "which_bn", "=", "which_conv", ",", "which_bn", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "upsample", "=", "upsample", "\n", "# Conv layers", "\n", "self", ".", "conv1", "=", "self", ".", "which_conv", "(", "self", ".", "in_channels", ",", "self", ".", "out_channels", ")", "\n", "self", ".", "conv2", "=", "self", ".", "which_conv", "(", "self", ".", "out_channels", ",", "self", ".", "out_channels", ")", "\n", "self", ".", "learnable_sc", "=", "in_channels", "!=", "out_channels", "or", "upsample", "\n", "if", "self", ".", "learnable_sc", ":", "\n", "      ", "self", ".", "conv_sc", "=", "self", ".", "which_conv", "(", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", "\n", "# Batchnorm layers", "\n", "", "self", ".", "bn1", "=", "self", ".", "which_bn", "(", "in_channels", ")", "\n", "self", ".", "bn2", "=", "self", ".", "which_bn", "(", "out_channels", ")", "\n", "# upsample layers", "\n", "self", ".", "upsample", "=", "upsample", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.GBlock.forward": [[404, 415], ["layers.GBlock.activation", "layers.GBlock.conv1", "layers.GBlock.activation", "layers.GBlock.conv2", "layers.GBlock.bn1", "layers.GBlock.upsample", "layers.GBlock.upsample", "layers.GBlock.bn2", "layers.GBlock.conv_sc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "    ", "h", "=", "self", ".", "activation", "(", "self", ".", "bn1", "(", "x", ",", "y", ")", ")", "\n", "if", "self", ".", "upsample", ":", "\n", "      ", "h", "=", "self", ".", "upsample", "(", "h", ")", "\n", "x", "=", "self", ".", "upsample", "(", "x", ")", "\n", "", "h", "=", "self", ".", "conv1", "(", "h", ")", "\n", "h", "=", "self", ".", "activation", "(", "self", ".", "bn2", "(", "h", ",", "y", ")", ")", "\n", "h", "=", "self", ".", "conv2", "(", "h", ")", "\n", "if", "self", ".", "learnable_sc", ":", "\n", "      ", "x", "=", "self", ".", "conv_sc", "(", "x", ")", "\n", "", "return", "h", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.GBlock2.__init__": [[417, 438], ["torch.Module.__init__", "layers.GBlock2.which_conv", "layers.GBlock2.which_conv", "layers.GBlock2.which_conv"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__"], ["  ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "\n", "which_conv", "=", "nn", ".", "Conv2d", ",", "which_bn", "=", "bn", ",", "activation", "=", "None", ",", "\n", "upsample", "=", "None", ",", "skip_connection", "=", "True", ")", ":", "\n", "    ", "super", "(", "GBlock2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_channels", ",", "self", ".", "out_channels", "=", "in_channels", ",", "out_channels", "\n", "self", ".", "which_conv", ",", "self", ".", "which_bn", "=", "which_conv", ",", "which_bn", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "upsample", "=", "upsample", "\n", "\n", "# Conv layers", "\n", "self", ".", "conv1", "=", "self", ".", "which_conv", "(", "self", ".", "in_channels", ",", "self", ".", "out_channels", ")", "\n", "self", ".", "conv2", "=", "self", ".", "which_conv", "(", "self", ".", "out_channels", ",", "self", ".", "out_channels", ")", "\n", "self", ".", "learnable_sc", "=", "in_channels", "!=", "out_channels", "or", "upsample", "\n", "if", "self", ".", "learnable_sc", ":", "\n", "      ", "self", ".", "conv_sc", "=", "self", ".", "which_conv", "(", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", "\n", "\n", "# upsample layers", "\n", "", "self", ".", "upsample", "=", "upsample", "\n", "self", ".", "skip_connection", "=", "skip_connection", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.GBlock2.forward": [[439, 458], ["layers.GBlock2.activation", "layers.GBlock2.conv1", "layers.GBlock2.activation", "layers.GBlock2.conv2", "layers.GBlock2.upsample", "layers.GBlock2.upsample", "layers.GBlock2.conv_sc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "h", "=", "self", ".", "activation", "(", "x", ")", "\n", "if", "self", ".", "upsample", ":", "\n", "      ", "h", "=", "self", ".", "upsample", "(", "h", ")", "\n", "x", "=", "self", ".", "upsample", "(", "x", ")", "\n", "", "h", "=", "self", ".", "conv1", "(", "h", ")", "\n", "#print(h.size())", "\n", "h", "=", "self", ".", "activation", "(", "h", ")", "\n", "h", "=", "self", ".", "conv2", "(", "h", ")", "\n", "# may be changed to h = self.conv2.forward_wo_sn(h)", "\n", "if", "self", ".", "learnable_sc", ":", "\n", "      ", "x", "=", "self", ".", "conv_sc", "(", "x", ")", "\n", "\n", "\n", "", "if", "self", ".", "skip_connection", ":", "\n", "        ", "out", "=", "h", "+", "x", "\n", "", "else", ":", "\n", "        ", "out", "=", "h", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.DBlock.__init__": [[462, 480], ["torch.Module.__init__", "layers.DBlock.which_conv", "layers.DBlock.which_conv", "layers.DBlock.which_conv"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__"], ["  ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "which_conv", "=", "SNConv2d", ",", "wide", "=", "True", ",", "\n", "preactivation", "=", "False", ",", "activation", "=", "None", ",", "downsample", "=", "None", ",", ")", ":", "\n", "    ", "super", "(", "DBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", ",", "self", ".", "out_channels", "=", "in_channels", ",", "out_channels", "\n", "# If using wide D (as in SA-GAN and BigGAN), change the channel pattern", "\n", "self", ".", "hidden_channels", "=", "self", ".", "out_channels", "if", "wide", "else", "self", ".", "in_channels", "\n", "self", ".", "which_conv", "=", "which_conv", "\n", "self", ".", "preactivation", "=", "preactivation", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "downsample", "=", "downsample", "\n", "\n", "# Conv layers", "\n", "self", ".", "conv1", "=", "self", ".", "which_conv", "(", "self", ".", "in_channels", ",", "self", ".", "hidden_channels", ")", "\n", "self", ".", "conv2", "=", "self", ".", "which_conv", "(", "self", ".", "hidden_channels", ",", "self", ".", "out_channels", ")", "\n", "self", ".", "learnable_sc", "=", "True", "if", "(", "in_channels", "!=", "out_channels", ")", "or", "downsample", "else", "False", "\n", "if", "self", ".", "learnable_sc", ":", "\n", "      ", "self", ".", "conv_sc", "=", "self", ".", "which_conv", "(", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", "\n", "", "", "def", "shortcut", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.DBlock.shortcut": [[480, 492], ["layers.DBlock.conv_sc", "layers.DBlock.downsample", "layers.DBlock.downsample", "layers.DBlock.conv_sc"], "methods", ["None"], ["", "", "def", "shortcut", "(", "self", ",", "x", ")", ":", "\n", "    ", "if", "self", ".", "preactivation", ":", "\n", "      ", "if", "self", ".", "learnable_sc", ":", "\n", "        ", "x", "=", "self", ".", "conv_sc", "(", "x", ")", "\n", "", "if", "self", ".", "downsample", ":", "\n", "        ", "x", "=", "self", ".", "downsample", "(", "x", ")", "\n", "", "", "else", ":", "\n", "      ", "if", "self", ".", "downsample", ":", "\n", "        ", "x", "=", "self", ".", "downsample", "(", "x", ")", "\n", "", "if", "self", ".", "learnable_sc", ":", "\n", "        ", "x", "=", "self", ".", "conv_sc", "(", "x", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.DBlock.forward": [[493, 507], ["layers.DBlock.conv1", "layers.DBlock.conv2", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "layers.DBlock.activation", "layers.DBlock.downsample", "layers.DBlock.shortcut"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.DBlock.shortcut"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "if", "self", ".", "preactivation", ":", "\n", "# h = self.activation(x) # NOT TODAY SATAN", "\n", "# Andy's note: This line *must* be an out-of-place ReLU or it", "\n", "#              will negatively affect the shortcut connection.", "\n", "      ", "h", "=", "F", ".", "relu", "(", "x", ")", "\n", "", "else", ":", "\n", "      ", "h", "=", "x", "\n", "", "h", "=", "self", ".", "conv1", "(", "h", ")", "\n", "h", "=", "self", ".", "conv2", "(", "self", ".", "activation", "(", "h", ")", ")", "\n", "if", "self", ".", "downsample", ":", "\n", "      ", "h", "=", "self", ".", "downsample", "(", "h", ")", "\n", "\n", "", "return", "h", "+", "self", ".", "shortcut", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.proj": [[15, 17], ["torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "y.t", "x.t"], "function", ["None"], ["def", "proj", "(", "x", ",", "y", ")", ":", "\n", "  ", "return", "torch", ".", "mm", "(", "y", ",", "x", ".", "t", "(", ")", ")", "*", "y", "/", "torch", ".", "mm", "(", "y", ",", "y", ".", "t", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.gram_schmidt": [[19, 23], ["layers.proj"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.proj"], ["", "def", "gram_schmidt", "(", "x", ",", "ys", ")", ":", "\n", "  ", "for", "y", "in", "ys", ":", "\n", "    ", "x", "=", "x", "-", "proj", "(", "x", ",", "y", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.power_iteration": [[25, 48], ["enumerate", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.normalize", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.normalize", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "layers.gram_schmidt", "W.t", "layers.gram_schmidt", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "F.normalize.t", "W.t"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.gram_schmidt", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.gram_schmidt"], ["", "def", "power_iteration", "(", "W", ",", "u_", ",", "update", "=", "True", ",", "eps", "=", "1e-12", ")", ":", "\n", "# Lists holding singular vectors and values", "\n", "  ", "us", ",", "vs", ",", "svs", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "u", "in", "enumerate", "(", "u_", ")", ":", "\n", "# Run one step of the power iteration", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "      ", "v", "=", "torch", ".", "matmul", "(", "u", ",", "W", ")", "\n", "# Run Gram-Schmidt to subtract components of all other singular vectors", "\n", "v", "=", "F", ".", "normalize", "(", "gram_schmidt", "(", "v", ",", "vs", ")", ",", "eps", "=", "eps", ")", "\n", "# Add to the list", "\n", "vs", "+=", "[", "v", "]", "\n", "# Update the other singular vector", "\n", "u", "=", "torch", ".", "matmul", "(", "v", ",", "W", ".", "t", "(", ")", ")", "\n", "# Run Gram-Schmidt to subtract components of all other singular vectors", "\n", "u", "=", "F", ".", "normalize", "(", "gram_schmidt", "(", "u", ",", "us", ")", ",", "eps", "=", "eps", ")", "\n", "# Add to the list", "\n", "us", "+=", "[", "u", "]", "\n", "if", "update", ":", "\n", "        ", "u_", "[", "i", "]", "[", ":", "]", "=", "u", "\n", "# Compute this singular value and add it to the list", "\n", "", "", "svs", "+=", "[", "torch", ".", "squeeze", "(", "torch", ".", "matmul", "(", "torch", ".", "matmul", "(", "v", ",", "W", ".", "t", "(", ")", ")", ",", "u", ".", "t", "(", ")", ")", ")", "]", "\n", "#svs += [torch.sum(F.linear(u, W.transpose(0, 1)) * v)]", "\n", "", "return", "svs", ",", "us", ",", "vs", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.fused_bn": [[176, 189], ["torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt"], "function", ["None"], ["", "", "def", "fused_bn", "(", "x", ",", "mean", ",", "var", ",", "gain", "=", "None", ",", "bias", "=", "None", ",", "eps", "=", "1e-5", ")", ":", "\n", "# Apply scale and shift--if gain and bias are provided, fuse them here", "\n", "# Prepare scale", "\n", "  ", "scale", "=", "torch", ".", "rsqrt", "(", "var", "+", "eps", ")", "\n", "# If a gain is provided, use it", "\n", "if", "gain", "is", "not", "None", ":", "\n", "    ", "scale", "=", "scale", "*", "gain", "\n", "# Prepare shift", "\n", "", "shift", "=", "mean", "*", "scale", "\n", "# If bias is provided, use it", "\n", "if", "bias", "is", "not", "None", ":", "\n", "    ", "shift", "=", "shift", "-", "bias", "\n", "", "return", "x", "*", "scale", "-", "shift", "\n", "#return ((x - mean) / ((var + eps) ** 0.5)) * gain + bias # The unfused way.", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.manual_bn": [[194, 212], ["x.float", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "var.type.type", "m.type.type", "x.type", "x.type", "layers.fused_bn", "layers.fused_bn", "m.type.squeeze", "var.type.squeeze"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.fused_bn", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.fused_bn"], ["", "def", "manual_bn", "(", "x", ",", "gain", "=", "None", ",", "bias", "=", "None", ",", "return_mean_var", "=", "False", ",", "eps", "=", "1e-5", ")", ":", "\n", "# Cast x to float32 if necessary", "\n", "  ", "float_x", "=", "x", ".", "float", "(", ")", "\n", "# Calculate expected value of x (m) and expected value of x**2 (m2)", "\n", "# Mean of x", "\n", "m", "=", "torch", ".", "mean", "(", "float_x", ",", "[", "0", ",", "2", ",", "3", "]", ",", "keepdim", "=", "True", ")", "\n", "# Mean of x squared", "\n", "m2", "=", "torch", ".", "mean", "(", "float_x", "**", "2", ",", "[", "0", ",", "2", ",", "3", "]", ",", "keepdim", "=", "True", ")", "\n", "# Calculate variance as mean of squared minus mean squared.", "\n", "var", "=", "(", "m2", "-", "m", "**", "2", ")", "\n", "# Cast back to float 16 if necessary", "\n", "var", "=", "var", ".", "type", "(", "x", ".", "type", "(", ")", ")", "\n", "m", "=", "m", ".", "type", "(", "x", ".", "type", "(", ")", ")", "\n", "# Return mean and variance for updating stored mean/var if requested", "\n", "if", "return_mean_var", ":", "\n", "    ", "return", "fused_bn", "(", "x", ",", "m", ",", "var", ",", "gain", ",", "bias", ",", "eps", ")", ",", "m", ".", "squeeze", "(", ")", ",", "var", ".", "squeeze", "(", ")", "\n", "", "else", ":", "\n", "    ", "return", "fused_bn", "(", "x", ",", "m", ",", "var", ",", "gain", ",", "bias", ",", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.groupnorm": [[262, 274], ["torch.group_norm", "int", "max", "int", "norm_style.split", "int", "norm_style.split"], "function", ["None"], ["", "", "", "def", "groupnorm", "(", "x", ",", "norm_style", ")", ":", "\n", "# If number of channels specified in norm_style:", "\n", "  ", "if", "'ch'", "in", "norm_style", ":", "\n", "    ", "ch", "=", "int", "(", "norm_style", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", "\n", "groups", "=", "max", "(", "int", "(", "x", ".", "shape", "[", "1", "]", ")", "//", "ch", ",", "1", ")", "\n", "# If number of groups specified in norm style", "\n", "", "elif", "'grp'", "in", "norm_style", ":", "\n", "    ", "groups", "=", "int", "(", "norm_style", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", "\n", "# If neither, default to groups = 16", "\n", "", "else", ":", "\n", "    ", "groups", "=", "16", "\n", "", "return", "F", ".", "group_norm", "(", "x", ",", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.calculate_inception_moments.prepare_parser": [[24, 53], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "prepare_parser", "(", ")", ":", "\n", "  ", "usage", "=", "'Calculate and store inception metrics.'", "\n", "parser", "=", "ArgumentParser", "(", "description", "=", "usage", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--dataset'", ",", "type", "=", "str", ",", "default", "=", "'I128_hdf5'", ",", "\n", "help", "=", "'Which Dataset to train on, out of I128, I256, C10, C100...'", "\n", "'Append _hdf5 to use the hdf5 version of the dataset. (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--data_root'", ",", "type", "=", "str", ",", "default", "=", "'data'", ",", "\n", "help", "=", "'Default location where data is stored (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Default overall batchsize (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--parallel'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Train with multiple GPUs (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--augment'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Augment with random crops and flips (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_workers'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'Number of dataloader workers (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--shuffle'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Shuffle the data? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Random seed to use.'", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.calculate_inception_moments.run": [[55, 143], ["inception_utils.load_inception_net", "range", "print", "inception_utils.calculate_inception_score", "print", "print", "print", "print", "numpy.savez", "os.path.join", "os.path.join", "torchvision.transforms.Compose", "PyTorchDatasets.FFHQ", "torch.utils.data.DataLoader", "enumerate", "numpy.concatenate", "numpy.mean", "numpy.cov", "torchvision.transforms.Compose", "PyTorchDatasets.CocoAnimals3", "torch.utils.data.DataLoader", "utils.get_data_loaders", "torchvision.utils.get_data_loaders", "tqdm.tqdm", "x.to.to", "x.to.size", "config[].strip", "torchvision.transforms.Scale", "torchvision.transforms.CenterCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.no_grad", "torch.no_grad", "torch.no_grad", "inception_utils.load_inception_net.", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "numpy.asarray", "numpy.asarray", "numpy.asarray", "pool_val.cpu", "torch.softmax().cpu", "y.cpu", "torch.softmax"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.load_inception_net", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.calculate_inception_score", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.get_data_loaders", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.get_data_loaders", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.to"], ["", "def", "run", "(", "config", ")", ":", "\n", "# Get loader", "\n", "  ", "config", "[", "'drop_last'", "]", "=", "False", "\n", "\n", "if", "config", "[", "\"dataset\"", "]", "==", "\"FFHQ\"", ":", "\n", "      ", "imsize", "=", "256", "\n", "\n", "root", "=", "os", ".", "path", ".", "join", "(", "os", ".", "environ", "[", "\"SSD\"", "]", ",", "\"images256x256\"", ")", "\n", "root_perm", "=", "os", ".", "path", ".", "join", "(", "os", ".", "environ", "[", "\"SSD\"", "]", ",", "\"images256x256\"", ")", "\n", "\n", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "Scale", "(", "imsize", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "imsize", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "[", "0.5", ",", "0.5", ",", "0.5", "]", ",", "[", "0.5", ",", "0.5", ",", "0.5", "]", ")", ",", "\n", "]", "\n", ")", "\n", "\n", "batch_size", "=", "100", "#config['batch_size']", "\n", "dataset", "=", "FFHQ", "(", "root", "=", "root", ",", "transform", "=", "transform", ",", "test_mode", "=", "False", ")", "\n", "data_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", ",", "shuffle", "=", "True", ",", "drop_last", "=", "True", ")", "\n", "loaders", "=", "[", "data_loader", "]", "\n", "\n", "", "elif", "config", "[", "\"dataset\"", "]", "==", "\"coco\"", ":", "\n", "\n", "      ", "imsize", "=", "128", "\n", "batch_size", "=", "config", "[", "'batch_size'", "]", "\n", "\n", "transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "Resize", "(", "imsize", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "imsize", ")", ",", "\n", "#transforms.RandomHorizontalFlip(),", "\n", "#transforms.ColorJitter(brightness=0.01, contrast=0.01, saturation=0.01, hue=0.01),", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "\n", "classes", "=", "[", "'bird'", ",", "'cat'", ",", "'dog'", ",", "'horse'", ",", "'sheep'", ",", "'cow'", ",", "'elephant'", ",", "'monkey'", ",", "'zebra'", ",", "'giraffe'", "]", "\n", "\n", "\n", "root", "=", "None", "\n", "root_perm", "=", "None", "\n", "dataset", "=", "CocoAnimals", "(", "root", "=", "root", ",", "batch_size", "=", "batch_size", ",", "classes", "=", "classes", ",", "transform", "=", "transform", ",", "masks", "=", "False", ",", "return_all", "=", "True", ",", "test_mode", "=", "False", ",", "imsize", "=", "imsize", ")", "\n", "data_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", ",", "drop_last", "=", "True", ",", "num_workers", "=", "1", ",", "shuffle", "=", "True", ")", "#,shuffle=False)", "\n", "loaders", "=", "[", "data_loader", "]", "\n", "\n", "", "else", ":", "\n", "      ", "loaders", "=", "utils", ".", "get_data_loaders", "(", "**", "config", ")", "\n", "\n", "# Load inception net", "\n", "", "net", "=", "inception_utils", ".", "load_inception_net", "(", "parallel", "=", "config", "[", "'parallel'", "]", ")", "\n", "pool", ",", "logits", ",", "labels", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "device", "=", "'cuda'", "\n", "used_samples", "=", "0", "\n", "for", "e", "in", "range", "(", "2", ")", ":", "\n", "    ", "for", "i", ",", "batch_data", "in", "enumerate", "(", "tqdm", "(", "loaders", "[", "0", "]", ")", ")", ":", "\n", "\n", "      ", "x", "=", "batch_data", "[", "0", "]", "\n", "y", "=", "batch_data", "[", "1", "]", "\n", "x", "=", "x", ".", "to", "(", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "pool_val", ",", "logits_val", "=", "net", "(", "x", ")", "\n", "pool", "+=", "[", "np", ".", "asarray", "(", "pool_val", ".", "cpu", "(", ")", ")", "]", "\n", "logits", "+=", "[", "np", ".", "asarray", "(", "F", ".", "softmax", "(", "logits_val", ",", "1", ")", ".", "cpu", "(", ")", ")", "]", "\n", "labels", "+=", "[", "np", ".", "asarray", "(", "y", ".", "cpu", "(", ")", ")", "]", "\n", "\n", "", "used_samples", "+=", "x", ".", "size", "(", "0", ")", "\n", "if", "used_samples", ">=", "50000", ":", "\n", "        ", "break", "\n", "\n", "", "", "", "pool", ",", "logits", ",", "labels", "=", "[", "np", ".", "concatenate", "(", "item", ",", "0", ")", "for", "item", "in", "[", "pool", ",", "logits", ",", "labels", "]", "]", "\n", "# uncomment to save pool, logits, and labels to disk", "\n", "# print('Saving pool, logits, and labels to disk...')", "\n", "# np.savez(config['dataset']+'_inception_activations.npz',", "\n", "#           {'pool': pool, 'logits': logits, 'labels': labels})", "\n", "# Calculate inception metrics and report them", "\n", "print", "(", "'Calculating inception metrics...'", ")", "\n", "IS_mean", ",", "IS_std", "=", "inception_utils", ".", "calculate_inception_score", "(", "logits", ")", "\n", "print", "(", "'Training data from dataset %s has IS of %5.5f +/- %5.5f'", "%", "(", "config", "[", "'dataset'", "]", ",", "IS_mean", ",", "IS_std", ")", ")", "\n", "# Prepare mu and sigma, save to disk. Remove \"hdf5\" by default", "\n", "# (the FID code also knows to strip \"hdf5\")", "\n", "print", "(", "'Calculating means and covariances...'", ")", "\n", "print", "(", "pool", ".", "shape", ")", "\n", "mu", ",", "sigma", "=", "np", ".", "mean", "(", "pool", ",", "axis", "=", "0", ")", ",", "np", ".", "cov", "(", "pool", ",", "rowvar", "=", "False", ")", "\n", "print", "(", "'Saving calculated means and covariances to disk...'", ")", "\n", "np", ".", "savez", "(", "config", "[", "'dataset'", "]", ".", "strip", "(", "'_hdf5'", ")", "+", "'_inception_moments.npz'", ",", "**", "{", "'mu'", ":", "mu", ",", "'sigma'", ":", "sigma", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.calculate_inception_moments.main": [[144, 150], ["calculate_inception_moments.prepare_parser", "vars", "print", "calculate_inception_moments.run", "prepare_parser.parse_args"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.prepare_parser", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.calculate_inception_moments.run"], ["", "def", "main", "(", ")", ":", "\n", "# parse command line", "\n", "  ", "parser", "=", "prepare_parser", "(", ")", "\n", "config", "=", "vars", "(", "parser", ".", "parse_args", "(", ")", ")", "\n", "print", "(", "config", ")", "\n", "run", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.CocoAnimals.__init__": [[15, 74], ["len", "len", "print", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "print", "torchvision.transforms.ToTensor", "int", "sum", "enumerate", "range", "torch.tensor().long().cuda", "os.path.join", "os.listdir", "len", "open", "pickle.load", "open", "pickle.load", "numpy.random.randint", "random.choice", "os.path.join", "PyTorchDatasets.CocoAnimals.fixed_files.append", "PyTorchDatasets.CocoAnimals.fixed_impaths.append", "PyTorchDatasets.CocoAnimals.fixed_labels.append", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "os.path.join", "len", "os.path.join", "zip", "len", "os.path.join", "os.path.join", "torch.tensor().long", "torch.tensor"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", "=", "None", ",", "batch_size", "=", "80", ",", "classes", "=", "None", ",", "transform", "=", "None", ",", "return_all", "=", "False", ",", "test_mode", "=", "False", ",", "imsize", "=", "128", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "len", "(", "classes", ")", "\n", "if", "root", "==", "None", ":", "\n", "            ", "root", "=", "os", ".", "path", ".", "join", "(", "os", ".", "environ", "[", "\"SSD\"", "]", ",", "\"animals\"", ")", "\n", "\n", "", "self", ".", "root", "=", "root", "\n", "self", ".", "return_all", "=", "return_all", "\n", "self", ".", "names", "=", "classes", "\n", "self", ".", "nclasses", "=", "len", "(", "classes", ")", "\n", "print", "(", "self", ".", "names", ")", "\n", "self", ".", "mask_trans", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "Resize", "(", "imsize", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "imsize", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", ")", "\n", "self", ".", "fixed_transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "Resize", "(", "imsize", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "imsize", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "\n", "self", ".", "image_files", "=", "[", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "n", ")", ")", "for", "n", "in", "self", ".", "names", "]", "\n", "self", ".", "lenghts", "=", "[", "len", "(", "f", ")", "for", "f", "in", "self", ".", "image_files", "]", "\n", "\n", "print", "(", "\"images per class \"", ",", "self", ".", "lenghts", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "totensor", "=", "transforms", ".", "ToTensor", "(", ")", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n", "self", ".", "k", "=", "int", "(", "batch_size", "/", "self", ".", "num_classes", ")", "\n", "self", ".", "length", "=", "sum", "(", "[", "len", "(", "folder", ")", "for", "folder", "in", "self", ".", "image_files", "]", ")", "\n", "\n", "all_files", "=", "[", "[", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "n", ",", "f", ")", "for", "f", "in", "files", "]", "for", "n", ",", "files", "in", "zip", "(", "self", ".", "names", ",", "self", ".", "image_files", ")", "]", "\n", "self", ".", "all_files", "=", "[", "]", "\n", "self", ".", "all_labels", "=", "[", "]", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "all_files", ")", ":", "\n", "            ", "self", ".", "all_files", "+=", "f", "\n", "self", ".", "all_labels", "+=", "[", "i", "]", "*", "len", "(", "f", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "\"merged_bbdict_v2.p\"", ")", ",", "\"rb\"", ")", "as", "h", ":", "\n", "            ", "self", ".", "bbox", "=", "pickle", ".", "load", "(", "h", ")", "\n", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "\"coco_ann_dict.p\"", ")", ",", "\"rb\"", ")", "as", "h", ":", "\n", "            ", "self", ".", "mask_coco", "=", "pickle", ".", "load", "(", "h", ")", "\n", "\n", "", "self", ".", "fixed_files", "=", "[", "]", "\n", "self", ".", "fixed_impaths", "=", "[", "]", "\n", "self", ".", "fixed_labels", "=", "[", "]", "\n", "\n", "for", "_", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "id", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "nclasses", ")", "\n", "file", "=", "random", ".", "choice", "(", "self", ".", "image_files", "[", "id", "]", ")", "\n", "image_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "names", "[", "id", "]", ",", "file", ")", "\n", "self", ".", "fixed_files", ".", "append", "(", "file", ")", "\n", "self", ".", "fixed_impaths", ".", "append", "(", "image_path", ")", "\n", "self", ".", "fixed_labels", ".", "append", "(", "id", ")", "\n", "", "self", ".", "fixed_labels", "=", "torch", ".", "tensor", "(", "self", ".", "fixed_labels", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.CocoAnimals.__len__": [[76, 79], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "# Here, we need to return the number of samples in this dataset.", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.CocoAnimals.fixed_batch": [[80, 87], ["torch.stack", "torch.stack", "[].cuda", "[].cuda", "zip", "zip", "PyTorchDatasets.CocoAnimals.random_batch", "PyTorchDatasets.CocoAnimals.random_batch"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.Celeba.random_batch", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.Celeba.random_batch"], ["", "def", "fixed_batch", "(", "self", ",", "return_labels", "=", "False", ")", ":", "\n", "        ", "if", "return_labels", "==", "True", ":", "\n", "            ", "images", "=", "torch", ".", "stack", "(", "[", "self", ".", "random_batch", "(", "0", ",", "0", ",", "file", "=", "fi", ",", "image_path", "=", "im", ")", "[", "0", "]", ".", "cuda", "(", ")", "for", "fi", ",", "im", "in", "zip", "(", "self", ".", "fixed_files", ",", "self", ".", "fixed_impaths", ")", "]", ")", "\n", "labels", "=", "self", ".", "fixed_labels", "\n", "return", "images", ",", "labels", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "stack", "(", "[", "self", ".", "random_batch", "(", "0", ",", "0", ",", "file", "=", "fi", ",", "image_path", "=", "im", ")", "[", "0", "]", ".", "cuda", "(", ")", "for", "fi", ",", "im", "in", "zip", "(", "self", ".", "fixed_files", ",", "self", ".", "fixed_impaths", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.CocoAnimals.single_batch": [[88, 93], ["torch.stack", "torch.stack", "PyTorchDatasets.CocoAnimals.__getitem__", "numpy.random.randint", "range", "e[].cuda", "e[].long().cuda", "e[].long"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__getitem__"], ["", "", "def", "single_batch", "(", "self", ")", ":", "\n", "        ", "w", "=", "[", "self", ".", "__getitem__", "(", "np", ".", "random", ".", "randint", "(", "self", ".", "length", ")", ")", "for", "_", "in", "range", "(", "self", ".", "batch_size", ")", "]", "\n", "x", "=", "torch", ".", "stack", "(", "[", "e", "[", "0", "]", ".", "cuda", "(", ")", "for", "e", "in", "w", "]", ")", "\n", "y", "=", "torch", ".", "stack", "(", "[", "e", "[", "1", "]", ".", "long", "(", ")", ".", "cuda", "(", ")", "for", "e", "in", "w", "]", ")", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.CocoAnimals.random_batch": [[94, 190], ["PIL.Image.open().convert", "random.choice.strip", "torch.LongTensor", "numpy.random.randint", "random.choice", "os.path.join", "random.choice.strip.isdigit", "isinstance", "max", "min", "PyTorchDatasets.CocoAnimals.transform", "PIL.Image.open", "len", "random.choice", "min", "max", "max", "max", "max", "PyTorchDatasets.CocoAnimals.crop", "PyTorchDatasets.CocoAnimals.fixed_transform", "random.choice.strip", "numpy.arange", "float", "float", "float", "float", "float", "float", "max", "max", "max", "random.choice.strip", "len", "numpy.random.rand"], "methods", ["None"], ["", "def", "random_batch", "(", "self", ",", "index", ",", "id", "=", "0", ",", "file", "=", "None", ",", "image_path", "=", "None", ")", ":", "\n", "# this function adds some data augmentation by cropping and resizing the", "\n", "# images with the help of the bounding boxes. In particular we make sure", "\n", "# that the animal is still in the frame if we crop randomly and resize.", "\n", "\n", "        ", "if", "image_path", "==", "None", ":", "\n", "            ", "id", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "nclasses", ")", "\n", "file", "=", "random", ".", "choice", "(", "self", ".", "image_files", "[", "id", "]", ")", "\n", "image_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "names", "[", "id", "]", ",", "file", ")", "\n", "\n", "#image_name = self.random.choice(self.image_files[random.choice(self.names)][\"image_files\"])", "\n", "fixed", "=", "False", "\n", "usebbx", "=", "True", "\n", "", "else", ":", "\n", "            ", "fixed", "=", "True", "\n", "usebbx", "=", "False", "\n", "\n", "", "img", "=", "Image", ".", "open", "(", "image_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n", "w", ",", "h", "=", "img", ".", "size", "\n", "im_id", "=", "file", ".", "strip", "(", "\".jpg\"", ")", "\n", "if", "usebbx", ":", "\n", "            ", "if", "im_id", ".", "isdigit", "(", ")", ":", "\n", "                ", "origin", "=", "\"coco\"", "\n", "bbox", "=", "{", "\"bbox\"", ":", "self", ".", "mask_coco", "[", "file", "]", "[", "\"bbox\"", "]", ",", "\"label\"", ":", "self", ".", "mask_coco", "[", "file", "]", "[", "\"category_id\"", "]", "}", "\n", "", "else", ":", "\n", "                ", "origin", "=", "\"oi\"", "\n", "bbox", "=", "self", ".", "bbox", "[", "file", ".", "strip", "(", "\".jpg\"", ")", "]", "\n", "\n", "", "if", "len", "(", "bbox", "[", "\"bbox\"", "]", ")", ">", "0", ":", "\n", "                ", "usebbx", "=", "True", "\n", "", "else", ":", "\n", "                ", "usebbx", "=", "False", "\n", "\n", "", "", "if", "usebbx", ":", "\n", "            ", "if", "isinstance", "(", "bbox", "[", "\"bbox\"", "]", "[", "0", "]", ",", "list", ")", ":", "\n", "                ", "idx", "=", "random", ".", "choice", "(", "np", ".", "arange", "(", "len", "(", "bbox", "[", "\"bbox\"", "]", ")", ")", ")", "\n", "bbox", "=", "bbox", "[", "\"bbox\"", "]", "[", "idx", "]", "# choose a random bbox from the list", "\n", "", "else", ":", "\n", "                ", "bbox", "=", "bbox", "[", "\"bbox\"", "]", "\n", "\n", "", "", "if", "usebbx", ":", "\n", "            ", "if", "origin", "==", "\"coco\"", ":", "\n", "                ", "a", "=", "bbox", "[", "0", "]", "\n", "b", "=", "bbox", "[", "1", "]", "\n", "c", "=", "bbox", "[", "2", "]", "\n", "d", "=", "bbox", "[", "3", "]", "\n", "", "else", ":", "\n", "                ", "a", "=", "float", "(", "bbox", "[", "0", "]", ")", "*", "w", "\n", "b", "=", "float", "(", "bbox", "[", "1", "]", ")", "*", "w", "\n", "c", "=", "float", "(", "bbox", "[", "2", "]", ")", "*", "h", "\n", "d", "=", "float", "(", "bbox", "[", "3", "]", ")", "*", "h", "\n", "\n", "a", ",", "b", ",", "c", ",", "d", "=", "a", ",", "c", ",", "b", "-", "a", ",", "d", "-", "c", "\n", "\n", "", "eps", "=", "0.0001", "\n", "longer_side", "=", "max", "(", "h", ",", "d", ")", "\n", "r_max", "=", "min", "(", "float", "(", "longer_side", ")", "/", "(", "d", "+", "eps", ")", ",", "float", "(", "longer_side", ")", "/", "(", "c", "+", "eps", ")", ")", "\n", "r_min", "=", "1.5", "\n", "\n", "if", "r_max", ">", "r_min", "and", "w", ">", "200", "and", "h", ">", "200", "and", "c", "*", "d", ">", "30", "*", "30", ":", "\n", "                ", "r", "=", "1", "+", "np", ".", "random", ".", "rand", "(", ")", "*", "(", "r_max", "-", "1", ")", "\n", "d_new", "=", "r", "*", "d", "\n", "c_new", "=", "r", "*", "c", "\n", "\n", "longer_side", "=", "min", "(", "max", "(", "c_new", ",", "d_new", ")", ",", "h", ",", "w", ")", "\n", "\n", "d_new", "=", "max", "(", "longer_side", ",", "150", ")", "\n", "c_new", "=", "max", "(", "longer_side", ",", "150", ")", "\n", "\n", "a_new", "=", "max", "(", "0", ",", "a", "-", "0.5", "*", "(", "c_new", "-", "c", ")", ")", "\n", "b_new", "=", "max", "(", "0", ",", "b", "-", "0.5", "*", "(", "d_new", "-", "d", ")", ")", "\n", "\n", "if", "c_new", "+", "a_new", ">", "w", ":", "\n", "                    ", "a_new", "=", "max", "(", "0", ",", "a_new", "-", "(", "(", "c_new", "+", "a_new", ")", "-", "w", ")", ")", "\n", "", "if", "d_new", "+", "b_new", ">", "h", ":", "\n", "                    ", "b_new", "=", "max", "(", "0", ",", "b_new", "-", "(", "(", "d_new", "+", "b_new", ")", "-", "h", ")", ")", "\n", "\n", "", "c_new", "=", "c_new", "+", "a_new", "\n", "d_new", "=", "d_new", "+", "b_new", "\n", "\n", "img", "=", "img", ".", "crop", "(", "(", "a_new", ",", "b_new", ",", "c_new", ",", "d_new", ")", ")", "\n", "\n", "", "", "idx", "=", "image_path", "\n", "\n", "if", "not", "fixed", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "elif", "fixed", ":", "\n", "            ", "img", "=", "self", ".", "fixed_transform", "(", "img", ")", "\n", "\n", "", "label", "=", "torch", ".", "LongTensor", "(", "[", "id", "]", ")", "\n", "\n", "bbox", "=", "self", ".", "bbox", "[", "file", ".", "strip", "(", "\".jpg\"", ")", "]", "\n", "out", "=", "(", "img", ",", "label", ",", "idx", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.CocoAnimals.exact_batch": [[191, 199], ["PIL.Image.open().convert", "PyTorchDatasets.CocoAnimals.transform", "torch.LongTensor", "PIL.Image.open"], "methods", ["None"], ["", "def", "exact_batch", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "image_path", "=", "self", ".", "all_files", "[", "index", "]", "\n", "img", "=", "Image", ".", "open", "(", "image_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "id", "=", "self", ".", "all_labels", "[", "index", "]", "\n", "label", "=", "torch", ".", "LongTensor", "(", "[", "id", "]", ")", "\n", "return", "img", ",", "label", ",", "image_path", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.CocoAnimals.__getitem__": [[200, 206], ["PyTorchDatasets.CocoAnimals.exact_batch", "PyTorchDatasets.CocoAnimals.random_batch"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.CocoAnimals.exact_batch", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.Celeba.random_batch"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "if", "self", ".", "return_all", ":", "\n", "            ", "return", "self", ".", "exact_batch", "(", "index", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "random_batch", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.FFHQ.__init__": [[210, 234], ["print", "os.listdir", "sum", "torchvision.transforms.Compose", "range", "numpy.random.randint", "PyTorchDatasets.FFHQ.fixed_indices.append", "len", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "os.listdir", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "transform", ",", "batch_size", "=", "60", ",", "test_mode", "=", "False", ",", "return_all", "=", "False", ",", "imsize", "=", "256", ")", ":", "\n", "\n", "        ", "self", ".", "root", "=", "root", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "return_all", "=", "return_all", "\n", "\n", "print", "(", "\"root:\"", ",", "self", ".", "root", ")", "\n", "all_folders", "=", "os", ".", "listdir", "(", "self", ".", "root", ")", "\n", "\n", "self", ".", "length", "=", "sum", "(", "[", "len", "(", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "folder", ")", ")", ")", "for", "folder", "in", "all_folders", "]", ")", "# = 70000", "\n", "self", ".", "fixed_transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "Resize", "(", "imsize", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "imsize", ")", ",", "\n", "#transforms.RandomHorizontalFlip(),", "\n", "#transforms.ColorJitter(brightness=0.01, contrast=0.01, saturation=0.01, hue=0.01),", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "\n", "self", ".", "fixed_indices", "=", "[", "]", "\n", "\n", "for", "_", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "id", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "length", ")", "\n", "self", ".", "fixed_indices", ".", "append", "(", "id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.FFHQ.__len__": [[235, 237], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.FFHQ.fixed_batch": [[239, 244], ["torch.stack", "torch.stack", "[].cuda", "[].cuda", "range", "len", "PyTorchDatasets.FFHQ.random_batch", "PyTorchDatasets.FFHQ.random_batch", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.Celeba.random_batch", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.Celeba.random_batch"], ["", "def", "fixed_batch", "(", "self", ",", "random", "=", "False", ")", ":", "\n", "        ", "if", "random", "==", "False", ":", "\n", "            ", "return", "torch", ".", "stack", "(", "[", "self", ".", "random_batch", "(", "idx", ",", "True", ")", "[", "0", "]", ".", "cuda", "(", ")", "for", "idx", "in", "self", ".", "fixed_indices", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "stack", "(", "[", "self", ".", "random_batch", "(", "np", ".", "random", ".", "randint", "(", "self", ".", "length", ")", ",", "True", ")", "[", "0", "]", ".", "cuda", "(", ")", "for", "_", "in", "range", "(", "len", "(", "self", ".", "fixed_indices", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.FFHQ.random_batch": [[245, 258], ["str().zfill", "os.path.join", "PIL.Image.open().convert", "str().zfill", "PyTorchDatasets.FFHQ.fixed_transform", "PyTorchDatasets.FFHQ.transform", "torch.zeros().long", "str", "PIL.Image.open", "int", "str", "torch.zeros", "numpy.floor"], "methods", ["None"], ["", "", "def", "random_batch", "(", "self", ",", "index", ",", "fixed", "=", "False", ")", ":", "\n", "\n", "        ", "folder", "=", "str", "(", "int", "(", "np", ".", "floor", "(", "index", "/", "1000", ")", "*", "1000", ")", ")", ".", "zfill", "(", "5", ")", "\n", "file", "=", "str", "(", "index", ")", ".", "zfill", "(", "5", ")", "+", "\".png\"", "\n", "image_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "folder", ",", "file", ")", "\n", "img", "=", "Image", ".", "open", "(", "image_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "if", "fixed", ":", "\n", "            ", "img", "=", "self", ".", "fixed_transform", "(", "img", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "\n", "", "return", "img", ",", "torch", ".", "zeros", "(", "1", ")", ".", "long", "(", ")", ",", "image_path", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.FFHQ.__getitem__": [[259, 265], ["PyTorchDatasets.FFHQ.exact_batch", "PyTorchDatasets.FFHQ.random_batch"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.CocoAnimals.exact_batch", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.Celeba.random_batch"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "if", "self", ".", "return_all", ":", "\n", "            ", "return", "self", ".", "exact_batch", "(", "index", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "random_batch", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.Celeba.__init__": [[269, 290], ["os.listdir", "len", "torchvision.transforms.Compose", "range", "numpy.random.randint", "PyTorchDatasets.Celeba.fixed_indices.append", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "transform", ",", "batch_size", "=", "60", ",", "test_mode", "=", "False", ",", "return_all", "=", "False", ",", "imsize", "=", "128", ")", ":", "\n", "\n", "        ", "self", ".", "root", "=", "root", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "return_all", "=", "return_all", "\n", "all_files", "=", "os", ".", "listdir", "(", "self", ".", "root", ")", "\n", "self", ".", "length", "=", "len", "(", "all_files", ")", "\n", "self", ".", "fixed_transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "Resize", "(", "imsize", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "imsize", ")", ",", "\n", "#transforms.RandomHorizontalFlip(),", "\n", "#transforms.ColorJitter(brightness=0.01, contrast=0.01, saturation=0.01, hue=0.01),", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "\n", "self", ".", "fixed_indices", "=", "[", "]", "\n", "\n", "for", "_", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "id", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "length", ")", "\n", "self", ".", "fixed_indices", ".", "append", "(", "id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.Celeba.__len__": [[291, 293], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.Celeba.fixed_batch": [[295, 297], ["torch.stack", "[].cuda", "PyTorchDatasets.Celeba.random_batch"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.Celeba.random_batch"], ["", "def", "fixed_batch", "(", "self", ")", ":", "\n", "        ", "return", "torch", ".", "stack", "(", "[", "self", ".", "random_batch", "(", "idx", ",", "True", ")", "[", "0", "]", ".", "cuda", "(", ")", "for", "idx", "in", "self", ".", "fixed_indices", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.Celeba.random_batch": [[299, 310], ["os.path.join", "PIL.Image.open().convert", "str().zfill", "PyTorchDatasets.Celeba.fixed_transform", "PyTorchDatasets.Celeba.transform", "torch.zeros().long", "PIL.Image.open", "str", "torch.zeros"], "methods", ["None"], ["", "def", "random_batch", "(", "self", ",", "index", ",", "fixed", "=", "False", ")", ":", "\n", "\n", "        ", "file", "=", "str", "(", "index", "+", "1", ")", ".", "zfill", "(", "6", ")", "+", "'.png'", "\n", "image_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "file", ")", "\n", "img", "=", "Image", ".", "open", "(", "image_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "if", "fixed", ":", "\n", "            ", "img", "=", "self", ".", "fixed_transform", "(", "img", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "return", "img", ",", "torch", ".", "zeros", "(", "1", ")", ".", "long", "(", ")", ",", "image_path", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.Celeba.__getitem__": [[311, 317], ["PyTorchDatasets.Celeba.exact_batch", "PyTorchDatasets.Celeba.random_batch"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.CocoAnimals.exact_batch", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.PyTorchDatasets.Celeba.random_batch"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "if", "self", ".", "return_all", ":", "\n", "            ", "return", "self", ".", "exact_batch", "(", "index", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "random_batch", "(", "index", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.mixup.random_boundingbox": [[8, 23], ["numpy.sqrt", "numpy.int", "numpy.int", "numpy.random.randint", "numpy.random.randint", "numpy.clip", "numpy.clip", "numpy.clip", "numpy.clip"], "function", ["None"], ["def", "random_boundingbox", "(", "size", ",", "lam", ")", ":", "\n", "    ", "width", ",", "height", "=", "size", ",", "size", "\n", "\n", "r", "=", "np", ".", "sqrt", "(", "1.", "-", "lam", ")", "\n", "w", "=", "np", ".", "int", "(", "width", "*", "r", ")", "\n", "h", "=", "np", ".", "int", "(", "height", "*", "r", ")", "\n", "x", "=", "np", ".", "random", ".", "randint", "(", "width", ")", "\n", "y", "=", "np", ".", "random", ".", "randint", "(", "height", ")", "\n", "\n", "x1", "=", "np", ".", "clip", "(", "x", "-", "w", "//", "2", ",", "0", ",", "width", ")", "\n", "y1", "=", "np", ".", "clip", "(", "y", "-", "h", "//", "2", ",", "0", ",", "height", ")", "\n", "x2", "=", "np", ".", "clip", "(", "x", "+", "w", "//", "2", ",", "0", ",", "width", ")", "\n", "y2", "=", "np", ".", "clip", "(", "y", "+", "h", "//", "2", ",", "0", ",", "height", ")", "\n", "\n", "return", "x1", ",", "y1", ",", "x2", ",", "y2", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.mixup.CutMix": [[24, 36], ["numpy.random.beta", "mixup.random_boundingbox", "torch.ones", "torch.rand"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.mixup.random_boundingbox"], ["", "def", "CutMix", "(", "imsize", ")", ":", "\n", "    ", "lam", "=", "np", ".", "random", ".", "beta", "(", "1", ",", "1", ")", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "random_boundingbox", "(", "imsize", ",", "lam", ")", "\n", "# adjust lambda to exactly match pixel ratio", "\n", "lam", "=", "1", "-", "(", "(", "x2", "-", "x1", ")", "*", "(", "y2", "-", "y1", ")", "/", "(", "imsize", "*", "imsize", ")", ")", "\n", "map", "=", "torch", ".", "ones", "(", "(", "imsize", ",", "imsize", ")", ")", "\n", "map", "[", "x1", ":", "x2", ",", "y1", ":", "y2", "]", "=", "0", "\n", "if", "torch", ".", "rand", "(", "1", ")", ">", "0.5", ":", "\n", "        ", "map", "=", "1", "-", "map", "\n", "lam", "=", "1", "-", "lam", "\n", "# lam is equivalent to map.mean()", "\n", "", "return", "map", "#, lam", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.mixup.cutmixdemo": [[41, 51], ["range", "print", "matplotlib.pyplot.show", "matplotlib.pyplot.figure", "mixup.CutMix", "print", "matplotlib.pyplot.imshow", "CutMix.mean", "CutMix.mean"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.mixup.CutMix"], ["", "def", "cutmixdemo", "(", ")", ":", "\n", "    ", "means", "=", "0", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "        ", "plt", ".", "figure", "(", ")", "\n", "b", "=", "CutMix", "(", "128", ")", "\n", "print", "(", "b", ".", "mean", "(", ")", ")", "\n", "means", "+=", "b", ".", "mean", "(", ")", "/", "10", "\n", "plt", ".", "imshow", "(", "b", ",", "cmap", "=", "\"gray\"", ")", "\n", "", "print", "(", "\">>>\"", ",", "means", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.WrapInception.__init__": [[29, 36], ["torch.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__"], ["  ", "def", "__init__", "(", "self", ",", "net", ")", ":", "\n", "    ", "super", "(", "WrapInception", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "net", "=", "net", "\n", "self", ".", "mean", "=", "P", "(", "torch", ".", "tensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "self", ".", "std", "=", "P", "(", "torch", ".", "tensor", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.WrapInception.forward": [[36, 86], ["inception_utils.WrapInception.net.Conv2d_1a_3x3", "inception_utils.WrapInception.net.Conv2d_2a_3x3", "inception_utils.WrapInception.net.Conv2d_2b_3x3", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "inception_utils.WrapInception.net.Conv2d_3b_1x1", "inception_utils.WrapInception.net.Conv2d_4a_3x3", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "inception_utils.WrapInception.net.Mixed_5b", "inception_utils.WrapInception.net.Mixed_5c", "inception_utils.WrapInception.net.Mixed_5d", "inception_utils.WrapInception.net.Mixed_6a", "inception_utils.WrapInception.net.Mixed_6b", "inception_utils.WrapInception.net.Mixed_6c", "inception_utils.WrapInception.net.Mixed_6d", "inception_utils.WrapInception.net.Mixed_6e", "inception_utils.WrapInception.net.Mixed_7a", "inception_utils.WrapInception.net.Mixed_7b", "inception_utils.WrapInception.net.Mixed_7c", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "inception_utils.WrapInception.net.fc", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.interpolate.view", "torch.dropout().view", "torch.dropout().view", "torch.dropout().view", "torch.interpolate.size", "torch.interpolate.size", "torch.mean.size", "torch.mean.size", "torch.mean.size", "torch.dropout", "torch.dropout", "torch.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# Normalize x", "\n", "    ", "x", "=", "(", "x", "+", "1.", ")", "/", "2.0", "\n", "x", "=", "(", "x", "-", "self", ".", "mean", ")", "/", "self", ".", "std", "\n", "# Upsample if necessary", "\n", "if", "x", ".", "shape", "[", "2", "]", "!=", "299", "or", "x", ".", "shape", "[", "3", "]", "!=", "299", ":", "\n", "      ", "x", "=", "F", ".", "interpolate", "(", "x", ",", "size", "=", "(", "299", ",", "299", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "# 299 x 299 x 3", "\n", "", "x", "=", "self", ".", "net", ".", "Conv2d_1a_3x3", "(", "x", ")", "\n", "# 149 x 149 x 32", "\n", "x", "=", "self", ".", "net", ".", "Conv2d_2a_3x3", "(", "x", ")", "\n", "# 147 x 147 x 32", "\n", "x", "=", "self", ".", "net", ".", "Conv2d_2b_3x3", "(", "x", ")", "\n", "# 147 x 147 x 64", "\n", "x", "=", "F", ".", "max_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "# 73 x 73 x 64", "\n", "x", "=", "self", ".", "net", ".", "Conv2d_3b_1x1", "(", "x", ")", "\n", "# 73 x 73 x 80", "\n", "x", "=", "self", ".", "net", ".", "Conv2d_4a_3x3", "(", "x", ")", "\n", "# 71 x 71 x 192", "\n", "x", "=", "F", ".", "max_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "# 35 x 35 x 192", "\n", "x", "=", "self", ".", "net", ".", "Mixed_5b", "(", "x", ")", "\n", "# 35 x 35 x 256", "\n", "x", "=", "self", ".", "net", ".", "Mixed_5c", "(", "x", ")", "\n", "# 35 x 35 x 288", "\n", "x", "=", "self", ".", "net", ".", "Mixed_5d", "(", "x", ")", "\n", "# 35 x 35 x 288", "\n", "x", "=", "self", ".", "net", ".", "Mixed_6a", "(", "x", ")", "\n", "# 17 x 17 x 768", "\n", "x", "=", "self", ".", "net", ".", "Mixed_6b", "(", "x", ")", "\n", "# 17 x 17 x 768", "\n", "x", "=", "self", ".", "net", ".", "Mixed_6c", "(", "x", ")", "\n", "# 17 x 17 x 768", "\n", "x", "=", "self", ".", "net", ".", "Mixed_6d", "(", "x", ")", "\n", "# 17 x 17 x 768", "\n", "x", "=", "self", ".", "net", ".", "Mixed_6e", "(", "x", ")", "\n", "# 17 x 17 x 768", "\n", "# 17 x 17 x 768", "\n", "x", "=", "self", ".", "net", ".", "Mixed_7a", "(", "x", ")", "\n", "# 8 x 8 x 1280", "\n", "x", "=", "self", ".", "net", ".", "Mixed_7b", "(", "x", ")", "\n", "# 8 x 8 x 2048", "\n", "x", "=", "self", ".", "net", ".", "Mixed_7c", "(", "x", ")", "\n", "# 8 x 8 x 2048", "\n", "pool", "=", "torch", ".", "mean", "(", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "-", "1", ")", ",", "2", ")", "\n", "# 1 x 1 x 2048", "\n", "logits", "=", "self", ".", "net", ".", "fc", "(", "F", ".", "dropout", "(", "pool", ",", "training", "=", "False", ")", ".", "view", "(", "pool", ".", "size", "(", "0", ")", ",", "-", "1", ")", ")", "\n", "# 1000 (num_classes)", "\n", "return", "pool", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.sqrt_newton_schulz": [[92, 108], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "A.mul().sum().sum().sqrt", "A.div", "torch.eye().view().repeat().type", "torch.eye().view().repeat().type", "torch.eye().view().repeat().type", "torch.eye().view().repeat().type", "torch.eye().view().repeat().type", "torch.eye().view().repeat().type", "range", "A.type", "A.mul().sum().sum().sqrt.view().expand_as", "Y.bmm.bmm", "T.bmm", "torch.sqrt().view().expand_as", "torch.sqrt().view().expand_as", "torch.sqrt().view().expand_as", "A.mul().sum().sum", "torch.eye().view().repeat", "torch.eye().view().repeat", "torch.eye().view().repeat", "torch.eye().view().repeat", "torch.eye().view().repeat", "torch.eye().view().repeat", "A.mul().sum().sum().sqrt.view", "T.bmm.bmm", "torch.sqrt().view", "torch.sqrt().view", "torch.sqrt().view", "A.mul().sum", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.sqrt", "torch.sqrt", "torch.sqrt", "A.mul", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye"], "function", ["None"], ["", "", "def", "sqrt_newton_schulz", "(", "A", ",", "numIters", ",", "dtype", "=", "None", ")", ":", "\n", "  ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "    ", "if", "dtype", "is", "None", ":", "\n", "      ", "dtype", "=", "A", ".", "type", "(", ")", "\n", "", "batchSize", "=", "A", ".", "shape", "[", "0", "]", "\n", "dim", "=", "A", ".", "shape", "[", "1", "]", "\n", "normA", "=", "A", ".", "mul", "(", "A", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "sqrt", "(", ")", "\n", "Y", "=", "A", ".", "div", "(", "normA", ".", "view", "(", "batchSize", ",", "1", ",", "1", ")", ".", "expand_as", "(", "A", ")", ")", ";", "\n", "I", "=", "torch", ".", "eye", "(", "dim", ",", "dim", ")", ".", "view", "(", "1", ",", "dim", ",", "dim", ")", ".", "repeat", "(", "batchSize", ",", "1", ",", "1", ")", ".", "type", "(", "dtype", ")", "\n", "Z", "=", "torch", ".", "eye", "(", "dim", ",", "dim", ")", ".", "view", "(", "1", ",", "dim", ",", "dim", ")", ".", "repeat", "(", "batchSize", ",", "1", ",", "1", ")", ".", "type", "(", "dtype", ")", "\n", "for", "i", "in", "range", "(", "numIters", ")", ":", "\n", "      ", "T", "=", "0.5", "*", "(", "3.0", "*", "I", "-", "Z", ".", "bmm", "(", "Y", ")", ")", "\n", "Y", "=", "Y", ".", "bmm", "(", "T", ")", "\n", "Z", "=", "T", ".", "bmm", "(", "Z", ")", "\n", "", "sA", "=", "Y", "*", "torch", ".", "sqrt", "(", "normA", ")", ".", "view", "(", "batchSize", ",", "1", ",", "1", ")", ".", "expand_as", "(", "A", ")", "\n", "", "return", "sA", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.numpy_calculate_frechet_distance": [[112, 166], ["numpy.atleast_1d", "numpy.atleast_1d", "numpy.atleast_2d", "numpy.atleast_2d", "scipy.linalg.sqrtm", "numpy.iscomplexobj", "numpy.trace", "np.atleast_2d.dot", "numpy.isfinite().all", "print", "scipy.linalg.sqrtm", "print", "numpy.eye", "numpy.allclose", "numpy.max", "ValueError", "numpy.trace", "numpy.isfinite", "numpy.abs", "diff.dot", "numpy.trace", "numpy.diagonal"], "function", ["None"], ["", "def", "numpy_calculate_frechet_distance", "(", "mu1", ",", "sigma1", ",", "mu2", ",", "sigma2", ",", "eps", "=", "1e-6", ")", ":", "\n", "  ", "\"\"\"Numpy implementation of the Frechet Distance.\n  Taken from https://github.com/bioinf-jku/TTUR\n  The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n  and X_2 ~ N(mu_2, C_2) is\n          d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n  Stable version by Dougal J. Sutherland.\n  Params:\n  -- mu1   : Numpy array containing the activations of a layer of the\n             inception net (like returned by the function 'get_predictions')\n             for generated samples.\n  -- mu2   : The sample mean over activations, precalculated on an\n             representive data set.\n  -- sigma1: The covariance matrix over activations for generated samples.\n  -- sigma2: The covariance matrix over activations, precalculated on an\n             representive data set.\n  Returns:\n  --   : The Frechet Distance.\n  \"\"\"", "\n", "\n", "mu1", "=", "np", ".", "atleast_1d", "(", "mu1", ")", "\n", "mu2", "=", "np", ".", "atleast_1d", "(", "mu2", ")", "\n", "\n", "sigma1", "=", "np", ".", "atleast_2d", "(", "sigma1", ")", "\n", "sigma2", "=", "np", ".", "atleast_2d", "(", "sigma2", ")", "\n", "\n", "assert", "mu1", ".", "shape", "==", "mu2", ".", "shape", ",", "'Training and test mean vectors have different lengths'", "\n", "assert", "sigma1", ".", "shape", "==", "sigma2", ".", "shape", ",", "'Training and test covariances have different dimensions'", "\n", "\n", "diff", "=", "mu1", "-", "mu2", "\n", "\n", "# Product might be almost singular", "\n", "covmean", ",", "_", "=", "linalg", ".", "sqrtm", "(", "sigma1", ".", "dot", "(", "sigma2", ")", ",", "disp", "=", "False", ")", "\n", "if", "not", "np", ".", "isfinite", "(", "covmean", ")", ".", "all", "(", ")", ":", "\n", "    ", "msg", "=", "(", "'fid calculation produces singular product; '", "\n", "'adding %s to diagonal of cov estimates'", ")", "%", "eps", "\n", "print", "(", "msg", ")", "\n", "offset", "=", "np", ".", "eye", "(", "sigma1", ".", "shape", "[", "0", "]", ")", "*", "eps", "\n", "covmean", "=", "linalg", ".", "sqrtm", "(", "(", "sigma1", "+", "offset", ")", ".", "dot", "(", "sigma2", "+", "offset", ")", ")", "\n", "\n", "# Numerical error might give slight imaginary component", "\n", "", "if", "np", ".", "iscomplexobj", "(", "covmean", ")", ":", "\n", "    ", "print", "(", "'wat'", ")", "\n", "if", "not", "np", ".", "allclose", "(", "np", ".", "diagonal", "(", "covmean", ")", ".", "imag", ",", "0", ",", "atol", "=", "1e-3", ")", ":", "\n", "      ", "m", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "covmean", ".", "imag", ")", ")", "\n", "raise", "ValueError", "(", "'Imaginary component {}'", ".", "format", "(", "m", ")", ")", "\n", "", "covmean", "=", "covmean", ".", "real", "\n", "\n", "", "tr_covmean", "=", "np", ".", "trace", "(", "covmean", ")", "\n", "\n", "out", "=", "diff", ".", "dot", "(", "diff", ")", "+", "np", ".", "trace", "(", "sigma1", ")", "+", "np", ".", "trace", "(", "sigma2", ")", "-", "2", "*", "tr_covmean", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.torch_calculate_frechet_distance": [[168, 202], ["sqrt_newton_schulz().squeeze", "inception_utils.sqrt_newton_schulz", "torch.trace", "torch.trace", "torch.trace", "torch.trace", "torch.trace", "torch.trace", "sigma1.mm().unsqueeze", "diff.dot", "torch.trace", "torch.trace", "torch.trace", "sigma1.mm"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.sqrt_newton_schulz"], ["", "def", "torch_calculate_frechet_distance", "(", "mu1", ",", "sigma1", ",", "mu2", ",", "sigma2", ",", "eps", "=", "1e-6", ")", ":", "\n", "  ", "\"\"\"Pytorch implementation of the Frechet Distance.\n  Taken from https://github.com/bioinf-jku/TTUR\n  The Frechet distance between two multivariate Gaussians X_1 ~ N(mu_1, C_1)\n  and X_2 ~ N(mu_2, C_2) is\n          d^2 = ||mu_1 - mu_2||^2 + Tr(C_1 + C_2 - 2*sqrt(C_1*C_2)).\n  Stable version by Dougal J. Sutherland.\n  Params:\n  -- mu1   : Numpy array containing the activations of a layer of the\n             inception net (like returned by the function 'get_predictions')\n             for generated samples.\n  -- mu2   : The sample mean over activations, precalculated on an\n             representive data set.\n  -- sigma1: The covariance matrix over activations for generated samples.\n  -- sigma2: The covariance matrix over activations, precalculated on an\n             representive data set.\n  Returns:\n  --   : The Frechet Distance.\n  \"\"\"", "\n", "\n", "\n", "assert", "mu1", ".", "shape", "==", "mu2", ".", "shape", ",", "'Training and test mean vectors have different lengths'", "\n", "assert", "sigma1", ".", "shape", "==", "sigma2", ".", "shape", ",", "'Training and test covariances have different dimensions'", "\n", "\n", "diff", "=", "mu1", "-", "mu2", "\n", "# Run 50 itrs of newton-schulz to get the matrix sqrt of sigma1 dot sigma2", "\n", "covmean", "=", "sqrt_newton_schulz", "(", "sigma1", ".", "mm", "(", "sigma2", ")", ".", "unsqueeze", "(", "0", ")", ",", "50", ")", ".", "squeeze", "(", ")", "\n", "#print(\"covmean\")", "\n", "#print(covmean)", "\n", "out", "=", "(", "diff", ".", "dot", "(", "diff", ")", "+", "torch", ".", "trace", "(", "sigma1", ")", "+", "torch", ".", "trace", "(", "sigma2", ")", "\n", "-", "2", "*", "torch", ".", "trace", "(", "covmean", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.calculate_inception_score": [[205, 213], ["range", "numpy.mean", "scores.append", "numpy.mean", "numpy.std", "numpy.sum", "numpy.exp", "numpy.log", "numpy.log", "numpy.expand_dims", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.MyLogger.log", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.MyLogger.log"], ["", "def", "calculate_inception_score", "(", "pred", ",", "num_splits", "=", "10", ")", ":", "\n", "  ", "scores", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "num_splits", ")", ":", "\n", "    ", "pred_chunk", "=", "pred", "[", "index", "*", "(", "pred", ".", "shape", "[", "0", "]", "//", "num_splits", ")", ":", "(", "index", "+", "1", ")", "*", "(", "pred", ".", "shape", "[", "0", "]", "//", "num_splits", ")", ",", ":", "]", "\n", "kl_inception", "=", "pred_chunk", "*", "(", "np", ".", "log", "(", "pred_chunk", ")", "-", "np", ".", "log", "(", "np", ".", "expand_dims", "(", "np", ".", "mean", "(", "pred_chunk", ",", "0", ")", ",", "0", ")", ")", ")", "\n", "kl_inception", "=", "np", ".", "mean", "(", "np", ".", "sum", "(", "kl_inception", ",", "1", ")", ")", "\n", "scores", ".", "append", "(", "np", ".", "exp", "(", "kl_inception", ")", ")", "\n", "", "return", "np", ".", "mean", "(", "scores", ")", ",", "np", ".", "std", "(", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.accumulate_inception_activations": [[218, 228], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "sample", "net", "images.float", "torch.softmax", "torch.cat", "torch.cat", "torch.cat"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.sample"], ["", "def", "accumulate_inception_activations", "(", "sample", ",", "net", ",", "num_inception_images", "=", "50000", ")", ":", "\n", "  ", "pool", ",", "logits", ",", "labels", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "while", "(", "torch", ".", "cat", "(", "logits", ",", "0", ")", ".", "shape", "[", "0", "]", "if", "len", "(", "logits", ")", "else", "0", ")", "<", "num_inception_images", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "      ", "images", ",", "labels_val", "=", "sample", "(", ")", "\n", "pool_val", ",", "logits_val", "=", "net", "(", "images", ".", "float", "(", ")", ")", "\n", "pool", "+=", "[", "pool_val", "]", "\n", "logits", "+=", "[", "F", ".", "softmax", "(", "logits_val", ",", "1", ")", "]", "\n", "labels", "+=", "[", "labels_val", "]", "\n", "", "", "return", "torch", ".", "cat", "(", "pool", ",", "0", ")", ",", "torch", ".", "cat", "(", "logits", ",", "0", ")", ",", "torch", ".", "cat", "(", "labels", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.load_inception_net": [[231, 238], ["torchvision.models.inception.inception_v3", "WrapInception().cuda", "print", "torch.DataParallel", "inception_utils.WrapInception", "nn.DataParallel.eval"], "function", ["None"], ["", "def", "load_inception_net", "(", "parallel", "=", "False", ")", ":", "\n", "  ", "inception_model", "=", "inception_v3", "(", "pretrained", "=", "True", ",", "transform_input", "=", "False", ")", "\n", "inception_model", "=", "WrapInception", "(", "inception_model", ".", "eval", "(", ")", ")", ".", "cuda", "(", ")", "\n", "if", "parallel", ":", "\n", "    ", "print", "(", "'Parallelizing Inception module...'", ")", "\n", "inception_model", "=", "nn", ".", "DataParallel", "(", "inception_model", ")", "\n", "", "return", "inception_model", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.prepare_inception_metrics": [[244, 291], ["dataset.strip.strip", "inception_utils.load_inception_net", "numpy.load", "numpy.load", "inception_utils.accumulate_inception_activations", "inception_utils.calculate_inception_score", "print", "print", "logits.cpu().numpy", "print", "print", "print", "print", "inception_utils.torch_calculate_frechet_distance", "float", "inception_utils.numpy_calculate_frechet_distance", "logits.cpu", "numpy.mean", "numpy.cov", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.tensor().float().cuda", "torch.tensor().float().cuda", "torch.tensor().float().cuda", "torch.tensor().float().cuda", "torch.tensor().float().cuda", "torch.tensor().float().cuda", "numpy_calculate_frechet_distance.cpu().numpy", "mu.cpu().numpy", "sigma.cpu().numpy", "pool.cpu().numpy", "pool.cpu().numpy", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "numpy_calculate_frechet_distance.cpu", "mu.cpu", "sigma.cpu", "pool.cpu", "pool.cpu", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.load_inception_net", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.accumulate_inception_activations", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.calculate_inception_score", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.torch_calculate_frechet_distance", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.numpy_calculate_frechet_distance"], ["", "def", "prepare_inception_metrics", "(", "dataset", ",", "parallel", ",", "no_fid", "=", "False", ",", "use_torch", "=", "True", ")", ":", "\n", "# Load metrics; this is intentionally not in a try-except loop so that", "\n", "# the script will crash here if it cannot find the Inception moments.", "\n", "# By default, remove the \"hdf5\" from dataset", "\n", "\n", "  ", "dataset", "=", "dataset", ".", "strip", "(", "'_hdf5'", ")", "\n", "data_mu", "=", "np", ".", "load", "(", "dataset", "+", "'_inception_moments.npz'", ")", "[", "'mu'", "]", "\n", "data_sigma", "=", "np", ".", "load", "(", "dataset", "+", "'_inception_moments.npz'", ")", "[", "'sigma'", "]", "\n", "#print(\"data_mu\")", "\n", "#print(data_mu)", "\n", "#print(\"data_sigma\")", "\n", "#print(data_sigma)", "\n", "# Load network", "\n", "net", "=", "load_inception_net", "(", "parallel", ")", "\n", "def", "get_inception_metrics", "(", "sample", ",", "num_inception_images", ",", "num_splits", "=", "10", ",", "\n", "prints", "=", "True", ",", "use_torch", "=", "use_torch", ")", ":", "\n", "    ", "if", "prints", ":", "\n", "      ", "print", "(", "'Gathering activations...'", ")", "\n", "", "pool", ",", "logits", ",", "labels", "=", "accumulate_inception_activations", "(", "sample", ",", "net", ",", "num_inception_images", ")", "\n", "if", "prints", ":", "\n", "      ", "print", "(", "'Calculating Inception Score...'", ")", "\n", "", "IS_mean", ",", "IS_std", "=", "calculate_inception_score", "(", "logits", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "num_splits", ")", "\n", "if", "no_fid", ":", "\n", "      ", "FID", "=", "9999.0", "\n", "", "else", ":", "\n", "      ", "if", "prints", ":", "\n", "        ", "print", "(", "'Calculating means and covariances...'", ")", "\n", "", "if", "use_torch", ":", "\n", "# this never worked really", "\n", "        ", "pass", "\n", "", "else", ":", "\n", "        ", "mu", ",", "sigma", "=", "np", ".", "mean", "(", "pool", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", ",", "np", ".", "cov", "(", "pool", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "rowvar", "=", "False", ")", "\n", "mu", ",", "sigma", "=", "torch", ".", "from_numpy", "(", "mu", ")", ",", "torch", ".", "from_numpy", "(", "sigma", ")", "\n", "\n", "", "print", "(", "\"sigma\"", ")", "\n", "print", "(", "sigma", ")", "\n", "if", "prints", ":", "\n", "        ", "print", "(", "'Covariances calculated, getting FID...'", ")", "\n", "", "if", "use_torch", ":", "\n", "        ", "FID", "=", "torch_calculate_frechet_distance", "(", "mu", ",", "sigma", ",", "torch", ".", "tensor", "(", "data_mu", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", ",", "torch", ".", "tensor", "(", "data_sigma", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", ")", "\n", "FID", "=", "float", "(", "FID", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "FID", "=", "numpy_calculate_frechet_distance", "(", "mu", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "sigma", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "data_mu", ",", "data_sigma", ")", "\n", "# Delete mu, sigma, pool, logits, and labels, just in case", "\n", "", "", "del", "mu", ",", "sigma", ",", "pool", ",", "logits", ",", "labels", "\n", "return", "IS_mean", ",", "IS_std", ",", "FID", "\n", "", "return", "get_inception_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.prepare_inception_metrics_from_npz": [[293, 315], ["print", "print", "print", "inception_utils.numpy_calculate_frechet_distance", "numpy.load", "numpy.load", "numpy.load", "numpy.load"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.inception_utils.numpy_calculate_frechet_distance"], ["", "def", "prepare_inception_metrics_from_npz", "(", "data_npz", ",", "gen_npz", ")", ":", "#, parallel, no_fid=False, use_torch = True):", "\n", "# Load metrics; this is intentionally not in a try-except loop so that", "\n", "# the script will crash here if it cannot find the Inception moments.", "\n", "# By default, remove the \"hdf5\" from dataset", "\n", "\n", "  ", "data_mu", "=", "np", ".", "load", "(", "data_npz", ")", "[", "'pool_mean'", "]", "\n", "data_sigma", "=", "np", ".", "load", "(", "data_npz", ")", "[", "'pool_var'", "]", "\n", "\n", "mu", "=", "np", ".", "load", "(", "gen_npz", ")", "[", "\"pool_mean\"", "]", "\n", "sigma", "=", "np", ".", "load", "(", "gen_npz", ")", "[", "\"pool_var\"", "]", "\n", "\n", "#def get_inception_metrics(sample, num_inception_images, num_splits=10,", "\n", "#                          prints=True, use_torch=use_torch):", "\n", "\n", "#mu, sigma = torch.from_numpy(mu), torch.from_numpy(sigma)", "\n", "print", "(", "\"sigma\"", ")", "\n", "print", "(", "sigma", ")", "\n", "print", "(", "'Covariances calculated, getting FID...'", ")", "\n", "FID", "=", "numpy_calculate_frechet_distance", "(", "mu", ",", "sigma", ",", "data_mu", ",", "data_sigma", ")", "\n", "# Delete mu, sigma, pool, logits, and labels, just in case", "\n", "\n", "return", "FID", "\n", "#return get_inception_metrics", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.CenterCropLongEdge.__call__": [[462, 470], ["torchvision.functional.center_crop", "torchvision.functional.center_crop", "min"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        img (PIL Image): Image to be cropped.\n    Returns:\n        PIL Image: Cropped image.\n    \"\"\"", "\n", "return", "transforms", ".", "functional", ".", "center_crop", "(", "img", ",", "min", "(", "img", ".", "size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.CenterCropLongEdge.__repr__": [[471, 473], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.RandomCropLongEdge.__call__": [[481, 495], ["torchvision.functional.crop", "torchvision.functional.crop", "min", "min", "numpy.random.randint", "numpy.random.randint"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        img (PIL Image): Image to be cropped.\n    Returns:\n        PIL Image: Cropped image.\n    \"\"\"", "\n", "size", "=", "(", "min", "(", "img", ".", "size", ")", ",", "min", "(", "img", ".", "size", ")", ")", "\n", "# Only step forward along this edge if it's the long edge", "\n", "i", "=", "(", "0", "if", "size", "[", "0", "]", "==", "img", ".", "size", "[", "0", "]", "\n", "else", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "img", ".", "size", "[", "0", "]", "-", "size", "[", "0", "]", ")", ")", "\n", "j", "=", "(", "0", "if", "size", "[", "1", "]", "==", "img", ".", "size", "[", "1", "]", "\n", "else", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "img", ".", "size", "[", "1", "]", "-", "size", "[", "1", "]", ")", ")", "\n", "return", "transforms", ".", "functional", ".", "crop", "(", "img", ",", "i", ",", "j", ",", "size", "[", "0", "]", ",", "size", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.RandomCropLongEdge.__repr__": [[496, 498], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.ema.__init__": [[637, 650], ["utils.ema.source.state_dict", "utils.ema.target.state_dict", "print", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "utils.ema.target_dict[].data.copy_"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "source", ",", "target", ",", "decay", "=", "0.9999", ",", "start_itr", "=", "0", ")", ":", "\n", "    ", "self", ".", "source", "=", "source", "\n", "self", ".", "target", "=", "target", "\n", "self", ".", "decay", "=", "decay", "\n", "# Optional parameter indicating what iteration to start the decay at", "\n", "self", ".", "start_itr", "=", "start_itr", "\n", "# Initialize target's params to be source's", "\n", "self", ".", "source_dict", "=", "self", ".", "source", ".", "state_dict", "(", ")", "\n", "self", ".", "target_dict", "=", "self", ".", "target", ".", "state_dict", "(", ")", "\n", "print", "(", "'Initializing EMA parameters to be source parameters...'", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "      ", "for", "key", "in", "self", ".", "source_dict", ":", "\n", "        ", "self", ".", "target_dict", "[", "key", "]", ".", "data", ".", "copy_", "(", "self", ".", "source_dict", "[", "key", "]", ".", "data", ")", "\n", "# target_dict[key].data = source_dict[key].data # Doesn't work!", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.ema.update": [[654, 665], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "utils.ema.target_dict[].data.copy_"], "methods", ["None"], ["", "", "", "def", "update", "(", "self", ",", "itr", "=", "None", ")", ":", "\n", "# If an iteration counter is provided and itr is less than the start itr,", "\n", "# peg the ema weights to the underlying weights.", "\n", "    ", "if", "itr", "and", "itr", "<", "self", ".", "start_itr", ":", "\n", "      ", "decay", "=", "0.0", "\n", "", "else", ":", "\n", "      ", "decay", "=", "self", ".", "decay", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "      ", "for", "key", "in", "self", ".", "source_dict", ":", "\n", "        ", "self", ".", "target_dict", "[", "key", "]", ".", "data", ".", "copy_", "(", "self", ".", "target_dict", "[", "key", "]", ".", "data", "*", "decay", "\n", "+", "self", ".", "source_dict", "[", "key", "]", ".", "data", "*", "(", "1", "-", "decay", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.MetricsLogger.__init__": [[782, 789], ["os.path.exists", "print", "os.remove"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "fname", ",", "reinitialize", "=", "False", ")", ":", "\n", "    ", "self", ".", "fname", "=", "fname", "\n", "self", ".", "reinitialize", "=", "reinitialize", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "fname", ")", ":", "\n", "      ", "if", "self", ".", "reinitialize", ":", "\n", "        ", "print", "(", "'{} exists, deleting...'", ".", "format", "(", "self", ".", "fname", ")", ")", "\n", "os", ".", "remove", "(", "self", ".", "fname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.MetricsLogger.log": [[790, 800], ["record.update", "time.time", "open", "f.write", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.ema.update"], ["", "", "", "def", "log", "(", "self", ",", "record", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Assumption: no newlines in the input.\n    \"\"\"", "\n", "if", "record", "is", "None", ":", "\n", "      ", "record", "=", "{", "}", "\n", "", "record", ".", "update", "(", "kwargs", ")", "\n", "record", "[", "'_stamp'", "]", "=", "time", ".", "time", "(", ")", "\n", "with", "open", "(", "self", ".", "fname", ",", "'a'", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "json", ".", "dumps", "(", "record", ",", "ensure_ascii", "=", "True", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.MyLogger.__init__": [[809, 816], ["os.path.exists", "os.mkdir"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "fname", ",", "reinitialize", "=", "False", ",", "logstyle", "=", "'%3.3f'", ")", ":", "\n", "    ", "self", ".", "root", "=", "fname", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "root", ")", ":", "\n", "      ", "os", ".", "mkdir", "(", "self", ".", "root", ")", "\n", "", "self", ".", "reinitialize", "=", "reinitialize", "\n", "self", ".", "metrics", "=", "[", "]", "\n", "self", ".", "logstyle", "=", "logstyle", "# One of '%3.3f' or like '%3.3e'", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.MyLogger.reinit": [[818, 828], ["os.path.exists", "os.remove", "print", "any", "print"], "methods", ["None"], ["", "def", "reinit", "(", "self", ",", "item", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "'%s/%s.log'", "%", "(", "self", ".", "root", ",", "item", ")", ")", ":", "\n", "      ", "if", "self", ".", "reinitialize", ":", "\n", "# Only print the removal mess", "\n", "        ", "if", "'sv'", "in", "item", ":", "\n", "          ", "if", "not", "any", "(", "'sv'", "in", "item", "for", "item", "in", "self", ".", "metrics", ")", ":", "\n", "            ", "print", "(", "'Deleting singular value logs...'", ")", "\n", "", "", "else", ":", "\n", "          ", "print", "(", "'{} exists, deleting...'", ".", "format", "(", "'%s_%s.log'", "%", "(", "self", ".", "root", ",", "item", ")", ")", ")", "\n", "", "os", ".", "remove", "(", "'%s/%s.log'", "%", "(", "self", ".", "root", ",", "item", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.MyLogger.log": [[830, 851], ["isinstance", "print", "utils.MyLogger.reinit", "print", "open", "isinstance", "f.write", "f.write", "str", "str"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.MyLogger.reinit"], ["", "", "", "def", "log", "(", "self", ",", "itr", ",", "**", "kwargs", ")", ":", "\n", "    ", "for", "arg", "in", "kwargs", ":", "\n", "      ", "if", "isinstance", "(", "kwargs", "[", "arg", "]", ",", "list", ")", ":", "\n", "        ", "mylist", "=", "\"[ \"", "+", "\",\"", ".", "join", "(", "[", "str", "(", "e", ")", "for", "e", "in", "kwargs", "[", "arg", "]", "]", ")", "+", "\" ]\"", "\n", "kwargs", "[", "arg", "]", "=", "mylist", "\n", "", "if", "arg", "not", "in", "self", ".", "metrics", ":", "\n", "        ", "if", "self", ".", "reinitialize", ":", "\n", "          ", "self", ".", "reinit", "(", "arg", ")", "\n", "", "self", ".", "metrics", "+=", "[", "arg", "]", "\n", "", "if", "self", ".", "logstyle", "==", "'pickle'", ":", "\n", "        ", "print", "(", "'Pickle not currently supported...'", ")", "\n", "# with open('%s/%s.log' % (self.root, arg), 'a') as f:", "\n", "# pickle.dump(kwargs[arg], f)", "\n", "", "elif", "self", ".", "logstyle", "==", "'mat'", ":", "\n", "        ", "print", "(", "'.mat logstyle not currently supported...'", ")", "\n", "", "else", ":", "\n", "        ", "with", "open", "(", "'%s/%s.log'", "%", "(", "self", ".", "root", ",", "arg", ")", ",", "'a'", ")", "as", "f", ":", "\n", "          ", "if", "isinstance", "(", "kwargs", "[", "arg", "]", ",", "str", ")", ":", "\n", "            ", "f", ".", "write", "(", "str", "(", "itr", ")", "+", "\": \"", "+", "kwargs", "[", "arg", "]", "+", "\"\\n\"", ")", "\n", "", "else", ":", "\n", "            ", "f", ".", "write", "(", "'%d: %s\\n'", "%", "(", "itr", ",", "self", ".", "logstyle", "%", "kwargs", "[", "arg", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.init_distribution": [[1135, 1142], ["None"], "methods", ["None"], ["    ", "def", "init_distribution", "(", "self", ",", "dist_type", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "dist_type", "=", "dist_type", "\n", "self", ".", "dist_kwargs", "=", "kwargs", "\n", "if", "self", ".", "dist_type", "==", "'normal'", "or", "self", ".", "dist_type", "==", "'nested_normal'", ":", "\n", "            ", "self", ".", "mean", ",", "self", ".", "var", "=", "kwargs", "[", "'mean'", "]", ",", "kwargs", "[", "'var'", "]", "\n", "", "elif", "self", ".", "dist_type", "==", "'categorical'", ":", "\n", "            ", "self", ".", "num_categories", "=", "kwargs", "[", "'num_categories'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.sample_": [[1143, 1148], ["utils.Distribution.normal_", "utils.Distribution.random_"], "methods", ["None"], ["", "", "def", "sample_", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dist_type", "==", "'normal'", ":", "\n", "            ", "self", ".", "normal_", "(", "self", ".", "mean", ",", "self", ".", "var", ")", "\n", "", "elif", "self", ".", "dist_type", "==", "'categorical'", ":", "\n", "            ", "self", ".", "random_", "(", "0", ",", "self", ".", "num_categories", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.to": [[1149, 1154], ["utils.Distribution", "utils.Distribution.init_distribution", "super().to"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.init_distribution", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.to"], ["", "", "def", "to", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "dist", "=", "Distribution", "(", "self", ")", "\n", "dist", ".", "init_distribution", "(", "self", ".", "dist_type", ",", "**", "self", ".", "dist_kwargs", ")", "\n", "dist", ".", "data", "=", "super", "(", ")", ".", "to", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Adam16.__init__": [[1200, 1205], ["dict", "list", "torch.optim.optimizer.Optimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__"], ["  ", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "weight_decay", "=", "0", ")", ":", "\n", "    ", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "\n", "weight_decay", "=", "weight_decay", ")", "\n", "params", "=", "list", "(", "params", ")", "\n", "super", "(", "Adam16", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Adam16.load_state_dict": [[1207, 1214], ["super().load_state_dict", "[].float", "[].float", "[].float"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Adam16.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "    ", "super", "(", "Adam16", ",", "self", ")", ".", "load_state_dict", "(", "state_dict", ")", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "      ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "        ", "self", ".", "state", "[", "p", "]", "[", "'exp_avg'", "]", "=", "self", ".", "state", "[", "p", "]", "[", "'exp_avg'", "]", ".", "float", "(", ")", "\n", "self", ".", "state", "[", "p", "]", "[", "'exp_avg_sq'", "]", "=", "self", ".", "state", "[", "p", "]", "[", "'exp_avg_sq'", "]", ".", "float", "(", ")", "\n", "self", ".", "state", "[", "p", "]", "[", "'fp32_p'", "]", "=", "self", ".", "state", "[", "p", "]", "[", "'fp32_p'", "]", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Adam16.step": [[1215, 1265], ["closure", "p.grad.data.float", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "exp_avg_sq.sqrt().add_", "state[].addcdiv_", "state[].half", "len", "grad.add.add.new().resize_as_().zero_", "grad.add.add.new().resize_as_().zero_", "p.data.float", "grad.add.add.add", "exp_avg.mul_", "exp_avg_sq.mul_", "exp_avg_sq.sqrt", "math.sqrt", "grad.add.add.new().resize_as_", "grad.add.add.new().resize_as_", "grad.add.add.new", "grad.add.add.new"], "methods", ["None"], ["", "", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "    ", "\"\"\"Performs a single optimization step.\n    Arguments:\n      closure (callable, optional): A closure that reevaluates the model\n        and returns the loss.\n    \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "      ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "      ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "        ", "if", "p", ".", "grad", "is", "None", ":", "\n", "          ", "continue", "\n", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "          ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "grad", ".", "new", "(", ")", ".", "resize_as_", "(", "grad", ")", ".", "zero_", "(", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "grad", ".", "new", "(", ")", ".", "resize_as_", "(", "grad", ")", ".", "zero_", "(", ")", "\n", "# Fp32 copy of the weights", "\n", "state", "[", "'fp32_p'", "]", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "          ", "grad", "=", "grad", ".", "add", "(", "group", "[", "'weight_decay'", "]", ",", "state", "[", "'fp32_p'", "]", ")", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "\n", "bias_correction1", "=", "1", "-", "beta1", "**", "state", "[", "'step'", "]", "\n", "bias_correction2", "=", "1", "-", "beta2", "**", "state", "[", "'step'", "]", "\n", "step_size", "=", "group", "[", "'lr'", "]", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "bias_correction1", "\n", "\n", "state", "[", "'fp32_p'", "]", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "p", ".", "data", "=", "state", "[", "'fp32_p'", "]", ".", "half", "(", ")", "\n", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.prepare_parser": [[30, 385], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "prepare_parser", "(", ")", ":", "\n", "  ", "usage", "=", "'Parser for all scripts.'", "\n", "parser", "=", "ArgumentParser", "(", "description", "=", "usage", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_folder\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_epochs\"", ",", "type", "=", "float", ",", "default", "=", "200", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--id\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gpus\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--sample_every\"", ",", "type", "=", "int", ",", "default", "=", "1000", ")", "\n", "parser", ".", "add_argument", "(", "\"--resume_from\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--epoch_id\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--unconditional\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--slow_mixup\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--consistency_loss\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--consistency_loss_and_augmentation\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--full_batch_mixup\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--debug\"", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataloader\"", ",", "type", "=", "str", ",", "default", "=", "\"celeba128\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--unet_mixup\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--progress_bar\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "#use progress bar", "\n", "parser", ".", "add_argument", "(", "\"--display_mixed_batch\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "### Dataset/Dataloader stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--dataset'", ",", "type", "=", "str", ",", "default", "=", "'coco'", ",", "\n", "help", "=", "'Which Dataset to train on, out of I128, I256, C10, C100;'", "\n", "'Append \"_hdf5\" to use the hdf5 version for ISLVRC '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--augment'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Augment with random crops and flips (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_workers'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "\n", "help", "=", "'Number of dataloader workers; consider using less for HDF5 '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--no_pin_memory'", ",", "action", "=", "'store_false'", ",", "dest", "=", "'pin_memory'", ",", "default", "=", "True", ",", "\n", "help", "=", "'Pin data into memory through dataloader? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--shuffle'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Shuffle the data (strongly recommended)? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--load_in_mem'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Load all data into memory? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--use_multiepoch_sampler'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Use the multi-epoch sampler for dataloader? (default: %(default)s)'", ")", "\n", "\n", "\n", "### Model stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--model'", ",", "type", "=", "str", ",", "default", "=", "'BigGAN'", ",", "\n", "help", "=", "'Name of the model module (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_param'", ",", "type", "=", "str", ",", "default", "=", "'SN'", ",", "\n", "help", "=", "'Parameterization style to use for G, spectral norm (SN) or SVD (SVD)'", "\n", "' or None (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_param'", ",", "type", "=", "str", ",", "default", "=", "'SN'", ",", "\n", "help", "=", "'Parameterization style to use for D, spectral norm (SN) or SVD (SVD)'", "\n", "' or None (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_ch'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Channel multiplier for G (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_ch'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Channel multiplier for D (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_depth'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of resblocks per stage in G? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_depth'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of resblocks per stage in D? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_thin'", ",", "action", "=", "'store_false'", ",", "dest", "=", "'D_wide'", ",", "default", "=", "True", ",", "\n", "help", "=", "'Use the SN-GAN channel pattern for D? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_shared'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Use shared embeddings in G? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--shared_dim'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'G'", "'s shared embedding dimensionality; if 0, will be equal to dim_z. '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--dim_z'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "\n", "help", "=", "'Noise dimensionality: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--z_var'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'Noise variance: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--hier'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Use hierarchical z in G? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cross_replica'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Cross_replica batchnorm in G?(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--mybn'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Use my batchnorm (which supports standing stats?) %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_nl'", ",", "type", "=", "str", ",", "default", "=", "'relu'", ",", "\n", "help", "=", "'Activation function for G (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_nl'", ",", "type", "=", "str", ",", "default", "=", "'relu'", ",", "\n", "help", "=", "'Activation function for D (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_attn'", ",", "type", "=", "str", ",", "default", "=", "'64'", ",", "\n", "help", "=", "'What resolutions to use attention on for G (underscore separated) '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_attn'", ",", "type", "=", "str", ",", "default", "=", "'64'", ",", "\n", "help", "=", "'What resolutions to use attention on for D (underscore separated) '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--norm_style'", ",", "type", "=", "str", ",", "default", "=", "'bn'", ",", "\n", "help", "=", "'Normalizer style for G, one of bn [batchnorm], in [instancenorm], '", "\n", "'ln [layernorm], gn [groupnorm] (default: %(default)s)'", ")", "\n", "\n", "### Model init stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Random seed to use; affects both initialization and '", "\n", "' dataloading. (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_init'", ",", "type", "=", "str", ",", "default", "=", "'ortho'", ",", "\n", "help", "=", "'Init style to use for G (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_init'", ",", "type", "=", "str", ",", "default", "=", "'ortho'", ",", "\n", "help", "=", "'Init style to use for D(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--skip_init'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Skip initialization, ideal for testing when ortho init was used '", "\n", "'(default: %(default)s)'", ")", "\n", "\n", "### Optimizer stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_lr'", ",", "type", "=", "float", ",", "default", "=", "5e-5", ",", "\n", "help", "=", "'Learning rate to use for Generator (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_lr'", ",", "type", "=", "float", ",", "default", "=", "2e-4", ",", "\n", "help", "=", "'Learning rate to use for Discriminator (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_B1'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "'Beta1 to use for Generator (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_B1'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "'Beta1 to use for Discriminator (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_B2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "'Beta2 to use for Generator (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_B2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "'Beta2 to use for Discriminator (default: %(default)s)'", ")", "\n", "\n", "### Batch size, parallel, and precision stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Default overall batchsize (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_batch_size'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Batch size to use for G; if 0, same as D (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_G_accumulations'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of passes to accumulate G'", "'s gradients over '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_D_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "#2 is default but gives index error", "\n", "help", "=", "'Number of D steps per G step (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_D_accumulations'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of passes to accumulate D'", "'s gradients over '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--split_D'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Run D twice rather than concatenating inputs? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_epochs'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "'Number of epochs to train for (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--parallel'", ",", "action", "=", "'store_true'", ",", "default", "=", "True", ",", "\n", "help", "=", "'Train with multiple GPUs (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_fp16'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Train with half-precision in G? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_fp16'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Train with half-precision in D? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_mixed_precision'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Train with half-precision activations but fp32 params in D? '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_mixed_precision'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Train with half-precision activations but fp32 params in G? '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--accumulate_stats'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Accumulate \"standing\" batchnorm stats? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_standing_accumulations'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "\n", "help", "=", "'Number of forward passes to use in accumulating standing stats? '", "\n", "'(default: %(default)s)'", ")", "\n", "\n", "### Bookkeping stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_eval_mode'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Run G in eval mode (running/standing stats?) at sample/test time? '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--save_every'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "\n", "help", "=", "'Save every X iterations (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_save_copies'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'How many copies to save (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_best_copies'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'How many previous best checkpoints to save (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--which_best'", ",", "type", "=", "str", ",", "default", "=", "'IS'", ",", "\n", "help", "=", "'Which metric to use to determine when to save new \"best\"'", "\n", "'checkpoints, one of IS or FID (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--no_fid'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Calculate IS only, not FID? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--test_every'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "\n", "help", "=", "'Test every X iterations (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_inception_images'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "'Number of samples to compute inception metrics with '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--hashname'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Use a hash of the experiment name instead of the full config '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--base_root'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Default location to store all weights, samples, data, and logs '", "\n", "' (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--data_root'", ",", "type", "=", "str", ",", "default", "=", "'data'", ",", "\n", "help", "=", "'Default location where data is stored (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--weights_root'", ",", "type", "=", "str", ",", "default", "=", "'weights'", ",", "\n", "help", "=", "'Default location to store weights (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--logs_root'", ",", "type", "=", "str", ",", "default", "=", "'logs'", ",", "\n", "help", "=", "'Default location to store logs (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--samples_root'", ",", "type", "=", "str", ",", "default", "=", "'samples'", ",", "\n", "help", "=", "'Default location to store samples (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--pbar'", ",", "type", "=", "str", ",", "default", "=", "'mine'", ",", "\n", "help", "=", "'Type of progressbar to use; one of \"mine\" or \"tqdm\" '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--name_suffix'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Suffix for experiment name for loading weights for sampling '", "\n", "'(consider \"best0\") (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--experiment_name'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Optionally override the automatic experiment naming with this arg. '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--config_from_name'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Use a hash of the experiment name instead of the full config '", "\n", "'(default: %(default)s)'", ")", "\n", "\n", "### EMA Stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--ema'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Keep an ema of G'", "'s weights? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--ema_decay'", ",", "type", "=", "float", ",", "default", "=", "0.9999", ",", "\n", "help", "=", "'EMA decay rate (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--use_ema'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Use the EMA parameters of G for evaluation? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--ema_start'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'When to start updating the EMA weights (default: %(default)s)'", ")", "\n", "\n", "### Numerical precision and SV stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--adam_eps'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ",", "\n", "help", "=", "'epsilon value to use for Adam (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--BN_eps'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ",", "\n", "help", "=", "'epsilon value to use for BatchNorm (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--SN_eps'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ",", "\n", "help", "=", "'epsilon value to use for Spectral Norm(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_G_SVs'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of SVs to track in G (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_D_SVs'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of SVs to track in D (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_G_SV_itrs'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of SV itrs in G (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--num_D_SV_itrs'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of SV itrs in D (default: %(default)s)'", ")", "\n", "\n", "### Ortho reg stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--G_ortho'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "# 1e-4 is default for BigGAN", "\n", "help", "=", "'Modified ortho reg coefficient in G(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--D_ortho'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "'Modified ortho reg coefficient in D (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--toggle_grads'", ",", "action", "=", "'store_true'", ",", "default", "=", "True", ",", "\n", "help", "=", "'Toggle D and G'", "'s \"requires_grad\" settings when not training them? '", "\n", "' (default: %(default)s)'", ")", "\n", "\n", "### Which train function ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--which_train_fn'", ",", "type", "=", "str", ",", "default", "=", "'GAN'", ",", "\n", "help", "=", "'How2trainyourbois (default: %(default)s)'", ")", "\n", "\n", "### Resume training stuff", "\n", "parser", ".", "add_argument", "(", "\n", "'--load_weights'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Suffix for which weights to load (e.g. best0, copy0) '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--resume'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Resume training? (default: %(default)s)'", ")", "\n", "\n", "\n", "### Log stuff ###", "\n", "parser", ".", "add_argument", "(", "\n", "'--logstyle'", ",", "type", "=", "str", ",", "default", "=", "'%3.3e'", ",", "\n", "help", "=", "'What style to use when logging training metrics?'", "\n", "'One of: %#.#f/ %#.#e (float/exp, text),'", "\n", "'pickle (python pickle),'", "\n", "'npz (numpy zip),'", "\n", "'mat (MATLAB .mat file) (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--log_G_spectra'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Log the top 3 singular values in each SN layer in G? '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--log_D_spectra'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Log the top 3 singular values in each SN layer in D? '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sv_log_interval'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'Iteration interval for logging singular values '", "\n", "' (default: %(default)s)'", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.add_sample_parser": [[387, 423], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "def", "add_sample_parser", "(", "parser", ")", ":", "\n", "  ", "parser", ".", "add_argument", "(", "\n", "'--sample_npz'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Sample \"sample_num_npz\" images and save to npz? '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sample_num_npz'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "'Number of images to sample when sampling NPZs '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sample_sheets'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Produce class-conditional sample sheets and stick them in '", "\n", "'the samples root? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sample_interps'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Produce interpolation sheets and stick them in '", "\n", "'the samples root? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sample_sheet_folder_num'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Number to use for the folder for these sample sheets '", "\n", "'(default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sample_random'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Produce a single random sheet? (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sample_trunc_curves'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Get inception metrics with a range of variances?'", "\n", "'To use this, specify a startpoint, step, and endpoint, e.g. '", "\n", "'--sample_trunc_curves 0.2_0.1_1.0 for a startpoint of 0.2, '", "\n", "'endpoint of 1.0, and stepsize of 1.0.  Note that this is '", "\n", "'not exactly identical to using tf.truncated_normal, but should '", "\n", "'have approximately the same effect. (default: %(default)s)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sample_inception_metrics'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Calculate Inception metrics with sample.py? (default: %(default)s)'", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.get_data_loaders": [[546, 606], ["print", "which_dataset", "loaders.append", "torchvision.Compose", "print", "MultiEpochSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "print", "torchvision.RandomCrop", "torchvision.RandomHorizontalFlip", "utils.RandomCropLongEdge", "torchvision.Resize", "torchvision.RandomHorizontalFlip", "utils.CenterCropLongEdge", "torchvision.Resize", "torchvision.ToTensor", "torchvision.Normalize"], "function", ["None"], ["def", "get_data_loaders", "(", "dataset", ",", "data_root", "=", "None", ",", "augment", "=", "False", ",", "batch_size", "=", "64", ",", "\n", "num_workers", "=", "8", ",", "shuffle", "=", "True", ",", "load_in_mem", "=", "False", ",", "hdf5", "=", "False", ",", "\n", "pin_memory", "=", "True", ",", "drop_last", "=", "True", ",", "start_itr", "=", "0", ",", "\n", "num_epochs", "=", "500", ",", "use_multiepoch_sampler", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "# Append /FILENAME.hdf5 to root if using hdf5", "\n", "  ", "data_root", "+=", "'/%s'", "%", "root_dict", "[", "dataset", "]", "\n", "print", "(", "'Using dataset root location %s'", "%", "data_root", ")", "\n", "\n", "which_dataset", "=", "dset_dict", "[", "dataset", "]", "\n", "norm_mean", "=", "[", "0.5", ",", "0.5", ",", "0.5", "]", "\n", "norm_std", "=", "[", "0.5", ",", "0.5", ",", "0.5", "]", "\n", "image_size", "=", "imsize_dict", "[", "dataset", "]", "\n", "# For image folder datasets, name of the file where we store the precomputed", "\n", "# image locations to avoid having to walk the dirs every time we load.", "\n", "dataset_kwargs", "=", "{", "'index_filename'", ":", "'%s_imgs.npz'", "%", "dataset", "}", "\n", "\n", "# HDF5 datasets have their own inbuilt transform, no need to train_transform", "\n", "if", "'hdf5'", "in", "dataset", ":", "\n", "    ", "train_transform", "=", "None", "\n", "", "else", ":", "\n", "    ", "if", "augment", ":", "\n", "      ", "print", "(", "'Data will be augmented...'", ")", "\n", "if", "dataset", "in", "[", "'C10'", ",", "'C100'", "]", ":", "\n", "        ", "train_transform", "=", "[", "transforms", ".", "RandomCrop", "(", "32", ",", "padding", "=", "4", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", "]", "\n", "", "else", ":", "\n", "        ", "train_transform", "=", "[", "RandomCropLongEdge", "(", ")", ",", "\n", "transforms", ".", "Resize", "(", "image_size", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", "]", "\n", "", "", "else", ":", "\n", "      ", "print", "(", "'Data will not be augmented...'", ")", "\n", "if", "dataset", "in", "[", "'C10'", ",", "'C100'", "]", ":", "\n", "        ", "train_transform", "=", "[", "]", "\n", "", "else", ":", "\n", "        ", "train_transform", "=", "[", "CenterCropLongEdge", "(", ")", ",", "transforms", ".", "Resize", "(", "image_size", ")", "]", "\n", "# train_transform = [transforms.Resize(image_size), transforms.CenterCrop]", "\n", "", "", "train_transform", "=", "transforms", ".", "Compose", "(", "train_transform", "+", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "norm_mean", ",", "norm_std", ")", "]", ")", "\n", "", "train_set", "=", "which_dataset", "(", "root", "=", "data_root", ",", "transform", "=", "train_transform", ",", "\n", "load_in_mem", "=", "load_in_mem", ",", "**", "dataset_kwargs", ")", "\n", "\n", "# Prepare loader; the loaders list is for forward compatibility with", "\n", "# using validation / test splits.", "\n", "loaders", "=", "[", "]", "\n", "if", "use_multiepoch_sampler", ":", "\n", "    ", "print", "(", "'Using multiepoch sampler from start_itr %d...'", "%", "start_itr", ")", "\n", "loader_kwargs", "=", "{", "'num_workers'", ":", "num_workers", ",", "'pin_memory'", ":", "pin_memory", "}", "\n", "sampler", "=", "MultiEpochSampler", "(", "train_set", ",", "num_epochs", ",", "start_itr", ",", "batch_size", ")", "\n", "train_loader", "=", "DataLoader", "(", "train_set", ",", "batch_size", "=", "batch_size", ",", "\n", "sampler", "=", "sampler", ",", "**", "loader_kwargs", ")", "\n", "", "else", ":", "\n", "    ", "loader_kwargs", "=", "{", "'num_workers'", ":", "num_workers", ",", "'pin_memory'", ":", "pin_memory", ",", "\n", "'drop_last'", ":", "drop_last", "}", "# Default, drop last incomplete batch", "\n", "train_loader", "=", "DataLoader", "(", "train_set", ",", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "shuffle", ",", "**", "loader_kwargs", ")", "\n", "", "loaders", ".", "append", "(", "train_loader", ")", "\n", "return", "loaders", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.seed_rng": [[609, 613], ["torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "numpy.random.seed"], "function", ["None"], ["", "def", "seed_rng", "(", "seed", ")", ":", "\n", "  ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.update_config_roots": [[617, 623], ["print"], "function", ["None"], ["", "def", "update_config_roots", "(", "config", ")", ":", "\n", "  ", "if", "config", "[", "'base_root'", "]", ":", "\n", "    ", "print", "(", "'Pegging all root folders to base root %s'", "%", "config", "[", "'base_root'", "]", ")", "\n", "for", "key", "in", "[", "'data'", ",", "'weights'", ",", "'logs'", ",", "'samples'", "]", ":", "\n", "      ", "config", "[", "'%s_root'", "%", "key", "]", "=", "'%s/%s'", "%", "(", "config", "[", "'base_root'", "]", ",", "key", ")", "\n", "", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.prepare_root": [[626, 631], ["os.path.exists", "print", "os.mkdir"], "function", ["None"], ["", "def", "prepare_root", "(", "config", ")", ":", "\n", "  ", "for", "key", "in", "[", "'weights_root'", ",", "'logs_root'", ",", "'samples_root'", "]", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "config", "[", "key", "]", ")", ":", "\n", "      ", "print", "(", "'Making directory %s for %s...'", "%", "(", "config", "[", "key", "]", ",", "key", ")", ")", "\n", "os", ".", "mkdir", "(", "config", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.ortho": [[670, 680], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "model.parameters", "param.view", "any", "torch.mm", "torch.mm", "torch.mm", "grad.view", "len", "torch.mm", "torch.mm", "torch.mm", "param.view.t", "torch.eye", "torch.eye", "torch.eye"], "function", ["None"], ["", "", "", "", "def", "ortho", "(", "model", ",", "strength", "=", "1e-4", ",", "blacklist", "=", "[", "]", ")", ":", "\n", "  ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "    ", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "# Only apply this to parameters with at least 2 axes, and not in the blacklist", "\n", "      ", "if", "len", "(", "param", ".", "shape", ")", "<", "2", "or", "any", "(", "[", "param", "is", "item", "for", "item", "in", "blacklist", "]", ")", ":", "\n", "        ", "continue", "\n", "", "w", "=", "param", ".", "view", "(", "param", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "grad", "=", "(", "2", "*", "torch", ".", "mm", "(", "torch", ".", "mm", "(", "w", ",", "w", ".", "t", "(", ")", ")", "\n", "*", "(", "1.", "-", "torch", ".", "eye", "(", "w", ".", "shape", "[", "0", "]", ",", "device", "=", "w", ".", "device", ")", ")", ",", "w", ")", ")", "\n", "param", ".", "grad", ".", "data", "+=", "strength", "*", "grad", ".", "view", "(", "param", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.default_ortho": [[685, 695], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "model.parameters", "param.view", "torch.mm", "torch.mm", "torch.mm", "grad.view", "len", "torch.mm", "torch.mm", "torch.mm", "torch.eye", "torch.eye", "torch.eye", "param.view.t"], "function", ["None"], ["", "", "", "def", "default_ortho", "(", "model", ",", "strength", "=", "1e-4", ",", "blacklist", "=", "[", "]", ")", ":", "\n", "  ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "    ", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "# Only apply this to parameters with at least 2 axes & not in blacklist", "\n", "      ", "if", "len", "(", "param", ".", "shape", ")", "<", "2", "or", "param", "in", "blacklist", ":", "\n", "        ", "continue", "\n", "", "w", "=", "param", ".", "view", "(", "param", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "grad", "=", "(", "2", "*", "torch", ".", "mm", "(", "torch", ".", "mm", "(", "w", ",", "w", ".", "t", "(", ")", ")", "\n", "-", "torch", ".", "eye", "(", "w", ".", "shape", "[", "0", "]", ",", "device", "=", "w", ".", "device", ")", ",", "w", ")", ")", "\n", "param", ".", "grad", ".", "data", "+=", "strength", "*", "grad", ".", "view", "(", "param", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.toggle_grad": [[698, 701], ["model.parameters"], "function", ["None"], ["", "", "", "def", "toggle_grad", "(", "model", ",", "on_or_off", ")", ":", "\n", "  ", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "    ", "param", ".", "requires_grad", "=", "on_or_off", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.join_strings": [[706, 708], ["base_string.join"], "function", ["None"], ["", "", "def", "join_strings", "(", "base_string", ",", "strings", ")", ":", "\n", "  ", "return", "base_string", ".", "join", "(", "[", "item", "for", "item", "in", "strings", "if", "item", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.save_weights": [[711, 733], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.exists", "os.mkdir", "print", "print", "G.state_dict", "G.optim.state_dict", "D.state_dict", "D.optim.state_dict", "torch.save", "torch.save", "torch.save", "G_ema.state_dict", "utils.join_strings", "utils.join_strings", "utils.join_strings", "utils.join_strings", "utils.join_strings", "utils.join_strings", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.join_strings", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.join_strings", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.join_strings", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.join_strings", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.join_strings", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.join_strings"], ["", "def", "save_weights", "(", "G", ",", "D", ",", "state_dict", ",", "weights_root", ",", "experiment_name", ",", "\n", "name_suffix", "=", "None", ",", "G_ema", "=", "None", ")", ":", "\n", "  ", "root", "=", "'/'", ".", "join", "(", "[", "weights_root", ",", "experiment_name", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "root", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "root", ")", "\n", "", "if", "name_suffix", ":", "\n", "    ", "print", "(", "'Saving weights to %s/%s...'", "%", "(", "root", ",", "name_suffix", ")", ")", "\n", "", "else", ":", "\n", "    ", "print", "(", "'Saving weights to %s...'", "%", "root", ")", "\n", "", "torch", ".", "save", "(", "G", ".", "state_dict", "(", ")", ",", "\n", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'G'", ",", "name_suffix", ",", "\"ep\"", ",", "str", "(", "state_dict", "[", "\"epoch\"", "]", ")", "]", ")", ")", ")", "\n", "torch", ".", "save", "(", "G", ".", "optim", ".", "state_dict", "(", ")", ",", "\n", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'G_optim'", ",", "name_suffix", ",", "\"ep\"", ",", "str", "(", "state_dict", "[", "\"epoch\"", "]", ")", "]", ")", ")", ")", "\n", "torch", ".", "save", "(", "D", ".", "state_dict", "(", ")", ",", "\n", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'D'", ",", "name_suffix", ",", "\"ep\"", ",", "str", "(", "state_dict", "[", "\"epoch\"", "]", ")", "]", ")", ")", ")", "\n", "torch", ".", "save", "(", "D", ".", "optim", ".", "state_dict", "(", ")", ",", "\n", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'D_optim'", ",", "name_suffix", ",", "\"ep\"", ",", "str", "(", "state_dict", "[", "\"epoch\"", "]", ")", "]", ")", ")", ")", "\n", "torch", ".", "save", "(", "state_dict", ",", "\n", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'state_dict'", ",", "name_suffix", ",", "\"ep\"", ",", "str", "(", "state_dict", "[", "\"epoch\"", "]", ")", "]", ")", ")", ")", "\n", "if", "G_ema", "is", "not", "None", ":", "\n", "    ", "torch", ".", "save", "(", "G_ema", ".", "state_dict", "(", ")", ",", "\n", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'G_ema'", ",", "name_suffix", ",", "\"ep\"", ",", "str", "(", "state_dict", "[", "\"epoch\"", "]", ")", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.load_weights": [[736, 777], ["print", "print", "print", "G.load_state_dict", "torch.load.load_state_dict", "torch.load", "torch.load", "torch.load", "G_ema.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "print", "G.optim.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load.optim.load_state_dict", "print", "torch.load", "torch.load", "torch.load", "len", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "utils.join_strings", "utils.join_strings", "utils.join_strings", "utils.join_strings", "utils.join_strings", "utils.join_strings", "utils.join_strings"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Adam16.load_state_dict", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Adam16.load_state_dict", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Adam16.load_state_dict", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Adam16.load_state_dict", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Adam16.load_state_dict", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.join_strings", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.join_strings", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.join_strings", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.join_strings", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.join_strings", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.join_strings", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.join_strings"], ["", "", "def", "load_weights", "(", "G", ",", "D", ",", "state_dict", ",", "weights_root", ",", "experiment_name", ",", "config", ",", "epoch_id", "=", "''", ",", "\n", "name_suffix", "=", "None", ",", "G_ema", "=", "None", ",", "strict", "=", "True", ",", "load_optim", "=", "True", ")", ":", "\n", "#\"/dlc/Employees/esc2rng/biggan_abst/56932_1708_c_ctrl/weights\"", "\n", "#root = '/'.join([weights_root, experiment_name])", "\n", "#root = \"/dlc/Employees/esc2rng/biggan_abst/56932_1708_c_ctrl/weights/BigGAN_coco_seed0_Gch64_Dch64_bs64_Glr5.0e-05_Dlr2.0e-04_Gnlrelu_Dnlrelu_Ginitortho_Dinitortho_Gattn64_Dattn64/\"", "\n", "  ", "root", "=", "config", "[", "\"resume_from\"", "]", "\n", "if", "name_suffix", ":", "\n", "    ", "print", "(", "'Loading %s weights from %s...'", "%", "(", "name_suffix", ",", "root", ")", ")", "\n", "", "else", ":", "\n", "    ", "print", "(", "'Loading weights from %s...'", "%", "root", ")", "\n", "", "print", "(", "\"epoch id : \"", ",", "epoch_id", ")", "\n", "if", "G", "is", "not", "None", ":", "\n", "    ", "G", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'G'", ",", "epoch_id", ",", "name_suffix", "]", ")", ")", ")", ",", "\n", "strict", "=", "strict", ")", "\n", "if", "load_optim", ":", "\n", "      ", "s", "=", "torch", ".", "load", "(", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'G_optim'", ",", "epoch_id", ",", "name_suffix", "]", ")", ")", ")", "\n", "print", "(", "\">>\"", ",", "len", "(", "s", ")", ")", "\n", "#print(s)", "\n", "G", ".", "optim", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'G_optim'", ",", "epoch_id", ",", "name_suffix", "]", ")", ")", ")", ")", "\n", "", "", "if", "D", "is", "not", "None", ":", "\n", "    ", "D", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'D'", ",", "epoch_id", ",", "name_suffix", "]", ")", ")", ")", ",", "\n", "strict", "=", "strict", ")", "\n", "if", "load_optim", ":", "\n", "      ", "D", ".", "optim", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'D_optim'", ",", "epoch_id", ",", "name_suffix", "]", ")", ")", ")", ")", "\n", "# Load state dict", "\n", "", "", "for", "item", "in", "state_dict", ":", "\n", "    ", "D", "=", "torch", ".", "load", "(", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'state_dict'", ",", "epoch_id", ",", "name_suffix", "]", ")", ")", ")", "\n", "if", "item", "in", "D", ":", "\n", "      ", "state_dict", "[", "item", "]", "=", "D", "[", "item", "]", "\n", "", "else", ":", "\n", "      ", "print", "(", "item", ",", "\" not in state_dict, creating it ...\"", ")", "\n", "state_dict", "[", "item", "]", "=", "[", "]", "\n", "\n", "", "", "if", "G_ema", "is", "not", "None", ":", "\n", "    ", "G_ema", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "'%s/%s.pth'", "%", "(", "root", ",", "join_strings", "(", "'_'", ",", "[", "'G_ema'", ",", "epoch_id", ",", "name_suffix", "]", ")", ")", ")", ",", "\n", "strict", "=", "strict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.write_metadata": [[854, 860], ["open", "writefile.write", "writefile.write", "writefile.write", "str", "str", "str", "datetime.datetime.now"], "function", ["None"], ["", "", "", "", "", "", "def", "write_metadata", "(", "logs_root", ",", "experiment_name", ",", "config", ",", "state_dict", ")", ":", "\n", "  ", "with", "open", "(", "(", "'%s/%s/metalog.txt'", "%", "\n", "(", "logs_root", ",", "experiment_name", ")", ")", ",", "'w'", ")", "as", "writefile", ":", "\n", "    ", "writefile", ".", "write", "(", "'datetime: %s\\n'", "%", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ")", "\n", "writefile", ".", "write", "(", "'config: %s\\n'", "%", "str", "(", "config", ")", ")", "\n", "writefile", ".", "write", "(", "'state: %s\\n'", "%", "str", "(", "state_dict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.progress": [[869, 905], ["time.time", "enumerate", "print", "len", "time.time", "time.time", "print", "sys.stdout.flush", "divmod", "print", "print", "list", "list", "list", "list", "divmod", "divmod", "tuple", "divmod", "divmod", "tuple", "float"], "function", ["None"], ["def", "progress", "(", "items", ",", "desc", "=", "''", ",", "total", "=", "None", ",", "min_delay", "=", "0.1", ",", "displaytype", "=", "'s1k'", ")", ":", "\n", "  ", "\"\"\"\n  Returns a generator over `items`, printing the number and percentage of\n  items processed and the estimated remaining processing time before yielding\n  the next item. `total` gives the total number of items (required if `items`\n  has no length), and `min_delay` gives the minimum time in seconds between\n  subsequent prints. `desc` gives an optional prefix text (end with a space).\n  \"\"\"", "\n", "total", "=", "total", "or", "len", "(", "items", ")", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "t_last", "=", "0", "\n", "for", "n", ",", "item", "in", "enumerate", "(", "items", ")", ":", "\n", "    ", "t_now", "=", "time", ".", "time", "(", ")", "\n", "if", "t_now", "-", "t_last", ">", "min_delay", ":", "\n", "      ", "print", "(", "\"\\r%s%d/%d (%6.2f%%)\"", "%", "(", "\n", "desc", ",", "n", "+", "1", ",", "total", ",", "n", "/", "float", "(", "total", ")", "*", "100", ")", ",", "end", "=", "\" \"", ")", "\n", "if", "n", ">", "0", ":", "\n", "\n", "        ", "if", "displaytype", "==", "'s1k'", ":", "# minutes/seconds for 1000 iters", "\n", "          ", "next_1000", "=", "n", "+", "(", "1000", "-", "n", "%", "1000", ")", "\n", "t_done", "=", "t_now", "-", "t_start", "\n", "t_1k", "=", "t_done", "/", "n", "*", "next_1000", "\n", "outlist", "=", "list", "(", "divmod", "(", "t_done", ",", "60", ")", ")", "+", "list", "(", "divmod", "(", "t_1k", "-", "t_done", ",", "60", ")", ")", "\n", "print", "(", "\"(TE/ET1k: %d:%02d / %d:%02d)\"", "%", "tuple", "(", "outlist", ")", ",", "end", "=", "\" \"", ")", "\n", "", "else", ":", "# displaytype == 'eta':", "\n", "          ", "t_done", "=", "t_now", "-", "t_start", "\n", "t_total", "=", "t_done", "/", "n", "*", "total", "\n", "outlist", "=", "list", "(", "divmod", "(", "t_done", ",", "60", ")", ")", "+", "list", "(", "divmod", "(", "t_total", "-", "t_done", ",", "60", ")", ")", "\n", "print", "(", "\"(TE/ETA: %d:%02d / %d:%02d)\"", "%", "tuple", "(", "outlist", ")", ",", "end", "=", "\" \"", ")", "\n", "\n", "", "", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "t_last", "=", "t_now", "\n", "", "yield", "item", "\n", "", "t_total", "=", "time", ".", "time", "(", ")", "-", "t_start", "\n", "print", "(", "\"\\r%s%d/%d (100.00%%) (took %d:%02d)\"", "%", "(", "(", "desc", ",", "total", ",", "total", ")", "+", "\n", "divmod", "(", "t_total", ",", "60", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.sample": [[908, 917], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "z_.sample_", "y_.sample_", "torch.parallel.data_parallel", "G", "G.shared", "G.shared"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.sample_"], ["", "def", "sample", "(", "G", ",", "z_", ",", "y_", ",", "config", ")", ":", "\n", "  ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "    ", "z_", ".", "sample_", "(", ")", "\n", "y_", ".", "sample_", "(", ")", "\n", "if", "config", "[", "'parallel'", "]", ":", "\n", "      ", "G_z", "=", "nn", ".", "parallel", ".", "data_parallel", "(", "G", ",", "(", "z_", ",", "G", ".", "shared", "(", "y_", ")", ")", ")", "\n", "", "else", ":", "\n", "      ", "G_z", "=", "G", "(", "z_", ",", "G", ".", "shared", "(", "y_", ")", ")", "\n", "", "return", "G_z", ",", "y_", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.sample_single_class": [[918, 928], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "z_.sample_", "y_.sample_", "torch.ones().cuda().long", "torch.ones().cuda().long", "torch.ones().cuda().long", "torch.parallel.data_parallel", "G", "G.shared", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "G.shared", "torch.ones", "torch.ones", "torch.ones", "y_.size"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.sample_"], ["", "", "def", "sample_single_class", "(", "G", ",", "z_", ",", "y_", ",", "class_index", ",", "config", ")", ":", "\n", "  ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "    ", "z_", ".", "sample_", "(", ")", "\n", "y_", ".", "sample_", "(", ")", "\n", "y_", "=", "class_index", "*", "torch", ".", "ones", "(", "y_", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", ".", "long", "(", ")", "\n", "if", "config", "[", "'parallel'", "]", ":", "\n", "      ", "G_z", "=", "nn", ".", "parallel", ".", "data_parallel", "(", "G", ",", "(", "z_", ",", "G", ".", "shared", "(", "y_", ")", ")", ")", "\n", "", "else", ":", "\n", "      ", "G_z", "=", "G", "(", "z_", ",", "G", ".", "shared", "(", "y_", ")", ")", "\n", "", "return", "G_z", ",", "y_", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.sample_sheet": [[931, 975], ["range", "os.path.isdir", "os.mkdir", "os.path.isdir", "os.mkdir", "torch.arange", "torch.arange", "torch.arange", "range", "torch.stack().view().data.float().cpu", "torch.stack().view().data.float().cpu", "torch.stack().view().data.float().cpu", "torch.stack().view().data.float().cpu.size", "range", "torchvision.utils.save_image", "torchvision.utils.save_image", "hasattr", "torch.randn.sample_", "torch.randn", "torch.randn", "torch.randn", "torch.no_grad", "torch.no_grad", "torch.no_grad", "G.data.cpu", "torch.stack().view().data.float", "torch.stack().view().data.float", "torch.stack().view().data.float", "torchvision.utils.save_image", "torchvision.utils.save_image", "torch.randn.size", "torch.parallel.data_parallel", "G", "G.shared", "G.shared", "torch.stack().view", "torch.stack().view", "torch.stack().view", "torch.stack", "torch.stack", "torch.stack"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.sample_"], ["", "", "def", "sample_sheet", "(", "G", ",", "classes_per_sheet", ",", "num_classes", ",", "samples_per_class", ",", "parallel", ",", "\n", "samples_root", ",", "experiment_name", ",", "folder_number", ",", "z_", "=", "None", ",", "k", "=", "\"_\"", ",", "tons_of_results", "=", "False", ")", ":", "\n", "# Prepare sample directory", "\n", "  ", "if", "not", "os", ".", "path", ".", "isdir", "(", "'%s/%s'", "%", "(", "samples_root", ",", "experiment_name", ")", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "'%s/%s'", "%", "(", "samples_root", ",", "experiment_name", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "'%s/%s/%d'", "%", "(", "samples_root", ",", "experiment_name", ",", "folder_number", ")", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "'%s/%s/%d'", "%", "(", "samples_root", ",", "experiment_name", ",", "folder_number", ")", ")", "\n", "# loop over total number of sheets", "\n", "", "for", "i", "in", "range", "(", "num_classes", "//", "classes_per_sheet", ")", ":", "\n", "    ", "ims", "=", "[", "]", "\n", "y", "=", "torch", ".", "arange", "(", "i", "*", "classes_per_sheet", ",", "(", "i", "+", "1", ")", "*", "classes_per_sheet", ",", "device", "=", "'cuda'", ")", "\n", "#print(\"sampl\",y.size())", "\n", "for", "j", "in", "range", "(", "samples_per_class", ")", ":", "\n", "      ", "if", "(", "z_", "is", "not", "None", ")", "and", "hasattr", "(", "z_", ",", "'sample_'", ")", "and", "classes_per_sheet", "<=", "z_", ".", "size", "(", "0", ")", ":", "\n", "        ", "z_", ".", "sample_", "(", ")", "\n", "", "else", ":", "\n", "        ", "z_", "=", "torch", ".", "randn", "(", "classes_per_sheet", ",", "G", ".", "dim_z", ",", "device", "=", "'cuda'", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "if", "parallel", ":", "\n", "          ", "o", "=", "nn", ".", "parallel", ".", "data_parallel", "(", "G", ",", "(", "z_", "[", ":", "classes_per_sheet", "]", ",", "G", ".", "shared", "(", "y", ")", ")", ")", "\n", "", "else", ":", "\n", "          ", "o", "=", "G", "(", "z_", "[", ":", "classes_per_sheet", "]", ",", "G", ".", "shared", "(", "y", ")", ")", "\n", "\n", "", "", "ims", "+=", "[", "o", ".", "data", ".", "cpu", "(", ")", "]", "\n", "# This line should properly unroll the images", "\n", "", "out_ims", "=", "torch", ".", "stack", "(", "ims", ",", "1", ")", ".", "view", "(", "-", "1", ",", "ims", "[", "0", "]", ".", "shape", "[", "1", "]", ",", "ims", "[", "0", "]", ".", "shape", "[", "2", "]", ",", "\n", "ims", "[", "0", "]", ".", "shape", "[", "3", "]", ")", ".", "data", ".", "float", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "#print(\"out_ims \", out_ims.size())", "\n", "# The path for the samples", "\n", "if", "tons_of_results", ":", "\n", "        ", "n", "=", "out_ims", ".", "size", "(", "0", ")", "\n", "for", "id", "in", "range", "(", "n", ")", ":", "\n", "            ", "image_filename", "=", "'%s/%s/%d/samples%d_%s_%s.jpg'", "%", "(", "samples_root", ",", "experiment_name", ",", "\n", "folder_number", ",", "i", ",", "id", ",", "k", ")", "\n", "torchvision", ".", "utils", ".", "save_image", "(", "out_ims", "[", "id", ",", ":", ",", ":", ",", ":", "]", ",", "image_filename", ",", "\n", "nrow", "=", "1", ",", "normalize", "=", "True", ")", "\n", "\n", "\n", "", "", "else", ":", "\n", "        ", "image_filename", "=", "'%s/%s/%d/samples%d_%s.jpg'", "%", "(", "samples_root", ",", "experiment_name", ",", "\n", "folder_number", ",", "i", ",", "k", ")", "\n", "torchvision", ".", "utils", ".", "save_image", "(", "out_ims", ",", "image_filename", ",", "\n", "nrow", "=", "samples_per_class", ",", "normalize", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.interp": [[978, 981], ["torch.linspace().to", "torch.linspace().to", "torch.linspace().to", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace().to.view", "torch.linspace().to.view"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.to", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.to", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.to"], ["", "", "", "def", "interp", "(", "x0", ",", "x1", ",", "num_midpoints", ")", ":", "\n", "  ", "lerp", "=", "torch", ".", "linspace", "(", "0", ",", "1.0", ",", "num_midpoints", "+", "2", ",", "device", "=", "'cuda'", ")", ".", "to", "(", "x0", ".", "dtype", ")", "\n", "return", "(", "(", "x0", "*", "(", "1", "-", "lerp", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", ")", ")", "+", "(", "x1", "*", "lerp", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.interp_sheet": [[985, 1032], ["torchvision.utils.save_image", "torchvision.utils.save_image", "torch.randn", "torch.randn", "torch.randn", "interp().view.repeat().view", "utils.sample_1hot", "G.shared().view", "interp().view.repeat().view", "interp().view", "interp().view.half", "torch.no_grad", "torch.no_grad", "torch.no_grad", "z_.sample_", "z_[].view", "z_.sample_", "z_[].view", "interp().view", "interp().view", "torch.parallel.data_parallel().data.cpu", "interp().view.repeat", "G.shared", "interp().view.repeat", "utils.interp", "torch.parallel.data_parallel().data.cpu", "G().data.cpu", "utils.interp", "utils.interp", "G.shared().view", "G.shared().view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.parallel.data_parallel", "G.shared", "G.shared", "torch.parallel.data_parallel", "G", "utils.sample_1hot", "utils.sample_1hot", "G.shared"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.sample_1hot", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.sample_", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.interp", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.interp", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.interp", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.sample_1hot", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.sample_1hot"], ["", "def", "interp_sheet", "(", "G", ",", "num_per_sheet", ",", "num_midpoints", ",", "num_classes", ",", "parallel", ",", "\n", "samples_root", ",", "experiment_name", ",", "folder_number", ",", "sheet_number", "=", "0", ",", "\n", "fix_z", "=", "False", ",", "fix_y", "=", "False", ",", "device", "=", "'cuda'", ",", "z_", "=", "None", ",", "use_z", "=", "False", ",", "config", "=", "None", ")", ":", "\n", "# Prepare zs and ys", "\n", "  ", "if", "fix_z", ":", "# If fix Z, only sample 1 z per row", "\n", "    ", "zs", "=", "torch", ".", "randn", "(", "num_per_sheet", ",", "1", ",", "G", ".", "dim_z", ",", "device", "=", "device", ")", "\n", "zs", "=", "zs", ".", "repeat", "(", "1", ",", "num_midpoints", "+", "2", ",", "1", ")", ".", "view", "(", "-", "1", ",", "G", ".", "dim_z", ")", "\n", "", "elif", "use_z", ":", "\n", "    ", "z_", ".", "sample_", "(", ")", "\n", "z1", "=", "z_", "[", ":", "num_per_sheet", ",", ":", "]", ".", "view", "(", "num_per_sheet", ",", "1", ",", "G", ".", "dim_z", ",", ")", "\n", "z_", ".", "sample_", "(", ")", "\n", "z2", "=", "z_", "[", ":", "num_per_sheet", ",", ":", "]", ".", "view", "(", "num_per_sheet", ",", "1", ",", "G", ".", "dim_z", ",", ")", "\n", "\n", "zs", "=", "interp", "(", "z1", ",", "\n", "z2", ",", "\n", "num_midpoints", ")", ".", "view", "(", "-", "1", ",", "G", ".", "dim_z", ")", "\n", "\n", "", "else", ":", "\n", "    ", "zs", "=", "interp", "(", "torch", ".", "randn", "(", "num_per_sheet", ",", "1", ",", "G", ".", "dim_z", ",", "device", "=", "device", ")", ",", "\n", "torch", ".", "randn", "(", "num_per_sheet", ",", "1", ",", "G", ".", "dim_z", ",", "device", "=", "device", ")", ",", "\n", "num_midpoints", ")", ".", "view", "(", "-", "1", ",", "G", ".", "dim_z", ")", "\n", "", "if", "fix_y", ":", "# If fix y, only sample 1 z per row", "\n", "    ", "ys", "=", "sample_1hot", "(", "num_per_sheet", ",", "num_classes", ")", "\n", "ys", "=", "G", ".", "shared", "(", "ys", ")", ".", "view", "(", "num_per_sheet", ",", "1", ",", "-", "1", ")", "\n", "ys", "=", "ys", ".", "repeat", "(", "1", ",", "num_midpoints", "+", "2", ",", "1", ")", ".", "view", "(", "num_per_sheet", "*", "(", "num_midpoints", "+", "2", ")", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "    ", "ys", "=", "interp", "(", "G", ".", "shared", "(", "sample_1hot", "(", "num_per_sheet", ",", "num_classes", ")", ")", ".", "view", "(", "num_per_sheet", ",", "1", ",", "-", "1", ")", ",", "\n", "G", ".", "shared", "(", "sample_1hot", "(", "num_per_sheet", ",", "num_classes", ")", ")", ".", "view", "(", "num_per_sheet", ",", "1", ",", "-", "1", ")", ",", "\n", "num_midpoints", ")", ".", "view", "(", "num_per_sheet", "*", "(", "num_midpoints", "+", "2", ")", ",", "-", "1", ")", "\n", "# Run the net--note that we've already passed y through G.shared.", "\n", "", "if", "G", ".", "fp16", ":", "\n", "    ", "zs", "=", "zs", ".", "half", "(", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "#print(\"intepr\",ys.size())", "\n", "    ", "if", "config", "[", "\"dataset\"", "]", "==", "\"coco_animals\"", ":", "\n", "\n", "        ", "out_ims", "=", "nn", ".", "parallel", ".", "data_parallel", "(", "G", ",", "(", "zs", ",", "G", ".", "shared", "(", "ys", ")", ")", ")", ".", "data", ".", "cpu", "(", ")", "\n", "", "elif", "parallel", ":", "# and not config[\"no_parallel_for_sampling\"]:", "\n", "      ", "out_ims", "=", "nn", ".", "parallel", ".", "data_parallel", "(", "G", ",", "(", "zs", ",", "ys", ")", ")", ".", "data", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "     ", "out_ims", "=", "G", "(", "zs", ",", "ys", ")", ".", "data", ".", "cpu", "(", ")", "\n", "", "", "interp_style", "=", "''", "+", "(", "'Z'", "if", "not", "fix_z", "else", "''", ")", "+", "(", "'Y'", "if", "not", "fix_y", "else", "''", ")", "\n", "image_filename", "=", "'%s/%s/%d/interp%s%d.jpg'", "%", "(", "samples_root", ",", "experiment_name", ",", "\n", "folder_number", ",", "interp_style", ",", "\n", "sheet_number", ")", "\n", "torchvision", ".", "utils", ".", "save_image", "(", "out_ims", ",", "image_filename", ",", "\n", "nrow", "=", "num_midpoints", "+", "2", ",", "normalize", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.print_grad_norms": [[1036, 1045], ["numpy.argsort", "print", "float", "float", "net.parameters", "torch.norm().item", "torch.norm().item", "torch.norm().item", "torch.norm().item", "torch.norm().item", "torch.norm().item", "str", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "function", ["None"], ["", "def", "print_grad_norms", "(", "net", ")", ":", "\n", "    ", "gradsums", "=", "[", "[", "float", "(", "torch", ".", "norm", "(", "param", ".", "grad", ")", ".", "item", "(", ")", ")", ",", "\n", "float", "(", "torch", ".", "norm", "(", "param", ")", ".", "item", "(", ")", ")", ",", "param", ".", "shape", "]", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", "]", "\n", "order", "=", "np", ".", "argsort", "(", "[", "item", "[", "0", "]", "for", "item", "in", "gradsums", "]", ")", "\n", "print", "(", "[", "'%3.3e,%3.3e, %s'", "%", "(", "gradsums", "[", "item_index", "]", "[", "0", "]", ",", "\n", "gradsums", "[", "item_index", "]", "[", "1", "]", ",", "\n", "str", "(", "gradsums", "[", "item_index", "]", "[", "2", "]", ")", ")", "\n", "for", "item_index", "in", "order", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.get_SVs": [[1049, 1054], ["net.state_dict", "float", "d[].item"], "function", ["None"], ["", "def", "get_SVs", "(", "net", ",", "prefix", ")", ":", "\n", "  ", "d", "=", "net", ".", "state_dict", "(", ")", "\n", "return", "{", "(", "'%s_%s'", "%", "(", "prefix", ",", "key", ")", ")", ".", "replace", "(", "'.'", ",", "'_'", ")", ":", "\n", "float", "(", "d", "[", "key", "]", ".", "item", "(", ")", ")", "\n", "for", "key", "in", "d", "if", "'sv'", "in", "key", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.name_from_config": [[1057, 1103], ["utils.hashname"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.hashname"], ["", "def", "name_from_config", "(", "config", ")", ":", "\n", "  ", "name", "=", "'_'", ".", "join", "(", "[", "\n", "item", "for", "item", "in", "[", "\n", "'Big%s'", "%", "config", "[", "'which_train_fn'", "]", ",", "\n", "config", "[", "'dataset'", "]", ",", "\n", "config", "[", "'model'", "]", "if", "config", "[", "'model'", "]", "!=", "'BigGAN'", "else", "None", ",", "\n", "'seed%d'", "%", "config", "[", "'seed'", "]", ",", "\n", "'Gch%d'", "%", "config", "[", "'G_ch'", "]", ",", "\n", "'Dch%d'", "%", "config", "[", "'D_ch'", "]", ",", "\n", "'Gd%d'", "%", "config", "[", "'G_depth'", "]", "if", "config", "[", "'G_depth'", "]", ">", "1", "else", "None", ",", "\n", "'Dd%d'", "%", "config", "[", "'D_depth'", "]", "if", "config", "[", "'D_depth'", "]", ">", "1", "else", "None", ",", "\n", "'bs%d'", "%", "config", "[", "'batch_size'", "]", ",", "\n", "'Gfp16'", "if", "config", "[", "'G_fp16'", "]", "else", "None", ",", "\n", "'Dfp16'", "if", "config", "[", "'D_fp16'", "]", "else", "None", ",", "\n", "'nDs%d'", "%", "config", "[", "'num_D_steps'", "]", "if", "config", "[", "'num_D_steps'", "]", ">", "1", "else", "None", ",", "\n", "'nDa%d'", "%", "config", "[", "'num_D_accumulations'", "]", "if", "config", "[", "'num_D_accumulations'", "]", ">", "1", "else", "None", ",", "\n", "'nGa%d'", "%", "config", "[", "'num_G_accumulations'", "]", "if", "config", "[", "'num_G_accumulations'", "]", ">", "1", "else", "None", ",", "\n", "'Glr%2.1e'", "%", "config", "[", "'G_lr'", "]", ",", "\n", "'Dlr%2.1e'", "%", "config", "[", "'D_lr'", "]", ",", "\n", "'GB%3.3f'", "%", "config", "[", "'G_B1'", "]", "if", "config", "[", "'G_B1'", "]", "!=", "0.0", "else", "None", ",", "\n", "'GBB%3.3f'", "%", "config", "[", "'G_B2'", "]", "if", "config", "[", "'G_B2'", "]", "!=", "0.999", "else", "None", ",", "\n", "'DB%3.3f'", "%", "config", "[", "'D_B1'", "]", "if", "config", "[", "'D_B1'", "]", "!=", "0.0", "else", "None", ",", "\n", "'DBB%3.3f'", "%", "config", "[", "'D_B2'", "]", "if", "config", "[", "'D_B2'", "]", "!=", "0.999", "else", "None", ",", "\n", "'Gnl%s'", "%", "config", "[", "'G_nl'", "]", ",", "\n", "'Dnl%s'", "%", "config", "[", "'D_nl'", "]", ",", "\n", "'Ginit%s'", "%", "config", "[", "'G_init'", "]", ",", "\n", "'Dinit%s'", "%", "config", "[", "'D_init'", "]", ",", "\n", "'G%s'", "%", "config", "[", "'G_param'", "]", "if", "config", "[", "'G_param'", "]", "!=", "'SN'", "else", "None", ",", "\n", "'D%s'", "%", "config", "[", "'D_param'", "]", "if", "config", "[", "'D_param'", "]", "!=", "'SN'", "else", "None", ",", "\n", "'Gattn%s'", "%", "config", "[", "'G_attn'", "]", "if", "config", "[", "'G_attn'", "]", "!=", "'0'", "else", "None", ",", "\n", "'Dattn%s'", "%", "config", "[", "'D_attn'", "]", "if", "config", "[", "'D_attn'", "]", "!=", "'0'", "else", "None", ",", "\n", "'Gortho%2.1e'", "%", "config", "[", "'G_ortho'", "]", "if", "config", "[", "'G_ortho'", "]", ">", "0.0", "else", "None", ",", "\n", "'Dortho%2.1e'", "%", "config", "[", "'D_ortho'", "]", "if", "config", "[", "'D_ortho'", "]", ">", "0.0", "else", "None", ",", "\n", "config", "[", "'norm_style'", "]", "if", "config", "[", "'norm_style'", "]", "!=", "'bn'", "else", "None", ",", "\n", "'cr'", "if", "config", "[", "'cross_replica'", "]", "else", "None", ",", "\n", "'Gshared'", "if", "config", "[", "'G_shared'", "]", "else", "None", ",", "\n", "'hier'", "if", "config", "[", "'hier'", "]", "else", "None", ",", "\n", "'ema'", "if", "config", "[", "'ema'", "]", "else", "None", ",", "\n", "config", "[", "'name_suffix'", "]", "if", "config", "[", "'name_suffix'", "]", "else", "None", ",", "\n", "]", "\n", "if", "item", "is", "not", "None", "]", ")", "\n", "# dogball", "\n", "if", "config", "[", "'hashname'", "]", ":", "\n", "    ", "return", "hashname", "(", "name", ")", "\n", "", "else", ":", "\n", "    ", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.hashname": [[1106, 1114], ["hash", "len", "len", "len", "len", "len"], "function", ["None"], ["", "", "def", "hashname", "(", "name", ")", ":", "\n", "  ", "h", "=", "hash", "(", "name", ")", "\n", "a", "=", "h", "%", "len", "(", "animal_hash", ".", "a", ")", "\n", "h", "=", "h", "//", "len", "(", "animal_hash", ".", "a", ")", "\n", "b", "=", "h", "%", "len", "(", "animal_hash", ".", "b", ")", "\n", "h", "=", "h", "//", "len", "(", "animal_hash", ".", "c", ")", "\n", "c", "=", "h", "%", "len", "(", "animal_hash", ".", "c", ")", "\n", "return", "animal_hash", ".", "a", "[", "a", "]", "+", "animal_hash", ".", "b", "[", "b", "]", "+", "animal_hash", ".", "c", "[", "c", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.query_gpu": [[1117, 1119], ["os.system"], "function", ["None"], ["", "def", "query_gpu", "(", "indices", ")", ":", "\n", "  ", "os", ".", "system", "(", "'nvidia-smi -i 0 --query-gpu=memory.free --format=csv'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.count_parameters": [[1122, 1125], ["print", "sum", "p.data.nelement", "module.parameters"], "function", ["None"], ["", "def", "count_parameters", "(", "module", ")", ":", "\n", "  ", "print", "(", "'Number of parameters: {}'", ".", "format", "(", "\n", "sum", "(", "[", "p", ".", "data", ".", "nelement", "(", ")", "for", "p", "in", "module", ".", "parameters", "(", ")", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.sample_1hot": [[1128, 1131], ["torch.randint", "torch.randint", "torch.randint"], "function", ["None"], ["", "def", "sample_1hot", "(", "batch_size", ",", "num_classes", ",", "device", "=", "'cuda'", ")", ":", "\n", "  ", "return", "torch", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "num_classes", ",", "size", "=", "(", "batch_size", ",", ")", ",", "\n", "device", "=", "device", ",", "dtype", "=", "torch", ".", "int64", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.prepare_z_y": [[1157, 1170], ["utils.Distribution", "z_.half.init_distribution", "z_.half.to", "utils.Distribution", "y_.to.init_distribution", "y_.to.to", "torch.randn", "torch.randn", "torch.randn", "z_.half.half", "torch.zeros", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.init_distribution", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.to", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.init_distribution", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.Distribution.to"], ["", "", "def", "prepare_z_y", "(", "G_batch_size", ",", "dim_z", ",", "nclasses", ",", "device", "=", "'cuda'", ",", "\n", "fp16", "=", "False", ",", "z_var", "=", "1.0", ",", "z_distribution", "=", "'normal'", ")", ":", "\n", "  ", "z_", "=", "Distribution", "(", "torch", ".", "randn", "(", "G_batch_size", ",", "dim_z", ",", "requires_grad", "=", "False", ")", ")", "\n", "z_", ".", "init_distribution", "(", "z_distribution", ",", "mean", "=", "0", ",", "var", "=", "z_var", ",", "bs", "=", "G_batch_size", ")", "\n", "z_", "=", "z_", ".", "to", "(", "device", ",", "torch", ".", "float16", "if", "fp16", "else", "torch", ".", "float32", ")", "\n", "\n", "if", "fp16", ":", "\n", "    ", "z_", "=", "z_", ".", "half", "(", ")", "\n", "\n", "", "y_", "=", "Distribution", "(", "torch", ".", "zeros", "(", "G_batch_size", ",", "requires_grad", "=", "False", ")", ")", "\n", "y_", ".", "init_distribution", "(", "'categorical'", ",", "num_categories", "=", "nclasses", ")", "\n", "y_", "=", "y_", ".", "to", "(", "device", ",", "torch", ".", "int64", ")", "\n", "return", "z_", ",", "y_", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.initiate_standing_stats": [[1172, 1177], ["net.modules", "hasattr", "module.reset_stats"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.layers.myBN.reset_stats"], ["", "def", "initiate_standing_stats", "(", "net", ")", ":", "\n", "  ", "for", "module", "in", "net", ".", "modules", "(", ")", ":", "\n", "    ", "if", "hasattr", "(", "module", ",", "'accumulate_standing'", ")", ":", "\n", "      ", "module", ".", "reset_stats", "(", ")", "\n", "module", ".", "accumulate_standing", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.accumulate_standing_stats": [[1179, 1189], ["utils.initiate_standing_stats", "net.train", "range", "net.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "z.normal_", "y.random_", "net", "net.shared"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.utils.initiate_standing_stats"], ["", "", "", "def", "accumulate_standing_stats", "(", "net", ",", "z", ",", "y", ",", "nclasses", ",", "num_accumulations", "=", "16", ")", ":", "\n", "  ", "initiate_standing_stats", "(", "net", ")", "\n", "net", ".", "train", "(", ")", "\n", "for", "i", "in", "range", "(", "num_accumulations", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "      ", "z", ".", "normal_", "(", ")", "\n", "y", ".", "random_", "(", "0", ",", "nclasses", ")", "\n", "x", "=", "net", "(", "z", ",", "net", ".", "shared", "(", "y", ")", ")", "# No need to parallelize here unless using syncbn", "\n", "# Set to eval mode", "\n", "", "", "net", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.losses.loss_dcgan_dis": [[8, 12], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.softplus", "torch.softplus"], "function", ["None"], ["def", "loss_dcgan_dis", "(", "dis_fake", ",", "dis_real", ")", ":", "\n", "  ", "L1", "=", "torch", ".", "mean", "(", "F", ".", "softplus", "(", "-", "dis_real", ")", ")", "\n", "L2", "=", "torch", ".", "mean", "(", "F", ".", "softplus", "(", "dis_fake", ")", ")", "\n", "return", "L1", ",", "L2", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.losses.loss_dcgan_gen": [[14, 17], ["torch.mean", "torch.mean", "torch.mean", "torch.softplus"], "function", ["None"], ["", "def", "loss_dcgan_gen", "(", "dis_fake", ")", ":", "\n", "  ", "loss", "=", "torch", ".", "mean", "(", "F", ".", "softplus", "(", "-", "dis_fake", ")", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.losses.discriminator_loss_hinge_fake": [[18, 21], ["torch.mean", "torch.mean", "torch.mean", "torch.relu"], "function", ["None"], ["", "def", "discriminator_loss_hinge_fake", "(", "dis_fake", ",", "weight_fake", "=", "None", ")", ":", "\n", "    ", "loss_fake", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "+", "dis_fake", ")", ")", "\n", "return", "loss_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.losses.discriminator_loss_hinge_real": [[22, 25], ["torch.mean", "torch.mean", "torch.mean", "torch.relu"], "function", ["None"], ["", "def", "discriminator_loss_hinge_real", "(", "dis_real", ")", ":", "\n", "    ", "loss_real", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "-", "dis_real", ")", ")", "\n", "return", "loss_real", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.losses.loss_hinge_gen": [[26, 29], ["torch.mean", "torch.mean", "torch.mean"], "function", ["None"], ["", "def", "loss_hinge_gen", "(", "dis_fake", ",", "weight_fake", "=", "None", ")", ":", "\n", "  ", "loss", "=", "-", "torch", ".", "mean", "(", "dis_fake", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.losses.loss_hinge_dis": [[31, 35], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.relu", "torch.relu"], "function", ["None"], ["", "def", "loss_hinge_dis", "(", "dis_fake", ",", "dis_real", ",", "weight_real", "=", "None", ",", "weight_fake", "=", "None", ")", ":", "\n", "  ", "loss_real", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "-", "dis_real", ")", ")", "\n", "loss_fake", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1.", "+", "dis_fake", ")", ")", "\n", "return", "loss_real", ",", "loss_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.ImageFolder.__init__": [[111, 145], ["datasets.find_classes", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "print", "print", "datasets.make_dataset", "numpy.savez_compressed", "len", "RuntimeError", "print", "tqdm", "numpy.load", "range", "datasets.ImageFolder.data.append", "datasets.ImageFolder.labels.append", "len", "datasets.ImageFolder.transform", "datasets.ImageFolder.loader"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.find_classes", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.make_dataset"], ["def", "__init__", "(", "self", ",", "root", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "loader", "=", "default_loader", ",", "load_in_mem", "=", "False", ",", "\n", "index_filename", "=", "'imagenet_imgs.npz'", ",", "**", "kwargs", ")", ":", "\n", "    ", "classes", ",", "class_to_idx", "=", "find_classes", "(", "root", ")", "\n", "# Load pre-computed image directory walk", "\n", "if", "os", ".", "path", ".", "exists", "(", "index_filename", ")", ":", "\n", "      ", "print", "(", "'Loading pre-saved Index file %s...'", "%", "index_filename", ")", "\n", "imgs", "=", "np", ".", "load", "(", "index_filename", ")", "[", "'imgs'", "]", "\n", "# If first time, walk the folder directory and save the", "\n", "# results to a pre-computed file.", "\n", "", "else", ":", "\n", "      ", "print", "(", "'Generating  Index file %s...'", "%", "index_filename", ")", "\n", "imgs", "=", "make_dataset", "(", "root", ",", "class_to_idx", ")", "\n", "np", ".", "savez_compressed", "(", "index_filename", ",", "**", "{", "'imgs'", ":", "imgs", "}", ")", "\n", "", "if", "len", "(", "imgs", ")", "==", "0", ":", "\n", "      ", "raise", "(", "RuntimeError", "(", "\"Found 0 images in subfolders of: \"", "+", "root", "+", "\"\\n\"", "\n", "\"Supported image extensions are: \"", "+", "\",\"", ".", "join", "(", "IMG_EXTENSIONS", ")", ")", ")", "\n", "\n", "", "self", ".", "root", "=", "root", "\n", "self", ".", "imgs", "=", "imgs", "\n", "self", ".", "classes", "=", "classes", "\n", "self", ".", "class_to_idx", "=", "class_to_idx", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "loader", "=", "loader", "\n", "self", ".", "load_in_mem", "=", "load_in_mem", "\n", "\n", "if", "self", ".", "load_in_mem", ":", "\n", "      ", "print", "(", "'Loading all images into memory...'", ")", "\n", "self", ".", "data", ",", "self", ".", "labels", "=", "[", "]", ",", "[", "]", "\n", "for", "index", "in", "tqdm", "(", "range", "(", "len", "(", "self", ".", "imgs", ")", ")", ")", ":", "\n", "        ", "path", ",", "target", "=", "self", ".", "transform", "(", "imgs", "[", "index", "]", "[", "0", "]", ")", ",", "imgs", "[", "index", "]", "[", "1", "]", "\n", "self", ".", "data", ".", "append", "(", "self", ".", "loader", "(", "path", ")", ")", "\n", "self", ".", "labels", ".", "append", "(", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.ImageFolder.__getitem__": [[147, 169], ["datasets.ImageFolder.loader", "datasets.ImageFolder.target_transform", "int", "str", "datasets.ImageFolder.transform"], "methods", ["None"], ["", "", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        index (int): Index\n\n    Returns:\n        tuple: (image, target) where target is class_index of the target class.\n    \"\"\"", "\n", "if", "self", ".", "load_in_mem", ":", "\n", "        ", "img", "=", "self", ".", "data", "[", "index", "]", "\n", "target", "=", "self", ".", "labels", "[", "index", "]", "\n", "", "else", ":", "\n", "      ", "path", ",", "target", "=", "self", ".", "imgs", "[", "index", "]", "\n", "img", "=", "self", ".", "loader", "(", "str", "(", "path", ")", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "        ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "      ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "# print(img.size(), target)", "\n", "", "return", "img", ",", "int", "(", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.ImageFolder.__len__": [[170, 172], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "self", ".", "imgs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.ImageFolder.__repr__": [[173, 182], ["datasets.ImageFolder.__len__", "datasets.ImageFolder.transform.__repr__().replace", "datasets.ImageFolder.target_transform.__repr__().replace", "datasets.ImageFolder.transform.__repr__", "datasets.ImageFolder.target_transform.__repr__", "len", "len"], "methods", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__len__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.ImageFolder.__repr__", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.ImageFolder.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "    ", "fmt_str", "=", "'Dataset '", "+", "self", ".", "__class__", ".", "__name__", "+", "'\\n'", "\n", "fmt_str", "+=", "'    Number of datapoints: {}\\n'", ".", "format", "(", "self", ".", "__len__", "(", ")", ")", "\n", "fmt_str", "+=", "'    Root Location: {}\\n'", ".", "format", "(", "self", ".", "root", ")", "\n", "tmp", "=", "'    Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}\\n'", ".", "format", "(", "tmp", ",", "self", ".", "transform", ".", "__repr__", "(", ")", ".", "replace", "(", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "tmp", "=", "'    Target Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}'", ".", "format", "(", "tmp", ",", "self", ".", "target_transform", ".", "__repr__", "(", ")", ".", "replace", "(", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "return", "fmt_str", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.ILSVRC_HDF5.__init__": [[189, 211], ["len", "print", "h5py.File", "h5py.File"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "root", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "load_in_mem", "=", "False", ",", "train", "=", "True", ",", "download", "=", "False", ",", "validate_seed", "=", "0", ",", "\n", "val_split", "=", "0", ",", "**", "kwargs", ")", ":", "# last four are dummies", "\n", "\n", "    ", "self", ".", "root", "=", "root", "\n", "self", ".", "num_imgs", "=", "len", "(", "h5", ".", "File", "(", "root", ",", "'r'", ")", "[", "'labels'", "]", ")", "\n", "\n", "# self.transform = transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "\n", "# Set the transform here", "\n", "self", ".", "transform", "=", "transform", "\n", "\n", "# load the entire dataset into memory?", "\n", "self", ".", "load_in_mem", "=", "load_in_mem", "\n", "\n", "# If loading into memory, do so now", "\n", "if", "self", ".", "load_in_mem", ":", "\n", "      ", "print", "(", "'Loading %s into memory...'", "%", "root", ")", "\n", "with", "h5", ".", "File", "(", "root", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "self", ".", "data", "=", "f", "[", "'imgs'", "]", "[", ":", "]", "\n", "self", ".", "labels", "=", "f", "[", "'labels'", "]", "[", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.ILSVRC_HDF5.__getitem__": [[212, 241], ["datasets.ILSVRC_HDF5.target_transform", "int", "h5py.File", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        index (int): Index\n\n    Returns:\n        tuple: (image, target) where target is class_index of the target class.\n    \"\"\"", "\n", "# If loaded the entire dataset in RAM, get image from memory", "\n", "if", "self", ".", "load_in_mem", ":", "\n", "      ", "img", "=", "self", ".", "data", "[", "index", "]", "\n", "target", "=", "self", ".", "labels", "[", "index", "]", "\n", "\n", "# Else load it from disk", "\n", "", "else", ":", "\n", "      ", "with", "h5", ".", "File", "(", "self", ".", "root", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "img", "=", "f", "[", "'imgs'", "]", "[", "index", "]", "\n", "target", "=", "f", "[", "'labels'", "]", "[", "index", "]", "\n", "\n", "\n", "# if self.transform is not None:", "\n", "# img = self.transform(img)", "\n", "# Apply my own transform", "\n", "", "", "img", "=", "(", "(", "torch", ".", "from_numpy", "(", "img", ")", ".", "float", "(", ")", "/", "255", ")", "-", "0.5", ")", "*", "2", "\n", "\n", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "      ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "int", "(", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.ILSVRC_HDF5.__len__": [[242, 244], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "      ", "return", "self", ".", "num_imgs", "\n", "# return len(self.f['imgs'])", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__init__": [[249, 329], ["os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "numpy.concatenate", "datasets.CIFAR10.download", "datasets.CIFAR10._check_integrity", "RuntimeError", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "datasets.CIFAR10.data.append", "open.close", "enumerate", "numpy.asarray", "numpy.random.seed", "list", "datasets.CIFAR10.data.reshape", "datasets.CIFAR10.data.transpose", "pickle.load", "pickle.load", "list", "print", "datasets.CIFAR10.data.reshape", "datasets.CIFAR10.data.transpose", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "open.close", "datasets.CIFAR10.data.reshape", "datasets.CIFAR10.data.transpose", "range", "numpy.asarray", "int", "numpy.shape", "numpy.delete", "list", "pickle.load", "pickle.load", "numpy.delete", "int", "max", "numpy.random.choice", "numpy.asarray", "len", "int", "max", "len"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "root", ",", "train", "=", "True", ",", "\n", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "download", "=", "True", ",", "validate_seed", "=", "0", ",", "\n", "val_split", "=", "0", ",", "load_in_mem", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "self", ".", "root", "=", "os", ".", "path", ".", "expanduser", "(", "root", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "train", "=", "train", "# training set or test set", "\n", "self", ".", "val_split", "=", "val_split", "\n", "\n", "if", "download", ":", "\n", "      ", "self", ".", "download", "(", ")", "\n", "\n", "", "if", "not", "self", ".", "_check_integrity", "(", ")", ":", "\n", "      ", "raise", "RuntimeError", "(", "'Dataset not found or corrupted.'", "+", "\n", "' You can use download=True to download it'", ")", "\n", "\n", "# now load the picked numpy arrays", "\n", "", "self", ".", "data", "=", "[", "]", "\n", "self", ".", "labels", "=", "[", "]", "\n", "for", "fentry", "in", "self", ".", "train_list", ":", "\n", "      ", "f", "=", "fentry", "[", "0", "]", "\n", "file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "f", ")", "\n", "fo", "=", "open", "(", "file", ",", "'rb'", ")", "\n", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "        ", "entry", "=", "pickle", ".", "load", "(", "fo", ")", "\n", "", "else", ":", "\n", "        ", "entry", "=", "pickle", ".", "load", "(", "fo", ",", "encoding", "=", "'latin1'", ")", "\n", "", "self", ".", "data", ".", "append", "(", "entry", "[", "'data'", "]", ")", "\n", "if", "'labels'", "in", "entry", ":", "\n", "        ", "self", ".", "labels", "+=", "entry", "[", "'labels'", "]", "\n", "", "else", ":", "\n", "        ", "self", ".", "labels", "+=", "entry", "[", "'fine_labels'", "]", "\n", "", "fo", ".", "close", "(", ")", "\n", "\n", "", "self", ".", "data", "=", "np", ".", "concatenate", "(", "self", ".", "data", ")", "\n", "# Randomly select indices for validation", "\n", "if", "self", ".", "val_split", ">", "0", ":", "\n", "      ", "label_indices", "=", "[", "[", "]", "for", "_", "in", "range", "(", "max", "(", "self", ".", "labels", ")", "+", "1", ")", "]", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "self", ".", "labels", ")", ":", "\n", "        ", "label_indices", "[", "l", "]", "+=", "[", "i", "]", "\n", "", "label_indices", "=", "np", ".", "asarray", "(", "label_indices", ")", "\n", "\n", "# randomly grab 500 elements of each class", "\n", "np", ".", "random", ".", "seed", "(", "validate_seed", ")", "\n", "self", ".", "val_indices", "=", "[", "]", "\n", "for", "l_i", "in", "label_indices", ":", "\n", "        ", "self", ".", "val_indices", "+=", "list", "(", "l_i", "[", "np", ".", "random", ".", "choice", "(", "len", "(", "l_i", ")", ",", "int", "(", "len", "(", "self", ".", "data", ")", "*", "val_split", ")", "//", "(", "max", "(", "self", ".", "labels", ")", "+", "1", ")", ",", "replace", "=", "False", ")", "]", ")", "\n", "\n", "", "", "if", "self", ".", "train", "==", "'validate'", ":", "\n", "      ", "self", ".", "data", "=", "self", ".", "data", "[", "self", ".", "val_indices", "]", "\n", "self", ".", "labels", "=", "list", "(", "np", ".", "asarray", "(", "self", ".", "labels", ")", "[", "self", ".", "val_indices", "]", ")", "\n", "\n", "self", ".", "data", "=", "self", ".", "data", ".", "reshape", "(", "(", "int", "(", "50e3", "*", "self", ".", "val_split", ")", ",", "3", ",", "32", ",", "32", ")", ")", "\n", "self", ".", "data", "=", "self", ".", "data", ".", "transpose", "(", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "# convert to HWC", "\n", "\n", "", "elif", "self", ".", "train", ":", "\n", "      ", "print", "(", "np", ".", "shape", "(", "self", ".", "data", ")", ")", "\n", "if", "self", ".", "val_split", ">", "0", ":", "\n", "        ", "self", ".", "data", "=", "np", ".", "delete", "(", "self", ".", "data", ",", "self", ".", "val_indices", ",", "axis", "=", "0", ")", "\n", "self", ".", "labels", "=", "list", "(", "np", ".", "delete", "(", "np", ".", "asarray", "(", "self", ".", "labels", ")", ",", "self", ".", "val_indices", ",", "axis", "=", "0", ")", ")", "\n", "\n", "", "self", ".", "data", "=", "self", ".", "data", ".", "reshape", "(", "(", "int", "(", "50e3", "*", "(", "1.", "-", "self", ".", "val_split", ")", ")", ",", "3", ",", "32", ",", "32", ")", ")", "\n", "self", ".", "data", "=", "self", ".", "data", ".", "transpose", "(", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "# convert to HWC", "\n", "", "else", ":", "\n", "      ", "f", "=", "self", ".", "test_list", "[", "0", "]", "[", "0", "]", "\n", "file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "f", ")", "\n", "fo", "=", "open", "(", "file", ",", "'rb'", ")", "\n", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "        ", "entry", "=", "pickle", ".", "load", "(", "fo", ")", "\n", "", "else", ":", "\n", "        ", "entry", "=", "pickle", ".", "load", "(", "fo", ",", "encoding", "=", "'latin1'", ")", "\n", "", "self", ".", "data", "=", "entry", "[", "'data'", "]", "\n", "if", "'labels'", "in", "entry", ":", "\n", "        ", "self", ".", "labels", "=", "entry", "[", "'labels'", "]", "\n", "", "else", ":", "\n", "        ", "self", ".", "labels", "=", "entry", "[", "'fine_labels'", "]", "\n", "", "fo", ".", "close", "(", ")", "\n", "self", ".", "data", "=", "self", ".", "data", ".", "reshape", "(", "(", "10000", ",", "3", ",", "32", ",", "32", ")", ")", "\n", "self", ".", "data", "=", "self", ".", "data", ".", "transpose", "(", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "# convert to HWC", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__getitem__": [[330, 350], ["PIL.Image.fromarray", "datasets.CIFAR10.transform", "datasets.CIFAR10.target_transform"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        index (int): Index\n    Returns:\n        tuple: (image, target) where target is index of the target class.\n    \"\"\"", "\n", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "self", ".", "labels", "[", "index", "]", "\n", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL Image", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "      ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "      ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.CIFAR10.__len__": [[351, 353], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "      ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.is_image_file": [[22, 33], ["filename.lower", "any", "filename.lower.endswith"], "function", ["None"], ["def", "is_image_file", "(", "filename", ")", ":", "\n", "    ", "\"\"\"Checks if a file is an image.\n\n    Args:\n        filename (string): path to a file\n\n    Returns:\n        bool: True if the filename ends with a known image extension\n    \"\"\"", "\n", "filename_lower", "=", "filename", ".", "lower", "(", ")", "\n", "return", "any", "(", "filename_lower", ".", "endswith", "(", "ext", ")", "for", "ext", "in", "IMG_EXTENSIONS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.find_classes": [[35, 40], ["classes.sort", "os.listdir", "os.listdir", "os.path.isdir", "os.path.isdir", "range", "os.path.join", "os.path.join", "len"], "function", ["None"], ["", "def", "find_classes", "(", "dir", ")", ":", "\n", "    ", "classes", "=", "[", "d", "for", "d", "in", "os", ".", "listdir", "(", "dir", ")", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "d", ")", ")", "]", "\n", "classes", ".", "sort", "(", ")", "\n", "class_to_idx", "=", "{", "classes", "[", "i", "]", ":", "i", "for", "i", "in", "range", "(", "len", "(", "classes", ")", ")", "}", "\n", "return", "classes", ",", "class_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.make_dataset": [[42, 60], ["os.path.expanduser", "os.path.expanduser", "tqdm", "sorted", "os.path.join", "os.path.join", "sorted", "os.listdir", "os.listdir", "os.path.isdir", "os.path.isdir", "os.walk", "os.walk", "sorted", "datasets.is_image_file", "os.path.join", "os.path.join", "images.append"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.is_image_file"], ["", "def", "make_dataset", "(", "dir", ",", "class_to_idx", ")", ":", "\n", "  ", "images", "=", "[", "]", "\n", "dir", "=", "os", ".", "path", ".", "expanduser", "(", "dir", ")", "\n", "\n", "T", "=", "tqdm", "(", "sorted", "(", "os", ".", "listdir", "(", "dir", ")", ")", ")", "\n", "for", "target", "in", "T", ":", "\n", "    ", "d", "=", "os", ".", "path", ".", "join", "(", "dir", ",", "target", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "d", ")", ":", "\n", "      ", "continue", "\n", "\n", "", "for", "root", ",", "_", ",", "fnames", "in", "sorted", "(", "os", ".", "walk", "(", "d", ")", ")", ":", "\n", "      ", "for", "fname", "in", "sorted", "(", "fnames", ")", ":", "\n", "        ", "if", "is_image_file", "(", "fname", ")", ":", "\n", "          ", "path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "fname", ")", "\n", "item", "=", "(", "path", ",", "class_to_idx", "[", "target", "]", ")", "\n", "images", ".", "append", "(", "item", ")", "\n", "\n", "", "", "", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.pil_loader": [[62, 67], ["open", "PIL.Image.open", "Image.open.convert"], "function", ["None"], ["", "def", "pil_loader", "(", "path", ")", ":", "\n", "# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)", "\n", "  ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "    ", "img", "=", "Image", ".", "open", "(", "f", ")", "\n", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.accimage_loader": [[69, 76], ["accimage.Image", "datasets.pil_loader"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.pil_loader"], ["", "", "def", "accimage_loader", "(", "path", ")", ":", "\n", "  ", "import", "accimage", "\n", "try", ":", "\n", "    ", "return", "accimage", ".", "Image", "(", "path", ")", "\n", "", "except", "IOError", ":", "\n", "# Potentially a decoding problem, fall back to PIL.Image", "\n", "    ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.default_loader": [[78, 84], ["get_image_backend", "datasets.accimage_loader", "datasets.pil_loader"], "function", ["home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.accimage_loader", "home.repos.pwc.inspect_result.boschresearch_unetgan.None.datasets.pil_loader"], ["", "", "def", "default_loader", "(", "path", ")", ":", "\n", "  ", "from", "torchvision", "import", "get_image_backend", "\n", "if", "get_image_backend", "(", ")", "==", "'accimage'", ":", "\n", "    ", "return", "accimage_loader", "(", "path", ")", "\n", "", "else", ":", "\n", "    ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]]}