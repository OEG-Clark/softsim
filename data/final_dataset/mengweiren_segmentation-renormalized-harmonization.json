{"home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.utils.visualization.tensorboard_vis": [[11, 48], ["matplotlib.figure", "len", "numpy.ceil", "print", "range", "summarywriter.add_figure", "matplotlib.subplot", "isinstance", "cv2.resize", "plt.subplot.imshow", "matplotlib.title", "matplotlib.axis"], "function", ["None"], ["def", "tensorboard_vis", "(", "summarywriter", ",", "step", ",", "board_name", ",", "img_list", ",", "num_row", ",", "cmaps", ",", "titles", ",", "resize", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    :param summarywriter: tensorboard summary writer handle\n    :param step:\n    :param board_name: display name\n    :param img_list: a list of images to show\n    :param num_row: specify the number of row\n    :param cmaps: specify color maps for each image ('gray' for MRI, i.e.)\n    :param titles: specify each image title\n    :param resize: whether resize the image to show\n    :return:\n    \"\"\"", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "num_figs", "=", "len", "(", "img_list", ")", "\n", "num_col", "=", "np", ".", "ceil", "(", "num_figs", "/", "num_row", ")", "\n", "print", "(", "'Visualizing %d images in %d row %d column'", "%", "(", "num_figs", ",", "num_row", ",", "num_col", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_figs", ")", ":", "\n", "        ", "ax", "=", "plt", ".", "subplot", "(", "num_row", ",", "num_col", ",", "i", "+", "1", ")", "\n", "if", "resize", ":", "\n", "            ", "tmp", "=", "cv2", ".", "resize", "(", "img_list", "[", "i", "]", ",", "(", "256", ",", "256", ")", ")", "\n", "", "else", ":", "\n", "            ", "tmp", "=", "img_list", "[", "i", "]", "\n", "#print(tmp.shape)", "\n", "", "if", "isinstance", "(", "cmaps", ",", "str", ")", ":", "c", "=", "cmaps", "\n", "else", ":", "c", "=", "cmaps", "[", "i", "]", "\n", "\n", "if", "'seg'", "in", "titles", "[", "i", "]", ":", "\n", "            ", "vmin", "=", "0", "\n", "vmax", "=", "3", "\n", "", "else", ":", "\n", "            ", "vmin", "=", "-", "1", "\n", "vmax", "=", "1.", "\n", "", "ax", ".", "imshow", "(", "tmp", ",", "cmap", "=", "c", ",", "vmin", "=", "vmin", ",", "vmax", "=", "vmax", ")", ",", "plt", ".", "title", "(", "titles", "[", "i", "]", ")", ",", "plt", ".", "axis", "(", "'off'", ")", "\n", "\n", "", "summarywriter", ".", "add_figure", "(", "board_name", ",", "fig", ",", "step", ")", "\n", "return", "summarywriter", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.utils.visualization.create_group_fig": [[50, 103], ["matplotlib.figure", "len", "numpy.ceil", "range", "matplotlib.subplot", "isinstance", "print", "time.time", "time.time", "cv2.resize", "plt.subplot.imshow", "matplotlib.title", "matplotlib.axis", "matplotlib.savefig", "matplotlib.savefig", "isinstance", "cv2.resize.max", "cv2.resize.min", "cv2.resize.max"], "function", ["None"], ["", "def", "create_group_fig", "(", "img_list", ",", "num_row", ",", "cmaps", ",", "titles", ",", "resize", "=", "True", ",", "save_name", "=", "None", ",", "fig_size", "=", "[", "15", ",", "15", "]", ",", "\n", "vmin", "=", "None", ",", "vmax", "=", "None", ",", "is_log", "=", "False", ",", "dpi", "=", "100", ",", "format", "=", "'eps'", ")", ":", "\n", "    ", "\"\"\"\n    :param summarywriter: tensorboard summary writer handle\n    :param step:\n    :param board_name: display name\n    :param img_list: a list of images to show\n    :param num_row: specify the number of row\n    :param cmaps: specify color maps for each image ('gray' for MRI, i.e.)\n    :param titles: specify each image title\n    :param resize: whether resize the image to show\n    :return:\n    \"\"\"", "\n", "plt", ".", "rcParams", "[", "'figure.figsize'", "]", "=", "fig_size", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "num_figs", "=", "len", "(", "img_list", ")", "\n", "num_col", "=", "np", ".", "ceil", "(", "num_figs", "/", "num_row", ")", "\n", "#print('Visualizing %d images in %d row %d column' % (num_figs, num_row, num_col))", "\n", "for", "i", "in", "range", "(", "num_figs", ")", ":", "\n", "        ", "ax", "=", "plt", ".", "subplot", "(", "num_row", ",", "num_col", ",", "i", "+", "1", ")", "\n", "if", "resize", ":", "\n", "            ", "tmp", "=", "cv2", ".", "resize", "(", "img_list", "[", "i", "]", ",", "(", "256", ",", "256", ")", ")", "\n", "", "else", ":", "\n", "            ", "tmp", "=", "img_list", "[", "i", "]", "\n", "#print(tmp.shape)", "\n", "", "if", "isinstance", "(", "cmaps", ",", "str", ")", ":", "\n", "            ", "c", "=", "cmaps", "\n", "", "else", ":", "\n", "            ", "c", "=", "cmaps", "[", "i", "]", "\n", "\n", "", "if", "'seg'", "in", "titles", "[", "i", "]", ":", "\n", "            ", "v_min", ",", "v_max", "=", "0", ",", "3", "\n", "", "else", ":", "\n", "            ", "if", "vmax", "is", "not", "None", ":", "\n", "                ", "if", "isinstance", "(", "vmax", ",", "list", ")", ":", "v_min", ",", "v_max", "=", "vmin", "[", "i", "]", ",", "vmax", "[", "i", "]", "\n", "else", ":", "v_min", ",", "v_min", "=", "vmin", ",", "vmax", "\n", "", "elif", "tmp", ".", "max", "(", ")", "<=", "1", ":", "\n", "                ", "v_min", ",", "v_max", "=", "-", "1.", ",", "1.", "\n", "", "else", ":", "\n", "                ", "v_min", ",", "v_max", "=", "tmp", ".", "min", "(", ")", ",", "tmp", ".", "max", "(", ")", "\n", "", "", "print", "(", "v_min", ",", "v_max", ")", "\n", "ax", ".", "imshow", "(", "tmp", ",", "cmap", "=", "c", ",", "vmin", "=", "v_min", ",", "vmax", "=", "v_max", ")", ",", "plt", ".", "title", "(", "titles", "[", "i", "]", ")", ",", "plt", ".", "axis", "(", "'off'", ")", "\n", "\n", "", "if", "save_name", ":", "\n", "        ", "s", "=", "time", ".", "time", "(", ")", "\n", "if", "dpi", ":", "\n", "            ", "plt", ".", "savefig", "(", "save_name", ",", "format", "=", "format", ",", "dpi", "=", "dpi", ")", "\n", "", "else", ":", "\n", "            ", "plt", ".", "savefig", "(", "save_name", ",", "format", "=", "format", ")", "\n", "", "e", "=", "time", ".", "time", "(", ")", "\n", "#print('save figure %s in %.5f seconds'%(save_name, (e-s)))", "\n", "\n", "", "return", "fig", "\n", "", ""]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.utils.utilization.mkdirs": [[5, 16], ["isinstance", "utilization.mkdir", "isinstance", "utilization.mkdir"], "function", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.utils.utilization.mkdir", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.utils.utilization.mkdir"], ["def", "mkdirs", "(", "paths", ")", ":", "\n", "    ", "\"\"\"create empty directories if they don't exist\n\n    Parameters:\n        paths (str list) -- a list of directory paths\n    \"\"\"", "\n", "if", "isinstance", "(", "paths", ",", "list", ")", "and", "not", "isinstance", "(", "paths", ",", "str", ")", ":", "\n", "        ", "for", "path", "in", "paths", ":", "\n", "            ", "mkdir", "(", "path", ")", "\n", "", "", "else", ":", "\n", "        ", "mkdir", "(", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.utils.utilization.mkdir": [[18, 26], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "def", "mkdir", "(", "path", ")", ":", "\n", "    ", "\"\"\"create a single empty directory if it didn't exist\n\n    Parameters:\n        path (str) -- a single directory path\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.mains.train_seg_kfold.seg_loss": [[32, 52], ["seg_map.size", "torch.argmax", "torch.argmax", "torch.argmax", "criterion", "criterion", "mask.float().view().expand_as", "mask.long", "mask_back.float().view().expand_as", "mask_back.long", "mask.float().view", "mask_back.float().view", "mask.float", "mask_back.float"], "function", ["None"], ["def", "seg_loss", "(", "criterion", ",", "output", ",", "seg_map", ",", "lambda_fg", "=", "0.95", ",", "weight", "=", "1.", ")", ":", "\n", "    ", "'''\n    :param output: the segmentation before softmax!\n    :param seg_map: one hot segmentation map with discrete range [0,1]\n    :param weight: weight applied to the returned loss value\n    :return:\n    '''", "\n", "b", ",", "c", ",", "w", ",", "h", "=", "seg_map", ".", "size", "(", ")", "\n", "seg_gt", "=", "torch", ".", "argmax", "(", "seg_map", ",", "dim", "=", "1", ")", "# b, w, h", "\n", "mask", "=", "(", "seg_gt", ">", "0.", ")", "\n", "mask_output", "=", "mask", ".", "float", "(", ")", ".", "view", "(", "b", ",", "1", ",", "w", ",", "h", ")", ".", "expand_as", "(", "output", ")", "*", "output", "\n", "mask_gt", "=", "mask", ".", "long", "(", ")", "*", "seg_gt", "\n", "foreground_loss", "=", "criterion", "(", "mask_output", ",", "mask_gt", ")", "\n", "\n", "mask_back", "=", "(", "seg_gt", "==", "0.", ")", "\n", "mask_back_output", "=", "mask_back", ".", "float", "(", ")", ".", "view", "(", "b", ",", "1", ",", "w", ",", "h", ")", ".", "expand_as", "(", "output", ")", "*", "output", "\n", "mask_back_gt", "=", "mask_back", ".", "long", "(", ")", "*", "seg_gt", "\n", "background_loss", "=", "criterion", "(", "mask_back_output", ",", "mask_back_gt", ")", "\n", "# print(mask_output.size(), seg_gt.size())", "\n", "return", "weight", "*", "(", "lambda_fg", "*", "foreground_loss", "+", "(", "1", "-", "lambda_fg", ")", "*", "background_loss", ")", "\n", "#return foreground_loss, background_loss", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.mains.train_seg_kfold.cross_entropy": [[54, 59], ["torch.softmax", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.sum().mean", "torch.sum().mean", "torch.sum().mean", "torch.sum", "torch.sum", "torch.sum", "torch.log", "torch.log", "torch.log"], "function", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.softmax"], ["", "def", "cross_entropy", "(", "pred", ",", "label", ")", ":", "\n", "    ", "pred", "=", "F", ".", "softmax", "(", "pred", ",", "dim", "=", "1", ")", "\n", "pred", "=", "torch", ".", "clamp", "(", "pred", ",", "1e-7", ",", "1.0", ")", "\n", "label", "=", "torch", ".", "clamp", "(", "label", ",", "1e-4", ",", "1.0", ")", "\n", "return", "-", "1", "*", "torch", ".", "sum", "(", "label", "*", "torch", ".", "log", "(", "pred", ")", ",", "dim", "=", "1", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.mains.train_seg_kfold.focal_loss": [[61, 67], ["torch.cross_entropy", "torch.exp", "torch.exp", "torch.exp"], "function", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.cross_entropy"], ["", "def", "focal_loss", "(", "pred", ",", "label", ",", "alpha", "=", "1", ",", "gamma", "=", "2", ")", ":", "\n", "    ", "ce_loss", "=", "F", ".", "cross_entropy", "(", "pred", ",", "label", ",", "reduction", "=", "'none'", ")", "# important to add reduction='none' to keep per-batch-item loss", "\n", "#print(ce_loss.size())", "\n", "pt", "=", "torch", ".", "exp", "(", "-", "ce_loss", ")", "\n", "loss", "=", "(", "alpha", "*", "(", "1", "-", "pt", ")", "**", "gamma", "*", "ce_loss", ")", ".", "mean", "(", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.mains.train_mae.adjust_learning_rate": [[37, 43], ["None"], "function", ["None"], ["def", "adjust_learning_rate", "(", "init_lr", ",", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"", "\n", "lr", "=", "init_lr", "*", "(", "0.1", "**", "(", "epoch", "//", "100", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.mains.train_seg.seg_loss": [[23, 43], ["seg_map.size", "torch.argmax", "torch.argmax", "torch.argmax", "criterion", "criterion", "mask.float().view().expand_as", "mask.long", "mask_back.float().view().expand_as", "mask_back.long", "mask.float().view", "mask_back.float().view", "mask.float", "mask_back.float"], "function", ["None"], ["def", "seg_loss", "(", "criterion", ",", "output", ",", "seg_map", ",", "lambda_fg", "=", "0.95", ",", "weight", "=", "1.", ")", ":", "\n", "    ", "'''\n    :param output: the segmentation before softmax!\n    :param seg_map: one hot segmentation map with discrete range [0,1]\n    :param weight: weight applied to the returned loss value\n    :return:\n    '''", "\n", "b", ",", "c", ",", "w", ",", "h", "=", "seg_map", ".", "size", "(", ")", "\n", "seg_gt", "=", "torch", ".", "argmax", "(", "seg_map", ",", "dim", "=", "1", ")", "# b, w, h", "\n", "mask", "=", "(", "seg_gt", ">", "0.", ")", "\n", "mask_output", "=", "mask", ".", "float", "(", ")", ".", "view", "(", "b", ",", "1", ",", "w", ",", "h", ")", ".", "expand_as", "(", "output", ")", "*", "output", "\n", "mask_gt", "=", "mask", ".", "long", "(", ")", "*", "seg_gt", "\n", "foreground_loss", "=", "criterion", "(", "mask_output", ",", "mask_gt", ")", "\n", "\n", "mask_back", "=", "(", "seg_gt", "==", "0.", ")", "\n", "mask_back_output", "=", "mask_back", ".", "float", "(", ")", ".", "view", "(", "b", ",", "1", ",", "w", ",", "h", ")", ".", "expand_as", "(", "output", ")", "*", "output", "\n", "mask_back_gt", "=", "mask_back", ".", "long", "(", ")", "*", "seg_gt", "\n", "background_loss", "=", "criterion", "(", "mask_back_output", ",", "mask_back_gt", ")", "\n", "# print(mask_output.size(), seg_gt.size())", "\n", "return", "weight", "*", "(", "lambda_fg", "*", "foreground_loss", "+", "(", "1", "-", "lambda_fg", ")", "*", "background_loss", ")", "\n", "#return foreground_loss, background_loss", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.mains.train_seg.cross_entropy": [[45, 50], ["torch.softmax", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.sum().mean", "torch.sum().mean", "torch.sum().mean", "torch.sum", "torch.sum", "torch.sum", "torch.log", "torch.log", "torch.log"], "function", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.softmax"], ["", "def", "cross_entropy", "(", "pred", ",", "label", ")", ":", "\n", "    ", "pred", "=", "F", ".", "softmax", "(", "pred", ",", "dim", "=", "1", ")", "\n", "pred", "=", "torch", ".", "clamp", "(", "pred", ",", "1e-7", ",", "1.0", ")", "\n", "label", "=", "torch", ".", "clamp", "(", "label", ",", "1e-4", ",", "1.0", ")", "\n", "return", "-", "1", "*", "torch", ".", "sum", "(", "label", "*", "torch", ".", "log", "(", "pred", ")", ",", "dim", "=", "1", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.mains.train_mae_kfold.adjust_learning_rate": [[37, 43], ["None"], "function", ["None"], ["def", "adjust_learning_rate", "(", "init_lr", ",", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"", "\n", "lr", "=", "init_lr", "*", "(", "0.1", "**", "(", "epoch", "//", "100", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.cycle_gan.CycleGAN.__init__": [[11, 115], ["base_model.BaseModel.__init__", "networks.define_G", "networks.define_G", "cycle_gan.CycleGAN.loss_names.append", "cycle_gan.CycleGAN.loss_names.append", "cycle_gan.CycleGAN.loss_names.append", "cycle_gan.CycleGAN.loss_names.append", "cycle_gan.CycleGAN.loss_names.append", "cycle_gan.CycleGAN.loss_names.append", "cycle_gan.CycleGAN.loss_names.append", "cycle_gan.CycleGAN.loss_names.append", "visual_names_A.append", "visual_names_B.append", "cycle_gan.CycleGAN.loss_names.append", "cycle_gan.CycleGAN.loss_names.append", "cycle_gan.CycleGAN.model_names.append", "cycle_gan.CycleGAN.model_names.append", "networks.define_G", "networks.define_G", "networks.define_D", "networks.define_D", "networks.GANLoss().to", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.nn.L1Loss", "cycle_gan.CycleGAN.optimizers.append", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "cycle_gan.CycleGAN.optimizers.append", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "itertools.chain", "networks.GANLoss", "itertools.chain", "itertools.chain", "cycle_gan.CycleGAN.netD_A.parameters", "cycle_gan.CycleGAN.netD_B.parameters", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "cycle_gan.CycleGAN.netG_A.parameters", "cycle_gan.CycleGAN.netG_B.parameters", "cycle_gan.CycleGAN.netS_A.parameters", "cycle_gan.CycleGAN.netS_B.parameters", "cycle_gan.CycleGAN.netG_A.parameters", "cycle_gan.CycleGAN.netG_B.parameters", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.define_G", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.define_G", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.define_G", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.define_G", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.define_D", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.define_D"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "BaseModel", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "self", ".", "loss_names", "=", "[", "'D_A'", ",", "'G_A'", ",", "'cycle_A'", ",", "'D_B'", ",", "'G_B'", ",", "'cycle_B'", "]", "\n", "if", "opt", ".", "lambda_cc", ">", "0", ":", "\n", "            ", "self", ".", "loss_names", ".", "append", "(", "'cc_AB'", ")", "\n", "self", ".", "loss_names", ".", "append", "(", "'cc_BA'", ")", "\n", "", "if", "opt", ".", "lambda_tv", ">", "0", ":", "\n", "            ", "self", ".", "loss_names", ".", "append", "(", "'tv_AB'", ")", "\n", "self", ".", "loss_names", ".", "append", "(", "'tv_BA'", ")", "\n", "", "self", ".", "srenorm", "=", "opt", ".", "srenorm", "\n", "self", ".", "learn_seg", "=", "opt", ".", "joint_seg", "\n", "if", "opt", ".", "joint_seg", ":", "\n", "            ", "self", ".", "loss_names", ".", "append", "(", "'seg_real_A'", ")", "\n", "self", ".", "loss_names", ".", "append", "(", "'seg_fake_A'", ")", "\n", "self", ".", "loss_names", ".", "append", "(", "'seg_real_B'", ")", "\n", "self", ".", "loss_names", ".", "append", "(", "'seg_fake_B'", ")", "\n", "", "self", ".", "sem_dropout", "=", "opt", ".", "sem_dropout", "\n", "# specify the images you want to save/display.", "\n", "# The training/test scripts will call <BaseModel.get_current_visuals>", "\n", "visual_names_A", "=", "[", "'real_A'", ",", "'fake_B'", ",", "'rec_A'", "]", "\n", "visual_names_B", "=", "[", "'real_B'", ",", "'fake_A'", ",", "'rec_B'", "]", "\n", "if", "self", ".", "isTrain", "and", "self", ".", "opt", ".", "lambda_identity", ">", "0.0", ":", "\n", "# if identity loss is used, we also visualize idt_B=G_A(B) ad idt_A=G_A(B)", "\n", "            ", "visual_names_A", ".", "append", "(", "'idt_B'", ")", "\n", "visual_names_B", ".", "append", "(", "'idt_A'", ")", "\n", "self", ".", "loss_names", ".", "append", "(", "'idt_A'", ")", "\n", "self", ".", "loss_names", ".", "append", "(", "'idt_B'", ")", "\n", "\n", "", "self", ".", "visual_names", "=", "visual_names_A", "+", "visual_names_B", "# combine visualizations for A and B", "\n", "self", ".", "sigma", "=", "opt", ".", "noise_std", "\n", "# specify the models you want to save to the disk.", "\n", "# The training/test scripts will call <BaseModel.save_networks> and <BaseModel.load_networks>.", "\n", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "model_names", "=", "[", "'G_A'", ",", "'G_B'", ",", "'D_A'", ",", "'D_B'", "]", "\n", "", "else", ":", "# during test time, only load Gs", "\n", "            ", "self", ".", "model_names", "=", "[", "'G_A'", ",", "'G_B'", "]", "\n", "\n", "", "if", "opt", ".", "dim", "==", "2", ":", "\n", "            ", "networks", "=", "networks2d", "\n", "", "else", ":", "\n", "            ", "networks", "=", "networks3d", "\n", "\n", "# define networks", "\n", "", "film_nc", "=", "opt", ".", "seg_nc", "\n", "if", "opt", ".", "mask", ":", "\n", "            ", "film_nc", "=", "opt", ".", "seg_nc", "+", "1", "\n", "self", ".", "add_mask", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "add_mask", "=", "False", "\n", "", "self", ".", "netG_A", "=", "networks", ".", "define_G", "(", "opt", ".", "input_nc", ",", "opt", ".", "output_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "typeG", ",", "norm", "=", "opt", ".", "norm", ",", "\n", "use_dropout", "=", "not", "opt", ".", "no_dropout", ",", "init_type", "=", "opt", ".", "init_type", ",", "\n", "init_gain", "=", "opt", ".", "init_gain", ",", "gpu_ids", "=", "opt", ".", "gpu_ids", ",", "return_feature", "=", "opt", ".", "fid", ",", "srenorm", "=", "opt", ".", "srenorm", ",", "seg_nc", "=", "film_nc", ")", "\n", "self", ".", "netG_B", "=", "networks", ".", "define_G", "(", "opt", ".", "output_nc", ",", "opt", ".", "input_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "typeG", ",", "norm", "=", "opt", ".", "norm", ",", "\n", "use_dropout", "=", "not", "opt", ".", "no_dropout", ",", "init_type", "=", "opt", ".", "init_type", ",", "\n", "init_gain", "=", "opt", ".", "init_gain", ",", "gpu_ids", "=", "opt", ".", "gpu_ids", ",", "return_feature", "=", "opt", ".", "fid", ",", "srenorm", "=", "opt", ".", "srenorm", ",", "seg_nc", "=", "film_nc", ")", "\n", "if", "self", ".", "learn_seg", ":", "\n", "            ", "if", "opt", ".", "dataset", "==", "'msseg'", ":", "\n", "                ", "stype", "=", "'unet_up'", "\n", "", "else", ":", "\n", "                ", "stype", "=", "'resunet'", "\n", "#stype = 'resunet'", "\n", "", "self", ".", "model_names", ".", "append", "(", "'S_A'", ")", "\n", "self", ".", "model_names", ".", "append", "(", "'S_B'", ")", "\n", "self", ".", "netS_A", "=", "networks", ".", "define_G", "(", "opt", ".", "input_nc", ",", "opt", ".", "seg_nc", ",", "opt", ".", "ngf", ",", "netG", "=", "stype", ",", "norm", "=", "opt", ".", "norm", ",", "\n", "use_dropout", "=", "not", "opt", ".", "no_dropout", ",", "init_type", "=", "opt", ".", "init_type", ",", "\n", "init_gain", "=", "opt", ".", "init_gain", ",", "gpu_ids", "=", "opt", ".", "gpu_ids", ",", "return_feature", "=", "opt", ".", "fid", ",", "srenorm", "=", "False", ",", "is_seg", "=", "True", ")", "\n", "self", ".", "netS_B", "=", "networks", ".", "define_G", "(", "opt", ".", "input_nc", ",", "opt", ".", "seg_nc", ",", "opt", ".", "ngf", ",", "netG", "=", "stype", ",", "norm", "=", "opt", ".", "norm", ",", "\n", "use_dropout", "=", "not", "opt", ".", "no_dropout", ",", "init_type", "=", "opt", ".", "init_type", ",", "\n", "init_gain", "=", "opt", ".", "init_gain", ",", "gpu_ids", "=", "opt", ".", "gpu_ids", ",", "return_feature", "=", "opt", ".", "fid", ",", "srenorm", "=", "False", ",", "is_seg", "=", "True", ")", "\n", "\n", "", "if", "self", ".", "isTrain", ":", "# define discriminators", "\n", "            ", "self", ".", "multiD", "=", "False", "\n", "self", ".", "netD_A", "=", "networks", ".", "define_D", "(", "opt", ".", "output_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "n_layer", "=", "opt", ".", "n_layers_D", ",", "norm", "=", "opt", ".", "norm", ",", "init_type", "=", "opt", ".", "init_type", ",", "\n", "init_gain", "=", "opt", ".", "init_gain", ",", "gpu_ids", "=", "opt", ".", "gpu_ids", ")", "\n", "self", ".", "netD_B", "=", "networks", ".", "define_D", "(", "opt", ".", "input_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "n_layer", "=", "opt", ".", "n_layers_D", ",", "norm", "=", "opt", ".", "norm", ",", "init_type", "=", "opt", ".", "init_type", ",", "\n", "init_gain", "=", "opt", ".", "init_gain", ",", "gpu_ids", "=", "opt", ".", "gpu_ids", ")", "\n", "\n", "if", "opt", ".", "lambda_identity", ">", "0.0", ":", "# only works when input and output images have the same number of channels", "\n", "                ", "assert", "(", "opt", ".", "input_nc", "==", "opt", ".", "output_nc", ")", "\n", "# define loss functions", "\n", "", "self", ".", "criterionGAN", "=", "networks", ".", "GANLoss", "(", "opt", ".", "gan_mode", ")", ".", "to", "(", "self", ".", "device", ")", "# define GAN loss.", "\n", "self", ".", "criterionCycle", "=", "torch", ".", "nn", ".", "L1Loss", "(", "reduction", "=", "'mean'", ")", "\n", "self", ".", "criterionIdt", "=", "torch", ".", "nn", ".", "L1Loss", "(", "reduction", "=", "'mean'", ")", "\n", "if", "self", ".", "learn_seg", ":", "\n", "                ", "if", "opt", ".", "dataset", "==", "'ixi'", ":", "seg_weights", "=", "[", "0.5", ",", "0.5", ",", "0.5", ",", "0.5", "]", "\n", "if", "opt", ".", "dataset", "==", "'retouch'", ":", "seg_weights", "=", "[", "0.3", ",", "0.7", ",", "0.7", ",", "0.7", "]", "\n", "if", "opt", ".", "dataset", "==", "'msseg'", ":", "seg_weights", "=", "[", "0.2", ",", "0.8", "]", "\n", "self", ".", "criterionSeg", "=", "nn", ".", "CrossEntropyLoss", "(", "weight", "=", "torch", ".", "tensor", "(", "seg_weights", ")", ".", "cuda", "(", ")", ")", "\n", "# initialize optimizers; schedulers will be automatically created by function <BaseModel.setup>.", "\n", "\n", "", "if", "self", ".", "learn_seg", ":", "\n", "                ", "self", ".", "optimizer_G", "=", "torch", ".", "optim", ".", "Adam", "(", "itertools", ".", "chain", "(", "self", ".", "netG_A", ".", "parameters", "(", ")", ",", "self", ".", "netG_B", ".", "parameters", "(", ")", ",", "\n", "self", ".", "netS_A", ".", "parameters", "(", ")", ",", "self", ".", "netS_B", ".", "parameters", "(", ")", ")", ",", "\n", "lr", "=", "opt", ".", "lr_g", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "optimizer_G", "=", "torch", ".", "optim", ".", "Adam", "(", "itertools", ".", "chain", "(", "self", ".", "netG_A", ".", "parameters", "(", ")", ",", "self", ".", "netG_B", ".", "parameters", "(", ")", ")", ",", "\n", "lr", "=", "opt", ".", "lr_g", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_G", ")", "\n", "\n", "\n", "self", ".", "optimizer_D", "=", "torch", ".", "optim", ".", "Adam", "(", "itertools", ".", "chain", "(", "self", ".", "netD_A", ".", "parameters", "(", ")", ",", "self", ".", "netD_B", ".", "parameters", "(", ")", ")", ",", "lr", "=", "opt", ".", "lr_d", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_D", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.cycle_gan.CycleGAN.set_input": [[118, 133], ["input[].to", "input[].to", "input[].to", "input[].to", "input[].to", "input[].to", "networks2d.PairedSemanticDropout", "networks2d.PairedSemanticDropout."], "methods", ["None"], ["", "", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "self", ".", "real_A", "=", "input", "[", "'A'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "real_B", "=", "input", "[", "'B'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "if", "self", ".", "learn_seg", ":", "\n", "            ", "self", ".", "seg_A", "=", "input", "[", "'A_seg'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "seg_B", "=", "input", "[", "'B_seg'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "seg_A", "=", "None", "\n", "self", ".", "seg_B", "=", "None", "\n", "", "if", "self", ".", "add_mask", ":", "\n", "            ", "self", ".", "mask_A", "=", "input", "[", "'A_mask'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "mask_B", "=", "input", "[", "'B_mask'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "", "if", "self", ".", "sem_dropout", ":", "\n", "            ", "SM", "=", "networks2d", ".", "PairedSemanticDropout", "(", "0.3", ",", "4", ")", "\n", "self", ".", "real_A", ",", "self", ".", "seg_A", ",", "self", ".", "real_B", ",", "self", ".", "seg_B", "=", "SM", "(", "self", ".", "real_A", ",", "self", ".", "seg_A", ",", "self", ".", "real_B", ",", "self", ".", "seg_B", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.cycle_gan.CycleGAN.forward": [[134, 194], ["cycle_gan.CycleGAN.netG_A", "cycle_gan.CycleGAN.netG_B", "cycle_gan.CycleGAN.netG_B", "cycle_gan.CycleGAN.netG_A", "cycle_gan.CycleGAN.netS_A", "cycle_gan.CycleGAN.netS_B", "cycle_gan.CycleGAN.netG_A", "cycle_gan.CycleGAN.netG_B", "cycle_gan.CycleGAN.netS_B", "cycle_gan.CycleGAN.netS_A", "cycle_gan.CycleGAN.netG_B", "cycle_gan.CycleGAN.netG_A", "cycle_gan.CycleGAN.netG_A", "cycle_gan.CycleGAN.netG_B", "cycle_gan.CycleGAN.netG_B", "cycle_gan.CycleGAN.netG_A", "cycle_gan.CycleGAN.netS_A", "cycle_gan.CycleGAN.netS_B", "cycle_gan.CycleGAN.netS_B", "cycle_gan.CycleGAN.netS_A", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "learn_seg", ":", "\n", "            ", "if", "self", ".", "srenorm", ":", "\n", "# segmentation conditioned cycle GAN with segmentation learnable", "\n", "                ", "self", ".", "seg_real_A_out", "=", "self", ".", "netS_A", "(", "self", ".", "real_A", ")", "#", "\n", "self", ".", "seg_real_B_out", "=", "self", ".", "netS_B", "(", "self", ".", "real_B", ")", "\n", "if", "self", ".", "add_mask", ":", "\n", "                    ", "seg_cond_A", "=", "torch", ".", "cat", "(", "[", "self", ".", "seg_real_A_out", ",", "self", ".", "mask_A", "]", ",", "dim", "=", "1", ")", "\n", "seg_cond_B", "=", "torch", ".", "cat", "(", "[", "self", ".", "seg_real_B_out", ",", "self", ".", "mask_B", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                    ", "seg_cond_A", "=", "self", ".", "seg_real_A_out", "\n", "seg_cond_B", "=", "self", ".", "seg_real_B_out", "\n", "", "self", ".", "fake_B", "=", "self", ".", "netG_A", "(", "self", ".", "real_A", ",", "seg_cond_A", ",", "freeze", "=", "False", ")", "\n", "self", ".", "fake_A", "=", "self", ".", "netG_B", "(", "self", ".", "real_B", ",", "seg_cond_B", ",", "freeze", "=", "False", ")", "\n", "\n", "self", ".", "seg_fake_B_out", "=", "self", ".", "netS_B", "(", "self", ".", "fake_B", ")", "#self.tmpS_B(self.fake_B)#.detach()", "\n", "self", ".", "seg_fake_A_out", "=", "self", ".", "netS_A", "(", "self", ".", "fake_A", ")", "#self.tmpS_A(self.fake_A)#.detach()", "\n", "\n", "if", "self", ".", "add_mask", ":", "\n", "                    ", "seg_cond_A_fake", "=", "torch", ".", "cat", "(", "[", "self", ".", "seg_fake_B_out", ",", "self", ".", "mask_A", "]", ",", "dim", "=", "1", ")", "\n", "seg_cond_B_fake", "=", "torch", ".", "cat", "(", "[", "self", ".", "seg_fake_A_out", ",", "self", ".", "mask_B", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                    ", "seg_cond_A_fake", "=", "self", ".", "seg_fake_B_out", "\n", "seg_cond_B_fake", "=", "self", ".", "seg_fake_A_out", "\n", "\n", "", "self", ".", "rec_A", "=", "self", ".", "netG_B", "(", "self", ".", "fake_B", ",", "seg_cond_A_fake", ",", "freeze", "=", "True", ")", "\n", "self", ".", "rec_B", "=", "self", ".", "netG_A", "(", "self", ".", "fake_A", ",", "seg_cond_B_fake", ",", "freeze", "=", "True", ")", "\n", "\n", "", "else", ":", "\n", "# cycle GAN with segmentation loss", "\n", "                ", "self", ".", "fake_B", "=", "self", ".", "netG_A", "(", "self", ".", "real_A", ")", "\n", "self", ".", "rec_A", "=", "self", ".", "netG_B", "(", "self", ".", "fake_B", ")", "\n", "self", ".", "fake_A", "=", "self", ".", "netG_B", "(", "self", ".", "real_B", ")", "\n", "self", ".", "rec_B", "=", "self", ".", "netG_A", "(", "self", ".", "fake_A", ")", "\n", "self", ".", "seg_real_A_out", "=", "self", ".", "netS_A", "(", "self", ".", "real_A", ")", "\n", "self", ".", "seg_real_B_out", "=", "self", ".", "netS_B", "(", "self", ".", "real_B", ")", "\n", "self", ".", "seg_fake_B_out", "=", "self", ".", "netS_B", "(", "self", ".", "fake_B", ")", "\n", "self", ".", "seg_fake_A_out", "=", "self", ".", "netS_A", "(", "self", ".", "fake_A", ")", "\n", "\n", "", "if", "self", ".", "sem_dropout", "and", "self", ".", "isTrain", ":", "# ONLY MASK OUT TO COMPUTE LOSS DURING TRAINING!!", "\n", "                ", "self", ".", "seg_real_A_out", "=", "self", ".", "seg_real_A_out", "*", "self", ".", "seg_A", "\n", "self", ".", "seg_real_B_out", "=", "self", ".", "seg_real_B_out", "*", "self", ".", "seg_B", "\n", "self", ".", "seg_fake_A_out", "=", "self", ".", "seg_fake_A_out", "*", "self", ".", "seg_B", "\n", "self", ".", "seg_fake_B_out", "=", "self", ".", "seg_fake_B_out", "*", "self", ".", "seg_A", "\n", "\n", "img_mask_A", "=", "torch", ".", "sum", "(", "self", ".", "seg_A", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "img_mask_B", "=", "torch", ".", "sum", "(", "self", ".", "seg_B", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "self", ".", "fake_B", "=", "self", ".", "fake_B", "*", "img_mask_A", "\n", "self", ".", "fake_A", "=", "self", ".", "fake_A", "*", "img_mask_B", "\n", "self", ".", "rec_A", "=", "self", ".", "rec_A", "*", "img_mask_A", "\n", "self", ".", "rec_B", "=", "self", ".", "rec_B", "*", "img_mask_B", "\n", "\n", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "fake_B", "=", "self", ".", "netG_A", "(", "self", ".", "real_A", ")", "\n", "self", ".", "rec_A", "=", "self", ".", "netG_B", "(", "self", ".", "fake_B", ")", "\n", "self", ".", "fake_A", "=", "self", ".", "netG_B", "(", "self", ".", "real_B", ")", "\n", "self", ".", "rec_B", "=", "self", ".", "netG_A", "(", "self", ".", "fake_A", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.cycle_gan.CycleGAN.backward_D_basic": [[196, 216], ["netD", "cycle_gan.CycleGAN.criterionGAN", "netD", "cycle_gan.CycleGAN.criterionGAN", "loss_D.backward", "fake.detach"], "methods", ["None"], ["", "", "def", "backward_D_basic", "(", "self", ",", "netD", ",", "real", ",", "fake", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for the discriminator\n        Parameters:\n            netD (network)      -- the discriminator D\n            real (tensor array) -- real images\n            fake (tensor array) -- images generated by a generator\n        Return the discriminator loss.\n        We also call loss_D.backward() to calculate the gradients.\n        \"\"\"", "\n", "# Real", "\n", "pred_real", "=", "netD", "(", "real", ")", "\n", "#print(pred_real.size())", "\n", "loss_D_real", "=", "self", ".", "criterionGAN", "(", "pred_real", ",", "True", ")", "\n", "# Fake", "\n", "pred_fake", "=", "netD", "(", "fake", ".", "detach", "(", ")", ")", "\n", "loss_D_fake", "=", "self", ".", "criterionGAN", "(", "pred_fake", ",", "False", ")", "\n", "# Combined loss and calculate gradients", "\n", "loss_D", "=", "(", "loss_D_real", "+", "loss_D_fake", ")", "*", "0.5", "\n", "loss_D", ".", "backward", "(", ")", "\n", "return", "loss_D", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.cycle_gan.CycleGAN.backward_D_A": [[217, 220], ["cycle_gan.CycleGAN.backward_D_basic"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.cycle_gan.CycleGAN.backward_D_basic"], ["", "def", "backward_D_A", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for discriminator D_A\"\"\"", "\n", "self", ".", "loss_D_A", "=", "self", ".", "backward_D_basic", "(", "self", ".", "netD_A", ",", "self", ".", "real_B", ",", "self", ".", "fake_B", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.cycle_gan.CycleGAN.backward_D_B": [[221, 224], ["cycle_gan.CycleGAN.backward_D_basic"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.cycle_gan.CycleGAN.backward_D_basic"], ["", "def", "backward_D_B", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for discriminator D_B\"\"\"", "\n", "self", ".", "loss_D_B", "=", "self", ".", "backward_D_basic", "(", "self", ".", "netD_B", ",", "self", ".", "real_A", ",", "self", ".", "fake_A", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.cycle_gan.CycleGAN.backward_G": [[225, 266], ["cycle_gan.CycleGAN.criterionGAN", "cycle_gan.CycleGAN.criterionGAN", "cycle_gan.CycleGAN.netG_A", "cycle_gan.CycleGAN.netG_B", "cycle_gan.CycleGAN.netD_A", "cycle_gan.CycleGAN.netD_B", "cycle_gan.CycleGAN.criterionCycle", "cycle_gan.CycleGAN.criterionCycle", "cycle_gan.CycleGAN.criterionSeg", "cycle_gan.CycleGAN.criterionSeg", "cycle_gan.CycleGAN.criterionSeg", "cycle_gan.CycleGAN.criterionSeg", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "torch.argmax().long", "cycle_gan.CycleGAN.criterionIdt", "cycle_gan.CycleGAN.criterionIdt", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "cycle_gan.CycleGAN.seg_A.detach", "cycle_gan.CycleGAN.seg_B.detach", "cycle_gan.CycleGAN.seg_B.detach", "cycle_gan.CycleGAN.seg_A.detach"], "methods", ["None"], ["", "def", "backward_G", "(", "self", ",", "steps", ")", ":", "\n", "        ", "\"\"\"Calculate the loss for generators G_A and G_B\"\"\"", "\n", "lambda_idt", "=", "self", ".", "opt", ".", "lambda_identity", "\n", "lambda_A", "=", "self", ".", "opt", ".", "lambda_A", "\n", "lambda_B", "=", "self", ".", "opt", ".", "lambda_B", "\n", "# Identity loss", "\n", "if", "lambda_idt", ">", "0", ":", "\n", "# G_A should be identity if real_B is fed: ||G_A(B) - B||", "\n", "            ", "self", ".", "idt_A", "=", "self", ".", "netG_A", "(", "self", ".", "real_B", ")", "\n", "self", ".", "loss_idt_A", "=", "self", ".", "criterionIdt", "(", "self", ".", "idt_A", ",", "self", ".", "real_B", ")", "*", "lambda_B", "*", "lambda_idt", "\n", "# G_B should be identity if real_A is fed: ||G_B(A) - A||", "\n", "self", ".", "idt_B", "=", "self", ".", "netG_B", "(", "self", ".", "real_A", ")", "\n", "self", ".", "loss_idt_B", "=", "self", ".", "criterionIdt", "(", "self", ".", "idt_B", ",", "self", ".", "real_A", ")", "*", "lambda_A", "*", "lambda_idt", "\n", "", "else", ":", "\n", "            ", "self", ".", "loss_idt_A", "=", "0", "\n", "self", ".", "loss_idt_B", "=", "0", "\n", "\n", "# GAN loss D_A(G_A(A))", "\n", "", "self", ".", "loss_G_A", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD_A", "(", "self", ".", "fake_B", ")", ",", "True", ")", "\n", "\n", "# GAN loss D_B(G_B(B))", "\n", "self", ".", "loss_G_B", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD_B", "(", "self", ".", "fake_A", ")", ",", "True", ")", "\n", "\n", "# Forward cycle loss || G_B(G_A(A)) - A||", "\n", "self", ".", "loss_cycle_A", "=", "self", ".", "criterionCycle", "(", "self", ".", "rec_A", ",", "self", ".", "real_A", ")", "*", "lambda_A", "\n", "# Backward cycle loss || G_A(G_B(B)) - B||", "\n", "self", ".", "loss_cycle_B", "=", "self", ".", "criterionCycle", "(", "self", ".", "rec_B", ",", "self", ".", "real_B", ")", "*", "lambda_B", "\n", "# combined loss and calculate gradients", "\n", "loss_G_B", "=", "self", ".", "loss_G_B", "+", "self", ".", "loss_cycle_B", "+", "self", ".", "loss_idt_B", "\n", "loss_G_A", "=", "self", ".", "loss_G_A", "+", "self", ".", "loss_cycle_A", "+", "self", ".", "loss_idt_A", "\n", "\n", "if", "self", ".", "learn_seg", ":", "\n", "            ", "self", ".", "loss_seg_real_A", "=", "self", ".", "criterionSeg", "(", "self", ".", "seg_real_A_out", ",", "torch", ".", "argmax", "(", "self", ".", "seg_A", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", ".", "long", "(", ")", ")", "\n", "self", ".", "loss_seg_real_B", "=", "self", ".", "criterionSeg", "(", "self", ".", "seg_real_B_out", ",", "torch", ".", "argmax", "(", "self", ".", "seg_B", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", ".", "long", "(", ")", ")", "\n", "self", ".", "loss_seg_fake_A", "=", "self", ".", "criterionSeg", "(", "self", ".", "seg_fake_A_out", ",", "torch", ".", "argmax", "(", "self", ".", "seg_B", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", ".", "long", "(", ")", ")", "\n", "self", ".", "loss_seg_fake_B", "=", "self", ".", "criterionSeg", "(", "self", ".", "seg_fake_B_out", ",", "torch", ".", "argmax", "(", "self", ".", "seg_A", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", ".", "long", "(", ")", ")", "\n", "loss_G_A", "+=", "(", "self", ".", "loss_seg_real_A", "*", "0.5", "+", "self", ".", "loss_seg_fake_B", "*", "0.05", ")", "\n", "loss_G_B", "+=", "(", "self", ".", "loss_seg_real_B", "*", "0.5", "+", "self", ".", "loss_seg_fake_A", "*", "0.05", ")", "# (self.loss_seg_real_B + self.loss_seg_fake_A)", "\n", "# loss_G_B += (self.loss_seg_real_B+ self.loss_seg_fake_A)", "\n", "", "loss_G", "=", "loss_G_A", "+", "loss_G_B", "\n", "return", "loss_G", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.cycle_gan.CycleGAN.optimize_parameters": [[267, 285], ["cycle_gan.CycleGAN.forward", "cycle_gan.CycleGAN.set_requires_grad", "cycle_gan.CycleGAN.optimizer_G.zero_grad", "cycle_gan.CycleGAN.backward_G", "cycle_gan.CycleGAN.backward", "cycle_gan.CycleGAN.optimizer_G.step", "cycle_gan.CycleGAN.set_requires_grad", "cycle_gan.CycleGAN.optimizer_D.zero_grad", "cycle_gan.CycleGAN.backward_D_A", "cycle_gan.CycleGAN.backward_D_B", "cycle_gan.CycleGAN.optimizer_D.step"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.forward", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.cycle_gan.CycleGAN.backward_G", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.cycle_gan.CycleGAN.backward_D_A", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.cycle_gan.CycleGAN.backward_D_B"], ["", "def", "optimize_parameters", "(", "self", ",", "steps", ")", ":", "\n", "        ", "\"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"", "\n", "# forward", "\n", "self", ".", "forward", "(", ")", "# compute fake images and reconstruction images.", "\n", "\n", "# G_A, S_A and G_B, S_B", "\n", "self", ".", "set_requires_grad", "(", "[", "self", ".", "netD_A", ",", "self", ".", "netD_B", "]", ",", "False", ")", "# Ds require no gradients when optimizing Gs", "\n", "self", ".", "optimizer_G", ".", "zero_grad", "(", ")", "\n", "loss_G", "=", "self", ".", "backward_G", "(", "steps", ")", "\n", "loss_G", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_G", ".", "step", "(", ")", "\n", "\n", "# D_A and D_B", "\n", "self", ".", "set_requires_grad", "(", "[", "self", ".", "netD_A", ",", "self", ".", "netD_B", "]", ",", "True", ")", "\n", "self", ".", "optimizer_D", ".", "zero_grad", "(", ")", "# set D_A and D_B's gradients to zero", "\n", "self", ".", "backward_D_A", "(", ")", "# calculate gradients for D_A", "\n", "self", ".", "backward_D_B", "(", ")", "# calculate graidents for D_B", "\n", "self", ".", "optimizer_D", ".", "step", "(", ")", "# update D_A and D_B's weights", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.normalization.SegFeature.__init__": [[10, 31], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "label_nc", ",", "ngf", "=", "64", ",", "feat_nc", "=", "512", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "convfeat", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "label_nc", ",", "ngf", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ngf", ",", "2", "*", "ngf", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "2", "*", "ngf", ",", "4", "*", "ngf", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "4", "*", "ngf", ",", "8", "*", "ngf", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ")", "\n", "self", ".", "avp", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "7", ",", "7", ")", ")", "\n", "self", ".", "mlp", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "8", "*", "ngf", "*", "7", "*", "7", ",", "8", "*", "ngf", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "8", "*", "ngf", ",", "feat_nc", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.normalization.SegFeature.forward": [[32, 38], ["normalization.SegFeature.convfeat", "normalization.SegFeature.avp", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "normalization.SegFeature.mlp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "image", ",", "seg_map", ")", ":", "\n", "        ", "seg_feat", "=", "self", ".", "convfeat", "(", "seg_map", ")", "\n", "seg_feat", "=", "self", ".", "avp", "(", "seg_feat", ")", "\n", "seg_feat", "=", "torch", ".", "flatten", "(", "seg_feat", ",", "1", ")", "\n", "seg_feat", "=", "self", ".", "mlp", "(", "seg_feat", ")", "\n", "return", "seg_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.normalization.SharedSRenorm.__init__": [[83, 99], ["torch.Module.__init__", "config_text.startswith", "re.search", "str", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "re.search.group", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "ValueError"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config_text", ",", "norm_nc", ",", "label_nc", "=", "4", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "config_text", ".", "startswith", "(", "'spade'", ")", "\n", "parsed", "=", "re", ".", "search", "(", "'spade(\\D+)(\\d)x\\d'", ",", "config_text", ")", "\n", "param_free_norm_type", "=", "str", "(", "parsed", ".", "group", "(", "1", ")", ")", "\n", "ks", "=", "3", "\n", "if", "param_free_norm_type", "==", "'instance'", ":", "\n", "            ", "self", ".", "param_free_norm", "=", "nn", ".", "InstanceNorm2d", "(", "norm_nc", ",", "affine", "=", "False", ")", "\n", "", "elif", "param_free_norm_type", "==", "'batch'", ":", "\n", "            ", "self", ".", "param_free_norm", "=", "nn", ".", "BatchNorm2d", "(", "norm_nc", ",", "affine", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'%s is not a recognized param-free norm type in SPADE'", "\n", "%", "param_free_norm_type", ")", "\n", "", "nhidden", "=", "512", "\n", "self", ".", "mlp_gamma", "=", "nn", ".", "Linear", "(", "nhidden", ",", "norm_nc", ")", "\n", "self", ".", "mlp_beta", "=", "nn", ".", "Linear", "(", "nhidden", ",", "norm_nc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.normalization.SharedSRenorm.forward": [[100, 116], ["normalization.SharedSRenorm.param_free_norm", "normalization.SharedSRenorm.mlp_gamma", "gamma.view.view.size", "gamma.view.view.view", "normalization.SharedSRenorm.mlp_beta", "beta.view.view.view", "beta.view.view.expand_as", "gamma.view.view.expand_as"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "seg_feat", ")", ":", "\n", "# Part 1. generate parameter-free normalized activations", "\n", "        ", "normalized", "=", "self", ".", "param_free_norm", "(", "x", ")", "\n", "\n", "# Part 2. produce scaling and bias conditioned on semantic map", "\n", "gamma", "=", "self", ".", "mlp_gamma", "(", "seg_feat", ")", "\n", "b", ",", "c", "=", "gamma", ".", "size", "(", ")", "\n", "gamma", "=", "gamma", ".", "view", "(", "b", ",", "c", ",", "1", ",", "1", ")", "\n", "\n", "beta", "=", "self", ".", "mlp_beta", "(", "seg_feat", ")", "\n", "beta", "=", "beta", ".", "view", "(", "b", ",", "c", ",", "1", ",", "1", ")", "\n", "\n", "# apply scale and bias", "\n", "out", "=", "normalized", "*", "(", "1", "+", "gamma", ".", "expand_as", "(", "normalized", ")", ")", "+", "beta", ".", "expand_as", "(", "normalized", ")", "\n", "\n", "return", "out", "", "", "", ""]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.normalization.get_nonspade_norm_layer": [[43, 80], ["hasattr", "torch.weight.size", "norm_type.startswith", "torch.Sequential", "getattr", "torch", "getattr", "delattr", "torch.register_parameter", "torch.BatchNorm2d", "len", "normalization.get_nonspade_norm_layer.get_out_channel"], "function", ["None"], ["", "", "def", "get_nonspade_norm_layer", "(", "opt", ",", "norm_type", "=", "'instance'", ")", ":", "\n", "    ", "\"\"\"\n    Copyright (C) 2019 NVIDIA Corporation.  All rights reserved.\n    Licensed under the CC BY-NC-SA 4.0 license (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).\n    \"\"\"", "\n", "# helper function to get # output channels of the previous layer", "\n", "def", "get_out_channel", "(", "layer", ")", ":", "\n", "        ", "if", "hasattr", "(", "layer", ",", "'out_channels'", ")", ":", "\n", "            ", "return", "getattr", "(", "layer", ",", "'out_channels'", ")", "\n", "", "return", "layer", ".", "weight", ".", "size", "(", "0", ")", "\n", "\n", "# this function will be returned", "\n", "", "def", "add_norm_layer", "(", "layer", ")", ":", "\n", "        ", "nonlocal", "norm_type", "\n", "if", "norm_type", ".", "startswith", "(", "'spectral'", ")", ":", "\n", "            ", "layer", "=", "spectral_norm", "(", "layer", ")", "\n", "subnorm_type", "=", "norm_type", "[", "len", "(", "'spectral'", ")", ":", "]", "\n", "\n", "", "if", "subnorm_type", "==", "'none'", "or", "len", "(", "subnorm_type", ")", "==", "0", ":", "\n", "            ", "return", "layer", "\n", "\n", "# remove bias in the previous layer, which is meaningless", "\n", "# since it has no effect after normalization", "\n", "", "if", "getattr", "(", "layer", ",", "'bias'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "delattr", "(", "layer", ",", "'bias'", ")", "\n", "layer", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "\n", "", "if", "subnorm_type", "==", "'batch'", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "(", "get_out_channel", "(", "layer", ")", ",", "affine", "=", "True", ")", "\n", "", "elif", "subnorm_type", "==", "'instance'", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "InstanceNorm2d", "(", "get_out_channel", "(", "layer", ")", ",", "affine", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'normalization layer %s is not recognized'", "%", "subnorm_type", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "layer", ",", "norm_layer", ")", "\n", "\n", "", "return", "add_norm_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.Identity.forward": [[17, 19], ["None"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SingleSemanticDropout.__init__": [[222, 227], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dropout_rate", "=", "0.2", ",", "num_class", "=", "4", ",", "weighted_prob", "=", "False", ")", ":", "\n", "        ", "super", "(", "SingleSemanticDropout", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "p", "=", "dropout_rate", "\n", "self", ".", "nclass", "=", "num_class", "\n", "self", ".", "weighted_prob", "=", "weighted_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SingleSemanticDropout.__call__": [[228, 259], ["torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "list", "torch.argmax.unique().numpy", "torch.argmax.unique().numpy", "torch.argmax.unique().numpy", "torch.argmax.unique().numpy", "numpy.random.uniform", "numpy.unique", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "numpy.zeros", "range", "random.choices", "random.choices", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "mask_img.size", "img.size", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "len", "len", "networks2d.softmax", "torch.argmax.nelement", "torch.argmax.nelement", "torch.argmax.nelement", "torch.argmax.nelement", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.softmax"], ["", "def", "__call__", "(", "self", ",", "img", ",", "seg", ")", ":", "\n", "#tmp_img = img", "\n", "#tmp_img = (tmp_img + 1)/2.", "\n", "        ", "label", "=", "torch", ".", "argmax", "(", "seg", ",", "dim", "=", "1", ")", "\n", "lab_list", "=", "list", "(", "label", ".", "unique", "(", ")", ".", "numpy", "(", ")", ")", "\n", "if", "np", ".", "random", ".", "uniform", "(", "0", ",", "1", ")", "<=", "self", ".", "p", ":", "\n", "            ", "if", "self", ".", "weighted_prob", ":", "\n", "                ", "weights", "=", "np", ".", "zeros", "(", "len", "(", "lab_list", ")", ")", "\n", "for", "l", "in", "range", "(", "len", "(", "lab_list", ")", ")", ":", "\n", "                    ", "weights", "[", "l", "]", "=", "(", "label", "==", "lab_list", "[", "l", "]", ")", ".", "sum", "(", ")", ".", "float", "(", ")", "/", "label", ".", "nelement", "(", ")", "\n", "", "weights", "=", "1.", "-", "softmax", "(", "weights", ")", "\n", "#print(lab_list, weights)", "\n", "selected", "=", "random", ".", "choices", "(", "lab_list", ",", "weights", "=", "weights", ",", "k", "=", "len", "(", "lab_list", ")", ")", "\n", "", "else", ":", "\n", "                ", "selected", "=", "random", ".", "choices", "(", "lab_list", ",", "k", "=", "len", "(", "lab_list", ")", ")", "\n", "\n", "", "selected", "=", "np", ".", "unique", "(", "selected", ")", "\n", "#exclude = np.array(list(set(np.arange(self.nclass)) - set(selected)))", "\n", "#print(selected)", "\n", "mask", "=", "torch", ".", "zeros_like", "(", "seg", ")", "\n", "mask", "[", ":", ",", "selected", ",", ":", ",", ":", "]", "=", "seg", "[", ":", ",", "selected", ",", ":", ",", ":", "]", "\n", "\n", "mask_img", "=", "torch", ".", "sum", "(", "seg", "[", ":", ",", "selected", ",", ":", ",", ":", "]", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "*", "img", "\n", "#mask_img = 2*mask_img - 1.", "\n", "#print(tmpa.min(), tmpa.max(), tmpb.min(), tmpb.max())", "\n", "assert", "mask_img", ".", "size", "(", ")", "==", "img", ".", "size", "(", ")", ",", "'Masked image shape must match input'", "\n", "\n", "return", "mask_img", ",", "mask", "\n", "\n", "", "else", ":", "\n", "            ", "return", "img", ",", "seg", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.PairedSemanticDropout.__init__": [[262, 267], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dropout_rate", "=", "0.2", ",", "num_class", "=", "4", ",", "weighted_prob", "=", "False", ")", ":", "\n", "        ", "super", "(", "PairedSemanticDropout", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "p", "=", "dropout_rate", "\n", "self", ".", "nclass", "=", "num_class", "\n", "self", ".", "weighted_prob", "=", "weighted_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.PairedSemanticDropout.__call__": [[268, 307], ["torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax.unique().size", "torch.argmax.unique().size", "torch.argmax.unique().size", "torch.argmax.unique().size", "torch.argmax.unique().size", "torch.argmax.unique().size", "torch.argmax.unique().size", "torch.argmax.unique().size", "numpy.random.uniform", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "label_ab.append", "numpy.zeros", "range", "print", "random.choices", "random.choices", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "torch.argmax.unique", "i.item", "len", "len", "networks2d.softmax", "mask_img_a.size", "img_a.size", "mask_img_b.size", "img_b.size", "mask_a.size", "seg_a.size", "mask_b.size", "seg_b.size", "len", "len", "torch.argmax.nelement", "torch.argmax.nelement", "torch.argmax.nelement", "torch.argmax.nelement", "torch.argmax.nelement", "torch.argmax.nelement", "torch.argmax.nelement", "torch.argmax.nelement"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.softmax"], ["", "def", "__call__", "(", "self", ",", "img_a", ",", "seg_a", ",", "img_b", ",", "seg_b", ")", ":", "\n", "        ", "label_a", "=", "torch", ".", "argmax", "(", "seg_a", ",", "dim", "=", "1", ")", "\n", "label_b", "=", "torch", ".", "argmax", "(", "seg_b", ",", "dim", "=", "1", ")", "\n", "if", "label_a", ".", "unique", "(", ")", ".", "size", "(", ")", ">", "label_b", ".", "unique", "(", ")", ".", "size", "(", ")", ":", "\n", "            ", "tmp1", ",", "tmp2", "=", "label_a", ".", "unique", "(", ")", ",", "label_b", ".", "unique", "(", ")", "\n", "", "else", ":", "\n", "            ", "tmp1", ",", "tmp2", "=", "label_b", ".", "unique", "(", ")", ",", "label_a", ".", "unique", "(", ")", "\n", "", "label_ab", "=", "[", "]", "\n", "for", "i", "in", "tmp1", ":", "\n", "            ", "if", "i", "in", "tmp2", ":", "\n", "                ", "label_ab", ".", "append", "(", "i", ".", "item", "(", ")", ")", "\n", "", "", "if", "np", ".", "random", ".", "uniform", "(", "0", ",", "1", ")", "<=", "self", ".", "p", ":", "\n", "            ", "if", "self", ".", "weighted_prob", ":", "\n", "                ", "weights", "=", "np", ".", "zeros", "(", "len", "(", "label_ab", ")", ")", "\n", "for", "l", "in", "range", "(", "len", "(", "label_ab", ")", ")", ":", "\n", "                    ", "weights", "[", "l", "]", "=", "(", "(", "label_a", "==", "label_ab", "[", "l", "]", ")", ".", "sum", "(", ")", "+", "(", "label_b", "==", "label_ab", "[", "l", "]", ")", ".", "sum", "(", ")", ")", ".", "float", "(", ")", "/", "(", "label_a", ".", "nelement", "(", ")", "+", "label_b", ".", "nelement", "(", ")", ")", "\n", "", "weights", "=", "1.", "-", "softmax", "(", "weights", ")", "\n", "print", "(", "label_ab", ",", "weights", ")", "\n", "selected", "=", "random", ".", "choices", "(", "label_ab", ",", "weights", "=", "weights", ",", "k", "=", "len", "(", "label_ab", ")", ")", "\n", "", "else", ":", "\n", "                ", "selected", "=", "random", ".", "choices", "(", "label_ab", ",", "k", "=", "len", "(", "label_ab", ")", ")", "\n", "\n", "#exclude = np.array(list(set(np.arange(self.nclass)) - set(selected)))", "\n", "#print(selected)", "\n", "", "mask_a", ",", "mask_b", "=", "torch", ".", "zeros_like", "(", "seg_a", ")", ",", "torch", ".", "zeros_like", "(", "seg_b", ")", "\n", "mask_a", "[", ":", ",", "selected", ",", ":", ",", ":", "]", "=", "seg_a", "[", ":", ",", "selected", ",", ":", ",", ":", "]", "\n", "mask_b", "[", ":", ",", "selected", ",", ":", ",", ":", "]", "=", "seg_b", "[", ":", ",", "selected", ",", ":", ",", ":", "]", "\n", "\n", "mask_img_a", "=", "torch", ".", "sum", "(", "seg_a", "[", ":", ",", "selected", ",", ":", ",", ":", "]", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "*", "img_a", "\n", "mask_img_b", "=", "torch", ".", "sum", "(", "seg_b", "[", ":", ",", "selected", ",", ":", ",", ":", "]", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "*", "img_b", "\n", "tmpa", ",", "tmpb", "=", "torch", ".", "sum", "(", "seg_a", "[", ":", ",", "selected", ",", ":", ",", ":", "]", ",", "dim", "=", "1", ")", ",", "torch", ".", "sum", "(", "seg_b", "[", ":", ",", "selected", ",", ":", ",", ":", "]", ",", "dim", "=", "1", ")", "\n", "#print(tmpa.min(), tmpa.max(), tmpb.min(), tmpb.max())", "\n", "assert", "mask_img_a", ".", "size", "(", ")", "==", "img_a", ".", "size", "(", ")", "and", "mask_img_b", ".", "size", "(", ")", "==", "img_b", ".", "size", "(", ")", ",", "'Masked image shape must match input'", "\n", "assert", "mask_a", ".", "size", "(", ")", "==", "seg_a", ".", "size", "(", ")", "and", "mask_b", ".", "size", "(", ")", "==", "seg_b", ".", "size", "(", ")", ",", "'Masked image shape must match input'", "\n", "\n", "return", "mask_img_a", ",", "mask_a", ",", "mask_img_b", ",", "mask_b", "\n", "\n", "", "else", ":", "\n", "            ", "return", "img_a", ",", "seg_a", ",", "img_b", ",", "seg_b", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SegLoss.__init__": [[317, 322], ["torch.Module.__init__", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "weight", "=", "0.5", ",", "prob_seg", "=", "False", ")", ":", "\n", "        ", "super", "(", "SegLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "prob_seg", "=", "prob_seg", "\n", "self", ".", "ce", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "weight", "=", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SegLoss.__call__": [[323, 341], ["target.size", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "networks2d.SegLoss.ce", "networks2d.SegLoss.ce", "networks2d.symmetric_cross_entropy", "mask.float().view().expand_as", "mask.long", "mask_back.float().view().expand_as", "mask_back.long", "mask.float().view", "mask_back.float().view", "mask.float", "mask_back.float"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.symmetric_cross_entropy"], ["", "def", "__call__", "(", "self", ",", "prediction", ",", "target", ")", ":", "\n", "        ", "b", ",", "c", ",", "w", ",", "h", "=", "target", ".", "size", "(", ")", "\n", "if", "not", "self", ".", "prob_seg", ":", "\n", "            ", "seg_gt", "=", "torch", ".", "argmax", "(", "target", ",", "dim", "=", "1", ")", "# b, w, h", "\n", "mask", "=", "(", "seg_gt", ">", "0.", ")", "\n", "mask_output", "=", "mask", ".", "float", "(", ")", ".", "view", "(", "b", ",", "1", ",", "w", ",", "h", ")", ".", "expand_as", "(", "prediction", ")", "*", "prediction", "\n", "mask_gt", "=", "mask", ".", "long", "(", ")", "*", "seg_gt", "\n", "foreground_loss", "=", "self", ".", "ce", "(", "mask_output", ",", "mask_gt", ")", "\n", "\n", "mask_back", "=", "(", "seg_gt", "==", "0.", ")", "\n", "mask_back_output", "=", "mask_back", ".", "float", "(", ")", ".", "view", "(", "b", ",", "1", ",", "w", ",", "h", ")", ".", "expand_as", "(", "prediction", ")", "*", "prediction", "\n", "mask_back_gt", "=", "mask_back", ".", "long", "(", ")", "*", "seg_gt", "\n", "background_loss", "=", "self", ".", "ce", "(", "mask_back_output", ",", "mask_back_gt", ")", "\n", "#print(foreground_loss, background_loss)", "\n", "return", "(", "1", "-", "self", ".", "weight", ")", "*", "foreground_loss", "+", "self", ".", "weight", "*", "background_loss", "\n", "\n", "", "else", ":", "\n", "            ", "return", "symmetric_cross_entropy", "(", "prediction", ",", "target", ",", "1.", ",", "0.", ")", "#self.ce(prediction, target.float())", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.GANLoss.__init__": [[350, 371], ["torch.Module.__init__", "networks2d.GANLoss.register_buffer", "networks2d.GANLoss.register_buffer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "gan_mode", ",", "target_real_label", "=", "1.0", ",", "target_fake_label", "=", "0.0", ")", ":", "\n", "        ", "\"\"\" Initialize the GANLoss class.\n        Parameters:\n            gan_mode (str) - - the type of GAN objective. It currently supports vanilla, lsgan, and wgangp.\n            target_real_label (bool) - - label for a real image\n            target_fake_label (bool) - - label of a fake image\n        Note: Do not use sigmoid as the last layer of Discriminator.\n        LSGAN needs no sigmoid. vanilla GANs will handle it with BCEWithLogitsLoss.\n        \"\"\"", "\n", "super", "(", "GANLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "'real_label'", ",", "torch", ".", "tensor", "(", "target_real_label", ")", ")", "\n", "self", ".", "register_buffer", "(", "'fake_label'", ",", "torch", ".", "tensor", "(", "target_fake_label", ")", ")", "\n", "self", ".", "gan_mode", "=", "gan_mode", "\n", "if", "gan_mode", "==", "'lsgan'", ":", "\n", "            ", "self", ".", "loss", "=", "nn", ".", "MSELoss", "(", ")", "\n", "", "elif", "gan_mode", "==", "'vanilla'", ":", "\n", "            ", "self", ".", "loss", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "", "elif", "gan_mode", "in", "[", "'wgangp'", "]", ":", "\n", "            ", "self", ".", "loss", "=", "None", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'gan mode %s not implemented'", "%", "gan_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.GANLoss.get_target_tensor": [[372, 386], ["target_tensor.expand_as"], "methods", ["None"], ["", "", "def", "get_target_tensor", "(", "self", ",", "prediction", ",", "target_is_real", ")", ":", "\n", "        ", "\"\"\"Create label tensors with the same size as the input.\n        Parameters:\n            prediction (tensor) - - tpyically the prediction from a discriminator\n            target_is_real (bool) - - if the ground truth label is for real images or fake images\n        Returns:\n            A label tensor filled with ground truth label, and with the size of the input\n        \"\"\"", "\n", "\n", "if", "target_is_real", ":", "\n", "            ", "target_tensor", "=", "self", ".", "real_label", "\n", "", "else", ":", "\n", "            ", "target_tensor", "=", "self", ".", "fake_label", "\n", "", "return", "target_tensor", ".", "expand_as", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.GANLoss.__call__": [[387, 404], ["networks2d.GANLoss.get_target_tensor", "networks2d.GANLoss.loss", "prediction.mean", "prediction.mean"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.GANLoss.get_target_tensor"], ["", "def", "__call__", "(", "self", ",", "prediction", ",", "target_is_real", ")", ":", "\n", "        ", "\"\"\"Calculate loss given Discriminator's output and grount truth labels.\n        Parameters:\n            prediction (tensor) - - tpyically the prediction output from a discriminator\n            target_is_real (bool) - - if the ground truth label is for real images or fake images\n        Returns:\n            the calculated loss.\n        \"\"\"", "\n", "if", "self", ".", "gan_mode", "in", "[", "'lsgan'", ",", "'vanilla'", "]", ":", "\n", "            ", "target_tensor", "=", "self", ".", "get_target_tensor", "(", "prediction", ",", "target_is_real", ")", "\n", "loss", "=", "self", ".", "loss", "(", "prediction", ",", "target_tensor", ")", "\n", "", "elif", "self", ".", "gan_mode", "==", "'wgangp'", ":", "\n", "            ", "if", "target_is_real", ":", "\n", "                ", "loss", "=", "-", "prediction", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "prediction", ".", "mean", "(", ")", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SRenormGenerator.__init__": [[442, 475], ["torch.Module.__init__", "models.normalization.SegFeature", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "networks2d.SharedSReNormResBlock", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "networks2d.SharedSReNormResBlock", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "networks2d.SharedSReNormResBlock", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "networks2d.SharedSReNormResBlock", "networks2d.SharedSReNormResBlock", "networks2d.SharedSReNormResBlock", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "networks2d.SharedSReNormResBlock", "networks2d.SharedSReNormResBlock", "networks2d.SharedSReNormResBlock", "networks2d.SharedSReNormResBlock", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "type"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "ngf", ",", "norm_layer", "=", "nn", ".", "InstanceNorm2d", ",", "use_dropout", "=", "False", ",", "padding_type", "=", "'zeros'", ",", "label_nc", "=", "4", ")", ":", "\n", "        ", "super", "(", "SRenormGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "self", ".", "shared_seg_feature", "=", "SegFeature", "(", "label_nc", "=", "label_nc", ")", "\n", "self", ".", "head", "=", "nn", ".", "Conv2d", "(", "input_nc", ",", "ngf", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "\n", "#self.down_0 = nn.Conv2d(ngf, ngf, kernel_size=4, stride=2, padding=1, bias=use_bias)", "\n", "self", ".", "down_spade_0", "=", "SharedSReNormResBlock", "(", "1", "*", "ngf", ",", "2", "*", "ngf", ")", "\n", "\n", "self", ".", "down_1", "=", "nn", ".", "Conv2d", "(", "2", "*", "ngf", ",", "2", "*", "ngf", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "self", ".", "down_spade_1", "=", "SharedSReNormResBlock", "(", "2", "*", "ngf", ",", "4", "*", "ngf", ")", "\n", "\n", "self", ".", "down_2", "=", "nn", ".", "Conv2d", "(", "4", "*", "ngf", ",", "4", "*", "ngf", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "self", ".", "down_spade_2", "=", "SharedSReNormResBlock", "(", "4", "*", "ngf", ",", "8", "*", "ngf", ")", "\n", "\n", "self", ".", "down_3", "=", "nn", ".", "Conv2d", "(", "8", "*", "ngf", ",", "8", "*", "ngf", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "self", ".", "down_spade_3", "=", "SharedSReNormResBlock", "(", "8", "*", "ngf", ",", "8", "*", "ngf", ")", "\n", "\n", "self", ".", "middle_0", "=", "SharedSReNormResBlock", "(", "8", "*", "ngf", ",", "8", "*", "ngf", ")", "\n", "self", ".", "middle_1", "=", "SharedSReNormResBlock", "(", "8", "*", "ngf", ",", "8", "*", "ngf", ")", "\n", "\n", "self", ".", "up", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ")", "\n", "self", ".", "up_3", "=", "SharedSReNormResBlock", "(", "16", "*", "ngf", ",", "8", "*", "ngf", ")", "\n", "self", ".", "up_2", "=", "SharedSReNormResBlock", "(", "16", "*", "ngf", ",", "4", "*", "ngf", ")", "\n", "self", ".", "up_1", "=", "SharedSReNormResBlock", "(", "8", "*", "ngf", ",", "2", "*", "ngf", ")", "\n", "self", ".", "up_0", "=", "SharedSReNormResBlock", "(", "4", "*", "ngf", ",", "1", "*", "ngf", ")", "\n", "\n", "self", ".", "tail", "=", "nn", ".", "Conv2d", "(", "ngf", ",", "output_nc", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "self", ".", "activate", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SRenormGenerator.set_required_grad": [[476, 479], ["networks2d.SRenormGenerator.parameters"], "methods", ["None"], ["", "def", "set_required_grad", "(", "self", ",", "requires_grad", ")", ":", "\n", "        ", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SRenormGenerator.forward": [[480, 505], ["networks2d.SRenormGenerator.shared_seg_feature", "networks2d.SRenormGenerator.head", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "networks2d.SRenormGenerator.down_spade_0", "networks2d.SRenormGenerator.down_spade_1", "networks2d.SRenormGenerator.down_spade_2", "networks2d.SRenormGenerator.down_spade_3", "networks2d.SRenormGenerator.up", "networks2d.SRenormGenerator.middle_0", "networks2d.SRenormGenerator.middle_1", "networks2d.SRenormGenerator.up_2", "networks2d.SRenormGenerator.up", "networks2d.SRenormGenerator.up_1", "networks2d.SRenormGenerator.up", "networks2d.SRenormGenerator.up_0", "networks2d.SRenormGenerator.up", "networks2d.SRenormGenerator.tail", "networks2d.SRenormGenerator.activate", "networks2d.SRenormGenerator.down_1", "networks2d.SRenormGenerator.down_2", "networks2d.SRenormGenerator.down_3", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "seg", ")", ":", "\n", "#self.set_required_grad(not freeze)", "\n", "        ", "seg_feat", ",", "seg_rep", ",", "seg_off", ",", "loss", "=", "self", ".", "shared_seg_feature", "(", "input", ",", "seg", ")", "\n", "x", "=", "self", ".", "head", "(", "input", ")", "# n, w/2, h/2", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x_0", "=", "self", ".", "down_spade_0", "(", "x", ",", "seg_feat", ")", "# 2n, w/2, h/2", "\n", "x_1", "=", "self", ".", "down_spade_1", "(", "self", ".", "down_1", "(", "x_0", ")", ",", "seg_feat", ")", "# 4n, w/4, h/4", "\n", "x_2", "=", "self", ".", "down_spade_2", "(", "self", ".", "down_2", "(", "x_1", ")", ",", "seg_feat", ")", "# 8n, w/8, h/8", "\n", "x_3", "=", "self", ".", "down_spade_3", "(", "self", ".", "down_3", "(", "x_2", ")", ",", "seg_feat", ")", "# 8n, w/16, h/16", "\n", "out", "=", "self", ".", "up", "(", "x_3", ")", "# 8n, w/8, h/8", "\n", "out", "=", "self", ".", "middle_0", "(", "out", ",", "seg_feat", ")", "#8n, w/8, h/8", "\n", "out", "=", "self", ".", "middle_1", "(", "out", ",", "seg_feat", ")", "#8n, w/8, h/8", "\n", "#out = self.up(out)  # 8n, w/8, h/8", "\n", "out", "=", "self", ".", "up_2", "(", "torch", ".", "cat", "(", "(", "out", ",", "x_2", ")", ",", "1", ")", ",", "seg_feat", ")", "#4n, w/8, w/8", "\n", "out", "=", "self", ".", "up", "(", "out", ")", "#4n, w/4, w/4", "\n", "out", "=", "self", ".", "up_1", "(", "torch", ".", "cat", "(", "(", "out", ",", "x_1", ")", ",", "1", ")", ",", "seg_feat", ")", "#2n, w/4, w/4", "\n", "\n", "out", "=", "self", ".", "up", "(", "out", ")", "#2n, w/2, h/2", "\n", "out", "=", "self", ".", "up_0", "(", "torch", ".", "cat", "(", "(", "out", ",", "x_0", ")", ",", "1", ")", ",", "seg_feat", ")", "#n, w/2, w/2", "\n", "\n", "out", "=", "self", ".", "up", "(", "out", ")", "#n, w, h", "\n", "out", "=", "self", ".", "tail", "(", "F", ".", "leaky_relu", "(", "out", ",", "2e-1", ")", ")", "\n", "\n", "out", "=", "self", ".", "activate", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.ResnetGenerator.__init__": [[512, 563], ["torch.Module.__init__", "range", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "networks2d.ResnetBlock", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "int", "int"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ",", "\n", "n_blocks", "=", "6", ",", "padding_type", "=", "'reflect'", ",", "activate", "=", "nn", ".", "Tanh", ")", ":", "\n", "        ", "\"\"\"Construct a Resnet-based generator\n        Parameters:\n            input_nc (int)      -- the number of channels in input images\n            output_nc (int)     -- the number of channels in output images\n            ngf (int)           -- the number of filters in the last conv layer\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers\n            n_blocks (int)      -- the number of ResNet blocks\n            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n        \"\"\"", "\n", "assert", "(", "n_blocks", ">=", "0", ")", "\n", "super", "(", "ResnetGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "model", "=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", ",", "\n", "nn", ".", "Conv2d", "(", "input_nc", ",", "ngf", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "n_downsampling", "=", "2", "\n", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add downsampling layers", "\n", "            ", "mult", "=", "2", "**", "i", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", "*", "mult", ",", "ngf", "*", "mult", "*", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", "*", "mult", "*", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "", "mult", "=", "2", "**", "n_downsampling", "\n", "for", "i", "in", "range", "(", "n_blocks", ")", ":", "# add ResNet blocks", "\n", "\n", "            ", "model", "+=", "[", "ResnetBlock", "(", "ngf", "*", "mult", ",", "padding_type", "=", "padding_type", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "use_bias", "=", "use_bias", ")", "]", "\n", "\n", "", "self", ".", "down_model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "model", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add upsampling layers", "\n", "            ", "mult", "=", "2", "**", "(", "n_downsampling", "-", "i", ")", "\n", "model", "+=", "[", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "mult", ",", "int", "(", "ngf", "*", "mult", "/", "2", ")", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "output_padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "int", "(", "ngf", "*", "mult", "/", "2", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "", "model", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", "]", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", ",", "output_nc", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ")", "]", "\n", "model", "+=", "[", "activate", "]", "\n", "\n", "self", ".", "upmodel", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.ResnetGenerator.forward": [[564, 570], ["networks2d.ResnetGenerator.down_model", "networks2d.ResnetGenerator.upmodel"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward\"\"\"", "\n", "feature", "=", "self", ".", "down_model", "(", "input", ")", "\n", "#print(feature.size())", "\n", "rec", "=", "self", ".", "upmodel", "(", "feature", ")", "\n", "return", "feature", ",", "rec", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.ResnetBlock.__init__": [[575, 584], ["torch.Module.__init__", "networks2d.ResnetBlock.build_conv_block"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.ResnetBlock.build_conv_block"], ["def", "__init__", "(", "self", ",", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", ":", "\n", "        ", "\"\"\"Initialize the Resnet block\n        A resnet block is a conv block with skip connections\n        We construct a conv block with build_conv_block function,\n        and implement skip connections in <forward> function.\n        Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n        \"\"\"", "\n", "super", "(", "ResnetBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_block", "=", "self", ".", "build_conv_block", "(", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.ResnetBlock.build_conv_block": [[585, 622], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "NotImplementedError", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "NotImplementedError"], "methods", ["None"], ["", "def", "build_conv_block", "(", "self", ",", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", ":", "\n", "        ", "\"\"\"Construct a convolutional block.\n        Parameters:\n            dim (int)           -- the number of channels in the conv layer.\n            padding_type (str)  -- the name of padding layer: reflect | replicate | zero\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers.\n            use_bias (bool)     -- if the conv layer uses bias or not\n        Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU))\n        \"\"\"", "\n", "conv_block", "=", "[", "]", "\n", "p", "=", "0", "\n", "if", "padding_type", "==", "'reflect'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'replicate'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReplicationPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'zero'", ":", "\n", "            ", "p", "=", "1", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'padding [%s] is not implemented'", "%", "padding_type", ")", "\n", "\n", "", "conv_block", "+=", "[", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "3", ",", "padding", "=", "p", ",", "bias", "=", "use_bias", ")", ",", "norm_layer", "(", "dim", ")", ",", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "if", "use_dropout", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "Dropout", "(", "0.5", ")", "]", "\n", "\n", "", "p", "=", "0", "\n", "if", "padding_type", "==", "'reflect'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'replicate'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReplicationPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'zero'", ":", "\n", "            ", "p", "=", "1", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'padding [%s] is not implemented'", "%", "padding_type", ")", "\n", "", "conv_block", "+=", "[", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "3", ",", "padding", "=", "p", ",", "bias", "=", "use_bias", ")", ",", "norm_layer", "(", "dim", ")", "]", "\n", "\n", "return", "nn", ".", "Sequential", "(", "*", "conv_block", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.ResnetBlock.forward": [[623, 627], ["networks2d.ResnetBlock.conv_block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward function (with skip connections)\"\"\"", "\n", "out", "=", "x", "+", "self", ".", "conv_block", "(", "x", ")", "# add skip connections", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.ResidualBasicBlock.__init__": [[629, 634], ["torch.Module.__init__", "networks2d.ResnetBlock", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "biases", ",", "padding", ",", "dropout", ",", "norm", ")", ":", "\n", "        ", "super", "(", "ResidualBasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "res_conv", "=", "ResnetBlock", "(", "input_nc", ",", "padding_type", "=", "padding", ",", "use_dropout", "=", "dropout", ",", "use_bias", "=", "biases", ",", "norm_layer", "=", "norm", ")", "\n", "self", ".", "down_conv", "=", "nn", ".", "Conv2d", "(", "input_nc", ",", "output_nc", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "biases", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.ResidualBasicBlock.forward": [[635, 640], ["networks2d.ResidualBasicBlock.res_conv", "networks2d.ResidualBasicBlock.down_conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "#print(x.size(), self.conv(x).size())", "\n", "        ", "out", "=", "self", ".", "res_conv", "(", "x", ")", "\n", "out", "=", "self", ".", "down_conv", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.UnetGenerator.__init__": [[646, 676], ["torch.Module.__init__", "networks2d.UnetSkipConnectionBlock", "range", "networks2d.UnetSkipConnectionBlock", "networks2d.UnetSkipConnectionBlock", "networks2d.UnetSkipConnectionBlock", "networks2d.UnetSkipConnectionBlock", "networks2d.UnetSkipConnectionBlock"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "num_downs", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ",", "upsample", "=", "False", ",", "res", "=", "False", ",", "is_seg", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Unet generator\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            output_nc (int) -- the number of channels in output images\n            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n                                image of size 128x128 will become of size 1x1 # at the bottleneck\n            ngf (int)       -- the number of filters in the last conv layer\n            norm_layer      -- normalization layer\n\n        We construct the U-Net from the innermost layer to the outermost layer.\n        It is a recursive process.\n        \"\"\"", "\n", "super", "(", "UnetGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# construct unet structure", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "8", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "None", ",", "norm_layer", "=", "norm_layer", ",", "\n", "innermost", "=", "True", ",", "upsample", "=", "upsample", ",", "residual", "=", "res", ",", "is_seg", "=", "is_seg", ")", "# add the innermost layer", "\n", "for", "i", "in", "range", "(", "num_downs", "-", "5", ")", ":", "# add intermediate layers with ngf * 8 filters", "\n", "            ", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "8", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "\n", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "\n", "upsample", "=", "upsample", ",", "residual", "=", "res", ",", "is_seg", "=", "is_seg", ")", "\n", "# gradually reduce the number of filters from ngf * 8 to ngf", "\n", "", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "4", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "\n", "norm_layer", "=", "norm_layer", ",", "upsample", "=", "upsample", ",", "residual", "=", "res", ",", "is_seg", "=", "is_seg", ")", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "2", ",", "ngf", "*", "4", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "\n", "norm_layer", "=", "norm_layer", ",", "upsample", "=", "upsample", ",", "residual", "=", "res", ",", "is_seg", "=", "is_seg", ")", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", ",", "ngf", "*", "2", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ",", "\n", "upsample", "=", "upsample", ",", "residual", "=", "res", ",", "is_seg", "=", "is_seg", ")", "\n", "self", ".", "model", "=", "UnetSkipConnectionBlock", "(", "output_nc", ",", "ngf", ",", "input_nc", "=", "input_nc", ",", "submodule", "=", "unet_block", ",", "outermost", "=", "True", ",", "\n", "norm_layer", "=", "norm_layer", ",", "upsample", "=", "upsample", ",", "residual", "=", "res", ",", "is_seg", "=", "is_seg", ")", "# add the outermost layer", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.UnetGenerator.set_required_grad": [[677, 680], ["networks2d.UnetGenerator.parameters"], "methods", ["None"], ["", "def", "set_required_grad", "(", "self", ",", "requires_grad", ")", ":", "\n", "        ", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.UnetGenerator.forward": [[681, 688], ["networks2d.UnetGenerator.set_required_grad", "networks2d.UnetGenerator.model"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.UnetGenerator.set_required_grad"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "requires_grad", "=", "True", ")", ":", "\n", "        ", "\"\"\"Standard forward\"\"\"", "\n", "#print(self.model)", "\n", "#print(input.size())", "\n", "#print(seg.size())", "\n", "self", ".", "set_required_grad", "(", "requires_grad", ")", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.UnetSkipConnectionBlock.__init__": [[696, 795], ["torch.Module.__init__", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "norm_layer", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "networks2d.ResidualBasicBlock", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "print", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "outer_nc", ",", "inner_nc", ",", "input_nc", "=", "None", ",", "\n", "submodule", "=", "None", ",", "outermost", "=", "False", ",", "innermost", "=", "False", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ",", "\n", "upsample", "=", "True", ",", "residual", "=", "False", ",", "padding_type", "=", "'zeros'", ",", "is_seg", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Unet submodule with skip connections.\n\n        Parameters:\n            outer_nc (int) -- the number of filters in the outer conv layer\n            inner_nc (int) -- the number of filters in the inner conv layer\n            input_nc (int) -- the number of channels in input images/features\n            submodule (UnetSkipConnectionBlock) -- previously defined submodules\n            outermost (bool)    -- if this module is the outermost module\n            innermost (bool)    -- if this module is the innermost module\n            norm_layer          -- normalization layer\n            user_dropout (bool) -- if use dropout layers.\n        \"\"\"", "\n", "super", "(", "UnetSkipConnectionBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "kw", "=", "4", "\n", "p", "=", "0", "\n", "downconv", "=", "[", "]", "\n", "upconv", "=", "[", "]", "\n", "\n", "if", "padding_type", "==", "'reflect'", ":", "\n", "            ", "downconv", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", "]", "\n", "upconv", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'replicate'", ":", "\n", "            ", "downconv", "+=", "[", "nn", ".", "ReplicationPad2d", "(", "1", ")", "]", "\n", "upconv", "+=", "[", "nn", ".", "ReplicationPad2d", "(", "1", ")", "]", "\n", "", "else", ":", "\n", "            ", "p", "=", "1", "\n", "", "self", ".", "outermost", "=", "outermost", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "", "if", "input_nc", "is", "None", ":", "\n", "            ", "input_nc", "=", "outer_nc", "\n", "\n", "", "if", "residual", "is", "True", ":", "# add residual connection", "\n", "            ", "downconv", "=", "[", "ResidualBasicBlock", "(", "input_nc", ",", "inner_nc", ",", "biases", "=", "use_bias", ",", "norm", "=", "norm_layer", ",", "\n", "dropout", "=", "use_dropout", ",", "padding", "=", "'reflect'", ")", "]", "\n", "", "else", ":", "\n", "            ", "downconv", "+=", "[", "nn", ".", "Conv2d", "(", "input_nc", ",", "inner_nc", ",", "kernel_size", "=", "4", ",", "\n", "stride", "=", "2", ",", "padding", "=", "p", ",", "bias", "=", "use_bias", ")", "]", "\n", "\n", "", "downrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "downnorm", "=", "norm_layer", "(", "inner_nc", ")", "\n", "uprelu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "upnorm", "=", "norm_layer", "(", "outer_nc", ")", "\n", "\n", "\n", "\n", "if", "outermost", ":", "\n", "            ", "upconv", "+=", "[", "nn", ".", "ConvTranspose2d", "(", "inner_nc", "*", "2", ",", "outer_nc", ",", "\n", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "\n", "padding", "=", "p", ")", "]", "\n", "if", "upsample", ":", "\n", "                ", "up_interp", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "conv", "=", "nn", ".", "Conv2d", "(", "inner_nc", "*", "2", ",", "outer_nc", ",", "\n", "kernel_size", "=", "3", ",", "padding", "=", "p", ")", "\n", "upconv", "=", "[", "up_interp", ",", "conv", "]", "\n", "", "down", "=", "downconv", "\n", "if", "is_seg", "is", "False", ":", "\n", "                ", "up", "=", "[", "uprelu", "]", "+", "upconv", "+", "[", "nn", ".", "Tanh", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "print", "(", "'No activation here'", ")", "\n", "up", "=", "[", "uprelu", "]", "+", "upconv", "\n", "", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "\n", "\n", "\n", "", "elif", "innermost", ":", "\n", "            ", "upconv", "=", "[", "nn", ".", "ConvTranspose2d", "(", "inner_nc", ",", "outer_nc", ",", "\n", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "\n", "padding", "=", "p", ",", "bias", "=", "use_bias", ")", "]", "\n", "if", "upsample", ":", "\n", "                ", "up_interp", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "conv", "=", "nn", ".", "Conv2d", "(", "inner_nc", ",", "outer_nc", ",", "stride", "=", "1", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "upconv", "=", "[", "up_interp", ",", "conv", "]", "\n", "", "down", "=", "[", "downrelu", "]", "+", "downconv", "\n", "up", "=", "[", "uprelu", "]", "+", "upconv", "+", "[", "upnorm", "]", "\n", "model", "=", "down", "+", "up", "\n", "#print(model)", "\n", "", "else", ":", "\n", "            ", "upconv", "+=", "[", "nn", ".", "ConvTranspose2d", "(", "inner_nc", "*", "2", ",", "outer_nc", ",", "\n", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "\n", "padding", "=", "p", ",", "bias", "=", "use_bias", ")", "]", "\n", "if", "upsample", ":", "\n", "                ", "up_interp", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "\n", "conv", "=", "nn", ".", "Conv2d", "(", "inner_nc", "*", "2", ",", "outer_nc", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "upconv", "=", "[", "up_interp", ",", "conv", "]", "\n", "\n", "", "down", "=", "[", "downrelu", "]", "+", "downconv", "+", "[", "downnorm", "]", "\n", "up", "=", "[", "uprelu", "]", "+", "upconv", "+", "[", "upnorm", "]", "\n", "\n", "if", "use_dropout", ":", "\n", "                ", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "+", "[", "nn", ".", "Dropout", "(", "0.5", ")", "]", "\n", "", "else", ":", "\n", "                ", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "\n", "\n", "", "", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.UnetSkipConnectionBlock.forward": [[796, 805], ["networks2d.UnetSkipConnectionBlock.model", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks2d.UnetSkipConnectionBlock.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "#print(x.size())", "\n", "#return self.model(x, seg)", "\n", "        ", "if", "self", ".", "outermost", ":", "\n", "#print('Outermost', x.size(), self.model(x,seg).size())", "\n", "            ", "return", "self", ".", "model", "(", "x", ")", "\n", "", "else", ":", "# add skip connections", "\n", "#print('Inner',x.size(), self.model(x).size())", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "x", ",", "self", ".", "model", "(", "x", ")", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SReNormResBlock.__init__": [[809, 827], ["torch.Module.__init__", "min", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch", "torch", "torch", "torch", "torch", "torch", "torch", "torch", "torch", "torch", "torch", "torch"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "fin", ",", "fout", ",", "norm_G", "=", "'spadeinstance3x3'", ",", "semantic_nc", "=", "4", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# Attributes", "\n", "self", ".", "learned_shortcut", "=", "(", "fin", "!=", "fout", ")", "\n", "fmiddle", "=", "min", "(", "fin", ",", "fout", ")", "\n", "\n", "# create conv layers", "\n", "self", ".", "conv_0", "=", "nn", ".", "Conv2d", "(", "fin", ",", "fmiddle", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv_1", "=", "nn", ".", "Conv2d", "(", "fmiddle", ",", "fout", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "if", "self", ".", "learned_shortcut", ":", "\n", "            ", "self", ".", "conv_s", "=", "nn", ".", "Conv2d", "(", "fin", ",", "fout", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n", "# apply spectral norm if specified", "\n", "", "if", "'spectral'", "in", "norm_G", ":", "\n", "            ", "self", ".", "conv_0", "=", "spectral_norm", "(", "self", ".", "conv_0", ")", "\n", "self", ".", "conv_1", "=", "spectral_norm", "(", "self", ".", "conv_1", ")", "\n", "if", "self", ".", "learned_shortcut", ":", "\n", "                ", "self", ".", "conv_s", "=", "spectral_norm", "(", "self", ".", "conv_s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SReNormResBlock.forward": [[831, 840], ["networks2d.SReNormResBlock.shortcut", "networks2d.SReNormResBlock.conv_0", "networks2d.SReNormResBlock.conv_1", "networks2d.SReNormResBlock.actvn", "networks2d.SReNormResBlock.actvn", "networks2d.SReNormResBlock.norm_0", "networks2d.SReNormResBlock.norm_1"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SharedSReNormResBlock.shortcut", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SReNormResBlock.actvn", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SReNormResBlock.actvn"], ["", "", "", "def", "forward", "(", "self", ",", "x", ",", "seg", ")", ":", "\n", "        ", "x_s", "=", "self", ".", "shortcut", "(", "x", ",", "seg", ")", "\n", "\n", "dx", "=", "self", ".", "conv_0", "(", "self", ".", "actvn", "(", "self", ".", "norm_0", "(", "x", ",", "seg", ")", ")", ")", "\n", "dx", "=", "self", ".", "conv_1", "(", "self", ".", "actvn", "(", "self", ".", "norm_1", "(", "dx", ",", "seg", ")", ")", ")", "\n", "\n", "out", "=", "x_s", "+", "dx", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SReNormResBlock.shortcut": [[841, 847], ["networks2d.SReNormResBlock.conv_s", "networks2d.SReNormResBlock.norm_s"], "methods", ["None"], ["", "def", "shortcut", "(", "self", ",", "x", ",", "seg", ")", ":", "\n", "        ", "if", "self", ".", "learned_shortcut", ":", "\n", "            ", "x_s", "=", "self", ".", "conv_s", "(", "self", ".", "norm_s", "(", "x", ",", "seg", ")", ")", "\n", "", "else", ":", "\n", "            ", "x_s", "=", "x", "\n", "", "return", "x_s", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SReNormResBlock.actvn": [[848, 850], ["torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu"], "methods", ["None"], ["", "def", "actvn", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "F", ".", "leaky_relu", "(", "x", ",", "2e-1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SharedSReNormResBlock.__init__": [[853, 862], ["networks2d.SReNormResBlock.__init__", "min", "norm_G.replace", "models.normalization.SharedSRenorm", "models.normalization.SharedSRenorm", "models.normalization.SharedSRenorm"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "fin", ",", "fout", ",", "norm_G", "=", "'spadeinstance3x3'", ",", "semantic_nc", "=", "4", ")", ":", "\n", "#super().__init__(fin, fout)", "\n", "        ", "SReNormResBlock", ".", "__init__", "(", "self", ",", "fin", ",", "fout", ",", "norm_G", "=", "'spadeinstance3x3'", ",", "semantic_nc", "=", "4", ")", "\n", "fmiddle", "=", "min", "(", "fin", ",", "fout", ")", "\n", "spade_config_str", "=", "norm_G", ".", "replace", "(", "'spectral'", ",", "''", ")", "\n", "self", ".", "norm_0", "=", "SharedSRenorm", "(", "spade_config_str", ",", "norm_nc", "=", "fin", ",", "label_nc", "=", "semantic_nc", ")", "\n", "self", ".", "norm_1", "=", "SharedSRenorm", "(", "spade_config_str", ",", "norm_nc", "=", "fmiddle", ",", "label_nc", "=", "semantic_nc", ")", "\n", "if", "self", ".", "learned_shortcut", ":", "\n", "            ", "self", ".", "norm_s", "=", "SharedSRenorm", "(", "spade_config_str", ",", "fin", ",", "semantic_nc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SharedSReNormResBlock.forward": [[863, 872], ["networks2d.SharedSReNormResBlock.shortcut", "networks2d.SharedSReNormResBlock.conv_0", "networks2d.SharedSReNormResBlock.conv_1", "networks2d.SharedSReNormResBlock.actvn", "networks2d.SharedSReNormResBlock.actvn", "networks2d.SharedSReNormResBlock.norm_0", "networks2d.SharedSReNormResBlock.norm_1"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SharedSReNormResBlock.shortcut", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SReNormResBlock.actvn", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SReNormResBlock.actvn"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "seg", ")", ":", "\n", "        ", "x_s", "=", "self", ".", "shortcut", "(", "x", ",", "seg", ")", "\n", "\n", "dx", "=", "self", ".", "conv_0", "(", "self", ".", "actvn", "(", "self", ".", "norm_0", "(", "x", ",", "seg", ")", ")", ")", "\n", "dx", "=", "self", ".", "conv_1", "(", "self", ".", "actvn", "(", "self", ".", "norm_1", "(", "dx", ",", "seg", ")", ")", ")", "\n", "\n", "out", "=", "x_s", "+", "dx", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.SharedSReNormResBlock.shortcut": [[873, 879], ["networks2d.SharedSReNormResBlock.conv_s", "networks2d.SharedSReNormResBlock.norm_s"], "methods", ["None"], ["", "def", "shortcut", "(", "self", ",", "x", ",", "seg", ")", ":", "\n", "        ", "if", "self", ".", "learned_shortcut", ":", "\n", "            ", "x_s", "=", "self", ".", "conv_s", "(", "self", ".", "norm_s", "(", "x", ",", "seg", ")", ")", "\n", "", "else", ":", "\n", "            ", "x_s", "=", "x", "\n", "", "return", "x_s", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.NLayerDiscriminator.__init__": [[885, 925], ["torch.Module.__init__", "range", "min", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.utils.spectral_norm", "torch.utils.spectral_norm", "torch.utils.spectral_norm", "torch.utils.spectral_norm", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "min", "torch.utils.spectral_norm", "torch.utils.spectral_norm", "torch.utils.spectral_norm", "torch.utils.spectral_norm", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.utils.spectral_norm", "torch.utils.spectral_norm", "torch.utils.spectral_norm", "torch.utils.spectral_norm", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "ndf", "=", "64", ",", "n_layers", "=", "3", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "\"\"\"Construct a PatchGAN discriminator\n\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            ndf (int)       -- the number of filters in the last conv layer\n            n_layers (int)  -- the number of conv layers in the discriminator\n            norm_layer      -- normalization layer\n        \"\"\"", "\n", "super", "(", "NLayerDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "# no need to use bias as BatchNorm2d has affine parameters", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "kw", "=", "4", "\n", "padw", "=", "1", "\n", "sequence", "=", "[", "nn", ".", "utils", ".", "spectral_norm", "(", "nn", ".", "Conv2d", "(", "input_nc", ",", "ndf", ",", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ")", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "]", "\n", "nf_mult", "=", "1", "\n", "nf_mult_prev", "=", "1", "\n", "for", "n", "in", "range", "(", "1", ",", "n_layers", ")", ":", "# gradually increase the number of filters", "\n", "            ", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "nn", ".", "utils", ".", "spectral_norm", "(", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ")", ",", "\n", "#norm_layer(ndf * nf_mult),", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n_layers", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "nn", ".", "utils", ".", "spectral_norm", "(", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ")", ",", "\n", "#norm_layer(ndf * nf_mult),", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "sequence", "+=", "[", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult", ",", "1", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ")", "]", "# output 1 channel prediction map", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.NLayerDiscriminator.forward": [[926, 931], ["networks2d.NLayerDiscriminator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward.\"\"\"", "\n", "#print(self.model)  #receptive field 16", "\n", "#print(self.model(input).size())", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.ResMultitaskAutoEncoder.__init__": [[935, 948], ["torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Module.__init__", "networks2d.ResnetGenerator", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_nc", ",", "numclass", ",", "n_blocks", "=", "6", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ",", "activate", "=", "nn", ".", "Tanh", "(", ")", ")", ":", "\n", "        ", "super", "(", "ResMultitaskAutoEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "net", "=", "ResnetGenerator", "(", "input_nc", ",", "input_nc", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "n_blocks", "=", "n_blocks", ",", "activate", "=", "activate", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "2", ",", "2", ")", ")", "\n", "\n", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "256", "*", "2", "*", "2", ",", "1024", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "1024", ",", "1024", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "1024", ",", "numclass", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.ResMultitaskAutoEncoder.forward": [[950, 957], ["networks2d.ResMultitaskAutoEncoder.net", "networks2d.ResMultitaskAutoEncoder.avgpool", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "networks2d.ResMultitaskAutoEncoder.classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "            ", "feature", ",", "rec", "=", "self", ".", "net", "(", "input", ")", "\n", "feat", "=", "self", ".", "avgpool", "(", "feature", ")", "\n", "pred", "=", "torch", ".", "flatten", "(", "feat", ",", "1", ")", "\n", "#print(feat.size())", "\n", "pred", "=", "self", ".", "classifier", "(", "pred", ")", "\n", "return", "pred", ",", "feat", ",", "rec", "", "", "", ""]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.get_norm_layer": [[21, 37], ["functools.partial", "functools.partial", "NotImplementedError", "networks2d.Identity"], "function", ["None"], ["", "", "def", "get_norm_layer", "(", "norm_type", "=", "'instance'", ")", ":", "\n", "    ", "\"\"\"Return a normalization layer\n    Parameters:\n        norm_type (str) -- the name of the normalization layer: batch | instance | none\n    For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n    For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics.\n    \"\"\"", "\n", "if", "norm_type", "==", "'batch'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "BatchNorm2d", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "", "elif", "norm_type", "==", "'instance'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "InstanceNorm2d", ",", "affine", "=", "False", ",", "track_running_stats", "=", "False", ")", "\n", "", "elif", "norm_type", "==", "'none'", ":", "\n", "        ", "norm_layer", "=", "lambda", "x", ":", "Identity", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'normalization layer [%s] is not found'", "%", "norm_type", ")", "\n", "", "return", "norm_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.get_scheduler": [[39, 64], ["torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.ReduceLROnPlateau", "max", "float", "torch.optim.lr_scheduler.CosineAnnealingLR", "NotImplementedError"], "function", ["None"], ["", "def", "get_scheduler", "(", "optimizer", ",", "opt", ")", ":", "\n", "    ", "\"\"\"Return a learning rate scheduler\n    Parameters:\n        optimizer          -- the optimizer of the network\n        opt (option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\uff0e\u3000\n                              opt.lr_policy is the name of learning rate policy: linear | step | plateau | cosine\n    For 'linear', we keep the same learning rate for the first <opt.niter> epochs\n    and linearly decay the rate to zero over the next <opt.niter_decay> epochs.\n    For other schedulers (step, plateau, and cosine), we use the default PyTorch schedulers.\n    See https://pytorch.org/docs/stable/optim.html for more details.\n    \"\"\"", "\n", "if", "opt", ".", "lr_policy", "==", "'linear'", ":", "\n", "        ", "def", "lambda_rule", "(", "epoch", ")", ":", "\n", "            ", "lr_l", "=", "1.0", "-", "max", "(", "0", ",", "epoch", "+", "opt", ".", "epoch_count", "-", "opt", ".", "niter", ")", "/", "float", "(", "opt", ".", "niter_decay", "+", "1", ")", "\n", "return", "lr_l", "\n", "", "scheduler", "=", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lambda_rule", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'step'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "step_size", "=", "opt", ".", "lr_decay_iters", ",", "gamma", "=", "0.1", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'plateau'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "factor", "=", "0.2", ",", "threshold", "=", "0.01", ",", "patience", "=", "5", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'cosine'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "CosineAnnealingLR", "(", "optimizer", ",", "T_max", "=", "opt", ".", "niter", ",", "eta_min", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "return", "NotImplementedError", "(", "'learning rate policy [%s] is not implemented'", ",", "opt", ".", "lr_policy", ")", "\n", "", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.init_weights": [[66, 96], ["print", "net.apply", "hasattr", "torch.nn.init.normal_", "hasattr", "torch.nn.init.constant_", "classname.find", "torch.nn.init.normal_", "torch.nn.init.constant_", "classname.find", "classname.find", "torch.nn.init.xavier_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.orthogonal_", "NotImplementedError"], "function", ["None"], ["", "def", "init_weights", "(", "net", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ")", ":", "\n", "    ", "\"\"\"Initialize network weights.\n    Parameters:\n        net (network)   -- network to be initialized\n        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n    work better for some applications. Feel free to try yourself.\n    \"\"\"", "\n", "def", "init_func", "(", "m", ")", ":", "# define the initialization function", "\n", "        ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "(", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", "or", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ")", ":", "\n", "            ", "if", "init_type", "==", "'normal'", ":", "\n", "                ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "0.0", ",", "init_gain", ")", "\n", "", "elif", "init_type", "==", "'xavier'", ":", "\n", "                ", "init", ".", "xavier_normal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "init_gain", ")", "\n", "", "elif", "init_type", "==", "'kaiming'", ":", "\n", "                ", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ".", "data", ",", "a", "=", "0", ",", "mode", "=", "'fan_in'", ")", "\n", "", "elif", "init_type", "==", "'orthogonal'", ":", "\n", "                ", "init", ".", "orthogonal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "init_gain", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'initialization method [%s] is not implemented'", "%", "init_type", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'BatchNorm2d'", ")", "!=", "-", "1", ":", "# BatchNorm Layer's weight is not a matrix; only normal distribution applies.", "\n", "            ", "init", ".", "normal_", "(", "m", ".", "weight", ",", "1.0", ",", "init_gain", ")", "\n", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.0", ")", "\n", "\n", "", "", "print", "(", "'initialize network with %s'", "%", "init_type", ")", "\n", "net", ".", "apply", "(", "init_func", ")", "# apply the initialization function <init_func>", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.init_net": [[98, 113], ["networks2d.init_weights", "len", "net.cuda"], "function", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.init_weights"], ["", "def", "init_net", "(", "net", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n    Parameters:\n        net (network)      -- the network to be initialized\n        init_type (str)    -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n        gain (float)       -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n    Return an initialized network.\n    \"\"\"", "\n", "if", "len", "(", "gpu_ids", ")", ">", "0", ":", "\n", "#assert(torch.cuda.is_available())", "\n", "        ", "net", ".", "cuda", "(", ")", "#to(gpu_ids[0])", "\n", "#net = torch.nn.DataParallel(net, gpu_ids)  # multi-GPUs", "\n", "", "init_weights", "(", "net", ",", "init_type", ",", "init_gain", "=", "init_gain", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.define_G": [[115, 157], ["networks2d.get_norm_layer", "networks2d.init_net", "networks2d.UnetGenerator", "networks2d.UnetGenerator", "networks2d.SRenormGenerator", "networks2d.UnetGenerator", "networks2d.UnetGenerator", "networks2d.UnetGenerator", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.get_norm_layer", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.init_net"], ["", "def", "define_G", "(", "input_nc", ",", "output_nc", ",", "ngf", "=", "64", ",", "netG", "=", "'resunet'", ",", "norm", "=", "'batch'", ",", "use_dropout", "=", "False", ",", "init_type", "=", "'normal'", ",", "\n", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ",", "return_feature", "=", "False", ",", "srenorm", "=", "False", ",", "is_seg", "=", "False", ",", "seg_nc", "=", "4", ")", ":", "\n", "    ", "\"\"\"Create a generator\n    Parameters:\n        input_nc (int) -- the number of channels in input images\n        output_nc (int) -- the number of channels in output images\n        ngf (int) -- the number of filters in the last conv layer\n        netG (str) -- the architecture's name: resnet_9blocks | resnet_6blocks | unet_256 | unet_128\n        norm (str) -- the name of normalization layers used in the network: batch | instance | none\n        use_dropout (bool) -- if use dropout layers.\n        init_type (str)    -- the name of our initialization method.\n        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n    Returns a generator\n    Our current implementation provides two types of generators:\n        U-Net: [unet_128] (for 128x128 input images) and [unet_256] (for 256x256 input images)\n        The original U-Net paper: https://arxiv.org/abs/1505.04597\n        Resnet-based generator: [resnet_6blocks] (with 6 Resnet blocks) and [resnet_9blocks] (with 9 Resnet blocks)\n        Resnet-based generator consists of several Resnet blocks between a few downsampling/upsampling operations.\n        We adapt Torch code from Justin Johnson's neural style transfer project (https://github.com/jcjohnson/fast-neural-style).\n    The generator has been initialized by <init_net>. It uses RELU for non-linearity.\n    \"\"\"", "\n", "net", "=", "None", "\n", "norm_layer", "=", "get_norm_layer", "(", "norm_type", "=", "norm", ")", "\n", "if", "netG", "==", "'unet_up'", ":", "\n", "        ", "net", "=", "UnetGenerator", "(", "input_nc", ",", "output_nc", ",", "7", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "upsample", "=", "True", ")", "\n", "", "elif", "netG", "==", "'unet'", ":", "\n", "        ", "net", "=", "UnetGenerator", "(", "input_nc", ",", "output_nc", ",", "7", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "upsample", "=", "False", ")", "\n", "", "elif", "netG", "==", "'resunet'", ":", "\n", "        ", "if", "srenorm", ":", "\n", "            ", "net", "=", "SRenormGenerator", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "label_nc", "=", "seg_nc", ")", "\n", "", "else", ":", "\n", "            ", "net", "=", "UnetGenerator", "(", "input_nc", ",", "output_nc", ",", "7", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "\n", "use_dropout", "=", "use_dropout", ",", "upsample", "=", "False", ",", "res", "=", "True", ",", "is_seg", "=", "is_seg", ")", "\n", "", "", "elif", "netG", "==", "'resunet_seg'", ":", "\n", "        ", "net", "=", "UnetGenerator", "(", "input_nc", ",", "output_nc", ",", "7", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "\n", "use_dropout", "=", "use_dropout", ",", "upsample", "=", "False", ",", "res", "=", "True", ",", "is_seg", "=", "True", ")", "\n", "", "elif", "netG", "==", "'resunet_up'", ":", "\n", "        ", "net", "=", "UnetGenerator", "(", "input_nc", ",", "output_nc", ",", "7", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "upsample", "=", "True", ",", "res", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Generator model name [%s] is not recognized'", "%", "netG", ")", "\n", "", "return", "init_net", "(", "net", ",", "init_type", ",", "init_gain", ",", "gpu_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.define_D": [[158, 192], ["networks2d.get_norm_layer", "networks2d.init_net", "networks2d.NLayerDiscriminator", "networks2d.NLayerDiscriminator", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.get_norm_layer", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.init_net"], ["", "def", "define_D", "(", "input_nc", ",", "ndf", ",", "netD", "=", "'n_layers'", ",", "n_layer", "=", "3", ",", "norm", "=", "'batch'", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Create a discriminator\n    Parameters:\n        input_nc (int)     -- the number of channels in input images\n        ndf (int)          -- the number of filters in the first conv layer\n        netD (str)         -- the architecture's name: basic | n_layers | pixel\n        n_layers_D (int)   -- the number of conv layers in the discriminator; effective when netD=='n_layers'\n        norm (str)         -- the type of normalization layers used in the network.\n        init_type (str)    -- the name of the initialization method.\n        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n    Returns a discriminator\n    Our current implementation provides three types of discriminators:\n        [basic]: 'PatchGAN' classifier described in the original pix2pix paper.\n        It can classify whether 70\u00d770 overlapping patches are real or fake.\n        Such a patch-level discriminator architecture has fewer parameters\n        than a full-image discriminator and can work on arbitrarily-sized images\n        in a fully convolutional fashion.\n        [n_layers]: With this mode, you cna specify the number of conv layers in the discriminator\n        with the parameter <n_layers_D> (default=3 as used in [basic] (PatchGAN).)\n        [pixel]: 1x1 PixelGAN discriminator can classify whether a pixel is real or not.\n        It encourages greater color diversity but has no effect on spatial statistics.\n    The discriminator has been initialized by <init_net>. It uses Leakly RELU for non-linearity.\n    \"\"\"", "\n", "net", "=", "None", "\n", "norm_layer", "=", "get_norm_layer", "(", "norm_type", "=", "norm", ")", "\n", "\n", "if", "netD", "==", "'basic'", ":", "# default PatchGAN classifier", "\n", "        ", "net", "=", "NLayerDiscriminator", "(", "input_nc", ",", "ndf", ",", "n_layers", "=", "3", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "elif", "netD", "==", "'n_layers'", ":", "# more options", "\n", "        ", "net", "=", "NLayerDiscriminator", "(", "input_nc", ",", "ndf", ",", "n_layer", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Discriminator model name [%s] is not recognized'", "%", "netD", ")", "\n", "", "return", "init_net", "(", "net", ",", "init_type", ",", "init_gain", ",", "gpu_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.symmetric_cross_entropy": [[198, 206], ["torch.softmax", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.sum().mean", "torch.sum().mean", "torch.sum().mean", "torch.sum().mean", "torch.sum().mean", "torch.sum().mean", "torch.sum().mean", "torch.sum().mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "function", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.softmax"], ["", "def", "symmetric_cross_entropy", "(", "pred", ",", "label", ",", "alpha", ",", "beta", ")", ":", "\n", "    ", "pred", "=", "F", ".", "softmax", "(", "pred", ",", "dim", "=", "1", ")", "\n", "pred", "=", "torch", ".", "clamp", "(", "pred", ",", "1e-7", ",", "1.0", ")", "\n", "label", "=", "torch", ".", "clamp", "(", "label", ",", "1e-4", ",", "1.0", ")", "\n", "ce_loss", "=", "-", "1", "*", "torch", ".", "sum", "(", "label", "*", "torch", ".", "log", "(", "pred", ")", ",", "dim", "=", "1", ")", ".", "mean", "(", ")", "\n", "rce_loss", "=", "-", "1", "*", "torch", ".", "sum", "(", "pred", "*", "torch", ".", "log", "(", "label", ")", ",", "dim", "=", "1", ")", ".", "mean", "(", ")", "\n", "\n", "return", "alpha", "*", "ce_loss", "+", "beta", "*", "rce_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.cross_entropy": [[208, 213], ["torch.softmax", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.sum().mean", "torch.sum().mean", "torch.sum().mean", "torch.sum().mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.log", "torch.log", "torch.log", "torch.log"], "function", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.softmax"], ["", "def", "cross_entropy", "(", "pred", ",", "label", ")", ":", "\n", "    ", "pred", "=", "F", ".", "softmax", "(", "pred", ",", "dim", "=", "1", ")", "\n", "pred", "=", "torch", ".", "clamp", "(", "pred", ",", "1e-7", ",", "1.0", ")", "\n", "label", "=", "torch", ".", "clamp", "(", "label", ",", "1e-4", ",", "1.0", ")", "\n", "return", "-", "1", "*", "torch", ".", "sum", "(", "label", "*", "torch", ".", "log", "(", "pred", ")", ",", "dim", "=", "1", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.softmax": [[215, 219], ["numpy.exp", "np.exp.sum", "numpy.max"], "function", ["None"], ["", "def", "softmax", "(", "x", ")", ":", "\n", "    ", "\"\"\"Compute softmax values for each sets of scores in x.\"\"\"", "\n", "e_x", "=", "np", ".", "exp", "(", "x", "-", "np", ".", "max", "(", "x", ")", ")", "\n", "return", "e_x", "/", "e_x", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.cal_gradient_penalty": [[406, 439], ["interpolatesv.requires_grad_", "netD", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "gradients[].view", "real_data.size", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "alpha.expand().contiguous().view.expand().contiguous().view", "NotImplementedError", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "alpha.expand().contiguous().view.expand().contiguous", "netD.size", "alpha.expand().contiguous().view.expand", "real_data.nelement"], "function", ["None"], ["", "", "def", "cal_gradient_penalty", "(", "netD", ",", "real_data", ",", "fake_data", ",", "device", ",", "type", "=", "'mixed'", ",", "constant", "=", "1.0", ",", "lambda_gp", "=", "10.0", ")", ":", "\n", "    ", "\"\"\"Calculate the gradient penalty loss, used in WGAN-GP paper https://arxiv.org/abs/1704.00028\n    Arguments:\n        netD (network)              -- discriminator network\n        real_data (tensor array)    -- real images\n        fake_data (tensor array)    -- generated images from the generator\n        device (str)                -- GPU / CPU: from torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')\n        type (str)                  -- if we mix real and fake data or not [real | fake | mixed].\n        constant (float)            -- the constant used in formula ( | |gradient||_2 - constant)^2\n        lambda_gp (float)           -- weight for this loss\n    Returns the gradient penalty loss\n    \"\"\"", "\n", "if", "lambda_gp", ">", "0.0", ":", "\n", "        ", "if", "type", "==", "'real'", ":", "# either use real images, fake images, or a linear interpolation of two.", "\n", "            ", "interpolatesv", "=", "real_data", "\n", "", "elif", "type", "==", "'fake'", ":", "\n", "            ", "interpolatesv", "=", "fake_data", "\n", "", "elif", "type", "==", "'mixed'", ":", "\n", "            ", "alpha", "=", "torch", ".", "rand", "(", "real_data", ".", "shape", "[", "0", "]", ",", "1", ",", "device", "=", "device", ")", "\n", "alpha", "=", "alpha", ".", "expand", "(", "real_data", ".", "shape", "[", "0", "]", ",", "real_data", ".", "nelement", "(", ")", "//", "real_data", ".", "shape", "[", "0", "]", ")", ".", "contiguous", "(", ")", ".", "view", "(", "*", "real_data", ".", "shape", ")", "\n", "interpolatesv", "=", "alpha", "*", "real_data", "+", "(", "(", "1", "-", "alpha", ")", "*", "fake_data", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'{} not implemented'", ".", "format", "(", "type", ")", ")", "\n", "", "interpolatesv", ".", "requires_grad_", "(", "True", ")", "\n", "disc_interpolates", "=", "netD", "(", "interpolatesv", ")", "\n", "gradients", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "disc_interpolates", ",", "inputs", "=", "interpolatesv", ",", "\n", "grad_outputs", "=", "torch", ".", "ones", "(", "disc_interpolates", ".", "size", "(", ")", ")", ".", "to", "(", "device", ")", ",", "\n", "create_graph", "=", "True", ",", "retain_graph", "=", "True", ",", "only_inputs", "=", "True", ")", "\n", "gradients", "=", "gradients", "[", "0", "]", ".", "view", "(", "real_data", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# flat the data", "\n", "gradient_penalty", "=", "(", "(", "(", "gradients", "+", "1e-16", ")", ".", "norm", "(", "2", ",", "dim", "=", "1", ")", "-", "constant", ")", "**", "2", ")", ".", "mean", "(", ")", "*", "lambda_gp", "# added eps", "\n", "return", "gradient_penalty", ",", "gradients", "\n", "", "else", ":", "\n", "        ", "return", "0.0", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.__init__": [[18, 43], ["os.path.join", "torch.device", "torch.device"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the BaseModel class.\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n        When creating your custom class, you need to implement your own initialization.\n        In this fucntion, you should first call <BaseModel.__init__(self, opt)>\n        Then, you need to define four lists:\n            -- self.loss_names (str list):          specify the training losses that you want to plot and save.\n            -- self.model_names (str list):         specify the images that you want to display and save.\n            -- self.visual_names (str list):        define networks used in our training.\n            -- self.optimizers (optimizer list):    define and initialize optimizers. You can define one optimizer for each network. If two networks are updated at the same time, you can use itertools.chain to group them. See cycle_gan_model.py for an example.\n        \"\"\"", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "gpu_ids", "=", "opt", ".", "gpu_ids", "\n", "self", ".", "isTrain", "=", "opt", ".", "isTrain", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:{}'", ".", "format", "(", "self", ".", "gpu_ids", "[", "0", "]", ")", ")", "if", "self", ".", "gpu_ids", "else", "torch", ".", "device", "(", "'cpu'", ")", "# get device name: CPU or GPU", "\n", "self", ".", "save_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "# save all the checkpoints to save_dir", "\n", "if", "opt", ".", "preprocess", "!=", "'scale_width'", ":", "# with [scale_width], input images might have different sizes, which hurts the performance of cudnn.benchmark.", "\n", "            ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "", "self", ".", "loss_names", "=", "[", "]", "\n", "self", ".", "model_names", "=", "[", "]", "\n", "self", ".", "visual_names", "=", "[", "]", "\n", "self", ".", "optimizers", "=", "[", "]", "\n", "self", ".", "image_paths", "=", "[", "]", "\n", "self", ".", "metric", "=", "0", "# used for learning rate policy 'plateau'", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.modify_commandline_options": [[44, 54], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"Add new model-specific configs, and rewrite default values for existing configs.\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific configs.\n        Returns:\n            the modified parser.\n        \"\"\"", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.set_input": [[55, 62], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n        Parameters:\n            input (dict): includes the data itself and its metadata information.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.forward": [[63, 67], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "forward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.optimize_parameters": [[68, 72], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "optimize_parameters", "(", "self", ",", "steps", ")", ":", "\n", "        ", "\"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.setup": [[73, 85], ["base_model.BaseModel.print_networks", "print", "base_model.BaseModel.load_networks", "networks2d.get_scheduler"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.print_networks", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.load_networks", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.networks2d.get_scheduler"], ["", "def", "setup", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Load and print networks; create schedulers\n        Parameters:\n            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "schedulers", "=", "[", "networks2d", ".", "get_scheduler", "(", "optimizer", ",", "opt", ")", "for", "optimizer", "in", "self", ".", "optimizers", "]", "\n", "", "if", "not", "self", ".", "isTrain", "or", "opt", ".", "continue_train", ":", "\n", "#load_suffix = 'epoch_%d' % opt.load_epoch", "\n", "            ", "print", "(", "'Continue training from epoch: %s'", "%", "(", "opt", ".", "load_epoch", ")", ")", "\n", "self", ".", "load_networks", "(", "opt", ".", "load_epoch", ",", "opt", ".", "load_step", ")", "\n", "", "self", ".", "print_networks", "(", "opt", ".", "verbose", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.eval": [[86, 92], ["isinstance", "getattr", "getattr.eval"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.eval"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make models eval mode during test time\"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "net", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.train": [[93, 99], ["isinstance", "getattr", "getattr.train"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.train"], ["", "", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make models eval mode during test time\"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "net", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.test": [[100, 108], ["torch.no_grad", "base_model.BaseModel.forward", "base_model.BaseModel.compute_visuals"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.forward", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.compute_visuals"], ["", "", "", "def", "test", "(", "self", ")", ":", "\n", "        ", "\"\"\"Forward function used in test time.\n        This function wraps <forward> function in no_grad() so we don't save intermediate steps for backprop\n        It also calls <compute_visuals> to produce additional visualization.py results\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "forward", "(", ")", "\n", "self", ".", "compute_visuals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.compute_visuals": [[109, 112], ["None"], "methods", ["None"], ["", "", "def", "compute_visuals", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate additional output images for visdom and HTML visualization.py\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.get_image_paths": [[113, 116], ["None"], "methods", ["None"], ["", "def", "get_image_paths", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return image paths that are used to load current data\"\"\"", "\n", "return", "self", ".", "image_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.update_learning_rate": [[117, 127], ["print", "scheduler.step", "scheduler.step"], "methods", ["None"], ["", "def", "update_learning_rate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Update learning rates for all the networks; called at the end of every epoch\"\"\"", "\n", "for", "scheduler", "in", "self", ".", "schedulers", ":", "\n", "            ", "if", "self", ".", "opt", ".", "lr_policy", "==", "'plateau'", ":", "\n", "                ", "scheduler", ".", "step", "(", "self", ".", "metric", ")", "\n", "", "else", ":", "\n", "                ", "scheduler", ".", "step", "(", ")", "\n", "\n", "", "", "lr", "=", "self", ".", "optimizers", "[", "0", "]", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "print", "(", "'learning rate = %.7f'", "%", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.get_current_visuals": [[128, 135], ["collections.OrderedDict", "isinstance", "getattr"], "methods", ["None"], ["", "def", "get_current_visuals", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return visualization.py images. train.py will display these images with visdom, and save the images to a HTML\"\"\"", "\n", "visual_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "visual_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "visual_ret", "[", "name", "]", "=", "getattr", "(", "self", ",", "name", ")", "\n", "", "", "return", "visual_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.get_current_losses": [[136, 143], ["collections.OrderedDict", "isinstance", "float", "getattr"], "methods", ["None"], ["", "def", "get_current_losses", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return traning losses / errors. train.py will print out these errors on console, and save them to a file\"\"\"", "\n", "errors_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "loss_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "errors_ret", "[", "name", "]", "=", "float", "(", "getattr", "(", "self", ",", "'loss_'", "+", "name", ")", ")", "# float(...) works for both scalar tensor and float number", "\n", "", "", "return", "errors_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.save_networks": [[144, 160], ["isinstance", "os.path.join", "getattr", "torch.cuda.is_available", "torch.save", "getattr.cuda", "torch.save", "len", "getattr.cpu().state_dict", "getattr.cpu().state_dict", "getattr.cpu", "getattr.cpu"], "methods", ["None"], ["", "def", "save_networks", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Save all the networks to the disk.\n        Parameters:\n            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n        \"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "save_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch", ",", "name", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "save_filename", ")", "\n", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "\n", "if", "len", "(", "self", ".", "gpu_ids", ")", ">", "0", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "torch", ".", "save", "(", "net", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "net", ".", "cuda", "(", "self", ".", "gpu_ids", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "save", "(", "net", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.__patch_instance_norm_state_dict": [[161, 174], ["len", "base_model.BaseModel.__patch_instance_norm_state_dict", "module.__class__.__name__.startswith", "module.__class__.__name__.startswith", "state_dict.pop", "getattr", "getattr", "state_dict.pop"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.__patch_instance_norm_state_dict"], ["", "", "", "", "def", "__patch_instance_norm_state_dict", "(", "self", ",", "state_dict", ",", "module", ",", "keys", ",", "i", "=", "0", ")", ":", "\n", "        ", "\"\"\"Fix InstanceNorm checkpoints incompatibility (prior to 0.4)\"\"\"", "\n", "key", "=", "keys", "[", "i", "]", "\n", "if", "i", "+", "1", "==", "len", "(", "keys", ")", ":", "# at the end, pointing to a parameter/buffer", "\n", "            ", "if", "module", ".", "__class__", ".", "__name__", ".", "startswith", "(", "'InstanceNorm'", ")", "and", "(", "key", "==", "'running_mean'", "or", "key", "==", "'running_var'", ")", ":", "\n", "                ", "if", "getattr", "(", "module", ",", "key", ")", "is", "None", ":", "\n", "                    ", "state_dict", ".", "pop", "(", "'.'", ".", "join", "(", "keys", ")", ")", "\n", "", "", "if", "module", ".", "__class__", ".", "__name__", ".", "startswith", "(", "'InstanceNorm'", ")", "and", "(", "key", "==", "'num_batches_tracked'", ")", ":", "\n", "                ", "state_dict", ".", "pop", "(", "'.'", ".", "join", "(", "keys", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "__patch_instance_norm_state_dict", "(", "state_dict", ",", "getattr", "(", "module", ",", "key", ")", ",", "keys", ",", "i", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.load_networks": [[175, 205], ["isinstance", "os.path.join", "getattr", "isinstance", "print", "torch.load", "hasattr", "list", "getattr.load_state_dict", "torch.load.keys", "base_model.BaseModel.__patch_instance_norm_state_dict", "str", "key.split"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.__patch_instance_norm_state_dict"], ["", "", "def", "load_networks", "(", "self", ",", "epoch", ",", "step", "=", "0", ",", "model_names", "=", "None", ")", ":", "\n", "        ", "\"\"\"Load all the networks from the disk.\n        Parameters:\n            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n            model_names (list) -- specify the models to load, otherwise load complete cycle gan\n        \"\"\"", "\n", "if", "model_names", "is", "None", ":", "model_names", "=", "self", ".", "model_names", "\n", "for", "name", "in", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "if", "step", "==", "-", "1", ":", "\n", "                    ", "load_filename", "=", "'latest_net_%s.pth'", "%", "(", "name", ")", "\n", "", "elif", "step", "==", "0", ":", "\n", "                    ", "load_filename", "=", "'epoch%s_net_%s.pth'", "%", "(", "name", ")", "\n", "", "else", ":", "\n", "                    ", "load_filename", "=", "'epoch%sstep%s_net_%s.pth'", "%", "(", "epoch", ",", "step", ",", "name", ")", "\n", "", "load_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "load_filename", ")", "\n", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "if", "isinstance", "(", "net", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "                    ", "net", "=", "net", ".", "module", "\n", "", "print", "(", "'loading the model from %s'", "%", "load_path", ")", "\n", "# if you are using PyTorch newer than 0.4 (e.g., built from", "\n", "# GitHub source), you can remove str() on self.device", "\n", "state_dict", "=", "torch", ".", "load", "(", "load_path", ",", "map_location", "=", "str", "(", "self", ".", "device", ")", ")", "\n", "if", "hasattr", "(", "state_dict", ",", "'_metadata'", ")", ":", "\n", "                    ", "del", "state_dict", ".", "_metadata", "\n", "\n", "# patch InstanceNorm checkpoints prior to 0.4", "\n", "", "for", "key", "in", "list", "(", "state_dict", ".", "keys", "(", ")", ")", ":", "# need to copy keys here because we mutate in loop", "\n", "                    ", "self", ".", "__patch_instance_norm_state_dict", "(", "state_dict", ",", "net", ",", "key", ".", "split", "(", "'.'", ")", ")", "\n", "", "net", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.print_networks": [[206, 222], ["print", "print", "isinstance", "getattr", "getattr.parameters", "print", "param.numel", "print"], "methods", ["None"], ["", "", "", "def", "print_networks", "(", "self", ",", "verbose", ")", ":", "\n", "        ", "\"\"\"Print the total number of parameters in the network and (if verbose) network architecture\n        Parameters:\n            verbose (bool) -- if verbose: print the network architecture\n        \"\"\"", "\n", "print", "(", "'---------- Networks initialized -------------'", ")", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "num_params", "=", "0", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "                    ", "num_params", "+=", "param", ".", "numel", "(", ")", "\n", "", "if", "verbose", ":", "\n", "                    ", "print", "(", "net", ")", "\n", "", "print", "(", "'[Network %s] Total number of parameters : %.3f M'", "%", "(", "name", ",", "num_params", "/", "1e6", ")", ")", "\n", "", "", "print", "(", "'-----------------------------------------------'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.models.base_model.BaseModel.set_requires_grad": [[223, 235], ["isinstance", "net.parameters"], "methods", ["None"], ["", "def", "set_requires_grad", "(", "self", ",", "nets", ",", "requires_grad", "=", "False", ")", ":", "\n", "        ", "\"\"\"Set requies_grad=Fasle for all the networks to avoid unnecessary computations\n        Parameters:\n            nets (network list)   -- a list of networks\n            requires_grad (bool)  -- whether the networks require gradients or not\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "nets", ",", "list", ")", ":", "\n", "            ", "nets", "=", "[", "nets", "]", "\n", "", "for", "net", "in", "nets", ":", "\n", "            ", "if", "net", "is", "not", "None", ":", "\n", "                ", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "requires_grad", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.data.augmentation.RandomCrop.__init__": [[15, 21], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "crop_size", "=", "128", ",", "pre_center", "=", "False", ",", "range", "=", "(", ")", ")", ":", "\n", "        ", "self", ".", "crop_size", "=", "crop_size", "\n", "self", ".", "max_trail", "=", "50", "\n", "self", ".", "pre_crop", "=", "pre_center", "\n", "if", "pre_center", ":", "\n", "            ", "self", ".", "xmin", ",", "self", ".", "xmax", ",", "self", ".", "ymin", ",", "self", ".", "ymax", "=", "range", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.data.augmentation.RandomCrop.__call__": [[22, 58], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "numpy.sum"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "image", ",", "masks", ")", ":", "\n", "        ", "if", "self", ".", "pre_crop", ":", "\n", "            ", "image", "=", "image", "[", "self", ".", "xmin", ":", "self", ".", "xmax", ",", "self", ".", "ymin", ":", "self", ".", "ymax", "]", "\n", "masks", "=", "masks", "[", "self", ".", "xmin", ":", "self", ".", "xmax", ",", "self", ".", "ymin", ":", "self", ".", "ymax", "]", "\n", "", "x", ",", "y", ",", "c", "=", "image", ".", "shape", "\n", "sx", ",", "sy", ",", "sc", "=", "masks", ".", "shape", "\n", "imgout", "=", "np", ".", "zeros", "(", "[", "self", ".", "crop_size", ",", "self", ".", "crop_size", ",", "c", "]", ")", "\n", "if", "image", ".", "shape", "==", "masks", ".", "shape", ":", "\n", "            ", "prob_seg", "=", "False", "\n", "maskout", "=", "np", ".", "zeros", "(", "[", "self", ".", "crop_size", ",", "self", ".", "crop_size", "]", ")", "\n", "", "else", ":", "\n", "            ", "prob_seg", "=", "True", "\n", "maskout", "=", "np", ".", "zeros", "(", "[", "self", ".", "crop_size", ",", "self", ".", "crop_size", ",", "sc", "]", ")", "\n", "", "rand_range_x", "=", "x", "-", "self", ".", "crop_size", "\n", "rand_range_y", "=", "y", "-", "self", ".", "crop_size", "\n", "if", "rand_range_x", "<=", "0", ":", "\n", "            ", "x_offset", "=", "0", "\n", "", "else", ":", "\n", "            ", "x_offset", "=", "np", ".", "random", ".", "randint", "(", "rand_range_x", ")", "#rand_range_x = 0", "\n", "", "if", "rand_range_y", "<=", "0", ":", "\n", "            ", "y_offset", "=", "0", "\n", "", "else", ":", "\n", "            ", "y_offset", "=", "np", ".", "random", ".", "randint", "(", "rand_range_y", ")", "\n", "", "tmp", "=", "image", "[", "x_offset", ":", "x_offset", "+", "self", ".", "crop_size", ",", "y_offset", ":", "y_offset", "+", "self", ".", "crop_size", "]", "\n", "i", "=", "0", "\n", "while", "np", ".", "sum", "(", "tmp", ")", "==", "0.", "and", "i", "<", "self", ".", "max_trail", "and", "rand_range_x", ">", "0", ":", "\n", "            ", "x_offset", "=", "np", ".", "random", ".", "randint", "(", "rand_range_x", ")", "\n", "y_offset", "=", "np", ".", "random", ".", "randint", "(", "rand_range_y", ")", "\n", "tmp", "=", "image", "[", "x_offset", ":", "x_offset", "+", "self", ".", "crop_size", ",", "y_offset", ":", "y_offset", "+", "self", ".", "crop_size", "]", "\n", "i", "+=", "1", "\n", "", "imgout", "[", ":", "x", ",", ":", "y", "]", "=", "tmp", "\n", "if", "prob_seg", ":", "\n", "            ", "maskout", "[", ":", "x", ",", ":", "y", "]", "=", "masks", "[", "x_offset", ":", "x_offset", "+", "self", ".", "crop_size", ",", "y_offset", ":", "y_offset", "+", "self", ".", "crop_size", ",", ":", "]", "\n", "", "else", ":", "\n", "            ", "maskout", "[", ":", "x", ",", ":", "y", "]", "=", "masks", "[", "x_offset", ":", "x_offset", "+", "self", ".", "crop_size", ",", "y_offset", ":", "y_offset", "+", "self", ".", "crop_size", ",", "0", "]", "\n", "", "return", "imgout", ",", "maskout", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.data.augmentation.Compose.__init__": [[71, 73], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.data.augmentation.Compose.__call__": [[74, 78], ["t"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ",", "labels", "=", "None", ")", ":", "\n", "        ", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "img", ",", "labels", "=", "t", "(", "img", ",", "labels", ")", "\n", "", "return", "img", ",", "labels", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.data.augmentation.one_hot": [[7, 12], ["numpy.zeros", "numpy.reshape", "np.reshape.transpose", "numpy.arange", "seg.ravel"], "function", ["None"], ["def", "one_hot", "(", "seg", ",", "ncols", "=", "4", ")", ":", "\n", "    ", "ss_oh", "=", "np", ".", "zeros", "(", "(", "seg", ".", "size", ",", "ncols", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "ss_oh", "[", "np", ".", "arange", "(", "seg", ".", "size", ")", ",", "seg", ".", "ravel", "(", ")", "]", "=", "1", "\n", "ss_oh", "=", "np", ".", "reshape", "(", "ss_oh", ",", "seg", ".", "shape", "+", "(", "ncols", ",", ")", ")", "\n", "return", "ss_oh", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.data.example_loader.h5loader.__init__": [[15, 23], ["data.augmentation.Compose", "data.augmentation.RandomCrop"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "is_train", ",", "src_key", ",", "trg_key", ",", "crop_size", ")", ":", "\n", "        ", "if", "is_train", "and", "augment", ":", "\n", "            ", "self", ".", "augment", "=", "Compose", "(", "[", "\n", "RandomCrop", "(", "self", ".", "crop_size", ")", "\n", "]", ")", "\n", "", "self", ".", "src_key", "=", "src_key", "\n", "self", ".", "trg_key", "=", "trg_key", "\n", "self", ".", "crop_size", "=", "crop_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.data.example_loader.h5loader.read_h5": [[24, 28], ["h5py.File"], "methods", ["None"], ["", "def", "read_h5", "(", "self", ",", "path", ")", ":", "\n", "        ", "with", "h5py", ".", "File", "(", "path", ",", "'r'", ")", "as", "hf", ":", "\n", "            ", "self", ".", "src_num", "=", "hf", "[", "src_key", "]", "[", "'img'", "]", ".", "shape", "[", "0", "]", "\n", "self", ".", "trg_num", "=", "hf", "[", "trg_key", "]", "[", "'img'", "]", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.data.example_loader.h5loader.__len__": [[29, 31], ["max"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "max", "(", "self", ".", "src_num", ",", "self", ".", "trg_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.data.example_loader.h5loader.__getitem__": [[32, 62], ["numpy.zeros().astype", "numpy.zeros().astype", "src_img.astype().transpose", "trg_img.astype().transpose", "src_seg.astype", "data.augmentation.one_hot", "trg_seg.astype", "data.augmentation.one_hot", "h5py.File", "numpy.random.randint", "numpy.zeros", "numpy.zeros", "src_img.astype", "trg_img.astype"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.data.augmentation.one_hot", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.data.augmentation.one_hot"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "with", "h5py", ".", "File", "(", "self", ".", "path", ",", "'r'", ")", "as", "hf", ":", "\n", "            ", "src_img", ",", "src_seg", "=", "hf", "[", "self", ".", "src_key", "]", "[", "'img'", "]", "[", "item", "]", ",", "hf", "[", "self", ".", "trg_key", "]", "[", "'seg'", "]", "[", "item", "]", "\n", "\n", "item", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "trg_num", ")", "\n", "trg_img", ",", "trg_seg", "=", "hf", "[", "self", ".", "trg_key", "]", "[", "'img'", "]", "[", "item", "]", ",", "hf", "[", "self", ".", "trg_key", "]", "[", "'seg'", "]", "[", "item", "]", "\n", "\n", "", "xs", "=", "np", ".", "zeros", "(", "(", "1", ",", "\n", "self", ".", "crop_size", ",", "\n", "self", ".", "crop_size", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "ys", "=", "np", ".", "zeros", "(", "(", "1", ",", "\n", "self", ".", "crop_size", ",", "\n", "self", ".", "crop_size", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "xs", "[", "0", ",", ":", ",", ":", "]", "=", "src_img", ".", "astype", "(", "np", ".", "float32", ")", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "ys", "[", "0", ",", ":", ",", ":", "]", "=", "trg_img", ".", "astype", "(", "np", ".", "float32", ")", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "\n", "dict", "=", "{", "}", "\n", "dict", "[", "'A'", "]", "=", "xs", "\n", "dict", "[", "'B'", "]", "=", "ys", "\n", "\n", "ss", "=", "src_seg", ".", "astype", "(", "np", ".", "uint8", ")", "# w, h", "\n", "# One hot encoding", "\n", "ss_oh", "=", "one_hot", "(", "ss", ")", "\n", "dict", "[", "'A_seg'", "]", "=", "ss_oh", "\n", "\n", "ss", "=", "trg_seg", ".", "astype", "(", "np", ".", "uint8", ")", "# w, h", "\n", "ss_oh", "=", "one_hot", "(", "ss", ")", "\n", "dict", "[", "'B_seg'", "]", "=", "ss_oh", "\n", "return", "dict", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.test_options.TestOptions.initialize": [[10, 30], ["base_options.BaseOptions.initialize", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.set_defaults", "base_options.BaseOptions.initialize.set_defaults", "float", "base_options.BaseOptions.initialize.get_default"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.initialize"], ["def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "parser", "=", "BaseOptions", ".", "initialize", "(", "self", ",", "parser", ")", "# define shared options", "\n", "parser", ".", "add_argument", "(", "'--ntest'", ",", "type", "=", "int", ",", "default", "=", "float", "(", "\"inf\"", ")", ",", "help", "=", "'# of test examples.'", ")", "\n", "parser", ".", "add_argument", "(", "'--results_dir'", ",", "type", "=", "str", ",", "default", "=", "'../results/'", ",", "help", "=", "'saves results here.'", ")", "\n", "parser", ".", "add_argument", "(", "'--aspect_ratio'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'aspect ratio of result images'", ")", "\n", "parser", ".", "add_argument", "(", "'--phase'", ",", "type", "=", "str", ",", "default", "=", "'test'", ",", "help", "=", "'train, val, test, etc'", ")", "\n", "# Dropout and Batchnorm has different behavioir during training and test.", "\n", "parser", ".", "add_argument", "(", "'--eval'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use eval mode during test time.'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_test'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'how many test images to run'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint_dir'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--is_target'", ",", "action", "=", "'store_true'", ",", "help", "=", "'test source or target'", ")", "\n", "parser", ".", "add_argument", "(", "'--is_result'", ",", "action", "=", "'store_true'", ",", "help", "=", "'test result'", ")", "\n", "\n", "\n", "# rewrite devalue values", "\n", "parser", ".", "set_defaults", "(", "model", "=", "'test'", ")", "\n", "# To avoid cropping, the load_size should be the same as crop_size", "\n", "parser", ".", "set_defaults", "(", "load_size", "=", "parser", ".", "get_default", "(", "'crop_size'", ")", ")", "\n", "self", ".", "isTrain", "=", "False", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.train_options.TrainOptions.initialize": [[10, 47], ["base_options.BaseOptions.initialize", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.initialize"], ["def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "parser", "=", "BaseOptions", ".", "initialize", "(", "self", ",", "parser", ")", "\n", "# visdom and HTML visualization.py parameters", "\n", "parser", ".", "add_argument", "(", "'--display_freq'", ",", "type", "=", "int", ",", "default", "=", "400", ",", "help", "=", "'frequency of showing training results on screen'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_ncols'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'if positive, display all images in a single visdom web panel with certain number of images per row.'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_id'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'window id of the web display'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_server'", ",", "type", "=", "str", ",", "default", "=", "\"http://localhost\"", ",", "help", "=", "'visdom server of the web display'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_env'", ",", "type", "=", "str", ",", "default", "=", "'main'", ",", "help", "=", "'visdom display environment name (default is \"main\")'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_port'", ",", "type", "=", "int", ",", "default", "=", "8097", ",", "help", "=", "'visdom port of the web display'", ")", "\n", "parser", ".", "add_argument", "(", "'--update_html_freq'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'frequency of saving training results to html'", ")", "\n", "parser", ".", "add_argument", "(", "'--print_freq'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'frequency of showing training results on console'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_html'", ",", "action", "=", "'store_true'", ",", "help", "=", "'do not save intermediate training results to [opt.checkpoints_dir]/[opt.name]/web/'", ")", "\n", "# network saving and loading parameters", "\n", "parser", ".", "add_argument", "(", "'--save_latest_freq'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'frequency of saving the latest results'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_epoch_freq'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'frequency of saving checkpoints at the end of epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_by_iter'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether saves model by iteration'", ")", "\n", "parser", ".", "add_argument", "(", "'--continue_train'", ",", "action", "=", "'store_true'", ",", "help", "=", "'continue training: load the latest model'", ")", "\n", "parser", ".", "add_argument", "(", "'--epoch_count'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'the starting epoch count, we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>, ...'", ")", "\n", "parser", ".", "add_argument", "(", "'--phase'", ",", "type", "=", "str", ",", "default", "=", "'train'", ",", "help", "=", "'train, val, test, etc'", ")", "\n", "# training parameters", "\n", "parser", ".", "add_argument", "(", "'--niter'", ",", "type", "=", "int", ",", "default", "=", "15", ",", "help", "=", "'# of iter at starting learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--niter_decay'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'# of iter to linearly decay learning rate to zero'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta1'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'momentum term of adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_g'", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "help", "=", "'initial learning rate for generator optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_d'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'initial learning rate for discriminator optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "'--gan_mode'", ",", "type", "=", "str", ",", "default", "=", "'lsgan'", ",", "help", "=", "'the type of GAN objective. [vanilla| lsgan | wgangp]. vanilla GAN loss is the cross-entropy objective used in the original GAN paper.'", ")", "\n", "parser", ".", "add_argument", "(", "'--pool_size'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'the size of image buffer that stores previously generated images'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_policy'", ",", "type", "=", "str", ",", "default", "=", "'linear'", ",", "help", "=", "'learning rate policy. [linear | step | plateau | cosine]'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_decay_iters'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'multiply by a gamma every lr_decay_iters iterations'", ")", "\n", "parser", ".", "add_argument", "(", "'--paired'", ",", "action", "=", "'store_true'", ",", "help", "=", "'using paired data or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--resize'", ",", "action", "=", "'store_true'", ",", "help", "=", "'resize input or not'", ")", "\n", "\n", "\n", "\n", "\n", "self", ".", "isTrain", "=", "True", "\n", "return", "parser", "", "", "", ""]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.__init__": [[16, 19], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset the class; indicates the class hasn't been initailized\"\"\"", "\n", "self", ".", "initialized", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.initialize": [[20, 94], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "float"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "\"\"\"Define the common configs that are used in both training and test.\"\"\"", "\n", "# basic parameters", "\n", "parser", ".", "add_argument", "(", "'--name'", ",", "type", "=", "str", ",", "default", "=", "'cyclegan'", ",", "\n", "help", "=", "'name of the experiment. It decides where to store samples and models'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_ids'", ",", "type", "=", "str", ",", "default", "=", "'0'", ",", "help", "=", "'gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoints_dir'", ",", "type", "=", "str", ",", "default", "=", "'../ckpts7'", ",", "help", "=", "'models are saved here'", ")", "\n", "# model parameters", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "'cycle_gan_3d'", ",", "\n", "help", "=", "'chooses which model to use. [cycle_gan_3d | cycle_gan_2d_slice | test ]'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_nc'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'# of input image channels: 3 for RGB and 1 for grayscale'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_nc'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'# of output image channels: 3 for RGB and 1 for grayscale'", ")", "\n", "parser", ".", "add_argument", "(", "'--f_map'", ",", "type", "=", "list", ",", "default", "=", "[", "16", ",", "32", ",", "64", ",", "128", "]", ",", "help", "=", "'# of gen filters in the last conv layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--ngf'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'# of gen filters in the last conv layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--ndf'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'# of discrim filters in the first conv layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--netD'", ",", "type", "=", "str", ",", "default", "=", "'basic'", ",", "\n", "help", "=", "'specify discriminator architecture [basic | n_layers | pixel]. The basic model is a 70x70 PatchGAN. n_layers allows you to specify the layers in the discriminator'", ")", "\n", "parser", ".", "add_argument", "(", "'--typeG'", ",", "type", "=", "str", ",", "default", "=", "'unet'", ",", "\n", "help", "=", "'specify generator architecture [unet | resunet ]'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_layers_D'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'only used if netD==n_layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--norm'", ",", "type", "=", "str", ",", "default", "=", "'instance'", ",", "\n", "help", "=", "'instance normalization or batch normalization [instance | batch | none]'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_type'", ",", "type", "=", "str", ",", "default", "=", "'normal'", ",", "\n", "help", "=", "'network initialization [normal | xavier | kaiming | orthogonal]'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_gain'", ",", "type", "=", "float", ",", "default", "=", "0.02", ",", "\n", "help", "=", "'scaling factor for normal, xavier and orthogonal.'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_dropout'", ",", "action", "=", "'store_true'", ",", "help", "=", "'no dropout for the generator'", ")", "\n", "# dataset parameters", "\n", "parser", ".", "add_argument", "(", "'--direction'", ",", "type", "=", "str", ",", "default", "=", "'AtoB'", ",", "help", "=", "'AtoB or BtoA'", ")", "\n", "parser", ".", "add_argument", "(", "'--serial_batches'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'if true, takes images in order to make batches, otherwise takes them randomly'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_threads'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "'# threads for loading data'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "'input batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--crop_size'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "'then crop to this size'", ")", "\n", "parser", ".", "add_argument", "(", "'--thickness'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'thickness when doing the cropping'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_dataset_size'", ",", "type", "=", "int", ",", "default", "=", "float", "(", "\"inf\"", ")", ",", "\n", "help", "=", "'Maximum number of samples allowed per dataset. If the dataset directory contains more than max_dataset_size, only a subset is loaded.'", ")", "\n", "parser", ".", "add_argument", "(", "'--preprocess'", ",", "type", "=", "str", ",", "default", "=", "'resize_and_crop'", ",", "\n", "help", "=", "'scaling and cropping of images at load time [resize_and_crop | crop | scale_width | scale_width_and_crop | none]'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_flip'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'if specified, do not flip the images for data augmentation'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_winsize'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "\n", "help", "=", "'display window size for both visdom and HTML'", ")", "\n", "# additional parameters", "\n", "parser", ".", "add_argument", "(", "'--epoch'", ",", "type", "=", "str", ",", "default", "=", "'latest'", ",", "\n", "help", "=", "'which epoch to load? set to latest to use latest cached model'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_iter'", ",", "type", "=", "int", ",", "default", "=", "'0'", ",", "\n", "help", "=", "'which iteration to load? if load_iter > 0, the code will load models by iter_[load_iter]; otherwise, the code will load models by [epoch]'", ")", "\n", "parser", ".", "add_argument", "(", "'--verbose'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, print more debugging information'", ")", "\n", "parser", ".", "add_argument", "(", "'--suffix'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "'customized suffix: opt.name = opt.name + suffix: e.g., {model}_{netG}_size{load_size}'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_A'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for cycle loss (A -> B -> A)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_B'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for cycle loss (B -> A -> B)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_identity'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "'use identity mapping. Setting lambda_identity other than 0 has an effect of scaling the weight of the identity mapping loss. For example, if the weight of the identity loss should be 10 times smaller than the weight of the reconstruction loss, please set lambda_identity = 0.1'", ")", "\n", "parser", ".", "add_argument", "(", "'--dim'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "'2|3'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "type", "=", "str", ",", "default", "=", "'adni'", ",", "help", "=", "'select a dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_cc'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'use correlation coefficient loss if larger than 0'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_tv'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'use total variance regularization if larger than 0'", ")", "\n", "parser", ".", "add_argument", "(", "'--fid'", ",", "action", "=", "'store_true'", ",", "help", "=", "'calculate frechet inception distance'", ")", "\n", "parser", ".", "add_argument", "(", "'--srenorm'", ",", "action", "=", "'store_true'", ",", "help", "=", "'using spatial adaptive denormalization'", ")", "\n", "parser", ".", "add_argument", "(", "'--joint_seg'", ",", "action", "=", "'store_true'", ",", "help", "=", "'learning segmentation instead of input segmentation map, and using spatial adaptive denormalization'", ")", "\n", "parser", ".", "add_argument", "(", "'--prob_seg'", ",", "action", "=", "'store_true'", ",", "help", "=", "'segmentation map is a probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_epoch'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'continue training: the epoch to continue from'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_step'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'continue training: the step to continue from'", ")", "\n", "parser", ".", "add_argument", "(", "'--sem_dropout'", ",", "action", "=", "'store_true'", ",", "help", "=", "'semantic dropout or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--seg_nc'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'number of semantic class'", ")", "\n", "parser", ".", "add_argument", "(", "'--fold'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "help", "=", "'fold id for LOOCV'", ")", "\n", "parser", ".", "add_argument", "(", "'--mask'", ",", "action", "=", "'store_true'", ",", "help", "=", "'add mask for brain'", ")", "\n", "\n", "self", ".", "initialized", "=", "True", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.gather_options": [[96, 112], ["base_options.BaseOptions.parse_known_args", "base_options.BaseOptions.parse_args", "argparse.ArgumentParser", "base_options.BaseOptions.initialize"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.initialize"], ["", "def", "gather_options", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize our parser with basic configs(only once).\n        Add additional model-specific and dataset-specific configs.\n        These configs are defined in the <modify_commandline_options> function\n        in model and dataset classes.\n        \"\"\"", "\n", "if", "not", "self", ".", "initialized", ":", "# check if it has been initialized", "\n", "            ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", "=", "self", ".", "initialize", "(", "parser", ")", "\n", "\n", "# get the basic configs", "\n", "", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "\n", "# save and return the parser", "\n", "self", ".", "parser", "=", "parser", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.print_options": [[113, 137], ["sorted", "print", "os.path.join", "utils.utilization.mkdirs", "os.path.join", "vars().items", "base_options.BaseOptions.parser.get_default", "open", "opt_file.write", "opt_file.write", "str", "str", "vars", "str"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.utils.utilization.mkdirs"], ["", "def", "print_options", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Print and save configs\n\n        It will print both current configs and default values(if different).\n        It will save configs into a text file / [checkpoints_dir] / opt.txt\n        \"\"\"", "\n", "message", "=", "''", "\n", "message", "+=", "'----------------- Options ---------------\\n'", "\n", "for", "k", ",", "v", "in", "sorted", "(", "vars", "(", "opt", ")", ".", "items", "(", ")", ")", ":", "\n", "            ", "comment", "=", "''", "\n", "default", "=", "self", ".", "parser", ".", "get_default", "(", "k", ")", "\n", "if", "v", "!=", "default", ":", "\n", "                ", "comment", "=", "'\\t[default: %s]'", "%", "str", "(", "default", ")", "\n", "", "message", "+=", "'{:>25}: {:<30}{}\\n'", ".", "format", "(", "str", "(", "k", ")", ",", "str", "(", "v", ")", ",", "comment", ")", "\n", "", "message", "+=", "'----------------- End -------------------'", "\n", "print", "(", "message", ")", "\n", "\n", "# save to the disk", "\n", "expr_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "\n", "mkdirs", "(", "expr_dir", ")", "\n", "file_name", "=", "os", ".", "path", ".", "join", "(", "expr_dir", ",", "'{}_opt.txt'", ".", "format", "(", "opt", ".", "phase", ")", ")", "\n", "with", "open", "(", "file_name", ",", "'wt'", ")", "as", "opt_file", ":", "\n", "            ", "opt_file", ".", "write", "(", "message", ")", "\n", "opt_file", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.parse": [[138, 163], ["base_options.BaseOptions.gather_options", "base_options.BaseOptions.print_options", "base_options.BaseOptions.gpu_ids.split", "int", "len", "torch.cuda.set_device", "base_options.BaseOptions.gpu_ids.append", "base_options.BaseOptions.suffix.format", "vars"], "methods", ["home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.gather_options", "home.repos.pwc.inspect_result.mengweiren_segmentation-renormalized-harmonization.configs.base_options.BaseOptions.print_options"], ["", "", "def", "parse", "(", "self", ")", ":", "\n", "        ", "\"\"\"Parse our configs, create checkpoints directory suffix, and set up gpu device.\"\"\"", "\n", "opt", "=", "self", ".", "gather_options", "(", ")", "\n", "opt", ".", "isTrain", "=", "self", ".", "isTrain", "# train or test", "\n", "\n", "# process opt.suffix", "\n", "if", "opt", ".", "suffix", ":", "\n", "            ", "suffix", "=", "(", "'_'", "+", "opt", ".", "suffix", ".", "format", "(", "**", "vars", "(", "opt", ")", ")", ")", "if", "opt", ".", "suffix", "!=", "''", "else", "''", "\n", "opt", ".", "name", "=", "opt", ".", "name", "+", "suffix", "\n", "\n", "", "opt", ".", "f_map", "=", "[", "opt", ".", "crop_size", ",", "opt", ".", "crop_size", "*", "2", ",", "opt", ".", "crop_size", "*", "4", ",", "opt", ".", "crop_size", "*", "8", "]", "\n", "self", ".", "print_options", "(", "opt", ")", "\n", "\n", "# set gpu ids", "\n", "str_ids", "=", "opt", ".", "gpu_ids", ".", "split", "(", "','", ")", "\n", "opt", ".", "gpu_ids", "=", "[", "]", "\n", "for", "str_id", "in", "str_ids", ":", "\n", "            ", "id", "=", "int", "(", "str_id", ")", "\n", "if", "id", ">=", "0", ":", "\n", "                ", "opt", ".", "gpu_ids", ".", "append", "(", "id", ")", "\n", "", "", "if", "len", "(", "opt", ".", "gpu_ids", ")", ">", "0", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu_ids", "[", "0", "]", ")", "\n", "\n", "", "self", ".", "opt", "=", "opt", "\n", "return", "self", ".", "opt", "", "", "", ""]]}