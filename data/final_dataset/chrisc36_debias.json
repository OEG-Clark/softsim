{"home.repos.pwc.inspect_result.chrisc36_debias.debias.download_all.download_squad": [[7, 15], ["debias.datasets.squad.load_bias", "debias.datasets.squad.load_annotated_squad", "debias.datasets.squad.load_squad_documents"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_bias", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.load_annotated_squad", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.load_squad_documents"], ["def", "download_squad", "(", ")", ":", "\n", "  ", "squad", ".", "load_bias", "(", "\"train\"", ")", "\n", "\n", "for", "dataset", "in", "[", "\"train\"", ",", "\"dev\"", ",", "\"add_sent\"", ",", "\"add_one_sent\"", "]", ":", "\n", "    ", "squad", ".", "load_annotated_squad", "(", "dataset", ")", "\n", "\n", "", "for", "dataset", "in", "[", "\"dev\"", ",", "\"add_sent\"", ",", "\"add_one_sent\"", "]", ":", "\n", "    ", "squad", ".", "load_squad_documents", "(", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.debias.download_all.download_triviaqa_cp": [[17, 24], ["debias.datasets.triviaqa_cp.load_bias", "debias.datasets.triviaqa_cp.load_triviaqa_cp", "debias.datasets.triviaqa_cp.load_annotated_triviaqa"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_bias", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_loader.load_triviaqa_cp", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.triviaqa_cp.load_annotated_triviaqa"], ["", "", "def", "download_triviaqa_cp", "(", ")", ":", "\n", "  ", "for", "dataset", "in", "[", "\"location\"", ",", "\"person\"", "]", ":", "\n", "    ", "triviaqa_cp", ".", "load_bias", "(", "dataset", ")", "\n", "triviaqa_cp", ".", "load_triviaqa_cp", "(", "dataset", ",", "\"test\"", ")", "\n", "\n", "", "for", "is_train", "in", "[", "True", ",", "False", "]", ":", "\n", "    ", "triviaqa_cp", ".", "load_annotated_triviaqa", "(", "is_train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.debias.download_all.download_mnli": [[26, 30], ["debias.datasets.mnli.ensure_mnli_is_downloaded", "debias.datasets.mnli.load_hans", "debias.datasets.mnli.load_bias"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.ensure_mnli_is_downloaded", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_hans", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_bias"], ["", "", "def", "download_mnli", "(", ")", ":", "\n", "  ", "mnli", ".", "ensure_mnli_is_downloaded", "(", ")", "\n", "mnli", ".", "load_hans", "(", ")", "\n", "mnli", ".", "load_bias", "(", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.debias.download_all.download_wordvecs": [[32, 35], ["debias.utils.load_word_vectors.download_fasttext", "debias.utils.load_word_vectors.download_glove_6b"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors.download_fasttext", "home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors.download_glove_6b"], ["", "def", "download_wordvecs", "(", ")", ":", "\n", "  ", "load_word_vectors", ".", "download_fasttext", "(", ")", "\n", "load_word_vectors", ".", "download_glove_6b", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.debias.download_all.main": [[37, 48], ["debias.utils.py_utils.add_stdout_logger", "logging.info", "download_all.download_wordvecs", "logging.info", "download_all.download_mnli", "logging.info", "download_all.download_squad", "logging.info", "download_all.download_triviaqa_cp", "logging.info"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.add_stdout_logger", "home.repos.pwc.inspect_result.chrisc36_debias.debias.download_all.download_wordvecs", "home.repos.pwc.inspect_result.chrisc36_debias.debias.download_all.download_mnli", "home.repos.pwc.inspect_result.chrisc36_debias.debias.download_all.download_squad", "home.repos.pwc.inspect_result.chrisc36_debias.debias.download_all.download_triviaqa_cp"], ["", "def", "main", "(", ")", ":", "\n", "  ", "py_utils", ".", "add_stdout_logger", "(", ")", "\n", "logging", ".", "info", "(", "\"Checking word vectors..\"", ")", "\n", "download_wordvecs", "(", ")", "\n", "logging", ".", "info", "(", "\"Checking MNLI...\"", ")", "\n", "download_mnli", "(", ")", "\n", "logging", ".", "info", "(", "\"Checking SQUAD...\"", ")", "\n", "download_squad", "(", ")", "\n", "logging", ".", "info", "(", "\"Checking TriviaQA-CP...\"", ")", "\n", "download_triviaqa_cp", "(", ")", "\n", "logging", ".", "info", "(", "\"Done! All data should be ready\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_mnli_bias_only.is_subseq": [[42, 48], ["len", "len", "any", "range", "len"], "function", ["None"], ["def", "is_subseq", "(", "needle", ",", "haystack", ")", ":", "\n", "  ", "l", "=", "len", "(", "needle", ")", "\n", "if", "l", ">", "len", "(", "haystack", ")", ":", "\n", "    ", "return", "False", "\n", "", "else", ":", "\n", "    ", "return", "any", "(", "haystack", "[", "i", ":", "i", "+", "l", "]", "==", "needle", "for", "i", "in", "range", "(", "len", "(", "haystack", ")", "-", "l", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_mnli_bias_only.build_mnli_bias_only": [[50, 169], ["debias.utils.py_utils.add_stdout_logger", "debias.utils.tokenizer.NltkAndPunctTokenizer", "pickle.load.values", "pickle.load.items", "tensorflow.logging.info", "sklearn.linear_model.LogisticRegression", "sklearn.linear_model.LogisticRegression.fit", "dataset_to_features.items", "os.path.exists", "tensorflow.logging.info", "debias.datasets.mnli.tokenize_examples", "debias.datasets.mnli.tokenize_examples", "debias.datasets.mnli.tokenize_examples", "enumerate", "os.path.exists", "tensorflow.logging.info", "logging.info", "set", "pickle.load.values", "debias.utils.load_word_vectors.load_word_vectors", "tensorflow.logging.info", "pandas.DataFrame", "dataset_to_features[].fillna", "os.path.exists", "os.mkdir", "tensorflow.logging.info", "sklearn.linear_model.LogisticRegression.predict_log_proba().astype", "range", "numpy.mean", "print", "open", "pickle.load", "debias.datasets.mnli.load_hans", "debias.datasets.mnli.load_mnli", "debias.datasets.mnli.load_mnli", "open", "pickle.load", "set", "sum", "features.append", "len", "open", "pickle.dump", "open", "pickle.dump", "ex._replace", "set.update", "set.update", "numpy.linalg.norm", "zip", "open", "pickle.dump", "x.lower", "x.lower", "build_mnli_bias_only.is_subseq", "numpy.log", "numpy.stack", "numpy.stack", "numpy.matmul", "numpy.max", "np.max.sort", "sklearn.linear_model.LogisticRegression.predict_log_proba", "RuntimeError", "numpy.argmax", "os.path.join", "len", "len", "max", "len", "len", "np.max.sum", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.add_stdout_logger", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.tokenize_examples", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.tokenize_examples", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.tokenize_examples", "home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors.load_word_vectors", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadLoader.load", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_hans", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_mnli", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_mnli", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadLoader.load", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_mnli_bias_only.is_subseq"], ["", "", "def", "build_mnli_bias_only", "(", "out_dir", ",", "cache_examples", "=", "None", ",", "w2v_cache", "=", "None", ")", ":", "\n", "  ", "\"\"\"Builds our bias-only MNLI model and saves its predictions\n\n  :param out_dir: Directory to save the predictions\n  :param cache_examples: Cache examples to this file\n  :param w2v_cache: Cache w2v features to this file\n  \"\"\"", "\n", "py_utils", ".", "add_stdout_logger", "(", ")", "\n", "\n", "tok", "=", "NltkAndPunctTokenizer", "(", ")", "\n", "\n", "# Load the data we want to use", "\n", "if", "cache_examples", "and", "exists", "(", "cache_examples", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "\"Loading cached examples\"", ")", "\n", "with", "open", "(", "cache_examples", ",", "\"rb\"", ")", "as", "f", ":", "\n", "      ", "dataset_to_examples", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "    ", "dataset_to_examples", "=", "{", "}", "\n", "dataset_to_examples", "[", "\"hans\"", "]", "=", "tokenize_examples", "(", "load_hans", "(", ")", ",", "tok", ",", "5", ")", "\n", "dataset_to_examples", "[", "\"train\"", "]", "=", "tokenize_examples", "(", "load_mnli", "(", "True", ")", ",", "tok", ",", "5", ")", "\n", "dataset_to_examples", "[", "\"dev\"", "]", "=", "tokenize_examples", "(", "load_mnli", "(", "False", ")", ",", "tok", ",", "5", ")", "\n", "if", "cache_examples", ":", "\n", "      ", "with", "open", "(", "cache_examples", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "dataset_to_examples", ",", "f", ")", "\n", "\n", "# Our models will only distinguish entailment vs (neutral/contradict)", "\n", "", "", "", "for", "examples", "in", "dataset_to_examples", ".", "values", "(", ")", ":", "\n", "    ", "for", "i", ",", "ex", "in", "enumerate", "(", "examples", ")", ":", "\n", "      ", "if", "ex", ".", "label", "==", "2", ":", "\n", "        ", "examples", "[", "i", "]", "=", "ex", ".", "_replace", "(", "label", "=", "0", ")", "\n", "\n", "# Load the pre-normalized word vectors to use when building features", "\n", "", "", "", "if", "w2v_cache", "and", "exists", "(", "w2v_cache", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "\"Loading cached word vectors\"", ")", "\n", "with", "open", "(", "w2v_cache", ",", "\"rb\"", ")", "as", "f", ":", "\n", "      ", "w2v", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "    ", "logging", ".", "info", "(", "\"Loading word vectors\"", ")", "\n", "voc", "=", "set", "(", ")", "\n", "for", "v", "in", "dataset_to_examples", ".", "values", "(", ")", ":", "\n", "      ", "for", "ex", "in", "v", ":", "\n", "        ", "voc", ".", "update", "(", "ex", ".", "hypothesis", ")", "\n", "voc", ".", "update", "(", "ex", ".", "premise", ")", "\n", "", "", "words", ",", "vecs", "=", "load_word_vectors", "(", "\"crawl-300d-2M\"", ",", "voc", ")", "\n", "w2v", "=", "{", "w", ":", "v", "/", "np", ".", "linalg", ".", "norm", "(", "v", ")", "for", "w", ",", "v", "in", "zip", "(", "words", ",", "vecs", ")", "}", "\n", "if", "w2v_cache", ":", "\n", "      ", "with", "open", "(", "w2v_cache", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "w2v", ",", "f", ")", "\n", "\n", "# Build the features, store as a pandas dataset", "\n", "", "", "", "dataset_to_features", "=", "{", "}", "\n", "for", "name", ",", "examples", "in", "dataset_to_examples", ".", "items", "(", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "\"Building features for %s..\"", "%", "name", ")", "\n", "features", "=", "[", "]", "\n", "for", "example", "in", "examples", ":", "\n", "      ", "h", "=", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "example", ".", "hypothesis", "]", "\n", "p", "=", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "example", ".", "premise", "]", "\n", "p_words", "=", "set", "(", "p", ")", "\n", "n_words_in_p", "=", "sum", "(", "x", "in", "p_words", "for", "x", "in", "h", ")", "\n", "fe", "=", "{", "\n", "\"h-is-subseq\"", ":", "is_subseq", "(", "h", ",", "p", ")", ",", "\n", "\"all-in-p\"", ":", "n_words_in_p", "==", "len", "(", "h", ")", ",", "\n", "\"percent-in-p\"", ":", "n_words_in_p", "/", "len", "(", "h", ")", ",", "\n", "\"log-len-diff\"", ":", "np", ".", "log", "(", "max", "(", "len", "(", "p", ")", "-", "len", "(", "h", ")", ",", "1", ")", ")", ",", "\n", "\"label\"", ":", "example", ".", "label", "\n", "}", "\n", "\n", "h_vecs", "=", "[", "w2v", "[", "w", "]", "for", "w", "in", "example", ".", "hypothesis", "if", "w", "in", "w2v", "]", "\n", "p_vecs", "=", "[", "w2v", "[", "w", "]", "for", "w", "in", "example", ".", "premise", "if", "w", "in", "w2v", "]", "\n", "if", "len", "(", "h_vecs", ")", ">", "0", "and", "len", "(", "p_vecs", ")", ">", "0", ":", "\n", "        ", "h_vecs", "=", "np", ".", "stack", "(", "h_vecs", ",", "0", ")", "\n", "p_vecs", "=", "np", ".", "stack", "(", "p_vecs", ",", "0", ")", "\n", "# [h_size, p_size]", "\n", "similarities", "=", "np", ".", "matmul", "(", "h_vecs", ",", "p_vecs", ".", "T", ")", "\n", "# [h_size]", "\n", "similarities", "=", "np", ".", "max", "(", "similarities", ",", "1", ")", "\n", "similarities", ".", "sort", "(", ")", "\n", "fe", "[", "\"average-sim\"", "]", "=", "similarities", ".", "sum", "(", ")", "/", "len", "(", "h", ")", "\n", "fe", "[", "\"min-similarity\"", "]", "=", "similarities", "[", "0", "]", "\n", "if", "len", "(", "similarities", ")", ">", "1", ":", "\n", "          ", "fe", "[", "\"min2-similarity\"", "]", "=", "similarities", "[", "1", "]", "\n", "\n", "", "", "features", ".", "append", "(", "fe", ")", "\n", "\n", "", "dataset_to_features", "[", "name", "]", "=", "pd", ".", "DataFrame", "(", "features", ")", "\n", "dataset_to_features", "[", "name", "]", ".", "fillna", "(", "0.0", ",", "inplace", "=", "True", ")", "\n", "\n", "# Train the model", "\n", "", "tf", ".", "logging", ".", "info", "(", "\"Fitting...\"", ")", "\n", "train_df", "=", "dataset_to_features", "[", "\"train\"", "]", "\n", "feature_cols", "=", "[", "x", "for", "x", "in", "train_df", ".", "columns", "if", "x", "!=", "\"label\"", "]", "\n", "\n", "# class_weight='balanced' will weight the entailemnt/non-entailment examples equally", "\n", "# C=100 means no regularization", "\n", "lr", "=", "LogisticRegression", "(", "multi_class", "=", "\"auto\"", ",", "solver", "=", "\"liblinear\"", ",", "\n", "class_weight", "=", "'balanced'", ",", "C", "=", "100", ")", "\n", "lr", ".", "fit", "(", "train_df", "[", "feature_cols", "]", ".", "values", ",", "train_df", ".", "label", ".", "values", ")", "\n", "\n", "# Save the model predictions", "\n", "if", "not", "exists", "(", "out_dir", ")", ":", "\n", "    ", "mkdir", "(", "out_dir", ")", "\n", "\n", "", "for", "name", ",", "ds", "in", "dataset_to_features", ".", "items", "(", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "\"Predicting for %s\"", "%", "name", ")", "\n", "examples", "=", "dataset_to_examples", "[", "name", "]", "\n", "pred", "=", "lr", ".", "predict_log_proba", "(", "ds", "[", "feature_cols", "]", ".", "values", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "y", "=", "ds", ".", "label", ".", "values", "\n", "\n", "bias", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "pred", ")", ")", ":", "\n", "      ", "if", "examples", "[", "i", "]", ".", "id", "in", "bias", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"non-unique IDs?\"", ")", "\n", "", "bias", "[", "examples", "[", "i", "]", ".", "id", "]", "=", "pred", "[", "i", "]", "\n", "\n", "", "acc", "=", "np", ".", "mean", "(", "y", "==", "np", ".", "argmax", "(", "pred", ",", "1", ")", ")", "\n", "print", "(", "\"%s two-class accuracy: %.4f (size=%d)\"", "%", "(", "name", ",", "acc", ",", "len", "(", "examples", ")", ")", ")", "\n", "\n", "with", "open", "(", "join", "(", "out_dir", ",", "\"%s.pkl\"", "%", "name", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "      ", "pickle", ".", "dump", "(", "bias", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_mnli_bias_only.main": [[171, 179], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "build_mnli_bias_only.build_mnli_bias_only"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_mnli_bias_only.build_mnli_bias_only"], ["", "", "", "def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\"Train our MNLI bias-only model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"output_dir\"", ",", "help", "=", "\"Directory to store the bias-only predictions\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_examples\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_w2v_features\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "build_mnli_bias_only", "(", "args", ".", "output_dir", ",", "args", ".", "cache_examples", ",", "args", ".", "cache_w2v_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.ScalarFeaturePredictor.__init__": [[32, 36], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "plain", "=", "True", ",", "log", "=", "None", ",", "sumexp", "=", "False", ")", ":", "\n", "    ", "self", ".", "plain", "=", "plain", "\n", "self", ".", "log", "=", "log", "\n", "self", ".", "sumexp", "=", "sumexp", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.ScalarFeaturePredictor.get_tokenizer": [[37, 39], ["None"], "methods", ["None"], ["", "def", "get_tokenizer", "(", "self", ")", ":", "\n", "    ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.ScalarFeaturePredictor.set_vocab": [[40, 42], ["None"], "methods", ["None"], ["", "def", "set_vocab", "(", "self", ",", "_", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.ScalarFeaturePredictor.tensorize_fn": [[43, 48], ["None"], "methods", ["None"], ["", "def", "tensorize_fn", "(", "self", ")", ":", "\n", "    ", "def", "fn", "(", "x", ")", ":", "\n", "      ", "return", "x", "\n", "\n", "", "return", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.ScalarFeaturePredictor.apply": [[49, 89], ["tensorflow.stack", "debias.utils.ops.last_dim_weighted_sum", "debias.utils.ops.mask_logits", "debias.utils.ops.last_dim_weighted_sum", "debias.utils.ops.mask_logits", "tensorflow.stack", "tensorflow.nn.log_softmax", "fe.append", "isinstance", "fe.append", "tensorflow.add_to_collection", "fe.append", "train_squad_bias.elementwise_logsumexp", "len", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "fe.append", "tensorflow.log", "tensorflow.log", "tensorflow.get_variable", "labels.shape.as_list", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "debias.modules.qa_debias_loss_functions.compute_nll", "tensorflow.log"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.last_dim_weighted_sum", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.mask_logits", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.last_dim_weighted_sum", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.mask_logits", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.elementwise_logsumexp", "home.repos.pwc.inspect_result.chrisc36_debias.modules.qa_debias_loss_functions.compute_nll"], ["", "def", "apply", "(", "self", ",", "is_train", ",", "features", ",", "labels", ")", ":", "\n", "    ", "p_mask", "=", "features", "[", "PREMISE_LEN_KEY", "]", "\n", "feature", "=", "features", "[", "PREMISE_KEY", "]", "# The feature to use during prediction", "\n", "\n", "fe", "=", "[", "]", "# Transformation of the feature to predict with", "\n", "if", "self", ".", "plain", ":", "\n", "      ", "fe", ".", "append", "(", "feature", ")", "\n", "", "if", "self", ".", "log", ":", "\n", "      ", "if", "isinstance", "(", "self", ".", "log", ",", "list", ")", ":", "\n", "        ", "for", "l", "in", "self", ".", "log", ":", "\n", "          ", "fe", ".", "append", "(", "tf", ".", "log", "(", "feature", "+", "l", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "fe", ".", "append", "(", "tf", ".", "log", "(", "feature", "+", "self", ".", "log", ")", ")", "\n", "", "", "if", "self", ".", "sumexp", ":", "\n", "      ", "fe", ".", "append", "(", "elementwise_logsumexp", "(", "tf", ".", "log", "(", "feature", "+", "0.1", ")", ",", "tf", ".", "get_variable", "(", "\"offset\"", ",", "(", ")", ")", ")", ")", "\n", "", "feature", "=", "tf", ".", "stack", "(", "fe", ",", "2", ")", "\n", "\n", "start_scores", "=", "ops", ".", "last_dim_weighted_sum", "(", "feature", ",", "\"start-w\"", ")", "\n", "start_scores", "=", "ops", ".", "mask_logits", "(", "start_scores", ",", "p_mask", ")", "\n", "end_scores", "=", "ops", ".", "last_dim_weighted_sum", "(", "feature", ",", "\"end-w\"", ")", "\n", "end_scores", "=", "ops", ".", "mask_logits", "(", "end_scores", ",", "p_mask", ")", "\n", "logits", "=", "tf", ".", "stack", "(", "[", "start_scores", ",", "end_scores", "]", ",", "-", "1", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "      ", "if", "len", "(", "labels", ".", "shape", ".", "as_list", "(", ")", ")", "==", "2", ":", "\n", "# Sparse label of size [batch, 2] of target start/end tokens", "\n", "        ", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "labels", "=", "labels", "[", ":", ",", "0", "]", ",", "\n", "logits", "=", "start_scores", "\n", ")", ")", "\n", "loss", "+=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "labels", "=", "labels", "[", ":", ",", "1", "]", ",", "\n", "logits", "=", "end_scores", "\n", ")", ")", "\n", "", "else", ":", "\n", "# Dense label of size [batch, seq_len, 2] with true/false for target start/end tokens", "\n", "        ", "loss", "=", "tf", ".", "reduce_mean", "(", "compute_nll", "(", "logits", ",", "labels", ",", "None", ")", ")", "\n", "", "tf", ".", "add_to_collection", "(", "tf", ".", "GraphKeys", ".", "LOSSES", ",", "loss", ")", "\n", "\n", "", "return", "tf", ".", "nn", ".", "log_softmax", "(", "logits", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.SquadTfidfFeaturesLoader.__init__": [[136, 140], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "pos_filtered", ",", "train_sample", ",", "multi_label", ")", ":", "\n", "    ", "self", ".", "pos_filtered", "=", "pos_filtered", "\n", "self", ".", "train_sample", "=", "train_sample", "\n", "self", ".", "multi_label", "=", "multi_label", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.SquadTfidfFeaturesLoader.load": [[141, 145], ["train_squad_bias.load_squad_with_features", "train_squad_bias.make_dataset", "debias.datasets.training_data_loader.TrainingData"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.load_squad_with_features", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset"], ["", "def", "load", "(", "self", ",", "tokenizer", ",", "n_processes", "=", "None", ")", ":", "\n", "    ", "train", "=", "load_squad_with_features", "(", "\"train\"", ",", "self", ".", "pos_filtered", ",", "self", ".", "multi_label", ")", "\n", "train_ds", "=", "make_dataset", "(", "train", ",", "None", ",", "shuffle", "=", "True", ")", "\n", "return", "TrainingData", "(", "train_ds", ",", "{", "}", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.elementwise_logsumexp": [[25, 27], ["tensorflow.maximum", "tensorflow.log1p", "tensorflow.exp", "tensorflow.abs"], "function", ["None"], ["def", "elementwise_logsumexp", "(", "x", ",", "y", ")", ":", "\n", "  ", "return", "tf", ".", "maximum", "(", "x", ",", "y", ")", "+", "tf", ".", "log1p", "(", "tf", ".", "exp", "(", "-", "tf", ".", "abs", "(", "x", "-", "y", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.make_dataset": [[91, 112], ["debias.datasets.dataset_utils.build_epoch_fn", "tensorflow.data.Dataset.from_generator", "tf.data.Dataset.from_generator.map", "len", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.dataset_utils.build_epoch_fn"], ["", "", "def", "make_dataset", "(", "features", ",", "sample", "=", "None", ",", "shuffle", "=", "False", ")", ":", "\n", "  ", "get", "=", "build_epoch_fn", "(", "features", ",", "sample", ",", "shuffle", "=", "shuffle", ")", "\n", "if", "len", "(", "features", "[", "0", "]", "[", "2", "]", ".", "shape", ")", "==", "2", ":", "\n", "    ", "label_shape", "=", "(", "None", ",", "2", ")", "\n", "label_dtype", "=", "tf", ".", "bool", "\n", "", "else", ":", "\n", "    ", "label_shape", "=", "(", "2", ",", ")", "\n", "label_dtype", "=", "tf", ".", "int32", "\n", "\n", "", "data", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "\n", "get", ",", "(", "tf", ".", "string", ",", "tf", ".", "float32", ",", "label_dtype", ")", ",", "(", "(", ")", ",", "(", "None", ",", ")", ",", "label_shape", ")", ")", "\n", "\n", "def", "to_map", "(", "qid", ",", "features", ",", "labels", ")", ":", "\n", "    ", "return", "{", "\n", "\"qid\"", ":", "qid", ",", "\n", "PREMISE_KEY", ":", "features", ",", "\n", "\"label\"", ":", "labels", ",", "\n", "PREMISE_LEN_KEY", ":", "tf", ".", "shape", "(", "features", ")", "[", "0", "]", "\n", "}", "\n", "\n", "", "return", "data", ".", "map", "(", "to_map", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.load_squad_with_features": [[114, 132], ["debias.preprocessing.squad_tfidf_features.get_squad_tfidf_features", "debias.datasets.squad.load_annotated_squad", "out.sort", "numpy.zeros", "out.append", "out.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.squad_tfidf_features.get_squad_tfidf_features", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.load_annotated_squad"], ["", "def", "load_squad_with_features", "(", "key", ",", "pos_filtered", ",", "multi_label", ")", ":", "\n", "  ", "fe", "=", "get_squad_tfidf_features", "(", "key", ",", "pos_filtered", ")", "\n", "data", "=", "load_annotated_squad", "(", "key", ")", "\n", "out", "=", "[", "]", "\n", "for", "ex", "in", "data", ":", "\n", "    ", "for", "q", "in", "ex", ".", "questions", ":", "\n", "      ", "if", "multi_label", ":", "\n", "        ", "dense_answers", "=", "np", ".", "zeros", "(", "(", "len", "(", "ex", ".", "tokens", ")", ",", "2", ")", ",", "np", ".", "bool", ")", "\n", "for", "s", ",", "e", "in", "q", ".", "answer_spans", ":", "\n", "          ", "dense_answers", "[", "s", ",", "0", "]", "=", "True", "\n", "dense_answers", "[", "e", ",", "1", "]", "=", "True", "\n", "\n", "", "out", ".", "append", "(", "(", "q", ".", "question_id", ",", "fe", "[", "q", ".", "question_id", "]", ",", "dense_answers", ")", ")", "\n", "", "else", ":", "\n", "        ", "out", ".", "append", "(", "(", "q", ".", "question_id", ",", "fe", "[", "q", ".", "question_id", "]", ",", "q", ".", "answer_spans", "[", "0", "]", ")", ")", "\n", "\n", "", "", "", "out", ".", "sort", "(", "key", "=", "lambda", "x", ":", "-", "len", "(", "x", "[", "0", "]", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.build_squad_bias_only_model": [[147, 223], ["debias.training.trainer.AdamOptimizer", "train_squad_bias.SquadTfidfFeaturesLoader", "debias.training.trainer.Trainer", "train_squad_bias.ScalarFeaturePredictor", "print", "print", "train_squad_bias.load_squad_with_features", "len", "train_squad_bias.make_dataset", "train.padded_batch().prefetch.padded_batch().prefetch", "tensorflow.data.Iterator.from_structure", "tf.data.Iterator.from_structure.get_next", "train_squad_bias.ScalarFeaturePredictor.apply", "tensorflow.Session", "tf.Session.run", "tf.Session.run", "tf.Session.run", "tensorflow.train.Saver", "tf.train.Saver.restore", "debias.datasets.dataset_utils.QuantileBatcher", "tensorflow.Session", "debias.training.trainer.Trainer.train", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "debias.models.model_dir.ModelDir().get_latest_checkpoint", "os.path.exists", "os.mkdir", "tqdm.tqdm", "tqdm.tqdm.close", "train.padded_batch().prefetch.padded_batch", "tf.Session.run", "train_squad_bias.load_squad_with_features", "len", "train_squad_bias.make_dataset", "ds.padded_batch().prefetch.padded_batch().prefetch", "tf.Session.run", "tqdm.tqdm.update", "zip", "open", "pickle.dump", "tensorflow.Graph", "debias.models.model_dir.ModelDir", "tf.data.Iterator.from_structure.make_initializer", "tf.data.Iterator.from_structure.make_initializer", "tf.Session.run", "len", "os.path.join", "ds.padded_batch().prefetch.padded_batch", "qid.decode"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.load_squad_with_features", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.trainer.Trainer.train", "home.repos.pwc.inspect_result.chrisc36_debias.models.model_dir.ModelDir.get_latest_checkpoint", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.load_squad_with_features", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run"], ["", "", "def", "build_squad_bias_only_model", "(", "model_dir", ",", "output_dir", ",", "pos_filtered", ")", ":", "\n", "  ", "\"\"\"Train the SQuAD Bias-Only model\n\n  :param model_dir: Directory to save the model\n  :param output_dir: Director to save the model predictions\n  :param pos_filtered: Should we use pos-filtered TF-IDF features or not\n  \"\"\"", "\n", "debias", "/", "preprocessing", "/", "train_squad_bias", ".", "py", "\n", "opt", "=", "AdamOptimizer", "(", "\n", "learning_rate", "=", "0.001", ",", "\n", "max_grad_norm", "=", "5.0", ",", "\n", "staircase", "=", "True", ",", "\n", "decay_steps", "=", "100", ",", "\n", "decay_rate", "=", "0.999", "\n", ")", "\n", "\n", "data_loader", "=", "SquadTfidfFeaturesLoader", "(", "pos_filtered", ",", "5000", ",", "False", ")", "\n", "\n", "tr", "=", "Trainer", "(", "\n", "QuantileBatcher", "(", "45", ",", "10", ",", "300", ",", "4", ",", "12", ")", ",", "\n", "opt", ",", "\n", "evaluator", "=", "None", ",", "\n", "eval_batch_size", "=", "90", ",", "\n", "epoch_size", "=", "1341", ",", "num_epochs", "=", "10", ",", "log_period", "=", "100", ",", "\n", ")", "\n", "\n", "model", "=", "ScalarFeaturePredictor", "(", "sumexp", "=", "True", ",", "log", "=", "0.1", ")", "\n", "\n", "print", "(", "\"Training...\"", ")", "\n", "with", "tf", ".", "Session", "(", "graph", "=", "tf", ".", "Graph", "(", ")", ")", "as", "sess", ":", "\n", "    ", "tr", ".", "train", "(", "data_loader", ",", "model", ",", "model_dir", ",", "sess", "=", "sess", ")", "\n", "\n", "", "print", "(", "\"Evaluating...\"", ")", "\n", "train", "=", "load_squad_with_features", "(", "\"train\"", ",", "pos_filtered", ",", "data_loader", ".", "multi_label", ")", "\n", "total", "=", "len", "(", "train", ")", "\n", "train", "=", "make_dataset", "(", "train", ")", "\n", "train", "=", "train", ".", "padded_batch", "(", "45", ",", "train", ".", "output_shapes", ")", ".", "prefetch", "(", "5", ")", "\n", "\n", "eval_it", "=", "tf", ".", "data", ".", "Iterator", ".", "from_structure", "(", "train", ".", "output_types", ",", "train", ".", "output_shapes", ")", "\n", "eval_input_op", "=", "eval_it", ".", "get_next", "(", ")", "\n", "logit_op", "=", "model", ".", "apply", "(", "False", ",", "eval_input_op", ",", "None", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "ModelDir", "(", "model_dir", ")", ".", "get_latest_checkpoint", "(", ")", ")", "\n", "\n", "if", "not", "exists", "(", "output_dir", ")", ":", "\n", "    ", "mkdir", "(", "output_dir", ")", "\n", "\n", "", "for", "dataset_name", "in", "[", "\"train\"", ",", "\"add_sent\"", ",", "\"dev\"", ",", "\"add_one_sent\"", "]", ":", "\n", "    ", "out", "=", "{", "}", "\n", "if", "dataset_name", "==", "\"train\"", ":", "\n", "      ", "sess", ".", "run", "(", "eval_it", ".", "make_initializer", "(", "train", ")", ")", "\n", "", "else", ":", "\n", "      ", "ds", "=", "load_squad_with_features", "(", "dataset_name", ",", "pos_filtered", ",", "data_loader", ".", "multi_label", ")", "\n", "total", "=", "len", "(", "ds", ")", "\n", "ds", "=", "make_dataset", "(", "ds", ")", "\n", "ds", "=", "ds", ".", "padded_batch", "(", "45", ",", "ds", ".", "output_shapes", ")", ".", "prefetch", "(", "5", ")", "\n", "sess", ".", "run", "(", "eval_it", ".", "make_initializer", "(", "ds", ")", ")", "\n", "\n", "", "pbar", "=", "tqdm", "(", "desc", "=", "dataset_name", ",", "ncols", "=", "100", ",", "total", "=", "total", ")", "\n", "while", "True", ":", "\n", "      ", "try", ":", "\n", "        ", "logits", ",", "qids", ",", "p_lens", "=", "sess", ".", "run", "(", "[", "logit_op", ",", "eval_input_op", "[", "\"qid\"", "]", ",", "eval_input_op", "[", "PREMISE_LEN_KEY", "]", "]", ")", "\n", "", "except", "OutOfRangeError", ":", "\n", "        ", "break", "\n", "", "pbar", ".", "update", "(", "len", "(", "logits", ")", ")", "\n", "for", "logit", ",", "qid", ",", "p_len", "in", "zip", "(", "logits", ",", "qids", ",", "p_lens", ")", ":", "\n", "        ", "out", "[", "qid", ".", "decode", "(", "\"utf-8\"", ")", "]", "=", "logit", "[", ":", "p_len", "]", "\n", "", "", "pbar", ".", "close", "(", ")", "\n", "\n", "with", "open", "(", "join", "(", "output_dir", ",", "dataset_name", "+", "\".pkl\"", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "      ", "pickle", ".", "dump", "(", "out", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.main": [[225, 233], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "train_squad_bias.build_squad_bias_only_model"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.train_squad_bias.build_squad_bias_only_model"], ["", "", "", "def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"model_dir\"", ",", "help", "=", "\"Directory to save the trained model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"output_dir\"", ",", "help", "=", "\"Directory to save the model predictions\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--pos_filtered\"", ",", "help", "=", "\"Use POS Filtered TF-IDF features\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "build_squad_bias_only_model", "(", "args", ".", "model_dir", ",", "args", ".", "output_dir", ",", "args", ".", "pos_filtered", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.squad_tfidf_features.get_squad_tfidf_features": [[13, 28], ["os.path.join", "debias.utils.py_utils.load_pickle", "os.path.exists", "squad_tfidf_features.build_squad_tfidf_features"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_pickle", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.squad_tfidf_features.build_squad_tfidf_features"], ["def", "get_squad_tfidf_features", "(", "dataset_name", ",", "pos_filter", ")", ":", "\n", "  ", "\"\"\"Gets the tfidf features we used to train the bias-only model\n\n  :param dataset_name: Name of SQuAD dataset to get features for\n  :param pos_filter: POS filtered TF-IDF scores or not\n  :return: Dictionary of question_id -> per-word array of TT-IDF scores\n  \"\"\"", "\n", "if", "pos_filter", ":", "\n", "    ", "root", "=", "SQUAD_FILTERED_TFIDF_FEATURES", "\n", "", "else", ":", "\n", "    ", "root", "=", "SQUAD_TFIDF_FEATURES", "\n", "", "src", "=", "join", "(", "root", ",", "dataset_name", "+", "\".pkl\"", ")", "\n", "if", "not", "exists", "(", "src", ")", ":", "\n", "    ", "build_squad_tfidf_features", "(", "pos_filter", ")", "\n", "", "return", "py_utils", ".", "load_pickle", "(", "src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.squad_tfidf_features.get_pos_filtered_sentences": [[30, 39], ["pruned.append", "zip", "p.startswith"], "function", ["None"], ["", "def", "get_pos_filtered_sentences", "(", "ex", ":", "AnnotatedSquadParagraph", ")", ":", "\n", "  ", "on_ix", "=", "0", "\n", "pruned", "=", "[", "]", "\n", "for", "l", "in", "ex", ".", "sentence_lens", ":", "\n", "    ", "tok", "=", "ex", ".", "tokens", "[", "on_ix", ":", "on_ix", "+", "l", "]", "\n", "pos", "=", "ex", ".", "pos_tags", "[", "on_ix", ":", "on_ix", "+", "l", "]", "\n", "on_ix", "+=", "l", "\n", "pruned", ".", "append", "(", "[", "w", "for", "w", ",", "p", "in", "zip", "(", "tok", ",", "pos", ")", "if", "not", "(", "p", "==", "\"CD\"", "or", "p", ".", "startswith", "(", "\"NNP\"", ")", ")", "]", ")", "\n", "", "return", "pruned", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.squad_tfidf_features.build_squad_tfidf_features": [[41, 107], ["print", "debias.datasets.squad.load_annotated_squad", "print", "TfidfVectorizer", "TfidfVectorizer.fit", "print", "print", "print", "debias.utils.py_utils.flatten_list", "debias.utils.py_utils.flatten_list", "os.path.exists", "os.mkdir", "print", "tqdm.tqdm", "os.path.join", "debias.datasets.squad.load_annotated_squad", "numpy.zeros", "enumerate", "TfidfVectorizer.transform", "TfidfVectorizer.transform", "cosine_similarity", "enumerate", "open", "pickle.dump", "squad_tfidf_features.get_pos_filtered_sentences", "ex.sentences", "squad_tfidf_features.get_pos_filtered_sentences", "ex.sentences", "len", "w.lower"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.load_annotated_squad", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.flatten_list", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.flatten_list", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.load_annotated_squad", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.squad_tfidf_features.get_pos_filtered_sentences", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadParagraph.sentences", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.squad_tfidf_features.get_pos_filtered_sentences", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadParagraph.sentences"], ["", "def", "build_squad_tfidf_features", "(", "pos_filter", "=", "False", ")", ":", "\n", "  ", "from", "sklearn", ".", "feature_extraction", ".", "text", "import", "TfidfVectorizer", "\n", "from", "sklearn", ".", "metrics", ".", "pairwise", "import", "cosine_similarity", "\n", "\n", "if", "pos_filter", ":", "\n", "    ", "print", "(", "\"Computing SQuAD pos-filtered TF-IDF Features\"", ")", "\n", "", "else", ":", "\n", "    ", "print", "(", "\"Computing SQuAD TF-IDF Features\"", ")", "\n", "", "print", "(", "\"Loading train...\"", ")", "\n", "train", "=", "load_annotated_squad", "(", "\"train\"", ")", "\n", "\n", "print", "(", "\"Fitting training...\"", ")", "\n", "tfidf", "=", "TfidfVectorizer", "(", "\n", "strip_accents", "=", "\"unicode\"", ",", "\n", "ngram_range", "=", "(", "1", ",", "3", ")", ",", "max_df", "=", "0.3", ",", "min_df", "=", "50", ",", "\n", "tokenizer", "=", "lambda", "x", ":", "x", ",", "\n", "token_pattern", "=", "None", ",", "\n", "preprocessor", "=", "lambda", "x", ":", "[", "w", ".", "lower", "(", ")", "for", "w", "in", "x", "]", "\n", ")", "\n", "if", "pos_filter", ":", "\n", "    ", "text", "=", "py_utils", ".", "flatten_list", "(", "get_pos_filtered_sentences", "(", "ex", ")", "for", "ex", "in", "train", ")", "\n", "", "else", ":", "\n", "    ", "text", "=", "py_utils", ".", "flatten_list", "(", "ex", ".", "sentences", "(", ")", "for", "ex", "in", "train", ")", "\n", "", "tfidf", ".", "fit", "(", "text", ")", "\n", "\n", "to_eval", "=", "[", "\n", "(", "\"train\"", ",", "train", ")", ",", "\n", "(", "\"dev\"", ",", "None", ")", ",", "\n", "(", "\"add_sent\"", ",", "None", ")", ",", "\n", "(", "\"add_one_sent\"", ",", "None", ")", "\n", "]", "\n", "\n", "if", "pos_filter", ":", "\n", "    ", "root", "=", "SQUAD_FILTERED_TFIDF_FEATURES", "\n", "", "else", ":", "\n", "    ", "root", "=", "SQUAD_TFIDF_FEATURES", "\n", "", "if", "not", "exists", "(", "root", ")", ":", "\n", "    ", "mkdir", "(", "root", ")", "\n", "\n", "", "for", "ds_name", ",", "data", "in", "to_eval", ":", "\n", "    ", "print", "(", "\"Building features for \"", "+", "ds_name", ")", "\n", "if", "data", "is", "None", ":", "\n", "      ", "data", "=", "load_annotated_squad", "(", "ds_name", ")", "\n", "", "features", "=", "{", "}", "\n", "for", "ex", "in", "tqdm", "(", "data", ",", "ncols", "=", "100", ",", "desc", "=", "ds_name", ")", ":", "\n", "      ", "if", "pos_filter", ":", "\n", "        ", "sentences", "=", "get_pos_filtered_sentences", "(", "ex", ")", "\n", "", "else", ":", "\n", "        ", "sentences", "=", "ex", ".", "sentences", "(", ")", "\n", "", "token_to_sent_id", "=", "np", ".", "zeros", "(", "len", "(", "ex", ".", "tokens", ")", ",", "np", ".", "int32", ")", "\n", "on", "=", "0", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "ex", ".", "sentence_lens", ")", ":", "\n", "        ", "token_to_sent_id", "[", "on", ":", "on", "+", "l", "]", "=", "i", "\n", "on", "+=", "l", "\n", "\n", "", "question_fe", "=", "tfidf", ".", "transform", "(", "[", "x", ".", "words", "for", "x", "in", "ex", ".", "questions", "]", ",", "copy", "=", "None", ")", "\n", "sentence_fe", "=", "tfidf", ".", "transform", "(", "sentences", ",", "copy", "=", "None", ")", "\n", "question_to_sentence_dist", "=", "cosine_similarity", "(", "question_fe", ",", "sentence_fe", ")", "\n", "\n", "for", "q_ix", ",", "q", "in", "enumerate", "(", "ex", ".", "questions", ")", ":", "\n", "        ", "features", "[", "q", ".", "question_id", "]", "=", "question_to_sentence_dist", "[", "q_ix", "]", "[", "token_to_sent_id", "]", "\n", "\n", "", "", "src", "=", "join", "(", "root", ",", "ds_name", "+", "\".pkl\"", ")", "\n", "with", "open", "(", "src", ",", "\"wb\"", ")", "as", "f", ":", "\n", "      ", "pickle", ".", "dump", "(", "features", ",", "f", ")", "\n", "", "", "print", "(", "'Done!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_triviaqa.AnnotateTriviaqaQuestions.__init__": [[116, 120], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "port", ",", "reuse_session", "=", "False", ",", "legacy_tokenization", "=", "True", ")", ":", "\n", "    ", "self", ".", "port", "=", "port", "\n", "self", ".", "reuse_session", "=", "reuse_session", "\n", "self", ".", "legacy_tokenization", "=", "legacy_tokenization", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_triviaqa.AnnotateTriviaqaQuestions.process": [[121, 163], ["debias.preprocessing.corenlp_client.CoreNLPClient", "requests.Session", "build_annotated_triviaqa.extract_normalized_answers", "example[].split", "numpy.array", "out.append", "build_annotated_triviaqa.extract_tokens", "build_annotated_triviaqa.extract_tokens", "build_annotated_triviaqa.find_answer_spans", "debias.datasets.triviaqa_cp.AnnotatedTriviaQaExample", "build_annotated_triviaqa.extract_tokens", "len", "answers_tokenized.append", "numpy.array", "debias.preprocessing.corenlp_client.CoreNLPClient.query_tokenize", "build_annotated_triviaqa.extract_tokens", "debias.preprocessing.corenlp_client.CoreNLPClient.query_ner", "debias.preprocessing.corenlp_client.CoreNLPClient.query_ner", "debias.preprocessing.corenlp_client.CoreNLPClient.query_tokenize", "debias.preprocessing.corenlp_client.CoreNLPClient.query_tokenize"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_triviaqa.extract_normalized_answers", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_triviaqa.extract_tokens", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_triviaqa.extract_tokens", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_triviaqa.find_answer_spans", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_triviaqa.extract_tokens", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.corenlp_client.CoreNLPClient.query_tokenize", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_triviaqa.extract_tokens", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.corenlp_client.CoreNLPClient.query_ner", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.corenlp_client.CoreNLPClient.query_ner", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.corenlp_client.CoreNLPClient.query_tokenize", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.corenlp_client.CoreNLPClient.query_tokenize"], ["", "def", "process", "(", "self", ",", "data", ":", "List", "[", "Dict", "]", ")", "->", "List", "[", "AnnotatedTriviaQaExample", "]", ":", "\n", "    ", "cli", "=", "CoreNLPClient", "(", "port", "=", "self", ".", "port", ")", "\n", "sess", "=", "None", "\n", "if", "self", ".", "reuse_session", ":", "\n", "      ", "sess", "=", "requests", ".", "Session", "(", ")", "\n", "sess", ".", "trust_env", "=", "False", "\n", "\n", "", "out", "=", "[", "]", "\n", "for", "example", "in", "data", ":", "\n", "      ", "q_tok", "=", "extract_tokens", "(", "cli", ".", "query_tokenize", "(", "example", "[", "'Question'", "]", ",", "sess", "=", "sess", ")", "[", "\"sentences\"", "]", ",", "False", ")", "[", "0", "]", "\n", "\n", "answers", "=", "extract_normalized_answers", "(", "example", "[", "\"Answer\"", "]", ")", "\n", "answers_tokenized", "=", "[", "]", "\n", "for", "ans", "in", "answers", ":", "\n", "        ", "ans_tok", "=", "extract_tokens", "(", "cli", ".", "query_tokenize", "(", "ans", ",", "sess", "=", "sess", ")", "[", "\"sentences\"", "]", ",", "False", ")", "[", "0", "]", "\n", "if", "len", "(", "ans_tok", ")", ">", "0", ":", "# Can happen very wonky unicode answers", "\n", "          ", "answers_tokenized", ".", "append", "(", "ans_tok", ")", "\n", "\n", "", "", "tok", "=", "[", "]", "\n", "pos", "=", "[", "]", "\n", "ner", "=", "[", "]", "\n", "for", "para", "in", "example", "[", "'Passage'", "]", ".", "split", "(", "\"\\n\"", ")", ":", "\n", "        ", "if", "self", ".", "legacy_tokenization", ":", "\n", "# The original code did tokenization and NER separately instead of doing both", "\n", "# in one query in order to do some additional caching. Unfortunately this can slightly", "\n", "# change tagging output due to the respitting we do, so we preserve that behavior here.", "\n", "          ", "_tok", "=", "extract_tokens", "(", "cli", ".", "query_tokenize", "(", "para", ",", "sess", "=", "sess", ")", "[", "\"sentences\"", "]", ",", "False", ")", "[", "0", "]", "\n", "sentences", "=", "cli", ".", "query_ner", "(", "\" \"", ".", "join", "(", "_tok", ")", ",", "sess", "=", "sess", ",", "whitespace", "=", "True", ")", "[", "\"sentences\"", "]", "\n", "", "else", ":", "\n", "          ", "sentences", "=", "cli", ".", "query_ner", "(", "para", ",", "sess", "=", "sess", ")", "[", "\"sentences\"", "]", "\n", "", "p_tok", ",", "p_pos", ",", "p_ner", ",", "_", "=", "extract_tokens", "(", "sentences", ",", "True", ")", "\n", "tok", "+=", "p_tok", "\n", "pos", "+=", "p_pos", "\n", "ner", "+=", "p_ner", "\n", "\n", "", "spans", "=", "np", ".", "array", "(", "find_answer_spans", "(", "tok", ",", "answers_tokenized", ")", ")", "\n", "spans", "[", ":", ",", "1", "]", "-=", "1", "# Switch to inclusive", "\n", "\n", "out", ".", "append", "(", "AnnotatedTriviaQaExample", "(", "\n", "example", "[", "\"QuestionId\"", "]", ",", "example", "[", "\"QuestionType\"", "]", ",", "np", ".", "array", "(", "example", "[", "\"QuestionTypeProbs\"", "]", ")", ",", "\n", "q_tok", ",", "tok", ",", "pos", ",", "ner", ",", "answers", ",", "spans", ")", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_triviaqa.extract_normalized_answers": [[27, 40], ["ans.get", "triviaqa_cp.triviaqa_cp_evaluation.normalize_answer"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer"], ["def", "extract_normalized_answers", "(", "ans", ")", ":", "\n", "  ", "\"\"\"Get the normalized answers from a json TriviaQa question\"\"\"", "\n", "\n", "if", "ans", "is", "not", "None", ":", "\n", "    ", "answers", "=", "ans", "[", "'NormalizedAliases'", "]", "\n", "human_answers", "=", "ans", ".", "get", "(", "'HumanAnswers'", ")", "\n", "if", "human_answers", "is", "not", "None", ":", "\n", "# This are fair game since they are used in the eval script, but be", "\n", "# careful to normalize them as well", "\n", "      ", "answers", "+=", "[", "normalize_answer", "(", "x", ")", "for", "x", "in", "human_answers", "]", "\n", "", "", "else", ":", "\n", "    ", "answers", "=", "None", "# test question", "\n", "", "return", "answers", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_triviaqa.find_answer_spans": [[42, 65], ["enumerate", "list", "triviaqa_cp.triviaqa_cp_evaluation.normalize_answer", "len", "set", "enumerate", "occurances.append", "len"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer"], ["", "def", "find_answer_spans", "(", "para", ":", "List", "[", "str", "]", ",", "tokenized_answers", ":", "List", "[", "List", "[", "str", "]", "]", ")", ":", "\n", "  ", "\"\"\"Find spans that the eval script would given an EM of 1 in `para`\"\"\"", "\n", "\n", "words", "=", "[", "normalize_answer", "(", "w", ")", "for", "w", "in", "para", "]", "\n", "occurances", "=", "[", "]", "\n", "for", "answer_ix", ",", "answer", "in", "enumerate", "(", "tokenized_answers", ")", ":", "\n", "    ", "word_starts", "=", "[", "i", "for", "i", ",", "w", "in", "enumerate", "(", "words", ")", "if", "answer", "[", "0", "]", "==", "w", "]", "\n", "n_tokens", "=", "len", "(", "answer", ")", "\n", "for", "start", "in", "word_starts", ":", "\n", "      ", "end", "=", "start", "+", "1", "\n", "ans_token", "=", "1", "\n", "while", "ans_token", "<", "n_tokens", "and", "end", "<", "len", "(", "words", ")", ":", "\n", "        ", "next", "=", "words", "[", "end", "]", "\n", "if", "answer", "[", "ans_token", "]", "==", "next", ":", "\n", "          ", "ans_token", "+=", "1", "\n", "end", "+=", "1", "\n", "", "elif", "next", "==", "\"\"", ":", "\n", "          ", "end", "+=", "1", "\n", "", "else", ":", "\n", "          ", "break", "\n", "", "", "if", "n_tokens", "==", "ans_token", ":", "\n", "        ", "occurances", ".", "append", "(", "(", "start", ",", "end", ")", ")", "\n", "", "", "", "return", "list", "(", "set", "(", "occurances", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_triviaqa.extract_tokens": [[73, 111], ["sentence_lens.append", "len", "len", "RuntimeError", "len", "words.append", "len", "pos.append", "ner.append", "split_regex.split", "len", "len", "split_regex.match"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split"], ["def", "extract_tokens", "(", "annotations", ",", "tags", "=", "True", ")", ":", "\n", "  ", "\"\"\"Extract tokens from CoreNLP output\"\"\"", "\n", "\n", "words", ",", "pos", ",", "ner", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "sentence_lens", "=", "[", "]", "\n", "on_len", "=", "0", "\n", "for", "sentences", "in", "annotations", ":", "\n", "    ", "if", "len", "(", "sentences", "[", "\"tokens\"", "]", ")", "==", "0", ":", "\n", "      ", "raise", "RuntimeError", "(", ")", "\n", "", "for", "token", "in", "sentences", "[", "\"tokens\"", "]", ":", "\n", "      ", "w", "=", "token", "[", "\"originalText\"", "]", "\n", "\n", "if", "w", "==", "\"''\"", "or", "w", "==", "'``'", ":", "\n", "        ", "split", "=", "[", "w", "]", "\n", "", "else", ":", "\n", "# We tokenize a bit more aggresively the CoreNLP so span-based models", "\n", "# can make fine-grained choices of what text to return", "\n", "        ", "split", "=", "[", "x", "for", "x", "in", "split_regex", ".", "split", "(", "w", ")", "if", "len", "(", "x", ")", ">", "0", "]", "\n", "\n", "", "if", "len", "(", "split", ")", "==", "1", ":", "\n", "        ", "words", ".", "append", "(", "w", ")", "\n", "if", "tags", ":", "\n", "          ", "p", ",", "n", "=", "token", "[", "\"pos\"", "]", ",", "token", "[", "\"ner\"", "]", "\n", "pos", ".", "append", "(", "p", ")", "\n", "ner", ".", "append", "(", "n", ")", "\n", "", "", "else", ":", "\n", "        ", "words", "+=", "split", "\n", "if", "tags", ":", "\n", "          ", "p", ",", "n", "=", "token", "[", "\"pos\"", "]", ",", "token", "[", "\"ner\"", "]", "\n", "ner", "+=", "[", "n", "]", "*", "len", "(", "split", ")", "\n", "pos", "+=", "[", "'SEP'", "if", "split_regex", ".", "match", "(", "x", ")", "else", "p", "for", "x", "in", "split", "]", "\n", "\n", "", "", "", "sentence_lens", ".", "append", "(", "len", "(", "words", ")", "-", "on_len", ")", "\n", "on_len", "=", "len", "(", "words", ")", "\n", "", "if", "tags", ":", "\n", "    ", "return", "words", ",", "pos", ",", "ner", ",", "sentence_lens", "\n", "", "else", ":", "\n", "    ", "return", "words", ",", "sentence_lens", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_triviaqa.main": [[165, 185], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "build_annotated_triviaqa.AnnotateTriviaqaQuestions", "debias.utils.process_par.process_par", "open", "open", "f.write", "json.load"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.process_par.process_par", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadLoader.load"], ["", "", "def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\"Builds annotated TriviaQA-CP data\"", ")", "\n", "parser", ".", "add_argument", "(", "\"source\"", ",", "help", "=", "\"Source TriviaQa-CP file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"output\"", ",", "help", "=", "\"Output pickle file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--port\"", ",", "default", "=", "9000", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_processes\"", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_legacy_tokenization\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Turn off legacy tokenization, which will more closely reproduce our\"", "\n", "\" results, but might make tagging worse in rare cases\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "with", "open", "(", "args", ".", "source", ",", "\"r\"", ")", "as", "f", ":", "\n", "    ", "examples", "=", "json", ".", "load", "(", "f", ")", "[", "'Data'", "]", "\n", "\n", "", "annotator", "=", "AnnotateTriviaqaQuestions", "(", "\n", "args", ".", "port", ",", "legacy_tokenization", "=", "not", "args", ".", "no_legacy_tokenization", ")", "\n", "output", "=", "process_par", ".", "process_par", "(", "examples", ",", "annotator", ",", "args", ".", "n_processes", ",", "10", ")", "\n", "\n", "with", "open", "(", "args", ".", "output", ",", "\"wb\"", ")", "as", "f", ":", "\n", "    ", "f", ".", "write", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.corenlp_client.CoreNLPClient.__init__": [[10, 19], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "hostname", "=", "'http://localhost'", ",", "port", "=", "7000", ")", ":", "\n", "    ", "\"\"\"Create the client.\n    Args:\n      hostname: hostname of server.\n      port: port of server.\n      cache_file: load and save cache to this file.\n    \"\"\"", "\n", "self", ".", "hostname", "=", "hostname", "\n", "self", ".", "port", "=", "port", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.corenlp_client.CoreNLPClient.query": [[20, 43], ["isinstance", "str", "requests.post", "sess.post", "json.loads", "ValueError", "data.encode", "data.encode"], "methods", ["None"], ["", "def", "query", "(", "self", ",", "sents", ",", "properties", ",", "sess", "=", "None", ")", ":", "\n", "    ", "\"\"\"Most general way to query the server.\n\n    Args:\n      sents: Either a string or a list of strings.\n      properties: CoreNLP properties to send as part of the request.\n    \"\"\"", "\n", "url", "=", "'%s:%d'", "%", "(", "self", ".", "hostname", ",", "self", ".", "port", ")", "\n", "params", "=", "{", "'properties'", ":", "str", "(", "properties", ")", "}", "\n", "if", "isinstance", "(", "sents", ",", "list", ")", ":", "\n", "      ", "data", "=", "'\\n'", ".", "join", "(", "sents", ")", "\n", "", "else", ":", "\n", "      ", "data", "=", "sents", "\n", "", "if", "sess", "is", "None", ":", "\n", "      ", "r", "=", "requests", ".", "post", "(", "url", ",", "params", "=", "params", ",", "data", "=", "data", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "", "else", ":", "\n", "      ", "r", "=", "sess", ".", "post", "(", "url", ",", "params", "=", "params", ",", "data", "=", "data", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "", "r", ".", "encoding", "=", "'utf-8'", "\n", "try", ":", "\n", "      ", "json_response", "=", "json", ".", "loads", "(", "r", ".", "text", ",", "strict", "=", "False", ")", "\n", "", "except", "json", ".", "JSONDecodeError", ":", "\n", "      ", "raise", "ValueError", "(", "\"CoreNLP error: \"", "+", "r", ".", "text", ")", "\n", "", "return", "json_response", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.corenlp_client.CoreNLPClient.query_tokenize": [[44, 52], ["corenlp_client.CoreNLPClient.query"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.corenlp_client.CoreNLPClient.query"], ["", "def", "query_tokenize", "(", "self", ",", "sents", ",", "sess", "=", "None", ")", ":", "\n", "    ", "\"\"\"Standard query for getting POS tags.\"\"\"", "\n", "properties", "=", "{", "\n", "'ssplit.newlineIsSentenceBreak'", ":", "'always'", ",", "\n", "'annotators'", ":", "'tokenize,ssplit'", ",", "\n", "'outputFormat'", ":", "'json'", "\n", "}", "\n", "return", "self", ".", "query", "(", "sents", ",", "properties", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.corenlp_client.CoreNLPClient.query_ner": [[53, 64], ["corenlp_client.CoreNLPClient.query"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.corenlp_client.CoreNLPClient.query"], ["", "def", "query_ner", "(", "self", ",", "paragraphs", ",", "sess", "=", "None", ",", "whitespace", "=", "False", ")", ":", "\n", "    ", "\"\"\"Standard query for getting NERs on raw paragraphs.\"\"\"", "\n", "annotators", "=", "'tokenize,ssplit,pos,ner,entitymentions'", "\n", "properties", "=", "{", "\n", "'ssplit.newlineIsSentenceBreak'", ":", "'always'", ",", "\n", "'annotators'", ":", "annotators", ",", "\n", "'outputFormat'", ":", "'json'", "\n", "}", "\n", "if", "whitespace", ":", "\n", "      ", "properties", "[", "\"tokenize.whitespace\"", "]", "=", "True", "\n", "", "return", "self", ".", "query", "(", "paragraphs", ",", "properties", ",", "sess", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_squad.SquadAnnotator.__init__": [[23, 32], ["regex.compile"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "port", ",", "intern", "=", "False", ",", "resplit", "=", "True", ")", ":", "\n", "    ", "self", ".", "port", "=", "port", "\n", "self", ".", "intern", "=", "intern", "\n", "self", ".", "resplit", "=", "resplit", "\n", "if", "self", ".", "resplit", ":", "\n", "      ", "resplit", "=", "r\"\\p{Pd}\\p{Po}\\p{Ps}\\p{Pe}\\p{S}\\p{Pc}\"", "\n", "resplit", "=", "\"([\"", "+", "resplit", "+", "\"]|'')\"", "\n", "split_regex", "=", "r\"(?![\\.,'])\"", "+", "resplit", "\n", "self", ".", "split_regex", "=", "regex", ".", "compile", "(", "split_regex", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_squad.SquadAnnotator.process": [[33, 121], ["debias.preprocessing.corenlp_client.CoreNLPClient", "passage[].isspace", "numpy.array", "numpy.array", "out.append", "debias.preprocessing.corenlp_client.CoreNLPClient.query_ner", "NotImplementedError", "sum", "len", "RuntimeError", "debias.utils.py_utils.flatten_list", "enumerate", "questions.append", "debias.datasets.squad.AnnotatedSquadParagraph", "numpy.array.append", "len", "debias.utils.py_utils.get_containing_spans", "answer_spans.append", "answers_text.append", "debias.datasets.squad.SquadQuestion", "len", "RuntimeError", "len", "RuntimeError", "numpy.array", "len", "len", "words.append", "pos.append", "ner.append", "numpy.array.append", "len", "len", "len", "numpy.array.append", "len", "RuntimeError", "debias.preprocessing.corenlp_client.CoreNLPClient.query_tokenize", "build_annotated_squad.SquadAnnotator.split_regex.split", "build_annotated_squad.SquadAnnotator.split_regex.match", "len", "len"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.corenlp_client.CoreNLPClient.query_ner", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.flatten_list", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.get_containing_spans", "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.corenlp_client.CoreNLPClient.query_tokenize", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split"], ["", "", "def", "process", "(", "self", ",", "data", ":", "Iterable", "[", "Dict", "]", ")", "->", "List", "[", "AnnotatedSquadParagraph", "]", ":", "\n", "    ", "client", "=", "CoreNLPClient", "(", "port", "=", "self", ".", "port", ")", "\n", "out", "=", "[", "]", "\n", "\n", "for", "para", "in", "data", ":", "\n", "      ", "passage", "=", "para", "[", "'context'", "]", "\n", "\n", "offset", "=", "0", "\n", "while", "passage", "[", "offset", "]", ".", "isspace", "(", ")", ":", "\n", "        ", "offset", "+=", "1", "\n", "", "annotations", "=", "client", ".", "query_ner", "(", "passage", "[", "offset", ":", "]", ")", "[", "\"sentences\"", "]", "\n", "\n", "if", "self", ".", "resplit", ":", "\n", "# We re-split the CORENLP tokens on some punctuation tags, since we need pretty aggressive tokenization", "\n", "# in ensure (almost) all answers span are contained within tokens", "\n", "        ", "words", ",", "pos", ",", "ner", ",", "inv", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "sentence_lens", "=", "[", "]", "\n", "on_len", "=", "0", "\n", "for", "sentences", "in", "annotations", ":", "\n", "          ", "if", "len", "(", "sentences", "[", "\"tokens\"", "]", ")", "==", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", ")", "\n", "", "for", "token", "in", "sentences", "[", "\"tokens\"", "]", ":", "\n", "            ", "p", ",", "n", "=", "token", "[", "\"pos\"", "]", ",", "token", "[", "\"ner\"", "]", "\n", "s", ",", "e", "=", "(", "token", "[", "\"characterOffsetBegin\"", "]", ",", "token", "[", "\"characterOffsetEnd\"", "]", ")", "\n", "if", "len", "(", "token", "[", "\"originalText\"", "]", ")", "!=", "(", "e", "-", "s", ")", ":", "\n", "# For some reason (probably due to unicode-shenanigans) the character offsets", "\n", "# we get make are sometime incorrect, we fix it here", "\n", "              ", "offset", "-=", "(", "e", "-", "s", ")", "-", "len", "(", "token", "[", "\"originalText\"", "]", ")", "\n", "", "s", "+=", "offset", "\n", "e", "+=", "offset", "\n", "\n", "w", "=", "passage", "[", "s", ":", "e", "]", "\n", "\n", "if", "w", "==", "\"''\"", "or", "w", "==", "'``'", ":", "\n", "              ", "split", "=", "[", "w", "]", "\n", "", "else", ":", "\n", "              ", "split", "=", "[", "x", "for", "x", "in", "self", ".", "split_regex", ".", "split", "(", "w", ")", "if", "len", "(", "x", ")", ">", "0", "]", "\n", "\n", "", "if", "len", "(", "split", ")", "==", "1", ":", "\n", "              ", "words", ".", "append", "(", "w", ")", "\n", "pos", ".", "append", "(", "p", ")", "\n", "ner", ".", "append", "(", "n", ")", "\n", "inv", ".", "append", "(", "(", "s", ",", "e", ")", ")", "\n", "", "else", ":", "\n", "              ", "words", "+=", "split", "\n", "ner", "+=", "[", "n", "]", "*", "len", "(", "split", ")", "\n", "pos", "+=", "[", "'SEP'", "if", "self", ".", "split_regex", ".", "match", "(", "x", ")", "else", "p", "for", "x", "in", "split", "]", "\n", "\n", "for", "w", "in", "split", ":", "\n", "                ", "inv", ".", "append", "(", "(", "s", ",", "s", "+", "len", "(", "w", ")", ")", ")", "\n", "s", "+=", "len", "(", "w", ")", "\n", "", "if", "s", "!=", "e", ":", "\n", "                ", "raise", "RuntimeError", "(", ")", "\n", "\n", "", "", "", "sentence_lens", ".", "append", "(", "len", "(", "words", ")", "-", "on_len", ")", "\n", "on_len", "=", "len", "(", "words", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "inv", "=", "np", ".", "array", "(", "inv", ",", "np", ".", "int32", ")", "\n", "sentence_lens", "=", "np", ".", "array", "(", "sentence_lens", ",", "np", ".", "int32", ")", "\n", "if", "sum", "(", "sentence_lens", ")", "!=", "len", "(", "words", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", ")", "\n", "\n", "", "questions", "=", "[", "]", "\n", "for", "question", "in", "para", "[", "\"qas\"", "]", ":", "\n", "        ", "q_tokens", "=", "py_utils", ".", "flatten_list", "(", "[", "x", "[", "\"tokens\"", "]", "for", "x", "in", "client", ".", "query_tokenize", "(", "question", "[", "\"question\"", "]", ")", "[", "\"sentences\"", "]", "]", ")", "\n", "\n", "answer_spans", "=", "[", "]", "\n", "answers_text", "=", "[", "]", "\n", "for", "answer_ix", ",", "answer", "in", "enumerate", "(", "question", "[", "'answers'", "]", ")", ":", "\n", "          ", "answer_raw", "=", "answer", "[", "'text'", "]", "\n", "answer_start", "=", "answer", "[", "'answer_start'", "]", "\n", "answer_stop", "=", "answer_start", "+", "len", "(", "answer_raw", ")", "\n", "if", "passage", "[", "answer_start", ":", "answer_stop", "]", "!=", "answer_raw", ":", "\n", "            ", "raise", "RuntimeError", "(", ")", "\n", "", "word_ixs", "=", "get_containing_spans", "(", "inv", ",", "answer_start", ",", "answer_stop", ")", "\n", "answer_spans", ".", "append", "(", "(", "word_ixs", "[", "0", "]", ",", "word_ixs", "[", "-", "1", "]", ")", ")", "\n", "answers_text", ".", "append", "(", "answer_raw", ")", "\n", "\n", "", "questions", ".", "append", "(", "SquadQuestion", "(", "\n", "question", "[", "\"id\"", "]", ",", "[", "x", "[", "\"word\"", "]", "for", "x", "in", "q_tokens", "]", ",", "\n", "answers_text", ",", "np", ".", "array", "(", "answer_spans", ",", "dtype", "=", "np", ".", "int32", ")", ",", "\n", ")", ")", "\n", "\n", "", "out", ".", "append", "(", "AnnotatedSquadParagraph", "(", "\n", "passage", ",", "words", ",", "inv", ",", "pos", ",", "ner", ",", "sentence_lens", ",", "questions", ")", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_squad.cache_docs": [[123, 134], ["build_annotated_squad.SquadAnnotator", "debias.utils.py_utils.flatten_list", "debias.utils.process_par.process_par", "open", "open", "pickle.dump", "json.load"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.flatten_list", "home.repos.pwc.inspect_result.chrisc36_debias.utils.process_par.process_par", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadLoader.load"], ["", "", "def", "cache_docs", "(", "source_file", ",", "output_file", ",", "port", ",", "n_processes", ")", ":", "\n", "  ", "annotator", "=", "SquadAnnotator", "(", "port", ",", "True", ")", "\n", "with", "open", "(", "source_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "    ", "docs", "=", "json", ".", "load", "(", "f", ")", "[", "\"data\"", "]", "\n", "\n", "", "paragraphs", "=", "py_utils", ".", "flatten_list", "(", "x", "[", "\"paragraphs\"", "]", "for", "x", "in", "docs", ")", "\n", "\n", "annotated", "=", "process_par", "(", "paragraphs", ",", "annotator", ",", "n_processes", ",", "30", ",", "\"annotate\"", ")", "\n", "\n", "with", "open", "(", "output_file", ",", "\"wb\"", ")", "as", "f", ":", "\n", "    ", "pickle", ".", "dump", "(", "annotated", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_squad.main": [[136, 144], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "build_annotated_squad.cache_docs"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.preprocessing.build_annotated_squad.cache_docs"], ["", "", "def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"source_file\"", ",", "help", "=", "\"SQuAD source file\"", ")", "\n", "parser", ".", "add_argument", "(", "\"output_file\"", ",", "help", "=", "\"Output pickle file to dump the annotated paragraphs\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--port\"", ",", "type", "=", "int", ",", "default", "=", "9000", ",", "help", "=", "\"CoreNLP port\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_processes\"", ",", "\"-n\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "cache_docs", "(", "args", ".", "source_file", ",", "args", ".", "output_file", ",", "args", ".", "port", ",", "args", ".", "n_processes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_pickle": [[26, 30], ["open", "pickle.load"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadLoader.load"], ["def", "load_pickle", "(", "filename", ")", ":", "\n", "  ", "\"\"\"Load an object from a pickled file.\"\"\"", "\n", "with", "open", "(", "filename", ",", "\"rb\"", ")", "as", "f", ":", "\n", "    ", "return", "pickle", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_json": [[32, 36], ["open", "json.load"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadLoader.load"], ["", "", "def", "load_json", "(", "filename", ")", ":", "\n", "  ", "\"\"\"Load an object from a json file.\"\"\"", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "    ", "return", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.transpose_lists": [[38, 41], ["list", "zip"], "function", ["None"], ["", "", "def", "transpose_lists", "(", "lsts", ":", "Iterable", "[", "Iterable", "[", "T", "]", "]", ")", "->", "List", "[", "List", "[", "T", "]", "]", ":", "\n", "  ", "\"\"\"Transpose a list of lists.\"\"\"", "\n", "return", "[", "list", "(", "i", ")", "for", "i", "in", "zip", "(", "*", "lsts", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.flatten_list": [[43, 46], ["None"], "function", ["None"], ["", "def", "flatten_list", "(", "iterable_of_lists", ":", "Iterable", "[", "Iterable", "[", "T", "]", "]", ")", "->", "List", "[", "T", "]", ":", "\n", "  ", "\"\"\"Unpack lists into a single list.\"\"\"", "\n", "return", "[", "x", "for", "sublist", "in", "iterable_of_lists", "for", "x", "in", "sublist", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split": [[48, 62], ["range", "len", "len", "groups.append"], "function", ["None"], ["", "def", "split", "(", "lst", ":", "List", "[", "T", "]", ",", "n_groups", ")", "->", "List", "[", "List", "[", "T", "]", "]", ":", "\n", "  ", "\"\"\" partition `lst` into `n_groups` that are as evenly sized as possible  \"\"\"", "\n", "per_group", "=", "len", "(", "lst", ")", "//", "n_groups", "\n", "remainder", "=", "len", "(", "lst", ")", "%", "n_groups", "\n", "groups", "=", "[", "]", "\n", "ix", "=", "0", "\n", "for", "_", "in", "range", "(", "n_groups", ")", ":", "\n", "    ", "group_size", "=", "per_group", "\n", "if", "remainder", ">", "0", ":", "\n", "      ", "remainder", "-=", "1", "\n", "group_size", "+=", "1", "\n", "", "groups", ".", "append", "(", "lst", "[", "ix", ":", "ix", "+", "group_size", "]", ")", "\n", "ix", "+=", "group_size", "\n", "", "return", "groups", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.group": [[64, 82], ["range", "len", "len", "groups.append", "len"], "function", ["None"], ["", "def", "group", "(", "lst", ":", "List", "[", "T", "]", ",", "max_group_size", ")", "->", "List", "[", "List", "[", "T", "]", "]", ":", "\n", "  ", "\"\"\"partition `lst` into that the mininal number of groups that as evenly sized\n  as possible  and are at most `max_group_size` in size \"\"\"", "\n", "if", "max_group_size", "is", "None", ":", "\n", "    ", "return", "[", "lst", "]", "\n", "", "n_groups", "=", "(", "len", "(", "lst", ")", "+", "max_group_size", "-", "1", ")", "//", "max_group_size", "\n", "per_group", "=", "len", "(", "lst", ")", "//", "n_groups", "\n", "remainder", "=", "len", "(", "lst", ")", "%", "n_groups", "\n", "groups", "=", "[", "]", "\n", "ix", "=", "0", "\n", "for", "_", "in", "range", "(", "n_groups", ")", ":", "\n", "    ", "group_size", "=", "per_group", "\n", "if", "remainder", ">", "0", ":", "\n", "      ", "remainder", "-=", "1", "\n", "group_size", "+=", "1", "\n", "", "groups", ".", "append", "(", "lst", "[", "ix", ":", "ix", "+", "group_size", "]", ")", "\n", "ix", "+=", "group_size", "\n", "", "return", "groups", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.add_stdout_logger": [[84, 100], ["logging.StreamHandler", "logging.Formatter", "logging.StreamHandler.setFormatter", "logging.StreamHandler.setLevel", "logging.getLogger", "logging.getLogger.setLevel", "logging.getLogger.addHandler"], "function", ["None"], ["", "def", "add_stdout_logger", "(", ")", ":", "\n", "  ", "\"\"\"Setup stdout logging\"\"\"", "\n", "if", "tf_deprecation", "is", "not", "None", ":", "\n", "# Tensorflow really wants to let us know about all the to-be-deprecated tf 1.13.1 functions,", "\n", "# some of which are called within the tensorflow library. Tell it to quite down", "\n", "    ", "tf_deprecation", ".", "_PRINT_DEPRECATION_WARNINGS", "=", "False", "\n", "\n", "", "handler", "=", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s - %(levelname)s - %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", ")", "\n", "handler", ".", "setFormatter", "(", "formatter", ")", "\n", "handler", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "\n", "root", "=", "logging", ".", "getLogger", "(", ")", "\n", "root", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "root", ".", "addHandler", "(", "handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.get_containing_spans": [[102, 112], ["enumerate", "idxs.append"], "function", ["None"], ["", "def", "get_containing_spans", "(", "spans", ":", "np", ".", "ndarray", ",", "start", ":", "int", ",", "stop", ":", "int", ")", ":", "\n", "  ", "\"\"\"Get indices of the sorted spans in `spans` that overlap with `start` and `stop`\"\"\"", "\n", "idxs", "=", "[", "]", "\n", "for", "word_ix", ",", "(", "s", ",", "e", ")", "in", "enumerate", "(", "spans", ")", ":", "\n", "    ", "if", "e", ">", "start", ":", "\n", "      ", "if", "s", "<", "stop", ":", "\n", "        ", "idxs", ".", "append", "(", "word_ix", ")", "\n", "", "else", ":", "\n", "        ", "break", "\n", "", "", "", "return", "idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.ensure_dir_exists": [[114, 117], ["os.makedirs", "os.path.dirname"], "function", ["None"], ["", "def", "ensure_dir_exists", "(", "filename", ")", ":", "\n", "  ", "\"\"\"Make sure the parent directory of `filename` exists\"\"\"", "\n", "makedirs", "(", "dirname", "(", "filename", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_to_file": [[119, 126], ["py_utils.ensure_dir_exists", "requests.get", "r.raise_for_status", "open", "f.write"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.ensure_dir_exists"], ["", "def", "download_to_file", "(", "url", ",", "output_file", ")", ":", "\n", "  ", "\"\"\"Download `url` to `output_file`, intended for small files.\"\"\"", "\n", "ensure_dir_exists", "(", "output_file", ")", "\n", "with", "requests", ".", "get", "(", "url", ")", "as", "r", ":", "\n", "    ", "r", ".", "raise_for_status", "(", ")", "\n", "with", "open", "(", "output_file", ",", "'wb'", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "r", ".", "content", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_zip": [[128, 142], ["os.makedirs", "logging.info", "tempfile.TemporaryFile", "logging.info", "requests.get", "py_utils._write_to_stream", "zipfile.ZipFile", "f.extractall"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils._write_to_stream"], ["", "", "", "def", "download_zip", "(", "name", ",", "url", ",", "source", ",", "progress_bar", "=", "True", ")", ":", "\n", "  ", "\"\"\"Download zip file at `url` and extract to `source`\"\"\"", "\n", "makedirs", "(", "source", ",", "exist_ok", "=", "True", ")", "\n", "logging", ".", "info", "(", "\"Downloading %s\"", "%", "name", ")", "\n", "\n", "# Probably best to download to a temp file to ensure we", "\n", "# don't eat a lot of RAM with downloading a large file", "\n", "tmp_f", "=", "tempfile", ".", "TemporaryFile", "(", ")", "\n", "with", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "as", "r", ":", "\n", "    ", "_write_to_stream", "(", "r", ",", "tmp_f", ",", "progress_bar", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Extracting to %s....\"", "%", "source", ")", "\n", "with", "zipfile", ".", "ZipFile", "(", "tmp_f", ")", "as", "f", ":", "\n", "    ", "f", ".", "extractall", "(", "source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_from_drive": [[147, 165], ["py_utils.ensure_dir_exists", "requests.Session", "requests.Session.get", "session.get.cookies.items", "session.get.close", "key.startswith", "open", "py_utils._write_to_stream", "requests.Session.get"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.ensure_dir_exists", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils._write_to_stream"], ["def", "download_from_drive", "(", "file_id", ",", "output_file", ",", "progress_bar", "=", "False", ")", ":", "\n", "  ", "\"\"\"Download the public google drive file `file_id` to `output_file`\"\"\"", "\n", "ensure_dir_exists", "(", "output_file", ")", "\n", "\n", "session", "=", "requests", ".", "Session", "(", ")", "\n", "\n", "response", "=", "session", ".", "get", "(", "DRIVE_URL", ",", "params", "=", "{", "'id'", ":", "file_id", "}", ",", "stream", "=", "True", ")", "\n", "\n", "# Check to see if we need to send a second, confirm, request", "\n", "# https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url", "\n", "for", "key", ",", "value", "in", "response", ".", "cookies", ".", "items", "(", ")", ":", "\n", "    ", "if", "key", ".", "startswith", "(", "'download_warning'", ")", ":", "\n", "      ", "params", "=", "{", "'id'", ":", "file_id", ",", "'confirm'", ":", "value", "}", "\n", "response", "=", "session", ".", "get", "(", "DRIVE_URL", ",", "params", "=", "params", ",", "stream", "=", "True", ")", "\n", "\n", "", "", "with", "open", "(", "output_file", ",", "\"wb\"", ")", "as", "f", ":", "\n", "    ", "_write_to_stream", "(", "response", ",", "f", ",", "progress_bar", ")", "\n", "", "response", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils._write_to_stream": [[167, 198], ["response.raise_for_status", "response.iter_content", "response.headers.get", "tqdm.tqdm", "tqdm.tqdm.close", "output_fh.write", "tqdm.tqdm.update", "math.ceil", "len", "tqdm.tqdm.update", "math.floor", "float"], "function", ["None"], ["", "def", "_write_to_stream", "(", "response", ",", "output_fh", ",", "progress_bar", "=", "True", ",", "chunk_size", "=", "32768", ")", ":", "\n", "  ", "\"\"\"Write streaming `response` to `output_fs` in chunks\"\"\"", "\n", "mb", "=", "1024", "*", "1024", "\n", "response", ".", "raise_for_status", "(", ")", "\n", "if", "progress_bar", ":", "\n", "# tqdm does not format decimal numbers. We could in theory add decimal formatting", "\n", "# using the `bar_format` arg, but in practice doing so is finicky, in particular it", "\n", "# seems impossible to properly format the `rate` parameter. Instead we just manually", "\n", "# ensure the 'total' and 'n' values of the bar are rounded to the 10th decimal place", "\n", "    ", "content_len", "=", "response", ".", "headers", ".", "get", "(", "\"Content-Length\"", ")", "\n", "if", "content_len", "is", "not", "None", ":", "\n", "      ", "total", "=", "math", ".", "ceil", "(", "10", "*", "float", "(", "content_len", ")", "/", "mb", ")", "/", "10", "\n", "", "else", ":", "\n", "      ", "total", "=", "None", "\n", "", "pbar", "=", "tqdm", "(", "desc", "=", "\"downloading\"", ",", "total", "=", "total", ",", "ncols", "=", "100", ",", "unit", "=", "\"mb\"", ")", "\n", "", "else", ":", "\n", "    ", "pbar", "=", "None", "\n", "\n", "", "cur_total", "=", "0", "\n", "for", "chunk", "in", "response", ".", "iter_content", "(", "chunk_size", "=", "chunk_size", ")", ":", "\n", "    ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "      ", "if", "pbar", "is", "not", "None", ":", "\n", "        ", "cur_total", "+=", "len", "(", "chunk", ")", "\n", "next_value", "=", "math", ".", "floor", "(", "10", "*", "cur_total", "/", "mb", ")", "/", "10.0", "\n", "pbar", ".", "update", "(", "next_value", "-", "pbar", ".", "n", ")", "\n", "", "output_fh", ".", "write", "(", "chunk", ")", "\n", "\n", "", "", "if", "pbar", "is", "not", "None", ":", "\n", "    ", "if", "pbar", ".", "total", "is", "not", "None", ":", "\n", "      ", "pbar", ".", "update", "(", "pbar", ".", "total", "-", "pbar", ".", "n", ")", "# Fix rounding errors just for neatness", "\n", "", "pbar", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.cli_utils.add_general_args": [[7, 15], ["parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["def", "add_general_args", "(", "parser", ":", "ArgumentParser", ")", ":", "\n", "  ", "\"\"\"Arguments that are common between all experiments\"\"\"", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "\"-o\"", ",", "default", "=", "None", ",", "\n", "help", "=", "\"Place to store the model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_processes\"", ",", "\"-n\"", ",", "type", "=", "int", ",", "default", "=", "4", ",", "\n", "help", "=", "\"Number of processes to use when pre-processing\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--debug\"", ",", "\"--dbg\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Run on smaller model on a sample of the data\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.cli_utils.add_loss_args": [[17, 23], ["argparser.add_argument", "argparser.add_argument"], "function", ["None"], ["", "def", "add_loss_args", "(", "argparser", ":", "ArgumentParser", ",", "default_penalty", ")", ":", "\n", "  ", "\"\"\"Arguments for selecting the loss function\"\"\"", "\n", "argparser", ".", "add_argument", "(", "\"--mode\"", ",", "choices", "=", "[", "\"bias_product\"", ",", "\"none\"", ",", "\"learned_mixin\"", ",", "\"reweight\"", "]", ",", "\n", "default", "=", "\"learned_mixin\"", ",", "help", "=", "\"Kind of debiasing method to use\"", ")", "\n", "argparser", ".", "add_argument", "(", "\"--penalty\"", ",", "type", "=", "float", ",", "default", "=", "default_penalty", ",", "\n", "help", "=", "\"Penalty weight for the learn_mixin model\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.cli_utils.get_clf_loss_fn": [[25, 37], ["debias.modules.clf_debias_loss_functions.Plain", "debias.modules.clf_debias_loss_functions.Reweight", "debias.modules.clf_debias_loss_functions.BiasProduct", "debias.modules.clf_debias_loss_functions.LearnedMixin", "RuntimeError"], "function", ["None"], ["", "def", "get_clf_loss_fn", "(", "args", ")", "->", "clf_debias_loss_functions", ".", "ClfDebiasLossFunction", ":", "\n", "  ", "if", "args", ".", "mode", "==", "\"none\"", ":", "\n", "    ", "fn", "=", "clf_debias_loss_functions", ".", "Plain", "(", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"reweight\"", ":", "\n", "    ", "fn", "=", "clf_debias_loss_functions", ".", "Reweight", "(", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"bias_product\"", ":", "\n", "    ", "fn", "=", "clf_debias_loss_functions", ".", "BiasProduct", "(", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"learned_mixin\"", ":", "\n", "    ", "fn", "=", "clf_debias_loss_functions", ".", "LearnedMixin", "(", "args", ".", "penalty", ")", "\n", "", "else", ":", "\n", "    ", "raise", "RuntimeError", "(", ")", "\n", "", "return", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.cli_utils.get_qa_loss_fn": [[39, 51], ["debias.modules.qa_debias_loss_functions.Plain", "debias.modules.qa_debias_loss_functions.Reweight", "debias.modules.qa_debias_loss_functions.BiasProduct", "debias.modules.qa_debias_loss_functions.LearnedMixin", "RuntimeError"], "function", ["None"], ["", "def", "get_qa_loss_fn", "(", "args", ")", "->", "qa_debias_loss_functions", ".", "QaDebiasLossFunction", ":", "\n", "  ", "if", "args", ".", "mode", "==", "\"none\"", ":", "\n", "    ", "fn", "=", "qa_debias_loss_functions", ".", "Plain", "(", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"reweight\"", ":", "\n", "    ", "fn", "=", "qa_debias_loss_functions", ".", "Reweight", "(", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"bias_product\"", ":", "\n", "    ", "fn", "=", "qa_debias_loss_functions", ".", "BiasProduct", "(", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"learned_mixin\"", ":", "\n", "    ", "fn", "=", "qa_debias_loss_functions", ".", "LearnedMixin", "(", "args", ".", "penalty", ")", "\n", "", "else", ":", "\n", "    ", "raise", "RuntimeError", "(", ")", "\n", "", "return", "fn", "\n", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_shape_tuple": [[5, 18], ["x.shape.as_list", "tensorflow.shape", "range", "len", "tensorflow.shape"], "function", ["None"], ["def", "get_shape_tuple", "(", "x", ",", "axis", "=", "None", ")", ":", "\n", "  ", "\"\"\"Shape of a tensor as a tuple composed of ints or scalar int tensors\"\"\"", "\n", "s", "=", "x", ".", "shape", ".", "as_list", "(", ")", "\n", "if", "axis", "is", "None", ":", "\n", "    ", "tf_shape", "=", "tf", ".", "shape", "(", "x", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "s", ")", ")", ":", "\n", "      ", "if", "s", "[", "i", "]", "is", "None", ":", "\n", "        ", "s", "[", "i", "]", "=", "tf_shape", "[", "i", "]", "\n", "", "", "return", "s", "\n", "", "if", "s", "[", "axis", "]", "is", "None", ":", "\n", "    ", "return", "tf", ".", "shape", "(", "x", ")", "[", "axis", "]", "\n", "", "else", ":", "\n", "    ", "return", "s", "[", "axis", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.flatten": [[20, 27], ["x.shape.as_list", "any", "tensorflow.reshape", "tensorflow.reshape", "numpy.prod"], "function", ["None"], ["", "", "def", "flatten", "(", "x", ")", ":", "\n", "  ", "\"\"\"Flatten x while trying to preserve shape information\"\"\"", "\n", "sh", "=", "x", ".", "shape", ".", "as_list", "(", ")", "\n", "if", "any", "(", "x", "is", "None", "for", "x", "in", "sh", ")", ":", "\n", "    ", "return", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "    ", "return", "tf", ".", "reshape", "(", "x", ",", "[", "np", ".", "prod", "(", "sh", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.affine": [[29, 43], ["tensorflow.get_variable", "tensorflow.tensordot", "x.shape.as_list", "tensorflow.get_variable", "range", "tensorflow.expand_dims", "tensorflow.zeros_initializer", "len", "len"], "function", ["None"], ["", "", "def", "affine", "(", "x", ",", "output_size", ":", "int", ",", "weight_name", ":", "str", ",", "bias_name", "=", "None", ",", "weight_init", "=", "None", ")", ":", "\n", "  ", "\"\"\"Affine transformation of `x` using the specified variable names\"\"\"", "\n", "dim", "=", "x", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "w", "=", "tf", ".", "get_variable", "(", "\n", "weight_name", ",", "(", "dim", ",", "output_size", ")", ",", "tf", ".", "float32", ",", "initializer", "=", "weight_init", ")", "\n", "out", "=", "tf", ".", "tensordot", "(", "x", ",", "w", ",", "[", "[", "len", "(", "x", ".", "shape", ")", "-", "1", "]", ",", "[", "0", "]", "]", ")", "\n", "\n", "if", "bias_name", ":", "\n", "    ", "b", "=", "tf", ".", "get_variable", "(", "\n", "bias_name", ",", "(", "output_size", ",", ")", ",", "tf", ".", "float32", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "for", "_", "in", "range", "(", "len", "(", "out", ".", "shape", ")", "-", "1", ")", ":", "\n", "      ", "b", "=", "tf", ".", "expand_dims", "(", "b", ",", "0", ")", "\n", "", "out", "+=", "b", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.last_dim_weighted_sum": [[45, 54], ["tensorflow.get_variable", "tensorflow.tensordot", "x.shape.as_list", "tensorflow.expand_dims", "len", "len"], "function", ["None"], ["", "def", "last_dim_weighted_sum", "(", "x", ",", "weight_name", ",", "weight_init", "=", "None", ",", "keepdims", "=", "False", ")", ":", "\n", "  ", "\"\"\"Weighted sum of the last dim of a tensor using the given weight name\"\"\"", "\n", "dim", "=", "x", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "w", "=", "tf", ".", "get_variable", "(", "weight_name", ",", "dim", ",", "initializer", "=", "weight_init", ")", "\n", "out", "=", "tf", ".", "tensordot", "(", "x", ",", "w", ",", "[", "[", "len", "(", "x", ".", "shape", ")", "-", "1", "]", ",", "[", "0", "]", "]", ")", "\n", "if", "keepdims", ":", "\n", "    ", "return", "tf", ".", "expand_dims", "(", "out", ",", "len", "(", "out", ".", "shape", ")", ")", "\n", "", "else", ":", "\n", "    ", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.entropy": [[56, 65], ["tensorflow.nn.log_softmax", "tensorflow.exp", "ops.mask_logits", "tensorflow.sequence_mask", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.shape", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.mask_logits"], ["", "", "def", "entropy", "(", "logits", ",", "mask", "=", "None", ")", ":", "\n", "  ", "\"\"\"Compute the entropy of the probabilities implied by `logit`\"\"\"", "\n", "logits", "=", "tf", ".", "nn", ".", "log_softmax", "(", "mask_logits", "(", "logits", ",", "mask", ")", ")", "\n", "prob", "=", "tf", ".", "exp", "(", "logits", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "    ", "f_mask", "=", "tf", ".", "sequence_mask", "(", "mask", ",", "tf", ".", "shape", "(", "logits", ")", "[", "1", "]", ",", "tf", ".", "float32", ")", "\n", "return", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "prob", "*", "(", "logits", "*", "f_mask", ")", ",", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "    ", "return", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "prob", "*", "logits", ",", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.max_pool": [[67, 74], ["tensorflow.maximum", "tensorflow.sequence_mask", "tensorflow.expand_dims", "tensorflow.reduce_max", "ops.get_shape_tuple"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_shape_tuple"], ["", "", "def", "max_pool", "(", "x", ",", "mask", ")", ":", "\n", "  ", "\"\"\"Max pool along dimension 1 followed by RELu\"\"\"", "\n", "if", "mask", "is", "not", "None", ":", "\n", "    ", "mask", "=", "tf", ".", "sequence_mask", "(", "mask", ",", "get_shape_tuple", "(", "x", ",", "1", ")", ",", "tf", ".", "float32", ")", "\n", "mask", "=", "tf", ".", "expand_dims", "(", "mask", ",", "2", ")", "\n", "x", "*=", "mask", "\n", "", "return", "tf", ".", "maximum", "(", "tf", ".", "reduce_max", "(", "x", ",", "-", "2", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.bucket_by_quantiles": [[76, 117], ["len", "any", "tensorflow.get_local_variable", "tensorflow.constant", "tensorflow.contrib.data.group_by_window", "ValueError", "ValueError", "tensorflow.zeros_initializer", "len_fn", "tensorflow.to_int64", "tensorflow.pad", "tensorflow.assign_add", "tensorflow.floordiv", "x.padded_batch", "tensorflow.to_int64", "tensorflow.greater", "tensorflow.reduce_sum", "range", "ValueError"], "function", ["None"], ["", "def", "bucket_by_quantiles", "(", "len_fn", ",", "batch_size", ",", "n_buckets", ",", "hist_bounds", ")", ":", "\n", "  ", "n_hist_binds", "=", "len", "(", "hist_bounds", ")", "\n", "\n", "if", "n_hist_binds", "<", "n_buckets", ":", "\n", "    ", "raise", "ValueError", "(", "\"Requested %d buckets, but only have %d histogram bins\"", "%", "\n", "(", "n_buckets", ",", "n_hist_binds", ")", ")", "\n", "", "if", "any", "(", "hist_bounds", "[", "i", "]", ">=", "hist_bounds", "[", "i", "+", "1", "]", "for", "i", "in", "range", "(", "n_hist_binds", "-", "1", ")", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\"Bins must be descending\"", ")", "\n", "\n", "# The hisogram: A count of the number of elements whose length was", "\n", "# greater than a fixed set values (so `hist_counts[i]` is the number of elements", "\n", "# with size > hist_bounds[i]_", "\n", "# Need to use `use_resource = True` to make this work correctly", "\n", "# within tf.data.Dataset", "\n", "", "hist_counts", "=", "tf", ".", "get_local_variable", "(", "\n", "\"hist-counts\"", ",", "n_hist_binds", "+", "1", ",", "tf", ".", "int64", ",", "\n", "tf", ".", "zeros_initializer", "(", ")", ",", "use_resource", "=", "True", ")", "\n", "hist_bounds", "=", "tf", ".", "constant", "(", "hist_bounds", ",", "tf", ".", "int64", ")", "\n", "\n", "def", "bucket_fn", "(", "x", ")", ":", "\n", "    ", "\"\"\"Compute the element bucket and update the histogram.\"\"\"", "\n", "ix", "=", "len_fn", "(", "x", ")", "\n", "if", "ix", ".", "dtype", "==", "tf", ".", "int32", ":", "\n", "      ", "ix", "=", "tf", ".", "to_int64", "(", "ix", ")", "\n", "", "elif", "ix", ".", "dtype", "!=", "tf", ".", "int64", ":", "\n", "      ", "raise", "ValueError", "(", "\"Len function returned a non-int\"", ")", "\n", "\n", "", "adds_to_bins", "=", "tf", ".", "to_int64", "(", "tf", ".", "greater", "(", "hist_bounds", ",", "ix", ")", ")", "\n", "# pad with a 1 for the \"larger than all\" bin", "\n", "adds_to_bins", "=", "tf", ".", "pad", "(", "adds_to_bins", ",", "[", "[", "0", ",", "1", "]", "]", ",", "constant_values", "=", "1", ")", "\n", "new_counts", "=", "tf", ".", "assign_add", "(", "hist_counts", ",", "adds_to_bins", ")", "\n", "bin_ix", "=", "n_hist_binds", "-", "tf", ".", "reduce_sum", "(", "adds_to_bins", ")", "\n", "\n", "# Computes the quantile based on the counts of the exammple's bucket", "\n", "bucket_ix", "=", "tf", ".", "floordiv", "(", "(", "(", "n_buckets", "-", "1", ")", "*", "new_counts", "[", "bin_ix", "]", ")", ",", "new_counts", "[", "-", "1", "]", ")", "\n", "return", "bucket_ix", "\n", "\n", "", "def", "reduce_fn", "(", "_", ",", "x", ")", ":", "\n", "    ", "return", "x", ".", "padded_batch", "(", "batch_size", ",", "x", ".", "output_shapes", ")", "\n", "\n", "", "return", "tf", ".", "contrib", ".", "data", ".", "group_by_window", "(", "bucket_fn", ",", "reduce_fn", ",", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.as_initialized_variable": [[119, 133], ["tensorflow.py_func", "tf.py_func.set_shape", "tensorflow.get_local_variable", "tensorflow.get_variable"], "function", ["None"], ["", "def", "as_initialized_variable", "(", "x", ",", "var_name", ",", "local", "=", "True", ")", ":", "\n", "  ", "\"\"\"Build a variable the is initialized to `x`, but without adding\n  `x` to the tensorflow graph.\n\n  The main reason to do this is to avoid the tensorflow\n  graph becoming bloating with huge constants, which can make some operation very slow.\n  This is accomplished by `hiding` the variable behind a py_fun intitializer\n  \"\"\"", "\n", "init_fn", "=", "tf", ".", "py_func", "(", "lambda", ":", "x", ",", "[", "]", ",", "tf", ".", "float32", ",", "False", ")", "\n", "init_fn", ".", "set_shape", "(", "x", ".", "shape", ")", "\n", "if", "local", ":", "\n", "    ", "return", "tf", ".", "get_local_variable", "(", "var_name", ",", "initializer", "=", "init_fn", ")", "\n", "", "else", ":", "\n", "    ", "return", "tf", ".", "get_variable", "(", "var_name", ",", "initializer", "=", "init_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.mask_logits": [[135, 152], ["tensorflow.sequence_mask", "tensorflow.cast", "len", "tensorflow.expand_dims", "len", "ValueError", "len", "tensorflow.shape", "len"], "function", ["None"], ["", "", "def", "mask_logits", "(", "vec", ",", "mask", ")", ":", "\n", "  ", "\"\"\"Mask `vec` in logspace by setting out of bounds elements to very negative values\"\"\"", "\n", "if", "mask", "is", "None", ":", "\n", "    ", "return", "vec", "\n", "\n", "", "if", "mask", ".", "dtype", "==", "tf", ".", "int32", ":", "\n", "# Assume `mask` holds sequence lengths", "\n", "    ", "if", "len", "(", "vec", ".", "shape", ")", "not", "in", "[", "2", ",", "3", "]", ":", "\n", "      ", "raise", "ValueError", "(", "\"Can't use a length mask on tensor of rank>3\"", ")", "\n", "", "mask", "=", "tf", ".", "sequence_mask", "(", "mask", ",", "tf", ".", "shape", "(", "vec", ")", "[", "1", "]", ",", "tf", ".", "float32", ")", "\n", "", "else", ":", "\n", "    ", "mask", "=", "tf", ".", "cast", "(", "mask", ",", "tf", ".", "float32", ")", "\n", "\n", "", "if", "len", "(", "mask", ".", "shape", ")", "==", "(", "len", "(", "vec", ".", "shape", ")", "-", "1", ")", ":", "\n", "    ", "mask", "=", "tf", ".", "expand_dims", "(", "mask", ",", "len", "(", "vec", ".", "shape", ")", "-", "1", ")", "\n", "\n", "", "return", "vec", "*", "mask", "-", "(", "1", "-", "mask", ")", "*", "1E20", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_best_span": [[154, 180], ["tensorflow.reshape", "tensorflow.matrix_band_part", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.nn.top_k", "tensorflow.squeeze", "tensorflow.stack", "ops.get_shape_tuple", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.minimum", "tensorflow.ones", "tensorflow.to_int32", "tensorflow.log", "tensorflow.convert_to_tensor", "tensorflow.to_int32"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_shape_tuple"], ["", "def", "get_best_span", "(", "span_logits", ",", "bound", ")", ":", "\n", "  ", "\"\"\"Get spans with highest start+end score and length <= `bound`\n\n  :param span_logits: [batch, seq_len, 2] start/end scores\n  :param bound: Max span len\n  :return: [batch, 2] highest scoring spans\n  \"\"\"", "\n", "batch", ",", "time", "=", "get_shape_tuple", "(", "span_logits", ")", "[", ":", "2", "]", "\n", "\n", "# [batch, time, time], per-span scores", "\n", "scores", "=", "tf", ".", "expand_dims", "(", "span_logits", "[", ":", ",", ":", ",", "0", "]", ",", "2", ")", "+", "tf", ".", "expand_dims", "(", "span_logits", "[", ":", ",", ":", ",", "1", "]", ",", "1", ")", "\n", "scores", "=", "tf", ".", "reshape", "(", "scores", ",", "[", "batch", ",", "-", "1", "]", ")", "# flattened [batch, time*time]", "\n", "\n", "# Mask span beyond `bound`", "\n", "if", "bound", "is", "not", "None", ":", "\n", "    ", "bound", "=", "tf", ".", "minimum", "(", "tf", ".", "convert_to_tensor", "(", "bound", ",", "tf", ".", "int32", ")", ",", "time", ")", "\n", "", "bound_mask", "=", "tf", ".", "matrix_band_part", "(", "\n", "tf", ".", "ones", "(", "(", "time", ",", "time", ")", ")", ",", "tf", ".", "to_int32", "(", "0", ")", ",", "tf", ".", "to_int32", "(", "-", "1", ")", "if", "bound", "is", "None", "else", "bound", ")", "\n", "bound_mask", "=", "tf", ".", "reshape", "(", "bound_mask", ",", "[", "-", "1", "]", ")", "\n", "\n", "scores", "+=", "tf", ".", "expand_dims", "(", "tf", ".", "log", "(", "bound_mask", ")", ",", "0", ")", "# sets out-of-bounds span to -inf", "\n", "\n", "_", ",", "ix", "=", "tf", ".", "nn", ".", "top_k", "(", "scores", ",", "1", ",", "False", ")", "# get top spans", "\n", "ix", "=", "tf", ".", "squeeze", "(", "ix", ",", "1", ")", "\n", "spans", "=", "tf", ".", "stack", "(", "[", "ix", "//", "time", ",", "ix", "%", "time", "]", ",", "1", ")", "# convert non-flattened indices", "\n", "return", "spans", "\n", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.tokenizer.Tokenizer.tokenize": [[13, 15], ["NotImplementedError"], "methods", ["None"], ["  ", "def", "tokenize", "(", "self", ",", "text", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.tokenizer.Tokenizer.tokenize_with_inverse": [[16, 19], ["NotImplementedError"], "methods", ["None"], ["", "def", "tokenize_with_inverse", "(", "self", ",", "text", ":", "str", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "np", ".", "ndarray", "]", ":", "\n", "    ", "\"\"\"Tokenize the text, and return start/end character mapping of each token within `text`\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.tokenizer.NltkAndPunctTokenizer.__init__": [[49, 85], ["regex.compile", "nltk.TreebankWordTokenizer", "len", "nltk.load", "logging.info", "nltk.download", "nltk.load"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadLoader.load", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadLoader.load"], ["def", "__init__", "(", "self", ",", "split_dash", "=", "True", ",", "split_single_quote", "=", "False", ",", "split_period", "=", "False", ",", "split_comma", "=", "False", ")", ":", "\n", "    ", "self", ".", "split_dash", "=", "split_dash", "\n", "self", ".", "split_single_quote", "=", "split_single_quote", "\n", "self", ".", "split_period", "=", "split_period", "\n", "self", ".", "split_comma", "=", "split_comma", "\n", "\n", "# Unix character classes to split on", "\n", "resplit", "=", "r\"\\p{Pd}\\p{Po}\\p{Pe}\\p{S}\\p{Pc}\"", "\n", "\n", "# A list of optional exceptions, will we trust nltk to split them correctly", "\n", "# unless otherwise specified by the ini arguments", "\n", "dont_split", "=", "\"\"", "\n", "if", "not", "split_dash", ":", "\n", "      ", "dont_split", "+=", "\"\\-\"", "\n", "", "if", "not", "split_single_quote", ":", "\n", "      ", "dont_split", "+=", "\"'\"", "\n", "", "if", "not", "split_period", ":", "\n", "      ", "dont_split", "+=", "\"\\.\"", "\n", "", "if", "not", "split_comma", ":", "\n", "      ", "dont_split", "+=", "\",\"", "\n", "\n", "", "resplit", "=", "\"([\"", "+", "resplit", "+", "\"]|'')\"", "\n", "if", "len", "(", "dont_split", ")", ">", "0", ":", "\n", "      ", "split_regex", "=", "r\"(?![\"", "+", "dont_split", "+", "\"])\"", "+", "resplit", "\n", "", "else", ":", "\n", "      ", "split_regex", "=", "resplit", "\n", "\n", "", "self", ".", "split_regex", "=", "regex", ".", "compile", "(", "split_regex", ")", "\n", "try", ":", "\n", "      ", "self", ".", "sent_tokenzier", "=", "nltk", ".", "load", "(", "'tokenizers/punkt/english.pickle'", ")", "\n", "", "except", "LookupError", ":", "\n", "      ", "logging", ".", "info", "(", "\"Downloading NLTK punkt tokenizer\"", ")", "\n", "nltk", ".", "download", "(", "'punkt'", ")", "\n", "self", ".", "sent_tokenzier", "=", "nltk", ".", "load", "(", "'tokenizers/punkt/english.pickle'", ")", "\n", "\n", "", "self", ".", "word_tokenizer", "=", "nltk", ".", "TreebankWordTokenizer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.tokenizer.NltkAndPunctTokenizer.retokenize": [[86, 91], ["_double_quote_re.match", "x.strip", "tokenizer.NltkAndPunctTokenizer.split_regex.split", "len"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split"], ["", "def", "retokenize", "(", "self", ",", "x", ")", ":", "\n", "    ", "if", "_double_quote_re", ".", "match", "(", "x", ")", ":", "\n", "# Never split isolated double quotes(TODO Just integrate this into the regex?)", "\n", "      ", "return", "(", "x", ",", ")", "\n", "", "return", "(", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "split_regex", ".", "split", "(", "x", ")", "if", "len", "(", "x", ")", ">", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.tokenizer.NltkAndPunctTokenizer.tokenize": [[92, 97], ["tokenizer.NltkAndPunctTokenizer.sent_tokenzier.tokenize", "debias.utils.py_utils.flatten_list", "tokenizer.NltkAndPunctTokenizer.retokenize", "tokenizer.NltkAndPunctTokenizer.word_tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.tokenizer.NltkAndPunctTokenizer.tokenize", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.flatten_list", "home.repos.pwc.inspect_result.chrisc36_debias.utils.tokenizer.NltkAndPunctTokenizer.retokenize", "home.repos.pwc.inspect_result.chrisc36_debias.utils.tokenizer.NltkAndPunctTokenizer.tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "out", "=", "[", "]", "\n", "for", "s", "in", "self", ".", "sent_tokenzier", ".", "tokenize", "(", "text", ")", ":", "\n", "      ", "out", "+=", "flatten_list", "(", "self", ".", "retokenize", "(", "w", ")", "for", "w", "in", "self", ".", "word_tokenizer", ".", "tokenize", "(", "s", ")", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.tokenizer.NltkAndPunctTokenizer.tokenize_with_inverse": [[98, 102], ["tokenizer.NltkAndPunctTokenizer.tokenize", "tokenizer.convert_to_spans"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.tokenizer.NltkAndPunctTokenizer.tokenize", "home.repos.pwc.inspect_result.chrisc36_debias.utils.tokenizer.convert_to_spans"], ["", "def", "tokenize_with_inverse", "(", "self", ",", "paragraph", ":", "str", ")", ":", "\n", "    ", "text", "=", "self", ".", "tokenize", "(", "paragraph", ")", "\n", "inv", "=", "convert_to_spans", "(", "paragraph", ",", "text", ")", "\n", "return", "text", ",", "inv", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.tokenizer.convert_to_spans": [[24, 44], ["numpy.zeros", "enumerate", "_double_quote_re.match", "len", "_double_quote_re.search", "raw_text.find", "len", "ValueError", "_double_quote_re.search.start", "_double_quote_re.search.end", "_double_quote_re.search.start"], "function", ["None"], ["def", "convert_to_spans", "(", "raw_text", ":", "str", ",", "text", ":", "List", "[", "str", "]", ")", "->", "np", ".", "ndarray", ":", "\n", "  ", "\"\"\" Convert a tokenized version of `raw_text` into a series character\n  spans referencing the `raw_text` \"\"\"", "\n", "cur_idx", "=", "0", "\n", "all_spans", "=", "np", ".", "zeros", "(", "(", "len", "(", "text", ")", ",", "2", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "text", ")", ":", "\n", "    ", "if", "_double_quote_re", ".", "match", "(", "token", ")", ":", "\n", "      ", "span", "=", "_double_quote_re", ".", "search", "(", "raw_text", "[", "cur_idx", ":", "]", ")", "\n", "tmp", "=", "cur_idx", "+", "span", ".", "start", "(", ")", "\n", "l", "=", "span", ".", "end", "(", ")", "-", "span", ".", "start", "(", ")", "\n", "", "else", ":", "\n", "      ", "tmp", "=", "raw_text", ".", "find", "(", "token", ",", "cur_idx", ")", "\n", "l", "=", "len", "(", "token", ")", "\n", "\n", "", "if", "tmp", "<", "cur_idx", ":", "\n", "      ", "raise", "ValueError", "(", "token", ")", "\n", "", "cur_idx", "=", "tmp", "\n", "all_spans", "[", "i", "]", "=", "(", "cur_idx", ",", "cur_idx", "+", "l", ")", "\n", "cur_idx", "+=", "l", "\n", "", "return", "all_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.Configuration.__init__": [[21, 25], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "name", ",", "version", ",", "params", ")", ":", "\n", "    ", "self", ".", "name", "=", "name", "\n", "self", ".", "version", "=", "version", "\n", "self", ".", "params", "=", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.Configured._get_param_names": [[42, 54], ["inspect.signature", "inspect.signature.parameters.values", "ValueError", "inspect.signature.parameters.keys"], "methods", ["None"], ["@", "classmethod", "\n", "def", "_get_param_names", "(", "cls", ")", ":", "\n", "    ", "\"\"\"Returns all parameter names of the `__init__` method.\"\"\"", "\n", "init", "=", "cls", ".", "__init__", "\n", "if", "init", "is", "object", ".", "__init__", ":", "\n", "      ", "return", "[", "]", "# No init args", "\n", "\n", "", "init_signature", "=", "signature", "(", "init", ")", "\n", "for", "param", "in", "init_signature", ".", "parameters", ".", "values", "(", ")", ":", "\n", "      ", "if", "param", ".", "kind", "!=", "Parameter", ".", "POSITIONAL_OR_KEYWORD", ":", "\n", "        ", "raise", "ValueError", "(", "cls", ".", "__name__", "+", "\" has kwargs or args in __init__\"", ")", "\n", "", "", "return", "[", "p", "for", "p", "in", "init_signature", ".", "parameters", ".", "keys", "(", ")", "if", "p", "!=", "\"self\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.Configured.name": [[55, 58], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.Configured.version": [[59, 62], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "version", "(", "self", ")", ":", "\n", "    ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.Configured.get_config": [[63, 65], ["configured.Configuration", "configured.Configured.get_params"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.Configured.get_params"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "    ", "return", "Configuration", "(", "self", ".", "name", ",", "self", ".", "version", ",", "self", ".", "get_params", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.Configured.get_params": [[66, 72], ["collections.OrderedDict", "configured.Configured._get_param_names", "getattr", "configured._get_configuration"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.Configured._get_param_names", "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured._get_configuration"], ["", "def", "get_params", "(", "self", ")", ":", "\n", "    ", "out", "=", "OrderedDict", "(", ")", "\n", "for", "key", "in", "self", ".", "_get_param_names", "(", ")", ":", "\n", "      ", "v", "=", "getattr", "(", "self", ",", "key", ")", "\n", "out", "[", "key", "]", "=", "_get_configuration", "(", "v", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.Configured.to_json": [[73, 75], ["configured.config_to_json"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.config_to_json"], ["", "def", "to_json", "(", "self", ",", "indent", "=", "None", ")", ":", "\n", "    ", "return", "config_to_json", "(", "self", ",", "indent", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.Configured.__getstate__": [[76, 82], ["configured.Configured._get_param_names", "getattr"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.Configured._get_param_names"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "    ", "state", "=", "{", "}", "\n", "for", "key", "in", "self", ".", "_get_param_names", "(", ")", ":", "\n", "      ", "state", "[", "key", "]", "=", "getattr", "(", "self", ",", "key", ")", "\n", "", "state", "[", "\"version\"", "]", "=", "self", ".", "version", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.Configured.__setstate__": [[83, 92], ["configured.Configured.__init__", "RuntimeError", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.bert.clf_debias_loss_functions.LearnedMixin.__init__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "    ", "if", "\"version\"", "not", "in", "state", ":", "\n", "      ", "raise", "RuntimeError", "(", "\n", "\"Version should be in state (%s)\"", "%", "self", ".", "__class__", ".", "__name__", ")", "\n", "", "if", "state", "[", "\"version\"", "]", "!=", "self", ".", "version", ":", "\n", "      ", "warn", "(", "(", "\"%s loaded with version %s, but class version is %s\"", ")", "%", "\n", "(", "self", ".", "__class__", ".", "__name__", ",", "state", "[", "\"version\"", "]", ",", "self", ".", "version", ")", ")", "\n", "", "del", "state", "[", "\"version\"", "]", "\n", "self", ".", "__init__", "(", "**", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured._ConfiguredJSONEncoder.default": [[124, 148], ["isinstance", "isinstance", "collections.OrderedDict", "collections.OrderedDict.update", "int", "isinstance", "ValueError", "float", "isinstance", "bool", "isinstance", "obj.tolist", "isinstance", "obj.get_config", "isinstance", "isinstance", "sorted", "super().default"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.Configured.get_config", "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured._ConfiguredJSONEncoder.default"], ["def", "default", "(", "self", ",", "obj", ")", ":", "\n", "    ", "if", "isinstance", "(", "obj", ",", "Configuration", ")", ":", "\n", "      ", "if", "\"version\"", "in", "obj", ".", "params", "or", "\"name\"", "in", "obj", ".", "params", ":", "\n", "        ", "raise", "ValueError", "(", ")", "\n", "", "out", "=", "OrderedDict", "(", ")", "\n", "out", "[", "\"name\"", "]", "=", "obj", ".", "name", "\n", "if", "obj", ".", "version", "!=", "0", ":", "\n", "        ", "out", "[", "\"version\"", "]", "=", "obj", ".", "version", "\n", "", "out", ".", "update", "(", "obj", ".", "params", ")", "\n", "return", "out", "\n", "", "if", "isinstance", "(", "obj", ",", "np", ".", "integer", ")", ":", "\n", "      ", "return", "int", "(", "obj", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "np", ".", "floating", ")", ":", "\n", "      ", "return", "float", "(", "obj", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "np", ".", "bool_", ")", ":", "\n", "      ", "return", "bool", "(", "obj", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "np", ".", "ndarray", ")", ":", "\n", "      ", "return", "obj", ".", "tolist", "(", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "Configured", ")", ":", "\n", "      ", "return", "obj", ".", "get_config", "(", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "set", ")", "or", "isinstance", "(", "obj", ",", "frozenset", ")", ":", "\n", "      ", "return", "sorted", "(", "obj", ")", "# Ensure deterministic order", "\n", "", "else", ":", "\n", "      ", "return", "super", "(", "_ConfiguredJSONEncoder", ",", "self", ")", ".", "default", "(", "obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured._get_configuration": [[94, 119], ["isinstance", "type", "isinstance", "isinstance", "obj.get_config", "type.", "int", "float", "ValueError", "type.", "obj.items", "configured._get_configuration", "isinstance", "configured._get_configuration", "str", "ValueError", "type"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.Configured.get_config", "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured._get_configuration", "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured._get_configuration"], ["", "", "def", "_get_configuration", "(", "obj", ")", ":", "\n", "  ", "\"\"\"Transform `obj` into a `Configuration` object or json-serialable type.\"\"\"", "\n", "\n", "if", "isinstance", "(", "obj", ",", "Configured", ")", ":", "\n", "    ", "return", "obj", ".", "get_config", "(", ")", "\n", "\n", "", "obj_type", "=", "type", "(", "obj", ")", "\n", "\n", "if", "obj_type", "in", "(", "list", ",", "set", ",", "frozenset", ",", "tuple", ")", ":", "\n", "    ", "return", "obj_type", "(", "[", "_get_configuration", "(", "e", ")", "for", "e", "in", "obj", "]", ")", "\n", "", "elif", "obj_type", "in", "(", "OrderedDict", ",", "dict", ")", ":", "\n", "    ", "output", "=", "obj_type", "(", ")", "\n", "for", "k", ",", "v", "in", "obj", ".", "items", "(", ")", ":", "\n", "      ", "if", "isinstance", "(", "k", ",", "Configured", ")", ":", "\n", "        ", "raise", "ValueError", "(", ")", "\n", "", "output", "[", "k", "]", "=", "_get_configuration", "(", "v", ")", "\n", "", "return", "output", "\n", "", "elif", "obj_type", "in", "{", "str", ",", "int", ",", "float", ",", "bool", ",", "type", "(", "None", ")", "}", ":", "\n", "    ", "return", "obj", "\n", "", "if", "isinstance", "(", "obj", ",", "np", ".", "integer", ")", ":", "\n", "    ", "return", "int", "(", "obj", ")", "\n", "", "if", "isinstance", "(", "obj", ",", "np", ".", "floating", ")", ":", "\n", "    ", "return", "float", "(", "obj", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Can't configure obj \"", "+", "str", "(", "obj_type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.config_to_json": [[150, 155], ["json.dumps"], "function", ["None"], ["", "", "", "def", "config_to_json", "(", "data", ",", "indent", "=", "None", ")", ":", "\n", "# sort_keys=False since the configuration objects will dump their", "\n", "# parameters in an ordered manner", "\n", "  ", "return", "json", ".", "dumps", "(", "\n", "data", ",", "sort_keys", "=", "False", ",", "cls", "=", "_ConfiguredJSONEncoder", ",", "indent", "=", "indent", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.process_par.Processor.process": [[12, 16], ["NotImplementedError"], "methods", ["None"], ["  ", "def", "process", "(", "self", ",", "data", ":", "Iterable", ")", ":", "\n", "    ", "\"\"\"Map elements to an unspecified output type, the output but type must None or\n    be able to be aggregated with the  `+` operator\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.process_par.Processor.finalize_chunk": [[17, 21], ["None"], "methods", ["None"], ["", "def", "finalize_chunk", "(", "self", ",", "data", ")", ":", "\n", "    ", "\"\"\"Finalize the output from `preprocess`, in multi-processing senarios this will still be run on\n     the main thread so it can be used for things like interning\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.process_par._process_and_count": [[23, 27], ["len", "preprocessor.process"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.ExampleConverter.process"], ["", "", "def", "_process_and_count", "(", "questions", ":", "List", ",", "preprocessor", ":", "Processor", ")", ":", "\n", "  ", "count", "=", "len", "(", "questions", ")", "\n", "output", "=", "preprocessor", ".", "process", "(", "questions", ")", "\n", "return", "output", ",", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.process_par.process_par": [[29, 68], ["min", "ValueError", "ValueError", "len", "processor.process", "processor.finalize_chunk", "debias.utils.py_utils.split", "debias.utils.py_utils.flatten_list", "len", "tqdm.tqdm", "multiprocessing.Lock", "tqdm.tqdm.close", "tqdm.tqdm", "processor.finalize_chunk", "multiprocessing.Pool", "debias.utils.py_utils.group", "tqdm.tqdm.update", "pool.apply_async", "r.get"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.ExampleConverter.process", "home.repos.pwc.inspect_result.chrisc36_debias.utils.process_par.Processor.finalize_chunk", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.flatten_list", "home.repos.pwc.inspect_result.chrisc36_debias.utils.process_par.Processor.finalize_chunk", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.group"], ["", "def", "process_par", "(", "data", ":", "List", ",", "processor", ":", "Processor", ",", "n_processes", ",", "\n", "chunk_size", "=", "1000", ",", "desc", "=", "None", ",", "initializer", "=", "None", ")", ":", "\n", "  ", "\"\"\"Runs `processor` on the elements in `data`, possibly in parallel, and monitor with tqdm\"\"\"", "\n", "\n", "if", "chunk_size", "<=", "0", ":", "\n", "    ", "raise", "ValueError", "(", "\"Chunk size must be >= 0, but got %s\"", "%", "chunk_size", ")", "\n", "", "if", "n_processes", "is", "not", "None", "and", "n_processes", "<=", "0", ":", "\n", "    ", "raise", "ValueError", "(", "\"n_processes must be >= 1 or None, but got %s\"", "%", "n_processes", ")", "\n", "", "n_processes", "=", "min", "(", "len", "(", "data", ")", ",", "1", "if", "n_processes", "is", "None", "else", "n_processes", ")", "\n", "\n", "if", "n_processes", "==", "1", "and", "not", "initializer", ":", "\n", "    ", "out", "=", "processor", ".", "process", "(", "tqdm", "(", "data", ",", "desc", "=", "desc", ",", "ncols", "=", "80", ")", ")", "\n", "processor", ".", "finalize_chunk", "(", "out", ")", "\n", "return", "out", "\n", "", "else", ":", "\n", "    ", "chunks", "=", "split", "(", "data", ",", "n_processes", ")", "\n", "chunks", "=", "flatten_list", "(", "[", "group", "(", "c", ",", "chunk_size", ")", "for", "c", "in", "chunks", "]", ")", "\n", "total", "=", "len", "(", "data", ")", "\n", "pbar", "=", "tqdm", "(", "total", "=", "total", ",", "desc", "=", "desc", ",", "ncols", "=", "80", ")", "\n", "lock", "=", "Lock", "(", ")", "\n", "\n", "def", "call_back", "(", "results", ")", ":", "\n", "      ", "processor", ".", "finalize_chunk", "(", "results", "[", "0", "]", ")", "\n", "with", "lock", ":", "\n", "        ", "pbar", ".", "update", "(", "results", "[", "1", "]", ")", "\n", "\n", "", "", "with", "Pool", "(", "n_processes", ",", "initializer", "=", "initializer", ")", "as", "pool", ":", "\n", "      ", "results", "=", "[", "\n", "pool", ".", "apply_async", "(", "_process_and_count", ",", "[", "c", ",", "processor", "]", ",", "callback", "=", "call_back", ")", "\n", "for", "c", "in", "chunks", "\n", "]", "\n", "results", "=", "[", "r", ".", "get", "(", ")", "[", "0", "]", "for", "r", "in", "results", "]", "\n", "\n", "", "pbar", ".", "close", "(", ")", "\n", "output", "=", "results", "[", "0", "]", "\n", "if", "output", "is", "not", "None", ":", "\n", "      ", "for", "r", "in", "results", "[", "1", ":", "]", ":", "\n", "        ", "output", "+=", "r", "\n", "", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors.download_word_vectors": [[20, 28], ["load_word_vectors.download_fasttext", "load_word_vectors.download_glove_6b", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors.download_fasttext", "home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors.download_glove_6b"], ["def", "download_word_vectors", "(", "vec_name", ")", ":", "\n", "  ", "if", "vec_name", "==", "\"crawl-300d-2M\"", ":", "\n", "    ", "download_fasttext", "(", ")", "\n", "", "elif", "vec_name", "in", "GLOVE_6B_VECS", ":", "\n", "    ", "download_glove_6b", "(", ")", "\n", "", "else", ":", "\n", "    ", "raise", "NotImplementedError", "(", "\n", "vec_name", "+", "\" does not exist, and cannot be automatically downloaded, please download manually\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors.download_fasttext": [[30, 34], ["os.path.exists", "debias.utils.py_utils.download_zip", "os.path.join"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_zip"], ["", "", "def", "download_fasttext", "(", ")", ":", "\n", "  ", "if", "exists", "(", "join", "(", "config", ".", "WORD_VEC_SOURCE", ",", "\"crawl-300d-2M.vec\"", ")", ")", ":", "\n", "    ", "return", "\n", "", "py_utils", ".", "download_zip", "(", "\"crawl-300d-2M.vec\"", ",", "FASTTEXT_URL", ",", "config", ".", "WORD_VEC_SOURCE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors.download_glove_6b": [[36, 40], ["all", "debias.utils.py_utils.download_zip", "os.path.exists", "os.path.join"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_zip"], ["", "def", "download_glove_6b", "(", ")", ":", "\n", "  ", "if", "all", "(", "exists", "(", "join", "(", "config", ".", "WORD_VEC_SOURCE", ",", "x", "+", "\".txt\"", ")", ")", "for", "x", "in", "GLOVE_6B_VECS", ")", ":", "\n", "    ", "return", "\n", "", "py_utils", ".", "download_zip", "(", "\"Glove 6B\"", ",", "GLOVE_6B_URL", ",", "config", ".", "WORD_VEC_SOURCE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors._find_vec_path": [[42, 54], ["os.path.join", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists"], "function", ["None"], ["", "def", "_find_vec_path", "(", "vec_name", ")", ":", "\n", "  ", "vec_path", "=", "join", "(", "config", ".", "WORD_VEC_SOURCE", ",", "vec_name", ")", "\n", "if", "exists", "(", "vec_path", "+", "\".txt\"", ")", ":", "\n", "    ", "return", "vec_path", "+", "\".txt\"", "\n", "", "elif", "exists", "(", "vec_path", "+", "\".txt.gz\"", ")", ":", "\n", "    ", "return", "vec_path", "+", "\".txt.gz\"", "\n", "", "elif", "exists", "(", "vec_path", "+", "\".pkl\"", ")", ":", "\n", "    ", "return", "vec_path", "+", "\".pkl\"", "\n", "", "elif", "exists", "(", "vec_path", "+", "\".vec\"", ")", ":", "\n", "    ", "return", "vec_path", "+", "\".vec\"", "\n", "", "else", ":", "\n", "    ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors.load_word_vectors": [[56, 65], ["load_word_vectors._find_vec_path", "load_word_vectors._find_vec_path", "load_word_vectors.load_word_vector_file", "load_word_vectors.download_word_vectors", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors._find_vec_path", "home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors._find_vec_path", "home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors.load_word_vector_file", "home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors.download_word_vectors"], ["", "", "def", "load_word_vectors", "(", "vec_name", ":", "str", ",", "vocab", ":", "Optional", "[", "Iterable", "[", "str", "]", "]", "=", "None", ",", "n_words_to_scan", "=", "None", ")", ":", "\n", "  ", "vec_path", "=", "_find_vec_path", "(", "vec_name", ")", "\n", "if", "vec_path", "is", "None", ":", "\n", "    ", "download_word_vectors", "(", "vec_name", ")", "\n", "", "vec_path", "=", "_find_vec_path", "(", "vec_name", ")", "\n", "if", "vec_path", "is", "None", ":", "\n", "    ", "raise", "RuntimeError", "(", "\"Download bug?\"", ")", "\n", "\n", "", "return", "load_word_vector_file", "(", "vec_path", ",", "vocab", ",", "n_words_to_scan", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors.load_word_vector_file": [[67, 112], ["vec_path.endswith", "tqdm.tqdm", "tqdm.tqdm.close", "set", "vec_path.endswith", "handle", "enumerate", "open", "pickle.load", "logging.info", "logging.info", "logging.info", "logging.info", "tqdm.tqdm.update", "line.find", "gzip.open", "open", "words.append", "vecs.append", "numpy.fromstring", "len", "len"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadLoader.load"], ["", "def", "load_word_vector_file", "(", "vec_path", ":", "str", ",", "vocab", ":", "Optional", "[", "Iterable", "[", "str", "]", "]", "=", "None", ",", "\n", "n_words_to_scan", "=", "None", ")", ":", "\n", "  ", "if", "vocab", "is", "not", "None", ":", "\n", "    ", "vocab", "=", "set", "(", "vocab", ")", "\n", "\n", "", "if", "vec_path", ".", "endswith", "(", "\".pkl\"", ")", ":", "\n", "    ", "with", "open", "(", "vec_path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "      ", "return", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "# some of the large vec files produce utf-8 errors for some words, just skip them", "\n", "", "", "elif", "vec_path", ".", "endswith", "(", "\".txt.gz\"", ")", ":", "\n", "    ", "handle", "=", "lambda", "x", ":", "gzip", ".", "open", "(", "x", ",", "'r'", ",", "encoding", "=", "'utf-8'", ",", "errors", "=", "'ignore'", ")", "\n", "", "else", ":", "\n", "    ", "handle", "=", "lambda", "x", ":", "open", "(", "x", ",", "'r'", ",", "encoding", "=", "'utf-8'", ",", "errors", "=", "'ignore'", ")", "\n", "\n", "", "if", "n_words_to_scan", "is", "None", ":", "\n", "    ", "if", "vocab", "is", "None", ":", "\n", "      ", "logging", ".", "info", "(", "\"Loading word vectors from %s...\"", "%", "vec_path", ")", "\n", "", "else", ":", "\n", "      ", "logging", ".", "info", "(", "\"Loading word vectors from %s for voc size %d...\"", "%", "(", "vec_path", ",", "len", "(", "vocab", ")", ")", ")", "\n", "", "", "else", ":", "\n", "    ", "if", "vocab", "is", "None", ":", "\n", "      ", "logging", ".", "info", "(", "\"Loading up to %d word vectors from %s...\"", "%", "(", "n_words_to_scan", ",", "vec_path", ")", ")", "\n", "", "else", ":", "\n", "      ", "logging", ".", "info", "(", "\"Loading up to %d word vectors from %s for voc size %d...\"", "%", "(", "n_words_to_scan", ",", "vec_path", ",", "len", "(", "vocab", ")", ")", ")", "\n", "\n", "", "", "words", "=", "[", "]", "\n", "vecs", "=", "[", "]", "\n", "pbar", "=", "tqdm", "(", "desc", "=", "\"word-vec\"", ")", "\n", "with", "handle", "(", "vec_path", ")", "as", "fh", ":", "\n", "    ", "for", "i", ",", "line", "in", "enumerate", "(", "fh", ")", ":", "\n", "      ", "pbar", ".", "update", "(", "1", ")", "\n", "if", "n_words_to_scan", "is", "not", "None", "and", "i", ">=", "n_words_to_scan", ":", "\n", "        ", "break", "\n", "", "word_ix", "=", "line", ".", "find", "(", "\" \"", ")", "\n", "if", "i", "==", "0", "and", "\" \"", "not", "in", "line", "[", "word_ix", "+", "1", ":", "]", ":", "\n", "# assume a header row, such as found in the fasttext word vectors", "\n", "        ", "continue", "\n", "", "word", "=", "line", "[", ":", "word_ix", "]", "\n", "if", "(", "vocab", "is", "None", ")", "or", "(", "word", "in", "vocab", ")", ":", "\n", "        ", "words", ".", "append", "(", "word", ")", "\n", "vecs", ".", "append", "(", "np", ".", "fromstring", "(", "line", "[", "word_ix", "+", "1", ":", "]", ",", "sep", "=", "\" \"", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "\n", "", "", "", "pbar", ".", "close", "(", ")", "\n", "return", "words", ",", "vecs", "\n", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.triviaqa_cp.AnnotatedTriviaQaExample.__init__": [[39, 53], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "question_id", ":", "str", ",", "question_type", ":", "str", ",", "\n", "question_type_probs", ":", "np", ".", "ndarray", ",", "\n", "question", ":", "List", "[", "str", "]", ",", "tokens", ":", "List", "[", "str", "]", ",", "\n", "pos", ":", "List", "[", "str", "]", ",", "ner", ":", "List", "[", "str", "]", ",", "\n", "answers", ":", "List", "[", "str", "]", ",", "answer_spans", ":", "np", ".", "ndarray", ")", ":", "\n", "    ", "self", ".", "question_type", "=", "question_type", "\n", "self", ".", "question_type_probs", "=", "question_type_probs", "\n", "self", ".", "question_id", "=", "question_id", "\n", "self", ".", "question", "=", "question", "\n", "self", ".", "tokens", "=", "tokens", "\n", "self", ".", "ner", "=", "ner", "\n", "self", ".", "pos", "=", "pos", "\n", "self", ".", "answers", "=", "answers", "\n", "self", ".", "answer_spans", "=", "answer_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.triviaqa_cp.AnnotatedTriviaQACPLoader.__init__": [[217, 229], ["ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "dataset_name", ",", "load_bias", "=", "True", ",", "\n", "sample_train_eval", "=", "None", ",", "sample_train", "=", "None", ",", "\n", "sample_dev", "=", "None", ",", "stratify", "=", "False", ")", ":", "\n", "    ", "if", "dataset_name", "not", "in", "[", "\"person\"", ",", "\"location\"", "]", ":", "\n", "      ", "raise", "ValueError", "(", ")", "\n", "", "self", ".", "dataset_name", "=", "dataset_name", "\n", "self", ".", "load_bias", "=", "load_bias", "\n", "self", ".", "sample_train", "=", "sample_train", "\n", "self", ".", "sample_train_eval", "=", "sample_train_eval", "\n", "self", ".", "sample_dev", "=", "sample_dev", "\n", "self", ".", "stratify", "=", "stratify", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.triviaqa_cp.AnnotatedTriviaQACPLoader.load": [[230, 264], ["triviaqa_cp.load_annotated_triviaqa_cp", "triviaqa_cp.load_annotated_triviaqa_cp", "triviaqa_cp.compute_voc", "make_dataset.sort", "triviaqa_cp.convert_to_tuples", "numpy.random.choice().tolist.sort", "triviaqa_cp.convert_to_tuples", "dict", "triviaqa_cp.make_dataset", "debias.datasets.training_data_loader.TrainingData", "numpy.random.choice().tolist", "numpy.random.choice().tolist", "triviaqa_cp.load_bias", "triviaqa_cp.make_dataset_stratify", "triviaqa_cp.make_dataset", "triviaqa_cp.make_dataset", "numpy.random.choice", "numpy.random.choice", "len", "len"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.triviaqa_cp.load_annotated_triviaqa_cp", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.triviaqa_cp.load_annotated_triviaqa_cp", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.compute_voc", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.convert_to_tuples", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.convert_to_tuples", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_bias", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset_stratify", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset"], ["", "def", "load", "(", "self", ",", "tokenizer", ",", "n_processes", "=", "None", ")", ":", "\n", "    ", "train", "=", "load_annotated_triviaqa_cp", "(", "self", ".", "dataset_name", ",", "\"train\"", ")", "\n", "dev", "=", "load_annotated_triviaqa_cp", "(", "self", ".", "dataset_name", ",", "\"dev\"", ")", "\n", "\n", "if", "self", ".", "sample_train", ":", "\n", "      ", "train", "=", "np", ".", "random", ".", "choice", "(", "train", ",", "self", ".", "sample_train", ",", "False", ")", ".", "tolist", "(", ")", "\n", "", "if", "self", ".", "sample_dev", ":", "\n", "      ", "dev", "=", "np", ".", "random", ".", "choice", "(", "dev", ",", "self", ".", "sample_dev", ",", "False", ")", ".", "tolist", "(", ")", "\n", "\n", "", "voc", "=", "compute_voc", "(", "train", ",", "dev", ")", "\n", "\n", "train", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", ".", "tokens", ")", ")", "\n", "train_tuples", "=", "convert_to_tuples", "(", "train", ")", "\n", "\n", "dev", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", ".", "tokens", ")", ")", "\n", "dev_tuples", "=", "convert_to_tuples", "(", "dev", ")", "\n", "\n", "eval_sets", "=", "dict", "(", ")", "\n", "\n", "if", "load_bias", ":", "\n", "      ", "bias", "=", "load_bias", "(", "self", ".", "dataset_name", ",", "True", ")", "\n", "", "else", ":", "\n", "      ", "bias", "=", "None", "\n", "\n", "", "if", "self", ".", "stratify", ":", "\n", "      ", "train", "=", "make_dataset_stratify", "(", "train_tuples", ",", "bias", ",", "self", ".", "stratify", ")", "\n", "", "else", ":", "\n", "      ", "train", "=", "make_dataset", "(", "train_tuples", ",", "bias", ",", "shuffle", "=", "True", ")", "\n", "\n", "", "if", "self", ".", "sample_train_eval", ":", "\n", "      ", "eval_sets", "[", "\"train\"", "]", "=", "make_dataset", "(", "train_tuples", ",", "None", ",", "self", ".", "sample_train_eval", ",", "shuffle", "=", "False", ")", "\n", "", "eval_sets", "[", "\"dev\"", "]", "=", "make_dataset", "(", "dev_tuples", ",", "None", ",", "None", ",", "shuffle", "=", "False", ")", "\n", "\n", "return", "TrainingData", "(", "train", ",", "eval_sets", ",", "voc", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.triviaqa_cp.load_annotated_triviaqa": [[55, 65], ["os.path.join", "logging.info", "debias.utils.py_utils.load_pickle", "os.path.exists", "logging.info", "debias.utils.py_utils.download_from_drive"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_pickle", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_from_drive"], ["", "", "def", "load_annotated_triviaqa", "(", "is_train", ":", "bool", ")", "->", "List", "[", "AnnotatedTriviaQaExample", "]", ":", "\n", "  ", "\"\"\"Loads TriviaQA data that has been tokenized and tagged by CoreNLP\"\"\"", "\n", "dataset_name", "=", "\"train\"", "if", "is_train", "else", "\"dev\"", "\n", "src", "=", "join", "(", "config", ".", "TRIVIAQA_CP_CORENLP", ",", "\"%s.pkl\"", "%", "dataset_name", ")", "\n", "if", "not", "exists", "(", "src", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"Download pre-processed TriviaQA %s to %s\"", "%", "(", "dataset_name", ",", "src", ")", ")", "\n", "py_utils", ".", "download_from_drive", "(", "TRIVIAQA_CP_CORENLP_FILE_IDS", "[", "dataset_name", "]", ",", "src", ",", "progress_bar", "=", "True", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Loading CoreNLP TriviaQA %s...\"", "%", "dataset_name", ")", "\n", "return", "py_utils", ".", "load_pickle", "(", "src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.triviaqa_cp.load_annotated_triviaqa_cp": [[67, 72], ["triviaqa_cp.load_annotated_triviaqa", "triviaqa_cp.triviaqa_cp_loader.get_qtypes"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.triviaqa_cp.load_annotated_triviaqa", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_loader.get_qtypes"], ["", "def", "load_annotated_triviaqa_cp", "(", "dataset_name", ":", "str", ",", "part", ":", "str", ")", "->", "List", "[", "AnnotatedTriviaQaExample", "]", ":", "\n", "  ", "\"\"\"Loads TriviaQA-CP data that has been tokenized and tagged by CoreNLP\"\"\"", "\n", "triviaqa", "=", "load_annotated_triviaqa", "(", "part", "==", "\"train\"", ")", "\n", "target_qytpes", "=", "triviaqa_cp_loader", ".", "get_qtypes", "(", "dataset_name", ",", "part", ")", "\n", "return", "[", "x", "for", "x", "in", "triviaqa", "if", "x", ".", "question_type", "in", "target_qytpes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.triviaqa_cp.load_bias": [[74, 98], ["os.path.join", "debias.utils.py_utils.load_pickle", "os.path.exists", "logging.info", "debias.utils.py_utils.download_from_drive", "ValueError", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_pickle", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_from_drive"], ["", "def", "load_bias", "(", "dataset_name", ":", "str", ",", "is_train", "=", "True", ")", "->", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", ":", "\n", "  ", "\"\"\"Loads the output of our bias-only model\n\n  Note that since this produces per-token output, it is only valid on data with the\n  same tokenization as our annotated data.\n  \"\"\"", "\n", "if", "dataset_name", "==", "\"location\"", ":", "\n", "    ", "cache_dir", "=", "TRIVIAQA_CP_LOCATION_FILTERED_BIAS", "\n", "", "elif", "dataset_name", "==", "\"person\"", ":", "\n", "    ", "cache_dir", "=", "TRIVIAQA_CP_PERSON_FILTERED_BIAS", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "dataset_name", ")", "\n", "\n", "", "part_name", "=", "\"train\"", "if", "is_train", "else", "\"dev\"", "\n", "src", "=", "join", "(", "cache_dir", ",", "\"%s.pkl\"", "%", "part_name", ")", "\n", "\n", "if", "not", "exists", "(", "src", ")", ":", "\n", "    ", "key", "=", "(", "dataset_name", ",", "part_name", ")", "\n", "if", "key", "not", "in", "TRIVIAQA_CP_BIAS_FILE_IDS", ":", "\n", "      ", "raise", "RuntimeError", "(", ")", "\n", "", "logging", ".", "info", "(", "\"Downloading TriviaQA-CP bias for %s to %s\"", "%", "(", "dataset_name", ",", "src", ")", ")", "\n", "py_utils", ".", "download_from_drive", "(", "TRIVIAQA_CP_BIAS_FILE_IDS", "[", "key", "]", ",", "src", ",", "progress_bar", "=", "False", ")", "\n", "\n", "", "return", "py_utils", ".", "load_pickle", "(", "src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.triviaqa_cp.load_triviaqa_cp": [[100, 109], ["os.path.join", "triviaqa_cp.triviaqa_cp_loader.load_triviaqa_cp", "os.path.exists", "logging.info", "debias.utils.py_utils.download_from_drive"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_loader.load_triviaqa_cp", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_from_drive"], ["", "def", "load_triviaqa_cp", "(", "dataset_name", ":", "str", ",", "part", ":", "str", ")", "->", "List", "[", "Dict", "]", ":", "\n", "  ", "\"\"\"Load the official TriviaQA-CP dataset, needed for evaluation\"\"\"", "\n", "src_name", "=", "\"train\"", "if", "(", "part", "==", "\"train\"", ")", "else", "\"dev\"", "\n", "src", "=", "join", "(", "config", ".", "TRIVIAQA_CP_SOURCE", ",", "src_name", "+", "\".json\"", ")", "\n", "if", "not", "exists", "(", "src", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"Download TriviaQA-CP %s to %s\"", "%", "(", "src_name", ",", "src", ")", ")", "\n", "py_utils", ".", "download_from_drive", "(", "TRIVIAQA_CP_FILE_IDS", "[", "src_name", "]", ",", "src", ",", "True", ")", "\n", "\n", "", "return", "triviaqa_cp_loader", ".", "load_triviaqa_cp", "(", "src", ",", "dataset_name", ",", "part", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.triviaqa_cp.compute_voc": [[111, 118], ["set", "set.update", "set.update"], "function", ["None"], ["", "def", "compute_voc", "(", "*", "datasets", ":", "List", "[", "AnnotatedTriviaQaExample", "]", ")", "->", "Set", "[", "str", "]", ":", "\n", "  ", "voc", "=", "set", "(", ")", "\n", "for", "data", "in", "datasets", ":", "\n", "    ", "for", "x", "in", "data", ":", "\n", "      ", "voc", ".", "update", "(", "x", ".", "tokens", ")", "\n", "voc", ".", "update", "(", "x", ".", "question", ")", "\n", "", "", "return", "voc", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.triviaqa_cp.convert_to_tuples": [[120, 130], ["numpy.zeros", "out.append", "len"], "function", ["None"], ["", "def", "convert_to_tuples", "(", "examples", ":", "List", "[", "AnnotatedTriviaQaExample", "]", ")", "->", "List", "[", "Tuple", "]", ":", "\n", "  ", "out", "=", "[", "]", "\n", "for", "ex", "in", "examples", ":", "\n", "    ", "dense_answers", "=", "np", ".", "zeros", "(", "(", "len", "(", "ex", ".", "tokens", ")", ",", "2", ")", ",", "np", ".", "bool", ")", "\n", "for", "s", ",", "e", "in", "ex", ".", "answer_spans", ":", "\n", "      ", "dense_answers", "[", "s", ",", "0", "]", "=", "True", "\n", "dense_answers", "[", "e", ",", "1", "]", "=", "True", "\n", "\n", "", "out", ".", "append", "(", "(", "ex", ".", "question_id", ",", "ex", ".", "question", ",", "ex", ".", "tokens", ",", "dense_answers", ",", "ex", ".", "answers", ")", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.triviaqa_cp.make_dataset": [[146, 168], ["list", "debias.datasets.dataset_utils.build_epoch_fn", "tensorflow.data.Dataset.from_generator", "tf.data.Dataset.from_generator.map", "len", "list.append", "tuple", "debias.utils.py_utils.transpose_lists", "zip", "zip"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.dataset_utils.build_epoch_fn", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.transpose_lists"], ["def", "make_dataset", "(", "lst", ":", "List", "[", "Tuple", "]", ",", "bias", "=", "None", ",", "sample", "=", "None", ",", "shuffle", "=", "False", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "  ", "\"\"\"Convert tuples from `convert_to_tuples` into a tf.data.Dataset\"\"\"", "\n", "dataset_structure", "=", "list", "(", "base_features", ")", "\n", "if", "bias", ":", "\n", "    ", "n", "=", "len", "(", "base_features", ")", "\n", "lst", "=", "[", "x", "[", ":", "n", "]", "+", "(", "bias", "[", "x", "[", "0", "]", "]", ",", ")", "+", "x", "[", "n", ":", "]", "for", "x", "in", "lst", "]", "\n", "dataset_structure", ".", "append", "(", "(", "\"bias\"", ",", "tf", ".", "float32", ",", "(", "None", ",", "2", ")", ")", ")", "\n", "\n", "", "dataset_structure", "+=", "label_structure", "\n", "\n", "ds_names", ",", "ds_dtypes", ",", "ds_shapes", "=", "[", "tuple", "(", "x", ")", "for", "x", "in", "py_utils", ".", "transpose_lists", "(", "dataset_structure", ")", "]", "\n", "\n", "get", "=", "build_epoch_fn", "(", "lst", ",", "sample", ",", "shuffle", ")", "\n", "data", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "get", ",", "ds_dtypes", ",", "ds_shapes", ")", "\n", "\n", "def", "to_dict", "(", "*", "args", ")", ":", "\n", "    ", "labels", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "ds_names", "[", "-", "n_label_elements", ":", "]", ",", "args", "[", "-", "n_label_elements", ":", "]", ")", "}", "\n", "features", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "ds_names", "[", ":", "-", "n_label_elements", "]", ",", "args", "[", ":", "-", "n_label_elements", "]", ")", "}", "\n", "features", "[", "\"label\"", "]", "=", "labels", "\n", "return", "features", "\n", "\n", "", "return", "data", ".", "map", "(", "to_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.triviaqa_cp.make_dataset_stratify": [[170, 212], ["list", "numpy.argsort", "debias.datasets.dataset_utils.build_stratified_epoch_fn", "tensorflow.data.Dataset.from_generator", "tf.data.Dataset.from_generator.map", "len", "list.append", "tuple", "len", "ValueError", "debias.utils.py_utils.transpose_lists", "enumerate", "len", "bias_probs.append", "bias_probs.append", "bias[].sum", "zip", "zip"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.dataset_utils.build_stratified_epoch_fn", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.transpose_lists"], ["", "def", "make_dataset_stratify", "(", "lst", ":", "List", "[", "Tuple", "]", ",", "bias", ",", "n_groups", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "  ", "\"\"\"Convert tuples from `convert_to_tuples` into a tf.data.Dataset,\n  while stratifying on the bias accuracy\"\"\"", "\n", "dataset_structure", "=", "list", "(", "base_features", ")", "\n", "if", "bias", ":", "\n", "    ", "n", "=", "len", "(", "base_features", ")", "\n", "lst", "=", "[", "x", "[", ":", "n", "]", "+", "(", "bias", "[", "x", "[", "0", "]", "]", ",", ")", "+", "x", "[", "n", ":", "]", "for", "x", "in", "lst", "]", "\n", "dataset_structure", ".", "append", "(", "(", "\"bias\"", ",", "tf", ".", "float32", ",", "(", "None", ",", "2", ")", ")", ")", "\n", "\n", "", "dataset_structure", "+=", "label_structure", "\n", "\n", "ds_names", ",", "ds_dtypes", ",", "ds_shapes", "=", "[", "tuple", "(", "x", ")", "for", "x", "in", "py_utils", ".", "transpose_lists", "(", "dataset_structure", ")", "]", "\n", "\n", "bias_ix", "=", "[", "i", "for", "i", ",", "name", "in", "enumerate", "(", "ds_names", ")", "if", "name", "==", "\"bias\"", "]", "\n", "if", "len", "(", "bias_ix", ")", "!=", "1", ":", "\n", "    ", "raise", "ValueError", "(", ")", "\n", "", "bias_ix", "=", "bias_ix", "[", "0", "]", "\n", "\n", "bias_probs", "=", "[", "]", "\n", "for", "example", "in", "lst", ":", "\n", "    ", "bias", "=", "example", "[", "bias_ix", "]", "\n", "spans", "=", "example", "[", "-", "2", "]", "\n", "if", "len", "(", "spans", ")", "==", "0", ":", "\n", "      ", "bias_probs", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "      ", "valid", "=", "example", "[", "-", "2", "]", "\n", "bias_probs", ".", "append", "(", "bias", "[", "valid", "]", ".", "sum", "(", ")", ")", "\n", "\n", "", "", "ix", "=", "np", ".", "argsort", "(", "bias_probs", ")", "\n", "lst", "=", "[", "lst", "[", "i", "]", "for", "i", "in", "ix", "]", "\n", "\n", "fn", "=", "build_stratified_epoch_fn", "(", "lst", ",", "n_groups", ")", "\n", "\n", "lst", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "fn", ",", "ds_dtypes", ",", "ds_shapes", ")", "\n", "\n", "def", "to_dict", "(", "*", "args", ")", ":", "\n", "    ", "labels", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "ds_names", "[", "-", "n_label_elements", ":", "]", ",", "args", "[", "-", "n_label_elements", ":", "]", ")", "}", "\n", "features", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "ds_names", "[", ":", "-", "n_label_elements", "]", ",", "args", "[", ":", "-", "n_label_elements", "]", ")", "}", "\n", "features", "[", "\"label\"", "]", "=", "labels", "\n", "return", "features", "\n", "\n", "", "return", "lst", ".", "map", "(", "to_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.dataset_utils.QuantileBatcher.__init__": [[66, 72], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "hist_min", ",", "hist_max", ",", "hist_step", ",", "n_buckets", ")", ":", "\n", "    ", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "hist_min", "=", "hist_min", "\n", "self", ".", "hist_max", "=", "hist_max", "\n", "self", ".", "hist_step", "=", "hist_step", "\n", "self", ".", "n_buckets", "=", "n_buckets", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.dataset_utils.QuantileBatcher.batch": [[73, 85], ["list", "logging.info", "dataset.apply", "range", "debias.utils.ops.bucket_by_quantiles", "len", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.bucket_by_quantiles"], ["", "def", "batch", "(", "self", ",", "dataset", ":", "tf", ".", "data", ".", "Dataset", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "    ", "bounds", "=", "list", "(", "range", "(", "self", ".", "hist_min", ",", "self", ".", "hist_max", ",", "self", ".", "hist_step", ")", ")", "\n", "\n", "logging", ".", "info", "(", "\n", "\"Quantile bucketing from %d-%d with %d buckets\"", "%", "\n", "(", "bounds", "[", "0", "]", ",", "bounds", "[", "-", "1", "]", ",", "len", "(", "bounds", ")", ")", ")", "\n", "\n", "return", "dataset", ".", "apply", "(", "ops", ".", "bucket_by_quantiles", "(", "\n", "len_fn", "=", "lambda", "x", ":", "tf", ".", "shape", "(", "x", "[", "PREMISE_KEY", "]", ")", "[", "0", "]", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "n_buckets", "=", "self", ".", "n_buckets", ",", "\n", "hist_bounds", "=", "bounds", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.dataset_utils.build_epoch_fn": [[10, 28], ["numpy.random.choice", "len", "np.random.choice.sort", "list", "numpy.random.shuffle"], "function", ["None"], ["def", "build_epoch_fn", "(", "lst", ",", "sample", "=", "None", ",", "shuffle", "=", "False", ")", ":", "\n", "  ", "\"\"\"Build a function to return `lst` after sampling/shuffling\"\"\"", "\n", "if", "sample", ":", "\n", "    ", "def", "get", "(", ")", ":", "\n", "      ", "ix", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "lst", ")", ",", "sample", ",", "replace", "=", "False", ")", "\n", "if", "not", "shuffle", ":", "\n", "        ", "ix", ".", "sort", "(", ")", "\n", "", "return", "[", "lst", "[", "i", "]", "for", "i", "in", "ix", "]", "\n", "\n", "", "", "elif", "shuffle", ":", "\n", "      ", "def", "get", "(", ")", ":", "\n", "        ", "cpy", "=", "list", "(", "lst", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "cpy", ")", "\n", "return", "cpy", "\n", "", "", "else", ":", "\n", "    ", "get", "=", "lambda", ":", "lst", "\n", "\n", "", "return", "get", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.dataset_utils.build_stratified_epoch_fn": [[30, 60], ["debias.utils.py_utils.split", "list", "numpy.random.shuffle", "out.append", "group.pop", "len"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split"], ["", "def", "build_stratified_epoch_fn", "(", "lst", ",", "n_groups", ")", ":", "\n", "  ", "\"\"\"Build a function to return `lst` after doing a stratified shuffle\n\n  Assuming the data is sorted by a per-example score, the data will yield examples\n  with scores that are deliberately spread out\n\n  We used this for some of the QA dataset so its preserved here for exactness,\n  although I *think* it doesn't really make a difference\n  \"\"\"", "\n", "\n", "# Split lst into group, assuming lst is sorted by the score we are stratifying on,", "\n", "# each group will contain examples with a similar score", "\n", "groups", "=", "py_utils", ".", "split", "(", "lst", ",", "n_groups", ")", "\n", "\n", "def", "build", "(", ")", ":", "\n", "    ", "local_groups", "=", "[", "list", "(", "x", ")", "for", "x", "in", "groups", "]", "\n", "for", "group", "in", "local_groups", ":", "\n", "# Shuffle the individual groups", "\n", "      ", "np", ".", "random", ".", "shuffle", "(", "group", ")", "\n", "\n", "# Merge the groups", "\n", "", "out", "=", "[", "]", "\n", "while", "local_groups", ":", "\n", "      ", "for", "group", "in", "local_groups", ":", "\n", "        ", "out", ".", "append", "(", "group", ".", "pop", "(", ")", ")", "\n", "", "local_groups", "=", "[", "x", "for", "x", "in", "local_groups", "if", "len", "(", "x", ")", ">", "0", "]", "\n", "\n", "", "return", "out", "\n", "\n", "", "return", "build", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.TokenizeProcessor.__init__": [[117, 119], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tokenizer", ")", ":", "\n", "    ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.TokenizeProcessor.process": [[120, 131], ["out.append", "TextPairExample", "tokenizer.tokenize", "tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.tokenizer.NltkAndPunctTokenizer.tokenize", "home.repos.pwc.inspect_result.chrisc36_debias.utils.tokenizer.NltkAndPunctTokenizer.tokenize"], ["", "def", "process", "(", "self", ",", "data", ":", "Iterable", "[", "TextPairExample", "]", ")", "->", "List", "[", "TextPairExample", "]", ":", "\n", "    ", "tokenizer", "=", "self", ".", "tokenizer", "\n", "out", "=", "[", "]", "\n", "for", "example", "in", "data", ":", "\n", "      ", "out", ".", "append", "(", "TextPairExample", "(", "\n", "example", ".", "id", ",", "\n", "tokenizer", ".", "tokenize", "(", "example", ".", "premise", ")", ",", "\n", "tokenizer", ".", "tokenize", "(", "example", ".", "hypothesis", ")", ",", "\n", "example", ".", "label", "\n", ")", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.MnliTrainingDataLoader.__init__": [[162, 167], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "n_train_eval_sample", ",", "n_train_sample", "=", "None", ",", "n_dev_sample", "=", "None", ",", "use_bias", "=", "True", ")", ":", "\n", "    ", "self", ".", "n_train_eval_sample", "=", "n_train_eval_sample", "\n", "self", ".", "n_train_sample", "=", "n_train_sample", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "n_dev_sample", "=", "n_dev_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.MnliTrainingDataLoader.load": [[168, 193], ["mnli.tokenize_examples", "mnli.tokenize_examples", "tokenize_examples.sort", "tokenize_examples.sort", "set", "mnli.make_dataset", "dict", "mnli.make_dataset", "debias.datasets.training_data_loader.TrainingData", "mnli.load_mnli", "mnli.load_mnli", "mnli.load_bias", "mnli.make_dataset", "set.update", "set.update", "len", "len"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.tokenize_examples", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.tokenize_examples", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_mnli", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_mnli", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_bias", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset"], ["", "def", "load", "(", "self", ",", "tokenizer", ",", "n_processes", "=", "None", ")", ":", "\n", "    ", "train", "=", "tokenize_examples", "(", "load_mnli", "(", "True", ",", "self", ".", "n_train_sample", ")", ",", "tokenizer", ",", "n_processes", ")", "\n", "dev", "=", "tokenize_examples", "(", "load_mnli", "(", "False", ",", "self", ".", "n_dev_sample", ")", ",", "tokenizer", ",", "n_processes", ")", "\n", "dev", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", ".", "premise", ")", ")", "\n", "train", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", ".", "premise", ")", ")", "\n", "\n", "voc", "=", "set", "(", ")", "\n", "for", "ds", "in", "[", "train", ",", "dev", "]", ":", "\n", "      ", "for", "ex", "in", "ds", ":", "\n", "        ", "voc", ".", "update", "(", "ex", ".", "premise", ")", "\n", "voc", ".", "update", "(", "ex", ".", "hypothesis", ")", "\n", "\n", "", "", "if", "self", ".", "use_bias", ":", "\n", "      ", "bias", "=", "load_bias", "(", "\"train\"", ")", "\n", "", "else", ":", "\n", "      ", "bias", "=", "None", "\n", "\n", "", "train_ds", "=", "make_dataset", "(", "train", ",", "bias", ",", "shuffle", "=", "True", ")", "\n", "eval_sets", "=", "dict", "(", ")", "\n", "if", "self", ".", "n_train_eval_sample", ":", "\n", "      ", "eval_sets", "[", "\"train\"", "]", "=", "make_dataset", "(", "train", ",", "None", ",", "shuffle", "=", "False", ",", "sample", "=", "self", ".", "n_train_eval_sample", ")", "\n", "\n", "", "eval_sets", "[", "\"dev\"", "]", "=", "make_dataset", "(", "dev", ",", "None", ",", "shuffle", "=", "False", ")", "\n", "\n", "return", "TrainingData", "(", "train_ds", ",", "eval_sets", ",", "voc", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.load_hans": [[33, 60], ["logging.info", "os.path.join", "os.path.exists", "logging.info", "debias.utils.py_utils.download_to_file", "open", "f.readline", "f.readlines", "numpy.random.RandomState().choice", "line.split", "out.append", "TextPairExample", "numpy.random.RandomState", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_to_file", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split"], ["def", "load_hans", "(", "n_samples", "=", "None", ")", "->", "List", "[", "TextPairExample", "]", ":", "\n", "  ", "out", "=", "[", "]", "\n", "logging", ".", "info", "(", "\"Loading hans...\"", ")", "\n", "src", "=", "join", "(", "config", ".", "HANS_SOURCE", ",", "\"heuristics_evaluation_set.txt\"", ")", "\n", "if", "not", "exists", "(", "src", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"Downloading source to %s...\"", "%", "config", ".", "HANS_SOURCE", ")", "\n", "py_utils", ".", "download_to_file", "(", "HANS_URL", ",", "src", ")", "\n", "\n", "", "with", "open", "(", "src", ",", "\"r\"", ")", "as", "f", ":", "\n", "    ", "f", ".", "readline", "(", ")", "\n", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "if", "n_samples", "is", "not", "None", ":", "\n", "    ", "lines", "=", "np", ".", "random", ".", "RandomState", "(", "16349", "+", "n_samples", ")", ".", "choice", "(", "lines", ",", "n_samples", ",", "replace", "=", "False", ")", "\n", "\n", "", "for", "line", "in", "lines", ":", "\n", "    ", "parts", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "label", "=", "parts", "[", "0", "]", "\n", "if", "label", "==", "\"non-entailment\"", ":", "\n", "      ", "label", "=", "0", "\n", "", "elif", "label", "==", "\"entailment\"", ":", "\n", "      ", "label", "=", "1", "\n", "", "else", ":", "\n", "      ", "raise", "RuntimeError", "(", ")", "\n", "", "s1", ",", "s2", ",", "pair_id", "=", "parts", "[", "5", ":", "8", "]", "\n", "out", ".", "append", "(", "TextPairExample", "(", "pair_id", ",", "s1", ",", "s2", ",", "label", ")", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.ensure_mnli_is_downloaded": [[62, 67], ["os.path.join", "debias.utils.py_utils.download_zip", "os.path.exists", "len", "os.listdir"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_zip"], ["", "def", "ensure_mnli_is_downloaded", "(", ")", ":", "\n", "  ", "mnli_source", "=", "join", "(", "config", ".", "GLUE_SOURCE", ",", "\"MNLI\"", ")", "\n", "if", "exists", "(", "mnli_source", ")", "and", "len", "(", "listdir", "(", "mnli_source", ")", ")", ">", "0", ":", "\n", "    ", "return", "\n", "", "py_utils", ".", "download_zip", "(", "\"MNLI\"", ",", "MNLI_URL", ",", "config", ".", "GLUE_SOURCE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.load_mnli": [[69, 89], ["mnli.ensure_mnli_is_downloaded", "logging.info", "os.path.join", "os.path.join", "open", "f.readline", "f.readlines", "numpy.random.RandomState().choice", "line.split.split", "out.append", "TextPairExample", "numpy.random.RandomState", "line[].rstrip"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.ensure_mnli_is_downloaded", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split"], ["", "def", "load_mnli", "(", "is_train", ",", "sample", "=", "None", ")", "->", "List", "[", "TextPairExample", "]", ":", "\n", "  ", "ensure_mnli_is_downloaded", "(", ")", "\n", "if", "is_train", ":", "\n", "    ", "filename", "=", "join", "(", "config", ".", "GLUE_SOURCE", ",", "\"MNLI\"", ",", "\"train.tsv\"", ")", "\n", "", "else", ":", "\n", "    ", "filename", "=", "join", "(", "config", ".", "GLUE_SOURCE", ",", "\"MNLI\"", ",", "\"dev_matched.tsv\"", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Loading mnli \"", "+", "(", "\"train\"", "if", "is_train", "else", "\"dev\"", ")", ")", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "    ", "f", ".", "readline", "(", ")", "\n", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "if", "sample", ":", "\n", "    ", "lines", "=", "np", ".", "random", ".", "RandomState", "(", "26096781", "+", "sample", ")", ".", "choice", "(", "lines", ",", "sample", ",", "replace", "=", "False", ")", "\n", "\n", "", "out", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "    ", "line", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "out", ".", "append", "(", "TextPairExample", "(", "line", "[", "0", "]", ",", "line", "[", "8", "]", ",", "line", "[", "9", "]", ",", "NLI_LABEL_MAP", "[", "line", "[", "-", "1", "]", ".", "rstrip", "(", ")", "]", ")", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.load_bias": [[91, 112], ["os.path.join", "debias.utils.py_utils.load_pickle", "py_utils.load_pickle.items", "ValueError", "os.path.exists", "logging.info", "debias.utils.py_utils.download_from_drive", "numpy.array", "numpy.log", "numpy.log"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_pickle", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_from_drive"], ["", "def", "load_bias", "(", "dataset_name", ")", "->", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", ":", "\n", "  ", "\"\"\"Load dictionary of example_id->bias where bias is a length 3 array\n  of log-probabilities\"\"\"", "\n", "\n", "if", "dataset_name", "not", "in", "MNLI_BIAS_DRIVE_IDS", ":", "\n", "    ", "raise", "ValueError", "(", "dataset_name", ")", "\n", "", "bias_src", "=", "join", "(", "config", ".", "MNLI_WORD_OVERLAP_BIAS", ",", "dataset_name", "+", "\".pkl\"", ")", "\n", "if", "not", "exists", "(", "bias_src", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"Downloading MNLI bias to %s...\"", "%", "bias_src", ")", "\n", "py_utils", ".", "download_from_drive", "(", "MNLI_BIAS_DRIVE_IDS", "[", "dataset_name", "]", ",", "bias_src", ")", "\n", "\n", "", "bias", "=", "py_utils", ".", "load_pickle", "(", "bias_src", ")", "\n", "for", "k", ",", "v", "in", "bias", ".", "items", "(", ")", ":", "\n", "# Convert from entail vs non-entail to 3-way classes by splitting non-entail", "\n", "# to neutral and contradict", "\n", "    ", "bias", "[", "k", "]", "=", "np", ".", "array", "(", "[", "\n", "v", "[", "0", "]", "-", "np", ".", "log", "(", "2.", ")", ",", "\n", "v", "[", "1", "]", ",", "\n", "v", "[", "0", "]", "-", "np", ".", "log", "(", "2.", ")", ",", "\n", "]", ")", "\n", "", "return", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.tokenize_examples": [[133, 136], ["debias.utils.process_par.process_par", "mnli.TokenizeProcessor"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.process_par.process_par"], ["", "", "def", "tokenize_examples", "(", "examples", ":", "List", "[", "TextPairExample", "]", ",", "tokenizer", ",", "n_processes", ")", "->", "List", "[", "TextPairExample", "]", ":", "\n", "  ", "return", "process_par", ".", "process_par", "(", "\n", "examples", ",", "TokenizeProcessor", "(", "tokenizer", ")", ",", "n_processes", ",", "desc", "=", "\"tokenizing\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.make_dataset": [[138, 158], ["debias.datasets.dataset_utils.build_epoch_fn", "debias.utils.py_utils.transpose_lists", "tensorflow.data.Dataset.from_generator", "tf.data.Dataset.from_generator.map", "structure.append", "tuple", "tuple", "tuple", "zip"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.dataset_utils.build_epoch_fn", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.transpose_lists"], ["", "def", "make_dataset", "(", "data", ":", "List", "[", "TextPairExample", "]", ",", "bias", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "sample", "=", "None", ",", "shuffle", "=", "True", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "  ", "if", "bias", ":", "\n", "    ", "data", "=", "[", "tuple", "(", "x", ")", "+", "(", "bias", "[", "x", ".", "id", "]", ",", ")", "for", "x", "in", "data", "]", "\n", "\n", "", "fn", "=", "build_epoch_fn", "(", "data", ",", "sample", ",", "shuffle", "=", "shuffle", ")", "\n", "structure", "=", "[", "\n", "(", "\"id\"", ",", "tf", ".", "string", ",", "(", ")", ")", ",", "\n", "(", "PREMISE_KEY", ",", "tf", ".", "string", ",", "(", "None", ",", ")", ")", ",", "\n", "(", "HYPOTHESIS_KEY", ",", "tf", ".", "string", ",", "(", "None", ",", ")", ")", ",", "\n", "(", "\"label\"", ",", "tf", ".", "int32", ",", "(", ")", ")", "\n", "]", "\n", "if", "bias", ":", "\n", "    ", "structure", ".", "append", "(", "(", "\"bias\"", ",", "tf", ".", "float32", ",", "(", "3", ",", ")", ")", ")", "\n", "", "names", ",", "dtypes", ",", "shapes", "=", "py_utils", ".", "transpose_lists", "(", "structure", ")", "\n", "ds", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "fn", ",", "tuple", "(", "dtypes", ")", ",", "tuple", "(", "shapes", ")", ")", "\n", "\n", "def", "to_map", "(", "*", "args", ")", ":", "\n", "    ", "return", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "names", ",", "args", ")", "}", "\n", "\n", "", "return", "ds", ".", "map", "(", "to_map", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.synthetic.MnliWithSyntheticBiasLoading.__init__": [[81, 89], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "train_noise", ",", "n_train_eval", ",", "indicator_noise", "=", "None", ",", "n_train_sample", "=", "None", ",", "\n", "n_dev_sample", "=", "None", ")", ":", "\n", "    ", "self", ".", "train_noise", "=", "train_noise", "\n", "self", ".", "n_train_eval", "=", "n_train_eval", "\n", "self", ".", "n_train_sample", "=", "n_train_sample", "\n", "self", ".", "n_dev_sample", "=", "n_dev_sample", "\n", "self", ".", "indicator_noise", "=", "indicator_noise", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.synthetic.MnliWithSyntheticBiasLoading.load": [[90, 118], ["debias.datasets.mnli.tokenize_examples", "debias.datasets.mnli.tokenize_examples", "add_noise.sort", "debias.datasets.mnli.tokenize_examples.sort", "set", "synthetic.add_noise", "debias.datasets.mnli.make_dataset", "synthetic.add_noise", "add_noise.sort", "debias.datasets.mnli.make_dataset", "dict", "debias.datasets.training_data_loader.TrainingData", "debias.datasets.mnli.load_mnli", "debias.datasets.mnli.load_mnli", "set.update", "set.update", "set.update", "set.update", "bias_fn", "debias.datasets.mnli.make_dataset", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.tokenize_examples", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.tokenize_examples", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.synthetic.add_noise", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.synthetic.add_noise", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_mnli", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_mnli", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset"], ["", "def", "load", "(", "self", ",", "tokenizer", ",", "n_processes", "=", "None", ")", ":", "\n", "    ", "train", "=", "tokenize_examples", "(", "load_mnli", "(", "True", ",", "self", ".", "n_train_sample", ")", ",", "tokenizer", ",", "n_processes", ")", "\n", "dev", "=", "tokenize_examples", "(", "load_mnli", "(", "False", ",", "self", ".", "n_dev_sample", ")", ",", "tokenizer", ",", "n_processes", ")", "\n", "dev", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", ".", "premise", ")", ")", "\n", "train", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", ".", "premise", ")", ")", "\n", "\n", "voc", "=", "set", "(", ")", "\n", "for", "_", ",", "p", ",", "h", ",", "_", "in", "train", ":", "\n", "      ", "voc", ".", "update", "(", "p", ")", "\n", "voc", ".", "update", "(", "h", ")", "\n", "", "for", "_", ",", "p", ",", "h", ",", "_", "in", "dev", ":", "\n", "      ", "voc", ".", "update", "(", "p", ")", "\n", "voc", ".", "update", "(", "h", ")", "\n", "\n", "", "train", ",", "bias_fn", "=", "add_noise", "(", "train", ",", "self", ".", "train_noise", ",", "self", ".", "indicator_noise", ",", "3", ",", "True", ")", "\n", "train_bias", "=", "{", "x", ".", "id", ":", "bias_fn", "(", "x", ")", "for", "x", "in", "train", "}", "\n", "\n", "train_ds", "=", "make_dataset", "(", "train", ",", "train_bias", ")", "\n", "\n", "if", "self", ".", "n_train_eval", ">", "0", ":", "\n", "      ", "train_eval", "=", "make_dataset", "(", "train", ",", "None", ",", "sample", "=", "self", ".", "n_train_eval", ",", "shuffle", "=", "False", ")", "\n", "\n", "", "dev", "=", "add_noise", "(", "dev", ",", "self", ".", "train_noise", ",", "self", ".", "indicator_noise", ",", "3", ",", "False", ")", "\n", "dev", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", ".", "premise", ")", ")", "\n", "dev_eval", "=", "make_dataset", "(", "dev", ",", "None", ",", "sample", "=", "self", ".", "n_dev_sample", ",", "shuffle", "=", "False", ")", "\n", "\n", "eval_sets", "=", "dict", "(", "biased_dev", "=", "dev_eval", ",", "train", "=", "train_eval", ")", "\n", "return", "TrainingData", "(", "train_ds", ",", "eval_sets", ",", "voc", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.synthetic.add_noise": [[10, 76], ["enumerate", "isinstance", "zlib.crc32", "numpy.random.RandomState", "example_noise.append", "out.append", "numpy.zeros", "numpy.zeros", "zip", "numpy.expand_dims", "numpy.log().astype", "ValueError", "indicators.append", "debias.datasets.mnli.TextPairExample", "np.random.RandomState.uniform", "np.random.RandomState.uniform", "np.random.RandomState.uniform", "numpy.log", "np.random.RandomState.randint", "str", "str", "int", "str", "str"], "function", ["None"], ["def", "add_noise", "(", "examples", ":", "List", "[", "TextPairExample", "]", ",", "prob_correct", ",", "indicator_prob", ",", "n_classes", ",", "build_bias_model", "=", "False", ")", ":", "\n", "  ", "\"\"\"\n  :param examples: Tokenized TextPair examples to modify\n  :param prob_correct: Chance the bias token agrees with the label\n  :param indicator_prob: Optionally, chance the indicator token is one, in which case the bias will be random\n  :param n_classes:\n  :param build_bias_model: Build and return a function that maps  TextPairExample -> bias predictions\n  :return: List of modified `TextPairExample`, and optionally the bias-only model\n  \"\"\"", "\n", "example_noise", "=", "[", "]", "\n", "indicators", "=", "[", "]", "\n", "for", "x", "in", "examples", ":", "\n", "    ", "if", "isinstance", "(", "x", ".", "hypothesis", ",", "str", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"Example not tokenized\"", ")", "\n", "", "l", "=", "x", "[", "3", "]", "\n", "# To ensure the noise is consistent between examples, use a hash as the seed", "\n", "h", "=", "crc32", "(", "(", "str", "(", "x", ".", "label", ")", "+", "\"\\n\"", "+", "\" \"", ".", "join", "(", "x", ".", "hypothesis", ")", "+", "\"\\n\"", "+", "\" \"", ".", "join", "(", "x", ".", "premise", ")", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "h", ")", "\n", "\n", "if", "indicator_prob", "is", "not", "None", ":", "\n", "      ", "if", "rng", ".", "uniform", "(", "0", ",", "1", ")", "<", "indicator_prob", ":", "\n", "# Indicator is off, the bias matches with `prob_correct`", "\n", "        ", "group", "=", "0", "\n", "p", "=", "prob_correct", "\n", "", "else", ":", "# Indicator is set, the bias is random", "\n", "        ", "group", "=", "1", "\n", "p", "=", "1", "/", "n_classes", "\n", "", "indicators", ".", "append", "(", "group", ")", "\n", "\n", "match_label", "=", "rng", ".", "uniform", "(", "0", ",", "1", ")", "<", "p", "\n", "", "else", ":", "\n", "      ", "match_label", "=", "rng", ".", "uniform", "(", "0", ",", "1", ")", "<", "prob_correct", "\n", "\n", "", "if", "match_label", ":", "\n", "      ", "noise", "=", "l", "\n", "", "else", ":", "\n", "      ", "noise", "=", "(", "l", "+", "rng", ".", "randint", "(", "1", ",", "n_classes", ")", ")", "%", "n_classes", "# Select a different class", "\n", "", "example_noise", ".", "append", "(", "noise", ")", "\n", "\n", "", "out", "=", "[", "]", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "examples", ")", ":", "\n", "    ", "n", "=", "example_noise", "[", "i", "]", "\n", "if", "indicator_prob", "is", "not", "None", ":", "\n", "      ", "new_hypothesis", "=", "[", "str", "(", "n", ")", "]", "+", "x", ".", "hypothesis", "+", "[", "str", "(", "indicators", "[", "i", "]", ")", "]", "\n", "", "else", ":", "\n", "      ", "new_hypothesis", "=", "[", "str", "(", "n", ")", "]", "+", "x", ".", "hypothesis", "\n", "", "out", ".", "append", "(", "TextPairExample", "(", "x", ".", "id", ",", "x", ".", "premise", ",", "new_hypothesis", ",", "x", ".", "label", ")", ")", "\n", "\n", "", "if", "build_bias_model", ":", "\n", "# 'Trains' the bias-only model, to simulate the fact the bias-only model will not be perfect", "\n", "# it uses the empirical bias/label correlation, not the true correlation", "\n", "    ", "bias_model", "=", "np", ".", "zeros", "(", "(", "3", ",", "3", ")", ")", "\n", "counts", "=", "np", ".", "zeros", "(", "3", ")", "\n", "for", "x", ",", "n", "in", "zip", "(", "examples", ",", "example_noise", ")", ":", "\n", "      ", "bias_model", "[", "n", ",", "x", ".", "label", "]", "+=", "1", "\n", "counts", "[", "n", "]", "+=", "1", "\n", "\n", "", "bias_model", "/=", "np", ".", "expand_dims", "(", "counts", ",", "1", ")", "\n", "bias_model", "=", "np", ".", "log", "(", "bias_model", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "def", "compute_bias", "(", "ex", ":", "TextPairExample", ")", ":", "\n", "      ", "return", "bias_model", "[", "int", "(", "ex", ".", "hypothesis", "[", "0", "]", ")", "]", "\n", "\n", "", "return", "out", ",", "compute_bias", "\n", "", "else", ":", "\n", "    ", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.training_data_loader.TrainingData.__init__": [[19, 35], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "train", ":", "tf", ".", "data", ".", "Dataset", ",", "eval_sets", ":", "Dict", "[", "str", ",", "tf", ".", "data", ".", "Dataset", "]", ",", "voc", ":", "Set", "[", "str", "]", ")", ":", "\n", "    ", "\"\"\"\n    All datasets yield individual examples, and should have (at least) the following structure:\n    {\n      HYPOTHESIS_KEY: <tf.string>[hypothesis_len] hypothesis or question tokens\n      PREMISE_KEY: <tf.string>[premise_len] premise or passage tokens\n      \"label\": label information, can be a tensor or dictionary\n    }\n\n    :param train: Training data, should yield shuffled examples\n    :param eval_sets: Dictionary of eval sets, should yield sorted example\n    :param voc: Set of words in all datasets\n    \"\"\"", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "eval_sets", "=", "eval_sets", "\n", "self", ".", "voc", "=", "voc", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.training_data_loader.TrainingDataLoader.load": [[38, 40], ["NotImplementedError"], "methods", ["None"], ["  ", "def", "load", "(", "self", ",", "tokenizer", ",", "n_processes", "=", "None", ")", "->", "TrainingData", ":", "\n", "    ", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.SquadQuestion.__init__": [[46, 53], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "question_id", ":", "str", ",", "words", ":", "List", "[", "str", "]", ",", "\n", "answer_text", ":", "List", "[", "str", "]", ",", "\n", "answer_spans", ":", "np", ".", "ndarray", ")", ":", "\n", "    ", "self", ".", "question_id", "=", "question_id", "\n", "self", ".", "words", "=", "words", "\n", "self", ".", "answer_text", "=", "answer_text", "\n", "self", ".", "answer_spans", "=", "answer_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.SquadQuestion.__repr__": [[54, 56], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "    ", "return", "\" \"", ".", "join", "(", "self", ".", "words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadParagraph.__init__": [[61, 70], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "passage_str", ",", "tokens", ":", "List", "[", "str", "]", ",", "inv", ",", "pos_tags", ":", "List", "[", "str", "]", ",", "\n", "ner_tags", ":", "List", "[", "str", "]", ",", "sentence_lens", ",", "questions", ":", "List", "[", "SquadQuestion", "]", ")", ":", "\n", "    ", "self", ".", "passage_str", "=", "passage_str", "\n", "self", ".", "tokens", "=", "tokens", "\n", "self", ".", "inv", "=", "inv", "\n", "self", ".", "pos_tags", "=", "pos_tags", "\n", "self", ".", "ner_tags", "=", "ner_tags", "\n", "self", ".", "sentence_lens", "=", "sentence_lens", "\n", "self", ".", "questions", "=", "questions", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadParagraph.sentences": [[71, 78], ["sentences.append"], "methods", ["None"], ["", "def", "sentences", "(", "self", ")", ":", "\n", "    ", "on", "=", "0", "\n", "sentences", "=", "[", "]", "\n", "for", "s", "in", "self", ".", "sentence_lens", ":", "\n", "      ", "sentences", ".", "append", "(", "self", ".", "tokens", "[", "on", ":", "on", "+", "s", "]", ")", "\n", "on", "+=", "s", "\n", "", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadLoader.__init__": [[242, 257], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "load_bias", "=", "True", ",", "\n", "filtered_bias", "=", "True", ",", "\n", "sample_train_eval", "=", "None", ",", "sample_dev_eval", "=", "None", ",", "\n", "sample_train", "=", "None", ",", "sample_dev", "=", "None", ",", "\n", "max_train_len", "=", "None", ",", "\n", "stratify", "=", "False", ")", ":", "\n", "    ", "self", ".", "filtered_bias", "=", "filtered_bias", "\n", "self", ".", "load_bias", "=", "load_bias", "\n", "self", ".", "sample_train", "=", "sample_train", "\n", "self", ".", "max_train_len", "=", "max_train_len", "\n", "self", ".", "sample_dev", "=", "sample_dev", "\n", "self", ".", "sample_train_eval", "=", "sample_train_eval", "\n", "self", ".", "sample_dev_eval", "=", "sample_dev_eval", "\n", "self", ".", "stratify", "=", "stratify", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadLoader.load": [[258, 297], ["squad.compute_voc", "zip", "dict", "squad.make_dataset", "debias.datasets.training_data_loader.TrainingData", "tensorflow.logging.info", "squad.load_annotated_squad", "datasets.append", "examples.sort", "tuple_datasets.append", "squad.load_bias", "squad.make_dataset_stratify", "squad.make_dataset", "squad.make_dataset", "numpy.random.choice().tolist", "squad.convert_to_tuples", "numpy.random.choice().tolist", "numpy.random.choice", "len", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.compute_voc", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.load_annotated_squad", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_bias", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset_stratify", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.convert_to_tuples"], ["", "def", "load", "(", "self", ",", "tokenizer", ",", "n_processes", "=", "None", ")", ":", "\n", "    ", "targets", "=", "[", "\"train\"", ",", "\"dev\"", "]", "\n", "\n", "datasets", "=", "[", "]", "\n", "for", "eval_set", "in", "targets", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "\"Loading %s...\"", "%", "eval_set", ")", "\n", "data", "=", "load_annotated_squad", "(", "eval_set", ")", "\n", "\n", "if", "eval_set", "==", "\"train\"", "and", "self", ".", "sample_train", ":", "\n", "        ", "data", "=", "np", ".", "random", ".", "choice", "(", "data", ",", "self", ".", "sample_train", ",", "False", ")", ".", "tolist", "(", ")", "\n", "", "elif", "eval_set", "==", "\"dev\"", "and", "self", ".", "sample_dev", ":", "\n", "        ", "data", "=", "np", ".", "random", ".", "choice", "(", "data", ",", "self", ".", "sample_dev", ",", "False", ")", ".", "tolist", "(", ")", "\n", "\n", "", "datasets", ".", "append", "(", "data", ")", "\n", "\n", "", "voc", "=", "compute_voc", "(", "*", "datasets", ")", "\n", "\n", "tuple_datasets", "=", "[", "]", "\n", "for", "name", ",", "examples", "in", "zip", "(", "targets", ",", "datasets", ")", ":", "\n", "      ", "examples", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", ".", "tokens", ")", ")", "\n", "tuple_datasets", ".", "append", "(", "convert_to_tuples", "(", "examples", ")", ")", "\n", "\n", "", "eval_sets", "=", "dict", "(", ")", "\n", "train_tuples", ",", "dev_tuples", "=", "tuple_datasets", "\n", "\n", "if", "self", ".", "load_bias", ":", "\n", "      ", "bias", "=", "load_bias", "(", "\"train\"", ",", "True", ")", "\n", "", "else", ":", "\n", "      ", "bias", "=", "None", "\n", "\n", "", "if", "self", ".", "stratify", ":", "\n", "      ", "train", "=", "make_dataset_stratify", "(", "train_tuples", ",", "bias", ",", "self", ".", "stratify", ")", "\n", "", "else", ":", "\n", "      ", "train", "=", "make_dataset", "(", "train_tuples", ",", "bias", ",", "shuffle", "=", "True", ")", "\n", "\n", "", "if", "self", ".", "sample_train_eval", ":", "\n", "      ", "eval_sets", "[", "\"train\"", "]", "=", "make_dataset", "(", "train_tuples", ",", "None", ",", "self", ".", "sample_train_eval", ",", "shuffle", "=", "False", ")", "\n", "", "eval_sets", "[", "\"dev\"", "]", "=", "make_dataset", "(", "dev_tuples", ",", "None", ",", "self", ".", "sample_dev", ",", "shuffle", "=", "False", ")", "\n", "return", "TrainingData", "(", "train", ",", "eval_sets", ",", "voc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.load_squad_documents": [[80, 91], ["os.path.join", "ValueError", "os.path.exists", "logging.info", "debias.utils.py_utils.download_to_file", "debias.utils.py_utils.load_json"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_to_file", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_json"], ["", "", "def", "load_squad_documents", "(", "dataset_name", ")", "->", "Dict", ":", "\n", "  ", "\"\"\"Loads the original SQuAD data, needed to run the official evaluation scripts\"\"\"", "\n", "\n", "if", "dataset_name", "not", "in", "SQUAD_URLS", ":", "\n", "    ", "raise", "ValueError", "(", "dataset_name", ")", "\n", "", "src", "=", "join", "(", "config", ".", "SQUAD_SOURCE", ",", "dataset_name", "+", "\".json\"", ")", "\n", "if", "not", "exists", "(", "src", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"Download SQuAD %s to %s\"", "%", "(", "dataset_name", ",", "src", ")", ")", "\n", "py_utils", ".", "download_to_file", "(", "SQUAD_URLS", "[", "dataset_name", "]", ",", "src", ")", "\n", "\n", "", "return", "py_utils", ".", "load_json", "(", "src", ")", "[", "\"data\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.load_annotated_squad": [[93, 103], ["os.path.join", "debias.utils.py_utils.load_pickle", "ValueError", "os.path.exists", "logging.info", "debias.utils.py_utils.download_from_drive"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_pickle", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_from_drive"], ["", "def", "load_annotated_squad", "(", "dataset_name", ")", "->", "List", "[", "AnnotatedSquadParagraph", "]", ":", "\n", "  ", "\"\"\"Loads SQuAD data that has been tokenized and tagged by CoreNLP\"\"\"", "\n", "\n", "if", "dataset_name", "not", "in", "DATASETS", ":", "\n", "    ", "raise", "ValueError", "(", "\"Invalid dataset %s\"", "%", "dataset_name", ")", "\n", "", "src", "=", "join", "(", "config", ".", "SQUAD_CORENLP", ",", "\"%s.pkl\"", "%", "dataset_name", ")", "\n", "if", "not", "exists", "(", "src", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"Download pre-processed SQuAD %s to %s\"", "%", "(", "dataset_name", ",", "src", ")", ")", "\n", "py_utils", ".", "download_from_drive", "(", "ANNOTATED_SQUAD_FILE_IDS", "[", "dataset_name", "]", ",", "src", ")", "\n", "", "return", "py_utils", ".", "load_pickle", "(", "src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.load_bias": [[105, 125], ["os.path.join", "debias.utils.py_utils.load_pickle", "ValueError", "os.path.exists", "logging.info", "debias.utils.py_utils.download_from_drive"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_pickle", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_from_drive"], ["", "def", "load_bias", "(", "dataset_name", ",", "filtered", "=", "False", ")", "->", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", ":", "\n", "  ", "\"\"\"Loads the output of our bias-only model\n\n  Note that since this produces per-token output, it is only valid on data with the\n  same tokenization as our annotated data.\n  \"\"\"", "\n", "if", "filtered", ":", "\n", "    ", "bias_ids", "=", "SQUAD_FILTERED_BIAS_FILE_IDS", "\n", "output_dir", "=", "SQUAD_TFIDF_FILTERED_BIAS", "\n", "", "else", ":", "\n", "    ", "bias_ids", "=", "SQUAD_BIAS_FILE_IDS", "\n", "output_dir", "=", "SQUAD_TFIDF_BIAS", "\n", "\n", "", "if", "dataset_name", "not", "in", "bias_ids", ":", "\n", "    ", "raise", "ValueError", "(", "\"No bias for %s\"", "%", "dataset_name", ")", "\n", "", "src", "=", "join", "(", "output_dir", ",", "\"%s.pkl\"", "%", "dataset_name", ")", "\n", "if", "not", "exists", "(", "src", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"Downloading SQuAD bias for %s to %s\"", "%", "(", "dataset_name", ",", "src", ")", ")", "\n", "py_utils", ".", "download_from_drive", "(", "bias_ids", "[", "dataset_name", "]", ",", "src", ")", "\n", "", "return", "py_utils", ".", "load_pickle", "(", "src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.compute_voc": [[127, 135], ["set", "set.update", "set.update"], "function", ["None"], ["", "def", "compute_voc", "(", "*", "datasets", ":", "List", "[", "AnnotatedSquadParagraph", "]", ")", "->", "Set", "[", "str", "]", ":", "\n", "  ", "voc", "=", "set", "(", ")", "\n", "for", "data", "in", "datasets", ":", "\n", "    ", "for", "x", "in", "data", ":", "\n", "      ", "voc", ".", "update", "(", "x", ".", "tokens", ")", "\n", "for", "q", "in", "x", ".", "questions", ":", "\n", "        ", "voc", ".", "update", "(", "q", ".", "words", ")", "\n", "", "", "", "return", "voc", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.convert_to_tuples": [[137, 151], ["numpy.zeros", "tuples.append", "len"], "function", ["None"], ["", "def", "convert_to_tuples", "(", "examples", ":", "List", "[", "AnnotatedSquadParagraph", "]", ")", "->", "List", "[", "Tuple", "]", ":", "\n", "  ", "\"\"\"Convert SQuAD paragraphs to individual examples in tuple form\"\"\"", "\n", "tuples", "=", "[", "]", "\n", "for", "ex", "in", "examples", ":", "\n", "    ", "for", "q", "in", "ex", ".", "questions", ":", "\n", "      ", "dense_answers", "=", "np", ".", "zeros", "(", "(", "len", "(", "ex", ".", "tokens", ")", ",", "2", ")", ",", "np", ".", "bool", ")", "\n", "for", "s", ",", "e", "in", "q", ".", "answer_spans", ":", "\n", "        ", "dense_answers", "[", "s", ",", "0", "]", "=", "True", "\n", "dense_answers", "[", "e", ",", "1", "]", "=", "True", "\n", "\n", "", "label", "=", "(", "ex", ".", "passage_str", ",", "ex", ".", "inv", ",", "dense_answers", ",", "q", ".", "answer_text", ")", "\n", "features", "=", "(", "q", ".", "question_id", ",", "q", ".", "words", ",", "ex", ".", "tokens", ")", "\n", "tuples", ".", "append", "(", "features", "+", "label", ")", "\n", "", "", "return", "tuples", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset": [[171, 193], ["list", "debias.datasets.dataset_utils.build_epoch_fn", "tensorflow.data.Dataset.from_generator", "tf.data.Dataset.from_generator.map", "len", "list.append", "tuple", "debias.utils.py_utils.transpose_lists", "zip", "zip"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.dataset_utils.build_epoch_fn", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.transpose_lists"], ["def", "make_dataset", "(", "lst", ":", "List", "[", "Tuple", "]", ",", "bias", "=", "None", ",", "sample", "=", "None", ",", "shuffle", "=", "False", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "  ", "\"\"\"Convert tuples from `convert_to_tuples` into a tf.data.Dataset\"\"\"", "\n", "dataset_structure", "=", "list", "(", "base_features", ")", "\n", "if", "bias", ":", "\n", "    ", "n", "=", "len", "(", "base_features", ")", "\n", "lst", "=", "[", "x", "[", ":", "n", "]", "+", "(", "bias", "[", "x", "[", "0", "]", "]", ",", ")", "+", "x", "[", "n", ":", "]", "for", "x", "in", "lst", "]", "\n", "dataset_structure", ".", "append", "(", "(", "\"bias\"", ",", "tf", ".", "float32", ",", "(", "None", ",", "2", ")", ")", ")", "\n", "\n", "", "dataset_structure", "+=", "label_structure", "\n", "\n", "ds_names", ",", "ds_dtypes", ",", "ds_shapes", "=", "[", "tuple", "(", "x", ")", "for", "x", "in", "py_utils", ".", "transpose_lists", "(", "dataset_structure", ")", "]", "\n", "\n", "get", "=", "build_epoch_fn", "(", "lst", ",", "sample", ",", "shuffle", ")", "\n", "data", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "get", ",", "ds_dtypes", ",", "ds_shapes", ")", "\n", "\n", "def", "to_dict", "(", "*", "args", ")", ":", "\n", "    ", "labels", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "ds_names", "[", "-", "n_label_elements", ":", "]", ",", "args", "[", "-", "n_label_elements", ":", "]", ")", "}", "\n", "features", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "ds_names", "[", ":", "-", "n_label_elements", "]", ",", "args", "[", ":", "-", "n_label_elements", "]", ")", "}", "\n", "features", "[", "\"label\"", "]", "=", "labels", "\n", "return", "features", "\n", "\n", "", "return", "data", ".", "map", "(", "to_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset_stratify": [[195, 237], ["list", "numpy.argsort", "debias.datasets.dataset_utils.build_stratified_epoch_fn", "tensorflow.data.Dataset.from_generator", "tf.data.Dataset.from_generator.map", "len", "list.append", "tuple", "len", "ValueError", "debias.utils.py_utils.transpose_lists", "enumerate", "len", "bias_probs.append", "bias_probs.append", "bias[].sum", "zip", "zip"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.dataset_utils.build_stratified_epoch_fn", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.transpose_lists"], ["", "def", "make_dataset_stratify", "(", "lst", ":", "List", "[", "Tuple", "]", ",", "bias", ",", "n_groups", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "  ", "\"\"\"Convert tuples from `convert_to_tuples` into a tf.data.Dataset,\n  while stratifying the bias accuracy\"\"\"", "\n", "dataset_structure", "=", "list", "(", "base_features", ")", "\n", "if", "bias", ":", "\n", "    ", "n", "=", "len", "(", "base_features", ")", "\n", "lst", "=", "[", "x", "[", ":", "n", "]", "+", "(", "bias", "[", "x", "[", "0", "]", "]", ",", ")", "+", "x", "[", "n", ":", "]", "for", "x", "in", "lst", "]", "\n", "dataset_structure", ".", "append", "(", "(", "\"bias\"", ",", "tf", ".", "float32", ",", "(", "None", ",", "2", ")", ")", ")", "\n", "\n", "", "dataset_structure", "+=", "label_structure", "\n", "\n", "ds_names", ",", "ds_dtypes", ",", "ds_shapes", "=", "[", "tuple", "(", "x", ")", "for", "x", "in", "py_utils", ".", "transpose_lists", "(", "dataset_structure", ")", "]", "\n", "\n", "bias_ix", "=", "[", "i", "for", "i", ",", "name", "in", "enumerate", "(", "ds_names", ")", "if", "name", "==", "\"bias\"", "]", "\n", "if", "len", "(", "bias_ix", ")", "!=", "1", ":", "\n", "    ", "raise", "ValueError", "(", ")", "\n", "", "bias_ix", "=", "bias_ix", "[", "0", "]", "\n", "\n", "bias_probs", "=", "[", "]", "\n", "for", "example", "in", "lst", ":", "\n", "    ", "bias", "=", "example", "[", "bias_ix", "]", "\n", "spans", "=", "example", "[", "-", "2", "]", "\n", "if", "len", "(", "spans", ")", "==", "0", ":", "\n", "      ", "bias_probs", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "      ", "valid", "=", "example", "[", "-", "2", "]", "\n", "bias_probs", ".", "append", "(", "bias", "[", "valid", "]", ".", "sum", "(", ")", ")", "\n", "\n", "", "", "ix", "=", "np", ".", "argsort", "(", "bias_probs", ")", "\n", "lst", "=", "[", "lst", "[", "i", "]", "for", "i", "in", "ix", "]", "\n", "\n", "fn", "=", "build_stratified_epoch_fn", "(", "lst", ",", "n_groups", ")", "\n", "\n", "lst", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "fn", ",", "ds_dtypes", ",", "ds_shapes", ")", "\n", "\n", "def", "to_dict", "(", "*", "args", ")", ":", "\n", "    ", "labels", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "ds_names", "[", "-", "n_label_elements", ":", "]", ",", "args", "[", "-", "n_label_elements", ":", "]", ")", "}", "\n", "features", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "ds_names", "[", ":", "-", "n_label_elements", "]", ",", "args", "[", ":", "-", "n_label_elements", "]", ")", "}", "\n", "features", "[", "\"label\"", "]", "=", "labels", "\n", "return", "features", "\n", "\n", "", "return", "lst", ".", "map", "(", "to_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.train_debiased_squad.main": [[18, 99], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "debias.utils.cli_utils.add_general_args", "debias.utils.cli_utils.add_loss_args", "argparse.ArgumentParser.parse_args", "debias.training.trainer.AdamOptimizer", "debias.datasets.dataset_utils.QuantileBatcher", "debias.training.evaluator.Evaluator", "debias.training.trainer.Trainer", "debias.modules.cudnn_recurrent_dropout.CudnnLSTMRecurrentDropout", "debias.models.text_pair_qa_model.TextPairQaDebiasingModel", "debias.utils.py_utils.add_stdout_logger", "debias.training.trainer.Trainer.train", "debias.datasets.squad.AnnotatedSquadLoader", "debias.datasets.squad.AnnotatedSquadLoader", "open", "f.read", "logging.info", "debias.experiments.eval_debiased_squad.compute_all_scores", "debias.modules.word_and_char_encoder.WordAndCharEncoder", "debias.modules.layers.seq", "debias.modules.attention_layers.BiAttention", "debias.modules.layers.seq", "debias.utils.cli_utils.get_qa_loss_fn", "debias.modules.layers.VariationalDropout", "debias.modules.layers.VariationalDropout", "debias.modules.attention_layers.WeightedDot", "debias.modules.layers.FullyConnected", "debias.modules.layers.VariationalDropout", "debias.modules.layers.VariationalDropout", "debias.modules.layers.VariationalDropout", "debias.modules.layers.Conv1d", "debias.modules.layers.MaxPooler"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.cli_utils.add_general_args", "home.repos.pwc.inspect_result.chrisc36_debias.utils.cli_utils.add_loss_args", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.add_stdout_logger", "home.repos.pwc.inspect_result.chrisc36_debias.training.trainer.Trainer.train", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_squad.compute_all_scores", "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.seq", "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.seq", "home.repos.pwc.inspect_result.chrisc36_debias.utils.cli_utils.get_qa_loss_fn"], ["def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--stratify\"", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--bias\"", ",", "choices", "=", "[", "\"tfidf\"", ",", "\"tfidf_filtered\"", "]", ",", "default", "=", "\"tfidf_filtered\"", ")", "\n", "cli_utils", ".", "add_general_args", "(", "parser", ")", "\n", "cli_utils", ".", "add_loss_args", "(", "parser", ",", "default_penalty", "=", "2.0", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "stratify", "is", "None", ":", "\n", "    ", "if", "args", ".", "mode", "==", "\"learned_mixin\"", ":", "\n", "# Note sure if this actually makes a difference, but I turned this on", "\n", "# for the learned_mixin case so we do here for exactness", "\n", "      ", "args", ".", "stratify", "=", "6", "\n", "\n", "", "", "dbg", "=", "args", ".", "debug", "\n", "\n", "if", "dbg", ":", "\n", "    ", "epoch_size", "=", "50", "\n", "", "else", ":", "\n", "    ", "epoch_size", "=", "1341", "\n", "\n", "", "opt", "=", "AdamOptimizer", "(", "max_grad_norm", "=", "5.0", ")", "\n", "batcher", "=", "QuantileBatcher", "(", "45", ",", "10", ",", "300", ",", "4", ",", "12", ")", "\n", "evaluator", "=", "Evaluator", "(", "\"squad\"", ")", "\n", "\n", "trainer", "=", "Trainer", "(", "\n", "batcher", ",", "opt", ",", "evaluator", ",", "\n", "eval_batch_size", "=", "90", ",", "\n", "num_epochs", "=", "30", ",", "epoch_size", "=", "epoch_size", ",", "\n", "log_period", "=", "100", ",", "\n", "prefetch", "=", "5", ",", "loss_ema", "=", "0.999", ",", "\n", "n_processes", "=", "args", ".", "n_processes", "\n", ")", "\n", "\n", "filtered_bias", "=", "args", ".", "bias", "==", "\"tfidf_filtered\"", "\n", "if", "dbg", ":", "\n", "    ", "dataset", "=", "AnnotatedSquadLoader", "(", "\n", "sample_train", "=", "1000", ",", "sample_dev", "=", "500", ",", "stratify", "=", "args", ".", "stratify", ",", "filtered_bias", "=", "filtered_bias", ")", "\n", "", "else", ":", "\n", "    ", "dataset", "=", "AnnotatedSquadLoader", "(", "\n", "sample_train_eval", "=", "10000", ",", "stratify", "=", "args", ".", "stratify", ",", "filtered_bias", "=", "filtered_bias", ")", "\n", "\n", "", "dim", "=", "100", "\n", "recurrent_layer", "=", "CudnnLSTMRecurrentDropout", "(", "dim", ",", "0.0", ")", "\n", "model", "=", "TextPairQaDebiasingModel", "(", "\n", "None", ",", "# Assume pre-tokenized data", "\n", "text_encoder", "=", "WordAndCharEncoder", "(", "\n", "\"glove.6B.50d\"", "if", "dbg", "else", "\"crawl-300d-2M\"", ",", "\n", "first_n", "=", "None", ",", "\n", "char_embed_dim", "=", "24", ",", "\n", "character_mapper", "=", "Conv1d", "(", "100", ",", "5", ",", "None", ")", ",", "\n", "character_pooler", "=", "MaxPooler", "(", ")", ",", "\n", "word_length", "=", "30", "\n", ")", ",", "\n", "map_embed", "=", "seq", "(", "\n", "VariationalDropout", "(", "0.2", ")", ",", "\n", "recurrent_layer", ",", "\n", "VariationalDropout", "(", "0.2", ")", "\n", ")", ",", "\n", "fuse_layer", "=", "BiAttention", "(", "WeightedDot", "(", ")", ")", ",", "\n", "post_process_layer", "=", "seq", "(", "\n", "FullyConnected", "(", "dim", "*", "2", ",", "activation", "=", "\"glu\"", ")", ",", "\n", "VariationalDropout", "(", "0.2", ")", ",", "\n", "recurrent_layer", ",", "\n", "VariationalDropout", "(", "0.2", ")", ",", "\n", "recurrent_layer", ",", "\n", "VariationalDropout", "(", "0.2", ")", ",", "\n", ")", ",", "\n", "debias_loss_fn", "=", "cli_utils", ".", "get_qa_loss_fn", "(", "args", ")", "\n", ")", "\n", "\n", "with", "open", "(", "__file__", ")", "as", "f", ":", "\n", "    ", "notes", "=", "f", ".", "read", "(", ")", "\n", "\n", "", "py_utils", ".", "add_stdout_logger", "(", ")", "\n", "\n", "trainer", ".", "train", "(", "dataset", ",", "model", ",", "args", ".", "output_dir", ",", "notes", ")", "\n", "\n", "if", "args", ".", "output_dir", ":", "\n", "    ", "logging", ".", "info", "(", "\"Evaluating\"", ")", "\n", "compute_all_scores", "(", "args", ".", "output_dir", ",", "[", "\"dev\"", ",", "\"add_sent\"", ",", "\"add_one_sent\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_triviaqa_cp.get_cache_name": [[16, 18], ["None"], "function", ["None"], ["def", "get_cache_name", "(", "dataset_name", ",", "part_name", ")", ":", "\n", "  ", "return", "dataset_name", "+", "\"-\"", "+", "part_name", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_triviaqa_cp.get_predictions": [[20, 85], ["os.path.join", "logging.info", "logging.info", "debias.models.model_dir.ModelDir", "debias.models.model_dir.ModelDir.get_model", "logging.info", "debias.datasets.triviaqa_cp.load_annotated_triviaqa_cp", "triviaqa_cp.load_annotated_triviaqa_cp.sort", "debias.datasets.triviaqa_cp.compute_voc", "model_dir.get_model.set_vocab", "debias.datasets.triviaqa_cp.convert_to_tuples", "numpy.concatenate", "zip", "os.path.exists", "debias.utils.py_utils.load_json", "numpy.random.shuffle", "tensorflow.Session", "debias.datasets.triviaqa_cp.make_dataset", "model_dir.get_model.tensorize_fn", "ds.padded_batch.map", "ds.padded_batch.padded_batch", "ds.padded_batch.prefetch", "ds.padded_batch.make_initializable_iterator", "ds.make_initializable_iterator.get_next", "model_dir.get_model.apply", "tensorflow.nn.log_softmax", "debias.utils.ops.get_best_span", "logging.info", "tf.Session.run", "tf.Session.run", "tf.Session.run", "logging.info", "tensorflow.train.Saver", "tf.train.Saver.restore", "tqdm.tqdm", "tqdm.tqdm.close", "eval_debiased_triviaqa_cp.get_cache_name", "tensorflow.Session", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "debias.models.model_dir.ModelDir.get_latest_checkpoint", "open", "json.dump", "len", "tensorflow.Graph", "len", "np.concatenate.append", "tqdm.tqdm.update", "tf.Session.run", "len"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.models.model_dir.ModelDir.get_model", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.triviaqa_cp.load_annotated_triviaqa_cp", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.compute_voc", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.set_vocab", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.convert_to_tuples", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_json", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.tensorize_fn", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_best_span", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_triviaqa_cp.get_cache_name", "home.repos.pwc.inspect_result.chrisc36_debias.models.model_dir.ModelDir.get_latest_checkpoint", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run"], ["", "def", "get_predictions", "(", "path", ",", "dataset_name", ",", "part", ",", "bach_size", "=", "128", ",", "sample", "=", "None", ",", "cache", "=", "True", ")", ":", "\n", "  ", "output_file", "=", "join", "(", "path", ",", "\"%s-predictions.json\"", "%", "get_cache_name", "(", "dataset_name", ",", "part", ")", ")", "\n", "if", "sample", "is", "None", "and", "cache", "and", "exists", "(", "output_file", ")", ":", "\n", "    ", "return", "py_utils", ".", "load_json", "(", "output_file", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Computing predictions for %s on %s...\"", "%", "(", "path", ",", "dataset_name", ")", ")", "\n", "logging", ".", "info", "(", "\"Loading model...\"", ")", "\n", "model_dir", "=", "ModelDir", "(", "path", ")", "\n", "model", "=", "model_dir", ".", "get_model", "(", ")", "\n", "\n", "logging", ".", "info", "(", "\"Setup data...\"", ")", "\n", "data", "=", "triviaqa_cp", ".", "load_annotated_triviaqa_cp", "(", "dataset_name", ",", "part", ")", "\n", "data", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", ".", "tokens", ")", ")", "\n", "voc", "=", "triviaqa_cp", ".", "compute_voc", "(", "data", ")", "\n", "model", ".", "set_vocab", "(", "voc", ")", "\n", "tuples", "=", "triviaqa_cp", ".", "convert_to_tuples", "(", "data", ")", "\n", "if", "sample", "is", "not", "None", ":", "\n", "    ", "np", ".", "random", ".", "shuffle", "(", "tuples", ")", "\n", "tuples", "=", "tuples", "[", ":", "sample", "]", "\n", "\n", "", "with", "tf", ".", "Session", "(", "graph", "=", "tf", ".", "Graph", "(", ")", ")", "as", "sess", ":", "\n", "    ", "ds", "=", "triviaqa_cp", ".", "make_dataset", "(", "tuples", ")", "\n", "fn", "=", "model", ".", "tensorize_fn", "(", ")", "\n", "\n", "ds", "=", "ds", ".", "map", "(", "fn", ")", "\n", "ds", "=", "ds", ".", "padded_batch", "(", "bach_size", ",", "ds", ".", "output_shapes", ")", "\n", "ds", ".", "prefetch", "(", "5", ")", "\n", "it", "=", "ds", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "next_op", "=", "it", ".", "get_next", "(", ")", "\n", "logit_op", "=", "model", ".", "apply", "(", "False", ",", "next_op", ",", "None", ")", "\n", "logit_op", "=", "tf", ".", "nn", ".", "log_softmax", "(", "logit_op", ",", "1", ")", "\n", "span_op", "=", "ops", ".", "get_best_span", "(", "logit_op", ",", "17", ")", "\n", "\n", "logging", ".", "info", "(", "\"Initializing...\"", ")", "\n", "if", "sess", "is", "None", ":", "\n", "      ", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "it", ".", "initializer", ")", "\n", "\n", "logging", ".", "info", "(", "\"Loading checkpoint...\"", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "model_dir", ".", "get_latest_checkpoint", "(", ")", ")", "\n", "\n", "predictions", "=", "[", "]", "\n", "pbar", "=", "tqdm", "(", "desc", "=", "\"classify\"", ",", "total", "=", "len", "(", "tuples", ")", ",", "ncols", "=", "80", ")", "\n", "while", "True", ":", "\n", "      ", "try", ":", "\n", "        ", "predictions", ".", "append", "(", "sess", ".", "run", "(", "span_op", ")", ")", "\n", "pbar", ".", "update", "(", "len", "(", "predictions", "[", "-", "1", "]", ")", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "break", "\n", "", "", "pbar", ".", "close", "(", ")", "\n", "\n", "", "predictions", "=", "np", ".", "concatenate", "(", "predictions", ",", "0", ")", "\n", "predicted_text", "=", "{", "}", "\n", "for", "tup", ",", "(", "s", ",", "e", ")", "in", "zip", "(", "tuples", ",", "predictions", ")", ":", "\n", "    ", "tokens", "=", "tup", "[", "2", "]", "\n", "predicted_text", "[", "tup", "[", "0", "]", "]", "=", "\" \"", ".", "join", "(", "tokens", "[", "s", ":", "e", "+", "1", "]", ")", "\n", "\n", "", "if", "sample", "is", "None", "and", "cache", ":", "\n", "    ", "with", "open", "(", "output_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "      ", "json", ".", "dump", "(", "predicted_text", ",", "f", ")", "\n", "", "", "return", "predicted_text", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_triviaqa_cp.compute_scores": [[87, 103], ["os.path.join", "logging.info", "debias.datasets.triviaqa_cp.load_triviaqa_cp", "eval_debiased_triviaqa_cp.get_predictions", "triviaqa_cp.triviaqa_cp_evaluation.evaluate_triviaqa", "os.path.exists", "debias.utils.py_utils.load_json", "eval_debiased_triviaqa_cp.get_cache_name", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_loader.load_triviaqa_cp", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.get_predictions", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.evaluate_triviaqa", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_json", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_triviaqa_cp.get_cache_name"], ["", "def", "compute_scores", "(", "path", ",", "dataset_name", ",", "part", ",", "cache", "=", "True", ")", ":", "\n", "  ", "output_file", "=", "join", "(", "path", ",", "\"%s-scores.json\"", "%", "get_cache_name", "(", "dataset_name", ",", "part", ")", ")", "\n", "if", "cache", "and", "exists", "(", "output_file", ")", ":", "\n", "    ", "return", "py_utils", ".", "load_json", "(", "output_file", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Scoring on %s\"", "%", "dataset_name", ")", "\n", "docs", "=", "triviaqa_cp", ".", "load_triviaqa_cp", "(", "dataset_name", ",", "part", ")", "\n", "ground_truth", "=", "{", "x", "[", "'QuestionId'", "]", ":", "x", "[", "'Answer'", "]", "for", "x", "in", "docs", "}", "\n", "\n", "pred", "=", "get_predictions", "(", "path", ",", "dataset_name", ",", "part", ",", "cache", "=", "cache", ")", "\n", "result", "=", "triviaqa_cp_evaluation", ".", "evaluate_triviaqa", "(", "ground_truth", ",", "pred", ",", "mute", "=", "True", ")", "\n", "\n", "if", "cache", ":", "\n", "    ", "with", "open", "(", "output_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "      ", "json", ".", "dump", "(", "result", ",", "f", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_triviaqa_cp.show_scores": [[105, 115], ["logging.info", "print", "results.items", "eval_debiased_triviaqa_cp.compute_scores", "print", "print", "json.dumps"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_squad.compute_scores"], ["", "def", "show_scores", "(", "path", ",", "dataset", ",", "parts", ",", "cache", "=", "True", ")", ":", "\n", "  ", "results", "=", "{", "}", "\n", "logging", ".", "info", "(", "\"Evaluating on %s\"", "%", "dataset", ")", "\n", "for", "p", "in", "parts", ":", "\n", "    ", "results", "[", "dataset", "]", "=", "compute_scores", "(", "path", ",", "dataset", ",", "p", ",", "cache", ")", "\n", "\n", "", "print", "(", ")", "\n", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "    ", "print", "(", "\"*\"", "*", "8", "+", "\" TriviaQA-CP \"", "+", "k", "+", "\" Test \"", "+", "\"*\"", "*", "8", ")", "\n", "print", "(", "json", ".", "dumps", "(", "v", ",", "indent", "=", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_triviaqa_cp.main": [[117, 136], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "debias.utils.py_utils.add_stdout_logger", "eval_debiased_triviaqa_cp.show_scores", "parser.parse_args.parts.split", "ValueError"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.add_stdout_logger", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.show_scores", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split"], ["", "", "def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"output_dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--nocache\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "choices", "=", "[", "\"location\"", ",", "\"person\"", "]", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Dataset to test on\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--parts\"", ",", "default", "=", "None", ",", "help", "=", "\"Comma seperated list of parts to test on\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "py_utils", ".", "add_stdout_logger", "(", ")", "\n", "\n", "if", "args", ".", "parts", "is", "None", ":", "\n", "    ", "parts", "=", "[", "\"dev\"", ",", "\"test\"", "]", "\n", "", "else", ":", "\n", "    ", "parts", "=", "args", ".", "parts", ".", "split", "(", "\",\"", ")", "\n", "for", "ds", "in", "parts", ":", "\n", "      ", "if", "ds", "not", "in", "[", "\"dev\"", ",", "\"test\"", ",", "\"train\"", "]", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unsupported dataset %s\"", "%", "ds", ")", "\n", "\n", "", "", "", "show_scores", "(", "args", ".", "output_dir", ",", "args", ".", "dataset", ",", "parts", ",", "not", "args", ".", "nocache", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_synthetic.add_bias": [[17, 29], ["debias.datasets.synthetic.add_noise", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.synthetic.add_noise"], ["def", "add_bias", "(", "all_examples", ",", "bias_name", ",", "unbaised", ")", ":", "\n", "  ", "if", "bias_name", "==", "\"indicator\"", ":", "\n", "    ", "bias_prob", ",", "i_prob", "=", "0.8", ",", "None", "\n", "", "elif", "bias_name", "==", "\"excluder\"", ":", "\n", "    ", "bias_prob", ",", "i_prob", "=", "0.03", ",", "None", "\n", "", "elif", "bias_name", "==", "\"dependent\"", ":", "\n", "    ", "bias_prob", ",", "i_prob", "=", "0.9", ",", "0.8", "\n", "", "else", ":", "\n", "    ", "raise", "RuntimeError", "(", ")", "\n", "", "if", "unbaised", ":", "\n", "    ", "bias_prob", "=", "1", "/", "3.0", "\n", "", "return", "synthetic", ".", "add_noise", "(", "all_examples", ",", "bias_prob", ",", "i_prob", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_synthetic.get_dataset_name": [[31, 37], ["None"], "function", ["None"], ["", "def", "get_dataset_name", "(", "bias_name", ",", "unbiased", ")", ":", "\n", "  ", "if", "unbiased", ":", "\n", "    ", "is_biased_str", "=", "\"unbiased\"", "\n", "", "else", ":", "\n", "    ", "is_biased_str", "=", "\"biased\"", "\n", "", "return", "is_biased_str", "+", "\"-\"", "+", "bias_name", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_synthetic.get_predictions": [[39, 104], ["eval_debiased_synthetic.get_dataset_name", "os.path.join", "logging.info", "logging.info", "debias.models.model_dir.ModelDir", "debias.models.model_dir.ModelDir.get_model", "logging.info", "debias.datasets.mnli.load_mnli", "debias.datasets.mnli.tokenize_examples", "eval_debiased_synthetic.add_bias", "add_bias.sort", "set", "model_dir.get_model.set_vocab", "numpy.concatenate", "os.path.exists", "debias.utils.py_utils.load_pickle", "model_dir.get_model.get_tokenizer", "set.update", "set.update", "tensorflow.Session", "debias.datasets.mnli.make_dataset", "model_dir.get_model.tensorize_fn", "ds.padded_batch.map", "ds.padded_batch.padded_batch", "ds.padded_batch.prefetch", "ds.padded_batch.make_initializable_iterator", "ds.make_initializable_iterator.get_next", "model_dir.get_model.apply", "tensorflow.nn.softmax", "logging.info", "tf.Session.run", "tf.Session.run", "tf.Session.run", "logging.info", "tensorflow.train.Saver", "tf.train.Saver.restore", "tqdm.tqdm", "tqdm.tqdm.close", "tensorflow.Session", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "debias.models.model_dir.ModelDir.get_latest_checkpoint", "zip", "open", "pickle.dump", "len", "tensorflow.Graph", "len", "np.concatenate.append", "tqdm.tqdm.update", "tf.Session.run", "len"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_synthetic.get_dataset_name", "home.repos.pwc.inspect_result.chrisc36_debias.models.model_dir.ModelDir.get_model", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_mnli", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.tokenize_examples", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_synthetic.add_bias", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.set_vocab", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_pickle", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.get_tokenizer", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.tensorize_fn", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.models.model_dir.ModelDir.get_latest_checkpoint", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run"], ["", "def", "get_predictions", "(", "path", ",", "bias_name", ":", "str", ",", "unbiased", ":", "bool", ",", "bach_size", "=", "128", ",", "sample", "=", "None", ",", "n_processes", "=", "None", ",", "cache", "=", "False", ")", ":", "\n", "  ", "dataset_name", "=", "get_dataset_name", "(", "bias_name", ",", "unbiased", ")", "\n", "\n", "output", "=", "join", "(", "path", ",", "\"%s-prediction.pkl\"", "%", "dataset_name", ")", "\n", "if", "sample", "is", "None", "and", "exists", "(", "output", ")", "and", "cache", ":", "\n", "    ", "return", "py_utils", ".", "load_pickle", "(", "output", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Computing predictions for %s on %s...\"", "%", "(", "path", ",", "dataset_name", ")", ")", "\n", "logging", ".", "info", "(", "\"Loading model...\"", ")", "\n", "model_dir", "=", "ModelDir", "(", "path", ")", "\n", "model", "=", "model_dir", ".", "get_model", "(", ")", "\n", "\n", "logging", ".", "info", "(", "\"Setup data...\"", ")", "\n", "all_examples", "=", "mnli", ".", "load_mnli", "(", "False", ")", "\n", "all_examples", "=", "mnli", ".", "tokenize_examples", "(", "all_examples", ",", "model", ".", "get_tokenizer", "(", ")", ",", "n_processes", ")", "\n", "all_examples", "=", "add_bias", "(", "all_examples", ",", "bias_name", ",", "unbiased", ")", "\n", "all_examples", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", ".", "premise", ")", ")", "\n", "\n", "voc", "=", "set", "(", ")", "\n", "for", "ex", "in", "all_examples", ":", "\n", "    ", "voc", ".", "update", "(", "ex", ".", "premise", ")", "\n", "voc", ".", "update", "(", "ex", ".", "hypothesis", ")", "\n", "\n", "", "model", ".", "set_vocab", "(", "voc", ")", "\n", "\n", "with", "tf", ".", "Session", "(", "graph", "=", "tf", ".", "Graph", "(", ")", ")", "as", "sess", ":", "\n", "    ", "ds", "=", "mnli", ".", "make_dataset", "(", "all_examples", ",", "shuffle", "=", "False", ")", "\n", "fn", "=", "model", ".", "tensorize_fn", "(", ")", "\n", "\n", "ds", "=", "ds", ".", "map", "(", "fn", ")", "\n", "ds", "=", "ds", ".", "padded_batch", "(", "bach_size", ",", "ds", ".", "output_shapes", ")", "\n", "ds", ".", "prefetch", "(", "5", ")", "\n", "it", "=", "ds", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "next_op", "=", "it", ".", "get_next", "(", ")", "\n", "logits", "=", "model", ".", "apply", "(", "False", ",", "next_op", ",", "None", ")", "\n", "pred_op", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "\n", "logging", ".", "info", "(", "\"Initializing...\"", ")", "\n", "if", "sess", "is", "None", ":", "\n", "      ", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "it", ".", "initializer", ")", "\n", "\n", "logging", ".", "info", "(", "\"Loading checkpoint...\"", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "model_dir", ".", "get_latest_checkpoint", "(", ")", ")", "\n", "\n", "predictions", "=", "[", "]", "\n", "pbar", "=", "tqdm", "(", "desc", "=", "\"classify\"", ",", "total", "=", "len", "(", "all_examples", ")", ",", "ncols", "=", "80", ")", "\n", "while", "True", ":", "\n", "      ", "try", ":", "\n", "        ", "predictions", ".", "append", "(", "sess", ".", "run", "(", "pred_op", ")", ")", "\n", "pbar", ".", "update", "(", "len", "(", "predictions", "[", "-", "1", "]", ")", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "break", "\n", "", "", "pbar", ".", "close", "(", ")", "\n", "\n", "", "predictions", "=", "np", ".", "concatenate", "(", "predictions", ",", "0", ")", "\n", "predictions", "=", "{", "k", ".", "id", ":", "p", "for", "p", ",", "k", "in", "zip", "(", "predictions", ",", "all_examples", ")", "}", "\n", "if", "sample", "is", "None", "and", "cache", ":", "\n", "    ", "with", "open", "(", "output", ",", "\"wb\"", ")", "as", "f", ":", "\n", "      ", "pickle", ".", "dump", "(", "predictions", ",", "f", ")", "\n", "", "", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_synthetic.compute_scores": [[106, 125], ["eval_debiased_synthetic.get_dataset_name", "os.path.join", "os.path.exists", "debias.utils.py_utils.load_json", "print", "eval_debiased_synthetic.get_predictions", "debias.datasets.mnli.load_mnli", "numpy.array", "numpy.array", "numpy.argmax", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_synthetic.get_dataset_name", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_json", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.get_predictions", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_mnli"], ["", "def", "compute_scores", "(", "path", ",", "bias_name", ",", "unbiased", ",", "cache", "=", "True", ",", "n_processes", "=", "None", ")", ":", "\n", "  ", "dataset_name", "=", "get_dataset_name", "(", "bias_name", ",", "unbiased", ")", "\n", "cache_file", "=", "join", "(", "path", ",", "\"%s-scores.json\"", "%", "dataset_name", ")", "\n", "if", "exists", "(", "cache_file", ")", "and", "cache", ":", "\n", "    ", "return", "py_utils", ".", "load_json", "(", "cache_file", ")", "\n", "", "else", ":", "\n", "    ", "print", "(", "\"Scoring %s...\"", "%", "path", ")", "\n", "pred", "=", "get_predictions", "(", "path", ",", "bias_name", ",", "unbiased", ",", "n_processes", "=", "n_processes", ",", "cache", "=", "cache", ")", "\n", "data", "=", "mnli", ".", "load_mnli", "(", "False", ")", "\n", "label_arr", "=", "np", ".", "array", "(", "[", "x", ".", "label", "for", "x", "in", "data", "]", ")", "\n", "pred_arr", "=", "np", ".", "array", "(", "[", "pred", "[", "x", ".", "id", "]", "for", "x", "in", "data", "]", ")", "\n", "pred_arr", "=", "np", ".", "argmax", "(", "pred_arr", ",", "1", ")", "\n", "acc", "=", "(", "label_arr", "==", "pred_arr", ")", ".", "mean", "(", ")", "\n", "result", "=", "{", "\"accuracy\"", ":", "acc", "}", "\n", "\n", "if", "cache", ":", "\n", "      ", "with", "open", "(", "cache_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "result", ",", "f", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_synthetic.show_scores": [[127, 136], ["result_dict.items", "eval_debiased_synthetic.compute_scores", "print", "print", "json.dumps"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_squad.compute_scores"], ["", "", "def", "show_scores", "(", "path", ",", "bias_name", ",", "is_biased", ":", "List", "[", "bool", "]", ",", "cache", "=", "True", ",", "n_processes", "=", "None", ")", ":", "\n", "  ", "result_dict", "=", "{", "}", "\n", "\n", "for", "b", "in", "is_biased", ":", "\n", "    ", "result_dict", "[", "b", "]", "=", "compute_scores", "(", "path", ",", "bias_name", ",", "b", ",", "cache", ",", "n_processes", ")", "\n", "\n", "", "for", "k", ",", "result", "in", "result_dict", ".", "items", "(", ")", ":", "\n", "    ", "print", "(", "\"*\"", "*", "8", "+", "\" \"", "+", "bias_name", "+", "\" \"", "+", "(", "\"unbiased\"", "if", "k", "else", "\"biased\"", ")", "+", "\" \"", "+", "\"*\"", "*", "8", ")", "\n", "print", "(", "json", ".", "dumps", "(", "result", ",", "indent", "=", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_synthetic.main": [[138, 159], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "debias.utils.py_utils.add_stdout_logger", "eval_debiased_synthetic.show_scores", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.add_stdout_logger", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.show_scores"], ["", "", "def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_processes\"", ",", "\"-n\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--bias\"", ",", "choices", "=", "[", "\"indicator\"", ",", "\"excluder\"", ",", "'depedent'", "]", ",", "\n", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--on\"", ",", "choices", "=", "[", "\"biased\"", ",", "\"unbiased\"", ",", "'both'", "]", ",", "default", "=", "\"unbiased\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--nocache\"", ",", "action", "=", "\"store_true\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "py_utils", ".", "add_stdout_logger", "(", ")", "\n", "\n", "if", "args", ".", "on", "==", "\"biased\"", ":", "\n", "    ", "is_biased", "=", "[", "True", "]", "\n", "", "elif", "args", ".", "on", "==", "\"unbiased\"", ":", "\n", "    ", "is_biased", "=", "[", "False", "]", "\n", "", "elif", "args", ".", "on", "==", "\"both\"", ":", "\n", "    ", "is_biased", "=", "[", "True", ",", "False", "]", "\n", "", "else", ":", "\n", "    ", "raise", "RuntimeError", "(", "args", ".", "on", ")", "\n", "\n", "", "show_scores", "(", "args", ".", "model", ",", "args", ".", "bias", ",", "is_biased", ",", "not", "args", ".", "nocache", ",", "args", ".", "n_processes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.train_debiased_triviaqa_cp.main": [[19, 105], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "debias.utils.cli_utils.add_general_args", "debias.utils.cli_utils.add_loss_args", "argparse.ArgumentParser.parse_args", "debias.training.trainer.AdamOptimizer", "debias.datasets.dataset_utils.QuantileBatcher", "debias.training.evaluator.Evaluator", "debias.training.trainer.Trainer", "debias.modules.cudnn_recurrent_dropout.CudnnLSTMRecurrentDropout", "debias.models.text_pair_qa_model.TextPairQaDebiasingModel", "debias.utils.py_utils.add_stdout_logger", "debias.training.trainer.Trainer.train", "debias.datasets.triviaqa_cp.AnnotatedTriviaQACPLoader", "debias.datasets.triviaqa_cp.AnnotatedTriviaQACPLoader", "open", "f.read", "logging.info", "debias.experiments.eval_debiased_triviaqa_cp.show_scores", "debias.modules.word_and_char_encoder.WordAndCharEncoder", "debias.modules.layers.seq", "debias.modules.attention_layers.BiAttention", "debias.modules.layers.seq", "debias.utils.cli_utils.get_qa_loss_fn", "debias.modules.layers.Dropout", "debias.modules.layers.HighwayLayer", "debias.modules.attention_layers.WeightedDot", "debias.modules.layers.VariationalDropout", "debias.modules.layers.FullyConnected", "debias.modules.layers.VariationalDropout", "debias.modules.layers.HighwayLayer", "debias.modules.layers.VariationalDropout", "debias.modules.layers.HighwayLayer", "debias.modules.layers.VariationalDropout", "debias.modules.layers.Conv1d", "debias.modules.layers.MaxPooler"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.cli_utils.add_general_args", "home.repos.pwc.inspect_result.chrisc36_debias.utils.cli_utils.add_loss_args", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.add_stdout_logger", "home.repos.pwc.inspect_result.chrisc36_debias.training.trainer.Trainer.train", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.show_scores", "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.seq", "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.seq", "home.repos.pwc.inspect_result.chrisc36_debias.utils.cli_utils.get_qa_loss_fn"], ["def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--stratify\"", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "choices", "=", "[", "\"location\"", ",", "\"person\"", "]", ",", "default", "=", "\"location\"", ")", "\n", "cli_utils", ".", "add_general_args", "(", "parser", ")", "\n", "cli_utils", ".", "add_loss_args", "(", "parser", ",", "default_penalty", "=", "None", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "stratify", "is", "None", ":", "\n", "    ", "if", "args", ".", "mode", "==", "\"learned_mixin\"", ":", "\n", "# Note sure if this actually makes a difference, but I turned this on", "\n", "# for the learned_mixin case so we do here for exactness", "\n", "      ", "args", ".", "stratify", "=", "6", "\n", "\n", "", "", "if", "args", ".", "penalty", "is", "None", ":", "\n", "    ", "if", "args", ".", "dataset", "==", "\"person\"", ":", "\n", "      ", "args", ".", "penalty", "=", "0.2", "\n", "", "else", ":", "\n", "      ", "args", ".", "penalty", "=", "0.4", "\n", "\n", "", "", "dbg", "=", "args", ".", "debug", "\n", "\n", "if", "dbg", ":", "\n", "    ", "epoch_size", "=", "50", "\n", "", "else", ":", "\n", "    ", "epoch_size", "=", "1200", "\n", "\n", "", "opt", "=", "AdamOptimizer", "(", "decay_steps", "=", "50", ",", "max_grad_norm", "=", "3.0", ")", "\n", "batcher", "=", "QuantileBatcher", "(", "45", ",", "10", ",", "400", ",", "4", ",", "12", ")", "\n", "evaluator", "=", "Evaluator", "(", "\"triviaqa\"", ")", "\n", "\n", "trainer", "=", "Trainer", "(", "\n", "batcher", ",", "opt", ",", "evaluator", ",", "\n", "eval_batch_size", "=", "90", ",", "\n", "num_epochs", "=", "30", ",", "epoch_size", "=", "epoch_size", ",", "\n", "log_period", "=", "100", ",", "\n", "prefetch", "=", "5", ",", "loss_ema", "=", "0.999", ",", "\n", "n_processes", "=", "args", ".", "n_processes", "\n", ")", "\n", "\n", "if", "dbg", ":", "\n", "    ", "dataset", "=", "AnnotatedTriviaQACPLoader", "(", "\n", "args", ".", "dataset", ",", "sample_train", "=", "1000", ",", "stratify", "=", "args", ".", "stratify", ")", "\n", "", "else", ":", "\n", "    ", "dataset", "=", "AnnotatedTriviaQACPLoader", "(", "\n", "args", ".", "dataset", ",", "sample_train_eval", "=", "8000", ",", "stratify", "=", "args", ".", "stratify", ")", "\n", "\n", "", "dim", "=", "128", "\n", "recurrent_layer", "=", "CudnnLSTMRecurrentDropout", "(", "dim", ",", "0.2", ")", "\n", "model", "=", "TextPairQaDebiasingModel", "(", "\n", "None", ",", "# Assume pre-tokenized data", "\n", "text_encoder", "=", "WordAndCharEncoder", "(", "\n", "\"glove.6B.50d\"", "if", "dbg", "else", "\"crawl-300d-2M\"", ",", "\n", "first_n", "=", "500000", ",", "\n", "char_embed_dim", "=", "24", ",", "\n", "character_mapper", "=", "Conv1d", "(", "100", ",", "5", ",", "None", ")", ",", "\n", "character_pooler", "=", "MaxPooler", "(", ")", ",", "\n", "word_length", "=", "30", "\n", ")", ",", "\n", "map_embed", "=", "seq", "(", "\n", "Dropout", "(", "0.3", ")", ",", "\n", "HighwayLayer", "(", "recurrent_layer", ")", ",", "\n", ")", ",", "\n", "fuse_layer", "=", "BiAttention", "(", "WeightedDot", "(", ")", ")", ",", "\n", "post_process_layer", "=", "seq", "(", "\n", "VariationalDropout", "(", "0.2", ")", ",", "\n", "FullyConnected", "(", "dim", "*", "2", ",", "activation", "=", "\"relu\"", ")", ",", "\n", "VariationalDropout", "(", "0.2", ")", ",", "\n", "HighwayLayer", "(", "recurrent_layer", ")", ",", "\n", "VariationalDropout", "(", "0.2", ")", ",", "\n", "HighwayLayer", "(", "recurrent_layer", ")", ",", "\n", "VariationalDropout", "(", "0.2", ")", ",", "\n", ")", ",", "\n", "debias_loss_fn", "=", "cli_utils", ".", "get_qa_loss_fn", "(", "args", ")", "\n", ")", "\n", "\n", "with", "open", "(", "__file__", ")", "as", "f", ":", "\n", "    ", "notes", "=", "f", ".", "read", "(", ")", "\n", "\n", "", "py_utils", ".", "add_stdout_logger", "(", ")", "\n", "\n", "trainer", ".", "train", "(", "dataset", ",", "model", ",", "args", ".", "output_dir", ",", "notes", ")", "\n", "\n", "if", "args", ".", "output_dir", ":", "\n", "    ", "logging", ".", "info", "(", "\"Evaluating...\"", ")", "\n", "eval_debiased_triviaqa_cp", ".", "show_scores", "(", "args", ".", "output_dir", ",", "args", ".", "dataset", ",", "[", "\"dev\"", ",", "\"test\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_squad.get_predictions": [[16, 81], ["os.path.join", "logging.info", "logging.info", "debias.models.model_dir.ModelDir", "debias.models.model_dir.ModelDir.get_model", "logging.info", "debias.datasets.squad.load_annotated_squad", "squad.load_annotated_squad.sort", "debias.datasets.squad.compute_voc", "model_dir.get_model.set_vocab", "debias.datasets.squad.convert_to_tuples", "numpy.concatenate", "zip", "os.path.exists", "debias.utils.py_utils.load_json", "numpy.random.shuffle", "tensorflow.Session", "debias.datasets.squad.make_dataset", "model_dir.get_model.tensorize_fn", "ds.padded_batch.map", "ds.padded_batch.padded_batch", "ds.padded_batch.prefetch", "ds.padded_batch.make_initializable_iterator", "ds.make_initializable_iterator.get_next", "model_dir.get_model.apply", "tensorflow.nn.log_softmax", "debias.utils.ops.get_best_span", "logging.info", "tf.Session.run", "tf.Session.run", "tf.Session.run", "logging.info", "tensorflow.train.Saver", "tf.train.Saver.restore", "tqdm.tqdm", "tqdm.tqdm.close", "tensorflow.Session", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "debias.models.model_dir.ModelDir.get_latest_checkpoint", "open", "json.dump", "len", "tensorflow.Graph", "len", "np.concatenate.append", "tqdm.tqdm.update", "tf.Session.run", "len"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.models.model_dir.ModelDir.get_model", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.load_annotated_squad", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.compute_voc", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.set_vocab", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.convert_to_tuples", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_json", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.tensorize_fn", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_best_span", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.models.model_dir.ModelDir.get_latest_checkpoint", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run"], ["def", "get_predictions", "(", "path", ",", "dataset", ",", "bach_size", "=", "128", ",", "sample", "=", "None", ",", "cache", "=", "True", ")", ":", "\n", "  ", "output_file", "=", "join", "(", "path", ",", "\"%s-predictions.json\"", "%", "dataset", ")", "\n", "if", "sample", "is", "None", "and", "cache", "and", "exists", "(", "output_file", ")", ":", "\n", "    ", "return", "py_utils", ".", "load_json", "(", "output_file", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Computing predictions for %s on %s...\"", "%", "(", "path", ",", "dataset", ")", ")", "\n", "logging", ".", "info", "(", "\"Loading model...\"", ")", "\n", "model_dir", "=", "ModelDir", "(", "path", ")", "\n", "model", "=", "model_dir", ".", "get_model", "(", ")", "\n", "\n", "logging", ".", "info", "(", "\"Setup data...\"", ")", "\n", "data", "=", "squad", ".", "load_annotated_squad", "(", "dataset", ")", "\n", "data", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", ".", "tokens", ")", ")", "\n", "voc", "=", "squad", ".", "compute_voc", "(", "data", ")", "\n", "model", ".", "set_vocab", "(", "voc", ")", "\n", "tuples", "=", "squad", ".", "convert_to_tuples", "(", "data", ")", "\n", "if", "sample", "is", "not", "None", ":", "\n", "    ", "np", ".", "random", ".", "shuffle", "(", "tuples", ")", "\n", "tuples", "=", "tuples", "[", ":", "sample", "]", "\n", "\n", "", "with", "tf", ".", "Session", "(", "graph", "=", "tf", ".", "Graph", "(", ")", ")", "as", "sess", ":", "\n", "    ", "ds", "=", "squad", ".", "make_dataset", "(", "tuples", ")", "\n", "fn", "=", "model", ".", "tensorize_fn", "(", ")", "\n", "\n", "ds", "=", "ds", ".", "map", "(", "fn", ")", "\n", "ds", "=", "ds", ".", "padded_batch", "(", "bach_size", ",", "ds", ".", "output_shapes", ")", "\n", "ds", ".", "prefetch", "(", "5", ")", "\n", "it", "=", "ds", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "next_op", "=", "it", ".", "get_next", "(", ")", "\n", "logit_op", "=", "model", ".", "apply", "(", "False", ",", "next_op", ",", "None", ")", "\n", "logit_op", "=", "tf", ".", "nn", ".", "log_softmax", "(", "logit_op", ",", "1", ")", "\n", "span_op", "=", "ops", ".", "get_best_span", "(", "logit_op", ",", "17", ")", "\n", "\n", "logging", ".", "info", "(", "\"Initializing...\"", ")", "\n", "if", "sess", "is", "None", ":", "\n", "      ", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "it", ".", "initializer", ")", "\n", "\n", "logging", ".", "info", "(", "\"Loading checkpoint...\"", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "model_dir", ".", "get_latest_checkpoint", "(", ")", ")", "\n", "\n", "predictions", "=", "[", "]", "\n", "pbar", "=", "tqdm", "(", "desc", "=", "\"classify\"", ",", "total", "=", "len", "(", "tuples", ")", ",", "ncols", "=", "80", ")", "\n", "while", "True", ":", "\n", "      ", "try", ":", "\n", "        ", "predictions", ".", "append", "(", "sess", ".", "run", "(", "span_op", ")", ")", "\n", "pbar", ".", "update", "(", "len", "(", "predictions", "[", "-", "1", "]", ")", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "break", "\n", "", "", "pbar", ".", "close", "(", ")", "\n", "\n", "", "predictions", "=", "np", ".", "concatenate", "(", "predictions", ",", "0", ")", "\n", "predicted_text", "=", "{", "}", "\n", "for", "tup", ",", "(", "s", ",", "e", ")", "in", "zip", "(", "tuples", ",", "predictions", ")", ":", "\n", "    ", "passage_str", ",", "offsets", ",", "_", ",", "answer_text", "=", "tup", "[", "-", "4", ":", "]", "\n", "predicted_text", "[", "tup", "[", "0", "]", "]", "=", "(", "passage_str", "[", "offsets", "[", "s", "]", "[", "0", "]", ":", "offsets", "[", "e", "]", "[", "1", "]", "]", ")", "\n", "\n", "", "if", "sample", "is", "None", "and", "cache", ":", "\n", "    ", "with", "open", "(", "output_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "      ", "json", ".", "dump", "(", "predicted_text", ",", "f", ")", "\n", "", "", "return", "predicted_text", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_squad.compute_scores": [[83, 100], ["os.path.join", "logging.info", "debias.datasets.squad.load_squad_documents", "eval_debiased_squad.get_predictions", "os.path.exists", "debias.utils.py_utils.load_json", "debias.squad_eval.squad_v1_official_evaluation.evaluate", "debias.squad_eval.squad_v1_adversarial_evaluation.evaluate_adversarial", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.load_squad_documents", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.get_predictions", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_json", "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_official_evaluation.evaluate", "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.evaluate_adversarial"], ["", "def", "compute_scores", "(", "path", ",", "dataset_name", ",", "cache", "=", "True", ")", ":", "\n", "  ", "output_file", "=", "join", "(", "path", ",", "\"%s-scores.json\"", "%", "dataset_name", ")", "\n", "if", "cache", "and", "exists", "(", "output_file", ")", ":", "\n", "    ", "return", "py_utils", ".", "load_json", "(", "output_file", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Scoring on %s\"", "%", "dataset_name", ")", "\n", "docs", "=", "squad", ".", "load_squad_documents", "(", "dataset_name", ")", "\n", "pred", "=", "get_predictions", "(", "path", ",", "dataset_name", ",", "cache", "=", "cache", ")", "\n", "if", "dataset_name", "in", "[", "\"dev\"", ",", "\"train\"", "]", ":", "\n", "    ", "result", "=", "squad_v1_official_evaluation", ".", "evaluate", "(", "docs", ",", "pred", ")", "\n", "", "else", ":", "\n", "    ", "result", "=", "squad_v1_adversarial_evaluation", ".", "evaluate_adversarial", "(", "docs", ",", "pred", ")", "\n", "\n", "", "if", "cache", ":", "\n", "    ", "with", "open", "(", "output_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "      ", "json", ".", "dump", "(", "result", ",", "f", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_squad.compute_all_scores": [[102, 112], ["print", "results.items", "logging.info", "eval_debiased_squad.compute_scores", "print", "print", "json.dumps"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_squad.compute_scores"], ["", "def", "compute_all_scores", "(", "path", ",", "datasets", ",", "cache", "=", "True", ")", ":", "\n", "  ", "results", "=", "{", "}", "\n", "for", "ds", "in", "datasets", ":", "\n", "    ", "logging", ".", "info", "(", "\"Evaluating on %s\"", "%", "ds", ")", "\n", "results", "[", "ds", "]", "=", "compute_scores", "(", "path", ",", "ds", ",", "cache", ")", "\n", "\n", "", "print", "(", ")", "\n", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ":", "\n", "    ", "print", "(", "\"*\"", "*", "8", "+", "\" \"", "+", "k", "+", "\" \"", "+", "\"*\"", "*", "8", ")", "\n", "print", "(", "json", ".", "dumps", "(", "v", ",", "indent", "=", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_squad.main": [[114, 131], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "debias.utils.py_utils.add_stdout_logger", "eval_debiased_squad.compute_all_scores", "parser.parse_args.datasets.split", "ValueError"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.add_stdout_logger", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_squad.compute_all_scores", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split"], ["", "", "def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"output_dir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--nocache\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--datasets\"", ",", "default", "=", "None", ",", "help", "=", "\"Comma separated list of datasets\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "py_utils", ".", "add_stdout_logger", "(", ")", "\n", "\n", "if", "args", ".", "datasets", "is", "None", ":", "\n", "    ", "datasets", "=", "[", "\"dev\"", ",", "\"add_sent\"", ",", "\"add_one_sent\"", "]", "\n", "", "else", ":", "\n", "    ", "datasets", "=", "args", ".", "datasets", ".", "split", "(", "\",\"", ")", "\n", "for", "ds", "in", "datasets", ":", "\n", "      ", "if", "ds", "not", "in", "squad", ".", "DATASETS", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unsupported dataset %s\"", "%", "ds", ")", "\n", "\n", "", "", "", "compute_all_scores", "(", "args", ".", "output_dir", ",", "datasets", ",", "not", "args", ".", "nocache", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.train_debiased_mnli.main": [[19, 90], ["argparse.ArgumentParser", "debias.utils.cli_utils.add_general_args", "debias.utils.cli_utils.add_loss_args", "argparse.ArgumentParser.parse_args", "debias.training.trainer.AdamOptimizer", "debias.datasets.dataset_utils.QuantileBatcher", "debias.training.evaluator.Evaluator", "debias.training.trainer.Trainer", "debias.modules.cudnn_recurrent_dropout.CudnnLSTMRecurrentDropout", "debias.models.text_pair_clf_model.TextPairClfDebiasingModel", "debias.utils.py_utils.add_stdout_logger", "debias.training.trainer.Trainer.train", "debias.datasets.mnli.MnliTrainingDataLoader", "debias.datasets.mnli.MnliTrainingDataLoader", "debias.utils.tokenizer.NltkAndPunctTokenizer", "debias.modules.word_and_char_encoder.WordAndCharEncoder", "open", "f.read", "logging.info", "debias.experiments.eval_debiased_mnli.show_scores", "debias.modules.layers.seq", "debias.modules.attention_layers.AttentionBiFuse", "debias.modules.layers.seq", "debias.modules.layers.MaxPooler", "debias.modules.layers.mseq", "debias.utils.cli_utils.get_clf_loss_fn", "debias.modules.layers.mseq", "debias.modules.layers.MaxPooler", "debias.modules.layers.VariationalDropout", "debias.modules.attention_layers.WeightedDot", "debias.modules.layers.VariationalDropout", "debias.modules.layers.FullyConnected", "debias.modules.layers.Dropout", "debias.modules.layers.Dropout", "debias.modules.layers.Conv1d"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.cli_utils.add_general_args", "home.repos.pwc.inspect_result.chrisc36_debias.utils.cli_utils.add_loss_args", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.add_stdout_logger", "home.repos.pwc.inspect_result.chrisc36_debias.training.trainer.Trainer.train", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.show_scores", "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.seq", "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.seq", "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.mseq", "home.repos.pwc.inspect_result.chrisc36_debias.utils.cli_utils.get_clf_loss_fn", "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.mseq"], ["def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "cli_utils", ".", "add_general_args", "(", "parser", ")", "\n", "cli_utils", ".", "add_loss_args", "(", "parser", ",", "default_penalty", "=", "0.03", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "dbg", "=", "args", ".", "debug", "\n", "\n", "if", "dbg", ":", "\n", "    ", "epoch_size", "=", "200", "\n", "", "else", ":", "\n", "    ", "epoch_size", "=", "6000", "\n", "\n", "", "opt", "=", "AdamOptimizer", "(", "max_grad_norm", "=", "5.0", ")", "\n", "batcher", "=", "QuantileBatcher", "(", "32", ",", "10", ",", "160", ",", "4", ",", "12", ")", "\n", "evaluator", "=", "Evaluator", "(", "mode", "=", "\"clf\"", ")", "\n", "\n", "trainer", "=", "Trainer", "(", "\n", "batcher", ",", "opt", ",", "evaluator", ",", "\n", "eval_batch_size", "=", "64", ",", "\n", "num_epochs", "=", "30", ",", "epoch_size", "=", "epoch_size", ",", "\n", "log_period", "=", "100", ",", "\n", "prefetch", "=", "5", ",", "loss_ema", "=", "0.999", ",", "\n", "n_processes", "=", "args", ".", "n_processes", ",", "\n", ")", "\n", "\n", "if", "dbg", ":", "\n", "    ", "dataset", "=", "MnliTrainingDataLoader", "(", "1000", ",", "3000", ",", "1000", ")", "\n", "", "else", ":", "\n", "    ", "dataset", "=", "MnliTrainingDataLoader", "(", "n_train_eval_sample", "=", "10000", ")", "\n", "\n", "", "dim", "=", "50", "if", "dbg", "else", "200", "\n", "recurrent_layer", "=", "CudnnLSTMRecurrentDropout", "(", "dim", ",", "0.2", ")", "\n", "model", "=", "TextPairClfDebiasingModel", "(", "\n", "NltkAndPunctTokenizer", "(", ")", ",", "\n", "WordAndCharEncoder", "(", "\n", "\"glove.6B.50d\"", "if", "dbg", "else", "\"crawl-300d-2M\"", ",", "\n", "first_n", "=", "None", ",", "\n", "char_embed_dim", "=", "24", ",", "\n", "character_mapper", "=", "mseq", "(", "Dropout", "(", "0.1", ")", ",", "Conv1d", "(", "100", ",", "5", ",", "None", ")", ")", ",", "\n", "character_pooler", "=", "MaxPooler", "(", ")", ",", "\n", "word_length", "=", "30", ",", "\n", ")", ",", "\n", "map_embed", "=", "seq", "(", "\n", "VariationalDropout", "(", "0.2", ")", ",", "\n", "recurrent_layer", "\n", ")", ",", "\n", "bifuse_layer", "=", "AttentionBiFuse", "(", "WeightedDot", "(", ")", ")", ",", "\n", "post_process_layer", "=", "seq", "(", "\n", "recurrent_layer", ",", "\n", "VariationalDropout", "(", "0.2", ")", ",", "\n", ")", ",", "\n", "pool_layer", "=", "MaxPooler", "(", ")", ",", "\n", "processs_joint", "=", "mseq", "(", "\n", "FullyConnected", "(", "100", ")", ",", "\n", "Dropout", "(", "0.2", ")", "\n", ")", ",", "\n", "n_classes", "=", "3", ",", "\n", "debias_loss_fn", "=", "cli_utils", ".", "get_clf_loss_fn", "(", "args", ")", "\n", ")", "\n", "\n", "with", "open", "(", "__file__", ")", "as", "f", ":", "\n", "    ", "notes", "=", "f", ".", "read", "(", ")", "\n", "\n", "", "py_utils", ".", "add_stdout_logger", "(", ")", "\n", "\n", "trainer", ".", "train", "(", "dataset", ",", "model", ",", "args", ".", "output_dir", ",", "notes", ")", "\n", "\n", "if", "args", ".", "output_dir", ":", "\n", "    ", "logging", ".", "info", "(", "\"Evaluating...\"", ")", "\n", "eval_debiased_mnli", ".", "show_scores", "(", "args", ".", "output_dir", ",", "True", ",", "True", ",", "n_processes", "=", "args", ".", "n_processes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.load_eval_set": [[16, 23], ["debias.datasets.mnli.load_hans", "debias.datasets.mnli.load_mnli", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_hans", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_mnli"], ["def", "load_eval_set", "(", "dataset_name", ",", "sample", "=", "None", ")", ":", "\n", "  ", "if", "dataset_name", "==", "\"hans\"", ":", "\n", "    ", "return", "mnli", ".", "load_hans", "(", "sample", ")", "\n", "", "elif", "dataset_name", "==", "\"dev\"", ":", "\n", "    ", "return", "mnli", ".", "load_mnli", "(", "False", ",", "sample", ")", "\n", "", "else", ":", "\n", "    ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.get_predictions": [[25, 88], ["os.path.join", "logging.info", "logging.info", "debias.models.model_dir.ModelDir", "debias.models.model_dir.ModelDir.get_model", "model_dir.get_model.get_tokenizer", "eval_debiased_mnli.load_eval_set", "debias.datasets.mnli.tokenize_examples", "mnli.tokenize_examples.sort", "logging.info", "set", "model_dir.get_model.set_vocab", "numpy.concatenate", "os.path.exists", "debias.utils.py_utils.load_pickle", "set.update", "set.update", "tensorflow.Session", "debias.datasets.mnli.make_dataset", "model_dir.get_model.tensorize_fn", "ds.padded_batch.map", "ds.padded_batch.padded_batch", "ds.padded_batch.prefetch", "ds.padded_batch.make_initializable_iterator", "ds.make_initializable_iterator.get_next", "model_dir.get_model.apply", "tensorflow.nn.softmax", "logging.info", "tf.Session.run", "tf.Session.run", "tf.Session.run", "logging.info", "tensorflow.train.Saver", "tf.train.Saver.restore", "tqdm.tqdm", "tqdm.tqdm.close", "tensorflow.Session", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "debias.models.model_dir.ModelDir.get_latest_checkpoint", "zip", "open", "pickle.dump", "len", "tensorflow.Graph", "len", "np.concatenate.append", "tqdm.tqdm.update", "tf.Session.run", "len"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.models.model_dir.ModelDir.get_model", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.get_tokenizer", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.load_eval_set", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.mnli.tokenize_examples", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.set_vocab", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_pickle", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.make_dataset", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.tensorize_fn", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.models.model_dir.ModelDir.get_latest_checkpoint", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run"], ["", "", "def", "get_predictions", "(", "path", ",", "part", "=", "\"hans\"", ",", "bach_size", "=", "128", ",", "sample", "=", "None", ",", "n_processes", "=", "None", ",", "cache", "=", "False", ")", ":", "\n", "  ", "output", "=", "join", "(", "path", ",", "\"%s-prediction.pkl\"", "%", "part", ")", "\n", "if", "sample", "is", "None", "and", "exists", "(", "output", ")", "and", "cache", ":", "\n", "    ", "return", "py_utils", ".", "load_pickle", "(", "output", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Computing predictions for %s on %s...\"", "%", "(", "path", ",", "part", ")", ")", "\n", "logging", ".", "info", "(", "\"Loading model...\"", ")", "\n", "model_dir", "=", "ModelDir", "(", "path", ")", "\n", "model", "=", "model_dir", ".", "get_model", "(", ")", "\n", "tokenizer", "=", "model", ".", "get_tokenizer", "(", ")", "\n", "all_examples", "=", "load_eval_set", "(", "part", ",", "sample", ")", "\n", "all_examples", "=", "mnli", ".", "tokenize_examples", "(", "all_examples", ",", "tokenizer", ",", "n_processes", ")", "\n", "\n", "all_examples", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", ".", "premise", ")", ")", "\n", "\n", "logging", ".", "info", "(", "\"Setup data...\"", ")", "\n", "voc", "=", "set", "(", ")", "\n", "for", "ex", "in", "all_examples", ":", "\n", "    ", "voc", ".", "update", "(", "ex", ".", "premise", ")", "\n", "voc", ".", "update", "(", "ex", ".", "hypothesis", ")", "\n", "\n", "", "model", ".", "set_vocab", "(", "voc", ")", "\n", "\n", "with", "tf", ".", "Session", "(", "graph", "=", "tf", ".", "Graph", "(", ")", ")", "as", "sess", ":", "\n", "    ", "ds", "=", "mnli", ".", "make_dataset", "(", "all_examples", ",", "shuffle", "=", "False", ")", "\n", "fn", "=", "model", ".", "tensorize_fn", "(", ")", "\n", "\n", "ds", "=", "ds", ".", "map", "(", "fn", ")", "\n", "ds", "=", "ds", ".", "padded_batch", "(", "bach_size", ",", "ds", ".", "output_shapes", ")", "\n", "ds", ".", "prefetch", "(", "5", ")", "\n", "it", "=", "ds", ".", "make_initializable_iterator", "(", ")", "\n", "\n", "next_op", "=", "it", ".", "get_next", "(", ")", "\n", "logits", "=", "model", ".", "apply", "(", "False", ",", "next_op", ",", "None", ")", "\n", "pred_op", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ")", "\n", "\n", "logging", ".", "info", "(", "\"Initializing...\"", ")", "\n", "if", "sess", "is", "None", ":", "\n", "      ", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "it", ".", "initializer", ")", "\n", "\n", "logging", ".", "info", "(", "\"Loading checkpoint...\"", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "model_dir", ".", "get_latest_checkpoint", "(", ")", ")", "\n", "\n", "predictions", "=", "[", "]", "\n", "pbar", "=", "tqdm", "(", "desc", "=", "\"classify\"", ",", "total", "=", "len", "(", "all_examples", ")", ",", "ncols", "=", "80", ")", "\n", "while", "True", ":", "\n", "      ", "try", ":", "\n", "        ", "predictions", ".", "append", "(", "sess", ".", "run", "(", "pred_op", ")", ")", "\n", "pbar", ".", "update", "(", "len", "(", "predictions", "[", "-", "1", "]", ")", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "break", "\n", "", "", "pbar", ".", "close", "(", ")", "\n", "\n", "", "predictions", "=", "np", ".", "concatenate", "(", "predictions", ",", "0", ")", "\n", "predictions", "=", "{", "k", ".", "id", ":", "p", "for", "p", ",", "k", "in", "zip", "(", "predictions", ",", "all_examples", ")", "}", "\n", "if", "sample", "is", "None", "and", "cache", ":", "\n", "    ", "with", "open", "(", "output", ",", "\"wb\"", ")", "as", "f", ":", "\n", "      ", "pickle", ".", "dump", "(", "predictions", ",", "f", ")", "\n", "", "", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.compute_dev_score": [[90, 94], ["numpy.stack", "numpy.array", "numpy.argmax"], "function", ["None"], ["", "def", "compute_dev_score", "(", "predictions", ",", "dev_examples", ")", ":", "\n", "  ", "pred", "=", "np", ".", "stack", "(", "[", "predictions", "[", "x", ".", "id", "]", "for", "x", "in", "dev_examples", "]", ",", "0", ")", "\n", "label_arr", "=", "np", ".", "array", "(", "[", "x", ".", "label", "for", "x", "in", "dev_examples", "]", ")", "\n", "return", "(", "np", ".", "argmax", "(", "pred", ",", "1", ")", "==", "label_arr", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.compute_hans_score": [[96, 112], ["numpy.array", "numpy.stack", "correct.mean", "numpy.argmax", "numpy.stack", "numpy.argmax", "NotImplementedError"], "function", ["None"], ["", "def", "compute_hans_score", "(", "preds", ",", "hans_examples", ",", "mode", "=", "\"sum\"", ")", ":", "\n", "  ", "label_arr", "=", "np", ".", "array", "(", "[", "x", ".", "label", "for", "x", "in", "hans_examples", "]", ")", "\n", "pred", "=", "np", ".", "stack", "(", "[", "preds", "[", "x", ".", "id", "]", "for", "x", "in", "hans_examples", "]", ",", "0", ")", "\n", "if", "mode", "==", "\"sum\"", ":", "\n", "    ", "pred", "=", "np", ".", "argmax", "(", "np", ".", "stack", "(", "[", "\n", "pred", "[", ":", ",", "0", "]", "+", "pred", "[", ":", ",", "2", "]", ",", "\n", "pred", "[", ":", ",", "1", "]", "\n", "]", ",", "1", ")", ",", "1", ")", "\n", "", "elif", "mode", "==", "\"map\"", ":", "\n", "    ", "pred", "=", "np", ".", "argmax", "(", "pred", ",", "1", ")", "\n", "pred", "[", "pred", "==", "2", "]", "=", "0", "\n", "", "else", ":", "\n", "    ", "raise", "NotImplementedError", "(", "mode", ")", "\n", "\n", "", "correct", "=", "pred", "==", "label_arr", "\n", "return", "correct", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.get_hans_scores": [[114, 129], ["os.path.join", "os.path.exists", "debias.utils.py_utils.load_json", "logging.info", "eval_debiased_mnli.get_predictions", "eval_debiased_mnli.load_eval_set", "eval_debiased_mnli.compute_hans_score", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_json", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.get_predictions", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.load_eval_set", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.compute_hans_score"], ["", "def", "get_hans_scores", "(", "path", ",", "cache", "=", "True", ",", "n_processes", "=", "None", ",", "mode", "=", "\"sum\"", ")", ":", "\n", "  ", "cache_file", "=", "join", "(", "path", ",", "\"hans_scores.json\"", ")", "\n", "if", "exists", "(", "cache_file", ")", "and", "cache", "and", "mode", "==", "\"sum\"", ":", "\n", "    ", "return", "py_utils", ".", "load_json", "(", "cache_file", ")", "\n", "", "else", ":", "\n", "    ", "logging", ".", "info", "(", "\"Scoring %s...\"", "%", "path", ")", "\n", "pred", "=", "get_predictions", "(", "path", ",", "\"hans\"", ",", "n_processes", "=", "n_processes", ",", "cache", "=", "cache", ")", "\n", "hans", "=", "load_eval_set", "(", "\"hans\"", ")", "\n", "\n", "score", "=", "compute_hans_score", "(", "pred", ",", "hans", ",", "mode", ")", "\n", "score", "=", "{", "\"accuracy\"", ":", "score", "}", "\n", "if", "cache", "and", "mode", "==", "\"sum\"", ":", "\n", "      ", "with", "open", "(", "cache_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "score", ",", "f", ")", "\n", "", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.get_dev_scores": [[131, 145], ["os.path.join", "os.path.exists", "debias.utils.py_utils.load_json", "logging.info", "eval_debiased_mnli.get_predictions", "eval_debiased_mnli.load_eval_set", "eval_debiased_mnli.compute_dev_score", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_json", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.get_predictions", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.load_eval_set", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.compute_dev_score"], ["", "", "def", "get_dev_scores", "(", "path", ",", "cache", "=", "True", ",", "n_processes", "=", "None", ")", ":", "\n", "  ", "cache_file", "=", "join", "(", "path", ",", "\"dev_scores.json\"", ")", "\n", "if", "exists", "(", "cache_file", ")", "and", "cache", ":", "\n", "    ", "return", "py_utils", ".", "load_json", "(", "cache_file", ")", "\n", "", "else", ":", "\n", "    ", "logging", ".", "info", "(", "\"Scoring %s...\"", "%", "path", ")", "\n", "pred", "=", "get_predictions", "(", "path", ",", "\"dev\"", ",", "n_processes", "=", "n_processes", ",", "cache", "=", "cache", ")", "\n", "hans", "=", "load_eval_set", "(", "\"dev\"", ")", "\n", "score", "=", "compute_dev_score", "(", "pred", ",", "hans", ")", "\n", "score", "=", "{", "\"accuracy\"", ":", "score", "}", "\n", "if", "cache", ":", "\n", "      ", "with", "open", "(", "cache_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "score", ",", "f", ")", "\n", "", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.show_scores": [[147, 156], ["result_dict.items", "eval_debiased_mnli.get_dev_scores", "eval_debiased_mnli.get_hans_scores", "print", "print", "json.dumps"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.get_dev_scores", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.get_hans_scores"], ["", "", "def", "show_scores", "(", "path", ",", "dev", ":", "bool", ",", "hans", ":", "bool", ",", "cache", "=", "True", ",", "n_processes", "=", "None", ")", ":", "\n", "  ", "result_dict", "=", "{", "}", "\n", "if", "dev", ":", "\n", "    ", "result_dict", "[", "\"dev\"", "]", "=", "get_dev_scores", "(", "path", ",", "n_processes", "=", "n_processes", ",", "cache", "=", "cache", ")", "\n", "", "if", "hans", ":", "\n", "    ", "result_dict", "[", "\"hans\"", "]", "=", "get_hans_scores", "(", "path", ",", "n_processes", "=", "n_processes", ",", "cache", "=", "cache", ")", "\n", "", "for", "k", ",", "result", "in", "result_dict", ".", "items", "(", ")", ":", "\n", "    ", "print", "(", "\"*\"", "*", "8", "+", "\" \"", "+", "k", "+", "\" \"", "+", "\"*\"", "*", "8", ")", "\n", "print", "(", "json", ".", "dumps", "(", "result", ",", "indent", "=", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.main": [[158, 171], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "debias.utils.py_utils.add_stdout_logger", "compute_scores"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.add_stdout_logger", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_squad.compute_scores"], ["", "", "def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_processes\"", ",", "\"-n\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--nocache\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "choices", "=", "[", "\"dev\"", ",", "\"hans\"", ",", "\"both\"", "]", ",", "\n", "default", "=", "\"both\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "py_utils", ".", "add_stdout_logger", "(", ")", "\n", "\n", "compute_scores", "(", "\n", "args", ".", "model", ",", "args", ".", "dataset", "in", "[", "\"dev\"", ",", "\"both\"", "]", ",", "args", ".", "dataset", "in", "[", "\"hans\"", ",", "\"both\"", "]", ",", "\n", "not", "args", ".", "nocache", ",", "args", ".", "n_processes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.experiments.train_debiased_sythetic.main": [[22, 109], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "debias.utils.cli_utils.add_general_args", "debias.utils.cli_utils.add_loss_args", "argparse.ArgumentParser.parse_args", "debias.training.trainer.AdamOptimizer", "debias.datasets.dataset_utils.QuantileBatcher", "debias.training.evaluator.Evaluator", "debias.training.trainer.Trainer", "debias.modules.cudnn_recurrent_dropout.CudnnLSTMRecurrentDropout", "debias.models.text_pair_clf_model.TextPairClfDebiasingModel", "debias.utils.py_utils.add_stdout_logger", "debias.training.trainer.Trainer.train", "debias.datasets.synthetic.MnliWithSyntheticBiasLoading", "debias.datasets.synthetic.MnliWithSyntheticBiasLoading", "debias.utils.tokenizer.NltkAndPunctTokenizer", "debias.modules.word_and_char_encoder.WordAndCharEncoder", "open", "f.read", "logging.info", "debias.experiments.eval_debiased_synthetic.show_scores", "debias.modules.layers.seq", "debias.modules.attention_layers.AttentionBiFuse", "debias.modules.layers.seq", "debias.modules.layers.MaxPooler", "debias.modules.layers.mseq", "debias.utils.cli_utils.get_clf_loss_fn", "RuntimeError", "debias.modules.layers.mseq", "debias.modules.layers.MaxPooler", "debias.modules.layers.VariationalDropout", "debias.modules.attention_layers.WeightedDot", "debias.modules.layers.VariationalDropout", "debias.modules.layers.FullyConnected", "debias.modules.layers.Dropout", "debias.modules.layers.Dropout", "debias.modules.layers.Conv1d"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.cli_utils.add_general_args", "home.repos.pwc.inspect_result.chrisc36_debias.utils.cli_utils.add_loss_args", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.add_stdout_logger", "home.repos.pwc.inspect_result.chrisc36_debias.training.trainer.Trainer.train", "home.repos.pwc.inspect_result.chrisc36_debias.experiments.eval_debiased_mnli.show_scores", "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.seq", "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.seq", "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.mseq", "home.repos.pwc.inspect_result.chrisc36_debias.utils.cli_utils.get_clf_loss_fn", "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.mseq"], ["def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--bias\"", ",", "choices", "=", "[", "\"indicator\"", ",", "\"excluder\"", ",", "\"dependent\"", "]", ",", "default", "=", "\"indicator\"", ")", "\n", "cli_utils", ".", "add_general_args", "(", "parser", ")", "\n", "cli_utils", ".", "add_loss_args", "(", "parser", ",", "default_penalty", "=", "None", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "penalty", "is", "None", ":", "\n", "    ", "if", "args", ".", "bias", "==", "\"indicator\"", ":", "\n", "      ", "args", ".", "penalty", "=", "0.01", "\n", "", "else", ":", "\n", "      ", "args", ".", "penalty", "=", "0.005", "\n", "\n", "", "", "dbg", "=", "args", ".", "debug", "\n", "\n", "if", "dbg", ":", "\n", "    ", "epoch_size", "=", "200", "\n", "", "else", ":", "\n", "    ", "epoch_size", "=", "6000", "\n", "\n", "", "opt", "=", "AdamOptimizer", "(", "max_grad_norm", "=", "5.0", ")", "\n", "batcher", "=", "QuantileBatcher", "(", "32", ",", "10", ",", "160", ",", "4", ",", "12", ")", "\n", "evaluator", "=", "Evaluator", "(", "mode", "=", "\"clf\"", ")", "\n", "\n", "trainer", "=", "Trainer", "(", "\n", "batcher", ",", "opt", ",", "evaluator", ",", "\n", "eval_batch_size", "=", "64", ",", "\n", "num_epochs", "=", "30", ",", "epoch_size", "=", "epoch_size", ",", "\n", "log_period", "=", "100", ",", "\n", "prefetch", "=", "5", ",", "loss_ema", "=", "0.999", ",", "\n", "n_processes", "=", "args", ".", "n_processes", ",", "\n", ")", "\n", "\n", "if", "args", ".", "bias", "==", "\"indicator\"", ":", "\n", "    ", "bias_prob", ",", "i_prob", "=", "0.8", ",", "None", "\n", "", "elif", "args", ".", "bias", "==", "\"excluder\"", ":", "\n", "    ", "bias_prob", ",", "i_prob", "=", "0.03", ",", "None", "\n", "", "elif", "args", ".", "bias", "==", "\"dependent\"", ":", "\n", "    ", "bias_prob", ",", "i_prob", "=", "0.9", ",", "0.8", "\n", "", "else", ":", "\n", "    ", "raise", "RuntimeError", "(", ")", "\n", "\n", "", "if", "dbg", ":", "\n", "    ", "dataset", "=", "MnliWithSyntheticBiasLoading", "(", "bias_prob", ",", "n_train_eval", "=", "200", ",", "n_train_sample", "=", "1000", ",", "n_dev_sample", "=", "200", ",", "indicator_noise", "=", "i_prob", ")", "\n", "", "else", ":", "\n", "    ", "dataset", "=", "MnliWithSyntheticBiasLoading", "(", "bias_prob", ",", "n_train_eval", "=", "10000", ",", "indicator_noise", "=", "i_prob", ")", "\n", "\n", "", "dim", "=", "50", "if", "dbg", "else", "200", "\n", "recurrent_layer", "=", "CudnnLSTMRecurrentDropout", "(", "dim", ",", "0.2", ")", "\n", "model", "=", "TextPairClfDebiasingModel", "(", "\n", "NltkAndPunctTokenizer", "(", ")", ",", "\n", "WordAndCharEncoder", "(", "\n", "\"glove.6B.50d\"", "if", "dbg", "else", "\"crawl-300d-2M\"", ",", "\n", "first_n", "=", "None", ",", "\n", "char_embed_dim", "=", "24", ",", "\n", "character_mapper", "=", "mseq", "(", "Dropout", "(", "0.1", ")", ",", "Conv1d", "(", "100", ",", "5", ",", "None", ")", ")", ",", "\n", "character_pooler", "=", "MaxPooler", "(", ")", ",", "\n", "word_length", "=", "30", ",", "\n", ")", ",", "\n", "map_embed", "=", "seq", "(", "\n", "VariationalDropout", "(", "0.2", ")", ",", "\n", "recurrent_layer", "\n", ")", ",", "\n", "bifuse_layer", "=", "AttentionBiFuse", "(", "WeightedDot", "(", ")", ")", ",", "\n", "post_process_layer", "=", "seq", "(", "\n", "recurrent_layer", ",", "\n", "VariationalDropout", "(", "0.2", ")", ",", "\n", ")", ",", "\n", "pool_layer", "=", "MaxPooler", "(", ")", ",", "\n", "processs_joint", "=", "mseq", "(", "\n", "FullyConnected", "(", "100", ")", ",", "\n", "Dropout", "(", "0.2", ")", "\n", ")", ",", "\n", "n_classes", "=", "3", ",", "\n", "debias_loss_fn", "=", "cli_utils", ".", "get_clf_loss_fn", "(", "args", ")", "\n", ")", "\n", "\n", "with", "open", "(", "__file__", ")", "as", "f", ":", "\n", "    ", "notes", "=", "f", ".", "read", "(", ")", "\n", "\n", "", "py_utils", ".", "add_stdout_logger", "(", ")", "\n", "\n", "trainer", ".", "train", "(", "dataset", ",", "model", ",", "args", ".", "output_dir", ",", "notes", ")", "\n", "\n", "if", "args", ".", "output_dir", ":", "\n", "    ", "logging", ".", "info", "(", "\"Evaluating...\"", ")", "\n", "show_scores", "(", "args", ".", "output_dir", ",", "args", ".", "bias", ",", "[", "False", ",", "True", "]", ",", "n_processes", "=", "args", ".", "n_processes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_eval.eval_squad": [[9, 39], ["numpy.zeros", "enumerate", "tqdm.tqdm", "zip", "list", "len", "len", "debias.squad_eval.squad_v1_official_evaluation.normalize_answer", "zip", "debias.squad_eval.squad_v1_official_evaluation.normalize_answer", "max", "len", "len", "len", "debias.squad_eval.squad_v1_official_evaluation.f1_score"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.f1_score"], ["def", "eval_squad", "(", "predicted_ans", ",", "actual_answers", ",", "use_tqdm", "=", "False", ")", ":", "\n", "  ", "\"\"\"\n  :param predicted_ans: List of strings,\n  :param actual_answers: List of list of strings\n  :param use_tqdm: Show progress with tqdm\n  :return: ndarray of size [n_answers, 2] with the em/f1 scores\n  \"\"\"", "\n", "if", "use_tqdm", ":", "\n", "    ", "it", "=", "tqdm", "(", "list", "(", "zip", "(", "predicted_ans", ",", "actual_answers", ")", ")", ",", "ncols", "=", "100", ",", "desc", "=", "\"eval\"", ")", "\n", "", "else", ":", "\n", "    ", "it", "=", "zip", "(", "predicted_ans", ",", "actual_answers", ")", "\n", "\n", "", "scores", "=", "np", ".", "zeros", "(", "(", "len", "(", "predicted_ans", ")", ",", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", ",", "(", "predicted_ans", ",", "actual", ")", "in", "enumerate", "(", "it", ")", ":", "\n", "    ", "em", "=", "0", "\n", "f1", "=", "0", "\n", "if", "len", "(", "actual", ")", ">", "0", ":", "\n", "      ", "predicted_ans", "=", "normalize_answer", "(", "predicted_ans", ")", "\n", "for", "ans", "in", "actual", ":", "\n", "        ", "if", "len", "(", "ans", ")", "==", "0", ":", "\n", "          ", "continue", "\n", "", "ans", "=", "normalize_answer", "(", "ans", ")", "\n", "em", "=", "em", "or", "(", "ans", "==", "predicted_ans", ")", "\n", "f1", "=", "max", "(", "f1", ",", "f1_score", "(", "predicted_ans", ",", "ans", ")", ")", "\n", "", "", "else", ":", "\n", "      ", "em", "=", "len", "(", "predicted_ans", ")", "==", "0", "\n", "f1", "=", "len", "(", "predicted_ans", ")", "==", "0", "\n", "", "scores", "[", "i", "]", "=", "(", "em", ",", "f1", ")", "\n", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_eval._eval_squad_from_spans": [[41, 50], ["range", "squad_eval.eval_squad", "len", "texts[].decode", "predicted_answers.append", "x.decode", "len"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_eval.eval_squad"], ["", "def", "_eval_squad_from_spans", "(", "spans", ",", "invs", ",", "texts", ",", "actual_answers", ")", ":", "\n", "  ", "predicted_answers", "=", "[", "]", "\n", "actual_answers", "=", "[", "[", "x", ".", "decode", "(", "\"utf-8\"", ")", "for", "x", "in", "ans", "if", "len", "(", "x", ")", ">", "0", "]", "for", "ans", "in", "actual_answers", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "spans", ")", ")", ":", "\n", "    ", "inv", "=", "invs", "[", "i", "]", "\n", "text", "=", "texts", "[", "i", "]", ".", "decode", "(", "\"utf-8\"", ")", "\n", "ans", "=", "text", "[", "inv", "[", "spans", "[", "i", ",", "0", "]", ",", "0", "]", ":", "inv", "[", "spans", "[", "i", ",", "1", "]", ",", "1", "]", "]", "\n", "predicted_answers", ".", "append", "(", "ans", ")", "\n", "", "return", "eval_squad", "(", "predicted_answers", ",", "actual_answers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_eval.eval_squad_op": [[52, 62], ["debias.utils.ops.get_best_span", "tensorflow.py_func", "tf.py_func.set_shape", "inv.shape.as_list"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_best_span"], ["", "def", "eval_squad_op", "(", "span_logits", ",", "inv", ",", "passage_text", ",", "actual_answers", ",", "max_bound", ")", ":", "\n", "  ", "\"\"\"Tensorflow op to compute em/f1 scores using SQuAD metrics\"\"\"", "\n", "batch", "=", "inv", ".", "shape", ".", "as_list", "(", ")", "[", "0", "]", "\n", "predicted_span", "=", "get_best_span", "(", "span_logits", ",", "max_bound", ")", "\n", "scores", "=", "tf", ".", "py_func", "(", "\n", "_eval_squad_from_spans", ",", "\n", "[", "predicted_span", ",", "inv", ",", "passage_text", ",", "actual_answers", "]", ",", "\n", "tf", ".", "float32", ",", "False", ")", "\n", "scores", ".", "set_shape", "(", "[", "batch", ",", "2", "]", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.normalize_answer": [[12, 28], ["squad_v1_adversarial_evaluation.normalize_answer.white_space_fix"], "function", ["None"], ["def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.f1_score": [[30, 41], ["normalize_answer().split", "normalize_answer().split", "sum", "collections.Counter", "collections.Counter", "common.values", "len", "len", "squad_v1_adversarial_evaluation.normalize_answer", "squad_v1_adversarial_evaluation.normalize_answer"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer"], ["", "def", "f1_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "prediction_tokens", "=", "normalize_answer", "(", "prediction", ")", ".", "split", "(", ")", "\n", "ground_truth_tokens", "=", "normalize_answer", "(", "ground_truth", ")", ".", "split", "(", ")", "\n", "common", "=", "Counter", "(", "prediction_tokens", ")", "&", "Counter", "(", "ground_truth_tokens", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "prediction_tokens", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "ground_truth_tokens", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.exact_match_score": [[43, 45], ["squad_v1_adversarial_evaluation.normalize_answer", "squad_v1_adversarial_evaluation.normalize_answer"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer"], ["", "def", "exact_match_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "return", "(", "normalize_answer", "(", "prediction", ")", "==", "normalize_answer", "(", "ground_truth", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.metric_max_over_ground_truths": [[47, 53], ["max", "scores_for_ground_truths.append", "squad_v1_adversarial_evaluation.exact_match_score", "squad_v1_adversarial_evaluation.f1_score", "squad_v1_adversarial_evaluation.exact_match_score", "squad_v1_adversarial_evaluation.f1_score"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.exact_match_score", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.f1_score", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.exact_match_score", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.f1_score"], ["", "def", "metric_max_over_ground_truths", "(", "metric_fn", ",", "prediction", ",", "ground_truths", ")", ":", "\n", "    ", "scores_for_ground_truths", "=", "[", "]", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "score", "=", "metric_fn", "(", "prediction", ",", "ground_truth", ")", "\n", "scores_for_ground_truths", ".", "append", "(", "score", ")", "\n", "", "return", "max", "(", "scores_for_ground_truths", ")", "\n", "### END: official SQuAD code", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.strip_id": [[55, 57], ["id_str.split"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split"], ["", "def", "strip_id", "(", "id_str", ")", ":", "\n", "  ", "return", "id_str", ".", "split", "(", "'-'", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.highlight_after": [[58, 60], ["colored"], "function", ["None"], ["", "def", "highlight_after", "(", "s", ",", "n", ")", ":", "\n", "  ", "return", "s", "[", ":", "n", "]", "+", "colored", "(", "s", "[", "n", ":", "]", ",", "'cyan'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.get_answer_color": [[61, 68], ["squad_v1_adversarial_evaluation.metric_max_over_ground_truths", "squad_v1_adversarial_evaluation.metric_max_over_ground_truths"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.metric_max_over_ground_truths"], ["", "def", "get_answer_color", "(", "pred", ",", "answers", ")", ":", "\n", "  ", "ans_texts", "=", "[", "a", "[", "'text'", "]", "for", "a", "in", "answers", "]", "\n", "exact", "=", "metric_max_over_ground_truths", "(", "exact_match_score", ",", "pred", ",", "ans_texts", ")", "\n", "if", "exact", ":", "return", "'green'", "\n", "f1", "=", "metric_max_over_ground_truths", "(", "f1_score", ",", "pred", ",", "ans_texts", ")", "\n", "if", "f1", ":", "return", "'yellow'", "\n", "return", "'red'", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.print_details": [[70, 99], ["squad_v1_adversarial_evaluation.strip_id", "print", "print", "print", "print", "squad_v1_adversarial_evaluation.get_answer_color", "print", "print", "print", "print", "squad_v1_adversarial_evaluation.get_answer_color", "print", "article[].encode", "paragraph[].encode", "qa[].encode", "colored().encode", "highlight_after().encode", "colored().encode", "a[].encode", "colored", "squad_v1_adversarial_evaluation.highlight_after", "colored", "len"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.strip_id", "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.get_answer_color", "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.get_answer_color", "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.highlight_after"], ["", "def", "print_details", "(", "dataset", ",", "predictions", ",", "adv_ids", ")", ":", "\n", "  ", "id_to_paragraph", "=", "{", "}", "\n", "for", "article", "in", "dataset", ":", "\n", "    ", "for", "paragraph", "in", "article", "[", "'paragraphs'", "]", ":", "\n", "      ", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "        ", "id_to_paragraph", "[", "qa", "[", "'id'", "]", "]", "=", "paragraph", "[", "'context'", "]", "\n", "", "", "", "for", "article", "in", "dataset", ":", "\n", "    ", "for", "paragraph", "in", "article", "[", "'paragraphs'", "]", ":", "\n", "      ", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "        ", "orig_id", "=", "strip_id", "(", "qa", "[", "'id'", "]", ")", "\n", "if", "orig_id", "!=", "qa", "[", "'id'", "]", ":", "continue", "# Skip the mutated ones", "\n", "adv_id", "=", "adv_ids", "[", "orig_id", "]", "\n", "print", "(", "'Title: %s'", "%", "article", "[", "'title'", "]", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "print", "(", "'Paragraph: %s'", "%", "paragraph", "[", "'context'", "]", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "print", "(", "'Question: %s'", "%", "qa", "[", "'question'", "]", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "print", "(", "'Answers: [%s]'", "%", "', '", ".", "join", "(", "a", "[", "'text'", "]", ".", "encode", "(", "'utf-8'", ")", "\n", "for", "a", "in", "qa", "[", "'answers'", "]", ")", ")", "\n", "orig_color", "=", "get_answer_color", "(", "predictions", "[", "orig_id", "]", ",", "qa", "[", "'answers'", "]", ")", "\n", "print", "(", "'Predicted: %s'", "%", "colored", "(", "\n", "predictions", "[", "orig_id", "]", ",", "orig_color", ")", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "print", "(", "'Adversary succeeded?: %s'", "%", "(", "adv_id", "!=", "orig_id", ")", ")", "\n", "if", "adv_id", "!=", "orig_id", ":", "\n", "          ", "print", "(", "'Adversarial Paragraph: %s'", "%", "highlight_after", "(", "\n", "id_to_paragraph", "[", "adv_id", "]", ",", "len", "(", "paragraph", "[", "'context'", "]", ")", ")", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "# highlight_after is a hack that only works when mutations append stuff.", "\n", "adv_color", "=", "get_answer_color", "(", "predictions", "[", "adv_id", "]", ",", "qa", "[", "'answers'", "]", ")", "\n", "print", "(", "'Prediction under Adversary: %s'", "%", "colored", "(", "\n", "predictions", "[", "adv_id", "]", ",", "adv_color", ")", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.evaluate_adversarial": [[102, 153], ["set", "collections.OrderedDict", "squad_v1_adversarial_evaluation.print_details", "len", "len", "len", "len", "sum", "sum", "set.add", "list", "squad_v1_adversarial_evaluation.metric_max_over_ground_truths", "squad_v1_adversarial_evaluation.metric_max_over_ground_truths", "adv_exact_match_scores.values", "adv_f1_scores.values", "qa[].split", "print", "map"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.print_details", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split"], ["", "", "", "", "def", "evaluate_adversarial", "(", "dataset", ",", "predictions", ",", "verbose", "=", "False", ",", "id_set", "=", "None", ")", ":", "\n", "  ", "orig_f1_score", "=", "0.0", "\n", "orig_exact_match_score", "=", "0.0", "\n", "adv_f1_scores", "=", "{", "}", "# Map from original ID to F1 score", "\n", "adv_exact_match_scores", "=", "{", "}", "# Map from original ID to exact match score", "\n", "adv_ids", "=", "{", "}", "\n", "all_ids", "=", "set", "(", ")", "# Set of all original IDs", "\n", "f1", "=", "exact_match", "=", "0", "\n", "for", "article", "in", "dataset", ":", "\n", "    ", "for", "paragraph", "in", "article", "[", "'paragraphs'", "]", ":", "\n", "      ", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "        ", "orig_id", "=", "qa", "[", "'id'", "]", ".", "split", "(", "'-'", ")", "[", "0", "]", "\n", "if", "id_set", "and", "orig_id", "not", "in", "id_set", ":", "continue", "\n", "all_ids", ".", "add", "(", "orig_id", ")", "\n", "if", "qa", "[", "'id'", "]", "not", "in", "predictions", ":", "\n", "          ", "message", "=", "'Unanswered question '", "+", "qa", "[", "'id'", "]", "+", "' will receive score 0.'", "\n", "print", "(", "message", ")", "\n", "continue", "\n", "", "ground_truths", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "'text'", "]", ",", "qa", "[", "'answers'", "]", ")", ")", "\n", "prediction", "=", "predictions", "[", "qa", "[", "'id'", "]", "]", "\n", "cur_exact_match", "=", "metric_max_over_ground_truths", "(", "exact_match_score", ",", "\n", "prediction", ",", "ground_truths", ")", "\n", "cur_f1", "=", "metric_max_over_ground_truths", "(", "f1_score", ",", "prediction", ",", "ground_truths", ")", "\n", "if", "orig_id", "==", "qa", "[", "'id'", "]", ":", "\n", "# This is an original example", "\n", "          ", "orig_f1_score", "+=", "cur_f1", "\n", "orig_exact_match_score", "+=", "cur_exact_match", "\n", "if", "orig_id", "not", "in", "adv_f1_scores", ":", "\n", "# Haven't seen adversarial example yet, so use original for adversary", "\n", "            ", "adv_ids", "[", "orig_id", "]", "=", "orig_id", "\n", "adv_f1_scores", "[", "orig_id", "]", "=", "cur_f1", "\n", "adv_exact_match_scores", "[", "orig_id", "]", "=", "cur_exact_match", "\n", "", "", "else", ":", "\n", "# This is an adversarial example", "\n", "          ", "if", "(", "orig_id", "not", "in", "adv_f1_scores", "or", "adv_ids", "[", "orig_id", "]", "==", "orig_id", "\n", "or", "adv_f1_scores", "[", "orig_id", "]", ">", "cur_f1", ")", ":", "\n", "# Always override if currently adversary currently using orig_id", "\n", "            ", "adv_ids", "[", "orig_id", "]", "=", "qa", "[", "'id'", "]", "\n", "adv_f1_scores", "[", "orig_id", "]", "=", "cur_f1", "\n", "adv_exact_match_scores", "[", "orig_id", "]", "=", "cur_exact_match", "\n", "", "", "", "", "", "if", "verbose", ":", "\n", "    ", "print_details", "(", "dataset", ",", "predictions", ",", "adv_ids", ")", "\n", "", "orig_f1", "=", "100.0", "*", "orig_f1_score", "/", "len", "(", "all_ids", ")", "\n", "orig_exact_match", "=", "100.0", "*", "orig_exact_match_score", "/", "len", "(", "all_ids", ")", "\n", "adv_exact_match", "=", "100.0", "*", "sum", "(", "adv_exact_match_scores", ".", "values", "(", ")", ")", "/", "len", "(", "all_ids", ")", "\n", "adv_f1", "=", "100.0", "*", "sum", "(", "adv_f1_scores", ".", "values", "(", ")", ")", "/", "len", "(", "all_ids", ")", "\n", "return", "OrderedDict", "(", "[", "\n", "(", "'orig_exact_match'", ",", "orig_exact_match", ")", ",", "\n", "(", "'orig_f1'", ",", "orig_f1", ")", ",", "\n", "(", "'adv_exact_match'", ",", "adv_exact_match", ")", ",", "\n", "(", "'adv_f1'", ",", "adv_f1", ")", ",", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.split_by_attempted": [[155, 167], ["set", "set", "set.add", "qa[].split", "set.add"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split"], ["", "def", "split_by_attempted", "(", "dataset", ")", ":", "\n", "  ", "all_ids", "=", "set", "(", ")", "\n", "attempted_ids", "=", "set", "(", ")", "\n", "for", "article", "in", "dataset", ":", "\n", "    ", "for", "paragraph", "in", "article", "[", "'paragraphs'", "]", ":", "\n", "      ", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "        ", "orig_id", "=", "qa", "[", "'id'", "]", ".", "split", "(", "'-'", ")", "[", "0", "]", "\n", "all_ids", ".", "add", "(", "orig_id", ")", "\n", "if", "orig_id", "!=", "qa", "[", "'id'", "]", ":", "\n", "          ", "attempted_ids", ".", "add", "(", "orig_id", ")", "\n", "", "", "", "", "not_attempted_ids", "=", "all_ids", "-", "attempted_ids", "\n", "return", "attempted_ids", ",", "not_attempted_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.evaluate_by_attempted": [[168, 181], ["squad_v1_adversarial_evaluation.split_by_attempted", "squad_v1_adversarial_evaluation.evaluate_adversarial", "print", "print", "squad_v1_adversarial_evaluation.evaluate_adversarial", "print", "print", "len", "len", "json.dumps", "json.dumps", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.split_by_attempted", "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.evaluate_adversarial", "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_adversarial_evaluation.evaluate_adversarial"], ["", "def", "evaluate_by_attempted", "(", "dataset", ",", "predictions", ")", ":", "\n", "  ", "attempted", ",", "not_attempted", "=", "split_by_attempted", "(", "dataset", ")", "\n", "total_num", "=", "len", "(", "attempted", ")", "+", "len", "(", "not_attempted", ")", "\n", "results_attempted", "=", "evaluate_adversarial", "(", "dataset", ",", "predictions", ",", "\n", "id_set", "=", "attempted", ")", "\n", "print", "(", "'Attempted %d/%d = %.2f%%'", "%", "(", "\n", "len", "(", "attempted", ")", ",", "total_num", ",", "100.0", "*", "len", "(", "attempted", ")", "/", "total_num", ")", ")", "\n", "print", "(", "json", ".", "dumps", "(", "results_attempted", ")", ")", "\n", "results_not_attempted", "=", "evaluate_adversarial", "(", "dataset", ",", "predictions", ",", "\n", "id_set", "=", "not_attempted", ")", "\n", "print", "(", "'Did not attempt %d/%d = %.2f%%'", "%", "(", "\n", "len", "(", "not_attempted", ")", ",", "total_num", ",", "100.0", "*", "len", "(", "not_attempted", ")", "/", "total_num", ")", ")", "\n", "print", "(", "json", ".", "dumps", "(", "results_not_attempted", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.triviaqa_eval.eval_triviaqa": [[9, 38], ["numpy.zeros", "enumerate", "tqdm.tqdm", "zip", "len", "list", "len", "triviaqa_cp.triviaqa_cp_evaluation.normalize_answer", "zip", "max", "len", "len", "len", "triviaqa_cp.triviaqa_cp_evaluation.f1_score"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.f1_score"], ["def", "eval_triviaqa", "(", "predicted_ans", ",", "actual_answers", ",", "use_tqdm", "=", "False", ")", ":", "\n", "  ", "\"\"\"\n  :param predicted_ans: List of strings,\n  :param actual_answers: List of list of strings\n  :param use_tqdm: Show progress with tqdm\n  :return: ndarray of size [n_answers, 2] with the em/f1 scores\n  \"\"\"", "\n", "scores", "=", "np", ".", "zeros", "(", "(", "len", "(", "predicted_ans", ")", ",", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "if", "use_tqdm", ":", "\n", "    ", "it", "=", "tqdm", "(", "list", "(", "zip", "(", "predicted_ans", ",", "actual_answers", ")", ")", ",", "ncols", "=", "100", ",", "desc", "=", "\"eval\"", ")", "\n", "", "else", ":", "\n", "    ", "it", "=", "zip", "(", "predicted_ans", ",", "actual_answers", ")", "\n", "", "for", "i", ",", "(", "predicted_ans", ",", "actual", ")", "in", "enumerate", "(", "it", ")", ":", "\n", "    ", "predicted", "=", "predicted_ans", "\n", "em", "=", "0", "\n", "f1", "=", "0", "\n", "if", "len", "(", "actual", ")", ">", "0", ":", "\n", "      ", "predicted", "=", "normalize_answer", "(", "predicted", ")", "\n", "for", "ans", "in", "actual", ":", "\n", "        ", "if", "len", "(", "ans", ")", "==", "0", ":", "\n", "          ", "continue", "\n", "", "em", "=", "em", "or", "(", "ans", "==", "predicted", ")", "\n", "f1", "=", "max", "(", "f1", ",", "f1_score", "(", "predicted", ",", "ans", ")", ")", "\n", "", "", "else", ":", "\n", "      ", "em", "=", "len", "(", "predicted", ")", "==", "0", "\n", "f1", "=", "len", "(", "predicted", ")", "==", "0", "\n", "", "scores", "[", "i", "]", "=", "(", "em", ",", "f1", ")", "\n", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.triviaqa_eval._eval_triviaqa_decode": [[40, 44], ["triviaqa_eval.eval_triviaqa", "x.decode", "x.decode", "len"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.triviaqa_eval.eval_triviaqa"], ["", "def", "_eval_triviaqa_decode", "(", "predicted_ans", ",", "actual_answers", ")", ":", "\n", "  ", "return", "eval_triviaqa", "(", "\n", "[", "x", ".", "decode", "(", "\"utf-8\"", ")", "for", "x", "in", "predicted_ans", "]", ",", "\n", "[", "[", "x", ".", "decode", "(", "\"utf-8\"", ")", "for", "x", "in", "ans", "if", "len", "(", "x", ")", ">", "0", "]", "for", "ans", "in", "actual_answers", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.triviaqa_eval.eval_triviaqa_op": [[47, 62], ["debias.utils.ops.get_best_span", "tensorflow.map_fn", "tensorflow.py_func", "tf.py_func.set_shape", "tensorflow.range", "tensorflow.reduce_join", "debias.utils.ops.get_shape_tuple", "logits.shape.as_list"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_best_span", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_shape_tuple"], ["", "def", "eval_triviaqa_op", "(", "logits", ",", "tokens", ",", "actual_answers", ",", "bound", ")", ":", "\n", "  ", "\"\"\"Tensorflow op to compute em/f1 scores using TriviaQA metrics\"\"\"", "\n", "answer_spans", "=", "ops", ".", "get_best_span", "(", "logits", ",", "bound", ")", "\n", "\n", "# Unlike SQuAD, for TriviaQA we don't bother properly untokenizing the", "\n", "# span, and just return the tokens with space seperators, since", "\n", "# that is almost always good enough for TriviaQA", "\n", "answer_text", "=", "tf", ".", "map_fn", "(", "\n", "lambda", "i", ":", "tf", ".", "reduce_join", "(", "tokens", "[", "i", ",", "answer_spans", "[", "i", "]", "[", "0", "]", ":", "answer_spans", "[", "i", "]", "[", "1", "]", "+", "1", "]", ",", "0", ",", "separator", "=", "\" \"", ")", ",", "\n", "tf", ".", "range", "(", "ops", ".", "get_shape_tuple", "(", "logits", ",", "0", ")", ")", ",", "\n", "dtype", "=", "tf", ".", "string", ",", "back_prop", "=", "False", "\n", ")", "\n", "scores", "=", "tf", ".", "py_func", "(", "_eval_triviaqa_decode", ",", "[", "answer_text", ",", "actual_answers", "]", ",", "tf", ".", "float32", ",", "False", ")", "\n", "scores", ".", "set_shape", "(", "[", "logits", ".", "shape", ".", "as_list", "(", ")", "[", "0", "]", ",", "2", "]", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_official_evaluation.normalize_answer": [[12, 28], ["squad_v1_official_evaluation.normalize_answer.white_space_fix"], "function", ["None"], ["def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_official_evaluation.f1_score": [[30, 41], ["normalize_answer().split", "normalize_answer().split", "sum", "collections.Counter", "collections.Counter", "common.values", "len", "len", "squad_v1_official_evaluation.normalize_answer", "squad_v1_official_evaluation.normalize_answer"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer"], ["", "def", "f1_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "prediction_tokens", "=", "normalize_answer", "(", "prediction", ")", ".", "split", "(", ")", "\n", "ground_truth_tokens", "=", "normalize_answer", "(", "ground_truth", ")", ".", "split", "(", ")", "\n", "common", "=", "Counter", "(", "prediction_tokens", ")", "&", "Counter", "(", "ground_truth_tokens", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "prediction_tokens", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "ground_truth_tokens", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_official_evaluation.exact_match_score": [[43, 45], ["squad_v1_official_evaluation.normalize_answer", "squad_v1_official_evaluation.normalize_answer"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer"], ["", "def", "exact_match_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "return", "(", "normalize_answer", "(", "prediction", ")", "==", "normalize_answer", "(", "ground_truth", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_official_evaluation.metric_max_over_ground_truths": [[47, 53], ["max", "scores_for_ground_truths.append", "squad_v1_official_evaluation.exact_match_score", "squad_v1_official_evaluation.f1_score"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.exact_match_score", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.f1_score"], ["", "def", "metric_max_over_ground_truths", "(", "metric_fn", ",", "prediction", ",", "ground_truths", ")", ":", "\n", "    ", "scores_for_ground_truths", "=", "[", "]", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "score", "=", "metric_fn", "(", "prediction", ",", "ground_truth", ")", "\n", "scores_for_ground_truths", ".", "append", "(", "score", ")", "\n", "", "return", "max", "(", "scores_for_ground_truths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_v1_official_evaluation.evaluate": [[55, 77], ["list", "squad_v1_official_evaluation.metric_max_over_ground_truths", "squad_v1_official_evaluation.metric_max_over_ground_truths", "print", "map"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.metric_max_over_ground_truths"], ["", "def", "evaluate", "(", "dataset", ",", "predictions", ")", ":", "\n", "    ", "f1", "=", "exact_match", "=", "total", "=", "0", "\n", "for", "article", "in", "dataset", ":", "\n", "        ", "for", "paragraph", "in", "article", "[", "'paragraphs'", "]", ":", "\n", "            ", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                ", "total", "+=", "1", "\n", "if", "qa", "[", "'id'", "]", "not", "in", "predictions", ":", "\n", "                    ", "message", "=", "'Unanswered question '", "+", "qa", "[", "'id'", "]", "+", "' will receive score 0.'", "\n", "print", "(", "message", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "continue", "\n", "", "ground_truths", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "'text'", "]", ",", "qa", "[", "'answers'", "]", ")", ")", "\n", "prediction", "=", "predictions", "[", "qa", "[", "'id'", "]", "]", "\n", "exact_match", "+=", "metric_max_over_ground_truths", "(", "\n", "exact_match_score", ",", "prediction", ",", "ground_truths", ")", "\n", "f1", "+=", "metric_max_over_ground_truths", "(", "\n", "f1_score", ",", "prediction", ",", "ground_truths", ")", "\n", "\n", "", "", "", "exact_match", "=", "100.0", "*", "exact_match", "/", "total", "\n", "f1", "=", "100.0", "*", "f1", "/", "total", "\n", "\n", "return", "{", "'exact_match'", ":", "exact_match", ",", "'f1'", ":", "f1", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.training.trainer.AdamOptimizer.__init__": [[24, 31], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "learning_rate", "=", "0.001", ",", "decay_steps", "=", "100", ",", "decay_rate", "=", "0.999", ",", "\n", "staircase", "=", "True", ",", "max_grad_norm", "=", "None", ")", ":", "\n", "    ", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "max_grad_norm", "=", "max_grad_norm", "\n", "self", ".", "decay_rate", "=", "decay_rate", "\n", "self", ".", "staircase", "=", "staircase", "\n", "self", ".", "decay_steps", "=", "decay_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.training.trainer.AdamOptimizer.get_train_op": [[32, 51], ["tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.compute_gradients", "tensorflow.train.AdamOptimizer.apply_gradients", "tensorflow.train.get_global_step", "tensorflow.train.exponential_decay", "tensorflow.clip_by_global_norm", "zip"], "methods", ["None"], ["", "def", "get_train_op", "(", "self", ",", "loss", ",", "var_list", "=", "None", ")", ":", "\n", "    ", "lr", "=", "self", ".", "learning_rate", "\n", "if", "self", ".", "decay_rate", "is", "not", "None", ":", "\n", "      ", "gs", "=", "tf", ".", "train", ".", "get_global_step", "(", ")", "\n", "lr", "=", "tf", ".", "train", ".", "exponential_decay", "(", "\n", "global_step", "=", "gs", ",", "learning_rate", "=", "lr", ",", "\n", "staircase", "=", "self", ".", "staircase", ",", "decay_steps", "=", "self", ".", "decay_steps", ",", "\n", "decay_rate", "=", "self", ".", "decay_rate", ")", "\n", "\n", "", "opt", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "lr", ")", "\n", "\n", "grad_and_vars", "=", "opt", ".", "compute_gradients", "(", "loss", ",", "var_list", "=", "var_list", ")", "\n", "\n", "if", "self", ".", "max_grad_norm", "is", "not", "None", ":", "\n", "      ", "grads", "=", "[", "x", "[", "0", "]", "for", "x", "in", "grad_and_vars", "]", "\n", "grads", ",", "_", "=", "tf", ".", "clip_by_global_norm", "(", "grads", ",", "self", ".", "max_grad_norm", ")", "\n", "grad_and_vars", "=", "[", "(", "g", ",", "v", ")", "for", "g", ",", "(", "_", ",", "v", ")", "in", "zip", "(", "grads", ",", "grad_and_vars", ")", "]", "\n", "\n", "", "return", "opt", ".", "apply_gradients", "(", "grad_and_vars", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.training.trainer.Trainer.__init__": [[55, 80], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "\n", "self", ",", "train_batcher", ":", "QuantileBatcher", ",", "\n", "optimizer", ":", "AdamOptimizer", ",", "evaluator", ":", "Evaluator", ",", "\n", "eval_batch_size", ",", "\n", "num_epochs", ":", "int", ",", "epoch_size", ":", "int", ",", "\n", "tensorize_par_calls", "=", "1", ",", "learning_rate", "=", "0.001", ",", "log_period", ":", "int", "=", "100", ",", "\n", "prefetch", ":", "int", "=", "5", ",", "max_checkpoints_to_keep", ":", "int", "=", "1", ",", "\n", "loss_ema", ":", "Optional", "[", "float", "]", "=", "0.999", ",", "n_processes", ":", "int", "=", "1", ",", "\n", "progress_bar", "=", "True", ",", "seed", ":", "int", "=", "None", "\n", ")", ":", "\n", "    ", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "epoch_size", "=", "epoch_size", "\n", "self", ".", "evaluator", "=", "evaluator", "\n", "self", ".", "train_batcher", "=", "train_batcher", "\n", "self", ".", "eval_batch_size", "=", "eval_batch_size", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "max_checkpoints_to_keep", "=", "max_checkpoints_to_keep", "\n", "self", ".", "loss_ema", "=", "loss_ema", "\n", "self", ".", "num_epochs", "=", "num_epochs", "\n", "self", ".", "log_period", "=", "log_period", "\n", "self", ".", "n_processes", "=", "n_processes", "\n", "self", ".", "progress_bar", "=", "progress_bar", "\n", "self", ".", "prefetch", "=", "prefetch", "\n", "self", ".", "tensorize_par_calls", "=", "tensorize_par_calls", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.training.trainer.Trainer.train": [[81, 269], ["model.get_tokenizer", "logging.info", "data.load", "logging.info", "model.set_vocab", "model.tensorize_fn", "data.load.train.repeat", "dict.map", "trainer.Trainer.train_batcher.batch", "dict.prefetch", "eval_datasets.items", "tensorflow.get_variable", "tensorflow.assign_add", "tensorflow.add_to_collection", "logging.info", "dict.make_initializable_iterator", "dict.make_initializable_iterator.get_next", "tensorflow.get_collection", "tensorflow.add_n", "trainer.Trainer.optimizer.get_train_op", "tensorflow.summary.scalar", "tensorflow.summary.merge_all", "train_update_ops.append", "logging.info", "tensorflow.Session.run", "tensorflow.Session.run", "tensorflow.Session.run", "tensorflow.Session.run", "tensorflow.Session.run", "tensorflow.get_default_graph().finalize", "logging.info", "range", "tensorflow.summary.FileWriter.close", "debias.models.model_dir.ModelDir", "ds.prefetch.prefetch.map", "ds.prefetch.prefetch.padded_batch", "ds.prefetch.prefetch.prefetch", "logging.info", "tensorflow.Session", "tensorflow.set_random_seed", "tensorflow.ones", "tensorflow.name_scope", "model.apply", "len", "ValueError", "len", "ValueError", "tensorflow.train.ExponentialMovingAverage", "train_update_ops.append", "tensorflow.train.ExponentialMovingAverage.average", "tensorflow.control_dependencies", "trainer.Trainer.evaluator.setup", "tensorflow.train.Saver", "tensorflow.summary.FileWriter", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "tensorflow.tables_initializer", "socket.gethostname", "dict", "range", "logging.info", "os.path.exists", "tensorflow.constant_initializer", "tensorflow.train.ExponentialMovingAverage.apply", "tensorflow.get_collection", "tensorflow.control_dependencies", "tensorflow.identity", "open", "f.write", "open", "f.write", "open", "f.write", "open", "pickle.dump", "tensorflow.get_default_graph", "tqdm.tqdm.tqdm", "numpy.isnan", "numpy.isinf", "tensorflow.Session.run", "tqdm.tqdm.tqdm.close", "tensorflow.train.Saver.save", "trainer.Trainer.evaluator.run", "logging.info", "len", "input().strip", "shutil.rmtree", "ValueError", "tensorflow.add_n.shape.as_list", "os.path.join", "debias.utils.configured.config_to_json", "os.path.join", "debias.utils.configured.config_to_json", "open", "f.write", "datetime.datetime.datetime.now().strftime", "os.path.join", "debias.utils.configured.config_to_json", "os.path.join", "tensorflow.Session.run", "tensorflow.Session.run", "tensorflow.Session.run", "RuntimeError", "RuntimeError", "tqdm.tqdm.tqdm.update", "tqdm.tqdm.tqdm.set_description", "tensorflow.summary.FileWriter.add_summary", "os.path.join", "os.listdir", "os.path.join", "tensorflow.summary.FileWriter.add_summary", "input", "datetime.datetime.datetime.now", "results.items"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.get_tokenizer", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadLoader.load", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.set_vocab", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.tensorize_fn", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.dataset_utils.QuantileBatcher.batch", "home.repos.pwc.inspect_result.chrisc36_debias.training.trainer.AdamOptimizer.get_train_op", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.setup", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.config_to_json", "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.config_to_json", "home.repos.pwc.inspect_result.chrisc36_debias.utils.configured.config_to_json", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run"], ["", "def", "train", "(", "\n", "self", ",", "\n", "data", ":", "TrainingDataLoader", ",", "\n", "model", ":", "TextModel", ",", "\n", "out", ":", "str", ",", "\n", "notes", ":", "str", "=", "None", ",", "\n", "config", "=", "None", ",", "\n", "sess", "=", "None", "\n", ")", ":", "\n", "    ", "if", "out", "is", "not", "None", ":", "\n", "      ", "if", "exists", "(", "out", ")", "and", "len", "(", "listdir", "(", "out", ")", ")", ">", "0", ":", "\n", "        ", "if", "input", "(", "\"Files already exist in %s, override (y/n)?\"", "%", "out", ")", ".", "strip", "(", ")", "==", "\"y\"", ":", "\n", "          ", "rmtree", "(", "out", ")", "\n", "", "else", ":", "\n", "          ", "raise", "ValueError", "(", "\"Files already exist in %s\"", "%", "out", ")", "\n", "", "", "out", "=", "ModelDir", "(", "out", ")", "\n", "\n", "", "tokenizer", "=", "model", ".", "get_tokenizer", "(", ")", "\n", "logging", ".", "info", "(", "\"Loading data...\"", ")", "\n", "training_data", "=", "data", ".", "load", "(", "tokenizer", ",", "self", ".", "n_processes", ")", "\n", "\n", "logging", ".", "info", "(", "\"Setting up datasets...\"", ")", "\n", "model", ".", "set_vocab", "(", "training_data", ".", "voc", ")", "\n", "tensorize_fn", "=", "model", ".", "tensorize_fn", "(", ")", "\n", "\n", "train", "=", "training_data", ".", "train", ".", "repeat", "(", ")", "\n", "train", "=", "train", ".", "map", "(", "tensorize_fn", ",", "num_parallel_calls", "=", "self", ".", "tensorize_par_calls", ")", "\n", "train", "=", "self", ".", "train_batcher", ".", "batch", "(", "train", ")", "\n", "train", "=", "train", ".", "prefetch", "(", "self", ".", "prefetch", ")", "\n", "\n", "eval_datasets", "=", "training_data", ".", "eval_sets", "\n", "for", "k", ",", "ds", "in", "eval_datasets", ".", "items", "(", ")", ":", "\n", "      ", "ds", "=", "ds", ".", "map", "(", "tensorize_fn", ",", "num_parallel_calls", "=", "self", ".", "tensorize_par_calls", ")", "\n", "ds", "=", "ds", ".", "padded_batch", "(", "self", ".", "eval_batch_size", ",", "ds", ".", "output_shapes", ")", "\n", "ds", "=", "ds", ".", "prefetch", "(", "self", ".", "prefetch", ")", "\n", "eval_datasets", "[", "k", "]", "=", "ds", "\n", "\n", "", "if", "sess", "is", "None", ":", "\n", "      ", "logging", ".", "info", "(", "\"Initializing session...\"", ")", "\n", "sess", "=", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "\n", "", "if", "self", ".", "seed", "is", "not", "None", ":", "\n", "      ", "tf", ".", "set_random_seed", "(", "self", ".", "seed", ")", "\n", "\n", "", "global_step", "=", "tf", ".", "get_variable", "(", "'global_step'", ",", "shape", "=", "(", ")", ",", "dtype", "=", "'int32'", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0", ")", ",", "trainable", "=", "False", ")", "\n", "add_global_step", "=", "tf", ".", "assign_add", "(", "global_step", ",", "tf", ".", "ones", "(", "(", ")", ",", "global_step", ".", "dtype", ")", ")", "\n", "tf", ".", "add_to_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_STEP", ",", "global_step", ")", "\n", "\n", "logging", ".", "info", "(", "\"Building graph...\"", ")", "\n", "\n", "# **** train op ****", "\n", "train_it", "=", "train", ".", "make_initializable_iterator", "(", ")", "\n", "train_input_op", "=", "train_it", ".", "get_next", "(", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"train\"", ")", ":", "\n", "      ", "model", ".", "apply", "(", "True", ",", "train_input_op", ",", "train_input_op", "[", "\"label\"", "]", ")", "\n", "\n", "", "losses", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "LOSSES", ",", "\"train\"", ")", "\n", "if", "len", "(", "losses", ")", "==", "0", ":", "\n", "      ", "raise", "ValueError", "(", "\"Model did not add any losses\"", ")", "\n", "", "loss", "=", "tf", ".", "add_n", "(", "losses", ")", "\n", "if", "len", "(", "loss", ".", "shape", ")", "!=", "0", ":", "\n", "      ", "raise", "ValueError", "(", "\"Loss is not a scalar, has shape %s\"", "%", "loss", ".", "shape", ".", "as_list", "(", ")", ")", "\n", "\n", "", "train_op", "=", "self", ".", "optimizer", ".", "get_train_op", "(", "loss", ")", "\n", "\n", "train_update_ops", "=", "[", "]", "\n", "\n", "# EMA for the loss", "\n", "if", "self", ".", "loss_ema", "is", "not", "None", ":", "\n", "      ", "loss_ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "self", ".", "loss_ema", ",", "name", "=", "\"LossEMA\"", ",", "zero_debias", "=", "True", ")", "\n", "train_update_ops", ".", "append", "(", "loss_ema", ".", "apply", "(", "[", "loss", "]", ")", ")", "\n", "report_loss_op", "=", "loss_ema", ".", "average", "(", "loss", ")", "\n", "", "else", ":", "\n", "      ", "report_loss_op", "=", "loss", "\n", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"monitor/loss\"", ",", "report_loss_op", ")", "\n", "\n", "summary_op", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "\n", "# Finally, merge the training op and any other op into one op", "\n", "# that additionally computes the loss", "\n", "train_update_ops", ".", "append", "(", "train_op", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", ")", ":", "\n", "      ", "with", "tf", ".", "control_dependencies", "(", "train_update_ops", ")", ":", "\n", "          ", "train_op", "=", "tf", ".", "identity", "(", "loss", ")", "\n", "\n", "# **** build evaluation ops ****", "\n", "", "", "if", "self", ".", "evaluator", "is", "not", "None", ":", "\n", "      ", "self", ".", "evaluator", ".", "setup", "(", "eval_datasets", ",", "model", ")", "\n", "\n", "# Savers to record/log as we go", "\n", "", "if", "out", "is", "not", "None", ":", "\n", "      ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "self", ".", "max_checkpoints_to_keep", ",", "save_relative_paths", "=", "True", ")", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "out", ".", "log_dir", ")", "\n", "", "else", ":", "\n", "      ", "saver", "=", "None", "\n", "summary_writer", "=", "None", "\n", "\n", "", "logging", ".", "info", "(", "\"Initializing...\"", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "tables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "train_it", ".", "initializer", ")", "\n", "\n", "# Initialize the output dir", "\n", "# We do this last so if there are bugs in the setup nothing will have been written yet", "\n", "if", "out", "is", "not", "None", ":", "\n", "      ", "with", "open", "(", "join", "(", "out", ".", "dir", ",", "\"model.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "configured", ".", "config_to_json", "(", "model", ",", "indent", "=", "2", ")", ")", "\n", "\n", "", "with", "open", "(", "join", "(", "out", ".", "dir", ",", "\"data.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "configured", ".", "config_to_json", "(", "data", ",", "indent", "=", "2", ")", ")", "\n", "\n", "", "if", "notes", "is", "not", "None", ":", "\n", "        ", "with", "open", "(", "join", "(", "out", ".", "dir", ",", "\"notes.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "          ", "f", ".", "write", "(", "notes", ")", "\n", "\n", "", "", "hostname", "=", "socket", ".", "gethostname", "(", ")", "\n", "train", "=", "dict", "(", "\n", "trainer", "=", "self", ",", "\n", "evaluator", "=", "self", ".", "evaluator", ",", "\n", "date", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%m%d-%H%M%S\"", ")", ",", "\n", "host", "=", "hostname", "\n", ")", "\n", "with", "open", "(", "join", "(", "out", ".", "dir", ",", "\"trainer.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "configured", ".", "config_to_json", "(", "train", ",", "indent", "=", "2", ")", ")", "\n", "\n", "# Model also saved via pickle since I didn't want to deal with", "\n", "# doing the json->python conversion", "\n", "", "with", "open", "(", "join", "(", "out", ".", "dir", ",", "\"model.pkl\"", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "model", ",", "f", ")", "\n", "\n", "", "", "on_step", "=", "sess", ".", "run", "(", "global_step", ")", "\n", "\n", "# Make sure a bug doesn't cause us to add more ops later", "\n", "tf", ".", "get_default_graph", "(", ")", ".", "finalize", "(", ")", "\n", "\n", "logging", ".", "info", "(", "\"Start training!\"", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "1", ",", "self", ".", "num_epochs", "+", "1", ")", ":", "\n", "      ", "if", "self", ".", "progress_bar", ":", "\n", "        ", "pbar", "=", "tqdm", "(", "total", "=", "self", ".", "epoch_size", ",", "desc", "=", "\"ep=%d\"", "%", "epoch", ",", "ncols", "=", "100", ")", "\n", "", "else", ":", "\n", "        ", "pbar", "=", "None", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "epoch_size", ")", ":", "\n", "        ", "on_step", "=", "sess", ".", "run", "(", "global_step", ")", "+", "1", "\n", "get_summary", "=", "on_step", "%", "self", ".", "log_period", "==", "0", "\n", "\n", "if", "get_summary", ":", "\n", "          ", "summary", ",", "batch_loss", ",", "report_loss", "=", "sess", ".", "run", "(", "[", "summary_op", ",", "train_op", ",", "report_loss_op", "]", ")", "\n", "", "else", ":", "\n", "          ", "summary", "=", "None", "\n", "batch_loss", ",", "report_loss", "=", "sess", ".", "run", "(", "[", "train_op", ",", "report_loss_op", "]", ")", "\n", "\n", "", "if", "np", ".", "isnan", "(", "batch_loss", ")", ":", "\n", "          ", "raise", "RuntimeError", "(", "\"NaN loss!\"", ")", "\n", "", "if", "np", ".", "isinf", "(", "batch_loss", ")", ":", "\n", "          ", "raise", "RuntimeError", "(", "\"Infinity loss!\"", ")", "\n", "\n", "", "sess", ".", "run", "(", "add_global_step", ")", "\n", "\n", "if", "pbar", "is", "not", "None", ":", "\n", "          ", "pbar", ".", "update", "(", "1", ")", "\n", "descript", "=", "\"ep=%d loss=%.4f\"", "%", "(", "epoch", ",", "report_loss", ")", "\n", "pbar", ".", "set_description", "(", "descript", ",", "refresh", "=", "False", ")", "\n", "\n", "", "if", "summary", "is", "not", "None", "and", "out", "is", "not", "None", ":", "\n", "          ", "summary_writer", ".", "add_summary", "(", "summary", ",", "on_step", ")", "\n", "\n", "# Finished the training for this epoch, now save/evaluate", "\n", "", "", "if", "pbar", "is", "not", "None", ":", "\n", "        ", "pbar", ".", "close", "(", ")", "\n", "\n", "", "if", "out", "is", "not", "None", ":", "\n", "        ", "saver", ".", "save", "(", "sess", ",", "join", "(", "out", ".", "save_dir", ",", "\"checkpoint\"", ")", ",", "global_step", "=", "global_step", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Running evaluation %d...\"", "%", "epoch", ")", "\n", "for", "eval_name", "in", "eval_datasets", ":", "\n", "        ", "results", ",", "summaries", "=", "self", ".", "evaluator", ".", "run", "(", "sess", ",", "eval_name", ")", "\n", "logging", ".", "info", "(", "\"%s: %s\"", ",", "eval_name", ",", "\" \"", ".", "join", "(", "\"%s=%.4f\"", "%", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "results", ".", "items", "(", ")", ")", ")", "\n", "if", "summary_writer", "is", "not", "None", ":", "\n", "          ", "for", "sum", "in", "summaries", ":", "\n", "            ", "summary_writer", ".", "add_summary", "(", "sum", ",", "on_step", ")", "\n", "\n", "", "", "", "", "summary_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.__init__": [[16, 28], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mode", ",", "progress_bar", "=", "True", ")", ":", "\n", "    ", "self", ".", "progress_bar", "=", "progress_bar", "\n", "self", ".", "mode", "=", "mode", "\n", "\n", "self", ".", "eval_dataset_iterators", "=", "None", "\n", "self", ".", "eval_results", "=", "None", "\n", "self", ".", "eval_update_ops", "=", "None", "\n", "self", ".", "eval_summaries", "=", "None", "\n", "self", ".", "init_eval_vars", "=", "None", "\n", "self", ".", "eval_batch_size", "=", "None", "\n", "self", ".", "eval_max_sizes", "=", "None", "\n", "self", ".", "task_name", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.setup": [[29, 74], ["tensorflow.variables_initializer", "tensorflow.name_scope", "tensorflow.variable_scope", "tensorflow.data.Iterator.from_structure.make_initializer", "tensorflow.local_variables", "tensorflow.shape", "tensorflow.variable_scope", "tensorflow.data.Iterator.from_structure", "tensorflow.data.Iterator.from_structure.get_next", "model.apply", "tensorflow.nn.log_softmax", "tensorflow.metrics.accuracy", "eval_datasets.items", "tensorflow.summary.scalar", "tensorflow.get_variable_scope", "list", "tensorflow.argmax", "tensorflow.nn.log_softmax", "debias.squad_eval.squad_eval.eval_squad_op", "tensorflow.metrics.mean", "tensorflow.metrics.mean", "evaluator.Evaluator.eval_results.items", "eval_datasets.values", "tensorflow.nn.log_softmax", "debias.squad_eval.triviaqa_eval.eval_triviaqa_op", "tensorflow.metrics.mean", "tensorflow.metrics.mean", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.squad_eval.eval_squad_op", "home.repos.pwc.inspect_result.chrisc36_debias.squad_eval.triviaqa_eval.eval_triviaqa_op"], ["", "def", "setup", "(", "self", ",", "eval_datasets", ":", "Dict", "[", "str", ",", "tf", ".", "data", ".", "Dataset", "]", ",", "model", ":", "TextModel", ",", "reuse", "=", "True", ")", ":", "\n", "    ", "\"\"\"Build ops needed to evaluate on each (already batched) dataset in `eval_datasets`\"\"\"", "\n", "\n", "name", "=", "\"eval\"", "\n", "with", "tf", ".", "name_scope", "(", "name", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "example", "=", "list", "(", "eval_datasets", ".", "values", "(", ")", ")", "[", "0", "]", "\n", "eval_it", "=", "tf", ".", "data", ".", "Iterator", ".", "from_structure", "(", "example", ".", "output_types", ",", "example", ".", "output_shapes", ")", "\n", "eval_op", "=", "eval_it", ".", "get_next", "(", ")", "\n", "eval_pred", "=", "model", ".", "apply", "(", "False", ",", "eval_op", ",", "eval_op", "[", "\"label\"", "]", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "      ", "if", "self", ".", "mode", "==", "\"clf\"", ":", "\n", "        ", "eval_pred", "=", "tf", ".", "nn", ".", "log_softmax", "(", "eval_pred", ")", "\n", "op", ",", "up", "=", "tf", ".", "metrics", ".", "accuracy", "(", "eval_op", "[", "\"label\"", "]", ",", "tf", ".", "argmax", "(", "eval_pred", ",", "1", ")", ")", "\n", "self", ".", "eval_update_ops", "=", "[", "up", "]", "\n", "self", ".", "eval_results", "=", "{", "\"accuracy\"", ":", "op", "}", "\n", "", "elif", "self", ".", "mode", "==", "\"squad\"", ":", "\n", "        ", "label", "=", "eval_op", "[", "\"label\"", "]", "\n", "eval_pred", "=", "tf", ".", "nn", ".", "log_softmax", "(", "eval_pred", ",", "1", ")", "\n", "scores", "=", "eval_squad_op", "(", "eval_pred", ",", "label", "[", "\"token_offsets\"", "]", ",", "label", "[", "\"passage_str\"", "]", ",", "label", "[", "\"answers\"", "]", ",", "17", ")", "\n", "em_op", ",", "em_up", "=", "tf", ".", "metrics", ".", "mean", "(", "scores", "[", ":", ",", "0", "]", ")", "\n", "f1_op", ",", "f1_up", "=", "tf", ".", "metrics", ".", "mean", "(", "scores", "[", ":", ",", "1", "]", ")", "\n", "self", ".", "eval_update_ops", "=", "[", "em_up", ",", "f1_up", "]", "\n", "self", ".", "eval_results", "=", "{", "\"em\"", ":", "em_op", ",", "\"f1\"", ":", "f1_op", "}", "\n", "", "elif", "self", ".", "mode", "==", "\"triviaqa\"", ":", "\n", "        ", "label", "=", "eval_op", "[", "\"label\"", "]", "\n", "eval_pred", "=", "tf", ".", "nn", ".", "log_softmax", "(", "eval_pred", ",", "1", ")", "\n", "scores", "=", "eval_triviaqa_op", "(", "eval_pred", ",", "eval_op", "[", "\"premise_tok\"", "]", ",", "label", "[", "\"answers\"", "]", ",", "8", ")", "\n", "em_op", ",", "em_up", "=", "tf", ".", "metrics", ".", "mean", "(", "scores", "[", ":", ",", "0", "]", ")", "\n", "f1_op", ",", "f1_up", "=", "tf", ".", "metrics", ".", "mean", "(", "scores", "[", ":", ",", "1", "]", ")", "\n", "self", ".", "eval_update_ops", "=", "[", "em_up", ",", "f1_up", "]", "\n", "self", ".", "eval_results", "=", "{", "\"em\"", ":", "em_op", ",", "\"f1\"", ":", "f1_op", "}", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "self", ".", "mode", ")", "\n", "\n", "", "", "self", ".", "eval_dataset_iterators", "=", "{", "k", ":", "eval_it", ".", "make_initializer", "(", "d", ")", "for", "k", ",", "d", "in", "eval_datasets", ".", "items", "(", ")", "}", "\n", "self", ".", "eval_summaries", "=", "{", "}", "\n", "for", "dataset_name", "in", "eval_datasets", ":", "\n", "      ", "self", ".", "eval_summaries", "[", "dataset_name", "]", "=", "[", "tf", ".", "summary", ".", "scalar", "(", "dataset_name", "+", "\"/\"", "+", "k", ",", "v", ")", "for", "\n", "k", ",", "v", "in", "self", ".", "eval_results", ".", "items", "(", ")", "]", "\n", "\n", "", "self", ".", "init_eval_vars", "=", "tf", ".", "variables_initializer", "(", "tf", ".", "local_variables", "(", "name", ")", ")", "\n", "self", ".", "eval_batch_size", "=", "tf", ".", "shape", "(", "eval_op", "[", "PREMISE_LEN_KEY", "]", ")", "[", "0", "]", "\n", "self", ".", "eval_max_sizes", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run": [[75, 114], ["sess.run", "evaluator.Evaluator.eval_max_sizes.get", "max", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm.close", "evaluator.Evaluator.eval_max_sizes.get", "sess.run", "sess.run", "sess.run", "tqdm.tqdm.tqdm.update", "tqdm.tqdm.tqdm.update"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run", "home.repos.pwc.inspect_result.chrisc36_debias.training.evaluator.Evaluator.run"], ["", "def", "run", "(", "self", ",", "sess", ":", "tf", ".", "Session", ",", "eval_name", ":", "str", ",", "return_summaries", "=", "True", ")", ":", "\n", "    ", "\"\"\"Run evaluation on `eval_name`, which should refer to a dataset passed into `self.setup`\"\"\"", "\n", "\n", "sess", ".", "run", "(", "[", "self", ".", "eval_dataset_iterators", "[", "eval_name", "]", ",", "self", ".", "init_eval_vars", "]", ")", "\n", "\n", "estimate_steps", "=", "self", ".", "eval_max_sizes", ".", "get", "(", "eval_name", ")", "\n", "max_steps", "=", "None", "\n", "\n", "if", "self", ".", "progress_bar", ":", "\n", "      ", "pbar", "=", "tqdm", "(", "desc", "=", "eval_name", ",", "ncols", "=", "80", ",", "total", "=", "estimate_steps", ")", "\n", "", "else", ":", "\n", "      ", "pbar", "=", "None", "\n", "", "total_size", "=", "0", "\n", "\n", "up", "=", "self", ".", "eval_update_ops", "\n", "r", "=", "self", ".", "eval_results", "\n", "\n", "while", "True", ":", "\n", "      ", "try", ":", "\n", "        ", "bs", ",", "_", "=", "sess", ".", "run", "(", "[", "self", ".", "eval_batch_size", ",", "up", "]", ")", "\n", "total_size", "+=", "bs", "\n", "if", "max_steps", "is", "not", "None", "and", "total_size", ">=", "max_steps", ":", "\n", "          ", "total_size", "-=", "bs", "\n", "if", "pbar", "is", "not", "None", ":", "\n", "            ", "pbar", ".", "update", "(", "max_steps", "-", "total_size", ")", "\n", "", "break", "\n", "", "else", ":", "\n", "          ", "if", "pbar", "is", "not", "None", ":", "\n", "            ", "pbar", ".", "update", "(", "bs", ")", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "break", "\n", "", "", "if", "pbar", "is", "not", "None", ":", "\n", "      ", "pbar", ".", "close", "(", ")", "\n", "", "self", ".", "eval_max_sizes", "[", "eval_name", "]", "=", "max", "(", "total_size", ",", "self", ".", "eval_max_sizes", ".", "get", "(", "eval_name", ",", "0", ")", ")", "\n", "\n", "if", "return_summaries", ":", "\n", "      ", "return", "sess", ".", "run", "(", "[", "r", ",", "self", ".", "eval_summaries", "[", "eval_name", "]", "]", ")", "\n", "", "else", ":", "\n", "      ", "return", "sess", ".", "run", "(", "r", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.word_and_char_encoder.WordAndCharEncoder.__init__": [[14, 43], ["ValueError", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "word_vectors", ",", "first_n", "=", "None", ",", "char_embed_dim", "=", "None", ",", "\n", "character_mapper", "=", "None", ",", "character_pooler", "=", "None", ",", "\n", "lower_fallback", "=", "False", ",", "\n", "embed_cpu", "=", "True", ",", "word_pooling", "=", "True", ",", "\n", "word_mapper", "=", "None", ",", "lowercase", "=", "False", ",", "word_length", "=", "30", ",", "\n", "include_bounds_embeddings", ":", "bool", "=", "False", ")", ":", "\n", "    ", "if", "character_mapper", "is", "not", "None", "and", "character_pooler", "is", "None", ":", "\n", "      ", "raise", "ValueError", "(", ")", "\n", "", "if", "character_pooler", "is", "not", "None", "and", "character_mapper", "is", "None", ":", "\n", "      ", "raise", "ValueError", "(", ")", "\n", "\n", "", "self", ".", "include_bounds_embeddings", "=", "include_bounds_embeddings", "\n", "self", ".", "lower_fallback", "=", "lower_fallback", "\n", "self", ".", "word_pooling", "=", "word_pooling", "\n", "self", ".", "character_mapper", "=", "character_mapper", "\n", "self", ".", "embed_cpu", "=", "embed_cpu", "\n", "self", ".", "char_embed_dim", "=", "char_embed_dim", "\n", "self", ".", "lowercase", "=", "lowercase", "\n", "self", ".", "character_pooler", "=", "character_pooler", "\n", "self", ".", "word_mapper", "=", "word_mapper", "\n", "self", ".", "word_vectors", "=", "word_vectors", "\n", "self", ".", "first_n", "=", "first_n", "\n", "self", ".", "word_length", "=", "word_length", "\n", "\n", "self", ".", "_input_vocab", "=", "None", "\n", "self", ".", "_cached_char_ids", "=", "None", "\n", "\n", "self", ".", "_word_vec_vocab", "=", "None", "\n", "self", ".", "_embeddings", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.word_and_char_encoder.WordAndCharEncoder.set_vocab": [[44, 54], ["list", "list", "set", "x.lower"], "methods", ["None"], ["", "def", "set_vocab", "(", "self", ",", "vocab", ")", ":", "\n", "    ", "self", ".", "_cached_char_ids", "=", "None", "\n", "self", ".", "_embeddings", "=", "None", "\n", "self", ".", "_word_vec_vocab", "=", "None", "\n", "if", "vocab", "is", "None", "or", "not", "self", ".", "word_pooling", ":", "\n", "      ", "self", ".", "_input_vocab", "=", "None", "\n", "", "elif", "self", ".", "lowercase", ":", "\n", "      ", "self", ".", "_input_vocab", "=", "list", "(", "set", "(", "x", ".", "lower", "(", ")", "for", "x", "in", "vocab", ")", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "_input_vocab", "=", "list", "(", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.word_and_char_encoder.WordAndCharEncoder.get_vocab": [[55, 57], ["None"], "methods", ["None"], ["", "", "def", "get_vocab", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_input_vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.word_and_char_encoder.WordAndCharEncoder.use_word_vecs": [[58, 61], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "use_word_vecs", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "word_vectors", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.word_and_char_encoder.WordAndCharEncoder.use_chars": [[62, 65], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "use_chars", "(", "self", ")", ":", "\n", "    ", "return", "(", "self", ".", "char_embed_dim", "is", "not", "None", "and", "self", ".", "character_pooler", "is", "not", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.word_and_char_encoder.WordAndCharEncoder.tensorize_fn": [[66, 154], ["debias.modules.char_encoder.words_to_char_ids_py", "len", "tensorflow.contrib.lookup.index_table_from_tensor", "tuple", "set", "set.update", "set.update", "debias.utils.load_word_vectors.load_word_vectors", "debias.utils.load_word_vectors.load_word_vectors", "logging.info", "numpy.stack", "numpy.zeros", "enumerate", "debias.utils.ops.lowercase_op", "tensorflow.to_int32", "out.append", "debias.modules.char_encoder.words_to_char_ids", "out.append", "w_to_ix.get", "w_to_ix.get", "tensorflow.contrib.lookup.index_table_from_tensor.lookup", "tensorflow.less", "x.encode", "x.lower", "enumerate", "w[].isupper", "w_to_ix.get", "w_to_ix.get", "words.append", "vecs.append", "enumerate", "tensorflow.control_dependencies", "tensorflow.identity", "x[].lower", "w.lower", "len", "len", "numpy.zeros", "len", "w[].lower", "len", "len", "tensorflow.assert_greater_equal", "tensorflow.reduce_min", "tensorflow.boolean_mask"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.modules.char_encoder.words_to_char_ids_py", "home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors.load_word_vectors", "home.repos.pwc.inspect_result.chrisc36_debias.utils.load_word_vectors.load_word_vectors", "home.repos.pwc.inspect_result.chrisc36_debias.modules.char_encoder.words_to_char_ids"], ["", "def", "tensorize_fn", "(", "self", ")", ":", "\n", "    ", "if", "(", "self", ".", "_input_vocab", "is", "not", "None", "and", "\n", "self", ".", "_cached_char_ids", "is", "None", "and", "self", ".", "use_chars", ")", ":", "\n", "# Pre-compute the charids for all words in our vocab", "\n", "      ", "self", ".", "_cached_char_ids", "=", "char_encoder", ".", "words_to_char_ids_py", "(", "\n", "[", "x", ".", "encode", "(", "\"utf-8\"", ")", "for", "x", "in", "self", ".", "_input_vocab", "]", "+", "[", "\"\"", "]", ",", "\n", "self", ".", "word_length", "\n", ")", "\n", "\n", "", "if", "self", ".", "_embeddings", "is", "None", "and", "self", ".", "use_word_vecs", ":", "\n", "# Load and cache the words vectors", "\n", "      ", "if", "self", ".", "lower_fallback", ":", "\n", "        ", "v", "=", "set", "(", "self", ".", "_input_vocab", ")", "\n", "v", ".", "update", "(", "x", ".", "lower", "(", ")", "for", "x", "in", "self", ".", "_input_vocab", ")", "\n", "v", ".", "update", "(", "x", "[", "0", "]", ".", "lower", "(", ")", "+", "x", "[", "1", ":", "]", "for", "x", "in", "self", ".", "_input_vocab", ")", "\n", "words_l", ",", "vecs_l", "=", "load_word_vectors", ".", "load_word_vectors", "(", "self", ".", "word_vectors", ",", "v", ",", "self", ".", "first_n", ")", "\n", "w_to_ix", "=", "{", "w", ":", "i", "for", "i", ",", "w", "in", "enumerate", "(", "words_l", ")", "}", "\n", "\n", "words", "=", "[", "]", "\n", "vecs", "=", "[", "]", "\n", "for", "w", "in", "self", ".", "_input_vocab", ":", "\n", "          ", "ix", "=", "w_to_ix", ".", "get", "(", "w", ")", "\n", "if", "ix", "is", "None", "and", "w", "[", "0", "]", ".", "isupper", "(", ")", ":", "\n", "            ", "ix", "=", "w_to_ix", ".", "get", "(", "w", "[", "0", "]", ".", "lower", "(", ")", "+", "w", "[", "1", ":", "]", ")", "\n", "", "if", "ix", "is", "None", ":", "\n", "            ", "ix", "=", "w_to_ix", ".", "get", "(", "w", ".", "lower", "(", ")", ")", "\n", "", "if", "ix", "is", "not", "None", ":", "\n", "            ", "words", ".", "append", "(", "w", ")", "\n", "vecs", ".", "append", "(", "vecs_l", "[", "ix", "]", ")", "\n", "\n", "", "", "", "else", ":", "\n", "        ", "words", ",", "vecs", "=", "load_word_vectors", ".", "load_word_vectors", "(", "self", ".", "word_vectors", ",", "self", ".", "_input_vocab", ",", "self", ".", "first_n", ")", "\n", "\n", "", "if", "self", ".", "_input_vocab", "is", "not", "None", ":", "\n", "        ", "logging", ".", "info", "(", "\"Have vectors for %d/%d (%.4f) words\"", "%", "(", "\n", "len", "(", "words", ")", ",", "len", "(", "self", ".", "_input_vocab", ")", ",", "len", "(", "words", ")", "/", "len", "(", "self", ".", "_input_vocab", ")", ")", ")", "\n", "\n", "", "dim", "=", "len", "(", "vecs", "[", "0", "]", ")", "\n", "\n", "if", "self", ".", "_input_vocab", "is", "None", ":", "\n", "        ", "self", ".", "_embeddings", "=", "np", ".", "stack", "(", "vecs", "+", "[", "np", ".", "zeros", "(", "dim", ",", "dtype", "=", "np", ".", "float32", ")", "]", ")", "\n", "self", ".", "_word_vec_vocab", "=", "words", "\n", "", "else", ":", "\n", "        ", "w_to_ix", "=", "{", "w", ":", "i", "for", "i", ",", "w", "in", "enumerate", "(", "words", ")", "}", "\n", "self", ".", "_embeddings", "=", "np", ".", "zeros", "(", "(", "len", "(", "self", ".", "_input_vocab", ")", "+", "1", ",", "dim", ")", ",", "np", ".", "float32", ")", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "self", ".", "_input_vocab", ")", ":", "\n", "          ", "ix", "=", "w_to_ix", ".", "get", "(", "word", ")", "\n", "if", "ix", "is", "not", "None", ":", "\n", "            ", "self", ".", "_embeddings", "[", "i", "]", "=", "vecs", "[", "ix", "]", "\n", "", "", "self", ".", "_word_vec_vocab", "=", "self", ".", "_input_vocab", "+", "[", "\"\"", "]", "\n", "\n", "", "", "elif", "self", ".", "_input_vocab", "is", "not", "None", ":", "\n", "      ", "self", ".", "_word_vec_vocab", "=", "self", ".", "_input_vocab", "\n", "\n", "", "if", "self", ".", "_word_vec_vocab", "is", "not", "None", ":", "\n", "      ", "tbl", "=", "tf", ".", "contrib", ".", "lookup", ".", "index_table_from_tensor", "(", "\n", "mapping", "=", "self", ".", "_word_vec_vocab", ",", "\n", "num_oov_buckets", "=", "1", "if", "self", ".", "_input_vocab", "is", "None", "else", "0", "\n", ")", "\n", "", "else", ":", "\n", "      ", "tbl", "=", "None", "\n", "\n", "", "def", "fn", "(", "string_tensor", ")", ":", "\n", "      ", "\"\"\"Builds the output tensor dictionary.\"\"\"", "\n", "if", "self", ".", "lowercase", ":", "\n", "        ", "string_tensor", "=", "ops", ".", "lowercase_op", "(", "string_tensor", ")", "\n", "\n", "", "out", "=", "[", "]", "\n", "if", "tbl", "is", "not", "None", ":", "\n", "        ", "wids", "=", "tf", ".", "to_int32", "(", "tbl", ".", "lookup", "(", "string_tensor", ")", ")", "\n", "\n", "if", "self", ".", "_input_vocab", "is", "not", "None", ":", "\n", "          ", "errors", "=", "tf", ".", "less", "(", "wids", ",", "0", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "tf", ".", "assert_greater_equal", "(", "\n", "tf", ".", "reduce_min", "(", "wids", ")", ",", "0", ",", "\n", "data", "=", "[", "tf", ".", "boolean_mask", "(", "string_tensor", ",", "errors", ")", "]", ",", "\n", "summarize", "=", "100", ",", "message", "=", "\"Words missing from vocab\"", "\n", ")", "]", ")", ":", "\n", "            ", "wids", "=", "tf", ".", "identity", "(", "wids", ")", "\n", "", "", "out", ".", "append", "(", "wids", ")", "\n", "\n", "", "if", "self", ".", "use_chars", "and", "self", ".", "_input_vocab", "is", "None", ":", "\n", "        ", "cids", "=", "char_encoder", ".", "words_to_char_ids", "(", "string_tensor", ",", "self", ".", "word_length", ")", "\n", "out", ".", "append", "(", "cids", ")", "\n", "\n", "", "return", "tuple", "(", "out", ")", "\n", "\n", "", "return", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.word_and_char_encoder.WordAndCharEncoder.embed_words": [[155, 164], ["w_embeds.append", "tensorflow.get_variable_scope().reuse_variables", "word_and_char_encoder.WordAndCharEncoder._embed_words_from_ids", "word_and_char_encoder.WordAndCharEncoder._embed_words_from_features", "tensorflow.get_variable_scope"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.modules.word_and_char_encoder.WordAndCharEncoder._embed_words_from_ids", "home.repos.pwc.inspect_result.chrisc36_debias.modules.word_and_char_encoder.WordAndCharEncoder._embed_words_from_features"], ["", "def", "embed_words", "(", "self", ",", "is_train", ",", "tensors", ")", ":", "\n", "    ", "if", "self", ".", "_input_vocab", "is", "None", ":", "\n", "      ", "w_embeds", "=", "[", "]", "\n", "for", "features", "in", "tensors", ":", "\n", "        ", "w_embeds", ".", "append", "(", "self", ".", "_embed_words_from_features", "(", "is_train", ",", "features", ")", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "", "return", "w_embeds", "\n", "", "else", ":", "\n", "      ", "return", "self", ".", "_embed_words_from_ids", "(", "is_train", ",", "tensors", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.word_and_char_encoder.WordAndCharEncoder.get_word_ids": [[165, 170], ["None"], "methods", ["None"], ["", "", "def", "get_word_ids", "(", "self", ",", "tensors", ")", ":", "\n", "    ", "if", "self", ".", "_input_vocab", "is", "None", ":", "\n", "      ", "return", "None", "\n", "", "else", ":", "\n", "      ", "return", "tensors", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.word_and_char_encoder.WordAndCharEncoder.embed_words_with_ids": [[171, 173], ["word_and_char_encoder.WordAndCharEncoder._embed_words_from_ids"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.modules.word_and_char_encoder.WordAndCharEncoder._embed_words_from_ids"], ["", "", "def", "embed_words_with_ids", "(", "self", ",", "is_train", ",", "tensors", ",", "embed_words_with_ids", "=", "None", ")", ":", "\n", "    ", "return", "self", ".", "_embed_words_from_ids", "(", "is_train", ",", "tensors", ",", "embed_words_with_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.word_and_char_encoder.WordAndCharEncoder._embed_words_from_features": [[174, 199], ["tensorflow.concat", "debias.modules.char_encoder.embed_ids", "out.append", "debias.utils.ops.as_initialized_variable", "tensorflow.nn.embedding_lookup", "tensorflow.variable_scope", "word_and_char_encoder.WordAndCharEncoder.character_mapper.apply", "tensorflow.variable_scope", "word_and_char_encoder.WordAndCharEncoder.character_pooler.apply", "tensorflow.device", "debias.utils.ops.as_initialized_variable", "tensorflow.nn.embedding_lookup"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.modules.char_encoder.embed_ids", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.as_initialized_variable", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.as_initialized_variable"], ["", "def", "_embed_words_from_features", "(", "self", ",", "is_train", ",", "tensors", ")", ":", "\n", "    ", "out", "=", "[", "]", "\n", "if", "self", ".", "use_word_vecs", ":", "\n", "      ", "if", "self", ".", "embed_cpu", ":", "\n", "        ", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "          ", "embeding_var", "=", "ops", ".", "as_initialized_variable", "(", "self", ".", "_embeddings", ",", "\"embeddings\"", ")", "\n", "w_embed", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "embeding_var", ",", "tensors", "[", "0", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "embeding_var", "=", "ops", ".", "as_initialized_variable", "(", "self", ".", "_embeddings", ",", "\"embeddings\"", ")", "\n", "w_embed", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "embeding_var", ",", "tensors", "[", "0", "]", ")", "\n", "", "out", "=", "[", "w_embed", "]", "\n", "tensors", "=", "tensors", "[", "1", ":", "]", "\n", "\n", "", "if", "self", ".", "use_chars", ":", "\n", "      ", "cids", "=", "tensors", "[", "0", "]", "\n", "char_emb", "=", "char_encoder", ".", "embed_ids", "(", "cids", ",", "self", ".", "char_embed_dim", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"char-map\"", ")", ":", "\n", "        ", "char_emb", "=", "self", ".", "character_mapper", ".", "apply", "(", "is_train", ",", "char_emb", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"char-pool\"", ")", ":", "\n", "        ", "char_emb", "=", "self", ".", "character_pooler", ".", "apply", "(", "is_train", ",", "char_emb", ")", "\n", "", "out", ".", "append", "(", "char_emb", ")", "\n", "\n", "", "return", "tf", ".", "concat", "(", "out", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.word_and_char_encoder.WordAndCharEncoder._embed_words_from_ids": [[200, 266], ["tensorflow.concat", "tensorflow.unique", "tensorflow.concat", "tensorflow.gather", "tensorflow.split", "tensorflow.split", "NotImplementedError", "debias.utils.ops.get_shape_tuple", "debias.utils.ops.flatten", "debias.utils.ops.get_shape_tuple", "tensorflow.concat.append", "debias.utils.ops.flatten", "debias.modules.char_encoder.embed_ids", "word_and_char_encoder.WordAndCharEncoder.append", "word_and_char_encoder.WordAndCharEncoder.shape.as_list", "tensorflow.reshape", "tensorflow.reshape", "debias.utils.ops.as_initialized_variable", "tensorflow.device", "tensorflow.gather", "tensorflow.variable_scope", "word_and_char_encoder.WordAndCharEncoder.character_mapper.apply", "tensorflow.variable_scope", "word_and_char_encoder.WordAndCharEncoder.character_pooler.apply", "tensorflow.variable_scope", "word_and_char_encoder.WordAndCharEncoder.word_mapper.apply", "zip", "zip", "tensorflow.device", "debias.utils.ops.as_initialized_variable", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "debias.utils.ops.get_shape_tuple"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_shape_tuple", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.flatten", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_shape_tuple", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.flatten", "home.repos.pwc.inspect_result.chrisc36_debias.modules.char_encoder.embed_ids", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.as_initialized_variable", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.as_initialized_variable", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_shape_tuple"], ["", "def", "_embed_words_from_ids", "(", "self", ",", "is_train", ",", "tensors", ",", "additional_wids", "=", "None", ")", ":", "\n", "    ", "if", "self", ".", "_input_vocab", "is", "None", ":", "\n", "      ", "raise", "NotImplementedError", "(", ")", "\n", "", "wids", "=", "[", "x", "[", "0", "]", "for", "x", "in", "tensors", "]", "\n", "\n", "shapes", "=", "[", "ops", ".", "get_shape_tuple", "(", "x", ")", "for", "x", "in", "wids", "]", "\n", "unique_wids", "=", "[", "ops", ".", "flatten", "(", "x", ")", "for", "x", "in", "wids", "]", "\n", "sizes", "=", "[", "ops", ".", "get_shape_tuple", "(", "x", ",", "0", ")", "for", "x", "in", "unique_wids", "]", "\n", "\n", "if", "additional_wids", "is", "not", "None", ":", "\n", "      ", "unique_wids", ".", "append", "(", "additional_wids", ")", "\n", "\n", "", "unique_wids", "=", "tf", ".", "concat", "(", "unique_wids", ",", "0", ")", "\n", "wixs", ",", "w_mapping", "=", "tf", ".", "unique", "(", "ops", ".", "flatten", "(", "unique_wids", ")", ",", "tf", ".", "int32", ")", "\n", "\n", "if", "additional_wids", "is", "not", "None", ":", "\n", "      ", "w_mapping", "=", "w_mapping", "[", ":", "-", "ops", ".", "get_shape_tuple", "(", "additional_wids", ")", "[", "0", "]", "]", "\n", "\n", "", "if", "self", ".", "use_word_vecs", ":", "\n", "      ", "if", "self", ".", "embed_cpu", ":", "\n", "        ", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "          ", "embeding_var", "=", "ops", ".", "as_initialized_variable", "(", "self", ".", "_embeddings", ",", "\"embeddings\"", ")", "\n", "w_embed", "=", "[", "tf", ".", "nn", ".", "embedding_lookup", "(", "embeding_var", ",", "wixs", ")", "]", "\n", "", "", "else", ":", "\n", "        ", "embeding_var", "=", "ops", ".", "as_initialized_variable", "(", "self", ".", "_embeddings", ",", "\"embeddings\"", ")", "\n", "w_embed", "=", "[", "tf", ".", "nn", ".", "embedding_lookup", "(", "embeding_var", ",", "wixs", ")", "]", "\n", "", "", "else", ":", "\n", "      ", "w_embed", "=", "[", "]", "\n", "\n", "", "if", "self", ".", "use_chars", ":", "\n", "      ", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "        ", "cids", "=", "tf", ".", "gather", "(", "self", ".", "_cached_char_ids", ",", "wixs", ")", "\n", "# dim = self._cached_char_ids.shape[1]", "\n", "# cids = tf.matmul(self._cached_char_ids,", "\n", "#                  tf.one_hot(wixs, dim, dtype=tf.int32))", "\n", "\n", "", "char_emb", "=", "char_encoder", ".", "embed_ids", "(", "cids", ",", "self", ".", "char_embed_dim", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"char-map\"", ")", ":", "\n", "        ", "char_emb", "=", "self", ".", "character_mapper", ".", "apply", "(", "is_train", ",", "char_emb", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"char-pool\"", ")", ":", "\n", "        ", "char_emb", "=", "self", ".", "character_pooler", ".", "apply", "(", "is_train", ",", "char_emb", ")", "\n", "\n", "", "w_embed", ".", "append", "(", "char_emb", ")", "\n", "\n", "", "w_embed", "=", "tf", ".", "concat", "(", "w_embed", ",", "1", ")", "\n", "unique_word_embeddings", "=", "w_embed", "\n", "\n", "if", "self", ".", "word_mapper", "is", "not", "None", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "\"word-map\"", ")", ":", "\n", "        ", "w_embed", "=", "self", ".", "word_mapper", ".", "apply", "(", "is_train", ",", "w_embed", ")", "\n", "\n", "", "", "dim", "=", "w_embed", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "\n", "# Undo tf.unique", "\n", "w_embeds", "=", "tf", ".", "gather", "(", "w_embed", ",", "w_mapping", ")", "\n", "\n", "# Undo tf.concat", "\n", "w_embeds", "=", "tf", ".", "split", "(", "w_embeds", ",", "sizes", ",", "0", ")", "\n", "w_mapping", "=", "tf", ".", "split", "(", "w_mapping", ",", "sizes", ",", "0", ")", "\n", "\n", "# Undo ops.flatten", "\n", "w_embeds", "=", "[", "tf", ".", "reshape", "(", "t", ",", "s", "+", "[", "dim", "]", ")", "for", "t", ",", "s", "in", "zip", "(", "w_embeds", ",", "shapes", ")", "]", "\n", "w_mapping", "=", "[", "tf", ".", "reshape", "(", "t", ",", "s", ")", "for", "t", ",", "s", "in", "zip", "(", "w_mapping", ",", "shapes", ")", "]", "\n", "return", "w_embeds", ",", "w_mapping", ",", "unique_word_embeddings", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.cudnn_recurrent_dropout.CudnnLSTMRecurrentDropout.__init__": [[19, 26], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "n_out", ":", "int", ",", "dropout", ":", "float", ",", "learn_initial_states", ":", "bool", "=", "True", ",", "\n", "direction", "=", "\"bi\"", ",", "lstm_bias", "=", "1", ")", ":", "\n", "    ", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "lstm_bias", "=", "lstm_bias", "\n", "self", ".", "learn_initial_states", "=", "learn_initial_states", "\n", "self", ".", "n_out", "=", "n_out", "\n", "self", ".", "direction", "=", "direction", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.cudnn_recurrent_dropout.CudnnLSTMRecurrentDropout._apply_transposed": [[27, 67], ["tensorflow.python.TruncatedNormal", "tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnLSTM", "tensorflow.contrib.cudnn_rnn.python.layers.CudnnLSTM", "tensorflow.constant", "tensorflow.constant", "tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnLSTM.canonical_to_params", "tensorflow.get_variable", "x.shape.as_list", "ValueError", "x.shape.as_list", "tensorflow.python.TruncatedNormal.", "tensorflow.zeros", "range", "tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnLSTM.canonical_to_params", "tensorflow.contrib.cudnn_rnn.python.ops.cudnn_rnn_ops.CudnnLSTM.", "tensorflow.ones_like", "tensorflow.ones_like", "tensorflow.floor", "tensorflow.expand_dims", "str", "tensorflow.random_uniform"], "methods", ["None"], ["", "def", "_apply_transposed", "(", "self", ",", "is_train", ",", "x", ",", "initial_states", "=", "None", ")", ":", "\n", "    ", "w_init", "=", "TruncatedNormal", "(", "stddev", "=", "0.05", ")", "\n", "x_size", "=", "x", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "if", "x_size", "is", "None", ":", "\n", "      ", "raise", "ValueError", "(", "\"Last dimension must be defined (have shape %s)\"", "%", "str", "(", "x", ".", "shape", ")", ")", "\n", "\n", "", "cell", "=", "cudnn_rnn_ops", ".", "CudnnLSTM", "(", "1", ",", "self", ".", "n_out", ",", "x_size", ",", "input_mode", "=", "\"linear_input\"", ")", "\n", "\n", "# We need to know the mapping of weights/baises -> CudnnLSTM parameter, so just", "\n", "# build a `CudnnLSTM` and read its fields", "\n", "c", "=", "cudnn_layers", ".", "CudnnLSTM", "(", "1", ",", "self", ".", "n_out", ")", "\n", "c", ".", "_input_size", "=", "x", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "w_shapes", "=", "c", ".", "canonical_weight_shapes", "\n", "b_shapes", "=", "c", ".", "canonical_bias_shapes", "\n", "weights", "=", "[", "w_init", "(", "s", ",", "tf", ".", "float32", ")", "for", "s", "in", "w_shapes", "]", "\n", "biases", "=", "[", "tf", ".", "zeros", "(", "s", ",", "tf", ".", "float32", ")", "for", "s", "in", "b_shapes", "]", "\n", "biases", "[", "1", "]", "=", "tf", ".", "constant", "(", "self", ".", "lstm_bias", "/", "2.0", ",", "tf", ".", "float32", ",", "b_shapes", "[", "1", "]", ")", "\n", "biases", "[", "5", "]", "=", "tf", ".", "constant", "(", "self", ".", "lstm_bias", "/", "2.0", ",", "tf", ".", "float32", ",", "b_shapes", "[", "5", "]", ")", "\n", "\n", "opaque_params_t", "=", "cell", ".", "canonical_to_params", "(", "weights", ",", "biases", ")", "\n", "parameters", "=", "tf", ".", "get_variable", "(", "\"opaque_kernel\"", ",", "initializer", "=", "opaque_params_t", ",", "validate_shape", "=", "False", ")", "\n", "\n", "p", "=", "1.0", "-", "self", ".", "dropout", "\n", "\n", "if", "is_train", "and", "self", ".", "dropout", ">", "0", ":", "\n", "      ", "mult_bias", "=", "[", "tf", ".", "ones_like", "(", "x", ")", "for", "x", "in", "biases", "]", "\n", "mult_w", "=", "[", "tf", ".", "ones_like", "(", "x", ")", "for", "x", "in", "weights", "]", "\n", "\n", "bias_mask", "=", "tf", ".", "floor", "(", "tf", ".", "random_uniform", "(", "(", "self", ".", "n_out", ",", ")", ",", "p", ",", "1", "+", "p", ")", ")", "/", "p", "\n", "\n", "for", "j", "in", "range", "(", "4", ",", "8", ")", ":", "\n", "        ", "mult_w", "[", "j", "]", "*=", "tf", ".", "expand_dims", "(", "bias_mask", ",", "0", ")", "\n", "\n", "", "mult_mask", "=", "cell", ".", "canonical_to_params", "(", "mult_w", ",", "mult_bias", ")", "\n", "parameters", "=", "parameters", "*", "mult_mask", "\n", "\n", "", "initial_state_h", ",", "initial_state_c", "=", "initial_states", "\n", "out", "=", "cell", "(", "x", ",", "initial_state_h", ",", "initial_state_c", ",", "parameters", ",", "True", ")", "[", "0", "]", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.cudnn_recurrent_dropout.CudnnLSTMRecurrentDropout.apply": [[68, 111], ["tensorflow.transpose", "debias.utils.ops.get_shape_tuple", "tensorflow.transpose", "tuple", "tensorflow.concat", "tensorflow.expand_dims", "tensorflow.get_variable", "initial_states.append", "tensorflow.zeros", "tensorflow.variable_scope", "cudnn_recurrent_dropout.CudnnLSTMRecurrentDropout._apply_transposed", "tensorflow.variable_scope", "cudnn_recurrent_dropout.CudnnLSTMRecurrentDropout._apply_transposed", "cudnn_recurrent_dropout.CudnnLSTMRecurrentDropout._apply_transposed", "tensorflow.cast", "tensorflow.expand_dims", "tensorflow.zeros_initializer", "tensorflow.tile", "range", "tensorflow.reverse_sequence", "tensorflow.reverse_sequence", "cudnn_recurrent_dropout.CudnnLSTMRecurrentDropout._apply_transposed", "ValueError", "tensorflow.sequence_mask", "tensorflow.expand_dims", "tensorflow.reverse_sequence", "tensorflow.reverse_sequence", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_shape_tuple", "home.repos.pwc.inspect_result.chrisc36_debias.modules.cudnn_recurrent_dropout.CudnnLSTMRecurrentDropout._apply_transposed", "home.repos.pwc.inspect_result.chrisc36_debias.modules.cudnn_recurrent_dropout.CudnnLSTMRecurrentDropout._apply_transposed", "home.repos.pwc.inspect_result.chrisc36_debias.modules.cudnn_recurrent_dropout.CudnnLSTMRecurrentDropout._apply_transposed", "home.repos.pwc.inspect_result.chrisc36_debias.modules.cudnn_recurrent_dropout.CudnnLSTMRecurrentDropout._apply_transposed"], ["", "def", "apply", "(", "self", ",", "is_train", ",", "x", ",", "mask", "=", "None", ",", "inital_states", "=", "None", ")", ":", "\n", "    ", "x_t", "=", "tf", ".", "transpose", "(", "x", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "batch", "=", "ops", ".", "get_shape_tuple", "(", "x_t", ",", "1", ")", "\n", "bidr", "=", "self", ".", "direction", "==", "\"bi\"", "\n", "\n", "if", "inital_states", "is", "not", "None", ":", "\n", "      ", "inital_states", "=", "tuple", "(", "tf", ".", "expand_dims", "(", "x", ",", "0", ")", "for", "x", "in", "inital_states", ")", "\n", "\n", "", "if", "self", ".", "learn_initial_states", "and", "inital_states", "is", "None", ":", "\n", "      ", "if", "bidr", ":", "\n", "        ", "names", "=", "[", "\"fw_h\"", ",", "\"fw_c\"", ",", "\"bw_h\"", ",", "\"bw_c\"", "]", "\n", "", "else", ":", "\n", "        ", "names", "=", "[", "\"fw_h\"", ",", "\"fw_c\"", "]", "\n", "\n", "", "initial_states", "=", "[", "]", "\n", "for", "n", "in", "names", ":", "\n", "        ", "v", "=", "tf", ".", "get_variable", "(", "n", ",", "(", "1", ",", "self", ".", "n_out", ")", ",", "tf", ".", "float32", ",", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "initial_states", ".", "append", "(", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "v", ",", "1", ")", ",", "[", "1", ",", "batch", ",", "1", "]", ")", ")", "\n", "", "", "else", ":", "\n", "      ", "initial_states", "=", "[", "tf", ".", "zeros", "(", "(", "1", ",", "batch", ",", "self", ".", "n_out", ")", ")", "for", "_", "in", "range", "(", "2", "+", "2", "*", "bidr", ")", "]", "\n", "\n", "", "if", "self", ".", "direction", "==", "'bi'", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "\"forward\"", ")", ":", "\n", "        ", "fw", "=", "self", ".", "_apply_transposed", "(", "is_train", ",", "x_t", ",", "initial_states", "=", "initial_states", "[", ":", "2", "]", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"backward\"", ")", ":", "\n", "        ", "x_bw", "=", "x_t", "[", ":", ":", "-", "1", "]", "if", "mask", "is", "None", "else", "tf", ".", "reverse_sequence", "(", "x_t", ",", "mask", ",", "0", ",", "1", ")", "\n", "bw", "=", "self", ".", "_apply_transposed", "(", "is_train", ",", "x_bw", ",", "initial_states", "=", "initial_states", "[", "2", ":", "]", ")", "\n", "bw", "=", "bw", "[", ":", ":", "-", "1", "]", "if", "mask", "is", "None", "else", "tf", ".", "reverse_sequence", "(", "bw", ",", "mask", ",", "0", ",", "1", ")", "\n", "", "out", "=", "tf", ".", "concat", "(", "[", "fw", ",", "bw", "]", ",", "axis", "=", "2", ")", "\n", "", "elif", "self", ".", "direction", "==", "\"fw\"", ":", "\n", "      ", "out", "=", "self", ".", "_apply_transposed", "(", "is_train", ",", "x_t", ",", "initial_states", "=", "initial_states", ")", "\n", "", "elif", "self", ".", "direction", "==", "\"bw\"", ":", "\n", "      ", "x_bw", "=", "x_t", "[", ":", ":", "-", "1", "]", "if", "mask", "is", "None", "else", "tf", ".", "reverse_sequence", "(", "x_t", ",", "mask", ",", "0", ",", "1", ")", "\n", "bw", "=", "self", ".", "_apply_transposed", "(", "is_train", ",", "x_bw", ",", "initial_states", "=", "initial_states", ")", "\n", "out", "=", "bw", "[", ":", ":", "-", "1", "]", "if", "mask", "is", "None", "else", "tf", ".", "reverse_sequence", "(", "bw", ",", "mask", ",", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", ")", "\n", "\n", "", "out", "=", "tf", ".", "transpose", "(", "out", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "      ", "out", "*=", "tf", ".", "expand_dims", "(", "tf", ".", "cast", "(", "tf", ".", "sequence_mask", "(", "mask", ",", "tf", ".", "shape", "(", "out", ")", "[", "1", "]", ")", ",", "tf", ".", "float32", ")", ",", "2", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.qa_debias_loss_functions.QaDebiasLossFunction.compute_qa_loss": [[26, 37], ["NotImplementedError"], "methods", ["None"], ["def", "compute_qa_loss", "(", "self", ",", "question_hidden", ",", "passage_hidden", ",", "logits", ",", "bias", ",", "labels", ",", "mask", ")", ":", "\n", "    ", "\"\"\"\n    :param question_hidden: [batch, seq_len, n_q_features] hidden features for question words\n    :param passage_hidden: [batch, seq_len, n_p_features] hidden features for passage words\n    :param logits: [batch, seq_len, 2] logit start/end score for each word\n    :param bias: [batch, seq_len, 2] bias log-probability for the start/end tokens\n    :param labels: [batch, seq_len, 2] binary mask of correct start/end tokens\n    :param mask: [batch] sequence lengths\n    :return: scalar loss\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.qa_debias_loss_functions.Plain.compute_qa_loss": [[40, 42], ["tensorflow.reduce_mean", "qa_debias_loss_functions.compute_nll"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.modules.qa_debias_loss_functions.compute_nll"], ["  ", "def", "compute_qa_loss", "(", "self", ",", "question_hidden", ",", "passage_hidden", ",", "logits", ",", "bias", ",", "labels", ",", "mask", ")", ":", "\n", "    ", "return", "tf", ".", "reduce_mean", "(", "compute_nll", "(", "logits", ",", "labels", ",", "mask", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.qa_debias_loss_functions.BiasProduct.compute_qa_loss": [[45, 48], ["tensorflow.nn.log_softmax", "tensorflow.reduce_mean", "qa_debias_loss_functions.compute_nll"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.modules.qa_debias_loss_functions.compute_nll"], ["  ", "def", "compute_qa_loss", "(", "self", ",", "question_hidden", ",", "passage_hidden", ",", "logits", ",", "bias", ",", "labels", ",", "mask", ")", ":", "\n", "    ", "logits", "=", "tf", ".", "nn", ".", "log_softmax", "(", "logits", ",", "1", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "compute_nll", "(", "logits", "+", "bias", ",", "labels", ",", "mask", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.qa_debias_loss_functions.Reweight.compute_qa_loss": [[51, 55], ["qa_debias_loss_functions.compute_nll", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.exp", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.modules.qa_debias_loss_functions.compute_nll"], ["  ", "def", "compute_qa_loss", "(", "self", ",", "question_hidden", ",", "passage_hidden", ",", "logits", ",", "bias", ",", "labels", ",", "mask", ")", ":", "\n", "    ", "losses", "=", "compute_nll", "(", "logits", "+", "bias", ",", "labels", ",", "mask", ")", "\n", "weights", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "exp", "(", "bias", ")", "*", "tf", ".", "cast", "(", "labels", ",", "tf", ".", "float32", ")", ",", "1", ")", "\n", "return", "tf", ".", "reduce_sum", "(", "losses", "*", "weights", ")", "/", "tf", ".", "reduce_sum", "(", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.qa_debias_loss_functions.LearnedMixin.__init__": [[58, 61], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "w", ",", "dim", "=", "50", ")", ":", "\n", "    ", "self", ".", "w", "=", "w", "\n", "self", ".", "dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.qa_debias_loss_functions.LearnedMixin.compute_qa_loss": [[62, 81], ["tensorflow.nn.log_softmax", "debias.utils.ops.max_pool", "debias.utils.ops.max_pool", "tensorflow.concat", "debias.utils.ops.affine", "tensorflow.nn.softplus", "tensorflow.reduce_mean", "tensorflow.nn.log_softmax", "debias.utils.ops.affine", "debias.utils.ops.affine", "tensorflow.expand_dims", "qa_debias_loss_functions.compute_nll", "debias.utils.ops.mask_logits", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.exp"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.max_pool", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.max_pool", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.affine", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.affine", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.affine", "home.repos.pwc.inspect_result.chrisc36_debias.modules.qa_debias_loss_functions.compute_nll", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.mask_logits"], ["", "def", "compute_qa_loss", "(", "self", ",", "question_hidden", ",", "passage_hidden", ",", "logits", ",", "bias", ",", "labels", ",", "mask", ")", ":", "\n", "    ", "logits", "=", "tf", ".", "nn", ".", "log_softmax", "(", "logits", ",", "1", ")", "\n", "\n", "p1", "=", "ops", ".", "max_pool", "(", "ops", ".", "affine", "(", "question_hidden", ",", "self", ".", "dim", ",", "\"q-w\"", ",", "\"q-b\"", ")", ",", "mask", ")", "\n", "p2", "=", "ops", ".", "max_pool", "(", "ops", ".", "affine", "(", "passage_hidden", ",", "self", ".", "dim", ",", "\"p-w\"", ",", "\"p-b\"", ")", ",", "mask", ")", "\n", "hidden", "=", "tf", ".", "concat", "(", "[", "p1", ",", "p2", "]", ",", "1", ")", "# [batch, dim*2]", "\n", "factor", "=", "ops", ".", "affine", "(", "hidden", ",", "1", ",", "\"scale-w\"", ",", "\"scale-b\"", ")", "# [batch, 1]", "\n", "factor", "=", "tf", ".", "nn", ".", "softplus", "(", "factor", ")", "\n", "bias", "=", "bias", "*", "tf", ".", "expand_dims", "(", "factor", ",", "2", ")", "\n", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "compute_nll", "(", "bias", "+", "logits", ",", "labels", ",", "mask", ")", ")", "\n", "\n", "if", "self", ".", "w", "==", "0", ":", "\n", "      ", "return", "loss", "\n", "\n", "", "bias_lp", "=", "tf", ".", "nn", ".", "log_softmax", "(", "ops", ".", "mask_logits", "(", "bias", ",", "mask", ")", ",", "1", ")", "\n", "entropy", "=", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "exp", "(", "bias_lp", ")", "*", "bias_lp", ",", "1", ")", ")", "\n", "\n", "return", "loss", "+", "self", ".", "w", "*", "entropy", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.qa_debias_loss_functions.compute_nll": [[7, 18], ["tensorflow.reduce_logsumexp", "tensorflow.reduce_logsumexp", "debias.utils.ops.mask_logits", "debias.utils.ops.mask_logits"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.mask_logits", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.mask_logits"], ["def", "compute_nll", "(", "logits", ",", "labels", ",", "mask", "=", "None", ")", ":", "\n", "  ", "\"\"\"Computes the NLL of selecting the elements in `labels`\n\n  :param logits: [batch, time, n]\n  :param labels: [batch, time, n]\n  :param mask: [batch] sequence lengths or [batch, time] binary mask\n  :return: [batch, n], the negative log probabilities\n  \"\"\"", "\n", "norms", "=", "tf", ".", "reduce_logsumexp", "(", "ops", ".", "mask_logits", "(", "logits", ",", "mask", ")", ",", "1", ")", "\n", "answer_scores", "=", "tf", ".", "reduce_logsumexp", "(", "ops", ".", "mask_logits", "(", "logits", ",", "labels", ")", ",", "1", ")", "\n", "return", "norms", "-", "answer_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.attention_layers.SimilarityLayer.get_scores": [[30, 32], ["None"], "methods", ["None"], ["def", "get_scores", "(", "self", ",", "is_train", ",", "tensor_1", ",", "tensor_2", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.attention_layers.SimilarityLayer.get_logit_masked_scores": [[33, 38], ["attention_layers.SimilarityLayer.get_scores", "attention_layers.compute_attention_mask", "debias.utils.ops.mask_logits", "debias.utils.ops.get_shape_tuple"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.modules.attention_layers.WeightedDot.get_scores", "home.repos.pwc.inspect_result.chrisc36_debias.modules.attention_layers.compute_attention_mask", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.mask_logits", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_shape_tuple"], ["", "def", "get_logit_masked_scores", "(", "self", ",", "is_train", ",", "tensor_1", ",", "tensor_2", ",", "mask1", ",", "mask2", ")", ":", "\n", "      ", "atten", "=", "self", ".", "get_scores", "(", "is_train", ",", "tensor_1", ",", "tensor_2", ")", "\n", "dim1", ",", "dim2", "=", "ops", ".", "get_shape_tuple", "(", "atten", ")", "[", "1", ":", "]", "\n", "mask", "=", "compute_attention_mask", "(", "mask1", ",", "mask2", ",", "dim1", ",", "dim2", ")", "\n", "return", "ops", ".", "mask_logits", "(", "atten", ",", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.attention_layers.WeightedDot.get_scores": [[42, 57], ["tensorflow.get_variable", "tensorflow.tensordot", "tensorflow.get_variable", "tensorflow.tensordot", "tensorflow.get_variable", "tensorflow.matmul", "keys.shape.as_list", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims"], "methods", ["None"], ["def", "get_scores", "(", "self", ",", "is_train", ",", "x", ",", "keys", ")", ":", "\n", "    ", "dim", "=", "keys", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "key_w", "=", "tf", ".", "get_variable", "(", "\"key_w\"", ",", "shape", "=", "dim", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "key_logits", "=", "tf", ".", "tensordot", "(", "keys", ",", "key_w", ",", "axes", "=", "[", "[", "2", "]", ",", "[", "0", "]", "]", ")", "# (batch, key_len)", "\n", "\n", "x_w", "=", "tf", ".", "get_variable", "(", "\"input_w\"", ",", "shape", "=", "dim", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "x_logits", "=", "tf", ".", "tensordot", "(", "x", ",", "x_w", ",", "axes", "=", "[", "[", "2", "]", ",", "[", "0", "]", "]", ")", "# (batch, x_len)", "\n", "\n", "dot_w", "=", "tf", ".", "get_variable", "(", "\"dot_w\"", ",", "shape", "=", "dim", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# Compute x * dot_weights first, the batch mult with x", "\n", "x_dots", "=", "x", "*", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "dot_w", ",", "0", ")", ",", "0", ")", "\n", "dot_logits", "=", "tf", ".", "matmul", "(", "x_dots", ",", "keys", ",", "transpose_b", "=", "True", ")", "\n", "\n", "return", "dot_logits", "+", "tf", ".", "expand_dims", "(", "key_logits", ",", "1", ")", "+", "tf", ".", "expand_dims", "(", "x_logits", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.attention_layers.WeightedDot.__setstate__": [[58, 63], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.modules.clf_debias_loss_functions.LearnedMixin.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "    ", "if", "\"dropout\"", "in", "state", ":", "# FIXME", "\n", "      ", "del", "state", "[", "\"dropout\"", "]", "\n", "del", "state", "[", "\"vdropout\"", "]", "\n", "", "super", "(", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.attention_layers.AttentionBiFuse.__init__": [[66, 68], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "similarity", ":", "SimilarityLayer", ")", ":", "\n", "    ", "self", ".", "similarity", "=", "similarity", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.attention_layers.AttentionBiFuse.apply": [[69, 79], ["tensorflow.matmul", "tensorflow.matmul", "tensorflow.concat", "tensorflow.concat", "tensorflow.variable_scope", "attention_layers.AttentionBiFuse.similarity.get_logit_masked_scores", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.transpose"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.modules.attention_layers.SimilarityLayer.get_logit_masked_scores"], ["", "def", "apply", "(", "self", ",", "is_train", ",", "seq1", ",", "seq2", ",", "mask1", ",", "mask2", ")", "->", "Tuple", "[", "Tensor", ",", "Tensor", "]", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"sim\"", ")", ":", "\n", "      ", "atten", "=", "self", ".", "similarity", ".", "get_logit_masked_scores", "(", "is_train", ",", "seq1", ",", "seq2", ",", "mask1", ",", "mask2", ")", "\n", "\n", "", "atten1", "=", "tf", ".", "matmul", "(", "tf", ".", "nn", ".", "softmax", "(", "atten", ")", ",", "seq2", ")", "\n", "atten2", "=", "tf", ".", "matmul", "(", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "transpose", "(", "atten", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", ",", "seq1", ")", "\n", "\n", "s1", "=", "tf", ".", "concat", "(", "[", "seq1", ",", "atten1", ",", "seq1", "*", "atten1", "]", ",", "2", ")", "\n", "s2", "=", "tf", ".", "concat", "(", "[", "seq2", ",", "atten2", ",", "seq2", "*", "atten2", "]", ",", "2", ")", "\n", "return", "s1", ",", "s2", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.attention_layers.BiAttention.__init__": [[84, 88], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sim", ":", "SimilarityLayer", ",", "q2c", ":", "bool", "=", "True", ",", "query_dots", ":", "bool", "=", "True", ")", ":", "\n", "    ", "self", ".", "sim", "=", "sim", "\n", "self", ".", "q2c", "=", "q2c", "\n", "self", ".", "query_dots", "=", "query_dots", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.attention_layers.BiAttention.apply": [[89, 112], ["attention_layers.BiAttention.sim.get_logit_masked_scores", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.reduce_max", "tensorflow.nn.softmax", "tensorflow.einsum", "tensorflow.expand_dims", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.modules.attention_layers.SimilarityLayer.get_logit_masked_scores"], ["", "def", "apply", "(", "self", ",", "is_train", ",", "src", ",", "other", ",", "src_mask", "=", "None", ",", "other_mask", "=", "None", ")", ":", "\n", "    ", "dist_matrix", "=", "self", ".", "sim", ".", "get_logit_masked_scores", "(", "is_train", ",", "src", ",", "other", ",", "src_mask", ",", "other_mask", ")", "\n", "query_probs", "=", "tf", ".", "nn", ".", "softmax", "(", "dist_matrix", ")", "# probability of each mem_word per x_word", "\n", "\n", "# Batch matrix multiplication to get the attended vectors", "\n", "select_query", "=", "tf", ".", "matmul", "(", "query_probs", ",", "other", ")", "# (batch, x_words, q_dim)", "\n", "\n", "if", "not", "self", ".", "q2c", ":", "\n", "      ", "if", "self", ".", "query_dots", ":", "\n", "        ", "return", "tf", ".", "concat", "(", "[", "src", ",", "select_query", ",", "src", "*", "select_query", "]", ",", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "concat", "(", "[", "src", ",", "select_query", "]", ",", "axis", "=", "2", ")", "\n", "\n", "# select query-to-context", "\n", "", "", "context_dist", "=", "tf", ".", "reduce_max", "(", "dist_matrix", ",", "axis", "=", "2", ")", "# (batch, x_word``s)", "\n", "context_probs", "=", "tf", ".", "nn", ".", "softmax", "(", "context_dist", ")", "# (batch, x_words)", "\n", "select_context", "=", "tf", ".", "einsum", "(", "\"ai,aik->ak\"", ",", "context_probs", ",", "src", ")", "# (batch, x_dim)", "\n", "select_context", "=", "tf", ".", "expand_dims", "(", "select_context", ",", "1", ")", "\n", "\n", "if", "self", ".", "query_dots", ":", "\n", "      ", "return", "tf", ".", "concat", "(", "[", "src", ",", "select_query", ",", "src", "*", "select_query", ",", "src", "*", "select_context", "]", ",", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "      ", "return", "tf", ".", "concat", "(", "[", "src", ",", "select_query", ",", "src", "*", "select_context", "]", ",", "axis", "=", "2", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.attention_layers.compute_attention_mask": [[10, 23], ["tensorflow.sequence_mask", "tensorflow.sequence_mask", "tensorflow.logical_and", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.sequence_mask", "tensorflow.expand_dims", "tensorflow.sequence_mask"], "function", ["None"], ["def", "compute_attention_mask", "(", "x_mask", ",", "mem_mask", ",", "x_word_dim", ",", "key_word_dim", ")", ":", "\n", "    ", "\"\"\" computes a (batch, x_word_dim, key_word_dim) bool mask for clients that want masking \"\"\"", "\n", "if", "x_mask", "is", "None", "and", "mem_mask", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "elif", "x_mask", "is", "None", ":", "\n", "        ", "return", "tf", ".", "expand_dims", "(", "tf", ".", "sequence_mask", "(", "mem_mask", ",", "key_word_dim", ")", ",", "1", ")", "\n", "", "elif", "mem_mask", "is", "None", ":", "\n", "        ", "return", "tf", ".", "expand_dims", "(", "tf", ".", "sequence_mask", "(", "x_mask", ",", "x_word_dim", ")", ",", "2", ")", "\n", "\n", "", "x_mask", "=", "tf", ".", "sequence_mask", "(", "x_mask", ",", "x_word_dim", ")", "\n", "mem_mask", "=", "tf", ".", "sequence_mask", "(", "mem_mask", ",", "key_word_dim", ")", "\n", "join_mask", "=", "tf", ".", "logical_and", "(", "tf", ".", "expand_dims", "(", "x_mask", ",", "2", ")", ",", "tf", ".", "expand_dims", "(", "mem_mask", ",", "1", ")", ")", "\n", "return", "join_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.SequenceMapper.apply": [[32, 34], ["NotImplementedError"], "methods", ["None"], ["def", "apply", "(", "self", ",", "is_train", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.Mapper.apply": [[38, 40], ["NotImplementedError"], "methods", ["None"], ["def", "apply", "(", "self", ",", "is_train", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.PoolingLayer.apply": [[43, 45], ["NotImplementedError"], "methods", ["None"], ["  ", "def", "apply", "(", "self", ",", "is_train", ",", "x", ",", "mask", ")", ":", "\n", "    ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.MapperSeq.__init__": [[48, 50], ["list"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "layers", ":", "Iterable", "[", "SequenceMapper", "]", ")", ":", "\n", "    ", "self", ".", "layers", "=", "list", "(", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.MapperSeq.apply": [[51, 56], ["enumerate", "tensorflow.variable_scope", "layer.apply"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply"], ["", "def", "apply", "(", "self", ",", "is_train", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "    ", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "\"layer-%d\"", "%", "i", ")", ":", "\n", "        ", "x", "=", "layer", ".", "apply", "(", "is_train", ",", "x", ",", "mask", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.SequenceMapperSeq.__init__": [[63, 65], ["list"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "layers", ":", "Iterable", "[", "SequenceMapper", "]", ")", ":", "\n", "    ", "self", ".", "layers", "=", "list", "(", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.SequenceMapperSeq.apply": [[66, 71], ["enumerate", "tensorflow.variable_scope", "layer.apply"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply"], ["", "def", "apply", "(", "self", ",", "is_train", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "    ", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "\"layer-%d\"", "%", "i", ")", ":", "\n", "        ", "x", "=", "layer", ".", "apply", "(", "is_train", ",", "x", ",", "mask", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.FullyConnected.__init__": [[78, 81], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "n_out", "=", "None", ",", "activation", "=", "\"relu\"", ")", ":", "\n", "    ", "self", ".", "n_out", "=", "n_out", "\n", "self", ".", "activation", "=", "activation", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.FullyConnected.apply": [[82, 92], ["tensorflow.split", "tensorflow.get_variable", "layers.activation_fn", "x.shape.as_list", "debias.utils.ops.affine", "tensorflow.nn.sigmoid", "debias.utils.ops.affine", "tensorflow.zeros_initializer"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split", "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.activation_fn", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.affine", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.affine"], ["", "def", "apply", "(", "self", ",", "is_train", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "    ", "n_out", "=", "self", ".", "n_out", "\n", "if", "n_out", "is", "None", ":", "\n", "      ", "n_out", "=", "x", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "", "if", "self", ".", "activation", "==", "\"glu\"", ":", "\n", "      ", "gate", ",", "lin", "=", "tf", ".", "split", "(", "ops", ".", "affine", "(", "x", ",", "n_out", "*", "2", ",", "\"w\"", ")", ",", "2", ",", "-", "1", ")", "\n", "gate", "+=", "tf", ".", "get_variable", "(", "\"b\"", ",", "n_out", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "return", "tf", ".", "nn", ".", "sigmoid", "(", "gate", ")", "*", "lin", "\n", "", "else", ":", "\n", "      ", "return", "activation_fn", "(", "ops", ".", "affine", "(", "x", ",", "n_out", ",", "\"w\"", ",", "bias_name", "=", "\"b\"", ")", ",", "self", ".", "activation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.VariationalDropout.__init__": [[95, 97], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "dropout_rate", ")", ":", "\n", "    ", "self", ".", "dropout_rate", "=", "dropout_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.VariationalDropout.apply": [[98, 104], ["debias.utils.ops.get_shape_tuple", "tensorflow.nn.dropout"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_shape_tuple"], ["", "def", "apply", "(", "self", ",", "is_train", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "      ", "shape", "=", "get_shape_tuple", "(", "x", ")", "\n", "return", "tf", ".", "nn", ".", "dropout", "(", "x", ",", "rate", "=", "self", ".", "dropout_rate", ",", "noise_shape", "=", "[", "shape", "[", "0", "]", ",", "1", ",", "shape", "[", "2", "]", "]", ")", "\n", "", "else", ":", "\n", "      ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.Dropout.__init__": [[107, 109], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "dropout_rate", ")", ":", "\n", "    ", "self", ".", "dropout_rate", "=", "dropout_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.Dropout.apply": [[110, 115], ["tensorflow.nn.dropout"], "methods", ["None"], ["", "def", "apply", "(", "self", ",", "is_train", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "    ", "if", "is_train", ":", "\n", "      ", "return", "tf", ".", "nn", ".", "dropout", "(", "x", ",", "rate", "=", "self", ".", "dropout_rate", ")", "\n", "", "else", ":", "\n", "      ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.MaxPooler.apply": [[118, 120], ["debias.utils.ops.max_pool"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.max_pool"], ["  ", "def", "apply", "(", "self", ",", "is_train", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "    ", "return", "ops", ".", "max_pool", "(", "x", ",", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.Conv1d.__init__": [[123, 130], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "num_filters", ",", "filter_size", ",", "activation", "=", "\"relu\"", ",", "same", "=", "False", ",", "\n", "leftpad", "=", "None", ")", ":", "\n", "    ", "self", ".", "num_filters", "=", "num_filters", "\n", "self", ".", "filter_size", "=", "filter_size", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "same", "=", "same", "\n", "self", ".", "leftpad", "=", "leftpad", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.Conv1d.apply": [[131, 168], ["debias.utils.ops.get_shape_tuple", "tensorflow.get_variable", "tensorflow.nn.conv1d", "tensorflow.expand_dims", "tensorflow.pad", "len", "tensorflow.reshape", "tensorflow.get_variable", "len", "tensorflow.reshape", "tensorflow.sequence_mask", "ValueError", "tensorflow.split", "layers.activation_fn", "tensorflow.zeros_initializer", "tensorflow.nn.sigmoid", "debias.utils.ops.get_shape_tuple"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_shape_tuple", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split", "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.activation_fn", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_shape_tuple"], ["", "def", "apply", "(", "self", ",", "is_train", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "    ", "x_shape", "=", "get_shape_tuple", "(", "x", ")", "\n", "dim", "=", "x_shape", "[", "-", "1", "]", "\n", "time", "=", "x_shape", "[", "-", "2", "]", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "      ", "x", "*=", "tf", ".", "expand_dims", "(", "tf", ".", "sequence_mask", "(", "mask", ",", "x_shape", "[", "1", "]", ",", "tf", ".", "float32", ")", ",", "2", ")", "\n", "\n", "", "if", "self", ".", "leftpad", ":", "\n", "      ", "if", "self", ".", "same", ":", "\n", "        ", "raise", "ValueError", "(", ")", "\n", "", "x", "=", "tf", ".", "pad", "(", "x", ",", "[", "[", "0", ",", "0", "]", ",", "[", "self", ".", "filter_size", "-", "1", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "\n", "", "n_filters", "=", "self", ".", "num_filters", "\n", "if", "self", ".", "activation", "==", "\"glu\"", ":", "\n", "      ", "n_filters", "*=", "2", "\n", "\n", "", "if", "len", "(", "x_shape", ")", "!=", "3", ":", "\n", "      ", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", ",", "time", ",", "dim", "]", ")", "\n", "\n", "", "filter_", "=", "tf", ".", "get_variable", "(", "\"conv1d/filters\"", ",", "shape", "=", "[", "self", ".", "filter_size", ",", "dim", ",", "n_filters", "]", ",", "\n", "dtype", "=", "'float'", ")", "\n", "out", "=", "tf", ".", "nn", ".", "conv1d", "(", "x", ",", "filter_", ",", "1", ",", "\"SAME\"", "if", "self", ".", "same", "else", "\"VALID\"", ")", "\n", "\n", "if", "self", ".", "activation", "is", "not", "None", ":", "\n", "      ", "bias", "=", "tf", ".", "get_variable", "(", "\"conv1d/bias\"", ",", "shape", "=", "[", "self", ".", "num_filters", "]", ",", "dtype", "=", "'float'", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "\n", "if", "self", ".", "activation", "==", "\"glu\"", ":", "\n", "        ", "gates", ",", "lin", "=", "tf", ".", "split", "(", "out", ",", "2", ",", "-", "1", ")", "\n", "out", "=", "tf", ".", "nn", ".", "sigmoid", "(", "gates", "+", "bias", ")", "*", "lin", "\n", "", "else", ":", "\n", "        ", "out", "=", "activation_fn", "(", "out", "+", "bias", ",", "self", ".", "activation", ")", "\n", "\n", "", "", "if", "len", "(", "x_shape", ")", "!=", "3", ":", "\n", "      ", "out", "=", "tf", ".", "reshape", "(", "out", ",", "x_shape", "[", ":", "-", "2", "]", "+", "get_shape_tuple", "(", "out", ")", "[", "-", "2", ":", "]", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.HighwayLayer.__init__": [[171, 174], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "layer", ",", "transform", "=", "\"tanh\"", ")", ":", "\n", "    ", "self", ".", "layer", "=", "layer", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.HighwayLayer.apply": [[175, 191], ["tensorflow.sigmoid", "tensorflow.variable_scope", "layers.HighwayLayer.layer.apply", "layers.HighwayLayer.shape.as_list", "isinstance", "isinstance", "debias.utils.ops.affine", "debias.utils.ops.affine", "tensorflow.split", "layers.activation_fn", "tensorflow.variable_scope", "layers.HighwayLayer.transform.apply"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.affine", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.affine", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split", "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.activation_fn", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply"], ["", "def", "apply", "(", "self", ",", "is_train", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"layer\"", ")", ":", "\n", "      ", "out", "=", "self", ".", "layer", ".", "apply", "(", "is_train", ",", "x", ",", "mask", ")", "\n", "", "dim", "=", "out", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "\n", "if", "isinstance", "(", "self", ".", "transform", ",", "Mapper", ")", "or", "isinstance", "(", "self", ".", "transform", ",", "SequenceMapper", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "\"transform\"", ")", ":", "\n", "        ", "transform", "=", "self", ".", "transform", ".", "apply", "(", "is_train", ",", "x", ",", "mask", ")", "\n", "", "gate", "=", "ops", ".", "affine", "(", "x", ",", "dim", ",", "\"w\"", ",", "\"b\"", ")", "\n", "", "else", ":", "\n", "      ", "proj", "=", "ops", ".", "affine", "(", "x", ",", "dim", "*", "2", ",", "\"w\"", ",", "bias_name", "=", "\"b\"", ")", "\n", "gate", ",", "transform", "=", "tf", ".", "split", "(", "proj", ",", "2", ",", "2", ")", "\n", "transform", "=", "activation_fn", "(", "transform", ",", "self", ".", "transform", ")", "\n", "\n", "", "gate", "=", "tf", ".", "sigmoid", "(", "gate", ")", "\n", "return", "transform", "*", "(", "1", "-", "gate", ")", "+", "gate", "*", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.activation_fn": [[10, 19], ["tensorflow.nn.relu", "tensorflow.nn.tanh", "NotImplementedError"], "function", ["None"], ["def", "activation_fn", "(", "x", ",", "fn_name", ")", ":", "\n", "  ", "if", "fn_name", "==", "\"relu\"", ":", "\n", "    ", "return", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "", "elif", "fn_name", "==", "\"tanh\"", ":", "\n", "    ", "return", "tf", ".", "nn", ".", "tanh", "(", "x", ")", "\n", "", "elif", "fn_name", "is", "None", ":", "\n", "    ", "return", "x", "\n", "", "else", ":", "\n", "    ", "raise", "NotImplementedError", "(", "fn_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers._wrap_init": [[21, 28], ["init_fn", "ValueError"], "function", ["None"], ["", "", "def", "_wrap_init", "(", "init_fn", ")", ":", "\n", "  ", "def", "wrapped", "(", "shape", ",", "dtype", "=", "None", ",", "partition_info", "=", "None", ")", ":", "\n", "    ", "if", "partition_info", "is", "not", "None", ":", "\n", "      ", "raise", "ValueError", "(", ")", "\n", "", "return", "init_fn", "(", "shape", ",", "dtype", ")", "\n", "\n", "", "return", "wrapped", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.mseq": [[58, 60], ["layers.MapperSeq"], "function", ["None"], ["", "", "def", "mseq", "(", "*", "layers", ":", "Mapper", ")", ":", "\n", "  ", "return", "MapperSeq", "(", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.layers.seq": [[73, 75], ["layers.SequenceMapperSeq"], "function", ["None"], ["", "", "def", "seq", "(", "*", "layers", ":", "SequenceMapper", ")", ":", "\n", "  ", "return", "SequenceMapperSeq", "(", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.char_encoder.word_to_char_ids": [[12, 18], ["tensorflow.to_int32", "tensorflow.fill", "tensorflow.concat", "tf.concat.set_shape", "tensorflow.decode_raw", "tensorflow.shape"], "function", ["None"], ["def", "word_to_char_ids", "(", "word", ",", "word_len", ")", ":", "\n", "  ", "char_ids", "=", "tf", ".", "to_int32", "(", "tf", ".", "decode_raw", "(", "word", ",", "tf", ".", "uint8", ")", "[", ":", "word_len", "-", "2", "]", ")", "\n", "padding", "=", "tf", ".", "fill", "(", "[", "word_len", "-", "tf", ".", "shape", "(", "char_ids", ")", "[", "0", "]", "-", "2", "]", ",", "PAD_CHAR", ")", "\n", "char_ids", "=", "tf", ".", "concat", "(", "[", "[", "BOW_CHAR", "]", ",", "char_ids", ",", "[", "EOW_CHAR", "]", ",", "padding", "]", ",", "0", ")", "\n", "char_ids", ".", "set_shape", "(", "[", "word_len", "]", ")", "\n", "return", "char_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.char_encoder.words_to_char_ids_py": [[20, 28], ["numpy.full", "enumerate", "len", "list", "len", "len"], "function", ["None"], ["", "def", "words_to_char_ids_py", "(", "words", ",", "word_length", ")", ":", "\n", "  ", "out", "=", "np", ".", "full", "(", "(", "len", "(", "words", ")", ",", "word_length", ")", ",", "PAD_CHAR", ",", "np", ".", "int32", ")", "\n", "out", "[", ":", ",", "0", "]", "=", "BOW_CHAR", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "    ", "word", "=", "list", "(", "word", ")", "[", ":", "word_length", "-", "2", "]", "\n", "out", "[", "i", ",", "1", ":", "len", "(", "word", ")", "+", "1", "]", "=", "word", "\n", "out", "[", "i", ",", "len", "(", "word", ")", "+", "1", "]", "=", "EOW_CHAR", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.char_encoder.words_to_char_ids": [[30, 41], ["tensorflow.reshape", "tensorflow.py_func", "tensorflow.reshape", "char_encoder.words_to_char_ids_py", "debias.utils.ops.get_shape_tuple"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.modules.char_encoder.words_to_char_ids_py", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_shape_tuple"], ["", "def", "words_to_char_ids", "(", "words", ",", "word_length", ",", "cpu", "=", "True", ")", ":", "\n", "  ", "flat_words", "=", "tf", ".", "reshape", "(", "words", ",", "[", "-", "1", "]", ")", "\n", "# Surprisingly, using a py_func here is much faster then the pure tensorflow option", "\n", "# Presumably because we have to .map in the tensorflow version which is very slow", "\n", "flat_char_ids", "=", "tf", ".", "py_func", "(", "\n", "lambda", "x", ":", "words_to_char_ids_py", "(", "x", ",", "word_length", ")", ",", "\n", "[", "flat_words", "]", ",", "\n", "[", "tf", ".", "int32", "]", ",", "\n", "False", "\n", ")", "\n", "return", "tf", ".", "reshape", "(", "flat_char_ids", ",", "ops", ".", "get_shape_tuple", "(", "words", ")", "+", "[", "word_length", "]", ")", "\n", "# if cpu:", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.char_encoder.embed_ids": [[60, 64], ["tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.truncated_normal_initializer"], "function", ["None"], ["", "def", "embed_ids", "(", "cids", ",", "char_embed_dim", ")", ":", "\n", "  ", "c_embed", "=", "tf", ".", "get_variable", "(", "\"char_embeddings\"", ",", "[", "NUM_CHARS", ",", "char_embed_dim", "]", ",", "\n", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.1", ")", ")", "\n", "return", "tf", ".", "nn", ".", "embedding_lookup", "(", "c_embed", ",", "cids", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.clf_debias_loss_functions.ClfDebiasLossFunction.compute_clf_loss": [[10, 19], ["NotImplementedError"], "methods", ["None"], ["def", "compute_clf_loss", "(", "self", ",", "hidden", ",", "logits", ",", "bias", ",", "labels", ")", ":", "\n", "    ", "\"\"\"\n    :param hidden: [batch, n_hidden] hidden units from the model\n    :param logits: [batch, n_classes] per-class logit scores\n    :param bias: [batch, n_classes] per-class log-probabilities from the bias\n    :param labels: [batch] labels\n    :return: scalar loss\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.clf_debias_loss_functions.Plain.compute_clf_loss": [[22, 25], ["tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean"], "methods", ["None"], ["  ", "def", "compute_clf_loss", "(", "self", ",", "hidden", ",", "logits", ",", "bias", ",", "labels", ",", "mask", "=", "None", ")", ":", "\n", "    ", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", "=", "logits", ",", "labels", "=", "labels", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.clf_debias_loss_functions.Reweight.compute_clf_loss": [[28, 33], ["tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.one_hot", "debias.utils.ops.get_shape_tuple", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.exp"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.get_shape_tuple"], ["  ", "def", "compute_clf_loss", "(", "self", ",", "hidden", ",", "logits", ",", "bias", ",", "labels", ",", "mask", "=", "None", ")", ":", "\n", "    ", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", "=", "logits", ",", "labels", "=", "labels", ")", "\n", "label_one_hot", "=", "tf", ".", "one_hot", "(", "labels", ",", "ops", ".", "get_shape_tuple", "(", "logits", ",", "1", ")", ")", "\n", "weights", "=", "1", "-", "tf", ".", "reduce_sum", "(", "tf", ".", "exp", "(", "bias", ")", "*", "label_one_hot", ",", "1", ")", "\n", "return", "tf", ".", "reduce_sum", "(", "weights", "*", "loss", ")", "/", "tf", ".", "reduce_sum", "(", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.clf_debias_loss_functions.BiasProduct.compute_clf_loss": [[36, 40], ["tensorflow.nn.log_softmax", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean"], "methods", ["None"], ["  ", "def", "compute_clf_loss", "(", "self", ",", "hidden", ",", "logits", ",", "bias", ",", "labels", ")", ":", "\n", "    ", "logits", "=", "tf", ".", "nn", ".", "log_softmax", "(", "logits", ")", "\n", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", "=", "logits", "+", "bias", ",", "labels", "=", "labels", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.clf_debias_loss_functions.LearnedMixin.__init__": [[43, 45], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "w", ")", ":", "\n", "    ", "self", ".", "w", "=", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.clf_debias_loss_functions.LearnedMixin.compute_clf_loss": [[46, 63], ["tensorflow.nn.log_softmax", "tensorflow.get_variable", "debias.utils.ops.last_dim_weighted_sum", "tensorflow.nn.softplus", "tensorflow.expand_dims", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "debias.utils.ops.entropy"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.last_dim_weighted_sum", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.entropy"], ["", "def", "compute_clf_loss", "(", "self", ",", "hidden", ",", "logits", ",", "bias", ",", "labels", ")", ":", "\n", "    ", "logits", "=", "tf", ".", "nn", ".", "log_softmax", "(", "logits", ")", "\n", "\n", "factor", "=", "tf", ".", "get_variable", "(", "\"factor-b\"", ",", "(", ")", ")", "\n", "factor", "+=", "ops", ".", "last_dim_weighted_sum", "(", "hidden", ",", "\"scale-w\"", ")", "\n", "factor", "=", "tf", ".", "nn", ".", "softplus", "(", "factor", ")", "\n", "bias", "*=", "tf", ".", "expand_dims", "(", "factor", ",", "1", ")", "\n", "\n", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", "+", "bias", ",", "labels", "=", "labels", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "\n", "if", "self", ".", "w", "==", "0", ":", "\n", "      ", "return", "loss", "\n", "\n", "", "loss", "+=", "self", ".", "w", "*", "ops", ".", "entropy", "(", "bias", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.modules.clf_debias_loss_functions.LearnedMixin.__setstate__": [[64, 69], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.modules.clf_debias_loss_functions.LearnedMixin.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "# TODO remove", "\n", "    ", "if", "\"normalize_bias\"", "in", "state", ":", "\n", "      ", "del", "state", "[", "\"normalize_bias\"", "]", "\n", "", "super", "(", ")", ".", "__setstate__", "(", "state", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.models.model_dir.ModelDir.__init__": [[13, 15], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", ":", "str", ")", ":", "\n", "    ", "self", ".", "dir", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.models.model_dir.ModelDir.get_model_file": [[16, 18], ["os.path.join"], "methods", ["None"], ["", "def", "get_model_file", "(", "self", ")", "->", "str", ":", "\n", "    ", "return", "join", "(", "self", ".", "dir", ",", "\"model.pkl\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.models.model_dir.ModelDir.get_model": [[19, 21], ["debias.utils.py_utils.load_pickle", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_pickle"], ["", "def", "get_model", "(", "self", ")", "->", "TextModel", ":", "\n", "    ", "return", "load_pickle", "(", "join", "(", "self", ".", "dir", ",", "\"model.pkl\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.models.model_dir.ModelDir.get_eval_dir": [[22, 27], ["os.path.join", "os.path.exists", "os.mkdir"], "methods", ["None"], ["", "def", "get_eval_dir", "(", "self", ")", "->", "str", ":", "\n", "    ", "answer_dir", "=", "join", "(", "self", ".", "dir", ",", "\"answers\"", ")", "\n", "if", "not", "exists", "(", "answer_dir", ")", ":", "\n", "      ", "mkdir", "(", "answer_dir", ")", "\n", "", "return", "answer_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.models.model_dir.ModelDir.get_latest_checkpoint": [[28, 30], ["tensorflow.train.latest_checkpoint"], "methods", ["None"], ["", "def", "get_latest_checkpoint", "(", "self", ")", ":", "\n", "    ", "return", "tf", ".", "train", ".", "latest_checkpoint", "(", "self", ".", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.models.model_dir.ModelDir.save_dir": [[31, 35], ["os.path.join"], "methods", ["None"], ["", "@", "property", "\n", "def", "save_dir", "(", "self", ")", ":", "\n", "# Stores training checkpoint", "\n", "    ", "return", "join", "(", "self", ".", "dir", ",", "\"save\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.models.model_dir.ModelDir.log_dir": [[36, 39], ["os.path.join"], "methods", ["None"], ["", "@", "property", "\n", "def", "log_dir", "(", "self", ")", ":", "\n", "    ", "return", "join", "(", "self", ".", "dir", ",", "\"log\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.EncodedText.__init__": [[15, 18], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "embeddings", ",", "mask", ")", ":", "\n", "    ", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "mask", "=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.__init__": [[27, 30], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tokenizer", ":", "Tokenizer", ",", "text_encoder", ":", "WordAndCharEncoder", ")", ":", "\n", "    ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "text_encoder", "=", "text_encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.set_vocab": [[31, 35], ["text_model.TextModel.text_encoder.set_vocab", "list"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.set_vocab"], ["", "def", "set_vocab", "(", "self", ",", "voc", ")", ":", "\n", "    ", "if", "voc", "is", "not", "None", ":", "\n", "      ", "voc", "=", "list", "(", "voc", ")", "\n", "", "self", ".", "text_encoder", ".", "set_vocab", "(", "voc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.tensorize_fn": [[36, 49], ["text_model.TextModel.text_encoder.tensorize_fn", "text_model.TextModel.", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.tensorize_fn"], ["", "def", "tensorize_fn", "(", "self", ")", ":", "\n", "    ", "\"\"\"Build a function to pre-process tokenized data with that can be used with tf.map\"\"\"", "\n", "\n", "fn", "=", "self", ".", "text_encoder", ".", "tensorize_fn", "(", ")", "\n", "\n", "def", "map_fn", "(", "x", ")", ":", "\n", "      ", "for", "key", "in", "[", "PREMISE_KEY", ",", "HYPOTHESIS_KEY", "]", ":", "\n", "        ", "t", "=", "x", "[", "key", "]", "\n", "x", "[", "key", "+", "\"_tensors\"", "]", "=", "fn", "(", "t", ")", "\n", "x", "[", "key", "+", "\"_len\"", "]", "=", "tf", ".", "shape", "(", "t", ")", "[", "-", "1", "]", "\n", "", "return", "x", "\n", "\n", "", "return", "map_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.get_tokenizer": [[50, 53], ["None"], "methods", ["None"], ["", "def", "get_tokenizer", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns a tokenizer to use on raw text.\"\"\"", "\n", "return", "self", ".", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.apply": [[54, 68], ["NotImplementedError"], "methods", ["None"], ["", "def", "apply", "(", "self", ",", "is_train", ",", "features", ",", "labels", ")", ":", "\n", "    ", "\"\"\"Returns a tensor containing the model's output.\n\n    Also should add the loss tf.GraphKeys.LOSSES if `is_train` is True\n\n    Args:\n      is_train: train or evaluation mode\n      features: batched feature dictionary as built by `self.tensorize`\n      labels: tensor or nested set of tensors that are the example labels\n\n    Returns:\n      the models tensor output\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.get_text_embeddings": [[69, 88], ["text_model.EncodedText", "text_model.EncodedText", "tensorflow.variable_scope", "tensorflow.variable_scope", "text_model.TextModel.text_encoder.embed_words"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.modules.word_and_char_encoder.WordAndCharEncoder.embed_words"], ["", "def", "get_text_embeddings", "(", "self", ",", "is_train", ",", "features", ")", "->", "Tuple", "[", "EncodedText", ",", "EncodedText", "]", ":", "\n", "    ", "\"\"\"Build text embeddings from `features`, where `features` is the batch, dictionary\n    of tensors built by `self.tensorize_fn`\"\"\"", "\n", "\n", "p_tensors", "=", "features", "[", "PREMISE_KEY", "+", "\"_tensors\"", "]", "\n", "h_tensors", "=", "features", "[", "HYPOTHESIS_KEY", "+", "\"_tensors\"", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"embed\"", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "\"word-embed\"", ")", ":", "\n", "        ", "p_wembed", ",", "h_wembed", "=", "self", ".", "text_encoder", ".", "embed_words", "(", "\n", "is_train", ",", "[", "p_tensors", ",", "h_tensors", "]", ")", "\n", "\n", "", "", "h_len", "=", "features", "[", "HYPOTHESIS_LEN_KEY", "]", "\n", "h_embed", "=", "EncodedText", "(", "h_wembed", ",", "h_len", ")", "\n", "\n", "p_len", "=", "features", "[", "PREMISE_LEN_KEY", "]", "\n", "p_embed", "=", "EncodedText", "(", "p_wembed", ",", "p_len", ")", "\n", "\n", "return", "h_embed", ",", "p_embed", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_qa_model.TextPairQaDebiasingModel.__init__": [[15, 28], ["debias.models.text_model.TextModel.__init__"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.bert.clf_debias_loss_functions.LearnedMixin.__init__"], ["  ", "def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Tokenizer", ",", "\n", "text_encoder", ":", "WordAndCharEncoder", ",", "\n", "map_embed", ":", "Optional", "[", "SequenceMapper", "]", ",", "\n", "fuse_layer", ":", "BiAttention", ",", "\n", "post_process_layer", ":", "SequenceMapper", ",", "\n", "debias_loss_fn", ":", "QaDebiasLossFunction", "\n", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "tokenizer", ",", "text_encoder", ")", "\n", "self", ".", "map_embed", "=", "map_embed", "\n", "self", ".", "fuse_layer", "=", "fuse_layer", "\n", "self", ".", "post_process_layer", "=", "post_process_layer", "\n", "self", ".", "debias_loss_fn", "=", "debias_loss_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_qa_model.TextPairQaDebiasingModel.apply": [[29, 54], ["text_pair_qa_model.TextPairQaDebiasingModel.get_text_embeddings", "debias.utils.ops.affine", "debias.utils.ops.mask_logits", "tensorflow.variable_scope", "text_pair_qa_model.TextPairQaDebiasingModel.fuse_layer.apply", "tensorflow.variable_scope", "text_pair_qa_model.TextPairQaDebiasingModel.post_process_layer.apply", "text_pair_qa_model.TextPairQaDebiasingModel.debias_loss_fn.compute_qa_loss", "tensorflow.add_to_collection", "tensorflow.variable_scope", "text_pair_qa_model.TextPairQaDebiasingModel.map_embed.apply", "tensorflow.variable_scope", "text_pair_qa_model.TextPairQaDebiasingModel.map_embed.apply"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.get_text_embeddings", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.affine", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.mask_logits", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.modules.qa_debias_loss_functions.LearnedMixin.compute_qa_loss", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply"], ["", "def", "apply", "(", "self", ",", "is_train", ",", "features", ",", "labels", ")", ":", "\n", "    ", "hypoth", ",", "premise", "=", "self", ".", "get_text_embeddings", "(", "is_train", ",", "features", ")", "\n", "q_embed", ",", "q_mask", "=", "hypoth", ".", "embeddings", ",", "hypoth", ".", "mask", "\n", "p_embed", ",", "p_mask", "=", "premise", ".", "embeddings", ",", "premise", ".", "mask", "\n", "\n", "if", "self", ".", "map_embed", "is", "not", "None", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "\"map-embed\"", ")", ":", "\n", "        ", "q_embed", "=", "self", ".", "map_embed", ".", "apply", "(", "is_train", ",", "q_embed", ",", "q_mask", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"map-embed\"", ",", "reuse", "=", "True", ")", ":", "\n", "        ", "p_embed", "=", "self", ".", "map_embed", ".", "apply", "(", "is_train", ",", "p_embed", ",", "p_mask", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"fuse\"", ")", ":", "\n", "      ", "fused", "=", "self", ".", "fuse_layer", ".", "apply", "(", "is_train", ",", "p_embed", ",", "q_embed", ",", "p_mask", ",", "q_mask", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"post-process-fused\"", ")", ":", "\n", "      ", "fused", "=", "self", ".", "post_process_layer", ".", "apply", "(", "is_train", ",", "fused", ",", "p_mask", ")", "\n", "\n", "", "logits", "=", "ops", ".", "affine", "(", "fused", ",", "2", ",", "\"predict-w\"", ")", "\n", "\n", "if", "labels", "is", "not", "None", "and", "\"bias\"", "in", "features", ":", "\n", "      ", "loss", "=", "self", ".", "debias_loss_fn", ".", "compute_qa_loss", "(", "\n", "q_embed", ",", "fused", ",", "logits", ",", "features", "[", "\"bias\"", "]", ",", "labels", "[", "\"answer_tokens\"", "]", ",", "p_mask", ")", "\n", "tf", ".", "add_to_collection", "(", "tf", ".", "GraphKeys", ".", "LOSSES", ",", "loss", ")", "\n", "\n", "", "return", "ops", ".", "mask_logits", "(", "logits", ",", "p_mask", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.__init__": [[15, 34], ["debias.models.text_model.TextModel.__init__"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.bert.clf_debias_loss_functions.LearnedMixin.__init__"], ["  ", "def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Tokenizer", ",", "\n", "text_encoder", ":", "WordAndCharEncoder", ",", "\n", "map_embed", ":", "Optional", "[", "SequenceMapper", "]", ",", "\n", "bifuse_layer", ":", "AttentionBiFuse", ",", "\n", "post_process_layer", ":", "SequenceMapper", ",", "\n", "pool_layer", ":", "PoolingLayer", ",", "\n", "processs_joint", ":", "Mapper", ",", "\n", "n_classes", ",", "\n", "debias_loss_fn", ":", "ClfDebiasLossFunction", "\n", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "tokenizer", ",", "text_encoder", ")", "\n", "self", ".", "map_embed", "=", "map_embed", "\n", "self", ".", "bifuse_layer", "=", "bifuse_layer", "\n", "self", ".", "pool_layer", "=", "pool_layer", "\n", "self", ".", "post_process_layer", "=", "post_process_layer", "\n", "self", ".", "processs_joint", "=", "processs_joint", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "self", ".", "debias_loss_fn", "=", "debias_loss_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply": [[35, 70], ["text_pair_clf_model.TextPairClfDebiasingModel.get_text_embeddings", "tensorflow.concat", "debias.utils.ops.affine", "tensorflow.variable_scope", "text_pair_clf_model.TextPairClfDebiasingModel.bifuse_layer.apply", "tensorflow.variable_scope", "text_pair_clf_model.TextPairClfDebiasingModel.post_process_layer.apply", "tensorflow.variable_scope", "text_pair_clf_model.TextPairClfDebiasingModel.post_process_layer.apply", "tensorflow.variable_scope", "text_pair_clf_model.TextPairClfDebiasingModel.pool_layer.apply", "tensorflow.variable_scope", "text_pair_clf_model.TextPairClfDebiasingModel.pool_layer.apply", "tensorflow.variable_scope", "text_pair_clf_model.TextPairClfDebiasingModel.processs_joint.apply", "text_pair_clf_model.TextPairClfDebiasingModel.debias_loss_fn.compute_clf_loss", "tensorflow.add_to_collection", "tensorflow.variable_scope", "text_pair_clf_model.TextPairClfDebiasingModel.map_embed.apply", "tensorflow.variable_scope", "text_pair_clf_model.TextPairClfDebiasingModel.map_embed.apply"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.models.text_model.TextModel.get_text_embeddings", "home.repos.pwc.inspect_result.chrisc36_debias.utils.ops.affine", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.modules.clf_debias_loss_functions.LearnedMixin.compute_clf_loss", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply"], ["", "def", "apply", "(", "self", ",", "is_train", ",", "features", ",", "labels", ")", ":", "\n", "    ", "hypoth", ",", "premise", "=", "self", ".", "get_text_embeddings", "(", "is_train", ",", "features", ")", "\n", "h_embed", ",", "h_mask", "=", "hypoth", ".", "embeddings", ",", "hypoth", ".", "mask", "\n", "p_embed", ",", "p_mask", "=", "premise", ".", "embeddings", ",", "premise", ".", "mask", "\n", "\n", "if", "self", ".", "map_embed", "is", "not", "None", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "\"map-embed\"", ")", ":", "\n", "        ", "h_embed", "=", "self", ".", "map_embed", ".", "apply", "(", "is_train", ",", "h_embed", ",", "h_mask", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"map-embed\"", ",", "reuse", "=", "True", ")", ":", "\n", "        ", "p_embed", "=", "self", ".", "map_embed", ".", "apply", "(", "is_train", ",", "p_embed", ",", "p_mask", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"fuse\"", ")", ":", "\n", "      ", "p_fused", ",", "h_fused", "=", "self", ".", "bifuse_layer", ".", "apply", "(", "is_train", ",", "p_embed", ",", "h_embed", ",", "p_mask", ",", "h_mask", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"post-process-fused\"", ")", ":", "\n", "      ", "p_fused", "=", "self", ".", "post_process_layer", ".", "apply", "(", "is_train", ",", "p_fused", ",", "p_mask", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"post-process-fused\"", ",", "reuse", "=", "True", ")", ":", "\n", "      ", "h_fused", "=", "self", ".", "post_process_layer", ".", "apply", "(", "is_train", ",", "h_fused", ",", "h_mask", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"pool\"", ")", ":", "\n", "      ", "p_pooled", "=", "self", ".", "pool_layer", ".", "apply", "(", "is_train", ",", "p_fused", ",", "p_mask", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"pool\"", ",", "reuse", "=", "True", ")", ":", "\n", "      ", "h_pooled", "=", "self", ".", "pool_layer", ".", "apply", "(", "is_train", ",", "h_fused", ",", "h_mask", ")", "\n", "\n", "", "joint", "=", "tf", ".", "concat", "(", "[", "p_pooled", ",", "h_pooled", "]", ",", "1", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"post-process-pooled\"", ")", ":", "\n", "      ", "joint", "=", "self", ".", "processs_joint", ".", "apply", "(", "is_train", ",", "joint", ")", "\n", "\n", "", "logits", "=", "ops", ".", "affine", "(", "joint", ",", "self", ".", "n_classes", ",", "\"w\"", ",", "\"b\"", ")", "\n", "if", "labels", "is", "not", "None", "and", "\"bias\"", "in", "features", ":", "\n", "      ", "loss", "=", "self", ".", "debias_loss_fn", ".", "compute_clf_loss", "(", "joint", ",", "logits", ",", "features", "[", "\"bias\"", "]", ",", "labels", ")", "\n", "tf", ".", "add_to_collection", "(", "tf", ".", "GraphKeys", ".", "LOSSES", ",", "loss", ")", "\n", "", "return", "logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.bert_with_debias_loss.BertWithDebiasLoss.__init__": [[10, 18], ["pytorch_pretrained_bert.modeling.BertPreTrainedModel.__init__", "pytorch_pretrained_bert.modeling.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "bert_with_debias_loss.BertWithDebiasLoss.apply"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.bert.clf_debias_loss_functions.LearnedMixin.__init__", "home.repos.pwc.inspect_result.chrisc36_debias.models.text_pair_clf_model.TextPairClfDebiasingModel.apply"], ["def", "__init__", "(", "self", ",", "config", ",", "num_labels", ",", "loss_fn", ":", "ClfDebiasLossFunction", ")", ":", "\n", "    ", "super", "(", "BertWithDebiasLoss", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "loss_fn", "=", "loss_fn", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_labels", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.bert_with_debias_loss.BertWithDebiasLoss.forward": [[19, 27], ["bert_with_debias_loss.BertWithDebiasLoss.bert", "bert_with_debias_loss.BertWithDebiasLoss.classifier", "bert_with_debias_loss.BertWithDebiasLoss.loss_fn.forward", "bert_with_debias_loss.BertWithDebiasLoss.dropout"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.bert.clf_debias_loss_functions.LearnedMixin.forward"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "bias", "=", "None", ")", ":", "\n", "    ", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "self", ".", "dropout", "(", "pooled_output", ")", ")", "\n", "if", "labels", "is", "None", ":", "\n", "      ", "return", "logits", "\n", "", "loss", "=", "self", ".", "loss_fn", ".", "forward", "(", "pooled_output", ",", "logits", ",", "bias", ",", "labels", ")", "\n", "return", "logits", ",", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.InputFeatures.__init__": [[142, 148], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "example_id", ",", "input_ids", ",", "segment_ids", ",", "label_id", ",", "bias", ")", ":", "\n", "    ", "self", ".", "example_id", "=", "example_id", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "label_id", "=", "label_id", "\n", "self", ".", "bias", "=", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.ExampleConverter.__init__": [[151, 154], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "max_seq_length", ",", "tokenizer", ")", ":", "\n", "    ", "self", ".", "max_seq_length", "=", "max_seq_length", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.ExampleConverter.process": [[155, 193], ["tokenizer.tokenize", "tokenizer.convert_tokens_to_ids", "features.append", "tokenizer.tokenize", "train_bert._truncate_seq_pair", "len", "train_bert.InputFeatures", "len", "len", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.tokenizer.NltkAndPunctTokenizer.tokenize", "home.repos.pwc.inspect_result.chrisc36_debias.utils.tokenizer.NltkAndPunctTokenizer.tokenize", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert._truncate_seq_pair"], ["", "def", "process", "(", "self", ",", "data", ":", "Iterable", ")", ":", "\n", "    ", "features", "=", "[", "]", "\n", "tokenizer", "=", "self", ".", "tokenizer", "\n", "max_seq_length", "=", "self", ".", "max_seq_length", "\n", "\n", "for", "example", "in", "data", ":", "\n", "      ", "tokens_a", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "hypothesis", ")", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "premise", ":", "\n", "        ", "tokens_b", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "premise", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total", "\n", "# length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "        ", "if", "len", "(", "tokens_a", ")", ">", "max_seq_length", "-", "2", ":", "\n", "          ", "tokens_a", "=", "tokens_a", "[", ":", "(", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "tokens", "=", "[", "\"[CLS]\"", "]", "+", "tokens_a", "+", "[", "\"[SEP]\"", "]", "\n", "segment_ids", "=", "[", "0", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "        ", "tokens", "+=", "tokens_b", "+", "[", "\"[SEP]\"", "]", "\n", "segment_ids", "+=", "[", "1", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "features", ".", "append", "(", "\n", "InputFeatures", "(", "\n", "example_id", "=", "example", ".", "id", ",", "\n", "input_ids", "=", "np", ".", "array", "(", "input_ids", ")", ",", "\n", "segment_ids", "=", "np", ".", "array", "(", "segment_ids", ")", ",", "\n", "label_id", "=", "example", ".", "label", ",", "\n", "bias", "=", "None", "\n", ")", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.InputFeatureDataset.__init__": [[197, 199], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "examples", ":", "List", "[", "InputFeatures", "]", ")", ":", "\n", "    ", "self", ".", "examples", "=", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.InputFeatureDataset.__getitem__": [[200, 202], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "    ", "return", "self", ".", "examples", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.InputFeatureDataset.__len__": [[203, 205], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.SortedBatchSampler.__init__": [[230, 238], ["torch.utils.data.Sampler.__init__", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.bert.clf_debias_loss_functions.LearnedMixin.__init__"], ["  ", "def", "__init__", "(", "self", ",", "data_source", ",", "batch_size", ",", "seed", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", "data_source", ")", "\n", "self", ".", "data_source", "=", "data_source", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "seed", "=", "seed", "\n", "if", "batch_size", "==", "1", ":", "\n", "      ", "raise", "NotImplementedError", "(", ")", "\n", "", "self", ".", "_epoch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.SortedBatchSampler.__iter__": [[239, 260], ["numpy.random.RandomState", "len", "numpy.full", "numpy.cumsum", "numpy.pad", "numpy.stack", "numpy.random.RandomState.shuffle", "len", "len", "print", "RuntimeError", "numpy.random.RandomState.choice", "numpy.arange", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "    ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "self", ".", "_epoch", "+", "601767", "+", "self", ".", "seed", ")", "\n", "n_batches", "=", "len", "(", "self", ")", "\n", "batch_lens", "=", "np", ".", "full", "(", "n_batches", ",", "self", ".", "batch_size", ",", "np", ".", "int32", ")", "\n", "\n", "# Randomly select batches to reduce by size 1", "\n", "extra", "=", "n_batches", "*", "self", ".", "batch_size", "-", "len", "(", "self", ".", "data_source", ")", "\n", "batch_lens", "[", "rng", ".", "choice", "(", "len", "(", "batch_lens", ")", ",", "extra", ",", "False", ")", "]", "-=", "1", "\n", "\n", "batch_ends", "=", "np", ".", "cumsum", "(", "batch_lens", ")", "\n", "batch_starts", "=", "np", ".", "pad", "(", "batch_ends", "[", ":", "-", "1", "]", ",", "[", "1", ",", "0", "]", ",", "\"constant\"", ")", "\n", "\n", "if", "batch_ends", "[", "-", "1", "]", "!=", "len", "(", "self", ".", "data_source", ")", ":", "\n", "      ", "print", "(", "batch_ends", ")", "\n", "raise", "RuntimeError", "(", ")", "\n", "\n", "", "bounds", "=", "np", ".", "stack", "(", "[", "batch_starts", ",", "batch_ends", "]", ",", "1", ")", "\n", "rng", ".", "shuffle", "(", "bounds", ")", "\n", "\n", "for", "s", ",", "e", "in", "bounds", ":", "\n", "      ", "yield", "np", ".", "arange", "(", "s", ",", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.SortedBatchSampler.__len__": [[261, 263], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "    ", "return", "(", "len", "(", "self", ".", "data_source", ")", "+", "self", ".", "batch_size", "-", "1", ")", "//", "self", ".", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_hans": [[58, 85], ["logging.info", "os.path.join", "os.path.exists", "logging.info", "debias.utils.py_utils.download_to_file", "open", "f.readline", "f.readlines", "numpy.random.RandomState().choice", "line.split", "out.append", "TextPairExample", "numpy.random.RandomState", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_to_file", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split"], ["def", "load_hans", "(", "n_samples", "=", "None", ")", "->", "List", "[", "TextPairExample", "]", ":", "\n", "  ", "out", "=", "[", "]", "\n", "logging", ".", "info", "(", "\"Loading hans...\"", ")", "\n", "src", "=", "join", "(", "config", ".", "HANS_SOURCE", ",", "\"heuristics_evaluation_set.txt\"", ")", "\n", "if", "not", "exists", "(", "src", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"Downloading source to %s...\"", "%", "config", ".", "HANS_SOURCE", ")", "\n", "py_utils", ".", "download_to_file", "(", "HANS_URL", ",", "src", ")", "\n", "\n", "", "with", "open", "(", "src", ",", "\"r\"", ")", "as", "f", ":", "\n", "    ", "f", ".", "readline", "(", ")", "\n", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "if", "n_samples", "is", "not", "None", ":", "\n", "    ", "lines", "=", "np", ".", "random", ".", "RandomState", "(", "16349", "+", "n_samples", ")", ".", "choice", "(", "lines", ",", "n_samples", ",", "replace", "=", "False", ")", "\n", "\n", "", "for", "line", "in", "lines", ":", "\n", "    ", "parts", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "label", "=", "parts", "[", "0", "]", "\n", "if", "label", "==", "\"non-entailment\"", ":", "\n", "      ", "label", "=", "0", "\n", "", "elif", "label", "==", "\"entailment\"", ":", "\n", "      ", "label", "=", "1", "\n", "", "else", ":", "\n", "      ", "raise", "RuntimeError", "(", ")", "\n", "", "s1", ",", "s2", ",", "pair_id", "=", "parts", "[", "5", ":", "8", "]", "\n", "out", ".", "append", "(", "TextPairExample", "(", "pair_id", ",", "s1", ",", "s2", ",", "label", ")", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.ensure_mnli_is_downloaded": [[87, 92], ["os.path.join", "debias.utils.py_utils.download_zip", "os.path.exists", "len", "os.listdir"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_zip"], ["", "def", "ensure_mnli_is_downloaded", "(", ")", ":", "\n", "  ", "mnli_source", "=", "join", "(", "config", ".", "GLUE_SOURCE", ",", "\"MNLI\"", ")", "\n", "if", "exists", "(", "mnli_source", ")", "and", "len", "(", "os", ".", "listdir", "(", "mnli_source", ")", ")", ">", "0", ":", "\n", "    ", "return", "\n", "", "py_utils", ".", "download_zip", "(", "\"MNLI\"", ",", "MNLI_URL", ",", "config", ".", "GLUE_SOURCE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_mnli": [[94, 114], ["train_bert.ensure_mnli_is_downloaded", "logging.info", "os.path.join", "os.path.join", "open", "f.readline", "f.readlines", "numpy.random.RandomState().choice", "line.split.split", "out.append", "TextPairExample", "numpy.random.RandomState", "line[].rstrip"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.ensure_mnli_is_downloaded", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split"], ["", "def", "load_mnli", "(", "is_train", ",", "sample", "=", "None", ")", "->", "List", "[", "TextPairExample", "]", ":", "\n", "  ", "ensure_mnli_is_downloaded", "(", ")", "\n", "if", "is_train", ":", "\n", "    ", "filename", "=", "join", "(", "config", ".", "GLUE_SOURCE", ",", "\"MNLI\"", ",", "\"train.tsv\"", ")", "\n", "", "else", ":", "\n", "    ", "filename", "=", "join", "(", "config", ".", "GLUE_SOURCE", ",", "\"MNLI\"", ",", "\"dev_matched.tsv\"", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Loading mnli \"", "+", "(", "\"train\"", "if", "is_train", "else", "\"dev\"", ")", ")", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "    ", "f", ".", "readline", "(", ")", "\n", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "if", "sample", ":", "\n", "    ", "lines", "=", "np", ".", "random", ".", "RandomState", "(", "26096781", "+", "sample", ")", ".", "choice", "(", "lines", ",", "sample", ",", "replace", "=", "False", ")", "\n", "\n", "", "out", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "    ", "line", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "out", ".", "append", "(", "TextPairExample", "(", "line", "[", "0", "]", ",", "line", "[", "8", "]", ",", "line", "[", "9", "]", ",", "NLI_LABEL_MAP", "[", "line", "[", "-", "1", "]", ".", "rstrip", "(", ")", "]", ")", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_bias": [[116, 137], ["os.path.join", "debias.utils.py_utils.load_pickle", "py_utils.load_pickle.items", "ValueError", "os.path.exists", "logging.info", "debias.utils.py_utils.download_from_drive", "numpy.array", "numpy.log", "numpy.log"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.load_pickle", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.download_from_drive"], ["", "def", "load_bias", "(", "dataset_name", ")", "->", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", ":", "\n", "  ", "\"\"\"Load dictionary of example_id->bias where bias is a length 3 array\n  of log-probabilities\"\"\"", "\n", "\n", "if", "dataset_name", "not", "in", "MNLI_BIAS_DRIVE_IDS", ":", "\n", "    ", "raise", "ValueError", "(", "dataset_name", ")", "\n", "", "bias_src", "=", "join", "(", "config", ".", "MNLI_WORD_OVERLAP_BIAS", ",", "dataset_name", "+", "\".pkl\"", ")", "\n", "if", "not", "exists", "(", "bias_src", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\"Downloading MNLI bias to %s...\"", "%", "bias_src", ")", "\n", "py_utils", ".", "download_from_drive", "(", "MNLI_BIAS_DRIVE_IDS", "[", "dataset_name", "]", ",", "bias_src", ")", "\n", "\n", "", "bias", "=", "py_utils", ".", "load_pickle", "(", "bias_src", ")", "\n", "for", "k", ",", "v", "in", "bias", ".", "items", "(", ")", ":", "\n", "# Convert from entail vs non-entail to 3-way classes by splitting non-entail", "\n", "# to neutral and contradict", "\n", "    ", "bias", "[", "k", "]", "=", "np", ".", "array", "(", "[", "\n", "v", "[", "0", "]", "-", "np", ".", "log", "(", "2.", ")", ",", "\n", "v", "[", "1", "]", ",", "\n", "v", "[", "0", "]", "-", "np", ".", "log", "(", "2.", ")", ",", "\n", "]", ")", "\n", "", "return", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.collate_input_features": [[207, 227], ["max", "len", "numpy.zeros", "numpy.zeros", "torch.zeros", "enumerate", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.tensor", "numpy.array", "len", "len", "len", "len"], "function", ["None"], ["", "", "def", "collate_input_features", "(", "batch", ":", "List", "[", "InputFeatures", "]", ")", ":", "\n", "  ", "max_seq_len", "=", "max", "(", "len", "(", "x", ".", "input_ids", ")", "for", "x", "in", "batch", ")", "\n", "sz", "=", "len", "(", "batch", ")", "\n", "\n", "input_ids", "=", "np", ".", "zeros", "(", "(", "sz", ",", "max_seq_len", ")", ",", "np", ".", "int64", ")", "\n", "segment_ids", "=", "np", ".", "zeros", "(", "(", "sz", ",", "max_seq_len", ")", ",", "np", ".", "int64", ")", "\n", "mask", "=", "torch", ".", "zeros", "(", "sz", ",", "max_seq_len", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "for", "i", ",", "ex", "in", "enumerate", "(", "batch", ")", ":", "\n", "    ", "input_ids", "[", "i", ",", ":", "len", "(", "ex", ".", "input_ids", ")", "]", "=", "ex", ".", "input_ids", "\n", "segment_ids", "[", "i", ",", ":", "len", "(", "ex", ".", "segment_ids", ")", "]", "=", "ex", ".", "segment_ids", "\n", "mask", "[", "i", ",", ":", "len", "(", "ex", ".", "input_ids", ")", "]", "=", "1", "\n", "\n", "", "input_ids", "=", "torch", ".", "as_tensor", "(", "input_ids", ")", "\n", "segment_ids", "=", "torch", ".", "as_tensor", "(", "segment_ids", ")", "\n", "label_ids", "=", "torch", ".", "as_tensor", "(", "np", ".", "array", "(", "[", "x", ".", "label_id", "for", "x", "in", "batch", "]", ",", "np", ".", "int64", ")", ")", "\n", "if", "batch", "[", "0", "]", ".", "bias", "is", "None", ":", "\n", "    ", "return", "input_ids", ",", "mask", ",", "segment_ids", ",", "label_ids", "\n", "\n", "", "bias", "=", "torch", ".", "tensor", "(", "[", "x", ".", "bias", "for", "x", "in", "batch", "]", ")", "\n", "return", "input_ids", ",", "mask", ",", "segment_ids", ",", "label_ids", ",", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.build_train_dataloader": [[265, 274], ["data.sort", "train_bert.InputFeatureDataset", "train_bert.SortedBatchSampler", "torch.utils.data.DataLoader", "train_bert.InputFeatureDataset", "torch.utils.data.DataLoader", "torch.utils.data.RandomSampler", "len"], "function", ["None"], ["", "", "def", "build_train_dataloader", "(", "data", ":", "List", "[", "InputFeatures", "]", ",", "batch_size", ",", "seed", ",", "sorted", ")", ":", "\n", "  ", "if", "sorted", ":", "\n", "    ", "data", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", ".", "input_ids", ")", ")", "\n", "ds", "=", "InputFeatureDataset", "(", "data", ")", "\n", "sampler", "=", "SortedBatchSampler", "(", "ds", ",", "batch_size", ",", "seed", ")", "\n", "return", "DataLoader", "(", "ds", ",", "batch_sampler", "=", "sampler", ",", "collate_fn", "=", "collate_input_features", ")", "\n", "", "else", ":", "\n", "    ", "ds", "=", "InputFeatureDataset", "(", "data", ")", "\n", "return", "DataLoader", "(", "ds", ",", "batch_size", "=", "batch_size", ",", "sampler", "=", "RandomSampler", "(", "ds", ")", ",", "collate_fn", "=", "collate_input_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.build_eval_dataloader": [[276, 279], ["train_bert.InputFeatureDataset", "torch.utils.data.DataLoader", "torch.utils.data.SequentialSampler"], "function", ["None"], ["", "", "def", "build_eval_dataloader", "(", "data", ":", "List", "[", "InputFeatures", "]", ",", "batch_size", ")", ":", "\n", "  ", "ds", "=", "InputFeatureDataset", "(", "data", ")", "\n", "return", "DataLoader", "(", "ds", ",", "batch_size", "=", "batch_size", ",", "sampler", "=", "SequentialSampler", "(", "ds", ")", ",", "collate_fn", "=", "collate_input_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.convert_examples_to_features": [[281, 285], ["train_bert.ExampleConverter", "debias.utils.process_par.process_par"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.process_par.process_par"], ["", "def", "convert_examples_to_features", "(", "\n", "examples", ":", "List", "[", "TextPairExample", "]", ",", "max_seq_length", ",", "tokenizer", ",", "n_process", "=", "1", ")", ":", "\n", "  ", "converter", "=", "ExampleConverter", "(", "max_seq_length", ",", "tokenizer", ")", "\n", "return", "process_par", "(", "examples", ",", "converter", ",", "n_process", ",", "chunk_size", "=", "2000", ",", "desc", "=", "\"featurize\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert._truncate_seq_pair": [[287, 302], ["len", "len", "len", "len", "tokens_a.pop", "tokens_b.pop"], "function", ["None"], ["", "def", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_length", ")", ":", "\n", "  ", "\"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"", "\n", "\n", "# This is a simple heuristic which will always truncate the longer sequence", "\n", "# one token at a time. This makes more sense than truncating an equal percent", "\n", "# of tokens from each, since if one sequence is very short then each token", "\n", "# that's truncated likely contains more information than a longer sequence.", "\n", "while", "True", ":", "\n", "    ", "total_length", "=", "len", "(", "tokens_a", ")", "+", "len", "(", "tokens_b", ")", "\n", "if", "total_length", "<=", "max_length", ":", "\n", "      ", "break", "\n", "", "if", "len", "(", "tokens_a", ")", ">", "len", "(", "tokens_b", ")", ":", "\n", "      ", "tokens_a", ".", "pop", "(", ")", "\n", "", "else", ":", "\n", "      ", "tokens_b", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.simple_accuracy": [[304, 306], ["None"], "function", ["None"], ["", "", "", "def", "simple_accuracy", "(", "preds", ",", "labels", ")", ":", "\n", "  ", "return", "(", "preds", "==", "labels", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.main": [[308, 687], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "debias.utils.py_utils.add_stdout_logger", "print", "logging.info", "pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained", "debias.bert.bert_with_debias_loss.BertWithDebiasLoss.from_pretrained", "torch.nn.DataParallel.to", "list", "torch.nn.DataParallel.to", "torch.nn.DataParallel.eval", "debias.bert.clf_debias_loss_functions.Plain", "os.path.exists", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "ValueError", "random.seed", "numpy.random.seed", "torch.manual_seed", "ValueError", "os.path.exists", "os.listdir", "ValueError", "os.path.exists", "os.makedirs", "train_bert.load_mnli", "os.path.join", "torch.nn.DataParallel.half", "DDP", "torch.nn.DataParallel.named_parameters", "FusedAdam", "pytorch_pretrained_bert.optimization.BertAdam", "train_bert.convert_examples_to_features", "train_bert.load_bias", "logging.info", "logging.info", "logging.info", "logging.info", "train_bert.build_train_dataloader", "torch.nn.DataParallel.train", "tqdm.trange", "os.path.join", "torch.save", "os.path.join", "vars", "pytorch_pretrained_bert.modeling.BertConfig", "debias.bert.bert_with_debias_loss.BertWithDebiasLoss", "torch.nn.DataParallel.load_state_dict", "os.path.join", "pytorch_pretrained_bert.modeling.BertConfig.from_json_file", "os.path.join", "debias.bert.bert_with_debias_loss.BertWithDebiasLoss", "torch.nn.DataParallel.load_state_dict", "logging.info", "logging.info", "logging.info", "train_bert.convert_examples_to_features", "convert_examples_to_features.sort", "numpy.array", "train_bert.build_eval_dataloader", "tqdm.tqdm", "numpy.concatenate", "numpy.argmax", "os.path.join", "os.path.join", "debias.bert.clf_debias_loss_functions.ReweightByInvBias", "os.makedirs", "bool", "torch.cuda.manual_seed_all", "NotImplementedError", "int", "str", "torch.nn.DataParallel", "FP16_Optimizer", "FP16_Optimizer", "bias_map[].astype", "len", "int", "tqdm.tqdm", "enumerate", "hasattr", "model_to_save.state_dict", "open", "f.write", "getattr", "open", "json.dump", "torch.load", "torch.load", "train_bert.load_mnli", "train_bert.load_hans", "len", "input_ids.to.to", "input_mask.to.to", "segment_ids.to.to", "label_ids.to.to", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "loss_fct.mean().item", "np.concatenate.append", "train_bert.simple_accuracy", "open", "logging.info", "sorted", "open", "json.dump", "debias.bert.clf_debias_loss_functions.BiasProduct", "len", "ValueError", "torch.distributed.get_world_size", "ImportError", "ImportError", "tuple", "torch.nn.DataParallel.", "tqdm.tqdm.set_description", "loss.mean.item", "input_ids.to.size", "model_to_save.config.to_json_string", "os.path.join", "torch.distributed.get_rank", "torch.no_grad", "torch.nn.DataParallel.", "model.view", "label_ids.to.view", "torch.nn.functional.softmax().detach().cpu().numpy", "result.keys", "logging.info", "writer.write", "float", "zip", "debias.bert.clf_debias_loss_functions.LearnedMixin", "RuntimeError", "os.listdir", "torch.cuda.is_available", "any", "loss.mean.mean", "FP16_Optimizer.backward", "loss.mean.backward", "FP16_Optimizer.step", "FP16_Optimizer.zero_grad", "len", "loss_fct.mean", "str", "len", "any", "t.to", "loss.mean.cpu().detach().numpy", "torch.nn.functional.softmax().detach().cpu", "pytorch_pretrained_bert.optimization.warmup_linear", "str", "loss.mean.cpu().detach", "torch.nn.functional.softmax().detach", "loss.mean.cpu", "torch.nn.functional.softmax"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.add_stdout_logger", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_mnli", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.convert_examples_to_features", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_bias", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.build_train_dataloader", "home.repos.pwc.inspect_result.chrisc36_debias.training.trainer.Trainer.train", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.convert_examples_to_features", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.build_eval_dataloader", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadLoader.load", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadLoader.load", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_mnli", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.load_hans", "home.repos.pwc.inspect_result.chrisc36_debias.bert.train_bert.simple_accuracy"], ["", "def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--bert_model\"", ",", "default", "=", "\"bert-base-uncased\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Bert pre-trained model selected in the list: bert-base-uncased, \"", "\n", "\"bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, \"", "\n", "\"bert-base-multilingual-cased, bert-base-chinese.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after WordPiece tokenization. \\n\"", "\n", "\"Sequences longer than this will be truncated, and sequences shorter \\n\"", "\n", "\"than this will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "\n", "default", "=", "32", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Total batch size for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Seed for randomized elements in the training\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "\n", "default", "=", "16", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Total batch size for eval.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "\n", "default", "=", "5e-5", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "\n", "default", "=", "3.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_proportion\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Proportion of training to perform linear learning rate warmup for. \"", "\n", "\"E.g., 0.1 = 10%% of training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether not to use CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "-", "1", ",", "\n", "help", "=", "\"local_rank for distributed training on gpus\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit float precision instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--loss_scale'", ",", "\n", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True.\\n\"", "\n", "\"0 (default value): dynamic loss scaling.\\n\"", "\n", "\"Positive power of 2: static loss scaling value.\\n\"", ")", "\n", "\n", "## Our arguements", "\n", "parser", ".", "add_argument", "(", "\"--mode\"", ",", "choices", "=", "[", "\"bias_product\"", ",", "\"none\"", ",", "\"learned_mixin\"", ",", "\"reweight\"", "]", ",", "\n", "default", "=", "\"learned_mixin\"", ",", "help", "=", "\"Kind of debiasing method to use\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--penalty\"", ",", "type", "=", "float", ",", "default", "=", "0.03", ",", "\n", "help", "=", "\"Penalty weight for the learn_mixin model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_processes\"", ",", "type", "=", "int", ",", "default", "=", "4", ",", "\n", "help", "=", "\"Processes to use for pre-processing\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--debug\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--sorted\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Sort the data so most batches have the same input length,'", "\n", "' makes things about 2x faster. Our experiments did not actually'", "\n", "' use this in the end (not sure if it makes a difference) so '", "\n", "'its off by default.'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "py_utils", ".", "add_stdout_logger", "(", ")", "\n", "\n", "if", "args", ".", "mode", "==", "\"none\"", ":", "\n", "    ", "loss_fn", "=", "clf_debias_loss_functions", ".", "Plain", "(", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"reweight\"", ":", "\n", "    ", "loss_fn", "=", "clf_debias_loss_functions", ".", "ReweightByInvBias", "(", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"bias_product\"", ":", "\n", "    ", "loss_fn", "=", "clf_debias_loss_functions", ".", "BiasProduct", "(", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"learned_mixin\"", ":", "\n", "    ", "loss_fn", "=", "clf_debias_loss_functions", ".", "LearnedMixin", "(", "args", ".", "penalty", ")", "\n", "", "else", ":", "\n", "    ", "raise", "RuntimeError", "(", ")", "\n", "\n", "", "output_dir", "=", "args", ".", "output_dir", "\n", "\n", "if", "args", ".", "do_train", ":", "\n", "    ", "if", "exists", "(", "output_dir", ")", ":", "\n", "      ", "if", "len", "(", "os", ".", "listdir", "(", "output_dir", ")", ")", ">", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"Output dir exists and is non-empty\"", ")", "\n", "", "", "else", ":", "\n", "      ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "\n", "", "", "print", "(", "\"Saving model to %s\"", "%", "output_dir", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "    ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "\n", "    ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "n_gpu", "=", "1", "\n", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "", "logging", ".", "info", "(", "\"device: {} n_gpu: {}, distributed training: {}, 16-bits training: {}\"", ".", "format", "(", "\n", "device", ",", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", ")", "\n", "\n", "if", "args", ".", "gradient_accumulation_steps", "<", "1", ":", "\n", "    ", "raise", "ValueError", "(", "\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\"", ".", "format", "(", "\n", "args", ".", "gradient_accumulation_steps", ")", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "train_batch_size", "//", "args", ".", "gradient_accumulation_steps", "\n", "\n", "if", "args", ".", "seed", "is", "not", "None", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "n_gpu", ">", "0", ":", "\n", "      ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n", "", "", "if", "not", "args", ".", "do_train", "and", "not", "args", ".", "do_eval", ":", "\n", "    ", "raise", "ValueError", "(", "\"At least one of `do_train` or `do_eval` must be True.\"", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "output_dir", ")", "and", "os", ".", "listdir", "(", "output_dir", ")", "and", "args", ".", "do_train", ":", "\n", "    ", "raise", "ValueError", "(", "\"Output directory ({}) already exists and is not empty.\"", ".", "format", "(", "output_dir", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "\n", "# Its way ot easy to forget if this is being set by a command line flag", "\n", "", "if", "\"-uncased\"", "in", "args", ".", "bert_model", ":", "\n", "    ", "do_lower_case", "=", "True", "\n", "", "elif", "\"-cased\"", "in", "args", ".", "bert_model", ":", "\n", "    ", "do_lower_case", "=", "False", "\n", "", "else", ":", "\n", "    ", "raise", "NotImplementedError", "(", "args", ".", "bert_model", ")", "\n", "\n", "", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "bert_model", ",", "do_lower_case", "=", "do_lower_case", ")", "\n", "\n", "num_train_optimization_steps", "=", "None", "\n", "train_examples", "=", "None", "\n", "if", "args", ".", "do_train", ":", "\n", "    ", "train_examples", "=", "load_mnli", "(", "True", ",", "2000", "if", "args", ".", "debug", "else", "None", ")", "\n", "num_train_optimization_steps", "=", "int", "(", "\n", "len", "(", "train_examples", ")", "/", "args", ".", "train_batch_size", "/", "args", ".", "gradient_accumulation_steps", ")", "*", "args", ".", "num_train_epochs", "\n", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "      ", "num_train_optimization_steps", "=", "num_train_optimization_steps", "//", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "\n", "# Prepare model", "\n", "", "", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "os", ".", "path", ".", "join", "(", "str", "(", "PYTORCH_PRETRAINED_BERT_CACHE", ")", ",", "\n", "'distributed_{}'", ".", "format", "(", "args", ".", "local_rank", ")", ")", "\n", "\n", "model", "=", "BertWithDebiasLoss", ".", "from_pretrained", "(", "\n", "args", ".", "bert_model", ",", "cache_dir", "=", "cache_dir", ",", "num_labels", "=", "3", ",", "loss_fn", "=", "loss_fn", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "    ", "model", ".", "half", "(", ")", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "    ", "try", ":", "\n", "      ", "from", "apex", ".", "parallel", "import", "DistributedDataParallel", "as", "DDP", "\n", "", "except", "ImportError", ":", "\n", "      ", "raise", "ImportError", "(", "\n", "\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\"", ")", "\n", "\n", "", "model", "=", "DDP", "(", "model", ")", "\n", "", "elif", "n_gpu", ">", "1", ":", "\n", "    ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Prepare optimizer", "\n", "", "param_optimizer", "=", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "if", "args", ".", "fp16", ":", "\n", "    ", "try", ":", "\n", "      ", "from", "apex", ".", "optimizers", "import", "FP16_Optimizer", "\n", "from", "apex", ".", "optimizers", "import", "FusedAdam", "\n", "", "except", "ImportError", ":", "\n", "      ", "raise", "ImportError", "(", "\n", "\"Please install apex from https://www.github.com/nvidia/apex to use distributed and fp16 training.\"", ")", "\n", "\n", "", "optimizer", "=", "FusedAdam", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "args", ".", "learning_rate", ",", "\n", "bias_correction", "=", "False", ",", "\n", "max_grad_norm", "=", "1.0", ")", "\n", "if", "args", ".", "loss_scale", "==", "0", ":", "\n", "      ", "optimizer", "=", "FP16_Optimizer", "(", "optimizer", ",", "dynamic_loss_scale", "=", "True", ")", "\n", "", "else", ":", "\n", "      ", "optimizer", "=", "FP16_Optimizer", "(", "optimizer", ",", "static_loss_scale", "=", "args", ".", "loss_scale", ")", "\n", "\n", "", "", "else", ":", "\n", "    ", "optimizer", "=", "BertAdam", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "args", ".", "learning_rate", ",", "\n", "warmup", "=", "args", ".", "warmup_proportion", ",", "\n", "t_total", "=", "num_train_optimization_steps", ")", "\n", "\n", "", "global_step", "=", "0", "\n", "nb_tr_steps", "=", "0", "\n", "tr_loss", "=", "0", "\n", "\n", "if", "args", ".", "do_train", ":", "\n", "    ", "train_features", ":", "List", "[", "InputFeatures", "]", "=", "convert_examples_to_features", "(", "\n", "train_examples", ",", "args", ".", "max_seq_length", ",", "tokenizer", ",", "args", ".", "n_processes", ")", "\n", "\n", "bias_map", "=", "load_bias", "(", "\"train\"", ")", "\n", "for", "fe", "in", "train_features", ":", "\n", "      ", "fe", ".", "bias", "=", "bias_map", "[", "fe", ".", "example_id", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logging", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_examples", ")", ")", "\n", "logging", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "logging", ".", "info", "(", "\"  Num steps = %d\"", ",", "num_train_optimization_steps", ")", "\n", "\n", "train_dataloader", "=", "build_train_dataloader", "(", "train_features", ",", "args", ".", "train_batch_size", ",", "args", ".", "seed", ",", "args", ".", "sorted", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "loss_ema", "=", "0", "\n", "total_steps", "=", "0", "\n", "decay", "=", "0.99", "\n", "\n", "for", "_", "in", "trange", "(", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "ncols", "=", "100", ")", ":", "\n", "      ", "tr_loss", "=", "0", "\n", "nb_tr_examples", ",", "nb_tr_steps", "=", "0", ",", "0", "\n", "pbar", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"loss\"", ",", "ncols", "=", "100", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "pbar", ")", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "if", "bias_map", "is", "not", "None", ":", "\n", "          ", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", ",", "bias", "=", "batch", "\n", "", "else", ":", "\n", "          ", "bias", "=", "None", "\n", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", "=", "batch", "\n", "\n", "", "logits", ",", "loss", "=", "model", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "label_ids", ",", "bias", ")", "\n", "\n", "total_steps", "+=", "1", "\n", "loss_ema", "=", "loss_ema", "*", "decay", "+", "loss", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "*", "(", "1", "-", "decay", ")", "\n", "descript", "=", "\"loss=%.4f\"", "%", "(", "loss_ema", "/", "(", "1", "-", "decay", "**", "total_steps", ")", ")", "\n", "pbar", ".", "set_description", "(", "descript", ",", "refresh", "=", "False", ")", "\n", "\n", "if", "n_gpu", ">", "1", ":", "\n", "          ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu.", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "          ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "          ", "optimizer", ".", "backward", "(", "loss", ")", "\n", "", "else", ":", "\n", "          ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "nb_tr_examples", "+=", "input_ids", ".", "size", "(", "0", ")", "\n", "nb_tr_steps", "+=", "1", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "          ", "if", "args", ".", "fp16", ":", "\n", "# modify learning rate with special warm up BERT uses", "\n", "# if args.fp16 is False, BertAdam is used that handles this automatically", "\n", "            ", "lr_this_step", "=", "args", ".", "learning_rate", "*", "warmup_linear", "(", "global_step", "/", "num_train_optimization_steps", ",", "\n", "args", ".", "warmup_proportion", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "              ", "param_group", "[", "'lr'", "]", "=", "lr_this_step", "\n", "", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "# Save a trained model and the associated configuration", "\n", "", "", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "# Only save the model it-self", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "WEIGHTS_NAME", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_model_file", ")", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "CONFIG_NAME", ")", "\n", "with", "open", "(", "output_config_file", ",", "'w'", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "model_to_save", ".", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n", "# Record the args as well", "\n", "", "arg_dict", "=", "{", "}", "\n", "for", "arg", "in", "vars", "(", "args", ")", ":", "\n", "      ", "arg_dict", "[", "arg", "]", "=", "getattr", "(", "args", ",", "arg", ")", "\n", "", "with", "open", "(", "join", "(", "output_dir", ",", "\"args.json\"", ")", ",", "'w'", ")", "as", "out_fh", ":", "\n", "      ", "json", ".", "dump", "(", "arg_dict", ",", "out_fh", ")", "\n", "\n", "# Load a trained model and config that you have fine-tuned", "\n", "", "config", "=", "BertConfig", "(", "output_config_file", ")", "\n", "model", "=", "BertWithDebiasLoss", "(", "config", ",", "num_labels", "=", "3", ",", "loss_fn", "=", "loss_fn", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_model_file", ")", ")", "\n", "", "else", ":", "\n", "    ", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "CONFIG_NAME", ")", "\n", "config", "=", "BertConfig", ".", "from_json_file", "(", "output_config_file", ")", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "WEIGHTS_NAME", ")", "\n", "model", "=", "BertWithDebiasLoss", "(", "config", ",", "num_labels", "=", "3", ",", "loss_fn", "=", "loss_fn", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_model_file", ")", ")", "\n", "\n", "", "model", ".", "to", "(", "device", ")", "\n", "\n", "if", "not", "args", ".", "do_eval", ":", "\n", "    ", "return", "\n", "", "if", "not", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "    ", "return", "\n", "\n", "", "model", ".", "eval", "(", ")", "\n", "\n", "eval_datasets", "=", "[", "(", "\"dev\"", ",", "load_mnli", "(", "False", ")", ")", ",", "(", "\"hans\"", ",", "load_hans", "(", ")", ")", "]", "\n", "for", "name", ",", "eval_examples", "in", "eval_datasets", ":", "\n", "    ", "logging", ".", "info", "(", "\"***** Running evaluation on %s *****\"", "%", "name", ")", "\n", "logging", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_examples", ")", ")", "\n", "logging", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_features", "=", "convert_examples_to_features", "(", "\n", "eval_examples", ",", "args", ".", "max_seq_length", ",", "tokenizer", ")", "\n", "eval_features", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", ".", "input_ids", ")", ")", "\n", "all_label_ids", "=", "np", ".", "array", "(", "[", "x", ".", "label_id", "for", "x", "in", "eval_features", "]", ")", "\n", "eval_dataloader", "=", "build_eval_dataloader", "(", "eval_features", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "eval_loss", "=", "0", "\n", "nb_eval_steps", "=", "0", "\n", "probs", "=", "[", "]", "\n", "\n", "for", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ",", "ncols", "=", "100", ")", ":", "\n", "      ", "input_ids", "=", "input_ids", ".", "to", "(", "device", ")", "\n", "input_mask", "=", "input_mask", ".", "to", "(", "device", ")", "\n", "segment_ids", "=", "segment_ids", ".", "to", "(", "device", ")", "\n", "label_ids", "=", "label_ids", ".", "to", "(", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "logits", "=", "model", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "\n", "# create eval loss and other metric required by the task", "\n", "", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "tmp_eval_loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "3", ")", ",", "label_ids", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "nb_eval_steps", "+=", "1", "\n", "probs", ".", "append", "(", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "logits", ",", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "probs", "=", "np", ".", "concatenate", "(", "probs", ",", "0", ")", "\n", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "\n", "if", "name", "==", "\"hans\"", ":", "\n", "      ", "probs", "[", ":", ",", "0", "]", "+=", "probs", "[", ":", ",", "2", "]", "\n", "probs", "=", "probs", "[", ":", ",", ":", "2", "]", "\n", "\n", "", "preds", "=", "np", ".", "argmax", "(", "probs", ",", "axis", "=", "1", ")", "\n", "\n", "result", "=", "{", "\"acc\"", ":", "simple_accuracy", "(", "preds", ",", "all_label_ids", ")", "}", "\n", "loss", "=", "tr_loss", "/", "nb_tr_steps", "if", "args", ".", "do_train", "else", "None", "\n", "\n", "result", "[", "'eval_loss'", "]", "=", "eval_loss", "\n", "result", "[", "'global_step'", "]", "=", "global_step", "\n", "result", "[", "'loss'", "]", "=", "loss", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"eval_%s_results.txt\"", "%", "name", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "      ", "logging", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "output_answer_file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"eval_%s_answers.json\"", "%", "name", ")", "\n", "answers", "=", "{", "ex", ".", "example_id", ":", "[", "float", "(", "x", ")", "for", "x", "in", "p", "]", "for", "ex", ",", "p", "in", "zip", "(", "eval_features", ",", "probs", ")", "}", "\n", "with", "open", "(", "output_answer_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "      ", "json", ".", "dump", "(", "answers", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.clf_debias_loss_functions.ClfDebiasLossFunction.forward": [[9, 18], ["NotImplementedError"], "methods", ["None"], ["\n", "def", "compute_clf_loss", "(", "self", ",", "hidden", ",", "logits", ",", "bias", ",", "labels", ")", ":", "\n", "    ", "\"\"\"\n    :param hidden: [batch, n_hidden] hidden units from the model\n    :param logits: [batch, n_classes] per-class logit scores\n    :param bias: [batch, n_classes] per-class log-probabilities from the bias\n    :param labels: [batch] labels\n    :return: scalar loss\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.clf_debias_loss_functions.Plain.forward": [[21, 23], ["torch.nn.functional.cross_entropy"], "methods", ["None"], ["", "", "class", "Plain", "(", "ClfDebiasLossFunction", ")", ":", "\n", "  ", "def", "compute_clf_loss", "(", "self", ",", "hidden", ",", "logits", ",", "bias", ",", "labels", ",", "mask", "=", "None", ")", ":", "\n", "    ", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", "=", "logits", ",", "labels", "=", "labels", ")", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.clf_debias_loss_functions.ReweightByInvBias.forward": [[26, 32], ["logits.float.float.float", "torch.nn.functional.cross_entropy", "torch.eye().cuda", "weights.sum", "torch.eye", "logits.float.float.size", "torch.exp"], "methods", ["None"], ["\n", "", "", "class", "Reweight", "(", "ClfDebiasLossFunction", ")", ":", "\n", "  ", "def", "compute_clf_loss", "(", "self", ",", "hidden", ",", "logits", ",", "bias", ",", "labels", ",", "mask", "=", "None", ")", ":", "\n", "    ", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", "=", "logits", ",", "labels", "=", "labels", ")", "\n", "label_one_hot", "=", "tf", ".", "one_hot", "(", "labels", ",", "ops", ".", "get_shape_tuple", "(", "logits", ",", "1", ")", ")", "\n", "weights", "=", "1", "-", "tf", ".", "reduce_sum", "(", "tf", ".", "exp", "(", "bias", ")", "*", "label_one_hot", ",", "1", ")", "\n", "return", "tf", ".", "reduce_sum", "(", "weights", "*", "loss", ")", "/", "tf", ".", "reduce_sum", "(", "weights", ")", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.clf_debias_loss_functions.BiasProduct.forward": [[35, 39], ["torch.nn.functional.log_softmax.float", "torch.nn.functional.log_softmax", "torch.nn.functional.cross_entropy", "bias.float"], "methods", ["None"], ["", "", "class", "BiasProduct", "(", "ClfDebiasLossFunction", ")", ":", "\n", "  ", "def", "compute_clf_loss", "(", "self", ",", "hidden", ",", "logits", ",", "bias", ",", "labels", ")", ":", "\n", "    ", "logits", "=", "tf", ".", "nn", ".", "log_softmax", "(", "logits", ")", "\n", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", "=", "logits", "+", "bias", ",", "labels", "=", "labels", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "loss", ")", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.clf_debias_loss_functions.LearnedMixin.__init__": [[43, 47], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.bert.clf_debias_loss_functions.LearnedMixin.__init__"], ["  ", "def", "__init__", "(", "self", ",", "w", ")", ":", "\n", "    ", "self", ".", "w", "=", "w", "\n", "\n", "", "def", "compute_clf_loss", "(", "self", ",", "hidden", ",", "logits", ",", "bias", ",", "labels", ")", ":", "\n", "    ", "logits", "=", "tf", ".", "nn", ".", "log_softmax", "(", "logits", ")", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.bert.clf_debias_loss_functions.LearnedMixin.forward": [[48, 63], ["torch.nn.functional.log_softmax.float", "torch.nn.functional.log_softmax", "clf_debias_loss_functions.LearnedMixin.bias_lin.forward", "torch.nn.functional.softplus.float", "torch.nn.functional.softplus", "torch.nn.functional.log_softmax", "torch.nn.functional.cross_entropy", "torch.exp"], "methods", ["home.repos.pwc.inspect_result.chrisc36_debias.bert.clf_debias_loss_functions.LearnedMixin.forward"], ["\n", "factor", "=", "tf", ".", "get_variable", "(", "\"factor-b\"", ",", "(", ")", ")", "\n", "factor", "+=", "ops", ".", "last_dim_weighted_sum", "(", "hidden", ",", "\"scale-w\"", ")", "\n", "factor", "=", "tf", ".", "nn", ".", "softplus", "(", "factor", ")", "\n", "bias", "*=", "tf", ".", "expand_dims", "(", "factor", ",", "1", ")", "\n", "\n", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", "+", "bias", ",", "labels", "=", "labels", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "\n", "if", "self", ".", "w", "==", "0", ":", "\n", "      ", "return", "loss", "\n", "\n", "", "loss", "+=", "self", ".", "w", "*", "ops", ".", "entropy", "(", "bias", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_loader.get_qtypes": [[4, 25], ["ValueError", "ValueError", "RuntimeError"], "function", ["None"], ["def", "get_qtypes", "(", "dataset_name", ",", "part", ")", ":", "\n", "  ", "\"\"\"Return list of question-types for a particular TriviaQA-CP dataset\"\"\"", "\n", "if", "dataset_name", "not", "in", "{", "\"location\"", ",", "\"person\"", "}", ":", "\n", "    ", "raise", "ValueError", "(", "\"Unknown dataset %s\"", "%", "dataset_name", ")", "\n", "\n", "", "if", "part", "not", "in", "{", "\"train\"", ",", "\"dev\"", ",", "\"test\"", "}", ":", "\n", "    ", "raise", "ValueError", "(", "\"Unknown part %s\"", "%", "part", ")", "\n", "\n", "", "is_biased", "=", "part", "in", "{", "\"train\"", ",", "\"dev\"", "}", "\n", "is_location", "=", "dataset_name", "==", "\"location\"", "\n", "\n", "if", "is_biased", "and", "is_location", ":", "\n", "    ", "return", "[", "\"person\"", ",", "\"other\"", "]", "\n", "", "elif", "not", "is_biased", "and", "is_location", ":", "\n", "    ", "return", "[", "\"location\"", "]", "\n", "", "elif", "is_biased", "and", "not", "is_location", ":", "\n", "    ", "return", "[", "\"location\"", ",", "\"other\"", "]", "\n", "", "elif", "not", "is_biased", "and", "not", "is_location", ":", "\n", "    ", "return", "[", "\"person\"", "]", "\n", "", "else", ":", "\n", "    ", "raise", "RuntimeError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_loader.load_triviaqa_cp": [[27, 59], ["triviaqa_cp_loader.get_qtypes", "open", "json.load", "ValueError", "ValueError", "ValueError", "out.append"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_loader.get_qtypes", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadLoader.load"], ["", "", "def", "load_triviaqa_cp", "(", "filename", ",", "dataset_name", ",", "part", ",", "expected_version", "=", "None", ")", ":", "\n", "  ", "\"\"\"Load a TriviaQA-CP dataset\n\n  :param filename: The TriviaQA-CP train or dev json file, must be the train file if\n                   if `part`==\"train\" and the dev file otherwise\n  :param dataset_name: dataset to load, must be in [\"person\", \"location\"]\n  :param part: which part, must be in [\"test\", \"dev\", \"train\"[\n  :param expected_version: Optional version to require the data to match\n  :return: List of question in dictionary form\n  \"\"\"", "\n", "target_qtypes", "=", "get_qtypes", "(", "dataset_name", ",", "part", ")", "\n", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "    ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "expected_version", "is", "not", "None", ":", "\n", "    ", "if", "expected_version", "!=", "data", "[", "\"Version\"", "]", ":", "\n", "      ", "raise", "ValueError", "(", "\"Expected version %s, but data was version %s\"", "%", "(", "\n", "expected_version", ",", "data", "[", "\"Version\"", "]", ")", ")", "\n", "\n", "", "", "if", "part", "==", "\"train\"", ":", "\n", "    ", "if", "data", "[", "\"Split\"", "]", "!=", "\"Train\"", ":", "\n", "      ", "raise", "ValueError", "(", "\"Expected train file, but split is %s\"", "%", "data", "[", "\"Split\"", "]", ")", "\n", "", "", "else", ":", "\n", "    ", "if", "data", "[", "\"Split\"", "]", "!=", "\"Dev\"", ":", "\n", "      ", "raise", "ValueError", "(", "\"Expected dev file, but split is %s\"", "%", "data", "[", "\"Split\"", "]", ")", "\n", "\n", "", "", "out", "=", "[", "]", "\n", "for", "question", "in", "data", "[", "\"Data\"", "]", ":", "\n", "    ", "if", "question", "[", "\"QuestionType\"", "]", "in", "target_qtypes", ":", "\n", "      ", "out", ".", "append", "(", "question", ")", "\n", "", "", "return", "out", "\n", "", ""]], "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer": [[17, 37], ["white_space_fix().strip", "re.sub", "set", "text.lower", "text.replace", "text.split", "triviaqa_cp_evaluation.normalize_answer.white_space_fix"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split"], ["def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "handle_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", "+", "\"\"", ".", "join", "(", "[", "u\"\u2018\"", ",", "u\"\u2019\"", ",", "u\"\u00b4\"", ",", "u\"`\"", "]", ")", ")", "\n", "return", "''", ".", "join", "(", "ch", "if", "ch", "not", "in", "exclude", "else", "' '", "for", "ch", "in", "text", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "def", "replace_underscore", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "replace", "(", "'_'", ",", "' '", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "handle_punc", "(", "lower", "(", "replace_underscore", "(", "s", ")", ")", ")", ")", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.f1_score": [[39, 50], ["normalize_answer().split", "normalize_answer().split", "sum", "collections.Counter", "collections.Counter", "common.values", "len", "len", "triviaqa_cp_evaluation.normalize_answer", "triviaqa_cp_evaluation.normalize_answer"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split", "home.repos.pwc.inspect_result.chrisc36_debias.utils.py_utils.split", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer"], ["", "def", "f1_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "prediction_tokens", "=", "normalize_answer", "(", "prediction", ")", ".", "split", "(", ")", "\n", "ground_truth_tokens", "=", "normalize_answer", "(", "ground_truth", ")", ".", "split", "(", ")", "\n", "common", "=", "Counter", "(", "prediction_tokens", ")", "&", "Counter", "(", "ground_truth_tokens", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "prediction_tokens", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "ground_truth_tokens", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.exact_match_score": [[52, 54], ["triviaqa_cp_evaluation.normalize_answer", "triviaqa_cp_evaluation.normalize_answer"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer"], ["", "def", "exact_match_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "return", "normalize_answer", "(", "prediction", ")", "==", "normalize_answer", "(", "ground_truth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.metric_max_over_ground_truths": [[56, 62], ["max", "scores_for_ground_truths.append", "triviaqa_cp_evaluation.exact_match_score", "triviaqa_cp_evaluation.f1_score"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.exact_match_score", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.f1_score"], ["", "def", "metric_max_over_ground_truths", "(", "metric_fn", ",", "prediction", ",", "ground_truths", ")", ":", "\n", "    ", "scores_for_ground_truths", "=", "[", "]", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "score", "=", "metric_fn", "(", "prediction", ",", "ground_truth", ")", "\n", "scores_for_ground_truths", ".", "append", "(", "score", ")", "\n", "", "return", "max", "(", "scores_for_ground_truths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.is_exact_match": [[64, 70], ["triviaqa_cp_evaluation.get_ground_truths", "triviaqa_cp_evaluation.exact_match_score"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.get_ground_truths", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.exact_match_score"], ["", "def", "is_exact_match", "(", "answer_object", ",", "prediction", ")", ":", "\n", "    ", "ground_truths", "=", "get_ground_truths", "(", "answer_object", ")", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "if", "exact_match_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "            ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.has_exact_match": [[72, 77], ["None"], "function", ["None"], ["", "def", "has_exact_match", "(", "ground_truths", ",", "candidates", ")", ":", "\n", "    ", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "if", "ground_truth", "in", "candidates", ":", "\n", "            ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.get_ground_truths": [[79, 81], ["triviaqa_cp_evaluation.normalize_answer", "answer.get"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer"], ["", "def", "get_ground_truths", "(", "answer", ")", ":", "\n", "    ", "return", "answer", "[", "'NormalizedAliases'", "]", "+", "[", "normalize_answer", "(", "ans", ")", "for", "ans", "in", "answer", ".", "get", "(", "'HumanAnswers'", ",", "[", "]", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.get_oracle_score": [[83, 103], ["ground_truth.keys", "triviaqa_cp_evaluation.normalize_answer", "triviaqa_cp_evaluation.get_ground_truths", "triviaqa_cp_evaluation.has_exact_match", "int", "len", "len", "len", "len", "print"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.normalize_answer", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.get_ground_truths", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.has_exact_match"], ["", "def", "get_oracle_score", "(", "ground_truth", ",", "predicted_answers", ",", "qid_list", "=", "None", ",", "mute", "=", "False", ")", ":", "\n", "    ", "exact_match", "=", "common", "=", "0", "\n", "if", "qid_list", "is", "None", ":", "\n", "        ", "qid_list", "=", "ground_truth", ".", "keys", "(", ")", "\n", "", "for", "qid", "in", "qid_list", ":", "\n", "        ", "if", "qid", "not", "in", "predicted_answers", ":", "\n", "            ", "if", "not", "mute", ":", "\n", "                ", "message", "=", "'Irrelavant question {} will receive score 0.'", ".", "format", "(", "qid", ")", "\n", "print", "(", "message", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "", "continue", "\n", "", "common", "+=", "1", "\n", "prediction", "=", "normalize_answer", "(", "predicted_answers", "[", "qid", "]", ")", "\n", "ground_truths", "=", "get_ground_truths", "(", "ground_truth", "[", "qid", "]", ")", "\n", "em_for_this_question", "=", "has_exact_match", "(", "ground_truths", ",", "prediction", ")", "\n", "exact_match", "+=", "int", "(", "em_for_this_question", ")", "\n", "\n", "", "exact_match", "=", "100.0", "*", "exact_match", "/", "len", "(", "qid_list", ")", "\n", "\n", "return", "{", "'oracle_exact_match'", ":", "exact_match", ",", "'common'", ":", "common", ",", "'denominator'", ":", "len", "(", "qid_list", ")", ",", "\n", "'pred_len'", ":", "len", "(", "predicted_answers", ")", ",", "'gold_len'", ":", "len", "(", "ground_truth", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.evaluate_triviaqa": [[105, 137], ["ground_truth.keys", "triviaqa_cp_evaluation.get_ground_truths", "triviaqa_cp_evaluation.metric_max_over_ground_truths", "triviaqa_cp_evaluation.metric_max_over_ground_truths", "len", "len", "len", "len", "len", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.get_ground_truths", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.metric_max_over_ground_truths"], ["", "def", "evaluate_triviaqa", "(", "ground_truth", ",", "predicted_answers", ",", "qid_list", "=", "None", ",", "mute", "=", "False", ")", ":", "\n", "    ", "f1", "=", "exact_match", "=", "common", "=", "0", "\n", "if", "qid_list", "is", "None", ":", "\n", "        ", "qid_list", "=", "ground_truth", ".", "keys", "(", ")", "\n", "", "for", "qid", "in", "qid_list", ":", "\n", "        ", "if", "qid", "not", "in", "predicted_answers", ":", "\n", "            ", "if", "not", "mute", ":", "\n", "                ", "message", "=", "'Missed question {} will receive score 0.'", ".", "format", "(", "qid", ")", "\n", "print", "(", "message", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "", "continue", "\n", "", "if", "qid", "not", "in", "ground_truth", ":", "\n", "            ", "if", "not", "mute", ":", "\n", "                ", "message", "=", "'Irrelavant question {} will receive score 0.'", ".", "format", "(", "qid", ")", "\n", "print", "(", "message", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "", "continue", "\n", "", "common", "+=", "1", "\n", "prediction", "=", "predicted_answers", "[", "qid", "]", "\n", "ground_truths", "=", "get_ground_truths", "(", "ground_truth", "[", "qid", "]", ")", "\n", "em_for_this_question", "=", "metric_max_over_ground_truths", "(", "\n", "exact_match_score", ",", "prediction", ",", "ground_truths", ")", "\n", "if", "em_for_this_question", "==", "0", "and", "not", "mute", ":", "\n", "            ", "print", "(", "\"em=0:\"", ",", "prediction", ",", "ground_truths", ")", "\n", "", "exact_match", "+=", "em_for_this_question", "\n", "f1_for_this_question", "=", "metric_max_over_ground_truths", "(", "\n", "f1_score", ",", "prediction", ",", "ground_truths", ")", "\n", "f1", "+=", "f1_for_this_question", "\n", "\n", "", "exact_match", "=", "100.0", "*", "exact_match", "/", "len", "(", "qid_list", ")", "\n", "f1", "=", "100.0", "*", "f1", "/", "len", "(", "qid_list", ")", "\n", "\n", "return", "{", "'exact_match'", ":", "exact_match", ",", "'f1'", ":", "f1", ",", "'common'", ":", "common", ",", "'denominator'", ":", "len", "(", "qid_list", ")", ",", "\n", "'pred_len'", ":", "len", "(", "predicted_answers", ")", ",", "'gold_len'", ":", "len", "(", "ground_truth", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.main": [[139, 158], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "triviaqa_cp.triviaqa_cp_loader.load_triviaqa_cp", "triviaqa_cp_evaluation.evaluate_triviaqa", "print", "open", "json.load", "json.dumps"], "function", ["home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_loader.load_triviaqa_cp", "home.repos.pwc.inspect_result.chrisc36_debias.triviaqa_cp.triviaqa_cp_evaluation.evaluate_triviaqa", "home.repos.pwc.inspect_result.chrisc36_debias.datasets.squad.AnnotatedSquadLoader.load"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'Evaluation for TriviaQA-CP {}'", ".", "format", "(", "EXPECTED_VERSION", ")", ")", "\n", "parser", ".", "add_argument", "(", "'dataset_file'", ",", "help", "=", "'TriviaQA-CP dev file'", ")", "\n", "parser", ".", "add_argument", "(", "'prediction_file'", ",", "help", "=", "'File with a json dictionary of '", "\n", "'question_id->predicted answers'", ")", "\n", "parser", ".", "add_argument", "(", "'dataset_name'", ",", "choices", "=", "[", "\"location\"", ",", "\"person\"", "]", ",", "\n", "help", "=", "'Which dataset to evaluate on'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "test_questions", "=", "load_triviaqa_cp", "(", "\n", "args", ".", "dataset_file", ",", "False", ",", "args", ".", "dataset_name", ",", "EXPECTED_VERSION", ")", "\n", "ground_truth", "=", "{", "x", "[", "'QuestionId'", "]", ":", "x", "[", "'Answer'", "]", "for", "x", "in", "test_questions", "}", "\n", "\n", "with", "open", "(", "args", ".", "prediction_file", ")", "as", "f", ":", "\n", "      ", "predictions", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "eval_dict", "=", "evaluate_triviaqa", "(", "ground_truth", ",", "predictions", ")", "\n", "print", "(", "json", ".", "dumps", "(", "eval_dict", ",", "indent", "=", "2", ")", ")", "\n", "\n"]]}