{"home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.models.DataConsistencyLayer.__init__": [[56, 62], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.dataset.SliceDisplayDataDev.__init__"], ["    ", "def", "__init__", "(", "self", ",", "us_mask_path", ",", "device", ")", ":", "\n", "\n", "        ", "super", "(", "DataConsistencyLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "us_mask_path", "=", "us_mask_path", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.models.DataConsistencyLayer.forward": [[63, 89], ["os.path.join", "torch.from_numpy().unsqueeze().unsqueeze().to", "torch.from_numpy().unsqueeze().unsqueeze().to", "torch.from_numpy().unsqueeze().unsqueeze().to", "torch.from_numpy().unsqueeze().unsqueeze().to", "torch.from_numpy().unsqueeze().unsqueeze().to", "torch.from_numpy().unsqueeze().unsqueeze().to", "torch.from_numpy().unsqueeze().unsqueeze().to", "torch.from_numpy().unsqueeze().unsqueeze().to", "torch.from_numpy().unsqueeze().unsqueeze().to", "torch.rfft().double", "torch.rfft().double", "torch.rfft().double", "torch.rfft().double", "torch.rfft().double", "torch.rfft().double", "torch.rfft().double", "torch.rfft().double", "torch.rfft().double", "torch.ifft", "torch.ifft", "torch.ifft", "torch.ifft", "torch.ifft", "torch.ifft", "torch.ifft", "torch.ifft", "torch.ifft", "update_img_abs.unsqueeze.unsqueeze.unsqueeze", "update_img_abs.unsqueeze.unsqueeze.float", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.load"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "predicted_img", ",", "us_kspace", ",", "acc_factor", ",", "mask_string", ",", "dataset_string", ")", ":", "\n", "\n", "        ", "us_mask_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "us_mask_path", ",", "dataset_string", ",", "mask_string", ",", "'mask_{}.npy'", ".", "format", "(", "acc_factor", ")", ")", "\n", "#print(\"us_mask_path: \", us_mask_path)", "\n", "us_mask", "=", "torch", ".", "from_numpy", "(", "np", ".", "load", "(", "us_mask_path", ")", ")", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# us_kspace     = us_kspace[:,0,:,:]", "\n", "predicted_img", "=", "predicted_img", "[", ":", ",", "0", ",", ":", ",", ":", "]", "\n", "\n", "kspace_predicted_img", "=", "torch", ".", "rfft", "(", "predicted_img", ",", "2", ",", "True", ",", "False", ")", ".", "double", "(", ")", "\n", "#print (us_kspace.shape,predicted_img.shape,kspace_predicted_img.shape,self.us_mask.shape)", "\n", "#print(us_mask.dtype)", "\n", "updated_kspace1", "=", "us_mask", "*", "us_kspace", "\n", "updated_kspace2", "=", "(", "1", "-", "us_mask", ")", "*", "kspace_predicted_img", "\n", "\n", "updated_kspace", "=", "updated_kspace1", "+", "updated_kspace2", "\n", "\n", "\n", "updated_img", "=", "torch", ".", "ifft", "(", "updated_kspace", ",", "2", ",", "True", ")", "\n", "\n", "#update_img_abs = torch.sqrt(updated_img[:,:,:,0]**2 + updated_img[:,:,:,1]**2)", "\n", "update_img_abs", "=", "updated_img", "[", ":", ",", ":", ",", ":", ",", "0", "]", "# taking real part only, change done on Sep 18 '19 bcos taking abs till bring in the distortion due to imag part also. this was verified was done by simple experiment on FFT, mask and IFFT", "\n", "\n", "update_img_abs", "=", "update_img_abs", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "return", "update_img_abs", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.models.MACReconNet.__init__": [[92, 124], ["torch.Module.__init__", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "models.DataConsistencyLayer", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "numpy.prod", "numpy.prod", "numpy.prod", "numpy.prod", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.dataset.SliceDisplayDataDev.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "n_ch", "=", "1", ")", ":", "\n", "\n", "        ", "super", "(", "MACReconNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "weights", "=", "{", "'fc1'", ":", "[", "32", ",", "1", ",", "3", ",", "3", "]", ",", "\n", "'fc2'", ":", "[", "32", ",", "32", ",", "3", ",", "3", "]", ",", "\n", "'fc3'", ":", "[", "32", ",", "32", ",", "3", ",", "3", "]", ",", "\n", "'fc4'", ":", "[", "32", ",", "32", ",", "3", ",", "3", "]", ",", "\n", "'fc5'", ":", "[", "1", ",", "32", ",", "3", ",", "3", "]", "}", "\n", "\n", "\n", "cascade", "=", "nn", ".", "ModuleDict", "(", "{", "\n", "'fc1'", ":", "nn", ".", "Linear", "(", "3", ",", "np", ".", "prod", "(", "self", ".", "weights", "[", "'fc1'", "]", ")", ")", ",", "\n", "'fc2'", ":", "nn", ".", "Linear", "(", "3", ",", "np", ".", "prod", "(", "self", ".", "weights", "[", "'fc2'", "]", ")", ")", ",", "\n", "'fc3'", ":", "nn", ".", "Linear", "(", "3", ",", "np", ".", "prod", "(", "self", ".", "weights", "[", "'fc3'", "]", ")", ")", ",", "\n", "'fc4'", ":", "nn", ".", "Linear", "(", "3", ",", "np", ".", "prod", "(", "self", ".", "weights", "[", "'fc4'", "]", ")", ")", ",", "\n", "'fc5'", ":", "nn", ".", "Linear", "(", "3", ",", "np", ".", "prod", "(", "self", ".", "weights", "[", "'fc5'", "]", ")", ")", "}", ")", "\n", "\n", "instance_norm", "=", "nn", ".", "ModuleDict", "(", "{", "\n", "'fc1'", ":", "nn", ".", "InstanceNorm2d", "(", "32", ",", "affine", "=", "True", ")", ",", "\n", "'fc2'", ":", "nn", ".", "InstanceNorm2d", "(", "32", ",", "affine", "=", "True", ")", ",", "\n", "'fc3'", ":", "nn", ".", "InstanceNorm2d", "(", "32", ",", "affine", "=", "True", ")", ",", "\n", "'fc4'", ":", "nn", ".", "InstanceNorm2d", "(", "32", ",", "affine", "=", "True", ")", "}", ")", "\n", "dc", "=", "DataConsistencyLayer", "(", "args", ".", "usmask_path", ",", "args", ".", "device", ")", "\n", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "cascade", "]", ")", "\n", "#print(self.layer[0].keys())", "\n", "self", ".", "instance_norm", "=", "nn", ".", "ModuleList", "(", "[", "instance_norm", "]", ")", "\n", "\n", "self", ".", "dc", "=", "nn", ".", "ModuleList", "(", "[", "dc", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.models.MACReconNet.forward": [[126, 155], ["x.size", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.MACReconNet.unsqueeze", "models.MACReconNet.layer[].keys", "batch_outputs.append", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.conv2d", "torch.conv2d", "torch.conv2d", "models.MACReconNet.relu", "torch.conv2d", "torch.conv2d", "torch.conv2d"], "methods", ["home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.models.relu"], ["", "def", "forward", "(", "self", ",", "x", ",", "k", ",", "gamma_val", ",", "acc_string", ",", "mask_string", ",", "dataset_string", ")", ":", "\n", "#def forward(self,x, acc):", "\n", "#print(\"x enter: \", x.size())", "\n", "        ", "batch_size", "=", "x", ".", "size", "(", "0", ")", "\n", "batch_outputs", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "xout", "=", "x", "[", "n", "]", "\n", "xout", "=", "xout", ".", "unsqueeze", "(", "0", ")", "\n", "#print(\"xout shape in: \",xout.shape)", "\n", "xtemp", "=", "xout", "\n", "\n", "for", "fc_no", "in", "self", ".", "layer", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "#print(fc_no)    ", "\n", "                ", "conv_weight", "=", "self", ".", "layer", "[", "0", "]", "[", "fc_no", "]", "(", "gamma_val", "[", "n", "]", ")", "\n", "conv_weight", "=", "torch", ".", "reshape", "(", "conv_weight", ",", "self", ".", "weights", "[", "fc_no", "]", ")", "\n", "\n", "if", "fc_no", "==", "'fc5'", ":", "\n", "                    ", "xout", "=", "F", ".", "conv2d", "(", "xout", ",", "conv_weight", ",", "bias", "=", "None", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "", "else", ":", "\n", "                    ", "xout", "=", "self", ".", "relu", "(", "self", ".", "instance_norm", "[", "0", "]", "[", "fc_no", "]", "(", "F", ".", "conv2d", "(", "xout", ",", "conv_weight", ",", "bias", "=", "None", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ")", ")", "\n", "#print(\"xout shape: \",xout.shape)", "\n", "\n", "", "", "xout", "=", "xout", "+", "xtemp", "\n", "xout", "=", "self", ".", "dc", "[", "0", "]", "(", "xout", ",", "k", "[", "n", "]", ",", "acc_string", "[", "n", "]", ",", "mask_string", "[", "n", "]", ",", "dataset_string", "[", "n", "]", ")", "\n", "\n", "#print(\"xout shape out: \",xout.shape)", "\n", "batch_outputs", ".", "append", "(", "xout", ")", "\n", "", "output", "=", "torch", ".", "cat", "(", "batch_outputs", ",", "dim", "=", "0", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.models.DC_CNN.__init__": [[159, 177], ["torch.Module.__init__", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "models.MACReconNet", "cnn_blocks.append"], "methods", ["home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.dataset.SliceDisplayDataDev.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "checkpoint_file", ",", "n_ch", "=", "1", ",", "nc", "=", "5", ")", ":", "\n", "#def __init__(self, args, n_ch=1,nc=5):", "\n", "\n", "        ", "super", "(", "DC_CNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "cnn_blocks", "=", "[", "]", "\n", "#dc_blocks = []", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_file", ")", "\n", "self", ".", "nc", "=", "nc", "\n", "\n", "for", "ii", "in", "range", "(", "self", ".", "nc", ")", ":", "\n", "\n", "            ", "cnn", "=", "MACReconNet", "(", "args", ")", "\n", "#cnn.load_state_dict(checkpoint['model'])  # uncomment this line to load the best model of MACReconNet", "\n", "cnn_blocks", ".", "append", "(", "cnn", ")", "\n", "\n", "\n", "", "self", ".", "cnn_blocks", "=", "nn", ".", "ModuleList", "(", "cnn_blocks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.models.DC_CNN.forward": [[178, 183], ["range"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "k", ",", "gamma_val", ",", "acc_string", ",", "mask_string", ",", "dataset_string", ")", ":", "\n", "        ", "x_cnn", "=", "x", "\n", "for", "i", "in", "range", "(", "self", ".", "nc", ")", ":", "\n", "            ", "x_cnn", "=", "self", ".", "cnn_blocks", "[", "i", "]", "(", "x_cnn", ",", "k", ",", "gamma_val", ",", "acc_string", ",", "mask_string", ",", "dataset_string", ")", "\n", "", "return", "x_cnn", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.models.lrelu": [[8, 10], ["torch.LeakyReLU"], "function", ["None"], ["def", "lrelu", "(", ")", ":", "\n", "    ", "return", "nn", ".", "LeakyReLU", "(", "0.01", ",", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.models.relu": [[11, 13], ["torch.ReLU"], "function", ["None"], ["", "def", "relu", "(", ")", ":", "\n", "    ", "return", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.models.conv_block": [[14, 53], ["conv", "conv", "range", "torch.Sequential", "conv", "nll", "layers.append", "models.conv_block.conv_i"], "function", ["None"], ["", "def", "conv_block", "(", "n_ch", ",", "nd", ",", "nf", "=", "32", ",", "ks", "=", "3", ",", "dilation", "=", "1", ",", "bn", "=", "False", ",", "nl", "=", "'lrelu'", ",", "conv_dim", "=", "2", ",", "n_out", "=", "None", ")", ":", "\n", "\n", "# convolution dimension (2D or 3D)", "\n", "    ", "if", "conv_dim", "==", "2", ":", "\n", "        ", "conv", "=", "nn", ".", "Conv2d", "\n", "", "else", ":", "\n", "        ", "conv", "=", "nn", ".", "Conv3d", "\n", "\n", "# output dim: If None, it is assumed to be the same as n_ch", "\n", "", "if", "not", "n_out", ":", "\n", "        ", "n_out", "=", "n_ch", "\n", "\n", "# dilated convolution", "\n", "", "pad_conv", "=", "1", "\n", "if", "dilation", ">", "1", ":", "\n", "# in = floor(in + 2*pad - dilation * (ks-1) - 1)/stride + 1)", "\n", "# pad = dilation", "\n", "        ", "pad_dilconv", "=", "dilation", "\n", "", "else", ":", "\n", "        ", "pad_dilconv", "=", "pad_conv", "\n", "\n", "", "def", "conv_i", "(", ")", ":", "\n", "        ", "return", "conv", "(", "nf", ",", "nf", ",", "ks", ",", "stride", "=", "1", ",", "padding", "=", "pad_dilconv", ",", "dilation", "=", "dilation", ",", "bias", "=", "True", ")", "\n", "\n", "", "conv_1", "=", "conv", "(", "n_ch", ",", "nf", ",", "ks", ",", "stride", "=", "1", ",", "padding", "=", "pad_conv", ",", "bias", "=", "True", ")", "\n", "conv_n", "=", "conv", "(", "nf", ",", "n_out", ",", "ks", ",", "stride", "=", "1", ",", "padding", "=", "pad_conv", ",", "bias", "=", "True", ")", "\n", "\n", "# relu", "\n", "nll", "=", "relu", "if", "nl", "==", "'relu'", "else", "lrelu", "\n", "\n", "layers", "=", "[", "conv_1", ",", "nll", "(", ")", "]", "\n", "for", "i", "in", "range", "(", "nd", "-", "2", ")", ":", "\n", "        ", "if", "bn", ":", "\n", "            ", "layers", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "nf", ")", ")", "\n", "", "layers", "+=", "[", "conv_i", "(", ")", ",", "nll", "(", ")", "]", "\n", "\n", "", "layers", "+=", "[", "conv_n", "]", "\n", "\n", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.measures_csv.mse": [[12, 15], ["numpy.mean"], "function", ["None"], ["def", "mse", "(", "gt", ",", "pred", ")", ":", "\n", "    ", "\"\"\" Compute Mean Squared Error (MSE) \"\"\"", "\n", "return", "np", ".", "mean", "(", "(", "gt", "-", "pred", ")", "**", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.measures_csv.nmse": [[17, 20], ["numpy.linalg.norm", "numpy.linalg.norm"], "function", ["None"], ["", "def", "nmse", "(", "gt", ",", "pred", ")", ":", "\n", "    ", "\"\"\" Compute Normalized Mean Squared Error (NMSE) \"\"\"", "\n", "return", "np", ".", "linalg", ".", "norm", "(", "gt", "-", "pred", ")", "**", "2", "/", "np", ".", "linalg", ".", "norm", "(", "gt", ")", "**", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.measures_csv.psnr": [[22, 25], ["skimage.measure.compare_psnr", "gt.max"], "function", ["None"], ["", "def", "psnr", "(", "gt", ",", "pred", ")", ":", "\n", "    ", "\"\"\" Compute Peak Signal to Noise Ratio metric (PSNR) \"\"\"", "\n", "return", "compare_psnr", "(", "gt", ",", "pred", ",", "data_range", "=", "gt", ".", "max", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.measures_csv.ssim": [[27, 30], ["skimage.measure.compare_ssim", "gt.max"], "function", ["None"], ["", "def", "ssim", "(", "gt", ",", "pred", ")", ":", "\n", "    ", "\"\"\" Compute Structural Similarity Index Metric (SSIM). \"\"\"", "\n", "return", "compare_ssim", "(", "gt", ",", "pred", ",", "data_range", "=", "gt", ".", "max", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.measures_csv.evaluate": [[32, 59], ["args.target_path.iterdir", "h5py.File", "h5py.File", "numpy.transpose", "range", "round", "round", "round", "round", "metrics_info[].append", "metrics_info[].append", "metrics_info[].append", "metrics_info[].append", "metrics_info[].append", "metrics_info[].append", "measures_csv.mse", "measures_csv.nmse", "measures_csv.psnr", "measures_csv.ssim"], "function", ["home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.mse", "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.nmse", "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.psnr", "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.ssim"], ["", "def", "evaluate", "(", "args", ",", "recons_key", ",", "metrics_info", ")", ":", "\n", "\n", "    ", "for", "tgt_file", "in", "args", ".", "target_path", ".", "iterdir", "(", ")", ":", "\n", "        ", "with", "h5py", ".", "File", "(", "tgt_file", ")", "as", "target", ",", "h5py", ".", "File", "(", "args", ".", "predictions_path", "/", "tgt_file", ".", "name", ")", "as", "recons", ":", "\n", "            ", "target", "=", "target", "[", "recons_key", "]", ".", "value", "\n", "recons", "=", "recons", "[", "'reconstruction'", "]", ".", "value", "\n", "recons", "=", "np", ".", "transpose", "(", "recons", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "#print (target.shape,recons.shape)", "\n", "no_slices", "=", "target", ".", "shape", "[", "-", "1", "]", "\n", "\n", "for", "index", "in", "range", "(", "no_slices", ")", ":", "\n", "                ", "target_slice", "=", "target", "[", ":", ",", ":", ",", "index", "]", "\n", "recons_slice", "=", "recons", "[", ":", ",", ":", ",", "index", "]", "\n", "mse_slice", "=", "round", "(", "mse", "(", "target_slice", ",", "recons_slice", ")", ",", "5", ")", "\n", "nmse_slice", "=", "round", "(", "nmse", "(", "target_slice", ",", "recons_slice", ")", ",", "5", ")", "\n", "psnr_slice", "=", "round", "(", "psnr", "(", "target_slice", ",", "recons_slice", ")", ",", "2", ")", "\n", "ssim_slice", "=", "round", "(", "ssim", "(", "target_slice", ",", "recons_slice", ")", ",", "4", ")", "\n", "\n", "metrics_info", "[", "'MSE'", "]", ".", "append", "(", "mse_slice", ")", "\n", "metrics_info", "[", "'NMSE'", "]", ".", "append", "(", "nmse_slice", ")", "\n", "metrics_info", "[", "'PSNR'", "]", ".", "append", "(", "psnr_slice", ")", "\n", "metrics_info", "[", "'SSIM'", "]", ".", "append", "(", "ssim_slice", ")", "\n", "metrics_info", "[", "'VOLUME'", "]", ".", "append", "(", "tgt_file", ".", "name", ")", "\n", "metrics_info", "[", "'SLICE'", "]", ".", "append", "(", "index", ")", "\n", "#break", "\n", "\n", "", "", "", "return", "metrics_info", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.Metrics.__init__": [[69, 72], ["runstats.Statistics"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "metric_funcs", ")", ":", "\n", "        ", "self", ".", "metrics", "=", "{", "\n", "metric", ":", "Statistics", "(", ")", "for", "metric", "in", "metric_funcs", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.Metrics.push": [[74, 77], ["METRIC_FUNCS.items", "evaluate.Metrics.metrics[].push", "func"], "methods", ["home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.Metrics.push"], ["", "def", "push", "(", "self", ",", "target", ",", "recons", ")", ":", "\n", "        ", "for", "metric", ",", "func", "in", "METRIC_FUNCS", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "metrics", "[", "metric", "]", ".", "push", "(", "func", "(", "target", ",", "recons", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.Metrics.means": [[78, 81], ["stat.mean", "evaluate.Metrics.metrics.items"], "methods", ["None"], ["", "", "def", "means", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "metric", ":", "stat", ".", "mean", "(", ")", "for", "metric", ",", "stat", "in", "self", ".", "metrics", ".", "items", "(", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.Metrics.stddevs": [[83, 86], ["stat.stddev", "evaluate.Metrics.metrics.items"], "methods", ["None"], ["", "def", "stddevs", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "metric", ":", "stat", ".", "stddev", "(", ")", "for", "metric", ",", "stat", "in", "self", ".", "metrics", ".", "items", "(", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.Metrics.get_report": [[99, 105], ["evaluate.Metrics.means", "evaluate.Metrics.stddevs", "sorted", "list"], "methods", ["home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.Metrics.means", "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.Metrics.stddevs"], ["def", "get_report", "(", "self", ")", ":", "\n", "        ", "means", "=", "self", ".", "means", "(", ")", "\n", "stddevs", "=", "self", ".", "stddevs", "(", ")", "\n", "metric_names", "=", "sorted", "(", "list", "(", "means", ")", ")", "\n", "return", "' '", ".", "join", "(", "\n", "f'{name} = {means[name]:.4g} +/- {2 * stddevs[name]:.4g}'", "for", "name", "in", "metric_names", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.hfn": [[13, 31], ["range", "numpy.mean", "skimage.filters.laplace", "skimage.filters.laplace", "hfn_total.append", "numpy.sum", "numpy.sum"], "function", ["None"], ["def", "hfn", "(", "gt", ",", "pred", ")", ":", "\n", "\n", "    ", "hfn_total", "=", "[", "]", "\n", "\n", "for", "ii", "in", "range", "(", "gt", ".", "shape", "[", "-", "1", "]", ")", ":", "\n", "        ", "gt_slice", "=", "gt", "[", ":", ",", ":", ",", "ii", "]", "\n", "pred_slice", "=", "pred", "[", ":", ",", ":", ",", "ii", "]", "\n", "\n", "pred_slice", "[", "pred_slice", "<", "0", "]", "=", "0", "#bring the range to 0 and 1.", "\n", "pred_slice", "[", "pred_slice", ">", "1", "]", "=", "1", "\n", "\n", "gt_slice_laplace", "=", "laplace", "(", "gt_slice", ")", "\n", "pred_slice_laplace", "=", "laplace", "(", "pred_slice", ")", "\n", "\n", "hfn_slice", "=", "np", ".", "sum", "(", "(", "gt_slice_laplace", "-", "pred_slice_laplace", ")", "**", "2", ")", "/", "np", ".", "sum", "(", "gt_slice_laplace", "**", "2", ")", "\n", "hfn_total", ".", "append", "(", "hfn_slice", ")", "\n", "\n", "", "return", "np", ".", "mean", "(", "hfn_total", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.mse": [[33, 36], ["numpy.mean"], "function", ["None"], ["", "def", "mse", "(", "gt", ",", "pred", ")", ":", "\n", "    ", "\"\"\" Compute Mean Squared Error (MSE) \"\"\"", "\n", "return", "np", ".", "mean", "(", "(", "gt", "-", "pred", ")", "**", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.nmse": [[38, 41], ["numpy.linalg.norm", "numpy.linalg.norm"], "function", ["None"], ["", "def", "nmse", "(", "gt", ",", "pred", ")", ":", "\n", "    ", "\"\"\" Compute Normalized Mean Squared Error (NMSE) \"\"\"", "\n", "return", "np", ".", "linalg", ".", "norm", "(", "gt", "-", "pred", ")", "**", "2", "/", "np", ".", "linalg", ".", "norm", "(", "gt", ")", "**", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.psnr": [[43, 46], ["skimage.measure.compare_psnr", "gt.max"], "function", ["None"], ["", "def", "psnr", "(", "gt", ",", "pred", ")", ":", "\n", "    ", "\"\"\" Compute Peak Signal to Noise Ratio metric (PSNR) \"\"\"", "\n", "return", "compare_psnr", "(", "gt", ",", "pred", ",", "data_range", "=", "gt", ".", "max", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.ssim": [[48, 54], ["skimage.measure.compare_ssim", "gt.max"], "function", ["None"], ["", "def", "ssim", "(", "gt", ",", "pred", ")", ":", "\n", "    ", "\"\"\" Compute Structural Similarity Index Metric (SSIM). \"\"\"", "\n", "#return compare_ssim(", "\n", "#    gt.transpose(1, 2, 0), pred.transpose(1, 2, 0), multichannel=True, data_range=gt.max()", "\n", "#)", "\n", "return", "compare_ssim", "(", "gt", ",", "pred", ",", "multichannel", "=", "True", ",", "data_range", "=", "gt", ".", "max", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.evaluate": [[110, 125], ["evaluate.Metrics", "args.target_path.iterdir", "h5py.File", "h5py.File", "numpy.transpose", "print", "evaluate.Metrics.push"], "function", ["home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.evaluate.Metrics.push"], ["", "", "def", "evaluate", "(", "args", ",", "recons_key", ")", ":", "\n", "    ", "metrics", "=", "Metrics", "(", "METRIC_FUNCS", ")", "\n", "\n", "for", "tgt_file", "in", "args", ".", "target_path", ".", "iterdir", "(", ")", ":", "\n", "#print (tgt_file)", "\n", "        ", "with", "h5py", ".", "File", "(", "tgt_file", ")", "as", "target", ",", "h5py", ".", "File", "(", "\n", "args", ".", "predictions_path", "/", "tgt_file", ".", "name", ")", "as", "recons", ":", "\n", "            ", "target", "=", "target", "[", "recons_key", "]", ".", "value", "\n", "recons", "=", "recons", "[", "'reconstruction'", "]", ".", "value", "\n", "recons", "=", "np", ".", "transpose", "(", "recons", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "print", "(", "tgt_file", ")", "\n", "#print (target.shape,recons.shape)", "\n", "metrics", ".", "push", "(", "target", ",", "recons", ")", "\n", "\n", "", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.create_datasets": [[26, 39], ["args.acceleration_factor.split", "args.mask_type.split", "args.dataset_type.split", "dataset.SliceData", "dataset.SliceData", "dataset.SliceDisplayDataDev", "dataset.SliceDisplayDataDev"], "function", ["None"], ["def", "create_datasets", "(", "args", ")", ":", "\n", "\n", "\n", "    ", "acc_factors", "=", "args", ".", "acceleration_factor", ".", "split", "(", "','", ")", "\n", "mask_types", "=", "args", ".", "mask_type", ".", "split", "(", "','", ")", "\n", "dataset_types", "=", "args", ".", "dataset_type", ".", "split", "(", "','", ")", "\n", "#print(args.mask_type,mask_types)", "\n", "train_data", "=", "SliceData", "(", "args", ".", "train_path", ",", "acc_factors", ",", "dataset_types", ",", "mask_types", ",", "'train'", ")", "\n", "dev_data", "=", "SliceData", "(", "args", ".", "validation_path", ",", "acc_factors", ",", "dataset_types", ",", "mask_types", ",", "'validation'", ")", "\n", "display1_data", "=", "SliceDisplayDataDev", "(", "args", ".", "validation_path", ",", "'mrbrain_t1'", ",", "'cartesian'", ",", "'4x'", ")", "\n", "display2_data", "=", "SliceDisplayDataDev", "(", "args", ".", "validation_path", ",", "'mrbrain_flair'", ",", "'cartesian'", ",", "'4x'", ")", "\n", "#return dev_data, train_data", "\n", "return", "dev_data", ",", "train_data", ",", "display1_data", ",", "display2_data", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.create_data_loaders": [[40, 87], ["train.create_datasets", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "range", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.create_datasets"], ["", "def", "create_data_loaders", "(", "args", ")", ":", "\n", "    ", "dev_data", ",", "train_data", ",", "display1_data", ",", "display2_data", "=", "create_datasets", "(", "args", ")", "\n", "\n", "#display_data = [dev_data[i] for i in range(0, len(dev_data), len(dev_data) // 16)]", "\n", "display1", "=", "[", "display1_data", "[", "i", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "display1_data", ")", ",", "len", "(", "display1_data", ")", "//", "16", ")", "]", "\n", "display2", "=", "[", "display2_data", "[", "i", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "display2_data", ")", ",", "len", "(", "display2_data", ")", "//", "16", ")", "]", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "dataset", "=", "train_data", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "True", "\n", "#num_workers=64,", "\n", "#pin_memory=True,", "\n", ")", "\n", "dev_loader", "=", "DataLoader", "(", "\n", "dataset", "=", "dev_data", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "#num_workers=64,", "\n", "#pin_memory=True,", "\n", ")", "\n", "'''\n    display_loader = DataLoader(\n        dataset=display_data,\n        batch_size=16,\n        shuffle=True\n        #num_workers=64,\n        #pin_memory=True,\n    )\n    '''", "\n", "display_loader1", "=", "DataLoader", "(", "\n", "dataset", "=", "display1", ",", "\n", "batch_size", "=", "16", ",", "\n", "shuffle", "=", "True", "\n", "#num_workers=64,", "\n", "#pin_memory=True,", "\n", ")", "\n", "display_loader2", "=", "DataLoader", "(", "\n", "dataset", "=", "display2", ",", "\n", "batch_size", "=", "16", ",", "\n", "shuffle", "=", "True", "\n", "#num_workers=64,", "\n", "#pin_memory=True,", "\n", ")", "\n", "\n", "\n", "# return train_loader, dev_loader, display_loader", "\n", "return", "train_loader", ",", "dev_loader", ",", "display_loader1", ",", "display_loader2", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.train_epoch": [[89, 138], ["model.train", "time.perf_counter", "enumerate", "len", "tqdm.tqdm", "input.float.unsqueeze().to", "input_kspace.unsqueeze().to.unsqueeze().to", "target.float.unsqueeze().to", "gamma_val.float.to", "input.float.float", "target.float.float", "gamma_val.float.float", "model", "torch.nn.functional.l1_loss", "optimizer.zero_grad", "F.l1_loss.backward", "optimizer.step", "writer.add_scalar", "time.perf_counter", "F.l1_loss.item", "F.l1_loss.item", "logging.info", "time.perf_counter", "input.float.unsqueeze", "input_kspace.unsqueeze().to.unsqueeze", "target.float.unsqueeze", "F.l1_loss.item", "len", "F.l1_loss.item", "time.perf_counter"], "function", ["None"], ["", "def", "train_epoch", "(", "args", ",", "epoch", ",", "model", ",", "data_loader", ",", "optimizer", ",", "writer", ")", ":", "\n", "\n", "    ", "model", ".", "train", "(", ")", "\n", "avg_loss", "=", "0.", "\n", "start_epoch", "=", "start_iter", "=", "time", ".", "perf_counter", "(", ")", "\n", "global_step", "=", "epoch", "*", "len", "(", "data_loader", ")", "\n", "#print (\"Entering Train epoch\")", "\n", "\n", "for", "iter", ",", "data", "in", "enumerate", "(", "tqdm", "(", "data_loader", ")", ")", ":", "\n", "\n", "#print (data)", "\n", "\n", "#print (\"Received data from loader\")", "\n", "        ", "input", ",", "input_kspace", ",", "target", ",", "gamma_val", ",", "acc_factor_string", ",", "mask_string", ",", "dataset_string", "=", "data", "\n", "\n", "input", "=", "input", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "input_kspace", "=", "input_kspace", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "target", "=", "target", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "gamma_val", "=", "gamma_val", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "input", "=", "input", ".", "float", "(", ")", "\n", "target", "=", "target", ".", "float", "(", ")", "\n", "gamma_val", "=", "gamma_val", ".", "float", "(", ")", "\n", "\n", "\n", "output", "=", "model", "(", "input", ",", "input_kspace", ",", "gamma_val", ",", "acc_factor_string", ",", "mask_string", ",", "dataset_string", ")", "\n", "\n", "loss", "=", "F", ".", "l1_loss", "(", "output", ",", "target", ")", "\n", "#print (\"Input passed to model\")", "\n", "#print (\"Loss calculated\")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "avg_loss", "=", "0.99", "*", "avg_loss", "+", "0.01", "*", "loss", ".", "item", "(", ")", "if", "iter", ">", "0", "else", "loss", ".", "item", "(", ")", "\n", "writer", ".", "add_scalar", "(", "'TrainLoss'", ",", "loss", ".", "item", "(", ")", ",", "global_step", "+", "iter", ")", "\n", "\n", "if", "iter", "%", "args", ".", "report_interval", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\n", "f'Epoch = [{epoch:3d}/{args.num_epochs:3d}] '", "\n", "f'Iter = [{iter:4d}/{len(data_loader):4d}] '", "\n", "f'Loss = {loss.item():.4g} Avg Loss = {avg_loss:.4g} '", "\n", "f'Time = {time.perf_counter() - start_iter:.4f}s'", ",", "\n", ")", "\n", "", "start_iter", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n", "#break", "\n", "\n", "", "return", "avg_loss", ",", "time", ".", "perf_counter", "(", ")", "-", "start_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.evaluate": [[140, 172], ["model.eval", "time.perf_counter", "torch.no_grad", "enumerate", "writer.add_scalar", "numpy.mean", "tqdm.tqdm", "input.float.unsqueeze().to", "input_kspace.unsqueeze().to.unsqueeze().to", "target.float.unsqueeze().to", "gamma_val.float.to", "input.float.float", "target.float.float", "gamma_val.float.float", "model", "torch.nn.functional.mse_loss", "losses.append", "numpy.mean", "time.perf_counter", "F.mse_loss.item", "input.float.unsqueeze", "input_kspace.unsqueeze().to.unsqueeze", "target.float.unsqueeze"], "function", ["None"], ["", "def", "evaluate", "(", "args", ",", "epoch", ",", "model", ",", "data_loader", ",", "writer", ")", ":", "\n", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "losses", "=", "[", "]", "\n", "loss_acc_val", "=", "{", "'3.3x'", ":", "[", "]", ",", "'4x'", ":", "[", "]", ",", "'5x'", ":", "[", "]", "}", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "iter", ",", "data", "in", "enumerate", "(", "tqdm", "(", "data_loader", ")", ")", ":", "\n", "\n", "            ", "input", ",", "input_kspace", ",", "target", ",", "gamma_val", ",", "acc_factor_string", ",", "mask_string", ",", "dataset_string", "=", "data", "\n", "\n", "input", "=", "input", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "input_kspace", "=", "input_kspace", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "target", "=", "target", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "gamma_val", "=", "gamma_val", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "input", "=", "input", ".", "float", "(", ")", "\n", "target", "=", "target", ".", "float", "(", ")", "\n", "gamma_val", "=", "gamma_val", ".", "float", "(", ")", "\n", "\n", "output", "=", "model", "(", "input", ",", "input_kspace", ",", "gamma_val", ",", "acc_factor_string", ",", "mask_string", ",", "dataset_string", ")", "\n", "#loss = F.mse_loss(output,target, size_average=False)", "\n", "loss", "=", "F", ".", "mse_loss", "(", "output", ",", "target", ")", "\n", "losses", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "#break", "\n", "\n", "\n", "\n", "", "writer", ".", "add_scalar", "(", "'Dev_Loss'", ",", "np", ".", "mean", "(", "losses", ")", ",", "epoch", ")", "\n", "\n", "", "return", "np", ".", "mean", "(", "losses", ")", ",", "time", ".", "perf_counter", "(", ")", "-", "start", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.visualize": [[174, 202], ["model.eval", "image.min", "image.max", "torchvision.utils.make_grid", "torchvision.utils.make_grid", "writer.add_image", "torch.no_grad", "enumerate", "tqdm.tqdm", "input.float.unsqueeze().to", "input_kspace.unsqueeze().to.unsqueeze().to", "target.float.unsqueeze().to", "gamma_val.float.to", "input.float.float", "target.float.float", "gamma_val.float.float", "model", "train.visualize.save_image"], "function", ["None"], ["", "def", "visualize", "(", "args", ",", "epoch", ",", "model", ",", "data_loader", ",", "writer", ",", "datasettype_string", ")", ":", "\n", "\n", "    ", "def", "save_image", "(", "image", ",", "tag", ")", ":", "\n", "        ", "image", "-=", "image", ".", "min", "(", ")", "\n", "image", "/=", "image", ".", "max", "(", ")", "\n", "grid", "=", "torchvision", ".", "utils", ".", "make_grid", "(", "image", ",", "nrow", "=", "4", ",", "pad_value", "=", "1", ")", "\n", "writer", ".", "add_image", "(", "tag", ",", "grid", ",", "epoch", ")", "\n", "\n", "", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "iter", ",", "data", "in", "enumerate", "(", "tqdm", "(", "data_loader", ")", ")", ":", "\n", "            ", "input", ",", "input_kspace", ",", "target", ",", "gamma_val", ",", "acc_factor_string", ",", "mask_string", ",", "dataset_string", "=", "data", "\n", "\n", "input", "=", "input", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "input_kspace", "=", "input_kspace", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "target", "=", "target", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "gamma_val", "=", "gamma_val", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "input", "=", "input", ".", "float", "(", ")", "\n", "target", "=", "target", ".", "float", "(", ")", "\n", "gamma_val", "=", "gamma_val", ".", "float", "(", ")", "\n", "output", "=", "model", "(", "input", ",", "input_kspace", ",", "gamma_val", ",", "acc_factor_string", ",", "mask_string", ",", "dataset_string", ")", "\n", "\n", "save_image", "(", "input", ",", "'Input_{}'", ".", "format", "(", "datasettype_string", ")", ")", "\n", "save_image", "(", "target", ",", "'Target_{}'", ".", "format", "(", "datasettype_string", ")", ")", "\n", "save_image", "(", "output", ",", "'Reconstruction_{}'", ".", "format", "(", "datasettype_string", ")", ")", "\n", "save_image", "(", "torch", ".", "abs", "(", "target", ".", "float", "(", ")", "-", "output", ".", "float", "(", ")", ")", ",", "'Error_{}'", ".", "format", "(", "datasettype_string", ")", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.save_model": [[203, 219], ["torch.save", "shutil.copyfile", "model.state_dict", "optimizer.state_dict"], "function", ["None"], ["", "", "", "def", "save_model", "(", "args", ",", "exp_dir", ",", "epoch", ",", "model", ",", "optimizer", ",", "best_dev_loss", ",", "is_new_best", ")", ":", "\n", "\n", "    ", "out", "=", "torch", ".", "save", "(", "\n", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'args'", ":", "args", ",", "\n", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'best_dev_loss'", ":", "best_dev_loss", ",", "\n", "'exp_dir'", ":", "exp_dir", "\n", "}", ",", "\n", "f", "=", "exp_dir", "/", "'model.pt'", "\n", ")", "\n", "\n", "if", "is_new_best", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "exp_dir", "/", "'model.pt'", ",", "exp_dir", "/", "'best_model.pt'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.build_model": [[221, 232], ["None"], "function", ["None"], ["", "", "def", "build_model", "(", "args", ")", ":", "\n", "\n", "# Step 1: Train MACReconNet by uncommenting the line below", "\n", "\n", "#model = MACReconNet(args).to(args.device) # (working code )this line was uncommented to train decouple wang et al for separate training of cartesian and gaussian masks", "\n", "# Step 2: To train MACReconNet in deep cascaded mode, load the best model trained in step 1 as shown below. uncomment the following two lines ", "\n", "#checkpoint_file = '/<path where MACReconNet folder is stored>/best_model.pt'", "\n", "# Use a different model name 'DC-MACReconNet' in the sh files", "\n", "#model = DC_CNN(args,checkpoint_file).to(args.device)", "\n", "\n", "    ", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.load_model": [[233, 247], ["torch.load", "train.build_model", "torch.nn.DataParallel.load_state_dict", "train.build_optim", "build_optim.load_state_dict", "torch.nn.DataParallel", "torch.nn.DataParallel.parameters"], "function", ["home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.build_model", "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.build_optim"], ["", "def", "load_model", "(", "checkpoint_file", ")", ":", "\n", "    ", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_file", ")", "\n", "args", "=", "checkpoint", "[", "'args'", "]", "\n", "model", "=", "build_model", "(", "args", ")", "\n", "\n", "if", "args", ".", "data_parallel", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "\n", "optimizer", "=", "build_optim", "(", "args", ",", "model", ".", "parameters", "(", ")", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "\n", "return", "checkpoint", ",", "model", ",", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.load_pretrained_model": [[248, 252], ["torch.load", "model.load_state_dict"], "function", ["None"], ["", "def", "load_pretrained_model", "(", "model", ",", "checkpoint_file", ")", ":", "\n", "    ", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_file", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.build_optim": [[253, 256], ["torch.optim.Adam"], "function", ["None"], ["", "def", "build_optim", "(", "args", ",", "params", ")", ":", "\n", "    ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "params", ",", "args", ".", "lr", ",", "weight_decay", "=", "args", ".", "weight_decay", ")", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.main": [[258, 304], ["args.exp_dir.mkdir", "tensorboardX.SummaryWriter", "logging.info", "logging.info", "train.create_data_loaders", "torch.optim.lr_scheduler.StepLR", "range", "tensorboardX.SummaryWriter.close", "print", "train.load_model", "train.build_model", "train.build_optim", "torch.optim.lr_scheduler.StepLR.step", "train.train_epoch", "train.evaluate", "train.visualize", "train.visualize", "min", "train.save_model", "logging.info", "str", "torch.nn.DataParallel", "torch.nn.DataParallel.parameters"], "function", ["home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.valid.create_data_loaders", "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.valid.load_model", "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.build_model", "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.build_optim", "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.train_epoch", "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.evaluate", "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.visualize", "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.visualize", "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.save_model"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "args", ".", "exp_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "writer", "=", "SummaryWriter", "(", "log_dir", "=", "str", "(", "args", ".", "exp_dir", "/", "'summary'", ")", ")", "\n", "\n", "if", "args", ".", "resume", ":", "\n", "        ", "print", "(", "'resuming model, batch_size'", ",", "args", ".", "batch_size", ")", "\n", "checkpoint", ",", "model", ",", "optimizer", ",", "disc", ",", "optimizerD", "=", "load_model", "(", "args", ".", "checkpoint", ")", "\n", "args", "=", "checkpoint", "[", "'args'", "]", "\n", "args", ".", "batch_size", "=", "28", "\n", "best_dev_mse", "=", "checkpoint", "[", "'best_dev_mse'", "]", "\n", "best_dev_ssim", "=", "checkpoint", "[", "'best_dev_mse'", "]", "\n", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "del", "checkpoint", "\n", "", "else", ":", "\n", "        ", "model", "=", "build_model", "(", "args", ")", "\n", "#print (\"Model Built\")", "\n", "if", "args", ".", "data_parallel", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "", "optimizer", "=", "build_optim", "(", "args", ",", "model", ".", "parameters", "(", ")", ")", "\n", "#print (\"Optmizer initialized\")", "\n", "best_dev_loss", "=", "1e9", "\n", "start_epoch", "=", "0", "\n", "\n", "", "logging", ".", "info", "(", "args", ")", "\n", "logging", ".", "info", "(", "model", ")", "\n", "\n", "train_loader", ",", "dev_loader", ",", "display1_loader", ",", "display2_loader", "=", "create_data_loaders", "(", "args", ")", "\n", "#print (\"Dataloader initialized\")", "\n", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "args", ".", "lr_step_size", ",", "args", ".", "lr_gamma", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "args", ".", "num_epochs", ")", ":", "\n", "\n", "        ", "scheduler", ".", "step", "(", "epoch", ")", "\n", "train_loss", ",", "train_time", "=", "train_epoch", "(", "args", ",", "epoch", ",", "model", ",", "train_loader", ",", "optimizer", ",", "writer", ")", "\n", "dev_loss", ",", "dev_time", "=", "evaluate", "(", "args", ",", "epoch", ",", "model", ",", "dev_loader", ",", "writer", ")", "\n", "visualize", "(", "args", ",", "epoch", ",", "model", ",", "display1_loader", ",", "writer", ",", "'t1'", ")", "\n", "visualize", "(", "args", ",", "epoch", ",", "model", ",", "display2_loader", ",", "writer", ",", "'flair'", ")", "\n", "\n", "is_new_best", "=", "dev_loss", "<", "best_dev_loss", "\n", "best_dev_loss", "=", "min", "(", "best_dev_loss", ",", "dev_loss", ")", "\n", "save_model", "(", "args", ",", "args", ".", "exp_dir", ",", "epoch", ",", "model", ",", "optimizer", ",", "best_dev_loss", ",", "is_new_best", ")", "\n", "logging", ".", "info", "(", "\n", "f'Epoch = [{epoch:4d}/{args.num_epochs:4d}] TrainLoss = {train_loss:.4g}'", "\n", "f'DevLoss= {dev_loss:.4g} TrainTime = {train_time:.4f}s DevTime = {dev_time:.4f}s'", ",", "\n", ")", "\n", "", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.train.create_arg_parser": [[306, 343], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["", "def", "create_arg_parser", "(", ")", ":", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train setup for MR recon U-Net'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "default", "=", "42", ",", "type", "=", "int", ",", "help", "=", "'Seed for random number generators'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-pools'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'Number of U-Net pooling layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--drop-prob'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "help", "=", "'Dropout probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-chans'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "help", "=", "'Number of U-Net channels'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "'Mini batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-epochs'", ",", "type", "=", "int", ",", "default", "=", "150", ",", "help", "=", "'Number of training epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'Learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-step-size'", ",", "type", "=", "int", ",", "default", "=", "40", ",", "\n", "help", "=", "'Period of learning rate decay'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr-gamma'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "'Multiplicative factor of learning rate decay'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight-decay'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "\n", "help", "=", "'Strength of weight decay regularization'", ")", "\n", "parser", ".", "add_argument", "(", "'--report-interval'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'Period of loss reporting'", ")", "\n", "parser", ".", "add_argument", "(", "'--data-parallel'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'If set, use multiple GPUs using data parallelism'", ")", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "type", "=", "str", ",", "default", "=", "'cuda'", ",", "\n", "help", "=", "'Which device to train on. Set to \"cuda\" to use the GPU'", ")", "\n", "parser", ".", "add_argument", "(", "'--exp-dir'", ",", "type", "=", "pathlib", ".", "Path", ",", "default", "=", "'checkpoints'", ",", "\n", "help", "=", "'Path where model and results should be saved'", ")", "\n", "parser", ".", "add_argument", "(", "'--resume'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'If set, resume the training from a previous model checkpoint. '", "\n", "'\"--checkpoint\" should be set with this'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Path to an existing checkpoint. Used along with \"--resume\"'", ")", "\n", "parser", ".", "add_argument", "(", "'--train-path'", ",", "type", "=", "str", ",", "help", "=", "'Path to train h5 files'", ")", "\n", "parser", ".", "add_argument", "(", "'--validation-path'", ",", "type", "=", "str", ",", "help", "=", "'Path to test h5 files'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--acceleration_factor'", ",", "type", "=", "str", ",", "help", "=", "'acceleration factors'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_type'", ",", "type", "=", "str", ",", "help", "=", "'cardiac,kirby'", ")", "\n", "parser", ".", "add_argument", "(", "'--usmask_path'", ",", "type", "=", "str", ",", "help", "=", "'us mask path'", ")", "\n", "parser", ".", "add_argument", "(", "'--mask_type'", ",", "type", "=", "str", ",", "help", "=", "'mask type - cartesian, gaussian'", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.dataset.SliceData.__init__": [[17, 42], ["os.path.join", "os.path.join", "list", "sorted", "pathlib.Path().iterdir", "h5py.File", "pathlib.Path", "os.path.join", "range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "root", ",", "acc_factors", ",", "dataset_types", ",", "mask_types", ",", "train_or_valid", ")", ":", "# acc_factor can be passed here and saved as self variable", "\n", "# List the h5 files in root ", "\n", "#files = list(pathlib.Path(root).iterdir())", "\n", "        ", "self", ".", "examples", "=", "[", "]", "\n", "#self.acc_factor = acc_factor ", "\n", "#self.dataset_type = dataset_type", "\n", "#self.key_img = 'img_volus_{}'.format(self.acc_factor)", "\n", "#self.key_kspace = 'kspace_volus_{}'.format(self.acc_factor)", "\n", "#mask_path = os.path.join(mask_path,'mask_{}.npy'.format(acc_factor))", "\n", "#self.mask = np.load(mask_path)", "\n", "#acc_factors = ['3_3x','4x','5x']", "\n", "#print(\"acc_factors in slice data: \", acc_factors)", "\n", "for", "dataset_type", "in", "dataset_types", ":", "\n", "            ", "dataroot", "=", "os", ".", "path", ".", "join", "(", "root", ",", "dataset_type", ")", "\n", "for", "mask_type", "in", "mask_types", ":", "\n", "                ", "newroot", "=", "os", ".", "path", ".", "join", "(", "dataroot", ",", "mask_type", ",", "train_or_valid", ")", "\n", "for", "acc_factor", "in", "acc_factors", ":", "\n", "#print(\"acc_factor: \", acc_factor)", "\n", "                    ", "files", "=", "list", "(", "pathlib", ".", "Path", "(", "os", ".", "path", ".", "join", "(", "newroot", ",", "'acc_{}'", ".", "format", "(", "acc_factor", ")", ")", ")", ".", "iterdir", "(", ")", ")", "\n", "for", "fname", "in", "sorted", "(", "files", ")", ":", "\n", "                        ", "with", "h5py", ".", "File", "(", "fname", ",", "'r'", ")", "as", "hf", ":", "\n", "                            ", "fsvol", "=", "hf", "[", "'volfs'", "]", "\n", "num_slices", "=", "fsvol", ".", "shape", "[", "2", "]", "\n", "#acc_factor = float(acc_factor[:-1].replace(\"_\",\".\"))", "\n", "self", ".", "examples", "+=", "[", "(", "fname", ",", "slice", ",", "acc_factor", ",", "mask_type", ",", "dataset_type", ")", "for", "slice", "in", "range", "(", "num_slices", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.dataset.SliceData.__len__": [[43, 45], ["len"], "methods", ["None"], ["", "", "", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.dataset.SliceData.__getitem__": [[46, 84], ["h5py.File", "utils.npComplexToTorch", "[].astype", "float", "numpy.array", "acc_factor[].replace", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.utils.npComplexToTorch"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "# Index the fname and slice using the list created in __init__", "\n", "\n", "        ", "fname", ",", "slice", ",", "acc_factor", ",", "mask_type", ",", "dataset_type", "=", "self", ".", "examples", "[", "i", "]", "\n", "# Print statements ", "\n", "#print (fname,slice)", "\n", "#print (\"acc_factor: \",acc_factor)", "\n", "\n", "with", "h5py", ".", "File", "(", "fname", ",", "'r'", ")", "as", "data", ":", "\n", "            ", "key_img", "=", "'img_volus_{}'", ".", "format", "(", "acc_factor", ")", "\n", "key_kspace", "=", "'kspace_volus_{}'", ".", "format", "(", "acc_factor", ")", "\n", "\n", "input_img", "=", "data", "[", "key_img", "]", "[", ":", ",", ":", ",", "slice", "]", "\n", "#print(key_img)", "\n", "input_kspace", "=", "data", "[", "key_kspace", "]", "[", ":", ",", ":", ",", "slice", "]", "\n", "input_kspace", "=", "npComplexToTorch", "(", "input_kspace", ")", "\n", "\n", "target", "=", "data", "[", "'volfs'", "]", "[", ":", ",", ":", ",", "slice", "]", ".", "astype", "(", "np", ".", "float64", ")", "# converting to double", "\n", "#target = data['volfs'][:,:,slice]", "\n", "\n", "#kspace_cmplx = np.fft.fft2(target,norm='ortho')", "\n", "#uskspace_cmplx = kspace_cmplx * self.mask", "\n", "#zf_img = np.abs(np.fft.ifft2(uskspace_cmplx,norm='ortho'))", "\n", "\n", "# Print statements", "\n", "#print (input.shape,target.shape)", "\n", "#return torch.from_numpy(zf_img), torch.from_numpy(target)", "\n", "#acc_val = torch.Tensor([float(acc_factor[:-1].replace(\"_\",\".\"))])", "\n", "acc_val", "=", "float", "(", "acc_factor", "[", ":", "-", "1", "]", ".", "replace", "(", "\"_\"", ",", "\".\"", ")", ")", "\n", "mask_val", "=", "0", "if", "mask_type", "==", "'cartesian'", "else", "1", "\n", "dataset_val", "=", "0", "if", "dataset_type", "==", "'mrbrain_t1'", "else", "1", "\n", "gamma_input", "=", "np", ".", "array", "(", "[", "acc_val", ",", "mask_val", ",", "dataset_val", "]", ")", "\n", "#print(torch.from_numpy(gamma_input).shape)", "\n", "\n", "\n", "#print (input_img.dtype,input_kspace.dtype,target.dtype,gamma_input.dtype)", "\n", "\n", "return", "torch", ".", "from_numpy", "(", "input_img", ")", ",", "input_kspace", ",", "torch", ".", "from_numpy", "(", "target", ")", ",", "torch", ".", "from_numpy", "(", "gamma_input", ")", ",", "acc_factor", ",", "mask_type", ",", "dataset_type", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.dataset.SliceDataDev.__init__": [[92, 115], ["list", "sorted", "pathlib.Path().iterdir", "h5py.File", "pathlib.Path", "range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "root", ",", "acc_factor", ",", "dataset_type", ",", "mask_type", ")", ":", "\n", "\n", "# List the h5 files in root ", "\n", "        ", "files", "=", "list", "(", "pathlib", ".", "Path", "(", "root", ")", ".", "iterdir", "(", ")", ")", "\n", "self", ".", "examples", "=", "[", "]", "\n", "#self.acc_factor = acc_factor", "\n", "#self.dataset_type = dataset_type", "\n", "\n", "#self.key_img = 'img_volus_{}'.format(self.acc_factor)", "\n", "#self.key_kspace = 'kspace_volus_{}'.format(self.acc_factor)", "\n", "\n", "#mask_path = os.path.join(mask_path,'mask_{}.npy'.format(acc_factor))", "\n", "#self.mask = np.load(mask_path)", "\n", "#for acc_factor in acc_factors:", "\n", "\n", "#files = list(pathlib.Path(os.path.join(root,'acc_{}'.format(acc_factor))).iterdir())", "\n", "\n", "for", "fname", "in", "sorted", "(", "files", ")", ":", "\n", "            ", "with", "h5py", ".", "File", "(", "fname", ",", "'r'", ")", "as", "hf", ":", "\n", "                ", "fsvol", "=", "hf", "[", "'volfs'", "]", "\n", "num_slices", "=", "fsvol", ".", "shape", "[", "2", "]", "\n", "#acc_factor = float(acc_factor[:-1].replace(\"_\",\".\"))", "\n", "self", ".", "examples", "+=", "[", "(", "fname", ",", "slice", ",", "acc_factor", ",", "mask_type", ",", "dataset_type", ")", "for", "slice", "in", "range", "(", "num_slices", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.dataset.SliceDataDev.__len__": [[118, 120], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.dataset.SliceDataDev.__getitem__": [[121, 149], ["h5py.File", "utils.npComplexToTorch", "float", "numpy.array", "acc_factor[].replace", "torch.from_numpy", "torch.from_numpy", "str", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.utils.npComplexToTorch"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "# Index the fname and slice using the list created in __init__", "\n", "\n", "        ", "fname", ",", "slice", ",", "acc_factor", ",", "mask_type", ",", "dataset_type", "=", "self", ".", "examples", "[", "i", "]", "\n", "# Print statements ", "\n", "#print (type(fname),slice)", "\n", "\n", "with", "h5py", ".", "File", "(", "fname", ",", "'r'", ")", "as", "data", ":", "\n", "\n", "            ", "key_img", "=", "'img_volus_{}'", ".", "format", "(", "acc_factor", ")", "\n", "key_kspace", "=", "'kspace_volus_{}'", ".", "format", "(", "acc_factor", ")", "\n", "input_img", "=", "data", "[", "key_img", "]", "[", ":", ",", ":", ",", "slice", "]", "\n", "input_kspace", "=", "data", "[", "key_kspace", "]", "[", ":", ",", ":", ",", "slice", "]", "\n", "input_kspace", "=", "npComplexToTorch", "(", "input_kspace", ")", "\n", "target", "=", "data", "[", "'volfs'", "]", "[", ":", ",", ":", ",", "slice", "]", "\n", "\n", "#kspace_cmplx = np.fft.fft2(target,norm='ortho')", "\n", "#uskspace_cmplx = kspace_cmplx * self.mask", "\n", "#zf_img = np.abs(np.fft.ifft2(uskspace_cmplx,norm='ortho'))", "\n", "\n", "# Print statements", "\n", "#print (input.shape,target.shape)", "\n", "acc_val", "=", "float", "(", "acc_factor", "[", ":", "-", "1", "]", ".", "replace", "(", "\"_\"", ",", "\".\"", ")", ")", "\n", "mask_val", "=", "0", "if", "mask_type", "==", "'cartesian'", "else", "1", "\n", "dataset_val", "=", "0", "if", "dataset_type", "==", "'mrbrain_t1'", "else", "1", "\n", "gamma_input", "=", "np", ".", "array", "(", "[", "acc_val", ",", "mask_val", ",", "dataset_val", "]", ")", "\n", "#gamma_input = np.array([acc_val,dataset_val])", "\n", "return", "torch", ".", "from_numpy", "(", "input_img", ")", ",", "input_kspace", ",", "torch", ".", "from_numpy", "(", "target", ")", ",", "str", "(", "fname", ".", "name", ")", ",", "slice", ",", "torch", ".", "from_numpy", "(", "gamma_input", ")", ",", "acc_factor", ",", "mask_type", ",", "dataset_type", "\n", "#return torch.from_numpy(zf_img), torch.from_numpy(target),str(fname.name),slice", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.dataset.SliceDisplayDataDev.__init__": [[157, 181], ["os.path.join", "list", "sorted", "pathlib.Path().iterdir", "h5py.File", "pathlib.Path", "range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "root", ",", "dataset_type", ",", "mask_type", ",", "acc_factor", ")", ":", "\n", "\n", "# List the h5 files in root ", "\n", "        ", "newroot", "=", "os", ".", "path", ".", "join", "(", "root", ",", "dataset_type", ",", "mask_type", ",", "'validation'", ",", "'acc_{}'", ".", "format", "(", "acc_factor", ")", ")", "\n", "files", "=", "list", "(", "pathlib", ".", "Path", "(", "newroot", ")", ".", "iterdir", "(", ")", ")", "\n", "self", ".", "examples", "=", "[", "]", "\n", "#self.acc_factor = acc_factor", "\n", "#self.dataset_type = dataset_type", "\n", "\n", "#self.key_img = 'img_volus_{}'.format(self.acc_factor)", "\n", "#self.key_kspace = 'kspace_volus_{}'.format(self.acc_factor)", "\n", "\n", "#mask_path = os.path.join(mask_path,'mask_{}.npy'.format(acc_factor))", "\n", "#self.mask = np.load(mask_path)", "\n", "#for acc_factor in acc_factors:", "\n", "\n", "#files = list(pathlib.Path(os.path.join(root,'acc_{}'.format(acc_factor))).iterdir())", "\n", "#print(files)", "\n", "for", "fname", "in", "sorted", "(", "files", ")", ":", "\n", "            ", "with", "h5py", ".", "File", "(", "fname", ",", "'r'", ")", "as", "hf", ":", "\n", "                ", "fsvol", "=", "hf", "[", "'volfs'", "]", "\n", "num_slices", "=", "fsvol", ".", "shape", "[", "2", "]", "\n", "#acc_factor = float(acc_factor[:-1].replace(\"_\",\".\"))", "\n", "self", ".", "examples", "+=", "[", "(", "fname", ",", "slice", ",", "acc_factor", ",", "mask_type", ",", "dataset_type", ")", "for", "slice", "in", "range", "(", "num_slices", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.dataset.SliceDisplayDataDev.__len__": [[184, 186], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.dataset.SliceDisplayDataDev.__getitem__": [[187, 216], ["h5py.File", "utils.npComplexToTorch", "[].astype", "float", "numpy.array", "acc_factor[].replace", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.utils.npComplexToTorch"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "# Index the fname and slice using the list created in __init__", "\n", "\n", "        ", "fname", ",", "slice", ",", "acc_factor", ",", "mask_type", ",", "dataset_type", "=", "self", ".", "examples", "[", "i", "]", "\n", "# Print statements ", "\n", "#print (type(fname),slice)", "\n", "\n", "with", "h5py", ".", "File", "(", "fname", ",", "'r'", ")", "as", "data", ":", "\n", "\n", "            ", "key_img", "=", "'img_volus_{}'", ".", "format", "(", "acc_factor", ")", "\n", "key_kspace", "=", "'kspace_volus_{}'", ".", "format", "(", "acc_factor", ")", "\n", "input_img", "=", "data", "[", "key_img", "]", "[", ":", ",", ":", ",", "slice", "]", "\n", "input_kspace", "=", "data", "[", "key_kspace", "]", "[", ":", ",", ":", ",", "slice", "]", "\n", "input_kspace", "=", "npComplexToTorch", "(", "input_kspace", ")", "\n", "#target = data['volfs'][:,:,slice]", "\n", "target", "=", "data", "[", "'volfs'", "]", "[", ":", ",", ":", ",", "slice", "]", ".", "astype", "(", "np", ".", "float64", ")", "# converting to double", "\n", "\n", "#kspace_cmplx = np.fft.fft2(target,norm='ortho')", "\n", "#uskspace_cmplx = kspace_cmplx * self.mask", "\n", "#zf_img = np.abs(np.fft.ifft2(uskspace_cmplx,norm='ortho'))", "\n", "\n", "# Print statements", "\n", "#print (input.shape,target.shape)", "\n", "acc_val", "=", "float", "(", "acc_factor", "[", ":", "-", "1", "]", ".", "replace", "(", "\"_\"", ",", "\".\"", ")", ")", "\n", "mask_val", "=", "0", "if", "mask_type", "==", "'cartesian'", "else", "1", "\n", "dataset_val", "=", "0", "if", "dataset_type", "==", "'mrbrain_t1'", "else", "1", "\n", "gamma_input", "=", "np", ".", "array", "(", "[", "acc_val", ",", "mask_val", ",", "dataset_val", "]", ")", "\n", "#gamma_input = np.array([acc_val,dataset_val])", "\n", "return", "torch", ".", "from_numpy", "(", "input_img", ")", ",", "input_kspace", ",", "torch", ".", "from_numpy", "(", "target", ")", ",", "torch", ".", "from_numpy", "(", "gamma_input", ")", ",", "acc_factor", ",", "mask_type", ",", "dataset_type", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.valid.save_reconstructions": [[13, 27], ["out_dir.mkdir", "reconstructions.items", "h5py.File", "f.create_dataset"], "function", ["None"], ["def", "save_reconstructions", "(", "reconstructions", ",", "out_dir", ")", ":", "\n", "    ", "\"\"\"\n    Saves the reconstructions from a model into h5 files that is appropriate for submission\n    to the leaderboard.\n    Args:\n        reconstructions (dict[str, np.array]): A dictionary mapping input filenames to\n            corresponding reconstructions (of shape num_slices x height x width).\n        out_dir (pathlib.Path): Path to the output directory where the reconstructions\n            should be saved.\n    \"\"\"", "\n", "out_dir", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "for", "fname", ",", "recons", "in", "reconstructions", ".", "items", "(", ")", ":", "\n", "        ", "with", "h5py", ".", "File", "(", "out_dir", "/", "fname", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "create_dataset", "(", "'reconstruction'", ",", "data", "=", "recons", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.valid.create_data_loaders": [[29, 41], ["dataset.SliceDataDev", "torch.utils.data.DataLoader"], "function", ["None"], ["", "", "", "def", "create_data_loaders", "(", "args", ")", ":", "\n", "\n", "#data = SliceDataDev(args.data_path,args.acceleration_factor,args.dataset_type,args.usmask_path)", "\n", "    ", "data", "=", "SliceDataDev", "(", "args", ".", "data_path", ",", "args", ".", "acceleration_factor", ",", "args", ".", "dataset_type", ",", "args", ".", "mask_type", ")", "\n", "data_loader", "=", "DataLoader", "(", "\n", "dataset", "=", "data", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "num_workers", "=", "1", ",", "\n", "pin_memory", "=", "True", ",", "\n", ")", "\n", "\n", "return", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.valid.load_model": [[43, 57], ["torch.load", "models.DC_CNN().to", "models.DC_CNN"], "function", ["None"], ["", "def", "load_model", "(", "checkpoint_file", ")", ":", "\n", "\n", "    ", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_file", ")", "\n", "args", "=", "checkpoint", "[", "'args'", "]", "\n", "\n", "#print(model)", "\n", "\n", "#checkpoint_file = '/<path to MACReconNet folder>/best_model.pt'", "\n", "model", "=", "DC_CNN", "(", "args", ",", "checkpoint_file", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "#model = MACReconNet(args).to(args.device)", "\n", "#model.load_state_dict(checkpoint['model'])", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.valid.run_unet": [[59, 87], ["model.eval", "collections.defaultdict", "torch.no_grad", "enumerate", "numpy.stack", "tqdm.tqdm", "input.float.unsqueeze().to().float", "gamma_val.unsqueeze().to().float.unsqueeze().to().float", "input_kspace.unsqueeze().to.unsqueeze().to", "input.float.float", "model().to().squeeze", "range", "collections.defaultdict.items", "reconstructions[].append", "input.float.unsqueeze().to", "gamma_val.unsqueeze().to().float.unsqueeze().to", "input_kspace.unsqueeze().to.unsqueeze", "model().to", "sorted", "slices[].numpy", "recons[].numpy", "input.float.unsqueeze", "gamma_val.unsqueeze().to().float.unsqueeze", "model"], "function", ["None"], ["", "def", "run_unet", "(", "args", ",", "model", ",", "data_loader", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "reconstructions", "=", "defaultdict", "(", "list", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "(", "iter", ",", "data", ")", "in", "enumerate", "(", "tqdm", "(", "data_loader", ")", ")", ":", "\n", "\n", "\n", "            ", "input", ",", "input_kspace", ",", "target", ",", "fnames", ",", "slices", ",", "gamma_val", ",", "acc_factor_string", ",", "mask_string", ",", "dataset_string", "=", "data", "\n", "\n", "input", "=", "input", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "args", ".", "device", ")", ".", "float", "(", ")", "\n", "gamma_val", "=", "gamma_val", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "args", ".", "device", ")", ".", "float", "(", ")", "\n", "input_kspace", "=", "input_kspace", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "input", "=", "input", ".", "float", "(", ")", "\n", "\n", "#print (input.shape,acc_val.shape)", "\n", "recons", "=", "model", "(", "input", ",", "input_kspace", ",", "gamma_val", ",", "acc_factor_string", ",", "mask_string", ",", "dataset_string", ")", ".", "to", "(", "'cpu'", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "\n", "for", "i", "in", "range", "(", "recons", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "recons", "[", "i", "]", "=", "recons", "[", "i", "]", "\n", "reconstructions", "[", "fnames", "[", "i", "]", "]", ".", "append", "(", "(", "slices", "[", "i", "]", ".", "numpy", "(", ")", ",", "recons", "[", "i", "]", ".", "numpy", "(", ")", ")", ")", "\n", "\n", "", "", "", "reconstructions", "=", "{", "\n", "fname", ":", "np", ".", "stack", "(", "[", "pred", "for", "_", ",", "pred", "in", "sorted", "(", "slice_preds", ")", "]", ")", "\n", "for", "fname", ",", "slice_preds", "in", "reconstructions", ".", "items", "(", ")", "\n", "}", "\n", "return", "reconstructions", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.valid.main": [[89, 95], ["valid.create_data_loaders", "valid.load_model", "valid.run_unet", "valid.save_reconstructions"], "function", ["home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.valid.create_data_loaders", "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.valid.load_model", "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.valid.run_unet", "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.valid.save_reconstructions"], ["", "def", "main", "(", "args", ")", ":", "\n", "\n", "    ", "data_loader", "=", "create_data_loaders", "(", "args", ")", "\n", "model", "=", "load_model", "(", "args", ".", "checkpoint", ")", "\n", "reconstructions", "=", "run_unet", "(", "args", ",", "model", ",", "data_loader", ")", "\n", "save_reconstructions", "(", "reconstructions", ",", "args", ".", "out_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.valid.create_arg_parser": [[97, 114], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["", "def", "create_arg_parser", "(", ")", ":", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Valid setup for MR recon U-Net\"", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "type", "=", "pathlib", ".", "Path", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path to the U-Net model'", ")", "\n", "parser", ".", "add_argument", "(", "'--out-dir'", ",", "type", "=", "pathlib", ".", "Path", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path to save the reconstructions to'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "default", "=", "16", ",", "type", "=", "int", ",", "help", "=", "'Mini-batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "type", "=", "str", ",", "default", "=", "'cuda'", ",", "help", "=", "'Which device to run on'", ")", "\n", "parser", ".", "add_argument", "(", "'--data-path'", ",", "type", "=", "str", ",", "help", "=", "'path to validation dataset'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--acceleration_factor'", ",", "type", "=", "str", ",", "help", "=", "'acceleration factors'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_type'", ",", "type", "=", "str", ",", "help", "=", "'cardiac,kirby'", ")", "\n", "#parser.add_argument('--usmask_path',type=str,help='undersampling mask path')", "\n", "parser", ".", "add_argument", "(", "'--mask_type'", ",", "type", "=", "str", ",", "help", "=", "'mask type - cartesian, gaussian'", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.sriprabhar_MAC-ReconNet.src.utils.npComplexToTorch": [[5, 13], ["torch.from_numpy", "torch.from_numpy", "torch.stack"], "function", ["None"], ["def", "npComplexToTorch", "(", "kspace_np", ")", ":", "\n", "\n", "# Converts a numpy complex to torch ", "\n", "    ", "kspace_real_torch", "=", "torch", ".", "from_numpy", "(", "kspace_np", ".", "real", ")", "\n", "kspace_imag_torch", "=", "torch", ".", "from_numpy", "(", "kspace_np", ".", "imag", ")", "\n", "kspace_torch", "=", "torch", ".", "stack", "(", "[", "kspace_real_torch", ",", "kspace_imag_torch", "]", ",", "dim", "=", "2", ")", "\n", "\n", "return", "kspace_torch", "", "", ""]]}