{"home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.metrics.positive_predictions_for": [[6, 9], ["torch.gt().float().sum", "torch.gt().float", "torch.gt"], "function", ["None"], ["def", "positive_predictions_for", "(", "predicted_probs", ",", "threshold", "=", "0.5", ")", ":", "\n", "#return sum(torch.gt(predicted_probs.data, threshold).cpu().numpy().tolist())", "\n", "    ", "return", "(", "torch", ".", "gt", "(", "predicted_probs", ".", "data", ",", "threshold", ")", ".", "float", "(", ")", ".", "sum", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.metrics.mrr": [[10, 22], ["metrics.get_mask", "torch.sigmoid", "torch.sort", "argsort.data.cpu().numpy.data.cpu().numpy", "gold_labels.data.cpu().numpy.data.cpu().numpy", "range", "torch.sigmoid.size", "torch.sigmoid.size", "reciprocal_ranks.append", "argsort.data.cpu().numpy.data.cpu", "gold_labels.data.cpu().numpy.data.cpu", "numpy.where"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_mask"], ["", "def", "mrr", "(", "predictions", ",", "gold_labels", ",", "all_true", ",", "candidates", "=", "None", ")", ":", "\n", "    ", "reciprocal_ranks", "=", "[", "]", "\n", "candidate_mask", "=", "get_mask", "(", "all_true", ",", "candidates", ",", "gold_labels", ",", "predictions", ".", "size", "(", "1", ")", ")", "\n", "predictions", "=", "torch", ".", "sigmoid", "(", "predictions", ")", "\n", "predictions", "=", "predictions", "*", "candidate_mask", "\n", "max_values", ",", "argsort", "=", "torch", ".", "sort", "(", "predictions", ",", "1", ",", "descending", "=", "True", ")", "\n", "argsort", "=", "argsort", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "gold_labels", "=", "gold_labels", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "i", "in", "range", "(", "predictions", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "rank", "=", "np", ".", "where", "(", "argsort", "[", "i", "]", "==", "gold_labels", "[", "i", "]", ")", "[", "0", "]", "[", "0", "]", "\n", "reciprocal_ranks", ".", "append", "(", "rank", "+", "1", ")", "\n", "", "return", "reciprocal_ranks", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.metrics.masked_index_fill": [[24, 28], ["index_mask.long().sum", "tensor.index_fill_", "index_mask.long"], "function", ["None"], ["", "def", "masked_index_fill", "(", "tensor", ",", "index", ",", "index_mask", ",", "value", ")", ":", "\n", "    ", "num_indices", "=", "index_mask", ".", "long", "(", ")", ".", "sum", "(", ")", "\n", "valid_indices", "=", "index", "[", ":", "num_indices", "]", "\n", "tensor", ".", "index_fill_", "(", "0", ",", "valid_indices", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.metrics.get_mask": [[30, 45], ["gold_labels.size", "range", "torch.zeros.scatter_", "torch.autograd.Variable", "torch.ones", "torch.zeros", "metrics.masked_index_fill", "torch.zeros.float", "torch.eq().float", "metrics.masked_index_fill", "gold_labels.unsqueeze", "torch.eq().float", "all_true_objects.size", "all_true_objects.data.new", "candidates.size", "all_true_objects.data.new", "torch.eq", "torch.eq"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.metrics.masked_index_fill", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.metrics.masked_index_fill"], ["", "def", "get_mask", "(", "all_true_objects", ",", "candidates", ",", "gold_labels", ",", "num_labels", ")", ":", "\n", "    ", "batch_size", "=", "gold_labels", ".", "size", "(", "0", ")", "\n", "all_true_objects_mask", "=", "(", "1", "-", "torch", ".", "eq", "(", "all_true_objects", ",", "-", "1", ")", ".", "float", "(", ")", ")", ".", "byte", "(", ")", "\n", "if", "candidates", "is", "None", ":", "\n", "        ", "candidates_mask", "=", "torch", ".", "ones", "(", "(", "all_true_objects", ".", "size", "(", "0", ")", ",", "num_labels", ")", ",", "out", "=", "all_true_objects", ".", "data", ".", "new", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "candidates_mask", "=", "torch", ".", "zeros", "(", "(", "candidates", ".", "size", "(", "0", ")", ",", "num_labels", ")", ",", "out", "=", "all_true_objects", ".", "data", ".", "new", "(", ")", ")", "\n", "cand_index_mask", "=", "(", "1", "-", "torch", ".", "eq", "(", "candidates", ",", "-", "1", ")", ".", "float", "(", ")", ")", "\n", "", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "if", "candidates", "is", "not", "None", ":", "\n", "            ", "masked_index_fill", "(", "candidates_mask", "[", "i", "]", ",", "candidates", "[", "i", "]", ".", "data", ",", "cand_index_mask", "[", "i", "]", ".", "data", ",", "1", ")", "\n", "", "masked_index_fill", "(", "candidates_mask", "[", "i", "]", ",", "all_true_objects", "[", "i", "]", ".", "data", ",", "all_true_objects_mask", "[", "i", "]", ".", "data", ",", "0", ")", "\n", "# candidates_mask.scatter_(1, all_true_objects.data, 0)", "\n", "", "candidates_mask", ".", "scatter_", "(", "1", ",", "gold_labels", ".", "unsqueeze", "(", "1", ")", ".", "data", ",", "1", ")", "\n", "return", "Variable", "(", "candidates_mask", ".", "float", "(", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.__init__": [[158, 175], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "self", ".", "n_examples", "=", "0", "\n", "self", ".", "loss", "=", "0.0", "\n", "self", ".", "pos_from_observed", "=", "0.0", "\n", "self", ".", "pos_from_sampled", "=", "0.0", "\n", "self", ".", "threshold", "=", "config", ".", "threshold", "\n", "self", ".", "pos_pred", "=", "0.0", "\n", "self", ".", "neg_pred", "=", "0.0", "\n", "self", ".", "positive_loss", "=", "0", "\n", "self", ".", "neg_sub_loss", "=", "0", "\n", "self", ".", "neg_obj_loss", "=", "0", "\n", "self", ".", "neg_rel_loss", "=", "0", "\n", "self", ".", "type_obj_loss", "=", "0", "\n", "self", ".", "type_sub_loss", "=", "0", "\n", "self", ".", "num_neg_samples", "=", "config", ".", "num_neg_samples", "\n", "self", ".", "num_sampled_relations", "=", "config", ".", "num_sampled_relations", "\n", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.update": [[176, 193], ["loss.item", "output_dict[].item", "output_dict[].item", "output_dict[].item", "output_dict[].item", "output_dict[].item", "output_dict[].item", "embeddings.metrics.positive_predictions_for", "embeddings.metrics.positive_predictions_for", "observed_probabilities.size"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.metrics.positive_predictions_for", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.metrics.positive_predictions_for"], ["", "def", "update", "(", "self", ",", "loss", ",", "output_dict", ")", ":", "\n", "        ", "self", ".", "loss", "+=", "loss", ".", "item", "(", ")", "\n", "self", ".", "positive_loss", "+=", "output_dict", "[", "'positive_loss'", "]", ".", "item", "(", ")", "\n", "self", ".", "neg_sub_loss", "+=", "output_dict", "[", "'negative_subject_loss'", "]", ".", "item", "(", ")", "if", "'negative_subject_loss'", "in", "output_dict", "else", "self", ".", "neg_sub_loss", "\n", "self", ".", "neg_obj_loss", "+=", "output_dict", "[", "'negative_object_loss'", "]", ".", "item", "(", ")", "if", "'negative_object_loss'", "in", "output_dict", "else", "self", ".", "neg_obj_loss", "\n", "\n", "self", ".", "type_sub_loss", "+=", "output_dict", "[", "'type_subject_loss'", "]", ".", "item", "(", ")", "if", "'type_subject_loss'", "in", "output_dict", "else", "self", ".", "type_sub_loss", "\n", "self", ".", "type_obj_loss", "+=", "output_dict", "[", "'type_object_loss'", "]", ".", "item", "(", ")", "if", "'type_object_loss'", "in", "output_dict", "else", "self", ".", "type_obj_loss", "\n", "self", ".", "neg_rel_loss", "+=", "output_dict", "[", "'negative_rel_loss'", "]", ".", "item", "(", ")", "if", "'negative_rel_loss'", "in", "output_dict", "else", "self", ".", "neg_rel_loss", "\n", "if", "'observed_probabilities'", "in", "output_dict", ":", "\n", "            ", "observed_probabilities", "=", "output_dict", "[", "'observed_probabilities'", "]", "\n", "self", ".", "n_examples", "+=", "observed_probabilities", ".", "size", "(", ")", "[", "0", "]", "\n", "sampled_probabilities", "=", "output_dict", "[", "'sampled_probabilities'", "]", "\n", "self", ".", "pos_pred", "+=", "metrics", ".", "positive_predictions_for", "(", "observed_probabilities", ",", "self", ".", "threshold", ")", "\n", "self", ".", "neg_pred", "+=", "metrics", ".", "positive_predictions_for", "(", "sampled_probabilities", ",", "self", ".", "threshold", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "n_examples", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.average": [[194, 196], ["None"], "methods", ["None"], ["", "", "def", "average", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "loss", "/", "self", ".", "n_examples", ",", "self", ".", "pos_pred", "/", "self", ".", "n_examples", ",", "(", "self", ".", "neg_pred", "/", "self", ".", "n_examples", ")", "/", "self", ".", "num_sampled_relations", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.average_loss": [[197, 199], ["None"], "methods", ["None"], ["", "def", "average_loss", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "positive_loss", "/", "self", ".", "n_examples", ",", "self", ".", "neg_sub_loss", "/", "self", ".", "n_examples", ",", "self", ".", "neg_obj_loss", "/", "self", ".", "n_examples", ",", "self", ".", "neg_rel_loss", "/", "self", ".", "n_examples", ",", "self", ".", "type_sub_loss", "/", "self", ".", "n_examples", ",", "self", ".", "type_obj_loss", "/", "self", ".", "n_examples", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.StatsLogger.__init__": [[203, 208], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "writer", ",", "start", ",", "batches_per_epoch", ")", ":", "\n", "        ", "self", ".", "log_template", "=", "' '", ".", "join", "(", "'{:>6.0f},{:>5.0f},{:>9.0f},{:>5.0f}/{:<5.0f},{:>8.6f},{:8.6f},{:12.4f},{:12.4f},{:12.4f},{:12.4f}'", ".", "split", "(", "','", ")", ")", "\n", "self", ".", "writer", "=", "writer", "\n", "self", ".", "start", "=", "start", "\n", "self", ".", "batches_per_epoch", "=", "batches_per_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.StatsLogger.log": [[209, 231], ["train_eval_stats.average", "logger.info", "train.StatsLogger.writer.add_scalar", "train.StatsLogger.writer.add_scalar", "train.StatsLogger.writer.add_scalar", "train.StatsLogger.writer.add_scalar", "train.StatsLogger.writer.add_scalar", "train.StatsLogger.writer.add_scalar", "dev_eval_stats.average", "train.StatsLogger.log_template.format", "time.time"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.average", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.average"], ["", "def", "log", "(", "self", ",", "epoch", ",", "iterations", ",", "batch_index", ",", "train_eval_stats", ",", "dev_eval_stats", "=", "None", ")", ":", "\n", "        ", "train_loss", ",", "train_pos", ",", "train_neg", "=", "train_eval_stats", ".", "average", "(", ")", "\n", "dev_loss", ",", "dev_pos", ",", "dev_neg", "=", "dev_eval_stats", ".", "average", "(", ")", "if", "dev_eval_stats", "is", "not", "None", "else", "(", "-", "1.0", ",", "-", "1.0", ",", "-", "1.0", ")", "\n", "logger", ".", "info", "(", "self", ".", "log_template", ".", "format", "(", "\n", "time", ".", "time", "(", ")", "-", "self", ".", "start", ",", "\n", "epoch", ",", "\n", "iterations", ",", "\n", "batch_index", "+", "1", ",", "\n", "self", ".", "batches_per_epoch", ",", "\n", "train_loss", ",", "\n", "dev_loss", ",", "\n", "train_pos", ",", "\n", "train_neg", ",", "\n", "dev_pos", ",", "\n", "dev_neg", ")", ")", "\n", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'Train_Loss'", ",", "train_loss", ",", "iterations", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'Dev_Loss'", ",", "dev_loss", ",", "iterations", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'Train_Pos.'", ",", "train_pos", ",", "iterations", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'Train_Neg.'", ",", "train_neg", ",", "iterations", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'Dev_Pos.'", ",", "dev_pos", ",", "iterations", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'Dev_Neg.'", ",", "dev_neg", ",", "iterations", ")", "\n", "# pos_loss, neg_sub_loss, neg_obj_loss, neg_rel_loss = train_eval_stats.average_loss()", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.StatsLogger.epoch_log": [[234, 242], ["train_eval_stats.average", "dev_eval_stats.average", "train_eval_stats.average_loss", "logger.info", "logger.info", "logger.info"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.average", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.average", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.average_loss"], ["", "def", "epoch_log", "(", "self", ",", "epoch", ",", "iterations", ",", "train_eval_stats", ",", "dev_eval_stats", ")", ":", "\n", "        ", "train_loss", ",", "train_pos", ",", "train_neg", "=", "train_eval_stats", ".", "average", "(", ")", "\n", "dev_loss", ",", "dev_pos", ",", "dev_neg", "=", "dev_eval_stats", ".", "average", "(", ")", "\n", "pos_loss", ",", "neg_sub_loss", ",", "neg_obj_loss", ",", "neg_rel_loss", ",", "type_sub_loss", ",", "type_obj_loss", "=", "train_eval_stats", ".", "average_loss", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"In epoch {}\"", ".", "format", "(", "epoch", ")", ")", "\n", "logger", ".", "info", "(", "\"Epoch:{}, iter:{}, train loss: {:.6f}, dev loss:{:.6f}, train pos:{:.4f}, train neg:{:.4f}, dev pos: {:.4f} dev neg: {:.4f}\"", ".", "format", "(", "epoch", ",", "iterations", ",", "train_loss", ",", "dev_loss", ",", "train_pos", ",", "train_neg", ",", "dev_pos", ",", "dev_neg", ")", ")", "\n", "logger", ".", "info", "(", "'pos_loss {:.3f}, neg_sub_loss {:.3f}, neg_obj_loss {:.3f}, neg_rel_loss {:.3f}, type_sub_loss {:.3f}, type_obj_loss {:.3f}'", ".", "format", "(", "pos_loss", ",", "neg_sub_loss", ",", "neg_obj_loss", ",", "neg_rel_loss", ",", "type_sub_loss", ",", "type_obj_loss", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.prepare_env": [[24, 38], ["logging.FileHandler", "logging.FileHandler.setFormatter", "logger.addHandler", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.is_available", "torch.cuda.is_available", "os.path.join", "logging.Formatter", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "prepare_env", "(", "args", ",", "config", ")", ":", "\n", "# logging", "\n", "    ", "mode", "=", "'a'", "if", "args", ".", "resume_snapshot", "else", "'w'", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "config", ".", "save_path", ",", "'stdout.log'", ")", ",", "mode", "=", "mode", ")", "\n", "fh", ".", "setFormatter", "(", "logging", ".", "Formatter", "(", "format", ")", ")", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "\n", "# add seeds", "\n", "seed", "=", "args", ".", "seed", "\n", "numpy", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "# Seed all GPUs with the same seed if available.", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.main": [[39, 63], ["train.prepare_env", "embeddings.matrix_data.read_data", "getattr", "embeddings.model.Pair2Vec.cuda", "filter", "torch.SGD", "tensorboardX.SummaryWriter", "train.train", "tensorboardX.SummaryWriter.export_scalars_to_json", "tensorboardX.SummaryWriter.close", "embeddings.model.Pair2Vec", "NotImplementedError", "embeddings.model.Pair2Vec.parameters", "embeddings.util.resume_from"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.prepare_env", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.read_data", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.train", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.resume_from"], ["", "", "def", "main", "(", "args", ",", "config", ")", ":", "\n", "    ", "prepare_env", "(", "args", ",", "config", ")", "\n", "train_data", ",", "dev_data", ",", "train_iterator", ",", "dev_iterator", ",", "args_field", ",", "rels_field", "=", "read_data", "(", "config", ",", "preindex", "=", "True", ")", "\n", "\n", "model_type", "=", "getattr", "(", "config", ",", "'model_type'", ",", "'sampling'", ")", "\n", "if", "model_type", "==", "'sampling'", ":", "\n", "        ", "model", "=", "Pair2Vec", "(", "config", ",", "args_field", ".", "vocab", ",", "rels_field", ".", "vocab", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "model", ".", "cuda", "(", ")", "\n", "params", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", "\n", "opt", "=", "optim", ".", "SGD", "(", "params", ",", "lr", "=", "config", ".", "lr", ")", "\n", "\n", "checkpoint", "=", "None", "\n", "if", "args", ".", "resume_snapshot", ":", "\n", "        ", "checkpoint", "=", "util", ".", "resume_from", "(", "args", ".", "resume_snapshot", ",", "model", ",", "opt", ")", "\n", "\n", "", "writer", "=", "SummaryWriter", "(", "comment", "=", "\"_\"", "+", "args", ".", "exp", ")", "\n", "\n", "train", "(", "train_data", ",", "dev_data", ",", "train_iterator", ",", "dev_iterator", ",", "model", ",", "config", ",", "opt", ",", "writer", ",", "checkpoint", ")", "\n", "\n", "writer", ".", "export_scalars_to_json", "(", "\"./all_scalars.json\"", ")", "\n", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.get_lr": [[64, 69], ["None"], "function", ["None"], ["", "def", "get_lr", "(", "optimizer", ")", ":", "\n", "    ", "lr", "=", "[", "]", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "       ", "lr", "+=", "[", "param_group", "[", "'lr'", "]", "]", "\n", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.train": [[70, 140], ["logger.info", "time.time", "embeddings.util.makedirs", "train.StatsLogger", "torch.optim.lr_scheduler.ReduceLROnPlateau", "logger.info", "logger.info", "range", "train.EvaluationStatistics", "enumerate", "embeddings.util.save_checkpoint", "train.get_lr", "train_iterator", "model.train", "opt.zero_grad", "model", "loss.backward", "train.rescale_gradients", "opt.step", "train.EvaluationStatistics.update", "train.EvaluationStatistics.average", "model.eval", "train.EvaluationStatistics", "enumerate", "torch.optim.lr_scheduler.ReduceLROnPlateau.step", "train.StatsLogger.log", "train.StatsLogger.epoch_log", "train.EvaluationStatistics", "logger.info", "dev_iterator", "model", "train.EvaluationStatistics.update", "train.EvaluationStatistics.average", "embeddings.util.save_checkpoint", "train.StatsLogger.log", "train.EvaluationStatistics.average", "train.get_lr"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.makedirs", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.save_checkpoint", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.get_lr", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.train", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.rescale_gradients", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.update", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.average", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.StatsLogger.log", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.StatsLogger.epoch_log", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.update", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.average", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.save_checkpoint", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.StatsLogger.log", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.average", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.get_lr"], ["", "def", "train", "(", "train_data", ",", "dev_data", ",", "train_iterator", ",", "dev_iterator", ",", "model", ",", "config", ",", "opt", ",", "writer", ",", "checkpoint", "=", "None", ")", ":", "\n", "\n", "    ", "logger", ".", "info", "(", "model", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "best_dev_loss", ",", "best_train_loss", "=", "1000", ",", "1000", "\n", "\n", "makedirs", "(", "config", ".", "save_path", ")", "\n", "stats_logger", "=", "StatsLogger", "(", "writer", ",", "start", ",", "0", ")", "\n", "\n", "iterations", "=", "0", "if", "checkpoint", "is", "None", "else", "checkpoint", "[", "'iterations'", "]", "\n", "start_epoch", "=", "0", "if", "checkpoint", "is", "None", "else", "checkpoint", "[", "'epoch'", "]", "\n", "#scheduler = StepLR(opt, step_size=1, gamma=0.9)", "\n", "scheduler", "=", "ReduceLROnPlateau", "(", "opt", ",", "mode", "=", "'min'", ",", "factor", "=", "0.9", ",", "patience", "=", "10", ",", "verbose", "=", "True", ",", "threshold", "=", "0.001", ")", "\n", "\n", "logger", ".", "info", "(", "'LR: {}'", ".", "format", "(", "get_lr", "(", "opt", ")", ")", ")", "\n", "logger", ".", "info", "(", "'    Time Epoch Iteration Progress    Loss     Dev_Loss     Train_Pos     Train_Neg     Dev_Pos     Dev_Neg'", ")", "\n", "\n", "dev_eval_stats", "=", "None", "\n", "#import ipdb", "\n", "#ipdb.set_trace()", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "config", ".", "epochs", ")", ":", "\n", "# train_iter.init_epoch()", "\n", "        ", "train_eval_stats", "=", "EvaluationStatistics", "(", "config", ")", "\n", "\n", "for", "batch_index", ",", "batch", "in", "enumerate", "(", "train_iterator", "(", "train_data", ",", "device", "=", "None", ",", "train", "=", "True", ")", ")", ":", "\n", "# Switch model to training mode, clear gradient accumulators", "\n", "            ", "model", ".", "train", "(", ")", "\n", "opt", ".", "zero_grad", "(", ")", "\n", "iterations", "+=", "1", "\n", "\n", "# forward pass", "\n", "answer", ",", "loss", ",", "output_dict", "=", "model", "(", "batch", ")", "\n", "\n", "# backpropagate and update optimizer learning rate", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# grad clipping", "\n", "rescale_gradients", "(", "model", ",", "config", ".", "grad_norm", ")", "\n", "opt", ".", "step", "(", ")", "\n", "\n", "# aggregate training error", "\n", "train_eval_stats", ".", "update", "(", "loss", ",", "output_dict", ")", "\n", "\n", "\n", "# evaluate performance on validation set periodically", "\n", "if", "iterations", "%", "config", ".", "dev_every", "==", "0", ":", "\n", "                ", "model", ".", "eval", "(", ")", "\n", "dev_eval_stats", "=", "EvaluationStatistics", "(", "config", ")", "\n", "for", "dev_batch_index", ",", "dev_batch", "in", "(", "enumerate", "(", "dev_iterator", "(", "dev_data", ",", "device", "=", "None", ",", "train", "=", "False", ")", ")", ")", ":", "\n", "                    ", "answer", ",", "loss", ",", "dev_output_dict", "=", "model", "(", "dev_batch", ")", "\n", "dev_eval_stats", ".", "update", "(", "loss", ",", "dev_output_dict", ")", "\n", "\n", "", "scheduler", ".", "step", "(", "train_eval_stats", ".", "average", "(", ")", "[", "0", "]", ")", "\n", "stats_logger", ".", "log", "(", "epoch", ",", "iterations", ",", "batch_index", ",", "train_eval_stats", ",", "dev_eval_stats", ")", "\n", "stats_logger", ".", "epoch_log", "(", "epoch", ",", "iterations", ",", "train_eval_stats", ",", "dev_eval_stats", ")", "\n", "\n", "# update best validation set accuracy", "\n", "train_loss", "=", "train_eval_stats", ".", "average", "(", ")", "[", "0", "]", "\n", "if", "train_loss", "<", "best_train_loss", ":", "\n", "                    ", "best_train_loss", "=", "train_loss", "\n", "util", ".", "save_checkpoint", "(", "config", ",", "model", ",", "opt", ",", "epoch", ",", "iterations", ",", "train_eval_stats", ",", "dev_eval_stats", ",", "'best_train_snapshot'", ")", "\n", "\n", "# reset train stats", "\n", "", "train_eval_stats", "=", "EvaluationStatistics", "(", "config", ")", "\n", "logger", ".", "info", "(", "'LR: {}'", ".", "format", "(", "get_lr", "(", "opt", ")", ")", ")", "\n", "\n", "", "elif", "iterations", "%", "config", ".", "log_every", "==", "0", ":", "\n", "                ", "stats_logger", ".", "log", "(", "epoch", ",", "iterations", ",", "batch_index", ",", "train_eval_stats", ",", "dev_eval_stats", ")", "\n", "", "", "train_loss", "=", "train_eval_stats", ".", "average", "(", ")", "[", "0", "]", "\n", "util", ".", "save_checkpoint", "(", "config", ",", "model", ",", "opt", ",", "epoch", ",", "iterations", ",", "train_eval_stats", ",", "dev_eval_stats", ",", "'epoch_train_snapshot'", ",", "remove", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.rescale_gradients": [[142, 145], ["torch.nn.utils.clip_grad_norm", "model.parameters"], "function", ["None"], ["", "", "def", "rescale_gradients", "(", "model", ",", "grad_norm", ")", ":", "\n", "    ", "parameters_to_clip", "=", "[", "p", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "grad", "is", "not", "None", "]", "\n", "clip_grad_norm", "(", "parameters_to_clip", ",", "grad_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.save": [[147, 154], ["os.path.join", "torch.save", "torch.save", "glob.glob", "model.state_dict", "os.remove"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.save", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.save"], ["", "def", "save", "(", "config", ",", "model", ",", "loss", ",", "iterations", ",", "name", ")", ":", "\n", "    ", "snapshot_prefix", "=", "os", ".", "path", ".", "join", "(", "config", ".", "save_path", ",", "name", ")", "\n", "snapshot_path", "=", "snapshot_prefix", "+", "'_loss_{:.6f}_iter_{}_model.pt'", ".", "format", "(", "loss", ".", "data", "[", "0", "]", ",", "iterations", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "snapshot_path", ")", "\n", "for", "f", "in", "glob", ".", "glob", "(", "snapshot_prefix", "+", "'*'", ")", ":", "\n", "        ", "if", "f", "!=", "snapshot_path", ":", "\n", "            ", "os", ".", "remove", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.RawField.__init__": [[34, 37], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "preprocessing", "=", "None", ",", "postprocessing", "=", "None", ")", ":", "\n", "\t\t", "self", ".", "preprocessing", "=", "preprocessing", "\n", "self", ".", "postprocessing", "=", "postprocessing", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.RawField.preprocess": [[38, 44], ["indexed_field.RawField.preprocessing"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ",", "x", ")", ":", "\n", "\t\t", "\"\"\" Preprocess an example if the `preprocessing` Pipeline is provided. \"\"\"", "\n", "if", "self", ".", "preprocessing", "is", "not", "None", ":", "\n", "\t\t\t", "return", "self", ".", "preprocessing", "(", "x", ")", "\n", "", "else", ":", "\n", "\t\t\t", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.RawField.process": [[45, 59], ["indexed_field.RawField.postprocessing"], "methods", ["None"], ["", "", "def", "process", "(", "self", ",", "batch", ",", "*", "args", ",", "**", "kargs", ")", ":", "\n", "\t\t", "\"\"\" Process a list of examples to create a batch.\n\n\t\tPostprocess the batch with user-provided Pipeline.\n\n\t\tArgs:\n\t\t\tbatch (list(object)): A list of object from a batch of examples.\n\t\tReturns:\n\t\t\tobject: Processed object given the input and custom\n\t\t\t\tpostprocessing Pipeline.\n\t\t\"\"\"", "\n", "if", "self", ".", "postprocessing", "is", "not", "None", ":", "\n", "\t\t\t", "batch", "=", "self", ".", "postprocessing", "(", "batch", ")", "\n", "", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.Field.__init__": [[134, 156], ["torchtext.data.utils.get_tokenizer", "s.split"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sequential", "=", "True", ",", "use_vocab", "=", "True", ",", "init_token", "=", "None", ",", "\n", "eos_token", "=", "None", ",", "fix_length", "=", "None", ",", "tensor_type", "=", "torch", ".", "LongTensor", ",", "\n", "preprocessing", "=", "None", ",", "postprocessing", "=", "None", ",", "lower", "=", "False", ",", "\n", "tokenize", "=", "(", "lambda", "s", ":", "s", ".", "split", "(", ")", ")", ",", "include_lengths", "=", "False", ",", "\n", "batch_first", "=", "False", ",", "pad_token", "=", "\"<pad>\"", ",", "unk_token", "=", "\"<unk>\"", ",", "\n", "pad_first", "=", "False", ",", "truncate_first", "=", "False", ")", ":", "\n", "\t\t", "self", ".", "sequential", "=", "sequential", "\n", "self", ".", "use_vocab", "=", "use_vocab", "\n", "self", ".", "init_token", "=", "init_token", "\n", "self", ".", "eos_token", "=", "eos_token", "\n", "self", ".", "unk_token", "=", "unk_token", "\n", "self", ".", "fix_length", "=", "fix_length", "\n", "self", ".", "tensor_type", "=", "tensor_type", "\n", "self", ".", "preprocessing", "=", "preprocessing", "\n", "self", ".", "postprocessing", "=", "postprocessing", "\n", "self", ".", "lower", "=", "lower", "\n", "self", ".", "tokenize", "=", "get_tokenizer", "(", "tokenize", ")", "\n", "self", ".", "include_lengths", "=", "include_lengths", "\n", "self", ".", "batch_first", "=", "batch_first", "\n", "self", ".", "pad_token", "=", "pad_token", "if", "self", ".", "sequential", "else", "None", "\n", "self", ".", "pad_first", "=", "pad_first", "\n", "self", ".", "truncate_first", "=", "truncate_first", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.Field.preprocess": [[157, 175], ["isinstance", "isinstance", "indexed_field.Field.tokenize", "indexed_field.Field.preprocessing", "isinstance", "torchtext.data.pipeline.Pipeline", "indexed_field.Field.rstrip", "torchtext.data.pipeline.Pipeline", "six.text_type"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ",", "x", ")", ":", "\n", "\t\t", "\"\"\"Load a single example using this field, tokenizing if necessary.\n\n\t\tIf the input is a Python 2 `str`, it will be converted to Unicode\n\t\tfirst. If `sequential=True`, it will be tokenized. Then the input\n\t\twill be optionally lowercased and passed to the user-provided\n\t\t`preprocessing` Pipeline.\"\"\"", "\n", "if", "(", "six", ".", "PY2", "and", "isinstance", "(", "x", ",", "six", ".", "string_types", ")", "and", "\n", "not", "isinstance", "(", "x", ",", "six", ".", "text_type", ")", ")", ":", "\n", "\t\t\t", "x", "=", "Pipeline", "(", "lambda", "s", ":", "six", ".", "text_type", "(", "s", ",", "encoding", "=", "'utf-8'", ")", ")", "(", "x", ")", "\n", "", "if", "self", ".", "sequential", "and", "isinstance", "(", "x", ",", "six", ".", "text_type", ")", ":", "\n", "\t\t\t", "x", "=", "self", ".", "tokenize", "(", "x", ".", "rstrip", "(", "'\\n'", ")", ")", "\n", "", "if", "self", ".", "lower", ":", "\n", "\t\t\t", "x", "=", "Pipeline", "(", "six", ".", "text_type", ".", "lower", ")", "(", "x", ")", "\n", "", "if", "self", ".", "preprocessing", "is", "not", "None", ":", "\n", "\t\t\t", "return", "self", ".", "preprocessing", "(", "x", ")", "\n", "", "else", ":", "\n", "\t\t\t", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.Field.process": [[176, 194], ["indexed_field.Field.pad", "indexed_field.Field.numericalize", "indexed_field.Field.pad_indexed", "indexed_field.Field.numericalize_indexed"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.Field.pad", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.Field.numericalize", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.Field.pad_indexed", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.Field.numericalize_indexed"], ["", "", "def", "process", "(", "self", ",", "batch", ",", "device", ",", "train", ",", "indexed", "=", "False", ")", ":", "\n", "\t\t", "\"\"\" Process a list of examples to create a torch.Tensor.\n\n\t\tPad, numericalize, and postprocess a batch and create a tensor.\n\n\t\tArgs:\n\t\t\tbatch (list(object)): A list of object from a batch of examples.\n\t\tReturns:\n\t\t\ttorch.autograd.Variable: Processed object given the input\n\t\t\t\tand custom postprocessing Pipeline.\n\t\t\"\"\"", "\n", "if", "not", "indexed", ":", "\n", "\t\t\t", "padded", "=", "self", ".", "pad", "(", "batch", ")", "\n", "tensor", "=", "self", ".", "numericalize", "(", "padded", ",", "device", "=", "device", ",", "train", "=", "train", ")", "\n", "", "else", ":", "\n", "\t\t\t", "padded", "=", "self", ".", "pad_indexed", "(", "batch", ")", "\n", "tensor", "=", "self", ".", "numericalize_indexed", "(", "padded", ",", "device", "=", "device", ",", "train", "=", "train", ")", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.Field.pad": [[195, 231], ["list", "max", "lengths.append", "padded.append", "padded.append", "len", "len", "max", "list", "max", "len", "list", "max", "len", "len"], "methods", ["None"], ["", "def", "pad", "(", "self", ",", "minibatch", ")", ":", "\n", "\t\t", "\"\"\"Pad a batch of examples using this field.\n\n\t\tPads to self.fix_length if provided, otherwise pads to the length of\n\t\tthe longest example in the batch. Prepends self.init_token and appends\n\t\tself.eos_token if those attributes are not None. Returns a tuple of the\n\t\tpadded list and a list containing lengths of each example if\n\t\t`self.include_lengths` is `True` and `self.sequential` is `True`, else just\n\t\treturns the padded list. If `self.sequential` is `False`, no padding is applied.\n\t\t\"\"\"", "\n", "minibatch", "=", "list", "(", "minibatch", ")", "\n", "if", "not", "self", ".", "sequential", ":", "\n", "\t\t\t", "return", "minibatch", "\n", "", "if", "self", ".", "fix_length", "is", "None", ":", "\n", "\t\t\t", "max_len", "=", "max", "(", "len", "(", "x", ")", "for", "x", "in", "minibatch", ")", "\n", "", "else", ":", "\n", "\t\t\t", "max_len", "=", "self", ".", "fix_length", "+", "(", "\n", "self", ".", "init_token", ",", "self", ".", "eos_token", ")", ".", "count", "(", "None", ")", "-", "2", "\n", "", "padded", ",", "lengths", "=", "[", "]", ",", "[", "]", "\n", "for", "x", "in", "minibatch", ":", "\n", "\t\t\t", "if", "self", ".", "pad_first", ":", "\n", "\t\t\t\t", "padded", ".", "append", "(", "\n", "[", "self", ".", "pad_token", "]", "*", "max", "(", "0", ",", "max_len", "-", "len", "(", "x", ")", ")", "+", "\n", "(", "[", "]", "if", "self", ".", "init_token", "is", "None", "else", "[", "self", ".", "init_token", "]", ")", "+", "\n", "list", "(", "x", "[", "-", "max_len", ":", "]", "if", "self", ".", "truncate_first", "else", "x", "[", ":", "max_len", "]", ")", "+", "\n", "(", "[", "]", "if", "self", ".", "eos_token", "is", "None", "else", "[", "self", ".", "eos_token", "]", ")", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "padded", ".", "append", "(", "\n", "(", "[", "]", "if", "self", ".", "init_token", "is", "None", "else", "[", "self", ".", "init_token", "]", ")", "+", "\n", "list", "(", "x", "[", "-", "max_len", ":", "]", "if", "self", ".", "truncate_first", "else", "x", "[", ":", "max_len", "]", ")", "+", "\n", "(", "[", "]", "if", "self", ".", "eos_token", "is", "None", "else", "[", "self", ".", "eos_token", "]", ")", "+", "\n", "[", "self", ".", "pad_token", "]", "*", "max", "(", "0", ",", "max_len", "-", "len", "(", "x", ")", ")", ")", "\n", "", "lengths", ".", "append", "(", "len", "(", "padded", "[", "-", "1", "]", ")", "-", "max", "(", "0", ",", "max_len", "-", "len", "(", "x", ")", ")", ")", "\n", "", "if", "self", ".", "include_lengths", ":", "\n", "\t\t\t", "return", "(", "padded", ",", "lengths", ")", "\n", "", "return", "padded", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.Field.pad_indexed": [[232, 268], ["list", "max", "lengths.append", "padded.append", "padded.append", "len", "len", "max", "list", "max", "len", "list", "max", "len", "len"], "methods", ["None"], ["", "def", "pad_indexed", "(", "self", ",", "minibatch", ")", ":", "\n", "\t\t", "\"\"\"Pad a batch of pre-indexed examples using this field.\n\n\t\tPads to self.fix_length if provided, otherwise pads to the length of\n\t\tthe longest example in the batch. Prepends self.init_token and appends\n\t\tself.eos_token if those attributes are not None. Returns a tuple of the\n\t\tpadded list and a list containing lengths of each example if\n\t\t`self.include_lengths` is `True` and `self.sequential` is `True`, else just\n\t\treturns the padded list. If `self.sequential` is `False`, no padding is applied.\n\t\t\"\"\"", "\n", "minibatch", "=", "list", "(", "minibatch", ")", "\n", "if", "not", "self", ".", "sequential", ":", "\n", "\t\t\t", "return", "minibatch", "\n", "", "if", "self", ".", "fix_length", "is", "None", ":", "\n", "\t\t\t", "max_len", "=", "max", "(", "len", "(", "x", ")", "for", "x", "in", "minibatch", ")", "\n", "", "else", ":", "\n", "\t\t\t", "max_len", "=", "self", ".", "fix_length", "+", "(", "\n", "self", ".", "vocab", ".", "stoi", "[", "self", ".", "init_token", "]", ",", "self", ".", "eos_token", ")", ".", "count", "(", "None", ")", "-", "2", "\n", "", "padded", ",", "lengths", "=", "[", "]", ",", "[", "]", "\n", "for", "x", "in", "minibatch", ":", "\n", "\t\t\t", "if", "self", ".", "pad_first", ":", "\n", "\t\t\t\t", "padded", ".", "append", "(", "\n", "[", "pad_id", "]", "*", "max", "(", "0", ",", "max_len", "-", "len", "(", "x", ")", ")", "+", "\n", "(", "[", "]", "if", "self", ".", "init_token", "is", "None", "else", "[", "self", ".", "vocab", ".", "stoi", "[", "self", ".", "init_token", "]", "]", ")", "+", "\n", "list", "(", "x", "[", "-", "max_len", ":", "]", "if", "self", ".", "truncate_first", "else", "x", "[", ":", "max_len", "]", ")", "+", "\n", "(", "[", "]", "if", "self", ".", "eos_token", "is", "None", "else", "[", "self", ".", "vocab", ".", "stoi", "[", "eos_token", "]", "]", ")", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "padded", ".", "append", "(", "\n", "(", "[", "]", "if", "self", ".", "init_token", "is", "None", "else", "[", "self", ".", "vocab", ".", "stoi", "[", "self", ".", "init_token", "]", "]", ")", "+", "\n", "list", "(", "x", "[", "-", "max_len", ":", "]", "if", "self", ".", "truncate_first", "else", "x", "[", ":", "max_len", "]", ")", "+", "\n", "(", "[", "]", "if", "self", ".", "eos_token", "is", "None", "else", "[", "self", ".", "vocab", ".", "stoi", "[", "self", ".", "eos_token", "]", "]", ")", "+", "\n", "[", "self", ".", "vocab", ".", "stoi", "[", "self", ".", "pad_token", "]", "]", "*", "max", "(", "0", ",", "max_len", "-", "len", "(", "x", ")", ")", ")", "\n", "", "lengths", ".", "append", "(", "len", "(", "padded", "[", "-", "1", "]", ")", "-", "max", "(", "0", ",", "max_len", "-", "len", "(", "x", ")", ")", ")", "\n", "", "if", "self", ".", "include_lengths", ":", "\n", "\t\t\t", "return", "(", "padded", ",", "lengths", ")", "\n", "", "return", "padded", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.Field.build_vocab": [[269, 299], ["collections.Counter", "list", "indexed_field.Field.vocab_cls", "isinstance", "collections.OrderedDict.fromkeys", "sources.append", "collections.Counter.update", "getattr", "arg.fields.items"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.update"], ["", "def", "build_vocab", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "\"\"\"Construct the Vocab object for this field from one or more datasets.\n\n\t\tArguments:\n\t\t\tPositional arguments: Dataset objects or other iterable data\n\t\t\t\tsources from which to construct the Vocab object that\n\t\t\t\trepresents the set of possible values for this field. If\n\t\t\t\ta Dataset object is provided, all columns corresponding\n\t\t\t\tto this field are used; individual columns can also be\n\t\t\t\tprovided directly.\n\t\t\tRemaining keyword arguments: Passed to the constructor of Vocab.\n\t\t\"\"\"", "\n", "counter", "=", "Counter", "(", ")", "\n", "sources", "=", "[", "]", "\n", "for", "arg", "in", "args", ":", "\n", "\t\t\t", "if", "isinstance", "(", "arg", ",", "Dataset", ")", ":", "\n", "\t\t\t\t", "sources", "+=", "[", "getattr", "(", "arg", ",", "name", ")", "for", "name", ",", "field", "in", "\n", "arg", ".", "fields", ".", "items", "(", ")", "if", "field", "is", "self", "]", "\n", "", "else", ":", "\n", "\t\t\t\t", "sources", ".", "append", "(", "arg", ")", "\n", "", "", "for", "data", "in", "sources", ":", "\n", "\t\t\t", "for", "x", "in", "data", ":", "\n", "\t\t\t\t", "if", "not", "self", ".", "sequential", ":", "\n", "\t\t\t\t\t", "x", "=", "[", "x", "]", "\n", "", "counter", ".", "update", "(", "x", ")", "\n", "", "", "specials", "=", "list", "(", "OrderedDict", ".", "fromkeys", "(", "\n", "tok", "for", "tok", "in", "[", "self", ".", "unk_token", ",", "self", ".", "pad_token", ",", "self", ".", "init_token", ",", "\n", "self", ".", "eos_token", "]", "\n", "if", "tok", "is", "not", "None", ")", ")", "\n", "self", ".", "vocab", "=", "self", ".", "vocab_cls", "(", "counter", ",", "specials", "=", "specials", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.Field.index": [[300, 353], ["isinstance", "ValueError", "isinstance", "indexed_field.Field.postprocessing", "ValueError", "indexed_field.Field.postprocessing", "torch.autograd.Variable", "isinstance", "numericalization_func"], "methods", ["None"], ["", "def", "index", "(", "self", ",", "arr", ")", ":", "\n", "\t\t", "\"\"\"Turn a batch of examples that use this field into a indexes.\n\n\t\tIf the field has include_lengths=True, a tensor of lengths will be\n\t\tincluded in the return value.\n\n\t\tArguments:\n\t\t\tarr (List[List[str]], or tuple of (List[List[str]], List[int])):\n\t\t\t\tList of tokenized and padded examples, or tuple of List of\n\t\t\t\ttokenized and padded examples and List of lengths of each\n\t\t\t\texample if self.include_lengths is True.\n\t\t\tdevice (-1 or None): Device to create the Variable's Tensor on.\n\t\t\t\tUse -1 for CPU and None for the currently active GPU device.\n\t\t\t\tDefault: None.\n\t\t\ttrain (boolean): Whether the batch is for a training set.\n\t\t\t\tIf False, the Variable will be created with volatile=True.\n\t\t\t\tDefault: True.\n\t\t\"\"\"", "\n", "if", "self", ".", "include_lengths", "and", "not", "isinstance", "(", "arr", ",", "tuple", ")", ":", "\n", "\t\t\t", "raise", "ValueError", "(", "\"Field has include_lengths set to True, but \"", "\n", "\"input data is not a tuple of \"", "\n", "\"(data batch, batch lengths).\"", ")", "\n", "", "if", "isinstance", "(", "arr", ",", "tuple", ")", ":", "\n", "\t\t\t", "arr", ",", "lengths", "=", "arr", "\n", "\n", "", "if", "self", ".", "use_vocab", ":", "\n", "\t\t\t", "if", "self", ".", "sequential", ":", "\n", "\t\t\t\t", "arr", "=", "[", "[", "self", ".", "vocab", ".", "stoi", "[", "x", "]", "for", "x", "in", "ex", "]", "for", "ex", "in", "arr", "]", "\n", "", "else", ":", "\n", "\t\t\t\t", "arr", "=", "[", "self", ".", "vocab", ".", "stoi", "[", "x", "]", "for", "x", "in", "arr", "]", "\n", "\n", "", "if", "self", ".", "postprocessing", "is", "not", "None", ":", "\n", "\t\t\t\t", "arr", "=", "self", ".", "postprocessing", "(", "arr", ",", "self", ".", "vocab", ",", "train", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "if", "self", ".", "tensor_type", "not", "in", "self", ".", "tensor_types", ":", "\n", "\t\t\t\t", "raise", "ValueError", "(", "\n", "\"Specified Field tensor_type {} can not be used with \"", "\n", "\"use_vocab=False because we do not know how to numericalize it. \"", "\n", "\"Please raise an issue at \"", "\n", "\"https://github.com/pytorch/text/issues\"", ".", "format", "(", "self", ".", "tensor_type", ")", ")", "\n", "", "numericalization_func", "=", "self", ".", "tensor_types", "[", "self", ".", "tensor_type", "]", "\n", "# It doesn't make sense to explictly coerce to a numeric type if", "\n", "# the data is sequential, since it's unclear how to coerce padding tokens", "\n", "# to a numeric type.", "\n", "if", "not", "self", ".", "sequential", ":", "\n", "\t\t\t\t", "arr", "=", "[", "numericalization_func", "(", "x", ")", "if", "isinstance", "(", "x", ",", "six", ".", "string_types", ")", "\n", "else", "x", "for", "x", "in", "arr", "]", "\n", "", "if", "self", ".", "postprocessing", "is", "not", "None", ":", "\n", "\t\t\t\t", "arr", "=", "self", ".", "postprocessing", "(", "arr", ",", "None", ",", "train", ")", "\n", "\n", "", "", "if", "self", ".", "include_lengths", ":", "\n", "\t\t\t", "return", "Variable", "(", "arr", ",", "volatile", "=", "not", "train", ")", ",", "lengths", "\n", "", "return", "arr", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.Field.numericalize_indexed": [[354, 392], ["isinstance", "indexed_field.Field.tensor_type", "torch.autograd.Variable", "ValueError", "torch.LongTensor", "arr.contiguous.contiguous.t_", "arr.contiguous.contiguous.cuda", "isinstance", "arr.contiguous.contiguous.contiguous", "lengths.cuda.cuda.cuda", "torch.autograd.Variable"], "methods", ["None"], ["", "def", "numericalize_indexed", "(", "self", ",", "arr", ",", "device", "=", "None", ",", "train", "=", "True", ")", ":", "\n", "\t\t", "\"\"\"Turn a batch of examples that use this field into a Variable.\n\n\t\tIf the field has include_lengths=True, a tensor of lengths will be\n\t\tincluded in the return value.\n\n\t\tArguments:\n\t\t\tarr (List[List[str]], or tuple of (List[List[str]], List[int])):\n\t\t\t\tList of tokenized and padded examples, or tuple of List of\n\t\t\t\ttokenized and padded examples and List of lengths of each\n\t\t\t\texample if self.include_lengths is True.\n\t\t\tdevice (-1 or None): Device to create the Variable's Tensor on.\n\t\t\t\tUse -1 for CPU and None for the currently active GPU device.\n\t\t\t\tDefault: None.\n\t\t\ttrain (boolean): Whether the batch is for a training set.\n\t\t\t\tIf False, the Variable will be created with volatile=True.\n\t\t\t\tDefault: True.\n\t\t\"\"\"", "\n", "if", "self", ".", "include_lengths", "and", "not", "isinstance", "(", "arr", ",", "tuple", ")", ":", "\n", "\t\t\t", "raise", "ValueError", "(", "\"Field has include_lengths set to True, but \"", "\n", "\"input data is not a tuple of \"", "\n", "\"(data batch, batch lengths).\"", ")", "\n", "", "if", "isinstance", "(", "arr", ",", "tuple", ")", ":", "\n", "\t\t\t", "arr", ",", "lengths", "=", "arr", "\n", "lengths", "=", "torch", ".", "LongTensor", "(", "lengths", ")", "\n", "", "arr", "=", "self", ".", "tensor_type", "(", "arr", ")", "\n", "if", "self", ".", "sequential", "and", "not", "self", ".", "batch_first", ":", "\n", "\t\t\t", "arr", ".", "t_", "(", ")", "\n", "", "if", "device", "==", "-", "1", ":", "\n", "\t\t\t", "if", "self", ".", "sequential", ":", "\n", "\t\t\t\t", "arr", "=", "arr", ".", "contiguous", "(", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "arr", "=", "arr", ".", "cuda", "(", "device", ")", "\n", "if", "self", ".", "include_lengths", ":", "\n", "\t\t\t\t", "lengths", "=", "lengths", ".", "cuda", "(", "device", ")", "\n", "", "", "if", "self", ".", "include_lengths", ":", "\n", "\t\t\t", "return", "Variable", "(", "arr", ",", "volatile", "=", "not", "train", ")", ",", "lengths", "\n", "", "return", "Variable", "(", "arr", ",", "volatile", "=", "not", "train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.Field.numericalize": [[393, 457], ["isinstance", "indexed_field.Field.tensor_type", "torch.autograd.Variable", "ValueError", "torch.LongTensor", "arr.contiguous.contiguous.t_", "arr.contiguous.contiguous.cuda", "isinstance", "indexed_field.Field.postprocessing", "ValueError", "indexed_field.Field.postprocessing", "arr.contiguous.contiguous.contiguous", "lengths.cuda.cuda.cuda", "torch.autograd.Variable", "isinstance", "numericalization_func"], "methods", ["None"], ["", "def", "numericalize", "(", "self", ",", "arr", ",", "device", "=", "None", ",", "train", "=", "True", ")", ":", "\n", "\t\t", "\"\"\"Turn a batch of examples that use this field into a Variable.\n\n\t\tIf the field has include_lengths=True, a tensor of lengths will be\n\t\tincluded in the return value.\n\n\t\tArguments:\n\t\t\tarr (List[List[str]], or tuple of (List[List[str]], List[int])):\n\t\t\t\tList of tokenized and padded examples, or tuple of List of\n\t\t\t\ttokenized and padded examples and List of lengths of each\n\t\t\t\texample if self.include_lengths is True.\n\t\t\tdevice (-1 or None): Device to create the Variable's Tensor on.\n\t\t\t\tUse -1 for CPU and None for the currently active GPU device.\n\t\t\t\tDefault: None.\n\t\t\ttrain (boolean): Whether the batch is for a training set.\n\t\t\t\tIf False, the Variable will be created with volatile=True.\n\t\t\t\tDefault: True.\n\t\t\"\"\"", "\n", "if", "self", ".", "include_lengths", "and", "not", "isinstance", "(", "arr", ",", "tuple", ")", ":", "\n", "\t\t\t", "raise", "ValueError", "(", "\"Field has include_lengths set to True, but \"", "\n", "\"input data is not a tuple of \"", "\n", "\"(data batch, batch lengths).\"", ")", "\n", "", "if", "isinstance", "(", "arr", ",", "tuple", ")", ":", "\n", "\t\t\t", "arr", ",", "lengths", "=", "arr", "\n", "lengths", "=", "torch", ".", "LongTensor", "(", "lengths", ")", "\n", "\n", "", "if", "self", ".", "use_vocab", ":", "\n", "\t\t\t", "if", "self", ".", "sequential", ":", "\n", "\t\t\t\t", "arr", "=", "[", "[", "self", ".", "vocab", ".", "stoi", "[", "x", "]", "for", "x", "in", "ex", "]", "for", "ex", "in", "arr", "]", "\n", "", "else", ":", "\n", "\t\t\t\t", "arr", "=", "[", "self", ".", "vocab", ".", "stoi", "[", "x", "]", "for", "x", "in", "arr", "]", "\n", "\n", "", "if", "self", ".", "postprocessing", "is", "not", "None", ":", "\n", "\t\t\t\t", "arr", "=", "self", ".", "postprocessing", "(", "arr", ",", "self", ".", "vocab", ",", "train", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "if", "self", ".", "tensor_type", "not", "in", "self", ".", "tensor_types", ":", "\n", "\t\t\t\t", "raise", "ValueError", "(", "\n", "\"Specified Field tensor_type {} can not be used with \"", "\n", "\"use_vocab=False because we do not know how to numericalize it. \"", "\n", "\"Please raise an issue at \"", "\n", "\"https://github.com/pytorch/text/issues\"", ".", "format", "(", "self", ".", "tensor_type", ")", ")", "\n", "", "numericalization_func", "=", "self", ".", "tensor_types", "[", "self", ".", "tensor_type", "]", "\n", "# It doesn't make sense to explictly coerce to a numeric type if", "\n", "# the data is sequential, since it's unclear how to coerce padding tokens", "\n", "# to a numeric type.", "\n", "if", "not", "self", ".", "sequential", ":", "\n", "\t\t\t\t", "arr", "=", "[", "numericalization_func", "(", "x", ")", "if", "isinstance", "(", "x", ",", "six", ".", "string_types", ")", "\n", "else", "x", "for", "x", "in", "arr", "]", "\n", "", "if", "self", ".", "postprocessing", "is", "not", "None", ":", "\n", "\t\t\t\t", "arr", "=", "self", ".", "postprocessing", "(", "arr", ",", "None", ",", "train", ")", "\n", "\n", "", "", "arr", "=", "self", ".", "tensor_type", "(", "arr", ")", "\n", "if", "self", ".", "sequential", "and", "not", "self", ".", "batch_first", ":", "\n", "\t\t\t", "arr", ".", "t_", "(", ")", "\n", "", "if", "device", "==", "-", "1", ":", "\n", "\t\t\t", "if", "self", ".", "sequential", ":", "\n", "\t\t\t\t", "arr", "=", "arr", ".", "contiguous", "(", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "arr", "=", "arr", ".", "cuda", "(", "device", ")", "\n", "if", "self", ".", "include_lengths", ":", "\n", "\t\t\t\t", "lengths", "=", "lengths", ".", "cuda", "(", "device", ")", "\n", "", "", "if", "self", ".", "include_lengths", ":", "\n", "\t\t\t", "return", "Variable", "(", "arr", ",", "volatile", "=", "not", "train", ")", ",", "lengths", "\n", "", "return", "Variable", "(", "arr", ",", "volatile", "=", "not", "train", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.DistributionalModel.__init__": [[19, 28], ["super().__init__", "torch.nn.Embedding", "bats_analysis.DistributionalModel.arg_vocab.load_vectors", "bats_analysis.DistributionalModel.represent_arguments.weight.data.copy_", "len", "embeddings.vocab.Vectors"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.__init__", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.Vocab.load_vectors"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ",", "dim", ",", "name", "=", "'wikipedia-jan-18-model-300.vec'", ",", "cache", "=", "'/fasttext'", ")", ":", "\n", "        ", "super", "(", "DistributionalModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "arg_vocab", "=", "vocab", "\n", "self", ".", "represent_arguments", "=", "torch", ".", "nn", ".", "Embedding", "(", "len", "(", "vocab", ")", ",", "dim", ")", "\n", "self", ".", "represent_arguments", ".", "weight", ".", "requires_grad", "=", "False", "\n", "self", ".", "arg_vocab", ".", "load_vectors", "(", "Vectors", "(", "name", "=", "name", ",", "cache", "=", "cache", ")", ")", "\n", "pretrained", "=", "self", ".", "arg_vocab", ".", "vectors", "\n", "#pretrained = normalize(pretrained) ", "\n", "self", ".", "represent_arguments", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.DistributionalModel.forward": [[29, 31], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.DistributionalModel.predict_relations": [[33, 35], ["None"], "methods", ["None"], ["", "def", "predict_relations", "(", "self", ",", "subjects", ",", "objects", ")", ":", "\n", "        ", "return", "subjects", "-", "objects", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.read_pairs": [[36, 67], ["print", "open", "enumerate", "right.strip.strip", "line.lower().split", "line.lower().split", "len", "int", "sum", "pairs.append", "idxs.append", "print", "print", "print", "exit", "i.strip", "i.strip", "len", "line.lower", "line.lower", "right.strip.split", "right.strip.split", "int"], "function", ["None"], ["", "", "def", "read_pairs", "(", "fname", ",", "vocab", ")", ":", "\n", "    ", "pairs", ",", "idxs", "=", "[", "]", ",", "[", "]", "\n", "oov", ",", "total", "=", "0", ",", "0", "\n", "with", "open", "(", "fname", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "id_line", "=", "0", "\n", "for", "id_line", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "\"\\t\"", "in", "line", ":", "\n", "                    ", "left", ",", "right", "=", "line", ".", "lower", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "", "else", ":", "\n", "                    ", "left", ",", "right", "=", "line", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "", "right", "=", "right", ".", "strip", "(", ")", "\n", "if", "\"/\"", "in", "right", ":", "\n", "                    ", "right", "=", "[", "i", ".", "strip", "(", ")", "for", "i", "in", "right", ".", "split", "(", "\"/\"", ")", "]", "\n", "", "else", ":", "\n", "                    ", "right", "=", "[", "i", ".", "strip", "(", ")", "for", "i", "in", "right", ".", "split", "(", "\",\"", ")", "]", "\n", "", "left_idx", "=", "vocab", ".", "stoi", "[", "left", "]", "\n", "right", "=", "[", "r", "for", "r", "in", "right", "if", "vocab", ".", "stoi", "[", "r", "]", "!=", "0", "]", "\n", "right_idxs", "=", "[", "vocab", ".", "stoi", "[", "r", "]", "for", "r", "in", "right", "]", "\n", "total", "+=", "1", "+", "len", "(", "right_idxs", ")", "\n", "oov", "+=", "int", "(", "left_idx", "==", "0", ")", "+", "sum", "(", "int", "(", "r", "==", "0", ")", "for", "r", "in", "right_idxs", ")", "\n", "if", "left_idx", "!=", "0", "and", "len", "(", "right_idxs", ")", ">", "0", ":", "\n", "                    ", "pairs", ".", "append", "(", "[", "left", ",", "right", "]", ")", "\n", "idxs", ".", "append", "(", "[", "left_idx", ",", "right_idxs", "]", ")", "\n", "", "", "except", ":", "\n", "                ", "print", "(", "\"error reading pairs\"", ")", "\n", "print", "(", "\"in file\"", ",", "fname", ")", "\n", "print", "(", "\"in line\"", ",", "id_line", ",", "line", ")", "\n", "exit", "(", "-", "1", ")", "\n", "", "", "", "print", "(", "'oov'", ",", "oov", "*", "100.0", "/", "total", ")", "\n", "return", "pairs", ",", "idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.create_dataset": [[70, 76], ["os.walk", "fnmatch.filter", "sorted", "bats_analysis.read_pairs", "os.path.join"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.read_pairs"], ["", "def", "create_dataset", "(", "bats_dir", ")", ":", "\n", "    ", "pairs", "=", "[", "]", "\n", "for", "root", ",", "dirnames", ",", "filenames", "in", "os", ".", "walk", "(", "bats_dir", ")", ":", "\n", "        ", "for", "filename", "in", "fnmatch", ".", "filter", "(", "sorted", "(", "filenames", ")", ",", "'*'", ")", ":", "\n", "            ", "pairs", "+=", "read_pairs", "(", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ")", ")", "\n", "", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.predict_relations": [[78, 85], ["model.represent_arguments", "model.represent_arguments", "model.predict_relations", "torch.nn.functional.normalize"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.predict_relations"], ["", "def", "predict_relations", "(", "pair", ",", "model", ")", ":", "\n", "    ", "word1", ",", "word2", "=", "pair", "\n", "word1_embedding", "=", "model", ".", "represent_arguments", "(", "word1", ")", "\n", "word2_embedding", "=", "model", ".", "represent_arguments", "(", "word2", ")", "\n", "mlp_output", "=", "model", ".", "predict_relations", "(", "word1_embedding", ",", "word2_embedding", ")", "\n", "mlp_output", "=", "normalize", "(", "mlp_output", ",", "dim", "=", "-", "1", ")", "\n", "return", "mlp_output", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.vocab_pair_embeddings": [[87, 100], ["model.represent_arguments", "torch.autograd.Variable", "model.represent_arguments.size", "torch.autograd.Variable.size", "model.represent_arguments.unsqueeze().expand", "torch.autograd.Variable.unsqueeze().expand", "model.predict_relations().contiguous().view", "model.predict_relations().contiguous().view", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "model.represent_arguments.unsqueeze", "torch.autograd.Variable.unsqueeze", "model.predict_relations().contiguous", "model.predict_relations().contiguous", "model.predict_relations", "model.predict_relations", "word1_embedding.unsqueeze().expand.contiguous().view", "vocab_embedding.unsqueeze().expand.contiguous().view", "vocab_embedding.unsqueeze().expand.contiguous().view", "word1_embedding.unsqueeze().expand.contiguous().view", "word1_embedding.unsqueeze().expand.contiguous", "vocab_embedding.unsqueeze().expand.contiguous", "vocab_embedding.unsqueeze().expand.contiguous", "word1_embedding.unsqueeze().expand.contiguous"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.predict_relations", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.predict_relations"], ["", "def", "vocab_pair_embeddings", "(", "model", ",", "word1", ")", ":", "\n", "# (bs, dim)", "\n", "    ", "word1_embedding", "=", "model", ".", "represent_arguments", "(", "word1", ")", "\n", "# (V, dim)", "\n", "vocab_embedding", "=", "Variable", "(", "model", ".", "represent_arguments", ".", "weight", ".", "data", ",", "requires_grad", "=", "False", ")", "\n", "bs", ",", "dim", "=", "word1_embedding", ".", "size", "(", ")", "\n", "vocab_size", ",", "_", "=", "vocab_embedding", ".", "size", "(", ")", "\n", "rep_word1_embedding", "=", "word1_embedding", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "bs", ",", "vocab_size", ",", "dim", ")", "\n", "rep_vocab_embedding", "=", "vocab_embedding", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "bs", ",", "vocab_size", ",", "dim", ")", "\n", "vocab_pair_fwd", "=", "model", ".", "predict_relations", "(", "rep_word1_embedding", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "dim", ")", ",", "rep_vocab_embedding", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "dim", ")", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bs", ",", "vocab_size", ",", "dim", ")", "\n", "vocab_pair_bwd", "=", "model", ".", "predict_relations", "(", "rep_vocab_embedding", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "dim", ")", ",", "rep_word1_embedding", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "dim", ")", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bs", ",", "vocab_size", ",", "dim", ")", "\n", "vocab_pair", "=", "normalize", "(", "vocab_pair_fwd", ",", "dim", "=", "-", "1", ")", ",", "normalize", "(", "vocab_pair_bwd", ",", "dim", "=", "-", "1", ")", "\n", "return", "vocab_pair", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.pairs_to_analogies": [[101, 111], ["random.shuffle", "get", "get", "get", "get", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "tups.append", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.LongTensor", "torch.LongTensor().cuda", "torch.LongTensor", "torch.LongTensor"], "function", ["None"], ["", "def", "pairs_to_analogies", "(", "pairs", ")", ":", "\n", "    ", "tups", "=", "[", "]", "\n", "for", "pair1", "in", "pairs", ":", "\n", "        ", "for", "pair2", "in", "pairs", ":", "\n", "            ", "if", "pair1", "!=", "pair2", ":", "\n", "                ", "tups", ".", "append", "(", "(", "pair1", "[", "0", "]", ",", "pair1", "[", "1", "]", "[", "0", "]", ",", "pair2", "[", "0", "]", ",", "pair2", "[", "1", "]", ")", ")", "\n", "", "", "", "shuffle", "(", "tups", ")", "\n", "get", "=", "lambda", "i", ":", "[", "x", "[", "i", "]", "for", "x", "in", "tups", "]", "\n", "w1", ",", "w2", ",", "w3", ",", "w4", "=", "get", "(", "0", ")", ",", "get", "(", "1", ")", ",", "get", "(", "2", ")", ",", "get", "(", "3", ")", "\n", "return", "Variable", "(", "torch", ".", "LongTensor", "(", "w1", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", ",", "Variable", "(", "torch", ".", "LongTensor", "(", "w2", ")", ".", "cuda", "(", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", ",", "Variable", "(", "torch", ".", "LongTensor", "(", "w3", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", ",", "w4", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.get_accuracy": [[113, 138], ["torch.sort", "indices[].cpu().data.numpy().tolist", "enumerate", "torch.autograd.Variable().float", "w1.data.cpu().numpy().tolist", "w2.data.cpu().numpy().tolist", "w3.data.cpu().numpy().tolist", "zip", "indices[].cpu().data.numpy().tolist", "indices[].cpu().data.numpy().tolist", "sorted_scores[].cpu().data.numpy().tolist", "indices[].cpu().data.numpy().tolist", "indices[].cpu().data.numpy", "indices[].cpu().data.numpy().tolist.index", "torch.autograd.Variable", "w1.data.cpu().numpy", "w2.data.cpu().numpy", "w3.data.cpu().numpy", "indices[].cpu().data.numpy", "indices[].cpu().data.numpy", "sorted_scores[].cpu().data.numpy", "indices[].cpu().data.numpy", "torch.from_numpy().cuda", "org_scores.min", "w1.data.cpu", "w2.data.cpu", "w3.data.cpu", "indices[].cpu", "torch.from_numpy", "indices[].cpu", "indices[].cpu", "sorted_scores[].cpu", "indices[].cpu"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.indexed_field.Field.index"], ["", "def", "get_accuracy", "(", "org_scores", ",", "w4", ",", "vocab", ",", "w1", ",", "w2", ",", "w3", ",", "mask", ",", "batch_num", ",", "preds", ",", "filename", ")", ":", "\n", "    ", "if", "mask", "is", "not", "None", ":", "\n", "        ", "mask", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "mask", ")", ".", "cuda", "(", ")", ",", "requires_grad", "=", "False", ")", ".", "float", "(", ")", "\n", "scores", "=", "(", "org_scores", "-", "(", "org_scores", ".", "min", "(", "-", "1", ",", "keepdim", "=", "True", ")", "[", "0", "]", ")", ")", "*", "mask", "\n", "", "else", ":", "\n", "        ", "scores", "=", "org_scores", "\n", "", "sorted_scores", ",", "indices", "=", "torch", ".", "sort", "(", "scores", ",", "descending", "=", "True", ",", "dim", "=", "-", "1", ")", "\n", "w1", ",", "w2", ",", "w3", "=", "w1", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ",", "w2", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ",", "w3", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "predictions", "=", "indices", "[", ":", ",", "0", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "acc", "=", "0", "\n", "for", "i", ",", "(", "pred", ",", "gold", ")", "in", "enumerate", "(", "zip", "(", "predictions", ",", "w4", ")", ")", ":", "\n", "        ", "ranks", "=", "indices", "[", "i", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "topk", "=", "indices", "[", "i", ",", ":", "10", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "topk_scores", "=", "sorted_scores", "[", "i", ",", ":", "10", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "topk", "=", "[", "vocab", ".", "itos", "[", "w", "]", "for", "w", "in", "topk", "]", "\n", "\n", "gold_ranks", "=", "[", "ranks", ".", "index", "(", "g", ")", "for", "g", "in", "gold", "]", "\n", "preds", "+=", "[", "(", "filename", ",", "vocab", ".", "itos", "[", "w1", "[", "i", "]", "]", ",", "vocab", ".", "itos", "[", "w2", "[", "i", "]", "]", ",", "vocab", ".", "itos", "[", "w3", "[", "i", "]", "]", ",", "'\\t'", ".", "join", "(", "topk", ")", ",", "'\\t'", ".", "join", "(", "[", "vocab", ".", "itos", "[", "g", "]", "for", "g", "in", "gold", "]", ")", ")", "]", "\n", "if", "pred", "in", "gold", ":", "\n", "            ", "acc", "+=", "1", "\n", "# if batch_num < 15:", "\n", "# print(vocab.itos[w1[i]], ':', vocab.itos[w2[i]], '::', vocab.itos[w3[i]], ':', vocab.itos[gold[0]], min(gold_ranks), topk)", "\n", "", "topk", "=", "indices", "[", "i", ",", ":", "10", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.mask_out_analogy_words": [[139, 146], ["numpy.tile", "enumerate", "file_mask.copy", "zip"], "function", ["None"], ["", "def", "mask_out_analogy_words", "(", "file_mask", ",", "w1_batch", ",", "w2_batch", ",", "w3_batch", ",", "model", ")", ":", "\n", "    ", "mask", "=", "np", ".", "tile", "(", "file_mask", ".", "copy", "(", ")", ",", "(", "w1_batch", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "for", "i", ",", "(", "w1", ",", "w2", ",", "w3", ")", "in", "enumerate", "(", "zip", "(", "w1_batch", ",", "w2_batch", ",", "w3_batch", ")", ")", ":", "\n", "        ", "mask", "[", "i", ",", "w1", "]", "=", "0", "\n", "mask", "[", "i", ",", "w2", "]", "=", "0", "\n", "mask", "[", "i", ",", "w3", "]", "=", "0", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.get_scores": [[148, 163], ["model.represent_arguments.weight.data.size", "torch.autograd.Variable().unsqueeze().expand", "torch.nn.functional.normalize", "torch.bmm().squeeze", "bats_analysis.vocab_pair_embeddings", "torch.bmm().squeeze", "torch.bmm().squeeze", "bats_analysis.predict_relations", "bats_analysis.predict_relations", "torch.autograd.Variable().unsqueeze", "model.represent_arguments", "torch.bmm", "torch.bmm", "torch.bmm", "model.represent_arguments", "model.represent_arguments", "torch.nn.functional.normalize.unsqueeze", "p1_fwd.unsqueeze", "p1_bwd.unsqueeze", "torch.autograd.Variable", "torch.nn.functional.normalize"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.vocab_pair_embeddings", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.predict_relations", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.predict_relations"], ["", "def", "get_scores", "(", "model", ",", "w1", ",", "w2", ",", "w3", ",", "batch", ",", "method", "=", "'3CosAdd'", ")", ":", "\n", "    ", "vocab_size", ",", "dim", "=", "model", ".", "represent_arguments", ".", "weight", ".", "data", ".", "size", "(", ")", "\n", "# (bs, V, dim))", "\n", "if", "method", "==", "'3CosAdd'", ":", "\n", "        ", "vocab_emb", "=", "Variable", "(", "normalize", "(", "model", ".", "represent_arguments", ".", "weight", ".", "data", ",", "dim", "=", "-", "1", ")", ",", "requires_grad", "=", "False", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch", ",", "vocab_size", ",", "dim", ")", "\n", "p1_relemb", "=", "normalize", "(", "model", ".", "represent_arguments", "(", "w3", ")", "-", "model", ".", "represent_arguments", "(", "w1", ")", "+", "model", ".", "represent_arguments", "(", "w2", ")", ",", "dim", "=", "-", "1", ")", "\n", "scores", "=", "torch", ".", "bmm", "(", "vocab_emb", ",", "p1_relemb", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "\n", "", "else", ":", "\n", "        ", "vocab_pair", "=", "vocab_pair_embeddings", "(", "model", ",", "w3", ")", "\n", "p1_fwd", ",", "p1_bwd", "=", "predict_relations", "(", "(", "w1", ",", "w2", ")", ",", "model", ")", ",", "predict_relations", "(", "(", "w2", ",", "w1", ")", ",", "model", ")", "\n", "vocab_pair_fwd", ",", "vocab_pair_bwd", "=", "vocab_pair", "\n", "scores_fwd", "=", "(", "torch", ".", "bmm", "(", "vocab_pair_fwd", ",", "p1_fwd", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", ")", "\n", "scores_bwd", "=", "(", "torch", ".", "bmm", "(", "vocab_pair_bwd", ",", "p1_bwd", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", ")", "\n", "scores", "=", "(", "scores_fwd", "+", "scores_bwd", ")", "/", "2", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.eval_on_bats_interpolate": [[164, 223], ["random.seed", "endtasks.util.get_pair2vec", "bats_analysis.DistributionalModel", "endtasks.util.get_pair2vec.cuda", "endtasks.util.get_pair2vec.eval", "DistributionalModel.cuda", "DistributionalModel.eval", "numpy.ones", "os.walk", "print", "collections.defaultdict", "collections.defaultdict", "print", "collections.defaultdict.keys", "len", "fnmatch.filter", "print", "print", "open", "sorted", "bats_analysis.read_pairs", "print", "numpy.linspace", "print", "print", "f.write", "os.path.join", "len", "float", "print", "bats_analysis.pairs_to_analogies", "len", "print", "tqdm.tqdm", "print", "all_alpha_acc.append", "range", "bats_analysis.get_scores", "bats_analysis.get_scores", "bats_analysis.mask_out_analogy_words", "bats_analysis.get_accuracy", "len", "len", "w1.data.cpu().numpy", "w2.data.cpu().numpy", "w3.data.cpu().numpy", "str", "w1.data.cpu", "w2.data.cpu", "w3.data.cpu"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_pair2vec", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.read_pairs", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.pairs_to_analogies", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.get_scores", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.get_scores", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.mask_out_analogy_words", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.get_accuracy"], ["", "def", "eval_on_bats_interpolate", "(", "bats_dir", ",", "model_file", ",", "config_file", ",", "pred_file", ",", "batch", "=", "1", ")", ":", "\n", "    ", "random", ".", "seed", "(", "10", ")", "\n", "pair2vec", "=", "get_pair2vec", "(", "config_file", ",", "model_file", ")", "\n", "vocab", "=", "pair2vec", ".", "arg_vocab", "\n", "distrib_model", "=", "DistributionalModel", "(", "vocab", ",", "300", ")", "\n", "pair2vec", ".", "cuda", "(", ")", "\n", "pair2vec", ".", "eval", "(", ")", "\n", "distrib_model", ".", "cuda", "(", ")", "\n", "distrib_model", ".", "eval", "(", ")", "\n", "\n", "file_mask", "=", "np", ".", "ones", "(", "len", "(", "vocab", ")", ")", "\n", "correct", ",", "total", "=", "0", ",", "0", "\n", "per_cat_acc", ",", "preds", "=", "[", "]", ",", "[", "]", "\n", "all_alpha_acc", "=", "[", "]", "\n", "for", "root", ",", "dirnames", ",", "filenames", "in", "os", ".", "walk", "(", "bats_dir", ")", ":", "\n", "        ", "for", "filename", "in", "fnmatch", ".", "filter", "(", "sorted", "(", "filenames", ")", ",", "'*.txt'", ")", ":", "\n", "            ", "pairs", ",", "idxs", "=", "read_pairs", "(", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ")", ",", "pair2vec", ".", "arg_vocab", ")", "\n", "print", "(", "filename", ",", "len", "(", "idxs", ")", ")", "\n", "best_correct", ",", "best_alpha", "=", "0", ",", "0", "\n", "for", "alpha", "in", "np", ".", "linspace", "(", "0", ",", "1", ",", "11", ")", ":", "\n", "                ", "alpha", "=", "float", "(", "alpha", ")", "\n", "print", "(", "'alpha'", ",", "alpha", ")", "\n", "file_correct", ",", "file_total", "=", "0", ",", "0", "\n", "all_w1", ",", "all_w2", ",", "all_w3", ",", "all_w4", "=", "pairs_to_analogies", "(", "idxs", ")", "\n", "\n", "bs", "=", "len", "(", "all_w1", ")", "\n", "print", "(", "bs", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "all_w1", ")", ",", "batch", ")", ")", ":", "\n", "                    ", "w1", ",", "w2", ",", "w3", ",", "w4", "=", "all_w1", "[", "i", ":", "i", "+", "batch", "]", ",", "all_w2", "[", "i", ":", "i", "+", "batch", "]", ",", "all_w3", "[", "i", ":", "i", "+", "batch", "]", ",", "all_w4", "[", "i", ":", "i", "+", "batch", "]", "\n", "distrib_scores", "=", "get_scores", "(", "distrib_model", ",", "w1", ",", "w2", ",", "w3", ",", "batch", ",", "method", "=", "'3CosAdd'", ")", "\n", "scores", "=", "get_scores", "(", "pair2vec", ",", "w1", ",", "w2", ",", "w3", ",", "batch", ",", "method", "=", "'pair2vec'", ")", "\n", "scores", "=", "alpha", "*", "distrib_scores", "+", "(", "1", "-", "alpha", ")", "*", "scores", "\n", "mask", "=", "mask_out_analogy_words", "(", "file_mask", ",", "w1", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "w2", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "w3", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "None", ")", "\n", "file_correct", "+=", "get_accuracy", "(", "scores", ",", "w4", ",", "pair2vec", ".", "arg_vocab", ",", "w1", ",", "w2", ",", "w3", ",", "mask", ",", "i", ",", "preds", ",", "filename", ")", "\n", "file_total", "+=", "len", "(", "w4", ")", "\n", "", "print", "(", "filename", ",", "file_correct", "*", "100.0", "/", "file_total", ",", "file_correct", ",", "file_total", ",", "alpha", ")", "\n", "all_alpha_acc", ".", "append", "(", "(", "filename", ",", "file_correct", ",", "file_total", ",", "file_correct", "*", "100.0", "/", "file_total", ",", "alpha", ")", ")", "\n", "if", "file_correct", ">", "best_correct", ":", "\n", "                    ", "best_correct", ",", "best_alpha", "=", "file_correct", ",", "alpha", "\n", "", "", "file_correct", "=", "best_correct", "\n", "correct", "+=", "file_correct", "\n", "total", "+=", "file_total", "\n", "print", "(", "filename", ",", "file_correct", "*", "100.0", "/", "file_total", ",", "file_correct", ",", "file_total", ",", "best_alpha", ")", "\n", "print", "(", "'cumulative'", ",", "correct", "*", "100.0", "/", "total", ")", "\n", "per_cat_acc", "+=", "[", "(", "filename", ",", "file_correct", ",", "file_total", ",", "best_alpha", ")", "]", "\n", "", "", "print", "(", "'Summary'", ")", "\n", "group_correct", "=", "defaultdict", "(", "int", ")", "\n", "group_total", "=", "defaultdict", "(", "int", ")", "\n", "for", "cat", ",", "cat_correct", ",", "cat_total", ",", "best_alpha", "in", "per_cat_acc", ":", "\n", "        ", "group_correct", "[", "cat", "[", "0", "]", "]", "+=", "cat_correct", "\n", "group_total", "[", "cat", "[", "0", "]", "]", "+=", "cat_total", "\n", "print", "(", "cat", ",", "cat_correct", "*", "100.0", "/", "cat_total", ",", "best_alpha", ")", "\n", "", "print", "(", "'Final'", ",", "correct", "*", "100", "/", "total", ")", "\n", "for", "group", "in", "group_correct", ".", "keys", "(", ")", ":", "\n", "        ", "acc", "=", "group_correct", "[", "group", "]", "*", "100.0", "/", "group_total", "[", "group", "]", "\n", "print", "(", "group", ",", "acc", ")", "\n", "", "with", "open", "(", "pred_file", ",", "encoding", "=", "'utf-8'", ",", "mode", "=", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "info", "in", "all_alpha_acc", ":", "\n", "            ", "f", ".", "write", "(", "'\\t'", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "info", "]", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.read_filtered_pairs": [[13, 28], ["float", "pairs_count.items", "open", "tqdm.tqdm", "sum", "line.strip().split", "pairs_count.values", "float", "line.strip", "float"], "function", ["None"], ["def", "read_filtered_pairs", "(", "fname", ",", "vocab", ",", "thr", "=", "None", ",", "sorted_file", "=", "False", ")", ":", "\n", "    ", "pairs_count", "=", "{", "}", "\n", "count", "=", "1", "\n", "with", "open", "(", "fname", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "tqdm", "(", "f", ")", ":", "\n", "            ", "w1", ",", "w2", ",", "count", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "thr", "is", "None", "or", "float", "(", "count", ")", ">", "thr", ":", "\n", "                ", "this_pair", "=", "(", "vocab", ".", "stoi", "[", "w1", "]", ",", "vocab", ".", "stoi", "[", "w2", "]", ")", "if", "vocab", ".", "stoi", "[", "w1", "]", "<", "vocab", ".", "stoi", "[", "w2", "]", "else", "(", "vocab", ".", "stoi", "[", "w2", "]", ",", "vocab", ".", "stoi", "[", "w1", "]", ")", "\n", "pairs_count", "[", "this_pair", "]", "=", "float", "(", "count", ")", "\n", "", "elif", "sorted_file", ":", "\n", "                ", "break", "\n", "", "", "", "total", "=", "float", "(", "sum", "(", "pairs_count", ".", "values", "(", ")", ")", ")", "\n", "for", "k", ",", "count", "in", "pairs_count", ".", "items", "(", ")", ":", "\n", "        ", "pairs_count", "[", "k", "]", "/=", "total", "\n", "", "return", "pairs_count", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.read_counts": [[30, 42], ["collections.defaultdict", "float", "collections.defaultdict.items", "open", "tqdm.tqdm", "sum", "line.strip().split", "collections.defaultdict.values", "float", "line.strip", "int"], "function", ["None"], ["", "def", "read_counts", "(", "fname", ",", "vocab", ",", "thr", "=", "10", ")", ":", "\n", "    ", "count_dict", "=", "defaultdict", "(", "int", ")", "\n", "with", "open", "(", "fname", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "tqdm", "(", "f", ")", ":", "\n", "            ", "w1", ",", "count", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "if", "int", "(", "count", ")", ">", "thr", "and", "w1", "in", "vocab", ".", "stoi", ":", "\n", "                ", "count_dict", "[", "vocab", ".", "stoi", "[", "w1", "]", "]", "=", "float", "(", "count", ")", "\n", "", "", "", "total", "=", "float", "(", "sum", "(", "count_dict", ".", "values", "(", ")", ")", ")", "\n", "for", "k", ",", "count", "in", "count_dict", ".", "items", "(", ")", ":", "\n", "        ", "count_dict", "[", "k", "]", "/=", "total", "\n", "# print('total {}, min {}'.format(total, thr / total))", "\n", "", "return", "count_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.main": [[44, 107], ["docopt.docopt", "print", "os.path.join", "int", "int", "int", "int", "int", "int", "print", "preprocess.get_vocab", "print", "preprocess.read_filtered_pairs", "set", "preprocess.read_counts", "len", "open", "tqdm.tqdm", "len", "preprocess.save", "enumerate", "line.strip().lower().split", "len", "enumerate", "len", "preprocess.save", "print", "line.strip().lower", "range", "keep_wordpair", "len", "line.strip", "len", "max"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.get_vocab", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.read_filtered_pairs", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.read_counts", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.save", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.save"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "docopt", "(", "\"\"\"\n    Usage:\n        preprocess.py [options] <corpus> <triplets_dir> <word_count_file> <pair_count_file>\n\n    Options:\n        --chunk NUM         The number of lines to read before dumping each matrix [default: 1000000]\n        --win NUM           Maximal number of tokens between X and Y [default: 4]\n        --left NUM          Left window size [default: 1]\n        --right NUM         Right window size [default: 1]\n        --word_thr NUM      Right window size [default: 10]\n        --pair_thr NUM      Right window size [default: 50]\n    \"\"\"", ")", "\n", "print", "(", "args", ")", "\n", "corpus_file", "=", "args", "[", "'<corpus>'", "]", "\n", "triplets_dir", "=", "args", "[", "'<triplets_dir>'", "]", "\n", "word_count_file", "=", "args", "[", "'<word_count_file>'", "]", "\n", "pair_count_file", "=", "args", "[", "'<pair_count_file>'", "]", "\n", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "triplets_dir", ",", "'vocab.txt'", ")", "\n", "word_thr", "=", "int", "(", "args", "[", "'--word_thr'", "]", ")", "\n", "pair_thr", "=", "int", "(", "args", "[", "'--pair_thr'", "]", ")", "\n", "chunk", "=", "int", "(", "args", "[", "'--chunk'", "]", ")", "\n", "win", "=", "int", "(", "args", "[", "'--win'", "]", ")", "\n", "left", "=", "int", "(", "args", "[", "'--left'", "]", ")", "\n", "right", "=", "int", "(", "args", "[", "'--right'", "]", ")", "\n", "unk", ",", "pad", ",", "x_placeholder", ",", "y_placeholder", "=", "'<unk>'", ",", "'<pad>'", ",", "'<X>'", ",", "'<Y>'", "\n", "print", "(", "'reading vocab from {}'", ".", "format", "(", "vocab_file", ")", ")", "\n", "specials", "=", "[", "unk", ",", "pad", ",", "x_placeholder", ",", "y_placeholder", "]", "\n", "vocab", "=", "get_vocab", "(", "vocab_file", ",", "corpus_file", ",", "specials", ")", "\n", "print", "(", "'Vocab Size:'", ",", "len", "(", "vocab", ")", ")", "\n", "chunk_i", "=", "1", "\n", "matrix", "=", "[", "]", "\n", "pair_filter", "=", "read_filtered_pairs", "(", "pair_count_file", ",", "vocab", ",", "pair_thr", ",", "sorted_file", "=", "True", ")", "\n", "stop_word_ids", "=", "set", "(", "[", "vocab", ".", "stoi", "[", "w", "]", "for", "w", "in", "stop_words", "]", ")", "\n", "keep_wordpair", "=", "keep_wordpair_by_mult", "\n", "word_unigram_dict", "=", "read_counts", "(", "word_count_file", ",", "vocab", ",", "word_thr", ")", "\n", "\n", "with", "open", "(", "corpus_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "i_line", ",", "line", "in", "tqdm", "(", "enumerate", "(", "f", ")", ")", ":", "\n", "            ", "tokens", "=", "line", ".", "strip", "(", ")", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "token_ids", "=", "[", "vocab", ".", "stoi", "[", "t", "]", "for", "t", "in", "tokens", "if", "vocab", ".", "stoi", "[", "t", "]", "!=", "0", "]", "\n", "len_tokens", "=", "len", "(", "token_ids", ")", "\n", "for", "ix", ",", "x", "in", "enumerate", "(", "token_ids", ")", ":", "\n", "# use ix+1 to start from adjacent word", "\n", "                ", "y_start", "=", "(", "ix", "+", "1", ")", "\n", "y_iter", "=", "[", "iy", "for", "iy", "in", "range", "(", "y_start", ",", "ix", "+", "2", "+", "win", ")", "if", "iy", "<", "len_tokens", "and", "token_ids", "[", "iy", "]", "!=", "0", "]", "\n", "for", "iy", "in", "y_iter", ":", "\n", "                    ", "ordered_pair", "=", "(", "token_ids", "[", "ix", "]", ",", "token_ids", "[", "iy", "]", ")", "\n", "this_pair", "=", "(", "token_ids", "[", "ix", "]", ",", "token_ids", "[", "iy", "]", ")", "if", "(", "token_ids", "[", "ix", "]", "<", "token_ids", "[", "iy", "]", ")", "else", "(", "token_ids", "[", "iy", "]", ",", "token_ids", "[", "ix", "]", ")", "\n", "\n", "if", "this_pair", "in", "pair_filter", "and", "keep_wordpair", "(", "word_unigram_dict", ",", "this_pair", ",", "vocab", ",", "stop_words", "=", "stop_word_ids", ")", ":", "\n", "                        ", "contexts", "=", "token_ids", "[", "max", "(", "0", ",", "ix", "-", "left", ")", ":", "ix", "]", "+", "[", "vocab", ".", "stoi", "[", "x_placeholder", "]", "]", "+", "token_ids", "[", "ix", "+", "1", ":", "iy", "]", "+", "[", "vocab", ".", "stoi", "[", "y_placeholder", "]", "]", "+", "token_ids", "[", "iy", "+", "1", ":", "iy", "+", "right", "+", "1", "]", "\n", "contexts", "+=", "[", "vocab", ".", "stoi", "[", "pad", "]", "]", "*", "(", "left", "+", "right", "+", "win", "+", "2", "-", "len", "(", "contexts", ")", ")", "\n", "matrix", "+=", "[", "[", "token_ids", "[", "ix", "]", ",", "token_ids", "[", "iy", "]", "]", "+", "contexts", "]", "\n", "\n", "", "", "", "if", "(", "i_line", "+", "1", ")", "%", "chunk", "==", "0", ":", "\n", "                ", "size", "=", "len", "(", "matrix", ")", "\n", "save", "(", "matrix", ",", "triplets_dir", ",", "chunk_i", ")", "\n", "print", "(", "'chunk {} len {}'", ".", "format", "(", "chunk_i", ",", "len", "(", "matrix", ")", ")", ")", "\n", "matrix", "=", "[", "]", "\n", "chunk_i", "+=", "1", "\n", "", "", "", "if", "len", "(", "matrix", ")", ">", "0", ":", "\n", "        ", "save", "(", "matrix", ",", "triplets_dir", ",", "chunk_i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.keep_wordpair_by_mult": [[109, 116], ["numpy.random.uniform", "clamp", "clamp", "math.sqrt", "math.sqrt"], "function", ["None"], ["", "", "def", "keep_wordpair_by_mult", "(", "count_dict", ",", "word_pair", ",", "vocab", ",", "thr", "=", "5e-5", ",", "stop_words", "=", "None", ")", ":", "\n", "    ", "x", ",", "y", "=", "word_pair", "\n", "clamp", "=", "lambda", "x", ":", "x", "if", "x", "<", "1.0", "else", "1.0", "\n", "keep_x", "=", "clamp", "(", "sqrt", "(", "thr", "/", "count_dict", "[", "x", "]", ")", ")", "if", "x", "in", "count_dict", "else", "0.0", "\n", "keep_y", "=", "clamp", "(", "sqrt", "(", "thr", "/", "count_dict", "[", "y", "]", ")", ")", "if", "y", "in", "count_dict", "else", "0.0", "\n", "random_prob", "=", "np", ".", "random", ".", "uniform", "(", ")", "\n", "return", "random_prob", "<", "keep_x", "*", "keep_y", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.get_vocab": [[117, 125], ["os.path.isfile", "preprocess.read_vocab_from_file", "preprocess.read_vocab", "embeddings.vocab.Vocab", "preprocess.save_vocab"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.cooccurance.read_vocab_from_file", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.read_vocab", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.save_vocab"], ["", "def", "get_vocab", "(", "vocab_path", ",", "corpus_file", ",", "specials", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isfile", "(", "vocab_path", ")", ":", "\n", "        ", "vocab", "=", "read_vocab_from_file", "(", "vocab_path", ",", "specials", ")", "\n", "", "else", ":", "\n", "        ", "selected", "=", "read_vocab", "(", "corpus_file", ")", "\n", "vocab", "=", "Vocab", "(", "selected", ",", "specials", ")", "\n", "save_vocab", "(", "selected", ",", "vocab_path", ")", "\n", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.read_vocab_from_file": [[126, 133], ["embeddings.vocab.Vocab", "open", "f.read", "f.read.rstrip().split", "f.read.rstrip"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.read"], ["", "def", "read_vocab_from_file", "(", "vocab_path", ",", "specials", ")", ":", "\n", "    ", "tokens", "=", "None", "\n", "with", "open", "(", "vocab_path", ")", "as", "f", ":", "\n", "        ", "text", "=", "f", ".", "read", "(", ")", "\n", "tokens", "=", "text", ".", "rstrip", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "", "vocab", "=", "Vocab", "(", "tokens", ",", "specials", "=", "specials", ")", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.read_vocab": [[134, 149], ["collections.Counter", "sorted", "sorted.sort", "open", "enumerate", "collections.Counter.items", "selected.append", "collections.Counter.update", "collections.Counter", "print", "len", "line.strip().lower().split", "line.strip().lower", "line.strip"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.update"], ["", "def", "read_vocab", "(", "corpus_file", ",", "thr", "=", "100", ",", "max_size", "=", "150000", ")", ":", "\n", "    ", "counter", "=", "Counter", "(", ")", "\n", "with", "open", "(", "corpus_file", ",", "mode", "=", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "i_line", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "            ", "counter", ".", "update", "(", "Counter", "(", "line", ".", "strip", "(", ")", ".", "lower", "(", ")", ".", "split", "(", ")", ")", ")", "\n", "if", "i_line", "%", "1000000", "==", "0", ":", "\n", "                ", "print", "(", "i_line", ")", "\n", "", "", "", "words_and_frequencies", "=", "sorted", "(", "counter", ".", "items", "(", ")", ",", "key", "=", "lambda", "tup", ":", "tup", "[", "0", "]", ")", "\n", "words_and_frequencies", ".", "sort", "(", "key", "=", "lambda", "tup", ":", "tup", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "selected", "=", "[", "]", "\n", "for", "word", ",", "freq", "in", "words_and_frequencies", ":", "\n", "        ", "if", "freq", "<", "thr", "or", "len", "(", "selected", ")", "==", "max_size", ":", "\n", "            ", "break", "\n", "", "selected", ".", "append", "(", "word", ")", "\n", "", "return", "selected", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.save_vocab": [[150, 153], ["open", "fout.write"], "function", ["None"], ["", "def", "save_vocab", "(", "selected", ",", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "fout", ":", "\n", "        ", "fout", ".", "write", "(", "'\\n'", ".", "join", "(", "selected", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.save": [[155, 157], ["numpy.save", "numpy.array", "tuple", "str"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.save"], ["", "", "def", "save", "(", "matrix", ",", "triplets_dir", ",", "chunk_i", ")", ":", "\n", "    ", "np", ".", "save", "(", "triplets_dir", "+", "'/triplets_'", "+", "str", "(", "chunk_i", ")", "+", "'.npy'", ",", "np", ".", "array", "(", "tuple", "(", "matrix", ")", ",", "dtype", "=", "np", ".", "int32", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.representation.SpanRepresentation.__init__": [[11, 25], ["torch.nn.Module.__init__", "len", "torch.nn.Embedding", "getattr", "torch.nn.Dropout", "torch.nn.Sequential", "torch.nn.Sequential", "representation.SpanRepresentation.init", "representation.LSTMContextualizer", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.__init__", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.init"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "d_output", ",", "vocab", ")", ":", "\n", "        ", "super", "(", "SpanRepresentation", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "vocab", "=", "vocab", "\n", "n_input", "=", "len", "(", "vocab", ")", "\n", "self", ".", "embedding", "=", "Embedding", "(", "n_input", ",", "config", ".", "d_embed", ")", "\n", "self", ".", "normalize_pretrained", "=", "getattr", "(", "config", ",", "'normalize_pretrained'", ",", "False", ")", "\n", "\n", "\n", "self", ".", "contextualizer", "=", "LSTMContextualizer", "(", "config", ")", "if", "config", ".", "n_lstm_layers", ">", "0", "else", "lambda", "x", ":", "x", "\n", "self", ".", "dropout", "=", "Dropout", "(", "p", "=", "config", ".", "dropout", ")", "\n", "self", ".", "head_attention", "=", "Sequential", "(", "self", ".", "dropout", ",", "Linear", "(", "2", "*", "config", ".", "d_lstm_hidden", ",", "1", ")", ")", "\n", "self", ".", "head_transform", "=", "Sequential", "(", "self", ".", "dropout", ",", "Linear", "(", "2", "*", "config", ".", "d_lstm_hidden", ",", "d_output", ")", ")", "\n", "self", ".", "init", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.representation.SpanRepresentation.init": [[26, 35], ["torch.nn.init.xavier_normal", "representation.SpanRepresentation.embedding.weight.data.copy_", "print", "representation.SpanRepresentation.embedding.reset_parameters", "representation.SpanRepresentation.parameters", "normalize", "len", "p.size"], "methods", ["None"], ["", "def", "init", "(", "self", ")", ":", "\n", "        ", "[", "xavier_normal", "(", "p", ")", "for", "p", "in", "self", ".", "parameters", "(", ")", "if", "len", "(", "p", ".", "size", "(", ")", ")", ">", "1", "]", "\n", "if", "self", ".", "vocab", ".", "vectors", "is", "not", "None", ":", "\n", "            ", "pretrained", "=", "normalize", "(", "self", ".", "vocab", ".", "vectors", ",", "dim", "=", "-", "1", ")", "if", "self", ".", "normalize_pretrained", "else", "self", ".", "vocab", ".", "vectors", "\n", "self", ".", "embedding", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", ")", "\n", "print", "(", "'Copied pretrained vectors into relation span representation'", ")", "\n", "", "else", ":", "\n", "#xavier_normal(self.embedding.weight.data)", "\n", "            ", "self", ".", "embedding", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.representation.SpanRepresentation.forward": [[36, 43], ["representation.SpanRepresentation.dropout", "representation.SpanRepresentation.contextualizer", "embeddings.util.masked_softmax", "representation.SpanRepresentation.embedding", "representation.SpanRepresentation.head_attention().squeeze", "mask.float", "representation.SpanRepresentation.head_attention", "embeddings.util.masked_softmax.unsqueeze", "representation.SpanRepresentation.head_transform"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.masked_softmax"], ["", "", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "text", ",", "mask", "=", "inputs", "\n", "text", "=", "self", ".", "dropout", "(", "self", ".", "embedding", "(", "text", ")", ")", "\n", "text", "=", "self", ".", "contextualizer", "(", "text", ")", "\n", "weights", "=", "masked_softmax", "(", "self", ".", "head_attention", "(", "text", ")", ".", "squeeze", "(", "-", "1", ")", ",", "mask", ".", "float", "(", ")", ")", "\n", "representation", "=", "(", "weights", ".", "unsqueeze", "(", "2", ")", "*", "self", ".", "head_transform", "(", "text", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "return", "representation", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.representation.LSTMContextualizer.__init__": [[46, 51], ["torch.nn.Module.__init__", "getattr", "torch.nn.LSTM"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "LSTMContextualizer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "bidirectional", "=", "getattr", "(", "config", ",", "'bidirectional'", ",", "True", ")", "\n", "self", ".", "rnn", "=", "LSTM", "(", "input_size", "=", "config", ".", "d_lstm_input", ",", "hidden_size", "=", "config", ".", "d_lstm_hidden", ",", "num_layers", "=", "config", ".", "n_lstm_layers", ",", "dropout", "=", "config", ".", "dropout", ",", "bidirectional", "=", "bidirectional", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.representation.LSTMContextualizer.forward": [[52, 56], ["inputs.permute.permute.permute", "representation.LSTMContextualizer.rnn", "outputs.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "inputs", "=", "inputs", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "outputs", ",", "_", "=", "self", ".", "rnn", "(", "inputs", ")", "# outputs: [seq_len, batch, hidden * 2]", "\n", "return", "outputs", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.__init__": [[21, 64], ["torch.nn.Module.__init__", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "torch.nn.Embedding", "model.Pair2Vec.init", "hasattr", "get_type_file().cuda", "hasattr", "get_type_file().cuda", "model.Pair2Vec.represent_arguments", "torch.nn.Embedding", "embeddings.representation.SpanRepresentation", "NotImplementedError", "NotImplementedError", "getattr", "getattr", "getattr", "getattr", "model.Pair2Vec.represent_arguments", "model.MLP", "Exception", "model.get_type_file", "model.get_type_file", "torch.nn.functional.cosine_similarity", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.__init__", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.init", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.get_type_file", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.get_type_file"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "arg_vocab", ",", "rel_vocab", ")", ":", "\n", "        ", "super", "(", "Pair2Vec", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "arg_vocab", "=", "arg_vocab", "\n", "self", ".", "rel_vocab", "=", "rel_vocab", "\n", "self", ".", "compositional_rels", "=", "config", ".", "compositional_rels", "\n", "self", ".", "normalize_pretrained", "=", "getattr", "(", "config", ",", "'normalize_pretrained'", ",", "False", ")", "\n", "self", ".", "separate_mlr", "=", "getattr", "(", "config", ",", "'separate_mlr'", ",", "False", ")", "\n", "self", ".", "positional_rels", "=", "getattr", "(", "config", ",", "'positional_rels'", ",", "False", ")", "\n", "self", ".", "type_scores", "=", "get_type_file", "(", "config", ".", "type_scores_file", ",", "arg_vocab", ")", ".", "cuda", "(", ")", "if", "hasattr", "(", "config", ",", "'type_scores_file'", ")", "else", "None", "\n", "self", ".", "type_indices", "=", "get_type_file", "(", "config", ".", "type_indices_file", ",", "arg_vocab", ",", "indxs", "=", "True", ")", ".", "cuda", "(", ")", "if", "hasattr", "(", "config", ",", "'type_indices_file'", ")", "else", "None", "\n", "self", ".", "pad", "=", "arg_vocab", ".", "stoi", "[", "'<pad>'", "]", "\n", "score_fn_str", "=", "getattr", "(", "config", ",", "'score_function'", ",", "'dot_product'", ")", "\n", "if", "score_fn_str", "==", "'dot_product'", ":", "\n", "            ", "self", ".", "score", "=", "(", "lambda", "predicted", ",", "observed", ":", "(", "predicted", "*", "observed", ")", ".", "sum", "(", "-", "1", ")", ")", "\n", "", "elif", "score_fn_str", "==", "'cosine'", ":", "\n", "            ", "self", ".", "score", "=", "(", "lambda", "predicted", ",", "observed", ":", "cosine_similarity", "(", "predicted", ",", "observed", ",", "dim", "=", "1", ",", "eps", "=", "1e-8", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "", "self", ".", "num_neg_samples", "=", "getattr", "(", "config", ",", "'num_neg_samples'", ",", "1", ")", "\n", "self", ".", "num_sampled_relations", "=", "getattr", "(", "config", ",", "'num_sampled_relations'", ",", "1", ")", "\n", "self", ".", "subword_vocab_file", "=", "getattr", "(", "config", ",", "'subword_vocab_file'", ",", "None", ")", "\n", "self", ".", "loss_weights", "=", "[", "(", "'positive_loss'", ",", "getattr", "(", "config", ",", "'positive_loss'", ",", "1.0", ")", ")", ",", "\n", "(", "'negative_rel_loss'", ",", "getattr", "(", "config", ",", "'negative_rel_loss'", ",", "1.0", ")", ")", ",", "\n", "(", "'negative_subject_loss'", ",", "getattr", "(", "config", ",", "'negative_subject_loss'", ",", "1.0", ")", ")", ",", "\n", "(", "'negative_object_loss'", ",", "getattr", "(", "config", ",", "'negative_object_loss'", ",", "1.0", ")", ")", "]", "\n", "if", "self", ".", "type_scores", "is", "not", "None", ":", "\n", "            ", "self", ".", "loss_weights", "+=", "[", "(", "'type_subject_loss'", ",", "getattr", "(", "config", ",", "'type_subject_loss'", ",", "0.3", ")", ")", ",", "(", "'type_object_loss'", ",", "getattr", "(", "config", ",", "'type_object_loss'", ",", "0.3", ")", ")", "]", "\n", "", "self", ".", "shared_arg_embeddings", "=", "getattr", "(", "config", ",", "'shared_arg_embeddings'", ",", "True", ")", "\n", "self", ".", "represent_arguments", "=", "Embedding", "(", "config", ".", "n_args", ",", "config", ".", "d_embed", ")", "\n", "self", ".", "represent_left_argument", "=", "lambda", "x", ":", "self", ".", "represent_arguments", "(", "x", ")", "\n", "self", ".", "represent_right_argument", "=", "(", "lambda", "x", ":", "self", ".", "represent_arguments", "(", "x", ")", ")", "if", "self", ".", "shared_arg_embeddings", "else", "Embedding", "(", "config", ".", "n_args", ",", "config", ".", "d_embed", ")", "\n", "if", "config", ".", "compositional_rels", ":", "\n", "            ", "self", ".", "represent_relations", "=", "SpanRepresentation", "(", "config", ",", "config", ".", "d_rels", ",", "rel_vocab", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "", "if", "config", ".", "relation_predictor", "==", "'multiplication'", ":", "\n", "            ", "self", ".", "predict_relations", "=", "lambda", "x", ",", "y", ":", "x", "*", "y", "\n", "", "elif", "config", ".", "relation_predictor", "==", "'mlp'", ":", "\n", "            ", "self", ".", "predict_relations", "=", "MLP", "(", "config", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unknown relation predictor: '", "+", "config", ".", "relation_predictor", ")", "\n", "", "self", ".", "init", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.to_tensors": [[65, 67], ["len", "torch.eq().float", "field.size", "torch.eq"], "methods", ["None"], ["", "def", "to_tensors", "(", "self", ",", "fields", ")", ":", "\n", "        ", "return", "(", "(", "field", ",", "1.0", "-", "torch", ".", "eq", "(", "field", ",", "self", ".", "pad", ")", ".", "float", "(", ")", ")", "if", "(", "len", "(", "field", ".", "size", "(", ")", ")", ">", "1", "and", "(", "self", ".", "compositional_rels", ")", ")", "else", "field", "for", "field", "in", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.init": [[68, 77], ["isinstance", "arg_matrix.weight.data[].copy_", "print", "arg_matrix.reset_parameters", "torch.nn.functional.normalize", "pretrained.size"], "methods", ["None"], ["", "def", "init", "(", "self", ")", ":", "\n", "        ", "for", "arg_matrix", "in", "[", "self", ".", "represent_arguments", ",", "self", ".", "represent_right_argument", "]", ":", "\n", "            ", "if", "isinstance", "(", "arg_matrix", ",", "Embedding", ")", ":", "\n", "                ", "if", "self", ".", "arg_vocab", ".", "vectors", "is", "not", "None", ":", "\n", "                    ", "pretrained", "=", "normalize", "(", "self", ".", "arg_vocab", ".", "vectors", ",", "dim", "=", "-", "1", ")", "if", "self", ".", "normalize_pretrained", "else", "self", ".", "arg_vocab", ".", "vectors", "\n", "arg_matrix", ".", "weight", ".", "data", "[", ":", ",", ":", "pretrained", ".", "size", "(", "1", ")", "]", ".", "copy_", "(", "pretrained", ")", "\n", "print", "(", "'Copied pretrained vecs for argument matrix'", ")", "\n", "", "else", ":", "\n", "                    ", "arg_matrix", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.forward": [[78, 125], ["model.Pair2Vec.view().squeeze", "model.Pair2Vec.to_tensors", "model.Pair2Vec.represent_left_argument", "model.Pair2Vec.represent_right_argument", "model.Pair2Vec.predict_relations", "model.Pair2Vec.to_tensors", "model.Pair2Vec.represent_relations", "model.Pair2Vec.represent_relations", "model.Pair2Vec.repeat", "model.Pair2Vec.repeat", "torch.nn.functional.sigmoid", "torch.nn.functional.sigmoid", "len", "model.Pair2Vec.score", "model.Pair2Vec.score", "torch.nn.functional.logsigmoid().sum", "torch.nn.functional.logsigmoid().sum", "model.Pair2Vec.predict_relations", "model.Pair2Vec.predict_relations", "model.Pair2Vec.repeat", "model.Pair2Vec.predict_relations", "model.Pair2Vec.predict_relations", "model.Pair2Vec.view", "sampled_subjects.view().squeeze", "sampled_objects.view().squeeze", "model.Pair2Vec.represent_left_argument", "model.Pair2Vec.represent_right_argument", "model.Pair2Vec.repeat", "model.Pair2Vec.repeat", "torch.nn.functional.logsigmoid().sum", "torch.nn.functional.logsigmoid().sum", "model.Pair2Vec.get_type_sampled_arguments", "model.Pair2Vec.get_type_sampled_arguments", "model.Pair2Vec.represent_left_argument", "model.Pair2Vec.represent_right_argument", "torch.nn.functional.logsigmoid().sum", "torch.nn.functional.logsigmoid().sum", "model.Pair2Vec.size", "torch.nn.functional.logsigmoid", "torch.nn.functional.logsigmoid", "sampled_subjects.view", "sampled_objects.view", "torch.nn.functional.logsigmoid", "torch.nn.functional.logsigmoid", "torch.nn.functional.logsigmoid", "torch.nn.functional.logsigmoid", "model.Pair2Vec.score", "model.Pair2Vec.score", "model.Pair2Vec.score", "model.Pair2Vec.score"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.to_tensors", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.predict_relations", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.to_tensors", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.score", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.score", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.predict_relations", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.predict_relations", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.predict_relations", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.predict_relations", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.get_type_sampled_arguments", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.get_type_sampled_arguments", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.score", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.score", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.score", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.score"], ["", "", "", "", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "if", "len", "(", "batch", ")", "==", "4", ":", "\n", "            ", "batch", "=", "batch", "+", "(", "None", ",", "None", ")", "\n", "", "subjects", ",", "objects", ",", "observed_relations", ",", "sampled_relations", ",", "sampled_subjects", ",", "sampled_objects", "=", "batch", "\n", "sampled_relations", "=", "sampled_relations", ".", "view", "(", "-", "1", ",", "observed_relations", ".", "size", "(", "1", ")", ",", "1", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "subjects", ",", "objects", "=", "self", ".", "to_tensors", "(", "(", "subjects", ",", "objects", ")", ")", "\n", "embedded_subjects", "=", "self", ".", "represent_left_argument", "(", "subjects", ")", "\n", "embedded_objects", "=", "self", ".", "represent_right_argument", "(", "objects", ")", "\n", "predicted_relations", "=", "self", ".", "predict_relations", "(", "embedded_subjects", ",", "embedded_objects", ")", "\n", "\n", "observed_relations", ",", "sampled_relations", "=", "self", ".", "to_tensors", "(", "(", "observed_relations", ",", "sampled_relations", ")", ")", "\n", "observed_relations", "=", "self", ".", "represent_relations", "(", "observed_relations", ")", "\n", "sampled_relations", "=", "self", ".", "represent_relations", "(", "sampled_relations", ")", "\n", "# score = lambda predicted, observed :  (predicted * observed).sum(-1)", "\n", "rep_observed_relations", "=", "observed_relations", ".", "repeat", "(", "self", ".", "num_sampled_relations", ",", "1", ")", "\n", "rep_predicted_relations", "=", "predicted_relations", ".", "repeat", "(", "self", ".", "num_sampled_relations", ",", "1", ")", "\n", "pos_rel_scores", ",", "neg_rel_scores", "=", "self", ".", "score", "(", "predicted_relations", ",", "observed_relations", ")", ",", "self", ".", "score", "(", "rep_predicted_relations", ",", "sampled_relations", ")", "\n", "\n", "output_dict", "=", "{", "}", "\n", "output_dict", "[", "'positive_loss'", "]", "=", "-", "logsigmoid", "(", "pos_rel_scores", ")", ".", "sum", "(", ")", "\n", "output_dict", "[", "'negative_rel_loss'", "]", "=", "-", "logsigmoid", "(", "-", "neg_rel_scores", ")", ".", "sum", "(", ")", "\n", "# fake pair loss", "\n", "if", "sampled_subjects", "is", "not", "None", "and", "sampled_objects", "is", "not", "None", ":", "\n", "# sampled_subjects, sampled_objects = self.to_tensors((sampled_subjects, sampled_objects))", "\n", "            ", "sampled_subjects", ",", "sampled_objects", "=", "sampled_subjects", ".", "view", "(", "-", "1", ",", "1", ")", ".", "squeeze", "(", "-", "1", ")", ",", "sampled_objects", ".", "view", "(", "-", "1", ",", "1", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "sampled_subjects", ",", "sampled_objects", "=", "self", ".", "represent_left_argument", "(", "sampled_subjects", ")", ",", "self", ".", "represent_right_argument", "(", "sampled_objects", ")", "\n", "rep_embedded_objects", ",", "rep_embedded_subjects", "=", "embedded_objects", ".", "repeat", "(", "self", ".", "num_neg_samples", ",", "1", ")", ",", "embedded_subjects", ".", "repeat", "(", "self", ".", "num_neg_samples", ",", "1", ")", "\n", "pred_relations_for_sampled_sub", "=", "self", ".", "predict_relations", "(", "sampled_subjects", ",", "rep_embedded_objects", ")", "\n", "pred_relations_for_sampled_obj", "=", "self", ".", "predict_relations", "(", "rep_embedded_subjects", ",", "sampled_objects", ")", "\n", "rep_observed_relations", "=", "observed_relations", ".", "repeat", "(", "self", ".", "num_neg_samples", ",", "1", ")", "\n", "output_dict", "[", "'negative_subject_loss'", "]", "=", "-", "logsigmoid", "(", "-", "self", ".", "score", "(", "pred_relations_for_sampled_sub", ",", "rep_observed_relations", ")", ")", ".", "sum", "(", ")", "#/ self.num_neg_samples", "\n", "output_dict", "[", "'negative_object_loss'", "]", "=", "-", "logsigmoid", "(", "-", "self", ".", "score", "(", "pred_relations_for_sampled_obj", ",", "rep_observed_relations", ")", ")", ".", "sum", "(", ")", "#/ self.num_neg_samples", "\n", "", "if", "self", ".", "type_scores", "is", "not", "None", ":", "\n", "# loss_weights += [('type_subject_loss', 0.3), ('type_object_loss', 0.3)]", "\n", "            ", "method", "=", "'uniform'", "\n", "type_sampled_subjects", ",", "type_sampled_objects", "=", "self", ".", "get_type_sampled_arguments", "(", "subjects", ",", "method", ")", ",", "self", ".", "get_type_sampled_arguments", "(", "objects", ",", "method", ")", "\n", "type_sampled_subjects", ",", "type_sampled_objects", "=", "self", ".", "represent_left_argument", "(", "type_sampled_subjects", ")", ",", "self", ".", "represent_right_argument", "(", "type_sampled_objects", ")", "\n", "pred_relations_for_type_sampled_sub", "=", "self", ".", "predict_relations", "(", "type_sampled_subjects", ",", "embedded_objects", ")", "\n", "pred_relations_for_type_sampled_obj", "=", "self", ".", "predict_relations", "(", "embedded_subjects", ",", "type_sampled_objects", ")", "\n", "output_dict", "[", "'type_subject_loss'", "]", "=", "-", "logsigmoid", "(", "-", "self", ".", "score", "(", "pred_relations_for_type_sampled_sub", ",", "observed_relations", ")", ")", ".", "sum", "(", ")", "\n", "output_dict", "[", "'type_object_loss'", "]", "=", "-", "logsigmoid", "(", "-", "self", ".", "score", "(", "pred_relations_for_type_sampled_obj", ",", "observed_relations", ")", ")", ".", "sum", "(", ")", "\n", "", "loss", "=", "0.0", "\n", "for", "loss_name", ",", "weight", "in", "self", ".", "loss_weights", ":", "\n", "            ", "loss", "+=", "weight", "*", "output_dict", "[", "loss_name", "]", "\n", "", "output_dict", "[", "'observed_probabilities'", "]", "=", "sigmoid", "(", "pos_rel_scores", ")", "\n", "output_dict", "[", "'sampled_probabilities'", "]", "=", "sigmoid", "(", "neg_rel_scores", ")", "\n", "return", "predicted_relations", ",", "loss", ",", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.get_type_sampled_arguments": [[126, 137], ["torch.index_select", "torch.autograd.Variable", "torch.index_select", "torch.multinomial().squeeze().cuda", "torch.gather().squeeze", "torch.LongTensor().random_().cuda", "torch.gather().squeeze", "torch.multinomial().squeeze", "torch.gather", "torch.LongTensor().random_", "torch.gather", "torch.LongTensor().random_().cuda.unsqueeze", "model.Pair2Vec.type_scores.size", "torch.LongTensor().random_().cuda.unsqueeze", "torch.multinomial", "torch.LongTensor", "arguments.size"], "methods", ["None"], ["", "def", "get_type_sampled_arguments", "(", "self", ",", "arguments", ",", "method", "=", "'uniform'", ")", ":", "\n", "        ", "argument_indices", "=", "torch", ".", "index_select", "(", "self", ".", "type_indices", ",", "0", ",", "arguments", ".", "data", ")", "\n", "if", "method", "==", "'unigram'", ":", "\n", "            ", "argument_scores", "=", "torch", ".", "index_select", "(", "self", ".", "type_scores", ",", "0", ",", "arguments", ".", "data", ")", "\n", "sampled_idx_idxs", "=", "torch", ".", "multinomial", "(", "argument_scores", ",", "1", ",", "replacement", "=", "True", ")", ".", "squeeze", "(", "1", ")", ".", "cuda", "(", ")", "\n", "sampled_idxs", "=", "torch", ".", "gather", "(", "argument_indices", ",", "1", ",", "sampled_idx_idxs", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "# sampled_idx_idxs = torch.randint(0, self.type_scores.size(1), size=arguments.size(0), replacement=True)", "\n", "            ", "sampled_idx_idxs", "=", "torch", ".", "LongTensor", "(", "arguments", ".", "size", "(", "0", ")", ")", ".", "random_", "(", "0", ",", "self", ".", "type_scores", ".", "size", "(", "1", ")", ")", ".", "cuda", "(", ")", "\n", "sampled_idxs", "=", "torch", ".", "gather", "(", "argument_indices", ",", "1", ",", "sampled_idx_idxs", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "", "return", "Variable", "(", "sampled_idxs", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.Pair2Vec.score": [[138, 140], ["torch.bmm().squeeze().squeeze", "torch.bmm().squeeze", "torch.bmm", "predicted.unsqueeze", "observed.unsqueeze"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "predicted", ",", "observed", ")", ":", "\n", "        ", "return", "torch", ".", "bmm", "(", "predicted", ".", "unsqueeze", "(", "1", ")", ",", "observed", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", "-", "1", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.MLP.__init__": [[144, 158], ["torch.nn.Module.__init__", "torch.nn.Dropout", "torch.nn.ReLU", "getattr", "getattr", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sequential", "NotImplementedError", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "Dropout", "(", "p", "=", "config", ".", "dropout", ")", "\n", "self", ".", "nonlinearity", "=", "ReLU", "(", ")", "\n", "self", ".", "normalize", "=", "normalize", "if", "getattr", "(", "config", ",", "'normalize_args'", ",", "False", ")", "else", "(", "lambda", "x", ":", "x", ")", "\n", "layers", "=", "getattr", "(", "config", ",", "\"mlp_layers\"", ",", "4", ")", "\n", "if", "layers", "==", "2", ":", "\n", "            ", "self", ".", "mlp", "=", "Sequential", "(", "self", ".", "dropout", ",", "Linear", "(", "3", "*", "config", ".", "d_args", ",", "config", ".", "d_args", ")", ",", "self", ".", "nonlinearity", ",", "self", ".", "dropout", ",", "Linear", "(", "config", ".", "d_args", ",", "config", ".", "d_rels", ")", ")", "\n", "", "elif", "layers", "==", "3", ":", "\n", "            ", "self", ".", "mlp", "=", "Sequential", "(", "self", ".", "dropout", ",", "Linear", "(", "3", "*", "config", ".", "d_args", ",", "config", ".", "d_args", ")", ",", "self", ".", "nonlinearity", ",", "self", ".", "dropout", ",", "Linear", "(", "config", ".", "d_args", ",", "config", ".", "d_args", ")", ",", "self", ".", "nonlinearity", ",", "self", ".", "dropout", ",", "Linear", "(", "config", ".", "d_args", ",", "config", ".", "d_rels", ")", ")", "\n", "", "elif", "layers", "==", "4", ":", "\n", "            ", "self", ".", "mlp", "=", "Sequential", "(", "self", ".", "dropout", ",", "Linear", "(", "3", "*", "config", ".", "d_args", ",", "config", ".", "d_args", ")", ",", "self", ".", "nonlinearity", ",", "self", ".", "dropout", ",", "Linear", "(", "config", ".", "d_args", ",", "config", ".", "d_args", ")", ",", "self", ".", "nonlinearity", ",", "self", ".", "dropout", ",", "Linear", "(", "config", ".", "d_args", ",", "config", ".", "d_args", ")", ",", "self", ".", "nonlinearity", ",", "self", ".", "dropout", ",", "Linear", "(", "config", ".", "d_args", ",", "config", ".", "d_rels", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.MLP.forward": [[159, 163], ["model.MLP.normalize", "model.MLP.normalize", "model.MLP.mlp", "torch.cat"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "subjects", ",", "objects", ")", ":", "\n", "        ", "subjects", "=", "self", ".", "normalize", "(", "subjects", ")", "\n", "objects", "=", "self", ".", "normalize", "(", "objects", ")", "\n", "return", "self", ".", "mlp", "(", "torch", ".", "cat", "(", "[", "subjects", ",", "objects", ",", "subjects", "*", "objects", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.model.get_type_file": [[12, 19], ["numpy.load", "torch.from_numpy", "numpy.concatenate", "len", "numpy.ones", "len", "len"], "function", ["None"], ["def", "get_type_file", "(", "filename", ",", "vocab", ",", "indxs", "=", "False", ")", ":", "\n", "    ", "data", "=", "np", ".", "load", "(", "filename", ")", "\n", "if", "len", "(", "vocab", ")", "-", "data", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "        ", "if", "indxs", ":", "\n", "            ", "data", "=", "data", "+", "(", "len", "(", "vocab", ")", "-", "data", ".", "shape", "[", "0", "]", ")", "\n", "", "data", "=", "np", ".", "concatenate", "(", "(", "np", ".", "ones", "(", "(", "len", "(", "vocab", ")", "-", "data", ".", "shape", "[", "0", "]", ",", "data", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "data", ".", "dtype", ")", ",", "data", ")", ")", "\n", "", "return", "torch", ".", "from_numpy", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.Config.__init__": [[116, 118], ["util.Config.__dict__.update"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.update"], ["    ", "def", "__init__", "(", "self", ",", "**", "entries", ")", ":", "\n", "        ", "self", ".", "__dict__", ".", "update", "(", "entries", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.Config.__str__": [[119, 124], ["util.Config.__dict__.items", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "string", "=", "''", "\n", "for", "key", ",", "value", "in", "self", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "            ", "string", "+=", "key", "+", "': '", "+", "str", "(", "value", ")", "+", "'\\n'", "\n", "", "return", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.Config.dump_to_file": [[125, 128], ["open", "json.dump"], "methods", ["None"], ["", "def", "dump_to_file", "(", "self", ",", "path", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "__dict__", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.masked_softmax": [[13, 31], ["torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax.sum"], "function", ["None"], ["def", "masked_softmax", "(", "vector", ",", "mask", ")", ":", "\n", "    ", "\"\"\"\n    ``torch.nn.functional.softmax(vector)`` does not work if some elements of ``vector`` should be\n    masked.  This performs a softmax on just the non-masked portions of ``vector``.  Passing\n    ``None`` in for the mask is also acceptable; you'll just get a regular softmax.\n    We assume that both ``vector`` and ``mask`` (if given) have shape ``(batch_size, vector_dim)``.\n    In the case that the input vector is completely masked, this function returns an array\n    of ``0.0``. This behavior may cause ``NaN`` if this is used as the last layer of a model\n    that uses categorical cross-entropy loss.\n    \"\"\"", "\n", "if", "mask", "is", "None", ":", "\n", "        ", "result", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "vector", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "# To limit numerical errors from large vector elements outside the mask, we zero these out.", "\n", "        ", "result", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "vector", "*", "mask", ",", "dim", "=", "-", "1", ")", "\n", "result", "=", "result", "*", "mask", "\n", "result", "=", "result", "/", "(", "result", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "+", "1e-13", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.load_model": [[32, 41], ["os.path.isfile", "torch.load", "print", "model.load_state_dict", "ValueError"], "function", ["None"], ["", "def", "load_model", "(", "resume_snapshot", ",", "model", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isfile", "(", "resume_snapshot", ")", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "resume_snapshot", ")", "\n", "print", "(", "\"Loaded checkpoint '{}' (epoch {} iter: {} train_loss: {}, dev_loss: {}, train_pos:{}, train_neg: {}, dev_pos: {}, dev_neg: {})\"", "\n", ".", "format", "(", "resume_snapshot", ",", "checkpoint", "[", "'epoch'", "]", ",", "checkpoint", "[", "'iterations'", "]", ",", "checkpoint", "[", "'train_loss'", "]", ",", "checkpoint", "[", "'dev_loss'", "]", ",", "checkpoint", "[", "'train_pos'", "]", ",", "checkpoint", "[", "'train_neg'", "]", ",", "checkpoint", "[", "'dev_pos'", "]", ",", "checkpoint", "[", "'dev_neg'", "]", ")", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "True", ")", "\n", "", "else", ":", "\n", "# logger.info(\"No checkpoint found at '{}'\".format(resume_snapshot))", "\n", "        ", "raise", "ValueError", "(", "\"No checkpoint found at {}\"", ".", "format", "(", "resume_snapshot", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.resume_from": [[42, 55], ["os.path.isfile", "logger.info", "torch.load", "model.load_state_dict", "logger.info", "logger.info", "optimizer.load_state_dict"], "function", ["None"], ["", "", "def", "resume_from", "(", "resume_snapshot", ",", "model", ",", "optimizer", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isfile", "(", "resume_snapshot", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading checkpoint '{}'\"", ".", "format", "(", "resume_snapshot", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "resume_snapshot", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "if", "optimizer", "is", "not", "None", ":", "\n", "            ", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "", "logger", ".", "info", "(", "\"Loaded checkpoint '{}' (epoch {} iter: {} train_loss: {}, dev_loss: {}, train_pos:{}, train_neg: {}, dev_pos: {}, dev_neg: {})\"", "\n", ".", "format", "(", "resume_snapshot", ",", "checkpoint", "[", "'epoch'", "]", ",", "checkpoint", "[", "'iterations'", "]", ",", "checkpoint", "[", "'train_loss'", "]", ",", "checkpoint", "[", "'dev_loss'", "]", ",", "checkpoint", "[", "'train_pos'", "]", ",", "checkpoint", "[", "'train_neg'", "]", ",", "checkpoint", "[", "'dev_pos'", "]", ",", "checkpoint", "[", "'dev_neg'", "]", ")", ")", "\n", "return", "checkpoint", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"No checkpoint found at '{}'\"", ".", "format", "(", "resume_snapshot", ")", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.save_checkpoint": [[56, 84], ["config.dump_to_file", "train_eval_stats.average", "os.path.join", "torch.save", "os.path.join", "dev_eval_stats.average", "model.state_dict", "optimizer.state_dict", "glob.glob", "os.remove"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.Config.dump_to_file", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.average", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.save", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.average"], ["", "", "def", "save_checkpoint", "(", "config", ",", "model", ",", "optimizer", ",", "epoch", ",", "iterations", ",", "train_eval_stats", ",", "dev_eval_stats", ",", "name", ",", "remove", "=", "True", ")", ":", "\n", "# save config", "\n", "    ", "config", ".", "dump_to_file", "(", "os", ".", "path", ".", "join", "(", "config", ".", "save_path", ",", "\"saved_config.json\"", ")", ")", "\n", "\n", "train_loss", ",", "train_pos", ",", "train_neg", "=", "train_eval_stats", ".", "average", "(", ")", "\n", "dev_loss", ",", "dev_pos", ",", "dev_neg", "=", "dev_eval_stats", ".", "average", "(", ")", "if", "dev_eval_stats", "is", "not", "None", "else", "(", "-", "1.0", ",", "-", "1.0", ",", "-", "1.0", ")", "\n", "\n", "snapshot_prefix", "=", "os", ".", "path", ".", "join", "(", "config", ".", "save_path", ",", "name", ")", "\n", "snapshot_path", "=", "snapshot_prefix", "+", "'_loss_{:.6f}_iter_{}_pos_{}_neg_{}_model.pt'", ".", "format", "(", "train_loss", ",", "iterations", ",", "\n", "train_pos", ",", "train_neg", ")", "\n", "\n", "state", "=", "{", "\n", "'epoch'", ":", "epoch", ",", "\n", "'iterations'", ":", "iterations", "+", "1", ",", "\n", "'state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'train_loss'", ":", "train_loss", ",", "\n", "'dev_loss'", ":", "dev_loss", ",", "\n", "'train_pos'", ":", "train_pos", ",", "\n", "'train_neg'", ":", "train_neg", ",", "\n", "'dev_pos'", ":", "dev_pos", ",", "\n", "'dev_neg'", ":", "dev_neg", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", "\n", "torch", ".", "save", "(", "state", ",", "snapshot_path", ")", "\n", "if", "remove", ":", "\n", "        ", "for", "f", "in", "glob", ".", "glob", "(", "snapshot_prefix", "+", "'*'", ")", ":", "\n", "            ", "if", "f", "!=", "snapshot_path", ":", "\n", "                ", "os", ".", "remove", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.pretrained_embeddings_or_xavier": [[86, 93], ["hasattr", "util.pretrained_embeddings", "torch.nn.init.xavier_normal"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.pretrained_embeddings"], ["", "", "", "", "def", "pretrained_embeddings_or_xavier", "(", "config", ",", "embedding", ",", "vocab", ",", "namespace", ")", ":", "\n", "    ", "pretrained_file", "=", "config", ".", "pretrained_file", "if", "hasattr", "(", "config", ",", "\"pretrained_file\"", ")", "else", "None", "\n", "if", "pretrained_file", "is", "not", "None", ":", "\n", "        ", "pretrained_embeddings", "(", "pretrained_file", ",", "embedding", ",", "\n", "vocab", ",", "namespace", ")", "\n", "", "else", ":", "\n", "        ", "xavier_normal", "(", "embedding", ".", "weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.pretrained_embeddings": [[94, 98], ["_read_pretrained_embedding_file", "embedding.weight.data.copy_"], "function", ["None"], ["", "", "def", "pretrained_embeddings", "(", "pretrained_file", ",", "embedding", ",", "vocab", ",", "namespace", ")", ":", "\n", "    ", "weight", "=", "_read_pretrained_embedding_file", "(", "pretrained_file", ",", "embedding", ".", "embedding_dim", ",", "\n", "vocab", ",", "namespace", ")", "\n", "embedding", ".", "weight", ".", "data", ".", "copy_", "(", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.makedirs": [[100, 113], ["os.makedirs", "os.path.isdir"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.makedirs"], ["", "def", "makedirs", "(", "name", ")", ":", "\n", "    ", "\"\"\"helper function for python 2 and 3 to call os.makedirs()\n       avoiding an error if the directory to be created already exists\"\"\"", "\n", "import", "os", ",", "errno", "\n", "try", ":", "\n", "        ", "os", ".", "makedirs", "(", "name", ")", "\n", "", "except", "OSError", "as", "ex", ":", "\n", "        ", "if", "ex", ".", "errno", "==", "errno", ".", "EEXIST", "and", "os", ".", "path", ".", "isdir", "(", "name", ")", ":", "\n", "# ignore existing directory", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "# a different error happened", "\n", "            ", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.get_config": [[129, 137], ["pyhocon.ConfigFactory.parse_file", "util.Config"], "function", ["None"], ["", "", "", "def", "get_config", "(", "filename", ",", "exp_name", "=", "None", ",", "save_path", "=", "None", ")", ":", "\n", "    ", "config_dict", "=", "pyhocon", ".", "ConfigFactory", ".", "parse_file", "(", "filename", ")", "\n", "if", "exp_name", "is", "not", "None", "and", "exp_name", "in", "config_dict", ":", "\n", "        ", "config_dict", "=", "config_dict", "[", "exp_name", "]", "\n", "", "config", "=", "Config", "(", "**", "config_dict", ")", "\n", "if", "save_path", "is", "not", "None", ":", "\n", "        ", "config", ".", "save_path", "=", "save_path", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.print_config": [[139, 141], ["print", "pyhocon.HOCONConverter.convert"], "function", ["None"], ["", "def", "print_config", "(", "config", ")", ":", "\n", "    ", "print", "(", "pyhocon", ".", "HOCONConverter", ".", "convert", "(", "config", ",", "\"hocon\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.get_args": [[143, 153], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.parse_args"], ["", "def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", "description", "=", "'Relation Embeddings'", ")", "\n", "parser", ".", "add_argument", "(", "'--config'", ",", "type", "=", "str", ",", "default", "=", "\"experiments.conf\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_path'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "45", ")", "\n", "parser", ".", "add_argument", "(", "'--exp'", ",", "type", "=", "str", ",", "default", "=", "'multiplication'", ")", "\n", "parser", ".", "add_argument", "(", "'--resume_snapshot'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "", ""]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data._LazyInstances.__init__": [[23, 26], ["typing.Iterable.__init__"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.__init__"], ["def", "__init__", "(", "self", ",", "instance_generator", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "instance_generator", "=", "instance_generator", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data._LazyInstances.__iter__": [[27, 30], ["matrix_data._LazyInstances.instance_generator"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "instances", "=", "self", ".", "instance_generator", "(", ")", "\n", "return", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.TripletIterator.__init__": [[89, 102], ["numpy.load", "numpy.load"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "batch_size", ",", "fields", ",", "return_nl", "=", "False", ",", "limit", "=", "None", ",", "compositional_rels", "=", "True", ",", "type_scores_file", "=", "None", ",", "type_indices_file", "=", "None", ",", "num_neg_samples", "=", "1", ",", "\n", "alpha", "=", "0.75", ",", "num_sampled_relations", "=", "1", ",", "model_type", "=", "'sampling'", ")", ":", "\n", "        ", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "return_nl", "=", "return_nl", "\n", "self", ".", "limit", "=", "limit", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "compositional_rels", "=", "compositional_rels", "\n", "self", ".", "num_neg_samples", "=", "num_neg_samples", "\n", "self", ".", "num_sampled_relations", "=", "num_sampled_relations", "\n", "self", ".", "model_type", "=", "model_type", "\n", "self", ".", "type_scores", "=", "None", "if", "type_scores_file", "is", "None", "else", "np", ".", "load", "(", "type_scores_file", ")", "\n", "self", ".", "type_indices", "=", "None", "if", "type_indices_file", "is", "None", "else", "np", ".", "load", "(", "type_indices_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.TripletIterator.__call__": [[103, 107], ["matrix_data.TripletIterator._create_batches"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.TripletIterator._create_batches"], ["", "def", "__call__", "(", "self", ",", "data", ",", "device", "=", "-", "1", ",", "train", "=", "True", ")", ":", "\n", "        ", "batches", "=", "self", ".", "_create_batches", "(", "data", ",", "device", ",", "train", ")", "\n", "for", "batch", "in", "batches", ":", "\n", "            ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.TripletIterator._create_batches": [[109, 126], ["enumerate", "sample", "range", "tuple", "tuple", "torch.autograd.Variable", "torch.LongTensor", "t.cuda"], "methods", ["None"], ["", "", "def", "_create_batches", "(", "self", ",", "instance_gen", ",", "device", "=", "-", "1", ",", "train", "=", "True", ")", ":", "\n", "        ", "for", "instances", "in", "instance_gen", ":", "\n", "            ", "start", "=", "0", "\n", "sample", "=", "sample_compositional", "\n", "inputs", "=", "instances", "if", "(", "not", "train", ")", "else", "sample", "(", "instances", ",", "self", ".", "alpha", ",", "self", ".", "compositional_rels", ",", "self", ".", "type_scores", ",", "self", ".", "type_indices", ",", "self", ".", "num_neg_samples", ",", "self", ".", "num_sampled_relations", ",", "model_type", "=", "self", ".", "model_type", ")", "\n", "for", "num", ",", "batch_start", "in", "enumerate", "(", "range", "(", "0", ",", "inputs", "[", "0", "]", ".", "shape", "[", "0", "]", ",", "self", ".", "batch_size", ")", ")", ":", "\n", "                ", "tensors", "=", "tuple", "(", "Variable", "(", "torch", ".", "LongTensor", "(", "x", "[", "batch_start", ":", "batch_start", "+", "self", ".", "batch_size", "]", ")", ",", "requires_grad", "=", "False", ")", "for", "x", "in", "inputs", ")", "\n", "if", "device", "==", "None", ":", "\n", "                    ", "tensors", "=", "tuple", "(", "[", "t", ".", "cuda", "(", ")", "if", "t", "is", "not", "None", "else", "None", "for", "t", "in", "tensors", "]", ")", "\n", "", "if", "self", ".", "return_nl", ":", "\n", "                    ", "relation_nl", "=", "[", "]", "\n", "rel_index", "=", "2", "\n", "for", "rel", "in", "inputs", "[", "rel_index", "]", "[", "batch_start", ":", "batch_start", "+", "self", ".", "batch_size", "]", ":", "\n", "                        ", "relation_nl", "+=", "[", "' '", ".", "join", "(", "[", "self", ".", "fields", "[", "rel_index", "]", ".", "vocab", ".", "itos", "[", "j", "]", "for", "j", "in", "rel", "]", ")", "]", "\n", "", "yield", "tensors", ",", "(", "relation_nl", ")", "\n", "", "else", ":", "\n", "                    ", "yield", "tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.smoothed_sampling": [[32, 41], ["numpy.unique", "numpy.arange", "numpy.random.choice", "numpy.take", "numpy.power", "np.power.astype", "np.power.sum"], "function", ["None"], ["", "", "def", "smoothed_sampling", "(", "instances", ",", "alpha", "=", "None", ",", "num_neg_samples", "=", "1", ")", ":", "\n", "    ", "unique", ",", "counts", "=", "np", ".", "unique", "(", "instances", ",", "return_counts", "=", "True", ",", "axis", "=", "0", ")", "\n", "unique_idxs", "=", "np", ".", "arange", "(", "0", ",", "unique", ".", "shape", "[", "0", "]", ")", "\n", "if", "alpha", "is", "not", "None", ":", "\n", "        ", "counts", "=", "np", ".", "power", "(", "counts", ",", "alpha", ")", "\n", "", "probs", "=", "counts", ".", "astype", "(", "'float'", ")", "/", "counts", ".", "sum", "(", ")", "\n", "sample_idxs", "=", "np", ".", "random", ".", "choice", "(", "unique_idxs", ",", "size", "=", "instances", ".", "shape", "[", "0", "]", "*", "num_neg_samples", ",", "replace", "=", "True", ",", "p", "=", "probs", ")", "\n", "sample", "=", "np", ".", "take", "(", "unique", ",", "sample_idxs", ",", "axis", "=", "0", ")", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.uniform_type_sampling": [[42, 52], ["numpy.take", "numpy.random.randint", "numpy.take"], "function", ["None"], ["", "def", "uniform_type_sampling", "(", "instances", ",", "scores_matrix", ",", "indxs_matrix", ")", ":", "\n", "# (num_ins, topk)", "\n", "    ", "batch_indxs", "=", "np", ".", "take", "(", "indxs_matrix", ",", "instances", ",", "axis", "=", "0", ")", "\n", "# (num_ins, 1))", "\n", "sample_idx_idxs", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "indxs_matrix", ".", "shape", "[", "1", "]", ",", "indxs_matrix", ".", "shape", "[", "0", "]", ")", "\n", "# import ipdb", "\n", "# ipdb.set_trace()", "\n", "# (num_ins, 1))", "\n", "sample_idxs", "=", "np", ".", "take", "(", "batch_indxs", ",", "sample_idx_idxs", ",", "axis", "=", "1", ")", "\n", "return", "sample_idxs", "\n", "", "def", "batched_unigram_type_sampling", "(", "instances", ",", "scores_matrix", ",", "indxs_matrix", ")", ":", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.batched_unigram_type_sampling": [[52, 64], ["numpy.take", "numpy.take", "torch.multinomial", "numpy.take", "torch.from_numpy", "torch.multinomial.cpu().numpy", "torch.multinomial.cpu"], "function", ["None"], ["", "def", "batched_unigram_type_sampling", "(", "instances", ",", "scores_matrix", ",", "indxs_matrix", ")", ":", "\n", "# (num_ins, topk)", "\n", "    ", "batch_indxs", "=", "np", ".", "take", "(", "indxs_matrix", ",", "instances", ",", "axis", "=", "0", ")", "\n", "# (num_ins, topk)", "\n", "batch_scores", "=", "np", ".", "take", "(", "scores_matrix", ",", "instances", ",", "axis", "=", "0", ")", "\n", "# (num_ins, 1))", "\n", "sample_idx_idxs", "=", "torch", ".", "multinomial", "(", "torch", ".", "from_numpy", "(", "batch_scores", ")", ",", "1", ",", "replacement", "=", "True", ")", "\n", "# import ipdb", "\n", "# ipdb.set_trace()", "\n", "# (num_ins, 1))", "\n", "sample_idxs", "=", "np", ".", "take", "(", "batch_indxs", ",", "sample_idx_idxs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "1", ")", "\n", "return", "sample_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.unigram_type_sampling": [[65, 70], ["range", "numpy.concatenate", "samples.append", "matrix_data.batched_unigram_type_sampling"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.batched_unigram_type_sampling"], ["", "def", "unigram_type_sampling", "(", "instances", ",", "scores_matrix", ",", "indxs_matrix", ",", "batch_size", "=", "10000", ")", ":", "\n", "    ", "samples", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "instances", ".", "shape", "[", "0", "]", ",", "batch_size", ")", ":", "\n", "        ", "samples", ".", "append", "(", "batched_unigram_type_sampling", "(", "instances", "[", "i", ":", "i", "+", "batch_size", "]", ",", "scores_matrix", ",", "indxs_matrix", ")", ")", "\n", "", "return", "np", ".", "concatenate", "(", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.shuffled_sampling": [[72, 74], ["numpy.random.permutation"], "function", ["None"], ["", "def", "shuffled_sampling", "(", "instances", ")", ":", "\n", "    ", "return", "np", ".", "random", ".", "permutation", "(", "instances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.sample_compositional": [[75, 85], ["numpy.random.shuffle", "sample_fn", "sampled_relations.reshape.reshape", "relations.reshape", "sample_fn().reshape", "sample_fn().reshape", "sample_fn", "sample_fn"], "function", ["None"], ["", "def", "sample_compositional", "(", "instances", ",", "alpha", "=", "None", ",", "compositional_rels", "=", "True", ",", "type_scores", "=", "None", ",", "type_indices", "=", "None", ",", "num_neg_samples", "=", "1", ",", "num_sampled_relations", "=", "1", ",", "model_type", "=", "'sampling'", ")", ":", "\n", "    ", "np", ".", "random", ".", "shuffle", "(", "instances", ")", "\n", "subjects", ",", "objects", ",", "relations", "=", "instances", "[", ":", ",", "0", "]", ",", "instances", "[", ":", ",", "1", "]", ",", "instances", "[", ":", ",", "2", ":", "]", "\n", "relations", "=", "relations", "if", "compositional_rels", "or", "relations", ".", "shape", "[", "1", "]", ">", "1", "else", "relations", ".", "reshape", "(", "relations", ".", "shape", "[", "0", "]", ")", "\n", "sample_fn", ",", "kwargs", "=", "(", "smoothed_sampling", ",", "{", "'alpha'", ":", "alpha", ",", "'num_neg_samples'", ":", "num_sampled_relations", "}", ")", "if", "alpha", "is", "not", "None", "else", "(", "shuffled_sampling", ",", "{", "}", ")", "\n", "sampled_relations", "=", "sample_fn", "(", "relations", ",", "**", "kwargs", ")", "\n", "sampled_relations", "=", "sampled_relations", ".", "reshape", "(", "(", "relations", ".", "shape", "[", "0", "]", ",", "relations", ".", "shape", "[", "1", "]", ",", "num_sampled_relations", ")", ")", "\n", "sample_fn", ",", "kwargs", "=", "(", "smoothed_sampling", ",", "{", "'alpha'", ":", "alpha", ",", "'num_neg_samples'", ":", "num_neg_samples", "}", ")", "if", "alpha", "is", "not", "None", "else", "(", "shuffled_sampling", ",", "{", "}", ")", "\n", "sampled_subjects", ",", "sampled_objects", "=", "sample_fn", "(", "subjects", ",", "**", "kwargs", ")", ".", "reshape", "(", "(", "instances", ".", "shape", "[", "0", "]", ",", "num_neg_samples", ")", ")", ",", "sample_fn", "(", "objects", ",", "**", "kwargs", ")", ".", "reshape", "(", "(", "instances", ".", "shape", "[", "0", "]", ",", "num_neg_samples", ")", ")", "\n", "return", "subjects", ",", "objects", ",", "relations", ",", "sampled_relations", ",", "sampled_subjects", ",", "sampled_objects", "#, type_sampled_subjects, type_sampled_objects", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.create_vocab": [[127, 138], ["getattr", "getattr", "embeddings.vocab.Vocab", "os.path.join", "open", "f.read", "f.read.rstrip().split", "getattr", "getattr", "f.read.rstrip"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.read"], ["", "", "", "", "", "def", "create_vocab", "(", "config", ",", "field", ")", ":", "\n", "    ", "vocab_path", "=", "getattr", "(", "config", ",", "'vocab_file'", ",", "os", ".", "path", ".", "join", "(", "config", ".", "triplet_dir", ",", "\"vocab.txt\"", ")", ")", "\n", "tokens", "=", "None", "\n", "with", "open", "(", "vocab_path", ")", "as", "f", ":", "\n", "        ", "text", "=", "f", ".", "read", "(", ")", "\n", "tokens", "=", "text", ".", "rstrip", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "", "specials", "=", "[", "'<unk>'", ",", "'<pad>'", ",", "'<X>'", ",", "'<Y>'", "]", "if", "config", ".", "compositional_rels", "else", "[", "'<unk>'", ",", "''", "]", "\n", "init_with_pretrained", "=", "getattr", "(", "config", ",", "'init_with_pretrained'", ",", "True", ")", "\n", "vectors", ",", "vectors_cache", "=", "(", "None", ",", "None", ")", "if", "not", "init_with_pretrained", "else", "(", "getattr", "(", "config", ",", "'word_vecs'", ",", "'fasttext.en.300d'", ")", ",", "getattr", "(", "config", ",", "'word_vecs_cache'", ",", "'data/fasttext'", ")", ")", "\n", "vocab", "=", "Vocab", "(", "tokens", ",", "specials", "=", "specials", ",", "vectors", "=", "vectors", ",", "vectors_cache", "=", "vectors_cache", ")", "\n", "field", ".", "vocab", "=", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.read": [[139, 145], ["os.path.isfile", "numpy.load", "logger.info"], "function", ["None"], ["", "def", "read", "(", "filenames", ")", ":", "\n", "    ", "for", "fname", "in", "filenames", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "fname", ")", ":", "\n", "            ", "instances", "=", "np", ".", "load", "(", "fname", ")", "\n", "logger", ".", "info", "(", "'Loading {} instances from {}'", ".", "format", "(", "instances", ".", "shape", "[", "0", "]", ",", "fname", ")", ")", "\n", "yield", "instances", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.read_dev": [[146, 154], ["numpy.load", "logger.info", "sample", "numpy.load", "numpy.load"], "function", ["None"], ["", "", "", "def", "read_dev", "(", "fname", ",", "limit", "=", "None", ",", "compositional_rels", "=", "True", ",", "type_scores_file", "=", "None", ",", "type_indices_file", "=", "None", ",", "num_neg_samples", "=", "1", ",", "num_sampled_relations", "=", "1", ",", "model_type", "=", "'sampling'", ")", ":", "\n", "    ", "instances", "=", "np", ".", "load", "(", "fname", ")", "\n", "instances", "=", "instances", "[", ":", "limit", "]", "if", "limit", "is", "not", "None", "else", "instances", "\n", "logger", ".", "info", "(", "'Loading {} instances from {}'", ".", "format", "(", "instances", ".", "shape", "[", "0", "]", ",", "fname", ")", ")", "\n", "type_scores", "=", "None", "if", "type_scores_file", "is", "None", "else", "np", ".", "load", "(", "type_scores_file", ")", "\n", "type_indices", "=", "None", "if", "type_indices_file", "is", "None", "else", "np", ".", "load", "(", "type_indices_file", ")", "\n", "sample", "=", "sample_compositional", "\n", "return", "sample", "(", "instances", ",", "alpha", "=", ".75", ",", "compositional_rels", "=", "compositional_rels", ",", "type_scores", "=", "type_scores", ",", "type_indices", "=", "type_indices", ",", "num_neg_samples", "=", "num_neg_samples", ",", "num_sampled_relations", "=", "num_sampled_relations", ",", "model_type", "=", "model_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.dev_data": [[155, 157], ["None"], "function", ["None"], ["", "def", "dev_data", "(", "sample", ")", ":", "\n", "    ", "yield", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.create_dataset": [[158, 169], ["matrix_data._LazyInstances", "getattr", "matrix_data.read_dev", "matrix_data._LazyInstances", "os.path.join", "hasattr", "hasattr", "range", "iter", "iter", "matrix_data.read", "matrix_data.dev_data", "str"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.read_dev", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.read", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.dev_data"], ["", "def", "create_dataset", "(", "config", ",", "triplet_dir", "=", "None", ")", ":", "\n", "    ", "triplet_dir", "=", "config", ".", "triplet_dir", "if", "triplet_dir", "is", "None", "else", "triplet_dir", "\n", "#files = [os.path.join(config.triplet_dir, fname) for fname in os.listdir(config.triplet_dir) if fname.endswith('.npy')]", "\n", "files", "=", "[", "os", ".", "path", ".", "join", "(", "triplet_dir", ",", "'triplets_'", "+", "str", "(", "i", ")", "+", "'.npy'", ")", "for", "i", "in", "range", "(", "1", ",", "1000", ")", "]", "\n", "train_data", "=", "_LazyInstances", "(", "lambda", ":", "iter", "(", "read", "(", "files", "[", "1", ":", "]", ")", ")", ")", "\n", "type_scores_file", "=", "config", ".", "type_scores_file", "if", "hasattr", "(", "config", ",", "'type_scores_file'", ")", "else", "None", "\n", "type_indices_file", "=", "config", ".", "type_indices_file", "if", "hasattr", "(", "config", ",", "'type_indices_file'", ")", "else", "None", "\n", "model_type", "=", "getattr", "(", "config", ",", "'model_type'", ",", "'sampling'", ")", "\n", "validation_sample", "=", "read_dev", "(", "files", "[", "0", "]", ",", "500000", ",", "config", ".", "compositional_rels", ",", "type_scores_file", ",", "type_indices_file", ",", "config", ".", "num_neg_samples", ",", "config", ".", "num_sampled_relations", ",", "model_type", ")", "\n", "validation_data", "=", "_LazyInstances", "(", "lambda", ":", "iter", "(", "dev_data", "(", "validation_sample", ")", ")", ")", "\n", "return", "train_data", ",", "validation_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.read_data": [[170, 192], ["embeddings.indexed_field.Field", "matrix_data.create_dataset", "matrix_data.create_vocab", "len", "len", "getattr", "getattr", "matrix_data.TripletIterator", "matrix_data.TripletIterator", "embeddings.indexed_field.Field", "embeddings.indexed_field.Field", "hasattr", "hasattr", "getattr", "getattr", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.create_dataset", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.create_vocab"], ["", "def", "read_data", "(", "config", ",", "return_nl", "=", "False", ",", "preindex", "=", "True", ")", ":", "\n", "    ", "args", "=", "Field", "(", "lower", "=", "True", ",", "batch_first", "=", "True", ")", "\n", "rels", "=", "Field", "(", "lower", "=", "True", ",", "batch_first", "=", "True", ")", "if", "config", ".", "compositional_rels", "else", "Field", "(", "batch_first", "=", "True", ")", "\n", "fields", "=", "[", "args", ",", "args", ",", "rels", "]", "\n", "train", ",", "dev", "=", "create_dataset", "(", "config", ")", "\n", "create_vocab", "(", "config", ",", "args", ")", "\n", "rels", ".", "vocab", "=", "args", ".", "vocab", "\n", "config", ".", "n_args", "=", "len", "(", "args", ".", "vocab", ")", "\n", "config", ".", "n_rels", "=", "len", "(", "rels", ".", "vocab", ")", "\n", "sample_arguments", "=", "getattr", "(", "config", ",", "\"sample_arguments\"", ",", "True", ")", "\n", "fields", "=", "fields", "+", "[", "rels", ",", "args", ",", "args", "]", "if", "sample_arguments", "else", "fields", "+", "[", "rels", "]", "\n", "type_scores_file", "=", "config", ".", "type_scores_file", "if", "hasattr", "(", "config", ",", "'type_scores_file'", ")", "else", "None", "\n", "type_indices_file", "=", "config", ".", "type_indices_file", "if", "hasattr", "(", "config", ",", "'type_indices_file'", ")", "else", "None", "\n", "model_type", "=", "getattr", "(", "config", ",", "'model_type'", ",", "'sampling'", ")", "\n", "\n", "train_iterator", "=", "TripletIterator", "(", "config", ".", "train_batch_size", ",", "fields", ",", "return_nl", "=", "return_nl", ",", "\n", "compositional_rels", "=", "config", ".", "compositional_rels", ",", "type_scores_file", "=", "type_scores_file", ",", "type_indices_file", "=", "type_indices_file", ",", "num_neg_samples", "=", "config", ".", "num_neg_samples", ",", "\n", "alpha", "=", "getattr", "(", "config", ",", "'alpha'", ",", "0.75", ")", ",", "num_sampled_relations", "=", "getattr", "(", "config", ",", "'num_sampled_relations'", ",", "1", ")", ",", "model_type", "=", "model_type", ")", "\n", "dev_iterator", "=", "TripletIterator", "(", "config", ".", "dev_batch_size", ",", "fields", ",", "return_nl", "=", "return_nl", ",", "compositional_rels", "=", "config", ".", "compositional_rels", ",", "num_neg_samples", "=", "config", ".", "num_neg_samples", ",", "\n", "alpha", "=", "getattr", "(", "config", ",", "'alpha'", ",", "0.75", ")", ",", "num_sampled_relations", "=", "getattr", "(", "config", ",", "'num_sampled_relations'", ",", "1", ")", ",", "model_type", "=", "model_type", ")", "\n", "\n", "return", "train", ",", "dev", ",", "train_iterator", ",", "dev_iterator", ",", "args", ",", "rels", "\n", "", ""]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.cooccurance.read_vocab_from_file": [[6, 15], ["embeddings.vocab.Vocab", "print", "open", "f.read", "f.read.rstrip().split", "len", "f.read.rstrip"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.read"], ["def", "read_vocab_from_file", "(", "vocab_path", ",", "specials", ")", ":", "\n", "    ", "tokens", "=", "None", "\n", "with", "open", "(", "vocab_path", ")", "as", "f", ":", "\n", "        ", "text", "=", "f", ".", "read", "(", ")", "\n", "tokens", "=", "text", ".", "rstrip", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "", "tokens", "=", "tokens", "[", "3", ":", "]", "\n", "vocab", "=", "Vocab", "(", "tokens", ",", "specials", "=", "specials", ")", "\n", "print", "(", "'Loaded vocab with {} tokens'", ".", "format", "(", "len", "(", "tokens", ")", ")", ")", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.cooccurance.get_cooccurance": [[16, 34], ["cooccurance.read_vocab_from_file", "collections.defaultdict", "sorted", "open", "tqdm.tqdm", "sorted.items", "open", "enumerate", "line.strip().lower().split", "len", "enumerate", "f.write", "line.strip().lower", "range", "str", "line.strip"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.cooccurance.read_vocab_from_file"], ["", "def", "get_cooccurance", "(", "fname", ",", "vocab_file", ",", "outf", ")", ":", "\n", "    ", "vocab", "=", "read_vocab_from_file", "(", "vocab_file", ",", "specials", "=", "[", "'<unk>'", ",", "'<pad>'", ",", "'<X>'", ",", "'<Y>'", "]", ")", "\n", "counts", "=", "defaultdict", "(", "int", ")", "\n", "win", "=", "5", "\n", "with", "open", "(", "fname", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "i_line", ",", "line", "in", "tqdm", "(", "enumerate", "(", "f", ")", ")", ":", "\n", "            ", "tokens", "=", "line", ".", "strip", "(", ")", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "token_ids", "=", "[", "vocab", ".", "stoi", "[", "t", "]", "for", "t", "in", "tokens", "if", "vocab", ".", "stoi", "[", "t", "]", "!=", "0", "]", "\n", "len_tokens", "=", "len", "(", "token_ids", ")", "\n", "for", "ix", ",", "x", "in", "enumerate", "(", "token_ids", ")", ":", "\n", "                ", "y_iter", "=", "[", "iy", "for", "iy", "in", "range", "(", "ix", "+", "1", ",", "ix", "+", "2", "+", "win", ")", "if", "iy", "<", "len_tokens", "and", "token_ids", "[", "iy", "]", "!=", "0", "]", "\n", "for", "iy", "in", "y_iter", ":", "\n", "                    ", "pair", "=", "(", "token_ids", "[", "ix", "]", ",", "token_ids", "[", "iy", "]", ")", "if", "token_ids", "[", "ix", "]", "<", "token_ids", "[", "iy", "]", "else", "(", "token_ids", "[", "iy", "]", ",", "token_ids", "[", "ix", "]", ")", "\n", "counts", "[", "pair", "]", "+=", "1", "\n", "", "", "", "", "counts", "=", "sorted", "(", "counts", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "with", "open", "(", "outf", ",", "mode", "=", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "pair", ",", "count", "in", "counts", ":", "\n", "            ", "f", ".", "write", "(", "vocab", ".", "itos", "[", "pair", "[", "0", "]", "]", "+", "'\\t'", "+", "vocab", ".", "itos", "[", "pair", "[", "1", "]", "]", "+", "'\\t'", "+", "str", "(", "count", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.Vocab.__init__": [[43, 78], ["collections.defaultdict", "vocab.Vocab.stoi.update", "list", "vocab.Vocab.load_vectors", "print", "enumerate"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.update", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.Vocab.load_vectors"], ["def", "__init__", "(", "self", ",", "word_list", ",", "max_size", "=", "None", ",", "min_freq", "=", "1", ",", "specials", "=", "[", "'<pad>'", "]", ",", "\n", "vectors", "=", "None", ",", "unk_init", "=", "None", ",", "vectors_cache", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create a Vocab object from a collections.Counter.\n\n        Arguments:\n            counter: collections.Counter object holding the frequencies of\n                each value found in the data.\n            max_size: The maximum size of the vocabulary, or None for no\n                maximum. Default: None.\n            min_freq: The minimum frequency needed to include a token in the\n                vocabulary. Values less than 1 will be set to 1. Default: 1.\n            specials: The list of special tokens (e.g., padding or eos) that\n                will be prepended to the vocabulary in addition to an <unk>\n                token. Default: ['<pad>']\n            vectors: One of either the available pretrained vectors\n                or custom pretrained vectors (see Vocab.load_vectors);\n                or a list of aforementioned vectors\n            unk_init (callback): by default, initialize out-of-vocabulary word vectors\n                to zero vectors; can be any function that takes in a Tensor and\n                returns a Tensor of the same size. Default: torch.Tensor.zero_\n            vectors_cache: directory for cached vectors. Default: '.vector_cache'\n        \"\"\"", "\n", "\n", "self", ".", "itos", "=", "list", "(", "specials", ")", "+", "word_list", "\n", "self", ".", "specials", "=", "specials", "\n", "self", ".", "stoi", "=", "defaultdict", "(", "_default_unk_index", ")", "\n", "# stoi is simply a reverse dict for itos", "\n", "self", ".", "stoi", ".", "update", "(", "{", "tok", ":", "i", "for", "i", ",", "tok", "in", "enumerate", "(", "self", ".", "itos", ")", "}", ")", "\n", "\n", "self", ".", "vectors", "=", "None", "\n", "if", "vectors", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_vectors", "(", "vectors", ",", "unk_init", "=", "unk_init", ",", "cache", "=", "vectors_cache", ")", "\n", "print", "(", "'Loaded from {} {}'", ".", "format", "(", "vectors", ",", "vectors_cache", ")", ")", "\n", "", "else", ":", "\n", "            ", "assert", "unk_init", "is", "None", "and", "vectors_cache", "is", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.Vocab.__eq__": [[79, 87], ["None"], "methods", ["None"], ["", "", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "self", ".", "stoi", "!=", "other", ".", "stoi", ":", "\n", "            ", "return", "False", "\n", "", "if", "self", ".", "itos", "!=", "other", ".", "itos", ":", "\n", "            ", "return", "False", "\n", "", "if", "self", ".", "vectors", "!=", "other", ".", "vectors", ":", "\n", "            ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.Vocab.__len__": [[88, 90], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "itos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.Vocab.extend": [[91, 97], ["sorted", "vocab.Vocab.itos.append", "len"], "methods", ["None"], ["", "def", "extend", "(", "self", ",", "v", ",", "sort", "=", "False", ")", ":", "\n", "        ", "words", "=", "sorted", "(", "v", ".", "itos", ")", "if", "sort", "else", "v", ".", "itos", "\n", "for", "w", "in", "words", ":", "\n", "            ", "if", "w", "not", "in", "self", ".", "stoi", ":", "\n", "                ", "self", ".", "itos", ".", "append", "(", "w", ")", "\n", "self", ".", "stoi", "[", "w", "]", "=", "len", "(", "self", ".", "itos", ")", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.Vocab.load_vectors": [[98, 147], ["enumerate", "sum", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "enumerate", "isinstance", "isinstance", "len", "isinstance", "six.text_type", "ValueError", "isinstance", "ValueError", "token.strip", "list", "type", "pretrained_aliases.keys"], "methods", ["None"], ["", "", "", "def", "load_vectors", "(", "self", ",", "vectors", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            vectors: one of or a list containing instantiations of the\n                GloVe, CharNGram, or Vectors classes. Alternatively, one\n                of or a list of available pretrained vectors:\n                charngram.100d\n                fasttext.en.300d\n                fasttext.simple.300d\n                glove.42B.300d\n                glove.840B.300d\n                glove.twitter.27B.25d\n                glove.twitter.27B.50d\n                glove.twitter.27B.100d\n                glove.twitter.27B.200d\n                glove.6B.50d\n                glove.6B.100d\n                glove.6B.200d\n                glove.6B.300d\n            Remaining keyword arguments: Passed to the constructor of Vectors classes.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "vectors", ",", "list", ")", ":", "\n", "            ", "vectors", "=", "[", "vectors", "]", "\n", "", "for", "idx", ",", "vector", "in", "enumerate", "(", "vectors", ")", ":", "\n", "            ", "if", "six", ".", "PY2", "and", "isinstance", "(", "vector", ",", "str", ")", ":", "\n", "                ", "vector", "=", "six", ".", "text_type", "(", "vector", ")", "\n", "", "if", "isinstance", "(", "vector", ",", "six", ".", "string_types", ")", ":", "\n", "# Convert the string pretrained vector identifier", "\n", "# to a Vectors object", "\n", "                ", "if", "vector", "not", "in", "pretrained_aliases", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Got string input vector {}, but allowed pretrained \"", "\n", "\"vectors are {}\"", ".", "format", "(", "\n", "vector", ",", "list", "(", "pretrained_aliases", ".", "keys", "(", ")", ")", ")", ")", "\n", "", "vectors", "[", "idx", "]", "=", "pretrained_aliases", "[", "vector", "]", "(", "**", "kwargs", ")", "\n", "", "elif", "not", "isinstance", "(", "vector", ",", "Vectors", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Got input vectors of type {}, expected str or \"", "\n", "\"Vectors object\"", ".", "format", "(", "type", "(", "vector", ")", ")", ")", "\n", "\n", "", "", "tot_dim", "=", "sum", "(", "v", ".", "dim", "for", "v", "in", "vectors", ")", "\n", "self", ".", "vectors", "=", "torch", ".", "Tensor", "(", "len", "(", "self", ")", ",", "tot_dim", ")", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "self", ".", "itos", ")", ":", "\n", "            ", "start_dim", "=", "0", "\n", "for", "v", "in", "vectors", ":", "\n", "                ", "end_dim", "=", "start_dim", "+", "v", ".", "dim", "\n", "self", ".", "vectors", "[", "i", "]", "[", "start_dim", ":", "end_dim", "]", "=", "v", "[", "token", ".", "strip", "(", ")", "]", "\n", "start_dim", "=", "end_dim", "\n", "", "assert", "(", "start_dim", "==", "tot_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.Vocab.set_vectors": [[148, 171], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "enumerate", "len", "stoi.get", "unk_init"], "methods", ["None"], ["", "", "def", "set_vectors", "(", "self", ",", "stoi", ",", "vectors", ",", "dim", ",", "unk_init", "=", "torch", ".", "Tensor", ".", "zero_", ")", ":", "\n", "        ", "\"\"\"\n        Set the vectors for the Vocab instance from a collection of Tensors.\n\n        Arguments:\n            stoi: A dictionary of string to the index of the associated vector\n                in the `vectors` input argument.\n            vectors: An indexed iterable (or other structure supporting __getitem__) that\n                given an input index, returns a FloatTensor representing the vector\n                for the token associated with the index. For example,\n                vector[stoi[\"string\"]] should return the vector for \"string\".\n            dim: The dimensionality of the vectors.\n            unk_init (callback): by default, initialize out-of-vocabulary word vectors\n                to zero vectors; can be any function that takes in a Tensor and\n                returns a Tensor of the same size. Default: torch.Tensor.zero_\n        \"\"\"", "\n", "self", ".", "vectors", "=", "torch", ".", "Tensor", "(", "len", "(", "self", ")", ",", "dim", ")", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "self", ".", "itos", ")", ":", "\n", "            ", "wv_index", "=", "stoi", ".", "get", "(", "token", ",", "None", ")", "\n", "if", "wv_index", "is", "not", "None", ":", "\n", "                ", "self", ".", "vectors", "[", "i", "]", "=", "vectors", "[", "wv_index", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "vectors", "[", "i", "]", "=", "unk_init", "(", "self", ".", "vectors", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.SubwordVocab.__init__": [[175, 212], ["collections.defaultdict", "vocab.SubwordVocab.stoi.update", "revtok.SubwordSegmenter", "sorted", "vocab.SubwordVocab.segment.vocab.items", "vocab.SubwordVocab.itos.append", "vocab.SubwordVocab.load_vectors", "print", "len", "len", "enumerate", "len"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.update", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.Vocab.load_vectors"], ["    ", "def", "__init__", "(", "self", ",", "counter", ",", "max_size", "=", "None", ",", "specials", "=", "[", "'<pad>'", "]", ",", "\n", "vectors", "=", "None", ",", "unk_init", "=", "torch", ".", "Tensor", ".", "zero_", ")", ":", "\n", "        ", "\"\"\"Create a revtok subword vocabulary from a collections.Counter.\n\n        Arguments:\n            counter: collections.Counter object holding the frequencies of\n                each word found in the data.\n            max_size: The maximum size of the subword vocabulary, or None for no\n                maximum. Default: None.\n            specials: The list of special tokens (e.g., padding or eos) that\n                will be prepended to the vocabulary in addition to an <unk>\n                token.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "import", "revtok", "\n", "", "except", "ImportError", ":", "\n", "            ", "print", "(", "\"Please install revtok.\"", ")", "\n", "raise", "\n", "\n", "", "self", ".", "stoi", "=", "defaultdict", "(", "_default_unk_index", ")", "\n", "self", ".", "stoi", ".", "update", "(", "{", "tok", ":", "i", "for", "i", ",", "tok", "in", "enumerate", "(", "specials", ")", "}", ")", "\n", "self", ".", "itos", "=", "specials", "\n", "\n", "self", ".", "segment", "=", "revtok", ".", "SubwordSegmenter", "(", "counter", ",", "max_size", ")", "\n", "\n", "max_size", "=", "None", "if", "max_size", "is", "None", "else", "max_size", "+", "len", "(", "self", ".", "itos", ")", "\n", "\n", "# sort by frequency/entropy, then alphabetically", "\n", "toks", "=", "sorted", "(", "self", ".", "segment", ".", "vocab", ".", "items", "(", ")", ",", "\n", "key", "=", "lambda", "tup", ":", "(", "len", "(", "tup", "[", "0", "]", ")", "!=", "1", ",", "-", "tup", "[", "1", "]", ",", "tup", "[", "0", "]", ")", ")", "\n", "\n", "for", "tok", ",", "_", "in", "toks", ":", "\n", "            ", "self", ".", "itos", ".", "append", "(", "tok", ")", "\n", "self", ".", "stoi", "[", "tok", "]", "=", "len", "(", "self", ".", "itos", ")", "-", "1", "\n", "\n", "", "if", "vectors", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_vectors", "(", "vectors", ",", "unk_init", "=", "unk_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.Vectors.__init__": [[216, 230], ["vocab.Vectors.cache"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.Vectors.cache"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "cache", "=", "None", ",", "\n", "url", "=", "None", ",", "unk_init", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n           name: name of the file that contains the vectors\n           cache: directory for cached vectors\n           url: url for download if vectors not found in cache\n           unk_init (callback): by default, initalize out-of-vocabulary word vectors\n               to zero vectors; can be any function that takes in a Tensor and\n               returns a Tensor of the same size\n         \"\"\"", "\n", "cache", "=", "'.vector_cache'", "if", "cache", "is", "None", "else", "cache", "\n", "self", ".", "unk_init", "=", "torch", ".", "Tensor", ".", "zero_", "if", "unk_init", "is", "None", "else", "unk_init", "\n", "self", ".", "cache", "(", "name", ",", "cache", ",", "url", "=", "url", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.Vectors.__getitem__": [[231, 236], ["vocab.Vectors.unk_init", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "stoi", ":", "\n", "            ", "return", "self", ".", "vectors", "[", "self", ".", "stoi", "[", "token", "]", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "unk_init", "(", "torch", ".", "Tensor", "(", "1", ",", "self", ".", "dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.Vectors.cache": [[237, 327], ["os.path.isfile", "os.path.join", "os.path.isfile", "logger.info", "tqdm.tqdm.tqdm", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "logger.info", "torch.save", "torch.save", "torch.save", "torch.save", "logger.info", "torch.load", "torch.load", "torch.load", "torch.load", "os.path.join", "logger.info", "os.path.join", "logger.info", "os.path.isfile", "RuntimeError", "array.array", "enumerate", "line.rstrip().split", "vectors.extend", "itos.append", "os.path.basename", "os.path.isfile", "os.path.exists", "os.makedirs", "os.path.basename", "os.path.isfile", "str", "io.open", "logger.warning", "len", "len", "enumerate", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "tqdm.tqdm.tqdm", "os.path.splitext", "zipfile.ZipFile", "zf.extractall", "open", "line.rstrip", "len", "len", "logger.warning", "isinstance", "float", "six.moves.urllib.request.urlretrieve", "tarfile.open", "tar.extractall", "len", "RuntimeError", "word.decode.decode.decode", "logger.info", "os.remove", "torchtext.utils.reporthook", "len", "repr"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.save", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.save", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.save", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.preprocess.save", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.Vocab.extend", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.makedirs", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.decode"], ["", "", "def", "cache", "(", "self", ",", "name", ",", "cache", ",", "url", "=", "None", ")", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "name", ")", ":", "\n", "            ", "path", "=", "name", "\n", "path_pt", "=", "os", ".", "path", ".", "join", "(", "cache", ",", "os", ".", "path", ".", "basename", "(", "name", ")", ")", "+", "'.pt'", "\n", "", "else", ":", "\n", "            ", "path", "=", "os", ".", "path", ".", "join", "(", "cache", ",", "name", ")", "\n", "path_pt", "=", "path", "+", "'.pt'", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isfile", "(", "path_pt", ")", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "isfile", "(", "path", ")", "and", "url", ":", "\n", "                ", "logger", ".", "info", "(", "'Downloading vectors from {}'", ".", "format", "(", "url", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "cache", ")", "\n", "", "dest", "=", "os", ".", "path", ".", "join", "(", "cache", ",", "os", ".", "path", ".", "basename", "(", "url", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "dest", ")", ":", "\n", "                    ", "with", "tqdm", "(", "unit", "=", "'B'", ",", "unit_scale", "=", "True", ",", "miniters", "=", "1", ",", "desc", "=", "dest", ")", "as", "t", ":", "\n", "                        ", "try", ":", "\n", "                            ", "urlretrieve", "(", "url", ",", "dest", ",", "reporthook", "=", "reporthook", "(", "t", ")", ")", "\n", "", "except", "KeyboardInterrupt", "as", "e", ":", "# remove the partial zip file", "\n", "                            ", "os", ".", "remove", "(", "dest", ")", "\n", "raise", "e", "\n", "", "", "", "logger", ".", "info", "(", "'Extracting vectors into {}'", ".", "format", "(", "cache", ")", ")", "\n", "ext", "=", "os", ".", "path", ".", "splitext", "(", "dest", ")", "[", "1", "]", "[", "1", ":", "]", "\n", "if", "ext", "==", "'zip'", ":", "\n", "                    ", "with", "zipfile", ".", "ZipFile", "(", "dest", ",", "\"r\"", ")", "as", "zf", ":", "\n", "                        ", "zf", ".", "extractall", "(", "cache", ")", "\n", "", "", "elif", "ext", "==", "'gz'", ":", "\n", "                    ", "with", "tarfile", ".", "open", "(", "dest", ",", "'r:gz'", ")", "as", "tar", ":", "\n", "                        ", "tar", ".", "extractall", "(", "path", "=", "cache", ")", "\n", "", "", "", "if", "not", "os", ".", "path", ".", "isfile", "(", "path", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "'no vectors found at {}'", ".", "format", "(", "path", ")", ")", "\n", "\n", "# str call is necessary for Python 2/3 compatibility, since", "\n", "# argument must be Python 2 str (Python 3 bytes) or", "\n", "# Python 3 str (Python 2 unicode)", "\n", "", "itos", ",", "vectors", ",", "dim", "=", "[", "]", ",", "array", ".", "array", "(", "str", "(", "'d'", ")", ")", ",", "None", "\n", "\n", "# Try to read the whole file with utf-8 encoding.", "\n", "binary_lines", "=", "False", "\n", "try", ":", "\n", "                ", "with", "io", ".", "open", "(", "path", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "                    ", "lines", "=", "[", "line", "for", "line", "in", "f", "]", "\n", "# If there are malformed lines, read in binary mode", "\n", "# and manually decode each word from utf-8", "\n", "", "", "except", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Could not read {} as UTF8 file, \"", "\n", "\"reading file as bytes and skipping \"", "\n", "\"words with malformed UTF8.\"", ".", "format", "(", "path", ")", ")", "\n", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "                    ", "lines", "=", "[", "line", "for", "line", "in", "f", "]", "\n", "", "binary_lines", "=", "True", "\n", "\n", "", "logger", ".", "info", "(", "\"Loading vectors from {}\"", ".", "format", "(", "path", ")", ")", "\n", "for", "iline", ",", "line", "in", "tqdm", "(", "enumerate", "(", "lines", ")", ",", "total", "=", "len", "(", "lines", ")", ")", ":", "\n", "# Explicitly splitting on \" \" is important, so we don't", "\n", "# get rid of Unicode non-breaking spaces in the vectors.", "\n", "                ", "entries", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "b\" \"", "if", "binary_lines", "else", "\" \"", ")", "\n", "\n", "word", ",", "entries", "=", "entries", "[", "0", "]", ",", "entries", "[", "1", ":", "]", "\n", "if", "dim", "is", "None", "and", "len", "(", "entries", ")", ">", "1", ":", "\n", "                    ", "dim", "=", "len", "(", "entries", ")", "\n", "", "elif", "len", "(", "entries", ")", "==", "1", ":", "\n", "                    ", "logger", ".", "warning", "(", "\"Skipping token {} with 1-dimensional \"", "\n", "\"vector {}; likely a header\"", ".", "format", "(", "word", ",", "entries", ")", ")", "\n", "continue", "\n", "", "elif", "dim", "!=", "len", "(", "entries", ")", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\n", "\"Vector for token {} at line {} has {} dimensions, but previously \"", "\n", "\"read vectors have {} dimensions. All vectors must have \"", "\n", "\"the same number of dimensions.\"", ".", "format", "(", "word", ",", "iline", ",", "len", "(", "entries", ")", ",", "dim", ")", ")", "\n", "\n", "", "if", "binary_lines", ":", "\n", "                    ", "try", ":", "\n", "                        ", "if", "isinstance", "(", "word", ",", "six", ".", "binary_type", ")", ":", "\n", "                            ", "word", "=", "word", ".", "decode", "(", "'utf-8'", ")", "\n", "", "", "except", ":", "\n", "                        ", "logger", ".", "info", "(", "\"Skipping non-UTF8 token {}\"", ".", "format", "(", "repr", "(", "word", ")", ")", ")", "\n", "continue", "\n", "", "", "vectors", ".", "extend", "(", "float", "(", "x", ")", "for", "x", "in", "entries", ")", "\n", "itos", ".", "append", "(", "word", ")", "\n", "\n", "", "self", ".", "itos", "=", "itos", "\n", "self", ".", "stoi", "=", "{", "word", ":", "i", "for", "i", ",", "word", "in", "enumerate", "(", "itos", ")", "}", "\n", "self", ".", "vectors", "=", "torch", ".", "Tensor", "(", "vectors", ")", ".", "view", "(", "-", "1", ",", "dim", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "logger", ".", "info", "(", "'Saving vectors to {}'", ".", "format", "(", "path_pt", ")", ")", "\n", "torch", ".", "save", "(", "(", "self", ".", "itos", ",", "self", ".", "stoi", ",", "self", ".", "vectors", ",", "self", ".", "dim", ")", ",", "path_pt", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "'Loading vectors from {}'", ".", "format", "(", "path_pt", ")", ")", "\n", "self", ".", "itos", ",", "self", ".", "stoi", ",", "self", ".", "vectors", ",", "self", ".", "dim", "=", "torch", ".", "load", "(", "path_pt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.GloVe.__init__": [[337, 341], ["vocab.Vectors.__init__", "str"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.__init__"], ["def", "__init__", "(", "self", ",", "name", "=", "'840B'", ",", "dim", "=", "300", ",", "**", "kwargs", ")", ":", "\n", "        ", "url", "=", "self", ".", "url", "[", "name", "]", "\n", "name", "=", "'glove.{}.{}d.txt'", ".", "format", "(", "name", ",", "str", "(", "dim", ")", ")", "\n", "super", "(", "GloVe", ",", "self", ")", ".", "__init__", "(", "name", ",", "url", "=", "url", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.FastText.__init__": [[347, 351], ["vocab.FastText.url_base.format", "os.path.basename", "vocab.Vectors.__init__"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.__init__"], ["def", "__init__", "(", "self", ",", "language", "=", "\"en\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "url", "=", "self", ".", "url_base", ".", "format", "(", "language", ")", "\n", "name", "=", "os", ".", "path", ".", "basename", "(", "url", ")", "\n", "super", "(", "FastText", ",", "self", ")", ".", "__init__", "(", "name", ",", "url", "=", "url", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.CharNGram.__init__": [[359, 361], ["vocab.Vectors.__init__"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CharNGram", ",", "self", ")", ".", "__init__", "(", "self", ".", "name", ",", "url", "=", "self", ".", "url", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab.CharNGram.__getitem__": [[362, 383], ["torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "vocab.CharNGram.unk_init", "vocab.CharNGram.unk_init", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "list", "len", "range"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "token", ")", ":", "\n", "        ", "vector", "=", "torch", ".", "Tensor", "(", "1", ",", "self", ".", "dim", ")", ".", "zero_", "(", ")", "\n", "if", "token", "==", "\"<unk>\"", ":", "\n", "            ", "return", "self", ".", "unk_init", "(", "vector", ")", "\n", "# These literals need to be coerced to unicode for Python 2 compatibility", "\n", "# when we try to join them with read ngrams from the files.", "\n", "", "chars", "=", "[", "'#BEGIN#'", "]", "+", "list", "(", "token", ")", "+", "[", "'#END#'", "]", "\n", "num_vectors", "=", "0", "\n", "for", "n", "in", "[", "2", ",", "3", ",", "4", "]", ":", "\n", "            ", "end", "=", "len", "(", "chars", ")", "-", "n", "+", "1", "\n", "grams", "=", "[", "chars", "[", "i", ":", "(", "i", "+", "n", ")", "]", "for", "i", "in", "range", "(", "end", ")", "]", "\n", "for", "gram", "in", "grams", ":", "\n", "                ", "gram_key", "=", "'{}gram-{}'", ".", "format", "(", "n", ",", "''", ".", "join", "(", "gram", ")", ")", "\n", "if", "gram_key", "in", "self", ".", "stoi", ":", "\n", "                    ", "vector", "+=", "self", ".", "vectors", "[", "self", ".", "stoi", "[", "gram_key", "]", "]", "\n", "num_vectors", "+=", "1", "\n", "", "", "", "if", "num_vectors", ">", "0", ":", "\n", "            ", "vector", "/=", "num_vectors", "\n", "", "else", ":", "\n", "            ", "vector", "=", "self", ".", "unk_init", "(", "vector", ")", "\n", "", "return", "vector", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.vocab._default_unk_index": [[385, 387], ["None"], "function", ["None"], ["", "", "def", "_default_unk_index", "(", ")", ":", "\n", "    ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.modules.VariationalDropout.forward": [[5, 17], ["torch.autograd.Variable", "torch.nn.functional.dropout", "input.data.new().fill_", "torch.nn.functional.dropout.unsqueeze", "torch.nn.functional.dropout.unsqueeze", "input.data.new"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"\n        input is shape (batch_size, timesteps, embedding_dim)\n        Samples one mask of size (batch_size, embedding_dim) and applies it to every time step.\n        \"\"\"", "\n", "ones", "=", "Variable", "(", "input", ".", "data", ".", "new", "(", "input", ".", "shape", "[", "0", "]", ",", "input", ".", "shape", "[", "-", "1", "]", ")", ".", "fill_", "(", "1", ")", ")", "\n", "dropout_mask", "=", "torch", ".", "nn", ".", "functional", ".", "dropout", "(", "ones", ",", "self", ".", "p", ",", "self", ".", "training", ",", "inplace", "=", "False", ")", "\n", "if", "self", ".", "inplace", ":", "\n", "            ", "input", "*=", "dropout_mask", ".", "unsqueeze", "(", "1", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "            ", "return", "dropout_mask", ".", "unsqueeze", "(", "1", ")", "*", "input", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.esim_pair2vec.ESIMPair2Vec.__init__": [[56, 107], ["allennlp.nn.InitializerApplicator", "allennlp.models.model.Model.__init__", "endtasks.util.get_pair2vec", "DotProductMatrixAttention", "torch.nn.Dropout", "vocab.get_vocab_size", "allennlp.training.metrics.CategoricalAccuracy", "torch.nn.CrossEntropyLoss", "initializer", "torch.nn.Dropout", "endtasks.modules.VariationalDropout"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.__init__", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_pair2vec"], ["def", "__init__", "(", "self", ",", "vocab", ":", "Vocabulary", ",", "\n", "encoder_keys", ":", "List", "[", "str", "]", ",", "\n", "mask_key", ":", "str", ",", "\n", "pair2vec_config_file", ":", "str", ",", "\n", "pair2vec_model_file", ":", "str", ",", "\n", "text_field_embedder", ":", "TextFieldEmbedder", ",", "\n", "encoder", ":", "Seq2SeqEncoder", ",", "\n", "similarity_function", ":", "SimilarityFunction", ",", "\n", "projection_feedforward", ":", "FeedForward", ",", "\n", "inference_encoder", ":", "Seq2SeqEncoder", ",", "\n", "output_feedforward", ":", "FeedForward", ",", "\n", "output_logit", ":", "FeedForward", ",", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ",", "\n", "dropout", ":", "float", "=", "0.5", ",", "\n", "pair2vec_dropout", ":", "float", "=", "0.0", ",", "\n", "bidirectional_pair2vec", ":", "bool", "=", "True", ",", "\n", "regularizer", ":", "Optional", "[", "RegularizerApplicator", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ",", "regularizer", ")", "\n", "self", ".", "_vocab", "=", "vocab", "\n", "self", ".", "pair2vec", "=", "util", ".", "get_pair2vec", "(", "pair2vec_config_file", ",", "pair2vec_model_file", ")", "\n", "self", ".", "_encoder_keys", "=", "encoder_keys", "\n", "self", ".", "_mask_key", "=", "mask_key", "\n", "self", ".", "_text_field_embedder", "=", "text_field_embedder", "\n", "self", ".", "_projection_feedforward", "=", "projection_feedforward", "\n", "self", ".", "_encoder", "=", "encoder", "\n", "from", "allennlp", ".", "modules", ".", "matrix_attention", "import", "DotProductMatrixAttention", "\n", "\n", "self", ".", "_matrix_attention", "=", "DotProductMatrixAttention", "(", ")", "\n", "\n", "\n", "self", ".", "_inference_encoder", "=", "inference_encoder", "\n", "self", ".", "_pair2vec_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "pair2vec_dropout", ")", "\n", "self", ".", "_bidirectional_pair2vec", "=", "bidirectional_pair2vec", "\n", "\n", "if", "dropout", ":", "\n", "            ", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "rnn_input_dropout", "=", "VariationalDropout", "(", "dropout", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "None", "\n", "self", ".", "rnn_input_dropout", "=", "None", "\n", "\n", "", "self", ".", "_output_feedforward", "=", "output_feedforward", "\n", "self", ".", "_output_logit", "=", "output_logit", "\n", "\n", "self", ".", "_num_labels", "=", "vocab", ".", "get_vocab_size", "(", "namespace", "=", "\"labels\"", ")", "\n", "\n", "\n", "self", ".", "_accuracy", "=", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "initializer", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.esim_pair2vec.ESIMPair2Vec.forward": [[108, 245], ["endtasks.util.get_encoder_input", "endtasks.util.get_encoder_input", "endtasks.util.get_pair2vec_word_embeddings", "endtasks.util.get_pair2vec_word_embeddings", "endtasks.util.get_mask().float", "endtasks.util.get_mask().float", "esim_pair2vec.ESIMPair2Vec._encoder", "esim_pair2vec.ESIMPair2Vec._encoder", "esim_pair2vec.ESIMPair2Vec._matrix_attention", "allennlp.nn.util.last_dim_softmax", "allennlp.nn.util.weighted_sum", "allennlp.nn.util.last_dim_softmax", "allennlp.nn.util.weighted_sum", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "allennlp.nn.util.last_dim_softmax", "allennlp.nn.util.last_dim_softmax", "torch.cat", "torch.cat", "esim_pair2vec.ESIMPair2Vec._projection_feedforward", "esim_pair2vec.ESIMPair2Vec._projection_feedforward", "esim_pair2vec.ESIMPair2Vec._inference_encoder", "esim_pair2vec.ESIMPair2Vec._inference_encoder", "allennlp.nn.util.replace_masked_values().max", "allennlp.nn.util.replace_masked_values().max", "torch.cat", "esim_pair2vec.ESIMPair2Vec._output_feedforward", "esim_pair2vec.ESIMPair2Vec._output_logit", "torch.nn.functional.softmax", "esim_pair2vec.ESIMPair2Vec.rnn_input_dropout", "esim_pair2vec.ESIMPair2Vec.rnn_input_dropout", "esim_pair2vec.ESIMPair2Vec.transpose().contiguous", "endtasks.util.get_pair_embeddings", "endtasks.util.get_pair_embeddings", "torch.cat", "torch.cat", "esim_pair2vec.ESIMPair2Vec.transpose().contiguous", "esim_pair2vec.ESIMPair2Vec._pair2vec_dropout", "pair2vec_premise_mask.float().unsqueeze", "esim_pair2vec.ESIMPair2Vec._pair2vec_dropout", "pair2vec_hypothesis_mask.float().unsqueeze", "esim_pair2vec.ESIMPair2Vec.rnn_input_dropout", "esim_pair2vec.ESIMPair2Vec.rnn_input_dropout", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "esim_pair2vec.ESIMPair2Vec.dropout", "esim_pair2vec.ESIMPair2Vec._loss", "esim_pair2vec.ESIMPair2Vec._accuracy", "endtasks.util.get_mask", "endtasks.util.get_mask", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "allennlp.nn.util.weighted_sum", "allennlp.nn.util.weighted_sum", "allennlp.nn.util.replace_masked_values", "allennlp.nn.util.replace_masked_values", "label.long().view", "esim_pair2vec.ESIMPair2Vec.transpose", "torch.cat.transpose", "torch.nn.functional.normalize.transpose", "esim_pair2vec.ESIMPair2Vec.transpose", "pair2vec_premise_mask.float", "pair2vec_hypothesis_mask.float", "endtasks.util.get_mask().float.unsqueeze", "endtasks.util.get_mask().float.unsqueeze", "endtasks.util.get_mask().float.unsqueeze", "endtasks.util.get_mask().float.unsqueeze", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "label.long"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_encoder_input", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_encoder_input", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_pair2vec_word_embeddings", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_pair2vec_word_embeddings", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_pair_embeddings", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_pair_embeddings", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_mask", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_mask"], ["", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "premise", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "hypothesis", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "label", ":", "torch", ".", "IntTensor", "=", "None", ",", "\n", "metadata", ":", "Dict", "=", "None", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "# pylint: disable=arguments-differ", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        premise : Dict[str, torch.LongTensor]\n            From a ``TextField``\n        hypothesis : Dict[str, torch.LongTensor]\n            From a ``TextField``\n        label : torch.IntTensor, optional (default = None)\n            From a ``LabelField``\n\n        Returns\n        -------\n        An output dictionary consisting of:\n\n        label_logits : torch.FloatTensor\n            A tensor of shape ``(batch_size, num_labels)`` representing unnormalised log\n            probabilities of the entailment label.\n        label_probs : torch.FloatTensor\n            A tensor of shape ``(batch_size, num_labels)`` representing probabilities of the\n            entailment label.\n        loss : torch.FloatTensor, optional\n            A scalar loss to be optimised.\n        \"\"\"", "\n", "embedded_premise", "=", "util", ".", "get_encoder_input", "(", "self", ".", "_text_field_embedder", ",", "premise", ",", "self", ".", "_encoder_keys", ")", "\n", "embedded_hypothesis", "=", "util", ".", "get_encoder_input", "(", "self", ".", "_text_field_embedder", ",", "hypothesis", ",", "self", ".", "_encoder_keys", ")", "\n", "premise_as_args", "=", "util", ".", "get_pair2vec_word_embeddings", "(", "self", ".", "pair2vec", ",", "premise", "[", "'pair2vec_tokens'", "]", ")", "\n", "hypothesis_as_args", "=", "util", ".", "get_pair2vec_word_embeddings", "(", "self", ".", "pair2vec", ",", "hypothesis", "[", "'pair2vec_tokens'", "]", ")", "\n", "\n", "premise_mask", "=", "util", ".", "get_mask", "(", "premise", ",", "self", ".", "_mask_key", ")", ".", "float", "(", ")", "\n", "hypothesis_mask", "=", "util", ".", "get_mask", "(", "hypothesis", ",", "self", ".", "_mask_key", ")", ".", "float", "(", ")", "\n", "\n", "# apply dropout for LSTM", "\n", "if", "self", ".", "rnn_input_dropout", ":", "\n", "            ", "embedded_premise", "=", "self", ".", "rnn_input_dropout", "(", "embedded_premise", ")", "\n", "embedded_hypothesis", "=", "self", ".", "rnn_input_dropout", "(", "embedded_hypothesis", ")", "\n", "\n", "# encode premise and hypothesis", "\n", "", "encoded_premise", "=", "self", ".", "_encoder", "(", "embedded_premise", ",", "premise_mask", ")", "\n", "encoded_hypothesis", "=", "self", ".", "_encoder", "(", "embedded_hypothesis", ",", "hypothesis_mask", ")", "\n", "\n", "\n", "# Shape: (batch_size, premise_length, hypothesis_length)", "\n", "similarity_matrix", "=", "self", ".", "_matrix_attention", "(", "encoded_premise", ",", "encoded_hypothesis", ")", "\n", "\n", "# Shape: (batch_size, premise_length, hypothesis_length)", "\n", "p2h_attention", "=", "last_dim_softmax", "(", "similarity_matrix", ",", "hypothesis_mask", ")", "\n", "# Shape: (batch_size, premise_length, embedding_dim)", "\n", "attended_hypothesis", "=", "weighted_sum", "(", "encoded_hypothesis", ",", "p2h_attention", ")", "\n", "\n", "# Shape: (batch_size, hypothesis_length, premise_length)", "\n", "h2p_attention", "=", "last_dim_softmax", "(", "similarity_matrix", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ",", "premise_mask", ")", "\n", "# Shape: (batch_size, hypothesis_length, embedding_dim)", "\n", "attended_premise", "=", "weighted_sum", "(", "encoded_premise", ",", "h2p_attention", ")", "\n", "\n", "# cross sequence embeddings", "\n", "ph_pair_embeddings", "=", "normalize", "(", "util", ".", "get_pair_embeddings", "(", "self", ".", "pair2vec", ",", "premise_as_args", ",", "hypothesis_as_args", ")", ",", "dim", "=", "-", "1", ")", "\n", "hp_pair_embeddings", "=", "normalize", "(", "util", ".", "get_pair_embeddings", "(", "self", ".", "pair2vec", ",", "hypothesis_as_args", ",", "premise_as_args", ")", ",", "dim", "=", "-", "1", ")", "\n", "if", "self", ".", "_bidirectional_pair2vec", ":", "\n", "            ", "temp", "=", "torch", ".", "cat", "(", "(", "ph_pair_embeddings", ",", "hp_pair_embeddings", ".", "transpose", "(", "1", ",", "2", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "hp_pair_embeddings", "=", "torch", ".", "cat", "(", "(", "hp_pair_embeddings", ",", "ph_pair_embeddings", ".", "transpose", "(", "1", ",", "2", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "ph_pair_embeddings", "=", "temp", "\n", "# pair_embeddings = torch.cat((ph_pair_embeddings, hp_pair_embeddings.transpose(1,2)), dim=-1)", "\n", "# pair2vec masks", "\n", "", "pair2vec_premise_mask", "=", "1", "-", "(", "torch", ".", "eq", "(", "premise", "[", "'pair2vec_tokens'", "]", ",", "0", ")", ".", "long", "(", ")", "+", "torch", ".", "eq", "(", "premise", "[", "'pair2vec_tokens'", "]", ",", "1", ")", ".", "long", "(", ")", ")", "\n", "pair2vec_hypothesis_mask", "=", "1", "-", "(", "torch", ".", "eq", "(", "hypothesis", "[", "'pair2vec_tokens'", "]", ",", "0", ")", ".", "long", "(", ")", "+", "torch", ".", "eq", "(", "hypothesis", "[", "'pair2vec_tokens'", "]", ",", "1", ")", ".", "long", "(", ")", ")", "\n", "# re-normalize attention using pair2vec masks", "\n", "h2p_attention", "=", "last_dim_softmax", "(", "similarity_matrix", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ",", "pair2vec_premise_mask", ")", "\n", "p2h_attention", "=", "last_dim_softmax", "(", "similarity_matrix", ",", "pair2vec_hypothesis_mask", ")", "\n", "\n", "attended_hypothesis_pairs", "=", "self", ".", "_pair2vec_dropout", "(", "weighted_sum", "(", "ph_pair_embeddings", ",", "p2h_attention", ")", ")", "*", "pair2vec_premise_mask", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "attended_premise_pairs", "=", "self", ".", "_pair2vec_dropout", "(", "weighted_sum", "(", "hp_pair_embeddings", ",", "h2p_attention", ")", ")", "*", "pair2vec_hypothesis_mask", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "\n", "# the \"enhancement\" layer", "\n", "premise_enhanced", "=", "torch", ".", "cat", "(", "\n", "[", "encoded_premise", ",", "attended_hypothesis", ",", "\n", "encoded_premise", "-", "attended_hypothesis", ",", "\n", "encoded_premise", "*", "attended_hypothesis", ",", "\n", "attended_hypothesis_pairs", "]", ",", "\n", "dim", "=", "-", "1", "\n", ")", "\n", "hypothesis_enhanced", "=", "torch", ".", "cat", "(", "\n", "[", "encoded_hypothesis", ",", "attended_premise", ",", "\n", "encoded_hypothesis", "-", "attended_premise", ",", "\n", "encoded_hypothesis", "*", "attended_premise", ",", "\n", "attended_premise_pairs", "]", ",", "\n", "dim", "=", "-", "1", "\n", ")", "\n", "\n", "projected_enhanced_premise", "=", "self", ".", "_projection_feedforward", "(", "premise_enhanced", ")", "\n", "projected_enhanced_hypothesis", "=", "self", ".", "_projection_feedforward", "(", "hypothesis_enhanced", ")", "\n", "\n", "# Run the inference layer", "\n", "if", "self", ".", "rnn_input_dropout", ":", "\n", "            ", "projected_enhanced_premise", "=", "self", ".", "rnn_input_dropout", "(", "projected_enhanced_premise", ")", "\n", "projected_enhanced_hypothesis", "=", "self", ".", "rnn_input_dropout", "(", "projected_enhanced_hypothesis", ")", "\n", "", "v_ai", "=", "self", ".", "_inference_encoder", "(", "projected_enhanced_premise", ",", "premise_mask", ")", "\n", "v_bi", "=", "self", ".", "_inference_encoder", "(", "projected_enhanced_hypothesis", ",", "hypothesis_mask", ")", "\n", "\n", "# The pooling layer -- max and avg pooling.", "\n", "# (batch_size, model_dim)", "\n", "v_a_max", ",", "_", "=", "replace_masked_values", "(", "\n", "v_ai", ",", "premise_mask", ".", "unsqueeze", "(", "-", "1", ")", ",", "-", "1e7", "\n", ")", ".", "max", "(", "dim", "=", "1", ")", "\n", "v_b_max", ",", "_", "=", "replace_masked_values", "(", "\n", "v_bi", ",", "hypothesis_mask", ".", "unsqueeze", "(", "-", "1", ")", ",", "-", "1e7", "\n", ")", ".", "max", "(", "dim", "=", "1", ")", "\n", "\n", "v_a_avg", "=", "torch", ".", "sum", "(", "v_ai", "*", "premise_mask", ".", "unsqueeze", "(", "-", "1", ")", ",", "dim", "=", "1", ")", "/", "torch", ".", "sum", "(", "premise_mask", ",", "1", ",", "keepdim", "=", "True", ")", "\n", "v_b_avg", "=", "torch", ".", "sum", "(", "v_bi", "*", "hypothesis_mask", ".", "unsqueeze", "(", "-", "1", ")", ",", "dim", "=", "1", ")", "/", "torch", ".", "sum", "(", "hypothesis_mask", ",", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "# Now concat", "\n", "# (batch_size, model_dim * 2 * 4)", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v_a_avg", ",", "v_a_max", ",", "v_b_avg", ",", "v_b_max", "]", ",", "dim", "=", "1", ")", "\n", "\n", "# the final MLP -- apply dropout to input, and MLP applies to output & hidden", "\n", "if", "self", ".", "dropout", ":", "\n", "            ", "v", "=", "self", ".", "dropout", "(", "v", ")", "\n", "\n", "", "output_hidden", "=", "self", ".", "_output_feedforward", "(", "v", ")", "\n", "label_logits", "=", "self", ".", "_output_logit", "(", "output_hidden", ")", "\n", "label_probs", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "label_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "output_dict", "=", "{", "\"label_logits\"", ":", "label_logits", ",", "\"label_probs\"", ":", "label_probs", "}", "\n", "\n", "if", "label", "is", "not", "None", ":", "\n", "            ", "loss", "=", "self", ".", "_loss", "(", "label_logits", ",", "label", ".", "long", "(", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "self", ".", "_accuracy", "(", "label_logits", ",", "label", ")", "\n", "output_dict", "[", "\"loss\"", "]", "=", "loss", "\n", "\n", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.esim_pair2vec.ESIMPair2Vec.get_metrics": [[246, 249], ["esim_pair2vec.ESIMPair2Vec._accuracy.get_metric"], "methods", ["None"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "return", "{", "\n", "'accuracy'", ":", "self", ".", "_accuracy", ".", "get_metric", "(", "reset", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_reader.NoAnswerSquad2Reader.__init__": [[133, 140], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "allennlp.data.tokenizers.WordTokenizer", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Tokenizer", "=", "None", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "lazy", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "or", "WordTokenizer", "(", ")", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "or", "{", "'tokens'", ":", "SingleIdTokenIndexer", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_reader.NoAnswerSquad2Reader._read": [[141, 171], ["allennlp.common.file_utils.cached_path", "logger.info", "logger.info", "open", "json.load", "squad2_reader.NoAnswerSquad2Reader._tokenizer.tokenize", "question_answer[].strip().replace", "squad2_reader.NoAnswerSquad2Reader.text_to_instance", "zip", "question_answer[].strip", "len", "len", "zip", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_reader.NoAnswerSquad2Reader.text_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ":", "str", ")", ":", "\n", "# if `file_path` is a URL, redirect to the cache", "\n", "        ", "no_answer_token", "=", "'CANNOTANSWER'", "\n", "file_path", "=", "cached_path", "(", "file_path", ")", "\n", "\n", "logger", ".", "info", "(", "\"Reading file at %s\"", ",", "file_path", ")", "\n", "with", "open", "(", "file_path", ")", "as", "dataset_file", ":", "\n", "            ", "dataset_json", "=", "json", ".", "load", "(", "dataset_file", ")", "\n", "dataset", "=", "dataset_json", "[", "'data'", "]", "\n", "", "logger", ".", "info", "(", "\"Reading the dataset\"", ")", "\n", "for", "article", "in", "dataset", ":", "\n", "            ", "for", "paragraph_json", "in", "article", "[", "'paragraphs'", "]", ":", "\n", "                ", "paragraph", "=", "paragraph_json", "[", "\"context\"", "]", "+", "' '", "+", "no_answer_token", "\n", "tokenized_paragraph", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "paragraph", ")", "# + ['<no_answer_token>']", "\n", "\n", "for", "question_answer", "in", "paragraph_json", "[", "'qas'", "]", ":", "\n", "                    ", "question_text", "=", "question_answer", "[", "\"question\"", "]", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "answers", "=", "[", "{", "'text'", ":", "no_answer_token", ",", "'answer_start'", ":", "len", "(", "paragraph", ")", "-", "len", "(", "no_answer_token", ")", "}", "]", "if", "len", "(", "question_answer", "[", "'answers'", "]", ")", "==", "0", "else", "question_answer", "[", "'answers'", "]", "\n", "answer_texts", "=", "[", "answer", "[", "'text'", "]", "for", "answer", "in", "answers", "]", "\n", "span_starts", "=", "[", "answer", "[", "'answer_start'", "]", "for", "answer", "in", "answers", "]", "\n", "span_ends", "=", "[", "start", "+", "len", "(", "answer", ")", "for", "start", ",", "answer", "in", "zip", "(", "span_starts", ",", "answer_texts", ")", "]", "\n", "# print(answer_texts, span_starts, span_ends)", "\n", "instance", "=", "self", ".", "text_to_instance", "(", "question_text", ",", "\n", "paragraph", ",", "\n", "question_answer", "[", "'id'", "]", ",", "\n", "zip", "(", "span_starts", ",", "span_ends", ")", ",", "\n", "answer_texts", ",", "\n", "tokenized_paragraph", ")", "\n", "yield", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_reader.NoAnswerSquad2Reader.text_to_instance": [[172, 210], ["squad2_reader.make_reading_comprehension_instance", "squad2_reader.NoAnswerSquad2Reader._tokenizer.tokenize", "allennlp.data.dataset_readers.reading_comprehension.util.char_span_to_token_span", "token_spans.append", "squad2_reader.NoAnswerSquad2Reader._tokenizer.tokenize", "logger.debug", "logger.debug", "logger.debug", "logger.debug", "logger.debug", "logger.debug", "logger.debug", "len"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_reader.make_reading_comprehension_instance"], ["", "", "", "", "@", "overrides", "\n", "def", "text_to_instance", "(", "self", ",", "# type: ignore", "\n", "question_text", ":", "str", ",", "\n", "passage_text", ":", "str", ",", "\n", "question_id", ":", "str", ",", "\n", "char_spans", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", "answer_texts", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "passage_tokens", ":", "List", "[", "Token", "]", "=", "None", ")", "->", "Instance", ":", "\n", "# pylint: disable=arguments-differ", "\n", "        ", "if", "not", "passage_tokens", ":", "\n", "            ", "passage_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "passage_text", ")", "\n", "", "char_spans", "=", "char_spans", "or", "[", "]", "\n", "\n", "# We need to convert character indices in `passage_text` to token indices in", "\n", "# `passage_tokens`, as the latter is what we'll actually use for supervision.", "\n", "token_spans", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "[", "]", "\n", "passage_offsets", "=", "[", "(", "token", ".", "idx", ",", "token", ".", "idx", "+", "len", "(", "token", ".", "text", ")", ")", "for", "token", "in", "passage_tokens", "]", "\n", "for", "char_span_start", ",", "char_span_end", "in", "char_spans", ":", "\n", "            ", "(", "span_start", ",", "span_end", ")", ",", "error", "=", "util", ".", "char_span_to_token_span", "(", "passage_offsets", ",", "\n", "(", "char_span_start", ",", "char_span_end", ")", ")", "\n", "if", "error", ":", "\n", "                ", "logger", ".", "debug", "(", "\"Passage: %s\"", ",", "passage_text", ")", "\n", "logger", ".", "debug", "(", "\"Passage tokens: %s\"", ",", "passage_tokens", ")", "\n", "logger", ".", "debug", "(", "\"Question text: %s\"", ",", "question_text", ")", "\n", "logger", ".", "debug", "(", "\"Answer span: (%d, %d)\"", ",", "char_span_start", ",", "char_span_end", ")", "\n", "logger", ".", "debug", "(", "\"Token span: (%d, %d)\"", ",", "span_start", ",", "span_end", ")", "\n", "logger", ".", "debug", "(", "\"Tokens in answer: %s\"", ",", "passage_tokens", "[", "span_start", ":", "span_end", "+", "1", "]", ")", "\n", "logger", ".", "debug", "(", "\"Answer: %s\"", ",", "passage_text", "[", "char_span_start", ":", "char_span_end", "]", ")", "\n", "", "token_spans", ".", "append", "(", "(", "span_start", ",", "span_end", ")", ")", "\n", "\n", "", "return", "make_reading_comprehension_instance", "(", "\n", "self", ".", "_tokenizer", ".", "tokenize", "(", "question_text", ")", ",", "\n", "passage_tokens", ",", "\n", "self", ".", "_token_indexers", ",", "\n", "passage_text", ",", "\n", "question_id", ",", "\n", "token_spans", ",", "\n", "answer_texts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_reader.make_reading_comprehension_instance": [[19, 106], ["allennlp.data.fields.TextField", "allennlp.data.fields.TextField", "metadata.update", "allennlp.data.fields.MetadataField", "allennlp.data.instance.Instance", "collections.Counter", "list", "allennlp.data.fields.ListField", "allennlp.data.fields.ListField", "len", "set", "len", "allennlp.data.fields.SpanField", "allennlp.data.fields.SpanField", "len", "len"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.train.EvaluationStatistics.update"], ["def", "make_reading_comprehension_instance", "(", "question_tokens", ":", "List", "[", "Token", "]", ",", "\n", "passage_tokens", ":", "List", "[", "Token", "]", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", ",", "\n", "passage_text", ":", "str", ",", "\n", "question_id", ":", "str", ",", "\n", "token_spans", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", "answer_texts", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "additional_metadata", ":", "Dict", "[", "str", ",", "Any", "]", "=", "None", ")", "->", "Instance", ":", "\n", "    ", "\"\"\"\n    Converts a question, a passage, and an optional answer (or answers) to an ``Instance`` for use\n    in a reading comprehension model.\n\n    Creates an ``Instance`` with at least these fields: ``question`` and ``passage``, both\n    ``TextFields``; and ``metadata``, a ``MetadataField``.  Additionally, if both ``answer_texts``\n    and ``char_span_starts`` are given, the ``Instance`` has ``span_start`` and ``span_end``\n    fields, which are both ``IndexFields``.\n\n    Parameters\n    ----------\n    question_tokens : ``List[Token]``\n        An already-tokenized question.\n    passage_tokens : ``List[Token]``\n        An already-tokenized passage that contains the answer to the given question.\n    token_indexers : ``Dict[str, TokenIndexer]``\n        Determines how the question and passage ``TextFields`` will be converted into tensors that\n        get input to a model.  See :class:`TokenIndexer`.\n    passage_text : ``str``\n        The original passage text.  We need this so that we can recover the actual span from the\n        original passage that the model predicts as the answer to the question.  This is used in\n        official evaluation scripts.\n    token_spans : ``List[Tuple[int, int]]``, optional\n        Indices into ``passage_tokens`` to use as the answer to the question for training.  This is\n        a list because there might be several possible correct answer spans in the passage.\n        Currently, we just select the most frequent span in this list (i.e., SQuAD has multiple\n        annotations on the dev set; this will select the span that the most annotators gave as\n        correct).\n    answer_texts : ``List[str]``, optional\n        All valid answer strings for the given question.  In SQuAD, e.g., the training set has\n        exactly one answer per question, but the dev and test sets have several.  TriviaQA has many\n        possible answers, which are the aliases for the known correct entity.  This is put into the\n        metadata for use with official evaluation scripts, but not used anywhere else.\n    additional_metadata : ``Dict[str, Any]``, optional\n        The constructed ``metadata`` field will by default contain ``original_passage``,\n        ``token_offsets``, ``question_tokens``, ``passage_tokens``, and ``answer_texts`` keys.  If\n        you want any other metadata to be associated with each instance, you can pass that in here.\n        This dictionary will get added to the ``metadata`` dictionary we already construct.\n    \"\"\"", "\n", "additional_metadata", "=", "additional_metadata", "or", "{", "}", "\n", "fields", ":", "Dict", "[", "str", ",", "Field", "]", "=", "{", "}", "\n", "passage_offsets", "=", "[", "(", "token", ".", "idx", ",", "token", ".", "idx", "+", "len", "(", "token", ".", "text", ")", ")", "for", "token", "in", "passage_tokens", "]", "\n", "\n", "# This is separate so we can reference it later with a known type.", "\n", "passage_field", "=", "TextField", "(", "passage_tokens", ",", "token_indexers", ")", "\n", "fields", "[", "'passage'", "]", "=", "passage_field", "\n", "fields", "[", "'question'", "]", "=", "TextField", "(", "question_tokens", ",", "token_indexers", ")", "\n", "metadata", "=", "{", "\n", "'original_passage'", ":", "passage_text", ",", "\n", "'token_offsets'", ":", "passage_offsets", ",", "\n", "'question_id'", ":", "question_id", ",", "\n", "'question_tokens'", ":", "[", "token", ".", "text", "for", "token", "in", "question_tokens", "]", ",", "\n", "'passage_tokens'", ":", "[", "token", ".", "text", "for", "token", "in", "passage_tokens", "]", ",", "\n", "}", "\n", "if", "answer_texts", "is", "None", "or", "len", "(", "answer_texts", ")", ">", "0", ":", "\n", "        ", "metadata", "[", "'answer_texts'", "]", "=", "answer_texts", "\n", "", "else", ":", "\n", "        ", "metadata", "[", "'answer_texts'", "]", "=", "[", "''", "]", "\n", "\n", "\n", "", "if", "token_spans", ":", "\n", "# There may be multiple answer annotations, so we pick the one that occurs the most.  This", "\n", "# only matters on the SQuAD dev set, and it means our computed metrics (\"start_acc\",", "\n", "# \"end_acc\", and \"span_acc\") aren't quite the same as the official metrics, which look at", "\n", "# all of the annotations.  This is why we have a separate official SQuAD metric calculation", "\n", "# (the \"em\" and \"f1\" metrics use the official script).", "\n", "        ", "candidate_answers", ":", "Counter", "=", "Counter", "(", ")", "\n", "token_spans", "=", "list", "(", "set", "(", "token_spans", ")", ")", "\n", "span_fields", "=", "[", "]", "\n", "# print(answer_texts, passage_tokens[token_spans[0][0]: token_spans[0][1] + 1])", "\n", "span_fields", "=", "ListField", "(", "[", "SpanField", "(", "start", ",", "end", ",", "passage_field", ")", "\n", "for", "start", ",", "end", "in", "token_spans", "]", ")", "\n", "", "else", ":", "\n", "        ", "span_fields", "=", "ListField", "(", "[", "SpanField", "(", "len", "(", "passage_tokens", ")", "-", "1", ",", "len", "(", "passage_tokens", ")", "-", "1", ",", "passage_field", ")", "]", ")", "\n", "\n", "", "fields", "[", "'spans'", "]", "=", "span_fields", "\n", "metadata", ".", "update", "(", "additional_metadata", ")", "\n", "fields", "[", "'metadata'", "]", "=", "MetadataField", "(", "metadata", ")", "\n", "return", "Instance", "(", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.__init__": [[53, 103], ["allennlp.models.model.Model.__init__", "phrase_layer.get_output_dim", "endtasks.util.get_pair2vec", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "allennlp.modules.matrix_attention.linear_matrix_attention.LinearMatrixAttention", "allennlp.modules.TimeDistributed", "allennlp.modules.matrix_attention.linear_matrix_attention.LinearMatrixAttention", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "allennlp.training.metrics.SquadEmAndF1", "initializer", "allennlp.training.metrics.CategoricalAccuracy", "allennlp.training.metrics.CategoricalAccuracy", "allennlp.training.metrics.Average", "allennlp.training.metrics.Average", "allennlp.training.metrics.BooleanAccuracy", "endtasks.modules.VariationalDropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.__init__", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_pair2vec"], ["def", "__init__", "(", "self", ",", "vocab", ":", "Vocabulary", ",", "\n", "text_field_embedder", ":", "TextFieldEmbedder", ",", "\n", "phrase_layer", ":", "Seq2SeqEncoder", ",", "\n", "residual_encoder", ":", "Seq2SeqEncoder", ",", "\n", "span_start_encoder", ":", "Seq2SeqEncoder", ",", "\n", "span_end_encoder", ":", "Seq2SeqEncoder", ",", "\n", "initializer", ":", "InitializerApplicator", ",", "\n", "dropout", ":", "float", "=", "0.2", ",", "\n", "pair2vec_dropout", ":", "float", "=", "0.15", ",", "\n", "max_span_length", ":", "int", "=", "30", ",", "\n", "pair2vec_model_file", ":", "str", "=", "None", ",", "\n", "pair2vec_config_file", ":", "str", "=", "None", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "_max_span_length", "=", "max_span_length", "\n", "self", ".", "_text_field_embedder", "=", "text_field_embedder", "\n", "self", ".", "_phrase_layer", "=", "phrase_layer", "\n", "self", ".", "_encoding_dim", "=", "phrase_layer", ".", "get_output_dim", "(", ")", "\n", "\n", "self", ".", "pair2vec", "=", "pair2vec_util", ".", "get_pair2vec", "(", "pair2vec_config_file", ",", "pair2vec_model_file", ")", "\n", "self", ".", "_pair2vec_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "pair2vec_dropout", ")", "\n", "\n", "self", ".", "_matrix_attention", "=", "LinearMatrixAttention", "(", "self", ".", "_encoding_dim", ",", "self", ".", "_encoding_dim", ",", "'x,y,x*y'", ")", "\n", "\n", "# atten_dim = self._encoding_dim * 4 + 600 if ablation_type == 'attn_over_rels' else self._encoding_dim * 4", "\n", "atten_dim", "=", "self", ".", "_encoding_dim", "*", "4", "+", "600", "\n", "self", ".", "_merge_atten", "=", "TimeDistributed", "(", "torch", ".", "nn", ".", "Linear", "(", "atten_dim", ",", "self", ".", "_encoding_dim", ")", ")", "\n", "\n", "self", ".", "_residual_encoder", "=", "residual_encoder", "\n", "\n", "self", ".", "_self_attention", "=", "LinearMatrixAttention", "(", "self", ".", "_encoding_dim", ",", "self", ".", "_encoding_dim", ",", "'x,y,x*y'", ")", "\n", "\n", "self", ".", "_merge_self_attention", "=", "TimeDistributed", "(", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "_encoding_dim", "*", "3", ",", "\n", "self", ".", "_encoding_dim", ")", ")", "\n", "\n", "self", ".", "_span_start_encoder", "=", "span_start_encoder", "\n", "self", ".", "_span_end_encoder", "=", "span_end_encoder", "\n", "\n", "self", ".", "_span_start_predictor", "=", "TimeDistributed", "(", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "_encoding_dim", ",", "1", ")", ")", "\n", "self", ".", "_span_end_predictor", "=", "TimeDistributed", "(", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "_encoding_dim", ",", "1", ")", ")", "\n", "self", ".", "_squad_metrics", "=", "SquadEmAndF1", "(", ")", "\n", "initializer", "(", "self", ")", "\n", "\n", "self", ".", "_span_start_accuracy", "=", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "_span_end_accuracy", "=", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "_official_em", "=", "Average", "(", ")", "\n", "self", ".", "_official_f1", "=", "Average", "(", ")", "\n", "\n", "self", ".", "_span_accuracy", "=", "BooleanAccuracy", "(", ")", "\n", "self", ".", "_variational_dropout", "=", "InputVariationalDropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.forward": [[107, 304], ["bidaf_pair2vec.BidafPair2Vec._variational_dropout", "bidaf_pair2vec.BidafPair2Vec._variational_dropout", "bidaf_pair2vec.BidafPair2Vec.size", "bidaf_pair2vec.BidafPair2Vec.size", "endtasks.util.get_mask().float", "endtasks.util.get_mask().float", "bidaf_pair2vec.BidafPair2Vec._variational_dropout", "bidaf_pair2vec.BidafPair2Vec._variational_dropout", "bidaf_pair2vec.BidafPair2Vec.size", "bidaf_pair2vec.BidafPair2Vec.size", "bidaf_pair2vec.BidafPair2Vec._matrix_attention", "allennlp.nn.util.masked_softmax", "allennlp.nn.util.weighted_sum", "allennlp.nn.util.replace_masked_values", "[].squeeze", "allennlp.nn.util.masked_softmax", "endtasks.util.get_pair2vec_word_embeddings", "endtasks.util.get_pair2vec_word_embeddings", "allennlp.nn.util.last_dim_softmax", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "bidaf_pair2vec.BidafPair2Vec._pair2vec_dropout", "bidaf_pair2vec.BidafPair2Vec._pair2vec_dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "allennlp.nn.util.weighted_sum", "allennlp.nn.util.weighted_sum.unsqueeze().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "bidaf_pair2vec.BidafPair2Vec._variational_dropout", "bidaf_pair2vec.BidafPair2Vec._self_attention", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "bidaf_pair2vec.BidafPair2Vec.resize", "allennlp.nn.util.masked_softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "bidaf_pair2vec.BidafPair2Vec._variational_dropout", "bidaf_pair2vec.BidafPair2Vec._span_start_encoder", "bidaf_pair2vec.BidafPair2Vec._span_start_predictor().squeeze", "bidaf_pair2vec.BidafPair2Vec._span_end_encoder", "bidaf_pair2vec.BidafPair2Vec._span_end_predictor().squeeze", "allennlp.nn.util.replace_masked_values", "allennlp.nn.util.replace_masked_values", "bidaf_pair2vec.BidafPair2Vec._get_best_span", "bidaf_pair2vec.BidafPair2Vec.detach().cpu().numpy", "range", "bidaf_pair2vec.BidafPair2Vec._text_field_embedder", "bidaf_pair2vec.BidafPair2Vec._text_field_embedder", "bidaf_pair2vec.BidafPair2Vec._phrase_layer", "bidaf_pair2vec.BidafPair2Vec._phrase_layer", "endtasks.util.get_mask().float.unsqueeze", "endtasks.util.get_pair_embeddings", "endtasks.util.get_pair_embeddings", "allennlp.nn.util.weighted_sum", "allennlp.nn.util.weighted_sum", "pair2vec_passage_mask.float().unsqueeze", "pair2vec_passage_mask.float().unsqueeze", "bidaf_pair2vec.BidafPair2Vec._merge_atten", "bidaf_pair2vec.BidafPair2Vec._residual_encoder", "endtasks.util.get_mask().float.resize", "endtasks.util.get_mask().float.resize", "bidaf_pair2vec.BidafPair2Vec._merge_self_attention", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.functional.nll_loss", "torch.nn.functional.nll_loss", "torch.nn.functional.nll_loss", "torch.nn.functional.nll_loss", "tuple", "output_dict[].append", "output_dict[].append", "metadata[].get", "bidaf_pair2vec.BidafPair2Vec._official_em", "bidaf_pair2vec.BidafPair2Vec._official_f1", "endtasks.util.get_mask", "endtasks.util.get_mask", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.nn.functional.normalize.transpose", "torch.nn.functional.normalize.transpose", "allennlp.nn.util.weighted_sum.unsqueeze", "bidaf_pair2vec.BidafPair2Vec._span_start_predictor", "bidaf_pair2vec.BidafPair2Vec._span_end_predictor", "allennlp.nn.util.masked_log_softmax", "span_start.view", "allennlp.nn.util.masked_log_softmax", "span_end.view", "bidaf_pair2vec.BidafPair2Vec.detach().cpu", "best_span[].cpu().numpy", "endtasks.squad2_eval.metric_max_over_ground_truths", "endtasks.squad2_eval.metric_max_over_ground_truths", "allennlp.nn.util.replace_masked_values.max", "pair2vec_passage_mask.float", "pair2vec_passage_mask.float", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "bidaf_pair2vec.BidafPair2Vec.detach", "best_span[].cpu"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.masked_softmax", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.masked_softmax", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_pair2vec_word_embeddings", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_pair2vec_word_embeddings", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.masked_softmax", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec._get_best_span", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_pair_embeddings", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_pair_embeddings", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_mask", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_mask", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.metric_max_over_ground_truths"], ["", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "question", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "passage", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "spans", ":", "torch", ".", "IntTensor", "=", "None", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "# pylint: disable=arguments-differ", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        question : Dict[str, torch.LongTensor]\n            From a ``TextField``.\n        passage : Dict[str, torch.LongTensor]\n            From a ``TextField``.  The model assumes that this passage contains the answer to the\n            question, and predicts the beginning and ending positions of the answer within the\n            passage.\n        span_start : ``torch.IntTensor``, optional\n            From an ``IndexField``.  This is one of the things we are trying to predict - the\n            beginning position of the answer with the passage.  This is an `inclusive` token index.\n            If this is given, we will compute a loss that gets included in the output dictionary.\n        span_end : ``torch.IntTensor``, optional\n            From an ``IndexField``.  This is one of the things we are trying to predict - the\n            ending position of the answer with the passage.  This is an `inclusive` token index.\n            If this is given, we will compute a loss that gets included in the output dictionary.\n        metadata : ``List[Dict[str, Any]]``, optional\n            If present, this should contain the question ID, original passage text, and token\n            offsets into the passage for each instance in the batch.  We use this for computing\n            official metrics using the official SQuAD evaluation script.  The length of this list\n            should be the batch size, and each dictionary should have the keys ``id``,\n            ``original_passage``, and ``token_offsets``.  If you only want the best span string and\n            don't care about official metrics, you can omit the ``id`` key.\n\n        Returns\n        -------\n        An output dictionary consisting of the followings.\n        Each of the followings is a nested list because first iterates over dialog, then questions in dialog.\n\n        qid : List[List[str]]\n            A list of list, consisting of question ids.\n        best_span_str : List[List[str]]\n            If sufficient metadata was provided for the instances in the batch, we also return the\n            string from the original passage that the model thinks is the best answer to the\n            question.\n        loss : torch.FloatTensor, optional\n            A scalar loss to be optimised.\n        \"\"\"", "\n", "span_start", "=", "None", "if", "spans", "is", "None", "else", "spans", "[", ":", ",", "0", ",", "0", "]", "\n", "span_end", "=", "None", "if", "spans", "is", "None", "else", "spans", "[", ":", ",", "0", ",", "1", "]", "\n", "pair2vec_question_tokens", "=", "question", "[", "'pair2vec_tokens'", "]", "\n", "pair2vec_passage_tokens", "=", "passage", "[", "'pair2vec_tokens'", "]", "\n", "del", "question", "[", "'pair2vec_tokens'", "]", "\n", "del", "passage", "[", "'pair2vec_tokens'", "]", "\n", "embedded_question", "=", "self", ".", "_variational_dropout", "(", "self", ".", "_text_field_embedder", "(", "question", ")", ")", "\n", "embedded_passage", "=", "self", ".", "_variational_dropout", "(", "self", ".", "_text_field_embedder", "(", "passage", ")", ")", "\n", "\n", "# Extended batch size takes into account batch size * num paragraphs", "\n", "extended_batch_size", "=", "embedded_question", ".", "size", "(", "0", ")", "\n", "passage_length", "=", "embedded_passage", ".", "size", "(", "1", ")", "\n", "#question_mask = util.get_text_field_mask(question).float()", "\n", "#passage_mask = util.get_text_field_mask(passage).float()", "\n", "question_mask", "=", "pair2vec_util", ".", "get_mask", "(", "question", ",", "'elmo'", ")", ".", "float", "(", ")", "\n", "passage_mask", "=", "pair2vec_util", ".", "get_mask", "(", "passage", ",", "'elmo'", ")", ".", "float", "(", ")", "\n", "\n", "# Phrase layer is the shared Bi-GRU in the paper", "\n", "# (extended_batch_size, sequence_length, input_dim) -> (extended_batch_size, sequence_length, encoding_dim)", "\n", "encoded_question", "=", "self", ".", "_variational_dropout", "(", "self", ".", "_phrase_layer", "(", "embedded_question", ",", "question_mask", ")", ")", "\n", "encoded_passage", "=", "self", ".", "_variational_dropout", "(", "self", ".", "_phrase_layer", "(", "embedded_passage", ",", "passage_mask", ")", ")", "\n", "batch_size", ",", "num_tokens", ",", "_", "=", "encoded_passage", ".", "size", "(", ")", "\n", "encoding_dim", "=", "encoded_question", ".", "size", "(", "-", "1", ")", "\n", "\n", "# Shape: (batch_size * max_qa_count, passage_length, question_length)", "\n", "passage_question_similarity", "=", "self", ".", "_matrix_attention", "(", "encoded_passage", ",", "encoded_question", ")", "\n", "# Shape: (batch_size * max_qa_count, passage_length, question_length)", "\n", "passage_question_attention", "=", "util", ".", "masked_softmax", "(", "passage_question_similarity", ",", "question_mask", ")", "\n", "# Shape: (batch_size * max_qa_count, passage_length, encoding_dim)", "\n", "passage_question_vectors", "=", "util", ".", "weighted_sum", "(", "encoded_question", ",", "passage_question_attention", ")", "\n", "\n", "# We replace masked values with something really negative here, so they don't affect the", "\n", "# max below.", "\n", "masked_similarity", "=", "util", ".", "replace_masked_values", "(", "passage_question_similarity", ",", "\n", "question_mask", ".", "unsqueeze", "(", "1", ")", ",", "\n", "-", "1e7", ")", "\n", "\n", "question_passage_similarity", "=", "masked_similarity", ".", "max", "(", "dim", "=", "-", "1", ")", "[", "0", "]", ".", "squeeze", "(", "-", "1", ")", "\n", "question_passage_attention", "=", "util", ".", "masked_softmax", "(", "question_passage_similarity", ",", "\n", "passage_mask", ")", "\n", "passage_as_args", "=", "pair2vec_util", ".", "get_pair2vec_word_embeddings", "(", "self", ".", "pair2vec", ",", "pair2vec_passage_tokens", ")", "\n", "question_as_args", "=", "pair2vec_util", ".", "get_pair2vec_word_embeddings", "(", "self", ".", "pair2vec", ",", "pair2vec_question_tokens", ")", "\n", "# get mask for padding and unknowns", "\n", "pair2vec_passage_mask", "=", "1", "-", "(", "torch", ".", "eq", "(", "pair2vec_passage_tokens", ",", "0", ")", ".", "long", "(", ")", "+", "torch", ".", "eq", "(", "pair2vec_passage_tokens", ",", "1", ")", ".", "long", "(", ")", ")", "\n", "pair2vec_question_mask", "=", "1", "-", "(", "torch", ".", "eq", "(", "pair2vec_question_tokens", ",", "0", ")", ".", "long", "(", ")", "+", "torch", ".", "eq", "(", "pair2vec_question_tokens", ",", "1", ")", ".", "long", "(", ")", ")", "\n", "# normalize with masked softmask", "\n", "pair2vec_attention", "=", "util", ".", "last_dim_softmax", "(", "passage_question_similarity", ",", "pair2vec_question_mask", ")", "\n", "# get relation embedding", "\n", "p2q_pairs", "=", "normalize", "(", "pair2vec_util", ".", "get_pair_embeddings", "(", "self", ".", "pair2vec", ",", "passage_as_args", ",", "question_as_args", ")", ",", "dim", "=", "-", "1", ")", "\n", "q2p_pairs", "=", "normalize", "(", "pair2vec_util", ".", "get_pair_embeddings", "(", "self", ".", "pair2vec", ",", "question_as_args", ",", "passage_as_args", ")", ",", "dim", "=", "-", "1", ")", "\n", "# attention over pair2vec", "\n", "attended_question_relations", "=", "self", ".", "_pair2vec_dropout", "(", "util", ".", "weighted_sum", "(", "p2q_pairs", ",", "pair2vec_attention", ")", ")", "\n", "attended_passage_relations", "=", "self", ".", "_pair2vec_dropout", "(", "util", ".", "weighted_sum", "(", "q2p_pairs", ".", "transpose", "(", "1", ",", "2", ")", ",", "pair2vec_attention", ")", ")", "\n", "# mask out stuff", "\n", "attended_question_pairs", "=", "attended_question_relations", "*", "pair2vec_passage_mask", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "attended_passage_pairs", "=", "attended_passage_relations", "*", "pair2vec_passage_mask", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "attended_pairs", "=", "torch", ".", "cat", "(", "(", "attended_question_pairs", ",", "attended_passage_pairs", ")", ",", "dim", "=", "-", "1", ")", "\n", "# Shape: (batch_size * max_qa_count, encoding_dim)", "\n", "question_passage_vector", "=", "util", ".", "weighted_sum", "(", "encoded_passage", ",", "question_passage_attention", ")", "\n", "tiled_question_passage_vector", "=", "question_passage_vector", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "extended_batch_size", ",", "\n", "passage_length", ",", "\n", "encoding_dim", ")", "\n", "\n", "\n", "# Shape: (batch_size * max_qa_count, passage_length, encoding_dim * 4)", "\n", "final_merged_passage", "=", "torch", ".", "cat", "(", "[", "encoded_passage", ",", "\n", "passage_question_vectors", ",", "\n", "encoded_passage", "*", "passage_question_vectors", ",", "\n", "encoded_passage", "*", "tiled_question_passage_vector", ",", "\n", "attended_pairs", "]", ",", "\n", "dim", "=", "-", "1", ")", "\n", "\n", "final_merged_passage", "=", "F", ".", "relu", "(", "self", ".", "_merge_atten", "(", "final_merged_passage", ")", ")", "\n", "\n", "residual_layer", "=", "self", ".", "_variational_dropout", "(", "self", ".", "_residual_encoder", "(", "final_merged_passage", ",", "\n", "passage_mask", ")", ")", "\n", "self_attention_matrix", "=", "self", ".", "_self_attention", "(", "residual_layer", ",", "residual_layer", ")", "\n", "# Expand mask for self-attention", "\n", "mask", "=", "(", "passage_mask", ".", "resize", "(", "extended_batch_size", ",", "passage_length", ",", "1", ")", "*", "\n", "passage_mask", ".", "resize", "(", "extended_batch_size", ",", "1", ",", "passage_length", ")", ")", "\n", "\n", "self_mask", "=", "torch", ".", "eye", "(", "passage_length", ",", "passage_length", ",", "device", "=", "self_attention_matrix", ".", "device", ")", "\n", "self_mask", "=", "self_mask", ".", "resize", "(", "1", ",", "passage_length", ",", "passage_length", ")", "\n", "mask", "=", "mask", "*", "(", "1", "-", "self_mask", ")", "\n", "\n", "self_attention_probs", "=", "util", ".", "masked_softmax", "(", "self_attention_matrix", ",", "mask", ")", "\n", "\n", "# (batch, passage_len, passage_len) * (batch, passage_len, dim) -> (batch, passage_len, dim)", "\n", "self_attention_vecs", "=", "torch", ".", "matmul", "(", "self_attention_probs", ",", "residual_layer", ")", "\n", "self_attention_vecs", "=", "torch", ".", "cat", "(", "[", "self_attention_vecs", ",", "residual_layer", ",", "\n", "residual_layer", "*", "self_attention_vecs", "]", ",", "\n", "dim", "=", "-", "1", ")", "\n", "residual_layer", "=", "F", ".", "relu", "(", "self", ".", "_merge_self_attention", "(", "self_attention_vecs", ")", ")", "\n", "\n", "final_merged_passage", "=", "final_merged_passage", "+", "residual_layer", "\n", "# batch_size * maxqa_pair_len * max_passage_len * 200", "\n", "final_merged_passage", "=", "self", ".", "_variational_dropout", "(", "final_merged_passage", ")", "\n", "start_rep", "=", "self", ".", "_span_start_encoder", "(", "final_merged_passage", ",", "passage_mask", ")", "\n", "span_start_logits", "=", "self", ".", "_span_start_predictor", "(", "start_rep", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "end_rep", "=", "self", ".", "_span_end_encoder", "(", "torch", ".", "cat", "(", "[", "final_merged_passage", ",", "start_rep", "]", ",", "dim", "=", "-", "1", ")", ",", "\n", "passage_mask", ")", "\n", "span_end_logits", "=", "self", ".", "_span_end_predictor", "(", "end_rep", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "span_start_logits", "=", "util", ".", "replace_masked_values", "(", "span_start_logits", ",", "passage_mask", ",", "-", "1e7", ")", "\n", "# batch_size * maxqa_len_pair, max_document_len", "\n", "span_end_logits", "=", "util", ".", "replace_masked_values", "(", "span_end_logits", ",", "passage_mask", ",", "-", "1e7", ")", "\n", "\n", "best_span", "=", "self", ".", "_get_best_span", "(", "span_start_logits", ",", "span_end_logits", ",", "self", ".", "_max_span_length", ")", "\n", "\n", "output_dict", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "\n", "# Compute the loss.", "\n", "if", "span_start", "is", "not", "None", ":", "\n", "            ", "loss", "=", "nll_loss", "(", "util", ".", "masked_log_softmax", "(", "span_start_logits", ",", "passage_mask", ")", ",", "span_start", ".", "view", "(", "-", "1", ")", ",", "\n", "ignore_index", "=", "-", "1", ")", "\n", "loss", "+=", "nll_loss", "(", "util", ".", "masked_log_softmax", "(", "span_end_logits", ",", "\n", "passage_mask", ")", ",", "span_end", ".", "view", "(", "-", "1", ")", ",", "ignore_index", "=", "-", "1", ")", "\n", "# add a select for the right span to compute loss", "\n", "output_dict", "[", "\"loss\"", "]", "=", "loss", "\n", "\n", "# Compute F1 and preparing the output dictionary.", "\n", "", "output_dict", "[", "'best_span_str'", "]", "=", "[", "]", "\n", "output_dict", "[", "'question_id'", "]", "=", "[", "]", "\n", "best_span_cpu", "=", "best_span", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "passage_str", "=", "metadata", "[", "i", "]", "[", "'original_passage'", "]", "\n", "offsets", "=", "metadata", "[", "i", "]", "[", "'token_offsets'", "]", "\n", "predicted_span", "=", "tuple", "(", "best_span", "[", "i", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "start_offset", "=", "offsets", "[", "predicted_span", "[", "0", "]", "]", "[", "0", "]", "\n", "end_offset", "=", "offsets", "[", "predicted_span", "[", "1", "]", "]", "[", "1", "]", "\n", "best_span_string", "=", "passage_str", "[", "start_offset", ":", "end_offset", "]", "\n", "# if best_span_string == 'noanswertoken':", "\n", "# best_span_string = ''", "\n", "# print(predicted_span, best_span_string)", "\n", "output_dict", "[", "'best_span_str'", "]", ".", "append", "(", "best_span_string", ")", "\n", "output_dict", "[", "'question_id'", "]", ".", "append", "(", "metadata", "[", "i", "]", "[", "'question_id'", "]", ")", "\n", "\n", "answer_texts", "=", "metadata", "[", "i", "]", ".", "get", "(", "'answer_texts'", ",", "[", "]", ")", "\n", "exact_match", "=", "f1_score", "=", "0", "\n", "if", "answer_texts", ":", "\n", "                ", "exact_match", "=", "squad2_eval", ".", "metric_max_over_ground_truths", "(", "\n", "squad2_eval", ".", "compute_exact", ",", "\n", "best_span_string", ",", "\n", "answer_texts", ")", "\n", "f1_score", "=", "squad2_eval", ".", "metric_max_over_ground_truths", "(", "\n", "squad2_eval", ".", "compute_f1", ",", "\n", "best_span_string", ",", "\n", "answer_texts", ")", "\n", "", "self", ".", "_official_em", "(", "100", "*", "exact_match", ")", "\n", "self", ".", "_official_f1", "(", "100", "*", "f1_score", ")", "\n", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.decode": [[305, 308], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "decode", "(", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec.get_metrics": [[309, 312], ["bidaf_pair2vec.BidafPair2Vec._official_em.get_metric", "bidaf_pair2vec.BidafPair2Vec._official_f1.get_metric"], "methods", ["None"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "return", "{", "'em'", ":", "self", ".", "_official_em", ".", "get_metric", "(", "reset", ")", ",", "\n", "'f1'", ":", "self", ".", "_official_f1", ".", "get_metric", "(", "reset", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.bidaf_pair2vec.BidafPair2Vec._get_best_span": [[313, 343], ["span_start_logits.data.cpu().numpy.data.cpu().numpy.size", "span_start_logits.data.cpu().numpy.data.cpu().numpy.new_zeros", "span_start_logits.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "span_end_logits.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "range", "ValueError", "range", "span_start_logits.data.cpu().numpy.data.cpu().numpy.dim", "span_end_logits.data.cpu().numpy.data.cpu().numpy.dim", "span_start_logits.data.cpu().numpy.data.cpu().numpy.data.cpu", "span_end_logits.data.cpu().numpy.data.cpu().numpy.data.cpu"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_best_span", "(", "span_start_logits", ":", "torch", ".", "Tensor", ",", "\n", "span_end_logits", ":", "torch", ".", "Tensor", ",", "\n", "max_span_length", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "# Returns the index of highest-scoring span that is not longer than 30 tokens, as well as", "\n", "# yesno prediction bit and followup prediction bit from the predicted span end token.", "\n", "        ", "if", "span_start_logits", ".", "dim", "(", ")", "!=", "2", "or", "span_end_logits", ".", "dim", "(", ")", "!=", "2", ":", "\n", "            ", "raise", "ValueError", "(", "\"Input shapes must be (batch_size, passage_length)\"", ")", "\n", "", "batch_size", ",", "passage_length", "=", "span_start_logits", ".", "size", "(", ")", "\n", "max_span_log_prob", "=", "[", "-", "1e20", "]", "*", "batch_size", "\n", "span_start_argmax", "=", "[", "0", "]", "*", "batch_size", "\n", "\n", "best_word_span", "=", "span_start_logits", ".", "new_zeros", "(", "(", "batch_size", ",", "2", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "span_start_logits", "=", "span_start_logits", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "span_end_logits", "=", "span_end_logits", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "b_i", "in", "range", "(", "batch_size", ")", ":", "# pylint: disable=invalid-name", "\n", "            ", "for", "j", "in", "range", "(", "passage_length", ")", ":", "\n", "                ", "val1", "=", "span_start_logits", "[", "b_i", ",", "span_start_argmax", "[", "b_i", "]", "]", "\n", "if", "val1", "<", "span_start_logits", "[", "b_i", ",", "j", "]", ":", "\n", "                    ", "span_start_argmax", "[", "b_i", "]", "=", "j", "\n", "val1", "=", "span_start_logits", "[", "b_i", ",", "j", "]", "\n", "", "val2", "=", "span_end_logits", "[", "b_i", ",", "j", "]", "\n", "if", "val1", "+", "val2", ">", "max_span_log_prob", "[", "b_i", "]", ":", "\n", "                    ", "if", "j", "-", "span_start_argmax", "[", "b_i", "]", ">", "max_span_length", ":", "\n", "                        ", "continue", "\n", "", "best_word_span", "[", "b_i", ",", "0", "]", "=", "span_start_argmax", "[", "b_i", "]", "\n", "best_word_span", "[", "b_i", ",", "1", "]", "=", "j", "\n", "max_span_log_prob", "[", "b_i", "]", "=", "val1", "+", "val2", "\n", "", "", "", "return", "best_word_span", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_encoder_input": [[8, 16], ["embedder", "getattr", "torch.cat"], "function", ["None"], ["import", "glob", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "# From AllenNLP", "\n", "def", "masked_softmax", "(", "vector", ",", "mask", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_pair2vec": [[18, 30], ["embeddings.util.get_config", "embeddings.indexed_field.Field", "embeddings.matrix_data.create_vocab", "len", "embeddings.model.Pair2Vec", "embeddings.util.load_model", "embeddings.model.Pair2Vec.parameters"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.get_config", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.matrix_data.create_vocab", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.load_model"], ["\n", "if", "mask", "is", "None", ":", "\n", "        ", "result", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "vector", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "# To limit numerical errors from large vector elements outside the mask, we zero these out.", "\n", "        ", "result", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "vector", "*", "mask", ",", "dim", "=", "-", "1", ")", "\n", "result", "=", "result", "*", "mask", "\n", "result", "=", "result", "/", "(", "result", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "+", "1e-13", ")", "\n", "", "return", "result", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_pair_embeddings": [[32, 38], ["seq1.unsqueeze().expand().contiguous().view.unsqueeze().expand().contiguous().view", "seq2.unsqueeze().expand().contiguous().view.unsqueeze().expand().contiguous().view", "pair2vec.predict_relations().contiguous().view", "seq1.unsqueeze().expand().contiguous().view.size", "seq2.unsqueeze().expand().contiguous().view.size", "seq1.unsqueeze().expand().contiguous().view.unsqueeze().expand().contiguous", "seq2.unsqueeze().expand().contiguous().view.unsqueeze().expand().contiguous", "pair2vec.predict_relations().contiguous", "seq1.unsqueeze().expand().contiguous().view.unsqueeze().expand", "seq2.unsqueeze().expand().contiguous().view.unsqueeze().expand", "pair2vec.predict_relations", "seq1.unsqueeze().expand().contiguous().view.unsqueeze", "seq2.unsqueeze().expand().contiguous().view.unsqueeze"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.bats_analysis.predict_relations"], ["", "def", "load_model", "(", "resume_snapshot", ",", "model", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isfile", "(", "resume_snapshot", ")", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "resume_snapshot", ")", "\n", "print", "(", "\"Loaded checkpoint '{}' (epoch {} iter: {} train_loss: {}, dev_loss: {}, train_pos:{}, train_neg: {}, dev_pos: {}, dev_neg: {})\"", "\n", ".", "format", "(", "resume_snapshot", ",", "checkpoint", "[", "'epoch'", "]", ",", "checkpoint", "[", "'iterations'", "]", ",", "checkpoint", "[", "'train_loss'", "]", ",", "checkpoint", "[", "'dev_loss'", "]", ",", "checkpoint", "[", "'train_pos'", "]", ",", "checkpoint", "[", "'train_neg'", "]", ",", "checkpoint", "[", "'dev_pos'", "]", ",", "checkpoint", "[", "'dev_neg'", "]", ")", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "True", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_pair2vec_word_embeddings": [[40, 44], ["tokens.size", "pair2vec.represent_arguments().view", "pair2vec.represent_arguments", "tokens.view"], "function", ["None"], ["        ", "raise", "ValueError", "(", "\"No checkpoint found at {}\"", ".", "format", "(", "resume_snapshot", ")", ")", "\n", "\n", "", "", "def", "resume_from", "(", "resume_snapshot", ",", "model", ",", "optimizer", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isfile", "(", "resume_snapshot", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading checkpoint '{}'\"", ".", "format", "(", "resume_snapshot", ")", ")", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.util.get_mask": [[45, 52], ["text_field_tensors[].dim", "text_field_tensors[].dim", "NotImplementedError"], "function", ["None"], ["checkpoint", "=", "torch", ".", "load", "(", "resume_snapshot", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "if", "optimizer", "is", "not", "None", ":", "\n", "            ", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "", "logger", ".", "info", "(", "\"Loaded checkpoint '{}' (epoch {} iter: {} train_loss: {}, dev_loss: {}, train_pos:{}, train_neg: {}, dev_pos: {}, dev_neg: {})\"", "\n", ".", "format", "(", "resume_snapshot", ",", "checkpoint", "[", "'epoch'", "]", ",", "checkpoint", "[", "'iterations'", "]", ",", "checkpoint", "[", "'train_loss'", "]", ",", "checkpoint", "[", "'dev_loss'", "]", ",", "checkpoint", "[", "'train_pos'", "]", ",", "checkpoint", "[", "'train_neg'", "]", ",", "checkpoint", "[", "'dev_pos'", "]", ",", "checkpoint", "[", "'dev_neg'", "]", ")", ")", "\n", "return", "checkpoint", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad_predictor.Squad2Predictor.predict": [[13, 32], ["squad_predictor.Squad2Predictor.predict_json"], "methods", ["None"], ["def", "predict", "(", "self", ",", "question", ":", "str", ",", "passage", ":", "str", ",", "question_id", ":", "str", ")", "->", "JsonDict", ":", "\n", "        ", "\"\"\"\n        Make a machine comprehension prediction on the supplied input.\n        See https://rajpurkar.github.io/SQuAD-explorer/ for more information about the machine comprehension task.\n\n        Parameters\n        ----------\n        question : ``str``\n            A question about the content in the supplied paragraph.  The question must be answerable by a\n            span in the paragraph.\n        passage : ``str``\n            A paragraph of information relevant to the question.\n\n        Returns\n        -------\n        A dictionary that represents the prediction made by the system.  The answer string will be under the\n        \"best_span_str\" key.\n        \"\"\"", "\n", "return", "self", ".", "predict_json", "(", "{", "\"passage\"", ":", "passage", ",", "\"question\"", ":", "question", ",", "\"question_id\"", ":", "question_id", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad_predictor.Squad2Predictor._json_to_instance": [[33, 42], ["squad_predictor.Squad2Predictor._dataset_reader.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_reader.NoAnswerSquad2Reader.text_to_instance"], ["", "@", "overrides", "\n", "def", "_json_to_instance", "(", "self", ",", "json_dict", ":", "JsonDict", ")", "->", "Instance", ":", "\n", "        ", "\"\"\"\n        Expects JSON that looks like ``{\"question\": \"...\", \"passage\": \"...\"}``.\n        \"\"\"", "\n", "question_text", "=", "json_dict", "[", "\"question\"", "]", "\n", "passage_text", "=", "json_dict", "[", "\"passage\"", "]", "\n", "question_id", "=", "json_dict", "[", "\"question_id\"", "]", "\n", "return", "self", ".", "_dataset_reader", ".", "text_to_instance", "(", "question_text", ",", "passage_text", ",", "question_id", ")", ",", "{", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.parse_args": [[19, 36], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "len", "argparse.ArgumentParser.print_help", "sys.exit"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "'Official evaluation script for SQuAD version 2.0.'", ")", "\n", "parser", ".", "add_argument", "(", "'data_file'", ",", "metavar", "=", "'data.json'", ",", "help", "=", "'Input data JSON file.'", ")", "\n", "parser", ".", "add_argument", "(", "'pred_file'", ",", "metavar", "=", "'pred.json'", ",", "help", "=", "'Model predictions.'", ")", "\n", "parser", ".", "add_argument", "(", "'--out-file'", ",", "'-o'", ",", "metavar", "=", "'eval.json'", ",", "\n", "help", "=", "'Write accuracy metrics to file (default is stdout).'", ")", "\n", "parser", ".", "add_argument", "(", "'--na-prob-file'", ",", "'-n'", ",", "metavar", "=", "'na_prob.json'", ",", "\n", "help", "=", "'Model estimates of probability of no answer.'", ")", "\n", "parser", ".", "add_argument", "(", "'--na-prob-thresh'", ",", "'-t'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'Predict \"\" if no-answer probability exceeds this (default = 1.0).'", ")", "\n", "parser", ".", "add_argument", "(", "'--out-image-dir'", ",", "'-p'", ",", "metavar", "=", "'out_images'", ",", "default", "=", "None", ",", "\n", "help", "=", "'Save precision-recall curves to directory.'", ")", "\n", "parser", ".", "add_argument", "(", "'--verbose'", ",", "'-v'", ",", "action", "=", "'store_true'", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "1", ":", "\n", "    ", "parser", ".", "print_help", "(", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.make_qid_to_has_ans": [[37, 44], ["bool"], "function", ["None"], ["", "def", "make_qid_to_has_ans", "(", "dataset", ")", ":", "\n", "  ", "qid_to_has_ans", "=", "{", "}", "\n", "for", "article", "in", "dataset", ":", "\n", "    ", "for", "p", "in", "article", "[", "'paragraphs'", "]", ":", "\n", "      ", "for", "qa", "in", "p", "[", "'qas'", "]", ":", "\n", "        ", "qid_to_has_ans", "[", "qa", "[", "'id'", "]", "]", "=", "bool", "(", "qa", "[", "'answers'", "]", ")", "\n", "", "", "", "return", "qid_to_has_ans", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.normalize_answer": [[45, 58], ["squad2_eval.normalize_answer.white_space_fix"], "function", ["None"], ["", "def", "normalize_answer", "(", "s", ")", ":", "\n", "  ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "    ", "regex", "=", "re", ".", "compile", "(", "r'\\b(a|an|the)\\b'", ",", "re", ".", "UNICODE", ")", "\n", "return", "re", ".", "sub", "(", "regex", ",", "' '", ",", "text", ")", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "    ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "    ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "    ", "return", "text", ".", "lower", "(", ")", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.get_tokens": [[59, 62], ["normalize_answer().split", "squad2_eval.normalize_answer"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.normalize_answer"], ["", "def", "get_tokens", "(", "s", ")", ":", "\n", "  ", "if", "not", "s", ":", "return", "[", "]", "\n", "return", "normalize_answer", "(", "s", ")", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.compute_exact": [[63, 65], ["int", "squad2_eval.normalize_answer", "squad2_eval.normalize_answer"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.normalize_answer", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.normalize_answer"], ["", "def", "compute_exact", "(", "a_gold", ",", "a_pred", ")", ":", "\n", "  ", "return", "int", "(", "normalize_answer", "(", "a_gold", ")", "==", "normalize_answer", "(", "a_pred", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.compute_f1": [[66, 80], ["squad2_eval.get_tokens", "squad2_eval.get_tokens", "sum", "collections.Counter", "collections.Counter", "common.values", "int", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.get_tokens", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.get_tokens"], ["", "def", "compute_f1", "(", "a_gold", ",", "a_pred", ")", ":", "\n", "  ", "gold_toks", "=", "get_tokens", "(", "a_gold", ")", "\n", "pred_toks", "=", "get_tokens", "(", "a_pred", ")", "\n", "common", "=", "collections", ".", "Counter", "(", "gold_toks", ")", "&", "collections", ".", "Counter", "(", "pred_toks", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "len", "(", "gold_toks", ")", "==", "0", "or", "len", "(", "pred_toks", ")", "==", "0", ":", "\n", "# If either is no-answer, then F1 is 1 if they agree, 0 otherwise", "\n", "    ", "return", "int", "(", "gold_toks", "==", "pred_toks", ")", "\n", "", "if", "num_same", "==", "0", ":", "\n", "    ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "pred_toks", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "gold_toks", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.metric_max_over_ground_truths": [[81, 83], ["max", "metric_fn"], "function", ["None"], ["", "def", "metric_max_over_ground_truths", "(", "metric_fn", ",", "prediction", ",", "ground_truths", ")", ":", "\n", "  ", "return", "max", "(", "metric_fn", "(", "ground_truth", ",", "prediction", ")", "for", "ground_truth", "in", "ground_truths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.get_raw_scores": [[84, 104], ["max", "max", "print", "squad2_eval.normalize_answer", "squad2_eval.compute_exact", "squad2_eval.compute_f1"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.normalize_answer", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.compute_exact", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.compute_f1"], ["", "def", "get_raw_scores", "(", "dataset", ",", "preds", ")", ":", "\n", "  ", "exact_scores", "=", "{", "}", "\n", "f1_scores", "=", "{", "}", "\n", "for", "article", "in", "dataset", ":", "\n", "    ", "for", "p", "in", "article", "[", "'paragraphs'", "]", ":", "\n", "      ", "for", "qa", "in", "p", "[", "'qas'", "]", ":", "\n", "        ", "qid", "=", "qa", "[", "'id'", "]", "\n", "gold_answers", "=", "[", "a", "[", "'text'", "]", "for", "a", "in", "qa", "[", "'answers'", "]", "\n", "if", "normalize_answer", "(", "a", "[", "'text'", "]", ")", "]", "\n", "if", "not", "gold_answers", ":", "\n", "# For unanswerable questions, only correct answer is empty string", "\n", "          ", "gold_answers", "=", "[", "''", "]", "\n", "", "if", "qid", "not", "in", "preds", ":", "\n", "          ", "print", "(", "'Missing prediction for %s'", "%", "qid", ")", "\n", "continue", "\n", "", "a_pred", "=", "preds", "[", "qid", "]", "\n", "# Take max over all gold answers", "\n", "exact_scores", "[", "qid", "]", "=", "max", "(", "compute_exact", "(", "a", ",", "a_pred", ")", "for", "a", "in", "gold_answers", ")", "\n", "f1_scores", "[", "qid", "]", "=", "max", "(", "compute_f1", "(", "a", ",", "a_pred", ")", "for", "a", "in", "gold_answers", ")", "\n", "", "", "", "return", "exact_scores", ",", "f1_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.apply_no_ans_threshold": [[105, 114], ["scores.items", "float"], "function", ["None"], ["", "def", "apply_no_ans_threshold", "(", "scores", ",", "na_probs", ",", "qid_to_has_ans", ",", "na_prob_thresh", ")", ":", "\n", "  ", "new_scores", "=", "{", "}", "\n", "for", "qid", ",", "s", "in", "scores", ".", "items", "(", ")", ":", "\n", "    ", "pred_na", "=", "na_probs", "[", "qid", "]", ">", "na_prob_thresh", "\n", "if", "pred_na", ":", "\n", "      ", "new_scores", "[", "qid", "]", "=", "float", "(", "not", "qid_to_has_ans", "[", "qid", "]", ")", "\n", "", "else", ":", "\n", "      ", "new_scores", "[", "qid", "]", "=", "s", "\n", "", "", "return", "new_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.make_eval_dict": [[115, 129], ["len", "collections.OrderedDict", "len", "collections.OrderedDict", "sum", "sum", "sum", "sum", "exact_scores.values", "f1_scores.values"], "function", ["None"], ["", "def", "make_eval_dict", "(", "exact_scores", ",", "f1_scores", ",", "qid_list", "=", "None", ")", ":", "\n", "  ", "if", "not", "qid_list", ":", "\n", "    ", "total", "=", "len", "(", "exact_scores", ")", "\n", "return", "collections", ".", "OrderedDict", "(", "[", "\n", "(", "'exact'", ",", "100.0", "*", "sum", "(", "exact_scores", ".", "values", "(", ")", ")", "/", "total", ")", ",", "\n", "(", "'f1'", ",", "100.0", "*", "sum", "(", "f1_scores", ".", "values", "(", ")", ")", "/", "total", ")", ",", "\n", "(", "'total'", ",", "total", ")", ",", "\n", "]", ")", "\n", "", "else", ":", "\n", "    ", "total", "=", "len", "(", "qid_list", ")", "\n", "return", "collections", ".", "OrderedDict", "(", "[", "\n", "(", "'exact'", ",", "100.0", "*", "sum", "(", "exact_scores", "[", "k", "]", "for", "k", "in", "qid_list", ")", "/", "total", ")", ",", "\n", "(", "'f1'", ",", "100.0", "*", "sum", "(", "f1_scores", "[", "k", "]", "for", "k", "in", "qid_list", ")", "/", "total", ")", ",", "\n", "(", "'total'", ",", "total", ")", ",", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.merge_eval": [[131, 134], ["None"], "function", ["None"], ["", "", "def", "merge_eval", "(", "main_eval", ",", "new_eval", ",", "prefix", ")", ":", "\n", "  ", "for", "k", "in", "new_eval", ":", "\n", "    ", "main_eval", "[", "'%s_%s'", "%", "(", "prefix", ",", "k", ")", "]", "=", "new_eval", "[", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.plot_pr_curve": [[135, 145], ["plt.step", "plt.fill_between", "plt.xlabel", "plt.ylabel", "plt.xlim", "plt.ylim", "plt.title", "plt.savefig", "plt.clf"], "function", ["None"], ["", "", "def", "plot_pr_curve", "(", "precisions", ",", "recalls", ",", "out_image", ",", "title", ")", ":", "\n", "  ", "plt", ".", "step", "(", "recalls", ",", "precisions", ",", "color", "=", "'b'", ",", "alpha", "=", "0.2", ",", "where", "=", "'post'", ")", "\n", "plt", ".", "fill_between", "(", "recalls", ",", "precisions", ",", "step", "=", "'post'", ",", "alpha", "=", "0.2", ",", "color", "=", "'b'", ")", "\n", "plt", ".", "xlabel", "(", "'Recall'", ")", "\n", "plt", ".", "ylabel", "(", "'Precision'", ")", "\n", "plt", ".", "xlim", "(", "[", "0.0", ",", "1.05", "]", ")", "\n", "plt", ".", "ylim", "(", "[", "0.0", ",", "1.05", "]", ")", "\n", "plt", ".", "title", "(", "title", ")", "\n", "plt", ".", "savefig", "(", "out_image", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.make_precision_recall_eval": [[146, 168], ["sorted", "enumerate", "squad2_eval.plot_pr_curve", "float", "float", "precisions.append", "recalls.append", "len"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.plot_pr_curve"], ["", "def", "make_precision_recall_eval", "(", "scores", ",", "na_probs", ",", "num_true_pos", ",", "qid_to_has_ans", ",", "\n", "out_image", "=", "None", ",", "title", "=", "None", ")", ":", "\n", "  ", "qid_list", "=", "sorted", "(", "na_probs", ",", "key", "=", "lambda", "k", ":", "na_probs", "[", "k", "]", ")", "\n", "true_pos", "=", "0.0", "\n", "cur_p", "=", "1.0", "\n", "cur_r", "=", "0.0", "\n", "precisions", "=", "[", "1.0", "]", "\n", "recalls", "=", "[", "0.0", "]", "\n", "avg_prec", "=", "0.0", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "    ", "if", "qid_to_has_ans", "[", "qid", "]", ":", "\n", "      ", "true_pos", "+=", "scores", "[", "qid", "]", "\n", "", "cur_p", "=", "true_pos", "/", "float", "(", "i", "+", "1", ")", "\n", "cur_r", "=", "true_pos", "/", "float", "(", "num_true_pos", ")", "\n", "if", "i", "==", "len", "(", "qid_list", ")", "-", "1", "or", "na_probs", "[", "qid", "]", "!=", "na_probs", "[", "qid_list", "[", "i", "+", "1", "]", "]", ":", "\n", "# i.e., if we can put a threshold after this point", "\n", "      ", "avg_prec", "+=", "cur_p", "*", "(", "cur_r", "-", "recalls", "[", "-", "1", "]", ")", "\n", "precisions", ".", "append", "(", "cur_p", ")", "\n", "recalls", ".", "append", "(", "cur_r", ")", "\n", "", "", "if", "out_image", ":", "\n", "    ", "plot_pr_curve", "(", "precisions", ",", "recalls", ",", "out_image", ",", "title", ")", "\n", "", "return", "{", "'ap'", ":", "100.0", "*", "avg_prec", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.run_precision_recall_analysis": [[169, 192], ["sum", "squad2_eval.make_precision_recall_eval", "squad2_eval.make_precision_recall_eval", "squad2_eval.make_precision_recall_eval", "squad2_eval.merge_eval", "squad2_eval.merge_eval", "squad2_eval.merge_eval", "os.makedirs", "float", "os.path.exists", "os.path.join", "os.path.join", "qid_to_has_ans.items", "os.path.join", "qid_to_has_ans.values"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.make_precision_recall_eval", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.make_precision_recall_eval", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.make_precision_recall_eval", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.merge_eval", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.merge_eval", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.merge_eval", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.embeddings.util.makedirs"], ["", "def", "run_precision_recall_analysis", "(", "main_eval", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "\n", "qid_to_has_ans", ",", "out_image_dir", ")", ":", "\n", "  ", "if", "out_image_dir", "and", "not", "os", ".", "path", ".", "exists", "(", "out_image_dir", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "out_image_dir", ")", "\n", "", "num_true_pos", "=", "sum", "(", "1", "for", "v", "in", "qid_to_has_ans", ".", "values", "(", ")", "if", "v", ")", "\n", "if", "num_true_pos", "==", "0", ":", "\n", "    ", "return", "\n", "", "pr_exact", "=", "make_precision_recall_eval", "(", "\n", "exact_raw", ",", "na_probs", ",", "num_true_pos", ",", "qid_to_has_ans", ",", "\n", "out_image", "=", "os", ".", "path", ".", "join", "(", "out_image_dir", ",", "'pr_exact.png'", ")", ",", "\n", "title", "=", "'Precision-Recall curve for Exact Match score'", ")", "\n", "pr_f1", "=", "make_precision_recall_eval", "(", "\n", "f1_raw", ",", "na_probs", ",", "num_true_pos", ",", "qid_to_has_ans", ",", "\n", "out_image", "=", "os", ".", "path", ".", "join", "(", "out_image_dir", ",", "'pr_f1.png'", ")", ",", "\n", "title", "=", "'Precision-Recall curve for F1 score'", ")", "\n", "oracle_scores", "=", "{", "k", ":", "float", "(", "v", ")", "for", "k", ",", "v", "in", "qid_to_has_ans", ".", "items", "(", ")", "}", "\n", "pr_oracle", "=", "make_precision_recall_eval", "(", "\n", "oracle_scores", ",", "na_probs", ",", "num_true_pos", ",", "qid_to_has_ans", ",", "\n", "out_image", "=", "os", ".", "path", ".", "join", "(", "out_image_dir", ",", "'pr_oracle.png'", ")", ",", "\n", "title", "=", "'Oracle Precision-Recall curve (binary task of HasAns vs. NoAns)'", ")", "\n", "merge_eval", "(", "main_eval", ",", "pr_exact", ",", "'pr_exact'", ")", "\n", "merge_eval", "(", "main_eval", ",", "pr_f1", ",", "'pr_f1'", ")", "\n", "merge_eval", "(", "main_eval", ",", "pr_oracle", ",", "'pr_oracle'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.histogram_na_prob": [[193, 204], ["plt.hist", "plt.xlabel", "plt.ylabel", "plt.title", "plt.savefig", "plt.clf", "numpy.ones_like", "float", "os.path.join", "len"], "function", ["None"], ["", "def", "histogram_na_prob", "(", "na_probs", ",", "qid_list", ",", "image_dir", ",", "name", ")", ":", "\n", "  ", "if", "not", "qid_list", ":", "\n", "    ", "return", "\n", "", "x", "=", "[", "na_probs", "[", "k", "]", "for", "k", "in", "qid_list", "]", "\n", "weights", "=", "np", ".", "ones_like", "(", "x", ")", "/", "float", "(", "len", "(", "x", ")", ")", "\n", "plt", ".", "hist", "(", "x", ",", "weights", "=", "weights", ",", "bins", "=", "20", ",", "range", "=", "(", "0.0", ",", "1.0", ")", ")", "\n", "plt", ".", "xlabel", "(", "'Model probability of no-answer'", ")", "\n", "plt", ".", "ylabel", "(", "'Proportion of dataset'", ")", "\n", "plt", ".", "title", "(", "'Histogram of no-answer probability: %s'", "%", "name", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "image_dir", ",", "'na_prob_hist_%s.png'", "%", "name", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.find_best_thresh": [[205, 225], ["sum", "sorted", "enumerate", "len"], "function", ["None"], ["", "def", "find_best_thresh", "(", "preds", ",", "scores", ",", "na_probs", ",", "qid_to_has_ans", ")", ":", "\n", "  ", "num_no_ans", "=", "sum", "(", "1", "for", "k", "in", "qid_to_has_ans", "if", "not", "qid_to_has_ans", "[", "k", "]", ")", "\n", "cur_score", "=", "num_no_ans", "\n", "best_score", "=", "cur_score", "\n", "best_thresh", "=", "0.0", "\n", "qid_list", "=", "sorted", "(", "na_probs", ",", "key", "=", "lambda", "k", ":", "na_probs", "[", "k", "]", ")", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "    ", "if", "qid", "not", "in", "scores", ":", "continue", "\n", "if", "qid_to_has_ans", "[", "qid", "]", ":", "\n", "      ", "diff", "=", "scores", "[", "qid", "]", "\n", "", "else", ":", "\n", "      ", "if", "preds", "[", "qid", "]", ":", "\n", "        ", "diff", "=", "-", "1", "\n", "", "else", ":", "\n", "        ", "diff", "=", "0", "\n", "", "", "cur_score", "+=", "diff", "\n", "if", "cur_score", ">", "best_score", ":", "\n", "      ", "best_score", "=", "cur_score", "\n", "best_thresh", "=", "na_probs", "[", "qid", "]", "\n", "", "", "return", "100.0", "*", "best_score", "/", "len", "(", "scores", ")", ",", "best_thresh", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.find_all_best_thresh": [[226, 233], ["squad2_eval.find_best_thresh", "squad2_eval.find_best_thresh"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.find_best_thresh", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.find_best_thresh"], ["", "def", "find_all_best_thresh", "(", "main_eval", ",", "preds", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", ":", "\n", "  ", "best_exact", ",", "exact_thresh", "=", "find_best_thresh", "(", "preds", ",", "exact_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "best_f1", ",", "f1_thresh", "=", "find_best_thresh", "(", "preds", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "main_eval", "[", "'best_exact'", "]", "=", "best_exact", "\n", "main_eval", "[", "'best_exact_thresh'", "]", "=", "exact_thresh", "\n", "main_eval", "[", "'best_f1'", "]", "=", "best_f1", "\n", "main_eval", "[", "'best_f1_thresh'", "]", "=", "f1_thresh", "\n", "\n"]], "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.main": [[234, 272], ["squad2_eval.make_qid_to_has_ans", "squad2_eval.get_raw_scores", "squad2_eval.apply_no_ans_threshold", "squad2_eval.apply_no_ans_threshold", "squad2_eval.make_eval_dict", "open", "json.load", "open", "json.load", "squad2_eval.make_eval_dict", "squad2_eval.merge_eval", "squad2_eval.make_eval_dict", "squad2_eval.merge_eval", "squad2_eval.find_all_best_thresh", "squad2_eval.run_precision_recall_analysis", "squad2_eval.histogram_na_prob", "squad2_eval.histogram_na_prob", "print", "open", "json.load", "make_qid_to_has_ans.items", "make_qid_to_has_ans.items", "open", "json.dump", "json.dumps"], "function", ["home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.make_qid_to_has_ans", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.get_raw_scores", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.apply_no_ans_threshold", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.apply_no_ans_threshold", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.make_eval_dict", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.make_eval_dict", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.merge_eval", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.make_eval_dict", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.merge_eval", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.find_all_best_thresh", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.run_precision_recall_analysis", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.histogram_na_prob", "home.repos.pwc.inspect_result.mandarjoshi90_pair2vec.endtasks.squad2_eval.histogram_na_prob"], ["", "def", "main", "(", ")", ":", "\n", "  ", "with", "open", "(", "OPTS", ".", "data_file", ")", "as", "f", ":", "\n", "    ", "dataset_json", "=", "json", ".", "load", "(", "f", ")", "\n", "dataset", "=", "dataset_json", "[", "'data'", "]", "\n", "", "with", "open", "(", "OPTS", ".", "pred_file", ")", "as", "f", ":", "\n", "    ", "preds", "=", "json", ".", "load", "(", "f", ")", "\n", "", "if", "OPTS", ".", "na_prob_file", ":", "\n", "    ", "with", "open", "(", "OPTS", ".", "na_prob_file", ")", "as", "f", ":", "\n", "      ", "na_probs", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "    ", "na_probs", "=", "{", "k", ":", "0.0", "for", "k", "in", "preds", "}", "\n", "", "qid_to_has_ans", "=", "make_qid_to_has_ans", "(", "dataset", ")", "# maps qid to True/False", "\n", "has_ans_qids", "=", "[", "k", "for", "k", ",", "v", "in", "qid_to_has_ans", ".", "items", "(", ")", "if", "v", "]", "\n", "no_ans_qids", "=", "[", "k", "for", "k", ",", "v", "in", "qid_to_has_ans", ".", "items", "(", ")", "if", "not", "v", "]", "\n", "exact_raw", ",", "f1_raw", "=", "get_raw_scores", "(", "dataset", ",", "preds", ")", "\n", "exact_thresh", "=", "apply_no_ans_threshold", "(", "exact_raw", ",", "na_probs", ",", "qid_to_has_ans", ",", "\n", "OPTS", ".", "na_prob_thresh", ")", "\n", "f1_thresh", "=", "apply_no_ans_threshold", "(", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ",", "\n", "OPTS", ".", "na_prob_thresh", ")", "\n", "out_eval", "=", "make_eval_dict", "(", "exact_thresh", ",", "f1_thresh", ")", "\n", "if", "has_ans_qids", ":", "\n", "    ", "has_ans_eval", "=", "make_eval_dict", "(", "exact_thresh", ",", "f1_thresh", ",", "qid_list", "=", "has_ans_qids", ")", "\n", "merge_eval", "(", "out_eval", ",", "has_ans_eval", ",", "'HasAns'", ")", "\n", "", "if", "no_ans_qids", ":", "\n", "    ", "no_ans_eval", "=", "make_eval_dict", "(", "exact_thresh", ",", "f1_thresh", ",", "qid_list", "=", "no_ans_qids", ")", "\n", "merge_eval", "(", "out_eval", ",", "no_ans_eval", ",", "'NoAns'", ")", "\n", "", "if", "OPTS", ".", "na_prob_file", ":", "\n", "    ", "find_all_best_thresh", "(", "out_eval", ",", "preds", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "", "if", "OPTS", ".", "na_prob_file", "and", "OPTS", ".", "out_image_dir", ":", "\n", "    ", "run_precision_recall_analysis", "(", "out_eval", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "\n", "qid_to_has_ans", ",", "OPTS", ".", "out_image_dir", ")", "\n", "histogram_na_prob", "(", "na_probs", ",", "has_ans_qids", ",", "OPTS", ".", "out_image_dir", ",", "'hasAns'", ")", "\n", "histogram_na_prob", "(", "na_probs", ",", "no_ans_qids", ",", "OPTS", ".", "out_image_dir", ",", "'noAns'", ")", "\n", "", "if", "OPTS", ".", "out_file", ":", "\n", "    ", "with", "open", "(", "OPTS", ".", "out_file", ",", "'w'", ")", "as", "f", ":", "\n", "      ", "json", ".", "dump", "(", "out_eval", ",", "f", ")", "\n", "", "", "else", ":", "\n", "    ", "print", "(", "json", ".", "dumps", "(", "out_eval", ",", "indent", "=", "2", ")", ")", "\n", "\n"]]}