{"home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.build_yelp_dataset.NumpySerializer.default": [[25, 34], ["isinstance", "int", "isinstance", "float", "isinstance", "obj.tolist", "super().default"], "methods", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.build_yelp_dataset.NumpySerializer.default"], ["def", "default", "(", "self", ",", "obj", ")", ":", "\n", "    ", "if", "isinstance", "(", "obj", ",", "np", ".", "integer", ")", ":", "\n", "      ", "return", "int", "(", "obj", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "np", ".", "floating", ")", ":", "\n", "      ", "return", "float", "(", "obj", ")", "\n", "", "elif", "isinstance", "(", "obj", ",", "np", ".", "ndarray", ")", ":", "\n", "      ", "return", "obj", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "      ", "return", "super", "(", "NumpySerializer", ",", "self", ")", ".", "default", "(", "obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.build_yelp_dataset.load_users": [[36, 47], ["open", "json.loads", "int", "line.rstrip"], "function", ["None"], ["", "", "", "def", "load_users", "(", "workdir", ",", "userfn", ")", ":", "\n", "  ", "''' Load which users received at least one useful flag '''", "\n", "user_usefuls", "=", "{", "}", "\n", "with", "open", "(", "userfn", ")", "as", "inf", ":", "\n", "    ", "for", "line", "in", "inf", ":", "\n", "      ", "user", "=", "json", ".", "loads", "(", "line", ".", "rstrip", "(", ")", ")", "\n", "user_id", "=", "user", "[", "'user_id'", "]", "\n", "useful", "=", "user", "[", "'useful'", "]", "\n", "user_usefuls", "[", "user_id", "]", "=", "int", "(", "useful", ">", "1", ")", "\n", "\n", "", "", "return", "user_usefuls", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.build_yelp_dataset.get_words": [[49, 60], ["nltk.tokenize.word_tokenize", "text.lower", "stems.append", "set", "stemmer.stem"], "function", ["None"], ["", "def", "get_words", "(", "text", ",", "vocab", "=", "None", ")", ":", "\n", "  ", "''' Given words and text, return vectors '''", "\n", "words", "=", "word_tokenize", "(", "text", ".", "lower", "(", ")", ")", "\n", "words", "=", "[", "word", "for", "word", "in", "words", "if", "word", "not", "in", "stopwords", "]", "\n", "stems", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "    ", "stems", ".", "append", "(", "stemmer", ".", "stem", "(", "word", ")", ")", "\n", "", "if", "vocab", "is", "None", ":", "\n", "    ", "return", "stems", "\n", "", "else", ":", "\n", "    ", "return", "set", "(", "[", "vocab", "[", "stem", "]", "for", "stem", "in", "stems", "if", "stem", "in", "vocab", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.build_yelp_dataset.build_vocab": [[62, 98], ["time.time", "os.path.join", "os.path.join", "enumerate", "os.path.join", "os.path.exists", "os.path.exists", "logging.warn", "open", "range", "gzip.open", "outf.write", "vocab.keys", "gzip.open", "outf.write", "inf.readline", "json.loads", "build_yelp_dataset.get_words", "vocab.items", "json.dumps().encode", "json.dumps().encode", "logging.warn", "inf.readline.rstrip", "vocab.get", "json.dumps", "json.dumps", "time.time"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.build_yelp_dataset.get_words"], ["", "", "def", "build_vocab", "(", "workdir", ",", "reviewfn", ",", "n_vocab", "=", "1000000", ",", "min_freq", "=", "10", ")", ":", "\n", "  ", "'''\n  Build the vocab using n_vocab reviews and only counting words that appear at least min_freq times\n  '''", "\n", "vocab", "=", "{", "}", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "freqs_fn", "=", "os", ".", "path", ".", "join", "(", "workdir", ",", "\"freqs.{}.gz\"", ".", "format", "(", "n_vocab", ")", ")", "\n", "vocab_fn", "=", "os", ".", "path", ".", "join", "(", "workdir", ",", "\"vocab.{}.{}.gz\"", ".", "format", "(", "n_vocab", ",", "min_freq", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "freqs_fn", ")", "and", "os", ".", "path", ".", "exists", "(", "vocab_fn", ")", ":", "\n", "    ", "logging", ".", "warn", "(", "\"vocab already exists, skipping\"", ")", "\n", "return", "None", "\n", "\n", "", "with", "open", "(", "reviewfn", ",", "encoding", "=", "'utf8'", ")", "as", "inf", ":", "\n", "    ", "for", "i", "in", "range", "(", "n_vocab", ")", ":", "\n", "      ", "if", "(", "i", "+", "1", ")", "%", "10000", "==", "0", ":", "\n", "        ", "logging", ".", "warn", "(", "\"{} processed in {:.1f} seconds\"", ".", "format", "(", "i", "+", "1", ",", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "", "line", "=", "inf", ".", "readline", "(", ")", "\n", "review", "=", "json", ".", "loads", "(", "line", ".", "rstrip", "(", ")", ")", "\n", "text", "=", "review", "[", "'text'", "]", "\n", "words", "=", "get_words", "(", "text", ")", "\n", "for", "word", "in", "words", ":", "\n", "        ", "vocab", "[", "word", "]", "=", "vocab", ".", "get", "(", "word", ",", "0", ")", "+", "1", "\n", "\n", "", "", "", "vocab", "=", "{", "key", ":", "val", "for", "key", ",", "val", "in", "vocab", ".", "items", "(", ")", "if", "val", ">=", "min_freq", "}", "\n", "with", "gzip", ".", "open", "(", "freqs_fn", ",", "\"wb\"", ")", "as", "outf", ":", "\n", "    ", "outf", ".", "write", "(", "json", ".", "dumps", "(", "vocab", ",", "cls", "=", "NumpySerializer", ")", ".", "encode", "(", "'utf8'", ")", ")", "\n", "\n", "", "indices", "=", "{", "}", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "vocab", ".", "keys", "(", ")", ")", ":", "\n", "    ", "indices", "[", "key", "]", "=", "i", "\n", "", "vocab_fn", "=", "os", ".", "path", ".", "join", "(", "workdir", ",", "\"vocab.{}.{}.gz\"", ".", "format", "(", "n_vocab", ",", "min_freq", ")", ")", "\n", "with", "gzip", ".", "open", "(", "vocab_fn", ",", "\"wb\"", ")", "as", "outf", ":", "\n", "    ", "outf", ".", "write", "(", "json", ".", "dumps", "(", "indices", ",", "cls", "=", "NumpySerializer", ")", ".", "encode", "(", "'utf8'", ")", ")", "\n", "\n", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.build_yelp_dataset.load_vocab": [[100, 106], ["os.path.join", "gzip.open", "json.loads", "x.decode"], "function", ["None"], ["", "def", "load_vocab", "(", "workdir", ",", "n_vocab", ",", "min_freq", ")", ":", "\n", "  ", "''' Load an existing vocab '''", "\n", "vocab_fn", "=", "os", ".", "path", ".", "join", "(", "workdir", ",", "\"vocab.{}.{}.gz\"", ".", "format", "(", "n_vocab", ",", "min_freq", ")", ")", "\n", "with", "gzip", ".", "open", "(", "vocab_fn", ",", "\"rb\"", ")", "as", "inf", ":", "\n", "    ", "vocab", "=", "json", ".", "loads", "(", "\"\"", ".", "join", "(", "x", ".", "decode", "(", ")", "for", "x", "in", "inf", ")", ")", "\n", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.build_yelp_dataset.build_dataset": [[108, 159], ["int", "int", "time.time", "open", "inf.readline", "json.loads", "int", "int", "logging.warn", "inf.readline.rstrip", "reviews.append", "build_yelp_dataset.get_words", "reviews.append", "numpy.array", "numpy.array", "logging.warn", "os.path.join", "range", "gzip.open", "time.time", "len", "outf.write", "json.dumps"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.build_yelp_dataset.get_words"], ["", "def", "build_dataset", "(", "workdir", ",", "reviewfn", ",", "user_usefuls", ",", "total", ",", "vocab", "=", "None", ",", "outfn", "=", "None", ")", ":", "\n", "  ", "'''\n  Build a dataset using an existing vocab\n  '''", "\n", "reviews", "=", "[", "]", "\n", "\n", "total", "=", "int", "(", "total", ")", "\n", "dump_every", "=", "int", "(", "1e5", ")", "\n", "i", "=", "0", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "with", "open", "(", "reviewfn", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "inf", ":", "\n", "    ", "while", "i", "<", "total", ":", "\n", "      ", "line", "=", "inf", ".", "readline", "(", ")", "\n", "if", "(", "i", "+", "1", ")", "%", "dump_every", "==", "0", ":", "\n", "        ", "logging", ".", "warn", "(", "\"{} processed in {}\"", ".", "format", "(", "i", "+", "1", ",", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "", "review", "=", "json", ".", "loads", "(", "line", ".", "rstrip", "(", ")", ")", "\n", "\n", "# Treatment: review rating", "\n", "stars", "=", "review", "[", "'stars'", "]", "\n", "if", "stars", "==", "3", ":", "\n", "        ", "continue", "\n", "", "i", "+=", "1", "\n", "positive", "=", "int", "(", "stars", ">", "3", ")", "\n", "\n", "# Outcome: received useful", "\n", "received_useful", "=", "int", "(", "review", "[", "'useful'", "]", ">", "0", ")", "\n", "\n", "# Confounder: user has received usefuls", "\n", "user", "=", "review", "[", "'user_id'", "]", "\n", "user_is_useful", "=", "user_usefuls", "[", "user", "]", "\n", "\n", "if", "vocab", "is", "None", ":", "\n", "        ", "reviews", ".", "append", "(", "np", ".", "array", "(", "(", "user_is_useful", ",", "positive", ",", "received_useful", ")", ")", ")", "\n", "", "else", ":", "\n", "# text", "\n", "        ", "text", "=", "review", "[", "'text'", "]", "\n", "words", "=", "get_words", "(", "text", ",", "vocab", ")", "\n", "text_arr", "=", "[", "1", "if", "x", "in", "words", "else", "0", "for", "x", "in", "range", "(", "len", "(", "vocab", ")", ")", "]", "\n", "row", "=", "[", "user_is_useful", ",", "positive", ",", "received_useful", ",", "]", "\n", "reviews", ".", "append", "(", "np", ".", "array", "(", "row", "+", "text_arr", ")", ")", "\n", "\n", "# Every \"dump_every\" examples, write to file", "\n", "", "if", "outfn", "is", "not", "None", ":", "\n", "        ", "if", "(", "i", "+", "1", ")", "%", "dump_every", "==", "0", "or", "i", "==", "total", ":", "\n", "          ", "logging", ".", "warn", "(", "\"dumping!\"", ")", "\n", "part", "=", "(", "i", "+", "1", ")", "//", "dump_every", "\n", "outfn", "=", "os", ".", "path", ".", "join", "(", "workdir", ",", "\"{}.{}.gz\"", ".", "format", "(", "outfn", ",", "part", ")", ")", "\n", "with", "gzip", ".", "open", "(", "outfn", ",", "\"wt\"", ")", "as", "outf", ":", "\n", "            ", "for", "review", "in", "reviews", ":", "\n", "              ", "outf", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "json", ".", "dumps", "(", "review", ",", "cls", "=", "NumpySerializer", ")", ")", ")", "\n", "", "", "reviews", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.build_yelp_dataset.main": [[161, 216], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.exists", "os.path.exists", "build_yelp_dataset.build_vocab", "build_yelp_dataset.load_users", "build_yelp_dataset.build_dataset", "os.path.exists", "logging.error", "os.path.exists", "os.path.exists", "build_yelp_dataset.load_vocab", "os.path.join", "os.path.join", "logging.error", "os.path.join", "os.path.join", "logging.error"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.build_yelp_dataset.build_vocab", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.build_yelp_dataset.load_users", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.build_yelp_dataset.build_dataset", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.build_yelp_dataset.load_vocab"], ["", "", "", "", "", "def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"n_vocab\"", ",", "help", "=", "\"How many reviews to use for building vocab\"", ",", "\n", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"min_freq\"", ",", "help", "=", "\"Minimum word frequence to include in vocab\"", ",", "\n", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_total\"", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "\"how many examples to write. If None, set equal to n_vocab\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--workdir\"", ",", "type", "=", "str", ",", "default", "=", "\"work/\"", ",", "help", "=", "\" \"", ".", "join", "(", "(", "\n", "\"Where are review.json and user.json,\"", ",", "\n", "\"and where should we put vocab and data files?\"", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--reviewfn\"", ",", "type", "=", "str", ",", "default", "=", "\"review.json\"", ",", "\n", "help", "=", "\"filename for review file in workdir\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--userfn\"", ",", "type", "=", "str", ",", "default", "=", "\"user.json\"", ",", "\n", "help", "=", "\"filename for user file in workdir\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "n_total", "is", "None", ":", "\n", "    ", "n_total", "=", "args", ".", "n_vocab", "\n", "", "else", ":", "\n", "    ", "n_total", "=", "args", ".", "n_total", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "workdir", ")", ":", "\n", "    ", "logging", ".", "error", "(", "\"Can't find workdir at {}\"", ".", "format", "(", "args", ".", "workdir", ")", ")", "\n", "return", "\n", "\n", "# Locate the review/user files in workdir or via absolute path", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "reviewfn", ")", ":", "\n", "    ", "reviewfn", "=", "args", ".", "reviewfn", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "args", ".", "workdir", ",", "args", ".", "reviewfn", ")", ")", ":", "\n", "    ", "reviewfn", "=", "os", ".", "path", ".", "join", "(", "args", ".", "workdir", ",", "args", ".", "reviewfn", ")", "\n", "", "else", ":", "\n", "    ", "logging", ".", "error", "(", "\"Can't find review file at {}\"", ".", "format", "(", "args", ".", "reviewfn", ")", ")", "\n", "return", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "userfn", ")", ":", "\n", "    ", "userfn", "=", "args", ".", "userfn", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "args", ".", "workdir", ",", "args", ".", "userfn", ")", ")", ":", "\n", "    ", "userfn", "=", "os", ".", "path", ".", "join", "(", "args", ".", "workdir", ",", "args", ".", "userfn", ")", "\n", "", "else", ":", "\n", "    ", "logging", ".", "error", "(", "\"Can't find user file at {}\"", ".", "format", "(", "args", ".", "userfn", ")", ")", "\n", "return", "\n", "\n", "# Build/load vocab using n_vocab examples", "\n", "", "vocab", "=", "build_vocab", "(", "args", ".", "workdir", ",", "reviewfn", ",", "\n", "min_freq", "=", "args", ".", "min_freq", ",", "n_vocab", "=", "args", ".", "n_vocab", ")", "\n", "if", "vocab", "is", "None", ":", "\n", "    ", "vocab", "=", "load_vocab", "(", "args", ".", "workdir", ",", "args", ".", "n_vocab", ",", "args", ".", "min_freq", ")", "\n", "\n", "# Load the user-level data", "\n", "", "user_usefuls", "=", "load_users", "(", "args", ".", "workdir", ",", "userfn", ")", "\n", "\n", "# Use vocab and user data to build dataset", "\n", "build_dataset", "(", "args", ".", "workdir", ",", "reviewfn", ",", "\n", "user_usefuls", ",", "total", "=", "n_total", ",", "vocab", "=", "vocab", ",", "\n", "outfn", "=", "'yelpdata.{}.{}'", ".", "format", "(", "args", ".", "n_vocab", ",", "args", ".", "min_freq", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.missing_data.textless_mi": [[12, 48], ["utils.impute", "range", "range", "numpy.squeeze", "a.copy", "missing_data.textless_mi.get_imputed_values"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.impute"], ["def", "textless_mi", "(", "truth", ",", "mask", ",", "k", ")", ":", "\n", "  ", "'''\n  Multiple imputation without using text data\n  This corresponds to \"no_text\" in the paper, \\S 5.3.2\n  '''", "\n", "c", ",", "a", ",", "y", "=", "truth", "\n", "\n", "obs_i", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "mask", ")", ")", "if", "not", "mask", "[", "i", "]", "]", "\n", "missing_i", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "mask", ")", ")", "if", "mask", "[", "i", "]", "]", "\n", "a_imputed", "=", "impute", "(", "\n", "(", "c", "[", "obs_i", "]", ",", "y", "[", "obs_i", "]", ")", ",", "\n", "a", "[", "obs_i", "]", ",", "\n", "(", "c", "[", "missing_i", "]", ",", "y", "[", "missing_i", "]", ")", ")", "\n", "\n", "def", "get_imputed_values", "(", "imputed_probs", ")", ":", "\n", "    ", "vals", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "missing_i", ")", ")", ":", "\n", "      ", "w", "=", "np", ".", "random", ".", "choice", "(", "[", "0", ",", "1", "]", ",", "1", ",", "p", "=", "a_imputed", "[", "i", "]", ")", "\n", "vals", ".", "append", "(", "w", ")", "\n", "", "return", "np", ".", "squeeze", "(", "np", ".", "array", "(", "vals", ")", ")", "\n", "\n", "", "resamples", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k", ")", ":", "\n", "    ", "imp_a", "=", "a", ".", "copy", "(", ")", "\n", "imp_a", "[", "missing_i", "]", "=", "get_imputed_values", "(", "a_imputed", ")", "\n", "\n", "imp_pyac", "=", "fit_simple", "(", "(", "c", ",", "imp_a", ")", ",", "y", ")", "\n", "resamples", ".", "append", "(", "imp_pyac", ")", "\n", "\n", "", "pyac", "=", "{", "key", ":", "0", "for", "key", "in", "resamples", "[", "0", "]", "}", "\n", "for", "key", "in", "pyac", ":", "\n", "    ", "for", "resample", "in", "resamples", ":", "\n", "      ", "pyac", "[", "key", "]", "+=", "resample", "[", "key", "]", "\n", "", "pyac", "[", "key", "]", "=", "pyac", "[", "key", "]", "/", "k", "\n", "\n", "", "return", "pyac", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.missing_data.bad_mis": [[50, 86], ["utils.impute", "range", "range", "numpy.squeeze", "a.copy", "missing_data.textless_mi.get_imputed_values"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.impute"], ["", "def", "bad_mis", "(", "truth", ",", "t", ",", "mask", ",", "k", ")", ":", "\n", "  ", "'''\n  Multiple imputation without accounting for y\n  This corresponds to \"no_y\" in the paper, \\S 5.3.3 \n  '''", "\n", "c", ",", "a", ",", "y", "=", "truth", "\n", "\n", "obs_i", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "mask", ")", ")", "if", "not", "mask", "[", "i", "]", "]", "\n", "missing_i", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "mask", ")", ")", "if", "mask", "[", "i", "]", "]", "\n", "a_imputed", "=", "impute", "(", "\n", "(", "c", "[", "obs_i", "]", ",", "t", "[", "obs_i", "]", ")", ",", "# NOTE y[obs_i] is intentionally left out", "\n", "a", "[", "obs_i", "]", ",", "\n", "(", "c", "[", "missing_i", "]", ",", "t", "[", "missing_i", "]", ")", ")", "\n", "\n", "def", "get_imputed_values", "(", "imputed_probs", ")", ":", "\n", "    ", "vals", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "missing_i", ")", ")", ":", "\n", "      ", "w", "=", "np", ".", "random", ".", "choice", "(", "[", "0", ",", "1", "]", ",", "1", ",", "p", "=", "a_imputed", "[", "i", "]", ")", "\n", "vals", ".", "append", "(", "w", ")", "\n", "", "return", "np", ".", "squeeze", "(", "np", ".", "array", "(", "vals", ")", ")", "\n", "\n", "", "resamples", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k", ")", ":", "\n", "    ", "imp_a", "=", "a", ".", "copy", "(", ")", "\n", "imp_a", "[", "missing_i", "]", "=", "get_imputed_values", "(", "a_imputed", ")", "\n", "\n", "imp_pyac", "=", "fit_simple", "(", "(", "c", ",", "imp_a", ")", ",", "y", ")", "\n", "resamples", ".", "append", "(", "imp_pyac", ")", "\n", "\n", "", "pyac", "=", "{", "key", ":", "0", "for", "key", "in", "resamples", "[", "0", "]", "}", "\n", "for", "key", "in", "pyac", ":", "\n", "    ", "for", "resample", "in", "resamples", ":", "\n", "      ", "pyac", "[", "key", "]", "+=", "resample", "[", "key", "]", "\n", "", "pyac", "[", "key", "]", "=", "pyac", "[", "key", "]", "/", "k", "\n", "\n", "", "return", "pyac", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.missing_data.mi": [[88, 124], ["utils.impute", "range", "range", "numpy.squeeze", "a.copy", "missing_data.textless_mi.get_imputed_values"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.impute"], ["", "def", "mi", "(", "truth", ",", "t", ",", "mask", ",", "k", ")", ":", "\n", "  ", "'''\n  Correct multiple imputation implementation\n  '''", "\n", "c", ",", "a", ",", "y", "=", "truth", "\n", "\n", "obs_i", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "mask", ")", ")", "if", "not", "mask", "[", "i", "]", "]", "\n", "missing_i", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "mask", ")", ")", "if", "mask", "[", "i", "]", "]", "\n", "\n", "a_imputed", "=", "impute", "(", "\n", "(", "c", "[", "obs_i", "]", ",", "y", "[", "obs_i", "]", ",", "t", "[", "obs_i", "]", ")", ",", "\n", "a", "[", "obs_i", "]", ",", "\n", "(", "c", "[", "missing_i", "]", ",", "y", "[", "missing_i", "]", ",", "t", "[", "missing_i", "]", ")", ")", "\n", "\n", "def", "get_imputed_values", "(", "imputed_probs", ")", ":", "\n", "    ", "vals", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "missing_i", ")", ")", ":", "\n", "      ", "w", "=", "np", ".", "random", ".", "choice", "(", "[", "0", ",", "1", "]", ",", "1", ",", "p", "=", "a_imputed", "[", "i", "]", ")", "\n", "vals", ".", "append", "(", "w", ")", "\n", "", "return", "np", ".", "squeeze", "(", "np", ".", "array", "(", "vals", ")", ")", "\n", "\n", "", "resamples", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k", ")", ":", "\n", "    ", "imp_a", "=", "a", ".", "copy", "(", ")", "\n", "imp_a", "[", "missing_i", "]", "=", "get_imputed_values", "(", "a_imputed", ")", "\n", "\n", "imp_pyac", "=", "fit_simple", "(", "(", "c", ",", "imp_a", ")", ",", "y", ")", "\n", "resamples", ".", "append", "(", "imp_pyac", ")", "\n", "\n", "", "pyac", "=", "{", "key", ":", "0", "for", "key", "in", "resamples", "[", "0", "]", "}", "\n", "for", "key", "in", "pyac", ":", "\n", "    ", "for", "resample", "in", "resamples", ":", "\n", "      ", "pyac", "[", "key", "]", "+=", "resample", "[", "key", "]", "\n", "", "pyac", "[", "key", "]", "=", "pyac", "[", "key", "]", "/", "k", "\n", "\n", "", "return", "pyac", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.missing_data.yelp": [[126, 144], ["datasets.synthetic_config.copy", "synthetic_config.copy.update", "datasets.YelpData", "datasets.YelpData.load", "datasets.YelpData.mar", "kwargs.get", "missing_data.experiment"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.YelpData.load", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.SyntheticData.mar", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.missing_data.experiment"], ["", "def", "yelp", "(", "n_examples", ",", "**", "kwargs", ")", ":", "\n", "  ", "'''\n  Run a Yelp experiment using n_examples examples\n  '''", "\n", "args", "=", "synthetic_config", ".", "copy", "(", ")", "\n", "args", ".", "update", "(", "kwargs", ")", "\n", "\n", "sampler", "=", "YelpData", "(", "**", "args", ")", "\n", "dataset", "=", "sampler", ".", "load", "(", "n_examples", ")", "\n", "\n", "c", "=", "dataset", "[", ":", ",", "0", "]", "\n", "a", "=", "dataset", "[", ":", ",", "1", "]", "\n", "y", "=", "dataset", "[", ":", ",", "2", "]", "\n", "t", "=", "dataset", "[", ":", ",", "3", ":", "]", "\n", "mask", "=", "sampler", ".", "mar", "(", "a", ",", "(", "c", ",", "y", ",", "t", ")", ")", "\n", "\n", "debug", "=", "kwargs", ".", "get", "(", "'debug'", ",", "False", ")", "\n", "return", "experiment", "(", "c", ",", "a", ",", "y", ",", "t", ",", "mask", ",", "debug", "=", "debug", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.missing_data.synthetic": [[146, 163], ["numpy.random.seed", "datasets.synthetic_config.copy", "synthetic_config.copy.update", "datasets.SyntheticData", "datasets.SyntheticData.sample_truth", "datasets.SyntheticData.sample_text", "datasets.SyntheticData.mar", "kwargs.get", "missing_data.experiment", "synthetic_config.copy.get"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.SyntheticData.sample_truth", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.SyntheticData.sample_text", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.SyntheticData.mar", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.missing_data.experiment"], ["", "def", "synthetic", "(", "n_examples", ",", "**", "kwargs", ")", ":", "\n", "  ", "'''\n  Run a synthetic experiment using n_examples examples\n  '''", "\n", "np", ".", "random", ".", "seed", "(", "42", ")", "\n", "\n", "config", "=", "synthetic_config", ".", "copy", "(", ")", "\n", "config", ".", "update", "(", "kwargs", ")", "\n", "assert", "config", ".", "get", "(", "'vocab_size'", ")", "is", "not", "None", ",", "\"Must specify synthetic data vocab_size\"", "\n", "\n", "sampler", "=", "SyntheticData", "(", "**", "config", ")", "\n", "c", ",", "a", ",", "y", "=", "sampler", ".", "sample_truth", "(", "n_examples", ")", "\n", "t", "=", "sampler", ".", "sample_text", "(", "(", "c", ",", "a", ",", "y", ")", ")", "\n", "mask", "=", "sampler", ".", "mar", "(", "a", ",", "(", "c", ",", "y", ",", "t", ")", ")", "\n", "\n", "debug", "=", "kwargs", ".", "get", "(", "'debug'", ",", "False", ")", "\n", "return", "experiment", "(", "c", ",", "a", ",", "y", ",", "t", ",", "mask", ",", "debug", "=", "debug", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.missing_data.experiment": [[165, 194], ["utils.fit_bernoulli", "utils.fit_simple", "utils.fit_simple", "utils.fit_bernoulli", "missing_data.textless_mi", "missing_data.mi", "missing_data.bad_mis", "utils.gformula", "utils.gformula", "utils.gformula", "utils.gformula", "utils.gformula", "print", "print", "print", "print", "print", "range", "len"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.fit_bernoulli", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.fit_simple", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.fit_simple", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.fit_bernoulli", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.missing_data.textless_mi", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.missing_data.mi", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.missing_data.bad_mis", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.gformula", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.gformula", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.gformula", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.gformula", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.gformula"], ["", "def", "experiment", "(", "c", ",", "a", ",", "y", ",", "t", ",", "mask", ",", "debug", "=", "False", ")", ":", "\n", "  ", "'''\n  Accept data columns from dataset wrapper function and run experiment \n  '''", "\n", "obs_i", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "mask", ")", ")", "if", "not", "mask", "[", "i", "]", "]", "\n", "\n", "full_pc", "=", "fit_bernoulli", "(", "c", ")", "\n", "full_pyac", "=", "fit_simple", "(", "(", "c", ",", "a", ")", ",", "y", ")", "\n", "cc_pyac", "=", "fit_simple", "(", "(", "c", "[", "obs_i", "]", ",", "a", "[", "obs_i", "]", ")", ",", "y", "[", "obs_i", "]", ")", "\n", "cc_pc", "=", "fit_bernoulli", "(", "c", "[", "obs_i", "]", ")", "\n", "textless_mi_pyac", "=", "textless_mi", "(", "(", "c", ",", "a", ",", "y", ")", ",", "mask", ",", "20", ")", "\n", "mi_pyac", "=", "mi", "(", "(", "c", ",", "a", ",", "y", ")", ",", "t", ",", "mask", ",", "20", ")", "\n", "bad_mi_pyac", "=", "bad_mis", "(", "(", "c", ",", "a", ",", "y", ")", ",", "t", ",", "mask", ",", "20", ")", "\n", "\n", "oracle_err", "=", "gformula", "(", "full_pyac", ",", "full_pc", ")", "\n", "naive_err", "=", "gformula", "(", "cc_pyac", ",", "cc_pc", ")", "\n", "textless_err", "=", "gformula", "(", "textless_mi_pyac", ",", "full_pc", ")", "\n", "bad_mi_err", "=", "gformula", "(", "bad_mi_pyac", ",", "full_pc", ")", "\n", "mi_err", "=", "gformula", "(", "mi_pyac", ",", "full_pc", ")", "\n", "\n", "if", "debug", ":", "\n", "    ", "print", "(", "\"\\tOracle: {:0.3f}\"", ".", "format", "(", "oracle_err", ")", ")", "\n", "print", "(", "\"\\tNaive: {:0.6f}\"", ".", "format", "(", "naive_err", ")", ")", "\n", "print", "(", "\"\\tTextless: {:0.6f}\"", ".", "format", "(", "textless_err", ")", ")", "\n", "print", "(", "\"\\tbad m.i.: {:0.6f}\"", ".", "format", "(", "bad_mi_err", ")", ")", "\n", "print", "(", "\"\\tm.i.: {:0.6f}\"", ".", "format", "(", "mi_err", ")", ")", "\n", "\n", "", "return", "[", "(", "x", "-", "oracle_err", ")", "**", "2", "\n", "for", "x", "in", "(", "naive_err", ",", "textless_err", ",", "bad_mi_err", ",", "mi_err", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.missing_data.main": [[196, 261], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "int", "os.path.exists", "range", "numpy.array", "numpy.mean", "range", "print", "os.path.join", "logging.error", "numpy.sqrt", "len", "outlines.append", "open", "outf.write", "ValueError", "print", "np.array.append", "numpy.std", "json.dumps", "print", "os.path.join", "test_func", "logging.warn"], "function", ["None"], ["", "def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"logn_examples\"", ",", "type", "=", "float", ",", "help", "=", "\"how many examples (log 10)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--k\"", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "\"how many duplicate runs to average for this experiment?\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_freq\"", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "\n", "help", "=", "\"min freq for yelp data vocabulary\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocab_size\"", ",", "type", "=", "int", ",", "default", "=", "4334", ",", "\n", "help", "=", "\"vocab size for synthetic data\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_vocab\"", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"how many examples were usedto build the vocab\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "type", "=", "str", ",", "default", "=", "'synthetic'", ")", "\n", "parser", ".", "add_argument", "(", "\"--debug\"", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--workdir\"", ",", "type", "=", "str", ",", "default", "=", "'work/'", ")", "\n", "parser", ".", "add_argument", "(", "\"--outdir\"", ",", "type", "=", "str", ",", "default", "=", "\"results/\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "n_examples", "=", "int", "(", "10", "**", "args", ".", "logn_examples", ")", "\n", "if", "args", ".", "debug", ":", "\n", "    ", "print", "(", "\"missing\"", ",", "n_examples", ",", "args", ".", "k", ",", "args", ".", "dataset", ",", "args", ".", "min_freq", ")", "\n", "\n", "", "outfn", "=", "\"md.{}.{}.{}.{}.json\"", ".", "format", "(", "args", ".", "dataset", ",", "args", ".", "logn_examples", ",", "args", ".", "k", ",", "args", ".", "min_freq", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "args", ".", "outdir", ",", "outfn", ")", ")", ":", "\n", "    ", "logging", ".", "error", "(", "\"{} already exists!\"", ".", "format", "(", "outfn", ")", ")", "\n", "return", "\n", "\n", "", "job_args", "=", "{", "'debug'", ":", "args", ".", "debug", "}", "\n", "if", "args", ".", "dataset", "==", "'synthetic'", ":", "\n", "    ", "test_func", "=", "synthetic", "\n", "job_args", "[", "'vocab_size'", "]", "=", "args", ".", "vocab_size", "\n", "", "elif", "args", ".", "dataset", "==", "'yelp'", ":", "\n", "    ", "test_func", "=", "yelp", "\n", "job_args", "[", "'workdir'", "]", "=", "args", ".", "workdir", "\n", "job_args", "[", "'n_vocab'", "]", "=", "args", ".", "n_vocab", "\n", "job_args", "[", "'min_freq'", "]", "=", "args", ".", "min_freq", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"unknown dataset {}\"", ".", "format", "(", "args", ".", "dataset", ")", ")", "\n", "\n", "# Run experiments", "\n", "", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "args", ".", "k", ")", ":", "\n", "    ", "if", "args", ".", "debug", ":", "\n", "      ", "print", "(", "\" {} \"", ".", "format", "(", "i", ")", ",", "end", "=", "'\\r'", ")", "\n", "", "try", ":", "\n", "      ", "results", ".", "append", "(", "test_func", "(", "n_examples", ",", "**", "job_args", ")", ")", "\n", "", "except", "ValueError", "as", "e", ":", "\n", "      ", "logging", ".", "warn", "(", "\"Single run failed with error '{}'\"", ".", "format", "(", "e", ")", ")", "\n", "raise", "e", "\n", "pass", "\n", "\n", "# Compile results", "\n", "", "", "results", "=", "np", ".", "array", "(", "results", ")", "\n", "means", "=", "np", ".", "mean", "(", "results", ",", "axis", "=", "0", ")", "\n", "sems", "=", "1.96", "*", "np", ".", "std", "(", "results", ",", "axis", "=", "0", ")", "/", "np", ".", "sqrt", "(", "n_examples", ")", "\n", "models", "=", "[", "'naive'", ",", "'textless'", ",", "\"bad_mi\"", ",", "'mi'", "]", "\n", "\n", "outlines", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "models", ")", ")", ":", "\n", "    ", "outlines", ".", "append", "(", "json", ".", "dumps", "(", "{", "\n", "'model'", ":", "models", "[", "i", "]", ",", "'n'", ":", "n_examples", ",", "'err'", ":", "means", "[", "i", "]", ",", "'se'", ":", "sems", "[", "i", "]", "}", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "      ", "print", "(", "\"{:8s} {:8.2e} {:8.2e}\"", ".", "format", "(", "models", "[", "i", "]", ",", "means", "[", "i", "]", ",", "sems", "[", "i", "]", ")", ")", "\n", "\n", "# Write to file", "\n", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "outdir", ",", "outfn", ")", ",", "\"w\"", ")", "as", "outf", ":", "\n", "    ", "outf", ".", "write", "(", "\"\\n\"", ".", "join", "(", "outlines", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_error_rate": [[14, 35], ["numpy.all", "sum", "numpy.all", "sum", "numpy.stack", "numpy.stack", "range", "len"], "function", ["None"], ["def", "get_error_rate", "(", "proxy", ",", "truth", ",", "truth_val", ",", "confounds", "=", "None", ",", "confound_assn", "=", "None", ")", ":", "\n", "  ", "'''\n  Given a proxy (A*) and truth (A), calculate the error rate when A=1.\n  If confounds and confound_assn are given, limit this calculation to when\n    confounds have the given assignment\n  '''", "\n", "where", "=", "[", "]", "\n", "if", "confounds", "is", "not", "None", "and", "confound_assn", "is", "not", "None", ":", "\n", "    ", "where", "=", "[", "confounds", "[", "i", ",", ":", "]", "==", "confound_assn", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "confound_assn", ")", ")", "]", "\n", "\n", "", "true_where", "=", "where", "+", "[", "truth", "==", "truth_val", "]", "\n", "true_where", "=", "np", ".", "all", "(", "np", ".", "stack", "(", "true_where", ",", "axis", "=", "0", ")", ",", "axis", "=", "0", ")", "\n", "true", "=", "sum", "(", "true_where", ")", "\n", "\n", "correct_where", "=", "where", "+", "[", "proxy", "==", "truth_val", ",", "truth", "==", "truth_val", "]", "\n", "correct_where", "=", "np", ".", "all", "(", "np", ".", "stack", "(", "correct_where", ",", "axis", "=", "0", ")", ",", "axis", "=", "0", ")", "\n", "correct", "=", "sum", "(", "correct_where", ")", "\n", "\n", "if", "true", "==", "0", ":", "\n", "    ", "return", "0", "\n", "", "return", "1", "-", "correct", "/", "true", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.calculate_error_matrix": [[37, 54], ["list", "itertools.product", "measurement_error.get_error_rate", "range"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_error_rate"], ["", "def", "calculate_error_matrix", "(", "proxy", ",", "truth", ",", "confounds", "=", "None", ",", "debug", "=", "False", ")", ":", "\n", "  ", "'''\n    Given the proxy (A*) and truth (A), calculate the correction matrix\n    to adjust the causal effect calculations\n  '''", "\n", "errs", "=", "{", "}", "\n", "if", "confounds", "is", "None", ":", "\n", "    ", "confound_assns", "=", "[", "(", ")", "]", "\n", "", "else", ":", "\n", "    ", "confound_assns", "=", "list", "(", "itertools", ".", "product", "(", "*", "[", "range", "(", "2", ")", "for", "_", "in", "confounds", "]", ")", ")", "\n", "\n", "", "for", "truth_val", "in", "[", "0", ",", "1", "]", ":", "\n", "    ", "for", "confound_assn", "in", "confound_assns", ":", "\n", "      ", "err_rate", "=", "get_error_rate", "(", "proxy", ",", "truth", ",", "truth_val", ",", "confounds", ",", "confound_assn", ")", "\n", "errs", "[", "(", "truth_val", ",", ")", "+", "confound_assn", "]", "=", "err_rate", "\n", "\n", "", "", "return", "errs", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist": [[56, 68], ["itertools.product", "numpy.all", "numpy.stack", "numpy.sum", "range", "range", "tuple", "range", "len"], "function", ["None"], ["", "def", "get_dist", "(", "dist", ",", "debug", "=", "False", ")", ":", "\n", "  ", "'''\n  Calculate the probability mass on all variable assignments\n  '''", "\n", "n", "=", "dist", ".", "shape", "[", "1", "]", "\n", "d", "=", "{", "}", "\n", "for", "assn", "in", "itertools", ".", "product", "(", "*", "[", "range", "(", "2", ")", "for", "_", "in", "range", "(", "3", ")", "]", ")", ":", "\n", "    ", "where", "=", "[", "dist", "[", "i", ",", ":", "]", "==", "assn", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "assn", ")", ")", "]", "\n", "where", "=", "np", ".", "all", "(", "np", ".", "stack", "(", "where", ",", "axis", "=", "0", ")", ",", "axis", "=", "0", ")", "\n", "d", "[", "tuple", "(", "assn", ")", "]", "=", "np", ".", "sum", "(", "where", ")", "/", "n", "\n", "\n", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_corrected_dist": [[70, 115], ["measurement_error.get_dist", "itertools.product", "list", "list.insert", "list", "list.insert", "numpy.isfinite", "numpy.isfinite", "print", "print", "print", "print", "range", "range", "tuple", "tuple", "tuple", "tuple", "tuple", "tuple", "tuple", "tuple", "tuple", "tuple", "tuple", "tuple", "len", "tuple", "tuple", "tuple", "tuple"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist"], ["", "def", "get_corrected_dist", "(", "dist", ",", "errs", ",", "truth", ",", "proxied_index", ",", "confounds", "=", "(", ")", ",", "debug", "=", "False", ")", ":", "\n", "  ", "'''\n  Given a proxy distribution dist, error estimates, and a held-out truth,\n    calculate the new dist that comes from using the error estimates to correct the proxy.\n  dist: p(C, A*, Y)\n  errs: p(A*, A)\n  truth: p(C, A, Y)\n  '''", "\n", "start", "=", "get_dist", "(", "dist", ")", "\n", "\n", "corrected", "=", "{", "}", "\n", "for", "assn", "in", "itertools", ".", "product", "(", "*", "[", "range", "(", "2", ")", "for", "_", "in", "range", "(", "len", "(", "dist", ")", "-", "1", ")", "]", ")", ":", "\n", "    ", "assn0", "=", "list", "(", "assn", "[", ":", "]", ")", "\n", "assn0", ".", "insert", "(", "proxied_index", ",", "0", ")", "\n", "assn1", "=", "list", "(", "assn", "[", ":", "]", ")", "\n", "assn1", ".", "insert", "(", "proxied_index", ",", "1", ")", "\n", "confound_assn", "=", "[", "assn0", "[", "i", "]", "for", "i", "in", "confounds", "]", "\n", "\n", "# error assignment indexing is proxied value first", "\n", "err1", "=", "errs", "[", "(", "1", ",", ")", "+", "tuple", "(", "confound_assn", ")", "]", "\n", "err0", "=", "errs", "[", "(", "0", ",", ")", "+", "tuple", "(", "confound_assn", ")", "]", "\n", "\n", "corrected0", "=", "(", "1", "-", "err1", ")", "*", "start", "[", "tuple", "(", "assn0", ")", "]", "-", "err1", "*", "start", "[", "tuple", "(", "assn1", ")", "]", "\n", "corrected0", "/=", "(", "1", "-", "err1", "-", "err0", ")", "\n", "if", "np", ".", "isfinite", "(", "corrected0", ")", ":", "\n", "      ", "corrected", "[", "tuple", "(", "assn0", ")", "]", "=", "corrected0", "\n", "", "else", ":", "\n", "      ", "corrected", "[", "tuple", "(", "assn0", ")", "]", "=", "start", "[", "tuple", "(", "assn0", ")", "]", "\n", "\n", "", "corrected1", "=", "-", "err0", "*", "start", "[", "tuple", "(", "assn0", ")", "]", "+", "(", "1", "-", "err0", ")", "*", "start", "[", "tuple", "(", "assn1", ")", "]", "\n", "corrected1", "/=", "(", "1", "-", "err1", "-", "err0", ")", "\n", "if", "np", ".", "isfinite", "(", "corrected1", ")", ":", "\n", "      ", "corrected", "[", "tuple", "(", "assn1", ")", "]", "=", "corrected1", "\n", "", "else", ":", "\n", "      ", "corrected", "[", "tuple", "(", "assn1", ")", "]", "=", "start", "[", "tuple", "(", "assn1", ")", "]", "\n", "\n", "", "if", "debug", ":", "\n", "      ", "print", "(", "\"errors: {:0.3f} and {:0.3f}\"", ".", "format", "(", "err0", ",", "err1", ")", ")", "\n", "print", "(", "\"correcting took:\"", ")", "\n", "print", "(", "\"p(c'={}, a={}, y={}) from {:0.3f} to {:0.3f}, truth is {:0.3f}\"", ".", "format", "(", "\n", "*", "(", "assn0", "+", "[", "start", "[", "tuple", "(", "assn0", ")", "]", ",", "corrected0", ",", "truth", "[", "tuple", "(", "assn0", ")", "]", "]", ")", ")", ")", "\n", "print", "(", "\"p(c'={}, a={}, y={}) from {:0.3f} to {:0.3f}, truth is {:0.3f}\"", ".", "format", "(", "\n", "*", "(", "assn1", "+", "[", "start", "[", "tuple", "(", "assn1", ")", "]", ",", "corrected1", ",", "truth", "[", "tuple", "(", "assn1", ")", "]", "]", ")", ")", ")", "\n", "\n", "", "", "return", "corrected", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.check_restoration": [[117, 126], ["None"], "function", ["None"], ["", "def", "check_restoration", "(", "dist1", ",", "dist2", ")", ":", "\n", "  ", "'''\n  Calculate the L2 distance between two distributions as a sanity check.\n  '''", "\n", "dist_err", "=", "0", "\n", "for", "key", "in", "dist1", ":", "\n", "    ", "dist_err", "+=", "(", "dist1", "[", "key", "]", "-", "dist2", "[", "key", "]", ")", "**", "2", "\n", "\n", "", "return", "dist_err", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.dist_pyac": [[128, 139], ["None"], "function", ["None"], ["", "def", "dist_pyac", "(", "dist", ")", ":", "\n", "  ", "'''\n  Assume dist is ordered as c, a, y\n  Given a distribution dictionary from get_dist, calculate p(Y=1 | A, C)\n  '''", "\n", "pyac", "=", "{", "}", "\n", "for", "a", "in", "[", "0", ",", "1", "]", ":", "\n", "    ", "for", "c", "in", "[", "0", ",", "1", "]", ":", "\n", "      ", "pyac", "[", "(", "c", ",", "a", ")", "]", "=", "dist", "[", "(", "c", ",", "a", ",", "1", ")", "]", "/", "(", "dist", "[", "(", "c", ",", "a", ",", "1", ")", "]", "+", "dist", "[", "(", "c", ",", "a", ",", "0", ")", "]", ")", "\n", "\n", "", "", "return", "pyac", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.dist_pc": [[141, 149], ["None"], "function", ["None"], ["", "def", "dist_pc", "(", "dist", ")", ":", "\n", "  ", "''' Given a distribution dictionary from get_dist, calculate p(C=1) '''", "\n", "pc", "=", "0", "\n", "for", "a", "in", "[", "0", ",", "1", "]", ":", "\n", "    ", "for", "y", "in", "[", "0", ",", "1", "]", ":", "\n", "      ", "pc", "+=", "dist", "[", "(", "1", ",", "a", ",", "y", ")", "]", "\n", "\n", "", "", "return", "pc", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.textless_impute": [[151, 200], ["sklearn.linear_model.LogisticRegression", "numpy.concatenate", "sklearn.linear_model.LogisticRegression.fit", "sklearn.linear_model.LogisticRegression.predict", "measurement_error.calculate_error_matrix", "numpy.concatenate", "test[].copy", "sklearn.linear_model.LogisticRegression.predict", "measurement_error.check_restoration", "measurement_error.get_corrected_dist", "measurement_error.check_restoration", "numpy.transpose", "print", "numpy.transpose", "print", "print", "numpy.transpose", "measurement_error.get_dist", "measurement_error.get_dist", "measurement_error.get_dist", "measurement_error.get_dist", "print", "print", "measurement_error.get_dist", "print", "measurement_error.get_dist", "print", "print", "print", "print", "sklearn.linear_model.LogisticRegression.score", "sklearn.linear_model.LogisticRegression.score", "measurement_error.check_restoration", "numpy.transpose", "numpy.transpose", "measurement_error.get_dist", "calculate_error_matrix.values"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.calculate_error_matrix", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.check_restoration", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_corrected_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.check_restoration", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.check_restoration", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist"], ["", "def", "textless_impute", "(", "train", ",", "test", ",", "n", ",", "num_train", ",", "\n", "proxy_i", "=", "1", ",", "confound_i", "=", "(", ")", ",", "debug", "=", "False", ")", ":", "\n", "  ", "'''\n  Unused code for measurement error without text.\n  In our experiments, always led to singular matrix.\n  '''", "\n", "\n", "model", "=", "sklearn", ".", "linear_model", ".", "LogisticRegression", "(", ")", "\n", "features", "=", "np", ".", "concatenate", "(", "(", "train", "[", ":", "1", ",", ":", "]", ",", "train", "[", "2", ":", "3", ",", ":", "]", ")", ",", "axis", "=", "0", ")", "\n", "model", ".", "fit", "(", "np", ".", "transpose", "(", "features", "[", ":", ",", ":", "num_train", "]", ")", ",", "train", "[", "proxy_i", ",", ":", "num_train", "]", ")", "\n", "if", "debug", ":", "\n", "    ", "print", "(", "\"Model dev acc: {:0.3f}\"", ".", "format", "(", "model", ".", "score", "(", "\n", "np", ".", "transpose", "(", "features", "[", ":", ",", "num_train", ":", "]", ")", ",", "train", "[", "proxy_i", ",", "num_train", ":", "]", ")", ")", ")", "\n", "", "train_proxy", "=", "model", ".", "predict", "(", "np", ".", "transpose", "(", "features", "[", ":", ",", "num_train", ":", "]", ")", ")", "\n", "\n", "if", "confound_i", ":", "\n", "    ", "err_confounds", "=", "train", "[", "confound_i", ",", "num_train", ":", "]", "\n", "", "else", ":", "\n", "    ", "err_confounds", "=", "None", "\n", "\n", "", "errs", "=", "calculate_error_matrix", "(", "train_proxy", ",", "train", "[", "proxy_i", ",", "num_train", ":", "]", ",", "\n", "confounds", "=", "err_confounds", ",", "debug", "=", "debug", ")", "\n", "if", "debug", ":", "\n", "    ", "print", "(", "\"Dev error rates: {}\"", ".", "format", "(", "\", \"", ".", "join", "(", "[", "\"{:0.1f}\"", ".", "format", "(", "err", ")", "for", "err", "in", "errs", ".", "values", "(", ")", "]", ")", ")", ")", "\n", "\n", "", "features", "=", "np", ".", "concatenate", "(", "(", "test", "[", ":", "1", ",", ":", "]", ",", "test", "[", "2", ":", "3", ",", ":", "]", ")", ",", "axis", "=", "0", ")", "\n", "if", "debug", ":", "\n", "    ", "print", "(", "\"Test acc: {:0.3f}\"", ".", "format", "(", "model", ".", "score", "(", "np", ".", "transpose", "(", "features", ")", ",", "test", "[", "proxy_i", ",", ":", "]", ")", ")", ")", "\n", "", "proxy", "=", "test", "[", ":", "3", ",", ":", "]", ".", "copy", "(", ")", "\n", "proxy", "[", "proxy_i", ",", ":", "]", "=", "model", ".", "predict", "(", "np", ".", "transpose", "(", "features", ")", ")", "\n", "truth", "=", "test", "[", ":", "3", ",", ":", "]", "\n", "\n", "start_err", "=", "check_restoration", "(", "get_dist", "(", "truth", ")", ",", "get_dist", "(", "proxy", ")", ")", "\n", "new_dist", "=", "get_corrected_dist", "(", "proxy", ",", "errs", ",", "get_dist", "(", "truth", ")", ",", "proxy_i", ",", "confound_i", ",", "debug", ")", "\n", "end_err", "=", "check_restoration", "(", "get_dist", "(", "truth", ")", ",", "new_dist", ")", "\n", "\n", "if", "debug", ":", "\n", "    ", "print", "(", "\"true dist\"", ")", "\n", "print", "(", "truth", ".", "shape", ")", "\n", "get_dist", "(", "truth", ",", "debug", ")", "\n", "print", "(", "\"proxy dist\"", ")", "\n", "get_dist", "(", "proxy", ",", "debug", ")", "\n", "print", "(", "\"start err: {:0.3e}\"", ".", "format", "(", "start_err", ")", ")", "\n", "print", "(", "\"end err: {:0.3e}\"", ".", "format", "(", "end_err", ")", ")", "\n", "print", "(", "\"proxy to correction diff: {:0.3f}\"", ".", "format", "(", "\n", "check_restoration", "(", "new_dist", ",", "get_dist", "(", "proxy", ")", ")", ")", ")", "\n", "print", "(", "\"Correction reduced error by a factor of {:0.1f}\"", ".", "format", "(", "start_err", "/", "end_err", ")", ")", "\n", "\n", "", "return", "new_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.impute_and_correct": [[202, 261], ["numpy.concatenate", "sklearn.linear_model.LogisticRegression", "sklearn.linear_model.LogisticRegression.fit", "sklearn.linear_model.LogisticRegression.predict", "measurement_error.calculate_error_matrix", "numpy.concatenate", "sorted", "test.copy", "sklearn.linear_model.LogisticRegression.predict", "measurement_error.check_restoration", "measurement_error.get_corrected_dist", "measurement_error.check_restoration", "numpy.transpose", "numpy.transpose", "numpy.transpose", "measurement_error.get_dist", "measurement_error.get_dist", "measurement_error.get_dist", "measurement_error.get_dist", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "measurement_error.get_dist", "measurement_error.get_dist", "sklearn.linear_model.LogisticRegression.score", "sklearn.linear_model.LogisticRegression.score", "measurement_error.check_restoration", "numpy.transpose", "numpy.transpose", "measurement_error.get_dist", "calculate_error_matrix.values"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.calculate_error_matrix", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.check_restoration", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_corrected_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.check_restoration", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.check_restoration", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist"], ["", "def", "impute_and_correct", "(", "train", ",", "test", ",", "n", ",", "num_train", ",", "\n", "proxy_i", "=", "1", ",", "confound_i", "=", "(", ")", ",", "debug", "=", "False", ")", ":", "\n", "  ", "'''\n  train: training data\n  test: testing data\n  num_train: how many examples of training data to use for training,\n    (leaving the rest for development)\n  proxy_i: what is the index of the proxied variable (e.g. 1)\n  confound_i: what are the indices of the proxy's confounders (e.g. 0, 2)\n  '''", "\n", "\n", "# features are everything but the proxy variable", "\n", "train_features", "=", "np", ".", "concatenate", "(", "(", "train", "[", ":", "proxy_i", ",", ":", "]", ",", "train", "[", "1", "+", "proxy_i", ":", ",", ":", "]", ")", ",", "axis", "=", "0", ")", "\n", "\n", "model", "=", "sklearn", ".", "linear_model", ".", "LogisticRegression", "(", ")", "\n", "model", ".", "fit", "(", "np", ".", "transpose", "(", "train_features", "[", ":", ",", ":", "num_train", "]", ")", ",", "train", "[", "proxy_i", ",", ":", "num_train", "]", ")", "\n", "train_proxy", "=", "model", ".", "predict", "(", "np", ".", "transpose", "(", "train_features", "[", ":", ",", "num_train", ":", "]", ")", ")", "\n", "\n", "if", "confound_i", ":", "\n", "    ", "err_confounds", "=", "train", "[", "confound_i", ",", "num_train", ":", "]", "\n", "", "else", ":", "\n", "    ", "err_confounds", "=", "None", "\n", "\n", "", "errs", "=", "calculate_error_matrix", "(", "train_proxy", ",", "train", "[", "proxy_i", ",", "num_train", ":", "]", ",", "\n", "confounds", "=", "err_confounds", ",", "debug", "=", "debug", ")", "\n", "\n", "# features are everything but the proxy variable, including text", "\n", "test_features", "=", "np", ".", "concatenate", "(", "(", "test", "[", ":", "proxy_i", ",", ":", "]", ",", "test", "[", "1", "+", "proxy_i", ":", ",", ":", "]", ")", ",", "axis", "=", "0", ")", "\n", "\n", "# \"proxy\" and \"truth\" arrays have all non-text variables", "\n", "nontext_vars", "=", "sorted", "(", "confound_i", "+", "(", "proxy_i", ",", ")", ")", "\n", "proxy", "=", "test", ".", "copy", "(", ")", "\n", "proxy", "[", "proxy_i", ",", ":", "]", "=", "model", ".", "predict", "(", "np", ".", "transpose", "(", "test_features", ")", ")", "\n", "proxy", "=", "proxy", "[", "nontext_vars", ",", ":", "]", "\n", "truth", "=", "test", "[", "nontext_vars", ",", ":", "]", "\n", "\n", "start_err", "=", "check_restoration", "(", "get_dist", "(", "truth", ")", ",", "get_dist", "(", "proxy", ")", ")", "\n", "\n", "new_dist", "=", "get_corrected_dist", "(", "proxy", ",", "errs", ",", "get_dist", "(", "truth", ")", ",", "proxy_i", ",", "confound_i", ",", "debug", ")", "\n", "end_err", "=", "check_restoration", "(", "get_dist", "(", "truth", ")", ",", "new_dist", ")", "\n", "\n", "if", "debug", ":", "\n", "    ", "print", "(", "\"Model dev acc: {:0.3f}\"", ".", "format", "(", "model", ".", "score", "(", "\n", "np", ".", "transpose", "(", "train_features", "[", ":", ",", "num_train", ":", "]", ")", ",", "train", "[", "proxy_i", ",", "num_train", ":", "]", ")", ")", ")", "\n", "print", "(", "\"Dev error rates: {}\"", ".", "format", "(", "\", \"", ".", "join", "(", "[", "\"{:0.1f}\"", ".", "format", "(", "err", ")", "for", "err", "in", "errs", ".", "values", "(", ")", "]", ")", ")", ")", "\n", "print", "(", "\"Test acc: {:0.3f}\"", ".", "format", "(", "model", ".", "score", "(", "np", ".", "transpose", "(", "test_features", ")", ",", "test", "[", "proxy_i", ",", ":", "]", ")", ")", ")", "\n", "print", "(", "\"true dist\"", ")", "\n", "print", "(", "get_dist", "(", "truth", ",", "debug", ")", ")", "\n", "print", "(", "\"new dist\"", ")", "\n", "print", "(", "new_dist", ")", "\n", "print", "(", "\"proxy dist\"", ")", "\n", "print", "(", "get_dist", "(", "proxy", ",", "debug", ")", ")", "\n", "print", "(", "\"start err: {:0.3e}\"", ".", "format", "(", "start_err", ")", ")", "\n", "print", "(", "\"end err: {:0.3e}\"", ".", "format", "(", "end_err", ")", ")", "\n", "print", "(", "\"proxy to correction diff: {:0.3f}\"", ".", "format", "(", "\n", "check_restoration", "(", "new_dist", ",", "get_dist", "(", "proxy", ")", ")", ")", ")", "\n", "print", "(", "\"Correction reduced error by a factor of {:0.1f}\"", ".", "format", "(", "start_err", "/", "end_err", ")", ")", "\n", "\n", "", "return", "new_dist", ",", "proxy", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.train_adjust": [[263, 297], ["measurement_error.impute_and_correct", "utils.gformula", "utils.gformula", "utils.gformula", "utils.gformula", "measurement_error.dist_pyac", "measurement_error.dist_pc", "utils.fit_simple", "utils.fit_bernoulli", "measurement_error.dist_pyac", "measurement_error.dist_pc", "measurement_error.dist_pyac", "measurement_error.dist_pc", "print", "print", "print", "print", "measurement_error.get_dist", "measurement_error.get_dist", "numpy.transpose", "measurement_error.get_dist", "measurement_error.get_dist"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.impute_and_correct", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.gformula", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.gformula", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.gformula", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.gformula", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.dist_pyac", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.dist_pc", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.fit_simple", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.fit_bernoulli", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.dist_pyac", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.dist_pc", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.dist_pyac", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.dist_pc", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.get_dist"], ["", "def", "train_adjust", "(", "train", ",", "test", ",", "proxy_i", "=", "1", ",", "confound_i", "=", "(", ")", ",", "debug", "=", "False", ")", ":", "\n", "  ", "'''\n  Given train and test data, train a logistic regression classifier to\n    impute a proxy for the missing variables, then calculate the errors\n    from an oracle in causal effect estimation.\n  '''", "\n", "n", "=", "test", ".", "shape", "[", "0", "]", "\n", "\n", "# use half the train set for training, half for dev and error calculation", "\n", "num_train", "=", "train", ".", "shape", "[", "1", "]", "//", "2", "\n", "\n", "truth", "=", "test", "[", ":", "3", ",", ":", "]", "\n", "new_dist", ",", "proxy", "=", "impute_and_correct", "(", "train", ",", "test", ",", "n", ",", "num_train", ",", "\n", "proxy_i", ",", "confound_i", ",", "debug", ")", "\n", "\n", "oracle_effect", "=", "gformula", "(", "dist_pyac", "(", "get_dist", "(", "truth", ")", ")", ",", "dist_pc", "(", "get_dist", "(", "truth", ")", ")", ")", "\n", "\n", "# Instead of training our model for the mismeasurement, just report", "\n", "#   the causal effect present in the training dataset", "\n", "naive_effect", "=", "gformula", "(", "fit_simple", "(", "\n", "np", ".", "transpose", "(", "train", "[", ":", "2", ",", ":", "]", ")", ",", "train", "[", "2", ",", ":", "]", ")", ",", "\n", "fit_bernoulli", "(", "train", "[", "0", ",", ":", "]", ")", ")", "\n", "\n", "misspecified_effect", "=", "gformula", "(", "dist_pyac", "(", "get_dist", "(", "proxy", ")", ")", ",", "dist_pc", "(", "get_dist", "(", "proxy", ")", ")", ")", "\n", "corrected_effect", "=", "gformula", "(", "dist_pyac", "(", "new_dist", ")", ",", "dist_pc", "(", "new_dist", ")", ")", "\n", "\n", "if", "debug", ":", "\n", "    ", "print", "(", "\"True dist gives effect: {:0.3f}\"", ".", "format", "(", "oracle_effect", ")", ")", "\n", "print", "(", "\"Naive approach gives effect: {:0.3f}\"", ".", "format", "(", "naive_effect", ")", ")", "\n", "print", "(", "\"Misspecified dist gives effect: {:0.3f}\"", ".", "format", "(", "misspecified_effect", ")", ")", "\n", "print", "(", "\"corrected dist gives effect: {:0.3f}\"", ".", "format", "(", "corrected_effect", ")", ")", "\n", "\n", "", "return", "[", "(", "x", "-", "oracle_effect", ")", "**", "2", "\n", "for", "x", "in", "(", "naive_effect", ",", "misspecified_effect", ",", "corrected_effect", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.synthetic": [[299, 326], ["numpy.random.seed", "datasets.synthetic_config.copy", "synthetic_config.copy.update", "datasets.SyntheticData", "datasets.SyntheticData.sample_truth", "datasets.SyntheticData.sample_text", "datasets.SyntheticData.sample_truth", "datasets.SyntheticData.sample_text", "kwargs.get", "measurement_error.train_adjust", "synthetic_config.copy.get", "numpy.concatenate", "numpy.concatenate", "numpy.array", "numpy.transpose", "numpy.array", "numpy.transpose"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.SyntheticData.sample_truth", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.SyntheticData.sample_text", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.SyntheticData.sample_truth", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.SyntheticData.sample_text", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.train_adjust"], ["", "def", "synthetic", "(", "n_examples", ",", "n_train", ",", "**", "kwargs", ")", ":", "\n", "  ", "'''\n  Run a synthetic experiment using n_examples examples in target dataset p(A*, C, Y)\n  and n_train examples of external data to estimate p(A*, A)\n  '''", "\n", "np", ".", "random", ".", "seed", "(", "42", ")", "\n", "\n", "proxy_i", "=", "1", "\n", "confound_i", "=", "(", "0", ",", "2", ",", ")", "\n", "\n", "config", "=", "synthetic_config", ".", "copy", "(", ")", "\n", "config", ".", "update", "(", "kwargs", ")", "\n", "assert", "config", ".", "get", "(", "'vocab_size'", ")", "is", "not", "None", ",", "\"Must specify synthetic data vocab_size\"", "\n", "\n", "sampler", "=", "SyntheticData", "(", "**", "config", ")", "\n", "\n", "truth", "=", "sampler", ".", "sample_truth", "(", "n_examples", ")", "\n", "truth_t", "=", "sampler", ".", "sample_text", "(", "truth", "[", "proxy_i", "]", ")", "\n", "external", "=", "sampler", ".", "sample_truth", "(", "n_train", ")", "\n", "external_t", "=", "sampler", ".", "sample_text", "(", "external", "[", "proxy_i", "]", ")", "\n", "\n", "debug", "=", "kwargs", ".", "get", "(", "'debug'", ",", "False", ")", "\n", "\n", "return", "train_adjust", "(", "\n", "np", ".", "concatenate", "(", "(", "np", ".", "array", "(", "external", ")", ",", "np", ".", "transpose", "(", "external_t", ")", ")", ",", "axis", "=", "0", ")", ",", "\n", "np", ".", "concatenate", "(", "(", "np", ".", "array", "(", "truth", ")", ",", "np", ".", "transpose", "(", "truth_t", ")", ")", ",", "axis", "=", "0", ")", ",", "\n", "proxy_i", ",", "confound_i", ",", "debug", "=", "debug", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.yelp": [[328, 348], ["datasets.synthetic_config.copy", "synthetic_config.copy.update", "datasets.YelpData", "datasets.YelpData.load", "datasets.YelpData.load", "kwargs.get", "measurement_error.train_adjust", "numpy.transpose", "numpy.transpose"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.YelpData.load", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.YelpData.load", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.train_adjust"], ["", "def", "yelp", "(", "n_examples", ",", "n_train", ",", "**", "kwargs", ")", ":", "\n", "  ", "'''\n  Run a Yelp experiment using n_examples examples in target dataset p(A*, C, Y)\n  and n_train examples of external data to estimate p(A*, A)\n  '''", "\n", "proxy_i", "=", "1", "\n", "confound_i", "=", "(", "0", ",", "2", ",", ")", "\n", "\n", "args", "=", "synthetic_config", ".", "copy", "(", ")", "\n", "args", ".", "update", "(", "kwargs", ")", "\n", "\n", "sampler", "=", "YelpData", "(", "**", "args", ")", "\n", "truth", "=", "sampler", ".", "load", "(", "n_examples", ")", "\n", "external", "=", "sampler", ".", "load", "(", "n_train", ")", "\n", "\n", "debug", "=", "kwargs", ".", "get", "(", "'debug'", ",", "False", ")", "\n", "\n", "return", "train_adjust", "(", "\n", "np", ".", "transpose", "(", "external", ")", ",", "np", ".", "transpose", "(", "truth", ")", ",", "\n", "proxy_i", ",", "confound_i", ",", "debug", "=", "debug", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.measurement_error.main": [[350, 415], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "int", "max", "os.path.exists", "range", "numpy.array", "numpy.nanmean", "range", "print", "os.path.exists", "logging.error", "os.path.join", "logging.error", "np.array.append", "numpy.sqrt", "print", "print", "len", "outlines.append", "open", "outf.write", "ValueError", "print", "test_func", "numpy.nanstd", "json.dumps", "print", "os.path.join", "sum", "sum", "numpy.isnan", "numpy.isnan"], "function", ["None"], ["", "def", "main", "(", ")", ":", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"logn_examples\"", ",", "type", "=", "float", ",", "help", "=", "\"how many examples (log 10)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--k\"", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "\"how many runs for each?\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "type", "=", "str", ",", "default", "=", "'synthetic'", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_freq\"", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "\"min freq for yelp data vocabulary\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocab_size\"", ",", "type", "=", "int", ",", "default", "=", "4334", ",", "\n", "help", "=", "\"vocab size for synthetic data\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_vocab\"", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"how many examples to use to build vocab\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--debug\"", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--workdir\"", ",", "type", "=", "str", ",", "default", "=", "'work/'", ")", "\n", "parser", ".", "add_argument", "(", "\"--outdir\"", ",", "type", "=", "str", ",", "default", "=", "\"results/\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "n_examples", "=", "int", "(", "10", "**", "args", ".", "logn_examples", ")", "\n", "n_train", "=", "max", "(", "1000", ",", "n_examples", "//", "10", ")", "\n", "if", "args", ".", "debug", ":", "\n", "    ", "print", "(", "\"measure\"", ",", "n_examples", ",", "n_train", ",", "args", ".", "k", ",", "args", ".", "dataset", ",", "args", ".", "min_freq", ")", "\n", "\n", "", "outfn", "=", "\"me.{}.{}.{}.{}.json\"", ".", "format", "(", "args", ".", "dataset", ",", "args", ".", "logn_examples", ",", "args", ".", "k", ",", "args", ".", "min_freq", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "outdir", ")", ":", "\n", "    ", "logging", ".", "error", "(", "\"{} doesn't exist, quitting\"", ".", "format", "(", "args", ".", "outdir", ")", ")", "\n", "return", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "args", ".", "outdir", ",", "outfn", ")", ")", ":", "\n", "    ", "logging", ".", "error", "(", "\"{} already exists, quitting\"", ".", "format", "(", "outfn", ")", ")", "\n", "return", "\n", "\n", "", "job_args", "=", "{", "'debug'", ":", "args", ".", "debug", "}", "\n", "if", "args", ".", "dataset", "==", "'synthetic'", ":", "\n", "    ", "test_func", "=", "synthetic", "\n", "job_args", "[", "'vocab_size'", "]", "=", "args", ".", "vocab_size", "\n", "", "elif", "args", ".", "dataset", "==", "'yelp'", ":", "\n", "    ", "test_func", "=", "yelp", "\n", "job_args", "[", "'workdir'", "]", "=", "args", ".", "workdir", "\n", "job_args", "[", "'n_vocab'", "]", "=", "args", ".", "n_vocab", "\n", "job_args", "[", "'min_freq'", "]", "=", "args", ".", "min_freq", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"unknown dataset {}\"", ".", "format", "(", "args", ".", "dataset", ")", ")", "\n", "\n", "", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "args", ".", "k", ")", ":", "\n", "    ", "if", "args", ".", "debug", ":", "\n", "      ", "print", "(", "\" {} \"", ".", "format", "(", "i", ")", ",", "end", "=", "'\\r'", ")", "\n", "", "results", ".", "append", "(", "test_func", "(", "n_examples", ",", "n_train", ",", "**", "job_args", ")", ")", "\n", "\n", "", "results", "=", "np", ".", "array", "(", "results", ")", "\n", "means", "=", "np", ".", "nanmean", "(", "results", ",", "axis", "=", "0", ")", "\n", "sems", "=", "1.96", "*", "np", ".", "nanstd", "(", "results", ",", "axis", "=", "0", ")", "/", "np", ".", "sqrt", "(", "n_examples", ")", "\n", "models", "=", "[", "'naive'", ",", "\"misspecified\"", ",", "'correct'", "]", "\n", "\n", "if", "args", ".", "debug", ":", "\n", "    ", "print", "(", "\"Missp NaNs: {} of {}\"", ".", "format", "(", "sum", "(", "np", ".", "isnan", "(", "results", "[", ":", ",", "1", "]", ")", ")", ",", "args", ".", "k", ")", ")", "\n", "print", "(", "\"Correct NaNs: {} of {}\"", ".", "format", "(", "sum", "(", "np", ".", "isnan", "(", "results", "[", ":", ",", "2", "]", ")", ")", ",", "args", ".", "k", ")", ")", "\n", "\n", "", "outlines", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "models", ")", ")", ":", "\n", "    ", "outlines", ".", "append", "(", "json", ".", "dumps", "(", "{", "\n", "'model'", ":", "models", "[", "i", "]", ",", "'n'", ":", "n_examples", ",", "'err'", ":", "means", "[", "i", "]", ",", "'se'", ":", "sems", "[", "i", "]", "}", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "      ", "print", "(", "\"{:8s} {:8.2e} {:8.2e}\"", ".", "format", "(", "models", "[", "i", "]", ",", "means", "[", "i", "]", ",", "sems", "[", "i", "]", ")", ")", "\n", "\n", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "outdir", ",", "outfn", ")", ",", "\"w\"", ")", "as", "outf", ":", "\n", "    ", "outf", ".", "write", "(", "\"\\n\"", ".", "join", "(", "outlines", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.maybe_stack": [[7, 19], ["type", "any", "numpy.concatenate", "len", "inp.reshape", "numpy.concatenate", "len", "x.reshape", "len"], "function", ["None"], ["def", "maybe_stack", "(", "inp", ")", ":", "\n", "  ", "''' If inp is a list or tuple, concatenate along axis 1'''", "\n", "if", "type", "(", "inp", ")", "in", "[", "list", ",", "tuple", "]", ":", "\n", "    ", "if", "any", "(", "len", "(", "x", ".", "shape", ")", "==", "1", "for", "x", "in", "inp", ")", ":", "\n", "      ", "inp", "=", "[", "x", ".", "reshape", "(", "-", "1", ",", "1", ")", "if", "len", "(", "x", ".", "shape", ")", "==", "1", "else", "x", "for", "x", "in", "inp", "]", "\n", "return", "np", ".", "concatenate", "(", "inp", ",", "axis", "=", "1", ")", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "inp", ",", "axis", "=", "1", ")", "\n", "\n", "", "if", "len", "(", "inp", ".", "shape", ")", "==", "1", ":", "\n", "    ", "return", "inp", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "", "return", "inp", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.naive": [[21, 37], ["numpy.stack", "numpy.sum", "numpy.sum", "numpy.where"], "function", ["None"], ["", "def", "naive", "(", "truth", ")", ":", "\n", "  ", "'''\n  Given a (c, a, y) dataset of confounder, treatment, outcome\n  Calculate the causal effect assuming no confounding or mismeasurement\n    as p(Y=1 | A=1) - p(Y=1 | A=0).\n  '''", "\n", "v", "=", "np", ".", "stack", "(", "truth", ",", "axis", "=", "0", ")", "\n", "\n", "tot_effect", "=", "0", "\n", "for", "a", "in", "[", "0", ",", "1", "]", ":", "\n", "    ", "where", "=", "(", "v", "[", "1", ",", ":", "]", "==", "a", ")", "\n", "y_true", "=", "np", ".", "sum", "(", "v", "[", ":", ",", "np", ".", "where", "(", "where", ")", "]", "[", "2", ",", ":", "]", ")", "\n", "y_tot", "=", "np", ".", "sum", "(", "where", ")", "\n", "tot_effect", "+=", "(", "-", "1", ",", "1", ")", "[", "a", "]", "*", "(", "y_true", "/", "y_tot", ")", "\n", "\n", "", "return", "tot_effect", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.fit_bernoulli": [[39, 43], ["numpy.sum", "len"], "function", ["None"], ["", "def", "fit_bernoulli", "(", "v", ")", ":", "\n", "  ", "''' Calculate p(C=1) for a binary variable '''", "\n", "assert", "len", "(", "v", ".", "shape", ")", "==", "1", "or", "v", ".", "shape", "[", "1", "]", "==", "1", "\n", "return", "np", ".", "sum", "(", "v", ")", "/", "v", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.fit_simple": [[45, 66], ["utils.maybe_stack", "list", "itertools.product", "numpy.all", "numpy.sum", "numpy.sum", "numpy.stack", "max", "range", "tuple", "range", "len", "range"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.maybe_stack"], ["", "def", "fit_simple", "(", "inp", ",", "out", ")", ":", "\n", "  ", "'''\n    inp is a n x k matrix of features (e.g. c, a)\n    out is a n x 1 matrix of targets (e.g. y)\n    Simply calculate the 2 ** k truth table probabilities\n  '''", "\n", "inp", "=", "maybe_stack", "(", "inp", ")", "\n", "n", "=", "inp", ".", "shape", "[", "0", "]", "\n", "assert", "out", ".", "shape", "[", "0", "]", "==", "n", "\n", "k", "=", "inp", ".", "shape", "[", "1", "]", "\n", "\n", "dist", "=", "{", "}", "\n", "assns", "=", "list", "(", "itertools", ".", "product", "(", "*", "[", "range", "(", "2", ")", "for", "_", "in", "range", "(", "k", ")", "]", ")", ")", "\n", "for", "assn", "in", "assns", ":", "\n", "    ", "where", "=", "[", "inp", "[", ":", ",", "i", "]", "==", "assn", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "assn", ")", ")", "]", "\n", "where", "=", "np", ".", "all", "(", "np", ".", "stack", "(", "where", ",", "axis", "=", "0", ")", ",", "axis", "=", "0", ")", "\n", "y_true", "=", "np", ".", "sum", "(", "out", "[", "where", "]", ")", "\n", "y_tot", "=", "np", ".", "sum", "(", "where", ")", "\n", "dist", "[", "tuple", "(", "assn", ")", "]", "=", "y_true", "/", "max", "(", "1", ",", "y_tot", ")", "\n", "\n", "", "return", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.fit_logis": [[68, 81], ["utils.maybe_stack", "sklearn.linear_model.LogisticRegression", "sklearn.linear_model.LogisticRegression.fit"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.maybe_stack"], ["", "def", "fit_logis", "(", "inp", ",", "out", ")", ":", "\n", "  ", "'''\n    inp is a n x k matrix of features (e.g. c, y, t_i)\n    out is a n x 1 matrix of targets (e.g. a)\n    Fit a logistic regression classifier to predict the target\n  '''", "\n", "inp", "=", "maybe_stack", "(", "inp", ")", "\n", "n", "=", "inp", ".", "shape", "[", "0", "]", "\n", "assert", "out", ".", "shape", "[", "0", "]", "==", "n", "\n", "\n", "model", "=", "sklearn", ".", "linear_model", ".", "LogisticRegression", "(", "C", "=", "1e8", ")", "\n", "model", ".", "fit", "(", "inp", ",", "out", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.logis_proba": [[83, 91], ["utils.maybe_stack", "model.predict_proba().reshape", "model.predict_proba"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.maybe_stack"], ["", "def", "logis_proba", "(", "model", ",", "inp", ")", ":", "\n", "  ", "'''\n    inp is a n x k matrix of features\n    model is a logistic regression classifier\n    Uses the model to infer the targets \n  '''", "\n", "inp", "=", "maybe_stack", "(", "inp", ")", "\n", "return", "model", ".", "predict_proba", "(", "inp", ")", ".", "reshape", "(", "-", "1", ")", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.gformula": [[93, 107], ["None"], "function", ["None"], ["", "def", "gformula", "(", "pyac", ",", "pc", ")", ":", "\n", "  ", "'''\n  pyac: truth table probabilities for p(Y | A, C)\n  pc: bernoulli probability of p(C)\n  Use the g-formula to calculate the causal effect of A on Y given C\n    Assumes no mismeasurement.\n  '''", "\n", "tot_effect", "=", "0", "\n", "for", "a", "in", "[", "0", ",", "1", "]", ":", "\n", "    ", "a_multiplier", "=", "(", "-", "1", ",", "1", ")", "[", "a", "]", "\n", "for", "c", "in", "[", "0", ",", "1", "]", ":", "\n", "      ", "my_pc", "=", "(", "1", "-", "pc", ",", "pc", ")", "[", "c", "]", "\n", "tot_effect", "+=", "a_multiplier", "*", "pyac", "[", "(", "c", ",", "a", ")", "]", "*", "my_pc", "\n", "", "", "return", "tot_effect", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.mcar": [[109, 115], ["numpy.random.binomial"], "function", ["None"], ["", "def", "mcar", "(", "truth", ",", "prob", ")", ":", "\n", "  ", "'''\n  Given some truth vector, introduce MCAR missingness with prob.\n  '''", "\n", "n", "=", "truth", ".", "shape", "[", "0", "]", "\n", "return", "np", ".", "random", ".", "binomial", "(", "1", ",", "prob", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.impute": [[117, 128], ["utils.fit_logis", "utils.maybe_stack", "fit_logis.predict_proba", "print", "fit_logis.score"], "function", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.fit_logis", "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.maybe_stack"], ["", "def", "impute", "(", "features", ",", "targets", ",", "test_features", ",", "debug", "=", "False", ")", ":", "\n", "  ", "'''\n  Given some training features, training targets, and test features\n    Train a logistic model to predict targets from features,\n    then use that model to impute test targets from test features.\n  '''", "\n", "model", "=", "fit_logis", "(", "features", ",", "targets", ")", "\n", "if", "debug", ":", "\n", "    ", "print", "(", "\"acc:\"", ",", "model", ".", "score", "(", "features", ",", "targets", ")", ")", "\n", "", "test_features", "=", "maybe_stack", "(", "test_features", ")", "\n", "return", "model", ".", "predict_proba", "(", "test_features", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.YelpData.__init__": [[19, 41], ["os.path.exists", "IOError", "gzip.open", "json.loads", "len", "os.path.join", "os.path.join", "inf.readline().decode", "numpy.random.normal", "inf.readline"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "workdir", ",", "n_vocab", ",", "min_freq", "=", "1000", ",", "**", "kwargs", ")", ":", "\n", "    ", "''' Create a Yelp dataset '''", "\n", "\n", "vocabfn", "=", "\"vocab.{}.{}.gz\"", ".", "format", "(", "n_vocab", ",", "min_freq", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "workdir", ",", "vocabfn", ")", ")", ":", "\n", "      ", "raise", "IOError", "(", "\"can't find {} to calculate vocab size\"", ".", "format", "(", "vocabfn", ")", ")", "\n", "\n", "", "with", "gzip", ".", "open", "(", "os", ".", "path", ".", "join", "(", "workdir", ",", "vocabfn", ")", ")", "as", "inf", ":", "\n", "      ", "vocab", "=", "json", ".", "loads", "(", "inf", ".", "readline", "(", ")", ".", "decode", "(", ")", ")", "\n", "self", ".", "vocab_size", "=", "len", "(", "vocab", ")", "\n", "\n", "", "self", ".", "workdir", "=", "workdir", "\n", "self", ".", "n_vocab", "=", "n_vocab", "\n", "\n", "self", ".", "missing_bias", "=", "kwargs", "[", "'missing_bias'", "]", "\n", "self", ".", "missing_effect_std", "=", "kwargs", "[", "'missing_effect_std'", "]", "\n", "self", ".", "missing_effects", "=", "(", "\n", "*", "kwargs", "[", "'missing_effects'", "]", ",", "\n", "*", "np", ".", "random", ".", "normal", "(", "0", ",", "self", ".", "missing_effect_std", ",", "self", ".", "vocab_size", ")", ")", "\n", "self", ".", "min_freq", "=", "min_freq", "\n", "self", ".", "dataset", "=", "[", "]", "\n", "self", ".", "max_seen", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.YelpData.load": [[42, 86], ["len", "len", "numpy.array", "numpy.array", "ValueError", "numpy.array", "os.path.exists", "logging.error", "gzip.open", "len", "len", "numpy.array", "os.path.join", "os.path.join", "numpy.array.append", "json.loads", "len", "line.decode"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "num_examples", ",", "allow_overlap", "=", "False", ",", "enforce_full", "=", "True", ")", ":", "\n", "    ", "'''\n    Load num_examples from files and return a numpy array.\n    allow_overlap: subsequent calls to load() can re-use data from previous calls.\n    enforce_full: if we haven't preprocessed enough data, raise an error.\n    '''", "\n", "\n", "if", "len", "(", "self", ".", "dataset", ")", ">=", "num_examples", ":", "\n", "      ", "if", "allow_overlap", ":", "\n", "        ", "return", "np", ".", "array", "(", "self", ".", "dataset", "[", ":", "num_examples", "]", ")", "\n", "", "else", ":", "\n", "        ", "if", "len", "(", "self", ".", "dataset", ")", ">=", "num_examples", "+", "self", ".", "max_seen", ":", "\n", "          ", "return", "np", ".", "array", "(", "self", ".", "dataset", "[", "self", ".", "max_seen", ":", "self", ".", "max_seen", "+", "num_examples", "]", ")", "\n", "\n", "", "", "", "part", "=", "0", "\n", "dataset", "=", "[", "]", "\n", "total_to_load", "=", "num_examples", "\n", "if", "not", "allow_overlap", ":", "\n", "      ", "total_to_load", "+=", "self", ".", "max_seen", "\n", "\n", "", "while", "len", "(", "dataset", ")", "<", "total_to_load", ":", "\n", "      ", "infn", "=", "\"yelpdata.{}.{}.{}.gz\"", ".", "format", "(", "self", ".", "n_vocab", ",", "self", ".", "min_freq", ",", "part", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "workdir", ",", "infn", ")", ")", ":", "\n", "        ", "logging", ".", "error", "(", "\"stopping before part #{}, {} doesn't exist\"", ".", "format", "(", "part", ",", "infn", ")", ")", "\n", "break", "\n", "", "with", "gzip", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "workdir", ",", "infn", ")", ",", "\"rb\"", ")", "as", "inf", ":", "\n", "        ", "for", "line", "in", "inf", ":", "\n", "          ", "dataset", ".", "append", "(", "json", ".", "loads", "(", "line", ".", "decode", "(", ")", ")", ")", "\n", "if", "len", "(", "dataset", ")", ">", "total_to_load", ":", "\n", "            ", "break", "\n", "\n", "", "", "", "part", "+=", "1", "\n", "\n", "", "self", ".", "dataset", "=", "dataset", "\n", "if", "allow_overlap", ":", "\n", "      ", "dataset", "=", "np", ".", "array", "(", "dataset", "[", ":", "num_examples", "]", ")", "\n", "", "else", ":", "\n", "      ", "dataset", "=", "np", ".", "array", "(", "dataset", "[", "self", ".", "max_seen", ":", "self", ".", "max_seen", "+", "num_examples", "]", ")", "\n", "\n", "", "if", "len", "(", "dataset", ")", "<", "num_examples", "and", "enforce_full", ":", "\n", "      ", "raise", "ValueError", "(", "\"Unable to find {} examples for Yelp dataset\"", ".", "format", "(", "num_examples", ")", ")", "\n", "\n", "", "self", ".", "max_seen", "+=", "num_examples", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.YelpData.mar": [[87, 97], ["utils.maybe_stack", "numpy.clip", "numpy.random.binomial", "numpy.dot", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.maybe_stack"], ["", "def", "mar", "(", "self", ",", "truth", ",", "confounds", ")", ":", "\n", "    ", "'''\n    Return a MAR missingness mask of which examples should have the treatment hidden.\n    '''", "\n", "n", "=", "truth", ".", "shape", "[", "0", "]", "\n", "confounds", "=", "maybe_stack", "(", "confounds", ")", "\n", "\n", "prob", "=", "np", ".", "ones", "(", "n", ")", "*", "self", ".", "missing_bias", "+", "np", ".", "dot", "(", "confounds", ",", "self", ".", "missing_effects", ")", "\n", "prob", "=", "np", ".", "clip", "(", "prob", ",", "0.01", ",", "0.99", ")", "\n", "return", "np", ".", "random", ".", "binomial", "(", "1", ",", "prob", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.SyntheticData.__init__": [[100, 132], ["max", "numpy.concatenate", "numpy.random.shuffle", "numpy.ones", "numpy.random.choice", "numpy.random.normal", "range", "numpy.ones", "numpy.zeros", "numpy.random.normal"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "    ", "''' Create a synthetic dataset '''", "\n", "\n", "self", ".", "c_bias", "=", "0.4", "\n", "self", ".", "a_bias", "=", "0.40", "\n", "self", ".", "ca_effect", "=", "-", "0.3", "\n", "self", ".", "y_bias", "=", "0.5", "\n", "self", ".", "cy_effect", "=", "0.2", "\n", "self", ".", "ay_effect", "=", "0.1", "\n", "\n", "self", ".", "vocab_size", "=", "kwargs", "[", "'vocab_size'", "]", "\n", "self", ".", "topic_std", "=", "kwargs", "[", "'topic_std'", "]", "\n", "self", ".", "topic_bias", "=", "np", ".", "ones", "(", "self", ".", "vocab_size", ")", "*", "0.5", "\n", "self", ".", "topic_effects", "=", "[", "np", ".", "random", ".", "choice", "(", "[", "-", "1.", ",", "1.", "]", ",", "self", ".", "vocab_size", ")", "*", "\n", "np", ".", "random", ".", "normal", "(", "0", ",", "self", ".", "topic_std", ",", "self", ".", "vocab_size", ")", "\n", "for", "_", "in", "range", "(", "3", ")", "]", "\n", "\n", "# NOTE This is a way to prevent the measurement error classifier from getting perfect", "\n", "#      accuracy on the synthetic data. When vocab size increases, sufficient training", "\n", "#      data make it possible to get 100% accuracy. If many \"words\"", "\n", "#      have no association with the treatment, the logistic regression gets harder.", "\n", "num_nonzero_effects", "=", "max", "(", "100", ",", "self", ".", "vocab_size", "//", "50", ")", "\n", "self", ".", "topic_effects_mask", "=", "np", ".", "concatenate", "(", "\n", "[", "np", ".", "ones", "(", "num_nonzero_effects", ")", ",", "np", ".", "zeros", "(", "self", ".", "vocab_size", "-", "num_nonzero_effects", ")", "]", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "self", ".", "topic_effects_mask", ")", "\n", "self", ".", "topic_effects", "*=", "self", ".", "topic_effects_mask", "\n", "\n", "self", ".", "missing_bias", "=", "kwargs", "[", "'missing_bias'", "]", "\n", "self", ".", "missing_effect_std", "=", "kwargs", "[", "'missing_effect_std'", "]", "\n", "self", ".", "missing_effects", "=", "(", "\n", "*", "kwargs", "[", "'missing_effects'", "]", ",", "\n", "*", "np", ".", "random", ".", "normal", "(", "0", ",", "self", ".", "missing_effect_std", ",", "self", ".", "vocab_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.SyntheticData.sample_truth": [[133, 144], ["numpy.random.choice", "numpy.random.binomial", "numpy.random.binomial", "numpy.ones", "numpy.ones"], "methods", ["None"], ["", "def", "sample_truth", "(", "self", ",", "n", ")", ":", "\n", "    ", "''' Sample n (c, a, y) examples from our synthetic distribution '''", "\n", "c", "=", "np", ".", "random", ".", "choice", "(", "[", "0", ",", "1", "]", ",", "n", ",", "p", "=", "(", "1", "-", "self", ".", "c_bias", ",", "self", ".", "c_bias", ")", ")", "\n", "\n", "a_prob", "=", "self", ".", "a_bias", "*", "np", ".", "ones", "(", "n", ")", "+", "self", ".", "ca_effect", "*", "c", "\n", "a", "=", "np", ".", "random", ".", "binomial", "(", "1", ",", "a_prob", ",", "n", ")", "\n", "\n", "y_prob", "=", "self", ".", "y_bias", "*", "np", ".", "ones", "(", "n", ")", "+", "self", ".", "cy_effect", "*", "c", "+", "self", ".", "ay_effect", "*", "a", "\n", "y", "=", "np", ".", "random", ".", "binomial", "(", "1", ",", "y_prob", ",", "n", ")", "\n", "\n", "return", "(", "c", ",", "a", ",", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.SyntheticData.sample_text": [[145, 160], ["utils.maybe_stack", "numpy.tile().reshape", "range", "numpy.clip", "range", "numpy.array", "numpy.array.append", "numpy.tile", "truth[].reshape", "numpy.tile().reshape", "numpy.tile", "numpy.random.random"], "methods", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.maybe_stack"], ["", "def", "sample_text", "(", "self", ",", "truth", ")", ":", "\n", "    ", "''' Sample text variables from the (c, a, y) truth variables '''", "\n", "truth", "=", "maybe_stack", "(", "truth", ")", "\n", "n", "=", "truth", ".", "shape", "[", "0", "]", "\n", "topic", "=", "np", ".", "tile", "(", "self", ".", "topic_bias", ",", "n", ")", ".", "reshape", "(", "n", ",", "self", ".", "vocab_size", ")", "\n", "for", "i", "in", "range", "(", "truth", ".", "shape", "[", "1", "]", ")", ":", "\n", "      ", "topic", "+=", "truth", "[", ":", ",", "i", "]", ".", "reshape", "(", "n", ",", "1", ")", "*", "np", ".", "tile", "(", "\n", "self", ".", "topic_effects", "[", "i", "]", ",", "n", ")", ".", "reshape", "(", "n", ",", "self", ".", "vocab_size", ")", "\n", "", "topic", "=", "np", ".", "clip", "(", "topic", ",", "0.01", ",", "0.99", ")", "\n", "words", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "      ", "word", "=", "(", "np", ".", "random", ".", "random", "(", "self", ".", "vocab_size", ")", "<", "topic", "[", "i", "]", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "words", ".", "append", "(", "word", ")", "\n", "", "words", "=", "np", ".", "array", "(", "words", ")", "\n", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.datasets.SyntheticData.mar": [[161, 169], ["utils.maybe_stack", "numpy.clip", "numpy.random.binomial", "numpy.dot", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.zachwooddoughty_emnlp2018-causal.None.utils.maybe_stack"], ["", "def", "mar", "(", "self", ",", "truth", ",", "confounds", ")", ":", "\n", "    ", "''' Return a MAR missingness mask of which examples should have the treatment hidden. '''", "\n", "n", "=", "truth", ".", "shape", "[", "0", "]", "\n", "confounds", "=", "maybe_stack", "(", "confounds", ")", "\n", "\n", "prob", "=", "np", ".", "ones", "(", "n", ")", "*", "self", ".", "missing_bias", "+", "np", ".", "dot", "(", "confounds", ",", "self", ".", "missing_effects", ")", "\n", "prob", "=", "np", ".", "clip", "(", "prob", ",", "0.01", ",", "0.99", ")", "\n", "return", "np", ".", "random", ".", "binomial", "(", "1", ",", "prob", ",", "n", ")", "\n", "", "", ""]]}