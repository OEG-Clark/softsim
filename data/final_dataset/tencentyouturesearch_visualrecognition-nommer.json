{"home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.config._update_config_from_file": [[173, 184], ["config.defrost", "yaml.load.setdefault", "print", "config.merge_from_file", "config.freeze", "open", "yaml.load", "config._update_config_from_file", "os.path.join", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.config._update_config_from_file"], ["def", "_update_config_from_file", "(", "config", ",", "cfg_file", ")", ":", "\n", "    ", "config", ".", "defrost", "(", ")", "\n", "with", "open", "(", "cfg_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "yaml_cfg", "=", "yaml", ".", "load", "(", "f", ",", "Loader", "=", "yaml", ".", "FullLoader", ")", "\n", "\n", "", "for", "cfg", "in", "yaml_cfg", ".", "setdefault", "(", "'BASE'", ",", "[", "''", "]", ")", ":", "\n", "        ", "if", "cfg", ":", "\n", "            ", "_update_config_from_file", "(", "config", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "cfg_file", ")", ",", "cfg", ")", ")", "\n", "", "", "print", "(", "'=> merge config from {}'", ".", "format", "(", "cfg_file", ")", ")", "\n", "config", ".", "merge_from_file", "(", "cfg_file", ")", "\n", "config", ".", "freeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.config.update_config": [[186, 228], ["config._update_config_from_file", "config.defrost", "os.path.join", "config.freeze", "config.merge_from_list"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.config._update_config_from_file"], ["", "def", "update_config", "(", "config", ",", "args", ")", ":", "\n", "    ", "_update_config_from_file", "(", "config", ",", "args", ".", "cfg", ")", "\n", "\n", "config", ".", "defrost", "(", ")", "\n", "if", "args", ".", "opts", ":", "\n", "        ", "config", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "\n", "# merge from specific arguments", "\n", "", "if", "args", ".", "batch_size", ":", "\n", "        ", "config", ".", "DATA", ".", "BATCH_SIZE", "=", "args", ".", "batch_size", "\n", "", "if", "args", ".", "data_path", ":", "\n", "        ", "config", ".", "DATA", ".", "DATA_PATH", "=", "args", ".", "data_path", "\n", "", "if", "args", ".", "zip", ":", "\n", "        ", "config", ".", "DATA", ".", "ZIP_MODE", "=", "True", "\n", "", "if", "args", ".", "cache_mode", ":", "\n", "        ", "config", ".", "DATA", ".", "CACHE_MODE", "=", "args", ".", "cache_mode", "\n", "", "if", "args", ".", "resume", ":", "\n", "        ", "config", ".", "MODEL", ".", "RESUME", "=", "args", ".", "resume", "\n", "", "if", "args", ".", "accumulation_steps", ":", "\n", "        ", "config", ".", "TRAIN", ".", "ACCUMULATION_STEPS", "=", "args", ".", "accumulation_steps", "\n", "", "if", "args", ".", "use_checkpoint", ":", "\n", "        ", "config", ".", "TRAIN", ".", "USE_CHECKPOINT", "=", "True", "\n", "", "if", "args", ".", "amp_opt_level", ":", "\n", "        ", "config", ".", "AMP_OPT_LEVEL", "=", "args", ".", "amp_opt_level", "\n", "", "if", "args", ".", "output", ":", "\n", "        ", "config", ".", "OUTPUT", "=", "args", ".", "output", "\n", "", "if", "args", ".", "tag", ":", "\n", "        ", "config", ".", "TAG", "=", "args", ".", "tag", "\n", "", "if", "args", ".", "eval", ":", "\n", "        ", "config", ".", "EVAL_MODE", "=", "True", "\n", "", "if", "args", ".", "throughput", ":", "\n", "        ", "config", ".", "THROUGHPUT_MODE", "=", "True", "\n", "", "if", "args", ".", "load_param_only", ":", "\n", "        ", "config", ".", "LOAD_PARAM_ONLY", "=", "True", "\n", "\n", "# set local rank for distributed training", "\n", "", "config", ".", "LOCAL_RANK", "=", "args", ".", "local_rank", "\n", "\n", "# output folder", "\n", "config", ".", "OUTPUT", "=", "os", ".", "path", ".", "join", "(", "config", ".", "OUTPUT", ",", "config", ".", "MODEL", ".", "NAME", ",", "config", ".", "TAG", ")", "\n", "\n", "config", ".", "freeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.config.get_config": [[230, 238], ["_C.clone", "config.update_config"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.config.update_config"], ["", "def", "get_config", "(", "args", ")", ":", "\n", "    ", "\"\"\"Get a yacs CfgNode object with default values.\"\"\"", "\n", "# Return a clone so that the defaults will not be altered", "\n", "# This is for the \"local variable\" use pattern", "\n", "config", "=", "_C", ".", "clone", "(", ")", "\n", "update_config", "(", "config", ",", "args", ")", "\n", "\n", "return", "config", "\n", "", ""]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.main.parse_option": [[38, 97], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "config.get_config"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.config.get_config"], ["", "def", "parse_option", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "'NomMer Transformer training and evaluation script'", ",", "add_help", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cfg'", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "metavar", "=", "\"FILE\"", ",", "\n", "help", "=", "'path to config file'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--opts\"", ",", "\n", "help", "=", "\"Modify config options by adding 'KEY VALUE' pairs. \"", ",", "\n", "default", "=", "None", ",", "\n", "nargs", "=", "'+'", ",", "\n", ")", "\n", "\n", "# easy config modification", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "type", "=", "int", ",", "help", "=", "\"batch size for single GPU\"", ")", "\n", "parser", ".", "add_argument", "(", "'--data-path'", ",", "type", "=", "str", ",", "help", "=", "'path to dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--zip'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use zipped dataset instead of folder dataset'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--cache-mode'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'part'", ",", "\n", "choices", "=", "[", "'no'", ",", "'full'", ",", "'part'", "]", ",", "\n", "help", "=", "'no: no cache, '", "\n", "'full: cache all data, '", "\n", "'part: sharding the dataset into nonoverlapping pieces and only cache one piece'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "'--resume'", ",", "help", "=", "'resume from checkpoint'", ")", "\n", "parser", ".", "add_argument", "(", "'--accumulation-steps'", ",", "type", "=", "int", ",", "help", "=", "\"gradient accumulation steps\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--use-checkpoint'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"whether to use gradient checkpointing to save memory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--amp-opt-level'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'O0'", ",", "\n", "choices", "=", "[", "'O0'", ",", "'O1'", ",", "'O2'", "]", ",", "\n", "help", "=", "'mixed precision opt level, if O0, no amp is used'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--output'", ",", "\n", "default", "=", "'output'", ",", "\n", "type", "=", "str", ",", "\n", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'root of output folder, the full path is <output>/<model_name>/<tag> (default: output)'", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "'--tag'", ",", "help", "=", "'tag of experiment'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Perform evaluation only'", ")", "\n", "parser", ".", "add_argument", "(", "'--throughput'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Test throughput only'", ")", "\n", "parser", ".", "add_argument", "(", "'--load-param-only'", ",", "action", "=", "'store_true'", ",", "help", "=", "'only load net params'", ")", "\n", "\n", "# distributed training", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "required", "=", "True", ",", "help", "=", "'local rank for DistributedDataParallel'", ")", "\n", "args", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "config", "=", "get_config", "(", "args", ")", "\n", "\n", "return", "args", ",", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.main.main": [[99, 164], ["data.build_loader", "logger.info", "models.build_model", "torch.nn.parallel.DistributedDataParallel.cuda", "logger.info", "optimizer.build_optimizer", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "sum", "logger.info", "str", "amp.initialize", "lr_scheduler.build_scheduler", "lr_scheduler.build_scheduler", "utils.auto_resume_helper", "main.throughput", "utils.load_checkpoint", "main.validate", "logger.info", "main.train", "p.numel", "len", "config.defrost", "config.freeze", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.parameters", "logger.warning", "len"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.build.build_loader", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.build.build_model", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.optimizer.build_optimizer", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.lr_scheduler.build_scheduler", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.lr_scheduler.build_scheduler", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.utils.auto_resume_helper", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.main.throughput", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.utils.load_checkpoint", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.main.validate", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.main.train"], ["", "def", "main", "(", "config", ")", ":", "\n", "# only load val datasets on eval mode", "\n", "    ", "_", ",", "dataset_val", ",", "data_loader_train", ",", "data_loader_val", ",", "mixup_fn", "=", "build_loader", "(", "config", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Creating model:{config.MODEL.TYPE}/{config.MODEL.NAME}\"", ")", "\n", "model", "=", "build_model", "(", "config", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "logger", ".", "info", "(", "str", "(", "model", ")", ")", "\n", "\n", "optimizer", "=", "build_optimizer", "(", "config", ",", "model", ")", "\n", "if", "config", ".", "AMP_OPT_LEVEL", "!=", "\"O0\"", ":", "\n", "# if you installed apex, set AMP_OPT_LEVEL ot O1 can reserve huge GPU memory", "\n", "        ", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "config", ".", "AMP_OPT_LEVEL", ")", "\n", "", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "config", ".", "LOCAL_RANK", "]", ",", "broadcast_buffers", "=", "False", ")", "\n", "model_without_ddp", "=", "model", ".", "module", "\n", "\n", "# print n_parameters of model", "\n", "n_parameters", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "logger", ".", "info", "(", "f\"number of params: {n_parameters}\"", ")", "\n", "\n", "lr_scheduler", "=", "None", "\n", "if", "data_loader_train", "is", "None", ":", "\n", "# for eval mode, do not load train datasets, so set length to 1", "\n", "        ", "lr_scheduler", "=", "build_scheduler", "(", "config", ",", "optimizer", ",", "1", ")", "\n", "", "else", ":", "\n", "        ", "lr_scheduler", "=", "build_scheduler", "(", "config", ",", "optimizer", ",", "len", "(", "data_loader_train", ")", ")", "\n", "\n", "", "max_accuracy", "=", "0.0", "\n", "if", "config", ".", "TRAIN", ".", "AUTO_RESUME", "and", "not", "config", ".", "MODEL", ".", "RESUME", ":", "\n", "# auto load latest checkpoint", "\n", "        ", "resume_file", "=", "auto_resume_helper", "(", "config", ".", "OUTPUT", ")", "\n", "if", "resume_file", ":", "\n", "            ", "if", "config", ".", "MODEL", ".", "RESUME", ":", "\n", "                ", "logger", ".", "warning", "(", "f\"auto-resume changing resume file from {config.MODEL.RESUME} to {resume_file}\"", ")", "\n", "", "config", ".", "defrost", "(", ")", "\n", "config", ".", "MODEL", ".", "RESUME", "=", "resume_file", "\n", "config", ".", "freeze", "(", ")", "\n", "logger", ".", "info", "(", "f'auto resuming from {resume_file}'", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "f'no checkpoint found in {config.OUTPUT}, ignoring auto resume'", ")", "\n", "\n", "", "", "if", "config", ".", "THROUGHPUT_MODE", ":", "\n", "# test throughput and return", "\n", "        ", "throughput", "(", "data_loader_val", ",", "model", ",", "logger", ")", "\n", "return", "\n", "\n", "", "if", "config", ".", "MODEL", ".", "RESUME", ":", "\n", "        ", "max_accuracy", "=", "load_checkpoint", "(", "config", ",", "model_without_ddp", ",", "optimizer", ",", "lr_scheduler", ",", "logger", ")", "\n", "acc1", ",", "_", ",", "_", "=", "validate", "(", "config", ",", "data_loader_val", ",", "model", ")", "\n", "logger", ".", "info", "(", "f\"Accuracy of the network on the {len(dataset_val)} test images: {acc1:.1f}%\"", ")", "\n", "if", "config", ".", "EVAL_MODE", ":", "\n", "            ", "return", "\n", "\n", "", "", "if", "data_loader_train", "is", "not", "None", ":", "\n", "        ", "train", "(", "\n", "config", ",", "\n", "model", ",", "\n", "model_without_ddp", ",", "\n", "data_loader_train", ",", "\n", "data_loader_val", ",", "\n", "dataset_val", ",", "\n", "optimizer", ",", "\n", "mixup_fn", ",", "\n", "lr_scheduler", ",", "\n", "max_accuracy", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.main.train": [[167, 231], ["logger.info", "time.time", "range", "str", "logger.info", "timm.loss.SoftTargetCrossEntropy", "data_loader_train.sampler.set_epoch", "main.train_one_epoch", "main.validate", "logger.info", "max", "logger.info", "time.time", "datetime.timedelta", "timm.loss.LabelSmoothingCrossEntropy", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.get_rank", "utils.save_checkpoint", "utils.save_checkpoint", "utils.save_checkpoint", "torch.get_rank", "int", "utils.save_checkpoint", "len"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.samplers.SubsetRandomSampler.set_epoch", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.main.train_one_epoch", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.main.validate", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.utils.save_checkpoint", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.utils.save_checkpoint", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.utils.save_checkpoint", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.utils.save_checkpoint"], ["", "", "def", "train", "(", "\n", "config", ",", "\n", "model", ",", "\n", "model_without_ddp", ",", "\n", "data_loader_train", ",", "\n", "data_loader_val", ",", "\n", "dataset_val", ",", "\n", "optimizer", ",", "\n", "mixup_fn", ",", "\n", "lr_scheduler", ",", "\n", "max_accuracy", ",", "\n", ")", ":", "\n", "\n", "    ", "logger", ".", "info", "(", "\"Start training\"", ")", "\n", "criterion", "=", "None", "\n", "if", "config", ".", "AUG", ".", "MIXUP", ">", "0.0", ":", "\n", "# smoothing is handled with mixup label transform", "\n", "        ", "criterion", "=", "SoftTargetCrossEntropy", "(", ")", "\n", "", "elif", "config", ".", "MODEL", ".", "LABEL_SMOOTHING", ">", "0.0", ":", "\n", "        ", "criterion", "=", "LabelSmoothingCrossEntropy", "(", "smoothing", "=", "config", ".", "MODEL", ".", "LABEL_SMOOTHING", ")", "\n", "", "else", ":", "\n", "        ", "criterion", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "for", "epoch", "in", "range", "(", "config", ".", "TRAIN", ".", "START_EPOCH", ",", "config", ".", "TRAIN", ".", "EPOCHS", ")", ":", "\n", "        ", "data_loader_train", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "\n", "train_one_epoch", "(", "config", ",", "model", ",", "criterion", ",", "data_loader_train", ",", "optimizer", ",", "epoch", ",", "mixup_fn", ",", "lr_scheduler", ")", "\n", "if", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "            ", "if", "epoch", "==", "(", "config", ".", "TRAIN", ".", "EPOCHS", "-", "1", ")", ":", "\n", "# save for last epoch", "\n", "                ", "save_checkpoint", "(", "config", ",", "epoch", ",", "model_without_ddp", ",", "max_accuracy", ",", "optimizer", ",", "lr_scheduler", ",", "logger", ")", "\n", "", "elif", "epoch", "%", "config", ".", "SAVE_FREQ", "==", "0", ":", "\n", "# save checkpoint every {SAVE_FREQ} epochs", "\n", "                ", "save_checkpoint", "(", "config", ",", "epoch", ",", "model_without_ddp", ",", "max_accuracy", ",", "optimizer", ",", "lr_scheduler", ",", "logger", ")", "\n", "", "if", "config", ".", "SAVE_FREQ", ">", "1", "and", "epoch", "%", "config", ".", "SAVE_FREQ", "!=", "0", ":", "\n", "# save the latest epoch's checkpoint", "\n", "                ", "save_checkpoint", "(", "\n", "config", ",", "epoch", ",", "model_without_ddp", ",", "max_accuracy", ",", "optimizer", ",", "lr_scheduler", ",", "logger", ",", "save_latest", "=", "True", "\n", ")", "\n", "\n", "", "", "acc1", ",", "_", ",", "_", "=", "validate", "(", "config", ",", "data_loader_val", ",", "model", ")", "\n", "logger", ".", "info", "(", "f\"Accuracy of the network on the {len(dataset_val)} test images: {acc1:.2f}%\"", ")", "\n", "if", "dist", ".", "get_rank", "(", ")", "==", "0", "and", "acc1", ">", "max_accuracy", ":", "\n", "# save the best checkpoint", "\n", "            ", "save_checkpoint", "(", "\n", "config", ",", "\n", "epoch", ",", "\n", "model_without_ddp", ",", "\n", "acc1", ",", "\n", "optimizer", ",", "\n", "lr_scheduler", ",", "\n", "logger", ",", "\n", "save_latest", "=", "False", ",", "\n", "save_best", "=", "True", ",", "\n", ")", "\n", "\n", "# record max accuracy while training", "\n", "", "max_accuracy", "=", "max", "(", "max_accuracy", ",", "acc1", ")", "\n", "logger", ".", "info", "(", "f'Max accuracy: {max_accuracy:.2f}%'", ")", "\n", "\n", "", "total_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "total_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_time", ")", ")", ")", "\n", "logger", ".", "info", "(", "'Training time {}'", ".", "format", "(", "total_time_str", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.main.train_one_epoch": [[233, 307], ["model.train", "optimizer.zero_grad", "len", "timm.utils.AverageMeter", "timm.utils.AverageMeter", "timm.utils.AverageMeter", "time.time", "time.time", "enumerate", "logger.info", "samples.cuda.cuda", "targets.cuda.cuda", "model", "criterion", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "timm.utils.AverageMeter.update", "timm.utils.AverageMeter.update", "timm.utils.AverageMeter.update", "time.time", "time.time", "mixup_fn", "optimizer.zero_grad", "criterion.backward", "optimizer.step", "optimizer.zero_grad", "lr_scheduler.step_update", "optimizer.step", "lr_scheduler.step_update", "criterion.item", "targets.cuda.size", "logger.info", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "utils.get_grad_norm", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "utils.get_grad_norm", "time.time", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "datetime.timedelta", "amp.master_params", "amp.master_params", "model.parameters", "model.parameters", "datetime.timedelta", "int", "int"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.main.train", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.utils.get_grad_norm", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.utils.get_grad_norm"], ["", "def", "train_one_epoch", "(", "config", ",", "model", ",", "criterion", ",", "data_loader", ",", "optimizer", ",", "epoch", ",", "mixup_fn", ",", "lr_scheduler", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "num_steps", "=", "len", "(", "data_loader", ")", "\n", "batch_time", "=", "AverageMeter", "(", ")", "\n", "loss_meter", "=", "AverageMeter", "(", ")", "\n", "norm_meter", "=", "AverageMeter", "(", ")", "\n", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "idx", ",", "(", "samples", ",", "targets", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "samples", "=", "samples", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "targets", "=", "targets", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "\n", "if", "mixup_fn", "is", "not", "None", ":", "\n", "            ", "samples", ",", "targets", "=", "mixup_fn", "(", "samples", ",", "targets", ")", "\n", "\n", "", "outputs", "=", "model", "(", "samples", ")", "\n", "loss", "=", "criterion", "(", "outputs", ",", "targets", ")", "\n", "\n", "if", "config", ".", "TRAIN", ".", "ACCUMULATION_STEPS", ">", "1", ":", "\n", "# average loss by ACCUMULATION_STEPS", "\n", "            ", "loss", "=", "loss", "/", "config", ".", "TRAIN", ".", "ACCUMULATION_STEPS", "\n", "", "else", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "if", "config", ".", "AMP_OPT_LEVEL", "!=", "\"O0\"", ":", "\n", "            ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "if", "config", ".", "TRAIN", ".", "CLIP_GRAD", ":", "\n", "                ", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "config", ".", "TRAIN", ".", "CLIP_GRAD", ")", "\n", "", "else", ":", "\n", "                ", "grad_norm", "=", "get_grad_norm", "(", "amp", ".", "master_params", "(", "optimizer", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "if", "config", ".", "TRAIN", ".", "CLIP_GRAD", ":", "\n", "                ", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "config", ".", "TRAIN", ".", "CLIP_GRAD", ")", "\n", "", "else", ":", "\n", "                ", "grad_norm", "=", "get_grad_norm", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "# for ACCUMULATION_STEPS > 1", "\n", "", "", "if", "config", ".", "TRAIN", ".", "ACCUMULATION_STEPS", ">", "1", "and", "(", "idx", "+", "1", ")", "%", "config", ".", "TRAIN", ".", "ACCUMULATION_STEPS", "==", "0", ":", "\n", "            ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "lr_scheduler", ".", "step_update", "(", "epoch", "*", "num_steps", "+", "idx", ")", "\n", "\n", "", "if", "config", ".", "TRAIN", ".", "ACCUMULATION_STEPS", "<=", "1", ":", "\n", "            ", "optimizer", ".", "step", "(", ")", "\n", "lr_scheduler", ".", "step_update", "(", "epoch", "*", "num_steps", "+", "idx", ")", "\n", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "\n", "loss_meter", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "targets", ".", "size", "(", "0", ")", ")", "\n", "norm_meter", ".", "update", "(", "grad_norm", ")", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "# print logs while training", "\n", "if", "idx", "%", "config", ".", "PRINT_FREQ", "==", "0", ":", "\n", "            ", "lr", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "memory_used", "=", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "/", "(", "1024.0", "*", "1024.0", ")", "\n", "etas", "=", "batch_time", ".", "avg", "*", "(", "num_steps", "-", "idx", ")", "\n", "logger", ".", "info", "(", "\n", "f'Train: [{epoch}/{config.TRAIN.EPOCHS}][{idx}/{num_steps}]\\t'", "\n", "f'eta {datetime.timedelta(seconds=int(etas))} lr {lr:.8f}\\t'", "\n", "f'time {batch_time.val:.4f} ({batch_time.avg:.4f})\\t'", "\n", "f'loss {loss_meter.val:.4f} ({loss_meter.avg:.4f})\\t'", "\n", "f'grad_norm {norm_meter.val:.4f} ({norm_meter.avg:.4f})\\t'", "\n", "f'mem {memory_used:.0f}MB'", "\n", ")", "\n", "", "", "epoch_time", "=", "time", ".", "time", "(", ")", "-", "start", "\n", "logger", ".", "info", "(", "f\"EPOCH {epoch} training takes {datetime.timedelta(seconds=int(epoch_time))}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.main.validate": [[309, 357], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "model.eval", "timm.utils.AverageMeter", "timm.utils.AverageMeter", "timm.utils.AverageMeter", "timm.utils.AverageMeter", "time.time", "enumerate", "logger.info", "images.cuda.cuda", "target.cuda.cuda", "model", "torch.nn.CrossEntropyLoss.", "timm.utils.accuracy", "utils.reduce_tensor", "utils.reduce_tensor", "utils.reduce_tensor", "timm.utils.AverageMeter.update", "timm.utils.AverageMeter.update", "timm.utils.AverageMeter.update", "timm.utils.AverageMeter.update", "time.time", "utils.reduce_tensor.item", "target.cuda.size", "utils.reduce_tensor.item", "target.cuda.size", "utils.reduce_tensor.item", "target.cuda.size", "logger.info", "time.time", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated", "len"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.utils.reduce_tensor", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.utils.reduce_tensor", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.utils.reduce_tensor"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validate", "(", "config", ",", "data_loader", ",", "model", ")", ":", "\n", "# use CrossEntropyLoss for eval mode", "\n", "    ", "criterion", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "batch_time", "=", "AverageMeter", "(", ")", "\n", "loss_meter", "=", "AverageMeter", "(", ")", "\n", "acc1_meter", "=", "AverageMeter", "(", ")", "\n", "acc5_meter", "=", "AverageMeter", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "idx", ",", "(", "images", ",", "target", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "images", "=", "images", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "target", "=", "target", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "\n", "# compute output", "\n", "output", "=", "model", "(", "images", ")", "\n", "\n", "# measure accuracy and record loss", "\n", "loss", "=", "criterion", "(", "output", ",", "target", ")", "\n", "acc1", ",", "acc5", "=", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "\n", "acc1", "=", "reduce_tensor", "(", "acc1", ")", "\n", "acc5", "=", "reduce_tensor", "(", "acc5", ")", "\n", "loss", "=", "reduce_tensor", "(", "loss", ")", "\n", "\n", "loss_meter", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "target", ".", "size", "(", "0", ")", ")", "\n", "acc1_meter", ".", "update", "(", "acc1", ".", "item", "(", ")", ",", "target", ".", "size", "(", "0", ")", ")", "\n", "acc5_meter", ".", "update", "(", "acc5", ".", "item", "(", ")", ",", "target", ".", "size", "(", "0", ")", ")", "\n", "\n", "# measure elapsed time for every batch", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "idx", "%", "config", ".", "PRINT_FREQ", "==", "0", ":", "\n", "            ", "memory_used", "=", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "/", "(", "1024.0", "*", "1024.0", ")", "\n", "logger", ".", "info", "(", "\n", "f'Test: [{idx}/{len(data_loader)}]\\t'", "\n", "f'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'", "\n", "f'Loss {loss_meter.val:.4f} ({loss_meter.avg:.4f})\\t'", "\n", "f'Acc@1 {acc1_meter.val:.3f} ({acc1_meter.avg:.3f})\\t'", "\n", "f'Acc@5 {acc5_meter.val:.3f} ({acc5_meter.avg:.3f})\\t'", "\n", "f'Mem {memory_used:.0f}MB'", "\n", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "f' * Acc@1 {acc1_meter.avg:.3f} Acc@5 {acc5_meter.avg:.3f}'", ")", "\n", "return", "acc1_meter", ".", "avg", ",", "acc5_meter", ".", "avg", ",", "loss_meter", ".", "avg", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.main.throughput": [[359, 381], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "model.eval", "enumerate", "images.cuda.cuda", "logger.info", "range", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "logger.info", "time.time", "range", "time.time", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "logger.info", "model", "model"], "function", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "throughput", "(", "data_loader", ",", "model", ",", "logger", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "\n", "for", "_", ",", "(", "images", ",", "_", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "images", "=", "images", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "batch_size", "=", "images", ".", "shape", "[", "0", "]", "\n", "# run 50 times before test", "\n", "logger", ".", "info", "(", "f\"throughput pre running\"", ")", "\n", "for", "_", "in", "range", "(", "50", ")", ":", "\n", "            ", "model", "(", "images", ")", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "\n", "# run 30 times for test", "\n", "logger", ".", "info", "(", "f\"throughput averaged with 30 times\"", ")", "\n", "tic1", "=", "time", ".", "time", "(", ")", "\n", "for", "_", "in", "range", "(", "30", ")", ":", "\n", "            ", "model", "(", "images", ")", "\n", "", "tic2", "=", "time", ".", "time", "(", ")", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "logger", ".", "info", "(", "f\"batch_size {batch_size} throughput {30 * batch_size / (tic2 - tic1)}\"", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.logger.create_logger": [[18, 47], ["functools.lru_cache", "logging.getLogger", "logging.getLogger.setLevel", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "os.path.join", "logging.Formatter", "termcolor.colored", "termcolor.colored", "logging.Formatter"], "function", ["None"], ["@", "functools", ".", "lru_cache", "(", ")", "\n", "def", "create_logger", "(", "output_dir", ",", "dist_rank", "=", "0", ",", "name", "=", "''", ")", ":", "\n", "# create logger", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "logger", ".", "propagate", "=", "False", "\n", "\n", "# create formatter", "\n", "fmt", "=", "'[%(asctime)s %(name)s] (%(filename)s %(lineno)d): %(levelname)s %(message)s'", "\n", "color_fmt", "=", "(", "\n", "colored", "(", "'[%(asctime)s %(name)s]'", ",", "'green'", ")", "\n", "+", "colored", "(", "'(%(filename)s %(lineno)d)'", ",", "'yellow'", ")", "\n", "+", "': %(levelname)s %(message)s'", "\n", ")", "\n", "\n", "# create console handlers for master process", "\n", "if", "dist_rank", "==", "0", ":", "\n", "        ", "console_handler", "=", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "\n", "console_handler", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "console_handler", ".", "setFormatter", "(", "logging", ".", "Formatter", "(", "fmt", "=", "color_fmt", ",", "datefmt", "=", "'%Y-%m-%d %H:%M:%S'", ")", ")", "\n", "logger", ".", "addHandler", "(", "console_handler", ")", "\n", "\n", "# create file handlers", "\n", "", "file_handler", "=", "logging", ".", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "f'log_rank{dist_rank}.txt'", ")", ",", "mode", "=", "'a'", ")", "\n", "file_handler", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "file_handler", ".", "setFormatter", "(", "logging", ".", "Formatter", "(", "fmt", "=", "fmt", ",", "datefmt", "=", "'%Y-%m-%d %H:%M:%S'", ")", ")", "\n", "logger", ".", "addHandler", "(", "file_handler", ")", "\n", "\n", "return", "logger", "\n", "", ""]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.lr_scheduler.LinearLRScheduler.__init__": [[67, 116], ["timm.scheduler.scheduler.Scheduler.__init__", "super().update_groups"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "t_initial", ":", "int", ",", "\n", "lr_min_rate", ":", "float", ",", "\n", "warmup_t", "=", "0", ",", "\n", "warmup_lr_init", "=", "0.0", ",", "\n", "t_in_epochs", "=", "True", ",", "\n", "noise_range_t", "=", "None", ",", "\n", "noise_pct", "=", "0.67", ",", "\n", "noise_std", "=", "1.0", ",", "\n", "noise_seed", "=", "42", ",", "\n", "initialize", "=", "True", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"[crate linear LR Scheduler]\n\n        Args:\n            optimizer (torch.optim.Optimizer): []\n            t_initial (int): []\n            lr_min_rate (float): []\n            warmup_t (int, optional): []. Defaults to 0.\n            warmup_lr_init ([type], optional): []. Defaults to 0..\n            t_in_epochs (bool, optional): []. Defaults to True.\n            noise_range_t ([type], optional): []. Defaults to None.\n            noise_pct (float, optional): []. Defaults to 0.67.\n            noise_std (float, optional): []. Defaults to 1.0.\n            noise_seed (int, optional): []. Defaults to 42.\n            initialize (bool, optional): []. Defaults to True.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "optimizer", ",", "\n", "param_group_field", "=", "\"lr\"", ",", "\n", "noise_range_t", "=", "noise_range_t", ",", "\n", "noise_pct", "=", "noise_pct", ",", "\n", "noise_std", "=", "noise_std", ",", "\n", "noise_seed", "=", "noise_seed", ",", "\n", "initialize", "=", "initialize", ",", "\n", ")", "\n", "\n", "self", ".", "t_initial", "=", "t_initial", "\n", "self", ".", "lr_min_rate", "=", "lr_min_rate", "\n", "self", ".", "warmup_t", "=", "warmup_t", "\n", "self", ".", "warmup_lr_init", "=", "warmup_lr_init", "\n", "self", ".", "t_in_epochs", "=", "t_in_epochs", "\n", "if", "self", ".", "warmup_t", ":", "\n", "            ", "self", ".", "warmup_steps", "=", "[", "(", "v", "-", "warmup_lr_init", ")", "/", "self", ".", "warmup_t", "for", "v", "in", "self", ".", "base_values", "]", "\n", "super", "(", ")", ".", "update_groups", "(", "self", ".", "warmup_lr_init", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "warmup_steps", "=", "[", "1", "for", "_", "in", "self", ".", "base_values", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.lr_scheduler.LinearLRScheduler._get_lr": [[117, 125], ["min"], "methods", ["None"], ["", "", "def", "_get_lr", "(", "self", ",", "t", ")", ":", "\n", "        ", "if", "t", "<", "self", ".", "warmup_t", ":", "\n", "            ", "lrs", "=", "[", "self", ".", "warmup_lr_init", "+", "t", "*", "s", "for", "s", "in", "self", ".", "warmup_steps", "]", "\n", "", "else", ":", "\n", "            ", "t", "=", "t", "-", "self", ".", "warmup_t", "\n", "total_t", "=", "self", ".", "t_initial", "-", "self", ".", "warmup_t", "\n", "lrs", "=", "[", "v", "-", "(", "(", "v", "-", "v", "*", "self", ".", "lr_min_rate", ")", "*", "min", "(", "1.0", ",", "t", "/", "total_t", ")", ")", "for", "v", "in", "self", ".", "base_values", "]", "\n", "", "return", "lrs", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.lr_scheduler.LinearLRScheduler.get_epoch_values": [[126, 131], ["lr_scheduler.LinearLRScheduler._get_lr"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.lr_scheduler.LinearLRScheduler._get_lr"], ["", "def", "get_epoch_values", "(", "self", ",", "epoch", ":", "int", ")", ":", "\n", "        ", "if", "self", ".", "t_in_epochs", ":", "\n", "            ", "return", "self", ".", "_get_lr", "(", "epoch", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.lr_scheduler.LinearLRScheduler.get_update_values": [[132, 137], ["lr_scheduler.LinearLRScheduler._get_lr"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.lr_scheduler.LinearLRScheduler._get_lr"], ["", "", "def", "get_update_values", "(", "self", ",", "num_updates", ":", "int", ")", ":", "\n", "        ", "if", "not", "self", ".", "t_in_epochs", ":", "\n", "            ", "return", "self", ".", "_get_lr", "(", "num_updates", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.lr_scheduler.build_scheduler": [[17, 64], ["int", "int", "int", "timm.scheduler.cosine_lr.CosineLRScheduler", "lr_scheduler.LinearLRScheduler", "timm.scheduler.step_lr.StepLRScheduler"], "function", ["None"], ["def", "build_scheduler", "(", "config", ",", "optimizer", ",", "n_iter_per_epoch", ")", ":", "\n", "    ", "\"\"\"[build lr scheduler]\n\n    Args:\n        config ([]): []\n        optimizer ([torch.optim]): []\n        n_iter_per_epoch ([int]): []\n\n    Returns:\n        [timm.scheduler]: []\n    \"\"\"", "\n", "num_steps", "=", "int", "(", "config", ".", "TRAIN", ".", "EPOCHS", "*", "n_iter_per_epoch", ")", "\n", "warmup_steps", "=", "int", "(", "config", ".", "TRAIN", ".", "WARMUP_EPOCHS", "*", "n_iter_per_epoch", ")", "\n", "decay_steps", "=", "int", "(", "config", ".", "TRAIN", ".", "LR_SCHEDULER", ".", "DECAY_EPOCHS", "*", "n_iter_per_epoch", ")", "\n", "\n", "lr_scheduler", "=", "None", "\n", "if", "config", ".", "TRAIN", ".", "LR_SCHEDULER", ".", "NAME", "==", "'cosine'", ":", "\n", "        ", "lr_scheduler", "=", "CosineLRScheduler", "(", "\n", "optimizer", ",", "\n", "t_initial", "=", "num_steps", ",", "\n", "t_mul", "=", "1.0", ",", "\n", "lr_min", "=", "config", ".", "TRAIN", ".", "MIN_LR", ",", "\n", "warmup_lr_init", "=", "config", ".", "TRAIN", ".", "WARMUP_LR", ",", "\n", "warmup_t", "=", "warmup_steps", ",", "\n", "cycle_limit", "=", "1", ",", "\n", "t_in_epochs", "=", "False", ",", "\n", ")", "\n", "", "elif", "config", ".", "TRAIN", ".", "LR_SCHEDULER", ".", "NAME", "==", "'linear'", ":", "\n", "        ", "lr_scheduler", "=", "LinearLRScheduler", "(", "\n", "optimizer", ",", "\n", "t_initial", "=", "num_steps", ",", "\n", "lr_min_rate", "=", "0.01", ",", "\n", "warmup_lr_init", "=", "config", ".", "TRAIN", ".", "WARMUP_LR", ",", "\n", "warmup_t", "=", "warmup_steps", ",", "\n", "t_in_epochs", "=", "False", ",", "\n", ")", "\n", "", "elif", "config", ".", "TRAIN", ".", "LR_SCHEDULER", ".", "NAME", "==", "'step'", ":", "\n", "        ", "lr_scheduler", "=", "StepLRScheduler", "(", "\n", "optimizer", ",", "\n", "decay_t", "=", "decay_steps", ",", "\n", "decay_rate", "=", "config", ".", "TRAIN", ".", "LR_SCHEDULER", ".", "DECAY_RATE", ",", "\n", "warmup_lr_init", "=", "config", ".", "TRAIN", ".", "WARMUP_LR", ",", "\n", "warmup_t", "=", "warmup_steps", ",", "\n", "t_in_epochs", "=", "False", ",", "\n", ")", "\n", "\n", "", "return", "lr_scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.optimizer.build_optimizer": [[14, 46], ["hasattr", "hasattr", "optimizer.set_weight_decay", "config.TRAIN.OPTIMIZER.NAME.lower", "model.no_weight_decay", "model.no_weight_decay_keywords", "torch.optim.SGD", "torch.optim.AdamW"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.optimizer.set_weight_decay"], ["def", "build_optimizer", "(", "config", ",", "model", ")", ":", "\n", "    ", "\"\"\"\n    Build optimizer, set weight decay of normalization to 0 by default.\n    \"\"\"", "\n", "skip", "=", "{", "}", "\n", "skip_keywords", "=", "{", "}", "\n", "if", "hasattr", "(", "model", ",", "'no_weight_decay'", ")", ":", "\n", "        ", "skip", "=", "model", ".", "no_weight_decay", "(", ")", "\n", "", "if", "hasattr", "(", "model", ",", "'no_weight_decay_keywords'", ")", ":", "\n", "        ", "skip_keywords", "=", "model", ".", "no_weight_decay_keywords", "(", ")", "\n", "", "parameters", "=", "set_weight_decay", "(", "model", ",", "skip", ",", "skip_keywords", ")", "\n", "\n", "opt_lower", "=", "config", ".", "TRAIN", ".", "OPTIMIZER", ".", "NAME", ".", "lower", "(", ")", "\n", "optimizer", "=", "None", "\n", "if", "opt_lower", "==", "'sgd'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "SGD", "(", "\n", "parameters", ",", "\n", "momentum", "=", "config", ".", "TRAIN", ".", "OPTIMIZER", ".", "MOMENTUM", ",", "\n", "nesterov", "=", "True", ",", "\n", "lr", "=", "config", ".", "TRAIN", ".", "BASE_LR", ",", "\n", "weight_decay", "=", "config", ".", "TRAIN", ".", "WEIGHT_DECAY", ",", "\n", ")", "\n", "", "elif", "opt_lower", "==", "'adamw'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "AdamW", "(", "\n", "parameters", ",", "\n", "eps", "=", "config", ".", "TRAIN", ".", "OPTIMIZER", ".", "EPS", ",", "\n", "betas", "=", "config", ".", "TRAIN", ".", "OPTIMIZER", ".", "BETAS", ",", "\n", "lr", "=", "config", ".", "TRAIN", ".", "BASE_LR", ",", "\n", "weight_decay", "=", "config", ".", "TRAIN", ".", "WEIGHT_DECAY", ",", "\n", ")", "\n", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.optimizer.set_weight_decay": [[48, 66], ["model.named_parameters", "name.endswith", "optimizer.check_keywords_in_name", "no_decay.append", "has_decay.append", "len"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.optimizer.check_keywords_in_name"], ["", "def", "set_weight_decay", "(", "model", ",", "skip_list", "=", "(", ")", ",", "skip_keywords", "=", "(", ")", ")", ":", "\n", "    ", "has_decay", "=", "[", "]", "\n", "no_decay", "=", "[", "]", "\n", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "not", "param", ".", "requires_grad", ":", "\n", "            ", "continue", "# frozen weights", "\n", "", "if", "(", "\n", "len", "(", "param", ".", "shape", ")", "==", "1", "\n", "or", "name", ".", "endswith", "(", "\".bias\"", ")", "\n", "or", "(", "name", "in", "skip_list", ")", "\n", "or", "check_keywords_in_name", "(", "name", ",", "skip_keywords", ")", "\n", ")", ":", "\n", "            ", "no_decay", ".", "append", "(", "param", ")", "\n", "# print(f\"{name} has no weight decay\")", "\n", "", "else", ":", "\n", "            ", "has_decay", ".", "append", "(", "param", ")", "\n", "", "", "return", "[", "{", "'params'", ":", "has_decay", "}", ",", "{", "'params'", ":", "no_decay", ",", "'weight_decay'", ":", "0.0", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.optimizer.check_keywords_in_name": [[68, 74], ["None"], "function", ["None"], ["", "def", "check_keywords_in_name", "(", "name", ",", "keywords", "=", "(", ")", ")", ":", "\n", "    ", "isin", "=", "False", "\n", "for", "keyword", "in", "keywords", ":", "\n", "        ", "if", "keyword", "in", "name", ":", "\n", "            ", "isin", "=", "True", "\n", "", "", "return", "isin", "\n", "", ""]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.utils.load_checkpoint": [[22, 64], ["logger.info", "config.MODEL.RESUME.startswith", "logger.info", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.hub.load_state_dict_from_url", "torch.hub.load_state_dict_from_url", "torch.load", "torch.load", "model.load_state_dict", "model.named_parameters", "model.load_state_dict", "optimizer.load_state_dict", "lr_scheduler.load_state_dict", "config.defrost", "config.freeze", "logger.info", "amp.load_state_dict", "logger.info"], "function", ["None"], ["", "def", "load_checkpoint", "(", "config", ",", "model", ",", "optimizer", ",", "lr_scheduler", ",", "logger", ")", ":", "\n", "    ", "logger", ".", "info", "(", "f\"==============> Resuming form {config.MODEL.RESUME}....................\"", ")", "\n", "if", "config", ".", "MODEL", ".", "RESUME", ".", "startswith", "(", "'https'", ")", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "hub", ".", "load_state_dict_from_url", "(", "config", ".", "MODEL", ".", "RESUME", ",", "map_location", "=", "'cpu'", ",", "check_hash", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "config", ".", "MODEL", ".", "RESUME", ",", "map_location", "=", "'cpu'", ")", "\n", "\n", "", "if", "'state_dict_ema'", "in", "checkpoint", ":", "\n", "        ", "msg", "=", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict_ema'", "]", ",", "strict", "=", "False", ")", "\n", "", "else", ":", "\n", "# when pretrain/finetune, delete some mismatch params, for example mlp_head", "\n", "        ", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "name", "not", "in", "checkpoint", "[", "'model'", "]", ":", "\n", "                ", "continue", "\n", "", "if", "param", ".", "shape", "!=", "checkpoint", "[", "'model'", "]", "[", "name", "]", ".", "shape", ":", "\n", "                ", "del", "checkpoint", "[", "'model'", "]", "[", "name", "]", "\n", "logger", ".", "info", "(", "'del mismatch param: '", "+", "name", ")", "\n", "", "", "msg", "=", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ",", "strict", "=", "False", ")", "\n", "", "logger", ".", "info", "(", "msg", ")", "\n", "\n", "max_accuracy", "=", "0.0", "\n", "if", "(", "\n", "not", "config", ".", "LOAD_PARAM_ONLY", "\n", "and", "not", "config", ".", "EVAL_MODE", "\n", "and", "'optimizer'", "in", "checkpoint", "\n", "and", "'lr_scheduler'", "in", "checkpoint", "\n", "and", "'epoch'", "in", "checkpoint", "\n", ")", ":", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "lr_scheduler", ".", "load_state_dict", "(", "checkpoint", "[", "'lr_scheduler'", "]", ")", "\n", "config", ".", "defrost", "(", ")", "\n", "config", ".", "TRAIN", ".", "START_EPOCH", "=", "checkpoint", "[", "'epoch'", "]", "+", "1", "\n", "config", ".", "freeze", "(", ")", "\n", "if", "'amp'", "in", "checkpoint", "and", "config", ".", "AMP_OPT_LEVEL", "!=", "\"O0\"", "and", "checkpoint", "[", "'config'", "]", ".", "AMP_OPT_LEVEL", "!=", "\"O0\"", ":", "\n", "            ", "amp", ".", "load_state_dict", "(", "checkpoint", "[", "'amp'", "]", ")", "\n", "", "logger", ".", "info", "(", "f\"=> loaded successfully '{config.MODEL.RESUME}' (epoch {checkpoint['epoch']})\"", ")", "\n", "if", "'max_accuracy'", "in", "checkpoint", ":", "\n", "            ", "max_accuracy", "=", "checkpoint", "[", "'max_accuracy'", "]", "\n", "\n", "", "", "del", "checkpoint", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "return", "max_accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.utils.save_checkpoint": [[66, 89], ["torch.save", "torch.save", "logger.info", "model.state_dict", "optimizer.state_dict", "lr_scheduler.state_dict", "amp.state_dict", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "save_checkpoint", "(", "\n", "config", ",", "epoch", ",", "model", ",", "max_accuracy", ",", "optimizer", ",", "lr_scheduler", ",", "logger", ",", "save_latest", "=", "False", ",", "save_best", "=", "False", "\n", ")", ":", "\n", "    ", "save_state", "=", "{", "\n", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'lr_scheduler'", ":", "lr_scheduler", ".", "state_dict", "(", ")", ",", "\n", "'max_accuracy'", ":", "max_accuracy", ",", "\n", "'epoch'", ":", "epoch", ",", "\n", "'config'", ":", "config", ",", "\n", "}", "\n", "if", "config", ".", "AMP_OPT_LEVEL", "!=", "\"O0\"", ":", "\n", "        ", "save_state", "[", "'amp'", "]", "=", "amp", ".", "state_dict", "(", ")", "\n", "\n", "", "if", "save_best", ":", "\n", "        ", "save_path", "=", "os", ".", "path", ".", "join", "(", "config", ".", "OUTPUT", ",", "'ckpt_best.pth'", ")", "\n", "", "elif", "save_latest", ":", "\n", "        ", "save_path", "=", "os", ".", "path", ".", "join", "(", "config", ".", "OUTPUT", ",", "'ckpt_last.pth'", ")", "\n", "", "else", ":", "\n", "        ", "save_path", "=", "os", ".", "path", ".", "join", "(", "config", ".", "OUTPUT", ",", "f'ckpt_epoch_{epoch}.pth'", ")", "\n", "\n", "", "torch", ".", "save", "(", "save_state", ",", "save_path", ")", "\n", "logger", ".", "info", "(", "f\"{save_path} saved !!!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.utils.get_grad_norm": [[91, 102], ["isinstance", "list", "float", "filter", "p.grad.data.norm", "p.grad.data.norm.item"], "function", ["None"], ["", "def", "get_grad_norm", "(", "parameters", ",", "norm_type", "=", "2", ")", ":", "\n", "    ", "if", "isinstance", "(", "parameters", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "parameters", "=", "[", "parameters", "]", "\n", "", "parameters", "=", "list", "(", "filter", "(", "lambda", "p", ":", "p", ".", "grad", "is", "not", "None", ",", "parameters", ")", ")", "\n", "norm_type", "=", "float", "(", "norm_type", ")", "\n", "total_norm", "=", "0", "\n", "for", "p", "in", "parameters", ":", "\n", "        ", "param_norm", "=", "p", ".", "grad", ".", "data", ".", "norm", "(", "norm_type", ")", "\n", "total_norm", "+=", "param_norm", ".", "item", "(", ")", "**", "norm_type", "\n", "", "total_norm", "=", "total_norm", "**", "(", "1.0", "/", "norm_type", ")", "\n", "return", "total_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.utils.auto_resume_helper": [[105, 116], ["os.listdir", "print", "len", "max", "print", "ckpt.endswith", "os.path.join"], "function", ["None"], ["", "def", "auto_resume_helper", "(", "output_dir", ")", ":", "\n", "    ", "checkpoints", "=", "os", ".", "listdir", "(", "output_dir", ")", "\n", "checkpoints", "=", "[", "ckpt", "for", "ckpt", "in", "checkpoints", "if", "ckpt", ".", "endswith", "(", "'pth'", ")", "]", "\n", "print", "(", "f\"All checkpoints founded in {output_dir}: {checkpoints}\"", ")", "\n", "if", "len", "(", "checkpoints", ")", ">", "0", ":", "\n", "        ", "latest_checkpoint", "=", "max", "(", "[", "os", ".", "path", ".", "join", "(", "output_dir", ",", "d", ")", "for", "d", "in", "checkpoints", "]", ",", "key", "=", "os", ".", "path", ".", "getmtime", ")", "\n", "print", "(", "f\"The latest checkpoint founded: {latest_checkpoint}\"", ")", "\n", "resume_file", "=", "latest_checkpoint", "\n", "", "else", ":", "\n", "        ", "resume_file", "=", "None", "\n", "", "return", "resume_file", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.None.utils.reduce_tensor": [[118, 123], ["tensor.clone", "torch.all_reduce", "torch.get_world_size"], "function", ["None"], ["", "def", "reduce_tensor", "(", "tensor", ")", ":", "\n", "    ", "rt", "=", "tensor", ".", "clone", "(", ")", "\n", "dist", ".", "all_reduce", "(", "rt", ",", "op", "=", "dist", ".", "ReduceOp", ".", "SUM", ")", "\n", "rt", "/=", "dist", ".", "get_world_size", "(", ")", "\n", "return", "rt", "\n", "", ""]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.build.build_model": [[14, 32], ["nommer.NomMerAttn", "NotImplementedError"], "function", ["None"], ["def", "build_model", "(", "config", ")", ":", "\n", "    ", "model_type", "=", "config", ".", "MODEL", ".", "TYPE", "\n", "if", "model_type", "==", "'nommer_attn'", ":", "\n", "        ", "model", "=", "NomMerAttn", "(", "\n", "emd_dim", "=", "config", ".", "MODEL", ".", "NomMer", ".", "EMBED_DIM", ",", "\n", "depths", "=", "config", ".", "MODEL", ".", "NomMer", ".", "DEPTHS", ",", "\n", "num_heads", "=", "config", ".", "MODEL", ".", "NomMer", ".", "NUM_HEADS", ",", "\n", "input_size", "=", "config", ".", "DATA", ".", "IMG_SIZE", ",", "\n", "win_size", "=", "config", ".", "MODEL", ".", "NomMer", ".", "WINDOW_SIZE", ",", "\n", "pool_size", "=", "config", ".", "MODEL", ".", "NomMer", ".", "POOLING_SIZE", ",", "\n", "cnn_expansion", "=", "config", ".", "MODEL", ".", "NomMer", ".", "CNN_EXPANSION", ",", "\n", "drop_path_rate", "=", "config", ".", "MODEL", ".", "DROP_PATH_RATE", ",", "\n", "num_class", "=", "config", ".", "MODEL", ".", "NUM_CLASSES", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"Unkown model: {model_type}\"", ")", "\n", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.FeedForward.__init__": [[20, 24], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.GELU", "torch.GELU", "torch.GELU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "hidden_dim", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "dim", ",", "hidden_dim", ")", ",", "nn", ".", "GELU", "(", ")", ",", "nn", ".", "Dropout", "(", "dropout", ")", ",", "nn", ".", "Linear", "(", "hidden_dim", ",", "dim", ")", ",", "nn", ".", "Dropout", "(", "dropout", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.FeedForward.forward": [[26, 28], ["nommer.FeedForward.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "net", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.PreNorm.__init__": [[31, 35], ["torch.Module.__init__", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "fn", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm", "=", "nn", ".", "LayerNorm", "(", "dim", ")", "\n", "self", ".", "fn", "=", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.PreNorm.forward": [[36, 38], ["nommer.PreNorm.fn", "nommer.PreNorm.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "fn", "(", "self", ".", "norm", "(", "x", ")", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.WindowAttention.__init__": [[53, 85], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "relative_coords.permute().contiguous.permute().contiguous.permute().contiguous", "relative_coords.permute().contiguous.permute().contiguous.sum", "nommer.WindowAttention.register_buffer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "timm.models.layers.trunc_normal_", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "relative_coords.permute().contiguous.permute().contiguous.permute"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "window_size", ",", "num_heads", ",", "qkv_bias", "=", "True", ",", "qk_scale", "=", "None", ",", "attn_drop", "=", "0.0", ",", "proj_drop", "=", "0.0", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "head_dim", "=", "dim", "//", "num_heads", "\n", "self", ".", "scale", "=", "qk_scale", "or", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "relative_position_bias_table", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "(", "2", "*", "window_size", "[", "0", "]", "-", "1", ")", "*", "(", "2", "*", "window_size", "[", "1", "]", "-", "1", ")", ",", "num_heads", ")", "\n", ")", "\n", "\n", "coords_h", "=", "torch", ".", "arange", "(", "self", ".", "window_size", "[", "0", "]", ")", "\n", "coords_w", "=", "torch", ".", "arange", "(", "self", ".", "window_size", "[", "1", "]", ")", "\n", "coords", "=", "torch", ".", "stack", "(", "torch", ".", "meshgrid", "(", "[", "coords_h", ",", "coords_w", "]", ")", ")", "\n", "coords_flatten", "=", "torch", ".", "flatten", "(", "coords", ",", "1", ")", "\n", "relative_coords", "=", "coords_flatten", "[", ":", ",", ":", ",", "None", "]", "-", "coords_flatten", "[", ":", ",", "None", ",", ":", "]", "\n", "relative_coords", "=", "relative_coords", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "relative_coords", "[", ":", ",", ":", ",", "0", "]", "+=", "self", ".", "window_size", "[", "0", "]", "-", "1", "\n", "relative_coords", "[", ":", ",", ":", ",", "1", "]", "+=", "self", ".", "window_size", "[", "1", "]", "-", "1", "\n", "relative_coords", "[", ":", ",", ":", ",", "0", "]", "*=", "2", "*", "self", ".", "window_size", "[", "1", "]", "-", "1", "\n", "relative_position_index", "=", "relative_coords", ".", "sum", "(", "-", "1", ")", "\n", "self", ".", "register_buffer", "(", "\"relative_position_index\"", ",", "relative_position_index", ")", "\n", "\n", "self", ".", "qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", "*", "3", ",", "bias", "=", "qkv_bias", ")", "\n", "self", ".", "attn_drop", "=", "nn", ".", "Dropout", "(", "attn_drop", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "proj_drop", "=", "nn", ".", "Dropout", "(", "proj_drop", ")", "\n", "\n", "trunc_normal_", "(", "self", ".", "relative_position_bias_table", ",", "std", "=", "0.02", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.WindowAttention.forward": [[86, 113], ["nommer.WindowAttention.qkv().reshape().permute", "nommer.WindowAttention.relative_position_bias_table[].view", "relative_position_bias.permute().contiguous.permute().contiguous.permute().contiguous", "nommer.WindowAttention.softmax", "nommer.WindowAttention.attn_drop", "nommer.WindowAttention.proj", "nommer.WindowAttention.proj_drop", "k.transpose", "relative_position_bias.permute().contiguous.permute().contiguous.unsqueeze", "nommer.WindowAttention.qkv().reshape", "relative_position_bias.permute().contiguous.permute().contiguous.permute", "nommer.WindowAttention.qkv", "nommer.WindowAttention.relative_position_index.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x: input features with shape of (num_windows*B, N, C)\n            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None\n        \"\"\"", "\n", "B", ",", "N", ",", "C", "=", "x", ".", "shape", "\n", "qkv", "=", "self", ".", "qkv", "(", "x", ")", ".", "reshape", "(", "B", ",", "N", ",", "3", ",", "self", ".", "num_heads", ",", "C", "//", "self", ".", "num_heads", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", "[", "0", "]", ",", "qkv", "[", "1", "]", ",", "qkv", "[", "2", "]", "\n", "\n", "q", "=", "q", "*", "self", ".", "scale", "\n", "attn", "=", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", "\n", "\n", "relative_position_bias", "=", "self", ".", "relative_position_bias_table", "[", "self", ".", "relative_position_index", ".", "view", "(", "-", "1", ")", "]", ".", "view", "(", "\n", "self", ".", "window_size", "[", "0", "]", "*", "self", ".", "window_size", "[", "1", "]", ",", "self", ".", "window_size", "[", "0", "]", "*", "self", ".", "window_size", "[", "1", "]", ",", "-", "1", "\n", ")", "\n", "relative_position_bias", "=", "relative_position_bias", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "attn", "=", "attn", "+", "relative_position_bias", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "attn", "=", "self", ".", "softmax", "(", "attn", ")", "\n", "attn", "=", "self", ".", "attn_drop", "(", "attn", ")", "\n", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "B", ",", "N", ",", "C", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_drop", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.Attention.__init__": [[116, 129], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "heads", "=", "8", ",", "dim_head", "=", "64", ",", "dropout", "=", "0.0", ",", "depth", "=", "-", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "depth", "=", "depth", "\n", "inner_dim", "=", "dim_head", "*", "heads", "\n", "project_out", "=", "not", "(", "heads", "==", "1", "and", "dim_head", "==", "dim", ")", "\n", "\n", "self", ".", "heads", "=", "heads", "\n", "self", ".", "scale", "=", "dim_head", "**", "-", "0.5", "\n", "\n", "self", ".", "to_qkv", "=", "nn", ".", "Linear", "(", "dim", ",", "inner_dim", "*", "3", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "to_out", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "inner_dim", ",", "dim", ")", ",", "nn", ".", "Dropout", "(", "dropout", ")", ")", "if", "project_out", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.Attention.forward": [[130, 139], ["nommer.Attention.to_qkv().reshape().permute", "attn.softmax.softmax.softmax", "nommer.Attention.to_out", "nommer.Attention.to_qkv().reshape", "k.transpose", "nommer.Attention.to_qkv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "b", ",", "n", ",", "channels", ",", "h", "=", "*", "x", ".", "shape", ",", "self", ".", "heads", "\n", "qkv", "=", "self", ".", "to_qkv", "(", "x", ")", ".", "reshape", "(", "b", ",", "n", ",", "3", ",", "h", ",", "channels", "//", "h", ")", ".", "permute", "(", "2", ",", "0", ",", "3", ",", "1", ",", "4", ")", "\n", "q", ",", "k", ",", "v", "=", "qkv", "[", "0", "]", ",", "qkv", "[", "1", "]", ",", "qkv", "[", "2", "]", "\n", "attn", "=", "(", "q", "@", "k", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "*", "self", ".", "scale", "\n", "attn", "=", "attn", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "x", "=", "(", "attn", "@", "v", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "b", ",", "n", ",", "channels", ")", "\n", "\n", "return", "self", ".", "to_out", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.Bottleneck.__init__": [[167, 180], ["torch.Module.__init__", "nommer.conv1x1", "norm_layer", "nommer.conv3x3", "norm_layer", "nommer.conv1x1", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "int"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.__init__", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.conv1x1", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.conv3x3", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.conv1x1"], ["    ", "def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "expansion", "=", "4", ",", "stride", "=", "1", ",", "groups", "=", "1", ",", "base_width", "=", "64", ",", "dilation", "=", "1", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "width", "=", "int", "(", "planes", "//", "expansion", ")", "*", "groups", "\n", "self", ".", "conv1", "=", "conv1x1", "(", "inplanes", ",", "width", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "width", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "width", ",", "width", ",", "stride", ",", "groups", ",", "dilation", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "width", ")", "\n", "self", ".", "conv3", "=", "conv1x1", "(", "width", ",", "planes", ")", "\n", "self", ".", "bn3", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.Bottleneck.forward": [[181, 199], ["nommer.Bottleneck.conv1", "nommer.Bottleneck.bn1", "nommer.Bottleneck.relu", "nommer.Bottleneck.conv2", "nommer.Bottleneck.bn2", "nommer.Bottleneck.relu", "nommer.Bottleneck.conv3", "nommer.Bottleneck.bn3", "nommer.Bottleneck.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.DCTAttention.__init__": [[283, 294], ["torch.Module.__init__", "nommer.init_dct_kernel", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "nommer.Attention", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "nommer.init_idct_kernel", "torch.PixelShuffle", "torch.PixelShuffle", "torch.PixelShuffle"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.__init__", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.init_dct_kernel", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.init_idct_kernel"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "ksize", ",", "heads", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ksize", "=", "ksize", "\n", "reserve_kernel", "=", "(", "ksize", "+", "1", ")", "//", "2", "\n", "reserve_size", "=", "(", "reserve_kernel", ")", "**", "2", "\n", "self", ".", "dct_conv_8x8", "=", "init_dct_kernel", "(", "dim", ",", "ksize", ",", "reserve_kernel", ")", "\n", "self", ".", "dw", "=", "nn", ".", "Conv2d", "(", "reserve_size", "*", "dim", ",", "dim", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "groups", "=", "8", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "dim", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "dim", ",", "heads", "=", "heads", ",", "dim_head", "=", "dim", "//", "heads", ")", "\n", "self", ".", "up", "=", "nn", ".", "Conv2d", "(", "dim", ",", "reserve_size", "*", "dim", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "groups", "=", "8", ",", "bias", "=", "False", ")", "\n", "self", ".", "idct_conv", "=", "nn", ".", "Sequential", "(", "init_idct_kernel", "(", "dim", ",", "ksize", ",", "reserve_kernel", ")", ",", "nn", ".", "PixelShuffle", "(", "ksize", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.DCTAttention.forward": [[295, 310], ["nommer.DCTAttention.dct_conv_8x8", "nommer.DCTAttention.dw", "nommer.DCTAttention.bn1", "nommer.DCTAttention.attn", "nommer.DCTAttention.up", "nommer.DCTAttention.idct_conv", "nommer.DCTAttention.permute().flatten", "nommer.DCTAttention.permute().view", "nommer.DCTAttention.permute", "nommer.DCTAttention.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "_", ",", "_", ",", "_", "=", "x", ".", "shape", "\n", "\n", "input_8x8", "=", "self", ".", "dct_conv_8x8", "(", "x", ")", "\n", "_", ",", "_", ",", "h", ",", "w", "=", "input_8x8", ".", "shape", "\n", "\n", "x", "=", "self", ".", "dw", "(", "input_8x8", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "attn", "(", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "flatten", "(", "1", ",", "2", ")", ")", "\n", "\n", "x", "=", "self", ".", "up", "(", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "view", "(", "B", ",", "-", "1", ",", "h", ",", "w", ")", ")", "\n", "x", "=", "self", ".", "idct_conv", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.HybridAttention.__init__": [[347, 367], ["torch.Module.__init__", "nommer.Bottleneck", "nommer.WindowAttention", "nommer.DCTAttention", "torch.Linear", "torch.Linear", "torch.Linear", "timm.models.layers.to_2tuple"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "heads", "=", "8", ",", "dropout", "=", "0.0", ",", "depth", "=", "0", ",", "wsize", "=", "-", "1", ",", "psize", "=", "-", "1", ",", "cnn_expansion", "=", "4", ")", ":", "\n", "        ", "\"\"\"[a hybrid attention that can dynamically Nominate the synergistic global-local context]\n\n        Args:\n            dim ([int]): []\n            heads (int, optional): []. Defaults to 8.\n            dropout ([float], optional): []. Defaults to 0..\n            depth (int, optional): []. Defaults to 0.\n            wsize (int, optional): []. Defaults to -1.\n            psize (int, optional): [used for dct-attention]. Defaults to -1.\n            cnn_expansion (int, optional): []. Defaults to 4.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "wsize", "=", "wsize", "\n", "self", ".", "psize", "=", "psize", "\n", "self", ".", "cnn", "=", "Bottleneck", "(", "dim", ",", "dim", ",", "expansion", "=", "cnn_expansion", ")", "\n", "self", ".", "attention", "=", "WindowAttention", "(", "dim", ",", "to_2tuple", "(", "wsize", ")", ",", "heads", ",", "proj_drop", "=", "0.0", ")", "\n", "self", ".", "attentionG", "=", "DCTAttention", "(", "dim", ",", "psize", ",", "heads", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "dim", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.HybridAttention.window_partition": [[368, 373], ["x.view.view.view", "x.view.view.permute().contiguous().view", "x.view.view.permute().contiguous", "x.view.view.permute"], "methods", ["None"], ["", "def", "window_partition", "(", "self", ",", "x", ",", "window_size", ")", ":", "\n", "        ", "B", ",", "H", ",", "W", ",", "C", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "H", "//", "window_size", ",", "window_size", ",", "W", "//", "window_size", ",", "window_size", ",", "C", ")", "\n", "windows", "=", "x", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ",", "5", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "window_size", ",", "window_size", ",", "C", ")", "\n", "return", "windows", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.HybridAttention.window_reverse": [[374, 379], ["int", "windows.view", "x.permute().contiguous().view.permute().contiguous().view.permute().contiguous().view", "x.permute().contiguous().view.permute().contiguous().view.permute().contiguous", "x.permute().contiguous().view.permute().contiguous().view.permute"], "methods", ["None"], ["", "def", "window_reverse", "(", "self", ",", "windows", ",", "window_size", ",", "H", ",", "W", ")", ":", "\n", "        ", "B", "=", "int", "(", "windows", ".", "shape", "[", "0", "]", "/", "(", "H", "*", "W", "/", "window_size", "/", "window_size", ")", ")", "\n", "x", "=", "windows", ".", "view", "(", "B", ",", "H", "//", "window_size", ",", "W", "//", "window_size", ",", "window_size", ",", "window_size", ",", "-", "1", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ",", "5", ")", ".", "contiguous", "(", ")", ".", "view", "(", "B", ",", "H", ",", "W", ",", "-", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.HybridAttention.forward": [[380, 407], ["nommer.HybridAttention.cnn", "x1.permute.permute.permute", "nommer.HybridAttention.window_partition().flatten", "nommer.HybridAttention.attention", "nommer.HybridAttention.window_reverse", "nommer.HybridAttention.attentionG().permute", "nommer.HybridAttention.fc", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum.permute", "torch.sum.permute", "torch.sum.permute", "nommer.gumbel_softmax", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "_values.unsqueeze.unsqueeze.unsqueeze", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long", "torch.eq().long.unsqueeze", "torch.eq().long.unsqueeze", "torch.eq().long.unsqueeze", "nommer.HybridAttention.window_partition", "nommer.HybridAttention.attentionG", "torch.sum.permute", "torch.sum.permute", "torch.sum.permute", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.HybridAttention.window_reverse", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.gumbel_softmax", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.HybridAttention.window_partition"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "_", ",", "H", ",", "W", ",", "_", "=", "x", ".", "shape", "\n", "\n", "x1", "=", "self", ".", "cnn", "(", "x", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "x1", "=", "x1", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n", "x2", "=", "self", ".", "window_partition", "(", "x", ",", "self", ".", "wsize", ")", ".", "flatten", "(", "1", ",", "2", ")", "\n", "x2", "=", "self", ".", "attention", "(", "x2", ")", "\n", "x2", "=", "self", ".", "window_reverse", "(", "x2", ",", "self", ".", "wsize", ",", "H", ",", "W", ")", "\n", "\n", "x3", "=", "self", ".", "attentionG", "(", "x", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n", "hybrid_x", "=", "x1", "+", "x2", "+", "x3", "\n", "logits", "=", "self", ".", "fc", "(", "hybrid_x", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "logits", "=", "gumbel_softmax", "(", "logits", ",", "tau", "=", "1", ",", "hard", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "_values", ",", "_indexes", "=", "torch", ".", "max", "(", "logits", ",", "-", "1", ")", "\n", "_values", "=", "_values", ".", "unsqueeze", "(", "-", "1", ")", "\n", "logits", "=", "torch", ".", "eq", "(", "logits", ",", "_values", ")", ".", "long", "(", ")", "\n", "\n", "", "x", "=", "torch", ".", "stack", "(", "[", "x1", ",", "x2", ",", "x3", "]", ",", "-", "2", ")", "\n", "x", "=", "torch", ".", "mul", "(", "x", ",", "logits", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "x", "=", "torch", ".", "sum", "(", "x", ",", "-", "2", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.HybridNet.__init__": [[410, 433], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "nommer.HybridNet.layers.append", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "nommer.PreNorm", "nommer.PreNorm", "timm.models.layers.DropPath", "nommer.HybridAttention", "nommer.FeedForward"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "depth", ",", "heads", ",", "mlp_dim", ",", "wsize", ",", "psize", ",", "cnn_expansion", ",", "dropout", "=", "0.0", ",", "drop_path", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "for", "n", "in", "range", "(", "depth", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "PreNorm", "(", "\n", "dim", ",", "\n", "HybridAttention", "(", "\n", "dim", ",", "\n", "heads", "=", "heads", ",", "\n", "dropout", "=", "dropout", ",", "\n", "depth", "=", "n", ",", "\n", "wsize", "=", "wsize", ",", "\n", "psize", "=", "psize", ",", "\n", "cnn_expansion", "=", "cnn_expansion", ",", "\n", ")", ",", "\n", ")", ",", "\n", "PreNorm", "(", "dim", ",", "FeedForward", "(", "dim", ",", "mlp_dim", ",", "dropout", "=", "dropout", ")", ")", ",", "\n", "DropPath", "(", "drop_path", "[", "n", "]", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.HybridNet.forward": [[437, 443], ["drop", "drop", "attn", "ff"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "attn", ",", "ff", ",", "drop", "in", "self", ".", "layers", ":", "\n", "            ", "shortcut", "=", "x", "\n", "x", "=", "shortcut", "+", "drop", "(", "attn", "(", "x", ")", ")", "\n", "x", "=", "x", "+", "drop", "(", "ff", "(", "x", ")", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.Transformer.__init__": [[446, 457], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "nommer.Transformer.layers.append", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "nommer.PreNorm", "nommer.PreNorm", "timm.models.layers.DropPath", "nommer.Attention", "nommer.FeedForward"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "depth", ",", "heads", ",", "mlp_dim", ",", "dropout", "=", "0.0", ",", "drop_path", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "assert", "dim", "%", "heads", "==", "0", "\n", "for", "n", "in", "range", "(", "depth", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "PreNorm", "(", "dim", ",", "Attention", "(", "dim", ",", "heads", "=", "heads", ",", "dim_head", "=", "dim", "//", "heads", ",", "dropout", "=", "dropout", ",", "depth", "=", "n", ")", ")", ",", "\n", "PreNorm", "(", "dim", ",", "FeedForward", "(", "dim", ",", "mlp_dim", ",", "dropout", "=", "dropout", ")", ")", ",", "\n", "DropPath", "(", "drop_path", "[", "n", "]", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.Transformer.forward": [[461, 467], ["drop", "drop", "attn", "ff"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "attn", ",", "ff", ",", "drop", "in", "self", ".", "layers", ":", "\n", "            ", "shortcut", "=", "x", "\n", "x", "=", "shortcut", "+", "drop", "(", "attn", "(", "x", ")", ")", "\n", "x", "=", "x", "+", "drop", "(", "ff", "(", "x", ")", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.MergeBlock.__init__": [[470, 475], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "norm_layer"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "dim_out", ",", "norm_layer", "=", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "dim", ",", "dim_out", ",", "3", ",", "1", ",", "1", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "(", "2", ",", "2", ")", ")", "\n", "self", ".", "norm", "=", "norm_layer", "(", "dim_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.MergeBlock.forward": [[476, 493], ["nommer.MergeBlock.norm", "x.view().transpose().contiguous.view().transpose().contiguous.dim", "x.view().transpose().contiguous.view().transpose().contiguous.permute().contiguous", "nommer.MergeBlock.conv", "nommer.MergeBlock.pool", "x.view().transpose().contiguous.view().transpose().contiguous.permute().contiguous", "int", "x.view().transpose().contiguous.view().transpose().contiguous.transpose().contiguous().view", "nommer.MergeBlock.conv", "nommer.MergeBlock.pool", "x.view().transpose().contiguous.view().transpose().contiguous.view().transpose().contiguous", "numpy.sqrt", "x.view().transpose().contiguous.view().transpose().contiguous.permute", "x.view().transpose().contiguous.view().transpose().contiguous.permute", "x.view().transpose().contiguous.view().transpose().contiguous.transpose().contiguous", "x.view().transpose().contiguous.view().transpose().contiguous.view().transpose", "x.view().transpose().contiguous.view().transpose().contiguous.transpose", "x.view().transpose().contiguous.view().transpose().contiguous.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "x", ".", "dim", "(", ")", "==", "4", ":", "\n", "            ", "B", ",", "H", ",", "W", ",", "C", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "            ", "B", ",", "new_HW", ",", "C", "=", "x", ".", "shape", "\n", "H", "=", "W", "=", "int", "(", "np", ".", "sqrt", "(", "new_HW", ")", ")", "\n", "x", "=", "x", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "B", ",", "C", ",", "H", ",", "W", ")", "\n", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "B", ",", "C", "=", "x", ".", "shape", "[", ":", "2", "]", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "C", ",", "-", "1", ")", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.NomMerAttn.__init__": [[496, 565], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "nommer.HybridNet", "nommer.MergeBlock", "nommer.HybridNet", "nommer.MergeBlock", "nommer.Transformer", "nommer.MergeBlock", "nommer.Transformer", "torch.Sequential", "torch.Sequential", "torch.Sequential", "nommer.NomMerAttn.apply", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "x.item", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "sum", "sum", "sum", "sum", "sum", "sum", "sum"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "emd_dim", "=", "128", ",", "\n", "depths", "=", "None", ",", "\n", "num_heads", "=", "None", ",", "\n", "input_size", "=", "224", ",", "\n", "win_size", "=", "7", ",", "\n", "pool_size", "=", "None", ",", "\n", "cnn_expansion", "=", "None", ",", "\n", "drop_path_rate", "=", "0.1", ",", "\n", "num_class", "=", "1000", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            emd_dim (int, optional): []. Defaults to 128.\n            depths (list, optional): []. Defaults to [2,2,16,2].\n            num_heads (list, optional): []. Defaults to [2,4,8,16].\n            input_size (int, optional): []. Defaults to 224.\n            win_size (int, optional): []. Defaults to 7.\n            cnn_expansion (list, optional): []. Defaults to [4,4].\n            drop_path_rate (float, optional): []. Defaults to 0.1.\n            num_class (int, optional): []. Defaults to 1000.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "cnn1", "=", "nn", ".", "Conv2d", "(", "3", ",", "emd_dim", ",", "kernel_size", "=", "4", ",", "stride", "=", "4", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "emd_dim", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "pos_embedding", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "1", ",", "input_size", "//", "16", ",", "input_size", "//", "16", ",", "emd_dim", "*", "4", ")", ")", "\n", "self", ".", "cls_token", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "1", ",", "1", ",", "emd_dim", "*", "8", ")", ")", "\n", "dpr", "=", "[", "x", ".", "item", "(", ")", "for", "x", "in", "torch", ".", "linspace", "(", "0", ",", "drop_path_rate", ",", "sum", "(", "depths", ")", ")", "]", "\n", "\n", "self", ".", "transformer1", "=", "HybridNet", "(", "\n", "emd_dim", ",", "\n", "depths", "[", "0", "]", ",", "\n", "num_heads", "[", "0", "]", ",", "\n", "emd_dim", "*", "2", ",", "\n", "win_size", ",", "\n", "pool_size", "[", "0", "]", ",", "\n", "cnn_expansion", "[", "0", "]", ",", "\n", "0.0", ",", "\n", "dpr", "[", "0", ":", "sum", "(", "depths", "[", ":", "1", "]", ")", "]", ",", "\n", ")", "\n", "self", ".", "merge1", "=", "MergeBlock", "(", "emd_dim", ",", "emd_dim", "*", "2", ")", "\n", "\n", "self", ".", "transformer2", "=", "HybridNet", "(", "\n", "emd_dim", "*", "2", ",", "\n", "depths", "[", "1", "]", ",", "\n", "num_heads", "[", "1", "]", ",", "\n", "emd_dim", "*", "4", ",", "\n", "win_size", ",", "\n", "pool_size", "[", "1", "]", ",", "\n", "cnn_expansion", "[", "1", "]", ",", "\n", "0.0", ",", "\n", "dpr", "[", "sum", "(", "depths", "[", ":", "1", "]", ")", ":", "sum", "(", "depths", "[", ":", "2", "]", ")", "]", ",", "\n", ")", "\n", "self", ".", "merge2", "=", "MergeBlock", "(", "emd_dim", "*", "2", ",", "emd_dim", "*", "4", ")", "\n", "\n", "self", ".", "transformer3", "=", "Transformer", "(", "\n", "emd_dim", "*", "4", ",", "depths", "[", "2", "]", ",", "num_heads", "[", "2", "]", ",", "emd_dim", "*", "8", ",", "0.0", ",", "dpr", "[", "sum", "(", "depths", "[", ":", "2", "]", ")", ":", "sum", "(", "depths", "[", ":", "3", "]", ")", "]", "\n", ")", "\n", "self", ".", "merge3", "=", "MergeBlock", "(", "emd_dim", "*", "4", ",", "emd_dim", "*", "8", ")", "\n", "\n", "self", ".", "transformer4", "=", "Transformer", "(", "emd_dim", "*", "8", ",", "depths", "[", "3", "]", ",", "num_heads", "[", "3", "]", ",", "emd_dim", "*", "8", ",", "0.0", ",", "dpr", "[", "sum", "(", "depths", "[", ":", "3", "]", ")", ":", "]", ")", "\n", "\n", "self", ".", "num_class", "=", "num_class", "\n", "self", ".", "mlp_head", "=", "nn", ".", "Sequential", "(", "nn", ".", "LayerNorm", "(", "emd_dim", "*", "8", ")", ",", "nn", ".", "Linear", "(", "emd_dim", "*", "8", ",", "self", ".", "num_class", ")", ")", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.NomMerAttn._init_weights": [[566, 574], ["isinstance", "timm.models.layers.trunc_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "trunc_normal_", "(", "m", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "(", "nn", ".", "LayerNorm", ",", "nn", ".", "BatchNorm2d", ")", ")", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.NomMerAttn.forward": [[575, 602], ["nommer.NomMerAttn.cnn1", "nommer.NomMerAttn.bn1", "nommer.NomMerAttn.relu", "nommer.NomMerAttn.permute", "nommer.NomMerAttn.transformer1", "nommer.NomMerAttn.merge1", "nommer.NomMerAttn.transformer2", "nommer.NomMerAttn.merge2", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "nommer.NomMerAttn.transformer3", "nommer.NomMerAttn.merge3", "einops.repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "nommer.NomMerAttn.transformer4", "nommer.NomMerAttn.mlp_head"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "cnn1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "b", ",", "_", ",", "_", ",", "_", "=", "x", ".", "shape", "\n", "\n", "x", "=", "self", ".", "transformer1", "(", "x", ")", "\n", "x", "=", "self", ".", "merge1", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "transformer2", "(", "x", ")", "\n", "x", "=", "self", ".", "merge2", "(", "x", ")", "\n", "\n", "x", "=", "x", "+", "self", ".", "pos_embedding", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "1", ",", "2", ")", "\n", "x", "=", "self", ".", "transformer3", "(", "x", ")", "\n", "x", "=", "self", ".", "merge3", "(", "x", ")", "\n", "\n", "cls_tokens", "=", "repeat", "(", "self", ".", "cls_token", ",", "'() n d -> b n d'", ",", "b", "=", "b", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "cls_tokens", ",", "x", ")", ",", "dim", "=", "1", ")", "\n", "x", "=", "self", ".", "transformer4", "(", "x", ")", "\n", "\n", "x", "=", "x", "[", ":", ",", "0", "]", "\n", "out", "=", "self", ".", "mlp_head", "(", "x", ")", "\n", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.conv3x3": [[141, 152], ["torch.Conv2d"], "function", ["None"], ["", "", "def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ",", "groups", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "\n", "in_planes", ",", "\n", "out_planes", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "dilation", ",", "\n", "groups", "=", "groups", ",", "\n", "bias", "=", "False", ",", "\n", "dilation", "=", "dilation", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.conv1x1": [[155, 158], ["torch.Conv2d"], "function", ["None"], ["", "def", "conv1x1", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"1x1 convolution\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.init_dct_kernel": [[201, 239], ["numpy.zeros", "numpy.meshgrid", "numpy.ones", "range", "numpy.transpose", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.cat", "torch.cat", "torch.cat", "torch.Conv2d", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "range", "range", "numpy.sqrt", "range", "torch.tensor", "torch.tensor", "torch.tensor", "range", "numpy.cos", "numpy.cos"], "function", ["None"], ["", "", "def", "init_dct_kernel", "(", "in_ch", ",", "ksize", "=", "8", ",", "rsize", "=", "2", ")", ":", "\n", "    ", "\"\"\"[init a conv2d kernel for dct]\n\n    Args:\n        in_ch ([int]): [input dims]\n        ksize (int, optional): [kernel size for dct]. Defaults to 8.\n        rsize (int, optional): [reserve size for dct kernel]. Defaults to 2.\n\n    Returns:\n        [nn.Conv2d]: []\n    \"\"\"", "\n", "DCT_filter_n", "=", "np", ".", "zeros", "(", "[", "ksize", ",", "ksize", ",", "1", ",", "rsize", "**", "2", "]", ")", "\n", "XX", ",", "YY", "=", "np", ".", "meshgrid", "(", "range", "(", "ksize", ")", ",", "range", "(", "ksize", ")", ")", "\n", "# DCT basis as filters", "\n", "C", "=", "np", ".", "ones", "(", "ksize", ")", "\n", "C", "[", "0", "]", "=", "1", "/", "np", ".", "sqrt", "(", "2", ")", "\n", "for", "v", "in", "range", "(", "rsize", ")", ":", "\n", "        ", "for", "u", "in", "range", "(", "rsize", ")", ":", "\n", "            ", "kernel", "=", "(", "\n", "(", "2", "*", "C", "[", "v", "]", "*", "C", "[", "u", "]", "/", "ksize", ")", "\n", "*", "np", ".", "cos", "(", "(", "2", "*", "YY", "+", "1", ")", "*", "v", "*", "np", ".", "pi", "/", "(", "2", "*", "ksize", ")", ")", "\n", "*", "np", ".", "cos", "(", "(", "2", "*", "XX", "+", "1", ")", "*", "u", "*", "np", ".", "pi", "/", "(", "2", "*", "ksize", ")", ")", "\n", ")", "\n", "DCT_filter_n", "[", ":", ",", ":", ",", "0", ",", "u", "+", "v", "*", "rsize", "]", "=", "kernel", "\n", "", "", "DCT_filter_n", "=", "np", ".", "transpose", "(", "DCT_filter_n", ",", "(", "3", ",", "2", ",", "0", ",", "1", ")", ")", "\n", "DCT_filter", "=", "torch", ".", "tensor", "(", "DCT_filter_n", ")", ".", "float", "(", ")", "\n", "\n", "DCT_filters", "=", "[", "DCT_filter", "for", "i", "in", "range", "(", "0", ",", "in_ch", ")", "]", "\n", "DCT_filters", "=", "torch", ".", "cat", "(", "DCT_filters", ",", "0", ")", "\n", "\n", "dct_conv", "=", "nn", ".", "Conv2d", "(", "\n", "in_ch", ",", "rsize", "**", "2", "*", "in_ch", ",", "kernel_size", "=", "(", "ksize", ",", "ksize", ")", ",", "stride", "=", "ksize", ",", "padding", "=", "0", ",", "groups", "=", "in_ch", ",", "bias", "=", "False", "\n", ")", "\n", "dct_conv", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "DCT_filters", ")", "\n", "dct_conv", ".", "weight", ".", "requires_grad", "=", "False", "\n", "dct_conv", ".", "requires_grad", "=", "False", "\n", "\n", "return", "dct_conv", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.init_idct_kernel": [[241, 280], ["numpy.zeros", "numpy.ones", "range", "numpy.transpose", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.cat", "torch.cat", "torch.cat", "torch.Conv2d", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "numpy.sqrt", "range", "range", "torch.tensor", "torch.tensor", "torch.tensor", "range", "range", "numpy.cos", "numpy.cos"], "function", ["None"], ["", "def", "init_idct_kernel", "(", "out_ch", ",", "ksize", "=", "8", ",", "rsize", "=", "2", ")", ":", "\n", "    ", "\"\"\"[init a conv2d kernel for idct]\n\n    Args:\n        out_ch ([int]): [output dims]\n        ksize (int, optional): [kernel size for idct]. Defaults to 8.\n        rsize (int, optional): [reserve size for idct kernel]. Defaults to 2.\n\n    Returns:\n        [nn.Conv2d]: []\n    \"\"\"", "\n", "IDCT_filter_n", "=", "np", ".", "zeros", "(", "[", "1", ",", "1", ",", "rsize", "**", "2", ",", "ksize", "**", "2", "]", ")", "\n", "# IDCT basis as filters", "\n", "C", "=", "np", ".", "ones", "(", "ksize", ")", "\n", "C", "[", "0", "]", "=", "1", "/", "np", ".", "sqrt", "(", "2", ")", "\n", "for", "v", "in", "range", "(", "rsize", ")", ":", "\n", "        ", "for", "u", "in", "range", "(", "rsize", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "ksize", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "ksize", ")", ":", "\n", "                    ", "kernel", "=", "(", "\n", "(", "2", "*", "C", "[", "v", "]", "*", "C", "[", "u", "]", "/", "ksize", ")", "\n", "*", "np", ".", "cos", "(", "(", "2", "*", "j", "+", "1", ")", "*", "v", "*", "np", ".", "pi", "/", "(", "2", "*", "ksize", ")", ")", "\n", "*", "np", ".", "cos", "(", "(", "2", "*", "i", "+", "1", ")", "*", "u", "*", "np", ".", "pi", "/", "(", "2", "*", "ksize", ")", ")", "\n", ")", "\n", "IDCT_filter_n", "[", "0", ",", "0", ",", "u", "+", "v", "*", "rsize", ",", "i", "+", "j", "*", "ksize", "]", "=", "kernel", "\n", "\n", "", "", "", "", "IDCT_filter_n", "=", "np", ".", "transpose", "(", "IDCT_filter_n", ",", "(", "3", ",", "2", ",", "0", ",", "1", ")", ")", "\n", "IDCT_filter", "=", "torch", ".", "tensor", "(", "IDCT_filter_n", ")", ".", "float", "(", ")", "\n", "IDCT_filters", "=", "[", "IDCT_filter", "for", "i", "in", "range", "(", "0", ",", "out_ch", ")", "]", "\n", "IDCT_filters", "=", "torch", ".", "cat", "(", "IDCT_filters", ",", "0", ")", "\n", "\n", "idct_conv", "=", "nn", ".", "Conv2d", "(", "\n", "rsize", "**", "2", "*", "out_ch", ",", "ksize", "**", "2", "*", "out_ch", ",", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "groups", "=", "out_ch", ",", "bias", "=", "False", "\n", ")", "\n", "idct_conv", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "IDCT_filters", ")", "\n", "idct_conv", ".", "weight", ".", "requires_grad", "=", "False", "\n", "idct_conv", ".", "requires_grad", "=", "False", "\n", "\n", "return", "idct_conv", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.sample_gumbel": [[312, 316], ["torch.rand", "torch.rand", "torch.rand", "U.cuda.cuda", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "function", ["None"], ["", "", "def", "sample_gumbel", "(", "shape", ",", "eps", "=", "1e-20", ")", ":", "\n", "    ", "U", "=", "torch", ".", "rand", "(", "shape", ")", "\n", "U", "=", "U", ".", "cuda", "(", ")", "\n", "return", "-", "torch", ".", "log", "(", "-", "torch", ".", "log", "(", "U", "+", "eps", ")", "+", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.gumbel_softmax_sample": [[318, 321], ["torch.softmax", "nommer.sample_gumbel", "logits.size"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.sample_gumbel"], ["", "def", "gumbel_softmax_sample", "(", "logits", ",", "tau", "=", "1", ")", ":", "\n", "    ", "y", "=", "logits", "+", "sample_gumbel", "(", "logits", ".", "size", "(", ")", ")", "\n", "return", "F", ".", "softmax", "(", "y", "/", "tau", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.gumbel_softmax": [[323, 344], ["nommer.gumbel_softmax_sample", "gumbel_softmax_sample.size", "gumbel_softmax_sample.max", "torch.zeros_like().view", "torch.zeros_like().view", "torch.zeros_like().view", "y_hard.view.scatter_", "y_hard.view.view", "ind.view", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.models.nommer.gumbel_softmax_sample"], ["", "def", "gumbel_softmax", "(", "logits", ",", "tau", "=", "1", ",", "hard", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    ST-gumple-softmax\n    input: [*, n_class]\n    return: flatten --> [*, n_class] an one-hot vector\n    from https://github.com/ericjang/gumbel-softmax\n    when we use torch.nn.functional.gumbel_softmax and set amp-opt-level==1, train failed(Gradient overflow always)\n    \"\"\"", "\n", "y", "=", "gumbel_softmax_sample", "(", "logits", ",", "tau", ")", "\n", "\n", "if", "not", "hard", ":", "\n", "        ", "return", "y", "\n", "\n", "", "shape", "=", "y", ".", "size", "(", ")", "\n", "_", ",", "ind", "=", "y", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "y_hard", "=", "torch", ".", "zeros_like", "(", "y", ")", ".", "view", "(", "-", "1", ",", "shape", "[", "-", "1", "]", ")", "\n", "y_hard", ".", "scatter_", "(", "1", ",", "ind", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "y_hard", "=", "y_hard", ".", "view", "(", "*", "shape", ")", "\n", "# Set gradients w.r.t. y_hard gradients w.r.t. y", "\n", "y_hard", "=", "(", "y_hard", "-", "y", ")", ".", "detach", "(", ")", "+", "y", "\n", "return", "y_hard", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.samplers.SubsetRandomSampler.__init__": [[21, 24], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "indices", ")", ":", "\n", "        ", "self", ".", "epoch", "=", "0", "\n", "self", ".", "indices", "=", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.samplers.SubsetRandomSampler.__iter__": [[25, 27], ["torch.randperm", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "indices", "[", "i", "]", "for", "i", "in", "torch", ".", "randperm", "(", "len", "(", "self", ".", "indices", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.samplers.SubsetRandomSampler.__len__": [[28, 30], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.samplers.SubsetRandomSampler.set_epoch": [[31, 33], ["None"], "methods", ["None"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "self", ".", "epoch", "=", "epoch", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.build.build_loader": [[24, 92], ["torch.get_world_size", "torch.get_rank", "config.defrost", "build.build_dataset", "config.freeze", "print", "print", "numpy.arange", "samplers.SubsetRandomSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "config.defrost", "build.build_dataset", "config.freeze", "print", "print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "torch.get_rank", "len", "torch.get_world_size", "len", "numpy.arange", "samplers.SubsetRandomSampler", "torch.utils.data.DistributedSampler", "torch.utils.data.DistributedSampler", "print", "timm.data.Mixup", "print", "torch.get_rank", "len", "torch.get_world_size", "torch.get_rank", "torch.get_rank"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.build.build_dataset", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.build.build_dataset"], ["cnn_expansion", "=", "config", ".", "MODEL", ".", "NomMer", ".", "CNN_EXPANSION", ",", "\n", "drop_path_rate", "=", "config", ".", "MODEL", ".", "DROP_PATH_RATE", ",", "\n", "num_class", "=", "config", ".", "MODEL", ".", "NUM_CLASSES", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"Unkown model: {model_type}\"", ")", "\n", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.build.build_dataset": [[95, 117], ["build.build_transform", "NotImplementedError", "cached_image_folder.CachedImageFolder", "os.path.join", "torchvision.datasets.ImageFolder"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.build.build_transform"], []], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.build.build_transform": [[119, 158], ["t.append", "t.append", "torchvision.transforms.Compose", "timm.data.create_transform", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.RandomCrop", "int", "t.append", "t.append", "t.append", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.Resize", "timm.data.transforms._pil_interp", "timm.data.transforms._pil_interp"], "function", ["None"], []], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.DatasetFolder.__init__": [[100, 144], ["list", "cached_image_folder.find_classes", "cached_image_folder.make_dataset", "cached_image_folder.make_dataset_with_ann", "len", "RuntimeError", "set", "cached_image_folder.DatasetFolder.init_cache", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.find_classes", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.make_dataset", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.make_dataset_with_ann", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.DatasetFolder.init_cache"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root", ",", "\n", "loader", ",", "\n", "extensions", ",", "\n", "ann_file", "=", "''", ",", "\n", "img_prefix", "=", "''", ",", "\n", "transform", "=", "None", ",", "\n", "target_transform", "=", "None", ",", "\n", "cache_mode", "=", "\"no\"", ",", "\n", ")", ":", "\n", "# image folder mode", "\n", "        ", "if", "ann_file", "==", "''", ":", "\n", "            ", "_", ",", "class_to_idx", "=", "find_classes", "(", "root", ")", "\n", "samples", "=", "make_dataset", "(", "root", ",", "class_to_idx", ",", "extensions", ")", "\n", "# zip mode", "\n", "", "else", ":", "\n", "            ", "samples", "=", "make_dataset_with_ann", "(", "os", ".", "path", ".", "join", "(", "root", ",", "ann_file", ")", ",", "os", ".", "path", ".", "join", "(", "root", ",", "img_prefix", ")", ",", "extensions", ")", "\n", "\n", "", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "raise", "(", "\n", "RuntimeError", "(", "\n", "\"Found 0 files in subfolders of: \"", "\n", "+", "root", "\n", "+", "\"\\n\"", "\n", "+", "\"Supported extensions are: \"", "\n", "+", "\",\"", ".", "join", "(", "extensions", ")", "\n", ")", "\n", ")", "\n", "\n", "", "self", ".", "root", "=", "root", "\n", "self", ".", "loader", "=", "loader", "\n", "self", ".", "extensions", "=", "extensions", "\n", "\n", "self", ".", "samples", "=", "samples", "\n", "self", ".", "labels", "=", "[", "y_1k", "for", "_", ",", "y_1k", "in", "samples", "]", "\n", "self", ".", "classes", "=", "list", "(", "set", "(", "self", ".", "labels", ")", ")", "\n", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "\n", "self", ".", "cache_mode", "=", "cache_mode", "\n", "if", "self", ".", "cache_mode", "!=", "\"no\"", ":", "\n", "            ", "self", ".", "init_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.DatasetFolder.init_cache": [[145, 166], ["len", "torch.get_rank", "torch.get_rank", "torch.get_world_size", "torch.get_world_size", "time.time", "range", "range", "print", "time.time", "time.time", "zipreader.ZipReader.read", "zipreader.ZipReader.read", "torch.get_rank", "torch.get_rank"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.read", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.read"], ["", "", "def", "init_cache", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "cache_mode", "in", "[", "\"part\"", ",", "\"full\"", "]", "\n", "n_sample", "=", "len", "(", "self", ".", "samples", ")", "\n", "global_rank", "=", "dist", ".", "get_rank", "(", ")", "\n", "world_size", "=", "dist", ".", "get_world_size", "(", ")", "\n", "\n", "samples_bytes", "=", "[", "None", "for", "_", "in", "range", "(", "n_sample", ")", "]", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "for", "index", "in", "range", "(", "n_sample", ")", ":", "\n", "            ", "if", "index", "%", "(", "n_sample", "//", "10", ")", "==", "0", ":", "\n", "                ", "t", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "f'global_rank {dist.get_rank()} cached {index}/{n_sample} takes {t:.2f}s/block'", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "", "path", ",", "target", "=", "self", ".", "samples", "[", "index", "]", "\n", "if", "self", ".", "cache_mode", "==", "\"full\"", ":", "\n", "                ", "samples_bytes", "[", "index", "]", "=", "(", "ZipReader", ".", "read", "(", "path", ")", ",", "target", ")", "\n", "", "elif", "self", ".", "cache_mode", "==", "\"part\"", "and", "index", "%", "world_size", "==", "global_rank", ":", "\n", "                ", "samples_bytes", "[", "index", "]", "=", "(", "ZipReader", ".", "read", "(", "path", ")", ",", "target", ")", "\n", "", "else", ":", "\n", "                ", "samples_bytes", "[", "index", "]", "=", "(", "path", ",", "target", ")", "\n", "", "", "self", ".", "samples", "=", "samples_bytes", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.DatasetFolder.__getitem__": [[167, 182], ["cached_image_folder.DatasetFolder.loader", "cached_image_folder.DatasetFolder.transform", "cached_image_folder.DatasetFolder.target_transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (sample, target) where target is class_index of the target class.\n        \"\"\"", "\n", "path", ",", "target", "=", "self", ".", "samples", "[", "index", "]", "\n", "sample", "=", "self", ".", "loader", "(", "path", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "sample", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.DatasetFolder.__len__": [[183, 185], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.DatasetFolder.__repr__": [[186, 195], ["cached_image_folder.DatasetFolder.__len__", "cached_image_folder.DatasetFolder.transform.__repr__().replace", "cached_image_folder.DatasetFolder.target_transform.__repr__().replace", "cached_image_folder.DatasetFolder.transform.__repr__", "cached_image_folder.DatasetFolder.target_transform.__repr__", "len", "len"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.DatasetFolder.__len__", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.DatasetFolder.__repr__", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.DatasetFolder.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "fmt_str", "=", "'Dataset '", "+", "self", ".", "__class__", ".", "__name__", "+", "'\\n'", "\n", "fmt_str", "+=", "'    Number of datapoints: {}\\n'", ".", "format", "(", "self", ".", "__len__", "(", ")", ")", "\n", "fmt_str", "+=", "'    Root Location: {}\\n'", ".", "format", "(", "self", ".", "root", ")", "\n", "tmp", "=", "'    Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}\\n'", ".", "format", "(", "tmp", ",", "self", ".", "transform", ".", "__repr__", "(", ")", ".", "replace", "(", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "tmp", "=", "'    Target Transforms (if any): '", "\n", "fmt_str", "+=", "'{0}{1}'", ".", "format", "(", "tmp", ",", "self", ".", "target_transform", ".", "__repr__", "(", ")", ".", "replace", "(", "'\\n'", ",", "'\\n'", "+", "' '", "*", "len", "(", "tmp", ")", ")", ")", "\n", "return", "fmt_str", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.CachedImageFolder.__init__": [[251, 272], ["cached_image_folder.DatasetFolder.__init__"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root", ",", "\n", "ann_file", "=", "''", ",", "\n", "img_prefix", "=", "''", ",", "\n", "transform", "=", "None", ",", "\n", "target_transform", "=", "None", ",", "\n", "loader", "=", "default_img_loader", ",", "\n", "cache_mode", "=", "\"no\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", "CachedImageFolder", ",", "self", ")", ".", "__init__", "(", "\n", "root", ",", "\n", "loader", ",", "\n", "IMG_EXTENSIONS", ",", "\n", "ann_file", "=", "ann_file", ",", "\n", "img_prefix", "=", "img_prefix", ",", "\n", "transform", "=", "transform", ",", "\n", "target_transform", "=", "target_transform", ",", "\n", "cache_mode", "=", "cache_mode", ",", "\n", ")", "\n", "self", ".", "imgs", "=", "self", ".", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.CachedImageFolder.__getitem__": [[273, 290], ["cached_image_folder.CachedImageFolder.loader", "cached_image_folder.CachedImageFolder.transform", "cached_image_folder.CachedImageFolder.target_transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is class_index of the target class.\n        \"\"\"", "\n", "path", ",", "target", "=", "self", ".", "samples", "[", "index", "]", "\n", "image", "=", "self", ".", "loader", "(", "path", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "image", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "image", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.has_file_allowed_extension": [[22, 31], ["filename.lower", "any", "filename.lower.endswith"], "function", ["None"], ["def", "has_file_allowed_extension", "(", "filename", ",", "extensions", ")", ":", "\n", "    ", "\"\"\"Checks if a file is an allowed extension.\n    Args:\n        filename (string): path to a file\n    Returns:\n        bool: True if the filename ends with a known image extension\n    \"\"\"", "\n", "filename_lower", "=", "filename", ".", "lower", "(", ")", "\n", "return", "any", "(", "filename_lower", ".", "endswith", "(", "ext", ")", "for", "ext", "in", "extensions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.find_classes": [[33, 38], ["classes.sort", "os.listdir", "os.path.isdir", "range", "os.path.join", "len"], "function", ["None"], ["", "def", "find_classes", "(", "dir", ")", ":", "\n", "    ", "classes", "=", "[", "d", "for", "d", "in", "os", ".", "listdir", "(", "dir", ")", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "d", ")", ")", "]", "\n", "classes", ".", "sort", "(", ")", "\n", "class_to_idx", "=", "{", "classes", "[", "i", "]", ":", "i", "for", "i", "in", "range", "(", "len", "(", "classes", ")", ")", "}", "\n", "return", "classes", ",", "class_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.make_dataset": [[40, 56], ["os.path.expanduser", "sorted", "os.listdir", "os.path.join", "sorted", "os.path.isdir", "os.walk", "sorted", "cached_image_folder.has_file_allowed_extension", "os.path.join", "images.append"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.has_file_allowed_extension"], ["", "def", "make_dataset", "(", "dir", ",", "class_to_idx", ",", "extensions", ")", ":", "\n", "    ", "images", "=", "[", "]", "\n", "dir", "=", "os", ".", "path", ".", "expanduser", "(", "dir", ")", "\n", "for", "target", "in", "sorted", "(", "os", ".", "listdir", "(", "dir", ")", ")", ":", "\n", "        ", "d", "=", "os", ".", "path", ".", "join", "(", "dir", ",", "target", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "d", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "for", "root", ",", "_", ",", "fnames", "in", "sorted", "(", "os", ".", "walk", "(", "d", ")", ")", ":", "\n", "            ", "for", "fname", "in", "sorted", "(", "fnames", ")", ":", "\n", "                ", "if", "has_file_allowed_extension", "(", "fname", ",", "extensions", ")", ":", "\n", "                    ", "path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "fname", ")", "\n", "item", "=", "(", "path", ",", "class_to_idx", "[", "target", "]", ")", "\n", "images", ".", "append", "(", "item", ")", "\n", "\n", "", "", "", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.make_dataset_with_ann": [[58, 77], ["open", "f.readlines", "len", "int", "images.append", "str.lower", "os.path.join", "random.random", "line_str.split", "os.path.splitext"], "function", ["None"], ["", "def", "make_dataset_with_ann", "(", "ann_file", ",", "img_prefix", ",", "extensions", ")", ":", "\n", "    ", "images", "=", "[", "]", "\n", "filter_r", "=", "0.75", "\n", "with", "open", "(", "ann_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "contents", "=", "f", ".", "readlines", "(", ")", "\n", "lines_num", "=", "len", "(", "contents", ")", "\n", "for", "line_str", "in", "contents", ":", "\n", "            ", "if", "random", ".", "random", "(", ")", ">", "filter_r", "and", "lines_num", ">", "5000000", ":", "\n", "                ", "continue", "\n", "", "path_contents", "=", "[", "c", "for", "c", "in", "line_str", ".", "split", "(", "'\\t'", ")", "]", "\n", "im_file_name", "=", "path_contents", "[", "0", "]", "\n", "class_index", "=", "int", "(", "path_contents", "[", "1", "]", ")", "\n", "\n", "assert", "str", ".", "lower", "(", "os", ".", "path", ".", "splitext", "(", "im_file_name", ")", "[", "-", "1", "]", ")", "in", "extensions", "\n", "item", "=", "(", "os", ".", "path", ".", "join", "(", "img_prefix", ",", "im_file_name", ")", ",", "class_index", ")", "\n", "\n", "images", ".", "append", "(", "item", ")", "\n", "\n", "", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.pil_loader": [[200, 211], ["isinstance", "Image.open.convert", "PIL.Image.open", "zipreader.is_zip_path", "io.BytesIO", "zipreader.ZipReader.read", "PIL.Image.open", "io.BytesIO", "open", "PIL.Image.open"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.is_zip_path", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.read"], ["def", "pil_loader", "(", "path", ")", ":", "\n", "# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)", "\n", "    ", "if", "isinstance", "(", "path", ",", "bytes", ")", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "io", ".", "BytesIO", "(", "path", ")", ")", "\n", "", "elif", "is_zip_path", "(", "path", ")", ":", "\n", "        ", "data", "=", "ZipReader", ".", "read", "(", "path", ")", "\n", "img", "=", "Image", ".", "open", "(", "io", ".", "BytesIO", "(", "data", ")", ")", "\n", "", "else", ":", "\n", "        ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "f", ")", "\n", "", "", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.accimage_loader": [[213, 221], ["accimage.Image", "cached_image_folder.pil_loader"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.pil_loader"], ["", "def", "accimage_loader", "(", "path", ")", ":", "\n", "    ", "import", "accimage", "\n", "\n", "try", ":", "\n", "        ", "return", "accimage", ".", "Image", "(", "path", ")", "\n", "", "except", "IOError", ":", "\n", "# Potentially a decoding problem, fall back to PIL.Image", "\n", "        ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.default_img_loader": [[223, 230], ["get_image_backend", "cached_image_folder.accimage_loader", "cached_image_folder.pil_loader"], "function", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.accimage_loader", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.cached_image_folder.pil_loader"], ["", "", "def", "default_img_loader", "(", "path", ")", ":", "\n", "    ", "from", "torchvision", "import", "get_image_backend", "\n", "\n", "if", "get_image_backend", "(", ")", "==", "'accimage'", ":", "\n", "        ", "return", "accimage_loader", "(", "path", ")", "\n", "", "else", ":", "\n", "        ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.__init__": [[31, 33], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "ZipReader", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.get_zipfile": [[34, 41], ["zipfile.ZipFile"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_zipfile", "(", "path", ")", ":", "\n", "        ", "zip_bank", "=", "ZipReader", ".", "zip_bank", "\n", "if", "path", "not", "in", "zip_bank", ":", "\n", "            ", "zfile", "=", "zipfile", ".", "ZipFile", "(", "path", ",", "'r'", ")", "\n", "zip_bank", "[", "path", "]", "=", "zfile", "\n", "", "return", "zip_bank", "[", "path", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.split_zip_style_path": [[42, 51], ["path.index", "str.strip"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "split_zip_style_path", "(", "path", ")", ":", "\n", "        ", "pos_at", "=", "path", ".", "index", "(", "'@'", ")", "\n", "assert", "pos_at", "!=", "-", "1", ",", "\"character '@' is not found from the given path '%s'\"", "%", "path", "\n", "\n", "zip_path", "=", "path", "[", "0", ":", "pos_at", "]", "\n", "folder_path", "=", "path", "[", "pos_at", "+", "1", ":", "]", "\n", "folder_path", "=", "str", ".", "strip", "(", "folder_path", ",", "'/'", ")", "\n", "return", "zip_path", ",", "folder_path", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.read": [[52, 58], ["zipreader.ZipReader.split_zip_style_path", "zipreader.ZipReader.get_zipfile", "zipreader.ZipReader.get_zipfile"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.split_zip_style_path", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.get_zipfile", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.get_zipfile"], ["", "@", "staticmethod", "\n", "def", "read", "(", "path", ")", ":", "\n", "        ", "zip_path", ",", "path_img", "=", "ZipReader", ".", "split_zip_style_path", "(", "path", ")", "\n", "zfile", "=", "ZipReader", ".", "get_zipfile", "(", "zip_path", ")", "\n", "data", "=", "zfile", ".", "read", "(", "path_img", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.imread": [[59, 73], ["zipreader.ZipReader.split_zip_style_path", "zipreader.ZipReader.get_zipfile", "zipreader.ZipReader.get_zipfile", "PIL.Image.open", "io.BytesIO", "print", "PIL.Image.fromarray", "numpy.random.rand", "numpy.uint8"], "methods", ["home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.split_zip_style_path", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.get_zipfile", "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.ZipReader.get_zipfile"], ["", "@", "staticmethod", "\n", "def", "imread", "(", "path", ")", ":", "\n", "        ", "zip_path", ",", "path_img", "=", "ZipReader", ".", "split_zip_style_path", "(", "path", ")", "\n", "zfile", "=", "ZipReader", ".", "get_zipfile", "(", "zip_path", ")", "\n", "data", "=", "zfile", ".", "read", "(", "path_img", ")", "\n", "data", "=", "data", "[", "10", ":", "]", "\n", "try", ":", "\n", "            ", "im", "=", "Image", ".", "open", "(", "io", ".", "BytesIO", "(", "data", ")", ")", "\n", "", "except", "UnidentifiedImageError", ":", "\n", "            ", "print", "(", "\"ERROR IMG LOADED: \"", ",", "path_img", ")", "\n", "random_img", "=", "np", ".", "random", ".", "rand", "(", "224", ",", "224", ",", "3", ")", "*", "255", "\n", "im", "=", "Image", ".", "fromarray", "(", "np", ".", "uint8", "(", "random_img", ")", ")", "\n", "\n", "", "return", "im", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tencentyouturesearch_visualrecognition-nommer.data.zipreader.is_zip_path": [[21, 24], ["None"], "function", ["None"], ["def", "is_zip_path", "(", "img_or_path", ")", ":", "\n", "    ", "\"\"\"judge if this is a zip path\"\"\"", "\n", "return", "'.zip@'", "in", "img_or_path", "\n", "\n"]]}