{"home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_vision.__init__": [[31, 57], ["numpy.load().item", "numpy.random.shuffle", "tqdm.tqdm.tqdm", "print", "numpy.load", "glob.glob.glob", "os.path.exists", "f.split", "f.split", "os.path.exists", "len", "data_loaders.mesh_loader_vision.names.append", "data_loaders.mesh_loader_vision.classes_names[].append", "classes.index"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load"], ["\t", "def", "__init__", "(", "self", ",", "classes", ",", "args", ",", "set_type", "=", "'train'", ",", "sample_num", "=", "3000", ")", ":", "\n", "\n", "# initialization of data locations", "\n", "\t\t", "self", ".", "args", "=", "args", "\n", "self", ".", "surf_location", "=", "'../data/surfaces/'", "\n", "self", ".", "img_location", "=", "'../data/images/'", "\n", "self", ".", "touch_location", "=", "'../data/scene_info/'", "\n", "self", ".", "sheet_location", "=", "'../data/sheets/'", "\n", "self", ".", "sample_num", "=", "sample_num", "\n", "self", ".", "set_type", "=", "set_type", "\n", "self", ".", "set_list", "=", "np", ".", "load", "(", "'../data/split.npy'", ",", "allow_pickle", "=", "'TRUE'", ")", ".", "item", "(", ")", "\n", "\n", "names", "=", "[", "[", "f", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ",", "f", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "]", "for", "f", "in", "glob", "(", "(", "f'{self.img_location}/*/*'", ")", ")", "]", "\n", "self", ".", "names", "=", "[", "]", "\n", "self", ".", "classes_names", "=", "[", "[", "]", "for", "_", "in", "classes", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "names", ")", "\n", "for", "n", "in", "tqdm", "(", "names", ")", ":", "\n", "\t\t\t", "if", "n", "[", "1", "]", "in", "classes", ":", "\n", "\t\t\t\t", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "surf_location", "+", "n", "[", "1", "]", "+", "'/'", "+", "n", "[", "0", "]", "+", "'.npy'", ")", ":", "\n", "\t\t\t\t\t", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "touch_location", "+", "n", "[", "1", "]", "+", "'/'", "+", "n", "[", "0", "]", ")", ":", "\n", "\t\t\t\t\t\t", "if", "n", "[", "0", "]", "+", "n", "[", "1", "]", "in", "self", ".", "set_list", "[", "self", ".", "set_type", "]", ":", "\n", "\t\t\t\t\t\t\t", "if", "n", "[", "0", "]", "+", "n", "[", "1", "]", "in", "self", ".", "set_list", "[", "self", ".", "set_type", "]", ":", "\n", "\t\t\t\t\t\t\t\t", "self", ".", "names", ".", "append", "(", "n", ")", "\n", "self", ".", "classes_names", "[", "classes", ".", "index", "(", "n", "[", "1", "]", ")", "]", ".", "append", "(", "n", ")", "\n", "\n", "", "", "", "", "", "", "print", "(", "f'The number of {set_type} set objects found : {len(self.names)}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_vision.__len__": [[58, 60], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "\t\t", "return", "len", "(", "self", ".", "names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_vision.get_training_instance": [[62, 76], ["random.choice", "random.choice", "range", "random.shuffle", "random.choice", "nums.append", "num_choices.index"], "methods", ["None"], ["", "def", "get_training_instance", "(", "self", ")", ":", "\n", "# select an object and and a principle grasp randomly", "\n", "\t\t", "class_choice", "=", "random", ".", "choice", "(", "self", ".", "classes_names", ")", "\n", "object_choice", "=", "random", ".", "choice", "(", "class_choice", ")", "\n", "obj", ",", "obj_class", "=", "object_choice", "\n", "# select the remaining grasps and shuffle the select grasps", "\n", "num_choices", "=", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", "\n", "nums", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "args", ".", "num_grasps", ")", ":", "\n", "\t\t\t", "choice", "=", "random", ".", "choice", "(", "num_choices", ")", "\n", "nums", ".", "append", "(", "choice", ")", "\n", "del", "(", "num_choices", "[", "num_choices", ".", "index", "(", "choice", ")", "]", ")", "\n", "", "random", ".", "shuffle", "(", "nums", ")", "\n", "return", "obj", ",", "obj_class", ",", "nums", "[", "-", "1", "]", ",", "nums", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_vision.get_validation_examples": [[78, 85], ["range"], "methods", ["None"], ["", "def", "get_validation_examples", "(", "self", ",", "index", ")", ":", "\n", "# select an object and a principle grasp", "\n", "\t\t", "obj", ",", "obj_class", "=", "self", ".", "names", "[", "index", "]", "\n", "orig_num", "=", "0", "\n", "# select the remaining grasps deterministically", "\n", "nums", "=", "[", "(", "orig_num", "+", "i", ")", "%", "5", "for", "i", "in", "range", "(", "self", ".", "args", ".", "num_grasps", ")", "]", "\n", "return", "obj", ",", "obj_class", ",", "orig_num", ",", "nums", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_vision.get_gt_points": [[87, 96], ["numpy.load", "numpy.random.shuffle", "torch.FloatTensor", "numpy.random.seed"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load"], ["", "def", "get_gt_points", "(", "self", ",", "obj_class", ",", "obj", ")", ":", "\n", "\t\t", "samples", "=", "np", ".", "load", "(", "self", ".", "surf_location", "+", "obj_class", "+", "'/'", "+", "obj", "+", "'.npy'", ")", "\n", "if", "self", ".", "args", ".", "eval", ":", "\n", "\t\t\t", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "", "np", ".", "random", ".", "shuffle", "(", "samples", ")", "\n", "gt_points", "=", "torch", ".", "FloatTensor", "(", "samples", "[", ":", "self", ".", "sample_num", "]", ")", "\n", "gt_points", "*=", ".5", "# scales the models to the size of shape we use", "\n", "gt_points", "[", ":", ",", "-", "1", "]", "+=", ".6", "# this is to make the hand and the shape the right releative sizes", "\n", "return", "gt_points", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_vision.get_images": [[98, 106], ["PIL.Image.open", "PIL.Image.open", "preprocess", "preprocess", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["None"], ["", "def", "get_images", "(", "self", ",", "obj_class", ",", "obj", ",", "grasp_number", ")", ":", "\n", "# load images", "\n", "\t\t", "img_occ", "=", "Image", ".", "open", "(", "f'{self.img_location}/{obj_class}/{obj}/{grasp_number}.png'", ")", "\n", "img_unocc", "=", "Image", ".", "open", "(", "f'{self.img_location}/{obj_class}/{obj}/unoccluded.png'", ")", "\n", "# apply pytorch image preprocessing", "\n", "img_occ", "=", "preprocess", "(", "img_occ", ")", "\n", "img_unocc", "=", "preprocess", "(", "img_unocc", ")", "\n", "return", "torch", ".", "FloatTensor", "(", "img_occ", ")", ",", "torch", ".", "FloatTensor", "(", "img_unocc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_vision.get_touch_info": [[108, 118], ["numpy.load().item", "data_loaders.mesh_loader_vision.get_touch_sheets", "sheets.append", "torch.cat", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_vision.get_touch_sheets", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load"], ["", "def", "get_touch_info", "(", "self", ",", "obj_class", ",", "obj", ",", "grasps", ")", ":", "\n", "\t\t", "sheets", ",", "successful", "=", "[", "]", ",", "[", "]", "\n", "# cycle though grasps and load touch sheets", "\n", "for", "grasp", "in", "grasps", ":", "\n", "\t\t\t", "sheet_location", "=", "self", ".", "sheet_location", "+", "f'{obj_class}/{obj}/sheets_{grasp}_finger_num.npy'", "\n", "hand_info", "=", "np", ".", "load", "(", "f'{self.touch_location}/{obj_class}/{obj}/{grasp}.npy'", ",", "allow_pickle", "=", "True", ")", ".", "item", "(", ")", "\n", "sheet", ",", "success", "=", "self", ".", "get_touch_sheets", "(", "sheet_location", ",", "hand_info", ")", "\n", "sheets", ".", "append", "(", "sheet", ")", "\n", "successful", "+=", "success", "\n", "", "return", "torch", ".", "cat", "(", "sheets", ")", ",", "successful", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_vision.get_touch_sheets": [[120, 138], ["torch.FloatTensor", "range", "torch.stack", "numpy.load", "location.replace", "torch.stack.append", "successful.append", "torch.stack.append", "successful.append", "str", "finger_pos[].view().expand", "torch.FloatTensor", "finger_pos[].view"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load"], ["", "def", "get_touch_sheets", "(", "self", ",", "location", ",", "hand_info", ")", ":", "\n", "\t\t", "sheets", "=", "[", "]", "\n", "successful", "=", "[", "]", "\n", "touches", "=", "hand_info", "[", "'touch_success'", "]", "\n", "finger_pos", "=", "torch", ".", "FloatTensor", "(", "hand_info", "[", "'cam_pos'", "]", ")", "\n", "# cycle through fingers in the grasp", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "\t\t\t", "sheet", "=", "np", ".", "load", "(", "location", ".", "replace", "(", "'finger_num'", ",", "str", "(", "i", ")", ")", ")", "\n", "# if the touch was unsuccessful", "\n", "if", "not", "touches", "[", "i", "]", "or", "sheet", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "\t\t\t\t", "sheets", ".", "append", "(", "finger_pos", "[", "i", "]", ".", "view", "(", "1", ",", "3", ")", ".", "expand", "(", "25", ",", "3", ")", ")", "# save the finger position instead in every vertex", "\n", "successful", ".", "append", "(", "False", ")", "# binary mask for unsuccessful touch", "\n", "# if the touch was successful", "\n", "", "else", ":", "\n", "\t\t\t\t", "sheets", ".", "append", "(", "torch", ".", "FloatTensor", "(", "sheet", ")", ")", "# save the sheet", "\n", "successful", ".", "append", "(", "True", ")", "# binary mask for successful touch", "\n", "", "", "sheets", "=", "torch", ".", "stack", "(", "sheets", ")", "\n", "return", "sheets", ",", "successful", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_vision.__getitem__": [[139, 160], ["data_loaders.mesh_loader_vision.get_gt_points", "data_loaders.mesh_loader_vision.get_images", "data_loaders.mesh_loader_vision.get_touch_info", "data_loaders.mesh_loader_vision.get_training_instance", "data_loaders.mesh_loader_vision.get_validation_examples"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_vision.get_gt_points", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_vision.get_images", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_vision.get_touch_info", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_vision.get_training_instance", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_vision.get_validation_examples"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\t\t", "if", "self", ".", "set_type", "==", "'train'", ":", "\n", "\t\t\t", "obj", ",", "obj_class", ",", "grasp_number", ",", "grasps", "=", "self", ".", "get_training_instance", "(", ")", "\n", "", "else", ":", "\n", "\t\t\t", "obj", ",", "obj_class", ",", "grasp_number", ",", "grasps", "=", "self", ".", "get_validation_examples", "(", "index", ")", "\n", "", "data", "=", "{", "}", "\n", "\n", "# meta data", "\n", "data", "[", "'names'", "]", "=", "obj", ",", "obj_class", ",", "grasp_number", "\n", "data", "[", "'class'", "]", "=", "obj_class", "\n", "\n", "# load sampled ground truth points", "\n", "data", "[", "'gt_points'", "]", "=", "self", ".", "get_gt_points", "(", "obj_class", ",", "obj", ")", "\n", "\n", "# load images", "\n", "data", "[", "'img_occ'", "]", ",", "data", "[", "'img_unocc'", "]", "=", "self", ".", "get_images", "(", "obj_class", ",", "obj", ",", "grasp_number", ")", "\n", "\n", "# get touch information", "\n", "data", "[", "'sheets'", "]", ",", "data", "[", "'successful'", "]", "=", "self", ".", "get_touch_info", "(", "obj_class", ",", "obj", ",", "grasps", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_vision.collate": [[161, 172], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "item[].unsqueeze", "item[].unsqueeze", "item[].unsqueeze", "item[].unsqueeze"], "methods", ["None"], ["", "def", "collate", "(", "self", ",", "batch", ")", ":", "\n", "\t\t", "data", "=", "{", "}", "\n", "data", "[", "'names'", "]", "=", "[", "item", "[", "'names'", "]", "for", "item", "in", "batch", "]", "\n", "data", "[", "'class'", "]", "=", "[", "item", "[", "'class'", "]", "for", "item", "in", "batch", "]", "\n", "data", "[", "'sheets'", "]", "=", "torch", ".", "cat", "(", "[", "item", "[", "'sheets'", "]", ".", "unsqueeze", "(", "0", ")", "for", "item", "in", "batch", "]", ")", "\n", "data", "[", "'gt_points'", "]", "=", "torch", ".", "cat", "(", "[", "item", "[", "'gt_points'", "]", ".", "unsqueeze", "(", "0", ")", "for", "item", "in", "batch", "]", ")", "\n", "data", "[", "'img_occ'", "]", "=", "torch", ".", "cat", "(", "[", "item", "[", "'img_occ'", "]", ".", "unsqueeze", "(", "0", ")", "for", "item", "in", "batch", "]", ")", "\n", "data", "[", "'img_unocc'", "]", "=", "torch", ".", "cat", "(", "[", "item", "[", "'img_unocc'", "]", ".", "unsqueeze", "(", "0", ")", "for", "item", "in", "batch", "]", ")", "\n", "data", "[", "'successful'", "]", "=", "[", "item", "[", "'successful'", "]", "for", "item", "in", "batch", "]", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_touch.__init__": [[184, 220], ["numpy.load().item", "torch.FloatTensor", "tqdm.tqdm.tqdm", "print", "numpy.load", "numpy.load", "glob.glob.glob", "os.path.exists", "f.split", "f.split", "os.path.exists", "len", "range", "range", "range", "numpy.load().item", "range", "data_loaders.mesh_loader_touch.names.append", "numpy.load", "data_loaders.mesh_loader_touch.names.append"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load"], ["\t", "def", "__init__", "(", "self", ",", "classes", ",", "args", ",", "set_type", "=", "'train'", ",", "produce_sheets", "=", "False", ")", ":", "\n", "\n", "# initialization of data locations", "\n", "\t\t", "self", ".", "args", "=", "args", "\n", "self", ".", "surf_location", "=", "'../data/surfaces/'", "\n", "self", ".", "img_location", "=", "'../data/images/'", "\n", "self", ".", "touch_location", "=", "'../data/scene_info/'", "\n", "self", ".", "sheet_location", "=", "'../data/remake_sheets/'", "\n", "self", ".", "set_type", "=", "set_type", "\n", "self", ".", "set_list", "=", "np", ".", "load", "(", "'../data/split.npy'", ",", "allow_pickle", "=", "'TRUE'", ")", ".", "item", "(", ")", "\n", "self", ".", "empty", "=", "torch", ".", "FloatTensor", "(", "np", ".", "load", "(", "'../data/empty_gel.npy'", ")", ")", "\n", "self", ".", "produce_sheets", "=", "produce_sheets", "\n", "\n", "\n", "\n", "names", "=", "[", "[", "f", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ",", "f", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "]", "for", "f", "in", "glob", "(", "(", "f'{self.img_location}/*/*'", ")", ")", "]", "\n", "self", ".", "names", "=", "[", "]", "\n", "import", "os", "\n", "for", "n", "in", "tqdm", "(", "names", ")", ":", "\n", "\t\t\t", "if", "n", "[", "1", "]", "in", "classes", ":", "\n", "\t\t\t\t", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "surf_location", "+", "n", "[", "1", "]", "+", "'/'", "+", "n", "[", "0", "]", "+", "'.npy'", ")", ":", "\n", "\t\t\t\t\t", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "touch_location", "+", "n", "[", "1", "]", "+", "'/'", "+", "n", "[", "0", "]", ")", ":", "\n", "\t\t\t\t\t\t", "if", "self", ".", "produce_sheets", "or", "(", "n", "[", "0", "]", "+", "n", "[", "1", "]", ")", "in", "self", ".", "set_list", "[", "self", ".", "set_type", "]", ":", "\n", "\t\t\t\t\t\t\t", "if", "produce_sheets", ":", "\n", "\t\t\t\t\t\t\t\t", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "\t\t\t\t\t\t\t\t\t", "for", "j", "in", "range", "(", "4", ")", ":", "\n", "\t\t\t\t\t\t\t\t\t\t\t", "self", ".", "names", ".", "append", "(", "n", "+", "[", "i", ",", "j", "]", ")", "\n", "", "", "", "else", ":", "\n", "\t\t\t\t\t\t\t\t", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "\t\t\t\t\t\t\t\t\t", "hand_info", "=", "np", ".", "load", "(", "f'{self.touch_location}/{n[1]}/{n[0]}/{i}.npy'", ",", "\n", "allow_pickle", "=", "True", ")", ".", "item", "(", ")", "\n", "for", "j", "in", "range", "(", "4", ")", ":", "\n", "\t\t\t\t\t\t\t\t\t\t", "if", "hand_info", "[", "'touch_success'", "]", "[", "j", "]", ":", "\n", "\t\t\t\t\t\t\t\t\t\t\t", "self", ".", "names", ".", "append", "(", "n", "+", "[", "i", ",", "j", "]", ")", "\n", "\n", "", "", "", "", "", "", "", "", "", "print", "(", "f'The number of {set_type} set objects found : {len(self.names)}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_touch.__len__": [[221, 223], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "\t\t", "return", "len", "(", "self", ".", "names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_touch.standerdize_point_size": [[224, 234], ["numpy.random.shuffle", "torch.FloatTensor", "torch.randperm", "torch.zeros", "torch.cat"], "methods", ["None"], ["", "def", "standerdize_point_size", "(", "self", ",", "points", ")", ":", "\n", "\t\t", "if", "points", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "\t\t\t", "return", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "num_samples", ",", "3", ")", ")", "\n", "", "np", ".", "random", ".", "shuffle", "(", "points", ")", "\n", "points", "=", "torch", ".", "FloatTensor", "(", "points", ")", "\n", "while", "points", ".", "shape", "[", "0", "]", "<", "self", ".", "args", ".", "num_samples", ":", "\n", "\t\t\t", "points", "=", "torch", ".", "cat", "(", "(", "points", ",", "points", ",", "points", ",", "points", ")", ")", "\n", "", "perm", "=", "torch", ".", "randperm", "(", "points", ".", "shape", "[", "0", "]", ")", "\n", "idx", "=", "perm", "[", ":", "self", ".", "args", ".", "num_samples", "]", "\n", "return", "points", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_touch.get_finger_transforms": [[235, 241], ["scipy.spatial.transform.Rotation.from_euler().as_matrix", "scipy.spatial.transform.Rotation.from_matrix().as_quat", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "scipy.spatial.transform.Rotation.from_euler", "scipy.spatial.transform.Rotation.from_matrix"], "methods", ["None"], ["", "def", "get_finger_transforms", "(", "self", ",", "hand_info", ",", "finger_num", ",", "args", ")", ":", "\n", "\t\t", "rot", "=", "hand_info", "[", "'cam_rot'", "]", "[", "finger_num", "]", "\n", "rot", "=", "R", ".", "from_euler", "(", "'xyz'", ",", "rot", ",", "degrees", "=", "False", ")", ".", "as_matrix", "(", ")", "\n", "rot_q", "=", "R", ".", "from_matrix", "(", "rot", ")", ".", "as_quat", "(", ")", "\n", "pos", "=", "hand_info", "[", "'cam_pos'", "]", "[", "finger_num", "]", "\n", "return", "torch", ".", "FloatTensor", "(", "rot_q", ")", ",", "torch", ".", "FloatTensor", "(", "rot", ")", ",", "torch", ".", "FloatTensor", "(", "pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_touch.__getitem__": [[243, 269], ["numpy.load().item", "data_loaders.mesh_loader_touch.get_finger_transforms", "numpy.load().item", "torch.clamp", "torch.FloatTensor().permute().contiguous().view", "torch.FloatTensor().permute().contiguous().view", "data_loaders.mesh_loader_touch.standerdize_point_size", "torch.FloatTensor().unsqueeze", "numpy.load", "numpy.load", "torch.FloatTensor().permute().contiguous", "torch.FloatTensor().permute().contiguous", "torch.FloatTensor", "torch.FloatTensor().permute", "torch.FloatTensor().permute", "torch.FloatTensor", "torch.FloatTensor", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_touch.get_finger_transforms", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_touch.standerdize_point_size", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\t\t", "obj", ",", "obj_class", ",", "num", ",", "finger_num", "=", "self", ".", "names", "[", "index", "]", "\n", "\n", "# meta data", "\n", "data", "=", "{", "}", "\n", "data", "[", "'names'", "]", "=", "[", "obj", ",", "num", ",", "finger_num", "]", "\n", "data", "[", "'class'", "]", "=", "obj_class", "\n", "\n", "# hand infomation", "\n", "hand_info", "=", "np", ".", "load", "(", "f'{self.touch_location}/{obj_class}/{obj}/{num}.npy'", ",", "allow_pickle", "=", "True", ")", ".", "item", "(", ")", "\n", "data", "[", "'rot'", "]", ",", "data", "[", "'rot_M'", "]", ",", "data", "[", "'pos'", "]", "=", "self", ".", "get_finger_transforms", "(", "hand_info", ",", "finger_num", ",", "self", ".", "args", ")", "\n", "data", "[", "'good_touch'", "]", "=", "hand_info", "[", "'touch_success'", "]", "\n", "\n", "# simulated touch information", "\n", "scene_info", "=", "np", ".", "load", "(", "f'{self.touch_location}/{obj_class}/{obj}/{num}.npy'", ",", "allow_pickle", "=", "True", ")", ".", "item", "(", ")", "\n", "data", "[", "'depth'", "]", "=", "torch", ".", "clamp", "(", "torch", ".", "FloatTensor", "(", "scene_info", "[", "'depth'", "]", "[", "finger_num", "]", ")", ".", "unsqueeze", "(", "0", ")", ",", "0", ",", "1", ")", "\n", "data", "[", "'sim_touch'", "]", "=", "torch", ".", "FloatTensor", "(", "np", ".", "array", "(", "scene_info", "[", "'gel'", "]", "[", "finger_num", "]", ")", "/", "255.", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "3", ",", "100", ",", "100", ")", "\n", "data", "[", "'empty'", "]", "=", "torch", ".", "FloatTensor", "(", "self", ".", "empty", "/", "255.", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "3", ",", "100", ",", "100", ")", "\n", "\n", "# point cloud information", "\n", "data", "[", "'samples'", "]", "=", "self", ".", "standerdize_point_size", "(", "scene_info", "[", "'points'", "]", "[", "finger_num", "]", ")", "\n", "data", "[", "'num_samples'", "]", "=", "scene_info", "[", "'points'", "]", "[", "finger_num", "]", ".", "shape", "\n", "\n", "# where to save sheets", "\n", "data", "[", "'save_dir'", "]", "=", "f'{self.sheet_location}/{obj_class}/{obj}/sheets_{num}_{finger_num}.npy'", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.data_loaders.mesh_loader_touch.collate": [[272, 289], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "item[].unsqueeze", "item[].unsqueeze", "item[].unsqueeze", "item[].unsqueeze", "item[].unsqueeze", "item[].unsqueeze", "item[].unsqueeze"], "methods", ["None"], ["", "def", "collate", "(", "self", ",", "batch", ")", ":", "\n", "\t\t", "data", "=", "{", "}", "\n", "data", "[", "'names'", "]", "=", "[", "item", "[", "'names'", "]", "for", "item", "in", "batch", "]", "\n", "data", "[", "'class'", "]", "=", "[", "item", "[", "'class'", "]", "for", "item", "in", "batch", "]", "\n", "data", "[", "'samples'", "]", "=", "torch", ".", "cat", "(", "[", "item", "[", "'samples'", "]", ".", "unsqueeze", "(", "0", ")", "for", "item", "in", "batch", "]", ")", "\n", "data", "[", "'sim_touch'", "]", "=", "torch", ".", "cat", "(", "[", "item", "[", "'sim_touch'", "]", ".", "unsqueeze", "(", "0", ")", "for", "item", "in", "batch", "]", ")", "\n", "data", "[", "'empty'", "]", "=", "torch", ".", "cat", "(", "[", "item", "[", "'empty'", "]", ".", "unsqueeze", "(", "0", ")", "for", "item", "in", "batch", "]", ")", "\n", "data", "[", "'depth'", "]", "=", "torch", ".", "cat", "(", "[", "item", "[", "'depth'", "]", ".", "unsqueeze", "(", "0", ")", "for", "item", "in", "batch", "]", ")", "\n", "data", "[", "'ref'", "]", "=", "{", "}", "\n", "data", "[", "'ref'", "]", "[", "'rot'", "]", "=", "torch", ".", "cat", "(", "[", "item", "[", "'rot'", "]", ".", "unsqueeze", "(", "0", ")", "for", "item", "in", "batch", "]", ")", "\n", "data", "[", "'ref'", "]", "[", "'rot_M'", "]", "=", "torch", ".", "cat", "(", "[", "item", "[", "'rot_M'", "]", ".", "unsqueeze", "(", "0", ")", "for", "item", "in", "batch", "]", ")", "\n", "data", "[", "'ref'", "]", "[", "'pos'", "]", "=", "torch", ".", "cat", "(", "[", "item", "[", "'pos'", "]", ".", "unsqueeze", "(", "0", ")", "for", "item", "in", "batch", "]", ")", "\n", "data", "[", "'good_touch'", "]", "=", "[", "item", "[", "'good_touch'", "]", "for", "item", "in", "batch", "]", "\n", "data", "[", "'save_dir'", "]", "=", "[", "item", "[", "'save_dir'", "]", "for", "item", "in", "batch", "]", "\n", "data", "[", "'num_samples'", "]", "=", "[", "item", "[", "'num_samples'", "]", "for", "item", "in", "batch", "]", "\n", "\n", "return", "data", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.import_obj.__init__": [[42, 53], ["open", "line.replace.replace.replace", "line.replace.replace.replace", "utils.import_obj.vertices.append", "utils.import_obj.faces.append", "float", "int", "line.replace.replace.split", "s.split", "line.replace.replace.split"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "file", ")", ":", "\n", "\t\t", "self", ".", "vertices", "=", "[", "]", "\n", "self", ".", "faces", "=", "[", "]", "\n", "with", "open", "(", "file", ")", "as", "f", ":", "\n", "\t\t\t", "for", "line", "in", "f", ":", "\n", "\t\t\t\t", "line", "=", "line", ".", "replace", "(", "'//'", ",", "'/'", ")", "\n", "line", "=", "line", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "if", "line", "[", ":", "2", "]", "==", "\"v \"", ":", "\n", "\t\t\t\t\t", "self", ".", "vertices", ".", "append", "(", "[", "float", "(", "v", ")", "for", "v", "in", "line", ".", "split", "(", "\" \"", ")", "[", "1", ":", "]", "]", ")", "\n", "", "elif", "line", "[", "0", "]", "==", "\"f\"", ":", "\n", "\t\t\t\t\t", "self", ".", "faces", ".", "append", "(", "[", "int", "(", "s", ".", "split", "(", "'/'", ")", "[", "0", "]", ")", "for", "s", "in", "line", ".", "split", "(", "' '", ")", "[", "1", ":", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.load_mesh_vision": [[27, 36], ["utils.import_obj", "numpy.array", "torch.FloatTensor().cuda", "torch.LongTensor().cuda", "utils.adj_init", "torch.FloatTensor", "torch.LongTensor", "numpy.array"], "function", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.adj_init"], ["def", "load_mesh_vision", "(", "args", ",", "obj_name", ")", ":", "\n", "# load obj file", "\n", "\t", "obj", "=", "import_obj", "(", "obj_name", ")", "\n", "verts", "=", "np", ".", "array", "(", "obj", ".", "vertices", ")", "\n", "verts", "=", "torch", ".", "FloatTensor", "(", "verts", ")", ".", "cuda", "(", ")", "\n", "faces", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "obj", ".", "faces", ")", "-", "1", ")", ".", "cuda", "(", ")", "\n", "# get adjacency matrix infomation", "\n", "adj_info", "=", "adj_init", "(", "verts", ",", "faces", ",", "args", ")", "\n", "return", "adj_info", ",", "verts", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.normalize_adj": [[56, 62], ["torch.mm.sum", "torch.mm", "torch.eye().to", "torch.eye"], "function", ["None"], ["", "", "", "", "", "def", "normalize_adj", "(", "mx", ")", ":", "\n", "\t", "rowsum", "=", "mx", ".", "sum", "(", "1", ")", "\n", "r_inv", "=", "(", "1.", "/", "rowsum", ")", ".", "view", "(", "-", "1", ")", "\n", "r_inv", "[", "r_inv", "!=", "r_inv", "]", "=", "0.", "\n", "mx", "=", "torch", ".", "mm", "(", "torch", ".", "eye", "(", "r_inv", ".", "shape", "[", "0", "]", ")", ".", "to", "(", "mx", ".", "device", ")", "*", "r_inv", ",", "mx", ")", "\n", "return", "mx", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.adj_init": [[64, 79], ["utils.calc_adj", "utils.normalize_adj", "utils.adj_fuse_touch"], "function", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.calc_adj", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.normalize_adj", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.adj_fuse_touch"], ["", "def", "adj_init", "(", "verts", ",", "faces", ",", "args", ")", ":", "\n", "# get generic adjacency matrix for vision charts", "\n", "\t", "adj", "=", "calc_adj", "(", "faces", ")", "\n", "adj_info", "=", "{", "}", "\n", "if", "args", ".", "use_touch", ":", "\n", "# this combines the adjacency information of touch and vision charts", "\n", "# the output adj matrix has the first k rows corresponding to vision charts, and the last |V| - k", "\n", "# corresponding to touch charts. Similarly the first l faces are correspond to vision charts, and the", "\n", "# remaining correspond to touch charts", "\n", "\t\t", "adj", ",", "faces", "=", "adj_fuse_touch", "(", "verts", ",", "faces", ",", "adj", ",", "args", ")", "\n", "\n", "", "adj", "=", "normalize_adj", "(", "adj", ")", "\n", "adj_info", "[", "'adj'", "]", "=", "adj", "\n", "adj_info", "[", "'faces'", "]", "=", "faces", "\n", "return", "adj_info", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.adj_fuse_touch": [[91, 143], ["verts.data.cpu().numpy.data.cpu().numpy", "enumerate", "utils.import_obj", "torch.FloatTensor().cuda", "torch.LongTensor().cuda", "utils.calc_adj", "torch.zeros().cuda", "adj.clone", "range", "range", "torch.cat", "hash.keys", "calc_adj.clone", "all_faces.append", "verts.data.cpu().numpy.data.cpu", "v.tobytes", "hash[].append", "torch.FloatTensor", "torch.LongTensor", "range", "torch.zeros", "torch.LongTensor().cuda.clone", "len", "numpy.array", "v.tobytes", "numpy.array", "v.tobytes"], "function", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.calc_adj"], ["", "def", "adj_fuse_touch", "(", "verts", ",", "faces", ",", "adj", ",", "args", ")", ":", "\n", "\t", "verts", "=", "verts", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "hash", "=", "{", "}", "\n", "\n", "# find vertices which have the same 3D position", "\n", "for", "e", ",", "v", "in", "enumerate", "(", "verts", ")", ":", "\n", "\t\t", "if", "v", ".", "tobytes", "(", ")", "in", "hash", ":", "\n", "\t\t\t", "hash", "[", "v", ".", "tobytes", "(", ")", "]", ".", "append", "(", "e", ")", "\n", "", "else", ":", "\n", "\t\t\t", "hash", "[", "v", ".", "tobytes", "(", ")", "]", "=", "[", "e", "]", "\n", "\n", "# load object information for generic touch chart", "\n", "", "", "sheet", "=", "import_obj", "(", "'../data/initial_sheet.obj'", ")", "\n", "sheet_verts", "=", "torch", ".", "FloatTensor", "(", "np", ".", "array", "(", "sheet", ".", "vertices", ")", ")", ".", "cuda", "(", ")", "\n", "sheet_faces", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "sheet", ".", "faces", ")", "-", "1", ")", ".", "cuda", "(", ")", "\n", "sheet_adj", "=", "calc_adj", "(", "sheet_faces", ")", "\n", "\n", "# central vertex for each touch chart that will communicate with all vision charts", "\n", "central_point", "=", "4", "\n", "central_points", "=", "[", "central_point", "+", "(", "i", "*", "sheet_adj", ".", "shape", "[", "0", "]", ")", "+", "adj", ".", "shape", "[", "0", "]", "for", "i", "in", "range", "(", "4", "*", "args", ".", "num_grasps", ")", "]", "\n", "\n", "# define and fill new adjacency matrix with vision and touch charts", "\n", "new_dim", "=", "adj", ".", "shape", "[", "0", "]", "+", "(", "4", "*", "args", ".", "num_grasps", "*", "sheet_adj", ".", "shape", "[", "0", "]", ")", "\n", "new_adj", "=", "torch", ".", "zeros", "(", "(", "new_dim", ",", "new_dim", ")", ")", ".", "cuda", "(", ")", "\n", "new_adj", "[", ":", "adj", ".", "shape", "[", "0", "]", ",", ":", "adj", ".", "shape", "[", "0", "]", "]", "=", "adj", ".", "clone", "(", ")", "\n", "for", "i", "in", "range", "(", "4", "*", "args", ".", "num_grasps", ")", ":", "\n", "\t\t", "start", "=", "adj", ".", "shape", "[", "0", "]", "+", "(", "sheet_adj", ".", "shape", "[", "0", "]", "*", "i", ")", "\n", "end", "=", "adj", ".", "shape", "[", "0", "]", "+", "(", "sheet_adj", ".", "shape", "[", "0", "]", "*", "(", "i", "+", "1", ")", ")", "\n", "new_adj", "[", "start", ":", "end", ",", "start", ":", "end", "]", "=", "sheet_adj", ".", "clone", "(", ")", "\n", "", "adj", "=", "new_adj", "\n", "\n", "# define new faces with vision and touch charts", "\n", "all_faces", "=", "[", "faces", "]", "\n", "for", "i", "in", "range", "(", "4", "*", "args", ".", "num_grasps", ")", ":", "\n", "\t\t", "temp_sheet_faces", "=", "sheet_faces", ".", "clone", "(", ")", "+", "verts", ".", "shape", "[", "0", "]", "\n", "temp_sheet_faces", "+=", "i", "*", "sheet_verts", ".", "shape", "[", "0", "]", "\n", "all_faces", ".", "append", "(", "temp_sheet_faces", ")", "\n", "", "faces", "=", "torch", ".", "cat", "(", "all_faces", ")", "\n", "\n", "# update adjacency matrix to allow communication between vision and touch charts", "\n", "for", "key", "in", "hash", ".", "keys", "(", ")", ":", "\n", "\t\t", "cur_verts", "=", "hash", "[", "key", "]", "\n", "if", "len", "(", "cur_verts", ")", ">", "1", ":", "\n", "\t\t\t", "for", "v1", "in", "cur_verts", ":", "\n", "\t\t\t\t", "for", "v2", "in", "cur_verts", ":", "# vertices on the boundary of vision charts can communicate", "\n", "\t\t\t\t\t", "adj", "[", "v1", ",", "v2", "]", "=", "1", "\n", "", "if", "args", ".", "use_touch", ":", "\n", "\t\t\t\t\t", "for", "c", "in", "central_points", ":", "# touch and vision charts can communicate", "\n", "\t\t\t\t\t\t", "adj", "[", "v1", ",", "c", "]", "=", "1", "\n", "adj", "[", "c", ",", "v1", "]", "=", "1", "\n", "\n", "", "", "", "", "", "return", "adj", ",", "faces", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.calc_adj": [[145, 160], ["int", "torch.eye().to", "faces.max", "torch.eye"], "function", ["None"], ["", "def", "calc_adj", "(", "faces", ")", ":", "\n", "\t", "v1", "=", "faces", "[", ":", ",", "0", "]", "\n", "v2", "=", "faces", "[", ":", ",", "1", "]", "\n", "v3", "=", "faces", "[", ":", ",", "2", "]", "\n", "num_verts", "=", "int", "(", "faces", ".", "max", "(", ")", ")", "\n", "adj", "=", "torch", ".", "eye", "(", "num_verts", "+", "1", ")", ".", "to", "(", "faces", ".", "device", ")", "\n", "\n", "adj", "[", "(", "v1", ",", "v2", ")", "]", "=", "1", "\n", "adj", "[", "(", "v1", ",", "v3", ")", "]", "=", "1", "\n", "adj", "[", "(", "v2", ",", "v1", ")", "]", "=", "1", "\n", "adj", "[", "(", "v2", ",", "v3", ")", "]", "=", "1", "\n", "adj", "[", "(", "v3", ",", "v1", ")", "]", "=", "1", "\n", "adj", "[", "(", "v3", ",", "v2", ")", "]", "=", "1", "\n", "\n", "return", "adj", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.batch_sample": [[174, 214], ["torch.distributions.Uniform", "torch.split", "torch.split", "faces[].view", "select_faces.view.view", "verts.view", "torch.index_select", "torch.index_select", "torch.index_select", "torch.sqrt", "torch.distributions.Uniform.sample_n", "points.view.view", "torch.tensor().cuda", "torch.tensor().cuda", "torch.sqrt", "Areas.squeeze", "torch.sum", "torch.arange().cuda().unsqueeze().expand", "face_arange.unsqueeze", "torch.distributions.Uniform.sample_n", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.multinomial", "torch.cat", "torch.tensor", "torch.tensor", "torch.arange().cuda().unsqueeze", "torch.multinomial", "torch.arange().cuda", "torch.arange"], "function", ["None"], ["", "def", "batch_sample", "(", "verts", ",", "faces", ",", "num", "=", "10000", ")", ":", "\n", "\t", "dist_uni", "=", "torch", ".", "distributions", ".", "Uniform", "(", "torch", ".", "tensor", "(", "[", "0.0", "]", ")", ".", "cuda", "(", ")", ",", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", ".", "cuda", "(", ")", ")", "\n", "batch_size", "=", "verts", ".", "shape", "[", "0", "]", "\n", "\n", "# calculate area of each face", "\n", "x1", ",", "x2", ",", "x3", "=", "torch", ".", "split", "(", "torch", ".", "index_select", "(", "verts", ",", "1", ",", "faces", "[", ":", ",", "0", "]", ")", "-", "torch", ".", "index_select", "(", "verts", ",", "1", ",", "faces", "[", ":", ",", "1", "]", ")", ",", "1", ",", "\n", "dim", "=", "-", "1", ")", "\n", "y1", ",", "y2", ",", "y3", "=", "torch", ".", "split", "(", "torch", ".", "index_select", "(", "verts", ",", "1", ",", "faces", "[", ":", ",", "1", "]", ")", "-", "torch", ".", "index_select", "(", "verts", ",", "1", ",", "faces", "[", ":", ",", "2", "]", ")", ",", "1", ",", "\n", "dim", "=", "-", "1", ")", "\n", "a", "=", "(", "x2", "*", "y3", "-", "x3", "*", "y2", ")", "**", "2", "\n", "b", "=", "(", "x3", "*", "y1", "-", "x1", "*", "y3", ")", "**", "2", "\n", "c", "=", "(", "x1", "*", "y2", "-", "x2", "*", "y1", ")", "**", "2", "\n", "Areas", "=", "torch", ".", "sqrt", "(", "a", "+", "b", "+", "c", ")", "/", "2", "\n", "Areas", "=", "Areas", ".", "squeeze", "(", "-", "1", ")", "/", "torch", ".", "sum", "(", "Areas", ",", "dim", "=", "1", ")", "# percentage of each face w.r.t. full surface area", "\n", "\n", "# define distrubtions of relative face surface areas", "\n", "choices", "=", "None", "\n", "for", "A", "in", "Areas", ":", "\n", "\t\t", "if", "choices", "is", "None", ":", "\n", "\t\t\t", "choices", "=", "torch", ".", "multinomial", "(", "A", ",", "num", ",", "True", ")", "# list of faces to be sampled from", "\n", "", "else", ":", "\n", "\t\t\t", "choices", "=", "torch", ".", "cat", "(", "(", "choices", ",", "torch", ".", "multinomial", "(", "A", ",", "num", ",", "True", ")", ")", ")", "\n", "\n", "# select the faces to be used", "\n", "", "", "select_faces", "=", "faces", "[", "choices", "]", ".", "view", "(", "verts", ".", "shape", "[", "0", "]", ",", "3", ",", "num", ")", "\n", "face_arange", "=", "verts", ".", "shape", "[", "1", "]", "*", "torch", ".", "arange", "(", "0", ",", "batch_size", ")", ".", "cuda", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "batch_size", ",", "num", ")", "\n", "select_faces", "=", "select_faces", "+", "face_arange", ".", "unsqueeze", "(", "1", ")", "\n", "select_faces", "=", "select_faces", ".", "view", "(", "-", "1", ",", "3", ")", "\n", "flat_verts", "=", "verts", ".", "view", "(", "-", "1", ",", "3", ")", "\n", "\n", "# sample one point from each", "\n", "xs", "=", "torch", ".", "index_select", "(", "flat_verts", ",", "0", ",", "select_faces", "[", ":", ",", "0", "]", ")", "\n", "ys", "=", "torch", ".", "index_select", "(", "flat_verts", ",", "0", ",", "select_faces", "[", ":", ",", "1", "]", ")", "\n", "zs", "=", "torch", ".", "index_select", "(", "flat_verts", ",", "0", ",", "select_faces", "[", ":", ",", "2", "]", ")", "\n", "u", "=", "torch", ".", "sqrt", "(", "dist_uni", ".", "sample_n", "(", "batch_size", "*", "num", ")", ")", "\n", "v", "=", "dist_uni", ".", "sample_n", "(", "batch_size", "*", "num", ")", "\n", "points", "=", "(", "1", "-", "u", ")", "*", "xs", "+", "(", "u", "*", "(", "1", "-", "v", ")", ")", "*", "ys", "+", "u", "*", "v", "*", "zs", "\n", "points", "=", "points", ".", "view", "(", "batch_size", ",", "num", ",", "3", ")", "\n", "\n", "return", "points", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.calc_local_chamfer": [[224, 262], ["batch[].cuda().view", "batch[].cuda().view", "zip", "range", "batch[].cuda", "batch[].cuda", "range", "torch.zeros().clone", "pytorch3d.loss.chamfer_distance", "loss.mean", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.chamfer_distance"], ["", "def", "calc_local_chamfer", "(", "samples", ",", "batch", ",", "losses", ")", ":", "\n", "\t", "batch_size", "=", "samples", ".", "shape", "[", "0", "]", "\n", "# a grid of point projected towards the surface of the object, starting from the same position and orientation", "\n", "# as the touch sensor when the touch occurred, but 5 times its size", "\n", "planes", "=", "batch", "[", "'radius'", "]", ".", "cuda", "(", ")", ".", "view", "(", "batch_size", ",", "4", ",", "100", ",", "100", ",", "3", ")", "\n", "# mask indicating which point hit the surface of the object, ie, tho ones we care about", "\n", "masks", "=", "batch", "[", "'radius_masks'", "]", ".", "cuda", "(", ")", ".", "view", "(", "batch_size", ",", "4", ",", "100", ",", "100", ")", "\n", "successful", "=", "batch", "[", "'successful'", "]", "\n", "\n", "num_examples", "=", "0", "\n", "# for every grasps", "\n", "for", "pred", ",", "gt", ",", "mask", ",", "success", "in", "zip", "(", "samples", ",", "planes", ",", "masks", ",", "successful", ")", ":", "\n", "# for every ring size around each touch site", "\n", "\t\t", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "# for every touch", "\n", "\t\t\t", "for", "j", "in", "range", "(", "4", ")", ":", "\n", "\t\t\t\t", "if", "not", "success", "[", "j", "]", ":", "\n", "\t\t\t\t\t", "continue", "\n", "\n", "# select the right ring of points, ie 1 x size of sensor ... 5 x size of sensor", "\n", "", "dim_mask", "=", "torch", ".", "zeros", "(", "mask", "[", "j", "]", ".", "shape", ")", ".", "clone", "(", ")", "\n", "dim_mask", "[", "40", "-", "i", "*", "10", ":", "60", "+", "i", "*", "10", ",", "40", "-", "i", "*", "10", ":", "60", "+", "i", "*", "10", "]", "=", "1", "\n", "dim_mask", "[", "50", "-", "i", "*", "10", ":", "50", "+", "i", "*", "10", ",", "50", "-", "i", "*", "10", ":", "50", "+", "i", "*", "10", "]", "=", "0", "\n", "\n", "# select point which are on the objects surface", "\n", "dim_mask", "[", "mask", "[", "j", "]", "==", "0", "]", "=", "0", "\n", "gt_masked", "=", "gt", "[", "j", "]", "[", "dim_mask", "==", "1", "]", "\n", "if", "(", "gt_masked", ".", "shape", "[", "0", "]", "==", "0", ")", ":", "\n", "\t\t\t\t\t", "continue", "\n", "\n", "# compute the local loss between the selected points and the predicted surface", "\n", "", "loss", ",", "_", "=", "cuda_cd", "(", "pred_points", ",", "gt_points", ",", "batch_reduction", "=", "None", ")", "\n", "\n", "losses", "[", "i", "]", "+=", "loss", ".", "mean", "(", ")", "\n", "if", "i", "==", "0", ":", "\n", "\t\t\t\t\t", "num_examples", "+=", "1.", "\n", "\n", "", "", "", "", "return", "losses", ",", "num_examples", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.pretrained_args": [[264, 319], ["None"], "function", ["None"], ["", "def", "pretrained_args", "(", "args", ")", ":", "\n", "\n", "\t", "if", "args", ".", "pretrained", "==", "'empty'", ":", "\n", "\t\t", "args", ".", "use_occluded", "=", "False", "\n", "args", ".", "use_unoccluded", "=", "False", "\n", "args", ".", "use_touch", "=", "False", "\n", "\n", "", "elif", "args", ".", "pretrained", "==", "'touch'", ":", "\n", "\t\t", "args", ".", "num_gcn_layers", "=", "25", "\n", "args", ".", "hidden_gcn_layers", "=", "250", "\n", "args", ".", "use_occluded", "=", "False", "\n", "args", ".", "use_unoccluded", "=", "False", "\n", "args", ".", "use_touch", "=", "True", "\n", "\n", "", "elif", "args", ".", "pretrained", "==", "'touch_unoccluded'", ":", "\n", "\t\t", "args", ".", "num_img_blocks", "=", "4", "\n", "args", ".", "num_img_layers", "=", "3", "\n", "args", ".", "size_img_ker", "=", "5", "\n", "args", ".", "num_gcn_layers", "=", "15", "\n", "args", ".", "hidden_gcn_layers", "=", "200", "\n", "args", ".", "use_occluded", "=", "False", "\n", "args", ".", "use_unoccluded", "=", "True", "\n", "args", ".", "use_touch", "=", "True", "\n", "\n", "", "elif", "args", ".", "pretrained", "==", "'touch_occluded'", ":", "\n", "\t\t", "args", ".", "num_img_blocks", "=", "4", "\n", "args", ".", "num_img_layers", "=", "3", "\n", "args", ".", "size_img_ker", "=", "5", "\n", "args", ".", "num_gcn_layers", "=", "20", "\n", "args", ".", "hidden_gcn_layers", "=", "200", "\n", "args", ".", "use_occluded", "=", "True", "\n", "args", ".", "use_unoccluded", "=", "False", "\n", "args", ".", "use_touch", "=", "True", "\n", "\n", "", "elif", "args", ".", "pretrained", "==", "'unoccluded'", ":", "\n", "\t\t", "args", ".", "num_img_blocks", "=", "5", "\n", "args", ".", "num_img_layers", "=", "3", "\n", "args", ".", "size_img_ker", "=", "5", "\n", "args", ".", "num_gcn_layers", "=", "15", "\n", "args", ".", "hidden_gcn_layers", "=", "150", "\n", "args", ".", "use_occluded", "=", "False", "\n", "args", ".", "use_unoccluded", "=", "True", "\n", "args", ".", "use_touch", "=", "False", "\n", "\n", "", "elif", "args", ".", "pretrained", "==", "'occluded'", ":", "\n", "\t\t", "args", ".", "num_img_blocks", "=", "4", "\n", "args", ".", "num_img_layers", "=", "3", "\n", "args", ".", "size_img_ker", "=", "5", "\n", "args", ".", "num_gcn_layers", "=", "25", "\n", "args", ".", "hidden_gcn_layers", "=", "250", "\n", "args", ".", "use_occluded", "=", "True", "\n", "args", ".", "use_unoccluded", "=", "False", "\n", "args", ".", "use_touch", "=", "False", "\n", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.load_mesh_touch": [[328, 334], ["utils.import_obj", "numpy.array", "torch.FloatTensor().cuda", "torch.LongTensor().cuda", "torch.FloatTensor", "torch.LongTensor", "numpy.array"], "function", ["None"], ["", "def", "load_mesh_touch", "(", "obj", "=", "'386.obj'", ")", ":", "\n", "\t", "obj", "=", "import_obj", "(", "obj", ")", "\n", "verts", "=", "np", ".", "array", "(", "obj", ".", "vertices", ")", "\n", "verts", "=", "torch", ".", "FloatTensor", "(", "verts", ")", ".", "cuda", "(", ")", "\n", "faces", "=", "torch", ".", "LongTensor", "(", "np", ".", "array", "(", "obj", ".", "faces", ")", "-", "1", ")", ".", "cuda", "(", ")", "\n", "return", "verts", ",", "faces", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.chamfer_distance": [[345, 354], ["utils.batch_sample", "pytorch3d.loss.chamfer_distance", "cd.mean"], "function", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.batch_sample", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.chamfer_distance"], ["", "def", "chamfer_distance", "(", "verts", ",", "faces", ",", "gt_points", ",", "num", "=", "1000", ")", ":", "\n", "\t", "batch_size", "=", "verts", ".", "shape", "[", "0", "]", "\n", "\n", "# sample from faces and calculate pairs", "\n", "pred_points", "=", "batch_sample", "(", "verts", ",", "faces", ",", "num", "=", "num", ")", "\n", "\n", "\n", "cd", ",", "_", "=", "cuda_cd", "(", "pred_points", ",", "gt_points", ",", "batch_reduction", "=", "None", ")", "\n", "return", "cd", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.batch_calc_edge": [[361, 375], ["torch.index_select", "torch.index_select", "torch.index_select", "torch.sum().mean", "torch.sum().mean", "torch.sum().mean", "torch.sum", "torch.sum", "torch.sum"], "function", ["None"], ["", "def", "batch_calc_edge", "(", "verts", ",", "faces", ")", ":", "\n", "# get vertex locations of faces", "\n", "\t", "p1", "=", "torch", ".", "index_select", "(", "verts", ",", "1", ",", "faces", "[", ":", ",", "0", "]", ")", "\n", "p2", "=", "torch", ".", "index_select", "(", "verts", ",", "1", ",", "faces", "[", ":", ",", "1", "]", ")", "\n", "p3", "=", "torch", ".", "index_select", "(", "verts", ",", "1", ",", "faces", "[", ":", ",", "2", "]", ")", "\n", "\n", "# get edge lengths", "\n", "e1", "=", "p2", "-", "p1", "\n", "e2", "=", "p3", "-", "p1", "\n", "e3", "=", "p2", "-", "p3", "\n", "\n", "edge_length", "=", "(", "torch", ".", "sum", "(", "e1", "**", "2", ",", "-", "1", ")", ".", "mean", "(", ")", "+", "torch", ".", "sum", "(", "e2", "**", "2", ",", "-", "1", ")", ".", "mean", "(", ")", "+", "torch", ".", "sum", "(", "e3", "**", "2", ",", "-", "1", ")", ".", "mean", "(", ")", ")", "/", "3.", "\n", "\n", "return", "edge_length", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.point_loss": [[383, 386], ["pytorch3d.loss.chamfer_distance", "cd.mean"], "function", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.chamfer_distance"], ["", "def", "point_loss", "(", "gt_points", ",", "pred_points", ")", ":", "\n", "\t", "cd", ",", "_", "=", "cuda_cd", "(", "pred_points", ",", "gt_points", ",", "batch_reduction", "=", "None", ")", "\n", "return", "cd", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.third_party_code.chamfer_distance.ChamferDistanceFunction.forward": [[13, 34], ["xyz1.contiguous.contiguous.size", "xyz2.contiguous.contiguous.size", "xyz1.contiguous.contiguous.contiguous", "xyz2.contiguous.contiguous.contiguous", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "dist1.cuda.cuda.cuda", "dist2.cuda.cuda.cuda", "idx1.cuda.cuda.cuda", "idx2.cuda.cuda.cuda", "cd.forward_cuda"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "xyz1", ",", "xyz2", ")", ":", "\n", "        ", "batchsize", ",", "n", ",", "_", "=", "xyz1", ".", "size", "(", ")", "\n", "_", ",", "m", ",", "_", "=", "xyz2", ".", "size", "(", ")", "\n", "xyz1", "=", "xyz1", ".", "contiguous", "(", ")", "\n", "xyz2", "=", "xyz2", ".", "contiguous", "(", ")", "\n", "dist1", "=", "torch", ".", "zeros", "(", "batchsize", ",", "n", ")", "\n", "dist2", "=", "torch", ".", "zeros", "(", "batchsize", ",", "m", ")", "\n", "\n", "idx1", "=", "torch", ".", "zeros", "(", "batchsize", ",", "n", ",", "dtype", "=", "torch", ".", "int", ")", "\n", "idx2", "=", "torch", ".", "zeros", "(", "batchsize", ",", "m", ",", "dtype", "=", "torch", ".", "int", ")", "\n", "\n", "\n", "dist1", "=", "dist1", ".", "cuda", "(", ")", "\n", "dist2", "=", "dist2", ".", "cuda", "(", ")", "\n", "idx1", "=", "idx1", ".", "cuda", "(", ")", "\n", "idx2", "=", "idx2", ".", "cuda", "(", ")", "\n", "cd", ".", "forward_cuda", "(", "xyz1", ",", "xyz2", ",", "dist1", ",", "dist2", ",", "idx1", ",", "idx2", ")", "\n", "\n", "\n", "return", "idx1", ",", "idx2", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.third_party_code.chamfer_distance.ChamferDistance.forward": [[39, 41], ["ChamferDistanceFunction.apply"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "xyz1", ",", "xyz2", ")", ":", "\n", "        ", "return", "ChamferDistanceFunction", ".", "apply", "(", "xyz1", ",", "xyz2", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.models.DoubleConv.__init__": [[15, 26], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.__init__"], ["\t", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "mid_channels", "=", "None", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "not", "mid_channels", ":", "\n", "\t\t\t", "mid_channels", "=", "out_channels", "\n", "", "self", ".", "double_conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "mid_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "mid_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "mid_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.models.DoubleConv.forward": [[27, 29], ["models.DoubleConv.double_conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\t\t", "return", "self", ".", "double_conv", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.models.Down.__init__": [[34, 39], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "models.DoubleConv"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.__init__"], ["\t", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "maxpool_conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "MaxPool2d", "(", "2", ")", ",", "\n", "DoubleConv", "(", "in_channels", ",", "out_channels", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.models.Down.forward": [[40, 42], ["models.Down.maxpool_conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\t\t", "return", "self", ".", "maxpool_conv", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.models.Up.__init__": [[47, 51], ["torch.Module.__init__", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "models.DoubleConv"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.__init__"], ["\t", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "up", "=", "nn", ".", "ConvTranspose2d", "(", "in_channels", ",", "in_channels", "//", "2", ",", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", "\n", "self", ".", "conv", "=", "DoubleConv", "(", "in_channels", ",", "out_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.models.Up.forward": [[52, 61], ["models.Up.up", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.pad", "torch.pad", "torch.pad", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.Up.conv", "x2.size", "torch.pad.size", "x2.size", "torch.pad.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ")", ":", "\n", "\t\t", "x1", "=", "self", ".", "up", "(", "x1", ")", "\n", "diffY", "=", "torch", ".", "tensor", "(", "[", "x2", ".", "size", "(", ")", "[", "2", "]", "-", "x1", ".", "size", "(", ")", "[", "2", "]", "]", ")", "\n", "diffX", "=", "torch", ".", "tensor", "(", "[", "x2", ".", "size", "(", ")", "[", "3", "]", "-", "x1", ".", "size", "(", ")", "[", "3", "]", "]", ")", "\n", "x1", "=", "F", ".", "pad", "(", "x1", ",", "[", "diffX", "//", "2", ",", "diffX", "-", "diffX", "//", "2", ",", "\n", "diffY", "//", "2", ",", "diffY", "-", "diffY", "//", "2", "]", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x2", ",", "x1", "]", ",", "dim", "=", "1", ")", "\n", "output", "=", "self", ".", "conv", "(", "x", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.models.OutConv.__init__": [[66, 69], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.__init__"], ["\t", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ")", ":", "\n", "\t\t", "super", "(", "OutConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.models.OutConv.forward": [[70, 72], ["models.OutConv.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\t\t", "return", "self", ".", "conv", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.models.Encoder.__init__": [[76, 104], ["torch.Module.__init__", "models.DoubleConv", "models.Down", "models.Down", "models.Down", "models.Down", "models.Up", "models.Up", "models.Up", "models.Up", "models.OutConv", "torch.arange().cuda().view().expand().float", "torch.arange().cuda().view().expand().float", "torch.arange().cuda().view().expand().float", "torch.arange().cuda().view().expand().float", "torch.arange().cuda().view().expand().float", "torch.arange().cuda().view().expand().float", "torch.arange().cuda().view().expand().float", "torch.arange().cuda().view().expand().float", "torch.arange().cuda().view().expand().float", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange().cuda().view().expand", "torch.arange().cuda().view().expand", "torch.arange().cuda().view().expand", "torch.arange().cuda().view().expand", "torch.arange().cuda().view().expand", "torch.arange().cuda().view().expand", "torch.arange().cuda().view().expand", "torch.arange().cuda().view().expand", "torch.arange().cuda().view().expand", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "float", "torch.arange().cuda().view", "torch.arange().cuda().view", "torch.arange().cuda().view", "torch.arange().cuda().view", "torch.arange().cuda().view", "torch.arange().cuda().view", "torch.arange().cuda().view", "torch.arange().cuda().view", "torch.arange().cuda().view", "torch.stack().permute.permute", "torch.stack().permute.permute", "torch.stack().permute.permute", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.__init__"], ["\t", "def", "__init__", "(", "self", ",", "args", ",", "dim", "=", "100", ")", ":", "\n", "\t\t", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "# settings", "\n", "n_channels", "=", "3", "\n", "n_classes", "=", "1", "\n", "\n", "# downscale the image", "\n", "self", ".", "inc", "=", "DoubleConv", "(", "n_channels", ",", "64", ")", "\n", "self", ".", "down1", "=", "Down", "(", "64", ",", "128", ")", "\n", "self", ".", "down2", "=", "Down", "(", "128", ",", "256", ")", "\n", "self", ".", "down3", "=", "Down", "(", "256", ",", "512", ")", "\n", "\n", "# upscale the image", "\n", "self", ".", "down4", "=", "Down", "(", "512", ",", "1024", ")", "\n", "self", ".", "up1", "=", "Up", "(", "1024", ",", "512", ")", "\n", "self", ".", "up2", "=", "Up", "(", "512", ",", "256", ")", "\n", "self", ".", "up3", "=", "Up", "(", "256", ",", "128", ")", "\n", "self", ".", "up4", "=", "Up", "(", "128", ",", "64", ")", "\n", "self", ".", "outc", "=", "OutConv", "(", "64", ",", "n_classes", ")", "\n", "\n", "# define a plane of the same size, and shape at the touch sensor", "\n", "width", "=", ".0218", "-", "0.00539", "\n", "y_z", "=", "torch", ".", "arange", "(", "dim", ")", ".", "cuda", "(", ")", ".", "view", "(", "dim", ",", "1", ")", ".", "expand", "(", "dim", ",", "dim", ")", ".", "float", "(", ")", "\n", "y_z", "=", "torch", ".", "stack", "(", "(", "y_z", ",", "y_z", ".", "permute", "(", "1", ",", "0", ")", ")", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ")", "\n", "plane", "=", "torch", ".", "cat", "(", "(", "torch", ".", "zeros", "(", "dim", ",", "dim", ",", "1", ")", ".", "cuda", "(", ")", ",", "y_z", ")", ",", "dim", "=", "-", "1", ")", "\n", "self", ".", "orig_plane", "=", "(", "plane", "/", "float", "(", "dim", ")", "-", ".5", ")", "*", "width", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.models.Encoder.project_depth": [[106, 121], ["models.Encoder.orig_plane.view().expand", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "pos.view", "torch.FloatTensor().cuda().view().expand", "torch.FloatTensor().cuda().view().expand", "torch.FloatTensor().cuda().view().expand", "torch.FloatTensor().cuda().view().expand", "torch.FloatTensor().cuda().view().expand", "torch.FloatTensor().cuda().view().expand", "torch.FloatTensor().cuda().view().expand", "torch.FloatTensor().cuda().view().expand", "torch.FloatTensor().cuda().view().expand", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "torch.normalize().view().expand", "torch.normalize().view().expand", "torch.normalize().view().expand", "depths.unsqueeze", "models.Encoder.orig_plane.view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.FloatTensor().cuda().view", "torch.FloatTensor().cuda().view", "torch.FloatTensor().cuda().view", "torch.FloatTensor().cuda().view", "torch.FloatTensor().cuda().view", "torch.FloatTensor().cuda().view", "torch.FloatTensor().cuda().view", "torch.FloatTensor().cuda().view", "torch.FloatTensor().cuda().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.normalize().view", "torch.normalize().view", "torch.normalize().view", "torch.bmm().permute.permute", "torch.bmm().permute.permute", "torch.bmm().permute.permute", "depth_update.view", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.normalize", "torch.normalize", "torch.normalize", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["None"], ["", "def", "project_depth", "(", "self", ",", "depths", ",", "pos", ",", "rot", ",", "dim", "=", "100", ")", ":", "\n", "# reshape the plane to have the same position and orientation as the touch sensor when the touch occurred", "\n", "\t\t", "batch_size", "=", "depths", ".", "shape", "[", "0", "]", "\n", "planes", "=", "self", ".", "orig_plane", ".", "view", "(", "1", ",", "-", "1", ",", "3", ")", ".", "expand", "(", "batch_size", ",", "-", "1", ",", "3", ")", "\n", "planes", "=", "torch", ".", "bmm", "(", "rot", ",", "planes", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "planes", "+=", "pos", ".", "view", "(", "batch_size", ",", "1", ",", "3", ")", "\n", "\n", "# add the depth in the same direction as the normal of the sensor plane", "\n", "init_camera_vector", "=", "torch", ".", "FloatTensor", "(", "(", "1", ",", "0", ",", "0", ")", ")", ".", "cuda", "(", ")", ".", "view", "(", "1", ",", "3", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "3", ",", "1", ")", "\n", "camera_vector", "=", "torch", ".", "bmm", "(", "rot", ",", "init_camera_vector", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "camera_vector", "=", "F", ".", "normalize", "(", "camera_vector", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", ".", "view", "(", "batch_size", ",", "1", ",", "1", ",", "3", ")", ".", "expand", "(", "batch_size", ",", "dim", ",", "dim", ",", "3", ")", "\n", "depth_update", "=", "depths", ".", "unsqueeze", "(", "-", "1", ")", "*", "camera_vector", "\n", "local_depth", "=", "(", "planes", "+", "depth_update", ".", "view", "(", "batch_size", ",", "-", "1", ",", "3", ")", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "3", ")", "\n", "\n", "return", "local_depth", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.models.Encoder.forward": [[122, 175], ["ref_frame[].cuda().view", "ref_frame[].cuda().view", "models.Encoder.inc", "models.Encoder.down1", "models.Encoder.down2", "models.Encoder.down3", "models.Encoder.down4", "models.Encoder.up1", "models.Encoder.up2", "models.Encoder.up3", "models.Encoder.up4", "models.Encoder.outc", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "models.Encoder.project_depth().view", "zip", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.cat.clone", "torch.cat.clone", "torch.cat.clone", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.stack.append", "torch.stack.append", "torch.stack.append", "ref_frame[].cuda", "ref_frame[].cuda", "models.Encoder.project_depth", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.Encoder.squeeze", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "gel.permute", "empty.permute"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.models.Encoder.project_depth"], ["", "def", "forward", "(", "self", ",", "gel", ",", "depth", ",", "ref_frame", ",", "empty", ",", "producing_sheet", "=", "False", ")", ":", "\n", "# get initial data", "\n", "\t\t", "batch_size", "=", "ref_frame", "[", "'pos'", "]", ".", "shape", "[", "0", "]", "\n", "pos", "=", "ref_frame", "[", "'pos'", "]", ".", "cuda", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "rot_m", "=", "ref_frame", "[", "'rot_M'", "]", ".", "cuda", "(", ")", ".", "view", "(", "-", "1", ",", "3", ",", "3", ")", "\n", "\n", "# U-Net prediction", "\n", "# downscale the image", "\n", "x1", "=", "self", ".", "inc", "(", "gel", ")", "\n", "x2", "=", "self", ".", "down1", "(", "x1", ")", "\n", "x3", "=", "self", ".", "down2", "(", "x2", ")", "\n", "x4", "=", "self", ".", "down3", "(", "x3", ")", "\n", "x5", "=", "self", ".", "down4", "(", "x4", ")", "\n", "# upscale the image", "\n", "x", "=", "self", ".", "up1", "(", "x5", ",", "x4", ")", "\n", "x", "=", "self", ".", "up2", "(", "x", ",", "x3", ")", "\n", "x", "=", "self", ".", "up3", "(", "x", ",", "x2", ")", "\n", "x", "=", "self", ".", "up4", "(", "x", ",", "x1", ")", "\n", "pred_depth", "=", "(", "self", ".", "outc", "(", "x", ")", ")", "\n", "# scale the prediction", "\n", "pred_depth", "=", "F", ".", "sigmoid", "(", "pred_depth", ")", "*", "0.1", "\n", "\n", "# we only want to use the points in the predicted point cloud if they correspond to pixels in the touch signal", "\n", "# which are \"different\" enough from the an untouched touch signal, otherwise the do not correspond to any", "\n", "# geometry of the object which is deforming the touch sensor's surface.", "\n", "diff", "=", "torch", ".", "sqrt", "(", "(", "(", "(", "gel", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "-", "empty", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "3", ")", ")", "**", "2", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ")", "\n", "useful_points", "=", "diff", ">", "0.001", "\n", "# project the depth values into 3D points", "\n", "projected_depths", "=", "self", ".", "project_depth", "(", "pred_depth", ".", "squeeze", "(", "1", ")", ",", "pos", ",", "rot_m", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "3", ")", "\n", "\n", "pred_points", "=", "[", "]", "\n", "for", "points", ",", "useful", "in", "zip", "(", "projected_depths", ",", "useful_points", ")", ":", "\n", "# select only useful points", "\n", "\t\t\t", "orig_points", "=", "points", ".", "clone", "(", ")", "\n", "points", "=", "points", "[", "useful", "]", "\n", "if", "points", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "\t\t\t\t", "if", "producing_sheet", ":", "\n", "\t\t\t\t\t", "pred_points", ".", "append", "(", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "num_samples", ",", "3", ")", ")", ".", "cuda", "(", ")", ")", "\n", "continue", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "points", "=", "orig_points", "\n", "\n", "# make the number of points in each element of a batch consistent", "\n", "", "", "while", "points", ".", "shape", "[", "0", "]", "<", "self", ".", "args", ".", "num_samples", ":", "\n", "\t\t\t\t", "points", "=", "torch", ".", "cat", "(", "(", "points", ",", "points", ",", "points", ",", "points", ")", ")", "\n", "", "perm", "=", "torch", ".", "randperm", "(", "points", ".", "shape", "[", "0", "]", ")", "\n", "idx", "=", "perm", "[", ":", "self", ".", "args", ".", "num_samples", "]", "\n", "points", "=", "points", "[", "idx", "]", "\n", "pred_points", ".", "append", "(", "points", ")", "\n", "", "pred_points", "=", "torch", ".", "stack", "(", "pred_points", ")", "\n", "\n", "\n", "return", "pred_depth", ",", "pred_points", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.produce_sheets.Engine.__init__": [[22, 32], ["numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "utils.load_mesh_touch"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.load_mesh_touch"], ["\t", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "\n", "# set seeds", "\n", "\t\t", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n", "self", ".", "classes", "=", "[", "'0001'", ",", "'0002'", "]", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "verts", ",", "self", ".", "faces", "=", "utils", ".", "load_mesh_touch", "(", "f'../data/initial_sheet.obj'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.produce_sheets.Engine.__call__": [[33, 108], ["models.Encoder", "produce_sheets.Engine.encoder.load_state_dict", "produce_sheets.Engine.encoder.cuda", "produce_sheets.Engine.encoder.eval", "data_loaders.mesh_loader_touch", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "enumerate", "torch.load", "torch.load", "torch.load", "torch.load", "tqdm.tqdm.tqdm", "batch[].cuda", "batch[].cuda", "zip", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "produce_sheets.Engine.encoder", "os.path.exists", "produce_sheets.Engine.verts.clone().unsqueeze", "ref_frame[].cuda().view", "ref_frame[].cuda().view", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "torch.bmm().permute", "ref_frame[].cuda().view.view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Adam", "torch.Adam", "numpy.save", "os.path.exists", "os.makedirs", "torch.abs().sum", "torch.abs().sum", "torch.abs().sum", "torch.abs().sum", "numpy.save", "torch.Adam.zero_grad", "utils.chamfer_distance", "utils.batch_calc_edge", "loss.backward", "torch.Adam.step", "verts.clone.data.cpu().numpy", "batch[].cuda", "numpy.zeros", "produce_sheets.Engine.verts.clone", "ref_frame[].cuda", "ref_frame[].cuda", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "verts.unsqueeze", "points.unsqueeze", "verts.unsqueeze", "verts.clone", "len", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.bmm().permute.permute", "torch.bmm().permute.permute", "verts.clone.data.cpu", "dir.split"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.chamfer_distance", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.batch_calc_edge"], ["", "def", "__call__", "(", "self", ")", "->", "float", ":", "\n", "\t\t", "self", ".", "encoder", "=", "models", ".", "Encoder", "(", "self", ".", "args", ")", "\n", "self", ".", "encoder", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "args", ".", "save_directory", ")", ")", "\n", "self", ".", "encoder", ".", "cuda", "(", ")", "\n", "self", ".", "encoder", ".", "eval", "(", ")", "\n", "\n", "train_data", "=", "data_loaders", ".", "mesh_loader_touch", "(", "self", ".", "classes", ",", "self", ".", "args", ",", "produce_sheets", "=", "True", ")", "\n", "train_data", ".", "names", "=", "train_data", ".", "names", "[", "self", ".", "args", ".", "start", ":", "self", ".", "args", ".", "end", "]", "\n", "train_loader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "16", ",", "collate_fn", "=", "train_data", ".", "collate", ")", "\n", "\n", "for", "k", ",", "batch", "in", "enumerate", "(", "tqdm", "(", "train_loader", ",", "smoothing", "=", "0", ")", ")", ":", "\n", "# initialize data", "\n", "\t\t\t", "sim_touch", "=", "batch", "[", "'sim_touch'", "]", ".", "cuda", "(", ")", "\n", "depth", "=", "batch", "[", "'depth'", "]", ".", "cuda", "(", ")", "\n", "ref_frame", "=", "batch", "[", "'ref'", "]", "\n", "\n", "# predict point cloud", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t\t", "pred_depth", ",", "sampled_points", "=", "self", ".", "encoder", "(", "sim_touch", ",", "depth", ",", "ref_frame", ",", "empty", "=", "batch", "[", "'empty'", "]", ".", "cuda", "(", ")", ")", "\n", "\n", "# optimize touch chart", "\n", "", "for", "points", ",", "dir", "in", "zip", "(", "sampled_points", ",", "batch", "[", "'save_dir'", "]", ")", ":", "\n", "\t\t\t\t", "if", "os", ".", "path", ".", "exists", "(", "dir", ")", ":", "\n", "\t\t\t\t\t", "continue", "\n", "", "directory", "=", "dir", "[", ":", "-", "len", "(", "dir", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "]", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "\t\t\t\t\t", "os", ".", "makedirs", "(", "directory", ")", "\n", "\n", "# if not a successful touch", "\n", "", "if", "torch", ".", "abs", "(", "points", ")", ".", "sum", "(", ")", "==", "0", ":", "\n", "\t\t\t\t\t", "np", ".", "save", "(", "dir", ",", "np", ".", "zeros", "(", "1", ")", ")", "\n", "continue", "\n", "\n", "# make initial mesh match touch sensor when touch occurred", "\n", "", "initial", "=", "self", ".", "verts", ".", "clone", "(", ")", ".", "unsqueeze", "(", "0", ")", "\n", "pos", "=", "ref_frame", "[", "'pos'", "]", ".", "cuda", "(", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "rot", "=", "ref_frame", "[", "'rot_M'", "]", ".", "cuda", "(", ")", ".", "view", "(", "1", ",", "3", ",", "3", ")", "\n", "initial", "=", "torch", ".", "bmm", "(", "rot", ",", "initial", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "initial", "+=", "pos", ".", "view", "(", "1", ",", "1", ",", "3", ")", "\n", "initial", "=", "initial", "[", "0", "]", "\n", "\n", "# set up optimization", "\n", "updates", "=", "torch", ".", "zeros", "(", "self", ".", "verts", ".", "shape", ",", "requires_grad", "=", "True", ",", "device", "=", "\"cuda\"", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "[", "updates", "]", ",", "lr", "=", "0.003", ",", "weight_decay", "=", "0", ")", "\n", "last_improvement", "=", "0", "\n", "best_loss", "=", "10000", "\n", "\n", "while", "True", ":", "\n", "# update", "\n", "\t\t\t\t\t", "optimizer", ".", "zero_grad", "(", ")", "\n", "verts", "=", "initial", "+", "updates", "\n", "\n", "# losses", "\n", "surf_loss", "=", "utils", ".", "chamfer_distance", "(", "verts", ".", "unsqueeze", "(", "0", ")", ",", "self", ".", "faces", ",", "points", ".", "unsqueeze", "(", "0", ")", ",", "num", "=", "self", ".", "args", ".", "num_samples", ")", "\n", "edge_lengths", "=", "utils", ".", "batch_calc_edge", "(", "verts", ".", "unsqueeze", "(", "0", ")", ",", "self", ".", "faces", ")", "\n", "loss", "=", "self", ".", "args", ".", "surf_co", "*", "surf_loss", "+", "70", "*", "edge_lengths", "\n", "\n", "# optimize", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# check results", "\n", "if", "loss", "<", "0.0006", ":", "\n", "\t\t\t\t\t\t", "break", "\n", "", "if", "best_loss", ">", "loss", ":", "\n", "\t\t\t\t\t\t", "best_loss", "=", "loss", "\n", "best_verts", "=", "verts", ".", "clone", "(", ")", "\n", "last_improvement", "=", "0", "\n", "", "else", ":", "\n", "\t\t\t\t\t\t", "last_improvement", "+=", "1", "\n", "if", "last_improvement", ">", "50", ":", "\n", "\t\t\t\t\t\t\t", "break", "\n", "\n", "", "", "", "np", ".", "save", "(", "dir", ",", "best_verts", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.recon.Engine.__init__": [[24, 40], ["numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "os.path.join", "os.path.exists", "os.makedirs"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "# set seeds", "\n", "\t\t", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# set initial data values", "\n", "self", ".", "epoch", "=", "0", "\n", "self", ".", "best_loss", "=", "10000", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "last_improvement", "=", "0", "\n", "self", ".", "classes", "=", "[", "'0001'", ",", "'0002'", "]", "\n", "self", ".", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "'experiments/checkpoint/'", ",", "args", ".", "exp_type", ",", "args", ".", "exp_id", ")", "\n", "self", ".", "log_dir", "=", "f'experiments/results/{self.args.exp_type}/{self.args.exp_id}/'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "log_dir", ")", ":", "\n", "\t\t\t", "os", ".", "makedirs", "(", "self", ".", "log_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.recon.Engine.__call__": [[42, 62], ["models.Encoder", "recon.Engine.encoder.cuda", "list", "torch.Adam", "torch.Adam", "torch.utils.tensorboard.SummaryWriter", "torch.utils.tensorboard.SummaryWriter", "recon.Engine.get_loaders", "range", "recon.Engine.encoder.parameters", "os.path.join", "recon.Engine.load", "exit", "recon.Engine.train", "recon.Engine.check_values", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "recon.Engine.validate", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "recon.Engine.validate"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.get_loaders", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.train", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.check_values", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.validate", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.validate"], ["", "", "def", "__call__", "(", "self", ")", "->", "float", ":", "\n", "\t\t", "self", ".", "encoder", "=", "models", ".", "Encoder", "(", "self", ".", "args", ")", "\n", "self", ".", "encoder", ".", "cuda", "(", ")", "\n", "params", "=", "list", "(", "self", ".", "encoder", ".", "parameters", "(", ")", ")", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "params", ",", "lr", "=", "self", ".", "args", ".", "lr", ",", "weight_decay", "=", "0", ")", "\n", "writer", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "'experiments/tensorboard/'", ",", "args", ".", "exp_type", ")", ")", "\n", "\n", "train_loader", ",", "valid_loaders", "=", "self", ".", "get_loaders", "(", ")", "\n", "\n", "if", "self", ".", "args", ".", "eval", ":", "\n", "\t\t\t", "self", ".", "load", "(", "''", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t\t", "self", ".", "validate", "(", "valid_loaders", ",", "writer", ")", "\n", "", "exit", "(", ")", "\n", "", "for", "epoch", "in", "range", "(", "self", ".", "args", ".", "epochs", ")", ":", "\n", "\t\t\t", "self", ".", "epoch", "=", "epoch", "\n", "self", ".", "train", "(", "train_loader", ",", "writer", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t\t", "self", ".", "validate", "(", "valid_loaders", ",", "writer", ")", "\n", "", "self", ".", "check_values", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.recon.Engine.get_loaders": [[64, 77], ["data_loaders.mesh_loader_touch", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "data_loaders.mesh_loader_touch", "valid_loaders.append", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "", "def", "get_loaders", "(", "self", ")", ":", "\n", "# training data", "\n", "\t\t", "train_data", "=", "data_loaders", ".", "mesh_loader_touch", "(", "self", ".", "classes", ",", "self", ".", "args", ",", "set_type", "=", "'train'", ")", "\n", "train_loader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "self", ".", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "16", ",", "collate_fn", "=", "train_data", ".", "collate", ")", "\n", "\n", "# validation data", "\n", "valid_loaders", "=", "[", "]", "\n", "set_type", "=", "'test'", "if", "self", ".", "args", ".", "eval", "else", "'valid'", "\n", "for", "c", "in", "self", ".", "classes", ":", "\n", "\t\t\t", "valid_data", "=", "data_loaders", ".", "mesh_loader_touch", "(", "c", ",", "self", ".", "args", ",", "set_type", "=", "set_type", ")", "\n", "valid_loaders", ".", "append", "(", "\n", "DataLoader", "(", "valid_data", ",", "batch_size", "=", "self", ".", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "num_workers", "=", "16", ",", "collate_fn", "=", "valid_data", ".", "collate", ")", ")", "\n", "", "return", "train_loader", ",", "valid_loaders", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.recon.Engine.train": [[79, 110], ["recon.Engine.encoder.train", "enumerate", "writer.add_scalars", "tqdm.tqdm.tqdm", "recon.Engine.optimizer.zero_grad", "batch[].cuda", "batch[].cuda", "batch[].cuda", "recon.Engine.encoder", "point_loss.item", "loss.backward", "recon.Engine.optimizer.step", "tqdm.tqdm.tqdm.write", "utils.point_loss", "batch[].cuda", "loss.item"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.train", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.point_loss"], ["", "def", "train", "(", "self", ",", "data", ",", "writer", ")", ":", "\n", "\t\t", "total_loss", "=", "0", "\n", "iterations", "=", "0", "\n", "self", ".", "encoder", ".", "train", "(", ")", "\n", "for", "k", ",", "batch", "in", "enumerate", "(", "tqdm", "(", "data", ")", ")", ":", "\n", "\t\t\t", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# initialize data", "\n", "sim_touch", "=", "batch", "[", "'sim_touch'", "]", ".", "cuda", "(", ")", "\n", "depth", "=", "batch", "[", "'depth'", "]", ".", "cuda", "(", ")", "\n", "ref_frame", "=", "batch", "[", "'ref'", "]", "\n", "gt_points", "=", "batch", "[", "'samples'", "]", ".", "cuda", "(", ")", "\n", "\n", "# inference", "\n", "pred_depth", ",", "pred_points", "=", "self", ".", "encoder", "(", "sim_touch", ",", "depth", ",", "ref_frame", ",", "empty", "=", "batch", "[", "'empty'", "]", ".", "cuda", "(", ")", ")", "\n", "\n", "# losses", "\n", "loss", "=", "point_loss", "=", "self", ".", "args", ".", "loss_coeff", "*", "utils", ".", "point_loss", "(", "pred_points", ",", "gt_points", ")", "\n", "total_loss", "+=", "point_loss", ".", "item", "(", ")", "\n", "\n", "# backprop", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# log", "\n", "message", "=", "f'Train || Epoch: {self.epoch},  loss: {loss.item():.5f} '", "\n", "message", "+=", "f'|| best_loss:  {self.best_loss :.5f}'", "\n", "tqdm", ".", "write", "(", "message", ")", "\n", "iterations", "+=", "1.", "\n", "\n", "", "writer", ".", "add_scalars", "(", "'train'", ",", "{", "self", ".", "args", ".", "exp_id", ":", "total_loss", "/", "iterations", "}", ",", "self", ".", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.recon.Engine.validate": [[113, 158], ["recon.Engine.encoder.eval", "enumerate", "print", "print", "print", "enumerate", "tqdm.tqdm.tqdm.write", "writer.add_scalars", "tqdm.tqdm.tqdm", "batch[].cuda", "batch[].cuda", "batch[].cuda", "recon.Engine.encoder", "float", "float", "utils.point_loss", "float", "len", "batch[].cuda"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.point_loss"], ["", "def", "validate", "(", "self", ",", "data", ",", "writer", ")", ":", "\n", "\t\t", "total_loss", "=", "0", "\n", "self", ".", "encoder", ".", "eval", "(", ")", "\n", "\n", "# loop through every class", "\n", "for", "v", ",", "valid_loader", "in", "enumerate", "(", "data", ")", ":", "\n", "\t\t\t", "num_examples", "=", "0", "\n", "class_loss", "=", "0", "\n", "\n", "# loop through every batch", "\n", "for", "k", ",", "batch", "in", "enumerate", "(", "tqdm", "(", "valid_loader", ")", ")", ":", "\n", "\n", "# initialize data", "\n", "\t\t\t\t", "sim_touch", "=", "batch", "[", "'sim_touch'", "]", ".", "cuda", "(", ")", "\n", "depth", "=", "batch", "[", "'depth'", "]", ".", "cuda", "(", ")", "\n", "ref_frame", "=", "batch", "[", "'ref'", "]", "\n", "gt_points", "=", "batch", "[", "'samples'", "]", ".", "cuda", "(", ")", "\n", "obj_class", "=", "batch", "[", "'class'", "]", "[", "0", "]", "\n", "batch_size", "=", "gt_points", ".", "shape", "[", "0", "]", "\n", "\n", "# inference", "\n", "pred_depth", ",", "pred_points", "=", "self", ".", "encoder", "(", "sim_touch", ",", "depth", ",", "ref_frame", ",", "empty", "=", "batch", "[", "'empty'", "]", ".", "cuda", "(", ")", ")", "\n", "\n", "# losses", "\n", "point_loss", "=", "self", ".", "args", ".", "loss_coeff", "*", "utils", ".", "point_loss", "(", "pred_points", ",", "gt_points", ")", "\n", "\n", "# log", "\n", "num_examples", "+=", "float", "(", "batch_size", ")", "\n", "class_loss", "+=", "point_loss", "*", "float", "(", "batch_size", ")", "\n", "\n", "\n", "# log", "\n", "", "class_loss", "=", "(", "class_loss", "/", "num_examples", ")", "\n", "message", "=", "f'Valid || Epoch: {self.epoch}, class: {obj_class}, loss: {class_loss:.5f}'", "\n", "message", "+=", "f' ||  best_loss: {self.best_loss:.5f}'", "\n", "tqdm", ".", "write", "(", "message", ")", "\n", "total_loss", "+=", "(", "class_loss", "/", "float", "(", "len", "(", "self", ".", "classes", ")", ")", ")", "\n", "\n", "# log", "\n", "", "print", "(", "'*******************************************************'", ")", "\n", "print", "(", "f'Total validation loss: {total_loss}'", ")", "\n", "print", "(", "'*******************************************************'", ")", "\n", "if", "not", "self", ".", "args", ".", "eval", ":", "\n", "\t\t\t", "writer", ".", "add_scalars", "(", "'valid'", ",", "{", "self", ".", "args", ".", "exp_id", ":", "total_loss", "}", ",", "self", ".", "epoch", ")", "\n", "", "self", ".", "current_loss", "=", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.recon.Engine.save": [[159, 164], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.exists", "os.makedirs", "recon.Engine.encoder.state_dict", "recon.Engine.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save"], ["", "def", "save", "(", "self", ",", "label", ")", ":", "\n", "\t\t", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "checkpoint_dir", ")", ":", "\n", "\t\t\t", "os", ".", "makedirs", "(", "self", ".", "checkpoint_dir", ")", "\n", "", "torch", ".", "save", "(", "self", ".", "encoder", ".", "state_dict", "(", ")", ",", "self", ".", "checkpoint_dir", "+", "'/encoder_touch'", "+", "label", ")", "\n", "torch", ".", "save", "(", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "self", ".", "checkpoint_dir", "+", "'/optim_touch'", "+", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.recon.Engine.check_values": [[165, 183], ["print", "print", "recon.Engine.save", "print", "recon.Engine.save", "print", "print", "exit"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save"], ["", "def", "check_values", "(", "self", ")", ":", "\n", "\t\t", "if", "self", ".", "best_loss", ">=", "self", ".", "current_loss", ":", "\n", "\t\t\t", "improvement", "=", "self", ".", "best_loss", "-", "self", ".", "current_loss", "\n", "self", ".", "best_loss", "=", "self", ".", "current_loss", "\n", "print", "(", "f'Saving Model with a {improvement} improvement in point loss'", ")", "\n", "self", ".", "save", "(", "''", ")", "\n", "self", ".", "last_improvement", "=", "0", "\n", "", "else", ":", "\n", "\t\t\t", "self", ".", "last_improvement", "+=", "1", "\n", "if", "self", ".", "last_improvement", "==", "self", ".", "args", ".", "patience", ":", "\n", "\t\t\t\t", "print", "(", "f'Over {self.args.patience} steps since last imporvement'", ")", "\n", "print", "(", "'Exiting now'", ")", "\n", "exit", "(", ")", "\n", "\n", "", "", "if", "self", ".", "epoch", "%", "10", "==", "0", ":", "\n", "\t\t\t", "print", "(", "f'Saving Model at epoch {self.epoch}'", ")", "\n", "self", ".", "save", "(", "f'_recent'", ")", "\n", "", "print", "(", "'*******************************************************'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.recon.Engine.load": [[185, 188], ["recon.Engine.encoder.load_state_dict", "recon.Engine.optimizer.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load"], ["", "def", "load", "(", "self", ",", "label", ")", ":", "\n", "\t\t", "self", ".", "encoder", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "checkpoint_dir", "+", "'/encoder_touch'", "+", "label", ")", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "checkpoint_dir", "+", "'/optim_touch'", "+", "label", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.touch_charts.submit.call": [[19, 21], ["os.system"], "function", ["None"], ["", "def", "call", "(", "command", ")", ":", "\n", "\t", "os", ".", "system", "(", "command", ")", "\n", "", "from", "multiprocessing", "import", "Pool", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.models.Image_Encoder.__init__": [[16, 37], ["torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "numpy.array", "numpy.array", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "layers.append", "range", "models.CNN_layer", "layers.append", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "models.CNN_layer", "numpy.array.dot"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.__init__", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.models.CNN_layer", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.models.CNN_layer"], ["\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "not", "mid_channels", ":", "\n", "\t\t\t", "mid_channels", "=", "out_channels", "\n", "", "self", ".", "double_conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "mid_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "mid_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "mid_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\t\t", "return", "self", ".", "double_conv", "(", "x", ")", "\n", "\n", "# implemented from:", "\n", "# https://github.com/MicrosoftLearning/dev290x-v2/blob/master/Mod04/02-Unet/unet_pytorch/model.py", "\n", "# MIT License", "\n", "", "", "class", "Down", "(", "nn", ".", "Module", ")", ":", "\n", "\t", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "maxpool_conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "MaxPool2d", "(", "2", ")", ",", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.models.Image_Encoder.pooling": [[42, 124], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "models.Image_Encoder.matrix.permute", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "torch.clamp().data.cpu().numpy().astype", "range", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "x1s.type.type.type", "y1s.type.type.type", "x2s.type.type.type", "y2s.type.type.type", "block.permute().contiguous().view", "torch.arange().cuda().unsqueeze().expand", "torch.arange().cuda().unsqueeze().expand", "torch.arange().cuda().unsqueeze().expand", "torch.arange().cuda().unsqueeze().expand", "torch.arange().cuda().unsqueeze().expand", "torch.arange().cuda().unsqueeze().expand", "torch.arange().cuda().unsqueeze().expand", "torch.arange().cuda().unsqueeze().expand", "torch.arange().cuda().unsqueeze().expand", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "C.view().permute.view().permute.view().permute", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "D.view().permute.view().permute.view().permute", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "E.view().permute.view().permute.view().permute", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "F.view().permute.view().permute.view().permute", "features.permute.permute.permute", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "zip", "Image.fromarray().save", "print", "input", "torch.floor", "torch.floor", "torch.floor", "torch.floor", "torch.floor", "torch.floor", "torch.floor", "torch.floor", "torch.floor", "torch.floor", "torch.floor", "torch.floor", "torch.floor", "torch.floor", "torch.floor", "torch.floor", "torch.floor", "torch.floor", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "G.unsqueeze", "A.unsqueeze", "B.unsqueeze", "H.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "torch.clamp().data.cpu().numpy", "blocks[].permute().data.cpu().numpy", "block.permute().contiguous", "torch.arange().cuda().unsqueeze", "torch.arange().cuda().unsqueeze", "torch.arange().cuda().unsqueeze", "torch.arange().cuda().unsqueeze", "torch.arange().cuda().unsqueeze", "torch.arange().cuda().unsqueeze", "torch.arange().cuda().unsqueeze", "torch.arange().cuda().unsqueeze", "torch.arange().cuda().unsqueeze", "C.view().permute.view().permute.view", "D.view().permute.view().permute.view", "E.view().permute.view().permute.view", "F.view().permute.view().permute.view", "A.unsqueeze", "H.unsqueeze", "G.unsqueeze", "B.unsqueeze", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "Image.fromarray", "numpy.ones", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "torch.clamp().data.cpu", "blocks[].permute().data.cpu", "block.permute", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "blocks[].permute"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save"], ["\n", "# implemented from:", "\n", "# https://github.com/MicrosoftLearning/dev290x-v2/blob/master/Mod04/02-Unet/unet_pytorch/model.py", "\n", "# MIT License", "\n", "", "", "class", "Up", "(", "nn", ".", "Module", ")", ":", "\n", "\t", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "up", "=", "nn", ".", "ConvTranspose2d", "(", "in_channels", ",", "in_channels", "//", "2", ",", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", "\n", "self", ".", "conv", "=", "DoubleConv", "(", "in_channels", ",", "out_channels", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x1", ",", "x2", ")", ":", "\n", "\t\t", "x1", "=", "self", ".", "up", "(", "x1", ")", "\n", "diffY", "=", "torch", ".", "tensor", "(", "[", "x2", ".", "size", "(", ")", "[", "2", "]", "-", "x1", ".", "size", "(", ")", "[", "2", "]", "]", ")", "\n", "diffX", "=", "torch", ".", "tensor", "(", "[", "x2", ".", "size", "(", ")", "[", "3", "]", "-", "x1", ".", "size", "(", ")", "[", "3", "]", "]", ")", "\n", "x1", "=", "F", ".", "pad", "(", "x1", ",", "[", "diffX", "//", "2", ",", "diffX", "-", "diffX", "//", "2", ",", "\n", "diffY", "//", "2", ",", "diffY", "-", "diffY", "//", "2", "]", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x2", ",", "x1", "]", ",", "dim", "=", "1", ")", "\n", "output", "=", "self", ".", "conv", "(", "x", ")", "\n", "return", "output", "\n", "\n", "# implemented from:", "\n", "# https://github.com/MicrosoftLearning/dev290x-v2/blob/master/Mod04/02-Unet/unet_pytorch/model.py", "\n", "# MIT License", "\n", "", "", "class", "OutConv", "(", "nn", ".", "Module", ")", ":", "\n", "\t", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ")", ":", "\n", "\t\t", "super", "(", "OutConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\t\t", "return", "self", ".", "conv", "(", "x", ")", "\n", "\n", "\n", "\n", "", "", "class", "Encoder", "(", "nn", ".", "Module", ")", ":", "\n", "\t", "def", "__init__", "(", "self", ",", "args", ",", "dim", "=", "100", ")", ":", "\n", "\t\t", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "# settings", "\n", "n_channels", "=", "3", "\n", "n_classes", "=", "1", "\n", "\n", "# downscale the image", "\n", "self", ".", "inc", "=", "DoubleConv", "(", "n_channels", ",", "64", ")", "\n", "self", ".", "down1", "=", "Down", "(", "64", ",", "128", ")", "\n", "self", ".", "down2", "=", "Down", "(", "128", ",", "256", ")", "\n", "self", ".", "down3", "=", "Down", "(", "256", ",", "512", ")", "\n", "\n", "# upscale the image", "\n", "self", ".", "down4", "=", "Down", "(", "512", ",", "1024", ")", "\n", "self", ".", "up1", "=", "Up", "(", "1024", ",", "512", ")", "\n", "self", ".", "up2", "=", "Up", "(", "512", ",", "256", ")", "\n", "self", ".", "up3", "=", "Up", "(", "256", ",", "128", ")", "\n", "self", ".", "up4", "=", "Up", "(", "128", ",", "64", ")", "\n", "self", ".", "outc", "=", "OutConv", "(", "64", ",", "n_classes", ")", "\n", "\n", "# define a plane of the same size, and shape at the touch sensor", "\n", "width", "=", ".0218", "-", "0.00539", "\n", "y_z", "=", "torch", ".", "arange", "(", "dim", ")", ".", "cuda", "(", ")", ".", "view", "(", "dim", ",", "1", ")", ".", "expand", "(", "dim", ",", "dim", ")", ".", "float", "(", ")", "\n", "y_z", "=", "torch", ".", "stack", "(", "(", "y_z", ",", "y_z", ".", "permute", "(", "1", ",", "0", ")", ")", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ")", "\n", "plane", "=", "torch", ".", "cat", "(", "(", "torch", ".", "zeros", "(", "dim", ",", "dim", ",", "1", ")", ".", "cuda", "(", ")", ",", "y_z", ")", ",", "dim", "=", "-", "1", ")", "\n", "self", ".", "orig_plane", "=", "(", "plane", "/", "float", "(", "dim", ")", "-", ".5", ")", "*", "width", "\n", "\n", "# update the plane with the predicted depth information", "\n", "", "def", "project_depth", "(", "self", ",", "depths", ",", "pos", ",", "rot", ",", "dim", "=", "100", ")", ":", "\n", "# reshape the plane to have the same position and orientation as the touch sensor when the touch occurred", "\n", "\t\t", "batch_size", "=", "depths", ".", "shape", "[", "0", "]", "\n", "planes", "=", "self", ".", "orig_plane", ".", "view", "(", "1", ",", "-", "1", ",", "3", ")", ".", "expand", "(", "batch_size", ",", "-", "1", ",", "3", ")", "\n", "planes", "=", "torch", ".", "bmm", "(", "rot", ",", "planes", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "planes", "+=", "pos", ".", "view", "(", "batch_size", ",", "1", ",", "3", ")", "\n", "\n", "# add the depth in the same direction as the normal of the sensor plane", "\n", "init_camera_vector", "=", "torch", ".", "FloatTensor", "(", "(", "1", ",", "0", ",", "0", ")", ")", ".", "cuda", "(", ")", ".", "view", "(", "1", ",", "3", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "3", ",", "1", ")", "\n", "camera_vector", "=", "torch", ".", "bmm", "(", "rot", ",", "init_camera_vector", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "camera_vector", "=", "F", ".", "normalize", "(", "camera_vector", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", ".", "view", "(", "batch_size", ",", "1", ",", "1", ",", "3", ")", ".", "expand", "(", "batch_size", ",", "dim", ",", "dim", ",", "3", ")", "\n", "depth_update", "=", "depths", ".", "unsqueeze", "(", "-", "1", ")", "*", "camera_vector", "\n", "local_depth", "=", "(", "planes", "+", "depth_update", ".", "view", "(", "batch_size", ",", "-", "1", ",", "3", ")", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "3", ")", "\n", "\n", "return", "local_depth", "\n", "\n", "", "def", "forward", "(", "self", ",", "gel", ",", "depth", ",", "ref_frame", ",", "empty", ",", "producing_sheet", "=", "False", ")", ":", "\n", "# get initial data", "\n", "\t\t", "batch_size", "=", "ref_frame", "[", "'pos'", "]", ".", "shape", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.models.Image_Encoder.forward": [[125, 147], ["enumerate", "features.append", "models.Image_Encoder.pooling", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "features.append", "len"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.models.Image_Encoder.pooling"], ["pos", "=", "ref_frame", "[", "'pos'", "]", ".", "cuda", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "rot_m", "=", "ref_frame", "[", "'rot_M'", "]", ".", "cuda", "(", ")", ".", "view", "(", "-", "1", ",", "3", ",", "3", ")", "\n", "\n", "# U-Net prediction", "\n", "# downscale the image", "\n", "x1", "=", "self", ".", "inc", "(", "gel", ")", "\n", "x2", "=", "self", ".", "down1", "(", "x1", ")", "\n", "x3", "=", "self", ".", "down2", "(", "x2", ")", "\n", "x4", "=", "self", ".", "down3", "(", "x3", ")", "\n", "x5", "=", "self", ".", "down4", "(", "x4", ")", "\n", "# upscale the image", "\n", "x", "=", "self", ".", "up1", "(", "x5", ",", "x4", ")", "\n", "x", "=", "self", ".", "up2", "(", "x", ",", "x3", ")", "\n", "x", "=", "self", ".", "up3", "(", "x", ",", "x2", ")", "\n", "x", "=", "self", ".", "up4", "(", "x", ",", "x1", ")", "\n", "pred_depth", "=", "(", "self", ".", "outc", "(", "x", ")", ")", "\n", "# scale the prediction", "\n", "pred_depth", "=", "F", ".", "sigmoid", "(", "pred_depth", ")", "*", "0.1", "\n", "\n", "# we only want to use the points in the predicted point cloud if they correspond to pixels in the touch signal", "\n", "# which are \"different\" enough from the an untouched touch signal, otherwise the do not correspond to any", "\n", "# geometry of the object which is deforming the touch sensor's surface.", "\n", "diff", "=", "torch", ".", "sqrt", "(", "(", "(", "(", "gel", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "-", "empty", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "3", ")", ")", "**", "2", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.models.Encoder.__init__": [[153, 169], ["torch.Module.__init__", "GCN().cuda", "Image_Encoder().cuda", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "models.GCN", "models.Image_Encoder", "models.Encoder.img_encoder", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.__init__"], ["for", "points", ",", "useful", "in", "zip", "(", "projected_depths", ",", "useful_points", ")", ":", "\n", "# select only useful points", "\n", "\t\t\t", "orig_points", "=", "points", ".", "clone", "(", ")", "\n", "points", "=", "points", "[", "useful", "]", "\n", "if", "points", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "\t\t\t\t", "if", "producing_sheet", ":", "\n", "\t\t\t\t\t", "pred_points", ".", "append", "(", "torch", ".", "zeros", "(", "(", "self", ".", "args", ".", "num_samples", ",", "3", ")", ")", ".", "cuda", "(", ")", ")", "\n", "continue", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "points", "=", "orig_points", "\n", "\n", "# make the number of points in each element of a batch consistent", "\n", "", "", "while", "points", ".", "shape", "[", "0", "]", "<", "self", ".", "args", ".", "num_samples", ":", "\n", "\t\t\t\t", "points", "=", "torch", ".", "cat", "(", "(", "points", ",", "points", ",", "points", ",", "points", ")", ")", "\n", "", "perm", "=", "torch", ".", "randperm", "(", "points", ".", "shape", "[", "0", "]", ")", "\n", "idx", "=", "perm", "[", ":", "self", ".", "args", ".", "num_samples", "]", "\n", "points", "=", "points", "[", "idx", "]", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.models.Encoder.forward": [[171, 204], ["models.Encoder.initial_positions.unsqueeze().expand", "range", "batch[].cuda().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.clone", "torch.cat.clone", "torch.cat.clone", "models.Encoder.mesh_decoder", "models.Encoder.initial_positions.unsqueeze", "models.Encoder.img_encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.FloatTensor().cuda().unsqueeze().expand", "torch.FloatTensor().cuda().unsqueeze().expand", "torch.FloatTensor().cuda().unsqueeze().expand", "torch.FloatTensor().cuda().unsqueeze().expand", "torch.FloatTensor().cuda().unsqueeze().expand", "torch.FloatTensor().cuda().unsqueeze().expand", "torch.FloatTensor().cuda().unsqueeze().expand", "torch.FloatTensor().cuda().unsqueeze().expand", "torch.FloatTensor().cuda().unsqueeze().expand", "touch_chart_mask.contiguous().view.contiguous().view.contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "batch[].cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.FloatTensor().cuda().unsqueeze", "torch.FloatTensor().cuda().unsqueeze", "torch.FloatTensor().cuda().unsqueeze", "torch.FloatTensor().cuda().unsqueeze", "torch.FloatTensor().cuda().unsqueeze", "torch.FloatTensor().cuda().unsqueeze", "torch.FloatTensor().cuda().unsqueeze", "torch.FloatTensor().cuda().unsqueeze", "torch.FloatTensor().cuda().unsqueeze", "touch_chart_mask.contiguous().view.contiguous().view.contiguous", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["None"], ["", "pred_points", "=", "torch", ".", "stack", "(", "pred_points", ")", "\n", "\n", "\n", "return", "pred_depth", ",", "pred_points", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.models.GCN.__init__": [[210, 222], ["torch.Module.__init__", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "layers.append", "models.GCN_layer", "range"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.__init__"], []], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.models.GCN.forward": [[224, 234], ["range"], "methods", ["None"], []], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.models.GCN_layer.__init__": [[249, 254], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "models.GCN_layer.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.__init__", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.models.GCN_layer.reset_parameters"], []], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.models.GCN_layer.reset_parameters": [[255, 260], ["models.GCN_layer.weight1.data.uniform_", "models.GCN_layer.bias.data.uniform_", "math.sqrt", "models.GCN_layer.weight1.size", "models.GCN_layer.weight1.size"], "methods", ["None"], []], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.models.GCN_layer.forward": [[261, 268], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "activation"], "methods", ["None"], []], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.models.CNN_layer": [[236, 242], ["layers.append", "layers.append", "layers.append", "torch.Sequential", "torch.Conv2d", "torch.BatchNorm2d", "torch.ReLU", "int", "int", "int"], "function", ["None"], []], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.__init__": [[28, 43], ["numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "os.path.join"], "methods", ["None"], ["torch", ".", "cuda", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# set initial data values", "\n", "self", ".", "epoch", "=", "0", "\n", "self", ".", "best_loss", "=", "10000", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "last_improvement", "=", "0", "\n", "self", ".", "classes", "=", "[", "'0001'", ",", "'0002'", "]", "\n", "self", ".", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "'experiments/checkpoint/'", ",", "args", ".", "exp_type", ",", "args", ".", "exp_id", ")", "\n", "self", ".", "log_dir", "=", "f'experiments/results/{self.args.exp_type}/{self.args.exp_id}/'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "log_dir", ")", ":", "\n", "\t\t\t", "os", ".", "makedirs", "(", "self", ".", "log_dir", ")", "\n", "\n", "\n", "", "", "def", "__call__", "(", "self", ")", "->", "float", ":", "\n", "\t\t", "self", ".", "encoder", "=", "models", ".", "Encoder", "(", "self", ".", "args", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.__call__": [[46, 75], ["models.Encoder", "recon.Engine.encoder.cuda", "list", "torch.Adam", "torch.Adam", "torch.utils.tensorboard.SummaryWriter", "torch.utils.tensorboard.SummaryWriter", "recon.Engine.get_loaders", "range", "utils.load_mesh_vision", "utils.load_mesh_vision", "torch.autograd.Variable", "torch.autograd.Variable", "recon.Engine.encoder.parameters", "os.path.join", "exit", "recon.Engine.train", "recon.Engine.check_values", "initial_positions.cuda", "recon.Engine.load_pretrained", "recon.Engine.load", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "recon.Engine.validate", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "recon.Engine.validate"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.get_loaders", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.load_mesh_vision", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.load_mesh_vision", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.train", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.check_values", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load_pretrained", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.validate", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.validate"], ["self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "params", ",", "lr", "=", "self", ".", "args", ".", "lr", ",", "weight_decay", "=", "0", ")", "\n", "writer", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "'experiments/tensorboard/'", ",", "args", ".", "exp_type", ")", ")", "\n", "\n", "train_loader", ",", "valid_loaders", "=", "self", ".", "get_loaders", "(", ")", "\n", "\n", "if", "self", ".", "args", ".", "eval", ":", "\n", "\t\t\t", "self", ".", "load", "(", "''", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t\t", "self", ".", "validate", "(", "valid_loaders", ",", "writer", ")", "\n", "", "exit", "(", ")", "\n", "", "for", "epoch", "in", "range", "(", "self", ".", "args", ".", "epochs", ")", ":", "\n", "\t\t\t", "self", ".", "epoch", "=", "epoch", "\n", "self", ".", "train", "(", "train_loader", ",", "writer", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t\t", "self", ".", "validate", "(", "valid_loaders", ",", "writer", ")", "\n", "", "self", ".", "check_values", "(", ")", "\n", "\n", "\n", "", "", "def", "get_loaders", "(", "self", ")", ":", "\n", "# training data", "\n", "\t\t", "train_data", "=", "data_loaders", ".", "mesh_loader_touch", "(", "self", ".", "classes", ",", "self", ".", "args", ",", "set_type", "=", "'train'", ")", "\n", "train_loader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "self", ".", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "16", ",", "collate_fn", "=", "train_data", ".", "collate", ")", "\n", "\n", "# validation data", "\n", "valid_loaders", "=", "[", "]", "\n", "set_type", "=", "'test'", "if", "self", ".", "args", ".", "eval", "else", "'valid'", "\n", "for", "c", "in", "self", ".", "classes", ":", "\n", "\t\t\t", "valid_data", "=", "data_loaders", ".", "mesh_loader_touch", "(", "c", ",", "self", ".", "args", ",", "set_type", "=", "set_type", ")", "\n", "valid_loaders", ".", "append", "(", "\n", "DataLoader", "(", "valid_data", ",", "batch_size", "=", "self", ".", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "num_workers", "=", "16", ",", "collate_fn", "=", "valid_data", ".", "collate", ")", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.get_loaders": [[77, 87], ["data_loaders.mesh_loader_vision", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "data_loaders.mesh_loader_vision", "valid_loaders.append", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], ["\n", "\n", "", "def", "train", "(", "self", ",", "data", ",", "writer", ")", ":", "\n", "\t\t", "total_loss", "=", "0", "\n", "iterations", "=", "0", "\n", "self", ".", "encoder", ".", "train", "(", ")", "\n", "for", "k", ",", "batch", "in", "enumerate", "(", "tqdm", "(", "data", ")", ")", ":", "\n", "\t\t\t", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# initialize data", "\n", "sim_touch", "=", "batch", "[", "'sim_touch'", "]", ".", "cuda", "(", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.train": [[88, 120], ["recon.Engine.encoder.train", "enumerate", "writer.add_scalars", "tqdm.tqdm.tqdm", "recon.Engine.optimizer.zero_grad", "batch[].cuda", "batch[].cuda", "batch[].cuda", "recon.Engine.encoder", "utils.chamfer_distance", "utils.chamfer_distance.backward", "recon.Engine.optimizer.step", "tqdm.tqdm.tqdm.write", "utils.chamfer_distance.item", "utils.chamfer_distance.mean", "utils.chamfer_distance.item"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.train", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.chamfer_distance"], ["depth", "=", "batch", "[", "'depth'", "]", ".", "cuda", "(", ")", "\n", "ref_frame", "=", "batch", "[", "'ref'", "]", "\n", "gt_points", "=", "batch", "[", "'samples'", "]", ".", "cuda", "(", ")", "\n", "\n", "# inference", "\n", "pred_depth", ",", "pred_points", "=", "self", ".", "encoder", "(", "sim_touch", ",", "depth", ",", "ref_frame", ",", "empty", "=", "batch", "[", "'empty'", "]", ".", "cuda", "(", ")", ")", "\n", "\n", "# losses", "\n", "loss", "=", "point_loss", "=", "self", ".", "args", ".", "loss_coeff", "*", "utils", ".", "point_loss", "(", "pred_points", ",", "gt_points", ")", "\n", "total_loss", "+=", "point_loss", ".", "item", "(", ")", "\n", "\n", "# backprop", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# log", "\n", "message", "=", "f'Train || Epoch: {self.epoch},  loss: {loss.item():.5f} '", "\n", "message", "+=", "f'|| best_loss:  {self.best_loss :.5f}'", "\n", "tqdm", ".", "write", "(", "message", ")", "\n", "iterations", "+=", "1.", "\n", "\n", "", "writer", ".", "add_scalars", "(", "'train'", ",", "{", "self", ".", "args", ".", "exp_id", ":", "total_loss", "/", "iterations", "}", ",", "self", ".", "epoch", ")", "\n", "\n", "\n", "\n", "", "def", "validate", "(", "self", ",", "data", ",", "writer", ")", ":", "\n", "\t\t", "total_loss", "=", "0", "\n", "self", ".", "encoder", ".", "eval", "(", ")", "\n", "\n", "# loop through every class", "\n", "for", "v", ",", "valid_loader", "in", "enumerate", "(", "data", ")", ":", "\n", "\t\t\t", "num_examples", "=", "0", "\n", "class_loss", "=", "0", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.validate": [[124, 163], ["recon.Engine.encoder.eval", "enumerate", "print", "print", "print", "writer.add_scalars", "enumerate", "tqdm.tqdm.tqdm.write", "tqdm.tqdm.tqdm", "batch[].cuda", "batch[].cuda", "batch[].cuda", "recon.Engine.encoder", "utils.chamfer_distance", "float", "float", "len", "utils.chamfer_distance.mean"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.None.utils.chamfer_distance"], ["\n", "# initialize data", "\n", "\t\t\t\t", "sim_touch", "=", "batch", "[", "'sim_touch'", "]", ".", "cuda", "(", ")", "\n", "depth", "=", "batch", "[", "'depth'", "]", ".", "cuda", "(", ")", "\n", "ref_frame", "=", "batch", "[", "'ref'", "]", "\n", "gt_points", "=", "batch", "[", "'samples'", "]", ".", "cuda", "(", ")", "\n", "obj_class", "=", "batch", "[", "'class'", "]", "[", "0", "]", "\n", "batch_size", "=", "gt_points", ".", "shape", "[", "0", "]", "\n", "\n", "# inference", "\n", "pred_depth", ",", "pred_points", "=", "self", ".", "encoder", "(", "sim_touch", ",", "depth", ",", "ref_frame", ",", "empty", "=", "batch", "[", "'empty'", "]", ".", "cuda", "(", ")", ")", "\n", "\n", "# losses", "\n", "point_loss", "=", "self", ".", "args", ".", "loss_coeff", "*", "utils", ".", "point_loss", "(", "pred_points", ",", "gt_points", ")", "\n", "\n", "# log", "\n", "num_examples", "+=", "float", "(", "batch_size", ")", "\n", "class_loss", "+=", "point_loss", "*", "float", "(", "batch_size", ")", "\n", "\n", "\n", "# log", "\n", "", "class_loss", "=", "(", "class_loss", "/", "num_examples", ")", "\n", "message", "=", "f'Valid || Epoch: {self.epoch}, class: {obj_class}, loss: {class_loss:.5f}'", "\n", "message", "+=", "f' ||  best_loss: {self.best_loss:.5f}'", "\n", "tqdm", ".", "write", "(", "message", ")", "\n", "total_loss", "+=", "(", "class_loss", "/", "float", "(", "len", "(", "self", ".", "classes", ")", ")", ")", "\n", "\n", "# log", "\n", "", "print", "(", "'*******************************************************'", ")", "\n", "print", "(", "f'Total validation loss: {total_loss}'", ")", "\n", "print", "(", "'*******************************************************'", ")", "\n", "if", "not", "self", ".", "args", ".", "eval", ":", "\n", "\t\t\t", "writer", ".", "add_scalars", "(", "'valid'", ",", "{", "self", ".", "args", ".", "exp_id", ":", "total_loss", "}", ",", "self", ".", "epoch", ")", "\n", "", "self", ".", "current_loss", "=", "total_loss", "\n", "\n", "", "def", "save", "(", "self", ",", "label", ")", ":", "\n", "\t\t", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "checkpoint_dir", ")", ":", "\n", "\t\t\t", "os", ".", "makedirs", "(", "self", ".", "checkpoint_dir", ")", "\n", "", "torch", ".", "save", "(", "self", ".", "encoder", ".", "state_dict", "(", ")", ",", "self", ".", "checkpoint_dir", "+", "'/encoder_touch'", "+", "label", ")", "\n", "torch", ".", "save", "(", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "self", ".", "checkpoint_dir", "+", "'/optim_touch'", "+", "label", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save": [[164, 169], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.exists", "os.makedirs", "recon.Engine.encoder.state_dict", "recon.Engine.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save"], ["\n", "", "def", "check_values", "(", "self", ")", ":", "\n", "\t\t", "if", "self", ".", "best_loss", ">=", "self", ".", "current_loss", ":", "\n", "\t\t\t", "improvement", "=", "self", ".", "best_loss", "-", "self", ".", "current_loss", "\n", "self", ".", "best_loss", "=", "self", ".", "current_loss", "\n", "print", "(", "f'Saving Model with a {improvement} improvement in point loss'", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.check_values": [[170, 188], ["print", "print", "recon.Engine.save", "print", "recon.Engine.save", "print", "print", "exit"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.save"], ["self", ".", "save", "(", "''", ")", "\n", "self", ".", "last_improvement", "=", "0", "\n", "", "else", ":", "\n", "\t\t\t", "self", ".", "last_improvement", "+=", "1", "\n", "if", "self", ".", "last_improvement", "==", "self", ".", "args", ".", "patience", ":", "\n", "\t\t\t\t", "print", "(", "f'Over {self.args.patience} steps since last imporvement'", ")", "\n", "print", "(", "'Exiting now'", ")", "\n", "exit", "(", ")", "\n", "\n", "", "", "if", "self", ".", "epoch", "%", "10", "==", "0", ":", "\n", "\t\t\t", "print", "(", "f'Saving Model at epoch {self.epoch}'", ")", "\n", "self", ".", "save", "(", "f'_recent'", ")", "\n", "", "print", "(", "'*******************************************************'", ")", "\n", "\n", "\n", "", "def", "load", "(", "self", ",", "label", ")", ":", "\n", "\t\t", "self", ".", "encoder", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "checkpoint_dir", "+", "'/encoder_touch'", "+", "label", ")", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "checkpoint_dir", "+", "'/optim_touch'", "+", "label", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load": [[189, 192], ["recon.Engine.encoder.load_state_dict", "recon.Engine.optimizer.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load"], ["\n", "", "", "if", "__name__", "==", "'__main__'", ":", "\n", "\n", "\t", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load_pretrained": [[193, 196], ["recon.Engine.encoder.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load", "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.recon.Engine.load"], ["parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Setting for the random seed.'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "300", ",", "help", "=", "'Number of epochs to use.'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'Initial learning rate.'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'Evaluate the trained model on the test set.'", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.submit.call": [[10, 12], ["os.system"], "function", ["None"], ["\n", "\n", "interval", "=", "1300", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_3D-Vision-and-Touch.vision_charts.submit.add_commands": [[21, 44], ["list", "numpy.where", "numpy.stack().transpose", "params.keys", "number.append", "enumerate", "commands.append", "len", "numpy.zeros", "numpy.stack"], "function", ["None"], ["", "from", "multiprocessing", "import", "Pool", "\n", "pool", "=", "Pool", "(", "processes", "=", "10", ")", "\n", "pbar", "=", "tqdm", "(", "pool", ".", "imap_unordered", "(", "call", ",", "commands_to_run", ")", ",", "total", "=", "len", "(", "commands_to_run", ")", ")", "\n", "pbar", ".", "set_description", "(", "f\"calling submitit\"", ")", "\n", "for", "_", "in", "pbar", ":", "\n", "\t", "pass", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "", ""]]}