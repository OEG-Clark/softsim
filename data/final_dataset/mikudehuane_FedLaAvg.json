{"home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba.AlibabaDatasetBasic.__init__": [[78, 86], ["torch.utils.data.Dataset.__init__", "open().readlines", "open"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ",", "source_fp", ",", "max_length", "=", "100", ")", ":", "\n", "        ", "\"\"\"\n        :param source_fp: source file path\n        :param max_length: maximum length of user behvaior for training\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "data", "=", "open", "(", "source_fp", ")", ".", "readlines", "(", ")", "\n", "self", ".", "max_length", "=", "max_length", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba.AlibabaDatasetBasic.__len__": [[87, 89], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba.AlibabaDatasetBasic.__getitem__": [[90, 111], ["datum.strip().split.strip().split.strip().split", "int", "int", "int", "torch.from_numpy", "torch.from_numpy", "int", "int", "numpy.array", "int", "numpy.array", "len", "datum.strip().split.strip().split.strip", "torch.from_numpy.split", "torch.from_numpy.split"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "datum", "=", "self", ".", "data", "[", "item", "]", "\n", "datum", "=", "datum", ".", "strip", "(", ")", ".", "split", "(", "_split_column", ")", "\n", "uid", "=", "int", "(", "datum", "[", "AlibabaDataset", ".", "CLIENT", "]", ")", "\n", "gid", "=", "int", "(", "datum", "[", "AlibabaDataset", ".", "GOOD", "]", ")", "\n", "cid", "=", "int", "(", "datum", "[", "AlibabaDataset", ".", "CAT", "]", ")", "\n", "\n", "gid_his", "=", "datum", "[", "AlibabaDataset", ".", "GOOD_HIS", "]", "\n", "gid_his", "=", "[", "int", "(", "x", ")", "for", "x", "in", "gid_his", ".", "split", "(", "_split_his", ")", "]", "\n", "gid_his", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "gid_his", ")", ")", "\n", "cid_his", "=", "datum", "[", "AlibabaDataset", ".", "CAT_HIS", "]", "\n", "cid_his", "=", "[", "int", "(", "x", ")", "for", "x", "in", "cid_his", ".", "split", "(", "_split_his", ")", "]", "\n", "cid_his", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "cid_his", ")", ")", "\n", "\n", "if", "len", "(", "gid_his", ")", ">", "self", ".", "max_length", ":", "\n", "            ", "gid_his", "=", "gid_his", "[", "-", "self", ".", "max_length", ":", "]", "\n", "cid_his", "=", "cid_his", "[", "-", "self", ".", "max_length", ":", "]", "\n", "\n", "", "click", "=", "int", "(", "datum", "[", "AlibabaDataset", ".", "CLK", "]", ")", "\n", "\n", "return", "uid", ",", "gid", ",", "cid", ",", "gid_his", ",", "cid_his", ",", "click", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba.AlibabaDataset.__init__": [[117, 128], ["alibaba.AlibabaDatasetBasic.__init__", "pickle.load", "pickle.load", "pickle.load", "print", "open", "open", "open"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        :param source_fp: source file path\n        :param max_length: maximum length of user behvaior for training\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "client_map", "=", "pickle", ".", "load", "(", "open", "(", "common", ".", "alibaba_uid_map_fp", ",", "'rb'", ")", ")", "\n", "self", ".", "good_map", "=", "pickle", ".", "load", "(", "open", "(", "common", ".", "alibaba_gid_map_fp", ",", "'rb'", ")", ")", "\n", "self", ".", "cat_map", "=", "pickle", ".", "load", "(", "open", "(", "common", ".", "alibaba_cid_map_fp", ",", "'rb'", ")", ")", "\n", "print", "(", "f\"number of clients: {self.num_clients}, goods: {self.num_goods}, categories: {self.num_cats}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba.AlibabaDataset.shuffle_": [[129, 132], ["random.seed", "random.shuffle"], "methods", ["None"], ["", "def", "shuffle_", "(", "self", ",", "seed", "=", "3", ")", ":", "\n", "        ", "random", ".", "seed", "(", "3", ")", "\n", "random", ".", "shuffle", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba.AlibabaDataset.num_clients": [[133, 136], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_clients", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "client_map", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba.AlibabaDataset.num_goods": [[137, 140], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_goods", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "good_map", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba.AlibabaDataset.num_cats": [[141, 144], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_cats", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "cat_map", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba.AlibabaDataset.partition_clients": [[145, 163], ["kwargs.pop", "kwargs.pop", "os.join", "os.join", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "enumerate", "open.close", "pickle.dump", "line.strip().split", "open.write", "dict", "open", "open", "os.join", "os.join", "line.strip", "open.close", "os.join", "os.join"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close"], ["", "def", "partition_clients", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "filter_thres", "=", "kwargs", ".", "pop", "(", "\"filter_thres\"", ")", "\n", "filter_clients_up", "=", "kwargs", ".", "pop", "(", "\"filter_thres_up\"", ",", "2", "**", "32", ")", "\n", "fd", "=", "osp", ".", "join", "(", "common", ".", "alibaba_fd", ",", "f\"{filter_thres}_{filter_clients_up}\"", ")", "\n", "os", ".", "makedirs", "(", "fd", ",", "exist_ok", "=", "False", ")", "\n", "f", "=", "None", "\n", "last_client", "=", "None", "\n", "for", "idx", ",", "line", "in", "enumerate", "(", "self", ".", "data", ")", ":", "\n", "            ", "datum", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "_split_column", ")", "\n", "client_id", "=", "datum", "[", "AlibabaDataset", ".", "CLIENT", "]", "\n", "if", "client_id", "!=", "last_client", ":", "\n", "                ", "if", "f", "is", "not", "None", ":", "\n", "                    ", "f", ".", "close", "(", ")", "\n", "", "f", "=", "open", "(", "osp", ".", "join", "(", "fd", ",", "client_id", ")", ",", "'a'", ")", "\n", "", "last_client", "=", "client_id", "\n", "f", ".", "write", "(", "line", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "pickle", ".", "dump", "(", "dict", "(", "num_clients", "=", "self", ".", "num_clients", ")", ",", "open", "(", "osp", ".", "join", "(", "fd", ",", "'meta.pkl'", ")", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba.AlibabaDataset.filter_clients_": [[164, 175], ["set", "line.strip().split", "int", "new_data.append", "line.strip"], "methods", ["None"], ["", "def", "filter_clients_", "(", "self", ",", "clients", ")", ":", "\n", "        ", "\"\"\"\n        filter the dataset, reserve only data with client in clients\n        \"\"\"", "\n", "clients", "=", "set", "(", "client", ".", "id", "for", "client", "in", "clients", ")", "\n", "new_data", "=", "[", "]", "\n", "for", "line", "in", "self", ".", "data", ":", "\n", "            ", "datum", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "_split_column", ")", "\n", "if", "int", "(", "datum", "[", "AlibabaDataset", ".", "CLIENT", "]", ")", "in", "clients", ":", "\n", "                ", "new_data", ".", "append", "(", "line", ")", "\n", "", "", "self", ".", "data", "=", "new_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba.AlibabaDataset.collate_fn": [[176, 192], ["tuple", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.zeros_like", "enumerate", "zip", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "collate_fn", "(", "batch", ")", ":", "\n", "        ", "uids", ",", "gids", ",", "cids", ",", "gid_his", ",", "cid_his", ",", "clicks", "=", "tuple", "(", "zip", "(", "*", "batch", ")", ")", "\n", "seq_lens", "=", "[", "len", "(", "h", ")", "for", "h", "in", "gid_his", "]", "\n", "\n", "uids", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "uids", ",", "dtype", "=", "np", ".", "int64", ")", ")", "\n", "gids", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "gids", ",", "dtype", "=", "np", ".", "int64", ")", ")", "\n", "cids", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "cids", ",", "dtype", "=", "np", ".", "int64", ")", ")", "\n", "clicks", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "clicks", ",", "dtype", "=", "np", ".", "int64", ")", ")", "\n", "\n", "gid_his", "=", "pad_sequence", "(", "gid_his", ",", "batch_first", "=", "True", ")", "\n", "cid_his", "=", "pad_sequence", "(", "cid_his", ",", "batch_first", "=", "True", ")", "\n", "masks", "=", "torch", ".", "zeros_like", "(", "gid_his", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "for", "idx", ",", "seq_len", "in", "enumerate", "(", "seq_lens", ")", ":", "\n", "            ", "masks", "[", "idx", ",", ":", "seq_len", "]", "=", "1.0", "\n", "", "return", "[", "uids", ",", "gids", ",", "cids", ",", "gid_his", ",", "cid_his", ",", "masks", "]", ",", "clicks", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba.str2datetime": [[35, 43], ["datetime.datetime", "int", "int", "int", "int", "int", "int"], "function", ["None"], ["def", "str2datetime", "(", "dtime", ")", ":", "\n", "    ", "return", "datetime", ".", "datetime", "(", "\n", "year", "=", "int", "(", "dtime", "[", ":", "4", "]", ")", ",", "\n", "month", "=", "int", "(", "dtime", "[", "4", ":", "6", "]", ")", ",", "\n", "day", "=", "int", "(", "dtime", "[", "6", ":", "8", "]", ")", ",", "\n", "hour", "=", "int", "(", "dtime", "[", "8", ":", "10", "]", ")", ",", "\n", "minute", "=", "int", "(", "dtime", "[", "11", ":", "13", "]", ")", ",", "\n", "second", "=", "int", "(", "dtime", "[", "14", ":", "16", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba._remap": [[46, 75], ["pickle.load", "pickle.load", "pickle.load", "set", "print", "open", "open", "open", "open", "open", "enumerate", "line.strip().split.strip().split", "fout.write", "len", "set.add", "print", "line.strip().split.strip", "str", "str", "gid_his.split", "cid_his.split"], "function", ["None"], ["", "def", "_remap", "(", "src", ",", "dst", ")", ":", "\n", "    ", "client_map", "=", "pickle", ".", "load", "(", "open", "(", "common", ".", "alibaba_uid_map_fp", ",", "'rb'", ")", ")", "\n", "good_map", "=", "pickle", ".", "load", "(", "open", "(", "common", ".", "alibaba_gid_map_fp", ",", "'rb'", ")", ")", "\n", "cat_map", "=", "pickle", ".", "load", "(", "open", "(", "common", ".", "alibaba_cid_map_fp", ",", "'rb'", ")", ")", "\n", "good_map", "[", "'183215'", "]", "=", "0", "# this is the only good not in the map", "\n", "count_uid_notin", "=", "0", "\n", "notin_clients", "=", "set", "(", ")", "\n", "with", "open", "(", "src", ",", "'r'", ")", "as", "fin", ":", "\n", "        ", "with", "open", "(", "dst", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "for", "line_idx", ",", "line", "in", "enumerate", "(", "fin", ")", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "click", "=", "line", "[", "AlibabaDataset", ".", "CLK", "]", "\n", "uid", "=", "line", "[", "AlibabaDataset", ".", "CLIENT", "]", "\n", "if", "uid", "not", "in", "client_map", ":", "\n", "                    ", "count_uid_notin", "+=", "1", "\n", "notin_clients", ".", "add", "(", "uid", ")", "\n", "uid", "=", "0", "\n", "", "else", ":", "\n", "                    ", "uid", "=", "client_map", "[", "uid", "]", "\n", "", "gid", "=", "good_map", "[", "line", "[", "AlibabaDataset", ".", "GOOD", "]", "]", "\n", "cid", "=", "cat_map", "[", "line", "[", "AlibabaDataset", ".", "CAT", "]", "]", "\n", "gid_his", "=", "line", "[", "AlibabaDataset", ".", "GOOD_HIS", "]", "\n", "gid_his", "=", "' '", ".", "join", "(", "[", "str", "(", "good_map", "[", "_gid", "]", ")", "for", "_gid", "in", "gid_his", ".", "split", "(", "'\\x02'", ")", "]", ")", "\n", "cid_his", "=", "line", "[", "AlibabaDataset", ".", "CAT_HIS", "]", "\n", "cid_his", "=", "' '", ".", "join", "(", "[", "str", "(", "cat_map", "[", "_cid", "]", ")", "for", "_cid", "in", "cid_his", ".", "split", "(", "'\\x02'", ")", "]", ")", "\n", "fout", ".", "write", "(", "f\"{click},{uid},{gid},{cid},{gid_his},{cid_his}\\n\"", ")", "\n", "if", "line_idx", "%", "100000", "==", "0", ":", "\n", "                    ", "print", "(", "f\"{line_idx} lines processed\"", ",", "end", "=", "'\\r'", ")", "\n", "", "", "", "", "print", "(", "f\"{count_uid_notin} data in {src} with clients not in the map file, these are {len(notin_clients)} clients\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba.get_clients": [[194, 228], ["kwargs.pop", "kwargs.pop", "random.seed", "pickle.load", "pickle.load", "os.walk", "os.walk", "sorted", "open", "open", "random.sample", "os.join", "os.join", "os.join", "alibaba.AlibabaDatasetBasic", "isinstance", "clients.append", "train.client.Client", "isinstance", "train.client.Client", "int", "int", "int", "int"], "function", ["None"], ["", "", "def", "get_clients", "(", "data_fd", ",", "collate_fn", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "collate_fn", "is", "None", ":", "\n", "        ", "collate_fn", "=", "AlibabaDataset", ".", "collate_fn", "\n", "", "num_clients", "=", "kwargs", ".", "pop", "(", "\"num_clients\"", ",", "-", "1", ")", "\n", "availability_file", "=", "kwargs", ".", "pop", "(", "\"availability_file\"", ",", "'client_availability'", ")", "\n", "random", ".", "seed", "(", "3", ")", "\n", "\n", "meta", "=", "pickle", ".", "load", "(", "open", "(", "osp", ".", "join", "(", "data_fd", ",", "'meta.pkl'", ")", ",", "'rb'", ")", ")", "\n", "client_available", "=", "pickle", ".", "load", "(", "open", "(", "osp", ".", "join", "(", "common", ".", "cache_fd", ",", "f'{availability_file}.pkl'", ")", ",", "'rb'", ")", ")", "\n", "\n", "files", "=", "[", "]", "\n", "for", "root", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "data_fd", ")", ":", "\n", "        ", "break", "\n", "# enforce same results each run", "\n", "", "files", "=", "sorted", "(", "files", ")", "\n", "\n", "clients", "=", "[", "]", "\n", "if", "num_clients", "!=", "-", "1", ":", "\n", "        ", "files", "=", "random", ".", "sample", "(", "files", ",", "num_clients", ")", "\n", "", "for", "fn", "in", "files", ":", "\n", "        ", "if", "fn", "!=", "\"meta.pkl\"", ":", "\n", "            ", "fp", "=", "osp", ".", "join", "(", "data_fd", ",", "fn", ")", "\n", "dataset", "=", "AlibabaDatasetBasic", "(", "fp", ")", "\n", "if", "isinstance", "(", "client_available", ",", "list", ")", ":", "\n", "                ", "ar", "=", "client_available", "[", "int", "(", "fn", ")", "]", "\n", "client", "=", "Client", "(", "dataset", ",", "train_indices", "=", "None", ",", "is_available", "=", "(", "\"check_in_range\"", ",", "ar", ")", ",", "collate_fn", "=", "collate_fn", ",", "\n", "id", "=", "int", "(", "fn", ")", ",", "**", "kwargs", ")", "\n", "", "elif", "isinstance", "(", "client_available", ",", "dict", ")", ":", "\n", "                ", "ar", "=", "client_available", "[", "'content'", "]", "[", "int", "(", "fn", ")", "]", "\n", "client", "=", "Client", "(", "dataset", ",", "train_indices", "=", "None", ",", "is_available", "=", "(", "\"check_time\"", ",", "ar", ",", "client_available", "[", "'num_hours1block'", "]", ")", ",", "collate_fn", "=", "collate_fn", ",", "\n", "id", "=", "int", "(", "fn", ")", ",", "**", "kwargs", ")", "\n", "", "clients", ".", "append", "(", "client", ")", "\n", "\n", "", "", "return", "clients", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba._test": [[230, 245], ["alibaba.AlibabaDataset", "enumerate", "print", "print"], "function", ["None"], ["", "def", "_test", "(", ")", ":", "\n", "# _remap(_alibaba_test_fp, _alibaba_test_fp_remap)", "\n", "# _remap(_alibaba_train_fp, _alibaba_train_fp_remap)", "\n", "    ", "ali_trainset", "=", "AlibabaDataset", "(", "alibaba_train_fp", ")", "\n", "num_neg", "=", "0", "\n", "num_posi", "=", "0", "\n", "for", "idx", ",", "datum", "in", "enumerate", "(", "ali_trainset", ")", ":", "\n", "        ", "click", "=", "datum", "[", "-", "1", "]", "\n", "if", "click", "==", "1", ":", "\n", "            ", "num_posi", "+=", "1", "\n", "", "else", ":", "\n", "            ", "num_neg", "+=", "1", "\n", "", "if", "idx", "%", "100000", "==", "0", ":", "\n", "            ", "print", "(", "idx", ")", "\n", "", "", "print", "(", "f\"click {num_posi} ignore {num_neg}, ratio {num_posi / (num_posi + num_neg)}\"", ")", "\n", "# ali_testset = AlibabaDataset(alibaba_test_fp)", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.partition.partition_class": [[16, 32], ["enumerate", "inds[].append", "range", "random.shuffle"], "function", ["None"], ["def", "partition_class", "(", "train_set", ",", "shuffle", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    :param train_set: pytorch dataset to be partitioned mnist or cifar10\n    :param shuffle: whether to shuffle data in one class\n    :return inds: inds[label] is the list of image index with the given label\n    \"\"\"", "\n", "inds", "=", "[", "[", "]", "for", "_", "in", "range", "(", "common", ".", "NUM_CIFAR10_CLASSES", ")", "]", "\n", "\n", "for", "i", ",", "(", "fig", ",", "label", ")", "in", "enumerate", "(", "train_set", ")", ":", "\n", "        ", "inds", "[", "label", "]", ".", "append", "(", "i", ")", "\n", "\n", "", "if", "shuffle", ":", "\n", "        ", "for", "inds_i", "in", "inds", ":", "\n", "            ", "random", ".", "shuffle", "(", "inds_i", ")", "\n", "\n", "", "", "return", "inds", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.partition.train_set2files": [[34, 44], ["os.join", "os.exists", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "os.makedirs", "os.makedirs", "enumerate", "ValueError", "open", "pickle.dump", "os.join", "str"], "function", ["None"], ["", "def", "train_set2files", "(", "raw_data_dir", "=", "common", ".", "raw_data_dir", ",", "output_data_dir", "=", "osp", ".", "join", "(", "common", ".", "data_cache_dir", ",", "\"processed\"", ")", ")", ":", "\n", "    ", "if", "osp", ".", "exists", "(", "output_data_dir", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f'Output data directory \\\"{output_data_dir}\\\" exists!'", ")", "\n", "\n", "", "train_set", "=", "torchvision", ".", "datasets", ".", "CIFAR10", "(", "root", "=", "raw_data_dir", ",", "train", "=", "True", ",", "download", "=", "True", ",", "\n", "transform", "=", "common", ".", "transform", ")", "\n", "os", ".", "makedirs", "(", "output_data_dir", ",", "exist_ok", "=", "True", ")", "\n", "for", "ind", ",", "data", "in", "enumerate", "(", "train_set", ")", ":", "\n", "        ", "with", "open", "(", "osp", ".", "join", "(", "output_data_dir", ",", "str", "(", "ind", ")", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "pkl", ".", "dump", "(", "data", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.partition.partition": [[46, 148], ["os.join", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "random.seed", "numpy.random.seed", "os.exists", "partition.partition_class", "range", "len", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "os.makedirs", "os.makedirs", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "range", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "ValueError", "np.array.sum", "range", "numpy.round().astype", "numpy.array", "os.join", "numpy.random.randn", "np.round().astype.append", "print", "str", "open", "f.write", "f.write", "f.write", "numpy.round", "range", "range", "numpy.array", "len"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.partition.partition_class"], ["", "", "", "def", "partition", "(", "raw_data_dir", "=", "common", ".", "raw_data_dir", ",", "output_data_dir", "=", "osp", ".", "join", "(", "common", ".", "data_cache_dir", ",", "'debug'", ")", ",", "\n", "num_clients", "=", "100", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Partition data and save to output_data_dir\n        Each class with num_clients // NUM_CIFAR10_CLASSES clients\n        Each client is a txt file named by client index, while the content is image index array (format by f\"{arr}\")\n        The txt file can be read into a python object by eval the first line\n        client idx are sorted by their corresponding image class, e.g. 0-99 for class 0, 100-199 for class 1\n    :param output_data_dir: the directory to save the partitioned data\n    :param raw_data_dir: the directory with the raw data\n    :param num_clients: number of clients, should be multiple of 10 (CIFAR10 class number)\n    :param kwargs:\n        num_samples_base: control the degree of data imbalance, larger means imbalance lower\n        num_samples_clamp_thres: control the degree of data imbalance, trivial\n        seed: random process seed, to enforce fairness\n        dataset: cifar10 / mnist\n        num_iid: num_iid samples are taken IID from the dataset, default 0 (each class 0 / 10 images)\n    \"\"\"", "\n", "num_samples_base", "=", "kwargs", ".", "pop", "(", "\"num_samples_base\"", ",", "5", ")", "\n", "num_samples_clamp_thres", "=", "kwargs", ".", "pop", "(", "\"num_samples_clamp_thres\"", ",", "2", ")", "\n", "seed", "=", "kwargs", ".", "pop", "(", "\"seed\"", ",", "1", ")", "\n", "dataset_indicator", "=", "kwargs", ".", "pop", "(", "\"dataset\"", ",", "\"cifar10\"", ")", "\n", "num_iid", "=", "kwargs", ".", "pop", "(", "\"num_iid\"", ",", "0", ")", "\n", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "if", "len", "(", "kwargs", ")", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Unexpected parameter {kwargs}\"", ")", "\n", "", "if", "num_iid", "%", "10", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Expect num_iid to be multiple of 10, but get {num_iid}\"", ")", "\n", "\n", "# parameter check", "\n", "", "if", "num_samples_base", "<=", "num_samples_clamp_thres", ":", "\n", "        ", "raise", "ValueError", "(", "f\"num_samples_base \\\"{num_samples_base}\\\" should be larger than num_samples_clamp_thres\"", ")", "\n", "", "if", "num_clients", "%", "common", ".", "NUM_CIFAR10_CLASSES", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "f'num_clients \\\"{num_clients}\\\" should be a multiple of NUM_CIFAR10_CLASSES'", ")", "\n", "", "if", "osp", ".", "exists", "(", "output_data_dir", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f'Output data directory \\\"{output_data_dir}\\\" exists!'", ")", "\n", "", "else", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_data_dir", ")", "\n", "\n", "", "if", "dataset_indicator", "==", "'cifar10'", ":", "\n", "        ", "train_set", "=", "torchvision", ".", "datasets", ".", "CIFAR10", "(", "root", "=", "raw_data_dir", ",", "train", "=", "True", ",", "download", "=", "False", ")", "\n", "num_clients1class", "=", "num_clients", "//", "common", ".", "NUM_CIFAR10_CLASSES", "\n", "", "elif", "dataset_indicator", "==", "\"mnist\"", ":", "\n", "# note that each digit has different number of images", "\n", "        ", "train_set", "=", "torchvision", ".", "datasets", ".", "MNIST", "(", "root", "=", "raw_data_dir", ",", "train", "=", "True", ",", "download", "=", "False", ")", "\n", "num_clients1class", "=", "num_clients", "//", "common", ".", "NUM_MNIST_CLASSES", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"dataset = {dataset_indicator} is not recognized\"", ")", "\n", "\n", "", "inds", "=", "partition_class", "(", "train_set", ")", "\n", "\n", "num_iid1class", "=", "num_iid", "//", "10", "\n", "num_non_iid_start", "=", "num_iid1class", "*", "num_clients", "\n", "\n", "for", "class_", "in", "range", "(", "common", ".", "NUM_CIFAR10_CLASSES", ")", ":", "\n", "# unbalance partition", "\n", "        ", "while", "True", ":", "\n", "            ", "num_samples_list", "=", "num_samples_base", "+", "np", ".", "random", ".", "randn", "(", "num_clients1class", ")", "\n", "num_samples_list", "[", "num_samples_list", "<", "num_samples_base", "-", "num_samples_clamp_thres", "]", "=", "num_samples_base", "-", "num_samples_clamp_thres", "\n", "num_samples_list", "[", "num_samples_list", ">", "num_samples_base", "+", "num_samples_clamp_thres", "]", "=", "num_samples_base", "+", "num_samples_clamp_thres", "\n", "sum_weight", "=", "num_samples_list", ".", "sum", "(", ")", "\n", "num_samples_list", "/=", "sum_weight", "# normalize", "\n", "\n", "pre_weight", "=", "0.0", "\n", "accumulated", "=", "[", "0.0", "]", "\n", "for", "end", "in", "range", "(", "num_clients1class", ")", ":", "\n", "                ", "pre_weight", "=", "pre_weight", "+", "num_samples_list", "[", "end", "]", "\n", "accumulated", ".", "append", "(", "pre_weight", ")", "\n", "", "accumulated", "[", "-", "1", "]", "=", "1.0", "\n", "accumulated", "=", "np", ".", "round", "(", "np", ".", "array", "(", "accumulated", ")", "*", "len", "(", "inds", "[", "class_", "]", ")", ")", ".", "astype", "(", "int", ")", "\n", "\n", "num_samples_list", "=", "[", "accumulated", "[", "i", "+", "1", "]", "-", "accumulated", "[", "i", "]", "for", "i", "in", "range", "(", "num_clients1class", ")", "]", "\n", "num_samples_list", "=", "np", ".", "array", "(", "num_samples_list", ")", "\n", "if", "not", "(", "num_samples_list", "<", "num_iid", ")", ".", "sum", "(", ")", "==", "0", ":", "\n", "                ", "print", "(", "f'In class {class_}, client with less than {num_iid} data exists, retrying...'", ")", "\n", "", "else", ":", "\n", "                ", "break", "\n", "\n", "", "", "start_train", "=", "num_non_iid_start", "\n", "for", "worker_ind", "in", "range", "(", "num_clients1class", ")", ":", "\n", "            ", "worker_identifier", "=", "worker_ind", "+", "num_clients1class", "*", "class_", "\n", "worker_fp", "=", "osp", ".", "join", "(", "output_data_dir", ",", "str", "(", "worker_identifier", ")", ")", "\n", "\n", "num_train_samples", "=", "num_samples_list", "[", "worker_ind", "]", "\n", "\n", "worker_ind_global", "=", "class_", "*", "num_clients1class", "+", "worker_ind", "\n", "data_inds_iid", "=", "[", "class_inds", "[", "worker_ind_global", "*", "num_iid1class", "+", "idx", "]", "\n", "for", "class_inds", "in", "inds", "for", "idx", "in", "range", "(", "num_iid1class", ")", "]", "\n", "data_inds_non_iid", "=", "inds", "[", "class_", "]", "[", "start_train", ":", "start_train", "+", "num_train_samples", "-", "num_iid", "]", "\n", "\n", "file_content", "=", "f\"{data_inds_iid + data_inds_non_iid}\"", "\n", "with", "open", "(", "worker_fp", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "file_content", "+", "'\\n'", ")", "\n", "f", ".", "write", "(", "f\"number of training samples: {num_train_samples}\\n\"", ")", "\n", "f", ".", "write", "(", "f\"samples are from class {class_}\\n\"", ")", "\n", "\n", "", "start_train", "+=", "num_train_samples", "-", "num_iid", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.partition._test": [[150, 159], ["partition.partition", "os.join"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.partition"], ["", "", "", "def", "_test", "(", ")", ":", "\n", "# train_set2files()", "\n", "# partition(num_clients=1000, output_data_dir=osp.join(common.data_cache_dir, 'cifar10_N1000_ni0'), dataset=\"cifar10\")", "\n", "# partition(num_clients=1000, output_data_dir=osp.join(common.data_cache_dir, 'mnist_N1000_ni0'), dataset=\"mnist\")", "\n", "# partition(num_clients=1000, output_data_dir=osp.join(common.data_cache_dir, 'cifar10_N1000_ni20'), num_iid=20, dataset=\"cifar10\")", "\n", "# partition(num_clients=1000, output_data_dir=osp.join(common.data_cache_dir, 'mnist_N1000_ni20'), num_iid=20, dataset=\"mnist\")", "\n", "    ", "N", "=", "200", "\n", "ni", "=", "0", "\n", "partition", "(", "num_clients", "=", "N", ",", "output_data_dir", "=", "osp", ".", "join", "(", "common", ".", "data_cache_dir", ",", "f'mnist_N{N}_ni{ni}'", ")", ",", "num_iid", "=", "ni", ",", "dataset", "=", "\"mnist\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.data_b_to_right_device": [[15, 22], ["isinstance", "range", "data_b.to.to", "len", "data_b[].to"], "function", ["None"], ["def", "data_b_to_right_device", "(", "data_b", ")", ":", "\n", "    ", "if", "isinstance", "(", "data_b", ",", "list", ")", ":", "\n", "        ", "for", "idx", "in", "range", "(", "len", "(", "data_b", ")", ")", ":", "\n", "            ", "data_b", "[", "idx", "]", "=", "data_b", "[", "idx", "]", ".", "to", "(", "device", "=", "common", ".", "device", ")", "\n", "", "", "else", ":", "\n", "        ", "data_b", "=", "data_b", ".", "to", "(", "device", "=", "common", ".", "device", ")", "\n", "", "return", "data_b", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.get_output": [[24, 30], ["isinstance", "model", "model"], "function", ["None"], ["", "def", "get_output", "(", "model", ",", "data_b", ")", ":", "\n", "    ", "if", "isinstance", "(", "data_b", ",", "list", ")", ":", "\n", "        ", "output_b", "=", "model", "(", "*", "data_b", ")", "\n", "", "else", ":", "\n", "        ", "output_b", "=", "model", "(", "data_b", ")", "\n", "", "return", "output_b", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.get_spare_dir": [[32, 51], ["os.path.exists", "os.path.join", "os.path.join", "os.makedirs", "str", "str", "str"], "function", ["None"], ["", "def", "get_spare_dir", "(", "f_dir", ",", "c_dir", ",", "new", "=", "True", ",", "cdir", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    :param new: seek for new path\n    :param f_dir: father directory\n    :param c_dir: child directory prefix\n    :return: a created idle directory like f_dir/c_dir0\n    \"\"\"", "\n", "test_num", "=", "0", "\n", "while", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "f_dir", ",", "c_dir", "+", "str", "(", "test_num", ")", ")", ")", ":", "\n", "        ", "test_num", "+=", "1", "\n", "", "if", "not", "new", ":", "\n", "        ", "test_num", "-=", "1", "\n", "", "assert", "test_num", ">=", "0", "\n", "if", "cdir", ":", "\n", "        ", "return", "c_dir", "+", "str", "(", "test_num", ")", "\n", "", "else", ":", "\n", "        ", "idle_path", "=", "os", ".", "path", ".", "join", "(", "f_dir", ",", "c_dir", "+", "str", "(", "test_num", ")", ")", "\n", "os", ".", "makedirs", "(", "idle_path", ",", "exist_ok", "=", "True", ")", "\n", "return", "idle_path", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.init_pars": [[53, 69], ["traceback.print_exc", "print"], "function", ["None"], ["", "", "def", "init_pars", "(", "dst", ",", "src", ")", ":", "\n", "    ", "\"\"\"\n    init self.pars in __init__\n    :param dst: self.pars\n    :param src: pars delivered\n    :return: None\n    \"\"\"", "\n", "try", ":", "\n", "        ", "for", "k", "in", "src", ":", "\n", "            ", "if", "k", "not", "in", "dst", ":", "\n", "                ", "print", "(", "f\"Invalid parameter {k}\"", ")", "\n", "raise", "AssertionError", "\n", "", "dst", "[", "k", "]", "=", "src", "[", "k", "]", "\n", "", "", "except", "AssertionError", "as", "e", ":", "\n", "        ", "traceback", ".", "print_exc", "(", ")", "\n", "raise", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.test_loader": [[71, 128], ["torch.nn.CrossEntropyLoss", "copy.deepcopy", "copy.deepcopy.zero_grad", "enumerate", "copy.deepcopy.parameters", "widgets.data_b_to_right_device", "label_b.to.to", "widgets.get_output", "torch.softmax", "list", "probs.extend", "labels.extend", "criterion", "criterion.backward", "criterion.item", "len", "[].reshape", "list", "torch.no_grad", "torch.argmax", "print", "torch.norm", "sklearn.metrics.roc_auc_score", "label_b.to.detach().cpu().numpy", "print", "list.detach().cpu().numpy", "label_b.to.detach().cpu", "len", "list.detach().cpu", "label_b.to.detach", "list.detach"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.data_b_to_right_device", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.get_output"], ["", "", "def", "test_loader", "(", "net", ":", "nn", ".", "Module", ",", "loader", ",", "max_checked", "=", "-", "1", ",", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'sum'", ")", ",", "average", "=", "True", ",", "\n", "loss_", "=", "None", ",", "acc_", "=", "None", ",", "grad_norm_", "=", "None", ",", "auc_", "=", "None", ",", "verbose", "=", "False", ")", ":", "\n", "# use sum reduction for criterion please", "\n", "    ", "net", "=", "deepcopy", "(", "net", ")", "\n", "net", ".", "zero_grad", "(", ")", "\n", "\n", "num_checked", "=", "0", "\n", "num_right", "=", "0", "\n", "total_loss", "=", "0.0", "\n", "probs", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "\n", "for", "idx", ",", "(", "data_b", ",", "label_b", ")", "in", "enumerate", "(", "loader", ")", ":", "\n", "        ", "data_b", "=", "data_b_to_right_device", "(", "data_b", ")", "\n", "label_b", "=", "label_b", ".", "to", "(", "device", "=", "common", ".", "device", ")", "\n", "\n", "output_b", "=", "get_output", "(", "net", ",", "data_b", ")", "\n", "probs_", "=", "torch", ".", "softmax", "(", "output_b", ",", "dim", "=", "1", ")", "\n", "probs_", "=", "list", "(", "probs_", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", ":", ",", "1", "]", ".", "reshape", "(", "-", "1", ")", ")", "\n", "probs", ".", "extend", "(", "probs_", ")", "\n", "labels", ".", "extend", "(", "list", "(", "label_b", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "\n", "loss", "=", "criterion", "(", "output_b", ",", "label_b", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pred_b", "=", "torch", ".", "argmax", "(", "output_b", ",", "dim", "=", "1", ")", "\n", "num_right", "+=", "(", "pred_b", "==", "label_b", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "num_checked", "+=", "len", "(", "label_b", ")", "\n", "if", "max_checked", "!=", "-", "1", "and", "num_checked", ">=", "max_checked", ":", "\n", "            ", "break", "\n", "\n", "", "if", "verbose", "and", "idx", "%", "10", "==", "0", ":", "\n", "            ", "print", "(", "f\"{idx}/{len(loader)} batches tested\"", ",", "end", "=", "'\\r'", ")", "\n", "", "", "grad_norm_squ", "=", "0.0", "\n", "for", "par", "in", "net", ".", "parameters", "(", ")", ":", "\n", "        ", "grad_norm_squ", "+=", "torch", ".", "norm", "(", "par", ".", "grad", ")", "**", "2", "\n", "", "grad_norm", "=", "grad_norm_squ", "**", "0.5", "\n", "\n", "if", "average", ":", "\n", "        ", "num_right", "/=", "num_checked", "\n", "total_loss", "/=", "num_checked", "\n", "grad_norm", "/=", "num_checked", "\n", "\n", "", "if", "loss_", "is", "not", "None", ":", "\n", "        ", "loss_", "[", "0", "]", "=", "total_loss", "\n", "", "if", "acc_", "is", "not", "None", ":", "\n", "        ", "acc_", "[", "0", "]", "=", "num_right", "\n", "", "if", "grad_norm_", "is", "not", "None", ":", "\n", "        ", "grad_norm_", "[", "0", "]", "=", "grad_norm", "\n", "", "if", "auc_", "is", "not", "None", ":", "\n", "        ", "try", ":", "\n", "            ", "auc_", "[", "0", "]", "=", "sklearn", ".", "metrics", ".", "roc_auc_score", "(", "labels", ",", "probs", ")", "\n", "", "except", "ValueError", "as", "e", ":", "\n", "            ", "print", "(", "f\"probs: {probs}\"", ")", "\n", "raise", "e", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.latest_gradient_avg": [[130, 149], ["copy.deepcopy", "len", "ValueError", "len", "zip", "print", "type", "type"], "function", ["None"], ["", "", "", "def", "latest_gradient_avg", "(", "clients", ")", ":", "\n", "    ", "if", "len", "(", "clients", ")", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"no client given\"", ")", "\n", "", "lg_sum", "=", "deepcopy", "(", "clients", "[", "0", "]", ".", "latest_grad", ")", "\n", "for", "client", "in", "clients", "[", "1", ":", "]", ":", "\n", "        ", "lg", "=", "client", ".", "latest_grad", "\n", "try", ":", "\n", "            ", "lg_sum", "=", "[", "lg_", "+", "lgs_", "for", "lg_", ",", "lgs_", "in", "zip", "(", "lg", ",", "lg_sum", ")", "]", "\n", "", "except", "TypeError", "as", "e", ":", "\n", "            ", "if", "lg", "is", "None", "or", "lg_sum", "is", "None", ":", "\n", "# lg_sum remain as itself", "\n", "                ", "lg_sum", "=", "lg_sum", "\n", "", "else", ":", "\n", "                ", "print", "(", "f\"lg is {type(lg)}, lg_sum is {type(lg_sum)}\"", ")", "\n", "raise", "e", "\n", "", "", "", "if", "lg_sum", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "return", "[", "lgs", "/", "len", "(", "clients", ")", "for", "lgs", "in", "lg_sum", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.rel_and_norm_error": [[151, 170], ["t1.to", "torch.max().item", "max", "zip", "zip", "torch.abs", "zip", "torch.zeros_like", "torch.max", "torch.zeros_like", "torch.norm", "torch.abs", "torch.abs"], "function", ["None"], ["", "", "def", "rel_and_norm_error", "(", "tensor_list1", ",", "tensor_list2", ",", "eps", "=", "1e-7", ")", ":", "\n", "# tensor_list is None means that it is zero", "\n", "    ", "if", "tensor_list1", "is", "None", "and", "tensor_list2", "is", "None", ":", "\n", "        ", "return", "0.0", ",", "0.0", "\n", "", "else", ":", "\n", "        ", "if", "tensor_list1", "is", "None", ":", "\n", "            ", "tensor_list1", "=", "[", "torch", ".", "zeros_like", "(", "t", ")", "for", "t", "in", "tensor_list2", "]", "\n", "", "elif", "tensor_list2", "is", "None", ":", "\n", "            ", "tensor_list2", "=", "[", "torch", ".", "zeros_like", "(", "t", ")", "for", "t", "in", "tensor_list1", "]", "\n", "", "", "tensor_list1", "=", "[", "t1", ".", "to", "(", "device", "=", "t2", ".", "device", ")", "for", "t1", ",", "t2", "in", "zip", "(", "tensor_list1", ",", "tensor_list2", ")", "]", "\n", "diff", "=", "[", "t1", "-", "t2", "for", "t1", ",", "t2", "in", "zip", "(", "tensor_list1", ",", "tensor_list2", ")", "]", "\n", "diff_norm", "=", "0.0", "\n", "for", "diff_", "in", "diff", ":", "\n", "        ", "diff_norm", "+=", "(", "torch", ".", "norm", "(", "diff_", ")", "**", "2", ")", ".", "item", "(", ")", "\n", "", "diff_norm", "=", "diff_norm", "**", "0.5", "\n", "rel_errors", "=", "[", "torch", ".", "abs", "(", "d", ")", "/", "(", "torch", ".", "abs", "(", "t1", ")", "+", "torch", ".", "abs", "(", "t2", ")", "+", "eps", ")", "\n", "for", "d", ",", "t1", ",", "t2", "in", "zip", "(", "diff", ",", "tensor_list1", ",", "tensor_list2", ")", "]", "\n", "rel_errors", "=", "[", "torch", ".", "max", "(", "rel", ")", ".", "item", "(", ")", "for", "rel", "in", "rel_errors", "]", "\n", "return", "max", "(", "rel_errors", ")", ",", "diff_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.count_parameters": [[172, 178], ["model.parameters", "numpy.prod"], "function", ["None"], ["", "def", "count_parameters", "(", "model", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "count", "=", "0", "\n", "for", "par", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "_count", "=", "np", ".", "prod", "(", "par", ".", "shape", ")", "\n", "count", "+=", "_count", "\n", "", "return", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets._check_local_test_or_train": [[180, 205], ["open", "enumerate", "line.strip.strip", "line.strip.split", "_user_behaviors_load[].find", "print", "print", "print", "print", "input", "print"], "function", ["None"], ["", "def", "_check_local_test_or_train", "(", "fp", ",", "user_behaviors", ")", ":", "\n", "    ", "\"\"\"\n    check:\n    log time are Monotonically increasing\n    \"\"\"", "\n", "with", "open", "(", "fp", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line_idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", "'\\n'", ")", "\n", "click", ",", "uid", ",", "gid", ",", "cid", ",", "gid_his", ",", "cid_his", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "\n", "# gid_his = gid_his.split('\\x02')", "\n", "# if uid not in user_behaviors:", "\n", "#     user_behaviors[uid] = gid_his", "\n", "# if click == \"1\":", "\n", "#     user_behaviors[uid].append(gid)", "\n", "\n", "if", "_user_behaviors_load", "[", "uid", "]", ".", "find", "(", "gid_his", ")", "==", "-", "1", ":", "\n", "                ", "print", "(", "f\"line {line_idx}\"", ")", "\n", "print", "(", "f\"gid_his = {gid_his}\"", ")", "\n", "print", "(", "f\"not in\"", ")", "\n", "print", "(", "f\"user_behavior = {_user_behaviors_load[uid]}\"", ")", "\n", "input", "(", "\"continue?\"", ")", "\n", "\n", "", "if", "line_idx", "%", "1000000", "==", "0", ":", "\n", "                ", "print", "(", "line_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.plot_time2available_data_ratio": [[218, 245], ["enumerate", "range", "plt.figure", "plt.plot", "plt.plot", "plt.savefig", "plt.close", "plt.figure", "plt.plot", "plt.savefig", "len", "datetime.timedelta", "enumerate", "range", "range", "osp.join", "range", "osp.join", "range", "range", "client.is_available", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close"], ["", "", "def", "plot_time2available_data_ratio", "(", "clients", ",", "fn_abs", "=", "\"time2available_data_abs.png\"", ",", "fn_ratio", "=", "\"time2available_data_ratio.png\"", ")", ":", "\n", "    ", "from", "matplotlib", "import", "pyplot", "as", "plt", "\n", "import", "os", ".", "path", "as", "osp", "\n", "posi_counts", "=", "[", "0", "for", "hour", "in", "range", "(", "24", ")", "]", "\n", "total_counts", "=", "[", "0", "for", "hour", "in", "range", "(", "24", ")", "]", "\n", "client_sample_count", "=", "[", "0", "for", "client", "in", "clients", "]", "\n", "client_posi_count", "=", "[", "0", "for", "client", "in", "clients", "]", "\n", "for", "idx", ",", "client", "in", "enumerate", "(", "clients", ")", ":", "\n", "        ", "client_sample_count", "[", "idx", "]", "=", "len", "(", "client", ".", "dataset", ")", "\n", "for", "uid", ",", "gid", ",", "cid", ",", "gid_his", ",", "cid_his", ",", "click", "in", "client", ".", "dataset", ":", "\n", "            ", "if", "click", "==", "1", ":", "\n", "                ", "client_posi_count", "[", "idx", "]", "+=", "1", "\n", "", "", "", "for", "hour", "in", "range", "(", "24", ")", ":", "\n", "        ", "time_", "=", "datetime", ".", "timedelta", "(", "hours", "=", "hour", ")", "\n", "avai_count", "=", "0", "\n", "for", "idx", ",", "client", "in", "enumerate", "(", "clients", ")", ":", "\n", "            ", "if", "client", ".", "is_available", "(", "time_", ")", ":", "\n", "                ", "posi_counts", "[", "hour", "]", "+=", "client_posi_count", "[", "idx", "]", "\n", "total_counts", "[", "hour", "]", "+=", "client_sample_count", "[", "idx", "]", "\n", "", "", "", "plt", ".", "figure", "(", "0", ")", "\n", "plt", ".", "plot", "(", "range", "(", "24", ")", ",", "posi_counts", ")", "\n", "plt", ".", "plot", "(", "range", "(", "24", ")", ",", "total_counts", ")", "\n", "plt", ".", "savefig", "(", "osp", ".", "join", "(", "common", ".", "figure_fd", ",", "fn_abs", ")", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "plt", ".", "figure", "(", "0", ")", "\n", "plt", ".", "plot", "(", "range", "(", "24", ")", ",", "np", ".", "array", "(", "posi_counts", ")", "/", "np", ".", "array", "(", "total_counts", ")", ")", "\n", "plt", ".", "savefig", "(", "osp", ".", "join", "(", "common", ".", "figure_fd", ",", "fn_ratio", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.__init__": [[33, 122], ["torch.utils.data.Dataset.__init__", "os.join", "os.join", "os.exists", "print", "os.exists", "pickle.load", "print", "pickle.dump", "pickle.load", "print", "preprocess", "pickle.dump", "print", "os.join", "os.exists", "open", "open", "enumerate", "open", "open", "open", "pickle.load", "print", "os.join", "dict", "os.join", "gensim.models.KeyedVectors.load_word2vec_format", "pickle.dump", "print", "os.join", "f.readlines", "line.split", "pickle.load.append", "embedding_fn.split", "open", "embedding_fn.split", "pickle.load", "print", "tweet.split", "open", "iter().__next__", "f.write", "dict.items", "open", "open", "gensim.models.KeyedVectors.load_word2vec_format", "os.join", "pickle.dump", "print", "ValueError", "f.write", "len", "len", "embedding_fn.split", "os.join", "gensim.scripts.glove2word2vec.glove2word2vec", "print", "open", "iter", "len", "len", "str", "dict.items", "embedding_fn.split", "embedding_fn.split"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["def", "__init__", "(", "self", ",", "preprocess", ",", "embedding_fn", "=", "None", ",", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "transform", "==", "'glove_trans'", ":", "\n", "            ", "self", ".", "transform", "=", "self", ".", "glove_trans", "\n", "", "else", ":", "\n", "            ", "self", ".", "transform", "=", "transform", "\n", "\n", "", "dataset_id", "=", "preprocess", ".", "id", "\n", "\n", "# process pars", "\n", "# get cache fp", "\n", "cache_fn", "=", "dataset_id", "+", "'.pkl'", "\n", "self", ".", "cache_fp", "=", "osp", ".", "join", "(", "common", ".", "data_cache_dir", ",", "cache_fn", ")", "\n", "\n", "# load and process data", "\n", "raw_data_dump_fp", "=", "osp", ".", "join", "(", "common", ".", "sentiment140_fd", ",", "common", ".", "sentiment140_pyobj_fn", ")", "\n", "if", "osp", ".", "exists", "(", "raw_data_dump_fp", ")", ":", "\n", "            ", "raw_data", "=", "pickle", ".", "load", "(", "open", "(", "raw_data_dump_fp", ",", "'rb'", ")", ")", "\n", "print", "(", "f\"raw data loaded from {raw_data_dump_fp}\"", ")", "\n", "", "else", ":", "\n", "            ", "raw_data", "=", "[", "]", "\n", "with", "open", "(", "osp", ".", "join", "(", "common", ".", "sentiment140_fd", ",", "common", ".", "sentiment140_fn", ")", ",", "'r'", ",", "encoding", "=", "'latin1'", ")", "as", "f", ":", "\n", "                ", "for", "line_idx", ",", "line", "in", "enumerate", "(", "f", ".", "readlines", "(", ")", ")", ":", "\n", "                    ", "tup", "=", "line", ".", "split", "(", "'\",\"'", ")", "\n", "# remove \"\"", "\n", "tup", "[", "0", "]", "=", "tup", "[", "0", "]", "[", "1", ":", "]", "\n", "tup", "[", "-", "1", "]", "=", "tup", "[", "-", "1", "]", "[", ":", "-", "1", "]", "\n", "raw_data", ".", "append", "(", "tup", ")", "\n", "if", "line_idx", ">", "0", ":", "\n", "                        ", "assert", "len", "(", "raw_data", "[", "-", "1", "]", ")", "==", "len", "(", "raw_data", "[", "-", "2", "]", ")", "\n", "", "", "", "pickle", ".", "dump", "(", "raw_data", ",", "open", "(", "raw_data_dump_fp", ",", "'wb'", ")", ")", "\n", "", "self", ".", "raw_data", "=", "raw_data", "\n", "\n", "print", "(", "f\"processed data cached file path: \\\"{self.cache_fp}\\\"\"", ")", "\n", "if", "osp", ".", "exists", "(", "self", ".", "cache_fp", ")", ":", "\n", "            ", "self", ".", "processed_data", "=", "pickle", ".", "load", "(", "open", "(", "self", ".", "cache_fp", ",", "'rb'", ")", ")", "\n", "print", "(", "f\"processed data loaded from {self.cache_fp}\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "processed_data", "=", "preprocess", "(", "self", ".", "raw_data", ")", "\n", "pickle", ".", "dump", "(", "self", ".", "processed_data", ",", "open", "(", "self", ".", "cache_fp", ",", "'wb'", ")", ")", "\n", "print", "(", "f\"processed data dumped into {self.cache_fp}\"", ")", "\n", "\n", "", "if", "embedding_fn", "is", "not", "None", ":", "\n", "            ", "if", "embedding_fn", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", "not", "in", "(", "'pkl'", ",", "'txt'", ")", ":", "\n", "                ", "embedding_fn", "+=", "'.pkl'", "\n", "", "needed_glove_fn", "=", "'sentiment140_'", "+", "'.'", ".", "join", "(", "embedding_fn", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", "+", "'.pkl'", "\n", "needed_glove_fp", "=", "osp", ".", "join", "(", "common", ".", "cache_fd", ",", "needed_glove_fn", ")", "\n", "if", "osp", ".", "exists", "(", "needed_glove_fp", ")", ":", "\n", "                ", "self", ".", "glove_model", "=", "pickle", ".", "load", "(", "open", "(", "needed_glove_fp", ",", "'rb'", ")", ")", "\n", "print", "(", "f\"needed glove model loaded from {needed_glove_fp}\"", ")", "\n", "", "else", ":", "\n", "                ", "embedding_fp", "=", "osp", ".", "join", "(", "common", ".", "nlp_embedding_fd", ",", "embedding_fn", ")", "\n", "embedding_ext", "=", "embedding_fn", ".", "split", "(", "'.'", ")", "[", "-", "2", ":", "]", "\n", "if", "embedding_ext", "[", "-", "1", "]", "==", "'pkl'", ":", "\n", "                    ", "glove_model", "=", "pickle", ".", "load", "(", "open", "(", "embedding_fp", ",", "'rb'", ")", ")", "\n", "print", "(", "f\"whole glove model loaded from {embedding_fp}\"", ")", "\n", "", "elif", "embedding_ext", "[", "-", "1", "]", "==", "'txt'", ":", "\n", "                    ", "if", "embedding_ext", "[", "0", "]", "!=", "'word2vec'", ":", "\n", "                        ", "new_embedding_fn", "=", "'.'", ".", "join", "(", "embedding_fn", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", "+", "'.word2vec.txt'", "\n", "new_embedding_fp", "=", "osp", ".", "join", "(", "common", ".", "nlp_embedding_fd", ",", "new_embedding_fn", ")", "\n", "glove2word2vec", "(", "embedding_fp", ",", "new_embedding_fp", ")", "\n", "embedding_fp", "=", "new_embedding_fp", "\n", "print", "(", "\"glove format to word2vec done\"", ")", "\n", "", "glove_model", "=", "KeyedVectors", ".", "load_word2vec_format", "(", "embedding_fp", ",", "binary", "=", "False", ")", "\n", "pkl_fn", "=", "'.'", ".", "join", "(", "embedding_fn", ".", "split", "(", "'.'", ")", "[", ":", "-", "1", "]", ")", "+", "'.pkl'", "\n", "pkl_fp", "=", "osp", ".", "join", "(", "common", ".", "nlp_embedding_fd", ",", "pkl_fn", ")", "\n", "pickle", ".", "dump", "(", "glove_model", ",", "open", "(", "pkl_fp", ",", "'wb'", ")", ")", "\n", "print", "(", "f\"glove model dumped into {pkl_fp}\"", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"unrecognized embedding file {embedding_fp}\"", ")", "\n", "", "needed_glove_model", "=", "dict", "(", ")", "\n", "for", "data_tup", "in", "self", ".", "processed_data", ":", "\n", "                    ", "tweet", "=", "data_tup", "[", "Sentiment140Dataset", ".", "TWEET", "]", "\n", "for", "word", "in", "tweet", ".", "split", "(", ")", ":", "\n", "                        ", "if", "word", "in", "glove_model", ":", "\n", "                            ", "needed_glove_model", "[", "word", "]", "=", "glove_model", "[", "word", "]", "\n", "", "", "", "intermediate_fp", "=", "osp", ".", "join", "(", "common", ".", "cache_fd", ",", "needed_glove_fn", "+", "'.tmp.txt'", ")", "\n", "with", "open", "(", "intermediate_fp", ",", "'w'", ")", "as", "f", ":", "\n", "                    ", "_w", ",", "_v", "=", "iter", "(", "needed_glove_model", ".", "items", "(", ")", ")", ".", "__next__", "(", ")", "\n", "f", ".", "write", "(", "\"{0} {1}\\n\"", ".", "format", "(", "len", "(", "needed_glove_model", ")", ",", "len", "(", "_v", ")", ")", ")", "\n", "for", "word", ",", "vec", "in", "needed_glove_model", ".", "items", "(", ")", ":", "\n", "                        ", "vec", "=", "[", "str", "(", "ele", ")", "for", "ele", "in", "vec", "]", "\n", "vec", "=", "' '", ".", "join", "(", "[", "word", "]", "+", "vec", ")", "\n", "f", ".", "write", "(", "vec", "+", "'\\n'", ")", "\n", "", "", "self", ".", "glove_model", "=", "KeyedVectors", ".", "load_word2vec_format", "(", "intermediate_fp", ",", "binary", "=", "False", ")", "\n", "pickle", ".", "dump", "(", "self", ".", "glove_model", ",", "open", "(", "needed_glove_fp", ",", "'wb'", ")", ")", "\n", "print", "(", "f\"needed glove model dumped into {needed_glove_fp}\"", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "glove_model", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.statistic_words": [[123, 156], ["enumerate", "list", "sorted", "enumerate", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "tweet.split", "sorted.items", "plot_data_abs.append", "plot_data_accumulate.append", "list", "os.join", "list", "os.join", "print", "print", "range", "range", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close"], ["", "", "def", "statistic_words", "(", "self", ",", "verbose", "=", "True", ",", "num_print", "=", "1024", ")", ":", "\n", "        ", "words2num", "=", "{", "}", "\n", "summ", "=", "0", "\n", "for", "idx", ",", "data_tup", "in", "enumerate", "(", "self", ".", "processed_data", ")", ":", "\n", "            ", "if", "verbose", "and", "idx", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "f\"{idx}/{len(self.processed_data)}\"", ",", "end", "=", "'\\r'", ")", "\n", "", "tweet", "=", "data_tup", "[", "Sentiment140Dataset", ".", "TWEET", "]", "\n", "words", "=", "tweet", ".", "split", "(", ")", "\n", "for", "word", "in", "words", ":", "\n", "                ", "if", "word", "in", "words2num", ":", "\n", "                    ", "words2num", "[", "word", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "words2num", "[", "word", "]", "=", "1", "\n", "", "summ", "+=", "1", "\n", "", "", "words2num", "=", "list", "(", "words2num", ".", "items", "(", ")", ")", "\n", "words2num", "=", "sorted", "(", "words2num", ",", "key", "=", "lambda", "pair", ":", "-", "pair", "[", "1", "]", ")", "\n", "plot_data_abs", "=", "[", "]", "\n", "plot_data_accumulate", "=", "[", "]", "\n", "accumulate", "=", "0", "\n", "for", "idx", ",", "(", "word", ",", "count", ")", "in", "enumerate", "(", "words2num", ")", ":", "\n", "            ", "plot_data_abs", ".", "append", "(", "count", ")", "\n", "accumulate", "+=", "count", "\n", "plot_data_accumulate", ".", "append", "(", "accumulate", ")", "\n", "if", "verbose", "and", "idx", ">=", "len", "(", "words2num", ")", "-", "num_print", ":", "\n", "                ", "print", "(", "f\"{word}: {count}, total: {accumulate}/{summ}\"", ")", "\n", "", "", "plt", ".", "figure", "(", "0", ")", "\n", "plt", ".", "plot", "(", "list", "(", "range", "(", "len", "(", "words2num", ")", ")", ")", ",", "plot_data_abs", ")", "\n", "plt", ".", "savefig", "(", "osp", ".", "join", "(", "common", ".", "figure_fd", ",", "\"words_distribution.png\"", ")", ")", "\n", "plt", ".", "close", "(", "0", ")", "\n", "plt", ".", "figure", "(", "1", ")", "\n", "plt", ".", "plot", "(", "list", "(", "range", "(", "len", "(", "words2num", ")", ")", ")", ",", "plot_data_accumulate", ")", "\n", "plt", ".", "savefig", "(", "osp", ".", "join", "(", "common", ".", "figure_fd", ",", "\"words_pdf.png\"", ")", ")", "\n", "plt", ".", "close", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.__len__": [[157, 159], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "processed_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.__getitem__": [[160, 167], ["sentiment140.Sentiment140Dataset.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "tup", "=", "self", ".", "processed_data", "[", "item", "]", "\n", "tweet", "=", "tup", "[", "Sentiment140Dataset", ".", "TWEET", "]", "\n", "label", "=", "tup", "[", "Sentiment140Dataset", ".", "SENTIMENT", "]", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "tweet", "=", "self", ".", "transform", "(", "tweet", ")", "\n", "", "return", "tweet", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.count_clients": [[168, 173], ["set", "len", "set.add"], "methods", ["None"], ["", "def", "count_clients", "(", "self", ")", ":", "\n", "        ", "client_set", "=", "set", "(", ")", "\n", "for", "data_tup", "in", "self", ".", "processed_data", ":", "\n", "            ", "client_set", ".", "add", "(", "data_tup", "[", "Sentiment140Dataset", ".", "CLIENT_ID", "]", ")", "\n", "", "return", "len", "(", "client_set", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.count_words": [[174, 182], ["set", "enumerate", "len", "tweet.split", "set.add"], "methods", ["None"], ["", "def", "count_words", "(", "self", ")", ":", "\n", "        ", "words_set", "=", "set", "(", ")", "\n", "for", "idx", ",", "data_tup", "in", "enumerate", "(", "self", ".", "processed_data", ")", ":", "\n", "            ", "tweet", "=", "data_tup", "[", "Sentiment140Dataset", ".", "TWEET", "]", "\n", "words", "=", "tweet", ".", "split", "(", ")", "\n", "for", "word", "in", "words", ":", "\n", "                ", "words_set", ".", "add", "(", "word", ")", "\n", "", "", "return", "len", "(", "words_set", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.count_chars": [[183, 193], ["set", "len", "set.add"], "methods", ["None"], ["", "def", "count_chars", "(", "self", ")", ":", "\n", "        ", "ch_set", "=", "set", "(", ")", "\n", "\n", "for", "data_tup", "in", "self", ".", "processed_data", ":", "\n", "            ", "tweet", "=", "data_tup", "[", "Sentiment140Dataset", ".", "TWEET", "]", "\n", "for", "ch", "in", "tweet", ":", "\n", "                ", "if", "ch", "not", "in", "ch_set", ":", "\n", "# print(ch)", "\n", "                    ", "ch_set", ".", "add", "(", "ch", ")", "\n", "", "", "", "return", "len", "(", "ch_set", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.partition": [[194, 227], ["random.seed", "len", "int", "random.sample", "copy.deepcopy", "copy.deepcopy", "enumerate", "list", "range", "copy.deepcopy.raw_data.append", "copy.deepcopy.processed_data.append", "copy.deepcopy.raw_data.append", "copy.deepcopy.processed_data.append"], "methods", ["None"], ["", "def", "partition", "(", "self", ",", "test_ratio", "=", "0.1", ",", "seed", "=", "common", ".", "seed_for_train_test_partition", ")", ":", "\n", "# share glove_model", "\n", "        ", "random", ".", "seed", "(", "seed", ")", "\n", "num_total", "=", "len", "(", "self", ".", "processed_data", ")", "\n", "num_test", "=", "int", "(", "num_total", "*", "test_ratio", ")", "\n", "test_indices", "=", "random", ".", "sample", "(", "list", "(", "range", "(", "num_total", ")", ")", ",", "num_test", ")", "\n", "test_indicators", "=", "[", "False", "]", "*", "num_total", "\n", "for", "idx", "in", "test_indices", ":", "\n", "            ", "test_indicators", "[", "idx", "]", "=", "True", "\n", "\n", "", "raw_data", "=", "self", ".", "raw_data", "\n", "processed_data", "=", "self", ".", "processed_data", "\n", "glove_model", "=", "self", ".", "glove_model", "\n", "self", ".", "raw_data", "=", "[", "]", "\n", "self", ".", "processed_data", "=", "[", "]", "\n", "self", ".", "glove_model", "=", "None", "\n", "testset", "=", "copy", ".", "deepcopy", "(", "self", ")", "\n", "trainset", "=", "copy", ".", "deepcopy", "(", "self", ")", "\n", "self", ".", "glove_model", "=", "glove_model", "\n", "trainset", ".", "glove_model", "=", "glove_model", "\n", "testset", ".", "glove_model", "=", "glove_model", "\n", "\n", "for", "idx", ",", "is_test", "in", "enumerate", "(", "test_indicators", ")", ":", "\n", "            ", "if", "is_test", ":", "\n", "                ", "testset", ".", "raw_data", ".", "append", "(", "raw_data", "[", "idx", "]", ")", "\n", "testset", ".", "processed_data", ".", "append", "(", "processed_data", "[", "idx", "]", ")", "\n", "", "else", ":", "\n", "                ", "trainset", ".", "raw_data", ".", "append", "(", "raw_data", "[", "idx", "]", ")", "\n", "trainset", ".", "processed_data", ".", "append", "(", "processed_data", "[", "idx", "]", ")", "\n", "\n", "", "", "self", ".", "raw_data", "=", "raw_data", "\n", "self", ".", "processed_data", "=", "processed_data", "\n", "return", "trainset", ",", "testset", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.filter_clients_": [[228, 236], ["sentiment140.Sentiment140Dataset.get_clients", "len", "indices.extend"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.get_clients"], ["", "def", "filter_clients_", "(", "self", ",", "threshold", ",", "up", "=", "2", "**", "32", ")", ":", "\n", "        ", "clients", "=", "self", ".", "get_clients", "(", "train_batch_size", "=", "1", ")", "\n", "indices", "=", "[", "]", "\n", "for", "client", "in", "clients", ":", "\n", "            ", "if", "up", ">=", "len", "(", "client", ".", "train_indices", ")", ">", "threshold", ":", "\n", "                ", "indices", ".", "extend", "(", "client", ".", "train_indices", ")", "\n", "", "", "self", ".", "raw_data", "=", "[", "self", ".", "raw_data", "[", "idx", "]", "for", "idx", "in", "indices", "]", "\n", "self", ".", "processed_data", "=", "[", "self", ".", "processed_data", "[", "idx", "]", "for", "idx", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.random_select_clients_": [[237, 246], ["random.seed", "sentiment140.Sentiment140Dataset.get_clients", "random.sample", "indices.extend"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.get_clients"], ["", "def", "random_select_clients_", "(", "self", ",", "N", ",", "seed", "=", "common", ".", "seed_for_client_sampling", ")", ":", "\n", "        ", "random", ".", "seed", "(", "seed", ")", "\n", "clients", "=", "self", ".", "get_clients", "(", "train_batch_size", "=", "1", ")", "\n", "use_clients", "=", "random", ".", "sample", "(", "clients", ",", "N", ")", "\n", "indices", "=", "[", "]", "\n", "for", "client", "in", "use_clients", ":", "\n", "            ", "indices", ".", "extend", "(", "client", ".", "train_indices", ")", "\n", "", "self", ".", "raw_data", "=", "[", "self", ".", "raw_data", "[", "idx", "]", "for", "idx", "in", "indices", "]", "\n", "self", ".", "processed_data", "=", "[", "self", ".", "processed_data", "[", "idx", "]", "for", "idx", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.get_clients": [[247, 309], ["kwargs.pop", "kwargs.pop", "enumerate", "ValueError", "clients[].append", "clients.append", "clients_available_data[].add", "train.client.Client", "ValueError", "clients_available_data.append", "sentiment140.time2int", "clients_available_data[].append", "ValueError", "enumerate", "train.client.Client", "set", "clients_available_data.append", "ValueError", "zip", "enumerate", "sentiment140.infer_sleep", "zip"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.time2int", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.infer_sleep"], ["", "def", "get_clients", "(", "self", ",", "collate_fn", "=", "None", ",", "strategy", "=", "\"blocked\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        :param strategy: chosen from (blocked, modeled_mid)\n            blocked: when data available in some block, always available in this block\n            modeled_mid: get the middle time of all tweets, num_hours_busy hours around this time are unavailable\n        :param collate_fn: passed to client.dataloader\n        :param kwargs: customized parameters for each strategy\n        :return: clients\n        \"\"\"", "\n", "if", "strategy", "not", "in", "(", "\"blocked\"", ",", "\"modeled_mid\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f\"strategy={strategy} not recognized\"", ")", "\n", "", "if", "collate_fn", "is", "None", ":", "\n", "            ", "collate_fn", "=", "Sentiment140Dataset", ".", "collate_fn", "\n", "", "num_hours1block", "=", "kwargs", ".", "pop", "(", "\"num_hours1block\"", ",", "1", ")", "\n", "num_hours_busy", "=", "kwargs", ".", "pop", "(", "\"num_hours_busy\"", ",", "16", ")", "\n", "\n", "client2id", "=", "{", "}", "\n", "clients", "=", "[", "]", "# index: id from 0, content: data indices", "\n", "clients_available_data", "=", "[", "]", "\n", "\n", "current_id", "=", "0", "\n", "for", "idx", ",", "data_tup", "in", "enumerate", "(", "self", ".", "processed_data", ")", ":", "\n", "            ", "client_name", "=", "data_tup", "[", "Sentiment140Dataset", ".", "CLIENT_ID", "]", "\n", "if", "client_name", "in", "client2id", ":", "\n", "                ", "client_id", "=", "client2id", "[", "client_name", "]", "\n", "", "else", ":", "\n", "                ", "client2id", "[", "client_name", "]", "=", "current_id", "\n", "client_id", "=", "current_id", "\n", "clients", ".", "append", "(", "[", "]", ")", "\n", "if", "strategy", "==", "\"blocked\"", ":", "\n", "                    ", "clients_available_data", ".", "append", "(", "set", "(", ")", ")", "\n", "", "elif", "strategy", "==", "\"modeled_mid\"", ":", "\n", "                    ", "clients_available_data", ".", "append", "(", "[", "]", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"strategy={strategy} not recognized\"", ")", "\n", "", "current_id", "+=", "1", "\n", "", "clients", "[", "client_id", "]", ".", "append", "(", "idx", ")", "\n", "if", "strategy", "==", "\"blocked\"", ":", "\n", "                ", "tweet_hour", "=", "data_tup", "[", "Sentiment140Dataset", ".", "DATETIME", "]", ".", "hour", "\n", "tweet_block", "=", "tweet_hour", "//", "num_hours1block", "\n", "clients_available_data", "[", "client_id", "]", ".", "add", "(", "tweet_block", ")", "\n", "", "elif", "strategy", "==", "\"modeled_mid\"", ":", "\n", "                ", "tweet_time", "=", "data_tup", "[", "Sentiment140Dataset", ".", "DATETIME", "]", "\n", "tweet_time_int", "=", "time2int", "(", "tweet_time", ")", "\n", "clients_available_data", "[", "client_id", "]", ".", "append", "(", "tweet_time_int", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"strategy={strategy} not recognized\"", ")", "\n", "\n", "", "", "if", "strategy", "==", "\"blocked\"", ":", "\n", "            ", "clients", "=", "[", "Client", "(", "self", ",", "indices", ",", "(", "\"check_time\"", ",", "a_blocks", ",", "num_hours1block", ")", ",", "\n", "id", "=", "client_id", ",", "collate_fn", "=", "collate_fn", ",", "**", "kwargs", ")", "\n", "for", "client_id", ",", "(", "indices", ",", "a_blocks", ")", "in", "enumerate", "(", "zip", "(", "clients", ",", "clients_available_data", ")", ")", "]", "\n", "", "elif", "strategy", "==", "\"modeled_mid\"", ":", "\n", "            ", "num_seconds_day", "=", "24", "*", "3600", "\n", "num_seconds_sleep", "=", "num_seconds_day", "-", "num_hours_busy", "*", "3600", "\n", "clients", "=", "[", "Client", "(", "self", ",", "indices", ",", "\n", "(", "\"check_in_range\"", ",", "infer_sleep", "(", "tweets_time", ",", "num_seconds_day", "=", "num_seconds_day", ",", "num_seconds_sleep", "=", "num_seconds_sleep", ")", ")", ",", "\n", "id", "=", "client_id", ",", "collate_fn", "=", "collate_fn", ",", "**", "kwargs", ")", "\n", "for", "client_id", ",", "(", "indices", ",", "tweets_time", ")", "in", "enumerate", "(", "zip", "(", "clients", ",", "clients_available_data", ")", ")", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"strategy={strategy} not recognized\"", ")", "\n", "", "return", "clients", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.glove_trans": [[310, 319], ["tweet.split", "numpy.stack", "word_vecs.append", "word_vecs.append", "numpy.zeros"], "methods", ["None"], ["", "def", "glove_trans", "(", "self", ",", "tweet", ")", ":", "\n", "        ", "words", "=", "tweet", ".", "split", "(", ")", "\n", "word_vecs", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "try", ":", "\n", "                ", "word_vecs", ".", "append", "(", "self", ".", "glove_model", "[", "word", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "                ", "word_vecs", ".", "append", "(", "np", ".", "zeros", "(", "self", ".", "glove_model", ".", "vector_size", ",", "dtype", "=", "self", ".", "glove_model", ".", "vectors", ".", "dtype", ")", ")", "\n", "", "", "return", "np", ".", "stack", "(", "word_vecs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.count_in_gloves": [[320, 335], ["set", "enumerate", "print", "tweet.split", "set.add", "len"], "methods", ["None"], ["", "def", "count_in_gloves", "(", "self", ")", ":", "\n", "        ", "words_set", "=", "set", "(", ")", "\n", "num_in", "=", "0", "\n", "for", "idx", ",", "data_tup", "in", "enumerate", "(", "self", ".", "processed_data", ")", ":", "\n", "            ", "tweet", "=", "data_tup", "[", "Sentiment140Dataset", ".", "TWEET", "]", "\n", "words", "=", "tweet", ".", "split", "(", ")", "\n", "for", "word", "in", "words", ":", "\n", "                ", "if", "word", "not", "in", "words_set", ":", "\n", "                    ", "words_set", ".", "add", "(", "word", ")", "\n", "if", "word", "in", "self", ".", "glove_model", ":", "\n", "                        ", "num_in", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "pass", "\n", "# print(word)", "\n", "", "", "", "", "print", "(", "f\"{num_in}/{len(words_set)} words in glove_model\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.time_variation_": [[336, 379], ["random.seed", "enumerate", "enumerate", "ValueError", "[].append", "len", "len", "len", "math.floor", "random.sample", "indices.extend", "indices.extend", "range"], "methods", ["None"], ["", "def", "time_variation_", "(", "self", ",", "num_blocks", "=", "6", ",", "max_prop", "=", "1.0", ",", "min_prop", "=", "0.0", ",", "seed", "=", "common", ".", "seed_for_drop", ")", ":", "\n", "        ", "\"\"\"\n        drop samples to enforce distribution variation with time\n        max_prop, min_prop: maximum or minimum proportion of positive sentiment\n        \"\"\"", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "if", "24", "%", "num_blocks", "!=", "0", "or", "num_blocks", "%", "2", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "f\"num_blocks={num_blocks} should be a even number that can divide 24\"", ")", "\n", "", "num_hours1block", "=", "24", "//", "num_blocks", "\n", "# partition data by time", "\n", "blocks_indices", "=", "[", "[", "[", "]", ",", "[", "]", "]", "for", "_", "in", "range", "(", "num_blocks", ")", "]", "\n", "for", "data_idx", ",", "data_tup", "in", "enumerate", "(", "self", ".", "processed_data", ")", ":", "\n", "            ", "block_idx", "=", "data_tup", "[", "Sentiment140Dataset", ".", "DATETIME", "]", ".", "hour", "//", "num_hours1block", "\n", "sentiment", "=", "data_tup", "[", "Sentiment140Dataset", ".", "SENTIMENT", "]", "\n", "# noinspection PyTypeChecker", "\n", "blocks_indices", "[", "block_idx", "]", "[", "sentiment", "]", ".", "append", "(", "data_idx", ")", "\n", "# drop data", "\n", "", "indices", "=", "[", "]", "\n", "for", "block_idx", ",", "block_indices", "in", "enumerate", "(", "blocks_indices", ")", ":", "\n", "            ", "num_posi", "=", "len", "(", "block_indices", "[", "1", "]", ")", "\n", "num_nega", "=", "len", "(", "block_indices", "[", "0", "]", ")", "\n", "num_total", "=", "num_posi", "+", "num_nega", "\n", "num_blocks_mid", "=", "num_blocks", "//", "2", "\n", "block_idx_mid", "=", "block_idx", "if", "block_idx", "<=", "num_blocks_mid", "else", "num_blocks", "-", "block_idx", "\n", "target_posi_ratio", "=", "(", "max_prop", "-", "min_prop", ")", "*", "(", "block_idx_mid", "/", "num_blocks_mid", ")", "+", "min_prop", "\n", "posi_ratio", "=", "num_posi", "/", "num_total", "\n", "# 1 for drop posi; 0 for drop nega", "\n", "if", "posi_ratio", ">", "target_posi_ratio", ":", "\n", "                ", "drop_group", "=", "1", "\n", "drop_remain_ratio", "=", "target_posi_ratio", "/", "(", "1", "-", "target_posi_ratio", ")", "\n", "", "else", ":", "\n", "                ", "drop_group", "=", "0", "\n", "drop_remain_ratio", "=", "(", "1", "-", "target_posi_ratio", ")", "/", "target_posi_ratio", "\n", "", "remain_group", "=", "1", "-", "drop_group", "\n", "num_remain_group", "=", "len", "(", "block_indices", "[", "remain_group", "]", ")", "\n", "num_drop_remain", "=", "math", ".", "floor", "(", "num_remain_group", "*", "drop_remain_ratio", ")", "\n", "block_indices", "[", "drop_group", "]", "=", "random", ".", "sample", "(", "block_indices", "[", "drop_group", "]", ",", "num_drop_remain", ")", "\n", "indices", ".", "extend", "(", "block_indices", "[", "0", "]", ")", "\n", "indices", ".", "extend", "(", "block_indices", "[", "1", "]", ")", "\n", "\n", "# filter data", "\n", "", "self", ".", "raw_data", "=", "[", "self", ".", "raw_data", "[", "idx", "]", "for", "idx", "in", "indices", "]", "\n", "self", ".", "processed_data", "=", "[", "self", ".", "processed_data", "[", "idx", "]", "for", "idx", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.collate_fn": [[380, 391], ["tuple", "torch.nn.utils.rnn.pack_sequence", "zip", "len", "numpy.argsort", "numpy.array", "numpy.array", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "collate_fn", "(", "batch", ")", ":", "\n", "        ", "tweets", ",", "labels", "=", "tuple", "(", "zip", "(", "*", "batch", ")", ")", "\n", "seq_lens", "=", "[", "len", "(", "tweet", ")", "for", "tweet", "in", "tweets", "]", "\n", "order", "=", "np", ".", "argsort", "(", "seq_lens", ")", "[", ":", ":", "-", "1", "]", "\n", "# TODO(islander): variant length", "\n", "tweets", "=", "np", ".", "array", "(", "tweets", ")", "[", "order", "]", "\n", "labels", "=", "np", ".", "array", "(", "labels", ")", "[", "order", "]", "\n", "tweets", "=", "[", "torch", ".", "from_numpy", "(", "tweet", ")", "for", "tweet", "in", "tweets", "]", "\n", "tweets", "=", "pack_sequence", "(", "tweets", ")", "\n", "return", "tweets", ",", "torch", ".", "from_numpy", "(", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.BasicProcess.__init__": [[446, 449], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "id", "=", "'base'", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.BasicProcess.__call__": [[450, 476], ["dict", "enumerate", "datetime.datetime.split", "int", "int", "datetime.datetime", "int", "RuntimeError", "time_.split"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "raw_data", ")", ":", "\n", "        ", "client_idmap", "=", "{", "}", "\n", "c_client_id", "=", "0", "\n", "month_map", "=", "dict", "(", "Jan", "=", "1", ",", "Feb", "=", "2", ",", "Mar", "=", "3", ",", "Apr", "=", "4", ",", "May", "=", "5", ",", "Jun", "=", "6", ",", "Jul", "=", "7", ",", "Aug", "=", "8", ",", "Sep", "=", "9", ",", "Oct", "=", "10", ",", "Nov", "=", "11", ",", "Dec", "=", "12", ")", "\n", "for", "idx", ",", "(", "sentiment", ",", "tweet_id", ",", "dtime", ",", "query", ",", "client_id", ",", "tweet", ")", "in", "enumerate", "(", "raw_data", ")", ":", "\n", "            ", "if", "sentiment", "==", "'4'", ":", "\n", "                ", "sentiment", "=", "1", "\n", "", "elif", "sentiment", "==", "'0'", ":", "\n", "                ", "sentiment", "=", "0", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"sentiment not 0 / 4\"", ")", "\n", "\n", "", "weekday", ",", "month", ",", "day", ",", "time_", ",", "_", ",", "year", "=", "dtime", ".", "split", "(", ")", "\n", "month", "=", "month_map", "[", "month", "]", "\n", "day", "=", "int", "(", "day", ")", "\n", "hour", ",", "minute", ",", "second", "=", "[", "int", "(", "x", ")", "for", "x", "in", "time_", ".", "split", "(", "':'", ")", "]", "\n", "year", "=", "int", "(", "year", ")", "\n", "dtime", "=", "datetime", ".", "datetime", "(", "year", "=", "year", ",", "month", "=", "month", ",", "day", "=", "day", ",", "hour", "=", "hour", ",", "minute", "=", "minute", ",", "second", "=", "second", ")", "\n", "\n", "if", "client_id", "not", "in", "client_idmap", ":", "\n", "                ", "client_idmap", "[", "client_id", "]", "=", "c_client_id", "\n", "c_client_id", "+=", "1", "\n", "", "client_id", "=", "client_idmap", "[", "client_id", "]", "\n", "\n", "raw_data", "[", "idx", "]", "=", "[", "sentiment", ",", "tweet_id", ",", "dtime", ",", "query", ",", "client_id", ",", "tweet", "]", "\n", "", "return", "raw_data", "\n", "# print(c_client_id)", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.ComposedProcess.__init__": [[480, 488], ["super().__init__", "len", "ValueError"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "processes", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "len", "(", "processes", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"should pass at least one transform\"", ")", "\n", "", "self", ".", "processes", "=", "processes", "\n", "ids", "=", "[", "process", ".", "id", "for", "process", "in", "processes", "]", "\n", "self", ".", "id", "=", "'_'", ".", "join", "(", "ids", ")", "\n", "self", ".", "ids", "=", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.ComposedProcess.__process": [[489, 506], ["os.join", "os.exists", "len", "pickle.load", "print", "sentiment140.ComposedProcess.__process", "pickle.dump", "print", "len", "open", "open"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.ComposedProcess.__process"], ["", "def", "__process", "(", "self", ",", "raw_data", ",", "processes", ")", ":", "# recursive process for loaded data", "\n", "        ", "if", "len", "(", "processes", ")", "==", "1", ":", "\n", "            ", "return", "processes", "[", "0", "]", "(", "raw_data", ")", "\n", "\n", "", "ids", "=", "self", ".", "ids", "[", ":", "len", "(", "processes", ")", "]", "\n", "prev_id", "=", "'_'", ".", "join", "(", "ids", "[", ":", "-", "1", "]", ")", "\n", "cache_fn", "=", "prev_id", "+", "'.pkl'", "\n", "cache_fp", "=", "osp", ".", "join", "(", "common", ".", "data_cache_dir", ",", "cache_fn", ")", "\n", "if", "osp", ".", "exists", "(", "cache_fp", ")", ":", "\n", "            ", "raw_data", "=", "pickle", ".", "load", "(", "open", "(", "cache_fp", ",", "'rb'", ")", ")", "\n", "print", "(", "f\"intermediate data loaded from {cache_fp}\"", ")", "\n", "", "else", ":", "\n", "            ", "raw_data", "=", "self", ".", "__process", "(", "raw_data", ",", "processes", "[", ":", "-", "1", "]", ")", "\n", "pickle", ".", "dump", "(", "raw_data", ",", "open", "(", "cache_fp", ",", "'wb'", ")", ")", "\n", "print", "(", "f\"intermediate data dumped into {cache_fp}\"", ")", "\n", "", "raw_data", "=", "processes", "[", "-", "1", "]", "(", "raw_data", ")", "\n", "return", "raw_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.ComposedProcess.__call__": [[507, 514], ["sentiment140.ComposedProcess.__process", "process"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.ComposedProcess.__process"], ["", "def", "__call__", "(", "self", ",", "raw_data", ",", "load_cache", "=", "True", ")", ":", "\n", "        ", "if", "load_cache", ":", "\n", "            ", "return", "self", ".", "__process", "(", "raw_data", ",", "self", ".", "processes", ")", "\n", "", "else", ":", "\n", "            ", "for", "process", "in", "self", ".", "processes", ":", "\n", "                ", "raw_data", "=", "process", "(", "raw_data", ")", "\n", "", "return", "raw_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.CleanTweet.__init__": [[523, 540], ["super().__init__", "sentiment140.get_and_fill", "sentiment140.get_and_fill", "sentiment140.get_and_fill", "sentiment140.get_and_fill", "sentiment140.get_and_fill", "sentiment140.get_and_fill", "sentiment140.get_and_fill", "collections.OrderedDict", "collections.OrderedDict.items"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.get_and_fill", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.get_and_fill", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.get_and_fill", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.get_and_fill", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.get_and_fill", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.get_and_fill", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.get_and_fill"], ["    ", "def", "__init__", "(", "self", ",", "verbose", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "_id", "=", "\"clean\"", "\n", "self", ".", "lxml", "=", "get_and_fill", "(", "kwargs", ",", "'lxml'", ",", "True", ")", "\n", "self", ".", "username", "=", "get_and_fill", "(", "kwargs", ",", "'username'", ",", "True", ")", "\n", "self", ".", "url", "=", "get_and_fill", "(", "kwargs", ",", "'url'", ",", "True", ")", "\n", "self", ".", "bom", "=", "get_and_fill", "(", "kwargs", ",", "'bom'", ",", "True", ")", "\n", "self", ".", "rm_punctuation", "=", "get_and_fill", "(", "kwargs", ",", "'rm_punctuation'", ",", "True", ")", "\n", "self", ".", "rm_repeat", "=", "get_and_fill", "(", "kwargs", ",", "'rm_repeat'", ",", "True", ")", "\n", "self", ".", "lowercase", "=", "get_and_fill", "(", "kwargs", ",", "'lowercase'", ",", "True", ")", "\n", "kwargs", "=", "collections", ".", "OrderedDict", "(", "kwargs", ")", "\n", "for", "key", ",", "val", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "not", "val", ":", "\n", "                ", "_id", "+=", "f'_{key}'", "\n", "", "", "self", ".", "id", "=", "_id", "\n", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.CleanTweet.__call__": [[541, 584], ["re.compile", "re.compile", "re.compile", "enumerate", "print", "print", "bs4.BeautifulSoup().get_text", "re.sub", "re.sub", "re.sub.replace", "re.sub.lower", "re.sub", "re.sub.split", "enumerate", "bs4.BeautifulSoup", "len", "ch_list.append"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "raw_data", ")", ":", "\n", "        ", "user_pat", "=", "re", ".", "compile", "(", "r'@[A-Za-z0-9]+'", ")", "\n", "http_pat", "=", "re", ".", "compile", "(", "r'https?://[A-Za-z0-9./]+'", ")", "\n", "punctuation_pat", "=", "re", ".", "compile", "(", "r\"[^a-zA-Z]\"", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"cleaning data\"", ")", "\n", "", "for", "idx", ",", "data_tup", "in", "enumerate", "(", "raw_data", ")", ":", "\n", "            ", "if", "self", ".", "verbose", "and", "idx", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "f\"{idx}/{len(raw_data)}\"", ",", "end", "=", "'\\r'", ")", "\n", "", "tweet", "=", "data_tup", "[", "Sentiment140Dataset", ".", "TWEET", "]", "\n", "if", "self", ".", "lxml", ":", "\n", "                ", "tweet", "=", "BeautifulSoup", "(", "tweet", ",", "'lxml'", ")", ".", "get_text", "(", ")", "\n", "", "if", "self", ".", "username", ":", "\n", "                ", "tweet", "=", "re", ".", "sub", "(", "user_pat", ",", "'atUSERNAMEat'", ",", "tweet", ")", "\n", "", "if", "self", ".", "url", ":", "\n", "                ", "tweet", "=", "re", ".", "sub", "(", "http_pat", ",", "'URLhttp'", ",", "tweet", ")", "\n", "", "if", "self", ".", "bom", ":", "\n", "                ", "tweet", "=", "tweet", ".", "replace", "(", "u\"\\xef\\xbf\\xbd\"", ",", "\" \"", ")", "\n", "", "if", "self", ".", "lowercase", ":", "\n", "                ", "tweet", "=", "tweet", ".", "lower", "(", ")", "\n", "", "if", "self", ".", "rm_punctuation", ":", "\n", "                ", "tweet", "=", "re", ".", "sub", "(", "punctuation_pat", ",", "' '", ",", "tweet", ")", "\n", "", "if", "self", ".", "rm_repeat", ":", "\n", "                ", "words", "=", "tweet", ".", "split", "(", ")", "\n", "for", "word_idx", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "                    ", "last_ch", "=", "None", "\n", "count", "=", "1", "\n", "ch_list", "=", "[", "]", "\n", "for", "ch", "in", "word", ":", "\n", "                        ", "if", "count", "<", "2", "or", "ch", "!=", "last_ch", ":", "\n", "                            ", "ch_list", ".", "append", "(", "ch", ")", "\n", "", "if", "ch", "==", "last_ch", ":", "\n", "                            ", "count", "+=", "1", "\n", "", "else", ":", "\n", "                            ", "count", "=", "1", "\n", "", "last_ch", "=", "ch", "\n", "", "word", "=", "''", ".", "join", "(", "ch_list", ")", "\n", "words", "[", "word_idx", "]", "=", "word", "\n", "", "tweet", "=", "' '", ".", "join", "(", "words", ")", "\n", "", "raw_data", "[", "idx", "]", "[", "Sentiment140Dataset", ".", "TWEET", "]", "=", "tweet", "\n", "\n", "", "return", "raw_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.BagOfWords.__init__": [[587, 596], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Bag of words model, take the most frequent num_features words as features.\n        Tweets processed as torch.FloatTensor\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "id", "=", "f\"BOW{num_features}\"", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.BagOfWords.__call__": [[597, 644], ["enumerate", "list", "sorted", "enumerate", "enumerate", "print", "tweet.split", "sorted.items", "print", "print", "tweet.split", "list", "print", "print", "print", "list.items", "len", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "raw_data", ")", ":", "\n", "        ", "verbose", "=", "self", ".", "verbose", "\n", "\n", "# count words", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"counting words\"", ")", "\n", "", "words2num", "=", "{", "}", "\n", "for", "idx", ",", "data_tup", "in", "enumerate", "(", "raw_data", ")", ":", "\n", "            ", "if", "verbose", "and", "idx", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "f\"{idx}/{len(raw_data)}\"", ",", "end", "=", "'\\r'", ")", "\n", "", "tweet", "=", "data_tup", "[", "Sentiment140Dataset", ".", "TWEET", "]", "\n", "words", "=", "tweet", ".", "split", "(", ")", "\n", "for", "word", "in", "words", ":", "\n", "                ", "if", "word", "in", "words2num", ":", "\n", "                    ", "words2num", "[", "word", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "words2num", "[", "word", "]", "=", "1", "\n", "", "", "", "words2num", "=", "list", "(", "words2num", ".", "items", "(", ")", ")", "\n", "words2num", "=", "sorted", "(", "words2num", ",", "key", "=", "lambda", "pair", ":", "-", "pair", "[", "1", "]", ")", "\n", "valid_features", "=", "words2num", "[", ":", "self", ".", "num_features", "]", "\n", "valid_features_dict", "=", "{", "}", "\n", "for", "idx", ",", "(", "word", ",", "num", ")", "in", "enumerate", "(", "valid_features", ")", ":", "\n", "            ", "valid_features_dict", "[", "word", "]", "=", "idx", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", ")", "\n", "\n", "# transform", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "\"transforming\"", ")", "\n", "", "for", "idx", ",", "data_tup", "in", "enumerate", "(", "raw_data", ")", ":", "\n", "            ", "if", "verbose", "and", "idx", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "f\"{idx}/{len(raw_data)}\"", ",", "end", "=", "'\\r'", ")", "\n", "", "tweet", "=", "data_tup", "[", "Sentiment140Dataset", ".", "TWEET", "]", "\n", "words", "=", "tweet", ".", "split", "(", ")", "\n", "idx2count", "=", "{", "}", "\n", "for", "word", "in", "words", ":", "\n", "                ", "if", "word", "in", "valid_features_dict", ":", "\n", "                    ", "if", "valid_features_dict", "[", "word", "]", "in", "idx2count", ":", "\n", "                        ", "idx2count", "[", "valid_features_dict", "[", "word", "]", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "idx2count", "[", "valid_features_dict", "[", "word", "]", "]", "=", "1", "\n", "", "", "", "idx2count", "=", "list", "(", "idx2count", ".", "items", "(", ")", ")", "\n", "raw_data", "[", "idx", "]", "[", "Sentiment140Dataset", ".", "TWEET", "]", "=", "idx2count", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", ")", "\n", "\n", "", "return", "raw_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.BagOfWords.multihot": [[645, 656], ["torch.zeros"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "multihot", "(", "num_features", ")", ":", "\n", "        ", "\"\"\"\n        multihot decode\n        \"\"\"", "\n", "def", "_multihot", "(", "idx2count", ")", ":", "\n", "            ", "vec", "=", "torch", ".", "zeros", "(", "num_features", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "for", "idx", ",", "count", "in", "idx2count", ":", "\n", "                ", "vec", "[", "idx", "]", "=", "count", "\n", "", "return", "vec", "\n", "", "return", "_multihot", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.infer_sleep": [[393, 433], ["sorted", "len", "len"], "function", ["None"], ["", "", "def", "infer_sleep", "(", "tweets_time", ",", "num_seconds_day", ",", "num_seconds_sleep", ")", ":", "\n", "    ", "\"\"\"\n    infer the sleeping time of a client, by finding a length-num_seconds_sleep window with the least tweets in it\n    window is a *open* interval\n    return: (window_start, window_end)\n    \"\"\"", "\n", "tweets_time", "=", "sorted", "(", "tweets_time", ")", "\n", "\n", "num_tweets", "=", "len", "(", "tweets_time", ")", "\n", "min_included", "=", "len", "(", "tweets_time", ")", "\n", "start_idx_min", ",", "end_idx_min", "=", "-", "1", ",", "-", "1", "\n", "start_idx", "=", "0", "# interval start", "\n", "end_idx", "=", "(", "start_idx", "+", "1", ")", "%", "num_tweets", "# first tweet outside the open interval", "\n", "while", "start_idx", "!=", "num_tweets", ":", "\n", "        ", "start_time", "=", "tweets_time", "[", "start_idx", "]", "\n", "end_time", "=", "tweets_time", "[", "end_idx", "]", "if", "end_idx", ">", "start_idx", "else", "tweets_time", "[", "end_idx", "]", "+", "num_seconds_day", "\n", "if", "end_time", "-", "start_time", "<", "num_seconds_sleep", ":", "\n", "            ", "end_idx", "=", "(", "end_idx", "+", "1", ")", "%", "num_tweets", "\n", "", "else", ":", "# start_idx -> end_idx - 1 are included in the interval", "\n", "            ", "if", "end_idx", ">", "start_idx", ":", "\n", "                ", "num_included", "=", "end_idx", "-", "start_idx", "-", "1", "\n", "", "else", ":", "\n", "                ", "num_included", "=", "end_idx", "-", "start_idx", "-", "1", "+", "num_tweets", "\n", "\n", "", "if", "num_included", "<", "min_included", ":", "\n", "                ", "start_idx_min", ",", "end_idx_min", "=", "start_idx", ",", "end_idx", "\n", "min_included", "=", "num_included", "\n", "\n", "", "start_idx", "+=", "1", "\n", "\n", "", "", "min_start_time", "=", "tweets_time", "[", "start_idx_min", "]", "\n", "max_start_time", "=", "tweets_time", "[", "end_idx_min", "]", "-", "num_seconds_sleep", "\n", "max_start_time", "=", "max_start_time", "if", "max_start_time", ">=", "0", "else", "max_start_time", "+", "num_seconds_day", "\n", "\n", "if", "max_start_time", "<", "min_start_time", ":", "\n", "        ", "max_start_time", "+=", "num_seconds_day", "\n", "", "start_time", "=", "(", "min_start_time", "+", "max_start_time", ")", "/", "2", "\n", "end_time", "=", "start_time", "+", "num_seconds_sleep", "\n", "\n", "return", "start_time", "%", "num_seconds_day", ",", "end_time", "%", "num_seconds_day", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.get_and_fill": [[516, 520], ["None"], "function", ["None"], ["", "", "", "def", "get_and_fill", "(", "kwargs", ",", "key", ",", "default", ")", ":", "\n", "    ", "if", "key", "not", "in", "kwargs", ":", "\n", "        ", "kwargs", "[", "key", "]", "=", "default", "\n", "", "return", "kwargs", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.time2int": [[658, 661], ["None"], "function", ["None"], ["", "", "def", "time2int", "(", "time_", ")", ":", "\n", "# time_: Time or DateTime", "\n", "    ", "return", "time_", ".", "hour", "*", "3600", "+", "time_", ".", "minute", "*", "60", "+", "time_", ".", "second", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140._test_infer_sleep": [[663, 667], ["print", "print", "random.randint", "sentiment140.infer_sleep", "range"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.infer_sleep"], ["", "def", "_test_infer_sleep", "(", ")", ":", "\n", "    ", "tweets_time", "=", "[", "random", ".", "randint", "(", "0", ",", "76400", "-", "1", ")", "for", "_", "in", "range", "(", "32", ")", "]", "\n", "print", "(", "tweets_time", ")", "\n", "print", "(", "infer_sleep", "(", "tweets_time", ",", "86400", ",", "28800", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.plot_availability_count": [[669, 682], ["range", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "datetime.timedelta", "avai_counts.append", "range", "os.join", "client.is_available"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close"], ["", "def", "plot_availability_count", "(", "clients", ",", "fn", "=", "\"availability_count.png\"", ")", ":", "\n", "    ", "avai_counts", "=", "[", "]", "\n", "for", "hour", "in", "range", "(", "24", ")", ":", "\n", "        ", "time_", "=", "datetime", ".", "timedelta", "(", "hours", "=", "hour", ")", "\n", "avai_count", "=", "0", "\n", "for", "client", "in", "clients", ":", "\n", "            ", "if", "client", ".", "is_available", "(", "time_", ")", ":", "\n", "                ", "avai_count", "+=", "1", "\n", "", "", "avai_counts", ".", "append", "(", "avai_count", ")", "\n", "", "plt", ".", "figure", "(", "0", ")", "\n", "plt", ".", "plot", "(", "range", "(", "24", ")", ",", "avai_counts", ")", "\n", "plt", ".", "savefig", "(", "osp", ".", "join", "(", "common", ".", "figure_fd", ",", "fn", ")", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140._plot_block_count2client_count": [[684, 697], ["dict", "sorted", "list", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "len", "list", "zip", "os.join", "dict.items"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close"], ["", "def", "_plot_block_count2client_count", "(", "clients", ")", ":", "\n", "    ", "block_count2client_count", "=", "dict", "(", ")", "\n", "for", "client", "in", "clients", ":", "\n", "        ", "block_count", "=", "len", "(", "client", ".", "available_blocks", ")", "\n", "if", "block_count", "not", "in", "block_count2client_count", ":", "\n", "            ", "block_count2client_count", "[", "block_count", "]", "=", "0", "\n", "", "block_count2client_count", "[", "block_count", "]", "+=", "1", "\n", "", "plot_array", "=", "sorted", "(", "list", "(", "block_count2client_count", ".", "items", "(", ")", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "_x", ",", "_y", "=", "list", "(", "zip", "(", "*", "plot_array", ")", ")", "\n", "plt", ".", "figure", "(", "1", ")", "\n", "plt", ".", "plot", "(", "_x", ",", "_y", ")", "\n", "plt", ".", "savefig", "(", "osp", ".", "join", "(", "common", ".", "figure_fd", ",", "\"block_count2client_count.png\"", ")", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.plot_client_sample_volume": [[699, 720], ["max", "numpy.arange", "numpy.zeros_like", "numpy.zeros_like", "enumerate", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "print", "os.join", "os.join"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close"], ["", "def", "plot_client_sample_volume", "(", "clients", ")", ":", "\n", "    ", "client_num_samples", "=", "[", "client", ".", "num_samples", "for", "client", "in", "clients", "]", "\n", "max_num_samples", "=", "max", "(", "client_num_samples", ")", "\n", "x_axis", "=", "np", ".", "arange", "(", "max_num_samples", "+", "1", ")", "\n", "y_axis", "=", "np", ".", "zeros_like", "(", "x_axis", ")", "\n", "for", "num_samples", "in", "client_num_samples", ":", "\n", "        ", "y_axis", "[", "num_samples", "]", "+=", "1", "\n", "", "summ", "=", "0", "\n", "y_axis_accumulate", "=", "np", ".", "zeros_like", "(", "x_axis", ")", "\n", "for", "num_samples", ",", "num_clients", "in", "enumerate", "(", "y_axis", ")", ":", "\n", "        ", "summ", "+=", "num_clients", "\n", "print", "(", "f\"num_samples: {num_samples}, num_clients: {num_clients}, total: {summ}\"", ")", "\n", "y_axis_accumulate", "[", "num_samples", "]", "=", "summ", "\n", "", "fig", "=", "plt", ".", "figure", "(", "0", ")", "\n", "plt", ".", "plot", "(", "x_axis", "[", "1", ":", "]", ",", "y_axis", "[", "1", ":", "]", ")", "\n", "plt", ".", "savefig", "(", "osp", ".", "join", "(", "common", ".", "figure_fd", ",", "\"num_samples_distribution.png\"", ")", ")", "\n", "plt", ".", "close", "(", "0", ")", "\n", "fig", "=", "plt", ".", "figure", "(", "1", ")", "\n", "plt", ".", "plot", "(", "x_axis", "[", "1", ":", "]", ",", "y_axis_accumulate", "[", "1", ":", "]", ")", "\n", "plt", ".", "savefig", "(", "osp", ".", "join", "(", "common", ".", "figure_fd", ",", "\"num_samples_pdf.png\"", ")", ")", "\n", "plt", ".", "close", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140._plot_availability_pattern": [[722, 760], ["min().date", "matplotlib.pyplot.figure", "range", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "matplotlib.pyplot.subplot", "random.sample", "print", "zip", "list", "matplotlib.pyplot.yticks", "os.join", "min", "range", "sorted", "numpy.array", "numpy.array", "np.array.argsort", "date_line.append", "time_line.append", "matplotlib.pyplot.scatter", "range", "len", "dtime.date", "dtime.time", "np.array.append", "np.array.append"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close"], ["", "def", "_plot_availability_pattern", "(", "dataset", ",", "clients", ")", ":", "\n", "    ", "num_figures", "=", "9", "\n", "test_num", "=", "1", "\n", "thres_num_samples", "=", "10", "\n", "filtered_clients", "=", "[", "client", "for", "client", "in", "clients", "if", "client", ".", "num_samples", ">", "thres_num_samples", "]", "\n", "datetimes", "=", "[", "tup", "[", "Sentiment140Dataset", ".", "DATETIME", "]", "for", "tup", "in", "dataset", ".", "processed_data", "]", "\n", "start_date", "=", "min", "(", "datetimes", ")", ".", "date", "(", ")", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "14", ",", "14", ")", ")", "\n", "for", "figure_idx", "in", "range", "(", "num_figures", ")", ":", "\n", "        ", "plt", ".", "subplot", "(", "3", ",", "3", ",", "figure_idx", "+", "1", ")", "\n", "client_indices", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "filtered_clients", ")", ")", ",", "test_num", ")", "\n", "print", "(", "f\"chosen clients: {client_indices}\"", ")", "\n", "test_clients", "=", "[", "filtered_clients", "[", "idx", "]", "for", "idx", "in", "client_indices", "]", "\n", "date_line", "=", "[", "]", "\n", "time_line", "=", "[", "]", "\n", "for", "client", "in", "test_clients", ":", "\n", "            ", "date_line_", "=", "[", "]", "\n", "time_line_", "=", "[", "]", "\n", "for", "idx", "in", "sorted", "(", "client", ".", "train_indices", ")", ":", "\n", "                ", "data_tup", "=", "dataset", ".", "processed_data", "[", "idx", "]", "\n", "dtime", "=", "data_tup", "[", "Sentiment140Dataset", ".", "DATETIME", "]", "\n", "this_date", "=", "dtime", ".", "date", "(", ")", "\n", "this_time", "=", "dtime", ".", "time", "(", ")", "\n", "date_line_", ".", "append", "(", "(", "this_date", "-", "start_date", ")", ".", "days", ")", "\n", "time_line_", ".", "append", "(", "this_time", ".", "hour", "*", "3600", "+", "this_time", ".", "minute", "*", "60", "+", "this_time", ".", "second", ")", "\n", "", "date_line_", "=", "np", ".", "array", "(", "date_line_", ")", "\n", "time_line_", "=", "np", ".", "array", "(", "time_line_", ")", "\n", "order", "=", "date_line_", ".", "argsort", "(", ")", "\n", "date_line", ".", "append", "(", "date_line_", "[", "order", "]", ")", "\n", "time_line", ".", "append", "(", "time_line_", "[", "order", "]", ")", "\n", "\n", "", "for", "dline", ",", "tline", "in", "zip", "(", "date_line", ",", "time_line", ")", ":", "\n", "            ", "plt", ".", "scatter", "(", "dline", ",", "tline", ")", "\n", "", "y_ticks_texts", "=", "list", "(", "range", "(", "25", ")", ")", "\n", "y_ticks_vals", "=", "[", "text", "*", "3600", "for", "text", "in", "y_ticks_texts", "]", "\n", "plt", ".", "yticks", "(", "y_ticks_vals", ",", "y_ticks_texts", ")", "\n", "", "plt", ".", "savefig", "(", "osp", ".", "join", "(", "common", ".", "figure_fd", ",", "f\"availability.png\"", ")", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140._statistics": [[762, 777], ["dataset.statistic_words", "dataset.count_in_gloves", "print", "print", "print", "dataset.get_clients", "max", "print", "print", "dataset.count_clients", "dataset.count_words", "dataset.count_chars", "len"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.statistic_words", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.count_in_gloves", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.get_clients", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.count_clients", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.count_words", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.count_chars"], ["", "def", "_statistics", "(", "dataset", ")", ":", "\n", "    ", "dataset", ".", "statistic_words", "(", "num_print", "=", "0", ")", "\n", "dataset", ".", "count_in_gloves", "(", ")", "\n", "print", "(", "f\"Number of clients: {dataset.count_clients()}\"", ")", "\n", "print", "(", "f\"Number of words: {dataset.count_words()}\"", ")", "\n", "print", "(", "f\"Number of characters: {dataset.count_chars()}\"", ")", "\n", "clients", "=", "dataset", ".", "get_clients", "(", "train_batch_size", "=", "1", ")", "\n", "client_num_samples", "=", "[", "client", ".", "num_samples", "for", "client", "in", "clients", "]", "\n", "max_num_samples", "=", "max", "(", "client_num_samples", ")", "\n", "print", "(", "f\"maximum number of samples {max_num_samples}\"", ")", "\n", "positive_count", "=", "0", "\n", "for", "tweet", ",", "label", "in", "dataset", ":", "\n", "        ", "if", "label", "==", "1", ":", "\n", "            ", "positive_count", "+=", "1", "\n", "", "", "print", "(", "f\"{positive_count}/{len(dataset)} positive samples\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140._test_forward": [[779, 790], ["torch.utils.data.DataLoader", "train.model.LSTM2", "print", "print", "train.model.LSTM2.", "net.sum().backward", "print", "net.sum"], "function", ["None"], ["", "def", "_test_forward", "(", "dataset", ")", ":", "\n", "    ", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "10", ",", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "Sentiment140Dataset", ".", "collate_fn", ")", "\n", "net", "=", "LSTM2", "(", ")", "\n", "for", "tweets", ",", "labels", "in", "dataloader", ":", "\n", "        ", "print", "(", "tweets", ")", "\n", "print", "(", "labels", ")", "\n", "output", "=", "net", "(", "tweets", ")", "\n", "output", ".", "sum", "(", ")", ".", "backward", "(", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140._test_filter": [[792, 798], ["dataset.filter_clients_", "dataset.random_select_clients_", "dataset.partition", "trainset.count_clients", "print"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.filter_clients_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.random_select_clients_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.partition", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.count_clients"], ["", "", "def", "_test_filter", "(", "dataset", ")", ":", "\n", "    ", "dataset", ".", "filter_clients_", "(", "8", ")", "\n", "dataset", ".", "random_select_clients_", "(", "10000", ")", "\n", "trainset", ",", "testset", "=", "dataset", ".", "partition", "(", ")", "\n", "actual_N", "=", "trainset", ".", "count_clients", "(", ")", "\n", "print", "(", "f\"There are actually {actual_N} clients\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140._count_availability_mid16": [[800, 818], ["dataset.filter_clients_", "dataset.get_clients", "print", "numpy.arange", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "datetime.timedelta", "avai_counts.append", "numpy.arange", "os.join", "client.is_available", "len"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.filter_clients_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.get_clients", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close"], ["", "def", "_count_availability_mid16", "(", "dataset", ")", ":", "\n", "    ", "thres", "=", "100", "\n", "dataset", ".", "filter_clients_", "(", "thres", ")", "\n", "\n", "clients", "=", "dataset", ".", "get_clients", "(", "strategy", "=", "\"modeled_mid\"", ")", "\n", "print", "(", "f\"{len(clients)} clients\"", ")", "\n", "avai_counts", "=", "[", "]", "\n", "for", "hour", "in", "np", ".", "arange", "(", "0", ",", "24", ",", "0.5", ")", ":", "\n", "        ", "time_", "=", "datetime", ".", "timedelta", "(", "seconds", "=", "hour", "*", "3600", ")", "\n", "avai_count", "=", "0", "\n", "for", "client", "in", "clients", ":", "\n", "            ", "if", "client", ".", "is_available", "(", "time_", ")", ":", "\n", "                ", "avai_count", "+=", "1", "\n", "", "", "avai_counts", ".", "append", "(", "avai_count", ")", "\n", "", "plt", ".", "figure", "(", "0", ")", "\n", "plt", ".", "plot", "(", "np", ".", "arange", "(", "0", ",", "24", ",", "0.5", ")", ",", "avai_counts", ")", "\n", "plt", ".", "savefig", "(", "osp", ".", "join", "(", "common", ".", "figure_fd", ",", "f\"available_count_modeled_mid_filter{thres}.png\"", ")", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.plot_datum_time": [[820, 830], ["matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "range", "os.join"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close"], ["", "def", "plot_datum_time", "(", "dataset", ",", "fn", "=", "\"tweets_time.png\"", ")", ":", "\n", "    ", "counts", "=", "[", "0", "]", "*", "24", "\n", "for", "data_tup", "in", "dataset", ".", "processed_data", ":", "\n", "        ", "datum_time", "=", "data_tup", "[", "dataset", ".", "DATETIME", "]", "\n", "datum", "=", "datum_time", ".", "hour", "\n", "counts", "[", "datum", "]", "+=", "1", "\n", "", "plt", ".", "figure", "(", "0", ")", "\n", "plt", ".", "plot", "(", "range", "(", "24", ")", ",", "counts", ")", "\n", "plt", ".", "savefig", "(", "osp", ".", "join", "(", "common", ".", "figure_fd", ",", "fn", ")", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.plot_posi_ratio_with_time": [[832, 851], ["numpy.zeros", "numpy.zeros", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.plot", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "print", "range", "range", "os.join", "range", "os.join", "sum", "sum"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close"], ["", "def", "plot_posi_ratio_with_time", "(", "dataset", ")", ":", "\n", "    ", "posi_counts", "=", "np", ".", "zeros", "(", "24", ",", "int", ")", "\n", "total_counts", "=", "np", ".", "zeros", "(", "24", ",", "int", ")", "\n", "for", "data_tup", "in", "dataset", ".", "processed_data", ":", "\n", "        ", "hour", "=", "data_tup", "[", "dataset", ".", "DATETIME", "]", ".", "hour", "\n", "sentiment", "=", "data_tup", "[", "dataset", ".", "SENTIMENT", "]", "\n", "total_counts", "[", "hour", "]", "+=", "1", "\n", "if", "sentiment", "==", "1", ":", "\n", "            ", "posi_counts", "[", "hour", "]", "+=", "1", "\n", "", "", "plt", ".", "figure", "(", "0", ")", "\n", "plt", ".", "plot", "(", "range", "(", "24", ")", ",", "total_counts", ")", "\n", "plt", ".", "plot", "(", "range", "(", "24", ")", ",", "posi_counts", ")", "\n", "plt", ".", "savefig", "(", "osp", ".", "join", "(", "common", ".", "figure_fd", ",", "\"count_in_variation.png\"", ")", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "plt", ".", "figure", "(", "1", ")", "\n", "plt", ".", "plot", "(", "range", "(", "24", ")", ",", "posi_counts", "/", "total_counts", ")", "\n", "plt", ".", "savefig", "(", "osp", ".", "join", "(", "common", ".", "figure_fd", ",", "\"ratio_in_variation.png\"", ")", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "print", "(", "f\"{sum(posi_counts)}/{sum(total_counts)} tweets are positive\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140._test": [[853, 867], ["sentiment140.Sentiment140Dataset", "sentiment140.Sentiment140Dataset.filter_clients_", "print", "print", "exit", "sentiment140.Sentiment140Dataset.random_select_clients_", "sentiment140.Sentiment140Dataset.time_variation_", "sentiment140.Sentiment140Dataset.partition", "print", "_plot_posi_ratio_with_time", "sentiment140.ComposedProcess", "sentiment140.Sentiment140Dataset.count_clients", "len", "trainset.count_clients", "sentiment140.BasicProcess"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.filter_clients_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.random_select_clients_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.time_variation_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.partition", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.count_clients", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.count_clients"], ["", "def", "_test", "(", ")", ":", "\n", "    ", "dataset", "=", "Sentiment140Dataset", "(", "ComposedProcess", "(", "\n", "BasicProcess", "(", ")", ",", "\n", "# CleanTweet(verbose=True),", "\n", ")", ")", "\n", "dataset", ".", "filter_clients_", "(", "40", ")", "\n", "print", "(", "dataset", ".", "count_clients", "(", ")", ")", "\n", "print", "(", "len", "(", "dataset", ")", ")", "\n", "exit", "(", ")", "\n", "dataset", ".", "random_select_clients_", "(", "1000", ")", "\n", "dataset", ".", "time_variation_", "(", "num_blocks", "=", "24", ")", "\n", "trainset", ",", "testset", "=", "dataset", ".", "partition", "(", ")", "\n", "print", "(", "trainset", ".", "count_clients", "(", ")", ")", "\n", "_plot_posi_ratio_with_time", "(", "trainset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.__init__": [[22, 66], ["os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.join", "os.join", "logger.Logger.has_checkpoint", "torch.utils.tensorboard.SummaryWriter", "os.exists", "os.exists", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.abspath", "os.abspath", "os.symlink", "os.symlink", "os.symlink", "os.symlink", "os.join", "os.join", "open", "logger.Logger.load_meta", "os.join", "os.join", "open", "f_in.readlines", "open", "f_out.write", "f_in.readline", "open", "f_out.write", "int", "valid_content.append", "line.split"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.has_checkpoint", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.load_meta"], ["def", "__init__", "(", "self", ",", "run_name", ")", ":", "\n", "        ", "self", ".", "father_fd", "=", "osp", ".", "join", "(", "common", ".", "project_dir", ",", "common", ".", "record_fd", ",", "run_name", ")", "\n", "self", ".", "log_fd", "=", "osp", ".", "join", "(", "self", ".", "father_fd", ",", "common", ".", "log_fd", ")", "\n", "self", ".", "tb_fd", "=", "osp", ".", "join", "(", "self", ".", "father_fd", ",", "common", ".", "tensorboard_fd", ")", "\n", "self", ".", "ck_fd", "=", "osp", ".", "join", "(", "self", ".", "father_fd", ",", "common", ".", "checkpoint_fd", ")", "\n", "\n", "os", ".", "makedirs", "(", "self", ".", "tb_fd", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "log_fd", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "ck_fd", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# make the soft link to tensorboard", "\n", "slink_fp", "=", "osp", ".", "join", "(", "common", ".", "tb_slink_fd", ",", "run_name", ")", "\n", "if", "not", "osp", ".", "exists", "(", "slink_fp", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "common", ".", "tb_slink_fd", ",", "exist_ok", "=", "True", ")", "\n", "tb_abs_path", "=", "osp", ".", "abspath", "(", "self", ".", "tb_fd", ")", "\n", "os", ".", "symlink", "(", "tb_abs_path", ",", "slink_fp", ")", "\n", "\n", "", "if", "self", ".", "has_checkpoint", "(", ")", ":", "\n", "            ", "c_round", "=", "self", ".", "load_meta", "(", ")", "[", "'current_round'", "]", "\n", "", "else", ":", "\n", "            ", "c_round", "=", "0", "\n", "\n", "# remove dirty data", "\n", "", "for", "_fn", "in", "Logger", ".", "criteria", ":", "\n", "            ", "_fp", "=", "osp", ".", "join", "(", "self", ".", "log_fd", ",", "_fn", "+", "'.csv'", ")", "\n", "try", ":", "\n", "                ", "with", "open", "(", "_fp", ",", "'r'", ")", "as", "f_in", ":", "\n", "                    ", "valid_content", "=", "[", "f_in", ".", "readline", "(", ")", "]", "\n", "for", "line", "in", "f_in", ".", "readlines", "(", ")", ":", "\n", "                        ", "if", "int", "(", "line", ".", "split", "(", "','", ")", "[", "1", "]", ")", "<", "c_round", ":", "\n", "                            ", "valid_content", ".", "append", "(", "line", ")", "\n", "", "else", ":", "\n", "                            ", "break", "\n", "", "", "valid_content", "=", "''", ".", "join", "(", "valid_content", ")", "\n", "", "with", "open", "(", "_fp", ",", "'w'", ")", "as", "f_out", ":", "\n", "                    ", "f_out", ".", "write", "(", "valid_content", ")", "\n", "", "", "except", "FileNotFoundError", ":", "\n", "                ", "with", "open", "(", "_fp", ",", "'w'", ")", "as", "f_out", ":", "\n", "                    ", "f_out", ".", "write", "(", "\"Time,Step,Value\\n\"", ")", "\n", "", "", "", "self", ".", "log_handlers", "=", "{", "_fn", ":", "open", "(", "osp", ".", "join", "(", "self", ".", "log_fd", ",", "_fn", "+", "'.csv'", ")", ",", "'a'", ")", "for", "_fn", "in", "Logger", ".", "criteria", "}", "\n", "\n", "self", ".", "summaryWriter", "=", "SummaryWriter", "(", "log_dir", "=", "self", ".", "tb_fd", ",", "purge_step", "=", "c_round", ")", "\n", "\n", "self", ".", "__tmp_checkpoint_fd", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.backup_checkpoint": [[67, 72], ["os.join", "os.join", "os.exists", "os.exists", "shutil.copytree", "FileExistsError", "os.split", "os.split", "os.split", "os.split"], "methods", ["None"], ["", "def", "backup_checkpoint", "(", "self", ")", ":", "\n", "        ", "self", ".", "__tmp_checkpoint_fd", "=", "osp", ".", "join", "(", "osp", ".", "split", "(", "self", ".", "ck_fd", ")", "[", "0", "]", ",", "osp", ".", "split", "(", "self", ".", "ck_fd", ")", "[", "1", "]", "+", "\"_bak\"", ")", "\n", "if", "osp", ".", "exists", "(", "self", ".", "__tmp_checkpoint_fd", ")", ":", "\n", "            ", "raise", "FileExistsError", "(", "f\"{self.__tmp_checkpoint_fd} already exists, can not be a backup destination\"", ")", "\n", "", "shutil", ".", "copytree", "(", "self", ".", "ck_fd", ",", "self", ".", "__tmp_checkpoint_fd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.remove_backup": [[73, 76], ["shutil.rmtree"], "methods", ["None"], ["", "def", "remove_backup", "(", "self", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "self", ".", "__tmp_checkpoint_fd", ")", "\n", "self", ".", "__tmp_checkpoint_fd", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.has_checkpoint": [[77, 79], ["os.exists", "os.exists", "os.join", "os.join"], "methods", ["None"], ["", "def", "has_checkpoint", "(", "self", ")", ":", "\n", "        ", "return", "osp", ".", "exists", "(", "osp", ".", "join", "(", "self", ".", "ck_fd", ",", "Logger", ".", "META_FN", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.load_meta": [[80, 82], ["pickle.load", "open", "os.join", "os.join"], "methods", ["None"], ["", "def", "load_meta", "(", "self", ")", ":", "\n", "        ", "return", "pickle", ".", "load", "(", "open", "(", "osp", ".", "join", "(", "self", ".", "ck_fd", ",", "Logger", ".", "META_FN", ")", ",", "'rb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.dump_meta": [[83, 85], ["pickle.dump", "open", "os.join", "os.join"], "methods", ["None"], ["", "def", "dump_meta", "(", "self", ",", "meta", ")", ":", "\n", "        ", "pickle", ".", "dump", "(", "meta", ",", "open", "(", "osp", ".", "join", "(", "self", ".", "ck_fd", ",", "Logger", ".", "META_FN", ")", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.load_model": [[86, 88], ["model.load_state_dict", "torch.load", "os.join", "os.join"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.load_state_dict"], ["", "def", "load_model", "(", "self", ",", "model", ")", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "osp", ".", "join", "(", "self", ".", "ck_fd", ",", "Logger", ".", "MODEL_FN", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.dump_model": [[89, 93], ["torch.save", "model.state_dict", "os.join", "os.join"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.state_dict"], ["", "def", "dump_model", "(", "self", ",", "model", ",", "fn", "=", "None", ")", ":", "\n", "        ", "if", "fn", "is", "None", ":", "\n", "            ", "fn", "=", "Logger", ".", "MODEL_FN", "\n", "", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "osp", ".", "join", "(", "self", ".", "ck_fd", ",", "fn", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.load_server": [[94, 96], ["pickle.load", "open", "os.join", "os.join"], "methods", ["None"], ["", "def", "load_server", "(", "self", ")", ":", "\n", "        ", "return", "pickle", ".", "load", "(", "open", "(", "osp", ".", "join", "(", "self", ".", "ck_fd", ",", "Logger", ".", "SERVER_FN", ")", ",", "'rb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.dump_server": [[97, 99], ["pickle.dump", "open", "os.join", "os.join"], "methods", ["None"], ["", "def", "dump_server", "(", "self", ",", "server", ")", ":", "\n", "        ", "pickle", ".", "dump", "(", "server", ",", "open", "(", "osp", ".", "join", "(", "self", ".", "ck_fd", ",", "Logger", ".", "SERVER_FN", ")", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.load_clients": [[100, 107], ["pickle.load", "zip", "ValueError", "open", "dict", "client.load_state_dict", "os.join", "os.join"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.load_state_dict"], ["", "def", "load_clients", "(", "self", ",", "clients", ",", "target_alg", ")", ":", "\n", "        ", "if", "target_alg", "not", "in", "(", "'fedavg'", ",", "'lastavg'", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f\"target_alg={target_alg} not recognized in load_clients\"", ")", "\n", "", "dumped_clients", "=", "pickle", ".", "load", "(", "open", "(", "osp", ".", "join", "(", "self", ".", "ck_fd", ",", "Logger", ".", "CLIENTS_FN", ")", ",", "'rb'", ")", ")", "\n", "load_last_grad_sum", "=", "dict", "(", "fedavg", "=", "False", ",", "lastavg", "=", "True", ")", "[", "target_alg", "]", "\n", "for", "client", ",", "state_dict", "in", "zip", "(", "clients", ",", "dumped_clients", ")", ":", "\n", "            ", "client", ".", "load_state_dict", "(", "state_dict", ",", "load_last_grad_sum", "=", "load_last_grad_sum", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.dump_clients": [[108, 113], ["pickle.dump", "dumped_clients.append", "open", "client.state_dict", "os.join", "os.join"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.state_dict"], ["", "", "def", "dump_clients", "(", "self", ",", "clients", ")", ":", "\n", "        ", "dumped_clients", "=", "[", "]", "\n", "for", "client", "in", "clients", ":", "\n", "            ", "dumped_clients", ".", "append", "(", "client", ".", "state_dict", "(", ")", ")", "\n", "", "pickle", ".", "dump", "(", "dumped_clients", ",", "open", "(", "osp", ".", "join", "(", "self", ".", "ck_fd", ",", "Logger", ".", "CLIENTS_FN", ")", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.reserve_checkpoint": [[114, 118], ["logger.Logger.load_checkpoint_round", "shutil.copytree", "os.join", "os.join", "os.split", "os.split", "os.split", "os.split"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.load_checkpoint_round"], ["", "def", "reserve_checkpoint", "(", "self", ")", ":", "\n", "        ", "checkpoint_round", "=", "self", ".", "load_checkpoint_round", "(", ")", "\n", "shutil", ".", "copytree", "(", "self", ".", "father_fd", ",", "osp", ".", "join", "(", "osp", ".", "split", "(", "self", ".", "father_fd", ")", "[", "0", "]", ",", "\n", "osp", ".", "split", "(", "self", ".", "father_fd", ")", "[", "1", "]", "+", "f\"_step{checkpoint_round}\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.load_checkpoint_round": [[119, 124], ["logger.Logger.has_checkpoint", "logger.Logger.load_meta"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.has_checkpoint", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.load_meta"], ["", "def", "load_checkpoint_round", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "has_checkpoint", "(", ")", ":", "\n", "            ", "return", "self", ".", "load_meta", "(", ")", "[", "'current_round'", "]", "\n", "", "else", ":", "\n", "            ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar": [[125, 130], ["logger.Logger.summaryWriter.add_scalar", "log_f.write"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar"], ["", "", "def", "add_scalar", "(", "self", ",", "tag", ",", "scalar", ",", "x", ",", "time", "=", "''", ",", "write_file", "=", "True", ")", ":", "\n", "        ", "self", ".", "summaryWriter", ".", "add_scalar", "(", "tag", ",", "scalar", ",", "x", ")", "\n", "if", "write_file", ":", "\n", "            ", "log_f", "=", "self", ".", "log_handlers", "[", "tag", "]", "\n", "log_f", ".", "write", "(", "f\"{time},{x},{scalar}\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_meta": [[131, 138], ["open", "f.write", "f.write", "f.write", "f.write", "os.join", "os.join", "str"], "methods", ["None"], ["", "", "def", "add_meta", "(", "self", ",", "pars", ",", "argv", ",", "current_round", ")", ":", "\n", "        ", "with", "open", "(", "osp", ".", "join", "(", "self", ".", "log_fd", ",", "'meta.txt'", ")", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "f\"Training starts from {current_round}\\n\"", ")", "\n", "command", "=", "'python '", "+", "' '", ".", "join", "(", "argv", ")", "\n", "f", ".", "write", "(", "f\"Command: {command}\\n\"", ")", "\n", "f", ".", "write", "(", "str", "(", "pars", ")", "+", "'\\n'", ")", "\n", "f", ".", "write", "(", "'-'", "*", "80", "+", "'\\n\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_error": [[139, 142], ["open", "f.write", "os.join", "os.join"], "methods", ["None"], ["", "", "def", "add_error", "(", "self", ",", "msg", ")", ":", "\n", "        ", "with", "open", "(", "osp", ".", "join", "(", "self", ".", "log_fd", ",", "'error.txt'", ")", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "msg", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_statistics": [[143, 150], ["print", "open", "f.write", "os.join", "os.join", "f.write", "f.write", "len"], "methods", ["None"], ["", "", "def", "add_statistics", "(", "self", ",", "clients", ",", "c_round", ")", ":", "\n", "        ", "print", "(", "\"log statistics\"", ")", "\n", "with", "open", "(", "osp", ".", "join", "(", "self", ".", "log_fd", ",", "'statistics.txt'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "f\"current_round: {c_round}\\n\"", ")", "\n", "for", "client", "in", "clients", ":", "\n", "                ", "f", ".", "write", "(", "f\"client: {client.id}, r: {client.r}, num_trained: {len(client.train_log)}\\n\"", ")", "\n", "f", ".", "write", "(", "f\"{client.train_log}\\n\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close": [[151, 155], ["logger.Logger.summaryWriter.close", "logger.Logger.log_handlers.items", "_f.close"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close"], ["", "", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "summaryWriter", ".", "close", "(", ")", "\n", "for", "_", ",", "_f", "in", "self", ".", "log_handlers", ".", "items", "(", ")", ":", "\n", "            ", "_f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.flush": [[156, 160], ["logger.Logger.summaryWriter.flush", "logger.Logger.log_handlers.items", "_f.flush"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.flush", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.flush"], ["", "", "def", "flush", "(", "self", ")", ":", "\n", "        ", "self", ".", "summaryWriter", ".", "flush", "(", ")", "\n", "for", "_", ",", "_f", "in", "self", ".", "log_handlers", ".", "items", "(", ")", ":", "\n", "            ", "_f", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger._test": [[162, 167], ["logger.Logger", "logger.Logger.add_scalar", "logger.Logger.add_scalar", "logger.Logger.add_scalar"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar"], ["", "", "", "def", "_test", "(", ")", ":", "\n", "    ", "logger", "=", "Logger", "(", "\"debug\"", ")", "\n", "logger", ".", "add_scalar", "(", "\"toy\"", ",", "100", ",", "0", ",", "0.0", ")", "\n", "logger", ".", "add_scalar", "(", "\"toy\"", ",", "20", ",", "1", ",", "1.0", ")", "\n", "logger", ".", "add_scalar", "(", "\"toy\"", ",", "50", ",", "2", ",", "3.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils._init_paths.add_path": [[5, 8], ["sys.path.insert"], "function", ["None"], ["def", "add_path", "(", "path", ")", ":", "\n", "    ", "if", "path", "not", "in", "sys", ".", "path", ":", "\n", "        ", "sys", ".", "path", ".", "insert", "(", "0", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.load_from_tensorflow.load_embedding": [[13, 19], ["os.join", "pickle.load", "torch.from_numpy", "open"], "function", ["None"], ["def", "load_embedding", "(", "fn", ",", "model_fd", "=", "_model_fd", ")", ":", "\n", "    ", "def", "_init", "(", "m", ")", ":", "\n", "        ", "fp", "=", "osp", ".", "join", "(", "model_fd", ",", "fn", ")", "\n", "weight", "=", "pickle", ".", "load", "(", "open", "(", "fp", ",", "'rb'", ")", ")", "\n", "m", ".", "weight", ".", "data", "[", "...", "]", "=", "torch", ".", "from_numpy", "(", "weight", ")", "\n", "", "return", "_init", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.load_from_tensorflow.load_dice": [[21, 25], ["os.join", "pickle.load", "torch.from_numpy", "open"], "function", ["None"], ["", "def", "load_dice", "(", "fn", ")", ":", "\n", "    ", "fp", "=", "osp", ".", "join", "(", "_model_fd", ",", "fn", ")", "\n", "weight", "=", "pickle", ".", "load", "(", "open", "(", "fp", ",", "'rb'", ")", ")", "\n", "return", "torch", ".", "from_numpy", "(", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.load_from_tensorflow.load_fc": [[27, 36], ["os.join", "os.join", "pickle.load", "pickle.load", "torch.from_numpy", "torch.from_numpy", "open", "open", "pickle.load.transpose"], "function", ["None"], ["", "def", "load_fc", "(", "weight_fn", ",", "bias_fn", ")", ":", "\n", "    ", "def", "_init", "(", "m", ")", ":", "\n", "        ", "weight_fp", "=", "osp", ".", "join", "(", "_model_fd", ",", "weight_fn", ")", "\n", "bias_fp", "=", "osp", ".", "join", "(", "_model_fd", ",", "bias_fn", ")", "\n", "weight", "=", "pickle", ".", "load", "(", "open", "(", "weight_fp", ",", "'rb'", ")", ")", "\n", "bias", "=", "pickle", ".", "load", "(", "open", "(", "bias_fp", ",", "'rb'", ")", ")", "\n", "m", ".", "weight", ".", "data", "[", "...", "]", "=", "torch", ".", "from_numpy", "(", "weight", ".", "transpose", "(", ")", ")", "\n", "m", ".", "bias", ".", "data", "[", "...", "]", "=", "torch", ".", "from_numpy", "(", "bias", ")", "\n", "", "return", "_init", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.load_from_tensorflow.load_bn": [[38, 47], ["os.join", "os.join", "pickle.load", "pickle.load", "torch.from_numpy", "torch.from_numpy", "open", "open", "pickle.load.transpose"], "function", ["None"], ["", "def", "load_bn", "(", "gamma_fn", ",", "beta_fn", ")", ":", "\n", "    ", "def", "_init", "(", "m", ")", ":", "\n", "        ", "gamma_fp", "=", "osp", ".", "join", "(", "_model_fd", ",", "gamma_fn", ")", "\n", "beta_fp", "=", "osp", ".", "join", "(", "_model_fd", ",", "beta_fn", ")", "\n", "gamma", "=", "pickle", ".", "load", "(", "open", "(", "gamma_fp", ",", "'rb'", ")", ")", "\n", "beta", "=", "pickle", ".", "load", "(", "open", "(", "beta_fp", ",", "'rb'", ")", ")", "\n", "m", ".", "weight", ".", "data", "[", "...", "]", "=", "torch", ".", "from_numpy", "(", "gamma", ".", "transpose", "(", ")", ")", "\n", "m", ".", "bias", ".", "data", "[", "...", "]", "=", "torch", ".", "from_numpy", "(", "beta", ")", "\n", "", "return", "_init", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.load_from_tensorflow._test": [[52, 84], ["net.din.user_embedding.apply", "net.din.cat_embedding.apply", "net.din.good_embedding.apply", "net.din.mlp.fc1.apply", "net.din.mlp.fc2.apply", "net.din.mlp.fc3.apply", "net.din.mlp.bn.apply", "load_from_tensorflow.load_dice", "load_from_tensorflow.load_dice", "net.din.attention.fc1.apply", "net.din.attention.fc2.apply", "net.din.attention.fc3.apply", "AlibabaDataset", "torch.utils.data.DataLoader", "net.cuda", "widgets.test_loader", "print", "load_from_tensorflow.load_embedding", "load_from_tensorflow.load_embedding", "load_from_tensorflow.load_embedding", "load_from_tensorflow.load_fc", "load_from_tensorflow.load_fc", "load_from_tensorflow.load_fc", "load_from_tensorflow.load_bn", "load_from_tensorflow.load_fc", "load_from_tensorflow.load_fc", "load_from_tensorflow.load_fc"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.load_from_tensorflow.load_dice", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.load_from_tensorflow.load_dice", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.test_loader", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.load_embedding", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.load_embedding", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.load_embedding", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.load_from_tensorflow.load_fc", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.load_from_tensorflow.load_fc", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.load_from_tensorflow.load_fc", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.load_from_tensorflow.load_bn", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.load_from_tensorflow.load_fc", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.load_from_tensorflow.load_fc", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.load_from_tensorflow.load_fc"], ["def", "_test", "(", ")", ":", "\n", "    ", "net", ".", "din", ".", "user_embedding", ".", "apply", "(", "load_embedding", "(", "\"uid_embedding_var-0_49023-18.pkl\"", ")", ")", "\n", "net", ".", "din", ".", "cat_embedding", ".", "apply", "(", "load_embedding", "(", "\"cat_embedding_var-0_4815-18.pkl\"", ")", ")", "\n", "net", ".", "din", ".", "good_embedding", ".", "apply", "(", "load_embedding", "(", "\"mid_embedding_var-0_143534-18.pkl\"", ")", ")", "\n", "\n", "net", ".", "din", ".", "mlp", ".", "fc1", ".", "apply", "(", "load_fc", "(", "\"f1-kernel-0_162-200.pkl\"", ",", "\"f1-bias-0_200.pkl\"", ")", ")", "\n", "net", ".", "din", ".", "mlp", ".", "fc2", ".", "apply", "(", "load_fc", "(", "\"f2-kernel-0_200-80.pkl\"", ",", "\"f2-bias-0_80.pkl\"", ")", ")", "\n", "net", ".", "din", ".", "mlp", ".", "fc3", ".", "apply", "(", "load_fc", "(", "\"f3-kernel-0_80-2.pkl\"", ",", "\"f3-bias-0_2.pkl\"", ")", ")", "\n", "net", ".", "din", ".", "mlp", ".", "bn", ".", "apply", "(", "load_bn", "(", "\"bn1-gamma-0_162.pkl\"", ",", "\"bn1-beta-0_162.pkl\"", ")", ")", "\n", "net", ".", "din", ".", "mlp", ".", "a1", ".", "weight", ".", "data", "[", "...", "]", "=", "load_dice", "(", "\"dice_1-alphadice_1-0_200.pkl\"", ")", "\n", "net", ".", "din", ".", "mlp", ".", "a2", ".", "weight", ".", "data", "[", "...", "]", "=", "load_dice", "(", "\"dice_2-alphadice_2-0_80.pkl\"", ")", "\n", "\n", "net", ".", "din", ".", "attention", ".", "fc1", ".", "apply", "(", "load_fc", "(", "\"f1_att-kernel-0_144-80.pkl\"", ",", "\"f1_att-bias-0_80.pkl\"", ")", ")", "\n", "net", ".", "din", ".", "attention", ".", "fc2", ".", "apply", "(", "load_fc", "(", "\"f2_att-kernel-0_80-40.pkl\"", ",", "\"f2_att-bias-0_40.pkl\"", ")", ")", "\n", "net", ".", "din", ".", "attention", ".", "fc3", ".", "apply", "(", "load_fc", "(", "\"f3_att-kernel-0_40-1.pkl\"", ",", "\"f3_att-bias-0_1.pkl\"", ")", ")", "\n", "\n", "from", "utils", ".", "alibaba", "import", "AlibabaDataset", ",", "alibaba_train_fp", ",", "alibaba_test_fp", "\n", "import", "utils", ".", "widgets", "as", "widgets", "\n", "# trainset = AlibabaDataset(alibaba_train_fp)", "\n", "testset", "=", "AlibabaDataset", "(", "alibaba_test_fp", ")", "\n", "testloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "testset", ",", "batch_size", "=", "1024", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "AlibabaDataset", ".", "collate_fn", ")", "\n", "test_acc_", ",", "_", "=", "[", "-", "1.", "]", ",", "[", "-", "1.", "]", "\n", "test_loss_", ",", "_", "=", "[", "-", "1.", "]", ",", "[", "-", "1.", "]", "\n", "test_auc_", ",", "_", "=", "[", "-", "1.", "]", ",", "[", "-", "1.", "]", "\n", "net", ".", "cuda", "(", ")", "\n", "widgets", ".", "test_loader", "(", "net", "=", "net", ",", "loader", "=", "testloader", ",", "max_checked", "=", "1200000", ",", "\n", "acc_", "=", "test_acc_", ",", "loss_", "=", "test_loss_", ",", "auc_", "=", "test_auc_", ",", "verbose", "=", "True", ")", "\n", "print", "(", "\"test_acc: %.3f, test_loss: %.3f, test_auc: %.3f\"", "%", "\n", "(", "test_acc_", "[", "0", "]", ",", "test_loss_", "[", "0", "]", ",", "test_auc_", "[", "0", "]", ")", ")", "\n", "\n", "debug", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.__init__": [[40, 63], ["torch.utils.data.Dataset.__init__", "alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.__get_preprocessed_data", "print", "print", "[].date", "[].date", "alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.get_data_start", "alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.get_data_start", "print", "alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.get_client_behaviors", "[].isoformat", "[].isoformat", "len"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.__get_preprocessed_data", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.get_data_start", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.get_data_start", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.get_client_behaviors"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# remap dataset", "\n", "# preprocess DATETIME as datetime, others as int", "\n", "# sort by datetime", "\n", "self", ".", "data", ",", "self", ".", "num_clients", ",", "self", ".", "num_goods", ",", "self", ".", "num_cats", "=", "self", ".", "__get_preprocessed_data", "(", ")", "\n", "print", "(", "f\"number of clients: {self.num_clients}, goods: {self.num_goods}, categories: {self.num_cats}\"", ")", "\n", "\n", "print", "(", "f\"Data collected \"", "\n", "f\"from {self.data[0][AlibabaSourceDatasetForInferAvailability.DATETIME].isoformat(sep=' ')} \"", "\n", "f\"to {self.data[-1][AlibabaSourceDatasetForInferAvailability.DATETIME].isoformat(sep=' ')}\"", ")", "\n", "\n", "# get the first data index in the 15th day", "\n", "# first_date: the date of the first datum", "\n", "self", ".", "first_date", "=", "self", ".", "data", "[", "0", "]", "[", "AlibabaSourceDatasetForInferAvailability", ".", "DATETIME", "]", ".", "date", "(", ")", "\n", "self", ".", "last_date", "=", "self", ".", "data", "[", "-", "1", "]", "[", "AlibabaSourceDatasetForInferAvailability", ".", "DATETIME", "]", ".", "date", "(", ")", "\n", "self", ".", "train_start", "=", "self", ".", "get_data_start", "(", "num_days", "=", "_WINDOW_SIZE", ",", "from_", "=", "14005500", ")", "# 15005575", "\n", "self", ".", "test_start", "=", "self", ".", "get_data_start", "(", "num_days", "=", "(", "self", ".", "last_date", "-", "self", ".", "first_date", ")", ".", "days", ",", "from_", "=", "28000000", ")", "# 31312950", "\n", "print", "(", "f\"training data from {self.train_start}, test data from {self.test_start}, total data {len(self.data)}\"", ")", "\n", "\n", "# get the clients", "\n", "self", ".", "client_behaviors", "=", "self", ".", "get_client_behaviors", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.__len__": [[64, 66], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.__getitem__": [[67, 84], ["torch.from_numpy", "torch.from_numpy", "numpy.array", "numpy.array", "datum[].date"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "datum", "=", "self", ".", "data", "[", "item", "]", "\n", "uid", "=", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "CLIENT", "]", "\n", "gid", "=", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "GOOD", "]", "\n", "cid", "=", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "CATEGORY", "]", "\n", "\n", "client_behavior", "=", "self", ".", "client_behaviors", "[", "uid", "]", "\n", "end_day", "=", "(", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "DATETIME", "]", ".", "date", "(", ")", "-", "self", ".", "first_date", ")", ".", "days", "# not included", "\n", "start_day", "=", "end_day", "-", "_WINDOW_SIZE", "\n", "gid_his", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "[", "gid", "for", "day", ",", "gid", ",", "cid", "in", "client_behavior", "if", "start_day", "<=", "day", "<", "end_day", "]", ",", "\n", "dtype", "=", "np", ".", "int64", ")", ")", "\n", "cid_his", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "[", "cid", "for", "day", ",", "gid", ",", "cid", "in", "client_behavior", "if", "start_day", "<=", "day", "<", "end_day", "]", ",", "\n", "dtype", "=", "np", ".", "int64", ")", ")", "\n", "\n", "click", "=", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "CLK", "]", "\n", "\n", "return", "uid", ",", "gid", ",", "cid", ",", "gid_his", ",", "cid_his", ",", "click", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.get_clients_available": [[85, 135], ["enumerate", "matplotlib.pyplot.figure", "enumerate", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "isinstance", "enumerate", "utils.sentiment140.time2int", "clients_click_seconds[].append", "matplotlib.pyplot.scatter", "os.join", "alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.get_clients_available.ratio2availability"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.time2int"], ["", "def", "get_clients_available", "(", "self", ",", "ratio2availability", "=", "lambda", "x", ":", "8", "*", "3600", ")", ":", "\n", "        ", "\"\"\"\n        :param ratio2availability: a function, input is positive click ratio, output is number of *seconds* to be available\n        :return: an array of client sleeping time (start, end), unit: seconds, array indexed by client id (remaped)\n        \"\"\"", "\n", "clients_click_seconds", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "num_clients", ")", "]", "\n", "\n", "id2posi", "=", "[", "0", "for", "_", "in", "range", "(", "self", ".", "num_clients", ")", "]", "\n", "id2total", "=", "[", "0", "for", "_", "in", "range", "(", "self", ".", "num_clients", ")", "]", "\n", "for", "idx", ",", "datum", "in", "enumerate", "(", "self", ".", "data", ")", ":", "\n", "            ", "client_id", "=", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "CLIENT", "]", "\n", "click_time", "=", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "DATETIME", "]", "\n", "click_time", "=", "time2int", "(", "click_time", ")", "\n", "clients_click_seconds", "[", "client_id", "]", ".", "append", "(", "click_time", ")", "\n", "\n", "id2total", "[", "client_id", "]", "+=", "1", "\n", "if", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "CLK", "]", "==", "1", ":", "\n", "                ", "id2posi", "[", "client_id", "]", "+=", "1", "\n", "", "", "id2ratio", "=", "[", "posi", "/", "(", "total", "+", "1e-7", ")", "for", "posi", ",", "total", "in", "zip", "(", "id2posi", ",", "id2total", ")", "]", "\n", "# print(id2ratio)", "\n", "plt", ".", "figure", "(", "0", ")", "\n", "for", "idx", ",", "ratio", "in", "enumerate", "(", "id2ratio", ")", ":", "\n", "            ", "plt", ".", "scatter", "(", "random", ".", "random", "(", ")", ",", "ratio", ")", "\n", "if", "idx", ">=", "1000", ":", "\n", "                ", "break", "\n", "", "", "plt", ".", "savefig", "(", "osp", ".", "join", "(", "common", ".", "figure_fd", ",", "'client_positive_ratio.png'", ")", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n", "num_seconds_day", "=", "24", "*", "3600", "\n", "if", "isinstance", "(", "ratio2availability", ",", "tuple", ")", ":", "\n", "            ", "if", "ratio2availability", "[", "0", "]", "==", "'uniform_map'", ":", "\n", "                ", "function", ",", "range_min", ",", "range_max", ",", "max_clip", "=", "ratio2availability", "\n", "ratio_min", "=", "min", "(", "id2ratio", ")", "\n", "ratio_max", "=", "min", "(", "max", "(", "id2ratio", ")", ",", "max_clip", ")", "\n", "print", "(", "f\"ration_min={ratio_min}, ratio_max={ratio_max}\"", ")", "\n", "\n", "def", "ratio2availability", "(", "_ratio", ")", ":", "\n", "                    ", "return", "(", "min", "(", "_ratio", ",", "max_clip", ")", "-", "ratio_min", ")", "*", "(", "range_max", "-", "range_min", ")", "/", "(", "ratio_max", "-", "ratio_min", ")", "+", "range_min", "\n", "", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Unaccepted {ratio2availability}\"", ")", "\n", "", "", "client_available", "=", "[", "None", "for", "_", "in", "range", "(", "self", ".", "num_clients", ")", "]", "\n", "for", "client_id", ",", "click_time", "in", "enumerate", "(", "clients_click_seconds", ")", ":", "\n", "            ", "posi_ratio", "=", "id2ratio", "[", "client_id", "]", "\n", "num_seconds_sleep", "=", "ratio2availability", "(", "posi_ratio", ")", "\n", "if", "len", "(", "click_time", ")", "!=", "0", ":", "\n", "                ", "sleep_range", "=", "infer_sleep", "(", "click_time", ",", "num_seconds_day", "=", "num_seconds_day", ",", "num_seconds_sleep", "=", "num_seconds_sleep", ")", "\n", "", "else", ":", "\n", "                ", "sleep_range", "=", "(", "0", ",", "num_seconds_sleep", ")", "\n", "", "client_available", "[", "client_id", "]", "=", "sleep_range", "\n", "", "return", "client_available", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.get_clients_available_block": [[136, 167], ["random.seed", "dict", "enumerate", "enumerate", "dict", "range", "set", "range", "utils.sentiment140.time2int", "range", "len", "random.randint", "clients_available_block[].append", "clients_available_block[].append", "dict.get", "clients_available_block[].append"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.time2int"], ["", "def", "get_clients_available_block", "(", "self", ",", "num_hours1block", ",", "include_neg", "=", "False", ",", "thres", "=", "1", ",", "reverse", "=", "False", ")", ":", "\n", "        ", "random", ".", "seed", "(", "1", ")", "\n", "clients_available_block", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "num_clients", ")", "]", "\n", "client_block2count", "=", "dict", "(", ")", "\n", "for", "idx", ",", "datum", "in", "enumerate", "(", "self", ".", "data", ")", ":", "\n", "            ", "if", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "CLK", "]", "==", "1", "or", "include_neg", ":", "\n", "                ", "client_id", "=", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "CLIENT", "]", "\n", "click_time", "=", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "DATETIME", "]", "\n", "click_time", "=", "time2int", "(", "click_time", ")", "\n", "click_hour", "=", "click_time", "//", "3600", "\n", "click_block", "=", "click_hour", "//", "num_hours1block", "\n", "if", "(", "client_id", ",", "click_block", ")", "not", "in", "client_block2count", ":", "\n", "                    ", "client_block2count", "[", "(", "client_id", ",", "click_block", ")", "]", "=", "0", "\n", "", "client_block2count", "[", "(", "client_id", ",", "click_block", ")", "]", "+=", "1", "\n", "", "", "if", "not", "reverse", ":", "\n", "            ", "for", "client_id", ",", "click_block", "in", "client_block2count", ":", "\n", "                ", "if", "client_block2count", "[", "(", "client_id", ",", "click_block", ")", "]", ">=", "thres", ":", "\n", "                    ", "clients_available_block", "[", "client_id", "]", ".", "append", "(", "click_block", ")", "\n", "", "", "", "else", ":", "\n", "            ", "for", "client_id", "in", "range", "(", "self", ".", "num_clients", ")", ":", "\n", "                ", "for", "click_block", "in", "range", "(", "24", "//", "num_hours1block", ")", ":", "\n", "                    ", "if", "client_block2count", ".", "get", "(", "(", "client_id", ",", "click_block", ")", ",", "0", ")", "<=", "thres", ":", "\n", "                        ", "clients_available_block", "[", "client_id", "]", ".", "append", "(", "click_block", ")", "\n", "", "", "", "", "for", "idx", ",", "ab", "in", "enumerate", "(", "clients_available_block", ")", ":", "\n", "            ", "if", "len", "(", "ab", ")", "==", "0", ":", "\n", "                ", "click_time", "=", "random", ".", "randint", "(", "0", ",", "3600", "*", "24", "-", "1", ")", "\n", "click_hour", "=", "click_time", "//", "3600", "\n", "client_block", "=", "click_hour", "//", "num_hours1block", "\n", "clients_available_block", "[", "idx", "]", ".", "append", "(", "client_block", ")", "\n", "", "", "clients_available_block", "=", "[", "set", "(", "x", ")", "for", "x", "in", "clients_available_block", "]", "\n", "return", "dict", "(", "content", "=", "clients_available_block", ",", "type", "=", "'block'", ",", "num_hours1block", "=", "num_hours1block", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.__get_preprocessed_data": [[168, 261], ["os.exists", "dict", "open", "print", "sorted", "len", "len", "len", "pickle.dump", "print", "pickle.load", "print", "dict", "dict", "dict", "line.strip().split.strip().split.strip().split", "open", "print", "print", "open", "open", "pickle.load", "pickle.load", "pickle.load", "ValueError", "int", "int", "open", "enumerate", "open", "open", "open", "line.strip().split.strip().split.strip", "print", "line.strip().split.strip().split.strip().split", "alibaba_get_availability.str2datetime", "int", "pickle.load.get", "pickle.load.get", "sorted.append", "f_out.write", "int", "print", "print", "line.strip().split.strip().split.strip", "print", "print", "print", "int", "print", "str2datetime.isoformat", "str", "str", "str", "str", "int"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba_get_availability.str2datetime"], ["", "@", "staticmethod", "\n", "def", "__get_preprocessed_data", "(", "map_", "=", "\"load\"", ")", ":", "\n", "        ", "if", "not", "osp", ".", "exists", "(", "common", ".", "alibaba_new_fp", ")", ":", "\n", "            ", "c_client", "=", "0", "\n", "c_good", "=", "0", "\n", "c_cat", "=", "0", "\n", "if", "map_", "==", "\"generate\"", ":", "\n", "                ", "client_map", "=", "dict", "(", ")", "\n", "good_map", "=", "dict", "(", ")", "\n", "cat_map", "=", "dict", "(", ")", "\n", "", "elif", "map_", "==", "\"load\"", ":", "\n", "                ", "client_map", "=", "pickle", ".", "load", "(", "open", "(", "common", ".", "alibaba_uid_map_fp", ",", "'rb'", ")", ")", "\n", "good_map", "=", "pickle", ".", "load", "(", "open", "(", "common", ".", "alibaba_gid_map_fp", ",", "'rb'", ")", ")", "\n", "cat_map", "=", "pickle", ".", "load", "(", "open", "(", "common", ".", "alibaba_cid_map_fp", ",", "'rb'", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"unrecognized map_={map_}\"", ")", "\n", "\n", "# get the original gid-cid map", "\n", "", "good2cat_original", "=", "dict", "(", ")", "\n", "for", "line", "in", "open", "(", "common", ".", "alibaba_meta_fp", ",", "'r'", ")", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "'\\t'", ")", "\n", "gid", ",", "cid", "=", "line", "\n", "gid", ",", "cid", "=", "int", "(", "gid", ")", ",", "int", "(", "cid", ")", "\n", "if", "gid", "not", "in", "good2cat_original", ":", "\n", "                    ", "good2cat_original", "[", "gid", "]", "=", "cid", "\n", "", "else", ":", "\n", "                    ", "if", "good2cat_original", "[", "gid", "]", "!=", "cid", ":", "\n", "                        ", "print", "(", "f\"the good {gid} has multiple categories ({cid} and {good2cat_original[gid]})\"", ")", "\n", "\n", "", "", "", "processed_data", "=", "[", "]", "\n", "with", "open", "(", "common", ".", "alibaba_fp", ",", "'r'", ")", "as", "f_in", ":", "\n", "                ", "with", "open", "(", "common", ".", "alibaba_new_fp_csv", ",", "'w'", ")", "as", "f_out", ":", "\n", "                    ", "for", "line_idx", ",", "line", "in", "enumerate", "(", "f_in", ")", ":", "\n", "                        ", "line", "=", "line", ".", "strip", "(", "'\\n'", ")", ".", "split", "(", "'\\t'", ")", "\n", "dtime", "=", "str2datetime", "(", "line", "[", "AlibabaSourceDatasetForInferAvailability", ".", "DATETIME", "]", ")", "\n", "click", "=", "int", "(", "line", "[", "AlibabaSourceDatasetForInferAvailability", ".", "CLK", "]", ")", "\n", "client_id", "=", "line", "[", "AlibabaSourceDatasetForInferAvailability", ".", "CLIENT", "]", "\n", "good_id", "=", "line", "[", "AlibabaSourceDatasetForInferAvailability", ".", "GOOD", "]", "\n", "cat_id", "=", "line", "[", "AlibabaSourceDatasetForInferAvailability", ".", "CATEGORY", "]", "\n", "\n", "# check meta", "\n", "if", "good2cat_original", "[", "int", "(", "good_id", ")", "]", "!=", "int", "(", "cat_id", ")", ":", "\n", "                            ", "print", "(", "f\"good {good_id} is mapped to category {good2cat_original[int(good_id)]} in the meta\"", "\n", "f\" but recorded as {cat_id} in line {line_idx}\"", ")", "\n", "\n", "", "if", "map_", "==", "'generate'", ":", "\n", "                            ", "if", "client_id", "not", "in", "client_map", ":", "\n", "                                ", "client_map", "[", "client_id", "]", "=", "c_client", "\n", "c_client", "+=", "1", "\n", "", "if", "good_id", "not", "in", "good_map", ":", "\n", "                                ", "good_map", "[", "good_id", "]", "=", "c_good", "\n", "c_good", "+=", "1", "\n", "", "if", "cat_id", "not", "in", "cat_map", ":", "\n", "                                ", "cat_map", "[", "cat_id", "]", "=", "c_cat", "\n", "c_cat", "+=", "1", "\n", "", "", "if", "map_", "==", "'load'", ":", "\n", "                            ", "if", "good_id", "not", "in", "good_map", ":", "\n", "                                ", "print", "(", "f\"{good_id} not in good_map\"", ",", "end", "=", "''", ")", "\n", "if", "client_id", "not", "in", "client_map", ":", "\n", "                                    ", "print", "(", "f\", the corresponding client {client_id} also not\"", ",", "end", "=", "\"\"", ")", "\n", "", "print", "(", ")", "\n", "c_good", "+=", "1", "\n", "", "if", "cat_id", "not", "in", "cat_map", ":", "\n", "                                ", "print", "(", "f\"{cat_id} not in cat_map\"", ")", "\n", "c_cat", "+=", "1", "\n", "", "if", "client_id", "not", "in", "client_map", ":", "\n", "                                ", "c_client", "+=", "1", "\n", "# ignore this datum if the client is not in the map", "\n", "continue", "\n", "", "", "client_id", "=", "client_map", "[", "client_id", "]", "\n", "good_id", "=", "good_map", ".", "get", "(", "good_id", ",", "0", ")", "\n", "cat_id", "=", "cat_map", ".", "get", "(", "cat_id", ",", "0", ")", "\n", "\n", "processed_data", ".", "append", "(", "[", "dtime", ",", "click", ",", "client_id", ",", "good_id", ",", "cat_id", "]", ")", "\n", "f_out", ".", "write", "(", "','", ".", "join", "(", "[", "dtime", ".", "isoformat", "(", "sep", "=", "' '", ")", ",", "str", "(", "click", ")", ",", "str", "(", "client_id", ")", ",", "str", "(", "good_id", ")", ",", "str", "(", "cat_id", ")", "]", ")", "+", "'\\n'", ")", "\n", "if", "line_idx", "%", "10000", "==", "0", ":", "\n", "                            ", "print", "(", "f\"{line_idx}/32345219 lines processed\"", ",", "end", "=", "'\\r'", ")", "\n", "", "", "", "", "if", "map_", "==", "'load'", ":", "\n", "                ", "print", "(", "f\"count not in voc\"", ")", "\n", "print", "(", "f\"number of clients: {c_client}, goods: {c_good}, categories: {c_cat}\"", ")", "\n", "", "print", "(", "\"data preprocessed\"", ")", "\n", "processed_data", "=", "sorted", "(", "processed_data", ",", "key", "=", "lambda", "x", ":", "x", "[", "AlibabaSourceDatasetForInferAvailability", ".", "DATETIME", "]", ")", "\n", "num_clients", "=", "len", "(", "client_map", ")", "\n", "num_goods", "=", "len", "(", "good_map", ")", "\n", "num_cats", "=", "len", "(", "cat_map", ")", "\n", "pickle", ".", "dump", "(", "(", "processed_data", ",", "num_clients", ",", "num_goods", ",", "num_cats", ")", ",", "\n", "open", "(", "common", ".", "alibaba_new_fp", ",", "'wb'", ")", ")", "\n", "data", "=", "processed_data", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"loading preprocessed data file...\"", ")", "\n", "data", ",", "num_clients", ",", "num_goods", ",", "num_cats", "=", "pickle", ".", "load", "(", "open", "(", "common", ".", "alibaba_new_fp", ",", "'rb'", ")", ")", "\n", "print", "(", "\"loaded\"", ")", "\n", "", "return", "data", ",", "num_clients", ",", "num_goods", ",", "num_cats", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.get_data_start": [[262, 271], ["first_datetime.date", "enumerate", "RuntimeError", "datum[].date"], "methods", ["None"], ["", "def", "get_data_start", "(", "self", ",", "num_days", ",", "from_", ")", ":", "\n", "        ", "first_datetime", "=", "self", ".", "data", "[", "0", "]", "[", "AlibabaSourceDatasetForInferAvailability", ".", "DATETIME", "]", "\n", "first_date", "=", "first_datetime", ".", "date", "(", ")", "\n", "for", "idx", ",", "datum", "in", "enumerate", "(", "self", ".", "data", "[", "from_", ":", "]", ",", "start", "=", "from_", ")", ":", "\n", "            ", "if", "(", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "DATETIME", "]", ".", "date", "(", ")", "-", "first_date", ")", ".", "days", ">=", "num_days", ":", "\n", "                ", "if", "idx", "==", "from_", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\"A wrong data_start may be generated because of too large from_\"", ")", "\n", "", "else", ":", "\n", "                    ", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.get_client_behaviors": [[272, 283], ["range", "client_behaviors[].append", "datum[].date"], "methods", ["None"], ["", "", "", "", "def", "get_client_behaviors", "(", "self", ")", ":", "\n", "        ", "client_behaviors", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "num_clients", ")", "]", "\n", "for", "datum", "in", "self", ".", "data", ":", "\n", "            ", "if", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "CLK", "]", "==", "1", ":", "\n", "                ", "client_id", "=", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "CLIENT", "]", "\n", "good_id", "=", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "GOOD", "]", "\n", "cat_id", "=", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "CATEGORY", "]", "\n", "days", "=", "(", "datum", "[", "AlibabaSourceDatasetForInferAvailability", ".", "DATETIME", "]", ".", "date", "(", ")", "-", "self", ".", "first_date", ")", ".", "days", "\n", "# noinspection PyTypeChecker", "\n", "client_behaviors", "[", "client_id", "]", ".", "append", "(", "(", "days", ",", "good_id", ",", "cat_id", ")", ")", "\n", "", "", "return", "client_behaviors", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba_get_availability.str2datetime": [[25, 33], ["datetime.datetime", "int", "int", "int", "int", "int", "int"], "function", ["None"], ["def", "str2datetime", "(", "dtime", ")", ":", "\n", "    ", "return", "datetime", ".", "datetime", "(", "\n", "year", "=", "int", "(", "dtime", "[", ":", "4", "]", ")", ",", "\n", "month", "=", "int", "(", "dtime", "[", "4", ":", "6", "]", ")", ",", "\n", "day", "=", "int", "(", "dtime", "[", "6", ":", "8", "]", ")", ",", "\n", "hour", "=", "int", "(", "dtime", "[", "8", ":", "10", "]", ")", ",", "\n", "minute", "=", "int", "(", "dtime", "[", "11", ":", "13", "]", ")", ",", "\n", "second", "=", "int", "(", "dtime", "[", "14", ":", "16", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba_get_availability._test": [[285, 314], ["alibaba_get_availability.AlibabaSourceDatasetForInferAvailability", "alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.get_clients_available_block", "matplotlib.pyplot.figure", "enumerate", "matplotlib.pyplot.savefig", "matplotlib.pyplot.close", "pickle.dump", "utils.alibaba.get_clients", "utils.sentiment140.plot_availability_count", "utils.widgets.plot_time2available_data_ratio", "len", "matplotlib.pyplot.scatter", "os.join", "open", "os.join", "random.random", "os.join"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba_get_availability.AlibabaSourceDatasetForInferAvailability.get_clients_available_block", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.close", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.get_clients", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.plot_availability_count", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.plot_time2available_data_ratio"], ["", "", "def", "_test", "(", ")", ":", "\n", "    ", "ali_dataset", "=", "AlibabaSourceDatasetForInferAvailability", "(", ")", "\n", "\n", "# available_min, available_max = 4*3600, 24*3600", "\n", "# max_clip = 1.0", "\n", "# client_available = ali_dataset.get_clients_available(ratio2availability=('uniform_map', available_min, available_max, max_clip))", "\n", "\n", "num_blocks", "=", "6", "\n", "include_neg", "=", "True", "\n", "thres", "=", "16", "\n", "reverse", "=", "True", "\n", "client_available", "=", "ali_dataset", ".", "get_clients_available_block", "(", "24", "//", "num_blocks", ",", "include_neg", "=", "include_neg", ",", "thres", "=", "thres", ",", "reverse", "=", "reverse", ")", "\n", "plt", ".", "figure", "(", "1", ")", "\n", "for", "idx", ",", "ab", "in", "enumerate", "(", "client_available", "[", "'content'", "]", ")", ":", "\n", "        ", "duration", "=", "len", "(", "ab", ")", "\n", "plt", ".", "scatter", "(", "random", ".", "random", "(", ")", ",", "duration", ")", "\n", "if", "idx", ">=", "1000", ":", "\n", "            ", "break", "\n", "", "", "plt", ".", "savefig", "(", "osp", ".", "join", "(", "common", ".", "figure_fd", ",", "\"availability_duration.png\"", ")", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n", "availability_file", "=", "f\"client_available_nb{num_blocks}_in{include_neg}_th{thres}_r{reverse}.pkl\"", "\n", "pickle", ".", "dump", "(", "client_available", ",", "open", "(", "osp", ".", "join", "(", "common", ".", "cache_fd", ",", "availability_file", ")", ",", "'wb'", ")", ")", "\n", "\n", "clients", "=", "get_clients", "(", "osp", ".", "join", "(", "common", ".", "alibaba_fd", ",", "\"32_512\"", ")", ",", "num_clients", "=", "1000", ",", "\n", "availability_file", "=", "availability_file", "[", ":", "-", "4", "]", ")", "\n", "sentiment140", ".", "plot_availability_count", "(", "clients", ")", "\n", "widgets", ".", "plot_time2available_data_ratio", "(", "clients", ",", "fn_abs", "=", "f\"time2available_data_abs_{availability_file}.png\"", ",", "\n", "fn_ratio", "=", "f\"time2available_data_ratio_{availability_file}.png\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.Dice.__init__": [[21, 25], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "num_features", ")", ".", "fill_", "(", "0.25", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "num_features", ",", "momentum", "=", "0.0", ",", "eps", "=", "1e-9", ",", "affine", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.Dice.forward": [[26, 31], ["din.Dice.bn", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "inp_normed", "=", "self", ".", "bn", "(", "inp", ")", "\n", "prob", "=", "torch", ".", "sigmoid", "(", "inp_normed", ")", "\n", "inp", "=", "prob", "*", "inp", "+", "(", "1", "-", "prob", ")", "*", "inp", "*", "self", ".", "weight", "\n", "return", "inp", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.MLP.__init__": [[34, 51], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.PReLU", "din.Dice", "din.Dice", "ValueError"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embedding_dim", ",", "hidden_size", "=", "(", "200", ",", "80", ")", ",", "activation", "=", "'PReLU'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "input_size", "=", "embedding_dim", "*", "9", "\n", "# self.bn = nn.BatchNorm1d(num_features=input_size, momentum=0.99, eps=0.001)", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", "[", "0", "]", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_size", "[", "0", "]", ",", "hidden_size", "[", "1", "]", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "hidden_size", "[", "1", "]", ",", "2", ")", "\n", "\n", "if", "activation", "==", "'PReLU'", ":", "\n", "            ", "self", ".", "a1", "=", "nn", ".", "PReLU", "(", "hidden_size", "[", "0", "]", ")", "\n", "self", ".", "a2", "=", "nn", ".", "PReLU", "(", "hidden_size", "[", "1", "]", ")", "\n", "", "elif", "activation", "==", "'Dice'", ":", "\n", "            ", "self", ".", "a1", "=", "Dice", "(", "hidden_size", "[", "0", "]", ")", "\n", "self", ".", "a2", "=", "Dice", "(", "hidden_size", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unrecognized activation: {activation}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.MLP.forward": [[52, 58], ["din.MLP.a1", "din.MLP.a2", "din.MLP.fc3", "din.MLP.fc1", "din.MLP.fc2"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# x = self.bn(x)", "\n", "        ", "x", "=", "self", ".", "a1", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "a2", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "fc3", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.UserEmbeddingAttentionLayer.__init__": [[61, 68], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embedding_dim", ",", "hidden_size", "=", "(", "80", ",", "40", ")", ",", "activation", "=", "torch", ".", "sigmoid", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "embedding_dim", "*", "8", ",", "hidden_size", "[", "0", "]", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_size", "[", "0", "]", ",", "hidden_size", "[", "1", "]", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "hidden_size", "[", "1", "]", ",", "1", ")", "\n", "self", ".", "activation", "=", "activation", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.UserEmbeddingAttentionLayer.forward": [[69, 102], ["queries.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.functional.softmax.view", "torch.nn.functional.softmax.view", "din.UserEmbeddingAttentionLayer.activation", "din.UserEmbeddingAttentionLayer.activation", "din.UserEmbeddingAttentionLayer.fc3", "torch.nn.functional.softmax.view", "torch.nn.functional.softmax.view", "masks.unsqueeze().to.unsqueeze().to.unsqueeze().to", "torch.where", "torch.where", "torch.where", "torch.where", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "user_behaviors.sum.sum.sum", "din.UserEmbeddingAttentionLayer.fc1", "din.UserEmbeddingAttentionLayer.fc2", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "queries.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "masks.unsqueeze().to.unsqueeze().to.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "queries", ",", "user_behaviors", ",", "masks", ")", ":", "\n", "        ", "\"\"\"\n        :param queries: (B, 2D)\n        :param user_behaviors: (B, L, 2D) L is the maximum length\n        :param masks: (B, L) 1 for valid behavior (0 for padded)\n        :return: user embeddings (B, 2D)\n        \"\"\"", "\n", "# (B, L, 2D)", "\n", "queries", "=", "queries", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "user_behaviors", ".", "shape", "[", "1", "]", ",", "1", ")", "\n", "B", ",", "L", ",", "_D", "=", "queries", ".", "shape", "\n", "D", "=", "_D", "//", "2", "\n", "\n", "# initial scores for attention input", "\n", "scores", "=", "torch", ".", "cat", "(", "[", "queries", ",", "user_behaviors", ",", "queries", "-", "user_behaviors", ",", "queries", "*", "user_behaviors", "]", ",", "dim", "=", "2", ")", "\n", "scores", "=", "scores", ".", "view", "(", "-", "1", ",", "D", "*", "8", ")", "\n", "scores", "=", "self", ".", "activation", "(", "self", ".", "fc1", "(", "scores", ")", ")", "\n", "scores", "=", "self", ".", "activation", "(", "self", ".", "fc2", "(", "scores", ")", ")", "\n", "# B L 1", "\n", "scores", "=", "self", ".", "fc3", "(", "scores", ")", "\n", "scores", "=", "scores", ".", "view", "(", "B", ",", "L", ",", "1", ")", "\n", "\n", "# softmax the score", "\n", "masks", "=", "masks", ".", "unsqueeze", "(", "-", "1", ")", ".", "to", "(", "dtype", "=", "torch", ".", "bool", ")", "\n", "paddings", "=", "torch", ".", "ones_like", "(", "scores", ")", "*", "(", "-", "2", "**", "32", "+", "1", ")", "\n", "# zero out padded behaviors", "\n", "scores", "=", "torch", ".", "where", "(", "masks", ",", "scores", ",", "paddings", ")", "\n", "scores", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "scores", ",", "dim", "=", "1", ")", "\n", "\n", "# apply attention and mask", "\n", "user_behaviors", "=", "scores", "*", "user_behaviors", "\n", "user_behaviors", "=", "user_behaviors", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "return", "user_behaviors", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.DeepInterestNetwork.__init__": [[105, 116], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "din.MLP", "din.UserEmbeddingAttentionLayer"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_users", "=", "49023", ",", "num_goods", "=", "143534", ",", "num_cats", "=", "4815", ",", "embedding_dim", "=", "18", ",", "activation", "=", "'PReLU'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_users", ",", "self", ".", "num_goods", ",", "self", ".", "num_cats", ",", "self", ".", "embedding_dim", "=", "num_users", ",", "num_goods", ",", "num_cats", ",", "embedding_dim", "\n", "self", ".", "activation", "=", "activation", "\n", "\n", "self", ".", "user_embedding", "=", "nn", ".", "Embedding", "(", "num_users", ",", "embedding_dim", ")", "\n", "self", ".", "good_embedding", "=", "nn", ".", "Embedding", "(", "num_goods", ",", "embedding_dim", ")", "\n", "self", ".", "cat_embedding", "=", "nn", ".", "Embedding", "(", "num_cats", ",", "embedding_dim", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "embedding_dim", "=", "embedding_dim", ",", "activation", "=", "activation", ")", "\n", "self", ".", "attention", "=", "UserEmbeddingAttentionLayer", "(", "embedding_dim", "=", "embedding_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.DeepInterestNetwork.forward": [[117, 143], ["din.DeepInterestNetwork.user_embedding", "din.DeepInterestNetwork.good_embedding", "din.DeepInterestNetwork.cat_embedding", "din.DeepInterestNetwork.good_embedding", "din.DeepInterestNetwork.cat_embedding", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "din.DeepInterestNetwork.attention", "torch.cat.sum", "torch.cat.sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "din.DeepInterestNetwork.mlp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "uid_b", ",", "gid_b", ",", "cid_b", ",", "gid_his_b", ",", "cid_his_b", ",", "masks", ")", ":", "\n", "        ", "\"\"\"\n        :param uid_b: (B) user ids batch\n        :param gid_b: (B) good ids batch\n        :param cid_b: (B) category ids batch\n        :param gid_his_b: (B, L) interacted good ids batch, padded\n        :param cid_his_b: (B, L) interacted category ids batch, padded\n        :param masks: (B, L) mask for interacted goods\n        :return: CTR (direct output of self.mlp, not softmaxed)\n        \"\"\"", "\n", "user_b", "=", "self", ".", "user_embedding", "(", "uid_b", ")", "\n", "good_b", "=", "self", ".", "good_embedding", "(", "gid_b", ")", "\n", "cat_b", "=", "self", ".", "cat_embedding", "(", "cid_b", ")", "\n", "good_his_b", "=", "self", ".", "good_embedding", "(", "gid_his_b", ")", "\n", "cat_his_b", "=", "self", ".", "cat_embedding", "(", "cid_his_b", ")", "\n", "\n", "query_b", "=", "torch", ".", "cat", "(", "[", "good_b", ",", "cat_b", "]", ",", "dim", "=", "-", "1", ")", "\n", "user_behaviors", "=", "torch", ".", "cat", "(", "[", "good_his_b", ",", "cat_his_b", "]", ",", "dim", "=", "-", "1", ")", "\n", "attention_output", "=", "self", ".", "attention", "(", "query_b", ",", "user_behaviors", ",", "masks", ")", "\n", "\n", "user_behaviors_sum_b", "=", "user_behaviors", ".", "sum", "(", "dim", "=", "1", ")", "\n", "mlp_input", "=", "torch", ".", "cat", "(", "[", "user_b", ",", "query_b", ",", "user_behaviors_sum_b", ",", "user_behaviors_sum_b", "*", "query_b", ",", "attention_output", "]", ",", "\n", "dim", "=", "-", "1", ")", "\n", "mlp_output", "=", "self", ".", "mlp", "(", "mlp_input", ")", "\n", "mlp_output", "=", "mlp_output", "# to compat the loaded weight from tensorflow", "\n", "return", "mlp_output", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.DeepInterestNetworkFixEmb.__init__": [[146, 170], ["torch.Module.__init__", "dict", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "din.DeepInterestNetworkFixEmb.embeddings[].apply", "din.DeepInterestNetworkFixEmb.embeddings[].apply", "din.DeepInterestNetworkFixEmb.embeddings[].apply", "din.DeepInterestNetworkFixEmb.embeddings.items", "din.MLP", "din.UserEmbeddingAttentionLayer", "din.load_embedding", "din.load_embedding", "din.load_embedding", "emb.to", "emb.parameters"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.load_embedding", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.load_embedding", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.load_embedding"], ["    ", "def", "__init__", "(", "self", ",", "din_source", ":", "DeepInterestNetwork", ",", "copy_pars", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embeddings", "=", "dict", "(", "user", "=", "None", ",", "good", "=", "None", ",", "cat", "=", "None", ")", "\n", "if", "copy_pars", ":", "\n", "            ", "self", ".", "embeddings", "[", "'user'", "]", "=", "copy", ".", "deepcopy", "(", "din_source", ".", "user_embedding", ")", "\n", "self", ".", "embeddings", "[", "'good'", "]", "=", "copy", ".", "deepcopy", "(", "din_source", ".", "good_embedding", ")", "\n", "self", ".", "embeddings", "[", "'cat'", "]", "=", "copy", ".", "deepcopy", "(", "din_source", ".", "cat_embedding", ")", "\n", "self", ".", "mlp", "=", "copy", ".", "deepcopy", "(", "din_source", ".", "mlp", ")", "\n", "self", ".", "attention", "=", "copy", ".", "deepcopy", "(", "din_source", ".", "attention", ")", "\n", "", "else", ":", "\n", "            ", "ub_fn", ",", "gb_fn", ",", "cb_fn", "=", "\"user_embedding.pkl\"", ",", "\"good_embedding.pkl\"", ",", "\"cat_embedding.pkl\"", "\n", "model_fd", "=", "common", ".", "cache_fd", "\n", "self", ".", "embeddings", "[", "'user'", "]", "=", "nn", ".", "Embedding", "(", "din_source", ".", "num_users", ",", "din_source", ".", "embedding_dim", ")", "\n", "self", ".", "embeddings", "[", "'good'", "]", "=", "nn", ".", "Embedding", "(", "din_source", ".", "num_goods", ",", "din_source", ".", "embedding_dim", ")", "\n", "self", ".", "embeddings", "[", "'cat'", "]", "=", "nn", ".", "Embedding", "(", "din_source", ".", "num_cats", ",", "din_source", ".", "embedding_dim", ")", "\n", "self", ".", "embeddings", "[", "'user'", "]", ".", "apply", "(", "load_embedding", "(", "ub_fn", ",", "model_fd", "=", "model_fd", ")", ")", "\n", "self", ".", "embeddings", "[", "'good'", "]", ".", "apply", "(", "load_embedding", "(", "gb_fn", ",", "model_fd", "=", "model_fd", ")", ")", "\n", "self", ".", "embeddings", "[", "'cat'", "]", ".", "apply", "(", "load_embedding", "(", "cb_fn", ",", "model_fd", "=", "model_fd", ")", ")", "\n", "for", "_", ",", "emb", "in", "self", ".", "embeddings", ".", "items", "(", ")", ":", "\n", "                ", "emb", ".", "to", "(", "device", "=", "common", ".", "device", ")", "\n", "for", "par", "in", "emb", ".", "parameters", "(", ")", ":", "\n", "                    ", "par", ".", "requires_grad", "=", "False", "\n", "", "", "self", ".", "mlp", "=", "MLP", "(", "embedding_dim", "=", "din_source", ".", "embedding_dim", ",", "activation", "=", "din_source", ".", "activation", ")", "\n", "self", ".", "attention", "=", "UserEmbeddingAttentionLayer", "(", "embedding_dim", "=", "din_source", ".", "embedding_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.DeepInterestNetworkFixEmb.forward": [[171, 197], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "din.DeepInterestNetworkFixEmb.attention", "torch.cat.sum", "torch.cat.sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "din.DeepInterestNetworkFixEmb.mlp"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "uid_b", ",", "gid_b", ",", "cid_b", ",", "gid_his_b", ",", "cid_his_b", ",", "masks", ")", ":", "\n", "        ", "\"\"\"\n        :param uid_b: (B) user ids batch\n        :param gid_b: (B) good ids batch\n        :param cid_b: (B) category ids batch\n        :param gid_his_b: (B, L) interacted good ids batch, padded\n        :param cid_his_b: (B, L) interacted category ids batch, padded\n        :param masks: (B, L) mask for interacted goods\n        :return: CTR (direct output of self.mlp, not softmaxed)\n        \"\"\"", "\n", "user_b", "=", "self", ".", "embeddings", "[", "\"user\"", "]", "(", "uid_b", ")", "\n", "good_b", "=", "self", ".", "embeddings", "[", "\"good\"", "]", "(", "gid_b", ")", "\n", "cat_b", "=", "self", ".", "embeddings", "[", "'cat'", "]", "(", "cid_b", ")", "\n", "good_his_b", "=", "self", ".", "embeddings", "[", "\"good\"", "]", "(", "gid_his_b", ")", "\n", "cat_his_b", "=", "self", ".", "embeddings", "[", "\"cat\"", "]", "(", "cid_his_b", ")", "\n", "\n", "query_b", "=", "torch", ".", "cat", "(", "[", "good_b", ",", "cat_b", "]", ",", "dim", "=", "-", "1", ")", "\n", "user_behaviors", "=", "torch", ".", "cat", "(", "[", "good_his_b", ",", "cat_his_b", "]", ",", "dim", "=", "-", "1", ")", "\n", "attention_output", "=", "self", ".", "attention", "(", "query_b", ",", "user_behaviors", ",", "masks", ")", "\n", "\n", "user_behaviors_sum_b", "=", "user_behaviors", ".", "sum", "(", "dim", "=", "1", ")", "\n", "mlp_input", "=", "torch", ".", "cat", "(", "[", "user_b", ",", "query_b", ",", "user_behaviors_sum_b", ",", "user_behaviors_sum_b", "*", "query_b", ",", "attention_output", "]", ",", "\n", "dim", "=", "-", "1", ")", "\n", "mlp_output", "=", "self", ".", "mlp", "(", "mlp_input", ")", "\n", "mlp_output", "=", "mlp_output", "# to compat the loaded weight from tensorflow", "\n", "return", "mlp_output", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din.load_embedding": [[12, 18], ["os.join", "pickle.load", "torch.from_numpy", "torch.from_numpy", "open"], "function", ["None"], ["def", "load_embedding", "(", "fn", ",", "model_fd", ")", ":", "\n", "    ", "def", "_init", "(", "m", ")", ":", "\n", "        ", "fp", "=", "osp", ".", "join", "(", "model_fd", ",", "fn", ")", "\n", "weight", "=", "pickle", ".", "load", "(", "open", "(", "fp", ",", "'rb'", ")", ")", "\n", "m", ".", "weight", ".", "data", "[", "...", "]", "=", "torch", ".", "from_numpy", "(", "weight", ")", "\n", "", "return", "_init", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din._test_attention": [[199, 209], ["torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.ones", "torch.ones", "din.UserEmbeddingAttentionLayer", "UserEmbeddingAttentionLayer."], "function", ["None"], ["", "", "def", "_test_attention", "(", ")", ":", "\n", "    ", "B", "=", "3", "\n", "D", "=", "18", "\n", "L", "=", "5", "\n", "queries", "=", "torch", ".", "rand", "(", "(", "B", ",", "2", "*", "D", ")", ")", "\n", "user_behaviors", "=", "torch", ".", "rand", "(", "(", "B", ",", "L", ",", "2", "*", "D", ")", ")", "\n", "masks", "=", "torch", ".", "ones", "(", "(", "B", ",", "L", ")", ")", "\n", "masks", "[", ":", ",", "3", ":", "]", "=", "0", "\n", "user_embedding", "=", "UserEmbeddingAttentionLayer", "(", "embedding_dim", "=", "D", ")", "\n", "user_embedding", "(", "queries", ",", "user_behaviors", ",", "masks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din._test_din": [[211, 220], ["din.DeepInterestNetwork", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "print", "DeepInterestNetwork."], "function", ["None"], ["", "def", "_test_din", "(", ")", ":", "\n", "    ", "din", "=", "DeepInterestNetwork", "(", "num_users", "=", "10", ",", "num_goods", "=", "11", ",", "num_cats", "=", "12", ")", "\n", "uids", "=", "torch", ".", "LongTensor", "(", "[", "0", ",", "1", ",", "2", "]", ")", "\n", "gids", "=", "torch", ".", "LongTensor", "(", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "cids", "=", "torch", ".", "LongTensor", "(", "[", "0", ",", "0", ",", "0", "]", ")", "\n", "gid_his", "=", "torch", ".", "LongTensor", "(", "[", "[", "3", ",", "4", ",", "5", "]", ",", "[", "1", ",", "2", ",", "0", "]", ",", "[", "9", ",", "0", ",", "0", "]", "]", ")", "\n", "cid_his", "=", "torch", ".", "LongTensor", "(", "[", "[", "1", ",", "2", ",", "3", "]", ",", "[", "4", ",", "5", ",", "0", "]", ",", "[", "5", ",", "0", ",", "0", "]", "]", ")", "\n", "masks", "=", "torch", ".", "LongTensor", "(", "[", "[", "1", ",", "1", ",", "1", "]", ",", "[", "1", ",", "1", ",", "0", "]", ",", "[", "1", ",", "0", ",", "0", "]", "]", ")", "\n", "print", "(", "din", "(", "uids", ",", "gids", ",", "cids", ",", "gid_his", ",", "cid_his", ",", "masks", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.din._test_dice": [[222, 227], ["din.Dice", "torch.from_numpy", "torch.from_numpy", "Dice.", "np.arange().reshape().astype", "np.arange().reshape", "np.arange"], "function", ["None"], ["", "def", "_test_dice", "(", ")", ":", "\n", "    ", "import", "numpy", "as", "np", "\n", "dice", "=", "Dice", "(", "4", ")", "\n", "inp", "=", "torch", ".", "from_numpy", "(", "np", ".", "arange", "(", "12", ")", ".", "reshape", "(", "3", ",", "4", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "out", "=", "dice", "(", "inp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples.one_dim_example.Tester.__init__": [[13, 22], ["one_dim_example.Tester.__quad_func", "one_dim_example.Tester.__quad_func", "one_dim_example.Tester.__quad_func", "one_dim_example.Tester.__quad_func"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples.one_dim_example2.Tester.__quad_func", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples.one_dim_example2.Tester.__quad_func", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples.one_dim_example2.Tester.__quad_func", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples.one_dim_example2.Tester.__quad_func"], ["    ", "def", "__init__", "(", "self", ",", "writer", ",", "gamma", "=", "1e-4", ",", "T", "=", "100032", ",", "C", "=", "10", ")", ":", "\n", "        ", "self", ".", "functions", "=", "[", "Tester", ".", "__quad_func", "(", "0", ")", ",", "Tester", ".", "__quad_func", "(", "1", ")", ",", "Tester", ".", "__quad_func", "(", "10", ")", ",", "Tester", ".", "__quad_func", "(", "11", ")", "]", "\n", "self", ".", "day_idxs", "=", "[", "0", ",", "1", "]", "\n", "self", ".", "night_idxs", "=", "[", "2", ",", "3", "]", "\n", "self", ".", "Is", "=", "[", "50", ",", "150", "]", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "T", "=", "T", "\n", "self", ".", "writer", "=", "writer", "\n", "self", ".", "C", "=", "C", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples.one_dim_example.Tester.__quad_func": [[23, 26], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "__quad_func", "(", "e", ")", ":", "\n", "        ", "return", "{", "'ori'", ":", "lambda", "x", ":", "(", "x", "-", "e", ")", "**", "2", ",", "'grad'", ":", "lambda", "x", ":", "2", "*", "(", "x", "-", "e", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples.one_dim_example.Tester.get_update": [[27, 32], ["copy.deepcopy", "range"], "methods", ["None"], ["", "def", "get_update", "(", "self", ",", "function", ",", "x", ",", "mu", ")", ":", "\n", "        ", "x_", "=", "deepcopy", "(", "x", ")", "\n", "for", "c", "in", "range", "(", "self", ".", "C", ")", ":", "\n", "            ", "x_", "-=", "self", ".", "gamma", "*", "(", "function", "[", "'grad'", "]", "(", "x_", ")", "+", "2", "*", "mu", "*", "(", "x_", "-", "x", ")", ")", "\n", "", "return", "x_", "-", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples.one_dim_example.Tester.fedavg": [[33, 48], ["range", "one_dim_example.Tester.writer.add_scalar", "one_dim_example.Tester.get_update", "len", "sum"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples.one_dim_example.Tester.get_update"], ["", "def", "fedavg", "(", "self", ",", "x0", ",", "mu", "=", "0.0", ")", ":", "\n", "        ", "x", "=", "x0", "\n", "for", "t", "in", "range", "(", "self", ".", "T", ")", ":", "\n", "            ", "if", "t", "%", "sum", "(", "self", ".", "Is", ")", "<", "self", ".", "Is", "[", "0", "]", ":", "\n", "                ", "function_idxs", "=", "self", ".", "day_idxs", "\n", "", "else", ":", "\n", "                ", "function_idxs", "=", "self", ".", "night_idxs", "\n", "\n", "", "total_update", "=", "0", "\n", "for", "function_idx", "in", "function_idxs", ":", "\n", "                ", "update", "=", "self", ".", "get_update", "(", "self", ".", "functions", "[", "function_idx", "]", ",", "x", ",", "mu", "=", "mu", ")", "\n", "total_update", "+=", "update", "\n", "", "x", "+=", "(", "total_update", "/", "len", "(", "function_idxs", ")", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "TAG", ",", "x", ",", "t", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples.one_dim_example.Tester.lastavg": [[49, 64], ["range", "one_dim_example.Tester.writer.add_scalar", "one_dim_example.Tester.get_update", "sum", "len", "sum"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples.one_dim_example.Tester.get_update"], ["", "def", "lastavg", "(", "self", ",", "x0", ")", ":", "\n", "        ", "x", "=", "x0", "\n", "latest_updates", "=", "[", "0", "for", "_", "in", "self", ".", "functions", "]", "\n", "for", "t", "in", "range", "(", "self", ".", "T", ")", ":", "\n", "            ", "if", "t", "%", "sum", "(", "self", ".", "Is", ")", "<", "self", ".", "Is", "[", "0", "]", ":", "\n", "                ", "function_idxs", "=", "self", ".", "day_idxs", "\n", "", "else", ":", "\n", "                ", "function_idxs", "=", "self", ".", "night_idxs", "\n", "\n", "", "for", "function_idx", "in", "function_idxs", ":", "\n", "                ", "update", "=", "self", ".", "get_update", "(", "self", ".", "functions", "[", "function_idx", "]", ",", "x", ")", "\n", "latest_updates", "[", "function_idx", "]", "=", "update", "\n", "", "x", "+=", "(", "sum", "(", "latest_updates", ")", "/", "len", "(", "self", ".", "functions", ")", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "TAG", ",", "x", ",", "t", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples.one_dim_example.Tester.scaffold": [[65, 88], ["range", "numpy.mean", "one_dim_example.Tester.writer.add_scalar", "sum", "len", "copy.deepcopy", "range", "updates.append", "sum", "grads.append", "sum", "len"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar"], ["", "def", "scaffold", "(", "self", ",", "x0", ")", ":", "\n", "        ", "x", "=", "x0", "\n", "cs", "=", "[", "0", "for", "_", "in", "self", ".", "functions", "]", "\n", "for", "t", "in", "range", "(", "self", ".", "T", ")", ":", "\n", "            ", "if", "t", "%", "sum", "(", "self", ".", "Is", ")", "<", "self", ".", "Is", "[", "0", "]", ":", "\n", "                ", "function_idxs", "=", "self", ".", "day_idxs", "\n", "", "else", ":", "\n", "                ", "function_idxs", "=", "self", ".", "night_idxs", "\n", "\n", "", "updates", "=", "[", "]", "\n", "cc", "=", "sum", "(", "cs", ")", "/", "len", "(", "cs", ")", "\n", "for", "function_idx", "in", "function_idxs", ":", "\n", "                ", "x_", "=", "deepcopy", "(", "x", ")", "\n", "grads", "=", "[", "]", "\n", "for", "c", "in", "range", "(", "self", ".", "C", ")", ":", "\n", "                    ", "grad", "=", "self", ".", "functions", "[", "function_idx", "]", "[", "'grad'", "]", "(", "x_", ")", "\n", "grads", ".", "append", "(", "grad", ")", "\n", "x_", "-=", "self", ".", "gamma", "*", "(", "grad", "-", "cs", "[", "function_idx", "]", "+", "cc", ")", "\n", "", "cs", "[", "function_idx", "]", "=", "sum", "(", "grads", ")", "/", "len", "(", "grads", ")", "\n", "updates", ".", "append", "(", "x_", "-", "x", ")", "\n", "", "x", "+=", "np", ".", "mean", "(", "updates", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "TAG", ",", "x", ",", "t", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples._init_paths.add_path": [[5, 8], ["sys.path.insert"], "function", ["None"], ["def", "add_path", "(", "path", ")", ":", "\n", "    ", "if", "path", "not", "in", "sys", ".", "path", ":", "\n", "        ", "sys", ".", "path", ".", "insert", "(", "0", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples.one_dim_example2.Tester.__init__": [[12, 19], ["one_dim_example2.Tester.__quad_func"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples.one_dim_example2.Tester.__quad_func"], ["    ", "def", "__init__", "(", "self", ",", "writer", ",", "gamma", ",", "T", "=", "100032", ")", ":", "\n", "        ", "self", ".", "functions", "=", "[", "Tester", ".", "__quad_func", "(", "target", ")", "for", "target", "in", "[", "0", ",", "2", ",", "50", ",", "100", ",", "-", "3", "]", "]", "\n", "self", ".", "target_it", "=", "10", "\n", "self", ".", "its", "=", "[", "3", ",", "20", ",", "5", ",", "10", ",", "8", "]", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "T", "=", "T", "\n", "self", ".", "writer", "=", "writer", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples.one_dim_example2.Tester.__quad_func": [[20, 23], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "__quad_func", "(", "e", ")", ":", "\n", "        ", "return", "{", "'ori'", ":", "lambda", "x", ":", "(", "x", "-", "e", ")", "**", "2", ",", "'grad'", ":", "lambda", "x", ":", "2", "*", "(", "x", "-", "e", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.toy_examples.one_dim_example2.Tester.fedavg": [[24, 42], ["range", "copy.deepcopy", "one_dim_example2.Tester.gamma", "zip", "one_dim_example2.Tester.writer.add_scalar", "print", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar"], ["", "def", "fedavg", "(", "self", ",", "x0", ",", "scaled", "=", "True", ")", ":", "\n", "        ", "x", "=", "x0", "\n", "for", "t", "in", "range", "(", "self", ".", "T", ")", ":", "\n", "            ", "next_x", "=", "deepcopy", "(", "x", ")", "\n", "gamma", "=", "self", ".", "gamma", "(", "t", ")", "\n", "for", "function", ",", "num_it", "in", "zip", "(", "self", ".", "functions", ",", "self", ".", "its", ")", ":", "\n", "                ", "x_local", "=", "deepcopy", "(", "x", ")", "\n", "for", "it", "in", "range", "(", "num_it", ")", ":", "\n", "                    ", "x_local", "-=", "gamma", "*", "function", "[", "'grad'", "]", "(", "x_local", ")", "\n", "", "x_update", "=", "x_local", "-", "x", "\n", "if", "scaled", ":", "\n", "                    ", "next_x", "+=", "x_update", "*", "self", ".", "target_it", "/", "num_it", "\n", "", "else", ":", "\n", "                    ", "next_x", "+=", "x_update", "\n", "", "", "x", "=", "next_x", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'scaled'", "if", "scaled", "else", "'unscaled'", ",", "x", ",", "t", ")", "\n", "print", "(", "f\"{t}: {x}\"", ",", "end", "=", "'\\r'", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train._init_paths.add_path": [[5, 8], ["sys.path.insert"], "function", ["None"], ["def", "add_path", "(", "path", ")", ":", "\n", "    ", "if", "path", "not", "in", "sys", ".", "path", ":", "\n", "        ", "sys", ".", "path", ".", "insert", "(", "0", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.__init__": [[31, 99], ["isinstance", "kwargs.pop", "kwargs.pop", "kwargs.pop", "len", "ValueError", "isinstance", "torch.utils.data.DataLoader", "isinstance", "torch.utils.data.sampler.SubsetRandomSampler", "torch.utils.data.sampler.SequentialSampler", "ValueError", "ValueError", "print", "open", "eval", "isinstance", "ValueError", "f.readline", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "train_set", ",", "train_indices", ",", "is_available", ",", "collate_fn", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        :param train_set: the whole dataset\n        :param train_indices:\n            list (indices of the train images)\n            str (file path recording the indices, produced by partition)\n        :param is_available: a function to judge whether the client is available\n        :param kwargs:\n            train_batch_size\n            id\n        \"\"\"", "\n", "self", ".", "available_blocks", "=", "None", "\n", "self", ".", "num_hours1block", "=", "None", "\n", "self", ".", "is_available_input", "=", "'round'", "\n", "if", "isinstance", "(", "is_available", ",", "tuple", ")", ":", "\n", "            ", "if", "is_available", "[", "0", "]", "==", "'check_time'", ":", "\n", "                ", "self", ".", "available_blocks", "=", "is_available", "[", "1", "]", "\n", "self", ".", "num_hours1block", "=", "is_available", "[", "2", "]", "\n", "is_available", "=", "self", ".", "check_time", "\n", "self", ".", "is_available_input", "=", "'time'", "\n", "", "elif", "is_available", "[", "0", "]", "==", "'check_in_range'", ":", "# for modeled_mid", "\n", "                ", "self", ".", "available_start", ",", "self", ".", "available_end", "=", "is_available", "[", "1", "]", "# time2int output", "\n", "is_available", "=", "self", ".", "check_in_range", "\n", "self", ".", "is_available_input", "=", "'time'", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"is_available is a tuple that can not be recognized\"", ")", "\n", "\n", "", "", "self", ".", "is_available", "=", "is_available", "\n", "self", ".", "train_batch_size", "=", "kwargs", ".", "pop", "(", "\"train_batch_size\"", ",", "5", ")", "\n", "self", ".", "shuffle", "=", "kwargs", ".", "pop", "(", "\"shuffle\"", ",", "True", ")", "\n", "self", ".", "id", "=", "kwargs", ".", "pop", "(", "\"id\"", ",", "None", ")", "\n", "self", ".", "collate_fn", "=", "collate_fn", "\n", "\n", "if", "len", "(", "kwargs", ")", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unexpected parameter {kwargs}\"", ")", "\n", "\n", "", "if", "train_indices", "is", "None", ":", "\n", "# do not use dataloader, dataset is already partitioned", "\n", "            ", "self", ".", "dataset", "=", "train_set", "\n", "self", ".", "train_indices", "=", "None", "\n", "", "else", ":", "\n", "            ", "if", "isinstance", "(", "train_indices", ",", "list", ")", ":", "\n", "                ", "self", ".", "train_indices", "=", "train_indices", "\n", "", "elif", "isinstance", "(", "train_indices", ",", "str", ")", ":", "\n", "                ", "with", "open", "(", "train_indices", ",", "'r'", ")", "as", "f", ":", "\n", "                    ", "self", ".", "train_indices", "=", "eval", "(", "f", ".", "readline", "(", ")", ")", "\n", "", "if", "not", "isinstance", "(", "self", ".", "train_indices", ",", "list", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"{train_indices} is not a valid client file\"", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"train_indices with type {type(train_indices)} is not accepted\"", ")", "\n", "\n", "", "if", "self", ".", "num_samples", "<", "self", ".", "train_batch_size", ":", "\n", "                ", "if", "Client", ".", "batch_size_warn_count", "==", "0", ":", "\n", "                    ", "print", "(", "\n", "f\"some clients are given batch size too high, using {self.num_samples} instead for one of them \"", "\n", "f\"(full batch)\"", ")", "\n", "", "Client", ".", "batch_size_warn_count", "+=", "1", "\n", "self", ".", "train_batch_size", "=", "self", ".", "num_samples", "\n", "\n", "", "if", "self", ".", "shuffle", ":", "\n", "                ", "_sampler", "=", "sampler", ".", "SubsetRandomSampler", "(", "self", ".", "train_indices", ")", "\n", "", "else", ":", "\n", "                ", "_sampler", "=", "sampler", ".", "SequentialSampler", "(", "self", ".", "train_indices", ")", "\n", "", "self", ".", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_set", ",", "batch_size", "=", "self", ".", "train_batch_size", ",", "\n", "collate_fn", "=", "collate_fn", ",", "sampler", "=", "_sampler", ")", "\n", "\n", "", "self", ".", "__last_grad_sum", "=", "None", "# cache the update calculated in last training", "\n", "self", ".", "__train_log", "=", "[", "]", "# log real iteration where self is chosen to train in it", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.check_time": [[100, 105], ["None"], "methods", ["None"], ["", "def", "check_time", "(", "self", ",", "current_time", ")", ":", "\n", "# current_time: timedelta, only care seconds (days ignored)", "\n", "        ", "hour", "=", "current_time", ".", "seconds", "//", "3600", "\n", "block_idx", "=", "hour", "//", "self", ".", "num_hours1block", "\n", "return", "block_idx", "in", "self", ".", "available_blocks", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.check_in_range": [[106, 115], ["None"], "methods", ["None"], ["", "def", "check_in_range", "(", "self", ",", "current_time", ")", ":", "\n", "# current_time: timedelta, only care seconds (days ignored)", "\n", "        ", "seconds", "=", "current_time", ".", "seconds", "\n", "if", "self", ".", "available_end", "==", "self", ".", "available_start", ":", "\n", "            ", "return", "True", "\n", "", "if", "self", ".", "available_end", ">", "self", ".", "available_start", ":", "\n", "            ", "return", "self", ".", "available_start", "<=", "seconds", "<=", "self", ".", "available_end", "\n", "", "else", ":", "# for available_end == available_start: always available", "\n", "            ", "return", "seconds", ">=", "self", ".", "available_end", "or", "seconds", "<=", "self", ".", "available_start", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.train_log": [[116, 119], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "train_log", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__train_log", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.num_samples": [[120, 123], ["len", "len"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_samples", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "train_indices", ")", "if", "self", ".", "train_indices", "is", "not", "None", "else", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.r": [[124, 131], ["None"], "methods", ["None"], ["", "@", "property", "\n", "# last iteration when the client is picked -1 if never picked", "\n", "def", "r", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "self", ".", "__train_log", "[", "-", "1", "]", "\n", "", "except", "IndexError", ":", "\n", "            ", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.latest_grad": [[132, 135], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "latest_grad", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__last_grad_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.get_loss": [[136, 151], ["torch.nn.CrossEntropyLoss", "torch.no_grad", "inputs.to.to.to", "labels.to.to.to", "net", "criterion().item", "len", "criterion"], "methods", ["None"], ["", "def", "get_loss", "(", "self", ",", "net", ",", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'sum'", ")", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "loss", "=", "0.0", "\n", "num_samples", "=", "0", "\n", "for", "inputs", ",", "labels", "in", "self", ".", "dataloader", ":", "\n", "                ", "if", "inputs", ".", "shape", "[", "0", "]", "==", "1", ":", "# can't resolve batchnorm", "\n", "                    ", "continue", "\n", "\n", "", "inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "outputs", "=", "net", "(", "inputs", ")", "\n", "loss", "+=", "criterion", "(", "outputs", ",", "labels", ")", ".", "item", "(", ")", "\n", "num_samples", "+=", "len", "(", "labels", ")", "\n", "", "", "return", "loss", "/", "num_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.train": [[152, 249], ["copy.deepcopy().to", "copy.deepcopy().to", "copy.deepcopy().to.parameters", "torch.optim.SGD", "iter", "range", "client.Client.__train_log.append", "copy.deepcopy().to.parameters", "max", "torch.utils.data.DataLoader", "isinstance", "torch.optim.SGD.zero_grad", "utils.widgets.data_b_to_right_device", "labels.to.to.to", "torch.optim.SGD.zero_grad", "utils.widgets.get_output", "zip", "total_loss.backward", "copy.deepcopy().to.parameters", "torch.optim.SGD.step", "copy.deepcopy", "copy.deepcopy", "torch.zeros_like", "round", "ValueError", "iter.__next__", "criterion", "copy.deepcopy().to.parameters", "copy.deepcopy().to.parameters", "zip", "gs.data.cpu", "copy.deepcopy().to.parameters", "len", "iter", "iter.__next__", "iter", "iter.__next__", "torch.isnan().sum", "print", "copy.deepcopy().to.parameters", "current_model.parameters", "old_gs.data.to", "zip", "torch.isnan", "torch.isnan"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.data_b_to_right_device", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.get_output"], ["", "def", "train", "(", "self", ",", "current_model", ",", "criterion", ",", "lr", ",", "scale", ",", "C", ",", "current_round", ",", "abs_grad_sum_", "=", "None", ",", "mu_FedProx", "=", "0.0", ",", "\n", "scale_in_it", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        won't modify model, only return information about update\n        :param scale_in_it: True to scale in iteration (use C * scale iterations)\n        :param mu_FedProx: proxy term for FedProx\n        :param abs_grad_sum_: holder to pass the actual update value (for FedAvg)\n        :param lr: learning rate\n        :param current_round: current round in the training process\n        :param C: number of local iterations\n        :param scale: scale of the loss function for unbalanced data (N * num_samples / NUM_CIFAR10_TRAIN)\n        :param criterion: criterion to be used\n        :param current_model: model to be trained\n        :return: the difference between 2 successive ***scaled gradient sum (-update / base_lr)***\n        \"\"\"", "\n", "model", "=", "deepcopy", "(", "current_model", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "initial_model", "=", "deepcopy", "(", "current_model", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "for", "par", "in", "initial_model", ".", "parameters", "(", ")", ":", "\n", "            ", "par", ".", "requires_grad", "=", "False", "\n", "", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "# FedLaAvg and first round", "\n", "if", "abs_grad_sum_", "is", "None", "and", "self", ".", "__last_grad_sum", "is", "None", ":", "\n", "            ", "self", ".", "__last_grad_sum", "=", "[", "torch", ".", "zeros_like", "(", "par", ".", "data", ")", "for", "par", "in", "model", ".", "parameters", "(", ")", "]", "\n", "\n", "", "if", "scale_in_it", ":", "\n", "            ", "C_", "=", "max", "(", "1", ",", "round", "(", "C", "*", "scale", ")", ")", "\n", "scale_", "=", "1", "\n", "", "else", ":", "\n", "            ", "C_", "=", "C", "\n", "scale_", "=", "scale", "\n", "\n", "", "if", "self", ".", "train_indices", "is", "None", ":", "\n", "            ", "if", "not", "self", ".", "shuffle", ":", "\n", "                ", "raise", "ValueError", "(", "\"We should shuffle the dataset for hard partitioned clients\"", ")", "\n", "", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "dataset", ",", "batch_size", "=", "self", ".", "train_batch_size", ",", "\n", "collate_fn", "=", "self", ".", "collate_fn", ",", "shuffle", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "dataloader", "=", "self", ".", "dataloader", "\n", "", "dataiter", "=", "iter", "(", "dataloader", ")", "\n", "for", "c_it", "in", "range", "(", "C_", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "inputs", ",", "labels", "=", "dataiter", ".", "__next__", "(", ")", "\n", "assert", "len", "(", "labels", ")", "!=", "1", "\n", "", "except", "StopIteration", "as", "e", ":", "\n", "                ", "dataiter", "=", "iter", "(", "dataloader", ")", "\n", "inputs", ",", "labels", "=", "dataiter", ".", "__next__", "(", ")", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "# batchnorm do not accept 1-sample batch", "\n", "                ", "dataiter", "=", "iter", "(", "dataloader", ")", "\n", "inputs", ",", "labels", "=", "dataiter", ".", "__next__", "(", ")", "\n", "\n", "# for rnn may be not Tensor", "\n", "", "if", "isinstance", "(", "inputs", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "if", "inputs", ".", "shape", "[", "0", "]", "==", "1", ":", "# can't resolve batchnorm", "\n", "                    ", "continue", "\n", "\n", "", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "inputs", "=", "data_b_to_right_device", "(", "inputs", ")", "\n", "labels", "=", "labels", ".", "to", "(", "device", "=", "common", ".", "device", ")", "\n", "\n", "# zero the parameter gradients", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "outputs", "=", "get_output", "(", "model", ",", "inputs", ")", "\n", "loss", "=", "criterion", "(", "outputs", ",", "labels", ")", "*", "scale_", "\n", "\n", "prox", "=", "0.0", "\n", "for", "par", ",", "init_par", "in", "zip", "(", "model", ".", "parameters", "(", ")", ",", "initial_model", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "prox", "+=", "mu_FedProx", "/", "2.0", "*", "(", "(", "par", "-", "init_par", ")", "**", "2", ")", ".", "sum", "(", ")", "\n", "", "total_loss", "=", "loss", "+", "prox", "\n", "total_loss", ".", "backward", "(", ")", "\n", "\n", "for", "par", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "torch", ".", "isnan", "(", "par", ".", "grad", ")", ".", "sum", "(", ")", "!=", "0", ":", "\n", "# may cause bug if the exception is caught because the function has modified self ()", "\n", "# but I check the code and think there is no bug", "\n", "# raise RuntimeError(\"nan in the optimization\")", "\n", "                    ", "print", "(", "f\"nan in the optimization of client {self.id}, force to 0\"", ")", "\n", "par", ".", "grad", "[", "torch", ".", "isnan", "(", "par", ".", "grad", ")", "]", "=", "0.0", "\n", "\n", "", "", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "self", ".", "__train_log", ".", "append", "(", "current_round", ")", "\n", "\n", "new_grad_sum", "=", "[", "-", "(", "new_par", ".", "data", "-", "old_par", ".", "data", ")", "/", "lr", "for", "new_par", ",", "old_par", "in", "\n", "zip", "(", "model", ".", "parameters", "(", ")", ",", "current_model", ".", "parameters", "(", ")", ")", "]", "\n", "if", "abs_grad_sum_", "is", "not", "None", ":", "\n", "            ", "abs_grad_sum_", "[", "0", "]", "=", "new_grad_sum", "\n", "", "else", ":", "\n", "            ", "grad_sum_diff", "=", "[", "(", "new_gs", ".", "data", "-", "old_gs", ".", "data", ".", "to", "(", "device", "=", "device", ")", ")", "for", "new_gs", ",", "old_gs", "in", "\n", "zip", "(", "new_grad_sum", ",", "self", ".", "__last_grad_sum", ")", "]", "\n", "\n", "self", ".", "__last_grad_sum", "=", "[", "gs", ".", "data", ".", "cpu", "(", ")", "for", "gs", "in", "new_grad_sum", "]", "\n", "\n", "return", "grad_sum_diff", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.state_dict": [[250, 256], ["dict"], "methods", ["None"], ["", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "state_dict", "=", "dict", "(", "\n", "train_log", "=", "self", ".", "__train_log", ",", "\n", "last_grad_sum", "=", "self", ".", "__last_grad_sum", ",", "\n", ")", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.load_state_dict": [[257, 263], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "load_last_grad_sum", "=", "True", ")", ":", "\n", "# to save memory, do not load last_grad_sum for fedavg (current code actually do not save this,", "\n", "# but older code save this data, for compatibility this is passed", "\n", "        ", "self", ".", "__train_log", "=", "state_dict", "[", "'train_log'", "]", "\n", "if", "load_last_grad_sum", ":", "\n", "            ", "self", ".", "__last_grad_sum", "=", "state_dict", "[", "'last_grad_sum'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client._test": [[265, 369], ["torchvision.datasets.CIFAR10", "os.join", "os.join", "client.Client", "client.Client", "utils.logger.Logger", "train.model.Net", "net.to", "utils.logger.Logger.has_checkpoint", "range", "utils.logger.Logger.dump_model", "utils.logger.Logger.dump_clients", "utils.logger.Logger.dump_meta", "utils.logger.Logger.load_clients", "utils.logger.Logger.load_checkpoint_round", "utils.logger.Logger.load_model", "print", "client._test.lr"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.has_checkpoint", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.dump_model", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.dump_clients", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.dump_meta", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.load_clients", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.load_checkpoint_round", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.load_model"], ["", "", "", "def", "_test", "(", ")", ":", "\n", "    ", "train_set", "=", "torchvision", ".", "datasets", ".", "CIFAR10", "(", "root", "=", "raw_data_dir", ",", "train", "=", "True", ",", "download", "=", "True", ")", "\n", "client_partition", "=", "\"N1000-balance\"", "\n", "train_indices1", "=", "osp", ".", "join", "(", "data_cache_dir", ",", "client_partition", ",", "'0'", ")", "\n", "train_indices2", "=", "osp", ".", "join", "(", "data_cache_dir", ",", "client_partition", ",", "'100'", ")", "\n", "client1", "=", "Client", "(", "train_set", ",", "train_indices1", ",", "None", ",", "train_batch_size", "=", "50", ")", "\n", "client2", "=", "Client", "(", "train_set", ",", "train_indices2", ",", "None", ",", "train_batch_size", "=", "50", ")", "\n", "run_name", "=", "\"2client_example\"", "\n", "sub_run_name", "=", "'async'", "\n", "run_name", "=", "run_name", "+", "'_'", "+", "sub_run_name", "\n", "if", "sub_run_name", "==", "'1local'", ":", "\n", "        ", "C1", ",", "C2", "=", "1", ",", "1", "\n", "sc1", ",", "sc2", "=", "1.0", ",", "1.0", "\n", "\n", "def", "lr", "(", "r", ")", ":", "\n", "            ", "return", "1e-2", "\n", "", "", "elif", "sub_run_name", "==", "'sync'", ":", "\n", "        ", "C1", ",", "C2", "=", "3", ",", "3", "\n", "sc1", ",", "sc2", "=", "1.0", ",", "1.0", "\n", "\n", "def", "lr", "(", "r", ")", ":", "\n", "            ", "return", "1e-2", "\n", "", "", "elif", "sub_run_name", "==", "'sync_bias1'", ":", "\n", "        ", "C1", ",", "C2", "=", "3", ",", "3", "\n", "sc1", ",", "sc2", "=", "5.0", ",", "1.0", "\n", "\n", "def", "lr", "(", "r", ")", ":", "\n", "            ", "return", "2e-3", "\n", "", "", "elif", "sub_run_name", "==", "'sync_bias2'", ":", "\n", "        ", "C1", ",", "C2", "=", "3", ",", "3", "\n", "sc1", ",", "sc2", "=", "1.0", ",", "5.0", "\n", "\n", "def", "lr", "(", "r", ")", ":", "\n", "            ", "return", "2e-3", "\n", "", "", "elif", "sub_run_name", "==", "'async'", ":", "\n", "        ", "C1", ",", "C2", "=", "1", ",", "5", "\n", "sc1", ",", "sc2", "=", "1.0", ",", "1.0", "\n", "\n", "def", "lr", "(", "r", ")", ":", "\n", "            ", "return", "2e-3", "\n", "", "", "elif", "sub_run_name", "==", "'async_scaled'", ":", "\n", "        ", "C1", ",", "C2", "=", "1", ",", "5", "\n", "sc1", ",", "sc2", "=", "5.0", ",", "1.0", "\n", "\n", "def", "lr", "(", "r", ")", ":", "\n", "            ", "return", "2e-3", "if", "r", "<=", "1000", "else", "2e-4", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", ")", "\n", "\n", "", "logger", "=", "utils", ".", "logger", ".", "Logger", "(", "run_name", ")", "\n", "num_total_samples", "=", "client1", ".", "num_samples", "+", "client2", ".", "num_samples", "\n", "ratio1", ",", "ratio2", "=", "client1", ".", "num_samples", "/", "num_total_samples", ",", "client2", ".", "num_samples", "/", "num_total_samples", "\n", "scale1", ",", "scale2", "=", "ratio1", "*", "2", ",", "ratio2", "*", "2", "\n", "\n", "net", ":", "nn", ".", "Module", "=", "Net", "(", ")", "\n", "net", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "if", "logger", ".", "has_checkpoint", "(", ")", ":", "\n", "        ", "logger", ".", "load_clients", "(", "[", "client1", ",", "client2", "]", ")", "\n", "c_round", "=", "logger", ".", "load_checkpoint_round", "(", ")", "\n", "logger", ".", "load_model", "(", "net", ")", "\n", "", "else", ":", "\n", "        ", "c_round", "=", "0", "\n", "print", "(", "\"no checkpoint\"", ")", "\n", "\n", "", "for", "round_", "in", "range", "(", "c_round", ",", "10000", ")", ":", "\n", "        ", "lr_", "=", "lr", "(", "round_", ")", "\n", "grad_sum", "=", "[", "torch", ".", "zeros_like", "(", "par", ")", "for", "par", "in", "net", ".", "parameters", "(", ")", "]", "\n", "grad_sum_", "=", "[", "[", "torch", ".", "zeros_like", "(", "par", ")", "for", "par", "in", "net", ".", "parameters", "(", ")", "]", "]", "\n", "client1", ".", "train", "(", "net", ",", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ",", "lr", "=", "lr_", ",", "scale", "=", "scale1", ",", "C", "=", "C1", ",", "current_round", "=", "round_", ",", "\n", "abs_grad_sum_", "=", "grad_sum_", ")", "\n", "grad_sum", "=", "[", "gs", "+", "d", "/", "2", "*", "sc1", "for", "gs", ",", "d", "in", "zip", "(", "grad_sum", ",", "grad_sum_", "[", "0", "]", ")", "]", "\n", "client2", ".", "train", "(", "net", ",", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ",", "lr", "=", "lr_", ",", "scale", "=", "scale2", ",", "C", "=", "C2", ",", "current_round", "=", "round_", ",", "\n", "abs_grad_sum_", "=", "grad_sum_", ")", "\n", "grad_sum", "=", "[", "gs", "+", "d", "/", "2", "*", "sc2", "for", "gs", ",", "d", "in", "zip", "(", "grad_sum", ",", "grad_sum_", "[", "0", "]", ")", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "par", ",", "gs", "in", "zip", "(", "net", ".", "parameters", "(", ")", ",", "grad_sum", ")", ":", "\n", "                ", "par", ".", "data", "-=", "gs", "*", "lr_", "\n", "", "", "acc1_", ",", "acc2_", "=", "[", "-", "1.", "]", ",", "[", "-", "1.", "]", "\n", "loss1_", ",", "loss2_", "=", "[", "-", "1.", "]", ",", "[", "-", "1.", "]", "\n", "grad_norm1_", ",", "grad_norm2_", "=", "[", "-", "1.", "]", ",", "[", "-", "1.", "]", "\n", "test_loader", "(", "net", ",", "client1", ".", "dataloader", ",", "acc_", "=", "acc1_", ",", "loss_", "=", "loss1_", ",", "grad_norm_", "=", "grad_norm1_", ")", "\n", "test_loader", "(", "net", ",", "client2", ".", "dataloader", ",", "acc_", "=", "acc2_", ",", "loss_", "=", "loss2_", ",", "grad_norm_", "=", "grad_norm2_", ")", "\n", "c_accuracy", "=", "acc1_", "[", "0", "]", "*", "ratio1", "+", "acc2_", "[", "0", "]", "*", "ratio2", "\n", "c_loss", "=", "loss1_", "[", "0", "]", "*", "ratio1", "+", "loss2_", "[", "0", "]", "*", "ratio2", "\n", "# print(round_)", "\n", "if", "round_", "%", "1", "==", "0", ":", "\n", "            ", "logger", ".", "add_scalar", "(", "'acc1'", ",", "acc1_", "[", "0", "]", ",", "round_", ",", "write_file", "=", "False", ")", "\n", "logger", ".", "add_scalar", "(", "'acc2'", ",", "acc2_", "[", "0", "]", ",", "round_", ",", "write_file", "=", "False", ")", "\n", "logger", ".", "add_scalar", "(", "'acc'", ",", "c_accuracy", ",", "round_", ",", "write_file", "=", "False", ")", "\n", "logger", ".", "add_scalar", "(", "'loss1'", ",", "loss1_", "[", "0", "]", ",", "round_", ",", "write_file", "=", "False", ")", "\n", "logger", ".", "add_scalar", "(", "'loss2'", ",", "loss2_", "[", "0", "]", ",", "round_", ",", "write_file", "=", "False", ")", "\n", "logger", ".", "add_scalar", "(", "'loss'", ",", "c_loss", ",", "round_", ",", "write_file", "=", "False", ")", "\n", "logger", ".", "add_scalar", "(", "'grad_norm1'", ",", "grad_norm1_", "[", "0", "]", ",", "round_", ",", "write_file", "=", "False", ")", "\n", "logger", ".", "add_scalar", "(", "'grad_norm2'", ",", "grad_norm2_", "[", "0", "]", ",", "round_", ",", "write_file", "=", "False", ")", "\n", "print", "(", "f\"round: {round_}:\"", ")", "\n", "print", "(", "f\"acc {c_accuracy}, acc1 {acc1_[0]}, acc2 {acc2_[0]}\"", ")", "\n", "print", "(", "f\"loss {c_loss}, loss1 {loss1_[0]}, loss2 {loss2_[0]}\"", ")", "\n", "print", "(", "f\"grad_norm1 {grad_norm1_[0]}, grad_norm2 {grad_norm2_[0]}\"", ")", "\n", "\n", "", "", "logger", ".", "dump_model", "(", "net", ")", "\n", "logger", ".", "dump_clients", "(", "[", "client1", ",", "client2", "]", ")", "\n", "logger", ".", "dump_meta", "(", "{", "'current_round'", ":", "c_round", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.MyModule.__init__": [[21, 23], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.MyModule.load_initial": [[24, 27], ["os.join", "model.MyModule.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.load_state_dict"], ["", "def", "load_initial", "(", "self", ")", ":", "\n", "        ", "fp", "=", "osp", ".", "join", "(", "common", ".", "cache_fd", ",", "f'{self.id}.pth'", ")", "\n", "self", ".", "load_state_dict", "(", "torch", ".", "load", "(", "fp", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.MyModule.save_initial": [[28, 31], ["os.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "model.MyModule.state_dict"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.state_dict"], ["", "def", "save_initial", "(", "self", ")", ":", "\n", "        ", "fp", "=", "osp", ".", "join", "(", "common", ".", "cache_fd", ",", "f'{self.id}.pth'", ")", "\n", "torch", ".", "save", "(", "self", ".", "state_dict", "(", ")", ",", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.MyModule.exists_initial": [[32, 35], ["os.join", "os.exists"], "methods", ["None"], ["", "def", "exists_initial", "(", "self", ")", ":", "\n", "        ", "fp", "=", "osp", ".", "join", "(", "common", ".", "cache_fd", ",", "f'{self.id}.pth'", ")", "\n", "return", "osp", ".", "exists", "(", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.Net.__init__": [[38, 47], ["model.MyModule.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "id", "=", "\"CPCFF\"", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "6", ",", "5", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "6", ",", "16", ",", "5", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "16", "*", "5", "*", "5", ",", "120", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "120", ",", "84", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "84", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.Net.forward": [[48, 56], ["model.Net.pool", "model.Net.pool", "model.Net.view", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.Net.fc3", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.Net.fc1", "model.Net.fc2", "model.Net.conv1", "model.Net.conv2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "pool", "(", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "pool", "(", "F", ".", "relu", "(", "self", ".", "conv2", "(", "x", ")", ")", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "16", "*", "5", "*", "5", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "fc3", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.Logistic.__init__": [[59, 63], ["model.MyModule.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "id", "=", "\"logistic\"", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "28", "*", "28", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.Logistic.forward": [[64, 68], ["model.Logistic.view", "model.Logistic.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "view", "(", "-", "1", ",", "28", "*", "28", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.MobileNetV2.__init__": [[71, 75], ["model.MyModule.__init__", "torchvision.models.mobilenet_v2"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ",", "width_mult", "=", "1.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "id", "=", "f\"mobile2_wm{width_mult}\"", "\n", "self", ".", "net", "=", "torchvision", ".", "models", ".", "mobilenet_v2", "(", "num_classes", "=", "10", ",", "width_mult", "=", "width_mult", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.MobileNetV2.forward": [[76, 79], ["model.MobileNetV2.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "net", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.BowLinear.__init__": [[82, 86], ["model.MyModule.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "id", "=", "f\"linear{num_features}\"", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "num_features", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.BowLinear.forward": [[87, 92], ["model.BowLinear.fc", "output.view.view.view", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output", "=", "self", ".", "fc", "(", "x", ")", "\n", "output", "=", "output", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "neg_vec", "=", "torch", ".", "zeros_like", "(", "output", ")", "\n", "return", "torch", ".", "cat", "(", "(", "neg_vec", ",", "output", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.LSTM2.__init__": [[95, 100], ["model.MyModule.__init__", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", "=", "300", ",", "hidden_size", "=", "256", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "id", "=", "f\"lstm_i{input_size}_h{hidden_size}\"", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "input_size", "=", "input_size", ",", "hidden_size", "=", "hidden_size", ",", "num_layers", "=", "2", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.LSTM2.forward": [[101, 111], ["model.LSTM2.lstm.flatten_parameters", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "model.LSTM2.fc", "x.view.view.view", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.LSTM2.lstm", "range"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "self", ".", "lstm", ".", "flatten_parameters", "(", ")", "\n", "x", "=", "self", ".", "lstm", "(", "x", ")", "[", "0", "]", "\n", "# noinspection PyTypeChecker", "\n", "x", ",", "lengths", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "x", ")", "\n", "x", "=", "x", "[", "lengths", "-", "1", ",", "range", "(", "x", ".", "shape", "[", "1", "]", ")", "]", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "neg_vec", "=", "torch", ".", "zeros_like", "(", "x", ")", "\n", "return", "torch", ".", "cat", "(", "(", "neg_vec", ",", "x", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.DCNN.__init__": [[114, 127], ["model.MyModule.__init__", "model.DynamicMaxPool", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", "=", "300", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "id", "=", "f\"dcnn{num_features}\"", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "top_k", "=", "4", "\n", "self", ".", "dmp", "=", "DynamicMaxPool", "(", "top_k", "=", "self", ".", "top_k", ")", "\n", "self", ".", "ks1", "=", "7", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "num_features", ",", "out_channels", "=", "3", "*", "num_features", ",", "kernel_size", "=", "self", ".", "ks1", ",", "\n", "padding", "=", "self", ".", "ks1", "-", "1", ",", "groups", "=", "num_features", "//", "2", ")", "\n", "self", ".", "ks2", "=", "(", "6", ",", "5", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "num_features", "//", "2", ",", "out_channels", "=", "14", "*", "num_features", "//", "4", ",", "\n", "kernel_size", "=", "self", ".", "ks2", ",", "padding", "=", "(", "0", ",", "self", ".", "ks2", "[", "1", "]", "-", "1", ")", ",", "groups", "=", "num_features", "//", "4", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "in_features", "=", "self", ".", "top_k", "*", "14", "*", "num_features", "//", "4", ",", "out_features", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.DCNN.forward": [[128, 162], ["torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "x.view.view.transpose", "model.DCNN.conv1", "x.view.view.transpose", "model.DCNN.dmp", "x.view.view.transpose", "x.view.view.view", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "model.DCNN.conv2", "x.view.view.view", "x.view.view.transpose", "model.DCNN.dmp", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "x.view.view.reshape", "model.DCNN.fc", "x.view.view.view", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.array"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# batch_size x seq_len x dim", "\n", "        ", "x", ",", "lengths", "=", "pad_packed_sequence", "(", "x", ",", "batch_first", "=", "True", ")", "\n", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "dim", "=", "x", ".", "shape", "[", "2", "]", "\n", "\n", "# batch_size x dim x seq_len", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# batch_size x out_channels1 x seq_len+6", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "# batch_size x seq_len+6 x out_channels1", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# batch_size x max_pool_dim x out_channels1", "\n", "x", ",", "pool_result_ranges", "=", "self", ".", "dmp", "(", "x", ",", "lengths", ",", "1", ",", "2", ",", "pool_ranges", "=", "lengths", "+", "(", "self", ".", "ks1", "-", "1", ")", ")", "\n", "# batch_size x out_channels1 x max_pool_dim", "\n", "x", "=", "x", ".", "transpose", "(", "2", ",", "1", ")", "\n", "# batch_size x dim//2 x num_maps x max_pool_dim", "\n", "x", "=", "x", ".", "view", "(", "batch_size", ",", "dim", "//", "2", ",", "x", ".", "shape", "[", "1", "]", "//", "(", "dim", "//", "2", ")", ",", "x", ".", "shape", "[", "-", "1", "]", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "# batch_size x ? x 1 x out_channels2", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "# batch_size x dim//4 x num_maps x seq_len", "\n", "x", "=", "x", ".", "view", "(", "batch_size", ",", "dim", "//", "4", ",", "x", ".", "shape", "[", "1", "]", "//", "(", "dim", "//", "4", ")", ",", "x", ".", "shape", "[", "-", "1", "]", ")", "\n", "# batch_size x seq_len x num_maps x dim//4", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "3", ")", "\n", "# batch_size x max_pool_dim x num_maps x dim//4, aligned", "\n", "x", ",", "_", "=", "self", ".", "dmp", "(", "x", ",", "lengths", ",", "2", ",", "2", ",", "pool_ranges", "=", "numpy", ".", "array", "(", "pool_result_ranges", ")", "+", "(", "self", ".", "ks2", "[", "1", "]", "-", "1", ")", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "neg_vec", "=", "torch", ".", "zeros_like", "(", "x", ")", "\n", "return", "torch", ".", "cat", "(", "(", "neg_vec", ",", "x", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.DinWhole.__init__": [[165, 169], ["model.MyModule.__init__", "utils.din.DeepInterestNetwork"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "id", "=", "\"din-whole\"", "\n", "self", ".", "din", "=", "DeepInterestNetwork", "(", "activation", "=", "'PReLU'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.DinWhole.forward": [[170, 172], ["model.DinWhole.din"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "batch", ")", ":", "\n", "        ", "return", "self", ".", "din", "(", "*", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.DinDiceWhole.__init__": [[175, 179], ["model.MyModule.__init__", "utils.din.DeepInterestNetwork"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "id", "=", "\"din-dice-whole\"", "\n", "self", ".", "din", "=", "DeepInterestNetwork", "(", "activation", "=", "'Dice'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.DinDiceWhole.forward": [[180, 182], ["model.DinDiceWhole.din"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "batch", ")", ":", "\n", "        ", "return", "self", ".", "din", "(", "*", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.DinDice.__init__": [[185, 189], ["model.MyModule.__init__", "utils.din.DeepInterestNetworkFixEmb", "utils.din.DeepInterestNetwork"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "id", "=", "\"din-dice\"", "\n", "self", ".", "din", "=", "DeepInterestNetworkFixEmb", "(", "DeepInterestNetwork", "(", "activation", "=", "'Dice'", ")", ",", "copy_pars", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.DinDice.forward": [[190, 192], ["model.DinDice.din"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "batch", ")", ":", "\n", "        ", "return", "self", ".", "din", "(", "*", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.Din.__init__": [[195, 199], ["model.MyModule.__init__", "utils.din.DeepInterestNetworkFixEmb", "utils.din.DeepInterestNetwork"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "id", "=", "\"din\"", "\n", "self", ".", "din", "=", "DeepInterestNetworkFixEmb", "(", "DeepInterestNetwork", "(", "activation", "=", "'PReLU'", ")", ",", "copy_pars", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.Din.forward": [[200, 202], ["model.Din.din"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "batch", ")", ":", "\n", "        ", "return", "self", ".", "din", "(", "*", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.DynamicMaxPool.__init__": [[210, 213], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__"], ["    ", "def", "__init__", "(", "self", ",", "top_k", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "top_k", "=", "top_k", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.DynamicMaxPool.forward": [[214, 225], ["zip", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "max", "model.kmax_pooling", "torch.nn.utils.rnn.pad_sequence.append", "torch.nn.utils.rnn.pad_sequence.append", "torch.nn.utils.rnn.pad_sequence.append", "len", "math.ceil"], "methods", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.kmax_pooling"], ["", "def", "forward", "(", "self", ",", "x", ",", "lengths", ",", "layer", ",", "total_layers", ",", "pool_ranges", ")", ":", "\n", "        ", "results", "=", "[", "]", "\n", "for", "sample", ",", "length", ",", "pool_range", "in", "zip", "(", "x", ",", "lengths", ",", "pool_ranges", ")", ":", "\n", "# pool_range x out_channels", "\n", "            ", "sample", "=", "sample", "[", ":", "pool_range", "]", "\n", "pool_target", "=", "max", "(", "self", ".", "top_k", ",", "ceil", "(", "(", "total_layers", "-", "layer", ")", "/", "total_layers", "*", "length", ")", ")", "\n", "sample", "=", "kmax_pooling", "(", "sample", ",", "pool_target", ",", "dim", "=", "0", ")", "\n", "results", ".", "append", "(", "sample", ")", "\n", "", "pool_result_ranges", "=", "[", "len", "(", "result", ")", "for", "result", "in", "results", "]", "\n", "results", "=", "pad_sequence", "(", "results", ",", "batch_first", "=", "True", ")", "\n", "return", "results", ",", "pool_result_ranges", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.kmax_pooling": [[204, 207], ["x.gather", "[].sort", "x.topk"], "function", ["None"], ["", "", "def", "kmax_pooling", "(", "x", ",", "k", ",", "dim", "=", "0", ")", ":", "\n", "    ", "index", "=", "x", ".", "topk", "(", "k", ",", "dim", "=", "dim", ")", "[", "1", "]", ".", "sort", "(", "dim", "=", "dim", ")", "[", "0", "]", "\n", "return", "x", ".", "gather", "(", "dim", ",", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.main": [[227, 242], ["torch.random.manual_seed", "torch.random.manual_seed", "torch.random.manual_seed", "random.seed", "numpy.random.seed", "model.Logistic", "model.LSTM2", "model.exists_initial", "model.save_initial", "print", "model.load_initial", "FileExistsError", "widgets.count_parameters"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.MyModule.exists_initial", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.MyModule.save_initial", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.MyModule.load_initial", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.count_parameters"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "from", "utils", "import", "widgets", "\n", "\n", "torch", ".", "random", ".", "manual_seed", "(", "0", ")", "\n", "random", ".", "seed", "(", "0", ")", "\n", "numpy", ".", "random", ".", "seed", "(", "0", ")", "\n", "\n", "for", "model", "in", "[", "Logistic", "(", ")", ",", "LSTM2", "(", "input_size", "=", "25", ",", "hidden_size", "=", "16", ")", "]", ":", "\n", "        ", "if", "model", ".", "exists_initial", "(", ")", ":", "\n", "            ", "model", ".", "load_initial", "(", ")", "\n", "raise", "FileExistsError", "(", "f\"{model.id} exists\"", ")", "\n", "\n", "", "model", ".", "save_initial", "(", ")", "\n", "\n", "print", "(", "f\"{widgets.count_parameters(model)} parameters in {model.id}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.__init__": [[40, 47], ["set"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mode", ")", ":", "\n", "        ", "self", ".", "mode", "=", "mode", "\n", "self", ".", "grad_sum", "=", "None", "\n", "self", ".", "running_grad_sum", "=", "None", "\n", "self", ".", "latest_grad_sum_avg", "=", "None", "\n", "self", ".", "grad_sum_cache", "=", "None", "\n", "self", ".", "participated_clients", "=", "set", "(", ")", "# clients that have participated, hold the ids", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.new_round": [[48, 61], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "model.parameters", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "server.Server.participated_clients.clear", "ValueError", "model.parameters", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "model.parameters", "model.parameters"], "methods", ["None"], ["", "def", "new_round", "(", "self", ",", "model", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'fedavg'", ":", "\n", "            ", "self", ".", "grad_sum", "=", "[", "torch", ".", "zeros_like", "(", "par", ")", "for", "par", "in", "model", ".", "parameters", "(", ")", "]", "\n", "if", "self", ".", "running_grad_sum", "is", "None", ":", "\n", "                ", "self", ".", "running_grad_sum", "=", "[", "torch", ".", "zeros_like", "(", "par", ")", "for", "par", "in", "model", ".", "parameters", "(", ")", "]", "\n", "", "", "elif", "self", ".", "mode", "==", "'lastavg'", ":", "\n", "            ", "if", "self", ".", "latest_grad_sum_avg", "is", "None", ":", "\n", "                ", "self", ".", "latest_grad_sum_avg", "=", "[", "torch", ".", "zeros_like", "(", "par", ")", "for", "par", "in", "model", ".", "parameters", "(", ")", "]", "\n", "", "", "elif", "self", ".", "mode", "==", "'waitavg'", ":", "\n", "            ", "self", ".", "grad_sum_cache", "=", "[", "torch", ".", "zeros_like", "(", "par", ")", "for", "par", "in", "model", ".", "parameters", "(", ")", "]", "\n", "self", ".", "participated_clients", ".", "clear", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unexpected mode {self.mode}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.aggregate": [[62, 77], ["kwargs.pop", "kwargs.pop", "zip", "zip", "zip", "ValueError"], "methods", ["None"], ["", "", "def", "aggregate", "(", "self", ",", "client_upload", ",", "**", "kwargs", ")", ":", "\n", "        ", "K", "=", "kwargs", ".", "pop", "(", "\"K\"", ",", "None", ")", "\n", "N", "=", "kwargs", ".", "pop", "(", "\"N\"", ",", "None", ")", "\n", "\n", "if", "self", ".", "mode", "==", "'fedavg'", ":", "\n", "            ", "for", "gs", ",", "client_gs", "in", "zip", "(", "self", ".", "grad_sum", ",", "client_upload", ")", ":", "\n", "                ", "gs", "+=", "client_gs", "/", "K", "\n", "", "", "elif", "self", ".", "mode", "==", "'lastavg'", ":", "\n", "            ", "for", "gs", ",", "client_gs", "in", "zip", "(", "self", ".", "latest_grad_sum_avg", ",", "client_upload", ")", ":", "\n", "                ", "gs", "+=", "client_gs", "/", "N", "\n", "", "", "elif", "self", ".", "mode", "==", "'waitavg'", ":", "\n", "            ", "for", "gs", ",", "client_gs", "in", "zip", "(", "self", ".", "grad_sum_cache", ",", "client_upload", ")", ":", "\n", "                ", "gs", "+=", "client_gs", "/", "N", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unexpected mode {self.mode}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.update": [[78, 93], ["kwargs.pop", "zip", "zip", "model.parameters", "par.data.sub_", "zip", "model.parameters", "par.data.sub_", "zip", "ValueError", "model.parameters", "par.data.sub_"], "methods", ["None"], ["", "", "def", "update", "(", "self", ",", "model", ",", "lr", ",", "**", "kwargs", ")", ":", "\n", "        ", "momentum", "=", "kwargs", ".", "pop", "(", "\"momentum\"", ",", "0.0", ")", "\n", "if", "self", ".", "mode", "==", "'fedavg'", ":", "\n", "            ", "for", "gs", ",", "running_gs", "in", "zip", "(", "self", ".", "grad_sum", ",", "self", ".", "running_grad_sum", ")", ":", "\n", "                ", "running_gs", "[", "...", "]", "=", "running_gs", "*", "momentum", "+", "gs", "*", "(", "1", "-", "momentum", ")", "\n", "", "for", "running_gs", ",", "par", "in", "zip", "(", "self", ".", "running_grad_sum", ",", "model", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "par", ".", "data", ".", "sub_", "(", "lr", "*", "running_gs", ")", "\n", "", "", "elif", "self", ".", "mode", "==", "'lastavg'", ":", "\n", "            ", "for", "gs", ",", "par", "in", "zip", "(", "self", ".", "latest_grad_sum_avg", ",", "model", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "par", ".", "data", ".", "sub_", "(", "lr", "*", "gs", ")", "\n", "", "", "elif", "self", ".", "mode", "==", "'waitavg'", ":", "\n", "            ", "for", "gs", ",", "par", "in", "zip", "(", "self", ".", "grad_sum_cache", ",", "model", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "par", ".", "data", ".", "sub_", "(", "lr", "*", "gs", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unexpected mode {self.mode}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.pick_clients": [[94, 113], ["client.is_available", "sorted.append", "len", "print", "len", "sorted", "random.sample", "len"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "pick_clients", "(", "clients", ",", "K", ",", "pick_outdated", ",", "current_round", ")", ":", "\n", "# current_round can be current_time for sentiment140", "\n", "        ", "available_clients", "=", "[", "]", "\n", "for", "client", "in", "clients", ":", "\n", "            ", "if", "client", ".", "is_available", "(", "current_round", ")", ":", "\n", "                ", "available_clients", ".", "append", "(", "client", ")", "\n", "", "", "if", "K", "==", "'all'", ":", "\n", "            ", "return", "available_clients", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "available_clients", ")", "<", "K", ":", "\n", "                ", "print", "(", "f\"*** Warning: round {current_round} available clients {len(available_clients)} < K {K}\"", ")", "\n", "K", "=", "len", "(", "available_clients", ")", "\n", "", "if", "pick_outdated", ":", "\n", "                ", "available_clients", "=", "sorted", "(", "available_clients", ",", "key", "=", "lambda", "c", ":", "c", ".", "r", ")", "\n", "picked_clients", "=", "available_clients", "[", ":", "K", "]", "\n", "", "else", ":", "\n", "                ", "picked_clients", "=", "random", ".", "sample", "(", "available_clients", ",", "K", ")", "\n", "", "return", "picked_clients", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.pick_clients_no_participated": [[114, 124], ["client.is_available", "picked_clients.append", "server.Server.participated_clients.add"], "methods", ["None"], ["", "", "def", "pick_clients_no_participated", "(", "self", ",", "clients", ",", "current_round", ")", ":", "\n", "# pick clients that have not participated in current 'epoch' training", "\n", "        ", "picked_clients", "=", "[", "]", "\n", "for", "client", "in", "clients", ":", "\n", "            ", "client", ":", "Client", "\n", "if", "client", ".", "is_available", "(", "current_round", ")", ":", "\n", "                ", "if", "client", ".", "id", "not", "in", "self", ".", "participated_clients", ":", "\n", "                    ", "picked_clients", ".", "append", "(", "client", ")", "\n", "self", ".", "participated_clients", ".", "add", "(", "client", ".", "id", ")", "\n", "", "", "", "return", "picked_clients", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.train_": [[126, 371], ["torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "model.to.to", "utils.logger.Logger", "utils.logger.Logger.has_checkpoint", "time.time", "utils.logger.Logger.add_meta", "kwargs.pop", "datetime.timedelta", "utils.logger.Logger.load_meta", "utils.logger.Logger.load_model", "datetime.timedelta", "kwargs.pop", "iter", "len", "ValueError", "logger.load_server.new_round", "kwargs.pop.", "time.time", "datetime.timedelta", "print", "datetime.timedelta", "kwargs.pop", "print", "utils.logger.Logger.reserve_checkpoint", "print", "utils.widgets.test_loader", "utils.logger.Logger.add_scalar", "utils.logger.Logger.add_scalar", "utils.logger.Logger.add_scalar", "print", "print", "torch.SGD", "range", "print", "utils.logger.Logger.flush", "utils.logger.Logger.backup_checkpoint", "utils.logger.Logger.dump_meta", "utils.logger.Logger.dump_model", "utils.logger.Logger.remove_backup", "utils.logger.Logger.add_statistics", "kwargs.pop", "kwargs.pop", "sum", "print", "kwargs.pop", "kwargs.pop", "kwargs.pop", "utils.logger.Logger.has_checkpoint", "utils.logger.Logger.add_scalar", "utils.widgets.test_loader", "utils.logger.Logger.add_scalar", "utils.logger.Logger.add_scalar", "utils.logger.Logger.add_scalar", "utils.widgets.latest_gradient_avg", "utils.widgets.rel_and_norm_error", "utils.logger.Logger.add_scalar", "utils.logger.Logger.add_scalar", "print", "model.to.parameters", "optim.SGD.zero_grad", "utils.widgets.data_b_to_right_device", "label_b.to.to", "utils.widgets.get_output", "criterion", "criterion.backward", "criterion.item", "optim.SGD.step", "torch.SGD", "optim.SGD.zero_grad", "enumerate", "model.to.parameters", "optim.SGD.step", "utils.logger.Logger.add_scalar", "utils.logger.Logger.add_scalar", "utils.logger.Logger.add_scalar", "print", "utils.logger.Logger.dump_server", "utils.logger.Logger.dump_clients", "utils.logger.Logger.load_server", "utils.logger.Logger.load_clients", "ValueError", "kwargs.pop", "kwargs.pop", "kwargs.pop", "utils.logger.Logger.add_scalar", "iter.__next__", "model.to.parameters", "print", "utils.widgets.data_b_to_right_device", "label_b.to.to", "utils.widgets.get_output", "criterion.backward", "criterion.item", "logger.load_server.new_round", "logger.load_server.pick_clients", "kwargs.pop", "iter", "iter.__next__", "torch.no_grad", "torch.no_grad", "torch.argmax", "torch.argmax", "criterion", "len", "torch.norm", "torch.norm", "logger.load_server.update", "logger.load_server.pick_clients_no_participated", "ValueError", "RuntimeError", "client.train", "logger.load_server.aggregate", "client.train", "logger.load_server.aggregate", "len", "len", "logger.load_server.update", "print", "logger.load_server.new_round", "time.time", "len", "client.train", "logger.load_server.aggregate", "logger.load_server.update", "RuntimeError", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.has_checkpoint", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_meta", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.load_meta", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.load_model", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.new_round", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.reserve_checkpoint", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.test_loader", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.flush", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.backup_checkpoint", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.dump_meta", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.dump_model", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.remove_backup", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_statistics", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.has_checkpoint", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.test_loader", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.latest_gradient_avg", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.rel_and_norm_error", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.data_b_to_right_device", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.get_output", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.dump_server", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.dump_clients", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.load_server", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.load_clients", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.data_b_to_right_device", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.widgets.get_output", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.new_round", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.pick_clients", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.update", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.pick_clients_no_participated", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.train", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.aggregate", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.train", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.aggregate", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.update", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.new_round", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.client.Client.train", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.aggregate", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.Server.update"], ["", "", "def", "train_", "(", "run_name", ",", "test_loader", ",", "train_loader", ",", "alg", ",", "log_args", ",", "log_argv", ",", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ",", "test_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'sum'", ")", ",", "\n", "**", "kwargs", ")", ":", "\n", "# get parameters", "\n", "    ", "lr", "=", "kwargs", ".", "pop", "(", "\"lr\"", ",", "lambda", "r", ":", "1e-2", ")", "\n", "num_rounds", "=", "kwargs", ".", "pop", "(", "\"num_rounds\"", ",", "50000", ")", "+", "1", "\n", "model", "=", "kwargs", ".", "pop", "(", "\"model_ori_path\"", ")", "# model rather than path", "\n", "print_every", "=", "kwargs", ".", "pop", "(", "\"print_every\"", ",", "1", ")", "\n", "tb_every", "=", "kwargs", ".", "pop", "(", "\"tb_every\"", ",", "1", ")", "\n", "statistics_every", "=", "kwargs", ".", "pop", "(", "\"statistics_every\"", ",", "100", ")", "\n", "checkpoint_every", "=", "kwargs", ".", "pop", "(", "\"checkpoint_every\"", ",", "100", ")", "\n", "max_checked", "=", "kwargs", ".", "pop", "(", "\"max_checked\"", ",", "10000", ")", "\n", "reserve_checkpoint_steps", "=", "kwargs", ".", "pop", "(", "\"reserve_checkpoint_steps\"", ",", "[", "]", ")", "\n", "E", "=", "kwargs", ".", "pop", "(", "\"E\"", ",", "None", ")", "\n", "num_non_update_rounds", "=", "kwargs", ".", "pop", "(", "\"num_non_update_rounds\"", ",", "None", ")", "\n", "log_auc", "=", "kwargs", ".", "pop", "(", "\"log_auc\"", ",", "False", ")", "\n", "\n", "# initialize", "\n", "model", "=", "model", ".", "to", "(", "device", "=", "common", ".", "device", ")", "\n", "logger", "=", "Logger", "(", "run_name", ")", "\n", "if", "E", "is", "not", "None", ":", "\n", "        ", "time1round", "=", "datetime", ".", "timedelta", "(", "days", "=", "1", ")", "/", "E", "\n", "", "else", ":", "\n", "        ", "time1round", "=", "datetime", ".", "timedelta", "(", "seconds", "=", "0", ")", "# not logged", "\n", "\n", "# common checkpoint practice", "\n", "", "if", "logger", ".", "has_checkpoint", "(", ")", ":", "\n", "        ", "state_dict", "=", "logger", ".", "load_meta", "(", ")", "\n", "current_round", "=", "state_dict", "[", "'current_round'", "]", "\n", "time_base", "=", "state_dict", "[", "'time'", "]", "\n", "if", "'simulated_time'", "not", "in", "state_dict", ":", "\n", "            ", "print", "(", "\"*** Warning: checkpoint of older runs, no simulated time dumped ***\"", ")", "\n", "simulated_time", "=", "datetime", ".", "timedelta", "(", "seconds", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "simulated_time", "=", "state_dict", "[", "'simulated_time'", "]", "\n", "", "logger", ".", "load_model", "(", "model", ")", "\n", "", "else", ":", "\n", "        ", "simulated_time", "=", "datetime", ".", "timedelta", "(", "seconds", "=", "0", ")", "\n", "current_round", "=", "0", "\n", "time_base", "=", "0.0", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# custom parameters", "\n", "if", "alg", "==", "'sgd'", ":", "\n", "        ", "num_its1round", "=", "kwargs", ".", "pop", "(", "'num_its1round'", ",", "None", ")", "\n", "train_iter", "=", "iter", "(", "train_loader", ")", "\n", "", "elif", "alg", "==", "'gd'", ":", "\n", "        ", "num_training_samples", "=", "kwargs", ".", "pop", "(", "'num_training_samples'", ")", "\n", "", "elif", "alg", "in", "(", "'fedavg'", ",", "'lastavg'", ",", "'waitavg'", ")", ":", "\n", "        ", "server", ":", "Server", "=", "kwargs", ".", "pop", "(", "'server'", ")", "\n", "clients", "=", "kwargs", ".", "pop", "(", "'clients'", ")", "\n", "num_training_samples", "=", "sum", "(", "[", "client", ".", "num_samples", "for", "client", "in", "clients", "]", ")", "\n", "print", "(", "f\"Actual number of training samples: {num_training_samples}\"", ")", "\n", "K", "=", "kwargs", ".", "pop", "(", "\"K\"", ",", "100", ")", "\n", "C", "=", "kwargs", ".", "pop", "(", "\"C\"", ",", "10", ")", "\n", "scale_in_it", "=", "kwargs", ".", "pop", "(", "\"scale_in_it\"", ",", "False", ")", "\n", "if", "logger", ".", "has_checkpoint", "(", ")", ":", "\n", "            ", "server", "=", "logger", ".", "load_server", "(", ")", "\n", "logger", ".", "load_clients", "(", "clients", ",", "target_alg", "=", "alg", ")", "\n", "", "if", "server", ".", "mode", "!=", "alg", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Wrong server with mode {server.mode}, expected {alg}\"", ")", "\n", "", "if", "alg", "==", "'fedavg'", ":", "\n", "            ", "momentum", "=", "kwargs", ".", "pop", "(", "\"momentum\"", ",", "0.0", ")", "\n", "pick_outdated", "=", "kwargs", ".", "pop", "(", "'pick_outdated'", ",", "False", ")", "\n", "mu_FedProx", "=", "kwargs", ".", "pop", "(", "\"mu_FedProx\"", ",", "0.0", ")", "\n", "", "elif", "alg", "==", "'lastavg'", ":", "\n", "            ", "pick_outdated", "=", "kwargs", ".", "pop", "(", "'pick_outdated'", ",", "True", ")", "\n", "", "", "if", "len", "(", "kwargs", ")", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Unexpected parameter {kwargs}\"", ")", "\n", "\n", "", "logger", ".", "add_meta", "(", "log_args", ",", "log_argv", ",", "current_round", ")", "\n", "\n", "num_updates", "=", "0", "# for waitavg", "\n", "if", "alg", "==", "'waitavg'", ":", "\n", "        ", "server", ".", "new_round", "(", "model", ")", "# first round", "\n", "", "while", "True", ":", "\n", "        ", "lr_", "=", "lr", "(", "current_round", ")", "\n", "c_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "current_round", "in", "reserve_checkpoint_steps", ":", "\n", "# to corporate with multistep decay, reserve checkpoint before training", "\n", "            ", "print", "(", "\"reserve checkpoint\"", ")", "\n", "logger", ".", "reserve_checkpoint", "(", ")", "\n", "", "if", "current_round", "%", "print_every", "==", "0", "and", "alg", "!=", "'gd'", ":", "\n", "            ", "print", "(", "f\"{run_name[:50]}, {current_round}, {simulated_time.days}d, lr %.5f\"", "%", "lr_", ",", "end", "=", "'\\r'", ")", "\n", "", "if", "current_round", "%", "tb_every", "==", "0", ":", "\n", "            ", "test_acc_", ",", "train_acc_", "=", "[", "-", "1.", "]", ",", "[", "-", "1.", "]", "\n", "test_loss_", ",", "train_loss_", "=", "[", "-", "1.", "]", ",", "[", "-", "1.", "]", "\n", "test_grad_norm_", ",", "train_grad_norm_", "=", "[", "-", "1.", "]", ",", "[", "-", "1.", "]", "\n", "if", "log_auc", ":", "\n", "                ", "test_auc_", ",", "train_auc_", "=", "[", "-", "1.", "]", ",", "[", "-", "1.", "]", "\n", "", "else", ":", "\n", "                ", "test_auc_", ",", "train_auc_", "=", "None", ",", "None", "\n", "", "widgets", ".", "test_loader", "(", "model", ",", "test_loader", ",", "max_checked", "=", "max_checked", ",", "criterion", "=", "test_criterion", ",", "\n", "acc_", "=", "test_acc_", ",", "loss_", "=", "test_loss_", ",", "grad_norm_", "=", "test_grad_norm_", ",", "auc_", "=", "test_auc_", ")", "\n", "time_stamp", "=", "c_time", "-", "start_time", "+", "time_base", "\n", "logger", ".", "add_scalar", "(", "\"test_accuracy\"", ",", "test_acc_", "[", "0", "]", ",", "current_round", ",", "time_stamp", ")", "\n", "logger", ".", "add_scalar", "(", "\"test_loss\"", ",", "test_loss_", "[", "0", "]", ",", "current_round", ",", "time_stamp", ")", "\n", "logger", ".", "add_scalar", "(", "\"test_grad_norm\"", ",", "test_grad_norm_", "[", "0", "]", ",", "current_round", ",", "time_stamp", ")", "\n", "if", "log_auc", ":", "\n", "                ", "logger", ".", "add_scalar", "(", "\"test_auc\"", ",", "test_auc_", "[", "0", "]", ",", "current_round", ",", "time_stamp", ")", "\n", "", "if", "alg", "!=", "'gd'", ":", "\n", "# gd log every iteration since there is no overhead", "\n", "                ", "widgets", ".", "test_loader", "(", "model", ",", "train_loader", ",", "max_checked", "=", "max_checked", ",", "criterion", "=", "test_criterion", ",", "\n", "acc_", "=", "train_acc_", ",", "loss_", "=", "train_loss_", ",", "grad_norm_", "=", "train_grad_norm_", ",", "auc_", "=", "train_auc_", ")", "\n", "logger", ".", "add_scalar", "(", "\"train_accuracy\"", ",", "train_acc_", "[", "0", "]", ",", "current_round", ",", "time_stamp", ")", "\n", "logger", ".", "add_scalar", "(", "\"train_loss\"", ",", "train_loss_", "[", "0", "]", ",", "current_round", ",", "time_stamp", ")", "\n", "logger", ".", "add_scalar", "(", "\"train_grad_norm\"", ",", "train_grad_norm_", "[", "0", "]", ",", "current_round", ",", "time_stamp", ")", "\n", "if", "log_auc", ":", "\n", "                    ", "logger", ".", "add_scalar", "(", "'train_auc'", ",", "train_auc_", "[", "0", "]", ",", "current_round", ",", "time_stamp", ")", "\n", "", "", "if", "alg", "==", "'lastavg'", ":", "\n", "# log the difference between the real latest gradient average and the running one", "\n", "                ", "latest_grad_avg", "=", "widgets", ".", "latest_gradient_avg", "(", "clients", ")", "\n", "rel_error", ",", "gs_error_norm", "=", "widgets", ".", "rel_and_norm_error", "(", "latest_grad_avg", ",", "server", ".", "latest_grad_sum_avg", ")", "\n", "logger", ".", "add_scalar", "(", "\"gs_rel_error\"", ",", "rel_error", ",", "current_round", ",", "time_stamp", ")", "\n", "logger", ".", "add_scalar", "(", "\"gs_error_norm\"", ",", "gs_error_norm", ",", "current_round", ",", "time_stamp", ")", "\n", "", "print", "(", "\"%d, te_ac: %.3f, tr_ac: %.3f, te_lo: %.5f, tr_lo: %.5f, te_gn: %.5f, tr_gn: %.5f\"", "%", "\n", "(", "current_round", ",", "test_acc_", "[", "0", "]", ",", "train_acc_", "[", "0", "]", ",", "test_loss_", "[", "0", "]", ",", "train_loss_", "[", "0", "]", ",", "\n", "test_grad_norm_", "[", "0", "]", ",", "train_grad_norm_", "[", "0", "]", ")", ",", "end", "=", "''", ")", "\n", "if", "log_auc", ":", "\n", "                ", "print", "(", "\", te_auc: %.3f, tr_auc: %.3f\"", "%", "\n", "(", "test_auc_", "[", "0", "]", ",", "train_auc_", "[", "0", "]", ")", ",", "end", "=", "''", ")", "\n", "", "print", "(", ")", "\n", "\n", "# perform a round", "\n", "", "if", "alg", "==", "'sgd'", ":", "\n", "            ", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr_", ")", "\n", "running_loss", "=", "0.0", "\n", "for", "c_it", "in", "range", "(", "num_its1round", ")", ":", "\n", "                ", "optimizer", ".", "zero_grad", "(", ")", "\n", "try", ":", "\n", "                    ", "data_b", ",", "label_b", "=", "train_iter", ".", "__next__", "(", ")", "\n", "", "except", "StopIteration", "as", "e", ":", "\n", "                    ", "train_iter", "=", "iter", "(", "train_loader", ")", "\n", "data_b", ",", "label_b", "=", "train_iter", ".", "__next__", "(", ")", "\n", "", "data_b", "=", "widgets", ".", "data_b_to_right_device", "(", "data_b", ")", "\n", "label_b", "=", "label_b", ".", "to", "(", "device", "=", "common", ".", "device", ")", "\n", "output_b", "=", "widgets", ".", "get_output", "(", "model", ",", "data_b", ")", "\n", "loss", "=", "criterion", "(", "output_b", ",", "label_b", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "running_loss", "+=", "loss", ".", "item", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "", "running_loss", "/=", "num_its1round", "\n", "", "elif", "alg", "==", "'gd'", ":", "\n", "            ", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr_", "/", "num_training_samples", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "running_loss", "=", "0.0", "\n", "num_right", "=", "0", "\n", "for", "b_idx", ",", "(", "data_b", ",", "label_b", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "                ", "print", "(", "f\"{b_idx}/{len(train_loader)}\"", ",", "end", "=", "'\\r'", ")", "\n", "data_b", "=", "widgets", ".", "data_b_to_right_device", "(", "data_b", ")", "\n", "label_b", "=", "label_b", ".", "to", "(", "device", "=", "common", ".", "device", ")", "\n", "output_b", "=", "widgets", ".", "get_output", "(", "model", ",", "data_b", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "pred_b", "=", "torch", ".", "argmax", "(", "output_b", ",", "dim", "=", "1", ")", "\n", "num_right", "+=", "(", "pred_b", "==", "label_b", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "loss", "=", "criterion", "(", "output_b", ",", "label_b", ")", "*", "len", "(", "label_b", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "running_loss", "+=", "loss", ".", "item", "(", ")", "\n", "", "grad_norm_squ", "=", "0.0", "\n", "for", "par", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "grad_norm_squ", "+=", "torch", ".", "norm", "(", "par", ".", "grad", "/", "num_training_samples", ")", "**", "2", "\n", "", "grad_norm", "=", "grad_norm_squ", "**", "0.5", "\n", "optimizer", ".", "step", "(", ")", "\n", "running_loss", "/=", "num_training_samples", "\n", "train_acc", "=", "num_right", "/", "num_training_samples", "\n", "time_stamp", "=", "c_time", "-", "start_time", "+", "time_base", "\n", "logger", ".", "add_scalar", "(", "\"train_accuracy\"", ",", "train_acc", ",", "current_round", ",", "time_stamp", ")", "\n", "logger", ".", "add_scalar", "(", "\"train_loss\"", ",", "running_loss", ",", "current_round", ",", "time_stamp", ")", "\n", "logger", ".", "add_scalar", "(", "\"train_grad_norm\"", ",", "grad_norm", ",", "current_round", ",", "time_stamp", ")", "\n", "print", "(", "\"GD %d, lr: %.7f, train_acc: %.5f, train_loss: %.5f, train_gn: %.5f\"", "%", "\n", "(", "current_round", ",", "lr_", ",", "train_acc", ",", "running_loss", ",", "grad_norm", ")", ")", "\n", "", "elif", "alg", "in", "(", "'fedavg'", ",", "'lastavg'", ")", ":", "\n", "            ", "server", ".", "new_round", "(", "model", ")", "\n", "_isa_input", "=", "clients", "[", "0", "]", ".", "is_available_input", "\n", "if", "_isa_input", "==", "'round'", ":", "\n", "                ", "_current_round", "=", "current_round", "\n", "", "elif", "_isa_input", "==", "'time'", ":", "\n", "                ", "_current_round", "=", "simulated_time", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "f\"clients weirdly initialized with is_available_input = {_isa_input}\"", ")", "\n", "", "picked_clients", "=", "server", ".", "pick_clients", "(", "clients", ",", "K", ",", "pick_outdated", "=", "pick_outdated", ",", "\n", "current_round", "=", "_current_round", ")", "\n", "\n", "client", ":", "Client", "\n", "if", "alg", "==", "'fedavg'", ":", "\n", "                ", "for", "client", "in", "picked_clients", ":", "\n", "                    ", "scale_inner", "=", "len", "(", "clients", ")", "*", "client", ".", "num_samples", "/", "num_training_samples", "\n", "grad_sum_", "=", "[", "None", "]", "\n", "client", ".", "train", "(", "model", ",", "criterion", ",", "lr_", ",", "scale", "=", "scale_inner", ",", "scale_in_it", "=", "scale_in_it", ",", "\n", "C", "=", "C", ",", "current_round", "=", "current_round", ",", "abs_grad_sum_", "=", "grad_sum_", ",", "mu_FedProx", "=", "mu_FedProx", ")", "\n", "server", ".", "aggregate", "(", "grad_sum_", "[", "0", "]", ",", "K", "=", "len", "(", "picked_clients", ")", ")", "\n", "", "server", ".", "update", "(", "model", ",", "lr", "=", "lr_", ",", "momentum", "=", "momentum", ")", "\n", "", "elif", "alg", "==", "'lastavg'", ":", "\n", "                ", "for", "client", "in", "picked_clients", ":", "\n", "                    ", "scale_inner", "=", "len", "(", "clients", ")", "*", "client", ".", "num_samples", "/", "num_training_samples", "\n", "grad_sum_diff", "=", "client", ".", "train", "(", "model", ",", "criterion", ",", "lr_", ",", "scale", "=", "scale_inner", ",", "scale_in_it", "=", "scale_in_it", ",", "\n", "C", "=", "C", ",", "current_round", "=", "current_round", ")", "\n", "server", ".", "aggregate", "(", "grad_sum_diff", ",", "N", "=", "len", "(", "clients", ")", ")", "\n", "", "if", "current_round", ">=", "num_non_update_rounds", ":", "\n", "                    ", "server", ".", "update", "(", "model", ",", "lr", "=", "lr_", ")", "\n", "", "", "", "elif", "alg", "==", "'waitavg'", ":", "\n", "            ", "_isa_input", "=", "clients", "[", "0", "]", ".", "is_available_input", "\n", "if", "_isa_input", "==", "'round'", ":", "\n", "                ", "_current_round", "=", "current_round", "\n", "", "elif", "_isa_input", "==", "'time'", ":", "\n", "                ", "_current_round", "=", "simulated_time", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "f\"clients weirdly initialized with is_available_input = {_isa_input}\"", ")", "\n", "", "picked_clients", "=", "server", ".", "pick_clients_no_participated", "(", "clients", "=", "clients", ",", "current_round", "=", "_current_round", ")", "\n", "\n", "client", ":", "Client", "\n", "for", "client", "in", "picked_clients", ":", "\n", "                ", "scale_inner", "=", "len", "(", "clients", ")", "*", "client", ".", "num_samples", "/", "num_training_samples", "\n", "grad_sum_", "=", "[", "None", "]", "\n", "client", ".", "train", "(", "model", ",", "criterion", ",", "lr_", ",", "scale", "=", "scale_inner", ",", "scale_in_it", "=", "scale_in_it", ",", "\n", "C", "=", "C", ",", "current_round", "=", "current_round", ",", "abs_grad_sum_", "=", "grad_sum_", ")", "\n", "server", ".", "aggregate", "(", "grad_sum_", "[", "0", "]", ",", "N", "=", "len", "(", "clients", ")", ")", "\n", "\n", "", "if", "len", "(", "server", ".", "participated_clients", ")", "==", "len", "(", "clients", ")", ":", "# all clients participated update model", "\n", "                ", "server", ".", "update", "(", "model", ",", "lr", "=", "lr_", ")", "\n", "num_updates", "+=", "1", "\n", "print", "(", "'\\nserver updated model in round: %d for the %d times'", "%", "(", "current_round", ",", "num_updates", ")", ")", "\n", "server", ".", "new_round", "(", "model", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unrecognized alg: {alg}\"", ")", "\n", "\n", "", "current_round", "+=", "1", "\n", "simulated_time", "+=", "time1round", "\n", "if", "current_round", "%", "checkpoint_every", "==", "0", ":", "\n", "            ", "print", "(", "\"checkpoint\"", ")", "\n", "logger", ".", "flush", "(", ")", "\n", "logger", ".", "backup_checkpoint", "(", ")", "\n", "logger", ".", "dump_meta", "(", "{", "'current_round'", ":", "current_round", ",", "\n", "'time'", ":", "time", ".", "time", "(", ")", "-", "start_time", "+", "time_base", ",", "\n", "'simulated_time'", ":", "simulated_time", "}", ")", "\n", "logger", ".", "dump_model", "(", "model", ")", "\n", "if", "alg", "in", "(", "'fedavg'", ",", "'lastavg'", ",", "'waitavg'", ")", ":", "\n", "                ", "logger", ".", "dump_server", "(", "server", ")", "\n", "logger", ".", "dump_clients", "(", "clients", ")", "\n", "", "logger", ".", "remove_backup", "(", ")", "\n", "", "if", "alg", "in", "(", "'fedavg'", ",", "'lastavg'", ",", "'waitavg'", ")", "and", "current_round", "%", "statistics_every", "==", "0", ":", "\n", "            ", "logger", ".", "add_statistics", "(", "clients", ",", "current_round", ")", "\n", "", "if", "current_round", "==", "num_rounds", ":", "\n", "            ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.main": [[373, 773], ["train.command_line.parser.parse_args", "dict", "dict", "dict", "dict", "os.exists", "train.model.Din.load_initial", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "dict.get", "ValueError", "round", "os.join", "input", "model_ori.split", "train.model.Net", "torchvision.transforms.Compose", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "server.Server", "print", "print", "print", "server.train_", "server.train_", "dict.get", "exit", "float", "train.model.MobileNetV2", "torchvision.transforms.Compose", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "os.join", "train.prepare_clients.initialize_clients", "server.train_", "ValueError", "train.model.Logistic", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "print", "utils.sentiment140.Sentiment140Dataset.filter_clients_", "utils.sentiment140.Sentiment140Dataset.random_select_clients_", "print", "print", "print", "print", "utils.sentiment140.Sentiment140Dataset.partition", "print", "utils.alibaba.AlibabaDataset.count_clients", "print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "os.exists", "print", "utils.alibaba.AlibabaDataset.get_clients", "len", "server.train_", "ValueError", "ValueError", "model_ori.split", "train.model.LSTM2", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "int", "utils.sentiment140.Sentiment140Dataset", "utils.sentiment140.Sentiment140Dataset.time_variation_", "input", "print", "utils.alibaba.AlibabaDataset", "utils.alibaba.AlibabaDataset", "utils.alibaba.AlibabaDataset.shuffle_", "utils.alibaba.AlibabaDataset.shuffle_", "print", "ValueError", "utils.partition.partition", "utils.partition.partition", "utils.alibaba.get_clients", "print", "utils.alibaba.AlibabaDataset.filter_clients_", "utils.alibaba.AlibabaDataset.filter_clients_", "print", "print", "ValueError", "len", "server.train_", "open", "eval", "eval", "model_ori.split", "train.model.DinWhole", "re.search().group", "utils.sentiment140.ComposedProcess", "utils.sentiment140.Sentiment140Dataset", "ValueError", "exit", "os.join", "os.join", "f.readline", "f.readline", "ValueError", "len", "len", "ValueError", "list", "int", "int", "train.model.DinDiceWhole", "utils.sentiment140.BasicProcess", "utils.sentiment140.CleanTweet", "utils.sentiment140.BagOfWords", "utils.sentiment140.BagOfWords.multihot", "utils.sentiment140.ComposedProcess", "len", "zip", "train.model.DinDice", "re.search", "utils.sentiment140.BasicProcess", "utils.sentiment140.CleanTweet", "len", "len", "train.model.Din", "ValueError"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.model.MyModule.load_initial", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.train_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.train_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.prepare_clients.initialize_clients", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.train_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.filter_clients_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.random_select_clients_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.partition", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.count_clients", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.get_clients", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.train_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.time_variation_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba.AlibabaDataset.shuffle_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.alibaba.AlibabaDataset.shuffle_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.partition", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.partition", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.get_clients", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.filter_clients_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.Sentiment140Dataset.filter_clients_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.server.train_", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.utils.sentiment140.BagOfWords.multihot"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "\"\"\"\n    *** maintenance guidance ***\n    When modifying parser:\n        please parse it and get the argument into local variables\n        please check whether we need to add it to the auto_generated run_name\n        please pass it to train for *all* algorithms\n    \"\"\"", "\n", "# configure command line args", "\n", "import", "train", ".", "command_line", "\n", "\n", "# parse args", "\n", "args", "=", "train", ".", "command_line", ".", "parser", ".", "parse_args", "(", ")", "\n", "# modify default arguments", "\n", "if", "args", ".", "lr_strategy", "==", "'multi'", ":", "\n", "        ", "args", ".", "lr_decay", "=", "1.0", "\n", "", "default_model_ori", "=", "dict", "(", "cifar10", "=", "'CPCFF'", ",", "sentiment140", "=", "'lstm_i300_h256'", ",", "mnist", "=", "'logistic'", ",", "ali", "=", "'din'", ")", "\n", "if", "args", ".", "model_ori", "is", "None", ":", "\n", "        ", "args", ".", "model_ori", "=", "default_model_ori", "[", "args", ".", "dataset", "]", "\n", "", "default_batch_size", "=", "dict", "(", "cifar10", "=", "5", ",", "sentiment140", "=", "2", ",", "mnist", "=", "5", ",", "ali", "=", "2", ")", "\n", "if", "args", ".", "batch_size", "==", "-", "1", ":", "\n", "        ", "args", ".", "batch_size", "=", "default_batch_size", "[", "args", ".", "dataset", "]", "\n", "", "default_alpha", "=", "dict", "(", "time", "=", "0.5", ",", "number", "=", "0.1", ",", "mix", "=", "0.3", ",", "block", "=", "None", ")", "\n", "if", "args", ".", "alpha", "==", "-", "1", ":", "\n", "        ", "args", ".", "alpha", "=", "default_alpha", "[", "args", ".", "strategy", "]", "\n", "", "default_filter_clients", "=", "dict", "(", "sentiment140", "=", "40", ",", "ali", "=", "32", ")", "\n", "if", "args", ".", "filter_clients", "==", "-", "1", ":", "\n", "        ", "args", ".", "filter_clients", "=", "default_filter_clients", ".", "get", "(", "args", ".", "dataset", ",", "-", "1", ")", "\n", "\n", "# focused parameters", "\n", "", "dataset_indicator", "=", "args", ".", "dataset", "\n", "run_name", "=", "args", ".", "run_name", "\n", "alg", "=", "args", ".", "algorithm", "\n", "N", "=", "args", ".", "num_total_clients", "\n", "beta", "=", "args", ".", "beta", "\n", "C", "=", "args", ".", "num_local_iterations", "\n", "E", "=", "args", ".", "E", "\n", "momentum", "=", "args", ".", "momentum", "\n", "mu_FedProx", "=", "args", ".", "mu_FedProx", "\n", "availability_file", "=", "args", ".", "availability_file", "\n", "# learning rate parameters", "\n", "lr_strategy", "=", "args", ".", "lr_strategy", "\n", "init_lr", "=", "args", ".", "init_lr", "\n", "lr_decay", "=", "args", ".", "lr_decay", "\n", "lr_dstep", "=", "args", ".", "lr_dstep", "\n", "lr_indicator", "=", "args", ".", "lr_indicator", "\n", "lr_config", "=", "args", ".", "lr_config", "\n", "# parameters controlling logging", "\n", "print_every", "=", "args", ".", "print_every", "\n", "tb_every", "=", "args", ".", "tb_every", "\n", "checkpoint_every", "=", "args", ".", "checkpoint_every", "\n", "sta_every", "=", "args", ".", "statistics_every", "\n", "max_test", "=", "args", ".", "max_test", "\n", "# uncared parameters", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "batch_size_when_test", "=", "args", ".", "batch_size_when_test", "\n", "num_rounds", "=", "args", ".", "num_rounds", "\n", "num_non_update_rounds", "=", "args", ".", "num_non_update_rounds", "\n", "balanced", "=", "args", ".", "balanced", "\n", "shuffle", "=", "args", ".", "shuffle", "\n", "filter_clients", "=", "args", ".", "filter_clients", "\n", "filter_clients_up", "=", "args", ".", "filter_clients_up", "\n", "scale_in_it", "=", "args", ".", "scale_in_it", "\n", "# image classification parameters", "\n", "alpha", "=", "args", ".", "alpha", "\n", "normalize_mean", "=", "args", ".", "normalize_mean", "\n", "normalize_std", "=", "args", ".", "normalize_std", "\n", "num_iid", "=", "args", ".", "num_iid", "\n", "strategy", "=", "args", ".", "strategy", "\n", "# ML model", "\n", "model_ori", "=", "args", ".", "model_ori", "\n", "nlp_algorithm", "=", "args", ".", "nlp_algorithm", "\n", "glove_model", "=", "args", ".", "glove_model", "\n", "# sentiment140", "\n", "availability_model", "=", "args", ".", "availability_model", "\n", "force_variation", "=", "args", ".", "force_variation", "\n", "fv_num_blocks", "=", "args", ".", "fv_num_blocks", "\n", "fv_min_prop", "=", "args", ".", "fv_min_prop", "\n", "fv_max_prop", "=", "args", ".", "fv_max_prop", "\n", "\n", "if", "dataset_indicator", "==", "'sentiment140'", "and", "E", "%", "24", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\"Only accept E=24 for sentiment140\"", ")", "\n", "\n", "# generate args", "\n", "", "if", "beta", "!=", "1.0", ":", "\n", "        ", "K", "=", "round", "(", "N", "*", "beta", ")", "\n", "", "else", ":", "\n", "        ", "K", "=", "'all'", "\n", "", "shuffle", "=", "True", "if", "shuffle", "else", "False", "\n", "scale_in_it", "=", "True", "if", "scale_in_it", "else", "False", "\n", "# run name", "\n", "if", "run_name", "is", "None", ":", "\n", "        ", "run_name", "=", "f\"{alg}\"", "\n", "if", "dataset_indicator", "!=", "'cifar10'", ":", "\n", "            ", "run_name", "+=", "f\"_{dataset_indicator}\"", "\n", "", "if", "N", "!=", "1000", ":", "\n", "            ", "run_name", "+=", "f\"_N{N}\"", "\n", "", "if", "beta", "!=", "0.1", ":", "\n", "            ", "run_name", "+=", "f\"_beta{beta}\"", "\n", "", "if", "C", "!=", "10", ":", "\n", "            ", "run_name", "+=", "f\"_C{C}\"", "\n", "", "if", "E", "!=", "10", ":", "\n", "            ", "run_name", "+=", "f\"_E{E}\"", "\n", "", "if", "alpha", "!=", "default_alpha", "[", "strategy", "]", "and", "strategy", "!=", "'block'", ":", "\n", "            ", "run_name", "+=", "f\"_alpha{alpha}\"", "\n", "", "if", "momentum", "!=", "0.0", ":", "\n", "            ", "run_name", "+=", "f\"_momentum{momentum}\"", "\n", "", "if", "lr_strategy", "!=", "'exp'", ":", "\n", "            ", "run_name", "+=", "f\"_lrS{lr_strategy}\"", "\n", "", "if", "init_lr", "!=", "0.01", "and", "lr_strategy", "!=", "'multi'", ":", "\n", "            ", "run_name", "+=", "f\"_lrI{init_lr}\"", "\n", "", "if", "lr_decay", "!=", "0.9999", "and", "lr_strategy", "!=", "'multi'", ":", "\n", "            ", "run_name", "+=", "f\"_lrD{lr_decay}\"", "\n", "", "if", "lr_dstep", "!=", "1", "and", "lr_strategy", "!=", "'multi'", ":", "\n", "            ", "run_name", "+=", "f\"_lrDs{lr_dstep}\"", "\n", "", "if", "lr_indicator", "!=", "'?'", ":", "\n", "            ", "run_name", "+=", "f\"_lrSC{lr_indicator}\"", "# scheme", "\n", "", "if", "batch_size", "!=", "default_batch_size", "[", "dataset_indicator", "]", ":", "\n", "            ", "run_name", "+=", "f\"_bs{batch_size}\"", "\n", "", "if", "model_ori", "!=", "default_model_ori", "[", "dataset_indicator", "]", ":", "\n", "            ", "run_name", "+=", "f\"_[mo_{model_ori}]\"", "\n", "", "if", "nlp_algorithm", "!=", "'embedding'", ":", "\n", "            ", "run_name", "+=", "f\"_[nlp_alg_{nlp_algorithm}]\"", "\n", "", "if", "glove_model", "!=", "'glove.840B.300d'", ":", "\n", "            ", "run_name", "+=", "f'_[gm_{glove_model}]'", "\n", "", "if", "filter_clients", "!=", "default_filter_clients", ".", "get", "(", "dataset_indicator", ",", "-", "1", ")", ":", "\n", "            ", "run_name", "+=", "f\"_fc{filter_clients}\"", "\n", "", "if", "filter_clients_up", "!=", "2", "**", "32", ":", "\n", "            ", "run_name", "+=", "f\"_fcu{filter_clients_up}\"", "\n", "", "if", "num_non_update_rounds", "!=", "0", ":", "\n", "            ", "run_name", "+=", "f\"_nnur{num_non_update_rounds}\"", "\n", "", "if", "availability_model", "!=", "\"blocked\"", ":", "\n", "            ", "run_name", "+=", "f\"_[am_{availability_model}]\"", "\n", "", "if", "normalize_mean", "!=", "0.5", ":", "\n", "            ", "run_name", "+=", "f\"_nm{normalize_mean}\"", "\n", "", "if", "normalize_std", "!=", "0.5", ":", "\n", "            ", "run_name", "+=", "f\"_ns{normalize_std}\"", "\n", "", "if", "num_iid", "!=", "0", ":", "\n", "            ", "run_name", "+=", "f\"_ni{num_iid}\"", "\n", "", "if", "strategy", "!=", "'time'", ":", "\n", "            ", "run_name", "+=", "f\"_[stg_{strategy}]\"", "\n", "", "if", "mu_FedProx", "!=", "0.0", ":", "\n", "            ", "run_name", "+=", "f\"_mu{mu_FedProx}\"", "\n", "", "if", "force_variation", "==", "1", ":", "\n", "            ", "run_name", "+=", "f\"_fv\"", "\n", "", "if", "fv_num_blocks", "!=", "24", ":", "\n", "            ", "run_name", "+=", "f\"-nb{fv_num_blocks}\"", "\n", "", "if", "fv_min_prop", "!=", "0.0", ":", "\n", "            ", "run_name", "+=", "f\"-mi{fv_min_prop}\"", "\n", "", "if", "fv_max_prop", "!=", "1.0", ":", "\n", "            ", "run_name", "+=", "f\"-ma{fv_max_prop}\"", "\n", "", "if", "balanced", "==", "1", ":", "\n", "            ", "run_name", "+=", "f\"_balanced\"", "\n", "", "if", "not", "shuffle", ":", "\n", "            ", "run_name", "+=", "f\"_nshuf\"", "\n", "", "if", "scale_in_it", ":", "\n", "            ", "run_name", "+=", "f\"_sii\"", "\n", "", "if", "availability_file", "!=", "\"client_available\"", ":", "\n", "            ", "run_name", "+=", "f\"_[_af_{availability_file}]\"", "\n", "\n", "# interact with user", "\n", "", "", "checkpoint_exists", "=", "osp", ".", "exists", "(", "osp", ".", "join", "(", "common", ".", "record_fd", ",", "run_name", ")", ")", "\n", "if", "checkpoint_exists", ":", "\n", "        ", "proceed", "=", "input", "(", "f\"run_name: \\\"{run_name}\\\" exists, do you really want to continue from checkpoints? (yes/no)\"", ")", "\n", "if", "proceed", "!=", "'yes'", ":", "\n", "            ", "exit", "(", ")", "\n", "\n", "# reserve intermediate checkpoints", "\n", "", "", "reserve_checkpoint_steps", "=", "[", "]", "\n", "\n", "# learning rate", "\n", "if", "lr_strategy", "==", "'const'", ":", "\n", "        ", "def", "lr", "(", "r", ")", ":", "\n", "            ", "return", "init_lr", "\n", "", "", "elif", "lr_strategy", "==", "'exp'", ":", "\n", "        ", "def", "lr", "(", "r", ")", ":", "\n", "            ", "return", "init_lr", "*", "lr_decay", "**", "(", "r", "//", "lr_dstep", ")", "\n", "", "", "elif", "lr_strategy", "==", "'multi'", ":", "\n", "        ", "if", "lr_indicator", "==", "'?'", ":", "\n", "            ", "raise", "ValueError", "(", "\"multistep decay should specify a indicator\"", ")", "\n", "", "if", "lr_decay", "!=", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"lr_decay should be 1.0 for multistep decay\"", ")", "\n", "\n", "", "if", "lr_config", "is", "None", ":", "\n", "            ", "def", "lr", "(", "r", ")", ":", "\n", "                ", "return", "init_lr", "\n", "", "", "else", ":", "\n", "            ", "with", "open", "(", "osp", ".", "join", "(", "common", ".", "lr_configure_fd", ",", "lr_config", "+", "'.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "decay_steps", "=", "eval", "(", "f", ".", "readline", "(", ")", ")", "\n", "lrs", "=", "eval", "(", "f", ".", "readline", "(", ")", ")", "\n", "if", "decay_steps", "[", "0", "]", "!=", "0", ":", "\n", "                    ", "raise", "ValueError", "(", "\"invalid lr config since not specify initial lr\"", ")", "\n", "", "if", "len", "(", "decay_steps", ")", "!=", "len", "(", "lrs", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "\"invalid lr config since steps and lrs do not match in length\"", ")", "\n", "", "", "reserve_checkpoint_steps", "=", "decay_steps", "[", "1", ":", "]", "\n", "\n", "def", "lr", "(", "r", ")", ":", "\n", "                ", "for", "step", ",", "lr_", "in", "list", "(", "zip", "(", "decay_steps", ",", "lrs", ")", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "                    ", "if", "r", ">=", "step", ":", "\n", "                        ", "return", "lr_", "\n", "", "", "", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Unrecognized lr_strategy: {lr_strategy}\"", ")", "\n", "\n", "# dataset, loaders, and ml model", "\n", "", "model_indicator", "=", "model_ori", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "if", "model_indicator", "==", "\"CPCFF\"", ":", "\n", "        ", "ori_model", "=", "Net", "(", ")", "\n", "", "elif", "model_indicator", "==", "'mobile2'", ":", "\n", "        ", "width_mult_", "=", "float", "(", "model_ori", ".", "split", "(", "'_'", ")", "[", "1", "]", "[", "2", ":", "]", ")", "\n", "ori_model", "=", "train", ".", "model", ".", "MobileNetV2", "(", "width_mult", "=", "width_mult_", ")", "\n", "", "elif", "model_indicator", "==", "'logistic'", ":", "\n", "        ", "ori_model", "=", "Logistic", "(", ")", "\n", "", "elif", "model_indicator", "==", "\"lstm\"", ":", "\n", "        ", "_", ",", "in_features", ",", "h_features", "=", "model_ori", ".", "split", "(", "'_'", ")", "\n", "ori_model", "=", "LSTM2", "(", "input_size", "=", "int", "(", "in_features", "[", "1", ":", "]", ")", ",", "hidden_size", "=", "int", "(", "h_features", "[", "1", ":", "]", ")", ")", "\n", "", "elif", "model_indicator", "==", "'din-whole'", ":", "\n", "        ", "ori_model", "=", "DinWhole", "(", ")", "\n", "", "elif", "model_indicator", "==", "'din-dice-whole'", ":", "\n", "        ", "ori_model", "=", "DinDiceWhole", "(", ")", "\n", "", "elif", "model_indicator", "==", "'din-dice'", ":", "\n", "        ", "ori_model", "=", "DinDice", "(", ")", "\n", "", "elif", "model_indicator", "==", "'din'", ":", "\n", "        ", "ori_model", "=", "Din", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Unrecognized model {model_indicator}\"", ")", "\n", "", "ori_model", ".", "load_initial", "(", ")", "\n", "if", "dataset_indicator", "==", "'cifar10'", ":", "\n", "        ", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "normalize_mean", ",", ")", "*", "3", ",", "(", "normalize_std", ",", ")", "*", "3", ")", "]", ")", "\n", "trainset", "=", "torchvision", ".", "datasets", ".", "CIFAR10", "(", "root", "=", "common", ".", "raw_data_dir", ",", "train", "=", "True", ",", "download", "=", "False", ",", "\n", "transform", "=", "transform", ")", "\n", "testset", "=", "torchvision", ".", "datasets", ".", "CIFAR10", "(", "root", "=", "common", ".", "raw_data_dir", ",", "train", "=", "False", ",", "download", "=", "False", ",", "\n", "transform", "=", "transform", ")", "\n", "", "elif", "dataset_indicator", "==", "'mnist'", ":", "\n", "        ", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "normalize_mean", ",", ")", ",", "(", "normalize_std", ",", ")", ")", "]", ")", "\n", "trainset", "=", "torchvision", ".", "datasets", ".", "MNIST", "(", "root", "=", "common", ".", "raw_data_dir", ",", "train", "=", "True", ",", "download", "=", "True", ",", "\n", "transform", "=", "transform", ")", "\n", "testset", "=", "torchvision", ".", "datasets", ".", "MNIST", "(", "root", "=", "common", ".", "raw_data_dir", ",", "train", "=", "False", ",", "download", "=", "True", ",", "\n", "transform", "=", "transform", ")", "\n", "", "elif", "dataset_indicator", "==", "'sentiment140'", ":", "\n", "        ", "if", "nlp_algorithm", "==", "'bow'", ":", "\n", "            ", "bow_num_features", "=", "int", "(", "re", ".", "search", "(", "r\"[0-9]+\"", ",", "model_ori", ")", ".", "group", "(", ")", ")", "\n", "sentiment140_dataset", "=", "Sentiment140Dataset", "(", "ComposedProcess", "(", "\n", "BasicProcess", "(", ")", ",", "\n", "CleanTweet", "(", "verbose", "=", "True", ")", ",", "\n", "BagOfWords", "(", "bow_num_features", ",", "verbose", "=", "True", ")", "\n", ")", ",", "embedding_fn", "=", "None", ",", "transform", "=", "BagOfWords", ".", "multihot", "(", "bow_num_features", ")", ")", "\n", "", "elif", "nlp_algorithm", "==", "'embedding'", ":", "\n", "            ", "sentiment140_dataset", "=", "Sentiment140Dataset", "(", "ComposedProcess", "(", "\n", "BasicProcess", "(", ")", ",", "\n", "CleanTweet", "(", "verbose", "=", "True", ")", ",", "\n", ")", ",", "embedding_fn", "=", "glove_model", ",", "transform", "=", "\"glove_trans\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unexpected nlp_algorithm {nlp_algorithm}\"", ")", "\n", "", "print", "(", "\"filtering clients...\"", ",", "end", "=", "'\\r'", ")", "\n", "sentiment140_dataset", ".", "filter_clients_", "(", "filter_clients", ",", "up", "=", "filter_clients_up", ")", "\n", "sentiment140_dataset", ".", "random_select_clients_", "(", "N", ")", "\n", "print", "(", "\"clients filtered    \"", ")", "\n", "print", "(", "\"drop samples...\"", ",", "end", "=", "\"\\r\"", ")", "\n", "if", "force_variation", ":", "\n", "            ", "sentiment140_dataset", ".", "time_variation_", "(", "num_blocks", "=", "fv_num_blocks", ",", "min_prop", "=", "fv_min_prop", ",", "max_prop", "=", "fv_max_prop", ")", "\n", "", "print", "(", "\"samples droped \"", ")", "\n", "print", "(", "\"partitioning dataset...\"", ",", "end", "=", "'\\r'", ")", "\n", "trainset", ",", "testset", "=", "sentiment140_dataset", ".", "partition", "(", ")", "\n", "print", "(", "\"dataset partitioned    \"", ")", "\n", "actual_N", "=", "trainset", ".", "count_clients", "(", ")", "\n", "print", "(", "f\"There are actually {actual_N} clients, {len(trainset)} training samples\"", ")", "\n", "if", "actual_N", "!=", "N", ":", "\n", "            ", "response", "=", "input", "(", "f\"After filtering and sampling clients, there are actually {actual_N}!={N} clients, \"", "\n", "f\"continue? (yes/no)\"", ")", "\n", "if", "response", "!=", "'yes'", ":", "\n", "                ", "exit", "(", ")", "\n", "", "", "", "elif", "dataset_indicator", "==", "'ali'", ":", "\n", "        ", "print", "(", "\"loading dataset...\"", ",", "end", "=", "'\\r'", ")", "\n", "trainset", "=", "AlibabaDataset", "(", "alibaba_train_fp", ")", "\n", "testset", "=", "AlibabaDataset", "(", "alibaba_test_fp", ")", "\n", "trainset", ".", "shuffle_", "(", ")", "\n", "testset", ".", "shuffle_", "(", ")", "\n", "print", "(", "\"dataset loaded    \"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Unrecognized dataset {dataset_indicator}\"", ")", "\n", "", "criterion_mean", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "criterion_sum", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'sum'", ")", "\n", "if", "dataset_indicator", "==", "'sentiment140'", "and", "nlp_algorithm", "==", "'embedding'", ":", "\n", "        ", "if", "alg", "in", "(", "'gd'", ",", "'sgd'", ")", ":", "\n", "            ", "trainloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "shuffle", ",", "\n", "collate_fn", "=", "Sentiment140Dataset", ".", "collate_fn", ")", "\n", "", "else", ":", "\n", "            ", "trainloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "batch_size_when_test", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "Sentiment140Dataset", ".", "collate_fn", ")", "\n", "", "testloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "testset", ",", "batch_size", "=", "batch_size_when_test", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "Sentiment140Dataset", ".", "collate_fn", ")", "\n", "", "elif", "dataset_indicator", "==", "'ali'", ":", "\n", "        ", "if", "alg", "in", "(", "'gd'", ",", "'sgd'", ")", ":", "\n", "            ", "trainloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "shuffle", ",", "\n", "collate_fn", "=", "AlibabaDataset", ".", "collate_fn", ")", "\n", "", "else", ":", "\n", "            ", "trainloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "batch_size_when_test", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "AlibabaDataset", ".", "collate_fn", ")", "\n", "", "testloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "testset", ",", "batch_size", "=", "batch_size_when_test", ",", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "AlibabaDataset", ".", "collate_fn", ")", "\n", "", "else", ":", "\n", "        ", "if", "alg", "in", "(", "'gd'", ",", "'sgd'", ")", ":", "\n", "            ", "trainloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "shuffle", ")", "\n", "", "else", ":", "\n", "            ", "trainloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "batch_size_when_test", ",", "shuffle", "=", "False", ")", "\n", "", "testloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "testset", ",", "batch_size", "=", "batch_size_when_test", ",", "shuffle", "=", "False", ")", "\n", "\n", "# server and clients", "\n", "", "if", "alg", "in", "(", "'fedavg'", ",", "'lastavg'", ",", "'waitavg'", ")", ":", "\n", "        ", "server", "=", "Server", "(", "alg", ")", "\n", "print", "(", "\"getting clients...\"", ")", "\n", "if", "dataset_indicator", "in", "(", "'cifar10'", ",", "'mnist'", ")", ":", "\n", "            ", "partition_fn", "=", "f\"{dataset_indicator}_N{N}_ni{num_iid}\"", "\n", "if", "balanced", ":", "\n", "                ", "partition_fn", "+=", "\"_b1\"", "\n", "", "partition_fp", "=", "osp", ".", "join", "(", "common", ".", "data_cache_dir", ",", "partition_fn", ")", "\n", "if", "not", "osp", ".", "exists", "(", "partition_fp", ")", ":", "\n", "                ", "if", "balanced", ":", "\n", "                    ", "partition", "(", "num_clients", "=", "N", ",", "num_iid", "=", "num_iid", ",", "dataset", "=", "dataset_indicator", ",", "\n", "output_data_dir", "=", "partition_fp", ",", "num_samples_clamp_thres", "=", "0.0", ")", "\n", "", "else", ":", "\n", "                    ", "partition", "(", "num_clients", "=", "N", ",", "num_iid", "=", "num_iid", ",", "dataset", "=", "dataset_indicator", ",", "\n", "output_data_dir", "=", "partition_fp", ")", "\n", "", "print", "(", "f\"client partition file saved into {partition_fp}\"", ")", "\n", "", "clients", "=", "initialize_clients", "(", "trainset", ",", "partition_fp", ",", "\n", "E", ",", "alpha", "=", "alpha", ",", "train_batch_size", "=", "batch_size", ",", "strategy", "=", "strategy", ")", "\n", "", "elif", "dataset_indicator", "==", "'sentiment140'", ":", "\n", "            ", "clients", "=", "trainset", ".", "get_clients", "(", "strategy", "=", "availability_model", ",", "train_batch_size", "=", "batch_size", ")", "\n", "", "elif", "dataset_indicator", "==", "'ali'", ":", "\n", "            ", "clients", "=", "alibaba", ".", "get_clients", "(", "osp", ".", "join", "(", "common", ".", "alibaba_fd", ",", "f\"{filter_clients}_{filter_clients_up}\"", ")", ",", "\n", "train_batch_size", "=", "batch_size", ",", "num_clients", "=", "N", ",", "availability_file", "=", "availability_file", ")", "\n", "print", "(", "\"filtering clients\"", ")", "\n", "trainset", ".", "filter_clients_", "(", "clients", ")", "\n", "testset", ".", "filter_clients_", "(", "clients", ")", "\n", "# print(\"plotting statistics\")", "\n", "# widgets.plot_time2available_data_ratio(clients)", "\n", "# print(\"plotted\")", "\n", "print", "(", "f\"filter complete, {len(trainset)} training samples, {len(testset)} test samples\"", ")", "\n", "print", "(", "f\"*** Warning! filter_clients upper and lower bound currently not supported for ali\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"unrecognized dataset {dataset_indicator}\"", ")", "\n", "", "print", "(", "f\"Got {len(clients)} clients                   \"", ")", "\n", "\n", "", "log_auc", "=", "dataset_indicator", "==", "'ali'", "\n", "\n", "# starting training", "\n", "if", "alg", "==", "'sgd'", ":", "\n", "        ", "print", "(", "f\"number of iterations one round in SGD: {K * C}\"", ")", "\n", "train_", "(", "run_name", "=", "run_name", ",", "test_loader", "=", "testloader", ",", "train_loader", "=", "trainloader", ",", "alg", "=", "alg", ",", "\n", "num_its1round", "=", "K", "*", "C", ",", "\n", "criterion", "=", "criterion_mean", ",", "test_criterion", "=", "criterion_sum", ",", "\n", "lr", "=", "lr", ",", "num_rounds", "=", "num_rounds", ",", "model_ori_path", "=", "ori_model", ",", "\n", "print_every", "=", "print_every", ",", "tb_every", "=", "tb_every", ",", "checkpoint_every", "=", "checkpoint_every", ",", "max_checked", "=", "max_test", ",", "\n", "log_args", "=", "args", ",", "log_argv", "=", "sys", ".", "argv", ",", "\n", "log_auc", "=", "log_auc", ",", "\n", "reserve_checkpoint_steps", "=", "reserve_checkpoint_steps", ")", "\n", "", "if", "alg", "==", "'gd'", ":", "\n", "        ", "train_", "(", "run_name", "=", "run_name", ",", "test_loader", "=", "testloader", ",", "train_loader", "=", "trainloader", ",", "alg", "=", "alg", ",", "\n", "num_training_samples", "=", "len", "(", "trainset", ")", ",", "\n", "criterion", "=", "criterion_mean", ",", "test_criterion", "=", "criterion_sum", ",", "\n", "lr", "=", "lr", ",", "num_rounds", "=", "num_rounds", ",", "model_ori_path", "=", "ori_model", ",", "\n", "print_every", "=", "print_every", ",", "tb_every", "=", "tb_every", ",", "checkpoint_every", "=", "checkpoint_every", ",", "max_checked", "=", "max_test", ",", "\n", "log_args", "=", "args", ",", "log_argv", "=", "sys", ".", "argv", ",", "\n", "log_auc", "=", "log_auc", ",", "\n", "reserve_checkpoint_steps", "=", "reserve_checkpoint_steps", ")", "\n", "", "elif", "alg", "==", "'fedavg'", ":", "\n", "        ", "train_", "(", "run_name", "=", "run_name", ",", "test_loader", "=", "testloader", ",", "train_loader", "=", "trainloader", ",", "alg", "=", "alg", ",", "\n", "server", "=", "server", ",", "clients", "=", "clients", ",", "K", "=", "K", ",", "C", "=", "C", ",", "momentum", "=", "momentum", ",", "E", "=", "E", ",", "mu_FedProx", "=", "mu_FedProx", ",", "\n", "scale_in_it", "=", "scale_in_it", ",", "\n", "criterion", "=", "criterion_mean", ",", "test_criterion", "=", "criterion_sum", ",", "\n", "lr", "=", "lr", ",", "num_rounds", "=", "num_rounds", ",", "model_ori_path", "=", "ori_model", ",", "\n", "print_every", "=", "print_every", ",", "tb_every", "=", "tb_every", ",", "checkpoint_every", "=", "checkpoint_every", ",", "\n", "statistics_every", "=", "sta_every", ",", "max_checked", "=", "max_test", ",", "\n", "log_args", "=", "args", ",", "log_argv", "=", "sys", ".", "argv", ",", "\n", "log_auc", "=", "log_auc", ",", "\n", "reserve_checkpoint_steps", "=", "reserve_checkpoint_steps", ")", "\n", "", "elif", "alg", "==", "'lastavg'", ":", "\n", "        ", "train_", "(", "run_name", "=", "run_name", ",", "test_loader", "=", "testloader", ",", "train_loader", "=", "trainloader", ",", "alg", "=", "alg", ",", "\n", "server", "=", "server", ",", "clients", "=", "clients", ",", "K", "=", "K", ",", "C", "=", "C", ",", "E", "=", "E", ",", "num_non_update_rounds", "=", "num_non_update_rounds", ",", "\n", "scale_in_it", "=", "scale_in_it", ",", "\n", "criterion", "=", "criterion_mean", ",", "test_criterion", "=", "criterion_sum", ",", "\n", "lr", "=", "lr", ",", "num_rounds", "=", "num_rounds", ",", "model_ori_path", "=", "ori_model", ",", "\n", "print_every", "=", "print_every", ",", "tb_every", "=", "tb_every", ",", "checkpoint_every", "=", "checkpoint_every", ",", "\n", "statistics_every", "=", "sta_every", ",", "max_checked", "=", "max_test", ",", "\n", "log_args", "=", "args", ",", "log_argv", "=", "sys", ".", "argv", ",", "\n", "log_auc", "=", "log_auc", ",", "\n", "reserve_checkpoint_steps", "=", "reserve_checkpoint_steps", ")", "\n", "", "elif", "alg", "==", "'waitavg'", ":", "\n", "        ", "train_", "(", "run_name", "=", "run_name", ",", "test_loader", "=", "testloader", ",", "train_loader", "=", "trainloader", ",", "alg", "=", "alg", ",", "\n", "server", "=", "server", ",", "clients", "=", "clients", ",", "K", "=", "K", ",", "C", "=", "C", ",", "E", "=", "E", ",", "num_non_update_rounds", "=", "num_non_update_rounds", ",", "\n", "scale_in_it", "=", "scale_in_it", ",", "\n", "criterion", "=", "criterion_mean", ",", "test_criterion", "=", "criterion_sum", ",", "\n", "lr", "=", "lr", ",", "num_rounds", "=", "num_rounds", ",", "model_ori_path", "=", "ori_model", ",", "\n", "print_every", "=", "print_every", ",", "tb_every", "=", "tb_every", ",", "checkpoint_every", "=", "checkpoint_every", ",", "\n", "statistics_every", "=", "sta_every", ",", "max_checked", "=", "max_test", ",", "\n", "log_args", "=", "args", ",", "log_argv", "=", "sys", ".", "argv", ",", "\n", "log_auc", "=", "log_auc", ",", "\n", "reserve_checkpoint_steps", "=", "reserve_checkpoint_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.prepare_clients.diurnal_available": [[23, 45], ["int", "int", "ValueError"], "function", ["None"], ["def", "diurnal_available", "(", "E", ",", "alpha", ",", "client_group", ")", ":", "\n", "    ", "\"\"\"\n    :param E: defined in paper\n    :param alpha: defined in paper, ratio\n    :param client_group: 0 or 1, 0: available for E rounds 1: available for \\alpha E rounds\n    :return: the availability function to be passed to a Client initializer\n        prototype: is_available(r) -> bool\n    \"\"\"", "\n", "\n", "def", "is_available", "(", "r", ")", ":", "\n", "        ", "E0", "=", "int", "(", "E", ")", "\n", "E1", "=", "int", "(", "alpha", "*", "E", ")", "\n", "period", "=", "E0", "+", "E1", "\n", "r_mod", "=", "r", "%", "period", "\n", "if", "client_group", "==", "0", ":", "\n", "            ", "return", "r_mod", "<", "E0", "\n", "", "elif", "client_group", "==", "1", ":", "\n", "            ", "return", "r_mod", ">=", "E0", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"invalid client_group: {client_group}\"", ")", "\n", "\n", "", "", "return", "is_available", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.prepare_clients.block_available": [[47, 63], ["None"], "function", ["None"], ["", "def", "block_available", "(", "E", ",", "num_blocks", ",", "client_block", ")", ":", "\n", "    ", "\"\"\"\n    :param E: defined in paper\n    :param num_blocks: total number of blocks\n    :param client_block: the block idx for this client\n    :return: the availability function to be passed to a Client initializer\n        prototype: is_available(r) -> bool\n    \"\"\"", "\n", "\n", "def", "is_available", "(", "r", ")", ":", "\n", "        ", "r_in_period", "=", "r", "%", "E", "\n", "num_rounds1block", "=", "E", "//", "num_blocks", "\n", "current_block", "=", "r_in_period", "//", "num_rounds1block", "\n", "return", "current_block", "==", "client_block", "\n", "\n", "", "return", "is_available", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.prepare_clients.initialize_clients": [[65, 153], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "random.seed", "os.walk", "len", "ValueError", "ValueError", "ValueError", "ValueError", "range", "train.client.Client", "clients.append", "round", "set", "range", "random.shuffle", "round", "RuntimeError", "osp.join", "prepare_clients.diurnal_available", "random.sample", "random.sample", "train.client.Client", "clients.append", "range", "random.shuffle", "ValueError", "ValueError", "str", "range", "range", "osp.join", "prepare_clients.diurnal_available", "train.client.Client", "clients.append", "str", "osp.join", "prepare_clients.block_available", "str"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.prepare_clients.diurnal_available", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.prepare_clients.diurnal_available", "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.prepare_clients.block_available"], ["", "def", "initialize_clients", "(", "trainset", ",", "client_partition", ",", "E", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    :param trainset: training set\n    :param client_partition: the directory saving client data partition schemes\n    :param E: defined in paper\n    :param kwargs:\n        alpha: defined in the paper\n        train_batch_size: training batch size for each client\n        strategy: chosen from ('time', 'number')\n            'time' means available for alpha E rounds\n            'number' means alpha proportion of clients are available in half time\n                e.g. alpha = 0.2, 20% clients (those corresponding to class 1 and 2) are available in the first block\n                for number, alpha = 0.5 means balanced\n            'mix' means first group has (1 - alpha) with class 0-4 and alpha with class 5-9, while the second group is the contrast\n            'block' means partition multiple client block with different class\n        seed: remove randomness among experiments\n        num_blocks: number of blocks for block strategy\n    :return: a list of the clients\n    \"\"\"", "\n", "alpha", "=", "kwargs", ".", "pop", "(", "\"alpha\"", ",", "0.5", ")", "\n", "train_batch_size", "=", "kwargs", ".", "pop", "(", "\"train_batch_size\"", ",", "5", ")", "\n", "strategy", "=", "kwargs", ".", "pop", "(", "'strategy'", ",", "'time'", ")", "\n", "seed", "=", "kwargs", ".", "pop", "(", "'seed'", ",", "common", ".", "other_seed", ")", "\n", "num_blocks", "=", "kwargs", ".", "pop", "(", "\"num_blocks\"", ",", "5", ")", "\n", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "N", "=", "None", "\n", "for", "_", ",", "_", ",", "_files", "in", "os", ".", "walk", "(", "client_partition", ")", ":", "\n", "        ", "N", "=", "len", "(", "_files", ")", "\n", "break", "\n", "", "if", "N", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "f\"invalid client_partition directory: {client_partition}\"", ")", "\n", "", "if", "N", "%", "2", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "f\"N = {N} should be multiple of 2\"", ")", "\n", "", "if", "N", "%", "num_blocks", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "f\"N={N} should be a multiple of num_blocks={num_blocks}\"", ")", "\n", "", "if", "E", "%", "num_blocks", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "f\"E={E} should be a multiple of num_blocks={num_blocks}\"", ")", "\n", "\n", "", "clients", "=", "[", "]", "\n", "if", "strategy", "in", "(", "'time'", ",", "'number'", ")", ":", "\n", "        ", "if", "strategy", "==", "'time'", ":", "\n", "            ", "num_classes_in_day", "=", "5", "\n", "alpha_time", "=", "alpha", "\n", "", "elif", "strategy", "==", "'number'", ":", "\n", "            ", "_eps", "=", "0.0001", "\n", "if", "_eps", "<", "alpha", "%", "0.1", "<", "0.1", "-", "_eps", ":", "\n", "                ", "raise", "ValueError", "(", "f\"When strategy == number, alpha={alpha}, but should be multiple of 0.1\"", ")", "\n", "", "num_classes_in_day", "=", "round", "(", "10", "*", "alpha", ")", "\n", "alpha_time", "=", "1", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"bug in program\"", ")", "\n", "\n", "", "for", "client_idx", "in", "range", "(", "N", ")", ":", "\n", "            ", "if", "client_idx", "<", "N", "//", "10", "*", "num_classes_in_day", ":", "\n", "                ", "client_group", "=", "0", "\n", "", "else", ":", "\n", "                ", "client_group", "=", "1", "\n", "", "client", "=", "Client", "(", "trainset", ",", "osp", ".", "join", "(", "client_partition", ",", "str", "(", "client_idx", ")", ")", ",", "\n", "diurnal_available", "(", "E", ",", "alpha_time", ",", "client_group", ")", ",", "\n", "train_batch_size", "=", "train_batch_size", ",", "id", "=", "client_idx", ")", "\n", "clients", ".", "append", "(", "client", ")", "\n", "", "", "elif", "strategy", "==", "'mix'", ":", "\n", "        ", "num_clients_minor", "=", "round", "(", "N", "//", "2", "*", "alpha", ")", "\n", "num_clients_major", "=", "N", "//", "2", "-", "num_clients_minor", "\n", "group0_client_idxs", "=", "random", ".", "sample", "(", "range", "(", "N", "//", "2", ")", ",", "num_clients_major", ")", "+", "random", ".", "sample", "(", "range", "(", "N", "//", "2", ",", "N", ")", ",", "num_clients_minor", ")", "\n", "group0_client_idxs", "=", "set", "(", "group0_client_idxs", ")", "\n", "for", "client_idx", "in", "range", "(", "N", ")", ":", "\n", "            ", "client_group", "=", "0", "if", "client_idx", "in", "group0_client_idxs", "else", "1", "\n", "client", "=", "Client", "(", "trainset", ",", "osp", ".", "join", "(", "client_partition", ",", "str", "(", "client_idx", ")", ")", ",", "\n", "diurnal_available", "(", "E", ",", "1", ",", "client_group", ")", ",", "\n", "train_batch_size", "=", "train_batch_size", ",", "id", "=", "client_idx", ")", "\n", "clients", ".", "append", "(", "client", ")", "\n", "", "random", ".", "shuffle", "(", "clients", ")", "\n", "", "elif", "strategy", "==", "'block'", ":", "\n", "        ", "num_clients1block", "=", "N", "//", "num_blocks", "\n", "for", "client_idx", "in", "range", "(", "N", ")", ":", "\n", "            ", "client_block", "=", "client_idx", "//", "num_clients1block", "\n", "client", "=", "Client", "(", "trainset", ",", "osp", ".", "join", "(", "client_partition", ",", "str", "(", "client_idx", ")", ")", ",", "\n", "block_available", "(", "E", "=", "E", ",", "num_blocks", "=", "num_blocks", ",", "client_block", "=", "client_block", ")", ",", "\n", "train_batch_size", "=", "train_batch_size", ",", "id", "=", "client_idx", ")", "\n", "clients", ".", "append", "(", "client", ")", "\n", "", "random", ".", "shuffle", "(", "clients", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"strategy={strategy}, but should be chosen from ('time', 'number')\"", ")", "\n", "", "return", "clients", "\n", "\n"]], "home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.prepare_clients._test1": [[155, 176], ["torchvision.datasets.CIFAR10", "prepare_clients.initialize_clients", "set", "enumerate", "plt.savefig", "print", "range", "osp.join", "plt.scatter", "osp.join", "print", "enumerate", "print", "set.add", "random.random", "client.is_available", "len", "available_set.append"], "function", ["home.repos.pwc.inspect_result.mikudehuane_FedLaAvg.train.prepare_clients.initialize_clients"], ["", "def", "_test1", "(", ")", ":", "\n", "    ", "trainset", "=", "torchvision", ".", "datasets", ".", "CIFAR10", "(", "root", "=", "raw_data_dir", ",", "train", "=", "True", ",", "download", "=", "False", ")", "\n", "clients", "=", "initialize_clients", "(", "trainset", ",", "osp", ".", "join", "(", "data_cache_dir", ",", "\"cifar10_N100_ni0\"", ")", ",", "\n", "E", "=", "10", ",", "alpha", "=", "0.3", ",", "train_batch_size", "=", "5", ",", "strategy", "=", "'block'", ")", "\n", "training_indices", "=", "set", "(", ")", "\n", "\n", "from", "matplotlib", "import", "pyplot", "as", "plt", "\n", "for", "client_idx", ",", "client", "in", "enumerate", "(", "clients", ")", ":", "\n", "        ", "for", "idx", "in", "client", ".", "train_indices", ":", "\n", "            ", "training_indices", ".", "add", "(", "idx", ")", "\n", "", "plt", ".", "scatter", "(", "client", ".", "num_samples", ",", "random", ".", "random", "(", ")", ",", "c", "=", "'red'", ")", "\n", "", "plt", ".", "savefig", "(", "osp", ".", "join", "(", "'debug'", ",", "'statistic.png'", ")", ")", "\n", "print", "(", "f\"total training samples: {len(training_indices)}\"", ")", "\n", "\n", "for", "round_", "in", "range", "(", "30", ")", ":", "\n", "        ", "print", "(", "f\"round: {round_}\"", ")", "\n", "available_set", "=", "[", "]", "\n", "for", "client_idx", ",", "client", "in", "enumerate", "(", "clients", ")", ":", "\n", "            ", "if", "client", ".", "is_available", "(", "round_", ")", ":", "\n", "                ", "available_set", ".", "append", "(", "client", ".", "id", ")", "\n", "", "", "print", "(", "available_set", ")", "\n", "\n"]]}