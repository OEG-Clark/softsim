{"home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.__init__": [[15, 21], ["baselines.common.vec_env.VecEnv.__init__"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.__init__"], ["def", "__init__", "(", "self", ",", "venv", ",", "observation_space", "=", "None", ",", "action_space", "=", "None", ")", ":", "\n", "        ", "self", ".", "venv", "=", "venv", "\n", "VecEnv", ".", "__init__", "(", "self", ",", "\n", "num_envs", "=", "venv", ".", "num_envs", ",", "\n", "observation_space", "=", "observation_space", "or", "venv", ".", "observation_space", ",", "\n", "action_space", "=", "action_space", "or", "venv", ".", "action_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.step_async": [[22, 24], ["multitask_vec_normalize.MTVecEnvWrapper.venv.step_async"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.MTSubprocVecEnv.step_async"], ["", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "        ", "self", ".", "venv", ".", "step_async", "(", "actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.reset": [[25, 28], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "reset", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.step_wait": [[29, 32], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.close": [[33, 35], ["multitask_vec_normalize.MTVecEnvWrapper.venv.close"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.render": [[36, 41], ["multitask_vec_normalize.MTVecEnvWrapper.venv.render", "multitask_vec_normalize.MTVecEnvWrapper.venv.render"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.render", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.render"], ["", "def", "render", "(", "self", ",", "z", "=", "None", ",", "mode", "=", "'human'", ")", ":", "\n", "        ", "if", "z", "is", "None", ":", "\n", "            ", "return", "self", ".", "venv", ".", "render", "(", "mode", "=", "mode", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "venv", ".", "render", "(", "z", "=", "z", ",", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.get_images": [[42, 44], ["multitask_vec_normalize.MTVecEnvWrapper.venv.get_images"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.MTSubprocVecEnv.get_images"], ["", "", "def", "get_images", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "get_images", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.draw_and_set_task": [[45, 47], ["multitask_vec_normalize.MTVecEnvWrapper.venv.draw_and_set_task"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.draw_and_set_task"], ["", "def", "draw_and_set_task", "(", "self", ",", "constraint", ",", "seed", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "draw_and_set_task", "(", "constraint", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecNormalize.__init__": [[55, 64], ["multitask_vec_normalize.MTVecEnvWrapper.__init__", "numpy.zeros", "baselines.common.running_mean_std.RunningMeanStd", "baselines.common.running_mean_std.RunningMeanStd"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.__init__"], ["def", "__init__", "(", "self", ",", "venv", ",", "ob", "=", "True", ",", "ret", "=", "True", ",", "clipob", "=", "10.", ",", "cliprew", "=", "10.", ",", "gamma", "=", "0.99", ",", "epsilon", "=", "1e-8", ")", ":", "\n", "        ", "MTVecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ")", "\n", "self", ".", "ob_rms", "=", "RunningMeanStd", "(", "shape", "=", "self", ".", "observation_space", ".", "shape", ")", "if", "ob", "else", "None", "\n", "self", ".", "ret_rms", "=", "RunningMeanStd", "(", "shape", "=", "(", ")", ")", "if", "ret", "else", "None", "\n", "self", ".", "clipob", "=", "clipob", "\n", "self", ".", "cliprew", "=", "cliprew", "\n", "self", ".", "ret", "=", "np", ".", "zeros", "(", "self", ".", "num_envs", ")", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecNormalize.step_wait": [[65, 74], ["multitask_vec_normalize.MTVecNormalize.venv.step_wait", "multitask_vec_normalize.MTVecNormalize._obfilt", "multitask_vec_normalize.MTVecNormalize.ret_rms.update", "numpy.clip", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.MTSubprocVecEnv.step_wait", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecNormalize._obfilt", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.update"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "obs", ",", "rews", ",", "news", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "self", ".", "ret", "=", "self", ".", "ret", "*", "self", ".", "gamma", "+", "rews", "\n", "obs", "=", "self", ".", "_obfilt", "(", "obs", ")", "\n", "if", "self", ".", "ret_rms", ":", "\n", "            ", "self", ".", "ret_rms", ".", "update", "(", "self", ".", "ret", ")", "\n", "rews", "=", "np", ".", "clip", "(", "rews", "/", "np", ".", "sqrt", "(", "self", ".", "ret_rms", ".", "var", "+", "self", ".", "epsilon", ")", ",", "-", "self", ".", "cliprew", ",", "self", ".", "cliprew", ")", "\n", "", "self", ".", "ret", "[", "news", "]", "=", "0.", "\n", "return", "obs", ",", "rews", ",", "news", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecNormalize._obfilt": [[75, 82], ["multitask_vec_normalize.MTVecNormalize.ob_rms.update", "numpy.clip", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.update"], ["", "def", "_obfilt", "(", "self", ",", "obs", ")", ":", "\n", "        ", "if", "self", ".", "ob_rms", ":", "\n", "            ", "self", ".", "ob_rms", ".", "update", "(", "obs", ")", "\n", "obs", "=", "np", ".", "clip", "(", "(", "obs", "-", "self", ".", "ob_rms", ".", "mean", ")", "/", "np", ".", "sqrt", "(", "self", ".", "ob_rms", ".", "var", "+", "self", ".", "epsilon", ")", ",", "-", "self", ".", "clipob", ",", "self", ".", "clipob", ")", "\n", "return", "obs", "\n", "", "else", ":", "\n", "            ", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecNormalize.reset": [[83, 87], ["numpy.zeros", "multitask_vec_normalize.MTVecNormalize.venv.reset", "multitask_vec_normalize.MTVecNormalize._obfilt"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.reset", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecNormalize._obfilt"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "ret", "=", "np", ".", "zeros", "(", "self", ".", "num_envs", ")", "\n", "obs", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "return", "self", ".", "_obfilt", "(", "obs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.main.printHeader": [[51, 56], ["logging.info", "logging.info"], "function", ["None"], ["def", "printHeader", "(", ")", ":", "\n", "    ", "logging", ".", "info", "(", "\n", "'      Progr | FPS | avg | med | min | max  '", ")", "\n", "logging", ".", "info", "(", "\n", "'      ------|-----|-----|-----|-----|----- '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.main.configuration": [[58, 77], ["float"], "function", ["None"], ["", "@", "ex", ".", "config", "\n", "def", "configuration", "(", "environment", ",", "architecture", ",", "tasks", ",", "test_tasks", ",", "num_steps", ",", "num_test_steps", ",", "loss", ")", ":", "\n", "\n", "    ", "if", "test_tasks", "is", "None", ":", "\n", "        ", "test_tasks", "=", "tasks", "\n", "\n", "", "if", "num_test_steps", "is", "None", ":", "\n", "        ", "num_test_steps", "=", "num_steps", "\n", "\n", "", "if", "loss", "[", "'c_kl_a'", "]", "is", "None", ":", "\n", "        ", "loss", "[", "'c_kl_a'", "]", "=", "float", "(", "loss", "[", "'c_kl_b'", "]", ")", "\n", "loss", "[", "'fixed_a'", "]", "=", "False", "\n", "", "else", ":", "\n", "        ", "loss", "[", "'fixed_a'", "]", "=", "True", "\n", "", "loss", "[", "'c_kl_b_orig'", "]", "=", "loss", "[", "'c_kl_b'", "]", "\n", "loss", "[", "'c_kl_a_orig'", "]", "=", "loss", "[", "'c_kl_a'", "]", "\n", "\n", "if", "loss", "[", "'entropy_loss_coef_test'", "]", "is", "None", ":", "\n", "        ", "loss", "[", "'entropy_loss_coef_test'", "]", "=", "loss", "[", "'entropy_loss_coef_0'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.main.reset_task": [[79, 106], ["len", "agent.init_optimizer", "print", "hierarchical_actor_critic.reset_task_policy", "numpy.random.randint", "hierarchical_actor_critic.get_slice", "range", "envs.draw_and_set_task", "testing_envs.draw_and_set_task"], "function", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.init_optimizer", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.reset_task_policy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.get_slice", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.draw_and_set_task", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.draw_and_set_task"], ["", "", "@", "ex", ".", "capture", "\n", "def", "reset_task", "(", "restart_tasks", ",", "hierarchical_actor_critic", ",", "constraint", ",", "agent", ",", "returned_task_seed", ",", "envs", ",", "testing_envs", ",", "\n", "tasks", ",", "num_processes", ")", ":", "\n", "    ", "num_tasks", "=", "len", "(", "tasks", ")", "\n", "num_processes_per_task", "=", "num_processes", "//", "num_tasks", "\n", "\n", "for", "next_restart_task", "in", "restart_tasks", ":", "\n", "        ", "print", "(", "\"Resetting task {} ({})\"", ".", "format", "(", "next_restart_task", ",", "\n", "constraint", "[", "next_restart_task", "*", "num_processes_per_task", "]", ")", ")", "\n", "hierarchical_actor_critic", ".", "reset_task_policy", "(", "task_id", "=", "next_restart_task", ")", "\n", "\n", "# Set a new task seed for all processes of the task that needs to be replaced", "\n", "# Constraints remain the same", "\n", "new_task_seed", "=", "np", ".", "random", ".", "randint", "(", "LONG_NUMBER", ")", "\n", "low", ",", "high", "=", "hierarchical_actor_critic", ".", "get_slice", "(", "next_restart_task", ")", "\n", "for", "i", "in", "range", "(", "low", ",", "high", ")", ":", "\n", "            ", "returned_task_seed", "[", "i", "]", "=", "new_task_seed", "\n", "\n", "", "returned_task_seed", "=", "envs", ".", "draw_and_set_task", "(", "\n", "constraint", "=", "constraint", ",", "\n", "seed", "=", "returned_task_seed", ")", "\n", "testing_envs", ".", "draw_and_set_task", "(", "\n", "constraint", "=", "constraint", ",", "\n", "seed", "=", "returned_task_seed", ")", "\n", "", "agent", ".", "init_optimizer", "(", "hierarchical_actor_critic", ")", "\n", "\n", "return", "returned_task_seed", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.main.save_model": [[108, 130], ["os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "logging.info", "_run.add_artifact", "os.remove", "model.state_dict", "os.path.getsize", "isinstance", "os.path.join", "numpy.save", "logging.info", "_run.add_artifact", "os.remove", "os.path.getsize"], "function", ["None"], ["", "@", "ex", ".", "capture", "\n", "def", "save_model", "(", "model", ",", "name", ",", "envs", ",", "save_dir", ",", "_run", ")", ":", "\n", "    ", "name_model", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "name", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "name_model", ")", "\n", "s_current", "=", "os", ".", "path", ".", "getsize", "(", "name_model", ")", "/", "(", "1024", "*", "1024", ")", "\n", "logging", ".", "info", "(", "'Saving model {}: Size: {} MB'", ".", "format", "(", "name", ",", "s_current", ")", ")", "\n", "_run", ".", "add_artifact", "(", "name_model", ")", "\n", "os", ".", "remove", "(", "name_model", ")", "\n", "\n", "# Saving the observation normalization", "\n", "if", "isinstance", "(", "envs", ",", "MTVecNormalize", ")", "and", "envs", ".", "ob_rms", "is", "not", "None", ":", "\n", "        ", "np_name", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'{}.npy'", ".", "format", "(", "name", ")", ")", "\n", "np", ".", "save", "(", "np_name", ",", "{", "\n", "'mean'", ":", "envs", ".", "ob_rms", ".", "mean", ",", "\n", "'var'", ":", "envs", ".", "ob_rms", ".", "var", ",", "\n", "'count'", ":", "envs", ".", "ob_rms", ".", "count", "\n", "}", ")", "\n", "s_current", "=", "os", ".", "path", ".", "getsize", "(", "np_name", ")", "/", "(", "1024", "*", "1024", ")", "\n", "logging", ".", "info", "(", "'Saving ob_rms {}: Size: {} MB'", ".", "format", "(", "\n", "np_name", ",", "s_current", ")", ")", "\n", "_run", ".", "add_artifact", "(", "np_name", ")", "\n", "os", ".", "remove", "(", "np_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.main.test_policy": [[132, 233], ["len", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "testing_envs.reset", "utils.update_current_obs", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "next", "current_obs.cuda.cuda", "action.size", "action.view", "action.view.squeeze().cpu().numpy", "testing_envs.step", "numpy.reshape", "numpy.reshape", "numpy.reshape", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "range", "masks.to.to", "utils.update_current_obs", "hierarchical_actor_critic.parameters", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "hierarchical_actor_critic.executePolicy", "hierarchical_actor_critic.executePolicy", "hierarchical_actor_critic.executePolicy", "numpy.stack", "numpy.stack", "numpy.stack", "range", "current_obs.cuda.dim", "masks.to.unsqueeze().unsqueeze", "action.view.squeeze().cpu", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.expand_dims", "masks.to.unsqueeze", "action.view.squeeze", "numpy.stack"], "function", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.reset", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.update_current_obs", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.KFACOptimizer.step", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.update_current_obs", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.executePolicy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.executePolicy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.executePolicy"], ["", "", "@", "ex", ".", "capture", "\n", "def", "test_policy", "(", "testing_envs", ",", "hierarchical_actor_critic", ",", "\n", "tasks", ",", "num_steps", ",", "num_processes", ",", "num_stack", ",", "loss", ",", "cuda", ")", ":", "\n", "    ", "num_tasks", "=", "len", "(", "tasks", ")", "\n", "num_processes_per_task", "=", "num_processes", "//", "num_tasks", "\n", "obs_shape", "=", "testing_envs", ".", "observation_space", ".", "shape", "\n", "obs_shape", "=", "(", "obs_shape", "[", "0", "]", "*", "num_stack", ",", "*", "obs_shape", "[", "1", ":", "]", ")", "\n", "device", "=", "next", "(", "hierarchical_actor_critic", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "if", "testing_envs", ".", "action_space", ".", "__class__", ".", "__name__", "==", "\"Discrete\"", ":", "\n", "        ", "action_shape", "=", "1", "\n", "", "else", ":", "\n", "        ", "action_shape", "=", "testing_envs", ".", "action_space", ".", "shape", "[", "0", "]", "\n", "\n", "", "current_obs", "=", "torch", ".", "zeros", "(", "\n", "num_tasks", ",", "num_processes_per_task", ",", "*", "obs_shape", ")", ".", "to", "(", "device", ")", "\n", "\n", "masks", "=", "torch", ".", "zeros", "(", "num_tasks", ",", "num_processes_per_task", ",", "1", ")", ".", "to", "(", "device", ")", "\n", "z", "=", "torch", ".", "zeros", "(", "num_tasks", ",", "num_processes_per_task", ",", "1", ")", ".", "long", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "obs", "=", "testing_envs", ".", "reset", "(", ")", "\n", "update_current_obs", "(", "obs", ",", "current_obs", ",", "obs_shape", ",", "num_stack", ",", "\n", "num_tasks", ",", "num_processes_per_task", ")", "\n", "\n", "# These variables are used to compute average rewards for all processes.", "\n", "episode_rewards", "=", "torch", ".", "zeros", "(", "[", "num_tasks", ",", "num_processes_per_task", ",", "1", "]", ")", "\n", "final_rewards", "=", "torch", ".", "zeros", "(", "[", "num_tasks", ",", "num_processes_per_task", ",", "1", "]", ")", "\n", "\n", "if", "cuda", ":", "\n", "        ", "current_obs", "=", "current_obs", ".", "cuda", "(", ")", "\n", "\n", "", "finished_environments", "=", "torch", ".", "zeros", "(", "(", "num_processes", ",", ")", ")", "\n", "\n", "while", "(", "finished_environments", "==", "0", ")", ".", "any", "(", ")", ":", "\n", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "b", ",", "b_log_prob", ",", "_", "=", "hierarchical_actor_critic", ".", "executePolicy", "(", "\n", "obs", "=", "current_obs", ",", "\n", "z", "=", "z", ",", "\n", "policy_type", "=", "\"termination\"", ",", "\n", "masks", "=", "masks", ",", "\n", "deterministic", "=", "True", "\n", ")", "\n", "\n", "z", ",", "z_log_prob", ",", "_", "=", "hierarchical_actor_critic", ".", "executePolicy", "(", "\n", "obs", "=", "current_obs", ",", "\n", "z", "=", "z", ",", "\n", "policy_type", "=", "\"master\"", ",", "\n", "b", "=", "b", ",", "\n", "deterministic", "=", "True", "\n", ")", "\n", "action", ",", "action_log_prob", ",", "_", "=", "hierarchical_actor_critic", ".", "executePolicy", "(", "\n", "obs", "=", "current_obs", ",", "\n", "z", "=", "z", ",", "\n", "policy_type", "=", "\"option\"", ",", "\n", "deterministic", "=", "True", "\n", ")", "\n", "\n", "", "_", ",", "_", ",", "*", "action_shape", "=", "action", ".", "size", "(", ")", "\n", "flat_action", "=", "action", ".", "view", "(", "\n", "num_tasks", "*", "num_processes_per_task", ",", "*", "action_shape", ")", "\n", "cpu_actions", "=", "flat_action", ".", "squeeze", "(", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Obser reward and next obs", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "testing_envs", ".", "step", "(", "cpu_actions", ")", "\n", "\n", "single_obs_shape", "=", "obs", ".", "shape", "[", "1", ":", "]", "\n", "obs", "=", "np", ".", "reshape", "(", "\n", "np", ".", "stack", "(", "obs", ")", ",", "(", "num_tasks", ",", "num_processes_per_task", ")", "+", "single_obs_shape", ")", "\n", "reward", "=", "np", ".", "reshape", "(", "\n", "np", ".", "stack", "(", "reward", ")", ",", "(", "num_tasks", ",", "num_processes_per_task", ")", ")", "\n", "done", "=", "np", ".", "reshape", "(", "np", ".", "stack", "(", "done", ")", ",", "(", "num_tasks", ",", "num_processes_per_task", ")", ")", "\n", "\n", "reward", "=", "torch", ".", "from_numpy", "(", "np", ".", "expand_dims", "(", "np", ".", "stack", "(", "reward", ")", ",", "2", ")", ")", ".", "float", "(", ")", "\n", "\n", "episode_rewards", "+=", "reward", "\n", "\n", "# If done then clean the history of observations.", "\n", "masks", "=", "torch", ".", "ones", "(", "\n", "(", "num_tasks", ",", "num_processes_per_task", ",", "1", ")", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "for", "task", "in", "range", "(", "num_tasks", ")", ":", "\n", "            ", "for", "process", "in", "range", "(", "num_processes_per_task", ")", ":", "\n", "                ", "masks", "[", "task", ",", "process", "]", "=", "0.0", "if", "done", "[", "task", "]", "[", "process", "]", "else", "1.0", "\n", "\n", "# Mask rewards", "\n", "", "", "final_rewards", "*=", "masks", "\n", "final_rewards", "+=", "(", "1", "-", "masks", ")", "*", "episode_rewards", "\n", "episode_rewards", "*=", "masks", "\n", "\n", "# Mask observations", "\n", "finished_environments", "+=", "(", "1", "-", "masks", ")", ".", "view", "(", "-", "1", ")", "\n", "masks", "=", "masks", ".", "to", "(", "device", ")", "\n", "if", "current_obs", ".", "dim", "(", ")", "==", "5", ":", "\n", "            ", "current_obs", "*=", "masks", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "2", ")", "\n", "", "else", ":", "\n", "            ", "current_obs", "*=", "masks", "\n", "\n", "", "update_current_obs", "(", "obs", ",", "current_obs", ",", "obs_shape", ",", "\n", "num_stack", ",", "num_tasks", ",", "num_processes_per_task", ")", "\n", "\n", "", "return", "final_rewards", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.main.main": [[235, 768], ["len", "print", "print", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "print", "print", "print", "torch.set_num_threads", "torch.set_num_threads", "torch.set_num_threads", "torch.set_num_threads", "multitask_vec_normalize.MTVecNormalize.draw_and_set_task", "multitask_vec_normalize.MTVecNormalize.draw_and_set_task", "print", "hierarchical_policy.HierarchicalPolicy", "hierarchical_policy.HierarchicalPolicy.parameters", "hierarchical_policy.HierarchicalPolicy.masters[].parameters", "hierarchical_policy.HierarchicalPolicy.options[].parameters", "print", "print", "print", "print", "main.main.reset_envs"], "function", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.draw_and_set_task", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.draw_and_set_task"], ["", "@", "ex", ".", "automain", "\n", "def", "main", "(", "algorithm", ",", "opt", ",", "loss", ",", "ppo", ",", "normalization", ",", "\n", "alpha", ",", "seed", ",", "num_processes", ",", "num_steps", ",", "num_test_steps", ",", "\n", "num_stack", ",", "log_interval", ",", "test_log_interval", ",", "\n", "num_frames", ",", "reset_encoder_in_test", ",", "freeze_in_test", ",", "\n", "environment", ",", "tasks", ",", "test_tasks", ",", "architecture", ",", "num_env_restarts", ",", "\n", "warmup_period_frames", ",", "final_period_frames", ",", "load_id", ",", "\n", "testing_frames", ",", "option_init", ",", "num_simultaneous_restarts", ",", "\n", "save_dir", ",", "cuda", ",", "add_timestep", ",", "_run", ")", ":", "\n", "\n", "    ", "import", "os", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "save_dir", ")", "\n", "\n", "# ACKTR currently broken", "\n", "", "assert", "algorithm", "in", "[", "'a2c'", ",", "'ppo'", "]", "\n", "\n", "# If all tasks are ints, convert them to actual ints", "\n", "try", ":", "\n", "        ", "tasks", "=", "list", "(", "map", "(", "int", ",", "tasks", ")", ")", "\n", "test_tasks", "=", "list", "(", "map", "(", "int", ",", "test_tasks", ")", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "\n", "", "num_tasks", "=", "len", "(", "tasks", ")", "\n", "num_processes_per_task", "=", "num_processes", "//", "num_tasks", "\n", "# num_frames = num_frames PER TASK", "\n", "num_updates", "=", "int", "(", "num_frames", ")", "*", "num_tasks", "//", "num_steps", "//", "num_processes", "\n", "print", "(", "'Num updates:{}\\n'", ".", "format", "(", "num_updates", ")", ")", "\n", "assert", "num_updates", ">", "0", ",", "'num_updates is 0, increase number of frames'", "\n", "\n", "# There will be `num_env_restarts` within the time between warmup_updates:(num_updates -", "\n", "# final_updates)", "\n", "# This leaves some warmup period and final training period to inspect the fully trained options", "\n", "warmup_updates", "=", "int", "(", "warmup_period_frames", ")", "*", "num_tasks", "//", "num_steps", "//", "num_processes", "\n", "final_updates", "=", "int", "(", "final_period_frames", ")", "*", "num_tasks", "//", "num_steps", "//", "num_processes", "\n", "testing_updates", "=", "int", "(", "testing_frames", ")", "*", "num_tasks", "//", "num_test_steps", "//", "num_processes", "\n", "\n", "restart_interval", "=", "(", "num_updates", "-", "warmup_updates", "-", "\n", "final_updates", ")", "//", "(", "num_env_restarts", "+", "1", ")", "\n", "\n", "print", "(", "'Num tasks:{}\\nNum processes per task:{}\\n'", ".", "format", "(", "\n", "num_tasks", ",", "num_processes_per_task", ")", ")", "\n", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "cuda", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "\n", "", "print", "(", "\"#######\"", ")", "\n", "print", "(", "\n", "\"WARNING: All rewards are clipped or normalized, but we are plotting the average return after clipping. Sacred plots will be inaccurate if per-timestep rewards are out of the range [-1, 1]\"", ")", "\n", "print", "(", "\"#######\"", ")", "\n", "\n", "torch", ".", "set_num_threads", "(", "1", ")", "\n", "\n", "envs", "=", "[", "make_env", "(", "environment", ",", "seed", ",", "i", ",", "add_timestep", ")", "\n", "for", "i", "in", "range", "(", "num_tasks", "*", "num_processes_per_task", ")", "]", "\n", "testing_envs", "=", "[", "make_env", "(", "environment", ",", "seed", ",", "i", ",", "add_timestep", ")", "\n", "for", "i", "in", "range", "(", "num_tasks", "*", "num_processes_per_task", ")", "]", "\n", "constraint", "=", "[", "]", "\n", "test_constraint", "=", "[", "]", "\n", "task_seed", "=", "[", "]", "\n", "for", "task", "in", "tasks", ":", "\n", "        ", "constraint", "+=", "[", "task", "]", "*", "num_processes_per_task", "\n", "task_seed", "+=", "[", "np", ".", "random", ".", "randint", "(", "LONG_NUMBER", ")", "]", "*", "num_processes_per_task", "\n", "", "for", "task", "in", "test_tasks", ":", "\n", "        ", "test_constraint", "+=", "[", "task", "]", "*", "num_processes_per_task", "\n", "\n", "", "if", "num_processes", ">", "1", ":", "\n", "        ", "envs", "=", "MTSubprocVecEnv", "(", "envs", ")", "\n", "testing_envs", "=", "MTSubprocVecEnv", "(", "testing_envs", ")", "\n", "", "else", ":", "\n", "        ", "envs", "=", "DummyVecEnv", "(", "envs", ")", "\n", "testing_envs", "=", "DummyVecEnv", "(", "testing_envs", ")", "\n", "\n", "", "if", "len", "(", "envs", ".", "observation_space", ".", "shape", ")", "==", "1", ":", "\n", "        ", "envs", "=", "MTVecNormalize", "(", "\n", "envs", ",", "ob", "=", "normalization", "[", "'ob'", "]", ",", "ret", "=", "normalization", "[", "'ret'", "]", ",", "gamma", "=", "loss", "[", "'gamma'", "]", ")", "\n", "testing_envs", "=", "MTVecNormalize", "(", "\n", "testing_envs", ",", "ob", "=", "normalization", "[", "'ob'", "]", ",", "ret", "=", "False", ",", "gamma", "=", "loss", "[", "'gamma'", "]", ")", "\n", "\n", "", "returned_task_seed", "=", "envs", ".", "draw_and_set_task", "(", "\n", "constraint", "=", "constraint", ",", "\n", "seed", "=", "task_seed", ")", "\n", "testing_envs", ".", "draw_and_set_task", "(", "\n", "constraint", "=", "constraint", ",", "\n", "seed", "=", "returned_task_seed", "\n", ")", "\n", "\n", "print", "(", "\"Task seeds: {}\"", ".", "format", "(", "returned_task_seed", ")", ")", "\n", "\n", "obs_shape", "=", "envs", ".", "observation_space", ".", "shape", "\n", "obs_shape", "=", "(", "obs_shape", "[", "0", "]", "*", "num_stack", ",", "*", "obs_shape", "[", "1", ":", "]", ")", "\n", "\n", "hierarchical_actor_critic", "=", "HierarchicalPolicy", "(", "\n", "num_tasks", ",", "num_processes_per_task", ",", "alpha", ",", "\n", "obs_shape", ",", "envs", ".", "action_space", ",", "loss", ",", "architecture", ",", "\n", "option_init", "=", "option_init", ")", "\n", "\n", "if", "load_id", "is", "not", "None", ":", "\n", "        ", "docs", "=", "get_docs", "(", "db_uri", ",", "db_name", ",", "'runs'", ")", "\n", "doc", "=", "docs", ".", "find_one", "(", "{", "'_id'", ":", "load_id", "}", ")", "\n", "name", "=", "\"model_after_training\"", "\n", "# config = doc['config']", "\n", "# config.update({'num_processes': len(config['tasks']), 'cuda': False})", "\n", "file_id", "=", "get_file_id", "(", "doc", "=", "doc", ",", "file_name", "=", "name", ")", "\n", "save_file_from_db", "(", "file_id", "=", "file_id", ",", "destination", "=", "'model_tmp_{}.pyt'", ".", "format", "(", "\n", "_run", ".", "_id", ")", ",", "db_uri", "=", "db_uri", ",", "db_name", "=", "db_name", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "\"model_tmp_{}.pyt\"", ".", "format", "(", "\n", "_run", ".", "_id", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "hierarchical_actor_critic", ".", "load_state_dict", "(", "state_dict", ")", "\n", "os", ".", "remove", "(", "'model_tmp_{}.pyt'", ".", "format", "(", "_run", ".", "_id", ")", ")", "\n", "print", "(", "\"Loading model parameters complete.\"", ")", "\n", "\n", "if", "isinstance", "(", "envs", ",", "MTVecNormalize", ")", "and", "envs", ".", "ob_rms", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"Loading ob_rms normalization\"", ")", "\n", "ob_name", "=", "name", "+", "\".npy\"", "\n", "file_id", "=", "get_file_id", "(", "doc", "=", "doc", ",", "file_name", "=", "ob_name", ")", "\n", "save_file_from_db", "(", "\n", "file_id", "=", "file_id", ",", "destination", "=", "'ob_rms_tmp.npy'", ",", "db_uri", "=", "db_uri", ",", "db_name", "=", "db_name", ")", "\n", "rms_dict", "=", "np", ".", "load", "(", "\"ob_rms_tmp.npy\"", ")", "[", "(", ")", "]", "\n", "print", "(", "rms_dict", ")", "\n", "envs", ".", "ob_rms", ".", "mean", "=", "rms_dict", "[", "'mean'", "]", "\n", "envs", ".", "ob_rms", ".", "var", "=", "rms_dict", "[", "'var'", "]", "\n", "envs", ".", "ob_rms", ".", "count", "=", "rms_dict", "[", "'count'", "]", "\n", "testing_envs", ".", "ob_rms", ".", "mean", "=", "rms_dict", "[", "'mean'", "]", "\n", "testing_envs", ".", "ob_rms", ".", "var", "=", "rms_dict", "[", "'var'", "]", "\n", "testing_envs", ".", "ob_rms", ".", "count", "=", "rms_dict", "[", "'count'", "]", "\n", "os", ".", "remove", "(", "\"ob_rms_tmp.npy\"", ")", "\n", "\n", "", "", "num_parameters", "=", "0", "\n", "for", "p", "in", "hierarchical_actor_critic", ".", "parameters", "(", ")", ":", "\n", "        ", "num_parameters", "+=", "p", ".", "nelement", "(", ")", "\n", "\n", "", "num_params_master", "=", "0", "\n", "for", "p", "in", "hierarchical_actor_critic", ".", "masters", "[", "0", "]", ".", "parameters", "(", ")", ":", "\n", "        ", "num_params_master", "+=", "p", ".", "nelement", "(", ")", "\n", "\n", "", "num_params_option", "=", "0", "\n", "for", "p", "in", "hierarchical_actor_critic", ".", "options", "[", "0", "]", ".", "parameters", "(", ")", ":", "\n", "        ", "num_params_option", "+=", "p", ".", "nelement", "(", ")", "\n", "\n", "", "print", "(", "hierarchical_actor_critic", ")", "\n", "print", "(", "\"Total Number parameters: {}\"", ".", "format", "(", "num_parameters", ")", ")", "\n", "print", "(", "\"Number parameters master: {}\"", ".", "format", "(", "num_params_master", ")", ")", "\n", "print", "(", "\"Number parameters option: {}\"", ".", "format", "(", "num_params_option", ")", ")", "\n", "\n", "if", "envs", ".", "action_space", ".", "__class__", ".", "__name__", "==", "\"Discrete\"", ":", "\n", "        ", "action_shape", "=", "1", "\n", "", "else", ":", "\n", "        ", "action_shape", "=", "envs", ".", "action_space", ".", "shape", "[", "0", "]", "\n", "\n", "", "if", "cuda", ":", "\n", "        ", "hierarchical_actor_critic", ".", "cuda", "(", ")", "\n", "\n", "", "if", "algorithm", "==", "'a2c'", ":", "\n", "        ", "agent", "=", "algo", ".", "A2C", "(", "hierarchical_actor_critic", ",", "loss", "=", "loss", ",", "opt", "=", "opt", ")", "\n", "", "elif", "algorithm", "==", "'ppo'", ":", "\n", "        ", "agent", "=", "algo", ".", "PPO", "(", "hierarchical_actor_critic", ",", "loss", ",", "opt", ",", "ppo", ")", "\n", "", "elif", "algorithm", "==", "'acktr'", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"ACKTR not implemented with HRL\"", ")", "\n", "# agent = algo.A2C_ACKTR(hierarchical_actor_critic, value_loss_coef,", "\n", "#                        entropy_coef, acktr=True)", "\n", "\n", "", "def", "reset_envs", "(", "storage_length", ")", ":", "\n", "        ", "rollouts", "=", "RolloutStorage", "(", "num_tasks", ",", "storage_length", ",", "num_processes_per_task", ",", "\n", "obs_shape", ",", "envs", ".", "action_space", ",", "loss", ")", "\n", "current_obs", "=", "torch", ".", "zeros", "(", "\n", "num_tasks", ",", "num_processes_per_task", ",", "*", "obs_shape", ")", "\n", "\n", "obs", "=", "envs", ".", "reset", "(", ")", "\n", "\n", "update_current_obs", "(", "obs", ",", "current_obs", ",", "obs_shape", ",", "\n", "num_stack", ",", "num_tasks", ",", "num_processes_per_task", ")", "\n", "for", "task", "in", "range", "(", "num_tasks", ")", ":", "\n", "            ", "rollouts", ".", "obs", "[", "task", ",", "0", "]", ".", "copy_", "(", "current_obs", "[", "task", "]", ")", "\n", "", "if", "cuda", ":", "\n", "            ", "current_obs", "=", "current_obs", ".", "cuda", "(", ")", "\n", "rollouts", ".", "cuda", "(", ")", "\n", "\n", "# These variables are used to compute average rewards for all processes.", "\n", "", "episode_rewards", "=", "torch", ".", "zeros", "(", "[", "num_tasks", ",", "num_processes_per_task", ",", "1", "]", ")", "\n", "final_rewards", "=", "torch", ".", "zeros", "(", "[", "num_tasks", ",", "num_processes_per_task", ",", "1", "]", ")", "\n", "episode_length", "=", "torch", ".", "zeros", "(", "[", "num_tasks", ",", "num_processes_per_task", ",", "1", "]", ")", "\n", "final_length", "=", "torch", ".", "zeros", "(", "[", "num_tasks", ",", "num_processes_per_task", ",", "1", "]", ")", "\n", "episode_terminations", "=", "torch", ".", "zeros", "(", "\n", "[", "num_tasks", ",", "num_processes_per_task", ",", "1", "]", ")", "\n", "final_terminations", "=", "torch", ".", "zeros", "(", "\n", "[", "num_tasks", ",", "num_processes_per_task", ",", "1", "]", ")", "\n", "master_terminations", "=", "torch", ".", "zeros", "(", "\n", "[", "num_tasks", ",", "num_processes_per_task", ",", "1", "]", ")", "\n", "final_master_terminations", "=", "torch", ".", "zeros", "(", "\n", "[", "num_tasks", ",", "num_processes_per_task", ",", "1", "]", ")", "\n", "return", "(", "rollouts", ",", "current_obs", ",", "episode_rewards", ",", "final_rewards", ",", "\n", "episode_length", ",", "final_length", ",", "episode_terminations", ",", "final_terminations", ",", "\n", "master_terminations", ",", "final_master_terminations", ")", "\n", "\n", "", "rollouts", ",", "current_obs", ",", "episode_rewards", ",", "final_rewards", ",", "episode_length", ",", "final_length", ",", "episode_terminations", ",", "final_terminations", ",", "master_terminations", ",", "final_master_terminations", "=", "reset_envs", "(", "\n", "storage_length", "=", "num_steps", ")", "\n", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "hierarchical_actor_critic", ".", "train", "(", ")", "\n", "rollout_length", "=", "num_steps", "\n", "assert", "num_tasks", ">=", "num_simultaneous_restarts", "\n", "randomSampler", "=", "data", ".", "sampler", ".", "BatchSampler", "(", "data", ".", "sampler", ".", "RandomSampler", "(", "range", "(", "num_tasks", ")", ")", ",", "\n", "batch_size", "=", "num_simultaneous_restarts", ",", "\n", "drop_last", "=", "True", ")", "\n", "rndSampler_iter", "=", "iter", "(", "randomSampler", ")", "\n", "iterator", "=", "iter", "(", "range", "(", "num_updates", "+", "testing_updates", ")", ")", "\n", "\n", "for", "j", "in", "iterator", ":", "\n", "\n", "# Load old model if load_id is given", "\n", "        ", "if", "load_id", "is", "not", "None", "and", "j", "==", "0", ":", "\n", "# Skip to j == num_updates - 1", "\n", "            ", "next", "(", "islice", "(", "iterator", ",", "num_updates", "-", "2", ",", "num_updates", "-", "2", ")", ",", "None", ")", "\n", "j", "=", "next", "(", "iterator", ")", "\n", "ppo", "[", "'use_linear_clip_decay'", "]", "=", "False", "\n", "opt", "[", "'use_lr_decay'", "]", "=", "False", "\n", "\n", "# Updated Learning rate", "\n", "", "j_mod", "=", "j", "%", "num_updates", "\n", "lr_schedule_length", "=", "num_updates", "if", "j", "<=", "num_updates", "else", "testing_updates", "\n", "if", "opt", "[", "'use_lr_decay'", "]", ":", "\n", "            ", "update_linear_schedule", "(", "\n", "agent", ".", "optimizer", ",", "j_mod", ",", "lr_schedule_length", ",", "opt", "[", "'lr'", "]", ")", "\n", "\n", "# Update clip param", "\n", "", "if", "algorithm", "==", "'ppo'", "and", "ppo", "[", "'use_linear_clip_decay'", "]", ":", "\n", "            ", "agent", ".", "clip_param", "=", "ppo", "[", "'clip_param'", "]", "*", "(", "1", "-", "j_mod", "/", "float", "(", "lr_schedule_length", ")", ")", "\n", "\n", "# Update c_kl_b", "\n", "", "if", "loss", "[", "'c_kl_b_1'", "]", "is", "not", "None", ":", "\n", "            ", "per", "=", "np", ".", "clip", "(", "(", "j", "-", "warmup_updates", ")", "/", "(", "num_updates", "-", "final_updates", ")", ",", "0", ",", "1", ")", "\n", "cur_val", "=", "(", "1", "-", "per", ")", "*", "loss", "[", "'c_kl_b_orig'", "]", "+", "per", "*", "loss", "[", "'c_kl_b_1'", "]", "\n", "rollouts", ".", "loss", "[", "'c_kl_b'", "]", "=", "cur_val", "\n", "if", "not", "loss", "[", "'fixed_a'", "]", ":", "\n", "                ", "rollouts", ".", "loss", "[", "'c_kl_a'", "]", "=", "cur_val", "\n", "\n", "# Update c_kl_a", "\n", "", "", "if", "loss", "[", "'c_kl_a_1'", "]", "is", "not", "None", ":", "\n", "            ", "per", "=", "np", ".", "clip", "(", "(", "j", "-", "warmup_updates", ")", "/", "(", "num_updates", "-", "final_updates", ")", ",", "0", ",", "1", ")", "\n", "cur_val", "=", "(", "1", "-", "per", ")", "*", "loss", "[", "'c_kl_a_orig'", "]", "+", "per", "*", "loss", "[", "'c_kl_a_1'", "]", "\n", "rollouts", ".", "loss", "[", "'c_kl_a'", "]", "=", "cur_val", "\n", "# if not loss['fixed_b']:", "\n", "#     rollouts.loss['c_kl_a'] = cur_val", "\n", "\n", "# Update entropy_coef", "\n", "", "train_progress", "=", "j", "/", "(", "num_updates", "-", "final_updates", ")", "\n", "if", "not", "agent", ".", "hierarchical_actor_critic", ".", "training", ":", "\n", "# Testing", "\n", "            ", "elc", "=", "loss", "[", "'entropy_loss_coef_test'", "]", "\n", "", "elif", "loss", "[", "'entropy_loss_coef_1'", "]", "is", "not", "None", ":", "\n", "            ", "factor", "=", "max", "(", "0", ",", "1", "-", "train_progress", ")", "\n", "elc", "=", "(", "loss", "[", "'entropy_loss_coef_0'", "]", "*", "factor", "+", "\n", "loss", "[", "'entropy_loss_coef_1'", "]", "*", "(", "1", "-", "factor", ")", ")", "\n", "", "else", ":", "\n", "            ", "elc", "=", "loss", "[", "'entropy_loss_coef_0'", "]", "\n", "", "loss", "[", "'elc'", "]", "=", "elc", "\n", "\n", "for", "step", "in", "range", "(", "rollout_length", ")", ":", "\n", "# Sample actions", "\n", "            ", "\"\"\"\n            Note regarding z:\n            z_t is treated the same way as s_t with regards to saving because at t=0 we need access to\n            s_{-1} and z_{t-1}. HOWEVER, that means that the code is off by one compared to the\n            equations:\n            In equations: z_t depends on s_t and z_{t-1}\n            Here: z_t depends on s_{t-1} and z_{t-1}\n            \"\"\"", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "b", ",", "b_log_prob", ",", "_", "=", "hierarchical_actor_critic", ".", "executePolicy", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", "step", "]", ",", "\n", "z", "=", "rollouts", ".", "z", "[", ":", ",", "step", "]", ",", "\n", "policy_type", "=", "\"termination\"", ",", "\n", "masks", "=", "rollouts", ".", "masks", "[", ":", ",", "step", "]", "\n", ")", "\n", "\n", "z", ",", "z_log_prob", ",", "_", "=", "hierarchical_actor_critic", ".", "executePolicy", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", "step", "]", ",", "\n", "z", "=", "rollouts", ".", "z", "[", ":", ",", "step", "]", ",", "\n", "policy_type", "=", "\"master\"", ",", "\n", "b", "=", "b", "\n", ")", "\n", "\n", "action", ",", "action_log_prob", ",", "_", "=", "hierarchical_actor_critic", ".", "executePolicy", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", "step", "]", ",", "\n", "z", "=", "z", ",", "\n", "policy_type", "=", "\"option\"", "\n", ")", "\n", "\n", "# Evaluate Log probs for regularized reward", "\n", "b_prior_log_prob", "=", "hierarchical_actor_critic", ".", "evaluatePrior", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", "step", "]", ",", "\n", "z", "=", "rollouts", ".", "z", "[", ":", ",", "step", "]", ",", "\n", "action", "=", "b", ",", "\n", "policy_type", "=", "\"termination\"", ",", "\n", "masks", "=", "rollouts", ".", "masks", "[", ":", ",", "step", "]", "\n", ")", "\n", "action_prior_log_prob", "=", "hierarchical_actor_critic", ".", "evaluatePrior", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", "step", "]", ",", "\n", "z", "=", "z", ",", "\n", "action", "=", "action", ",", "\n", "policy_type", "=", "\"option\"", "\n", ")", "\n", "value_pred", "=", "hierarchical_actor_critic", ".", "get_U", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", "step", "]", ",", "\n", "previous_z", "=", "z", "\n", ")", "\n", "\n", "# Flatten actions:", "\n", "", "_", ",", "_", ",", "*", "action_shape", "=", "action", ".", "size", "(", ")", "\n", "flat_action", "=", "action", ".", "view", "(", "\n", "num_tasks", "*", "num_processes_per_task", ",", "*", "action_shape", ")", "\n", "cpu_actions", "=", "flat_action", ".", "squeeze", "(", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Obser reward and next obs", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "envs", ".", "step", "(", "cpu_actions", ")", "\n", "\n", "single_obs_shape", "=", "obs", ".", "shape", "[", "1", ":", "]", "\n", "obs", "=", "np", ".", "reshape", "(", "\n", "np", ".", "stack", "(", "obs", ")", ",", "(", "num_tasks", ",", "num_processes_per_task", ")", "+", "single_obs_shape", ")", "\n", "reward", "=", "np", ".", "reshape", "(", "\n", "np", ".", "stack", "(", "reward", ")", ",", "(", "num_tasks", ",", "num_processes_per_task", ")", ")", "\n", "done", "=", "np", ".", "reshape", "(", "\n", "np", ".", "stack", "(", "done", ")", ",", "(", "num_tasks", ",", "num_processes_per_task", ")", ")", "\n", "\n", "reward", "=", "torch", ".", "from_numpy", "(", "\n", "np", ".", "expand_dims", "(", "np", ".", "stack", "(", "reward", ")", ",", "2", ")", ")", ".", "float", "(", ")", "\n", "\n", "episode_rewards", "+=", "reward", "\n", "episode_length", "+=", "1", "\n", "episode_terminations", "+=", "b", ".", "cpu", "(", ")", ".", "float", "(", ")", "\n", "\n", "delta_b", "=", "1", "-", "(", "z", "==", "rollouts", ".", "z", "[", ":", ",", "step", "]", ")", ".", "int", "(", ")", "\n", "master_terminations", "+=", "delta_b", ".", "cpu", "(", ")", ".", "float", "(", ")", "\n", "\n", "# If done then clean the history of observations.", "\n", "masks", "=", "torch", ".", "ones", "(", "\n", "(", "num_tasks", ",", "num_processes_per_task", ",", "1", ")", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "for", "task", "in", "range", "(", "num_tasks", ")", ":", "\n", "                ", "for", "process", "in", "range", "(", "num_processes_per_task", ")", ":", "\n", "                    ", "masks", "[", "task", ",", "process", "]", "=", "0.0", "if", "done", "[", "task", "]", "[", "process", "]", "else", "1.0", "\n", "\n", "# Mask rewards", "\n", "", "", "final_rewards", "*=", "masks", "\n", "final_rewards", "+=", "(", "1", "-", "masks", ")", "*", "episode_rewards", "\n", "episode_rewards", "*=", "masks", "\n", "\n", "final_length", "*=", "masks", "\n", "final_length", "+=", "(", "1", "-", "masks", ")", "*", "episode_length", "\n", "episode_length", "*=", "masks", "\n", "\n", "final_terminations", "*=", "masks", "\n", "# It starts of with a termination", "\n", "final_terminations", "+=", "(", "1", "-", "masks", ")", "*", "(", "episode_terminations", "-", "1", ")", "\n", "episode_terminations", "*=", "masks", "\n", "\n", "final_master_terminations", "*=", "masks", "\n", "# It starts of with a termination", "\n", "final_master_terminations", "+=", "(", "1", "-", "masks", ")", "*", "(", "master_terminations", "-", "1", ")", "\n", "master_terminations", "*=", "masks", "\n", "\n", "# Mask observations", "\n", "if", "cuda", ":", "\n", "                ", "masks", "=", "masks", ".", "cuda", "(", ")", "\n", "", "if", "current_obs", ".", "dim", "(", ")", "==", "5", ":", "\n", "                ", "current_obs", "*=", "masks", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "2", ")", "\n", "", "else", ":", "\n", "                ", "current_obs", "*=", "masks", "\n", "\n", "", "update_current_obs", "(", "obs", ",", "current_obs", ",", "obs_shape", ",", "\n", "num_stack", ",", "num_tasks", ",", "num_processes_per_task", ")", "\n", "\n", "rollouts", ".", "insert", "(", "\n", "current_obs", "=", "current_obs", ",", "\n", "z", "=", "z", ",", "\n", "b", "=", "b", ",", "\n", "action", "=", "action", ",", "\n", "value_pred", "=", "value_pred", ",", "\n", "action_log_prob", "=", "action_log_prob", ",", "\n", "action_prior_log_prob", "=", "action_prior_log_prob", ",", "\n", "z_log_prob", "=", "z_log_prob", ",", "\n", "b_log_prob", "=", "b_log_prob", ",", "\n", "b_prior_log_prob", "=", "b_prior_log_prob", ",", "\n", "reward", "=", "reward", ",", "\n", "mask", "=", "masks", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# obs[-1] is s_{t+1} in equations", "\n", "# z[-1] is z_{t} in equations", "\n", "# Basically: Those are the last values we know which are s_{t+1} and z_t", "\n", "            ", "next_value_u", "=", "hierarchical_actor_critic", ".", "get_U", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", "-", "1", "]", ",", "\n", "previous_z", "=", "rollouts", ".", "z", "[", ":", ",", "-", "1", "]", ")", "\n", "\n", "", "rollouts", ".", "store_next_value", "(", "next_value_u", ")", "\n", "rollouts", ".", "compute_returns", "(", ")", "\n", "losses", "=", "agent", ".", "update", "(", "rollouts", ")", "\n", "\n", "rollouts", ".", "after_update", "(", ")", "\n", "\n", "# While still in training and in between warmup_updates and final_updates", "\n", "if", "warmup_updates", "<", "j", "<", "num_updates", "and", "j", "<", "(", "num_updates", "-", "final_updates", ")", "and", "(", "j", "-", "warmup_updates", ")", "%", "restart_interval", "==", "0", ":", "\n", "# Get tasks to reset", "\n", "            ", "try", ":", "\n", "                ", "next_restart_tasks", "=", "next", "(", "rndSampler_iter", ")", "\n", "", "except", "StopIteration", "as", "e", ":", "\n", "                ", "rndSampler_iter", "=", "iter", "(", "randomSampler", ")", "\n", "next_restart_tasks", "=", "next", "(", "rndSampler_iter", ")", "\n", "\n", "", "returned_task_seed", "=", "reset_task", "(", "\n", "next_restart_tasks", ",", "hierarchical_actor_critic", ",", "constraint", ",", "agent", ",", "\n", "returned_task_seed", ",", "envs", ",", "testing_envs", ")", "\n", "# load_master=train_load_master_params)", "\n", "\n", "# Unfortunately there isn't a simple nice way to only restart the environment that was resetted", "\n", "rollouts", ",", "current_obs", ",", "episode_rewards", ",", "final_rewards", ",", "episode_length", ",", "final_length", ",", "episode_terminations", ",", "final_terminations", ",", "master_terminations", ",", "final_master_terminations", "=", "reset_envs", "(", "\n", "storage_length", "=", "num_steps", ")", "\n", "\n", "# When we reached the end of the training phase, reset all tasks", "\n", "", "if", "j", "==", "num_updates", "-", "1", ":", "\n", "            ", "save_model", "(", "hierarchical_actor_critic", ",", "\"model_after_training\"", ",", "envs", ")", "\n", "print", "(", "\"Reset all tasks, stop updating prior, start testing\"", ")", "\n", "last_training_task_seed", "=", "returned_task_seed", ".", "copy", "(", ")", "\n", "hierarchical_actor_critic", ".", "eval", "(", ")", "\n", "returned_task_seed", "=", "reset_task", "(", "\n", "restart_tasks", "=", "range", "(", "num_tasks", ")", ",", "\n", "hierarchical_actor_critic", "=", "hierarchical_actor_critic", ",", "\n", "constraint", "=", "test_constraint", ",", "\n", "agent", "=", "agent", ",", "\n", "returned_task_seed", "=", "returned_task_seed", ",", "\n", "envs", "=", "envs", ",", "\n", "testing_envs", "=", "testing_envs", ")", "\n", "\n", "print", "(", "\"Freezing and resetting for test\"", ")", "\n", "hierarchical_actor_critic", ".", "frozen", "[", "'prior'", "]", "=", "freeze_in_test", "[", "'prior'", "]", "\n", "hierarchical_actor_critic", ".", "frozen", "[", "'option'", "]", "=", "freeze_in_test", "[", "'option'", "]", "\n", "\n", "if", "architecture", "[", "'shared_encoder'", "]", ":", "\n", "                ", "hierarchical_actor_critic", ".", "split_encoder", "(", ")", "\n", "\n", "# This will create a new Encoder!", "\n", "", "if", "reset_encoder_in_test", "[", "'option'", "]", ":", "\n", "                ", "hierarchical_actor_critic", ".", "reset_encoder", "(", "'option'", ")", "\n", "\n", "", "if", "reset_encoder_in_test", "[", "'master'", "]", ":", "\n", "                ", "hierarchical_actor_critic", ".", "reset_encoder", "(", "'master'", ")", "\n", "", "agent", ".", "init_optimizer", "(", "hierarchical_actor_critic", ")", "\n", "\n", "# Unfortunately there isn't a simple nice way to only restart the environment that was resetted", "\n", "rollouts", ",", "current_obs", ",", "episode_rewards", ",", "final_rewards", ",", "episode_length", ",", "final_length", ",", "episode_terminations", ",", "final_terminations", ",", "master_terminations", ",", "final_master_terminations", "=", "reset_envs", "(", "\n", "storage_length", "=", "num_test_steps", ")", "\n", "rollout_length", "=", "num_test_steps", "\n", "\n", "", "if", "(", "j", "<", "num_updates", "and", "j", "%", "log_interval", "==", "0", ")", "or", "(", "j", ">=", "num_updates", "and", "j", "%", "test_log_interval", "==", "0", ")", ":", "\n", "\n", "            ", "test_performance", "=", "test_policy", "(", "\n", "testing_envs", ",", "hierarchical_actor_critic", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "if", "j", "%", "(", "log_interval", "*", "10", ")", "==", "0", ":", "\n", "                ", "printHeader", "(", ")", "\n", "\n", "", "if", "j", "<", "num_updates", ":", "\n", "                ", "total_num_steps", "=", "(", "j", "+", "1", ")", "*", "num_processes", "*", "num_steps", "\n", "", "else", ":", "\n", "                ", "total_num_steps", "=", "(", "\n", "num_updates", "*", "num_steps", "+", "(", "j", "+", "1", "-", "num_updates", ")", "*", "num_test_steps", ")", "*", "num_processes", "\n", "\n", "# FPS PER TASK (because num_frames is also per task!)", "\n", "", "fps", "=", "int", "(", "total_num_steps", "/", "num_tasks", "/", "(", "end", "-", "start", ")", ")", "\n", "\n", "logging", ".", "info", "(", "'Updt: {:5} |{:5} {:5}|{:5}|{:5}|{:5}'", ".", "format", "(", "\n", "str", "(", "j", "/", "num_updates", ")", "[", ":", "5", "]", ",", "\n", "str", "(", "fps", ")", ",", "\n", "str", "(", "final_rewards", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "[", ":", "5", "]", ",", "\n", "str", "(", "final_rewards", ".", "median", "(", ")", ".", "item", "(", ")", ")", "[", ":", "5", "]", ",", "\n", "str", "(", "final_rewards", ".", "min", "(", ")", ".", "item", "(", ")", ")", "[", ":", "5", "]", ",", "\n", "str", "(", "final_rewards", ".", "max", "(", ")", ".", "item", "(", ")", ")", "[", ":", "5", "]", ",", "\n", ")", ")", "\n", "\n", "for", "task", "in", "range", "(", "num_tasks", ")", ":", "\n", "                ", "_run", ".", "log_scalar", "(", "'return.avg.{}'", ".", "format", "(", "task", ")", ",", "float", "(", "\n", "final_rewards", "[", "task", "]", ".", "mean", "(", ")", ")", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "_run", ".", "log_scalar", "(", "'return.test.avg.{}'", ".", "format", "(", "task", ")", ",", "float", "(", "\n", "test_performance", "[", "task", "]", ".", "mean", "(", ")", ")", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "\n", "", "_run", ".", "log_scalar", "(", "'return.avg'", ",", "final_rewards", ".", "mean", "(", "\n", ")", ".", "item", "(", ")", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "_run", ".", "log_scalar", "(", "'return.test.avg'", ",", "test_performance", ".", "mean", "(", "\n", ")", ".", "item", "(", ")", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "_run", ".", "log_scalar", "(", "'episode.length'", ",", "final_length", ".", "mean", "(", "\n", ")", ".", "item", "(", ")", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "_run", ".", "log_scalar", "(", "'episode.terminations'", ",", "final_terminations", ".", "mean", "(", "\n", ")", ".", "item", "(", ")", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "_run", ".", "log_scalar", "(", "'episode.master_terminations'", ",", "final_master_terminations", ".", "mean", "(", "\n", ")", ".", "item", "(", ")", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "_run", ".", "log_scalar", "(", "'fps'", ",", "fps", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "\n", "_run", ".", "log_scalar", "(", "\n", "'loss.value'", ",", "losses", "[", "'value_loss'", "]", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "_run", ".", "log_scalar", "(", "\n", "'loss.action_a'", ",", "losses", "[", "'action_loss_a'", "]", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "_run", ".", "log_scalar", "(", "\n", "'loss.action_z'", ",", "losses", "[", "'action_loss_z'", "]", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "_run", ".", "log_scalar", "(", "\n", "'loss.action_b'", ",", "losses", "[", "'action_loss_b'", "]", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "_run", ".", "log_scalar", "(", "\n", "'loss.action_prior'", ",", "losses", "[", "'action_prior_loss'", "]", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "_run", ".", "log_scalar", "(", "\n", "'loss.b_prior'", ",", "losses", "[", "'b_prior_loss'", "]", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "_run", ".", "log_scalar", "(", "'loss.entropy_a'", ",", "\n", "losses", "[", "'entropy_a'", "]", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "_run", ".", "log_scalar", "(", "'loss.entropy_b'", ",", "\n", "losses", "[", "'entropy_b'", "]", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "_run", ".", "log_scalar", "(", "'loss.entropy_z'", ",", "\n", "losses", "[", "'entropy_z'", "]", ",", "total_num_steps", "//", "num_tasks", ")", "\n", "\n", "", "", "_run", ".", "info", "[", "\"seeds_final\"", "]", "=", "returned_task_seed", "\n", "# _run.info[\"last_training_task_seed\"] = last_training_task_seed", "\n", "_run", ".", "info", "[", "\"constraints_final\"", "]", "=", "constraint", "\n", "_run", ".", "info", "[", "'test_constraints_final'", "]", "=", "test_constraint", "\n", "\n", "save_model", "(", "hierarchical_actor_critic", ",", "\"final_model\"", ",", "envs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.MTSubprocVecEnv.__init__": [[80, 101], ["len", "zip", "subproc_multitask_vec_env.MTSubprocVecEnv.remotes[].send", "subproc_multitask_vec_env.MTSubprocVecEnv.remotes[].recv", "baselines.common.vec_env.VecEnv.__init__", "multiprocessing.Process", "p.start", "remote.close", "len", "zip", "multiprocessing.Pipe", "range", "baselines.common.vec_env.CloudpickleWrapper"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.__init__", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.close"], ["def", "__init__", "(", "self", ",", "env_fns", ",", "spaces", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n        env_fns: iterable of callables -  functions that create environments to run in subprocesses. Need to be cloud-pickleable\n        \"\"\"", "\n", "self", ".", "waiting", "=", "False", "\n", "self", ".", "closed", "=", "False", "\n", "nenvs", "=", "len", "(", "env_fns", ")", "\n", "self", ".", "remotes", ",", "self", ".", "work_remotes", "=", "zip", "(", "*", "[", "Pipe", "(", ")", "for", "_", "in", "range", "(", "nenvs", ")", "]", ")", "\n", "self", ".", "ps", "=", "[", "Process", "(", "target", "=", "worker", ",", "args", "=", "(", "work_remote", ",", "remote", ",", "CloudpickleWrapper", "(", "env_fn", ")", ")", ")", "\n", "for", "(", "work_remote", ",", "remote", ",", "env_fn", ")", "in", "zip", "(", "self", ".", "work_remotes", ",", "self", ".", "remotes", ",", "env_fns", ")", "]", "\n", "for", "p", "in", "self", ".", "ps", ":", "\n", "            ", "p", ".", "daemon", "=", "True", "# if the main process crashes, we should not cause things to hang", "\n", "p", ".", "start", "(", ")", "\n", "", "for", "remote", "in", "self", ".", "work_remotes", ":", "\n", "            ", "remote", ".", "close", "(", ")", "\n", "\n", "", "self", ".", "remotes", "[", "0", "]", ".", "send", "(", "(", "'get_spaces'", ",", "None", ")", ")", "\n", "observation_space", ",", "action_space", "=", "self", ".", "remotes", "[", "0", "]", ".", "recv", "(", ")", "\n", "self", ".", "viewer", "=", "None", "\n", "VecEnv", ".", "__init__", "(", "self", ",", "len", "(", "env_fns", ")", ",", "observation_space", ",", "action_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.MTSubprocVecEnv.step_async": [[102, 107], ["subproc_multitask_vec_env.MTSubprocVecEnv._assert_not_closed", "zip", "remote.send"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.MTSubprocVecEnv._assert_not_closed"], ["", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "        ", "self", ".", "_assert_not_closed", "(", ")", "\n", "for", "remote", ",", "action", "in", "zip", "(", "self", ".", "remotes", ",", "actions", ")", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'step'", ",", "action", ")", ")", "\n", "", "self", ".", "waiting", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.MTSubprocVecEnv.step_wait": [[108, 114], ["subproc_multitask_vec_env.MTSubprocVecEnv._assert_not_closed", "zip", "remote.recv", "numpy.stack", "numpy.stack", "numpy.stack"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.MTSubprocVecEnv._assert_not_closed"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "self", ".", "_assert_not_closed", "(", ")", "\n", "results", "=", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", "\n", "self", ".", "waiting", "=", "False", "\n", "obs", ",", "rews", ",", "dones", ",", "infos", "=", "zip", "(", "*", "results", ")", "\n", "return", "np", ".", "stack", "(", "obs", ")", ",", "np", ".", "stack", "(", "rews", ")", ",", "np", ".", "stack", "(", "dones", ")", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.MTSubprocVecEnv.draw_and_set_task": [[115, 125], ["subproc_multitask_vec_env.MTSubprocVecEnv._assert_not_closed", "print", "zip", "len", "len", "len", "remote.send", "remote.recv"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.MTSubprocVecEnv._assert_not_closed"], ["", "def", "draw_and_set_task", "(", "self", ",", "constraint", ",", "seed", ")", ":", "\n", "        ", "self", ".", "_assert_not_closed", "(", ")", "\n", "print", "(", "len", "(", "self", ".", "remotes", ")", ",", "len", "(", "constraint", ")", ",", "len", "(", "seed", ")", ")", "\n", "for", "remote", ",", "c", ",", "s", "in", "zip", "(", "self", ".", "remotes", ",", "constraint", ",", "seed", ")", ":", "\n", "            ", "data", "=", "{", "'constraint'", ":", "c", ",", "'seed'", ":", "s", "}", "\n", "remote", ".", "send", "(", "(", "'draw_and_set_task'", ",", "data", ")", ")", "\n", "", "self", ".", "waiting", "=", "True", "\n", "results", "=", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", "\n", "self", ".", "waiting", "=", "False", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.MTSubprocVecEnv.reset": [[126, 131], ["subproc_multitask_vec_env.MTSubprocVecEnv._assert_not_closed", "numpy.stack", "remote.send", "remote.recv"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.MTSubprocVecEnv._assert_not_closed"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_assert_not_closed", "(", ")", "\n", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'reset'", ",", "None", ")", ")", "\n", "", "return", "np", ".", "stack", "(", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.MTSubprocVecEnv.close_extras": [[132, 141], ["remote.send", "p.join", "remote.recv"], "methods", ["None"], ["", "def", "close_extras", "(", "self", ")", ":", "\n", "        ", "self", ".", "closed", "=", "True", "\n", "if", "self", ".", "waiting", ":", "\n", "            ", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "                ", "remote", ".", "recv", "(", ")", "\n", "", "", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'close'", ",", "None", ")", ")", "\n", "", "for", "p", "in", "self", ".", "ps", ":", "\n", "            ", "p", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.MTSubprocVecEnv.get_images": [[142, 148], ["subproc_multitask_vec_env.MTSubprocVecEnv._assert_not_closed", "pipe.send", "pipe.recv"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.MTSubprocVecEnv._assert_not_closed"], ["", "", "def", "get_images", "(", "self", ")", ":", "\n", "        ", "self", ".", "_assert_not_closed", "(", ")", "\n", "for", "pipe", "in", "self", ".", "remotes", ":", "\n", "            ", "pipe", ".", "send", "(", "(", "'render'", ",", "None", ")", ")", "\n", "", "imgs", "=", "[", "pipe", ".", "recv", "(", ")", "for", "pipe", "in", "self", ".", "remotes", "]", "\n", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.MTSubprocVecEnv._assert_not_closed": [[149, 151], ["None"], "methods", ["None"], ["", "def", "_assert_not_closed", "(", "self", ")", ":", "\n", "        ", "assert", "not", "self", ".", "closed", ",", "\"Trying to operate on a SubprocVecEnv after calling close()\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.draw_and_set_task": [[16, 25], ["range", "isinstance", "unwrapped_env.draw_and_set_task"], "function", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.draw_and_set_task"], ["def", "draw_and_set_task", "(", "self", ",", "constraint", ",", "seed", ")", ":", "\n", "    ", "seeds", "=", "[", "None", "]", "*", "self", ".", "num_envs", "\n", "for", "e", "in", "range", "(", "self", ".", "num_envs", ")", ":", "\n", "\n", "        ", "unwrapped_env", "=", "self", ".", "envs", "[", "e", "]", "\n", "while", "isinstance", "(", "unwrapped_env", ",", "gym", ".", "Wrapper", ")", ":", "\n", "            ", "unwrapped_env", "=", "unwrapped_env", ".", "env", "\n", "", "seeds", "[", "e", "]", "=", "unwrapped_env", ".", "draw_and_set_task", "(", "constraint", "[", "e", "]", ",", "seed", "[", "e", "]", ")", "\n", "", "return", "seeds", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.subproc_multitask_vec_env.worker": [[30, 72], ["parent_remote.close", "env_fn_wrapper.x", "isinstance", "env_fn_wrapper.x.close", "remote.recv", "print", "env_fn_wrapper.x.step", "remote.send", "env_fn_wrapper.x.reset", "env_fn_wrapper.x.reset", "remote.send", "remote.send", "env_fn_wrapper.x.render", "remote.close", "remote.send", "unwrapped_env.draw_and_set_task", "remote.send"], "function", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.close", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.close", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.KFACOptimizer.step", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.reset", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.reset", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.render", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.close", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.draw_and_set_task"], ["def", "worker", "(", "remote", ",", "parent_remote", ",", "env_fn_wrapper", ")", ":", "\n", "    ", "parent_remote", ".", "close", "(", ")", "\n", "env", "=", "env_fn_wrapper", ".", "x", "(", ")", "\n", "unwrapped_env", "=", "env", "\n", "while", "isinstance", "(", "unwrapped_env", ",", "gym", ".", "Wrapper", ")", ":", "\n", "        ", "unwrapped_env", "=", "unwrapped_env", ".", "env", "\n", "", "try", ":", "\n", "        ", "while", "True", ":", "\n", "# print(\"Waiting for command...\")", "\n", "# cmd, data = remote.recv()", "\n", "            ", "recieved", "=", "remote", ".", "recv", "(", ")", "\n", "# print(\"Recieved: \" + str(recieved))", "\n", "cmd", ",", "data", "=", "recieved", "\n", "# print(\"Command: \"+cmd)", "\n", "if", "cmd", "==", "'step'", ":", "\n", "                ", "ob", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "data", ")", "\n", "if", "done", ":", "\n", "                    ", "ob", "=", "env", ".", "reset", "(", ")", "\n", "", "remote", ".", "send", "(", "(", "ob", ",", "reward", ",", "done", ",", "info", ")", ")", "\n", "", "elif", "cmd", "==", "'reset'", ":", "\n", "                ", "ob", "=", "env", ".", "reset", "(", ")", "\n", "remote", ".", "send", "(", "ob", ")", "\n", "", "elif", "cmd", "==", "'render'", ":", "\n", "                ", "remote", ".", "send", "(", "env", ".", "render", "(", "mode", "=", "'rgb_array'", ")", ")", "\n", "", "elif", "cmd", "==", "'close'", ":", "\n", "                ", "remote", ".", "close", "(", ")", "\n", "break", "\n", "", "elif", "cmd", "==", "'get_spaces'", ":", "\n", "                ", "remote", ".", "send", "(", "(", "env", ".", "observation_space", ",", "env", ".", "action_space", ")", ")", "\n", "# print(\"spaces sent\")", "\n", "", "elif", "cmd", "==", "'draw_and_set_task'", ":", "\n", "# print(data)", "\n", "                ", "seed", "=", "unwrapped_env", ".", "draw_and_set_task", "(", "\n", "data", "[", "'constraint'", "]", ",", "data", "[", "'seed'", "]", ")", "\n", "# print(seed)", "\n", "remote", ".", "send", "(", "seed", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "print", "(", "'SubprocVecEnv worker: got KeyboardInterrupt'", ")", "\n", "", "finally", ":", "\n", "        ", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.envs.AddTimestep.__init__": [[54, 61], ["gym.ObservationWrapper.__init__", "gym.spaces.box.Box"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", "=", "None", ")", ":", "\n", "        ", "super", "(", "AddTimestep", ",", "self", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "observation_space", "=", "Box", "(", "\n", "self", ".", "observation_space", ".", "low", "[", "0", "]", ",", "\n", "self", ".", "observation_space", ".", "high", "[", "0", "]", ",", "\n", "[", "self", ".", "observation_space", ".", "shape", "[", "0", "]", "+", "1", "]", ",", "\n", "dtype", "=", "self", ".", "observation_space", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.envs.AddTimestep.observation": [[62, 64], ["numpy.concatenate"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "observation", ")", ":", "\n", "        ", "return", "np", ".", "concatenate", "(", "(", "observation", ",", "[", "self", ".", "env", ".", "_elapsed_steps", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.envs.WrapPyTorch.__init__": [[67, 84], ["gym.ObservationWrapper.__init__", "len", "gym.spaces.box.Box", "len", "gym.spaces.box.Box"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", "=", "None", ")", ":", "\n", "        ", "super", "(", "WrapPyTorch", ",", "self", ")", ".", "__init__", "(", "env", ")", "\n", "obs_shape", "=", "self", ".", "observation_space", ".", "shape", "\n", "if", "len", "(", "obs_shape", ")", "==", "1", ":", "\n", "            ", "self", ".", "observation_space", "=", "Box", "(", "\n", "self", ".", "observation_space", ".", "low", "[", "0", "]", ",", "\n", "self", ".", "observation_space", ".", "high", "[", "0", "]", ",", "\n", "[", "obs_shape", "[", "0", "]", "]", ",", "\n", "dtype", "=", "self", ".", "observation_space", ".", "dtype", ")", "\n", "", "elif", "len", "(", "obs_shape", ")", "==", "3", ":", "\n", "            ", "self", ".", "observation_space", "=", "Box", "(", "\n", "self", ".", "observation_space", ".", "low", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "self", ".", "observation_space", ".", "high", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "[", "obs_shape", "[", "2", "]", ",", "obs_shape", "[", "0", "]", ",", "obs_shape", "[", "1", "]", "]", ",", "\n", "dtype", "=", "self", ".", "observation_space", ".", "dtype", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.envs.WrapPyTorch.observation": [[85, 87], ["observation.transpose"], "methods", ["None"], ["", "", "def", "observation", "(", "self", ",", "observation", ")", ":", "\n", "        ", "return", "observation", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.envs.make_env": [[27, 51], ["env_id.startswith", "WrapPyTorch.seed", "env_id.split", "dm_control2gym.make", "gym.make", "gym.wrappers.Monitor", "envs.AddTimestep", "envs.WrapPyTorch", "len", "str().find", "len", "str"], "function", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.seed"], ["", "def", "make_env", "(", "env_id", ",", "seed", ",", "rank", ",", "add_timestep", ",", "save_video", "=", "None", ")", ":", "\n", "    ", "def", "_thunk", "(", ")", ":", "\n", "        ", "if", "env_id", ".", "startswith", "(", "\"dm\"", ")", ":", "\n", "            ", "_", ",", "domain", ",", "task", "=", "env_id", ".", "split", "(", "'.'", ")", "\n", "env", "=", "dm_control2gym", ".", "make", "(", "domain_name", "=", "domain", ",", "task_name", "=", "task", ")", "\n", "", "else", ":", "\n", "            ", "env", "=", "gym", ".", "make", "(", "env_id", ")", "\n", "", "if", "save_video", "is", "not", "None", ":", "\n", "            ", "env", "=", "Monitor", "(", "env", ",", "save_video", ",", "force", "=", "True", ")", "\n", "", "env", ".", "seed", "(", "seed", "+", "rank", ")", "\n", "\n", "obs_shape", "=", "env", ".", "observation_space", ".", "shape", "\n", "if", "add_timestep", "and", "len", "(", "\n", "obs_shape", ")", "==", "1", "and", "str", "(", "env", ")", ".", "find", "(", "'TimeLimit'", ")", ">", "-", "1", ":", "\n", "            ", "env", "=", "AddTimestep", "(", "env", ")", "\n", "\n", "# If the input has shape (W,H,3), wrap for PyTorch convolutions", "\n", "", "obs_shape", "=", "env", ".", "observation_space", ".", "shape", "\n", "if", "len", "(", "obs_shape", ")", "==", "3", "and", "obs_shape", "[", "2", "]", "in", "[", "1", ",", "2", ",", "3", "]", ":", "\n", "            ", "env", "=", "WrapPyTorch", "(", "env", ")", "\n", "\n", "", "return", "env", "\n", "\n", "", "return", "_thunk", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.__init__": [[26, 95], ["torch.Module.__init__", "gym.spaces.Discrete", "gym.spaces.Discrete", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "model.Policy", "model.Policy", "model.Encoder", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "model.Policy", "model.Policy", "model.Policy", "model.ValueFunction", "model.Encoder", "range", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_tasks", ",", "num_processes_per_task", ",", "alpha", ",", "\n", "obs_shape", ",", "action_space", ",", "loss", ",", "architecture", ",", "option_init", ")", ":", "\n", "        ", "\"\"\"\n        Initialize all master policies, options and respective priors.\n\n        Note that the value function returned by options is V(s_t,z_t) and the value function\n        returned by masters is U(s_t, z_{t-1}), so we don't need to initialize them separately.\n\n\n        Args:\n            num_tasks (int): Number of tasks (how many different task specific policies we need)\n            num_options (int): How many different options we use\n            num_processes_per_task: How many environments share the same task structure?\n            alpha (float) with 0<alpha<1: Prob. mass in prior master of repeating option obs_shape\n            obs_shape: Observation shape of environment (already stacked if num_stack > 1)\n            action_space: Action_space of environment\n        \"\"\"", "\n", "super", "(", "HierarchicalPolicy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "num_processes_per_task", "=", "num_processes_per_task", "\n", "self", ".", "num_tasks", "=", "num_tasks", "\n", "self", ".", "num_options", "=", "architecture", "[", "'num_options'", "]", "\n", "self", ".", "loss", "=", "loss", "\n", "self", ".", "action_space", "=", "action_space", "\n", "self", ".", "obs_shape", "=", "obs_shape", "\n", "self", ".", "architecture", "=", "architecture", "\n", "self", ".", "option_init", "=", "option_init", "\n", "# self.use_learned_master_prior = False", "\n", "# self.use_distilled_termination_prior = False", "\n", "\n", "# Initialize Master Policies", "\n", "self", ".", "master_action_space", "=", "Discrete", "(", "self", ".", "num_options", ")", "\n", "self", ".", "binary_action_space", "=", "Discrete", "(", "2", ")", "\n", "\n", "\n", "# Separate encoders for priors, masters and options", "\n", "# TODO: Make ugly workaround nicer", "\n", "# IMPORTANT: When changing stuff here, make sure the optimizer is initialized correctly!", "\n", "if", "architecture", "[", "'shared_encoder'", "]", ":", "\n", "            ", "encoder", "=", "Encoder", "(", "obs_shape", "=", "obs_shape", ",", "architecture", "=", "architecture", ")", "\n", "self", ".", "encoders", "=", "nn", ".", "ModuleList", "(", "[", "encoder", ",", "encoder", ",", "encoder", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "encoders", "=", "nn", ".", "ModuleList", "(", "[", "Encoder", "(", "obs_shape", "=", "obs_shape", ",", "architecture", "=", "architecture", ")", "for", "i", "in", "range", "(", "3", ")", "]", ")", "\n", "", "self", ".", "encoders_index", "=", "{", "\n", "\"option\"", ":", "0", ",", "\n", "\"prior\"", ":", "1", ",", "\n", "\"master\"", ":", "2", "\n", "}", "\n", "\n", "self", ".", "frozen", "=", "{", "\n", "\"option\"", ":", "False", ",", "\n", "\"prior\"", ":", "False", ",", "\n", "\"master\"", ":", "False", "\n", "}", "\n", "# OPTIONS", "\n", "self", ".", "options", "=", "nn", ".", "ModuleList", "(", "[", "Policy", "(", "action_space", "=", "action_space", ",", "architecture", "=", "architecture", ")", "\n", "for", "j", "in", "range", "(", "num_tasks", ")", "]", ")", "\n", "self", ".", "terminations", "=", "nn", ".", "ModuleList", "(", "[", "Policy", "(", "action_space", "=", "self", ".", "binary_action_space", ",", "architecture", "=", "architecture", ")", "\n", "for", "i", "in", "range", "(", "num_tasks", ")", "]", ")", "\n", "\n", "\n", "# MASTERS: During training, share encoder with options to prevent premature convergence", "\n", "self", ".", "masters", "=", "nn", ".", "ModuleList", "(", "[", "Policy", "(", "action_space", "=", "self", ".", "master_action_space", ",", "architecture", "=", "architecture", ")", "\n", "for", "i", "in", "range", "(", "num_tasks", ")", "]", ")", "\n", "self", ".", "value_functions", "=", "nn", ".", "ModuleList", "(", "[", "ValueFunction", "(", "architecture", "=", "architecture", ")", "for", "j", "in", "range", "(", "num_tasks", ")", "]", ")", "\n", "\n", "# PRIORS: Having a separate encoder allows freezing _only_ the priors will changing posteriors", "\n", "self", ".", "option_priors", "=", "Policy", "(", "action_space", "=", "action_space", ",", "architecture", "=", "architecture", ")", "\n", "self", ".", "termination_priors", "=", "Policy", "(", "action_space", "=", "self", ".", "binary_action_space", ",", "architecture", "=", "architecture", ")", "\n", "# self.master_priors = Policy(action_space=self.master_action_space, architecture=architecture)", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.split_encoder": [[98, 105], ["hierarchical_policy.HierarchicalPolicy.encoders[].state_dict", "torch.ModuleList", "torch.ModuleList", "range", "next", "hierarchical_policy.HierarchicalPolicy.encoders[].load_state_dict", "hierarchical_policy.HierarchicalPolicy.parameters", "model.Encoder().to", "range", "model.Encoder"], "methods", ["None"], ["", "def", "split_encoder", "(", "self", ")", ":", "\n", "        ", "\"\"\" Split all three encoders as they were shared before\"\"\"", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "encoder_state_dict", "=", "self", ".", "encoders", "[", "0", "]", ".", "state_dict", "(", ")", "\n", "self", ".", "encoders", "=", "nn", ".", "ModuleList", "(", "[", "Encoder", "(", "obs_shape", "=", "self", ".", "obs_shape", ",", "architecture", "=", "self", ".", "architecture", ")", ".", "to", "(", "device", ")", "for", "i", "in", "range", "(", "3", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "self", ".", "encoders", "[", "i", "]", ".", "load_state_dict", "(", "encoder_state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.get_features": [[107, 125], ["obs.size", "encoder().view", "features.detach.detach.detach", "encoder", "obs.contiguous().view", "z.contiguous().view", "obs.contiguous", "z.contiguous"], "methods", ["None"], ["", "", "def", "get_features", "(", "self", ",", "obs", ",", "z", ",", "encoder_type", ")", ":", "\n", "# print(\"Evaluate features: {}\".format(encoder_type))", "\n", "\n", "        ", "encoder", "=", "self", ".", "encoders", "[", "self", ".", "encoders_index", "[", "encoder_type", "]", "]", "\n", "\n", "num_tasks", ",", "num_processes_per_task", ",", "*", "obs_shape", "=", "obs", ".", "size", "(", ")", "\n", "features", "=", "encoder", "(", "\n", "inputs", "=", "obs", ".", "contiguous", "(", ")", ".", "view", "(", "num_tasks", "*", "num_processes_per_task", ",", "*", "obs_shape", ")", ",", "\n", "option", "=", "z", ".", "contiguous", "(", ")", ".", "view", "(", "num_tasks", "*", "num_processes_per_task", ",", "1", ")", "\n", ")", ".", "view", "(", "num_tasks", ",", "num_processes_per_task", ",", "-", "1", ")", "\n", "\n", "# if not self.training and not policy_type in [\"master\", \"value\", \"distilled-master\"]:", "\n", "if", "self", ".", "frozen", "[", "encoder_type", "]", ":", "\n", "# print(\"Cutting gradients\")", "\n", "            ", "features", "=", "features", ".", "detach", "(", ")", "\n", "# else:", "\n", "#     print(\"Not cutting gradients\")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.reset_encoder": [[126, 129], ["model.Encoder().to", "next", "hierarchical_policy.HierarchicalPolicy.parameters", "model.Encoder"], "methods", ["None"], ["", "def", "reset_encoder", "(", "self", ",", "encoder_type", ")", ":", "\n", "        ", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "self", ".", "encoders", "[", "self", ".", "encoders_index", "[", "encoder_type", "]", "]", "=", "Encoder", "(", "obs_shape", "=", "self", ".", "obs_shape", ",", "architecture", "=", "self", ".", "architecture", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.get_slice": [[130, 132], ["None"], "methods", ["None"], ["", "def", "get_slice", "(", "self", ",", "task_id", ")", ":", "\n", "        ", "return", "task_id", "*", "self", ".", "num_processes_per_task", ",", "(", "task_id", "+", "1", ")", "*", "self", ".", "num_processes_per_task", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.reset_task_policy": [[133, 154], ["model.Policy().to", "model.Policy().to", "model.Policy().to", "model.ValueFunction().to", "next", "hierarchical_policy.HierarchicalPolicy.options[].load_state_dict", "hierarchical_policy.HierarchicalPolicy.terminations[].load_state_dict", "hierarchical_policy.HierarchicalPolicy.encoders[].load_state_dict", "NotImplementedError", "hierarchical_policy.HierarchicalPolicy.encoders[].load_state_dict", "hierarchical_policy.HierarchicalPolicy.parameters", "model.Policy", "model.Policy", "model.Policy", "model.ValueFunction", "hierarchical_policy.HierarchicalPolicy.option_priors.state_dict", "hierarchical_policy.HierarchicalPolicy.termination_priors.state_dict", "hierarchical_policy.HierarchicalPolicy.encoders[].state_dict", "hierarchical_policy.HierarchicalPolicy.encoders[].state_dict"], "methods", ["None"], ["", "def", "reset_task_policy", "(", "self", ",", "task_id", ")", ":", "\n", "        ", "flags", "=", "self", ".", "option_init", "[", "'train_init_params'", "]", "if", "self", ".", "training", "else", "self", ".", "option_init", "[", "'test_init_params'", "]", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "# print(flags)", "\n", "\n", "self", ".", "options", "[", "task_id", "]", "=", "Policy", "(", "action_space", "=", "self", ".", "action_space", ",", "architecture", "=", "self", ".", "architecture", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "terminations", "[", "task_id", "]", "=", "Policy", "(", "action_space", "=", "self", ".", "binary_action_space", ",", "architecture", "=", "self", ".", "architecture", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "masters", "[", "task_id", "]", "=", "Policy", "(", "action_space", "=", "self", ".", "master_action_space", ",", "architecture", "=", "self", ".", "architecture", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "value_functions", "[", "task_id", "]", "=", "ValueFunction", "(", "architecture", "=", "self", ".", "architecture", ")", ".", "to", "(", "device", ")", "\n", "\n", "if", "flags", "[", "'options'", "]", ":", "\n", "            ", "self", ".", "options", "[", "task_id", "]", ".", "load_state_dict", "(", "self", ".", "option_priors", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "terminations", "[", "task_id", "]", ".", "load_state_dict", "(", "self", ".", "termination_priors", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "encoders", "[", "self", ".", "encoders_index", "[", "'option'", "]", "]", ".", "load_state_dict", "(", "\n", "self", ".", "encoders", "[", "self", ".", "encoders_index", "[", "'prior'", "]", "]", ".", "state_dict", "(", ")", "\n", ")", "\n", "", "if", "flags", "[", "'master'", "]", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Bad idea: Encoder isn't trained for value function. Create separate V encoder?\"", ")", "\n", "# self.masters[task_id].load_state_dict(copy.deepcopy(self.master_priors.state_dict()))", "\n", "self", ".", "encoders", "[", "self", ".", "encoders_index", "[", "'master'", "]", "]", ".", "load_state_dict", "(", "\n", "self", ".", "encoders", "[", "self", ".", "encoders_index", "[", "'prior'", "]", "]", ".", "state_dict", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.executePolicy": [[157, 234], ["hierarchical_policy.HierarchicalPolicy.get_features", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "policies[].act", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "b.float.float.float", "torch.stack.append", "torch.stack.append", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "model.toOnehot", "masks.long", "masks.long"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.get_features", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.model.Policy.act", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.model.toOnehot"], ["", "", "def", "executePolicy", "(", "self", ",", "obs", ",", "z", ",", "policy_type", ",", "b", "=", "None", ",", "masks", "=", "None", ",", "deterministic", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Execute policies. Either master or option as specified by type.\n\n        batch_size = num_processes_per_task [* num_steps]\n\n        Args:\n            obs [num_tasks, batch_size]: Observations\n            z [num_tasks, batch_size]: Previously (for master) or current (for policy) z\n            policy_type (String): \"master\" or \"option\". Specifies which policy to execute\n            masks: Mask, indicating the start of a new episode when =0\n\n        All return values have the first two dimensions [num_tasks, batch_size]\n        Return:\n            value (Scalar): U(s_t,z_{t-1}) for \"master\" or V(s_t, z_t) for \"option\"\n            action (Scalar for z_t, action_dimensions for a_t): z_t for \"master\" or a_t for \"option\"\n            action_log_prob (Scalar): master: log q(z_t|s_t,z_{t-1}) option: log q(a_t|s_t,z_t)\n        \"\"\"", "\n", "\n", "assert", "policy_type", "in", "[", "\"master\"", ",", "\"option\"", ",", "\"termination\"", "]", "\n", "\n", "if", "policy_type", "==", "\"termination\"", ":", "\n", "            ", "encoder_type", "=", "\"option\"", "\n", "policies", "=", "self", ".", "terminations", "\n", "", "elif", "policy_type", "==", "\"option\"", ":", "\n", "            ", "encoder_type", "=", "\"option\"", "\n", "policies", "=", "self", ".", "options", "\n", "", "elif", "policy_type", "==", "\"master\"", ":", "\n", "            ", "encoder_type", "=", "\"master\"", "\n", "policies", "=", "self", ".", "masters", "\n", "# Save old_z for b==0, i.e. when we don't change option", "\n", "old_z", "=", "z", "\n", "z", "=", "torch", ".", "full_like", "(", "z", ",", "0", ")", "\n", "\n", "", "actions", "=", "[", "]", "\n", "action_log_probs", "=", "[", "]", "\n", "probs", "=", "[", "]", "\n", "\n", "features", "=", "self", ".", "get_features", "(", "obs", ",", "z", ",", "encoder_type", ")", "\n", "# if not self.training and self.option_init['freeze_options_for_test'] and not policy_type == \"master\":", "\n", "if", "self", ".", "frozen", "[", "encoder_type", "]", ":", "\n", "            ", "deterministic", "=", "True", "\n", "\n", "", "for", "task_id", "in", "range", "(", "self", ".", "num_tasks", ")", ":", "\n", "            ", "action", ",", "action_log_prob", ",", "prob", "=", "policies", "[", "task_id", "]", ".", "act", "(", "features", "[", "task_id", "]", ",", "deterministic", "=", "deterministic", ")", "\n", "actions", ".", "append", "(", "action", ")", "\n", "action_log_probs", ".", "append", "(", "action_log_prob", ")", "\n", "if", "prob", "is", "not", "None", ":", "\n", "                ", "probs", ".", "append", "(", "prob", ")", "\n", "", "else", ":", "\n", "                ", "probs", "=", "None", "\n", "\n", "", "", "actions", "=", "torch", ".", "stack", "(", "actions", ",", "dim", "=", "0", ")", "\n", "action_log_probs", "=", "torch", ".", "stack", "(", "action_log_probs", ",", "dim", "=", "0", ")", "\n", "if", "probs", "is", "not", "None", ":", "\n", "            ", "probs", "=", "torch", ".", "stack", "(", "probs", ",", "dim", "=", "0", ")", "\n", "\n", "", "if", "policy_type", "==", "\"master\"", ":", "\n", "# Only execute the master policy when we terminate an option, i.e. when b==1,", "\n", "# Otherwise just return the previous option z", "\n", "            ", "actions", "=", "actions", "*", "b", "+", "old_z", "*", "(", "1", "-", "b", ")", "\n", "# If b=0, the master must take last action with p(z_t=z_{t-1}) = 1", "\n", "b", "=", "b", ".", "float", "(", ")", "\n", "action_log_probs", "=", "action_log_probs", "*", "b", "\n", "if", "probs", "is", "not", "None", ":", "\n", "                ", "probs", "=", "probs", "*", "b", "+", "(", "1", "-", "b", ")", "*", "toOnehot", "(", "old_z", ",", "self", ".", "num_options", ")", "\n", "", "", "elif", "policy_type", "==", "\"termination\"", ":", "\n", "# At the beginning of en episode, i.e. when masks==0, return 1", "\n", "            ", "actions", "=", "actions", "*", "masks", ".", "long", "(", ")", "+", "(", "1", "-", "masks", ".", "long", "(", ")", ")", "\n", "# If masks=0, the termination policy must take 1 with p(b=1|mask=0) = 1", "\n", "action_log_probs", "=", "action_log_probs", "*", "masks", "\n", "b_termination_onehot", "=", "torch", ".", "zeros_like", "(", "probs", ")", "\n", "b_termination_onehot", "[", ":", ",", ":", ",", "1", "]", "=", "1", "\n", "if", "probs", "is", "not", "None", ":", "\n", "                ", "probs", "=", "probs", "*", "masks", "+", "(", "1", "-", "masks", ")", "*", "b_termination_onehot", "\n", "\n", "", "", "return", "actions", ",", "action_log_probs", ",", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePolicy": [[236, 304], ["hierarchical_policy.HierarchicalPolicy.get_features", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "policies[].evaluate_actions", "dist_entropies.detach.detach.append", "action_log_probs.detach.detach.append", "b.float.float.float", "action_log_probs.detach.detach.detach", "dist_entropies.detach.detach.detach", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.get_features", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.model.Policy.evaluate_actions"], ["", "def", "evaluatePolicy", "(", "self", ",", "obs", ",", "action", ",", "policy_type", ",", "z", "=", "None", ",", "b", "=", "None", ",", "masks", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate policies. Either master or option as specified by type.\n\n        batch_size = num_processes_per_task [* num_steps]\n\n        Args:\n            obs [num_tasks, batch_size]: Observations on all tasks\n            z [num_tasks, batch_size]: Previously (for master) or current (for policy) z\n            action [num_tasks, batch_size]: Actions to evaluate\n            policy_type (String): \"master\" or \"option\". Specifies which policy to execute\n\n        All return values have the first two dimensions [num_tasks, batch_size]\n        Return:\n            value (Scalar): U(s_t,z_{t-1}) for \"master\" or V(s_t, z_t) for \"option\"\n            action_log_prob (Scalar): master: log q(z_t|s_t,z_{t-1}) option: log q(a_t|s_t,z_t)\n        \"\"\"", "\n", "\n", "assert", "policy_type", "in", "[", "\"termination\"", ",", "\"master\"", ",", "\"option\"", "]", "\n", "if", "policy_type", "==", "\"termination\"", ":", "\n", "            ", "encoder_type", "=", "\"option\"", "\n", "policies", "=", "self", ".", "terminations", "\n", "", "elif", "policy_type", "==", "\"option\"", ":", "\n", "            ", "encoder_type", "=", "\"option\"", "\n", "policies", "=", "self", ".", "options", "\n", "", "elif", "policy_type", "==", "\"master\"", ":", "\n", "            ", "encoder_type", "=", "\"master\"", "\n", "policies", "=", "self", ".", "masters", "\n", "# Need to use b because we don't have access to previous z", "\n", "z", "=", "torch", ".", "full_like", "(", "b", ",", "0", ")", "\n", "\n", "# print(\"Evaluate Policy: {}\".format(policy_type))", "\n", "\n", "", "dist_entropies", "=", "[", "]", "\n", "action_log_probs", "=", "[", "]", "\n", "features", "=", "self", ".", "get_features", "(", "obs", ",", "z", ",", "encoder_type", ")", "\n", "\n", "for", "task_id", "in", "range", "(", "self", ".", "num_tasks", ")", ":", "\n", "            ", "action_log_prob", ",", "dist_entropy", "=", "policies", "[", "task_id", "]", ".", "evaluate_actions", "(", "\n", "features", "=", "features", "[", "task_id", "]", ",", "action", "=", "action", "[", "task_id", "]", "\n", ")", "\n", "dist_entropies", ".", "append", "(", "dist_entropy", ")", "\n", "action_log_probs", ".", "append", "(", "action_log_prob", ")", "\n", "\n", "", "action_log_probs", "=", "torch", ".", "stack", "(", "action_log_probs", ",", "dim", "=", "0", ")", "\n", "dist_entropies", "=", "torch", ".", "stack", "(", "dist_entropies", ",", "dim", "=", "0", ")", "\n", "\n", "# This is were it's differentiated through", "\n", "if", "policy_type", "==", "\"master\"", ":", "\n", "# If b=0, the master must take last action with p(z_t=z_{t-1}) = 1", "\n", "# So log p = 0 and entropy = 0", "\n", "            ", "b", "=", "b", ".", "float", "(", ")", "\n", "action_log_probs", "=", "action_log_probs", "*", "b", "\n", "dist_entropies", "=", "dist_entropies", "*", "b", "\n", "", "elif", "policy_type", "==", "\"termination\"", ":", "\n", "# If masks=0, the termination policy must take 1 with p(b=1|mask=0) = 1", "\n", "            ", "action_log_probs", "=", "action_log_probs", "*", "masks", "\n", "dist_entropies", "=", "dist_entropies", "*", "masks", "\n", "\n", "# if not self.training and self.option_init['freeze_options_for_test'] and not policy_type == 'master':", "\n", "", "if", "self", ".", "frozen", "[", "encoder_type", "]", ":", "\n", "# print(\"Cutting gradients\")", "\n", "            ", "action_log_probs", "=", "action_log_probs", ".", "detach", "(", ")", "\n", "dist_entropies", "=", "dist_entropies", ".", "detach", "(", ")", "\n", "# else:", "\n", "# print(\"Not cutting gradients\")", "\n", "\n", "", "return", "(", "action_log_probs", ",", "dist_entropies", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePrior": [[307, 375], ["distributions.FixedCategorical().log_probs", "hierarchical_policy.HierarchicalPolicy.get_features", "action.size", "hierarchical_policy.HierarchicalPolicy.size", "priors.evaluate_actions", "prior_log_prob.detach.detach.view", "prior_log_prob.detach.detach.detach", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "b.float.float.float", "distributions.FixedCategorical", "hierarchical_policy.HierarchicalPolicy.view", "action.contiguous().view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "action.contiguous"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.get_features", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.model.Policy.evaluate_actions"], ["", "def", "evaluatePrior", "(", "self", ",", "obs", ",", "z", ",", "action", ",", "policy_type", ",", "masks", "=", "None", ",", "b", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate the prior probability distribution given an action.\n        We don't need to split between tasks because there is only one joint prior over all tasks.\n\n        batch_size = num_processes_per_task [* num_steps]\n\n        Args:\n            obs [num_tasks, batch_size]: Observations on all tasks\n            z [num_tasks, batch_size]: Previously (for master) or current (for policy) z\n            action [num_tasks, batch_size]: Action to evaluate\n            policy_type (String): \"master\" or \"option\". Specifies which policy to execute\n\n        Return:\n            prior_log_prob [num_tasks, batch_size]: Prior log probability of actions\n        \"\"\"", "\n", "# We don't need \"master\" because it has a uniform prior", "\n", "assert", "policy_type", "in", "[", "\"termination\"", ",", "\"option\"", ",", "\"distilled-termination\"", ",", "\"distilled-master\"", "]", "\n", "# print(\"Evaluate Prior: {}\".format(policy_type))", "\n", "\n", "# Use the distilled termination log prob if either policy_type ==", "\n", "# \"distilled-termination\" (used for training) or self.use_distilled_termination_prior (used", "\n", "# for distillation during test)", "\n", "# if policy_type == \"termination\" and self.use_distilled_termination_prior:", "\n", "# TODO: Easier way to write this?", "\n", "if", "policy_type", "==", "\"termination\"", "and", "not", "self", ".", "training", ":", "\n", "            ", "policy_type", "=", "\"distilled-termination\"", "\n", "\n", "", "if", "policy_type", "==", "\"termination\"", ":", "\n", "# Non-termination (i.e. 0) should have log_prob = log(alpha)", "\n", "            ", "prior_log_prob", "=", "FixedCategorical", "(", "probs", "=", "torch", ".", "tensor", "(", "\n", "[", "self", ".", "alpha", ",", "1", "-", "self", ".", "alpha", "]", ",", "\n", "device", "=", "action", ".", "device", "\n", ")", ")", ".", "log_probs", "(", "action", ")", "\n", "prior_log_prob", "=", "prior_log_prob", "*", "masks", "\n", "\n", "", "else", ":", "\n", "            ", "if", "policy_type", "==", "\"distilled-termination\"", ":", "\n", "                ", "priors", "=", "self", ".", "termination_priors", "\n", "", "if", "policy_type", "==", "\"distilled-master\"", ":", "\n", "                ", "priors", "=", "self", ".", "master_priors", "\n", "z", "=", "torch", ".", "full_like", "(", "z", ",", "0", ")", "\n", "", "elif", "policy_type", "==", "\"option\"", ":", "\n", "                ", "priors", "=", "self", ".", "option_priors", "\n", "\n", "", "features", "=", "self", ".", "get_features", "(", "obs", ",", "z", ",", "encoder_type", "=", "\"prior\"", ")", "\n", "\n", "num_tasks", ",", "batch_size", ",", "*", "action_shape", "=", "action", ".", "size", "(", ")", "\n", "num_tasks", ",", "batch_size", ",", "*", "features_shape", "=", "features", ".", "size", "(", ")", "\n", "prior_log_prob", ",", "_", "=", "priors", ".", "evaluate_actions", "(", "\n", "features", "=", "features", ".", "view", "(", "num_tasks", "*", "batch_size", ",", "*", "features_shape", ")", ",", "\n", "action", "=", "action", ".", "contiguous", "(", ")", ".", "view", "(", "num_tasks", "*", "batch_size", ",", "*", "action_shape", ")", ")", "\n", "prior_log_prob", "=", "prior_log_prob", ".", "view", "(", "num_tasks", ",", "batch_size", ",", "1", ")", "\n", "\n", "if", "policy_type", "==", "\"distilled-termination\"", ":", "\n", "                ", "prior_log_prob", "=", "prior_log_prob", "*", "masks", "\n", "", "if", "policy_type", "==", "\"distilled-master\"", ":", "\n", "                ", "b", "=", "b", ".", "float", "(", ")", "\n", "prior_log_prob", "=", "prior_log_prob", "*", "b", "\n", "# actions = actions * masks.long() + (1 - masks.long())", "\n", "\n", "# if not self.training and self.option_init['freeze_priors_for_test']:", "\n", "", "", "if", "self", ".", "frozen", "[", "\"prior\"", "]", ":", "\n", "# print(\"Cutting gradients\")", "\n", "            ", "prior_log_prob", "=", "prior_log_prob", ".", "detach", "(", ")", "\n", "# else:", "\n", "#     print(\"Not cutting gradients\")", "\n", "", "return", "prior_log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.get_V": [[378, 380], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_V", "(", "self", ",", "obs", ",", "z", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Currently only wendelins loss is implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.get_U": [[384, 412], ["hierarchical_policy.HierarchicalPolicy.get_features", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "hierarchical_policy.HierarchicalPolicy.value_functions[].get_value", "values.append"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.get_features", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.model.ValueFunction.get_value"], ["", "def", "get_U", "(", "self", ",", "obs", ",", "previous_z", ")", ":", "\n", "        ", "\"\"\"\n        Return the state-option value function U(s_{t+1}, z_t).\n        They correspond to the value returned by the master policies but can also be computed as\n        follows:\n\n        U(s_{t}, z_{t-1}) = \\sum_{z_t=0}^{num_options} V(s_t, z_t)\n            - action_log_prob (z_t|s_t,z_{t-1}) + prior_log_prob (z_t|s_t,z_{t-1})\n        \n        Currently, we're computing U. \n\n        Args:\n            obs [num_tasks, batch_size]: Observations on all tasks\n            z [num_tasks, batch_size]: Previously (for master) or current (for policy) z\n\n        Return:\n            values [num_tasks, batch_size]: V(s_t,z_t)\n        \"\"\"", "\n", "\n", "values", "=", "[", "]", "\n", "\n", "features", "=", "self", ".", "get_features", "(", "obs", ",", "previous_z", ",", "encoder_type", "=", "\"master\"", ")", "\n", "\n", "for", "task_id", "in", "range", "(", "self", ".", "num_tasks", ")", ":", "\n", "            ", "value", "=", "self", ".", "value_functions", "[", "task_id", "]", ".", "get_value", "(", "features", "[", "task_id", "]", ")", "\n", "values", ".", "append", "(", "value", ")", "\n", "\n", "", "return", "torch", ".", "stack", "(", "values", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.model.Flatten.forward": [[16, 18], ["x.view", "x.size"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.model.Policy.__init__": [[21, 34], ["torch.Module.__init__", "model.Policy.train", "distributions.Categorical", "distributions.DiagGaussian"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.__init__"], ["    ", "def", "__init__", "(", "self", ",", "action_space", ",", "architecture", ")", ":", "\n", "        ", "super", "(", "Policy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoder_output_size", "=", "architecture", "[", "'encoder_output_size'", "]", "\n", "if", "action_space", ".", "__class__", ".", "__name__", "==", "\"Discrete\"", ":", "\n", "            ", "self", ".", "num_outputs", "=", "action_space", ".", "n", "\n", "self", ".", "dist", "=", "Categorical", "(", "self", ".", "encoder_output_size", ",", "self", ".", "num_outputs", ")", "\n", "", "elif", "action_space", ".", "__class__", ".", "__name__", "==", "\"Box\"", ":", "\n", "            ", "num_outputs", "=", "action_space", ".", "shape", "[", "0", "]", "\n", "self", ".", "dist", "=", "DiagGaussian", "(", "self", ".", "encoder_output_size", ",", "num_outputs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.model.Policy.forward": [[37, 39], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.model.Policy.act": [[40, 58], ["model.Policy.dist", "model.Policy.log_probs", "model.Policy.mode", "model.Policy.sample"], "methods", ["None"], ["", "def", "act", "(", "self", ",", "features", ",", "deterministic", "=", "False", ")", ":", "\n", "        ", "dist", "=", "self", ".", "dist", "(", "features", ")", "\n", "\n", "if", "deterministic", ":", "\n", "            ", "action", "=", "dist", ".", "mode", "(", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "dist", ".", "sample", "(", ")", "\n", "\n", "", "action_log_probs", "=", "dist", ".", "log_probs", "(", "action", ")", "\n", "# dist_entropy = dist.entropy().mean()", "\n", "\n", "# dist.probs only exists if action space is discrete", "\n", "try", ":", "\n", "            ", "probs", "=", "dist", ".", "probs", "\n", "", "except", "AttributeError", ":", "\n", "            ", "probs", "=", "None", "\n", "\n", "", "return", "action", ",", "action_log_probs", ",", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.model.Policy.evaluate_actions": [[59, 66], ["model.Policy.dist", "model.Policy.log_probs", "model.Policy.entropy().mean", "model.Policy.entropy"], "methods", ["None"], ["", "def", "evaluate_actions", "(", "self", ",", "features", ",", "action", ")", ":", "\n", "        ", "dist", "=", "self", ".", "dist", "(", "features", ")", "\n", "\n", "action_log_probs", "=", "dist", ".", "log_probs", "(", "action", ")", "\n", "dist_entropy", "=", "dist", ".", "entropy", "(", ")", ".", "mean", "(", ")", "\n", "\n", "return", "action_log_probs", ",", "dist_entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.model.ValueFunction.__init__": [[68, 76], ["torch.Module.__init__", "init_fc_", "model.ValueFunction.train", "utils.init", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.__init__", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.init"], ["    ", "def", "__init__", "(", "self", ",", "architecture", ")", ":", "\n", "        ", "super", "(", "ValueFunction", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder_output_size", "=", "architecture", "[", "'encoder_output_size'", "]", "\n", "init_fc_", "=", "lambda", "m", ":", "init", "(", "m", ",", "\n", "nn", ".", "init", ".", "orthogonal_", ",", "\n", "lambda", "x", ":", "nn", ".", "init", ".", "constant_", "(", "x", ",", "0", ")", ")", "\n", "self", ".", "critic_linear", "=", "init_fc_", "(", "nn", ".", "Linear", "(", "self", ".", "encoder_output_size", ",", "1", ")", ")", "\n", "self", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.model.ValueFunction.get_value": [[77, 80], ["model.ValueFunction.critic_linear"], "methods", ["None"], ["", "def", "get_value", "(", "self", ",", "features", ")", ":", "\n", "        ", "value", "=", "self", ".", "critic_linear", "(", "features", ")", "\n", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.model.Encoder.__init__": [[82, 231], ["torch.Module.__init__", "init_fc_", "torch.Sequential", "torch.Sequential", "torch.Sequential", "model.Encoder.train", "utils.getOutputDimension", "utils.getOutputDimension", "print", "utils.init", "platform.system", "utils.init", "reduce", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "init_encoder_", "torch.ReLU", "torch.ReLU", "torch.ReLU", "utils.getOutputDimension", "utils.getOutputDimension", "utils.getOutputDimension", "utils.getOutputDimension", "torch.init.calculate_gain", "torch.init.calculate_gain", "torch.init.calculate_gain", "utils.init", "model.Flatten", "init_encoder_", "torch.ReLU", "torch.ReLU", "torch.ReLU", "init_encoder_", "torch.ReLU", "torch.ReLU", "torch.ReLU", "reduce", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.calculate_gain", "torch.init.calculate_gain", "torch.init.calculate_gain", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "model.Flatten", "init_encoder_", "torch.ReLU", "torch.ReLU", "torch.ReLU", "init_encoder_", "torch.ReLU", "torch.ReLU", "torch.ReLU", "reduce", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "model.Flatten", "init_encoder_", "torch.ReLU", "torch.ReLU", "torch.ReLU", "reduce", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "model.Flatten", "init_encoder_", "torch.ReLU", "torch.ReLU", "torch.ReLU", "init_encoder_", "torch.ReLU", "torch.ReLU", "torch.ReLU", "reduce", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "model.Flatten", "init_encoder_", "torch.ReLU", "torch.ReLU", "torch.ReLU", "init_encoder_", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "init_encoder_", "torch.ReLU", "torch.ReLU", "torch.ReLU", "init_encoder_", "torch.ReLU", "torch.ReLU", "torch.ReLU", "model.Flatten", "torch.Sequential", "torch.Sequential", "torch.Sequential", "NotImplementedError", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "init_encoder_", "torch.ReLU", "torch.ReLU", "torch.ReLU", "init_encoder_", "torch.ReLU", "torch.ReLU", "torch.ReLU", "init_encoder_", "torch.ReLU", "torch.ReLU", "torch.ReLU", "model.Flatten", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.__init__", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.getOutputDimension", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.getOutputDimension", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.init", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.init", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.getOutputDimension", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.getOutputDimension", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.getOutputDimension", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.getOutputDimension", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.init"], ["    ", "def", "__init__", "(", "self", ",", "obs_shape", ",", "architecture", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "architecture", "[", "'encoder'", "]", "in", "[", "'cnn'", ",", "'cnn3'", "]", ":", "\n", "            ", "k_size", "=", "architecture", "[", "'k_size'", "]", "\n", "padding", "=", "architecture", "[", "'padding'", "]", "\n", "\n", "last_width", "=", "getOutputDimension", "(", "\n", "getOutputDimension", "(", "obs_shape", "[", "1", "]", ",", "k_size", "=", "k_size", ",", "padding", "=", "padding", ",", "stride", "=", "1", ")", ",", "\n", "k_size", "=", "k_size", ",", "padding", "=", "padding", ",", "stride", "=", "1", ")", "\n", "\n", "last_height", "=", "getOutputDimension", "(", "\n", "getOutputDimension", "(", "obs_shape", "[", "2", "]", ",", "k_size", "=", "k_size", ",", "padding", "=", "padding", ",", "stride", "=", "1", ")", ",", "\n", "k_size", "=", "k_size", ",", "padding", "=", "padding", ",", "stride", "=", "1", ")", "\n", "\n", "if", "architecture", "[", "'encoder'", "]", "==", "'cnn3'", ":", "\n", "                ", "last_width", "=", "getOutputDimension", "(", "last_width", ",", "k_size", "=", "k_size", ",", "padding", "=", "padding", ",", "stride", "=", "1", ")", "\n", "last_height", "=", "getOutputDimension", "(", "last_height", ",", "k_size", "=", "k_size", ",", "padding", "=", "padding", ",", "stride", "=", "1", ")", "\n", "\n", "", "n_elements_last_layer", "=", "last_width", "*", "last_height", "*", "32", "\n", "print", "(", "\"Number elements after CNN: {}\"", ".", "format", "(", "n_elements_last_layer", ")", ")", "\n", "\n", "", "from", "operator", "import", "mul", "\n", "from", "functools", "import", "reduce", "\n", "self", ".", "num_options", "=", "architecture", "[", "'num_options'", "]", "\n", "self", ".", "output_size", "=", "architecture", "[", "'encoder_output_size'", "]", "\n", "init_encoder_", "=", "lambda", "m", ":", "init", "(", "m", ",", "\n", "nn", ".", "init", ".", "orthogonal_", ",", "\n", "lambda", "x", ":", "nn", ".", "init", ".", "constant_", "(", "x", ",", "0", ")", ",", "\n", "nn", ".", "init", ".", "calculate_gain", "(", "'relu'", ")", ")", "\n", "\n", "# Ugly hack to make it work on my computer because orthogonal crashes", "\n", "import", "platform", "\n", "if", "platform", ".", "system", "(", ")", "==", "'Darwin'", ":", "\n", "            ", "init_encoder_", "=", "lambda", "m", ":", "init", "(", "m", ",", "\n", "nn", ".", "init", ".", "xavier_normal_", ",", "\n", "lambda", "x", ":", "nn", ".", "init", ".", "constant_", "(", "x", ",", "0", ")", ",", "\n", "nn", ".", "init", ".", "calculate_gain", "(", "'relu'", ")", ")", "\n", "\n", "", "init_fc_", "=", "lambda", "m", ":", "init", "(", "m", ",", "\n", "nn", ".", "init", ".", "orthogonal_", ",", "\n", "lambda", "x", ":", "nn", ".", "init", ".", "constant_", "(", "x", ",", "0", ")", ")", "\n", "\n", "\n", "# Compute number of elements in last layer", "\n", "\n", "if", "architecture", "[", "'encoder'", "]", "==", "'large-fc'", ":", "\n", "            ", "self", ".", "architecture_type", "=", "'fc'", "\n", "num_elements", "=", "reduce", "(", "mul", ",", "obs_shape", ",", "1", ")", "\n", "self", ".", "actor_encoder", "=", "nn", ".", "Sequential", "(", "\n", "Flatten", "(", ")", ",", "\n", "init_encoder_", "(", "nn", ".", "Linear", "(", "num_elements", ",", "1024", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "init_encoder_", "(", "nn", ".", "Linear", "(", "1024", ",", "256", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "# init_encoder_(nn.Linear(256, self.output_size)),", "\n", "# nn.ReLU()", "\n", ")", "\n", "n_elements_last_layer", "=", "256", "\n", "", "elif", "architecture", "[", "'encoder'", "]", "==", "'fc'", ":", "\n", "            ", "self", ".", "architecture_type", "=", "'fc'", "\n", "num_elements", "=", "reduce", "(", "mul", ",", "obs_shape", ",", "1", ")", "\n", "self", ".", "actor_encoder", "=", "nn", ".", "Sequential", "(", "\n", "Flatten", "(", ")", ",", "\n", "init_encoder_", "(", "nn", ".", "Linear", "(", "num_elements", ",", "512", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "init_encoder_", "(", "nn", ".", "Linear", "(", "512", ",", "256", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "# init_encoder_(nn.Linear(256, self.output_size)),", "\n", "# nn.ReLU()", "\n", ")", "\n", "n_elements_last_layer", "=", "256", "\n", "", "elif", "architecture", "[", "'encoder'", "]", "==", "'tiny-fc'", ":", "\n", "            ", "self", ".", "architecture_type", "=", "'fc'", "\n", "num_elements", "=", "reduce", "(", "mul", ",", "obs_shape", ",", "1", ")", "\n", "self", ".", "actor_encoder", "=", "nn", ".", "Sequential", "(", "\n", "Flatten", "(", ")", ",", "\n", "init_encoder_", "(", "nn", ".", "Linear", "(", "num_elements", ",", "32", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "# init_encoder_(nn.Linear(256, self.output_size)),", "\n", "# nn.ReLU()", "\n", ")", "\n", "n_elements_last_layer", "=", "32", "\n", "", "elif", "architecture", "[", "'encoder'", "]", "==", "'small-fc'", ":", "\n", "            ", "self", ".", "architecture_type", "=", "'fc'", "\n", "num_elements", "=", "reduce", "(", "mul", ",", "obs_shape", ",", "1", ")", "\n", "self", ".", "actor_encoder", "=", "nn", ".", "Sequential", "(", "\n", "Flatten", "(", ")", ",", "\n", "init_encoder_", "(", "nn", ".", "Linear", "(", "num_elements", ",", "64", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "init_encoder_", "(", "nn", ".", "Linear", "(", "64", ",", "64", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "# init_encoder_(nn.Linear(256, self.output_size)),", "\n", "# nn.ReLU()", "\n", ")", "\n", "n_elements_last_layer", "=", "64", "\n", "", "elif", "architecture", "[", "'encoder'", "]", "==", "'medium-fc'", ":", "\n", "            ", "self", ".", "architecture_type", "=", "'fc'", "\n", "num_elements", "=", "reduce", "(", "mul", ",", "obs_shape", ",", "1", ")", "\n", "self", ".", "actor_encoder", "=", "nn", ".", "Sequential", "(", "\n", "Flatten", "(", ")", ",", "\n", "init_encoder_", "(", "nn", ".", "Linear", "(", "num_elements", ",", "256", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "init_encoder_", "(", "nn", ".", "Linear", "(", "256", ",", "128", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "# init_encoder_(nn.Linear(256, self.output_size)),", "\n", "# nn.ReLU()", "\n", ")", "\n", "n_elements_last_layer", "=", "128", "\n", "", "elif", "architecture", "[", "'encoder'", "]", "==", "'cnn'", ":", "\n", "            ", "self", ".", "architecture_type", "=", "'cnn'", "\n", "# Computer number of elements in last layer", "\n", "num_inputs", "=", "obs_shape", "[", "0", "]", "\n", "k_size", "=", "architecture", "[", "'k_size'", "]", "\n", "padding", "=", "architecture", "[", "'padding'", "]", "\n", "self", ".", "actor_encoder", "=", "nn", ".", "Sequential", "(", "\n", "init_encoder_", "(", "nn", ".", "Conv2d", "(", "num_inputs", ",", "32", ",", "k_size", ",", "stride", "=", "1", ",", "padding", "=", "padding", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "init_encoder_", "(", "nn", ".", "Conv2d", "(", "32", ",", "32", ",", "k_size", ",", "stride", "=", "1", ",", "padding", "=", "padding", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "Flatten", "(", ")", ",", "\n", ")", "\n", "", "elif", "architecture", "[", "'encoder'", "]", "==", "'cnn3'", ":", "\n", "            ", "self", ".", "architecture_type", "=", "'cnn'", "\n", "num_inputs", "=", "obs_shape", "[", "0", "]", "\n", "k_size", "=", "architecture", "[", "'k_size'", "]", "\n", "padding", "=", "architecture", "[", "'padding'", "]", "\n", "self", ".", "actor_encoder", "=", "nn", ".", "Sequential", "(", "\n", "init_encoder_", "(", "nn", ".", "Conv2d", "(", "num_inputs", ",", "32", ",", "k_size", ",", "stride", "=", "1", ",", "padding", "=", "padding", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "init_encoder_", "(", "nn", ".", "Conv2d", "(", "32", ",", "32", ",", "k_size", ",", "stride", "=", "1", ",", "padding", "=", "padding", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "init_encoder_", "(", "nn", ".", "Conv2d", "(", "32", ",", "32", ",", "k_size", ",", "stride", "=", "1", ",", "padding", "=", "padding", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "Flatten", "(", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Encoder '{}' not implemented\"", ".", "format", "(", "architecture", "[", "'encoder'", "]", ")", ")", "\n", "\n", "\n", "# Add the output of option input fc", "\n", "\n", "", "self", ".", "option_layer", "=", "init_fc_", "(", "nn", ".", "Linear", "(", "self", ".", "num_options", ",", "128", ")", ")", "\n", "self", ".", "actor", "=", "nn", ".", "Sequential", "(", "\n", "init_encoder_", "(", "nn", ".", "Linear", "(", "n_elements_last_layer", "+", "128", ",", "self", ".", "output_size", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "\n", "self", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.model.Encoder.forward": [[233, 244], ["model.Encoder.actor_encoder", "model.Encoder.option_layer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.Encoder.actor", "model.toOnehot"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.model.toOnehot"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "option", ")", ":", "\n", "        ", "norm_factor", "=", "1.0", "\n", "if", "self", ".", "architecture_type", "==", "'cnn'", ":", "\n", "            ", "norm_factor", "=", "255.0", "\n", "\n", "", "actor_features", "=", "self", ".", "actor_encoder", "(", "inputs", "/", "norm_factor", ")", "\n", "option_features", "=", "self", ".", "option_layer", "(", "toOnehot", "(", "option", ",", "self", ".", "num_options", ")", ")", "\n", "features", "=", "torch", ".", "cat", "(", "[", "actor_features", ",", "option_features", "]", ",", "dim", "=", "1", ")", "\n", "features", "=", "self", ".", "actor", "(", "features", ")", "\n", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.model.toOnehot": [[9, 15], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros.scatter_", "list", "option.size"], "function", ["None"], ["def", "toOnehot", "(", "option", ",", "num_options", ")", ":", "\n", "    ", "option_onehot", "=", "torch", ".", "zeros", "(", "\n", "size", "=", "list", "(", "option", ".", "size", "(", ")", "[", ":", "-", "1", "]", ")", "+", "[", "num_options", "]", ",", "\n", "device", "=", "option", ".", "device", ")", "\n", "option_onehot", ".", "scatter_", "(", "-", "1", ",", "option", ",", "1", ")", "\n", "return", "option_onehot", "\n", "", "class", "Flatten", "(", "nn", ".", "Module", ")", ":", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.distributions.Categorical.__init__": [[33, 42], ["torch.Module.__init__", "init_", "utils.init", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.__init__", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.init"], ["    ", "def", "__init__", "(", "self", ",", "num_inputs", ",", "num_outputs", ")", ":", "\n", "        ", "super", "(", "Categorical", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "init_", "=", "lambda", "m", ":", "init", "(", "m", ",", "\n", "nn", ".", "init", ".", "orthogonal_", ",", "\n", "lambda", "x", ":", "nn", ".", "init", ".", "constant_", "(", "x", ",", "0", ")", ",", "\n", "gain", "=", "0.01", ")", "\n", "\n", "self", ".", "linear", "=", "init_", "(", "nn", ".", "Linear", "(", "num_inputs", ",", "num_outputs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.distributions.Categorical.forward": [[43, 46], ["distributions.Categorical.linear", "FixedCategorical"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "linear", "(", "x", ")", "\n", "return", "FixedCategorical", "(", "logits", "=", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.distributions.DiagGaussian.__init__": [[49, 58], ["torch.Module.__init__", "init_", "utils.AddBias", "utils.init", "torch.Linear", "torch.Linear", "torch.Linear", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.__init__", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.init"], ["    ", "def", "__init__", "(", "self", ",", "num_inputs", ",", "num_outputs", ")", ":", "\n", "        ", "super", "(", "DiagGaussian", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "init_", "=", "lambda", "m", ":", "init", "(", "m", ",", "\n", "init_normc_", ",", "\n", "lambda", "x", ":", "nn", ".", "init", ".", "constant_", "(", "x", ",", "0", ")", ")", "\n", "\n", "self", ".", "fc_mean", "=", "init_", "(", "nn", ".", "Linear", "(", "num_inputs", ",", "num_outputs", ")", ")", "\n", "self", ".", "logstd", "=", "AddBias", "(", "torch", ".", "zeros", "(", "num_outputs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.distributions.DiagGaussian.forward": [[59, 69], ["distributions.DiagGaussian.fc_mean", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "distributions.DiagGaussian.logstd", "FixedNormal", "distributions.DiagGaussian.size", "zeros.cuda.cuda.cuda", "distributions.DiagGaussian.exp"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "action_mean", "=", "self", ".", "fc_mean", "(", "x", ")", "\n", "\n", "#  An ugly hack for my KFAC implementation.", "\n", "zeros", "=", "torch", ".", "zeros", "(", "action_mean", ".", "size", "(", ")", ")", "\n", "if", "x", ".", "is_cuda", ":", "\n", "            ", "zeros", "=", "zeros", ".", "cuda", "(", ")", "\n", "\n", "", "action_logstd", "=", "self", ".", "logstd", "(", "zeros", ")", "\n", "return", "FixedNormal", "(", "action_mean", ",", "action_logstd", ".", "exp", "(", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.play_taxi.getOptionsColormap": [[74, 457], ["list", "print", "numpy.zeros", "numpy.ones", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "play_taxi.get_print_name", "os.path.join", "int", "plt.close", "range", "torch.full().long", "numpy.ndindex", "os.path.exists", "os.makedirs", "math.ceil", "math.ceil", "plt.subplots", "fig.suptitle", "range", "os.path.join", "fig.tight_layout", "fig.subplots_adjust", "fig.savefig", "math.sqrt", "plt.subplots", "fig.suptitle", "range", "os.path.join", "fig.tight_layout", "fig.savefig", "plt.subplots", "fig.suptitle", "range", "os.path.join", "fig.tight_layout", "fig.savefig", "plt.subplots", "fig.suptitle", "range", "os.path.join", "fig.tight_layout", "fig.savefig", "plt.subplots", "fig.suptitle", "range", "os.path.join", "fig.tight_layout", "fig.savefig", "room.create_observation", "numpy.expand_dims", "numpy.repeat", "torch.from_numpy().float", "play_taxi.runPolicy", "math.sqrt", "axs[].axis", "axs[].imshow", "axs[].set_title", "axs[].tick_params", "numpy.copy", "axs[].imshow", "axs[].axis", "axs[].tick_params", "range", "axs[].imshow", "axs[].axis", "axs[].tick_params", "range", "range", "range", "torch.full", "range", "z_probs.numpy", "enumerate", "enumerate", "enumerate", "numpy.argmax", "numpy.array", "math.sqrt", "np.copy.transpose", "np.copy.transpose", "range", "np.copy.transpose", "range", "axs[].imshow", "axs[].axis", "axs[].set_ylabel", "axs[].tick_params", "range", "axs[].imshow", "axs[].axis", "axs[].set_ylabel", "axs[].tick_params", "range", "torch.from_numpy", "numpy.argmax", "numpy.argmax().item", "a_prob[].item", "numpy.array", "math.sqrt", "numpy.partition", "numpy.array", "max", "tuple", "axs[].arrow", "math.sqrt", "matplotlib.patches.Circle", "axs[].add_patch", "axs[].annotate", "np.copy.transpose", "range", "np.copy.transpose", "range", "tuple", "tuple", "np.repeat.reshape", "numpy.partition", "numpy.partition", "numpy.array", "max", "numpy.array().flatten", "tuple", "tuple", "tuple", "tuple", "math.sqrt", "matplotlib.patches.Circle", "axs[].add_patch", "axs[].annotate", "tuple", "axs[].arrow", "tuple", "numpy.array().flatten", "tuple", "numpy.array", "tuple", "numpy.argmax", "numpy.array().flatten", "tuple", "tuple", "tuple", "numpy.sign", "numpy.sign", "numpy.array", "numpy.array", "str", "numpy.sign", "numpy.sign", "numpy.array", "numpy.array", "numpy.array", "str"], "function", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.play_taxi.get_print_name", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.close", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.create_observation", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.play_taxi.runPolicy"], ["def", "getOptionsColormap", "(", "room", ",", "constraint", ",", "envs", ",", "directory", ",", "config", ",", "\n", "num_tasks", ",", "num_processes_per_task", ",", "num_options", ",", "type", "=", "'png'", ",", "do_master_map", "=", "False", ",", "do_action_map", "=", "False", ",", "do_termination_map", "=", "False", ",", "do_posterior_termination_map", "=", "False", ",", "\n", "task_id_reorder", "=", "list", "(", "range", "(", "10", ")", ")", ")", ":", "\n", "    ", "print", "(", "\"Creating Option Colormap...\"", ")", "\n", "# Set the situation", "\n", "task_id", "=", "1", "\n", "\n", "# valid_coords = np.transpose(np.nonzero(room.walkable))", "\n", "\n", "# Not dependent on option_id", "\n", "option_maps", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_tasks", ",", ")", "+", "room", ".", "walkable", ".", "shape", "+", "(", "3", ",", ")", ")", "\n", "wall_maps", "=", "np", ".", "ones", "(", "shape", "=", "room", ".", "walkable", ".", "shape", "+", "(", "3", ",", ")", ")", "\n", "posterior_termination_maps", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_tasks", ",", "num_options", ")", "+", "room", ".", "walkable", ".", "shape", "+", "(", "1", ",", ")", ")", "\n", "\n", "action_maps", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_options", ",", ")", "+", "room", ".", "walkable", ".", "shape", "+", "(", "3", ",", ")", ")", "\n", "arrow_maps", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_options", ",", ")", "+", "room", ".", "walkable", ".", "shape", "+", "(", "2", ",", ")", ")", "\n", "arrow_size", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_options", ",", ")", "+", "room", ".", "walkable", ".", "shape", "+", "(", "1", ",", ")", ")", "\n", "termination_prob_map", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_options", ",", ")", "+", "room", ".", "walkable", ".", "shape", "+", "(", "1", ",", ")", ")", "\n", "\n", "posterior_action_maps", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_tasks", ",", "num_options", ",", ")", "+", "room", ".", "walkable", ".", "shape", "+", "(", "3", ",", ")", ")", "\n", "posterior_arrow_maps", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_tasks", ",", "num_options", ",", ")", "+", "room", ".", "walkable", ".", "shape", "+", "(", "2", ",", ")", ")", "\n", "posterior_arrow_size", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_tasks", ",", "num_options", ",", ")", "+", "room", ".", "walkable", ".", "shape", "+", "(", "1", ",", ")", ")", "\n", "\n", "for", "option_id", "in", "range", "(", "num_options", ")", ":", "\n", "        ", "active_option", "=", "torch", ".", "full", "(", "(", "num_tasks", ",", "num_processes_per_task", ",", "1", ")", ",", "option_id", ")", ".", "long", "(", ")", "\n", "for", "coords", "in", "np", ".", "ndindex", "(", "room", ".", "walkable", ".", "shape", ")", ":", "\n", "            ", "if", "not", "room", ".", "walkable", "[", "tuple", "(", "coords", ")", "]", ":", "\n", "                ", "wall_maps", "[", "tuple", "(", "coords", ")", "]", "=", "GREY", "\n", "for", "task_id", "in", "range", "(", "num_tasks", ")", ":", "\n", "                    ", "option_maps", "[", "task_id", "]", "[", "tuple", "(", "coords", ")", "]", "=", "GREY", "\n", "", "continue", "\n", "# print('_____________')", "\n", "# print(coords)", "\n", "", "obs", "=", "room", ".", "create_observation", "(", "layout", "=", "room", ".", "walkable", ",", "loc", "=", "coords", ",", "action", "=", "0", ")", "\n", "# obs = obs.transpose(2, 0, 1) # Channel dimension 2=>0", "\n", "obs", "=", "np", ".", "expand_dims", "(", "obs", ",", "0", ")", "# Create first dimension for batch", "\n", "obs", "=", "np", ".", "repeat", "(", "obs", ",", "num_tasks", ",", "0", ")", "# Same dimension for each task", "\n", "\n", "torch_obs", "=", "torch", ".", "from_numpy", "(", "\n", "obs", ".", "reshape", "(", "num_tasks", ",", "num_processes_per_task", ",", "*", "envs", ".", "observation_space", ".", "shape", ")", ")", ".", "float", "(", ")", "\n", "\n", "z_probs", ",", "action_prior_probs", ",", "b_prior_probs", ",", "b_probs", ",", "a_probs", "=", "runPolicy", "(", "torch_obs", ",", "active_option", ",", "task_id", ")", "\n", "z_probs", "=", "z_probs", ".", "numpy", "(", ")", "[", ":", ",", "0", ",", ":", "]", "# Only one process per task", "\n", "\n", "# Color map for master policy", "\n", "# Master is independent of last option", "\n", "if", "do_master_map", ":", "\n", "                ", "for", "task_id", ",", "z_prob", "in", "enumerate", "(", "z_probs", ")", ":", "\n", "# task_id = task_id_reorder[task_id]", "\n", "                    ", "task_z", "=", "np", ".", "argmax", "(", "z_prob", ")", "\n", "probability", "=", "z_prob", "[", "task_z", "]", "\n", "second_prob", "=", "np", ".", "partition", "(", "np", ".", "array", "(", "z_prob", ")", ".", "flatten", "(", ")", ",", "-", "2", ")", "[", "-", "2", "]", "\n", "option_maps", "[", "task_id", "]", "[", "tuple", "(", "coords", ")", "]", "=", "np", ".", "array", "(", "COLOR_MAP", "[", "task_z", "]", ")", "/", "255.", "*", "(", "probability", "-", "second_prob", ")", "\n", "\n", "", "", "if", "do_action_map", "or", "do_termination_map", "or", "do_posterior_termination_map", ":", "\n", "                ", "for", "task_id", ",", "b_prob", "in", "enumerate", "(", "b_probs", ")", ":", "\n", "# task_id = task_id_reorder[task_id]", "\n", "                    ", "posterior_termination_maps", "[", "task_id", "]", "[", "option_id", "]", "[", "tuple", "(", "coords", ")", "]", "=", "b_prob", "[", "0", ",", "1", "]", "\n", "", "for", "task_id", ",", "a_prob", "in", "enumerate", "(", "a_probs", ")", ":", "\n", "                    ", "a_prob", "=", "a_prob", "[", "0", "]", "\n", "prior_action", "=", "np", ".", "argmax", "(", "a_prob", ")", ".", "item", "(", ")", "\n", "probability", "=", "a_prob", "[", "prior_action", "]", ".", "item", "(", ")", "\n", "second_prob", "=", "np", ".", "partition", "(", "np", ".", "array", "(", "a_prob", ")", ".", "flatten", "(", ")", ",", "-", "2", ")", "[", "-", "2", "]", "\n", "posterior_action_maps", "[", "task_id", "]", "[", "option_id", "]", "[", "tuple", "(", "coords", ")", "]", "=", "np", ".", "array", "(", "COLOR_MAP", "[", "prior_action", "]", ")", "/", "255.", "\n", "posterior_arrow_maps", "[", "task_id", "]", "[", "option_id", "]", "[", "tuple", "(", "coords", ")", "]", "=", "np", ".", "array", "(", "ARROW_MAP", "[", "prior_action", "]", ")", "\n", "posterior_arrow_size", "[", "task_id", "]", "[", "option_id", "]", "[", "tuple", "(", "coords", ")", "]", "=", "math", ".", "sqrt", "(", "max", "(", "probability", "-", "second_prob", ",", "0", ")", ")", "\n", "# Color map for option prior", "\n", "", "prior_action", "=", "np", ".", "argmax", "(", "action_prior_probs", ")", "\n", "probability", "=", "action_prior_probs", "[", "prior_action", "]", "\n", "second_prob", "=", "np", ".", "partition", "(", "np", ".", "array", "(", "action_prior_probs", ")", ".", "flatten", "(", ")", ",", "-", "2", ")", "[", "-", "2", "]", "\n", "action_maps", "[", "option_id", "]", "[", "tuple", "(", "coords", ")", "]", "=", "np", ".", "array", "(", "COLOR_MAP", "[", "prior_action", "]", ")", "/", "255.", "# For choosing color of arrow", "\n", "arrow_maps", "[", "option_id", "]", "[", "tuple", "(", "coords", ")", "]", "=", "np", ".", "array", "(", "ARROW_MAP", "[", "prior_action", "]", ")", "# Direction of arrow", "\n", "arrow_size", "[", "option_id", "]", "[", "tuple", "(", "coords", ")", "]", "=", "math", ".", "sqrt", "(", "max", "(", "probability", "-", "second_prob", ",", "0", ")", ")", "# Size of arrow", "\n", "\n", "termination_prob_map", "[", "option_id", "]", "[", "tuple", "(", "coords", ")", "]", "=", "b_prior_probs", "[", "1", "]", "\n", "\n", "\n", "############################### Plot Maps ####################", "\n", "", "", "", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "from", "skimage", ".", "transform", "import", "resize", "\n", "title", "=", "get_print_name", "(", "config", ")", "\n", "\n", "directory", "=", "os", ".", "path", ".", "join", "(", "\"./image_maps\"", ",", "folder", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "directory", ")", "\n", "\n", "# Create only starting option Map", "\n", "", "if", "do_master_map", ":", "\n", "\n", "        ", "nr_cols", "=", "math", ".", "ceil", "(", "math", ".", "sqrt", "(", "num_tasks", ")", ")", "\n", "nr_rows", "=", "math", ".", "ceil", "(", "num_tasks", "/", "nr_cols", ")", "\n", "\n", "figsize", "=", "(", "3", "*", "nr_cols", ",", "4", "*", "nr_rows", ")", "\n", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "nrows", "=", "nr_rows", ",", "ncols", "=", "nr_cols", ",", "figsize", "=", "figsize", ",", "squeeze", "=", "False", ")", "\n", "fig", ".", "suptitle", "(", "title", ")", "\n", "for", "task_id", "in", "range", "(", "num_tasks", ")", ":", "\n", "            ", "col", "=", "task_id", "%", "nr_cols", "\n", "row", "=", "task_id", "//", "nr_cols", "\n", "img", "=", "option_maps", "[", "task_id", "]", "\n", "# resize_factor = 20 ", "\n", "# image = resize(img, (img.shape[0] * resize_factor, img.shape[1] * resize_factor), order=0, mode='constant')", "\n", "axs", "[", "row", ",", "col", "]", ".", "axis", "(", "'off'", ")", "\n", "axs", "[", "row", ",", "col", "]", ".", "imshow", "(", "img", ".", "transpose", "(", "1", ",", "0", ",", "2", ")", ",", "extent", "=", "(", "0", ",", "11", ",", "0", ",", "11", ")", ")", "\n", "# axs[row, col].set_title(TITLE_MAP[constraint[task_id_reorder[task_id]]], fontsize=30)", "\n", "axs", "[", "row", ",", "col", "]", ".", "set_title", "(", "constraint", "[", "task_id", "]", ",", "fontsize", "=", "30", ")", "\n", "axs", "[", "row", ",", "col", "]", ".", "tick_params", "(", "\n", "axis", "=", "'both'", ",", "\n", "which", "=", "'both'", ",", "\n", "bottom", "=", "False", ",", "\n", "top", "=", "False", ",", "\n", "left", "=", "False", ",", "\n", "right", "=", "False", ",", "\n", "labelbottom", "=", "False", ",", "\n", "labelleft", "=", "False", ")", "\n", "# axs[row, col].set_xlim(0, 11)", "\n", "# axs[row, col].set_ylim(0, 11)", "\n", "\n", "", "filename", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "\"Option_map_{}.{}\"", ".", "format", "(", "_id", ",", "type", ")", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "subplots_adjust", "(", "top", "=", "0.8", ")", "\n", "fig", ".", "savefig", "(", "filename", ")", "\n", "\n", "\n", "", "nr_cols", "=", "int", "(", "math", ".", "sqrt", "(", "num_options", ")", ")", "\n", "nr_rows", "=", "num_options", "//", "nr_cols", "\n", "figsize", "=", "(", "4.5", "*", "nr_cols", ",", "4.5", "*", "nr_rows", ")", "\n", "\n", "resize_factor", "=", "10", "\n", "x_size", ",", "y_size", "=", "room", ".", "walkable", ".", "shape", "\n", "\n", "dx", "=", "1.", "\n", "dy", "=", "1.", "\n", "\n", "s", "=", "dx", "/", "2.", "\n", "d", "=", "0.0001", "\n", "\n", "# Print action map", "\n", "if", "do_action_map", ":", "\n", "        ", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "nrows", "=", "nr_rows", ",", "ncols", "=", "nr_cols", ",", "sharex", "=", "False", ",", "sharey", "=", "False", ",", "figsize", "=", "figsize", ",", "squeeze", "=", "False", ")", "\n", "fig", ".", "suptitle", "(", "title", ")", "\n", "\n", "for", "opt_id", "in", "range", "(", "num_options", ")", ":", "\n", "            ", "col", "=", "opt_id", "%", "nr_cols", "\n", "row", "=", "opt_id", "//", "nr_cols", "\n", "\n", "img", "=", "np", ".", "copy", "(", "wall_maps", ")", "\n", "img", "[", "0", ",", "0", "]", "=", "COLOR_MAP", "[", "opt_id", "]", "\n", "# image = resize(img, (img.shape[0] * resize_factor, img.shape[1] * resize_factor),", "\n", "# order=0, mode='constant')", "\n", "axs", "[", "row", ",", "col", "]", ".", "imshow", "(", "img", ".", "transpose", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "axs", "[", "row", ",", "col", "]", ".", "axis", "(", "'off'", ")", "\n", "axs", "[", "row", ",", "col", "]", ".", "tick_params", "(", "\n", "axis", "=", "'both'", ",", "\n", "which", "=", "'both'", ",", "\n", "bottom", "=", "False", ",", "\n", "top", "=", "False", ",", "\n", "left", "=", "False", ",", "\n", "right", "=", "False", ",", "\n", "labelbottom", "=", "False", ",", "\n", "labelleft", "=", "False", ")", "\n", "# axs[row, col].set_title(\"Option {}\".format(opt_id))", "\n", "for", "x", "in", "range", "(", "x_size", ")", ":", "\n", "                ", "for", "y", "in", "range", "(", "y_size", ")", ":", "\n", "                    ", "size_factor", "=", "arrow_size", "[", "opt_id", ",", "x", ",", "y", ",", "0", "]", "\n", "Dx", ",", "Dy", "=", "arrow_maps", "[", "opt_id", ",", "x", ",", "y", "]", "\n", "h_width", "=", "dx", "*", "0.66", "*", "size_factor", "\n", "h_length", "=", "1.5", "*", "h_width", "\n", "\n", "x_corr", "=", "0", "\n", "y_corr", "=", "0", "\n", "\n", "if", "room", ".", "walkable", "[", "x", ",", "y", "]", "==", "0", "or", "(", "Dx", "==", "0", "and", "Dy", "==", "0", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "Dx", "!=", "0", ":", "\n", "                        ", "x_corr", "=", "h_length", "/", "2", "*", "np", ".", "sign", "(", "Dx", ")", "\n", "", "else", ":", "\n", "                        ", "y_corr", "=", "h_length", "/", "2", "*", "np", ".", "sign", "(", "Dy", ")", "\n", "# print(dx, dy, Dx, Dy, y_corr, x_corr, h_width, h_length)", "\n", "", "color", "=", "tuple", "(", "action_maps", "[", "opt_id", ",", "x", ",", "y", "]", ")", "\n", "axs", "[", "row", ",", "col", "]", ".", "arrow", "(", "\n", "x", "=", "x", "*", "dx", "+", "dx", "/", "2.", "-", "x_corr", "-", "0.5", ",", "\n", "y", "=", "y", "*", "dy", "+", "dy", "/", "2.", "-", "y_corr", "-", "0.5", ",", "\n", "dx", "=", "Dx", ",", "\n", "dy", "=", "Dy", ",", "\n", "# fc='k',", "\n", "# ec='k',", "\n", "fc", "=", "color", ",", "\n", "ec", "=", "color", ",", "\n", "head_width", "=", "h_width", ",", "\n", "head_length", "=", "h_length", ",", "\n", "length_includes_head", "=", "False", ")", "\n", "\n", "", "", "", "filename", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "\"Action_map_{}.{}\"", ".", "format", "(", "_id", ",", "type", ")", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "# fig.subplots_adjust(top=0.9)", "\n", "fig", ".", "savefig", "(", "filename", ")", "\n", "\n", "# Plot termination probabilities", "\n", "", "if", "do_termination_map", ":", "\n", "        ", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "nrows", "=", "nr_rows", ",", "ncols", "=", "nr_cols", ",", "sharex", "=", "False", ",", "sharey", "=", "False", ",", "figsize", "=", "figsize", ",", "squeeze", "=", "False", ")", "\n", "fig", ".", "suptitle", "(", "title", ")", "\n", "\n", "for", "opt_id", "in", "range", "(", "num_options", ")", ":", "\n", "            ", "col", "=", "opt_id", "%", "nr_cols", "\n", "row", "=", "opt_id", "//", "nr_cols", "\n", "\n", "img", "=", "wall_maps", "\n", "# image = resize(img, (img.shape[0] * resize_factor, img.shape[1] * resize_factor),", "\n", "# order=0, mode='constant')", "\n", "axs", "[", "row", ",", "col", "]", ".", "imshow", "(", "img", ".", "transpose", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "axs", "[", "row", ",", "col", "]", ".", "axis", "(", "'off'", ")", "\n", "axs", "[", "row", ",", "col", "]", ".", "tick_params", "(", "\n", "axis", "=", "'both'", ",", "\n", "which", "=", "'both'", ",", "\n", "bottom", "=", "False", ",", "\n", "top", "=", "False", ",", "\n", "left", "=", "False", ",", "\n", "right", "=", "False", ",", "\n", "labelbottom", "=", "False", ",", "\n", "labelleft", "=", "False", ")", "\n", "# axs[row, col].set_title(\"Option {}\".format(opt_id))", "\n", "# patches = []", "\n", "for", "x", "in", "range", "(", "x_size", ")", ":", "\n", "                ", "for", "y", "in", "range", "(", "y_size", ")", ":", "\n", "                    ", "probability", "=", "termination_prob_map", "[", "opt_id", ",", "x", ",", "y", ",", "0", "]", "\n", "size_factor", "=", "math", ".", "sqrt", "(", "probability", ")", "\n", "\n", "x_pos", "=", "x", "*", "dx", "+", "dx", "/", "2.", "-", "0.5", "\n", "y_pos", "=", "y", "*", "dy", "+", "dy", "/", "2.", "-", "0.5", "\n", "\n", "r", "=", "0.5", "*", "size_factor", "\n", "\n", "if", "room", ".", "walkable", "[", "x", ",", "y", "]", "==", "0", ":", "\n", "                        ", "continue", "\n", "\n", "", "circle", "=", "Circle", "(", "(", "x_pos", ",", "y_pos", ")", ",", "r", ",", "\n", "color", "=", "np", ".", "array", "(", "[", "1.", ",", "1.", ",", "1.", "]", ")", "*", "(", "1", "-", "probability", ")", ")", "\n", "\n", "axs", "[", "row", ",", "col", "]", ".", "add_patch", "(", "circle", ")", "\n", "axs", "[", "row", ",", "col", "]", ".", "annotate", "(", "\"{}\"", ".", "format", "(", "str", "(", "probability", ")", "[", ":", "4", "]", ")", ",", "(", "x_pos", ",", "y_pos", ")", ")", "\n", "\n", "", "", "", "filename", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "\"Termination_map_{}.{}\"", ".", "format", "(", "_id", ",", "type", ")", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "# fig.subplots_adjust(top=0.9)", "\n", "fig", ".", "savefig", "(", "filename", ")", "\n", "\n", "\n", "", "if", "do_posterior_termination_map", ":", "\n", "        ", "figsize", "=", "(", "4.5", "*", "num_options", ",", "4.5", "*", "num_tasks", ")", "\n", "\n", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "nrows", "=", "num_tasks", ",", "ncols", "=", "num_options", ",", "sharex", "=", "False", ",", "sharey", "=", "False", ",", "figsize", "=", "figsize", ",", "squeeze", "=", "False", ")", "\n", "fig", ".", "suptitle", "(", "title", ")", "\n", "\n", "for", "col", "in", "range", "(", "num_options", ")", ":", "\n", "            ", "for", "row", "in", "range", "(", "num_tasks", ")", ":", "\n", "\n", "                ", "img", "=", "wall_maps", "\n", "# image = resize(img, (img.shape[0] * resize_factor, img.shape[1] * resize_factor),", "\n", "# order=0, mode='constant')", "\n", "axs", "[", "row", ",", "col", "]", ".", "imshow", "(", "img", ".", "transpose", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "axs", "[", "row", ",", "col", "]", ".", "axis", "(", "'off'", ")", "\n", "# axs[row, 0].set_ylabel(TITLE_MAP[constraint[task_id_reorder[row]]], fontsize=20)", "\n", "# axs[row, 0].set_ylabel(TITLE_MAP[constraint[row]], fontsize=20)", "\n", "axs", "[", "row", ",", "0", "]", ".", "set_ylabel", "(", "constraint", "[", "row", "]", ",", "fontsize", "=", "20", ")", "\n", "axs", "[", "row", ",", "col", "]", ".", "tick_params", "(", "\n", "axis", "=", "'both'", ",", "\n", "which", "=", "'both'", ",", "\n", "bottom", "=", "False", ",", "\n", "top", "=", "False", ",", "\n", "left", "=", "False", ",", "\n", "right", "=", "False", ",", "\n", "labelbottom", "=", "False", ",", "\n", "labelleft", "=", "False", ")", "\n", "for", "x", "in", "range", "(", "x_size", ")", ":", "\n", "                    ", "for", "y", "in", "range", "(", "y_size", ")", ":", "\n", "                        ", "probability", "=", "posterior_termination_maps", "[", "row", ",", "col", ",", "x", ",", "y", ",", "0", "]", "\n", "size_factor", "=", "math", ".", "sqrt", "(", "probability", ")", "\n", "\n", "x_pos", "=", "x", "*", "dx", "+", "dx", "/", "2.", "-", "0.5", "\n", "y_pos", "=", "y", "*", "dy", "+", "dy", "/", "2.", "-", "0.5", "\n", "\n", "r", "=", "0.5", "*", "size_factor", "\n", "\n", "if", "room", ".", "walkable", "[", "x", ",", "y", "]", "==", "0", ":", "\n", "                            ", "continue", "\n", "\n", "", "circle", "=", "Circle", "(", "(", "x_pos", ",", "y_pos", ")", ",", "r", ",", "\n", "color", "=", "np", ".", "array", "(", "[", "1.", ",", "1.", ",", "1.", "]", ")", "*", "(", "1", "-", "probability", ")", ")", "\n", "\n", "axs", "[", "row", ",", "col", "]", ".", "add_patch", "(", "circle", ")", "\n", "axs", "[", "row", ",", "col", "]", ".", "annotate", "(", "\"{}\"", ".", "format", "(", "str", "(", "probability", ")", "[", ":", "4", "]", ")", ",", "(", "x_pos", ",", "y_pos", ")", ")", "\n", "\n", "", "", "", "", "filename", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "\"Post_termination_map_{}.{}\"", ".", "format", "(", "_id", ",", "type", ")", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "# fig.subplots_adjust(top=0.9)", "\n", "fig", ".", "savefig", "(", "filename", ")", "\n", "\n", "################# Posterior action map", "\n", "figsize", "=", "(", "4.5", "*", "num_options", ",", "4.5", "*", "num_tasks", ")", "\n", "\n", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "nrows", "=", "num_tasks", ",", "ncols", "=", "num_options", ",", "sharex", "=", "False", ",", "sharey", "=", "False", ",", "figsize", "=", "figsize", ",", "squeeze", "=", "False", ")", "\n", "fig", ".", "suptitle", "(", "title", ")", "\n", "\n", "######### Old", "\n", "############ Old", "\n", "\n", "for", "col", "in", "range", "(", "num_options", ")", ":", "\n", "            ", "for", "row", "in", "range", "(", "num_tasks", ")", ":", "\n", "\n", "                ", "img", "=", "wall_maps", "\n", "# image = resize(img, (img.shape[0] * resize_factor, img.shape[1] * resize_factor),", "\n", "# order=0, mode='constant')", "\n", "axs", "[", "row", ",", "col", "]", ".", "imshow", "(", "img", ".", "transpose", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "axs", "[", "row", ",", "col", "]", ".", "axis", "(", "'off'", ")", "\n", "# axs[row, 0].set_ylabel(TITLE_MAP[constraint[task_id_reorder[row]]], fontsize=20)", "\n", "# axs[row, 0].set_ylabel(TITLE_MAP[constraint[row]], fontsize=20)", "\n", "axs", "[", "row", ",", "0", "]", ".", "set_ylabel", "(", "constraint", "[", "row", "]", ",", "fontsize", "=", "20", ")", "\n", "axs", "[", "row", ",", "col", "]", ".", "tick_params", "(", "\n", "axis", "=", "'both'", ",", "\n", "which", "=", "'both'", ",", "\n", "bottom", "=", "False", ",", "\n", "top", "=", "False", ",", "\n", "left", "=", "False", ",", "\n", "right", "=", "False", ",", "\n", "labelbottom", "=", "False", ",", "\n", "labelleft", "=", "False", ")", "\n", "\n", "for", "x", "in", "range", "(", "x_size", ")", ":", "\n", "                    ", "for", "y", "in", "range", "(", "y_size", ")", ":", "\n", "                        ", "size_factor", "=", "posterior_arrow_size", "[", "row", ",", "col", ",", "x", ",", "y", ",", "0", "]", "\n", "Dx", ",", "Dy", "=", "posterior_arrow_maps", "[", "row", ",", "col", ",", "x", ",", "y", "]", "\n", "h_width", "=", "dx", "*", "0.66", "*", "size_factor", "\n", "h_length", "=", "1.5", "*", "h_width", "\n", "\n", "x_corr", "=", "0", "\n", "y_corr", "=", "0", "\n", "\n", "if", "room", ".", "walkable", "[", "x", ",", "y", "]", "==", "0", "or", "(", "Dx", "==", "0", "and", "Dy", "==", "0", ")", ":", "\n", "                            ", "continue", "\n", "\n", "", "if", "Dx", "!=", "0", ":", "\n", "                            ", "x_corr", "=", "h_length", "/", "2", "*", "np", ".", "sign", "(", "Dx", ")", "\n", "", "else", ":", "\n", "                            ", "y_corr", "=", "h_length", "/", "2", "*", "np", ".", "sign", "(", "Dy", ")", "\n", "# print(dx, dy, Dx, Dy, y_corr, x_corr, h_width, h_length)", "\n", "", "color", "=", "tuple", "(", "posterior_action_maps", "[", "row", ",", "col", ",", "x", ",", "y", "]", ")", "\n", "axs", "[", "row", ",", "col", "]", ".", "arrow", "(", "\n", "x", "=", "x", "*", "dx", "+", "dx", "/", "2.", "-", "x_corr", "-", "0.5", ",", "\n", "y", "=", "y", "*", "dy", "+", "dy", "/", "2.", "-", "y_corr", "-", "0.5", ",", "\n", "dx", "=", "Dx", ",", "\n", "dy", "=", "Dy", ",", "\n", "# fc='k',", "\n", "# ec='k',", "\n", "fc", "=", "color", ",", "\n", "ec", "=", "color", ",", "\n", "head_width", "=", "h_width", ",", "\n", "head_length", "=", "h_length", ",", "\n", "length_includes_head", "=", "False", ")", "\n", "# for x in range(x_size):", "\n", "#     for y in range(y_size):", "\n", "#         probability = posterior_termination_maps[row, col, x, y, 0]", "\n", "#         size_factor = math.sqrt(probability)", "\n", "\n", "#         x_pos = x*dx + dx/2. - 0.5", "\n", "#         y_pos = y*dy + dy/2. - 0.5", "\n", "\n", "#         r = 0.5 * size_factor", "\n", "\n", "#         if room.walkable[x,y] == 0:", "\n", "#             continue", "\n", "\n", "#         circle = Circle((x_pos, y_pos), r, ", "\n", "#             color=np.array([1.,1.,1.]) * (1 - probability))", "\n", "\n", "#         axs[row, col].add_patch(circle)", "\n", "#         axs[row, col].annotate(\"{}\".format(str(probability)[:4]), (x_pos, y_pos))", "\n", "\n", "", "", "", "", "filename", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "\"Post_action_map_{}.{}\"", ".", "format", "(", "_id", ",", "type", ")", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "# fig.subplots_adjust(top=0.9)", "\n", "fig", ".", "savefig", "(", "filename", ")", "\n", "", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.play_taxi.runPolicy": [[459, 505], ["torch.ones_like", "torch.ones_like().float", "torch.no_grad", "hierarchical_actor_critic.executePolicy", "hierarchical_actor_critic.executePolicy", "hierarchical_actor_critic.executePolicy", "range", "range", "torch.ones_like", "hierarchical_actor_critic.evaluatePrior", "action_prior_probs.append", "hierarchical_actor_critic.evaluatePrior", "b_prior_probs.append", "[].item", "[].item", "torch.full", "torch.full", "torch.exp", "torch.exp"], "function", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.executePolicy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.executePolicy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.executePolicy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePrior", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePrior"], ["", "def", "runPolicy", "(", "torch_obs", ",", "active_option", ",", "task_id", ")", ":", "\n", "    ", "active_b", "=", "torch", ".", "ones_like", "(", "active_option", ")", "\n", "active_mask", "=", "torch", ".", "ones_like", "(", "active_option", ")", ".", "float", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "b", ",", "b_log_prob", ",", "b_probs", "=", "hierarchical_actor_critic", ".", "executePolicy", "(", "\n", "obs", "=", "torch_obs", ",", "\n", "z", "=", "active_option", ",", "\n", "policy_type", "=", "\"termination\"", ",", "\n", "masks", "=", "active_mask", ",", "\n", ")", "\n", "z", ",", "z_log_prob", ",", "z_probs", "=", "hierarchical_actor_critic", ".", "executePolicy", "(", "\n", "obs", "=", "torch_obs", ",", "\n", "z", "=", "active_option", ",", "\n", "policy_type", "=", "\"master\"", ",", "\n", "b", "=", "active_b", "\n", ")", "\n", "action", ",", "action_log_prob", ",", "a_probs", "=", "hierarchical_actor_critic", ".", "executePolicy", "(", "\n", "obs", "=", "torch_obs", ",", "\n", "z", "=", "active_option", ",", "\n", "policy_type", "=", "\"option\"", "\n", ")", "\n", "\n", "action_prior_probs", "=", "[", "]", "\n", "# print(torch_obs[:,:,0])", "\n", "# print(active_option)", "\n", "for", "i", "in", "range", "(", "envs", ".", "action_space", ".", "n", ")", ":", "\n", "            ", "action_prior_log_prob", "=", "hierarchical_actor_critic", ".", "evaluatePrior", "(", "\n", "obs", "=", "torch_obs", ",", "\n", "z", "=", "active_option", ",", "\n", "action", "=", "torch", ".", "full", "(", "(", "num_tasks", ",", "num_processes_per_task", ",", "1", ")", ",", "i", ")", ",", "\n", "policy_type", "=", "\"option\"", "\n", ")", "\n", "action_prior_probs", ".", "append", "(", "torch", ".", "exp", "(", "action_prior_log_prob", ")", "[", "task_id", ",", "0", "]", ".", "item", "(", ")", ")", "\n", "# print(action_prior_probs)", "\n", "", "b_prior_probs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "            ", "b_prior_log_prob", "=", "hierarchical_actor_critic", ".", "evaluatePrior", "(", "\n", "obs", "=", "torch_obs", ",", "\n", "z", "=", "active_option", ",", "\n", "action", "=", "torch", ".", "full", "(", "(", "num_tasks", ",", "num_processes_per_task", ",", "1", ")", ",", "i", ")", ",", "\n", "policy_type", "=", "\"distilled-termination\"", ",", "\n", "masks", "=", "active_mask", "\n", ")", "\n", "b_prior_probs", ".", "append", "(", "torch", ".", "exp", "(", "b_prior_log_prob", ")", "[", "task_id", ",", "0", "]", ".", "item", "(", ")", ")", "\n", "", "", "return", "z_probs", ",", "action_prior_probs", ",", "b_prior_probs", ",", "b_probs", ",", "a_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.play_taxi.load_config": [[506, 513], ["utils.get_docs", "utils.get_docs.find_one", "config.update", "len"], "function", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.update"], ["", "def", "load_config", "(", "_id", ")", ":", "\n", "\n", "    ", "docs", "=", "get_docs", "(", "db_uri", ",", "db_name", ",", "'runs'", ")", "\n", "doc", "=", "docs", ".", "find_one", "(", "{", "'_id'", ":", "_id", "}", ")", "\n", "config", "=", "doc", "[", "'config'", "]", "\n", "config", ".", "update", "(", "{", "'num_processes'", ":", "len", "(", "config", "[", "'tasks'", "]", ")", ",", "'cuda'", ":", "False", "}", ")", "\n", "return", "doc", ",", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.play_taxi.create_environment": [[514, 532], ["len", "print", "print", "subproc_multitask_vec_env.MTSubprocVecEnv", "subproc_multitask_vec_env.MTSubprocVecEnv.draw_and_set_task", "envs.make_env", "range"], "function", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.draw_and_set_task", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.envs.make_env"], ["", "def", "create_environment", "(", "environment", ",", "add_timestep", ",", "tasks", ",", "seeds", ",", "seed", ")", ":", "\n", "    ", "num_tasks", "=", "len", "(", "tasks", ")", "\n", "print", "(", "\"Creating environments...\"", ")", "\n", "print", "(", "\"Environment name: {}\"", ".", "format", "(", "environment", ")", ")", "\n", "# env = make_env('TwoRooms-v2', seed=0, rank=0, add_timestep=False)", "\n", "envs", "=", "[", "make_env", "(", "environment", ",", "seed", ",", "i", ",", "add_timestep", ")", "\n", "for", "i", "in", "range", "(", "num_processes_per_task", "*", "num_tasks", ")", "]", "\n", "envs", "=", "MTSubprocVecEnv", "(", "envs", ")", "\n", "\n", "# TODO: Replace with info dict!", "\n", "constraint", "=", "[", "]", "\n", "start_constraint", "=", "[", "]", "\n", "for", "task", "in", "tasks", ":", "\n", "        ", "constraint", "+=", "[", "task", "]", "*", "num_processes_per_task", "\n", "start_constraint", "+=", "[", "False", "]", "*", "num_processes_per_task", "\n", "\n", "", "seeds", "=", "envs", ".", "draw_and_set_task", "(", "constraint", "=", "constraint", ",", "seed", "=", "seeds", ")", "\n", "return", "envs", ",", "constraint", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.play_taxi.create_and_load_model": [[533, 558], ["print", "hierarchical_policy.HierarchicalPolicy", "print", "utils.get_file_id", "utils.save_file_from_db", "torch.load", "hierarchical_policy.HierarchicalPolicy.load_state_dict", "os.remove", "print"], "function", ["None"], ["", "def", "create_and_load_model", "(", "_id", ",", "num_tasks", ",", "alpha", ",", "envs", ",", "loss", ",", "architecture", ",", "name", ",", "doc", ",", "option_init", ")", ":", "\n", "\n", "    ", "print", "(", "\"Creating model...\"", ")", "\n", "hierarchical_actor_critic", "=", "HierarchicalPolicy", "(", "\n", "num_tasks", "=", "num_tasks", ",", "\n", "num_processes_per_task", "=", "num_processes_per_task", ",", "\n", "alpha", "=", "alpha", ",", "\n", "obs_shape", "=", "envs", ".", "observation_space", ".", "shape", ",", "\n", "action_space", "=", "envs", ".", "action_space", ",", "\n", "loss", "=", "loss", ",", "\n", "architecture", "=", "architecture", ",", "\n", "option_init", "=", "option_init", ")", "\n", "\n", "print", "(", "\"Loading model parameters from db: {}/{}\"", ".", "format", "(", "_id", ",", "name", ")", ")", "\n", "file_id", "=", "get_file_id", "(", "doc", "=", "doc", ",", "file_name", "=", "name", ")", "\n", "save_file_from_db", "(", "file_id", "=", "file_id", ",", "destination", "=", "'model_tmp.pyt'", ",", "db_uri", "=", "db_uri", ",", "db_name", "=", "db_name", ")", "\n", "\n", "# fname = \"/Users/greg/Documents/rl/treeqn/results/57/model_iteration_343750\"", "\n", "\n", "# state_dict  = torch.load(fname, map_location=lambda storage, loc: storage)", "\n", "state_dict", "=", "torch", ".", "load", "(", "\"model_tmp.pyt\"", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "hierarchical_actor_critic", ".", "load_state_dict", "(", "state_dict", ")", "\n", "os", ".", "remove", "(", "'model_tmp.pyt'", ")", "\n", "print", "(", "\"Loading model parameters complete.\"", ")", "\n", "return", "hierarchical_actor_critic", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.play_taxi.get_print_name": [[559, 574], ["[].split", "[].replace", "str().replace", "str", "condition.split", "reduce", "condition.split"], "function", ["None"], ["", "def", "get_print_name", "(", "config", ")", ":", "\n", "    ", "\"\"\"\n    Append the alg_name name with conditions UNLESS they are in the axis_condition\n    \"\"\"", "\n", "conditions", "=", "config", "[", "'meta'", "]", "[", "'conditions'", "]", ".", "split", "(", "\",\"", ")", "\n", "print_name", "=", "\"\"", "\n", "from", "functools", "import", "reduce", "\n", "for", "condition", "in", "conditions", ":", "\n", "        ", "condition_name", "=", "condition", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", ".", "replace", "(", "\"_\"", ",", "\"-\"", ")", "\n", "# insert_dict[condition_name] = \\", "\n", "condition_value", "=", "str", "(", "reduce", "(", "dict", ".", "get", ",", "\n", "condition", ".", "split", "(", "\".\"", ")", ",", "\n", "config", ")", ")", ".", "replace", "(", "\"_\"", ",", "\"-\"", ")", "\n", "print_name", "+=", "\"-\"", "+", "condition_name", "+", "\":\"", "+", "condition_value", "\n", "", "return", "print_name", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.__init__": [[5, 43], ["torch.zeros().long", "torch.zeros().long", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "storage.RolloutStorage.actions.long", "torch.zeros", "torch.zeros"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_tasks", ",", "num_steps", ",", "num_processes", ",", "obs_shape", ",", "action_space", ",", "loss", ")", ":", "\n", "        ", "self", ".", "num_steps", "=", "num_steps", "\n", "self", ".", "num_tasks", "=", "num_tasks", "\n", "self", ".", "num_processes_per_task", "=", "num_processes", "\n", "self", ".", "step", "=", "0", "\n", "self", ".", "loss", "=", "loss", "\n", "\n", "if", "action_space", ".", "__class__", ".", "__name__", "==", "'Discrete'", ":", "\n", "            ", "action_shape", "=", "1", "\n", "", "else", ":", "\n", "            ", "action_shape", "=", "action_space", ".", "shape", "[", "0", "]", "\n", "\n", "# I believe b is shifted by one?", "\n", "", "self", ".", "b", "=", "torch", ".", "zeros", "(", "num_tasks", ",", "num_steps", ",", "num_processes", ",", "1", ")", ".", "long", "(", ")", "\n", "self", ".", "z", "=", "torch", ".", "zeros", "(", "num_tasks", ",", "num_steps", "+", "1", ",", "num_processes", ",", "1", ")", ".", "long", "(", ")", "\n", "self", ".", "obs", "=", "torch", ".", "zeros", "(", "num_tasks", ",", "num_steps", "+", "1", ",", "num_processes", ",", "*", "obs_shape", ")", "\n", "self", ".", "actions", "=", "torch", ".", "zeros", "(", "num_tasks", ",", "num_steps", ",", "num_processes", ",", "action_shape", ")", "\n", "\n", "self", ".", "rewards", "=", "torch", ".", "zeros", "(", "num_tasks", ",", "num_steps", ",", "num_processes", ",", "1", ")", "\n", "self", ".", "value_preds", "=", "torch", ".", "zeros", "(", "num_tasks", ",", "num_steps", "+", "1", ",", "num_processes", ",", "1", ")", "\n", "\n", "self", ".", "b_log_probs", "=", "torch", ".", "zeros", "(", "num_tasks", ",", "num_steps", ",", "num_processes", ",", "1", ")", "\n", "self", ".", "b_prior_log_probs", "=", "torch", ".", "zeros", "(", "num_tasks", ",", "num_steps", ",", "num_processes", ",", "1", ")", "\n", "self", ".", "z_log_probs", "=", "torch", ".", "zeros", "(", "num_tasks", ",", "num_steps", ",", "num_processes", ",", "1", ")", "\n", "# self.z_prior_log_probs = torch.zeros(num_tasks, num_steps, num_processes, 1)", "\n", "self", ".", "action_log_probs", "=", "torch", ".", "zeros", "(", "num_tasks", ",", "num_steps", ",", "num_processes", ",", "1", ")", "\n", "self", ".", "action_prior_log_probs", "=", "torch", ".", "zeros", "(", "num_tasks", ",", "num_steps", ",", "num_processes", ",", "1", ")", "\n", "\n", "self", ".", "returns_z", "=", "torch", ".", "zeros", "(", "num_tasks", ",", "num_steps", "+", "1", ",", "num_processes", ",", "1", ")", "\n", "self", ".", "returns_a", "=", "torch", ".", "zeros", "(", "num_tasks", ",", "num_steps", "+", "1", ",", "num_processes", ",", "1", ")", "\n", "\n", "# Initialize first step of masks to 0, indicating that a new episode begins", "\n", "# This is required for correct treatment of q(z|s, z_{t-1}) and p(z|z_{t-1})", "\n", "self", ".", "masks", "=", "torch", ".", "zeros", "(", "num_tasks", ",", "num_steps", "+", "1", ",", "num_processes", ",", "1", ")", "\n", "\n", "if", "action_space", ".", "__class__", ".", "__name__", "==", "'Discrete'", ":", "\n", "            ", "self", ".", "actions", "=", "self", ".", "actions", ".", "long", "(", ")", "\n", "", "self", ".", "next_value_u", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda": [[44, 63], ["storage.RolloutStorage.obs.cuda", "storage.RolloutStorage.z.cuda", "storage.RolloutStorage.b.cuda", "storage.RolloutStorage.rewards.cuda", "storage.RolloutStorage.value_preds.cuda", "storage.RolloutStorage.b_log_probs.cuda", "storage.RolloutStorage.b_prior_log_probs.cuda", "storage.RolloutStorage.action_log_probs.cuda", "storage.RolloutStorage.action_prior_log_probs.cuda", "storage.RolloutStorage.z_log_probs.cuda", "storage.RolloutStorage.returns_z.cuda", "storage.RolloutStorage.returns_a.cuda", "storage.RolloutStorage.masks.cuda", "storage.RolloutStorage.actions.cuda"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda"], ["", "def", "cuda", "(", "self", ")", ":", "\n", "        ", "self", ".", "obs", "=", "self", ".", "obs", ".", "cuda", "(", ")", "\n", "self", ".", "z", "=", "self", ".", "z", ".", "cuda", "(", ")", "\n", "self", ".", "b", "=", "self", ".", "b", ".", "cuda", "(", ")", "\n", "self", ".", "rewards", "=", "self", ".", "rewards", ".", "cuda", "(", ")", "\n", "self", ".", "value_preds", "=", "self", ".", "value_preds", ".", "cuda", "(", ")", "\n", "\n", "self", ".", "b_log_probs", "=", "self", ".", "b_log_probs", ".", "cuda", "(", ")", "\n", "self", ".", "b_prior_log_probs", "=", "self", ".", "b_prior_log_probs", ".", "cuda", "(", ")", "\n", "self", ".", "action_log_probs", "=", "self", ".", "action_log_probs", ".", "cuda", "(", ")", "\n", "self", ".", "action_prior_log_probs", "=", "self", ".", "action_prior_log_probs", ".", "cuda", "(", ")", "\n", "self", ".", "z_log_probs", "=", "self", ".", "z_log_probs", ".", "cuda", "(", ")", "\n", "# self.z_prior_log_probs = self.z_prior_log_probs.cuda()", "\n", "\n", "self", ".", "returns_z", "=", "self", ".", "returns_z", ".", "cuda", "(", ")", "\n", "self", ".", "returns_a", "=", "self", ".", "returns_a", ".", "cuda", "(", ")", "\n", "\n", "self", ".", "masks", "=", "self", ".", "masks", ".", "cuda", "(", ")", "\n", "self", ".", "actions", "=", "self", ".", "actions", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.insert": [[64, 85], ["storage.RolloutStorage.obs[].copy_", "storage.RolloutStorage.z[].copy_", "storage.RolloutStorage.b[].copy_", "storage.RolloutStorage.actions[].copy_", "storage.RolloutStorage.value_preds[].copy_", "storage.RolloutStorage.b_log_probs[].copy_", "storage.RolloutStorage.b_prior_log_probs[].copy_", "storage.RolloutStorage.z_log_probs[].copy_", "storage.RolloutStorage.action_log_probs[].copy_", "storage.RolloutStorage.action_prior_log_probs[].copy_", "storage.RolloutStorage.rewards[].copy_", "storage.RolloutStorage.masks[].copy_"], "methods", ["None"], ["", "def", "insert", "(", "self", ",", "current_obs", ",", "b", ",", "z", ",", "action", ",", "value_pred", ",", "\n", "action_log_prob", ",", "action_prior_log_prob", ",", "z_log_prob", ",", "\n", "b_log_prob", ",", "b_prior_log_prob", ",", "reward", ",", "mask", ")", ":", "\n", "        ", "self", ".", "obs", "[", ":", ",", "self", ".", "step", "+", "1", "]", ".", "copy_", "(", "current_obs", ")", "\n", "self", ".", "z", "[", ":", ",", "self", ".", "step", "+", "1", "]", ".", "copy_", "(", "z", ")", "\n", "self", ".", "b", "[", ":", ",", "self", ".", "step", "]", ".", "copy_", "(", "b", ")", "\n", "self", ".", "actions", "[", ":", ",", "self", ".", "step", "]", ".", "copy_", "(", "action", ")", "\n", "\n", "self", ".", "value_preds", "[", ":", ",", "self", ".", "step", "]", ".", "copy_", "(", "value_pred", ")", "\n", "\n", "self", ".", "b_log_probs", "[", ":", ",", "self", ".", "step", "]", ".", "copy_", "(", "b_log_prob", ")", "\n", "self", ".", "b_prior_log_probs", "[", ":", ",", "self", ".", "step", "]", ".", "copy_", "(", "b_prior_log_prob", ")", "\n", "self", ".", "z_log_probs", "[", ":", ",", "self", ".", "step", "]", ".", "copy_", "(", "z_log_prob", ")", "\n", "# self.z_prior_log_probs[:, self.step].copy_(z_prior_log_prob)", "\n", "self", ".", "action_log_probs", "[", ":", ",", "self", ".", "step", "]", ".", "copy_", "(", "action_log_prob", ")", "\n", "self", ".", "action_prior_log_probs", "[", ":", ",", "self", ".", "step", "]", ".", "copy_", "(", "action_prior_log_prob", ")", "\n", "\n", "self", ".", "rewards", "[", ":", ",", "self", ".", "step", "]", ".", "copy_", "(", "reward", ")", "\n", "self", ".", "masks", "[", ":", ",", "self", ".", "step", "+", "1", "]", ".", "copy_", "(", "mask", ")", "\n", "\n", "self", ".", "step", "=", "(", "self", ".", "step", "+", "1", ")", "%", "self", ".", "num_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.after_update": [[86, 90], ["storage.RolloutStorage.obs[].copy_", "storage.RolloutStorage.masks[].copy_", "storage.RolloutStorage.z[].copy_"], "methods", ["None"], ["", "def", "after_update", "(", "self", ")", ":", "\n", "        ", "self", ".", "obs", "[", ":", ",", "0", "]", ".", "copy_", "(", "self", ".", "obs", "[", ":", ",", "-", "1", "]", ")", "\n", "self", ".", "masks", "[", ":", ",", "0", "]", ".", "copy_", "(", "self", ".", "masks", "[", ":", ",", "-", "1", "]", ")", "\n", "self", ".", "z", "[", ":", ",", "0", "]", ".", "copy_", "(", "self", ".", "z", "[", ":", ",", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.store_next_value": [[91, 93], ["None"], "methods", ["None"], ["", "def", "store_next_value", "(", "self", ",", "next_value_u", ")", ":", "\n", "        ", "self", ".", "next_value_u", "=", "next_value_u", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.get_reg_reward": [[94, 113], ["torch.tanh", "NotImplementedError"], "methods", ["None"], ["", "def", "get_reg_reward", "(", "self", ",", "step", ")", ":", "\n", "        ", "kl_b", "=", "self", ".", "b_prior_log_probs", "[", ":", ",", "step", "]", "-", "self", ".", "b_log_probs", "[", ":", ",", "step", "]", "\n", "\n", "if", "self", ".", "loss", "[", "'f_div_function'", "]", "==", "'tanh'", ":", "\n", "            ", "kl_b", "=", "torch", ".", "tanh", "(", "kl_b", ")", "\n", "", "elif", "self", ".", "loss", "[", "'f_div_function'", "]", "==", "'identity'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"loss['f_div_function'] '{}' not implemented\"", ".", "format", "(", "self", ".", "loss", "[", "'f_div_function'", "]", ")", ")", "\n", "\n", "", "reg_reward", "=", "(", "self", ".", "rewards", "[", ":", ",", "step", "]", "*", "self", ".", "loss", "[", "'c_r'", "]", "\n", "-", "self", ".", "z_log_probs", "[", ":", ",", "step", "]", "*", "(", "self", ".", "loss", "[", "'c_ent_z'", "]", ")", "\n", "# - self.b_log_probs[:, step] * (self.loss['c_kl_b'] + self.loss['c_ent_b'])", "\n", "-", "self", ".", "b_log_probs", "[", ":", ",", "step", "]", "*", "self", ".", "loss", "[", "'c_ent_b'", "]", "\n", "-", "self", ".", "action_log_probs", "[", ":", ",", "step", "]", "*", "(", "self", ".", "loss", "[", "'c_kl_a'", "]", "+", "self", ".", "loss", "[", "'c_ent_a'", "]", ")", "\n", "# + self.b_prior_log_probs[:,step] * self.loss['c_kl_b']", "\n", "+", "self", ".", "action_prior_log_probs", "[", ":", ",", "step", "]", "*", "self", ".", "loss", "[", "'c_kl_a'", "]", "\n", "+", "kl_b", "*", "self", ".", "loss", "[", "'c_kl_b'", "]", ")", "\n", "return", "reg_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.compute_returns": [[114, 137], ["reversed", "reversed", "range", "storage.RolloutStorage.get_reg_reward", "range", "storage.RolloutStorage.get_reg_reward", "storage.RolloutStorage.rewards.size", "storage.RolloutStorage.rewards.size"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.get_reg_reward", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.get_reg_reward"], ["", "def", "compute_returns", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Originally:\n        - Initialize with Bootstrap value\n        - R[t] = R[t+1] * gamma * mask[t+1] + r[t]\n\n        \"\"\"", "\n", "# Baseline should be the U of the _first_ z", "\n", "# next_value_u = U(s_{t+n}, z_{t+n-1})", "\n", "if", "self", ".", "loss", "[", "'use_gae'", "]", ":", "\n", "            ", "self", ".", "value_preds", "[", ":", ",", "-", "1", "]", "=", "self", ".", "next_value_u", "\n", "gae", "=", "0", "\n", "for", "step", "in", "reversed", "(", "range", "(", "self", ".", "rewards", ".", "size", "(", "1", ")", ")", ")", ":", "\n", "                ", "reg_reward", "=", "self", ".", "get_reg_reward", "(", "step", ")", "\n", "delta", "=", "reg_reward", "+", "self", ".", "loss", "[", "'gamma'", "]", "*", "self", ".", "value_preds", "[", ":", ",", "step", "+", "1", "]", "*", "self", ".", "masks", "[", ":", ",", "step", "+", "1", "]", "-", "self", ".", "value_preds", "[", ":", ",", "step", "]", "\n", "gae", "=", "delta", "+", "self", ".", "loss", "[", "'gamma'", "]", "*", "self", ".", "loss", "[", "'tau'", "]", "*", "self", ".", "masks", "[", ":", ",", "step", "+", "1", "]", "*", "gae", "\n", "self", ".", "returns_z", "[", ":", ",", "step", "]", "=", "gae", "+", "self", ".", "value_preds", "[", ":", ",", "step", "]", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "returns_z", "[", ":", ",", "-", "1", "]", "=", "self", ".", "next_value_u", "\n", "for", "step", "in", "reversed", "(", "range", "(", "self", ".", "rewards", ".", "size", "(", "1", ")", ")", ")", ":", "\n", "                ", "reg_reward", "=", "self", ".", "get_reg_reward", "(", "step", ")", "\n", "self", ".", "returns_z", "[", ":", ",", "step", "]", "=", "(", "\n", "self", ".", "returns_z", "[", ":", ",", "step", "+", "1", "]", "*", "self", ".", "loss", "[", "'gamma'", "]", "*", "self", ".", "masks", "[", ":", ",", "step", "+", "1", "]", "+", "reg_reward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.feed_forward_generator": [[138, 191], ["torch.utils.data.sampler.BatchSampler", "storage.RolloutStorage.rewards.size", "torch.utils.data.sampler.SubsetRandomSampler", "range", "storage.RolloutStorage.obs[].view", "storage.RolloutStorage.value_preds[].view", "storage.RolloutStorage.returns_z[].view", "storage.RolloutStorage.masks[].view", "storage.RolloutStorage.actions.view", "storage.RolloutStorage.z[].view", "storage.RolloutStorage.z[].view", "storage.RolloutStorage.b.view", "old_action_log_probs.view", "old_z_log_probs.view", "old_b_log_probs.view", "advantages.view", "advantages.mean", "advantages.std", "storage.RolloutStorage.actions.size", "storage.RolloutStorage.obs.size"], "methods", ["None"], ["", "", "", "def", "feed_forward_generator", "(", "self", ",", "\n", "old_action_log_probs", ",", "\n", "old_z_log_probs", ",", "\n", "old_b_log_probs", ",", "\n", "values_u", ",", "\n", "num_mini_batch", ")", ":", "\n", "        ", "\"\"\" Used for PPO\"\"\"", "\n", "num_tasks", ",", "num_steps", ",", "num_processes", "=", "self", ".", "rewards", ".", "size", "(", ")", "[", "0", ":", "3", "]", "\n", "batch_size", "=", "num_processes", "*", "num_steps", "\n", "\n", "# self.returns_z should have been updated", "\n", "advantages", "=", "self", ".", "returns_z", "[", ":", ",", ":", "-", "1", "]", "-", "values_u", "\n", "if", "self", ".", "loss", "[", "'normalize_advt'", "]", ":", "\n", "            ", "advantages", "=", "(", "advantages", "-", "advantages", ".", "mean", "(", ")", ")", "/", "(", "advantages", ".", "std", "(", ")", "+", "1e-5", ")", "\n", "\n", "", "assert", "batch_size", ">=", "num_mini_batch", ",", "(", "\n", "\"PPO requires the number of processes ({}) \"", "\n", "\"* number of steps ({}) = {} \"", "\n", "\"to be greater than or equal to the number of PPO mini batches ({}).\"", "\n", "\"\"", ".", "format", "(", "num_processes", ",", "num_steps", ",", "num_processes", "*", "num_steps", ",", "num_mini_batch", ")", ")", "\n", "\n", "mini_batch_size", "=", "batch_size", "//", "num_mini_batch", "\n", "assert", "mini_batch_size", ">", "1", ",", "\"Mini batch size less than or equal to 1 will completely break things\"", "\n", "\n", "sampler", "=", "BatchSampler", "(", "SubsetRandomSampler", "(", "range", "(", "batch_size", ")", ")", ",", "mini_batch_size", ",", "drop_last", "=", "False", ")", "\n", "\n", "for", "indices", "in", "sampler", ":", "\n", "# Standard stuff to return", "\n", "            ", "obs_batch", "=", "self", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "self", ".", "obs", ".", "size", "(", ")", "[", "3", ":", "]", ")", "[", ":", ",", "indices", "]", "\n", "value_preds_batch", "=", "self", ".", "value_preds", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", "[", ":", ",", "indices", "]", "\n", "returns_z_batch", "=", "self", ".", "returns_z", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", "[", ":", ",", "indices", "]", "\n", "masks_batch", "=", "self", ".", "masks", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", "[", ":", ",", "indices", "]", "\n", "\n", "# Policy choices", "\n", "actions_batch", "=", "self", ".", "actions", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "self", ".", "actions", ".", "size", "(", "-", "1", ")", ")", "[", ":", ",", "indices", "]", "\n", "z_batch_minus_one", "=", "self", ".", "z", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", "[", ":", ",", "indices", "]", "\n", "z_batch_plus_one", "=", "self", ".", "z", "[", ":", ",", "1", ":", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", "[", ":", ",", "indices", "]", "\n", "b_batch", "=", "self", ".", "b", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", "[", ":", ",", "indices", "]", "\n", "\n", "# Select old policy probabilities", "\n", "# We need to use the passed in ones because the ones in storage will change:", "\n", "# They are updated to compute new returns", "\n", "old_action_log_probs_batch", "=", "old_action_log_probs", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", "[", ":", ",", "indices", "]", "\n", "old_z_log_probs_batch", "=", "old_z_log_probs", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", "[", ":", ",", "indices", "]", "\n", "old_b_log_probs_batch", "=", "old_b_log_probs", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", "[", ":", ",", "indices", "]", "\n", "\n", "# Updated advantages", "\n", "adv_targ", "=", "advantages", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", "[", ":", ",", "indices", "]", "\n", "\n", "yield", "(", "obs_batch", ",", "value_preds_batch", ",", "returns_z_batch", ",", "masks_batch", ",", "\n", "actions_batch", ",", "z_batch_minus_one", ",", "z_batch_plus_one", ",", "b_batch", ",", "\n", "old_action_log_probs_batch", ",", "old_z_log_probs_batch", ",", "old_b_log_probs_batch", ",", "\n", "adv_targ", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.update_ppo_epoch": [[192, 239], ["storage.RolloutStorage.actions.size", "storage.RolloutStorage.b_log_probs.copy_", "storage.RolloutStorage.z_log_probs.copy_", "storage.RolloutStorage.action_log_probs.copy_", "storage.RolloutStorage.b_prior_log_probs.copy_", "storage.RolloutStorage.action_prior_log_probs.copy_", "storage.RolloutStorage.compute_returns", "storage.RolloutStorage.rewards.size", "storage.RolloutStorage.obs.size", "torch.no_grad", "hierarchical_actor_critic.evaluatePolicy", "hierarchical_actor_critic.evaluatePolicy", "hierarchical_actor_critic.evaluatePolicy", "hierarchical_actor_critic.evaluatePrior", "hierarchical_actor_critic.evaluatePrior", "b_log_probs.view", "z_log_probs.view", "action_log_probs.view", "hierarchical_actor_critic.evaluatePrior.view", "hierarchical_actor_critic.evaluatePrior.view", "storage.RolloutStorage.obs[].view", "storage.RolloutStorage.z[].view", "storage.RolloutStorage.b.view", "storage.RolloutStorage.masks[].view", "storage.RolloutStorage.obs[].view", "storage.RolloutStorage.b.view", "storage.RolloutStorage.z[].view", "storage.RolloutStorage.obs[].view", "storage.RolloutStorage.z[].view", "storage.RolloutStorage.actions.view", "storage.RolloutStorage.obs[].view", "storage.RolloutStorage.z[].view", "storage.RolloutStorage.b.view", "storage.RolloutStorage.masks[].view", "storage.RolloutStorage.obs[].view", "storage.RolloutStorage.z[].view", "storage.RolloutStorage.actions.view"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.compute_returns", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePolicy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePolicy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePolicy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePrior", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePrior"], ["", "", "def", "update_ppo_epoch", "(", "self", ",", "hierarchical_actor_critic", ")", ":", "\n", "        ", "num_tasks", ",", "num_steps", ",", "num_processes", "=", "self", ".", "rewards", ".", "size", "(", ")", "[", "0", ":", "3", "]", "\n", "obs_shape", "=", "self", ".", "obs", ".", "size", "(", ")", "[", "3", ":", "]", "\n", "action_shape", "=", "self", ".", "actions", ".", "size", "(", "-", "1", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "b_log_probs", ",", "entropy_b", "=", "hierarchical_actor_critic", ".", "evaluatePolicy", "(", "\n", "obs", "=", "self", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "obs_shape", ")", ",", "\n", "z", "=", "self", ".", "z", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "action", "=", "self", ".", "b", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "policy_type", "=", "\"termination\"", ",", "\n", "masks", "=", "self", ".", "masks", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ")", "\n", "\n", "z_log_probs", ",", "entropy_z", "=", "hierarchical_actor_critic", ".", "evaluatePolicy", "(", "\n", "obs", "=", "self", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "obs_shape", ")", ",", "\n", "b", "=", "self", ".", "b", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "action", "=", "self", ".", "z", "[", ":", ",", "1", ":", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "policy_type", "=", "\"master\"", ")", "\n", "\n", "action_log_probs", ",", "entropy_a", "=", "hierarchical_actor_critic", ".", "evaluatePolicy", "(", "\n", "obs", "=", "self", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "obs_shape", ")", ",", "\n", "z", "=", "self", ".", "z", "[", ":", ",", "1", ":", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "action", "=", "self", ".", "actions", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "action_shape", ")", ",", "\n", "policy_type", "=", "\"option\"", ")", "\n", "\n", "# Evaluate Priors", "\n", "b_prior_log_prob", "=", "hierarchical_actor_critic", ".", "evaluatePrior", "(", "\n", "obs", "=", "self", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "obs_shape", ")", ",", "\n", "z", "=", "self", ".", "z", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "action", "=", "self", ".", "b", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "policy_type", "=", "\"termination\"", ",", "\n", "masks", "=", "self", ".", "masks", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ")", "\n", "\n", "action_prior_log_prob", "=", "hierarchical_actor_critic", ".", "evaluatePrior", "(", "\n", "obs", "=", "self", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "obs_shape", ")", ",", "\n", "z", "=", "self", ".", "z", "[", ":", ",", "1", ":", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "action", "=", "self", ".", "actions", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "action_shape", ")", ",", "\n", "policy_type", "=", "\"option\"", ")", "\n", "\n", "# Copying to make sure dimensions are the same", "\n", "", "self", ".", "b_log_probs", ".", "copy_", "(", "b_log_probs", ".", "view", "(", "num_tasks", ",", "num_steps", ",", "num_processes", ",", "1", ")", ")", "\n", "self", ".", "z_log_probs", ".", "copy_", "(", "z_log_probs", ".", "view", "(", "num_tasks", ",", "num_steps", ",", "num_processes", ",", "1", ")", ")", "\n", "self", ".", "action_log_probs", ".", "copy_", "(", "action_log_probs", ".", "view", "(", "num_tasks", ",", "num_steps", ",", "num_processes", ",", "1", ")", ")", "\n", "self", ".", "b_prior_log_probs", ".", "copy_", "(", "b_prior_log_prob", ".", "view", "(", "num_tasks", ",", "num_steps", ",", "num_processes", ",", "1", ")", ")", "\n", "self", ".", "action_prior_log_probs", ".", "copy_", "(", "action_prior_log_prob", ".", "view", "(", "num_tasks", ",", "num_steps", ",", "num_processes", ",", "1", ")", ")", "\n", "\n", "self", ".", "compute_returns", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.AddBias.__init__": [[10, 13], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "bias.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.__init__"], ["    ", "def", "__init__", "(", "self", ",", "bias", ")", ":", "\n", "        ", "super", "(", "AddBias", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_bias", "=", "nn", ".", "Parameter", "(", "bias", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.AddBias.forward": [[14, 21], ["x.dim", "utils.AddBias._bias.t().view", "utils.AddBias._bias.t().view", "utils.AddBias._bias.t", "utils.AddBias._bias.t"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "x", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "bias", "=", "self", ".", "_bias", ".", "t", "(", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "bias", "=", "self", ".", "_bias", ".", "t", "(", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "", "return", "x", "+", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.update_linear_schedule": [[23, 28], ["float"], "function", ["None"], ["", "", "def", "update_linear_schedule", "(", "optimizer", ",", "epoch", ",", "total_num_epochs", ",", "initial_lr", ")", ":", "\n", "    ", "\"\"\"Decreases the learning rate linearly\"\"\"", "\n", "lr", "=", "initial_lr", "-", "(", "initial_lr", "*", "(", "epoch", "/", "float", "(", "total_num_epochs", ")", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.init": [[30, 34], ["weight_init", "bias_init"], "function", ["None"], ["", "", "def", "init", "(", "module", ",", "weight_init", ",", "bias_init", ",", "gain", "=", "1", ")", ":", "\n", "    ", "weight_init", "(", "module", ".", "weight", ".", "data", ",", "gain", "=", "gain", ")", "\n", "bias_init", "(", "module", ".", "bias", ".", "data", ")", "\n", "return", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.init_normc_": [[38, 41], ["weight.normal_", "torch.sqrt", "torch.sqrt", "weight.pow().sum", "weight.pow"], "function", ["None"], ["", "def", "init_normc_", "(", "weight", ",", "gain", "=", "1", ")", ":", "\n", "    ", "weight", ".", "normal_", "(", "0", ",", "1", ")", "\n", "weight", "*=", "gain", "/", "torch", ".", "sqrt", "(", "weight", ".", "pow", "(", "2", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.update_current_obs": [[43, 60], ["torch.from_numpy().float", "torch.from_numpy().float", "numpy.reshape", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["", "def", "update_current_obs", "(", "obs", ",", "current_obs", ",", "obs_shape", ",", "num_stack", ",", "num_tasks", ",", "num_processes_per_task", ")", ":", "\n", "    ", "shape_dim0", "=", "obs_shape", "[", "0", "]", "//", "num_stack", "\n", "obs", "=", "torch", ".", "from_numpy", "(", "obs", ")", ".", "float", "(", ")", "\n", "if", "num_stack", ">", "1", ":", "\n", "        ", "current_obs", "[", ":", ",", ":", ",", ":", "-", "shape_dim0", "]", "=", "current_obs", "[", ":", ",", ":", ",", "shape_dim0", ":", "]", "\n", "# It should be ok to just reshape it because we only use obs in this function", "\n", "", "obs", "=", "np", ".", "reshape", "(", "obs", ",", "(", "num_tasks", ",", "num_processes_per_task", ",", "\n", "shape_dim0", ",", "*", "obs_shape", "[", "1", ":", "]", ")", ")", "\n", "current_obs", "[", ":", ",", ":", ",", "-", "shape_dim0", ":", "]", "=", "obs", "\n", "\"\"\"\n    # Leave this here for debugging to make sure vectorized ops do what we expect\n    right_way = np.reshape(obs, (num_tasks, num_processes_per_task, 1, *obs_shape[1:]))\n    wrong_way = np.zeros((num_tasks, num_processes_per_task, *obs_shape[1:]))\n    for task in range(2):\n        wrong_way[task] = obs[task*num_processes_per_task:(task+1)*num_processes_per_task]\n    print(np.array_equal(right_way, wrong_way))\n    \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.utils.getOutputDimension": [[62, 64], ["None"], "function", ["None"], ["", "def", "getOutputDimension", "(", "dimension", ",", "k_size", ",", "padding", ",", "stride", ")", ":", "\n", "    ", "return", "(", "dimension", "-", "k_size", "+", "2", "*", "padding", ")", "//", "stride", "+", "1", "\n", "", ""]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.movement_bandits.MovementBandits.__init__": [[21, 41], ["gym.spaces.Discrete", "numpy.random.randint", "movement_bandits.MovementBandits._seed", "movement_bandits.MovementBandits._reset", "movement_bandits.MovementBandits._configure", "gym.spaces.Box", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.movement_bandits.MovementBandits._seed", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.movement_bandits.MovementBandits._reset", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.movement_bandits.MovementBandits._configure"], ["def", "__init__", "(", "self", ",", "add_action_in_obs", "=", "False", ")", ":", "\n", "# new action space = [left, right]", "\n", "        ", "self", ".", "action_space", "=", "spaces", ".", "Discrete", "(", "5", ")", "\n", "\n", "if", "add_action_in_obs", ":", "\n", "            ", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "-", "10000000", ",", "10000000", ",", "shape", "=", "(", "7", ",", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "-", "10000000", ",", "10000000", ",", "shape", "=", "(", "6", ",", ")", ")", "\n", "", "self", ".", "add_action_in_obs", "=", "add_action_in_obs", "\n", "\n", "self", ".", "realgoal", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ")", "\n", "\n", "self", ".", "_seed", "(", ")", "\n", "self", ".", "viewer", "=", "None", "\n", "self", ".", "_reset", "(", ")", "\n", "\n", "self", ".", "steps_beyond_done", "=", "None", "\n", "\n", "# Just need to initialize the relevant attributes", "\n", "self", ".", "_configure", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.movement_bandits.MovementBandits.draw_and_set_task": [[46, 64], ["gym.utils.seeding.np_random", "int", "movement_bandits.MovementBandits.np_random.randint", "_rnd.choice"], "methods", ["None"], ["", "def", "draw_and_set_task", "(", "self", ",", "constraint", "=", "None", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Draw a new task and set the environment to that task.\n\n        Args:\n            seed: Random seed that is used to generate task\n            contraint:  Should be e.g. \"B-Y\"\n        \"\"\"", "\n", "if", "seed", "is", "None", ":", "\n", "            ", "seed", "=", "self", ".", "np_random", ".", "randint", "(", "9223372036854775807", ")", "\n", "\n", "", "_rnd", ",", "seed1", "=", "seeding", ".", "np_random", "(", "seed", ")", "\n", "if", "constraint", "is", "None", ":", "\n", "            ", "constraint", "=", "_rnd", ".", "choice", "(", "[", "0", ",", "1", "]", ")", "\n", "# constraint should be either 0 or 1", "\n", "", "self", ".", "realgoal", "=", "int", "(", "constraint", ")", "\n", "\n", "return", "seed1", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.movement_bandits.MovementBandits._configure": [[65, 67], ["None"], "methods", ["None"], ["", "def", "_configure", "(", "self", ",", "display", "=", "None", ")", ":", "\n", "        ", "self", ".", "display", "=", "display", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.movement_bandits.MovementBandits._seed": [[68, 72], ["gym.utils.seeding.np_random", "print"], "methods", ["None"], ["", "def", "_seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "self", ".", "np_random", ",", "seed", "=", "seeding", ".", "np_random", "(", "seed", ")", "\n", "print", "(", "\"seeded\"", ")", "\n", "return", "[", "seed", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.movement_bandits.MovementBandits._step": [[73, 93], ["numpy.mean", "movement_bandits.MovementBandits.obs", "abs", "abs"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.movement_bandits.MovementBandits.obs"], ["", "def", "_step", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "action", "==", "1", ":", "\n", "            ", "self", ".", "state", "[", "0", "]", "+=", "20", "\n", "", "if", "action", "==", "2", ":", "\n", "            ", "self", ".", "state", "[", "0", "]", "-=", "20", "\n", "", "if", "action", "==", "3", ":", "\n", "            ", "self", ".", "state", "[", "1", "]", "+=", "20", "\n", "", "if", "action", "==", "4", ":", "\n", "            ", "self", ".", "state", "[", "1", "]", "-=", "20", "\n", "\n", "\n", "", "distance", "=", "np", ".", "mean", "(", "abs", "(", "self", ".", "state", "[", "0", "]", "-", "self", ".", "goals", "[", "self", ".", "realgoal", "]", "[", "0", "]", ")", "**", "2", "+", "abs", "(", "self", ".", "state", "[", "1", "]", "-", "self", ".", "goals", "[", "self", ".", "realgoal", "]", "[", "1", "]", ")", "**", "2", ")", "\n", "# reward = -distance / 5000", "\n", "# print(distance)", "\n", "if", "distance", "<", "2500", ":", "\n", "            ", "reward", "=", "1", "\n", "", "else", ":", "\n", "            ", "reward", "=", "0", "\n", "\n", "", "return", "self", ".", "obs", "(", "action", ")", ",", "reward", ",", "False", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.movement_bandits.MovementBandits.obs": [[94, 99], ["numpy.reshape", "numpy.concatenate", "numpy.array"], "methods", ["None"], ["", "def", "obs", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", "=", "np", ".", "reshape", "(", "np", ".", "array", "(", "[", "self", ".", "state", "]", "+", "self", ".", "goals", ")", ",", "(", "-", "1", ",", ")", ")", "/", "400", "\n", "if", "self", ".", "add_action_in_obs", ":", "\n", "            ", "obs", "=", "np", ".", "concatenate", "(", "[", "obs", ",", "[", "action", "]", "]", ")", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.movement_bandits.MovementBandits._reset": [[100, 111], ["range", "movement_bandits.MovementBandits.obs", "movement_bandits.MovementBandits.goals.append", "movement_bandits.MovementBandits.np_random.uniform"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.movement_bandits.MovementBandits.obs"], ["", "def", "_reset", "(", "self", ")", ":", "\n", "# self.randomizeCorrect()", "\n", "        ", "self", ".", "state", "=", "[", "200.0", ",", "200.0", "]", "\n", "self", ".", "goals", "=", "[", "]", "\n", "for", "x", "in", "range", "(", "2", ")", ":", "\n", "            ", "self", ".", "goals", ".", "append", "(", "self", ".", "np_random", ".", "uniform", "(", "0", ",", "400", ",", "size", "=", "(", "2", ",", ")", ")", ")", "\n", "# self.goals.append(np.array([300, 200]))", "\n", "\n", "# self.goals.append(np.array([300, 300]))", "\n", "# self.goals.append(np.array([100, 100]))", "\n", "", "return", "self", ".", "obs", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.movement_bandits.MovementBandits._render": [[112, 146], ["movement_bandits.MovementBandits.man_trans.set_translation", "range", "movement_bandits.MovementBandits.viewer.render", "rendering.Viewer", "rendering.Transform", "rendering.make_circle", "movement_bandits.MovementBandits.man.add_attr", "movement_bandits.MovementBandits.man.set_color", "movement_bandits.MovementBandits.viewer.add_geom", "range", "len", "movement_bandits.MovementBandits.goal_trans[].set_translation", "movement_bandits.MovementBandits.viewer.close", "len", "movement_bandits.MovementBandits.goal_trans.append", "rendering.make_circle", "movement_bandits.MovementBandits.goal.add_attr", "movement_bandits.MovementBandits.viewer.add_geom", "movement_bandits.MovementBandits.goal.set_color", "rendering.Transform"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.render", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.multitask_vec_normalize.MTVecEnvWrapper.close"], ["", "def", "_render", "(", "self", ",", "mode", "=", "'human'", ",", "close", "=", "False", ")", ":", "\n", "        ", "if", "close", ":", "\n", "            ", "if", "self", ".", "viewer", "is", "not", "None", ":", "\n", "                ", "self", ".", "viewer", ".", "close", "(", ")", "\n", "self", ".", "viewer", "=", "None", "\n", "", "return", "\n", "\n", "", "screen_width", "=", "400", "\n", "screen_height", "=", "400", "\n", "\n", "\n", "if", "self", ".", "viewer", "is", "None", ":", "\n", "            ", "from", "gym", ".", "envs", ".", "classic_control", "import", "rendering", "\n", "self", ".", "viewer", "=", "rendering", ".", "Viewer", "(", "screen_width", ",", "screen_height", ",", "display", "=", "self", ".", "display", ")", "\n", "self", ".", "man_trans", "=", "rendering", ".", "Transform", "(", ")", "\n", "self", ".", "man", "=", "rendering", ".", "make_circle", "(", "10", ")", "\n", "self", ".", "man", ".", "add_attr", "(", "self", ".", "man_trans", ")", "\n", "self", ".", "man", ".", "set_color", "(", ".5", ",", ".8", ",", ".5", ")", "\n", "self", ".", "viewer", ".", "add_geom", "(", "self", ".", "man", ")", "\n", "\n", "self", ".", "goal_trans", "=", "[", "]", "\n", "for", "g", "in", "range", "(", "len", "(", "self", ".", "goals", ")", ")", ":", "\n", "                ", "self", ".", "goal_trans", ".", "append", "(", "rendering", ".", "Transform", "(", ")", ")", "\n", "self", ".", "goal", "=", "rendering", ".", "make_circle", "(", "20", ")", "\n", "self", ".", "goal", ".", "add_attr", "(", "self", ".", "goal_trans", "[", "g", "]", ")", "\n", "self", ".", "viewer", ".", "add_geom", "(", "self", ".", "goal", ")", "\n", "self", ".", "goal", ".", "set_color", "(", ".5", ",", ".5", ",", "g", "*", "0.8", ")", "\n", "\n", "\n", "", "", "self", ".", "man_trans", ".", "set_translation", "(", "self", ".", "state", "[", "0", "]", ",", "self", ".", "state", "[", "1", "]", ")", "\n", "for", "g", "in", "range", "(", "len", "(", "self", ".", "goals", ")", ")", ":", "\n", "            ", "self", ".", "goal_trans", "[", "g", "]", ".", "set_translation", "(", "self", ".", "goals", "[", "g", "]", "[", "0", "]", ",", "self", ".", "goals", "[", "g", "]", "[", "1", "]", ")", "\n", "\n", "", "return", "self", ".", "viewer", ".", "render", "(", "return_rgb_array", "=", "mode", "==", "'rgb_array'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi.Taxi.__init__": [[62, 108], ["taxi.Taxi.seed", "gym.spaces.Discrete", "gym.spaces.Discrete", "taxi.Taxi.draw_and_set_task", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.seed", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.draw_and_set_task"], ["def", "__init__", "(", "self", ",", "\n", "add_action_in_obs", "=", "False", ",", "\n", "reward_wrong_movement", "=", "-", "0.1", ",", "\n", "image_obs", "=", "True", ",", "\n", "start_everywhere", "=", "False", ")", ":", "\n", "        ", "self", ".", "viewer", "=", "None", "\n", "self", ".", "seed", "(", ")", "\n", "self", ".", "walkable", "=", "TAXI_ROOMS_LAYOUT", "\n", "self", ".", "image_obs", "=", "image_obs", "\n", "self", ".", "start_everywhere", "=", "start_everywhere", "\n", "\n", "self", ".", "actions", "=", "ACTIONS", "\n", "if", "self", ".", "image_obs", ":", "\n", "            ", "num_layers", "=", "3", "if", "add_action_in_obs", "else", "2", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "\n", "low", "=", "0", ",", "high", "=", "255", ",", "\n", "shape", "=", "(", "self", ".", "walkable", ".", "shape", "[", "0", "]", ",", "self", ".", "walkable", ".", "shape", "[", "1", "]", ",", "num_layers", ")", ",", "\n", "dtype", "=", "np", ".", "uint8", ")", "\n", "", "else", ":", "\n", "# Position, passenger?, (last action)", "\n", "            ", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "\n", "low", "=", "0.", ",", "high", "=", "1.", ",", "\n", "shape", "=", "(", "73", "if", "add_action_in_obs", "else", "72", ",", ")", "\n", ")", "\n", "\n", "", "self", ".", "action_space", "=", "spaces", ".", "Discrete", "(", "6", ")", "\n", "\n", "self", ".", "state", "=", "{", "\n", "'loc'", ":", "(", "0", ",", "0", ")", ",", "\n", "# If passenger is in taxi, set to None", "\n", "'pas'", ":", "False", "\n", "}", "\n", "\n", "self", ".", "task", "=", "{", "\n", "'pic'", ":", "np", ".", "array", "(", "[", "0", ",", "0", "]", ")", ",", "\n", "'gol'", ":", "np", ".", "array", "(", "[", "0", ",", "0", "]", ")", "\n", "}", "\n", "\n", "self", ".", "done", "=", "True", "\n", "\n", "self", ".", "draw_and_set_task", "(", ")", "\n", "\n", "self", ".", "add_action_in_obs", "=", "add_action_in_obs", "\n", "self", ".", "reward_goal_found", "=", "2", "\n", "self", ".", "reward_per_timestep", "=", "-", "0.1", "\n", "self", ".", "reward_wrong_movement", "=", "reward_wrong_movement", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi.Taxi.draw_and_set_task": [[109, 152], ["gym.utils.seeding.np_random", "gym.utils.seeding.np_random", "constraint.split.split.split", "numpy.where", "isinstance", "taxi.Taxi.np_random.randint", "len", "LOCATIONS.values", "_rnd.choice", "_rnd.choice", "len", "NotImplementedError", "range", "taxi.Taxi.possible_loc_states.remove", "len", "tuple"], "methods", ["None"], ["", "def", "draw_and_set_task", "(", "self", ",", "constraint", "=", "None", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Draw a new task and set the environment to that task.\n\n        Args:\n            seed: Random seed that is used to generate task\n            contraint:  Should be e.g. \"B-Y\"\n        \"\"\"", "\n", "\n", "assert", "(", "constraint", "is", "None", "or", "isinstance", "(", "constraint", ",", "str", ")", ")", "\n", "\n", "# Not needed here", "\n", "if", "seed", "is", "None", ":", "\n", "            ", "seed", "=", "self", ".", "np_random", ".", "randint", "(", "9223372036854775807", ")", "\n", "\n", "", "_rnd", ",", "seed1", "=", "seeding", ".", "np_random", "(", "seed", ")", "\n", "if", "constraint", "is", "None", ":", "\n", "            ", "constraint", "=", "\"{}-{}\"", ".", "format", "(", "\n", "_rnd", ".", "choice", "(", "[", "'R'", ",", "'G'", ",", "'Y'", ",", "'B'", "]", ")", ",", "\n", "_rnd", ".", "choice", "(", "[", "'R'", ",", "'G'", ",", "'Y'", ",", "'B'", "]", ")", "\n", ")", "\n", "\n", "# constraint should be of the ", "\n", "", "constraint", "=", "constraint", ".", "split", "(", "'-'", ")", "\n", "assert", "len", "(", "constraint", ")", "in", "[", "2", ",", "3", "]", "\n", "\n", "if", "len", "(", "constraint", ")", "==", "2", "or", "constraint", "[", "2", "]", "==", "'easy'", ":", "\n", "            ", "self", ".", "possible_pas_states", "=", "[", "True", ",", "False", "]", "\n", "", "elif", "constraint", "[", "2", "]", "==", "'hard'", ":", "\n", "            ", "self", ".", "possible_pas_states", "=", "[", "False", "]", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"{} no a valid modifier\"", ".", "format", "(", "constraint", "[", "2", "]", ")", ")", "\n", "", "X", ",", "Y", "=", "np", ".", "where", "(", "self", ".", "walkable", "==", "1", ")", "\n", "self", ".", "possible_loc_states", "=", "[", "(", "X", "[", "i", "]", ",", "Y", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "X", ")", ")", "]", "\n", "if", "not", "self", ".", "start_everywhere", ":", "\n", "            ", "for", "loc", "in", "LOCATIONS", ".", "values", "(", ")", ":", "\n", "                ", "self", ".", "possible_loc_states", ".", "remove", "(", "tuple", "(", "loc", ")", ")", "\n", "\n", "# Set pickup and dropoff location", "\n", "", "", "self", ".", "task", "[", "'pic'", "]", "=", "LOCATIONS", "[", "constraint", "[", "0", "]", "]", "\n", "self", ".", "task", "[", "'gol'", "]", "=", "LOCATIONS", "[", "constraint", "[", "1", "]", "]", "\n", "\n", "return", "seed1", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi.Taxi.seed": [[153, 159], ["gym.utils.seeding.np_random", "gym.utils.seeding.np_random"], "methods", ["None"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Seed must be a non-negative \n        \"\"\"", "\n", "self", ".", "np_random", ",", "seed1", "=", "seeding", ".", "np_random", "(", "seed", ")", "\n", "return", "[", "seed1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi.Taxi.reset": [[160, 167], ["taxi.Taxi.np_random.choice", "taxi.Taxi.create_observation", "taxi.Taxi.np_random.choice", "len"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.create_observation"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "done", "=", "False", "\n", "# self.state['pas'] = np.random.choice([True, False])", "\n", "self", ".", "state", "[", "'pas'", "]", "=", "self", ".", "np_random", ".", "choice", "(", "self", ".", "possible_pas_states", ")", "\n", "self", ".", "state", "[", "'loc'", "]", "=", "self", ".", "possible_loc_states", "[", "self", ".", "np_random", ".", "choice", "(", "len", "(", "self", ".", "possible_loc_states", ")", ")", "]", "\n", "\n", "return", "self", ".", "create_observation", "(", "action", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi.Taxi.step": [[168, 198], ["taxi.Taxi.create_observation", "Exception", "taxi.Taxi.check_inside_area", "taxi.Taxi.check_walkable", "taxi.Taxi.check_pickup_possible", "taxi.Taxi.check_dropoff_possible"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.create_observation", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.check_inside_area", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.check_walkable", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.check_pickup_possible", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.check_dropoff_possible"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "self", ".", "done", ":", "\n", "            ", "raise", "Exception", "(", "\"Environment must be reset\"", ")", "\n", "\n", "# No-op (0) or movement (1-4)", "\n", "", "if", "action", "<", "5", ":", "\n", "            ", "mov", "=", "self", ".", "actions", "[", "action", "]", "\n", "loc", "=", "self", ".", "state", "[", "'loc'", "]", "\n", "new_loc", "=", "loc", "+", "mov", "\n", "\n", "if", "(", "self", ".", "check_inside_area", "(", "new_loc", ")", "and", "self", ".", "check_walkable", "(", "new_loc", ")", ")", ":", "\n", "                ", "reward", "=", "self", ".", "reward_per_timestep", "\n", "", "else", ":", "\n", "                ", "reward", "=", "self", ".", "reward_wrong_movement", "\n", "new_loc", "=", "loc", "\n", "", "self", ".", "state", "[", "'loc'", "]", "=", "new_loc", "\n", "\n", "# Pickup", "\n", "", "elif", "action", "==", "5", ":", "\n", "            ", "if", "self", ".", "check_pickup_possible", "(", ")", ":", "\n", "                ", "self", ".", "state", "[", "'pas'", "]", "=", "True", "\n", "reward", "=", "self", ".", "reward_per_timestep", "\n", "", "elif", "self", ".", "check_dropoff_possible", "(", ")", ":", "\n", "                ", "self", ".", "done", "=", "True", "\n", "reward", "=", "self", ".", "reward_goal_found", "\n", "", "else", ":", "\n", "                ", "reward", "=", "self", ".", "reward_wrong_movement", "\n", "\n", "", "", "obs", "=", "self", ".", "create_observation", "(", "action", "=", "action", ")", "\n", "return", "obs", ",", "reward", ",", "self", ".", "done", ",", "{", "'state'", ":", "self", ".", "state", ",", "'task'", ":", "self", ".", "task", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi.Taxi.create_observation": [[199, 231], ["numpy.expand_dims", "numpy.full_like", "numpy.concatenate", "numpy.zeros", "int", "numpy.concatenate", "numpy.copy", "tuple", "numpy.full_like", "numpy.array"], "methods", ["None"], ["", "def", "create_observation", "(", "self", ",", "action", ",", "loc", "=", "None", ",", "layout", "=", "None", ")", ":", "\n", "        ", "if", "loc", "is", "None", ":", "\n", "            ", "loc", "=", "self", ".", "state", "[", "'loc'", "]", "\n", "", "if", "layout", "is", "None", ":", "\n", "            ", "layout", "=", "self", ".", "walkable", "\n", "\n", "", "if", "self", ".", "image_obs", ":", "\n", "            ", "obs", "=", "(", "1", "-", "np", ".", "copy", "(", "layout", ")", ")", "*", "255", "\n", "obs", "=", "np", ".", "expand_dims", "(", "obs", ",", "2", ")", "\n", "obs", "[", "tuple", "(", "loc", ")", "]", "=", "125", "\n", "\n", "# All ones if picked up, otherwise all 0", "\n", "passenger_obs", "=", "np", ".", "full_like", "(", "obs", ",", "int", "(", "self", ".", "state", "[", "'pas'", "]", ")", ")", "\n", "layers", "=", "[", "obs", ",", "passenger_obs", "]", "\n", "\n", "if", "self", ".", "add_action_in_obs", ":", "\n", "# Add additional channelfor last action", "\n", "                ", "layers", "+=", "[", "np", ".", "full_like", "(", "obs", ",", "action", ")", "]", "\n", "# last_action_channel = np.full_like(obs, action)", "\n", "# obs = np.concatenate([obs, last_action_channel], axis=2)", "\n", "", "obs", "=", "np", ".", "concatenate", "(", "layers", ",", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "            ", "obs", "=", "np", ".", "zeros", "(", "72", ")", "\n", "# Remove wall from state", "\n", "x", "=", "loc", "[", "0", "]", "-", "1", "\n", "y", "=", "loc", "[", "1", "]", "-", "1", "\n", "idx", "=", "self", ".", "state", "[", "'pas'", "]", "*", "36", "+", "y", "*", "6", "+", "x", "\n", "obs", "[", "idx", "]", "=", "1", "\n", "if", "self", ".", "add_action_in_obs", ":", "\n", "                ", "obs", "=", "np", ".", "concatenate", "(", "[", "obs", ",", "np", ".", "array", "(", "[", "action", "]", ")", "]", ")", "\n", "\n", "", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi.Taxi.check_pickup_possible": [[232, 234], ["numpy.all"], "methods", ["None"], ["", "def", "check_pickup_possible", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "all", "(", "self", ".", "state", "[", "'loc'", "]", "==", "self", ".", "task", "[", "'pic'", "]", ")", "and", "not", "self", ".", "state", "[", "'pas'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi.Taxi.check_dropoff_possible": [[235, 237], ["numpy.all"], "methods", ["None"], ["", "def", "check_dropoff_possible", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "all", "(", "self", ".", "state", "[", "'loc'", "]", "==", "self", ".", "task", "[", "'gol'", "]", ")", "and", "self", ".", "state", "[", "'pas'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi.Taxi.check_walkable": [[238, 240], ["tuple"], "methods", ["None"], ["", "def", "check_walkable", "(", "self", ",", "loc", ")", ":", "\n", "        ", "return", "self", ".", "walkable", "[", "tuple", "(", "loc", ")", "]", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi.Taxi.check_inside_area": [[241, 244], ["None"], "methods", ["None"], ["", "def", "check_inside_area", "(", "self", ",", "loc", ")", ":", "\n", "        ", "return", "(", "0", "<=", "loc", "[", "0", "]", "<", "self", ".", "walkable", ".", "shape", "[", "0", "]", "and", "\n", "0", "<=", "loc", "[", "1", "]", "<", "self", ".", "walkable", ".", "shape", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.__init__": [[59, 107], ["taxi2a.Taxi2A.seed", "gym.spaces.Discrete", "gym.spaces.Discrete", "taxi2a.Taxi2A.draw_and_set_task", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "gym.spaces.Box", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.seed", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.draw_and_set_task"], ["def", "__init__", "(", "self", ",", "\n", "add_action_in_obs", "=", "False", ",", "\n", "reward_wrong_movement", "=", "-", "0.1", ",", "\n", "image_obs", "=", "True", ",", "\n", "start_everywhere", "=", "False", ",", "\n", "scramble_prob", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "viewer", "=", "None", "\n", "self", ".", "seed", "(", ")", "\n", "self", ".", "walkable", "=", "TAXI_ROOMS_LAYOUT", "\n", "self", ".", "image_obs", "=", "image_obs", "\n", "self", ".", "start_everywhere", "=", "start_everywhere", "\n", "self", ".", "scramble_prob", "=", "scramble_prob", "\n", "\n", "if", "self", ".", "image_obs", ":", "\n", "            ", "num_layers", "=", "3", "if", "add_action_in_obs", "else", "2", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "\n", "low", "=", "0", ",", "high", "=", "255", ",", "\n", "shape", "=", "(", "self", ".", "walkable", ".", "shape", "[", "0", "]", ",", "self", ".", "walkable", ".", "shape", "[", "1", "]", ",", "num_layers", ")", ",", "\n", "dtype", "=", "np", ".", "uint8", ")", "\n", "", "else", ":", "\n", "# Position, passenger?, (last action)", "\n", "            ", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "\n", "low", "=", "0.", ",", "high", "=", "1.", ",", "\n", "shape", "=", "(", "289", "if", "add_action_in_obs", "else", "288", ",", ")", "\n", ")", "\n", "\n", "", "self", ".", "action_space", "=", "spaces", ".", "Discrete", "(", "5", ")", "\n", "\n", "self", ".", "state", "=", "{", "\n", "'loc'", ":", "(", "0", ",", "0", ")", ",", "\n", "# If passenger is in taxi, set to None", "\n", "'pas'", ":", "False", ",", "\n", "'rot'", ":", "0", "\n", "}", "\n", "\n", "self", ".", "task", "=", "{", "\n", "'pic'", ":", "np", ".", "array", "(", "[", "0", ",", "0", "]", ")", ",", "\n", "'gol'", ":", "np", ".", "array", "(", "[", "0", ",", "0", "]", ")", "\n", "}", "\n", "\n", "self", ".", "done", "=", "True", "\n", "\n", "self", ".", "draw_and_set_task", "(", ")", "\n", "\n", "self", ".", "add_action_in_obs", "=", "add_action_in_obs", "\n", "self", ".", "reward_goal_found", "=", "2", "\n", "self", ".", "reward_per_timestep", "=", "-", "0.1", "\n", "self", ".", "reward_wrong_movement", "=", "reward_wrong_movement", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.draw_and_set_task": [[108, 148], ["gym.utils.seeding.np_random", "gym.utils.seeding.np_random", "constraint.split.split.split", "numpy.where", "isinstance", "taxi2a.Taxi2A.np_random.randint", "len", "LOCATIONS.values", "_rnd.choice", "_rnd.choice", "len", "range", "taxi2a.Taxi2A.possible_loc_states.remove", "len", "tuple"], "methods", ["None"], ["", "def", "draw_and_set_task", "(", "self", ",", "constraint", "=", "None", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Draw a new task and set the environment to that task.\n\n        Args:\n            seed: Random seed that is used to generate task\n            contraint:  Should be e.g. \"B-Y\"\n        \"\"\"", "\n", "assert", "(", "constraint", "is", "None", "or", "isinstance", "(", "constraint", ",", "str", ")", ")", "\n", "\n", "# Not needed here", "\n", "if", "seed", "is", "None", ":", "\n", "            ", "seed", "=", "self", ".", "np_random", ".", "randint", "(", "9223372036854775807", ")", "\n", "\n", "", "_rnd", ",", "seed1", "=", "seeding", ".", "np_random", "(", "seed", ")", "\n", "if", "constraint", "is", "None", ":", "\n", "            ", "constraint", "=", "\"{}-{}\"", ".", "format", "(", "\n", "_rnd", ".", "choice", "(", "[", "'R'", ",", "'G'", ",", "'Y'", ",", "'B'", "]", ")", ",", "\n", "_rnd", ".", "choice", "(", "[", "'R'", ",", "'G'", ",", "'Y'", ",", "'B'", "]", ")", "\n", ")", "\n", "\n", "# constraint should be of the ", "\n", "", "constraint", "=", "constraint", ".", "split", "(", "'-'", ")", "\n", "assert", "len", "(", "constraint", ")", "in", "[", "2", ",", "3", "]", "\n", "\n", "if", "len", "(", "constraint", ")", "==", "2", "or", "constraint", "[", "2", "]", "==", "'easy'", ":", "\n", "            ", "self", ".", "possible_pas_states", "=", "[", "True", ",", "False", "]", "\n", "", "elif", "constraint", "[", "2", "]", "==", "'hard'", ":", "\n", "            ", "self", ".", "possible_pas_states", "=", "[", "False", "]", "\n", "", "X", ",", "Y", "=", "np", ".", "where", "(", "self", ".", "walkable", "==", "1", ")", "\n", "self", ".", "possible_loc_states", "=", "[", "(", "X", "[", "i", "]", ",", "Y", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "X", ")", ")", "]", "\n", "if", "not", "self", ".", "start_everywhere", ":", "\n", "            ", "for", "loc", "in", "LOCATIONS", ".", "values", "(", ")", ":", "\n", "                ", "self", ".", "possible_loc_states", ".", "remove", "(", "tuple", "(", "loc", ")", ")", "\n", "\n", "# Set pickup and dropoff location", "\n", "", "", "self", ".", "task", "[", "'pic'", "]", "=", "LOCATIONS", "[", "constraint", "[", "0", "]", "]", "\n", "self", ".", "task", "[", "'gol'", "]", "=", "LOCATIONS", "[", "constraint", "[", "1", "]", "]", "\n", "\n", "return", "seed1", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.seed": [[149, 155], ["gym.utils.seeding.np_random", "gym.utils.seeding.np_random"], "methods", ["None"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Seed must be a non-negative \n        \"\"\"", "\n", "self", ".", "np_random", ",", "seed1", "=", "seeding", ".", "np_random", "(", "seed", ")", "\n", "return", "[", "seed1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.reset": [[156, 164], ["taxi2a.Taxi2A.np_random.choice", "taxi2a.Taxi2A.np_random.choice", "taxi2a.Taxi2A.create_observation", "taxi2a.Taxi2A.np_random.choice", "len"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.create_observation"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "done", "=", "False", "\n", "# self.state['pas'] = np.random.choice([True, False])", "\n", "self", ".", "state", "[", "'pas'", "]", "=", "self", ".", "np_random", ".", "choice", "(", "self", ".", "possible_pas_states", ")", "\n", "self", ".", "state", "[", "'loc'", "]", "=", "self", ".", "possible_loc_states", "[", "self", ".", "np_random", ".", "choice", "(", "len", "(", "self", ".", "possible_loc_states", ")", ")", "]", "\n", "self", ".", "state", "[", "'rot'", "]", "=", "self", ".", "np_random", ".", "choice", "(", "[", "0", ",", "1", ",", "2", ",", "3", "]", ")", "\n", "\n", "return", "self", ".", "create_observation", "(", "action", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.step": [[165, 220], ["taxi2a.Taxi2A.np_random.uniform", "taxi2a.Taxi2A.create_observation", "Exception", "taxi2a.Taxi2A.np_random.choice", "taxi2a.Taxi2A.check_pickup_possible", "taxi2a.Taxi2A.check_dropoff_possible", "taxi2a.Taxi2A.check_inside_area", "taxi2a.Taxi2A.check_walkable"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.create_observation", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.check_pickup_possible", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.check_dropoff_possible", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.check_inside_area", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.check_walkable"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "self", ".", "done", ":", "\n", "            ", "raise", "Exception", "(", "\"Environment must be reset\"", ")", "\n", "\n", "# No-op (0) or movement (1-4)", "\n", "", "rnd", "=", "self", ".", "np_random", ".", "uniform", "(", ")", "\n", "if", "rnd", "<", "self", ".", "scramble_prob", ":", "\n", "            ", "reward", "=", "self", ".", "reward_per_timestep", "\n", "self", ".", "state", "[", "'rot'", "]", "=", "self", ".", "np_random", ".", "choice", "(", "[", "0", ",", "1", ",", "2", ",", "3", "]", ")", "\n", "\n", "# mov = MOVE[self.state['rot']]", "\n", "# loc = self.state['loc']", "\n", "# new_loc = loc + mov", "\n", "\n", "# if (self.check_inside_area(new_loc) and self.check_walkable(new_loc)):", "\n", "#     pass", "\n", "# else:", "\n", "#     new_loc = loc", "\n", "# self.state['loc'] = new_loc", "\n", "\n", "", "elif", "action", "<", "4", ":", "\n", "            ", "if", "action", "==", "0", ":", "\n", "                ", "reward", "=", "self", ".", "reward_per_timestep", "\n", "", "elif", "action", "==", "1", ":", "\n", "# Move to adjacent field", "\n", "                ", "mov", "=", "MOVE", "[", "self", ".", "state", "[", "'rot'", "]", "]", "\n", "loc", "=", "self", ".", "state", "[", "'loc'", "]", "\n", "new_loc", "=", "loc", "+", "mov", "\n", "\n", "if", "(", "self", ".", "check_inside_area", "(", "new_loc", ")", "and", "self", ".", "check_walkable", "(", "new_loc", ")", ")", ":", "\n", "                    ", "reward", "=", "self", ".", "reward_per_timestep", "\n", "", "else", ":", "\n", "                    ", "reward", "=", "self", ".", "reward_wrong_movement", "\n", "new_loc", "=", "loc", "\n", "", "self", ".", "state", "[", "'loc'", "]", "=", "new_loc", "\n", "\n", "", "elif", "action", "==", "2", ":", "\n", "                ", "reward", "=", "self", ".", "reward_per_timestep", "\n", "self", ".", "state", "[", "'rot'", "]", "=", "(", "self", ".", "state", "[", "'rot'", "]", "+", "1", ")", "%", "4", "\n", "", "elif", "action", "==", "3", ":", "\n", "                ", "reward", "=", "self", ".", "reward_per_timestep", "\n", "self", ".", "state", "[", "'rot'", "]", "=", "(", "self", ".", "state", "[", "'rot'", "]", "-", "1", ")", "%", "4", "\n", "# Pickup / Dropoff", "\n", "", "", "elif", "action", "==", "4", ":", "\n", "            ", "if", "self", ".", "check_pickup_possible", "(", ")", ":", "\n", "                ", "self", ".", "state", "[", "'pas'", "]", "=", "True", "\n", "reward", "=", "self", ".", "reward_per_timestep", "\n", "", "elif", "self", ".", "check_dropoff_possible", "(", ")", ":", "\n", "                ", "self", ".", "done", "=", "True", "\n", "reward", "=", "self", ".", "reward_goal_found", "\n", "", "else", ":", "\n", "                ", "reward", "=", "self", ".", "reward_wrong_movement", "\n", "\n", "", "", "obs", "=", "self", ".", "create_observation", "(", "action", "=", "action", ")", "\n", "return", "obs", ",", "reward", ",", "self", ".", "done", ",", "{", "'state'", ":", "self", ".", "state", ",", "'task'", ":", "self", ".", "task", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.create_observation": [[221, 243], ["NotImplementedError", "numpy.zeros", "numpy.concatenate", "numpy.array"], "methods", ["None"], ["", "def", "create_observation", "(", "self", ",", "action", ",", "loc", "=", "None", ",", "rot", "=", "None", ",", "layout", "=", "None", ")", ":", "\n", "\n", "        ", "if", "loc", "is", "None", ":", "\n", "            ", "loc", "=", "self", ".", "state", "[", "'loc'", "]", "\n", "", "if", "rot", "is", "None", ":", "\n", "            ", "rot", "=", "self", ".", "state", "[", "'rot'", "]", "\n", "", "if", "layout", "is", "None", ":", "\n", "            ", "layout", "=", "self", ".", "walkable", "\n", "\n", "", "if", "self", ".", "image_obs", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Image not yet implemented\"", ")", "\n", "", "else", ":", "\n", "            ", "obs", "=", "np", ".", "zeros", "(", "288", ")", "\n", "# Remove wall from state", "\n", "x", "=", "loc", "[", "0", "]", "-", "1", "\n", "y", "=", "loc", "[", "1", "]", "-", "1", "\n", "idx", "=", "rot", "*", "72", "+", "self", ".", "state", "[", "'pas'", "]", "*", "36", "+", "y", "*", "6", "+", "x", "\n", "obs", "[", "idx", "]", "=", "1", "\n", "if", "self", ".", "add_action_in_obs", ":", "\n", "                ", "obs", "=", "np", ".", "concatenate", "(", "[", "obs", ",", "np", ".", "array", "(", "[", "action", "]", ")", "]", ")", "\n", "\n", "", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.check_pickup_possible": [[244, 246], ["numpy.all"], "methods", ["None"], ["", "def", "check_pickup_possible", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "all", "(", "self", ".", "state", "[", "'loc'", "]", "==", "self", ".", "task", "[", "'pic'", "]", ")", "and", "not", "self", ".", "state", "[", "'pas'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.check_dropoff_possible": [[247, 249], ["numpy.all"], "methods", ["None"], ["", "def", "check_dropoff_possible", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "all", "(", "self", ".", "state", "[", "'loc'", "]", "==", "self", ".", "task", "[", "'gol'", "]", ")", "and", "self", ".", "state", "[", "'pas'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.check_walkable": [[250, 252], ["tuple"], "methods", ["None"], ["", "def", "check_walkable", "(", "self", ",", "loc", ")", ":", "\n", "        ", "return", "self", ".", "walkable", "[", "tuple", "(", "loc", ")", "]", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.environments.taxi2a.Taxi2A.check_inside_area": [[253, 256], ["None"], "methods", ["None"], ["", "def", "check_inside_area", "(", "self", ",", "loc", ")", ":", "\n", "        ", "return", "(", "0", "<=", "loc", "[", "0", "]", "<", "self", ".", "walkable", ".", "shape", "[", "0", "]", "and", "\n", "0", "<=", "loc", "[", "1", "]", "<", "self", ".", "walkable", ".", "shape", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.a2c.A2C.__init__": [[7, 18], ["a2c.A2C.init_optimizer"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.init_optimizer"], ["    ", "def", "__init__", "(", "self", ",", "\n", "hierarchical_actor_critic", ",", "\n", "loss", ",", "\n", "opt", ")", ":", "\n", "\n", "        ", "self", ".", "hierarchical_actor_critic", "=", "hierarchical_actor_critic", "\n", "self", ".", "max_grad_norm", "=", "opt", "[", "'max_grad_norm'", "]", "\n", "self", ".", "loss", "=", "loss", "\n", "self", ".", "opt", "=", "opt", "\n", "# self.update_priors = True", "\n", "self", ".", "init_optimizer", "(", "agent", "=", "hierarchical_actor_critic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.a2c.A2C.init_optimizer": [[19, 35], ["agent.named_parameters", "torch.RMSprop", "torch.RMSprop", "torch.RMSprop", "name.startswith", "name.startswith", "master_params.append", "params.append"], "methods", ["None"], ["", "def", "init_optimizer", "(", "self", ",", "agent", ")", ":", "\n", "# params = agent.parameters()", "\n", "        ", "master_lr", "=", "self", ".", "opt", "[", "'lr'", "]", "\n", "if", "agent", ".", "training", ":", "\n", "            ", "master_lr", "*=", "self", ".", "opt", "[", "'master_lr_factor'", "]", "\n", "\n", "", "params", "=", "[", "]", "\n", "master_params", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "agent", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "name", ".", "startswith", "(", "\"masters\"", ")", "or", "name", ".", "startswith", "(", "\"encoders.2\"", ")", ":", "\n", "                ", "master_params", ".", "append", "(", "param", ")", "\n", "", "else", ":", "\n", "                ", "params", ".", "append", "(", "param", ")", "\n", "\n", "", "", "self", ".", "optimizer", "=", "optim", ".", "RMSprop", "(", "[", "{", "'params'", ":", "params", ",", "'lr'", ":", "self", ".", "opt", "[", "'lr'", "]", "}", ",", "\n", "{", "'params'", ":", "master_params", ",", "'lr'", ":", "master_lr", "}", "]", ",", "eps", "=", "self", ".", "opt", "[", "'eps'", "]", ",", "alpha", "=", "self", ".", "opt", "[", "'alpha'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.a2c.A2C.update": [[36, 217], ["rollouts.rewards.size", "a2c.A2C.hierarchical_actor_critic.evaluatePrior", "a2c.A2C.hierarchical_actor_critic.evaluatePolicy", "a2c.A2C.hierarchical_actor_critic.evaluatePolicy", "a2c.A2C.hierarchical_actor_critic.evaluatePolicy", "a2c.A2C.hierarchical_actor_critic.get_U", "z_log_probs.view.view.view", "action_log_probs.view.view.view", "b_log_probs.view.view.view", "action_prior_log_prob.view.view.view", "a2c.A2C.view", "values_u.view.view.view", "advantages_z.pow().mean", "a2c.A2C.optimizer.zero_grad", "torch.utils.clip_grad_norm_", "torch.utils.clip_grad_norm_", "torch.utils.clip_grad_norm_", "a2c.A2C.optimizer.step", "rollouts.obs.size", "rollouts.actions.size", "a2c.A2C.hierarchical_actor_critic.evaluatePrior", "action_prior_log_prob.view.view.mean", "a2c.A2C.mean", "a2c.A2C.hierarchical_actor_critic.parameters", "advantages_z.pow().mean.item", "action_loss_a.item", "action_loss_z.item", "action_loss_b.item", "action_prior_loss.item", "b_prior_loss.item", "entropy_a.mean().item", "entropy_b.mean().item", "entropy_z.mean().item", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "a2c.A2C.hierarchical_actor_critic.executePolicy", "a2c.A2C.hierarchical_actor_critic.evaluatePrior", "NotImplementedError", "rollouts.obs[].view", "rollouts.z[].view", "rollouts.actions.view", "rollouts.obs[].view", "rollouts.z[].view", "rollouts.b.view", "rollouts.masks[].view", "rollouts.obs[].view", "rollouts.b.view", "rollouts.z[].view", "rollouts.obs[].view", "rollouts.z[].view", "rollouts.actions.view", "rollouts.obs[].view", "rollouts.z[].view", "advantages_z.pow", "rollouts.obs[].view", "rollouts.z[].view", "rollouts.masks[].view", "entropy_a.mean", "entropy_b.mean", "entropy_z.mean", "rollouts.obs[].view", "rollouts.z[].view", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "rollouts.obs[].view", "rollouts.z[].view", "rollouts.b.view", "rollouts.masks[].view", "advantages_z.detach", "advantages_z.detach", "advantages_z.detach", "entropy_z.mean", "rollouts.b.view", "rollouts.z[].view", "entropy_b.mean", "entropy_a.mean"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePrior", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePolicy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePolicy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePolicy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.get_U", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.KFACOptimizer.step", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePrior", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.executePolicy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePrior"], ["", "def", "update", "(", "self", ",", "rollouts", ")", ":", "\n", "        ", "obs_shape", "=", "rollouts", ".", "obs", ".", "size", "(", ")", "[", "3", ":", "]", "\n", "action_shape", "=", "rollouts", ".", "actions", ".", "size", "(", ")", "[", "-", "1", "]", "\n", "num_tasks", ",", "num_steps", ",", "num_processes_per_task", ",", "_", "=", "rollouts", ".", "rewards", ".", "size", "(", ")", "\n", "\n", "\"\"\"\n        Get differentiable baseline values (which will also be trained).\n        Get differentiable log probs.\n\n        In rollouts:\n        - Compute n-step targets\n\n        We need:\n        - Loss for option prior\n        - Loss for V\n        - Loss for Master\n        - Loss for Option\n        \"\"\"", "\n", "\n", "# Recompute all the log probs that we wanna differentiate through", "\n", "# Output dimensions [num_tasks, num_tasks * num_steps, 1]", "\n", "\n", "# Evaluate Policies", "\n", "\n", "# Evaluate Priors", "\n", "\n", "if", "self", ".", "loss", "[", "'b_distillation'", "]", "==", "'master'", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Draw z_master with all b=1, i.e. let it choose freshly", "\n", "                ", "z_master", ",", "_", ",", "_", "=", "self", ".", "hierarchical_actor_critic", ".", "executePolicy", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "obs_shape", ")", ",", "\n", "# should be ignored", "\n", "z", "=", "rollouts", ".", "z", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "b", "=", "torch", ".", "ones_like", "(", "rollouts", ".", "b", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ")", ",", "\n", "policy_type", "=", "\"master\"", ",", "\n", ")", "\n", "\n", "", "delta_b", "=", "1", "-", "(", "z_master", "==", "rollouts", ".", "z", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ")", ".", "int", "(", ")", "\n", "\n", "b_prior_log_prob", "=", "self", ".", "hierarchical_actor_critic", ".", "evaluatePrior", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "obs_shape", ")", ",", "\n", "z", "=", "rollouts", ".", "z", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "# action=rollouts.b.view(num_tasks, -1, 1),", "\n", "action", "=", "delta_b", ",", "\n", "policy_type", "=", "\"distilled-termination\"", ",", "\n", "masks", "=", "rollouts", ".", "masks", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ")", "\n", "", "elif", "self", ".", "loss", "[", "'b_distillation'", "]", "==", "'posterior'", ":", "\n", "            ", "b_prior_log_prob", "=", "self", ".", "hierarchical_actor_critic", ".", "evaluatePrior", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "obs_shape", ")", ",", "\n", "z", "=", "rollouts", ".", "z", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "action", "=", "rollouts", ".", "b", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "policy_type", "=", "\"distilled-termination\"", ",", "\n", "masks", "=", "rollouts", ".", "masks", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"b_distillation type {} not implemented\"", ".", "format", "(", "self", ".", "loss", "[", "'b_distillation'", "]", ")", ")", "\n", "\n", "# z_prior_log_prob = self.hierarchical_actor_critic.evaluatePrior(", "\n", "#     obs=rollouts.obs[:, :-1].view(num_tasks, -1, *obs_shape),", "\n", "#     z=rollouts.z[:, :-1].view(num_tasks, -1, 1),", "\n", "#     b=rollouts.b.view(num_tasks, -1, 1),", "\n", "#     action=rollouts.z[:, 1:].view(num_tasks, -1, 1),", "\n", "#     policy_type=\"distilled-master\")", "\n", "\n", "", "action_prior_log_prob", "=", "self", ".", "hierarchical_actor_critic", ".", "evaluatePrior", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "obs_shape", ")", ",", "\n", "z", "=", "rollouts", ".", "z", "[", ":", ",", "1", ":", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "action", "=", "rollouts", ".", "actions", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "action_shape", ")", ",", "\n", "policy_type", "=", "\"option\"", ")", "\n", "\n", "# Evaluate Posteriors", "\n", "\n", "b_log_probs", ",", "entropy_b", "=", "self", ".", "hierarchical_actor_critic", ".", "evaluatePolicy", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "obs_shape", ")", ",", "\n", "z", "=", "rollouts", ".", "z", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "action", "=", "rollouts", ".", "b", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "policy_type", "=", "\"termination\"", ",", "\n", "masks", "=", "rollouts", ".", "masks", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ")", "\n", "\n", "z_log_probs", ",", "entropy_z", "=", "self", ".", "hierarchical_actor_critic", ".", "evaluatePolicy", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "obs_shape", ")", ",", "\n", "b", "=", "rollouts", ".", "b", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "action", "=", "rollouts", ".", "z", "[", ":", ",", "1", ":", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "policy_type", "=", "\"master\"", ")", "\n", "\n", "action_log_probs", ",", "entropy_a", "=", "self", ".", "hierarchical_actor_critic", ".", "evaluatePolicy", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "obs_shape", ")", ",", "\n", "z", "=", "rollouts", ".", "z", "[", ":", ",", "1", ":", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "action", "=", "rollouts", ".", "actions", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "action_shape", ")", ",", "\n", "policy_type", "=", "\"option\"", ")", "\n", "\n", "values_u", "=", "self", ".", "hierarchical_actor_critic", ".", "get_U", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "obs_shape", ")", ",", "\n", "previous_z", "=", "rollouts", ".", "z", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ")", "\n", "\n", "# TODO: Write down math and check again!", "\n", "z_log_probs", "=", "z_log_probs", ".", "view", "(", "\n", "num_tasks", ",", "num_steps", ",", "num_processes_per_task", ",", "1", ")", "\n", "action_log_probs", "=", "action_log_probs", ".", "view", "(", "\n", "num_tasks", ",", "num_steps", ",", "num_processes_per_task", ",", "1", ")", "\n", "b_log_probs", "=", "b_log_probs", ".", "view", "(", "\n", "num_tasks", ",", "num_steps", ",", "num_processes_per_task", ",", "1", ")", "\n", "action_prior_log_prob", "=", "action_prior_log_prob", ".", "view", "(", "\n", "num_tasks", ",", "num_steps", ",", "num_processes_per_task", ",", "1", ")", "\n", "b_prior_log_prob", "=", "b_prior_log_prob", ".", "view", "(", "\n", "num_tasks", ",", "num_steps", ",", "num_processes_per_task", ",", "1", ")", "\n", "# z_prior_log_prob = z_prior_log_prob.view(num_tasks, num_steps, num_processes_per_task, 1)", "\n", "# values_v = values_v.view(num_tasks, num_steps, num_processes_per_task, 1)", "\n", "values_u", "=", "values_u", ".", "view", "(", "num_tasks", ",", "num_steps", ",", "\n", "num_processes_per_task", ",", "1", ")", "\n", "\n", "# Currently only wendelin's loss is implemented", "\n", "advantages_z", "=", "rollouts", ".", "returns_z", "[", ":", ",", ":", "-", "1", "]", "-", "values_u", "\n", "\n", "# So far we only learn V", "\n", "value_loss", "=", "advantages_z", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "action_loss_a", "=", "-", "(", "advantages_z", ".", "detach", "(", ")", "*", "action_log_probs", ")", ".", "mean", "(", ")", "\n", "action_loss_z", "=", "-", "(", "advantages_z", ".", "detach", "(", ")", "*", "z_log_probs", ")", ".", "mean", "(", ")", "\n", "action_loss_b", "=", "-", "(", "advantages_z", ".", "detach", "(", ")", "*", "b_log_probs", ")", ".", "mean", "(", ")", "\n", "\n", "# TODO: What happens with gamma here (or in general for A2C)? Is the sign correct?", "\n", "action_prior_loss", "=", "-", "action_prior_log_prob", ".", "mean", "(", ")", "\n", "b_prior_loss", "=", "-", "b_prior_log_prob", ".", "mean", "(", ")", "\n", "# z_prior_loss = - z_prior_log_prob.mean()", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# update_master = (j % self.loss['master_update_freq'] == 0) or (not", "\n", "# self.hierarchical_actor_critic.training)", "\n", "\n", "elc_a", "=", "self", ".", "loss", "[", "'elc_a'", "]", "if", "self", ".", "loss", "[", "'elc_a'", "]", "is", "not", "None", "else", "self", ".", "loss", "[", "'elc'", "]", "\n", "elc_b", "=", "self", ".", "loss", "[", "'elc_b'", "]", "if", "self", ".", "loss", "[", "'elc_b'", "]", "is", "not", "None", "else", "self", ".", "loss", "[", "'elc'", "]", "\n", "elc_z", "=", "self", ".", "loss", "[", "'elc_z'", "]", "if", "self", ".", "loss", "[", "'elc_z'", "]", "is", "not", "None", "else", "self", ".", "loss", "[", "'elc'", "]", "\n", "\n", "# Whether or not gradients are cut is determined in the hierarchical_actor_critic", "\n", "(", "value_loss", "*", "self", ".", "loss", "[", "'value_loss_coef'", "]", "\n", "+", "action_loss_a", "*", "self", ".", "loss", "[", "'action_loss_coef_a'", "]", "\n", "+", "action_loss_z", "*", "self", ".", "loss", "[", "'action_loss_coef_z'", "]", "\n", "+", "action_loss_b", "*", "self", ".", "loss", "[", "'action_loss_coef_b'", "]", "\n", "+", "action_prior_loss", "*", "self", ".", "loss", "[", "'prior_loss_coef'", "]", "\n", "+", "b_prior_loss", "*", "self", ".", "loss", "[", "'prior_loss_coef'", "]", "\n", "#  + z_prior_loss * self.loss['prior_loss_coef']", "\n", "-", "entropy_a", ".", "mean", "(", ")", "*", "elc_a", "\n", "-", "entropy_b", ".", "mean", "(", ")", "*", "elc_b", "\n", "-", "entropy_z", ".", "mean", "(", ")", "*", "elc_z", ")", ".", "backward", "(", ")", "\n", "#  - entropy_a.mean() * self.loss['entropy_loss_coef']", "\n", "#  - entropy_b.mean() * self.loss['entropy_loss_coef']", "\n", "#  - entropy_z.mean() * self.loss['entropy_loss_coef']).backward()", "\n", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "hierarchical_actor_critic", ".", "parameters", "(", ")", ",", "\n", "self", ".", "max_grad_norm", ")", "\n", "\n", "####################### Debugging ###########################", "\n", "# # Checking whether all parameters are updated....", "\n", "# old_params = {}", "\n", "# for name, param in self.hierarchical_actor_critic.named_parameters():", "\n", "#     old_params[name] = param.clone()", "\n", "####################### End ###########################", "\n", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "####################### Debugging ###########################", "\n", "# # ...continued: Checking whether all parameters are updated", "\n", "# for name, param in self.hierarchical_actor_critic.named_parameters():", "\n", "#     if torch.equal(old_params[name], param):", "\n", "#         print(name)", "\n", "####################### End ###########################", "\n", "losses", "=", "{", "\n", "'value_loss'", ":", "value_loss", ".", "item", "(", ")", ",", "\n", "'action_loss_a'", ":", "action_loss_a", ".", "item", "(", ")", ",", "\n", "'action_loss_z'", ":", "action_loss_z", ".", "item", "(", ")", ",", "\n", "'action_loss_b'", ":", "action_loss_b", ".", "item", "(", ")", ",", "\n", "'action_prior_loss'", ":", "action_prior_loss", ".", "item", "(", ")", ",", "\n", "'b_prior_loss'", ":", "b_prior_loss", ".", "item", "(", ")", ",", "\n", "'entropy_a'", ":", "entropy_a", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "\n", "'entropy_b'", ":", "entropy_b", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "\n", "'entropy_z'", ":", "entropy_z", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "}", "\n", "\n", "return", "losses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.SplitBias.__init__": [[75, 80], ["torch.Module.__init__", "utils.AddBias"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.__init__"], ["    ", "def", "__init__", "(", "self", ",", "module", ")", ":", "\n", "        ", "super", "(", "SplitBias", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "add_bias", "=", "AddBias", "(", "module", ".", "bias", ".", "data", ")", "\n", "self", ".", "module", ".", "bias", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.SplitBias.forward": [[81, 85], ["kfac.SplitBias.module", "kfac.SplitBias.add_bias"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "x", "=", "self", ".", "module", "(", "input", ")", "\n", "x", "=", "self", ".", "add_bias", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.KFACOptimizer.__init__": [[88, 143], ["dict", "kfac.KFACOptimizer.__init__.split_bias"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "lr", "=", "0.25", ",", "\n", "momentum", "=", "0.9", ",", "\n", "stat_decay", "=", "0.99", ",", "\n", "kl_clip", "=", "0.001", ",", "\n", "damping", "=", "1e-2", ",", "\n", "weight_decay", "=", "0", ",", "\n", "fast_cnn", "=", "False", ",", "\n", "Ts", "=", "1", ",", "\n", "Tf", "=", "10", ")", ":", "\n", "        ", "defaults", "=", "dict", "(", ")", "\n", "\n", "def", "split_bias", "(", "module", ")", ":", "\n", "            ", "for", "mname", ",", "child", "in", "module", ".", "named_children", "(", ")", ":", "\n", "                ", "if", "hasattr", "(", "child", ",", "'bias'", ")", "and", "child", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "module", ".", "_modules", "[", "mname", "]", "=", "SplitBias", "(", "child", ")", "\n", "", "else", ":", "\n", "                    ", "split_bias", "(", "child", ")", "\n", "\n", "", "", "", "split_bias", "(", "model", ")", "\n", "\n", "super", "(", "KFACOptimizer", ",", "self", ")", ".", "__init__", "(", "model", ".", "parameters", "(", ")", ",", "defaults", ")", "\n", "\n", "self", ".", "known_modules", "=", "{", "'Linear'", ",", "'Conv2d'", ",", "'AddBias'", "}", "\n", "\n", "self", ".", "modules", "=", "[", "]", "\n", "self", ".", "grad_outputs", "=", "{", "}", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "_prepare_model", "(", ")", "\n", "\n", "self", ".", "steps", "=", "0", "\n", "\n", "self", ".", "m_aa", ",", "self", ".", "m_gg", "=", "{", "}", ",", "{", "}", "\n", "self", ".", "Q_a", ",", "self", ".", "Q_g", "=", "{", "}", ",", "{", "}", "\n", "self", ".", "d_a", ",", "self", ".", "d_g", "=", "{", "}", ",", "{", "}", "\n", "\n", "self", ".", "momentum", "=", "momentum", "\n", "self", ".", "stat_decay", "=", "stat_decay", "\n", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "kl_clip", "=", "kl_clip", "\n", "self", ".", "damping", "=", "damping", "\n", "self", ".", "weight_decay", "=", "weight_decay", "\n", "\n", "self", ".", "fast_cnn", "=", "fast_cnn", "\n", "\n", "self", ".", "Ts", "=", "Ts", "\n", "self", ".", "Tf", "=", "Tf", "\n", "\n", "self", ".", "optim", "=", "optim", ".", "SGD", "(", "\n", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "lr", "*", "(", "1", "-", "self", ".", "momentum", ")", ",", "\n", "momentum", "=", "self", ".", "momentum", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.KFACOptimizer._save_input": [[144, 160], ["torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "kfac.compute_cov_a", "kfac.update_running_stat", "compute_cov_a.clone"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.compute_cov_a", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.update_running_stat"], ["", "def", "_save_input", "(", "self", ",", "module", ",", "input", ")", ":", "\n", "        ", "if", "torch", ".", "is_grad_enabled", "(", ")", "and", "self", ".", "steps", "%", "self", ".", "Ts", "==", "0", ":", "\n", "            ", "classname", "=", "module", ".", "__class__", ".", "__name__", "\n", "layer_info", "=", "None", "\n", "if", "classname", "==", "'Conv2d'", ":", "\n", "                ", "layer_info", "=", "(", "module", ".", "kernel_size", ",", "module", ".", "stride", ",", "\n", "module", ".", "padding", ")", "\n", "\n", "", "aa", "=", "compute_cov_a", "(", "input", "[", "0", "]", ".", "data", ",", "classname", ",", "layer_info", ",", "\n", "self", ".", "fast_cnn", ")", "\n", "\n", "# Initialize buffers", "\n", "if", "self", ".", "steps", "==", "0", ":", "\n", "                ", "self", ".", "m_aa", "[", "module", "]", "=", "aa", ".", "clone", "(", ")", "\n", "\n", "", "update_running_stat", "(", "aa", ",", "self", ".", "m_aa", "[", "module", "]", ",", "self", ".", "stat_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.KFACOptimizer._save_grad_output": [[161, 177], ["kfac.compute_cov_g", "kfac.update_running_stat", "compute_cov_g.clone"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.compute_cov_g", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.update_running_stat"], ["", "", "def", "_save_grad_output", "(", "self", ",", "module", ",", "grad_input", ",", "grad_output", ")", ":", "\n", "        ", "if", "self", ".", "acc_stats", ":", "\n", "            ", "classname", "=", "module", ".", "__class__", ".", "__name__", "\n", "layer_info", "=", "None", "\n", "if", "classname", "==", "'Conv2d'", ":", "\n", "                ", "layer_info", "=", "(", "module", ".", "kernel_size", ",", "module", ".", "stride", ",", "\n", "module", ".", "padding", ")", "\n", "\n", "", "gg", "=", "compute_cov_g", "(", "grad_output", "[", "0", "]", ".", "data", ",", "classname", ",", "layer_info", ",", "\n", "self", ".", "fast_cnn", ")", "\n", "\n", "# Initialize buffers", "\n", "if", "self", ".", "steps", "==", "0", ":", "\n", "                ", "self", ".", "m_gg", "[", "module", "]", "=", "gg", ".", "clone", "(", ")", "\n", "\n", "", "update_running_stat", "(", "gg", ",", "self", ".", "m_gg", "[", "module", "]", ",", "self", ".", "stat_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.KFACOptimizer._prepare_model": [[178, 188], ["kfac.KFACOptimizer.model.modules", "kfac.KFACOptimizer.modules.append", "module.register_forward_pre_hook", "module.register_backward_hook"], "methods", ["None"], ["", "", "def", "_prepare_model", "(", "self", ")", ":", "\n", "        ", "for", "module", "in", "self", ".", "model", ".", "modules", "(", ")", ":", "\n", "            ", "classname", "=", "module", ".", "__class__", ".", "__name__", "\n", "if", "classname", "in", "self", ".", "known_modules", ":", "\n", "                ", "assert", "not", "(", "(", "classname", "in", "[", "'Linear'", ",", "'Conv2d'", "]", ")", "and", "module", ".", "bias", "is", "not", "None", ")", ",", "\"You must have a bias as a separate layer\"", "\n", "\n", "self", ".", "modules", ".", "append", "(", "module", ")", "\n", "module", ".", "register_forward_pre_hook", "(", "self", ".", "_save_input", ")", "\n", "module", ".", "register_backward_hook", "(", "self", ".", "_save_grad_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.KFACOptimizer.step": [[189, 242], ["enumerate", "kfac.KFACOptimizer.model.parameters", "min", "kfac.KFACOptimizer.model.parameters", "kfac.KFACOptimizer.optim.step", "kfac.KFACOptimizer.model.parameters", "next", "v.view.view.view", "math.sqrt", "next.grad.data.copy_", "next.grad.data.mul_", "next.grad.data.add_", "len", "m.parameters", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "torch.symeig", "kfac.KFACOptimizer.d_a[].mul_", "kfac.KFACOptimizer.d_g[].mul_", "next.grad.data.view", "kfac.KFACOptimizer.Q_a[].t", "next.grad.data.size", "list", "next.grad.data.size", "kfac.KFACOptimizer.Q_g[].t", "m.parameters", "kfac.KFACOptimizer.d_g[].unsqueeze", "kfac.KFACOptimizer.d_a[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.KFACOptimizer.step"], ["", "", "", "def", "step", "(", "self", ")", ":", "\n", "# Add weight decay", "\n", "        ", "if", "self", ".", "weight_decay", ">", "0", ":", "\n", "            ", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "grad", ".", "data", ".", "add_", "(", "self", ".", "weight_decay", ",", "p", ".", "data", ")", "\n", "\n", "", "", "updates", "=", "{", "}", "\n", "for", "i", ",", "m", "in", "enumerate", "(", "self", ".", "modules", ")", ":", "\n", "            ", "assert", "len", "(", "list", "(", "m", ".", "parameters", "(", ")", ")", "\n", ")", "==", "1", ",", "\"Can handle only one parameter at the moment\"", "\n", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "p", "=", "next", "(", "m", ".", "parameters", "(", ")", ")", "\n", "\n", "la", "=", "self", ".", "damping", "+", "self", ".", "weight_decay", "\n", "\n", "if", "self", ".", "steps", "%", "self", ".", "Tf", "==", "0", ":", "\n", "# My asynchronous implementation exists, I will add it later.", "\n", "# Experimenting with different ways to this in PyTorch.", "\n", "                ", "self", ".", "d_a", "[", "m", "]", ",", "self", ".", "Q_a", "[", "m", "]", "=", "torch", ".", "symeig", "(", "\n", "self", ".", "m_aa", "[", "m", "]", ",", "eigenvectors", "=", "True", ")", "\n", "self", ".", "d_g", "[", "m", "]", ",", "self", ".", "Q_g", "[", "m", "]", "=", "torch", ".", "symeig", "(", "\n", "self", ".", "m_gg", "[", "m", "]", ",", "eigenvectors", "=", "True", ")", "\n", "\n", "self", ".", "d_a", "[", "m", "]", ".", "mul_", "(", "(", "self", ".", "d_a", "[", "m", "]", ">", "1e-6", ")", ".", "float", "(", ")", ")", "\n", "self", ".", "d_g", "[", "m", "]", ".", "mul_", "(", "(", "self", ".", "d_g", "[", "m", "]", ">", "1e-6", ")", ".", "float", "(", ")", ")", "\n", "\n", "", "if", "classname", "==", "'Conv2d'", ":", "\n", "                ", "p_grad_mat", "=", "p", ".", "grad", ".", "data", ".", "view", "(", "p", ".", "grad", ".", "data", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "p_grad_mat", "=", "p", ".", "grad", ".", "data", "\n", "\n", "", "v1", "=", "self", ".", "Q_g", "[", "m", "]", ".", "t", "(", ")", "@", "p_grad_mat", "@", "self", ".", "Q_a", "[", "m", "]", "\n", "v2", "=", "v1", "/", "(", "\n", "self", ".", "d_g", "[", "m", "]", ".", "unsqueeze", "(", "1", ")", "*", "self", ".", "d_a", "[", "m", "]", ".", "unsqueeze", "(", "0", ")", "+", "la", ")", "\n", "v", "=", "self", ".", "Q_g", "[", "m", "]", "@", "v2", "@", "self", ".", "Q_a", "[", "m", "]", ".", "t", "(", ")", "\n", "\n", "v", "=", "v", ".", "view", "(", "p", ".", "grad", ".", "data", ".", "size", "(", ")", ")", "\n", "updates", "[", "p", "]", "=", "v", "\n", "\n", "", "vg_sum", "=", "0", "\n", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "v", "=", "updates", "[", "p", "]", "\n", "vg_sum", "+=", "(", "v", "*", "p", ".", "grad", ".", "data", "*", "self", ".", "lr", "*", "self", ".", "lr", ")", ".", "sum", "(", ")", "\n", "\n", "", "nu", "=", "min", "(", "1", ",", "math", ".", "sqrt", "(", "self", ".", "kl_clip", "/", "vg_sum", ")", ")", "\n", "\n", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "v", "=", "updates", "[", "p", "]", "\n", "p", ".", "grad", ".", "data", ".", "copy_", "(", "v", ")", "\n", "p", ".", "grad", ".", "data", ".", "mul_", "(", "nu", ")", "\n", "\n", "", "self", ".", "optim", ".", "step", "(", ")", "\n", "self", ".", "steps", "+=", "1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac._extract_patches": [[16, 27], ["x.view.unfold", "x.view.unfold", "x.view.transpose_().transpose_().contiguous", "x.view.view", "x.view.size", "x.view.size", "x.view.size", "torch.pad", "x.view.transpose_().transpose_", "x.view.size", "x.view.size", "x.view.size", "x.view.transpose_"], "function", ["None"], ["def", "_extract_patches", "(", "x", ",", "kernel_size", ",", "stride", ",", "padding", ")", ":", "\n", "    ", "if", "padding", "[", "0", "]", "+", "padding", "[", "1", "]", ">", "0", ":", "\n", "        ", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "padding", "[", "1", "]", ",", "padding", "[", "1", "]", ",", "padding", "[", "0", "]", ",", "\n", "padding", "[", "0", "]", ")", ")", ".", "data", "# Actually check dims", "\n", "", "x", "=", "x", ".", "unfold", "(", "2", ",", "kernel_size", "[", "0", "]", ",", "stride", "[", "0", "]", ")", "\n", "x", "=", "x", ".", "unfold", "(", "3", ",", "kernel_size", "[", "1", "]", ",", "stride", "[", "1", "]", ")", "\n", "x", "=", "x", ".", "transpose_", "(", "1", ",", "2", ")", ".", "transpose_", "(", "2", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "x", "=", "x", ".", "view", "(", "\n", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "x", ".", "size", "(", "2", ")", ",", "\n", "x", ".", "size", "(", "3", ")", "*", "x", ".", "size", "(", "4", ")", "*", "x", ".", "size", "(", "5", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.compute_cov_a": [[29, 47], ["a.cuda.size", "a.cuda.t", "kfac._extract_patches", "a.cuda.view", "a.cuda.mean", "kfac._extract_patches", "a.cuda.view().div_().div_", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "a.cuda.size", "a.cuda.size", "a.cuda.size", "a.cuda.size", "a.cuda.cuda", "a.cuda.view().div_", "a.cuda.size", "a.cuda.view", "a.cuda.size"], "function", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac._extract_patches", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac._extract_patches", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.cuda"], ["", "def", "compute_cov_a", "(", "a", ",", "classname", ",", "layer_info", ",", "fast_cnn", ")", ":", "\n", "    ", "batch_size", "=", "a", ".", "size", "(", "0", ")", "\n", "\n", "if", "classname", "==", "'Conv2d'", ":", "\n", "        ", "if", "fast_cnn", ":", "\n", "            ", "a", "=", "_extract_patches", "(", "a", ",", "*", "layer_info", ")", "\n", "a", "=", "a", ".", "view", "(", "a", ".", "size", "(", "0", ")", ",", "-", "1", ",", "a", ".", "size", "(", "-", "1", ")", ")", "\n", "a", "=", "a", ".", "mean", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "a", "=", "_extract_patches", "(", "a", ",", "*", "layer_info", ")", "\n", "a", "=", "a", ".", "view", "(", "-", "1", ",", "a", ".", "size", "(", "-", "1", ")", ")", ".", "div_", "(", "a", ".", "size", "(", "1", ")", ")", ".", "div_", "(", "a", ".", "size", "(", "2", ")", ")", "\n", "", "", "elif", "classname", "==", "'AddBias'", ":", "\n", "        ", "is_cuda", "=", "a", ".", "is_cuda", "\n", "a", "=", "torch", ".", "ones", "(", "a", ".", "size", "(", "0", ")", ",", "1", ")", "\n", "if", "is_cuda", ":", "\n", "            ", "a", "=", "a", ".", "cuda", "(", ")", "\n", "\n", "", "", "return", "a", ".", "t", "(", ")", "@", "(", "a", "/", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.compute_cov_g": [[49, 65], ["g.sum.size", "g_.t", "g.sum.view", "g.sum.sum", "g.sum.transpose().transpose().contiguous", "g.sum.view().mul_().mul_", "g.sum.view", "g.sum.sum", "g.sum.size", "g.sum.size", "g.sum.size", "g.sum.size", "g.sum.size", "g.sum.size", "g.sum.transpose().transpose", "g.sum.view().mul_", "g.sum.size", "g.sum.transpose", "g.sum.view", "g.sum.size"], "function", ["None"], ["", "def", "compute_cov_g", "(", "g", ",", "classname", ",", "layer_info", ",", "fast_cnn", ")", ":", "\n", "    ", "batch_size", "=", "g", ".", "size", "(", "0", ")", "\n", "\n", "if", "classname", "==", "'Conv2d'", ":", "\n", "        ", "if", "fast_cnn", ":", "\n", "            ", "g", "=", "g", ".", "view", "(", "g", ".", "size", "(", "0", ")", ",", "g", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "g", "=", "g", ".", "sum", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "g", "=", "g", ".", "transpose", "(", "1", ",", "2", ")", ".", "transpose", "(", "2", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "g", "=", "g", ".", "view", "(", "-", "1", ",", "g", ".", "size", "(", "-", "1", ")", ")", ".", "mul_", "(", "g", ".", "size", "(", "1", ")", ")", ".", "mul_", "(", "g", ".", "size", "(", "2", ")", ")", "\n", "", "", "elif", "classname", "==", "'AddBias'", ":", "\n", "        ", "g", "=", "g", ".", "view", "(", "g", ".", "size", "(", "0", ")", ",", "g", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "g", "=", "g", ".", "sum", "(", "-", "1", ")", "\n", "\n", "", "g_", "=", "g", "*", "batch_size", "\n", "return", "g_", ".", "t", "(", ")", "@", "(", "g_", "/", "g", ".", "size", "(", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.update_running_stat": [[67, 72], ["None"], "function", ["None"], ["", "def", "update_running_stat", "(", "aa", ",", "m_aa", ",", "momentum", ")", ":", "\n", "# Do the trick to keep aa unchanged and not create any additional tensors", "\n", "    ", "m_aa", "*=", "momentum", "/", "(", "1", "-", "momentum", ")", "\n", "m_aa", "+=", "aa", "\n", "m_aa", "*=", "(", "1", "-", "momentum", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.__init__": [[8, 22], ["ppo.PPO.init_optimizer"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.init_optimizer"], ["    ", "def", "__init__", "(", "self", ",", "\n", "hierarchical_actor_critic", ",", "\n", "loss", ",", "\n", "opt", ",", "\n", "ppo", ")", ":", "\n", "\n", "        ", "self", ".", "hierarchical_actor_critic", "=", "hierarchical_actor_critic", "\n", "self", ".", "loss", "=", "loss", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "ppo", "=", "ppo", "\n", "self", ".", "update_priors", "=", "True", "\n", "self", ".", "clip_param", "=", "self", ".", "ppo", "[", "'clip_param'", "]", "\n", "self", ".", "clipped_value_loss", "=", "self", ".", "ppo", "[", "'clip_value_loss'", "]", "\n", "self", ".", "init_optimizer", "(", "agent", "=", "hierarchical_actor_critic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.init_optimizer": [[23, 26], ["agent.parameters", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam"], "methods", ["None"], ["", "def", "init_optimizer", "(", "self", ",", "agent", ")", ":", "\n", "        ", "params", "=", "agent", ".", "parameters", "(", ")", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "params", ",", "lr", "=", "self", ".", "opt", "[", "'lr'", "]", ",", "eps", "=", "self", ".", "opt", "[", "'eps'", "]", ")", "\n", "#self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=50, gamma=0.5)", "\n"]], "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.ppo.PPO.update": [[28, 224], ["rollouts.obs.size", "rollouts.value_preds[].clone", "rollouts.action_log_probs.clone", "rollouts.z_log_probs.clone", "rollouts.b_log_probs.clone", "range", "rollouts.feed_forward_generator", "rollouts.update_ppo_epoch", "ppo.PPO.hierarchical_actor_critic.evaluatePolicy", "ppo.PPO.hierarchical_actor_critic.evaluatePolicy", "ppo.PPO.hierarchical_actor_critic.evaluatePolicy", "ppo.PPO.hierarchical_actor_critic.evaluatePrior", "ppo.PPO.hierarchical_actor_critic.get_U", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "ppo.PPO.optimizer.zero_grad", "torch.utils.clip_grad_norm_", "torch.utils.clip_grad_norm_", "torch.utils.clip_grad_norm_", "torch.utils.clip_grad_norm_", "ppo.PPO.optimizer.step", "torch.mse_loss.item", "action_loss.item", "action_prior_loss.item", "b_prior_loss.item", "entropy_a.mean().item", "entropy_z.mean().item", "entropy_b.mean().item", "ppo.PPO.hierarchical_actor_critic.evaluatePrior", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "adv_targ.detach", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "ppo.PPO.mean", "ppo.PPO.mean", "ppo.PPO.hierarchical_actor_critic.parameters", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "ppo.PPO.hierarchical_actor_critic.executePolicy", "ppo.PPO.hierarchical_actor_critic.evaluatePrior", "NotImplementedError", "ppo.PPO.update.mclamp"], "methods", ["home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.feed_forward_generator", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.storage.RolloutStorage.update_ppo_epoch", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePolicy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePolicy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePolicy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePrior", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.get_U", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.algo.kfac.KFACOptimizer.step", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePrior", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.executePolicy", "home.repos.pwc.inspect_result.maximilianigl_rl-msol.None.hierarchical_policy.HierarchicalPolicy.evaluatePrior"], ["", "def", "update", "(", "self", ",", "rollouts", ")", ":", "\n", "        ", "value_loss_epoch", "=", "0", "\n", "action_loss_epoch", "=", "0", "\n", "action_prior_loss_epoch", "=", "0", "\n", "\n", "b_prior_loss_epoch", "=", "0", "\n", "entropy_a_epoch", "=", "0", "\n", "entropy_z_epoch", "=", "0", "\n", "entropy_b_epoch", "=", "0", "\n", "\n", "num_tasks", ",", "num_steps", ",", "num_processes", ",", "*", "obs_shape", "=", "rollouts", ".", "obs", ".", "size", "(", ")", "\n", "\n", "### Things that shoudn't change during ppo_epochs (instead of advantage and value):", "\n", "# V_{\\pi-old}", "\n", "# [num_tasks, num_steps + 1, num_processes_per_task, 1]", "\n", "values_u", "=", "rollouts", ".", "value_preds", "[", ":", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "\n", "# \\pi-old (We need cloen b)", "\n", "old_action_log_probs", "=", "rollouts", ".", "action_log_probs", ".", "clone", "(", ")", "\n", "old_z_log_probs", "=", "rollouts", ".", "z_log_probs", ".", "clone", "(", ")", "\n", "old_b_log_probs", "=", "rollouts", ".", "b_log_probs", ".", "clone", "(", ")", "\n", "# And rewards but they are saved in rollouts", "\n", "# What we need to update is the log-fractions appearing in the advantage", "\n", "\n", "for", "e", "in", "range", "(", "self", ".", "ppo", "[", "'ppo_epoch'", "]", ")", ":", "\n", "# with torch.no_grad():", "\n", "#     values_u = self.hierarchical_actor_critic.get_U(", "\n", "#         obs=rollouts.obs[:, :-1].view(num_tasks, -1, *obs_shape),", "\n", "#         previous_z = rollouts.z[:, :-1].view(num_tasks, -1, 1)).view(num_tasks, num_steps - 1, num_processes, 1)", "\n", "\n", "#advantages_z = rollouts.returns_z[:, :-1] - rollouts.value_preds[:, :-1]", "\n", "\n", "            ", "data_generator", "=", "rollouts", ".", "feed_forward_generator", "(", "\n", "old_action_log_probs", "=", "old_action_log_probs", ",", "\n", "old_z_log_probs", "=", "old_z_log_probs", ",", "\n", "old_b_log_probs", "=", "old_b_log_probs", ",", "\n", "values_u", "=", "values_u", ",", "\n", "num_mini_batch", "=", "self", ".", "ppo", "[", "'num_mini_batch'", "]", ")", "\n", "\n", "for", "sample", "in", "data_generator", ":", "\n", "                ", "(", "obs_batch", ",", "value_preds_batch", ",", "returns_z_batch", ",", "masks_batch", ",", "\n", "actions_batch", ",", "z_batch_minus_one", ",", "z_batch_plus_one", ",", "b_batch", ",", "\n", "old_action_log_probs_batch", ",", "old_z_log_probs_batch", ",", "old_b_log_probs_batch", ",", "\n", "adv_targ", ")", "=", "sample", "\n", "\n", "#####################################################################", "\n", "# Evaluate Policies", "\n", "b_log_probs", ",", "entropy_b", "=", "self", ".", "hierarchical_actor_critic", ".", "evaluatePolicy", "(", "\n", "obs", "=", "obs_batch", ",", "\n", "z", "=", "z_batch_minus_one", ",", "\n", "action", "=", "b_batch", ",", "\n", "policy_type", "=", "\"termination\"", ",", "\n", "masks", "=", "masks_batch", ")", "\n", "\n", "z_log_probs", ",", "entropy_z", "=", "self", ".", "hierarchical_actor_critic", ".", "evaluatePolicy", "(", "\n", "obs", "=", "obs_batch", ",", "\n", "b", "=", "b_batch", ",", "\n", "action", "=", "z_batch_plus_one", ",", "\n", "policy_type", "=", "\"master\"", ")", "\n", "\n", "action_log_probs", ",", "entropy_a", "=", "self", ".", "hierarchical_actor_critic", ".", "evaluatePolicy", "(", "\n", "obs", "=", "obs_batch", ",", "\n", "z", "=", "z_batch_plus_one", ",", "\n", "action", "=", "actions_batch", ",", "\n", "policy_type", "=", "\"option\"", ")", "\n", "\n", "# Evaluate Priors", "\n", "if", "self", ".", "loss", "[", "'b_distillation'", "]", "==", "'master'", ":", "\n", "                    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Draw z_master with all b=1, i.e. let it choose freshly", "\n", "                        ", "z_master", ",", "_", ",", "_", "=", "self", ".", "hierarchical_actor_critic", ".", "executePolicy", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "obs_shape", ")", ",", "\n", "z", "=", "rollouts", ".", "z", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "# should be ignored", "\n", "b", "=", "torch", ".", "ones_like", "(", "rollouts", ".", "b", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ")", ",", "\n", "policy_type", "=", "\"master\"", ",", "\n", ")", "\n", "\n", "", "delta_b", "=", "1", "-", "(", "z_master", "==", "rollouts", ".", "z", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ")", "\n", "\n", "b_prior_log_prob", "=", "self", ".", "hierarchical_actor_critic", ".", "evaluatePrior", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "obs_shape", ")", ",", "\n", "z", "=", "rollouts", ".", "z", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "# action=rollouts.b.view(num_tasks, -1, 1),", "\n", "action", "=", "delta_b", ",", "\n", "policy_type", "=", "\"distilled-termination\"", ",", "\n", "masks", "=", "rollouts", ".", "masks", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ")", "\n", "", "elif", "self", ".", "loss", "[", "'b_distillation'", "]", "==", "'posterior'", ":", "\n", "                    ", "b_prior_log_prob", "=", "self", ".", "hierarchical_actor_critic", ".", "evaluatePrior", "(", "\n", "obs", "=", "rollouts", ".", "obs", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "*", "obs_shape", ")", ",", "\n", "z", "=", "rollouts", ".", "z", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "action", "=", "rollouts", ".", "b", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ",", "\n", "policy_type", "=", "\"distilled-termination\"", ",", "\n", "masks", "=", "rollouts", ".", "masks", "[", ":", ",", ":", "-", "1", "]", ".", "view", "(", "num_tasks", ",", "-", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "(", "\"b_distillation type {} not implemented\"", ".", "format", "(", "self", ".", "loss", "[", "'b_distillation'", "]", ")", ")", "\n", "\n", "", "action_prior_log_prob", "=", "self", ".", "hierarchical_actor_critic", ".", "evaluatePrior", "(", "\n", "obs", "=", "obs_batch", ",", "\n", "z", "=", "z_batch_plus_one", ",", "\n", "action", "=", "actions_batch", ",", "\n", "policy_type", "=", "\"option\"", ")", "\n", "\n", "values_u_batch", "=", "self", ".", "hierarchical_actor_critic", ".", "get_U", "(", "\n", "obs", "=", "obs_batch", ",", "\n", "previous_z", "=", "z_batch_minus_one", ")", "\n", "#####################################################################", "\n", "ratio_a", "=", "torch", ".", "exp", "(", "action_log_probs", "-", "old_action_log_probs_batch", ")", "\n", "ratio_z", "=", "torch", ".", "exp", "(", "z_log_probs", "-", "old_z_log_probs_batch", ")", "\n", "ratio_b", "=", "torch", ".", "exp", "(", "b_log_probs", "-", "old_b_log_probs_batch", ")", "\n", "\n", "def", "mclamp", "(", "value", ")", ":", "\n", "                    ", "return", "torch", ".", "clamp", "(", "value", ",", "\n", "1.0", "-", "self", ".", "clip_param", ",", "\n", "1.0", "+", "self", ".", "clip_param", ")", "\n", "\n", "# joint_ratio = torch.exp(num - denom)", "\n", "", "joint_surr_1", "=", "ratio_a", "*", "ratio_z", "*", "ratio_b", "*", "adv_targ", ".", "detach", "(", ")", "\n", "if", "self", ".", "ppo", "[", "'ppo_loss_type'", "]", "==", "'joint'", ":", "\n", "\n", "                    ", "joint_surr_2", "=", "mclamp", "(", "ratio_a", "*", "ratio_z", "*", "ratio_b", ")", "*", "adv_targ", ".", "detach", "(", ")", "\n", "\n", "action_loss", "=", "-", "torch", ".", "min", "(", "joint_surr_1", ",", "joint_surr_2", ")", ".", "mean", "(", ")", "\n", "\n", "", "elif", "self", ".", "ppo", "[", "'ppo_loss_type'", "]", "==", "'individual'", ":", "\n", "\n", "                    ", "indv_surr_2", "=", "mclamp", "(", "ratio_a", ")", "*", "mclamp", "(", "ratio_z", ")", "*", "mclamp", "(", "ratio_b", ")", "*", "adv_targ", ".", "detach", "(", ")", "\n", "\n", "action_loss", "=", "-", "torch", ".", "min", "(", "joint_surr_1", ",", "indv_surr_2", ")", ".", "mean", "(", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "(", "\"ppo_loss_type {} is not supported\"", ".", "format", "(", "self", ".", "ppo", "[", "'ppo_loss_type'", "]", ")", ")", "\n", "\n", "", "if", "self", ".", "clipped_value_loss", ":", "\n", "                    ", "value_pred_clipped", "=", "value_preds_batch", "+", "(", "values_u_batch", "-", "value_preds_batch", ")", ".", "clamp", "(", "-", "self", ".", "clip_param", ",", "self", ".", "clip_param", ")", "\n", "value_losses", "=", "(", "values_u_batch", "-", "returns_z_batch", ")", ".", "pow", "(", "2", ")", "\n", "value_losses_clipped", "=", "(", "value_pred_clipped", "-", "returns_z_batch", ")", ".", "pow", "(", "2", ")", "\n", "value_loss", "=", "torch", ".", "max", "(", "value_losses", ",", "value_losses_clipped", ")", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                    ", "value_loss", "=", "F", ".", "mse_loss", "(", "returns_z_batch", ",", "values_u_batch", ")", "\n", "\n", "", "action_prior_loss", "=", "-", "action_prior_log_prob", ".", "mean", "(", ")", "\n", "b_prior_loss", "=", "-", "b_prior_log_prob", ".", "mean", "(", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "elc_a", "=", "self", ".", "loss", "[", "'elc_a'", "]", "if", "self", ".", "loss", "[", "'elc_a'", "]", "is", "not", "None", "else", "self", ".", "loss", "[", "'elc'", "]", "\n", "elc_b", "=", "self", ".", "loss", "[", "'elc_b'", "]", "if", "self", ".", "loss", "[", "'elc_b'", "]", "is", "not", "None", "else", "self", ".", "loss", "[", "'elc'", "]", "\n", "elc_z", "=", "self", ".", "loss", "[", "'elc_z'", "]", "if", "self", ".", "loss", "[", "'elc_z'", "]", "is", "not", "None", "else", "self", ".", "loss", "[", "'elc'", "]", "\n", "\n", "(", "value_loss", "*", "self", ".", "loss", "[", "'value_loss_coef'", "]", "\n", "+", "action_loss", "*", "self", ".", "loss", "[", "'action_loss_coef_a'", "]", "\n", "+", "action_prior_loss", "*", "self", ".", "loss", "[", "'prior_loss_coef'", "]", "*", "self", ".", "update_priors", "# Yes, multiplying with booleans does what you'd expect", "\n", "+", "b_prior_loss", "*", "self", ".", "loss", "[", "'prior_loss_coef'", "]", "*", "self", ".", "update_priors", "# Yes, multiplying with booleans does what you'd expect", "\n", "-", "entropy_a", ".", "mean", "(", ")", "*", "elc_a", "\n", "-", "entropy_b", ".", "mean", "(", ")", "*", "elc_b", "\n", "-", "entropy_z", ".", "mean", "(", ")", "*", "elc_z", ")", ".", "backward", "(", ")", "\n", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "hierarchical_actor_critic", ".", "parameters", "(", ")", ",", "\n", "self", ".", "opt", "[", "'max_grad_norm'", "]", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "value_loss_epoch", "+=", "value_loss", ".", "item", "(", ")", "\n", "action_loss_epoch", "+=", "action_loss", ".", "item", "(", ")", "\n", "action_prior_loss_epoch", "+=", "action_prior_loss", ".", "item", "(", ")", "\n", "b_prior_loss_epoch", "+=", "b_prior_loss", ".", "item", "(", ")", "\n", "entropy_a_epoch", "+=", "entropy_a", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "entropy_z_epoch", "+=", "entropy_z", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "entropy_b_epoch", "+=", "entropy_b", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "rollouts", ".", "update_ppo_epoch", "(", "self", ".", "hierarchical_actor_critic", ")", "\n", "\n", "#self.scheduler.step()", "\n", "\n", "", "num_updates", "=", "self", ".", "ppo", "[", "'ppo_epoch'", "]", "*", "self", ".", "ppo", "[", "'num_mini_batch'", "]", "\n", "\n", "value_loss_epoch", "/=", "num_updates", "\n", "action_loss_epoch", "/=", "num_updates", "\n", "action_prior_loss_epoch", "/=", "num_updates", "\n", "b_prior_loss_epoch", "/=", "num_updates", "\n", "entropy_a_epoch", "/=", "num_updates", "\n", "entropy_z_epoch", "/=", "num_updates", "\n", "entropy_b_epoch", "/=", "num_updates", "\n", "\n", "losses", "=", "{", "\n", "'value_loss'", ":", "value_loss_epoch", ",", "\n", "'action_loss_a'", ":", "action_loss_epoch", ",", "\n", "'action_loss_z'", ":", "action_loss_epoch", ",", "\n", "'action_loss_b'", ":", "action_loss_epoch", ",", "\n", "'action_prior_loss'", ":", "action_prior_loss_epoch", ",", "\n", "'b_prior_loss'", ":", "b_prior_loss_epoch", ",", "\n", "'entropy_a'", ":", "entropy_a_epoch", ",", "\n", "'entropy_z'", ":", "entropy_z_epoch", ",", "\n", "'entropy_b'", ":", "entropy_b_epoch", "\n", "}", "\n", "\n", "return", "losses", "\n", "", "", ""]]}