{"home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.main.str2bool": [[8, 10], ["v.lower"], "function", ["None"], ["def", "str2bool", "(", "v", ")", ":", "\n", "    ", "return", "v", ".", "lower", "(", ")", "in", "(", "'true'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.main.main": [[11, 52], ["solver.Solver", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "data_loader.get_loader", "data_loader.get_loader", "solver.Solver.train", "solver.Solver.train_multi", "solver.Solver.test", "solver.Solver.test_multi"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.data_loader.get_loader", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.data_loader.get_loader", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.train", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.test"], ["", "def", "main", "(", "config", ")", ":", "\n", "# For fast training.", "\n", "    ", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# Create directories if not exist.", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "config", ".", "log_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "config", ".", "log_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "config", ".", "model_save_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "config", ".", "model_save_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "config", ".", "sample_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "config", ".", "sample_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "config", ".", "result_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "config", ".", "result_dir", ")", "\n", "\n", "# Data loader.", "\n", "", "celeba_loader", "=", "None", "\n", "rafd_loader", "=", "None", "\n", "\n", "if", "config", ".", "dataset", "in", "[", "'CelebA'", ",", "'Both'", "]", ":", "\n", "        ", "celeba_loader", "=", "get_loader", "(", "config", ".", "celeba_image_dir", ",", "config", ".", "attr_path", ",", "config", ".", "selected_attrs", ",", "\n", "config", ".", "celeba_crop_size", ",", "config", ".", "image_size", ",", "config", ".", "batch_size", ",", "\n", "'CelebA'", ",", "config", ".", "mode", ",", "config", ".", "num_workers", ")", "\n", "", "if", "config", ".", "dataset", "in", "[", "'RaFD'", ",", "'Both'", "]", ":", "\n", "        ", "rafd_loader", "=", "get_loader", "(", "config", ".", "rafd_image_dir", ",", "None", ",", "None", ",", "\n", "config", ".", "rafd_crop_size", ",", "config", ".", "image_size", ",", "config", ".", "batch_size", ",", "\n", "'RaFD'", ",", "config", ".", "mode", ",", "config", ".", "num_workers", ")", "\n", "\n", "\n", "# Solver for training and testing StarGAN.", "\n", "", "solver", "=", "Solver", "(", "celeba_loader", ",", "rafd_loader", ",", "config", ")", "\n", "\n", "if", "config", ".", "mode", "==", "'train'", ":", "\n", "        ", "if", "config", ".", "dataset", "in", "[", "'CelebA'", ",", "'RaFD'", "]", ":", "\n", "            ", "solver", ".", "train", "(", ")", "\n", "", "elif", "config", ".", "dataset", "in", "[", "'Both'", "]", ":", "\n", "            ", "solver", ".", "train_multi", "(", ")", "\n", "", "", "elif", "config", ".", "mode", "==", "'test'", ":", "\n", "        ", "if", "config", ".", "dataset", "in", "[", "'CelebA'", ",", "'RaFD'", "]", ":", "\n", "            ", "solver", ".", "test", "(", ")", "\n", "", "elif", "config", ".", "dataset", "in", "[", "'Both'", "]", ":", "\n", "            ", "solver", ".", "test_multi", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.data_loader.CelebA.__init__": [[13, 30], ["data_loader.CelebA.preprocess", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.data_loader.CelebA.preprocess"], ["def", "__init__", "(", "self", ",", "image_dir", ",", "attr_path", ",", "selected_attrs", ",", "transform", ",", "mode", ")", ":", "\n", "        ", "\"\"\"Initialize and preprocess the CelebA dataset.\"\"\"", "\n", "self", ".", "image_dir", "=", "image_dir", "\n", "self", ".", "attr_path", "=", "attr_path", "\n", "self", ".", "selected_attrs", "=", "selected_attrs", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "train_dataset", "=", "[", "]", "\n", "self", ".", "test_dataset", "=", "[", "]", "\n", "self", ".", "attr2idx", "=", "{", "}", "\n", "self", ".", "idx2attr", "=", "{", "}", "\n", "self", ".", "preprocess", "(", ")", "\n", "\n", "if", "mode", "==", "'train'", ":", "\n", "            ", "self", ".", "num_images", "=", "len", "(", "self", ".", "train_dataset", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_images", "=", "len", "(", "self", ".", "test_dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.data_loader.CelebA.preprocess": [[31, 58], ["lines[].split", "enumerate", "random.seed", "random.shuffle", "enumerate", "print", "line.rstrip", "line.split", "open", "label.append", "data_loader.CelebA.test_dataset.append", "data_loader.CelebA.train_dataset.append"], "methods", ["None"], ["", "", "def", "preprocess", "(", "self", ")", ":", "\n", "        ", "\"\"\"Preprocess the CelebA attribute file.\"\"\"", "\n", "lines", "=", "[", "line", ".", "rstrip", "(", ")", "for", "line", "in", "open", "(", "self", ".", "attr_path", ",", "'r'", ")", "]", "\n", "all_attr_names", "=", "lines", "[", "1", "]", ".", "split", "(", ")", "\n", "for", "i", ",", "attr_name", "in", "enumerate", "(", "all_attr_names", ")", ":", "\n", "            ", "self", ".", "attr2idx", "[", "attr_name", "]", "=", "i", "\n", "self", ".", "idx2attr", "[", "i", "]", "=", "attr_name", "\n", "\n", "", "lines", "=", "lines", "[", "2", ":", "]", "\n", "random", ".", "seed", "(", "1234", ")", "\n", "random", ".", "shuffle", "(", "lines", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "split", "=", "line", ".", "split", "(", ")", "\n", "filename", "=", "split", "[", "0", "]", "\n", "values", "=", "split", "[", "1", ":", "]", "\n", "\n", "label", "=", "[", "]", "\n", "for", "attr_name", "in", "self", ".", "selected_attrs", ":", "\n", "                ", "idx", "=", "self", ".", "attr2idx", "[", "attr_name", "]", "\n", "label", ".", "append", "(", "values", "[", "idx", "]", "==", "'1'", ")", "\n", "\n", "", "if", "(", "i", "+", "1", ")", "<", "2000", ":", "\n", "                ", "self", ".", "test_dataset", ".", "append", "(", "[", "filename", ",", "label", "]", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "train_dataset", ".", "append", "(", "[", "filename", ",", "label", "]", ")", "\n", "\n", "", "", "print", "(", "'Finished preprocessing the CelebA dataset...'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.data_loader.CelebA.__getitem__": [[59, 65], ["PIL.Image.open", "os.path.join", "data_loader.CelebA.transform", "torch.FloatTensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return one image and its corresponding attribute label.\"\"\"", "\n", "dataset", "=", "self", ".", "train_dataset", "if", "self", ".", "mode", "==", "'train'", "else", "self", ".", "test_dataset", "\n", "filename", ",", "label", "=", "dataset", "[", "index", "]", "\n", "image", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "image_dir", ",", "filename", ")", ")", "\n", "return", "self", ".", "transform", "(", "image", ")", ",", "torch", ".", "FloatTensor", "(", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.data_loader.CelebA.__len__": [[66, 69], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the number of images.\"\"\"", "\n", "return", "self", ".", "num_images", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.data_loader.get_loader": [[71, 93], ["T.Compose.append", "T.Compose.append", "T.Compose.append", "T.Compose.append", "torchvision.transforms.Compose", "torch.utils.data.DataLoader", "T.Compose.append", "torchvision.transforms.CenterCrop", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "data_loader.CelebA", "torchvision.transforms.RandomHorizontalFlip", "torchvision.datasets.ImageFolder"], "function", ["None"], ["", "", "def", "get_loader", "(", "image_dir", ",", "attr_path", ",", "selected_attrs", ",", "crop_size", "=", "178", ",", "image_size", "=", "128", ",", "\n", "batch_size", "=", "16", ",", "dataset", "=", "'CelebA'", ",", "mode", "=", "'train'", ",", "num_workers", "=", "1", ")", ":", "\n", "    ", "\"\"\"Build and return a data loader.\"\"\"", "\n", "transform", "=", "[", "]", "\n", "if", "mode", "==", "'train'", ":", "\n", "        ", "transform", ".", "append", "(", "T", ".", "RandomHorizontalFlip", "(", ")", ")", "\n", "", "transform", ".", "append", "(", "T", ".", "CenterCrop", "(", "crop_size", ")", ")", "\n", "transform", ".", "append", "(", "T", ".", "Resize", "(", "image_size", ")", ")", "\n", "transform", ".", "append", "(", "T", ".", "ToTensor", "(", ")", ")", "\n", "transform", ".", "append", "(", "T", ".", "Normalize", "(", "mean", "=", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "std", "=", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ")", "\n", "transform", "=", "T", ".", "Compose", "(", "transform", ")", "\n", "\n", "if", "dataset", "==", "'CelebA'", ":", "\n", "        ", "dataset", "=", "CelebA", "(", "image_dir", ",", "attr_path", ",", "selected_attrs", ",", "transform", ",", "mode", ")", "\n", "", "elif", "dataset", "==", "'RaFD'", ":", "\n", "        ", "dataset", "=", "ImageFolder", "(", "image_dir", ",", "transform", ")", "\n", "\n", "", "data_loader", "=", "data", ".", "DataLoader", "(", "dataset", "=", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "(", "mode", "==", "'train'", ")", ",", "\n", "num_workers", "=", "num_workers", ")", "\n", "return", "data_loader", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.__init__": [[16, 71], ["torch.device", "torch.device", "torch.device", "torch.device", "solver.Solver.build_model", "solver.Solver.build_tensorboard", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.build_model", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.build_tensorboard"], ["def", "__init__", "(", "self", ",", "celeba_loader", ",", "rafd_loader", ",", "config", ")", ":", "\n", "        ", "\"\"\"Initialize configurations.\"\"\"", "\n", "\n", "# Data loader.", "\n", "self", ".", "celeba_loader", "=", "celeba_loader", "\n", "self", ".", "rafd_loader", "=", "rafd_loader", "\n", "\n", "# Model configurations.", "\n", "self", ".", "c_dim", "=", "config", ".", "c_dim", "\n", "self", ".", "c2_dim", "=", "config", ".", "c2_dim", "\n", "self", ".", "image_size", "=", "config", ".", "image_size", "\n", "self", ".", "g_conv_dim", "=", "config", ".", "g_conv_dim", "\n", "self", ".", "d_conv_dim", "=", "config", ".", "d_conv_dim", "\n", "self", ".", "g_repeat_num", "=", "config", ".", "g_repeat_num", "\n", "self", ".", "d_repeat_num", "=", "config", ".", "d_repeat_num", "\n", "self", ".", "lambda_cls", "=", "config", ".", "lambda_cls", "\n", "self", ".", "lambda_rec", "=", "config", ".", "lambda_rec", "\n", "self", ".", "lambda_gp", "=", "config", ".", "lambda_gp", "\n", "\n", "# Training configurations.", "\n", "self", ".", "dataset", "=", "config", ".", "dataset", "\n", "self", ".", "batch_size", "=", "config", ".", "batch_size", "\n", "self", ".", "num_iters", "=", "config", ".", "num_iters", "\n", "self", ".", "num_iters_decay", "=", "config", ".", "num_iters_decay", "\n", "self", ".", "g_lr", "=", "config", ".", "g_lr", "\n", "self", ".", "d_lr", "=", "config", ".", "d_lr", "\n", "self", ".", "n_critic", "=", "config", ".", "n_critic", "\n", "self", ".", "beta1", "=", "config", ".", "beta1", "\n", "self", ".", "beta2", "=", "config", ".", "beta2", "\n", "self", ".", "resume_iters", "=", "config", ".", "resume_iters", "\n", "self", ".", "selected_attrs", "=", "config", ".", "selected_attrs", "\n", "\n", "# Test configurations.", "\n", "self", ".", "test_iters", "=", "config", ".", "test_iters", "\n", "\n", "# Miscellaneous.", "\n", "self", ".", "use_tensorboard", "=", "config", ".", "use_tensorboard", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "# Directories.", "\n", "self", ".", "log_dir", "=", "config", ".", "log_dir", "\n", "self", ".", "sample_dir", "=", "config", ".", "sample_dir", "\n", "self", ".", "model_save_dir", "=", "config", ".", "model_save_dir", "\n", "self", ".", "result_dir", "=", "config", ".", "result_dir", "\n", "\n", "# Step size.", "\n", "self", ".", "log_step", "=", "config", ".", "log_step", "\n", "self", ".", "sample_step", "=", "config", ".", "sample_step", "\n", "self", ".", "model_save_step", "=", "config", ".", "model_save_step", "\n", "self", ".", "lr_update_step", "=", "config", ".", "lr_update_step", "\n", "\n", "# Build the model and tensorboard.", "\n", "self", ".", "build_model", "(", ")", "\n", "if", "self", ".", "use_tensorboard", ":", "\n", "            ", "self", ".", "build_tensorboard", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.build_model": [[72, 88], ["torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "solver.Solver.print_network", "solver.Solver.print_network", "solver.Solver.G.to", "solver.Solver.D.to", "model.Generator", "model.Discriminator", "solver.Solver.G.parameters", "solver.Solver.D.parameters", "model.Generator", "model.Discriminator"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.print_network", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.print_network"], ["", "", "def", "build_model", "(", "self", ")", ":", "\n", "        ", "\"\"\"Create a generator and a discriminator.\"\"\"", "\n", "if", "self", ".", "dataset", "in", "[", "'CelebA'", ",", "'RaFD'", "]", ":", "\n", "            ", "self", ".", "G", "=", "Generator", "(", "self", ".", "g_conv_dim", ",", "self", ".", "c_dim", ",", "self", ".", "g_repeat_num", ")", "\n", "self", ".", "D", "=", "Discriminator", "(", "self", ".", "image_size", ",", "self", ".", "d_conv_dim", ",", "self", ".", "c_dim", ",", "self", ".", "d_repeat_num", ")", "\n", "", "elif", "self", ".", "dataset", "in", "[", "'Both'", "]", ":", "\n", "            ", "self", ".", "G", "=", "Generator", "(", "self", ".", "g_conv_dim", ",", "self", ".", "c_dim", "+", "self", ".", "c2_dim", "+", "2", ",", "self", ".", "g_repeat_num", ")", "# 2 for mask vector.", "\n", "self", ".", "D", "=", "Discriminator", "(", "self", ".", "image_size", ",", "self", ".", "d_conv_dim", ",", "self", ".", "c_dim", "+", "self", ".", "c2_dim", ",", "self", ".", "d_repeat_num", ")", "\n", "\n", "", "self", ".", "g_optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "G", ".", "parameters", "(", ")", ",", "self", ".", "g_lr", ",", "[", "self", ".", "beta1", ",", "self", ".", "beta2", "]", ")", "\n", "self", ".", "d_optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "D", ".", "parameters", "(", ")", ",", "self", ".", "d_lr", ",", "[", "self", ".", "beta1", ",", "self", ".", "beta2", "]", ")", "\n", "self", ".", "print_network", "(", "self", ".", "G", ",", "'G'", ")", "\n", "self", ".", "print_network", "(", "self", ".", "D", ",", "'D'", ")", "\n", "\n", "self", ".", "G", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "D", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.print_network": [[89, 97], ["model.parameters", "print", "print", "print", "p.numel"], "methods", ["None"], ["", "def", "print_network", "(", "self", ",", "model", ",", "name", ")", ":", "\n", "        ", "\"\"\"Print out the network information.\"\"\"", "\n", "num_params", "=", "0", "\n", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "num_params", "+=", "p", ".", "numel", "(", ")", "\n", "", "print", "(", "model", ")", "\n", "print", "(", "name", ")", "\n", "print", "(", "\"The number of parameters: {}\"", ".", "format", "(", "num_params", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.restore_model": [[98, 105], ["print", "os.path.join", "os.path.join", "solver.Solver.G.load_state_dict", "solver.Solver.D.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["None"], ["", "def", "restore_model", "(", "self", ",", "resume_iters", ")", ":", "\n", "        ", "\"\"\"Restore the trained generator and discriminator.\"\"\"", "\n", "print", "(", "'Loading the trained models from step {}...'", ".", "format", "(", "resume_iters", ")", ")", "\n", "G_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_save_dir", ",", "'{}-G.ckpt'", ".", "format", "(", "resume_iters", ")", ")", "\n", "D_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_save_dir", ",", "'{}-D.ckpt'", ".", "format", "(", "resume_iters", ")", ")", "\n", "self", ".", "G", ".", "load_state_dict", "(", "torch", ".", "load", "(", "G_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "self", ".", "D", ".", "load_state_dict", "(", "torch", ".", "load", "(", "D_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.build_tensorboard": [[106, 110], ["Logger"], "methods", ["None"], ["", "def", "build_tensorboard", "(", "self", ")", ":", "\n", "        ", "\"\"\"Build a tensorboard logger.\"\"\"", "\n", "from", "logger", "import", "Logger", "\n", "self", ".", "logger", "=", "Logger", "(", "self", ".", "log_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.update_lr": [[111, 117], ["None"], "methods", ["None"], ["", "def", "update_lr", "(", "self", ",", "g_lr", ",", "d_lr", ")", ":", "\n", "        ", "\"\"\"Decay learning rates of the generator and discriminator.\"\"\"", "\n", "for", "param_group", "in", "self", ".", "g_optimizer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "g_lr", "\n", "", "for", "param_group", "in", "self", ".", "d_optimizer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "d_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.reset_grad": [[118, 122], ["solver.Solver.g_optimizer.zero_grad", "solver.Solver.d_optimizer.zero_grad"], "methods", ["None"], ["", "", "def", "reset_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset the gradient buffers.\"\"\"", "\n", "self", ".", "g_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "d_optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.denorm": [[123, 127], ["out.clamp_"], "methods", ["None"], ["", "def", "denorm", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Convert the range from [-1, 1] to [0, 1].\"\"\"", "\n", "out", "=", "(", "x", "+", "1", ")", "/", "2", "\n", "return", "out", ".", "clamp_", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.gradient_penalty": [[128, 141], ["torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "dydx.view.view.view", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "dydx.view.view.size", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "y.size"], "methods", ["None"], ["", "def", "gradient_penalty", "(", "self", ",", "y", ",", "x", ")", ":", "\n", "        ", "\"\"\"Compute gradient penalty: (L2_norm(dy/dx) - 1)**2.\"\"\"", "\n", "weight", "=", "torch", ".", "ones", "(", "y", ".", "size", "(", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "dydx", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "y", ",", "\n", "inputs", "=", "x", ",", "\n", "grad_outputs", "=", "weight", ",", "\n", "retain_graph", "=", "True", ",", "\n", "create_graph", "=", "True", ",", "\n", "only_inputs", "=", "True", ")", "[", "0", "]", "\n", "\n", "dydx", "=", "dydx", ".", "view", "(", "dydx", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "dydx_l2norm", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "dydx", "**", "2", ",", "dim", "=", "1", ")", ")", "\n", "return", "torch", ".", "mean", "(", "(", "dydx_l2norm", "-", "1", ")", "**", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.label2onehot": [[142, 148], ["labels.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.arange", "labels.long"], "methods", ["None"], ["", "def", "label2onehot", "(", "self", ",", "labels", ",", "dim", ")", ":", "\n", "        ", "\"\"\"Convert label indices to one-hot vectors.\"\"\"", "\n", "batch_size", "=", "labels", ".", "size", "(", "0", ")", "\n", "out", "=", "torch", ".", "zeros", "(", "batch_size", ",", "dim", ")", "\n", "out", "[", "np", ".", "arange", "(", "batch_size", ")", ",", "labels", ".", "long", "(", ")", "]", "=", "1", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.create_labels": [[149, 174], ["range", "enumerate", "c_trg_list.append", "c_org.clone", "solver.Solver.to", "hair_color_indices.append", "solver.Solver.label2onehot", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "c_org.size"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.label2onehot"], ["", "def", "create_labels", "(", "self", ",", "c_org", ",", "c_dim", "=", "5", ",", "dataset", "=", "'CelebA'", ",", "selected_attrs", "=", "None", ")", ":", "\n", "        ", "\"\"\"Generate target domain labels for debugging and testing.\"\"\"", "\n", "# Get hair color indices.", "\n", "if", "dataset", "==", "'CelebA'", ":", "\n", "            ", "hair_color_indices", "=", "[", "]", "\n", "for", "i", ",", "attr_name", "in", "enumerate", "(", "selected_attrs", ")", ":", "\n", "                ", "if", "attr_name", "in", "[", "'Black_Hair'", ",", "'Blond_Hair'", ",", "'Brown_Hair'", ",", "'Gray_Hair'", "]", ":", "\n", "                    ", "hair_color_indices", ".", "append", "(", "i", ")", "\n", "\n", "", "", "", "c_trg_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "c_dim", ")", ":", "\n", "            ", "if", "dataset", "==", "'CelebA'", ":", "\n", "                ", "c_trg", "=", "c_org", ".", "clone", "(", ")", "\n", "if", "i", "in", "hair_color_indices", ":", "# Set one hair color to 1 and the rest to 0.", "\n", "                    ", "c_trg", "[", ":", ",", "i", "]", "=", "1", "\n", "for", "j", "in", "hair_color_indices", ":", "\n", "                        ", "if", "j", "!=", "i", ":", "\n", "                            ", "c_trg", "[", ":", ",", "j", "]", "=", "0", "\n", "", "", "", "else", ":", "\n", "                    ", "c_trg", "[", ":", ",", "i", "]", "=", "(", "c_trg", "[", ":", ",", "i", "]", "==", "0", ")", "# Reverse attribute value.", "\n", "", "", "elif", "dataset", "==", "'RaFD'", ":", "\n", "                ", "c_trg", "=", "self", ".", "label2onehot", "(", "torch", ".", "ones", "(", "c_org", ".", "size", "(", "0", ")", ")", "*", "i", ",", "c_dim", ")", "\n", "\n", "", "c_trg_list", ".", "append", "(", "c_trg", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "", "return", "c_trg_list", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.classification_loss": [[175, 181], ["torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "logit.size", "torch.cross_entropy", "torch.cross_entropy"], "methods", ["None"], ["", "def", "classification_loss", "(", "self", ",", "logit", ",", "target", ",", "dataset", "=", "'CelebA'", ")", ":", "\n", "        ", "\"\"\"Compute binary or softmax cross entropy loss.\"\"\"", "\n", "if", "dataset", "==", "'CelebA'", ":", "\n", "            ", "return", "F", ".", "binary_cross_entropy_with_logits", "(", "logit", ",", "target", ",", "size_average", "=", "False", ")", "/", "logit", ".", "size", "(", "0", ")", "\n", "", "elif", "dataset", "==", "'RaFD'", ":", "\n", "            ", "return", "F", ".", "cross_entropy", "(", "logit", ",", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.train": [[182, 353], ["iter", "next", "x_fixed.to.to.to", "solver.Solver.create_labels", "print", "time.time", "range", "solver.Solver.restore_model", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "x_real.to.to.to", "solver.Solver.to", "solver.Solver.to", "label_org.to.to.to", "label_trg.to.to.to", "solver.Solver.D", "solver.Solver.classification_loss", "solver.Solver.G", "solver.Solver.D", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "solver.Solver.D", "solver.Solver.gradient_penalty", "solver.Solver.reset_grad", "d_loss.backward", "solver.Solver.d_optimizer.step", "d_loss_real.item", "torch.mean.item", "torch.mean.item", "solver.Solver.item", "solver.Solver.item", "next", "label_org.to.to.size", "label_org.to.to.clone", "label_trg.to.to.clone", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "x_fake.detach", "solver.Solver.G", "solver.Solver.D", "solver.Solver.classification_loss", "solver.Solver.G", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "solver.Solver.reset_grad", "g_loss.backward", "solver.Solver.g_optimizer.step", "g_loss_fake.item", "torch.mean.item", "torch.mean.item", "solver.Solver.item", "loss.items", "print", "os.path.join", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "solver.Solver.update_lr", "print", "iter", "next", "solver.Solver.label2onehot", "solver.Solver.label2onehot", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "time.time", "str", "loss.items", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "os.path.join", "os.path.join", "os.path.join", "torchvision.utils.save_image", "torchvision.utils.save_image", "torchvision.utils.save_image", "print", "solver.Solver.G.state_dict", "solver.Solver.D.state_dict", "float", "float", "x_real.to.to.size", "datetime.timedelta", "solver.Solver.logger.scalar_summary", "solver.Solver.G", "x_fake_list.append", "x_attention_list.append", "x_content_list.append", "solver.Solver.denorm", "solver.Solver.denorm", "solver.Solver.denorm", "torch.cat.data.cpu", "torch.cat.data.cpu", "torch.cat.data.cpu", "torch.cat.data.cpu", "torch.cat.data.cpu", "torch.cat.data.cpu"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.create_labels", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.restore_model", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.classification_loss", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.gradient_penalty", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.reset_grad", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.LambdaLR.step", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.classification_loss", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.reset_grad", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.LambdaLR.step", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.save", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.save", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.save", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.save", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.save", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.save", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.save", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.save", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.update_lr", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.label2onehot", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.label2onehot", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.save_image", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.save_image", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.save_image", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.logger.Logger.scalar_summary", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.denorm", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.denorm", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.denorm"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\"Train StarGAN within a single dataset.\"\"\"", "\n", "# Set data loader.", "\n", "if", "self", ".", "dataset", "==", "'CelebA'", ":", "\n", "            ", "data_loader", "=", "self", ".", "celeba_loader", "\n", "", "elif", "self", ".", "dataset", "==", "'RaFD'", ":", "\n", "            ", "data_loader", "=", "self", ".", "rafd_loader", "\n", "\n", "# Fetch fixed inputs for debugging.", "\n", "", "data_iter", "=", "iter", "(", "data_loader", ")", "\n", "x_fixed", ",", "c_org", "=", "next", "(", "data_iter", ")", "\n", "x_fixed", "=", "x_fixed", ".", "to", "(", "self", ".", "device", ")", "\n", "c_fixed_list", "=", "self", ".", "create_labels", "(", "c_org", ",", "self", ".", "c_dim", ",", "self", ".", "dataset", ",", "self", ".", "selected_attrs", ")", "\n", "\n", "# Learning rate cache for decaying.", "\n", "g_lr", "=", "self", ".", "g_lr", "\n", "d_lr", "=", "self", ".", "d_lr", "\n", "\n", "# Start training from scratch or resume training.", "\n", "start_iters", "=", "0", "\n", "if", "self", ".", "resume_iters", ":", "\n", "            ", "start_iters", "=", "self", ".", "resume_iters", "\n", "self", ".", "restore_model", "(", "self", ".", "resume_iters", ")", "\n", "\n", "# Start training.", "\n", "", "print", "(", "'Start training...'", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "for", "i", "in", "range", "(", "start_iters", ",", "self", ".", "num_iters", ")", ":", "\n", "\n", "# =================================================================================== #", "\n", "#                             1. Preprocess input data                                #", "\n", "# =================================================================================== #", "\n", "\n", "# Fetch real images and labels.", "\n", "            ", "try", ":", "\n", "                ", "x_real", ",", "label_org", "=", "next", "(", "data_iter", ")", "\n", "", "except", ":", "\n", "                ", "data_iter", "=", "iter", "(", "data_loader", ")", "\n", "x_real", ",", "label_org", "=", "next", "(", "data_iter", ")", "\n", "\n", "# Generate target domain labels randomly.", "\n", "", "rand_idx", "=", "torch", ".", "randperm", "(", "label_org", ".", "size", "(", "0", ")", ")", "\n", "label_trg", "=", "label_org", "[", "rand_idx", "]", "\n", "\n", "if", "self", ".", "dataset", "==", "'CelebA'", ":", "\n", "                ", "c_org", "=", "label_org", ".", "clone", "(", ")", "\n", "c_trg", "=", "label_trg", ".", "clone", "(", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'RaFD'", ":", "\n", "                ", "c_org", "=", "self", ".", "label2onehot", "(", "label_org", ",", "self", ".", "c_dim", ")", "\n", "c_trg", "=", "self", ".", "label2onehot", "(", "label_trg", ",", "self", ".", "c_dim", ")", "\n", "\n", "", "x_real", "=", "x_real", ".", "to", "(", "self", ".", "device", ")", "# Input images.", "\n", "c_org", "=", "c_org", ".", "to", "(", "self", ".", "device", ")", "# Original domain labels.", "\n", "c_trg", "=", "c_trg", ".", "to", "(", "self", ".", "device", ")", "# Target domain labels.", "\n", "label_org", "=", "label_org", ".", "to", "(", "self", ".", "device", ")", "# Labels for computing classification loss.", "\n", "label_trg", "=", "label_trg", ".", "to", "(", "self", ".", "device", ")", "# Labels for computing classification loss.", "\n", "\n", "# =================================================================================== #", "\n", "#                             2. Train the discriminator                              #", "\n", "# =================================================================================== #", "\n", "\n", "# Compute loss with real images.", "\n", "out_src", ",", "out_cls", "=", "self", ".", "D", "(", "x_real", ")", "\n", "d_loss_real", "=", "-", "torch", ".", "mean", "(", "out_src", ")", "\n", "d_loss_cls", "=", "self", ".", "classification_loss", "(", "out_cls", ",", "label_org", ",", "self", ".", "dataset", ")", "\n", "\n", "# Compute loss with fake images.", "\n", "x_fake", ",", "attention_mask", ",", "content_mask", "=", "self", ".", "G", "(", "x_real", ",", "c_trg", ")", "\n", "out_src", ",", "out_cls", "=", "self", ".", "D", "(", "x_fake", ".", "detach", "(", ")", ")", "\n", "d_loss_fake", "=", "torch", ".", "mean", "(", "out_src", ")", "\n", "\n", "# Compute loss for gradient penalty.", "\n", "alpha", "=", "torch", ".", "rand", "(", "x_real", ".", "size", "(", "0", ")", ",", "1", ",", "1", ",", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "x_hat", "=", "(", "alpha", "*", "x_real", ".", "data", "+", "(", "1", "-", "alpha", ")", "*", "x_fake", ".", "data", ")", ".", "requires_grad_", "(", "True", ")", "\n", "out_src", ",", "_", "=", "self", ".", "D", "(", "x_hat", ")", "\n", "d_loss_gp", "=", "self", ".", "gradient_penalty", "(", "out_src", ",", "x_hat", ")", "\n", "\n", "# Backward and optimize.", "\n", "d_loss", "=", "d_loss_real", "+", "d_loss_fake", "+", "self", ".", "lambda_cls", "*", "d_loss_cls", "+", "self", ".", "lambda_gp", "*", "d_loss_gp", "\n", "self", ".", "reset_grad", "(", ")", "\n", "d_loss", ".", "backward", "(", ")", "\n", "self", ".", "d_optimizer", ".", "step", "(", ")", "\n", "\n", "# Logging.", "\n", "loss", "=", "{", "}", "\n", "loss", "[", "'D/loss_real'", "]", "=", "d_loss_real", ".", "item", "(", ")", "\n", "loss", "[", "'D/loss_fake'", "]", "=", "d_loss_fake", ".", "item", "(", ")", "\n", "loss", "[", "'D/loss_cls'", "]", "=", "d_loss_cls", ".", "item", "(", ")", "\n", "loss", "[", "'D/loss_gp'", "]", "=", "d_loss_gp", ".", "item", "(", ")", "\n", "\n", "# =================================================================================== #", "\n", "#                               3. Train the generator                                #", "\n", "# =================================================================================== #", "\n", "\n", "if", "(", "i", "+", "1", ")", "%", "self", ".", "n_critic", "==", "0", ":", "\n", "# Original-to-target domain.", "\n", "                ", "x_fake", ",", "attention_mask", ",", "content_mask", "=", "self", ".", "G", "(", "x_real", ",", "c_trg", ")", "\n", "out_src", ",", "out_cls", "=", "self", ".", "D", "(", "x_fake", ")", "\n", "g_loss_fake", "=", "-", "torch", ".", "mean", "(", "out_src", ")", "\n", "g_loss_cls", "=", "self", ".", "classification_loss", "(", "out_cls", ",", "label_trg", ",", "self", ".", "dataset", ")", "\n", "\n", "# Target-to-original domain.", "\n", "x_reconst", ",", "_", ",", "_", "=", "self", ".", "G", "(", "x_fake", ",", "c_org", ")", "\n", "g_loss_rec", "=", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "x_real", "-", "x_reconst", ")", ")", "\n", "\n", "# Backward and optimize.", "\n", "g_loss", "=", "g_loss_fake", "+", "self", ".", "lambda_rec", "*", "g_loss_rec", "+", "self", ".", "lambda_cls", "*", "g_loss_cls", "\n", "self", ".", "reset_grad", "(", ")", "\n", "g_loss", ".", "backward", "(", ")", "\n", "self", ".", "g_optimizer", ".", "step", "(", ")", "\n", "\n", "# Logging.", "\n", "loss", "[", "'G/loss_fake'", "]", "=", "g_loss_fake", ".", "item", "(", ")", "\n", "loss", "[", "'G/loss_rec'", "]", "=", "g_loss_rec", ".", "item", "(", ")", "\n", "loss", "[", "'G/loss_cls'", "]", "=", "g_loss_cls", ".", "item", "(", ")", "\n", "\n", "# =================================================================================== #", "\n", "#                                 4. Miscellaneous                                    #", "\n", "# =================================================================================== #", "\n", "\n", "# Print out training information.", "\n", "", "if", "(", "i", "+", "1", ")", "%", "self", ".", "log_step", "==", "0", ":", "\n", "                ", "et", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "et", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "et", ")", ")", "[", ":", "-", "7", "]", "\n", "log", "=", "\"Elapsed [{}], Iteration [{}/{}]\"", ".", "format", "(", "et", ",", "i", "+", "1", ",", "self", ".", "num_iters", ")", "\n", "for", "tag", ",", "value", "in", "loss", ".", "items", "(", ")", ":", "\n", "                    ", "log", "+=", "\", {}: {:.4f}\"", ".", "format", "(", "tag", ",", "value", ")", "\n", "", "print", "(", "log", ")", "\n", "\n", "if", "self", ".", "use_tensorboard", ":", "\n", "                    ", "for", "tag", ",", "value", "in", "loss", ".", "items", "(", ")", ":", "\n", "                        ", "self", ".", "logger", ".", "scalar_summary", "(", "tag", ",", "value", ",", "i", "+", "1", ")", "\n", "\n", "# Translate fixed images for debugging.", "\n", "", "", "", "if", "(", "i", "+", "1", ")", "%", "self", ".", "sample_step", "==", "0", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "x_fake_list", "=", "[", "x_fixed", "]", "\n", "x_attention_list", "=", "[", "x_fixed", "]", "\n", "x_content_list", "=", "[", "x_fixed", "]", "\n", "for", "c_fixed", "in", "c_fixed_list", ":", "\n", "# x_fake_list.append(self.G(x_fixed, c_fixed))", "\n", "                        ", "fake", ",", "attention", ",", "content", "=", "self", ".", "G", "(", "x_fixed", ",", "c_fixed", ")", "\n", "attention", "=", "(", "attention", "-", "0.5", ")", "/", "0.5", "\n", "x_fake_list", ".", "append", "(", "fake", ")", "\n", "x_attention_list", ".", "append", "(", "attention", ")", "\n", "x_content_list", ".", "append", "(", "content", ")", "\n", "", "x_concat", "=", "torch", ".", "cat", "(", "x_fake_list", ",", "dim", "=", "3", ")", "\n", "attention_concat", "=", "torch", ".", "cat", "(", "x_attention_list", ",", "dim", "=", "3", ")", "\n", "content_concat", "=", "torch", ".", "cat", "(", "x_content_list", ",", "dim", "=", "3", ")", "\n", "sample_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "sample_dir", ",", "'{}-images.jpg'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "attention_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "sample_dir", ",", "'{}-attention.jpg'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "content_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "sample_dir", ",", "'{}-content.jpg'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "save_image", "(", "self", ".", "denorm", "(", "x_concat", ".", "data", ".", "cpu", "(", ")", ")", ",", "sample_path", ",", "nrow", "=", "1", ",", "padding", "=", "0", ")", "\n", "save_image", "(", "self", ".", "denorm", "(", "attention_concat", ".", "data", ".", "cpu", "(", ")", ")", ",", "attention_path", ",", "nrow", "=", "1", ",", "padding", "=", "0", ")", "\n", "save_image", "(", "self", ".", "denorm", "(", "content_concat", ".", "data", ".", "cpu", "(", ")", ")", ",", "content_path", ",", "nrow", "=", "1", ",", "padding", "=", "0", ")", "\n", "print", "(", "'Saved real and fake images into {}...'", ".", "format", "(", "sample_path", ")", ")", "\n", "\n", "# Save model checkpoints.", "\n", "", "", "if", "(", "i", "+", "1", ")", "%", "self", ".", "model_save_step", "==", "0", ":", "\n", "                ", "G_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_save_dir", ",", "'{}-G.ckpt'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "D_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_save_dir", ",", "'{}-D.ckpt'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "G", ".", "state_dict", "(", ")", ",", "G_path", ")", "\n", "torch", ".", "save", "(", "self", ".", "D", ".", "state_dict", "(", ")", ",", "D_path", ")", "\n", "print", "(", "'Saved model checkpoints into {}...'", ".", "format", "(", "self", ".", "model_save_dir", ")", ")", "\n", "\n", "# Decay learning rates.", "\n", "", "if", "(", "i", "+", "1", ")", "%", "self", ".", "lr_update_step", "==", "0", "and", "(", "i", "+", "1", ")", ">", "(", "self", ".", "num_iters", "-", "self", ".", "num_iters_decay", ")", ":", "\n", "                ", "g_lr", "-=", "(", "self", ".", "g_lr", "/", "float", "(", "self", ".", "num_iters_decay", ")", ")", "\n", "d_lr", "-=", "(", "self", ".", "d_lr", "/", "float", "(", "self", ".", "num_iters_decay", ")", ")", "\n", "self", ".", "update_lr", "(", "g_lr", ",", "d_lr", ")", "\n", "print", "(", "'Decayed learning rates, g_lr: {}, d_lr: {}.'", ".", "format", "(", "g_lr", ",", "d_lr", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.test": [[536, 581], ["solver.Solver.restore_model", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "x_real.to.to.to", "solver.Solver.create_labels", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "os.path.join", "torchvision.utils.save_image", "os.path.join", "torchvision.utils.save_image", "os.path.join", "torchvision.utils.save_image", "print", "solver.Solver.G", "x_fake_list.append", "x_attention_list.append", "x_content_list.append", "solver.Solver.denorm", "solver.Solver.denorm", "solver.Solver.denorm", "torch.cat.data.cpu", "torch.cat.data.cpu", "torch.cat.data.cpu", "torch.cat.data.cpu", "torch.cat.data.cpu", "torch.cat.data.cpu"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.restore_model", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.create_labels", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.save_image", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.save_image", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.save_image", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.denorm", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.denorm", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.solver.Solver.denorm"], ["", "", "", "def", "test", "(", "self", ")", ":", "\n", "        ", "\"\"\"Translate images using StarGAN trained on a single dataset.\"\"\"", "\n", "# Load the trained generator.", "\n", "self", ".", "restore_model", "(", "self", ".", "test_iters", ")", "\n", "\n", "# Set data loader.", "\n", "if", "self", ".", "dataset", "==", "'CelebA'", ":", "\n", "            ", "data_loader", "=", "self", ".", "celeba_loader", "\n", "", "elif", "self", ".", "dataset", "==", "'RaFD'", ":", "\n", "            ", "data_loader", "=", "self", ".", "rafd_loader", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", ",", "(", "x_real", ",", "c_org", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "\n", "# Prepare input images and target domain labels.", "\n", "                ", "x_real", "=", "x_real", ".", "to", "(", "self", ".", "device", ")", "\n", "c_trg_list", "=", "self", ".", "create_labels", "(", "c_org", ",", "self", ".", "c_dim", ",", "self", ".", "dataset", ",", "self", ".", "selected_attrs", ")", "\n", "\n", "# Translate images.", "\n", "x_fake_list", "=", "[", "x_real", "]", "\n", "x_attention_list", "=", "[", "x_real", "]", "\n", "x_content_list", "=", "[", "x_real", "]", "\n", "for", "c_trg", "in", "c_trg_list", ":", "\n", "# x_fake_list.append(self.G(x_real, c_trg))", "\n", "                    ", "fake", ",", "attention", ",", "content", "=", "self", ".", "G", "(", "x_real", ",", "c_trg", ")", "\n", "attention", "=", "(", "attention", "-", "0.5", ")", "/", "0.5", "\n", "x_fake_list", ".", "append", "(", "fake", ")", "\n", "x_attention_list", ".", "append", "(", "attention", ")", "\n", "x_content_list", ".", "append", "(", "content", ")", "\n", "\n", "# Save the translated images.", "\n", "", "x_concat", "=", "torch", ".", "cat", "(", "x_fake_list", ",", "dim", "=", "3", ")", "\n", "attention_concat", "=", "torch", ".", "cat", "(", "x_attention_list", ",", "dim", "=", "3", ")", "\n", "content_concat", "=", "torch", ".", "cat", "(", "x_content_list", ",", "dim", "=", "3", ")", "\n", "\n", "result_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "result_dir", ",", "'{}-images.jpg'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "save_image", "(", "self", ".", "denorm", "(", "x_concat", ".", "data", ".", "cpu", "(", ")", ")", ",", "result_path", ",", "nrow", "=", "1", ",", "padding", "=", "0", ")", "\n", "\n", "attention_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "result_dir", ",", "'{}-attention.jpg'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "save_image", "(", "self", ".", "denorm", "(", "attention_concat", ".", "data", ".", "cpu", "(", ")", ")", ",", "attention_path", ",", "nrow", "=", "1", ",", "padding", "=", "0", ")", "\n", "\n", "content_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "result_dir", ",", "'{}-content.jpg'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "save_image", "(", "self", ".", "denorm", "(", "content_concat", ".", "data", ".", "cpu", "(", ")", ")", ",", "content_path", ",", "nrow", "=", "1", ",", "padding", "=", "0", ")", "\n", "\n", "print", "(", "'Saved real and fake images into {}...'", ".", "format", "(", "result_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.logger.Logger.__init__": [[7, 10], ["tensorflow.summary.FileWriter"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "log_dir", ")", ":", "\n", "        ", "\"\"\"Initialize summary writer.\"\"\"", "\n", "self", ".", "writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "log_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.logger.Logger.scalar_summary": [[11, 15], ["tensorflow.Summary", "logger.Logger.writer.add_summary", "tensorflow.Summary.Value"], "methods", ["None"], ["", "def", "scalar_summary", "(", "self", ",", "tag", ",", "value", ",", "step", ")", ":", "\n", "        ", "\"\"\"Add scalar summary.\"\"\"", "\n", "summary", "=", "tf", ".", "Summary", "(", "value", "=", "[", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "tag", ",", "simple_value", "=", "value", ")", "]", ")", "\n", "self", ".", "writer", ".", "add_summary", "(", "summary", ",", "step", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.model.ResidualBlock.__init__": [[9, 17], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "dim_in", ",", "dim_out", ")", ":", "\n", "        ", "super", "(", "ResidualBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "dim_in", ",", "dim_out", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "dim_out", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "dim_out", ",", "dim_out", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "dim_out", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.model.ResidualBlock.forward": [[18, 20], ["model.ResidualBlock.main"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.main.main"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "+", "self", ".", "main", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.model.Generator.__init__": [[24, 54], ["torch.Module.__init__", "layers.append", "layers.append", "layers.append", "range", "range", "range", "layers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "layers.append", "layers.append", "layers.append", "layers.append", "layers.append", "layers.append", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "model.ResidualBlock", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "conv_dim", "=", "64", ",", "c_dim", "=", "5", ",", "repeat_num", "=", "6", ")", ":", "\n", "        ", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "nn", ".", "Conv2d", "(", "3", "+", "c_dim", ",", "conv_dim", ",", "kernel_size", "=", "7", ",", "stride", "=", "1", ",", "padding", "=", "3", ",", "bias", "=", "False", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "InstanceNorm2d", "(", "conv_dim", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "\n", "# Down-sampling layers.", "\n", "curr_dim", "=", "conv_dim", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "            ", "layers", ".", "append", "(", "nn", ".", "Conv2d", "(", "curr_dim", ",", "curr_dim", "*", "2", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "InstanceNorm2d", "(", "curr_dim", "*", "2", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "curr_dim", "=", "curr_dim", "*", "2", "\n", "\n", "# Bottleneck layers.", "\n", "", "for", "i", "in", "range", "(", "repeat_num", ")", ":", "\n", "            ", "layers", ".", "append", "(", "ResidualBlock", "(", "dim_in", "=", "curr_dim", ",", "dim_out", "=", "curr_dim", ")", ")", "\n", "\n", "# Up-sampling layers.", "\n", "", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "            ", "layers", ".", "append", "(", "nn", ".", "ConvTranspose2d", "(", "curr_dim", ",", "curr_dim", "//", "2", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "InstanceNorm2d", "(", "curr_dim", "//", "2", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "curr_dim", "=", "curr_dim", "//", "2", "\n", "\n", "", "layers", ".", "append", "(", "nn", ".", "Conv2d", "(", "curr_dim", ",", "3", "+", "1", ",", "kernel_size", "=", "7", ",", "stride", "=", "1", ",", "padding", "=", "3", ",", "bias", "=", "False", ")", ")", "\n", "# layers.append(nn.Tanh()) # ht", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.model.Generator.forward": [[55, 72], ["c.repeat.repeat.view", "c.repeat.repeat.repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.Generator.main", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "attention_mask.repeat.repeat.repeat", "c.repeat.repeat.size", "c.repeat.repeat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.main.main"], ["", "def", "forward", "(", "self", ",", "x", ",", "c", ")", ":", "\n", "# Replicate spatially and concatenate domain information.", "\n", "# Note that this type of label conditioning does not work at all if we use reflection padding in Conv2d.", "\n", "# This is because instance normalization ignores the shifting (or bias) effect.", "\n", "        ", "c", "=", "c", ".", "view", "(", "c", ".", "size", "(", "0", ")", ",", "c", ".", "size", "(", "1", ")", ",", "1", ",", "1", ")", "\n", "c", "=", "c", ".", "repeat", "(", "1", ",", "1", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", "\n", "input_image", "=", "x", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "c", "]", ",", "dim", "=", "1", ")", "\n", "# return self.main(x)", "\n", "# print(x.size())", "\n", "output", "=", "self", ".", "main", "(", "x", ")", "\n", "# print(output.size())", "\n", "attention_mask", "=", "F", ".", "sigmoid", "(", "output", "[", ":", ",", ":", "1", "]", ")", "\n", "content_mask", "=", "output", "[", ":", ",", "1", ":", "]", "\n", "attention_mask", "=", "attention_mask", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "result", "=", "content_mask", "*", "attention_mask", "+", "input_image", "*", "(", "1", "-", "attention_mask", ")", "\n", "return", "result", ",", "attention_mask", ",", "content_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.model.Discriminator.__init__": [[76, 92], ["torch.Module.__init__", "layers.append", "layers.append", "range", "int", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "layers.append", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "numpy.power"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "image_size", "=", "128", ",", "conv_dim", "=", "64", ",", "c_dim", "=", "5", ",", "repeat_num", "=", "6", ")", ":", "\n", "        ", "super", "(", "Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "nn", ".", "Conv2d", "(", "3", ",", "conv_dim", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "LeakyReLU", "(", "0.01", ")", ")", "\n", "\n", "curr_dim", "=", "conv_dim", "\n", "for", "i", "in", "range", "(", "1", ",", "repeat_num", ")", ":", "\n", "            ", "layers", ".", "append", "(", "nn", ".", "Conv2d", "(", "curr_dim", ",", "curr_dim", "*", "2", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "LeakyReLU", "(", "0.01", ")", ")", "\n", "curr_dim", "=", "curr_dim", "*", "2", "\n", "\n", "", "kernel_size", "=", "int", "(", "image_size", "/", "np", ".", "power", "(", "2", ",", "repeat_num", ")", ")", "\n", "self", ".", "main", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "curr_dim", ",", "1", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "curr_dim", ",", "c_dim", ",", "kernel_size", "=", "kernel_size", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.model.Discriminator.forward": [[93, 98], ["model.Discriminator.main", "model.Discriminator.conv1", "model.Discriminator.conv2", "model.Discriminator.view", "model.Discriminator.size", "model.Discriminator.size"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1-multi.main.main"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "main", "(", "x", ")", "\n", "out_src", "=", "self", ".", "conv1", "(", "h", ")", "\n", "out_cls", "=", "self", ".", "conv2", "(", "h", ")", "\n", "return", "out_src", ",", "out_cls", ".", "view", "(", "out_cls", ".", "size", "(", "0", ")", ",", "out_cls", ".", "size", "(", "1", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.Identity.forward": [[15, 17], ["None"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.GANLoss.__init__": [[220, 243], ["torch.Module.__init__", "networks.GANLoss.register_buffer", "networks.GANLoss.register_buffer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "gan_mode", ",", "target_real_label", "=", "1.0", ",", "target_fake_label", "=", "0.0", ")", ":", "\n", "        ", "\"\"\" Initialize the GANLoss class.\n\n        Parameters:\n            gan_mode (str) - - the type of GAN objective. It currently supports vanilla, lsgan, and wgangp.\n            target_real_label (bool) - - label for a real image\n            target_fake_label (bool) - - label of a fake image\n\n        Note: Do not use sigmoid as the last layer of Discriminator.\n        LSGAN needs no sigmoid. vanilla GANs will handle it with BCEWithLogitsLoss.\n        \"\"\"", "\n", "super", "(", "GANLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "'real_label'", ",", "torch", ".", "tensor", "(", "target_real_label", ")", ")", "\n", "self", ".", "register_buffer", "(", "'fake_label'", ",", "torch", ".", "tensor", "(", "target_fake_label", ")", ")", "\n", "self", ".", "gan_mode", "=", "gan_mode", "\n", "if", "gan_mode", "==", "'lsgan'", ":", "\n", "            ", "self", ".", "loss", "=", "nn", ".", "MSELoss", "(", ")", "\n", "", "elif", "gan_mode", "==", "'vanilla'", ":", "\n", "            ", "self", ".", "loss", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "", "elif", "gan_mode", "in", "[", "'wgangp'", "]", ":", "\n", "            ", "self", ".", "loss", "=", "None", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'gan mode %s not implemented'", "%", "gan_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.GANLoss.get_target_tensor": [[244, 260], ["target_tensor.expand_as"], "methods", ["None"], ["", "", "def", "get_target_tensor", "(", "self", ",", "prediction", ",", "target_is_real", ")", ":", "\n", "        ", "\"\"\"Create label tensors with the same size as the input.\n\n        Parameters:\n            prediction (tensor) - - tpyically the prediction from a discriminator\n            target_is_real (bool) - - if the ground truth label is for real images or fake images\n\n        Returns:\n            A label tensor filled with ground truth label, and with the size of the input\n        \"\"\"", "\n", "\n", "if", "target_is_real", ":", "\n", "            ", "target_tensor", "=", "self", ".", "real_label", "\n", "", "else", ":", "\n", "            ", "target_tensor", "=", "self", ".", "fake_label", "\n", "", "return", "target_tensor", ".", "expand_as", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.GANLoss.__call__": [[261, 280], ["networks.GANLoss.get_target_tensor", "networks.GANLoss.loss", "prediction.mean", "prediction.mean"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.GANLoss.get_target_tensor"], ["", "def", "__call__", "(", "self", ",", "prediction", ",", "target_is_real", ")", ":", "\n", "        ", "\"\"\"Calculate loss given Discriminator's output and grount truth labels.\n\n        Parameters:\n            prediction (tensor) - - tpyically the prediction output from a discriminator\n            target_is_real (bool) - - if the ground truth label is for real images or fake images\n\n        Returns:\n            the calculated loss.\n        \"\"\"", "\n", "if", "self", ".", "gan_mode", "in", "[", "'lsgan'", ",", "'vanilla'", "]", ":", "\n", "            ", "target_tensor", "=", "self", ".", "get_target_tensor", "(", "prediction", ",", "target_is_real", ")", "\n", "loss", "=", "self", ".", "loss", "(", "prediction", ",", "target_tensor", ")", "\n", "", "elif", "self", ".", "gan_mode", "==", "'wgangp'", ":", "\n", "            ", "if", "target_is_real", ":", "\n", "                ", "loss", "=", "-", "prediction", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "prediction", ".", "mean", "(", ")", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.ResnetGenerator.__init__": [[325, 374], ["torch.Module.__init__", "range", "range", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "networks.ResnetBlock", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "int", "int"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ",", "n_blocks", "=", "6", ",", "padding_type", "=", "'reflect'", ")", ":", "\n", "        ", "\"\"\"Construct a Resnet-based generator\n\n        Parameters:\n            input_nc (int)      -- the number of channels in input images\n            output_nc (int)     -- the number of channels in output images\n            ngf (int)           -- the number of filters in the last conv layer\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers\n            n_blocks (int)      -- the number of ResNet blocks\n            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n        \"\"\"", "\n", "assert", "(", "n_blocks", ">=", "0", ")", "\n", "super", "(", "ResnetGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "model", "=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", ",", "\n", "nn", ".", "Conv2d", "(", "input_nc", ",", "ngf", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "n_downsampling", "=", "2", "\n", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add downsampling layers", "\n", "            ", "mult", "=", "2", "**", "i", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", "*", "mult", ",", "ngf", "*", "mult", "*", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", "*", "mult", "*", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "", "mult", "=", "2", "**", "n_downsampling", "\n", "for", "i", "in", "range", "(", "n_blocks", ")", ":", "# add ResNet blocks", "\n", "\n", "            ", "model", "+=", "[", "ResnetBlock", "(", "ngf", "*", "mult", ",", "padding_type", "=", "padding_type", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "use_bias", "=", "use_bias", ")", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add upsampling layers", "\n", "            ", "mult", "=", "2", "**", "(", "n_downsampling", "-", "i", ")", "\n", "model", "+=", "[", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "mult", ",", "int", "(", "ngf", "*", "mult", "/", "2", ")", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "output_padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "int", "(", "ngf", "*", "mult", "/", "2", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "", "model", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", "]", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", ",", "output_nc", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ")", "]", "\n", "model", "+=", "[", "nn", ".", "Tanh", "(", ")", "]", "\n", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.ResnetGenerator.forward": [[375, 378], ["networks.ResnetGenerator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward\"\"\"", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.ResnetGenerator_our.__init__": [[381, 433], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "networks.ResnetGenerator_our.resnet_blocks.append", "networks.ResnetGenerator_our.resnet_blocks[].weight_init", "networks.resnet_block"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.resnet_block.weight_init"], ["    ", "def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "ngf", "=", "64", ",", "n_blocks", "=", "9", ")", ":", "\n", "        ", "super", "(", "ResnetGenerator_our", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_nc", "=", "input_nc", "\n", "self", ".", "output_nc", "=", "output_nc", "\n", "self", ".", "ngf", "=", "ngf", "\n", "self", ".", "nb", "=", "n_blocks", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "input_nc", ",", "ngf", ",", "7", ",", "1", ",", "0", ")", "\n", "self", ".", "conv1_norm", "=", "nn", ".", "InstanceNorm2d", "(", "ngf", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "ngf", ",", "ngf", "*", "2", ",", "3", ",", "2", ",", "1", ")", "\n", "self", ".", "conv2_norm", "=", "nn", ".", "InstanceNorm2d", "(", "ngf", "*", "2", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "ngf", "*", "2", ",", "ngf", "*", "4", ",", "3", ",", "2", ",", "1", ")", "\n", "self", ".", "conv3_norm", "=", "nn", ".", "InstanceNorm2d", "(", "ngf", "*", "4", ")", "\n", "\n", "self", ".", "resnet_blocks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_blocks", ")", ":", "\n", "            ", "self", ".", "resnet_blocks", ".", "append", "(", "resnet_block", "(", "ngf", "*", "4", ",", "3", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "resnet_blocks", "[", "i", "]", ".", "weight_init", "(", "0", ",", "0.02", ")", "\n", "\n", "", "self", ".", "resnet_blocks", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "resnet_blocks", ")", "\n", "\n", "# self.resnet_blocks1 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks1.weight_init(0, 0.02)", "\n", "# self.resnet_blocks2 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks2.weight_init(0, 0.02)", "\n", "# self.resnet_blocks3 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks3.weight_init(0, 0.02)", "\n", "# self.resnet_blocks4 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks4.weight_init(0, 0.02)", "\n", "# self.resnet_blocks5 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks5.weight_init(0, 0.02)", "\n", "# self.resnet_blocks6 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks6.weight_init(0, 0.02)", "\n", "# self.resnet_blocks7 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks7.weight_init(0, 0.02)", "\n", "# self.resnet_blocks8 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks8.weight_init(0, 0.02)", "\n", "# self.resnet_blocks9 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks9.weight_init(0, 0.02)", "\n", "\n", "self", ".", "deconv1_content", "=", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "4", ",", "ngf", "*", "2", ",", "3", ",", "2", ",", "1", ",", "1", ")", "\n", "self", ".", "deconv1_norm_content", "=", "nn", ".", "InstanceNorm2d", "(", "ngf", "*", "2", ")", "\n", "self", ".", "deconv2_content", "=", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "2", ",", "ngf", ",", "3", ",", "2", ",", "1", ",", "1", ")", "\n", "self", ".", "deconv2_norm_content", "=", "nn", ".", "InstanceNorm2d", "(", "ngf", ")", "\n", "self", ".", "deconv3_content", "=", "nn", ".", "Conv2d", "(", "ngf", ",", "30", ",", "7", ",", "1", ",", "0", ")", "\n", "\n", "self", ".", "deconv1_attention", "=", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "4", ",", "ngf", "*", "2", ",", "3", ",", "2", ",", "1", ",", "1", ")", "\n", "self", ".", "deconv1_norm_attention", "=", "nn", ".", "InstanceNorm2d", "(", "ngf", "*", "2", ")", "\n", "self", ".", "deconv2_attention", "=", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "2", ",", "ngf", ",", "3", ",", "2", ",", "1", ",", "1", ")", "\n", "self", ".", "deconv2_norm_attention", "=", "nn", ".", "InstanceNorm2d", "(", "ngf", ")", "\n", "self", ".", "deconv3_attention", "=", "nn", ".", "Conv2d", "(", "ngf", ",", "10", ",", "1", ",", "1", ",", "0", ")", "\n", "\n", "self", ".", "tanh", "=", "torch", ".", "nn", ".", "Tanh", "(", ")", "\n", "# weight_init", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.ResnetGenerator_our.weight_init": [[434, 437], ["networks.normal_init"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.normal_init"], ["", "def", "weight_init", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "_modules", ":", "\n", "            ", "normal_init", "(", "self", ".", "_modules", "[", "m", "]", ",", "mean", ",", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.ResnetGenerator_our.forward": [[439, 518], ["torch.pad", "torch.pad", "torch.pad", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "networks.ResnetGenerator_our.resnet_blocks", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.pad", "torch.pad", "torch.pad", "networks.ResnetGenerator_our.deconv3_content", "networks.ResnetGenerator_our.tanh", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "networks.ResnetGenerator_our.deconv3_attention", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax.", "torch.nn.Softmax.", "torch.nn.Softmax.", "attention1_.repeat", "attention2_.repeat", "attention3_.repeat", "attention4_.repeat", "attention5_.repeat", "attention6_.repeat", "attention7_.repeat", "attention8_.repeat", "attention9_.repeat", "attention10_.repeat", "networks.ResnetGenerator_our.conv1_norm", "networks.ResnetGenerator_our.conv2_norm", "networks.ResnetGenerator_our.conv3_norm", "networks.ResnetGenerator_our.deconv1_norm_content", "networks.ResnetGenerator_our.deconv2_norm_content", "networks.ResnetGenerator_our.deconv1_norm_attention", "networks.ResnetGenerator_our.deconv2_norm_attention", "networks.ResnetGenerator_our.conv1", "networks.ResnetGenerator_our.conv2", "networks.ResnetGenerator_our.conv3", "networks.ResnetGenerator_our.deconv1_content", "networks.ResnetGenerator_our.deconv2_content", "networks.ResnetGenerator_our.deconv1_attention", "networks.ResnetGenerator_our.deconv2_attention"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "x", "=", "F", ".", "pad", "(", "input", ",", "(", "3", ",", "3", ",", "3", ",", "3", ")", ",", "'reflect'", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1_norm", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv2_norm", "(", "self", ".", "conv2", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv3_norm", "(", "self", ".", "conv3", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "resnet_blocks", "(", "x", ")", "\n", "# x = self.resnet_blocks1(x)", "\n", "# x = self.resnet_blocks2(x)", "\n", "# x = self.resnet_blocks3(x)", "\n", "# x = self.resnet_blocks4(x)", "\n", "# x = self.resnet_blocks5(x)", "\n", "# x = self.resnet_blocks6(x)", "\n", "# x = self.resnet_blocks7(x)", "\n", "# x = self.resnet_blocks8(x)", "\n", "# x = self.resnet_blocks9(x)", "\n", "x_content", "=", "F", ".", "relu", "(", "self", ".", "deconv1_norm_content", "(", "self", ".", "deconv1_content", "(", "x", ")", ")", ")", "\n", "x_content", "=", "F", ".", "relu", "(", "self", ".", "deconv2_norm_content", "(", "self", ".", "deconv2_content", "(", "x_content", ")", ")", ")", "\n", "x_content", "=", "F", ".", "pad", "(", "x_content", ",", "(", "3", ",", "3", ",", "3", ",", "3", ")", ",", "'reflect'", ")", "\n", "content", "=", "self", ".", "deconv3_content", "(", "x_content", ")", "\n", "image", "=", "self", ".", "tanh", "(", "content", ")", "\n", "image1", "=", "image", "[", ":", ",", "0", ":", "3", ",", ":", ",", ":", "]", "\n", "# print(image1.size()) # [1, 3, 256, 256]", "\n", "image2", "=", "image", "[", ":", ",", "3", ":", "6", ",", ":", ",", ":", "]", "\n", "image3", "=", "image", "[", ":", ",", "6", ":", "9", ",", ":", ",", ":", "]", "\n", "image4", "=", "image", "[", ":", ",", "9", ":", "12", ",", ":", ",", ":", "]", "\n", "image5", "=", "image", "[", ":", ",", "12", ":", "15", ",", ":", ",", ":", "]", "\n", "image6", "=", "image", "[", ":", ",", "15", ":", "18", ",", ":", ",", ":", "]", "\n", "image7", "=", "image", "[", ":", ",", "18", ":", "21", ",", ":", ",", ":", "]", "\n", "image8", "=", "image", "[", ":", ",", "21", ":", "24", ",", ":", ",", ":", "]", "\n", "image9", "=", "image", "[", ":", ",", "24", ":", "27", ",", ":", ",", ":", "]", "\n", "image10", "=", "image", "[", ":", ",", "27", ":", "30", ",", ":", ",", ":", "]", "\n", "\n", "x_attention", "=", "F", ".", "relu", "(", "self", ".", "deconv1_norm_attention", "(", "self", ".", "deconv1_attention", "(", "x", ")", ")", ")", "\n", "x_attention", "=", "F", ".", "relu", "(", "self", ".", "deconv2_norm_attention", "(", "self", ".", "deconv2_attention", "(", "x_attention", ")", ")", ")", "\n", "# x_attention = F.pad(x_attention, (3, 3, 3, 3), 'reflect')", "\n", "# print(x_attention.size()) [1, 64, 256, 256]", "\n", "attention", "=", "self", ".", "deconv3_attention", "(", "x_attention", ")", "\n", "\n", "softmax_", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "attention", "=", "softmax_", "(", "attention", ")", "\n", "\n", "attention1_", "=", "attention", "[", ":", ",", "0", ":", "1", ",", ":", ",", ":", "]", "\n", "attention2_", "=", "attention", "[", ":", ",", "1", ":", "2", ",", ":", ",", ":", "]", "\n", "attention3_", "=", "attention", "[", ":", ",", "2", ":", "3", ",", ":", ",", ":", "]", "\n", "attention4_", "=", "attention", "[", ":", ",", "3", ":", "4", ",", ":", ",", ":", "]", "\n", "attention5_", "=", "attention", "[", ":", ",", "4", ":", "5", ",", ":", ",", ":", "]", "\n", "attention6_", "=", "attention", "[", ":", ",", "5", ":", "6", ",", ":", ",", ":", "]", "\n", "attention7_", "=", "attention", "[", ":", ",", "6", ":", "7", ",", ":", ",", ":", "]", "\n", "attention8_", "=", "attention", "[", ":", ",", "7", ":", "8", ",", ":", ",", ":", "]", "\n", "attention9_", "=", "attention", "[", ":", ",", "8", ":", "9", ",", ":", ",", ":", "]", "\n", "attention10_", "=", "attention", "[", ":", ",", "9", ":", "10", ",", ":", ",", ":", "]", "\n", "\n", "attention1", "=", "attention1_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "# print(attention1.size())", "\n", "attention2", "=", "attention2_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "attention3", "=", "attention3_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "attention4", "=", "attention4_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "attention5", "=", "attention5_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "attention6", "=", "attention6_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "attention7", "=", "attention7_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "attention8", "=", "attention8_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "attention9", "=", "attention9_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "attention10", "=", "attention10_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "\n", "output1", "=", "image1", "*", "attention1", "\n", "output2", "=", "image2", "*", "attention2", "\n", "output3", "=", "image3", "*", "attention3", "\n", "output4", "=", "image4", "*", "attention4", "\n", "output5", "=", "image5", "*", "attention5", "\n", "output6", "=", "image6", "*", "attention6", "\n", "output7", "=", "image7", "*", "attention7", "\n", "output8", "=", "image8", "*", "attention8", "\n", "output9", "=", "image9", "*", "attention9", "\n", "output10", "=", "image10", "*", "attention10", "\n", "# output10 = input * attention10", "\n", "\n", "o", "=", "output1", "+", "output2", "+", "output3", "+", "output4", "+", "output5", "+", "output6", "+", "output7", "+", "output8", "+", "output9", "+", "output10", "\n", "\n", "return", "o", ",", "output1", ",", "output2", ",", "output3", ",", "output4", ",", "output5", ",", "output6", ",", "output7", ",", "output8", ",", "output9", ",", "output10", ",", "attention1", ",", "attention2", ",", "attention3", ",", "attention4", ",", "attention5", ",", "attention6", ",", "attention7", ",", "attention8", ",", "attention9", ",", "attention10", ",", "image1", ",", "image2", ",", "image3", ",", "image4", ",", "image5", ",", "image6", ",", "image7", ",", "image8", ",", "image9", ",", "image10", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.resnet_block.__init__": [[521, 531], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ",", "kernel", ",", "stride", ",", "padding", ")", ":", "\n", "        ", "super", "(", "resnet_block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "channel", "=", "channel", "\n", "self", ".", "kernel", "=", "kernel", "\n", "self", ".", "strdie", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "channel", ",", "channel", ",", "kernel", ",", "stride", ",", "0", ")", "\n", "self", ".", "conv1_norm", "=", "nn", ".", "InstanceNorm2d", "(", "channel", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "channel", ",", "channel", ",", "kernel", ",", "stride", ",", "0", ")", "\n", "self", ".", "conv2_norm", "=", "nn", ".", "InstanceNorm2d", "(", "channel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.resnet_block.weight_init": [[533, 536], ["networks.normal_init"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.normal_init"], ["", "def", "weight_init", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "_modules", ":", "\n", "            ", "normal_init", "(", "self", ".", "_modules", "[", "m", "]", ",", "mean", ",", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.resnet_block.forward": [[537, 544], ["torch.pad", "torch.pad", "torch.pad", "torch.relu", "torch.relu", "torch.relu", "torch.pad", "torch.pad", "torch.pad", "networks.resnet_block.conv2_norm", "networks.resnet_block.conv1_norm", "networks.resnet_block.conv2", "networks.resnet_block.conv1"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "x", "=", "F", ".", "pad", "(", "input", ",", "(", "self", ".", "padding", ",", "self", ".", "padding", ",", "self", ".", "padding", ",", "self", ".", "padding", ")", ",", "'reflect'", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1_norm", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "self", ".", "padding", ",", "self", ".", "padding", ",", "self", ".", "padding", ",", "self", ".", "padding", ")", ",", "'reflect'", ")", "\n", "x", "=", "self", ".", "conv2_norm", "(", "self", ".", "conv2", "(", "x", ")", ")", "\n", "\n", "return", "input", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.ResnetBlock.__init__": [[553, 563], ["torch.Module.__init__", "networks.ResnetBlock.build_conv_block"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.ResnetBlock.build_conv_block"], ["def", "__init__", "(", "self", ",", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", ":", "\n", "        ", "\"\"\"Initialize the Resnet block\n\n        A resnet block is a conv block with skip connections\n        We construct a conv block with build_conv_block function,\n        and implement skip connections in <forward> function.\n        Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n        \"\"\"", "\n", "super", "(", "ResnetBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_block", "=", "self", ".", "build_conv_block", "(", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.ResnetBlock.build_conv_block": [[564, 603], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "NotImplementedError", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "NotImplementedError"], "methods", ["None"], ["", "def", "build_conv_block", "(", "self", ",", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", ":", "\n", "        ", "\"\"\"Construct a convolutional block.\n\n        Parameters:\n            dim (int)           -- the number of channels in the conv layer.\n            padding_type (str)  -- the name of padding layer: reflect | replicate | zero\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers.\n            use_bias (bool)     -- if the conv layer uses bias or not\n\n        Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU))\n        \"\"\"", "\n", "conv_block", "=", "[", "]", "\n", "p", "=", "0", "\n", "if", "padding_type", "==", "'reflect'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'replicate'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReplicationPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'zero'", ":", "\n", "            ", "p", "=", "1", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'padding [%s] is not implemented'", "%", "padding_type", ")", "\n", "\n", "", "conv_block", "+=", "[", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "3", ",", "padding", "=", "p", ",", "bias", "=", "use_bias", ")", ",", "norm_layer", "(", "dim", ")", ",", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "if", "use_dropout", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "Dropout", "(", "0.5", ")", "]", "\n", "\n", "", "p", "=", "0", "\n", "if", "padding_type", "==", "'reflect'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'replicate'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReplicationPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'zero'", ":", "\n", "            ", "p", "=", "1", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'padding [%s] is not implemented'", "%", "padding_type", ")", "\n", "", "conv_block", "+=", "[", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "3", ",", "padding", "=", "p", ",", "bias", "=", "use_bias", ")", ",", "norm_layer", "(", "dim", ")", "]", "\n", "\n", "return", "nn", ".", "Sequential", "(", "*", "conv_block", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.ResnetBlock.forward": [[604, 608], ["networks.ResnetBlock.conv_block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward function (with skip connections)\"\"\"", "\n", "out", "=", "x", "+", "self", ".", "conv_block", "(", "x", ")", "# add skip connections", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.UnetGenerator.__init__": [[613, 636], ["torch.Module.__init__", "networks.UnetSkipConnectionBlock", "range", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "num_downs", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Unet generator\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            output_nc (int) -- the number of channels in output images\n            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n                                image of size 128x128 will become of size 1x1 # at the bottleneck\n            ngf (int)       -- the number of filters in the last conv layer\n            norm_layer      -- normalization layer\n\n        We construct the U-Net from the innermost layer to the outermost layer.\n        It is a recursive process.\n        \"\"\"", "\n", "super", "(", "UnetGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# construct unet structure", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "8", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "None", ",", "norm_layer", "=", "norm_layer", ",", "innermost", "=", "True", ")", "# add the innermost layer", "\n", "for", "i", "in", "range", "(", "num_downs", "-", "5", ")", ":", "# add intermediate layers with ngf * 8 filters", "\n", "            ", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "8", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ")", "\n", "# gradually reduce the number of filters from ngf * 8 to ngf", "\n", "", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "4", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ")", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "2", ",", "ngf", "*", "4", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ")", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", ",", "ngf", "*", "2", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "model", "=", "UnetSkipConnectionBlock", "(", "output_nc", ",", "ngf", ",", "input_nc", "=", "input_nc", ",", "submodule", "=", "unet_block", ",", "outermost", "=", "True", ",", "norm_layer", "=", "norm_layer", ")", "# add the outermost layer", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.UnetGenerator.forward": [[637, 640], ["networks.UnetGenerator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward\"\"\"", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.UnetSkipConnectionBlock.__init__": [[648, 704], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "norm_layer", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "outer_nc", ",", "inner_nc", ",", "input_nc", "=", "None", ",", "\n", "submodule", "=", "None", ",", "outermost", "=", "False", ",", "innermost", "=", "False", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Unet submodule with skip connections.\n\n        Parameters:\n            outer_nc (int) -- the number of filters in the outer conv layer\n            inner_nc (int) -- the number of filters in the inner conv layer\n            input_nc (int) -- the number of channels in input images/features\n            submodule (UnetSkipConnectionBlock) -- previously defined submodules\n            outermost (bool)    -- if this module is the outermost module\n            innermost (bool)    -- if this module is the innermost module\n            norm_layer          -- normalization layer\n            user_dropout (bool) -- if use dropout layers.\n        \"\"\"", "\n", "super", "(", "UnetSkipConnectionBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "outermost", "=", "outermost", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "", "if", "input_nc", "is", "None", ":", "\n", "            ", "input_nc", "=", "outer_nc", "\n", "", "downconv", "=", "nn", ".", "Conv2d", "(", "input_nc", ",", "inner_nc", ",", "kernel_size", "=", "4", ",", "\n", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "downrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "downnorm", "=", "norm_layer", "(", "inner_nc", ")", "\n", "uprelu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "upnorm", "=", "norm_layer", "(", "outer_nc", ")", "\n", "\n", "if", "outermost", ":", "\n", "            ", "upconv", "=", "nn", ".", "ConvTranspose2d", "(", "inner_nc", "*", "2", ",", "outer_nc", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ")", "\n", "down", "=", "[", "downconv", "]", "\n", "up", "=", "[", "uprelu", ",", "upconv", ",", "nn", ".", "Tanh", "(", ")", "]", "\n", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "\n", "", "elif", "innermost", ":", "\n", "            ", "upconv", "=", "nn", ".", "ConvTranspose2d", "(", "inner_nc", ",", "outer_nc", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "down", "=", "[", "downrelu", ",", "downconv", "]", "\n", "up", "=", "[", "uprelu", ",", "upconv", ",", "upnorm", "]", "\n", "model", "=", "down", "+", "up", "\n", "", "else", ":", "\n", "            ", "upconv", "=", "nn", ".", "ConvTranspose2d", "(", "inner_nc", "*", "2", ",", "outer_nc", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "down", "=", "[", "downrelu", ",", "downconv", ",", "downnorm", "]", "\n", "up", "=", "[", "uprelu", ",", "upconv", ",", "upnorm", "]", "\n", "\n", "if", "use_dropout", ":", "\n", "                ", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "+", "[", "nn", ".", "Dropout", "(", "0.5", ")", "]", "\n", "", "else", ":", "\n", "                ", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "\n", "\n", "", "", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.UnetSkipConnectionBlock.forward": [[705, 710], ["networks.UnetSkipConnectionBlock.model", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks.UnetSkipConnectionBlock.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "outermost", ":", "\n", "            ", "return", "self", ".", "model", "(", "x", ")", "\n", "", "else", ":", "# add skip connections", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "x", ",", "self", ".", "model", "(", "x", ")", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.NLayerDiscriminator.__init__": [[715, 754], ["torch.Module.__init__", "range", "min", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "min", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "ndf", "=", "64", ",", "n_layers", "=", "3", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "\"\"\"Construct a PatchGAN discriminator\n\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            ndf (int)       -- the number of filters in the last conv layer\n            n_layers (int)  -- the number of conv layers in the discriminator\n            norm_layer      -- normalization layer\n        \"\"\"", "\n", "super", "(", "NLayerDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "# no need to use bias as BatchNorm2d has affine parameters", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "kw", "=", "4", "\n", "padw", "=", "1", "\n", "sequence", "=", "[", "nn", ".", "Conv2d", "(", "input_nc", ",", "ndf", ",", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ")", ",", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "]", "\n", "nf_mult", "=", "1", "\n", "nf_mult_prev", "=", "1", "\n", "for", "n", "in", "range", "(", "1", ",", "n_layers", ")", ":", "# gradually increase the number of filters", "\n", "            ", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "nf_mult", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n_layers", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "nf_mult", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "sequence", "+=", "[", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult", ",", "1", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ")", "]", "# output 1 channel prediction map", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.NLayerDiscriminator.forward": [[755, 758], ["networks.NLayerDiscriminator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward.\"\"\"", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.PixelDiscriminator.__init__": [[763, 786], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "ndf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "\"\"\"Construct a 1x1 PatchGAN discriminator\n\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            ndf (int)       -- the number of filters in the last conv layer\n            norm_layer      -- normalization layer\n        \"\"\"", "\n", "super", "(", "PixelDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "# no need to use bias as BatchNorm2d has affine parameters", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "self", ".", "net", "=", "[", "\n", "nn", ".", "Conv2d", "(", "input_nc", ",", "ndf", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ndf", ",", "ndf", "*", "2", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "2", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "2", ",", "1", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", "]", "\n", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "net", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.PixelDiscriminator.forward": [[787, 790], ["networks.PixelDiscriminator.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward.\"\"\"", "\n", "return", "self", ".", "net", "(", "input", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.get_norm_layer": [[19, 37], ["functools.partial", "functools.partial", "NotImplementedError", "networks.Identity"], "function", ["None"], ["", "", "def", "get_norm_layer", "(", "norm_type", "=", "'instance'", ")", ":", "\n", "    ", "\"\"\"Return a normalization layer\n\n    Parameters:\n        norm_type (str) -- the name of the normalization layer: batch | instance | none\n\n    For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n    For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics.\n    \"\"\"", "\n", "if", "norm_type", "==", "'batch'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "BatchNorm2d", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "", "elif", "norm_type", "==", "'instance'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "InstanceNorm2d", ",", "affine", "=", "False", ",", "track_running_stats", "=", "False", ")", "\n", "", "elif", "norm_type", "==", "'none'", ":", "\n", "        ", "norm_layer", "=", "lambda", "x", ":", "Identity", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'normalization layer [%s] is not found'", "%", "norm_type", ")", "\n", "", "return", "norm_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.get_scheduler": [[39, 66], ["torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.ReduceLROnPlateau", "max", "float", "torch.optim.lr_scheduler.CosineAnnealingLR", "NotImplementedError"], "function", ["None"], ["", "def", "get_scheduler", "(", "optimizer", ",", "opt", ")", ":", "\n", "    ", "\"\"\"Return a learning rate scheduler\n\n    Parameters:\n        optimizer          -- the optimizer of the network\n        opt (option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\uff0e\u3000\n                              opt.lr_policy is the name of learning rate policy: linear | step | plateau | cosine\n\n    For 'linear', we keep the same learning rate for the first <opt.niter> epochs\n    and linearly decay the rate to zero over the next <opt.niter_decay> epochs.\n    For other schedulers (step, plateau, and cosine), we use the default PyTorch schedulers.\n    See https://pytorch.org/docs/stable/optim.html for more details.\n    \"\"\"", "\n", "if", "opt", ".", "lr_policy", "==", "'linear'", ":", "\n", "        ", "def", "lambda_rule", "(", "epoch", ")", ":", "\n", "            ", "lr_l", "=", "1.0", "-", "max", "(", "0", ",", "epoch", "+", "opt", ".", "epoch_count", "-", "opt", ".", "niter", ")", "/", "float", "(", "opt", ".", "niter_decay", "+", "1", ")", "\n", "return", "lr_l", "\n", "", "scheduler", "=", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lambda_rule", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'step'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "step_size", "=", "opt", ".", "lr_decay_iters", ",", "gamma", "=", "0.1", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'plateau'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "factor", "=", "0.2", ",", "threshold", "=", "0.01", ",", "patience", "=", "5", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'cosine'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "CosineAnnealingLR", "(", "optimizer", ",", "T_max", "=", "opt", ".", "niter", ",", "eta_min", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "return", "NotImplementedError", "(", "'learning rate policy [%s] is not implemented'", ",", "opt", ".", "lr_policy", ")", "\n", "", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.init_weights": [[68, 100], ["print", "net.apply", "hasattr", "torch.nn.init.normal_", "hasattr", "torch.nn.init.constant_", "classname.find", "torch.nn.init.normal_", "torch.nn.init.constant_", "classname.find", "classname.find", "torch.nn.init.xavier_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.orthogonal_", "NotImplementedError"], "function", ["None"], ["", "def", "init_weights", "(", "net", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ")", ":", "\n", "    ", "\"\"\"Initialize network weights.\n\n    Parameters:\n        net (network)   -- network to be initialized\n        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n\n    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n    work better for some applications. Feel free to try yourself.\n    \"\"\"", "\n", "def", "init_func", "(", "m", ")", ":", "# define the initialization function", "\n", "        ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "(", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", "or", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ")", ":", "\n", "            ", "if", "init_type", "==", "'normal'", ":", "\n", "                ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "0.0", ",", "init_gain", ")", "\n", "", "elif", "init_type", "==", "'xavier'", ":", "\n", "                ", "init", ".", "xavier_normal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "init_gain", ")", "\n", "", "elif", "init_type", "==", "'kaiming'", ":", "\n", "                ", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ".", "data", ",", "a", "=", "0", ",", "mode", "=", "'fan_in'", ")", "\n", "", "elif", "init_type", "==", "'orthogonal'", ":", "\n", "                ", "init", ".", "orthogonal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "init_gain", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'initialization method [%s] is not implemented'", "%", "init_type", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'BatchNorm2d'", ")", "!=", "-", "1", ":", "# BatchNorm Layer's weight is not a matrix; only normal distribution applies.", "\n", "            ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "1.0", ",", "init_gain", ")", "\n", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "\n", "", "", "print", "(", "'initialize network with %s'", "%", "init_type", ")", "\n", "net", ".", "apply", "(", "init_func", ")", "# apply the initialization function <init_func>", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.init_net": [[102, 119], ["networks.init_weights", "len", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.nn.DataParallel.to", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.init_weights"], ["", "def", "init_net", "(", "net", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n    Parameters:\n        net (network)      -- the network to be initialized\n        init_type (str)    -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n        gain (float)       -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n\n    Return an initialized network.\n    \"\"\"", "\n", "if", "len", "(", "gpu_ids", ")", ">", "0", ":", "\n", "        ", "assert", "(", "torch", ".", "cuda", ".", "is_available", "(", ")", ")", "\n", "# print(net)", "\n", "net", ".", "to", "(", "gpu_ids", "[", "0", "]", ")", "\n", "net", "=", "torch", ".", "nn", ".", "DataParallel", "(", "net", ",", "gpu_ids", ")", "# multi-GPUs", "\n", "", "init_weights", "(", "net", ",", "init_type", ",", "init_gain", "=", "init_gain", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.define_G": [[121, 164], ["networks.get_norm_layer", "networks.init_net", "networks.ResnetGenerator", "networks.ResnetGenerator", "networks.UnetGenerator", "networks.UnetGenerator", "networks.ResnetGenerator_our", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.init_net"], ["", "def", "define_G", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "netG", ",", "norm", "=", "'batch'", ",", "use_dropout", "=", "False", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Create a generator\n\n    Parameters:\n        input_nc (int) -- the number of channels in input images\n        output_nc (int) -- the number of channels in output images\n        ngf (int) -- the number of filters in the last conv layer\n        netG (str) -- the architecture's name: resnet_9blocks | resnet_6blocks | unet_256 | unet_128\n        norm (str) -- the name of normalization layers used in the network: batch | instance | none\n        use_dropout (bool) -- if use dropout layers.\n        init_type (str)    -- the name of our initialization method.\n        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n\n    Returns a generator\n\n    Our current implementation provides two types of generators:\n        U-Net: [unet_128] (for 128x128 input images) and [unet_256] (for 256x256 input images)\n        The original U-Net paper: https://arxiv.org/abs/1505.04597\n\n        Resnet-based generator: [resnet_6blocks] (with 6 Resnet blocks) and [resnet_9blocks] (with 9 Resnet blocks)\n        Resnet-based generator consists of several Resnet blocks between a few downsampling/upsampling operations.\n        We adapt Torch code from Justin Johnson's neural style transfer project (https://github.com/jcjohnson/fast-neural-style).\n\n\n    The generator has been initialized by <init_net>. It uses RELU for non-linearity.\n    \"\"\"", "\n", "net", "=", "None", "\n", "norm_layer", "=", "get_norm_layer", "(", "norm_type", "=", "norm", ")", "\n", "\n", "if", "netG", "==", "'resnet_9blocks'", ":", "\n", "        ", "net", "=", "ResnetGenerator", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "n_blocks", "=", "9", ")", "\n", "", "elif", "netG", "==", "'resnet_6blocks'", ":", "\n", "        ", "net", "=", "ResnetGenerator", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "n_blocks", "=", "6", ")", "\n", "", "elif", "netG", "==", "'unet_128'", ":", "\n", "        ", "net", "=", "UnetGenerator", "(", "input_nc", ",", "output_nc", ",", "7", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ")", "\n", "", "elif", "netG", "==", "'unet_256'", ":", "\n", "        ", "net", "=", "UnetGenerator", "(", "input_nc", ",", "output_nc", ",", "8", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ")", "\n", "", "elif", "netG", "==", "'our'", ":", "\n", "        ", "net", "=", "ResnetGenerator_our", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "n_blocks", "=", "9", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Generator model name [%s] is not recognized'", "%", "netG", ")", "\n", "", "return", "init_net", "(", "net", ",", "init_type", ",", "init_gain", ",", "gpu_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.define_D": [[166, 208], ["networks.get_norm_layer", "networks.init_net", "networks.NLayerDiscriminator", "networks.NLayerDiscriminator", "networks.PixelDiscriminator", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.init_net"], ["", "def", "define_D", "(", "input_nc", ",", "ndf", ",", "netD", ",", "n_layers_D", "=", "3", ",", "norm", "=", "'batch'", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Create a discriminator\n\n    Parameters:\n        input_nc (int)     -- the number of channels in input images\n        ndf (int)          -- the number of filters in the first conv layer\n        netD (str)         -- the architecture's name: basic | n_layers | pixel\n        n_layers_D (int)   -- the number of conv layers in the discriminator; effective when netD=='n_layers'\n        norm (str)         -- the type of normalization layers used in the network.\n        init_type (str)    -- the name of the initialization method.\n        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n\n    Returns a discriminator\n\n    Our current implementation provides three types of discriminators:\n        [basic]: 'PatchGAN' classifier described in the original pix2pix paper.\n        It can classify whether 70\u00d770 overlapping patches are real or fake.\n        Such a patch-level discriminator architecture has fewer parameters\n        than a full-image discriminator and can work on arbitrarily-sized images\n        in a fully convolutional fashion.\n\n        [n_layers]: With this mode, you cna specify the number of conv layers in the discriminator\n        with the parameter <n_layers_D> (default=3 as used in [basic] (PatchGAN).)\n\n        [pixel]: 1x1 PixelGAN discriminator can classify whether a pixel is real or not.\n        It encourages greater color diversity but has no effect on spatial statistics.\n\n    The discriminator has been initialized by <init_net>. It uses Leakly RELU for non-linearity.\n    \"\"\"", "\n", "net", "=", "None", "\n", "norm_layer", "=", "get_norm_layer", "(", "norm_type", "=", "norm", ")", "\n", "\n", "if", "netD", "==", "'basic'", ":", "# default PatchGAN classifier", "\n", "        ", "net", "=", "NLayerDiscriminator", "(", "input_nc", ",", "ndf", ",", "n_layers", "=", "3", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "elif", "netD", "==", "'n_layers'", ":", "# more options", "\n", "        ", "net", "=", "NLayerDiscriminator", "(", "input_nc", ",", "ndf", ",", "n_layers_D", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "elif", "netD", "==", "'pixel'", ":", "# classify if each pixel is real or fake", "\n", "        ", "net", "=", "PixelDiscriminator", "(", "input_nc", ",", "ndf", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Discriminator model name [%s] is not recognized'", "%", "netD", ")", "\n", "", "return", "init_net", "(", "net", ",", "init_type", ",", "init_gain", ",", "gpu_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.cal_gradient_penalty": [[282, 317], ["interpolatesv.requires_grad_", "netD", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "gradients[].view", "real_data.size", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.rand", "torch.rand", "torch.rand", "alpha.expand().contiguous().view.expand().contiguous().view", "NotImplementedError", "torch.ones", "torch.ones", "torch.ones", "alpha.expand().contiguous().view.expand().contiguous", "netD.size", "alpha.expand().contiguous().view.expand", "real_data.nelement"], "function", ["None"], ["", "", "def", "cal_gradient_penalty", "(", "netD", ",", "real_data", ",", "fake_data", ",", "device", ",", "type", "=", "'mixed'", ",", "constant", "=", "1.0", ",", "lambda_gp", "=", "10.0", ")", ":", "\n", "    ", "\"\"\"Calculate the gradient penalty loss, used in WGAN-GP paper https://arxiv.org/abs/1704.00028\n\n    Arguments:\n        netD (network)              -- discriminator network\n        real_data (tensor array)    -- real images\n        fake_data (tensor array)    -- generated images from the generator\n        device (str)                -- GPU / CPU: from torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')\n        type (str)                  -- if we mix real and fake data or not [real | fake | mixed].\n        constant (float)            -- the constant used in formula ( | |gradient||_2 - constant)^2\n        lambda_gp (float)           -- weight for this loss\n\n    Returns the gradient penalty loss\n    \"\"\"", "\n", "if", "lambda_gp", ">", "0.0", ":", "\n", "        ", "if", "type", "==", "'real'", ":", "# either use real images, fake images, or a linear interpolation of two.", "\n", "            ", "interpolatesv", "=", "real_data", "\n", "", "elif", "type", "==", "'fake'", ":", "\n", "            ", "interpolatesv", "=", "fake_data", "\n", "", "elif", "type", "==", "'mixed'", ":", "\n", "            ", "alpha", "=", "torch", ".", "rand", "(", "real_data", ".", "shape", "[", "0", "]", ",", "1", ",", "device", "=", "device", ")", "\n", "alpha", "=", "alpha", ".", "expand", "(", "real_data", ".", "shape", "[", "0", "]", ",", "real_data", ".", "nelement", "(", ")", "//", "real_data", ".", "shape", "[", "0", "]", ")", ".", "contiguous", "(", ")", ".", "view", "(", "*", "real_data", ".", "shape", ")", "\n", "interpolatesv", "=", "alpha", "*", "real_data", "+", "(", "(", "1", "-", "alpha", ")", "*", "fake_data", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'{} not implemented'", ".", "format", "(", "type", ")", ")", "\n", "", "interpolatesv", ".", "requires_grad_", "(", "True", ")", "\n", "disc_interpolates", "=", "netD", "(", "interpolatesv", ")", "\n", "gradients", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "disc_interpolates", ",", "inputs", "=", "interpolatesv", ",", "\n", "grad_outputs", "=", "torch", ".", "ones", "(", "disc_interpolates", ".", "size", "(", ")", ")", ".", "to", "(", "device", ")", ",", "\n", "create_graph", "=", "True", ",", "retain_graph", "=", "True", ",", "only_inputs", "=", "True", ")", "\n", "gradients", "=", "gradients", "[", "0", "]", ".", "view", "(", "real_data", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# flat the data", "\n", "gradient_penalty", "=", "(", "(", "(", "gradients", "+", "1e-16", ")", ".", "norm", "(", "2", ",", "dim", "=", "1", ")", "-", "constant", ")", "**", "2", ")", ".", "mean", "(", ")", "*", "lambda_gp", "# added eps", "\n", "return", "gradient_penalty", ",", "gradients", "\n", "", "else", ":", "\n", "        ", "return", "0.0", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.networks.normal_init": [[545, 549], ["isinstance", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_"], "function", ["None"], ["", "", "def", "normal_init", "(", "m", ",", "mean", ",", "std", ")", ":", "\n", "    ", "if", "isinstance", "(", "m", ",", "nn", ".", "ConvTranspose2d", ")", "or", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "mean", ",", "std", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.attention_gan_model.AttentionGANModel.modify_commandline_options": [[9, 18], ["parser.set_defaults", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", "=", "True", ")", ":", "\n", "        ", "parser", ".", "set_defaults", "(", "no_dropout", "=", "True", ")", "# default CycleGAN did not use dropout", "\n", "if", "is_train", ":", "\n", "            ", "parser", ".", "add_argument", "(", "'--lambda_A'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for cycle loss (A -> B -> A)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_B'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for cycle loss (B -> A -> B)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_identity'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'use identity mapping. Setting lambda_identity other than 0 has an effect of scaling the weight of the identity mapping loss. For example, if the weight of the identity loss should be 10 times smaller than the weight of the reconstruction loss, please set lambda_identity = 0.1'", ")", "\n", "\n", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.attention_gan_model.AttentionGANModel.__init__": [[19, 76], ["base_model.BaseModel.__init__", "networks.define_G", "networks.define_G", "visual_names_A.append", "visual_names_B.append", "networks.define_D", "networks.define_D", "util.image_pool.ImagePool", "util.image_pool.ImagePool", "networks.GANLoss().to", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.optim.Adam", "torch.optim.Adam", "attention_gan_model.AttentionGANModel.optimizers.append", "attention_gan_model.AttentionGANModel.optimizers.append", "itertools.chain", "itertools.chain", "networks.GANLoss", "attention_gan_model.AttentionGANModel.netG_A.parameters", "attention_gan_model.AttentionGANModel.netG_B.parameters", "attention_gan_model.AttentionGANModel.netD_A.parameters", "attention_gan_model.AttentionGANModel.netD_B.parameters"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.define_G", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.define_G", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.define_D", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.define_D"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the CycleGAN class.\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "BaseModel", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "# specify the training losses you want to print out. The training/test scripts will call <BaseModel.get_current_losses>", "\n", "self", ".", "loss_names", "=", "[", "'D_A'", ",", "'G_A'", ",", "'cycle_A'", ",", "'idt_A'", ",", "'D_B'", ",", "'G_B'", ",", "'cycle_B'", ",", "'idt_B'", "]", "\n", "# specify the images you want to save/display. The training/test scripts will call <BaseModel.get_current_visuals>", "\n", "visual_names_A", "=", "[", "'real_A'", ",", "'fake_B'", ",", "'rec_A'", ",", "'o1_b'", ",", "'o2_b'", ",", "'o3_b'", ",", "'o4_b'", ",", "'o5_b'", ",", "'o6_b'", ",", "'o7_b'", ",", "'o8_b'", ",", "'o9_b'", ",", "'o10_b'", ",", "\n", "'a1_b'", ",", "'a2_b'", ",", "'a3_b'", ",", "'a4_b'", ",", "'a5_b'", ",", "'a6_b'", ",", "'a7_b'", ",", "'a8_b'", ",", "'a9_b'", ",", "'a10_b'", ",", "'i1_b'", ",", "'i2_b'", ",", "'i3_b'", ",", "'i4_b'", ",", "'i5_b'", ",", "\n", "'i6_b'", ",", "'i7_b'", ",", "'i8_b'", ",", "'i9_b'", ",", "'i10_b'", "]", "\n", "visual_names_B", "=", "[", "'real_B'", ",", "'fake_A'", ",", "'rec_B'", ",", "'o1_a'", ",", "'o2_a'", ",", "'o3_a'", ",", "'o4_a'", ",", "'o5_a'", ",", "'o6_a'", ",", "'o7_a'", ",", "'o8_a'", ",", "'o9_a'", ",", "'o10_a'", ",", "\n", "'a1_a'", ",", "'a2_a'", ",", "'a3_a'", ",", "'a4_a'", ",", "'a5_a'", ",", "'a6_a'", ",", "'a7_a'", ",", "'a8_a'", ",", "'a9_a'", ",", "'a10_a'", ",", "'i1_a'", ",", "'i2_a'", ",", "'i3_a'", ",", "'i4_a'", ",", "'i5_a'", ",", "\n", "'i6_a'", ",", "'i7_a'", ",", "'i8_a'", ",", "'i9_a'", ",", "'i10_a'", "]", "\n", "if", "self", ".", "isTrain", "and", "self", ".", "opt", ".", "lambda_identity", ">", "0.0", ":", "# if identity loss is used, we also visualize idt_B=G_A(B) ad idt_A=G_A(B)", "\n", "            ", "visual_names_A", ".", "append", "(", "'idt_B'", ")", "\n", "visual_names_B", ".", "append", "(", "'idt_A'", ")", "\n", "\n", "", "if", "self", ".", "opt", ".", "saveDisk", ":", "\n", "            ", "self", ".", "visual_names", "=", "[", "'real_A'", ",", "'fake_B'", ",", "'a10_b'", ",", "'real_B'", ",", "'fake_A'", ",", "'a10_a'", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "visual_names", "=", "visual_names_A", "+", "visual_names_B", "# combine visualizations for A and B", "\n", "# specify the models you want to save to the disk. The training/test scripts will call <BaseModel.save_networks> and <BaseModel.load_networks>.", "\n", "", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "model_names", "=", "[", "'G_A'", ",", "'G_B'", ",", "'D_A'", ",", "'D_B'", "]", "\n", "", "else", ":", "# during test time, only load Gs", "\n", "            ", "self", ".", "model_names", "=", "[", "'G_A'", ",", "'G_B'", "]", "\n", "\n", "# define networks (both Generators and discriminators)", "\n", "# The naming is different from those used in the paper.", "\n", "# Code (vs. paper): G_A (G), G_B (F), D_A (D_Y), D_B (D_X)", "\n", "", "self", ".", "netG_A", "=", "networks", ".", "define_G", "(", "opt", ".", "input_nc", ",", "opt", ".", "output_nc", ",", "opt", ".", "ngf", ",", "'our'", ",", "opt", ".", "norm", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "self", ".", "netG_B", "=", "networks", ".", "define_G", "(", "opt", ".", "output_nc", ",", "opt", ".", "input_nc", ",", "opt", ".", "ngf", ",", "'our'", ",", "opt", ".", "norm", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "\n", "if", "self", ".", "isTrain", ":", "# define discriminators", "\n", "            ", "self", ".", "netD_A", "=", "networks", ".", "define_D", "(", "opt", ".", "output_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "opt", ".", "n_layers_D", ",", "opt", ".", "norm", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "self", ".", "netD_B", "=", "networks", ".", "define_D", "(", "opt", ".", "input_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "opt", ".", "n_layers_D", ",", "opt", ".", "norm", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "\n", "", "if", "self", ".", "isTrain", ":", "\n", "            ", "if", "opt", ".", "lambda_identity", ">", "0.0", ":", "# only works when input and output images have the same number of channels", "\n", "                ", "assert", "(", "opt", ".", "input_nc", "==", "opt", ".", "output_nc", ")", "\n", "", "self", ".", "fake_A_pool", "=", "ImagePool", "(", "opt", ".", "pool_size", ")", "# create image buffer to store previously generated images", "\n", "self", ".", "fake_B_pool", "=", "ImagePool", "(", "opt", ".", "pool_size", ")", "# create image buffer to store previously generated images", "\n", "# define loss functions", "\n", "self", ".", "criterionGAN", "=", "networks", ".", "GANLoss", "(", "opt", ".", "gan_mode", ")", ".", "to", "(", "self", ".", "device", ")", "# define GAN loss.", "\n", "self", ".", "criterionCycle", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "\n", "self", ".", "criterionIdt", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "\n", "# initialize optimizers; schedulers will be automatically created by function <BaseModel.setup>.", "\n", "self", ".", "optimizer_G", "=", "torch", ".", "optim", ".", "Adam", "(", "itertools", ".", "chain", "(", "self", ".", "netG_A", ".", "parameters", "(", ")", ",", "self", ".", "netG_B", ".", "parameters", "(", ")", ")", ",", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "self", ".", "optimizer_D", "=", "torch", ".", "optim", ".", "Adam", "(", "itertools", ".", "chain", "(", "self", ".", "netD_A", ".", "parameters", "(", ")", ",", "self", ".", "netD_B", ".", "parameters", "(", ")", ")", ",", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_G", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_D", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.attention_gan_model.AttentionGANModel.set_input": [[77, 87], ["input[].to", "input[].to"], "methods", ["None"], ["", "", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n        Parameters:\n            input (dict): include the data itself and its metadata information.\n        The option 'direction' can be used to swap domain A and domain B.\n        \"\"\"", "\n", "AtoB", "=", "self", ".", "opt", ".", "direction", "==", "'AtoB'", "\n", "self", ".", "real_A", "=", "input", "[", "'A'", "if", "AtoB", "else", "'B'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "real_B", "=", "input", "[", "'B'", "if", "AtoB", "else", "'A'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "image_paths", "=", "input", "[", "'A_paths'", "if", "AtoB", "else", "'B_paths'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.attention_gan_model.AttentionGANModel.forward": [[88, 104], ["attention_gan_model.AttentionGANModel.netG_A", "attention_gan_model.AttentionGANModel.netG_B", "attention_gan_model.AttentionGANModel.netG_B", "attention_gan_model.AttentionGANModel.netG_A"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"", "\n", "self", ".", "fake_B", ",", "self", ".", "o1_b", ",", "self", ".", "o2_b", ",", "self", ".", "o3_b", ",", "self", ".", "o4_b", ",", "self", ".", "o5_b", ",", "self", ".", "o6_b", ",", "self", ".", "o7_b", ",", "self", ".", "o8_b", ",", "self", ".", "o9_b", ",", "self", ".", "o10_b", ",", "self", ".", "a1_b", ",", "self", ".", "a2_b", ",", "self", ".", "a3_b", ",", "self", ".", "a4_b", ",", "self", ".", "a5_b", ",", "self", ".", "a6_b", ",", "self", ".", "a7_b", ",", "self", ".", "a8_b", ",", "self", ".", "a9_b", ",", "self", ".", "a10_b", ",", "self", ".", "i1_b", ",", "self", ".", "i2_b", ",", "self", ".", "i3_b", ",", "self", ".", "i4_b", ",", "self", ".", "i5_b", ",", "self", ".", "i6_b", ",", "self", ".", "i7_b", ",", "self", ".", "i8_b", ",", "self", ".", "i9_b", ",", "self", ".", "i10_b", "=", "self", ".", "netG_A", "(", "self", ".", "real_A", ")", "# G_A(A)", "\n", "self", ".", "rec_A", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "self", ".", "netG_B", "(", "self", ".", "fake_B", ")", "# G_B(G_A(A))", "\n", "self", ".", "fake_A", ",", "self", ".", "o1_a", ",", "self", ".", "o2_a", ",", "self", ".", "o3_a", ",", "self", ".", "o4_a", ",", "self", ".", "o5_a", ",", "self", ".", "o6_a", ",", "self", ".", "o7_a", ",", "self", ".", "o8_a", ",", "self", ".", "o9_a", ",", "self", ".", "o10_a", ",", "self", ".", "a1_a", ",", "self", ".", "a2_a", ",", "self", ".", "a3_a", ",", "self", ".", "a4_a", ",", "self", ".", "a5_a", ",", "self", ".", "a6_a", ",", "self", ".", "a7_a", ",", "self", ".", "a8_a", ",", "self", ".", "a9_a", ",", "self", ".", "a10_a", ",", "self", ".", "i1_a", ",", "self", ".", "i2_a", ",", "self", ".", "i3_a", ",", "self", ".", "i4_a", ",", "self", ".", "i5_a", ",", "self", ".", "i6_a", ",", "self", ".", "i7_a", ",", "self", ".", "i8_a", ",", "self", ".", "i9_a", ",", "self", ".", "i10_a", "=", "self", ".", "netG_B", "(", "self", ".", "real_B", ")", "# G_B(B)", "\n", "self", ".", "rec_B", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "self", ".", "netG_A", "(", "self", ".", "fake_A", ")", "# G_A(G_B(B))", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.attention_gan_model.AttentionGANModel.backward_D_basic": [[105, 124], ["netD", "attention_gan_model.AttentionGANModel.criterionGAN", "netD", "attention_gan_model.AttentionGANModel.criterionGAN", "loss_D.backward", "fake.detach"], "methods", ["None"], ["", "def", "backward_D_basic", "(", "self", ",", "netD", ",", "real", ",", "fake", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for the discriminator\n        Parameters:\n            netD (network)      -- the discriminator D\n            real (tensor array) -- real images\n            fake (tensor array) -- images generated by a generator\n        Return the discriminator loss.\n        We also call loss_D.backward() to calculate the gradients.\n        \"\"\"", "\n", "# Real", "\n", "pred_real", "=", "netD", "(", "real", ")", "\n", "loss_D_real", "=", "self", ".", "criterionGAN", "(", "pred_real", ",", "True", ")", "\n", "# Fake", "\n", "pred_fake", "=", "netD", "(", "fake", ".", "detach", "(", ")", ")", "\n", "loss_D_fake", "=", "self", ".", "criterionGAN", "(", "pred_fake", ",", "False", ")", "\n", "# Combined loss and calculate gradients", "\n", "loss_D", "=", "(", "loss_D_real", "+", "loss_D_fake", ")", "*", "0.5", "\n", "loss_D", ".", "backward", "(", ")", "\n", "return", "loss_D", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.attention_gan_model.AttentionGANModel.backward_D_A": [[125, 129], ["attention_gan_model.AttentionGANModel.fake_B_pool.query", "attention_gan_model.AttentionGANModel.backward_D_basic"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.image_pool.ImagePool.query", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_D_basic"], ["", "def", "backward_D_A", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for discriminator D_A\"\"\"", "\n", "fake_B", "=", "self", ".", "fake_B_pool", ".", "query", "(", "self", ".", "fake_B", ")", "\n", "self", ".", "loss_D_A", "=", "self", ".", "backward_D_basic", "(", "self", ".", "netD_A", ",", "self", ".", "real_B", ",", "fake_B", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.attention_gan_model.AttentionGANModel.backward_D_B": [[130, 134], ["attention_gan_model.AttentionGANModel.fake_A_pool.query", "attention_gan_model.AttentionGANModel.backward_D_basic"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.image_pool.ImagePool.query", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_D_basic"], ["", "def", "backward_D_B", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for discriminator D_B\"\"\"", "\n", "fake_A", "=", "self", ".", "fake_A_pool", ".", "query", "(", "self", ".", "fake_A", ")", "\n", "self", ".", "loss_D_B", "=", "self", ".", "backward_D_basic", "(", "self", ".", "netD_B", ",", "self", ".", "real_A", ",", "fake_A", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.attention_gan_model.AttentionGANModel.backward_G": [[135, 167], ["attention_gan_model.AttentionGANModel.criterionGAN", "attention_gan_model.AttentionGANModel.criterionGAN", "attention_gan_model.AttentionGANModel.loss_G.backward", "attention_gan_model.AttentionGANModel.netG_A", "attention_gan_model.AttentionGANModel.netG_B", "attention_gan_model.AttentionGANModel.netD_A", "attention_gan_model.AttentionGANModel.netD_B", "attention_gan_model.AttentionGANModel.criterionCycle", "attention_gan_model.AttentionGANModel.criterionCycle", "attention_gan_model.AttentionGANModel.criterionIdt", "attention_gan_model.AttentionGANModel.criterionIdt"], "methods", ["None"], ["", "def", "backward_G", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate the loss for generators G_A and G_B\"\"\"", "\n", "lambda_idt", "=", "self", ".", "opt", ".", "lambda_identity", "\n", "lambda_A", "=", "self", ".", "opt", ".", "lambda_A", "\n", "lambda_B", "=", "self", ".", "opt", ".", "lambda_B", "\n", "# Identity loss", "\n", "if", "lambda_idt", ">", "0", ":", "\n", "# G_A should be identity if real_B is fed: ||G_A(B) - B||", "\n", "            ", "self", ".", "idt_A", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "self", ".", "netG_A", "(", "self", ".", "real_B", ")", "\n", "self", ".", "loss_idt_A", "=", "self", ".", "criterionIdt", "(", "self", ".", "idt_A", ",", "self", ".", "real_B", ")", "*", "lambda_B", "*", "lambda_idt", "\n", "# G_B should be identity if real_A is fed: ||G_B(A) - A||", "\n", "self", ".", "idt_B", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "self", ".", "netG_B", "(", "self", ".", "real_A", ")", "\n", "self", ".", "loss_idt_B", "=", "self", ".", "criterionIdt", "(", "self", ".", "idt_B", ",", "self", ".", "real_A", ")", "*", "lambda_A", "*", "lambda_idt", "\n", "", "else", ":", "\n", "            ", "self", ".", "loss_idt_A", "=", "0", "\n", "self", ".", "loss_idt_B", "=", "0", "\n", "\n", "# GAN loss D_A(G_A(A))", "\n", "", "self", ".", "loss_G_A", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD_A", "(", "self", ".", "fake_B", ")", ",", "True", ")", "\n", "# GAN loss D_B(G_B(B))", "\n", "self", ".", "loss_G_B", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD_B", "(", "self", ".", "fake_A", ")", ",", "True", ")", "\n", "# Forward cycle loss || G_B(G_A(A)) - A||", "\n", "self", ".", "loss_cycle_A", "=", "self", ".", "criterionCycle", "(", "self", ".", "rec_A", ",", "self", ".", "real_A", ")", "*", "lambda_A", "\n", "# Backward cycle loss || G_A(G_B(B)) - B||", "\n", "self", ".", "loss_cycle_B", "=", "self", ".", "criterionCycle", "(", "self", ".", "rec_B", ",", "self", ".", "real_B", ")", "*", "lambda_B", "\n", "# combined loss and calculate gradients", "\n", "self", ".", "loss_G", "=", "self", ".", "loss_G_A", "+", "self", ".", "loss_G_B", "+", "self", ".", "loss_cycle_A", "+", "self", ".", "loss_cycle_B", "+", "self", ".", "loss_idt_A", "+", "self", ".", "loss_idt_B", "\n", "self", ".", "loss_G", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-geo.attention_gan_model.AttentionGANModel.optimize_parameters": [[168, 183], ["attention_gan_model.AttentionGANModel.forward", "attention_gan_model.AttentionGANModel.set_requires_grad", "attention_gan_model.AttentionGANModel.optimizer_G.zero_grad", "attention_gan_model.AttentionGANModel.backward_G", "attention_gan_model.AttentionGANModel.optimizer_G.step", "attention_gan_model.AttentionGANModel.set_requires_grad", "attention_gan_model.AttentionGANModel.optimizer_D.zero_grad", "attention_gan_model.AttentionGANModel.backward_D_A", "attention_gan_model.AttentionGANModel.backward_D_B", "attention_gan_model.AttentionGANModel.optimizer_D.step"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.forward", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_G", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.LambdaLR.step", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_D_A", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_D_B", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.LambdaLR.step"], ["", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"", "\n", "# forward", "\n", "self", ".", "forward", "(", ")", "# compute fake images and reconstruction images.", "\n", "# G_A and G_B", "\n", "self", ".", "set_requires_grad", "(", "[", "self", ".", "netD_A", ",", "self", ".", "netD_B", "]", ",", "False", ")", "# Ds require no gradients when optimizing Gs", "\n", "self", ".", "optimizer_G", ".", "zero_grad", "(", ")", "# set G_A and G_B's gradients to zero", "\n", "self", ".", "backward_G", "(", ")", "# calculate gradients for G_A and G_B", "\n", "self", ".", "optimizer_G", ".", "step", "(", ")", "# update G_A and G_B's weights", "\n", "# D_A and D_B", "\n", "self", ".", "set_requires_grad", "(", "[", "self", ".", "netD_A", ",", "self", ".", "netD_B", "]", ",", "True", ")", "\n", "self", ".", "optimizer_D", ".", "zero_grad", "(", ")", "# set D_A and D_B's gradients to zero", "\n", "self", ".", "backward_D_A", "(", ")", "# calculate gradients for D_A", "\n", "self", ".", "backward_D_B", "(", ")", "# calculate graidents for D_B", "\n", "self", ".", "optimizer_D", ".", "step", "(", ")", "# update D_A and D_B's weights", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.models.Generator.__init__": [[7, 48], ["torch.Module.__init__", "range", "range", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "models.ResnetBlock", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PixelShuffle", "torch.PixelShuffle", "torch.PixelShuffle", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "int", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_nc", "=", "3", ",", "output_nc", "=", "4", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ",", "n_blocks", "=", "6", ")", ":", "\n", "        ", "assert", "(", "n_blocks", ">=", "0", ")", "\n", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_nc", "=", "input_nc", "\n", "self", ".", "output_nc", "=", "output_nc", "\n", "self", ".", "ngf", "=", "ngf", "\n", "\n", "model", "=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", ",", "\n", "nn", ".", "Conv2d", "(", "input_nc", ",", "ngf", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ")", ",", "\n", "norm_layer", "(", "ngf", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "n_downsampling", "=", "2", "\n", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "\n", "            ", "mult", "=", "2", "**", "i", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", "*", "mult", ",", "ngf", "*", "mult", "*", "2", ",", "kernel_size", "=", "3", ",", "\n", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "norm_layer", "(", "ngf", "*", "mult", "*", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "", "mult", "=", "2", "**", "n_downsampling", "\n", "for", "i", "in", "range", "(", "n_blocks", ")", ":", "\n", "            ", "model", "+=", "[", "ResnetBlock", "(", "ngf", "*", "mult", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ")", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "\n", "            ", "mult", "=", "2", "**", "(", "n_downsampling", "-", "i", ")", "\n", "model", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ngf", "*", "mult", ",", "int", "(", "ngf", "*", "mult", "/", "2", ")", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "norm_layer", "(", "int", "(", "ngf", "*", "mult", "/", "2", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "int", "(", "ngf", "*", "mult", "/", "2", ")", ",", "int", "(", "ngf", "*", "mult", "/", "2", ")", "*", "4", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "nn", ".", "PixelShuffle", "(", "2", ")", ",", "\n", "norm_layer", "(", "int", "(", "ngf", "*", "mult", "/", "2", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "]", "\n", "", "model", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", "]", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", ",", "output_nc", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ")", "]", "\n", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.models.Generator.forward": [[49, 57], ["models.Generator.model", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "attention_mask.repeat.repeat.repeat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "output", "=", "self", ".", "model", "(", "input", ")", "\n", "attention_mask", "=", "F", ".", "sigmoid", "(", "output", "[", ":", ",", ":", "1", "]", ")", "\n", "content_mask", "=", "output", "[", ":", ",", "1", ":", "]", "\n", "attention_mask", "=", "attention_mask", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "result", "=", "content_mask", "*", "attention_mask", "+", "input", "*", "(", "1", "-", "attention_mask", ")", "\n", "\n", "return", "result", ",", "attention_mask", ",", "content_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.models.ResnetBlock.__init__": [[59, 62], ["torch.Module.__init__", "models.ResnetBlock.build_conv_block"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.ResnetBlock.build_conv_block"], ["    ", "def", "__init__", "(", "self", ",", "dim", ",", "norm_layer", ",", "use_dropout", ")", ":", "\n", "        ", "super", "(", "ResnetBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_block", "=", "self", ".", "build_conv_block", "(", "dim", ",", "norm_layer", ",", "use_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.models.ResnetBlock.build_conv_block": [[63, 76], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["None"], ["", "def", "build_conv_block", "(", "self", ",", "dim", ",", "norm_layer", ",", "use_dropout", ")", ":", "\n", "        ", "conv_block", "=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "3", ")", ",", "\n", "norm_layer", "(", "dim", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "if", "use_dropout", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "Dropout", "(", "0.5", ")", "]", "\n", "\n", "", "conv_block", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "3", ")", ",", "\n", "norm_layer", "(", "dim", ")", "]", "\n", "\n", "return", "nn", ".", "Sequential", "(", "*", "conv_block", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.models.ResnetBlock.forward": [[77, 80], ["models.ResnetBlock.conv_block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "x", "+", "self", ".", "conv_block", "(", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.models.Discriminator.__init__": [[83, 102], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_tower", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "4", ",", "2", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "4", ",", "2", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "128", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "4", ",", "2", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "256", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "512", ",", "4", ",", "2", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "512", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "4", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", ")", ",", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "1", ",", "1", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.models.Discriminator.forward": [[104, 107], ["models.Discriminator.conv_tower"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "img", ")", ":", "\n", "        ", "output", "=", "self", ".", "conv_tower", "(", "img", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.Logger.__init__": [[25, 36], ["visdom.Visdom", "time.time"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n_epochs", ",", "batches_epoch", ")", ":", "\n", "        ", "self", ".", "viz", "=", "Visdom", "(", ")", "\n", "self", ".", "n_epochs", "=", "n_epochs", "\n", "self", ".", "batches_epoch", "=", "batches_epoch", "\n", "self", ".", "epoch", "=", "1", "\n", "self", ".", "batch", "=", "1", "\n", "self", ".", "prev_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "mean_period", "=", "0", "\n", "self", ".", "losses", "=", "{", "}", "\n", "self", ".", "loss_windows", "=", "{", "}", "\n", "self", ".", "image_windows", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.Logger.log": [[38, 83], ["time.time", "sys.stdout.write", "enumerate", "sys.stdout.write", "images.items", "time.time", "losses.keys", "utils.Logger.losses.items", "sys.stdout.write", "len", "sys.stdout.write", "sys.stdout.write", "datetime.timedelta", "utils.Logger.viz.image", "utils.Logger.viz.image", "losses.keys", "utils.tensor2image", "utils.tensor2image", "utils.Logger.viz.line", "utils.Logger.viz.line", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.tensor2image", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.tensor2image"], ["", "def", "log", "(", "self", ",", "losses", "=", "None", ",", "images", "=", "None", ")", ":", "\n", "        ", "self", ".", "mean_period", "+=", "(", "time", ".", "time", "(", ")", "-", "self", ".", "prev_time", ")", "\n", "self", ".", "prev_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "sys", ".", "stdout", ".", "write", "(", "'\\rEpoch %03d/%03d [%04d/%04d] -- '", "%", "(", "self", ".", "epoch", ",", "self", ".", "n_epochs", ",", "self", ".", "batch", ",", "self", ".", "batches_epoch", ")", ")", "\n", "\n", "for", "i", ",", "loss_name", "in", "enumerate", "(", "losses", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "loss_name", "not", "in", "self", ".", "losses", ":", "\n", "                ", "self", ".", "losses", "[", "loss_name", "]", "=", "losses", "[", "loss_name", "]", ".", "data", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "losses", "[", "loss_name", "]", "+=", "losses", "[", "loss_name", "]", ".", "data", "[", "0", "]", "\n", "\n", "", "if", "(", "i", "+", "1", ")", "==", "len", "(", "losses", ".", "keys", "(", ")", ")", ":", "\n", "                ", "sys", ".", "stdout", ".", "write", "(", "'%s: %.4f -- '", "%", "(", "loss_name", ",", "self", ".", "losses", "[", "loss_name", "]", "/", "self", ".", "batch", ")", ")", "\n", "", "else", ":", "\n", "                ", "sys", ".", "stdout", ".", "write", "(", "'%s: %.4f | '", "%", "(", "loss_name", ",", "self", ".", "losses", "[", "loss_name", "]", "/", "self", ".", "batch", ")", ")", "\n", "\n", "", "", "batches_done", "=", "self", ".", "batches_epoch", "*", "(", "self", ".", "epoch", "-", "1", ")", "+", "self", ".", "batch", "\n", "batches_left", "=", "self", ".", "batches_epoch", "*", "(", "self", ".", "n_epochs", "-", "self", ".", "epoch", ")", "+", "self", ".", "batches_epoch", "-", "self", ".", "batch", "\n", "sys", ".", "stdout", ".", "write", "(", "'ETA: %s'", "%", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "batches_left", "*", "self", ".", "mean_period", "/", "batches_done", ")", ")", ")", "\n", "\n", "# Draw images", "\n", "for", "image_name", ",", "tensor", "in", "images", ".", "items", "(", ")", ":", "\n", "            ", "if", "image_name", "not", "in", "self", ".", "image_windows", ":", "\n", "                ", "self", ".", "image_windows", "[", "image_name", "]", "=", "self", ".", "viz", ".", "image", "(", "tensor2image", "(", "tensor", ".", "data", ")", ",", "opts", "=", "{", "'title'", ":", "image_name", "}", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "viz", ".", "image", "(", "tensor2image", "(", "tensor", ".", "data", ")", ",", "win", "=", "self", ".", "image_windows", "[", "image_name", "]", ",", "opts", "=", "{", "'title'", ":", "image_name", "}", ")", "\n", "\n", "# End of epoch", "\n", "", "", "if", "(", "self", ".", "batch", "%", "self", ".", "batches_epoch", ")", "==", "0", ":", "\n", "# Plot losses", "\n", "            ", "for", "loss_name", ",", "loss", "in", "self", ".", "losses", ".", "items", "(", ")", ":", "\n", "                ", "if", "loss_name", "not", "in", "self", ".", "loss_windows", ":", "\n", "                    ", "self", ".", "loss_windows", "[", "loss_name", "]", "=", "self", ".", "viz", ".", "line", "(", "X", "=", "np", ".", "array", "(", "[", "self", ".", "epoch", "]", ")", ",", "Y", "=", "np", ".", "array", "(", "[", "loss", "/", "self", ".", "batch", "]", ")", ",", "\n", "opts", "=", "{", "'xlabel'", ":", "'epochs'", ",", "'ylabel'", ":", "loss_name", ",", "'title'", ":", "loss_name", "}", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "viz", ".", "line", "(", "X", "=", "np", ".", "array", "(", "[", "self", ".", "epoch", "]", ")", ",", "Y", "=", "np", ".", "array", "(", "[", "loss", "/", "self", ".", "batch", "]", ")", ",", "win", "=", "self", ".", "loss_windows", "[", "loss_name", "]", ",", "update", "=", "'append'", ")", "\n", "# Reset losses for next epoch", "\n", "", "self", ".", "losses", "[", "loss_name", "]", "=", "0.0", "\n", "\n", "", "self", ".", "epoch", "+=", "1", "\n", "self", ".", "batch", "=", "1", "\n", "sys", ".", "stdout", ".", "write", "(", "'\\n'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "batch", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.ReplayBuffer.__init__": [[87, 91], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "max_size", "=", "50", ")", ":", "\n", "        ", "assert", "(", "max_size", ">", "0", ")", ",", "'Empty buffer or trying to create a black hole. Be careful.'", "\n", "self", ".", "max_size", "=", "max_size", "\n", "self", ".", "data", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.ReplayBuffer.push_and_pop": [[92, 107], ["torch.autograd.Variable", "torch.unsqueeze", "torch.cat", "len", "utils.ReplayBuffer.data.append", "to_return.append", "random.uniform", "random.randint", "to_return.append", "to_return.append", "utils.ReplayBuffer.data[].clone"], "methods", ["None"], ["", "def", "push_and_pop", "(", "self", ",", "data", ")", ":", "\n", "        ", "to_return", "=", "[", "]", "\n", "for", "element", "in", "data", ".", "data", ":", "\n", "            ", "element", "=", "torch", ".", "unsqueeze", "(", "element", ",", "0", ")", "\n", "if", "len", "(", "self", ".", "data", ")", "<", "self", ".", "max_size", ":", "\n", "                ", "self", ".", "data", ".", "append", "(", "element", ")", "\n", "to_return", ".", "append", "(", "element", ")", "\n", "", "else", ":", "\n", "                ", "if", "random", ".", "uniform", "(", "0", ",", "1", ")", ">", "0.5", ":", "\n", "                    ", "i", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "max_size", "-", "1", ")", "\n", "to_return", ".", "append", "(", "self", ".", "data", "[", "i", "]", ".", "clone", "(", ")", ")", "\n", "self", ".", "data", "[", "i", "]", "=", "element", "\n", "", "else", ":", "\n", "                    ", "to_return", ".", "append", "(", "element", ")", "\n", "", "", "", "return", "Variable", "(", "torch", ".", "cat", "(", "to_return", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.LambdaLR.__init__": [[109, 114], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n_epochs", ",", "offset", ",", "decay_start_epoch", ")", ":", "\n", "        ", "assert", "(", "(", "n_epochs", "-", "decay_start_epoch", ")", ">", "0", ")", ",", "\"Decay must start before the training session ends!\"", "\n", "self", ".", "n_epochs", "=", "n_epochs", "\n", "self", ".", "offset", "=", "offset", "\n", "self", ".", "decay_start_epoch", "=", "decay_start_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.LambdaLR.step": [[115, 117], ["max"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "return", "1.0", "-", "max", "(", "0", ",", "epoch", "+", "self", ".", "offset", "-", "self", ".", "decay_start_epoch", ")", "/", "(", "self", ".", "n_epochs", "-", "self", ".", "decay_start_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.print_network": [[11, 17], ["net.parameters", "print", "print", "param.numel"], "function", ["None"], ["def", "print_network", "(", "net", ")", ":", "\n", "    ", "num_params", "=", "0", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "        ", "num_params", "+=", "param", ".", "numel", "(", ")", "\n", "", "print", "(", "net", ")", "\n", "print", "(", "'Total number of parameters: %d'", "%", "num_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.tensor2image": [[18, 23], ["np.tile.astype", "numpy.tile", "tensor[].cpu().float().numpy", "tensor[].cpu().float", "tensor[].cpu"], "function", ["None"], ["", "def", "tensor2image", "(", "tensor", ")", ":", "\n", "    ", "image", "=", "127.5", "*", "(", "tensor", "[", "0", "]", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "+", "1.0", ")", "\n", "if", "image", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "        ", "image", "=", "np", ".", "tile", "(", "image", ",", "(", "3", ",", "1", ",", "1", ")", ")", "\n", "", "return", "image", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.weights_init_normal": [[118, 125], ["classname.find", "torch.nn.init.normal", "classname.find", "torch.nn.init.normal", "torch.nn.init.constant"], "function", ["None"], ["", "", "def", "weights_init_normal", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "normal", "(", "m", ".", "weight", ".", "data", ",", "0.0", ",", "0.02", ")", "\n", "", "elif", "classname", ".", "find", "(", "'BatchNorm2d'", ")", "!=", "-", "1", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "normal", "(", "m", ".", "weight", ".", "data", ",", "1.0", ",", "0.02", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.datasets.ImageDataset.__init__": [[10, 16], ["torchvision.Compose", "sorted", "sorted", "glob.glob", "glob.glob", "os.path.join", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "transforms_", "=", "None", ",", "unaligned", "=", "False", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "transforms_", ")", "\n", "self", ".", "unaligned", "=", "unaligned", "\n", "\n", "self", ".", "files_A", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "root", ",", "'%s/A'", "%", "mode", ")", "+", "'/*.*'", ")", ")", "\n", "self", ".", "files_B", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "root", ",", "'%s/B'", "%", "mode", ")", "+", "'/*.*'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.datasets.ImageDataset.__getitem__": [[17, 26], ["datasets.ImageDataset.transform", "PIL.Image.open", "datasets.ImageDataset.transform", "datasets.ImageDataset.transform", "PIL.Image.open", "PIL.Image.open", "len", "random.randint", "len", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "item_A", "=", "self", ".", "transform", "(", "Image", ".", "open", "(", "self", ".", "files_A", "[", "index", "%", "len", "(", "self", ".", "files_A", ")", "]", ")", ")", "\n", "\n", "if", "self", ".", "unaligned", ":", "\n", "            ", "item_B", "=", "self", ".", "transform", "(", "Image", ".", "open", "(", "self", ".", "files_B", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "files_B", ")", "-", "1", ")", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "item_B", "=", "self", ".", "transform", "(", "Image", ".", "open", "(", "self", ".", "files_B", "[", "index", "%", "len", "(", "self", ".", "files_B", ")", "]", ")", ")", "\n", "\n", "", "return", "{", "'A'", ":", "item_A", ",", "'B'", ":", "item_B", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.datasets.ImageDataset.__len__": [[27, 29], ["max", "len", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "max", "(", "len", "(", "self", ".", "files_A", ")", ",", "len", "(", "self", ".", "files_B", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.inception_score.inception_logits": [[12, 26], ["tensorflow.transpose", "tensorflow.image.resize_bilinear", "tensorflow.python.ops.array_ops.split", "tensorflow.python.ops.functional_ops.map_fn", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.array_ops.unstack", "functools.partial", "tensorflow.python.ops.array_ops.stack"], "function", ["None"], ["def", "inception_logits", "(", "images", ",", "num_splits", "=", "1", ")", ":", "\n", "    ", "images", "=", "tf", ".", "transpose", "(", "images", ",", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "size", "=", "299", "\n", "images", "=", "tf", ".", "image", ".", "resize_bilinear", "(", "images", ",", "[", "size", ",", "size", "]", ")", "\n", "generated_images_list", "=", "array_ops", ".", "split", "(", "images", ",", "num_or_size_splits", "=", "num_splits", ")", "\n", "logits", "=", "functional_ops", ".", "map_fn", "(", "\n", "fn", "=", "functools", ".", "partial", "(", "tfgan", ".", "eval", ".", "run_inception", ",", "output_tensor", "=", "'logits:0'", ")", ",", "\n", "elems", "=", "array_ops", ".", "stack", "(", "generated_images_list", ")", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "back_prop", "=", "False", ",", "\n", "swap_memory", "=", "True", ",", "\n", "name", "=", "'RunClassifier'", ")", "\n", "logits", "=", "array_ops", ".", "concat", "(", "array_ops", ".", "unstack", "(", "logits", ")", ",", "0", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.inception_score.get_inception_probs": [[27, 35], ["numpy.zeros", "range", "len", "numpy.exp", "numpy.sum", "logits.eval", "numpy.exp"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.eval"], ["", "def", "get_inception_probs", "(", "batch_size", ",", "images", ",", "inception_images", ",", "logits", ")", ":", "\n", "    ", "n_batches", "=", "len", "(", "images", ")", "//", "batch_size", "\n", "preds", "=", "np", ".", "zeros", "(", "[", "n_batches", "*", "batch_size", ",", "1000", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "n_batches", ")", ":", "\n", "        ", "inp", "=", "images", "[", "i", "*", "batch_size", ":", "(", "i", "+", "1", ")", "*", "batch_size", "]", "/", "255.", "*", "2", "-", "1", "\n", "preds", "[", "i", "*", "batch_size", ":", "(", "i", "+", "1", ")", "*", "batch_size", "]", "=", "logits", ".", "eval", "(", "{", "inception_images", ":", "inp", "}", ")", "[", ":", ",", ":", "1000", "]", "\n", "", "preds", "=", "np", ".", "exp", "(", "preds", ")", "/", "np", ".", "sum", "(", "np", ".", "exp", "(", "preds", ")", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.inception_score.preds2score": [[36, 44], ["range", "numpy.mean", "scores.append", "numpy.mean", "numpy.std", "numpy.sum", "numpy.exp", "numpy.log", "numpy.log", "numpy.expand_dims", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.Logger.log", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.Logger.log"], ["", "def", "preds2score", "(", "preds", ",", "splits", "=", "10", ")", ":", "\n", "    ", "scores", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "splits", ")", ":", "\n", "        ", "part", "=", "preds", "[", "(", "i", "*", "preds", ".", "shape", "[", "0", "]", "//", "splits", ")", ":", "(", "(", "i", "+", "1", ")", "*", "preds", ".", "shape", "[", "0", "]", "//", "splits", ")", ",", ":", "]", "\n", "kl", "=", "part", "*", "(", "np", ".", "log", "(", "part", ")", "-", "np", ".", "log", "(", "np", ".", "expand_dims", "(", "np", ".", "mean", "(", "part", ",", "0", ")", ",", "0", ")", ")", ")", "\n", "kl", "=", "np", ".", "mean", "(", "np", ".", "sum", "(", "kl", ",", "1", ")", ")", "\n", "scores", ".", "append", "(", "np", ".", "exp", "(", "kl", ")", ")", "\n", "", "return", "np", ".", "mean", "(", "scores", ")", ",", "np", ".", "std", "(", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.inception_score.get_inception_score": [[45, 56], ["print", "time.time", "inception_score.get_inception_probs", "inception_score.preds2score", "print", "type", "len", "numpy.min", "numpy.max", "time.time"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.inception_score.get_inception_probs", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.inception_score.preds2score"], ["", "def", "get_inception_score", "(", "batch_size", ",", "images", ",", "inception_images", ",", "logits", ",", "splits", "=", "10", ")", ":", "\n", "    ", "assert", "(", "type", "(", "images", ")", "==", "np", ".", "ndarray", ")", "\n", "assert", "(", "len", "(", "images", ".", "shape", ")", "==", "4", ")", "\n", "assert", "(", "images", ".", "shape", "[", "1", "]", "==", "3", ")", "\n", "assert", "(", "np", ".", "min", "(", "images", "[", "0", "]", ")", ">=", "0", "and", "np", ".", "max", "(", "images", "[", "0", "]", ")", ">", "10", ")", ",", "'Image values should be in the range [0, 255]'", "\n", "print", "(", "'Calculating Inception Score with %i images in %i splits'", "%", "(", "images", ".", "shape", "[", "0", "]", ",", "splits", ")", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "preds", "=", "get_inception_probs", "(", "batch_size", ",", "images", ",", "inception_images", ",", "logits", ")", "\n", "mean", ",", "std", "=", "preds2score", "(", "preds", ",", "splits", ")", "\n", "print", "(", "'Inception Score calculation time: %f s'", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "return", "mean", ",", "std", "# Reference values: 11.34 for 49984 CIFAR-10 training set images, or mean=11.31, std=0.08 if in 10 splits.", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.inception_score.get_images": [[57, 61], ["scipy.misc.imread", "scipy.misc.imresize"], "function", ["None"], ["", "def", "get_images", "(", "filename", ")", ":", "\n", "    ", "x", "=", "misc", ".", "imread", "(", "filename", ")", "\n", "x", "=", "misc", ".", "imresize", "(", "x", ",", "size", "=", "[", "299", ",", "299", "]", ")", "\n", "return", "x", "\n", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.main.inception_score": [[6, 23], ["glob.glob", "np.transpose", "tf.placeholder", "inception_score.inception_logits", "inception_score.get_inception_score", "print", "print", "os.path.join", "frechet_kernel_Inception_distance.get_images"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.inception_score.inception_logits", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.inception_score.get_inception_score", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_images"], ["\n", "\n", "def", "str2bool", "(", "v", ")", ":", "\n", "    ", "return", "v", ".", "lower", "(", ")", "in", "(", "'true'", ")", "\n", "\n", "", "def", "main", "(", "config", ")", ":", "\n", "# For fast training.", "\n", "    ", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# Create directories if not exist.", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "config", ".", "log_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "config", ".", "log_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "config", ".", "model_save_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "config", ".", "model_save_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "config", ".", "sample_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "config", ".", "sample_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "config", ".", "result_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "config", ".", "result_dir", ")", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.main.frechet_inception_distance": [[25, 49], ["glob.glob", "np.transpose", "glob.glob", "np.transpose", "tf.placeholder", "tf.placeholder", "tf.placeholder", "frechet_kernel_Inception_distance.frechet_classifier_distance_from_activations", "frechet_kernel_Inception_distance.inception_activations", "frechet_kernel_Inception_distance.get_fid", "print", "print", "os.path.join", "frechet_kernel_Inception_distance.get_images", "os.path.join", "frechet_kernel_Inception_distance.get_images"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.frechet_classifier_distance_from_activations", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.inception_activations", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_fid", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_images", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_images"], ["# Data loader.", "\n", "", "celeba_loader", "=", "None", "\n", "rafd_loader", "=", "None", "\n", "\n", "if", "config", ".", "dataset", "in", "[", "'CelebA'", ",", "'Both'", "]", ":", "\n", "        ", "celeba_loader", "=", "get_loader", "(", "config", ".", "celeba_image_dir", ",", "config", ".", "attr_path", ",", "config", ".", "selected_attrs", ",", "\n", "config", ".", "celeba_crop_size", ",", "config", ".", "image_size", ",", "config", ".", "batch_size", ",", "\n", "'CelebA'", ",", "config", ".", "mode", ",", "config", ".", "num_workers", ")", "\n", "", "if", "config", ".", "dataset", "in", "[", "'RaFD'", ",", "'Both'", "]", ":", "\n", "        ", "rafd_loader", "=", "get_loader", "(", "config", ".", "rafd_image_dir", ",", "None", ",", "None", ",", "\n", "config", ".", "rafd_crop_size", ",", "config", ".", "image_size", ",", "config", ".", "batch_size", ",", "\n", "'RaFD'", ",", "config", ".", "mode", ",", "config", ".", "num_workers", ")", "\n", "\n", "\n", "# Solver for training and testing StarGAN.", "\n", "", "solver", "=", "Solver", "(", "celeba_loader", ",", "rafd_loader", ",", "config", ")", "\n", "\n", "if", "config", ".", "mode", "==", "'train'", ":", "\n", "        ", "if", "config", ".", "dataset", "in", "[", "'CelebA'", ",", "'RaFD'", "]", ":", "\n", "            ", "solver", ".", "train", "(", ")", "\n", "", "elif", "config", ".", "dataset", "in", "[", "'Both'", "]", ":", "\n", "            ", "solver", ".", "train_multi", "(", ")", "\n", "", "", "elif", "config", ".", "mode", "==", "'test'", ":", "\n", "        ", "if", "config", ".", "dataset", "in", "[", "'CelebA'", ",", "'RaFD'", "]", ":", "\n", "            ", "solver", ".", "test", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.main.kernel_inception_distance": [[50, 76], ["glob.glob", "np.transpose", "glob.glob", "np.transpose", "tf.placeholder", "tf.placeholder", "tf.placeholder", "frechet_kernel_Inception_distance.kernel_classifier_distance_and_std_from_activations", "frechet_kernel_Inception_distance.inception_activations", "frechet_kernel_Inception_distance.get_kid", "frechet_kernel_Inception_distance.get_kid", "print", "print", "print", "os.path.join", "frechet_kernel_Inception_distance.get_images", "os.path.join", "frechet_kernel_Inception_distance.get_images"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.kernel_classifier_distance_and_std_from_activations", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.inception_activations", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_kid", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_kid", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_images", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_images"], ["", "elif", "config", ".", "dataset", "in", "[", "'Both'", "]", ":", "\n", "            ", "solver", ".", "test_multi", "(", ")", "\n", "\n", "\n", "", "", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Model configuration.", "\n", "parser", ".", "add_argument", "(", "'--c_dim'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'dimension of domain labels (1st dataset)'", ")", "\n", "parser", ".", "add_argument", "(", "'--c2_dim'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "'dimension of domain labels (2nd dataset)'", ")", "\n", "parser", ".", "add_argument", "(", "'--celeba_crop_size'", ",", "type", "=", "int", ",", "default", "=", "178", ",", "help", "=", "'crop size for the CelebA dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--rafd_crop_size'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'crop size for the RaFD dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--image_size'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'image resolution'", ")", "\n", "parser", ".", "add_argument", "(", "'--g_conv_dim'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'number of conv filters in the first layer of G'", ")", "\n", "parser", ".", "add_argument", "(", "'--d_conv_dim'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'number of conv filters in the first layer of D'", ")", "\n", "parser", ".", "add_argument", "(", "'--g_repeat_num'", ",", "type", "=", "int", ",", "default", "=", "6", ",", "help", "=", "'number of residual blocks in G'", ")", "\n", "parser", ".", "add_argument", "(", "'--d_repeat_num'", ",", "type", "=", "int", ",", "default", "=", "6", ",", "help", "=", "'number of strided conv layers in D'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_cls'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "'weight for domain classification loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_rec'", ",", "type", "=", "float", ",", "default", "=", "10", ",", "help", "=", "'weight for reconstruction loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_gp'", ",", "type", "=", "float", ",", "default", "=", "10", ",", "help", "=", "'weight for gradient penalty'", ")", "\n", "\n", "# Training configuration.", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "type", "=", "str", ",", "default", "=", "'CelebA'", ",", "choices", "=", "[", "'CelebA'", ",", "'RaFD'", ",", "'Both'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "'mini-batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_iters'", ",", "type", "=", "int", ",", "default", "=", "200000", ",", "help", "=", "'number of total iterations for training D'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_iters_decay'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "help", "=", "'number of iterations for decaying lr'", ")", "\n", "parser", ".", "add_argument", "(", "'--g_lr'", ",", "type", "=", "float", ",", "default", "=", "0.0001", ",", "help", "=", "'learning rate for G'", ")", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.main.mean_kernel_inception_distance": [[77, 127], ["glob.glob", "np.transpose", "glob.glob", "np.transpose", "glob.glob", "np.transpose", "tf.placeholder", "tf.placeholder", "tf.placeholder", "frechet_kernel_Inception_distance.frechet_classifier_distance_from_activations", "frechet_kernel_Inception_distance.kernel_classifier_distance_and_std_from_activations", "frechet_kernel_Inception_distance.inception_activations", "frechet_kernel_Inception_distance.get_fid", "frechet_kernel_Inception_distance.get_kid", "frechet_kernel_Inception_distance.get_kid", "frechet_kernel_Inception_distance.get_fid", "frechet_kernel_Inception_distance.get_kid", "frechet_kernel_Inception_distance.get_kid", "print", "print", "print", "print", "os.path.join", "frechet_kernel_Inception_distance.get_images", "os.path.join", "frechet_kernel_Inception_distance.get_images", "os.path.join", "frechet_kernel_Inception_distance.get_images"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.frechet_classifier_distance_from_activations", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.kernel_classifier_distance_and_std_from_activations", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.inception_activations", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_fid", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_kid", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_kid", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_fid", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_kid", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_kid", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_images", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_images", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_images"], ["parser", ".", "add_argument", "(", "'--d_lr'", ",", "type", "=", "float", ",", "default", "=", "0.0001", ",", "help", "=", "'learning rate for D'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_critic'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'number of D updates per each G update'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta1'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'beta1 for Adam optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "help", "=", "'beta2 for Adam optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "'--resume_iters'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "'resume training from this step'", ")", "\n", "parser", ".", "add_argument", "(", "'--selected_attrs'", ",", "'--list'", ",", "nargs", "=", "'+'", ",", "help", "=", "'selected attributes for the CelebA dataset'", ",", "\n", "default", "=", "[", "'Black_Hair'", ",", "'Blond_Hair'", ",", "'Brown_Hair'", ",", "'Male'", ",", "'Young'", "]", ")", "\n", "\n", "# Test configuration.", "\n", "parser", ".", "add_argument", "(", "'--test_iters'", ",", "type", "=", "int", ",", "default", "=", "200000", ",", "help", "=", "'test model from this step'", ")", "\n", "\n", "# Miscellaneous.", "\n", "parser", ".", "add_argument", "(", "'--num_workers'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "default", "=", "'train'", ",", "choices", "=", "[", "'train'", ",", "'test'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--use_tensorboard'", ",", "type", "=", "str2bool", ",", "default", "=", "True", ")", "\n", "\n", "# Directories.", "\n", "parser", ".", "add_argument", "(", "'--celeba_image_dir'", ",", "type", "=", "str", ",", "default", "=", "'data/celeba/images'", ")", "\n", "parser", ".", "add_argument", "(", "'--attr_path'", ",", "type", "=", "str", ",", "default", "=", "'data/celeba/list_attr_celeba.txt'", ")", "\n", "parser", ".", "add_argument", "(", "'--rafd_image_dir'", ",", "type", "=", "str", ",", "default", "=", "'data/RaFD/train'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_dir'", ",", "type", "=", "str", ",", "default", "=", "'stargan/logs'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_save_dir'", ",", "type", "=", "str", ",", "default", "=", "'stargan/models'", ")", "\n", "parser", ".", "add_argument", "(", "'--sample_dir'", ",", "type", "=", "str", ",", "default", "=", "'stargan/samples'", ")", "\n", "parser", ".", "add_argument", "(", "'--result_dir'", ",", "type", "=", "str", ",", "default", "=", "'stargan/results'", ")", "\n", "\n", "# Step size.", "\n", "parser", ".", "add_argument", "(", "'--log_step'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "'--sample_step'", ",", "type", "=", "int", ",", "default", "=", "1000", ")", "\n", "parser", ".", "add_argument", "(", "'--model_save_step'", ",", "type", "=", "int", ",", "default", "=", "10000", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_update_step'", ",", "type", "=", "int", ",", "default", "=", "1000", ")", "\n", "\n", "config", "=", "parser", ".", "parse_args", "(", ")", "\n", "print", "(", "config", ")", "\n", "main", "(", "config", ")", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance._symmetric_matrix_square_root": [[17, 42], ["tensorflow.python.ops.linalg_ops.svd", "tensorflow.python.ops.array_ops.where", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.math_ops.less", "tensorflow.python.ops.math_ops.sqrt", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.array_ops.diag"], "function", ["None"], ["def", "_symmetric_matrix_square_root", "(", "mat", ",", "eps", "=", "1e-10", ")", ":", "\n", "  ", "\"\"\"Compute square root of a symmetric matrix.\n\n  Note that this is different from an elementwise square root. We want to\n  compute M' where M' = sqrt(mat) such that M' * M' = mat.\n\n  Also note that this method **only** works for symmetric matrices.\n\n  Args:\n    mat: Matrix to take the square root of.\n    eps: Small epsilon such that any element less than eps will not be square\n      rooted to guard against numerical instability.\n\n  Returns:\n    Matrix square root of mat.\n  \"\"\"", "\n", "# Unlike numpy, tensorflow's return order is (s, u, v)", "\n", "s", ",", "u", ",", "v", "=", "linalg_ops", ".", "svd", "(", "mat", ")", "\n", "# sqrt is unstable around 0, just use 0 in such case", "\n", "si", "=", "array_ops", ".", "where", "(", "math_ops", ".", "less", "(", "s", ",", "eps", ")", ",", "s", ",", "math_ops", ".", "sqrt", "(", "s", ")", ")", "\n", "# Note that the v returned by Tensorflow is v = V", "\n", "# (when referencing the equation A = U S V^T)", "\n", "# This is unlike Numpy which returns v = V^T", "\n", "return", "math_ops", ".", "matmul", "(", "\n", "math_ops", ".", "matmul", "(", "u", ",", "array_ops", ".", "diag", "(", "si", ")", ")", ",", "v", ",", "transpose_b", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.trace_sqrt_product": [[43, 83], ["frechet_kernel_Inception_distance._symmetric_matrix_square_root", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.math_ops.trace", "tensorflow.python.ops.math_ops.matmul", "frechet_kernel_Inception_distance._symmetric_matrix_square_root"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance._symmetric_matrix_square_root", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance._symmetric_matrix_square_root"], ["", "def", "trace_sqrt_product", "(", "sigma", ",", "sigma_v", ")", ":", "\n", "  ", "\"\"\"Find the trace of the positive sqrt of product of covariance matrices.\n\n  '_symmetric_matrix_square_root' only works for symmetric matrices, so we\n  cannot just take _symmetric_matrix_square_root(sigma * sigma_v).\n  ('sigma' and 'sigma_v' are symmetric, but their product is not necessarily).\n\n  Let sigma = A A so A = sqrt(sigma), and sigma_v = B B.\n  We want to find trace(sqrt(sigma sigma_v)) = trace(sqrt(A A B B))\n  Note the following properties:\n  (i) forall M1, M2: eigenvalues(M1 M2) = eigenvalues(M2 M1)\n     => eigenvalues(A A B B) = eigenvalues (A B B A)\n  (ii) if M1 = sqrt(M2), then eigenvalues(M1) = sqrt(eigenvalues(M2))\n     => eigenvalues(sqrt(sigma sigma_v)) = sqrt(eigenvalues(A B B A))\n  (iii) forall M: trace(M) = sum(eigenvalues(M))\n     => trace(sqrt(sigma sigma_v)) = sum(eigenvalues(sqrt(sigma sigma_v)))\n                                   = sum(sqrt(eigenvalues(A B B A)))\n                                   = sum(eigenvalues(sqrt(A B B A)))\n                                   = trace(sqrt(A B B A))\n                                   = trace(sqrt(A sigma_v A))\n  A = sqrt(sigma). Both sigma and A sigma_v A are symmetric, so we **can**\n  use the _symmetric_matrix_square_root function to find the roots of these\n  matrices.\n\n  Args:\n    sigma: a square, symmetric, real, positive semi-definite covariance matrix\n    sigma_v: same as sigma\n\n  Returns:\n    The trace of the positive square root of sigma*sigma_v\n  \"\"\"", "\n", "\n", "# Note sqrt_sigma is called \"A\" in the proof above", "\n", "sqrt_sigma", "=", "_symmetric_matrix_square_root", "(", "sigma", ")", "\n", "\n", "# This is sqrt(A sigma_v A) above", "\n", "sqrt_a_sigmav_a", "=", "math_ops", ".", "matmul", "(", "sqrt_sigma", ",", "\n", "math_ops", ".", "matmul", "(", "sigma_v", ",", "sqrt_sigma", ")", ")", "\n", "\n", "return", "math_ops", ".", "trace", "(", "_symmetric_matrix_square_root", "(", "sqrt_a_sigmav_a", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.frechet_classifier_distance_from_activations": [[84, 166], ["math_ops.to_double.shape.assert_has_rank", "math_ops.to_double.shape.assert_has_rank", "tensorflow.python.ops.math_ops.reduce_mean", "tensorflow.python.ops.math_ops.reduce_mean", "tensorflow.python.ops.math_ops.to_double", "tensorflow.python.ops.math_ops.to_double", "frechet_kernel_Inception_distance.trace_sqrt_product", "tensorflow.python.ops.math_ops.reduce_sum", "tensorflow.python.ops.math_ops.to_double", "tensorflow.python.ops.math_ops.to_double", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.math_ops.trace", "tensorflow.python.ops.math_ops.squared_difference", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.array_ops.shape", "tensorflow.python.ops.array_ops.shape"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.trace_sqrt_product"], ["", "def", "frechet_classifier_distance_from_activations", "(", "real_activations", ",", "\n", "generated_activations", ")", ":", "\n", "    ", "\"\"\"Classifier distance for evaluating a generative model.\n\n    This methods computes the Frechet classifier distance from activations of\n    real images and generated images. This can be used independently of the\n    frechet_classifier_distance() method, especially in the case of using large\n    batches during evaluation where we would like precompute all of the\n    activations before computing the classifier distance.\n\n    This technique is described in detail in https://arxiv.org/abs/1706.08500.\n    Given two Gaussian distribution with means m and m_w and covariance matrices\n    C and C_w, this function calculates\n\n                  |m - m_w|^2 + Tr(C + C_w - 2(C * C_w)^(1/2))\n\n    which captures how different the distributions of real images and generated\n    images (or more accurately, their visual features) are. Note that unlike the\n    Inception score, this is a true distance and utilizes information about real\n    world images.\n\n    Note that when computed using sample means and sample covariance matrices,\n    Frechet distance is biased. It is more biased for small sample sizes. (e.g.\n    even if the two distributions are the same, for a small sample size, the\n    expected Frechet distance is large). It is important to use the same\n    sample size to compute frechet classifier distance when comparing two\n    generative models.\n\n    Args:\n      real_activations: 2D Tensor containing activations of real data. Shape is\n        [batch_size, activation_size].\n      generated_activations: 2D Tensor containing activations of generated data.\n        Shape is [batch_size, activation_size].\n\n    Returns:\n     The Frechet Inception distance. A floating-point scalar of the same type\n     as the output of the activations.\n\n    \"\"\"", "\n", "real_activations", ".", "shape", ".", "assert_has_rank", "(", "2", ")", "\n", "generated_activations", ".", "shape", ".", "assert_has_rank", "(", "2", ")", "\n", "\n", "activations_dtype", "=", "real_activations", ".", "dtype", "\n", "if", "activations_dtype", "!=", "dtypes", ".", "float64", ":", "\n", "        ", "real_activations", "=", "math_ops", ".", "to_double", "(", "real_activations", ")", "\n", "generated_activations", "=", "math_ops", ".", "to_double", "(", "generated_activations", ")", "\n", "\n", "# Compute mean and covariance matrices of activations.", "\n", "", "m", "=", "math_ops", ".", "reduce_mean", "(", "real_activations", ",", "0", ")", "\n", "m_w", "=", "math_ops", ".", "reduce_mean", "(", "generated_activations", ",", "0", ")", "\n", "num_examples_real", "=", "math_ops", ".", "to_double", "(", "array_ops", ".", "shape", "(", "real_activations", ")", "[", "0", "]", ")", "\n", "num_examples_generated", "=", "math_ops", ".", "to_double", "(", "\n", "array_ops", ".", "shape", "(", "generated_activations", ")", "[", "0", "]", ")", "\n", "\n", "# sigma = (1 / (n - 1)) * (X - mu) (X - mu)^T", "\n", "real_centered", "=", "real_activations", "-", "m", "\n", "sigma", "=", "math_ops", ".", "matmul", "(", "\n", "real_centered", ",", "real_centered", ",", "transpose_a", "=", "True", ")", "/", "(", "\n", "num_examples_real", "-", "1", ")", "\n", "\n", "gen_centered", "=", "generated_activations", "-", "m_w", "\n", "sigma_w", "=", "math_ops", ".", "matmul", "(", "\n", "gen_centered", ",", "gen_centered", ",", "transpose_a", "=", "True", ")", "/", "(", "\n", "num_examples_generated", "-", "1", ")", "\n", "\n", "# Find the Tr(sqrt(sigma sigma_w)) component of FID", "\n", "sqrt_trace_component", "=", "trace_sqrt_product", "(", "sigma", ",", "sigma_w", ")", "\n", "\n", "# Compute the two components of FID.", "\n", "\n", "# First the covariance component.", "\n", "# Here, note that trace(A + B) = trace(A) + trace(B)", "\n", "trace", "=", "math_ops", ".", "trace", "(", "sigma", "+", "sigma_w", ")", "-", "2.0", "*", "sqrt_trace_component", "\n", "\n", "# Next the distance between means.", "\n", "mean", "=", "math_ops", ".", "reduce_sum", "(", "\n", "math_ops", ".", "squared_difference", "(", "m", ",", "m_w", ")", ")", "# Equivalent to L2 but more stable.", "\n", "fid", "=", "trace", "+", "mean", "\n", "if", "activations_dtype", "!=", "dtypes", ".", "float64", ":", "\n", "        ", "fid", "=", "math_ops", ".", "cast", "(", "fid", ",", "activations_dtype", ")", "\n", "\n", "", "return", "fid", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.kernel_classifier_distance_and_std_from_activations": [[167, 301], ["math_ops.cast.shape.assert_has_rank", "math_ops.cast.shape.assert_has_rank", "math_ops.cast.shape[].assert_is_compatible_with", "tensorflow.python.ops.math_ops.maximum", "tensorflow.python.ops.math_ops.to_int32", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.array_ops.zeros", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.functional_ops.map_fn", "tensorflow.python.ops.math_ops.reduce_mean", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.control_flow_ops.cond", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.array_ops.shape", "tensorflow.python.ops.array_ops.shape", "tensorflow.python.ops.math_ops.ceil", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.range", "tensorflow.python.ops.math_ops.less_equal", "tensorflow.python.ops.math_ops.sqrt", "tensorflow.python.ops.array_ops.fill", "tensorflow.python.ops.array_ops.fill", "tensorflow.python.ops.array_ops.fill", "tensorflow.python.ops.array_ops.fill", "tensorflow.python.ops.math_ops.cumsum", "tensorflow.python.ops.math_ops.cumsum", "tensorflow.shape", "tensorflow.python.ops.array_ops.constant", "float", "tensorflow.python.ops.math_ops.reduce_sum", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.math_ops.reduce_mean", "tensorflow.python.ops.math_ops.reduce_sum", "tensorflow.python.ops.math_ops.trace", "tensorflow.python.ops.math_ops.square", "tensorflow.python.ops.math_ops.reduce_sum", "tensorflow.python.ops.math_ops.trace"], "function", ["None"], ["", "def", "kernel_classifier_distance_and_std_from_activations", "(", "real_activations", ",", "\n", "generated_activations", ",", "\n", "max_block_size", "=", "10", ",", "\n", "dtype", "=", "None", ")", ":", "\n", "    ", "\"\"\"Kernel \"classifier\" distance for evaluating a generative model.\n\n    This methods computes the kernel classifier distance from activations of\n    real images and generated images. This can be used independently of the\n    kernel_classifier_distance() method, especially in the case of using large\n    batches during evaluation where we would like to precompute all of the\n    activations before computing the classifier distance, or if we want to\n    compute multiple metrics based on the same images. It also returns a rough\n    estimate of the standard error of the estimator.\n\n    This technique is described in detail in https://arxiv.org/abs/1801.01401.\n    Given two distributions P and Q of activations, this function calculates\n\n        E_{X, X' ~ P}[k(X, X')] + E_{Y, Y' ~ Q}[k(Y, Y')]\n          - 2 E_{X ~ P, Y ~ Q}[k(X, Y)]\n\n    where k is the polynomial kernel\n\n        k(x, y) = ( x^T y / dimension + 1 )^3.\n\n    This captures how different the distributions of real and generated images'\n    visual features are. Like the Frechet distance (and unlike the Inception\n    score), this is a true distance and incorporates information about the\n    target images. Unlike the Frechet score, this function computes an\n    *unbiased* and asymptotically normal estimator, which makes comparing\n    estimates across models much more intuitive.\n\n    The estimator used takes time quadratic in max_block_size. Larger values of\n    max_block_size will decrease the variance of the estimator but increase the\n    computational cost. This differs slightly from the estimator used by the\n    original paper; it is the block estimator of https://arxiv.org/abs/1307.1954.\n    The estimate of the standard error will also be more reliable when there are\n    more blocks, i.e. when max_block_size is smaller.\n\n    NOTE: the blocking code assumes that real_activations and\n    generated_activations are both in random order. If either is sorted in a\n    meaningful order, the estimator will behave poorly.\n\n    Args:\n      real_activations: 2D Tensor containing activations of real data. Shape is\n        [batch_size, activation_size].\n      generated_activations: 2D Tensor containing activations of generated data.\n        Shape is [batch_size, activation_size].\n      max_block_size: integer, default 1024. The distance estimator splits samples\n        into blocks for computational efficiency. Larger values are more\n        computationally expensive but decrease the variance of the distance\n        estimate. Having a smaller block size also gives a better estimate of the\n        standard error.\n      dtype: if not None, coerce activations to this dtype before computations.\n\n    Returns:\n     The Kernel Inception Distance. A floating-point scalar of the same type\n       as the output of the activations.\n     An estimate of the standard error of the distance estimator (a scalar of\n       the same type).\n    \"\"\"", "\n", "\n", "real_activations", ".", "shape", ".", "assert_has_rank", "(", "2", ")", "\n", "generated_activations", ".", "shape", ".", "assert_has_rank", "(", "2", ")", "\n", "real_activations", ".", "shape", "[", "1", "]", ".", "assert_is_compatible_with", "(", "\n", "generated_activations", ".", "shape", "[", "1", "]", ")", "\n", "\n", "if", "dtype", "is", "None", ":", "\n", "        ", "dtype", "=", "real_activations", ".", "dtype", "\n", "assert", "generated_activations", ".", "dtype", "==", "dtype", "\n", "", "else", ":", "\n", "        ", "real_activations", "=", "math_ops", ".", "cast", "(", "real_activations", ",", "dtype", ")", "\n", "generated_activations", "=", "math_ops", ".", "cast", "(", "generated_activations", ",", "dtype", ")", "\n", "\n", "# Figure out how to split the activations into blocks of approximately", "\n", "# equal size, with none larger than max_block_size.", "\n", "", "n_r", "=", "array_ops", ".", "shape", "(", "real_activations", ")", "[", "0", "]", "\n", "n_g", "=", "array_ops", ".", "shape", "(", "generated_activations", ")", "[", "0", "]", "\n", "\n", "n_bigger", "=", "math_ops", ".", "maximum", "(", "n_r", ",", "n_g", ")", "\n", "n_blocks", "=", "math_ops", ".", "to_int32", "(", "math_ops", ".", "ceil", "(", "n_bigger", "/", "max_block_size", ")", ")", "\n", "\n", "v_r", "=", "n_r", "//", "n_blocks", "\n", "v_g", "=", "n_g", "//", "n_blocks", "\n", "\n", "n_plusone_r", "=", "n_r", "-", "v_r", "*", "n_blocks", "\n", "n_plusone_g", "=", "n_g", "-", "v_g", "*", "n_blocks", "\n", "\n", "sizes_r", "=", "array_ops", ".", "concat", "(", "[", "\n", "array_ops", ".", "fill", "(", "[", "n_blocks", "-", "n_plusone_r", "]", ",", "v_r", ")", ",", "\n", "array_ops", ".", "fill", "(", "[", "n_plusone_r", "]", ",", "v_r", "+", "1", ")", ",", "\n", "]", ",", "0", ")", "\n", "sizes_g", "=", "array_ops", ".", "concat", "(", "[", "\n", "array_ops", ".", "fill", "(", "[", "n_blocks", "-", "n_plusone_g", "]", ",", "v_g", ")", ",", "\n", "array_ops", ".", "fill", "(", "[", "n_plusone_g", "]", ",", "v_g", "+", "1", ")", ",", "\n", "]", ",", "0", ")", "\n", "\n", "zero", "=", "array_ops", ".", "zeros", "(", "[", "1", "]", ",", "dtype", "=", "dtypes", ".", "int32", ")", "\n", "inds_r", "=", "array_ops", ".", "concat", "(", "[", "zero", ",", "math_ops", ".", "cumsum", "(", "sizes_r", ")", "]", ",", "0", ")", "\n", "inds_g", "=", "array_ops", ".", "concat", "(", "[", "zero", ",", "math_ops", ".", "cumsum", "(", "sizes_g", ")", "]", ",", "0", ")", "\n", "\n", "dim", "=", "math_ops", ".", "cast", "(", "tf", ".", "shape", "(", "real_activations", ")", "[", "1", "]", ",", "dtype", ")", "\n", "\n", "def", "compute_kid_block", "(", "i", ")", ":", "\n", "        ", "'Compute the ith block of the KID estimate.'", "\n", "r_s", "=", "inds_r", "[", "i", "]", "\n", "r_e", "=", "inds_r", "[", "i", "+", "1", "]", "\n", "r", "=", "real_activations", "[", "r_s", ":", "r_e", "]", "\n", "m", "=", "math_ops", ".", "cast", "(", "r_e", "-", "r_s", ",", "dtype", ")", "\n", "\n", "g_s", "=", "inds_g", "[", "i", "]", "\n", "g_e", "=", "inds_g", "[", "i", "+", "1", "]", "\n", "g", "=", "generated_activations", "[", "g_s", ":", "g_e", "]", "\n", "n", "=", "math_ops", ".", "cast", "(", "g_e", "-", "g_s", ",", "dtype", ")", "\n", "\n", "k_rr", "=", "(", "math_ops", ".", "matmul", "(", "r", ",", "r", ",", "transpose_b", "=", "True", ")", "/", "dim", "+", "1", ")", "**", "3", "\n", "k_rg", "=", "(", "math_ops", ".", "matmul", "(", "r", ",", "g", ",", "transpose_b", "=", "True", ")", "/", "dim", "+", "1", ")", "**", "3", "\n", "k_gg", "=", "(", "math_ops", ".", "matmul", "(", "g", ",", "g", ",", "transpose_b", "=", "True", ")", "/", "dim", "+", "1", ")", "**", "3", "\n", "return", "(", "-", "2", "*", "math_ops", ".", "reduce_mean", "(", "k_rg", ")", "+", "\n", "(", "math_ops", ".", "reduce_sum", "(", "k_rr", ")", "-", "math_ops", ".", "trace", "(", "k_rr", ")", ")", "/", "(", "m", "*", "(", "m", "-", "1", ")", ")", "+", "\n", "(", "math_ops", ".", "reduce_sum", "(", "k_gg", ")", "-", "math_ops", ".", "trace", "(", "k_gg", ")", ")", "/", "(", "n", "*", "(", "n", "-", "1", ")", ")", ")", "\n", "\n", "", "ests", "=", "functional_ops", ".", "map_fn", "(", "\n", "compute_kid_block", ",", "math_ops", ".", "range", "(", "n_blocks", ")", ",", "dtype", "=", "dtype", ",", "back_prop", "=", "False", ")", "\n", "\n", "mn", "=", "math_ops", ".", "reduce_mean", "(", "ests", ")", "\n", "\n", "# nn_impl.moments doesn't use the Bessel correction, which we want here", "\n", "n_blocks_", "=", "math_ops", ".", "cast", "(", "n_blocks", ",", "dtype", ")", "\n", "var", "=", "control_flow_ops", ".", "cond", "(", "\n", "math_ops", ".", "less_equal", "(", "n_blocks", ",", "1", ")", ",", "\n", "lambda", ":", "array_ops", ".", "constant", "(", "float", "(", "'nan'", ")", ",", "dtype", "=", "dtype", ")", ",", "\n", "lambda", ":", "math_ops", ".", "reduce_sum", "(", "math_ops", ".", "square", "(", "ests", "-", "mn", ")", ")", "/", "(", "n_blocks_", "-", "1", ")", ")", "\n", "\n", "return", "mn", ",", "math_ops", ".", "sqrt", "(", "var", "/", "n_blocks_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.inception_activations": [[303, 317], ["tensorflow.transpose", "tensorflow.image.resize_bilinear", "tensorflow.python.ops.array_ops.split", "tensorflow.python.ops.functional_ops.map_fn", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.array_ops.unstack", "functools.partial", "tensorflow.python.ops.array_ops.stack"], "function", ["None"], ["", "def", "inception_activations", "(", "images", ",", "num_splits", "=", "1", ")", ":", "\n", "    ", "images", "=", "tf", ".", "transpose", "(", "images", ",", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "size", "=", "299", "\n", "images", "=", "tf", ".", "image", ".", "resize_bilinear", "(", "images", ",", "[", "size", ",", "size", "]", ")", "\n", "generated_images_list", "=", "array_ops", ".", "split", "(", "images", ",", "num_or_size_splits", "=", "num_splits", ")", "\n", "activations", "=", "functional_ops", ".", "map_fn", "(", "\n", "fn", "=", "functools", ".", "partial", "(", "tfgan", ".", "eval", ".", "run_inception", ",", "output_tensor", "=", "'pool_3:0'", ")", ",", "\n", "elems", "=", "array_ops", ".", "stack", "(", "generated_images_list", ")", ",", "\n", "parallel_iterations", "=", "1", ",", "\n", "back_prop", "=", "False", ",", "\n", "swap_memory", "=", "True", ",", "\n", "name", "=", "'RunClassifier'", ")", "\n", "activations", "=", "array_ops", ".", "concat", "(", "array_ops", ".", "unstack", "(", "activations", ")", ",", "0", ")", "\n", "return", "activations", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_inception_activations": [[319, 326], ["numpy.zeros", "range", "activations.eval"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.eval"], ["", "def", "get_inception_activations", "(", "batch_size", ",", "images", ",", "inception_images", ",", "activations", ")", ":", "\n", "    ", "n_batches", "=", "images", ".", "shape", "[", "0", "]", "//", "batch_size", "\n", "act", "=", "np", ".", "zeros", "(", "[", "n_batches", "*", "batch_size", ",", "2048", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "n_batches", ")", ":", "\n", "        ", "inp", "=", "images", "[", "i", "*", "batch_size", ":", "(", "i", "+", "1", ")", "*", "batch_size", "]", "/", "255.", "*", "2", "-", "1", "\n", "act", "[", "i", "*", "batch_size", ":", "(", "i", "+", "1", ")", "*", "batch_size", "]", "=", "activations", ".", "eval", "(", "feed_dict", "=", "{", "inception_images", ":", "inp", "}", ")", "\n", "", "return", "act", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.activations2distance": [[328, 330], ["fcd.eval"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.eval"], ["", "def", "activations2distance", "(", "fcd", ",", "real_activation", ",", "fake_activation", ",", "act1", ",", "act2", ")", ":", "\n", "    ", "return", "fcd", ".", "eval", "(", "feed_dict", "=", "{", "real_activation", ":", "act1", ",", "fake_activation", ":", "act2", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_fid": [[332, 340], ["time.time", "frechet_kernel_Inception_distance.get_inception_activations", "frechet_kernel_Inception_distance.get_inception_activations", "frechet_kernel_Inception_distance.activations2distance"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_inception_activations", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_inception_activations", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.activations2distance"], ["", "def", "get_fid", "(", "fcd", ",", "batch_size", ",", "images1", ",", "images2", ",", "inception_images", ",", "real_activation", ",", "fake_activation", ",", "activations", ")", ":", "\n", "# print('Calculating FID with %i images from each distribution' % (images1.shape[0]))", "\n", "    ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "act1", "=", "get_inception_activations", "(", "batch_size", ",", "images1", ",", "inception_images", ",", "activations", ")", "\n", "act2", "=", "get_inception_activations", "(", "batch_size", ",", "images2", ",", "inception_images", ",", "activations", ")", "\n", "fid", "=", "activations2distance", "(", "fcd", ",", "real_activation", ",", "fake_activation", ",", "act1", ",", "act2", ")", "\n", "# print('FID calculation time: %f s' % (time.time() - start_time))", "\n", "return", "fid", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_kid": [[341, 349], ["time.time", "frechet_kernel_Inception_distance.get_inception_activations", "frechet_kernel_Inception_distance.get_inception_activations", "frechet_kernel_Inception_distance.activations2distance"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_inception_activations", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_inception_activations", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.activations2distance"], ["", "def", "get_kid", "(", "kcd", ",", "batch_size", ",", "images1", ",", "images2", ",", "inception_images", ",", "real_activation", ",", "fake_activation", ",", "activations", ")", ":", "\n", "# print('Calculating KID with %i images from each distribution' % (images1.shape[0]))", "\n", "    ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "act1", "=", "get_inception_activations", "(", "batch_size", ",", "images1", ",", "inception_images", ",", "activations", ")", "\n", "act2", "=", "get_inception_activations", "(", "batch_size", ",", "images2", ",", "inception_images", ",", "activations", ")", "\n", "kcd", "=", "activations2distance", "(", "kcd", ",", "real_activation", ",", "fake_activation", ",", "act1", ",", "act2", ")", "\n", "# print('KID calculation time: %f s' % (time.time() - start_time))", "\n", "return", "kcd", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.GAN_Metrics-Tensorflow.frechet_kernel_Inception_distance.get_images": [[350, 354], ["scipy.misc.imread", "scipy.misc.imresize"], "function", ["None"], ["", "def", "get_images", "(", "filename", ")", ":", "\n", "    ", "x", "=", "misc", ".", "imread", "(", "filename", ")", "\n", "x", "=", "misc", ".", "imresize", "(", "x", ",", "size", "=", "[", "299", ",", "299", "]", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.__init__": [[14, 34], ["os.path.join", "dominate.document", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "dominate.tags.meta", "str"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "web_dir", ",", "title", ",", "refresh", "=", "0", ")", ":", "\n", "        ", "\"\"\"Initialize the HTML classes\n\n        Parameters:\n            web_dir (str) -- a directory that stores the webpage. HTML file will be created at <web_dir>/index.html; images will be saved at <web_dir/images/\n            title (str)   -- the webpage name\n            refresh (int) -- how often the website refresh itself; if 0; no refreshing\n        \"\"\"", "\n", "self", ".", "title", "=", "title", "\n", "self", ".", "web_dir", "=", "web_dir", "\n", "self", ".", "img_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "web_dir", ",", "'images'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "web_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "web_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "img_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "img_dir", ")", "\n", "\n", "", "self", ".", "doc", "=", "dominate", ".", "document", "(", "title", "=", "title", ")", "\n", "if", "refresh", ">", "0", ":", "\n", "            ", "with", "self", ".", "doc", ".", "head", ":", "\n", "                ", "meta", "(", "http_equiv", "=", "\"refresh\"", ",", "content", "=", "str", "(", "refresh", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.get_image_dir": [[35, 38], ["None"], "methods", ["None"], ["", "", "", "def", "get_image_dir", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the directory that stores images\"\"\"", "\n", "return", "self", ".", "img_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.add_header": [[39, 47], ["dominate.tags.h3"], "methods", ["None"], ["", "def", "add_header", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Insert a header to the HTML file\n\n        Parameters:\n            text (str) -- the header text\n        \"\"\"", "\n", "with", "self", ".", "doc", ":", "\n", "            ", "h3", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.add_images": [[48, 67], ["dominate.tags.table", "html.HTML.doc.add", "dominate.tags.tr", "zip", "dominate.tags.td", "dominate.tags.p", "dominate.tags.br", "dominate.tags.p", "dominate.tags.a", "dominate.tags.img", "os.path.join", "os.path.join"], "methods", ["None"], ["", "", "def", "add_images", "(", "self", ",", "ims", ",", "txts", ",", "links", ",", "width", "=", "400", ")", ":", "\n", "        ", "\"\"\"add images to the HTML file\n\n        Parameters:\n            ims (str list)   -- a list of image paths\n            txts (str list)  -- a list of image names shown on the website\n            links (str list) --  a list of hyperref links; when you click an image, it will redirect you to a new page\n        \"\"\"", "\n", "self", ".", "t", "=", "table", "(", "border", "=", "1", ",", "style", "=", "\"table-layout: fixed;\"", ")", "# Insert a table", "\n", "self", ".", "doc", ".", "add", "(", "self", ".", "t", ")", "\n", "with", "self", ".", "t", ":", "\n", "            ", "with", "tr", "(", ")", ":", "\n", "                ", "for", "im", ",", "txt", ",", "link", "in", "zip", "(", "ims", ",", "txts", ",", "links", ")", ":", "\n", "                    ", "with", "td", "(", "style", "=", "\"word-wrap: break-word;\"", ",", "halign", "=", "\"center\"", ",", "valign", "=", "\"top\"", ")", ":", "\n", "                        ", "with", "p", "(", ")", ":", "\n", "                            ", "with", "a", "(", "href", "=", "os", ".", "path", ".", "join", "(", "'images'", ",", "link", ")", ")", ":", "\n", "                                ", "img", "(", "style", "=", "\"width:%dpx\"", "%", "width", ",", "src", "=", "os", ".", "path", ".", "join", "(", "'images'", ",", "im", ")", ")", "\n", "", "br", "(", ")", "\n", "p", "(", "txt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.save": [[68, 74], ["open", "open.write", "open.close", "html.HTML.doc.render"], "methods", ["None"], ["", "", "", "", "", "", "def", "save", "(", "self", ")", ":", "\n", "        ", "\"\"\"save the current content to the HMTL file\"\"\"", "\n", "html_file", "=", "'%s/index.html'", "%", "self", ".", "web_dir", "\n", "f", "=", "open", "(", "html_file", ",", "'wt'", ")", "\n", "f", ".", "write", "(", "self", ".", "doc", ".", "render", "(", ")", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.image_pool.ImagePool.__init__": [[12, 22], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "pool_size", ")", ":", "\n", "        ", "\"\"\"Initialize the ImagePool class\n\n        Parameters:\n            pool_size (int) -- the size of image buffer, if pool_size=0, no buffer will be created\n        \"\"\"", "\n", "self", ".", "pool_size", "=", "pool_size", "\n", "if", "self", ".", "pool_size", ">", "0", ":", "# create an empty pool", "\n", "            ", "self", ".", "num_imgs", "=", "0", "\n", "self", ".", "images", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.image_pool.ImagePool.query": [[23, 55], ["torch.cat", "torch.unsqueeze", "image_pool.ImagePool.images.append", "torch.cat.append", "random.uniform", "random.randint", "image_pool.ImagePool.images[].clone", "torch.cat.append", "torch.cat.append"], "methods", ["None"], ["", "", "def", "query", "(", "self", ",", "images", ")", ":", "\n", "        ", "\"\"\"Return an image from the pool.\n\n        Parameters:\n            images: the latest generated images from the generator\n\n        Returns images from the buffer.\n\n        By 50/100, the buffer will return input images.\n        By 50/100, the buffer will return images previously stored in the buffer,\n        and insert the current images to the buffer.\n        \"\"\"", "\n", "if", "self", ".", "pool_size", "==", "0", ":", "# if the buffer size is 0, do nothing", "\n", "            ", "return", "images", "\n", "", "return_images", "=", "[", "]", "\n", "for", "image", "in", "images", ":", "\n", "            ", "image", "=", "torch", ".", "unsqueeze", "(", "image", ".", "data", ",", "0", ")", "\n", "if", "self", ".", "num_imgs", "<", "self", ".", "pool_size", ":", "# if the buffer is not full; keep inserting current images to the buffer", "\n", "                ", "self", ".", "num_imgs", "=", "self", ".", "num_imgs", "+", "1", "\n", "self", ".", "images", ".", "append", "(", "image", ")", "\n", "return_images", ".", "append", "(", "image", ")", "\n", "", "else", ":", "\n", "                ", "p", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "p", ">", "0.5", ":", "# by 50% chance, the buffer will return a previously stored image, and insert the current image into the buffer", "\n", "                    ", "random_id", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "pool_size", "-", "1", ")", "# randint is inclusive", "\n", "tmp", "=", "self", ".", "images", "[", "random_id", "]", ".", "clone", "(", ")", "\n", "self", ".", "images", "[", "random_id", "]", "=", "image", "\n", "return_images", ".", "append", "(", "tmp", ")", "\n", "", "else", ":", "# by another 50% chance, the buffer will return the current image", "\n", "                    ", "return_images", ".", "append", "(", "image", ")", "\n", "", "", "", "return_images", "=", "torch", ".", "cat", "(", "return_images", ",", "0", ")", "# collect all the images and return", "\n", "return", "return_images", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.visualizer.Visualizer.__init__": [[58, 92], ["os.path.join", "visdom.Visdom", "os.path.join", "os.path.join", "print", "util.mkdirs", "open", "time.strftime", "log_file.write", "visualizer.Visualizer.vis.check_connection", "visualizer.Visualizer.create_visdom_connections"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.mkdirs", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.visualizer.Visualizer.create_visdom_connections"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the Visualizer class\n\n        Parameters:\n            opt -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        Step 1: Cache the training/test options\n        Step 2: connect to a visdom server\n        Step 3: create an HTML object for saveing HTML filters\n        Step 4: create a logging file to store training losses\n        \"\"\"", "\n", "self", ".", "opt", "=", "opt", "# cache the option", "\n", "self", ".", "display_id", "=", "opt", ".", "display_id", "\n", "self", ".", "use_html", "=", "opt", ".", "isTrain", "and", "not", "opt", ".", "no_html", "\n", "self", ".", "win_size", "=", "opt", ".", "display_winsize", "\n", "self", ".", "name", "=", "opt", ".", "name", "\n", "self", ".", "port", "=", "opt", ".", "display_port", "\n", "self", ".", "saved", "=", "False", "\n", "if", "self", ".", "display_id", ">", "0", ":", "# connect to a visdom server given <display_port> and <display_server>", "\n", "            ", "import", "visdom", "\n", "self", ".", "ncols", "=", "opt", ".", "display_ncols", "\n", "self", ".", "vis", "=", "visdom", ".", "Visdom", "(", "server", "=", "opt", ".", "display_server", ",", "port", "=", "opt", ".", "display_port", ",", "env", "=", "opt", ".", "display_env", ")", "\n", "if", "not", "self", ".", "vis", ".", "check_connection", "(", ")", ":", "\n", "                ", "self", ".", "create_visdom_connections", "(", ")", "\n", "\n", "", "", "if", "self", ".", "use_html", ":", "# create an HTML object at <checkpoints_dir>/web/; images will be saved under <checkpoints_dir>/web/images/", "\n", "            ", "self", ".", "web_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ",", "'web'", ")", "\n", "self", ".", "img_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "web_dir", ",", "'images'", ")", "\n", "print", "(", "'create web directory %s...'", "%", "self", ".", "web_dir", ")", "\n", "util", ".", "mkdirs", "(", "[", "self", ".", "web_dir", ",", "self", ".", "img_dir", "]", ")", "\n", "# create a logging file to store training losses", "\n", "", "self", ".", "log_name", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ",", "'loss_log.txt'", ")", "\n", "with", "open", "(", "self", ".", "log_name", ",", "\"a\"", ")", "as", "log_file", ":", "\n", "            ", "now", "=", "time", ".", "strftime", "(", "\"%c\"", ")", "\n", "log_file", ".", "write", "(", "'================ Training Loss (%s) ================\\n'", "%", "now", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.visualizer.Visualizer.reset": [[93, 96], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset the self.saved status\"\"\"", "\n", "self", ".", "saved", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.visualizer.Visualizer.create_visdom_connections": [[97, 103], ["print", "print", "subprocess.Popen"], "methods", ["None"], ["", "def", "create_visdom_connections", "(", "self", ")", ":", "\n", "        ", "\"\"\"If the program could not connect to Visdom server, this function will start a new server at port < self.port > \"\"\"", "\n", "cmd", "=", "sys", ".", "executable", "+", "' -m visdom.server -p %d &>/dev/null &'", "%", "self", ".", "port", "\n", "print", "(", "'\\n\\nCould not connect to Visdom server. \\n Trying to start a server....'", ")", "\n", "print", "(", "'Command: %s'", "%", "cmd", ")", "\n", "Popen", "(", "cmd", ",", "shell", "=", "True", ",", "stdout", "=", "PIPE", ",", "stderr", "=", "PIPE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.visualizer.Visualizer.display_current_results": [[104, 184], ["visuals.items", "html.HTML", "range", "html.HTML.save", "min", "visuals.items", "util.tensor2im", "os.path.join", "util.save_image", "html.HTML.add_header", "visuals.items", "html.HTML.add_images", "len", "util.tensor2im", "images.append", "numpy.ones_like", "images.append", "visualizer.Visualizer.vis.images", "visualizer.Visualizer.vis.text", "visuals.items", "util.tensor2im", "ims.append", "txts.append", "links.append", "next", "util.tensor2im.transpose", "util.tensor2im.transpose", "visualizer.Visualizer.create_visdom_connections", "util.tensor2im", "visualizer.Visualizer.vis.image", "visualizer.Visualizer.create_visdom_connections", "iter", "dict", "dict", "util.tensor2im.transpose", "visuals.values", "dict"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.save", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.tensor2im", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.save_image", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.add_header", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.add_images", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.tensor2im", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.tensor2im", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.visualizer.Visualizer.create_visdom_connections", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.tensor2im", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.visualizer.Visualizer.create_visdom_connections"], ["", "def", "display_current_results", "(", "self", ",", "visuals", ",", "epoch", ",", "save_result", ")", ":", "\n", "        ", "\"\"\"Display current results on visdom; save current results to an HTML file.\n\n        Parameters:\n            visuals (OrderedDict) - - dictionary of images to display or save\n            epoch (int) - - the current epoch\n            save_result (bool) - - if save the current results to an HTML file\n        \"\"\"", "\n", "if", "self", ".", "display_id", ">", "0", ":", "# show images in the browser using visdom", "\n", "            ", "ncols", "=", "self", ".", "ncols", "\n", "if", "ncols", ">", "0", ":", "# show all the images in one visdom panel", "\n", "                ", "ncols", "=", "min", "(", "ncols", ",", "len", "(", "visuals", ")", ")", "\n", "h", ",", "w", "=", "next", "(", "iter", "(", "visuals", ".", "values", "(", ")", ")", ")", ".", "shape", "[", ":", "2", "]", "\n", "table_css", "=", "\"\"\"<style>\n                        table {border-collapse: separate; border-spacing: 4px; white-space: nowrap; text-align: center}\n                        table td {width: % dpx; height: % dpx; padding: 4px; outline: 4px solid black}\n                        </style>\"\"\"", "%", "(", "w", ",", "h", ")", "# create a table css", "\n", "# create a table of images.", "\n", "title", "=", "self", ".", "name", "\n", "label_html", "=", "''", "\n", "label_html_row", "=", "''", "\n", "images", "=", "[", "]", "\n", "idx", "=", "0", "\n", "for", "label", ",", "image", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                    ", "image_numpy", "=", "util", ".", "tensor2im", "(", "image", ")", "\n", "label_html_row", "+=", "'<td>%s</td>'", "%", "label", "\n", "images", ".", "append", "(", "image_numpy", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ")", "\n", "idx", "+=", "1", "\n", "if", "idx", "%", "ncols", "==", "0", ":", "\n", "                        ", "label_html", "+=", "'<tr>%s</tr>'", "%", "label_html_row", "\n", "label_html_row", "=", "''", "\n", "", "", "white_image", "=", "np", ".", "ones_like", "(", "image_numpy", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ")", "*", "255", "\n", "while", "idx", "%", "ncols", "!=", "0", ":", "\n", "                    ", "images", ".", "append", "(", "white_image", ")", "\n", "label_html_row", "+=", "'<td></td>'", "\n", "idx", "+=", "1", "\n", "", "if", "label_html_row", "!=", "''", ":", "\n", "                    ", "label_html", "+=", "'<tr>%s</tr>'", "%", "label_html_row", "\n", "", "try", ":", "\n", "                    ", "self", ".", "vis", ".", "images", "(", "images", ",", "nrow", "=", "ncols", ",", "win", "=", "self", ".", "display_id", "+", "1", ",", "\n", "padding", "=", "2", ",", "opts", "=", "dict", "(", "title", "=", "title", "+", "' images'", ")", ")", "\n", "label_html", "=", "'<table>%s</table>'", "%", "label_html", "\n", "self", ".", "vis", ".", "text", "(", "table_css", "+", "label_html", ",", "win", "=", "self", ".", "display_id", "+", "2", ",", "\n", "opts", "=", "dict", "(", "title", "=", "title", "+", "' labels'", ")", ")", "\n", "", "except", "VisdomExceptionBase", ":", "\n", "                    ", "self", ".", "create_visdom_connections", "(", ")", "\n", "\n", "", "", "else", ":", "# show each image in a separate visdom panel;", "\n", "                ", "idx", "=", "1", "\n", "try", ":", "\n", "                    ", "for", "label", ",", "image", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                        ", "image_numpy", "=", "util", ".", "tensor2im", "(", "image", ")", "\n", "self", ".", "vis", ".", "image", "(", "image_numpy", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ",", "opts", "=", "dict", "(", "title", "=", "label", ")", ",", "\n", "win", "=", "self", ".", "display_id", "+", "idx", ")", "\n", "idx", "+=", "1", "\n", "", "", "except", "VisdomExceptionBase", ":", "\n", "                    ", "self", ".", "create_visdom_connections", "(", ")", "\n", "\n", "", "", "", "if", "self", ".", "use_html", "and", "(", "save_result", "or", "not", "self", ".", "saved", ")", ":", "# save images to an HTML file if they haven't been saved.", "\n", "            ", "self", ".", "saved", "=", "True", "\n", "# save images to the disk", "\n", "for", "label", ",", "image", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                ", "image_numpy", "=", "util", ".", "tensor2im", "(", "image", ")", "\n", "img_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "img_dir", ",", "'epoch%.3d_%s.png'", "%", "(", "epoch", ",", "label", ")", ")", "\n", "util", ".", "save_image", "(", "image_numpy", ",", "img_path", ")", "\n", "\n", "# update website", "\n", "", "webpage", "=", "html", ".", "HTML", "(", "self", ".", "web_dir", ",", "'Experiment name = %s'", "%", "self", ".", "name", ",", "refresh", "=", "1", ")", "\n", "for", "n", "in", "range", "(", "epoch", ",", "0", ",", "-", "1", ")", ":", "\n", "                ", "webpage", ".", "add_header", "(", "'epoch [%d]'", "%", "n", ")", "\n", "ims", ",", "txts", ",", "links", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "label", ",", "image_numpy", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                    ", "image_numpy", "=", "util", ".", "tensor2im", "(", "image", ")", "\n", "img_path", "=", "'epoch%.3d_%s.png'", "%", "(", "n", ",", "label", ")", "\n", "ims", ".", "append", "(", "img_path", ")", "\n", "txts", ".", "append", "(", "label", ")", "\n", "links", ".", "append", "(", "img_path", ")", "\n", "", "webpage", ".", "add_images", "(", "ims", ",", "txts", ",", "links", ",", "width", "=", "self", ".", "win_size", ")", "\n", "", "webpage", ".", "save", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.visualizer.Visualizer.plot_current_losses": [[185, 209], ["visualizer.Visualizer.plot_data[].append", "visualizer.Visualizer.plot_data[].append", "hasattr", "visualizer.Visualizer.vis.line", "list", "visualizer.Visualizer.create_visdom_connections", "losses.keys", "numpy.stack", "numpy.array", "len", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.visualizer.Visualizer.create_visdom_connections"], ["", "", "def", "plot_current_losses", "(", "self", ",", "epoch", ",", "counter_ratio", ",", "losses", ")", ":", "\n", "        ", "\"\"\"display the current losses on visdom display: dictionary of error labels and values\n\n        Parameters:\n            epoch (int)           -- current epoch\n            counter_ratio (float) -- progress (percentage) in the current epoch, between 0 to 1\n            losses (OrderedDict)  -- training losses stored in the format of (name, float) pairs\n        \"\"\"", "\n", "if", "not", "hasattr", "(", "self", ",", "'plot_data'", ")", ":", "\n", "            ", "self", ".", "plot_data", "=", "{", "'X'", ":", "[", "]", ",", "'Y'", ":", "[", "]", ",", "'legend'", ":", "list", "(", "losses", ".", "keys", "(", ")", ")", "}", "\n", "", "self", ".", "plot_data", "[", "'X'", "]", ".", "append", "(", "epoch", "+", "counter_ratio", ")", "\n", "self", ".", "plot_data", "[", "'Y'", "]", ".", "append", "(", "[", "losses", "[", "k", "]", "for", "k", "in", "self", ".", "plot_data", "[", "'legend'", "]", "]", ")", "\n", "try", ":", "\n", "            ", "self", ".", "vis", ".", "line", "(", "\n", "X", "=", "np", ".", "stack", "(", "[", "np", ".", "array", "(", "self", ".", "plot_data", "[", "'X'", "]", ")", "]", "*", "len", "(", "self", ".", "plot_data", "[", "'legend'", "]", ")", ",", "1", ")", ",", "\n", "Y", "=", "np", ".", "array", "(", "self", ".", "plot_data", "[", "'Y'", "]", ")", ",", "\n", "opts", "=", "{", "\n", "'title'", ":", "self", ".", "name", "+", "' loss over time'", ",", "\n", "'legend'", ":", "self", ".", "plot_data", "[", "'legend'", "]", ",", "\n", "'xlabel'", ":", "'epoch'", ",", "\n", "'ylabel'", ":", "'loss'", "}", ",", "\n", "win", "=", "self", ".", "display_id", ")", "\n", "", "except", "VisdomExceptionBase", ":", "\n", "            ", "self", ".", "create_visdom_connections", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.visualizer.Visualizer.print_current_losses": [[211, 228], ["losses.items", "print", "open", "log_file.write"], "methods", ["None"], ["", "", "def", "print_current_losses", "(", "self", ",", "epoch", ",", "iters", ",", "losses", ",", "t_comp", ",", "t_data", ")", ":", "\n", "        ", "\"\"\"print current losses on console; also save the losses to the disk\n\n        Parameters:\n            epoch (int) -- current epoch\n            iters (int) -- current training iteration during this epoch (reset to 0 at the end of every epoch)\n            losses (OrderedDict) -- training losses stored in the format of (name, float) pairs\n            t_comp (float) -- computational time per data point (normalized by batch_size)\n            t_data (float) -- data loading time per data point (normalized by batch_size)\n        \"\"\"", "\n", "message", "=", "'(epoch: %d, iters: %d, time: %.3f, data: %.3f) '", "%", "(", "epoch", ",", "iters", ",", "t_comp", ",", "t_data", ")", "\n", "for", "k", ",", "v", "in", "losses", ".", "items", "(", ")", ":", "\n", "            ", "message", "+=", "'%s: %.3f '", "%", "(", "k", ",", "v", ")", "\n", "\n", "", "print", "(", "message", ")", "# print the message", "\n", "with", "open", "(", "self", ".", "log_name", ",", "\"a\"", ")", "as", "log_file", ":", "\n", "            ", "log_file", ".", "write", "(", "'%s\\n'", "%", "message", ")", "# save the message", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.visualizer.save_images": [[16, 50], ["webpage.get_image_dir", "ntpath.basename", "webpage.add_header", "visuals.items", "webpage.add_images", "os.path.splitext", "util.tensor2im", "os.path.join", "util.save_image", "ims.append", "txts.append", "links.append", "scipy.misc.imresize", "scipy.misc.imresize", "int", "int"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.get_image_dir", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.add_header", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.add_images", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.tensor2im", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.save_image"], ["", "def", "save_images", "(", "webpage", ",", "visuals", ",", "image_path", ",", "aspect_ratio", "=", "1.0", ",", "width", "=", "256", ")", ":", "\n", "    ", "\"\"\"Save images to the disk.\n\n    Parameters:\n        webpage (the HTML class) -- the HTML webpage class that stores these imaegs (see html.py for more details)\n        visuals (OrderedDict)    -- an ordered dictionary that stores (name, images (either tensor or numpy) ) pairs\n        image_path (str)         -- the string is used to create image paths\n        aspect_ratio (float)     -- the aspect ratio of saved images\n        width (int)              -- the images will be resized to width x width\n\n    This function will save images stored in 'visuals' to the HTML file specified by 'webpage'.\n    \"\"\"", "\n", "image_dir", "=", "webpage", ".", "get_image_dir", "(", ")", "\n", "short_path", "=", "ntpath", ".", "basename", "(", "image_path", "[", "0", "]", ")", "\n", "name", "=", "os", ".", "path", ".", "splitext", "(", "short_path", ")", "[", "0", "]", "\n", "\n", "webpage", ".", "add_header", "(", "name", ")", "\n", "ims", ",", "txts", ",", "links", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "label", ",", "im_data", "in", "visuals", ".", "items", "(", ")", ":", "\n", "        ", "im", "=", "util", ".", "tensor2im", "(", "im_data", ")", "\n", "image_name", "=", "'%s_%s.png'", "%", "(", "name", ",", "label", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "image_name", ")", "\n", "h", ",", "w", ",", "_", "=", "im", ".", "shape", "\n", "if", "aspect_ratio", ">", "1.0", ":", "\n", "            ", "im", "=", "imresize", "(", "im", ",", "(", "h", ",", "int", "(", "w", "*", "aspect_ratio", ")", ")", ",", "interp", "=", "'bicubic'", ")", "\n", "", "if", "aspect_ratio", "<", "1.0", ":", "\n", "            ", "im", "=", "imresize", "(", "im", ",", "(", "int", "(", "h", "/", "aspect_ratio", ")", ",", "w", ")", ",", "interp", "=", "'bicubic'", ")", "\n", "", "util", ".", "save_image", "(", "im", ",", "save_path", ")", "\n", "\n", "ims", ".", "append", "(", "image_name", ")", "\n", "txts", ".", "append", "(", "label", ")", "\n", "links", ".", "append", "(", "image_name", ")", "\n", "", "webpage", ".", "add_images", "(", "ims", ",", "txts", ",", "links", ",", "width", "=", "width", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.get_data.GetData.__init__": [[27, 34], ["url_dict.get", "technique.lower"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.get_data.GetData.get"], ["def", "__init__", "(", "self", ",", "technique", "=", "'cyclegan'", ",", "verbose", "=", "True", ")", ":", "\n", "        ", "url_dict", "=", "{", "\n", "'pix2pix'", ":", "'http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/'", ",", "\n", "'cyclegan'", ":", "'https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets'", "\n", "}", "\n", "self", ".", "url", "=", "url_dict", ".", "get", "(", "technique", ".", "lower", "(", ")", ")", "\n", "self", ".", "_verbose", "=", "verbose", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.get_data.GetData._print": [[35, 38], ["print"], "methods", ["None"], ["", "def", "_print", "(", "self", ",", "text", ")", ":", "\n", "        ", "if", "self", ".", "_verbose", ":", "\n", "            ", "print", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.get_data.GetData._get_options": [[39, 45], ["bs4.BeautifulSoup", "bs4.BeautifulSoup.find_all", "h.text.endswith"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_get_options", "(", "r", ")", ":", "\n", "        ", "soup", "=", "BeautifulSoup", "(", "r", ".", "text", ",", "'lxml'", ")", "\n", "options", "=", "[", "h", ".", "text", "for", "h", "in", "soup", ".", "find_all", "(", "'a'", ",", "href", "=", "True", ")", "\n", "if", "h", ".", "text", ".", "endswith", "(", "(", "'.zip'", ",", "'tar.gz'", ")", ")", "]", "\n", "return", "options", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.get_data.GetData._present_options": [[46, 55], ["requests.get", "get_data.GetData._get_options", "print", "enumerate", "input", "print", "int"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.get_data.GetData.get", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.get_data.GetData._get_options"], ["", "def", "_present_options", "(", "self", ")", ":", "\n", "        ", "r", "=", "requests", ".", "get", "(", "self", ".", "url", ")", "\n", "options", "=", "self", ".", "_get_options", "(", "r", ")", "\n", "print", "(", "'Options:\\n'", ")", "\n", "for", "i", ",", "o", "in", "enumerate", "(", "options", ")", ":", "\n", "            ", "print", "(", "\"{0}: {1}\"", ".", "format", "(", "i", ",", "o", ")", ")", "\n", "", "choice", "=", "input", "(", "\"\\nPlease enter the number of the \"", "\n", "\"dataset above you wish to download:\"", ")", "\n", "return", "options", "[", "int", "(", "choice", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.get_data.GetData._download_data": [[56, 78], ["os.path.basename", "os.path.join", "os.path.basename.endswith", "get_data.GetData._print", "zipfile.ZipFile.extractall", "zipfile.ZipFile.close", "os.remove", "os.path.isdir", "os.makedirs", "open", "requests.get", "f.write", "tarfile.open", "os.path.basename.endswith", "zipfile.ZipFile", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.get_data.GetData._print", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.get_data.GetData.get"], ["", "def", "_download_data", "(", "self", ",", "dataset_url", ",", "save_path", ")", ":", "\n", "        ", "if", "not", "isdir", "(", "save_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_path", ")", "\n", "\n", "", "base", "=", "basename", "(", "dataset_url", ")", "\n", "temp_save_path", "=", "join", "(", "save_path", ",", "base", ")", "\n", "\n", "with", "open", "(", "temp_save_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "r", "=", "requests", ".", "get", "(", "dataset_url", ")", "\n", "f", ".", "write", "(", "r", ".", "content", ")", "\n", "\n", "", "if", "base", ".", "endswith", "(", "'.tar.gz'", ")", ":", "\n", "            ", "obj", "=", "tarfile", ".", "open", "(", "temp_save_path", ")", "\n", "", "elif", "base", ".", "endswith", "(", "'.zip'", ")", ":", "\n", "            ", "obj", "=", "ZipFile", "(", "temp_save_path", ",", "'r'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown File Type: {0}.\"", ".", "format", "(", "base", ")", ")", "\n", "\n", "", "self", ".", "_print", "(", "\"Unpacking Data...\"", ")", "\n", "obj", ".", "extractall", "(", "save_path", ")", "\n", "obj", ".", "close", "(", ")", "\n", "os", ".", "remove", "(", "temp_save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.get_data.GetData.get": [[79, 111], ["os.path.join", "os.path.isdir", "os.path.abspath", "get_data.GetData._present_options", "warnings.warn", "get_data.GetData._print", "get_data.GetData._download_data", "get_data.GetData.split"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.get_data.GetData._present_options", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.get_data.GetData._print", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.get_data.GetData._download_data"], ["", "def", "get", "(", "self", ",", "save_path", ",", "dataset", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Download a dataset.\n\n        Parameters:\n            save_path (str) -- A directory to save the data to.\n            dataset (str)   -- (optional). A specific dataset to download.\n                            Note: this must include the file extension.\n                            If None, options will be presented for you\n                            to choose from.\n\n        Returns:\n            save_path_full (str) -- the absolute path to the downloaded data.\n\n        \"\"\"", "\n", "if", "dataset", "is", "None", ":", "\n", "            ", "selected_dataset", "=", "self", ".", "_present_options", "(", ")", "\n", "", "else", ":", "\n", "            ", "selected_dataset", "=", "dataset", "\n", "\n", "", "save_path_full", "=", "join", "(", "save_path", ",", "selected_dataset", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "\n", "\n", "if", "isdir", "(", "save_path_full", ")", ":", "\n", "            ", "warn", "(", "\"\\n'{0}' already exists. Voiding Download.\"", ".", "format", "(", "\n", "save_path_full", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_print", "(", "'Downloading Data...'", ")", "\n", "url", "=", "\"{0}/{1}\"", ".", "format", "(", "self", ".", "url", ",", "selected_dataset", ")", "\n", "self", ".", "_download_data", "(", "url", ",", "save_path", "=", "save_path", ")", "\n", "\n", "", "return", "abspath", "(", "save_path_full", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.tensor2im": [[9, 28], ["np.tile.astype", "isinstance", "isinstance", "image_tensor[].cpu().float().numpy", "numpy.tile", "image_tensor[].cpu().float", "numpy.transpose", "image_tensor[].cpu"], "function", ["None"], ["def", "tensor2im", "(", "input_image", ",", "imtype", "=", "np", ".", "uint8", ")", ":", "\n", "    ", "\"\"\"\"Converts a Tensor array into a numpy image array.\n\n    Parameters:\n        input_image (tensor) --  the input image tensor array\n        imtype (type)        --  the desired type of the converted numpy array\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "input_image", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "if", "isinstance", "(", "input_image", ",", "torch", ".", "Tensor", ")", ":", "# get the data from a variable", "\n", "            ", "image_tensor", "=", "input_image", ".", "data", "\n", "", "else", ":", "\n", "            ", "return", "input_image", "\n", "", "image_numpy", "=", "image_tensor", "[", "0", "]", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "# convert it into a numpy array", "\n", "if", "image_numpy", ".", "shape", "[", "0", "]", "==", "1", ":", "# grayscale to RGB", "\n", "            ", "image_numpy", "=", "np", ".", "tile", "(", "image_numpy", ",", "(", "3", ",", "1", ",", "1", ")", ")", "\n", "", "image_numpy", "=", "(", "np", ".", "transpose", "(", "image_numpy", ",", "(", "1", ",", "2", ",", "0", ")", ")", "+", "1", ")", "/", "2.0", "*", "255.0", "# post-processing: tranpose and scaling", "\n", "", "else", ":", "# if it is a numpy array, do nothing", "\n", "        ", "image_numpy", "=", "input_image", "\n", "", "return", "image_numpy", ".", "astype", "(", "imtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.diagnose_network": [[30, 47], ["net.parameters", "print", "print", "torch.mean", "torch.abs"], "function", ["None"], ["", "def", "diagnose_network", "(", "net", ",", "name", "=", "'network'", ")", ":", "\n", "    ", "\"\"\"Calculate and print the mean of average absolute(gradients)\n\n    Parameters:\n        net (torch network) -- Torch network\n        name (str) -- the name of the network\n    \"\"\"", "\n", "mean", "=", "0.0", "\n", "count", "=", "0", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "        ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "            ", "mean", "+=", "torch", ".", "mean", "(", "torch", ".", "abs", "(", "param", ".", "grad", ".", "data", ")", ")", "\n", "count", "+=", "1", "\n", "", "", "if", "count", ">", "0", ":", "\n", "        ", "mean", "=", "mean", "/", "count", "\n", "", "print", "(", "name", ")", "\n", "print", "(", "mean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.save_image": [[49, 58], ["PIL.Image.fromarray", "Image.fromarray.save"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.save"], ["", "def", "save_image", "(", "image_numpy", ",", "image_path", ")", ":", "\n", "    ", "\"\"\"Save a numpy image to the disk\n\n    Parameters:\n        image_numpy (numpy array) -- input numpy array\n        image_path (str)          -- the path of the image\n    \"\"\"", "\n", "image_pil", "=", "Image", ".", "fromarray", "(", "image_numpy", ")", "\n", "image_pil", ".", "save", "(", "image_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.print_numpy": [[60, 74], ["x.flatten.astype", "print", "x.flatten.flatten", "print", "numpy.mean", "numpy.min", "numpy.max", "numpy.median", "numpy.std"], "function", ["None"], ["", "def", "print_numpy", "(", "x", ",", "val", "=", "True", ",", "shp", "=", "False", ")", ":", "\n", "    ", "\"\"\"Print the mean, min, max, median, std, and size of a numpy array\n\n    Parameters:\n        val (bool) -- if print the values of the numpy array\n        shp (bool) -- if print the shape of the numpy array\n    \"\"\"", "\n", "x", "=", "x", ".", "astype", "(", "np", ".", "float64", ")", "\n", "if", "shp", ":", "\n", "        ", "print", "(", "'shape,'", ",", "x", ".", "shape", ")", "\n", "", "if", "val", ":", "\n", "        ", "x", "=", "x", ".", "flatten", "(", ")", "\n", "print", "(", "'mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f'", "%", "(", "\n", "np", ".", "mean", "(", "x", ")", ",", "np", ".", "min", "(", "x", ")", ",", "np", ".", "max", "(", "x", ")", ",", "np", ".", "median", "(", "x", ")", ",", "np", ".", "std", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.mkdirs": [[76, 87], ["isinstance", "util.mkdir", "isinstance", "util.mkdir"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.mkdir", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.mkdir"], ["", "", "def", "mkdirs", "(", "paths", ")", ":", "\n", "    ", "\"\"\"create empty directories if they don't exist\n\n    Parameters:\n        paths (str list) -- a list of directory paths\n    \"\"\"", "\n", "if", "isinstance", "(", "paths", ",", "list", ")", "and", "not", "isinstance", "(", "paths", ",", "str", ")", ":", "\n", "        ", "for", "path", "in", "paths", ":", "\n", "            ", "mkdir", "(", "path", ")", "\n", "", "", "else", ":", "\n", "        ", "mkdir", "(", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.mkdir": [[89, 97], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "def", "mkdir", "(", "path", ")", ":", "\n", "    ", "\"\"\"create a single empty directory if it didn't exist\n\n    Parameters:\n        path (str) -- a single directory path\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.Identity.forward": [[15, 17], ["None"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.GANLoss.__init__": [[220, 243], ["torch.Module.__init__", "networks.GANLoss.register_buffer", "networks.GANLoss.register_buffer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "gan_mode", ",", "target_real_label", "=", "1.0", ",", "target_fake_label", "=", "0.0", ")", ":", "\n", "        ", "\"\"\" Initialize the GANLoss class.\n\n        Parameters:\n            gan_mode (str) - - the type of GAN objective. It currently supports vanilla, lsgan, and wgangp.\n            target_real_label (bool) - - label for a real image\n            target_fake_label (bool) - - label of a fake image\n\n        Note: Do not use sigmoid as the last layer of Discriminator.\n        LSGAN needs no sigmoid. vanilla GANs will handle it with BCEWithLogitsLoss.\n        \"\"\"", "\n", "super", "(", "GANLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "'real_label'", ",", "torch", ".", "tensor", "(", "target_real_label", ")", ")", "\n", "self", ".", "register_buffer", "(", "'fake_label'", ",", "torch", ".", "tensor", "(", "target_fake_label", ")", ")", "\n", "self", ".", "gan_mode", "=", "gan_mode", "\n", "if", "gan_mode", "==", "'lsgan'", ":", "\n", "            ", "self", ".", "loss", "=", "nn", ".", "MSELoss", "(", ")", "\n", "", "elif", "gan_mode", "==", "'vanilla'", ":", "\n", "            ", "self", ".", "loss", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "", "elif", "gan_mode", "in", "[", "'wgangp'", "]", ":", "\n", "            ", "self", ".", "loss", "=", "None", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'gan mode %s not implemented'", "%", "gan_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.GANLoss.get_target_tensor": [[244, 260], ["target_tensor.expand_as"], "methods", ["None"], ["", "", "def", "get_target_tensor", "(", "self", ",", "prediction", ",", "target_is_real", ")", ":", "\n", "        ", "\"\"\"Create label tensors with the same size as the input.\n\n        Parameters:\n            prediction (tensor) - - tpyically the prediction from a discriminator\n            target_is_real (bool) - - if the ground truth label is for real images or fake images\n\n        Returns:\n            A label tensor filled with ground truth label, and with the size of the input\n        \"\"\"", "\n", "\n", "if", "target_is_real", ":", "\n", "            ", "target_tensor", "=", "self", ".", "real_label", "\n", "", "else", ":", "\n", "            ", "target_tensor", "=", "self", ".", "fake_label", "\n", "", "return", "target_tensor", ".", "expand_as", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.GANLoss.__call__": [[261, 280], ["networks.GANLoss.get_target_tensor", "networks.GANLoss.loss", "prediction.mean", "prediction.mean"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.GANLoss.get_target_tensor"], ["", "def", "__call__", "(", "self", ",", "prediction", ",", "target_is_real", ")", ":", "\n", "        ", "\"\"\"Calculate loss given Discriminator's output and grount truth labels.\n\n        Parameters:\n            prediction (tensor) - - tpyically the prediction output from a discriminator\n            target_is_real (bool) - - if the ground truth label is for real images or fake images\n\n        Returns:\n            the calculated loss.\n        \"\"\"", "\n", "if", "self", ".", "gan_mode", "in", "[", "'lsgan'", ",", "'vanilla'", "]", ":", "\n", "            ", "target_tensor", "=", "self", ".", "get_target_tensor", "(", "prediction", ",", "target_is_real", ")", "\n", "loss", "=", "self", ".", "loss", "(", "prediction", ",", "target_tensor", ")", "\n", "", "elif", "self", ".", "gan_mode", "==", "'wgangp'", ":", "\n", "            ", "if", "target_is_real", ":", "\n", "                ", "loss", "=", "-", "prediction", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "prediction", ".", "mean", "(", ")", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.ResnetGenerator.__init__": [[325, 374], ["torch.Module.__init__", "range", "range", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "networks.ResnetBlock", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "int", "int"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ",", "n_blocks", "=", "6", ",", "padding_type", "=", "'reflect'", ")", ":", "\n", "        ", "\"\"\"Construct a Resnet-based generator\n\n        Parameters:\n            input_nc (int)      -- the number of channels in input images\n            output_nc (int)     -- the number of channels in output images\n            ngf (int)           -- the number of filters in the last conv layer\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers\n            n_blocks (int)      -- the number of ResNet blocks\n            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n        \"\"\"", "\n", "assert", "(", "n_blocks", ">=", "0", ")", "\n", "super", "(", "ResnetGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "model", "=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", ",", "\n", "nn", ".", "Conv2d", "(", "input_nc", ",", "ngf", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "n_downsampling", "=", "2", "\n", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add downsampling layers", "\n", "            ", "mult", "=", "2", "**", "i", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", "*", "mult", ",", "ngf", "*", "mult", "*", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", "*", "mult", "*", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "", "mult", "=", "2", "**", "n_downsampling", "\n", "for", "i", "in", "range", "(", "n_blocks", ")", ":", "# add ResNet blocks", "\n", "\n", "            ", "model", "+=", "[", "ResnetBlock", "(", "ngf", "*", "mult", ",", "padding_type", "=", "padding_type", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "use_bias", "=", "use_bias", ")", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add upsampling layers", "\n", "            ", "mult", "=", "2", "**", "(", "n_downsampling", "-", "i", ")", "\n", "model", "+=", "[", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "mult", ",", "int", "(", "ngf", "*", "mult", "/", "2", ")", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "output_padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "int", "(", "ngf", "*", "mult", "/", "2", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "", "model", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", "]", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", ",", "output_nc", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ")", "]", "\n", "model", "+=", "[", "nn", ".", "Tanh", "(", ")", "]", "\n", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.ResnetGenerator.forward": [[375, 378], ["networks.ResnetGenerator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward\"\"\"", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.ResnetGenerator_our.__init__": [[381, 433], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh", "networks.ResnetGenerator_our.resnet_blocks.append", "networks.ResnetGenerator_our.resnet_blocks[].weight_init", "networks.resnet_block"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.resnet_block.weight_init"], ["    ", "def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "ngf", "=", "64", ",", "n_blocks", "=", "9", ")", ":", "\n", "        ", "super", "(", "ResnetGenerator_our", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_nc", "=", "input_nc", "\n", "self", ".", "output_nc", "=", "output_nc", "\n", "self", ".", "ngf", "=", "ngf", "\n", "self", ".", "nb", "=", "n_blocks", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "input_nc", ",", "ngf", ",", "7", ",", "1", ",", "0", ")", "\n", "self", ".", "conv1_norm", "=", "nn", ".", "InstanceNorm2d", "(", "ngf", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "ngf", ",", "ngf", "*", "2", ",", "3", ",", "2", ",", "1", ")", "\n", "self", ".", "conv2_norm", "=", "nn", ".", "InstanceNorm2d", "(", "ngf", "*", "2", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "ngf", "*", "2", ",", "ngf", "*", "4", ",", "3", ",", "2", ",", "1", ")", "\n", "self", ".", "conv3_norm", "=", "nn", ".", "InstanceNorm2d", "(", "ngf", "*", "4", ")", "\n", "\n", "self", ".", "resnet_blocks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_blocks", ")", ":", "\n", "            ", "self", ".", "resnet_blocks", ".", "append", "(", "resnet_block", "(", "ngf", "*", "4", ",", "3", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "resnet_blocks", "[", "i", "]", ".", "weight_init", "(", "0", ",", "0.02", ")", "\n", "\n", "", "self", ".", "resnet_blocks", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "resnet_blocks", ")", "\n", "\n", "# self.resnet_blocks1 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks1.weight_init(0, 0.02)", "\n", "# self.resnet_blocks2 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks2.weight_init(0, 0.02)", "\n", "# self.resnet_blocks3 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks3.weight_init(0, 0.02)", "\n", "# self.resnet_blocks4 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks4.weight_init(0, 0.02)", "\n", "# self.resnet_blocks5 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks5.weight_init(0, 0.02)", "\n", "# self.resnet_blocks6 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks6.weight_init(0, 0.02)", "\n", "# self.resnet_blocks7 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks7.weight_init(0, 0.02)", "\n", "# self.resnet_blocks8 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks8.weight_init(0, 0.02)", "\n", "# self.resnet_blocks9 = resnet_block(256, 3, 1, 1)", "\n", "# self.resnet_blocks9.weight_init(0, 0.02)", "\n", "\n", "self", ".", "deconv1_content", "=", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "4", ",", "ngf", "*", "2", ",", "3", ",", "2", ",", "1", ",", "1", ")", "\n", "self", ".", "deconv1_norm_content", "=", "nn", ".", "InstanceNorm2d", "(", "ngf", "*", "2", ")", "\n", "self", ".", "deconv2_content", "=", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "2", ",", "ngf", ",", "3", ",", "2", ",", "1", ",", "1", ")", "\n", "self", ".", "deconv2_norm_content", "=", "nn", ".", "InstanceNorm2d", "(", "ngf", ")", "\n", "self", ".", "deconv3_content", "=", "nn", ".", "Conv2d", "(", "ngf", ",", "30", ",", "7", ",", "1", ",", "0", ")", "\n", "\n", "self", ".", "deconv1_attention", "=", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "4", ",", "ngf", "*", "2", ",", "3", ",", "2", ",", "1", ",", "1", ")", "\n", "self", ".", "deconv1_norm_attention", "=", "nn", ".", "InstanceNorm2d", "(", "ngf", "*", "2", ")", "\n", "self", ".", "deconv2_attention", "=", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "2", ",", "ngf", ",", "3", ",", "2", ",", "1", ",", "1", ")", "\n", "self", ".", "deconv2_norm_attention", "=", "nn", ".", "InstanceNorm2d", "(", "ngf", ")", "\n", "self", ".", "deconv3_attention", "=", "nn", ".", "Conv2d", "(", "ngf", ",", "10", ",", "1", ",", "1", ",", "0", ")", "\n", "\n", "self", ".", "tanh", "=", "torch", ".", "nn", ".", "Tanh", "(", ")", "\n", "# weight_init", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.ResnetGenerator_our.weight_init": [[434, 437], ["networks.normal_init"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.normal_init"], ["", "def", "weight_init", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "_modules", ":", "\n", "            ", "normal_init", "(", "self", ".", "_modules", "[", "m", "]", ",", "mean", ",", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.ResnetGenerator_our.forward": [[439, 518], ["torch.pad", "torch.pad", "torch.pad", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "networks.ResnetGenerator_our.resnet_blocks", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.pad", "torch.pad", "torch.pad", "networks.ResnetGenerator_our.deconv3_content", "networks.ResnetGenerator_our.tanh", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "networks.ResnetGenerator_our.deconv3_attention", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax.", "torch.nn.Softmax.", "torch.nn.Softmax.", "attention1_.repeat", "attention2_.repeat", "attention3_.repeat", "attention4_.repeat", "attention5_.repeat", "attention6_.repeat", "attention7_.repeat", "attention8_.repeat", "attention9_.repeat", "attention10_.repeat", "networks.ResnetGenerator_our.conv1_norm", "networks.ResnetGenerator_our.conv2_norm", "networks.ResnetGenerator_our.conv3_norm", "networks.ResnetGenerator_our.deconv1_norm_content", "networks.ResnetGenerator_our.deconv2_norm_content", "networks.ResnetGenerator_our.deconv1_norm_attention", "networks.ResnetGenerator_our.deconv2_norm_attention", "networks.ResnetGenerator_our.conv1", "networks.ResnetGenerator_our.conv2", "networks.ResnetGenerator_our.conv3", "networks.ResnetGenerator_our.deconv1_content", "networks.ResnetGenerator_our.deconv2_content", "networks.ResnetGenerator_our.deconv1_attention", "networks.ResnetGenerator_our.deconv2_attention"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "x", "=", "F", ".", "pad", "(", "input", ",", "(", "3", ",", "3", ",", "3", ",", "3", ")", ",", "'reflect'", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1_norm", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv2_norm", "(", "self", ".", "conv2", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv3_norm", "(", "self", ".", "conv3", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "resnet_blocks", "(", "x", ")", "\n", "# x = self.resnet_blocks1(x)", "\n", "# x = self.resnet_blocks2(x)", "\n", "# x = self.resnet_blocks3(x)", "\n", "# x = self.resnet_blocks4(x)", "\n", "# x = self.resnet_blocks5(x)", "\n", "# x = self.resnet_blocks6(x)", "\n", "# x = self.resnet_blocks7(x)", "\n", "# x = self.resnet_blocks8(x)", "\n", "# x = self.resnet_blocks9(x)", "\n", "x_content", "=", "F", ".", "relu", "(", "self", ".", "deconv1_norm_content", "(", "self", ".", "deconv1_content", "(", "x", ")", ")", ")", "\n", "x_content", "=", "F", ".", "relu", "(", "self", ".", "deconv2_norm_content", "(", "self", ".", "deconv2_content", "(", "x_content", ")", ")", ")", "\n", "x_content", "=", "F", ".", "pad", "(", "x_content", ",", "(", "3", ",", "3", ",", "3", ",", "3", ")", ",", "'reflect'", ")", "\n", "content", "=", "self", ".", "deconv3_content", "(", "x_content", ")", "\n", "image", "=", "self", ".", "tanh", "(", "content", ")", "\n", "image1", "=", "image", "[", ":", ",", "0", ":", "3", ",", ":", ",", ":", "]", "\n", "# print(image1.size()) # [1, 3, 256, 256]", "\n", "image2", "=", "image", "[", ":", ",", "3", ":", "6", ",", ":", ",", ":", "]", "\n", "image3", "=", "image", "[", ":", ",", "6", ":", "9", ",", ":", ",", ":", "]", "\n", "image4", "=", "image", "[", ":", ",", "9", ":", "12", ",", ":", ",", ":", "]", "\n", "image5", "=", "image", "[", ":", ",", "12", ":", "15", ",", ":", ",", ":", "]", "\n", "image6", "=", "image", "[", ":", ",", "15", ":", "18", ",", ":", ",", ":", "]", "\n", "image7", "=", "image", "[", ":", ",", "18", ":", "21", ",", ":", ",", ":", "]", "\n", "image8", "=", "image", "[", ":", ",", "21", ":", "24", ",", ":", ",", ":", "]", "\n", "image9", "=", "image", "[", ":", ",", "24", ":", "27", ",", ":", ",", ":", "]", "\n", "image10", "=", "image", "[", ":", ",", "27", ":", "30", ",", ":", ",", ":", "]", "\n", "\n", "x_attention", "=", "F", ".", "relu", "(", "self", ".", "deconv1_norm_attention", "(", "self", ".", "deconv1_attention", "(", "x", ")", ")", ")", "\n", "x_attention", "=", "F", ".", "relu", "(", "self", ".", "deconv2_norm_attention", "(", "self", ".", "deconv2_attention", "(", "x_attention", ")", ")", ")", "\n", "# x_attention = F.pad(x_attention, (3, 3, 3, 3), 'reflect')", "\n", "# print(x_attention.size()) [1, 64, 256, 256]", "\n", "attention", "=", "self", ".", "deconv3_attention", "(", "x_attention", ")", "\n", "\n", "softmax_", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "attention", "=", "softmax_", "(", "attention", ")", "\n", "\n", "attention1_", "=", "attention", "[", ":", ",", "0", ":", "1", ",", ":", ",", ":", "]", "\n", "attention2_", "=", "attention", "[", ":", ",", "1", ":", "2", ",", ":", ",", ":", "]", "\n", "attention3_", "=", "attention", "[", ":", ",", "2", ":", "3", ",", ":", ",", ":", "]", "\n", "attention4_", "=", "attention", "[", ":", ",", "3", ":", "4", ",", ":", ",", ":", "]", "\n", "attention5_", "=", "attention", "[", ":", ",", "4", ":", "5", ",", ":", ",", ":", "]", "\n", "attention6_", "=", "attention", "[", ":", ",", "5", ":", "6", ",", ":", ",", ":", "]", "\n", "attention7_", "=", "attention", "[", ":", ",", "6", ":", "7", ",", ":", ",", ":", "]", "\n", "attention8_", "=", "attention", "[", ":", ",", "7", ":", "8", ",", ":", ",", ":", "]", "\n", "attention9_", "=", "attention", "[", ":", ",", "8", ":", "9", ",", ":", ",", ":", "]", "\n", "attention10_", "=", "attention", "[", ":", ",", "9", ":", "10", ",", ":", ",", ":", "]", "\n", "\n", "attention1", "=", "attention1_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "# print(attention1.size())", "\n", "attention2", "=", "attention2_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "attention3", "=", "attention3_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "attention4", "=", "attention4_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "attention5", "=", "attention5_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "attention6", "=", "attention6_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "attention7", "=", "attention7_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "attention8", "=", "attention8_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "attention9", "=", "attention9_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "attention10", "=", "attention10_", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "\n", "output1", "=", "image1", "*", "attention1", "\n", "output2", "=", "image2", "*", "attention2", "\n", "output3", "=", "image3", "*", "attention3", "\n", "output4", "=", "image4", "*", "attention4", "\n", "output5", "=", "image5", "*", "attention5", "\n", "output6", "=", "image6", "*", "attention6", "\n", "output7", "=", "image7", "*", "attention7", "\n", "output8", "=", "image8", "*", "attention8", "\n", "output9", "=", "image9", "*", "attention9", "\n", "output10", "=", "image10", "*", "attention10", "\n", "# output10 = input * attention10", "\n", "\n", "o", "=", "output1", "+", "output2", "+", "output3", "+", "output4", "+", "output5", "+", "output6", "+", "output7", "+", "output8", "+", "output9", "+", "output10", "\n", "\n", "return", "o", ",", "output1", ",", "output2", ",", "output3", ",", "output4", ",", "output5", ",", "output6", ",", "output7", ",", "output8", ",", "output9", ",", "output10", ",", "attention1", ",", "attention2", ",", "attention3", ",", "attention4", ",", "attention5", ",", "attention6", ",", "attention7", ",", "attention8", ",", "attention9", ",", "attention10", ",", "image1", ",", "image2", ",", "image3", ",", "image4", ",", "image5", ",", "image6", ",", "image7", ",", "image8", ",", "image9", ",", "image10", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.resnet_block.__init__": [[521, 531], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ",", "kernel", ",", "stride", ",", "padding", ")", ":", "\n", "        ", "super", "(", "resnet_block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "channel", "=", "channel", "\n", "self", ".", "kernel", "=", "kernel", "\n", "self", ".", "strdie", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "channel", ",", "channel", ",", "kernel", ",", "stride", ",", "0", ")", "\n", "self", ".", "conv1_norm", "=", "nn", ".", "InstanceNorm2d", "(", "channel", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "channel", ",", "channel", ",", "kernel", ",", "stride", ",", "0", ")", "\n", "self", ".", "conv2_norm", "=", "nn", ".", "InstanceNorm2d", "(", "channel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.resnet_block.weight_init": [[533, 536], ["networks.normal_init"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.normal_init"], ["", "def", "weight_init", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "_modules", ":", "\n", "            ", "normal_init", "(", "self", ".", "_modules", "[", "m", "]", ",", "mean", ",", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.resnet_block.forward": [[537, 544], ["torch.pad", "torch.pad", "torch.pad", "torch.relu", "torch.relu", "torch.relu", "torch.pad", "torch.pad", "torch.pad", "networks.resnet_block.conv2_norm", "networks.resnet_block.conv1_norm", "networks.resnet_block.conv2", "networks.resnet_block.conv1"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "x", "=", "F", ".", "pad", "(", "input", ",", "(", "self", ".", "padding", ",", "self", ".", "padding", ",", "self", ".", "padding", ",", "self", ".", "padding", ")", ",", "'reflect'", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1_norm", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "self", ".", "padding", ",", "self", ".", "padding", ",", "self", ".", "padding", ",", "self", ".", "padding", ")", ",", "'reflect'", ")", "\n", "x", "=", "self", ".", "conv2_norm", "(", "self", ".", "conv2", "(", "x", ")", ")", "\n", "\n", "return", "input", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.ResnetBlock.__init__": [[553, 563], ["torch.Module.__init__", "networks.ResnetBlock.build_conv_block"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.ResnetBlock.build_conv_block"], ["def", "__init__", "(", "self", ",", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", ":", "\n", "        ", "\"\"\"Initialize the Resnet block\n\n        A resnet block is a conv block with skip connections\n        We construct a conv block with build_conv_block function,\n        and implement skip connections in <forward> function.\n        Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n        \"\"\"", "\n", "super", "(", "ResnetBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_block", "=", "self", ".", "build_conv_block", "(", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.ResnetBlock.build_conv_block": [[564, 603], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "NotImplementedError", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "NotImplementedError"], "methods", ["None"], ["", "def", "build_conv_block", "(", "self", ",", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", ":", "\n", "        ", "\"\"\"Construct a convolutional block.\n\n        Parameters:\n            dim (int)           -- the number of channels in the conv layer.\n            padding_type (str)  -- the name of padding layer: reflect | replicate | zero\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers.\n            use_bias (bool)     -- if the conv layer uses bias or not\n\n        Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU))\n        \"\"\"", "\n", "conv_block", "=", "[", "]", "\n", "p", "=", "0", "\n", "if", "padding_type", "==", "'reflect'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'replicate'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReplicationPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'zero'", ":", "\n", "            ", "p", "=", "1", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'padding [%s] is not implemented'", "%", "padding_type", ")", "\n", "\n", "", "conv_block", "+=", "[", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "3", ",", "padding", "=", "p", ",", "bias", "=", "use_bias", ")", ",", "norm_layer", "(", "dim", ")", ",", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "if", "use_dropout", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "Dropout", "(", "0.5", ")", "]", "\n", "\n", "", "p", "=", "0", "\n", "if", "padding_type", "==", "'reflect'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'replicate'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReplicationPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'zero'", ":", "\n", "            ", "p", "=", "1", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'padding [%s] is not implemented'", "%", "padding_type", ")", "\n", "", "conv_block", "+=", "[", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "3", ",", "padding", "=", "p", ",", "bias", "=", "use_bias", ")", ",", "norm_layer", "(", "dim", ")", "]", "\n", "\n", "return", "nn", ".", "Sequential", "(", "*", "conv_block", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.ResnetBlock.forward": [[604, 608], ["networks.ResnetBlock.conv_block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward function (with skip connections)\"\"\"", "\n", "out", "=", "x", "+", "self", ".", "conv_block", "(", "x", ")", "# add skip connections", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.UnetGenerator.__init__": [[613, 636], ["torch.Module.__init__", "networks.UnetSkipConnectionBlock", "range", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "num_downs", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Unet generator\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            output_nc (int) -- the number of channels in output images\n            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n                                image of size 128x128 will become of size 1x1 # at the bottleneck\n            ngf (int)       -- the number of filters in the last conv layer\n            norm_layer      -- normalization layer\n\n        We construct the U-Net from the innermost layer to the outermost layer.\n        It is a recursive process.\n        \"\"\"", "\n", "super", "(", "UnetGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# construct unet structure", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "8", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "None", ",", "norm_layer", "=", "norm_layer", ",", "innermost", "=", "True", ")", "# add the innermost layer", "\n", "for", "i", "in", "range", "(", "num_downs", "-", "5", ")", ":", "# add intermediate layers with ngf * 8 filters", "\n", "            ", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "8", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ")", "\n", "# gradually reduce the number of filters from ngf * 8 to ngf", "\n", "", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "4", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ")", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "2", ",", "ngf", "*", "4", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ")", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", ",", "ngf", "*", "2", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "model", "=", "UnetSkipConnectionBlock", "(", "output_nc", ",", "ngf", ",", "input_nc", "=", "input_nc", ",", "submodule", "=", "unet_block", ",", "outermost", "=", "True", ",", "norm_layer", "=", "norm_layer", ")", "# add the outermost layer", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.UnetGenerator.forward": [[637, 640], ["networks.UnetGenerator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward\"\"\"", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.UnetSkipConnectionBlock.__init__": [[648, 704], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReLU", "norm_layer", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "outer_nc", ",", "inner_nc", ",", "input_nc", "=", "None", ",", "\n", "submodule", "=", "None", ",", "outermost", "=", "False", ",", "innermost", "=", "False", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Unet submodule with skip connections.\n\n        Parameters:\n            outer_nc (int) -- the number of filters in the outer conv layer\n            inner_nc (int) -- the number of filters in the inner conv layer\n            input_nc (int) -- the number of channels in input images/features\n            submodule (UnetSkipConnectionBlock) -- previously defined submodules\n            outermost (bool)    -- if this module is the outermost module\n            innermost (bool)    -- if this module is the innermost module\n            norm_layer          -- normalization layer\n            user_dropout (bool) -- if use dropout layers.\n        \"\"\"", "\n", "super", "(", "UnetSkipConnectionBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "outermost", "=", "outermost", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "", "if", "input_nc", "is", "None", ":", "\n", "            ", "input_nc", "=", "outer_nc", "\n", "", "downconv", "=", "nn", ".", "Conv2d", "(", "input_nc", ",", "inner_nc", ",", "kernel_size", "=", "4", ",", "\n", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "downrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "downnorm", "=", "norm_layer", "(", "inner_nc", ")", "\n", "uprelu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "upnorm", "=", "norm_layer", "(", "outer_nc", ")", "\n", "\n", "if", "outermost", ":", "\n", "            ", "upconv", "=", "nn", ".", "ConvTranspose2d", "(", "inner_nc", "*", "2", ",", "outer_nc", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ")", "\n", "down", "=", "[", "downconv", "]", "\n", "up", "=", "[", "uprelu", ",", "upconv", ",", "nn", ".", "Tanh", "(", ")", "]", "\n", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "\n", "", "elif", "innermost", ":", "\n", "            ", "upconv", "=", "nn", ".", "ConvTranspose2d", "(", "inner_nc", ",", "outer_nc", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "down", "=", "[", "downrelu", ",", "downconv", "]", "\n", "up", "=", "[", "uprelu", ",", "upconv", ",", "upnorm", "]", "\n", "model", "=", "down", "+", "up", "\n", "", "else", ":", "\n", "            ", "upconv", "=", "nn", ".", "ConvTranspose2d", "(", "inner_nc", "*", "2", ",", "outer_nc", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "down", "=", "[", "downrelu", ",", "downconv", ",", "downnorm", "]", "\n", "up", "=", "[", "uprelu", ",", "upconv", ",", "upnorm", "]", "\n", "\n", "if", "use_dropout", ":", "\n", "                ", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "+", "[", "nn", ".", "Dropout", "(", "0.5", ")", "]", "\n", "", "else", ":", "\n", "                ", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "\n", "\n", "", "", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.UnetSkipConnectionBlock.forward": [[705, 710], ["networks.UnetSkipConnectionBlock.model", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks.UnetSkipConnectionBlock.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "outermost", ":", "\n", "            ", "return", "self", ".", "model", "(", "x", ")", "\n", "", "else", ":", "# add skip connections", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "x", ",", "self", ".", "model", "(", "x", ")", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.NLayerDiscriminator.__init__": [[715, 754], ["torch.Module.__init__", "range", "min", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "min", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "ndf", "=", "64", ",", "n_layers", "=", "3", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "\"\"\"Construct a PatchGAN discriminator\n\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            ndf (int)       -- the number of filters in the last conv layer\n            n_layers (int)  -- the number of conv layers in the discriminator\n            norm_layer      -- normalization layer\n        \"\"\"", "\n", "super", "(", "NLayerDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "# no need to use bias as BatchNorm2d has affine parameters", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "kw", "=", "4", "\n", "padw", "=", "1", "\n", "sequence", "=", "[", "nn", ".", "Conv2d", "(", "input_nc", ",", "ndf", ",", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ")", ",", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "]", "\n", "nf_mult", "=", "1", "\n", "nf_mult_prev", "=", "1", "\n", "for", "n", "in", "range", "(", "1", ",", "n_layers", ")", ":", "# gradually increase the number of filters", "\n", "            ", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "nf_mult", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n_layers", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "nf_mult", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "sequence", "+=", "[", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult", ",", "1", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ")", "]", "# output 1 channel prediction map", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.NLayerDiscriminator.forward": [[755, 758], ["networks.NLayerDiscriminator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward.\"\"\"", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.PixelDiscriminator.__init__": [[763, 786], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "type", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "ndf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "\"\"\"Construct a 1x1 PatchGAN discriminator\n\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            ndf (int)       -- the number of filters in the last conv layer\n            norm_layer      -- normalization layer\n        \"\"\"", "\n", "super", "(", "PixelDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "# no need to use bias as BatchNorm2d has affine parameters", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "self", ".", "net", "=", "[", "\n", "nn", ".", "Conv2d", "(", "input_nc", ",", "ndf", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ndf", ",", "ndf", "*", "2", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "2", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "2", ",", "1", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", "]", "\n", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "net", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.PixelDiscriminator.forward": [[787, 790], ["networks.PixelDiscriminator.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward.\"\"\"", "\n", "return", "self", ".", "net", "(", "input", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.get_norm_layer": [[19, 37], ["functools.partial", "functools.partial", "NotImplementedError", "networks.Identity"], "function", ["None"], ["", "", "def", "get_norm_layer", "(", "norm_type", "=", "'instance'", ")", ":", "\n", "    ", "\"\"\"Return a normalization layer\n\n    Parameters:\n        norm_type (str) -- the name of the normalization layer: batch | instance | none\n\n    For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n    For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics.\n    \"\"\"", "\n", "if", "norm_type", "==", "'batch'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "BatchNorm2d", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "", "elif", "norm_type", "==", "'instance'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "InstanceNorm2d", ",", "affine", "=", "False", ",", "track_running_stats", "=", "False", ")", "\n", "", "elif", "norm_type", "==", "'none'", ":", "\n", "        ", "norm_layer", "=", "lambda", "x", ":", "Identity", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'normalization layer [%s] is not found'", "%", "norm_type", ")", "\n", "", "return", "norm_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.get_scheduler": [[39, 66], ["torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.ReduceLROnPlateau", "max", "float", "torch.optim.lr_scheduler.CosineAnnealingLR", "NotImplementedError"], "function", ["None"], ["", "def", "get_scheduler", "(", "optimizer", ",", "opt", ")", ":", "\n", "    ", "\"\"\"Return a learning rate scheduler\n\n    Parameters:\n        optimizer          -- the optimizer of the network\n        opt (option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\uff0e\u3000\n                              opt.lr_policy is the name of learning rate policy: linear | step | plateau | cosine\n\n    For 'linear', we keep the same learning rate for the first <opt.niter> epochs\n    and linearly decay the rate to zero over the next <opt.niter_decay> epochs.\n    For other schedulers (step, plateau, and cosine), we use the default PyTorch schedulers.\n    See https://pytorch.org/docs/stable/optim.html for more details.\n    \"\"\"", "\n", "if", "opt", ".", "lr_policy", "==", "'linear'", ":", "\n", "        ", "def", "lambda_rule", "(", "epoch", ")", ":", "\n", "            ", "lr_l", "=", "1.0", "-", "max", "(", "0", ",", "epoch", "+", "opt", ".", "epoch_count", "-", "opt", ".", "niter", ")", "/", "float", "(", "opt", ".", "niter_decay", "+", "1", ")", "\n", "return", "lr_l", "\n", "", "scheduler", "=", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lambda_rule", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'step'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "step_size", "=", "opt", ".", "lr_decay_iters", ",", "gamma", "=", "0.1", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'plateau'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "factor", "=", "0.2", ",", "threshold", "=", "0.01", ",", "patience", "=", "5", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'cosine'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "CosineAnnealingLR", "(", "optimizer", ",", "T_max", "=", "opt", ".", "niter", ",", "eta_min", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "return", "NotImplementedError", "(", "'learning rate policy [%s] is not implemented'", ",", "opt", ".", "lr_policy", ")", "\n", "", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.init_weights": [[68, 100], ["print", "net.apply", "hasattr", "torch.nn.init.normal_", "hasattr", "torch.nn.init.constant_", "classname.find", "torch.nn.init.normal_", "torch.nn.init.constant_", "classname.find", "classname.find", "torch.nn.init.xavier_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.orthogonal_", "NotImplementedError"], "function", ["None"], ["", "def", "init_weights", "(", "net", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ")", ":", "\n", "    ", "\"\"\"Initialize network weights.\n\n    Parameters:\n        net (network)   -- network to be initialized\n        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n\n    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n    work better for some applications. Feel free to try yourself.\n    \"\"\"", "\n", "def", "init_func", "(", "m", ")", ":", "# define the initialization function", "\n", "        ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "(", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", "or", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ")", ":", "\n", "            ", "if", "init_type", "==", "'normal'", ":", "\n", "                ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "0.0", ",", "init_gain", ")", "\n", "", "elif", "init_type", "==", "'xavier'", ":", "\n", "                ", "init", ".", "xavier_normal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "init_gain", ")", "\n", "", "elif", "init_type", "==", "'kaiming'", ":", "\n", "                ", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ".", "data", ",", "a", "=", "0", ",", "mode", "=", "'fan_in'", ")", "\n", "", "elif", "init_type", "==", "'orthogonal'", ":", "\n", "                ", "init", ".", "orthogonal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "init_gain", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'initialization method [%s] is not implemented'", "%", "init_type", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'BatchNorm2d'", ")", "!=", "-", "1", ":", "# BatchNorm Layer's weight is not a matrix; only normal distribution applies.", "\n", "            ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "1.0", ",", "init_gain", ")", "\n", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "\n", "", "", "print", "(", "'initialize network with %s'", "%", "init_type", ")", "\n", "net", ".", "apply", "(", "init_func", ")", "# apply the initialization function <init_func>", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.init_net": [[102, 119], ["networks.init_weights", "len", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.nn.DataParallel.to", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.init_weights"], ["", "def", "init_net", "(", "net", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n    Parameters:\n        net (network)      -- the network to be initialized\n        init_type (str)    -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n        gain (float)       -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n\n    Return an initialized network.\n    \"\"\"", "\n", "if", "len", "(", "gpu_ids", ")", ">", "0", ":", "\n", "        ", "assert", "(", "torch", ".", "cuda", ".", "is_available", "(", ")", ")", "\n", "# print(net)", "\n", "net", ".", "to", "(", "gpu_ids", "[", "0", "]", ")", "\n", "net", "=", "torch", ".", "nn", ".", "DataParallel", "(", "net", ",", "gpu_ids", ")", "# multi-GPUs", "\n", "", "init_weights", "(", "net", ",", "init_type", ",", "init_gain", "=", "init_gain", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.define_G": [[121, 164], ["networks.get_norm_layer", "networks.init_net", "networks.ResnetGenerator", "networks.ResnetGenerator", "networks.UnetGenerator", "networks.UnetGenerator", "networks.ResnetGenerator_our", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.init_net"], ["", "def", "define_G", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "netG", ",", "norm", "=", "'batch'", ",", "use_dropout", "=", "False", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Create a generator\n\n    Parameters:\n        input_nc (int) -- the number of channels in input images\n        output_nc (int) -- the number of channels in output images\n        ngf (int) -- the number of filters in the last conv layer\n        netG (str) -- the architecture's name: resnet_9blocks | resnet_6blocks | unet_256 | unet_128\n        norm (str) -- the name of normalization layers used in the network: batch | instance | none\n        use_dropout (bool) -- if use dropout layers.\n        init_type (str)    -- the name of our initialization method.\n        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n\n    Returns a generator\n\n    Our current implementation provides two types of generators:\n        U-Net: [unet_128] (for 128x128 input images) and [unet_256] (for 256x256 input images)\n        The original U-Net paper: https://arxiv.org/abs/1505.04597\n\n        Resnet-based generator: [resnet_6blocks] (with 6 Resnet blocks) and [resnet_9blocks] (with 9 Resnet blocks)\n        Resnet-based generator consists of several Resnet blocks between a few downsampling/upsampling operations.\n        We adapt Torch code from Justin Johnson's neural style transfer project (https://github.com/jcjohnson/fast-neural-style).\n\n\n    The generator has been initialized by <init_net>. It uses RELU for non-linearity.\n    \"\"\"", "\n", "net", "=", "None", "\n", "norm_layer", "=", "get_norm_layer", "(", "norm_type", "=", "norm", ")", "\n", "\n", "if", "netG", "==", "'resnet_9blocks'", ":", "\n", "        ", "net", "=", "ResnetGenerator", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "n_blocks", "=", "9", ")", "\n", "", "elif", "netG", "==", "'resnet_6blocks'", ":", "\n", "        ", "net", "=", "ResnetGenerator", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "n_blocks", "=", "6", ")", "\n", "", "elif", "netG", "==", "'unet_128'", ":", "\n", "        ", "net", "=", "UnetGenerator", "(", "input_nc", ",", "output_nc", ",", "7", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ")", "\n", "", "elif", "netG", "==", "'unet_256'", ":", "\n", "        ", "net", "=", "UnetGenerator", "(", "input_nc", ",", "output_nc", ",", "8", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ")", "\n", "", "elif", "netG", "==", "'our'", ":", "\n", "        ", "net", "=", "ResnetGenerator_our", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "n_blocks", "=", "9", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Generator model name [%s] is not recognized'", "%", "netG", ")", "\n", "", "return", "init_net", "(", "net", ",", "init_type", ",", "init_gain", ",", "gpu_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.define_D": [[166, 208], ["networks.get_norm_layer", "networks.init_net", "networks.NLayerDiscriminator", "networks.NLayerDiscriminator", "networks.PixelDiscriminator", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.init_net"], ["", "def", "define_D", "(", "input_nc", ",", "ndf", ",", "netD", ",", "n_layers_D", "=", "3", ",", "norm", "=", "'batch'", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Create a discriminator\n\n    Parameters:\n        input_nc (int)     -- the number of channels in input images\n        ndf (int)          -- the number of filters in the first conv layer\n        netD (str)         -- the architecture's name: basic | n_layers | pixel\n        n_layers_D (int)   -- the number of conv layers in the discriminator; effective when netD=='n_layers'\n        norm (str)         -- the type of normalization layers used in the network.\n        init_type (str)    -- the name of the initialization method.\n        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n\n    Returns a discriminator\n\n    Our current implementation provides three types of discriminators:\n        [basic]: 'PatchGAN' classifier described in the original pix2pix paper.\n        It can classify whether 70\u00d770 overlapping patches are real or fake.\n        Such a patch-level discriminator architecture has fewer parameters\n        than a full-image discriminator and can work on arbitrarily-sized images\n        in a fully convolutional fashion.\n\n        [n_layers]: With this mode, you cna specify the number of conv layers in the discriminator\n        with the parameter <n_layers_D> (default=3 as used in [basic] (PatchGAN).)\n\n        [pixel]: 1x1 PixelGAN discriminator can classify whether a pixel is real or not.\n        It encourages greater color diversity but has no effect on spatial statistics.\n\n    The discriminator has been initialized by <init_net>. It uses Leakly RELU for non-linearity.\n    \"\"\"", "\n", "net", "=", "None", "\n", "norm_layer", "=", "get_norm_layer", "(", "norm_type", "=", "norm", ")", "\n", "\n", "if", "netD", "==", "'basic'", ":", "# default PatchGAN classifier", "\n", "        ", "net", "=", "NLayerDiscriminator", "(", "input_nc", ",", "ndf", ",", "n_layers", "=", "3", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "elif", "netD", "==", "'n_layers'", ":", "# more options", "\n", "        ", "net", "=", "NLayerDiscriminator", "(", "input_nc", ",", "ndf", ",", "n_layers_D", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "elif", "netD", "==", "'pixel'", ":", "# classify if each pixel is real or fake", "\n", "        ", "net", "=", "PixelDiscriminator", "(", "input_nc", ",", "ndf", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Discriminator model name [%s] is not recognized'", "%", "netD", ")", "\n", "", "return", "init_net", "(", "net", ",", "init_type", ",", "init_gain", ",", "gpu_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.cal_gradient_penalty": [[282, 317], ["interpolatesv.requires_grad_", "netD", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "gradients[].view", "real_data.size", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.rand", "torch.rand", "torch.rand", "alpha.expand().contiguous().view.expand().contiguous().view", "NotImplementedError", "torch.ones", "torch.ones", "torch.ones", "alpha.expand().contiguous().view.expand().contiguous", "netD.size", "alpha.expand().contiguous().view.expand", "real_data.nelement"], "function", ["None"], ["", "", "def", "cal_gradient_penalty", "(", "netD", ",", "real_data", ",", "fake_data", ",", "device", ",", "type", "=", "'mixed'", ",", "constant", "=", "1.0", ",", "lambda_gp", "=", "10.0", ")", ":", "\n", "    ", "\"\"\"Calculate the gradient penalty loss, used in WGAN-GP paper https://arxiv.org/abs/1704.00028\n\n    Arguments:\n        netD (network)              -- discriminator network\n        real_data (tensor array)    -- real images\n        fake_data (tensor array)    -- generated images from the generator\n        device (str)                -- GPU / CPU: from torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')\n        type (str)                  -- if we mix real and fake data or not [real | fake | mixed].\n        constant (float)            -- the constant used in formula ( | |gradient||_2 - constant)^2\n        lambda_gp (float)           -- weight for this loss\n\n    Returns the gradient penalty loss\n    \"\"\"", "\n", "if", "lambda_gp", ">", "0.0", ":", "\n", "        ", "if", "type", "==", "'real'", ":", "# either use real images, fake images, or a linear interpolation of two.", "\n", "            ", "interpolatesv", "=", "real_data", "\n", "", "elif", "type", "==", "'fake'", ":", "\n", "            ", "interpolatesv", "=", "fake_data", "\n", "", "elif", "type", "==", "'mixed'", ":", "\n", "            ", "alpha", "=", "torch", ".", "rand", "(", "real_data", ".", "shape", "[", "0", "]", ",", "1", ",", "device", "=", "device", ")", "\n", "alpha", "=", "alpha", ".", "expand", "(", "real_data", ".", "shape", "[", "0", "]", ",", "real_data", ".", "nelement", "(", ")", "//", "real_data", ".", "shape", "[", "0", "]", ")", ".", "contiguous", "(", ")", ".", "view", "(", "*", "real_data", ".", "shape", ")", "\n", "interpolatesv", "=", "alpha", "*", "real_data", "+", "(", "(", "1", "-", "alpha", ")", "*", "fake_data", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'{} not implemented'", ".", "format", "(", "type", ")", ")", "\n", "", "interpolatesv", ".", "requires_grad_", "(", "True", ")", "\n", "disc_interpolates", "=", "netD", "(", "interpolatesv", ")", "\n", "gradients", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "disc_interpolates", ",", "inputs", "=", "interpolatesv", ",", "\n", "grad_outputs", "=", "torch", ".", "ones", "(", "disc_interpolates", ".", "size", "(", ")", ")", ".", "to", "(", "device", ")", ",", "\n", "create_graph", "=", "True", ",", "retain_graph", "=", "True", ",", "only_inputs", "=", "True", ")", "\n", "gradients", "=", "gradients", "[", "0", "]", ".", "view", "(", "real_data", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# flat the data", "\n", "gradient_penalty", "=", "(", "(", "(", "gradients", "+", "1e-16", ")", ".", "norm", "(", "2", ",", "dim", "=", "1", ")", "-", "constant", ")", "**", "2", ")", ".", "mean", "(", ")", "*", "lambda_gp", "# added eps", "\n", "return", "gradient_penalty", ",", "gradients", "\n", "", "else", ":", "\n", "        ", "return", "0.0", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.normal_init": [[545, 549], ["isinstance", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_"], "function", ["None"], ["", "", "def", "normal_init", "(", "m", ",", "mean", ",", "std", ")", ":", "\n", "    ", "if", "isinstance", "(", "m", ",", "nn", ".", "ConvTranspose2d", ")", "or", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "mean", ",", "std", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan_model.AttentionGANModel.modify_commandline_options": [[9, 18], ["parser.set_defaults", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", "=", "True", ")", ":", "\n", "        ", "parser", ".", "set_defaults", "(", "no_dropout", "=", "True", ")", "# default CycleGAN did not use dropout", "\n", "if", "is_train", ":", "\n", "            ", "parser", ".", "add_argument", "(", "'--lambda_A'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for cycle loss (A -> B -> A)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_B'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for cycle loss (B -> A -> B)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_identity'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'use identity mapping. Setting lambda_identity other than 0 has an effect of scaling the weight of the identity mapping loss. For example, if the weight of the identity loss should be 10 times smaller than the weight of the reconstruction loss, please set lambda_identity = 0.1'", ")", "\n", "\n", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan_model.AttentionGANModel.__init__": [[19, 72], ["base_model.BaseModel.__init__", "networks.define_G", "networks.define_G", "visual_names_A.append", "visual_names_B.append", "networks.define_D", "networks.define_D", "util.image_pool.ImagePool", "util.image_pool.ImagePool", "networks.GANLoss().to", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.optim.Adam", "torch.optim.Adam", "attention_gan_model.AttentionGANModel.optimizers.append", "attention_gan_model.AttentionGANModel.optimizers.append", "itertools.chain", "itertools.chain", "networks.GANLoss", "attention_gan_model.AttentionGANModel.netG_A.parameters", "attention_gan_model.AttentionGANModel.netG_B.parameters", "attention_gan_model.AttentionGANModel.netD_A.parameters", "attention_gan_model.AttentionGANModel.netD_B.parameters"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.define_G", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.define_G", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.define_D", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.define_D"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the CycleGAN class.\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "BaseModel", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "# specify the training losses you want to print out. The training/test scripts will call <BaseModel.get_current_losses>", "\n", "self", ".", "loss_names", "=", "[", "'D_A'", ",", "'G_A'", ",", "'cycle_A'", ",", "'idt_A'", ",", "'D_B'", ",", "'G_B'", ",", "'cycle_B'", ",", "'idt_B'", "]", "\n", "# specify the images you want to save/display. The training/test scripts will call <BaseModel.get_current_visuals>", "\n", "visual_names_A", "=", "[", "'real_A'", ",", "'fake_B'", ",", "'rec_A'", ",", "'o1_b'", ",", "'o2_b'", ",", "'o3_b'", ",", "'o4_b'", ",", "'o5_b'", ",", "'o6_b'", ",", "'o7_b'", ",", "'o8_b'", ",", "'o9_b'", ",", "'o10_b'", ",", "\n", "'a1_b'", ",", "'a2_b'", ",", "'a3_b'", ",", "'a4_b'", ",", "'a5_b'", ",", "'a6_b'", ",", "'a7_b'", ",", "'a8_b'", ",", "'a9_b'", ",", "'a10_b'", ",", "'i1_b'", ",", "'i2_b'", ",", "'i3_b'", ",", "'i4_b'", ",", "'i5_b'", ",", "\n", "'i6_b'", ",", "'i7_b'", ",", "'i8_b'", ",", "'i9_b'", ",", "'i10_b'", "]", "\n", "visual_names_B", "=", "[", "'real_B'", ",", "'fake_A'", ",", "'rec_B'", ",", "'o1_a'", ",", "'o2_a'", ",", "'o3_a'", ",", "'o4_a'", ",", "'o5_a'", ",", "'o6_a'", ",", "'o7_a'", ",", "'o8_a'", ",", "'o9_a'", ",", "'o10_a'", ",", "\n", "'a1_a'", ",", "'a2_a'", ",", "'a3_a'", ",", "'a4_a'", ",", "'a5_a'", ",", "'a6_a'", ",", "'a7_a'", ",", "'a8_a'", ",", "'a9_a'", ",", "'a10_a'", ",", "'i1_a'", ",", "'i2_a'", ",", "'i3_a'", ",", "'i4_a'", ",", "'i5_a'", ",", "\n", "'i6_a'", ",", "'i7_a'", ",", "'i8_a'", ",", "'i9_a'", ",", "'i10_a'", "]", "\n", "if", "self", ".", "isTrain", "and", "self", ".", "opt", ".", "lambda_identity", ">", "0.0", ":", "# if identity loss is used, we also visualize idt_B=G_A(B) ad idt_A=G_A(B)", "\n", "            ", "visual_names_A", ".", "append", "(", "'idt_B'", ")", "\n", "visual_names_B", ".", "append", "(", "'idt_A'", ")", "\n", "\n", "", "if", "self", ".", "opt", ".", "saveDisk", ":", "\n", "            ", "self", ".", "visual_names", "=", "[", "'real_A'", ",", "'fake_B'", ",", "'a10_b'", ",", "'real_B'", ",", "'fake_A'", ",", "'a10_a'", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "visual_names", "=", "visual_names_A", "+", "visual_names_B", "# combine visualizations for A and B", "\n", "# specify the models you want to save to the disk. The training/test scripts will call <BaseModel.save_networks> and <BaseModel.load_networks>.", "\n", "", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "model_names", "=", "[", "'G_A'", ",", "'G_B'", ",", "'D_A'", ",", "'D_B'", "]", "\n", "", "else", ":", "# during test time, only load Gs", "\n", "            ", "self", ".", "model_names", "=", "[", "'G_A'", ",", "'G_B'", "]", "\n", "\n", "# define networks (both Generators and discriminators)", "\n", "# The naming is different from those used in the paper.", "\n", "# Code (vs. paper): G_A (G), G_B (F), D_A (D_Y), D_B (D_X)", "\n", "", "self", ".", "netG_A", "=", "networks", ".", "define_G", "(", "opt", ".", "input_nc", ",", "opt", ".", "output_nc", ",", "opt", ".", "ngf", ",", "'our'", ",", "opt", ".", "norm", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "self", ".", "netG_B", "=", "networks", ".", "define_G", "(", "opt", ".", "output_nc", ",", "opt", ".", "input_nc", ",", "opt", ".", "ngf", ",", "'our'", ",", "opt", ".", "norm", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "\n", "if", "self", ".", "isTrain", ":", "# define discriminators", "\n", "            ", "self", ".", "netD_A", "=", "networks", ".", "define_D", "(", "opt", ".", "output_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "opt", ".", "n_layers_D", ",", "opt", ".", "norm", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "self", ".", "netD_B", "=", "networks", ".", "define_D", "(", "opt", ".", "input_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "opt", ".", "n_layers_D", ",", "opt", ".", "norm", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "\n", "", "if", "self", ".", "isTrain", ":", "\n", "            ", "if", "opt", ".", "lambda_identity", ">", "0.0", ":", "# only works when input and output images have the same number of channels", "\n", "                ", "assert", "(", "opt", ".", "input_nc", "==", "opt", ".", "output_nc", ")", "\n", "", "self", ".", "fake_A_pool", "=", "ImagePool", "(", "opt", ".", "pool_size", ")", "# create image buffer to store previously generated images", "\n", "self", ".", "fake_B_pool", "=", "ImagePool", "(", "opt", ".", "pool_size", ")", "# create image buffer to store previously generated images", "\n", "# define loss functions", "\n", "self", ".", "criterionGAN", "=", "networks", ".", "GANLoss", "(", "opt", ".", "gan_mode", ")", ".", "to", "(", "self", ".", "device", ")", "# define GAN loss.", "\n", "self", ".", "criterionCycle", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "\n", "self", ".", "criterionIdt", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "\n", "# initialize optimizers; schedulers will be automatically created by function <BaseModel.setup>.", "\n", "self", ".", "optimizer_G", "=", "torch", ".", "optim", ".", "Adam", "(", "itertools", ".", "chain", "(", "self", ".", "netG_A", ".", "parameters", "(", ")", ",", "self", ".", "netG_B", ".", "parameters", "(", ")", ")", ",", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan_model.AttentionGANModel.set_input": [[73, 83], ["input[].to", "input[].to"], "methods", ["None"], ["self", ".", "optimizer_D", "=", "torch", ".", "optim", ".", "Adam", "(", "itertools", ".", "chain", "(", "self", ".", "netD_A", ".", "parameters", "(", ")", ",", "self", ".", "netD_B", ".", "parameters", "(", ")", ")", ",", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_G", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_D", ")", "\n", "\n", "", "", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n        Parameters:\n            input (dict): include the data itself and its metadata information.\n        The option 'direction' can be used to swap domain A and domain B.\n        \"\"\"", "\n", "AtoB", "=", "self", ".", "opt", ".", "direction", "==", "'AtoB'", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan_model.AttentionGANModel.forward": [[84, 98], ["attention_gan_model.AttentionGANModel.netG_A", "attention_gan_model.AttentionGANModel.netG_B", "attention_gan_model.AttentionGANModel.netG_B", "attention_gan_model.AttentionGANModel.netG_A"], "methods", ["None"], ["self", ".", "real_A", "=", "input", "[", "'A'", "if", "AtoB", "else", "'B'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "real_B", "=", "input", "[", "'B'", "if", "AtoB", "else", "'A'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "image_paths", "=", "input", "[", "'A_paths'", "if", "AtoB", "else", "'B_paths'", "]", "\n", "\n", "", "def", "forward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"", "\n", "self", ".", "fake_B", ",", "self", ".", "o1_b", ",", "self", ".", "o2_b", ",", "self", ".", "o3_b", ",", "self", ".", "o4_b", ",", "self", ".", "o5_b", ",", "self", ".", "o6_b", ",", "self", ".", "o7_b", ",", "self", ".", "o8_b", ",", "self", ".", "o9_b", ",", "self", ".", "o10_b", ",", "self", ".", "a1_b", ",", "self", ".", "a2_b", ",", "self", ".", "a3_b", ",", "self", ".", "a4_b", ",", "self", ".", "a5_b", ",", "self", ".", "a6_b", ",", "self", ".", "a7_b", ",", "self", ".", "a8_b", ",", "self", ".", "a9_b", ",", "self", ".", "a10_b", ",", "self", ".", "i1_b", ",", "self", ".", "i2_b", ",", "self", ".", "i3_b", ",", "self", ".", "i4_b", ",", "self", ".", "i5_b", ",", "self", ".", "i6_b", ",", "self", ".", "i7_b", ",", "self", ".", "i8_b", ",", "self", ".", "i9_b", ",", "self", ".", "i10_b", "=", "self", ".", "netG_A", "(", "self", ".", "real_A", ")", "# G_A(A)", "\n", "self", ".", "rec_A", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "self", ".", "netG_B", "(", "self", ".", "fake_B", ")", "# G_B(G_A(A))", "\n", "self", ".", "fake_A", ",", "self", ".", "o1_a", ",", "self", ".", "o2_a", ",", "self", ".", "o3_a", ",", "self", ".", "o4_a", ",", "self", ".", "o5_a", ",", "self", ".", "o6_a", ",", "self", ".", "o7_a", ",", "self", ".", "o8_a", ",", "self", ".", "o9_a", ",", "self", ".", "o10_a", ","]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan_model.AttentionGANModel.backward_D_basic": [[99, 118], ["netD", "attention_gan_model.AttentionGANModel.criterionGAN", "netD", "attention_gan_model.AttentionGANModel.criterionGAN", "loss_D.backward", "fake.detach"], "methods", ["None"], ["self", ".", "a1_a", ",", "self", ".", "a2_a", ",", "self", ".", "a3_a", ",", "self", ".", "a4_a", ",", "self", ".", "a5_a", ",", "self", ".", "a6_a", ",", "self", ".", "a7_a", ",", "self", ".", "a8_a", ",", "self", ".", "a9_a", ",", "self", ".", "a10_a", ",", "self", ".", "i1_a", ",", "self", ".", "i2_a", ",", "self", ".", "i3_a", ",", "self", ".", "i4_a", ",", "self", ".", "i5_a", ",", "self", ".", "i6_a", ",", "self", ".", "i7_a", ",", "self", ".", "i8_a", ",", "self", ".", "i9_a", ",", "self", ".", "i10_a", "=", "self", ".", "netG_B", "(", "self", ".", "real_B", ")", "# G_B(B)", "\n", "self", ".", "rec_B", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "self", ".", "netG_A", "(", "self", ".", "fake_A", ")", "# G_A(G_B(B))", "\n", "\n", "", "def", "backward_D_basic", "(", "self", ",", "netD", ",", "real", ",", "fake", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for the discriminator\n        Parameters:\n            netD (network)      -- the discriminator D\n            real (tensor array) -- real images\n            fake (tensor array) -- images generated by a generator\n        Return the discriminator loss.\n        We also call loss_D.backward() to calculate the gradients.\n        \"\"\"", "\n", "# Real", "\n", "pred_real", "=", "netD", "(", "real", ")", "\n", "loss_D_real", "=", "self", ".", "criterionGAN", "(", "pred_real", ",", "True", ")", "\n", "# Fake", "\n", "pred_fake", "=", "netD", "(", "fake", ".", "detach", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan_model.AttentionGANModel.backward_D_A": [[119, 123], ["attention_gan_model.AttentionGANModel.fake_B_pool.query", "attention_gan_model.AttentionGANModel.backward_D_basic"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.image_pool.ImagePool.query", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_D_basic"], ["loss_D_fake", "=", "self", ".", "criterionGAN", "(", "pred_fake", ",", "False", ")", "\n", "# Combined loss and calculate gradients", "\n", "loss_D", "=", "(", "loss_D_real", "+", "loss_D_fake", ")", "*", "0.5", "\n", "loss_D", ".", "backward", "(", ")", "\n", "return", "loss_D", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan_model.AttentionGANModel.backward_D_B": [[124, 128], ["attention_gan_model.AttentionGANModel.fake_A_pool.query", "attention_gan_model.AttentionGANModel.backward_D_basic"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.image_pool.ImagePool.query", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_D_basic"], ["\n", "", "def", "backward_D_A", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for discriminator D_A\"\"\"", "\n", "fake_B", "=", "self", ".", "fake_B_pool", ".", "query", "(", "self", ".", "fake_B", ")", "\n", "self", ".", "loss_D_A", "=", "self", ".", "backward_D_basic", "(", "self", ".", "netD_A", ",", "self", ".", "real_B", ",", "fake_B", ")", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan_model.AttentionGANModel.backward_G": [[129, 161], ["attention_gan_model.AttentionGANModel.criterionGAN", "attention_gan_model.AttentionGANModel.criterionGAN", "attention_gan_model.AttentionGANModel.loss_G.backward", "attention_gan_model.AttentionGANModel.netG_A", "attention_gan_model.AttentionGANModel.netG_B", "attention_gan_model.AttentionGANModel.netD_A", "attention_gan_model.AttentionGANModel.netD_B", "attention_gan_model.AttentionGANModel.criterionCycle", "attention_gan_model.AttentionGANModel.criterionCycle", "attention_gan_model.AttentionGANModel.criterionIdt", "attention_gan_model.AttentionGANModel.criterionIdt"], "methods", ["None"], ["\n", "", "def", "backward_D_B", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for discriminator D_B\"\"\"", "\n", "fake_A", "=", "self", ".", "fake_A_pool", ".", "query", "(", "self", ".", "fake_A", ")", "\n", "self", ".", "loss_D_B", "=", "self", ".", "backward_D_basic", "(", "self", ".", "netD_B", ",", "self", ".", "real_A", ",", "fake_A", ")", "\n", "\n", "", "def", "backward_G", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate the loss for generators G_A and G_B\"\"\"", "\n", "lambda_idt", "=", "self", ".", "opt", ".", "lambda_identity", "\n", "lambda_A", "=", "self", ".", "opt", ".", "lambda_A", "\n", "lambda_B", "=", "self", ".", "opt", ".", "lambda_B", "\n", "# Identity loss", "\n", "if", "lambda_idt", ">", "0", ":", "\n", "# G_A should be identity if real_B is fed: ||G_A(B) - B||", "\n", "            ", "self", ".", "idt_A", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "self", ".", "netG_A", "(", "self", ".", "real_B", ")", "\n", "self", ".", "loss_idt_A", "=", "self", ".", "criterionIdt", "(", "self", ".", "idt_A", ",", "self", ".", "real_B", ")", "*", "lambda_B", "*", "lambda_idt", "\n", "# G_B should be identity if real_A is fed: ||G_B(A) - A||", "\n", "self", ".", "idt_B", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "self", ".", "netG_B", "(", "self", ".", "real_A", ")", "\n", "self", ".", "loss_idt_B", "=", "self", ".", "criterionIdt", "(", "self", ".", "idt_B", ",", "self", ".", "real_A", ")", "*", "lambda_A", "*", "lambda_idt", "\n", "", "else", ":", "\n", "            ", "self", ".", "loss_idt_A", "=", "0", "\n", "self", ".", "loss_idt_B", "=", "0", "\n", "\n", "# GAN loss D_A(G_A(A))", "\n", "", "self", ".", "loss_G_A", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD_A", "(", "self", ".", "fake_B", ")", ",", "True", ")", "\n", "# GAN loss D_B(G_B(B))", "\n", "self", ".", "loss_G_B", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD_B", "(", "self", ".", "fake_A", ")", ",", "True", ")", "\n", "# Forward cycle loss || G_B(G_A(A)) - A||", "\n", "self", ".", "loss_cycle_A", "=", "self", ".", "criterionCycle", "(", "self", ".", "rec_A", ",", "self", ".", "real_A", ")", "*", "lambda_A", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan_model.AttentionGANModel.optimize_parameters": [[162, 177], ["attention_gan_model.AttentionGANModel.forward", "attention_gan_model.AttentionGANModel.set_requires_grad", "attention_gan_model.AttentionGANModel.optimizer_G.zero_grad", "attention_gan_model.AttentionGANModel.backward_G", "attention_gan_model.AttentionGANModel.optimizer_G.step", "attention_gan_model.AttentionGANModel.set_requires_grad", "attention_gan_model.AttentionGANModel.optimizer_D.zero_grad", "attention_gan_model.AttentionGANModel.backward_D_A", "attention_gan_model.AttentionGANModel.backward_D_B", "attention_gan_model.AttentionGANModel.optimizer_D.step"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.forward", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_G", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.LambdaLR.step", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_D_A", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_D_B", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.LambdaLR.step"], ["# Backward cycle loss || G_A(G_B(B)) - B||", "\n", "self", ".", "loss_cycle_B", "=", "self", ".", "criterionCycle", "(", "self", ".", "rec_B", ",", "self", ".", "real_B", ")", "*", "lambda_B", "\n", "# combined loss and calculate gradients", "\n", "self", ".", "loss_G", "=", "self", ".", "loss_G_A", "+", "self", ".", "loss_G_B", "+", "self", ".", "loss_cycle_A", "+", "self", ".", "loss_cycle_B", "+", "self", ".", "loss_idt_A", "+", "self", ".", "loss_idt_B", "\n", "self", ".", "loss_G", ".", "backward", "(", ")", "\n", "\n", "", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"", "\n", "# forward", "\n", "self", ".", "forward", "(", ")", "# compute fake images and reconstruction images.", "\n", "# G_A and G_B", "\n", "self", ".", "set_requires_grad", "(", "[", "self", ".", "netD_A", ",", "self", ".", "netD_B", "]", ",", "False", ")", "# Ds require no gradients when optimizing Gs", "\n", "self", ".", "optimizer_G", ".", "zero_grad", "(", ")", "# set G_A and G_B's gradients to zero", "\n", "self", ".", "backward_G", "(", ")", "# calculate gradients for G_A and G_B", "\n", "self", ".", "optimizer_G", ".", "step", "(", ")", "# update G_A and G_B's weights", "\n", "# D_A and D_B", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.modify_commandline_options": [[17, 41], ["parser.set_defaults", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", "=", "True", ")", ":", "\n", "        ", "\"\"\"Add new dataset-specific options, and rewrite default values for existing options.\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n        Returns:\n            the modified parser.\n        For CycleGAN, in addition to GAN losses, we introduce lambda_A, lambda_B, and lambda_identity for the following losses.\n        A (source domain), B (target domain).\n        Generators: G_A: A -> B; G_B: B -> A.\n        Discriminators: D_A: G_A(A) vs. B; D_B: G_B(B) vs. A.\n        Forward cycle loss:  lambda_A * ||G_B(G_A(A)) - A|| (Eqn. (2) in the paper)\n        Backward cycle loss: lambda_B * ||G_A(G_B(B)) - B|| (Eqn. (2) in the paper)\n        Identity loss (optional): lambda_identity * (||G_A(B) - B|| * lambda_B + ||G_B(A) - A|| * lambda_A) (Sec 5.2 \"Photo generation from paintings\" in the paper)\n        Dropout is not used in the original CycleGAN paper.\n        \"\"\"", "\n", "parser", ".", "set_defaults", "(", "no_dropout", "=", "True", ")", "# default CycleGAN did not use dropout", "\n", "if", "is_train", ":", "\n", "            ", "parser", ".", "add_argument", "(", "'--lambda_A'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for cycle loss (A -> B -> A)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_B'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for cycle loss (B -> A -> B)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_identity'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'use identity mapping. Setting lambda_identity other than 0 has an effect of scaling the weight of the identity mapping loss. For example, if the weight of the identity loss should be 10 times smaller than the weight of the reconstruction loss, please set lambda_identity = 0.1'", ")", "\n", "\n", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.__init__": [[42, 98], ["base_model.BaseModel.__init__", "networks.define_G", "networks.define_G", "visual_names_A.append", "visual_names_B.append", "networks.define_D", "networks.define_D", "util.image_pool.ImagePool", "util.image_pool.ImagePool", "networks.GANLoss().to", "torch.nn.L1Loss", "torch.nn.L1Loss", "torch.optim.Adam", "torch.optim.Adam", "attention_gan1_model.CycleGAN1Model.optimizers.append", "attention_gan1_model.CycleGAN1Model.optimizers.append", "itertools.chain", "itertools.chain", "networks.GANLoss", "attention_gan1_model.CycleGAN1Model.netG_A.parameters", "attention_gan1_model.CycleGAN1Model.netG_B.parameters", "attention_gan1_model.CycleGAN1Model.netD_A.parameters", "attention_gan1_model.CycleGAN1Model.netD_B.parameters"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.define_G", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.define_G", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.define_D", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.define_D"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the CycleGAN class.\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "BaseModel", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "# specify the training losses you want to print out. The training/test scripts will call <BaseModel.get_current_losses>", "\n", "self", ".", "loss_names", "=", "[", "'D_A'", ",", "'G_A'", ",", "'cycle_A'", ",", "'idt_A'", ",", "'D_B'", ",", "'G_B'", ",", "'cycle_B'", ",", "'idt_B'", "]", "\n", "# specify the images you want to save/display. The training/test scripts will call <BaseModel.get_current_visuals>", "\n", "visual_names_A", "=", "[", "'real_A'", ",", "'fake_B'", ",", "'rec_A'", ",", "'o1_b'", ",", "'o2_b'", ",", "'o3_b'", ",", "'o4_b'", ",", "'o5_b'", ",", "'o6_b'", ",", "'o7_b'", ",", "'o8_b'", ",", "'o9_b'", ",", "'o10_b'", ",", "\n", "'a1_b'", ",", "'a2_b'", ",", "'a3_b'", ",", "'a4_b'", ",", "'a5_b'", ",", "'a6_b'", ",", "'a7_b'", ",", "'a8_b'", ",", "'a9_b'", ",", "'a10_b'", ",", "'i1_b'", ",", "'i2_b'", ",", "'i3_b'", ",", "'i4_b'", ",", "'i5_b'", ",", "\n", "'i6_b'", ",", "'i7_b'", ",", "'i8_b'", ",", "'i9_b'", ",", "'rec_A_o1'", ",", "'rec_A_o2'", ",", "'rec_A_o3'", ",", "'rec_A_o4'", ",", "'rec_A_o5'", ",", "'rec_A_o6'", ",", "'rec_A_o7'", ",", "'rec_A_o8'", ",", "'rec_A_o9'", ",", "'rec_A_o10'", ",", "\n", "'rec_A_a1'", ",", "'rec_A_a2'", ",", "'rec_A_a3'", ",", "'rec_A_a4'", ",", "'rec_A_a5'", ",", "'rec_A_a6'", ",", "'rec_A_a7'", ",", "'rec_A_a8'", ",", "'rec_A_a9'", ",", "'rec_A_a10'", ",", "\n", "'rec_A_i1'", ",", "'rec_A_i2'", ",", "'rec_A_i3'", ",", "'rec_A_i4'", ",", "'rec_A_i5'", ",", "'rec_A_i6'", ",", "'rec_A_i7'", ",", "'rec_A_i8'", ",", "'rec_A_i9'", "]", "\n", "visual_names_B", "=", "[", "'real_B'", ",", "'fake_A'", ",", "'rec_B'", ",", "'o1_a'", ",", "'o2_a'", ",", "'o3_a'", ",", "'o4_a'", ",", "'o5_a'", ",", "'o6_a'", ",", "'o7_a'", ",", "'o8_a'", ",", "'o9_a'", ",", "'o10_a'", ",", "\n", "'a1_a'", ",", "'a2_a'", ",", "'a3_a'", ",", "'a4_a'", ",", "'a5_a'", ",", "'a6_a'", ",", "'a7_a'", ",", "'a8_a'", ",", "'a9_a'", ",", "'a10_a'", ",", "'i1_a'", ",", "'i2_a'", ",", "'i3_a'", ",", "'i4_a'", ",", "'i5_a'", ",", "\n", "'i6_a'", ",", "'i7_a'", ",", "'i8_a'", ",", "'i9_a'", "]", "\n", "if", "self", ".", "isTrain", "and", "self", ".", "opt", ".", "lambda_identity", ">", "0.0", ":", "# if identity loss is used, we also visualize idt_B=G_A(B) ad idt_A=G_A(B)", "\n", "            ", "visual_names_A", ".", "append", "(", "'idt_B'", ")", "\n", "visual_names_B", ".", "append", "(", "'idt_A'", ")", "\n", "\n", "", "self", ".", "visual_names", "=", "visual_names_A", "+", "visual_names_B", "# combine visualizations for A and B", "\n", "# specify the models you want to save to the disk. The training/test scripts will call <BaseModel.save_networks> and <BaseModel.load_networks>.", "\n", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "model_names", "=", "[", "'G_A'", ",", "'G_B'", ",", "'D_A'", ",", "'D_B'", "]", "\n", "", "else", ":", "# during test time, only load Gs", "\n", "            ", "self", ".", "model_names", "=", "[", "'G_A'", ",", "'G_B'", "]", "\n", "\n", "# define networks (both Generators and discriminators)", "\n", "# The naming is different from those used in the paper.", "\n", "# Code (vs. paper): G_A (G), G_B (F), D_A (D_Y), D_B (D_X)", "\n", "", "self", ".", "netG_A", "=", "networks", ".", "define_G", "(", "opt", ".", "input_nc", ",", "opt", ".", "output_nc", ",", "opt", ".", "ngf", ",", "'our'", ",", "opt", ".", "norm", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "self", ".", "netG_B", "=", "networks", ".", "define_G", "(", "opt", ".", "output_nc", ",", "opt", ".", "input_nc", ",", "opt", ".", "ngf", ",", "'our'", ",", "opt", ".", "norm", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "\n", "if", "self", ".", "isTrain", ":", "# define discriminators", "\n", "            ", "self", ".", "netD_A", "=", "networks", ".", "define_D", "(", "opt", ".", "output_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "opt", ".", "n_layers_D", ",", "opt", ".", "norm", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "self", ".", "netD_B", "=", "networks", ".", "define_D", "(", "opt", ".", "input_nc", ",", "opt", ".", "ndf", ",", "opt", ".", "netD", ",", "\n", "opt", ".", "n_layers_D", ",", "opt", ".", "norm", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "\n", "", "if", "self", ".", "isTrain", ":", "\n", "            ", "if", "opt", ".", "lambda_identity", ">", "0.0", ":", "# only works when input and output images have the same number of channels", "\n", "                ", "assert", "(", "opt", ".", "input_nc", "==", "opt", ".", "output_nc", ")", "\n", "", "self", ".", "fake_A_pool", "=", "ImagePool", "(", "opt", ".", "pool_size", ")", "# create image buffer to store previously generated images", "\n", "self", ".", "fake_B_pool", "=", "ImagePool", "(", "opt", ".", "pool_size", ")", "# create image buffer to store previously generated images", "\n", "# define loss functions", "\n", "self", ".", "criterionGAN", "=", "networks", ".", "GANLoss", "(", "opt", ".", "gan_mode", ")", ".", "to", "(", "self", ".", "device", ")", "# define GAN loss.", "\n", "self", ".", "criterionCycle", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "\n", "self", ".", "criterionIdt", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "\n", "# initialize optimizers; schedulers will be automatically created by function <BaseModel.setup>.", "\n", "self", ".", "optimizer_G", "=", "torch", ".", "optim", ".", "Adam", "(", "itertools", ".", "chain", "(", "self", ".", "netG_A", ".", "parameters", "(", ")", ",", "self", ".", "netG_B", ".", "parameters", "(", ")", ")", ",", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "self", ".", "optimizer_D", "=", "torch", ".", "optim", ".", "Adam", "(", "itertools", ".", "chain", "(", "self", ".", "netD_A", ".", "parameters", "(", ")", ",", "self", ".", "netD_B", ".", "parameters", "(", ")", ")", ",", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_G", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_D", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.set_input": [[99, 109], ["input[].to", "input[].to"], "methods", ["None"], ["", "", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n        Parameters:\n            input (dict): include the data itself and its metadata information.\n        The option 'direction' can be used to swap domain A and domain B.\n        \"\"\"", "\n", "AtoB", "=", "self", ".", "opt", ".", "direction", "==", "'AtoB'", "\n", "self", ".", "real_A", "=", "input", "[", "'A'", "if", "AtoB", "else", "'B'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "real_B", "=", "input", "[", "'B'", "if", "AtoB", "else", "'A'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "image_paths", "=", "input", "[", "'A_paths'", "if", "AtoB", "else", "'B_paths'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.forward": [[110, 126], ["attention_gan1_model.CycleGAN1Model.netG_A", "attention_gan1_model.CycleGAN1Model.netG_B", "attention_gan1_model.CycleGAN1Model.netG_B", "attention_gan1_model.CycleGAN1Model.netG_A"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"", "\n", "self", ".", "fake_B", ",", "self", ".", "o1_b", ",", "self", ".", "o2_b", ",", "self", ".", "o3_b", ",", "self", ".", "o4_b", ",", "self", ".", "o5_b", ",", "self", ".", "o6_b", ",", "self", ".", "o7_b", ",", "self", ".", "o8_b", ",", "self", ".", "o9_b", ",", "self", ".", "o10_b", ",", "self", ".", "a1_b", ",", "self", ".", "a2_b", ",", "self", ".", "a3_b", ",", "self", ".", "a4_b", ",", "self", ".", "a5_b", ",", "self", ".", "a6_b", ",", "self", ".", "a7_b", ",", "self", ".", "a8_b", ",", "self", ".", "a9_b", ",", "self", ".", "a10_b", ",", "self", ".", "i1_b", ",", "self", ".", "i2_b", ",", "self", ".", "i3_b", ",", "self", ".", "i4_b", ",", "self", ".", "i5_b", ",", "self", ".", "i6_b", ",", "self", ".", "i7_b", ",", "self", ".", "i8_b", ",", "self", ".", "i9_b", "=", "self", ".", "netG_A", "(", "self", ".", "real_A", ")", "# G_A(A)", "\n", "\n", "self", ".", "rec_A", ",", "self", ".", "rec_A_o1", ",", "self", ".", "rec_A_o2", ",", "self", ".", "rec_A_o3", ",", "self", ".", "rec_A_o4", ",", "self", ".", "rec_A_o5", ",", "self", ".", "rec_A_o6", ",", "self", ".", "rec_A_o7", ",", "self", ".", "rec_A_o8", ",", "self", ".", "rec_A_o9", ",", "self", ".", "rec_A_o10", ",", "self", ".", "rec_A_a1", ",", "self", ".", "rec_A_a2", ",", "self", ".", "rec_A_a3", ",", "self", ".", "rec_A_a4", ",", "self", ".", "rec_A_a5", ",", "self", ".", "rec_A_a6", ",", "self", ".", "rec_A_a7", ",", "self", ".", "rec_A_a8", ",", "self", ".", "rec_A_a9", ",", "self", ".", "rec_A_a10", ",", "self", ".", "rec_A_i1", ",", "self", ".", "rec_A_i2", ",", "self", ".", "rec_A_i3", ",", "self", ".", "rec_A_i4", ",", "self", ".", "rec_A_i5", ",", "self", ".", "rec_A_i6", ",", "self", ".", "rec_A_i7", ",", "self", ".", "rec_A_i8", ",", "self", ".", "rec_A_i9", "=", "self", ".", "netG_B", "(", "self", ".", "fake_B", ")", "# G_B(G_A(A))", "\n", "\n", "self", ".", "fake_A", ",", "self", ".", "o1_a", ",", "self", ".", "o2_a", ",", "self", ".", "o3_a", ",", "self", ".", "o4_a", ",", "self", ".", "o5_a", ",", "self", ".", "o6_a", ",", "self", ".", "o7_a", ",", "self", ".", "o8_a", ",", "self", ".", "o9_a", ",", "self", ".", "o10_a", ",", "self", ".", "a1_a", ",", "self", ".", "a2_a", ",", "self", ".", "a3_a", ",", "self", ".", "a4_a", ",", "self", ".", "a5_a", ",", "self", ".", "a6_a", ",", "self", ".", "a7_a", ",", "self", ".", "a8_a", ",", "self", ".", "a9_a", ",", "self", ".", "a10_a", ",", "self", ".", "i1_a", ",", "self", ".", "i2_a", ",", "self", ".", "i3_a", ",", "self", ".", "i4_a", ",", "self", ".", "i5_a", ",", "self", ".", "i6_a", ",", "self", ".", "i7_a", ",", "self", ".", "i8_a", ",", "self", ".", "i9_a", "=", "self", ".", "netG_B", "(", "self", ".", "real_B", ")", "# G_B(B)", "\n", "self", ".", "rec_B", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "self", ".", "netG_A", "(", "self", ".", "fake_A", ")", "# G_A(G_B(B))", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_D_basic": [[127, 146], ["netD", "attention_gan1_model.CycleGAN1Model.criterionGAN", "netD", "attention_gan1_model.CycleGAN1Model.criterionGAN", "loss_D.backward", "fake.detach"], "methods", ["None"], ["", "def", "backward_D_basic", "(", "self", ",", "netD", ",", "real", ",", "fake", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for the discriminator\n        Parameters:\n            netD (network)      -- the discriminator D\n            real (tensor array) -- real images\n            fake (tensor array) -- images generated by a generator\n        Return the discriminator loss.\n        We also call loss_D.backward() to calculate the gradients.\n        \"\"\"", "\n", "# Real", "\n", "pred_real", "=", "netD", "(", "real", ")", "\n", "loss_D_real", "=", "self", ".", "criterionGAN", "(", "pred_real", ",", "True", ")", "\n", "# Fake", "\n", "pred_fake", "=", "netD", "(", "fake", ".", "detach", "(", ")", ")", "\n", "loss_D_fake", "=", "self", ".", "criterionGAN", "(", "pred_fake", ",", "False", ")", "\n", "# Combined loss and calculate gradients", "\n", "loss_D", "=", "(", "loss_D_real", "+", "loss_D_fake", ")", "*", "0.5", "\n", "loss_D", ".", "backward", "(", ")", "\n", "return", "loss_D", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_D_A": [[147, 151], ["attention_gan1_model.CycleGAN1Model.fake_B_pool.query", "attention_gan1_model.CycleGAN1Model.backward_D_basic"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.image_pool.ImagePool.query", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_D_basic"], ["", "def", "backward_D_A", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for discriminator D_A\"\"\"", "\n", "fake_B", "=", "self", ".", "fake_B_pool", ".", "query", "(", "self", ".", "fake_B", ")", "\n", "self", ".", "loss_D_A", "=", "self", ".", "backward_D_basic", "(", "self", ".", "netD_A", ",", "self", ".", "real_B", ",", "fake_B", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_D_B": [[152, 156], ["attention_gan1_model.CycleGAN1Model.fake_A_pool.query", "attention_gan1_model.CycleGAN1Model.backward_D_basic"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.image_pool.ImagePool.query", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_D_basic"], ["", "def", "backward_D_B", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate GAN loss for discriminator D_B\"\"\"", "\n", "fake_A", "=", "self", ".", "fake_A_pool", ".", "query", "(", "self", ".", "fake_A", ")", "\n", "self", ".", "loss_D_B", "=", "self", ".", "backward_D_basic", "(", "self", ".", "netD_B", ",", "self", ".", "real_A", ",", "fake_A", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_G": [[157, 189], ["attention_gan1_model.CycleGAN1Model.criterionGAN", "attention_gan1_model.CycleGAN1Model.criterionGAN", "attention_gan1_model.CycleGAN1Model.loss_G.backward", "attention_gan1_model.CycleGAN1Model.netG_A", "attention_gan1_model.CycleGAN1Model.netG_B", "attention_gan1_model.CycleGAN1Model.netD_A", "attention_gan1_model.CycleGAN1Model.netD_B", "attention_gan1_model.CycleGAN1Model.criterionCycle", "attention_gan1_model.CycleGAN1Model.criterionCycle", "attention_gan1_model.CycleGAN1Model.criterionIdt", "attention_gan1_model.CycleGAN1Model.criterionIdt"], "methods", ["None"], ["", "def", "backward_G", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate the loss for generators G_A and G_B\"\"\"", "\n", "lambda_idt", "=", "self", ".", "opt", ".", "lambda_identity", "\n", "lambda_A", "=", "self", ".", "opt", ".", "lambda_A", "\n", "lambda_B", "=", "self", ".", "opt", ".", "lambda_B", "\n", "# Identity loss", "\n", "if", "lambda_idt", ">", "0", ":", "\n", "# G_A should be identity if real_B is fed: ||G_A(B) - B||", "\n", "            ", "self", ".", "idt_A", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "self", ".", "netG_A", "(", "self", ".", "real_B", ")", "\n", "self", ".", "loss_idt_A", "=", "self", ".", "criterionIdt", "(", "self", ".", "idt_A", ",", "self", ".", "real_B", ")", "*", "lambda_B", "*", "lambda_idt", "\n", "# G_B should be identity if real_A is fed: ||G_B(A) - A||", "\n", "self", ".", "idt_B", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "self", ".", "netG_B", "(", "self", ".", "real_A", ")", "\n", "self", ".", "loss_idt_B", "=", "self", ".", "criterionIdt", "(", "self", ".", "idt_B", ",", "self", ".", "real_A", ")", "*", "lambda_A", "*", "lambda_idt", "\n", "", "else", ":", "\n", "            ", "self", ".", "loss_idt_A", "=", "0", "\n", "self", ".", "loss_idt_B", "=", "0", "\n", "\n", "# GAN loss D_A(G_A(A))", "\n", "", "self", ".", "loss_G_A", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD_A", "(", "self", ".", "fake_B", ")", ",", "True", ")", "\n", "# GAN loss D_B(G_B(B))", "\n", "self", ".", "loss_G_B", "=", "self", ".", "criterionGAN", "(", "self", ".", "netD_B", "(", "self", ".", "fake_A", ")", ",", "True", ")", "\n", "# Forward cycle loss || G_B(G_A(A)) - A||", "\n", "self", ".", "loss_cycle_A", "=", "self", ".", "criterionCycle", "(", "self", ".", "rec_A", ",", "self", ".", "real_A", ")", "*", "lambda_A", "\n", "# Backward cycle loss || G_A(G_B(B)) - B||", "\n", "self", ".", "loss_cycle_B", "=", "self", ".", "criterionCycle", "(", "self", ".", "rec_B", ",", "self", ".", "real_B", ")", "*", "lambda_B", "\n", "# combined loss and calculate gradients", "\n", "self", ".", "loss_G", "=", "self", ".", "loss_G_A", "+", "self", ".", "loss_G_B", "+", "self", ".", "loss_cycle_A", "+", "self", ".", "loss_cycle_B", "+", "self", ".", "loss_idt_A", "+", "self", ".", "loss_idt_B", "\n", "self", ".", "loss_G", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.optimize_parameters": [[190, 205], ["attention_gan1_model.CycleGAN1Model.forward", "attention_gan1_model.CycleGAN1Model.set_requires_grad", "attention_gan1_model.CycleGAN1Model.optimizer_G.zero_grad", "attention_gan1_model.CycleGAN1Model.backward_G", "attention_gan1_model.CycleGAN1Model.optimizer_G.step", "attention_gan1_model.CycleGAN1Model.set_requires_grad", "attention_gan1_model.CycleGAN1Model.optimizer_D.zero_grad", "attention_gan1_model.CycleGAN1Model.backward_D_A", "attention_gan1_model.CycleGAN1Model.backward_D_B", "attention_gan1_model.CycleGAN1Model.optimizer_D.step"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.forward", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_G", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.LambdaLR.step", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_D_A", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.attention_gan1_model.CycleGAN1Model.backward_D_B", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.LambdaLR.step"], ["", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"", "\n", "# forward", "\n", "self", ".", "forward", "(", ")", "# compute fake images and reconstruction images.", "\n", "# G_A and G_B", "\n", "self", ".", "set_requires_grad", "(", "[", "self", ".", "netD_A", ",", "self", ".", "netD_B", "]", ",", "False", ")", "# Ds require no gradients when optimizing Gs", "\n", "self", ".", "optimizer_G", ".", "zero_grad", "(", ")", "# set G_A and G_B's gradients to zero", "\n", "self", ".", "backward_G", "(", ")", "# calculate gradients for G_A and G_B", "\n", "self", ".", "optimizer_G", ".", "step", "(", ")", "# update G_A and G_B's weights", "\n", "# D_A and D_B", "\n", "self", ".", "set_requires_grad", "(", "[", "self", ".", "netD_A", ",", "self", ".", "netD_B", "]", ",", "True", ")", "\n", "self", ".", "optimizer_D", ".", "zero_grad", "(", ")", "# set D_A and D_B's gradients to zero", "\n", "self", ".", "backward_D_A", "(", ")", "# calculate gradients for D_A", "\n", "self", ".", "backward_D_B", "(", ")", "# calculate graidents for D_B", "\n", "self", ".", "optimizer_D", ".", "step", "(", ")", "# update D_A and D_B's weights", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.__init__.find_model_using_name": [[25, 46], ["importlib.import_module", "importlib.import_module.__dict__.items", "model_name.replace", "print", "exit", "issubclass", "name.lower", "target_model_name.lower"], "function", ["None"], []], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.__init__.get_option_setter": [[48, 52], ["__init__.find_model_using_name"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.__init__.find_model_using_name"], []], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.__init__.create_model": [[54, 68], ["__init__.find_model_using_name", "find_model_using_name.", "print", "type"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.__init__.find_model_using_name"], []], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.__init__": [[18, 45], ["os.path.join", "torch.device", "torch.device"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the BaseModel class.\n\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n\n        When creating your custom class, you need to implement your own initialization.\n        In this fucntion, you should first call <BaseModel.__init__(self, opt)>\n        Then, you need to define four lists:\n            -- self.loss_names (str list):          specify the training losses that you want to plot and save.\n            -- self.model_names (str list):         specify the images that you want to display and save.\n            -- self.visual_names (str list):        define networks used in our training.\n            -- self.optimizers (optimizer list):    define and initialize optimizers. You can define one optimizer for each network. If two networks are updated at the same time, you can use itertools.chain to group them. See cycle_gan_model.py for an example.\n        \"\"\"", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "gpu_ids", "=", "opt", ".", "gpu_ids", "\n", "self", ".", "isTrain", "=", "opt", ".", "isTrain", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:{}'", ".", "format", "(", "self", ".", "gpu_ids", "[", "0", "]", ")", ")", "if", "self", ".", "gpu_ids", "else", "torch", ".", "device", "(", "'cpu'", ")", "# get device name: CPU or GPU", "\n", "self", ".", "save_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "# save all the checkpoints to save_dir", "\n", "if", "opt", ".", "preprocess", "!=", "'scale_width'", ":", "# with [scale_width], input images might have different sizes, which hurts the performance of cudnn.benchmark.", "\n", "            ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "", "self", ".", "loss_names", "=", "[", "]", "\n", "self", ".", "model_names", "=", "[", "]", "\n", "self", ".", "visual_names", "=", "[", "]", "\n", "self", ".", "optimizers", "=", "[", "]", "\n", "self", ".", "image_paths", "=", "[", "]", "\n", "self", ".", "metric", "=", "0", "# used for learning rate policy 'plateau'", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.modify_commandline_options": [[46, 58], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"Add new model-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n        \"\"\"", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.set_input": [[59, 67], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n\n        Parameters:\n            input (dict): includes the data itself and its metadata information.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.forward": [[68, 72], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "forward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.optimize_parameters": [[73, 77], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.setup": [[78, 90], ["base_model.BaseModel.print_networks", "base_model.BaseModel.load_networks", "networks.get_scheduler"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.print_networks", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.load_networks", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.networks.get_scheduler"], ["", "def", "setup", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Load and print networks; create schedulers\n\n        Parameters:\n            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "schedulers", "=", "[", "networks", ".", "get_scheduler", "(", "optimizer", ",", "opt", ")", "for", "optimizer", "in", "self", ".", "optimizers", "]", "\n", "", "if", "not", "self", ".", "isTrain", "or", "opt", ".", "continue_train", ":", "\n", "            ", "load_suffix", "=", "'iter_%d'", "%", "opt", ".", "load_iter", "if", "opt", ".", "load_iter", ">", "0", "else", "opt", ".", "epoch", "\n", "self", ".", "load_networks", "(", "load_suffix", ")", "\n", "", "self", ".", "print_networks", "(", "opt", ".", "verbose", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.eval": [[91, 97], ["isinstance", "getattr", "getattr.eval"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.eval"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make models eval mode during test time\"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "net", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.test": [[98, 107], ["torch.no_grad", "base_model.BaseModel.forward", "base_model.BaseModel.compute_visuals"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.forward", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.compute_visuals"], ["", "", "", "def", "test", "(", "self", ")", ":", "\n", "        ", "\"\"\"Forward function used in test time.\n\n        This function wraps <forward> function in no_grad() so we don't save intermediate steps for backprop\n        It also calls <compute_visuals> to produce additional visualization results\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "forward", "(", ")", "\n", "self", ".", "compute_visuals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.compute_visuals": [[108, 111], ["None"], "methods", ["None"], ["", "", "def", "compute_visuals", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate additional output images for visdom and HTML visualization\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.get_image_paths": [[112, 115], ["None"], "methods", ["None"], ["", "def", "get_image_paths", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return image paths that are used to load current data\"\"\"", "\n", "return", "self", ".", "image_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.update_learning_rate": [[116, 126], ["print", "scheduler.step", "scheduler.step"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.LambdaLR.step", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.AttentionGAN-v1.utils.LambdaLR.step"], ["", "def", "update_learning_rate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Update learning rates for all the networks; called at the end of every epoch\"\"\"", "\n", "for", "scheduler", "in", "self", ".", "schedulers", ":", "\n", "            ", "if", "self", ".", "opt", ".", "lr_policy", "==", "'plateau'", ":", "\n", "                ", "scheduler", ".", "step", "(", "self", ".", "metric", ")", "\n", "", "else", ":", "\n", "                ", "scheduler", ".", "step", "(", ")", "\n", "\n", "", "", "lr", "=", "self", ".", "optimizers", "[", "0", "]", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "print", "(", "'learning rate = %.7f'", "%", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.get_current_visuals": [[127, 134], ["collections.OrderedDict", "isinstance", "getattr"], "methods", ["None"], ["", "def", "get_current_visuals", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return visualization images. train.py will display these images with visdom, and save the images to a HTML\"\"\"", "\n", "visual_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "visual_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "visual_ret", "[", "name", "]", "=", "getattr", "(", "self", ",", "name", ")", "\n", "", "", "return", "visual_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.get_current_losses": [[135, 142], ["collections.OrderedDict", "isinstance", "float", "getattr"], "methods", ["None"], ["", "def", "get_current_losses", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return traning losses / errors. train.py will print out these errors on console, and save them to a file\"\"\"", "\n", "errors_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "loss_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "errors_ret", "[", "name", "]", "=", "float", "(", "getattr", "(", "self", ",", "'loss_'", "+", "name", ")", ")", "# float(...) works for both scalar tensor and float number", "\n", "", "", "return", "errors_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.save_networks": [[143, 160], ["isinstance", "os.path.join", "getattr", "torch.cuda.is_available", "torch.save", "getattr.cuda", "torch.save", "len", "getattr.module.cpu().state_dict", "getattr.cpu().state_dict", "getattr.module.cpu", "getattr.cpu"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.save", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.html.HTML.save"], ["", "def", "save_networks", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Save all the networks to the disk.\n\n        Parameters:\n            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n        \"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "save_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch", ",", "name", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "save_filename", ")", "\n", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "\n", "if", "len", "(", "self", ".", "gpu_ids", ")", ">", "0", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "torch", ".", "save", "(", "net", ".", "module", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "net", ".", "cuda", "(", "self", ".", "gpu_ids", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "save", "(", "net", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.__patch_instance_norm_state_dict": [[161, 174], ["len", "base_model.BaseModel.__patch_instance_norm_state_dict", "module.__class__.__name__.startswith", "module.__class__.__name__.startswith", "state_dict.pop", "getattr", "getattr", "state_dict.pop"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.__patch_instance_norm_state_dict"], ["", "", "", "", "def", "__patch_instance_norm_state_dict", "(", "self", ",", "state_dict", ",", "module", ",", "keys", ",", "i", "=", "0", ")", ":", "\n", "        ", "\"\"\"Fix InstanceNorm checkpoints incompatibility (prior to 0.4)\"\"\"", "\n", "key", "=", "keys", "[", "i", "]", "\n", "if", "i", "+", "1", "==", "len", "(", "keys", ")", ":", "# at the end, pointing to a parameter/buffer", "\n", "            ", "if", "module", ".", "__class__", ".", "__name__", ".", "startswith", "(", "'InstanceNorm'", ")", "and", "(", "key", "==", "'running_mean'", "or", "key", "==", "'running_var'", ")", ":", "\n", "                ", "if", "getattr", "(", "module", ",", "key", ")", "is", "None", ":", "\n", "                    ", "state_dict", ".", "pop", "(", "'.'", ".", "join", "(", "keys", ")", ")", "\n", "", "", "if", "module", ".", "__class__", ".", "__name__", ".", "startswith", "(", "'InstanceNorm'", ")", "and", "(", "key", "==", "'num_batches_tracked'", ")", ":", "\n", "                ", "state_dict", ".", "pop", "(", "'.'", ".", "join", "(", "keys", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "__patch_instance_norm_state_dict", "(", "state_dict", ",", "getattr", "(", "module", ",", "key", ")", ",", "keys", ",", "i", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.load_networks": [[175, 199], ["isinstance", "os.path.join", "getattr", "isinstance", "print", "torch.load", "hasattr", "list", "getattr.load_state_dict", "torch.load.keys", "base_model.BaseModel.__patch_instance_norm_state_dict", "str", "key.split"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.__patch_instance_norm_state_dict"], ["", "", "def", "load_networks", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Load all the networks from the disk.\n\n        Parameters:\n            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n        \"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "load_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch", ",", "name", ")", "\n", "load_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "load_filename", ")", "\n", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "if", "isinstance", "(", "net", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "                    ", "net", "=", "net", ".", "module", "\n", "", "print", "(", "'loading the model from %s'", "%", "load_path", ")", "\n", "# if you are using PyTorch newer than 0.4 (e.g., built from", "\n", "# GitHub source), you can remove str() on self.device", "\n", "state_dict", "=", "torch", ".", "load", "(", "load_path", ",", "map_location", "=", "str", "(", "self", ".", "device", ")", ")", "\n", "if", "hasattr", "(", "state_dict", ",", "'_metadata'", ")", ":", "\n", "                    ", "del", "state_dict", ".", "_metadata", "\n", "\n", "# patch InstanceNorm checkpoints prior to 0.4", "\n", "", "for", "key", "in", "list", "(", "state_dict", ".", "keys", "(", ")", ")", ":", "# need to copy keys here because we mutate in loop", "\n", "                    ", "self", ".", "__patch_instance_norm_state_dict", "(", "state_dict", ",", "net", ",", "key", ".", "split", "(", "'.'", ")", ")", "\n", "", "net", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.print_networks": [[200, 217], ["print", "print", "isinstance", "getattr", "getattr.parameters", "print", "param.numel", "print"], "methods", ["None"], ["", "", "", "def", "print_networks", "(", "self", ",", "verbose", ")", ":", "\n", "        ", "\"\"\"Print the total number of parameters in the network and (if verbose) network architecture\n\n        Parameters:\n            verbose (bool) -- if verbose: print the network architecture\n        \"\"\"", "\n", "print", "(", "'---------- Networks initialized -------------'", ")", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "num_params", "=", "0", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "                    ", "num_params", "+=", "param", ".", "numel", "(", ")", "\n", "", "if", "verbose", ":", "\n", "                    ", "print", "(", "net", ")", "\n", "", "print", "(", "'[Network %s] Total number of parameters : %.3f M'", "%", "(", "name", ",", "num_params", "/", "1e6", ")", ")", "\n", "", "", "print", "(", "'-----------------------------------------------'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.models.base_model.BaseModel.set_requires_grad": [[218, 230], ["isinstance", "net.parameters"], "methods", ["None"], ["", "def", "set_requires_grad", "(", "self", ",", "nets", ",", "requires_grad", "=", "False", ")", ":", "\n", "        ", "\"\"\"Set requies_grad=Fasle for all the networks to avoid unnecessary computations\n        Parameters:\n            nets (network list)   -- a list of networks\n            requires_grad (bool)  -- whether the networks require gradients or not\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "nets", ",", "list", ")", ":", "\n", "            ", "nets", "=", "[", "nets", "]", "\n", "", "for", "net", "in", "nets", ":", "\n", "            ", "if", "net", "is", "not", "None", ":", "\n", "                ", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.BaseDataset.__init__": [[23, 31], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the class; save the options in the class\n\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "root", "=", "opt", ".", "dataroot", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.BaseDataset.modify_commandline_options": [[32, 44], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"Add new dataset-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n        \"\"\"", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.BaseDataset.__len__": [[45, 49], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the total number of images in the dataset.\"\"\"", "\n", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.BaseDataset.__getitem__": [[50, 61], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return a data point and its metadata information.\n\n        Parameters:\n            index - - a random integer for data indexing\n\n        Returns:\n            a dictionary of data with their names. It ususally contains the data itself and its metadata information.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.get_params": [[63, 79], ["random.randint", "random.randint", "numpy.maximum", "numpy.maximum", "random.random"], "function", ["None"], ["", "", "def", "get_params", "(", "opt", ",", "size", ")", ":", "\n", "    ", "w", ",", "h", "=", "size", "\n", "new_h", "=", "h", "\n", "new_w", "=", "w", "\n", "if", "opt", ".", "preprocess", "==", "'resize_and_crop'", ":", "\n", "        ", "new_h", "=", "new_w", "=", "opt", ".", "load_size", "\n", "", "elif", "opt", ".", "preprocess", "==", "'scale_width_and_crop'", ":", "\n", "        ", "new_w", "=", "opt", ".", "load_size", "\n", "new_h", "=", "opt", ".", "load_size", "*", "h", "//", "w", "\n", "\n", "", "x", "=", "random", ".", "randint", "(", "0", ",", "np", ".", "maximum", "(", "0", ",", "new_w", "-", "opt", ".", "crop_size", ")", ")", "\n", "y", "=", "random", ".", "randint", "(", "0", ",", "np", ".", "maximum", "(", "0", ",", "new_h", "-", "opt", ".", "crop_size", ")", ")", "\n", "\n", "flip", "=", "random", ".", "random", "(", ")", ">", "0.5", "\n", "\n", "return", "{", "'crop_pos'", ":", "(", "x", ",", "y", ")", ",", "'flip'", ":", "flip", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.get_transform": [[81, 113], ["torchvision.Compose", "transform_list.append", "transform_list.append", "transform_list.append", "torchvision.Grayscale", "torchvision.Resize", "transform_list.append", "transform_list.append", "transform_list.append", "torchvision.Lambda", "transform_list.append", "torchvision.ToTensor", "torchvision.Lambda", "torchvision.RandomCrop", "torchvision.Lambda", "torchvision.RandomHorizontalFlip", "transform_list.append", "torchvision.Normalize", "torchvision.Normalize", "base_dataset.__make_power_2", "torchvision.Lambda", "base_dataset.__scale_width", "base_dataset.__crop", "base_dataset.__flip"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.__make_power_2", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.__scale_width", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.__crop", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.__flip"], ["", "def", "get_transform", "(", "opt", ",", "params", "=", "None", ",", "grayscale", "=", "False", ",", "method", "=", "Image", ".", "BICUBIC", ",", "convert", "=", "True", ")", ":", "\n", "    ", "transform_list", "=", "[", "]", "\n", "if", "grayscale", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Grayscale", "(", "1", ")", ")", "\n", "", "if", "'resize'", "in", "opt", ".", "preprocess", ":", "\n", "        ", "osize", "=", "[", "opt", ".", "load_size", ",", "opt", ".", "load_size", "]", "\n", "transform_list", ".", "append", "(", "transforms", ".", "Resize", "(", "osize", ",", "method", ")", ")", "\n", "", "elif", "'scale_width'", "in", "opt", ".", "preprocess", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__scale_width", "(", "img", ",", "opt", ".", "load_size", ",", "method", ")", ")", ")", "\n", "\n", "", "if", "'crop'", "in", "opt", ".", "preprocess", ":", "\n", "        ", "if", "params", "is", "None", ":", "\n", "            ", "transform_list", ".", "append", "(", "transforms", ".", "RandomCrop", "(", "opt", ".", "crop_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__crop", "(", "img", ",", "params", "[", "'crop_pos'", "]", ",", "opt", ".", "crop_size", ")", ")", ")", "\n", "\n", "", "", "if", "opt", ".", "preprocess", "==", "'none'", ":", "\n", "        ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__make_power_2", "(", "img", ",", "base", "=", "4", ",", "method", "=", "method", ")", ")", ")", "\n", "\n", "", "if", "not", "opt", ".", "no_flip", ":", "\n", "        ", "if", "params", "is", "None", ":", "\n", "            ", "transform_list", ".", "append", "(", "transforms", ".", "RandomHorizontalFlip", "(", ")", ")", "\n", "", "elif", "params", "[", "'flip'", "]", ":", "\n", "            ", "transform_list", ".", "append", "(", "transforms", ".", "Lambda", "(", "lambda", "img", ":", "__flip", "(", "img", ",", "params", "[", "'flip'", "]", ")", ")", ")", "\n", "\n", "", "", "if", "convert", ":", "\n", "        ", "transform_list", "+=", "[", "transforms", ".", "ToTensor", "(", ")", "]", "\n", "if", "grayscale", ":", "\n", "            ", "transform_list", "+=", "[", "transforms", ".", "Normalize", "(", "(", "0.5", ",", ")", ",", "(", "0.5", ",", ")", ")", "]", "\n", "", "else", ":", "\n", "            ", "transform_list", "+=", "[", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "]", "\n", "", "", "return", "transforms", ".", "Compose", "(", "transform_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.__make_power_2": [[115, 124], ["int", "int", "base_dataset.__print_size_warning", "img.resize", "round", "round"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.__print_size_warning"], ["", "def", "__make_power_2", "(", "img", ",", "base", ",", "method", "=", "Image", ".", "BICUBIC", ")", ":", "\n", "    ", "ow", ",", "oh", "=", "img", ".", "size", "\n", "h", "=", "int", "(", "round", "(", "oh", "/", "base", ")", "*", "base", ")", "\n", "w", "=", "int", "(", "round", "(", "ow", "/", "base", ")", "*", "base", ")", "\n", "if", "(", "h", "==", "oh", ")", "and", "(", "w", "==", "ow", ")", ":", "\n", "        ", "return", "img", "\n", "\n", "", "__print_size_warning", "(", "ow", ",", "oh", ",", "w", ",", "h", ")", "\n", "return", "img", ".", "resize", "(", "(", "w", ",", "h", ")", ",", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.__scale_width": [[126, 133], ["int", "img.resize"], "function", ["None"], ["", "def", "__scale_width", "(", "img", ",", "target_width", ",", "method", "=", "Image", ".", "BICUBIC", ")", ":", "\n", "    ", "ow", ",", "oh", "=", "img", ".", "size", "\n", "if", "(", "ow", "==", "target_width", ")", ":", "\n", "        ", "return", "img", "\n", "", "w", "=", "target_width", "\n", "h", "=", "int", "(", "target_width", "*", "oh", "/", "ow", ")", "\n", "return", "img", ".", "resize", "(", "(", "w", ",", "h", ")", ",", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.__crop": [[135, 142], ["img.crop"], "function", ["None"], ["", "def", "__crop", "(", "img", ",", "pos", ",", "size", ")", ":", "\n", "    ", "ow", ",", "oh", "=", "img", ".", "size", "\n", "x1", ",", "y1", "=", "pos", "\n", "tw", "=", "th", "=", "size", "\n", "if", "(", "ow", ">", "tw", "or", "oh", ">", "th", ")", ":", "\n", "        ", "return", "img", ".", "crop", "(", "(", "x1", ",", "y1", ",", "x1", "+", "tw", ",", "y1", "+", "th", ")", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.__flip": [[144, 148], ["img.transpose"], "function", ["None"], ["", "def", "__flip", "(", "img", ",", "flip", ")", ":", "\n", "    ", "if", "flip", ":", "\n", "        ", "return", "img", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.__print_size_warning": [[150, 158], ["hasattr", "print"], "function", ["None"], ["", "def", "__print_size_warning", "(", "ow", ",", "oh", ",", "w", ",", "h", ")", ":", "\n", "    ", "\"\"\"Print warning information about image size(only print once)\"\"\"", "\n", "if", "not", "hasattr", "(", "__print_size_warning", ",", "'has_printed'", ")", ":", "\n", "        ", "print", "(", "\"The image size needs to be a multiple of 4. \"", "\n", "\"The loaded image size was (%d, %d), so it was adjusted to \"", "\n", "\"(%d, %d). This adjustment will be done to all images \"", "\n", "\"whose sizes are not multiples of 4\"", "%", "(", "ow", ",", "oh", ",", "w", ",", "h", ")", ")", "\n", "__print_size_warning", ".", "has_printed", "=", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.image_folder.ImageFolder.__init__": [[41, 54], ["image_folder.make_dataset", "len", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.image_folder.make_dataset"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "transform", "=", "None", ",", "return_paths", "=", "False", ",", "\n", "loader", "=", "default_loader", ")", ":", "\n", "        ", "imgs", "=", "make_dataset", "(", "root", ")", "\n", "if", "len", "(", "imgs", ")", "==", "0", ":", "\n", "            ", "raise", "(", "RuntimeError", "(", "\"Found 0 images in: \"", "+", "root", "+", "\"\\n\"", "\n", "\"Supported image extensions are: \"", "+", "\n", "\",\"", ".", "join", "(", "IMG_EXTENSIONS", ")", ")", ")", "\n", "\n", "", "self", ".", "root", "=", "root", "\n", "self", ".", "imgs", "=", "imgs", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "return_paths", "=", "return_paths", "\n", "self", ".", "loader", "=", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.image_folder.ImageFolder.__getitem__": [[55, 64], ["image_folder.ImageFolder.loader", "image_folder.ImageFolder.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "imgs", "[", "index", "]", "\n", "img", "=", "self", ".", "loader", "(", "path", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "if", "self", ".", "return_paths", ":", "\n", "            ", "return", "img", ",", "path", "\n", "", "else", ":", "\n", "            ", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.image_folder.ImageFolder.__len__": [[65, 67], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "imgs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.image_folder.is_image_file": [[19, 21], ["any", "filename.endswith"], "function", ["None"], ["def", "is_image_file", "(", "filename", ")", ":", "\n", "    ", "return", "any", "(", "filename", ".", "endswith", "(", "extension", ")", "for", "extension", "in", "IMG_EXTENSIONS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.image_folder.make_dataset": [[23, 33], ["float", "os.path.isdir", "os.path.isdir", "sorted", "os.walk", "os.walk", "image_folder.is_image_file", "min", "os.path.join", "os.path.join", "images.append", "len"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.image_folder.is_image_file"], ["", "def", "make_dataset", "(", "dir", ",", "max_dataset_size", "=", "float", "(", "\"inf\"", ")", ")", ":", "\n", "    ", "images", "=", "[", "]", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "dir", ")", ",", "'%s is not a valid directory'", "%", "dir", "\n", "\n", "for", "root", ",", "_", ",", "fnames", "in", "sorted", "(", "os", ".", "walk", "(", "dir", ")", ")", ":", "\n", "        ", "for", "fname", "in", "fnames", ":", "\n", "            ", "if", "is_image_file", "(", "fname", ")", ":", "\n", "                ", "path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "fname", ")", "\n", "images", ".", "append", "(", "path", ")", "\n", "", "", "", "return", "images", "[", ":", "min", "(", "max_dataset_size", ",", "len", "(", "images", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.image_folder.default_loader": [[35, 37], ["PIL.Image.open().convert", "PIL.Image.open"], "function", ["None"], ["", "def", "default_loader", "(", "path", ")", ":", "\n", "    ", "return", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.__init__.CustomDatasetDataLoader.__init__": [[65, 80], ["__init__.find_dataset_using_name", "find_dataset_using_name.", "print", "torch.utils.data.DataLoader", "int", "type"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.__init__.find_dataset_using_name"], []], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.__init__.CustomDatasetDataLoader.load_data": [[81, 83], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.__init__.CustomDatasetDataLoader.__len__": [[84, 87], ["min", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.__init__.CustomDatasetDataLoader.__iter__": [[88, 94], ["enumerate"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.__init__.find_dataset_using_name": [[18, 39], ["importlib.import_module", "importlib.import_module.__dict__.items", "dataset_name.replace", "NotImplementedError", "issubclass", "name.lower", "target_dataset_name.lower"], "function", ["None"], []], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.__init__.get_option_setter": [[41, 45], ["__init__.find_dataset_using_name"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.__init__.find_dataset_using_name"], []], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.__init__.create_dataset": [[47, 60], ["__init__.CustomDatasetDataLoader", "__init__.CustomDatasetDataLoader.load_data"], "function", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.__init__.CustomDatasetDataLoader.load_data"], []], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.unaligned_dataset.UnalignedDataset.__init__": [[19, 38], ["data.base_dataset.BaseDataset.__init__", "os.path.join", "os.path.join", "sorted", "sorted", "len", "len", "data.base_dataset.get_transform", "data.base_dataset.get_transform", "data.image_folder.make_dataset", "data.image_folder.make_dataset"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.get_transform", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.base_dataset.get_transform", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.image_folder.make_dataset", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.image_folder.make_dataset"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize this dataset class.\n\n        Parameters:\n            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "BaseDataset", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "self", ".", "dir_A", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "dataroot", ",", "opt", ".", "phase", "+", "'A'", ")", "# create a path '/path/to/data/trainA'", "\n", "self", ".", "dir_B", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "dataroot", ",", "opt", ".", "phase", "+", "'B'", ")", "# create a path '/path/to/data/trainB'", "\n", "\n", "self", ".", "A_paths", "=", "sorted", "(", "make_dataset", "(", "self", ".", "dir_A", ",", "opt", ".", "max_dataset_size", ")", ")", "# load images from '/path/to/data/trainA'", "\n", "self", ".", "B_paths", "=", "sorted", "(", "make_dataset", "(", "self", ".", "dir_B", ",", "opt", ".", "max_dataset_size", ")", ")", "# load images from '/path/to/data/trainB'", "\n", "self", ".", "A_size", "=", "len", "(", "self", ".", "A_paths", ")", "# get the size of dataset A", "\n", "self", ".", "B_size", "=", "len", "(", "self", ".", "B_paths", ")", "# get the size of dataset B", "\n", "btoA", "=", "self", ".", "opt", ".", "direction", "==", "'BtoA'", "\n", "input_nc", "=", "self", ".", "opt", ".", "output_nc", "if", "btoA", "else", "self", ".", "opt", ".", "input_nc", "# get the number of channels of input image", "\n", "output_nc", "=", "self", ".", "opt", ".", "input_nc", "if", "btoA", "else", "self", ".", "opt", ".", "output_nc", "# get the number of channels of output image", "\n", "self", ".", "transform_A", "=", "get_transform", "(", "self", ".", "opt", ",", "grayscale", "=", "(", "input_nc", "==", "1", ")", ")", "\n", "self", ".", "transform_B", "=", "get_transform", "(", "self", ".", "opt", ",", "grayscale", "=", "(", "output_nc", "==", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.unaligned_dataset.UnalignedDataset.__getitem__": [[39, 64], ["PIL.Image.open().convert", "PIL.Image.open().convert", "unaligned_dataset.UnalignedDataset.transform_A", "unaligned_dataset.UnalignedDataset.transform_B", "random.randint", "PIL.Image.open", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return a data point and its metadata information.\n\n        Parameters:\n            index (int)      -- a random integer for data indexing\n\n        Returns a dictionary that contains A, B, A_paths and B_paths\n            A (tensor)       -- an image in the input domain\n            B (tensor)       -- its corresponding image in the target domain\n            A_paths (str)    -- image paths\n            B_paths (str)    -- image paths\n        \"\"\"", "\n", "A_path", "=", "self", ".", "A_paths", "[", "index", "%", "self", ".", "A_size", "]", "# make sure index is within then range", "\n", "if", "self", ".", "opt", ".", "serial_batches", ":", "# make sure index is within then range", "\n", "            ", "index_B", "=", "index", "%", "self", ".", "B_size", "\n", "", "else", ":", "# randomize the index for domain B to avoid fixed pairs.", "\n", "            ", "index_B", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "B_size", "-", "1", ")", "\n", "", "B_path", "=", "self", ".", "B_paths", "[", "index_B", "]", "\n", "A_img", "=", "Image", ".", "open", "(", "A_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "B_img", "=", "Image", ".", "open", "(", "B_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "# apply image transformation", "\n", "A", "=", "self", ".", "transform_A", "(", "A_img", ")", "\n", "B", "=", "self", ".", "transform_B", "(", "B_img", ")", "\n", "\n", "return", "{", "'A'", ":", "A", ",", "'B'", ":", "B", ",", "'A_paths'", ":", "A_path", ",", "'B_paths'", ":", "B_path", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.unaligned_dataset.UnalignedDataset.__len__": [[65, 72], ["max"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the total number of images in the dataset.\n\n        As we have two datasets with potentially different number of images,\n        we take a maximum of\n        \"\"\"", "\n", "return", "max", "(", "self", ".", "A_size", ",", "self", ".", "B_size", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.test_options.TestOptions.initialize": [[10, 25], ["base_options.BaseOptions.initialize", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.set_defaults", "base_options.BaseOptions.initialize.set_defaults", "float", "base_options.BaseOptions.initialize.get_default"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.initialize"], ["def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "parser", "=", "BaseOptions", ".", "initialize", "(", "self", ",", "parser", ")", "# define shared options", "\n", "parser", ".", "add_argument", "(", "'--ntest'", ",", "type", "=", "int", ",", "default", "=", "float", "(", "\"inf\"", ")", ",", "help", "=", "'# of test examples.'", ")", "\n", "parser", ".", "add_argument", "(", "'--results_dir'", ",", "type", "=", "str", ",", "default", "=", "'./results/'", ",", "help", "=", "'saves results here.'", ")", "\n", "parser", ".", "add_argument", "(", "'--aspect_ratio'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'aspect ratio of result images'", ")", "\n", "parser", ".", "add_argument", "(", "'--phase'", ",", "type", "=", "str", ",", "default", "=", "'test'", ",", "help", "=", "'train, val, test, etc'", ")", "\n", "# Dropout and Batchnorm has different behavioir during training and test.", "\n", "parser", ".", "add_argument", "(", "'--eval'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use eval mode during test time.'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_test'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'how many test images to run'", ")", "\n", "# rewrite devalue values", "\n", "parser", ".", "set_defaults", "(", "model", "=", "'test'", ")", "\n", "# To avoid cropping, the load_size should be the same as crop_size", "\n", "parser", ".", "set_defaults", "(", "load_size", "=", "parser", ".", "get_default", "(", "'crop_size'", ")", ")", "\n", "self", ".", "isTrain", "=", "False", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.train_options.TrainOptions.initialize": [[10, 41], ["base_options.BaseOptions.initialize", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.initialize"], ["def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "parser", "=", "BaseOptions", ".", "initialize", "(", "self", ",", "parser", ")", "\n", "# visdom and HTML visualization parameters", "\n", "parser", ".", "add_argument", "(", "'--display_freq'", ",", "type", "=", "int", ",", "default", "=", "400", ",", "help", "=", "'frequency of showing training results on screen'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_ncols'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "'if positive, display all images in a single visdom web panel with certain number of images per row.'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_id'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'window id of the web display'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_server'", ",", "type", "=", "str", ",", "default", "=", "\"http://localhost\"", ",", "help", "=", "'visdom server of the web display'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_env'", ",", "type", "=", "str", ",", "default", "=", "'main'", ",", "help", "=", "'visdom display environment name (default is \"main\")'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_port'", ",", "type", "=", "int", ",", "default", "=", "8097", ",", "help", "=", "'visdom port of the web display'", ")", "\n", "parser", ".", "add_argument", "(", "'--update_html_freq'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'frequency of saving training results to html'", ")", "\n", "parser", ".", "add_argument", "(", "'--print_freq'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'frequency of showing training results on console'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_html'", ",", "action", "=", "'store_true'", ",", "help", "=", "'do not save intermediate training results to [opt.checkpoints_dir]/[opt.name]/web/'", ")", "\n", "# network saving and loading parameters", "\n", "parser", ".", "add_argument", "(", "'--save_latest_freq'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "help", "=", "'frequency of saving the latest results'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_epoch_freq'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'frequency of saving checkpoints at the end of epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_by_iter'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether saves model by iteration'", ")", "\n", "parser", ".", "add_argument", "(", "'--continue_train'", ",", "action", "=", "'store_true'", ",", "help", "=", "'continue training: load the latest model'", ")", "\n", "parser", ".", "add_argument", "(", "'--epoch_count'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'the starting epoch count, we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>, ...'", ")", "\n", "parser", ".", "add_argument", "(", "'--phase'", ",", "type", "=", "str", ",", "default", "=", "'train'", ",", "help", "=", "'train, val, test, etc'", ")", "\n", "# training parameters", "\n", "parser", ".", "add_argument", "(", "'--niter'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'# of iter at starting learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--niter_decay'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'# of iter to linearly decay learning rate to zero'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta1'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'momentum term of adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.0002", ",", "help", "=", "'initial learning rate for adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--gan_mode'", ",", "type", "=", "str", ",", "default", "=", "'lsgan'", ",", "help", "=", "'the type of GAN objective. [vanilla| lsgan | wgangp]. vanilla GAN loss is the cross-entropy objective used in the original GAN paper.'", ")", "\n", "parser", ".", "add_argument", "(", "'--pool_size'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'the size of image buffer that stores previously generated images'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_policy'", ",", "type", "=", "str", ",", "default", "=", "'linear'", ",", "help", "=", "'learning rate policy. [linear | step | plateau | cosine]'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_decay_iters'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'multiply by a gamma every lr_decay_iters iterations'", ")", "\n", "\n", "self", ".", "isTrain", "=", "True", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.__init__": [[16, 19], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset the class; indicates the class hasn't been initailized\"\"\"", "\n", "self", ".", "initialized", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.initialize": [[20, 60], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "float"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "\"\"\"Define the common options that are used in both training and test.\"\"\"", "\n", "# basic parameters", "\n", "parser", ".", "add_argument", "(", "'--dataroot'", ",", "required", "=", "True", ",", "help", "=", "'path to images (should have subfolders trainA, trainB, valA, valB, etc)'", ")", "\n", "parser", ".", "add_argument", "(", "'--name'", ",", "type", "=", "str", ",", "default", "=", "'experiment_name'", ",", "help", "=", "'name of the experiment. It decides where to store samples and models'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_ids'", ",", "type", "=", "str", ",", "default", "=", "'0'", ",", "help", "=", "'gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoints_dir'", ",", "type", "=", "str", ",", "default", "=", "'./checkpoints'", ",", "help", "=", "'models are saved here'", ")", "\n", "# model parameters", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "'cycle_gan'", ",", "help", "=", "'chooses which model to use. [cycle_gan | pix2pix | test | colorization]'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_nc'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'# of input image channels: 3 for RGB and 1 for grayscale'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_nc'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'# of output image channels: 3 for RGB and 1 for grayscale'", ")", "\n", "parser", ".", "add_argument", "(", "'--ngf'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'# of gen filters in the last conv layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--ndf'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'# of discrim filters in the first conv layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--netD'", ",", "type", "=", "str", ",", "default", "=", "'basic'", ",", "help", "=", "'specify discriminator architecture [basic | n_layers | pixel]. The basic model is a 70x70 PatchGAN. n_layers allows you to specify the layers in the discriminator'", ")", "\n", "parser", ".", "add_argument", "(", "'--netG'", ",", "type", "=", "str", ",", "default", "=", "'resnet_9blocks'", ",", "help", "=", "'specify generator architecture [resnet_9blocks | resnet_6blocks | unet_256 | unet_128]'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_layers_D'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'only used if netD==n_layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--norm'", ",", "type", "=", "str", ",", "default", "=", "'instance'", ",", "help", "=", "'instance normalization or batch normalization [instance | batch | none]'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_type'", ",", "type", "=", "str", ",", "default", "=", "'normal'", ",", "help", "=", "'network initialization [normal | xavier | kaiming | orthogonal]'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_gain'", ",", "type", "=", "float", ",", "default", "=", "0.02", ",", "help", "=", "'scaling factor for normal, xavier and orthogonal.'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_dropout'", ",", "action", "=", "'store_true'", ",", "help", "=", "'no dropout for the generator'", ")", "\n", "# dataset parameters", "\n", "parser", ".", "add_argument", "(", "'--dataset_mode'", ",", "type", "=", "str", ",", "default", "=", "'unaligned'", ",", "help", "=", "'chooses how datasets are loaded. [unaligned | aligned | single | colorization]'", ")", "\n", "parser", ".", "add_argument", "(", "'--direction'", ",", "type", "=", "str", ",", "default", "=", "'AtoB'", ",", "help", "=", "'AtoB or BtoA'", ")", "\n", "parser", ".", "add_argument", "(", "'--serial_batches'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if true, takes images in order to make batches, otherwise takes them randomly'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_threads'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "'# threads for loading data'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'input batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_size'", ",", "type", "=", "int", ",", "default", "=", "286", ",", "help", "=", "'scale images to this size'", ")", "\n", "parser", ".", "add_argument", "(", "'--crop_size'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'then crop to this size'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_dataset_size'", ",", "type", "=", "int", ",", "default", "=", "float", "(", "\"inf\"", ")", ",", "help", "=", "'Maximum number of samples allowed per dataset. If the dataset directory contains more than max_dataset_size, only a subset is loaded.'", ")", "\n", "parser", ".", "add_argument", "(", "'--preprocess'", ",", "type", "=", "str", ",", "default", "=", "'resize_and_crop'", ",", "help", "=", "'scaling and cropping of images at load time [resize_and_crop | crop | scale_width | scale_width_and_crop | none]'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_flip'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, do not flip the images for data augmentation'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_winsize'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'display window size for both visdom and HTML'", ")", "\n", "# additional parameters", "\n", "parser", ".", "add_argument", "(", "'--epoch'", ",", "type", "=", "str", ",", "default", "=", "'latest'", ",", "help", "=", "'which epoch to load? set to latest to use latest cached model'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_iter'", ",", "type", "=", "int", ",", "default", "=", "'0'", ",", "help", "=", "'which iteration to load? if load_iter > 0, the code will load models by iter_[load_iter]; otherwise, the code will load models by [epoch]'", ")", "\n", "parser", ".", "add_argument", "(", "'--verbose'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, print more debugging information'", ")", "\n", "parser", ".", "add_argument", "(", "'--suffix'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "help", "=", "'customized suffix: opt.name = opt.name + suffix: e.g., {model}_{netG}_size{load_size}'", ")", "\n", "parser", ".", "add_argument", "(", "'--saveDisk'", ",", "action", "=", "'store_true'", ",", "help", "=", "'save disk memory during testing time'", ")", "\n", "self", ".", "initialized", "=", "True", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.gather_options": [[61, 88], ["base_options.BaseOptions.parse_known_args", "models.get_option_setter", "models.get_option_setter.", "base_options.BaseOptions.parse_known_args", "data.get_option_setter", "data.get_option_setter.", "base_options.BaseOptions.parse_args", "argparse.ArgumentParser", "base_options.BaseOptions.initialize"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.__init__.get_option_setter", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.data.__init__.get_option_setter", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.initialize"], ["", "def", "gather_options", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize our parser with basic options(only once).\n        Add additional model-specific and dataset-specific options.\n        These options are defined in the <modify_commandline_options> function\n        in model and dataset classes.\n        \"\"\"", "\n", "if", "not", "self", ".", "initialized", ":", "# check if it has been initialized", "\n", "            ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", "=", "self", ".", "initialize", "(", "parser", ")", "\n", "\n", "# get the basic options", "\n", "", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "\n", "# modify model-related parser options", "\n", "model_name", "=", "opt", ".", "model", "\n", "model_option_setter", "=", "models", ".", "get_option_setter", "(", "model_name", ")", "\n", "parser", "=", "model_option_setter", "(", "parser", ",", "self", ".", "isTrain", ")", "\n", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "# parse again with new defaults", "\n", "\n", "# modify dataset-related parser options", "\n", "dataset_name", "=", "opt", ".", "dataset_mode", "\n", "dataset_option_setter", "=", "data", ".", "get_option_setter", "(", "dataset_name", ")", "\n", "parser", "=", "dataset_option_setter", "(", "parser", ",", "self", ".", "isTrain", ")", "\n", "\n", "# save and return the parser", "\n", "self", ".", "parser", "=", "parser", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.print_options": [[89, 113], ["sorted", "print", "os.path.join", "util.util.util.mkdirs", "os.path.join", "vars().items", "base_options.BaseOptions.parser.get_default", "open", "opt_file.write", "opt_file.write", "str", "str", "vars", "str"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.util.util.mkdirs"], ["", "def", "print_options", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Print and save options\n\n        It will print both current options and default values(if different).\n        It will save options into a text file / [checkpoints_dir] / opt.txt\n        \"\"\"", "\n", "message", "=", "''", "\n", "message", "+=", "'----------------- Options ---------------\\n'", "\n", "for", "k", ",", "v", "in", "sorted", "(", "vars", "(", "opt", ")", ".", "items", "(", ")", ")", ":", "\n", "            ", "comment", "=", "''", "\n", "default", "=", "self", ".", "parser", ".", "get_default", "(", "k", ")", "\n", "if", "v", "!=", "default", ":", "\n", "                ", "comment", "=", "'\\t[default: %s]'", "%", "str", "(", "default", ")", "\n", "", "message", "+=", "'{:>25}: {:<30}{}\\n'", ".", "format", "(", "str", "(", "k", ")", ",", "str", "(", "v", ")", ",", "comment", ")", "\n", "", "message", "+=", "'----------------- End -------------------'", "\n", "print", "(", "message", ")", "\n", "\n", "# save to the disk", "\n", "expr_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "\n", "util", ".", "mkdirs", "(", "expr_dir", ")", "\n", "file_name", "=", "os", ".", "path", ".", "join", "(", "expr_dir", ",", "'{}_opt.txt'", ".", "format", "(", "opt", ".", "phase", ")", ")", "\n", "with", "open", "(", "file_name", ",", "'wt'", ")", "as", "opt_file", ":", "\n", "            ", "opt_file", ".", "write", "(", "message", ")", "\n", "opt_file", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.parse": [[114, 138], ["base_options.BaseOptions.gather_options", "base_options.BaseOptions.print_options", "base_options.BaseOptions.gpu_ids.split", "int", "len", "torch.cuda.set_device", "base_options.BaseOptions.gpu_ids.append", "base_options.BaseOptions.suffix.format", "vars"], "methods", ["home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.gather_options", "home.repos.pwc.inspect_result.Ha0Tang_AttentionGAN.options.base_options.BaseOptions.print_options"], ["", "", "def", "parse", "(", "self", ")", ":", "\n", "        ", "\"\"\"Parse our options, create checkpoints directory suffix, and set up gpu device.\"\"\"", "\n", "opt", "=", "self", ".", "gather_options", "(", ")", "\n", "opt", ".", "isTrain", "=", "self", ".", "isTrain", "# train or test", "\n", "\n", "# process opt.suffix", "\n", "if", "opt", ".", "suffix", ":", "\n", "            ", "suffix", "=", "(", "'_'", "+", "opt", ".", "suffix", ".", "format", "(", "**", "vars", "(", "opt", ")", ")", ")", "if", "opt", ".", "suffix", "!=", "''", "else", "''", "\n", "opt", ".", "name", "=", "opt", ".", "name", "+", "suffix", "\n", "\n", "", "self", ".", "print_options", "(", "opt", ")", "\n", "\n", "# set gpu ids", "\n", "str_ids", "=", "opt", ".", "gpu_ids", ".", "split", "(", "','", ")", "\n", "opt", ".", "gpu_ids", "=", "[", "]", "\n", "for", "str_id", "in", "str_ids", ":", "\n", "            ", "id", "=", "int", "(", "str_id", ")", "\n", "if", "id", ">=", "0", ":", "\n", "                ", "opt", ".", "gpu_ids", ".", "append", "(", "id", ")", "\n", "", "", "if", "len", "(", "opt", ".", "gpu_ids", ")", ">", "0", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu_ids", "[", "0", "]", ")", "\n", "\n", "", "self", ".", "opt", "=", "opt", "\n", "return", "self", ".", "opt", "\n", "", "", ""]]}